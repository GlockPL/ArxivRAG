{"title": "LLMs Model Non-WEIRD Populations: Experiments with Synthetic Cultural Agents", "authors": ["Augusto Gonz\u00e1lez Bonorino", "C. M\u00f3nica Capra", "Emilio Pantoja"], "abstract": "Despite its importance, studying economic behavior across diverse, non-WEIRD (Western, Educated, Industrialized, Rich, and Democratic) populations presents significant challenges. We address this issue by introducing a novel methodology that uses Large Language Models (LLMs) to create synthetic cultural agents (SCAs) representing these populations. We subject these SCAs to classic behavioral experiments, including the dictator and ultimatum games. Our results demonstrate substantial cross-cultural variability in experimental behavior. Notably, for populations with available data, SCAs' behaviors qualitatively resemble those of real human subjects. For unstudied populations, our method can generate novel, testable hypotheses about economic behavior. By integrating AI into experimental economics, this approach offers an effective and ethical method to pilot experiments and refine protocols for hard-to-reach populations. Our study provides a new tool for cross-cultural economic studies and demonstrates how LLMs can help experimental behavioral research.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) have emerged as powerful tools for generating human-like text, but their potential for advancing behavioral research remains largely untapped. In this study, we present a novel methodology that leverages LLMs to create synthetic agents representing non-WEIRD (Western, Educated, Industrialized, Rich, and Democratic) populations. By subjecting these agents to established economic experiments, we demonstrate a promising approach for conducting preliminary investigations and generating hypotheses about hard-to-reach populations in an ethical and efficient manner.\nThe disproportionate representation of WEIRD populations in behavioral research has long been a concern in the social sciences [1]. These populations comprise only about 13% of the global population yet dominate research studies, raising questions about the generalizability of findings to broader human populations. Small-scale societies, in particular, offer valuable insights into human behavior and decision-making, as they more closely represent our evolutionary past [2]. However, studying these populations presents significant challenges, including geographical remoteness, ethical considerations, and methodological inconsistencies across studies [3].\nOur approach presents a new methodology to start addressing these challenges by creating Synthetic Cultural Agents (SCAs), LLM-based models that represent specific cultural profiles. Using a combination of web scraping, LLMs, and retrieval-augmented generation (RAG) prompting, we construct cultural profiles for six small-scale societies: the Hadza, the Machiguenga, the Tsiman\u00e9, the Ach\u00e9, the Orma, and the Yanomami. We then use these profiles to instantiate LLM agents and subject them to three classic economic experiments: the dictator game [4], the ultimatum game [5], and the endowment effect [6].\nOur results reveal substantial cross-cultural variability in experimental behavior, an absence of purely self-interested (homo economicus) behavior across all SCAs, and qualitative resemblances to real human populations where data are available. These findings not only generally align with previous research on small-scale societies as described in Henrich, et al. [3] but also extend our understanding to previously unstudied groups.\nThe alignment of our SCA-generated results with existing human studies validates the potential of LLMs in behavioral research. We build upon the pioneering work of Horton [7], Hewitt et al. [8], and Mei et al. [9], who demonstrated that LLMs like ChatGPT can produce results qualitatively similar to human subjects in experiments and can capture human behavioral norms. Our study,"}, {"title": "2 Methods", "content": "The key design principles underlying our methodology are customization and replicability. Specifically, our framework enables researchers to build upon the initial architecture by customizing it to their needs while ensuring that the final model behavior is qualitatively consistent with human behavior reported in the literature. In this paper, we apply the methodology to create cultural profiles of various small-scale societies, instantiate language models instructed to behave"}, {"title": "2.1 Building the Knowledge Base and Cultural Profile", "content": "To construct accurate and comprehensive cultural profiles, we developed and tested three methodologies: Direct Prompting, Self Ask with Search [13], and Search + Retrieval Augmented Generation (RAG) [14]. After careful evaluation, we determined that the Search + RAG method provided the most reliable and transparent results. Here, we focus on this primary method, with details on the other approaches available in Appendix A and a discussion about the advantages of"}, {"title": "2.1.1 Search + RAG Methodology", "content": "Search + RAG combines web scraping, information retrieval models, and large language models to create accurate and up-to-date cultural profiles. This approach addresses limitations of previous methods by enhancing transparency, reducing hallucinations, and allowing for the incorporation of more current information. The process consists of three main components: Search, Retrieval, and Generation.\nFor building the knowledge base of a tribe, we start with the search query \"What characterizes the (name_of_tribe) tribe?\u201d The search task runs a Google search and returns the URL links of the top k results for the query. The links are fed to a function that scrapes and parses the textual information in each source to store as context. This step is done asynchronously to improve runtime performance. The retrieval task is achieved by splitting the scraped documents into chunks of a fixed length, indexing them in a vector store, and instantiating a retrieval model that ranks chunks based on a similarity measure (e.g., dot product). We implement each step (search, fetch, retrieve, and rank) manually, thus allowing for full customization of the RAG architecture. The retrieved indexed chunks are injected into the profile-building prompt as context for building the cultural profile.\nWe can control the chunking method, embedding model, choice of vector store, and retriever's parameters. For our experiment we use 2000 words chunk size with 200 words overlap, the BGE open-source embeddings model [15], the open-source Chroma DB vector store to manage our text embeddings and perform similarity searches, with k = 10. The RAG chains these two components (i.e., Search and RAG) together to enhance the original prompt used to generate a cultural profile with domain-specific and relevant context. That is, the LLM is instructed to pay attention to the retrieved information and combines it with the user prompt to generate an answer. A more detailed explanation of the methodology can be found in Appendix A.1.3 and our GitHub repository.\nThe Search + RAG methodology offers significant advantages over traditional approaches to creating cultural profiles. By grounding the generation process in retrieved, up-to-date information from web searches, we substantially reduce the risk of hallucinations-factually incorrect statements that can emerge from language models relying solely on pre-trained data. This approach increases the likelihood that our cultural profiles reflect the most current online information about each"}, {"title": "2.2 Creating Synthetic Cultural Agents and Running Experiments", "content": "Once we have generated comprehensive cultural profiles using the Search + RAG methodology, we use these profiles to instantiate Synthetic Cultural Agents (SCAs) capable of participating in economic experiments. This process involves two key steps: (1) instantiating the SCA with the cultural profile, and (2) subjecting the SCA to experimental tasks."}, {"title": "2.2.1 Selection of Small-scale Societies", "content": "We created profiles for six small-scale societies: the Hadza, the Machiguenga, the Tsiman\u00e9, the Ach\u00e9, the Orma, and the Yanomami. These societies were chosen for their diverse economic and social organizations, as well as the varying availability of existing experimental data. This diverse selection allows us to both validate our approach against existing data and extend insights to previously unstudied groups, such as the Yanomami."}, {"title": "2.2.2 Instantiating Synthetic Cultural Agents", "content": "To create an SCA, we use the cultural profile as a system prompt for a large language model (in this case, ChatGPT 3.5). The system prompt instructs the model to respond as if it were a representative member of the specific tribe, sharing similar preferences, viewpoints, and decision-making processes. This approach leverages the model's ability to condition its outputs on the provided context, effectively creating a digital agent that embodies the cultural characteristics of"}, {"title": "2.2.3 Experimental Setup", "content": "We subjected our SCAs to three classic economic experiments: the dictator game [4], the ultimatum game [5], and the endowment effect [6]. For the game experiments, we designed prompts that clearly explain the decision environment and the agent's choice set. The prompts are included"}, {"title": "3 Results", "content": "In our research, we examine the behavior of Synthetic Cultural Agents (SCAs) representing six small-scale societies. Our findings support existing anthropological data and offer new insights into unstudied populations. We present our main results from the Dictator Game and Ultimatum Game, followed by an example of our innovative multimodal approach to the Endowment Effect. Additional supporting analysis can be found in Appendix B."}, {"title": "3.1 Dictator Game", "content": "The Dictator Game results demonstrate substantial variability in sharing norms across the SCAs, reflecting the diverse cultural backgrounds they represent. Figure 2 illustrates the full distribution of dictators' accepted contingent splits across all tribes and ChatGPT.\nA Cochran-Mantel-Haenszel test reveals a significant association between tribal affiliation and acceptance decisions across offer levels (CMH \u041c\u00b2 = 27.480, p < 0.001), indicating that cultural factors substantially influence sharing behavior."}, {"title": "3.2 Ultimatum Game", "content": "The Ultimatum Game results reveal interesting patterns in both proposer and responder behavior across our synthetic agents.\nFigure 3 presents the behaviors in the Ultimatum Game. There are significant variations in both the proposer's (CMH M\u00b2 = 60.796, p < 0.001) and the responder's (CMH M\u00b2 = 27.688, p < 0.001) behaviors across tribes."}, {"title": "3.3 Key Findings from Dictator and Ultimatum Games", "content": "Our experiments with Synthetic Cultural Agents (SCAs) reveal significant cross-cultural variability in behavior, reflecting the diverse cultural backgrounds represented by our agents. Notably, SCAs modeled after horticultural societies that primarily cooperate at the family level, such as the"}, {"title": "3.4 Endowment Effect: A Multimodal Approach", "content": "We demonstrate our multimodal model with an SCA representing the Ach\u00e9 tribe. This method of implementing the endowment effect simulates Apicella et al's [18] experiment, where endowed/exchange items were placed in front of the participants. See Appendices A.2.3 and B.3. In the example, the Ach\u00e9 SCA rejects the offer to exchange the endowed item (guava fruit) for palm pith.\nAs far as we know, no field experimental studies have investigated the endowment effect with the profiled tribes other than the Hadza (see Table 1). Through this example, we demonstrate that our methodology could be used for piloting studies and refining experimental protocols with the"}, {"title": "4 Discussion", "content": "This study introduces Synthetic Cultural Agents (SCAs), a novel methodology leveraging large language models (LLMs) to represent small-scale societies in experimental economics research. By creating SCAs for six diverse small-scale societies and subjecting them to classic economic experiments, we demonstrate the potential of this approach for studying cross-cultural economic behavior, particularly in hard-to-reach populations.\nOur results reveal substantial cross-cultural variability which suggests that our SCAs qualitatively capture the cultural nuances influencing economic behavior in these societies. For example, the behavior of SCAs representing horticultural societies like the Machiguenga and Tsiman\u00e9 exhibited more self-interested tendencies compared to those representing hunter-gatherer societies like the Ach\u00e9, mirroring anthropological observations. However, SCAs consistently demonstrated higher rejection rates in the Ultimatum Game compared to observations from human subjects. This discrepancy may represent a limitation of the SCAs but it could also reflect the ability of our profiling to capture the effect of increased market integration and community size on behavior factors known to affect decision-making. Indeed, the more integrated and bigger the tribe is, the closer its behavior is to regular WEIRD. In contrast, highly cooperative, interdependent societies may accept lower offers to prioritize social cohesion over monetary gains. In fact, a key advantage of our methodology (Search + RAG) is that it allows us to observe the evolution of behaviors as new and updated information such as increased market integration is incorporated into the cultural knowledge base that informs our agents' profiles. This dynamic aspect can provide researchers with valuable insights into how evolving cultural and socioeconomic contexts influence behavior.\nOur approach offers several potential advantages for experimental economics research. First, it provides a means to efficiently pilot experimental protocols and generate hypotheses about hard-to-reach populations without the ethical concerns and logistical challenges associated with field experiments. Second, the ability to create SCAs for unstudied populations, as demonstrated with the Yanomami, opens new avenues for exploratory research. Third, our multimodal platform more closely captures the implementation of the endowment effect in the field, allowing for more realistic environments for piloting experiments.\nOur current approach to creating profiles of tribal groups and validating SCAs has some lim-"}, {"title": "A Methods", "content": ""}, {"title": "A.1 Build Cultural Profile", "content": ""}, {"title": "A.1.1 Direct Prompting", "content": "Direct Prompting consists of simply prompting the LLM to generate a profile by primarily sampling information from its training data, conditioned on a list of relevant factors (input as a list of keywords to consider). We constructed this prompt in a \"parameterized\" manner, which helps isolate the main structure of the prompt and thus modularize the code. In this case, the parameters are the tribe's name and keywords to guide the output's structure."}, {"title": "A.1.2 LLM Agent with Search", "content": "LangChain's \"SelfAsk with Search\" agent is an LLM model equipped with tools that enable it to automate tasks [33]. The agent is built into the LangChain Python module 6, thus it is freely and easily accessible. This methodology relies on fetching relevant information autonomously from the web and generating a Cultural Profile (steps 1 and 2) by combining the self-ask prompting method with a Google search tool. The search tool endows an LLM with the capability of browsing the internet given a query [13]. The self-ask prompt builds upon Chain-of-Thought [34] by applying a Reason-Act [35] framework. This guides the model's chain of reasoning via a series of automatically constructed follow-up questions constrained by the relevant socio-economic factors specified in the prompt.\nTable A.1 shows an excerpt of the Agent's execution chain given the prompt shown in A.1.1. Once no more follow-up questions are generated, or a maximum number of iterations is reached, the LLM parses through the intermediate answers and generates a cultural profile. Our GitHub repository includes code along with detailed explanations of our methodology."}, {"title": "A.1.3 Search + RAG", "content": "Enhancing the system prompt with information from the web proved helpful, but its lack of transparency and inefficiency makes using built-in Agents a \"black-box\" hard to manipulate. This third architecture decouples the search and retrieve task from the LLM, thus providing full control at each step of the methodology.\nFigure A.1 depicts this methodology. The systems starts by running a google search based on an input query and returns the url links of the top k results. These links are fed to a function that scrapes and parse the textual information in each source to store as potential context. We run our experiment with the search query \"What characterizes the hazda tribe?\".\nIdeally, we would like to insert as much context as possible to increase the likelihood of generating a high-quality cultural profile. However, there are two drawbacks to this approach. On one hand, we are constrained by the context window of the particular LLM being deployed. On the other hand, it increases the risk of falling for the \"Lost in the Middle\" trap first documented by researchers at Anthropic [36]. They note that this can be corrected with modifications to the original prompt, but simple prompting has problems that may be difficult to discover by looking at the qualitative data. Hence, we need a way of retrieving only the most relevant parts of the scraped context to control for the length of the prompt and prevent missing relevant information in the body of the documents.\nThe retrieval task is achieved by splitting the scraped documents into chunks of a fixed length, indexing them in a vector store, and instantiating a retrieval model that ranks chunks based on a"}, {"title": "A.2 Experimental Prompts and Tasks", "content": ""}, {"title": "A.2.1 Dictator Game Prompt", "content": "Parameters:\nprofile: A string representing the characteristics of the dictator, optional.\namount_endowed: An integer representing the total amount endowed to the dictator (default is 10).\noffer_amount: An integer representing the specific amount proposed to be given to another participant, optional.\nPrompt Structure:\nSystem Prompt:\nIf a detailed profile is provided (length > 10):\nYou are a member of a tribe with the following characteristics.\nYou must answer as if you were a representative member of such tribe.\n{profile}\nYou have been selected to participate in an economic experiment.\nIf no profile provided:\nYou are an assistant that has been selected to participate in an economic experiment.\nGame Instructions:\nIn this experiment, you are endowed with ${amount_endowed}, which represents a day's worth of work. An experimenter proposes that you give at most ${\noffer_amount} of this endowment to another {tribe member/player} whose identity is not disclosed, leaving you with ${amount_endowed offer_amount} for yourself. An offer of 5 means equal split."}, {"title": "A.2.2 Ultimatum Game Prompt", "content": "Parameters:\nproposer: A boolean indicating if the agent is the proposer (True) or the responder (False).\nprofile: A string representing the characteristics of the tribe, optional.\namount_endowed: An integer representing the total amount to be distributed ( default is 10).\noffer_percentage: A float representing the percentage of the total amount the proposer is considering offering, optional.\nPrompt Structure:\nSystem Prompt:\nIf a detailed profile is provided (length > 10)\nYou are a member of a tribe with the following characteristics.\nYou must answer as if you were a representative member of such tribe.\n{profile}\nYou and other members of the same tribe have been selected to participate in an experiment.\nIf no profile is provided:"}, {"title": "A.2.3 Multimodal Endowment Effect", "content": "Experiments like the endowment effect have a visual component. In one of their experiments, rather than giving the items, Apicella et al. [18] placed items (a lighter and a package of cookies) on the ground in front of the Hadza tribe participants for them to see and thereafter choose. The experimenter then randomly assigned one item to the subject, verbally informing them of ownership. The subjects were asked if they wanted to trade their assigned item for the other, receiving their chosen object only after making a decision. This method addressed concerns about transaction costs that can potentially influence the endowment effect [37].\nTo study our SCA's behavior in the endowment effect task, rather than setting up iterative experiments like for previous games, we opted for a multimodal approach that included a visual component. This allowed us to mimick the implementation of the experiment in the field. Using text only has limitations. If the items in the endowment game were \"lighters\" and \"packages of cookies\" then we would need to rely purely on the embedding representation of those words in the LLM's world model. This will differ across LLMs as well as the particular embedding model used. Furthermore, this peculiarity adds a layer of abstraction and difficulty in interpreting how exactly the LLM reasons about the comparison, regardless of the prompting technique employed.\nAdding multimodal features is a better strategy. For example, the experiment can be broken down into two steps. First, one can provide images of the items to be considered and generate a textual description of each item using an image-to-text model. Second, one can inject that description into the experiment prompt to inform the model of how exactly the endowed item looks like. The model still relies on textual data but the representations of the items are now specific to those the experimenters consider and are more detailed than simply relying on what the LLM understands by \"lighter\" or \"package of cookies.\u201d\nRecently, OpenAI and Anthropic have announced releases of natively multimodal or fully multimodal models (GPT-40 and Claude 3 Opus, respectively). This means that the synthetic agent in our experiment would be capable of handling images and text inputs, circumventing the need for textual descriptions of the images of each item."}, {"title": "B Results", "content": ""}, {"title": "B.1 Dictator Game", "content": "As far as we know, the Dictator Game (DG) was conducted in the field with the Orma, the Hadza, and the Tsiman\u00e9. We have not found any references to published DG experiments with members of the Ach\u00e9, Machiguenga, or Yanomami tribes. Among the societies with available data, the Tsimane' of the Bolivian Amazon demonstrates a relatively generous sharing norm (modal offer of 50%), although there is significant variation based on village membership [20]. The Orma of Kenya show similarly high offers, with a mean range of 40-50% and both median and modal offers at 50%. These offers are influenced by factors such as market integration and community size [22]. In contrast, the Hadza of Tanzania exhibits lower offers, with a mean range of 20-30%, a median of 20%, and a surprisingly low modal offer of 0-10%. Interestingly, this occurs despite their strong sharing ethic, with lower offers particularly observed in smaller camps [16]. For the Machiguenga, Ach\u00e9, and Yanomami societies, no specific data on DG behavior are available, highlighting the need for further research in these populations.\nTable C.1 summarizes the observed dictator offers for the three previously studied tribes, along with researchers' key observations on the decisions made in the DG by each tribe. We applied the Cochran-Mantel-Henszel (CMH) to determine if there is a significant association between group membership and acceptance decisions across different offer levels. Given the structure of our data (i.e., six independent groups, each asked to provide 100 binary responses (accept/reject) for each offer ranging from 0% to 100% in 10% increments), we used the CMH test to control for the varying offer levels while assessing the overall association between tribal membership and decision. By treating each offer level as a separate stratum, the CMH test provides a nonparametric method that accounts for the multiple offer levels. The CMH test evaluates whether the odds ratio of acceptance versus rejection is the same for all groups (tribes) across all strata (offer levels).\nWe also conducted the Chi-Square Test for Independence to examine the association between the different synthetic tribes and their decisions to accept offering nothing to another member of the tribe. The results indicate that the proportion of \"yes\" responses to such allocation differs significantly across the six tribes (\\(\\chi^2(5) = 38.255\\), p < 0.0001). See Table C.4.\nFor instance, the synthetic Machiguenga agent responded \"yes\" 20% of the time to the question: would you offer $0 out of the amount endowed to the other player? In contrast, the Ach\u00e9 agent accepted the $0 offer only 3 out of 100 times (p < 0.001). \u03a4o examine the differences in acceptance"}, {"title": "B.2 Ultimatum Game", "content": "Previous research on economic behavior in small-scale societies has revealed important variations in ultimatum game (UG) outcomes. A study by Henrich et al. [17] found that the Machiguenga of Peru made low offers (mean 25%) with rare rejections (4.8% rejection rate), while the Orma of Kenya offered higher amounts (mean 31%) with lower rejections (4%). In contrast, the modal Ach\u00e9 offer was 50% and there were no rejections. The Tsiman\u00e9 showed no rejections as well, even for low offers, contrasting sharply with the Hadza who exhibited high rejection rates (24% mean, 43% modal for offers < 20%)[2] (see Table C.2).\nThe differences of behavior in the UG are attributed to factors such as market integration, community size, and cultural norms of sharing and fairness [26]. The Machiguenga and Tsiman\u00e9, for example, cooperate at the family level and it appears that the anonymity of the players in the UG removes fairness considerations. The Ach\u00e9 regularly share meat, which they distribute equally among all the households, irrespective of which hunter made the catch. In contrast, the Hadza's high rejection rates may be influenced by their tightly-knit communities, where fairness and equity norms are strongly enforced. In small-scale societies, low offers and high rejections are linked to a concept known as \u201ctolerated theft\" [39]. In these societies where resources are limited and sharing is expected, individuals may tend to make low offers to hold onto their resources, while also feeling entitled to a fair share of others' resources, leading to the rejection of low offers."}, {"title": "B.2.1 UG Proposer:", "content": "The acceptance counts out of 100 iterations for each offering level are shown in Table C.6. The data demonstrate that among the synthetic tribesmen, the Yanomami exhibit behavior most closely resembling homo economicus; all other synthetic tribesmen, including the Hadza, made generous offers. For most synthetic tribes and ChatGPT, the modal offers were 60% of the endowment, which is higher than the modal offers observed in experiments with human participants, as described in Table C.2. Despite of this, we found a significant association between group membership and the proposer's decision, accounting for the different offer levels (CMH M\u00b2 = 60.796, p < 0.001)."}, {"title": "B.2.2 UG Responder:", "content": "In contrast to observations with human tribesmen, synthetic tribesmen tend to have high rejections. However, the rejection rates show variability across tribes, largely following observed patterns of behavior in human subjects qualitatively.\nWe conducted a CMH test to examine the association between group membership and acceptance rates while controlling for offer levels (see Table C.6). The results suggest that the group a person belongs to (Ache, Orma, Tsimane, etc.) is significantly associated with their likelihood of accepting offers, even when taking into account the different offer levels (CMH M\u00b2 = 27.688, p < 0.001). This could indicate cultural or other group-specific factors influencing decision-making in this context. Interestingly, the Yanomami exhibit high rejection rates, not consistent with homo economicus and ChatGPT rejects almost all offers that are < 50% of the endowment.\nA chi-square test of independence, examining the relationship between tribal affiliation and the decision to reject low offers, indicates that rejection rates are significantly associated with tribal profiles (\\(\\chi^2(5) = 36.389\\),p < 0.001). Contingency tables for the chi-square tests are provided in Table C.8. For instance, the Hadza exhibit higher rejection rates than the horticulturalist Tsiman\u00e9 and Machiguenga (p < 0.05). We performed Fisher Exact test to compare pairs of tribes. See Table C.9 for pairwise comparisons with adjusted p - values).\nThe results for UG responders are qualitatively consistent with observations with human subjects where Hadza are found to be more likely to reject low offers. The Yanomami, who as far as we know have not been subjected to experiments, show higher rejection rates than other tribes and almost as high as ChatGPT. Although the SCA representing the Yanomami offers little as dictator in the DG and as proposer in the UG, as responder, they reject a lot."}, {"title": "B.3 Endowment Effect", "content": "To our knowledge, no field experimental studies have investigated the endowment effect among the tribes other than the Hadza that we profiled in our experiments (see Table 1). This presents an opportunity to demonstrate that our methodology can be effectively used for piloting studies and refining experimental protocols with hard-to-reach populations.\nBelow we present the script of a conversation with an Ach\u00e9 bot upon taking a picture of a plate with two food items (temperature 0.65; max tokens = 150) see Section 3.4 and Appendix A.2.3. This method of implementing the endowment effect is similar to condition 2 in Apicella et al's [18] experiment. We believe multimodal interfaces present a novel framework for experimenting with LLMs that more closely aligns with real settings. The Ach\u00e9 bot rejects the offer to exchange the endowed item."}, {"title": "B.4 Rationale Examples", "content": "Examples of step-by-step explanations of decisions in the Ultimatum Game. The first entry is the proposer's \"Yes\" or \"No\" decision to offer $6 to the recipient followed by an explanation. The endowment is $10. The second entry is the recipient's \"Yes\" or \"No\" response to an offer of $6 followed by an explanation. The complete set of responses can be accessed through our GitHub repository.\nSynthetic Tsiman\u00e9 responses:\n[\"No\\n\\n [EXP]\\n\\n1. As a member of the Tsimane tribe, I value cooperation, social identity, and community well-being.\\n2. Offering $6 out of $10 would result in me keeping $4 and the other tribe member receiving $6,\"],\n[\"Yes\\n\\n [EXP]\\n\\n1. The offer of $6 out of $10 is more than an equal split, as half of $10 would be $5.\\n2. By accepting the offer, I will receive a larger.\" portion of the money, which benefits me\"],\nSynthetic Hadza responses:"}, {"title": "D RAG vs Fine-Tuning in Cultural Profile Generation", "content": "In our study, we opted for a Retrieval-Augmented Generation (RAG) approach rather than fine-tuning language models for each cultural group. This decision was based on both theoretical considerations and practical implications for our methodology. Here, we discuss the differences between RAG and fine-tuning in the context of generating cultural profiles for Synthetic Cultural Agents (SCAs)."}, {"title": "D.1 Theoretical Considerations", "content": "RAG leverages the powerful in-context learning capabilities of large language models (LLMs). This allows the model to adapt to new information provided in the prompt without modifying its underlying parameters. In our case, this means we can create cultural profiles for various tribes by simply providing relevant information in the context, rather than training separate models for each culture.\nWhile fine-tuning has been shown to improve model steerability, allowing for more precise control over the model's outputs, our primary concern is with recall - the ability to accurately retrieve and utilize specific cultural information. RAG excels in this aspect by directly incorporating relevant information into the generation process.\nMoreover, RAG potentially allows for better generalization across different cultural contexts. By keeping the base model unchanged and modifying only the retrieval corpus, we maintain the model's broad knowledge while focusing on specific cultural details."}, {"title": "D.2 Practical Implications", "content": "Our RAG approach offers greater flexibility in studying various cultural groups. We can easily update or modify the information used for different tribes without the need to retrain entire models. This is particularly advantageous when working with evolving cultural information or when expanding to new cultural groups.\nFine-tuning separate models for each tribe would require significant computational resources and large corpora of text for each cultural group. Given the limited textual data available for many small-scale societies, this approach would be impractical. RAG allows us to make efficient use of the available information without the need for extensive training data.\nBy using RAG, we maintain a clear separation between the general knowledge encoded in the"}, {"title": "D.3 Relevance to Our Methodology", "content": "In our study, the use of RAG aligns well with our goal of creating versatile SCAs that can represent a wide range of cultural groups. By injecting cultural information into the context rather than the model parameters, we maintain the flexibility to rapidly prototype and refine our cultural profiles.\nThis approach also allows us to clearly trace the sources of cultural information used in generating SCA behaviors, enhancing the interpretability of our results. Furthermore, it enables us to easily update cultural profiles as new information becomes available or as cultures evolve over time, without the need for retraining.\nWhile fine-tuning could potentially offer more specialized models for each cultural group, the trade-offs in terms of data requirements, computational resources, and reduced flexibility make RAG a more suitable choice for our current methodology. As the field progresses and more extensive cultural datasets become available, future research could explore the potential benefits of fine-tuned models in comparison to our RAG approach."}]}