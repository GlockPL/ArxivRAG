{"title": "Patient-centered data science: an integrative framework for evaluating and predicting clinical outcomes in the digital health era", "authors": ["Mohsen Amoei MSc", "Dan Poenaru MD PhD"], "abstract": "This study proposes a novel, integrative framework for patient-centered data science in the digital health era. We developed a multidimensional model that combines traditional clinical data with patient-reported outcomes, social determinants of health, and multi-omic data to create comprehensive digital patient representations. Our framework employs a multi-agent artificial intelligence approach, utilizing various machine learning techniques including large language models, to analyze complex, longitudinal datasets. The model aims to optimize multiple patient outcomes simultaneously while addressing biases and ensuring generalizability. We demonstrate how this framework can be implemented to create a learning healthcare system that continuously refines strategies for optimal patient care. This approach has the potential to significantly improve the translation of digital health innovations into real-world clinical benefits, addressing current limitations in AI-driven healthcare models.", "sections": [{"title": "Introduction", "content": "The recent explosion in digital health has engendered claims of improved health outcomes through data science, wearable sensors, and artificial intelligence (AI) - particularly the new large language models (LLMs). Despite numerous published models showing equivalent or even improved accuracy in vitro compared to clinicians, very few Al models have been successfully integrated into clinical practice, 1,2 with the first model successfully resulting in actual improved patient outcomes being a standard machine learning (ML) model.\u00b3 This commentary explores the reasons behind the limited real-world progress in digital health and proposes a framework to address contemporary gaps and biases in digital health."}, {"title": "Limitations in Legacy Evaluative and Prognostic Studies", "content": "For centuries, clinical investigators have attempted to generate data which are accurate and faithful to their patients, for evaluating clinical interventions and predicting outcomes. Legacy clinical datasets have perennially been limited in both size and breadth, constrained by manual human collection abilities. These datasets were typically limited to demographic variables and clinical/physiological data such as signs and symptoms, laboratory results, and imaging data.\nIn recent decades, several other healthcare domains have become increasingly sampled, including genomic data, patient-centered outcomes, and a multitude of social determinants of health (SDoH). Integrating these new domains within \u201ctraditional\u201d medical data introduced the challenges of platform incompatibilities and large dataset analysis by conventional statistical methods. Moreover, even the rare integrative biopsychosocial studies seldom addressed the various intersectional identities of the participants. Even when broad healthcare domains were successfully combined with classic clinical datasets, personalized (as opposed to population-based) outcomes often remained elusive due to the loss of analytic power."}, {"title": "The Data Science/Digital Health/AI Era", "content": "Data science as a healthcare research space emerged in the 2000s, promising that \u201cbig data\u201d would answer healthcare questions better and faster. The healthcare data flood began after the turn of the century with the widespread use of electronic health records (EHRs) and computerized monitoring devices, first introduced in the 1970s, followed by the rapid proliferation of wearable monitoring devices in the 2010s. Despite much industry-generated enthusiasm that large amounts of personal health data would improve overall diagnostic and therapeutic abilities, there are several key reasons why this prophecy remains largely unfulfilled.\n1. The main reason is that our healthcare data, no matter how large or \u201crich\u201d, remains woefully\nincomplete. It is our assertion that, in fact, in the recent digital paradigm the extent of data\nincompleteness has increased, rather than decreased. Current healthcare datasets are\ncontinuously growing in size (latest global estimates placing them around 2 zettabytes, i.e.\n2x1021 bytes) through digital data streams, yet their clinical spectrum rarely expands. Once data\nscientists became the collectors and curators of healthcare data, basic tenets such as \"bigger is\nbetter\" and \"any data is good data\" prevailed, leading to fierce competitions for private data and\nmodels gauged by computer science accuracy metrics rather than by patient outcomes.6\n2. Legacy datasets were primarily clinical and physiological, while current datasets are mostly\nphysiologic and genomic. But precise, personalized care requires more than adding \u2018omics and\nwearable data to basic clinical data - it requires a solid sampling of broad other data\ndomains/dimensions.\u00b2 Even within the clinical data collected, the data science trend has been to\ncategorize patients into simple binary categories (disease/feature present/absent), rather than\nwithin the continuum of risk so evident to clinicians.2 In the absence of broad multidimensional\ndata, the industry solution appears to be multimodal data - combining text, images, audio, and"}, {"title": "Suggested Solutions", "content": "There are no clear, easy solutions to the current challenges in digital health. Any hope for a solution must however pause the race for more technology-reported outcomes (TechOs),12 and focus on the meticulous acquisition of truly multidimensional, real-life, longitudinal clinical datasets. These datasets must be patient-centered (rather than disease- or technology-centered), focus on health-related quality of life (HRQOL), and thus be anchored on patient-reported outcomes (PROs) and experiences (PREs). Outcomes reported by patients should not be clinician-defined (as in most generic and disease-specific PRO measures), but rather patients with lived experience of their illness should identify the outcomes that matter to them - as in the rare so-called individualized PROMs, such as the Patient-Generated Index. 13\nThe data must be multidimensional and multi-omic,\u00b94 including the various subcellular 'omes (such as the genome, transcriptome, proteome, metabolome, etc.) and the full phenome (clinical data), but also the exposome, the sociome, and even measures of allostatic stress.15 Longitudinal data is essential, considering patients' ongoing allostatic stress and its incremental impact on both wellness and illness trajectories. Within the exposome and sociome, SDoH and other stressors must be analyzed not only longitudinally but also intersectionally, capturing how social and political identities (such as gender, race, class, sexuality, disability, etc.) intersect and create unique experiences of privilege and oppression.16 The recent concept of the social exposome,\u00b9\u00b9 integrating social determinants and stressors within the broad range of environmental health exposures on an individual, aptly combines the principles of multidimensionality, reciprocity, and continuity along the life course. Beyond accurately describing various populations, the ultimate goal of integrating such vast, diverse patient data is the generation of highly granular, faithful digital representations of individual patients - the \u201cdigital twin\" concept invented decades ago - and its use in the transformation of healthcare processes towards what Eric Topol dubbed \u201cdeep medicine\".18\nAnalyzing such complex, multi-omic datasets will require thoughtfully designed AI models beyond traditional statistics and simple ML models. LLMs appear well-suited for extracting unstructured textual EHR, survey, and qualitative data. Deep neural networks are able to explore complex multi-dimensional, multimodal, longitudinal data to discover latent connections, clustering, and intersectionalities.\nTo be truly patient-centric, healthcare AI models must reflect the multiple outcomes - sometimes conflicting - being sought within each population or sample. \u201cImproved healthcare\u201d as a model policy needs to be replaced by more precise outcomes, such as \u201cdecreased mortality\u201d, \u201cdecreased short-term morbidity\u201d, \u201cimproved long-term clinical outcomes\u201d, \u201cimproved quality of life\u201d, as well as \u201cdecreased (or at least efficient) resource utilization\u201d, to name a few. Within the overall AI model, each individual outcome is assigned to one Al agent, whose task is to optimize for that outcome. Once these individual agents have generated their optimized recommendations, a meta-agent aggregates and analyzes these suggestions to determine the best overall course of action for the patient (Figure 1). The meta-agent, working under the supervision of a \u201chuman-in-the-loop\u201d clinician, considers the interplay between various recommendations, ensuring a holistic approach to patient care that balances different aspects and priorities of the treatment. The meta-agent therefore not only synthesizes the insights from multiple specialized agents, but also adapts dynamically to the patient's evolving health status, embodying a learning healthcare system that continuously refines its strategies for optimal patient outcomes."}, {"title": "Proposed Framework", "content": "Existing frameworks such as the Wilson-Cleary Model22, the International Classification of Functioning model,23 the Valderas-Alonso model,24 the intersectionality wheel,25 and the social exposome framework\u00b9\u00b9 provide as many useful foundations. The proposed framework below (Figure 2) integrates these existing models with the digital health ecosystem, while maintaining patient-centeredness, multi-dimensionality, a lifespan longitudinal perspective, and continuous learning and improvement."}, {"title": "Conclusion", "content": "The integration of AI and data science into healthcare has the potential to revolutionize patient outcomes. However, to fully realize this potential, a paradigm shift towards truly patient-centered, multidimensional data collection and analysis is essential. Current practices that prioritize data quantity over quality and rely on proprietary models have shown limited real-world success. By focusing on longitudinal, intersectional datasets that capture the full spectrum of patient experiences and outcomes, and by employing collaborative AI techniques that can handle such complex data, we can move towards a more personalized and effective healthcare system.\nMoreover, the development and implementation of AI models must be transparent, continuously locally validated, and deeply integrated into clinical workflows with a clear emphasis on improving patient outcomes rather than merely enhancing technological metrics. The proposed integrative framework, which combines the strengths of existing models with a focus on patient-centered data, offers a pathway to achieve these goals. By prioritizing patient-reported outcomes, leveraging collaborative AI techniques, and ensuring rigorous validation, we can create a healthcare environment that not only advances technology but also genuinely improves patient care and quality of life.\nUltimately, the future of digital health depends on our ability to balance innovation with patient-centeredness, ensuring that the benefits of AI and data science are fully realized in the clinical setting. This requires a commitment to ethical practices, continuous learning, and a relentless focus on the needs and experiences of patients. Through such efforts, we can transform the promise of digital health into a reality that delivers on its potential to enhance health and well-being for all."}]}