{"title": "Patient-centered data science: an integrative\nframework for evaluating and predicting\nclinical outcomes in the digital health era", "authors": ["Mohsen Amoei MSc", "Dan Poenaru MD PhD"], "abstract": "This study proposes a novel, integrative framework for patient-centered data science in the digital\nhealth era. We developed a multidimensional model that combines traditional clinical data with\npatient-reported outcomes, social determinants of health, and multi-omic data to create comprehensive\ndigital patient representations. Our framework employs a multi-agent artificial intelligence approach,\nutilizing various machine learning techniques including large language models, to analyze complex,\nlongitudinal datasets. The model aims to optimize multiple patient outcomes simultaneously while\naddressing biases and ensuring generalizability. We demonstrate how this framework can be\nimplemented to create a learning healthcare system that continuously refines strategies for optimal\npatient care. This approach has the potential to significantly improve the translation of digital health\ninnovations into real-world clinical benefits, addressing current limitations in AI-driven healthcare\nmodels.", "sections": [{"title": "Introduction", "content": "The recent explosion in digital health has engendered claims of improved health outcomes through data\nscience, wearable sensors, and artificial intelligence (AI) - particularly the new large language models\n(LLMs). Despite numerous published models showing equivalent or even improved accuracy in vitro\ncompared to clinicians, very few Al models have been successfully integrated into clinical practice, 1,2\nwith the first model successfully resulting in actual improved patient outcomes being a standard\nmachine learning (ML) model.\u00b3 This commentary explores the reasons behind the limited real-world\nprogress in digital health and proposes a framework to address contemporary gaps and biases in digital\nhealth."}, {"title": "Limitations in Legacy Evaluative and Prognostic Studies", "content": "For centuries, clinical investigators have attempted to generate data which are accurate and faithful to\ntheir patients, for evaluating clinical interventions and predicting outcomes. Legacy clinical datasets\nhave perennially been limited in both size and breadth, constrained by manual human collection\nabilities. These datasets were typically limited to demographic variables and clinical/physiological data\nsuch as signs and symptoms, laboratory results, and imaging data.\nIn recent decades, several other healthcare domains have become increasingly sampled, including\ngenomic data, patient-centered outcomes, and a multitude of social determinants of health (SDoH).\nIntegrating these new domains within \u201ctraditional\u201d medical data introduced the challenges of platform\nincompatibilities and large dataset analysis by conventional statistical methods. Moreover, even the rare\nintegrative biopsychosocial studies seldom addressed the various intersectional identities of the\nparticipants. Even when broad healthcare domains were successfully combined with classic clinical\ndatasets, personalized (as opposed to population-based) outcomes often remained elusive due to the\nloss of analytic power."}, {"title": "The Data Science/Digital Health/AI Era", "content": "Data science as a healthcare research space emerged in the 2000s, promising that \u201cbig data\u201d would\nanswer healthcare questions better and faster. The healthcare data flood began after the turn of the\ncentury with the widespread use of electronic health records (EHRs) and computerized monitoring\ndevices, first introduced in the 1970s, followed by the rapid proliferation of wearable monitoring\ndevices in the 2010s. Despite much industry-generated enthusiasm that large amounts of personal\nhealth data would improve overall diagnostic and therapeutic abilities, there are several key reasons\nwhy this prophecy remains largely unfulfilled.\n1. The main reason is that our healthcare data, no matter how large or \u201crich\u201d, remains woefully\nincomplete. It is our assertion that, in fact, in the recent digital paradigm the extent of data\nincompleteness has increased, rather than decreased. Current healthcare datasets are\ncontinuously growing in size (latest global estimates placing them around 2 zettabytes, i.e.\n2x1021 bytes) through digital data streams, yet their clinical spectrum rarely expands. Once data\nscientists became the collectors and curators of healthcare data, basic tenets such as \"bigger is\nbetter\" and \"any data is good data\" prevailed, leading to fierce competitions for private data and\nmodels gauged by computer science accuracy metrics rather than by patient outcomes.6\n2. Legacy datasets were primarily clinical and physiological, while current datasets are mostly\nphysiologic and genomic. But precise, personalized care requires more than adding \u2018omics and\nwearable data to basic clinical data - it requires a solid sampling of broad other data\ndomains/dimensions.\u00b2 Even within the clinical data collected, the data science trend has been to\ncategorize patients into simple binary categories (disease/feature present/absent), rather than\nwithin the continuum of risk so evident to clinicians.2 In the absence of broad multidimensional\ndata, the industry solution appears to be multimodal data - combining text, images, audio, and"}, {"title": "Suggested Solutions", "content": "There are no clear, easy solutions to the current challenges in digital health. Any hope for a solution\nmust however pause the race for more technology-reported outcomes (TechOs),12 and focus on the\nmeticulous acquisition of truly multidimensional, real-life, longitudinal clinical datasets. These datasets\nmust be patient-centered (rather than disease- or technology-centered), focus on health-related quality\nof life (HRQOL), and thus be anchored on patient-reported outcomes (PROs) and experiences (PREs).\nOutcomes reported by patients should not be clinician-defined (as in most generic and disease-specific\nPRO measures), but rather patients with lived experience of their illness should identify the outcomes\nthat matter to them - as in the rare so-called individualized PROMs, such as the Patient-Generated\nIndex. 13\nThe data must be multidimensional and multi-omic,\u00b94 including the various subcellular 'omes (such\nas the genome, transcriptome, proteome, metabolome, etc.) and the full phenome (clinical data), but"}, {"title": "", "content": "also the exposome, the sociome, and even measures of allostatic stress.15 Longitudinal data is essential,\nconsidering patients' ongoing allostatic stress and its incremental impact on both wellness and illness\ntrajectories. Within the exposome and sociome, SDoH and other stressors must be analyzed not only\nlongitudinally but also intersectionally, capturing how social and political identities (such as gender,\nrace, class, sexuality, disability, etc.) intersect and create unique experiences of privilege and\noppression.16 The recent concept of the social exposome,\u00b9\u00b9 integrating social determinants and stressors\nwithin the broad range of environmental health exposures on an individual, aptly combines the\nprinciples of multidimensionality, reciprocity, and continuity along the life course. Beyond accurately\ndescribing various populations, the ultimate goal of integrating such vast, diverse patient data is the\ngeneration of highly granular, faithful digital representations of individual patients - the \u201cdigital twin\"\nconcept invented decades ago - and its use in the transformation of healthcare processes towards what\nEric Topol dubbed \u201cdeep medicine\".18\nAnalyzing such complex, multi-omic datasets will require thoughtfully designed AI models beyond\ntraditional statistics and simple ML models. LLMs appear well-suited for extracting unstructured\ntextual EHR, survey, and qualitative data. Deep neural networks are able to explore complex\nmulti-dimensional, multimodal, longitudinal data to discover latent connections, clustering, and\nintersectionalities.\nTo be truly patient-centric, healthcare AI models must reflect the multiple outcomes - sometimes\nconflicting - being sought within each population or sample. \u201cImproved healthcare\u201d as a model policy\nneeds to be replaced by more precise outcomes, such as \u201cdecreased mortality\u201d, \u201cdecreased short-term\nmorbidity\u201d, \u201cimproved long-term clinical outcomes\u201d, \u201cimproved quality of life\u201d, as well as \u201cdecreased\n(or at least efficient) resource utilization\u201d, to name a few. Within the overall AI model, each individual\noutcome is assigned to one Al agent, whose task is to optimize for that outcome. Once these individual\nagents have generated their optimized recommendations, a meta-agent aggregates and analyzes these\nsuggestions to determine the best overall course of action for the patient (Figure 1). The meta-agent,\nworking under the supervision of a \u201chuman-in-the-loop\u201d clinician, considers the interplay between\nvarious recommendations, ensuring a holistic approach to patient care that balances different aspects\nand priorities of the treatment. The meta-agent therefore not only synthesizes the insights from multiple\nspecialized agents, but also adapts dynamically to the patient's evolving health status, embodying a\nlearning healthcare system that continuously refines its strategies for optimal patient outcomes."}, {"title": "", "content": "The individual agents adopt whichever AI approach best suits the task and the dataset characteristics.\nThis may include both supervised and unsupervised learning, reinforcement learning (RL), and\ntransformer-based approaches based on large-language models (LLMs). While traditional machine\nlearning and deep learning approaches are best suited for tabular, quantitative data derived either from\nphysiologic, genomic, and other tabular data, LLMs are particularly effective in extracting,\nsummarizing, and analyzing unstructured and qualitative textual data. This unique ability to understand\nand interpret patient narratives and experiences through LLMs ensures that the model\nrecommendations are not only data-driven, but also deeply aligned with the patients' subjective\nperspectives and needs. In light of the current concerns regarding the accuracy and reliability of LLMs,\nall such models must be fully anchored to the full medical corpus, and augmented and fine-tuned to the\nlocal datasets. While current approaches are still ill-defined in this emerging space, domain-specific\nretrieval-augmented generation,\u00b9\u00ba transfer or reinforcement learning, and locally generated knowledge\ngraphs20 are all promising venues.\nAnother key principle in the use of AI for healthcare data analysis, regardless of model used, is the\nintentional, assiduous search, exposure, and hopefully remediation of the countless biases\nthreatening every step in each analytic pipeline. This starts with the very cautious use of pre-trained\nlarge language and foundational models, particularly proprietary ones based on undisclosed datasets\nand with unexamined biases. Models generated locally, on the very populations on which they will be\napplied, are ideal. Further steps towards creating bias-free models include continuous analyses of\nmodel outputs for potentially vulnerable populations and health determinants, and continuous model"}, {"title": "", "content": "training and adjustments for temporal data shifts, data drifts, and therapeutic effects. This type of\ncontinuous internal validation is superior to the current external validation standards, 21 and can\nconstitute the basis for a true learning healthcare system, a continuous cycle of data collection, analysis,\nintervention, and model improvement around the patient and their family.\nFinally, the entire end-to-end AI healthcare pipeline must be evidence-based in its creation and\ncontinuous improvement. Ongoing, robust, comparative effectiveness studies of potential\ninterventions must demonstrate their superiority or at least equivalence, ideally paired with decreased\nresource utilization. In keeping with the framework's fierce patient-centeredness, improved clinical\noutcomes, rather than technological model metrics, are to be sought and expected at all times. In this\nframework the healthcare providers, rather than industry interests and agents, will, fully partnered with\ntheir patients, drive the healthcare AI process."}, {"title": "Proposed Framework", "content": "Existing frameworks such as the Wilson-Cleary Model22, the International Classification of Functioning\nmodel,23 the Valderas-Alonso model,24 the intersectionality wheel,25 and the social exposome\nframework\u00b9\u00b9 provide as many useful foundations. The proposed framework below (Figure 2) integrates\nthese existing models with the digital health ecosystem, while maintaining patient-centeredness,\nmulti-dimensionality, a lifespan longitudinal perspective, and continuous learning and improvement."}, {"title": "Conclusion", "content": "The integration of AI and data science into healthcare has the potential to revolutionize patient\noutcomes. However, to fully realize this potential, a paradigm shift towards truly patient-centered,"}, {"title": "", "content": "multidimensional data collection and analysis is essential. Current practices that prioritize data quantity\nover quality and rely on proprietary models have shown limited real-world success. By focusing on\nlongitudinal, intersectional datasets that capture the full spectrum of patient experiences and outcomes,\nand by employing collaborative AI techniques that can handle such complex data, we can move\ntowards a more personalized and effective healthcare system.\nMoreover, the development and implementation of AI models must be transparent, continuously locally\nvalidated, and deeply integrated into clinical workflows with a clear emphasis on improving patient\noutcomes rather than merely enhancing technological metrics. The proposed integrative framework,\nwhich combines the strengths of existing models with a focus on patient-centered data, offers a\npathway to achieve these goals. By prioritizing patient-reported outcomes, leveraging collaborative AI\ntechniques, and ensuring rigorous validation, we can create a healthcare environment that not only\nadvances technology but also genuinely improves patient care and quality of life.\nUltimately, the future of digital health depends on our ability to balance innovation with\npatient-centeredness, ensuring that the benefits of AI and data science are fully realized in the clinical\nsetting. This requires a commitment to ethical practices, continuous learning, and a relentless focus on\nthe needs and experiences of patients. Through such efforts, we can transform the promise of digital\nhealth into a reality that delivers on its potential to enhance health and well-being for all."}, {"title": "Appendix - Existing Frameworks", "content": "Wilson-Cleary Model22\nRelationships among measures of patient outcome in a health-related quality of life conceptual model.\nValderas-Alonso model24"}, {"title": "", "content": "Intersectionality wheel25\nSocial Exposome17"}]}