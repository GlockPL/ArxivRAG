{"title": "Beyond Minimax Rates in Group Distributionally Robust Optimization via a Novel Notion of Sparsity", "authors": ["Quan Nguyen", "Nishant A. Mehta", "Crist\u00f3bal Guzm\u00e1n"], "abstract": "The minimax sample complexity of group distributionally robust optimization\n(GDRO) has been determined up to a log(K) factor, for K the number of groups. In\nthis work, we venture beyond the minimax perspective via a novel notion of sparsity\nthat we dub (\u03bb, \u03b2)-sparsity. In short, this condition means that at any parameter 0,\nthere is a set of at most \u1e9e groups whose risks at 0 all are at least A larger than the\nrisks of the other groups. To find an e-optimal 0, we show via a novel algorithm\nand analysis that the e-dependent term in the sample complexity can swap a linear\ndependence on K for a linear dependence on the potentially much smaller B. This\nimprovement leverages recent progress in sleeping bandits, showing a fundamental\nconnection between the two-player zero-sum game optimization framework for\nGDRO and per-action regret bounds in sleeping bandits. The aforementioned result\nassumes having a particular A as input. Perhaps surprisingly, we next show an\nadaptive algorithm which, up to log factors, gets sample complexity that adapts to\nthe best (\u03bb, \u03b2)-sparsity condition that holds. Finally, for a particular input \u5165, we\nalso show how to get a dimension-free sample complexity result.", "sections": [{"title": "1 Introduction", "content": "Performing well across different data subpopulations and being robust to distribution-shift in testing\nare two of the most important goals in building machine learning models [1-3]. These goals are\nespecially important for models making decisions that could have societal and safety impacts. A re-\ncently proposed framework for achieving these goals is the group distributionally robust optimization\n(GDRO) framework, in which a learner aims to find a single hypothesis that minimizes the maximum\nrisk over a finite number of data distributions. This minimax objective is often considered in the\ncontext of fairness [4, 2, 5] when these distributions represent different demographic groups, or as a\nmeans to promote robustness when they represent possible shifts in the data distribution [6, 7, 3].\nMore formally, given an n-dimensional hypothesis set \u2282R\" and a group of K distributions Pi, the\nlearner aims to solve the optimization min\u0259\u2208\u0259 maxi\u2208 {1,...,K} Ri(0), where R\u2081(0) is the risk of the\nlearner with respect to Pi. Intuitively, this objective encourages the learner to find a model with good\nbalance in performance with respect to a finite number of distributions of data, and avoid models\nthat might perform extremely well on one distribution but have significantly worse performance\non others. The GDRO framework assumes that the learner has access to a sampling oracle, which"}, {"title": "2 Problem Setup", "content": "Let CRn be a compact convex set of hypotheses, Z be a sample space and l : \u04e8 \u00d7 Z \u2192 [0, 1] be\na loss function measuring the performance of a hypothesis on a data point. Similar to previous works\nin GDRO [3, 7], we use the following assumption on and l.\nAssumption 2.1. The diameter of O is bounded as ||0||2 \u2264 D for all \u03b8 \u2208 \u0398. The loss function l is\nconvex and G-Lipschitz in the first argument, i.e., |l(0, .) \u2013 l(0', .)| \u2264 G||0 \u2013 0'||2 for all \u03b8, \u03b8' \u2208 \u0398.\nThere are K groups, each characterized by a distribution Pi,i=1,...,K over Z. Let [K] =\n{1,2,..., K}. Let Ri(0) = Ez~p\u2081[l(0, z)] be the risk of @ with respect to group i. The worst-\ncase risk of a hypothesis @ is measured by its maximum risk over these distributions:\nL(0) = max Ri(\u03b8).\ni\u2208[K]\nThe objective is to find a hypothesis 0* with minimum worst-case risk\n0* = arg min L(0) = arg min max Ri (0).\n\u03b8\u0395\u0398 \u03b8\u0395\u0398 \u03af\u03b5[\u03ba]\n(1)"}, {"title": "2.1 (\u03bb, \u03b2)-Sparsity Structure", "content": "In this section, we formally introduce our novel structure in the GDRO problem. First, we define the\nnotion of a A-dominant set.\nDefinition 2.2. For any \u03bb\u2208 [0, 1] and \u03b8 \u2208 \u0398, a non-empty set of groups S \u2286 [K] is A-dominant at 0\nif there does not exist a group j \u2208 [K] \\ S such that\nmin R\u00bf(0) < R\u2081(0) + \u03bb.\n\u00a1ES\n(2)\nBy definition, for all \u03b8 \u2208 \u0398 and \u03bb \u2208 [0, 1], the set [K] is always a A-dominant set since there does not\nexist any group in the (empty) set [K] \\ S that can make (2) true. When a A-dominant set S \u2260 [K],\nboth S and [K] \\ S are non-empty and Definition 2.2 implies that R\u00bf(0) \u2265 Rj(0) + A for all i \u2208 S\nand j & S. Next, we introduce (\u03bb, \u03b2)-sparsity, a key, novel condition for GDRO problems.\nDefinition 2.3. For \u03bb > 0 and \u03b2\u2208 [1, K], a GDRO problem is (\u03bb, \u03b2)-sparse if for all \u03b8 \u2208 \u0398, there\nexists a A-dominant set whose size is at most \u03b2. If x > 0 and \u03b2 < K, we call (\u03bb, \u03b2) nontrivial.\nBy definition, a GDRO problem instance can be (\u03bb, \u03b2)-sparse for multiple (\u03bb, \u03b2). For example, a\n(0.2, 10)-sparse problem with K = 20 is also (0.2, 11) and (0.1, 10)-sparse. Similarly, there can be\nmultiple A-dominant sets at each \u03b8. Let $1,0 be the collection of all A-dominant sets at 0. Since [K]\nis always a A-dominant set, this collection always contains [K]. Let \u03b2\u03bb,0 = mins\u2208sx.0 |S| be the size\nof the smallest A-dominant set at \u03b8 \u2208 \u0398. Then, we have \u1e9ex = max\u04e9\u2208\u04e9 \u03b2\u03bb,0 is the smallest value of\n\u03b2 such that (\u03bb, \u03b2)-sparsity holds. Moreover, all GDRO instances are trivially (0, 1)-sparse, in which\ncase the 0-dominant set contains one of the groups with maximum expected loss. If (\u03bb, \u03b2)-sparsity\nholds for nontrivial (\u03bb, \u03b2), then for every model, there is a prominent gap in the outcome (i.e. risks) of\napplying that model across different groups. Figure 1 (right) illustrates the mathematical plausibility\nof nontrivial (\u03bb, \u03b2)-sparsity in the continuous domain via a simple example with O = [0, 1]. In the\nnext section, we begin by presenting a first algorithm which, for any input \u03bb\u2208 (0, 1], returns an\ne-optimal solution to the GDRO problem with sample complexity of order (\nKn + D\u00b2\u00b2+x).\nFor any such \u5165 \u2014 including trivial choices for which \u1e9ex = K, this algorithm (with high probability)\nprovides a valid sample complexity guarantee, but the guarantee is most useful for the unknown,\noptimal \u5165 - call it A* - that minimizes the sample complexity. The focus of Section 4 is a second,\nadaptive algorithm that obtains, without any knowlege of A*, sample complexity whose order is not\nmuch larger than that of the first algorithm when it is fed X*\u00b7"}, {"title": "3 Two-Player Zero-Sum Game Approach", "content": "In this section, we present a new algorithm called SB-GDRO that, for a given input \u03bb\u2208 (0,1],\nobtains an improved O (Knln(GDK/8) + (G2D2+8x)\n(K/8)) sample complexity. Let Ak be the\nK-dimensional probability simplex. For any q \u2208 \u0394\u03ba, let \u03c6(0, q) = \u2211=1qi Ri\u2081(0) be the weighted\nsum of the risks of 0 over K groups. Following [10], we write the objective function in (1) as\nmin L(0) = min max (0,q).\n\u03b8\u0395\u0398 \u03b8\u0395\u0398 \u0395\u0394\u039a\nThe optimality gap of a pair \u03b8\u2208 \u0398 and \u1fb7 \u2208 \u2206k is defined as follows:\nerr(0, 9) max (0, q) - min (0,9).\n\u0395\u0394\u039a \u0398\u0395\u0398\nSince L(0) \u2265 (\u03b8, \u1fb7) for all \u03b8, we have err(0) \u2264 err(\u0113, \u0101). To minimize err(\u0113, \u0101), similar to existing\nworks [10, 8], we employ the following two-player zero-sum game approach: a game is run in T\nrounds, where in each round, there are two players As and Aq corresponding to the min and max\noperators in the objective function (1). In round t, the min-player Ae first plays a hypothesis \u03b8t, and"}, {"title": "3.1 Computing the Dominant Sets", "content": "Before the game starts, a set of m samples is drawn from each of K groups, where m will be defined in\nLemma 3.1. Let Vi,j \u2208 Vi be the j-th sample collected from group i. Let R\u2081(0) = = = l(0, Vi,j)\nbe the empirical risk of @ with respect to Vi. To compute a 0.4\u5165-dominant set at Ot, we use the\nalgorithm DominantSet (Algorithm 2) which traverses the groups in order of decreasing R\u2081(0t) and\nreturns a set So, of groups up to (and including) the first group whose empirical risk exceeds the\nnext group's empirical risk by at least t = 0.7\u5165. The following lemma states a uniform convergence\nbound that holds for a sufficiently large value of m.\nLemma 3.1. Let m = 384n In (7416DK). With probability at least 1 8/2, the event\n\u0395\u03af,\u03b8 = {|Ri(0) \u2013 R\u2081(0)| \u2264 0.151}\n(6)\nholds simultaneously for all i \u2208 [K] and \u03b8 \u2208 \u0398.\nThe next lemma shows that if all events (Ei,0)i\u2208[K],\u03b8\u2208\u04e9 hold, then the set So, returned by Algorithm 2\nis a 0.40-dominant set at Ot whose size does not exceed \u03b2x. This implies that the max-player only\nneeds to sample the groups in \u015ce, in order to maximize the cumulative risks over T rounds.\nLemma 3.2. If Ei,o holds simultaneously for all i \u2208 [K] and 0 \u2208 \u2295 then for any t \u2208 [T], the set \u015cor\nreturned by DominantSet is a 0.41-dominant set at Or. Moreover, So"}, {"title": "3.2 Non-Oblivious Sleeping Bandits", "content": "In this section, we discuss the sleeping bandits problem [11]. Sleeping bandits is a variant of the\nadversarial multi-armed bandit problem with K total arms, where arms can be non-active in each\nround. Formally, in round t = 1, 2, . . ., T, an adaptive adversary gives the learner a set At \u2286 [K]\nof active arms. For each arm i \u2208 At, the adversary also selects a (hidden) loss value hi,t \u2208 [0,1].\nThe learner pulls one active arm it \u2208 At, observes and incurs the loss hit,t. Let Ii,t = 1{i \u2208 At}.\nFor any a \u2208 [K], the per-action regret of the learner with respect to arm a is the difference in the\ncumulative loss of the learner and that of arm a over the rounds in which a is active:\nRegret(a) = \u2211 Ia,t(hit,t - ha,t).\n(7)\nModified EXP3-IX for sleeping bandits. We use an algorithm called SB-EXP3 [12] for sleeping\nbandits. SB-EXP3 uses the standard IX-loss estimate [19] as the loss estimate hit in round t, i.e.,\nhit = hi,t1{it=i}, where Yt > 0 is the exploration factor in round t. For each arm i, over T rounds\nSB-EXP3 maintains a weight vector \u1fb7t \u2208 R defined as\nqi,t = exp nq,t t-1 Lhs,s - his - ys jeSes hj,s .\nwhere nq,s > 0 is the learning rate and his is the loss estimate of arm i in round s. Initially \u011di,1 = 1\nfor i \u2208 [K]. The sampling probability qt is computed by a filtering step, where inactive arms have"}, {"title": "3.3 Sample Complexity of SB-GDRO", "content": "In SB-GDRO, the max-player uses SB-EXP3 to compute the group-sampling probability qt. For the\nmax-player, the set So, in Algorithm 4 plays the same role as the set At of active arms in sleeping\nbandits: each group is an arm, and the set of \"active groups\" in each round depends on \u03b8t, which is\ndecided by a non-oblivious adversary (i.e. the min-player). Furthermore, choosing a group it ~ Qt\nand then drawing zit,t ~ Pit is mathematically equivalent to having K samples {zi,t ~ P\u00bf | i \u2208 [K]}\n(one from each group) but observing only the sample Zit,t. The hidden stochastic loss of group i in\nround t is l(0t, Zi,t). Note that SB-EXP3 is formulated in terms of minimizing losses rather than\nmaximizing gains, so similar to [9], we set hi,t = 1 - l(0t, zi,t) to be the (hidden) stochastic losses\nof arms i for SB-EXP3. By making a fundamental connection between the two-player zero-sum\ngame approach in GDRO and sleeping bandits, the following lemma upper bounds the regret of the\nmax-player R\u2081\u2081 by the per-action regret with \u015ce, the set of active groups at round t.\nLemma 3.4. If Ei,e holds simultaneously for all i \u2208 [K] and 0 \u2208 \u0398, the regret of the max-player Aq\nis bounded by the following per-action regret:\nRA, \u2264 max \u03a31{\u03af \u2208 \u015c\u03b8\u03b5} (Ri(\u03b8\u03b5) \u2013 (0t, qt)) .\ni\u2208[K] t=1\n(9)\nTheorem 3.3 and Lemma 3.4 imply the following sample complexity bound of SB-GDRO.\nTheorem 3.5. For any \u0454 > 0, \u03b4 \u2208 (0,1), with probability 1 \u2013 \u03b4, Algorithm 1 with learning rates\nNw,t = \u221at, Ng,t = 2Yt = returns an e-optimal hypothesis with sample complexity\nln(3K/\u03b4)\n\u039f\n(\nKnln(GDK/8) (D2G\u00b2 + \u03b2x) ln(K/\u03b4)\n+\n\u20ac2\nIn Theorem 3.5, because A is a fixed problem-dependent quantity while the required optimality gap e\ncan be arbitrarily small, the dependency on K in Theorem 3.5 is dominated by O (\n\u03b2\u03bb ln(\u039a/\u03b4)\n).\n\u20ac2\nThe following lower bound shows that the upper bound in Theorem 3.5 is essentially near-optimal.\nTheorem 3.6. For any algorithm A and any constants > \u2265 0.5, \u03b2 > 3, there exists a (\u03bb, \u03b2)-sparse\nGDRO instance with \u1e9ex = \u03b2 such that the sample complexity of A is at least \u03a9 (G2D2+B\n\u20ac2\n)"}, {"title": "4 *-Adaptive Sample Complexity Bound", "content": "Theorem 3.5 suggests that a desirable \u00c0 must be significantly larger than e (so that \u226a)) but\nalso not too large (so that \u1e9ex < K). In this section, we define the notion of an optimal X and present\na sample-efficient approach for adapting to this unknown * without any further assumptions. First,\nwe write the sample complexity in Theorem 3.5 in the following form:\nln(\u039a/\u03b4)\n+(1)\n+\nD2G2 ln(K/\u03b4)\n\u20ac2\n,\n(10)"}, {"title": "4.1 A Sample-Efficient Approach for Estimating AC,9,*", "content": "We present an algorithm called EstOptLambda for solving OPT(C', \u20ac, g). EstOptLambda outputs\na\u00c2 such that f(x) = O(f(x*)) while using at most O(f(1*) ln(K/8) ln(1/\u20ac)) samples. The\nsignificance of this result in the context of GDRO is as follows: by using O(f(x)) samples to obtain\nan estimate \u00c2 and then using \u00c2 for GDRO, we guarantee that the total sample complexity is of order\n\u00d5(f(x)). This implies that without knowing \u5165\u2217, we can achieve a bound with only a logarithmic\nfactor overhead than the bound obtained when \u5165\u2217 is known. Our results and techniques are applicable\nto other trade-off problems similar to (11), and thus they could be of independent interest.\n1 1\nThe main idea of EstOptLambda is maintain two variables U and L which specify an interval\n[L, U] that always contains a good estimate for \u5165*. We iteratively evaluate g(x) for \u03bb \u2208 [L, U] and\nshrink this interval over time, i.e., U monotonically decreases while L monotonically increases. The\nshrinking process is based on comparing f(x) and f (U): if f(x) < f(U) holds, then U is set to \u5165\nand L is increased accordingly. A crucial element of this process is choosing the geometric sequence\n(1, \u0a1b\u0a47, \u0a1b, ...) of common ratio as the sequence of A at which g(x) is evaluated. The process stops\nwhen X < L, at which point the algorithm return the last value of U as an estimate for \u5165*. The\nfirst key technical insight of this process is that L and U can be computed using only readily known\nquantities such as C, K and evaluated g(x). The second key technical insight is after some finite\nnumber of steps, it is guaranteed that any value in the interval [L, U] is a good estimate for \u5165*. The\ngeometric sequence ensures that there are at most ln(1/6) values of g(x) need to be evaluated, leading\nto the ln(1/6) multiplicative factor in the final bound. The full procedure is given in Algorithm 6 in\nAppendix B.1. The following lemma states the sample complexity of this approach.\nTheorem 4.1. For any OPT(C, g) problem defined in (11), EstOptLambda (Algorithm 6) returns a \u00c2\nsuch that f(1) < 50f(x\u2217) while using at most O (f(x\u2217) ln(K/8) ln(1/e)) samples."}, {"title": "4.2 A-Adaptive Sample Complexity Bound for GDRO", "content": "ln(K/\u03b4)\nWe present an algorithm called SB-GDRO-Full for GDRO, whose full procedure is given in Algo-\nrithm 8 in Appendix B.2. First, we specify a method that, given a \u03bb \u2208 [0, 1], returns an estimate\n\u03b2 for Bx using at most O(\u0108ln(K/8)) samples, where \u0108 = Knln(GDK ln(1/\u20ac)/8) Our estimation is\nbased on a covering argument, which was also used the proof of Lemma 3.1. More specifically, let\n-cover of \u0398. That is, for all \u03b8 \u2208 \u0398, there exists \u03b8' \u2208 \u2295 such that ||\u03b8' \u2013 0||2 \u2264 0.11/G.\nBecause is convex compact, has finitely many hypotheses. Let \u017f) (1), . . ., \u00f4(||) be the centers of\nthe l2-balls of radius within. At (1), a 0.41-dominant set S'(i) is computed using Algorithm 2.\nThen, we use\nbe a\n0.1\u03bb\n\u03b2\u03bb = max=1,2,...|||S(i)| as an estimate for \u03b2\u03bb."}, {"title": "5 A Dimension-Free Sample Complexity Bound", "content": "In this section, we present SB-GDRO-DF, a modified version of Algorithm 1 that uses\nsamples for computing the dominant sets over T rounds of the two-\nKDG\u221a(D2G2+\u03b2) KDGD 1n(K/\u03b4)\n\u03bb\u03b5\nplayer zero-sum game. This bound avoids the dependency on n, the dimension of O, which might\nbe preferable in high-dimensional settings. The trade-off for getting rid of n is an additional multiplicative factor in the non-leading term of the sample complexity bound.\n\u03bb\u03b5\nWe assume that a pair (\u03bb, \u03b2) is known such that the problem instance is (\u03bb, \u03b2)-sparse. Unlike\nSB-GDRO, SB-GDRO-DF does not use a fixed set of samples V for computing the dominant sets of\nall \u03b8\u2208 \u0398. Instead, SB-GDRO-DF computes the dominant sets only for the hypotheses \u03b8t that the\nlearner encounters during the game. In particular, the T rounds are divided into episodes, in which\neach episode has a consecutive rounds that use the same dominant set. By the stability property\nof the regularized update (5) and the Lipschitzness of the loss function l, if o is sufficiently small\nthen the differences between the risks of the hypotheses within each episode is small. This implies\nthat a dominant set for et will remain a dominant set (possibly with smaller gaps) and therefore can\nbe reused for the hypotheses Ot+1, 0t+2,..., 0t+6. The full procedure is given in Algorithm 9 in\nAppendix C, and its sample complexity is stated in the following theorem.\nTheorem 5.1. For any \u0454 > 0, \u03b4 \u2208 (0,1), with probability 1 \u2013 8, SB-GDRO-DF with yw,t = GVT'\n2D\nNg,t and Yt defined in Theorem 3.5 returns an e-optimal hypothesis with sample complexity\n\u039f\n(\nDKG\u221a(D2G2 + 3) ln(K/8) ln(KD) (D2G\u00b2 + \u03b2) ln(K/\u03b4)\n\u03bb\u03b2\u03b5\n+48)m(K/8)).\n\u20ac2"}, {"title": "6 Conclusion and Future Work", "content": "In this paper, we introduced a new structure called (\u03bb, \u03b2)-sparsity into the GDRO problem. We showed\na fundamental connection between the per-action regret in sleeping bandits and the optimality gap of\nthe two-player zero-sum game approach for the GDRO problem. Based on this novel connection, we\nreduced the dependency on the number of groups K from O(Kln(K)) to O(\u03b2ln(K)) in the leading\nterm of the sample complexity of (\u03bb, \u03b2)-sparse problems, even when the optimal X is unknown. We\nalso showed a near-matching lower bound, which both extends and generalizes the lower bound\nconstruction in minimax settings to the (\u03bb, \u03b2)-sparse settings.\nFuture work. There are a number of interesting directions going forward. One such direction is\ndeveloping a \u03b2\u5165 estimation algorithm that runs in polynomial time of the dimension n, improving the\npracticality of SB-GDRO in high-dimensional settings. Furthermore, it would be of great interest\nto relax the (\u03bb, \u03b2)-sparsity to hold only within some neighborhood of 0*. We did consider this\nrelaxation but found that leveraging it with our current algorithmic paradigm would require last"}, {"title": "A Proofs for Section 3", "content": "For a pseudometric space (F, ||.||), for any v > 0, let N(F, v, ||.||) be the v-covering number of F;\nthat is N(F, v, ||.||) is the minimal number of balls of radius v needed to cover F.\nA.1 Proof of Lemma 3.1\nOur proof for the uniform convergence bound in Lemma 3.1 is based on the Rademacher complexity\nbound of the class of functions Le defined as follows:\nLe = {l(0, .) : Z \u2192 [0, 1], 0 \u2208 \u04e8},\n(13)\nwhich is the set of all possible functions l(0, .) for \u03b8 \u2208 \u0398. First, we state the following bound for the\nempirical Rademacher complexity based on the chaining argument [22, 23].\nLemma A.1. (Dudley's Entropy Integral Bound [22, 23]) Let F = {f : Z \u2192 R} be a class of\nreal-valued functions, S = {21, Z2, ..., zm} be a set of m random i.i.d samples. For a function\nf\u2208 F, let\n|| f ||2,s = (f(zj))2\nm\nj=1\nbe an S-dependent seminorm of f. Assuming\nsup ||f||2,s \u2264 c,\nfEF\nwhere c is a positive constant, we have\nRad(F, S) inf\n+ m (f(zj)\n,m))d) .,\nv,\n(14)\n(15)\nwhere Rad(F, S) = \u201eEr\u2208{1}m [supfeF j=1&jf(j)] supfeF j=1&j f(zj) is the empirical Rademacher complexity\nof F and N(F, v, ||.||2,s) is the size of a v-cover of F.\nA proof of this lemma can be found in [23]. We now prove Lemma 3.1.\nProof (of Lemma 3.1). For i \u2208 [K], Theorem 26.5 in [24] states that with probability at least 1 over the set Vi of size m, for all \u03b8\u2208 \u0398,\n\u03a3l(0, Vi,j) \u2013 Ri(0) \u2264 2Rad(Le, Vi) +\n32ln(4K/\u03b4)\nm\nOur proof is based on the fact that the covering number of the compact set OCR is finite, and\nhence the empirical Rademacher complexity Rad(Le, Vi) is bounded for all i \u2208 [K]. Because the\nvalues of the loss function l is in [0, 1], we have || f ||2,v\u2081 \u2264 1 for all f \u2208 Le. Moreover, the diameter\nof L\u0259 measured in ||.||2,v, is\n1\nmax (l(0, Vi,j) \u2013 (0', Vi,j))2 \u2264 max 2||0 \u2013 0' ||2\nm\n\u03a3G G\nj=1\nm\n(f(zj))2\nmm\nj=1\nj=1\nm m\nj=1"}, {"title": "A.2 Proof of Lemma 3.2", "content": "Proof. Let Ri,t = Ri(0t) and Ri,t = Ri(0t) be the risk and empirical risk of \u03b8t with respect to\ngroup i, respectively. We consider two cases: \u03b2\u03bb < K and \u1e9ex = K."}, {"title": "A.3 Proof of Theorem 3.3", "content": "Let At = At be the number of active arms in round t. Throughout this section, we write Nt = Ng,t\nfor the learning rate of the SB-EXP3 algorithm used by the max-player.\nThe O high-probability per-action regret bound of the SB-EXP3 algorithm\nin [12] was established for a fixed learning rate nt = \u03b7 and a fixed exploration factor Yt = \u03b3. In this\nsection, we generalize their result to algorithms with time-varying learning rates and exploration\nfactors defined as follows:\n(\u221aln(K/\u03b4) \u03a31 At)10\nNt = 2Yt =ln(3K/\u03b4)/ \u03a3As .\n(18)\nNote that nt and Yt are chosen after the set of active arms At is revealed. As pointed out in [12,\nAppendix G], the SB-EXP3 algorithm is equivalent to their Follow-the-Regularized-and-Active-\nLeader (FTARL) algorithm with the Shannon entropy regularizer. Therefore, a high-probability\nregret bound of FTARL with Shannon entropy regularizer and nt and Yt defined in (18) would imply\nTheorem 3.3. For completeness, we provide the full procedure of FTARL with Shannon entropy\nregularizer in Algorithm 5. For each arm i \u2208 [K] and round t \u2208 [T], this algorithm maintains an\nestimated cumulative loss Li,t defined as\nList = list,\nand computes the weight of arm i in round t by\nqi,t =\nexp(-mLit-1)\n\u03a3exp(-mLj,t-1)\u1fbd\nwhere nt is the learning rate in round t. Initially, \u017d\u00bf,0 = 0 for all arms i \u2208 [K]. Upon receiving the\nset At of active arms, the sampling probability pt is computed by normalizing Ii,tqi,t as follows:\nPi,t =\nIilit\nj=1Ij.tqj.t\n(19)"}, {"title": "A.4 Proof of Lemma 3.4", "content": "Proof. Since Ak is convex, we can write\n\u03a3\u03c6(\u03b8\u03c4, 9)\nmax \u03a3qiRi (0)\nmax\n\u03a6\u0395\u0394\u039a\nt=1\n\u03a4\nt=1\nmax\n\u03a6\u0395\u0394\u039a\nt=1\nmax\n\u03a6\u0395\u0394\u039a\t=1TK\n TK\ni=1qERistRistqiq\nTqiqiqi,t T\n+==\u03a3\u03a3\u03a3i i \u03a3\nRi,t Rist.\ni=1max 1Thus, max1max 1(q),\nTK Riqi Ri(qi(,0))\nEKK i T(ii \u03a3\u03a3t(\u03a3\n(t i f a group1sn 7n (f 7n sn 7n\ni=1 1s1 1s\ni1ni 1i==tii\nTqiqiqiqiqiR11.0()0()sn ()()(,)qsn\n(t1\ni1i<<<<<<==<t\t=1\n\"", "T\n\u03a3\u03c6(\u03b8\u03c4))": "T Ri (qi (0t)))qq\n\u00ab() \u03a3qq()()"}, {"title": "A.5 Proof of Theorem 3.5", "content": "Let \u1e9et\n=\n|So,| be the size of So. Let \u1e9er =\nT\n+ =1 \u1e9et be the average number of active groups over\nT rounds. We first state the following bound for the regret of the max-player as a function of \u1e9et,\nwhich is obtained directly by combining Theorem 3.3 and Lemma 3.4."}, {"title": "Lemma A.3. With probability at least 1", "content": "A77,the regret of the max-player in SB-GDRO (Algorithm 1)\nis bounded by\n() 71(7)) 771() 0 <"}, {"title": "A.6 Proof of Theorem 3.6", "content": "Proof. Our lower bound construction directly extends that of [8]. In particular, let Z = [0, 1]\u00b3 be the\nset of samples and = [0, 1] be the hypothesis set. The loss of a hypothesis @ on a sample z =\nis\n2223(()1 1+ +) 3((\n1\nThe distributions of the first B groups are similar to that of [8], where 711++= +a(()"}, {"title": "Algorithm 6 EstoptLambda: algorithm for solving OPT(C, g)", "content": "Input: \u20ac \u2208 (0,1), 3 < K < C\nEvaluate g(1)\n2)\n1\nInitialize U = 1, L = ()+1;1 = 1;\nwhile > L doEvaluate g(x)\nif f() < f(U) then Assign U < 1, L < U\nUpdate = 1/5Return: 6 = U.\n(()+1)\"", "1)": 1, "2()": ""}, {"title": "B Proofs for Section 4", "content": "B.1 Proof for Section 4.1\nEstoptLambda (Algorithm 6) maintains a range of values [L,U] that always contains at\nleast one good estimate for A*, and evaluates g(x) at elements of the geometric series\n(U, 0+ , 0+ , 0+ ) to compute this estimate. Note that all elements of this series are\nin [L, U]. Whenever f(x) is strictly smaller than f(U) for some A, we shrink the range [L, U] by\nsetting U = A and L = (()+1). We first prove the following lemma which shows that L\nis always smaller than or equal to A*, thus at least one g(A) for A < A, will be evaluated while\nrunning EstOptLambda.\nLemma B.1. For any U \u2208 (0,1], let ((()())((("}, {"title": "((++(7(++)B.2 Proofs for Section 4.2", "content": "Let B(0, r) = {\u03b8' \u2208 \u0398 : ||0 \u2013 0\u2032 ||2 \u2264 r} be a l2-ball of radius r centered at \u03b8 \u2208 \u0398. In this section,\nwe prove Theorem 4.2 which specifies the sample complexity of SB-GDRO-Full (Algorithm 8) for\nthe setting where no A is known beforehand. The most important component of SB-GDRO-Full\nis computing an estimate A for the optimal A\u2217 using the algorithm EstoptLambda (Algorithm 6).\nThis computation uses the algorithm EstG (Algorithm 7) to compute an estimate of Bx for A in the\ngeometric sequence (1,\n1 1\n5, 25, ...) of common ratio.\nFirst, we prove the following lemma which bounds the number of A tested in Algorithm 6.\nLemma B.4. For any OPT(C, g) problem, in EstOptLambda (Algorithm 6), the number of values A\nwhose g(A) need to be evaluated is at most N = n 2 (0))++9"}, {"title": "Algorithm 7 EstG: estimating g(1) for A in the geometric sequence of common ratio", "content": ""}]}