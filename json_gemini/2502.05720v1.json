[{"title": "Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search", "authors": ["Ziyad Benomar", "Lorenzo Croissant", "Vianney Perchet", "Spyros Angelopoulos"], "abstract": "One-max search is a classic problem in online decision-making, in which a trader acts on a sequence of revealed prices and accepts one of them irrevocably to maximize its profit. The problem has been studied both in probabilistic and in worst-case settings, notably through competitive analysis, and more recently in learning-augmented settings in which the trader has access to a prediction on the sequence. However, existing approaches either lack smoothness, or do not achieve optimal worst-case guarantees: they do not attain the best possible trade-off between the consistency and the robustness of the algorithm. We close this gap by presenting the first algorithm that simultaneously achieves both of these important objectives. Furthermore, we show how to leverage the obtained smoothness to provide an analysis of one-max search in stochastic learning-augmented settings which capture randomness in both the observed prices and the prediction.", "sections": [{"title": "Introduction", "content": "Recent and rapid advances in machine learning have provided the ability to learn complex patterns in data and time series. These advancements have given rise to a new computational paradigm, in which the algorithm designer has the capacity to incorporate a prediction oracle in the design, the theoretical analysis, and the empirical evaluation of an algorithm. The field of learning-augmented algorithms was born out of this emerging requirement to leverage ML techniques towards the development of more efficient algorithms.\nLearning-augmented algorithms have witnessed remarkable growth in recent years, starting with the seminal works [Lykouris and Vassilvtiskii, 2018] and [Purohit et al., 2018], particularly in online decision making. In this class of problems, the input is a sequence of items, which are revealed one by one, with the algorithm making an irrevocable decision on each. Here, the prediction oracle provides some inherently imperfect information on the input items, which the algorithm must be able to leverage in a judicious manner.\nOne of the most challenging aspects of learning-augmented (online) algorithms is their theoretical evaluation. Unlike the prediction-free setting, in which worst-case measures such as the competitive ratio [Borodin and El-Yaniv, 2005] evaluate algorithms on a single metric, the analysis of learning-augmented settings is multifaceted and must incorporate the effect of the prediction error to be meaningful. Typical desiderata [Lykouris and Vassilvtiskii, 2018] include: an efficient performance if the prediction is accurate (consistency); a performance that is not much worse than the competitive ratio if the predictions are arbitrarily inaccurate (robustness); and between these, a smooth decay of performance as the prediction error grows (smoothness). This marks a significant departure from the worst-case, and overly pessimistic competitive analysis, and allows for a much more nuanced and beyond worst-case performance evaluation."}, {"title": "Main contributions", "content": "Our main result answers the above question in the affirmative by giving a deterministic Pareto-optimal algorithm with smooth guarantees. Furthermore, we demonstrate how to leverage smoothness so as to extend this analysis to stochastic settings in which the input and prediction are random.\nIn previous works on learning-augmented one-max-search [Sun et al., 2021, Benomar and Perchet, 2025], the proposed algorithms select the first price that exceeds a threshold $\\Phi(y)$, which is a function of the prediction $y$ of the maximum price $p^*$ in the sequence. We revisit the problem by first characterizing the class $P_r$ of all consistency-robustness Pareto-optimal thresholds $\\Phi$. Next, we focus on a specific family of Pareto-optimal thresholds within $P_r$ which generalise the algorithm of Sun et al. [2021] but also exhibit smoothness guarantees. In particular, our analysis quantifies smoothness in this family, showing it to be inversely proportional to the maximal slope of the corresponding threshold. Guided by this insight, we find the threshold that maximizes smoothness within the class $P_r$.\nFurthermore, this quantification of smoothness allows to establish a near-matching lower bound. Specifically, we show that, for a multiplicative definition of the error, no Pareto-optimal algorithm can guarantee better smoothness than our algorithm, for a large range of robustness values. For the additive definition of the prediction error, which is commonly used, we show that our algorithm optimises smoothness for all robustness values, thus attaining the triple Pareto front of consistency, robustness and smoothness.\nThe combination of smoothness and Pareto-optimality of our family of thresholds has direct practical benefits in handling the real-world uncertainty of predictions. When predictions and prices are both tied to a random environment (e.g. a financial market), we show how to derive general form bounds in expectation as a function of the distributions of predictions and prices and, for the first time, of their coupling. We provide prediction-quality metrics which help us better capture the notion of the \"usefulness\" of a prediction in stochastic environments and give detailed bounds on concrete settings. We also provide a general framework of analysis based on optimal transport.\nWe validate our theoretical results through numerical experiments, in which we compare our algorithm to the state of the art, by testing it under both synthetic and real data."}, {"title": "Related work", "content": "Learning-augmented algorithms. Algorithms with predictions have been studied in a large variety of online problems, such as rent-and-buy problems [Gollapudi and Panigrahi, 2019], scheduling [Lattanzi et al., 2020], caching [Lykouris and Vassilvtiskii, 2018], matching [Antoniadis et al., 2020], packing [Im et al., 2021], covering [Bamas et al., 2020] and secretaries D\u00fctting et al. [2024]. This paradigm also has applications beyond online computation, and has been used to improve the runtime of algorithms for classical problems such as sorting [Bai and Coester, 2023] and graph problems [Azar et al., 2022], as well as for the design of data structures such as search trees [Lin et al., 2022], dictionaries [Zeynali et al., 2024], and priority queues [Benomar and Coester, 2024]. We emphasize that the above lists only some representative works, and we refer to the online repository of Lindermayr and Megow [2025].\nPareto-optimal algorithms. Several studies have focused on consistency-robustness trade-offs in learning-augmented algorithms, e.g. [Sun et al., 2021, Wei and Zhang, 2020, Lee et al., 2024, Angelopoulos, 2023, Bamas et al., 2020, Christianson et al., 2023, Almanza et al., 2021]. However, Pareto-optimality imposes constraints which may, in certain cases, compromise smoothness. The brittleness of Pareto-optimal algorithms for problems such as one-way trading was observed by Elenter et al. [2024], who proposed a user-defined approach to smoothness, and by Benomar and Perchet [2025] who relied on randomization. These approaches differ from ours, in that the profile-based framework of Elenter et al. [2024] does not always lead to an objective and measurable notion of consistency. Moreover, we show that randomization is not necessary to achieve Pareto optimality.\nOne-Max Search. El-Yaniv [1998] showed that the optimal competitive ratio of (deterministic) one-max-search is $1/\\sqrt{\\theta}$, under the assumption that each price in the sequence is in $[1,\\theta]$, where $\\theta$ is a known upper bound on $p^*$. This assumption is required in order to achieve a bounded competitive ratio and has remained in all subsequent works on learning-augmented algorithms for this problem, such as [Sun et al., 2021, Angelopoulos et al., 2022, Sun et al., 2024, Benomar and Perchet, 2025]. The randomized version of one-max-search is equivalent to the one-way trading problem, in which the trader can sell fractional amounts. The optimal competitive ratio, for this problem, is $O(1/log \\theta)$ [El-Yaniv, 1998]. Pareto-optimal algorithms for one-way trading were given by Sun et al. [2021], however Elenter et al. [2024] showed that any Pareto-optimal algorithm for this problem is brittle and thus cannot guarantee smoothness. One-max-search and one-way trading model fundamental settings of trading, and many variants and generalizations have been studied under the competitive ratio, see the survey [Mohr et al., 2014]. One must note that worst-case measures such as the competitive ratio aim to model settings in which no Bayesian assumptions are known to the algorithm designer. There is a very rich literature on optimal Bayesian search, see, e.g. [Rosenfield and Shapiro, 1981]."}, {"title": "Preliminaries", "content": "In the standard setting of the one-max-search problem, the input consists of a (unknown in advance) sequence of prices $p := (p_i)_{i=1}^n \\in [1,\\theta]^n$, where the maximal range $\\theta$ is known. At each step $i \\in [n]$, the algorithm must decide irrevocably whether to accept $p_i$, terminating with a payoff of $p_i$, or to forfeit $p_i$ and proceed to step $i + 1$. If no price has been accepted by step $n$, then the payoff defaults to 1.\nThe competitive ratio of an algorithm is defined as the worst-case ratio (over all sequences $p$) between the algorithm's payoff and $p^*$, the maximum price in the sequence. A natural approach to this problem is to use threshold-based algorithms, which select the first price that exceeds a predetermined threshold $\\Phi \\in [1,\\theta]$. We denote such an algorithm by $A_{\\Phi}$. In particular, the optimal deterministic competitive ratio is $1/\\sqrt{\\theta}$ and it is achieved by $A_{\\sqrt{\\theta}}$ El-Yaniv [1998]. Focusing on this class of algorithms is not restrictive, as in worst-case instances any deterministic algorithm performs equivalently to a threshold algorithm (see Appendix B).\nIn the learning-augmented setting, the decision-maker receives a prediction $y$ of the maximum price in the input $p$. The payoff of an algorithm ALG in this setting is denoted by ALG(p, y). In this context, threshold rules are defined as mappings $\\Phi: [1,\\theta] \\rightarrow [1,\\theta]$ that depend on the prediction. We use again $A_{\\Phi}$ to denote the corresponding algorithm. We denote by $c(ALG)$ and by $r(ALG)$ the consistency and the robustness of the"}, {"title": "Pareto-Optimal and Smooth Algorithms", "content": "In this section, we present our main result in regards to deterministic learning augmented algorithms, namely a Pareto-optimal and smooth family of algorithms for one-max-search. Our approach is outlined as follows. We begin by characterising the class of all thresholds $P_r$ which induce Pareto-optimal algorithms (Theorem 3.1). We then present a family of thresholds in $P_r$, parametrised by a value $\\rho \\in [0, 1]$ (Eq. (2)) that characterises their smoothness and we show that $\\rho = 1$ yields the best smoothness guarantees. We complement this result with Theorem 3.3, which shows that not only is our algorithm smooth, but any Pareto-optimal algorithm cannot improve on its smoothness.\nBefore we discuss our algorithms, we note that the randomized algorithm of Benomar and Perchet [2025] has a measurable and significant deviation from the Pareto front, even in comparison to deterministic algorithms; see Appendix D.3 for the expression of the deviation. Furthermore, the guarantees of their algorithm hold in expectation only, whereas the results we obtain do not rely on randomisation.\nWe now proceed with the technical statements. Theorem 3.1 below provides a characterization of all thresholds that yield Pareto-optimal levels of consistency and robustness.\nTheorem 3.1. For any fixed of robustness $r$, the set of all thresholds $\\Phi : [1,\\theta] \\rightarrow [1,\\theta]$ such that $A_{\\Phi}$ has robustness $r$ and consistency $1/r\\theta$ is\n$P_r:= \\left\\{ \\Phi : \\forall z \\in [1,\\theta] : r\\theta < \\Phi(z) \\leq \\frac{1}{r} \\\\ \\forall z \\in [r\\theta, \\theta]: \\frac{z}{2} \\leq \\Phi(z) \\leq z\\right\\}.$\nWe now turn to identifying smooth algorithms within the class $P_r$. Let us begin by giving the intuition behind our approach. Our starting observation is that the algorithm of Sun et al. [2021] uses the threshold\n$\\Phi(y) := \\begin{cases}r\\theta & \\text{ if } y \\in [1, r\\theta) \\\\\\ \\varphi_r(y) & \\text{ if } y \\in [r\\theta, 1/r) \\\\\\ 1/r & \\text{ if } y \\in [1/r, \\theta] \\end{cases}$\nwherein\n$\\varphi_r: z \\mapsto \\frac{r\\theta - 1}{1 - r} + \\frac{1 - r^2\\theta}{1 - r}z$\nis the line defined by $(r\\theta, r\\theta)$ and $(\\theta,1/r)$. The function $\\varphi$ is illustrated in Figure 2, in dashed orange."}, {"title": "Multiplicative error $\\mathcal{E}$", "content": "This first theorem establishes smoothness guarantees of the family of algorithms $\\{A_{\\varphi}^\\rho\\}_{r,\\rho}$ with respect to the multiplicative error measure $\\mathcal{E}$.\nTheorem 3.2. The family $\\{A_{\\varphi}^{\\rho}\\}_{r,\\rho}$ satisfies\n$\\frac{A_{\\varphi}^{\\rho}(p,y)}{p^*} \\geq \\max \\left\\{r, \\left(\\frac{1}{\\sqrt{r\\theta}}\\mathcal{E}(p^*, y) \\right)^{s_\\rho}\\right\\},$\n(4)\nwith $s_\\rho := \\max \\left(1,\\frac{\\ln \\theta}{\\ln(r\\theta)}-2\\right)$, for $\\rho \\in [0, 1]$."}, {"title": "Extension to the additive error $\\eta$", "content": "While the multiplicative error provides a more natural fit for the problem at hand, we also derive smoothness guarantees for $A$ using the additive error $\\eta(p^*, y) = |p^* - y|$. Moreover, we prove that the smoothness it achieves is optimal for $\\eta$, for all possible values of $r\\in [\\theta^{-1},\\theta^{-1/2}]$.\nTheorem 3.4. Let A be any algorithm with robustness $r$ and consistency $1/r\\theta$. Suppose that A satisfies for all $p\\in [1,\\theta]^n$ and $y \\in [1,\\theta]$ that\n$\\frac{A(p, y)}{p^*} > \\max \\left\\{r, \\left(\\frac{1}{\\sqrt{r\\theta}}\\frac{\\beta \\eta(p^*, y)}{p^*}\\right)\\right\\},$\n(6)\nfor some $\\beta \\geq 0$, then necessarily $\\beta > \\beta^*$, where\n$\\beta^* := \\frac{1-r^2\\theta}{r\\theta} \\max \\left(\\frac{1}{r\\theta - 1}, \\frac{\\theta}{1 - r^2\\theta}\\right).$\nMoreover, Algorithm A satisfies (6) with $\\beta = \\beta^*$, which shows its optimality."}, {"title": "Stochastic One-Max Search", "content": "One-max-search under competitive analysis is a worst-case abstraction of online selection which is highly skewed towards pessimistic scenarios. This is an approach rooted in theoretical computer science that has the benefit of worst-case guarantees, but does not capture the stochasticity of real markets, e.g. [Cont and Tankov, 2004, Donnelly, 2022]. In contrast, in mathematical (and practical) finance, probabilistic analyses such as risk management are preferred, e.g. Merton [1975]. While reconciling the two approaches remains a very challenging perspective, we aim to narrow the very large gap between the worst-case and stochastic regimes by leveraging a probabilistic approach. This necessitates algorithms that can be robust to the randomness of the market, and to this end, the established smoothness of our algorithm (Section 3) will play a pivotal role, as we will show. A probabilistic analysis can thus yield two main practical benefits: 1) estimate performance under price distributions obtained from financial modelling; 2) leverage the consistency-robustness trade-off to handle risk.\nIn the stochastic formulation of one-max-search, we now consider the prices $(P_i)_{i=1}^n$ to be random variables whose maximum is $P^* \\sim F^*$. Since market prices are random, the historical data used to generate a machine-learned prediction should also be random, hence we consider the prediction to be a random variable $Y\\sim G$. As before, we consider that $P_i$, for $i \\in [n]$, and $Y$ take value in $[1,\\theta]$. The trading window unfolds as in the classic one-max-search problem, except that the prices and predictions are now random.\nWe will first give, in Section 4.1, a general probabilistic competitive analysis of the one-max-search problem which shows that the bounds of Section 3 transfer naturally by weighting the bounds of Theorem 3.2 according to the coupling of $(P^*, Y)$. In order to better understand the intuition behind these results, in Section 4.2, we instantiate the analysis with three insightful models. Finally, in Section 4.3, we show how to isolate the interaction of G and $F^*$ using analytical tools from optimal transport theory."}, {"title": "Competitive analysis in the stochastic framework", "content": "In the stochastic setting, we will evaluate the performance of the algorithm using the ratio of expectations $E[ALG(P^*, Y)]/E[P^*]$, but our results and arguments transfer readily to $E[ALG(P^*,Y)/P^*]$.\nBecause any algorithm must operate on the realisation of $Y$, its performance becomes a random variable depending on the specific relationship of $P^*$ and $Y$. This is captured the coupling $\\pi^*$ of $(P^*, Y)$, yielding\n$E[ALG(P^*, Y)] := \\int ALG(p^*, y)d\\pi^* (p^*, y).$\n(7)\nIn consequence, we can identify $\\pi^*$ and the instance $(P^*, Y) \\sim \\pi^*$ without loss of generality, as all such instances are indistinguishable to a probabilistic analysis.\nTaking into account the coupling, the bound proved in Theorem 3.4 adapts to the stochastic setting to yield Lemma 4.1 below.\nLemma 4.1. The family $\\{A_{\\varphi}^{\\rho}\\}_{r,\\rho}$ satisfies\n$\\frac{E[A(P^*, Y)]}{E[P^*]} > \\max \\left\\{r, \\frac{1}{\\sqrt{r\\theta}} \\frac{E[P^*\\mathcal{E}(P^*,Y)]}{E[P^*]}\\right\\}.$\n(8)\nProof. Apply Jensen's inequality to Theorem 3.2.\nAs expected, (8) shows that the robustness of $\\{A_{\\varphi}^{\\rho}\\}$, carries over to the stochastic setting through the $\\max\\{r,\\}$ term."}, {"title": "Instantiations of Lemma 4.1", "content": "The coupling $\\pi^*$, and Eq. (8) more broadly, encode effects that influence the quality of a prediction from two different sources: the relationship of G and $F^*$ and the relationship between Y and $P^*$ themselves (e.g. correlation). In this section, we aim to isolate the effect of G and $F^*$.\nStochastic predictions, deterministic prices. This semi-deterministic model, in which $F^* = \\delta_{p^*}$ (which is to say $P^* = p^*$ almost surely), isolates the effect of G. From a practical standpoint, it can also be used to model predictions which are noisy measurements of deterministic, but unknown, quantities. Its theoretical interest comes from the fact that it simplifies Eq. (7) into an integral over $F^*$. This allows us to derive Corollary 4.2 from Lemma 4.1, in which the function $\\Lambda : [1, \\theta] \\rightarrow [0, 1]$ defined by\n$\\Lambda(p^*) = E \\left[E(\\mathcal{P^*},Y)|\\mathcal{P^*} = p^*\\right]$\n(9)\nfor $p^* \\in [1, \\theta]$, directly quantifies the quality of the prediction in terms of the performance, with respect to the true, realised, maximal price $p^*$. Indeed, $\\Lambda(p^*) < 1$ for all $p^*$, and the closer to one, the better the prediction. In particular, if the maximal price is deterministic, but the prediction is stochastic, this yields the following guarantees. For the sake of clarity of the results, we will no longer specify the term coming from the robustness, with the understanding that one can add a maximum with r to any bound on the performance of $\\{A_{\\varphi}^{\\rho}\\}_r$.\nCorollary 4.2. Let $F^* = \\delta_{p^*}$ for some $p^* \\in [1,\\theta]$, then the family $\\{A_{\\varphi}^{\\rho}\\}_r$ satisfies\n$\\frac{E[A(P^*, Y)]}{E[P^*]} \\geq \\frac{2\\Lambda(p^*)}{r\\theta}.$\n(10)\nViewing $\\Lambda$ as a map (taking G to a real-valued function on $[1,\\theta]$) reveals that it quantifies the usefulness of G as a prediction distribution at any $p^* \\in [1,\\theta]$.\nAs an integral functional of G, $\\Lambda$ may not admit a closed form. Nevertheless, it can be estimated to capture subtle stochastic phenomena as demonstrated by Example 4.3.\nExample 4.3. Let $F^* = \\delta_{p^*}$ for some $p^* \\in [1,\\theta]$ and G = Unif$([p^* - \\epsilon, p^* + \\epsilon])$. There is a constant C > 0, dependent only on (s,$\\theta$), such that\n$\\frac{E[A(P^*, Y)]}{E[P^*]} > \\frac{1}{\\sqrt{r\\theta}} \\left(1-\\frac{\\epsilon^2}{2p^{*2}}-C \\epsilon^2\\right),$\n(11)\nas soon as $0 < \\epsilon \\leq \\min{\\{\\theta - p^*, p^* - 1\\}}$.\nEq. (11) reveals that the performance of $\\{A_{\\varphi}^{\\rho}\\}$, decays from consistency at a rate linear in the uncertainty $\\epsilon$ determined by the smoothness s of the algorithm. This captures the scale of the effect of smoothness on a practical example. In Eq. (11) we characterised the rate up to the second order $(\\epsilon^2)$, but higher-order estimates can be obtained similarly.\nMoreover, this shows that all sufficiently regular distributions can be approximated in terms of $\\Lambda$ using mixtures over the model of Example 4.3, i.e. $G = \\sum_{k=1}^K w_kUnif(I_k)$ for $w_i > 0$, $\\sum_i w_i = 1$, and $(I_k)_k$ disjoint subintervals of $[1,\\theta]$ (see Corollary C.2). Numerical integration (e.g. Monte-Carlo) offers another alternative method to estimate $\\Lambda$.\nDeterministic predictions, stochastic prices. The performances of our family of algorithms can also be computed if the prices are stochastic, but the prediction is deterministic. This model swaps the randomness: now the prices are random so that $p^* \\sim F^*$ is generic and it is $Y \\sim \\delta_y$ which is deterministic.\nWhile this setting appears symmetrical to the previous one, this is not the case as the one-max-search problem itself is highly asymmetrical. Indeed, using a threshold means that predictions too high or too low do not have the same impact. By defining\n$\\Upsilon(y) : = \\frac{E[P^*E(\\mathcal{P^*},Y)|Y = y]}{E[P^*]}$\nfor $y \\in [1,\\theta]$,\nwe can establish a quality quantification which mirrors $\\Lambda$: this functional of G states how good any unique prediction y is at influencing algorithmic performance. This yields the following Corollary 4.4, an analogue of Corollary 4.2. Note that $\\Upsilon(y) < 1$ for all $y \\in [1,\\theta]$."}, {"title": "Dependent predictions and optimal transport", "content": "The previous models successfully isolated the effect of the distributions $F^*$ and $G$. Using tools from Optimal Transport (OT) theory, one can generalise this approach. For brevity, we refer simply to Villani [2009] for the technicalities and background of this field. The key observation is that the right-hand side of Eq. (7) is a transport functional of $\\pi^*$, which can be lower bounded uniformly over the set of couplings $\\Pi(F^*, G)$ of $F^*$ and $G$. This set is exactly the set of joint distributions for $(P^*, Y)$ when $P^* \\sim F^*$ and $Y \\sim G$. Minimising a transport functional over couplings is the classic OT problem [Villani, 2009], hence Theorem 4.6.\nTheorem 4.6. The family $\\{A_{\\varphi}^{\\rho}\\}_r$ satisfies\n$\\frac{E[A(P^*, Y)]}{E[P^*]} > \\frac{1}{\\sqrt{r\\theta}} \\frac{\\inf \\int p^*\\mathcal{E}(p^*,y)^* d\\pi(p^*,y)}{E[P^*]}$\n(14)\nwhere infimum is taken over couplings $\\pi \\in \\Pi(F^*,G)$; in particular, the numerator is as most $E[P^*]$.\nTheorem 4.6 highlights a novel connection between (stochastic) competitive analysis and optimal transport. Contrary to most literature in OT, in which the optimal configuration tries to minimise the distance points $(p^*, y)$ are moved, the infimum in (14) tries to push them far apart to induce the algorithm to make mistakes. Optimal transport tools have been used before in algorithms with predictions, notably in the distributional predictions setting in which the algorithm is given G itself [Angelopoulos et al., 2024, Dinitz et al., 2024]. This analysis, however, is fundamentally different: it uses Wasserstein distances (see Appendix D.4) in place of $\\eta$ in quantifying the error of the distributional prediction G of $F^*$. Our stochastic framework ties its error metric closely to the asymmetric nature of the problem through $p^*\\mathcal{E}(p^*, y)$, which is why our OT problem, i.e. Eq. (14), is not symmetric: exchanging the roles of $(G, F^*)$ cannot be expected to yield the same performance. The optimal transport problem in Eq. (14) generally has no closed form, but thanks to its (strong) dual form (see Appendix C.2), one can use problem-specific knowledge to derive lower bounds, as demonstrated by Proposition 4.7."}, {"title": "Numerical Experiments", "content": "To complement our theoretical analysis and evaluate the performance of our algorithm in practice, we present experimental results in this section. We defer additional experimental results to Appendix E."}, {"title": "Experiments on synthetic data", "content": "We fix $\\theta = 5$, $\\lambda = 0.5$, and $r = \\theta^{-(1-1/2)}$. We consider instances $\\{I_n(q)\\}_{q\\in[1,\\theta]}$, where $I_n(q)$ is the sequence starting at 1, and increasing by $\\frac{\\theta-1}{n-1}$ at each step until reaching $q$, after which the prices drop to 1. These instances model worst-case instances with maximum price $q$.\nWe fix an error level $\\mathcal{E}_{min}$ and, for each $p^* \\in [1,\\theta]$, we generate the prediction $y$ by sampling uniformly at random in the interval $[p^*\\mathcal{E}_{min}, p^*/\\mathcal{E}_{min}] = \\{z : \\mathcal{E}(p^*, z) \\geq \\mathcal{E}_{min}\\}$, then compute the ratio $A(I_n(p^*), y)/p^*$. For $\\mathcal{E}_{min} \\in (0,1]$, Figure 3 illustrates the worst-case ratio $\\inf_{p^*\\in[1,\\theta]} E_y[A(p^*, y)]/p^*$, where the expectation is estimated empirically using 500 independent trials.\nFigure 3 shows that for the different values of $\\rho$, the worst-case ratio is $1/r\\theta$ when the prediction is perfect, i.e. $\\mathcal{E}_{min} = 1$, and degrades to r when the prediction can be arbitrarily bad, which is consistent with Theorem 3.1. However, the ratio achieved for $\\rho = 0$ drops significantly even with a slight perturbation in the prediction, while the ratios with $\\rho \\in \\{0.5, 1\\}$ decrease much slower. This is again consistent with the smoothness of $A_{\\varphi}^{\\rho}$, as shown in Theorem 3.2."}, {"title": "Experiments on real data", "content": "To further validate our algorithm's practicality, we evaluate it on the experimental setting of [Sun et al., 2021]. Specifically, we use real Bitcoin data (USD) recorded every minute from the beginning of 2020 to the end of 2024. The dataset's prices range from L = 3,858 USD to U = 108, 946 USD, yielding $\\theta = U/L \\approx 28."}, {"title": "Conclusion", "content": "We provided an intuitive Pareto-optimal and smooth algorithm for a fundamental online decision problem, namely one-max-search. We believe our methodology can be applied to generalizations such as the k-search problem Lorenz et al. [2009], i.e. multi-unit one-max-search, recently studied in a learning-augmented setting [Lee et al., 2024]. More broadly, we believe our framework can help bring competitive analysis much closer to the analysis of real financial markets since it combines three essential aspects: worst-case analysis, adaptivity to stochastic settings, and smooth performance relative to the error. A broader research direction is thus to extend the study of competitive financial optimization (see, e.g., Chapter 14 in [Borodin and El-Yaniv, 2005]) to such realistic learning-augmented settings. This work also sheds light on connections between competitive analysis and optimal transport, suggesting the study of the geometry of OT problems induced by competitive analysis as a promising direction for both theories."}, {"title": "Organisation and Notation", "content": "The following appendices are divided in the following way: Appendix B contains the proofs of Section 3, while Appendix C contains proofs of Section 4. In both cases, they follow the order of the main text. Appendix E provides further experiments not included in Section 5. After these sections which are ordered according to the text, Appendix D is transversal and regroups results in which the error analysis is additive instead of multiplicative."}, {"title": "Notation", "content": "The space of probability measures over a set S is denoted $\\mathcal{P}(S)$. The set of couplings between G and $F^*$ is $\\Pi(G, F^*) := \\{\\pi\\in\\mathcal{P}([1,\\theta]^2) : \\pi(\\cdot, [1,\\theta]) = G, \\pi([1,\\theta], \\cdot) = F^*\\}$ For $x \\in \\mathbb{R}$, $\\delta_x$ denotes the Dirac Delta distribution (i.e. the distribution of a degenerate random variable X satisfying $\\mathbb{P}(X = x) = 1$)."}, {"title": "Proofs of Section 3", "content": "We present in this appendix the proofs of the results stated in Section 3. Let us introduce some notations and observations that we will use throughout the proofs. For all $n \\geq 1$, we denote by $(p_i)_{i=1}^n$, the sequence of prices defined by\n$\\forall i \\in [n]: p_i = 1 + \\frac{\\theta-1}{n-1}(i - 1),$\nand for all $q \\in [1,\\theta]$, we denote by $I_n (q)$ the sequence of prices that are equal to $p_i$ while the latter is smaller than $q$ then drops to 1. Formally, the $i$th price in this sequence is\n$I_n(q)_i = 1 + (p_i - 1)1_{p_i \\leq q} .$\n(15)\nOn the class of instances $\\{I_n (q)\\}_{q\\in[1,\\theta]}$, any deterministic learning-augmented algorithm for one-max-search is equivalent to a single-threshold algorithm $A_{\\Phi}$. Moreover, observe that the payoff of $A_{\\Phi}$ satisfies\n$A_{\\Phi} (I_n (q), y) = \\begin{cases}1 & \\text{ if } \\Phi(y) > q \\\\\\ \\Phi(y) + O(\\frac{1}{n}) & \\text{ otherwise} \\end{cases}.$\n(16)\nIndeed, if the threshold exceeds the maximum price $q$ in the sequence, then no price is selected and the algorithm is left with a payoff of 1. On the hand, if the threshold is at most $q$, then the selected price is $\\min\\{p_i \\mid p_i > \\Phi(y)\\}$. By definition of the prices $p_i$, this value is in $[\\Phi(y), \\Phi(y) + \\frac{1}{n}]$. In particular, for $n$ arbitrarily large, the payoff of an algorithm with threshold $\\Phi(y) \\leq q$ is arbitrarily close $\\Phi(y)$. This observation will be useful in our proofs."}, {"title": "The class of all Pareto-optimal thresholds", "content": "Theorem 3.1. For any fixed of robustness $r$", "Phi": [1, "theta"], "1,\\theta": "such that $A_{\\Phi"}, "has robustness $r$ and consistency $1/r\\theta$ is\n$P_r := \\left\\{ \\Phi : \\forall z \\in [1,\\theta"], "theta]": "frac{z"}, {"Phi": [1, "theta"]}]