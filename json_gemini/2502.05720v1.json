{"title": "Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search", "authors": ["Ziyad Benomar", "Lorenzo Croissant", "Vianney Perchet", "Spyros Angelopoulos"], "abstract": "One-max search is a classic problem in online decision-making, in which a trader acts on a sequence of revealed prices and accepts one of them irrevocably to maximize its profit. The problem has been studied both in probabilistic and in worst-case settings, notably through competitive analysis, and more recently in learning-augmented settings in which the trader has access to a prediction on the sequence. However, existing approaches either lack smoothness, or do not achieve optimal worst-case guarantees: they do not attain the best possible trade-off between the consistency and the robustness of the algorithm. We close this gap by presenting the first algorithm that simultaneously achieves both of these important objectives. Furthermore, we show how to leverage the obtained smoothness to provide an analysis of one-max search in stochastic learning-augmented settings which capture randomness in both the observed prices and the prediction.", "sections": [{"title": "1 Introduction", "content": "Recent and rapid advances in machine learning have provided the ability to learn complex patterns in data and time series. These advancements have given rise to a new computational paradigm, in which the algorithm designer has the capacity to incorporate a prediction oracle in the design, the theoretical analysis, and the empirical evaluation of an algorithm. The field of learning-augmented algorithms was born out of this emerging requirement to leverage ML techniques towards the development of more efficient algorithms.\nLearning-augmented algorithms have witnessed remarkable growth in recent years, starting with the seminal works [Lykouris and Vassilvtiskii, 2018] and [Purohit et al., 2018], particularly in online decision making. In this class of problems, the input is a sequence of items, which are revealed one by one, with the algorithm making an irrevocable decision on each. Here, the prediction oracle provides some inherently imperfect information on the input items, which the algorithm must be able to leverage in a judicious manner.\nOne of the most challenging aspects of learning-augmented (online) algorithms is their theoretical evaluation. Unlike the prediction-free setting, in which worst-case measures such as the competitive ratio [Borodin and El-Yaniv, 2005] evaluate algorithms on a single metric, the analysis of learning-augmented settings is multifaceted and must incorporate the effect of the prediction error to be meaningful. Typical desiderata [Lykouris and Vassilvtiskii, 2018] include: an efficient performance if the prediction is accurate (consistency); a performance that is not much worse than the competitive ratio if the predictions are arbitrarily inaccurate (robustness); and between these, a smooth decay of performance as the prediction error grows (smoothness). This marks a significant departure from the worst-case, and overly pessimistic competitive analysis, and allows for a much more nuanced and beyond worst-case performance evaluation."}, {"title": "1.1 Main contributions", "content": "Our main result answers the above question in the affirmative by giving a deterministic Pareto-optimal algorithm with smooth guarantees. Furthermore, we demonstrate how to leverage smoothness so as to extend this analysis to stochastic settings in which the input and prediction are random.\nIn previous works on learning-augmented one-max-search [Sun et al., 2021, Benomar and Perchet, 2025], the proposed algorithms select the first price that exceeds a threshold \u03a6(y), which is a function of the prediction y of the maximum price p* in the sequence. We revisit the problem by first characterizing the class Pr of all consistency-robustness Pareto-optimal thresholds \u03a6. Next, we focus on a specific family of Pareto-optimal thresholds within Pr which generalise the algorithm of Sun et al. [2021] but also exhibit smoothness guarantees. In particular, our analysis quantifies smoothness in this family, showing it to be inversely proportional to the maximal slope of the corresponding threshold. Guided by this insight, we find the threshold that maximizes smoothness within the class Pr.\nFurthermore, this quantification of smoothness allows to establish a near-matching lower bound. Specifically, we show that, for a multiplicative definition of the error, no Pareto-optimal algorithm can guarantee better smoothness than our algorithm, for a large range of robustness values. For the additive definition of the prediction error, which is commonly used, we show that our algorithm optimises smoothness for all robustness values, thus attaining the triple Pareto front of consistency, robustness and smoothness.\nThe combination of smoothness and Pareto-optimality of our family of thresholds has direct practical benefits in handling the real-world uncertainty of predictions. When predictions and prices are both tied to a random environment (e.g. a financial market), we show how to derive general form bounds in expectation as a function of the distributions of predictions and prices and, for the first time, of their coupling. We provide prediction-quality metrics which help us better capture the notion of the \"usefulness\" of a prediction in stochastic environments and give detailed bounds on concrete settings. We also provide a general framework of analysis based on optimal transport.\nWe validate our theoretical results through numerical experiments, in which we compare our algorithm to the state of the art, by testing it under both synthetic and real data."}, {"title": "1.2 Related work", "content": "Learning-augmented algorithms. Algorithms with predictions have been studied in a large variety of online problems, such as rent-and-buy problems [Gollapudi and Panigrahi, 2019], scheduling [Lattanzi et al., 2020], caching [Lykouris and Vassilvtiskii, 2018], matching [Antoniadis et al., 2020], packing [Im et al., 2021], covering [Bamas et al., 2020] and secretaries D\u00fctting et al. [2024]. This paradigm also has applications beyond online computation, and has been used to improve the runtime of algorithms for classical problems such as sorting [Bai and Coester, 2023] and graph problems [Azar et al., 2022], as well as for the design of data structures such as search trees [Lin et al., 2022], dictionaries [Zeynali et al., 2024], and priority queues [Benomar and Coester, 2024]. We emphasize that the above lists only some representative works, and we refer to the online repository of Lindermayr and Megow [2025].\nPareto-optimal algorithms. Several studies have focused on consistency-robustness trade-offs in learning-augmented algorithms, e.g. [Sun et al., 2021, Wei and Zhang, 2020, Lee et al., 2024, Angelopoulos, 2023, Bamas et al., 2020, Christianson et al., 2023, Almanza et al., 2021]. However, Pareto-optimality imposes constraints which may, in certain cases, compromise smoothness. The brittleness of Pareto-optimal algorithms for problems such as one-way trading was observed by Elenter et al. [2024], who proposed a user-defined approach to smoothness, and by Benomar and Perchet [2025] who relied on randomization. These approaches differ from ours, in that the profile-based framework of Elenter et al. [2024] does not always lead to an objective and measurable notion of consistency. Moreover, we show that randomization is not necessary to achieve Pareto optimality.\nOne-Max Search. El-Yaniv [1998] showed that the optimal competitive ratio of (deterministic) one-max-search is 1/\u221a\u03b8, under the assumption that each price in the sequence is in [1,0], where 0 is a known upper bound on p*. This assumption is required in order to achieve a bounded competitive ratio and has remained in all subsequent works on learning-augmented algorithms for this problem, such as [Sun et al., 2021, Angelopoulos et al., 2022, Sun et al., 2024, Benomar and Perchet, 2025]. The randomized version of one-max-search is equivalent to the one-way trading problem, in which the trader can sell fractional amounts. The optimal competitive ratio, for this problem, is O(1/log \u03b8) [El-Yaniv, 1998]. Pareto-optimal algorithms for one-way trading were given by Sun et al. [2021], however Elenter et al. [2024] showed that any Pareto-optimal algorithm for this problem is brittle and thus cannot guarantee smoothness. One-max-search and one-way trading model fundamental settings of trading, and many variants and generalizations have been studied under the competitive ratio, see the survey [Mohr et al., 2014]. One must note that worst-case measures such as the competitive ratio aim to model settings in which no Bayesian assumptions are known to the algorithm designer. There is a very rich literature on optimal Bayesian search, see, e.g. [Rosenfield and Shapiro, 1981]."}, {"title": "2 Preliminaries", "content": "In the standard setting of the one-max-search problem, the input consists of a (unknown in advance) sequence of prices p := (pi)_{i=1}^n \u2208 [1,\u03b8], where the maximal range \u03b8 is known. At each step i \u2208 [n], the algorithm must decide irrevocably whether to accept pi, terminating with a payoff of pi, or to forfeit pi and proceed to step i + 1. If no price has been accepted by step n, then the payoff defaults to 1.\nThe competitive ratio of an algorithm is defined as the worst-case ratio (over all sequences p) between the algorithm's payoff and p*, the maximum price in the sequence. A natural approach to this problem is to use threshold-based algorithms, which select the first price that exceeds a predetermined threshold \u03a6\u2208 [1,\u03b8]. We denote such an algorithm by A\u03a6. In particular, the optimal deterministic competitive ratio is 1/\u221a\u03b8 and it is achieved by A_{\u221a\u03b8} El-Yaniv [1998]. Focusing on this class of algorithms is not restrictive, as in worst-case instances any deterministic algorithm performs equivalently to a threshold algorithm (see Appendix B).\nIn the learning-augmented setting, the decision-maker receives a prediction y of the maximum price in the input p. The payoff of an algorithm ALG in this setting is denoted by ALG(p, y). In this context, threshold rules are defined as mappings \u03a6: [1,\u03b8] \u2192 [1,\u03b8] that depend on the prediction. We use again A\u03a6 to denote the corresponding algorithm. We denote by c(ALG) and by r(ALG) the consistency and the robustness of the"}, {"title": "3 Pareto-Optimal and Smooth Algorithms", "content": "In this section, we present our main result in regards to deterministic learning augmented algorithms, namely a Pareto-optimal and smooth family of algorithms for one-max-search. Our approach is outlined as follows. We begin by characterising the class of all thresholds Pr which induce Pareto-optimal algorithms (Theorem 3.1). We then present a family of thresholds in Pr, parametrised by a value \u03c1\u2208 [0, 1] (Eq. (2)) that characterises their smoothness and we show that \u03c1 = 1 yields the best smoothness guarantees. We complement this result with Theorem 3.3, which shows that not only is our algorithm smooth, but any Pareto-optimal algorithm cannot improve on its smoothness.\nBefore we discuss our algorithms, we note that the randomized algorithm of Benomar and Perchet [2025] has a measurable and significant deviation from the Pareto front, even in comparison to deterministic algorithms; see Appendix D.3 for the expression of the deviation. Furthermore, the guarantees of their algorithm hold in expectation only, whereas the results we obtain do not rely on randomisation.\nWe now proceed with the technical statements. Theorem 3.1 below provides a characterization of all thresholds that yield Pareto-optimal levels of consistency and robustness."}, {"title": "3.1 Multiplicative error E", "content": "This first theorem establishes smoothness guarantees of the family of algorithms {A_{\u03c1}} with respect to the multiplicative error measure E."}, {"title": "3.2 Extension to the additive error \u03b7", "content": "While the multiplicative error provides a more natural fit for the problem at hand, we also derive smoothness guarantees for A using the additive error \u03b7(p*, y) = |p* \u2013 y|. Moreover, we prove that the smoothness it achieves is optimal for \u03b7, for all possible values of r\u2208 [\u03b8^{-1},\u03b8^{-1/2}]."}, {"title": "4 Stochastic One-Max Search", "content": "One-max-search under competitive analysis is a worst-case abstraction of online selection which is highly skewed towards pessimistic scenarios. This is an approach rooted in theoretical computer science that has the benefit of worst-case guarantees, but does not capture the stochasticity of real markets, e.g. [Cont and Tankov, 2004, Donnelly, 2022]. In contrast, in mathematical (and practical) finance, probabilistic analyses such as risk management are preferred, e.g. Merton [1975]. While reconciling the two approaches remains a very challenging perspective, we aim to narrow the very large gap between the worst-case and stochastic regimes by leveraging a probabilistic approach. This necessitates algorithms that can be robust to the randomness of the market, and to this end, the established smoothness of our algorithm (Section 3) will play a pivotal role, as we will show. A probabilistic analysis can thus yield two main practical benefits: 1) estimate performance under price distributions obtained from financial modelling; 2) leverage the consistency-robustness trade-off to handle risk.\nIn the stochastic formulation of one-max-search, we now consider the prices (Pi)_{i=1}^n to be random variables whose maximum is P* ~ F*. Since market prices are random, the historical data used to generate a machine-learned prediction should also be random, hence we consider the prediction to be a random variable Y~ G. As before, we consider that Pi, for i \u2208 [n], and Y take value in [1,\u03b8]. The trading window unfolds as in the classic one-max-search problem, except that the prices and predictions are now random.\nWe will first give, in Section 4.1, a general probabilistic competitive analysis of the one-max-search problem which shows that the bounds of Section 3 transfer naturally by weighting the bounds of Theorem 3.2 according to the coupling of (P*, Y). In order to better understand the intuition behind these results, in Section 4.2, we instantiate the analysis with three insightful models. Finally, in Section 4.3, we show how to isolate the interaction of G and F* using analytical tools from optimal transport theory."}, {"title": "4.1 Competitive analysis in the stochastic framework", "content": "In the stochastic setting, we will evaluate the performance of the algorithm using the ratio of expectations E[ALG(P*, Y)]/E[P*], but our results and arguments transfer readily to E[ALG(P*,Y)/P*].\nBecause any algorithm must operate on the realisation of Y, its performance becomes a random variable depending on the specific relationship of P* and Y. This is captured the coupling \u03c0* of (P*, Y), yielding"}, {"title": "4.2 Instantiations of Lemma 4.1", "content": "The coupling \u03c0*, and Eq. (8) more broadly, encode effects that influence the quality of a prediction from two different sources: the relationship of G and F* and the relationship between Y and P* themselves (e.g. correlation). In this section, we aim to isolate the effect of G and F*.\nStochastic predictions, deterministic prices. This semi-deterministic model, in which F* = \u03b4_{p*} (which is to say P* = p* almost surely), isolates the effect of G. From a practical standpoint, it can also be used to model predictions which are noisy measurements of deterministic, but unknown, quantities. Its theoretical interest comes from the fact that it simplifies Eq. (7) into an integral over F*. This allows us to derive Corollary 4.2 from Lemma 4.1, in which the function A : [1, \u03b8] \u2192 [0, 1] defined by"}, {"title": "4.3 Dependent predictions and optimal transport", "content": "The previous models successfully isolated the effect of the distributions F* and G. Using tools from Optimal Transport (OT) theory, one can generalise this approach. For brevity, we refer simply to Villani [2009] for the technicalities and background of this field. The key observation is that the right-hand side of Eq. (7) is a transport functional of \u03c0*, which can be lower bounded uniformly over the set of couplings \u03a0(F*, G) of F* and G. This set is exactly the set of joint distributions for (P*, Y) when P* ~ F* and Y ~ G. Minimising a transport functional over couplings is the classic OT problem [Villani, 2009], hence Theorem 4.6."}, {"title": "5 Numerical Experiments", "content": "To complement our theoretical analysis and evaluate the performance of our algorithm in practice, we present experimental results in this section. We defer additional experimental results to Appendix E."}, {"title": "5.1 Experiments on synthetic data", "content": "We fix \u03b8 = 5, \u03bb = 0.5, and r = \u03b8^{-(1-1/2)}. We consider instances {In(q)}_{q\u2208[1,\u03b8]}, where In(q) is the sequence starting at 1, and increasing by 1 at each step until reaching q, after which the prices drop to 1. These instances model worst-case instances with maximum price q.\nWe fix an error level Emin and, for each p* \u2208 [1,\u03b8], we generate the prediction y by sampling uniformly at random in the interval [p*Emin, p*/Emin] = {z : E(p*, z) \u2265 Emin}, then compute the ratio A(In(p*), y)/p*. For Emin \u2208 (0, 1], Figure 3 illustrates the worst-case ratio inf_{p*\u2208[1,\u03b8]} Ey[A(p*, y)]/p*, where the expectation is estimated empirically using 500 independent trials.\nFigure 3 shows that for the different values of \u03c1, the worst-case ratio is 1/r\u03b8 when the prediction is perfect, i.e. Emin = 1, and degrades to r when the prediction can be arbitrarily bad, which is consistent with Theorem 3.1. However, the ratio achieved for \u03c1 = 0 drops significantly even with a slight perturbation in the prediction, while the ratios with \u03c1\u2208 {0.5, 1} decrease much slower. This is again consistent with the smoothness of A_{\u03c1}, as shown in Theorem 3.2."}, {"title": "5.2 Experiments on real data", "content": "To further validate our algorithm's practicality, we evaluate it on the experimental setting of [Sun et al., 2021]. Specifically, we use real Bitcoin data (USD) recorded every minute from the beginning of 2020 to the end of 2024. The dataset's prices range from L = 3, 858 USD to U = 108, 946 USD, yielding \u03b8 = U/L \u2248 28."}, {"title": "6 Conclusion", "content": "We provided an intuitive Pareto-optimal and smooth algorithm for a fundamental online decision problem, namely one-max-search. We believe our methodology can be applied to generalizations such as the k-search problem Lorenz et al. [2009], i.e. multi-unit one-max-search, recently studied in a learning-augmented setting [Lee et al., 2024]. More broadly, we believe our framework can help bring competitive analysis much closer to the analysis of real financial markets since it combines three essential aspects: worst-case analysis, adaptivity to stochastic settings, and smooth performance relative to the error. A broader research direction is thus to extend the study of competitive financial optimization (see, e.g., Chapter 14 in [Borodin and El-Yaniv, 2005]) to such realistic learning-augmented settings. This work also sheds light on connections between competitive analysis and optimal transport, suggesting the study of the geometry of OT problems induced by competitive analysis as a promising direction for both theories."}, {"title": "A Organisation and Notation", "content": "The following appendices are divided in the following way: Appendix B contains the proofs of Section 3, while Appendix C contains proofs of Section 4. In both cases, they follow the order of the main text. Appendix E provides further experiments not included in Section 5. After these sections which are ordered according to the text, Appendix D is transversal and regroups results in which the error analysis is additive instead of multiplicative."}, {"title": "A.2 Notation", "content": "The space of probability measures over a set S is denoted P(S). The set of couplings between G and F* is \u03a0(G, F*) := {\u03c0\u2208P([1,\u03b8]^2) : \u03c0(\u00b7, [1,\u03b8]) = G, \u03c0([1,\u03b8], \u00b7) = F*} For x \u2208 R, \u03b4x denotes the Dirac Delta distribution (i.e. the distribution of a degenerate random variable X satisfying P(X = x) = 1)."}, {"title": "B Proofs of Section 3", "content": "We present in this appendix the proofs of the results stated in Section 3. Let us introduce some notations and observations that we will use throughout the proofs. For all n \u2265 1, we denote by (p_i)_{i=1}^n, the sequence of prices defined by"}, {"title": "B.1 The class of all Pareto-optimal thresholds", "content": ""}, {"title": "B.2 Smoothness analysis of A", "content": ""}, {"title": "C Complements to Section 4", "content": "Recall in this section the notations P* ~ F* for the maximum price, and Y ~ G for the prediction. When considered, their coupling is denoted \u03c0*."}, {"title": "C.1 Complements on Section 4.2", "content": "Stochastic predictions, deterministic prices."}, {"title": "C.2 Complements to section 4.3", "content": "Since it holds regardless of the coupling \u03c0*, the bound Eq. (14) has two direct benefits. First, it provides a notion of robustness for uncertainty in the coupling which is relevant for risk-assessment in practical applications. Second, it isolates the influence of the marginal distributions on the prediction from the coupling of Y and P*. Consequently, we can return to (8) and isolate the contribution of the coupling, either through its transport sub-optimality"}, {"title": "D Additive Prediction Error", "content": ""}, {"title": "D.1 Smoothness guarantee on A", "content": "We begin by proving a lemma that will be useful for establishing the smoothness of A."}, {"title": "D.2 Lower bound on smoothness", "content": ""}, {"title": "D.3 Comparison with prior smooth algorithms", "content": "In [Benomar and Perchet, 2025], the authors introduce a randomized family {\\widetilde{A}^{\\rho}}_{\\rho\\in[0,1]} of algorithms. For a fixed \u03c1, the maximum robustness that their algorithm can achieve is at most \\theta^{-1} - \\theta^{-1/2}, hence remains bounded away from \\theta^{-1/2}. Given any robustness level r \\in [\\theta^{-1}, 1-\\theta(1-\\theta^{-1/2})], the corresponding consistency achieved by their algorithm is c = (1-\\rho/\\theta)^2 - (1-\\rho/\\theta). This algorithm ensures smoothness in expectation with respect to the error \\eta(p^*, y), i.e. that"}, {"title": "D.4 Probabilistic analysis", "content": ""}, {"title": "E Additional Numerical Experiments", "content": "We give here an additional experiment made with the same synthetic data described in Section 5. The first experiment shows the performance of the algorithm as a function of the multiplicative error. Instead of fixing Emin, we set a maximum error level \\Omega_{max} and sample y uniformly at random from the interval [p^* - \\Omega_{max}, p^* + \\Omega_{max}]. Figure 6 presents the results in this setting.\nSimilarly to the behaviour with respect to the multiplicative error, Figure 6 shows that \u03c1 0 yields a significant performance degradation for an arbitrarily small error, which confirms the brittleness of Sun et al. [2021]'s algorithm. In contrast, \u03c1 = 1 achieves the best smoothness, having a performance that gracefully degrades with the prediction error."}, {"title": "E.1 Experiments on real datasets", "content": "We use the same experimental setting and Bitcoin data as in Section 5, but we set different values of \u03bb\u2208 {0.2,0.8} instead of fixing \u03bb = 0.5 as in Figure 4. This yields different robustness levels, again expressed as r = \u03b8^{-(1-1/2)}. The results are shown in Figures 7 and 8 for x = 0.2 and 0.8, respectively.\nFor \u03bb = 0.2, Figure 7 shows that the performances of A_{\u03c1=0} and A_{\u03c1=1} are similar when A is small, i.e., when r is close to 1/\u03b8. This corresponds to a consistency of 1, meaning that the algorithm fully trusts the prediction. Since both algorithms rely heavily on prediction in this setting, their behavior is naturally similar.\nFor larger A, as seen in Figures 4 and 8, the performance gap between the two algorithms increases. However, for A close to 1, both consistency and robustness approach 1/r\u03b8. While the performance of A degrades significantly more slowly than that of A for \u03bb = 0.8 (Figure 8), the values of r and 1/r0 remain close. Figure 4, presented in Section 5, is an intermediate setting between these two extremes, where A yields a better smoothness than A, without having the values r and 1/r close to each other."}]}