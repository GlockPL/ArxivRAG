{"title": "Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference", "authors": ["Hengrui Cai", "Huaqing Jin", "Lexin Li"], "abstract": "Estimating treatment effects from observational data is of central interest across numerous application domains. Individual treatment effect offers the most granular measure of treatment effect on an individual level, and is the most useful to facilitate personalized care. However, its estimation and inference remain underdeveloped due to several challenges. In this article, we propose a novel conformal diffusion model-based approach that addresses those intricate challenges. We integrate the highly flexible diffusion modeling, the model-free statistical inference paradigm of conformal inference, along with propensity score and covariate local approximation that tackle distributional shifts. We unbiasedly estimate the distributions of potential outcomes for individual treatment effect, construct an informative confidence interval, and establish rigorous theoretical guarantees. We demonstrate the competitive performance of the proposed method over existing solutions through extensive numerical studies.", "sections": [{"title": "Introduction", "content": "Estimating treatment effects from observational data is of central interest across a wide range of applications, spanning public health (Cole et al., 2020; Goodman-Bacon and Marcus, 2020), political science (Abadie et al., 2010; Sabia et al., 2012), economics (Cavallo et al., 2013; Dube and Zipperer, 2015), and beyond. Over the past decades, the extensive literature has focused on estimating the average treatment effect (ATE), which provides a measure of the average effectiveness of a treatment for a population of subjects (see, for example, Rubin, 1978; Pearl, 2009). More recently, some literature has shifted the interest to estimating the conditional average treatment effect (CATE), which provides a more refined measure of the average treatment effect for subgroups of the population defined by specific characteristics or covariates (see, for example, Athey and Imbens, 2015; Shalit et al., 2017; Wager and Athey, 2018; K\u00fcnzel et al., 2019; Farrell et al., 2021). While CATE offers a more detailed and informative understanding of the treatment effect than ATE, both measures overlook the inherent variability in individual responses to treatment, under which the effect of treatment can vary significantly between individuals. Such subject variability can be crucial for decision-making. For instance, while a treatment may prove effective for 90% of patients aged 60 or older, its efficacy for a specific individual may still remain uncertain. As such, there has been growing interest in estimating the individual treatment effect (ITE), which quantifies the effect of the treatment on an individual level (Wager and Athey, 2018; Lei and Cand\u00e8s, 2021; Alaa et al., 2023). Such a measure seeks the most granular insight into treatment effects and is particularly useful in facilitating personalized care.\nDespite the clear importance and demand for a better understanding of ITE, its estimation and inference remain underdeveloped, beset by some major challenges. First, inherent in the definition of ITE is the constraint that each individual can only be treated once, and ITE is a random quantity rather than a population parameter such as ATE or CATE. These characteristics pose challenges when working with observational data. Current solutions for ITE often rely on relatively simple models, or some strong distributional assumptions on the noise term, failing to adequately capture the complex treatment effect. Second, the presence of confounding variables often results in the covariate distributional shift, manifesting as differing distributions of covariates between the calibration and testing datasets, as well as between the treated and control groups. This covariate shift can lead to model inaccuracies and poor generalization performance. Consequently, there is a pressing need to develop new approaches to both flexibly capture complex treatment relations and effectively handle distributional shifts while maintaining theoretical guarantees.\nIn this article, we propose a novel conformal diffusion model that addresses the intricate challenges of individual treatment effect estimation and inference in observational studies. Leveraging the flexibility and robustness of diffusion modeling (Sohl-Dickstein et al., 2015;"}, {"title": "Related works", "content": "Individual treatment effect (ITE) has gained considerable attention in numerous domains, such as political science (Imai and Strauss, 2011; Grimmer and Westwood, 2017), psychology (Bolger and Laurenceau, 2019; Winkelbeiner et al., 2019), sociology (Xie and Brand, 2012; Breen and Katz, 2015), economics (Florens et al., 2008; Djebbari and Smith, 2008), and education (Morgan, 2001; Brand and Xie, 2012). ITE focuses on the effect of treatment at an individual level, contrasts traditional methods that focus on the effects"}, {"title": "Problem setup", "content": "We adopt the potential outcome framework of Rubin (1974) throughout this article. Consider a sample of n units, where each unit i is associated with a d-dimensional covariate $X_i \\in \\mathcal{X} \\subset \\mathbb{R}^d$, a binary treatment $T_i \\in \\{0, 1\\}$, and the potential outcomes $[Y_i(0), Y_i(1)]$. We assume the potential outcomes and treatment assignment are independent and identically distributed, i.e., $(Y_i(0), Y_i(1), T_i, X_i) \\stackrel{iid}{\\sim} (Y (0), Y(1), T, X)$. The individual treatment effect (ITE) $\\tau_i$ is defined as the difference between the potential outcomes under treatment and control conditions:\n$\\tau_i = Y_i(1) - Y_i(0)$.\nIn practice, we only observe the factual outcome associated with the received treatment, i.e., $Y_i = Y_i(T_i) = T_iY_i(1) + (1 - T_i)Y_i(0)$. Thus, our observed dataset consists of the triplets $(Y_i, T_i, X_i)_{i=1}^n$. Since $\\tau_i = Y_i(1) - Y_i(0)$ if $T_i = 1$ or $\\tau_i = Y_i(1) - Y_i$ if $T_i = 0$, the ITE $\\tau_i$ is a random variable and cannot be estimated as a point value. Hence, our objective is to construct a confidence interval for the individual treatment effect $\\tau_i$ that is tight and has the desired coverage property.\nAs each individual can only be treated once, $\\tau_i$ is not estimable from the observational data, unless some additional conditions are introduced. We postulate that the potential outcomes follow a general generating procedure as, $Y(T) = f_T (X, \\mathcal{E}_T)$, where $f_T (X, \\mathcal{E}_T)$ represents an unknown function of the covariates X and noise $\\mathcal{E}_T$ under different treatments"}, {"title": "Conformal inference with sample splitting", "content": "We briefly review the classic conformal inference with sample splitting. Specifically, we divide the observed triplets $(Y_i, T_i, X_i)_{i=1}^n$ into three parts: $\\mathcal{D}_{train} = (X_i, T_i, Y_i)_{i \\in I_{train}}$ as the training data, $\\mathcal{D}_{cal} = (X_j, T_j, Y_j)_{j \\in I_{cal}}$ as the calibration data, and $\\mathcal{D}_{test} = (X_k, T_k, Y_k)_{k \\in I_{test}}$ as the holdout testing or target data. Let $I_{train}, I_{cal}, I_{test}$ denote the corresponding index set, respectively. Without loss of generality, we follow the general literature of ITE (see e.g., Lei and Cand\u00e8s, 2021) and let $Y (0) = 0$. Then the confidence interval for $t_i$ is equivalent to that for $Y_i(1)$. Define $\\pi(x) = P(T = 1 | X = x)$ as the propensity score function that describes the treatment assignment mechanism, and $\\mu(x) = E[Y | X = x, T = 1]$ as the expectation"}, {"title": "Conformal diffusion models for ITE", "content": "While conformal inference has been utilized to construct a confidence interval for the individual treatment effect $\\tau_i$, existing approaches rely on some relatively simple models such as quantile regression or pseudo-outcome regression (Lei and Cand\u00e8s, 2021; Alaa et al., 2023), which limits their ability to handle complex treatment effects in real-world applications. Moreover, they usually require the exchangeability between the calibration data and the testing data, and do not explicitly tackle distributional shifts (Wang et al., 2023). These observations have motivated us to develop a new and powerful approach, by integrating a highly flexible deep generative model, the conformal inference paradigm, along with the propensity score and covariate local approximation, for the estimation and inference of the individual treatment effect. Our proposed method comprises a few key components, which we elaborate on next."}, {"title": "Modeling potential outcome distribution via deep generative learning", "content": "We propose to use a deep generative model to learn the conditional distribution of the potential outcome given the covariates, i.e., $P(Y(T) | X)$, then compute the mean of the random samples from the learnt distribution. This departs from the existing solutions such as Lei and Cand\u00e8s (2021) that rely on a point estimate of the conditional mean function $\\mu$. By leveraging the expressive power of deep generative modeling, our method is expected to better capture the intricately complicated relations between the covariates and the potential outcome, to obtain a better uncertainty quantification, and subsequently to facilitate the ITE confidence interval construction.\nMore specifically, we first build two separate diffusion models using the training data $\\mathcal{D}_{train}$ to learn the conditional distributions $q_0(Y | X)$ and $q_1(Y | X)$ for $T = 0$ and $T = 1$, respectively. Denote the corresponding diffusion models as $\\hat{q}_0(Y | X)$ and $\\hat{q}_1(Y | X)$, respectively. Many versions of deep diffusion models can be utilized for this step, and we implement the denoising diffusion probabilistic model (DDPM) of Song et al. (2020), which incorporates a probabilistic framework and enables a principled uncertainty quantification.\nWe next compute the non-conformity scores based on the estimated diffusion models. Toward that end, we generalize the probabilistic conformal prediction and extend the conditional random sampling for supervised regression (Wang et al., 2023) to the setting of ITE and deep generative modeling. Taking $Y(1)$ as an example, for each $(X_j, T_j, Y_j) \\in \\mathcal{D}_{cal}$, we randomly sample M samples, $\\hat{Y}_{j1}, ..., \\hat{Y}_{jM} \\sim \\hat{q}_1(Y | X_j)$. We calculate the non-conformity score as,\n$V_j = \\min_{1<m<M} |Y_j - \\hat{Y}_{jm}|$.\nFollowing the convention of the current literature (see e.g., Lei and Cand\u00e8s, 2021), we illustrate the construction of the confidence interval for the treated units only, whereas the inference for the controlled units can be established in a similar way."}, {"title": "Adjusting covariate distributional shifts", "content": "Directly using the mean difference between two separate deep generative models to construct the confidence interval for ITE may suffer from covariate distributional shift. This is because, the joint distribution of the observed samples (X, Y) under the treated group (T = 1) in the calibration data is given by $P_{X|T=1} \\times P_{Y(1)|X}$, while for the testing or target data, we have the corresponding joint distribution as $Q_X \\times P_{Y(1)|X}$, where $Q_X$ is the covariate distribution in the target population. These two distributions share the same conditional distribution $P_{Y(1)|X}$ of the outcome, but otherwise differ in the distribution of the covariates. Moreover, in the control group, X follows $P_{X|T=0}$, and in the treatment group, X follows $P_{X|T=1}$, where we often have $P_{X|T=0} \\neq P_{X|T=1}$ in the observational studies. This leads to another covariate shift owing to treatment assignment.\nTo adjust for the first potential distributional shift between the calibration data and the test data, we utilize the local approximation idea (Tibshirani et al., 2019; Guan, 2023; Hore and Barber, 2023), which measures the covariate similarity between the calibration data and the target one, then reweighs the non-conformity scores based on such similarity. Toward that end, we utilize a certain kernel function to characterize the distribution of covariates in the calibration data and measure the similarity to a given testing or target data point $X_k$ of interest. We then reweigh the non-conformity scores in $\\mathcal{D}_{cal}$ by placing more weight on $\\{X_j\\}_{j \\in I_{cal}}$ that lie near $X_k$. We choose the localization kernel (Guan, 2023) given by a kernel function $H : \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathbb{R}_{>0}$, and we calculate the local weight as,\n$\\varpi_1(X_k) = \\frac{H (X,X_k)}{\\Sigma_{j\\in I_{cal} \\cup \\{k\\}} H (X_j, X_k)},$\nwhere $\\tilde{X}_k$ is sampled from the density function proportional to $H(X_k, .)$. We note that the weights in(1) utilize the local covariate information in the calibration data, and thus improving the sample efficiency and also addressing the covariate shift problem. In our implementation, we use the popular Gaussian kernel $H(X, X') \\propto exp(-\\|X - X'\\|^2_2/h^2)$, where h is the bandwidth parameter (Hore and Barber, 2023). We discuss the tuning of h later in Section 5."}, {"title": "Weighted conformal inference for ITE", "content": "Based on the empirical distribution of the non-conformity scores $V_i$ by the deep generative model obtained in Section 3.1, and the balancing weights $\\hat{\\rho}(X)$ obtained in Section 3.2, we obtain the conditional quantile of the non-conformity scores for the treated unit as,\n$\\hat{Q}_{1-\\alpha} (X_k) = Quantile_{1-\\alpha} (\\sum_{j \\in I_{cal}} \\hat{\\rho}(X_j) \\delta_{V_j} + \\hat{\\rho}(X_k) \\delta_{+ \\infty}),$\nwhere $\\delta_s$ is the point mass at s, and the weights $\\hat{\\rho}(X)$ are given in (3). For a given coverage level of 1 - a, we construct the predictive interval for $Y_k$ at the target point $X_k$ in $\\mathcal{D}_{test}$ as,\n$\\hat{C}(X_k) = \\cup_{m=1}^M [\\hat{Y}_{(k),m} - \\hat{Q}_{1-\\alpha}(X_k), \\hat{Y}_{(k),m} + \\hat{Q}_{1-\\alpha}(X_k)],$\nwhere $\\hat{Y}_{(k),1}, ..., \\hat{Y}_{(k), M}$ are M random samples from the estimated diffusion model $\\hat{q}_1 (Y|X_k)$ for the treated unit at $X_k$. We summarize the above procedure in Algorithm 1."}, {"title": "Theory", "content": "We next establish the coverage properties of the constructed confidence interval by our proposed method. Unlike the existing literature, our work incorporates the diffusion models and weighted conformal inference for ITE. As such, the theoretical analysis is different and highly non-trivial. Our main ideas are to leverage the techniques of conditional random sampling (Wang et al., 2023) to establish the theoretical behavior of the non-conformity scores obtained by diffusion modeling, and then utilize the weighted conformal inference framework (Tibshirani et al., 2019; Lei and Cand\u00e8s, 2021) to handle the discrepancy between the true weights and the estimated weights in our work.\nTo begin with, we first establish the theoretical form of the weights for distributional shift adjustment. Under Assumptions 1 and 2, the joint distribution of observed samples in the calibration data under the treated group is given by $P_{X|T=1} \\times P_{Y(1)|X}$. We are interested in the target distribution $Q_X \\times P_{Y(1)|X}$, where $Q_X$ is the covariate distribution in the testing data population. Following Tibshirani et al. (2019) and Lei and Cand\u00e8s (2021), we obtain"}, {"title": "Simulation studies", "content": "We design the simulation examples following the general settings as in Lei and Cand\u00e8s (2021) but with additional complications. All numerical studies are conducted on the Wynton High-Performance Compute, with 30 parallel CPU nodes each with 4GB memory.\nWe generate the covariate vector $X = (X_1, ..., X_d)$ with $X_k = \\Phi(X_k)$, where $\\Phi$ is the cumulative distribution function (cdf) of a standard Gaussian distribution and $X_i$'s are independent standard Gaussian variable. We generate the potential outcome Y(1) by\n$Y(1) = E\\{Y(1)|X\\} + \\sigma(X)\\epsilon,$\nwhere the noise $\\epsilon$ follows a standard Gaussian, Gamma, or a non-local moment (Jin et al., 2022) distributions. We give more details on the forms of $E\\{Y(1)|X\\}$ and the noise distributions. Specifically, for the low-dimensional case, we set\n$E\\{Y(1)|X\\} = f(X_1)f(X_2)$, where $f(x) = \\frac{2}{1 + exp \\{-12(x - 0.5)\\}}$"}, {"title": "Comparison with alternative solutions", "content": "We refer to our method as conformal diffusion models (CDM), and compare it with a number of alternative solutions and some variations of our proposed method, including:\n\u2022 CF: causal forest (Wager and Athey, 2018), a benchmark method to estimate CATE also compared in Lei et al. (2018).\n\u2022 CQR: conditional quantile regression (Lei et al., 2018) using a quantile regression.\n\u2022 CDM-nolocal: CDM without the local weights to address the shift between calibration and testing.\n\u2022 MLP: the multilayer perceptron method, which replaces the diffusion model with an MLP.\n\u2022 Naive: the naive generative method that uses the generated samples to directly obtain the interval estimate without conformal inference.\nIn our CDM implementation, we use the denoising diffusion probabilistic model as our generative model, and we adopt the neural network structure following Pearce (2023). For CDM-nolocal, MLP, and the naive method, we use the same neural network architecture as CDM for a fair comparison. We train the neural network using the AdamW optimizer (Loshchilov and Hutter, 2018), with a weight decay of 10\u22122, an initial learning rate of 10\u22122, and a learning rate decay factor of 0.7 every 500 epochs. We choose the number of training epochs based on validation. We set the batch size for training as 128. We set the total number of diffusion steps as 400, linearly interpolate the variance of Gaussian noise between [10\u22124,0.02]. We set the hyperparameters for CQR and CF at their default values in the corresponding R functions: cfcausal::conformalCf and grf::causal_forest.\nIn addition, there are two key tuning parameters in CDM, the number of random samples M drawn from the generative model, and the bandwidth h in the kernel function"}, {"title": "Sensitivity analysis", "content": "For our proposed CDM, there are two key tuning parameters, the number of random samples M drawn from the generative model, and the bandwidth h in the kernel function H(\u00b7, \u00b7). For the Gaussian kernel, we set $h = c\\sqrt{d}$ and tune c. We next carry out a sensitivity analysis of these tuning parameters. We run the experiments for both homoscedastic and"}, {"title": "Data application", "content": "We further illustrate our method with a dataset from the electronic Intensive Care Unites (eICU) collaborative research database (Pollard et al., 2018), which contains over 200,000 admissions to intensive care units across the United States between 2014 and 2015. We choose the cumulative balance of metabolism as the response Y, the reception of IV fluid resuscitation as the treatment T (1 if receiving the IV fluid resuscitation, and 0 if not), and"}, {"title": "Conclusion and future works", "content": "In this article, we propose a conformal diffusion model-based approach to construct informative and model-free confidence intervals for individual treatment effects. Our method is versatile and can be extended to various causal effect estimation problems beyond ITE, for instance, CATE, potential outcome distribution, and decision-making. However, there are some potential limitations. Computationally, the cost is relatively high due to diffusion modeling. Combined training on different treatments may be a promising solution. Theoretically, studying the conditional coverage property beyond the marginal coverage is challenging but important, which relies on the convergence rate of the predictive model involved. We will pursue these directions in our future research."}, {"title": "Technical proofs", "content": "We introduce some lemmas from the literature, which will facilitate the proof of the main theorem.\nLemma 1. (Equation (2) in Lemma 1 from Tibshirani et al. (2019)). Let $v_1,..., v_{n+1} \\in \\mathbb{R}$ and $(\\rho_1,...,\\rho_{n+1}) \\in \\mathbb{R}$ be non-negative real numbers summing to 1. Then, for any $\\beta \\in [0, 1]$,\n$v_{n+1} \\leq Quantile \\left( \\beta; \\sum_{i=1}^{n} \\rho_i \\delta_{v_i} \\right) \\Longleftrightarrow v_{n+1} \\leq Quantile \\left( \\beta; \\sum_{i=1}^{n} \\rho_i \\delta_{v_i} + \\rho_{n+1} \\delta_{+ \\infty} \\right)$.\nLemma 2. (Equation (10) from Berrett et al. (2020)). Let $d_{TV} (Q_{1X}, Q_{2X})$ denote the total-variation distance between two distributions $Q_{1X}$ and $Q_{2X}$. Then,\n$d_{TV} (Q_{1X} \\times P_{Y|X}, Q_{2X} \\times P_{Y|X}) = d_{TV} (Q_{1X}, Q_{2X})$.\nWe first recall the following notations. We divide the observed triplets $(Y_i, T_i, X_i)_{i=1}^n$ into three parts: $\\mathcal{D}_{train} = (X_i, T_i, Y_i)_{i \\in I_{train}}$ as the training data, $\\mathcal{D}_{cal} = (X_j, T_j, Y_j)_{j \\in I_{cal}}$ as the calibration data, and $\\mathcal{D}_{test} = (X_k, T_k, Y_k)_{k \\in I_{test}}$ as the holdout testing or target data. Let $I_{train}, I_{cal}, I_{test}$ denote the corresponding index set, respectively. Without loss of generality, we follow the general literature of ITE (see e.g., Lei and Cand\u00e8s, 2021) and let $Y (0) = 0$. Then the confidence interval for $t_i$ is equivalent to that for $Y_i(1)$. Define $\\pi(x) = P(T = 1 | X = x)$ as the propensity score function that describes the treatment assignment mechanism.\nWe propose to estimate each component of the weight $w(X) = w_1(X)w_2(X)$ as follows. We estimate $w_1(X)$ as\n$\\varpi_1(X_k) = \\frac{H (\\tilde{X}, X_k)}{\\Sigma_{j \\in I_{cal} \\cup \\{k\\}} H (X_j, \\tilde{X}_k)}$"}]}