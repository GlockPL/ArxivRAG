{"title": "Urban Visual Appeal According to ChatGPT: Contrasting AI and Human Insights", "authors": ["Milad Malekzadeh", "Elias Willberg", "Jussi Torkko", "Tuuli Toivonen"], "abstract": "The visual appeal of urban environments significantly impacts residents' satisfaction with their living spaces and their overall mood, which in turn, affects their health and well-being. Given the resource-intensive nature of gathering evaluations on urban visual appeal through surveys or inquiries from residents, there is a constant quest for automated solutions to streamline this process and support spatial planning. In this study, we applied an off-the-shelf AI model to automate the analysis of urban visual appeal, using over 1,800 Google Street View images of Helsinki, Finland. By incorporating the GPT-4 model with specified criteria, we assessed these images through three criteria-based prompts. Simultaneously, 24 participants, categorised into residents and non-residents, were asked to rate the images. Our results demonstrated a strong alignment between GPT-4 and participant ratings, although geographic disparities were noted. Specifically, GPT-4 showed a preference for suburban areas with significant greenery, contrasting with participants who found these areas less appealing. Conversely, in the city centre and densely populated urban regions of Helsinki, GPT-4 assigned lower visual appeal scores than participant ratings. While there was general agreement between AI and human assessments across various locations, GPT-4 struggled to incorporate contextual nuances into its ratings, unlike participants, who considered both context and features of the urban environment. The study suggests that leveraging AI models like GPT-4 allows spatial planners to gather insights into the visual appeal of different areas efficiently, aiding decisions that enhance residents' and travellers' satisfaction and mental health. However, caution is necessary, particularly when interpreting results for suburban and densely-populated areas. While we used an off-the-shelf model, it is crucial to develop models specifically trained to understand the local context and provide insights into human perceptions of urban elements. Although AI models provide valuable insights, human perspectives are essential for a comprehensive understanding of urban visual appeal. This will ensure that planning and design decisions promote healthy living environments effectively.", "sections": [{"title": "1. Introduction", "content": "Urban environments have a profound role on our satisfaction, travel behaviour, and our health and well-being (1,2). Growing evidence shows how well-designed, pleasant urban environments that attract people to walk and cycle, can lead to a range of positive impacts, from higher physical activity and improved mood, to increased active travel, and economic vibrancy (2\u20135). Yet, it is also increasingly understood that unpleasant environments can inflict various negative emotions, including fear and anxiety, and be prone to adverse consequences such as crime, car dependence, and avoidance (1,6,7). Obviously, it is highly relevant for local planners and decision-makers to understand and locate such features when developing cities.\nWhile the key components of attractive urban environments were identified long ago (8,9), and have been recognised by the research community (3,10\u201312), the operationalisation of these principles into meaningful and robust spatial indicators is highly dependent on the availability of data. In this respect, recent years have witnessed a dramatic increase in the availability of micro-scale data collected from the street level, representing the immediate urban environment. The emergence of street view imagery (SVI) in many cities has provided a rich source of data with which to assess the visual quality of streets (13). Together with rapidly developed computer vision techniques for object detection, SVIs have allowed researchers to capture detailed street features automatically, thereby overcoming some of the limitations of less detailed neighbourhood-level metrics or field-based audit data collection (14). A burgeoning literature has applied SVIs to a variety of urban use cases, including the assessment of walkability (15,16), pedestrian and cycling"}, {"title": "", "content": "safety (17,18), pedestrian and cycling volume and behaviour (19,20), street greenery (21,22),\nmicroclimate (23,24), and physical disorder of streets (25,26).\nFrom the planning perspective, the process of turning the visual information contained by SVIs into environmental indicators applicable to planning practice nevertheless remains a challenge. Existing literature on SVIs and environmental quality has largely focused on searching for the most important correlation between visual street features and travel behaviour, improving the accuracy of existing street quality indicators, and mapping the spatial distribution of distinct environmental features (e.g., visual complexity or street enclosure) in the study cities (13,27). Despite the obvious potential of SVIs, translating their potential into planning practice is a non-trivial issue. Common hardships include distilling multiple attributes into conceptually and methodologically robust but simple indicators, ensuring spatial coverage, high requirements for technical and methodological know-how, and the need for computational capacity. It is therefore necessary to continue the search for ways which will lower entry barriers and streamline the process of harnessing SVIs when evaluating urban environmental quality in planning.\nEnsuring a high likelihood of finding these ways lies in the recent breakthroughs in artificial intelligence (AI). The emergence of Multimodal Large Language Models (MLLMs) like GPT-4 (Open AI) and Kosmos-2.5 (Microsoft) with capabilities to integrate the textual interaction capability with image analysis, holds great promise. The capacity of MLLMs to produce human-like text based on large amounts of data, opens new opportunities for applications requiring comprehensive analysis of both visual and textual information, such as the visual assessment of an urban area. Above all, the use of current MLLMs based on simple textual inputs can lower the barriers for using street view data in planning processes and can produce operable environmental quality indicators. However, it is still little known how well the results produced by MLLMs on"}, {"title": "", "content": "the visual appeal reflect people's experience, which is a central requirement for their application. Overall, the potential of MLLMs in analysing the visual appeal of urban environments, remains largely underexplored.\nFor this study, we explored the potential of MLLMs to produce assessments of the visual appeal of urban environments. We applied an AI model to automate the analysis of over 1,800 Google Street View (GSV) images collected in Helsinki, Finland. By incorporating the GPT-4 model with urban environmental quality criteria from the literature, we assessed these images through the set of three input prompts, from simpler, to more complex. To compare the ratings of environmental quality that we obtained from the AI model, we asked 24 participants, categorised into residents and non-residents, to rate the visual appeal of the urban environments in the images. By comparing the ratings of the Al models and our participants statistically and spatially, we revealed the potential, as well as the limitations, of MLLMs, when applied to environmental quality assessment. Finally, we discuss the implications and limitations of our approach in planning."}, {"title": "2. AI in Sentiment and Multimodal Analysis", "content": "The advent of Large Language Models (LLMs) such as GPT-3 (28) and BERT (29) has not only revolutionised AI with sophisticated text generation and understanding, but also democratised interactions with AI technologies (30). These models enable users to execute commands, optimise and fine-tune Al responses, and engage in nuanced interactions without requiring deep AI expertise. This suite of LLMs illustrates the leap towards intuitive, accessible technology, transforming user interactions across various domains. This capability is particularly crucial for our study, allowing for the customisation of analysis criteria. Nonetheless, the application of LLMs is limited, because it lacks the ability to process visual media, essential for assessing urban visual appeal."}, {"title": "", "content": "The emergence of MLLMs like GPT-4 (31) and Kosmos-2.5 (32,33), which integrate the textual interaction capability of LLMs with image analysis, presents a novel solution. Early studies in the field were dedicated to understanding and generating text based on multimodal inputs, focusing on how models interpret the relationship between visual elements and text. This research area benefited greatly from projects like BLIP-2 (Bootstrapping Language-Image Pre-training-2) (34), CLIP (Contrastive Language-Image Pretraining) (35), and LLaVA (Large Language-and-Vision Assistant) (36). As the field evolved, the scope of MLLMs broadened to include generating outputs specific to various modalities. These models emphasise the use of modality encoders, LLM backbones, and modality generators to process and generate multimodal content efficiently (37). Notable in this development is the flexibility in input representation, allowing for seamless integration of several data types into the LLM framework.\nThis advancement provides new options for applications requiring comprehensive analysis of both visual and textual information, such as an urban area's visual assessment, that can potentially benefit spatial planning. Some early studies have explored this field, including the study by Jongwiriyanurak et al. (38), which used LLaVA by prompting six questions to gather information on various factors considered critical in assessing motorcycle crash risks. Similarly, Liu et al. (39) employed CLIP to assess perceived walkability by analysing both tangible and subjective factors such as safety and attractiveness. Despite the progress made, the deployment of multimodal LLMs for a detailed analysis of urban visual appeal is still largely underexplored."}, {"title": "3. Determinants of Urban Visual Appeal", "content": "During recent decades, the determinants of urban visual appeal have become well established by an interdisciplinary research community. Within this literature, one of the key works is the book by Ewing et al., Measuring Urban Design: Metrics for livable places (40), which details a"}, {"title": "", "content": "framework of metrics for measuring the quality of urban environments, as well as the definitions and measurement protocols to operationalise these metrics. This framework is grounded in the multidisciplinary understanding of how physical spaces and urban design qualities interact to influence individual reactions and behaviours, particularly walking behaviour, which is often a proxy for urban visual appeal.\nThe framework divides the relevant metrics into three main groups. The first group, enduring physical features, comprises elements such as sidewalk features for pedestrian activity, street design for traffic and activity, tree canopy and greenery, physical indicators of human activity, and permanent lighting. The second group encompasses urban design qualities, including imageability, legibility, human scale, transparency, linkage, complexity, and coherence. Thirdly, the last group extends the evaluation criteria to include individual reactions, reflecting personal and emotional responses to the urban environment.\nIn the literature, physical features like sidewalk width, street width, and tree canopy are directly observable and are believed to influence the more subjective urban design qualities (41\u201343). These features are often used in active transportation audit instruments, to measure the quality of the walking or bicycling environment (42\u201347).\nOn the other hand, urban design qualities, while influenced by these physical features, contribute to a cumulative effect on the experience of walking down a street that is greater than the sum of the parts. For instance, imageability, a concept popularised by Lynch (48), refers to the quality in a physical object which gives it a high probability of evoking a strong image in any given observer. It is what makes a space memorable and distinct. Similarly, qualities such as legibility, which is the ease with which a place can be recognised and organised into a coherent pattern, play a crucial role in how an individual perceives and engages with an urban space (48,49). The concept of"}, {"title": "", "content": "transparency, derived from architecture and urban planning, refers to the literal and figurative visibility of a place. It affects how individuals perceive the openness and accessibility of a space, which is crucial for the sense of appealing (50\u201352). Complexity and coherence, on the other hand, reflect the visual richness and orderly arrangement of urban elements, which have been empirically linked to people's preference for and engagement with urban spaces (53). Moreover, enclosure, as described by Alexander (54) and Jacobs (52), refers to the creation of well-defined outdoor spaces with clear shapes and boundaries, akin to rooms, which evoke feelings of safety, definition, and memorability. Lastly, human scale and linkage refer to how the proportions of space and elements correspond with human dimensions, ensuring comfort (55), connectivity of different spaces (56), and facilitating movement and interaction (57).\nMoreover, the inclusion of subjective reactions in the evaluation criteria acknowledges the multifaceted nature of urban design qualities. While physical features can be measured objectively, their influence on individual perceptions and behaviours is subjective, and can vary widely. As such, an evaluation should consider individual reactions, such as a sense of safety, comfort, and interest, which are personal yet pivotal components of an environment's pleasantness. As Talen stated, the field of urban analysis has yet to reach consensus on the most appropriate measures to use (58). The literature reveals a diversity of approaches, with various studies opting for singular measures, others for combinations, but without a universally accepted standard."}, {"title": "4. Methodology", "content": "In this study, we used street view imagery as the input for MLLMs from which to evaluate urban visual appeal, which was then compared against human participant ratings. First, to find the evaluation criteria to optimise the AI model for our study, we defined a set of criteria and determinants of urban visual appeal. Our criteria were based on Ewing et al. (40) (see section 4)"}, {"title": "", "content": "to align with established theories and empirical evidence from the urban design literature. These criteria served as prompts in conjunction with visual data when engaging with the AI model. Initially, imagery data were collected and subjected to preliminary analysis with a subsample of the data to determine the most appropriate AI model. Following the preliminary analysis and model selection, participants were asked to rate the images, allowing for a comparative analysis between AI-generated and human assessments. Detailed procedural steps are provided in the following."}, {"title": "4.1. Study Area", "content": "Our study took place in Helsinki, the capital of Finland (Figure 1-a). Helsinki is a medium-sized city with a population of about 650,000 and a total land area of 214 km\u00b2 (59) (Figure 1-b). The city comprises various types of urban fabric, including a densely built urban core at the tip of the peninsula with the highest population density in the county of around 5550 people per km\u00b2 and the centre of economic, cultural, and social activity (Figure 1-c). Further away from the city centre are residential areas in the western, northern, and eastern parts of the city. The city, apart from its centre, is characterised by its greenery and multiple green spaces, which comprise approximately one-third of the total land area of Helsinki."}, {"title": "4.2. Acquisition of Urban Imagery", "content": "We acquired panoramic GSV images from Helsinki through Google Maps API with a key authorisation. The images had been collected between 2009 and 2017 over the study area (Figure 1-b). In the acquisition process, images were sampled at 20 metres intervals along the street network. Each GSV image included a time stamp referring to the month and year when the image was taken, as well as the coordinate location of the image. The size of the images was 640 \u00d7 640 with a field of view of 60\u00b0 and pitch 0\u00b0. The panoramic 360\u00b0 image that we used in the models and in the human evaluation, was composed of six directional images (0\u00b0, 60\u00b0, 120\u00b0, 180\u00b0, 240\u00b0, 300\u00b0) in each compass location, with 0\u00b0 directed towards the north."}, {"title": "4.3. AI Evaluation of Urban Imagery", "content": "In our preliminary analysis, we evaluated three MLLMs, including CLIP, BLIP, and GPT-4, to determine the most suitable model for our study. Results indicated that GPT-4 outperformed the others, yielding ratings closely aligned with those from a small group of participants (refer to Appendix A). Using OpenAI's API allowed us to automate the submission of prompts and to retrieve results for the extensive number of images, a necessity given the volume of data.\nDrawing on the determinants of visual appeal outlined in section 4, we developed three distinct prompt types for GPT-4, ranging from simple to complex, to assess the influence of these criteria on the visual appeal scores. These prompts were iteratively refined during the preliminary analysis, to enhance the alignment between AI-generated assessments and participant ratings, thereby reducing discrepancies.\nFor the first prompt, we simply asked GPT-4 to rate the overall visual appeal on a scale from 1 (completely unappealing) to 7 (completely appealing), without specifying any criteria (Table 1). The second prompt incorporated a set of physical features. In the third prompt, we integrated urban design quality criteria, as well as subjective reactions, into the previous set of criteria. Each criterion in the second and third prompts included a brief definition. For all prompts, we instructed"}, {"title": "", "content": "GPT-4 to disregard temporary elements such as weather or passing vehicles, to ensure consistency in responses. We also developed two distinct prompts for querying ChatGPT, tailored to reflect either a local resident's or a non-resident's perspective, which could be typical or atypical in terms of local aesthetic and environmental viewpoints. Hereafter, we have referred to these prompts as Model-1, Model-2, and Model-3, respectively, with the suffixes 'LR' for local residents and 'NR' for non-residents. Each prompt was accompanied by a panoramic image of the area. The exact wording of these prompts is available in Appendix B."}, {"title": "4.4. Human Evaluation of Urban Imagery", "content": "To assess the ratings generated by GPT-4, we primarily recruited university students as participants, and personnel affiliated with the institutions of the authors. Recognising that familiarity with an area and associated memories can influence perceptions, we included both residents and non-residents in our participant pool, to evaluate these effects and to compare their ratings with those from GPT-4. The study involved 13 participants who were residents of Helsinki at the time of the experiment, and 11 non-residents. Participants received instructions via a concise guidance document. We intentionally did not highlight specific criteria, unlike the prompts used with GPT-4, allowing participants to rate the visual appeal based on their intuitive perception, as if they were physically present in the area. This approach encouraged a more subjective assessment rather than a detailed objective analysis of features. However, they were instructed to disregard any temporary features. For the exact wording of the instructions, please refer to Appendix C.\nGiven the substantial number of images involved and the time-intensive nature of the task, we requested that participants rate at least 500 images each, although they were permitted to rate more if they chose to. To ensure a balanced distribution of ratings and prevent any single image from being rated excessively or not at all, we strategically divided the batch of images. On average, each participant provided 1,014 ratings, accumulating a total of 24,349 ratings in total. Each image was rated at least 9 times. On average, each image received 11 ratings."}, {"title": "4.5. Adjusting Ratings for Comparative Analysis", "content": "Recognising the subjective nature of visual appeal, we noted significant variance in the average ratings provided by participants; the lowest individual average was 3.12, while the highest was 5.55. Such disparities indicated that comparing raw rating values could be problematic and not directly comparable. To address this, we adjusted ratings by subtracting the individual's average rating from each raw rating they provided. This approach highlighted the relative visual appeal of areas, showing whether they were perceived as better or worse than an individual's average ratings. To maintain consistency, we also adjusted the GPT-4 ratings by subtracting the mean rating of each prompt, thus adjusting the data across different evaluators and prompts.\nTo adjust for potential bias due of luminosity, we investigated whether luminosity influenced the ratings, based on the assumption that brighter and sunnier images might receive higher ratings. If this correlation had been significant, it would have been necessary to adjust for luminosity in our analysis. However, our findings showed no significant correlation between luminosity and the visual appeal ratings (Appendix D). Consequently, we did not adjust the images based on luminosity."}, {"title": "4.6. Statistical Analysis", "content": "We observed that the ratings from the first prompt resulted in a non-normal distribution (refer to Appendix E). Consequently, when comparing the distribution of ratings from the first prompt with those of residents and non-residents, we employed the Wilcoxon test. In contrast, since the distributions from prompts two and three were normally distributed, we applied T-tests for comparisons. Additionally, we calculated the Pearson correlation coefficient to assess the degree of correlation between the ratings from GPT-4 and those provided by residents or non-residents."}, {"title": "", "content": "To evaluate the ratings spatially, we first assessed the overall spatial autocorrelation using Moran's I. We then calculated the differences between the ratings from GPT-4 and participants to further analyse these discrepancies using Moran's I. Subsequently, we identified clusters of these differences using local Moran's I. To pinpoint the hot spots (areas where the differences between GPT-4 and participant ratings are positive and significant) and cold spots (areas where these differences are negative and significant), we employed the Getis-Ord G* statistic."}, {"title": "5. Results", "content": "5.1. Descriptive findings\nIn the comparison between the local resident and non-resident groups of participants, we observed a similar pattern in the ratings (Table 2). Local residents showed a slightly lower standard deviation, but a broader range of values compared to non-residents. For the GPT-4 Model-1 (LR and NR), the standard deviation was higher, and the range of values broader than those observed in participant ratings, with both models displaying a tendency towards lower median values. This suggests that despite a general trend towards lower ratings, the values above the average were considerably higher for GPT-4 compared to the participants. When examining GPT-4 Models 2 and 3 (LR and NR), the standard deviations aligned closely with those of participants, but the range of values was broader, especially on the lower, negative values. Nevertheless, the values for the second and third quartiles remained similar across all models and participant ratings."}, {"title": "", "content": "In analysing the distribution of ratings between GPT-4 models and participants using Wilcoxon and T-tests, we found no significant differences, as indicated by the p-values (Table 3). This similarity in distributions suggests that the ratings from the GPT-4 models align closely with those provided by participants, with no statistically significant variations between the groups."}, {"title": "5.2. Spatial Statistics", "content": "To explore spatial autocorrelation within our dataset, we first analysed the global Moran's I for each set of ratings (Table 4). The results indicated a positive spatial autocorrelation across all observations. Ratings from non-resident participants showed the highest level of spatial autocorrelation. This suggests that participants have more consistent and generalised perceptions of an urban area when it is unfamiliar to them. In contrast, residents, who have detailed and varied understanding based on their personal experiences and familiarity with the area, are likely to use more diverse criteria in their ratings, leading to lower spatial autocorrelation."}, {"title": "", "content": "Comparing the spatial autocorrelation of ratings derived from different GPT-4 models, we observe that the more complex the model (i.e., the more criteria in the prompt), the higher the spatial autocorrelation (Table 4). This result can be interpreted in two contradictory ways. First, simple models may apply fewer criteria and lack the sophistication to analyse complex urban features"}, {"title": "", "content": "consistently, leading to more varied ratings, while more complex models apply more criteria uniformly, resulting in more homogenised evaluations and increased spatial autocorrelation. Alternatively, the additional criteria in more complex models might neutralise each other, leading to moderate and more similar ratings. This is supported by the descriptive analysis in Table 2, in which the range of the middle 50 percent of the data in Model-1 for both local residents and non-residents was higher than in Model-2 and Model-3. However, this analysis alone is insufficient to determine which interpretation is correct. To evaluate these views further, we also examined the spatial autocorrelation of differences between pairs of ratings (model-derived versus participant-derived) using Moran's I to evaluate the compatibility of these ratings with those of participants.\nThis analysis revealed that local residents' ratings exhibit slightly lower spatial autocorrelation compared to non-residents' ratings, indicating greater spatial variation in differences between local residents' ratings and those from GPT-4 models (Table 5). Comparing the GPT-4 models, we could observe a significant increase in spatial autocorrelation from Model-1 to Model-2 and Model-3, with the latter two models showing almost three times more spatial autocorrelation. This increase could be attributed to the specific criteria in Model-2 and Model-3, causing these models to treat areas that share partly similar characteristics uniformly.\nTo evaluate this further, we used Getis-Ord G* (Figure 3) and Local Moran's I (Appendix F) analyses. The results showed a clear pattern of more hot spots in suburban and rural areas in which GPT-4 model ratings were higher than participant ratings, while the reverse pattern was observed in densely populated urban areas. Additionally, we found that simpler models and non-residents had fewer hot/cold spots, compared to more complex models and local residents, indicating lower local spatial autocorrelation in differences between simpler models and non-residents' ratings."}, {"title": "6. Discussion", "content": "Attractive urban environments are associated with a range of positive impacts, including citizen satisfaction, well-being, and sustainable travel behaviours (1,2). Advances in artificial intelligence models, combined with visual data covering urban areas, have made it possible to analyse the urban attractiveness in unprecedented ways. However, the gap between advances in mapping and planning practice remains wide, due to the complexity and resource-intensity of the novel methods. In this study, we explored the applicability of an off-the-shelf Al model with simple text commands in producing reliable spatial estimates of urban visual appeal from Street View Imagery.\nOur findings revealed a general alignment between the AI-generated ratings and human evaluations on urban appeal, but also notable contextual differences. GPT models generally assigned higher ratings to suburban areas, and lower ratings to densely populated urban areas, compared to the human participants. This discrepancy may arise from the models' inability to grasp the contextual and cultural nuances that humans use when evaluating urban environments. Humans might find densely-populated areas appealing due to their vibrant social and economic activities, which are integral to their daily lives and enhance the urban quality of life (61), despite these areas being less green or visually complex. In Helsinki, GPT models underestimated the visual appeal, especially in the urban core with its dense population, active cultural and economic activity, and historical architecture, but less greenery. Conversely, suburban and rural areas, while often"}, {"title": "", "content": "perceived as more visually appealing by the models due to their greenery and open spaces, might lack the dynamic elements that contribute to human satisfaction in urban settings, as the results indicated in Helsinki.\nThe analysis indicated that local residents exhibited lower spatial autocorrelation in their ratings compared to non-residents. This finding suggests that residents' evaluations are more diverse and influenced by their personal experiences and attachments to specific areas. In contrast, non-residents, who lack such personal connections, tend to rate urban areas based on more uniform and generalised criteria. This difference highlights how familiarity and a sense of place can shift evaluative criteria and perceptions (62). When living in an area, the daily interactions and memories associated with specific locations play a significant role in shaping one's evaluation of those places.\nThe analysis of spatial autocorrelation, both globally and locally, along with the differences between GPT model ratings and participant ratings, indicates that simpler models (Model-1) exhibited lower spatial autocorrelation compared to more complex models (Model-2 and Model-3). This suggests that simpler models, which lack specific evaluative criteria in their prompts, tend to provide more random and less consistent ratings. It should be noted that the complexity of human perception, which encompasses emotional, cultural, and experiential factors, presents a significant challenge for AI models (63). While current MLLMs like GPT-4 offer a promising start, they require guided prompting with certain criteria and/or fine-tuning to approach the depth of human evaluative processes.\nAn important reason for choosing off-the-shelf models was to democratise the use of AI for researchers and users who are not AI experts. These models eliminate the need for users to train the model, which often requires large amounts of training data and computational resources."}, {"title": "", "content": "Instead, these models offer a straightforward and accessible way to utilise AI without extensive technical expertise. While we initially considered using other models for the analysis, ChatGPT outperformed the alternatives. ChatGPT is widely accessible and familiar to many users (64), making our workflow more user-friendly and reproducible. By providing our prompts, we have enabled others to modify and experiment with the criteria easily, engaging with ChatGPT in a conversational manner. This accessibility is crucial for ensuring that advanced AI tools can be used broadly in urban planning and design without requiring extensive technical expertise.\nDespite its advantages, the use of ChatGPT comes with limitations. It is proprietary model and has usage constraints, even in its premium version (31). This can be a limiting factor for users needing to process numerous requests in a short period, as demonstrated in our workflow. Consequently, cities with extensive street view imagery, like Helsinki, would require a sampling algorithm to optimise the number of images for assessment, minimising the cost and time of API usage. Future research should focus on developing open-access models tailored to urban landscape analysis, allowing users to fine-tune and adapt these models without associated costs.\nAn important limitation of this research is that the results cannot be fully compared to the actual experiences of people physically present in an area. While this workflow and method can highlight areas with high or low visual appeal, the ratings are based on images rather than the real-life experience of being in a space. Capturing a multisensory, real-life experience in a relatively low resolution 360-degree image is impossible. Real-life experiences involve a combination of visual, auditory, tactile, and even olfactory stimuli that images alone cannot convey (65\u201367). Consequently, the ratings generated from these images only correspond to a partial representation of the actual environment."}, {"title": "7. Conclusion", "content": "While AI models like GPT-4 offer significant potential for streamlining the evaluation of urban visual appeal, our study highlights the need to incorporate human perspectives to capture the full range of contextual and experiential nuances. Al models can serve as an increasingly valuable tool for preliminary assessments, identifying areas that may require further human investigation. This approach can reduce operational costs and time expended by urban planners and designers, providing a more efficient pathway to understanding urban environments. However, caution should be exercised when relying solely on Al models for policymaking decisions, especially in areas in which human experiences and perceptions play a crucial role. The results of AI assessments should complement, rather than replace, human evaluations. Future research should focus on enhancing AI models to mimic human perception better, by integrating more sophisticated and nuanced criteria.\nOur work demonstrates the potential for AI to aid in the assessment of urban landscapes, but it also underscores the limitations of current technology. The ongoing development of AI models that can better understand and replicate human experiences will be critical for their effective application in urban planning. Existing survey materials could be leveraged to build a training pipeline, enhancing AI's ability to provide meaningful insights tailored to the local context. Ultimately, a hybrid approach that leverages both AI and human insights will provide the most comprehensive understanding of urban visual appeal, ensuring that planning and design decisions effectively promote healthy and satisfying living environments."}, {"title": "Appendix D - Luminosity", "content": "To determine the luminosity, we apply the formula:\n$L = 0.2126*R+ 0.7152*G + 0.0722*B$ Eq. D.1\nwhere L is luminosity; R, G, and B are the red, green, blue bands of the image, respectively. This formula is derived from the luminosity function, which reflects how the human eye perceives brightness. This specific calculation is used in converting color images to grayscale, as established in standards like BT.709, which is utilized for HDTV.\nA primary reference for this formula is the ITU-R Recommendation BT.709, also known as Rec. 709. This recommendation outlines various parameters for high-definition television, including color representation and luminance coefficients. The coefficients indicate the relative contributions of the red, green, and blue components, respectively, to the perceived brightness. These values are derived from the human visual system's response to these colors.\nFor a more comprehensive understanding and detailed explanation, refer to:\nTitle: Recommendation ITU-R BT.709-6: Parameter values for the HDTV standards for\nproduction and international programme exchange\nOrganization: International Telecommunication Union (ITU)\nPublication Date: 2015\nFollowing the calculation of luminosity for images, our analysis revealed a weak correlation of -0.16 between luminosity and ratings. Although we initially anticipated a positive correlation, the weak nature of this correlation suggests that it is not significant; therefore, we decided not to pursue further analysis or adjust the ratings based on luminosity."}, {"title": "Appendix A \u2013 Preliminary analysis", "content": "In our preliminary evaluation to determine the best model for our study, we explored using BLIP, CLIP, and GPT-4.\nAs CLIP's primary strength lies in image classification (e.g., categorizing an image as 70% park, 20% residential area), it was not suitable for directly scoring visual appeal. We attempted to classify images based on various criteria such as greenery, pedestrian paths, building types, public amenities, among others. Using the classifications provided by CLIP, we created sentences to describe the spaces and then applied sentiment analysis to these sentences. However, this approach was flawed because sentiment analysis models were not effectively measuring the visual appeal of the described space but rather the sentiment of the sentence itself. When we used GPT-4 to interpret the visual appeal of these sentences instead of a sentiment analysis model, the results were not sensible. The sentences generated by CLIP failed to capture many aspects of the images, resulting in a mere report of image segmentation.\nIn contrast, BLIP proved more effective in generating captions and answering questions. We used a variant called BLIP_VQA from the BLIP model family. By having BLIP answer higher-level questions about the images rather than merely classifying them, we generated more meaningful sentences to analyze in GPT-4. Despite minor grammatical errors, ChatGPT could understand and process these statements effectively. Here's an example of the statement we provided to ChatGPT:\n\"The roads and pedestrian paths are cracked and worn. The greenery in the area is it is sparse. The types of buildings visible are primarily modern and traditional. The area is predominantly rural. Public amenities such as benches and lighting fixtures are present. Accessibility for different abilities is adequate. Identifiable safety features include crosswalk. The area integrates with adjacent neighborhoods or landmarks yes. There are structures or areas with local historical or"}, {"title": "", "content": "cultural significance. The area does not offer a mix of commercial, residential, and recreational spaces. Sustainable features like solar panels or eco-friendly integrations are present. Designated spaces for social interaction are not available.\"\nOur approach using GPT-4 alone was explained in the main text, so we will not discuss it further here.\nFor our preliminary analysis, we also asked 10 individuals (all non-residents) to rate 10 pictures to compare their ratings with those generated by the AI models. The results showed that the average difference between the ratings of using GPT-4 only was 0.56, whereas using the combination of BLIP and GPT-4 was 0.76. Consequently, we decided to use GPT-4 only for the main study. This decision was based on the finding that GPT-4 provided more consistent and sensible ratings without the need for additional preprocessing or the use of multiple models."}, {"title": "Appendix B - GPT-4 Prompts", "content": "Prompt 1\nImagine you are human resident of Helsinki (OR human tourist in Helsinki), Finland with (OR without)\na typical local perspective on aesthetics and environment. Based on the panoramic image provided, rate the\noverall visual appeal and functionality of this specific location on a scale of 1 (completely unappealing) to\n7 (completely appealing).\nPlease exclude temporary elements such as weather or passing vehicles. Consider the image as if you're\nexperiencing the environment in person and not just as a viewer of a photograph.\nYou must not provide any rational or any conversation. I only need one integer number between 1 to 7.\nPrompt 2\nImagine you are a human resident of Helsinki (OR human tourist in Helsinki), Finland with (OR without)\na typical local perspective on aesthetics and environment. Based on the panoramic image provided, rate the\noverall visual appeal and functionality of this specific location on a scale of 1 (completely unappealing) to\n7 (completely appealing). Focus your assessment on the following criteria:\n\u2022\nSidewalk Features for Pedestrian Activity: Assess the design and features of the sidewalks.\nConsider aspects like width, surface condition, pedestrian signage, and accessibility features\n(e.g., curb cuts, tactile paving) that facilitate comfort and activity.\n\u2022\nStreet Design for Traffic and Activity: Evaluate the street layout and design. Focus on\nstreet width, lane markings, traffic calming measures (e.g., speed bumps, pedestrian crossings),\nand the integration of cycle paths or public transit stops, assessing how these features impact\ntraffic flow and pedestrian interaction.\n\u2022\nTree Canopy and Greenery: Consider the presence of greenery and its contribution to the\narea's ambiance, irrespective of seasonal changes."}, {"title": "", "content": "\u2022\nPhysical Indicators of Human Activity: Assess features indicating a space designed for\nhuman activity, such as street furniture, public space design, and amenities like water fountains\nand public art, reflecting potential vibrancy and safety.\n\u2022\nPermanent Lighting: Examine the placement and design of lighting fixtures, disregarding\ntemporary effects of natural lighting due to weather conditions.\nPlease exclude temporary elements such as weather or passing vehicles. Consider the image as if you're\nexperiencing the environment in person and not just as a viewer of a photograph.\nYou must not provide any rational or any conversation. I only need one integer number between 1 to 7 per\ncriterion in the format of [##,##,##,##,##].\nPrompt 3\nImagine you are a human resident of Helsinki (OR human tourist in Helsinki), Finland with (OR without)\na typical local perspective on aesthetics and environment. Based on the panoramic image provided, rate the\noverall visual appeal and functionality of this specific location on a scale of 1 (completely unappealing) to\n7 (completely appealing). Focus your assessment on the following criteria:\nEnduring Physical Features:\n\u2022\nSidewalk Features for Pedestrian Activity: Assess the design and features of the sidewalks.\nConsider aspects like width, surface condition, pedestrian signage, and accessibility features\n(e.g., curb cuts, tactile paving) that facilitate comfort and activity.\n\u2022\nStreet Design for Traffic and Activity: Evaluate the street layout and design. Focus on\nstreet width, lane markings, traffic calming measures (e.g., speed bumps, pedestrian crossings),\nand the integration of cycle paths or public transit stops, assessing how these features impact\ntraffic flow and pedestrian interaction.\n\u2022\nTree Canopy and Greenery: Consider the presence of greenery and its contribution to the\narea's ambiance, irrespective of seasonal changes."}, {"title": "", "content": "\u2022\nPhysical Indicators of Human Activity: Assess features indicating a space designed for\nhuman activity, such as street furniture, public space design, and amenities like water fountains\nand public art, reflecting potential vibrancy and safety.\n\u2022\nPermanent Lighting: Examine the placement and design of lighting fixtures, disregarding\ntemporary effects of natural lighting due to weather conditions.\nUrban Design Qualities:\n\u2022\nImageability: Determine the visual distinctiveness and memorability of the environment.\n\u2022\nLegibility: Evaluate how easily one can understand and navigate the spatial layout.\n\u2022\nEnclosure: Consider the sense of spatial definition provided by buildings and natural\nelements.\n\u2022\nHuman Scale: Observe how the proportions of space and elements align with human\ndimensions for comfort.\n\u2022\nTransparency: Assess the visibility and perceived openness of space, including sightlines\nand visual connections.\n\u2022\nLinkage: Analyze how different spaces within the image are connected to facilitate\nmovement and interaction.\n\u2022\nComplexity: Reflect on the variety and visual richness of the environment.\n\u2022\nCoherence: Judge the consistency and unity of the urban design elements.\nSubjective Reaction: Contemplate your instinctive response to the area's appeal, considering the potential\nfor enjoyment and engagement with the space.\nPlease exclude temporary elements such as weather or passing vehicles. Provide a balanced assessment\nwithout leaning towards an overly positive or negative evaluation. Consider the image as if you're\nexperiencing the environment in person and not just as a viewer of a photograph.\nYou must not provide any rational or any conversation. I only need one integer number between 1 to 7 per\ncriterion in the format of [##, ##,##,##,##,##,##,##,##,##, ##,##, ##,##]."}, {"title": "Appendix C - Participant Guidance for Image Rating", "content": "Introduction\nThank you for participating in our urban environmental analysis study. Your insights are valuable in\nunderstanding how people perceive urban spaces. This guide will help you focus on the essential aspects of\nthe images you will be rating.\nObjective\nOur study aims to evaluate the visual appeal of urban spaces using street view imagery. Your task is to rate\neach image based on the permanent qualities, considering how you would feel if you were physically\npresent in these environments.\nWhat to Focus On\nPermanent Features: Pay attention to elements that are constant or long-term in the environment, such as:\n\u2022\nBuilding architecture and style\n\u2022\nPresence and quality of green spaces (parks, trees, gardens)\n\u2022\nWalkability and pedestrian spaces\n\u2022\nUrban design elements (street layout, benches, lighting)\n\u2022\nGeneral cleanliness and upkeep\nWhat to Ignore\nPlease disregard temporary or fleeting aspects that do not reflect the inherent qualities of the space, such\nas:\n\u2022\nWeather Conditions: Sunny, cloudy, rainy, etc.\n\u2022\nTemporary Objects: Passing cars, temporary constructions, movable objects.\n\u2022\nPeople: Crowds, individuals, or any activities that are not permanent features of the space.\nRating Process\n\u2022\nImagine yourself in the environment: Consider how you would feel and what your\nexperience would be like if you were there.\n\u2022\nBe consistent: Try to maintain a consistent standard in your ratings throughout the process."}, {"title": "", "content": "\u2022\nTrust your instincts: Your first impression is often the most reflective of your true\nConclusion\nperception of the space.\nYour honest and thoughtful ratings are crucial for our study. By focusing on the permanent, inherent\nqualities of these urban environments, your input will help us create a more accurate and meaningful\nanalysis of urban pleasantness."}]}