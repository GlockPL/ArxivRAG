{"title": "TrajWeaver: Trajectory Recovery with State Propagation Diffusion Model", "authors": ["Jinming Wang", "Hai Wang", "Geyong Min", "Hongkai Wen", "Man Luo"], "abstract": "With the proliferation of location-aware devices, large amount of trajectories have been generated when agents such as people, vehicles and goods flow around the urban environment. These raw trajectories, typically collected from various sources such as GPS in cars, personal mobile devices, and public transport, are often sparse and fragmented due to limited sampling rates, infrastructure coverage and data loss. In this context, trajectory recovery aims to reconstruct such sparse raw trajectories into their dense and continuous counterparts, so that fine-grained movement of agents across space and time can be captured faithfully. Existing trajectory recovery approaches typically rely on the prior knowledge of travel mode or motion patterns, and often fail in densely populated urban areas where accurate maps are absent. In this paper, we present a new recovery framework called TrajWeaver based on probabilistic diffusion models, which is able to recover dense and refined trajectories from the sparse raw ones, conditioned on various auxiliary features such as Areas of Interest along the way, user identity and waybill information. The core of TrajWeaver is a novel State Propagation Diffusion Model (SPDM), which introduces a new state propagation mechanism on top of the standard diffusion models, so that knowledge computed in earlier diffusion steps can be reused later, improving the recovery per-formance while reducing the number of steps needed. Extensive experiments show that the proposed TrajWeaver can recover from raw trajectories of various lengths, sparsity levels and heterogeneous travel modes, and outperform the state-of-the-art baselines significantly in recovery accuracy. Our code is available at: https://anonymous.4open.science/r/TrajWeaver/", "sections": [{"title": "I. INTRODUCTION", "content": "The ubiquity of GPS-enabled devices has revolutionized urban data collection, producing vast amounts of trajectory data that serve as the foundation for data-driven smart city applications. For instance, trajectories can be used to discover road networks [1], classify vehicle types [2] and identify transportation mode [3]. However, the collected trajectories are often sparse and disjointed due to constraints such as limited sampling rates and intermittent signal loss. This sparsity poses a significant challenge in accurately capturing the continuous movement of agents across urban landscapes. Trajectory re-covery emerges as an essential task, aiming to reconstruct these incomplete trajectories into detailed and seamless paths that accurately reflect the agents' movements. Specifically, given a sparse trajectory and various additional contexts such as user ID or waybill data, trajectory recovery is to generate and fill points into the gaps within the sparse trajectory. However, this task is fraught with challenges. First, the moving agents can exhibit heterogeneous mobility patterns. Especially in last-mile delivery scenarios, the couriers can frequently enter or exit apartments, moving quickly or staying at one loca-tion for a long time. The second challenge involves the diverse lengths and sparsity levels of trajectories, which requires the recovery model to have good scalability. Lastly, the detailed map information is usually absent in complex metropolitan or residential areas. Most existing methods perform poorly in these scenarios, struggling to generalize across diverse transportation modes or densely populated areas.\nRecently, diffusion models have demonstrated robust per-formance in content recovery tasks such as image inpainting [4] and time series imputation [5]. A diffusion model oper-ates through two multi-step processes. The diffusion process corrupts the data through recursive noise injection, eventually resulting in pure noise. Conversely, the denoising process employs neural networks to progressively remove the noise at each step, thereby recovering the original data. Compared to other content generation methods like Variational Autoencoders (VAEs) [6], [7] and Generative Adversarial Networks (GANs) [8], [9], diffusion models exhibit superior modeling, pattern capturing and content generation capabilities across a range of tasks [10], [11], [12]. These strengths suggest that diffusion models hold significant potential for enhancing trajectory recovery, offering more accurate and robust recon-structions of trajectories.\nAlthough the unique multi-step procedure endows diffusion models with strong recovery ability, several challenges arise when applying them to trajectory recovery. The first challenge lies in integrating diverse recovery conditions into diffusion models in an economic and efficient way. Different from trajectory generation task which generates the entire trajectory based on few conditions, trajectory recovery generates additional points given various conditions. In addition to the sparse trajectory being the foundation of this recovery task, extra contexts include the prior knowledge such as linear interpolated points, and numerous additional contexts such as user ID, weekday, and waybill information. Given that diffusion models perform recovery through many denoising steps, where conditions are fused at each step, the integration of conditions must be multi-modal, computationally efficient, and sensitive to the spatio-temporal correspondence among these conditions. A common way of conditioning in diffusion models is through cross-attention, as stated in [13], which em-ploys a pre-trained module to integrate and convert conditions into an embedding, then fuse the embedding into the denoising neural network. However, due to the squared memory usage of cross-attention modules, this way of condition fusing is not efficient, especially for long trajectories.\nAs the basic version of diffusion model, Denoising Diffu-sion Probabilistic Model (DDPM) [14] often takes thousands of denoising steps to complete recovery. Techniques such as Denoising Diffusion Implicit Model (DDIM) [15], DPM Solver [16] and Pseudo Numerical Methods for Diffusion Models (PNDM) [17] can reduce the number of steps needed to tens, while other methods have accelerated the denoising process through model pruning and distillation [18], [19], [20]. However, most approaches sacrifice recovery quality to achieve lower latency, and it is challenging to simultaneously ensure fast and high-quality recovery. The core issue that prevents efficient recovery is the inherently isolated nature of the denoising steps. The denoising process often takes hundreds of steps, where each step performs extensive feature extraction. However, as defined by diffusion framework, the denoised content is the only information passed to the next step, which hinders the sharing of knowledge among steps. A more efficient recovery process could be realized by promoting greater collaboration among denoising steps, enabling the reuse of features, and thereby achieving high-quality recovery with significantly fewer steps.\nScalability is a critical challenge in applying diffusion models to trajectory recovery, given the varying lengths and sparsity levels of trajectories. In logistics scenarios, trajectory lengths can range from tens of points to thousands, and the total distance can vary from hundred meters to kilometers. Short trajectories often lack sufficient conditional information, which requires the model to accurately reconstruct them with limited information. In the case of sparse trajectories, more points should be generated and inserted into the trajectory, so diffusion models introduce more noise into the data and leads to greater instability. On the other hand, long trajecto-ries require the model to distill useful information at each denoising step, which can increase model complexity and slow down recovery. Moreover, the diverse spatio-temporal patterns correspond to different trajectory length and sparsity can further complicate the condition fusion process. Therefore, ensuring the scalability of diffusion models is essential for their successful application in trajectory recovery.\nTo address the challenges outlined above, we propose a novel diffusion-based trajectory recovery framework called Traj Weaver, which is capable of effectively aggregate and fuse diverse conditions into the multi-step recovery process. To achieve high-quality and low-latency trajectory recovery simultaneously, Traj Weaver introduces a new variant of the diffusion model, State Propagation Diffusion Model (SPDM). In particular, it implements a state propagation pipeline on top of the standard denoising process, which allows knowl-edge sharing and features reuse among steps. This inter-step information sharing not only improves recovery efficiency, but also enhances scalability by transmitting multi-scale features within state. The design of TrajWeaver is anchored in three key elements: an advanced module for effective condition aggregation, a neural network that enables state fusing and propagation, and a specialized training algorithm tailored for SPDM. Through extensive experiments, TrajWeaver demon-strates its ability to recover both pedestrian and vehicle trajec-tories in complex urban environments with high accuracy and scalability.\nOverall, our contributions can be summarized as follows:\n\u2022 We propose a novel diffusion-based trajectory recovery framework named TrajWeaver, which is capable of ag-gregating various forms of conditions to achieve fast and accurate trajectory recovery in complex environments with dynamic moving patterns.\n\u2022 We introduce SPDM, which consists a new state prop-agation mechanism on top of the standard diffusion models, so that more efficient recovery process and better scalability can be achieved.\n\u2022 We conduct extensive experiments to validate the effec-tiveness of the proposed method, including comparisons with existing methods, ablation studies and use case analysis."}, {"title": "II. RELATED WORK", "content": "Trajectory Recovery. Numerous efforts have been dedicated to increase the accuracy of trajectory recovery. Certain map-based methods [21], [22], [23], [24] utilize a predefined set of points of interest (POI) or a pre-collected road network as strong prior knowledge, but the detailed map information is not always guaranteed. In contrast, DHTR [25] performs free space trajectory recovery leveraging RNNs, which does not require road network information. However, for very long and sparse trajectories, RNNs struggle to capture dependencies among points. This is because RNNs recovery consecutive points in auto-regressive manner, which may accumulate the recovery errors. AttnMove [26] is a method based on Trans-formers [27], which excel in capturing long-term dependen-cies within sequence. In particular, it assumes that the agent moves in periodic manner, thus similar trajectories will be produced in each period. By aggregating all history trajecto-ries and the current trajectory via inter- and intra-trajectory attention, the underlying mobility patterns of the agent can be revealed. TrajBERT [28] is another Transformer-based method that is mainly built on BERT [29], which incorporates multi-aspect spatial-temporal aware designs.\nDiffusion-based Trajectory Generation. There are no ex-isting works that apply diffusion models to trajectory re-covery, but diffusion-based methods on time series recovery and trajectory generation can be used as references. Existing approaches have successfully applied diffusion models to generate and recover time series data, including CSDI [30] and SSSD [31]. In particular, PriSTI [5] is a recent diffusion-based method designed for time series recovery, it utilizes spatio-temporal conditions and geographical factors for more accurate recovery. On the other hand, another thread of exist-ing work uses diffusion models for trajectory generation rather than recovery. The main difference between these two tasks is that trajectory generation produces the full trajectory without knowing existing portions, and the aim of this task is usually to ensure the generated dataset having similar distribution as the original trajectory dataset. For example, DiffTraj [32] employs UNet [33] to perform denoising steps with several simple contexts such as trajectory length, beginning point and end point. Diff-RNTraj [34] combines the advantages of both PriSTI and DiffTraj to perform trajectory generation with road network integrated.\nMore Efficient Diffusion Models. Denoising Diffusion Prob-abilistic Models (DDPM) [14] is the basic version of diffusion model, which requires hundreds of denoising steps to complete recovery. Many techniques were proposed to reduce the redun-dancy and improve efficiency of DDPM. Such works include Denoising Diffusion Implicit Model (DDIM) [15] and DPM Solver [16], which can shrink the denoising process to 10 to 20 steps with a cost of around 10% to 30% loss in recovery quality. There exists methods capable of distilling denoising process to one step [19], but it sacrifices more result quality for extremely fast recovery. Pseudo Numerical Methods for Diffusion Models (PNDM) [17] is a more advanced diffusion sampler that performs fast denoising process while preserves the original result quality. Moreover, model compression and quantization methods such as Diff-Pruning [18] and PTQD [35] can effectively reduce computation waste thus accelerate each denoising step. DeepCache [20] is the most similar method to our approach, which optimizes denoising process by excluding certain parts of the UNet [33] and reusing previously extracted features."}, {"title": "III. PRELIMINARIES", "content": "A. Problem Formulation\nTrajectory: A trajectory $T = {P_0, P_1,...}$ is a chronologi-cally ordered sequence that describes the movement of an entity, where each element is a spatio-temporal point $p_i = (lng_i, lat_i, time_i)$ consisting of longitude, latitude and time stamp.\nSparse Trajectory: Given a dense trajectory $T$, a sparse trajectory $\\tau$ contains a subset of $T$ and fails to accurately describe the continuous movement of the entity in the real world.\nQuery: A query $Q$ is a manually selected or procedurally generated sequence of time stamps. We want to determine the location of the moving entity at each specified time stamp in $Q$.\nTrajectory Recovery: Given sparse trajectory $\\tau$, query $Q$, and other types of contexts such as date, weekday, user ID, waybills, etc. The goal of trajectory recovery is to accurately predict the unknown locations correspond to the provided $Q$.\nB. Diffusion Models\nDiffusion Process. The diffusion process consists of a series of noise addition steps, where each step is formulated as in Equation 1. In this equation, $t \\in [0,T)$ denotes the index for the diffusion step, $\\alpha_t$ and $\\beta_t$ are noise schedules and $\\alpha_t = 1 - \\beta_t$. $\\epsilon_{t:t+1}$ represents single step noise drawn from $N(0, 1)$.\n$x_{t+1} = \\sqrt{\\alpha_t}x_t + \\sqrt{\\beta_t}\\epsilon_{t:t+1}$ (1)\nWe can further derive and compute $x_t$ directly from the original content $x_0$ instead of applying the forward step $t$ times, as shown in Equation 2. Here, $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_i$, and $\\epsilon_{0:t+1} \\sim N(0,1)$ represents the multi-step noise added to $x_0$ to produce $x_t$ in one step. The notation\n$x_{t+1} = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon_{0:t+1}$ (2)\nDenoising Process. The denoising process aims to reconstruct clear content $x_0$ from random noise $x_t$ through a series of denoising steps. Given noisy content $x_{t+1}$ at step $t+1$ where $t \\in [0,T-1]$, the aim of this denoising step is to predict the mean and standard deviation of the less noisy content $x_t$. The equation below explains one denoising step.\n$\\mu_{\\epsilon} = \\frac{\\beta_t}{\\sqrt{\\alpha_t} * (1 - \\bar{\\alpha}_t)} x_{t+1} - \\bar{\\alpha}_t \\epsilon_{0:t+1}$ (3)\n$\\sigma_{\\epsilon} = \\sqrt{\\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t}} * \\beta_t, z \\sim N(0,1)$\n$x_t = \\mu_{\\epsilon} + \\sigma_{\\epsilon} * z,$\nA neural network is trained to predict $\\epsilon_{0:t+1}$ in equation 3 since it is the only unknown value. During training, we choose $t$ from valid range from 0 to T\u22121, then sample $\\epsilon_{0:t} \\sim N(0,1)$ and apply diffusion forward process to $x_0$ to obtain $x_t$, where $x_0$ is the original content and $x_t$ is the noisy content. The model is trained to produce $\\epsilon_{0:t+1}^{pred}$ and the loss is computed using mean squared error."}, {"title": "IV. METHODOLOGY", "content": "A. TrajWeaver Overview\nCondition Aggregation Stage. Before entering the pipeline of TrajWeaver, we first need to define all input components that are crucial for the model's performance. The main input is a sparse trajectory $\\tau$, which represents a sequence of spatio-temporal points sampled at irregular intervals. Alongside this sparse trajectory, a query $Q$ is selected either manually or procedurally, containing a series of time stamps at which the locations need to be predicted. These time stamps from $Q$ are inserted into the sparse trajectory $\\tau$, with the corresponding un-known locations initialized with random noise values, denoted as $x_T$. The outcome of this initialization is the trajectory $\\tau_T$, where TrajWeaver's objective is to convert the noisy locations $x_T \\in \\tau_T$ into accurate predictions $x_0 \\in \\tau_0$, representing the original, noise-free trajectory. The process of composing $\\tau_T$ is depicted in Figure 3.\nTo facilitate the recovery process, we generate a binary mask $M$, where each entry is set to 0 or 1 to indicate whether a point is part of the original trajectory or an inserted point, respectively. This mask helps the model distinguish between observed and unobserved data points. Furthermore, to incorporate prior spatio-temporal knowledge into the model, we create an additional trajectory representation, $\\tau^I$, where unknown locations are filled with linearly interpolated values instead of random noise. This serves as a preliminary estimate or \"prior guess\" of the true trajectory, providing a useful baseline for the model to build upon during the diffusion process.\nIn addition to the previous inputs, various contextual fea-tures $C_0, C_1,...$ that are associated with the trajectory are also considered. Due to the sequential form of trajectories, the positions of tokens contain important spatio-temporal knowledge. To ensure good positional correspondence among conditions, we also want to process the contexts $C_0, C_1, ...$ to sequential forms just like other conditions. However, the forms of these contexts can vary widely in different industrial sce-narios, a universal embedding module design is inappropriate. Therefore, we assume a specifically designed module $Embed_i$ for each context $C_i$, which processes it into a sequential embedding $E_i$ of the same length as $\\tau_T$. These modules can be as trivial as several convolutional layers or fully-connected layers. All conditions are now in sequential format with the same length. Instead of applying cross attention to fuse them as in Stable Diffusion [13], we simply concatenate them together, witch keeps positional alignment among sequences, thus ensures good spatio-temporal correspondence. The final aggregated condition is denoted as $A_T$. This stage is illustrated in Figure 2 (a) and formulated as follows:\n$A_T \\leftarrow Concat(\\tau_{T}, \\tau^{I}, M, E_0, E_1, ...)$ (4)\n$E_i \\leftarrow Embed_i(C_i)$\nRecovery Stage. TrajWeaver recovery stage focuses on re-moving noise from $x_T \\in A_T$, while all other portions of $A_T$ remain fixed throughout the recovery procedure. As shown in Figure 2 (b), recovery takes T steps counting down from T-1 to 0. Each denoising step is illustrated in Figure 2 (c). Given $A_t$ in step t, a neural network is utilized to make a prediction $\\hat{\\epsilon}_{0:t}$. Then, $x_t$ is denoised to $x_{t-1}$, which also transforms $A_t$ to $A_{t-1}$. A typical denoising step in diffusion models takes only $A_t$ and t as inputs then produces $\\hat{\\epsilon}_{0:t}$. As a result, the traditional denoising steps are nearly isolated, and some similar features can be repeated extracted in each step. This significant redundancy makes the denoising process inefficient, and prevents the model from achieving low latency and high recovery quality simultaneously. Therefore, TrajWeaver em-ploys SPDM which allows inter-step information sharing and feature reuse. Specifically, as indicated by the orange arrows in Figure 2 (b), each denoising step produces an additional state $S_{t-1}$ that contains useful information for subsequent steps, and each step also absorbs state $s_t$ from the previous step, with the initial state $s_T$ filled with 0. This state propagation mechanism is completed by the specially designed denoising neural network, as formulated in Equation 5.\n$\\hat{\\epsilon}_{0:t}, S_{t-1} = Net(A_t, t, s_t)$ (5)\nB. Network Architecture\nAs illustrated in Figure 2 (c), the denoising neural network is based on UNet [33] architecture which facilitates multi-scale feature extraction and enhances scalability. Each UNet block is shown in Figure 2 (d) Multi-head self-attention modules are employed in the middle of the network, allowing global receptive field and better capture spatio-temporal dependencies in long and sparse trajectories. The unique design within TrajWeaver denoising neural network is the implementation of state propagation mechanism, which requires solving three key problems: determining the format of states, fusing state $s_t$ into the neural network, and updating $s_t$ to produce $S_{t-1}$.\nFormat of State. We design the state as multiple feature sequences, denoted as $s_t = {f_t^1, f_t^2, f_t^3, ...}$. This state rep-resentation has two advantages. First, since trajectory features are all in sequential format, using the same format for state features can ensure a strong positional correspondence during feature fusing. While other feature formats like vectors do not have this property, it also requires additional processing to fuse vectors with sequences. Second, the dynamic lengths and sparsity levels of trajectories can affect the patterns within the input contexts at different scale. We make $s_t$ multiple sequences with different scales to align with the UNet's multi-level design, allowing better scalability.\nFusing Previous State. Each feature sequence within $s_t$ is fused into each UNet block as shown in Figure 2 (d). There are several ways for sequence fusing, cross-attention is a widely adopted choice for multi-modal context fusion in diffusion models. However, the multi-scale sequential form of features have already ensure the good positional correspondence, which makes simple addition or concatenation sufficient for state fusion. In the figure, we show state feature fusion using addition.\nPropagating State. To update $s_t$ to $s_{t-1}$, a GRU cell is employed to propagate each $f_t^i$ to $f_{t-1}^i$. By adopting the GRU cell, $S_{t-1}$ not only encapsulates knowledge in the current denoising step, but also contains knowledge of all previous steps, which allows long-range inter-step information sharing. Ideally, at the last few steps of the denoising process, the state will contain the most useful knowledge extracted in the previous tens to hundreds of steps.\nC. Training of TrajWeaver\nDuring TrajWeaver training, a dense ground truth trajectory $T_0$ is provided, some time stamps are randomly selected as the query $Q$, and the corresponding locations are $x_0$. The diffusion process adds T steps of noise to $x_0$, producing $x_T$. Since $x_0$ is part of $T_0$, applying diffusion to $x_0$ also transforms $T_0$ into $T_T$.\nThe training of SPDM differs significantly from typical dif-fusion model training, because the state propagation introduces more dependency among denoising steps. As suggested in Equation 5 and Figure 2 (b), denoising step t cannot be per-formed without $s_{t+1}$ from previous step t + 1. Consequently, unlike in typical diffusion model training where a random t is chosen in each training sample, we must iterate over t from T-1 to 0 to ensure that we always have previous state $s_{t+1}$, with the initial state $s_T$ set to zero tensors.\nAnother problem is to ensure $s_t$ containing useful features for later steps. Since the $s_t$ is produced by the GRU cell and is used in the next denoising step, the parameters of GRU cannot be optimized when each step is trained independently. Therefore, we have to train multiple steps jointly in each training iteration. The ideal approach is to train the denoising process as a whole, thus the overall objective of SPDM is presented in Equation 6, where $\\theta$ represents the learnable parameters of the model.\n$min_{\\theta} \\sum_{t=1}^T MSE(\\epsilon_{0:t}, \\hat{\\epsilon}_{0:t})$ (6)\nHowever, it is unrealistic to train all tens to hundreds of steps in each iteration. Therefore, we split the denoising process into smaller segments consisting of several adjacent steps. The new objective for training 2 steps in a single iteration is formulated in Equation 7.\n$min(MSE(\\epsilon_{0:t+1}, \\hat{\\epsilon}_{0:t+1}) + MSE(\\epsilon_{0:t}, \\hat{\\epsilon}_{0:t}))$ (7)\nStandard diffusion model samples $\\epsilon_{0:t} \\sim N(0, 1)$ indepen-dently in each training iteration. This becomes inappropriate when multiple steps are included in one iteration, because $\\epsilon_{0:t+1}$ and $\\hat{\\epsilon}_{0:t}$ are dependent. In fact, $\\epsilon_{0:t+1}$ depends on all previous single-step noises ${\\epsilon_{0:1}, \\epsilon_{1:2}, ..., \\epsilon_{t:t+1}}$ and multi-step noises ${\\epsilon_{0:1}, \\epsilon_{0:2}, ..., \\epsilon_{0:t}}$. Therefore, $\\epsilon_{0:t}$ and $\\epsilon_{0:t+1}$ can-not be sampled directly from Gaussian distribution. Nonethe-less, the single-step noises $\\epsilon_{t:t+1}$ remain independent, which allows us to sample all single-step noises ${\\epsilon_{t:t+1}|t \\in [0,T)}$ and then derive multi-step noises using Equation IV-C.\nFirst, we combine equation 1 and 2\n$\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon_{0:t+1} = x_{t+1} = \\sqrt{\\alpha_t}x_t + \\sqrt{\\beta_t}\\epsilon_{t:t+1}$\nWe can also get $x_t$ from $x_0$ with equation 2, and then replace $x_t$ with a function of $x_0$ and $\\epsilon_{0:t}$.\n$\\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon_{0:t+1} = \\sqrt{\\alpha_t}(\\sqrt{\\bar{\\alpha}_{t-1}}x_0 + \\sqrt{1 - \\bar{\\alpha}_{t-1}}\\epsilon_{0:t}) + \\sqrt{\\beta_t}\\epsilon_{t:t+1}$\n$\\sqrt{1 - \\bar{\\alpha}_t}\\epsilon_{0:t+1} = \\sqrt{\\alpha_t}\\sqrt{1 - \\bar{\\alpha}_{t-1}}\\epsilon_{0:t} + \\sqrt{\\beta_t}\\epsilon_{t:t+1}$\n$\\epsilon_{0:t+1} = \\frac{\\sqrt{\\alpha_t}\\sqrt{1 - \\bar{\\alpha}_{t-1}}}{\\sqrt{1 - \\bar{\\alpha}_t}}\\epsilon_{0:t} + \\frac{\\sqrt{\\beta_t}}{\\sqrt{1 - \\bar{\\alpha}_t}}\\epsilon_{t:t+1}$\nThe resulting Equation IV-C shows a way to inference $\\epsilon_{0:t+1}$ based on $\\epsilon_{0:t}$ and $\\epsilon_{t:t+1}$. We call it a noise compose equation and simplify it as:\n$\\epsilon_{0:t} \\leftarrow Compose(\\epsilon_{0:t+1}, \\epsilon_{t:t+1})$ (8)\nWith this equation and randomly sampled list of single-step noises ${\\epsilon_{0:1}, \\epsilon_{1:2}, ...\\epsilon_{T-1:T}}$, we can obtain the list of multi-step noises through a recursive process shown below.\n$\\epsilon_{0:2} \\leftarrow Compose(\\epsilon_{0:1}, \\epsilon_{1:2})$\n$\\epsilon_{0:3} \\leftarrow Compose(\\epsilon_{0:2}, \\epsilon_{2:3})$\n$\\epsilon_{0:4} \\leftarrow Compose(\\epsilon_{0:3}, \\epsilon_{3:4})$\n$\\epsilon_{0:T} \\leftarrow Compose(\\epsilon_{0:T-1}, \\epsilon_{T-1:T})$\nThe general principles of SPDM training have been estab-lished, which makes TrajWeaver training possible. A naive procedure is presented in Algorithm 1.\nWhile the above design and formulas are sufficient for training, additional techniques are necessary in practical imple-mentation. One major problem is that each trajectory is used T training iterations and the counting down of t applies to the entire batch of trajectories, illustrated as Figure 4a. This shared countdown can lead to over-fitting to certain local range of t and poor generalization across the entire range of t. As a result, the training is very unstable and the convergence extremely slow.\nTo mitigate this issue, a new batch managing design has to be adopted. We assign a different private t for each sample in a mini-batch, as illustrated in Figure 4b. To further enhance generalization over the entire denoising process and ensure stable convergence, we distribute ts uniformly within the range [0, T-1] as shown in Figure 4c. The t value for each sample is independently updated, and a new sample is loaded in-place when the t for an old sample is reduced to 0."}, {"title": "V. EXPERIMENTS", "content": "A. Experimental Settings\nDatasets. We use two datasets consisting of dense and smooth taxi trajectories collected in Xi'an city and ChengDu city, China. The third dataset is collected in real-world logistics scenarios generated by couriers on foot, this dataset involves couriers moving in apartment areas and exhibits irregular sample intervals. We conduct experiments with three evaluation met-rics to assess various aspects of seven different methods. They include Mean Squared Error (MSE) between the original trajectory and the recovered trajectory, which aims to mea-sure how effectively models can recover broken trajectories. Normalized Dynamic Time Warping (NDTW) places empha-sis on the shape of the trajectory rather than point-to-point comparison. Jensen-Shannon Divergence (JSD) is employed to compare the likelihood of two distributions, serving as a measure of the distribution of points between the recovered trajectories and the trajectories in the original dataset. It is important to note that lower values are preferable for all three metrics.\nB. Overall Performance\nWe conduct comparative experiments among the proposed method and five baselines.\n\u2022 DeepMove [36", "26": "leverages both self-attention and cross-attention mechanisms to learn travel patterns from his-torical trajectories. It fuses intra- and inter-trajectory knowledge to enhance trajectory recovery, but may not be fully effective in scenarios where data is highly sparse or contains significant noise.\n\u2022 PriSTI [5", "32": "a UNet-based diffusion model for generating trajecto-ries, with RePaint [4"}]}