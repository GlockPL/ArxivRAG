{"title": "A* for Graphs of Convex Sets", "authors": ["Kaarthik Sundar", "Sivakumar Rathinam"], "abstract": "We present a novel algorithm that fuses the existing convex-programming based approach with heuristic information to find optimality guarantees and near-optimal paths for the Shortest Path Problem in the Graph of Convex Sets (SPP-GCS). Our method, inspired by A*, initiates a best-first-like procedure from a designated subset of vertices and iteratively expands it until further growth is neither possible nor beneficial. Traditionally, obtaining solutions with bounds for an optimization problem involves solving a relaxation, modifying the relaxed solution to a feasible one, and then comparing the two solutions to establish bounds. However, for SPP-GCS, we demonstrate that reversing this process can be more advantageous, especially with Euclidean travel costs. In other words, we initially employ A* to find a feasible solution for SPP-GCS, then solve a convex relaxation restricted to the vertices explored by A* to obtain a relaxed solution, and finally, compare the solutions to derive bounds. We present numerical results to highlight the advantages of our algorithm over the existing approach in terms of the sizes of the convex programs solved and computation time.", "sections": [{"title": "I. INTRODUCTION", "content": "The Shortest Path Problem (SPP) is one of the most important and fundamental problems in discrete optimization [1]\u2013[3]. Given a graph, the SPP aims to find a path between two vertices in the graph such that the sum of the cost of the edges in the path is minimized. In this paper, we concern ourselves with a generalization of the SPP, recently introduced in [4], where each vertex is associated with a convex set and the cost of the edge joining any two vertices depends on the choice of the points selected from each of the respective convex sets. In this generalization, referred to as the Shortest Path Problem in the Graph of Convex Sets (SPP-GCS) [4], the objective is to find a path and choose a point from each convex set associated with the vertices in the path such that the sum of the cost of the edges in the path is minimized (Fig. 1). The SPP-GCS naturally arises in several applications including motion planning of robots [5], [6], planning problems with neighborhoods [7], [8] and control of hybrid systems [4]. Numerical and experimental results [4]\u2013[6] have also shown that collision-free trajectories can be reliably designed using solutions to SPP-GCS in high-dimensional complex environments.\nSPP-GCS reduces to the standard SPP if the point to be selected from each convex set is given. Also, SPP-GCS reduces to a relatively easy-to-solve convex optimization problem if the path is given. Selecting an optimal point in each set, as well as determining the path, makes the SPP-GCS NP-Hard in the general case [4]. Brute force algorithms, which find all feasible paths from the origin to the destination and then selects a path that yields the shortest length, may not be"}, {"title": "II. PROBLEM STATEMENT", "content": "Let $V$ denote a set of vertices, and $E$ represent a set of directed edges joining vertices in $V$. Let each vertex $v \\in V$ be associated with a non-empty, compact convex set $X_v \\subset \\mathbb{R}^n$. Given vertices $u, v \\in V$, the cost of traveling the edge $e = (u, v)$ from $u$ to $v$ depends on the choice of the points in the sets $X_u$ and $X_v$. Specifically, given points $x_u \\in X_u$ and $x_v \\in X_v$, let $\\text{cost}(x_u, x_v)$ denote the travel cost of edge $e = (u, v)$. In this paper, we set $\\text{cost}(x_u, x_v)$ to be equal to the Euclidean distance between the points $x_u$ and $x_v$, i.e., $\\text{cost}(x_u, x_v) := ||x_u - x_v||_2$.\nAny path in the graph $(V, E)$ is a sequence of vertices $(v_1, v_2, \\dots, v_k)$ for some positive integer $k$ such that $v_i \\in V, i = 1, \\dots, k$ and $(v_i, v_{i+1}) \\in E, i = 1, \\dots, k-1$.\nGiven a path $P := (v_1, v_2, \\dots, v_k)$ and points $x_{v_i} \\in X_{v_i}, i = 1, \\dots, k$, the cost of traveling $P$ is defined as $\\sum_{i=1}^{k-1} \\text{cost}(x_{v_i}, x_{v_{i+1}})$. Given an origin $s \\in V$ and destination $d \\in V$, the objective of the SPP-GCS is to find a path $P := (v_1, v_2, \\dots, v_k)$ and points $x_{v_i} \\in X_{v_i}, i = 1, \\dots, k$, such that $v_1 = s, v_k = d$, and the cost of traveling $P$ is minimized. The optimal cost for SPP-GCS is denoted as $C_{\\text{opt}}(s, d)$."}, {"title": "III. GENERALIZATION OF SPP-GCS AND ITS RELAXATION", "content": "We first introduce some notations specific for A*-GCS. For each vertex $v \\in V$, let $h(v)$ denote an underestimate to the optimal cost for the SPP-GCS from $v$ to $d$, i.e., $h(v) \\le C_{\\text{opt}}(v, d)$. We refer to such underestimates as admissible (just like in A* [12]). Note that for the destination $d$, the underestimate $h(d) = 0$. We also refer to $h( . )$ as a heuristic"}, {"title": "A. Non-Linear Program for SPP*-GCS", "content": "To formulate SPP*-GCS, we use two sets of binary variables to specify the path and a set of continuous variables to choose the points from the convex sets corresponding to the vertices in the path. The first set of binary variables, denoted by $Y_{uv}$ for $(u, v) \\in E$, determines whether the edge $(u, v)$ is selected in a solution to the SPP*-GCS. Here, $Y_{uv} = 1$ implies that the edge $(u, v)$ is chosen, while $Y_{uv} = 0$ implies the opposite. The second set of variables, denoted by $\\alpha_v$ for $v \\in S'$, determines whether the vertex $v$ is selected as a terminal or not. The continuous variable $x_u$ for $u \\in V$ specifies the point chosen in the convex set corresponding to vertex $u$. For any vertex $u \\in V$, let $\\delta^+(u)$ be the subset of all the edges in $E$ leaving $u$, and let $\\delta^-(u)$ be the subset of all the edges in $E$ coming into $u$. The non-linear program for SPP*-GCS is as follows:\n$C_{\\text{opt}}^{S,S'} := \\min \\sum_{(u,v) \\in E} \\text{cost}(x_u, x_v) Y_{uv} + \\sum_{v \\in S'} \\alpha_v h(v)$\n$\\sum_{v \\in S'} \\alpha_v = 1$ (2)\n$\\sum_{v \\in V} Y_{sv} = 1$ (3)\n$\\sum_{(u,v) \\in E} Y_{uv} = \\alpha_v \\quad \\text{for} \\quad v \\in S'$ (4)\n$\\sum_{(u,v) \\in \\delta^-(v)} Y_{uv} = \\sum_{(v,u) \\in \\delta^+(v)} Y_{vu} \\quad \\text{for} \\quad v \\in S \\setminus \\{s\\}$ (5)\n$x_u \\in X_u \\quad \\text{for all} \\quad u \\in V$ (6)\n$Y_{uv} = \\{0, 1\\} \\quad \\text{for all} \\quad (u, v) \\in E$ (7)\n$\\alpha_v = \\{0, 1\\} \\quad \\text{for all} \\quad v \\in S'$ (8)\nConstraints (2) state that exactly one vertex in $S'$ must be chosen as a terminal. Constraints (3)-(5) state the standard flow constraints for a path from $s$ to a terminal in $S'$. Constraint (6) states that for any vertex $u \\in V$, its corresponding point must belong to $X_u$. The main challenge in solving the above formulation arises from the multiplication of the travel costs and the binary variables in (1). To address this challenge, we follow the approach in [4] and reformulate SPP*-GCS as a Mixed Integer Convex Program (MICP) in the next subsection."}, {"title": "B. MICP for SPP*-GCS", "content": "In this paper, as we are only dealing with travel costs derived from Euclidean distances, the objective in (1) can be re-written as:\n$C_{\\text{opt}}^{S,S'} := \\min \\sum_{(u,v) \\in E} || x_u - x_v ||_2 Y_{uv} + \\sum_{v \\in S'} \\alpha_v h(v)$\n$=\\min \\sum_{(u,v) \\in E} || x_u Y_{uv} - x_v Y_{uv} ||_2 + \\sum_{v \\in S'} \\alpha_v h(v)$.\nIn [4], the bi-linear terms $x_u Y_{uv}$ and $x_v Y_{uv}$ in the objective above are replaced with new variables, and the constraints in (5),(6) are transformed to form a MICP. Before we present the MICP corresponding to SPP*-GCS, we first need to define the perspective of a set. The perspective of a compact, convex set $X \\subset \\mathbb{R}^n$ is defined as $X' := \\{(x, x) : x \\ge 0, x \\in xX\\}$.\nNow, let $x_u Y_{uv} = z_{uv}$ and $x_v Y_{uv} = z'_{uv}$ for all $(u,v) \\in E$. By following the same procedure outlined in [4], we derive a Mixed-Integer Convex Program (MICP) for the SPP*-GCS as follows:\n$\\min \\sum_{(u,v) \\in E} || z_{uv} - z'_{uv} ||_2 + \\sum_{v \\in S'} \\alpha_v h(v)$ (9)\n$\\sum_{v \\in S'} \\alpha_v = 1$ (10)\n$\\sum_{v \\in V} Y_{sv} = 1$ (11)\n$\\sum_{(u,v) \\in E} Y_{uv} = \\alpha_v \\quad \\text{for} \\quad v \\in S'$ (12)\n$\\sum_{(u,v) \\in \\delta^-(v)} (z_{uv}, Y_{uv}) = \\sum_{(v,u) \\in \\delta^+(v)} (z'_{vu}, Y_{vu}) \\quad \\text{for} \\quad v \\in S \\setminus \\{s\\}$ (13)\n$(z_{uv}, Y_{uv}) \\in X_u' \\quad \\text{for all} \\quad u \\in V, (u, v) \\in E$ (14)\n$(z'_{uv}, Y_{uv}) \\in X_v' \\quad \\text{for all} \\quad v \\in V, (u, v) \\in E$ (15)\n$Y_{uv} = \\{0, 1\\} \\quad \\text{for all} \\quad (u, v) \\in E$ (16)\n$\\alpha_v = \\{0, 1\\} \\quad \\text{for all} \\quad v \\in S'$ (17)\nLemma 2. The MICP formulation in (9)-(17) for the SPP*-GCS has an optimal value equal to $C_{\\text{opt}}(S, S')$.\nProof: This result follows the same proof as Theorem 5.7 in [4].\nWe now arrive at the relaxation used in our algorithms:\n$\\min \\sum_{(u,v) \\in E} || z_{uv} - z'_{uv} ||_2 + \\sum_{v \\in S'} \\alpha_v h(v)$\nsubject to the constraints in (10)-(15) and,\n$0 \\le Y_{uv} \\le 1 \\quad \\text{for all} \\quad (u, v) \\in E$,\n$0 < \\alpha_v < 1 \\quad \\text{for all} \\quad v \\in S'$. (18)\nRemark 2. In the special case when the convex sets reduce to singletons, the relaxation of SPP*-GCS in (18) can be re-"}, {"title": "IV. A*-GCS", "content": "A*-GCS (Algorithm 1) starts with the input set $S := S_{\\text{init}}$ and iteratively grows $S$ until further growth is not possible or is not beneficial. This set $S$ during any iteration of A*-GCS will always be a cut-set. A*-GCS keeps track of the growth of $S$ in two phases (Phase 1 and Phase 2). The phases are determined based on the presence of the destination in the neighborhood of $S$.\nIn Phase 1, $d$ is not a member of the neighborhood of $S$ (line 16 of Algorithm 1). Therefore, in this phase, we can find lower bounds by solving the relaxation (line 18 of Algorithm 1), but we cannot convert a relaxed solution to a feasible solution for SPP-GCS. Additionally, we add a vertex $v \\in S'$ to $S$ if any edge $(u, v)$ leaving $S$ has $Y_{uv} > 0$ (line 20 of Algorithm 1, Algorithm 3).\nIn Phase 2, $d$ is part of the neighborhood of $S$, and therefore, it is possible to use the relaxation to find a lower bound and a corresponding feasible solution for SPP-GCS (lines 23-24, 33-34 of Algorithm 1). During this phase, we expand $S$ until one of the following two termination conditions is met: 1) all the vertices in $V \\setminus \\{d\\}$ have already been added to $S$, or, effectively in this condition, $S$ cannot grow any further (line 25 of Algorithm 1), 2) the relaxation cost of traveling through any vertex in $S' := N_S \\setminus \\{d\\}$ becomes greater than or equal to the relaxation cost of traveling directly to $d$, or, effectively in this condition, growing $S$ further may not lead to better lower bounds (line 29 of Algorithm 1). Also, the subroutine for expanding $S$ in Phase 2 (line 32 of Algorithm 1) mirrors that of Phase 1.\nThe following are the key features of A*-GCS:\n*   The initial set $S_{\\text{init}}$ can be any subset of $V$ as long as it is a cut-set. Specifically, $S_{\\text{init}}$ can either consist solely of the origin (similar to how we initiate A* for the SPP) or be generated by an algorithm. In this paper, we also consider $S_{\\text{init}}$ generated by A* as follows: Suppose $S_{A^*}$ is the closed set (which also includes $d$, the last vertex added to $S_{A^*}$) found by A* when implemented on the centroids of all the convex sets associated with the vertices in $V$; let $S_{A^*}' := S_{A^*} \\setminus d$ and then assign $S_{\\text{init}} := S_{A^*}'$.\n*   A*-GCS can also be preemptively stopped at the end of any iteration. A*-GCS will always produce a lower bound at the end of any iteration in any phase and may produce a feasible solution during an iteration if $S$ is processed in Phase 2.\n*   The algorithms for updating the set (Algorithm 3) and the feasible solution (Algorithm 4) based on the fractional values of the relaxed solutions are user-modifiable. Therefore, different variants of A*-GCS can be developed tailored to specific applications.\nRemark 3. A*-GCS initiated with $S := \\{s\\}$ mimics A* in the special case when each of the convex sets is a singleton."}, {"title": "V. THEORETICAL RESULTS", "content": "We will first demonstrate the termination of A*-GCS in a finite number of iterations and subsequently establish the validity of the bounds it generates. Without loss of generality, we assume there is at least one path from $s$ to $d$ in the input graph $G = (V, E)$. This assumption helps avoid certain trivial corner cases that may arise when updating the subsets (lines 20, 32 of Algorithm 1) or the bounds (lines 19, 28 of Algorithm 1).\nLemma 3. A*-GCS will terminate after completing at most $|V| - 1$ iterations of both Phase 1 and Phase 2.\nProof: If the algorithm enters Phase 1, each iteration of the phase must add at least one vertex from $N_S$ to $S$ since there is at least one edge $(u, v)$ leaving $S$ such that $Y_{uv} > 0$. If the algorithm enters Phase 2 and the termination condition in 29 is not met, $R_{\\text{opt}}(S, S')$ is some finite value, and therefore, there is at least one edge $(u, v)$ leaving $S$ and entering $S'$ such that $Y_{uv} > 0$. In both the phases, at most $|V| - 1$ vertices can be added to $S$ before at least one of the termination conditions (lines 25, 29 of Algorithm 1) become valid. Hence proved.\nLemma 4. Consider any subset $S \\subset V$ such that $s \\in S$ and $d \\notin S$. Let the path in an optimal solution to the SPP-GCS be denoted as $P^* := (v_1 = s, v_2, \\dots, v_k = d)$ and let the optimal points in the corresponding convex sets be denoted as $x_{v_i}, i = 1, \\dots, k$. For some $p \\in \\{2, \\dots, k\\}$, let $v_p$ be such that $v_i \\in S$ for $i = 1, \\dots, p-1$ and $v_p \\in N_S$. Let $S'$ be any subset of $N_S$ that contains $v_p$. Then, the optimal cost of the SPP-GCS is at least equal to the optimal relaxation cost of SPP*-GCS defined on $S$ and $S'$, i.e., $C_{\\text{opt}}(s, d) \\ge R_{\\text{opt}}(S, S')$.\nProof: Now, the cost of the given optimal solution to SPP-GCS is:"}, {"title": "VI. NUMERICAL RESULTS", "content": "Set up: We initially test our algorithms on six 2D maps generated from mazes and axis-aligned bars (Fig. 3). To generate a GCS corresponding to a maze, we first partition its free space into unit squares and consider the obstacle-free sides shared by any two adjacent squares as vertices in our GCS. The convex sets here are the line segments corresponding to the shared sides. Two vertices (or shared sides) in a maze-GCS are connected by an edge if the shared sides belong to the same unit square. An example of a GCS corresponding to a maze is shown in Fig. 3a. In the case of an instance with randomly generated, axis-aligned bars, we partition all the bars into unit squares and connect any two unit squares with an edge if they both belong to the same bar. Here, the convex sets are square regions, and an example of a GCS corresponding to a map with bars is shown in Fig. 3b. The size of the GCS generated for each of the maps is provided in Table I. The destination for each instance is always chosen to be the centroid of the top-rightmost square in the instance.\nWe will compare the performance of the lower bounds generated by A*-GCS with the lower bound generated by the baseline algorithm that solves the convex relaxation of SPP-GCS on the entire graph. The upper bound for both algorithms is the length of the feasible solution generated by the two-step heuristic. Note that the size of the cut-set during any iteration of A*-GCS determines the sizes of the convex relaxations we will solve. Therefore, we will keep track of the sizes of the cut-sets in addition to the run times of the algorithms. Also, the baseline is equivalent to implementing (18) with $S := V \\setminus \\{d\\}$; therefore, the size of the cut-set corresponding to the baseline is $|V| - 1$. All the algorithms were implemented using the Julia programming language [14] and run on an Intel Haswell 2.6 GHz, 32 GB, 20-core machine. Gurobi [9] was used to solve all the convex relaxations.\nHeuristics for generating underestimates: We designed two heuristics to generate underestimates for A*-GCS. Given a set, the first heuristic ($h_1$) simply computes the shortest Euclidean distance between any point in the set and the destination, ignoring all other vertices/edges in the graph. $h_1$ is very fast and requires negligible computation time; it is by default present in A*-GCS and is already part of all the run times reported in the results section. While $h_1$ produces consistent underestimates, its bounds may not be strong.\nOur second heuristic ($h_2$), referred to as the expand and freeze heuristic, computes underestimates of the optimum through an iterative process. It starts from the destination and proceeds in the reverse direction, adding a subset of vertices $U$ in each iteration to the set containing the destination while"}, {"title": "VII. CONCLUSIONS AND FUTURE WORK", "content": "In this paper, we show how to combine the existing convex-programming based approach with heuristic information to obtain near-optimal solutions for SPP-GCS. For Euclidean travel costs, we demonstrate that finding a feasible solution first using A* and then solving a convex relaxation on the subset of vertices informed by A* can reduce the size of the problems solved and computation times. There are several research directions for this work. One useful direction is to develop fast and consistent heuristics that can provide good underestimates for the SPP-GCS*. As mentioned in Remark 5, it would be useful to further understand the relationship between the properties of the underestimates (admissibility, consistency) and the bounds generated by A*-GCS. For large graphs, there are differential and compressed differential heuristics [18], [19] available for the SPP. Similar heuristic development for SPP-GCS can also be advantageous. A*-GCS can be considered as a uni-directional search method where the sets grow from the origin only in one direction"}, {"title": "VIII. APPENDIX", "content": "A. Special case of SPP-GCS\nAssume each of the convex sets associated with the vertices in $V$ is a singleton. Let the cost of traveling from $u \\in V$ to $v \\in V$ be denoted as $\\text{cost}_{uv} \\in \\mathbb{R}^+$. Let the underestimates denoted"}]}