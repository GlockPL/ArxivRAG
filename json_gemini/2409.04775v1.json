{"title": "Large Language Models, Graphs, and Taxonomy: A Path to Efficient Task Planning", "authors": ["Rodrigo P\u00e9rez-Dattari", "Zhaoting Li", "Robert Babu\u0161ka", "Jens Kober", "Cosimo Della Santina"], "abstract": "Abstract\u2014Planning methods struggle with computational intractability in solving task-level problems in large-scale environments. This work explores leveraging the commonsense knowledge encoded in LLMs to empower planning techniques to deal with these complex scenarios. We achieve this by efficiently using LLMs to prune irrelevant components from the planning problem's state space, substantially simplifying its complexity. We demonstrate the efficacy of this system through extensive experiments within a household simulation environment, alongside real-world validation using a 7-DoF manipulator.", "sections": [{"title": "I. INTRODUCTION", "content": "A major challenge in task planning for robotics is extending current approaches to large-scale, real-world problems. Planning methods that rely on search strategies, e.g., Monte Carlo Tree Search, become increasingly intractable as the number of objects robots can interact with increases [?]. Similarly, recent approaches using Large Language Models (LLMs) for planning [?], [?] also face scaling limitations. When problems are too large, it might not be feasible to feed all the information into the LLM due to its limited context window size. Furthermore, these methods become more expensive to use with an increasing number of characters in their context window, making it desirable to minimize its size. Additionally, the more complex a problem is, the more challenging it becomes to ground the LLM actions. Hence, we introduce a methodology for reducing the state-action space of a planning problem as a function of a task objective. This reduction is achieved by merging specific environment knowledge, represented through taxonomy graph states, with the commonsense knowledge present in LLMs. As a result, the state-action space of a problem can be dramatically reduced, making problems substantially more practical to solve by either search-based methods or LLMs. We validate this approach both in a simulator and with a real robot."}, {"title": "II. PRELIMINARIES", "content": ""}, {"title": "A. Graph-based State Representation", "content": "As the name suggests, a graph-based state representation represents the state of the environment via a graph. A graph is a tuple $S = (O, R)$ that models relationships R between objects O. Objects, known as the nodes or vertices of the graph, represent the entities in our environment, such as the kitchen table, a robot, or the bedroom. The relationships, known as the edges of the graph, between the objects correspond to physical relationships, such as robot in the bedroom or banana is being grabbed by the robot. Given a set of classes C and attributes H, each object has the form $O_i = (c_i, h_i)$, where $c_i \\in C$ is the class of the object, e.g., a microwave, and $h_i \\in H$ is a vector of attributes that provide information about the intrinsic state of the object, e.g., on/off or open/closed. As a result, we have $O = (o_1,..., o_m)$, with $m \\in N$. Moreover, given a set of possible relationships between objects R, every existing one is defined as $r_i = (O_j, O_k, k_i)$, with $k_i \\in R$, where $k_i$ represents relationships such us grabbed or inside. Hence, we get $R = (r_1,...,r_l)$, with $l\\in N$."}, {"title": "B. Problem Formulation", "content": "In task planning problems involving high-dimensional state-action spaces, both planning-based and LLM-based policies encounter practical limitations. Consequently, given an initial environment graph So and a set of goal states G, our objective is to reduce the dimensionality of the state-action space, rendering the problem solvable. Specifically, we aim to derive a subgraph $S_0 = (O, R_0) \\subseteq S_0$, minimizing the number of objects $|O|$ in the environment\u00b9, while maintaining all necessary objects $O_g \\subseteq O$ to achieve the task goal. Importantly, the set $O_g$ depends not only on G but also on the initial object relationships $R_0$. For example, consider the task of placing an apple on a table, with the apple inside a closed fridge. Although the fridge's state is irrelevant to G, it is imperative in $O_g$, as the task requires interacting with it. Thus, $O_g$ is influenced by the initial graph's objects and relationships.\nWe define the problem as follows:\n$\\begin{aligned} \nO &= \\text{arg} \\min_{\\Theta \\in O} ||\\\\\ns.t. O_g \\subseteq O.2\n\\end{aligned}$ Notably, addressing this problem significantly reduces the number of edges at any time step $|R_+|$, as only relationships involving objects in $\\overline{O}$ are relevant in $S_t$."}, {"title": "III. METHODOLOGY", "content": "We aim to address planning problems in large state-action spaces where high dimensionality renders current approaches impractical. To achieve this, we exploit the fact that, commonly, these problems can be solved using significantly lower dimensional state-action spaces. Therefore, given a task goal, we aim to identify this lower-dimensional space where finding a policy becomes manageable."}, {"title": "A. Taxonomy Graph States", "content": "Given an initial graph state of an environment So and a set of goal states G, our objective is to determine a subgraph So. To obtain So, we propose to feed an LLM with the graph's object classes $c_i$ and G (represented as g) and request it to select the most relevant ones. Nevertheless, our"}, {"title": "B. A Knowledge-based Approach for Minimal Graph Selection", "content": "We combine three key ingredients to solve the problem outlined in Eq. (1): knowledge of problem structure and taxonomy (as represented in taxonomy graph states), and commonsense knowledge (as provided by LLMs). To achieve this, we introduce a 2-step method.\n1) Step 1: Taxonomy-based Object Selection: First, based on a taxonomy of the environment and a task objective, an LLM selects the categories, i.e., taxonomy nodes, most relevant to the task. Since the categories are hierarchical, the LLM initially receives the higher-level categories and identifies the most pertinent ones according to the task objective. Then, by identifying the edges of these selected categories, the algorithm descends one level in the hierarchy. The information is once again fed into the LLM to select the most relevant lower-level taxonomy nodes or objects. This process repeats until further descent in the hierarchy is impossible, leaving only object nodes. We denote these selected objects as $O_T$.\n2) Step 2: Relationship-based Object Selection: In the second step, based on the relationships represented in So between objects in the environment, the neighborhoods of those selected in Step 1 are explored. Initially, all objects sharing edges with objects in $O_T$, along with the edges, are fed to the LLM. Then, according to the task objective and the relationships between objects, the LLM is requested to select those relevant to solving the task. For example, consider a scenario where the objective is to place a banana on the kitchen table. From this objective, we expect the LLM"}, {"title": "IV. PROBLEM FORMULATION", "content": "Given an initial environment graph So and a set of goal states G, our objective is to reduce the dimensionality of the state-action space, rendering the problem solvable. Specifically, we aim to derive a subgraph $S_0 = (O_o, R_o) \\subseteq S_0$, minimizing the number of objects $|O|$ in the environment, while maintaining all necessary objects $O_g$ to achieve the task goal. Importantly, the set $O_g$ depends not only on G but also on the initial object relationships $R_o$. For example, consider the task of placing an apple on a table, with the apple initially inside a closed fridge. Although the fridge's state is irrelevant to G, it is imperative in $O_g$, as the task requires interacting with it. Thus, $O_g$ is influenced by the initial graph's objects and relationships.\nWe define the problem as follows:\n$\\begin{aligned}\nO_o = \\text{arg} \\min_{O \\subseteq O} || \\quad s.t. O_g \\subseteq O.1\n\\end{aligned}$\nwhere the subscript in $O_o$ can be dropped, i.e., O, as the number of objects is invariant over time. Notably, addressing this problem significantly reduces the number of edges at any time step $|R_t|$, as only relationships involving objects in $\\overline{O}$ are relevant."}, {"title": "V. METHOD", "content": "We combine two ingredients to solve the problem outlined in (1): knowledge of the environment's structure (as represented in graph states), and commonsense knowledge (as provided by pre-trained LLMs). To achieve this, we follow two steps, exemplified in Fig. 2."}, {"title": "A. Step 1: Environment-agnostic Object Selection", "content": "First, we propose to obtain a subset of objects $\\overline{O}_T$ only as a function of the initial set of objects present in the environment O and the task objective G, disregarding any attribute or relationships the objects have. To achieve this, we query an LLM to select from O the objects that are potentially relevant for solving the task. As a result, the LLM can be represented as the function $LLM_T : (O, G) \\rightarrow \\overline{O}$.\nUnfortunately, as discussed previously, in large-scale problems, it is impractical, expensive or unfeasible to directly feed the complete set of objects to the LLM. To address this, we incorporate a taxonomy of object classes that provides a collapsed representation of O with which the LLM can interact, efficiently exploring it to gain access to the most promising groups of objects present in O.\n1) Taxonomy Graph States: The taxonomy can be represented as a graph and, therefore, can be seen as an extension to the previously introduced graph state S. Generally, taxonomies categorize items hierarchically into groups or types. Incorporating a taxonomy into our graph allows us to collapse multiple classes into broader concepts. Hence, we extend the graph S with a collection of taxonomy nodes C, which group together object classes and/or categories represented in other taxonomy nodes lower in the hierarchy. For instance, an object of the class keyboard can be grouped into the category computing, represented by a taxonomy node. Simultaneously, the category computing can be grouped into"}, {"title": "B. Step 2: Relationship-based Object Selection", "content": "Up to this point, the introduced method selects a subset of relevant objects without considering their interactions within the environment (Step 1). Next, we describe how to incorporate interaction information into the selection process (Step 2), which can often reveal additional relevant objects to consider.\nStep 2 grounds the LLM predictions of Step 1 on object interactions that are specific to the environment at hand. For example, consider a scenario where the objective is to place a banana on the kitchen table. From this objective, we expect the LLM to select the objects banana and kitchen table in Step 1. However, by examining the graph neighborhood of the kitchen table node, it can be observed that every banana has an edge to a plastic container, as they are stored inside it. Therefore, the container should also be selected as a relevant object, as it must be incorporated into the planning problem to fulfill the task.\nAs a result, in Step 2, based on the relationships present in the initial graph state So, the neighborhoods of the nodes selected in Step 1, i.e., $\\overline{O}_T$, are explored. We introduce the function that, given So and $\\overline{O}_T$, outputs the connected subgraph $S_E = (O, R_E)$. The graph $S_E$ is composed of the objects in O sharing edges with $\\overline{O}_T$, referred to as the connected objects $O_c$, and the shared edges, $R_E$. Hence, $\\Phi : (S_0, \\overline{O}_T) \\rightarrow S_E$.\nThe subgraph $S_E$, the objects selected in Step 1, $\\overline{O}_T$, and the task objective G, are fed to an LLM that is queried to select from the connected objects those relevant for achieving the objective based on their relationships $R_E$ with $O_T$. We represent this process with the function\n$LLM_R^i : (\\overline{O}_T \\cup O_R^{i-1}, S_E, G) \\rightarrow O_R^i,$\nwhere $O_R^i$ is new set of objects selected as relevant.\n1) Iterative selection process: Importantly, the introduced selection process should be repeated through multiple iterations, as the newly selected objects might also have relationships that need to be accounted for. For example, the plastic container might be related to the fridge because it is stored inside it. Thus, the fridge should also be incorporated into our problem. To determine the times $LLM_R$ must be employed, we can iterate until the LLM judges that none of the newly connected objects are relevant for solving the problem or when a maximum number of iterations I is reached.\nFollowing our previous notation, and by incorporating subindices i, which denote the relationship-based selection iteration, the previously defined LLM function can be modified to\n$LLM_R^i: (\\overline{O}_T \\cup O_R^{i-1}, S_E, G) \\rightarrow O_R^i.$\nHere, $\\overline{O}_T \\cup O_R^{i-1} = \\overline{O}_T \\cup \\bigcup_{j=0}^{i-1} O_R^j$, where $\\overline{O}_T \\cup O_R^0 = \\overline{O}_T$, and $S_E = \\Phi(S_0, \\overline{O}_T \\cup O_R^{i-1})$.\nFinally, $O_R$ is defined as the collection of the selected objects from each iteration $O_R^i$. As a result, we get that the set of selected objects considering steps 1 and 2 corresponds to $\\overline{O} = \\overline{O}_T \\cup O_R$. The complete process of obtaining $O_R$ is detailed in Algorithm 2."}, {"title": "C. Integrating Taxonomy Graph States with LLMs", "content": "So far, we have introduced functions based on LLMs that use information encoded in a graph to condition their output. Consequently, since LLMs expect natural language as input, the information stored in the graph must be presented in a natural language form.\nFor the function $LLM_T$, it is only necessary to generate a string that lists the categories present at a given hierarchical level. For example, the following string could be included in the context window of the LLM: \"Categories: electronics, lighting, appliances, . \". In the case of the lowest level, where object classes replace categories, the string could be: \"Objects: apple, chair, toilet, ... \".\nFor the relationship-based object step selection via $LLM_R$, a similar structure is employed. Nevertheless, each component of the list consists of two objects and their corresponding relationship. For instance, \u201cRelationships between"}, {"title": "D. Planning with State Graphs", "content": "Graph-based state representations provide an intuitive, object-centric abstraction of an environment where actions represent operations on specific objects within this environment. More precisely, actions either change objects' attributes hi and/or modify relationships between objects $r_i$. For instance, when a robot takes the action $a_t = close(microwave)$, it changes the microwave's attribute open to closed. Furthermore, the action $a_t = grab(apple)$, when applied to an apple on a table, creates a new edge between the robot and the apple and removes the relationship the apple had with the table. This approach provides a compact way of representing transitions in the environment, where, by defining $S_t$ as the graph at a given time step, given the effects an action has on its attributes and edges, we obtain the transition function $S_{t+1} = f(S_t,a_t)$.\nMoreover, attributes and edges are integral in constructing the affordance function $A(S_t)$, as they are employed to define preconditions required for an action to be applicable. Consider the action $a_t = close(microwave)$: for this to be applicable, the microwave must have the attribute is open, and the relationship near must exist between the robot and the microwave, indicating that the microwave is within reach of the robot.\nAs a result, by defining the actions in A along with their respective graph-based preconditions and effects, task planning problems can be addressed using graphs [15], [16]. By employing the functions $f(S_t, a_t)$ and $A(S_t, a_t)$, given So and G, a policy can be derived by searching the state-action space.\nIn this work, we employ two types of policies. The first type follows traditional planning approaches, while the second is based on LLMs. These are described below.\n1) Search-based Policies: These policies are derived from a solution to a search problem, given an initial condition So and a set of goal states G, e.g., Fast Downward [3] or MCTS [17]. This solution is a plan $ \\tilde{\\pi} = (a_0,..., a_{n-1})$ leading to a goal state, that is, $f(a_{n-1}, S_{n-1}) = S_n \\in G$. The plan is formulated by utilizing the known functions $f(S_t, a_t)$ and $A(S_t)$ to navigate the state-action space until a goal state $S_n \\in G$ is reached. In the context of robotics, the plan's initial condition can be estimated from the current state of the environment. However, the set G must be specified by some entity, e.g., a human. In practice, this is achieved by specifying desired Boolean conditions, for example, on(banana, kitchen table)=True and closed(microwave)=True. As a result, G would include every state fulfilling these conditions.\n2) LLM-based Policies: Multiple policies based on LLMs have been introduced [7]. In this work, we employ an approach consisting of three parts: a pre-trained LLM, context, and the affordance function $A(S_t)$. The pre-trained model"}, {"title": "VI. EXPERIMENTS", "content": "We empirically validated our method in three scenarios. Firstly, we studied the state-space reduction performance of our method. These experiments evaluate the main contribution of our work, which involves selecting only the necessary objects from an environment before executing planning algorithms. Nevertheless, the end goal of the work is to achieve better performance at the task planning level. Therefore, we also compared the performance of different planning methods, including both classical planning and LLM-based approaches, when the state space is reduced. Lastly, we validated the complete framework on a real-world robotic platform using a 7-DoF manipulator."}, {"title": "A. State-space size reduction", "content": "To study the state-space size reduction performance of our method, we used VirtualHome [10] (see Fig. 3). VirtualHome is a simulator that allows controlling agents in a household environment by sending them high-level commands, such as walk to kitchen or open the fridge. The agent is equipped with lower-level action primitives that enable it to execute these high-level commands. Consequently, it is an ideal setting for studying task-planning problems. We evaluated our method in six different household environments with ~ 280 objects each. Furthermore, to analyze the robustness of our method, we evaluated it for planning objectives that were increasingly difficult to achieve. To increase difficulty, we composed multiple single-objective tasks into single multi-objective tasks. For example, one single-objective task can be put a beer on a table, and a multi-objective task composed of two subtasks would be put one beer on the kitchen table and put one chicken inside the microwave."}, {"title": "B. Planning", "content": "Given that the objective of reducing the state space size is to simplify the planning problem, in Table II, we provide the performance of LLM-based planners and a search-based approach, namely, Monte Carlo Tree Search (MCTS) [17], in reduced-state-space settings. The employed LLM-based planners operate on a per-time-step basis, as explained in Section V-D. Every planner was executed over the reduced states obtained using GPT-40.\n1) Planning performance with state space reduction: From Table II, we observe that GPT-40 outperforms GPT-3.5 and MCTS in planning, achieving a 0.73 success rate even in the most challenging scenarios. The performance of GPT-3.5 is surprisingly low; we noted that this occurred because the model could not properly reason from the provided context, thereby selecting actions that did not bring the agent closer to the goal. Lastly, MCTS obtained the expected performance: as the problem size increases, it becomes increasingly intractable. It is also worth noting that the number of steps"}, {"title": "C. Real-world validation", "content": "We conducted a real-world validation of the proposed method, utilizing the best-performing models from the previous subsections, namely GPT-40, for both state space selection and planning. The objective of this experiment is to demonstrate the applicability of the proposed approach to real-world problems and its potential, given an extensive library of motion primitives. Fig. 5 presents a sequence of images depicting the task being executed on the robotic setup. It should be noted that, for practical reasons, the real setup did not include hundreds of objects; instead, the state"}, {"title": "VII. CONCLUSIONS", "content": "In this work, we present a method to reduce the state space in large-scale task planning by combining LLMs with state graphs and object taxonomies. We extensively evaluated the method using the VirtualHome simulator, performing tasks that would have been unfeasible with both search-based and LLM-based planners. With a reduced state space, LLM planners handled planning problems more cost-effectively, and GPT-40 significantly outperformed GPT-3.5, suggesting further improvements with model evolution. MCTS, a classical planner, also benefited by being able to solve an increased number of problems after reducing the state space size. We also validated our method on a real-world robotic platform, proving its practical use."}]}