{"title": "Windowed MAPF with Completeness Guarantees", "authors": ["Rishi Veerapaneni", "Muhammad Suhail Saleem", "Jiaoyang Li", "Maxim Likhachev"], "abstract": "Traditional multi-agent path finding (MAPF) methods try to compute entire start-goal paths which are collision free. However, computing an entire path can take too long for MAPF systems where agents need to replan fast. Methods that address this typically employ a \"windowed\" approach and only try to find collision free paths for a small windowed timestep horizon. This adaptation comes at the cost of incompleteness; all current windowed approaches can become stuck in deadlock or livelock. Our main contribution is to introduce our framework, WinC-MAPF, for Windowed MAPF that enables completeness. Our framework uses heuristic update insights from single-agent real-time heuristic search algorithms as well as agent independence ideas from MAPF algorithms. We also develop Single-Step CBS (SS-CBS), an instantiation of this framework using a novel modification to CBS. We show how SS-CBS, which only plans a single step and updates heuristics, can effectively solve tough scenarios where existing windowed approaches fail.", "sections": [{"title": "1 Introduction", "content": "A core problem for multi-agent systems is to figure out how agents should move from their current location to their goal location. Without careful consideration, agents can collide, get stuck in deadlock, or take inefficient paths which take longer to traverse. This Multi-Agent Path Finding (MAPF) problem is particularly tough in congestion or when the number of agents becomes very large (e.g. 100s). Initially, most MAPF methods attempted to find entire paths for each agent from their start to their goal. These solvers could take tens of seconds to even minutes to find a collision-free solution. In practice, this can require agents to idle during the planning phase and only execute once the solution is found. Real-world practitioners and systems aim to avoid having agents idle unnecessarily during long planning phases. Therefore instead of finding an entire collision-free path, newer methods took existing full-horizon MAPF solvers and modified them to only reason about collisions within a limited horizon. Concretely, these methods typically define a fixed time window W and plan paths for each agent to the goal such that the first W timesteps account for inter-agent coordination and avoid collisions. This window W is typically much shorter than the entire solution path, e.g. W = 5 is common when the entire solution path spans 50 to 500 timesteps. As a result, windowed methods are significantly faster than those that compute the entire path. A key issue with these windowed approaches is that their myopic planning results in deadlock or livelock if their window is too small. More broadly, all existing windowed MAPF solvers regardless of window size lack theoretical completeness and several windowed works have explicitly cited deadlock as a key issue in their experiments (Li et al. 2020; Okumura et al. 2022; Jiang et al. 2024). Our first main contribution is the introduction of the Windowed Complete MAPF framework, WinC-MAPF, designed to create Windowed MAPF solvers that guarantee completeness. WinC-MAPF is a general framework that leverages concepts from single-agent heuristic search and the semi-independent structure of MAPF. First, we view Windowed MAPF in its joint-configuration and show how we can apply real-time heuristic updates on the joint-configuration to enable completeness. However, due to the large joint state space in a MAPF problem, naive heuristic"}, {"title": "2 Related Work", "content": "2.1 Problem Formulation\nMulti-Agent Path Finding (MAPF) is the problem of finding collision-free paths for a group of N agents $i = 1, ..., N$, that takes each agent from its start location $s_i^{start}$ to its goal location $s_i^{goal}$. In traditional 2D MAPF, the environment is discretized into grid cells, and time is broken down into discrete timesteps. Agents are allowed to move in any cardinal direction or wait in the same cell. A valid solution is a set of agent paths $\\Pi = {\\pi_1,...,\\pi_N}$ where $\\pi_i[0] = s_i^{start}$, $\\pi_i[T_i] = s_i^{goal}$ where $T_i$ is the maximum timestep of the path for agent i. Critically, agents must avoid vertex collisions (when $\\pi_i[t] = \\pi_{j \\neq i}[t]$) and edge collisions (when $\\pi_i[t] = \\pi_j [t+1] \\land \\pi_i[t + 1] = \\pi_j[t]$) for all t timesteps. The typical objective in optimal MAPF is to find a solution II that minimizes $|\\Pi| = \\sum_{i=1}^N |\\pi_i| = \\sum_{i=1}^N \\sum_{t=0}^{T_i-1} c(s_i^t, s_i^{t+1})$.\nWindowed MAPF Planning a set of full horizon collision-free paths can take on the order of 10s of seconds, which is too slow for some applications. For instance, a recent MAPF competition, League of Robot Runners (Chan et al. 2024), required planning for hundreds of agents within 1 second. Therefore, instead of planning full horizon collision-free paths, several methods (discussed in the next section) only resolve collisions for a fixed windowed horizon W. As a result, instead of planning full-horizon collision-free paths, several methods (discussed in the next section) focus on resolving collisions only within a fixed windowed horizon W. Concretely, instead of reasoning about collisions for all t, these methods only reason about collisions for t < W. Thus after the first W timesteps, the remaining path $\\pi_i[W]...\\pi_i[T_i]$ will simply be the agent's optimal path to the goal as it does not need to avoid collisions with other agents.\nMathematically then, the cost of $\\pi_i$ is $\\sum_{t=0}^{W-1} c(s_i^t, s_i^{t+1}) + h(s_i^W, s_i^{goal})$. Additionally, all performant 2D MAPF methods compute a backward dijkstra's for each agent where $h(s) = c^*(s, s_i^{goal})$. Thus instead of planning each $\\pi_i^{0:T_i}$ we can equivalently plan just the"}, {"title": "2.2 MAPF Methods", "content": "There exist many different types of heuristic search solvers for MAPF. One old approach is Prioritized Planning (Erdmann and Lozano-Perez 1987) which assigns priorities to agents and plans them sequentially with later agents avoiding earlier agents. PIBT (Okumura et al. 2022) is a recent popular method that allows agents to \u201cinherit\u201d other agents' priorities. Conflict Based Search (Sharon et al. 2015) is another popular method that decoupled the planning problem into two stages. A high-level search resolves conflicts between agents by applying constraints while a low-level search finds plans for individual agents that satisfy constraints. There are many extensions to CBS that improve the searches as well as the applied constraints (Barer et al. 2014; Li, Ruml, and Koenig 2021; Li et al. 2021). When faced with shorter planning times, methods typically simplify the planning problem to just find partial collision-free paths. Windowed Hierarchical Cooperative A* (Silver 2005) is a windowed variant of Hierarchical Cooperative A* which is essentially a prioritized planner using a backward Dijkstra's heuristic. Silver notes that this is not complete due to their use of priorities. Rolling Horizon Conflict Resolution (RHCR) applies a rolling horizon for lifelong MAPF planning and replans paths at repeated intervals (Li et al. 2020). RHCR faces deadlock and attempts to combat it by increasing the planning window but still notes that their method is incomplete. Bounded Multi-Agent A* (Sigurdson et al. 2018) proposes that each agent runs its own limited horizon real-time planner considering other agents as dynamic obstacles. However, the method acknowledges that deadlock can become a problem when agents need to coordinate with one another. Planning and Improving while Executing (Zhang et al. 2024) is a recent work that attempts to quickly generate an initial full plan using LaCAM (Okumura 2022) and then refines it during execution using LNS2 (Li et al. 2022). However, if a complete plan cannot be found, the method resorts to using the best partial path available, making it incomplete in such situations. The winning submission (Jiang et al. 2024) to the Robot Runners competition, due to the tight planning time constraint, leveraged windowed planning of PIBT with LNS2. They explicitly note deadlock in congestion is a significant challenge. To the best of our knowledge, there does not exist any windowed MAPF solver with completeness guarantees."}, {"title": "2.3 Real-Time Single Agent Search", "content": "We leverage ideas from \u201cReal-Time\" search, a single-agent heuristic search problem where due to limited time constraints the agent is required to iteratively plan and execute partial paths. Despite repeatedly planning partial paths, Real-Time search methods are designed to maintain completeness. The main innovation in single-agent real-time search literature is that the agent updates (increases) the heuristic value of encountered states. This prevents deadlock/livelock as states that are repeatedly visited have larger and larger heuristic values which encourages the search to explore other areas. A large variety of real-time algorithms such as LRTA* (Korf 1990), RTAA* (Koenig and Likhachev 2006), and LSS-LRTA* (Koenig and Sun 2009) propose to update the heuristic in different ways. The core idea is that given a current state s and a partial plan leading to a new state s', we update the heuristic value as $h(s) \\leftarrow c(s, s') + h(s')$. Thus when stuck in a local minima, the agent repeatedly visits states in the local minima and updates their heuristic values until they become too high and cause the agent to expand states outside the local minima. Most single-agent heuristic search algorithms rely on optimal planners to pick the next state to move to."}, {"title": "3 Windowed-MAPF with Guarantees", "content": "This section describes our Windowed Complete MAPF framework, WinC-MAPF, for creating windowed MAPF solvers that guarantee completeness. We leverage two key insights. Our first insight is that we can apply single-agent real-time update ideas to MAPF planning if we interpret the MAPF problem as a single-agent problem in the combined joint state space. This allows us to update the heuristics of previously seen states enabling completeness. However, just doing this is ineffective due to the large state space. To this extent, our second insight is that we can leverage MAPF's agent semi-independence to intelligently update the heuristic value of multiple states, allowing the search to fill in heuristic depressions quickly and exit local minima faster.\n3.1 Planning in Joint-State Space\nOur first observation is to leverage existing Real-Time search literature that has been solely explored in single-agent planning as mentioned in Section 2.3. We can directly leverage single-agent Real-Time search literature if we view our multi-agent problem in the joint space. We formally redefine the windowed MAPF planning problem from this joint-space perspective. Given N agents, we define a joint configuration $C_t = [s_1,...s_N]$. At every timestep, we query a high-level \u201caction-generator\u201d to return a sequence of configurations $\\Pi_{0:W} = [C^0,...C^W]$ which minimizes $|\\Pi| = \\sum_{t=0}^{W-1} c(C^t, C^{t+1}) + |\\Pi_{W:T_{max}} | = h_{BD}(C^W)$. We define the joint cost and heuristic intuitively, $c(C, C') = \\sum c(s_i, s_i')$ and $h_{BD}(C) = \\sum h(s_i)$ (BD = Backward Dijkstra). To re-iterate, the advantage of this interpretation is that we have converted our windowed MAPF problem into a standard single-agent real-time search problem. Thus given this sequence of configurations, we apply a standard Bellman Update to the heuristic of C via $h(C) \\leftarrow c(C, C^H) + h(C^H)$. Given a timestep t and configuration $C_t$, we move our agents to $C_{t+1}$, update our heuristic of $C_t$, and repeat. h(C) is initially set to $h_{BD}(C)$ and gradually increases as agents visit states. Instead of calling these changes heuristic updates, we use the term \u201cheuristic penalty\u201d to describe how the heuristic for visited states increases when we apply our update equation. This effectively \"penalizes\" those states and encourages the search to explore other states. A heuristic penalty state is a state C which has a non-zero increase from the base heuristic value, i.e. $h(C) = h_{BD}(C) + h_p(C)$"}, {"title": "3.2 Reasoning about Coupled Agents", "content": "The framework we have described so far suffers from an obvious issue; the size of the joint state-space C is very large. Consequently, escaping local minima, which in our context are agents stuck in deadlock/livelock, can be challenging. The process often requires filling in large heuristic depressions, which can lead to poor performance as the agent may remain stuck in the minimum for extended periods before finding a way out. Concretely, imagine we have the starting configuration as depicted in Figure 1 (where the goals are indicated with arrows). Note that the blue and green agents on the bottom want to swap locations. The main observation is that the orange agents and the blue/green agents are independent even though they are on the same connected graph. However, iteratively planning and computing heuristic penalties on the joint configurations as described will result in the action generator wanting to avoid the exact joint configurations penalized. Thus, the AG could request the orange agents to move, encountering new configurations without penalties, even though the underlying blue-green deadlock remains. To resolve this deadlock, the current framework requires the AG to search over all agent's locations even though we intuitively know it should focus on just the blue and green agents. Our key idea is therefore to apply the heuristic penalty to specific groups of agents instead of on the entire joint-state space. In Figure 1, this means that instead of applying h on the single state C, we can determine the specific groups of agents (e.g. blue and green) and only attribute the heuristic penalty to them. Conceptually, the idea is that if each agent i was able to move from $s_i$ to their optimal next state $s_i'$, there would be no heuristic penalty as each $h_i(s_i) = c(s_i, s_i') + h_i(s_i')$ due to the heuristic being a perfect single-agent heuristic. Thus, $h_p(C) > 0$ means there exists at least one agent i with $h_i(s_i) < c(s_i, s_i') + h_i(s_i')$ unable to move to its best location. Additionally, this agent i must be blocked by some other agent j. Thus, instead of updating the heuristic of C, we can update $C_{Gr={i,j}}$ (assuming no other agents are interacting with i, j). Our objective is, given a C, C' transition, to detect these groups of agents and apply heuristic penalties to just the group of agents rather than the entire joint-state space. Concretely, for each agent we determine which other agents it is"}, {"title": "3.3 Overall WinC-MAPF Framework", "content": "Thus, we require the AG to incorporate h(C) updates when reasoning about which actions to execute as well as detect the coupled agents for the chosen actions. We focus on optimal windowed action generators that determine the action sequence minimizing arg $\\min_{C'} c(C, C') + h(C')$. We show in our proof in the appendix that these AGs retain completeness guarantees even though they plan partial paths. Future work could show how certain non-optimal windowed AGs could still retain completeness guarantees in our framework.\nTheorem 1. Given a finite undirected search space and: (1) the initial heuristic is admissible, (2) our AG picks $C' = arg \\min c(C, C') + h(C')$ and identifies coupled agents groups, then WinC-MAPF with its grouped update equation is complete (i.e. all agents will eventually reach their goals if a solution exists)."}, {"title": "Algorithm 1: Windowed Complete MAPF Framework", "content": ""}, {"title": "4 Single-Step CBS", "content": "We want to design a windowed solver that incorporates heuristic penalties and optimally solves W = 1, i.e. finds the next best step that minimizes $c(C, C') + h(C')$. We note that in MAPF with N agents and an individual action space of size 5, naively computing this requires generating all $5^N$ possible neighboring configurations as certain configurations may have heuristic penalties. Thus we employ CBS to intelligently find the optimal single-step configuration. Since we want a windowed solver with W = 1, Single-Step CBS (SS-CBS) only considers conflicts within the first timestep. However, regular CBS does not operate in the joint configuration space of MAPF problems and instead exploits the structure of MAPF to iteratively plan agents individually. One key assumption in CBS is that it can minimize the joint $c(C, C') + h(C')$ by minimizing individual $c(s_i, s_i') + h(s_i')$ subject to constraints. Thus, incorporating HPs which work on the joint configuration of multiple coupled agents breaks this assumption and requires careful reasoning. Our main innovation lies in modifying SS-CBS to return the optimal solution given heuristic penalty updates. A minor additional modification is returning groups of conflicting agents."}, {"title": "4.1 Handling Heuristic Penalties with Constraints", "content": "Incorporating updates to h via heuristic penalties is non-trivial in CBS. A naive way to incorporate a heuristic penalty in CBS is to plan CBS normally and just add the heuristic penalty cost to CT nodes whose configurations match the penalty. However, we show that this fails to find an optimal solution. A second naive way is to incorporate the penalty in the low-level search. We show how this similarly fails. The core conceptual issue with naively incorporating heuristic penalties is that the high-level/low-level is not fully aware of the heuristic penalties until after it has planned paths, so it is unable to avoid them beforehand.\nIncorrect: Incorporating HPs in High Level The most obvious way to incorporate HPs is to add them to the CT node's heuristic if the CT node's configuration matches the penalty. This fails as the penalty is applied after the low-level planning occurs, so the low-level planner does not avoid HPs in the beginning. Incorrect: Incorporating HPs in Low Level On the flip side, we could attempt to incorporate the heuristic penalty in the low-level search. Solution: Introducing \u201cHeuristic Conflicts\u201d Our idea is thus not to incorporate the heuristic penalty immediately. Instead, when CBS encounters a joint configuration that would incur a penalty, it marks the CT node with a \u201cheuristic conflict\" without adding the penalty into the CT node's heuristic value yet. Formally, a heuristic conflict occurs when agents' positions match the positions of a HP. Resolving the heuristic conflict requires applying regular (negative) vertex constraints on each agent in the heuristic conflict which forces them to avoid the joint configuration (and thus penalty) as well as one CT node with positive vertex constraints which requires the agents to be at the penalty joint-configuration and only then incurring the HP.\nIn our example, the agents plan independently like usual and the root node has no vertex or edge conflicts. However, we detect that HP2 could apply and create the corresponding heuristic conflict. We then generate three child nodes, the first two CT nodes with negative vertex constraints and the last one with multiple positive vertex constraints. Thus given an HP with K agents, our heuristic constraint will generate K children with a single additional negative vertex constraint and one child with K additional positive vertex constraints."}, {"title": "4.2 Detecting Heuristic Agent Groups", "content": "SS-CBS should also return groups of agents that are coupled. Our main observation is that agent conflicts directly denote coupled agents. If agents are directly coupled, they must have a conflict between them that got resolved. Similarly, independent agents will not conflict with each other. There is the possibility of indirect interactions. In particular, $R_1$ could conflict with $R_2$, causing $R_2$ to replan which then conflicts with $R_3$. In this case, $R_1$'s action of $R_2$ directly caused an interaction with $R_3$, so $R_1$ and $R_3$ are indirectly coupled. Thus we can determine disjoint groups of dependent agents by first generating non-disjoint groups of agents for each resolved conflict and then merging groups with shared agents. Thus, agents in vertex, edge, or heuristic conflicts on the CT branch to the goal node will be grouped together."}, {"title": "4.3 Subtleties", "content": "A powerful technique for speeding up CBS is Enhanced CBS (Barer et al. 2014) which replaces the low-level and high-level optimal searches with bounded-suboptimal focal searches. Thus, an obvious idea to potentially improve SS-CBS is to introduce these focal searches. As stated in Section 3.3, our proof of completeness only applies to optimal AGs. Hence we set $w_{so}$ = 1 which results in only using the focal search for tie-breaking. \nWe have two additional subtleties."}, {"title": "5 Experiments", "content": "Our experiments demonstrate the empirical performance of our theoretically complete SS-CBS algorithm. We first evaluate SS-CBS on standard benchmark maps (Stern et al. 2019) and observe that SS-CBS is indeed able to outperform the windowed baselines. We then evaluate SS-CBS on high-congestion small maps and showcase SS-CBS's superiority in this regime. Our appendix contains additional analysis and results. We highlight that there do not exist any complete windowed baselines. We thus compare against windowed ECBS with window $w = {1,2,4,8,16}$. For consistency with SS-CBS, we use a suboptimality factor of $w_{so} = 1$ for ECBS and no additional CBS improvements.\n5.1 Benchmark Scenarios\nFigure 3 shows the results of SS-CBS compared to windowed ECBS without heuristic penalties. We evaluate on 4 benchmark maps with a 1 minute timeout across 25 scenarios. We additionally end windowed ECBS in failure when it repeats previously visited configurations 100 times (i.e. deadlock or livelock). The first row shows how SS-CBS (blue) has an almost strictly better performance than the windowed ECBS baselines. We first highlight that the performance of Windowed ECBS depends significantly on the map, with no single window value dominating. Windowed ECBS with $w = 1,2$ sometimes perform poorly due to their small window size which leads to deadlock/livelock, while $w = 8,16$ sometimes suffer from large runtimes. SS-CBS is able to consistently perform better than the corresponding windowed ECBS method even though SS-CBS plans only a single step. SS-CBS's performance on warehouse-10-20-2-1 shows how it performs well in scenarios that require long-term planning (as shown by Windowed ECBS requiring a larger window size to have non-trivial success rate). The second row shows the per-iteration runtime of each method, with the median runtime in solid and the maximum (longest) iteration runtime in dashed. The difference between the median and maximum highlights how congested iterations can take a significant amount of time (e.g. 10s of seconds for one optimal step) compared to typical iterations. We observe how SS-CBS's runtime is usually in line with ECBS w = 1, 2, 4 and substantially smaller than w = 8, 16. The solution cost of SS-CBS was roughly 2-8% higher than windowed ECBS. We observed that across all maps, the number of HPs created by SS-CBS grew roughly linearly along with the number of agents, but the number of HPs encountered in the CT grew exponentially."}, {"title": "5.2 Tough Congested Scenarios", "content": "The previous section shows how SS-CBS can outperform windowed ECBS in standard benchmark scenarios. We were additionally interested in SS-CBS's performance in extremely congested scenarios and thus evaluated it on small maps with high congestion from Okumura (2022). Table 1 shows the average success from 20 seeds with a timeout of 1 minute, with the number N in parenthesis denoting using the first N agents in a scenario. We see how windowed ECBS with window sizes 1, 2, 4, 8, 16 fails completely. Additionally, we compared it to EECBS (Explicit Estimation high-level search) with all CBS improvements, including bypass, symmetry reasoning, prioritized conflicts, and full horizon planning. Despite these enhancements, EECBS still struggles due to high congestion. SS-CBS can solve nearly all problems with high accuracy. It's worth emphasizing that SS-CBS uses no CBS improvements, relying solely on basic focal search with $w_{so} = 1$ and planning just a single step at a time. Despite this, it outperforms both windowed ECBS and EECBS baselines.  SS-CBS's performance demonstrates two key points. First, its high success rate on these challenging, congested maps shows how heuristic penalties can effectively guide SS-CBS to bypass complex congestion. Second, EECBS struggles due to the high number of conflicts in these scenarios. SS-CBS's success highlights how iterative single-step planning with heuristic updates can be an effective approach for resolving difficult congestion issues. All existing windowed methods produce congestion due to their myopic planning. Thus, SS-CBS improving performance with windowed planning in severe congestion is remarkable."}, {"title": "6 Conclusion and Future Work", "content": "Existing MAPF works have focused on designing methods to solve full-horizon planning. When faced with shorter deadlines, all current methods take the full horizon MAPF methods and simply reduce the planning horizon to a smaller window. This has been shown to cause deadlock/livelock/insurmountable congestion due to the limited planning horizon. We introduce WinC-MAPF, the first framework that enables theoretical completeness with windowed MAPF solvers. In particular, we show that using windowed \"Action Generator\" that incorporates heuristic penalties, identifies agent groups, and optimally minimizes $c(C, C') + h(C')$ is complete. Following this framework, we designed SS-CBS which uniquely introduces \u201cheuristic conflicts\" to successfully incorporate heuristic penalties and return the optimal next step action. We experimentally validate how our theoretically complete method actually translates to real performance benefits with SS-CBS consistently outperforming windowed ECBS across a variety of windows and maps. We are very excited about future work that can relax the limitations of our framework. First, the most useful extension is to incorporate and prove completeness for bounded suboptimal AGs within our framework. This can allow more solvers such as PIBT, MAPF-LNS2 (Li et al. 2022), W-EECBS (Veerapaneni, Kusnur, and Likhachev 2023), or even using a learnt neural network policy. Second, one obvious extension is to generalize SS-CBS to work on longer horizons.  Planning partial paths rather than full paths is a significant target that researchers need to achieve for their methods to be used in real systems. We believe the WinC-MAPF framework and SS-CBS are a significant step towards bridging this gap and enabling effective windowed MAPF solvers."}]}