{"title": "DETECTION OF LLM-GENERATED JAVA CODE USING\nDISCRETIZED NESTED BIGRAMS", "authors": ["Timothy Paek", "Chilukuri Mohan"], "abstract": "Large Language Models (LLMs) are currently used extensively to generate code by professionals\nand students, motivating the development of tools to detect LLM-generated code for applications\nsuch as academic integrity and cybersecurity. We address this authorship attribution problem as a\nbinary classification task along with feature identification and extraction. We propose new Discretized\nNested Bigram Frequency features on source code groups of various sizes. Compared to prior\nwork, improvements are obtained by representing sparse information in dense membership bins.\nExperimental evaluation demonstrated that our approach significantly outperformed a commonly\nused GPT code-detection API and baseline features, with accuracy exceeding 96% compared to 72%\nand 79% respectively in detecting GPT-rewritten Java code fragments for 976 files with GPT 3.5 and\nGPT 4 using 12 features. We also outperformed three prior works on code author identification in a\n40-author dataset. Our approach scales well to larger data sets, and we achieved 99% accuracy and\n0.999 AUC for 76,089 files and over 1,000 authors with GPT 4o using 227 features.", "sections": [{"title": "1 Introduction", "content": "Detecting the authors of textual materials is a problem known as authorship attribution, and may be addressed using\nstylometric techniques that perform quantitative analyses of authors' writing styles. In addition to analyzing works of\nliterature, the stylometric approach has been explored for the identification of authors of Python code, e.g., [Hozhabrierdi\net al., 2018].\n\nThe recent extensive use of large language models (LLMs) to generate code has raised serious concerns, especially in\nacademic environments where students claim GPT-generated code as their own. Code generated by the same LLM may\nvary stylistically between samples, due to the multiplicity of sources used for training the LLM. This motivates our\nresearch on source code authorship attribution. Applications include academic integrity concerns, software development\nprocess evaluation, and assessments of intellectual property ownership.\n\nWe propose a new approach to address this problem, splitting Java source code into code fragments before feature\nextraction, and then using binary classification to identify whether a code fragment varies substantially from other code\nfragments written by an author, so that the model can distinguish between code written by different authors in the same\nfile.\n\nThe focus of our research has been on creating features suited to this task. We have also created and tested our approach\non datasets with combinations of LLMs, formatted and non-formatted code. We assess human-authored Java code"}, {"title": "2 Background", "content": "This section summarizes related work, the stylometric approach, and the primary features used in our research."}, {"title": "2.1 Related Work", "content": "In prior work [Yang et al., 2017, Omi et al., 2021, Czibula et al., 2022, Hao et al., 2022, Al-Ahmad et al., 2023], code\nauthorship attribution has typically been addressed as a multi-class classification problem, attributing an entire source\ncode file to a single author. However, this has the following limitations:\n\n1. Files often have multiple authors, potentially resulting in model confusion.\n2. An LLM may have been used to generate only some snippets of code, which may be undetected because the rest of\nthe code was written by the claimant author(s).\n3. There is often limited data on code from an individual, resulting in unavailability of sufficient data for effective\ntraining.\n\nAdditionally, current LLM detectors are trained on both code and non-code text, resulting in inadequate performance on\ncode alone. Most utilized features are based on natural language processing, not addressing syntactic features specific\nto code, such as Abstract Syntax Tree (AST) features. Three such recent works are discussed below.\n\nOedingen et al. (2024) address GPT code detection for Python code by utilizing Term Frequency - Inverse Term\nFrequency (TF-IDF), code2Vec, and human-generated features, achieving up to 0.98 accuracy on non-formatted code\nand 0.94 accuracy on formatted code. Their work tests only for code generated by GPT 3.5 (not GPT 4 or GPT 4o)\nbased on manually provided prompts.\n\nYe et al. (2024) also follow a similar approach, rewriting both human-authored and machine code, and testing various\nsimilarity metrics, achieving up to 0.8325 and 0.8623 accuracy on APS and MBPP benchmarks for Python, respectively,\nusing GPT 3.5 to rewrite the code; they achieved 0.9082 accuracy in detecting C++ code written by GPT 3.5.\n\nXu and Sheng (2024) use masked perturbation and a fine-tuned CodeBERT model on datasets created from CodeNET\nand AIGCode programming problems in various languages, using text-davinci-003 to generate solutions to problem\ndescriptions or translate code into another language. However, this approach only achieved 0.82 AUC for detecting\nLLM-authored Java code, substantially lower than the results from our approach."}, {"title": "2.2 Stylometry Features", "content": "Stylometry involves describing authors' unique coding styles using quantifiable features such as:\n\n1. Lexical features, focusing on specific tokens in the code, e.g., keywords, identifiers, and length.\n2. syntactic features, addressing the structure of the code, e.g., n-grams and control structures.\n3. Layout features, relating to code formatting, e.g., white-space, line-breaks, and indentation.\n\nAmong these categories, all useful in distinguishing between author coding styles, syntactic features tend to provide the\nmost information specific to certain code authors [Caliskan-Islam et al., 2015]. Emphasizing syntactic features makes\nthe model more robust to layout obfuscation, e.g., when those who use LLMs (to generate code) reformat the code,\nchanging the amount of white-space."}, {"title": "3 Methods", "content": "This section describes the dataset generation process, followed by the feature extraction approach and the machine\nlearning models used."}, {"title": "3.1 Dataset Generation", "content": "To the best of our knowledge, no publicly available datasets exist for LLM-generated Java code classification. Also,\ndifferent LLMs may correspond to different writing styles, and variations in the prompts may also result in variations of\nwriting style. Hence we created two new datasets: (1) GPT Dataset, a smaller one focusing on GPT 3.5 and GPT 4\nmodels; (2) GPT GCJ Dataset, a larger one focusing on GPT 4o. We have made both datasets publicly available on\nGitHub [Paek, 2024a,b].\n\nThe following process was used to obtain the GPT Dataset:\n\n1. 666 Java source code files from 11 different authors' GitHub pages were acquired from another dataset [Yang\net al., 2017].\n2. 5 of the 11 authors' files were passed through either ChatGPT 3.5 or Bing GPT 4 in a rewriting task, using\nthe prompt: \"The messages I send you will be in Java code. I want you to rewrite all of it while maintaining\nfunctionality.\"\n3. The entire file was passed through BingGPT (4000 character limit) and ChatGPT without additional prompting;\nthe resulting code was then pasted into a new file.\n4. The resulting files were either saved without additional formatting or were formatted using VSCode's format.\n\nThis resulted in 976 files, including 666 files of original authors, 108 files rewritten using Bing GPT 4 (61 formatted, 47\nnon-formatted); and 202 files rewritten using ChatGPT 3.5 (59 formatted, 143 non-formatted).\n\nThe following process was used to obtain the GPT GCJ Dataset:\n\n1. 58,524 human-authored Java source code files from over 1,000 participants were retrieved from the 2020\nGoogle Code Jam competition.\n2. 17,565 of these files were rewritten by GPT 4o API with the prompt: \"This is java code. Rewrite it entirely\nwhile maintaining functionality.\"\n\nThis resulted in 76,089 files, including 58,524 files of original authors, and 17,565 files rewritten using GPT 4o API.\n\nBy having the LLM rewrite existing code, we attempt to ensure that the LLM code is similar to the original, to make it\ndifficult to distinguish between the classes. The rewriting task intends to simulate different potential input prompts in a\nscalable manner. The rewritten code typically has rewritten variable names and slightly different formatting while still\nachieving the same code functionality. Additionally, some rewritten code was reformatted using VSCode to emulate\nwhat may occur in real-world scenarios for the GPT Dataset.\n\nCode was broken up into chunks called code groups, whose size (number of lines) varied from 10-70, yielding different\ndatasets. For discretized features, an additional parameter, bin width, determines how many features are allocated to a\nsingle bin."}, {"title": "3.2 Feature Extraction", "content": "For non-syntactic features, we use mean line length, mean comment length, and the numbers of spaces (Whitespace),\nstatement words (e.g., \"if\", \"for\", etc.), tabs, underscores, and empty lines. These are normalized by dividing by the\nlength of the code group in characters; this captures some contextual information.\n\nThe rest of this section focuses on syntactic features. We begin by observing that in nested bigrams (NB), nodes include\nattribute information such as the names of input variables, meaning that if another node does not contain the exact\nattribute information, it will not match. Feature specificity further increases due to the increased sub-tree relationships"}, {"title": "3.3 Machine Learning Models Used", "content": "Our focus in this research has been on identifying the best features to enable identification of LLM-generated code using\nexisting ML models or algorithms, not on improving the latter. For many problems, ensembles of machine learning\nmodels have been shown to be more effective than individual models [Kondratyuk et al., 2020]. This motivates us to\nuse Random Forests [Breiman, 2001], XGBoost [Chen and Guestrin, 2016], Light Gradient Boosting Machine (LGBM)\n[Ke et al., 2017], and CatBoost [Prokhorenkova et al., 2018] ensemble approaches, whose code was imported from\nvarious publicly available sources, i.e., sklearn.ensemble, xgboost, lightgbm, and catboost.\n\nEnsemble execution is deterministic; all random states for these models were initialized to the same value (42) for\nrepeatability, with all other hyperparameters set to constant values. Experiments with other initial states showed little\ndifference. The following values were used for the parameters of these machine learning approaches:\n\n\u2022 Random Forest:\n\tn_estimators = 100\n\tcriterion = gini\n\tmin_samples_split = 2\n\tmin_samples_leaf = 1\n\u2022 XGBoost:\n\tbooster = gbtree\n\teta = 0.3\n\tmax_depth = 6\n\tsampling_method = uniform\n\tgrow_policy = depthwise"}, {"title": "4 Experimental Results", "content": "We evaluated our approach on the newly generated GPT and GPT GCJ datasets (described earlier) as well as a 40-author\nJava Dataset with 3,021 files [Yang et al., 2017] with 15 authors considered the positive class, splitting training and\ntesting sets. Dataset features are subjected to Winsorized normalization; extreme values are mapped to 0 or 1, and each\nnon-extremal x is mapped to $\\frac{(x - x_{5\\%})}{(x_{95\\%} - x_{5\\%})}$, where $x_{k\\%}$ refers to the kth percentile.\n\nWe compared our results with ZeroGPT, an online service (API) that lets users detect whether input text was generated\nusing a GPT model. We tested the API on the same code groups and classified the model's output by checking if its\nprobability score (of being generated by GPT) >0.5."}, {"title": "4.1 GPT Dataset Detection Results", "content": "We compare the performance of group sizes 10-70 for various syntactic features, using Random Forest, XGBoost,\nLGBM, and CatBoost. Results shown are averages over all the ensembles tested. The bin width is optimized for\naccuracy for discretized features, though the bin width did not affect results, as long as it is sufficiently large. Table 1\nshows only the results for group sizes 10, 40, and 70, omitting 20, 30, 50, and 60 for space reasons.\n\nResults are summarized below with average values across all code groups:\n\nAccuracy: API: 0.72; CBN; 0.78; NB-F: 0.82; CNB-F: 0.86; EWD-CBNB-CM: 0.957; EWD-NB-F: 0.960; EWD-NB-F\nin combination with EWD-CBNB-CM: 0.974.\n\nF1: API: 0.14; CBN: 0.17; NB-F: 0.33; CNB-F: 0.56; EWD-CBNB-CM: 0.767; EWD-NB-F: 0.774; EWD-NB-F in\ncombination with EWD-CBNB-CM: 0.781.\n\nAUC: API: 0.49; CBN: 0.78; NB-F: 0.84; CNB-F: 0.899; EWD-CBNB-CM: 0.974; EWD-NB-F: 0.972; EWD-NB-F\nin combination with EWD-CBNB-CM: 0.979.\n\nPrecision: API: 0.16; CBN: 0.33; NB-F: 0.58; CNB-F: 0.74; EWD-CBNB-CM: 0.812; EWD-NB-F: 0.826; EWD-NB-F\nin combination with EWD-CBNB-CM: 0.838.\n\nThe performance of ensembles for the same dataset was similar for XGBoost, LGBM, and CatBoost for all metrics\ntested. Random Forest performs slightly worse. Performance was only marginally affected by group size.\n\nWe achieved high performance in accuracy, F1, AUC, and precision scores in detecting GPT in the Java GPT Dataset.\nEven the worst performing syntactic feature NB-F significantly outperformed the ZeroGPT API in all code group sizes\nand in all metrics tested. As the API was primarily meant to be used in detecting GPT generated text, it failed to perform\nwell in detecting GPT generated code, while our approach performed much better.\n\nCNB-F performed better than NB-F in all cases, since it has significantly fewer features. As an example, the NB-F\ndataset for group size 40 contains 13.5 thousand features, whereas CNB-F contains 52 features for all group sizes."}, {"title": "4.2 40-Author Anomaly Detection Results", "content": "Similar comparisons were carried out with the 40-author data set [Yang et al., 2017]. Table 3 shows only the results for\ngroup sizes 10, 40, and 70, again omitting 20, 30, 50, and 60 for space reasons. Results are summarized below with\naverage values across all code groups:\n\nAccuracy: NB-F: 0.95; CNB-F: 0.96; EWD-NB-F:0.98; EWD-NB-F in combination with EWD-CBNB-CM: 0.99.\n\nF1: NB-F: 0.75; CNB-F: 0.78; EWD-NB-F:0.91; EWD-NB-F in combination with EWD-CBNB-CM: 0.92.\n\nAUC: NB-F: 0.97; CNB-F: 0.98; EWD-NB-F: 0.993; EWD-NB-F in combination with EWD-CBNB-CM: 0.996."}, {"title": "4.3 GPT GCJ Dataset Detection Results", "content": "Finally, we addressed the GPT GCJ Dataset, which has up to 143,776 code groups for group size 10 and over 1,000\nauthors. We focus primarily on EWD-NB-F. Similar performance may be achievable with other features. However, we\ndid not test on those features due to the high computational requirements, e.g., creation of a single dataset for group\nsize 30 for EWD-CBNB-CM required over 3 days. We use bin width 3000, though any width > 2000 performed nearly\nthe same. Results are detailed in Table 5.\n\nPerformance remained high despite the significant scale-up in authors and files. Accuracy was maintained at 0.98-0.99;\nF1 score was 0.92-0.95 (excluding group size 10); AUC was 0.987-0.999; and precision was 0.97-0.98 (excluding group"}, {"title": "4.4 Computational Effort Required", "content": "We used an AMD Ryzen 9 5950X 16-Core Processor with 4.00 GHz, 64 GB RAM, Quadro RTX 5000. The feature\nextraction and dataset generation process required about 3 minutes for the GPT dataset and 10 minutes for the 40-author\ndataset. For evaluating discretized GPT datasets using the ensemble models, about 1 minute was required (on average)\nto complete the experiment for GPT Dataset and 48 minutes for GPT GCJ Dataset, evaluating 7 datasets for each group\nsize. For discretized 40-author datasets, the computational time required by the models was 3 minutes, 28 seconds (on\naverage) for all 7 datasets."}, {"title": "5 Conclusion", "content": "This paper has addressed the problem of detecting LLM-generated fragments in Java code. Source code files were split\ninto code groups (10-70 lines each) and categorized using new stylometric features (EWD-NB-F, EWD-CBNB-CM,\nand CNB-F); the subsequent application of well-known machine learning models resulted in very high accuracy.\n\nTwo datasets were created (and have been made available for other researchers) specific to Java GPT code detection: (1)\nGPT Dataset - with 15 human authors in addition to LLM (GPT 3.5 and GPT 4) rewritten code, (2) GPT GCJ Dataset\nwith 1k+ human authors in addition to GPT 4o rewritten code, where the LLM was prompted to rewrite the code while\nmaintaining functionality. Testing was performed using these as well as another 40-author dataset.\n\nWe achieved up to 0.977 accuracy on the GPT Dataset by combining EWD-NB-F and EWD-CBNB-CM using only 17\nfeatures, outperforming the commonly utilized GPTZero API which only achieves 0.73 accuracy. For the 40-author\ndataset, we achieved 0.99 accuracy with 85 features. We also achieved up to 0.99 accuracy on the GPT GCJ Dataset\nwith 76k+ files using EWD-NB-F.\n\nOur approach significantly outperformed three other recent approaches. Consistent results were observed for different\nsettings of code group sizes. For example, we achieved 0.97-0.98 accuracy on the GPT dataset, whereas the ZeroGPT\nAPI results were substantially worse (accuracy 0.73). When comparing feature sets, the improvement was substantial\nfor one data set (from baseline feature set accuracy 0.79-0.86 to 0.95-0.98); even in the other (easier) task, the accuracy\nwas improved from 0.94-0.95 (baseline feature set) to 0.98-0.99.\n\nFuture work includes exploring whether other mathematical operations in discretization could yield better results and\nmaking experiments more akin to real-world scenarios (code written by students and professionals). A real world\nLLM code detector would need to understand many LLM coding styles and be accurate even when given coding styles\nnot seen in the input dataset; this needs to be assessed, and further improvements may be necessary to ensure such\nrobustness. Finally, we note that the focus of this work was to find useful features for the task at hand, not on finding\nthe best machine learning model or algorithm for the author identification task; performance improvements may be\nobtainable using other machine learning models (or algorithms)."}]}