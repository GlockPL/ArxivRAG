{"title": "Chain Association-based Attacking and Shielding Natural Language Processing Systems", "authors": ["Jiacheng Huang", "Long Chen"], "abstract": "Association as a gift enables people do not have to mention something in completely straightforward words and allows others to understand what they intend to refer to. In this paper, we propose a chain association-based adversarial attack against natural language processing systems, utilizing the comprehension gap between humans and machines. We first generate a chain association graph for Chinese characters based on the association paradigm for building search space of potential adversarial examples. Then, we introduce an discrete particle swarm optimization algorithm to search for the optimal adversarial examples. We conduct comprehensive experiments and show that advanced natural language processing models and applications, including large language models, are vulnerable to our attack, while humans appear good at understanding the perturbed text. We also explore two methods, including adversarial training and associative graph-based recovery, to shield systems from chain association-based attack. Since a few examples that use some derogatory terms, this paper contains materials that may be offensive or upsetting to some people.", "sections": [{"title": "1. Introduction", "content": "In past years, many studies has shown that the adversarial examples can cause decision-making errors in natural language processing (NLP) systems Formento et al. (2023); Ou et al. (2022), even in large language models Wang et al. (2024) (LLMs).\nHowerver, existing adversarial attacks only consider the attack strategies in a direct way while ignoring the complexity of textual adversarial attacks in reality. For example, Chinese words\u201c\u5e7c\u7a1a\u201d, which means \u201cnaive\u201d, is an adjective with emotional tendency, but it will not be recognized as an emotional word by an emotion analysis system after being substituted with\u201c\u62ff\u8863\u670d\u201d, which is a verb object phrase meaning to \u201ctake clothes\u201d. The relation between\u201c\u5e7c\u7a1a\u201dand\u201c\u62ff\u8863\u670d\u201dis not a simple single-layer mapping, but a multi-layer mapping. Specifically, we associate\u201c\u5e7c\u7a1a\u201dwith\u201cnaive\" first, which is the English translation of \u201c\u5e7c\u7a1a\u201d, and then further associate it with \u201c\u62ff\u8863\u670d\u201d,which is one of the Mandarin transliterations of \u201cnaive\u201d. Note that the above is only a simple example of word substitution based on chain association while the associative ability of human being is complex.\nEnglish has analogous cases. Take \u201cscrew", "a metal object like a nail\" or \"having sex with someone\". Attackers online can replace \u201cscrew\u201d with its related emoji to form offensive phrases like \u201c you": "which utilizes human associations about the corresponding word of emoji and its polysemy. Note that this example is merely used as an analogy to explain our idea, in fact, this work only focuses on Chinese adversarial examples.\nIn this work, we investigate to what extent advanced Chinese NLP systems are sensitive to chain association-based attack and explore various shielding techniques. Specifically, we first generate a chain association graph for Chinese characters based on the association paradigm for building search space of potential adversarial examples. Then, we regard generating adversarial examples as a problem of combinatorial optimization and introduce an discrete particle swarm optimization algorithm to search for the optimal adversarial examples. We show that advanced NLP models and applications are extremely vulnerable to our attack. To our best knowledge, we are the first to introduce chain association in adversarial attack. Furthermore, we also explore two methods to protect NLP systems from our attacks."}, {"title": "2. Related Work", "content": "Although adversarial attacks were first proposed in the field of image recognition, however, due to the discrete nature of textual data and the uncertainty brought by perturbations to the semantic quality of text, it is difficult to directly migrate adversarial attack algorithms in the image domain to textual data types. Therefore, researchers have conducted extensive studies on textual data, forming different textual adversarial attack paradigms with different perturbation granularities, such as character-level, word-level, and sentence-level.\nThe form of character-level attacks vary across different linguistic and cultural environ-ments. In the English context, character-level attacks often exploit visual perturbations, including artificially constructed spelling errors such as the insertion, deletion, swapping, and modification of letters within words Formento et al. (2023). However, in the Chinese context, handwritten stroke errors on paper do not occur in electronic devices based on input methods. Therefore, character-level attacks in Chinese environments usually manifest as the replacement of homophones Cheng et al. (2020) or the utilization of visual character disassembly Ou et al. (2022).\nWord-level adversarial attacks achieve the deviation of semantic vectors of examples by disturbing the input at the word level, making them cross the decision boundary and thus leading to incorrect model outputs. As the core method of this strategy, word substitution covers various strategies, including word vector similarity Jin et al. (2020), synonyms Ren et al. (2019), sememes Zang et al. (2020), and language model scores Zhang et al. (2019).\nWord-level adversarial attacks do not violate the grammatical rules of the text and maximize the retention of the original semantics, thus exhibiting better performance in terms of adversarial text quality and attack success rate. Additionally, the utilization of language models for control also ensures the fluency and smoothness of the adversarial text.\nSentence-level adversarial attacks treat the entire original input sentence as the target of perturbation, carefully reconstructing the textual content by generating adversarial texts that maintain the same semantic meaning as the original input but cause the victim model to make incorrect decisions. Common sentence-level adversarial attack methods include re-"}, {"title": "3. Associations in Textual Adversarial Examples", "content": "Abundant association ability is vested in human beings, who are able to associate things that seem totally different but related. The gift enables people do not have to mention something in completely straightforward words and allows others to understand what they intend to refer to. Associationism psychology holds that all complex mental processes, such as thinking, learning, and memory, can be mainly explained by the associative links that connect ideas, according to specific laws and principles Bracken et al. (2021), e.g., Philosopher David Hume's Laws of Association: (i) Law of Similarity, (ii) Law of Contiguity, and (iii) Law of Causality. The Law of Similarity states that when two things are very similar to each other, the thought of one will often trigger the thought of the other. The Law of Contiguity states that we associate things that occur close to each other in time or space. The Law of Causality states that we associate things when there is a causal relationship with them.\nWe believe that the distance between associative words is close in human cognition even if it is far in word meaning, and such an inconsistency between two kinds of distances of associative words provides the motivation for this paper. Specifically, the existing textual adversarial attacking strategies, such as word substitutions and misspellings, are special cases of the laws of association. For examples, the synonym-based substitution belongs to the law of similarity in word meaning and the misspellings belongs to the law of similarity in vision. All these strategies take advantage of the inconsistency between the distances in human cognition and word meaning.\nFurthermore, the association of words is not necessarily single-layer as a chain association chain will be formed while associating constantly from one word to another. We believe that such a chain association of words will aggravate the inconsistency of distances in human cognition and word meaning, and cause the deep neural networks to fail blatantly."}, {"title": "3.1. Motivation", "content": "Abundant association ability is vested in human beings, who are able to associate things that seem totally different but related. The gift enables people do not have to mention something in completely straightforward words and allows others to understand what they intend to refer to. Associationism psychology holds that all complex mental processes, such as thinking, learning, and memory, can be mainly explained by the associative links that connect ideas, according to specific laws and principles Bracken et al. (2021), e.g., Philosopher David Hume's Laws of Association: (i) Law of Similarity, (ii) Law of Contiguity, and (iii) Law of Causality. The Law of Similarity states that when two things are very similar to each other, the thought of one will often trigger the thought of the other. The Law of Contiguity states that we associate things that occur close to each other in time or space. The Law of Causality states that we associate things when there is a causal relationship with them.\nWe believe that the distance between associative words is close in human cognition even if it is far in word meaning, and such an inconsistency between two kinds of distances of associative words provides the motivation for this paper. Specifically, the existing textual adversarial attacking strategies, such as word substitutions and misspellings, are special cases of the laws of association. For examples, the synonym-based substitution belongs to the law of similarity in word meaning and the misspellings belongs to the law of similarity in vision. All these strategies take advantage of the inconsistency between the distances in human cognition and word meaning.\nFurthermore, the association of words is not necessarily single-layer as a chain association chain will be formed while associating constantly from one word to another. We believe that such a chain association of words will aggravate the inconsistency of distances in human cognition and word meaning, and cause the deep neural networks to fail blatantly."}, {"title": "3.2. Rules of Word Association", "content": "It should be noted that not all associations can be used in the field of textual adversarial examples, as inappropriate associative word substitutions will cause the text to be un-readable. Thus, we summarize several rules of word association can be used in textual adversarial attack, according to Philosopher David Hume's laws of association and Chinese cultural environment, as shown in Table 1. The Law of Contiguity is excluded because it is difficult to introduce this law into textual adversarial attack.\nWith the help of knowledge graph technology, the association chain can be fully expressed while entity refers to word and edge refer to the associative relationship between words. Words out of vocabulary may appear while associating words in some way, such as the example mentioned in the introduction. Although these words have no specific meaning, we believe that readers will start a word guessing process which is kind of like completing a cloze, i.e., mask the unknown words temporarily and infer what the author intends to write after reading context. Due to the association between the original word and guessed word, readers can confirm whether they guessed correctly. Moreover, the word guessing process will be easier than normal cloze, since the topics involving supervision are usually confined to crime, pornography, and dirty words."}, {"title": "4. Approach", "content": "Generally, words in the original sentence vary in their impact on model predictions. Minor sentence alterations, especially replacing key words, can significantly alter predictions. Following Li et al. (2019), we identify the most influential words by measuring their re-moval effects and replace them in order of importance. The challenge lies in generating suitable substitutes and determining optimal adversarial examples that deceive the model while resembling the original. Here, we propose 1) an associative knowledge graph and 2) an adversarial search strategy."}, {"title": "4.1. Associative Knowledge Graph", "content": "The associations can be represented by a graph intuitively so that we consider building an associative knowledge graph G as shown in Fig. 1. In fact, due to the complexity of human association ability, we can not completely enumerate all the types of word association but summarize some typical rules to test our ideas. Fortunately, our design is highly scalable, allowing new rules and graph updates. Next, we elaborate on these rules and their implementation.\nEnglish Translation. We view English translations of Chinese characters as word asso-ciations based on similarity of meaning. For example, \u201cnaive\u201d translates to\u201c\u5e7c\u7a1a\u201d.Many Chinese online users know both languages, and English is crucial in Chinese education. English translations can be accessed via third-party platforms.\nChinese Pinyin. Chinese Pinyin is the Chinese phonetic notation with Latin alphabets according to Laws of Causality while each Chinese character has its corresponding Chinese Pinyin. For instance, it can be written as \u201cyou zhi\u201d if we were to represent the pronunciation of the Chinese characters\u201c\u5e7c\u7a1a\u201din Chinese Pinyin. The conversion between Chinese characters and Chinese Pinyin can be implemented with the Python third-party library named pypinyin.\nTransliteration. Transliteration refers to the translation of foreign words with Chinese characters with similar pronunciations and it is based on Laws of Similarity. This kind of Chinese characters used for transliteration no longer have their original meaning but only retain their pronunciation and writing form. For example, consider the pronuncia-tion of the word \u201cnaive\u201d as /nar'i:v/. This pronunciation is akin to the Chinese characters \u201c\u62ff(n\u00e1)\u8863(y\u012b)\u670d(f\u00fa)\u201d in terms of phonetics. To be more precise, /nar/ is similar to \u201cn\u00e1\u201d, /i/ is reminiscent of \u201cy\u012b\u201d, and /v/ bears resemblance to \u201cf\u00fa\u201d. We only consider the transliter-ation from English to Chinese in this work and implement it by establishing the mapping relationship between English phonetics and Chinese Pinyin, as the number of vowels and consonants in English is limited and their pronunciations can be similarly expressed with Chinese pinyin.\nAcronym. Acronym namely a word composed of the first letters of the words in a phrase, which is often used as an abbreviated form of Chinese network language, can be used as an association word of Chinese pinyin or English word. It is based on Law of Causality as the acronym cause readers want to figure out what the complete phrase is. For example, \"lol\" is typically an abbreviation for \"laugh out loud\" in English. Similarly, in Chinese internet slang, \"nb\" is often an abbreviation for \u201c\u725b(ni\u00fa)\u903c(b\u012b)\u201d, which means awesome. The conversion from Chinese Pinyin or English word to its acronym can be implemented with built-in Python string operations.\nFuzzy Matching. Fuzzy matching for Chinese Pinyin, i.e., search possible Pinyin starting with given first letters (i.e., acronym), is a common substitution for keywords in Chinese offensive text online recently, which often escapes offensive text automated detection systems. For instance, due to their shared first letters in Pinyin, \u201c\u7279(t\u00e8)\u55b5(mi\u0101o)\u7684(de)\u201d in Chinese internet slang carries the same meaning as\u201c\u4ed6(t\u0101)\u5988(m\u0101)\u7684(de)\u201d which is an offensive term equivalent to \u201cfuck\u201d, while \u201c\u7279(t\u00e8)\u55b5(mi\u0101o)\u7684(de)\u201d originally lacks a specific meaning of its own. It is based on Law of Similarity because they have similar consonants. The operation can be implemented by arranging and combining the first letters and vowels since the first letters are often consonants.\nHanzify. Hanzify, namely conversion from Chinese pinyin to Chinese characters in this paper, can also be an association link connected behind the fuzzy matching in the association chain, which is implemented simply with Python third party library named Pinyin2Hanzi. For example, the Pinyin \"hao\u201d can be converted into various Chinese characters, such as \u201c\u597d\u201d(good),\u201c\u53f7\u201d(number), and\u201c\u90dd\u201d(a Chinese surname). It is based on Law of Causality as Chinese Pinyin cause readers to associate the corresponding Chinese characters.\nVisually Similar Characters. Visual similarity can play a considerable role in replac-ing the important words in a sentence according to Law of Similarity, as a large number of characters with visual similar composition or shape exist in Chinese. For instance, the shape of the character\u201c\u65e5\u201dis similar to the character\u201c\u65e5\u201dvisually, even though they have completely different meanings. Specifically, the character\u201c\u65e5\u201dmeans\u201cday\u201d in a general context or \"fuck\u201d in an offensive context, while\u201c\u65e5\u201d means \"say\" in classical Chinese lan-guage. To this end, about twenty thousand Chinese characters are collected and converted into image representation using Python built-in library named PIL, and we build character embedding space with visual shape for retrieving similar characters.\nCharacters Disassembling. Chinese characters include a large number of combined char-acters composed of several single characters, some of which can be disassembled transversely and not or only mildly affect reading as the characters are left-right structures according to Law of Similarity. For example, Chinese character\u201c\u5e7c\u201dcan be disassembled into\u201c\u4e48\u201dand \u201c\u529b\u201d, i.e., \u201c\u5e7a\u529b\u201d. Similarly, the Chinese character\u201c\u7a1a\u201dcan be disassembled into\u201c\u79be\u201dand \u201c\u4f4f\u201d, i.e.,\u201c\u79be\u4f73\u201d.We collected the required data by crawler from a third-party website providing characters disassembling service.\nUsing the above rules, we can generate a large number of candidates for any word that needs to be replaced in a sentence. In order to modify the original sentence as little as possible, we only take the words whose importance is the one-third of the original sentence as the substituted words in this work."}, {"title": "4.2. Particle Swarm Optimization-based Search Strategy", "content": "The original sentences may contain multiple important words to be replaced and, for each word, abundant associative words exist according to the association rules. Besides, as we can see in Fig. 1, there are multiple paths and multiple layers to retrieve the associative words of a original word. Thus, an efficient adversarial examples search strategy is essential while a huge search space composed of numerous potential adversarial examples needs to be handled and, furthermore, the path from the original word to the final associative word is expected to be as short as possible for reducing the burden of comprehension to readers. Hence, we consider exploiting particle swarm optimization (PSO) to search for final adversarial examples in the search space.\nHowever, rather than the original PSO, whose search space is continuous, a variation suitable for discrete space composed of potential textual adversarial examples is what we need. Inspired by Zang et al. (2020), a position in the search space now corresponds to a potential adversarial example while each dimension of a position, i.e., sentence, corresponds to a word. Besides, the velocity of particle now corresponds to a probability vector, and each dimension of a velocity refers to the corresponding dimension of the related position will change, i.e., the probability of a word will be substituted.\nFormally, we denote an original sentence as $x^o = x_1^o...x_n^o...x_N^o$, where N is the length of original sentence and $x_n^o$ is the n-th word in original sentence. A position in the search space, i.e., a potential textual adversarial example related to $x^o$, is denoted as $x^a = x_1^a...x_n^a...x_N^a$, $x_n^a \\in A(x_n^o)$, where $A(x_n^o)$ is the set of $x_n^o$ and all its associative words. A velocity of a particle, is denoted as $v = v_1...v_n...v_N$, where $v_n$ refers to the probability with which determines whether n-th dimension of the particle's position will move.\nSince we expect that the final adversarial example can not only fool the victim model but also the association paths between substitution words and original words are as short as possible in total, the optimization score of a position is calculated by following the formula:\n$score(x^a) = \\frac{1-C(x^a)}{L(x^o, x^a)}$\nwhere $C(x^a)$ is the confidence of the true label of $x^a$ given by the victim model, and $L(x^o,x^a)$ is the total number of layers from the associative words in $x^a$ used to replace original words in $x^o$. If the current number of iterations reaches the maximum, the algorithm will terminate and output the position of the particle in the global best previous position as the search result.\nWhen presented with an original sentence, each particle is given a stochastic position x and velocity v. Specifically, the important words in the original sentence are substituted with their direct associative words and take the modified sentence as the initial position of a particle. In addition, the velocity v of particle in discrete search space is a probability vector, hence, each dimension of v is initialized randomly between interval [0.0,1.0] and updated by the following formula:\n$v_n = S(wv_n + \\varphi_1I(p_i, x) + \\varphi_2I(p^g, x))$\n$I(a, b) = \\begin{cases}\n-1, a = b\\\\\n1, a \\neq b\n\\end{cases}$\nwhere S(*) is a sigmoid limiting transformation for constraining $v_n$ to the interval [0.0, 1.0] since $v_n$ is a probability. It can be reasonably calculated as that $v_n$ is going to decrease, remain the same, or increase when the particle's position is at the global best previous position, individuals best previous position only, or both not.\nIn addition, compared with the fixed value, a dynamic decreasing w derived from a measure function enables particles to explore more positions in the early stage and gather around the best positions in the final stage. Thus, we introduce a nonlinear dynamic adaptation function to update w. Specifically,\n$\\omega = \\omega_{max} - \\frac{t^2 \\times (\\omega_{max} - \\omega_{min})}{t_{max}^3}$\nwhere t and tmax are the current and max numbers of iterations separately. w decreases slowly during the initial iteration, which is conducive to exploring the local optimum at an early stage, and w decreases rapidly while approaching the maximum number of iterations for improving the efficiency of converging to the global optimum.\nBesides, the original position update formula that makes addition is also not suitable for discrete space. Inspired by Kennedy and Eberhart (1997), we propose a probabilistic approach to update the position of particles. A probability P is introduced with which a particle determines whether one of its position's dimensions, i.e., $x_n$, moves to the corre-sponding dimension of global best previous position $p_i^g$. The movement of each dimension of a particle' position at an iteration is redefined by the following rule:\nif rand() < P and rand() < $v_n$\nthen $x_n = p_i^g$\nelse rand() > P and rand() < $v_n$\nthen $x_n = G_{adj}(x_n)$\nwhere rand() refers to a random number selected from a uniform distribution in [0.0, 1.0], and $G_{adj}(x_n)$ refers to one of the words adjacent to $x_n$ at random in the associative graph G. In addition, to encourage particles to explore more positions according to associative graph G at an early stage and search for better positions around the global best position at a final stage, P varies with iteration as follow:\nP = P_{min} + \\frac{t^2 \\times (P_{max} - P_{min})}{t_{max}}\nwhere 0 < Pmin < Pmax < 1, and we can see the probability of particles moving to the global previous best position will increase with the number of iterations."}, {"title": "5. Experiments", "content": "In this section, we conduct comprehensive experiments to evaluate our chain association-based attack on Chinese NLP systems and study the methods of shielding against chain association-based adversarial attack."}, {"title": "5.1. Attacking", "content": "Victims Models and Applications. To investigate the effects of chain association-based attack, we evaluate our attack method on five text classification models, namely Fasttext Joulin et al. (2017), TextCNN Guo et al. (2019), Attention-based Bidirectional LSTM (B\u0130LSTM) Xiaoyan and Raga (2023) and BERT Si and Wei (2023). Besides, we also test our attack methods on two industry-leading commercial applications used for offensive text detection, namely Baidu Text Censoring\u00b9 (BaiduCensor) and Alibaba Content Security\u00b2 (AliSecurity).\nIn addition, due to the significant impact of large-scale models on artificial intelligence recently, we also conduct experiments on LLMs, i.e., ERNIE Bot and Tongyi Qianwen, released by Baidu and Alibaba respectively. Due to the outputs of some LLMs are not easy to control while using the prompt-based paradigm, it is difficult to apply our attack algorithm directly to LLMs while each iteration in our adversarial attacking algorithm requires getting the confidence of classification of the victim model. Thus, as an alternative, we used the paradigm of transfer-based attack to conduct experiments on LLMs, that is, we obtain adversarial examples generated on the local model, and then use prompt-based paradigm to get answers for classification of LLMs by inputting prompt. All prompts used in this paper are presented in Appendix A.\nDataset and Associative Graph. We use public Chinese datasets, i.e., Meituan 3 and Amazon comments. Besides, we collect offensive text and normal text from online social platforms labeled by native Chinese speakers. We divide the dataset into two parts, i.e., 80% for training and 20% for testing. Details of the datasets are shown in Table 2."}, {"title": "5.2. Shielding", "content": "Without losing generality, we study two methods for shielding our attack on offensive text dataset, namely adversarial training (AT) and associative graph-based recovery (AGBR). For AT, we replace different percentages of the original offensive training set with perturbed text generated by our attacking method and retrain local victim models to improve the robustness. For AGBR, we recover the perturbed text by replacing the abnormal tokens,"}, {"title": "6. Conclusion", "content": "In this work, we propose a chain association-based perturbation approach, which is inspired by the strong association ability of humans, to attack Chinese NLP system. We reveal the vulnerability of the state-of-the-art NLP models and industrial-leading applications to our attack and show that human are able to understand the perturbed text with their strong association ability, showing that adversarial attack based on chain association can cause serious impact. We also explore methods to shield systems from chain association-based attack and show the effectiveness of associative knowledge graph in shielding such attack. Our work shows that gaps between humans and machines exist in reading comprehension while humans are able to associate things that seem totally different but related, and we hope that our work can inspire others to investigate more attacking and shielding technologies combining traits of the human thinking."}, {"title": "Appendix B. Case study", "content": "We display some adversarial examples generated by the baselines and ours on Meituan comments in Table 11. The examples of offensive text are not shown since there are many indecent words."}]}