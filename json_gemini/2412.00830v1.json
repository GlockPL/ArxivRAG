{"title": "SPILDL: A Scalable and Parallel Inductive Learner in Description Logic", "authors": ["Eyad Algahtani"], "abstract": "We present SPILDL, a Scalable and Parallel Inductive Learner in Description Logic (DL). SPILDL is based on the DL-Learner (the state of the art in DL-based ILP learning). As a DL-based ILP learner, SPILDL targets the ALCQI(D) DL language, and can learn DL hypotheses expressed as disjunctions of conjunctions (using the \\operator). Moreover, SPILDL's hypothesis language also incorporates the use of string concrete roles (also known as string data properties in the Web Ontology Language, OWL); As a result, this incorporation of powerful DL constructs, enables SPILDL to learn powerful DL-based hypotheses for describing many real-world complex concepts. SPILDL employs a hybrid parallel approach which combines both shared-memory and distributed-memory approaches, to accelerates ILP learning (for both hypothesis search and evaluation). According to experimental results, SPILDL's parallel search improved performance by up to ~27.3 folds (best case). For hypothesis evaluation, SPILDL improved evaluation performance through HT-HEDL (our multi-core CPU + multi-GPU hypothesis evaluation engine), by up to 38 folds (best case). By combining both parallel search and evaluation, SPILDL improved performance by up to ~560 folds (best case). In terms of worst case scenario, SPILDL's parallel search doesn't provide consistent speedups on all datasets, and is highly dependent on the search space nature of the ILP dataset. For some datasets, increasing the number of parallel search threads result in reduced performance, similar or worse than baseline. Some ILP datasets benefit from parallel search, while others don't (or the performance gains are negligible). In terms of parallel evaluation, on small datasets, parallel evaluation provide similar or worse performance than baseline.\nIndex Terms-Scalable Machine Learning, Inductive Logic Programming, Description Logic, GPU, Ontologies, Parallel Computing", "sections": [{"title": "I. INTRODUCTION", "content": "Inductive logic programming (ILP) is a Machine Learning (ML) technique which represents knowledge and models using logic-based representations. ILP as a machine learning technique, is used in several areas [6]\u2013[8] for learning complex concepts from multi-relational data; this ability of directly learning from multi-relational data, gives ILP an advantage (in terms of model expressivity) when compared to other techniques such as ID3 and Na\u00efve Bayes. A key advantage in ILP, is in the flexibility of its knowledge representation, that is, it is not tied to a particular logic representation. In fact, ILP has been used with other logic formalisms such as Description Logic (DL) [3], [5]; DL is typically used as the underlying knowledge representation for OWL (Web Ontology Language) [4], where DL also provide reasoning facilities on OWL ontologies. DL-based ILPs improve learning performance (and scalability) by reducing model expressivity into the midpoint between horn clauses and propositional logic (PL). Even though DL-based ILPs have reduced model expressivity (when compared to classical ILPs), yet they still retain a sufficient level of model expressivity to describe many complex real-world concepts. There are also other ML techniques capable of learning from multi-relational data such as artificial neural networks (ANN); however, such ML techniques provide black-box models which can not be interpreted by humans, whereas ILP algorithms learn white-box (human readable) models.\nEven though ILP algorithms are capable of learning complex human interpretable models, yet they suffer from poor scalability in terms of handling (or coping) with large learning data; because ILP algorithms are highly sequential in nature. Due to this poor scalability, ILP's potential real-world applications are limited to medium to small datasets. To address the scalability issue, several techniques were developed to improve the scalability of ILP algorithms such as reducing redundant computations through Query Packs [15], outsourcing hypothesis evaluation (a key component in ILP algorithms) to database systems [13]. Also, other developed approaches focused on improving ILP performance by parallelizing the hypothesis search [12]. However, most of the performance improvement approaches in the ILP literature, focus mainly on improving the performance for classical ILPS \u2013 i.e. ILPs that uses Horn clauses for knowledge and model representation. In terms of DL-based ILP literature, research works focus mainly on improving the hypothesis evaluation task for DL-based ILPs, such as through parallel DL reasoners [30]. In other words, we believe that there are no parallel ILP approaches that accelerate hypothesis search for DL-based ILPs.\nTherefore, in this work we propose a parallel DL-based ILP learner that employ a set of novel parallel approaches that accelerate the hypothesis search for DL-based ILP learning. In our proposed parallel DL-based ILP learner (SPILDL, a scalable and parallel inductive learner in DL), we provide parallel hypothesis search approaches, that utilize shared-memory and also distributed-memory architectures, to accelerate the performance of DL-based ILPs. In terms of accelerating hypothesis evaluation, SPILDL outsource hypothesis evaluation to HT-HEDL [14] (our multi-device hypothesis evaluation engine); HT-HEDL aggregates the computing power of multi-core CPUs with multi-GPUs for high performance hypothesis evaluation in DL. SPILDL (our proposed work) builds and extends upon the DL-Learner's OCEL (OWL Class Expression Learner) algorithm, where the DL-Learner [3] and its OCEL algorithm are regarded as the state of the art in the DL-based ILP literature. In the next section, we review the parallel and non-parallel ILP literature."}, {"title": "II. RELATED WORK", "content": "An ILP algorithm consists of three main procedures: hypothesis generation, hypothesis search and hypothesis evaluation; accelerating one or more of these steps will improve ILP performance. In terms of hypothesis generation, some existing techniques employ problem-related knowledge to restrict the hypothesis language to avoid generating invalid candidate hypotheses. Classical ILPs use mode declarations such as Progol [19] and Aleph [20]. For DL-based ILPs, the DL-Learner employ class/role hierarchy and statistics about the knowledge base such as max role fillers and value boundaries for numeric concrete roles; when generating DL refinements. Other approaches improve hypothesis generation by detecting and avoiding the expansion of weakly-equal hypotheses (i.e. the same hypothesis though with different operands order); the DL-Learner employ such approach by enforcing a deterministic operand order on DL hypotheses. In addition, a maximum hypothesis length may be used to restrict the hypothesis language further. In some ILP learning problems, it would be sufficient to use less expressive logic-based representations to learn an acceptable solution; in other words, using expressive logic representations is not always recommended especially if the ILP task at hand doesn't require a high level of hypothesis expressivity. Less expressive logic representations generate simpler hypotheses with faster learning speed.\nIn terms of hypothesis search, there are two existing ap-proaches. In the first approach, techniques were proposed to optimize the search process such as developing better scoring functions [13]. In the second approach, techniques were developed which focuses on dedicating more computing power towards the search (and evaluation) process. Some approaches were developed to accelerate the Aleph ILP al-gorithm using Message Passing Interface (MPI) [37] in [39]. Some parallel ILP approaches accelerated the search using shared-memory environment [21], while others focused on distributed-memory environments [16]. In terms of hypothesis evaluation, some approaches focused on accelerating the hypothesis evaluation by using: concurrent logic programming languages [18], database systems such as Datalogs [17], or parallel reasoners [22]. Moreover, some developed approaches used GPUs to accelerate hypothesis evaluation [23], [28], [29], [31], [32]. Furthermore, there are also approaches that use dedicated hardware (FPGA-based) accelerators to improve ILP computations [35], [36].\nThere are ILP acceleration approaches that use Big Data [33] technologies (such as MapReduce [24] and Apache Spark [34]) to accelerate ILP computations [25]\u2013[27], [38]. Although, one of the limitations (or challenges) with distributed parallel ILP approaches, is dealing with the search, coordination and communication overheads; the search overhead refers to the additional number of generated candidate hypotheses as opposed to the traditional (sequential) implementation. The communication overhead refers to the communication (network) cost between the distributed computers working on a single ILP problem; this overhead is small in shared-memory ILPs, though it is more pronounced (amplified) in distributed-memory ILPs.\nThe reviewed approaches focused mostly on improving classical ILPs (horn clauses). We have observed rarity on improving DL-based ILPs through either parallel or non-parallel approaches. Therefore, in this article, we focus on improving DL-based ILPs through the use of parallel computing approaches to accelerate both of hypothesis search and hypothesis evaluation. In the next section, we describe SPILDL (our proposed approach) which combines existing non-parallel approaches (employed by the state of the art, i.e. DL-Learner) with our proposed parallel approach, for improving the performance of DL-based ILPs."}, {"title": "III. SPILDL: SCALABLE AND PARALLEL INDUCTIVE LEARNING IN DL", "content": "In this section, we describe SPILDL, a Scalable and Parallel Inductive Learner in DL. SPILDL is a parallel ILP learner based on the DL-Learner. SPILDL aims to extends upon the DL-Learner by exploiting parallel computing capabilities of multi-core CPUs and multi-GPUs, to improve the performance of DL-based ILPs; in order to reduce ILP learning time and improve the scalability (i.e. coping with very large datasets). It is worth noting that some aspects of SPILDL in [1], are used in our previous works in [10], [11].\nSPILDL is based on the DL-Learner's OCEL algorithm, and follows OCEL's search procedure (including expanding hypotheses up to he), scoring function, and its full refinement operator; which also includes constructing hypotheses with the \\operator, e.g. $(\u0421_1 \u2229 \u0421_2) \u2294 (\u0421_3 \u2229 \u0421_4)$. In addition, SPILDL also increases the expressivity of learned hypotheses by incorporating string concrete roles (e.g. $injuryLevel = \u201csevere\u201d$, discussed in next section), in addition to numeric concrete roles, when constructing candidate hypotheses; this incorporation of expressive DL constructs, results in learning much more expressive DL hypotheses suitable for wider range of DL-based inductive learning applications.\nSPILDL targets the ALCQI(D) DL language. Similar to OCEL, SPILDL can also incorporate role hierarchy when generating refinements. In terms of generating hypotheses with string roles, SPILDL handles string roles (e.g. $stringProperty = \u201cvalue\u201d$), similar to how OCEL treats boolean concrete roles; i.e. for each string role, SPILDL adds to the MB set, all possible values for each string role. For"}, {"title": "A. High-performance ILP learning", "content": "SPILDL aggregates the computing power of local and network-linked heterogeneous processors (both GPUs and CPUs), to accelerate ILP learning. In terms of hypothesis search, SPILDL employs parallel hypothesis search which is performed by both local and networked (cluster-based) multi-core processors. In terms of hypothesis evaluation, SPILDL outsources hypothesis evaluation task to HT-HEDL, our novel high-performance multi device hypothesis evaluation engine; HT-HEDL aggregates the computing power of multi-CPUs (with their vector instructions) and multi-GPUs to accelerate hypothesis evaluation at the level of a single hypothesis and at the level of multiple hypotheses (a batch of hypotheses). See Fig. 3 and Fig. 2 for HT-HEDL's knowledge and DL hypothesis representation, respectively; HT-HEDL's hypothesis and knowledge representations are optimized for high performance hypothesis evaluation, and with minimal serialization/deserialization overheads (for remote evaluation)."}, {"title": "B. Shared-memory learning", "content": "SPILDL accelerates the hypotheses search for OCEL, by employing parallel (multi-threaded) beam search. SPILDL modifies OCEL's search algorithm in order to exploit parallel computing performance from multi-threaded processors. Even though SPILDL modifies OCEL search algorithm, though it still retains OCEL's ILP learning characteristics; In other words, when SPILDL conducts hypothesis search using only a single thread (i.e. sequential search), it should possess the same ILP learning characteristics as OCEL. The SPILDL algorithm is defined in Algorithm 1.\nIn Algorithm 1, SPILDL maintains an open list (ST) and a closed list (RHT). the reason for using an array for the open list (instead of, for example, a priority queue) is for performance reasons, that is, SPILDL may add large number of hypotheses to the open list at once, with which an array is much more suitable than a sorted hypothesis container; we use parallel sorting (in line 21) on the open list array in order to improve performance, and to avoid potential performance bottleneck due to using sequential (non-parallel) sorting on the open list.\nThe learning starts by getting the best BW nodes from the open list, where BW is set to the number of CPU cores. After the best BW nodes (with highest OCEL score) are extracted, the nodes are then expanded (refined) in parallel by each CPU core. Each CPU core generates refinements for its assigned node (hypothesis), sort each generated refinement's operands (see Fig. 4); sorting refinement's operand, means the reordering of conjunction/disjunction operands (sub DL concepts) to a deterministic order, which will then be used to detect and eliminate weakly-equal hypotheses. When a generated refinement is reordered, a hash value is computed and stored within the refinement for more efficient (faster) redundancy checking. After each CPU core, finished generating its refinements and sorting (their operands), it will then check its refinements' redundancy against the main closed list (RHT).\nOnce all parallel CPU cores complete their hypothesis expansion task (in line 7), a parallel reduction is performed for checking the redundancy of generated refinements (by all CPU cores), against each other to get the final list of non-redundant refinements; see Fig. 5 for the parallel redundancy check. Each CPU core has its local closed list which contains the hash values for its generated refinements (by the step in line 7), these local closed lists are used by the parallel reduction to improve efficiency, by reducing the cost of checking a single refinement to approximately O(1); when CPU corei's refinements are checked against CPU corej's."}, {"title": "C. Cluster-based learning", "content": "We have described SPILDL's shared-memory learning in the previous section, which uses the shared-memory parallel model. Other types of parallel computing models exist as well such as the distributed-memory model, which accelerates computations through remote (networked) processors. SPILDL's cluster-based learning combines the shared and distributed memory models into a hybrid model, in order to maximize performance advantages of each model while minimizing their limitations. In this hybrid model, SPILDL combines both local (multi-threaded) and remote processors to conduct the parallel hypothesis search. For hypothesis evaluation, each machine in the cluster will evaluate its generated refinements using HT-HEDL.\nSPILDL's cluster-based learning follows the master-worker model. In this setup, the master node (machine) manages, coordinates, and assigns work to worker nodes (which also includes collecting their computing results).\nSPILDL's cluster-based learning has 4 phases: discovery, probing, learning and termination phases. In the discovery phase, the master identifies available worker nodes in the network. In the probing phase, the master gauges (or probes) the hypothesis search and evaluation capabilities through a dummy load and then measure its execution time (similar to HT-HEDL's approach). In the learning phase, the master now will conduct the ILP learning assign hypothesis search and evaluation tasks, to each worker based on its computing capabilities. In the next sections, we describe each phase in detail."}, {"title": "1) The discovery phase:", "content": "In the discovery step, the master node broadcasts a message (using a UDP broadcast packet) to all machines (potential workers) in the network cluster, all machines will then replay back with a message to indicate their presence. The master will then establish a TCP connection for each worker (that replied to the broadcast message), and binds it to a dedicated CPU thread in the master's machine; the master node will now have multiple concurrent TCP connections, where each worker has a dedicated TCP connection to the master node. The reason for having multiple concurrent TCP connections, is to maximize the utilization of available network bandwidth (to improve efficiency). Even though these concurrent connections are not actually sending and receiving data in parallel, because they share the same communication channel. However, combining concurrent TCP connections with multi-threading (i.e. each parallel thread will send data through its TCP connection), will saturate the shared communication channel, thus improving the efficiency of network bandwidth."}, {"title": "2) The probing phase:", "content": "In the probing phase, the master will first send (through its TCP connections): TBox, RBox and ABox (in binary forms) to each worker. After all workers have received a copy of the knowledge base, the master will then issue to all workers to expand the top concept (\\(\top\\), also known as 'owl:thing') with horizontal expansion (he = 5). After that, each worker will evaluate its generated refinements through its local HT-HEDL evaluation; the worker will then measure the execution time for the top concept expansion + its refinements evaluation (using HT-HEDL). After that, each worker will reply back to the master with their CPU cores count and the measured execution time (for expansion + evaluation). The reason for expanding the concept and measuring its execution time, is to evaluate hypothesis expansion (or refinement generation) capabilities for each worker; which will then be used to assign appropriate workload sizes for each machine. Once all workers reply back to the master with their probing results, the master machine will count the total number of CPU cores for all workers, and then use it to calculate the scheduling ratio for each worker."}, {"title": "3) The learning phase:", "content": "In the learning phase, similar to shared-memory learning, SPILDL takes the best n nodes in the open list, expands them and evaluate their generated refinements in parallel. However, in cluster-based learning, SPILDL incorporates the multi-core CPUs of all workers in the network. A major challenge in incorporating networked processors to improve computing performance, is the communication overheads, i.e. the network and serialization/deserialization overheads. We have implemented some measures to improve communication performance, such as several concurrent TCP communication channels between the master and workers. In terms of serialization/deserialization, we serialize and deserialize DL hypotheses (represented in HT-HEDL representation) in parallel, to minimize serialization/deserialization overhead. see Fig. 8 for SPILDL's parallel (multi-threaded) serialization/deserialization of hypotheses. Also see Fig. 9 for SPILDL's ILP learning (in a cluster environment).\nIn Fig. 9, the master node maintains the open list and the main closed list, and each worker has its local closed list; the ILP learning starts in the master node. First, the master gets the best n hypotheses from the open list, where n is the total number of CPU cores across all workers (i.e. n = 16). After that, from the best n nodes, each CPU thread in the master will get (in parallel) the best wn hypotheses for each worker, where wn is the number of CPU cores in the worker's machine. Then, each master thread will serialize its wn hypotheses (from their raw HT-HEDL's representation to byte stream representation), and then send it to its corresponding worker.\nAt this point, each worker will proceed similarly to shared-memory learning (discussed previously). However, the worker will receive its wn hypotheses in a raw byte stream (from its TCP connection to the master); The worker will deserialize the received hypotheses (from bytes stream representation to HT-HEDL's representation). Once the hypotheses are in HT-HEDL's form, the worker will expand the hypotheses in parallel through multi-threading, then redundancy checking (through parallel reduction) until the final list of non-redundant refinements are produced. After that, the worker will evaluate its final list of non-redundant refinements using HT-HEDL (combining all CPUs and GPUs in the worker's machine). The worker's evaluated refinements which has non-weak scores are then serialized in parallel through multi-threading by the worker's multi-core processor, and then sent to the master. The master will receive the serialized hypotheses from workers. Once the master receives hypotheses from all workers, it will then deserialize them in parallel, and then will apply parallel redundancy checking against workers' refinements (and against the master's main closed list). The resulting non-redundant and non-weak refinements are then added to the master's open list."}, {"title": "4) The termination phase:", "content": "in the termination phase, if one of the workers reports back to the master with a hypothesis that satisfies the user-defined conditions (e.g. minimal acceptable accuracy, learning timeout), SPILDL will then terminates the learning by broadcasting to all worker nodes to stop learning. After that, workers will send their best discovered hypotheses to the master."}, {"title": "IV. IMPLEMENTATION", "content": "We implement SPILDL in C/C++ language, and we use the OpenMP API [40] for multi-threading in both shared and clustered -environments. For hypothesis evaluation, HT-HEDL is implemented in C/C++, and Nvidia's CUDA API [42] is used for HT-HEDL's GPU-based evaluation. For CPU-based evaluation, HT-HEDL uses the SSE instruction set (available in many x86 and x64 CPU architectures) in combination with OpenMP, to facilitate CPU-based vectorized multi-threaded evaluation. For cluster-based learning, the master and worker machines are connected using TCP/IP networks; the UDP protocol is used for broadcasting messages from the master to worker nodes, and TCP protocol for the set of dedicated (concurrent) connections between the master and each worker. For materializing the TBox and RBox, SPILDL uses the Hermit [41] DL reasoner. To aid SPILDL's implementation, we use the DL-Learner's Java implementation in [43] as a supplementary material, to determine key algorithmic details for the OCEL algorithm."}, {"title": "V. EXPERIMENTS AND DISCUSSION", "content": "In this section, we provide experimental results to evaluate SPILDL's: shared-memory and cluster based learning. For description of the hardware used in the experiments, see Table II. The reported execution times are in milliseconds for all experiments. We use the DL-version of classical ILP datasets (Michalski's trains, Moral reasoner and Carcinogenesis) from the DL-Learner's repository in [43].\nIn terms of ILP learning, we evaluate SPILDL learning using 6 datasets which can be seen in Table III. The 6 datasets vary in size in terms of ABox (which affects hypothesis evaluation), and TBox & RBox (which affects the size and nature of the search space); these datasets will provide a representative measure, which reflects SPILDL's learning performance against real-world applications."}, {"title": "A. The experiments for Shared-memory learning", "content": "We start evaluating SPILDL by studying the effect of different evaluation techniques (CPU, GPU, GPU + CPU, etc.) on learning performance. For all the experiments for SPILDL's shared-memory learning, we use machine 1 (M1), since it has the most computing capabilities as opposed to machine 2 (M2); we also use GPU\u2081 for single GPU evaluation in M\u2081, because it is M\u2081's most powerful GPU.\nSee Table IV for the experimental results on shared-memory learning."}, {"title": "B. The experiments for cluster-based learning", "content": "In the previous experiments, we have extensively evaluated the combinations of parallel search and parallel evaluation on all datasets. In this section, we provide experimental results on SPILDL's cluster-based learning. The main difference between shared-memory and cluster-based learning in SPILDL, is the locality of the CPUs that expands hypotheses. In shared-memory we expand hypotheses using the CPU cores within the same machine, whereas in cluster-based learning, we use TCP/IP networks to link (and communicate with) CPUs of networked machines. In terms of ILP learning, both learning modes (shared-memory & cluster) have the same ILP learning characteristic (as a machine learning algorithm). However, the performance difference (in terms of learning speed) varies, depending on the locality of the CPUs (local vs remote CPUs).\nSince both learning methods have identical machine learning performance, we evaluate cluster-based learning using 2 smallest and 2 largest datasets; where each dataset varies in the size of its search space and its ABox size. See Table VII for a comparison between share-memory learning and cluster-based learning, using sequential search and with parallel evaluation; we have extensively studied the effect of different combinations of parallel search and parallel evaluation in the previous section. In this section (cluster-based learning), we are concerned with studying the effect of communication overhead on learning performance."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "Scalable machine learning is an important capability, that helps constructing powerful Al models in many real-world applications. However, constructing AI models from real-world data is a very challenging task - especially for ILPS-since in many domains (such as e-commerce), the data is inherently large in size (GBs, or even TBs).\nIn the context of this work, we have proposed different parallel approaches to accelerate ILP learning in description logic, which reduced -according to experimental results- the learning time, in addition to the ability of directly handling (real-world) large datasets; our parallel approaches mainly targets hypothesis search and hypothesis evaluation. For hypothesis search, we have provided two parallel search approaches, which accelerates the search using multi-core processors of: a single machine (i.e. shared-memory learning), and multiple networked machines in a cluster. In terms of hypothesis evaluation, we have combined (through HT-HEDL) the aggregated computing power of all multi-core CPUs and GPUs of single machine, to accelerate the evaluation task: for a single hypothesis, and for multiple hypotheses (i.e. batch of hypotheses). All the aforementioned parallel search approaches, uses HT-HEDL on each machine to utilize maximum evaluation performance on that machine.\nAccording to experimental results, parallel search approaches improve performance by up to ~27.3 folds, and parallel evaluation approaches (using HT-HEDL) improves performance by up to 38 folds. When both approaches are combined (i.e. parallel search and parallel evaluation), a speedup of up to ~560 folds is achieved. For cluster-based learning, speedups of up to ~33.4 folds were achieved (using only parallel hypothesis evaluation). In the worst case scenario, using parallel search doesn't always translate into higher search performance. In fact, on some ILP datasets, parallel search introduced performance gains similar or worse than baseline, while on other datasets, parallel search introduced higher performance gains faster than baseline; the parallel search performance is highly affected by the number of parallel search threads, the search space of the ILP dataset. In some ILP datasets, the baseline (sequential) search, provide the best search performance. In terms of worst case scenario for parallel evaluation, the use of parallel evaluation (through HT-HEDL) result in similar or worse performance than baseline for small datasets; because on small datasets, parallel computing overheads are high enough that they cancel out any gained speedups. On the other hand, performance gains are consistently achieved for large datasets, where the achieved speedups vary depending on the used evaluation method.\nFor future directions, in terms of machine learning capabilities (as an ILP learner), SPILDL learning can be extended to include more expressive logics such as first-order-logic (Horn clauses in particular). In addition, we can develop case studies using SPILDL to learn multi-relational models describing variety of real-world concepts."}]}