{"title": "Joint Optimization of Resource Allocation and Data Selection for Fast and Cost-Efficient Federated Edge Learning", "authors": ["Yunjian Jia", "Zhen Huang", "Jiping Yan", "Yulu Zhang", "Kun Luo", "Wanli Wen"], "abstract": "Deploying federated learning at the wireless edge introduces federated edge learning (FEEL). Given FEEL's limited communication resources and potential mislabeled data on devices, improper resource allocation or data selection can hurt convergence speed and increase training costs. Thus, to realize an efficient FEEL system, this paper emphasizes jointly optimizing resource allocation and data selection. Specifically, in this work, through rigorously modeling the training process and deriving an upper bound on FEEL's one-round convergence rate, we establish a problem of joint resource allocation and data selection, which, unfortunately, cannot be solved directly. Toward this end, we equivalently transform the original problem into a solvable form via a variable substitution and then break it into two subproblems, that is, the resource allocation problem and the data selection problem. The two subproblems are mixed-integer non-convex and integer non-convex problems, respectively, and achieving their optimal solutions is a challenging task. Based on the matching theory and applying the convex-concave procedure and gradient projection methods, we devise a low-complexity suboptimal algorithm for the two subproblems, respectively. Finally, the superiority of our proposed scheme of joint resource allocation and data selection is validated by numerical results.", "sections": [{"title": "I. INTRODUCTION", "content": "It is estimated that there will be 29.3 billion networked devices, such as smart phones, pads, wearable devices and other consumer electronics, by 2024 around the world [1]. These devices will inevitably generate huge amounts of data at the wireless edge that can be applicable for multifarious machine learning (ML) tasks, e.g., autonomous driving and product recommendation. Traditional ML algorithms need to expose the raw data to third-party entities for model training, which, however, may compromise data privacy [2]. To tackle such privacy issue, researchers in the field of wireless communications integrate federated leaning with mobile edge computing, thus forming a concept known as federated edge learning (FEEL) [3]\u2013[6]. In the training process of FEEL, the devices must send their local training results such as gradients or model parameters, instead of the raw data, via wireless channels. Since the available radio resources such asbandwidth and time at the network edge are constrained, it is necessary to allocate appropriate radio resources for each device during model training. In addition, the data owned by the devices may be mislabeled in practice, for example, a hand-written digit \"1\" may be labeled as \"0\", and an image \"t-shirt\" may be labeled as \u201ctrouser\u201d. Training ML models on such mislabeled data can seriously deteriorate the convergence of FEEL, so it is necessary to select local data appropriately during model training [7].\nTo date, there have been many research efforts on the resource allocation for FEEL, among which some representative researches are [8]-[23]. Specifically, the authors in [8]-[15] developed an efficient joint device scheduling and wireless resource allocation scheme respectively, aiming to minimize devices' total energy cost [8]\u2013[10] and learning time cost [9], maximize the weighted sum data rate [11], or speed up the convergence of FEEL [12]\u2013[16]. The authors in [17] and [18] established a resource allocation problem to reduce the weighted sum of FEEL training time and total energy cost of all devices. A joint device scheduling and resource management strategy is developed in [19], which can significantly speed up model training and save energy costs. Additionally, a joint optimization of the processing-rate, the uplink Non-orthogonal Multiple Access (NOMA) transmission duration, and the broadcasting duration, as well as the accuracy of the local training was proposed in [20], with the aim of minimizing the system-wise cost including the total energy consumption and the FEEL convergence latency. It is worth noting that excessive energy cost may prevent devices from participating in model training, thus reducing the performance of FEEL. However, how to deal with this issue has not been well studied in the literature [8]-[20]. There are several ways to encourage devices to join in the model training process, such as rewarding the devices appropriately to compensate for their energy costs, as done in [21]\u2013[23]. More specifically, the authors in [21]\u2013[23] proposed to reward all devices based on the number of CPU cycles [21] or the quantity of available training samples [22], [23] that they are willing to contribute, and the greater the contribution, the higher the reward. On this basis, they further focused on how to achieve the desirable resource allocation. Note that the above works have never considered the design of data selection in the FEEL system, so the training algorithm they proposed may not be applicable for scenarios in which some local data are mislabeled.\nAs for the design of the data selection in FEEL, there are not many works in this direction recently, and some representative works include [24]\u2013[28]. Specifically, the work in [24] demonstrated the negative influence of data mislabeling on training performance and proposed an efficient data selectionmethod. The authors in [25] first evaluated the relevance of data samples and then proposed to filter out all irrelevant data before model training. In [26]\u2013[28], the authors built a joint data selection and resource allocation problem to either speed up model training [26] or minimize the energy cost of FEEL [27], [28]. Note that although the above works in [24]\u2013[28] have proposed several efficient schemes to speed up model training and reduce the cost of the FEEL system from various perspectives, there are still some limitations. First, the works in [24] and [25] overlooked the resource allocation of the FEEL system. Second, the authors in [26]\u2013[28] did not analyze the convergence of the training process. Third, the studies in [24]-[28] assumed that all devices can always participate in model training, which, however, may not hold in practice, since the edge devices may fail to upload local gradients due to the loss of connections. As a result, the proposed schemes therein may not be suitable for practical FEEL systems.\nIn this work, we would like to address the above issues. We investigate a generic FEEL system consisting of multiple devices and an edge server, where each device connect to the server via wireless channels. It is worth noting that to simulate the practical scenarios, we assume that the devices may not always be available to connect to the server. In addition, some devices may be not willing to conduct model training due to the high energy cost. Thus, to entice devices to join in model training, the server will reward the devices to compensate for the energy cost. Particularly, in the FEEL system, we consider that the communication resources are limited and each device may have some mislabeled data samples. On these bases, we would like to analyze the convergence of FEEL and jointly optimize the resource allocation and data selection to speed up model training while reducing the net cost (i.e., the energy cost minus the reward) of all devices. Our contributions are listed below."}, {"title": "II. SYSTEM MODEL", "content": "We investigate a generic FEEL system, which consists of one edge server and $K$ devices, as depicted in Fig. 1. To maintain the simplicity of analysis and optimization, we assume that both the BS and devices are equipped with a single antenna. Let $\\mathcal{K} = {1,2,\\ldots,K}$ denote the user set. Note that we assume that all devices are legitimate, with no malicious devices. Let $D_k = {(\\mathbf{x}_j, y_j)}$ denote the dataset of the $k$-th device. Here, $\\mathbf{x}_j \\in \\mathbb{R}^d$ is the $d$-dimensional data sample, $y_j \\in \\mathbb{R}$ denotes the data label, and $|\\cdot|$ depicts the cardinality of a set. We define $D = \\bigcup_{k \\in \\mathcal{K}}D_k$ as the whole dataset resided on all devices. Table I summarized the main notations used in this paper.\nLearning Model\nThe FEEL system can learn an ML model $\\mathbf{w} \\in \\mathbb{R}^d$ over the datasets of all devices by solving the problem below\n$\\mathbf{w}^* = \\arg \\min_{\\mathbf{w}} L(\\mathbf{w}).$ (1)\nHere, $L(\\mathbf{w}) = \\sum_{k \\in \\mathcal{K}} \\frac{|D_k|}{|D|} L_k(\\mathbf{w})$ is the loss function with\n$L_k(\\mathbf{w}) = \\frac{1}{|D_k|} \\sum_{j \\in D_k} l(\\mathbf{w}, \\mathbf{x}_j, y_j),$ (2)\ndenoting the loss function for device $k$ and $l(\\cdot)$ being an appropriate sample-wise loss function.\nTraining an ML model in the FEEL system usually is an iterative procedure, in which the iteration is also known as the communication round. Define $\\mathbf{w}^{(i)}$ to be the global model at round $i = 1, 2, \\ldots$ Then, the training process of FEEL at each round consists of three stages, i.e., Local Gradient Computing, Local Gradient Uploading, and Global Model Updating. We will detail these stages in the following subsections.\nLocal Gradient Computing\nThe $k$-th device will compute the local gradient, denoted by $\\mathbf{g}_k$, of $L_k(\\mathbf{w})$ at $\\mathbf{w} = \\mathbf{w}^{(i)}$, where $\\mathbf{w}^{(i)}$ is received fromthe edge server. The computed gradient $\\mathbf{g}_k$ is uploaded to the server subsequently in the stage of Local Gradient Uploading. Note that, most of the current literature on FEEL implicitly assumes that the device's data samples are always labeled correctly [8], [10]\u2013[14], [16]\u2013[20], and thus the gradient $\\mathbf{g}_k^{(i)}$ is\n$\\mathbf{g}_k^{(i)} = \\nabla L_k(\\mathbf{w}^{(i)}) = \\frac{1}{|D_k|} \\sum_{(\\mathbf{x}_j,y_j) \\in D_k} \\nabla l(\\mathbf{w}^{(i)}, \\mathbf{x}_j, y_j), \\ \\forall k \\in \\mathcal{K}$ (3)\nwhere $\\mathbf{g}_{k,j}^{(i)} = \\nabla l(\\mathbf{w}^{(i)}, \\mathbf{x}_j, y_j)$ and $L_k(\\mathbf{w}^{(i)})$ is given by (2). Nevertheless, in practice, some data samples in $D_k$ may be mislabeled, for example, a hand-written digit \"1\" may be labeled as \"O\", and an image \"t-shirt\" may be labeled as \"trouser\". Such mislabeling may degenerate the training performance of FEEL if directly sending $\\mathbf{g}_k^{(i)}$ in (3) to the edge server. To this end, we consider a data selection design, in which only a subset $\\mathcal{M}_k^{(i)}$ of the data samples in $D_k$ are selected to compute the local gradient. Specifically, a subdataset is first sampled from $D_k$ with size $|D_k|$, where $D_k \\subseteq D_k$. Then, the gradient norm square of each data sample in $D_k$ is computed and sent to the BS. On this basis, a subset $\\mathcal{M}_k^{(i)}$ is chosen from $D_k$ to compute the local gradient. On this basis, with a slight abuse of notation, we reexpress (3) as\n$\\hat{\\mathbf{g}}_k^{(i)} = \\frac{1}{|\\mathcal{M}_k^{(i)}|} \\sum_{(\\mathbf{x}_j,y_j) \\in \\mathcal{M}_k^{(i)}} \\mathbf{g}_{k,j}^{(i)}, \\ \\forall k \\in \\mathcal{K}$ (4)\nwhere $\\mathcal{M}_k^{(i)}$ satisfies the following constraints\n$\\mathcal{M}_k^{(i)} \\subseteq D_k, \\ \\forall k \\in \\mathcal{K},$ (5)\n$\\mathcal{M}_k^{(i)} \\neq \\emptyset, \\ \\forall k \\in \\mathcal{K}.$ (6)\nLet $\\mathcal{M}^{(i)} = {\\mathcal{M}_k^{(i)}}_{k \\in \\mathcal{K}}$ denote the data selection design. Note that the data selection design $\\mathcal{M}^{(i)}$ can be applicable in smart healthcare systems for disease diagnosis [5] and inautonomous vehicles for enhanced driving process safety [6]. After completing the local gradient calculation, device $k$ will send the local gradient $\\hat{\\mathbf{g}}_k^{(i)}$ given in (4) instead of (3) to the edge server.\nAs done in [22] and [4], to compensate for the cost of user participation in training and attract them to participate in model training, we consider that the server will reward each device. Let $q_k$ denote the reward per data sample for device $k$. Then, the total reward received by all devices in $\\mathcal{K}$ is\n$R(\\mathcal{M}^{(i)}) = \\sum_{k \\in \\mathcal{K}} q_k |\\mathcal{M}_k^{(i)}|.$ (7)\nOn the other hand, the local calculation will consume a certain amount of energy of each device. To be specific, we define $F_k$ as the CPU computational power required by device $k$ to compute the gradient norm square of a single data sample, which is quantified in terms of CPU cycles per sample. Concurrently, let $f_k$ denote the CPU frequency of device $k$, measured in CPU cycles per second. Then, the computation time at device $k$ for computing the gradient norm square of the data samples in $D_k$ is given by\n$T_k = \\frac{F_k|D_k|}{f_k}, \\ \\forall k \\in \\mathcal{K}.$ (8)\nBased on [29], the energy consumption for gradient computing at device $k$ is\n$E_k^{cmp} = \\kappa \\frac{F_k|D_k|}{f_k^2}, \\ \\forall k \\in \\mathcal{K}.$ (9)\nHere $\\kappa$ denotes the energy capacitance coefficient which is dependent on the chip architecture. Let $c_k$ denote the cost per unit energy consumption of device $k$. Thus, the total cost ofperforming gradient computing on all devices is given by\n$C^{cmp} = \\sum_{k \\in \\mathcal{K}} c_k E_k^{cmp}.$ (10)\nLocal Gradient Uploading\nIn this stage, each device needs to submit its gradient to the edge server. Due to the resource limitation of wireless transmission, we consider a grant-based NOMA system that has a set $\\mathcal{N} = {1,2,\\ldots,N}$ of $N$ resource blocks (RBs). To support the gradient uploading, these RBs in $\\mathcal{N}$ should be carefully allocated to the devices in $\\mathcal{K}$. Define $p_{k,n}^{(i)}$ to be the RB assignment indicator, where $p_{k,n}^{(i)} = 1$ indicates that the $n$-th RB is assigned to the $k$-th device, and $p_{k,n}^{(i)} = 0$, otherwise. Consider that each RB can be allocated to $Q \\ge 1$ devices at most, while each device can occupy only one RB [30], [31], i.e., the following constraints should be satisfied\n$p_{k,n}^{(i)} \\in {0,1}, \\ \\forall k \\in \\mathcal{K}, \\forall n \\in \\mathcal{N},$ (11)\n$\\sum_{k \\in \\mathcal{K}} p_{k,n}^{(i)} \\le Q, \\ \\forall n \\in \\mathcal{N},$ (12)\n$\\sum_{n \\in \\mathcal{N}} p_{k,n}^{(i)} \\le 1, \\ \\forall k \\in \\mathcal{K}.$ (13)\nAdditionally, as mentioned earlier, not all devices are available to transmit their gradients to the server. To reflect such behavior, let $\\alpha_k \\in {0,1}$ denote device $k$'s availability state, where $\\alpha_k = 1$ indicates that device $k$ can be available to upload its gradient $\\hat{\\mathbf{g}}_k^{(i)}$, and $\\alpha_k = 0$, otherwise. Then, we reform the uploaded local gradient of device $k$ as $\\alpha_k \\hat{\\mathbf{g}}_k^{(i)}$, and the following constraint should be satisfied\n$p_{k,n}^{(i)} \\le \\alpha_k^{(i)}, \\ \\forall k \\in \\mathcal{K}, \\forall n \\in \\mathcal{N}.$ (14)\nAccording to the NOMA transmission protocol [32]-[35], the uplink signals from the devices occupying the same RB will be superposed. Let $\\mathcal{S}_n^{(i)}$ denote the set of devices occupying RB $n$. Then, the received signal at the edge server on RB $n$ can be expressed as\n$\\mathbf{u}_n^{(i)} = \\sum_{k \\in \\mathcal{S}_n^{(i)}} \\sqrt{p_{k,n}^{(i)} P_{k,n}^{(i)}} h_{k,n}^{(i)} \\mathbf{v}_{k,n}^{(i)} + \\mathbf{m}, \\ \\forall n \\in \\mathcal{N},$ (15)\nwhere $\\mathbf{v}_{k,n}^{(i)}$ denotes the signal transmitted from device $k$ on the $n$-th RB with $\\mathbb{E}\\{|\\mathbf{v}_{k,n}^{(i)}|^2\\} = 1$ and $\\mathbb{E}\\{ \\cdot \\}$ being the expectation operator, $h_{k,n}^{(i)}$ is the channel power gain of device $k$ on RB $n$, $\\mathbf{m}$ denotes the zero-mean Gaussian noise with variance $N_0$, $P_{k,n}^{(i)}$ denotes the transmission power of device $k$ on RB $n$. Let $P_k^{max}$ represent the maximum power limit of device $k$. Then, we have\n$0 \\le P_{k,n}^{(i)} \\le p_{k,n}^{(i)} P_k^{max}, \\ \\forall k \\in \\mathcal{K}, \\forall n \\in \\mathcal{N},$ (15)\nWe consider that the successive interference cancellation is applied at the edge server. Specifically, for each RB, the edge server first decodes the signal from the device with the highest channel power gain and treats the signals of others as interference. Then, the edge server subtracts the decoded signal from the superposed signal. This iterative process continues until the signals from all users have beensuccessfully decoded. On this basis, we can calculate the achievable rate of device $k$ on RB $n$ as follows, $r_{k,n}^{(i)} = B \\log_2 \\left( 1 + \\frac{p_{k,n}^{(i)} P_{k,n}^{(i)} |h_{k,n}^{(i)}|^2}{\\sum_{\\substack{t \\in \\mathcal{S}_n^{(i)}, t \\neq k}} p_{t,n}^{(i)} P_{t,n}^{(i)} |h_{t,n}^{(i)}|^2 + N_0} \\right), \\ \\forall k \\in \\mathcal{K}, \\ \\forall n \\in \\mathcal{N}.$ Here, $B$ represents the bandwidth of each RB and $1[\\cdot]$ denotes an indicator function. Let $L$ and $T$ represent the size of the local gradient $\\hat{\\mathbf{g}}_k^{(i)}$ in (4) and the time duration for gradient uploading, respectively. To ensure that $\\hat{\\mathbf{g}}_k^{(i)}$ can be uploaded to the server successfully, we have\n$\\sum_{n \\in \\mathcal{N}} r_{k,n}^{(i)} T \\ge \\alpha_k^{(i)} L, \\ \\forall k \\in \\mathcal{K}.$ (16)\nFinally, the energy consumption of device $k$ for local gradient uploading is $E_k^{com}(\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}) = \\sum_{n \\in \\mathcal{N}} P_{k,n}^{(i)} T$, and the total cost of performing local gradient uploading from all devices can be expressed as\n$C^{com}(\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}) = \\sum_{k \\in \\mathcal{K}} c_k E_k^{com}(\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}),$ (17)\nwhere $\\mathbf{p}^{(i)} = {p_{k,n}^{(i)}}_{k \\in \\mathcal{K}, n \\in \\mathcal{N}}$ and $\\mathbf{P}^{(i)} = {P_{k,n}^{(i)}}_{k \\in \\mathcal{K}, n \\in \\mathcal{N}}$ denote the design parameters of RB assignment and transmission power allocation, respectively. Finally, based on the reward in (7), and the total costs in (10) and (17), we can compute the net cost (i.e., the energy cost minus the reward) of all devices as follows.\n$C(\\mathcal{M}^{(i)}, \\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}) = C^{com}(\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}) + C^{cmp} - R(\\mathcal{M}^{(i)}).$ (18)\nGlobal Model Updating\nIn this stage, by aggregating the gradients from the devices, the edge server will generate a new global model for the next round of model training. Let $\\mathbb{E}_k = \\Pr[\\alpha_k = 1]$ denote the probability that device $k$ is available to submit its local gradient. Then, we propose that at round $i$, the server aggregates the local gradients based on\n$\\mathbf{g}^{(i)} = \\frac{1}{|D|} \\sum_{k=1}^K \\frac{|D_k|\\mathbb{E}_k}{\\sum_{k=1}^K |D_k|\\mathbb{E}_k} \\alpha_k \\hat{\\mathbf{g}}_k^{(i)},$ (19)\nwhere $D = \\sum_{k=1}^K D_k$, and $\\mathbf{g}^{(i)}$ denotes the global gradient generated on the edge server side.\nThe following lemma shows the unbiasedness of $\\mathbf{g}^{(i)}$, which can greatly facilitate us to prove FEEL's convergence rate.\nLemma 1. The expectation of $\\mathbf{g}^{(i)}$ is equal to the ground-truth gradient $\\mathbf{g}^{(i)} = \\nabla V L(\\mathbf{w}^{(i)})$.\nThe proof can be found in Appendix A. Based on (19), the edge server generates a new global model $\\mathbf{w}^{(i+1)}$ for the next round of model training according to\n$\\mathbf{w}^{(i+1)} = \\mathbf{w}^{(i)} - \\eta^{(i)} \\mathbf{g}^{(i)}.$ (20)\nHere, $\\eta^{(i)} > 0$ denotes the learning rate at round $i$.\nConvergence Analysis\nThe above three stages will be repeated several times until FEEL converges. We now analysis the convergence behaviour"}, {"title": "III. PROBLEM FORMULATION AND TRANSFORMATION", "content": "In the sequel, we first establish a joint resource allocation and data selection problem. Then, we conduct some necessary transformations to facilitate solving the original problem.\nProblem Formulation\nAccording to (18) and (21), we see that the variables $(\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)})$ and $\\mathcal{M}^{(i)}$ can affect both the convergence of FEEL and the net cost of all devices. Therefore, a question naturally arises: how to design an appropriate joint resource allocation and data selection scheme to accelerate the convergence of FEEL while minimizing the net cost of all devices? To answer this question, the following problem is established.\nProblem 1 (Joint Resource Allocation and Data Selection).\n$\\min_{\\mathcal{M}^{(i)},\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}} \\Delta(\\mathcal{M}^{(i)}) + (1 - \\lambda)C(\\mathcal{M}^{(i)}, \\mathbf{p}^{(i)}, \\mathbf{P}^{(i)})$s.t. (5), (6), (11), (12), (13), (14), (15), (16).\nwhere $\\sigma_{k,j}^{(i)} = ||\\mathbf{g}_{k,j}^{(i)}||^2.$\nProblem 1 should be tackled on the server side, not on the device side. In particular, due to the constraints in (5) and (6), all users' local data should be uploaded to the server when solving Problem 1. However, to protect data privacy, FEEL does not allow the server to directly access the raw data of each device, so Problem 1 cannot be solved at the edge server. In the following subsection, we will transform Problem 1 into a solvable form through variable substitution. Subsequently, we will decompose it into two subproblems. Due to the transformation, the server can address Problem 1 without compromising user data confidentiality.\nProblem Transformation\nLet $\\delta_{k,j}^{(i)} \\in {0, 1}$ denote the data selection indicator, where $\\delta_{k,j}^{(i)} = 1$ represents that the $j$-th data sample in $D_k$ is selected into the set $\\mathcal{M}_k^{(i)}$, and $\\delta_{k,j}^{(i)} = 0$, otherwise. Define the variable $\\bm{\\delta}^{(i)} = {\\delta_{k,j}^{(i)}}_{k \\in \\mathcal{K}}$, where $\\bm{\\delta}_k^{(i)} = {\\delta_{k,j}^{(i)}}_{j \\in \\mathcal{I}_k}$ and $\\mathcal{I}_k = {1,2,\\ldots, |D_k|}$. Then, by replacing $\\mathcal{M}_k^{(i)}$ with $\\bm{\\delta}^{(i)}$, we transform Problem 1 into an equivalent problem as follows.\nProblem 2 (Joint Resource Allocation and Data Selection).\n$\\min_{\\bm{\\delta}^{(i)},\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}} \\Delta(\\bm{\\delta}^{(i)}) + (1 - \\lambda)\\hat{C}(\\bm{\\delta}^{(i)}, \\mathbf{p}^{(i)}, \\mathbf{P}^{(i)})$s.t. (11), (12), (13), (14), (15), (16),\n$\\delta_{k,j}^{(i)} \\in {0,1}, \\ \\forall j \\in \\mathcal{I}_k, \\ \\forall k \\in \\mathcal{K},$ (24)\n$0 < \\sum_{j \\in \\mathcal{I}_k} \\delta_{k,j}^{(i)} < |D_k|, \\ \\forall k \\in \\mathcal{K},$ (25)\nwhere $\\hat{\\Delta}(\\bm{\\delta}^{(i)})$ is given in (26), shown at the bottom of next page, and the net cost of devices is given by\n$\\hat{C}(\\bm{\\delta}^{(i)}, \\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}) = C^{com}(\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}) + C^{cmp} - \\sum_{k \\in \\mathcal{K}} \\alpha_k \\sum_{j \\in \\mathcal{I}_k} \\delta_{k,j}^{(i)}.$ (27)\nCompared to the original Problem 1, Problem 2 is a solvable problem, since it is only required to send the cardinality of $D_k$ to the server, instead of $D_k$ itself. Nonetheless, it is still difficult to achieve an optimal point of Problem 2 for the following reasons. First, the variables $\\mathbf{p}^{(i)}$ and $\\bm{\\delta}^{(i)}$ are binary. Second, the objective function and the constraint in (16) are non-convex. Thus, Problem 2 is recognized as a highly challenging mixed-integer non-convex problem. To tackle Problems 3, we decompose Problem 2 into it and 4 equivalently.\nProblem 3 (Resource Allocation Problem).\n$\\min_{\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}} C^{com}(\\mathbf{p}^{(i)}, \\mathbf{P}^{(i)}) + C^{cmps.t. (11), (12), (13), (14), (15), (16)."}, {"title": "IV. SOLUTION OF PROBLEM 3", "content": "Like Problem 2", "Formulation": "To rationally utilize the limited communication resources", "Detail": "Motivated by the housing assignment problem in [37", "follows": "Psi_0 \\rightarrow \\Psi_1 \\rightarrow \\Psi_2 \\rightarrow \\ldots$", "model.\nConvergence": "Psi_{l"}, "respectively. Then, we have $\\hat{C}_{l} < \\hat{C}_{l-1}$, namely, the net cost decreases after the swap. Since there is a certain positive net cost to the available devices to guarantee the successful uploading of the local gradients, the net cost has a lower bound, which implies that Algorithm 2 will converge after a finite number of swapping operations.\nFinally, we discuss the computational com- plexity of Algorithm 2. For each swapping operation, we should consider all possible swapping combinations, which requires $O(|\\mathcal{U}^{(i)}|^2)$ operations. For each swapping attempt, we need to allocate the power, and calculate and compare the net cost before and after the swapping of the available devices under the given RB assignment. Let $O(X)$ represent the complexity of the power allocation algorithm (i.e., Algo- rithm 3), which will be analyzed in Section IV-B. Assume that the matching remains unchanged after $V$ swapping oper- ations. Then, the computational complexity of Algorithm 2 is $O(|\\mathcal{U}^{(i)}|^2VX)$.\nComplexity:\nPower Allocation\nIn line 6 of Algorithm 2, the net cost is minimized by optimizing the power allocation under a given RB assignment via Algorithm 3. In this subsection, we focus on how to construct Algorithm 3. Given the RB assignment, Problem 3 becomes the problem in (28), shown at the top of next page. Due to the non-convexity of the constraint in (29), the problem in (28) is a non-convex problem. To solve it in a more tractable manner, we perform some transformations as detailed below.\nSpecifically, we assume that the devices in the set $\\mathcal{S}_n^{(i)}$ occupying RB $n$ are arranged in ascending order according to their channel power gains. Then, the term $\\sum_{t \\in \\mathcal{S}_n^{(i)}} 1[|h_{t,n}^{(i)}|^2 < |h_{k,n}^{(i)}|^2"]}