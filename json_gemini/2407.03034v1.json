{"title": "ATTENTION INCORPORATED NETWORK FOR SHARING\nLOW-RANK, IMAGE AND K-SPACE INFORMATION DURING MR\nIMAGE RECONSTRUCTION TO ACHIEVE SINGLE BREATH-HOLD\nCARDIAC CINE IMAGING", "authors": ["Siying Xu", "Kerstin Hammernik", "Andreas Lingg", "Jens K\u00fcbler", "Patrick Krumm", "Daniel Rueckert", "Sergios Gatidis", "Thomas K\u00fcstner"], "abstract": "Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment of heart mor-\nphology and function in clinical practice. However, MRI requires long acquisition times, with recent\ndeep learning-based methods showing great promise to accelerate imaging and enhance reconstruc-\ntion quality. Existing networks exhibit some common limitations that constrain further acceleration\npossibilities, including single-domain learning, reliance on a single regularization term, and equal\nfeature contribution. To address these limitations, we propose to embed information from multiple\ndomains, including low-rank, image, and k-space, in a novel deep learning network for MRI recon-\nstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch structure, enabling\nindependent learning in the k-space and image domain. Coupled information sharing layers realize\nthe information exchange between domains. Furthermore, we introduce attention mechanisms into\nthe network to assign greater weights to more critical coils or important temporal frames. Train-\ning and testing were conducted on an in-house dataset, including 91 cardiovascular patients and 38\nhealthy subjects scanned with 2D cardiac Cine using retrospective undersampling. Additionally, we\nevaluated A-LIKNet on the real-time 8\u00d7 prospectively undersampled data from the OCMR dataset.\nThe results demonstrate that our proposed A-LIKNet outperforms existing methods and provides\nhigh-quality reconstructions. The network can effectively reconstruct highly retrospectively under-\nsampled dynamic MR images up to 24\u00d7 accelerations, indicating its potential for single breath-hold\nimaging.", "sections": [{"title": "1 Introduction", "content": "For cardiovascular disease identification, an accurate analysis of cardiac function and anatomy is required. Cine mag-\netic resonance imaging (MRI) is commonly used in clinical practice as a non-invasive and radiation-free assessment\nof the structural dynamics over the cardiac cycle. However, conventional multi-slice 2D cardiac Cine is acquired un-\nder multiple breath-holds, which not only results in a longer acquisition time but also causes patient discomfort and\nrespiratory-induced slice misalignments. Therefore, numerous efforts have been made to accelerate cardiac Cine MRI\nover the past decades."}, {"title": "2 Methodology", "content": "In this section, we will first introduce the mathematical background of the proposed A-LIKNet in Sec. 2.1, explaining\nhow we formulate and solve the MR image reconstruction problem. In Sec. 2.2, we will describe how we transform\nthe mathematical expressions into the various components of our proposed A-LIKNet."}, {"title": "2.1 Problem formulation", "content": "Let $x \\in C^n$ be the desired fully-sampled complex-valued dynamic MR image stacked as a vector, with n being the\nnumber of pixels in x. Let $y_u \\in C^m$ denote the undersampled measurements in k-space, with m being the number of\nsampled k-space points and m < n. The forward model links x and $y_u$:\n$y_u = Ax,                                                          \\text{(1)}$\nwhere the encoding operator $A \\in C^{m \\times n}$ is describing the MR imaging operations:\n$A = MFS.                                                          \\text{(2)}$\nHere, S refers to the coil sensitivity maps of the multi-coil imaging scenario, F is the Fourier transform operator, and\nM denotes the binary undersampling trajectory. As the sampling process violates the Nyquist-Shannon theorem, the\nreconstruction problem in which we try to recover the image x from the acquired k-space $y_u$ is ill-posed. To solve this\nproblem, we transform the reconstruction into a regularized reconstruction problem:\n$\\arg \\min_x \\frac{1}{2} \\| Ax - y_u \\|_2^2 +\\lambda R (x),\\qquad\\text{(3)}$\nwhere $\\lambda$ weights the contribution of the regularization term $R(\\cdot)$. In general, Total Variation and $l_1$-norm on the image\nx are used as the sparse regularization $R(\\cdot)$. In dynamic MRI, low-rankness is an additional important prior that can"}, {"title": "2.2 Components of A-LIKNet", "content": "The overall architecture of A-LIKNet is shown in Fig. 1, which is built as a physics-based unrolled reconstruction\nnetwork and consists of an image branch (Sec. 2.2.1), a k-space branch (Sec. 2.2.2), and information sharing layers\n(Sec 2.2.3) between these two branches."}, {"title": "2.2.1 Image branch", "content": "The image branch is constructed to solve Eq. 4 and consists of an image subnetwork, a low-rank subnetwork, and a\ndata consistency layer. By introducing auxiliary variables $p \\in C^n$ and $q \\in C^n$, Eq. 4 can be equivalently written as:\n$x = \\arg \\min_x \\frac{1}{2} \\| Ax - y_u \\|_2^2 +\\lambda_s R_s (p) + \\lambda_l R_l (q)\\\\\\ \\text{s.t.} \\ \\ \\ p = x, q = x,\\qquad\\text{(7)}$\nwhich can be transformed into the unconstrained Lagrangian function using half quadratic splitting (HQS) with auxil-\niary variables $\\mu_1$ and $\\mu_2$:\n$L_{\\mu_1,\\mu_2} (x, p, q) = \\frac{1}{2} \\| Ax - y_u \\|_2^2 +\\lambda_s R_s (p) + \\lambda_l R_l (q) + \\frac{\\mu_1}{2} \\| p-x \\|_2^2+\\frac{\\mu_2}{2} \\| q-x \\|_2^2.\\qquad\\text{(8)}$\nThis problem can be solved iteratively to obtain the following sub-problems:\n$\\begin{cases}\np_{n+1} = \\arg \\min_p \\frac{\\mu_1}{2} \\| p - x_n \\|_2^2 + \\lambda_s R_s (p)\\\\\nq_{n+1} = \\arg \\min_q \\frac{\\mu_2}{2} \\| q - x_n \\|_2^2 + \\lambda_l R_l (q)\\\\\nx_{n+1} = \\arg \\min_x \\frac{1}{2} \\| Ax - y_u \\|_2^2+\\frac{\\mu_1}{2} \\| p_{n+1}-x \\|_2^2 + \\frac{\\mu_2}{2} \\| q_{n+1}-x \\|_2^2.\\end{cases}\\qquad\\text{(9)}$\nTo solve $p_n$, we introduce an image subnetwork $H_n$, a convolutional neural network (CNN) designed to learn a sparse\nprior for the given current image $x_{n-1}$. $H_n$ intends to reconstruct local information on a coarse-to-fine scale. To\nadaptively learn a low-rank prior to solve $q_n$, we design a low-rank subnetwork, denoted as $L_n$. The subnetwork $L_n$\ndecomposes a given $x_{n-1}$ into local spatial-temporal patches and learns the singular value threshold for each patch\nto constrain the low-rank nature. Following the updates of p and q, the data consistency operator $DC_{I,n}$ will be\nemployed to compute the output $x_n$ for the current iteration, ensuring data fidelity. The subscript I indicates the DC\nlayer operation in the image domain. With the learnable image subnetwork $H_n$, the low-rank subnetwork $L_n$, and the\ndata consistency layer $DC_{I,n}$, the equations in Eq. 9 can be reformulated as follows:\n$\\begin{cases}\np_n = H_n(x_{n-1})\\\\q_n = L_n(X_{n-1})\\\\x_n = DC_{I,n}(p_n, q_n),\\end{cases}\\qquad\\text{(10)}$\nwhere $n \\in \\{1, ..., N\\}$, with N being the total iteration number or unrolls of the network modules."}, {"title": "2.2.2 K-space branch", "content": "The k-space branch is dedicated to solving Eq. 5 and comprises a k-space subnetwork and a k-space data consistency\nlayer. By introducing an auxiliary variable r, Eq. 5 can be transformed into the unconstrained Lagrangian function\nusing HQS:\n$L_{\\mu_k} (y, r) = \\frac{1}{2} \\|My - y_u\\|_2^2 + \\lambda_k R_k(r) + \\frac{\\mu_k}{2} \\|r - y\\|_2^2, \\qquad\\text{(16)}$\nwhich can be solved iteratively:\n$\\begin{cases}\nr_{n+1} = \\arg \\min_r \\lambda_k R_k(r) + \\frac{\\mu_k}{2} \\|r - y_n\\|_2^2\\\\y_{n+1} = \\arg \\min_y \\frac{1}{2} \\|My - y_u\\|_2^2 + \\frac{\\mu_k}{2} \\|r_{n+1} - y\\|_2^2 \\end{cases}\\qquad\\text{(17)}$\nSimilarly, we use a CNN, $K_n$, operating in k-space to learn the generalized k-space prior (similar to a GRAPPA-\nbased PI) [22] and perform data consistency in k-space to update $y_{n+1}$. Then, Eq. 17 can be formulated as learnable\nnetworks:\n$\\begin{cases}\nr_n = K_n(y_{n-1})\\\\y_n = DC_{K,n}(r_n),\\end{cases}\\qquad\\text{(18)}$"}, {"title": "2.2.3 Information sharing layer", "content": "In the problem formulation Sec. 2.1, we have introduced the derivation of Eq. 6, which is implemented by the informa-\ntion sharing layer (ISL). The inputs to the ISL at the nth iteration are $x_n$ and $y_n$ from the image and k-space branches.\nTo satisfy Eq. 6, they can be expressed as follows:\n$\\begin{cases}\ny_n = a \\cdot (FSx_n) + (1 - a) \\cdot y_n\\\\x_n = b \\cdot ((FS)^Hy_n) + (1 -b) \\cdot x_n,\\end{cases}\\qquad\\text{(20)}$\nwhere a and b are real numbers with a, b \u2208 [0, 1]. As previously explained, achieving perfect consistency between $x_n$\nand $y_n$ can be challenging due to the inherent instability in the network training. Therefore, we set a and b in Eq. 20\nas trainable parameters, and Eq. 20 becomes the update rule of the ISL.\nIn conclusion, a single iteration of the proposed A-LIKNet consists of (1) an image branch which includes an image\nsubnetwork learning the sparse prior, a low-rank subnetwork enforcing local spatial-temporal low-rankness, and an\nimage DC layer; (2) a k-space branch which is comprised of a k-space subnetwork learning the k-space regularization\nand a k-space DC layer; (3) an information sharing layer which exchanges and combines information from the two\ndomains. Notably, the network weights are not shared across iterations, enabling each iteration to operate at different\nnoise and artifact levels."}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Database", "content": "The dataset used in our experiments contains in-house 2D cardiac Cine, which was acquired on a 1.5T MRI scanner\n(MAGNETOM Aera, Siemens Healthineers, Erlangen, Germany) with a balanced steady-state free processing (bSSFP)\nsequence. The imaging protocol ensured left ventricular coverage, achieved through multiple consecutive breath-holds.\nThe total scan time ranges between 122s and 611s, primarily falling within the range of 122s to 266s, depending on\nthe number of slices and physiological characteristics of the patients. Data was recorded with flexible 18-channel\nbody and 32-channel spine coils, resulting in 30 MR receiver channels. The sequence parameters are as follows:\nTE/TR=1.06/2.12ms, flip angle=52\u00b0, bandwidth=915 Hz/px, spatial resolution=1.9\u00d71.9mm\u00b2, slice thickness=8mm.\nThe acquired data has a temporal resolution of 40ms, encompassing 25 cardiac phases spanning a complete cardiac\ncycle. The database includes 129 subjects, amongst which are 38 healthy subjects and 91 patients with various cardio-\nvascular diseases. We split the dataset into 115 subjects for training, including 34 healthy volunteers and 86 patients.\nThe remainder of the dataset was used for testing. The study was approved by the local ethics committee, and all\nsubjects gave written consent."}, {"title": "3.2 Implementation details", "content": "The number of filters in the image sub-network starts from 12 for each UNet, which is doubled after the pooling\nlayer in the encoder and halved after the up-sampling layer in the decoder. We use the 3D max pooling with pooling\nsize 2 for the down-sampling operations and implement the up-sampling by a 3D transpose convolution with kernel\nsize=1 and strides=2. For 2D spatial convolution, we employ a kernel size of 5\u00d75, while for temporal convolution and\nk-space convolution, the kernel size is set to 3. We employ the complex-valued ModReLU activation [52] function as\nthe nonlinear activation function.\nThe hyperparameters used in A-LIKNet are set as follows: the trainable low-rank threshold coefficient $T_i$ in Eq. 12\nis initialized as -2 for each local spatial-temporal patch. For the patch-wise low-rank subnetwork, we choose the\nbest performance patch size, which divides the total T=25 frames into $(n_t, n_x, n_y) = (5, 4, 4)$ groups, implying that\neach spatial-temporal patch contains five frames with 1/16 original spatial size. The trainable parameter $\\alpha$ in Eq. 14\nis initialized as 0.5, meaning that the outputs of the image and the low-rank subnetworks have the same contribution\nto the DC layer at the start of training. Additionally, the trainable weights $\\eta$ (Eq. 15) and $\\mu_k$ in the k-space data\nconsistency layer (Eq. 19) are initialized as 1.0. Furthermore, to set the same importance of the k-space and image\nbranches at the start of training, we initialize the scaling factors a and b in the information sharing layer (Eq. 20) as\n0.5. The proposed A-LIKNet iterates N=8 times in total, resulting in 2,477,961 trainable parameters.\nWe train A-LIKNet in a supervised manner. During training, the network aims to minimize the pixel-wise mean\nabsolute error (MAE) between the reconstructed k-space/image and the corresponding fully-sampled k-space/image.\nFor complex-valued outputs, the loss function is calculated as follows:\n$\\mathcal{L}_{tot} = L_I + L_K\\\\= \\frac{1}{PS}\\sum_{s=1}^S\\sum_{p=1}^P(d_{i,sp}^*\\cdot d_{i,sp} +d_{k,sp}^*\\cdot d_{k,sp}), \\qquad\\text{(21)}$\nwhere $L_I$ is the image branch loss, $L_K$ is the k-space branch loss, $d_{i,sp} = x_{sp} - x_{ref,sp}$ is the difference between\nthe reconstructed image and the fully-sampled image at the $p^{th}$ pixel of the $s^{th}$ subject, and $d_{k,sp} = y_{sp} - Y_{ref, sp}$\nrepresents the k-space difference. The reconstructed image contains P pixels, and there are S subjects in the training\ndataset.\nWe implemented the proposed A-LIKNet framework using Tensorflow [58] v2.5.0 with Keras [59] v2.4.3. Complex-\nvalued operations such as convolution and activation are implemented by MERLIN v0.3 [60]. Networks were trained\nto converge (180 epochs) using an Adam optimizer [61] with a learning rate of 1\u00d710-4. Due to the high GPU memory\nburden, we set the batch size to one. The training of A-LIKNet took approximately 96 hours using 4 NVIDIA A6000\nGPUs (48 GB VRAM). The source code is publicly available: https://github.com/midas-tum/A-LIKNet.\nAll comparative and ablated experiments were conducted using the same VISTA sampling technique to ensure a fair\ncomparison. For deep learning-based networks, the acceleration rate at each training step was randomly selected\nbetween 2\u00d7 and 24\u00d7. Both qualitative and quantitative evaluations were performed. For qualitative comparisons,\nall grey-scale images are normalized to [0, 1]. For quantitative evaluations, we calculated the normalized root mean\nsquared error (NRMSE), peak signal-to-noise ratio (PSNR), and structural similarity index measure (SSIM). The\nevaluation metrics were computed for all slices across all subjects in the test dataset. All networks were trained until\nconvergence."}, {"title": "3.3 Comparative methods", "content": "We compare the proposed A-LIKNet to three conventional reconstruction methods: zero-filling, parallel-imaging\ncompressed sensing reconstruction (PICS) [11], and k-t SLR [13], as well as three deep learning-based methods:\nMoDL [27], multi-domain KIKI-net [42], and low-rank plus sparse network L+S-Net [45].\nFor traditional methods, parameters were adjusted to achieve optimal performance. KIKI-Net, which was initially\ndesigned for 2D single-coil data, was adapted to our 2D+t multi-coil data to maintain a fair comparison and only focus\non the multi-domain sharing aspect. We modified the original 2D convolutions to 3D convolutions, aligning them with\nthe dimensionality of our A-LIKNet: spatial-coil in the k-space and spatial-temporal in the image domain. The data\nconsistency layer applied the same gradient descent algorithm for the multi-coil data fidelity. Similarly, the original\n2D convolutions in MoDL were adjusted to 3D convolutions to fit our Cine data. The iteration numbers of MoDL and\nL+S-Net matched those of A-LIKNet, iterating eight times. The remaining network structures, loss functions, training\nstrategy, and other details remained consistent with the original implementations. The total trainable parameters and\nthe final reconstruction time for a Cine image sequence are summarized in Tab. 1.\nAs shown in Tab. 1, the proposed A-LIKNet has more trainable parameters than other networks due to multiple\nsubnetworks. To ensure further fairness, we selected the best-performing and least-parameterized network, L+S-Net,\nfrom the comparative DL-based methods for an additional enlarged L+S-Net experiment. In this experiment, we\naugmented the original L+S-Net by increasing the spatial-temporal convolutional kernel size from (3,3,3) to (3,5,5),\nmatching the kernel size in A-LIKNet. We summarized the hyperparameter changes in Tab. 2. The enlarged L+S-Net\nhas 2,688,015 parameters, which is comparable to the proposed A-LIKNet."}, {"title": "3.4 Ablations", "content": "The different contributions of the image, k-space, and low-rank subnetworks were examined. To investigate the roles\nof the different modules within A-LIKNet, we conducted the following five ablation experiments: A-INet, A-KNet, A-\nLINet, A-IKNet, and LIKNet. The components included in each experiment are summarized in Tab. 3. We furthermore\ntested the contribution of the attention mechanisms, marked as 'w/o' in Tab. 3 for the image or k-space subnetworks.\nAdditionally, we conducted a series of ablation experiments with varying patch sizes in the low-rank subnetwork to\nexplore the effect of the proposed patch-wise low-rank method. We use $(n_t, n_x, n_y)$ to denote the number of patches\nin the temporal and spatial dimensions."}, {"title": "4 Results", "content": ""}, {"title": "4.1 Reconstruction performance of A-LIKNet", "content": "We first explored the performance of the proposed A-LIKNet at different acceleration rates. It is worth noting that\nsince acceleration factors were randomly chosen between 2 and 24 during training, the pre-trained network can be\nused for testing at various accelerations without the need for retraining. The reconstruction results of A-LIKNet at\ndifferent acceleration factors are depicted in Fig. 4."}, {"title": "4.2 Comparative studies", "content": ""}, {"title": "4.2.1 Qualitative evaluation", "content": "Fig. 6 displays the reconstruction results for 12\u00d7 and 24\u00d7 retrospectively undersampled Cine images of another\npatient in the test dataset, distinct from the one shown in Fig. 4. We compare our A-LIKNet to zero-filling, PICS [11],\nk-t SLR [13], and deep learning-based methods including MoDL [27], KIKI-net [42], L+S-Net [45]. A frame from\nthe systolic phase is shown, as cardiac motion is the largest in this phase, making the reconstruction more challenging\nto capture the cardiac dynamics. Similarly, Fig. 6 illustrates the reconstructions in the x-y and y-t planes, along with\nthe absolute error maps.\nFrom Fig. 6, it is apparent that the traditional PICS method struggles with the VISTA sampling pattern. PICS fails\nto reconstruct the 24\u00d7 undersampled images and exhibits significant artifacts even at 12\u00d7 acceleration. Another\ntraditional approach, kt-SLR, achieves acceptable results at 12\u00d7 acceleration but shows noticeable blur at edges and\nover-smoothing of artifacts at 24\u00d7 acceleration. Among the deep learning-based methods, both MoDL and KIKI-Net\nexhibit significant errors in the myocardial region. While L+S-Net performs better than these two methods, some\nresidual ripple-like artifacts are still observable in the reconstructed images at 24\u00d7 acceleration. In contrast, whether"}, {"title": "4.2.2 Quantitative evaluation", "content": "To provide a fair comparison of the performance of various deep learning-based methods, we reconstructed Cine\nimages for all slices across all subjects in the test dataset. We calculated the NRMSE, PSNR, and SSIM between the\nreconstruction results and the fully-sampled images for four different acceleration factors: 8x, 16x, 24\u00d7, and 30\u00d7.\nNote that during training, the maximum acceleration factor is 24\u00d7, and we validate different DL-based methods on"}, {"title": "4.2.3 Prospective study", "content": "To investigate the generalization performance of different DL-based networks, we tested pre-trained networks on the\nprospectively real-time undersampled OCMR dataset [51]. It is important to note that the pre-trained networks were\nnot fine-tuned on the OCMR dataset but were used directly for testing. Fig. 8 displays two 8\u00d7 undersampled short-axis\nslices and the reconstruction results of MoDL, KIKI-Net, L+S-Net, and the proposed A-LIKNet.\nIn general, all four deep learning networks can reconstruct the prospectively undersampled images with high quality.\nAlthough the differences are subtle, A-LIKNet performs slightly better than the other methods. In both the full-\nview and magnified cardiac region images, we can observe that MoDL, KIKI-Net, and L+S-Net still exhibit some\nresidual stripe artifacts (indicated by yellow arrows). Additionally, the reconstructed images of A-LIKNet display\nbetter contrast."}, {"title": "4.3 Ablation studies", "content": "To assess the role of each component in the proposed A-LIKNet, we conducted a series of ablation experiments as\nlisted in Tab. 3. Fig. 9 displays the reconstruction results of various networks for a representative healthy subject from"}, {"title": "4.3.1 The effect of parallel branches", "content": "Compared to existing methods, one crucial innovation of the proposed A-LIKNet is its parallel-branch structure, where\ntwo branches are dedicated to learning information separately in the k-space and image domain. The ablation experi-\nments A-INet, A-KNet, and A-LINet are single-domain networks, either learning in the image domain or the k-space\nwith a single branch. In contrast, multi-domain networks like A-IKNet, LIKNet, and A-LIKNet have parallel branches\nand information sharing layers between them.\nBy comparing the reconstruction results in Fig. 9, we can observe that the reconstructed image quality of single-\ndomain networks is worse than that of multi-domain networks, the distinction particularly noticeable in the error maps.\nMulti-domain networks with the parallel-branch structure not only independently learn information in the frequency"}, {"title": "4.3.2 The effect of k-space branch", "content": "The impact of the k-space branch can be explored through a comparison between A-LIKNet and A-LINet. From Fig. 9,\nwe observed that the reconstruction results of A-LINet contain residual oscillatory artifacts that are even being sharp-\nened. At 24\u00d7 acceleration, including the k-space branch helps remove aliasing artifacts, resulting in a more precise\ndepiction of details, such as the edges of papillary muscles, compared to the relatively blurry boundaries of A-LINet.\nRegarding dynamic information learning, the y-t images of A-LINet exhibit noticeable noise and fail to reconstruct the\ntemporal dynamics. Moreover, introducing k-space learning has a positive impact on recovering contrast information.\nThe A-LIKNet reconstruction results present a contrast closest to the reference images. Quantitative metrics also sup-\nport a consistent conclusion where A-LIKNet outperforms A-LINet significantly in all evaluation metrics at different\nacceleration factors.\nFurthermore, the impact of the k-space branch can be deduced by comparing A-INet and A-IKNet. In the x-y plane,\nwhether in terms of artifact removal or edge sharpness, the network with the k-space branch outperforms the ones work-\ning solely in the image domain. Dynamic information learning in the y-t plane is also improved by the participation\nof k-space information. Quantitative metrics corroborate this finding.\nFrom both comparisons, joining the k-space branch with the image branch facilitates context learning. While k-space\ncontains redundant information compared to the image domain, convolutions in the frequency domain can compensate\nfor the limited local field of view of image domain convolutions. Furthermore, k-space harbors valuable coil-resolved\ninformation, which differs from the image domain where we typically work with coil-combined images."}, {"title": "4.3.3 The effect of low-rank subnetwork", "content": "By comparing the proposed A-LIKNet with A-IKNet, we can observe the role of the low-rank subnetwork. At 12\u00d7\nacceleration, both networks exhibit comparable reconstruction results. However, as the acceleration factor increases,\nA-IKNet shows significantly more error at 24\u00d7 acceleration. Since there are no evident visual differences in the\nreconstructed images, the errors appear to be inaccuracies in signal intensities. Due to the aggressive acceleration,\nartifacts introduced in the undersampled images make it challenging to learn contrast information accurately. However,\nthanks to the inclusion of low-rank constraints that suppress the noise, the proposed A-LIKNet is able to learn signal\nintensity correctly while removing artifacts.\nThe quantitative analysis indicates that the inclusion of the low-rank subnetwork leads to a slight improvement in\nreconstruction performance, with this improvement becoming more pronounced as the acceleration factor increases.\nFurthermore, in most cases, A-LIKNet exhibits smaller variances in metrics than A-IKNet, demonstrating the added\nrobustness of the low-rank subnetwork against noise influence.\nIn addition, the effect of the patch-wise operation in the low-rank subnetwork of A-LIKNet is qualitatively compared\nin Fig. S5 and quantitatively evaluated in Fig. S6 in the supplementary material. In Fig. S5, we compared the proposed\nA-LIKNet with (5,4,4) patch division to the ablated experiment without patch division. We observed that the network\nwith patch division demonstrates superior reconstruction quality at both 12\u00d7 and 24\u00d7 accelerations, affirming the\nefficacy of learning low-rank characteristics for each spatial-temporal patch, as adjacent temporal frames and spatial\npixels exhibit stronger correlations. Quantitative metrics are calculated for varying spatial patch sizes and presented\nas box plots in Fig. S6. We observed that moderate patch numbers yield the best performance, striking a balance\nbetween containing sufficient relevant information without overwhelming the network with irrelevant details. However,\nvariations in patch division numbers have minimal impact on the network performance. Therefore, we selected the\n(5,4,4) patch division, which showed the best performance in terms of both mean and variance, for comparison to other\nmethods."}, {"title": "4.3.4 The effect of attention mechanism", "content": "Another innovation in the proposed A-LIKNet involves incorporating attention mechanisms in both k-space and image\nsubnetworks. The impact of attention can be investigated by comparing A-LIKNet with LIKNet. From Fig. 9, we\nobserved that LIKNet has the best reconstruction performance in all ablation experiments. However, compared to\nA-LIKNet, which incorporates attention mechanisms, there are still minor discrepancies. In the 24\u00d7 reconstructed\nimage of LIKNet, oscillatory artifacts are still present in the right ventricle (indicated by yellow arrows). The edge\nand the contrast of the papillary muscles are less precise than in A-LIKNet.\nThe quantitative evaluation is consistent with our observations. At lower acceleration factors, the metrics for A-LIKNet\nand LIKNet are comparable. However, the attention mechanism further enhances the reconstruction quality at higher\nacceleration factors. In conclusion, allowing the network to autonomously select more important coil information\nin k-space and learn more critical time frames in the image domain has a positive impact on improving network\nperformance."}, {"title": "4.4 Trainable parameters", "content": "In the proposed A-LIKNet, some hyperparameters have been set as trainable to enhance model performance and ensure\ngeneralization ability. Observing the final values of these parameters allows us to draw interesting conclusions and\ninsights. Fig. 10 summarizes the final values of the trainable parameters $\\alpha$ in Eq. 14, a and b in Eq. 20, with the curves\ndepicting the trends of these parameters over iterations in the unrolled network. The initial values of these parameters\nwere all set to 0.5 in each iteration.\nIn the image domain, the parameter $\\alpha$ in Eq. 14 determines the weights between the low-rank and sparse priors. By\nobserving $\\alpha$ in all eight iterations in Fig. 10, we found that the initially set value of 0.5 eventually settles in the range\nof 0.4 to 0.6. This suggests that the low-rank and sparse regularization terms contribute similarly during training,\nwhich also confirms the necessity of considering both priors for dynamic image reconstruction. Our local spatial-\ntemporal low-rank subnetwork can effectively leverage the low-rank nature of dynamic images, complementing the\nimage subnetwork in image domain learning.\nIn the information sharing layer, the weights of information from the k-space and image branches are determined by\nthe parameters a and b in Eq. 20. A smaller a indicates that the reconstruction result from the k-space branch influences\nmore the update of k-space values in the ISL. Similarly, a smaller b means that the image branch mainly determines the\nimage update in ISL. As shown in Fig. 10, the values of a in all iterations are found to be greater than 0.5, while b are\nall less than 0.5. This indicates that, for both the image and k-space updates, the image branch has a more significant"}, {"title": "5 Discussion", "content": "In this work, we developed a novel attention-incorporated network for sharing low-rank, image, and k-space infor-\nmation during MR image reconstruction (A-LIKNet) to achieve single breath-hold cardiac Cine imaging. A-LIKNet\nconsists of three components: the k-space branch, the image branch, and the information sharing layers (ISL). We pro-\nposed a novel parallel-branch architecture that enables independent learning in the k-space and image domain. With\nthe ISL connecting the two parallel branches, the utilization of multi-domain information is maximized. In the image\nbranch, we do not only exploit the sparse priors but also leverage the intrinsic low-rank priors of dynamic images.\nWe designed a local spatial-temporal low-rank module to adaptively enforce low-rank constraints for each spatial-\ntemporal patch. Additionally, we introduced attention mechanisms in the network, allowing the k-space sub-network\nto assign different weights to the features from different coils, while the image sub-network can focus on the more\ncrucial temporal frames."}, {"title": "5.1 Experimental summaries", "content": "The reconstruction results of A-LIKNet shown in Fig. 4 and Fig. 5 demonstrate that the trained network can effectively\nreconstruct images at different accelerations and time frames. We observed that while the trained A-LIKNet can handle\nimage reconstruction under different conditions, the reconstruction performance slightly deteriorates during the cardiac\nsystolic phase because the rapid motion of the myocardium leads to larger displacements between adjacent time frames,\nreducing the available redundant spatial-temporal information for sharing. Additionally, the greater number of frames\nin the diastolic phase compared to the systolic phase creates an unavoidable dataset imbalance, which may contribute\nto better"}]}