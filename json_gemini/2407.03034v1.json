{"title": "ATTENTION INCORPORATED NETWORK FOR SHARING\nLOW-RANK, IMAGE AND K-SPACE INFORMATION DURING MR\nIMAGE RECONSTRUCTION TO ACHIEVE SINGLE BREATH-HOLD\nCARDIAC CINE IMAGING", "authors": ["Siying Xu", "Kerstin Hammernik", "Andreas Lingg", "Jens K\u00fcbler", "Patrick Krumm", "Daniel Rueckert", "Sergios Gatidis", "Thomas K\u00fcstner"], "abstract": "Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment of heart mor-\nphology and function in clinical practice. However, MRI requires long acquisition times, with recent\ndeep learning-based methods showing great promise to accelerate imaging and enhance reconstruc-\ntion quality. Existing networks exhibit some common limitations that constrain further acceleration\npossibilities, including single-domain learning, reliance on a single regularization term, and equal\nfeature contribution. To address these limitations, we propose to embed information from multiple\ndomains, including low-rank, image, and k-space, in a novel deep learning network for MRI recon-\nstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch structure, enabling\nindependent learning in the k-space and image domain. Coupled information sharing layers realize\nthe information exchange between domains. Furthermore, we introduce attention mechanisms into\nthe network to assign greater weights to more critical coils or important temporal frames. Train-\ning and testing were conducted on an in-house dataset, including 91 cardiovascular patients and 38\nhealthy subjects scanned with 2D cardiac Cine using retrospective undersampling. Additionally, we\nevaluated A-LIKNet on the real-time 8\u00d7 prospectively undersampled data from the OCMR dataset.\nThe results demonstrate that our proposed A-LIKNet outperforms existing methods and provides\nhigh-quality reconstructions. The network can effectively reconstruct highly retrospectively under-\nsampled dynamic MR images up to 24\u00d7 accelerations, indicating its potential for single breath-hold\nimaging.", "sections": [{"title": "1 Introduction", "content": "For cardiovascular disease identification, an accurate analysis of cardiac function and anatomy is required. Cine mag-\nnetic resonance imaging (MRI) is commonly used in clinical practice as a non-invasive and radiation-free assessment\nof the structural dynamics over the cardiac cycle. However, conventional multi-slice 2D cardiac Cine is acquired un-\nder multiple breath-holds, which not only results in a longer acquisition time but also causes patient discomfort and\nrespiratory-induced slice misalignments. Therefore, numerous efforts have been made to accelerate cardiac Cine MRI\nover the past decades.\nParallel imaging (PI) [1, 2, 3, 4] utilizes the recorded regular undersampled k-space signals over spatially distributed\nMR receiver coils. By using spatial information over the coils, the image can be reconstructed. PI reconstruction\ncan be either performed in the image domain, such as SENSitivity Encoding (SENSE) [1], or in the k-space, such as\nGeneRalized Auto-calibrating Partially Parallel Acquisitions (GRAPPA) [2]. In practice, the acceleration is often set\nto a lower value than theoretically possible, which is limited by the number of receiver coils, to ensure satisfactory\nimage quality. For cardiac Cine in clinical routine, 2\u00d7 to 4\u00d7 acceleration rates are commonly employed using parallel\nimaging techniques. Although PI enables the reduction of scan time, its acceleration capability is limited due to the\nfact that excessive accelerations can lead to enhanced noise.\nCompressed sensing (CS) has been proposed as an alternative to accelerate MR imaging, which exploits the fact that\nMR images can be sparsely represented in an appropriate transform domain. Given incoherent aliasing artifacts in the\ntransform domain due to a random k-space undersampling, the image can be reconstructed by non-linear optimization.\nRepresentative sparsity-enforcing methods include Wavelet transform [5], Total Variation (TV) [6, 7], and dictionary\nlearning [8, 9, 10]. CS MRI can also be combined with PI to jointly use image sparsity and coil sensitivity informa-\ntion [11, 12], thus further increasing the imaging speed. However, CS MRI still faces several challenges, such as long\nreconstruction time due to the iterative reconstruction process, challenging selection of hyperparameters for the sparse\nregularizations, and high computational burden for high-dimensional MRI reconstruction.\nSimilar to the goal of CS, low-rank priors aim to represent data or signals in a compact form by reducing the rank of a\nmatrix. Methods that jointly consider sparse and low-rank priors have shown improved performance in dynamic MR\nimage reconstruction. These methods can be categorized into two main approaches: low-rank and sparse (L&S) [13,\n14] and Low-rank plus sparse (L+S) [15, 16, 17]. L&S assumes that MR images simultaneously exhibit low-rank\nand sparse characteristics in the specific domain, while L+S hypothesizes that the image can be decomposed into a\nsuperposition of a low-rank component and a sparse component [17]. In dynamic MR imaging, L typically represents\nthe slowly varying background, while S models the dynamic information superimposed on top of it. Although the joint\nconsideration of sparse and low-rank priors has further improved the reconstruction speed and image quality, these\nmethods often require iterative optimization algorithms to estimate the low-rank and sparse components, leading to\nhigh computational complexity and longer reconstruction time. Additionally, determining the appropriate parameters\nrelies on empirical observations. The performance of these methods is heavily dependent on parameter selection, and\ndifferent applications necessitate different parameter settings.\nRecently, deep learning (DL) reconstruction methods started to flourish with the developments of graphics processing\nunits (GPU) and the increasing availability of large-scale databases. Based on the operation domain and the inputs\nto the neural network, supervised DL-based MRI reconstruction methods can be classified into five categories: image\nenhancement [18, 19, 20], k-space learning [21, 22, 23], physics-based reconstruction [24, 25, 26, 27, 28, 29, 30], plug\nand play priors (PnP) [31, 32, 33, 34, 35, 36], and distribution learning [37, 38, 39].\nImage enhancement networks take noise-corrupted images as inputs and artifact-free images as labels in a supervised\nsetting. In contrast, k-space learning, such as RAKI [22], operates in k-space, utilizing acquired k-space data to\nestimate nonlinear mapping kernels between coils to fill in missing k-space data - following the concept of PI. How-\never, these methods do not ensure data consistency in the acquired k-space samples. Hence, physics-based unrolled\nnetworks have been proposed, alternating between the neural network and a data consistency layer in an iterative\noptimization process. The neural network automatically learns the regularization in the image domain, while the in-\ntermittent data consistency layers introduce similarity to the acquired k-space data. Typical methods such as deep\ncascade network [25], MoDL [27], variational network (VN) [26], and CINENet [30] greatly improved the reconstruc-\ntion speed and image quality in highly undersampled data. However, the reconstruction performance can be limited\nwhen only operating in one domain, either in the image domain or k-space. Hybrid physics-based reconstruction\napproaches [40, 41] such as KIKI-net [42], MD-CNN [43], and KV-Net [44] additionally introduce k-space subnet-\nworks that integrate learning in both k-space and image domains. PnP algorithms embed prior information, typically\nrepresented by a denoiser, into a larger optimization algorithm to avoid dependence on the forward physics model\nduring training. Distribution learning utilizes generative models such as diffusion models to learn more accurate\nprior knowledge about data structures and data distributions for reconstruction. Furthermore, learning-based low-rank\nmethods [45, 46, 47] allow for learning hyperparameters in traditional low-rank methods, enhancing flexibility and\nreliability.\nWhile DL-based reconstruction methods have shown significant improvements compared to PI and CS MRI, we ob-\nserve that existing learning-based methods have at least one of the following challenges: (1) Operation on a single\ndomain: image enhancement, k-space learning, PnP and low-rank methods focus on single-domain reconstruction,\nmeaning that the neural network operates either in the k-space or image domain. Despite the utilization of k-space\nsamples in the data consistency layers in physics-based unrolled networks, they do not explicitly learn k-space infor-\nmation. (2) Focus on single prior: the image network in physics-based unrolled networks is solely for learning the"}, {"title": "", "content": "sparse prior, disregarding the inherent low-rank characteristic of dynamic images that could be exploited. (3) Equal\nfeature contribution: in most existing DL-based reconstruction methods, the features within the neural network are\ntreated equally in all dimensions, which impairs the representation ability of the network. In some works, the attention\nmechanism has been explored in MR image reconstruction [48, 49, 50], but they mainly focus on spatial or network-\nchannel-wise feature attention. The importance of temporal features for dynamic images and coil-wise features for\nk-space data has not been explored.\nTo address the aforementioned limitations and improve the reconstruction of dynamic MR imaging, we propose A-\nLIKNet, which incorporates the Attention mechanism to share Low-rank, Image, and K-space information during\nreconstruction. Unlike most existing networks with a single-input, single-output structure, our A-LIKNet consists of\nparallel k-space and image branches that output the reconstructed k-space and image. Both branches contribute to the\nloss calculation, allowing for the simultaneous reconstruction of k-space and image. The parallel structure ensures\nthe independence of single-domain learning while simultaneously enabling attention-based sharing between domains.\nTherefore, we introduce a learnable information sharing layer (ISL) in each optimization iteration to maximize multi-\ndomain information sharing. In the image branch, we consider both the sparsity and low-rank nature of dynamic MR\nimages. To achieve this, we employ a learnable image sub-network and low-rank sub-network for the sparse and low-\nrank priors, respectively. Furthermore, to enhance the representational capacity of the neural network, we introduce\nattention mechanisms along the temporal dimension in the image sub-network and the coil dimension in the k-space\nsub-network.\nThe main contributions of this work can be summarized as follows: (1) Maximizing information utilization in multiple\ndomains: the novel parallel-branch architecture with intermittent ISLs maximizes the information sharing between\ndomains while keeping the independence of image and k-space learning. The k-space branch complements global\ncoil-resolved learning to the local receptive field confinement of the image sub-network. (2) Leveraging the low-rank\nproperty of dynamic images: we design a local spatial-temporal low-rank threshold learning in the low-rank sub-\nnetwork. (3) Application of attention mechanism: we introduce a time-wise attention block in the image sub-network\nand a coil-wise attention block in the k-space sub-network, allowing the network to assign greater importance to\nspecific frames or coils. Investigations and comparisons to related DL reconstructions [11, 13, 27, 42, 45] were carried\nout on retrospectively undersampled data in an in-house database of 91 patients and 38 healthy subjects, as well as\nevaluations of pre-trained models on the prospectively undersampled OCMR dataset [51]. Experiments demonstrate\nthat the proposed A-LIKNet can reconstruct undersampled cardiac Cine images under extremely high acceleration\nfactors up to 24\u00d7, showcasing the potential for single breath-hold imaging."}, {"title": "2 Methodology", "content": "In this section, we will first introduce the mathematical background of the proposed A-LIKNet in Sec. 2.1, explaining\nhow we formulate and solve the MR image reconstruction problem. In Sec. 2.2, we will describe how we transform\nthe mathematical expressions into the various components of our proposed A-LIKNet."}, {"title": "2.1 Problem formulation", "content": "Let \\(x \\in \\mathbb{C}^n\\) be the desired fully-sampled complex-valued dynamic MR image stacked as a vector, with n being the\nnumber of pixels in x. Let \\(y_u \\in \\mathbb{C}^m\\) denote the undersampled measurements in k-space, with m being the number of\nsampled k-space points and \\(m < n\\). The forward model links x and yu:\n\\[\ny_u = Ax,\n\\]\nwhere the encoding operator \\(A \\in \\mathbb{C}^{m \\times n}\\) is describing the MR imaging operations:\n\\[\nA = MFS.\n\\]\nHere, S refers to the coil sensitivity maps of the multi-coil imaging scenario, F is the Fourier transform operator, and\nM denotes the binary undersampling trajectory. As the sampling process violates the Nyquist-Shannon theorem, the\nreconstruction problem in which we try to recover the image x from the acquired k-space yu is ill-posed. To solve this\nproblem, we transform the reconstruction into a regularized reconstruction problem:\n\\[\nx = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda R (x)}, \n\\]\nwhere \\(\\lambda\\) weights the contribution of the regularization term R(\u00b7). In general, Total Variation and l\u2081-norm on the image\nx are used as the sparse regularization R(\u00b7). In dynamic MRI, low-rankness is an additional important prior that can"}, {"title": "", "content": "be learned and leveraged during reconstruction. Therefore, we take into account both the sparsity of images and the\ninherent low-rank property of dynamic images, extending Eq. 3 to:\n\\[\nx = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda_s R_s (x) + \\lambda_l R_l (x)}, \n\\]\nwhere \\(R_s(\\cdot)\\) is the sparse regularization term with weighting factor \\(\\lambda_s\\), and \\(R_l(\\cdot)\\) is the low-rank regularizer with\nweighting parameter \\(\\lambda_l\\).\nIn our proposed method, we not only focus on the reconstruction of the coil combined image but also simultaneously\naim at reconstructing the coil-resolved k-space data. Therefore, in addition to Eq. 4, we introduce the minimization\nproblem in k-space:\n\\[\n\\hat{y} = \\arg \\min_y {\\frac{1}{2} || My - y_u ||_2^2 +\\lambda_k R_k (y)}, \n\\]\nwhere \\(R_k(\\cdot)\\) represents the frequency domain regularization term weighted by \\(\\lambda_k\\).\nIn the ideal scenario where we can obtain the globally optimal solution, Eq. 4 and Eq. 5 would be equivalent and result\nin the same solution. However, when we separately solve Eq. 4 and Eq. 5, we often end up at local minima for which\nx and \\(\\hat{y}\\) do not correspond. To avoid this situation and maximize information sharing between domains, we constrain\nthe reconstructed image and k-space by the forward model:\n\\[\n\\hat{y} = FSx.\n\\]\nEq. 6 implies that we aim for a solution where x and y correspond to each other.\nIn summary, Eq. 4, 5, and 6 form the overall reconstruction problem. Eq. 4 corresponds to the image branch in Fig. 1,\nwhich is designed to seek the optimal solution in the image domain. Eq. 5 is solved by the k-space branch in Fig. 1,\nwhich is responsible for recovering the k-space data in the frequency domain. As each data point in k-space contains\nthe corresponding frequency and phase information of all pixels in the image domain, the inclusion of the k-space\nbranch not only leverages coil-resolved information but also compensates for the limited receptive field of view in the\nimage domain. Moreover, Eq. 6 is implemented by the information sharing layer in Fig. 1. By harnessing estimated\ncoil sensitivity information, ISL facilitates the exchange of information across domains. We hypothesize that when\na particular branch becomes trapped in a local minimum or saddle point, this information sharing aids in guiding the\nmodel toward the global minimum. In the following sections, we will provide detailed derivations and descriptions of\neach network component in A-LIKNet."}, {"title": "2.2 Components of A-LIKNet", "content": "The overall architecture of A-LIKNet is shown in Fig. 1, which is built as a physics-based unrolled reconstruction\nnetwork and consists of an image branch (Sec. 2.2.1), a k-space branch (Sec. 2.2.2), and information sharing layers\n(Sec 2.2.3) between these two branches."}, {"title": "2.2.1 Image branch", "content": "The image branch is constructed to solve Eq. 4 and consists of an image subnetwork, a low-rank subnetwork, and a\ndata consistency layer. By introducing auxiliary variables \\(p \\in \\mathbb{C}^n\\) and \\(q \\in \\mathbb{C}^n\\), Eq. 4 can be equivalently written as:\n\\[\nx = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda_s R_s (p) + \\lambda_l R_l (q)} \\\\\ns.t. p = x, q = x,\n\\]\nwhich can be transformed into the unconstrained Lagrangian function using half quadratic splitting (HQS) with auxil-\niary variables \\(\\mu_1\\) and \\(\\mu_2\\):\n\\[\nL_{\\mu_1, \\mu_2} (x, p, q) = \\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda_s R_s (p) + \\lambda_l R_l (q) \\\\+\\frac{\\mu_1}{2} ||p - x||_2^2 +\\frac{\\mu_2}{2} ||q - x||_2^2.\n\\]\nThis problem can be solved iteratively to obtain the following sub-problems:\n\\[\np_{n+1} = \\arg \\min_p {\\frac{\\mu_1}{2} ||p - x_n||_2^2 + \\lambda_s R_s (p)} \\\\\nq_{n+1} = \\arg \\min_q {\\frac{\\mu_2}{2} ||q - x_n||_2^2 + \\lambda_l R_l (q)} \\\\\nx_{n+1} = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 + \\frac{\\mu_1}{2} ||p_{n+1} - x||_2^2 + \\frac{\\mu_2}{2} ||q_{n+1} - x||_2^2}.\n\\]\nTo solve \\(p_n\\), we introduce an image subnetwork \\(H_n\\), a convolutional neural network (CNN) designed to learn a sparse\nprior for the given current image \\(x_{n\u22121}\\). \\(H_n\\) intends to reconstruct local information on a coarse-to-fine scale. To\nadaptively learn a low-rank prior to solve \\(q_n\\), we design a low-rank subnetwork, denoted as \\(L_n\\). The subnetwork \\(L_n\ndecomposes a given \\(x_{n\u22121}\\) into local spatial-temporal patches and learns the singular value threshold for each patch\nto constrain the low-rank nature. Following the updates of p and q, the data consistency operator \\(DC_{I,n}\\) will be\nemployed to compute the output \\(x_n\\) for the current iteration, ensuring data fidelity. The subscript I indicates the DC\nlayer operation in the image domain. With the learnable image subnetwork \\(H_n\\), the low-rank subnetwork \\(L_n\\), and the\ndata consistency layer \\(DC_{I,n}\\), the equations in Eq. 9 can be reformulated as follows:\n\\[\n\\begin{cases}\np_n = H_n(x_{n-1}) \\\\\nq_n = L_n(x_{n-1}) \\\\\nx_n = DC_{I,n}(p_n, q_n),\n\\end{cases}\n\\]\nwhere \\(n \\in \\{1, ..., N\\}\\), with N being the total iteration number or unrolls of the network modules.\nImage subnetwork In the first step of Eq. 10, a complex-valued residual 2D+t UNet \\(H_n\\) with time-wise attention\nblocks is used to learn the sparse prior. As depicted in Fig. 2, the UNet contains two stages. In each stage, a 2D+t con-\nvolution, i.e., a 2D spatial convolution followed by a 1D temporal convolution, is performed. A ModReLU activation\nfunction [52] is introduced between and after convolutions. Using a 2D+t convolution instead of 3D convolution not\nonly reduces the computational burden but also allows for independent learning in the spatial and temporal domains.\nAt the end of each encoder stage, a 3D max pooling layer is used to reduce the feature size. The upsampling operation\nin the decoder is implemented by a 3D transpose convolution. The final output layer has only one kernel with a linear\nactivation function, serving to predict the coil-combined image. Residual paths between the encoder/decoder stages\nand the input/output enable the network to focus solely on learning to remove the noise and aliasing artifacts from the\nimages, reducing the learning complexity.\nDifferent from the conventional UNet[53], we incorporate the attention mechanism along the temporal dimension.\nAs shown in Fig. 2, the time-wise attention block is added at the end of each decoder stage. This block leverages\nthe squeeze-and-excitation mechanism [54]. Specifically, we concatenate the real and imaginary parts of the time-\nresolved feature maps along the temporal dimension to form real-valued arrays. Subsequently, 3D global max pooling"}, {"title": "", "content": "is performed over the spatial and channel dimensions to squeeze the feature maps. The squeezed spatial-channel\ninformation is then processed through two fully connected layers followed by a sigmoid function to generate an\nattention map. This map excites the original features by multiplication, assigning distinct weights to different temporal\nfeatures. The newly enhanced feature map is transformed back into the complex domain before being passed to the\nsubsequent layers of the UNet.\nDue to MR images being complex-valued, most existing methods tend to convert them into magnitude or two-channel\nimages (i.e., not considering the relationship between real and imaginary components). In contrast, except for the at-\ntention block, our network is built upon complex-valued operations, including complex convolution [55] and complex\nactivation functions [52]. The complex operations preserve both the phase and magnitude information of the input sig-\nnal. Furthermore, jointly processing the real and imaginary components within one operation conserves computational\nresources and mitigates information loss.\nLow-rank subnetwork The low-rank subnetwork is employed to update q in the second step of Eq. 10. In dynamic\nMR images, each pixel strongly correlates to the same or adjacent pixels in the neighboring time frames. Thus, our\nlow-rank subnetwork is tailored to focus on local spatial-temporal relationships. We split the input image sequence\n\\(x_{n-1}\\) into spatial-temporal patches. Specifically, the T frames are divided into \\(n_t\\) groups, and the spatial domain is\nsegmented into \\(n_x \\times n_y\\) patches. It is important to note that due to the varying spatial sizes of input images, we define\nthe number of partitions rather than specific patch sizes. Here, \\(n_x, n_y\\), and \\(n_t\\) refer to the number of patches in each\ndimension. To ensure information continuity and prevent disjoint edge effects, these patches overlap in the spatial\ndomain, and the size of the overlapping regions is adaptively calculated based on the image size. Decomposing the\nimage into patches brings the additional advantage of increasing computational efficiency, especially in the case of\nlong dynamic sequences.\nLow-rank regularization is applied to each patch. The implementation is based on the low-rank layer in L+S-Net [45],\nwith the key distinction in threshold calculation and patch-wise application. For the ith patch \\(x_i\\), we perform singular\nvalue decomposition (SVD):\n\\[\nx_i = U\\Sigma V^H,\n\\]\nwhere the singular value matrix \\(\\Sigma = diag(\\sigma_j), 1 \\leq j \\leq r\\) with \\(r = rank(x_i)\\) contains singular values of \\(x_i\\) along the\ndiagonal, and U, V contain the singular vectors. We assign each patch a learnable singular value threshold coefficient\n\\(\\tau_i\\). By applying a sigmoid function to \\(\\tau_i\\) and multiplying the result with the maximum singular value, we ensure that\nthe learned threshold lies between 0 and the existing maximum singular value. The updated singular value matrix can\nbe formulated as:\n\\[\n\\Sigma_s = diag(max(\\sigma_j - \\zeta, 0) + \\zeta \\cdot step(\\sigma_j - \\zeta)_{1<j<r}),\n\\]\nwhere \\(\\zeta = sigmoid(\\tau_i) \\cdot \\bar{\\sigma}\\) is the threshold with \\(\\bar{\\sigma}\\) being the maximum singular value in \\(\\Sigma\\), and \\(step(\\cdot)\\) denotes\nthe Heaviside step function. The thresholded singular value matrix induces updated patches \\(x_i = U\\Sigma_s V^H\\). This"}, {"title": "", "content": "operation guarantees the low-rank constraint by retaining only the singular values larger than the learned threshold.\nOnce local thresholds for all patches are learned, the patches are unpatched to recover the original image size.\nImage data consistency layer In the last update step in Eq. 10, we perform the data consistency step in the image\ndomain using a gradient descent algorithm. Let us denote the original objective function in Eq. 9 as f(x). The\nderivation of f (x) with respect to x is:\n\\[\n\\frac{df(x)}{dx} = A^H (Ax \u2013 y_u) \u2013 \\mu_1(p_{n+1} \u2013 x) \u2013 \\mu_2(q_{n+1} \u2013 x).\n\\]\nWe initialize the input to the DC layer as:\n\\[\nx_{init} = \\alpha \\cdot p_{n+1} + (1 \u2013 \\alpha) \\cdot q_{n+1}, \\alpha = \\frac{\\mu_1}{\\mu_1 + \\mu_2},\n\\]\nso that the gradient is simplified to \\(A^H (Ax_{init} \u2013 y_u)\\). By applying the gradient descent algorithm, the updated image\nof the DC layer is:\n\\[\nx_{n+1} = x_{init} - \\eta \\cdot (A^H (Ax_{init} \u2013 y_u)),\n\\]\nwhere \\(\\eta\\) is the trainable scaling parameter. Consequently, the data consistency layer takes the weighted combination\nof outputs from the image and low-rank subnetworks as input and induces fidelity to the sampled k-space yu to update\nthe image branch."}, {"title": "2.2.2 K-space branch", "content": "The k-space branch is dedicated to solving Eq. 5 and comprises a k-space subnetwork and a k-space data consistency\nlayer. By introducing an auxiliary variable r, Eq. 5 can be transformed into the unconstrained Lagrangian function\nusing HQS:\n\\[\nL_{\\mu_k} (y, r) = \\frac{1}{2} ||My - y_u||_2^2 + \\lambda_k R_k(r) + \\frac{\\mu_k}{2} ||r - y||_2^2,\n\\]\nwhich can be solved iteratively:\n\\[\nr_{n+1} = \\arg \\min_r {\\lambda_k R_k(r) + \\frac{\\mu_k}{2} ||r - y_n||_2^2} \\\\\ny_{n+1} = \\arg \\min_y {\\frac{1}{2} ||My - y_u||_2^2 + \\frac{\\mu_k}{2} ||r_{n+1} - y||_2^2}\n\\]\nSimilarly, we use a CNN, \\(K_n\\), operating in k-space to learn the generalized k-space prior (similar to a GRAPPA-\nbased PI) [22] and perform data consistency in k-space to update \\(y_{n+1}\\). Then, Eq. 17 can be formulated as learnable\nnetworks:\n\\[\n\\begin{cases}\nr_n = K_n(y_{n-1}) \\\\\ny_n = DC_{K,n}(r_n),\n\\end{cases}\n\\]\nK-space subnetwork The k-space subnetwork is designed to learn the generalized k-space prior. As depicted in\nFig. 3, the k-space subnetwork is a complex-valued CNN with coil-wise attention blocks. Its structure closely resem-\nbles RAKI [22], comprising a simple three-layer architecture. Unlike RAKI, however, we apply 3D convolutions in the\nspatial-coil dimensions and discard strides due to pseudo-random sampling patterns. The first two layers are followed\nby a ModReLU activation function and a coil-wise attention block. The last layer performs the output estimation with\nlinear activation. All layers do not include bias terms, as the bias could adversely affect robustness when k-space\nundergoes linear scaling.\nThe attention mechanism is similar to the time-wise attention block in the image subnetwork. However, the dimensions\non which it operates are different. In k-space, the real and imaginary parts are concatenated along the coil dimension,\nand the attention maps are calculated along this dimension. This modification stems from the fact that for multi-coil\nMR images, coil-resolved k-space data provides signal variations along the coils at distinct spatial locations, rendering\nthe coil dimension more vital. Furthermore, the k-space network operates in the complex domain besides the attention\nblock."}, {"title": "K-space data consistency layer", "content": "The DC layer aims to align predicted values with actual observations and to solve\nthe second problem in Eq. 17. This optimization function is convex and has an analytical solution:\n\\[\n\\begin{cases}\ny_{n+1}^p = \\frac{y_u^p + \\mu_k r_n^p}{1+\\mu_k} \\ p\\in \\Omega \\\\\ny_{n+1}^p = r_n^p \\ p \\notin \\Omega,\n\\end{cases}\n\\]"}, {"title": "2.2.3 Information sharing layer", "content": "In the problem formulation Sec. 2.1, we have introduced the derivation of Eq. 6, which is implemented by the informa-\ntion sharing layer (ISL). The inputs to the ISL at the nth iteration are \\(x_n\\) and \\(y_n\\) from the image and k-space branches.\nTo satisfy Eq. 6, they can be expressed as follows:\n\\[\n\\begin{cases}\ny_n = a \\cdot (FSx_n) + (1 - a) \\cdot y_n \\\\\nx_n = b \\cdot ((FS)^H y_n) + (1 \u2212b) \\cdot x_n,\n\\end{cases}\n\\]\nwhere a and b are real numbers with a, b \u2208 [0, 1]. As previously explained, achieving perfect consistency between \\(x_n\nand y_n\\) can be challenging due to the inherent instability in the network training. Therefore, we set a and b in Eq. 20\nas trainable parameters, and Eq. 20 becomes the update rule of the ISL.\nIn conclusion, a single iteration of the proposed A-LIKNet consists of (1) an image branch which includes an image\nsubnetwork learning the sparse prior, a low-rank subnetwork enforcing local spatial-temporal low-rankness, and an\nimage DC layer; (2) a k-space branch which is comprised of a k-space subnetwork learning the k-space regularization\nand a k-space DC layer; (3) an information sharing layer which exchanges and combines information from the two\ndomains. Notably, the network weights are not shared across iterations, enabling each iteration to operate at different\nnoise and artifact levels."}, {"title": "3 Experiments", "content": "3.1 Database\nThe dataset used in our experiments contains in-house 2D cardiac Cine, which was acquired on a 1.5T MRI scanner\n(MAGNETOM Aera, Siemens Healthineers, Erlangen, Germany) with a balanced steady-state free processing (bSSFP)\nsequence. The imaging protocol ensured left ventricular coverage, achieved through multiple consecutive breath-holds.\nThe total scan time ranges between 122s and 611s, primarily falling within the range of 122s to 266s, depending on\nthe number of slices and physiological characteristics of the patients. Data was recorded with flexible 18-channel\nbody and 32-channel spine coils, resulting in 30 MR receiver channels. The sequence parameters are as follows:\nTE/TR=1.06/2.12ms, flip angle=52\u00b0, bandwidth=915 Hz/px, spatial resolution=1.9\u00d71.9mm\u00b2, slice thickness=8mm.\nThe acquired data has a temporal resolution of 40ms, encompassing 25 cardiac phases spanning a complete cardiac\ncycle. The database includes 129 subjects, amongst which are 38 healthy subjects and 91 patients with various cardio-\nvascular diseases. We split the dataset into 115 subjects for training, including 34 healthy volunteers and 86 patients.\nThe remainder of the dataset was used for testing. The study was approved by the local ethics committee, and all\nsubjects gave written consent."}, {"title": "3.2 Implementation details", "content": "The number of filters in the image sub-network starts from 12 for each UNet"}, {"title": "ATTENTION INCORPORATED NETWORK FOR SHARING\nLOW-RANK, IMAGE AND K-SPACE INFORMATION DURING MR\nIMAGE RECONSTRUCTION TO ACHIEVE SINGLE BREATH-HOLD\nCARDIAC CINE IMAGING", "authors": ["Siying Xu", "Kerstin Hammernik", "Andreas Lingg", "Jens K\u00fcbler", "Patrick Krumm", "Daniel Rueckert", "Sergios Gatidis", "Thomas K\u00fcstner"], "abstract": "Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment of heart morphology and function in clinical practice. However, MRI requires long acquisition times, with recent deep learning-based methods showing great promise to accelerate imaging and enhance reconstruction quality. Existing networks exhibit some common limitations that constrain further acceleration possibilities, including single-domain learning, reliance on a single regularization term, and equal feature contribution. To address these limitations, we propose to embed information from multiple domains, including low-rank, image, and k-space, in a novel deep learning network for MRI reconstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch structure, enabling independent learning in the k-space and image domain. Coupled information sharing layers realize the information exchange between domains. Furthermore, we introduce attention mechanisms into the network to assign greater weights to more critical coils or important temporal frames. Training and testing were conducted on an in-house dataset, including 91 cardiovascular patients and 38 healthy subjects scanned with 2D cardiac Cine using retrospective undersampling. Additionally, we evaluated A-LIKNet on the real-time 8\u00d7 prospectively undersampled data from the OCMR dataset. The results demonstrate that our proposed A-LIKNet outperforms existing methods and provides high-quality reconstructions. The network can effectively reconstruct highly retrospectively undersampled dynamic MR images up to 24\u00d7 accelerations, indicating its potential for single breath-hold imaging.", "sections": [{"title": "1 Introduction", "content": "For cardiovascular disease identification, an accurate analysis of cardiac function and anatomy is required. Cine magnetic resonance imaging (MRI) is commonly used in clinical practice as a non-invasive and radiation-free assessment of the structural dynamics over the cardiac cycle. However, conventional multi-slice 2D cardiac Cine is acquired under multiple breath-holds, which not only results in a longer acquisition time but also causes patient discomfort and respiratory-induced slice misalignments. Therefore, numerous efforts have been made to accelerate cardiac Cine MRI over the past decades.\nParallel imaging (PI) [1, 2, 3, 4] utilizes the recorded regular undersampled k-space signals over spatially distributed MR receiver coils. By using spatial information over the coils, the image can be reconstructed. PI reconstruction can be either performed in the image domain, such as SENSitivity Encoding (SENSE) [1], or in the k-space, such as GeneRalized Auto-calibrating Partially Parallel Acquisitions (GRAPPA) [2]. In practice, the acceleration is often set to a lower value than theoretically possible, which is limited by the number of receiver coils, to ensure satisfactory image quality. For cardiac Cine in clinical routine, 2\u00d7 to 4\u00d7 acceleration rates are commonly employed using parallel imaging techniques. Although PI enables the reduction of scan time, its acceleration capability is limited due to the fact that excessive accelerations can lead to enhanced noise.\nCompressed sensing (CS) has been proposed as an alternative to accelerate MR imaging, which exploits the fact that MR images can be sparsely represented in an appropriate transform domain. Given incoherent aliasing artifacts in the transform domain due to a random k-space undersampling, the image can be reconstructed by non-linear optimization. Representative sparsity-enforcing methods include Wavelet transform [5], Total Variation (TV) [6, 7], and dictionary learning [8, 9, 10]. CS MRI can also be combined with PI to jointly use image sparsity and coil sensitivity information [11, 12], thus further increasing the imaging speed. However, CS MRI still faces several challenges, such as long reconstruction time due to the iterative reconstruction process, challenging selection of hyperparameters for the sparse regularizations, and high computational burden for high-dimensional MRI reconstruction.\nSimilar to the goal of CS, low-rank priors aim to represent data or signals in a compact form by reducing the rank of a matrix. Methods that jointly consider sparse and low-rank priors have shown improved performance in dynamic MR image reconstruction. These methods can be categorized into two main approaches: low-rank and sparse (L&S) [13, 14] and Low-rank plus sparse (L+S) [15, 16, 17]. L&S assumes that MR images simultaneously exhibit low-rank and sparse characteristics in the specific domain, while L+S hypothesizes that the image can be decomposed into a superposition of a low-rank component and a sparse component [17]. In dynamic MR imaging, L typically represents the slowly varying background, while S models the dynamic information superimposed on top of it. Although the joint consideration of sparse and low-rank priors has further improved the reconstruction speed and image quality, these methods often require iterative optimization algorithms to estimate the low-rank and sparse components, leading to high computational complexity and longer reconstruction time. Additionally, determining the appropriate parameters relies on empirical observations. The performance of these methods is heavily dependent on parameter selection, and different applications necessitate different parameter settings.\nRecently, deep learning (DL) reconstruction methods started to flourish with the developments of graphics processing units (GPU) and the increasing availability of large-scale databases. Based on the operation domain and the inputs to the neural network, supervised DL-based MRI reconstruction methods can be classified into five categories: image enhancement [18, 19, 20], k-space learning [21, 22, 23], physics-based reconstruction [24, 25, 26, 27, 28, 29, 30], plug and play priors (PnP) [31, 32, 33, 34, 35, 36], and distribution learning [37, 38, 39].\nImage enhancement networks take noise-corrupted images as inputs and artifact-free images as labels in a supervised setting. In contrast, k-space learning, such as RAKI [22], operates in k-space, utilizing acquired k-space data to estimate nonlinear mapping kernels between coils to fill in missing k-space data - following the concept of PI. However, these methods do not ensure data consistency in the acquired k-space samples. Hence, physics-based unrolled networks have been proposed, alternating between the neural network and a data consistency layer in an iterative optimization process. The neural network automatically learns the regularization in the image domain, while the intermittent data consistency layers introduce similarity to the acquired k-space data. Typical methods such as deep cascade network [25], MoDL [27], variational network (VN) [26], and CINENet [30] greatly improved the reconstruction speed and image quality in highly undersampled data. However, the reconstruction performance can be limited when only operating in one domain, either in the image domain or k-space. Hybrid physics-based reconstruction approaches [40, 41] such as KIKI-net [42], MD-CNN [43], and KV-Net [44] additionally introduce k-space subnetworks that integrate learning in both k-space and image domains. PnP algorithms embed prior information, typically represented by a denoiser, into a larger optimization algorithm to avoid dependence on the forward physics model during training. Distribution learning utilizes generative models such as diffusion models to learn more accurate prior knowledge about data structures and data distributions for reconstruction. Furthermore, learning-based low-rank methods [45, 46, 47] allow for learning hyperparameters in traditional low-rank methods, enhancing flexibility and reliability.\nWhile DL-based reconstruction methods have shown significant improvements compared to PI and CS MRI, we observe that existing learning-based methods have at least one of the following challenges: (1) Operation on a single domain: image enhancement, k-space learning, PnP and low-rank methods focus on single-domain reconstruction, meaning that the neural network operates either in the k-space or image domain. Despite the utilization of k-space samples in the data consistency layers in physics-based unrolled networks, they do not explicitly learn k-space information. (2) Focus on single prior: the image network in physics-based unrolled networks is solely for learning the"}, {"title": null, "content": "sparse prior, disregarding the inherent low-rank characteristic of dynamic images that could be exploited. (3) Equal feature contribution: in most existing DL-based reconstruction methods, the features within the neural network are treated equally in all dimensions, which impairs the representation ability of the network. In some works, the attention mechanism has been explored in MR image reconstruction [48, 49, 50], but they mainly focus on spatial or network-channel-wise feature attention. The importance of temporal features for dynamic images and coil-wise features for k-space data has not been explored.\nTo address the aforementioned limitations and improve the reconstruction of dynamic MR imaging, we propose A-LIKNet, which incorporates the Attention mechanism to share Low-rank, Image, and K-space information during reconstruction. Unlike most existing networks with a single-input, single-output structure, our A-LIKNet consists of parallel k-space and image branches that output the reconstructed k-space and image. Both branches contribute to the loss calculation, allowing for the simultaneous reconstruction of k-space and image. The parallel structure ensures the independence of single-domain learning while simultaneously enabling attention-based sharing between domains. Therefore, we introduce a learnable information sharing layer (ISL) in each optimization iteration to maximize multi-domain information sharing. In the image branch, we consider both the sparsity and low-rank nature of dynamic MR images. To achieve this, we employ a learnable image sub-network and low-rank sub-network for the sparse and low-rank priors, respectively. Furthermore, to enhance the representational capacity of the neural network, we introduce attention mechanisms along the temporal dimension in the image sub-network and the coil dimension in the k-space sub-network.\nThe main contributions of this work can be summarized as follows: (1) Maximizing information utilization in multiple domains: the novel parallel-branch architecture with intermittent ISLs maximizes the information sharing between domains while keeping the independence of image and k-space learning. The k-space branch complements global coil-resolved learning to the local receptive field confinement of the image sub-network. (2) Leveraging the low-rank property of dynamic images: we design a local spatial-temporal low-rank threshold learning in the low-rank sub-network. (3) Application of attention mechanism: we introduce a time-wise attention block in the image sub-network and a coil-wise attention block in the k-space sub-network, allowing the network to assign greater importance to specific frames or coils. Investigations and comparisons to related DL reconstructions [11, 13, 27, 42, 45] were carried out on retrospectively undersampled data in an in-house database of 91 patients and 38 healthy subjects, as well as evaluations of pre-trained models on the prospectively undersampled OCMR dataset [51]. Experiments demonstrate that the proposed A-LIKNet can reconstruct undersampled cardiac Cine images under extremely high acceleration factors up to 24\u00d7, showcasing the potential for single breath-hold imaging."}, {"title": "2 Methodology", "content": "In this section, we will first introduce the mathematical background of the proposed A-LIKNet in Sec. 2.1, explaining how we formulate and solve the MR image reconstruction problem. In Sec. 2.2, we will describe how we transform the mathematical expressions into the various components of our proposed A-LIKNet."}, {"title": "2.1 Problem formulation", "content": "Let \\(x \\in \\mathbb{C}^n\\) be the desired fully-sampled complex-valued dynamic MR image stacked as a vector, with n being the number of pixels in x. Let \\(y_u \\in \\mathbb{C}^m\\) denote the undersampled measurements in k-space, with m being the number of sampled k-space points and \\(m < n\\). The forward model links x and yu:\n\\[ y_u = Ax, \\]\nwhere the encoding operator \\(A \\in \\mathbb{C}^{m \\times n}\\) is describing the MR imaging operations:\n\\[ A = MFS. \\]\nHere, S refers to the coil sensitivity maps of the multi-coil imaging scenario, F is the Fourier transform operator, and M denotes the binary undersampling trajectory. As the sampling process violates the Nyquist-Shannon theorem, the reconstruction problem in which we try to recover the image x from the acquired k-space yu is ill-posed. To solve this problem, we transform the reconstruction into a regularized reconstruction problem:\n\\[ x = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda R (x)}, \\]\nwhere \\(\\lambda\\) weights the contribution of the regularization term R(\u00b7). In general, Total Variation and l\u2081-norm on the image x are used as the sparse regularization R(\u00b7). In dynamic MRI, low-rankness is an additional important prior that can"}, {"title": null, "content": "be learned and leveraged during reconstruction. Therefore, we take into account both the sparsity of images and the inherent low-rank property of dynamic images, extending Eq. 3 to:\n\\[ x = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda_s R_s (x) + \\lambda_l R_l (x)}, \\]\nwhere \\(R_s(\\cdot)\\) is the sparse regularization term with weighting factor \\(\\lambda_s\\), and \\(R_l(\\cdot)\\) is the low-rank regularizer with weighting parameter \\(\\lambda_l\\).\nIn our proposed method, we not only focus on the reconstruction of the coil combined image but also simultaneously aim at reconstructing the coil-resolved k-space data. Therefore, in addition to Eq. 4, we introduce the minimization problem in k-space:\n\\[ \\hat{y} = \\arg \\min_y {\\frac{1}{2} || My - y_u ||_2^2 +\\lambda_k R_k (y)}, \\]\nwhere \\(R_k(\\cdot)\\) represents the frequency domain regularization term weighted by \\(\\lambda_k\\).\nIn the ideal scenario where we can obtain the globally optimal solution, Eq. 4 and Eq. 5 would be equivalent and result in the same solution. However, when we separately solve Eq. 4 and Eq. 5, we often end up at local minima for which x and \\(\\hat{y}\\) do not correspond. To avoid this situation and maximize information sharing between domains, we constrain the reconstructed image and k-space by the forward model:\n\\[ \\hat{y} = FSx. \\]\nEq. 6 implies that we aim for a solution where x and y correspond to each other.\nIn summary, Eq. 4, 5, and 6 form the overall reconstruction problem. Eq. 4 corresponds to the image branch in Fig. 1, which is designed to seek the optimal solution in the image domain. Eq. 5 is solved by the k-space branch in Fig. 1, which is responsible for recovering the k-space data in the frequency domain. As each data point in k-space contains the corresponding frequency and phase information of all pixels in the image domain, the inclusion of the k-space branch not only leverages coil-resolved information but also compensates for the limited receptive field of view in the image domain. Moreover, Eq. 6 is implemented by the information sharing layer in Fig. 1. By harnessing estimated coil sensitivity information, ISL facilitates the exchange of information across domains. We hypothesize that when a particular branch becomes trapped in a local minimum or saddle point, this information sharing aids in guiding the model toward the global minimum. In the following sections, we will provide detailed derivations and descriptions of each network component in A-LIKNet."}, {"title": "2.2 Components of A-LIKNet", "content": "The overall architecture of A-LIKNet is shown in Fig. 1, which is built as a physics-based unrolled reconstruction network and consists of an image branch (Sec. 2.2.1), a k-space branch (Sec. 2.2.2), and information sharing layers (Sec 2.2.3) between these two branches."}, {"title": "2.2.1 Image branch", "content": "The image branch is constructed to solve Eq. 4 and consists of an image subnetwork, a low-rank subnetwork, and a data consistency layer. By introducing auxiliary variables \\(p \\in \\mathbb{C}^n\\) and \\(q \\in \\mathbb{C}^n\\), Eq. 4 can be equivalently written as:\n\\[ x = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda_s R_s (p) + \\lambda_l R_l (q)} \\\\ s.t. p = x, q = x, \\]\nwhich can be transformed into the unconstrained Lagrangian function using half quadratic splitting (HQS) with auxiliary variables \\(\\mu_1\\) and \\(\\mu_2\\):\n\\[ L_{\\mu_1, \\mu_2} (x, p, q) = \\frac{1}{2} || Ax - y_u ||_2^2 +\\lambda_s R_s (p) + \\lambda_l R_l (q) \\\\+\\frac{\\mu_1}{2} ||p - x||_2^2 +\\frac{\\mu_2}{2} ||q - x||_2^2. \\]\nThis problem can be solved iteratively to obtain the following sub-problems:\n\\[ p_{n+1} = \\arg \\min_p {\\frac{\\mu_1}{2} ||p - x_n||_2^2 + \\lambda_s R_s (p)} \\\\ q_{n+1} = \\arg \\min_q {\\frac{\\mu_2}{2} ||q - x_n||_2^2 + \\lambda_l R_l (q)} \\\\ x_{n+1} = \\arg \\min_x {\\frac{1}{2} || Ax - y_u ||_2^2 + \\frac{\\mu_1}{2} ||p_{n+1} - x||_2^2 + \\frac{\\mu_2}{2} ||q_{n+1} - x||_2^2}. \\]\nTo solve \\(p_n\\), we introduce an image subnetwork \\(H_n\\), a convolutional neural network (CNN) designed to learn a sparse prior for the given current image \\(x_{n\u22121}\\). \\(H_n\\) intends to reconstruct local information on a coarse-to-fine scale. To adaptively learn a low-rank prior to solve \\(q_n\\), we design a low-rank subnetwork, denoted as \\(L_n\\). The subnetwork \\(L_n decomposes a given \\(x_{n\u22121}\\) into local spatial-temporal patches and learns the singular value threshold for each patch to constrain the low-rank nature. Following the updates of p and q, the data consistency operator \\(DC_{I,n}\\) will be employed to compute the output \\(x_n\\) for the current iteration, ensuring data fidelity. The subscript I indicates the DC layer operation in the image domain. With the learnable image subnetwork \\(H_n\\), the low-rank subnetwork \\(L_n\\), and the data consistency layer \\(DC_{I,n}\\), the equations in Eq. 9 can be reformulated as follows:\n\\[ \\begin{cases} p_n = H_n(x_{n-1}) \\\\ q_n = L_n(x_{n-1}) \\\\ x_n = DC_{I,n}(p_n, q_n), \\end{cases} \\]\nwhere \\(n \\in \\{1, ..., N\\}\\), with N being the total iteration number or unrolls of the network modules.\nImage subnetwork In the first step of Eq. 10, a complex-valued residual 2D+t UNet \\(H_n\\) with time-wise attention blocks is used to learn the sparse prior. As depicted in Fig. 2, the UNet contains two stages. In each stage, a 2D+t convolution, i.e., a 2D spatial convolution followed by a 1D temporal convolution, is performed. A ModReLU activation function [52] is introduced between and after convolutions. Using a 2D+t convolution instead of 3D convolution not only reduces the computational burden but also allows for independent learning in the spatial and temporal domains. At the end of each encoder stage, a 3D max pooling layer is used to reduce the feature size. The upsampling operation in the decoder is implemented by a 3D transpose convolution. The final output layer has only one kernel with a linear activation function, serving to predict the coil-combined image. Residual paths between the encoder/decoder stages and the input/output enable the network to focus solely on learning to remove the noise and aliasing artifacts from the images, reducing the learning complexity.\nDifferent from the conventional UNet[53], we incorporate the attention mechanism along the temporal dimension. As shown in Fig. 2, the time-wise attention block is added at the end of each decoder stage. This block leverages the squeeze-and-excitation mechanism [54]. Specifically, we concatenate the real and imaginary parts of the time-resolved feature maps along the temporal dimension to form real-valued arrays. Subsequently, 3D global max pooling"}, {"title": null, "content": "is performed over the spatial and channel dimensions to squeeze the feature maps. The squeezed spatial-channel information is then processed through two fully connected layers followed by a sigmoid function to generate an attention map. This map excites the original features by multiplication, assigning distinct weights to different temporal features. The newly enhanced feature map is transformed back into the complex domain before being passed to the subsequent layers of the UNet.\nDue to MR images being complex-valued, most existing methods tend to convert them into magnitude or two-channel images (i.e., not considering the relationship between real and imaginary components). In contrast, except for the attention block, our network is built upon complex-valued operations, including complex convolution [55] and complex activation functions [52]. The complex operations preserve both the phase and magnitude information of the input signal. Furthermore, jointly processing the real and imaginary components within one operation conserves computational resources and mitigates information loss.\nLow-rank subnetwork The low-rank subnetwork is employed to update q in the second step of Eq. 10. In dynamic MR images, each pixel strongly correlates to the same or adjacent pixels in the neighboring time frames. Thus, our low-rank subnetwork is tailored to focus on local spatial-temporal relationships. We split the input image sequence \\(x_{n-1}\\) into spatial-temporal patches. Specifically, the T frames are divided into \\(n_t\\) groups, and the spatial domain is segmented into \\(n_x \\times n_y\\) patches. It is important to note that due to the varying spatial sizes of input images, we define the number of partitions rather than specific patch sizes. Here, \\(n_x, n_y\\), and \\(n_t\\) refer to the number of patches in each dimension. To ensure information continuity and prevent disjoint edge effects, these patches overlap in the spatial domain, and the size of the overlapping regions is adaptively calculated based on the image size. Decomposing the image into patches brings the additional advantage of increasing computational efficiency, especially in the case of long dynamic sequences.\nLow-rank regularization is applied to each patch. The implementation is based on the low-rank layer in L+S-Net [45], with the key distinction in threshold calculation and patch-wise application. For the ith patch \\(x_i\\), we perform singular value decomposition (SVD):\n\\[ x_i = U\\Sigma V^H, \\]\nwhere the singular value matrix \\(\\Sigma = diag(\\sigma_j), 1 \\leq j \\leq r\\) with \\(r = rank(x_i)\\) contains singular values of \\(x_i\\) along the diagonal, and U, V contain the singular vectors. We assign each patch a learnable singular value threshold coefficient \\(\\tau_i\\). By applying a sigmoid function to \\(\\tau_i\\) and multiplying the result with the maximum singular value, we ensure that the learned threshold lies between 0 and the existing maximum singular value. The updated singular value matrix can be formulated as:\n\\[ \\Sigma_s = diag(max(\\sigma_j - \\zeta, 0) + \\zeta \\cdot step(\\sigma_j - \\zeta)_{1<j<r}), \\]\nwhere \\(\\zeta = sigmoid(\\tau_i) \\cdot \\bar{\\sigma}\\) is the threshold with \\(\\bar{\\sigma}\\) being the maximum singular value in \\(\\Sigma\\), and \\(step(\\cdot)\\) denotes the Heaviside step function. The thresholded singular value matrix induces updated patches \\(x_i = U\\Sigma_s V^H\\). This"}, {"title": null, "content": "operation guarantees the low-rank constraint by retaining only the singular values larger than the learned threshold. Once local thresholds for all patches are learned, the patches are unpatched to recover the original image size.\nImage data consistency layer In the last update step in Eq. 10, we perform the data consistency step in the image domain using a gradient descent algorithm. Let us denote the original objective function in Eq. 9 as f(x). The derivation of f (x) with respect to x is:\n\\[ \\frac{df(x)}{dx} = A^H (Ax \u2013 y_u) \u2013 \\mu_1(p_{n+1} \u2013 x) \u2013 \\mu_2(q_{n+1} \u2013 x). \\]\nWe initialize the input to the DC layer as:\n\\[ x_{init} = \\alpha \\cdot p_{n+1} + (1 \u2013 \\alpha) \\cdot q_{n+1}, \\alpha = \\frac{\\mu_1}{\\mu_1 + \\mu_2}, \\]\nso that the gradient is simplified to \\(A^H (Ax_{init} \u2013 y_u)\\). By applying the gradient descent algorithm, the updated image of the DC layer is:\n\\[ x_{n+1} = x_{init} - \\eta \\cdot (A^H (Ax_{init} \u2013 y_u)), \\]\nwhere \\(\\eta\\) is the trainable scaling parameter. Consequently, the data consistency layer takes the weighted combination of outputs from the image and low-rank subnetworks as input and induces fidelity to the sampled k-space yu to update the image branch."}, {"title": "2.2.2 K-space branch", "content": "The k-space branch is dedicated to solving Eq. 5 and comprises a k-space subnetwork and a k-space data consistency layer. By introducing an auxiliary variable r, Eq. 5 can be transformed into the unconstrained Lagrangian function using HQS:\n\\[ L_{\\mu_k} (y, r) = \\frac{1}{2} ||My - y_u||_2^2 + \\lambda_k R_k(r) + \\frac{\\mu_k}{2} ||r - y||_2^2, \\]\nwhich can be solved iteratively:\n\\[ r_{n+1} = \\arg \\min_r {\\lambda_k R_k(r) + \\frac{\\mu_k}{2} ||r - y_n||_2^2} \\\\ y_{n+1} = \\arg \\min_y {\\frac{1}{2} ||My - y_u||_2^2 + \\frac{\\mu_k}{2} ||r_{n+1} - y||_2^2} \\]\nSimilarly, we use a CNN, \\(K_n\\), operating in k-space to learn the generalized k-space prior (similar to a GRAPPA-based PI) [22] and perform data consistency in k-space to update \\(y_{n+1}\\). Then, Eq. 17 can be formulated as learnable networks:\n\\[ \\begin{cases} r_n = K_n(y_{n-1}) \\\\ y_n = DC_{K,n}(r_n), \\end{cases} \\]\nK-space subnetwork The k-space subnetwork is designed to learn the generalized k-space prior. As depicted in Fig. 3, the k-space subnetwork is a complex-valued CNN with coil-wise attention blocks. Its structure closely resembles RAKI [22], comprising a simple three-layer architecture. Unlike RAKI, however, we apply 3D convolutions in the spatial-coil dimensions and discard strides due to pseudo-random sampling patterns. The first two layers are followed by a ModReLU activation function and a coil-wise attention block. The last layer performs the output estimation with linear activation. All layers do not include bias terms, as the bias could adversely affect robustness when k-space undergoes linear scaling.\nThe attention mechanism is similar to the time-wise attention block in the image subnetwork. However, the dimensions on which it operates are different. In k-space, the real and imaginary parts are concatenated along the coil dimension, and the attention maps are calculated along this dimension. This modification stems from the fact that for multi-coil MR images, coil-resolved k-space data provides signal variations along the coils at distinct spatial locations, rendering the coil dimension more vital. Furthermore, the k-space network operates in the complex domain besides the attention block."}, {"title": "K-space data consistency layer", "content": "The DC layer aims to align predicted values with actual observations and to solve the second problem in Eq. 17. This optimization function is convex and has an analytical solution:\n\\[ \\begin{cases} y_{n+1}^p = \\frac{y_u^p + \\mu_k r_n^p}{1+\\mu_k} \\ p\\in \\Omega \\\\ y_{n+1}^p = r_n^p \\ p \\notin \\Omega, \\end{cases} \\]"}, {"title": "2.2.3 Information sharing layer", "content": "In the problem formulation Sec. 2.1, we have introduced the derivation of Eq. 6, which is implemented by the information sharing layer (ISL). The inputs to the ISL at the nth iteration are \\(x_n\\) and \\(y_n\\) from the image and k-space branches. To satisfy Eq. 6, they can be expressed as follows:\n\\[ \\begin{cases} y_n = a \\cdot (FSx_n) + (1 - a) \\cdot y_n \\\\ x_n = b \\cdot ((FS)^H y_n) + (1 \u2212b) \\cdot x_n, \\end{cases} \\]\nwhere a and b are real numbers with a, b \u2208 [0, 1]. As previously explained, achieving perfect consistency between \\(x_n and y_n\\) can be challenging due to the inherent instability in the network training. Therefore, we set a and b in Eq. 20 as trainable parameters, and Eq. 20 becomes the update rule of the ISL.\nIn conclusion, a single iteration of the proposed A-LIKNet consists of (1) an image branch which includes an image subnetwork learning the sparse prior, a low-rank subnetwork enforcing local spatial-temporal low-rankness, and an image DC layer; (2) a k-space branch which is comprised of a k-space subnetwork learning the k-space regularization and a k-space DC layer; (3) an information sharing layer which exchanges and combines information from the two domains. Notably, the network weights are not shared across iterations, enabling each iteration to operate at different noise and artifact levels."}, {"title": "3 Experiments", "content": "3.1 Database\nThe dataset used in our experiments contains in-house 2D cardiac Cine, which was acquired on a 1.5T MRI scanner (MAGNETOM Aera, Siemens Healthineers, Erlangen, Germany) with a balanced steady-state free processing (bSSFP) sequence. The imaging protocol ensured left ventricular coverage, achieved through multiple consecutive breath-holds. The total scan time ranges between 122s and 611s, primarily falling within the range of 122s to 266s, depending on the number of slices and physiological characteristics of the patients. Data was recorded with flexible 18-channel body and 32-channel spine coils, resulting in 30 MR receiver channels. The sequence parameters are as follows: TE/TR=1.06/2.12ms, flip angle=52\u00b0, bandwidth=915 Hz/px, spatial resolution=1.9\u00d71.9mm\u00b2, slice thickness=8mm. The acquired data has a temporal resolution of 40ms, encompassing 25 cardiac phases spanning a complete cardiac cycle. The database includes 129 subjects, amongst which are 38 healthy subjects and 91 patients with various cardio-vascular diseases. We split the dataset into 115 subjects for training, including 34 healthy volunteers and 86 patients. The remainder of the dataset was used for testing. The study was approved by the local ethics committee, and all subjects gave written consent."}, {"title": "3.2 Implementation details", "content": "The number of filters in the image sub-network starts from 12 for each UNet", "52": "function as the nonlinear activation function.\nThe hyperparameters used in A-LIKNet are set as follows: the trainable low-rank threshold coefficient \\(\\tau_i\\) in Eq. 12 is initialized as -2 for each local spatial-temporal patch. For the patch-wise low-rank subnetwork", "follows": "n\\[ \\mathcal{L}_{tot} = \\mathcal{L}_I + \\mathcal{L}_K \\\\= \\frac{1}{SP} \\sum_{s=1}^S \\sum_{p=1}^P (d_{i,s,p} \\cdot d_{i,s,p} + d_{k,s,p} \\cdot d_{k"}]}]}