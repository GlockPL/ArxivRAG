{"title": "On Large Language Models in Mission-Critical IT Governance: Are We Ready Yet?", "authors": ["Matteo Esposito", "Francesco Palagiano", "Valentina Lenarduzzi", "Davide Taibi"], "abstract": "Context. The security of critical infrastructure has been a fundamental concern since the advent of computers, and this concern has only intensified in today's cyber warfare landscape. Protecting mission-critical systems (MCSs), including essential assets like healthcare, telecommunications, and military coordination, is vital for national security. These systems require prompt and comprehensive governance to ensure their resilience, yet recent events have shown that meeting these demands is increasingly challenging.\nAim. Building on prior research that demonstrated the po-tential of GAI, particularly Large Language Models (LLMs), in improving risk analysis tasks, we aim to explore practitioners' perspectives, specifically developers and security personnel, on using generative AI (GAI) in the governance of IT MCSs seeking to provide insights and recommendations for various stakehold-ers, including researchers, practitioners, and policymakers.\nMethod. We designed a survey to collect practical experiences, concerns, and expectations of practitioners who develop and im-plement security solutions in the context of MCSs. Analyzing this data will help identify key trends, challenges, and opportunities for introducing GAIs in this niche domain.\nConclusions and Future Works. Our findings highlight that the safe use of LLMs in MCS governance requires interdisciplinary collaboration. Researchers should focus on designing regulation-oriented models and focus on accountability; practitioners em-phasize data protection and transparency, while policymakers must establish a unified Al framework with global benchmarks to ensure ethical and secure LLMs-based MCS governance.", "sections": [{"title": "I. INTRODUCTION", "content": "Since the conception of computers [1], [2], security has been a requirement or an issue [3]. In the current cyber warfare landscape, where wars are fought over fiber optics cable [4], protecting critical infrastructure is becoming more daunting and paramount with each passing second [5]. Currently, our daily activities almost entirely rely on digital platforms [4]. Anyhow, telecommunication infrastructures enabling surfing the internet for a cooking recipe is not as critical or as fault-tolerant as the one used during a national crisis for military personnel and population coordination [6]\u2013[8]. We commonly refer to such vital infrastructure as \u201cmission-critical systems\" (MCSs), according to the Common Criteria's definitions [6]. Therefore, the context in which such systems operate is referred to as \u201cmission-critical context\u201d (MCC). MCSs need prompt and actionable plans to safeguard and protect them as soon and as much as possible [3]. Currently, each MCSs follows standardized rules and security practices that vary among nations and according to the criticality level [6]-[8] of the system. Hence, the laws and the standards defining the governance of such systems are fragmented and mostly incompatible among the various nations [9].\nGovernance of MCS (GMCS) involves directing, managing, and controlling IT resources to ensure full compliance with organizational objectives, value maximization, and mitigation of risks associated with core operations in a structured, re-producible method [3], [9]. According to the Italian National Security Authority (ANS), GMCS is (i) time-sensitive, (ii) cyber-physically fault-tolerant, and (iii) reproducible. In other words, practitioners design guidelines and enact workflows that are quick and easy to follow (time-sensitive), thoroughly documented (reproducible), and risks are extensively analyzed and managed to minimize them and account for backup plans (cyber-physically fault-tolerant).\nNonetheless, recent events exemplified that experts often can not match the three requirements [10], [11]. Stemming from the strict requirements and the latest known failed experiences [10], [11] we previously investigated the role of generative AI (GAI) in aiding human experts performing comprehensive risk analysis, one of the three main tasks of GMCS, according to ANS and ISO standards [3], [10], [12], [13]. Our findings proved that GAI, in the form of Large Language Models (LLMs), can aid, in some instances also, outperform human experts in terms of speed and accuracy.\nIn recent engagements with the industry, we received excit-ing opinions from the experts we were collaborating with on the general interest of introducing GAI in GMCS. Hence, to support our future research effort, and contribute to our com-munity, we considered the industrial partner's initial designs, the ethical implications, and regulations on the topic, and leveraging our experience, we aimed to investigate the practi-tioner's point of view on integrating GAIs, specifically LLMs, in the GMCSs. More specifically: (i) we provide the first survey on practitioners feelings and perceptions on integrating GAI in GMCS; (ii) we elaborate implications tailored to researchers to guide future works; (iii) we suggest actionable insights for practitioners; (iv) we provide suggestions for policymakers to craft informed regulations and policies.\nOur survey highlights the essential role of interdisciplinary collaboration among researchers, practitioners, and"}, {"title": "II. STUDY DESIGN", "content": "This section details the goal and research questions, data collection, and data analysis. Our empirical study follows established guidelines [14]\u2013[16] and previous similar survey works [17].\nA. Goal and Research Questions\nThe goal of our empirical study is to investigate the practitioners perceived benefits, effectiveness, and potential ethical and privacy issues on using LLMs in the governance of mission-critical information technology systems. Our per-spective is of practitioners seeking to understand the balance between innovation in the decision process and thorough application of regulations in the given context. Based on our goal, we defined the following four Research Questions (RQs):\nRQ1. What is the current level of familiarity and experience among MCS practitioners with LLMs?\nRecent years have witnessed the proliferation of AI-enabled technologies' general availability [18]. What was a nice cutting-edge lab experiment is now driving innovation in every possible field [18]. Our context is peculiar and dominated by a conservative approach to new technologies. For instance, in our previous investigation in this context [3], [10], we were the first to introduce LLMs in Risk Analysis (RA), a fundamental part of GMCS itself. We highlighted LLMs' role in RA as a valuable assistant to speed up and enhance human experts', i.e., practitioners, capabilities. However, to extend the reach of LLMs capabilities in GMCS and to investigate practitioners' perceptions of the technology and its introduction, they should have a minimal background in using LLMs in MCS. With this first research question, we aim to investigate the current level of familiarity of practitioners with LLMs.\nNonetheless, familiarity is only one face of a multi-faced dice. For instance, innovation is usually blocked by negative experiences or feelings towards a specific technology [19]. Practitioners exposed to LLMs in MCS for the first time can have different perceived benefits and potential limitations that may allow or prevent the adoption. Hence, we ask:\nRQ2. What are the perceived benefits and potential limitations of LLMs in GMCS?\nResearch is usually faster than industries when the latter are not involved in research and innovation (RI) initiatives [20]. Therefore, researcher-driven innovation can be far from real-world immediate actionability. Hence, research can lead to exciting results that may be hard to implement in a real-world MCC scenario [21]. In a conservative context such as the GMCS, it is paramount to drive innovation slowly and based on the practitioners' perception [22]. Therefore, this RQ aims to identify perceptions of benefits and potential limitations in addressing security challenges.\nPractioner's feeling-based research is an increasing trend [23], [24]. For instance, researchers have investigated early career developers' perceptions of code understandability [24]. Similarly, Saroar et al. [23] surveyed perceptions of GitHub actions, while Linberg et al. [25] surveyed developer percep-tions about software project failure. Moreover, practitioners in GMCS are used to a precise perimeter of action. Therefore, assessing the impact on the established GMCS framework is paramount before introducing a possible game-changing technology. Hence, we ask:\nRQ3. What is the impact of integrating LLMs into current in-use GMCS frameworks?\nGMCSs rely on well-established security protocols [6]\u2013[8]. MCC-related standards and regulations are slowly updated and rarely entirely replaced. Hence, the reticence towards integrat-ing new technologies is evident. LLMs have the advantage of quickly processing vast amounts of data [10] while human obviously fall short [3]. Hence, its impact on a consolidated pre-GAI workflow may have disruptive consequences. With this RQ, we aim to grasp practitioners' perception of integrat-ing such technologies into their usual workflow.\nFinally, when humanity started organizing into society, it be-stowed upon itself rules and regulations [26]. The new society emerging alongside such revolutionizing technologies requires new rules and policies. Hence, we aim to investigate the role of policies and policymakers in guiding ethical progress by asking:\nRQ4. What is the role of policy frameworks in ensuring LLMs' safe and ethical use in GMCS?\nWe are in the peculiar spot of a fast-changing regulation due to the impact AI is having on society. Recently, primary regulatory bodies, such as the European Union (EU), published a corpus of regulation, namely the AI Act [27], in which they intended to regulate AI technologies within the perimeter of the EU. It's one of the first comprehensive efforts by any major regulatory body to address AI's ethical, legal, and safety implications on a large scale. Conversely, the U.S. approach to"}, {"title": "B. Study Context", "content": "According to ISACA [32], our work is focused on GMCS, which involves the structured manner of directing, managing, and controlling IT resources to ensure full compliance with organizational objectives, value maximization, and mitigation of risks associated with core operations [3], [9]. Much empha-sis is placed on good governance through oversight, account-ability, and decision-making to address IT systems' continued availability, security, and reliability as intrinsic enablers to organizational success. It is that form of governance that is key in ensuring the best performance and compliance with regulatory standards and that the investments being made in technology support the core mission objectives and resilience [9], [10], [30].\nEffective governance ensures that IT resources support business goals, facilitates the continuous availability of critical systems, and upholds regulatory requirements. Frameworks like COBIT [13] and ISO/IEC 38500 [12] are commonly used to structure these processes, helping organizations optimize resource use, mitigate risks, and maintain compliance with industry standards [32].\nPoor governance causes misalignment, often preventing the proper identification of sensitive data from being compromised by critical services with insufficient security measures [10], [32]. Poor communication between business and IT leads to poor alignment of priorities and resource allocations, under-mining real risk mitigation."}, {"title": "C. Population", "content": "We interviewed practitioners and organizations primarily affiliated with the European public administration, specifically Italian ministries, high-ranking military personnel, foreign country embassies, and agencies connected to national security and defense departments and economic partners who insist on the same market. We collected the answers anonymously and provided all participants with information regarding the GDPR act for data collection and protection. We also thoroughly followed the ACM publications policy on research involv-ing human participants and subjects [33]. We leverage our industrial partner, Multitel, an Italian company operating in civil and military security for over 30 years. It is dedicated to researching and developing new technologies for information security and provides products and services aimed at safe-guarding data, both at rest and in motion. More specifically, we leverage its network to reach the aforementioned practitioners.\nIt is noteworthy to consider the peculiar and niche pop-ulation our investigation targeted. Practitioners who work in mission-critical contexts such as national security, development, and regulating secure communication between ministries and military personnel are usually instructed to avoid partici-pating in such research. We undergo a lengthy authorization process, which has led us to get valuable data regarding 31 practitioners' knowledge and perceptions of using LLMs in such delicate contexts. In the same vein, when answering the question, all the interviewees implicitly refer only to on-premise, i.e., private, LLMs. In our context, no data can exfiltrate the intended geographical location, with granularity ranging from national territory to single offices. Hence, although their reply does not reflect the general audience, they are, on the other hand, a representative sample of the primarily European personnel occupied in such contexts."}, {"title": "D. Questionnaire", "content": "Table I presents the questions induced by our RQs. Due to space constraints, we provide the complete questionnaire in the replication package. It is worth noticing that, before submitting the questionnaire, we have performed a pilot ques-tionnaire to derive the answers for the closed-ended questions (C) predefined answers. Moreover, for most of the closed-ended questions we provided an opened ended version (B) to account for possible missing categories or to allow room for an in-depth explanation of the selection, though we flag them as optional. We interviewed the experts involved in the previous papers [3], [10], and leveraging domain knowledge, we reached a consensus for the predefined answer to the closed-ended questions. We did not ask the pilot's experts to participate in the final questionnaire to avoid biases.\nAccording to our guidelines [14]\u2013[17], we asked the partic-ipants to answer demographic questions to extract insights on the population under examination.\nTherefore, Q1 to Q10 refers to the interview's personal background and professional activities. We gave the partici-pants predefined answers to facilitate data analysis by lever-aging domain knowledge [3].\nFor RQ1, we asked the interviewee their degree of famil-iarity with LLMs and similar technologies. We provided a Linkert scale question (L), Q11, and a closed-ended question, Q12. A Likert scale is a psychometric scale commonly used in questionnaires to gauge respondents' attitudes, opinions, or perceptions on a particular topic [34]. It typically consists of a series of statements where respondents indicate their level of agreement or disagreement on a symmetric agree-disagree scale, usually ranging from \u201cstrongly agree\u201d to \u201cstrongly disagree.\" This method allows for the measurement of people's attitudes or feelings toward a subject in a quantitative way. The values for each Linkert Scale question are available in the replication package.\nFor RQ2, we questioned their confidence in a possible role for LLMs in aiding IT MSCs governance. Questions Q14 and Q16-17 are closed-ended questions. While Q15 is open-ended, we also made room for open-ended answers to motivate the"}, {"title": "E. Data Analysis", "content": "This section presents the data analysis of our work. Our survey includes closed and open-ended questions. Therefore, we select different analysis methods for the two types of sur-vey output. To analyze the responses to the closed questions, we initially employed descriptive statistics to gain a clearer insight into the data. For ordinal and interval data, we focused on the mode and median to assess central tendency, while for nominal data, we calculated the distribution of participants' choices for each option.\nRegarding open-ended questions, we employed qualitative data analysis techniques suggested by Strauss and Corbin [35] and Seaman and Yuepu [36]. Qualitative analysis helps answer questions of the form \"What is going on here?\u201d when we want to learn about what people understand and how they deal with what is happening to them through time and changing circumstances [17]. Thus, it is an appropriate method for explaining, for example, the practitioners perceived benefits and limitations of LLM in GMCS.\nAlthough we already know that our specific context follows mostly a conservative approach towards new technologies, we do not deem that the responses to RQ2, RQ3, and RQ4 may"}, {"title": "III. RESULTS", "content": "This section presents the results of our survey. We collected data from 31 interviewee. In the following, we first summarize the information about the study population before describing the results for each of the RQs. Due to space constraints, we present the data only in a tabular format, avoiding graphs. We note that for the closed-ended questions we decided to mention only the top-three options.\nA. Demographic\nAccording to Table II, we note that most of the participants are senior experts with ages ranging from 35 to 64 years old (Q1) with over 10 years of experience in MCC (Q9). It is worth noting that only 45% of our population have a Master's degree, while 32% have only a high school diploma (Q3).\nMoreover, most interviewees come from Europe, although 16% of them come from North America (Q4). Regarding their affiliation, organization size ranged from small companies, usually subsidiaries of bigger ones, for 19% to enterprises for 12% of them. On average, ~42% of the interviewees belong to Medium and Large companies or institutions (Q5).\nRegarding the interviewees' primary role, most are exec-utive or managerial figures or employed in compliance and regulations roles (Q6). As per the occupation, 45% of the participants are IT/Technology professionals or government officials (38%) (Q7). Similarly, most of the interviewees,"}, {"title": "B. Familiarity and experience with LLMs (RQ1)", "content": "Table III shows practitioners' familiarity with LLMs. According to Table III, most interviewees are slightly to quite familiar with LLMs, with 16% being extremely familiar and ~26% having no experience at all with them. Moreover, 32% of the interviewees have specific experiences in employing LLMs for data or risk analysis.\nTake Aways for RQ1. Most of the interviewees are familiar with general-purpose LLMs. Morover, a small percentage of them have already employed LLMs for data and risk analysis."}, {"title": "C. Perceived Benefits and Limitations (RQ2)", "content": "Table IV shows the practitioners' point of view on the future role, the potential limitations, and concerns on LLMs for risk analysis in MCC. According to Table IV, practi-tioners focused on three main future roles for LLMs in RA (Q15). More spefifically, 27% of the interviewees affirmed that LLMs are useful for automated threat detection and response and enhancing the overall predictive power of RA. Finally, envisioning a continuously running LLM, the interviewee also highlights the potential for real-time anomaly detection.\nSimilarly, practitioners highlighted legal and regulatory com-pliance challenges, limited contextual understanding, and high computation resource requirements as the top three potential limitations (Q16). Moreover, privacy and data protection, accuracy and reliability of LLMs outputs and potential bias in data analysis where the top three concerns for the practitioners (Q17).\nIn the same vein, Table V shows the practitioners' point of view on the efficiency, effectiveness, and confidence of LLMs for IT governance at large. More specifically, according to Table V, all the interviewees have positive opinions that LLMs will improve operation efficiency (Q18) as well as the effectiveness (Q19) of the overall governance. It is worth noticing that, despite the very conservative context in which our study takes place, most participants have somewhat to fairly confidence in having LLMs handling sensitive infor-mation (Q20). Similarly, most participants expressed good to excellent confidence in current LLMs capabilities, hence goodness of fit, for improving GMCS (Q21).\nTake Aways for RQ2. Practitioners expressed positive perceptions of LLMs in GMCS. However, legal and regulatory compliance challenges and limited contextual understanding"}, {"title": "D. Impact on current GMCS frameworks (RQ3)", "content": "Table VI presents the impact of integrating LLMs in the currently established governance workflow. According to Table VI, 23% of the interviewees expressed an optimistic view of the integration, and 46% of them stated that LLMs have an innovative potential (Q22). Nonetheless, ~18% expressed a cautious approach while 5% a skeptical view (Q22). Furthermore, when asked to agree on the ease of integration (Q23), ~48% expressed a neutral agreement, and ~23% expressed a good agreement, with 6% strongly agreeing and 6% strongly disagree. Similarly, when asked to agree on the absence of concerns in the integration, (Q24) ~39% of the participants had a neutral agreement. In contrast, 19% of them agreed with 6% strongly agreeing and 12% strongly disagree.\nTake Aways for RQ3. Practitioners expressed a balanced to positive perception of the integration of LLMs in the current GMCS frameworks."}, {"title": "E. Role of policy in LLM's safe and ethical use (RQ4)", "content": "Table VII presents the practitioner's concerns and initiatives proposal on safety, ethics, and policies around using LLMs in"}, {"title": "IV. DISCUSSIONS", "content": "This section discusses our findings and presents implications for researchers, practitioners, and policymakers. Our findings allowed us to grasp the perceptions of practitioners for LLMS in GMCS following the red-thread of our RQs.\nImplications for Researchers. Our findings suggest that researchers have a crucial role in addressing the limitations and ethical challenges associated with LLM deployment in mission-critical contexts. One primary area for further research is the development of context-sensitive LLMs, i.e., regulation-oriented models (Q16). Our previous attempts showed that RAG improved contextual knowledge, reducing hallucinations in RA [10], yet future efforts will be focused on investigat-ing means to realize more regulations-oriented LLMs. For instance, due to the current state of the art, no ISO standards or national and international laws are not algorithmic-friendly regarding how an algorithm, or AI approach, can tackle and operate with zero to no deviation from them. Similarly, LLM-based governance is a branch of research that is not currently receiving substantial research effort. Our work highlighted many aspects, from regulation compliance (Q16) to missing ethical framework, the needs for accountable, explainable, and transparent Als and its reliability (Q17).\nFinally, researchers can contribute by leading interdisciplinary collaborations with industry and policymakers to shape future policies for LLMs in GMCS (Q28, Q31). In leading the research in this field, with close collaboration with practitioners and policymakers on initiatives like regular workshops, audits, and seminars, researchers can contribute to developing and regulating the LLMs-based GMCS.\n1. Researchers Roles.\nResearchers should focus on frameworks to allow the design of regulation-oriented LLMs. Interdisciplinary collaboration with industry and policymakers, will help shape policies and drive responsible LLM-based gov-ernance."}, {"title": "V. THREATS TO VALIDITY", "content": "In this section, we discuss the threats to the validity of our case study. We categorized the threats in Construct, Internal, External, and Conclusion validity following established guide-lines [14] and previous similar survey works [17].\nConstruct Validity concerns how our measurements reflect what we claim to measure [14]. Our design choices, measure-ment process, and data filtering may impact our results. To address this threat, we based our choice on past studies and well-established guidelines in designing our methodology [15], [16]. Moreover, threats to the construct validity may arise due to the behavior of both participants and researchers conducting the study. The participants may act differently merely because they know they are being studied [14]. The invitation email mentioned the aim of the study to avoid hypothesis guessing and evaluation apprehension risks. The subjects were also invited to reply in light of their personal experiences. They had been assured that the questionnaire was anonymous and the identity of the persons would not be considered while considering the data.\nOn the issue of the researcher's expectations, which may involve bias either wittingly or unwittingly due to the expected outcome of the research, we used several researchers who would act as both internal and external reviewers of the questionnaire. This reduced this potential threat to a minimum.\nInternal Validity is the extent to which an experimental design accurately identifies a cause-and-effect relationship between variables [14]. Maturation and instrumentation pose significant threats to the internal validity of this study.\nInstrumentation refers to the potential impact of the tools or materials used during the study, in this case, the question-naire. A poorly designed questionnaire can compromise the reliability of the study's results [14]. To address this threat, we designed the questionnaire with only direct questions, minimizing the need for interpretation and reducing the risk of misunderstandings that could lead to irrelevant answers. Additionally, the questionnaire underwent several rounds of validation (two internal and one external) and a pilot test to identify any inconsistencies or potential misunderstandings before the survey was conducted.\nMaturation refers to the possibility that participants' re-sponses may change over time, mainly if the questionnaire is too lengthy [14]. Therefore, we designed the questionnaire to be completed within a reasonable timeframe. During the pilot study, we found an average completion time of about 15 minutes. An early indication that this threat was minimized is that all participants finished the survey. Even though the ques-tionnaire included many open-ended questions, the responses were detailed and thoughtful, indicating that participants re-mained engaged throughout the survey. Participants who did not answer specific questions were consistent with their prior responses, suggesting a clear understanding of the content.\nExternal Validity concerns how the research elements (subjects, artifacts) represent actual elements [14]. Our sample size, though not as large as another similar study, is justified by the niche context the company operates in and is still smaller than those reflecting all possible contexts of IT MCS practitioners. We tried to mitigate this threat by increasing the diversity of the participants in organizational size, expertise, and experience and geographical location. Nonetheless, due to the referenced process and regulations being primarily inter-national, our findings may represent other countries, though considering the implementation allowance the international laws grant to each nation. Given these limitations, we plan to survey with overseas partners to synthesize results across time and the development of a more robust, empirically supported understanding.\nAnother potential threat is the lack of control over the sample selection, which may cause the sample to be biased toward individuals who are very interested or biased toward"}, {"title": "VI. RELATED WORKS", "content": "Since the general availability of GAI models, most promi-nently, LLMs, consumers, practitioners, and researchers have directed their interest toward this 'new' technology [10].\nScientific works regarding LLMs and their possible im-pact on research fields and industrial use cases have started rising prominently on our field landscape [3], [10], [40]- [42]. LLMs currently impact all scientific fields, which can leverage a 'copilot.' From healthcare to software development and security, LLMs are among the pinnacles of our research achievements [3], [40].\nFor instance, Fan et al. [40], surveyed the emerging area of LLMs in Software Engineering (SE) and identified open re-search challenges related to their application. They highlighted the novelty and creativity LLMs bring to various SE activities but also pointed out the technical challenges, such as the need to filter out incorrect solutions. The survey emphasized the crucial role of hybrid techniques combining traditional SE methods with LLMs to develop reliable and effective LLM-based SE solutions.\nFuthermore, Kirova et al. [41], discussed the growing signif-icance of generative AI, particularly LLMs, in various sectors and their impact on software engineering. They emphasized the need for software engineering education to adapt to the emerging LLM environment, addressing a gap in the literature regarding LLMs' specific implications for this field. The paper explored the goals of software engineering education, changes to the discipline, course pedagogy, and ethics, arguing for a holistic approach that combines technical skills, ethical awareness, and adaptable learning strategies.\nIn the same vein as the general cautious approach to-wards these new advances, Sallou et al. [42] highlighted the significant impact of LLMs on various SE tasks, such as code completion, test generation, program repair, and code summarization. Despite their potential, the authors cautioned researchers about the complex factors affecting the outcomes of LLM-based experiments. The paper discussed potential threats to LLM research's validity, including issues like closed-source models, data leakage, and reproducibility challenges. In response, the authors proposed guidelines for SE researchers and LM providers to address these concerns, demonstrating the"}, {"title": "VII. CONCLUSIONS", "content": "This section concludes our work. With our survey, we aimed to identify the perceived benefits and limitations, and the impact that LLMs may have on the current GMCS frameworks\nOur survey highlights the essential role of interdisciplinary collaboration among researchers, practitioners, and policymakers in advancing the safe, ethical, and effective use of LLMs in GMCS. Researchers are urged to focus on regulation-oriented models and accountability, while practitioners highlight the need for data protection, transparency, and regulatory compliance to complement hu-man expertise. Finally, policymakers should work towards a unified Al framework, fostering global benchmarks and advisory boards to ensure that LLMs in GMCS can match the needed security, ethical, and accountability standards. Our future research efforts will leverage the insights of our survey as the foundation to design how to deliver to the community what practitioners perceive as necessary for the LLM-based GMCS to come to fruition."}]}