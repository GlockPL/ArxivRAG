{"title": "DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations", "authors": ["Xuming He", "Zhiwang Zhou", "Wenlong Zhang", "Xiangyu Zhao", "Hao Chen", "Shiqi Chen", "Lei Bai"], "abstract": "Weather radar data synthesis can fill in data for areas where ground observations are missing. Existing methods often employ reconstruction-based approaches with MSE loss to reconstruct radar data from satellite observation. However, such methods lead to over-smoothing, which hinders the generation of high-frequency details or high-value observation areas associated with convective weather. To address this issue, we propose a two-stage diffusion-based method called DiffSR. We first pre-train a reconstruction model on global-scale data to obtain radar estimation and then synthesize radar reflectivity by combining radar estimation results with satellite data as conditions for the diffusion model. Extensive experiments show that our method achieves state-of-the-art (SOTA) results, demonstrating the ability to generate high-frequency details and high-value areas.\nIndex Terms-Radar composite reflectivity, conditional diffusion model, Radar reconstruction", "sections": [{"title": "I. INTRODUCTION", "content": "Weather radar data, particularly radar composite reflectivity (REFC), is essential for identifying severe convective weather events, such as thunderstorms, tornadoes, and heavy pre-cipitation [1]\u2013[3]. This information allows meteorologists to track weather patterns in real-time and issue timely warnings to reduce the high impact on people's lives and economic development [4]\u2013[6]. However, conventional radar systems rely heavily on ground-based stations, leading to significant gaps in coverage in remote regions, mountainous areas, and oceans [7]. To overcome these limitations, data-driven models are being developed to utilize satellite data for radar data reconstruction [8]\u2013[12], offering a promising approach for improving the accuracy of severe weather detection.\nRecently, deep learning technology has achieved rapid development in image super-resolution [13]\u2013[16], restora-tion [17]\u2013[19], and the enhancement of spatial resolution of meteorological satellites [20]\u2013[22]. Among various deep learn-ing models, UNet-based [8], [9] and Transformer-based [10], [11] architectures have been extensively applied to the task"}, {"title": "II. METHOD", "content": "Weather radar data synthesis aims to generate a radar data estimation from satellite observation, which can be defined as\n$$T : X \\rightarrow Y, X = \\{x_i\\}_{i=1}^{N}, Y = \\{y_i\\}_{i=1}^{N}$$\nwhere $x_i$ represents the satellite observation and $y_i$ denotes the weather radar observation.\nIn this work, we exploit a powerful generative diffusion model to solve the problem of radar data synthesis. The generative diffusion model [24], [25] has demonstrated its effectiveness in conditional image generation by using con-dition inputs, such as edge, segmentation map, and specific"}, {"title": "B. Transformation Module", "content": "In the first stage, we aim to generate radar composite reflec-tivity $y'$ with well-defined contours from satellite observation data $x_i$ on a image-level. As shown in Figure 1, we utilize image-level data directly to train the transformation mod-ule. This strategy can effectively capture global relationships within the full satellite image observation.\n$$TM(x_i) = y'$$\nSpecifically, we train a transformation module (TM) with weighted loss from [26] to balance high reflectivity values, which are rare, against the more common but smaller values.\n$$L_e = \\frac{1}{m} \\sum_{i=1}^{m} exp(w_0|y'_i - t_i|^p) \\cdot (y'_i - t_i)^2,$$\nwhere $t$ and $y'$ are the ground truth and reconstructed values, $m$ is the number of pixels. The pre-trained transformation module performs as a condition preprocessing for the gen-eration module."}, {"title": "C. Generation Module", "content": "Inspired by [24], [27], we use a conditional denoising diffusion model in the second stage to reconstruct composite radar reflectivity.\nThe conditional diffusion model generates a target $y_i$ over $T$ consecutive steps starting from pure Gaussian noise. At each time step, the model takes in a time step vector and a condition $y'$, iteratively denoises the image output from the previous step according to a learned conditional distribution $p_{\\theta}(y_{t-1} | y_t, y'_i)$, and ultimate obtaining $y_0 \\sim p(y | y').$"}, {"title": "Implementation Details", "content": "We train DiffSR based on the dataset from [29]\u2013[31] over the contiguous United States (CONUS). The study uses Advanced Baseline Imager (ABI) infrared Channels 7, 9, 13 and a Geostationary Lightning Mapper (GLM) from the Geostationary Operational Environmental Satellite (GOES) as input, with composite radar reflectivity from Multi-Radar Multi-Sensor (MRMS) product as target.\nThe original image size is 768\u00d71536 pixels, with a 3-kilometer spatial resolution and a 15-minute temporal reso-lution. However, due to the slow inference speed of diffusion models with such large dimensions, we divide each image into 18 patches of 256\u00d7256 using a sliding window approach. We set a threshold $\\gamma$ and discard patches that have fewer than $\\gamma$ pixels exceeding a value of 6 to avoid data skew. We use data from April to September 2020-2021 and April to July 2022 to construct the training dataset. For testing, we use data from August to September 2022."}, {"title": "Implementation", "content": "We train DiffSR for 180 epochs with a total batch size of 256 and a threshold of $\\gamma = 1000$ on 8\u00d780GB NVIDIA A100 GPUs. The model was optimized using the Adam optimizer, with mean squared error (MSE) as the loss function. The learning rate is set to le-4. we employ SRVIT [11] as our transformation module, which contains a patches-based embedding and positional embedding to convert the input to a feature map with positional information. Then, the feature vector is processed through transformer operations to generate the results for the first stage."}, {"title": "Metrics", "content": "For evaluation, we use traditional classifica-tion metrics, including Probability of Detection (POD), False Alarm Ratio (FAR), and Critical Success Index (CSI). Root-Mean-Squared Error (RMSE) is used as a regression metric to measure the difference between ground truth and prediction. To assess perceptual similarity, we also employ Learned Perceptual Image Patch Similarity (LPIPS), and Structural Similarity Index Measure (SSIM)."}, {"title": "Baselines", "content": "In our study, we compare the performance of our proposed model with established baseline architectures. [26] employs an encoder-decoder architecture, which we refer to as \"UNet\" in our study. [11] utilizes a patch-based em-bedding followed by a transformer architecture, denoted as \u201cSRViT\u201d in our work. UNet serves as our baseline for perfor-mance comparison, enabling us to evaluate the effectiveness of our proposed approach relative to existing methods."}, {"title": "B. Experimental Results", "content": "DiffSR demonstrates superior performance in both qualita-tive and quantitative results.\nDiffSR achieves state-of-the-art results on multiple quantitative metrics, particularly in high-value areas. We employ multiple thresholds (i.e., 15, 35, 50) across different pools (i.e., pooll, pool4, pool8) of CSI to provide a more multifaceted quantitative evaluation. As shown in Table I, DiffSR significantly improves quantitative performance on perceptual metrics such as CSI, SSIM, and LPIPS, even with a slight trade-off in RMSE. It is particularly noteworthy that the largest improvements are seen in CSI-50, suggesting that DiffSR outperforms previous methods in effectiveness for high-value data associated with convective weather events.\nDiffSR demonstrates the power ability to generate re-sults with both high-value and fine-grained characteristics. In the first two rows of Fig. 2, DiffSR generates high-value areas that UNet and SRViT fail to produce. In the last two rows, it is observed that DiffSR generates more detailed features in high-value regions and more accurate contours in low-value areas. These observations are aligned with the perpetual quantitative results in Table I, which shows our DiffSR achieves the highest performance on LPIPS, SSIM, and CSI with POOL8."}, {"title": "C. Ablation Studies and Analysis", "content": "We conduct ablation studies on the conditional inputs of diffusion models, analyzing the convergence of the model under different conditions. In Table II, Diff-baselinel utilizes satellite data as the condition of the diffusion model, while Diff-baseline2 relies solely on radar estimation.\nEffectiveness of satellite data condition. Using satellite data solely as a condition for the diffusion model results in insufficient accuracy despite yielding stronger perceptual generation outcomes. Table II reveals that while Diff-baseline1 achieves higher LPIPS, its performance on CSI-50 is signifi-cantly inferior to our method, which is highly unfavorable to the observation of convective weather.\nEffectiveness of radar estimation condition. As shown in Table II, the overall performance of Diff-baseline2 is limited when using radar estimation data alone as a condition for the diffusion model due to cumulative errors. Although radar estimation already contains the contours and high-value areas of the observational data, it also brings certain estimation errors. This situation leads to error accumulation and limited performance improvement when enhancing details using only radar estimation data as conditions.\nConvergence of diffusion models. In Fig. 5, the training process of diff-baseline1, which uses only satellite data con-ditions, is the least stable and has the slowest convergence rate. Diff-baseline2, which uses radar estimation conditions, converges more rapidly but performs worse. By leveraging a two-stage framework, we first use ViT to generate the radar estimation on a image-level. Then, we combine the satellite data and radar estimation as conditions for the diffusion model. In Figure 5, DiffSR achieves superior results in both convergence speed and performance."}, {"title": "IV. CONCLUSION", "content": "We propose a universal diffusion-based framework named DiffSR, which leverages satellite data to generate radar com-posite reflectivity with finer details. The framework consists of two stages: modal transformation and detail generation. Ex-tensive experiments demonstrate that DiffSR achieves SOTA performance on multiple quantitative metrics. Furthermore, our DiffSR exhibits the power ability to generate results with both high-value and fine-grained characteristics. Even though DiffSR incorporates multiple conditions to speed up conver-gence in the training stage, it still demands a considerable number of steps to yield results during the inference stage, which is computationally expensive."}]}