{"title": "Learning Set Functions with Implicit Differentiation", "authors": ["G\u00f6zde \u00d6zcan", "Chengzhi Shi", "Stratis Ioannidis"], "abstract": "Ou et al. (2022) introduce the problem of learning set functions from data generated by a so-called optimal subset oracle. Their approach approximates the underlying utility function with an energy-based model, whose parameters are estimated via mean-field variational inference. Ou et al. (2022) show this reduces to fixed point iterations; however, as the number of iterations increases, automatic differentiation quickly becomes computationally prohibitive due to the size of the Jacobians that are stacked during backpropagation. We address this challenge with implicit differentiation and examine the convergence conditions for the fixed-point iterations. We empirically demonstrate the efficiency of our method on synthetic and real-world subset selection applications including product recommendation, set anomaly detection and compound selection tasks.", "sections": [{"title": "1 Introduction", "content": "Many interesting applications operate with set-valued outputs and/or inputs. Examples include product recommendation (Bonab et al. 2021; Schafer, Konstan, and Riedl 1999), compound selection (Ning, Walters, and Karypis 2011), set matching (Saito et al. 2020), set retrieval (Feng, Zhou, and Lan 2016), point cloud processing (Zhao et al. 2019; Gionis, Gunopulos, and Koudas 2001), set prediction (Zhang, Hare, and Prugel-Bennett 2019), and set anomaly detection (Ma\u0161kov\u00e1 et al. 2024), to name a few. Several recent works (Zaheer et al. 2017; Lee et al. 2019) apply neural networks to learn set functions from input/function value pairs, assuming access to a dataset generated by a function value oracle. In other words, they assume having access to a dataset generated by an oracle that evaluates the value of the set function for any given input set.\nRecently, Ou et al. (2022) proposed an approximate maximum likelihood estimation framework under the supervision of a so-called optimal subset oracle. In contrast to traditional function value oracles, a label produced by an optimal subset oracle is the subset that maximizes an (implicit) utility set function, in the face of several alternatives. The goal of inference is to learn, in a parametric form, this utility function, under which observed oracle selections are optimal. As MLE is intractable in this setting, Ou et al. (2022) propose"}, {"title": "2 Related Work", "content": "Learning Set Functions from Oracles. There is a line of work where a learning algorithm is assumed to have access to the value of an unknown utility function for a given set (Feldman and Kothari 2014; Balcan and Harvey 2018; Zaheer et al. 2017; Lee et al. 2019; Wendler et al. 2021; De and Chakrabarti 2022). This is the function value oracle setting. Zaheer et al. (2017) and De and Chakrabarti (2022) regress over input set - function value pairs by minimizing the squared loss of the predictions while Lee et al. (2019) minimize the mean absolute error. However, obtaining a function value to a given subset is not an easy task for real-world applications. The value of a set may not be straightforward to quantify or can be expensive to compute. Alternatively, Tschiatschek, Sahin, and Krause (2018) and Ou et al. (2022) assume having access to an optimal subset oracle for a given ground set in the training data. Similarly, we do not learn the objective function explicitly from input set - output value pairs. We learn it implicitly in the optimal subset oracle setting.\nLearning Set Functions with Neural Networks. Multiple works aim to extend the capabilities of neural networks for functions on discrete domains, i.e., set functions (Zaheer et al. 2017; Wendler, P\u00fcschel, and Alistarh 2019; Soelch et al. 2019; Lee et al. 2019; Wagstaff et al. 2019; Kim et al. 2021; Zhang et al. 2022a; Giannone and Winther 2022). Diverging from the traditional paradigm where the input data is assumed to be in a fixed dimensional vector format, set functions are characterized by their permutation invariance, i.e., the output of a set does not depend on the order of its elements. We refer the reader to a survey about permutation-invariant networks by Kimura et al. (2024) for a more detailed overview. In this work, we also enforce permutation invariance by combining the energy-based model in Sec. 3.1 with deep sets (Zaheer et al. 2017), following the proposed method of Ou et al. (2022) (see also App. A).\nKaralias et al. (2022) integrate neural networks with set functions by leveraging extensions of these functions to the continuous domain. Note that, their goal is not to learn a set function but to learn with a set function, which differs from our objective.\nLearning Submodular Functions. It is common to impose some structure on the objective when learning set functions. The underlying objective is often assumed to be submodular, i.e., it exhibits a diminishing returns property, while the parameters of such function are typically learned from function value oracles (Dolhansky and Bilmes 2016; Bilmes and Bai 2017; Djolonga and Krause 2017; Kothawade et al. 2020; De and Chakrabarti 2022; Bhatt, Das, and Bilmes 2024; Gomez-Rodriguez, Leskovec, and Krause 2012; Bach 2013; Feldman and Kothari 2014; He et al. 2016). We do not make such assumptions, therefore, our results are applicable to a broader class of set functions.\nImplicit Differentiation. In the context of machine learning, implicit differentiation is used in hyperparameter optimization (Lorraine, Vicol, and Duvenaud 2020; Bertrand et al. 2020), optimal control (Xu, Molloy, and Gould 2024), reinforcement learning (Nikishin et al. 2022), bi-level optimization (Arbel and Mairal 2022; Zucchet and Sacramento 2022), neural ordinary differential equations (Chen et al. 2018; Li et al. 2020) and set prediction (Zhang et al. 2022b), to name a few. Inspired by the advantages observed over this wide-range of problems, we use implicit differentiation, i.e., a method for differentiating a function that is given implicitly (Krantz and Parks 2002), to learn set functions for subset selection tasks by leveraging the JAX-based, modular automatic implicit differentiation tool provided by Blondel et al. (2022).\nImplicit Layers. Instead of specifying the output of a deep neural network layer as an explicit function over its inputs, implicit layers are specified implicitly, via the conditions that layer outputs and inputs must jointly satisfy (Kolter, Duvenaud, and Johnson 2020). Deep Equilibrium Models (DEQs) (Bai, Kolter, and Koltun 2019) and their variants (Winston and Kolter 2020; Huang, Bai, and Kolter 2021; Sittoni and Tudisco 2024) directly compute the fixed-point resulting from stacking up hidden implicit layers by black-box root-finding methods, while also directly differentiating through the stacked fixed-point equations via implicit differentiation. We adapt this approach when satisfying the fixed-point constraints arising in our setting. The main difference is that in the aforementioned works, implicit layers correspond to a weight-tied feedforward network while in our case, they correspond to a deep set (Zaheer et al. 2017) style architecture."}, {"title": "3 Problem Setup", "content": "In the setting introduced by Ou et al. (2022), the aim is to learn set functions from a dataset generated by a so-called optimal subset oracle. The dataset D consists of sample pairs of the form (S*, V), where (query) $V \\subseteq \\Omega$ is a set of options, i.e., items from a universe \u03a9 and (response) S* is the optimal subset of V, as selected by an oracle. We further assume that each item is associated with a feature vector of dimension df, i.e., $ \\Omega \\subseteq \\mathbb{R}^{d_f} $. The goal is to learn a set function $F_{\\theta} : 2^{\\Omega} \\times 2^{\\Omega} \\rightarrow \\mathbb{R}$, parameterized by \u03b8 \u2208 Rd, modeling the utility of the oracle, so that\n$S^* = \\arg \\max_{S \\subseteq V} F_{\\theta}(S, V), $  (1)\nfor all pairs (S*, V) \u2208 D. As a motivating example, consider the case of product recommendations. Given a ground set V of possible products to recommend, a recommender selects an optimal subset S* C V and suggests these to a user. In this setting, the function F\u03b8(S, V) captures, e.g., the recommender objective, the utility of the user, etc. Having access to a dataset of such pairs, the goal is to learn F\u03b8, effectively reverse-engineering the objective of the recommender engine, inferring the user's preferences, etc."}, {"title": "3.1 MLE with Energy-Based Modeling", "content": "Ou et al. (2022) propose an approximate maximum likelihood estimation (MLE) by modeling oracle behavior via a Boltzmann energy (i.e., soft-max) model (Murphy 2012; Mnih and Hinton 2005; Hinton et al. 2006; LeCun et al. 2006). They assume that the oracle selection is probabilistic, and the probability that S is selected given options V is given by:\n$p_{\\theta}(S | V) = \\frac{\\exp (F_{\\theta}(S, V))}{\\sum_{S' \\subset V} \\exp (F_{\\theta}(S', V))}.$ (2)\nThis is equivalent to Eq. (1), presuming that the utility F\u03b8(\u00b7) is distorted by Gumbel noise (Kirsch et al. 2023). Then, given a dataset D = {(S*, Vi)}N\ni=1, MLE amounts to:\n$\\arg \\max_{\\theta} \\sum_{i=1}^{N} [\\log p_{\\theta} (S_i^* | V_i)].$ (3)\nNotice that multiplying F\u03b8 with a constant c > 0 makes no difference in the behavior of the optimal subset oracle in Eq. (1): the oracle would return the same decision under arbitrary re-scaling. However, using c \u00b7 F\u03b8(\u00b7) in the energy-based model of Eq. (2) corresponds to setting a temperature parameter c in the Boltzmann distribution (Murphy 2012; Kirsch et al. 2023), interpolating between the deterministic selection (c \u2192 \u221e) in Eq. (1) and the uniform distribution (c\u2192 0)."}, {"title": "3.2 Variational Approximation of Energy-Based Models", "content": "Learning \u03b8 by MLE is challenging precisely due to the exponential number of terms in the denominator of Eq. (2). Instead, Ou et al. (2022) construct an alternative optimization objective via mean-field variational inference as follows. First, they introduce a mean field variational approximation of the density p\u03b8 given by q(S, V, \u03c8) = \u03a0j\u2208S \u03c8j \u03a0j\u2208V\\S(1 \u2212 \u03c8j), parameterized by the probability vector \u03c8: this represents the probability that each element j \u2208 V is in the optimal subset S*. Then, estimation via variational inference amounts to the following optimization problem:\n$\\min_{\\{\\psi\\}, \\theta} \\mathcal{L}(\\{\\psi\\}) = E_{p(V, S)}[ - \\log q(S, V, \\psi^*)] \\approx$ (4)\n$\\frac{1}{N} \\sum_{i=1}^{N} [ - \\sum_{j \\in S_i} \\log \\psi_{ij} - \\sum_{j \\in V_i \\setminus S_i} \\log (1 - \\psi_{ij}) ] $ \nsubj. to $ \\psi^* = \\arg \\min_{\\psi} KL(q(S_i, V_i, \\Psi) || p_{\\theta}(S_i | V_i)), $ for all i \u2208 {1, ..., n},\nwhere \u03c8i \u2208 [0, 1]|Vi| is the probability vector of elements in Vi being included in Si, KL(\u00b7||\u00b7) is the Kullback-Leibler divergence, and p\u03b8(\u00b7) is the energy-based model defined in Eq. (2). In turn, this is found through the ELBO maximization process we discuss in the next section."}, {"title": "3.3 ELBO Maximization", "content": "From a Bayesian point of view, multiplying F\u03b8(\u00b7) with c > 0 yields the posterior predictive distribution under an uninformative Dirichlet conjugate prior per set with parameter \u03b1 = e\u03b8 (Murphy 2012).\nTo compute \u03c8*, Ou et al. (2022) show that minimizing the constraint in Eq. (4) via maximizing the corresponding evidence lower bound (ELBO) reduces to solving a fixed point equation. In particular, omitting the dependence on i for brevity, the constraint in Eq. (4) is equivalent to the following ELBO maximization (Kingma and Welling 2013; Blei, Kucukelbir, and McAuliffe 2017):\n$ \\max_{\\psi} F(\\psi, \\theta) + H(q(S, V, \\psi)), $  (5)\nwhere H(\u00b7) is the entropy and $F : [0, 1]^{|V|} \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}$ is the so-called multilinear extension of F\u03b8(S, V) (Calinescu et al. 2011), given by:\n$F(\\psi, \\theta) = \\sum_{S \\subset V} F_{\\theta}(S, V) \\prod_{j \\in S} \\psi_j \\prod_{j \\in V \\setminus S} (1 - \\psi_j).$ (6)\nOu et al. (2022) show that a stationary point maximizing the ELBO in Eq. (5) must satisfy:\n$\\psi - \\sigma(\\nabla_{\\psi} F(\\psi, \\theta)) = 0,$ (7)\nwhere the function \u03c3 : R|V| \u2192 R|V| is defined as \u03c3(x) = [\u03c3(x)]j=1 and \u03c3: R \u2192 R is the sigmoid function, i.e., \u03c3(x) = (1 + exp(-x))-1. The detailed derivation of this condition can be found in App. \u0421.1."}, {"title": "3.4 DiffMF and Variants", "content": "Putting everything together yields the DiffMF algorithm introduced by Ou et al. (2022). For completeness, we summarize this procedure in Alg. 1. In short, they implement the fixed-point iterative update steps in Eq. (8) by executing a fixed number of iterations K, given \u03b8, and unrolling the loop: in their implementation, this amounts to stacking up K layers, each involving an estimate of the gradient of the multilinear relaxation via sampling, and thereby multiple copies of a neural network representing F\u03b8(\u00b7) (one per sample). Subsequently, this extended network is entered in the loss given in Eq. (4), which is minimized w.r.t. \u03b8 via SGD.\nThey also introduce two variants of this algorithm, regressing also \u03c8(0) as a function of the item features via an extra recognition network, assuming the latter are independent (terming inference in this setting as EquiVSetind) or correlated by a Gaussian copula (Sklar 1973; Nelsen 2006) (termed EquiVSetcopula). Compared to DiffMF, both translate to additional initial layers and steps per epoch."}, {"title": "3.5 Challenges", "content": "The above approach by Ou et al. (2022), and its variants, have two drawbacks. First, the fixed-point iterative updates given in Eq. (8) are not guaranteed to converge to an optimal solution. We indeed frequently observed divergence experimentally, in practice. Without convergence and uniqueness guarantees, the quality of the output, \u03c8(K), is heavily dependent on the selection of the starting point, \u03c8(0). Moreover, as these iterations correspond to stacking up layers, each containing multiple copies of F\u03b8(\u00b7) due to sampling, backpropagation is computationally prohibitive both in terms of time as well as space complexity. In fact, poor performance due to lack of convergence, as well as computational considerations, led Ou et al. to set the number of iterations to K \u2264 5 (even K = 1) in their experiments. We address both of these challenges in the next section."}, {"title": "4 Our Approach", "content": "Recall from the previous section that minimizing the constraint of the optimization problem given in Eq. (4) is the equivalent of the ELBO in Eq. (5), and the stationary condition of optimizing this ELBO reduces to Eq. (7). Stitching everything together, we wish to solve the following optimization problem:\n$\\min_{\\{\\psi\\}, \\theta} \\mathcal{L}(\\{\\psi\\}) \\approx$ (9)\n$\\frac{1}{N} \\sum_{i=1}^{N} [ - \\sum_{j \\in S_i} \\log \\psi_{ij} - \\sum_{j \\in V_i \\setminus S_i} \\log (1 - \\psi_{ij}) ] $ \nsubj. to $ \\psi = \\sigma(\\nabla_{\\psi} F(\\psi, \\theta)), $ for all i \u2208 {i, . . ., n}.\nTo achieve this goal, we (a) establish conditions under which iterations of Eq. (8) converge to a unique solution, by utilizing the Banach fixed-point theorem and (b) establish a way to efficiently compute the gradient of the loss at the fixed-point by using the implicit function theorem. Our results pave the way to utilize recent tools developed in the context of implicit differentiation (Bai, Kolter, and Koltun 2019; Kolter, Duvenaud, and Johnson 2020; Blondel et al. 2022) to the setting of Ou et al. (2022)."}, {"title": "4.1 Convergence Condition for the Fixed-Point", "content": "Fixed-points can be attracting, repelling, or neutral (Davies 2018; Rechnitzer 2003). We characterize the condition under which the convergence is guaranteed in the following assumption.\nAssumption 4.1. Consider the multilinear relaxation $F : [0,1]^{|V|} \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}$ of F\u03b8(\u00b7), as defined in Eq. (6). For all \u03b8 \u2208 Rd,\n$\\sup_{\\psi \\in [0,1]} |F(\\psi, \\theta)| < \\frac{1}{|V|}.$ (10)\nAs discussed in Sec. 3, scaling F\u03b8(S, V) by a positive scalar amounts to setting the temperature of a Boltzmann distribution. Moreover, neural networks are often Lipschitz-regularized for bounded inputs and weights (Szegedy et al. 2014; Virmaux and Scaman 2018; Gouk et al. 2021). Therefore, for any such Lipschitz neural network, we can satisfy Asm. 4.1 by appropriately setting the temperature parameter of the EBM in Eq. (2). Most importantly, satisfying this condition guarantees convergence:\nTheorem 4.2. Assume a set function $F_{\\theta} : 2^V \\rightarrow \\mathbb{R}$ satisfies Asm. 4.1. Then, the fixed-point given in Eq. (7) has a unique solution \u03c8* \u2208 [0, 1]|V| where \u03c8* = \u03c3(\u2207\u03c8F(\u03c8*, \u03b8)). Moreover, starting with an arbitrary point \u03c8(0) \u2208 [0, 1]|V|, \u03c8\u2217 can be found via the fixed-point iterative sequence described in Eq. (8) where limk\u2192\u221e \u03c8(k) = \u03c8*."}, {"title": "4.2 Efficient Differentiation through Implicit Layers", "content": "Our second contribution is to disentangle gradient computation from stacking layers together, by using the implicit function theorem (Krantz and Parks 2002). This allows us to use the recent work on deep equilibrium models (DEQs) (Bai, Kolter, and Koltun 2019; Kolter, Duvenaud, and Johnson 2020).\nDefine \u03c8*(\u00b7) to be the map \u03b8 \u2192 \u03c8*(\u03b8) induced by Eq. (7); equivalently, given \u03b8, \u03c8*(\u03b8) is the (unique by Thm. 4.2) limit point of iterations given in Eq. (8). Observe that, by the chain rule:\n$\\nabla_{\\theta} \\mathcal{L}(\\psi^*(\\theta)) = \\nabla_{\\psi} \\mathcal{L}(\\psi^*(\\theta)) \\cdot \\partial_{\\theta} \\psi^*(\\theta).$ (11)\nThe term that is difficult to compute here via backpropagation, that required stacking in Ou et al. (2022), is the Jacobian \u2202\u03b8\u03c8*(\u03b8), as we do not have the map \u03c8*(\u00b7) in a closed form. Nevertheless, we can use the implicit function theorem (see Thm. D.4 in App. D) to compute this quantity. Indeed, to simplify the notation for clarity, we define a function $G : [0, 1]^{|V|} \\times \\mathbb{R}^d \\rightarrow [0, 1]^{|V|}$, where\n$G(\\psi(\\theta), \\theta) \\equiv \\sigma(\\nabla_{\\psi} F(\\psi,\\theta)) - \\psi$\nand rewrite Eq. (7) as G(\u03c8(\u03b8), \u03b8) = 0. Using the implicit function theorem, given in App. D, we obtain\n$- \\partial_{\\psi} G(\\psi^*(\\theta), \\theta) \\partial_{\\theta} \\psi^*(\\theta) = \\partial_{\\theta} G(\\psi^*(\\theta), \\theta).$ (12)\nThis yields the following way of computing the Jacobian via implicit differentiation:\nTheorem 4.3. Computing \u2202\u03b8\u03c8*(\u03b8) is the equivalent of solving a linear system of equations, i.e., \u2202\u03b8\u03c8*(\u03b8) = A-1B,\nA = $I - \\Sigma' (\\nabla_{\\psi} F (\\psi, \\theta)) \\cdot \\nabla^2_{\\psi} F (\\psi, \\theta)$, and\nB = $ \\Sigma'(\\nabla_{\\psi} F (\\psi, \\theta)) \\cdot \\partial_{\\theta} \\nabla_{\\psi} F (\\psi, \\theta),$ (13)\nwhere \u03c3'(x) = diag([\u03c3'(xj)])j=1 and \u03c3'(x) = (1 + exp(-x))-2 \u00b7 exp (-x).\nThe proof is in App. F. Eq. (12) shows that the Jacobian of the fixed-point solution, \u2202\u03b8\u03c8*(\u03b8), can be expressed in terms of Jacobians of G at the solution point. This means implicit differentiation only needs the final fixed point value, whereas automatic differentiation via the approach by Ou et al. (2022) required all the iterates (see also (Kolter, Duvenaud, and Johnson 2020)). In practice, we use JAXopt (Blondel et al. 2022) for its out-of-the-box implicit differentiation support. This allows us to handle Hessian inverse computations efficiently (see App. G)."}, {"title": "4.3 Implicit Differentiable Mean Field Variation", "content": "Putting everything together, we propose implicitly Differentiable Mean Field variation (iDiffMF) algorithm. This algorithm finds the solution of the fixed-point in Eq. (7) by a root-finding method. Then, computes the gradient of the loss given in Eq. (11) by using the result of the implicit function theorem given in Thm. 4.3, and updates parameter \u03b8 in the direction of this gradient. We summarize this process in Alg. 2.\nTo emphasize the difference between Alg. 1 and Alg. 2, let us focus on lines 13 and 9, respectively. On Line 13 of the"}, {"title": "4.4 Complexity", "content": "Reverse mode automatic differentiation has a memory complexity that scales linearly with the number of iterations performed for finding the root of the fixed-point, i.e., it has a memory complexity of O(K) where K is the total number of iterations (Bai, Kolter, and Koltun 2019). On the other hand, reverse mode implicit differentiation has a constant memory complexity, O(1), because the differentiation is performed analytically as a result of using the implicit function theorem. Fig. 1 in Sec. 5 reflects the advantage of using implicit differentiation in terms of space requirements numerically.\nIn the forward mode, the time complexity of the iterative sequence inside DiffMF is again O(K) as the number of iterations is pre-selected and does not change with the rate of convergence. Inside iDiffMF, the convergence rate depends on the Lipschitz constant of the fixed-point in Eq. (7) and the size of the ground set. In particular, the number of iterations required for finding the root of Eq. (7) is bounded by $ \\log(\\epsilon(1-q)/\\sqrt{|V|}) \\over {\\log q} $ where \u03f5 is the"}, {"title": "5 Experiments", "content": "We evaluate our proposed method on five datasets including set anomaly detection, product recommendation, and compound selection tasks (see Tab. 1 for a datasets summary and App. I for detailed dataset descriptions). The Gaussian and Moons are synthetic datasets, while the rest are real-world datasets. We closely follow the experimental setup of Ou et al. (2022) w.r.t. competing algorithm setup, experiments, and metrics."}, {"title": "5.1 Algorithms", "content": "We compare three competitor algorithms from (Ou et al. 2022) to three variants of our iDiffMF algorithm (Alg. 2). Additional implementation details are in App. I.\nDiffMF (Ou et al. 2022): This is the differentiable mean field variational inference algorithm described in Alg. 1. As per Ou et al., we set the number of iterations to K = 5 for all datasets.\nEquiVSetind (Ou et al. 2022): This is the equivariant variational inference algorithm proposed by Ou et al. (2022). It is a variation of the DiffMF algorithm where the parameter \u03b8 is predicted by an additional recognition network as a function of the data. As per Ou et al. (2022), we set K = 1 for all datasets.\nEquiVSetcopula (Ou et al. 2022): A correlation-aware version of the EquiVSetind algorithm where the relations among the input elements are modeled by a Gaussian copula. As per Ou et al. (2022), we set K = 1 for all datasets.\niDiffMF (Alg. 2): Our proposed implicit alternative to the DiffMF algorithm where we solve the fixed-point condition in Eq. (7) with a low tolerance threshold (\u03f5 = 10-6), instead of running the fixed-point iterations in Eq. (8) for only a fixed number of times. Although DNNs are bounded, the exact computation of their Lipschitz constant is, even for two-layer Multi-Layer-Perceptrons (MLP), NP-hard (Virmaux and Scaman 2018). In our implementation, we use several heuristic approaches to satisfy the condition in Asm. 4.1. First, we multiply the multilinear relaxation F by a constant scaling factor 2/(|V|c), treating c as a hyperparameter. We refer to this as iDiffMFc. We also consider a dynamic adaptation per batch and fixed-point iteration, normalizing the gradient of the multilinear relaxation by its norm as well as size of the ground set; we describe this heuristic in App. I.3. We propose two variants, termed iDiffMF2 and iDiffMF*, using l2 (||\u00b7||2) and nuclear (||\u00b7 ||*) norms when scaling, respectively."}, {"title": "5.2 Metrics", "content": "Following Ou et al. (2022), we measure the performance of different algorithms by (a) using the trained neural network to predict the optimal subsets corresponding to each query on the test set, and (b) measure the mean Jaccard Coefficient (JC) score across all predictions. We describe how the trained objective F\u03b8(\u00b7) is used to produce an optimal subset \u015c given query Vi in the test set in App. 1.5.\nWe also measure the running time and the GPU memory usage of the algorithms. During training, we track the amount of"}, {"title": "5.3 Results", "content": "We report the predictive performance of our proposed iDiffMF2 and iDiffMF* methods against the existing DiffMF method and its variants on Tab. 2, and iDiffMFc in App. I.7. For the vast majority of the test cases, iDiffMF variants achieve either the best or the second-best JC score. While the next best competitor, EquiVSetcopula, performs the best on some datasets, its performance is not consistent on the remaining datasets, not being even the second best. For the Amazon carseats, furniture and safety datasets, iDiffMF variants give significantly better results than EquiVSetcopula, even though EquiVSetcopula is faster. This is probably because EquiVSetcopula converges to a local optimum and finishes training earlier. It is also important to highlight that we evaluate iDiffMF using JAX+Flax while we use PyTorch to evaluate the baselines. Therefore, the differences in running time can also be explained with the framework differences. Even though iDiffMF executes fixed-point iterations until convergence, as opposed to K = 1 or K = 5 in remaining methods (Ou et al. 2022), the average running times are comparable across datasets.\nIn Fig. 1, we demonstrate the advantages of using implicit differentiation in terms of space complexity. As discussed in Sec. 4.4, memory requirements remain constant in an interval as the number of fixed-point iterations increases during implicit differentiation. On the contrast, memory requirements increase linearly with the number of iterations during automatic differentiation."}, {"title": "6 Conclusion", "content": "We improve upon an existing learning set functions with an optimal subset oracle setting by characterizing the convergence condition of the fixed point iterations resulting during MLE approximation and by using implicit differentiation over automatic differentiation. Our results perform better than or comparable to the baselines for the majority of the cases without the need of an additional recognition network while requiring less memory."}, {"title": "A Permutation Invariance", "content": "In this section, we formally define permutation invariant functions and state the relationship between sum-decomposable and permutation-invariant functions following the works of Zaheer et al. (2017) and Wagstaff et al. (2019). We use these definitions to explain how we also enforce the property of permutation invariance in this work.\nDefinition A.1. (Zaheer et al. 2017, Property 1) A function f(x) is permutation-invariant if $ f(x_1,...,x_M) = f(x_{\\pi(1)},..., x_{\\pi(M)}) $ for all \u03c0 permutations.\nDefinition A.2. (Wagstaff et al. 2019, Definition 2.2) A set function f is sum-decomposable if there are functions \u03c1 and \u03c6 such that\n$f(S) = \\rho (\\sum_{s \\in S} \\phi(s))$\nTheorem A.3. (Zaheer et al. 2017, Theorem 2) (Wagstaff et al. 2019, Theorem 2.8) Let $f : 2^S \\rightarrow \\mathbb{R}$ where S is countable. Then, f is permutation-invariant if and only if it is sum-decomposable via R.\nIn Ou et al. (2022), \u03c6 is a dataset specific initial layer that takes set elements, s, as inputs and transforms them into some representation \u03c6(s). These representations are added up and go through \u03c1, a fully connected feed forward neural network. We use the same architectures for \u03c6 and \u03c1 (see App. I.6). As a result, our model satisfies the permutation invariance property."}, {"title": "B Proof of Equation (5)", "content": "Proof. Starting from the definition of the KL divergence, we get\n$KL(q(S, \\psi)||p_{\\theta}(S)) = \\sum_{S \\subset V} q(S, \\psi) \\log \\frac{q(S, \\psi)}{p_{\\theta}(S)} $\n$= \\sum_{S \\subset V} q(S, \\psi) (\\log q(S, \\psi) - \\log p_{\\theta}(S))$\n$= \\sum_{S \\subset V} (q(S, \\psi) \\log q(S, \\psi) - q(S, \\psi) \\log p_{\\theta}(S))$\n$= \\sum_{S \\subset V} q(S, \\psi) \\log q(S, \\psi) - \\sum_{S \\subset V} q(S, \\psi) \\log p_{\\theta}(S)$\n$= -H(q(S, \\psi)) - E_{q(S, \\psi)}[\\log p_{\\theta}(S)].$\nObserve that, by Eq. (2).\n$E_{q(S, \\psi)}[\\log p_{\\theta}(S)] = E_{q(S, \\psi)}[F_{\\theta}(S)] - Z = F(\\psi, \\theta) - Z$\nwhere $Z = \\sum_{S' \\subset V} \\exp (F_{\\theta}(S', V))$ does not depend on \u03c8 and can be dropped, F(\u03c8, \u03b8) is the multilinear relaxation. Therefore, minimizing the KL divergence w.r.t. \u03c8 is equivalent to maximizing F(\u03c8, \u03b8) + H(q(S, \u03c8)). In summary,\n$\\min_{\\psi} KL(q(S, \\psi)||p_{\\theta}(S)) \\leftrightarrow \\max_{\\psi} F(\\psi, \\theta) + H(q(S, \\psi)).$ (14)"}, {"title": "C Derivations for Sec. 3", "content": "C.1 Derivation of the Fixed-Point\nRewriting the ELBO by plugging in the definition of entropy,\n$F(\\psi, \\theta) + H(q(S, \\psi)) = F(\\psi, \\theta) - \\sum_{i=1}^{|V|} [\\psi_i \\log \\psi_i + (1 - \\psi_i) \\log(1 - \\psi_i)].$ (15)"}, {"title": "D Technical Preliminaries", "content": "Theorem D.1. (Multivariate Mean Value"}]}