{"title": "KHNNS: hypercomplex neural networks computations via Keras using TensorFlow and PyTorch", "authors": ["Agnieszka Niemczynowicza", "Rados\u0142aw Antoni Kyciab"], "abstract": "Neural networks used in computations with more advanced algebras than real numbers perform better in some applications. However, there is no general framework for constructing hypercomplex neural networks. We propose a library integrated with Keras that can do computations within TensorFlow and PyTorch. It provides Dense and Convolutional 1D, 2D, and 3D layers architectures.", "sections": [{"title": "1. Motivation and significance", "content": "The Artificial Neural Networks (NN) develop in various directions. One of them is the replacement of real numbers computations within the neurons by different hypercomplex algebras like Complex numbers, Quaternions, Clifford algebras, or Octonions. There is a strong suggestion [7, 3] that such an approach results in NN that has fewer training parameters than the real- numbers approach with similar accuracy.\nThe Open Source implementation was provided for some four-dimensional hypercomplex algebras in [7]. This implementation requires the computa- tion of an algebra multiplication matrix to include new algebras. It also works only for four-dimensional data. In [4], the theoretical aspects of gener- alization for all possible algebras, including hypercomplex ones, were given. In this paper we describe an example implementation."}, {"title": "2. Software description", "content": "The library is based on Keras and has two branches: TensorFlow and Py- Torch. This means there are Dense and Convolutional layers that use internal TensorFlow, and PyTorch computations.\nThe library has predefined algebras like Complex numbers, Quaternions, Klein four-group, Clifford algebra (2,0), Clifford algebra (1,1), Bicomplex numbers, Tessarines, and Octionions. However it has an easy way to imple- ment arbitrary algebra computations.\nThe workflow with the library is standard and is as follows:\n1. Import algebra module and select or define algebra to work with.\n2. Import desired layers\n3. Construct neural network from the layers\n4. Train and tune NN\n5. Make predictions"}, {"title": "2.1. Software architecture", "content": "The KHNN is a divided into three logical parts:\n\u2022 Algebra module: contains the StructureConstants class that allows to define multiplication of an algebra; contains also predefined multi- plication tables for various algebras: Complex, Quaternions, Klein4, C120 Clifford (2,0) algebra, Coquaternions, Cl11- Clifford (1,1), Bicomplex, Tessarines, Octonions;\n\u2022 Keras + TensorFlow part contains:\nHyperdense module that contains HyperDense class realizing hy- percomplex Dense layer;"}, {"title": "2.2. Software functionalities", "content": "The software have two types of functionality: Algebra manipulations and NN construction.\nThe algebra computations are realized by Algebra module. The basic class is StructureConstants, which realizes multiplication within the algebra. We summarize the theory briefly from [4]. Assume that the algebra has a base $\\{e_i\\}_{i=1}^n$, where n is the dimension of algebra. One assumes that $e_0$ is the multiplication unit. Then the multiplication is defined by the tensor $C_{i,j}^k = A_{ijk} e_k$. An example of a multiplication table is given in (1).\n\n$e_j$\n$e_i$\n$C_{i,j}^k = A_{ijk} e_k$\n(1)\n\nThe way of defining a multiplication matrix is to define the dictionary where the entry is (i, j) : (k, $A_{ijk}$). \nAs a simple example define complex numbers (already defined in library) given by the multiplication table (2).\n\n$e_0 = 1$\n$e_1 = i$\n$e_0 = 1$\n$e_0$\n$e_1$\n(2)\n$e_1 = i$\n$e_1$\n$-e_0$\n\nThe second type is to define neural networks, which will be presented in the following subsection."}, {"title": "3. Illustrative examples", "content": "We give some elementary examples of applications of the KHNN library. The first example will be related to HyperDense layer for quaternions.\nThe example for TensorFlow is presented below.\n\nThe same code using PyTorch implementation:"}, {"title": "4. Impact", "content": "Currently, applications of hypercomplex algebras in neural networks and us- age in various disciplines are beginning. Usually, research focuses only on a small range of algebras due to a case-by-case approach to implementation. The presented library makes significant progress in the field by providing a general framework for the broad application of such NN.\nWhen data naturally lump into tuples, one can always try to find an algebra of data lump that encodes a single piece of data in its representative, and then, process it naturally as a whole.\nSince NN has various applications, the usefulness of this library is immense."}, {"title": "5. Conclusions", "content": "KHNN is a small, versatile library that updates the Keras interface (both in TensorFlow and PyTorch) for hypercomplex Dense and Convolutional layers. It can be extended easily for any algebra. Thanks to this, it can become an essential research tool for hypercomplex neural networks and applications."}]}