{"title": "Investigating the Monte-Carlo Tree Search Approach for the Job Shop Scheduling Problem", "authors": ["Boveroux Laurie", "Ernst Damien", "Louveaux Quentin"], "abstract": "The Job Shop Scheduling Problem (JSSP) is a well-known optimization problem in manufacturing, where the goal is to determine the optimal sequence of jobs across different machines to minimize a given objective. In this work, we focus on minimising the weighted sum of job completion times. We explore the potential of Monte Carlo Tree Search (MCTS), a heuristic-based reinforcement learning technique, to solve large-scale JSSPs, especially those with recirculation. We propose several Markov Decision Process (MDP) formulations to model the JSSP for the MCTS algorithm. In addition, we introduce a new synthetic benchmark derived from real manufacturing data, which captures the complexity of large, non-rectangular instances often encountered in practice. Our experimental results show that MCTS effectively produces good-quality solutions for large-scale JSSP instances, outperforming our constraint programming approach.", "sections": [{"title": "Introduction", "content": "The Job Shop Scheduling Problem (JSSP) is a complex challenge faced by manufacturers. The JSSP involves determining the optimal sequence of jobs on different machines to ensure that production processes are carried out efficiently. This problem is important because it directly impacts a company's productivity, operating costs and ability to meet delivery schedules. For example, delays in the production schedule can cause bottlenecks, higher inventory costs, and missed deadlines. These issues can lead to unhappy customers and financial penalties. Therefore, optimizing job scheduling is a practical need and a decisive strategy for success.\nMany mathematical programming-based approaches exist to solve the JSSP, such as mixed-integer linear programming and constraint programming. These methods are exact as they find optimal solutions by exhaustively exploring the search space.\nHowever, they have limitations in practice. The JSSP is known to be NP-hard. As the number of jobs and machines increases, the complexity of the problem grows exponentially. In practice, scheduling problems are often large-scale, dynamic and imbalanced. In such scenarios, some machines may be heavily loaded while others are idle and processing times of the tasks can vary widely from a few units of time to several hundreds units. In large-scale environments, exact methods often become impractical.\nTo address these limitations, approximate solutions have been developed. Commonly used heuristics are Priority Dispatching Rules (PDRs) [1]. PDRs"}, {"title": "Problem Statement", "content": "We consider the JSSP. In a general JSSP, we are given a set I of n jobs J1, J2, ..., Jn and a set M of m machines. Each job Ji \u2208 I has an operation set O; which contains ni operations Oij that must be processed in a specific order (i.e., with precedence constraints). Each operation Oij of job Ji requires a processing time pij on a specific machine M(ij). A job can have several operations that must be processed on the same machine (i.e., recirculation). Each machine can process at most one operation at a time with no preemption.\nTo solve the JSSP, we must find a schedule that determines the order in which the operations are processed to minimize a specific objective function. The objective most commonly minimized in the literature is the makespan, the maximum completion time of all operations in the schedule. However, this objective does not consider the schedule's internal structure. As we look only at the last operation to finish, we can open all jobs from the beginning.\nIt can be formulated as follows:\n\nminimize \u2211 wj Cj\nJET\n\nwhere w; is the weight of the job j and C; its completion time.\nTo describe a scheduling problem accurately, the standard notation in literature is the triplet \u03b1|\u03b2|\u03b3 where a represents the machine environment, \u1e9e the processing characteristics and the constraints and y the objective. The problem we consider can be characterized by the triplet\n\nJm|prec, rcrc|wjCj\n\nThis triplet refers to a job shop environment with m machines (Jm). There are precedence constraints (prec), meaning that there are certain jobs or operations that must be completed before others can begin. The other processing characteristic is the recirculation (rcrc), which implies that two or more operations of a job can be processed on the same machine. In contrast to a classic job shop, where each job has exactly one operation on each machine, recirculation allows jobs to visit a machine more than once. Finally, the objective is the minimisation of the total weighted completion times."}, {"title": "Approach", "content": "This section presents different approaches to solving the JSSP using MCTS. First, we detail the basic concepts of a MDP. Afterwards, we discuss how MCTS algorithms can be used to solve MDPs. And, finally, we show various ways for casting the JSSP introduced in Section 3.3 as an MDP.\nRecent studies have demonstrated the potential of MCTS in solving scheduling problems. For instance, Saqlain, Ali, and Lee [12] proposed an MCTS-based algorithm for the flexible JSSP to minimize makespan. Similarly, Chou et al. [13] developed an approach that minimizes a multi-objective function using MCTS. Building on this prior work, we propose additional MDP frameworks tailored to JSSPs and demonstrate how they can be effectively solved using MCTS methods."}, {"title": "Markov Decision Process", "content": "A Markov Decision Process (MDP) is a mathematical framework for modelling decision-making problems. It is defined through the following objects: a state space S, an action space A, transition probabilities p(s'|s, a)\u2200s, s' E S,a \u2208 A and a reward function r(s, a). The function p(s'|s, a) gives the probability of reaching a state s' after taking the action a while being in state s. At each time step t, the decision-maker observes the current state St and selects an action ut, which influences both the immediate reward and the state transition."}, {"title": "Monte-Carlo Tree Search", "content": "Monte Carlo Tree Search (MCTS) is a heuristic search algorithm used in decision processes [14]. It combines classic tree search implementations with machine learning principles of reinforcement learning to balance exploration and exploitation. The algorithm is based on the building of a search tree. The MCTS algorithm can be used to solve MDPs as it incrementally builds a search tree representing the states and actions of the MDP, using simulation-based techniques to evaluate potential policies. Indeed, each node of the tree represents a state of the decision process and each edge represents an action leading to a new state. This algorithm aims to determine an optimal policy, i.e., a mapping from states to actions, that maximizes the expected cumulative reward over time, often defined as a discounted sum of rewards. The algorithm is composed of four fundamental steps: selection, expansion, simulation and backpropagation. These are schematically represented in Figure 1 [14].\nIn the selection phase, the algorithm starts from the root node at time 0 and from a node at deep t at time t that corresponds to the state st. It successively selects a child node following a tree policy until it reaches a node that is not fully expanded. A tree policy that has promising properties is the Upper Confidence Bound (UCB) formula. This formula balances the exploitation of the best-known nodes and the exploration of less visited nodes. A child node j is selected based on the UCB formula:\n\nUCB = Xj + C \u221a(ln N) / Nj \n(1)\n\nThe first part of the equation is the exploitation part, where Xj is the average reward of the node, and must be in [0, 1]. The higher the average reward, the more the node is exploited. The second part of the equation is the exploration"}, {"title": "Modelling JSSP as an MDP", "content": "This article explores different environments for the MCTS applied to the JSSP. Each environment is defined by its state space, action space and reward function. These three components can be defined in multiple ways, each influencing the performance and behaviour of the MCTS algorithm differently. We explore a few of possible combinations of these components in the following."}, {"title": "State Space", "content": "In reinforcement learning, the state st is a representation of the situation of the agent at the decision step t. In the context of JSSP, the state st corresponds to the partial schedule of jobs at decision step t. Here, t in the MDP refers to the sequence of decision steps during the schedule construction and is unrelated to the actual physical timeline of the schedule. We introduce two distinct state representations for the partial schedule:\n1. Absolute Representation: This representation maintains the completion times of each operation, directly encoding the timing information of the partial schedule. This approach is greedy regarding the order of operations and the completion times.\n2. Relative Representation: This representation maintains the order of the operations on each machine, encoding the sequence of operations on each machine rather than their precise timing. This approach is greedy only on the order of operations and it maintains flexibility in terms of scheduling completion time.\nWe can readily convert the representation of one type to the other. These two representations are convertible. Starting from the relative representation, we can compute the completion times C; for all operations, provided the order of operations on every machine is known. This computation can be achieved in O(nlogn) where n is the total number of operations. On the other hand, we can derive the relative representation from the absolute one by ordering the operations on each machine based on their completion times."}, {"title": "Action Space", "content": "The action space is the set of possible actions that the agent can take in a given state. In the context of the JSSP, the action space can be defined by the selection of the operation(s) to be scheduled. We propose four types of actions.\n1. The first approach is to select a single operation based on different dispatching rules (PDRs). PDRs are simple heuristics that select the next operation to be scheduled based on some criterion. For example, the first in first out (FIFO) rule schedules the next operation in order of appearance, the shortest processing time (SPT) rule selects the operation with the shortest processing time and the most operation remaining (MOR) rule selects the first operation available of the job with the most remaining operations. More details on the different PDRs used are given in Section 3.4.\nA = {a | a = PDR(\u00d5), PDR \u2208 {FIFO, SPT, MOR,...}}\nwhere is the set of operations that have not yet been scheduled, and PDR represents a dispatching priority rule. All operations in the selected job are scheduled in the order they appear.\n2. A second approach is to select an entire job based on a PDR. All operations in the selected job are scheduled in the order they appear in the job.\nA = {a | a = PDR(\u012a), PDR \u2208 {FIFO, SPT, MOR, ...}}\nwhere I is the set of jobs that have not yet been scheduled, and PDR represents a dispatching priority rule. All operations in the selected job are scheduled in the order they appear. Scheduling a whole job as a single action allows the search tree to be less deep, making the exploration space more manageable.\n3. A third approach is to select an operation based on a single PDR and then select a percentage. This percentage determines the size of the gap in the schedule of the corresponding machine in which the operation is scheduled. For example, if the percentage is 50%, the operation will be scheduled in the first idle time in the schedule that is greater than 50% of the operation's processing time. This action type is feasible when using the relative state representation, where the completion times of operations are not explicitly encoded and only the sequencing of operations is maintained. In this representation, even if there appears to be\n\n insufficient space theoretically, all subsequent operations can be shifted to accommodate the new operation, as the representation focuses sol, as the representation focuses only on the order of operations. Formally, let A be the action space, then:\nA = {a | a = (PDR(\u012a), p), PDR \u2208 {FIFO, SPT, MOR, . . . }, p \u2208 [0, 1]}\nwhere is the set of operations that have not yet been scheduled, PDR represents a dispatching priority rule. and p is the percentage gap for the scheduling of the selected operation in the corresponding machine's schedule.\n4. The fourth approach is similar to the third one except that we schedule all the operations of the selected job in one step.\nA = {a | a = (PDR(\u012a), p), PDR \u2208 {FIFO, SPT, MOR, . . . }, p \u2208 [0,1]}\nwhere I is the set of jobs that have not yet been scheduled, PDR represents a dispatching priority rule."}, {"title": "Reward", "content": "The reward function is related to the objective function of the problem and is designed to reflect the quality of the solution. The most intuitive way to define the reward function in the context of the JSSP would be to set the reward to 0 unless a terminal state has been reached. A terminal state is a state reached when the problem is solved (i.e., all jobs are completed) or it is impossible to continue (for example, due to infeasibility, such as exceeding resource limits or invalid machine assignments). In such cases, the reward is defined differently:\n\u2022 If the terminal state represents a successfully completed schedule, the reward is the negative weighted sum of the completion times of all jobs, aligning with the objective to minimize the total weighted completion time.\n\u2022 If the terminal state represents an infeasible solution, the reward is -\u221e.\nThe reward can also be normalised between 0 and 1:\n\nr = (r - rmin)/(rmax - rmin)"}, {"title": "Priority Dispatching Rules", "content": "PDRs are simple heuristics that select the next operation or job to be scheduled based on a specific criterion [15]. They are widely used in practice because they are easy to implement and computationally efficient, particularly for large-scale problems. They can either focus on entire jobs or individual operations. At a job-level selection, a PDR prioritizes jobs based on the characteristics of different jobs. On the other hand, at the operation-level selection, a PDR prioritizes an individual operation. The operation can be selected based on their own characteristics (e.g., processing time) or because they are the first available operation of the job chosen by a job-level selection.\nThe list of the job-level PDRs are listed in the following:\n\u2022 The FIFO rule (first in first out) processes jobs in the order they are given in the instance.\nIf Ji and Jj are two jobs, then under FIFO:\nIf i < j, then Ji is processed before Jj.\n\u2022 The Least Work First (LWF) rule selects the job with the shortest total processing time. The processing time of a job is the sum of the processing times of all its operations. If Ji and J; are two jobs and P represents the total processing time for job Ji, then under LWF:\nIf P; <Pj, then Ji is scheduled before Jj.\n\u2022 The Most Work First (MWF) rule selects the job with the longest total processing time.\n\u2022 The Shortest Job First (SJF) rule prioritizes jobs with the least number of operations.\nIf Ji and J; are two jobs and ni represents the number of operations of job Ji, then under SJF:\nIf ni < nj, then Ji is scheduled before Jj."}, {"title": "Constraint programming", "content": "Constraint programming is a declarative programming paradigm for modelling and solving combinatorial problems. By integrating constraint programming into our analysis, we can compare its performance with the MCTS approach. This method is more sophisticated and involves a longer computational process than PDRs. As MCTS typically requires considerable computing time to converge on good solutions, the use of constraint programming allows a fairer comparison of results.\nThe constraint programming model we use is defined in the following:\nVariables\n\u2022 start: Start time of operation i, where i = 1,...,n (where n is the number of operations).\n\u2022 endi: End time of operation i, where i = 1, . . ., n.\nData\n\u2022 duration;: Processing time of operation i.\n\u2022 machine\u017c: Machine assigned to operation i.\nObjective\nMinimize the total completion time of jobs, i.e. of the last operations of each job:\n\nmin \u03a3 endi\niEterminal_operations\n\nConstraints\n\u2022 Precedence constraints: For each operation i, and its predecessors j\u2208 predecessors[i]:\nend; \u2265 end; + duration;.\n\u2022 No-Overlap Constraints: For each machine m, ensure that two intervals do not overlap:\nNoOverlap({(start\u012f, duration\u012f) | machine_i = m})\nAlong with the constraint programming model, we guide the search process by using the LWR PDR, which helps refine the search strategy and improve the efficiency of finding solutions."}, {"title": "Data Generation", "content": "There is a gap in the existing literature regarding job shop scheduling benchmarks. Most commonly referenced instances, such as those proposed by Taillard et al. [11], Adams et al. [2] or Demirkol et al. [16], focus on small and rectangular configurations where the number of machines equals the number of operations of each job. This structure does not adequately represent the complexities of larger, unbalanced scenarios commonly encountered in real-world manufacturing.\nTo address this gap, we analyze a job shop instance derived from a real-world manufacturing industry that includes 51 machines, 828 jobs and a total of 6057 operations. In this instance, the workload distribution is unbalanced, with some machines heavily loaded while others are lightly used. Furthermore, the number of operations per job varies significantly, ranging from 1 to 20.\nTo better simulate our real-world case, we generate a synthetic job shop scheduling benchmark based on the original instance. The data generation process includes the creation of job and machine configurations that reflect the original conditions while including some level of variability and noise. An overview of this process is detailed in the following.\n1. Job Configuration: we first generate a random integer between 600 and 1000 to determine the number of jobs. A type and a size are assigned to each job. We have two different types of jobs: common and unique. Common jobs are job types that occur more frequently in the job shop scheduling environment. They correspond to more frequent sets of pieces to manufacture. Unique jobs are job types that occur less frequently. They correspond to unique orders a manufacturing industry can receive. The sizes are drawn from a Gaussian distribution with a mean and standard deviation derived from the original instance.\n2. Machine configuration: we first generate a random integer between 50 and 70 to define the number of machines. They are then split into different types based on their operational characteristics. A specific distribution of the number of operations is assigned to each type. Once the machine types are identified, we introduce noise to the probability distribution of these types. The number of machines of each type is then determined by sampling from this noisy distribution and their number of operations are drawn.\n3. Operations to jobs assignment: with machine types and their distributions defined, we assign operations to jobs. Each job's operations are\n\n distributed across the available machines based on the machine type distribution. We also ensure that the processing times for each operation are generated from a normal distribution centred around the mean processing time for the machine type, with a specified standard deviation.\nBy following this process, we generated 20 instances of the JSSP based on the original data. These instances are used to evaluate the performance of the MCTS algorithm with different scenarios."}, {"title": "Experiments", "content": "In this work, we evaluate the performance of five different types of environments for the MCTS algorithm. Each of these types of environment has three possible actions in its action space, except for the fourth type, which has six actions. The state representation, the type of action and the corresponding set of dispatching rules and, if needed, the percentages are listed in the Table 1.\nWe note that we encountered significant computational problems due to the long-running time when evaluating the performance of the MCTS algorithm in environment type 3. Specifically, the number of operations is high, making the search process computationally expensive. One of the key issues arises from the need to recompute the completion times of all operations to identify the idle time at each new state. This means that at each new scheduled operation, we recompute all the completion times. As a result, this type of environment is not feasible for our use.\nThe MCTS algorithm is run for six repetition steps and 30 evaluations for the backpropagation phase. The results are compared to the constraint programming model 3.5. All the algorithms are coded in Python and the constraint programming model is solved using the Google OR-Tools library [17]. The computations are executed on a calculation server with 48 Intel Xeon E7 v4 2.20 GHz processors with a total RAM of 128 GB."}, {"title": "Results", "content": "Using performance profiles, we first explore the different configurations with the same environment type and then compare the best configurations across all environment types. A performance profile represents the percentage y of instances for which a specific method produces a solution whose objective\n\nfunction is not worse than x times the best solution found by any of the studied methods.\nEach figure compares all the variants of one specific type of environment outlined in Table 1. In Figure 2, the performance profiles indicate that Configuration 1.4 consistently outperforms all other configurations of Type 1. Figure 3 evaluates the configurations of Type 2. Configuration 2.3 dominates the other configurations, achieving the best performance across all instances for the configuration Type 2. Figure 4 presents the results for configurations of Type 4. Configurations 4.1 and 4.2 achieve the best performance, dominating the other configurations. Configurations with the same PDR but different percentages have similar performance, indicating that the PDR is a key determining factor. The results suggest that configurations using the LWF PDR consistently perform better, followed by those with SJF, MWF and finally LJF. Figure 5 compares configurations of Type 5, which demonstrate a similar pattern to Type 4. Configurations 5.6 and 5.7 outperform the other configurations. Again, configurations with the same pair of PDRs but different percentages perform equivalently. Configurations with LWF and SJF outperform those using LWF and MWF, which in turn perform better than those using SJF and LJF.\nAdditionally, the detailed results, including the mean performance across all instances for each configuration, are presented in Table 2.\nFinally, we compare the best-performing configurations of Types 1, 2, 4, and 5 alongside the constraint programming results. Figure 6 gives the resulting performance profiles. We observe that configurations from Types 4, 5 and 2 achieve the best performance for 50%, 40% and 10% of the instances, respectively. This highlights the benefit of using a less greedy and more flexible environment, as seen in Types 4 and 5, which process operations during idle time even if the operation processing time exceeds the available time. Additionally, the results indicate that the MCTS-based algorithm outperforms the CP approach on the large instances we have considered, even when the latter is paired with a search heuristic."}, {"title": "Conclusion", "content": "In this study, we explore the potential of using MCTS to solve large-scale and real-world instances of the JSSP. We introduced various MDP formulations to model the JSSP for the MCTS algorithm and compared their performance with a constraint programming model. In addition, we deliver a new synthetic benchmark derived from anonymised real-world manufacturing data that captures the complexity and variability of industrial scheduling\n\n environments. Our experimental results showed that MCTS is a promising approach for solving large-scale JSSPs, consistently outperforming our constraint programming approach. The MCTS-based algorithm showed better performance in different MDP formulations. In particular, configurations that allow operations to be inserted in idle time lower than their processing time are beneficial. The proposed MDP formulations provide a flexible framework for representing different scheduling problems and the new benchmark is a valuable tool for testing and evaluating scheduling algorithms in industrial contexts. Future research could further refine the MCTS approach by exploring a machine-learning-based reward function allowing the evaluation of a partial schedule. In conclusion, our results support the utility of MCTS as an alternative heuristic to solve large job shop scheduling problems."}]}