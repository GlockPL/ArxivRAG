{"title": "A Comprehensive Survey of Time Series Forecasting: Architectural Diversity and Open Challenges", "authors": ["Jongseon Kim", "Hyungjoon Kim", "HyunGi Kim", "Dongjun Lee", "Sungroh Yoon"], "abstract": "Time series forecasting is a critical task that provides key information for decision-making across various fields, such as economic planning, supply chain management, and medical diagnosis. After the use of traditional statistical methodologies and machine learning in the past, various fundamental deep learning architectures such as MLPs, CNNs, RNNs, and GNNs have been developed and applied to solve time series forecasting problems. However, the structural limitations caused by the inductive biases of each deep learning architecture constrained their performance. Transformer models, which excel at handling long-term dependencies, have become significant architectural components for time series forecasting. However, recent research has shown that alternatives such as simple linear layers can outperform Transformers. These findings have opened up new possibilities for using diverse architectures. In this context of exploration into various models, the architectural modeling of time series forecasting has now entered a renaissance. This survey not only provides a historical context for time series forecasting but also offers comprehensive and timely analysis of the movement toward architectural diversification. By comparing and re-examining various deep learning models, we uncover new perspectives and presents the latest trends in time series forecasting, including the emergence of hybrid models, diffusion models, Mamba models, and foundation models. By focusing on the inherent characteristics of time series data, we also address open challenges that have gained attention in time series forecasting, such as channel dependency, distribution shift, causality, and feature extraction. This survey explores vital elements that can enhance forecasting performance through diverse approaches. These contributions lead to lowering the entry barriers for newcomers to the field of time series forecasting, while also offering seasoned researchers broad perspectives, new opportunities, and deep insights.", "sections": [{"title": "1 Introduction", "content": "Time series forecasting (TSF) is a task that predicts future values based on sequential historical data over time (Cryer, 1986). It is utilized as a key decision-making tool in various fields, such as economics and finance, supply chain management, transportation, energy, weather and healthcare (Danese and Kalchschmidt, 2011; Abu-Mostafa and Atiya, 1996; Alghamdi et al, 2019; Nti et al, 2020; Dimri et al, 2020; Soyiri and Reidpath, 2013). Such applications offer various opportunities, including cost"}, {"title": "2 Background", "content": "In this section, before exploring time series forecasting models, we explain the definition and key characteristics of time series data to provide the necessary background. We also define the problem of time series forecasting tasks, discussing related datasets and evaluation metrics. This establishes the basic concepts of time series forecasting and provides preliminary information to help understand the models discussed in the following sections."}, {"title": "2.1 Time-Series Data", "content": "Time series data is a collection of sequential data points gathered at regular time intervals, representing a series of observations of phenomena that change over time. This temporal continuity allows for the understanding and analysis of phenomena that evolve according to time order. Each data point represents the state or value at a specific moment, and through the observation of these data points, various patterns such as long-term trends, seasonality, cyclicality, and irregularities can be recognized. These patterns provide valuable information for predicting future values or detecting changes at critical moments. By extracting and studying the meaningful information provided by time series data, it can be applied to practical applications, helping to address many challenges in various disciplines.\nCharacteristics of Time Series Data\nTime series data encapsulates various characteristics that play a critical role in explaining the diverse patterns and fluctuations within time series. Understanding these characteristic elements is essential for analyzing and predicting data. The key properties are explained in Fig. 5.\nIn time series data, the above features frequently appear in a mixed form. Therefore, decomposition is commonly used to separate the components for detailed analysis, or distribution shift alleviation methods are widely applied. Many time series datasets provide information on multivariate variables. Sometimes, these data provide additional information that univariate data cannot, and it is important to understand this for many problems. The main properties are explained in Fig. 6."}, {"title": "Univariate Time Series Forecasting (UTSF)", "content": "Univariate forecasting refers to making predictions using only one variable. For example, predicting the next day's temperature based solely on past temperature data from a weather station is a univariate forecast. The advantage of univariate forecasting is that the models are simple and computationally efficient. Since the data consists of a single variable, the model is relatively straightforward and easy to understand, making data collection and management easier. However, it may only utilize limited information as it cannot account for important external factors or interactions between different variables:\n$\\Yt+1 = f(Yt, Yt-1,..., Yt-p)$ (1)\nwhere \u0177t+1 represents the predicted value at time t + 1. The terms Yt, Yt\u22121,..., Yt-p are the past p observations, which include values at time t, t \u2212 1, continuing down to t \u2212 p. This approach uses historical data to forecast future values, relying on patterns within the observed variable itself."}, {"title": "Multivariate Time Series Forecasting (MTSF)", "content": "Multivariate forecasting involves making predictions using multiple variables simultaneously. For instance, in weather forecasting, predicting the next day's temperature by considering various variables such as temperature, humidity, and wind speed is an example of multivariate forecasting. By incorporating interactions and correlations between multiple variables, multivariate forecasting can capture complex relationships, offering higher predictive accuracy. However, these models tend to be more complex, require more data, and can be more challenging to handle, increasing the risk of overfitting."}, {"title": "Short-Term Time Series Forecasting (STSF)", "content": "Short-term time series forecasting focuses on predictions for the near future, making it suitable for tasks that require quick responses, such as immediate operational planning or short-term decision-making. The models are simple, making them easy to train and implement, and they often demonstrate relatively high accuracy. However, because the forecast range is short, it cannot capture long-term trends or complex variations, which limits its applicability."}, {"title": "Long-Term Time Series Forecasting (LTSF)", "content": "Long-term time series forecasting deals with predictions for the distant future, with forecast horizons increasingly extending to several months, years, or beyond. It is valuable for long-term strategy planning, investment decisions, and policy-making, addressing many real-world problems. By identifying long-term trends and cycles, organizations can prepare accordingly, highlighting its significance. However, predicting the distant future is challenging, and extensive research is being conducted to improve accuracy."}, {"title": "3 Historical TSF Models", "content": ""}, {"title": "3.1 Conventional Methods (Before Deep Learning)", "content": ""}, {"title": "3.1.1 Statistical Models", "content": "Prior to machine learning and deep learning, traditional statistical models, which laid the foundation for analyzing sequential data, were commonly utilized for time series forecasting. Exponential smoothing was introduced by Brown (1959), Holt (1957), and Winters (1960) as a method to forecast future values using a weighted average of past data. This method operates by computing an exponential weight decay of historical data, assigning greater weight to more recent data. The Autoregressive Integrated Moving Average (ARIMA) model was formalized through the work of George Box and Gwilym Jenkins in their book \"Time Series Analysis: Forecasting and Control (Bartholomew, 1971).\" The ARIMA model predicts future values by leveraging the autocorrelation in data and is composed of three main components. AutoRegressive (AR) uses a linear combination of past values to predict the current value. Moving Average (MA) employs a linear combination of past error terms to predict the current value. Integrated (I) removes non-stationarity (the property where mean and variance change over time) by differencing the data to achieve stationarity. While exponential smoothing models are advantageous for real-time data analysis due to their simplicity, ARIMA models are better suited for capturing complex patterns, making them ideal for long-term forecasting. The SARIMA model extends ARIMA by incorporating seasonal differencing, along with seasonal autoregressive and moving average components, allowing it to effectively model and predict data with regular cyclical patterns. These statistical models are based on specific assumptions and are simple, intuitive, and useful for identifying basic patterns in data."}, {"title": "3.1.2 Machine Learning Models", "content": "While statistical methods struggle to capture complex patterns in time series data due to their reliance on predefined linear relationships, machine learning models excel in learning nonlinear patterns directly from the data without relying on such assumptions. To address the limitations of statistical methods, traditional machine learning models have been increasingly applied to time series forecasting. Decision Trees (Quinlan, 1986) are machine learning models that use a tree structure for classification or prediction. The term \"classification and regression tree (CART) analysis\" was first introduced by Barlin et al (2013), and in time series forecasting, regression decision trees are used to split data into a tree structure to predict continuous values. While they are intuitive and easy to interpret, they are prone to overfitting. Support Vector Machines (SVM), introduced by Cortes and Vapnik (Cortes, 1995), are supervised learning models used for classification and regression analysis, characterized by finding the maximum margin. They handle high-dimensional data and non-linearities effectively, making them robust for classification and regression tasks. Support Vector Regression (SVR) applies SVM concepts to regression problems, predicting data points using an optimal hyperplane (Vapnik et al, 1996). This hyperplane is trained to minimize errors between data points, ensuring errors do not exceed a certain threshold. Gradient Boosting Machines (GBM) were developed in 1999 with an explicit regression gradient boosting algorithm. This method uses ensemble learning to combine multiple weak models into a single, strong predictive model (Friedman, 2001). This method iteratively improves the model, offering high predictive performance. XGBoost, an extension of the Gradient Boosting algorithm (Chen and Guestrin, 2016), incorporates various optimization techniques to enhance efficiency and performance. It gained significant attention for its outstanding performance in machine learning competitions, particularly in time series forecasting challenges. These machine learning models outperform traditional statistical models in capturing data structures and patterns, demonstrating high predictive power on large datasets (Kontopoulou et al, 2023). Their ability to automatically learn and optimize various data features and relationships has led to their widespread use in time series forecasting."}, {"title": "3.2 Traditional Deep Learning Models", "content": ""}, {"title": "3.2.1 MLPs: The Emergence and Constraints of Early Artificial Neural Networks", "content": "The development of the Multi-layer Perceptron (MLP) (Rumelhart et al, 1986) and the back-propagation algorithm established the foundation for artificial neural networks. Early artificial neural network models utilizing these MLPs demonstrated strong performance in modeling nonlinear patterns, prompting numerous attempts to apply them to time series data processing. However, several key limitations, as outlined below, restricted the training of deep neural networks using MLPs.\nLimited in learning temporal dependencies: MLPs are well-suited for processing fixed-length input vectors but struggle to adequately capture the temporal dependencies in time series data.\nVanishing gradient issue: The vanishing gradient problem in deep networks made training difficult.\nLack of data and computing resources: The scarcity of large-scale datasets and high-performance computing resources made it challenging to effectively train complex neural network models.\nAt that time, artificial neural network technology was still immature, and there was a lack of deep understanding and effective methodologies for dealing with time series data. Consequently, traditional statistical methods and machine learning models previously discussed continued to be widely used for time series analysis."}, {"title": "3.2.2 RNNs: The first neural network capable of processing sequential data and modeling temporal dependencies", "content": "The Emergence and Early Applications of RNNs\nRecurrent Neural Networks (RNNs) (Hopfield, 1982) emerged, opening up new possibilities for processing time series data. RNNs are specialized models designed to process sequential data, such as time series data, and were utilized to overcome the limitations of MLPs. The structure of an RNN consists of an input layer, a hidden layer, and an output layer, and it uses the output from"}, {"title": "Overcoming the Limitations of RNNs", "content": "To address the aforementioned issues with vanilla RNNs, researchers began developing various models. Notably, the Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997b) model was developed to address the long-term dependency issues of vanilla RNNs. With the cell state and gate mechanisms (input, output, and forget gates), LSTMs preserves crucial information over extended periods and the discards unnecessary information. The Gated Recurrent Unit (GRU) (Cho, 2014) emerged as a simpler alternative to LSTM, offering similar performance while using a more straightforward structure(update and reset gates) to manage information. These two models effectively addressed the vanishing gradient problem and sparked a boom in RNN-based models for time series analysis. Many subsequent RNN-based models used these two as their backbone, making them powerful tools for handling time series data until the advent of Transformers.\nNotable RNN Variants\nThe Dilated RNN (Chang et al, 2017) proposed Dilated Recurrent Skip Connections as a solution to various issues inherent in traditional vanilla RNNs. This approach enhanced parameter efficiency in long sequences and enabled the network to effectively learn complex dependencies across diverse temporal scales. The DA-RNN (Qin et al, 2017) attempted to effectively address long-term dependencies, which were challenging for existing methods, by employing a dual-stage attention mechanism. Utilizing an encoder with Input Attention and a decoder with Temporal Attention, it adaptively selected salient information from input features and temporal steps, thereby enhancing the accuracy and performance of time series predictions. Additionally, the MQ-RNN (Wen et al, 2017) combined the Sequence-to-Sequence neural network framework with Quantile Regression to provide probabilistic forecasts, thereby reflecting uncertainties across various scenarios. This model simultaneously generated multiple forecast horizons at each time step and employed the Forking-Sequences training method to enhance the stability and performance of the RNN."}, {"title": "3.2.3 CNNs: Extracting key patterns in time series data beyond just images", "content": "The Emergence and Early Applications of CNNs\nThe Neocognitron (Fukushima, 1980) was designed for visual pattern recognition and served as an early form of Convolutional Neural Networks (CNNs), introducing the fundamental concepts of CNNs. The CNN architecture, which became more widely known with the development of LeNet (LeCun et al, 1998), learned spatial patterns in images through a combination of convolutional and pooling layers. These features made CNNs well-suited for handling image data, leading early CNN-based models to primarily focus on image data without being directly applied to time series data. However, over time, their potential for handling time series data has also been recognized."}, {"title": "Attempts to Apply CNNs to Time Series Data", "content": "1D CNNs use one-dimensional convolutional filters to learn local patterns in time series data, allowing them to extract features that consider the temporal structure of the data. A prominent example is WaveNet (Van Den Oord et al, 2016a), which utilized 1D convolutions and dilated convolutions to model speech signals, effectively capturing long-term dependencies in audio signals. WaveNet demonstrated the utility of CNN-based models in speech synthesis and time series prediction, leading to the widespread adoption of CNN-based models for time series analysis. The development of the Temporal Convolutional Networks (TCNs) (Bai et al, 2018) model further highlighted the potential of CNN-based models in the time series domain. TCN consists of multiple layers of 1D convolutional networks, using dilated convolutions at each layer to achieve a wide receptive field, enabling the construction of deeper networks. This allows TCNs to effectively learn from long sequences of data. TCNs have demonstrated excellent performance in various sequential domains, including time series prediction, signal processing, and natural language processing.\nCNN and RNN Ensemble Models\nBuilding on the popularity of traditional time series forecasting models like RNNs and the emerging interest in CNN models, hybrid CNN-RNN models began to emerge, combining the strengths of both architectures. Models that combined CNNs and LSTMS were particularly advantageous for simultaneously learning local patterns and long-term dependencies in time series data. The structure involved using CNNs to extract complex features from the time series data and LSTMs to learn temporal dependencies.\nDeepAR (Salinas et al, 2020) combined LSTM and CNN to generate probabilistic forecasts of future distributions rather than single predicted values. Additionally, it improved generalization performance by simultaneously learning and predicting multiple time series within a single model. DCRNN (Li et al, 2017) modeled traffic flow as a diffusion process on a directed graph, capturing both temporal and spatial dependencies. The Diffusion Convolution leveraged bidirectional random walks on the graph to capture spatial dependencies within the traffic network, while the Gated Recurrent Units (GRU) modeled temporal dependencies. The introduction of the Diffusion Convolutional Gated Recurrent Unit (DCGRU) enabled the effective processing of temporal information. the TPA-LSTM (Shih et al, 2019) combined CNN and LSTM with an added attention mechanism, introducing the Temporal Pattern Attention(TPA) methodology to learn important patterns in time series data. Local patterns were extracted using CNN, while the combination of LSTM and the attention mechanism captured significant temporal patterns."}, {"title": "3.2.4 GNNs: Structurally modeling relationships between variables", "content": "The Emergence and Slow Growth of GNN-Based Models\nGraph Neural Networks (GNNs) (Scarselli et al, 2008) were primarily developed to process graph-structured data because they can effectively model the complex structural relationships between nodes and edges in graph data. Over time, GNNs gradually began to be applied to time series data analysis, primarily because multivariate time-series data often encapsulates intricate structural relationships.\nDuring their initial development, GNNs were less popular compared to widely used RNN or CNN-based models. The prevailing belief was that GNNs were not suitable for time series analysis compared to CNNs which are effective at extracting local patterns, and RNNs which are strong at learning long-term dependencies. However, as the range and complexity of time-series data increased, understanding their structural characteristics became more important. Consequently, GNNs began to gain prominence in fields such as traffic prediction and social networks. Research on applying GNNs to time-series data has primarily focused on capturing the dynamic characteristics of graph data, and the structural learning capabilities of GNNs have proven to be highly useful in capturing the complex patterns within time-series data.\nDevelopment and Expansion of GNN Applications\nUntil the development of Transformers, GNNs consistently garnered interest, showing consistent yet slow growth compared to RNNs and CNNs. The development of Graph Convolutional Networks (GCNs) (Kipf and Welling, 2016) marked another turning point for GNNs. GCNs learns node features through convolution operations on graph structures, and are powerful tools for processing"}, {"title": "3.3 The Prominence of Transformer-based Models", "content": "Transformer (Vaswani et al, 2017), introduced by the Google Brain team, is an innovative model designed to perform complex sequence-to-sequence tasks in natural language processing. This model features an encoder-decoder structure and utilizes an attention mechanism to capture the relationships between tokens in the input sequence. As a result, Transformers have gained significant attention for replacing traditional RNN-based models, offering parallel processing capabilities and effectively addressing long-term dependency issues. Transformers' success with sequential data naturally led to their extension into time series applications."}, {"title": "3.3.1 Transformer Variants", "content": "In recent years, substantial research has focused on transformer-based time series analysis, particularly long-term time series forecasting (LTSF), which has led to the development of various models (Zeng et al, 2023a). The original Transformer model has several limitations when applied to long-term time series forecasting (TSF). These limitations include quadratic time and memory complexity, as well as error accumulation caused by the auto-regressive decoder design. Specifically, the time and memory complexity of self-attention increases quadratically with the length of the input sequence. This high complexity can become a computational bottleneck, especially for time series forecasting tasks that rely on long-term historical information. To address these issues, Transformer variants primarily focus on reducing time and memory complexity."}, {"title": "3.3.2 Limitation of Transformer-based Models", "content": "However, even the models designed specifically for time series forecasting based on the original Transformer still have the following limitations.\nEfficiency Challenges\nEfforts to overcome the primary drawback of quadratic scaling in computational and memory complexity with window length have not fully resolved the issues. Various approaches to reduce this complexity have been proposed, but the attention mechanism inherently incurs higher computational and memory costs compared to MLP-based or convolutional models with O(L) complexity. Applying Transformers to the time domain does not easily mitigate this problem. Models such as Fedformer (Zhou et al, 2022), which uses Fourier or Wavelet transformations to operate in the frequency domain, have been made to address these issues. Although research into more efficient attention variants is ongoing (Tay et al, 2020), these solutions often sacrifice some of the effective characteristics of Trans-formers. Sparse attention mechanisms, used to reduce Self-Attention complexity, may result in the omission of important information. Models like LogTrans and Pyraformer introduce explicit sparsity biases in the attention mechanism but may suffer from significant performance degradation due to the loss of crucial information. None of these variants have yet been proven effective across diverse domains (Gu and Dao, 2023).\nFinite Context Window\nThe efficiency of self-attention is attributed to its ability to densely route information within a context window, enabling the modeling of complex data. However, unlike models such as RNNs or State Space Models (SSMs), Transformers have a fundamental limitation in modeling data beyond a finite window.\nIneffectiveness of Expanding Input Window Length\nAnother significant issue is the minimal or no performance improvement observed when increasing the input window length. Strong time series forecasting (TSF) models are generally expected to achieve better results with larger look-back window sizes due to their robust temporal relationship extraction capabilities. However, research (Zeng et al, 2023b; Zhou et al, 2021; Wen et al, 2022b) indicates that the performance of Transformers either deteriorates or remains stable as the look-back window increases, in contrast to improvements seen with linear-based methods (Zeng et al, 2023b). This suggests that transformer-based models tend to overfit noise rather than extract long-term temporal information when provided with longer sequences.\nIn conclusion, while transformer-based models have made significant advancements in time series forecasting, they still face limitations. Therefore, future research will continue to address these limitations and will also serve as a catalyst for re-exploring various alternative architectures."}, {"title": "3.4 Uprising of Non-Transformer-based Models", "content": "As previously discussed, transformer-based models demonstrate strong performance in processing time series data. However, they have several limitations when dealing with long-term time series data.\nThe point-wise operations of the self-attention mechanism have quadratic time complexity. Therefore, as sequence length increases, the computational load grows exponentially, making it challenging to handle long-term historical information.\nBecause storing the relationship information for all input token pairs requires substantial memory usage, applying Transformers in environments with limited GPU memory becomes challenging.\nWhen the length of the look-back window exceeds the structural capacity, learning long-term dependencies becomes challenging.\nDue to the high complexity of the model, large-scale and high-quality datasets are required. In the absence of sufficient data, overfitting can occur leading to a drop in model performance.\nContemporary TSF tasks increasingly require the prediction of diverse multivariates and long sequences. Unlike earlier tasks that involved relatively short sequences, the limitations of transformer-based models have become more pronounced when dealing with long sequences. Researchers adhering to the Transformer's philosophy have begun focusing intensively on two aspects to address these"}, {"title": "4 New Exploration of TSF Models", "content": ""}, {"title": "4.1 Overcoming Limitations of Transformer", "content": "As previously mentioned in 3.4, the performance of simple linear models in LTSF-Linear (Zeng et al, 2023a) surpassing traditional transformer-based models has raised doubts about the effectiveness of Transformers. However, in the field of NLP, Transformers still demonstrate superior performance in handling long-term dependencies in sequential data compared to other models (Patwardhan et al, 2023). This observation suggests that while Transformers have great potential, researchers have not fully leveraged their capabilities in time series analysis.\nTherefore, various methods have emerged in time series forecasting to overcome the limitations of existing Transformer-based models. This section categorizes and explains in detail the specific limitations of existing models and how these limitations are addressed. The structure begins with an introduction to the patching technique, followed by the use of cross-dimension and exogenous variables, and then provides a detailed explanation of other approaches, concluding with a summary of key points in Table 5."}, {"title": "4.1.1 Patching Technique", "content": "Transformers were originally developed for natural language processing (NLP), and applying them to time-series analysis requires appropriate adjustments to fit the domain of time series. Different from the rich semantic information carried by individual word tokens in NLP, individual data points in time series are often similar to their neighboring values, lacking substantial information (Nie et al, 2022). Therefore, the point-wise attention mechanism of traditional models fails to consider the broader context or patterns that may span multiple consecutive time steps and only calculates attention for individual time steps, which makes it difficult to capture the characteristics of time series data. For this reason, considering the surrounding context along with a single time point provides more information in time series data.\nPatching refers to the technique of dividing input sequences into multiple patches, as illustrated in Fig. 10. This method preserves the information within each patch, thereby enhancing locality. By processing patches instead of individual points, the model processes fewer tokens, thereby reducing the computational complexity of the attention mechanism. This approach helps overcome the issue of prediction performance degradation, which can occur when sparse attention is used to make self-attention more efficient, potentially missing critical information.\nPatchTST (Nie et al, 2022), inspired by Vision Transformer's (Dosovitskiy et al, 2020) division of images into 16 \u00d7 16 patches for capturing local semantic information, divides time series into 64 patches. This approach allows for utilizing a longer look-back window by grouping data into patches. By processing time-series data in patch units, PatchTST maximizes the advantages of Transformer models for time-series applications, achieving better performance than LTSF-Linear. PatchTST employs only the Transformer encoder, flattens the encoder output, and uses a linear layer for the final predictions. Additionally, the study shows that channel independence (CI) yields better performance, highlighting the limitations in learning channel correlations despite the intuitive consideration of channel dependencies (CD) in multivariate scenarios. MTST (Zhang et al, 2024d) addresses the limitation of PatchTST in learning patterns across different scales present in time-series data. By adopting a multi-scale approach, MTST proposes an effective model utilizing both shorter and longer patches for locality and long-term trend analysis. PETformer (Lin et al, 2023) critiques the flattening of Transformer encoder output in PatchTST, which results in a significant increase in parameters. PETformer introduces a placeholder-enhanced technique, modeling past and future data on the same time scale, thereby reducing the number of parameters by over 95% compared to PatchTST. This reduction enhances generalization performance while using less memory and computational resources. The model also leverages rich context information by allowing direct interaction between past and future data, maintaining the continuity of time-series data.\nBy applying the patching technique, it was possible to refute the notion that traditional linear models are superior to Transformers. This led to the patching technique becoming a widely adopted approach."}, {"title": "4.1.2 Cross-Dimension", "content": "In multivariate time-series forecasting, understanding the relationships between variables is crucial for improving prediction accuracy. Intuitively, higher temperatures lead to increased ice cream sales, indicating a relationship between variables. Despite this apparent correlation, surprising results have shown that models treating channels independently, such as LTSF-Linear, PatchTST, and PET-former, often outperform those considering inter-channel correlations. This result implies that current models fail to effectively capture the relationships between variables. Time series analysis differs significantly from natural language processing (NLP) and computer vision (CV) in terms of channel correlation. In NLP, there is no clear concept of channels. In CV, although channels exist, their relationships are tightly intertwined and well-defined, as seen in the RGB representation of images. Conversely, in time series analysis, channel relationships can be either independent or interdependent and often hidden, adding complexity to the task. Therefore, time series analysis requires models capable of capturing these intricate correlations. While earlier Transformer-based models primarily focused on temporal attention, recent models have increasingly focused on explicitly modeling the correlations between variables.\nThe overall progression of advancements is as follows. It begins with modeling that explicitly accounts for correlations between variables. This progresses to directly modeling the relationships between both temporal and variable aspects. Additionally, the model incorporates the possibility of time lags in the relationships between variables, allowing it to flexibly learn dependencies.\nCrossformer (Zhang and Yan, 2023) breaks away from solely temporal attention by employing a Two-Stage Attention mechanism that sequentially processes Cross-Time and Cross-Dimension stages. It divides each dimension's time series into patches, embeds them into 2D vectors, and performs attention. Crossformer incorporates a router mechanism in the Cross-Dimension stage to handle the increased complexity of dual attention. This hierarchical structure across multiple scales enables Crossformer to effectively model both temporal dependencies and inter-dimensional correlations, significantly enhancing multivariate time series forecasting performance. DSformer (Yu et al, 2023) criticizes Crossformer for emphasizing global interactions between variables in time series data, while overlooking the importance of local information, such as short-term variations and patterns. DSformer addresses this by using double sampling, obtaining global information via downsampling and local information through piecewise sampling. These samples undergo parallel temporal variable attention, allowing the model to integrate global, local, and inter-variable correlations in multivariate time series data through dual sampling and time-variable attention mechanisms. CARD (Wang"}, {"title": "4.1.3 Exogenous Variable", "content": "Most existing research primarily utilizes endogenous variables for prediction. However, in real-world scenarios, relying solely on endogenous variables can be insufficient due to the complexity of various influencing factors. For instance, stock price predictions are significantly affected by external factors such as economic indicators, political changes, and technological advancements. Ignoring these external factors and relying only on past data of endogenous variables can lead to failures in accurately predicting market volatility. Therefore, incorporating exogenous variables as supplementary information has emerged as a method to improve prediction performance.\nTimeXer (Wang et al, 2024c) proposes a method to integrate exogenous variables into the canonical Transformer model without structural changes. It operates by dividing the time series data of endogenous variables into patches, learning the temporal dependencies of each patch through self-attention. Then, it generates variate tokens summarizing the entire series of endogenous and exogenous variables and learns their interactions using a cross-attention mechanism. Through this process, TimeXer simultaneously considers the temporal patterns of endogenous variables and the impact of exogenous variables, enabling more precise and in-depth time-series predictions. However, TimeXer requires manual identification and input of appropriate exogenous variables. If unsuitable data is provided, it can hinder the model's predictive accuracy. TGTSF (Xu et al, 2024b) integrates text data from channel descriptions and news messages to enhance prediction accuracy. It embeds channel descriptions and news messages using a pre-trained text model, transforming them into a sequence of vectors over time. The cross-attention layer then calculates the relevance of the text to each channel. By incorporating text data into the time series prediction model, TGTSF not only improves prediction accuracy but also allows for direct comparison of the impact of textual information on predictive performance."}, {"title": "4.1.4 Additional Approaches", "content": "Beyond the topics discussed above, there are various other approaches to time series forecasting."}, {"title": "Generalization", "content": "Research has been conducted to improve model generalization, avoid overfitting, and achieve consistent performance across diverse datasets. SAMformer (Ilbert et al, 2024) addresses the issue of self-attention mechanisms converging to sharp local minima, causing entropy collapse during training, and demonstrates that applying SAM (Sharpness-Aware Minimization) can significantly enhance performance. Minusformer (Liang et al, 2024b) highlights the redundancy and overfitting caused by a large number of parameters in Transformers. To combat this, it employs a boosting ensemble method, where each subsequent model predicts the residuals of the previous model's outputs, thus reducing redundancy and improving generalization."}, {"title": "Multi-scale", "content": "The multi-scale approach extracts more information from time series data across various scales, offering distinct advantages. Scaleformer (Shabani et al, 2022) proposes a general framework by stacking existing models across different scales, resulting in improved performance. Pathformer (Chen et al, 2024b), on the other hand, allows the model to learn adaptive scales independently, rather than relying on fixed scales."}, {"title": "Decoder-only", "content": "Large-scale language models (LLMs) like LLaMA3 (Dubey et al, 2024) have been successfully implemented using only a decoder without the need for an encoder. The decoder-only architecture is simpler and involves less complex computations, resulting in faster training and inference. Additionally, the decoder-only structure helps avoid the temporal information loss often associated with the self-attention mechanism in encoders. This has led to a research proposal aimed at improving performance in time series forecasting using a decoder-only structure. CATS (Kim et al, 2024) addresses the high time and memory complexity of self-attention in Transformer encoders and the loss of temporal order information. It proposes a structure using only cross-attention, focusing solely on the relationship between future and past data with a decoder-only architecture, which reduces parameter count and enhances efficiency. In contrast to the encoder-only structure of most models discussed CATS demonstrates the effectiveness of using only the decoder in achieving superior performance."}, {"title": "Feature Enhancement", "content": "Fredformer (Piao et al, 2024) identifies the issue of frequency bias in time series data, where learning tends to focus disproportionately on either low or high frequencies. It addresses this by normalizing the frequencies to eliminate bias. Basisformer (Ni et al, 2024) proposes a method to construct flexible relationships with each time series by leveraging biases learned through contrastive learning."}, {"title": "4.2 Growth of Traditional Deep Learning Models", "content": "Since the advent of simple linear models, there has been a surge in research focused on non-transformer-based models. Attention has shifted to various architectures such as MLP, RNN, CNN, and GNN, with many models surpassing Transformers and achieving remarkable performance improvements. Although transformer-based models exhibit excellent performance across numerous fields, they have structural limitations in learning temporal order information, which is crucial for time series problems. While past tasks were simple and general enough to overlook these limitations, current real-world tasks involve many constraints and data-specific issues with diverse variables, necessitating approaches from various perspectives. Each architecture has its own strengths, and these characteristics provide valuable solutions for addressing diverse contemporary time series forecasting challenges. In this section, we will investigate the latest major models for each architecture and analyze their technical features. The key characteristics of each backbone architecture have been briefly summarized in comparison to Transformers in Table 6."}, {"title": "4.2.1 MLP-Based Models", "content": "MLP-based models have recently emerged as a key methodology for replacing Transformers in time series forecasting tasks. The simple"}]}