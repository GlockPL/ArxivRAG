{"title": "Understanding the Impact of Artificial Intelligence in Academic Writing: Metadata to the Rescue", "authors": ["Javier Conde", "Pedro Reviriego", "Joaqu\u00edn Salvach\u00faa", "Gonzalo Mart\u00ednez", "Jos\u00e9 Alberto Hern\u00e1ndez", "Fabrizio Lombardi"], "abstract": "The development of generative Al tools that can create diverse content such as text and images, is poised to have a great impact on academic writing. Understanding this phenomenon is far from trivial and needs to be carefully studied. The first step is to be able to identify papers written with the help of Al, ideally knowing which tools have been used, in which parts of the paper, and how they have been used. This enables tracking the number of papers that use Al tools as well as the list of employed Al tools but it will also make possible the generation of large datasets of documents that have used different Al tools. These datasets are needed to understand the impact of Al tools on academic language and their potential effects in the long term. Unfortunately, getting the details of the use of Al in academic papers does not seem to be possible unless Al-related metadata is defined with a common format and added to the papers. This column advocates the implementation of such metadata and discusses the potential benefits of having metadata in academic publications", "sections": [{"title": null, "content": "he rapid development and exponential adop-tion of artificial intelligence (AI) tools that can generate text for different tasks, are poised to have significant and far reaching implications in many sectors [1]. These tools can for example summarize, translate, or paraphrase text, but also can write text on any topic and provide relevant citations [2]. These capabilities are useful for academic writing and many researchers are starting to use Al tools as assistants when writing papers [3]. The use of Al tools poses many potential issues, ranging from the accuracy of the text generated that may contain false statements to ethical concerns [4]. Therefore, the impact of Al tools should be carefully analyzed, not only in research datasets but also in real data as Al-generated content starts to become widespread and for academic writing in published papers.\nThere are many angles to be considered when analyzing the impact of Al tools in academic writing. For example, will the use of Al tools have an impact on the citations of the papers? Which authors are more prone to use those tools? Which tools are more popular and for which tasks? Those are some of the basic questions but more fundamental aspects have to be considered. Initial studies suggest that Al tools will have an impact on the language itself [5], [6]. So for example, will linguistic features of papers written with the assistance of Al tools be different from those of human-written papers? Will the use of Al tools intro-duce biases in the vocabulary [7] used? The questions are numerous and soon academic papers written with"}, {"title": null, "content": "the help of Al tools will become common. The answers to the questions lie on those papers.\nTo analyze the impacts of these Al tools, the first step is to reliably identify Al-generated content with as many details as possible; for example, knowing the Al tool, its version, and the tasks for which it was used to assist in the writing. Unfortunately, such information is generally not available in academic papers. A potential solution is to use tools designed to detect Al-generated text [8]. This however has many limitations because these tools have limited accuracy and have to be constantly evolving to keep track of new Al-generative tools and features. Even if accurate, such tools can only provide limited information, but not the details on the Al tool and version used. Another possible direction is the policies being implemented by many publishers, for example, the IEEE, to request authors to disclose the use of Al tools in the acknowledgment section. However, this approach also has limitations because there is no standard form to report the use of Al tools and provide additional details. Finally, for both approaches, even if the information could be extracted reliably (which is not the case), gathering even basic information such as the percentage of papers that have used a given tool requires checking the full text of all papers. This is clearly not efficient.\nA more scalable and future-proof solution is to add metadata describing the use of Al tools in each aca-demic paper. This enables queries on the metadata on large numbers of documents but also the definition of common metadata formats that enable interoperability among different publishers. For example, the addition of the tool, version, and task makes answering the first set of simple questions discussed previously trivial. Interestingly, this metadata enables the generation of large corpora of text written with the assistance of Al tools from which the answers to the second set of questions can be extracted. The use of metadata also enables tracking the evolution of the use of Al tools, so making possible comparison among different tools, or for the same tool among different versions. Next, we discuss the metadata that should be added and illustrate the potential benefits."}, {"title": "METADATA FOR THE USE OF AI IN ACADEMIC WRITING", "content": "The information on the use of Al in an academic paper can be captured at different levels of detail, from a simple flag indicating the use of Al to assist the authors to detailed logs of the interactions with the Al tool. As it tends to happen, too little or too much detail is not good, so next, we try to list the main information that could be relevant to analyze the impact of Al in academic writing:\n1) Al tool used.\n2) Version of the tool.\n3) Main parameters of the tool.\n4) Use of the tool (translation, summarization, writ-ing, citations, etc.).\n5) Parts of the paper on which the tool was used.\nThe information can be divided into three cate-gories: which tool was used, how it was used, and where it was used. The knowledge of the tool enables a comparative analysis of different tools but also the study of the evolution of a given tool or its parameters. Similarly, knowing for what the tool was used provides information to analyze the impact of Al on different aspects of academic writing. Finally, knowing where it was used enables the extraction of the relevant sections of the paper for further analysis. The three categories are illustrated in Figure 1."}, {"title": "Which Al tools and parameters", "content": "This group of metadata must capture the tool, version and configuration. The data can be coded in JSON, XML, or any other convenient format to automate its retrieval and processing. The following list is an example of how the data could look like:\n\u2022 Name: GPT-4\n\u2022 Description: GPT-4 is a large multimodal model (accepting text inputs and emitting text outputs today, with image inputs coming in the future) that can solve difficult problems with greater accuracy than any of our previous models, due to its broader general knowledge and advanced reasoning capabilities\n\u2022 Version: gpt-4-0613\n\u2022 URL: https://platform.openai.com/docs/models/ gpt-4\n\u2022 Author: OpenAl\n\u2022 Web: https://chat.openai.com//\n\u2022 Size: not disclosed\n\u2022 Window: 8192 tokens\n\u2022 Temperature: 0\n\u2022 Context: default\nThe metadata includes information on the Al model itself but also on the specific parameters' values se-lected when using it to write the paper. This enables the evaluation of the impact of the model parameters on the written text."}, {"title": "Where Al was used", "content": "The information on where Al tools were used can be described with the parts of the papers. For example the abstract, each of the sections, the figures, the tables or the references. This enables the identification of the text for which Al assistance has been used."}, {"title": "How Al was used", "content": "Al tools can be used for many different tasks: summa-rizing, translation, paraphrasing, finding related work and citations, etc. So, it is important to have information on how Al tools were used in the paper. For example, we can encode in the metadata that GPT-4 (so the \"which\") was used to summarize (the \"how\") and write the abstract (the \"where\")."}, {"title": "UNDERSTANDING THE IMPACT OF AI IN ACADEMIC WRITING", "content": "Let us consider now that we have a large corpus of papers and we want to know how many of them have used Al to summarize the abstract. Without metadata, all papers look the same (Figure 2, left), so we have to extract the text and either try to detect the use of Al in the abstract or find a disclosure of the authors that states the use of Al in the abstract. Instead if the proposed metadata has been added to the paper, we can just look at the how (summarizing) and where (abstract) to find the papers. The papers are now marked and can be easily identified (Figure 2, right).\nThe metadata can be used to analyze many as-pects of the use of Al in academic writing, for example, we can analyze:\n1) The adoption of the different Al tools and their variations over time.\n2) The tasks for which Al tools are more frequently used.\n3) The parts of the papers for which Al tools are more widely used.\n4) The correlation between the use of Al in a paper and its citation and popularity metrics.\n5) The use of Al tools in the different journals and conferences by the same publisher.\n6) The use of Al tools by authors of different regions and institutions.\n7) The use of Al tools by an author over time.\nThese are just few simple examples that show how adding simple metadata to academic publications makes it possible to gain different insights into the impact of Al tools in academic writing. These analyses can be easily run and automated once the metadata is integrated into the publisher's information systems opening the possibility of periodic reporting and anal-ysis.\nThe proposed metadata not only enables purely Al-related studies but also those that combine existing metadata such as for example the number of citations and the use of Al tools. The combinations of param-eters that can be studied are endless, one possibility"}, {"title": null, "content": "is to feed the raw into a machine learning system to extract patterns and relations.\nIn addition to the analysis of the metadata, it is also possible to use the metadata to perform analysis of the content of the main body of the papers. This is of interest when studying the impact of Al tools on the linguistic features of the text generated [6], for example, lexical richness [7]. Using the metadata, the text in papers (or sections within those papers) in which Al tools have been used, can be extracted to build a corpus of text generated for example with the assistance of a given tool. More generally corpora of text for a given set of Al metadata values can be easily generated. This is very interesting because it enables the analysis of the impact of Al tools on real data generated by many different users. The availability of such corpora opens new possibilities, such as for example:\n1) Analyze how Al tools affect the features of gen-erated text depending on the tool and version.\n2) Analyze how Al tools affect the features of gen-erated text depending on the task.\n3) Compare text generated by the same authors with and without the help of Al tools.\n4) Compare text generated by native and not native speakers as authors with and without Al tools.\n5) Provide datasets of user-generated data to de-velop and validate tools that detect Al-generated text.\n6) Compare text generated by authors when using Al tools with text generated directly by Al tools to understand how the assistance rather than the direct use of Al tools impacts the text.\nThe overall scenario is illustrated in Figure 3 with an example that shows how metadata can be used to understand the summarizing process with Al tools as used in different journals and also how metadata is combined with full text to analyze the lexical richness of Al generated abstracts."}, {"title": "CONCLUSION", "content": "This column proposes adding metadata on the use of artificial intelligence to scientific publications. The provision of having this metadata is critical for the anal-ysis and understanding of artificial intelligence and its impact on academic writing. It is important to note that the implementation of this solution will require changes to scientific journal and academic database systems by adding new fields to store the new metadata."}]}