{"title": "RTLSquad: Multi-Agent Based Interpretable RTL Design", "authors": ["Wang Bowei", "Qi Xiong", "Zeqing Xiang", "Lei Wang", "Renzhi Chen"], "abstract": "Optimizing Register-Transfer Level (RTL) code is crucial for improving hardware PPA performance. Large Language Models (LLMs) offer new approaches for automatic RTL code generation and optimization. However, existing methods often lack decision interpretability (sufficient, understandable justification for decisions), making it difficult for hardware engineers to trust the generated results, thus preventing these methods from being integrated into the design process. To address this, we propose RTLSquad, a novel LLM-Based Multi-Agent system for interpretable RTL code generation. RTLSquad divides the design process into exploration, implementation, and verification & evaluation stages managed by specialized agent squads, generating optimized RTL code through inter-agent collaboration, and providing decision interpretability through the communication process. Experiments show that RTLSquad excels in generating functionally correct RTL code and optimizing PPA performance, while also having the capability to provide decision paths, demonstrating the practical value of our system.", "sections": [{"title": "I. INTRODUCTION", "content": "Register-transfer level (RTL) design fundamentally impacts the power, performance, and area (PPA) of hardware, highlighting the importance of optimizing RTL code. Recent research has introduced large language model (LLM) techniques for automated RTL code generation, either by fine-tuning to produce high-quality RTL code [1], [2], [3] or through multi-stage processes to progressively optimize RTL code [4], [5]. Multi-stage RTL code generation process requires decision-making ability (what design to select, how to implement the design, etc.). Existing work leverages traditional heuristic algorithms to guide LLMs in making decisions, such as Monte Carlo Tree Search algorithm [4], [5], [6]. These methods can provide result interpretability by providing generated code after each decision, but they are limited in providing decision interpretability [7], the ability to clearly explain the rationale behind each decision. This limitation arises from the inherent randomness and opaque nature of heuristic methods. The lack of decision interpretability leads to: 1) Hardware engineers may struggle to trust the generated results, therefore unlikely to integrate these methods into current design process [8]; 2) Engineers being unable to discern the quality of results during the generation process, thus lacking sufficient reason to accept the final result over others; 3) Engineers also being unable to"}, {"title": "II. RELATED WORK", "content": "LLM for hardware design has gradually gained attention from researchers. Related studies covering various design processes [14], [15], [16], [17]. Our work primarily focuses on automated RTL design. Relevant studies indicate that LLMs capable of generate Verilog code but with limitations [18]. The agent paradigm can enhance LLM's design capabilities, such as using the ReAct [19] paradigm to drive LLMs to fix Verilog syntax errors [20]. Further, we focus on the LLM-MA (LLM-Based Multi Agent) method [21], which completes tasks through collaboration among multiple agents. Existing work primarily utilizes LLM-MA for HLS design [22] or layout design [23], lacking attention to RTL design. Our work employs multiple agents to form multiple specialized squads of agents, used to generate and optimize RTL code."}, {"title": "B. Decision Interpretability with LLM-MA", "content": "AI interpretability enables users to understand why AI systems produce specific results, thereby enhancing trust [24]. The application of LLM-MA systems in decision interpretation has been achieved in several critical fields such as medical diagnosis [25], [26], fact-checking [27], etc. This demonstrates the feasibility of using such methods in hardware design, a field with equally high demands for reliability. Compared to decision paths generated by methods like CoT [28], LLM-MA systems provide superior decision interpretability, including robust justification for decisions [29] and better diversity [13]. Therefore, our work employs a squad of agents as decision-makers, aiming to provide complete decision interpretations for implementation, exploration, and analysis."}, {"title": "III. METHODOLOGY", "content": "In this section, we will comprehensively introduce the design and implementation of RTLSquad. First, we will show the workflow of RTLSquad (Section III-A). Then, we will introduce the exploration (Section III-D), implementation (Section III-B), and verification & evaluation stages (Section III-C) of RTLSquad, describing the roles and processes of each stage."}, {"title": "A. Overview", "content": "Figure 1 illustrates the workflow of RTLSquad. Consistent with the standard RTL design process, RTLSquad accepts design specifications, testbench files, and optional initial code as inputs, and outputs optimized code and comprehensive decision path documentation. Depending on whether the functional verification is passed, the iterative process of RTLSquad is divided into the verification-fix loop (inner loop) and the exploration-implementation loop (outer loop). If the current version of the RTL code fails the functional verification, it enters the inner loop, switching between the verification and implementation stages to obtain error reports and correct errors in the code; if verification is successful, RTLSquad enters the outer loop, switching between the exploration, implementation, and verification stages to explore and implement new design methods."}, {"title": "B. Implementation Stage", "content": "As shown in Figure 2, the implementation stage is used to implement the exploration plan (see Section III-D) or to fix errors discovered during the verification stage. The"}, {"title": "C. Verification & Evaluation Stage", "content": "As shown in Figure 3, the verification & evaluation stage is used to perform functional simulation and logic synthesis on the RTL code provided by the implementation stage, observe and analyze the reports, and evaluate the design. The squad $S_{veri}$ in the verification stage consists of an observer and an analyst. The observer is responsible for extracting important information such as compilation errors, verification failures, and abnormal performance indicators from the reports and conveying it to the analyst. The analyst analyzes the statistical"}, {"title": "D. Exploration Stage", "content": "As shown in Figure 4, the exploration stage is used to explore different designs, forming a set of code design decisions that can optimize current code in terms of PPA. The exploration stage includes a squad $S_{expl}$ composed of experts in optimizing power, performance, and area, where three agents will engage in a debate. The agents communicate through a shared message pool [9]. The three agents take turns"}, {"title": "IV. CASE STUDY: DECISION INTERPRETABILITY", "content": "In this section, we analyze the results generated by RTLSquad under three different typical designs to demonstrate decision interpretability at each stage and explain how these interpretabilities can address the issues inherent in existing methods. The content displayed is excerpted from the output decision path documentation and has been reformatted for readability. Due to space limitations, the examples provided here do not cover all design scenarios, but are sufficient to illustrate the forms of interpretability provided by RTLSquad."}, {"title": "A. Implementation Interpretability", "content": "In Example IV, the programmer first listed the implementation steps based on the exploration plan, and then implemented them step by step. During the implementation process, the programmer initially provided a syntax-correct implementation that met the exploration plan but did not conform to the design specifications. The reviewer, after reviewing, found that the current code met the requirements of the exploration plan but contained functional errors, and thus made modification suggestions to the programmer. Under the reviewer's suggestions, the programmer made targeted modifications and refactoring to the code, ultimately providing the correct implementation. Conclusion. The decision-making process during the implementation stage includes steps for RTL code generation, issues within the code, and the code refactoring actions required to address these issues. This information provides transitional details before and after code modifications, decomposing the otherwise difficult-to-understand code changes into specific"}, {"title": "B. Analysis Interpretability", "content": "In Example IV, after performing logic synthesis, the observer first read the QoR report, extracted key performance indicators such as clock frequency, area, and power consumption, and then informed the analyst. The analyst summarized"}, {"title": "C. Exporation Interpretability", "content": "In Example IV-B, power experts suggested inserting an optimization design decision (clock gating) to reduce power"}, {"title": "C. PPA Metrics", "content": "We utilized the verified RTL code provided by the RTLLM dataset and the RTL code generated by the base model using the SP method as baselines, comparing them with the code optimized by RTLSquad in terms of PPA metrics. RTLSquad took the reference implementations from the dataset as input, optimized them to evaluate the framework's capability in optimizing PPA metrics. We executed the generated RTL code using commercial EDA tools for logic synthesis and extracted evaluation metric data from the synthesis reports. The experimental results are shown in Table I, indicating that in most cases, the RTL code optimized by RTLSquad achieved better overall PPA metrics."}, {"title": "V. EXPERIMENTS", "content": "Benchmarks and Baselines. We used the RTLLM V2.0 [30] dataset for evaluation, which contains 50 designs with varying scenarios and complexity levels. We optimized the testbench files in the dataset, adding more debugging outputs, enabling the implementation stage to utilize verification run logs for code correction. The optimized dataset will be made publicly available. Consistent with RTLLM, we employed the Self-Planning (SP) [31] method as the baseline approach, which requires the LLM to plan before writing RTL code, then generate code based on the planning results. Experimental Setup. We utilized Deepseek-V2.5 [32] and LLaMA 3.1-70B [33] as the backbone model for driving agents, with temperature set to 0.8. We used a commercial EDA tool to compile the RTL code and perform functional verification, with testbench files provided by the dataset. For designs that passed verification, we used a synthesis tool equipped with a 40nm process library to perform logic synthesis, obtaining evaluation metrics from output logs. Evaluation Metrics. We mainly focus on the following categories of metrics: 1. Whether the generated RTL code can be correctly compiled and pass functional verification; 2. Whether the PPA are better than the baseline implementation. For functional verification, we use the Pass@k [34] metric commonly used in code evaluation. Specifically, we focus on the Pass@1 metric, considering the higher cost of hardware code errors in practical scenarios. For PPA, we utilize: Power: dynamic power consumption, in unit \u03bcW; Area: total cell area, in unit \u03bcm\u00b2; Performance: critical path length and slack, in unit ns."}, {"title": "B. Functional Correctness", "content": "We conducted experiments across multiple hardware designs to evaluate RTLSquad's capability in generating functionally correct RTL code. We employed rigorous evaluation criteria where any generated code that failed to compile or pass functional verification was considered a failure. Table II shows the average Pass@1 results of the SP method and RTLSquad. The results indicate that RTLSquad: 1) can correctly implement designs that the baseline method can implement; 2) through verification feedback, has the ability to accomplish designs that the baseline method cannot implement. Therefore, RTLSquad demonstrates better RTL code generation capability, thus serving as a foundation for the effective operation of design exploration."}, {"title": "VI. CONCLUSION", "content": "In this paper, we propose a LLM-MA system for RTL code generation and optimization. We set up exploration, implementation, and verification stages, and assign different squads of agents to perform the functions. This framework not only automates the exploration of designs with superior PPA but also provides the reasoning path for design iteration through communication among agents, thereby enhancing decision interpretability on the basis of result interpretability, making the results more acceptable to designers. This work emphasizes the importance of RTL code generation interpretability, a frequently overlooked issue, and can serve as a prototype for the application of LLM-MA methods in this context, providing a new direction for future research."}]}