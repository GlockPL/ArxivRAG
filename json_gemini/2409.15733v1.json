{"title": "EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition", "authors": ["Ming Jin", "Danni Zhang", "Gangming Zhao", "Changde Du", "Jinpeng Li"], "abstract": "Electroencephalography (EEG)-based emotion recognition has gained significant traction due to its accuracy and objectivity. However, the non-stationary nature of EEG signals leads to distribution drift over time, causing severe performance degradation when the model is reused. While numerous domain adaptation (DA) approaches have been proposed in recent years to address this issue, their reliance on large amounts of target data for calibration restricts them to offline scenarios, rendering them unsuitable for real-time applications. To address this challenge, this paper proposes Evolvable Fast Adaptation (EvoFA), an online adaptive framework tailored for EEG data. EvoFA organically integrates the rapid adaptation of Few-Shot Learning (FSL) and the distribution matching of Domain Adaptation (DA) through a two-stage generalization process. During the training phase, a robust base meta-learning model is constructed for strong generalization. In the testing phase, a designed evolvable meta-adaptation module iteratively aligns the marginal distribution of target (testing) data with the evolving source (training) data within a model-agnostic meta-learning framework, enabling the model to learn the evolving trends of testing data relative to training data and improving online testing performance. Experimental results demonstrate that EvoFA achieves significant improvements compared to the basic FSL method and previous online methods. The introduction of EvoFA paves the way for broader adoption of EEG-based emotion recognition in real-world applications. Our code will be released upon publication.", "sections": [{"title": "I. INTRODUCTION", "content": "Emotion recognition holds immense potential for various applications, including education and psychological diagnosis and treatment [1], [2]. EEG-based recognition has attracted research interest in recent years due to its low cost, high accuracy, and the difficulty for subjects to conceal their emotions [3], [4]. However, despite significant advancements in improving the efficiency and accuracy of recognition, the decline in model performance when reused, especially in online settings, remains a prominent issue limiting the practical application of EEG-based emotion recognition [5].\nA major obstacle to the reusability of EEG-based emotion recognition is the problem of \"domain drift.\u201d This issue manifests as changes in the statistical properties of EEG signals over time, significantly impacting the accuracy and reliability of emotion recognition models. Factors contributing to domain drift include changes in the physiological state of subjects (such as fatigue or hunger), environmental interference (such as noise or light), and errors in device usage [6], [7].\nDomain drift poses a significant challenge to model performance. Existing methods to address this issue can be broadly categorized into two approaches.\n\u2022 Supervised methods: As depicted in Figure 1(a), this approach relies on a large amount of labeled data for direct model training or fine-tuning[8], [9]. While it grants generalization capability initially, the model's performance progressively degrades as domain drift in new data becomes persistent. Maintaining high performance necessitates frequent retraining with substantial amounts of newly labeled data, hindering real-world practicality.\n\u2022 Offline adaptation methods: Illustrated in Figure 1(b), this approach utilizes transfer learning to bridge the distributional gap between source and target domains[3], [10]. By leveraging a pre-trained model and fine-tuning it with target data, the models gain discriminative ability on new data. However, existing transfer learning methods still require a significant amount of unlabeled target data for distribution matching, which can be a limitation in resource-constrained scenarios.\nBoth approaches share a common dependency on substantial calibration data for model adjustments. This reliance on large datasets hinders their applicability in real-world situations where data acquisition might be expensive or limited.\nHumans exhibit remarkable ability to recognize new categories with only a few examples. Inspired by this capability, FSL has emerged as a promising approach to significantly reduce the calibration data required for models on new data. Applying FSL to EEG-based emotion recognition holds the potential to address the challenge of time-consuming calibration [11]\u2013[13]. However, the FSL framework primarily focuses on rapid adaptation to entirely new categories, where the training and test sets have non-overlapping in label space. Applying the basic FSL model rigidly to EEG emotion recognition overlooks two critical issues: for EEG data, there may be only limited modality shift between source and target data, and the label space for training and test data are completely identical.\nConsidering that DA is mainly designed to address data drift from the training set to the test set within the same label space, and FSL enables rapid calibration in an online learning mode, an ideal approach would be to organically combine the online rapid recognition capability of FSL with the distribution matching ability of DA to address data drift.\nTo address the issue of data drift faced by models during online use, this paper proposes EvoFA, a novel online adaptation framework for EEG-based emotion recognition. As illustrated in Figure 1 (c), EvoFA requires only a small amount of calibration data to quickly calibrate the model for effective testing. EvoFA combines the advantages of FSL rapid generalization and DA distribution matching through a two-step generalization process. During the training phase, FSL is utilized to initialize a general emotion recognition model with strong generalization capabilities. In the meta-testing phase, domain shifts induced by data drift are simulated, and an evolvable meta-adaptation module is introduced to align the target domain with the gradually changing source domain, thereby mitigating the impact of data drift on model performance. Experimental results demonstrate that EvoFA achieves significant improvements compared to the basic FSL method and previous online methods.\nOur work makes the following significant contributions:\n\u2022 We propose EvoFA, a novel framework tailored for online adaptation of EEG data, which significantly reduces calibration data and lowers the barrier for deploying EEG-based emotion recognition in real-world scenarios.\n\u2022 Within this framework, we introduce a flexible and lightweight rapid test-time transfer method that mitigates the impact of domain drift caused by continuous changes in EEG data modalities. This method requires no retraining and is compatible with various FSL models.\n\u2022 Experimental results on two datasets demonstrate that EvoFA not only achieves superior performance in online recognition tasks but also significantly reduces calibration data.\nThe subsequent sections are organized as follows: Section II reviews the progress in EEG-based emotion recognition, DA and meta-learning. Section III primarily introduces our proposed EvoFA framework, which cleverly combines the advantages of FSL rapid generalization and DA distribution matching, making it suitable for EEG emotion recognition tasks. Section IV demonstrates the improvements achieved by EvoFA on intra-subject and inter-subject tasks. Section V summarizes this work and provides future perspectives."}, {"title": "II. RELATED WORK", "content": "EEG-based emotion recognition can be broadly categorized into three types based on the level of access to test/target data.\nSupervised Learning: In this approach, test data is entirely unknown. The primary reliance is on supervised learning, where models are trained on training data to develop strong generalization capabilities that can fit well on test data. Since deeper networks typically have stronger fitting abilities, constructing deep models to learn robust representations is a mainstream method [9], [14]. In recent years, Graph Convolutional Networks (GCNs) have also been proven effective for handling EEG data due to their ability to capture critical information from brain topologies, allowing better discrimination of emotional patterns at both the feature and brain topology levels [8], [15]\u2013[17]. However, the performance of these trained models often significantly declines when applied to completely unknown test data.\nOffline Learning: This approach allows access to part or all of the unlabeled test data. To address the inevitable issue of modal drift, many studies have turned to offline learning modes based on transfer learning [3], [4], [10]. She et al. [4] proposed a new emotion recognition method based on a multisource associate domain adaptation (DA) network, considering both domain invariant and domain-specific features. SSDA was proposed to align the joint distributions of subjects, assuming that fine-grained structures must be aligned to perform a greater knowledge transfer [3]. However, since offline learning requires access to a large amount of test data, it often loses its applicability in most real-world scenarios.\nOnline Learning: In this scenario, only a minimal amount of test set calibration data is accessible. To better meet practical application needs, some studies have attempted to achieve rapid calibration and online recognition of EEG data. Pan et al. [18] proposed a novel Online Multimodal Hypergraph Learning (OMHGL) method, which integrates multimodal information based on time-series physiological signals for emotion recognition. Blanco et al. [19] developed a machine learning model using principal component analysis, power spectral density, random forest, and Extra-Trees that can recognize emotions in real time, providing estimates of valence,\nB. Unsupervised Domain Adaptation\nUnsupervised domain adaptation (UDA) has emerged as a solution to address the insufficient generalization of models across different data distributions. UDA primarily tackles the challenges of costly data collection and annotation by pre-training on existing source data and fine-tuning on unlabeled target data to enhance model performance in the target domain.\nUDA methods can be categorized into three main approaches. One approach effectively aligns the distributions of source and target domain data by minimizing the discrepancy in the embedding space, thereby improving model performance on target data, where the domain discrepancy is measured by Maximum Mean Discrepancy (MMD) [20] and Joint MMD [21]. Another common UDA method introduces domain discriminators to train the model to make it difficult for the discriminators to distinguish between source and target domain features, achieving feature alignment [22], [23]. Self-training-based methods generate pseudo-labels for target domain data and utilize these labels to supervise further model training iteratively, progressively enhancing model performance on target data [24], [25].\nC. Meta Learning\nMeta-learning, also known as 'learning to learn', stands in contrast to traditional artificial intelligence methods that solve tasks from scratch using fixed learning algorithms. Instead, meta-learning aims to improve the learning algorithm itself based on the experience gained from multiple learning episodes. This approach has gained significant interest in recent years, particularly for tasks involving FSL, which aligns well with the challenges of limited calibration data in EEG-based emotion recognition. The two primary approaches are metric-based and optimization-based approaches.\nMetric-based methods focus on learning a meaningful distance or similarity measure, allowing the model to embed data into a space where similar patterns are close together. Common distance metrics include cosine similarity [26], Euclidean distance [27], and CNN-based relational modules [28]. Relation networks [28] and Prototypical Networks [27] are examples of such approaches in FSL, enabling models to quickly adapt to new tasks with only a few samples.\nOptimization-based meta-learning focuses on 'learning to fine-tune' through good parameter initialization, enabling rapid adaptation to new tasks with minimal gradient updates. MAML prepares a model for fast adaptation to new tasks through a two-step training process, maintaining compatibility with any model that learns via gradient descent [29]. Reptile simplifies MAML by steering the initialization towards weights that perform well across multiple tasks, effectively rendering it a simpler variant of MAML [30]. The optimization framework of MAML and its variants provides ideas for the rapid adaptation of EvoFA in the second stage [29]\u2013[31]."}, {"title": "III. METHODS", "content": "EvoFA achieves rapid calibration of EEG through two-step generalization, mitigating the impact of data modality drift. The main architecture is detailed in Figure 2. FSL-based primary generalization: We employ G2G paired with 2D CNN as the backbone network to extract deep representations from EEG signals and utilize FSL to enhance the model's generalization ability during online calibration. Rapid adaptation secondary generalization: In the meta-testing phase, we cache the data patterns of the source data as they change over time and construct meta-adaptation of the target data relative to the source domain based on time changes, enabling the model to adapt to in new data. The backbone network parameters are denoted by $\\theta$, representing the function $g_\\theta$. Extracted features are then processed through a novel adaptation optimization layer $h_\\phi$ parameterized by $\\phi$, followed by a classification layer $c_w$ to yield the corresponding emotional output. In the following description, to avoid misunderstandings, we will selectively use the terms source domain data / target domain data and training data / testing data in different contexts.\nG2G offers a novel approach to processing EEG data by capturing the dense information interactions between electrode nodes [9]. This allows the processed EEG data to maintain a larger shape and become more suitable for deep learning models, particularly for tasks like emotion recognition where the relationships between electrodes are crucial. Inspired by this concept, we process the EEG feature, denoted as $F \\in \\mathbb{R}^{n \\times d}$, into a 2D feature interaction matrix $F' \\in \\mathbb{R}^{c \\times n \\times n}$ using the G2G transformation:\n$F^{\\prime 2 D}=G2G(F^{1D}),$ (1)\nwhere $n$ represents the number of electrodes, $d$ denotes the number of features per electrode, and $c$ indicate channels.\nAfter processing EEG into 2D interaction matrices, we further employ a ConvNet to learn deep representations from these matrices. The ConvNet includes four distinct Conv-BN-ReLU structures. Both the G2G and the subsequent ConvNet are jointly denoted by the representation function $g_\\theta$. Next, the data is input into the meta adaptation optimization layer denoted by $h_\\phi$. This layer comprises two fully-connected layers and aims to capture the evolving emotional representations during meta-testing in section III-D, enabling the model to adapt to domain shift. Ultimately, the classification layer $c_w$ outputs the emotion recognition results. It's worth noting that in the context of RelationNet [28], the classification layer serves a similar function as the relation module.\nB. FSL-based Preliminary Generalization\nTraditional deep learning trains models on large datasets, mapping different categories of data to their corresponding labels. FSL, on the other hand, learns distinguishing features from a small amount of data, enabling the model to differentiate between different categories.\nMost EEG emotion recognition methods rely on offline learning with large datasets, rendering them impractical for online use. In contrast, FSL quickly achieves classification ability with a few samples, making it an inherently suitable framework for online emotion recognition.\nFSL empowers the model to recognize target data categories in query set $Q$ using few-shot support set $S$ calibration samples through episode training. During the training phase, we randomly sample $N$ classes from the training data. For each class, we randomly select $K + Q$ labeled samples, where $K$ are used for the support set and the remaining $Q$ for the query set (forming an $N$-way $K$-shot setting). The corresponding support and query sets are:\n$S = \\{(x_1, y_1), ..., (x_{N \\times K}, y_{N \\times K})\\},\\ Q = \\{(x_{N \\times K+1}, y_{N \\times K+1}),..., (x_{N \\times (K+Q)}, y_{N \\times (K+Q)})\\}.$\nThe model is updated by calculating its loss on the query set. In this paper, to demonstrate EvoFA's broad adaptability, we trained three models based on three commonly used FSL frameworks: MatchingNet (MN) [26], RelationNet (RN) [28], and ProtoNet (PN) [27]. The corresponding loss functions are:\n$L_{MN} (\\theta, \\phi, W) = \\frac{1}{Q \\cdot N} \\sum_{i=1}^Q \\sum_{n=1}^N y_{in} log(p_{in} (\\theta, \\phi, W))$\n$L_{RN} (\\theta, \\phi, W) = \\frac{1}{Q} \\sum_{i=1}^{1-Q} (r_i (\\theta, \\phi, W) \u2013 y_i)^2$\n$L_{PN} (\\theta, \\phi, W) = \\frac{1}{1-Q} \\sum_{i=1}^Q log \\frac{exp(-d(f_{\\theta,\\phi,W} (x_i), \\eta_{y_i}))}{\\sum_{n=1}^N exp(-d(f_{\\theta,\\phi,W}(x_i), \\eta_{n}))}$ (2)\nC. From Conventional FSL to EvoFA\nIn the basic FSL framework, during the testing phase, the category of unlabeled samples in the query set is determined based on a small labeled support set. The label spaces of the training and testing sets are mutually exclusive, and each episode's support set and query set correspond one-to-one in terms of categories.\nUnlike typical FSL tasks, in EEG emotion recognition, due to the limited emotion categories, the labels of the training and test sets are usually identical. Additionally, differences in the distribution of test set data relative to training set data generally stem from modal drift in the subjects' EEG data.\nBy reducing the modal drift of test data relative to training data, it is expected to improve the model's performance in few-shot testing scenarios. A common approach to reducing modal drift is DA. However, traditional domain adaptation typically requires access to all or a significant portion of the test set data and introduces additional training processes during the training phase. Implementing such domain adaptation contradicts existing online calibration patterns.\nEvoFA innovatively introduces test-time adaptation to address the performance degradation caused by modal drift. Before each episode's testing, DA is pre-introduced to adapt the test data to the evolving source data described in Section III-D, enhancing the model's adaptability to the test data. EvoFA's introduction offers the following advantages: (1) In the traditional FSL framework, it can be directly introduced during testing, improving the model's recognition ability for test data without additional training. (2) It captures the un-\n$F_{\\phi_{i+1}} \\leftarrow F_{\\phi_i} - N_i \\eta_i \\nabla_{\\phi} [d (f_{\\theta,\\phi_i,W} (x_t), f_{\\theta,\\phi_i,W} (x_p))]$\n$L(\\phi) = \\frac{1}{n} \\sum_{i=1}^n d (f_{\\theta,\\phi_n,W} (x_{s_i}), f_{\\theta,\\phi_n,W} (x_t)).$ (3) (4)\n$G_F \\leftarrow  F_i - N_i \\eta_i \\nabla_{F_i} [d (f_{\\theta,F_i,W} (x_{s_i}), f_{\\theta,F_i,W} (x_t))].$\nderlying patterns of modal drift in the data, better addressing unknown test data. (3) It exhibits broad adaptability, enabling its use with various FSL models.\nD. Rapid Adaptation Secondary Generalization\nUnlike traditional FSL-based methods, which directly measure the similarity between the query set and a small labeled support set to determine the category of samples during testing, EvoFA introduces an additional evolvable fast adaptation module before classification. This module aims to capture potential patterns of modal drift in the source data and apply them for rapid calibration of the target data.\nHowever, while there indeed exists a distribution drift of test data relative to training data caused by modal drift, this change is unknown. To better capture the trend of data changes, we sampled a series of subsets of the source data $S' = \\{X_{s1},X_{s2},...,X_{sn}\\}$ on the source domain $S$, and $T' = \\{X_{tn+k}\\}$ from the target domain $T$. Each source domain subset represents a snapshot of modal drift to target domain. MAML learns transferable features by minimizing errors on the support set in the inner loop and errors on the query set in the outer loop. Inspired by this, by gradually narrowing the distance between target data and different subsets of source data in the inner loop, we aim to capture potential patterns of modal drift from source to target. Subsequently, updating the optimizer's parameters in the outer loop is expected to mitigate the damage of modal drift and improve the model's accuracy on the test set.\nWe constructed different learning patterns for intra and inter-subject tasks, with a more detailed description of both tasks in Section IV-A. For intra-subject experiments, the modal drift of test data relative to training data gradually intensifies over time. To reduce the impact of modal drift caused by temporal changes, we uniformly sample the training set data over time to form subsets of the source data. For inter-subject experiments, the modal drift of test data relative to training data mainly stems from modal differences between different subjects. To mitigate modal drift caused by different subjects, we sample a subset of data for each subject in the training set.\nFast Adapt to Snapshot In the inner loop, we quantify the drift of each source domain snapshot relative to the target domain and sequentially calculate the MMD loss between the corresponding subset data and the test data. After computing the MMD loss for each subset, we update the parameters of the adaptation layer $h_\\phi$. During this stage, the parameters of $g_\\theta$ and $c_w$ are fixed. For $i = 0, 1, . . ., n \u2212 1,\n$L(\\phi) = \\frac{1}{n} \\sum_{i=1}^n d (f_{\\theta,\\phi_n,W} (x_{s_i}), f_{\\theta,\\phi_n,W} (x_t)).$"}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "We evaluated the proposed EvoFA on two open-source datasets, SEED [32] and SEED-V [33], and conducted both intra-subject and inter-subject experiments on each dataset.\nFirst, we trained the model under three common FSL frameworks and used the standard FSL-based test results as the baseline [26]\u2013[28]. To demonstrate the effectiveness of EvoFA, we directly used the model trained on the standard FSL framework and introduced the fast adaptation meta-testing module shown in Figure 2(b) during testing.\nIn this section, all results are derived from the author's replication of the original study, except for the comparison results in Figure 4, which are extracted from the corresponding citations. Due to the differences in tasks and the strict division of the training, validation, and test sets in this study, there are significant discrepancies between the reported results and those in the original papers.\nIntra-subject emotion recognition aims to demonstrate: (1) the advantages of online calibration over supervised learning; (2) the further improvement of EvoFA over standard FSL.\nFor supervised learning methods, we strictly followed the train-validation-test paradigm. During the training of each model, the model with the best performance on the validation set was saved and tested centrally after all training was completed. The learning rate of the model was set to 0.003 and the batch size was set to 32.\nFor online calibration methods, we conducted 3-way 1-shot and 3-way 5-shot experiments on the 3-class SEED dataset, where the number of samples per class in the query set was 10. We conducted 5-way 1-shot and 5-way 5-shot experiments on the 5-class SEED-V dataset, where the number of samples per class in the query set was set to five. This was done to ensure that the batch size was close to that of supervised learning.\n1) FSL-based online calibration: To demonstrate the superiority of online calibration over supervised learning, we reimplemented four supervised learning-based methods and three FSL-based online calibration methods.\nEvoFA enhances the adaptability of the test data by making it conform to the temporal variations of the training data and by narrowing the distance to the overall distribution of the test data during the testing process. This approach results in improved model compatibility with the test data. In the testing phase, the introduction of EvoFA led to performance gains across all three different FSL frameworks. On the SEED dataset, there was an average accuracy increase of 0.47%; on the SEED-V dataset, the average improvement was 0.44%. Furthermore, comparing the 1-shot and 5-shot settings, a larger support set contributes more effectively to the optimization of meta-adaptation, thereby resulting in more significant improvements.\nAlthough these enhancements are relatively modest compared to the original FSL frameworks, they are significant given that the model does not require retraining. The incorporation of the rapid adaptation module at the time of use, without introducing additional training losses, is a key advantage. Furthermore, the module's effectiveness across all three FSL frameworks demonstrates its general applicability.\nComparing the experimental results of the first four sections, we found that:\n1) Modal shift is widely prevalent. On the SEED dataset, the performance of the online calibration mode declined by approximately 25% in the inter-subject tasks compared to the intra-subject tasks; on the SEED-V dataset, this performance drop increased to 40%. This indicates a more severe data modal difference across inter-subject tasks. In EEG emotion recognition tasks, facing this modal shift is unavoidable.\n2) Supervised learning encounters bottlenecks. Faced with such significant modal drift in EEG data, supervised learning has struggled to address this issue through increasing network depth or generalization ability. Although there has been a plethora of work in recent years focusing on improving the accuracy of models on validation sets in EEG emotion recognition tasks, this improvement faces significant shrinkage when additional test sets are introduced.\n3) FSL still faces limitations. Current FSL-based online calibration methods still require labeled data. However, it is still costly to calibrate the data category during calibration, so it is very meaningful to update it to an unlabeled online calibration model.\n4) EvoFA repairs the calibration mode. EvoFA attempts to address the issue of distribution differences caused by data drift during testing (calibration) by introducing domain adaptation between training and testing data, and preliminary results in experimental results show promise. By introducing testing-time adaptation, models are expected to achieve unlabeled online calibration, which is also our future directions."}, {"title": "V. CONCLUSION", "content": "This paper addresses the adaptability issue in EEG emotion recognition caused by domain drift and proposes a framework, EvoFA, suitable for rapid calibration in online EEG emotion recognition. To tackle the data modal shift in EEG data and the subsequent need for rapid calibration, EvoFA integrates the rapid adaptation of FSL with the distribution alignment of DA in an organic manner. By adding EvoFA as a plug-in to various FSL frameworks based on online calibration modes, it reduces the domain gap between the source domain data and target domain data during testing, thereby enhancing the model's recognition ability. EvoFA, with its high compatibility and no need for retraining, brings about an additional improvement of around 0.4% in testing structures across three FSL frameworks. Moving forward, we will continue to focus on rapid modal adaptation in EEG, advancing the practical application of deep models in the EEG domain."}]}