{"title": "PCEvE: Part Contribution Evaluation Based Model Explanation for Human Figure Drawing Assessment and Beyond", "authors": ["Jongseo Lee", "Geo Ahn", "Jinwoo Choi", "Seong Tae Kim"], "abstract": "For automatic human figure drawing (HFD) assessment tasks, such as diagnosing autism spectrum disorder (ASD) using HFD images, the clarity and explainability of a model decision are crucial. Existing pixel-level attribution-based explainable AI (XAI) approaches demand considerable effort from users to interpret the semantic information of a region in an image, which can be often time-consuming and impractical. To overcome this challenge, we propose a part contribution evaluation based model explanation (PCEvE) framework. On top of the part detection, we measure the Shapley Value of each individual part to evaluate the contribution to a model decision. Unlike existing attribution-based XAI approaches, the PCEVE provides a straightforward explanation of a model decision, i.e., a part contribution histogram. Furthermore, the PCEVE expands the scope of explanations beyond the conventional sample-level to include class-level and task-level insights, offering a richer, more comprehensive understanding of model behavior. We rigorously validate the PCEvE via extensive experiments on multiple HFD assessment datasets. Also, we sanity-check the proposed method with a set of controlled experiments. Additionally, we demonstrate the versatility and applicability of our method to other domains by applying it to a photo-realistic dataset, the Stanford Cars.", "sections": [{"title": "1 Introduction", "content": "With recent advances in computer vision and deep learning, human figure drawing (HFD) assessment using a deep learning model has shown great progress [24]. Despite the great advancement, we still do not understand the decision-making processes underlying these models. The transparency of a method is crucial in medical applications such as ASD diagnosis since the clear and reliable rationale behind diagnosis should be provided to subjects and their families [37]\nIn this work, we propose a novel model explanation framework for HFD assessment, referred to as Part Contribution Evaluation based model Explanation (PCEvE). Our method is designed to provide explanations based on the contributions of human body parts on an input human figure drawing image. With the PCEVE, we can identify which part is more important than other parts in a model decision on an input human figure drawing image. By quantifying the contributions of parts, the PCEVE provides reliable clues for a model decision, which can be integrated into the class and task level."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Attribution-based Model Explanation", "content": "Attribution-based model explanation approaches measure the contribution of each pixel in various ways and visualize the contribution by overlaying a heatmap on the input image as shown in Figure 1(a). There are two main categories of attribution-based approaches: gradient-based and perturbation-based approaches. Gradient-based attribution approaches [28, 39] leverage the gradient of the model's output of the target class with respect to a particular feature. A higher gradient value suggests that a small change in the feature would lead to a significant change in the output, highlighting the contribution to the model decision. Perturbation-based approaches [26, 10] perturb one or more input features (e.g., pixels) and explain how the model prediction changes in the target class. By perturbing input pixels, these methods can identify regions in the input that highly contribute to the model predictions.\nAttribution-based approaches can provide pixel-level explanations of a model. However, pixel-level attribution approaches force a human to interpret the semantic information of a region in an image, leading to additional costs [36]. Interpreting a saliency map is often nontrivial and may even introduce human confirmation bias through qualitative evaluation [6]. In contrast, our work addresses the limitations of attribution-based approaches by taking a part-based model explanation approach, which offers a more intuitive framework for interpreting model decisions."}, {"title": "2.2 Shapley Value", "content": "The Shapley Value [29] is a concept borrowed from the cooperative game theory. In the game theory, the Shapley Value is a metric to fairly distribute payoffs among players based on their contribution to the total gain. In machine learning, the Shapley Value offers a principled approach to quantify the importance of individual input features. In many recent works on XA\u0391\u0399 [38, 1], the Shapely Value is used to measure the marginal contribution of each feature or neuron by considering all possible combinations of features, offering a comprehensive view of how each input impacts the model decision. While prior works focus on explaining a model by observing the feature or neuron, our work focuses on explaining a model behavior by observing the part contribution. Moreover, our PCEVE can provide a model explanation at various levels: sample, class, and task while the prior works mostly focus on sample-level explanations."}, {"title": "2.3 Human Figure Drawing Assessment", "content": "There have been extensive works on art psychotherapy using a human figure drawing (HFD) assessment aimed at estimating the mental developmental status of a child. The most popular HFD assessment tasks are Draw-a-Person (DAP) test [12] and House-Tree-Person (HTP) test [3]. The DAP test measures a child's intellectual developmental status through their drawing of a person. In the DAP test, the criteria include the presence of parts such as eyes and legs, the appropriateness of the position and proportion of each part, and other details reflecting the overall appearance [12]. The HTP test evaluates aspects of a participant's personality, emotions, and attitudes using the drawing of a house, a tree, and a person. The criteria include the shape, position, size, and shading of each component, as well as the overall mood, harmony, structure of the entire picture, and line pressure, among others [3]. The details of each part are important in the two popular HFD assessment tasks.\nRecent works [21, 24] have shown that deep neural networks can learn the HFD assessment tasks. There are only a few works on the deep learning based HFD assessment model explanation such as applying the CAM [40] to the HFD assessment models [17], and detecting objects [18] for the Drawing-A-Person-in-the-Rain assessment task [34]. However, the prior works do not provide a straightforward model explanation that a human can easily understand. In contrast, we propose the PCEVE to explain a model decision for HFD assessment tasks, which provides a straightforward model explanation: part contribution histogram."}, {"title": "2.4 Concept-based and Part-based Model Explanation", "content": "Concept-based and part-based model explanation approaches are popular in explaining fine-grained visual categorization (FGVC) model behaviors. Concept-based approaches [9, 23] extract high-level concepts learned by models. However, concept-based approaches heavily rely on the good representations learned by the model, making it challenging to extract reasonable concepts in data-scarce domains such as sketch-based HFD assessment tasks.\nPart-based XAI methods [16, 14] try to explain models by clarifying the semantic importance of different parts in fine-grained visual categorization tasks. However, it is nontrivial to apply the prior part-based XAI methods to the HFD assessment tasks. Since the HFD datasets often have limited size, the extracted features by a model are not quite reliable for the existing part-based XAI methods. To address the challenge, we define semantic parts by using part annotations/detections and evaluate part contributions using Shapley Value [29] instead of conventional optimization."}, {"title": "3 Part Contribution Evaluation Based Model Explanation", "content": "We introduce the Part Contribution Evaluation based model Explanation (PCEvE) framework. As shown in Figure 3, the PCEvE provides part contribution statistics of a model at a sample/class/task level, e.g., at the task level, 'Hair' of the drawing contributes most to a gender classification model decision. To evaluate part contribution, the PCEVE measures the Shapley Value [29] of each part. Since we can measure the Shapley Value for every model, the PCEvE is model-agnostic for the classification task. In this section, we provide a detailed description of the Shapley Value in Section 3.1. Then we show the overall PCEvE framework in Section 3.2. We illustrate the sample-level PCEVE in Section 3.3. Finally, we describe how we extend the sample-level PCEvE to class-level and task-level PCEVE in Section 3.4."}, {"title": "3.1 Preliminaries: Shapley Value", "content": "We provide preliminary descriptions on the Shapley Value [29]. The Shapley Value is a metric to evaluate the contribution of a player in a coalitional game. Using the Shapley Value, we can allocate a fair reward to each player by considering all the contributions in a game. The Shapley value is a robust metric for evaluating fair contributions among players.\nGiven a set, N, of n players, a value function $f : 2^N \\rightarrow R$ assigns each a subset $S \\subset N$ a real number, where the $2^N$ denotes the power set of N. The f (S) evaluates the summation of rewards obtained by the members of S in a coalitional game. Then the Shapley Value of an i-th player, $Vi(f)$, measures the average marginal contribution that the player makes across all possible coalitions S containing the player i.\n$Vi(f) = \\sum_{S\\subset N\\{i\\}} \\frac{|S|! (n - |S| - 1)!}{n!} (f(S\\cup \\{i\\}) - f(S)).$ (1)\nWith the Shapley Value, we can obtain a fair distribution of the total surplus from all the players by considering the pure contribution of each player in a coalitional game. There are four axiomatic characterizations to prove the fairness of the Shapley Value.\nDummy Player. If a player has no contribution to the game, the Shapley Value for that player should be zero. This means the concept that players who do not contribute should not receive any payoff.\nEfficiency. The sum of payoff distributed to all players must equal the total value generated by the coalitional game i.e., $f(N) = \\sum_{i \\in N} Vi(f)$. This ensures that the collective rewards allocated based on individual contributions match the overall value created, highlighting that no value is wasted.\nSymmetry. If two players have the same contributions, their Shapley Values should be the same. This reflects the idea that players with equivalent roles should receive equivalent rewards.\nLinearity. If there are two coalitional games with value functions f and g, the Shapley Value for a player in a combined game $Vi(a \\cdot f + b \\cdot g)$ is a linear combination of the two Shapley Value from individual Shapley values $Vi(f)$ and $Vi(g)$. i.e., $\\psi_{i}(a \\cdot f + b \\cdot g) = a\\psi_{i}(f) + b\\psi_{i}(g)$."}, {"title": "3.2 PCEVE Framework Overview", "content": "In our Part Contribution Evaluation based model Explanation (PCEvE) framework, we measure the Shapley Value [29] of each part to evaluate the contribution to a model decision on the target task. Since the Shapley Value fairly measures contributions from all players in a coalition game, we use it to fairly measure how much each part contributes to a model decision. In Figure 2, we provide an analogy between the PCEvE and the game theory. In the example shown in Figure 2 (b), we treat each part, i.e., 'Hair', \u2018Nose', \u2018Ear', and 'Hand', of an input image as a player in a coalitional game, i.e., a model decision. In the example, while each body part contributes to a model decision, \u2018Hair' contributes the most.\nLet us consider a classification task with a dataset $D = \\{(Xi, Yi)\\}_{i=1}^N$, where x\u1d62 is the i-th image and yi is the corresponding label, and N denotes the number of samples. As shown in Figure 3, given an input image xi, we run an off-the-shelf part detector to obtain K part pseudo-labels. The part pseudo-labels are the bounding box coordinates of each part. Then we generate $2^K$ images by masking each part to obtain a set of all possible part combinations $X_i$. In the sample-level PCEVE (S-PCEVE), to evaluate the contribution of each part, we aggregate the logit vectors of every image in $X_i$, predicted by a model of our interest. On top of the S-PCEvE, we can obtain a group-level explanation of a model. Given a target class, e.g., 'Female', the class-level PCEVE (C-PCEvE) counts the most significant part for every image belonging to the class, resulting in a class-level part contribution histogram. The task-level PCEVE (T-PCEvE) accumulates the class-level part contribution histograms of all classes in the task to obtain the task-level part contribution."}, {"title": "3.3 Sample-Level PCEVE", "content": "Given a set of all possible part combinations $X_i$ of an input image xi, the goal of S-PCEVE is to quantify the contribution of each part of the input image to the decision of a model of interest, $f$. Here, a model of interest $f_{\\theta}$, with parameters \u03b8, serves as a value function as described in"}, {"title": "3.4 Class-Level and Task-Level PCEVE", "content": "We expand our framework from individual sample-level PCEvE framework to a broader scope: class-level and task-level PCEvE frameworks. We aggregate all the sample-level part contribution histograms cs to obtain class-level and task-level statistics.\nC-PCEVE. The C-PCEvE quantifies the contribution of each part within a specific class. Let us consider a set $D_c \\in D$ containing Nc samples of the class c. The C-PCEVE calculates the most contributing part of every sample in Dc by (3). Then, the C-PCEvE constructs a class-level part contribution histogram by counting the most contributing parts as follows:\n$I_k = \\frac{1}{N_c} \\sum_{i=1}^{N_c} 1(k^*_i = k),$ (4)\n$I_c = [I_1, I_2, \u2026 \u2026 \u2026 , I_K]^T.$ (5)\nHere, $I_k$ denotes the frequency at which the k-th part is identified as the most significant contributor. The indicator function, denoted by $1(\\cdot)$ outputs 1 when the condition is satisfied and outputs 0 otherwise. With (5), the C-PCEVE can evaluate the contribution of each part at the class-level. For instance, in Figure 3 (b), 'Hair' is crucial to a model in classifying images as 'Female' within the dataset. In other words, we can explain that the model focuses on 'Hair' the most among the seven parts to predict an input image as \u2018Female' on average. C-PCEvE enhances the interpretability of a model and aids in identifying the importance of each part in decisions related to a specific class.\nT-PCEVE. The T-PCEvE framework extends the C-PCEvE to the entire dataset D, combining class-level part contribution histograms, Ic, across all C classes to provide a task-level statistics as follows:\n$I_T = \\sum_{c=1}^C I_c.$ (6)\nThe T-PCEvE framework evaluates the relative importance of each part in a classification task with a dataset D, offering insights into overall model behavior. For example, in Figure 3 (c), 'Hair' is the most contributing part, and 'Foot' is the second most contributing part among all seven parts in a model in distinguishing \u2018Male' and 'Female' classes.\nIn summary, the C-PCEvE and T-PCEvE frameworks enrich the interpretability of classification models by offering insights into how models prioritize different components in their decision-making processes. To the best of our knowledge, the PCEvE is the first approach providing such group-level explanation of classification models."}, {"title": "4 Results", "content": "In this section, we conduct extensive experiments across various HFD assessment datasets with diverse models to validate the effectiveness of our model explanation framework, PCEvE. Through the experiments, we answer the following research questions: (1) Does the PCEvE give reasonable part-based explanations in various HFD assessment tasks? (Section 4.3) (2) Is the PCEvE able to provide more abstract level explanations, i.e., class-level and task-level? (Section 4.4) (3) Is the PCEVE able to provide explanations of multiple models? (Section 4.5) (4) Can we apply the PCEVE to photo-realistic fine-grained classification tasks? (Section 4.6) To this end, we first provide the details on the dataset used, and our implementation in Section 4.1 and Section 4.2, respectively."}, {"title": "4.1 Datasets", "content": "We evaluate the PCEvE using two human figure drawing assessment datasets: the Autism Spectrum Disorder (ASD) screening and the Sketch for Child Art Therapy (SCAT). For the extension to the photo-realistic fine-grained visual classification task, we evaluate the PCEvE on the Stanford Cars[19] dataset.\nASD Screening. The ASD Screening [30] dataset comprises 100 sketches of human figures, created by subjects diagnosed with autism spectrum disorder (ASD) as well as typically developing (TD) children. These subjects range in age from 5 to 12 years. In each drawing session, the subject"}, {"title": "4.2 Implementation Details", "content": ""}, {"title": "4.2.1 Training", "content": "To validate the PCEVE, we train diverse model, including ResNet [13], DenseNet [15], Efficient-Net [32] and ViT [8] and choose the best performing model for the explanation. For the evaluation, we fine-tune ImageNet-1K [7] pre-trained models on the HFD datasets.\nHyperparameters. For the ASD Screening [30] and SCAT datasets, to maintain the aspect ratio of the human object, we resize input images into 224\u00d7168 pixels for all models except the ViT."}, {"title": "4.2.2 Part annotations", "content": "To apply the PCEVE, we need part annotations of each part, i.e., bounding boxes. The SCAT dataset provides bounding box annotations of 18 parts. In this work, we use the following seven parts for the evaluation: \u2018eye', 'nose', 'ear', 'mouth', 'hand', 'foot', and 'hair'.\nSince the ASD Screening [30] dataset does not provide part annotations, we manually annotate the bounding box of each part using the LabelMe toolkit [27]. We annotate nine distinct parts for a sample in the ASD Screening dataset: 'head', 'eye', 'nose', 'ear', 'mouth', 'hand', 'foot', 'upper body', and 'lower body'. To provide more clarity, the 'head' part includes hair and face, the 'upper body' part includes neck and hands, and the 'lower body' part includes feet. In this work, we use only the following seven parts: 'head', 'eye', 'nose', 'ear', 'mouth', 'hand', 'foot', and 'face' for the evaluation. After carefully observing the samples, we define the 'face' part to represent the head area excluding the eyes, nose, mouth, and ears since it also contains discriminative features beneficial in distinguishing ASD and TD samples.\nSince the Stanford Cars [19] dataset also does not provide bounding box annotations, we employ an off-the-shelf part detector, YOLOv3 [25] provided by a repository 5. With the part detector, we detect the following five parts in an image: 'door', 'light', 'glass', 'sideglass', and 'wheel'."}, {"title": "4.2.3 Inference", "content": "The PCEvE can determine which parts the model predominantly focuses on when making predictions. To obtain the part statistics, the PCEvE needs to infer the single test sample for 2K times, where K denotes the number of pre-defined parts. For the ASD Screening [30] dataset inference, we use the model trained on the training set of each fold being validated. We use the model checkpoint that achieves the highest validation accuracy for each fold."}, {"title": "4.3 Sample-level Part-Based Model Explanation", "content": "In Figure 5, we compare a few explanations of a model i.e., EfficientNet-B1 [32], generated by the PCEVE and GradCAM [28] on the ASD Screening [30] dataset and SCAT-Drawing dataset. While a pixel-level attribution method, GradCAM, can highlight the region the model of interest focuses on, we still need to interpret the semantic information of the region. For instance, in Figure 5 (b), GradCAM shows an attention map firing on 'face', 'eye', 'mouth' and 'hand'. To figure out which part contributes the most to the model decision, we, as humans, need to interpret the visualization. In contrast, the PCEvE shows an intuitive part contribution histogram which does not require much interpretation to understand. Clearly 'face' contributes the most and the 'eye' contributes the second most to the model decision. We can observe a similar trend in other examples as well."}, {"title": "4.4 Class-level and Task-level Part-Based Model Explanation", "content": "ASD Screening. We show the class-level and task-level model explanation generated by the PCEVE in Figure 6 and Figure 7, respectively. When counting the most contributing parts of each sample using (5), we consider the samples correctly predicted by the model only. In Figure 6, we observe that the 'Face' part is the most contributing part when the model predicts both ASD and TD samples. The model focuses more on the 'Face' and less on the 'Ear' and 'Hand' on average when recognizing TD samples, compared to when recognizing ASD samples. In Figure 7, we also observe that the 'Face' part is the most contributing part when the model distinguishes ASD and TD samples in the dataset. As shown in Figure 7 (a) and (b), the 'Face' drawn by ASD and TD children show distinct characteristics.\nSCAT. We show the class-level and task-level model explanation generated by the PCEvE in Figure 8 and Figure 9, respectively. When counting the most contributing parts of each sample, we consider the samples correctly predicted by the model only. In Figure 8 (a), the class-level part contribution histogram indicates that \u2018Foot' contributes the most for the model recognizing the male drawing while 'Hair' contributes the most for the model recognizing the female drawing. The trend shifts slightly when recognizing the gender of the drawer; here, \u2018Eye' becomes the most contributing part for the model recognizing the male drawer while 'Hair' remains same as the most contributing part in recognizing the female drawer as shown in Figure 8 (b). We also visualize the task-level part contribution statistics in Figure 9. We find the 'Hair' part is the most discriminative for the model regardless of drawing or drawer gender classification task. In Figure 9 (c) and (e), we visualize some sample images of the \u2018Hair' part in each drawing gender class to inspect if there are differences between classes. We observe apparent differences in the images of the 'Hair' part between drawing object genders. The 'Hair' part can be an important clue even for a human in distinguishing the gender of a human figure drawing, which aligns with the model explanation produced by the PCEVE. In the drawer gender classification task, we observe a similar trend. We observe subtle differences between the hair drawn by male and female subjects in Figure 9 (d) and (f)."}, {"title": "4.5 Other Model Explanations", "content": "In Figure 10, we show the class-level part contribution histograms generated by the PCEVE for explaining model behavior across different datasets and models. Specifically, we examine the ViT-Small [8] and DenseNet-121 [15] models on the SCAT-Drawing in Figure 10 (a) and (c), and on the Stanford Cars [19] dataset in Figure 10 (b) and (d). For the car-type classification task, we focus on histograms for the 'Cab' class. In the case of the SCAT-Drawing dataset, both the ViT-Small (Figure 10 (a)) and DenseNet-121 (Figure 10 (c)) models primarily focus on the 'Hair' part for predicting female samples, aligning with observations made for the EfficientNet-B1 model in Figure 8 (a). Their focus diverges when classifying male samples: ViT-Small leans towards the 'Foot' part, whereas DenseNet-121 prioritizes the 'Ear' part for identifying male drawings.\nFor the car-type classification, the most contributing parts for 'Cab' class differ between the two models; ViT-Small focuses on the 'Wheel' (in Figure 10 (b)), whereas DenseNet-121 focuses on the 'Door' (in Figure 10 (d)) the most. In summary, we validate that the PCEvE can provide reasonable explanations across multiple models including both CNNs and Transformers."}, {"title": "4.6 Extension to Photo-realistic Fine-grained Visual Categorization", "content": "In this section, we move beyond the human figure drawing assessment tasks. We showcase that our PCEvE framework is also suitable for the photo-realistic Fine-Grained Visual Categorization (FGVC) task. The FGVC is a task where the goal is to classify images into find-grained categories, e.g., 200 different bird species [35]. There are several image datasets [35, 20] for the FGVC task. These datasets share common characteristics: each sample consists of the same composition of parts, e.g., every bird has eyes, a beak, and wings, and a model should be able to pick up the subtle visual differences in specific parts that distinguish one class from others. Therefore, we can validate whether the PCEvE shows reasonable part-based explanations of a model or not on an FGVC dataset. Here, we validate the PCEvE framework on the Stanford Cars [19] dataset."}, {"title": "4.7 Sanity Check Experiments", "content": "In this section, we validate the effectiveness and reliability of the PCEvE by addressing several critical research questions. (1) Does the inclusion or exclusion of the most important part extracted by class-level PCEvE indeed significantly affect the model predictions? (Section 4.7.1) (2) Is there a substantial difference between the feature spaces of the most contributing part images and the"}, {"title": "4.7.1 Class-level Validation: Part Inclusion and Exclusion Experiments", "content": "We empirically validate the reliability of the class-level PCEvE by i) part inclusion and ii) exclusion experiments. In the part inclusion experiment, we evaluate the classification accuracy using inputs containing each part only (with a torso by default), e.g., using eyes only or hair only with a torso by default for the ASD screening task. We expect that using only the most contributing part determined by the PCEvE for the prediction shows the highest performance compared to using any other part only for the prediction. In the part exclusion experiment, we evaluate the classification performance using inputs not containing each part, e.g., not using eyes or hair for the ASD screening task. The expectation is that not using the most contributing part determined by the PCEvE for the prediction shows the lowest performance compared to not using any other part for the prediction.\nIn Figure 13, we show the result of the part inclusion and exclusion experiments conducted across three datasets: the ASD Screening [30] dataset in the first row, the SCAT-Drawing dataset in the second row, and the Stanford Cars [19] dataset in the third row. Each bar plot is sorted in descending order of part contribution value from left to right. In six out of six cases, we observe the classification with the most contributing part determined by the method only shows the highest accuracy: e.g., the inclusion of the \u2018Hair' part results in the female drawing recognition accuracy increases more than 50%p. Conversely, the classification without the most contributing part determined by the method shows the lowest accuracy in five out of six cases, e.g., the exclusion of the 'Face' part causes a substantial drop in TD recognition accuracy by 25%p. The results show a clear trend: the inclusion or exclusion of a most/least contributing part determined by the PCEvE results in a significant accuracy variation. The results validate the effectiveness of our method in identifying key parts of input images in a model decision."}, {"title": "4.7.2 Validation by T-SNE visualization with part features", "content": "Here, we take a closer look at the feature spaces of the most contributing part images and the least contributing part images on three datasets. Utilizing T-SNE [33], we examine the feature vectors for each part in isolation on the ASD Screening [30] dataset in the first row, on the SCAT-Drawing dataset in the second row, and on the Stanford Cars [19] dataset in the third row in Figure 14. We use the task-level PCEvE to select the most and least contributing parts. The visualization shows a clear pattern: the feature spaces of the most contributing part images, presented in Figure 14 (a), (c), and (e), tend to form compact clusters of classes. In contrast, the feature spaces of the least contributing part images, shown in Figure 14 (b), (d), and (f), tend to have more intermingled samples from different classes. The results demonstrate that the PCEvE can effectively identify parts that are crucial for the model decision, as well as the parts that are not crucial for the decision, offering an insightful part-based explanation of a model behavior."}, {"title": "4.7.3 Robustness to Quality of Part Annotations", "content": "In Figure 15, we study the robustness of the PCEvE to the quality of part annotations. On the SCAT-Drawing dataset, we compare two sets of class-level part contribution histograms: (a) the male and female class part contribution histograms generated by the PCEvE using ground-truth part annotations, (b) the male and female class part contribution histograms generated by the PCEVE using predicted annotations from an off-the-shelf part detector, YOLOv86. The histograms from (a) and (b) are quite similar with an average cosine similarity of 0.99. The results indicate that the"}, {"title": "5 Conclusions", "content": "In this paper, we propose the PCEVE, a novel framework for explaining models for human figure drawing (HFD) assessment. The PCEvE explains a model decision by evaluating the contributions of individual parts of an input image based on the Shapley Value. It offers more straightforward part-based explanations than previous pixel-level attribution-based methods, i.e., a part contribution histogram. Our PCEvE framework can also generate class/task-level explanations of a model by aggregating the sample-level results. With the aggregated part-based statistics, we can obtain a more comprehensive understanding of model behavior. Moreover, we move beyond the HFD assessment tasks and apply the PCEvE on a photo-realistic fine-grained visual classification task. We rigorously validate the proposed method via extensive and carefully designed experiments on multiple datasets.\nOur approach relies on part annotations, whether derived from ground-truth annotations or off-the-shelf detectors. Concerns may arise regarding the annotation cost and quality. As a future work, we plan to devise a training methodology enabling the model to automatically discover parts in an unsupervised manner, thereby integrating the part discovery into our evaluation pipeline. Also, leveraging our part-based statistics in conjunction with language models enables the generation of textual descriptions. The combined utilization of visual histograms and textual descriptions could provide users with more detailed and plausible explanations, thereby enhancing the practicality of our approach."}, {"title": "Data availability", "content": "No new data were created or analysed during this study. Data sharing is not applicable to this article. The code and pretrained models will be made publicly available upon acceptance."}]}