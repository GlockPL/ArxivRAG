{"title": "CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications", "authors": ["Mirza Masfiqur Rahman", "Imtiaz Karim", "Elisa Bertino"], "abstract": "In recent years, there has been a growing focus on scrutiniz-ing the security of cellular networks, often attributing security vulnerabilities to issues in the underlying protocol design descriptions. These protocol design specifications, typically extensive documents that are thousands of pages long, can harbor inaccuracies, underspecifications, implicit assumptions, and internal inconsistencies. In light of the evolving landscape, we introduce CellularLint-a semi-automatic framework for inconsistency detection within the standards of 4G and 5G, capitalizing on a suite of natural language processing tech-niques. Our proposed method uses a revamped few-shot learn-ing mechanism on domain-adapted large language models. Pre-trained on a vast corpus of cellular network protocols, this method enables CellularLint to simultaneously detect inconsistencies at various levels of semantics and practical use cases. In doing so, CellularLint significantly advances the automated analysis of protocol specifications in a scalable fashion. In our investigation, we focused on the Non-Access Stratum (NAS) and the security specifications of 4G and 5G networks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After verification of these inconsistencies on 3 open-source implementations and 17 commercial de-vices, we confirm that they indeed have a substantial impact on design decisions, potentially leading to concerns related to privacy, integrity, availability, and interoperability.", "sections": [{"title": "1 Introduction", "content": "Cellular networks have emerged as the primary means of com-munication in the modern world, with 4G and 5G being the latest commercially available versions. Ranging from mobile communications to IoT devices to vehicular communications, cellular networks are a critical infrastructure for the digital world. With more than 1.4 billion subscribers, 5G is expected to exceed its much larger predecessor, 4G, and is forecast to gain more than 13 billion subscribers globally by the end of 2026 [4, 5]. These networks embody large infrastructure and support different features, including backward compatibility, interoperability, and heterogeneity.\nLike any large-scale, complex, layered system, cellular net-work designs are governed by protocol documentation. 3GPP, the 3rd Generation Partnership Project-a consortium of ven-dors, is the supervising body that handles the design and distri-bution of these protocol documents [2]. These documents are quite lengthy, developed by many stakeholders, and improved through releases and change requests over the years. Incorpo-rating these changes and releases subsequently introduces di-verging descriptions. Recently, few studies have shown, albeit through manual analysis during implementation testing, that protocol documents have inconsistent descriptions accounting for differing design possibilities and undefined behaviors in real-world devices, often with severe consequences [37, 53]. Fig. 1 shows an example scenario for diverging sub-state tran-sitions on the same condition, found in the 4G Non-Access-Stratum (NAS) specification. Furthermore, in most cases, one of the inconsistent or conflicting behaviors is less secure than the other. For example, if one design suggests clearing some network identifier(s) after a connection has been lost while the other design suggests keeping it without specifying a clear motivation, the latter can make the user vulnerable to privacy violation attacks. Therefore, these diverging specifications defined in the standards can have severe security and privacy consequences."}, {"title": "Prior Research", "content": "Although prior research works [23-25, 34, 36, 37, 43, 45, 47, 53] have proposed approaches for detecting security and implementation flaws in cellular network proto-cols, they have at least one of the following limitations: (A) They are completely manual [25, 37, 43, 47] and inherently have limited scalability. (B) They employ formal verification [34, 36], foundationally relying on the quality of the prop-erties, and do not primarily deal with inconsistent descriptions-subsequently choosing the most secure option when an in-consistent or confusing situation is encountered. (C) They focus on implementation testing [44, 53] and only report a few inconsistent descriptions on the way without proposing an approach to uncover them. (D) They use differential testing for noncompliance checking [37] without focusing on con-flicting behavior detection in the standards. (E) They either analyze change requests or specifications through NLP tech-niques to understand security hazards [23, 24] without directly considering differing description analysis in specifications."}, {"title": "Problem", "content": "With the current state-of-the-art approaches having above-mentioned limitations, in this paper, we aim to take the first steps to answer the following research question- Is it possible to develop a systematic, generalizable, and scalable specification analysis framework that can identify inconsistent descriptions from 4G and 5G specifications and associate them with differential design choices?"}, {"title": "A promising direction", "content": "Following the major advances in nat-ural language processing (NLP) [19, 60], recent works have demonstrated the automated generation of Finite State Ma-chine from both Request For Comments (RFC) documents and cellular network specifications [39, 52]. Such results in-dicate that a data-driven approach can be taken to discover inconsistencies in specifications as a root cause of design flaws and vulnerabilities as well."}, {"title": "Challenges", "content": "Detecting inconsistent behaviors systematically from the large and complex cellular network specifications using NLP requires tackling some very important research challenges. The first and foremost challenge is to quantize the specification into segments, which we can use for incon-sistency detection. The specifications explain an event in a very large context; in some cases, an event is described in 5-6 pages. With such a large segment, any learning algorithm would fail to capture the finer details and attributes of the segment. Therefore, we need to devise a mechanism to create segments of reasonable size from the specifications. Second, the specifications are so large that in case all the segments are pairwise compared, the search space becomes intractable. For this, we need to devise an approach that reduces the search space substantially. Last, and most importantly, to the best of our knowledge, there are no datasets that could be utilized to detect inconsistent statements in cellular networks. In case there is a large number of inconsistencies that can be manually found, this trivially solves the problem and does not require a systematic framework. Fortunately or rather unfortunately, there are very few manually found conflicts in the specifica-tions that can be used for closed-form solutions that we can use to train. This lack of ground truth creates a major hurdle for any learning-based solution."}, {"title": "Our Approach", "content": "In this paper, we introduce CellularLint-the first framework for uncovering inconsistencies from the upper layer of 4G and 5G specifications. For our method, we employ few-shot domain adaptation of language models.\nTo obtain a scalable solution, we initially cast the docu-ments in sizeable segments based on domain-specific knowl-edge. These quantized segments preserve the context and event, which are essential before understanding inconsisten-cies. Second, based on this quantized pool of intra-document and inter-document test cases/segments, we produce Pairs of Segments (PoS). CellularLint compresses the search space of PoS into a manageable and informative dataset based on interpretable similarity measures. This guides our method to look into only relevant content-making the process highly scalable.\nTo address the lack of labeled examples, instead of heav-ily relying on expert annotations, CellularLint incorporates domain-aware annotations and ensemble decision mecha-nisms and takes only a fraction of labeled examples. We design seven domain-adapted, consistency-wise meaningful labels and map them to general-purpose natural language inference (NLI) annotations. CellularLint also utilizes human-in-the-loop active learning on multiple language models to finalize inconsistent descriptions in varying granularities.\nTo address the lack of supervision, we divide the learning objective into multiple phases- (1) initially converting the learning problem to a generalized setting of NLI and then (2) using multiple phases of active learning on a domain-specific dataset."}, {"title": "Findings", "content": "CellularLint discovered 157 conflicting descrip-tions from specifications. To evaluate the effectiveness of the discoveries, we investigate them on 3 open-source implemen-tations and test them on 17 commercial UEs.\nWe uncover that implementations indeed take different de-sign choices based on conflicting or inconsistent standards. Furthermore, in some cases, we have found that implementa-tions choose the less secure option, and in some cases, tried to implement both options. For ease of discussion, we charac-terize a subset of our findings into four different categories-impacting security enforcement, privacy, interoperability, and causing denial-of-service. In these categories, we discuss a total of 11 issues that can have a severe impact on the privacy, integrity, availability, and interoperability of cellular network infrastructure."}, {"title": "Open-source", "content": "We will completely open-source CellularLint and all the detected inconsistencies to foster research in in-consistency detection in other important protocol specifica-tions [13] 1."}, {"title": "Contributions", "content": "To summarize, we make the following contri-"}, {"title": "2 Background", "content": "In this section, we introduce various preliminaries ranging from the 4G Long Term Evaluation (LTE) and 5G New Radio (NR) architectures to various NLP methods that are relevant to our work."}, {"title": "2.1 Cellular Network Preliminary", "content": "For cellular network preliminaries, here we discuss the most common components that are relevant to this paper."}, {"title": "2.1.1 Cellular Network Architecture", "content": "The network is composed of three main components: the user equipment (UE), the radio access network (RAN), and the core network. The architectural difference between 4G and 5G mostly lies on the RAN and Core Network side.\nUser Equipment (UE). The UE, a terminal device on the user end, is equipped with a Universal Subscriber Identity Mod-ule (USIM). The USIM contains the user identifier, master secret key, and session key for connectivity. These are essen-tial for mutual Authentication and Key Agreement (AKA) between the user and the network. The most common UE are cell phones, tablet computers, and IoT devices with cellular connectivity.\neNodeB. eNodeBs or eNBs are base stations or, most com-monly, mobile network towers in the 4G architecture. They stand as a middle entity in the connection establishment and maintenance for which the Radio Resource Control (RRC) protocol is implemented. eNodeB is replaced by gNodeB in the 5G network. eNodeB is responsible for transmitting and receiving signals to and from UEs.\ngNodeB. The gNodeB or gNB-also called the Next-Generation NodeB-is used in 5G network. It is a significant upgrade from eNodeB. gNodeB supports Massive MIMO technology, has higher throughput, lower latency, and enables advanced network slicing.\n4G-Core The core network in 4G LTE is called Evolved Packet Core (EPC). Two functional components-Mobility Management Entity (MME) and Home Subscriber Server (HSS) are relevant to our paper; hence we briefly discuss them in what follows.\n\u2022 Mobility Management Entity (MME). The MME is re-sponsible for handling signals between the UE and the core, as well as the eNodeB and the core. It is responsible for UE authentication, detach procedure, tracking area updates, etc.\n\u2022 Home Subscriber Server. HSS works as a database to store subscriber information (IMEI and IMSI). It also provides relevant information for calls and IP sessions.\n5G-Core. The 5G Core comprises many functional compo-nents such as the Access and Mobility Management Function (AMF), Session Management Function (SMF), User Plane Function (UPF), Authentication Server Function (AUSF), and so on. 5G leverages a large number of antennas on the core side to enhance signal quality."}, {"title": "2.2 ML Preliminaries", "content": "CellularLint detects inconsistencies from a natural language perspective, meaning that it focuses on the lexical and con-textual analysis of the salient features of the protocol text documents to reveal inconsistencies from protocol specifi-cations. Here, we discuss the NLP preliminaries required for CellularLint."}, {"title": "2.2.1 Few Shot Learning", "content": "Few-Shot Learning (FSL) [19, 30] is a meta-learning approach that utilizes a pre-trained model to generalize over new cate-gories of data using only a few labeled examples per class. For N-way-k-shot learning in NLP, given k labeled examples of each class from N classes for a new NLP task where k is gen-erally very low, the pre-trained model has to learn efficiently to solve the new task."}, {"title": "2.2.2 Active Learning", "content": "Active learning [29, 51], especially human-in-the-loop ac-tive learning, is a machine learning paradigm that focuses on improving learning performance by minimizing the need to label large amounts of data. Often, domain-specific super-vised learning is hindered by the insufficiency of ground truth data. Guiding the model by associating expert annotation with a subset of important data points can largely boost the performance of supervised training."}, {"title": "2.2.3 NLP Methods", "content": "Textual Entailment (TE). Textual entailment, or Natural Language Inference (NLI), is a binary relation where two text sequences can either form an agreement, a contradiction or be completely irrelevant to each other [18, 38]. From a NLP perspective, given two text sequences, where the first is a hypothesis and the second is a premise, the model has to find out whether the first text is in agreement with the second (or vice versa) or is in contradiction or has no logical relation.\nLanguage Modeling. Recent years have seen revolutionary improvements in machine learning on textual data, much of which is due to the use of transformers [27, 48, 60, 62, 64]. Trans-formers are widely used for sequence-to-sequence modeling, semantic parsing, machine translation, question-answering, and most recently for large language models. Transformers rely on the attention mechanism, which excels at learning complex linguistic patterns effectively through the understand-ing of each word's importance and its ability to identify its surrounding words, thereby characterizing the context."}, {"title": "3 Overview", "content": "In this section, we discuss the problem analysis scope and state the problem formally. Next, we discuss the challenges and corresponding approaches."}, {"title": "3.1 Scope of Analysis", "content": "The cellular network protocols (4G and 5G) comprise thou-sands of specifications-from the low layers to the link layer to the upper layers (Layer 3) of the protocols. Among all these specifications and related procedures, we focus on the NAS layer procedures. NAS layer procedures contain the mobility management and session management components, which in turn manage the most critical control plane procedures such as connection setup, initial authentication, mobility, hand-off, and service notifications. Previous works have shown several vulnerabilities in these components, resulting in severe se-curity and privacy issues such as authentication-bypass [44], location exposure [35], impersonation [56], downgrading [40], to name a few. Keeping these in mind, in this work we focus on the NAS layer procedure. More specifically, we focus on four documents in two categories- the NAS technical specifi-cation TS (24.301, v17.6.0) [9] and the Security Architecture and Procedures specification (TS 33.401, v17.1.0) [7] for 4G, and the NAS specification (TS 24.501, v17.7.1) [8] and the Se-curity Architecture and Procedures specification (TS 33.501, v17.5.0) [3] for 5G. All of them are available from the 3GPP archive. Release 17 is the latest complete version to have both NAS and its security specifications. Furthermore, having the same release ensures consistency and removes the possibility of unexpected inconsistency prediction (false positives) in-troduced by version mismatch. In fact, finding cross-version inconsistency is a different task that we leave as future work."}, {"title": "3.2 Problem Formulation", "content": "Here we define the problem formally: given a set of cor-pora $\\mathcal{G} = {C_{NAS}^{4g}, C_{Sec}^{4g}, C_{NAS}^{5g}, C_{Sec}^{5g}} $ (where $C_{NAS}^{4g}$ is the corpus produced from 4G NAS specification, etc), $C_i$ is the corpus pro-duced from 4G security architecture specification, similar notations are applicable for 5G), we need to quantize each corpus in text segments, that is, $C_i = {t_1, t_2,...,t_n}_i$ where $t_a$ describes a-th meaningful event/sub-event/directive from corpus $G$. Now our first objective is to construct interme-diate sets, $S_1 = (C_{NAS}^{4g} \\times C_{Sec}^{4g}) \\cup (C_{Sec}^{4g} \\times C_{Sec}^{4g}) \\cup (C_{NAS}^{4g} \\times C_{NAS}^{4g})$ and $S_2 = (C_{NAS}^{5g} \\times C_{Sec}^{5g}) \\cup (C_{Sec}^{5g} \\times C_{Sec}^{5g}) \\cup (C_{NAS}^{5g} \\times C_{NAS}^{5g})$. Next, from each intermediate set $S_m \\in {S_1, S_2}$ containing tuples or pairs $(t_a, t_b)$ of text Segments (PoS), our objective is to devise a model $M$ which can determine all pairs that conflict between each other, that is, $M(t_a, t_b) = k$. Here, k takes the value consistent or inconsistent."}, {"title": "3.3 Challenges & Solution Outline", "content": "We now discuss the main challenges and corresponding ap-proaches that have driven the CellularLint's high-level design choices. We then present the key steps in our overall solution.\n(C1) Segment quantization. In numerous scenarios, the spec-ifications explain an event in a vast context. For example, in the 4G NAS specification, Section 5.5.1.2.4 describes \"Attach accepted by the network\", which is a six-page long descrip-tion concerning one major event where the network accepts an attach request from the UE. If we consider this whole event as one complete and discrete, meaningful segment, any learning algorithm will fail to capture the intricate details and attributes, causing differential and anomalous behaviors. Moreover, in the same section, there is a precondition \"If the UE indicates support for EMM-REGISTERED without PDN connection\", which shall trigger an event on the MME side. A similar precondition is found for tracking_are_update_request message further away in the document. If the whole section is considered as a potential segment, one would not be able to match such sub-event triggers and may miss numerous possible interesting scenarios. An alternative choice can be selecting each sentence as an atomic unit governing a seg-ment. However, this leads to a serious problem because, often, a single sentence from the specification is not sufficient to infer all the entities, states, or messages involved in a pro-cess. Also, due to the semi-structured nature of specifications, many sentences are repeated in different parts of the specifica-tions. Thus, considering each sentence a meaningful segment would produce too many repeating units in the dataset, and if needed, it would be impossible to map back uniquely to the specification. Thus, this trivial solution is not applicable to our case.\n(A1) Sub-event driven segment quantization. As we have already established that considering a whole event as a segment likely affects the effectiveness and purpose of detected inconsistencies, we quantize such larger descriptions into smaller segments. However, in doing so, we preserve the completeness of the description of sub-events. We combine domain-specific understanding with standard NLP techniques to pinpoint sub-events. Specifically, we consider subsections and complete paragraphs as atomic units while constraining the sequence length and entity based on Parts-Of-Speech filtering. Details about the approach for segment quantization are given in \u00a74.2.\n(C2) Intractable search space. The protocol specifications are large documents defining and explaining all entities, events, state transitions, message structures, and so on in finer detail. Moreover, when we execute segment quantization to address C1, the resulting quantized dataset is even larger. Thus, traversing and matching texts directly using the en-tire dataset of quantized segments makes the finalized search space intractable with millions of potential segment pairs. For example, after the segment quantization, the brute-force traverse and match solution gives us more than 12 million segment pairs for 5G-NAS specification alone. On top of that, to find inconsistencies, one may have to consider multiple related specifications rather than generating segments from just one. For instance, in our case, for 5G we consider the 5G NAS technical specifications and the security architecture and procedures specification. This, in turn, makes the search space tremendously larger and thereby causes a state-space explosion.\n(A2) Finite segment filtration. To address C2, we reduce the segment sequence pair space by filtering the initial dataset based on similarity measures. The intuition behind this idea is that two completely different segments should not be consid-ered inconsistent as they talk about totally different aspects of the protocol. Contrary to this, an inconsistent PoS would have at least the same pre-condition and hence would have a better similarity score. To achieve such a quantitative measure of texts, we first consider the vector embedding of texts. How-ever, we observe that choosing an arbitrary embedding can severely affect the search space shrinkage and effectiveness of similarity scoring. We have thus carried out an extensive evaluation to determine the most reliable text vectorization technique for our problem. The details of the evaluation are discussed in \u00a76.1. Thus we reduce the number of segments from millions to a few thousand-reducing the problem space to a tractable size.\n(C3) Absence of ground truth. To the best of our knowledge, there are no datasets that could be utilized for NLP-based ma-chine learning to detect conflicting statements from cellular protocols. Even if a processed, readily usable dataset existed, no closed-form solution would be able to trivially map text segments from multiple documents to specific inconsistencies. This is a novel problem-solving which is a key contribution of our work. Moreover, although state-of-the-art language models are very effective in learning contexts, they require a massive amount of labeled data due to the larger parameter landscape. Acquiring such a domain-specific dataset is often cumbersome and for this problem setup, even harder. Thus we have to design a technique that can work with only a handful of labeled examples.\n(A3) Ground truth generation. We employ multi-phase su-pervision through human-in-the-loop active learning to sub-due the insufficiency of ground truth. Our learning method neither requires a large amount of annotation nor suffers from too much uncertainty introduced by insufficient learning. In short, we first establish the learning landscape using a general-purpose dataset with some supervised data. Note that this general-purpose dataset is not from the cellular network do-main but rather from image-crowdsourced caption writing and is publicly available. This intermediary model is utilized in consensus with human involvement alongside minimal syn-thesized data repeatedly to prepare the finalized model. The whole process never requires the complete ground truth of our problem. In fact, having a complete ground truth from the beginning is fundamentally contradictory here, as it would trivially solve the problem we have at hand. Indeed, if there were already a large number of inconsistent descriptions in specifications, then those could be directly reported to im-prove the protocol and would not require any additional anal-ysis. Likewise, the lack of ground truth makes the problem both challenging and rewarding to some extent."}, {"title": "3.4 Approach Skeleton", "content": "Based on our discussion of challenges and approaches to the solution, we divide the inconsistency detection problem into multiple steps: (i) We employ domain-specific prepro-cessing alongside standard NLP techniques to quantize each G\u2208 G. (ii) To produce each $S_m$, we utilize an syntactic and contextual equivalence metric $\\gamma$ to filter out irrelevant PoS. (iii) To address the absence of labeled examples, we use $M'$ instead of $M$ which first learns from a general dataset P to solve textual entailment task. In this task, for any two text sequences $t_x, t_y \\in P$, $M'$ learns if $t_y$ entails $t_x$ or not. Formally, $M'(t_x, t_y) = k'$ where $k'$ takes the value of either entailment or contradiction or irrelevance (often called neutral). Subsequently we use $M'$ with few domain-specific labeled data to generate our specialized model $M$ with the learning objective of $M(t_a, t_b) = k'$, where $t_a, t_b \\in S_m$."}, {"title": "4 Detailed Design", "content": "In this section, we discuss CellularLint in detail. Fig. 2 shows the main components of our framework."}, {"title": "4.1 Architecture", "content": "The overall framework is organized into two parts:the Learner, and 2 the Dispatcher. Each of them has multiple submodules shown in Figure 2.\nLearner. The learner consists of five sub-modules.\n1A The first is preprocessing, which performs standard NLP preprocessing as well as domain-specific and task-specific preprocessing of all cellular network protocol specifications from the 3GPP archive. This generates a large corpus for our pre-training step. Here, a second-order preprocessing is also executed on the documents of our problem scope (NAS and Security of 4G and 5G), which produces the sub-event-oriented, context-preserving text segments. We call them context-preserving as when extracting them, our method makes sure that they do not describe multiple sections and the segments are not trimmed off halfway through an event description. For example, if a section is short and within our token limit (such as 5.3.10 in TS 24.301), we keep it as one segment. Alternatively, if a section contains multiple para-graphs (such as 5.5.3.2.3 from TS 24.301), each describing an independent event (they might be related when taken in a very large context), we consider each paragraph as a different segment. Details of the module can be found in \u00a74.2.\n1B The second sub-module is the pre-trainer. In this sub-module, we utilize the large corpus generated from the pre-processing module. This ensures that the model understands the domain with specific vocabularies and semantics. The detailed experimental setup is discussed in \u00a75. In parallel to the training, we create embedding vectors for each segment. The embedding vectors are utilized for pairing and filtration of PoSs in the next sub-module.\n1C In the third sub-module, we execute the uninformed fine-tuning. This is an important step for weak supervision and our first concrete endeavor toward task-specific learning. In short, we first fine-tune our candidate transformer models separately on the well-known Stanford Natural Language Inference (SNLI) corpus [18]. We call it uninformed supervi-sion because the SNLI corpus contains examples that are not completely in accordance with our definition of consistency from a protocol perspective. For example, \"A group of people are ice skating in a big city.\" and \"The people are outside skat-ing.\" are labeled as entailments in that corpus. Apparently, the second sequence is a vague representation of the first, i.e., a large and significant part of the first sequence is not expressed through the second sequence. Moreover, our main objective is to capture the protocol inconsistencies based on complex text patterns and intricate details of various cellular events for which fine-tuning on SNLI corpus is not solely sufficient. Thus, training on the SNLI corpus only gives us a loose es-timate of our objective model. Nonetheless, this uninformed supervision is the first stepping stone in our analysis. In paral-lel, we complete the segment pairing and filtration based on the embedding vectors generated in the previous step. In short, we create all possible pairs of the segment vectors and filter them based on a similarity measure. Details of the method can be found in \u00a74.3\n1D At the fourth sub-module, we combine the predictions of k models on our dataset. Note that these k models are now fine-tuned on SNLI corpus from the previous step. It is known that different models have the ability to capture different semantics in varying capabilities. Therefore, combining their predictions through majority voting allows us to boost the prediction confidence. However, these models have not learned what consistency means from the perspective of cellular networks. Therefore, these predictions are not completely reliable as final output.\n1E The most important sub-module for the learner is the multi-phase informed fine-tuning, which is the fifth and most crucial step. Here, we first take the ensemble prediction from the previous sub-module. Next, we sample a small subset of data from the predicted set, then validate and rectify the la-bels through domain-expert human annotators. This approach ensures ground truth addition while keeping the human in-volvement minimal. Also, rectifying annotations instead of annotating from scratch reduces the human effort even more. The models are again trained on the reconditioned examples in a supervised manner and used subsequently for predictions, again on the whole dataset. In such a manner, we complete one phase of training. This method is followed k times (each defining a phase) before finalizing the prediction. Details on the experimental choices of this step can be found in \u00a75.\nDispatcher. We take the high-confidence predictions as our results after multi-phase informed training and manually an-alyze them. To further show the impact of the inconsistent behaviors of the specifications, we use the dispatcher. The dispatcher has two sub-modules.\n2A In the first one, we map the discovered inconsistent descriptions to the open-source implementations-srsRAN, open5GS, and OpenAirInterface [10-12]. Note that many boundary cases and uncommon events are not available (or available in non-granularity) in the open-source implementa-tions. Even so, the predicted inconsistent sets are checked against these multiple sources to determine their design choices and security implications. Consequently, we create a subset of inconsistencies for the next sub-module.\n2B In the second sub-module of the dispatcher, we consider each of the inconsistencies gathered from the previous step to determine whether they cause issues in real-world devices. Details of the setup can be found on our website [13]."}, {"title": "4.2 Dataset Preparation", "content": "It has been shown that pre-training Large Language Models (LLM) can help understand domain-specific terminologies better than LLMs with no domain-specific pre-training (i.e., only pre-trained on general datasets such as Wikipedia cor-pus) [19, 21, 31, 54]. We first process the raw specifications from the 3GPP archive and pre-train language models on it to leverage the domain-specific learning in an enhanced capability. Our textual entailment task is a harness over the aforementioned pre-trained model. The details of the dataset preparation are discussed in what follows.\nWe remove the tables, figures, cross-document references, code segments, and additional ill-formed texts from the spec-ifications to create the pre-training corpora. For the down-stream fine-tuning, since we need semantically meaningful segments of texts to compare, we first extract section-wise texts. The sections usually comprise of many sub-descriptions based on cause values. Otherwise, each paragraph in a section is usually self-contained. Also, to conform to the sequence length limit of our candidate transformer models, we some-times do finer fragmentation. In this case, sections 4 to 8 are considered for NAS in both 4G and 5G as the rest of the sections mostly contain definitions, abbreviations, glossary, scope, etc. For security, we consider section 4 to the annex for both 4G and 5G."}, {"title": "4.3 Pairing & Filtration", "content": "As discussed earlier, comparing all segments with each other for inconsistency will result in a massive search space, quan-titatively, $\\binom{N}{2}$ datapoints where N is the total number of extracted segments. To overcome this, first, we use the Term Frequency- Inverse Document Frequency (TF-IDF) to vectorize such segments (submodule 1B in Figure 2). To answer why TF-IDF is effective here, we compare five different embedding techniques-Sentence BERT (SBERT), Doc2Vec, Universal Sentence Encoder (USE), Word2Vec, and TF-IDF [20, 46, 50, 55, 59]. Among them, TF-IDF appears to be most effective (see details in \u00a76.1).\nConsidering each segment to be a document, formally for a term t found in a document d \u2208 D:\n$tf(t, d) = \\frac{f_{t, d}}{\\sum_{t' \\in d} f_{t', d}}$\n$idf(t, D) = -log P(t | D) = log \\frac{n}{\\sum 1(d \\in D: t \\in d)}$\n$t fid f(t, d, D) = tf(t, d) \\cdot id f(t, D)$"}, {"content": "Here $f_{t,d}$ denotes the raw frequency of term t in document d. In our problem, d represents a text segment, and D rep-resents the corpus. TF-IDF maps the text segments d in a k-dimensional latent space X-\n$\\mathbb{X}: S \\ni d \\rightarrow \\mathbb{X} \\in \\mathbb{S}$\nIn the next step, we use the cosine similarity score (\u03c8) to measure the similarity between each pair of TF-IDF vectors. For each vector $x_1$ and $x_2$:\n$\\Psi(x_1, x_2) = \\frac{x_1 \\cdot x_2}{||x_1|| ||x_2||} = \\frac{\\sum_{i=1}^{k} x_{1 i} x_{2 i}}{\\sqrt{\\sum_{i=1}^{k} x_{1 i}^{2}} \\sqrt{\\sum_{i=1}^{k} x_{2 i}^{2}}}$\nWe generate the symmetric matrix of all pair similarity scores. Now, from this symmetric matrix (Figure 3), we take the lower triangular half and remove the datapoints that have \u03c8 < \u03a8min and \u03c8 > \u03a8max. We consider the following cases when choosing values for \u03c8min and \u03c8max:\n\u2022 When \u03c8min is too small, the segments are essentially de-scribing two totally different events with a few words matched in the protocol specification. For a refined dataset, \u03c8min should be kept relatively high.\n\u2022 Using a \u03c8max helps to filter out segments where two text segments have very small changes in vocabularies, i.e., synonymous words or changes of articles (\"a\" instead of \"the\", pronouns instead of proper noun phrases, etc.). These segment pairs state the same event with (almost) exact description."}, {"title": "4.4 Protocol Language Entailment Annotation", "content": "We now discuss the hierarchical annotations of our dataset. The key challenge in finding inconsistencies in 4G/5G proto-cols is that there are no ground truth labels for model training. Thus"}, {"title": "CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications", "authors": ["Mirza Masfiqur Rahman", "Imtiaz Karim", "Elisa Bertino"], "abstract": "In recent years, there has been a growing focus on scrutinizing the security of cellular networks, often attributing security vulnerabilities to issues in the underlying protocol design descriptions. These protocol design specifications, typically extensive documents that are thousands of pages long, can harbor inaccuracies, underspecifications, implicit assumptions, and internal inconsistencies. In light of the evolving landscape, we introduce CellularLint-a semi-automatic framework for inconsistency detection within the standards of 4G and 5G, capitalizing on a suite of natural language processing techniques. Our proposed method uses a revamped few-shot learning mechanism on domain-adapted large language models. Pre-trained on a vast corpus of cellular network protocols, this method enables CellularLint to simultaneously detect inconsistencies at various levels of semantics and practical use cases. In doing so, CellularLint significantly advances the automated analysis of protocol specifications in a scalable fashion. In our investigation, we focused on the Non-Access Stratum (NAS) and the security specifications of 4G and 5G networks, ultimately uncovering 157 inconsistencies with 82.67% accuracy. After verification of these inconsistencies on 3 open-source implementations and 17 commercial devices, we confirm that they indeed have a substantial impact on design decisions, potentially leading to concerns related to privacy, integrity, availability, and interoperability.", "sections": [{"title": "1 Introduction", "content": "Cellular networks have emerged as the primary means of communication in the modern world, with 4G and 5G being the latest commercially available versions. Ranging from mobile communications to IoT devices to vehicular communications, cellular networks are a critical infrastructure for the digital world. With more than 1.4 billion subscribers, 5G is expected to exceed its much larger predecessor, 4G, and is forecast to gain more than 13 billion subscribers globally by the end of 2026 [4, 5]. These networks embody large infrastructure and support different features, including backward compatibility, interoperability, and heterogeneity.\nLike any large-scale, complex, layered system, cellular network designs are governed by protocol documentation. 3GPP, the 3rd Generation Partnership Project-a consortium of vendors, is the supervising body that handles the design and distribution of these protocol documents [2]. These documents are quite lengthy, developed by many stakeholders, and improved through releases and change requests over the years. Incorporating these changes and releases subsequently introduces diverging descriptions. Recently, few studies have shown, albeit through manual analysis during implementation testing, that protocol documents have inconsistent descriptions accounting for differing design possibilities and undefined behaviors in real-world devices, often with severe consequences [37, 53]. Fig. 1 shows an example scenario for diverging sub-state transitions on the same condition, found in the 4G Non-Access-Stratum (NAS) specification. Furthermore, in most cases, one of the inconsistent or conflicting behaviors is less secure than the other. For example, if one design suggests clearing some network identifier(s) after a connection has been lost while the other design suggests keeping it without specifying a clear motivation, the latter can make the user vulnerable to privacy violation attacks. Therefore, these diverging specifications defined in the standards can have severe security and privacy consequences."}, {"title": "Prior Research", "content": "Although prior research works [23-25, 34, 36, 37, 43, 45, 47, 53] have proposed approaches for detecting security and implementation flaws in cellular network protocols, they have at least one of the following limitations: (A) They are completely manual [25, 37, 43, 47] and inherently have limited scalability. (B) They employ formal verification [34, 36], foundationally relying on the quality of the properties, and do not primarily deal with inconsistent descriptions-subsequently choosing the most secure option when an inconsistent or confusing situation is encountered. (C) They focus on implementation testing [44, 53] and only report a few inconsistent descriptions on the way without proposing an approach to uncover them. (D) They use differential testing for noncompliance checking [37] without focusing on conflicting behavior detection in the standards. (E) They either analyze change requests or specifications through NLP techniques to understand security hazards [23, 24] without directly considering differing description analysis in specifications."}, {"title": "Problem", "content": "With the current state-of-the-art approaches having above-mentioned limitations, in this paper, we aim to take the first steps to answer the following research question- Is it possible to develop a systematic, generalizable, and scalable specification analysis framework that can identify inconsistent descriptions from 4G and 5G specifications and associate them with differential design choices?"}, {"title": "A promising direction", "content": "Following the major advances in natural language processing (NLP) [19, 60], recent works have demonstrated the automated generation of Finite State Machine from both Request For Comments (RFC) documents and cellular network specifications [39, 52]. Such results indicate that a data-driven approach can be taken to discover inconsistencies in specifications as a root cause of design flaws and vulnerabilities as well."}, {"title": "Challenges", "content": "Detecting inconsistent behaviors systematically from the large and complex cellular network specifications using NLP requires tackling some very important research challenges. The first and foremost challenge is to quantize the specification into segments, which we can use for inconsistency detection. The specifications explain an event in a very large context; in some cases, an event is described in 5-6 pages. With such a large segment, any learning algorithm would fail to capture the finer details and attributes of the segment. Therefore, we need to devise a mechanism to create segments of reasonable size from the specifications. Second, the specifications are so large that in case all the segments are pairwise compared, the search space becomes intractable. For this, we need to devise an approach that reduces the search space substantially. Last, and most importantly, to the best of our knowledge, there are no datasets that could be utilized to detect inconsistent statements in cellular networks. In case there is a large number of inconsistencies that can be manually found, this trivially solves the problem and does not require a systematic framework. Fortunately or rather unfortunately, there are very few manually found conflicts in the specifications that can be used for closed-form solutions that we can use to train. This lack of ground truth creates a major hurdle for any learning-based solution."}, {"title": "Our Approach", "content": "In this paper, we introduce CellularLint-the first framework for uncovering inconsistencies from the upper layer of 4G and 5G specifications. For our method, we employ few-shot domain adaptation of language models.\nTo obtain a scalable solution, we initially cast the documents in sizeable segments based on domain-specific knowledge. These quantized segments preserve the context and event, which are essential before understanding inconsistencies. Second, based on this quantized pool of intra-document and inter-document test cases/segments, we produce Pairs of Segments (PoS). CellularLint compresses the search space of PoS into a manageable and informative dataset based on interpretable similarity measures. This guides our method to look into only relevant content-making the process highly scalable.\nTo address the lack of labeled examples, instead of heavily relying on expert annotations, CellularLint incorporates domain-aware annotations and ensemble decision mechanisms and takes only a fraction of labeled examples. We design seven domain-adapted, consistency-wise meaningful labels and map them to general-purpose natural language inference (NLI) annotations. CellularLint also utilizes human-in-the-loop active learning on multiple language models to finalize inconsistent descriptions in varying granularities.\nTo address the lack of supervision, we divide the learning objective into multiple phases- (1) initially converting the learning problem to a generalized setting of NLI and then (2) using multiple phases of active learning on a domain-specific dataset."}, {"title": "Findings", "content": "CellularLint discovered 157 conflicting descriptions from specifications. To evaluate the effectiveness of the discoveries, we investigate them on 3 open-source implementations and test them on 17 commercial UEs.\nWe uncover that implementations indeed take different design choices based on conflicting or inconsistent standards. Furthermore, in some cases, we have found that implementations choose the less secure option, and in some cases, tried to implement both options. For ease of discussion, we characterize a subset of our findings into four different categories-impacting security enforcement, privacy, interoperability, and causing denial-of-service. In these categories, we discuss a total of 11 issues that can have a severe impact on the privacy, integrity, availability, and interoperability of cellular network infrastructure."}, {"title": "Open-source", "content": "We will completely open-source CellularLint and all the detected inconsistencies to foster research in inconsistency detection in other important protocol specifications [13] 1."}, {"title": "Contributions", "content": "To summarize, we make the following contri-"}, {"title": "2 Background", "content": "In this section, we introduce various preliminaries ranging from the 4G Long Term Evaluation (LTE) and 5G New Radio (NR) architectures to various NLP methods that are relevant to our work."}, {"title": "2.1 Cellular Network Preliminary", "content": "For cellular network preliminaries, here we discuss the most common components that are relevant to this paper."}, {"title": "2.1.1 Cellular Network Architecture", "content": "The network is composed of three main components: the user equipment (UE), the radio access network (RAN), and the core network. The architectural difference between 4G and 5G mostly lies on the RAN and Core Network side.\nUser Equipment (UE). The UE, a terminal device on the user end, is equipped with a Universal Subscriber Identity Module (USIM). The USIM contains the user identifier, master secret key, and session key for connectivity. These are essential for mutual Authentication and Key Agreement (AKA) between the user and the network. The most common UE are cell phones, tablet computers, and IoT devices with cellular connectivity.\neNodeB. eNodeBs or eNBs are base stations or, most commonly, mobile network towers in the 4G architecture. They stand as a middle entity in the connection establishment and maintenance for which the Radio Resource Control (RRC) protocol is implemented. eNodeB is replaced by gNodeB in the 5G network. eNodeB is responsible for transmitting and receiving signals to and from UEs.\ngNodeB. The gNodeB or gNB-also called the Next-Generation NodeB-is used in 5G network. It is a significant upgrade from eNodeB. gNodeB supports Massive MIMO technology, has higher throughput, lower latency, and enables advanced network slicing.\n4G-Core The core network in 4G LTE is called Evolved Packet Core (EPC). Two functional components-Mobility Management Entity (MME) and Home Subscriber Server (HSS) are relevant to our paper; hence we briefly discuss them in what follows.\n\u2022 Mobility Management Entity (MME). The MME is responsible for handling signals between the UE and the core, as well as the eNodeB and the core. It is responsible for UE authentication, detach procedure, tracking area updates, etc.\n\u2022 Home Subscriber Server. HSS works as a database to store subscriber information (IMEI and IMSI). It also provides relevant information for calls and IP sessions.\n5G-Core. The 5G Core comprises many functional components such as the Access and Mobility Management Function (AMF), Session Management Function (SMF), User Plane Function (UPF), Authentication Server Function (AUSF), and so on. 5G leverages a large number of antennas on the core side to enhance signal quality."}, {"title": "2.2 ML Preliminaries", "content": "CellularLint detects inconsistencies from a natural language perspective, meaning that it focuses on the lexical and contextual analysis of the salient features of the protocol text documents to reveal inconsistencies from protocol specifications. Here, we discuss the NLP preliminaries required for CellularLint."}, {"title": "2.2.1 Few Shot Learning", "content": "Few-Shot Learning (FSL) [19, 30] is a meta-learning approach that utilizes a pre-trained model to generalize over new categories of data using only a few labeled examples per class. For N-way-k-shot learning in NLP, given k labeled examples of each class from N classes for a new NLP task where k is generally very low, the pre-trained model has to learn efficiently to solve the new task."}, {"title": "2.2.2 Active Learning", "content": "Active learning [29, 51], especially human-in-the-loop active learning, is a machine learning paradigm that focuses on improving learning performance by minimizing the need to label large amounts of data. Often, domain-specific supervised learning is hindered by the insufficiency of ground truth data. Guiding the model by associating expert annotation with a subset of important data points can largely boost the performance of supervised training."}, {"title": "2.2.3 NLP Methods", "content": "Textual Entailment (TE). Textual entailment, or Natural Language Inference (NLI), is a binary relation where two text sequences can either form an agreement, a contradiction or be completely irrelevant to each other [18, 38]. From a NLP perspective, given two text sequences, where the first is a hypothesis and the second is a premise, the model has to find out whether the first text is in agreement with the second (or vice versa) or is in contradiction or has no logical relation.\nLanguage Modeling. Recent years have seen revolutionary improvements in machine learning on textual data, much of which is due to the use of transformers [27, 48, 60, 62, 64]. Transformers are widely used for sequence-to-sequence modeling, semantic parsing, machine translation, question-answering, and most recently for large language models. Transformers rely on the attention mechanism, which excels at learning complex linguistic patterns effectively through the understanding of each word's importance and its ability to identify its surrounding words, thereby characterizing the context."}, {"title": "3 Overview", "content": "In this section, we discuss the problem analysis scope and state the problem formally. Next, we discuss the challenges and corresponding approaches."}, {"title": "3.1 Scope of Analysis", "content": "The cellular network protocols (4G and 5G) comprise thousands of specifications-from the low layers to the link layer to the upper layers (Layer 3) of the protocols. Among all these specifications and related procedures, we focus on the NAS layer procedures. NAS layer procedures contain the mobility management and session management components, which in turn manage the most critical control plane procedures such as connection setup, initial authentication, mobility, hand-off, and service notifications. Previous works have shown several vulnerabilities in these components, resulting in severe security and privacy issues such as authentication-bypass [44], location exposure [35], impersonation [56], downgrading [40], to name a few. Keeping these in mind, in this work we focus on the NAS layer procedure. More specifically, we focus on four documents in two categories- the NAS technical specification TS (24.301, v17.6.0) [9] and the Security Architecture and Procedures specification (TS 33.401, v17.1.0) [7] for 4G, and the NAS specification (TS 24.501, v17.7.1) [8] and the Security Architecture and Procedures specification (TS 33.501, v17.5.0) [3] for 5G. All of them are available from the 3GPP archive. Release 17 is the latest complete version to have both NAS and its security specifications. Furthermore, having the same release ensures consistency and removes the possibility of unexpected inconsistency prediction (false positives) introduced by version mismatch. In fact, finding cross-version inconsistency is a different task that we leave as future work."}, {"title": "3.2 Problem Formulation", "content": "Here we define the problem formally: given a set of corpora $\\mathcal{G} = \\{C_{NAS}^{4g}, C_{Sec}^{4g}, C_{NAS}^{5g}, C_{Sec}^{5g}\\} $ (where $C_{NAS}^{4g}$ is the corpus produced from 4G NAS specification, etc), $C_i$ is the corpus produced from 4G security architecture specification, similar notations are applicable for 5G), we need to quantize each corpus in text segments, that is, $C_i = \\{t_1, t_2,...,t_n\\}_i$ where $t_a$ describes a-th meaningful event/sub-event/directive from corpus $G$. Now our first objective is to construct intermediate sets, $S_1 = (C_{NAS}^{4g} \\times C_{Sec}^{4g}) \\cup (C_{Sec}^{4g} \\times C_{Sec}^{4g}) \\cup (C_{NAS}^{4g} \\times C_{NAS}^{4g})$ and $S_2 = (C_{NAS}^{5g} \\times C_{Sec}^{5g}) \\cup (C_{Sec}^{5g} \\times C_{Sec}^{5g}) \\cup (C_{NAS}^{5g} \\times C_{NAS}^{5g})$. Next, from each intermediate set $S_m \\in \\{S_1, S_2\\}$ containing tuples or pairs $(t_a, t_b)$ of text Segments (PoS), our objective is to devise a model $M$ which can determine all pairs that conflict between each other, that is, $M(t_a, t_b) = k$. Here, k takes the value consistent or inconsistent."}, {"title": "3.3 Challenges & Solution Outline", "content": "We now discuss the main challenges and corresponding approaches that have driven the CellularLint's high-level design choices. We then present the key steps in our overall solution.\n(C1) Segment quantization. In numerous scenarios, the specifications explain an event in a vast context. For example, in the 4G NAS specification, Section 5.5.1.2.4 describes \"Attach accepted by the network\", which is a six-page long description concerning one major event where the network accepts an attach request from the UE. If we consider this whole event as one complete and discrete, meaningful segment, any learning algorithm will fail to capture the intricate details and attributes, causing differential and anomalous behaviors. Moreover, in the same section, there is a precondition \"If the UE indicates support for EMM-REGISTERED without PDN connection\", which shall trigger an event on the MME side. A similar precondition is found for tracking_are_update_request message further away in the document. If the whole section is considered as a potential segment, one would not be able to match such sub-event triggers and may miss numerous possible interesting scenarios. An alternative choice can be selecting each sentence as an atomic unit governing a segment. However, this leads to a serious problem because, often, a single sentence from the specification is not sufficient to infer all the entities, states, or messages involved in a process. Also, due to the semi-structured nature of specifications, many sentences are repeated in different parts of the specifications. Thus, considering each sentence a meaningful segment would produce too many repeating units in the dataset, and if needed, it would be impossible to map back uniquely to the specification. Thus, this trivial solution is not applicable to our case.\n(A1) Sub-event driven segment quantization. As we have already established that considering a whole event as a segment likely affects the effectiveness and purpose of detected inconsistencies, we quantize such larger descriptions into smaller segments. However, in doing so, we preserve the completeness of the description of sub-events. We combine domain-specific understanding with standard NLP techniques to pinpoint sub-events. Specifically, we consider subsections and complete paragraphs as atomic units while constraining the sequence length and entity based on Parts-Of-Speech filtering. Details about the approach for segment quantization are given in \u00a74.2.\n(C2) Intractable search space. The protocol specifications are large documents defining and explaining all entities, events, state transitions, message structures, and so on in finer detail. Moreover, when we execute segment quantization to address C1, the resulting quantized dataset is even larger. Thus, traversing and matching texts directly using the entire dataset of quantized segments makes the finalized search space intractable with millions of potential segment pairs. For example, after the segment quantization, the brute-force traverse and match solution gives us more than 12 million segment pairs for 5G-NAS specification alone. On top of that, to find inconsistencies, one may have to consider multiple related specifications rather than generating segments from just one. For instance, in our case, for 5G we consider the 5G NAS technical specifications and the security architecture and procedures specification. This, in turn, makes the search space tremendously larger and thereby causes a state-space explosion.\n(A2) Finite segment filtration. To address C2, we reduce the segment sequence pair space by filtering the initial dataset based on similarity measures. The intuition behind this idea is that two completely different segments should not be considered inconsistent as they talk about totally different aspects of the protocol. Contrary to this, an inconsistent PoS would have at least the same pre-condition and hence would have a better similarity score. To achieve such a quantitative measure of texts, we first consider the vector embedding of texts. However, we observe that choosing an arbitrary embedding can severely affect the search space shrinkage and effectiveness of similarity scoring. We have thus carried out an extensive evaluation to determine the most reliable text vectorization technique for our problem. The details of the evaluation are discussed in \u00a76.1. Thus we reduce the number of segments from millions to a few thousand-reducing the problem space to a tractable size.\n(C3) Absence of ground truth. To the best of our knowledge, there are no datasets that could be utilized for NLP-based machine learning to detect conflicting statements from cellular protocols. Even if a processed, readily usable dataset existed, no closed-form solution would be able to trivially map text segments from multiple documents to specific inconsistencies. This is a novel problem-solving which is a key contribution of our work. Moreover, although state-of-the-art language models are very effective in learning contexts, they require a massive amount of labeled data due to the larger parameter landscape. Acquiring such a domain-specific dataset is often cumbersome and for this problem setup, even harder. Thus we have to design a technique that can work with only a handful of labeled examples.\n(A3) Ground truth generation. We employ multi-phase supervision through human-in-the-loop active learning to subdue the insufficiency of ground truth. Our learning method neither requires a large amount of annotation nor suffers from too much uncertainty introduced by insufficient learning. In short, we first establish the learning landscape using a general-purpose dataset with some supervised data. Note that this general-purpose dataset is not from the cellular network domain but rather from image-crowdsourced caption writing and is publicly available. This intermediary model is utilized in consensus with human involvement alongside minimal synthesized data repeatedly to prepare the finalized model. The whole process never requires the complete ground truth of our problem. In fact, having a complete ground truth from the beginning is fundamentally contradictory here, as it would trivially solve the problem we have at hand. Indeed, if there were already a large number of inconsistent descriptions in specifications, then those could be directly reported to improve the protocol and would not require any additional analysis. Likewise, the lack of ground truth makes the problem both challenging and rewarding to some extent."}, {"title": "3.4 Approach Skeleton", "content": "Based on our discussion of challenges and approaches to the solution, we divide the inconsistency detection problem into multiple steps: (i) We employ domain-specific preprocessing alongside standard NLP techniques to quantize each G\u2208 G. (ii) To produce each $S_m$, we utilize an syntactic and contextual equivalence metric $\\gamma$ to filter out irrelevant PoS. (iii) To address the absence of labeled examples, we use $M'$ instead of $M$ which first learns from a general dataset P to solve textual entailment task. In this task, for any two text sequences $t_x, t_y \\in P$, $M'$ learns if $t_y$ entails $t_x$ or not. Formally, $M'(t_x, t_y) = k'$ where $k'$ takes the value of either entailment or contradiction or irrelevance (often called neutral). Subsequently we use $M'$ with few domain-specific labeled data to generate our specialized model $M$ with the learning objective of $M(t_a, t_b) = k'$, where $t_a, t_b \\in S_m$."}, {"title": "4 Detailed Design", "content": "In this section, we discuss CellularLint in detail. Fig. 2 shows the main components of our framework."}, {"title": "4.1 Architecture", "content": "The overall framework is organized into two parts:the Learner, and 2 the Dispatcher. Each of them has multiple submodules shown in Figure 2.\nLearner. The learner consists of five sub-modules.\n1A The first is preprocessing, which performs standard NLP preprocessing as well as domain-specific and task-specific preprocessing of all cellular network protocol specifications from the 3GPP archive. This generates a large corpus for our pre-training step. Here, a second-order preprocessing is also executed on the documents of our problem scope (NAS and Security of 4G and 5G), which produces the sub-event-oriented, context-preserving text segments. We call them context-preserving as when extracting them, our method makes sure that they do not describe multiple sections and the segments are not trimmed off halfway through an event description. For example, if a section is short and within our token limit (such as 5.3.10 in TS 24.301), we keep it as one segment. Alternatively, if a section contains multiple paragraphs (such as 5.5.3.2.3 from TS 24.301), each describing an independent event (they might be related when taken in a very large context), we consider each paragraph as a different segment. Details of the module can be found in \u00a74.2.\n1B The second sub-module is the pre-trainer. In this sub-module, we utilize the large corpus generated from the pre-processing module. This ensures that the model understands the domain with specific vocabularies and semantics. The detailed experimental setup is discussed in \u00a75. In parallel to the training, we create embedding vectors for each segment. The embedding vectors are utilized for pairing and filtration of PoSs in the next sub-module.\n1C In the third sub-module, we execute the uninformed fine-tuning. This is an important step for weak supervision and our first concrete endeavor toward task-specific learning. In short, we first fine-tune our candidate transformer models separately on the well-known Stanford Natural Language Inference (SNLI) corpus [18]. We call it uninformed supervision because the SNLI corpus contains examples that are not completely in accordance with our definition of consistency from a protocol perspective. For example, \"A group of people are ice skating in a big city.\" and \"The people are outside skating.\" are labeled as entailments in that corpus. Apparently, the second sequence is a vague representation of the first, i.e., a large and significant part of the first sequence is not expressed through the second sequence. Moreover, our main objective is to capture the protocol inconsistencies based on complex text patterns and intricate details of various cellular events for which fine-tuning on SNLI corpus is not solely sufficient. Thus, training on the SNLI corpus only gives us a loose estimate of our objective model. Nonetheless, this uninformed supervision is the first stepping stone in our analysis. In parallel, we complete the segment pairing and filtration based on the embedding vectors generated in the previous step. In short, we create all possible pairs of the segment vectors and filter them based on a similarity measure. Details of the method can be found in \u00a74.3\n1D At the fourth sub-module, we combine the predictions of k models on our dataset. Note that these k models are now fine-tuned on SNLI corpus from the previous step. It is known that different models have the ability to capture different semantics in varying capabilities. Therefore, combining their predictions through majority voting allows us to boost the prediction confidence. However, these models have not learned what consistency means from the perspective of cellular networks. Therefore, these predictions are not completely reliable as final output.\n1E The most important sub-module for the learner is the multi-phase informed fine-tuning, which is the fifth and most crucial step. Here, we first take the ensemble prediction from the previous sub-module. Next, we sample a small subset of data from the predicted set, then validate and rectify the labels through domain-expert human annotators. This approach ensures ground truth addition while keeping the human involvement minimal. Also, rectifying annotations instead of annotating from scratch reduces the human effort even more. The models are again trained on the reconditioned examples in a supervised manner and used subsequently for predictions, again on the whole dataset. In such a manner, we complete one phase of training. This method is followed k times (each defining a phase) before finalizing the prediction. Details on the experimental choices of this step can be found in \u00a75.\nDispatcher. We take the high-confidence predictions as our results after multi-phase informed training and manually analyze them. To further show the impact of the inconsistent behaviors of the specifications, we use the dispatcher. The dispatcher has two sub-modules.\n2A In the first one, we map the discovered inconsistent descriptions to the open-source implementations-srsRAN, open5GS, and OpenAirInterface [10-12]. Note that many boundary cases and uncommon events are not available (or available in non-granularity) in the open-source implementations. Even so, the predicted inconsistent sets are checked against these multiple sources to determine their design choices and security implications. Consequently, we create a subset of inconsistencies for the next sub-module.\n2B In the second sub-module of the dispatcher, we consider each of the inconsistencies gathered from the previous step to determine whether they cause issues in real-world devices. Details of the setup can be found on our website [13]."}, {"title": "4.2 Dataset Preparation", "content": "It has been shown that pre-training Large Language Models (LLM) can help understand domain-specific terminologies better than LLMs with no domain-specific pre-training (i.e., only pre-trained on general datasets such as Wikipedia corpus) [19, 21, 31, 54]. We first process the raw specifications from the 3GPP archive and pre-train language models on it to leverage the domain-specific learning in an enhanced capability. Our textual entailment task is a harness over the aforementioned pre-trained model. The details of the dataset preparation are discussed in what follows.\nWe remove the tables, figures, cross-document references, code segments, and additional ill-formed texts from the specifications to create the pre-training corpora. For the downstream fine-tuning, since we need semantically meaningful segments of texts to compare, we first extract section-wise texts. The sections usually comprise of many sub-descriptions based on cause values. Otherwise, each paragraph in a section is usually self-contained. Also, to conform to the sequence length limit of our candidate transformer models, we sometimes do finer fragmentation. In this case, sections 4 to 8 are considered for NAS in both 4G and 5G as the rest of the sections mostly contain definitions, abbreviations, glossary, scope, etc. For security, we consider section 4 to the annex for both 4G and 5G."}, {"title": "4.3 Pairing & Filtration", "content": "As discussed earlier, comparing all segments with each other for inconsistency will result in a massive search space, quantitatively, $\\binom{N}{2}$ datapoints where N is the total number of extracted segments. To overcome this, first, we use the Term Frequency- Inverse Document Frequency (TF-IDF) to vectorize such segments (submodule 1B in Figure 2). To answer why TF-IDF is effective here, we compare five different embedding techniques-Sentence BERT (SBERT), Doc2Vec, Universal Sentence Encoder (USE), Word2Vec, and TF-IDF [20, 46, 50, 55, 59]. Among them, TF-IDF appears to be most effective (see details in \u00a76.1).\nConsidering each segment to be a document, formally for a term t found in a document d \u2208 D:\n$tf(t, d) = \\frac{f_{t, d}}{\\sum_{t' \\in d} f_{t', d}}$\n$idf(t, D) = -log P(t | D) = log \\frac{n}{\\sum 1(d \\in D: t \\in d)}$\n$t fid f(t, d, D) = tf(t, d) \\cdot id f(t, D)$"}, {"title": "", "content": "Here $f_{t,d}$ denotes the raw frequency of term t in document d. In our problem, d represents a text segment, and D represents the corpus. TF-IDF maps the text segments d in a k-dimensional latent space X-\n$\\mathbb{X}: S \\ni d \\rightarrow \\mathbb{X} \\in \\mathbb{S}$\nIn the next step, we use the cosine similarity score (\u03c8) to measure the similarity between each pair of TF-IDF vectors. For each vector $x_1$ and $x_2$:\n$\\Psi(x_1, x_2) = \\frac{x_1 \\cdot x_2}{||x_1|| ||x_2||} = \\frac{\\sum_{i=1}^{k} x_{1 i} x_{2 i}}{\\sqrt{\\sum_{i=1}^{k} x_{1 i}^{2}} \\sqrt{\\sum_{i=1}^{k} x_{2 i}^{2}}}$\nWe generate the symmetric matrix of all pair similarity scores. Now, from this symmetric matrix (Figure 3), we take the lower triangular half and remove the datapoints that have \u03c8 < \u03a8min and \u03c8 > \u03a8max. We consider the following cases when choosing values for \u03c8min and \u03c8max:\n\u2022 When \u03c8min is too small, the segments are essentially describing two totally different events with a few words matched in the protocol specification. For a refined dataset, \u03c8min should be kept relatively high.\n\u2022 Using a \u03c8max helps to filter out segments where two text segments have very small changes in vocabularies, i.e., synonymous words or changes of articles (\"a\" instead of \"the\", pronouns instead of proper noun phrases, etc.). These segment pairs state the same event with (almost) exact description."}, {"title": "4.4 Protocol Language Entailment Annotation", "content": "We now discuss the hierarchical annotations of our dataset. The key challenge in finding inconsistencies in 4G/5G protocols is that there are no ground truth labels for model training. Thus", "18": ".", "cases": "n1: t\u2081 = t2: t\u2081 is consistent with t2\n2: t1 \u2260 t2: t\u2081 is inconsistent with t2\n3: t1 ! t2: t\u2081 is not related to t2\n4: t1 ! t2: t\u2081 is related to t2. t\u2081 happens before t2\n5: t1 ! t2: t\u2081 is related to t2. t2 happens before t\u2081\n6: t1 ! t2: t\u2081 is related to t2. t\u2081 contains more/detailed information than t2\n7: t1 ! t2: t\u2081 is related to t2. t2 contains more/detailed information than t\u2081\nWe argue that cases"}]}]}