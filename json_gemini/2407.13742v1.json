{"title": "CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular\nNetwork Specifications", "authors": ["Mirza Masfiqur Rahman", "Imtiaz Karim", "Elisa Bertino"], "abstract": "In recent years, there has been a growing focus on scrutiniz-\ning the security of cellular networks, often attributing security\nvulnerabilities to issues in the underlying protocol design\ndescriptions. These protocol design specifications, typically\nextensive documents that are thousands of pages long, can har-\nbor inaccuracies, underspecifications, implicit assumptions,\nand internal inconsistencies. In light of the evolving landscape,\nwe introduce CellularLint-a semi-automatic framework for\ninconsistency detection within the standards of 4G and 5G,\ncapitalizing on a suite of natural language processing tech-\nniques. Our proposed method uses a revamped few-shot learn-\ning mechanism on domain-adapted large language models.\nPre-trained on a vast corpus of cellular network protocols,\nthis method enables CellularLint to simultaneously detect in-\nconsistencies at various levels of semantics and practical use\ncases. In doing so, CellularLint significantly advances the\nautomated analysis of protocol specifications in a scalable\nfashion. In our investigation, we focused on the Non-Access\nStratum (NAS) and the security specifications of 4G and\n5G networks, ultimately uncovering 157 inconsistencies with\n82.67% accuracy. After verification of these inconsistencies\non 3 open-source implementations and 17 commercial de-\nvices, we confirm that they indeed have a substantial impact\non design decisions, potentially leading to concerns related to\nprivacy, integrity, availability, and interoperability.", "sections": [{"title": "1 Introduction", "content": "Cellular networks have emerged as the primary means of com-\nmunication in the modern world, with 4G and 5G being the\nlatest commercially available versions. Ranging from mobile\ncommunications to IoT devices to vehicular communications,\ncellular networks are a critical infrastructure for the digital\nworld. With more than 1.4 billion subscribers, 5G is expected\nto exceed its much larger predecessor, 4G, and is forecast to\ngain more than 13 billion subscribers globally by the end of\n*Equal contribution. The student author's name is given first.\n2026 [4, 5]. These networks embody large infrastructure and\nsupport different features, including backward compatibility,\ninteroperability, and heterogeneity.\nLike any large-scale, complex, layered system, cellular net-\nwork designs are governed by protocol documentation. 3GPP,\nthe 3rd Generation Partnership Project-a consortium of ven-\ndors, is the supervising body that handles the design and distri-\nbution of these protocol documents [2]. These documents are\nquite lengthy, developed by many stakeholders, and improved\nthrough releases and change requests over the years. Incorpo-\nrating these changes and releases subsequently introduces di-\nverging descriptions. Recently, few studies have shown, albeit\nthrough manual analysis during implementation testing, that\nprotocol documents have inconsistent descriptions accounting\nfor differing design possibilities and undefined behaviors in\nreal-world devices, often with severe consequences [37,53].\nFig. 1 shows an example scenario for diverging sub-state tran-\nsitions on the same condition, found in the 4G Non-Access-\nStratum (NAS) specification. Furthermore, in most cases, one\nof the inconsistent or conflicting behaviors is less secure than\nthe other. For example, if one design suggests clearing some\nnetwork identifier(s) after a connection has been lost while\nthe other design suggests keeping it without specifying a clear\nmotivation, the latter can make the user vulnerable to privacy\nviolation attacks. Therefore, these diverging specifications\ndefined in the standards can have severe security and privacy\nconsequences."}, {"title": "Prior Research", "content": "Although prior research works [23-25, 34,\n36,37,43,45,47, 53] have proposed approaches for detecting\nsecurity and implementation flaws in cellular network proto-\ncols, they have at least one of the following limitations: (A)\nThey are completely manual [25, 37, 43, 47] and inherently\nhave limited scalability. (B) They employ formal verifica-\ntion [34,36], foundationally relying on the quality of the prop-\nerties, and do not primarily deal with inconsistent descriptions-\nsubsequently choosing the most secure option when an in-\nconsistent or confusing situation is encountered. (C) They\nfocus on implementation testing [44, 53] and only report a\nfew inconsistent descriptions on the way without proposing\nan approach to uncover them. (D) They use differential testing\nfor noncompliance checking [37] without focusing on con-\nflicting behavior detection in the standards. (E) They either\nanalyze change requests or specifications through NLP tech-\nniques to understand security hazards [23,24] without directly\nconsidering differing description analysis in specifications.\nProblem. With the current state-of-the-art approaches having\nabove-mentioned limitations, in this paper, we aim to take\nthe first steps to answer the following research question- Is it\npossible to develop a systematic, generalizable, and scalable\nspecification analysis framework that can identify inconsistent\ndescriptions from 4G and 5G specifications and associate\nthem with differential design choices?\nA promising direction. Following the major advances in nat-\nural language processing (NLP) [19, 60], recent works have\ndemonstrated the automated generation of Finite State Ma-\nchine from both Request For Comments (RFC) documents\nand cellular network specifications [39, 52]. Such results in-\ndicate that a data-driven approach can be taken to discover\ninconsistencies in specifications as a root cause of design\nflaws and vulnerabilities as well.\nChallenges. Detecting inconsistent behaviors systematically\nfrom the large and complex cellular network specifications\nusing NLP requires tackling some very important research\nchallenges. The first and foremost challenge is to quantize\nthe specification into segments, which we can use for incon-\nsistency detection. The specifications explain an event in a\nvery large context; in some cases, an event is described in\n5-6 pages. With such a large segment, any learning algorithm\nwould fail to capture the finer details and attributes of the\nsegment. Therefore, we need to devise a mechanism to create\nsegments of reasonable size from the specifications. Second,\nthe specifications are so large that in case all the segments are\npairwise compared, the search space becomes intractable. For\nthis, we need to devise an approach that reduces the search\nspace substantially. Last, and most importantly, to the best of\nour knowledge, there are no datasets that could be utilized to\ndetect inconsistent statements in cellular networks. In case\nthere is a large number of inconsistencies that can be manually\nfound, this trivially solves the problem and does not require\na systematic framework. Fortunately or rather unfortunately,\nthere are very few manually found conflicts in the specifica-"}, {"title": "Our Approach", "content": "tions that can be used for closed-form solutions that we can\nuse to train. This lack of ground truth creates a major hurdle\nfor any learning-based solution.\nIn this paper, we introduce CellularLint-the\nfirst framework for uncovering inconsistencies from the upper\nlayer of 4G and 5G specifications. For our method, we employ\nfew-shot domain adaptation of language models.\nTo obtain a scalable solution, we initially cast the docu-\nments in sizeable segments based on domain-specific knowl-\nedge. These quantized segments preserve the context and\nevent, which are essential before understanding inconsisten-\ncies. Second, based on this quantized pool of intra-document\nand inter-document test cases/segments, we produce Pairs\nof Segments (PoS). CellularLint compresses the search space\nof PoS into a manageable and informative dataset based on\ninterpretable similarity measures. This guides our method to\nlook into only relevant content-making the process highly\nscalable.\nTo address the lack of labeled examples, instead of heav-\nily relying on expert annotations, CellularLint incorporates\ndomain-aware annotations and ensemble decision mecha-\nnisms and takes only a fraction of labeled examples. We\ndesign seven domain-adapted, consistency-wise meaningful\nlabels and map them to general-purpose natural language\ninference (NLI) annotations. CellularLint also utilizes human-\nin-the-loop active learning on multiple language models to\nfinalize inconsistent descriptions in varying granularities.\nTo address the lack of supervision, we divide the learning\nobjective into multiple phases- (1) initially converting the\nlearning problem to a generalized setting of NLI and then (2)\nusing multiple phases of active learning on a domain-specific\ndataset.\nFindings. CellularLint discovered 157 conflicting descrip-\ntions from specifications. To evaluate the effectiveness of the\ndiscoveries, we investigate them on 3 open-source implemen-\ntations and test them on 17 commercial UEs.\nWe uncover that implementations indeed take different de-\nsign choices based on conflicting or inconsistent standards.\nFurthermore, in some cases, we have found that implementa-\ntions choose the less secure option, and in some cases, tried\nto implement both options. For ease of discussion, we charac-\nterize a subset of our findings into four different categories-\nimpacting security enforcement, privacy, interoperability, and\ncausing denial-of-service. In these categories, we discuss a\ntotal of 11 issues that can have a severe impact on the privacy,\nintegrity, availability, and interoperability of cellular network\ninfrastructure.\nOpen-source. We will completely open-source CellularLint\nand all the detected inconsistencies to foster research in in-\nconsistency detection in other important protocol specifica-\ntions [13] 1.\nContributions.To summarize, we make the following contri-"}, {"title": "2 Background", "content": "In this section, we introduce various preliminaries ranging\nfrom the 4G Long Term Evaluation (LTE) and 5G New Radio\n(NR) architectures to various NLP methods that are relevant\nto our work."}, {"title": "2.1 Cellular Network Preliminary", "content": "For cellular network preliminaries, here we discuss the most\ncommon components that are relevant to this paper."}, {"title": "2.1.1 Cellular Network Architecture", "content": "The network is composed of three main components: the user\nequipment (UE), the radio access network (RAN), and the\ncore network. The architectural difference between 4G and\n5G mostly lies on the RAN and Core Network side.\nUser Equipment (UE). The UE, a terminal device on the user\nend, is equipped with a Universal Subscriber Identity Mod-\nule (USIM). The USIM contains the user identifier, master\nsecret key, and session key for connectivity. These are essen-\ntial for mutual Authentication and Key Agreement (AKA)\nbetween the user and the network. The most common UE are\ncell phones, tablet computers, and IoT devices with cellular\nconnectivity.\neNodeB. eNodeBs or eNBs are base stations or, most com-\nmonly, mobile network towers in the 4G architecture. They\nstand as a middle entity in the connection establishment and\nmaintenance for which the Radio Resource Control (RRC)\nprotocol is implemented. eNodeB is replaced by gNodeB in\nthe 5G network. eNodeB is responsible for transmitting and\nreceiving signals to and from UEs.\ngNodeB. The gNodeB or gNB-also called the Next-\nGeneration NodeB-is used in 5G network. It is a significant\nupgrade from eNodeB. gNodeB supports Massive MIMO\ntechnology, has higher throughput, lower latency, and enables\nadvanced network slicing.\n4G-Core The core network in 4G LTE is called Evolved\nPacket Core (EPC). Two functional components-Mobility\nManagement Entity (MME) and Home Subscriber Server"}, {"title": "2.2 ML Preliminaries", "content": "CellularLint detects inconsistencies from a natural language\nperspective, meaning that it focuses on the lexical and con-\ntextual analysis of the salient features of the protocol text\ndocuments to reveal inconsistencies from protocol specifi-\ncations. Here, we discuss the NLP preliminaries required\nfor CellularLint."}, {"title": "2.2.1 Few Shot Learning", "content": "Few-Shot Learning (FSL) [19,30] is a meta-learning approach\nthat utilizes a pre-trained model to generalize over new cate-\ngories of data using only a few labeled examples per class. For\nN-way-k-shot learning in NLP, given k labeled examples of\neach class from N classes for a new NLP task where k is gen-\nerally very low, the pre-trained model has to learn efficiently\nto solve the new task."}, {"title": "2.2.2 Active Learning", "content": "Active learning [29, 51], especially human-in-the-loop ac-\ntive learning, is a machine learning paradigm that focuses\non improving learning performance by minimizing the need\nto label large amounts of data. Often, domain-specific super-\nvised learning is hindered by the insufficiency of ground truth\ndata. Guiding the model by associating expert annotation\nwith a subset of important data points can largely boost the\nperformance of supervised training."}, {"title": "2.2.3 NLP Methods", "content": "Textual Entailment (TE). Textual entailment, or Natural\nLanguage Inference (NLI), is a binary relation where two\ntext sequences can either form an agreement, a contradiction\nor be completely irrelevant to each other [18,38]. From a"}, {"title": "3 Overview", "content": "In this section, we discuss the problem analysis scope and\nstate the problem formally. Next, we discuss the challenges\nand corresponding approaches."}, {"title": "3.1 Scope of Analysis", "content": "The cellular network protocols (4G and 5G) comprise thou-\nsands of specifications-from the low layers to the link layer to\nthe upper layers (Layer 3) of the protocols. Among all these\nspecifications and related procedures, we focus on the NAS\nlayer procedures. NAS layer procedures contain the mobility\nmanagement and session management components, which in\nturn manage the most critical control plane procedures such\nas connection setup, initial authentication, mobility, hand-off,\nand service notifications. Previous works have shown several\nvulnerabilities in these components, resulting in severe se-\ncurity and privacy issues such as authentication-bypass [44],\nlocation exposure [35], impersonation [56], downgrading [40],\nto name a few. Keeping these in mind, in this work we focus\non the NAS layer procedure. More specifically, we focus on\nfour documents in two categories- the NAS technical specifi-\ncation TS (24.301, v17.6.0) [9] and the Security Architecture\nand Procedures specification (TS 33.401, v17.1.0) [7] for 4G,\nand the NAS specification (TS 24.501, v17.7.1) [8] and the Se-\ncurity Architecture and Procedures specification (TS 33.501,\nv17.5.0) [3] for 5G. All of them are available from the 3GPP\narchive. Release 17 is the latest complete version to have both\nNAS and its security specifications. Furthermore, having the\nsame release ensures consistency and removes the possibility\nof unexpected inconsistency prediction (false positives) in-\ntroduced by version mismatch. In fact, finding cross-version\ninconsistency is a different task that we leave as future work."}, {"title": "3.2 Problem Formulation", "content": "Here we define the problem formally: given a set of cor-\npora $G = \\{C^{4g}_{Nas}, C^{4g}_{Sec}, C^{5g}_{Nas}, C^{5g}_{Sec}\\}$ (where $C^{4g}_{Nas}$\nis the corpus\nproduced from 4G NAS specification, $C^{4g}_{Sec}$ is the corpus pro-\nduced from 4G security architecture specification, similar\nnotations are applicable for 5G), we need to quantize each\ncorpus in text segments, that is, $C_{i} = \\{t_{1},t_{2},...,t_{n}\\}_{i}$ where\n$t_{a}$ describes a-th meaningful event/sub-event/directive from\ncorpus G. Now our first objective is to construct interme-\ndiate sets, $S_{1} = (C^{4g}_{Nas} \\times C^{4g}_{Sec}) \\cup (C^{4g}_{Sec} \\times C^{4g}_{Nas}) \\cup (C^{4g}_{Nas} \\times C^{4g}_{Nas})$\nand $S_{2} = (C^{5g}_{Nas} \\times C^{5g}_{Sec}) \\cup (C^{5g}_{Sec} \\times C^{5g}_{Nas}) \\cup (C^{5g}_{Sec} \\times C^{5g}_{Sec})$. Next,\nfrom each intermediate set $S_{m} \\in \\{S_{1},S_{2}\\}$ containing tuples\nor pairs $(t_{a},t_{b})$ of text Segments (PoS), our objective is to\ndevise a model $M$ which can determine all pairs that conflict\nbetween each other, that is, $M(t_{a},t_{b}) = k$. Here, k takes the\nvalue consistent or inconsistent."}, {"title": "3.3 Challenges & Solution Outline", "content": "We now discuss the main challenges and corresponding ap-\nproaches that have driven the CellularLint's high-level design\nchoices. We then present the key steps in our overall solution.\n(C1) Segment quantization. In numerous scenarios, the spec-\nifications explain an event in a vast context. For example, in\nthe 4G NAS specification, Section 5.5.1.2.4 describes \"Attach\naccepted by the network\", which is a six-page long descrip-\ntion concerning one major event where the network accepts an\nattach request from the UE. If we consider this whole event as\none complete and discrete, meaningful segment, any learning\nalgorithm will fail to capture the intricate details and attributes,\ncausing differential and anomalous behaviors. Moreover, in\nthe same section, there is a precondition \"If the UE indicates\nsupport for EMM-REGISTERED without PDN connection\",\nwhich shall trigger an event on the MME side. A similar\nprecondition is found for tracking_are_update_request\nmessage further away in the document. If the whole section\nis considered as a potential segment, one would not be able\nto match such sub-event triggers and may miss numerous\npossible interesting scenarios. An alternative choice can be\nselecting each sentence as an atomic unit governing a seg-\nment. However, this leads to a serious problem because, often,\na single sentence from the specification is not sufficient to\ninfer all the entities, states, or messages involved in a pro-\ncess. Also, due to the semi-structured nature of specifications,\nmany sentences are repeated in different parts of the specifica-\ntions. Thus, considering each sentence a meaningful segment\nwould produce too many repeating units in the dataset, and if\nneeded, it would be impossible to map back uniquely to the\nspecification. Thus, this trivial solution is not applicable to\nour case.\n(A1) Sub-event driven segment quantization. As we\nhave already established that considering a whole event as\na segment likely affects the effectiveness and purpose of"}, {"title": "3.4 Approach Skeleton", "content": "detected inconsistencies, we quantize such larger descriptions\ninto smaller segments. However, in doing so, we preserve the\ncompleteness of the description of sub-events. We combine\ndomain-specific understanding with standard NLP techniques\nto pinpoint sub-events. Specifically, we consider subsections\nand complete paragraphs as atomic units while constraining\nthe sequence length and entity based on Parts-Of-Speech\nfiltering. Details about the approach for segment quantization\nare given in \u00a74.2.\n(C2) Intractable search space. The protocol specifications\nare large documents defining and explaining all entities,\nevents, state transitions, message structures, and so on in finer\ndetail. Moreover, when we execute segment quantization to\naddress C1, the resulting quantized dataset is even larger.\nThus, traversing and matching texts directly using the en-\ntire dataset of quantized segments makes the finalized search\nspace intractable with millions of potential segment pairs.\nFor example, after the segment quantization, the brute-force\ntraverse and match solution gives us more than 12 million\nsegment pairs for 5G-NAS specification alone. On top of that,\nto find inconsistencies, one may have to consider multiple\nrelated specifications rather than generating segments from\njust one. For instance, in our case, for 5G we consider the\n5G NAS technical specifications and the security architecture\nand procedures specification. This, in turn, makes the search\nspace tremendously larger and thereby causes a state-space\nexplosion.\n(A2) Finite segment filtration. To address C2, we reduce the\nsegment sequence pair space by filtering the initial dataset\nbased on similarity measures. The intuition behind this idea is\nthat two completely different segments should not be consid-\nered inconsistent as they talk about totally different aspects of\nthe protocol. Contrary to this, an inconsistent PoS would have\nat least the same pre-condition and hence would have a better\nsimilarity score. To achieve such a quantitative measure of\ntexts, we first consider the vector embedding of texts. How-\never, we observe that choosing an arbitrary embedding can\nseverely affect the search space shrinkage and effectiveness\nof similarity scoring. We have thus carried out an extensive\nevaluation to determine the most reliable text vectorization\ntechnique for our problem. The details of the evaluation are\ndiscussed in \u00a76.1. Thus we reduce the number of segments\nfrom millions to a few thousand-reducing the problem space\nto a tractable size.\n(C3) Absence of ground truth. To the best of our knowledge,\nthere are no datasets that could be utilized for NLP-based ma-\nchine learning to detect conflicting statements from cellular\nprotocols. Even if a processed, readily usable dataset existed,\nno closed-form solution would be able to trivially map text\nsegments from multiple documents to specific inconsistencies.\nThis is a novel problem-solving which is a key contribution\nof our work. Moreover, although state-of-the-art language\nmodels are very effective in learning contexts, they require a\nmassive amount of labeled data due to the larger parameter\nlandscape. Acquiring such a domain-specific dataset is often\ncumbersome and for this problem setup, even harder. Thus we\nhave to design a technique that can work with only a handful\nof labeled examples.\n(A3) Ground truth generation. We employ multi-phase su-\npervision through human-in-the-loop active learning to sub-\ndue the insufficiency of ground truth. Our learning method\nneither requires a large amount of annotation nor suffers from\ntoo much uncertainty introduced by insufficient learning. In\nshort, we first establish the learning landscape using a general-\npurpose dataset with some supervised data. Note that this\ngeneral-purpose dataset is not from the cellular network do-\nmain but rather from image-crowdsourced caption writing\nand is publicly available. This intermediary model is utilized\nin consensus with human involvement alongside minimal syn-\nthesized data repeatedly to prepare the finalized model. The\nwhole process never requires the complete ground truth of\nour problem. In fact, having a complete ground truth from the\nbeginning is fundamentally contradictory here, as it would\ntrivially solve the problem we have at hand. Indeed, if there\nwere already a large number of inconsistent descriptions in\nspecifications, then those could be directly reported to im-\nprove the protocol and would not require any additional anal-\nysis. Likewise, the lack of ground truth makes the problem\nboth challenging and rewarding to some extent."}, {"title": "4 Detailed Design", "content": "Based on our discussion of challenges and approaches to\nthe solution, we divide the inconsistency detection problem\ninto multiple steps: (i) We employ domain-specific prepro-\ncessing alongside standard NLP techniques to quantize each\n$G \\in G$. (ii) To produce each $S_{m}$, we utilize an syntactic and\ncontextual equivalence metric $\\gamma$ to filter out irrelevant PoS.\n(iii) To address the absence of labeled examples, we use $M'$\ninstead of $M$ which first learns from a general dataset $P$ to\nsolve textual entailment task. In this task, for any two text\nsequences $t_{x}, t_{y} \\in P$, $M'$ learns if $t_{y}$ entails $t_{x}$ or not. Formally,\n$M'(t_{x},t_{y}) = k'$ where $k'$ takes the value of either entailment\nor contradiction or irrelevance (often called neutral). Subse-\nquently we use $M'$ with few domain-specific labeled data to\ngenerate our specialized model $M$ with the learning objective\nof $M(t_{a},t_{b}) = k'$, where $t_{a}, t_{b} \\in S_{m}$.\nIn this section, we discuss CellularLint in detail. Fig. 2 shows\nthe main components of our framework."}, {"title": "4.1 Architecture", "content": "The overall framework is organized into two parts: 1 the\nLearner, and 2 the Dispatcher. Each of them has multiple"}, {"title": "3.2 Problem Formulation", "content": "Here we define the problem formally: given a set of cor-\npora $G = \\{C^{4g}_{Nas}, C^{4g}_{Sec}, C^{5g}_{Nas}, C^{5g}_{Sec}\\}$ (where $C^{4g}_{Nas}$\nis the corpus\nproduced from 4G NAS specification, $C^{4g}_{Sec}$ is the corpus pro-\nduced from 4G security architecture specification, similar\nnotations are applicable for 5G), we need to quantize each\ncorpus in text segments, that is, $C_{i} = \\{t_{1},t_{2},...,t_{n}\\}_{i}$ where\n$t_{a}$ describes a-th meaningful event/sub-event/directive from\ncorpus G. Now our first objective is to construct interme-\ndiate sets, $S_{1} = (C^{4g}_{Nas} \\times C^{4g}_{Sec}) \\cup (C^{4g}_{Sec} \\times C^{4g}_{Nas}) \\cup (C^{4g}_{Nas} \\times C^{4g}_{Nas})$\nand $S_{2} = (C^{5g}_{Nas} \\times C^{5g}_{Sec}) \\cup (C^{5g}_{Sec} \\times C^{5g}_{Nas}) \\cup (C^{5g}_{Sec} \\times C^{5g}_{Sec})$. Next,\nfrom each intermediate set $S_{m} \\in \\{S_{1},S_{2}\\}$ containing tuples\nor pairs $(t_{a},t_{b})$ of text Segments (PoS), our objective is to\ndevise a model $M$ which can determine all pairs that conflict\nbetween each other, that is, $M(t_{a},t_{b}) = k$. Here, k takes the\nvalue consistent or inconsistent."}, {"title": "4.2 Dataset Preparation", "content": "It has been shown that pre-training Large Language Models\n(LLM) can help understand domain-specific terminologies\nbetter than LLMs with no domain-specific pre-training (i.e.,\nonly pre-trained on general datasets such as Wikipedia cor-\npus) [19,21,31,54]. We first process the raw specifications\nfrom the 3GPP archive and pre-train language models on\nit to leverage the domain-specific learning in an enhanced\ncapability. Our textual entailment task is a harness over the\naforementioned pre-trained model. The details of the dataset\npreparation are discussed in what follows.\nWe remove the tables, figures, cross-document references,\ncode segments, and additional ill-formed texts from the spec-\nifications to create the pre-training corpora. For the down-\nstream fine-tuning, since we need semantically meaningful\nsegments of texts to compare, we first extract section-wise\ntexts. The sections usually comprise of many sub-descriptions\nbased on cause values. Otherwise, each paragraph in a section\nis usually self-contained. Also, to conform to the sequence\nlength limit of our candidate transformer models, we some-\ntimes do finer fragmentation. In this case, sections 4 to 8\nare considered for NAS in both 4G and 5G as the rest of the\nsections mostly contain definitions, abbreviations, glossary,\nscope, etc. For security, we consider section 4 to the annex\nfor both 4G and 5G."}, {"title": "4.3 Pairing & Filtration", "content": "As discussed earlier, comparing all segments with each other\nfor inconsistency will result in a massive search space, quan-\ntitatively, $\\binom{N}{2}$ datapoints where N is the total number of\nextracted segments. To overcome this, first, we use the\nTerm Frequency- Inverse Document Frequency (TF-IDF)\nto vectorize such segments (submodule 13 in Figure 2).\nTo answer why TF-IDF is effective here, we compare five\ndifferent embedding techniques-Sentence BERT (SBERT),\nDoc2Vec, Universal Sentence Encoder (USE), Word2Vec, and\nTF-IDF [20, 46, 50, 55, 59]. Among them, TF-IDF appears to\nbe most effective (see details in \u00a76.1).\nConsidering each segment to be a document, formally for\na term t found in a document $d \\in D$:\n$tf(t,d) = \\frac{f_{t,d}}{\\Sigma_{t' \\in d} f_{t',d}}$\n$id f (t,D) = -log P(t|D) = log \\frac{n}{\\Sigma 1(d \\in D : t \\in d)}$\n$t fid f (t,d,D) = tf(t,d) \\cdot id f (t,D)$\nHere $f_{t,d}$ denotes the raw frequency of term t in document\nd. In our problem, d represents a text segment, and D rep-\nresents the corpus. TF-IDF maps the text segments d in a\nk-dimensional latent space X-\n$\\phi :S \\rightarrow X d\\in S$\nIn the next step, we use the cosine similarity score (\u03c8) to\nmeasure the similarity between each pair of TF-IDF vectors.\nFor each vector x1 and x2:\n$\\Psi(X_{1},X_{2}) = \\frac{X_{1} \\cdot X_{2}}{|| X_{1} || || X_{2} ||} = \\frac{\\Sigma_{i=1}^{k} X_{1i}X_{2i}}{\\sqrt{\\Sigma X_{1i}^{2}} \\sqrt{\\Sigma X_{2i}^{2}}}$\nWe generate the symmetric matrix of all pair similarity scores.\nNow, from this symmetric matrix (Figure 3), we take the\nlower triangular half and remove the datapoints that have\n$\\psi < \\Psi_{min}$ and $\\psi > \\Psi_{max}$. We consider the following cases\nwhen choosing values for $\\Psi_{min}$ and $\\Psi_{max}$:"}, {"title": "4.4 Protocol Language Entailment Annotation", "content": "We now discuss the hierarchical annotations of our dataset.\nThe key challenge in finding inconsistencies in 4G/5G proto-\ncols is that there are no ground truth labels for model training.\nThus, any supervised training task is hindered. We address\nthis challenge by multi-phase training where the Oth phase\nensures the general capability of the model in distinguishing\nwhat an entailment or contradiction is, and the next phases\nare to precisely capture what sort of disparity is present in our\nactual cellular dataset.\nThe Stanford Natural Language Inference (SNLI) dataset\ncontains datapoints with 3 unique annotations, namely, en-\ntailment, conflict, and neutral [18]. Since our model is first\nfine-tuned on this dataset (submodule 10) as a Oth phase, we\nkeep the same annotations to train the model(s) for subsequent\nphases. To characterize all scenarios, we consider 7 cases:\n1: t\u2081 = t2: t\u2081 is consistent with t2\n2: t1 !=\nt2: t\u2081 is inconsistent with t2\n3: t1 || t2: t\u2081 is not related to t2\n4: t1 \\rightarrow t2: t\u2081 is related to t2. t\u2081 happens before t2\n5: t1 \\rightarrow t2: t\u2081 is related to t2. t2 happens before t\u2081\n6: t1 \\rightarrow t2: t\u2081 is related to t2. t\u2081 contains more/detailed infor-\nmation than t2\n7: t1 \\rightarrow t2: t\u2081 is related to t2. t2 contains more/detailed infor-\nmation than t\u2081\nWe argue that cases 1, 4, and 5 fall under entailment. Cases\n2, 6, and 7 fall under contradiction. Case 3 maps onto the neu-\ntral label in the NLI task. For the contradiction class, cases 6\nand 7 are difficult to perceive. We discuss this with a possible\nscenario. Suppose in a scenario both t\u2081 and t2 independently\ndescribe the actions after an attach_reject is received by\nthe UE with some specific EMM cause. Now, t\u2081 describes\nboth the EPS status update and the security context clearing.\nIn contrast, t2 describes only the process of updating the EPS\nstatus but does not mention anything about security context\nclearing. This will fall under case 6. This is considered as an\ninconsistency because the missing security context clearing"}, {"title": "4.5 NLI Adaptation", "content": "in t2 might create confusion in the implementation design and\nlater on cause serious security issues.\nAt each phase, our annotated protocol dataset contains 150\nPoS (in total 450 for three phases), whereas the SNLI dataset\ncontains 570k English sentence pairs, which are ~1266 times\nhigher than the number of PoS in our dataset. Achieving even\na reasonable performance is difficult if only this small dataset\nis used for transformer-based supervised learning, which con-\ntains millions of learnable parameters. Thus we first train\ntransformer $T$ on the SNLI dataset. This, in turn, produces\na model $T'$ that is ready to understand the difficult repre-\ns"}]}