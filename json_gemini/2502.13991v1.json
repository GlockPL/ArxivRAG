{"title": "LEARNING TO DISCOVER REGULATORY ELEMENTS FOR GENE EXPRESSION PREDICTION", "authors": ["Xingyu Su", "Haiyang Yu", "Degui Zhi", "Shuiwang Ji"], "abstract": "We consider the problem of predicting gene expressions from DNA sequences. A key challenge of this task is to find the regulatory elements that control gene expressions. Here, we introduce Seq2Exp, a Sequence to Expression network explicitly designed to discover and extract regulatory elements that drive target gene expression, enhancing the accuracy of the gene expression prediction. Our approach captures the causal relationship between epigenomic signals, DNA sequences and their associated regulatory elements. Specifically, we propose to decompose the epigenomic signals and the DNA sequence conditioned on the causal active regulatory elements, and apply an information bottleneck with the Beta distribution to combine their effects while filtering out non-causal components. Our experiments demonstrate that Seq2Exp outperforms existing baselines in gene expression prediction tasks and discovers influential regions compared to commonly used statistical methods for peak detection such as MACS3. The source code is released as part of the AIRS library (https://github.com/divelab/AIRS/).", "sections": [{"title": "1 INTRODUCTION", "content": "Gene expression serves as a fundamental process that dictates cellular function and variability, providing insights into the mechanisms underlying development (Pratapa et al., 2020), disease (Cookson et al., 2009; Emilsson et al., 2008), and responses to external factors (Schubert et al., 2018). Despite the critical importance of gene expression, predicting it from genomic sequences remains a challenging task due to the complexity and variability of regulatory elements involved. Recent advances in deep learning techniques (Avsec et al., 2021; Gu & Dao, 2023; Nguyen et al., 2024; Badia-i Mompel et al., 2023) have shown remarkable capabilities and performance in modeling long sequential data like language and DNA sequence. By capturing intricate dependencies within genomic data, these techniques provide a deeper understanding of how regulatory elements contribute to transcription (Aristizabal et al., 2020).\nTo predict gene expression, DNA language models are usually applied to encode long DNA sequences with a subsequent predictor to estimate the gene expression values (Avsec et al., 2021; Nguyen et al., 2024; Gu & Dao, 2023; Schiff et al., 2024). However, those language models are typically designed to encode DNA sequences alone, overlooking the specific environments like different cell types, which leads to suboptimal performance. Instead of predicting the gene expression only using DNA sequence, which is invariant across cell types, a more biological relevant formulation is to predict gene expression levels using both DNA sequence and epigenomic signals. For example, GraphReg (Karbalayghareh et al., 2022) uses epigenomic signals as input data to predict gene expression values. However, it does not integrate DNA sequences and epigenomic signals in a unified manner to improve gene expression prediction. EPInformer (Lin et al., 2024) uses statistical methods to identify the epigenomic signal peaks, and focuses on regulatory elements identified by those peaks. Although obtaining better results, EPInformer still neglects the complex relationship between DNA sequences, epigenomic signals and regulatory elements, which is essential for improving prediction accuracy."}, {"title": "2 RELATED WORKS AND PRELIMINARY", "content": "The task of predicting gene expression levels given the DNA sequences and epigenomic signals presents several challenges. First, epigenomic signals can be measured by a variety of experimental techniques, including ChIP-seq, DNase-seq, Hi-C, each with their own biases and limitations (Consortium et al., 2012; Bernstein et al., 2010; Moore et al., 2020). Additionally, the regulatory elements influencing target gene expression are often sparse and may involve long-range interactions, making them challenging to identify and integrate into predictive models. These complexities highlight the need for models that can effectively discover the actively interacted regulatory elements with the target gene on long DNA sequences.\nIn response to these challenges, we propose Seq2Exp (Sequence to Expression), a novel framework designed to improve gene expression prediction by selectively extracting relevant sub-sequences from both DNA sequences and epigenomic signals. Since DNA sequences and epigenomic signals capture different aspects of biological information, their integration offers deeper insights. For example, Hi-C/HiChIP data reveals the physical interaction frequency between distal DNA regions, and DNase-seq reflects the functional activity of regulatory elements. Effectively incorporating these signals along with DNA sequences can be highly beneficial for addressing the above challenges for gene expression prediction task. Specifically, in this work, we suggest the causal relationship between genomic data and gene expression to guide the learning process as depicted in Figure 1. Inspired by the causal relationship, we decompose the mask learning process into two components: one based on DNA sequences and the other on epigenomic signals. The proposed Seq2Exp first employs a generator module to learn a token-level mask based on both DNA sequences and epigenomic signals, to extract DNA sub-sequences. Then, the predictor module is applied on these extracted sub-sequences to predict gene expression. With information bottleneck, Seq2Exp can effectively filter out non-causal parts by constraining the mask size, ensuring that only the most relevant regions are extracted. Overall, the incorporation of the DNA sequences and epigenomic signals systematically discovers regions that are likely to influence gene expression.\nWe summarize our contributions here:\n\u2022 We propose a framework articulating the causal relationship between epigenomic signals, DNA sequences, target gene expression and related regulatory elements.\n\u2022 Based on the causal relationships, our framework is proposed to combine the mask probability distribution from DNA sequences and epigenomic signals, and filtering out non-causal region via information bottleneck.\n\u2022 The proposed Seq2Exp achieves SOTA performances compared to previous gene expression prediction baselines, and demonstrates the extracted regulatory elements serve as a better sub-sequences compared to statistical peaks calling methods of epigenomic signals such as MACS3."}, {"title": "2.1 TASK DESCRIPTION", "content": "Let $X_{seq} = [x_1, ..., x_L]$ denote the DNA sequence with length $L$, where each token $x_i \\in \\mathbb{R}^{4 \\times 1}$ is a one-hot vector representing a nucleotide from the set {A, C, G, T}. For this DNA sequence, the corresponding epigenomic signals are denoted as $X_{sig} = [s_1, ..., s_L]$, where $s_i \\in \\mathbb{R}^{d \\times 1}$ represents $d$ different signals. By using both the DNA sequence and epigenomic signals, the task aims to predict the target gene expression denoted as $Y \\in \\mathbb{R}$. To achieve this target, we propose our framework to extract the active regulatory elements by learning a token-level binary mask $M = [M_1, ..., M_L]$, where $m_i \\in \\{0, 1\\}$ or a soft mask $M$ where $m_i \\in [0, 1]$.\nSpecifically, in our implementation, each example contains one target gene. We first identify the transcription start site (TSS) of the target gene, then select input sequences $X_{seq}$ and $X_{sig}$ consist of $L = 200,000$ base pairs, centered on the TSS. Then, the entire sequences provide sufficient contextual information for accurate prediction of the target gene expression value $Y$."}, {"title": "2.2 RELATED WORKS", "content": "DNA language model has been proposed recently to apply language machine learning models to long DNA sequences (Nguyen et al., 2024; Gu & Dao, 2023; Schiff et al., 2024) and solve vari-"}, {"title": "2.3 BACKGROUND OF INFORMATION BOTTLENECK", "content": "To effectively extract active regulatory elements from DNA sequences, it is important to understand the concept of the information bottleneck. The information bottleneck method is a widely used technique in machine learning on tasks for images (Alemi et al., 2016; Chen et al., 2018), language data (Belinkov et al., 2020; Lei et al., 2016; Paranjape et al., 2020; Bastings et al., 2019; Jain et al., 2020) or graph data (Wu et al., 2020; Miao et al., 2022). Its goal is to maximize the mutual information between compressed representations $Z$ and the target variable $Y$, expressed as $I(Z;Y)$, while controlling the information extracted from the input $X$. Note that in the proposed method, $Y$ represents the target gene expression. A straightforward approach would be to set $Z = X$, but this retains the full complexity of $X$, which makes the optimization process challenging, especially with the long and noisy nature of DNA sequences.\nTo address this, researchers impose a constraint on the information transferred from $X$ to $Z$, ensuring that $I(X; Z) \\le I_c$, where $I_c$ is an information constraint that allows us to capture only the most critical compressed representations. The information bottleneck objective becomes maximizing:\n$L = I(Z; Y) - \\beta I(X; Z), \\qquad (1)$\nwhere $\\beta$ is a hyperparameter that balances the trade-off between compression and relevance. However, directly optimizing this objective is challenging. To overcome this, Chen et al. (2018) proposes to maximize a lower bound approximation, which leads to minimizing the following expression:\n$\\frac{1}{N} \\sum_{i=1}^N \\mathbb{E}_{p_{\\theta}(Z | x_i)}[ -\\log q_{\\phi}(y_i | Z)] + \\beta K L[p_{\\theta}(Z|x_i), r(Z)], \\qquad (2)$\nwhere $p_{\\theta}(Z|x_i)$ is a parametric approximation of $Z$, $q_{\\phi}(y_i|Z)$ is a variational approximation of the true distribution $p(y_i|Z)$, and $r(Z)$ approximates the marginal distribution $p(Z)$."}, {"title": "3 PROPOSED METHODS", "content": "In this section, we present our framework Seq2Exp. We first present our motivation for predicting gene expression with learnable extraction of effective regulatory elements. We illustrate the causal relationship among regulatory elements, epigenomic signals and DNA sequences as shown in Figure 1. Motivated by this structural causal model (SCM) (Pearl, 2009; Pearl et al., 2000; Wu et al., 2022), our framework provides a learnable approach to effectively extract effective regulatory elements, considering both DNA sequences and epigenomic signals, through an information bottleneck mechanism."}, {"title": "3.1 CAUSAL RELATIONSHIP AMONG REGULATORY ELEMENTS, DNA SEQUENCE AND EPIGENOMIC SIGNALS", "content": "The interactions between target gene and regulatory elements are complex, particularly when multiple potential regulatory elements are involved. Meanwhile, long sequences and distal interactions require a large search region, further complicating the discovery of effective regulatory elements that influence target gene expression. In this study, we take use of epigenomic signals $X_{sig}$ from laboratory experiments as well as the DNA sequence $X_{seq}$ for target gene expression $Y$, and formulate their relationships with the proposed three categories of regulatory elements.\n\u2022 $R_g$: Regulatory elements that have the potential to interact with target gene. However, they might not influence target gene expression if they are inactive in a specific cell type or are distant from the target gene.\n\u2022 $R_m$: Regulatory elements discovered from measurement. Typically, the region with strong measured epigenomic signals, such as peaks in DNase-seq, are more likely to influence the gene expression. However, there are usually multiple genes within a sequence and the association of $R_m$ with target gene remains unknown.\n\u2022 $R_{ag}$: Regulatory elements actively interacted with target gene. It is identified as the causal component for the final target gene expression $Y$.\nThe causal relationship between these variables is depicted in Figure 1. Note that each variable corresponds to a distribution and link represents a causal connection. The flow of this SCM illustrates the perspective of data generation.\n\u2022 $X_{seq} \\leftarrow R_g$. The DNA sequence consists of $R_g$ and other non-causal parts.\n\u2022 $R_{ag} \\rightarrow Y$. The causal part $R_{ag}$ directly influences the final gene expression. For example, an active enhancer interacting with a gene can significantly impact its expression.\n\u2022 $R_g \\rightleftarrows R_{ag} \\rightarrow R_m$. The key causal component $R_{ag}$ is shared by both $R_g$ and $R_m$. It can be detected through epigenomic signals in laboratory experiments and also participates in interactions with the target gene."}, {"title": "3.2 TASK OBJECTIVE", "content": "Based on information bottleneck, Equation 2 describes how to learn compressed representations $Z$ rather than selecting specific sub-sequences. To directly select regulatory elements, we define the latent representations as $Z = M \\odot X$, where $M$ is a binary variable controlling the selection of each DNA base or a soft mask $M$ indicating the importance of each DNA base. We assume that each selection is independent given the input sequence $X$, i.e., $p(M|X) = \\Pi_i p(m_i|X)$. Following the method of Paranjape et al. (2020), the objective becomes:\n$L \\approx \\frac{1}{N} \\sum_{i=1}^N \\mathbb{E}_{p_{\\theta}(m_i | x_i)}[ -\\log q_{\\phi}(y_i | m_i \\odot x_i)] + \\beta K L[p_{\\theta}(m_i|x_i), r(m_i)], \\qquad (3)$\nwhere the first term is the task-specific loss, such as mean square error in DNA gene expression prediction, and the second term imposes a constraint on the learned mask $m$, aligning it with the predefined distribution $r(m)$ without conditioning on any specific sequence $x$. In our case, we use this second term to enforce sparsity in the learned regulatory elements."}, {"title": "3.3 DECOMPOSITION OF SEQUENCES AND SIGNALS", "content": "By using information bottleneck shown in Equation 3, our primary focus is on estimating $p_{\\theta}(M|X)$, i.e., learning the mask from the input sequences. Given that the input $X$ consists of both DNA sequences and epigenomic signals, we need to estimate $p_{\\theta}(M|\\{X_{seq}, X_{sig}\\})$.\nAssumption 1 (Conditional Independence of Sequences and Signals). We assume that, conditioned on the selection of regulatory elements $M$, the DNA sequences and epigenomic signals are conditional independent to each other, i.e.,\n$p(X_{sig}, X_{seq}|M) = p(X_{sig}|M)p(X_{seq}|M) \\qquad (4)$\nAssumption 1 is based on the causal relationships outlined in Section 3.1. The selected sub-sequences of a full given sequence, represented by $M \\odot X$, can be viewed as the optimal regulatory elements ($R_{ag}$) for a specific gene in a particular cell type. From a data generation perspective, both the regulatory elements detected through measurements ($R_m$) and those interacting with the gene ($R_g$) originate from the optimal regulatory elements ($R_{ag}$). Therefore, given the optimal regulatory elements, the distributions $p(X_{sig}|M)$ and $p(X_{seq}|M)$ should be independent of each other.\nProposition 1. Based on Assumption 1, the estimation of $p_{\\theta}(M|X)$ can be decomposed into terms involving $X_{seq}$ and $X_{sig}$. Specifically, we have\n$p_{\\theta}(M|X) \\propto p_{\\theta_1}(M|X_{seq})p_{\\theta_2}(M|X_{sig}), \\qquad (5)$\nwhere $p_{\\theta_1}(M|X_{seq})$ and $p_{\\theta_2}(M|X_{sig})$ represent the contributions from the DNA sequence and the epigenomic signals, respectively.\nThe detailed proof of this decomposition is provided in Appendix A.1. Proposition 1 allows us to factorize the estimation of $p_{\\theta}(M|X)$ into two independent components, corresponding to the DNA sequence $X_{seq}$ and the epigenomic signals $X_{sig}$. As a result, we can independently estimate $p_{\\theta_1}(M|X_{seq})$ and $p_{\\theta_2}(M|X_{sig})$, which simplifies the overall estimation process. This decomposition is based on the assumption that, conditioned on the selection of regulatory elements $m$, the DNA sequences and epigenomic signals are independent, thus enabling more efficient and targeted modeling of each component."}, {"title": "3.4 MASK DISTRIBUTION", "content": "With the conditional independence property shown in Proposition 1, the estimation of the mask $M$ can be decomposed into two components: one based on DNA sequences $p_{\\theta_1}(M|X_{seq})$ and the other on epigenomic signals $p_{\\theta_2}(M|X_{sig})$. We assume that both components follow the Beta distribution, as described in Assumption 2. The sampled values from the Beta distribution represent the probability of selecting specific base pairs from a DNA sequence."}, {"title": "3.5 SPARSE OBJECTIVE", "content": "In this part, we focus on the mask prior distribution $r(m)$. From the objective in Equation 3, the KL divergence between $p_{\\theta}(m_i|x_i)$ and $r(m_i)$ needs to be computed. To simplify this calculation, we assume the prior distribution of the soft mask $r(m_s)$ follows the Beta distribution as well. Therefore, we have $r(m_s) \\sim Beta(\\alpha_3, \\beta_3)$, where $\\alpha_3$ and $\\beta_3$ are related to the sparsity of mask.\nThe expectation of the Beta distribution is\n$\\mathbb{E}[m_s] = \\mu \\approx \\frac{\\alpha_3}{\\alpha_3 + \\beta_3}, \\qquad (7)$\nwhere $\\mu$ approximately represents the proportion of regulatory elements within the DNA sequences. Therefore, by setting the hyperparameters $\\alpha_3$ and $\\beta_3$, the sparsity of the mask is taken into consideration, acting as a bottleneck to filter out non-causal parts."}, {"title": "4 MODEL DESIGNS", "content": "As shown in Figure 2, our proposed model generate the mask distribution $p_{\\theta} (M|X)$ from the DNA sequences and epigenomic signals $X = \\{X_{seq}, X_{sig}\\}$, and an predictor, $q_{\\phi} (Y|M \\odot X)$, provides gene expression values from the masked sequences $Z = M \\odot X$. Those two modules will be trained together.\nGenerator. As outlined in Section 3.4, we aim to generate a mask $M$ to identify the critical regions within the DNA sequences. To achieve this, we first learn a soft mask $m_s$, which is a probabilistic representation of each base pair's relevance, where $m_s \\in [0, 1]$. The soft mask is modeled using the Beta distribution, whose parameters $\\alpha_1, \\alpha_2, \\beta_1, and \\beta_2$ are estimated from the combination of DNA sequences and epigenomic signals, as detailed in Proposition 2."}, {"title": "4.2 OPTIMIZATION", "content": "To optimize the loss function introduced in Equation 3, it is essential that every step remains differentiable to allow for gradient-based optimization during training. After obtaining the parameters"}, {"title": "5 EXPERIMENTS", "content": null}, {"title": "5.1 SETTINGS", "content": null}, {"title": "5.1.1 DATASETS AND INPUT FEATURES", "content": "In this study, we aim to predict gene expression by modeling CAGE values, as it serves as key indicators of gene expression levels. Since gene expression varies across different cell types, we focus on two well-studied cell types: K562 and GM12878, both commonly used in biological research. The CAGE data are sourced from the ENCODE project (Consortium et al., 2012), and we follow the methodology of Lin et al. (2024) to predict gene expression values for 18,377 protein-coding genes.\nFor the input data, we utilize the HG38 human reference genome to provide the reference DNA sequences. Additionally, the model incorporates several types of epigenomic signals:\n\u2022 DNase-seq data is used to capture chromatin accessibility by identifying regions of the genome that are open and accessible to transcription factors and other regulatory proteins. The signals are extracted from bigWig files, providing genome-wide distributions of chromatin accessibility.\n\u2022 H3K27ac ChIP-seq data is used to detect histone modifications, specifically the acetylation of lysine 27 on histone H3, which is often associated with active enhancers and promoters. This data is also extracted from bigWig files to provide genome-wide information on histone modification patterns.\n\u2022 Hi-C data is processed to calculate the contact frequencies between each base pair and the target transcription start site (TSS), following the ABC pipeline method as described by Fulco et al. (2019).\nFurthermore, we incorporate additional features such as mRNA half-life and promoter activity from previous studies (Lin et al., 2024), which improve the model's prediction accuracy on gene expression levels. The detailed information about these signals can be found in Appendix A.3."}, {"title": "5.1.2 BASELINES", "content": "To benchmark our model's performance, we compare it against several well-established baselines in gene expression prediction:"}, {"title": "5.1.3 EVALUATION METRICS", "content": "We employ the following evaluation metrics to assess the performance of our model and baselines on the gene expression regression task: Mean Squared Error (MSE) measures the average squared difference between the predicted and target gene expression values, capturing large deviations strongly. Mean Absolute Error (MAE) evaluates the absolute differences between predicted and actual values, providing a more direct measure of average prediction error. Pearson Correlation is used to assess the linear correlation between the predicted and actual gene expression values, reflecting how well the model captures the relative ordering of gene expression. While MSE and MAE focus on the absolute errors in predictions, Pearson Correlation assess the model's ability to capture relative ranking and overall trends in the data."}, {"title": "5.1.4 IMPLEMENTATION DETAILS", "content": "We evaluate model performance using a cross-chromosome validation strategy. The model is trained on all chromosomes except those designated for validation and testing. Specifically, chromosomes 3 and 21 are used as the validation set, and chromosomes 22 and X are reserved for the test set. The inclusion of chromosome X is particularly challenging due to its unique biological characteristics compared to autosomes, thus providing a more stringent test of the model's robustness.\nBoth generator $p_{\\theta}$ and predictor $q_{\\phi}$ are based on Caduceus architecture (Schiff et al., 2024), an advanced long-sequence model considering the bi-direction and RC-equivariance for DNA. Specifically, we train for 50,000 steps on a 4-layer Caduceus architecture from scratch with a hidden dimension of 128, and more hyperparameters can be found in the Appendix A.4\nAll experiments were conducted on a system equipped with an NVIDIA A100 80GB PCIe GPU.\nThe input sequences consist of 200,000 base pairs, centered around the promoter regions of the target genes, providing sufficient contextual information for accurate gene expression prediction."}, {"title": "5.2 RESULTS OF GENE EXPRESSION PREDICTION", "content": "Table 1 presents the gene expression results based on CAGE values. Enformer, HyenaDNA, Mamba, and Caduceus are all DNA sequence-based methods, relying solely on DNA sequences without incorporating epigenomic signals. Among these, Caduceus achieves the best performance. We"}, {"title": "5.3 COMPARISON WITH PEAK DETECTION METHOD", "content": "Table 2 compares the performance of Seq2Exp with regions identified through peak calling by MACS3 (Zhang et al., 2008) on DNase-seq epigenomic signals. While DNase-seq is a crucial technique for identifying the positions of regulatory elements, statistical peak-calling methods, such as MACS3, can be considered a simple approach for measuring these elements. Our results show that Seq2Exp significantly outperforms MACS3 in terms of predictive performance. Seq2Exp-hard utilizes a hard binary mask. Seq2Exp-retrain builds on a soft mask, and explicitly select the top 10% of base pairs and retrain the predictor model using only the selected ones. Both models outperform MACS3, suggesting the ability of discovering regulatory elements."}, {"title": "6 CONCLUSION", "content": "In this work, we introduced Seq2Exp, a framework for gene expression prediction that learns critical regulatory elements from both DNA sequences and epigenomic signals. By generating a binary mask to identify relevant sub-sequences, Seq2Exp reduces input complexity and focuses on key regions for prediction. Our experiments demonstrate its effectiveness in identifying important regulatory elements and improving predictive performances, though current evaluations are limited to two cell types and several epigenomic signals.\nFor the future direction, expanding the framework to more cell types and integrating diverse epigenomic data will be important for validating its generalizability. Beyond gene expression, applying this approach to other tasks related to regulatory element discovery and sequence analysis presents exciting research opportunities. Developing pretraining models focused on regulatory element extraction could also advance the field, enhancing generalization across genomic tasks."}, {"title": "A APPENDIX", "content": null}, {"title": "A.1 DERIVATION OF SEQUENCE AND SIGNAL DECOMPOSITION", "content": "For the mask distribution $p_{\\theta}(m|X)$, we aim to decompose it. For simplicity, we omit the parameter $\\theta$ in the following derivation. By applying Bayes' theorem, we obtain\n$p(m|X) = p(m|X_{seq}, X_{sig}) \\\\\n= \\frac{p(X_{seq}, X_{sig}|m)p(m)}{p(X_{seq}, X_{sig})} \\qquad (10)\\\\\n\\propto p(X_{seq}|m)p(X_{sig}|m)p(m),$\nwhere $p(X_{seq}, X_{sig}|m) = p(X_{seq}|m)p(X_{sig}|m)$ is based on Assumption 1, and $p(X_{seq}, X_{sig})$ represents the input data, which is independent of the learning process.\nApplying Bayes' theorem again to $p(X_{seq}|m)$ and $p(X_{sig}|m)$, we have\n$p(m/X) \\propto p(X_{seq}|m)p(X_{sig}|m)p(m) \\\\\n= \\frac{p(m | X_{seq})p(X_{seq}) p(m|X_{sig})p(X_{sig})}{p(m)}p(m) \\\\\n\\propto \\frac{p(m | X_{seq})p(m|X_{sig})}{p(m)} \\qquad (11)$\nwhere we can safely omit $p(X_{seq})$ and $p(X_{sig})$. For the marginal distribution $p(m)$, we make it to be a prior distribution with constant predefined parameters, allowing us to omit it as well. Thus, we derive\n$p(m|X) \\propto p(m/X_{seq})p(m|X_{sig}), \\qquad (12)$\nwhich corresponds to Proposition 1."}, {"title": "A.2 BETA DISTRIBUTION PRODUCT", "content": "The probability density function for a Beta distribution is given by\n$Beta(x; \\alpha, \\beta) \\propto x^{\\alpha-1}(1 - x)^{\\beta-1}. \\qquad (13)$\nGiven that both $p(m_s|X_{seq})$ and $p(m_s|X_{sig})$ follow a Beta distribution, we have\n$p(m_s | X_{seq}) \\propto x^{\\alpha_1-1}(1 - x)^{\\beta_1-1}, \\qquad (14)$\n$p(m_s | X_{sig}) \\propto x^{\\alpha_2-1}(1 - x)^{\\beta_2-1}.$\nMultiplying these distributions yields\n$p(m_s | X_{seq})p(m_s | X_{sig}) \\propto x^{\\alpha_1 + \\alpha_2 - 2}(1 - x)^{\\beta_1 + \\beta_2 - 2} \\\\\n\\sim Beta(m_s; \\alpha_1 + \\alpha_2 - 1, \\beta_1 + \\beta_2 - 1). \\qquad (15)$\nNote that the parameters of a Beta distribution must lie within the range (0,\u221e), thus we require $\\alpha_1 + \\alpha_2 > 1$ and $\\beta_1 + \\beta_2 > 1$ to ensure a valid distribution."}, {"title": "A.3 DATA PROCESSING", "content": "The gene expression is different for different cell types. In this work, we consider the well-studied cell type K562 and GM12878.\nCAGE. Cap Analysis of Gene Expression (CAGE) is the primary target for prediction in this work. Each gene is assigned a CAGE value to quantify its expression level. CAGE is a high-throughput sequencing technique primarily used to map transcription start sites (TSS) and quantify gene expression. It provides a comprehensive profile of promoter usage and alternative TSS across different genes, quantifying the number of RNA molecules initiating at each TSS, thereby reflecting gene transcriptional activity."}, {"title": "A.4 EXPERIMENT SETUP", "content": "Here we present some hyperparameters values and their search space in Table 3."}, {"title": "A.5 EXPERIMENT RESULTS", "content": "Based on Table 1 and Table 2, here we present the experimental results with standard deviation in Table 4 and Table 5. The results are from five runs of different random seeds: {2,22,222,2222,22222}."}]}