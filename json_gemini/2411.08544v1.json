{"title": "Deeper Insights into Learning Performance of Stochastic Configuration Networks", "authors": ["Xiufeng Yan", "Dianhui Wang"], "abstract": "Stochastic Configuration Networks (SCNs) are a class of randomized neural networks that integrate randomized algorithms within an incremental learning framework. A defining feature of SCNs is the supervisory mechanism, which adaptively adjusts the distribution to generate effective random basis functions, thereby enabling error-free learning. In this paper, we present a comprehensive analysis of the impact of the supervisory mechanism on the learning performance of SCNs. Our findings reveal that the current SCN framework evaluates the effectiveness of each random basis function in reducing residual errors using a lower bound on its error reduction potential, which constrains SCNs' overall learning efficiency. Specifically, SCNs may fail to consistently select the most effective random candidate as the new basis function during each training iteration. To overcome this problem, we propose a novel method for evaluating the hidden layer's output matrix, supported by a new supervisory mechanism that accurately assesses the error reduction potential of random basis functions without requiring the computation of the Moore-Penrose inverse of the output matrix. This approach enhances the selection of basis functions, reducing computational complexity and improving the overall scalability and learning capabilities of SCNs. We introduce a Recursive Moore-Penrose Inverse-SCN (RMPI-SCN) training scheme based on the new supervisory mechanism and demonstrate its effectiveness through simulations over some benchmark datasets. Experiments show that RMPI-SCN outperforms the conventional SCN in terms of learning capability, underscoring its potential to advance the SCN framework for large-scale data modeling applications.", "sections": [{"title": "I. INTRODUCTION", "content": "NEURAL Networks (NNs) have achieved significant advancements in recent decades, primarily due to their universal approximation capabilities for modeling complex nonlinear mappings [1]\u2013[4] and their effectiveness in learning from data. Despite the strengths, traditional gradient-based training methods, such as Backpropagation (BP), face challenges including high computational costs, vulnerability to local minima, and sensitivity to hyperparameters. In contrast, randomized learning algorithms [5]-[10] offer substantial advantages for constructing fast learner models with significantly lower computational costs. Randomized training typically follows a two-step paradigm: first, random basis functions are generated, with input weights and biases drawn from a specified distribution; second, the output weights are optimized using least squares. Igelink and Pao [5] provided a theoretical justification for Random Vector Functional-links (RVFLs), demonstrating that when input weights and biases are randomly selected from a uniform distribution centered at zero and the output weights are optimized via least squares, RVFLs act as universal approximators in a probabilistic sense. The underlying idea is that if the target function can be represented as the integral of parametrized basis functions, then randomly sampling parameters from appropriate distributions can yield an accurate approximation. Recently, Needell et.al. [11] revisited and extended this significant result, using a concentration inequality to bound the accuracy of Monte-Carlo integral approximations in non-asymptotic settings. Compared with gradient-based training methods, randomized learning algorithms present a distinctive advantage: by employing least squares optimization, they avoid the computational complexity associated with iterative gradient-based searches, presenting a promising solution for building fast and efficient learner models. For practical implementations, RVFL requires two parameters: the number of hidden nodes and the radius of the uniform distribution's support. Tyukin and Prokhorov [12] and Li and Wang [13] have argued that these parameters should be data-dependent. Without a supervisory mechanism to adaptively adjust the distribution's support, the approximation capability of RVFL may be constrained, potentially resulting in limited learning and generalization performance.\nStochastic Configuration Networks (SCNs), introduced by Wang and Li in [14], are a class of randomized learning models within an incremental learning framework. In each training iteration, input weights and biases are randomly selected from uniform distributions to generate candidate random basis functions. SCNs then evaluate the effectiveness of each random basis function in reducing the training residual error using the inequality ${||e_L||}^2 < r{||e_{L-1}||}^2$, where r represents the learning"}, {"title": "II. RELATED WORK", "content": "Let $f: R^n \\rightarrow R$ denote the target function, and let $f_{L-1}$ represent a Single Layer Feedforward Neural Network (SLFNN) comprising $L-1$ hidden nodes, expressed as follows:\n${f_{L-1}(x) = \\sum_{i=1}^{L-1} \\beta_i g_i(x)}$\n${g_i(x) = \\sigma_i (w_i^T x + b_i),  1 \\leq i \\leq L - 1.}$\nHere, $\\sigma_i$, $w_i$, $b_i$, and $\\beta_i$ correspond to the activation function, input weight, bias, and output weight associated with the $i$-th basis function $g_i$, respectively. The primary objective of incremental learning is to establish criteria for selecting the next basis function $g_L$, such that the sequence of residual errors ${e_L}$, where $e_L = f - f_L$, converges to zero. The following result from Wang and Li [14] demonstrates the universal approximation property of SCNs.\nTheorem 1 [14]. Let $K$ be a compact subset of $R^n$. Suppose $\\Gamma$ is a collection of basis functions that are bounded in $L^2(K)$ and that $span(\\Gamma)$ is dense in $L^2(K)$. Let $0 < r < 1$ and ${u_L}$ be a sequence of nonnegative real numbers that converges to 0, satisfying $u_L < 1 - r$ for each $L$. Define the residual as $e_{L-1} = f - f_{L-1}$, and let:\n$\\delta_1 = (1 - r - u_1){||e_{L-1}||}^2.$\nIf the random basis function $g_L$ satisfies the inequality:\n${\\frac{(e_{L-1}, g_L)^2}{||g_L||^2} \\geq \\delta_L,}$\nand the output weights are evaluated as:\n${\\beta_L = \\frac{(e_{L-1}, g_L)}{||g_L||^2},}$\nthen, we have $lim_{L \\rightarrow \\infty} {||e_L||} = 0$, where $f_L = \\sum_{i=1}^{L} \\beta_i g_i$ and ${|| \\cdot ||}$ denotes the $L^2$ norm.\nNote that Theorem 1 ensures the universal approximation property of SCN at the algorithmic level, distinguishing it from the mathematical formulation of RVFL in [5]. The density of $span(\\Gamma)$ guarantees the existence of basis function $g_L$ satisfying the inequality in Eq. (4) for some $r$ close to 1. The inequality constraint in Eq. (4) serves two fundamental roles. First, since $u_L \\rightarrow 0$ as $L \\rightarrow \\infty$ and $r < 1$, there exists a threshold $L_0$ such that for all $L > L_0$, $r + u_L < r^* < 1$ holds. This condition ensures that $lim_{L \\rightarrow \\infty} \\frac{{||e_L||}}{||e_{L-1}||} \\leq \\sqrt{r^*}$, meaning that the residual errors converge at a rate of at least $\\sqrt{r^*}$. Second, the inequality evaluates the capability of the current uniform distribution to generate random basis functions that meet the error reduction criterion ${||e_L||} \\leq \\sqrt{r}{||e_{L-1}||}$"}, {"title": "III. THE SUPERVISORY MECHANISM OF SCN-III", "content": "In this section, we systematically address the concerns regarding the supervisory mechanism of SCN-III in three steps. In subsection 3.1, we derive a necessary and sufficient condition for a basis function $g$ with output $h$ to satisfy ${||Y - H_L H_L^\\dagger Y||} \\leq \\sqrt{r}{||e_{L-1}||}$ in SCN-III. The derivation is based on recursive calculations of the Moore-Penrose inverse.Building on these conditions, we propose a new supervisory mechanism for SCN-III in subsection 3.2, which further incorporates a hyperparameter $\\alpha$ to control the increase of $r$ as $L\\rightarrow \\infty$. Subsection 3.3 details the algorithm of Recursive Moore-Penrose Inverse Stochastic Configuration Network (RMPI-SCN).\nA. The inequality constraint of SCN-III\nConsider a batch of basis functions ${g_l}_{l=1}^{T_{max}}$ with corresponding outputs on training samples ${h_l}_{l=1}^{T_{max}}$. Let $H_{L,l} = [H_{L-1}, h_l]$ for $1 \\leq l \\leq T_{max}$, where $H_{L-1}$ represents the hidden layer output matrix from the previous iteration. The main objective of SCN-III is to select $h_l$ by $min_{1\\leq l \\leq T_{max}} {||H_{L,l} H_{L,l}^\\dagger Y - Y||}$.Directly calculating ${||H_{L,l} H_{L,l}^\\dagger Y - Y||}$ by computing $H_{L,l}^\\dagger$ for each $l$ becomes computationally infeasible, particularly in large-scale data modeling. Nevertheless, since SCN is an incremental learning framework and $H_{L-1}^\\dagger$ has been calculated in the previous iteration, recursive methods for calculating the Moore-Penrose inverse can significantly reduce the computational burden.\nThe following theorem presents a necessary and sufficient condition for ${||e_L||} \\leq \\sqrt{r}{||e_{L-1}||}$ in incremental learning with SLFNN. For brevity, we first present the case where the training output $Y = [y_1, y_2, ..., y_N]^T$ with $y_t \\in R$ for $1 \\leq t \\leq N$. The extension to the general case where $y_t \\in R^m$ is straightforward and will be presented in Corollary 2.\nTheorem 2. Suppose that $X$ and $Y$ are the training inputs and outputs respectively, where $X = [x_1, x_2, ..., x_N]^T$, $Y = [y_1, y_2, ..., y_N]^T$ and $x_t \\in R^d$, $y_t \\in R$, for $1 \\leq i \\leq N$. Given an activation function $\\sigma$ and $0 < r < 1$, the current training error is $e_{L-1} = Y - H_{L-1} H_{L-1}^\\dagger Y$ and $e_{L-1} \\neq 0$, where $H_{L-1}^\\dagger$ is the Moore-Penrose inverse of $H_{L-1}$, with $H_{L-1} = [h_1, h_2, ..., h_{L-1}]$ and $h_i = \\sigma(Xw_i + b_i)$, $1 \\leq i \\leq L - 1$. Suppose that $h$ is the output of a candidate basis function $g$ on $X$. Define $H_L$, $\\delta_L$, and $p_L$ as:\n$H_L = [H_{L-1}, h]$,\n$\\delta_L = \\frac{(e_{L-1}, p_L)^2}{||p_L||^2} - (1 - r){||e_{L-1}||}^2,$\n$p_L = h - H_{L-1} H_{L-1}^\\dagger h.$\nThen, ${||Y - H_L H_L^\\dagger Y||} \\leq \\sqrt{r}{||e_{L-1}||}$ if and only if\n$p_L \\neq 0,$\n${\\frac{(e_{L-1}, p_L)^2}{||p_L||^2}} \\geq (1-r){||e_{L-1}||}^2,$\n${|| \\langle Y - e_{L-1}, p_L \\rangle ||} \\leq \\sqrt{\\delta_L}.$\nIn particular, if $p_L \\neq 0$, then\n${||Y - H_L H_L^\\dagger Y|| = ||e_{L-1} - \\frac{(p_L, Y)}{||p_L||^2}p_L||}$", "B. A supervisory mechanism with controlled learning rate r": "The parameter $r$ directly determines the evaluation of the candidates of basis functions in each iteration of the training of SCN through the inequality ${||e_L||} \\leq \\sqrt{r}{||e_{L-1}||}$. It not only ensures the rate of convergence but also determines whether the support of the uniform distribution should be expanded. The common approach is to iteratively search for $r$ within a sequence starting from 0.9 to 1. As the size of the network increases, finding a random basis function that satisfies the inequality ${||e_L||} \\leq \\sqrt{r}{||e_{L-1}||}$ becomes more difficult. To address this challenge, an upper bound $r_{max}$ close to one is often set to ensure there are candidate functions available as the network grows. However, increasing $r$ does not inherently improve the capacity of random basis functions to reduce training errors; rather, it merely lowers the error reduction requirement. Fixing this requirement by imposing ${||e_L||} \\leq \\sqrt{r_{max}}{||e_{L-1}||}$ at each iteration limits the SCN's ability to adaptively explore optimal random weights, potentially leading to inefficient learning.\nTo resolve these issues, we propose a mechanism that gradually increases $r$ in accordance with network size, while ensuring convergence of training residual errors. This adaptive mechanism incorporates a hyperparameter $\\alpha$, which modulates the rate of $r$'s increase based on the complexity of the data. Given $0 < r < 1, 0 < \\alpha$, if ${x_L}$ is a sequence of non-negative real numbers such that $x_L < r^{(1+1/L)^\\alpha} x_{L-1}$ for each $L$, then $lim_{L\\rightarrow \\infty} x_L = 0$ evidently since\n$lim_{L\\rightarrow \\infty} \\frac{x_L}{x_{L-1}} \\leq lim_{L \\rightarrow \\infty} r^{(1+1/L)^\\alpha} = r^\\alpha.$\nBesides, $r^{(1+1/L)^\\alpha}$ is a monotone increasing function with respect to $L$, and its supremum is $r^\\alpha$. By controlling the rate at which $r$ increases using $\\alpha$, we ensure that the SCN can dynamically adjust the range of random weights explored, balancing computational efficiency and model performance. The hyperparameter $\\alpha$ thus provides a flexible means to control the speed of convergence, adapting to the complexity of the data being modeled.\nSpecifically, the logarithm of $r^{(1+1/L)^\\alpha}$ is $\\alpha (1 + 1/L) ln r$, whose derivative with respect to $L$ is $- \\alpha \\frac{ln r}{L^2}$. This means that a higher value of $\\alpha$ causes $r$ to converge more rapidly to $r^\\alpha$, allowing the model to relax the error reduction constraint at a faster rate as the network size grows. In practice, this provides a flexible way to adjust the learning rate based on the complexity of the data and the depth of the network, ensuring a more efficient search for suitable random basis functions as the model trains.\nWe now embed the design of $r^{(1+1/L)^\\alpha}$ into the inequality constraints established in Corollary 2 to present the following Corollary 3.\nCorollary 3. Suppose that $X$ and $Y$ are the training inputs and outputs respectively, where $X = [x_1, x_2, ..., x_N]^T$, $Y = [y_1, y_2, ..., y_N]^T$ and $x_t \\in R^d$, $y_t \\in R^m$, $1 \\leq t \\leq N$. Given a fixed activation function $\\sigma$ and $0 < r < 1$, let the current", "C. Algorithm description": "This subsection details the algorithmic structure of the proposed Recursive Moore-Penrose Inverse SCN (RMPI-SCN). The general training diagram of SCN consists of two main components: configuration of random basis functions and evaluation of output weights. The proposed RMPI-SCN differs from SCN-III in the following respects.\nFirst, RMPI-SCN cancels the inner iterative searching for $r$ and applies the design $r_L = r^{(1+1/L)^\\alpha}$ in Corollary 3. This ensures adaptive learning while reducing computational overhead by systematically increasing $r$ as the network grows. Second, it adopts the constraints in Eq. (50)-(51). These new constraints enhance the selection of random basis functions, providing a more efficient method for reducing training errors while maintaining theoretical guarantees for convergence. Third, it requires an initialization for the first basis function $g_1$ and the Moore-Penrose inverse $h_1^\\dagger$ of its output $h_1$. This initialization is crucial for ensuring that the subsequent steps of RMPI-SCN build on a stable foundation, setting the stage for efficient training and accurate function approximation. We first present the pseudocode for the RMPI-SCN in the following and then detail the involved calculations.\nGiven a basis function $g = \\sigma(w^T x + b)$, $x \\in R^d$ with the input weight $w = [w_1, ..., w_d]$ and bias $b$,\n$h = g(X) = [\\sigma(w^T x_1 + b_j), ..., \\sigma(w^T x_N + b_j)],  h \\in R^N.$\nDenote the $q$-th column of $Y$ as $Y_q$ where $Y_q = [y_{1,q}, y_{2,q}, ..., y_{N,q}]^T$.\nFor the initialization of RMPI-SCN, $h_j^\\dagger$ is evaluated through $w_j$; where", "IV. SIMULATION RESULTS": "This section reports the performance of Recursive Moore-Penrose Inverse SCN (RMPI-SCN) across ten regression tasks, including two function approximation examples [12, 28] and eight benchmark datasets from UCI and KEEL. The benchmark datasets were downloaded from the KEEL and UCI repositories. Each dataset is divided into training, validation, and test sets in a ratio of 6:2:2, followed by normalization to ensure consistent scales across features. The performance of RMPI-SCN is compared against SCN-III, RVFL, and a Multi-Layer Perceptron (MLP) trained using Backpropagation (BP). Hyperparameters for each model were selected through cross-validation. In particular, the number of nodes for the MLP was chosen from the set 5, 10, 15, 20, 25, 30, 50 using cross-validation techniques. An early stopping strategy was implemented to evaluate model performance before overfitting on the validation sets. Each model's performance was assessed through 100 independent experiments, employing the logistic sigmoid function as the activation function. The functions for the approximations, DB1 and DB2, are described as follows:\nDB1: DB1 consists of 1500 samples from a regularly spaced grid on [0,1], drawn from\n$f(x) = 0.2e^{-(10x-4)^2} + 0.5e^{-(80x-40)^2} + 0.3e^{-(80x-20)^2}$.\nDB2: DB2 is sampled from a classic nonlinear model in system identification given by:\n$y(k + 1) = f[y(k), y(k - 1), y(k \u2013 2), u(k), u(k \u2013 1)]$,\nwhere\n$f(x_1, x_2, x_3, x_4, x_5) = \\frac{x_1 x_2 x_3 x_5 (x_4 - 1)}{1 + x_2^2 + x_3^2}.$\nThe training samples and validation samples of DB2 are generated through 2400 iterations of random signals $u$ uniformly distributed over [-1,1]. The 600 test samples for DB2 are obtained through the function:\nDB3-DB10 are benchmark datasets downloaded from KEEL and UCI."}, {"title": "V. CONCLUSION", "content": "In this paper, we employ the recursive calculation of the Moore-Penrose inverse to derive necessary and sufficient conditions for the training residuals to satisfy ${||e_L||} \\leq \\sqrt{r}{||e_{L-1}||}$ for each $L$ in SCN-III, the benchmark algorithm of SCN. This condition not only theoretically ensures convergence of training residuals as a geometric sequence but also enables rapid and accurate evaluations of random basis functions' effectiveness in training error reductions, without necessitating the computation of the Moore-Penrose inverse of the output matrix of the hidden layer. Based on the conditions established, we propose the Recursive Moore-Penrose Inverse-SCN (RMPI-SCN). Compared to the classic SCN-III, the inequality constraint of RMPI-SCN consistently selects the most effective random candidate for the new basis function in each training iteration. This advancement not only ensures a faster convergence rate but also provides a more accurate assessment of the current uniform distribution's capacity to yield suitable random basis functions. Simulation results across ten datasets confirm that RMPI-SCN outperforms SCN-III, exhibiting faster convergence rates and enhanced learning capabilities, particularly evident in the reduced training RMSE and higher correlation coefficients. Specifically, RMPI-SCN demonstrates significant improvements in function approximation tasks, achieving lower error rates on critical datasets.\nFurther research avenues regarding the supervisory mechanism of SCN are plentiful. Notably, the adaptive control of the learning rater significantly impacts SCN's performance, making a data-driven approach to controlling r highly desirable. Moreover, the supervisory mechanism of SCN creates a subset in $L^2$ during each training iteration, where the basis functions within this subset contribute most effectively to reducing training errors. The mathematical exploration of this subset through probability measures or differential geometry could deepen our understanding of the learning and generalization capabilities of randomized learning models. Additionally, orthogonalizing the basis functions of SCN might yield interesting results regarding the model's interpretability, as it could facilitate clearer insights into how each function contributes to the overall prediction. Integrating optimization algorithms like PSO with the new inequality constraint may also significantly enhance SCN performance. Finally, this paper establishes a new inequality constraint for SCNs utilizing SLFNN. Future extensions of this constraint to other architectures, such as RSCNs, 2D-SCNs, and deep SCNs, present abundant opportunities for research."}]}