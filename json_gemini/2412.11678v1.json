{"title": "Loosely Synchronized Rule-Based Planning for Multi-Agent Path Finding with Asynchronous Actions", "authors": ["Shuai Zhou", "Shizhe Zhao", "Zhongqiang Ren"], "abstract": "Multi-Agent Path Finding (MAPF) seeks collision-free paths for multiple agents from their respective starting locations to their respective goal locations while minimizing path costs. Although many MAPF algorithms were developed and can handle up to thousands of agents, they usually rely on the assumption that each action of the agent takes a time unit, and the actions of all agents are synchronized in a sense that the actions of agents start at the same discrete time step, which may limit their use in practice. Only a few algorithms were developed to address asynchronous actions, and they all lie on one end of the spectrum, focusing on finding optimal solutions with limited scalability. This paper develops new planners that lie on the other end of the spectrum, trading off solution quality for scalability, by finding an unbounded sub-optimal solution for many agents. Our method leverages both search methods (LSS) in handling asynchronous actions and rule-based planning methods (PIBT) for MAPF. We analyze the properties of our method and test it against several baselines with up to 1000 agents in various maps. Given a runtime limit, our method can handle an order of magnitude more agents than the baselines with about 25% longer makespan.", "sections": [{"title": "1 Introduction", "content": "Multi-Agent Path Finding (MAPF) computes collision-free paths for multiple agents from their starting locations to destinations within a shared environment, while minimizing the path costs, which arises in applications such as warehouse logistics. Usually the environment is represented by a graph, where vertices represent the location that the agent can reach, and edges represent the transition between two locations. MAPF is NP-hard to solve to optimality (Yu and LaValle 2013), and a variety of MAPF planners were developed, ranging from optimal planners (Sharon et al. 2015; Wagner and Choset 2015), bounded sub-optimal planners (Barer et al. 2014; Li, Ruml, and Koenig 2021) to unbounded sub-optimal planners (Okumura et al. 2022; De Wilde, Ter Mors, and Witteveen 2013). These planners often rely on the assumption that each action of any agent takes the same duration, i.e., a time unit, and the actions of all agents are synchronized, in a sense that, the action of each agent starts at the same discrete time step. This assumption limits the application of MAPF planners, especially when the agent speeds are different or an agent has to vary its speed when going through different edges.\nTo get rid of this assumption on synchronous actions, MAPF variants such as Continuous-Time MAPF (Andreychuk et al. 2022), MAPF with Asynchronous Actions (Ren, Rathinam, and Choset 2021), MAPFR (Walker, Sturtevant, and Felner 2018) were proposed, and only a few algorithms were developed to solve these problems. Most of these algorithms lie on one end of the spectrum, finding optimal or bounded sub-optimal solutions at the cost of limited scalability as the number of agents grows. To name a few, Continuous-Time Conflict-Based Search (CCBS) (Andreychuk et al. 2022) extends the well-known Conflict-Based Search (CBS) to handle various action times and is able to find an optimal solution to the problem. Loosely Synchronized Search (LSS) (Ren, Rathinam, and Choset 2021) extends A* and M* (Wagner and Choset 2015) to handle the problem and can be combined with heuristic inflation to obtain bounded sub-optimal solutions. Although these algorithms can provide solution quality guarantees, they can handle only a small amount of agents (< 100) within a runtime limit of few minutes. Currently, we are not aware of any algorithm that can scale up to hundreds of agents in the presence of asynchronous actions. This paper seeks to develop new algorithms that lie on the other end of the spectrum, trading off solution optimality for scalability.\nWhen all agents' actions are synchronous, the existing MAPF algorithms, such as rule-based planning (Erdmann and Lozano-Perez 1987; Luna and Bekris 2011; De Wilde, Ter Mors, and Witteveen 2013; Okumura et al. 2022), can readily scale up to thousands of agents by finding an unbounded sub-optimal solution. However, extending them to handle asynchronous actions introduce additional challenges: Rule-based planning usually relies on the notion of time step where all agents take actions and plans forward in a step-by-step fashion. When the actions of agents are of various duration, there is no notion of planning steps, and one may have to plan multiple actions for a fast moving agent and only one action for a slow agent. In other words, an action with long duration of an agent may affect multiple subsequent actions of another agent, which thus complicates the interaction among the agents. To handle these challenges, we leverage the state space proposed in (Ren, Rathinam, and Choset 2021) where times are incorporated, and leverage Priority Inheritance with Backtracking (PIBT) (Okumura et al. 2022), a recent and fast rule-based planner, to this new state space. We introduce a cache mechanism to loosely synchronize the actions of agents during the search, when these actions have different, yet close, starting times. We therefore name our approach Loosely Synchronized Rule-based Planning (LSRP).\nWe analyze the theoretic properties of LSRP and show that LSRP guarantees reachability in graphs when the graph satisfies certain conditions. For the experiments, we compare LSRP against several baselines including CCBS (Andreychuk et al. 2022) and prioritized planning in various maps from a MAPF benchmark (Stern et al. 2019), and the results show that LSRP can solve up to an order of magnitude more agents than existing methods with low runtime, despite about 25% longer makespan. Additionally, our asynchronous planning method produces better solutions, whose makespan ranges from 55% to 90% of those planned by ignoring the asynchronous actions."}, {"title": "2 Problem Definition", "content": "Let set $I = \\{1,2,...,N\\}$ denote a set of $N$ agents. All agents move in a workspace represented as a finite graph $G = (V, E)$, where the vertex set $V$ represents all possible locations of agents and the edge set $E \\subset V \\times V$ denotes the set of all the possible actions that can move an agent between a pair of vertices in $V$. An edge between $u, v \\in V$ is denoted as $(u, v) \\in E$ and the cost of $e \\in E$ is a finite positive real number $cost(e) \\in R^+$. Let $v_i^s, v_i^g \\in V$ respectively denote the start and goal location of agent $i$.\nAll agents share a global clock and start moving from $v_i^s$ at $t = 0$. Let $D(i, v_1, v_2) \\in R^+$ denote amount of time (i.e., duration) for agent $i$ to go through edge $(v_1, v_2)$. Note that different agents may have different duration when traversing the same edge, and the same agent may have different duration when traversing different edges.\nWhen agent $i$ goes through an edge $(v_1, v_2) \\in E$ between times $(t_1, t_1 + D(i, v_1, v_2))$, agent $i$ is defined to occupy: (1) $v_1$ at $t = t_1$, (2) $v_2$ at $t = t_2$ and (3) both $v_1, v_2$ within the open interval $(t_1, t_1 + D(i, v_1, v_2))$. Two agents are in conflict if they occupy the same vertex at the same time. We refer to this definition of conflict as the duration conflict hereafter.\nLet $\\pi^i$ denote a path from $v_i^s$ to $v_i^g$ via a sequence of vertices $v \\in G$. Any two vertices $v_k^i$ and $v_{k+1}^i$ in $\\pi^i$ are either connected by edge $(v_k^i, v_{k+1}^i) \\in E$ or is a self-loop. Let $g(\\pi^i (v_i^s, v_i^g))$ denote the cost of the path, which is defined as the sum of duration of edges along the path. Let $\\pi = (\\pi^1, \\pi^2,...,\\pi^n)$ represent a joint path of all agents, and its cost is the sum of individual path costs of all the agents, i.e., $g(\\pi) = \\Sigma_i g(\\pi^i)$."}, {"title": "3 Preliminaries", "content": "Priority Inheritance with Backtracking (PIBT) plans the actions of the agents in a step-by-step manner until all agents reach their goals. PIBT assigns each agent a changing priority value. In each step, a planning function is called to plan the next action of the agents based on their current priorities. This planning function selects actions based on the individual shortest path to the goal of each agent, and actions toward a location closer to the goal are first selected. When two agents seek to occupy the same position, the higher-priority agent is able to take this location, and pushes the lower-priority agent to another less desired location. This function is applied recursively, where the pushed agent is planned next and inherits the priority of the pushing agent. When all agents' actions are planned for the current time step, PIBT starts a new iteration to plan the next time step.\nPIBT guarantees that the agent with the highest priority eventually reaches its goal, at which it becomes the lowest priority agent. Therefore, each agent becomes the highest priority agent at least once and is able to reach its goal at some time step. PIBT requires that for each vertex $v \\in G$, there is a cycle in $G$ containing $v$, so that PIBT can plan all agents to their goals. Otherwise, PIBT is incomplete, i.e., PIBT may not be able to find a feasible solution even if the instance is solvable. PIBT runs fast and can scale to many agents for MAPF. Our LSRP leverages the idea of PIBT to handle a large number of agents."}, {"title": "3.2 Loosely Synchronized Search", "content": "Loosely Synchronized Search (LSS) extends A* and M*-based approaches to solve MAPF-AA by introducing new search states that include both the locations and the action times (i.e., as timestamps) of the agents. Similarly to A*, LSS iteratively selects states from an open list, expands the states to generate new states, prunes states that are in-conflict or less promising, and adds remaining states to open for future expansion, until a conflict-free joint path for all agents is found from the starts to the goals. To expand a state, LSS only considers the agent(s) $i \\in I$ with the smallest timestamp and plan its actions, which increases the timestamp of agent $i$. In a future iteration, other agents $j \\neq i$ will be planned if the timestamp of $j$ becomes the smallest. Planning all agents together may lead to a large branching factor and LSS leverage M* to remedy this issue. LSS is complete and finds an optimal solution for MAPF-AA but can only handle a relatively small amount of agents. Our LSRP leverages the state definition and expansion in LSS to handle asynchronous actions."}, {"title": "3.3 Other Related Approaches", "content": "Safe Interval Path Planning (SIPP) (Phillips and Likhachev 2011) is a single-agent graph search algorithm that can find a path from start to goal with the minimum arrival time among dynamic obstacles along known trajectories. SIPP can be used together with priority-based planning to handle MAPF-AA. Specifically, each agent is assigned with a unique priority, and the agents are planned from the highest priority to the lowest using SIPP, where the planned agents are treated as dynamic obstacles. This priority-based method is used as a baseline in our experiments.\nAdditionally, CCBS (Andreychuk et al. 2022) is a two-level search algorithm that can be used to handle MAPF-AA. CCBS is similar to CBS (Sharon et al. 2015) for MAPF. The high-level search detects conflicts between any pair of agents, and resolves conflicts by generating constraints that forbid an agent from using certain vertices within certain time ranges. The low-level search uses SIPP to plan a single-agent path subject to the constraints added by the high-level. CCBS iteratively detects conflicts on the high-level and resolves conflicts using the low-level search until no conflict is detect along the paths. CCBS is guaranteed to find an optimal solution if the given problem instance is solvable. In practice, CCBS can handle tens of agents within a few minutes (Andreychuk et al. 2022). This paper uses CCBS as another baseline in the experiments."}, {"title": "4 Method", "content": ""}, {"title": "4.1 Notation and State Definition", "content": "Let $\\mathbb{G} = (\\mathbb{V}, \\mathbb{E}) = G \\times G \\times ... \\times G$ denote the joint graph, the Cartesian product of $N$ copies of $G$, where $v \\in \\mathbb{V}$ represents a joint vertex, and $e \\in \\mathbb{E}$ represents a joint edge that connects a pair of joint vertices. The joint vertices corresponding to the start and goal vertices of all the agents are $v_s = (v_1^s, v_2^s, ...., v_n^s)$ and $v_g = (v_1^g, v_2^g, ..., v_n^g)$ respectively. A joint search state (Ren, Rathinam, and Choset 2021) is $s = (s^1, s^2, . . ., s^n)$, where $s^i$ is the individual state of agent $i$, which consists of four components: (1) $p \\in V$, a (parent) vertex in $G$, from which the agent $i$ begin its action; (2) $v \\in V$, a vertex in $G$, at which the agent $i$ arrives; (3) $t_p$, the timestamp of $p$, representing the departure from $p$; (4) $t$, the timestamp of $v$, representing the arrival time at $v$.\nAn individual state $s^i = (p, v, t_p, t_v)$ describe the location occupied by agent $i$ within time interval $[t_p,t_v]$ with a pair of vertices $(p, v)$. Intuitively, an individual state is also an action of agent $i$, where $i$ moves from vertex $p$ to $v$ between timestamps $t_p$ and $t_v$. For the initial state $s_0$, we define $p = v = v_i^s$ and $t_p = t_v = 0,\\forall i \\in I$. Let $\\epsilon = (\\epsilon^1, \\epsilon^2,........, \\epsilon^n)$ denote the priorities of the agents, which are positive real numbers in $[0, 1]$. In this paper, we use the dot operator (.) to retrieve the element inside the variable (e.g. $s^i.t_v$ denote the arrival time $t_v$ of agent $i$ in the individual state $s^i$)."}, {"title": "4.2 Algorithm Overview", "content": "LSRP is shown in Alg. 1. Let $T$ denote a list of timestamps, and LSRP initializes $T$ as a list containing only 0, the starting timestamp of all agents. Let $S_T$ denote a list of joint states, which initially contains only the initial joint state. Let $P$ denote a dictionary where the keys are the timestamps and the values are joint states. $\\Phi$ is used to cache the planned actions of the agents and will be explained later. Then, LSRP initializes the priorities of the agents (Line 2), which can be set in different ways (such as using random numbers).\nLSRP plans the actions of the agents iteratively until all agents reach their goals. LSRP searches in a depth-first fashion. In each iteration, LSRP retrieves the most recent joint state that was added to $S_T$, and denote it as $s_{prev}$ (Line 5). If all agents have reached their goals in $s_{prev}$, $S_T$ now stores a list of joint states that brings all agents from $v_s$ to $v_g$. LSRP thus builds a joint path out of $S_T$, which is returned as the solution (Line 7), and then terminates. Otherwise, LSRP resets the priorities of the agents that have reached their goals, and increase the priority by one for agents that have not reached their goals yet (Lines 9-10).\nThen, LSRP extracts the next planning timestamp $t_{min}$ from $T$, which is the minimum timestamp in $T$, and extracts the subset of agents $I_{curr} \\subset I$ so that for each agent $i \\in I$, its arrival timestamp $t_v^i$ in $s_{prev}$ is equal to $t_{min}$ (Line 12). Intuitively, the agents in $I_{curr}$ needs to determine their next actions at time $t_{min}$. Here, $t_{next}$ is assigned to be the next planning timestamp in $T$ if $T$ is not empty. Otherwise ($T$ is empty), $t_{next}$ is set to be $t_{min}$ plus the a small amount of time (Lines 13-16). To generate the next joint state based on $s_{prev}$, LSRP first checks if the actions of agents in $I_{curr}$ have been planned and cached in $P$. If so, these cached actions are used and the corresponding individual states are generated and added to $s_{next}$ (Line 17). For agents without cached actions (Line 19), LSRP invokes a procedure ASY-PUSH to plan the next action for that agent.\nFinally, the generated next joint state $s_{next}$ is appended to the end of $S_T$, and the arrival timestamp $s_{prev}^i.t_v$ of each agent $i \\in I$ is added to $T$ for future planning."}, {"title": "4.3 Recursive Asynchronous Push", "content": "ASY-PUSH takes the following inputs: $i$, the agent to be planned; $ban$, a list of vertices that agent $i$ are banned to move to; $t$, the current timestamp; $t_{next}$, the next timestamp; and $bp$, a boolean value indicating if agent $i$ is being pushed away by other agents, which stands for \u201cbe pushed\u201d.\nAt the beginning, ASY-PUSH identifies all adjacent vertices $C$ that agent $i$ can reach from its current vertex in $G$. These vertices in $C$ are sorted based on their distance to the agent's goal (Line 1-2, Alg.2). Then, for each of these vertices from the closest to the furthest, ASY-PUSH checks whether the agent can move to that vertex without running into conflicts with other agents, based on the occupancy status of that vertex (Line 7-27, Alg.2). ASY-PUSH stops as soon as a valid vertex (i.e., a vertex that is unoccupied or can be made unoccupied through the push operation) is found. Specifically, among Line 7-27 in Alg.2, ASY-PUSH may run into one of the following three cases:\nCase 1 Occupied (Line 8): The procedure OCCUPIED returns true if either one of the following three conditions hold. (1) Vertex $v$ is inside $ban$, which means agent $i$ cannot be pushed to $v$. (2) $v$ is occupied by another agent $i'$ and $i'$ either has been planned or $i'$ is not in $I_{curr}$. (3) $bp$ is true (which indicates that agent $i$ is to be pushed away) and $v$ is the vertex currently occupied by agent $i$ (i.e., $v = s_{prev}.v^i$). When OCCUPIED returns true, agent $i$ cannot move to $v$. Then, ASY-PUSH ends the current iteration of the for-loop, and checks the next vertex in $C$.\nCase 2 Pushable (Line 9-18): ASY-PUSH invokes PUSH-REQUIRED to find if vertex $v$ is occupied by another agent $k$ that satisfy the following two conditions: (1) $k \\in I_{curr}$ and (2) the action of $k$ has not yet been planned (Line 9). If no such a $k$ is found, ASY-PUSH goes to the \u201cUnoccupied\u201d case as explained next. If such a $k$ is found, the current vertex $v^i$ occupied by agent $i$ is added to the list $ban$ so that agent $k$ will not try to push agent $i$ in a future recursive call of ASY-PUSH, which can thus prevent cyclic push in the recursive ASY-PUSH calls. Then, a recursive call of ASY-PUSH on agent $k$ is invoked and the input argument $bp$ is marked true, indicating that agent $k$ is pushed by some other agent. $bp$ is also used in SWAP-related procedures (Line 3-4,16-17 and 24-25), which will be explained later. This recursive call returns the timestamp when agent $k$ finished its next action, and agent $i$ has to wait till this timestamp, which is denoted as $t_{wait}$. Given $t_{wait}$, the procedure WAITANDMOVE is invoked to add both the wait action and the subsequent move action of agent $i$ into $\\Phi$, the dictionary storing all cached actions. Then, the timestamp $t_{move}$ when agent $i$ reaches $v$ is computed (Line 18) and returned.\nCase 3 Unoccupied (Line 19-26): Vertex $v$ is valid for agent $i$ to move into and an successor individual state $s_{next}$ for agent $i$ is generated (Line 23). Then, ASY-PUSH returns the timestamp $t_{move}$ when agent $i$ arrives at $v$ (Line 26)."}, {"title": "Cache Future Actions", "content": "During the search, $\\Phi$ caches the planned actions of the agents, and is updated in Alg.3, which takes an agent $i \\in I$, a vertex $v \\in V$, the timestamp $t_{wait}$ that agent $i$ needs to wait before moving as the input. Alg.3 first generates the corresponding individual state $s_{next}$ where agent $i$ waits in place till $t_{wait}$(Line 1), and then calculates time $t'_{move}$ when agent $i$ reaches $v$ after the wait (Line 2). Finally, the future individual state corresponding to the move action of agent $i$ from $v^i$ to $v$ between timestamps $[t_{wait}, t'_{move}]$ is generated and stored in $\\Phi$."}, {"title": "4.4 Relationship to PIBT and Causal PI\u0412\u0422", "content": "LSRP differs from PIBT in the following three aspects: First, PIBT solves MAPF where vertex and edge conflicts are considered. When one seeks to use PIBT-like approach to solve MAPF-DC (with duration conflict), the wait action may need to be considered in a similar way as LSRP does. Specifically, when two agents $i, j \\in I_{curr}$ compete for the same vertex $v$, the higher-priority agent starts to move to $v$ until the lower-priority agent is pushed away from $v$ and reaches a less desired vertex $u$. Here, the wait and the move action of $i$ are planned together and the move action is cached in $\\Phi$ for future execution. In PIBT, agent $i$ can move to $v$ that is currently occupied by $j$ as soon as $j$ leaves $v$, and there is no need for agent $i$ to wait and cache the move action. Second, different from MAPF-DC, MAPF-AA has various duration. As a result, in each iteration (with planning timestamp $t$), LSRP plans for agents whose arrival time are equal to $t$, instead of planning all agents as PIBT does. Third, LSRP also introduces a swap operation for MAPF-AA, which is demonstrated in Sec. 6.\nCausal PIBT (Okumura, Tamura, and D\u00e9fago 2021) extends PIBT to handle delays caused by imperfect execution of the planned path for MAPF. In the time-independent planning problem, due to the possible delays, the action duration is unknown until the action is finished. Causal PIBT thus plans \u201cpassively\u201d by recording the dependency among the agents during execution using tree-like data structure. When one agent moves, Causal PIBT signals all the related agents based on their dependency. In MAPF-AA, the action duration are known, and LSRP thus plans \u201cactively\u201d by looking ahead into the future given the action duration of the agents, and caches the planned actions when needed. The fundamental ideas in LSRP and Causal PIBT are related and similar, but the algorithms are different since they are solving different problems."}, {"title": "5 Analysis", "content": "Given a graph $G$, a cycle ${v_1, v_2, \u00b7\u00b7\u00b7, v_e, v_1 }$ is a special path that starts and ends at the same vertex $v_1$. The length of a cycle is defined as the number of vertices in it. Given a graph $G$ and $N$ agents, if there exists a cycle of length $> N + 1$ for all pairs of vertices that are adjacent in the graph, then we call this graph a c-graph. Intuitively, for a c-graph, LSRP guarantees that the agent with highest priority can push away any other agents that block its way to its goal, and reaches its goal within a bounded timestamp. Once the agent arrives at its goal, its priority is reset and thus becomes a small value, the priority of another agent becomes the highest and can move towards its goal. As a result, all agents are able to reach their goals at a certain timestamp. We now present the theorems that state these properties. Note that LSRP initializes all agents with a unique priority, and all agents' priorities are increased by one in each iteration of LSRP, unless the agent has reached its goal. Let $i^* \u2208 I$ denote the agent with the highest priority when initializing LSRP. Let $D_{max}$ denote the largest duration for any agent and any edge.\nTheorem 1 In a c-graph, in LSRP, when $i^* \u2208 I_{curr}$, let $v^*$ denote the nearest vertex from $v^{i^*}$ among all vertices in C, then $i^*$ can reach $v^*$ within time $N \u00b7 D_{max}$.\nProof 1 In each iteration, LSRP extracts the minimum timestamp $t_{min}$ from $T$, and at the end of the iteration, the newly added timestamps to $T$ must increase and be greater than $t_{min}$. As a result, $t_{min}$ keeps increasing as LSRP iterates and all agents are planned. Now, consider the iterations of LSRP where agent $i^* \u2208 I_{curr}$ and is planned. In ASY-PUSH, $v^*$ is check at first. If no other agent (k) occupies $v^*$, then $i^*$ reaches $v^*$ with a duration that is no larger than $D_{max}$. Otherwise (i.e., another agent k occupies $v^*$), agent $i^*$ seeks to push k to another vertices which may or may not be occupied by a third agent k'. Since the graph is a c-graph, there must be at least one unoccupied vertex in the cycle containing the $s_{prev}.v^{i*}$, the current vertex reached by $i^*$. In the worst case, all agents are inside this cycle and $i^*$ has to push all other agents before $i$ can reach $v^*$, which takes time at most $N \u00b7 D_{max}$, where the agent moves to its subsequent vertex in this cycle one after another.\nWe now consider the multi-agent case. Given a path $\\pi = \\{v_1, v_2,\u00b7\u00b7\u00b7, v_e\\}$ in graph G, the length of $\\pi$ is defined as the number of vertices in $\\pi$. Let diam(G) denote the diameter of graph G, which is the length of the longest path between any pair of vertices in G.\nTheorem 2 For a c-graph, LSRP (Alg. 1) returns a set of conflict-free paths such that for any agent $i \u2208 I$ reaches its goal at a timestamp $t$ with $t \\leq diam(G) \u00b7 N^2 \u00b7 D_{max}$.\nProof 2 From Theorem 1, the agent with the highest priority arrives $v^*$ within $N \u00b7 D_{max}$. So agent i arrives $v_i^g$ within $diam(G) \u00b7N\u00b7 D_{max}$. Once agent i reaches $v_i^g$, its priority is reset, which must be smaller than the priority of any other agents, and another agent j gains the highest priority and is able to reach its goal. This process continues until all agents in I have gained the highest priority at least once, and reached their goals. Thus, the total time for all agents to achieve their goals is within $diam(G) \u00b7 N^2 \u00b7 D_{max}$."}, {"title": "6 Extension with Swap Operation", "content": "Similarly to PIBT (Okumura et al. 2022), LSRP may fail to find a solution in tree-like graphs. Fig. 3 shows an example, where the agents have to swap their locations before they can reach their goals, and simply using push operations cannot solve the problem. We thus propose LSRP-SWAP, which uses ASY-PUSH-SWAP to plan the next action of an agent (Line 21 in Alg. 1), which improves ASY-PUSH with an additional swap operation. ASY-PUSH-SWAP is shown in Alg. 2, which is based on ASY-PUSH with the additional lines marked with an underline. ASY-PUSH-SWAP takes the same input as ASY-PUSH, and invokes a procedure SWAP-POSSIBLE-REQUIRED to check if there exists an agent $j$ that needs to swap vertices with agent $i$. If there is no such an agent $j$, ASY-PUSH-SWAP iterates vertices in C in the same way as ASY-PUSH. Otherwise (i.e., $j$ exists), ASY-PUSH-SWAP reverses the order of the vertices in C. For these vertices from the furthest to the closet, ASY-PUSH-SWAP checks whether the agent can move to that vertex without running into conflicts in the same way as ASY-PUSH does. If agent $i$ can move to the furthest vertex, and agent $j$ is not planned, $j$ is pulled to i's current vertex after $i$ vacates it (Line 16-17,24-25 in Alg. 2).\nNotify that the theoretical property of theorem 1 in Sec. 5 does not hold for LSRP-SWAP. In LSRP-SWAP, $i^*$ may not reach $v^*$ in a given time limit. Because the SWAP mechanism may be triggered and $i^*$ moves to another vertex other then $v^*$, the reason is that, at Line 4 in Alg. 2, $i^*$ does not move greedily to its goal, and if the condition on Line 24 in Alg. 2 is satisfied, $i$ moves to the vertex that is the farthest from $v^*$, which is not $v^*$, thus theorem 1 does not hold because we cannot guarantee a time limit that i reaches $v^*$.\nSWAP-REQUIRED-POSSIBLE is similar to the idea of the swap operation in PIBT (Okumura 2023). The major difference is that the swap operation in LSRP must consider the duration conflict between the agents rather than vertex or edge conflict as PIBT does. More details about this procedure can be found in the appendix."}, {"title": "7 Experimental Results", "content": "Our experiments uses three maps and the corresponding instances (starts and goals) from a MAPF benchmark (Stern et al. 2019). For each map, we run 25 instances with varying number of agents N, and we set a 30-seconds runtime limit for each instance. We make the grid maps four-connected, and each agent has a constant duration when going through any edge in the grid. This duration constant of agents vary from 1.0 to 5.0. We implement our LSRP and LSRP-SWAP in C++, and compare against two baselines. The first baseline is a modified CCBS (Andreychuk et al. 2022). The original CCBS implementation considers the shape of the agents and does not allow different agents to have different duration when going through the same edge. We modified this public implementation by using the duration conflict and allow different agents to have different duration. Note that the constraints remain \u201csound\u201d (Andreychuk et al. 2022), and the solution obtained is optimal to MAPF-AA. The second baseline SIPP (see Sec. 3.3) adopts prioritized planning using SIPP (Phillips and Likhachev 2011) as the single-agent planner. It uses the same initial priority as LSRP and LSRP-SWAP. All tests use Intel i5 CPU with 16GB RAM."}, {"title": "7.1 Success Rates and Runtime", "content": "Fig. 4 shows the success rates and runtime of the algorithms. Overall, it is obvious that our LSRP and LSRP-SWAP can often handle more than an order of magnitude number of agents than the baselines within the time limit with much smaller runtime. In particular, LSRP-SWAP runs fastest and handle up to 1000 agents in our tests. In sparse maps (Empty-16, Den520d), LSRP and LSRP-SWAP both scales well with respect to N, and the reason is that these graphs have many cycles that make the push operation highly efficient when resolving conflicts between the agents. In a cluttered environment (Warehouse), LSRP has similar performance to SIPP while LSRP-SWAP outperforms both LSRP and SIPP, which shows the advantage of the swap operation in comparison with LSRP without swap."}, {"title": "7.2 Solution Quality", "content": "Fig. 6 compares the solution quality of different algorithms, where the bars show the ratio of the solution costs obtained by LSRP-SWAP over either CCBS or SIPP. The ratios A/B are computed based on the instances from the experiment in Sec. 6.1 that were successfully solved by both planners A and B, where A is LSRP or LSRP-SWAP, and B is CBSS or SIPP. SIPP solves more instances than CCBS, and the ratios over CCBS and SIPP are thus calculated based on different sets of instances. We measure the solution costs using both sum of costs (SoC) and makespan. As shown in Fig. 6 and Fig. 5, the median ratios is about 4x in SoC, and 1.25x in makespan, which means LSRP and LSRP-SWAP return solutions that are more expensive than the baselines. In Empty-16, the ratios are usually larger, while in the other two maps, the ratios are smaller. This result shows that LSRP and LSRP-SWAP achieve high scalability at the cost of solution quality, while the baselines usually find high quality solution with limited scalability."}, {"title": "7."}]}