{"title": "PGSO: Prompt-based Generative Sequence Optimization Network for Aspect-based Sentiment Analysis", "authors": ["Hao Dong", "Wei Weib"], "abstract": "Recently, generative pre-training based models have demonstrated remarkable results on Aspect- based Sentiment Analysis (ABSA) task. However, previous works overemphasize crafting various templates to paraphrase training targets for enhanced decoding, ignoring the internal optimizations on generative models. Despite notable results achieved by these target-oriented optimization methods, they struggle with the complicated long texts since the implicit long-distance relation, e.g., aspect- opinion relation, is difficult to extract under the position embedding mechanism in generative models. Thus, in this paper, we first clarify the causes of the problem and introduce two sequence optimization strategies: the rule-based static optimization and the score-based dynamic optimization. The rule- based approach relies on handcraft priority of dependency relation to reorder the context, while the score-based algorithm dynamically regulates the contextual sequence by calculating word position scores using neural network. Based on the dynamic optimization structure, we further propose a unified Prompt-based Generative Sequence Optimization network (named PGSO), which jointly optimizes the training target as well as the generative model. Specifically, PGSO contains two components, namely, prompt construction and sequence regulator. The former constructs a task-specific prompt based on unsupervised training objects to fully utilize the pre-trained model. The latter jointly leverages semantic, syntactic and original-sequence information to dynamically regulate contextual sequence. Our experiments conducted on four ABSA tasks across multiple benchmarks indicate that PGSO outperforms state-of-the-art methods, with an average improvement of 3.52% in F1 score.", "sections": [{"title": "1. Introduction", "content": "Aspect-based sentiment analysis (ABSA) focuses on mining detailed sentiment information related to specific aspects. There are four fundamental sentiment elements: aspect category (c), aspect term (a), opinion term (o), and sentiment polarity (s) [1, 2, 3]. Taking the sentence \u201cThe pizza is tasty.\u201d as an example, the corresponding elements are \u201cpizza\", \"food quality\u201d, \u201ctasty\" and \u201cpositive\", respectively. As shown in Table 1, ABSA can be categorized into multiple tasks depending on the combination of various elements to be extracted.\nIn general, ABSA tasks are formulated as discriminative manners by designing task-specific classification networks [4, 5, 6] or labeling strategies [7, 8]. However, these methods suffer from poor transfer-ability between different ABSA tasks due to these well-designed classifiers or strategies. Therefore, unified generative pre-trained based methods, especially on T5, gradually become the theme of ABSA tasks. GAS-T5 [9] adopts T5 as the backbone model to tackle ABSA tasks with two styles of transferring paradigms. Zhang et al. [10] introduce a paradigm to conceptualize the quadruplet extraction (ASQP) as a paraphrase generation problem. Similarly, Mao et al. [11] treat multiple sentiment tuples as a path of the tree, predicting targets independently. Despite remarkable results achieved by these target-oriented optimization methods, they still suffer from the inability of handling the complicated long texts, since they ignore the insufficiency of the generative model itself."}, {"title": "2. Related Work", "content": "In this section, we make a comprehensive review of previous works, and point out the current problems of target-oriented optimization and model-oriented optimization.\nEarly studies for the ABSA tasks are concentrated on single sentiment element extractions such as Aspect Term Extraction (ATE) task [16], or predicting the sentiment po- larity of aspect term [17]. Lately, some researchers propose multiple sentiment elements extractions, like pair, triplet even quadruplet. For pair extrication, the Unified Aspect- Based Sentiment Analysis (UABSA) task [18] tries to jointly extracts the aspect term and predict its corresponding senti- ment polarities. For triplet extraction, the primary tasks are focused on Target Aspect Sentiment Detection (TASD) [19] and Aspect Sentiment Triplet Extraction (ASTE) [20]. For quadruplet extraction, Aspect Category Opinion Sentiment (ACOS) [21] requires to predict four mentioned sentiment elements simultaneously.\nSince the sentiment polarity in Aspect-based Sentiment Analysis task belongs to three-element set (i.e., positive, negative, neutral), ABSA tasks are usually formulated as discriminative manners. Zhang et al. [24] constructs a GCN over dependency tree to exploit syntactic information, boosting ABSA performance. Tang et al. [25] propose dual-transformer structure to jointly consider semantic and syntacitc channel. Liang et al. [26] propose a syntax-aware framework to fully leverage syntax information of con- stituent tree based on BERT model. Gu et al. [27] propose a graph convolutional network that fuses external sentiment knowledge to improve the ABSA performance. Tiwari et al. [28] propose an adversarial anylysis baed on BERT model. Yadav et al. [29] simplify positional embedding calculation process with Bi-GRU structure. Zhang et al. [30] propose a two-stage framework to solve compound ABSA tasks. Chen et al. [31] propose an enhanced multi-channel GCN network for ASTE task. Despite significant results achieved by these discriminative manners, they exhibit poor transfer-ability across various sub-tasks due to their classifiers are designed for certain specific sentiment elements or ABSA sub-tasks.\nRecently, end-to-end generative based approaches have been widely used to tackle various ABSA tasks uniformly. Different from discriminative manners, generation-based methods are not confined to specific tasks, predicting all the sentiment elements in an auto-regressive style. Meanwhile, generative models consider the rich label semantics, and do not require an extra task-specific classifier. Zhang et al. [9] propose GAS-T5 framework, which is the first work to adopt T5 as backbone model to tackle ABSA tasks with two paradigms, namely annotation and extraction style, formu- lating each ABSA task as text generation task. Based on this research, numerous optimization methods based on the generative model are emerged to improve the performance. Specifically, optimizations on generative models are mainly categorized into two directions: target-oriented optimization method and model-oriented method."}, {"title": "2.1. Target-oriented optimization", "content": "Target-oriented optimization methods require designing various templates to paraphrase training targets in terms of objective order or format. Zhang et al. [10] propose a method that transfers the quadruplet or triplet extraction into paraphrase generation with pre-defined templates, explicitly modeling the semantic relation between the sentiment ele- ment. Hu et al. [22] investigate the order of generated senti- ment elements, and try to find the best sequences for each task. Gao et al. [32] combine sentiment element prompts to tackle various ABSA tasks. Mao et al. [11] separate training targets independently, treating sentiment tuple as a path of a tree, and select valid paths via discriminative word with beam search technology. Gou et al. [23] jointly consider different orders of targets, solving ABSA tasks from different perspectives.\nAs shown in Table 3, most existing works conventionally formulate ABSA tasks as standard text generation, employ- ing static delimiters like commas or brackets. However, these methods usually have significant differences between pre-training tasks and the ABSA training tasks, leading to perfor- mance decline when transferred to ABSA tasks. Meanwhile, these methods concentrate on designing target-oriented tem- plates, paraphrasing the sentiment elements from various perspectives to enable a more comprehensive understanding of ABSA tasks by pre-trained language models, thereby im- proving the quality of generation. Despite their effectiveness, they heavily rely on the inherent structure and generation capability of the original pre-trained language model, ignor- ing the inability in capturing long-distance aspect-opinion relations due to the insufficiency of the generative model itself."}, {"title": "2.2. Model-oriented optimization", "content": "Compared with various target-oriented optimization methods, model-oriented optimization methods are rela- tively scarce. Yu et al. [15] design a dual-channel encoder and a pointer decoder based on the BART [33] (adopting similar structure with T5), aiming to improve the alignment between aspects and opinions. Fei et al. [34] investigate a structure-aware generative language model that leverages syntactic representations for better unified information ex- traction including ABSA tasks. Different from previous works, our model introduces a novel plug-in sequence reg- ulator located between the encoder and decoder. In tandem with the architectural enhancement, we also overwrite the model's default generative function."}, {"title": "3. Preliminary", "content": "In this section, we make a detailed explanation in the- ory (section 3.2) and experimentally (section 3.3) to better understand the mentioned issue."}, {"title": "3.1. Problem Definition", "content": "ABSA task aims to identify and analyze sentiment as- sociated with specific aspects within the given texts. Given an input sentence $s = {w_i}_n$, where n is the length of text. ABSA task is to predict the sentiment tuples set $T = {t_i}_m$ where m stands for the quantity of the sentiment tuples con- tained in the input text. Based on different task requirements in Table 1, each tuple $t_i$ is consisted of several sentiment fundamental elements. Taking ACOS task as an example, the sentiment tuple $t_i = (c_i, a_i, o_i, s_i)$, where $c_i, a_i, o_i, s_i$ represent aspect category, aspect term, opinion term and sentiment polarity consisted in the i-th tuple respectively."}, {"title": "3.2. Relative position mechanism", "content": "T5 [35] is a typical generative pre-trained model, em- ploying Transformer-based encoder-decoder structure. Since self-attention is order-independent, an explicit position sig- nal are provided to the calculation process. For efficiency, T5 adopts the simplified form of relative position embedding, which can be formulated as follows,\n$A_{t,s} = (W_Qx_t)W_Kx_s + r_{b(t-s)}$ (1)\nwhere the $x_t$ and $x_s$ indicates the representations of the query and key words, and $t - s$ represents the relative distance between the key and query words. $b(.)$ represents the bucket function. In the Equation 1, the former represents the common self-attention calculation, while the latter sig- nifies the incorporation of position signals. As illustrated in Figure 1, the relative position embedding mechanism comprises two distinct processes: compression and learning. In the compression process, a bucket function is employed to generate a fixed number of offsets. Specifically, short key- query offsets are retained, whereas long offsets are truncated using a pre-defined list, whose shared range expands with the increasing offset values. In the learning process, a shared scale $r_{b(t-s)}$ is acquired for each offset, contributing to the computation of attention weights. Still taking \u201cThe pizza itself is not exactly the best I 've had ever, but still pretty good.\u201d as an example, the original distance (15) between \u201cpizza\u201d and \u201cgood\u201d will be clipped to 9 with neighbors by bucket function, which results in a loss of precise position information between aspect and opinion word. Hence, T5- based target-oriented optimization methods mentioned in the Section 2.1 encounter challenges in addressing long- distance aspect-opinion relations."}, {"title": "3.3. Contextual Representation Optimization", "content": "As mentioned in Section 1, some works [15, 34] propose introducing syntactic structure to improve performance in ABSA tasks for generative models. In the Natural Language Processing field, syntax is commonly utilized to refine the representations generated by pre-trained language models. Meanwhile, to fully leverage the insights from both se- mantic and syntactic channel, sophisticated algorithms for information fusion are essential. Building on previous re- search, we design a similar approach to optimize contextual representations, which integrates syntactic information to enhance the representations and employs a dynamic gate mechanism [15] to fuse these two channels. As shown in Table 4, we have conducted experiments for T5 model in ASTE task. However, this approach does not always achieve the optimal performance, which indicates a limitation when transitioning from discriminative models to generative ones. One possible explanation is the difference in the pre-training phase: in contrast to independently initialized classifiers, generative models usually contain a pre-trianed decoder. Thus, direct modifications to contextual representation may lead to a semantic gap during auto-regressive generation. Furthermore, since the syntactic structures like dependency tree often contains noisy signals of irrelevant associations, methods that heavily rely on syntax may struggle with accu- rately aligning nuanced aspects, opinions and sentiments."}, {"title": "4. Methodology", "content": "In this section, we will first introduce two contextual optimization methods, rule-based approach and score-based approach. Next, based on the score-based optimization method, we further propose PGSO model."}, {"title": "4.1. Contextual Sequence Optimization Methods", "content": "Based on the viewpoint illustrated in the section 3, we design two optimization methods (i.e., rule-based static optimization method and score-based dynamic optimization method) to regulate the contextual sequence."}, {"title": "4.1.1. Rule-based Static Optimization", "content": "We first consider designing a regulating rule by the dependency feature of each word. The processes of the rule- based static optimization method are shown as Algorithm 1 and its structure is shown in Figure 2."}, {"title": "4.1.2. Score-based Dynamic Optimization", "content": "To further explore syntactic information, we propose a score-based dynamic optimization method, whose structure is shown in Figure 3. The processes of the method can be divided into two steps: (1) Representations enhance- ment: we first utilize syntax information to enhance the representations from the encoder, whose implementation details will be illustrated in the Syntax Encoder 4.4.1. (2) Evaluation function: to mine the semantic and syntactic information, we design a score-based evaluation function, whose implementation details are shown in Score Calculator 4.4.2.\nBase on the these two optimization structure, we further propose a Prompt-based Generative Sequence Optimization (named PGSO) model to joint optimize the training targets and language model, which will be described in the next Section."}, {"title": "4.2. Overview of PGSO", "content": "As shown in Figure 4, our proposed model takes the text s with task-specific prompt $S_{prompt}$ as the input, and out- puts the structural sentiment tuples. The architecture of the Prompt-based Generative Sequence Optimization (PGSO) model extends beyond the conventional encoder-decoder framework of the T5 model to incorporate two distinct components. Prompt Construction: this component is de- signed to narrow the gap between pre-training task and downstream ABSA task, maximizing the utilization of our proposed model. It is composed of two specialized prompts: a semantic prompt and a few-shot prompt. Sequence Reg- ulator: as the implementation of the score-based dynamic optimization method, this module includes a syntax encoder and a score calculator. The syntax encoder leverages rich syntax information to enhance the contextual representa- tions, thereby enhancing the model's interpretative ability. The score calculator operates on the refined representations to obtain the position score to each word in the input text. Subsequently, it produces the optimized sequence, which is meticulously ordered based on the computed scores, thereby ensuring that the output is not only syntactically coherent but also semantically rich and contextually relevant."}, {"title": "4.3. Prompt Construction", "content": "Inspired by previous works [32, 23], we adopt prompt- based methods to transfer the sequence generation task to the cloze-style format, aligning more closely with pre-training paradigm. The prompt contains two components: a semantic prompt and a few-shot prompt."}, {"title": "4.3.1. Semantic Prompt", "content": "The semantic prompt is constructed with sentiment terms to be predicted in ABSA tasks, accompanied by cor- responding sentinel words. As shown in Table 5, the format of the prompt is \u201c[Sentiment Term] means [Sentinel Word]\", adopting the word means to connect the sentiment terms and sentinel words, ensuring semantic coherence. Meanwhile, to align with the prompt, the target is also reformulated as a combination of sentiment elements with corresponding sentinel words, whose format is \u201c[Sentinel Word] sentiment element\u201d. Notably, one extra sentinel word will be inserted between sentiment tuples in the target to facilitate model recognition of the start and end of each tuple. For instance,\""}, {"title": "4.3.2. Few-shot Prompt", "content": "To fully utilize the proposed model, we insert a few- shot prompt between the semantic prompt and input text. Specifically, we choose to adopt only an fixed-template ar- tificial one-shot prompt for all tasks. Despite multiple shots may provide improvement, the risk of performance decline is associated with improperly crafted prompt cases due to the high sensitivity of the pre-trained language model to prompts. Importantly, our primary emphasis in the proposed model is on advancing sequence optimization rather than the prompt design."}, {"title": "4.4. Sequence Regulator", "content": "In this section, we will introduce the Sequence Regula- tor, the key module of PGSO. It takes the representations from encoder and output the optimized sequence to re-rank the context. As shown in Figure 4, there are two components: the syntax encoder and the sequence regulator."}, {"title": "4.4.1. Syntax Encoder", "content": "The text representations from T5 encoder primarily con- tains semantic information. To harness rich syntactic de- tails, we introduce a syntax encoder. Specifically, syntax encoder module utilizes a graph attention network (GAT) [36] composed by multiple graph attention layers guided by the dependency tree. The dependency tree is considered as a directed graph, whose adjacent matrix $D_A$ is formulated in the Equation 2 and GAT processes can be formulated in the Equation 3, 4 and 5.\n$D_{Ai,j} = \\begin{cases}\n1 & \\text{if } w_j \\text{ is the parent of } w_i \\text{ in Dep.Tree} \\\\\n0 & \\text{otherwise}\n\\end{cases}$ (2)\n$g_{i}^{l+1} = \\frac{1}{|N_i|} \\sum_{j\\in N_i} \\alpha_{ij}^{l} W_k g_{j}^{l}$ (3)\n$\\alpha_{ij}^{lk} = \\frac{\\exp(e_{ij}^{lk})}{\\sum_{j=1}^{N_i} \\exp(e_{ij}^{lk})}$ (4)\n$e_{ij}^{lk} = LeakyReLU(a^{T} [W^{lk}g_{i}^{l}||W^{lk}g_{j}^{l}])$ (5)\nwhere $N_i$ is the set of neighbors of $w_i$, $g_i^l$ is the representa- tion of $w_i$ in layer $l$, $||$ denotes vector concatenation, K is the number of attention heads, $W^{lk}$, a are trainable parameters of the kth head of layer $l$, $LeakyReLU$ is the activation function. The initial representations $g^{0} = h$, where the h stands for the contextual representations, and the final output representations from the syntax encoder is g."}, {"title": "4.4.2. Score Calculator", "content": "To transfer the contextual sequence as a trainable vari- able, we realize the score-based evaluation function, which jointly considers the semantic, syntactic and original se- quence information. Specifically, we introduce position score for each word to quantify its positional significance, which is composed by two parts: the representation score and the bias score, which is formulated as follows,\n$s^{ps}_{i} = s^{rs}_{i} + s^{bs}_{i}$ (6)\nwhere $s^{ps}_{i}$, $s^{rs}_{i}$, $s^{bs}_{i}$ are the position score, representation score and bias score of the word $w_i$ respectively.\nRepresentation Score: To obtain the latent optimal decoding sequence, we design a unified approach to leverage the representations from the syntax encoder. It consists a Linear layer and Normalization function, which can be formulated as follows,\n$s^{rs}_{i} = \\frac{\\exp (W g_{i})}{\\sum_{j=1}^{n} \\exp (W g_{j})}$ (7)\nBias Score: Given that attention calculation is order- independent, the rearrangement scheme relying solely on representation score may lead to over-adjustment due to syntactic noise propagation, especially for the short texts. To mitigate the issue, we also introduce bias score, explicitly leveraging the original sequence to provide a hierarchical rectified gradient. Specifically, for long texts, low-gradient preserves free-adjustment features, facilitating modeling long-distance relations. Conversely, in short texts, high- gradient provides resistance to rectify the over-adjustment in short texts. The calculation processes of the bias score are as follows,\n$s^{bs}_{i} = \\frac{\\exp (l_i)}{\\sum_{i=1}^{n} \\exp (l_i)}$ (8)\n$l_i = \\frac{I - i \\times d}{n}$ (9)\nwhere n is the length of text. $I$ and d are pre-defined hyper- parameters length and step respectively. For a clearer com- prehension of the function of the proposed bias score, we consider examples with text lengths of 3 and 18. As shown in Table 7, it is noteworthy that the initial interval for short texts is substantially larger than that for long texts, ensuring the positions are kept relatively stable. This observation under- scores the resistance to over-adjustment issue, particularly in the context of short texts."}, {"title": "5. Experiment", "content": "We evaluate the PGSO model on 12 datasets over four tasks, including Laptop14, Rest14, Rest15 and Rest16. These 12 datasets are originally provided by the SemEval shared challenges [37, 38, 39]. Specifically, for ASTE, TASD and UABSA tasks, we adopt the datasets provided by [40, 19, 41]. For ACOS tasks, the dataset is provided by [19]. The data statistics are shown in Table 6.\nAll results are the average F1 scores across three runs with different random seeds. To align with the settings of previous works, we adopt T5-base model from Huggingface Transformers Library 2 as our backbone model. The learning rate is set to be $3 \\times 10^{-4}$ and training epoch is set to 40. In the syntax encoder module, the number of graph attention layers is 2, the dropout rate is 0.4 and the alpha is 0.05. To align with the T5-base model, the $I$ and $d$ in bias score are fixed to 128 and 1 respectively. The details of each hyper-parameters are listed in the appendix C."}, {"title": "5.2. Baselines", "content": "We compare our model with discrimination-based meth- ods and generation-based methods, which are introduced as follows:\n(1) Discrimination-based methods: Span-ASTE [42] proposes a Span-BERT based methods to learn interactions between target spans and opinion spans for the ASTE task. SBN [43] is another span-level bidirectional network for ASTE task. RACL [44] proposes a relation propaga- tion mechanisms to tackle ABSA tasks based on BERT model. Jet-BERT [40] tackles ABSA tasks in an end-to- end manner by a tagging scheme. Dual-MRC [45] is a dual- channel MRC (Machine Reading Comprehension) structure to tackle triplet extraction task. Similarly, BMRC [12] is a Bi-direction MRC model to extract aspect and opinion separately. Extract-Classify-ACOS [21] is the first work to propose ACOS task, and propose a two-step structure based on BERT model.\n(2) Generation-based methods: GAS-T5 [9] is the first work to adopt T5 as backbone model to address ABSA tasks. Paraphrase-T5 [10] proposes a paraphrasing tem- plate to exploit semantic relation between sentiment ele- ments. Seq2Path [11] treats sentiment tuple as a path of the tree, predicting tuples separately. DLO [22] investigates the order of sentiment elements. LEGO-ABSA [32] pro- poses a LEGO-style prompt assemble structure. MvP [23] aggregates sentiment elements generated in different orders. BARTABSA [46] proposes a BART based model to tackle ACOS task. BART-CRN [47] tackles ACOS extraction as a"}, {"title": "5.3. Overall Performance", "content": "We have conducted extensive experiments on 4 tasks over 12 datasets. The overall performance comparison is shown in Table 8, 9, 10 and 11. Most baselines are copied from [11]. Our proposed model obtains the state-of-the-art results in almost all F1 scores."}, {"title": "5.4. Ablation Study", "content": "We also conduct an ablation study to verify each com- ponent's effectiveness in our proposed PGSO based on the dynamic optimization method. The results are shown in Table 12, and the observations are as follows:\n(1) The original T5 model achieves the lowest result, indicating that the pre-trained language model is not effec- tively utilized without any optimization methods.\n(2) To verify the impact of different types of prompts, we conducted additional experiments varying the prompt cat- egories, focusing on the effectiveness of semantic prompts and few-shot prompts. In category w/o SR, the model equipped with semantic prompts outperformed the baseline T5 model, achieving an average enhancement of 1.90 in F1 score. This significant improvement suggests that semantic prompts effectively convert the original generation task into a cloze- style task, which aligns well with the model's pre-training objectives. In contrast, the few-shot prompt only resulted in a modest 0.27 increase in F1 score, indicating that the model's performance is indeed sensitive to the nature of the prompts used.\n(3) Within category w/o PC, w/o SR performs inferior to w/ SR, which implies that the dynamic optimization scheme is also effective even without any prompts.\n(4) We also conduct experiment to identify the effec- tiveness of representations score. In the category w/ PC, compared with w/o SR, w/o BS achieves superior results except TASD and ACOS tasks under Rest16 dataset. This phenomenon suggests that while algorithms relying on rep- resentation scores are generally effective, they sometimes overlook the information contained in the original sequence, which can result in incorrect predictions in certain instances.\n(4) To verify the function of bias score in the sequence regulator, we also conduct comparison experiment. In cat- egory w/ PC, w/ BS is superior to w/o BS on almost the datasets, which means that introducing original sequence can boost performance, rectifying the aforementioned incor- rect predictions."}, {"title": "6. Analysis", "content": "To show the distinctive superiority of our proposed PGSO in long-distance relation extraction, we conduct ex- periments under different distance relations. All the results are average F1 scores across four datasets with three different random seeds in ASTE task. The results are shown in Figure 5. Key observations are as follows:\n(1) All models exhibit comparable performance on rela- tionships with a distance of less than 11, with the maximum discrepancy between any two models being less than 2.7. This is expected since predicting short relations is relatively straightforward for a model like T5-base, which boasts 220 million parameters.\n(2) In the domain of long-distance relations (11 to 16), our PGSO model significantly surpasses its competitors. Specifically, it achieves an F1 score improvement of 4.17 and 10.87 over the other two models, indicating the efficacy of our unique sequence rearrangement approach.\n(3) Due to the scarcity of extremely long-distance rela- tions, which aligns with the observed long-tail distribution, all models face lower performance results. Despite this chal- lenge, our model stands out, delivering a notable F1 score improvement of 4.30 and 12.13 over its competitors."}, {"title": "6.2. Effects of sequence optimization methods", "content": "We also investigate the effects of our sequence opti- mization methods. In the Section 4.1, we introduce a rule- based static optimization and a score-based dynamic opti- mization method. Firstly, we crafted three distinct sets of rules leveraging the dependency attributes of words, with the detailed rules provided in the Appendix D. Secondly, based on the PGSO structure, we experimented with diverse se- quence optimization methodologies as potential substitutes for the sequence regulator component.To isolate the effects of different optimization methods, we conducted controlled experiments: one without any sequence optimization and another with a score-based dynamic sequence regulator. The experiment results are shown as Table 13. Key observations are as follows:\n(1) Intentionally reversing the dependency ranking led to the model based on rule-1 showing the lowest F1 score of 64.45, which is even lower than the model without any sequence optimization. This suggests that introducing an irrational rule can disrupt the original contextual sequence, negatively affecting the decoder's modeling capabilities.\n(2) Models with well-crafted rules, namely rule-2 and rule-3, achieved sub-optimal results across various ABSA tasks. Compared to the baseline, these models respectively improved their F1 scores by 0.08 and 0.19, demonstrat- ing the effectiveness of sequence optimization algorithms. However, they not surpass the performance of the model with a score-based dynamic sequence optimization method, suggesting that the rule-based static approaches may lack generality.\n(3) The model with score-based dynamic optimization method achieves the best result across all the datasets and tasks, which exhibits greater completeness."}, {"title": "6.3. Case Study", "content": "As shown in Table 14, we present four cases to provide a comprehensive understanding of our proposed model. We choose GAS-T5 [9] for comparison, which is a target- oriented optimization method based on the original T5-base model.\nThe first three examples are typical sentences with long- distance aspect-opinion pairs. While GAS-T5 struggles to extract these relations, PGSO accurately predicts them, demonstrating that our contextual re-ranking mechanism enhances the model's capacity to extract such long-distance aspect-opinion relations.\nThe final example features a more complex sentence with an aspect interference term (\u201cblack olive butter\u201d). Tradition- ally, the original language model biases attention weights towards closer word pairs, leading to redundant predictions like (black olive butter, unique, POS) and (black olive butter, tasty, POS) for the GAS-T5 model. In contrast, trough con- textual rearrangement, PGSO successfully captures the cor- rect associations and diminishes the interference's impact."}, {"title": "6.4. Complexity Analysis", "content": "To assess the impact of our prompt construction and sequence regulator module, we conduct a complexity anal- ysis focusing on two key aspects: model scale and training duration.\n(1) Our sequence regulator module introduces an addi- tional 461,000 parameters, primarily due to the inclusion of Linear layers. This increase is relatively minor when compared to the original T5 model, which already possesses 222 million parameters. This suggests that our approach does not significantly expand the model's size.\n(2) Compared to the original T5 model, the model that incorporates the prompt construction module only experi- ences a 4.6% increase in training time. This result suggests that adding prompt texts does not substantially extend the model's runtime.\n(3) On average, the sequence regulator module demands 28.3% more training time than a model that solely incor- porates the prompt construction module. This increased time consumption could be attributed to two primary fac- tors. Firstly, due to the involvement of tensor scatter and sort operations, the sequence regulation process may not be sufficiently parallelized, which could limit performance. Secondly, our reconstructed generation function might not be as well-optimized as the original one, potentially leading to higher computational costs."}, {"title": "6.5. Error Analysis", "content": "To conduct comprehensive investigation of our method, we have chosen two typical wrong predictions for in-depth error analysis, aiming to specify the potential direction for the improvement or refinement. The examples are presented in Table 16.\nThe first case pertains to the ambiguity in determin- ing the boundaries of aspect or opinion spans. Despite the model's success in identifying the relation between aspects and opinions, it occasionally fails in predicting the exact spans. Thus, improving the precision of span boundary is a possible future enhancement.\nFor the second case, in the Aspect-Category-Opinion- Sentiment (ACOS) task, predicting the \"NULL\" aspect is particularly challenging. One possible reason is the absence of the \"NULL\" node in the dependency tree. In the syntax encoder module, we introduce a Graph Attention Network (GAT) to capture the relations within the dependency tree. However, when the aspect term is not explicitly mentioned in the text, the aspect-opinion relation is not reflected in the dependency tree, leading to a incorrect prediction. A potential solution is to integrate a \"NULL\" as a leaf node in the dependency tree, enabling the model to explicitly capture relations."}, {"title": "7. Conclusion", "content": "In this paper, we first propose two sequence optimization methods to address the limitation of the position embedding mechanism in the PLMs. Based on the score-based dynamic optimization structure, we further propose PGSO, a unified Prompt-based Generative Sequence Optimization network, to boost the long-distance relation extraction by rearranging context. This is the first work to introduce a model-oriented optimization methods aimed at addressing the limitations of generative models in long-distance relation extraction within ABSA tasks. Specifically, PGSO contains two components, namely, prompt construction method and sequence regula- tor module. The former constructs a task-specific prompt based on pre-training objectives, effectively bridging the gap between pre-training and downstream tasks, maximizing utility of the proposed model. The latter adopts syntactic in- formation to dynamically optimize the contextual sequence, thus enhancing the model's ability to identify long-distance relations. Moreover, we have conducted extensive exper- iments on four ABSA tasks across multiple benchmarks, which demonstrates that PGSO outperforms state-of-the-art methods."}]}