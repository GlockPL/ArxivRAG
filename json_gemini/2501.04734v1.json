{"title": "Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa", "authors": ["Rancy Chepchirchir", "Jill Sunday", "Raymond Confidence", "Dong Zhang", "Talha Chaudhry", "Udunna C. Anazodo", "Kendi Muchungi", "Yujing Zou"], "abstract": "In Sub-Saharan Africa (SSA), the utilization of lower-quality Magnetic Resonance Imaging (MRI) technology raises questions about the applicability of machine learning (ML) methods for clinical tasks. This study aims to provide a robust deep learning-based brain tumor segmentation (BraTS) method tailored for the SSA population using a threefold approach. Firstly, the impact of domain shift from the SSA training data on model efficacy was examined, revealing no significant effect. Secondly, a comparative analysis of 3D and 2D full-resolution models using the nnU-Net framework indicates similar performance of both the models trained for 300 epochs achieving a five-fold cross-validation score of 0.93. Lastly, addressing the performance gap observed in SSA validation as opposed to the relatively larger BraTS glioma (GLI) validation set, two strategies are proposed: fine-tuning SSA cases using the GLI+SSA best-pretrained 2D fullres model at 300 epochs, and introducing a novel neural style transfer-based data augmentation technique for the SSA cases. This investigation underscores the potential of enhancing brain tumor prediction within SSA's unique healthcare landscape.", "sections": [{"title": "1 Introduction", "content": "Brain tumors present a substantial health challenge in Africa. The efforts of research on brain tumors have barely made any positive change in survival rate in low-and middle-income countries (LMICs). The rate of mortalities from glioma is among the highest in the world, with the Sub-Saharan Africa experiencing a rise of 25% [1].\nAccurate segmentation of distinct sub-regions within gliomas such as peritumoral edema, necrotic core, enhancing, and non-enhancing tumor core, based on multimodal MRI scans, hold clinical relevance for the diagnosis, prognosis, and treatment of brain tumors. Accurately delineating the regions of interest within a tumor provides essential insight about its size, location, and shape, enabling the determination of the extent of tumor involvement [2].\nHowever, the segmentation of these sub-regions presents a formidable challenge due to the heterogeneity of brain tumors[3] and in resource-constrained settings such as the SSA, due to the propensity for suboptimal image contrast and resolution [1] from lower quality MRI scanners and lack of availability of advanced imaging"}, {"title": "1.1 Related Work", "content": "Neural style transfer (NST) has been employed as a data augmentation technique in various medical domains, including COVID-19 diagnosis classification [7] and 3D cardiovascular MRI image segmentation [8]. However, this study marks the first application of NST to brain tumor segmentation within a Sub-Saharan Africa context. Moreover, Tomar et.al. [9] explored a self-supervised style transfer technique as data augmentation to improve brain tumor segmentation performances. This comprehensive methodology was, however, more computationally expensive than the NST approach. Bouter et al. [10] demonstrated the feasibility of artificially creating super-resolution MRI images from low-resolution counterparts, indicating that such an approach could be leveraged for the BRaTS-2021 dataset. Lastly, the work conducted by Sendra et al. [11] addressed similar domain-shift challenges using comparable approaches. Their findings suggested that employing transfer learning for domain adaptation could integrate modest-sized African samples into extensive databases of developed nations. Notably, both studies highlighted the imbalance between African and high-resource country cases, with Sendra et al. studying 25 patients from five African centers, while our study examined 60 African cases."}, {"title": "2 Methods", "content": "Implementation\nOur solution, implemented with PyTorch, is an extension of nnUNet [12] which is publicly available on GitHub: https://github.com/MIC-DKFZ/nnUNet. The baseline model training and inference were done with mixed precision to minimize costs (i.e. time and memory). The experiments were run on Tesla T4 Turing GPUs and NVIDIA's V100 system on Compute Canada cluster. We then stored both the latest and best checkpoint models based on the Dice score on the validation dataset for use during inference.\nDatasets\nThis work was conducted as part of the BraTS 2023 Challenge, where the datasets pre-selected by the organizers were used. The datasets were multi-center MRI scans of 1251 adult glioma (GLI) cases from the 2021 Continuous Evaluation sub-challenge[13] and 60 adult glioma cases acquired in SSA (SSA) from the BraTS-Africa sub challenge[1] - the largest publicly available African adult glioma MRI data at the time of the 2023 challenge. Thus, a total of 1311 MRI scans of adults with pre-operative glioma including both low-grade glioma (LGG) and high-grade glioma (GBM/HGG) were used to train and validate the proposed model. The MRI scans comprised of routine T1-weighted (T1), post-contrast T1-weighted (T1ce), T2-weighted (T2) and T2-weighted Fluid Attenuated Inversion Recovery (FLAIR) images acquired as part of standard of care[13] [1]. Each case also contained pre-labelled brain tumor sub-region masks, namely, necrotic tumor core (NCR), enhancing tumor (ET), and peritumoral edematous tissue (ED).\nThe datasets were split into GLI (1251 cases) and GLI+SSA (1311) and used separately to train the model, while a five-fold cross-validation approach was used to evaluate the performance of the model. Four cases from the SSA dataset were excluded as outliers based on image quality inconsistencies. To investigate the impact of the outliers in real-world applications, the GLI+SSA data were also trained excluding the four outlier cases (GLI+SSA2; 1307 cases).\nData Preprocessing\nThe data were preprocessed following Futrega et.al's Optimized U-Net approach [14], which involved foreground cropping operation, intensity normalization, and resampling. These preprocessing steps were taken to establish"}, {"title": "2.1 Baseline Model (Optimized U-Net)", "content": "The Optimized U-Net model [14] was used as our baseline model, with deep supervision to improve the gradient flow by calculating the loss function at various decoder levels. Here, each experiment was trained for 2, 5, 10, and 30 epochs using the Adam optimizer with varying learning rates for the three experiments: 1) GLI, 2) GLI+SSA, and 3) GLI+SSA2."}, {"title": "2.2 nnU-Net Model", "content": "nnU-Net, an image segmentation method introduced in [12], adapts to specific datasets by autonomously configuring a U-Net-based segmentation pipeline. It simplifies model training by creating multiple U-Net configurations for different datasets, effectively handling diverse input modalities and class imbalances. Notably, nnU-Net version 2 was used given its ser-friendly development framework.\nTwo- and three-dimensional (2D & 3D) Configuration We have employed a 3D full resolution with a batch size of 2, a patch size of [128, 128, 128], 32 U-Net base features, a per-stage encoder and decoder of [2, 2, 2, 2, 2, 2], kernel sizes of [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], and convolution kernel sizes of [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]] on both the GLI dataset and the GLI+SSA dataset. We also employed a 2D full resolution with a batch size of 105, a patch size of [192, 160], 32 U-Net base features, a per-stage encoder and decoder of [2, 2, 2, 2, 2, 2], kernel sizes of [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], and convolution kernel sizes of [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]] on the GLI and GLI+SSA dataset. Each experiment was trained for 2, 5, 10, 30, and 300 epochs using the Adam optimizer with varying learning rates."}, {"title": "2.3 Proposed Methods: Neural Style Transfer Augmentation and 2D Full-Res Model Finetuning", "content": "In the context of resource-constrained settings where limited training data continues to pose a challenge, we employed neural style transfer (NST), first proposed by Gatys et.al. [15], as a data augmentation technique to enhance the effectiveness of our model training process. NST is a technique rooted in deep learning that enables the separation and combination of content and style aspects within images. Specifically, our application leveraged NST to enhance the SSA MRI image quality as a data augmentation method. This technique involved using an SSA MRI image as the content (or source) image and randomly pairing with a GLI MRI image as the style (or target) image. The NST process entailed adapting the stylistic features of the GLI image onto the SSA image, thereby creating new, augmented training samples for SSA cases. Using the Keras functional API, the intermediate layers of a pretrained VGG19 image classification network[16] were used as a feature extractor to obtain the content and style representations of an image. The neural style transfer algorithm computes a loss by evaluating the discrepancies between the stylistic and content features of the generated image and target images. The style loss measures stylistic differences using Gram matrices of feature maps, while the content loss quantifies content dissimilarity through feature map comparisons.\nOverall workflow The proposed methodology is illustrated below in Figure 1. At the time of submission for this short paper, we hereby present results for the nnU-Net best 2D and 3D models, as well as the best pre-trained 2D fullres nnU-Net model trained from GLI+SSA training data fine-tuned on the original and NST-augmented SSA training data. The 5-fold cross-validation model evaluation was based on mean Dice Similarity Coefficient (DSC) after each epoch. A Paired Samples t-test was conducted to compare model performances between datasets and as a function of training time/epochs (significance at p<0.05). Our code was made available on Github: https://github.com/CAMERA-MRI/SPARK2023/tree/main/SPARK_BTS_KIFARU."}, {"title": "3 Results", "content": "3.1 Baseline Model (Optimized U-Net)\nTo establish a robust evaluation, we conducted experiments using the Optimized U-Net [14] on both the GLI and GLI+SSA datasets as part of our foundational benchmarking process. This comparison aimed to elucidate how distributional shifts within training data can influence cross-validated model performance. Table 1 presents outcomes from both datasets. It includes their Dice Similarity Coefficient(DSC), training, and validation losses for the GLI and GLI+SSA datasets, with or without four outlier cases (00051, 00097, 00041, and 00084), as shown in Figure 1 in Appendix. We halted training at 30 epochs for comparative purposes with an experiment using the complete dataset for the same epoch count. From the aforementioned results, a decrease in model performance was observed from a Dice score of 0.89 for the GLI trained dataset to 0.88 for the GLI+SSA dataset at 30 epochs (Table 1). There was no statistical significant difference between the Dice scores of the GLI and GLI+SSA models (p>0.05) or between models when outliers were excluded (p>0.05) (Table 1). However, this exclusion was specific to this experiment, aimed at probing the domain shift issue in multi-institutional data, particularly in the SSA context.\n3.2 nnU-Net Model (version 2)\nWe compared the 3D fullres versus 2D fullres configurations of nnU-Net trained on the GLI+SSA dataset. The best model was considered to have obtained the best 5-fold cross-validation averaged Dice Similarity Coefficient.\nConfiguration name: 3D full resolution Here, we employed the 3D configuration models for the GLI and GLI+SSA datasets, as represented in Table 2. It is evident that the 300 epoch model achieved the best pseudo Dice score at 0.95 and 0.93 for the GLI and GLI+SSA datasets respectively; followed by the 30 epoch model at 0.90 for both the datasets. The paired t-test comparisons between models, showed no statistically significant difference (p>0.05) between the pseudo Dice scores (Table 2)."}, {"title": "3.3 Fine-tuning and neural style transfer on SSA training data as a data augmentation technique together improves SSA validation results", "content": "Despite the 2D fullres nnU-Net trained using GLI + SSA data displaying good performance in five-fold cross-validation and generating satisfactory predictions for previously unseen GLI validation data as illustrated"}, {"title": "4 Discussion", "content": "In this study, we explored the potential to enhance brain tumor segmentation in the resource-limited context of SSA by fine-tuning a pre-trained nnU-Net model with SSA training data augmented using NST, where each sample was paired with a high-quality MRI image from the BRaTS-2021 challenge dataset. Firstly, we highlighted the similarity in the model performance with or without the SSA datasets. The results of the Paired Samples t-test between datasets revealed that there was no significant statistical difference between the performance of the three models as shown in Table 1. The results showed that the model performs equally on both the GLI and GLI+SSA datasets, demonstrating the its generalizability. Secondly, we conducted a comparative analysis between the performance of 3D and 2D full-resolution models, utilizing of nnU-Net (version 2) [12]. Our investigation revealed that both the 2D and 3D full-res nnU-Net models trained for 300 epochs yielded an average pseudo Dice score of 0.93 for the GLI + SSA training data via a 5-fold cross-validation strategy. Thirdly, our validation process on the provided GLI and SSA cases revealed a significant performance discrepancy between the GLI and SSA validation sets. This can be visually inspected by the relatively good prediction for the GLI validation data shown in Figure 2 as compared to Figure 4A in the Appendix. The fusion of the NST data augmentation with subsequent fine-tuning targeted specifically at SSA cases demonstrated significant improvements in results for the SSA validation set (Figure 4B).\nAn important limitation of our study was the scarcity of African datasets. Future work should extend this approach to a larger African dataset to enhance its applicability. Thus, as proposed in the overall methodology workflow in Figure 1, one may ensemble the best 2D fullres and 3D full res nnU-Net model trained from the combined GLI and SSA training data, before repeating the fine-tuning experiment with the NST data augmented SSA in addition to the original SSA training data. Moreover, the availability of higher-quality GLI data should be exploited such that more NST random pairing with the limited SSA training data could be experimented."}, {"title": "5 Conclusion", "content": "As a part of the BRaTS-Africa 2023 Challenge, we have established the viability of enhancing brain tumor prediction within the limited-resource context of Sub-Saharan Africa (SSA). By utilizing a pre-trained and high-performing 2D fullres nnU-Net model, we achieved refinement through fine-tuning using SSA training data augmented via neural style transfer. This methodology underscores the potential for notable performance improvements within SSA's unique healthcare setting."}]}