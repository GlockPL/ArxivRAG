{"title": "Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis", "authors": ["Chiu-Chou Lin", "Yu-Wei Shih", "Kuei-Ting Kuo", "Yu-Cheng Chen", "Chien-Hua Chen", "Wei-Chen Chiu", "I-Chen Wu"], "abstract": "How can balance be quantified in game settings? This question is crucial for game designers, especially in player-versus-player (PvP) games, where analyzing the strength relations among predefined team compositions\u2014such as hero combinations in multiplayer online battle arena (MOBA) games or decks in card games\u2014is essential for enhancing gameplay and achieving balance. We have developed two advanced measures that extend beyond the simplistic win rate to quantify balance in zero-sum competitive scenarios. These measures are derived from win value estimations, which employ strength rating approximations via the Bradley-Terry model and counter relationship approximations via vector quantization, significantly reducing the computational complexity associated with traditional win value estimations. Throughout the learning process of these models, we identify useful categories of compositions and pinpoint their counter relationships, aligning with the experiences of human players without requiring specific game knowledge. Our methodology hinges on a simple technique to enhance codebook utilization in discrete representation with a deterministic vector quantization process for an extremely small state space. Our framework has been validated in popular online games, including Age of Empires II, Hearthstone, Brawl Stars, and League of Legends. The accuracy of the observed strength relations in these games is comparable to traditional pairwise win value predictions, while also offering a more manageable complexity for analysis. Ultimately, our findings contribute to a deeper understanding of PvP game dynamics and present a methodology that significantly improves game balance evaluation and design.", "sections": [{"title": "Introduction", "content": "In the dynamic landscape of player-versus-player (PvP) games, team compositions, or \"comps,\" such as hero combinations or decks formed before matches commence, are pivotal (Costa et al., 2019; de Mesentier Silva et al., 2019; Reis et al., 2021). The gaming industry, now approximately a 200 billion US dollar market (Kristianto, 2023), thrives on the diversity and engagement offered by these compositions, reflecting players' individuality and sustaining market competitiveness (Figueira et al., 2018; Fontaine et al., 2019). However,\nthe key to optimizing player engagement and competitive fairness lies in maintaining reasonable strength relations among diverse team compositions a challenge for both players aiming for victory and designers striving for balance (Levkoff, 2014; Bakkes et al., 2014; Beyer et al., 2016).\nA quantitative measure for game balancing is thus essential for addressing this challenge. Currently, win or success rate, use rate, or even the entropy of strategy distributions are available measures across various game genres, targeting optimizations from detailed game parameters to skill-based matchmaking among players (Morosan & Poli, 2017; Hunicke, 2005; Rupp et al., 2023; Nikolakaki et al., 2020; Pendurkar et al., 2023). However, the prevailing reliance on these measures for balance assessment overlooks critical factors such as player skill variability and the counter relationships between compositions, rendering evaluations imprecise. Traditional player skill ratings, including Elo rating, TrueSkill, and Matchmaking Rating, predominantly focus on individual prowess, leaving a gap in the strength assessment of team compositions (Elo, 1966; Herbrich et al., 2006; Pramono et al., 2018).\nTo better understand strength relations in compositions and analyze game balance, we pose the question: \"How many compositions are not dominated?\" If a composition shows no advantage over others, it could be considered redundant. Hence, our goal in this paper is to define measures that answer this question. We first integrate the Bradley-Terry model with Siamese neural networks (Bromley et al., 1993) to predict the strengths of team compositions from game outcomes under the competitive scenario (Bradley & Terry, 1952; Li et al., 2021). This scalar strength rating helps us identify the strongest or dominating composition more effectively with the numerical max operation compared to the comparison operation over all compositions. However, a single scalar strength often fails to provide precise predictions due to players potentially altering their playstyle under different states (Lin et al., 2021) or the inherent intransitivity present in competitive scenarios (Chen & Joachims, 2016; Balduzzi et al., 2018). Accurate predictions often consider cyclic dominance, such as the Rock-Paper-Scissors dynamic, which the Bradley-Terry model does not capture. By analyzing discrepancies between actual outcomes and Bradley-Terry model predictions, we learn a counter table through neural discrete representation learning (van den Oord et al., 2017), thereby enhancing prediction accuracy and offering insights into counter dynamics without specific game knowledge. During the learning of counter tables, we found that vanilla vector quantization (VQ) training leads to poor codebook utilization (Zhang et al., 2023), especially in small codebook sizes; hence, we proposed a new VQ Mean Loss to improve codebook utilization for this new use case. Leveraging these methods, we define new measures of game balance for counting non-dominated compositions that simple win rates face challenges in computation due to high time complexity.\nOur contributions are threefold: First, we establish two measures for balance by counting the non-dominated compositions: Top-D Diversity, which counts playable compositions given a tolerant win value gap, where the tolerant gap is defined by game designers and can be due to factors like skill or luck that make players willing to play those compositions; and Top-B Balance, which considers counter relationships in counting non-dominated compositions, i.e., how many meaningful counter relationships exist in the game. Next, we introduce the learning of composition strength and counter relationships, reducing the space complexity of analyzing composition strength relations from O(N\u00b2) to O(N+M\u00b2), where N is the number of compositions, and M is the category count of the counter table. This reduction in space complexity is crucial not only for storage reasons but also for generating a feasible size of balance report for game designers. Additionally, the time complexity of Top-D Diversity shifts from O(N2) to O(N) and Top-B Balance from O(N\u00b3) to O(N + M\u00b3). To clarify, this time complexity is only for the strength relationship analysis. The time for collecting game records and obtaining the strength prediction models is not included in this complexity as it depends on how many game records the game designers plan to collect within a given time period and does not necessarily increase with the number of compositions. Lastly, the rating and counter relationships derived from learning align with the experiences of human players without requiring specific game knowledge.\nWe validate our methods across popular online games such as Age of Empires II, Hearthstone, Brawl Stars, and League of Legends, demonstrating precision on par with pairwise strength predictions using neural net- works and also showcasing better generality compared to tabular statistics. Our methodology not only exhibits broad applicability but also underscores its potential to transform the evaluation and design pro- cesses of game balance. Furthermore, we believe these balance measures are not limited to games, as various competitive scenarios\u2014including sports, movie preferences, peer grading, and elections\u2014exhibit intransitiv- ity in comparisons similar to games (Chen & Joachims, 2016). Additionally, the strength measurement of recent large language models (LLMs) also incorporates PvP paradigms (Zheng et al., 2023)."}, {"title": "Game Balance", "content": "Game designers are tasked with devising engaging mechanisms and numerical frameworks that enhance player experiences (Schell, 2008). Developing an immersive game loop not only encourages participation but also assists players in forming a mental model of the game's mechanics (Sellers, 2017). Designers often apply the Yerkes-Dodson law to optimize player satisfaction, suggesting an optimal arousal level for peak performance that aligns in-game challenges with player skill progression (Dodson, 1915). This dynamic interaction is crucial for maintaining players in a state of mental flow (Cs\u00edkszentmih\u00e1lyi, 1990), where game balance plays a pivotal role in sustaining appropriate levels of difficulty and challenge.\nAs a critical research field within game design and operations (Schell, 2008; Novak et al., 2012; Sellers, 2017), game balance significantly influences player engagement through diverse strategies and playstyles. It extends beyond mere difficulty adjustments to encompass strategy, matchmaking, and game parameter tuning (Becker & G\u00f6rlich, 2020). Understanding balance definitions and metrics is vital for effectively addressing these components. Traditional metrics such as win rate, win value difference, and game scores have driven the evolution of game balancing techniques, refining the interplay between game mechanics and player satisfaction (Jaffe et al., 2012; Budijono et al., 2022; Mahlmann et al., 2012).\nIn PvP scenarios, win value estimation is a common approach, with values often normalized to scales like [0,1] or [-1,1] to simplify payoff calculations between competitors (Budijono et al., 2022). However, calibrating the strength of a composition with win values typically requires comparisons against multiple opponents (Fontaine et al., 2019). While strength rating systems like Elo, TrueSkill, and Matchmaking Rating can identify strength from a single scalar rating and suggest greater strength with higher ratings (Elo, 1966; Herbrich et al., 2006; Pramono et al., 2018), capturing intransitivity or cyclic dominance in scalar ratings is challenging. This necessitates multi-dimensional ratings (Chen & Joachims, 2016; Balduzzi et al., 2018), which reintroduce complexity into balance analysis. Thus, this paper aims to propose a solution that considers intransitivity while maintaining feasible complexity in balance analysis.\nAcquiring accurate game data is also crucial for balance analysis, often involving the deployment of rule-based agents during early development phases and integrating human testers later to capture realistic gameplay data. Advances in artificial intelligence, demonstrated by AlphaZero's performance in board games, have enabled learning-based agents to contribute to game balance data collection (Toma\u0161ev et al., 2022). Community discussions about strategies also provide valuable insights, often grounded in game theory principles or defining some empirical relationship graphs by humans to explain the game scenarios (Schmitz, 2022; Hern\u00e1ndez et al., 2020). Although the entropy of a strategy reaching Nash equilibrium can serve as a mea- sure of strategic balance (Pendurkar et al., 2023), computing Nash equilibrium policies at the game action level in complex games is resource-intensive, posing a challenge for practical application in the game design loop (Bowling et al., 2015; Perolat et al., 2022). Although a simpler alternative is using the idea of train- ing adversarial agents or exploiters to identify the weaknesses of main playing strategies (Reis et al., 2024; Vinyals et al., 2019), using rule-based agents or human players as the data source for game balancing is usually more affordable and remains the main approach.\nWith a comprehensive understanding of game balance, this paper focuses on analyzing balance directly through win-lose outcomes from human players and counting the number of meaningful compositions, par- ticularly in two-team zero-sum PvP games. Given the variability of opposing team compositions in matches, our exploration spans multiple game types, from the civilization choices in Age of Empire II to hero com- binations in League of Legends. Our methodology confronts the challenge of cataloging and evaluating an extensive array of possible team compositions, aiming to enhance the understanding and application of game balance. Before introducing our methods, let us formally define the target, \"domination\", in PvP balance analysis.\nDefinition 2.1. Define Win: $C_1, C_2 \\rightarrow w$ as a way to estimate the winner, where $c_1$ and $c_2$ are the compositions of players 1 and 2, respectively, and $w \\in R$, $w \\in [0,1]$ is the estimated win value.\nProposition 2.2. We say composition $c_1$ dominates $c_2$ over all compositions $c$ if $Win(c_1, c) > Win(c_2, C)$.\nWhen Proposition 2.2 is true, $c_2$ is considered useless in terms of win values because $c_1$ can perform better than $c_2$ in all cases. If game designers can validate all compositions with Proposition 2.2, they can analyze game balance by identifying overly strong or useless compositions. If some compositions are very weak or meaningless, leading to most compositions being able to defeat them 100% of the time, thus violating the domination relation, designers can either manually eliminate these compositions from the set of all compositions $c$ or iteratively eliminate dominated compositions by running Proposition 2.2 several times.\nHowever, the time complexity of validating Proposition 2.2 is O(N\u00b3) over N team compositions with a pairwise win value estimation Win(C1, C2). We will try to reduce this complexity with approximations later."}, {"title": "Learning Rating Table and Counter Table", "content": "For understanding the strength relations between compositions (comps) and performing efficient balance analysis, we need to quantify the strength and counter relationships first. Our methodology begins with the application of the Bradley-Terry model to allocate a scalar value representing the strength of each comp based on win estimations. This process is elaborated upon in Section 3.1. To tackle the issue of cyclic dominance or intransitivity of win values efficiently, epitomized by the Rock-Paper-Scissors dynamic, we devise a counter table. This involves examining the variances between actual win outcomes from specific comps and the predictions made by the Bradley-Terry model, a process detailed in Section 3.2. Furthermore, the overarching framework that integrates these components into our learning process is delineated in Section 3.3."}, {"title": "Neural Rating Table", "content": "Win rates in PvP games, while useful as a conventional metric, do not fully encapsulate the actual strengths of individual players or team compositions. A player's or comp's true prowess is better reflected in their ability to triumph over comparable opponents, as victories against both weaker and stronger opponents contribute equally to the win rate but signify different levels of strength. The Elo rating system, commonly utilized in chess and similar two-player zero-sum games, offers a scalar strength rating for entities, aligning with the principles of the Bradley-Terry model (Elo, 1966; Bradley & Terry, 1952). This model predicts the probability of player i defeating player j, as delineated in Equation 1:\n$\\begin{equation}P(i > j) = \\frac{\\gamma_i}{\\gamma_i + \\gamma_j}\\end{equation}$\nwhere $\\gamma_x$ represents the positive real valued strength of player x. To manage the scale of $\\gamma$, it is often reparameterized using a rating value \u03bb in an exponential function, as shown in Equation 2:\n$\\begin{equation}P(i > j) = \\frac{e^{\\lambda_i}}{e^{\\lambda_i}+e^{\\lambda_j}}\\end{equation}$\nAdopting this model, we treat comps analogously to individual players, estimating each comp's strength to predict win probabilities. Given the impracticality of analyzing an extensive N\u00d7N win rate table for a large number of comps, we harness the Bradley-Terry model in conjunction with neural networks to overcome this challenge. Our approach employs a Siamese neural network architecture to deduce the ratings $e^{\\lambda}$ for each comp, utilizing mean square error (MSE) as a regression loss function $D$ for model approximations. In our early experiments, we tried using binary cross entropy as the loss function for its probabilistic nature. However, this approach encouraged the rating values to become very large and prevented the model from converging, similar to using hinge loss. Therefore, we focused on using MSE for stable training.\nThis integration allows our neural network to learn the rating table $R_e$ from match outcomes, assigning a rating to each comp $c$ through $R_e(c)$. The ratings are computed using an exponential activation function to ensure appropriate scaling. The loss function, focused on match outcome $W_m$, is formalized as follows:\n$\\begin{equation}L_R = \\mathbb{E}\\left[ D\\left(W_m, \\frac{e^{R_o(C_m)}}{e^{R_o(C_m)} + e^{R_o(C_{m'})}}\\right)\\right] = \\mathbb{E}\\left[ D\\left(W_m, \\frac{e^{\\lambda_m}}{e^{\\lambda_m} + e^{\\lambda_{m'}}}\\right)\\right]\\end{equation}$\nBy adopting this methodology, our network efficiently processes diverse comp combinations, offering a robust and scalable solution for predicting team composition strengths. We can efficiently identify the strongest composition by tracing the ratings over all compositions with a time complexity of O(N)."}, {"title": "Neural Counter Table", "content": "Within the framework of adapting the Bradley-Terry model through neural networks, we can list the strength of all N team compositions with a space complexity of O(N). However, the precision of strength relations provided by this method may not match the precision afforded by direct pairwise comparisons for each composition, a process that inherently bears a space complexity of O(N2). While theoretically feasible via neural networks, such direct prediction incurs a high space complexity, making it challenging to check these ratings and analyze balance, especially with a large N.\nThe phenomenon of cyclic dominance or intransitivity of win values, a common challenge in analyzing game balance, introduces further complications. An N \u00d7 N counter table, which would record adjustments from rating predictions to enhance accuracy, becomes impractical due to its high space complexity and cognitive load. In practice, players intuitively grasp counter relationships without the need for exhaustive memorization of large tables. To navigate this, we propose a more manageable M \u00d7 M counter table that serves as an approximation of the full N \u00d7 N relationships, where M represents a manageable number of discrete categories. Beginning with a minimum of 3 to capture basic cyclic dominance patterns, M can be adjusted to strike a balance between prediction accuracy and table interpretability.\nFor the task of learning discrete categories, we employ Vector Quantization (VQ), a technique of neural discrete representation learning celebrated for its effectiveness (van den Oord et al., 2017). It acts as an end-to-end analog to K-means clustering within neural networks, primarily introduced in the context of VQ-VAE (van den Oord et al., 2017; Baevski et al., 2020). Our goal diverges from traditional autoencoder objectives; rather than reconstructing inputs, our focus is on developing a counter table that learns from the residuals between direct win predictions and those derived from the Bradley-Terry model."}, {"title": "Neural Discrete Representation Learning", "content": "Before introducing our design for learning the counter table, we first discuss a popular discrete representation learning method with neural networks, VQ-VAE (van den Oord et al., 2017). In scenarios that require discrete representation, clustering is a common approach, with k-means clustering being a widely used method for several decades (MacQueen et al., 1967). This clustering idea is based on finding k reference points in the feature space to represent corresponding groups of actual features using the nearest neighbor method. However, obtaining an effective feature space from raw observations for this clustering process is a critical problem. With the growth of deep learning, variational autoencoder (VAE) (Kingma & Welling, 2014) was proposed to learn effective latent feature spaces for several tasks.\nBuilding on the ideas of autoencoders and k-means clustering, VQ-VAE uses the concept of preparing an embedding codebook and employing the nearest neighbor method to convert continuous latent features into the discrete indexes of the codebook, thereby obtaining the discrete representation. Afterward, we can restore the discrete representations back to continuous for decoding tasks. This discretization process can be formulated with the following notations: Given an observation o and its latent features ze through encoder layers and an embedding space $E = e_1,\\ldots,e_k$ with size K (codebook), we can define the following probability function for mapping o to discrete space:\n$\\begin{equation}q(s = k_0) = \\begin{cases} 1 & \\text{for } k_0 = \\underset{j}{\\text{argmin}}||z(o) - e_j||^2, \\\\ 0 & \\text{otherwise}. \\end{cases}\\end{equation}$\nThrough this mapping, we can train a discrete encoder in an end-to-end manner without the need for feature engineering first as in k-means clustering.\nFor training this neural network, we use the following loss functions:\n$\\begin{equation}L_{rec} = \\mathbb{E}[D(o,o')], L_{vq} = \\mathbb{E}[D(sg[z_e], z_q)], L_{commit} = \\mathbb{E}[D(z_e, sg[z_q])]\\end{equation}$\nHere, D is a distance function, with mean square error (MSE) being a common choice. $z_e$ and $z_q$ are the latent codes before and after nearest neighbor replacement, respectively. The $sg[.]$ denotes the stop-gradient operator. The standard VQ-VAE minimizes the combined loss function $L = L_{rec}+ L_{vq} + \\beta \\times L_{commit}$, where \u03b2 is a weight term that encourages the encoder to produce latent codes closer to discrete representations.\nFor applying this loss to the encoder, we can use the gradient copy trick with the chain rule, as follows:\n$\\begin{equation}\\nabla_{\\theta_{encoder}} = \\frac{\\partial L_{rec}}{\\partial z_q} \\times \\frac{\\partial z_q}{\\partial z_e} \\times \\frac{\\partial z_e}{\\partial \\theta_{encoder}} + \\beta \\times \\frac{\\partial L_{commit}}{\\partial \\theta_{encoder}}\\end{equation}$\nFor applying this loss to the codebook, it is treated as a simple regression optimization problem."}, {"title": "Applying Vector Quantization to the Counter Table", "content": "After a brief understanding of vector quantization with neural networks, we extend this idea of discrete representation to our counter table application. Given the symmetrical nature of residual win values and our aim to classify compositions into M discrete categories, we utilize Siamese network architectures for both the learning of discrete representations and the prediction of residual win values, as illustrated in Figure 2. The residual win value, $W_{res}$, is defined as:\n$\\begin{equation}W_{res} (C_{m_i}, C_{m_j}|R_e) = W_m - \\frac{R_o(C_{m_i})}{R_o(C_{m_i}) + R_o(C_{m_j})}\\end{equation}$\nThe counter table, denoted as $C_o$, comprises a discrete encoder $C_{ee}$ and a residual win value decoder $C_{de}$, functioning as follows:\n$\\begin{equation}C_o(C_{m_i}, C_{m_j}) = C_{do}(C_{eo}(C_{m_i}), C_{eo}(C_{m_j})).\\end{equation}$\nHere, every output of $C_{ee}(x)$ belongs to $C_{ke}$, the embedding space optimized for vector quantization.\nThe core loss function focuses on the residual win values:\n$\\begin{equation}L_{res} = \\mathbb{E}[D(W_{res}(C_{m_i}, C_{m_j}|R_e), C_o(c_{m_i}, C_{m_j}))]\\end{equation}$\ncomplemented by a vector quantization loss:\n$\\begin{equation}L_{vq} = \\frac{\\mathbb{E} [D(z_e(c_{m_i}), z_q(C_{m_i})) + D(z_e(c_{m_j}), z_q (C_{m_j}))]}{2}\\end{equation}$\nwhere $z_e$ represents the latent code before vector quantization, and $z_q$ denotes the code post-quantization.\nIn our application, we require a minimal discrete state space to learn the counter table effectively. We observed low utilization of vectors within the embedding space $C_{ke}$, leading to unselected vectors during training, which cannot construct a comprehensive M \u00d7 M counter table. This low codebook utilization problem is common in VQ, and there are many techniques to improve it (van den Oord et al., 2017; Yu et al., 2022; Shin et al., 2023). Reg-VQ Zhang et al. (2023) specifically discusses this codebook utilization problem and suggests adopting KL divergence in stochastic VQ and leveraging Gumbel sampling over convolutional feature blocks. However, this raises the question of whether there is a simple and easy way to guarantee codebook utilization improvement conceptually and can be easily implemented for the vanilla VQ process for our simple usage. To handle this, we propose a new loss term for embedding vectors, termed VQ Mean Loss, which calculates the distance from the mean vector in the embedding space to the continuous latent code $z_e$. This mechanism can be seen as another K-means clustering, encouraging the vectors in $C_{ke}$ to gravitate towards $z_e$, thus increasing their likelihood of being selected by the nearest neighbor in subsequent iterations. For a more concrete explanation, we provide an example in Appendix A.1. We define this additional loss as:\n$\\begin{equation}L_{mean} = \\mathbb{E} \\frac{[D(z_e(c_{m_i}),\\bar{e}_k) + D(z_e(c_{m_j}), \\bar{e}_k)]}{2} , \\text{ where } \\bar{e}_k = \\frac{1}{M}\\sum{e_k \\in C{ke}}e_k.\\end{equation}$\nThe gradients for each component in the counter table learning process are calculated with the hyperparam- eters $\u03b2_N$ and $\u03b2_M$. $\u03b2_N$ is utilized in VQ-VAE to ensure the continuous latent codes $z_e$ closely align with their quantized versions $z_q$, and we use $\u03b2_M$ to activate $L_{mean}$, respectively:\n$\\begin{equation}\\nabla_{C_{ee}} = \\frac{\\partial L_{res}}{\\partial z_q} \\times \\frac{\\partial z_q}{\\partial z_e} \\times \\frac{\\partial z_e}{\\partial C_{ee}} + \\beta_N \\times \\frac{\\partial L_{vq}}{\\partial C_{ee}} + \\beta_M \\times \\frac{\\partial L_{mean}}{\\partial C_{ee}}, \\nabla_{C_{de}} = \\frac{\\partial L_{res}}{\\partial C_{do}}\\end{equation}$\nBy employing this MXM counter table, win values $W_o$ that consider counter relationships can be computed via Equation 13:\n$\\begin{equation}W_o(C_{m_i}, C_{m_j}) = \\frac{R_o(C_{m_i})}{R_o(C_{m_i}) + R_o(C_{m_j})} + W_{res}(C_{m_i}, C_{m_j}).\\end{equation}$\nThis approach reduces the space complexity of analyzing strength relations for N compositions from O(N2) to O(N + M\u00b2). When M is a small, constant value, the complexity can simplify further to O(N)."}, {"title": "Learning Procedure", "content": "The methodology underlying the construction of the rating and counter tables is encapsulated in the learning framework depicted in Figure 3. This framework requires a dataset consisting of match results, including the team compositions of the competing sides alongside the ultimate win-lose outcomes. The representation of these compositions is adaptable, ranging from simple binary encodings to more nuanced feature descriptions, according to the preferences and requirements set by game designers.\nCrucially, the derivation of the Neural Counter Table $C_o$ is predicated on the prior establishment of the Neural Rating Table $R_e$. This sequential approach ensures that the foundational ratings of team compositions are accurately determined before their interrelations and counter dynamics are analyzed. The development and refinement of these tables pave the way for the introduction of novel measures aimed at enhancing diversity and balance within the gaming environment. A comprehensive discussion of these newly introduced balance measures is forthcoming in Section 5, while the effectiveness and precision of the rating and counter tables will be evaluated in Section 4."}, {"title": "Accuracy of Strength Relations", "content": "With our rating table and counter table, we can approximate the win value of a match given two compositions and identify the strength relations for balance. In this section, we examine the accuracy of strength relations using these tables across different games and investigate the impact of the hyperparameters $\u03b2_N$ and $\u03b2_M$ on counter table training. There are 5 models for each method in our experiments, each trained from a different random seed. The results in the tables are the average values of these models."}, {"title": "New Balance Measures", "content": "The creation of rating and counter tables allows us to devise new ways to measure balance in games, going beyond simple win rates to consider domination relations as described in Proposition 2.2. In games where two players compete against each other, a common goal is to equalize win rates, aiming for each player to have a win rate near 50%. This is easier to achieve in real-time games with symmetric settings for each player, but it is harder in turn-based games because the player who goes first often has an advantage (Beau & Bakkes, 2016). The main challenge in balancing is determining which player has the upper hand and the extent of their advantage. We propose two new ways to measure balance based on estimated win values and explain how to calculate these measures using our approximations to reduce computational complexity.\nNext, we will examine the diversity of comps players might choose in Section 5.1, and identify how many comps might give players an advantage in Section 5.2.\nFirst, let us define some important concepts:\nAssumption 5.1. The Bradley-Terry rating function $R_e(c)$ provides an estimate of $Win = \\frac{R_e(C_1)}{R_e(C_1)+R_e(C_2)}$.\nProposition 5.2. The composition $C_{top}$ with the highest rating $R_o(C_{top})$ over a rating function $R_e$ is con- sidered to dominate all others with lower ratings.\nConsidering Definition 2.1, Proposition 2.2, and Assumption 5.1, we can conclude that Proposition 5.2 is true because $\\frac{x_1}{x_1+y} > \\frac{x_2}{x_2+y}$ when $X_1 > X_2 > 0$. According to Proposition 5.2, if there is only one composition $C_{top}$ with the highest rating, it is considered the best choice before considering counter strategies. This information is often sufficient for some balancing methods, such as identifying and adjusting the strongest comp (Fontaine et al., 2019). The time complexity of identifying $C_{top}$ can be done in O(N) over N comps,"}, {"title": "Top-D Diversity Measure", "content": "We are examining how many different game compositions (comps) players might prefer to play. More choices can enrich the game content for fun and also help designers generate revenue by selling these comps. We want to know which comps players will pick based on their chances of winning. Here are some definitions and assumptions for this measure.\nDefinition 5.3. Let us define an acceptable win value gap G, where G\u2208 R, G\u2208 [0, 1].\nAssumption 5.4. Players think that a small difference in win value, up to G, can be attributed to factors like skill or luck, and they are willing to play again under this belief.\nAssumption 5.5. If a comp c is considered not dominated by $C_{top}$, it is considered not dominated by any comps.\nLemma 5.6. Players are likely to choose comps c where $\\frac{R(c)}{R(c)+R(crop)} +G\\geq 0.5$.\nBy accepting Definition 5.3, Assumption 5.1, Assumption 5.4, Assumption 5.5, and Proposition 2.2, Lemma 5.6 is true, since comps that meet this condition are considered not dominated by any other comps. We use Algorithm 1 to count how many comps meet this condition, and this number represents the game's Top-D Diversity measure, where a larger D implies more diverse game content. The time complexity of this algorithm is O(N) over N comps. Without the property of a single scalar rating, the time complexity to check and define win value gaps on pairwise compositions is O(N2)."}, {"title": "Top-B Balance Measure", "content": "To further explore game balance, we recognize that the dynamics of counterplay are vital, and it is rare to have a single dominating comp. Our goal is to identify the number of comps that are not dominated by any other comps, considering their counter relationships.\nAssumption 5.7. The Bradley-Terry model with the rating function $R_e$, enhanced with a counter table $C_e$, provides more reliable predictions than using the Bradley-Terry model alone.\nBased on Assumption 5.7, we derive the following:\nProposition 5.8. A comp $c_1$ dominates $c_2$ if, for every comp $c$, $Win(c_1,c)+C_o(C_1, c) > Win(c_2, c)+C_o(C_2, c)$.\nHowever, verifying this for all comps is still computationally challenging (O(N\u00b3)). To mitigate this, we can categorize comps and record the top comp of each category, leading to the following propositions:\nProposition 5.9. If comps $c_1$ and $c_2$ fall into the same category in $C_o$, then $c_1$ dominates $c_2$ when $R_e(c_1) > R_o(C_2)$.\nProposition 5.10. If a comp $c_1$ dominates $c_2$ and $c_2$ dominates $c_3$, then $c_1$ also dominates $C_3."}, {"title": "Case Study of Top-D Diversity and Top-B Balance", "content": "With our new balance measures, previous works on game balancing, as mentioned in Sections 1 and 2, can now incorporate these measures to adjust game mechanisms beyond merely achieving a 50% win rate in PvP scenarios. In this section, we conduct two case studies using our measures for direct balance change suggestions in Age of Empires II and Hearthstone, employing our first model of rating and counter tables in the experiments to demonstrate an application. The actual ratings and counter categories of these tables can be found in Appendix A.3. We also discuss the use case and information for suggesting balance updates with our methods and existing approaches, including win rate observations and entropy-based methods."}, {"title": "Case Study on Age of Empires II", "content": "In Age of Empires II, there are 45 civilizations as compositions in 1v1 mode. We first examine the Top-D Diversity measure in Table 6(a). The top composition identified was the Romans with a strength of 1.08145. The result on Top-D Diversity suggests that to enhance general balance, setting the win value's standard deviation larger than 4% is reasonable. Such adjustments could be implemented through matchmaking mechanisms, map randomness, game rule variations, etc. A lower randomness level implies imbalance, forcing almost every player to choose Romans, especially since it is part of the DLC (requiring purchase for competitive advantage).\nRegarding Top-B Balance in Table 6(b), when we assume there are 9 categories considering counter rela- tionships, it showed that one category is dominated. According to our ad-hoc analysis in Appendix A.3.1, it is an economic powerhouse category, and the top civilization in this category is Poles. This indicates the potential necessity to enhance civilizations within this category on their economic bonuses to improve balance, as even the best among them, Poles, is dominated by other top civilizations.\nWhen we extend the size of the counter table to M = 27, Aztecs and"}]}