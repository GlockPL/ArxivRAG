{"title": "PREDICTING HEART FAILURE WITH ATTENTION LEARNING TECHNIQUES UTILIZING CARDIOVASCULAR DATA", "authors": ["Ershadul Haque", "Manoranjan Paul", "Faranak Tohidi"], "abstract": "Cardiovascular diseases (CVDs) encompass a group of disorders affecting the heart and blood vessels, including conditions such as coronary artery disease, heart failure, stroke, and hypertension. In cardiovascular diseases, heart failure is one of the main causes of death and also long-term suffering in patients worldwide. Prediction is one of the risk factors that is highly valuable for treatment and intervention to minimize heart failure. In this work, an attention learning-based heart failure prediction approach is proposed on EHR(electronic health record) cardiovascular data such as ejection fraction and serum creatinine. Moreover, different optimizers with various learning rate approaches are applied to fine-tune the proposed approach. Serum creatinine and ejection fraction are the two most important features to predict the patient's heart failure. The computational result shows that the RMSProp optimizer with 0.001 learning rate has a better prediction based on serum creatinine. On the other hand, the combination of SGD optimizer with 0.01 learning rate exhibits optimum performance based on ejection fraction features. Overall, the proposed attention learning-based approach performs very efficiently in predicting heart failure compared to the existing state-of-the-art such as LSTM approach.", "sections": [{"title": "1 Introduction", "content": "Cardiovascular diseases (CVDs), including coronary heart disease, stroke, and peripheral artery disease, are widely recognized as major causes of death globally. Heart failure is increasing day by day becoming a major health issue. In 2019, these diseases were responsible for approximately 18 million deaths, demonstrating their significant impact on global health[1, 2, 3]. Across the world, more than 620 million people live with circulatory and heart diseases. Heart failure prediction using a deep learning approach based on cardiovascular data has gained significant attention in recent years due to its potential to revolutionize risk assessment and early intervention strategies. Deep learning, a subset of machine learning techniques characterized by multiple computation layers that enable algorithms to learn predictive features from examples, has shown promising results in various cardiovascular applications [4]."}, {"title": "2 Related Works", "content": "Heart failure is a leading cause of death and disability worldwide, making early prediction and intervention crucial. The integration of deep learning in healthcare aims to enhance the accuracy and reliability of stroke prediction models, thus improving patient outcomes[9]. Heart and circulatory diseases encompass a wide range of conditions affecting the heart and circulation, including inherited disorders and those that develop over time like coronary heart disease, atrial fibrillation, heart failure, stroke, and vascular dementia shown in fig.1[10]. The global prevalence of individuals living with these diseases is approximately 620 million, a number that continues to increase due to lifestyle changes, an aging population, and improved survival rates from heart-related events. It is estimated that 1 in 13 individuals worldwide are affected by a heart or circulatory disease. In 2019, there were more women (290 million) than men (260 million) living with these conditions. The prevalence of heart and circulatory diseases has been on the rise over the years, with 285 million people affected in 1990, 350 million in 2000, and over 430 million in 2010. Since 1997, the global population living with these diseases has doubled. The most common cardiovascular conditions include coronary heart disease (200 million), peripheral arterial disease (110 million), stroke (100 million), and atrial fibrillation (60 million). Annually, approximately 60 million individuals worldwide develop a heart or circulatory disease, a figure comparable to the entire population of the UK.\nSeveral studies have demonstrated the potential of deep learning for heart failure prediction. For instance, Mishra and Mohapatra (2023) explored the performance of various machine learning techniques such as Support Vector Machine (SVM), Random Forest (RF), Navies Bayes (NB), Logistic Regression (LR), and Decision Tree (DT) in stroke prediction, highlighting the advantages of deep learning models in handling complex and high-dimensional data [?]. A CNN-based deep learning approach was proposed in [11] to determine to determine coronary-based heart stroke and related risk factors.\nGarg et al. (2023) developed a machine learning model that achieved a high F1-score in stroke prediction using cardiovascular data, emphasizing the model's potential in clinical applications using traditional deep learning approaches such as logistic regression, decision trees, random forests, and the KNN model, Naive Bayes[12]. Moreover, the use of federated learning, as discussed by Bhatt et al. (2023), has shown promise in improving model performance while maintaining data privacy and security [13]."}, {"title": "3 Proposed methodology", "content": "In this section, the proposed approach is described to predict heart failure based on cardiovascular data such as serum creatinine and ejection fraction. In this work, an attention learning approach [24] is proposed to predict heart failure as a risk factor. Fig.2 shows the architecture of the proposed approach to determine heart failure based on cardiovascular data."}, {"title": "3.1 Model architecture", "content": "The encoder considers the input as a sequence of symbol (X1, X2, .....Xn) to a continuous sequence of Z (Z1, Z2, ....Zn) representation. Then, the decoder generates output symbol sequence (Y1, Y2, \u2026\u2026Yn) consequently. For each step, the model is an auto-regressive approach means it considers the previously generated symbol as additional when generating the next symbol. In this way, it uses a point-wise selt attention fully connected approach shown in Fig. 2, where left and right sides indicate the encoder and decoder."}, {"title": "3.1.1 Encoder and decoder block", "content": "The encoder and decoder structure is the most competitive natural language model[25, 26, 27].\nEncoder: It consists of six identical layers. Each layer contains two sub-layers. Multi-head attention is the first layer and feed-forward position-wise fully connected network is the second one. A residual connection [28] is applied followed by the layer normalization[29] around each of the two sublayers. Therefore, LayerNorm(X + Sublayer(X)), where the sublayer is implemented using Sublayer(X) function. All sublayer, and embedding layers in the model architecture produce the output whose dimension is Dmodel = 512.\nDecoder: The decoder consists of 6 indistinguishable layers. It uses a third sub-layer in addition to two encoder layers. The third layer performs multi-head attention. The residual connection is also applied here followed by the layer normalization. In addition, due to the subsequent masking of position in the self-attention layer to the present position, the prediction only depends on the known output which is less than i."}, {"title": "3.1.2 Attention function", "content": "An attention function consists of queries, keys, and values where all are matrics values. The output of the attention block is the weighted sum of the values. The weighted sum is computed by query and keys. The attention function can be expressed as: Attenstion(Q, K, V) = $softmax(\\frac{Q K^T}{\\sqrt{d_k}})V$.\nDot-product attention and additive attention are the two most popular and commonly used attention functions[30]. In theoretical complexity both attention modules are similar. In practical consideration, dot product attention is much faster than other one.\nWhere, Q is the set of queries, K and V are the keys and values matrices. The multi-head attention acquires information from various positions. It can be expressed as follows:\nMultihead(K, Q, V) = Concat(head\u2081, head2, ..head\u0127)W0\nWhere, head\u2081 = Attention(QW, KWK,VWV)."}, {"title": "4 Result and discussion", "content": "In this section, the computational results of the proposed approach are analyzed and discussed. The details of the dataset including its variable and attribute interpretation can be found in [8]. It contains 299 records and 13 fields. It includes various clinical features related to heart failure patients and a target variable indicating death events. The data is clean with no missing values, making it suitable for predictive modeling and statistical analysis."}, {"title": "4.1 Serum creatinine and ejection fraction-based prediction using RMSProp, SGD, and Adadelta optimizer with 0.01,0.001, and 0.0001 learning rate", "content": "Fig. 3 shows the computational result of heart failure prediction using RMSProp, SGD, and Adadelta optimizer with 0.01, 0.001, and 0.0001 learning rate based on ejection fraction and serum creatinine.\nAlso, fig. 3(a), 3(d), 3(d), shows the computational result of the proposed approach using RMSprop optimizer in terms of 0.01, 0.001, and 0.0001 learning rate respectively. Moreover, fig. 3(j) depicts the comparison result of three different learning rates (0.01,0.001,0.0001) compared to actual heart failure happens. It shows that 0.001 learning rate prediction is more accurate compared to the others.\nFurther more, fig.3(b),3(e),3(h) shows the computational result of the proposed approach using SGD optimizer and 0.01,0.001, 0.0001 learning rate based serum creatinine. In addition, fig.3(k) depicts the comparison of the SGD optimizer with 0.1, 0.001, and 0.001 learning rates using serum creatinine. The computational comparison result shows that, compared to the actual number of heart failure, 0.01 learning rate than 0.001 and 0.0001."}, {"title": "4.2 Ejection fraction-based prediction using RMSprop, SGD, Adam optimizer with 0.01, 0.001 and 0.001 learning rates", "content": "Fig 4(g), 4(d), 4(d) shows the heart failure prediction result of the proposed approach using Adam optimizer with 0.001, 0.001 and 0.001 learning rate based on ejection fraction. In addition, fig. 4(j) shows the performance comparison result of Adam optimizer with 0.01, 0.001, and 0.0001 learning rates. Comparison results exhibit that with 0.001 learning rate with Adam optimizer provides better results than 0.01 and 0.0001 learning rates. Furthermore, fig.4(h), 4(e), 4(b) demonstrate the computation result of the proposed approach using RMSProp optimizer and 0.01, 0.001 and 0.0001 learning rate. Moreover, fig.4(k) shows the performance comparison of the proposed approach using RMSProp optimizer with 0.01, 0.001, and 0.0001 learning rates."}, {"title": "4.3 Serum creatinine-based prediction using Adadelta and Adam's optimizer based on 0.01, 0.001, and 0.0001 learning rates", "content": "Fig.5(c) shows the computational result of the LSTM approach using Adam optimizer with a 0.001 learning rate. The X- axis shows the patient's age and the Y- axis represents the total number of heart strokes. The actual value is represented by a blue color and the prediction one is indicated by a yellow color. On the other hand, Fig.5(f) demonstrates the prediction result of the LSTM approach using RMSProp optimizer with a 0.001 learning rate compared to the actual number. The computation result shows that it provides a better result with Adam optimizer with a 0.001 learning rate compared to the RMSProp learning approach.\nFurthermore, fig.5(1) shows the performance comparison of the proposed approach compared to the LSTM approach using Adam optimizer with 0.001 learning rate. The comparison result shows that the proposed approach performs better prediction compared to the LSTM approach. The result is reasonable due to the attention-based learning architecture makes this difference. For the rest of the result analysis, only the proposed model heart failure prediction result is analyzed using various optimizing algorithms with different learning rates.\nIn addition, fig.5 exhibits the heart failure prediction result of the proposed approach using Adadelta, Adam, and RSMprop optimizer using different learning rates such as 0.001, 0.01, and 0.0001 based on ages and serum creatinine. Also, fig.5(f), fig. 5(b),fig. 5(h) depict the heart failure prediction result using an Adadelta optimizer with 0.001, 0.01, and 0.0001 learning rates respectively. Moreover, fig.5(j) demonstrates the comparative view of 0.01,0.001,0.0001 learning rate using Adadelta optimizer compared to the actual prediction values. Comparison results depict that an Adadelta-based 0.01 learning rate provides a better prediction for serum creatinine.\nFurthermore, fig.5(a),fig.5(d),fig. 5(g) shows the computation of the proposed approach based on serum creatinine using Adam optimizer with 0.01, 0.001, and 0.001 learning rates respectively. The comparative view of the Adam optimizer including 0.1,0.001 and 0.0001 learning rates is shown in Fig. 5(j). It has been seen that Adam's optimizer with a 0.01 learning rate shows better results compared to the other learning rate."}, {"title": "5 conclusion", "content": "In this article, we have presented a novel quantum circuit for grayscale quantum image representation and compression. The improvement is done in the state connection circuit for efficient representation and compression. One of the major advantages is that it uses a 16 \u00d7 16 quantum block. Besides, the required number of qubits for state preparation is 8. Any size of the grayscale image could be presented using the proposed SCMNEQR approach. In addition, it uses the universal quantum Toffoli gate, reset gate, and auxiliary qubit. Another advantage of the proposed scheme is that it does not require a look-up table to perform the operation. It is concluded that the performance of the proposed scheme is much better than the existing approaches."}]}