{"title": "PREDICTING HEART FAILURE WITH ATTENTION LEARNING\nTECHNIQUES UTILIZING CARDIOVASCULAR DATA", "authors": ["Ershadul Haque", "Manoranjan Paul", "Faranak Tohidi"], "abstract": "Cardiovascular diseases (CVDs) encompass a group of disorders affecting the heart and blood vessels,\nincluding conditions such as coronary artery disease, heart failure, stroke, and hypertension. In\ncardiovascular diseases, heart failure is one of the main causes of death and also long-term suffering\nin patients worldwide. Prediction is one of the risk factors that is highly valuable for treatment\nand intervention to minimize heart failure. In this work, an attention learning-based heart failure\nprediction approach is proposed on EHR(electronic health record) cardiovascular data such as ejection\nfraction and serum creatinine. Moreover, different optimizers with various learning rate approaches\nare applied to fine-tune the proposed approach. Serum creatinine and ejection fraction are the two\nmost important features to predict the patient's heart failure. The computational result shows that the\nRMSProp optimizer with 0.001 learning rate has a better prediction based on serum creatinine. On the\nother hand, the combination of SGD optimizer with 0.01 learning rate exhibits optimum performance\nbased on ejection fraction features. Overall, the proposed attention learning-based approach performs\nvery efficiently in predicting heart failure compared to the existing state-of-the-art such as LSTM\napproach.", "sections": [{"title": "1 Introduction", "content": "Cardiovascular diseases (CVDs), including coronary heart disease, stroke, and peripheral artery disease, are widely\nrecognized as major causes of death globally. Heart failure is increasing day by day becoming a major health issue. In\n2019, these diseases were responsible for approximately 18 million deaths, demonstrating their significant impact on\nglobal health[1, 2, 3]. Across the world, more than 620 million people live with circulatory and heart diseases. Heart\nfailure prediction using a deep learning approach based on cardiovascular data has gained significant attention in recent\nyears due to its potential to revolutionize risk assessment and early intervention strategies. Deep learning, a subset of\nmachine learning techniques characterized by multiple computation layers that enable algorithms to learn predictive\nfeatures from examples, has shown promising results in various cardiovascular applications [4]."}, {"title": "2 Related Works", "content": "Heart failure is a leading cause of death and disability worldwide, making early prediction and intervention crucial.\nThe integration of deep learning in healthcare aims to enhance the accuracy and reliability of stroke prediction models,\nthus improving patient outcomes[9]. Heart and circulatory diseases encompass a wide range of conditions affecting\nthe heart and circulation, including inherited disorders and those that develop over time like coronary heart disease,\natrial fibrillation, heart failure, stroke, and vascular dementia shown in fig.1[10]. The global prevalence of individuals\nliving with these diseases is approximately 620 million, a number that continues to increase due to lifestyle changes,\nan aging population, and improved survival rates from heart-related events. It is estimated that 1 in 13 individuals\nworldwide are affected by a heart or circulatory disease. In 2019, there were more women (290 million) than men (260\nmillion) living with these conditions. The prevalence of heart and circulatory diseases has been on the rise over the\nyears, with 285 million people affected in 1990, 350 million in 2000, and over 430 million in 2010. Since 1997, the\nglobal population living with these diseases has doubled. The most common cardiovascular conditions include coronary\nheart disease (200 million), peripheral arterial disease (110 million), stroke (100 million), and atrial fibrillation (60\nmillion). Annually, approximately 60 million individuals worldwide develop a heart or circulatory disease, a figure\ncomparable to the entire population of the UK.\nSeveral studies have demonstrated the potential of deep learning for heart failure prediction. For instance, Mishra\nand Mohapatra (2023) explored the performance of various machine learning techniques such as Support Vector\nMachine (SVM), Random Forest (RF), Navies Bayes (NB), Logistic Regression (LR), and Decision Tree (DT) in stroke\nprediction, highlighting the advantages of deep learning models in handling complex and high-dimensional data [?]. A\nCNN-based deep learning approach was proposed in [11] to determine to determine coronary-based heart stroke and\nrelated risk factors.\nGarg et al. (2023) developed a machine learning model that achieved a high F1-score in stroke prediction using\ncardiovascular data, emphasizing the model's potential in clinical applications using traditional deep learning approaches\nsuch as logistic regression, decision trees, random forests, and the KNN model, Naive Bayes[12]. Moreover, the use\nof federated learning, as discussed by Bhatt et al. (2023), has shown promise in improving model performance while\nmaintaining data privacy and security [13].\nRecently, there has been a significant focus on predicting the mortality of patients with heart failure (HF)[14]. In[14]\na deep learning model was introduced for mortality rate prediction. Liu et al. (2022) utilized a fusion-based LSTM\napproach to identify event correlations [15]. However, existing risk prediction strategies have only achieved moderate\nsuccess, possibly due to their reliance on statistical analysis methods that do not fully capture prognostic information in\nlarge datasets with complex interactions[16].\nIn [17], a various traditional machine learning approach were applied to patient heart failure prediction utilizing 18\ndifferent machine learning models to predict heart failure based on 12 clinical features. Two normalization methods,\nz-score, and min-max, were compared, with z-score normalization showing better results. The synthetic minority\nover-sampling technique (SMOTE) was used to address class imbalance and improve prediction accuracy. Feature\nimportance analysis was conducted using XGBoost and CatBoost models to identify significant predictors of heart\nfailure.\nIn [18], a survival risk score was calculated to predict HF using patient-specific characteristics extracted from electronic\nhealth records (EHRs). The conventional classification approach was proposed in categorizing patients with HF into\nsubtypes: heart failure with preserved ejection fraction (HFPEF) and heart failure with reduced ejection fraction\n(HFREF) [19].\nHaque et al. (2023) focus on utilizing deep learning techniques, specifically Long Short-Term Memory (LSTM), to\npredict heart stroke rates[8]. It aims to identify factors that contribute to heart stroke and predict trends for different age\ngroups based on factors like anemia, diabetes, blood pressure, and smoking. It discusses the importance of predicting\nmortality in patients with heart failure, emphasizing the significance of deep learning models. Leveraging a large\nvolume of healthcare datasets and advancements in deep learning, enhances the prediction of heart stroke rates and\nincreases confidence in the LSTM model.\nThe prediction of heart stroke using deep learning techniques based on cardiovascular data has gained significant\ntraction in recent years[20, 21, 22, 23]. This field of research leverages the power of machine learning algorithms,\nparticularly deep learning models, to analyze vast amounts of cardiovascular data to predict the likelihood of a stroke.\nIn summary, the application of deep learning to heart stroke prediction represents a significant advancement in predictive\nhealthcare. By leveraging large datasets and sophisticated algorithms, these models offer a powerful tool for early\ndiagnosis and intervention, potentially reducing the incidence and severity of strokes."}, {"title": "3 Proposed methodology", "content": "In this section, the proposed approach is described to predict heart failure based on cardiovascular data such as serum\ncreatinine and ejection fraction. In this work, an attention learning approach [24] is proposed to predict heart failure as\na risk factor. Fig.2 shows the architecture of the proposed approach to determine heart failure based on cardiovascular\ndata."}, {"title": "3.1 Model architecture", "content": "The encoder considers the input as a sequence of symbol $(X_1, X_2, .....X_n)$ to a continuous sequence of Z\n$(Z_1, Z_2, ....Z_n)$ representation. Then, the decoder generates output symbol sequence $(Y_1, Y_2, \u2026\u2026Y_n)$ consequently.\nFor each step, the model is an auto-regressive approach means it considers the previously generated symbol as additional\nwhen generating the next symbol. In this way, it uses a point-wise selt attention fully connected approach shown in Fig.\n2, where left and right sides indicate the encoder and decoder."}, {"title": "3.1.1 Encoder and decoder block", "content": "The encoder and decoder structure are the most competitive natural language model[25, 26, 27].\nEncoder: It consists of six identical layers. Each layer contains two sub-layers. Multi-head attention is the first layer\nand feed-forward position-wise fully connected network is the second one. A residual connection [28] is applied\nfollowed by the layer normalization[29] around each of the two sublayers. Therefore, $LayerNorm(X + Sublayer(X))$,\nwhere the sublayer is implemented using Sublayer(X) function. All sublayer, and embedding layers in the model\narchitecture produce the output whose dimension is $D_{model} = 512$.\nDecoder: The decoder consists of 6 indistinguishable layers. It uses a third sub-layer in addition to two encoder layers.\nThe third layer performs multi-head attention. The residual connection is also applied here followed by the layer\nnormalization. In addition, due to the subsequent masking of position in the self-attention layer to the present position,\nthe prediction only depends on the known output which is less than i."}, {"title": "3.1.2 Attention function", "content": "An attention function consists of queries, keys, and values where all are matrics values. The output of the attention\nblock is the weighted sum of the values. The weighted sum is computed by query and keys. The attention function can\nbe expressed as: $Attenstion(Q, K, V) = softmax(\\frac{Q K^T}{\\sqrt{d_k}})V$.\nDot-product attention and additive attention are the two most popular and commonly used attention functions[30]. In\ntheoretical complexity both attention modules are similar. In practical consideration, dot product attention is much\nfaster than other one.\nWhere, Q is the set of queries, K and V are the keys and values matrices. The multi-head attention acquires information\nfrom various positions. It can be expressed as follows:\n$Multihead(K, Q, V) = Concat(head_1, head_2, ..head_h)W^O$\nWhere, $head_i = Attention(QW_i^Q, KW_i^K,VW_i^V)$."}, {"title": "4 Result and discussion", "content": "In this section, the computational results of the proposed approach are analyzed and discussed. The details of the dataset\nincluding its variable and attribute interpretation can be found in [8]. It contains 299 records and 13 fields. It includes\nvarious clinical features related to heart failure patients and a target variable indicating death events. The data is clean\nwith no missing values, making it suitable for predictive modeling and statistical analysis."}, {"title": "4.1 Serum creatinine and ejection fraction-based prediction using RMSProp, SGD, and Adadelta optimizer\nwith 0.01,0.001, and 0.0001 learning rate", "content": "Fig. 3 shows the computational result of heart failure prediction using RMSProp, SGD, and Adadelta optimizer with\n0.01, 0.001, and 0.0001 learning rate based on ejection fraction and serum creatinine.\nAlso, fig. 3(a), 3(d), 3(d), shows the computational result of the proposed approach using RMSprop optimizer in terms\nof 0.01, 0.001, and 0.0001 learning rate respectively. Moreover, fig. 3(j) depicts the comparison result of three different\nlearning rates (0.01,0.001,0.0001) compared to actual heart failure happens. It shows that 0.001 learning rate prediction\nis more accurate compared to the others.\nFurther more, fig.3(b),3(e),3(h) shows the computational result of the proposed approach using SGD optimizer and\n0.01,0.001, 0.0001 learning rate based serum creatinine. In addition, fig.3(k) depicts the comparison of the SGD\noptimizer with 0.1, 0.001, and 0.001 learning rates using serum creatinine. The computational comparison result shows\nthat, compared to the actual number of heart failure, 0.01 learning rate than 0.001 and 0.0001.\nFig. 3(c), 3(f), 3(i) exhibits the computational result of the proposed approach using Adadelta optimizer with 0.01,\n0.001, 0.0001 learning rate based on ejection fraction. Moreover, to find the better performance, fig.3(l) shows the\ncomparative view of the proposed approach using Adadelta optimizer and 0.01,0.001,0.0001 learning rates based on\nejection fraction compared to the actual number. Performance comparison shows that 0.01 learning rate performs\nbetter results compared to 0.001, and 0.0001 learning rates. An imperceptible has been found between actual value and\npredicted value due to the learning rate and internal architecture of the Adadelta."}, {"title": "4.2 Ejection fraction-based prediction using RMSprop, SGD, Adam optimizer with 0.01, 0.001 and 0.001\nlearning rates", "content": "Fig 4(g), 4(d), 4(d) shows the heart failure prediction result of the proposed approach using Adam optimizer with\n0.001, 0.001 and 0.001 learning rate based on ejection fraction. In addition, fig. 4(j) shows the performance comparison\nresult of Adam optimizer with 0.01, 0.001, and 0.0001 learning rates. Comparison results exhibit that with 0.001\nlearning rate with Adam optimizer provides better results than 0.01 and 0.0001 learning rates. Furthermore, fig.4(h),\n4(e), 4(b) demonstrate the computation result of the proposed approach using RMSProp optimizer and 0.01, 0.001 and\n0.0001 learning rate. Moreover, fig.4(k) shows the performance comparison of the proposed approach using RMSProp\noptimizer with 0.01, 0.001, and 0.0001 learning rates."}, {"title": "4.3 Serum creatinine-based prediction using Adadelta and Adam's optimizer based on 0.01, 0.001, and 0.0001\nlearning rates", "content": "Fig.5(c) shows the computational result of the LSTM approach using Adam optimizer with a 0.001 learning rate.\nThe X- axis shows the patient's age and the Y- axis represents the total number of heart strokes. The actual\nvalue is represented by a blue color and the prediction one is indicated by a yellow color. On the other hand, Fig.5(f)\ndemonstrates the prediction result of the LSTM approach using RMSProp optimizer with a 0.001 learning rate compared\nto the actual number. The computation result shows that it provides a better result with Adam optimizer with a 0.001\nlearning rate compared to the RMSProp learning approach.\nFurthermore, fig.5(1) shows the performance comparison of the proposed approach compared to the LSTM approach\nusing Adam optimizer with 0.001 learning rate. The comparison result shows that the proposed approach performs better\nprediction compared to the LSTM approach. The result is reasonable due to the attention-based learning architecture\nmakes this difference. For the rest of the result analysis, only the proposed model heart failure prediction result is\nanalyzed using various optimizing algorithms with different learning rates.\nIn addition, fig.5 exhibits the heart failure prediction result of the proposed approach using Adadelta, Adam, and\nRSMprop optimizer using different learning rates such as 0.001, 0.01, and 0.0001 based on ages and serum creatinine.\nAlso, fig.5(f), fig. 5(b),fig. 5(h) depict the heart failure prediction result using an Adadelta optimizer with 0.001, 0.01,\nand 0.0001 learning rates respectively. Moreover, fig.5(j) demonstrates the comparative view of 0.01,0.001,0.0001\nlearning rate using Adadelta optimizer compared to the actual prediction values. Comparison results depict that an\nAdadelta-based 0.01 learning rate provides a better prediction for serum creatinine.\nFurthermore, fig.5(a),fig.5(d),fig. 5(g) shows the computation of the proposed approach based on serum creatinine\nusing Adam optimizer with 0.01, 0.001, and 0.001 learning rates respectively. The comparative view of the Adam\noptimizer including 0.1,0.001 and 0.0001 learning rates is shown in Fig. 5(j). It has been seen that Adam's optimizer\nwith a 0.01 learning rate shows better results compared to the other learning rate."}, {"title": "5 conclusion", "content": "In this article, we have presented a novel quantum circuit for grayscale quantum image representation and compression.\nThe improvement is done in the state connection circuit for efficient representation and compression. One of the major\nadvantages is that it uses a 16 \u00d7 16 quantum block. Besides, the required number of qubits for state preparation is 8.\nAny size of the grayscale image could be presented using the proposed SCMNEQR approach. In addition, it uses the\nuniversal quantum Toffoli gate, reset gate, and auxiliary qubit. Another advantage of the proposed scheme is that it does\nnot require a look-up table to perform the operation. It is concluded that the performance of the proposed scheme is\nmuch better than the existing approaches."}]}