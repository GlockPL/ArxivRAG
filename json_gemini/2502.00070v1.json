{"title": "Can AI Solve the Peer Review Crisis? A Large-Scale Experiment on LLM\u2019s Performance and Biases in Evaluating Economics Papers", "authors": ["Pat Pataranutaporn", "Nattavudh Powdthavee", "Pattie Maes"], "abstract": "We investigate whether artificial intelligence can address the peer review crisis in economics by analyzing 27,090 evaluations of 9,030 unique submissions using a large language model (LLM). The experiment systematically varies author characteristics (e.g., affiliation, reputation, gender) and publication quality (e.g., top-tier, mid-tier, low-tier, AI-generated papers). The results indicate that LLMs effectively distinguish paper quality but exhibit biases favoring prominent institutions, male authors, and renowned economists. Additionally, LLMs struggle to differentiate high-quality AI-generated papers from genuine top-tier submissions. While LLMs offer efficiency gains, their susceptibility to bias necessitates cautious integration and hybrid peer review models to balance equity and accuracy. (100 words).", "sections": [{"title": "1. Introduction", "content": "The economics discipline has long grappled with two persistent challenges in the peer review process: an insufficient supply of willing and qualified referees and prolonged turnaround times, which can extend to two years or more (Ellison, 2002; Card & DellaVigna, 2013). These issues are magnified by the outsized career implications of publishing in the discipline's \"top five\" journals\u2014American Economic Review, Quarterly Journal of Economics, Journal of Political Economy, Econometrica, and Review of Economic Studies (Heckman & Moktan, 2020). To address these challenges, several reforms have been introduced, including shorter article formats (e.g., \u201cInsights\u201d or \u201cShort Papers\"), limitations on revise-and-resubmit rounds, and monetary compensation for referees. While these efforts have yielded some improvements, progress has been incremental rather than transformative. Leading journals such as Econometrica and the Review of Economic Studies, which attract disproportionately high submission volumes (Card & DellaVigna, 2013), continue to face significant difficulties in recruiting referees. These journals have median first decision times of 3\u20136 months, much longer than in psychology (2-4 months) and political science (3\u20134 months). This inefficiency imposes burdens on junior economists, who must navigate stringent tenure requirements that demand multiple publications in top-tier journals within tight timeframes. As a result, delays in the review process exacerbate the already considerable pressures faced by early-career researchers. Recent advancements in large language models (LLMs), such as OpenAI's ChatGPT, have spurred debates about whether artificial intelligence (AI) could alleviate the\""}, {"title": "Abstract", "content": "We investigate whether artificial intelligence can address the peer review crisis in economics by analyzing 27,090 evaluations of 9,030 unique submissions using a large language model (LLM). The experiment systematically varies author characteristics (e.g., affiliation, reputation, gender) and publication quality (e.g., top-tier, mid-tier, low-tier, AI-generated papers). The results indicate that LLMs effectively distinguish paper quality but exhibit biases favoring prominent institutions, male authors, and renowned economists. Additionally, LLMs struggle to differentiate high-quality AI-generated papers from genuine top-tier submissions. While LLMs offer efficiency gains, their susceptibility to bias necessitates cautious integration and hybrid peer review models to balance equity and accuracy. (100 words)."}, {"title": "Equations Section", "content": "We assume editors \u2013 whether consciously or unconsciously \u2013 maximize the journal's true utility for each submitted paper i, which can be expressed as: \n $u_i = \\beta_q q_i + \\beta_r r_i + \\beta_g g_i + \\beta_f f_i + \\epsilon_i$, (1) \n where Ba \u03b2q > 0 represents the journal's weight on intrinsic quality; \u03b2, \u03b2g, \u03b2f > 0 captures biases associated with author prominence, gender, and affiliation; and e\u00a1 is an idiosyncratic noise term reflecting factors unaccounted for in the model. The inclusion of author-related biases in the utility function reflects empirical evidence showing that prestigious affiliations and established reputations confer advantages in the peer review process, even when controlling for paper quality.\n Al, that can be written as: \n $s^{AI}_i = \\alpha_q q_i + \\alpha_b B_i + \\eta_i$, (2) \n where aq > 0 reflects LLM's positive weight on intrinsic quality; Bi = ri + gi + fi, i.e., a composite bias term capturing author attributes; ab > 0 reflects the extent to which LLM\n $P(a_i = 1) = \\Phi (\\frac{\\omega s^{AI}+(1-\\omega)s^{Human}-\\kappa}{\\sigma})$, (5) \n $Bias Amplification = \\frac{\\alpha_b}{\\beta_r + \\beta_g + \\beta_f}$ (7)"}]}