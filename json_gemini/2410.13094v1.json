{"title": "Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation", "authors": ["Wenbo Xu", "Yanan Wu", "Haoran Jiang", "Yang Wang", "Qiang Wu", "Jian Zhang"], "abstract": "Incremental Few-Shot Semantic Segmentation (iFSS) tackles a task that requires a model to continually expand its segmentation capability on novel classes using only a few annotated examples. Typical incremental approaches encounter a challenge that the objective of the base training phase (fitting base classes with sufficient instances) does not align with the incremental learning phase (rapidly adapting to new classes with less forgetting). This disconnect can result in suboptimal performance in the incremental setting. This study introduces a meta-learning-based prototype approach that encourages the model to learn how to adapt quickly while preserving previous knowledge. Concretely, we mimic the incremental evaluation protocol during the base training session by sampling a sequence of pseudo-incremental tasks. Each task in the simulated sequence is trained using a meta-objective to enable rapid adaptation without forgetting. To enhance discrimination among class prototypes, we introduce prototype space redistribution learning, which dynamically updates class prototypes to establish optimal inter-prototype boundaries within the prototype space. Extensive experiments on iFSS datasets built upon PASCAL and COCO benchmarks show the advanced performance of the proposed approach, offering valuable insights for addressing iFSS challenges.", "sections": [{"title": "1 Introduction", "content": "Deep learning models have made remarkable strides in semantic segmentation tasks by training on extensive datasets with rich annotations. In an effort to alleviate the burden of data annotation, Few-shot Semantic Segmentation (FSS) [12,30] has been introduced, aiming to rapidly adapt to novel classes with minimal labeled data rapidly. However, FSS frameworks typically operate under a fixed output space assumption, where the number of target classes is predetermined. This limitation constrains the practicality and scalability of deployment in real-world scenarios where the total number of categories is uncertain, and new class objects may emerge over time.\nIn this work, we address a more challenging and practical scenario where the model continuously encounters a stream of new image data containing instances of previously unseen classes. The objective is to update a model to effectively segment new classes using a few annotated samples while retaining its segmentation capability on existing seen classes. The task known as Incremental Few-Shot Semantic Segmentation (iFSS) in the existing literature [2,33], is inspired by few-shot class incremental learning (FSCIL) [22]. It shares two common challenges, namely catastrophic forgetting of learned knowledge and overfitting to a limited number of novel class examples. This arises due to the absence of access to previous session data during the incremental learning sessions. When updating parameters with imbalanced novel class data (where the number of novel classes is considerably smaller compared to base classes), the model tends to exhibit a strong bias towards novel classes in pursuit of rapid adaptation. Consequently, there is a risk of aggressively overwriting crucial knowledge related to old classes in an attempt to accommodate the latest instances, resulting in a loss of generalization ability.\nThe challenges mentioned above stem from the task misalignment inherent in existing iFSS methods [2,33]. These methods begin by initializing a model that effectively predicts the base classes through classical supervised learning during the base training session. However, in subsequent incremental sessions, the focus shifts to pursuing fast adaptation to novel classes with less forgetting. To overcome this drawback, we propose a meta-learning [5,25] based approach that directly learns to incrementally adapt to novel classes conditioned on a few examples. This is achieved by simulating the incremental few-shot scenario during base session training. Concretely, we sample a sequence of pseudo incremental tasks from the base class dataset. For each pseudo task, the model performs fast adaptation with a few new class examples and updates itself. Then the meta loss is calculated by measuring the performance of the updated model on the test images of both the old and the new classes. The object of the meta loss is meta loss is to incentivize the model to incrementally learn new classes while minimizing the forgetting of the old ones.\nRecently, some FSCIL studies [31,35] trains a backbone network on the base session and subsequently keep its parameters fixed during incremental sessions to maintain a consistent feature extractor. However, in these methods, the feature extractor remains static, implying that the feature space distributed for the base class is reused to accommodate additional classes. Our approach relies on prototype learning, wherein a prototype for a novel class is constructed from its features, forming a prototype classifier alongside the prototypes of the base classes. When generating a prototype for a new class, it may be positioned close to the prototypes of the base classes in the feature space. This can result in"}, {"title": "Task Consistent iFSS", "content": "interference, where a pixel will produce high similarity scores with both new and old prototypes, leading to catastrophic forgetting.\nTo optimize the prototype generation process, we propose a Prototype Space Re-distribution Learning (PSRL) to incrementally learn novel class prototypes and adaptively allocate base and novel prototypes into a latent prototype space, maintaining optimal prototype boundaries. Specifically, we fix the pre-trained feature backbone to preserve a unified feature extractor and introduce a prototype projector mapping intermediate class vectors to a subspace for dynamic prototype distribution. The redistribution process aims to enhance discrimination between new and old class prototypes, thereby improving segmentation performance. Furthermore, it regulates the updated base prototypes placed near their previous position to prevent prototype misalignment, effectively mitigating knowledge forgetting. The contributions of this work are summarized as:\nWe introduce a meta-learning approach that closely aligns the base learning objective with the incremental evaluation protocol. Through training with a series of pseudo incremental tasks, our method directly optimizes the model to enhance the discovery of novel objects while mitigating forgetting\nWe present Prototype Space Re-distribution Learning (PSRL), a method that incrementally learns novel classes while considering inter-prototype discrimination and maintaining base prototype consistency. This approach alleviates catastrophic forgetting of base classes and facilitates rapid adaptation to novel classes.\nExtensive experiments on dedicated iFSS benchmark from PASCAL and COCO datasets demonstrate the proposed method outperforms several counterparts."}, {"title": "2 Related work", "content": ""}, {"title": "2.1 Semantic Segmentation", "content": "Semantic segmentation has witnessed significant advancements through the development of deep learning models. Fully Convolutional Networks (FCNs) [15] marked a significant milestone, enabling end-to-end learning for pixel-wise classification. Building upon this foundation, numerous Convolutional Neural Networks (CNNs) based architectures have been designed in aspects of optimal encoder-decoder frameworks [3], pyramid pooling [32] and multi-scale feature fusion [11]. While CNNs progressively build context through layers, transformers inherently consider the entire image at each stage, allowing them to capture long-range dependencies more effectively. This has led to the development of transformer-based models that introduce strong feature representation [24], hybrid CNN-Transformer architectures [29], and cross-attention decoders [21,4]. Despite their impressive performance, these models typically require a substantial amount of mask-annotated data for training and are limited to predefined categories."}, {"title": "2.3 Incremental Learning", "content": "Incremental learning (IL), also known as lifelong or continuous learning, is an approach within machine learning that focuses on the model's ability to learn continuously, accommodating new knowledge while retaining previously learned information. IL methods can be broadly classified into replay-based [26] and regularization-based [34]. In replay-based methods, samples of previous tasks are either stored or generated at first and then replayed when learning the new task. Zhu et al. [34] propose to store the same number of old samples as each new class to form a joint set during its incremental learning process. Regularization-based methods protect old knowledge from being covered by imposing constraints on new tasks. In iFSS, Cermelli et al. [2] introduced a prototype-based distillation loss to force the current model to retain scores for old classes, thereby preventing forgetting. Guangchen et al. [19] proposes an embedding adaptive-update strategy to prevent catastrophic forgetting, where hyper-class embeddings remain fixed to preserve existing knowledge. To mitigate feature embedding bias, Kai et al. [10] presents class-agnostic foreground perception across multiple targets. Different from those methods, our method exploits the prototype classifier to remember knowledge and directly optimize the learning process with meta-learning tasks."}, {"title": "3 Method", "content": ""}, {"title": "3.1 Problem setting", "content": "iFSS addresses the challenge of updating a pre-trained segmentation model to accommodate newly introduced classes over time, utilizing limited annotated examples for each novel class. Specifically, let $D_{train/test} = \\{I, M\\}_n$, $n \\in \\{1,2,..., K\\}$, $t \\in \\{1, 2, ..., T\\}$, denote a sequence of the training and testing sets of image $I_{train/test}$ and their corresponding semantic label masks $M_{train/test}$. The label classes $C_t$ of each set are disjoint, such that $C_i \\cap C_j = \\emptyset$, $\\forall i \\neq j$. iFSS comprises a base session with abundant labeled training images from $D_0^{train}$ and a sequence of incremental sessions with only a few training images for each novel class from \\{$D_1^{train}$, $D_2^{train}$, \u2026, $D_T^{train}$ \\}. We undertake offline training in the base session to initialize a model using base classes $C^0$. After the base session, the model is expected to adapt to new classes $C^t (t > 0)$ with a few examples in the subsequent incremental sessions. Note that at the $t$th session, the model has access only to $D_t^{train}$ for training and then is evaluated on test images containing all the encountered classes so far, i.e. $\\{D_0^{test} \\cup D_1^{test}... \\cup D_t^{test}\\}$"}, {"title": "3.2 Prototype Space Re-distribution Learning", "content": "Prototype-based Semantic Segmentation. As introduced in [23], typical prototype-based few-shot semantic segmentation frameworks comprise a feature extractor and a prototype classifier. Feature extractor transforms the input image $I \\in \\mathbb{R}^{h \\times w \\times 3}$ into a feature embedding $F \\in \\mathbb{R}^{w \\times h \\times d}$ in a latent space. Subsequently, a prototype classifier $P \\in \\mathbb{R}^{N \\times d}$ is trained to perform pixel-wise predictions for $N$ classes on $F$. For iFSS, our objective is to progressively expand the base prototype classifier $P^0$ with prototypes of novel classes, facilitating the continuous segmentation of newly encountered classes without forgetting prior knowledge. Formally, in an N-class K-shot incremental session (N novel classes and each novel class has K training samples), all training samples $I_n$ are first processed by a feature extractor $f$ and mask average pooling. Subsequently, these samples are averaged over K shots to create N prototypes, denoted as $p(c \\in \\{1,2,...,N\\})$.\n$\\frac{1}{K}\\Sigma_{n=1}^{K}\\frac{\\Sigma_{h,w} [M_{t,n}\\cdot f(I_{t,n})]_{h,w}}{\\Sigma_{h,w} [M_{t,n}]_{h,w}}$ (1)\nwhere $I_{t,n}$ denotes the n-th training image of class c. $M_{t,n} \\in \\mathbb{R}^{h,w,1}$ is the class mask for class c on feature $f (I_{t,n}) \\in \\mathbb{R}^{h,w,d}$. After obtaining N prototypes, the prediction of pixel i of F is assigned according to the normalized cosine similarity score $S_{i,c}(F)$ between features and the class prototype $p_c$ as:\n$S_{i,c}(F) = \\frac{exp (Sim(F_i, P_c)/\\tau)}{\\Sigma_{j=1}^{N} exp (Sim(F_i, p^j)/\\tau)}$ (2)\nwhere $F_i \\in \\mathbb{R}^d$ are the positional features extracted from input image $I$, $N$ represents the cumulative category of prototype vectors up to session $t$, and $\\tau$ is a temperature parameter that controls the concentration level of the distribution [27]. $Sim(\\cdot,\\cdot) = \\frac{\\langle p,q\\rangle}{\\|p\\|\\cdot\\|q\\|}$ is the cosine similarity metric that measures the pixel classification score.\nTraining with few-shot examples in novel class sessions inevitably leads to overfitting and has the potential to undermine the feature extraction capabilities of the pre-train backbone network. Given that our prototype classifier encompasses both base and newly encountered classes, and we have no access to base examples during incremental learning, modulating the extractor may map new classes into a disparate feature space from that of base classes. Therefore, to ensure consistent feature mapping, the backbone is consistently maintained in a fixed state. However, the newly added prototypes may lie close to the base-class prototypes because the prototype is derived from a fixed feature space that is tailored for base classes. To discriminate novel prototypes from their base counterparts, we introduce the prototype projector g to map the current prototypes into a latent prototype space where base and novel prototypes are adaptively distributed to achieve two objectives: i) ensuring clear inter-prototype discrimination among base and novel prototypes for fast adaptation to new classes, and ii) minimizing the displacement of base prototypes away from their original positions to prevent catastrophic forgetting and maintain alignment between features and prototypes. Accordingly, we propose a novel prototype redistribution loss that places the new class prototype $p_t$ at a position far from base prototypes $P_{t-1}$ and relocates base classes to a near-optimal position as:\n$\\mathcal{L}_r = \\frac{\\Sigma_{i=1}^{N_b} \\Sigma_{j=1}^{N_t} Sim (P_i^{t-1}, p_j)}{\\Sigma_{i=1}^{N_b} Sim(P_i^{t-1}, P_i^{t-1})}$ (3)\nwhere $N_b$, $N_t$ are the class prototype number of previous sessions [0, 1, ..., t \u2212 1] and current session t. $P_t^{-1}$ represents the redistributed prototype vector derived from the base prototype $P_{t-1}$. We utilize cosine distance as the metric for the similarity matrix. The loss function $\\mathcal{L}_r$ is designed to minimize the similarity between new class prototypes and base prototypes, concurrently maximizing the similarity between the original base prototypes and their respective redistributions."}, {"title": "3.3 Learning to Incrementally learn", "content": "The core idea underlying our approach is meta-learning inspired by MAML [7] for few-shot tasks. During the meta-training phase, the model is trained with a set of novel class adaptation tasks that are formulated as few-shot learning problems, aiming to simulate the scenario encountered during meta-testing. In iFSS, the online incremental stage closely resembles the \"meta-testing\" stage. This stage entails adapting the model to a sequence of incremental sessions, where each session introduces several novel classes with few-shot examples. Inspired by this, the model is meta-trained on base classes with the goal of mimicking the incremental learning scenario anticipated during the subsequent online incremental learning (i.e., evaluation). This ensures that the model is learned in a manner enabling effective adaptation to new classes with less forgetting.\nSequential task sampling. We replicate the evaluation process by utilizing the base classes. More precisely, we segregate the training images of base classes into distinct training and testing sets with no overlap. In each epoch, we initiate the training process by sampling a sequence of T tasks, $D_{train/test} = \\{(P_j^{train/test}, M_j^{train/test}))\\}_j^T$, where T is the actual incremental session number, and each session include training and testing image-mask pairs. We define $D_0$ as the pseudo base set, comprising more classes and training examples than subsequent tasks (e.g., j > 0) in the few-shot setting. To mitigate the risk of the model overfitting to a particular sequence, we introduce random sampling of classes and their corresponding images"}, {"title": "Meta-training", "content": "During the meta-training phase, for every sampled sequence Dtrain/test, we introduce a prototype redistribution-oriented optimization approach grounded in Meta-Learning. We denote {$\\theta_f$,$\\theta_g$,$\\theta_{seg}$\\} as the parameter for the whole network, where $\\theta_f$, $\\theta_g$, $\\theta_{seg}$ denote the parameters for backbone, prototype projection layer and segmentation head, respectively. We first conduct supervised training of $\\theta$ on the base classes using cross-entropy loss ($L_{CE}$). The meta-training procedure is illustrated in Alg. 1 and Fig.3. At the beginning of training on each sequence, we define an empty cumulative meta test set $D_{meta}$ to store the test images from previous tasks. At the $j^{th}$ task, we first generate the new class prototypes $P_{new}$ and then concatenate it into the current prototype classifier $P_{old}$. Subsequently, we start to perform fast adaptation to new classes and update $\\theta_g$ and $\\theta_{seg}$ via a few L gradient steps:\n$\\theta_{g,seg} \\leftarrow \\theta_{g,seg} - \\lambda \\nabla_{\\theta_{g,seg}} L_{CE} (P_j^{train}, M_j^{train}; \\theta), \\qquad $ (4)\nwhere $P_j^{train}$, $M_j^{train}$ are the images and labels for training $j^{th}$ pseudo task. The loss $L_{CE}(:, :)$ is computed on the output of the current model and the target label $M^{train}$.\nThe adaptation process mimics the model's learning pattern for new classes during incremental sessions. Ideally, we aim for the adapted parameters to perform well in both the classes from the previous and current tasks. The meta-test set accumulated from previous tasks is used for evaluating how well the updated model resists catastrophic forgetting on old classes and adaptation on new classes. We append $D_j^{test}$ to $D_{meta}$, and accordingly, the meta-objective is defined as:\n$\\theta_{g,seg} \\leftarrow \\theta_{g,seg} - \\beta \\nabla_{\\theta_{g,seg}} \\Sigma_{(I,M) \\in D_{meta}} L_{meta} (I, M; \\theta_{g,seg}),$ (5)"}, {"title": null, "content": "Note that $L_{meta}$ is a function designed to optimize {$\\theta_g$,$\\theta_{seg}$\\} with the objective of achieving optimal performance through the redistribution of class prototypes as:\n$L_{meta} = L_{CE}(I_{test}, M_{test}) + \\lambda L_r$. (6)\nWhen all N tasks are done, $D_{meta}$ is reset to empty and we repeat the learning process from the random initialization and adaptation process.\nIn the online incremental learning stage, we execute Lines 5-7 of Alg. 1 to acquire knowledge about novel classes during evaluation. The steps outlined in Alg. 1 align with the evaluation protocol: after being trained on the current session, the model undergoes evaluation on all encountered classes so far. This meta-objective encourages our model to quickly adapt to novel classes without sacrificing remembering old ones."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Dataset", "content": "We evaluate the proposed method on two widely used semantic segmentation datasets: PASCAL VOC 2012 [6] and COCO [14]. Following established practices [2], we evenly partition the classes in PASCAL VOC and COCO into four folds, with each fold containing 5 and 20 categories, respectively. In the validation stage, three folds are used to form the base set, while the categories from the remaining fold are utilized for testing."}, {"title": "4.2 Implementation details and evaluation metrics", "content": "In all experiments, we employ ResNet-101 [9] pre-trained on ImageNet as the feature extractor. Our configuration involves ASPP [3] with a 1x1 convolutional layer as the segmentation head. We evaluate the performance of a method utilizing three mean intersection-over-union (mIoU) metrics: mIoU on base classes (mIoU-B), mIoU on new classes (mIoU-N), and the harmonic mean of the two (HM). Consistent with [2], all reported results are presented upon the completion of training in the final incremental session. Particularly, the single step means while multi-step has multiple sessions: 5 sessions of 1 class on VOC and 4 sessions of 5 classes on COCO."}, {"title": "4.3 Main results", "content": "The outcomes of our method on the PASCAL VOC 2012 and COCO datasets are consolidated in Table 1 and Table 2, respectively. We consider three baselines: Finetune, directly fine-tune the base model with new classes on each session; naive prototype classifier WI [18] and its dynamic version DWI [8]; knowledge-distillation-based method MiB [1]; FSS method HDMNet [17] and iFSS approach SRAA [33]. Our approach demonstrates superior performance in novel class adaptation across most settings for both PASCAL and COCO datasets. Additionally, it achieves state-of-the-art performance in terms of Harmonic Mean (HM) scores across all settings except for 5-shot single step, indicating that our approach effectively balances the retention of information about old classes while facilitating adaptation to new ones. Particularly noteworthy is our method's performance on the PASCAL dataset, where it achieves significantly higher novel class segmentation mIoU scores compared to all other methods, reaching 35.8% and 29.1% in single-step and multi-step settings, respectively. This surpasses the state-of-the-art method (SRAA) by 0.6% and 1.8% under 1-shot setting, respectively. Our meta-learning-based approach exhibits superior fast adaptation capability to novel classes without compromising base class segmentation accuracy, achieving competitive base class segmentation performance on both PASCAL and COCO datasets. In the single-step setting, all the new classes are introduced in a single session. When more samples are provided for a particular class, the model demonstrates improved adaptation to the novel class, as evidenced by the mIoU-N score, albeit with a potential decrease in performance for the base classes. This effect is mitigated in the multi-step setting, where our meta-learning approach effectively learns to resist forgetting through training across multiple sessions\nOn the COCO dataset, our approach showcases significantly greater improvements in HM scores compared to the state-of-the-art method SRAA [33]. For instance, in the task of 5-shot segmentation, our method's HM scores surpass those of SRAA by 3.9% and 2.8%, whereas the margins are only -1.3% and 0.7% on the PASCAL dataset. This highlights the effectiveness of our approach in tackling the more intricate challenges associated with a larger number of classes, which is particularly beneficial in real-world applications."}, {"title": "4.4 Ablation study", "content": "Componet effectiveness. As illustrated in the second row of Table 3, introducing the meta-learning strategy, which trains the model in a manner aligned with the expected evaluation in the incremental sessions, significantly enhances novel class adaptation and mitigates catastrophic forgetting. The application of $\\mathcal{L}_{inter}$ upon meta-learning results in a 0.9% increase in novel class accuracy but induces a 1.3% performance reduction in the base class. It suggests that merely focusing on minimizing the similarity between the new class and the old class prototypes while neglecting the drift of the base class can lead to prototype inconsistency before and after adaptation, resulting in knowledge forgetting.\nBackbone and prototype redistribution. To investigate the performance difference between frozen and updated backbones, we conduct comparison ex-"}, {"title": null, "content": "Coefficient selection. As shown in Fig. 5, we investigate the impact of the coefficient $\\lambda$ in Equation 6 on the model's performance, testing lambda values from 0.1 to 0.6. The objective is to identify the optimal $\\lambda$ that balances regularization with the model's ability to effectively learn new classes.\nOur findings indicate that a $\\lambda$ value of 0.3 achieves the best performance, as evidenced by the peak in the performance of HM under 1-shot setting. This optimal performance at lambda = 0.3 suggests an effective balance between forgetting and adaptability. Lower lambda values, closer to 0.1, may result in insufficient regularization, causing overfitting and poor generalization. Conversely, higher lambda values, approaching 0.6, could overly constrain the model, limiting its ability to adapt to novel classes and thereby degrading performance."}, {"title": "5 Conclusion", "content": "This work addresses a practical scenario of semantic segmentation that incrementally learns novel classes with a few examples. We propose a meta-learning-based approach, directly optimizing the network to acquire the ability to incrementally learn within the few-shot incremental setting. To alleviate catastrophic forgetting and overfitting problems, we introduce a prototype space re-distribution mechanism to dynamically update class prototypes during each incremental session. Extensive experiments on PASCAL and COCO benchmarks demonstrate that the proposed method facilitates a model learning paradigm for quick classes learning without forgetting."}]}