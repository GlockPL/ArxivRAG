{"title": "Variational Control for Guidance in Diffusion Models", "authors": ["Kushagra Pandey", "Farrin Marouf Sofian", "Felix Draxler", "Theofanis Karaletsos", "Stephan Mandt"], "abstract": "Diffusion models exhibit excellent sample quality, but existing guidance methods often require additional model training or are limited to specific tasks. We revisit guidance in diffusion models from the perspective of variational inference and control, introducing Diffusion Trajectory Matching (DTM) that enables guiding pretrained diffusion trajectories to satisfy a terminal cost. DTM unifies a broad class of guidance methods and enables novel instantiations. We introduce a new method within this framework that achieves state-of-the-art results on several linear and (blind) non-linear inverse problems without requiring additional model training or modifications. For instance, in ImageNet non-linear deblurring, our model achieves an FID score of 34.31, significantly improving over the best pretrained-method baseline (FID 78.07). We will make the code available in a future update.", "sections": [{"title": "1. Introduction", "content": "Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2020) and related families (Lipman et al., 2023; Albergo & Vanden-Eijnden, 2023; Liu et al., 2023) exhibit excellent synthesis quality in large-scale generative modeling applications. Additionally, due to their principled design, these models exhibit great potential in serving as powerful generative priors for downstream tasks (Daras et al., 2024).\nConsequently, guidance in diffusion models has received significant interest. However, the dominant approaches to classifier guidance (Dhariwal & Nichol, 2021) and classifier-free guidance (Ho & Salimans, 2021) require training additional models or retraining diffusion models for each conditioning task at hand, or are based on simplistic assumptions detrimental to sample quality (Kawar et al., 2022; Chung et al., 2022a; Song et al., 2022b; Pandey et al., 2024b).\nIn this work, we generalize classifier guidance to a variational control problem (Kappen, 2008). Inspired by ideas such as Control as Inference (Kappen et al., 2012; Levine, 2018), we model guided diffusion dynamics as a Markov chain with the control signals defined as variational parameters. Variational inference is applied to optimize the control signals, ensuring that the process satisfies the desired terminal conditions while keeping the generated samples close to the unconditional sample manifold, see Fig. 1a. We denote this framework as Diffusion Trajectory Matching (DTM).\nRecent work on steering diffusion models has already incorporated ideas from optimal control (Huang et al., 2024; Rout et al., 2024). However, these works focus on a restricted class of control problems. This obscures the available design choices revealed through our novel framework. Indeed, we find that DTM generalizes and explicitly contains a large class of prior work on guidance. We demonstrate the utility of this generalization by introducing a new sampling algorithm that seamlessly integrates with state-of-the-art diffusion model samplers like DDIM (Song et al., 2022a) and adapts well to diverse downstream tasks.\nTo summarize, we make the following contributions:\n\u2022 We propose Diffusion Trajectory Matching (DTM), a generalized framework for training-free guidance based on a variational control perspective. DTM subsumes many existing and novel guidance methods.\n\u2022 We instantiate our framework as Non-linear Diffusion Trajectory Matching (NDTM), which can be readily integrated with samplers like DDIM.\n\u2022 NDTM outperforms previous state-of-the-art baselines for solving challenging noisy linear and (blind) non-linear inverse problems such as superresolution and inpainting with diffusion models (Daras et al., 2024) on FFHQ-256 (Karras et al., 2021) and ImageNet-256 (Deng et al., 2009)."}, {"title": "2. Background", "content": "Diffusion Models. Given a perturbation kernel p(xt|xo) =\n$\\mathcal{N}(\\mu_t x_o, \\sigma_t I_d)$, diffusion models (Sohl-Dickstein et al.,"}, {"title": "3. Guidance with Diffusion Trajectory Matching (DTM)", "content": "We now propose a novel framework based on variational control for guidance in diffusion models. Our framework can be directly applied to pretrained diffusion models without requiring model retraining. For the remainder of our discussion, we restrict our attention to diffusion models and discuss an extension to flow-matching (Lipman et al., 2023) in Appendix A.3.\nIn the following, we first formulate guidance in discrete-time diffusion models as a variational optimal control problem (Section 3.1) following Kappen et al. (2012), which we refer to as Diffusion Trajectory Matching (DTM). We then present specific parameterizations of DTM in Section 3.2, which we work out as a guidance algorithm in Section 3.3. Lastly, in Appendix A.2, we transfer the DTM framework to continuous-time diffusion models (Song et al., 2020) and recover prior work in guidance in diffusion models."}, {"title": "3.1. Variational Control for Diffusion Guidance", "content": "The idea of our guidance framework is to take a controlled deviation from the unguided diffusion trajectory implied by Eq. (1) in Section 2, which we repeat for convenience:\n$Q : q(x_{0:T-1}|x_T) = \\prod_t q(x_{t-1}|x_t)$.\nTo steer the trajectory towards a target state fulfilling external constraints, we introduce a control signal $u_t$ at every time $t$. This yields the following guided dynamics for a given initial state $x_T$:\n$P : p(x_{0:T-1}|x_T, u_{1:T}) = \\prod_t P(x_{t-1}|x_t, u_t)$.\nWhile we model the guided dynamics as Markovian due to convenience, non-Markovian approximations are also possible (Li et al., 2021). Given a set of external constraints, the task is to determine the variational control $u_t$. Consequently, following Kappen et al. (2012), we can pose this problem as a stochastic optimal control problem with the terminal and transient costs formulated as,\n$C(x_T, u_{1:T}) = \\underset{\\text{Terminal Cost }C_{te}}{\\omega_T \\mathbb{E}_{x_0 \\sim p(\\cdot|x_T)}[\\Phi(x_0)]} + \\underset{\\text{Transient Cost }C_{tr}}{DKL(P || Q)}$.\nThe terminal cost in Eq. (8) encodes desirable constraints on the final guided state while the transient cost ensures that the guided trajectory does not deviate strongly from the unguided trajectory, so that the final guided state $x_0$ lies near the image manifold. The two losses are traded by a scalar $w_T$.\nChoice of Terminal Cost. The terminal cost in Eq. (8) encodes desirable constraints on the final guided state. For instance, $\\Phi(x_0) \\propto -\\log p(y|x_0)$ could be the log-likelihood of a probabilistic classifier for class-conditional generation or the degradation process for solving inverse problems. For instance, Huang et al. (2024) adapt guidance for a non-differentiable terminal cost using a path integral control (Kappen, 2005) formulation. While an interesting direction for further work, we only assume that the terminal cost is differentiable for now.\nChoice of Divergence. We use the KL-Divergence as it decomposes over individual timesteps,\n$C_{tr} = \\sum_t \\mathbb{E}_{x_t} [DKL (p(x_{t-1}|x_t, u_t) || q(x_{t-1}|x_t))]$.\nNote that other divergence measures can be useful depending on the specific form of the diffusion posterior (Nachmani et al., 2021; Zhou et al., 2023; Pandey et al., 2024a; Holderrieth et al., 2024).\nSimplifications. The proposed loss in Eq. (8) is generic and principled, but is difficult to jointly optimize for all controls $u_{1:T}$ due to the need to backpropagate through the entire diffusion trajectory. To avoid this computational overhead, we make several simplifications that make the objective computationally tractable. We justify the validity of the modifications through our empirical results in Section 4.\nFirst, we optimize $u_t$ in a greedy manner, that is at any time $t$ in the diffusion process we optimize $u_t$, assuming that the remaining steps $t-1,...,1$ are unguided. After optimizing for $u_t$, we sample from the optimized posterior $x_{t-1} \\sim P(x_{t-1}|x_t, u_t)$ and iterate. When the variational control of $u_t$ is flexible enough, suboptimal greedy choices early in the trajectory can be compensated for later.\nSecond, we evaluate the terminal cost at the current expected final guided state via Tweedie's Formula for $\\mathbb{E}[x_0|x_t, u_t]$:\n$C_{te} = \\mathbb{E}_{x_0}[\\Phi(x_0)] \\approx \\Phi(\\mathbb{E}[x_0|x_t, u_t]) = \\Phi(\\hat{x}_0)$.\nwhere we have approximated $p(x_0|x_t, u_t) \\approx \\delta(x_0 - \\hat{x}_0)$.\nDiffusion Trajectory Matching (DTM). Together, the optimization problem to solve at time $t$ given a position $x_t$ reads:\n$C(u_t) = \\omega_T \\Phi(\\hat{x}_0) + DKL(p(x_{t-1}|x_t, u_t) || q(x_{t-1}|x_t))$.\nWe refer to Eq. (11) as Diffusion Trajectory Matching (DTM)."}, {"title": "Continuous-Time Variants.", "content": "To apply DTM to continuous-time diffusion and flow matching, we adapt the transient costs $C_{tr}$. We call the following Continuous-Time Diffusion Trajectory Matching (CT-DTM), derived for continuous-time diffusion (Song et al., 2020) in Appendix A.2:\n$C_{tr} = \\frac{g(t)^2}{2} - \\mathbb{E}_{x_t} [||s_{\\theta} (x_t, t) - s_{\\theta} (x_t, u_t, t)||^2]$ ."}, {"title": "3.2. Non-linear Diffusion Trajectory Matching (NDTM)", "content": "In the context of Gaussian diffusion models (Ho et al., 2020; Song et al., 2020; Karras et al., 2022), the unguided diffusion posterior is often parameterized as,\n$q(x_{t-1}|x_t) = \\mathcal{N}(\\mu_{\\theta}(x_t, t), \\sigma_t^2 I_d)$\nFor the guided diffusion posterior, we choose the following parameterization such that the control can affect the diffusion dynamics non-linearly.\n$p(x_{t-1}|x_t, u_t) = \\mathcal{N}(\\mu_{\\phi}(x_t, u_t, t), \\sigma_t^2 I_d)$.\nFrom a practical standpoint, since unconditional score models are usually parameterized using neural networks with an input noisy state and a timestep embedding, we further parameterize the posterior mean $\\mu_{\\theta}(x_t, u_t, t) = \\mu_{\\theta} (f(x_t, u_t, t), t)$, where the aggregation function $f : \\mathbb{R}^d \\times \\mathbb{R}^d \\times \\mathbb{R} \\rightarrow \\mathbb{R}^d$ combines the noisy state $x_t$ and the control $u_t$ appropriately. In this work, we choose an additive form of $f = x_t + \\gamma u_t$ where $\\gamma$ is the guidance weight used to update the current noisy state $x_t$ in the direction of the control signal $u_t$. We leave exploring other aggregation functions as future work. Moreover, in practice, we sample from a single diffusion trajectory and therefore omit the expectation in Eq. (11). Consequently, the control cost in Eq. (11) can be simplified as,\n$C(u_t) = ||\\mu_{\\theta}(x_t + \\gamma u_t, t) - \\mu_{\\theta}(x_t, t)||^2 + \\omega_T \\Phi(\\hat{x}_0)$.\nDue to the non-linear dependence of the guided posterior on the control signal $u_t$, we refer to the transient cost specification in Eq. 16 as Non-Linear Diffusion Trajectory Matching (NDTM). We will show in Section 3.4 that linear control can be formulated as a special case of this parameterization, yielding classifier guidance. Next, we instantiate the NDTM objective practically."}, {"title": "3.3. Specific Instantiations", "content": "Here, we present a simplified form of the NDTM objective in the context of DDIM (Song et al., 2022a).\nProposition 3.1. For the diffusion posterior parameterization in DDIM (Song et al., 2022a), the NDTM objective in Eq. 16 has the following tractable upper bound (see proof in Appendix A.1),\n$C(u_t) \\leq k_t^2 ||u_t||^2 + \\tau_t^2 ||\\epsilon_{\\theta}(x'_t, t) - \\epsilon_{\\theta}(x_t, t)||^2 + \\omega_T \\Phi(\\hat{x}_0)$,\nwhere $x'_t = x_t + \\gamma u_t$ is the guided state and the coefficients $k_t = \\frac{\\gamma \\sqrt{a_{t-1}}}{\\sqrt{a_t}}$ and $\\tau_t = \\frac{\\sqrt{1 - a_{t-1}} - \\sigma_t - \\sigma_t \\frac{\\sqrt{a_{t-1}}(1-a_t)}{\\sqrt{a_t}}}{\\sqrt{a_t}}$ are time-dependent scalars.\nThe coefficients $a_t$ and $\\sigma_t$ are specific to DDIM (see Appendix A.1 for more details). Intuitively, the simplified NDTM loss in Eq. (17) measures the deviation between the guided and unguided dynamics, penalizing the magnitude of the control signal $u_t$ (first term) and deviations in the noise predictions (second term). On the contrary, the terminal loss ensures that the expected final guided state satisfies the external constraints. Therefore, the first two terms in Eq. (17) act as regularizers on the control signal $u_t$.\nIn Appendix A.2, we derive this simplification also for continuous-time diffusion models.\nPutting it all together. To summarize, at each diffusion time step $t$, we estimate the control signal $u_t$ by minimizing the cost $C(u_t)$ (for instance Eq. (17) for DDIM). This iterative optimization allows the model to dynamically adjust the control to best align the trajectory with the desired terminal cost while minimizing deviations with the unguided"}, {"title": "3.4. Connection to Existing Guidance Mechanisms", "content": "In this section, we rigorously establish a connection between optimal control and classifier guidance: Our variational formulation in Section 3.1 captures existing approaches. We derive this result in the continuous-time variant, as this allows for a closed-form solution of the control problem.\nIn particular, let us choose a linear parameterization of the guided score in Eq. (12), that is $s_{\\theta}(x_t, u_t, t) = s_{\\theta}(x_t, t) + u_t$. Then, the transient cost reduces to:\n$C_{tr} = \\frac{1}{T} \\int ||u_t||^2 dt$.\nThis is exactly the case of the well-established Path Integral Control (Kappen, 2005; 2008). The solution of this optimal control problem in Eq. (8) reads (Kappen, 2008, Eq. (34)):\n$u = g(t) \\omega_T \\nabla_{x_t} \\log \\mathbb{E}_{p(x_0|x_t)} [\\exp(-\\Phi(x_0))]$.\nNotably, if the terminal cost takes the form of a classifier likelihood $\\Phi(x_0) \\propto -\\log p(y | x_0)$, it can be shown (Huang et al., 2024) that the optimal control simplifies to classifier guidance (Dhariwal & Nichol, 2021): $u = g(t) \\omega_T \\nabla_{x_t} p(y|x_t)$.\nThis puts a large class of methods approximating the expectation over the posterior $p(x_0|x_t)$ (Chung et al., 2022a; Song et al., 2022b; Pandey et al., 2024b; Huang et al., 2024) into perspective: In terms of our DTM framework, they perform optimal control with a linear control mechanism. Empirically, we will see in Section 4 that our generalization to non-linear control provides significant performance improvements."}, {"title": "4. Experiments", "content": "While our method serves as a general framework for guidance in diffusion models, here, we focus on solving inverse problems (IP). Through both quantitative and qualitative results, we demonstrate that our approach outperforms recent state-of-the-art baselines across various (blind) non-linear and linear inverse problems. Lastly, we emphasize key design parameters of our proposed method as ablations. We present full implementation details in Appendix B.\nProblem Setup Given a corruption model $A$ and a noisy measurement $y \\in \\mathbb{R}^d$ the goal is to recover the unknown sample $x_0 \\sim P_{data}$, from the degradation $y = A(x_0) + \\sigma_y z$, $z \\sim \\mathcal{N} (0, I_d)$. For linear inverse problems, $y = Ax_0$ where $A$ can be any matrix. In the case where only the functional form of the degradation operator $A$ is known but its parameters are not, the problem is known as Blind IP."}, {"title": "A.1. Simplification of the NDTM Objective for DDIM", "content": "We restate the theoretical result for convenience.\nProposition A.1. For the diffusion posterior parameterization in Song et al. (2022a), the objective in Eq. 16 can be simplified as (see proof in Appendix A.1),\n$C \\leq k_t^2 ||u_t||^2 + \\tau_t^2 || \\epsilon_{\\theta}(x'_t, t) - \\epsilon_{\\theta}(x_t, t)||^2 + \\omega_T \\Phi(\\hat{x}_0)$.\nwhere $x'_t = x_t + \\gamma u_t$ is the guided state and the coefficients $k_t = \\frac{\\gamma \\sqrt{a_{t-1}}}{\\sqrt{a_t}}$ and $\\tau_t = \\frac{\\sqrt{1 - a_{t-1}} - \\sigma_t - \\sigma_t \\frac{\\sqrt{a_{t-1}}(1-a_t)}{\\sqrt{a_t}}}{\\sqrt{a_t}}$ are time-dependent scalars.\nProof. In the case of DDIM (Song et al., 2022a), the diffusion posterior is parameterized as (Eqn. 12 in Song et al. (2022a)),\n$\\mu_{\\theta'}(x_t, t) = \\frac{\\sqrt{a_{t-1}}}{\\sqrt{a_t}}x_t + \\sqrt{1-a_{t-1} - \\sigma_t^2} \\frac{\\sqrt{a_{t-1}(1-a_t)}}{\\sqrt{a_t}} \\epsilon_{\\theta}(x_t, t)$.\nwhere the diffusion noising process is parameterized as $p(x_t|x_0) = \\mathcal{N}(\\sqrt{a_t}x_0, (1 - a_t)I_d)$ and $\\epsilon_{\\theta}(x_t, t)$ is a pretrained denoiser which models $\\mathbb{E}[x_t|x_0]$ and intuitively predicts the amount of noise added to $x_0$ for a given noisy state $x_t$ at time t. Additionally, for notational convenience, we denote the coefficient of the denoiser in Eq. 21 as $\\tau_t$. Following Song et al. (2022a), the coefficient $\\sigma$ is further defined as,\n$\\sigma_t = \\sqrt{\\frac{(1 - a_t - \\sigma_t^2)}{a_t}}$.\nIt follows that,\n$\\mu_{\\theta'}(x_t, t) = \\frac{\\sqrt{a_{t-1}}}{\\sqrt{a_t}}x_t + \\tau_t \\epsilon_{\\theta}(x_t, t)$\n$\\mu_{\\theta'}(x_t + \\gamma u_t, t) = \\frac{\\sqrt{a_{t-1}}}{\\sqrt{a_t}}(x_t + \\gamma u_t) + \\tau_t \\epsilon_{\\theta}(x_t + \\gamma u_t, t)$\n$ \\frac{\\sqrt{a_{t-1}}}{\\sqrt{a_t}}x_t + \\frac{\\gamma \\sqrt{a_{t-1}}}{\\sqrt{a_t}} u_t + \\tau_t \\epsilon_{\\theta}(x_t + \\gamma u_t, t)$\nwhere we denote the coefficient of the control signal $u_t$ in the above equation as $k_t$ for notational convenience. Consequently, the NDTM cost in Eq. 16 can be simplified for the DDIM posterior parameterization in Eq. 21 as,\n$C = [||\\mu_{\\theta}(x_t + \\gamma u_t, t) - \\mu_{\\theta}(x_t, t)||^2 + \\omega_T \\Phi(\\hat{x}_0)]$\n$= [||k_t u_t + \\tau_t(\\epsilon_{\\theta}(x_t + \\gamma u_t, t) - \\epsilon_{\\theta}(x_t, t))||^2 + \\omega_T \\Phi(\\hat{x}_0)]$\n$\\leq k_t^2||u_t||^2 + \\tau_t^2||\\epsilon_{\\theta}(x_t + \\gamma u_t, t) - \\epsilon_{\\theta}(x_t, t)||^2 + \\omega_T \\Phi(\\hat{x}_0)$\nwhere (i) follows from the triangle inequality. This completes the proof."}, {"title": "A.2. Continuous-Time Diffusion Trajectory Matching", "content": "Analogous to the discrete case, we represent unguided diffusion dynamics using the following continuous-time reverse diffusion dynamics (Anderson, 1982; Song et al., 2020),\n$dx_t = [f(t)x_t - g(t)^2 s_{\\theta}(x_t, t)] dt + g(t)dw_t$,"}, {"title": "A.3. Extension to Flow Matching Models", "content": "For continuous flow matching models (Lipman et al., 2023; Albergo & Vanden-Eijnden, 2023; Liu et al., 2023) with a vector field $v_{\\theta} (x_t, t)$,\n$dx_t = v_{\\theta} (x_t, t) dt$,\nwe insert the control signal into the dynamics through an additional dependence of the velocity field:\n$\\frac{dx_t}{dt} = v_{\\theta} (x_t, u_t, t)$.\nSince flow matching uses the squared loss, it is natural to regularize deviation from the unguided trajectory in terms of the velocity field:\n$C_{tr} = \\int ||v_{\\theta}(x_t, u_t, t) - v_{\\theta} (x_t, t)||^2 dt$"}, {"title": "B. Implementation Details", "content": "In this section, we include practical implementation details for the results presented in Section 4."}, {"title": "B.1. Task Details", "content": "Here, we describe the task setup in more detail.\nSuperresolution (x4): We follow the setup from DPS (Chung et al., 2022a), More specifically,\n$y \\sim \\mathcal{N}(y|L_\\pounds x, \\sigma_y^2 I_d)$,\nwhere $S_f$ represents the bicubic downsampling matrix with downsampling factor $f$. In this work, we fix $f$ to 4 for both datasets.\nRandom Inpainting (90%) We use random inpainting with a dropout probability of 0.9 (or 90%). For this task, the forward model can be specified as,\n$y \\sim \\mathcal{N}(y|Mx, \\sigma_y^2 I_d)$\nwhere $M \\in \\{0, 1\\}^{d \\times d}$ is the masking matrix."}, {"title": "Non-Linear Deblurring", "content": "We use the non-linear deblurring setup from DPS. More specifically, we use the forward operator $F_\\phi$ (modeled using a neural network) for the non-linear deblurring operation. Given pairs of blurred and sharp images, $\\{x_i, y_i\\}$, one can train a forward model estimator as (Tran et al., 2021),\n$\\phi = arg min \\sum_i ||y_i - F_\\phi(x_i, G_\\xi(x_i, y_i))||^2$\nwhere $G$ extracts the kernel information from the training pairs. At inference, the operator $G$ can instead be replaced by a Gaussian random vector $g$. In this case, the inverse problem reduces to recovering $x_i$ from $y_i$. In this work, we directly adopt the default settings from DPS.\nBlind Image Deblurring (BID) We directly adopt the setup for blind image deblurring from DMPlug (see Appendix C.4 in Wang et al. (2024) for more details). More specifically, in the BID task, the goal is to recover the kernel $k$ in addition to the original signal $x_0$ such that,\n$y = k * x_0 + \\sigma_y z$\nIn this work, we adapt the default settings from DMPlug. For BID (Gaussian), the kernel size is 64 \u00d7 64 with the standard deviation set to 3.0. For BID (Motion), the kernel intensity is adjusted to 0.5."}, {"title": "B.2. Task Specific Hyperparameters", "content": "Here, we provide a detailed overview of different hyperparameters for the baselines considered in this work. We optimize all baselines and our method for the best sample perceptual quality. We use the official code implementation for RED-Diff (Mardani et al., 2023a) at https://github.com/NVlabs/RED-diff, https://github.com/mandt-lab/c-pigdm and https://github.com/sun-umn/DMPlug for running all competing baselines."}, {"title": "B.2.1. DPS (CHUNG ET AL., 2022A)", "content": "We adopt the DPS parameters from Mardani et al. (2023a). More specifically, we fix the number of diffusion steps to 1000 using the DDIM sampler. We set $\\eta = 0.5$ for all tasks. Following Chung et al. (2022a), we set,\n$\\zeta = \\frac{a}{\\mathbb{E}[||y - A(x_0)||^2]}$"}]}