{"title": "AGENT-ORIENTED PLANNING IN MULTI-AGENT SYSTEMS", "authors": ["Ao Li", "Yuexiang Xie", "Songze Li", "Fugee Tsung", "Bolin Ding", "Yaliang Li"], "abstract": "Through the collaboration of multiple agents possessing diverse expertise and tools, multi-agent systems achieve impressive progress in solving real-world problems. Given the user queries, the meta-agents, serving as the brain within these systems, are required to decompose the queries into multiple sub-tasks that can be allocated to suitable agents capable of solving them, so-called agent-oriented planning. In this study, we identify three critical design principles of agent-oriented planning, including solvability, completeness, and non-redundancy, to ensure that each sub-task is effectively resolved, leading to satisfactory responses to the original queries. These principles further inspire us to propose a novel framework for agent-oriented planning in multi-agent systems, leveraging a fast task decomposition and allocation process followed by an effective and efficient evaluation via a reward model. During the planning process, the meta-agent is also responsible for evaluating the performance of the expert agents, making timely adjustments to the sub-tasks and scheduling as necessary. Besides, we integrate a feedback loop into the proposed framework to further enhance the effectiveness and robustness of such a problem-solving process. Extensive experiments demonstrate the advancement of the proposed framework in solving real-world problems compared to both single-agent systems and existing planning strategies for multi-agent systems.", "sections": [{"title": "INTRODUCTION", "content": "In recent years, large language models (LLMs) (Achiam et al., 2023; Chowdhery et al., 2023; Tou-vron et al., 2023) have achieved impressive breakthroughs in natural language understanding and generation, marking a critical advancement in the exploration of artificial general intelligence (AGI).\nAs the capabilities of LLMs progress, LLM-empowered agents (Qin et al., 2023b; Dong et al., 2023;\nWang et al., 2024) emerge as key components for integrating expertise and tools to translate these advancements into practical applications effectively. Advancing this paradigm, multi-agent systems (Shen et al., 2024; Chen et al., 2023; Wu et al., 2023b), which involve multiple diverse agents, provide great flexibility and adaptability by leveraging and collaborating on the strengths of various agents, promoting comprehensive solutions to complex real-world problems.\nPrevious studies (Cai et al., 2023; Qian et al., 2023) propose to define suitable standard operating procedures (SOPs) based on the insights and experiences of human professionals for solving specific tasks, such as software development (Hong et al., 2023) and simulating personality traits (Serapio-Garc\u00eda et al., 2023). In these scenarios, multiple agents are assigned to execute tasks following the predefined SOPs, resulting in remarkable successes. However, for multi-agent systems designed to tackle a diverse range of complex real-world problems, there is a critical need for a central entity that can automatically generate task-specific operating procedures and coordinate the activities of various agents (Wang et al., 2024).\nThis central entity, typically referred to as a meta-agent (a.k.a. a controller or planner), carries two primary responsibilities. Firstly, the meta-agent needs to comprehend user queries and decompose them into several sub-tasks, ensuring that each sub-task can be adequately addressed by a single agent. Secondly, the meta-agent is also expected to assign these sub-tasks to the appropriate agents for execution, enabling the solutions of these sub-tasks to collectively provide comprehensive answers to the original user query.\nHowever, since the meta-agent cannot effectively associate sub-tasks based on the provided agent descriptions, the performance of task decomposition and allocations might be sub-optional. To tackle these challenges, we identify three design principles for an agent-oriented planning framework, including solvability, completeness, and non-redundancy, which further inspire us to propose a novel framework for multi-agent systems.\nSpecifically, to resolve a user query, the meta-agent first performs fast task decomposition and al-location, which serves as the intermediate results that can be further modified and revised. The proposed framework incorporates a reward model designed to efficiently evaluate the solvability of sub-tasks without requiring actual agent calls. According to the evaluation results, some sub-tasks may be executed by the assigned agents, others may be recognized as inappropriate and be required to perform a replan, while the remaining sub-tasks would be further assessed through the representative works mechanism, which helps determine whether they should be planned in detail or re-described for better aligning the ability of agents. A detector is utilized to identify the missing key information or redundant content in the decomposed sub-tasks, and to provide suggestions to the meta-agent for enhancing the completeness and non-redundancy. Besides, a feedback loop is integrated into the proposed framework to promote ongoing enhancements for the meta-agent.\nExtensive experiments are conducted based on a reasoning dataset that needs the collaboration of multiple agents. The comparisons between the proposed agent-oriented planning framework and baseline methods demonstrate the remarkable advancements achieved by the proposed framework. Besides, we conduct an ablation study to confirm the contributions of the different components in the proposed framework, and provide discussions on the potential for further improvements in the performance of agent-oriented planning within multi-agent systems."}, {"title": "PRELIMINARIES", "content": "Definition of Agent-Oriented Planning In this study, a multi-agent system involves a series of LLM-empowered agents that possess diverse expertise and tools. These agents are designed to leverage their expertise and tools to resolve specific real-world tasks. For example, a search agent can utilize search engines to retrieve up-to-date information relevant to a given query, while a code agent is capable of generating code and executing the code via a code interpreter. The collaboration among these agents is facilitated by a meta-agent, which serves as the brain of the multi-agent systems. When a user query is submitted to the multi-agent system, the meta-agent sends the relevant requests to the appropriate agents, optimizing for both effectiveness and efficiency. The responses produced by these agents are finally aggregated and synthesized to generate a comprehensive answer to the original user query.\nFormally, given a user query Q, a meta-agent P needs to select some appropriate agents from a total of n agents, denoted as A = {A1, ..., An}. Each agent is associated with a description d that outlines its capability. We denote the collection of all agent descriptions as D = {d1, ..., dn}. The user query Q is decomposed into m sub-tasks, with each sub-task assigned to a specific agent based on their descriptions:\n$P(Q,D, A) = {\\{(q_i, A_i)\\} | i \\in [m]}.$ \nAfter that, each selected agent $i \\in [m]$ produces a response to its assigned sub-task, denoted as $r_i = A(q_i)$. These responses are then utilized to generate the final answer based on $R = {r_1, ..., r_m}$ to resolve the original query Q. Such a process is called agent-oriented planning.\nChallenges The challenges of agent-oriented planning in multi-agent systems can be two-fold. Firstly, different from existing studies focused on task decomposition or chain-of-thought rea-soning, agent-oriented planning requires intentional decomposition of user queries to effectively associate sub-tasks with agents, which includes considerations of the description of sub-tasks, the granularity of decomposition, the format of the responses, and so on. An example is illustrated at the higher left of Figure 1. Given a user query \"How much tin (kg) with 100 kg of copper can lower the mixture's melting point to 800 \u00b0C?\", a naive decomposition might suggest \u201cdetermine the melting point of tin and copper.\" followed by \"calculate the amount of tin (kg) required to reduce the melting point of the mixture to 800 \u00b0C with 100 kg of copper.\". However, when the sub-task of"}, {"title": "Design Principles", "content": "We further identify three critical principles that guide the design of our frame-work for effective and efficient agent-oriented planning in multi-agent systems:\n\u2022 Solvability. Each sub-task $q_i \\forall i \\in [m]$ should be independently and completely resolvable by at least one single agent within the multi-agent system, ensuring that the response for each sub-task can be reliable. If a sub-task does not satisfy solvability, the meta-agent is expected to take some modifications or further decomposition.\n\u2022 Completeness. The array of sub-tasks $\\{q_1, ..., q_m \\}$ should include all necessary information from the original user query Q, which ensures that the aggregation of responses of these sub-tasks can effectively yield a comprehensive answer to the user query. If the decom-posed sub-tasks fail to satisfy completeness, the decomposition process should be revisited by the meta-agent.\n\u2022 Non-Redundancy. The array of sub-tasks $\\{q_1,..., q_m\\}$ should not include redundant ele-ments, avoiding those task executions that are either irrelevant to resolving Q, or duplicated. The principle of non-redundancy promotes that the sub-tasks form a minimal effective set necessary to address the user query, enhancing overall efficiency."}, {"title": "AGENT-ORIENTED PLANNING IN MULTI-AGENT SYSTEMS", "content": "In this section, we introduce the details of the proposed agent-oriented planning framework. The overall architecture is illustrated in Figure 2."}, {"title": "FAST DECOMPOSITION AND ALLOCATION", "content": "First of all, following existing studies (Shen et al., 2024; Chen et al., 2023), we provide detailed instructions to the meta-agent to guide it in performing agent-oriented planning. Different from pre-vious studies, the provided instructions incorporate the following requirements: (i) Integration of user query Q and all the agent descriptions A: We include both the user query and the descriptions of agents in the instructions, promoting the meta-agent to fully consider the capabilities of each agent and tailor the sub-tasks to align with these capabilities. (ii) Suggestions for assigned agents: We require the meta-agent to provide suggestions for the agents assigned to each decomposed sub-task. Although we tend to separate task decomposition and assignment into two independent tasks performed sequentially, the experimental observations indicate that combining these two tasks en-hances the effectiveness of agent-oriented planning. (iii) Structured decomposition of tasks: The decomposed tasks are required to be structured in a sequential manner, specifying any dependencies that may exist between sub-tasks, which ensures that the execution of tasks follows a correct logical order.\nThe aforementioned process of agent-oriented planning, which is called fast decomposition and al-location in this study, heavily relies on the capabilities of the meta-agent and meticulously designed system prompts. While such an end-to-end approach can achieve high efficiency, its success rate, namely fulfilling the three design principles mentioned above and providing reliable answers to the original user query, and its stability, namely the meta-agent can follow instructions and produce formatted responses, might not be satisfactory.\nInspired by recent studies on scaling laws during inference (OpenAI, 2024b), we propose to design mechanisms to guide the meta-agent toward more comprehensive reasoning processes. The results of fast decomposition and allocation should be viewed as intermediate outputs rather than final results, which need to be further evaluated to offer detailed revision suggestions for the meta-agent."}, {"title": "Is A SUB-TASK COMPLETELY RESOLVED?", "content": "To determine whether a sub-task can be resolved by a single agent, i.e., satisfying the principle of solvability, a straightforward solution is to send the sub-task to every agent in the system. Each agent generates a response to the sub-task, allowing us to select the best answer and assess whether it completely resolves the sub-task. However, this approach is often impractical due to the unafford-able overhead. For a user query decomposed into m sub-tasks, a multi-agent system with n agents would need to execute a total of m \u00d7 n agent calls for just a single trial, making it an inefficient strategy in scenarios with a large number of agents and sub-tasks.\nTo tackle this, we propose a reward model designed to provide efficient evaluations of the solv-ability of sub-tasks, which aims to predict the quality of the agents' responses to sub-tasks without necessitating actual agent calls.\nSpecifically, we first prepare a dataset for training the reward model. For a given user query Q, we follow the fast decomposition and allocation process introduced in Section 3.1, requiring the meta-agent to decompose Q into several sub-tasks and select l agents for each sub-task based on the agents' descriptions, which can be formally given as follows:\n$P(Q,D, A) = {\\{(q_i, A_{i,1}, ..., A_{i,l})\\} | i \\in [m]}.$\nAfter that, we execute the plan, i.e., sending the sub-tasks to the assigned agents, and obtain all the responses from agents as:\n$\\{r_{i,j} = A_{i,j}(q_i) | i \\in [m], j\\in [l]\\}.$\nwhere the choice of l can be a trade-off. A large l leads to comprehensive responses from lots of agents for constructing the training dataset, while it might need more computation resources and affect the overall quality of the dataset. In this study, we set l to be half the number of agents in the multi-agent systems.\nWe utilize a scorer S that evaluates agents' responses to sub-tasks, i.e., $S(q_i, r_{i,j}) = S_{i,j}$, which serves as annotations in the training dataset. The scorer S provides evaluations from three key aspects: correctness, relevance, and completeness, and can be implemented using powerful LLMS (OpenAI, 2024a) or human annotators. We apply this scoring process across a diverse ar-ray of user queries $Q = \\{Q_k\\}_{k=1}^K$ and collect the results to form the training dataset, denoted as $T = \\{(q_{k,i},d_{k,i},j, S_{k,i,j}) | k \\in [K], i \\in [m_k], j \\in [l]\\}$. More details on the construction of the dataset, such as the adopted prompts, are summarized in Appendix C.\nThe reward model, parameterized as 0, consists of embedding layers followed by fully connected layers. We obtain embeddings for both the sub-task and the agent's description separately, then concatenate these embeddings together and feed them into the fully connected layers for further processing. To provide evaluations without making actual agent calls, we design a training objective aimed at minimizing the discrepancies between the model's predictions and the annotations provided by the scorer, which can be formulated as follows:\n$L(T, \\theta) = \\frac{1}{K} \\sum_{k=1}^K \\frac{1}{m_k} \\sum_{i=1}^{m_k} \\frac{1}{l} \\sum_{j=1}^l (S_{k,i,j} \u2013 M_\\theta(q_{k,i}, d_{k,i,j}))^2.$\nWith the well-trained reward model, the evaluation of the results produced by fast decomposition and allocation can be summarized as follows. For each suggestion provided by the meta-agent, stating the assignment of sub-task $q_i$ to agent A, the reward model predicts a score denoted as $M_\\theta(q_i, d_i)$. A sufficiently high predicted score, which implies that $q_i$ can be completely resolved by agent A, leads to the acceptance of this suggestion. Conversely, if the predicted score falls below a predefined threshold, which indicates that the assignment should be revisited by the meta-agent, the reward model provides a set of scores $\\hat{s}_{i,j} = M_\\theta(q_i, d_j)$ for all the agents $A_j, j = 1, ..., n$.\nFrom these scores, the meta-agent reports the optimal solution as $j_{max} = argmax_j \\hat{S}_{i,j}$.\nNote that there may be scenarios where the highest score $\\hat{S}_{jmax}$ is still below the threshold, indicating that the sub-task $q_i$ does not satisfy the principle of solvability and that no single agent can resolve it independently. In these cases, the meta-agent P is required to perform a replan on $q_i$."}, {"title": "SUB-TASK MODIFICATIONS", "content": "In addition to the two scenarios mentioned in Section 3.2, where the assignment of sub-task $q_i$ to agent A is either predicted to be acceptable by the reward model or to be entirely inappropriate and requires a replan process, there also exists another situation where agent A might not provide a reliable response to sub-task $q_i$, even though the assignment seems reasonable according to the reward model.\nWe identify two intrinsic reasons for such a situation in agent-oriented planning. First, the de-scription of the sub-task may lack critical information necessary for solving the problem, such as the interpretation of contextually elements like pronouns or other ambiguous terms. In such cases, while the agent possesses the capability to resolve the sub-task, the missing information can hinder it to provide a satisfactory response. Second, the sub-task $q_i$ might be too complex, therefore a single agent can only address parts of this sub-task based on its expertise and tools. In this subsection, we design mechanisms to distinguish between these two cases and propose corresponding solutions.\nTo be specific, for each agent, we propose to construct a set of representative works that record the tasks it has completely resolved. We would initially bypass the construction and update for these representative works and focus on how to utilize them to make sub-tasks modifications here. Given a sub-task $q_i$, we calculate its similarity with a representative work $q_t$ following $cos(E(q_i), E(q_t))$, where $\\E$ is the embedding part in $M$ and $cos(u, v) = \\frac{u^T v}{\\|u\\| \\|v\\|}$ calculates the cosine similarity. We define the similarity as follows:\n$sim(q_i, Q_j) = max\\{cos(E(q_i), E(q_t))|q_t \\in Q_j\\}.$\nwhere it can be denoted as $sim_{i,j}$ for short.\nA large $max\\{sim_{i,j} | j \\in [n]\\}$ indicates that the representative works of the agent corresponding to $max\\{sim_{i,j} | j \\in [n]\\}$ contain a sub-task similar to $q_i$. Such a case should be attributed to the first reason mentioned above, and we tend to request the meta-agent to perform re-describe on $q_i$ according to the similar representative work.\nOn the other hand, if the calculated similarity does not meet the threshold, we regarded $q_i$ as too complex for any single agent in the system to solve (corresponding to the second reason above). As a result, the meta-agent P is requested to perform plan-in-detail for further decomposing the sub-task into simple ones. To avoid creating redundant sub-tasks, we provide P with all the sub-tasks and explicit instruction on avoiding overlapping sub-asks."}, {"title": "DETECTOR FOR COMPLETENESS AND NON-REDUNDANCY", "content": "Following the idea in fast decomposition and allocation, we attempt to enhance the proposed framework by incorporating detailed instructions to satisfy the principles of completeness and non-redundancy, such as \u201cmake sure all the important information of the original task such as nouns or numbers are included in the sub-tasks\". However, empirical observations reveal that these instruc-tions do not mitigate these issues. In fact, more than 15% of user queries still exhibit such issues during decomposition.\nTo tackle these issues, we involve a detector, implemented with providing a role-play prompt to LLMs, to evaluate both the completeness and non-redundancy of the intermediate results provided by the meta-agent. For the principle of completeness, the detector extracts all key elements and requirements from the original task, and then matches these elements against each sub-task, deter-mining whether the sub-tasks collectively address all essential aspects of the original task. Regard-ing the principle of non-redundancy, the detector checks for identical information and requirements across sub-tasks. The detector flags the redundancy if two sub-tasks include overlapping content.\nWhen the provided results do not satisfy the principles of completeness or non-redundancy, the detector identifies the missing key information or redundant content, and offers recommendations for refining the plan, such as suggestions for supplementing missing details or removing overlapping sub-tasks."}, {"title": "FEEDBACK LOOP", "content": "An automatic feedback loop is integrated into the proposed agent-oriented planning framework, promoting ongoing enhancement of the meta-agent.\nAs introduced in Section 3.2, the reward model can identify certain sub-tasks as being resolvable by specific agents. These identified sub-tasks are then collected to form the representative works of the corresponding agents. The training data for the reward model, which includes the sub-tasks and the ground truth scores of responses provided by the agents, is utilized to initialize these representative works.\nNote that the representative works are continuously updated. When a user query is completely resolved, the sub-tasks decomposed from that user query can be added to the representative works of the agents who are selected to provide response to these sub-tasks. To prevent redundancy in the representative works, we implement a similarity threshold. This threshold ensures that only new and sufficiently distinct sub-tasks are incorporated into an agent's representative works, maintaining the diversity and relevance of the tasks that each agent has previously resolved."}, {"title": "EXPERIMENTS", "content": "In this section, we provide empirical comparisons between the proposed agent-oriented planning framework and the existing studies."}, {"title": "SETTINGS", "content": "Datasets & Evaluations We conduct experiments based on a numerical reasoning dataset (Kim et al., 2024), which necessitates the collaboration of multiple agents in resolving the queries. For example, a query can be \"If Sarah wants to buy one BMW X5 and one Tesla Model 3, how much more would she need to pay to buy the BMW X5 compared to the Tesla Model 3?\" To resolve this query, we first need to search for the prices of the BMW X5 and Tesla Model 3, and then calculate the price difference between them. Following previous study (Kim et al., 2024), we construct a training dataset consisting of 1,440 queries, along with an annotated test dataset consisting of 292 queries. Note that the topics in the training dataset and test dataset may vary slightly.\nFor quantification comparisons, we provide instructions to GPT-40 (OpenAI, 2024b) for assisting in judging whether the execution results align with the ground truth, and calculate the accuracy as the evaluation metrics.\nInvolving Agents In the experiments, the multi-agent system includes a meta-agent and several diverse agents, including a code agent, math agent, search agent, and commonsense agent. The descriptions of these agents, which are similar to those in previous studies (Kim et al., 2024) for a fair comparison, are shown below:\n\u2022 Code Agent: Generate code in Python for precise computations to solve the given task.\n\u2022 Math Agent: Answer math questions by reasoning step-by-step.\n\u2022 Search Agent: Call the Bing Search API to obtain information related to the given task.\n\u2022 Commonsense Agent: Answer the given question using commonsense reasoning.\nThe meta-agent is tasked with decomposing user queries into sub-tasks and assigning the most suit-able agents to execute those sub-tasks. We use GPT-40 as the employed LLM for all agents.\nReward Model We adopt all-MiniLM-L6-v2 (Wang et al., 2020) as the embedding layers of the reward model, which maps text sentences or paragraphs into a 384-dimensional dense vector space."}, {"title": "COMPARISONS AND ANALYSIS", "content": "The comparisons between the proposed agent-oriented planning framework and the baseline meth-ods are shown in Table 1. We adopt accuracy as the metric for comparing effectiveness, and use prompt tokens, completion token, and the execution time for comparing efficiency.\nOverall, the experimental results demonstrate that the proposed agent-oriented planning framework achieves notable improvements compared to all baseline methods. To be specific, when comparing with single-agent systems including GPT-40, CoT, and Zero-Shot CoT, the proposed agent-oriented planning framework outperforms these systems by 10.4%, 8.1%, and 11.5% in terms of accuracy, re-spectively. These improvements can be attributed to the collaboration among multiple diverse agents and the effective scheduling provided by the meta-agent. It is not surprising to observe that the pro-posed framework incurs higher resource costs and longer inference times compared to single-agent systems. These additional costs during the inference phase, which includes task decomposition, allocation, and modifications carried out by the meta-agent, are affordable and can be worthwhile as long as they bring significant improvements in accuracy and stability when applying real-world applications.\nCompared to systems that also involve a meta-agent for task decomposition and allocation, we can observe from the table that the proposed method achieves at least a 4.1% improvement in terms of accuracy while maintaining the same level of computation costs and inference times. The results of Meta-Agent and Meta-Agent: Iteration indicate that simply instructing GPT-40 to perform task decomposition and allocation does not always yield satisfactory responses, even though the capa-bilities of LLM are recognized as powerful. Existing studies in task composition and allocation fail to consider the abilities and characteristics of the agents beyond their descriptions, and lack"}, {"title": "FURTHER DISCUSSIONS", "content": "Ablation Study We conducted an ablation study to confirm the contributions of different com-ponents in the proposed framework. Specifically, we disable the detector, the reward model, and the representatives of agents in separate experiments. From these results, we can observe that the detector has a significant impact on execution accuracy, as indicated by a notable increase in the incompleteness rate during the meta-agent's task decomposition phase. Both the reward model and the representative works are necessary in ensuring the solvability of tasks and in selecting the most suitable agents for each sub-task. Overall, these results demonstrate that all three components are indispensable, working together to ensure the feasibility of task decomposition and allocation, leading to satisfactory responses to the original user queries.\nImpact of Scorer and Reward Model The training dataset is constructed based on annotations provided by the scorer, which in the previous experiments is implemented using LLMs. In this sec-tion, we shift to using human annotators to manually provide scores for the responses, evaluating whether a reward model trained on this manually labeled dataset would further enhance perfor-mance. This approach is denoted as Manual Scoring. More detailed information about the manual scoring process can be found in Appendix C. Besides, based on the manually scored training dataset, we investigate the setting of updating the embedding layers of the reward model."}, {"title": "RELATED WORK", "content": "The field of artificial general intelligence has witnessed a transformative development with the ad-vent of large language models (LLMs)."}, {"title": "CONCLUSION", "content": "In this study, we propose a novel agent-oriented planning framework for multi-agent systems, fol-lowing three critical design principles to ensure that the meta-agent can effectively decompose the user query into several sub-tasks for producing satisfactory responses. The proposed framework utilizes a fast decomposition and allocation process, which relies on the ability of LLMs to generate an intermediate schedule efficiently. After that, a reward model and the representative work mecha-nism are employed to evaluate these intermediate results, routing three different paths for executing the sub-task or making necessary modifications to align the sub-task with agents, such as replan the sub-task, plan in detail, and re-describe. Extensive experiments demonstrate that the proposed agent-oriented framework achieves significant improvements over both the existing single-agent and multi-agent baseline methods. We provide discussions on the contributions of different components in the framework and the potential for improvements in agent-oriented planning. We will release the source code to promote further research in the community."}, {"title": "PLAN GENERATION AND MODIFICATION", "content": "The one-shot prompt for meta-agent's fast decomposition and allocation is shown in Figure 3."}]}