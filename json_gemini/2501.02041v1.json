{"title": "MRG: A Multi-Robot Manufacturing Digital Scene Generation Method Using Multi-Instance Point Cloud Registration", "authors": ["Songjie Han", "Yinhua Liu", "Yanzheng Li", "Hua Chen", "Dongmei Yang"], "abstract": "A high-fidelity digital simulation environment is crucial for accurately replicating physical operational processes. However, inconsistencies between simulation and physical environments result in low confidence in simulation outcomes, limiting their effectiveness in guiding real-world production. Unlike the traditional step-by-step point cloud \"segmentation-registration\u201d generation method, this paper introduces, for the first time, a novel Multi-Robot Manufacturing Digital Scene Generation (MRG) method that leverages multi-instance point cloud registration, specifically within manufacturing scenes. Tailored to the characteristics of industrial robots and manufacturing settings, an instance-focused transformer module is developed to delineate instance boundaries and capture correlations between local regions. Additionally, a hypothesis generation module is proposed to extract target instances while preserving key features. Finally, an efficient screening and optimization algorithm is designed to refine the final registration results. Experimental evaluations on the Scan2CAD and Welding-Station datasets demonstrate that: (1) the proposed method outperforms existing multi-instance point cloud registration techniques; (2) compared to state-of-the-art methods, the Scan2CAD dataset achieves improvements in MR and MP by 12.15% and 17.79%, respectively; and (3) on the Welding-Station dataset, MR and MP", "sections": [{"title": "1. Introduction", "content": "In recent years, digital twin technology has experienced widespread adoption across modern manufacturing sectors, particularly in the areas of welding, assembly, and quality inspection [1]. Through the construction of high-fidelity digital models, this technology facilitates the precise simulation of real-world production environments, thereby optimizing manufacturing processes and forecasting potential failures [2]. A large field-of-view three-dimensional (3D) scanner is employed to acquire high-quality ambient point clouds, which serve as the foundation for generating a highly reliable digital simulation environment. The generation process involves several stages: 1) utilizing a 3D scanner to capture the spatial configuration of the industrial robot's working shops; 2) preprocessing point cloud data to eliminate noise and enhance data quality; 3) segmenting the industrial robot's point cloud data; and 4) employing point cloud registration technology to align the corresponding robot's digital model with the spatial pose of the point cloud data [3].\nTo facilitate high-precision simulations within digital industrial man- ufacturing environments, point cloud registration technology has become indispensable. Its objective is to estimate the transformation relationships between point clouds from different locations and to align them spatially with high precision. Specifically, this involves identifying and establishing spatial mappings between two point clouds, thereby integrating their respective coor- dinate systems. This technology constitutes a critical research domain within industrial big data analysis and has found extensive applications in reverse engineering [4], simultaneous localization and mapping [5], pose estimation [6], and intelligent manufacturing [7].\nOver the past few decades, researchers have developed a variety of effective point cloud registration techniques. Traditional geometric methods include the Iterative Closest Point (ICP) algorithm [8]. Fast Global Registration (FGR) [9], the Normal Distribution Transform (NDT) [10, 11], and their"}, {"title": "2. Related works", "content": "Based on the number of objects in the scene and the registration require- ments, point cloud registration algorithms can be classified into pairwise point cloud registration methods and multi-instance registration methods. The latter can be further subdivided into multi-model fitting methods and DL-based methods."}, {"title": "2.1. Pairwise Point Cloud Registration", "content": "Point cloud registration has a long history, and most current methods focus on pairwise registration. These methods are generally divided into three sub-tasks: point matching, outlier rejection, and transformation estimation. Traditional point matching methods rely on manually designed descriptors [20, 21], to capture local information; however, these methods are sensitive to noise and outliers. To enhance the robustness of matching algorithms, DL-based methods have gradually replaced traditional methods. Zeng et al. [22] proposed the pioneering 3DMatch algorithm, which takes local voxel blocks as input and employs a 3D Convolutional Neural Network (CNN) to learn local geometric features, thereby generating robust and highly discriminative 3D descriptors. Deng et al. [23] proposed an unordered network architecture based on PointNet [24] that utilizes a novel N-tuple loss function to inject global contextual information into local descriptors, thereby enhancing their representation capability. Gojcic et al. [25] aligned Smoothed Density Value (SDV) with the Local Reference Frame (LRF) to address the rotation invariance issue of descriptors. They used a twin deep learning architecture for efficient point cloud matching.\nAccurate correspondences are essential for enhancing the accuracy and efficiency of pose estimation, making a robust outlier elimination module crucial. Random Sample Consensus (RANSAC) [26] and its variants [27, 28]"}, {"title": "2.2. Multi-model Fitting", "content": "Multi-model fitting methods aim to fit multiple models from noisy data, such as fitting multiple planes in a point cloud, estimating a fundamental ma- trix in motion segmentation, or determining a rigid transformation matrix in multi-instance point cloud registration. Existing multi-model fitting methods are categorized into RANSAC-based and cluster-based methods. RANSAC- based methods [16, 32] primarily adopt the hypothesis-verification method for sequential fitting of multiple models. For instance, Sequential RANSAC [32] detects instances by repeatedly running RANSAC to recover a single instance and subsequently removing its inlier points from the input. CONSAC [16] was the first to introduce the DL model into multi-model fitting, utilizing a network similar to PointNet [24] to guide sampling. However, efficiency significantly decreases with large-scale inputs. Cluster-based methods [15, 17] sample numerous hypotheses and group input points based on residuals under these hypotheses. For example, RansaCov [15] transforms the multi-model fitting problem into a maximum coverage problem and provides two approxi- mate solving strategies. T-linkage [17] initializes a broad range of hypotheses through point sampling and preference vector clustering to remove outliers."}, {"title": "2.3. Multi-instance Point Cloud Registration based on Deep Learning", "content": "Multi-instance registration methods based on deep learning require the estimation of multiple transformations for various instances in both the source"}, {"title": "3. Method", "content": "Given the source point cloud $P = \\{p_i \\in \\mathbb{R}^3|i = 1, ..., N\\}$ and the target point cloud $Q = \\{q_i \\in \\mathbb{R}^3|i = 1, ..., M\\}$. The source point cloud contains one instance of the 3D model, and the target point cloud contains $J$ instances of the same model. The purpose of multi-instance point cloud registration is to recover $J$ rigid transformations from two point clouds: $\\{R_j \\in SO(3), t_j E \\mathbb{R}^3\\}_{j=1}^J$. Given the number of instances $J$ in the target point cloud and the predicted value of the point set $C$, the process of solving the rigid"}, {"title": "3.1. Overview", "content": "MRG employs a coarse-to-fine strategy [13] based on a keypoint-free registration method for extracting correspondences. The comprehensive process of our method is illustrated in Fig. 2. To enhance the computational"}, {"title": "3.2. Instance-Focused Transformer", "content": "Accurate correspondence is essential for high-precision pose estimation. The feature similarity matrix represents the correlation between source and target point clouds. Transformers have been demonstrated to effectively capture contextual information within individual point clouds while facilitating cross-feature fusion between paired point clouds [36]. However, in industrial manufacturing, target instance features are susceptible to contamination, and robotic joint features often exhibit significant similarity. Consequently, the feature similarity matrix may become unreliable, as illustrated in Fig. 3. To address this, we propose a novel instance-focused transformer module. This module restricts the contextual encoding of target instance point clouds to intra-instance information and enhances associations between different local structures within each instance. The specific structural details of this module are illustrated in Fig. 4.\nRegional association module. The instance-focused transformer mod- ule comprises three key components: a regional association module, a cross- attention module, and a neighbor mask module. Given a superpoint $\\hat{q}_i \\in Q$, its $K$-nearest neighbors are represented as: $N_i^Q = \\{\\hat{q}_{i,1}, \\hat{q}_{i,2}, \\hat{q}_{i,3},..., \\hat{q}_{i,k}\\}$. The input feature matrix is $F^Q \\in \\mathbb{R}^{|Q|xd}$, and the neighbor mask matrix is $M^Q \\in \\mathbb{R}^{|Q|xk}$. Here, $|\\cdot|$ represents the number of elements in the set, and $d$ represents the feature dimension. The regional association module outputs"}, {"title": "3.3. Instance Hypothesis Generation", "content": "After obtaining the combined source and target point cloud features, a feature similarity matrix is typically generated. Subsequently, the top $N_i$ pairs with the highest matching scores are selected to form sparse superpoint matches [13, 14]. However, in industrial manufacturing scenes, as instances and robot geometries become more complex, target point clouds with low matching degrees are often frequently overlooked. This oversight results in partial loss of instance point clouds and decreased pose estimation accuracy.\nTo address this issue, this paper proposes an effective instance hypothesis generation module. By combining the neighbor mask matrix and feature similarity matrix, we restore the geometric structures of most target instances, even with low feature matching scores. Refer to Algorithm 1: for detailed steps."}, {"title": "3.4. Instance Filtering and Optimization", "content": "After completing these steps, the correspondence achieves high accuracy. The subsequent step involves partitioning these correspondences into subsets belonging to different instances and determining their final rigid transforma- tions through the application of weighted SVD as outlined in Equation 1. This division constitutes a clustering problem, where the number of instances cor- responds to the number of clusters. Previous methods [33] employed spectral"}, {"title": "3.5. Loss function", "content": "Regarding the loss functions, we employ three distinct loss functions to train MRG: 1) Overlap-aware Circle Loss; 2) Negative Log-likelihood Loss; 3) Neighbor Mask Loss. The overall loss function is detailed as follows:\n$L = L_{circle} + L_{nll} + L_{mask}$"}, {"title": "Overlap-aware Circle Loss", "content": "To supervise the superpoint features of the instance-focused module output (superpoint feature features), we adopt the method proposed in [14], utilizing the Overlap-aware Circle Loss, which weights the loss of each superpoint (patch) matching pair based on its overlap ratio. Given the set of local patches $U$, it consists of the patches in $Q$ which have at least one positive patch $P$. For each patch $G_o^Q \\in U$, we define the positive patches $P$, which share at least a 10% overlap with $G_o^Q$, as $E_p$, and the negative patches, which do not overlap with $G_o^Q$, as $E_n$. The Overlap-aware Circle Loss on $Q$ is then calculated as follows:\n$L_{circle}^{ord} = \\frac{1}{|U|} \\sum_{G_o^Q EU} log \\Big(1+ \\sum_{G_p^Q EE_p} e^{\\beta_p(d- \\Delta_p)} - \\sum_{G_n^Q EE_n} e^{\\beta_n(\\Delta_n-d)}\\Big)$\nwhere $d = || f_{G_p^Q} - f_{G_n^Q} ||_2$ represents the distance in feature space, $\\lambda = (lap)^{1/2}$, and $lap$ is the overlap ratio between $G_p^Q$ and $G_n^Q$. The weights $\\beta_p = \\gamma(d - \\Delta_p)$ and $\\beta_n = \\gamma(\\Delta_n - d)$ are determined individually for each positive and negative example, using the margin hyperparameters $\\Delta_p = 0.1$ and $\\Delta_n = 1.4$. The loss $L_{circle}^{ord}$ on $P$ is computed in the same way. The overall loss is $L_{circle} = (L_{circle}^{ord} + L_{circle}^{ord})/2$."}, {"title": "Negative Log-likelihood Loss", "content": "In accordance with [39], we employ a Negative Log-likelihood Loss on the assignment matrix $H_i$ for each ground- truth superpoint correspondence $C_i^{gt}$. For each $\\hat{C}_i$, we calculate the inlier ratio between matched patches using each ground-truth transformation. Sub- sequently, we select the transformation corresponding to the highest inlier ratio to estimate a set of ground-truth point correspondences $C_i$ within a matching radius $r$. The point matching loss for $\\hat{C}_i^{gt}$ is calculated as follows:\n$L_{nll,i} = -\\sum_{(x,yE\\hat{C}_i^{gt})} log h_{xy} - \\sum_{xEF_i} log h_{x,m_i+1} - \\sum_{yET_i} log h_{m_i+1,y}$\nwhere $F_i$ and $I_i$ are the unmatched points in the two matched patches. The final loss is the average loss over all sampled superpoint matches: $L_{nll} = \\frac{1}{N_i} \\sum_{i=1}^{N_m} L_{nll,i}$"}, {"title": "Neighbor Mask Loss", "content": "Following [40], the neighbor mask prediction loss consists of the Binary Cross-Entropy Loss and the Dice Loss with Laplace smoothing, which is defined as follows:\n$L_{mask,i} = BCE(m_i, m_i^{gt}) + 1 - 2 \\frac{m_i m_i^{gt} + 1}{|m_i| + |m_i^{gt}| + 1}$"}, {"title": "4. Experiments", "content": ""}, {"title": "4.1. Experimental Setup", "content": "Datasets. We collected a Welding-Station dataset from a real-world multi-robot welding workshop, capturing detailed 3D scans of industrial welding environments. The dataset includes different models of robots, various welding stations, electrical equipment, and fixtures. This diversity reflects the complexity and variability of real industrial settings. Each scene contains accurate annotations of object instances and their rigid transformations. For our experiments, we sampled the target point clouds from workshop scenes and the source point clouds from corresponding sources. We allocated 70% of the data for training, 10% for validation, and 20% for testing.\nTo comprehensively evaluate the performance of our method, we con- ducted experiments on the publicly available Scan2CAD dataset [41]. The Scan2CAD dataset precisely aligns object instances from ScanNet [42] with CAD models from ShapeNet [37]. It provides accurate rigid transformation annotations for multiple real-world scanned scenes, each containing 2 to 5 identical CAD instances. We fully utilize the annotation information and conduct experiments by separately sampling the target point clouds from the scene point clouds and the source point clouds from CAD models. After ob- taining 2,175 sets of point clouds, we used 1,523 scenes for training, 326 scenes for validation, and 326 scenes for testing. We utilize the fine-tuned Predator [18] for point matching to establish the initial putative correspondence set.\nMetrics. We follow the evaluation procedure of PointCLM [33], where the rotation error is defined as\n$RE = arccos[(Tr(R_t R_{est}) - 1)/2]$\nand translation error is defined as\n$TE = ||t_{est} - t_{gt}||_2$\nFor the Welding-Station dataset, we established strict thresholds to eval- uate registration success, aligning with the high-precision requirements of industrial environments. A registration is considered successful if the Rotation"}, {"title": "4.2. Evaluation on Real-World Welding-Station Dataset", "content": "To clearly illustrate the process of generating a digital shop model, we utilize an automotive body welding station as an example. This workstation comprises two distinct robot models, resulting in six robot instances. To generate the source point cloud, we sample points from each triangular face of the robot CAD models. The source point cloud is then aligned with and matched to the corresponding robot instances in the welding station. Through this registration process, we construct a digital manufacturing scene model for the body welding station. Fig. 6 illustrates the complete workflow of the digital scene generation process.\nAs shown in Table 1. Our MRG method outperforms all other methods. Compared to the closest competitor, it achieves improvements of 16.95% in MR metrics, 24.15% in MP metrics, and 20.79% in MF metrics. Although our method requires an additional 0.8s processing time compared to the state-of-the-art method, accuracy remains paramount in industrial digital scene generation applications. By leveraging the distance-invariance matrix, ECC directly clusters noise correspondences into distinct groups. While this method significantly improves registration accuracy, it incurs substantially"}, {"title": "4.3. Evaluation on Scan2CAD Dataset", "content": "In addition to conducting experiments on the Welding-Station dataset, we evaluated our method using the Scan2CAD dataset. Table 2 presents the quantitative results, demonstrating that MRG outperforms all other methods across three metrics: MR, MP, and MF. On average, MRG achieves im- provements of 35.65%, 37.31%, and 37.49% in these metrics. Notably, MRG outperforms PointCLM and ECC across three metrics without a significantly increasing in computational time. Compared to the other three multi-model fitting methods, PointCLM and ECC also demonstrate satisfactory perfor- mance.\nTo facilitate qualitative comparisons with competing methods, we present visual registration results for three sets of indoor point cloud scenes, each containing 8, 10, and 12 identical instances, as shown in Fig. 8. As the"}, {"title": "4.4. Ablation Experiments", "content": "Experiments to Verify Each Module. We conducted a series of ablation experiments using the Welding-Station dataset to assess the individ- ual contributions of each component within the proposed MRG framework. Our primary objective was to evaluate the impact of specific modules on registration accuracy. We began with a baseline network architecture (Fig. 9) and progressively integrated three essential modules: the regional association module, the neighbor mask module, and the instance hypothesis generation module (as described in Section 3.3). This stepwise method allowed us to quantify the contribution of each module, thereby validating the design choices made in our methodology.\nTable 3 presents the registration accuracy of different combinations of the backbone network and modules on the Welding-Station dataset. The results indicate a consistently positive trend in the impact of the modules on registration accuracy. Specifically, the combination of the regional association module and the neighbor mask module yields the greatest improvement in accuracy during the coarse correspondence extraction phase. Registration accuracy increased by 22.02%, 25.58%, and 23.86% for the three metrics (MR, MP, and MF), respectively. This enhancement is attributed to the iterative process in which the neighbor mask module accurately predicts instance boundaries, while the regional association module strengthens the relationships between local regions of the instance. As a result, the extracted features of the target instance exhibit greater distinguishability, enhancing the ability to differentiate instances with similar local structures and extract precise coarse correspondences. Furthermore, the instance hypothesis generation"}, {"title": "Validate the Advantages of the Instance-Focused Transformer", "content": "The results of this experiment demonstrate that using the Instance-Focused"}, {"title": "Validate the Design Advantages of the Instance Hypothesis Generation", "content": "The results of this experiment demonstrate the benefits of"}, {"title": "Validate the Design Advantages of the Instance Filtering and Optimization", "content": "To quantitatively assess the advantages of the proposed in- stance filtering and optimization module in complex point cloud registration tasks, comparative experiments were performed. In the MRG framework, the instance filtering and optimization module was replaced with three al- ternative methods: the spectral clustering method from PointCLM [33], the distance-invariance clustering from ECC [19], and multi-model fitting techniques [15, 16, 17]. The comparative results are presented in Table 8.\nAs shown in Table 8, the proposed full pipeline significantly outperforms all baseline multi-model fitting methods. Specifically, the proposed method achieves average improvements of 24.15%, 25.66%, and 25.29% in the MR, MP, and MF metrics, respectively. Although the ECC-based model demonstrates slightly better performance in MR compared to the proposed full pipeline, its performance in MP is substantially weaker. This observation suggests that ECC attains a higher MR by predicting an excessive number of registrations. This behavior consistently outperforms PointCLM across all three registration metrics, underscoring its robustness and effectiveness.\nSecondly, we analyzed instance filtering strategies involving outlier removal"}, {"title": "5. Conclusions", "content": "By constructing high-precision digital models of industrial manufacturing scenes, achieving precise simulation of physical operational results has emerged as the mainstream method for accurate simulation in the development of the manufacturing industry. The advantages of simulation systems include accelerating the manufacturing process and reducing manufacturing costs. However, inconsistencies between the simulation and physical environments reduce the credibility of simulation results, limiting their utility in guiding actual production. Unlike traditional step-by-step \"segmentation-registration\" generation methods, this paper presents a novel Multi-Robot Manufacturing Digital Scene Generation (MRG) method for the first time. This method employs multi-instance point cloud registration to replace key robot instances in the scene with digital models while retaining point cloud data of other non-production-related operations, thereby enhancing the credibility of the simulation environment and improving generation efficiency, making it es- pecially suitable for manufacturing scenes. Addressing the characteristics of industrial robots and manufacturing environments, an instance-focused Transformer module was developed to delineate instance boundaries and capture correlations between local regions. Additionally, an instance gen- eration module was proposed to extract target instances while preserving key features. Finally, an efficient filtering and optimization algorithm was designed to refine the final registration results. Experimental evaluations on the Scan2CAD and Welding-Station datasets demonstrate that: 1) this method outperforms existing multi-instance point cloud registration tech- niques; 2) compared to state-of-the-art methods, the Scan2CAD dataset shows improvements of 12.15% and 17.79% in MR and MP, respectively. This work represents the first application of multi-instance point cloud registration in manufacturing scenes, significantly enhancing the accuracy and reliability of digital simulation environments for industrial applications."}]}