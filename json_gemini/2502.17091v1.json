{"title": "WILDFRAME: Comparing Framing in Humans and LLMS\non Naturally Occurring Texts", "authors": ["Gili Lior", "Liron Naccache", "Gabriel Stanovsky"], "abstract": "Humans are influenced by how information is\npresented, a phenomenon known as the fram-\ning effect. Previous work has shown that LLMs\nmay also be susceptible to framing but has done\nso on synthetic data and did not compare to\nhuman behavior. We introduce WILDFRAME,\na dataset for evaluating LLM responses to\npositive and negative framing, in naturally-\noccurring sentences, and compare humans on\nthe same data. WILDFRAME consists of 1,000\ntexts, first selecting real-world statements with\nclear sentiment, then reframing them in either\npositive or negative light, and lastly, collecting\nhuman sentiment annotations. By evaluating\neight state-of-the-art LLMs on WILDFRAME,\nwe find that all models exhibit framing effects\nsimilar to humans (r\u2265 0.57), with both hu-\nmans and models being more influenced by\npositive rather than negative reframing. Our\nfindings benefit model developers, who can ei-\nther harness framing or mitigate its effects, de-\npending on the downstream application.", "sections": [{"title": "Introduction", "content": "The framing effect is a well-known cognitive phe-\nnomenon, where different presentations of the same\nunderlying facts affect human perception towards\nthem (Tversky and Kahneman, 1981). For exam-\nple, presenting an economic policy as only creating\n50,000 new jobs, versus also reporting that it would\ncost 2B USD, can dramatically shift public opin-\nion (Sniderman and Theriault, 2004).\nPrevious research has shown that LLMs exhibit\nvarious cognitive biases, including the framing ef-\nfect (Lor\u00e8 and Heydari, 2024; Shaikh et al., 2024;\nMalberg et al., 2024; Echterhoff et al., 2024). How-\never, these either rely on synthetic datasets or eval-\nuate LLMs on different data from what humans\nwere tested on. In addition, comparisons between\nmodels and humans typically treat human perfor-\nmance as a baseline rather than comparing patterns\nin human behavior."}, {"title": "The WILDFRAME Dataset", "content": "Our dataset curation consists of three steps, as de-\npicted in Figure 1. First, we collect natural, real-\nworld statements, with some clear sentiment, either\npositive or negative (\u00a72.1; e.g., \u201cI won the highest\nprize\" as positive). Next, we reframe each state-\nment by adding a prefix or suffix conveying the\nopposite sentiment (\u00a72.2; e.g., \u201cI won the highest\nprize, although I lost all my friends on the way\u201d).\nFinally, we collect large-scale human annotations\nvia crowdsourcing, to label the sentiment shifts\nwhen wrapping the statements with the opposite\nframing (\u00a72.3; e.g., labeling \u201cnegative\u201d the state-\nment \"I won the highest prize, although I lost all\nmy friends on the way\").\nThe complete dataset consists of 1000 state-\nments, in which 500 are statements that their base\nform has positive sentiment, and 500 are base neg-\native statements.\""}, {"title": "Collecting Base Statements", "content": "First, we collect base statements, which convey a\nclear sentiment, either clearly positive or clearly\nnegative statements. We use SPIKE an extractive\nsearch system, which allows to extract statements\nfrom real-world datasets (Taub Tabib et al., 2020).\nSpecifically, we collect statements from Amazon\nReviews dataset, which are naturally occurring,\nsentiment-rich, texts but are less likely to trigger\nstrong preexisting biases or emotional reactions,\nwhich may be a confound for our experiment.\nUsing SPIKE, we extract ~6k statements that\nfulfilled our designated queries, which we found\ncorrelated with clear sentiment. We designed the\nqueries to capture positive or negative verbs that\ndescribe actions with some clear sentiment (e.g.,\n\"enjoy\" or \"waste\u201d), or statements with positive or\nnegative adjective, describing an outcome with a\nclear sentiment (e.g., \"good\" or \"nasty\u201d). The pat-\nterns and queries used for extraction are detailed\nin Appendix A. Next, we run in-house annotations\nto label and filter the extracted statements, to han-\ndle negations or other cases where the statement\ndoes not convey a clear sentiment. The filtering\nprocess results in 1, 301 positive statements, and\n1, 229 negative statements."}, {"title": "Adding Framing", "content": "To reframe the statements in our dataset, we use\nGPT-4 (Achiam et al., 2023). The input prompt\nincludes a 1-shot example, followed by a task de-"}, {"title": "Collecting Human Annotations", "content": "In the final step, we collect human annotations\nthrough Amazon Mechanical Turk to evaluate the\nframing effect in WILDFRAME over human partic-\nipants, providing a reference for comparison with\nLLMs. Details about the annotation platform are\nelaborated in Appendix C.\nThe complete dataset includes 1K statements,\neach annotated by five different annotators. Given\nour budget, we preferred to collect five annotations\nper statement, resulting in less statements, but pro-\nviding a more robust scoring for the ambiguity of a\nstatement.\nFor the annotation process, each statement in\nour dataset is presented in its reframed version\n(i.e., positive base statements with negative framing\nand vice versa), to five different annotators. This\nsetup generates, for each dataset instance, a score\nranging from 0 to 5, representing the number of\nannotators that votes for the sentiment that aligns\nwith the opposite framing, which means that the\noverall sentiment of the reframed statement has\nshifted from its base sentiment. For example, in\nFigure 1, the statement \u201cI won the highest prize,\nalthough I lost all my friends on the way\u201d is shown\nto have two annotators voting \u201cnegative\u201d, which\naligns with the sentiment of the framing and not\nthe base statement, so the label for that instance in\nWILDFRAME would be 2 (sentiment shifts).\nInstances with score near 0 indicate that anno-\ntators agree that the overall sentiment remains un-\nchanged despite the opposite framing. Score closer\nto 5 indicates that annotators agree that reframing\nshifted the perceived sentiment, while score around"}, {"title": "Results", "content": "We evaluate 8 models on the WILDFRAME dataset,\ncomprising both open and closed-source mod-\nels. These included GPT-40, Llama-3 (8B and\n70B), Mistral-v0.3 (7B), Mixtral-v0.1 (8x7B and\n8x22B), and Gemma-2 (9B and 27B). We test the\ninstruction-tuned version of these models.\nHumans and LLMs are largely more influenced\nby positive framing applied to negative state-\nments than by negative framing applied to posi-\ntive statements. This trend is evident in Figure 3.\nFor LLMs, all models except GPT-40 exhibit higher\nratios of sentiment shifts for statements that were\noriginally negative (red bars) compared to those\nthat were originally positive (green bars). For hu-\nmans, we count the cases in which the majority\nvoted for a sentiment shift (3 annotators or more).\nThis finding aligns with Tong et al. (2021), which\ndemonstrated that positive framing is more effec-\ntive on humans when spatial distance is minimal.\nIn WILDFRAME, all statements are presented in\na first-person perspective (e.g., \u201cI won the high-\nest prize\"), creating zero spatial distance from the\nannotator's perception and thereby amplifying the\nimpact of positive framing.\nModel size partially correlates with similarity to\nhuman behavior under opposite framings. In"}, {"title": "Discussion and Future Work: When\nshould LLMs Imitate Humans?", "content": "We introduced WILDFRAME, a dataset designed to\nevaluate how LLMs are affected by different fram-\nings, in comparison to humans. The statements in\nthe dataset are start from a clear positive or neg-\native base statement, reframed with an opposite-\nsentiment suffix or prefix. By collecting human\nannotations, we quantify the strength of the fram-\ning effect for each instance and assess how LLMs\nreact to the same reframing, focusing on sentiment\nshifts cases where the perceived sentiment aligns\nwith the opposite framing sentiment.\nAs LLMs become increasingly integrated into\ndecision-making systems, it becomes crucial to\nunderstand how framing influences their outputs.\nIn some applications, e.g., in virtual companions,\nframing can be harnessed to produce human-like\nbehavior leading to better engagement. In contrast,\nin other applications, such as financial or legal ad-\nvice, mitigating the framing effect can lead to less\nbiased decisions. In both cases, a better under-\nstanding of framing in LLMs can help develop\napplication-appropriate strategies.\nWe find that LLMs and humans exhibit similar\nbehavior on WILDFRAME, with all tested models\nachieving a strong correlation (r \u2265 0.57) with hu-\nman responses. Notably, GPT-40 showed the weak-\nest correlation to humans, despite being widely\nregarded as a very capable model in other contexts.\nWe hope this work encourages research into\ndistinguishing between scenarios where human-\nlike behavior is desirable and those where models\nshould surpass human limitations to achieve above-\nhuman performance. These insights are essential\nfor developing LLMs that are both interpretable\nand optimized for their intended applications."}, {"title": "Limitations", "content": "In this work, we address a cognitive bias, and as\nwith any research involving human participants,\nour study has several limitations.\nFirst, our framing experiment is conducted\nwithin a single domain \u2013 Amazon reviews \u2013 and\nfocuses on a specific type of statement. Some of\nour findings may be artifacts of this dataset rather\nthan generalizable patterns.\nAdditionally, our approach to framing is highly\nspecific. We only manipulate statements by adding\na prefix or suffix, whereas reframing can take many\nother forms, such as restructuring sentences or alter-\ning word choices to convey ambiguous sentiment.\nThis may limit the generalizability of our results.\nFurthermore, our study focuses solely on senti-\nment analysis. Other downstream tasks influenced\nby framing, such as question answering or decision-\nmaking, may exhibit different patterns of sensitiv-\nity. Investigating these tasks could provide further\ninsights into the broader impact of framing on LLM\nbehavior in real-world applications."}, {"title": "Extracting data with SPIKE", "content": "We found two patterns of statements, which can\nconvey a clear sentiment, and built queries upon\nthese patterns to extract statements from SPIKE.\nExamples for all types of statements are presented\nin Table 1.\nFirst, are statements in which the verb in the\nstatements is a verb with clear sentiment, that of-\nten implies the sentiment of the entire statement.\nE.g., 'wastes', 'rejects', 'fails' are negative verbs,\nwhile verbs like 'enjoys', 'succeeds', 'empowers',\nconveys positive statements.\nThe second pattern of statements that we found\nsuitable for conveying a clear sentiment, are state-\nments which describe some event/action, and\nits consequences, where often the adjective that\ndescribes the consequences holds information\nwhether it is positive or negative.\nNext, we needed to label and filter them due to\ntwo main issues. First, we needed to handle the\ncases in which negation words appear in the state-\nment and flips the sentiment. For example, a state-\nment like \"We did not enjoy the show\" includes\na positive verb (enjoy), but the negation flips its\nsentiment to be a negative statement. Another issue\nwe encountered is that there are many statements\nwhich are irrelevant to our case, even though they"}, {"title": "SPIKE Queries", "content": "1. :something :[pos/neg verbs]develops\n2. :something: [pos/neg adjectives]badly :[cause\nsynonym]causes :something"}, {"title": "Word Lists", "content": "Positive verbs. achieve, admire, affirm, appreci-\nate, aspire, awe, bless, blossom, celebrate, cherish,\ncomfort, contribute, delight, donate, elevate, em-\npower, enchant, encourage, energize, engage, en-\njoy, enrich, enthuse, excel, fervor, flourish, fortify,\nglisten, glow, gratitude, grow, harmonize, heal, illu-\nminate, innovate, inspire, invigorate, laugh, learn,\nliberate, love, motivate, nourish, nurture, praise,\nprosper, radiate, rally, refresh, rejoice, renew, revel,\nrevere, revitalize, savor, shine, smile, soar, spark,\nsparkle, stimulate, strengthen, succeed, support,\nsynergize, thrive, unite, uplift, volunteer, adore,\namaze, boost, captivate, win.\nNegative verbs. abandon, abuse, accuse, alien-\nate, begrudge, betray, bewilder, blame, collapse,\ncomplain, condemn, confuse, contradict, criticize,\ndecay, deceive, decline, defeat, demoralize, deny,\ndespair, destroy, deteriorate, devalue, discourage,\ndiscriminate, dishearten, dismantle, dismiss, dis-\nsolve, doubt, exploit, fail, falter, fear, frustrate,\ngrieve, harass, hate, hurt, ignore, inhibit, intimidate,\nlose, mock, overlook, overwhelm, pollute, punish,\nregress, reject, repress, resent, sabotage, shatter,\nsicken, stifle, suffer, suffocate, suppress, terrorize,\ntorment, undermine, violate, waste, weaken, whine,\nwithdraw, withhold, worry.\nPositive adjectives. admirable, lucky, enjoyable,\nmagnificent, enthusiastic, marvelous, euphoric,\namazing, excellent, exceptional, amused, excited,\namusing, extraordinary, nice, noble, outstanding,\nappreciative, fabulous, overjoyed, astonishing, fan-\ntastic, benevolent, fortunate, pleasant, blissful, plea-\nsurable, brilliant, positive, glad, prominent, good,\nproud, charming, cheerful, reliable, gracious, grate-\nful, clever, great, happy, superb, superior, terrific,\nincredible, tremendous, inspirational, delighted,\ndelightful, joyful, joyous, uplifting, wonderful,\nlovely.\nNegative adjectives. sad, angry, upset, disgust-\ning, boring, disappointing, frustrating, annoying,\nmiserable, terrible, deppressing, unhappy, melan-\ncolic, heartbreaking, Furious, iritating, emberess-\ning, horrible, stupid, unlucky, negative, bad.\n\"Causes\" synonym. causes, creates, generates,\nprompts, produces, induces, yields, affects, in-\nvokes, effectuates, results, encourages, promotes,\nintroduces, begets, engenders, occasions, devel-\nops, starts, contributes, initiates, inaugurates, es-\ntablishes, begins, cultivates, acquires, provides,\nlaunches."}, {"title": "Adding Framing", "content": "Example for statements after framing are presented\nin in Table 2."}, {"title": "Framing Prompts", "content": "1. \"Here is an example of a base statement with\na negative sentiment: I failed my math test to-\nday. Here is the same statement, after adding\na positive framing: I failed my math test today,\nhowever I see it as an opportunity to learn and\nimprove in the future. Here is a negative state-\nment: <statement> Like the example, add a\npositive suffix or prefix to it. Don't change\nthe original statement.\"\n2. \"Here is an example of a base statement with\na positive sentiment: I got an A on my math\ntest. Here is the same statement, after adding\na negative framing: I got an A on my math\ntest. I think I spent too much time learning to\nit though. Here is a positive statement: <state-\nment>. Like the example, add a negative suf-\nfix or prefix to it. Don't change the original\nstatement.\""}, {"title": "Annotation Platform", "content": "We select a pool of 10 qualified workers who suc-\ncessfully passed our qualification test, which con-\nsisted of 20 base statements (unframed), for which\nannotators were expected to achieve perfect accu-\nracy. The estimated hourly wage for the entire\nexperiment was approximately 14USD per hour.\nScreenshot of the annotation platform is pre-\nsented in Figure 5."}, {"title": "Models", "content": "We ran the open models via together-ai API.6 The\nlist of models we used are:\n\u2022 \"google/gemma-2-9b-it\"\n\u2022 \"google/gemma-2-27b-it\"\n\u2022 \"mistralai/Mistral-7B-Instruct-v0.3\"\n\u2022 \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n\u2022 \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n\u2022 \"meta-llama/Llama-3-8b-chat-hf\"\n\u2022 \"meta-llama/Llama-3-70b-chat-hf\"\nFor GPT-40, we used the OpenAI api, with \"gpt-\n40-2024-08-06\"."}]}