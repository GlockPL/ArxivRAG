{"title": "GlobalMapNet: An Online Framework for Vectorized Global HD Map Construction", "authors": ["Anqi Shi", "Yuze Cai", "Xiangyu Chen", "Jian Pu", "Zeyu Fu", "Hong Lu"], "abstract": "High-definition (HD) maps are essential for autonomous driving systems. Traditionally, an expensive and labor-intensive pipeline is implemented to construct HD maps, which is limited in scalability. In recent years, crowdsourcing and online mapping have emerged as two alternative methods, but they have limitations respectively. In this paper, we provide a novel methodology, namely global map construction, to perform direct generation of vectorized global maps, combining the benefits of crowdsourcing and online mapping. We introduce GlobalMapNet, the first online framework for vectorized global HD map construction, which updates and utilizes a global map on the ego vehicle. To generate the global map from scratch, we propose GlobalMapBuilder to match and merge local maps continuously. We design a new algorithm, Map NMS, to remove duplicate map elements and produce a clean map. We also propose GlobalMapFusion to aggregate historical map information, improving consistency of prediction. We examine GlobalMapNet on two widely recognized datasets, Argoverse2 and nuScenes, showing that our framework is capable of generating globally consistent results.", "sections": [{"title": "I. INTRODUCTION", "content": "High-definition (HD) maps are highly accurate maps that provide detailed road information, such as geometric features of road boundaries, lanes, and pedestrian crossings. For high-level autonomous vehicles, HD map is crucial for accurate localization [1], [2], which forms the basis of safe autonomous driving. However, traditional HD map production requires expensive mobile mapping systems (MMSs) and excessive human labor, making it difficult to maintain up-to-date maps in a large scale [3], [4].\nRecent works facing up to this challenge can be divided into two categories: offline HD map crowdsourcing and on-line HD map construction (online mapping). Crowdsourcing methods utilize sensor data generated from massive vehicles [5], [6], which is adequate and cheap. Collected data are automatically preprocessed by cloud services, while manual labeling is not fully omitted [7], [8], [9]. On the other hand, online mapping alleviates the burden of laborious stages [6], [10], which directly predicts a local map from the surrounding environment on the ego vehicle. However, it is challenging to produce temporal consistent results. Also, former methods [11], [12], [13], [14] are not able to generate vectorized global maps like crowdsourcing does.\nTo move a step forward, we emphasize the Static Map Assumption, which means from the global perspective, the ground-truth map remains unchanged in a certain period of time, regardless of illumination, weather, and pose change of sensors. Therefore, we combine crowdsourcing with online mapping, bringing an online framework that performs closed-loop vectorized global map construction and utilization, to produce globally consistent results. It is possible to incorporate multi-run perception results from massive vehicles, and the vectorized map is space-saving for practical use on ego vehicles.\nIn this paper, we present GlobalMapNet, an online framework for vectorized global HD map construction. Based on local mapping methods, GlobalMapNet keeps an extraordinary global map as the long-term memory, which is obtained by continuously merging local perception results. Also, this global map can be rasterized and fused with bird's-eye-view (BEV) features improve real-time prediction. Our method differs from crowdsourcing methods in that, it produces vectorized map elements with an online framework, which can be directly applied to downstream tasks like localization and planning to enable multi-task knowledge exchanging in an end-to-end driving system [15].\nTo summarize, this paper makes the following contributions:\n\u2022\tWe introduce the first online framework for vectorized global HD map construction, namely GlobalMapNet, with the ability to continuously update and utilize a global map, producing consistent perception results.\n\u2022\tWe formulate the process of online global map construction and address major concerns on evaluation with global average precision (GAP), a novel metric designed for global map evaluation.\n\u2022\tWe conduct experiments on both nuScenes and Argoverse2 datasets, and show the effectiveness of our method by examining both local and global map construction."}, {"title": "II. RELATE WORKS", "content": "Crowdsourcing. Crowdsourcing aims at lowering both the cost of expensive devices and human labor. Researches are conducted on various sectors [5], including data collection and cleaning [8], [16], simultaneous localization and mapping (SLAM) [17], [18], feature reconstruction [19], change detection and map update [20], [21], [22], [23].\nRecent works address the automated generation of road structures based on crowdsourced data. [24] focuses on producing topological maps of road intersections. It collects and predicts a semantic map, together with accumulated traffic flows on the massive vehicles. On-cloud alignment is performed to form a consistent global map, using an optimization method based on Transformer [25]. Road intersections are detected by forming a polygon from pedestrian crossings, then traffic flows are clustered and postprocessed to generate a topology of the intersection. MapCVV [26] generates vectorized maps based on semantic road elements predicted on massive vehicles. The on-cloud system performs single-run aggregation for inter-frame consistency and multi-run aggregation for global consistency. Element-level optimization is adopted to minimize the internal error within a local subpart of the map, promoting absolute accuracy.\nCrowdsourcing methods specialize in integrating multi-run data into a unified global map. However, this part is mostly done by cloud services, preventing real-time interactions with the online driving system. Our work suggests aggregation on the ego vehicle, producing a globally consistent map with an online framework.\nOnline mapping with temporal modeling. Online mapping methods directly predict a local map on the ego vehicle. A common practice is to leverage short-term temporal information. HDMapNet [11] performs temporal fusion on rasterized maps by averaging probabilities over several frames. Tesla displays in its AI Day 2021 a temporal BEV mapping system with Spatial RNN, producing consistent rasterized results. StreamMapNet [13] generates vectorized local maps with the propagated BEV feature and map queries, which are iteratively updated within a driving scene. MapTracker [14] views online mapping as a tracking task, utilizing strided temporal information in different historical locations.\nSome works exploit long-term temporal information. NMP [27] builds a global BEV features map on-cloud. The ego vehicle downloads a local clip to fuse with the local BEV feature and updates the fused result to the server afterward. GNMap [28] aggregates multi-run generation of vectorized local maps and produces a rasterized global map. Since rasterized results are expensive to store when the map scales up, HRMapNet [29] stores a historical map with 8-bit unsigned int values. The map is utilized with BEV feature fusion and map query initialization, then updated by rasterizing vectorized map elements and simply replacing pixels.\nFormer methods have not considered building a vectorized global map on the ego vehicle. Rasterized maps cost a lot of memory, and pixel accumulation is not aligned with the target of predicting vectorized map elements. In this paper, we suggest that it is possible to update and utilize a vectorized global map online, which can be directly used in downstream tasks like localization and planning. The key point is to keep and arrange map elements in vectorized form, which is space-saving compared to methods based on rasterized maps."}, {"title": "III. GLOBAL MAP CONSTRUCTION", "content": "A. Task Formulation\nLocal map construction. Local mapping around the ego vehicle can be formulated as a procedure for generating vectorized map elements (e.g. road boundaries), which are composed of categorical labels and 2D polylines on the BEV plane [30], [31]. We define a local map Mi as a collection of labeled point sequences:\n$M_i = \\{(c_{ij}, P_{ij})\\}_{j=1}^{N_{c_i}}$\n(1)\n$P_{ij} = \\{(x_{ijk}, y_{ijk})\\}_{k=1}^{N_{P_{ij}}}$\n(2)\nwhere Pij is a 2D point sequence presenting a map element in Mi, and cij is the categorical label of Pij.\nSuppose the vanilla model F get a stream of camera images $I = \\{I_i\\}_{i=1}^{N_T}$ as the input during the time period $T = \\{T_i\\}_{i=1}^{N_T}$. The model continuously generates a stream of local maps $M = \\{M_i\\}_{i=1}^{N_T}$, where $M_i = F(I_i)$, using only current frame information.\nGlobal map construction. Based on the Static Map As-sumption that ground-truth map elements are unchanged during a certain period of time, a local clip of the optimal global map $M_{global}^*$ with ego vehicle pose pi is exactly the optimal local map $M_i^*$:\n$M_i^* = Clip(M_{global}^*, p_i)$.\n(3)\nThis encourages us to explore global map construction. As it is impractical to predict the global map $M_{global}^*$ at once, we have to continuously update it by merging local maps. At time Ti, our map fusion model Fmf will additionally load the propagated hidden state Hi\u22121 (e.g. BEV feature), and the latest global map $M_{global,i\u22121}$, where the local map prior $M_{i-1}$ is clipped. The model then predicts the current local map Mi, which is used to update the global map into Mglobal,i. This process can be formulated as follows:\n$M_{i-1} = Clip(M_{global,i-1}, p_i)$,\n(4)\n$M_i = F_{mf}(I_i, H_{i-1}, M_{i-1})$,\n(5)\n$M_{global,i} = Merge(M_{global,i-1}, M_i, p_i)$.\n(6)\n$M_{global,i}$ represents the overall perception result from T\u2081 to Ti. It can be further utilized to measure the overall quality of online perception, uploaded to the server to be inspected and corrected, or saved to local storage and transferred to other vehicles, serving as a long-term memory for multi-run perception. Equation (4) - (6) can also be used to formulate a practical paradigm for model-based offline global map construction.\nB. Evaluating global map construction\nThe average precision (AP) metric based on Chamfer Distance, often used to measure a single-frame local map prediction in online mapping literature [13], [31], cannot promise the overall perception quality in a certain period of time. AP cannot reflect the inconsistency of map prediction, which can bring security risks to autonomous driving systems. Also, given by the Static Map Assumption formulated with (3), if the model produces a high-quality global map, local map predictions are more trustworthy. The reasons above derive the necessity of a global map evaluation metric.\nLocal map evaluation. We first formulate local map evaluation with AP. Suppose the model produces a series of local maps $M = \\{M_i\\}_{i=1}^{N_T}$ and a global map Mglobal within time period $T = \\{T_i\\}_{i=1}^{N_T}$, AP is given by:\n$AP = AUC\\left(\\bigcup_{i=1}^{N_T}PR (M_i, M_i^*)\\right)$.\n(7)\nwhere Mi denotes the ground-truth local map. PR is the algorithm to match map elements and compute precision and recall within a pair of single-frame local maps and AUC computes the area under the precision-recall curve.\nGlobal map evaluation. Based on AP, we derive the formulation of GAP, our novel metric for evaluating global map construction. We simply apply AP computation on Mglobal instead of M:\n$GAP = AUC (PR (M_{global}, M_{global}^*))$.\n(8)\nPursuing AP does not always bring better GAP, and vice versa. A framework focusing on global map construction may tolerate a little AP decrease, so long as it produces more consistent results indicated by GAP."}, {"title": "IV. GLOBALMAPNET", "content": "The main idea of GlobalMapNet is to maintain and update a global map, which can be utilized as the prior for local map prediction. As shown in Fig. 2, GlobalMapNet comprises three modules:\n\u2022\tAn online local mapping system that accepts sequential sensor inputs to generate local maps;\n\u2022\tThe GlobalMapBuilder which keeps a global map memory, and continuously update it based on the latest local map prediction;\n\u2022\tThe GlobalMapFusion module that clips a local patch from the global map, fusing historical map information and the current local feature.\nA. Local mapping\nVarious online local mapping methods can fit into our global map construction framework. To keep a balance between accurate prediction and real-time computation, we choose StreamMapNet [13] as our local mapping module, which is a vision-based temporal model with simple archi-tecture and high FPS.\nBEV feature extraction. At first, the surrounding camera images are processed by a CNN Feature Extractor, a Feature Pyramid Network (FPN) [32] fusion module and a BEV Encoder, producing the initial BEV feature. It is fused with historical BEV feature through a Gated Recurrent Unit (GRU) [33] network, which further propagates the fused BEV feature as a short-term memory.\nMap Decoder. The Map Decoder is a variant of Deformable DETR [34]. It uses a set of learnable map queries to interact with fused BEV feature, and directly predicts map element instances in the current frame, each consists of the category and a point sequence.\nMatching and training. The model performs a Hungarian Matching between predictions and labels, and loss is com-puted between matched pairs. Matching cost and loss are designed to minimize both classification error of category labeling and regression error of point sequence prediction."}, {"title": "B. GlobalMapBuilder", "content": "Map generation of an online local mapping system is limited to a small range. To get a global output, the GlobalMapBuilder starts with an empty global map, and continuously incorporates predicted local maps through a series of geometric algorithms, including map matching, in-place replacement and Map Non-Maximum Suppression (NMS).\nMap matching. At a certain frame, newly detected local map elements are transformed into global coordinates, indicating the latest perception of the global environment. A map element in this local map may be a replacement or a part of a former global map element. In that case, new and old predictions should be matched before merging.\nTo formulate, we define {P},{P} as map elements in the global map and those in the newly predicted local map, correspondingly. Category labels are omitted, as merging only happens inside the same category. Equation (4) produces a local clip {P} from {P}, which is matched with {P} by Hungarian Matching algorithm based on Chamfer Distance, forming matched pairs {(PC,P)}.\nIn-place replacement. An in-place replacement strategy is adopted to merge matched pairs. A least-distance projection of P onto the corresponding Pf is computed, where subsequence of P will be replaced by the entire PL. Finally, we get $P_G^+$ as the merged global map, also including non-matched local and global map elements.\nMap NMS. To further improve the quality of global map construction, we propose a novel post-processing method, namely Map NMS, to remove duplicate predictions of map elements. Similar to NMS in object detection, {$P_G^+$} first sorted by confidence score, and a map element with higher score eliminates another if their Intersection over Union (IoU) is above the given threshold. Here, buffered IoU [35] is employed to formulate the overlapping between point sequences. With Map NMS, overlap within the same category can be eliminated to produce a clean global map."}, {"title": "C. GlobalMapFusion", "content": "To improve both the quality and consistency of local map prediction, the latest global map can be exploited as the prior. We employ the GlobalMapFusion module to put this idea into practice. The global map elements are first rasterized into BEV masks, then fused with the current BEV feature, which allows map queries in Map Decoder to interact with global map information.\nSoft rasterization. For a certain category ci \u2208 C, we gather corresponding map elements into $\\{P_{G_{ij}}\\}_{j=1}^{N_{c_i}}$, where Nc\u2081 denotes the total amount of map elements within this category.\nA local clip $\\{P_{V_{oj}}\\}_{j=1}^{N_{c_i}}$ is extracted from $\\{P_{G_{ij}}\\}_{j=1}^{N_{c_i}}$ GlobalMapFusion then rasterizes these point sequences into a soft BEV mask with Gaussian-based rendering method [36], [37]:\n$I_{c_i}(x, y) = \\max_{j=1}^{N_{c_i}}exp\\left(-\\frac{D(x,y; P_{G_{ij}})}{\\tau}\\right)$.\n(9)\nwhere $I_{c_i}(x, y)$ represents the intensity of mask with category ci in position (x, y), so that $I_{c_i}(x, y) \\in [0, 1)$, and $D (x,y; P_{G_{ij}})$ is the Euclidean distance between (x,y) and the point sequence $P_{G_{ij}}$. \u03c4 is a smoothness factor that regulates the distance, so that larger \u03c4 gives a smoother rendering.\nUtilizing traced region. It is important for an ego vehicle to ascertain the range of the traced region (i.e. visible region) where historical perception results have covered. The traced region boundary is viewed as a special category co. Take this into consideration, we acquire |C|+1 soft BEV masks {Ic\u1d62}all together.\nFusing the historical map. We adopt a simple yet effective way to utilize the map prior. GlobalMapFusion performs a channel concatenation between the linearly transformed BEV feature and rasterized soft BEV masks, and Layer Normalization is adopted to align these features. The fused BEV feature contains both local perception results and long-term information from the global map, both can be accessed by map queries in Map Decoder.\nWhen there is no existing global map, all BEV masks are filled with 0. The model is trained to fully rely on the local perception inputs when there is no available map information."}, {"title": "V. EXPERIMENTS", "content": "We evaluate our method for both local and global map generation on two widely recognized datasets: nuScenes [38] and Argoverse2 [39].\nA. Implementation details\nTasks. We base our experiments on driving scenes, each lasting for 20s (in nuScenes) or 15s (in Argoverse2), sampled at 2Hz. The inputs within each scene are a stream of surrounding camera images, 6 for nuScenes and 7 for Argoverse2, together with camera intrinsic and extrinsic parameters. The labels are the vectorized global map of this scene and a stream of vectorized local maps clipped from it. The map includes three generally concerned categories of map elements: road boundary, lane divider, and pedestrian crossing.\nTraining. We keep hyper-parameters and other training details aligned with StreamMapNet, which serves as the baseline. For both GlobalMapNet and StreamMapNet, models are trained on a single GPU with a batch size of 4 and a gradient accumulation step of 8. Each model is trained for 24 epochs, while in the first 4 epochs, GlobalMapNet keeps an empty map without update. Also, we adopt an uneven update strategy, where only 1/4 of scenes can update and fuse the stored global map frame by frame. This makes training smoother for the GlobalMapFusion module, and predicting scenes with empty maps increases the robustness of the model.\nEvaluation. Comparison is made to examine the effectiveness of GlobalMapFusion. Since the original StreamMapNet does not generate a vectorized global map, an identical GlobalMapBuilder is installed on it. We mainly consider mean AP (mAP) and mean GAP (mGAP) over all three categories, which indicates the overall ability of local and global map construction. The capability of GlobalMapBuilder is further explored in the ablation study and visualization.\nB. Results\nSingle-scene evaluation. We first consider map generation within a single scene. Experiments are conducted on new train and validation splits on nuScenes and Argoverse2, to minimize location overlap [13]. Every model starts with an empty global map, updates every 4 frames (about 2 seconds) with the latest perception results, and evaluates GAP after the entire scene is traversed.\nCross-scene evaluation. Cross-scene evaluation is a more challenging task, which examines the ability of long-term global map construction. Experiments are conducted on nuScenes, which contains scenes ranging from July 2018 to November 2018. Scenes are first sorted by timestamps as if the ego vehicle is naturally driving in order of date and time. At the first frame of every new scene, it inherits the latest historical map that contains the current position of the ego vehicle. Therefore, the range of the global map tends to grow as driving time increases, making it harder to predict long and continuous road boundaries and lane dividers.\nC. Ablation studies\nAblation studies are conducted on nuScenes at 60 \u00d7 30 m range, to analyze the effectiveness of each module, and how the parameters of GlobalMapBuilder affect global map construction."}, {"title": "Ablation on each module", "content": "Our ablation study on each module of GlobalMapNet is shown in Table V. Starting from a non-temporal model, modules are iteratively added and evaluated. Their contributions are demonstrated by mAP and mGAP increases:\n1) StreamMapNet- is the basic non-temporal model, which is a modified version of StreamMapNet deprived of any temporal information input.\n2) StreamMapNet is the original baseline model. It utilizes BEV feature propagation and Query propagation, which brings 2.8 mAP increase and 1.3 mGAP increase.\n3) GlobalMapNet- replaces Query propagation with GlobalMapFusion. This step brings 1.1 mAP increase and 3.4 mGAP increase.\n4) GlobalMapNet further utilizes traced region information in map fusion, which brings 0.8 mAP increase and 0.3 mGAP increase.\nThe results indicate that GlobalMapFusion is more pow-erful in incorporating vectorized map prior, which is important as well as propagated BEV feature. Traced region information also benefits both local map and global map prediction, in that it can be used to tell an empty region from an unexplored region.\nParameters of GlobalMapBuilder. The GlobalMapBuilder should be carefully optimized to generate decent global maps. We mainly analyze the impact of two map update parameters: the chamfer distance in map matching, and the buffer distance to compute buffered IoU in Map NMS. These parameters are adjusted only at the inference stage, to merely examine the GlobalMapBuilder.\nWe discover that these parameters can strongly affect the GAP at the inference stage. For GlobalMapNet, GAP is more sensitive to these parameters, and it's better to adjust the distance for every category according to its common pattern. For example, road boundaries are typically long and distant to each other, thus larger Droad should be adopted."}, {"title": "D. Visualization", "content": "To analyze single-scene performance, we examine GlobalMapNet and StreamMapNet on both nuScenes and Argoverse2 at 60 \u00d7 30 m range. As depicted in Fig. 3, GlobalMapBuilder helps both models to generate decent global maps with matching, replacement, and Map NMS algorithm. GlobalMapNet is superior to StreamMapNet in global map construction, showing the effectiveness of the GlobalMapFusion module. Also, predicting complex road structures remains the major challenge, as it is harder to understand long and continuous map elements with the range of the global map growing."}, {"title": "VI. CONCLUSION", "content": "In this study, we propose GlobalMapNet to provide a novel perspective in HD map construction. Our method can practically generate vectorized global maps on massive vehicles, with efficient map building algorithms and map fusing techniques. Current global mapping framework still struggles in producing complicated road structures, especially when taking accuracy, consistency and real-time performance into account. We hope our work will facilitate future research in overcoming these difficulties."}]}