{"title": "Randomized-Grid Search for Hyperparameter Tuning in Decision Tree Model to Improve Performance of Cardiovascular Disease Classification", "authors": ["Abhay Kumar Pathak", "Mrityunjay Chaubey", "Manjari Gupta"], "abstract": "Cardiovascular disease refers to any critical condition that impacts the heart. Because heart diseases can be life-threatening. Researchers are focusing on designing smart systems to accurately diagnose them based on electronic health data, with the aid of machine learning algorithms. Heart disease classification using machine learning (ML) algorithms such as Support Vector Machine(SVM), Na\u00efve Bayes(NB), Decision Trees (DTs) and Random Forests (RFs) are often hindered by overfitting. These ML algorithms need extensive hyperparameter tuning. Random Search offers a faster, and, more efficient exploration of hyperparameter space, but, it may overlook optimal regions. Grid Search, though exhaustive, but, it is computationally expensive and inefficient, particularly with high-dimensional data. To address these limitations, Randomized-Grid Search, a novel hybrid optimization method is proposed that combines the global exploration strengths of Random Search with the focused, and, exhaustive search of Grid Search in the most promising regions. This hybrid approach efficiently balances exploration and exploitation. The proposed model optimizes the hyperparameter for Decision Tree model. The proposed model is applied to UCI heart disease dataset for classification. It enhances model performance, provides improved accuracy, generalization, and computational efficiency. Experimental results demonstrate that Randomized-Grid Search outperforms traditional methods by significant margins. The proposed model provides a more effective solution for machine learning applications in healthcare diagnosis.", "sections": [{"title": "Introduction", "content": "Cardiovascular diseases (CVDs) are the leading cause of mortality and morbidity globally, including approximately 17.9 millions lives every year, which cumulates to 31% of global deaths [1]. The consistent increase in CVDs prevalence, influenced by the factors such as aging, population's lifestyle changes along with the regional factors also has significant role in it. Comorbidities like diabetes and hypertension, has led to an increasing burden on healthcare system worldwide [2]. Which necessitates the early and accurate diagnosis to mitigate the impact of heart disease by allowing timely intervention to reduce mortality rate and economic burden of healthcare. However, there are traditional diagnostic methods for heart diseases, which rely heavily on manual interpretation of electronic health records. It can be missed subtle trend and interactions that are clear indicative factors of heart disease progression [3-5]. Due to the severity of CVDs, it is essential to overcome this challenge by automating the diagnosis process. Hence, it sparked an interest of using Artificial intelligence (AI), which led us to develop more accurate and automated diagnostics tools for CVDs [6-8]. Especially Machine Learning (ML) has shown promising results improving the accuracy of heart disease classification. ML models can analyse large set of electronic health records to detect complex pattern that might be imperceptible by clinicians [9-14]. State-of-the-art models specifically Random Forest (RF), K-Nearest Neighbour (KNN), Decision Tree (DT), Extreme Gradient Boosting (XGB), and Multilayer Perceptron (MLP) have demonstrated their ability to predict disease risk, early diagnostics and classification of longitudinal health data [15]. Among different ML classification models, tree based models have emerged as popular choices due to its ability to handle large datasets, robustness in maintaining balance on both categorical and numerical attributes, and strong resilience to overfitting [16-19]. Tree based classification algorithms works by recursively splitting the dataset into subsets based on the attribute values, creating tree like structure which is able to effectively capture non-linear relationship between input data and final outcome. These models are effective particularly in healthcare domain where datasets are often high dimensional, noisy and imbalance [20]. Despite the overall usability of tree based ML models, these are highly sensitive to the proper selection of hyper parameters like many other ML algorithms. Performance of tree based models are highly reliable and depends on the selections of hyper parameter values. Hyper parameter tuning of tree based ML models significantly influence the models performance, generalizability and computational efficiency [21-22]. Hence, It necessitates to fine tune these hyper parameters for optimal performance. But finding the optimal set of parameters are often challenging and computationally expensive in terms of time and space complexity, particularly when dealing with large set of parameters that are mutually dependent. Tuning these hyperparameters is essential for optimizing model performance, but finding the optimal set is often challenging, especially when dealing with numerous parameters that interact in complex ways. Generally, hyperparameter tuning for tree based models is done using methods like random and grid search [23]. Grid search focuses on exhaustive search over a predefined set of hypermeters, testing all possible combinations to find the best set of hyperparameters for optimal model performance [24]. While effective, this approach can be computationally expensive, especially when the hyper parameters space requirement is too large. On the other hand, random search utilizes the random combinations of hyperparameter from predefined space. Which shifts to the exploitations over the separation leading to improved efficiency but often messing optimal hyperparameters sets of combinations. In contrast, it selects random combinations to omit optimal set of hyperparameter set to promise the efficiency but does not guarantee the comprehensive exploration of entire search space. Recent research has introduced techniques that integrates random sampling with some targeted searches in promising regions of the hyperparameter space, allowing more efficient opination of the ML models [ 25-27]. The trade-off between exploration and exploitation led us to develop a hybrid approach which combines strength of exploration and efficiency of random search together. In this study, a novel hybrid search has been proposed called Randomized-Grid Search to address the limitation of traditional random and grid search. Which leverages the efficient way to search most promising area, and exhaustive search in the targeted regions provided by the random search. The proposed randomized grid search technique applied to heart disease classification dataset using tree-based (Decision Tree, Random Forest and Gradient Boosting Decision) classifiers as a foundational method. Our experiment conducted on \u2018UCI Heart Disease' dataset which demonstrated that the proposed randomized grid search algorithm outperforms the both traditional random and grid search in terms of different performance evaluation matrix [28]. Additionally, proposed method significantly reduces the computational cost of hyper parameter tuning while providing a greater performance. This makes randomized grid search a valuable tool for optimizing ML models in real-world applications where time and computational resources are often limited and performance of model is critical [29]."}, {"title": "Proposed Methodology", "content": "In this section, a hybrid approach(Randomized-Grid Search) have been presented for hyperparameter tuning which combines the strength of Random Search for exploration and Grid Search for exploitation. The proposed technique further applied and validated for CVDs classification problem which uses the UCI Heart Disease Dataset.\nRandom Search: A hyperparameter optimization technique which involves randomly selecting values of hyperparameters from the pre-defined space. Instead of evaluating all possible combinations like Grid Search, it selects sample points randomly.\nLet O represent the hyperparameter space where each parameter \u03b8\u2081 drawn from the probability distribution p\u012f:\n\u03b8i~Pi\nGiven n random samples from the hyperparameter space the goal is to find the optimal parameter space 0*, that minimizes the specific loss function L.22 The mathematical expression of Random Search is given as:\n0* = ar90\u20ac{01,02.....}{min L(fo(Xtrain), Ytarin) }\nWhere fois the model parametrized by 0, Xtrainis the training data and Ytarin is the corresponding label.\nGrid Search: A parameter optimization technique which systematically explores the hyperparameter space by evaluating all possible combinations using predefined hyperparameter values.\nLet @ be a hyperparameter space of a discrete grid where each hyperparameter \u03b8\u2081 takes a specific value from the predefined set O\u00a1, It can represent in the form pf cartesian product of the set of values of each parameter:\n\u0398\n01 \u00d7 02 \u00d7 ... \u03a7 \u0398\u03c1,\np\nWhere 01, 02 ... \u0398p represents the possible values for each of the p parameters. The optimization problem can be expressed as:\n\u03b8\nargoe@grid{min L(fo(xtrain), Ytarin) }\nWhere L is a loss function, fois the model parametrized by \u03b8, and Ogrid represents the all possible combinations of hyperparameters in the grid."}, {"title": "Mathematical Expression of proposed Randomized-Grid Search", "content": "Randomly sample m hyperparameter sets from the space Orandom:\nOrandom = ar90\u20ac{01,02,...,.m} {min L(fe (xtrain), Ytarin)\nWhere \u03b8\u2081~pi and random is best performing configuration of parameter values from random search.\nAfter identifying brandom, restrict the search space to smaller grid Ogrid, which is cantered around @random, then exhaustive grid search is applied fine tuning:\n0* = arg0e@grid(@random) {min L(fo (Xtrain), Ytarin) }\nWhere Ogrid(random)is narrowed search space around \u017frandom, often chosen by smaller variations around the parameters of random"}, {"title": "Integration of Randomized-Grid Search with Decision Tree", "content": "The proposed framework presented in Fig. 2, illustrates the stepwise process of the model. It focuses on the pipeline used for CVDs classification using UCI Heart Disease dataset. The initial steps is Data Acquisition which have 13 independent and 1 dependent variable feature. Data Preprocessing involves Normalization, Null value imputation and outlier remover to prepare dataset for the model. In next step, a decision tree model is employed with its selected parameters. Following the decision tree model, hybrid hyper parameter tuning have been employed which combines the strength of Random search and grid search. In the next step optimized model with best hyperparameter set of values assessed using performance evaluation metrices. In the last step the results are shown with a focus on improved model generalizability and reduced computational cost.\nRandomized-Grid search integration with decision tree training process, it aims to optimize the hyperparameters Y1, Y2, \u2026, Yn\u00b7\nProblem Setup: Given the dataset D = {(xi, yi)}=1where:\nx\u2081 \u2208 Rdrepresents the feature vectors with d dimensions,\nyi \u2208 {0,1} is binary class label for each instance i."}, {"title": "", "content": "We defined parameter space \u0393 = (Y1, Y2, \u2026, Yi), where Y1, Y2, ..., Yi are the decision tree hyper parameters.\nThe objective is to minimize the validation loss L by optimizing these parameters Y1, Y2, \u2026, Vi through Randomized-Grid search.\nStep 1. Random Search:\n1.1: Random Sampling: randomly sample m hyperparameters configuration y = (\u03b3\u03ad, \u03b3\u03ad, ..., \u03b3\u03ae) from predefined distributions:\nv~Pj,\n\u2200;\u2208 (1,2, ..., n)\nWhere P; is a probability distribution for each parameter.\n1.2: Model Fitting: For each sampled hyperparameter configuration y\u00b9, train a decision tree fyi on training dataset DTraining:\nfyi = TrainTree(DTraining, \u03b3')\nWhere fyi represents the decision tree trained with sampled hyperparameter y\u00b9.\n1.3: Model validation: Compute the validation loss \u00a3(i) for each model fyi on validation set Dvalidation:\nL(i) = L(fyi (Xvalidation), yvalidation)\nWhere L represents the loss function.\n1.4: Storing Results: Store each hyperparameter configuration and its corresponding loss:\ni\nHrandom\n=\n{\u03b3\u03af, L(i)}\nSi=1\n1.5: Selection of best hyperparameter set:\n\u0176random = argyeyrandom min L(fy(xvalidation, Yvalidation))\nStep 2. Grid Search:\n2.1: Define the Grid search range: After identifying \u0176random, define a local grid search range around each hyperparameter in \u0177random:"}, {"title": "", "content": "\u300cGrid = {yj \u2208 [\u0177random,j \u2013 \u2206j, \u0177random,j + \u2206j ]}}=1\nWhere Aj defines the grid refinement range around each optimal random hyperparameter \u00cerandom,j.\n2.2: Exhaustive Grid Search: Perform an exhaustive grid search over the smaller parameter space \u300cGrid, for each set of hyperparameter y in the grid:\nTarin the model fy = TrainTree(Drraining, Y)\nCompute the validation loss of each grid search model:\nLGrid(y) = L(fyi(xvalidation), Yvalidation)\n2.3: Storing Grid Search Result:\nHGrid = {y, LGrid(y) | \u03b3\u2208 \u0393Grid}\n2.4: Selecting the best parameter set:\n\u03b3* = ar argyet Grid min(LGrid(y))\nStep 3. Final Model Training and Evaluation:\n3.1: Train the final decision tree: using the optimal hyperparameters y*, train the final decision tree on entire training set DTraining:\nfy* = TrainTree(Dtraining, Y*)\nWhere fy* is the final decision tree trained with optimal hyperparameters.\n3.2: Test Set Evaluation: Evaluate the final decision tree fy*, on test set Dresting, and compute the performance of test data :\nLTest = L(fy*(XTest, YTest))\nWhere Lrest represents appropriate evaluation metrics."}, {"title": "Results", "content": ""}, {"title": "Dataset Description", "content": "The dataset used in this research study is sourced from the UCI Heart Disease repository, which have been commonly used for research focusing on predicting cardiovascular diseases [28]. It holds the data gathered from a variety of medical examinations and clinical assessments. The dataset includes both, numerical and categorical features, such as demographic details like age and sex along with the clinical records like cholesterol level, blood pressure, and heart rate. Many other features like ECG, thallium stress tests are also included in this dataset to capture broader aspects of an individual. Also, the dataset provides the label for the indication whether patients have the heart disease or not. This dataset is widely used in the development of AI models, making it as a benchmark dataset for studying the risk factors associated with the CVDs."}, {"title": "Evaluation Metrics", "content": "Performance Evaluation Metrics:\nTP(True Positive) | The number of cases where model correctly identifies the presence of Heart Disease\nTN(True Negative)\nThe number of cases where model correctly identifies the absence of Heart Disease\nFP(False Positive)\nThe number of cases where model mistakenly identifies as presence of Heart Disease but actually it is absence\nFN(False Negative)\nThe number of cases where model mistakenly identifies as the absence of Heart Disease but it is present actually\nTPR(True Positive Rate)\nHigher value of TPR shows that the model is effective at identifying the presence of Heart Disease\nFPR(False Positive Rate)\nModel with Lower FPR is required to say that very few cases of without Heart Disease identifies as presence of Heart Disease\nA. Accuracy: The ratio of correctly predicted observations and the total observations.\nAccuracy = \\frac{TP + TN}{TP + TN + FP + FN}\nB. Precision: Ratio of correctly predicted positive observations to the total predicted positive observation"}, {"title": "", "content": "Precision = \\frac{TP}{TP + FP}\nC. Recall: It is the ratio of correctly predicted positive observation to all observation in actual class\nRecall = \\frac{TP}{TP + FN}\nD. F1 score: It is the weighted average of precision and recall\nF1 Score = 2(\\frac{Presicion * Recall}{Precisiom + recall}\nE. ROC(Receiver Operating Characteristics): A visual graph showing the performance model at all classification thresholds plotting true positive rates against false positive rates.\nTPR(True Positive Rate) = \\frac{TP}{TP + FN}\nFPR(False Positive Rate) = \\frac{FP}{FP + TN}\nF. AUC(Area Under the Curve): The models ability to classify between positive and negative class\nAUC = \\sum_{i=1}^{n-1} (\\frac{TPR_{i+1} + TPR_i}{2}) (FPR_i \u2013 FPR_{i+1})"}, {"title": "Hyperparameters Used in this Study", "content": "List are hyperparameters used in this study are given below:\nA. Criterion (criterion): it defines the metric ( \u2018gini' or 'entropy') uses to assess the quality of split for the classification tasks.\nB. Splitter (splitter): Defines the strategy of selecting the split at each node, \u2018Best' for optimal split and \u2018Random' selects the best splits from random subset.\nC. Maximum Depth (max_depth): Controls the maximum depth of tree(how much tree can grow) which handles the complexity of the model\nD. Minimum Sample Leaf (min_sample_leaf): Defines the minimum number of samples required to split an internal node which can be defined in integer or fraction of sample.\nE. Minimum Sample per Leaf (min_sample_leaf): Makes sure that every leaf node contains minimum number of sample which results in preventing overfitting by ignoring overly small leaf nodes.\nF. Minimum Weight Fraction per Leaf (min_weight_fraction_leaf): Similar to min_sample_leaf, but it considers the fraction of the total sample weights.\nG. Maximum Features (max_features): Restricts the number of features used in the split such as 'sqrt' (square roots of total features), \u2018log2' (logarithm of total features) and 'none' (considers all features).\nH. Maximum Leaf Nodes (max_leaf_nodes): Limits the total number of leaf nodes which results the preventing overfiiting by reducing model complexity.\nI. Minimum Purity Decrease (min_purity_decrease): If the decrease in impurity is greater than threshold then and only then split is allowed which restricts unnecessary splits.\nJ. Cost Complexity Pruning Alpha (ccp_alpha): In pruning it acts as a regularization parameter to control the tree complexity and impurity, the more higher leads to more aggressive pruning.\nK. Random State (random_state): Sets the value of seeds for random number generation for maintaining reproducibility."}, {"title": "Performance Evaluation of Proposed Model", "content": "The confusion matrix shown in Fig. 4 of the optimal model using randomized-Grid Search approach yields its effectiveness in correctly classifying CVDs cases. Higher True Positives (n=42) and True Negatives (n=31) showcases the model's ability to distinguish between patients and healthy individuals. On the other hand, low numbers in False Positive (n=10) and False Negative (n=8) demonstrates the minimized misclassification, which is crucial in healthcare applications where precision and recall plays an important roles.\nThe ROC graphs presented in Fig. 5, compares the performance of a decision tree using different parameter tuning techniques, Fig. 5(a) shows the 0.83 using decision tree with grid search which shows very decant performance but with high computational cost. Where decision tree with random forest shown in Fig. 5(b), demonstrates lower AUC value of 0.80 than Grid Search but faster in training on the data which could potentially lead the optimal solutions. On the other hand, in Fig. 5(c) it shows that decision tree with randomized grid search archives best AUC value of 0.84, combining the thoroughness of both techniques making it effective and computationally efficient approach."}, {"title": "Discussion", "content": "The Randomized-Grid Search approach achieved a notable improvement in all performance metrics compared to the traditional Random Search and Grid Search methods. The hybrid approach effectively balanced exploration and exploitation, leading to better hyperparameter tuning, which ultimately improved the classification performance. The F1-Score increase is particularly important in healthcare applications, as it represents a balance between Precision and Recall, which are crucial for accurate disease detection. In addition to improved model performance, the Randomized-Grid Search also demonstrated superior computational efficiency compared to traditional Grid Search. The following Table 3, summarizes the time taken to complete the hyperparameter tuning process for each method. While Grid Search provided competitive performance, it required significantly more time to train and optimize the model compared to both Random Search and Randomized-Grid Search. The hybrid Randomized-Grid Search method reduced the training time by nearly 40% compared to Grid Search, while still achieving better model performance. This improvement in computational efficiency is critical for real-world applications, where resources and time are often limited.\nThe findings of this study demonstrates the significance of the proposed Randomized-Grid Search approach in optimizing hyperparameters for decision tree model used in CVDs. The Proposed method successfully combines the strength of Random Search and Grid Search to achieve significant improvement in both performance and computational efficiency. Unlike random Search, which can look only to the high-performing regions of the hyperparameter space and Grid Search which is computationally inefficient, randomized-Grid Search balances the exploration and exploitations by narrowing the search space to promising regions identified through Random Search. The narrow search space further used exploited by Grid Search enhances the model's overall performance metrics.\nThe results demonstrates that proposed search technique with decision tree model achieves highest classification performance, outperforming both traditional methods. Additionally, an improvement in F1-score highlights the ability of the model to maintain a balance between precision and recall. Which is critical in healthcare applications where false positives and false negatives can have severe implications. Furthermore, the proposed technique significantly reduces the computational time compared to grid search, which leads to more practical solutions to the real-time problems, especially in resource constrained environment . By optimizing he Decision Tree parameters, the proposed study enhances the model's generalizability while maintaining computational efficiency. This is particularly crucial for large and high-dimensional datasets often encountered in medical datasets. The study suggests that Randomized-Grid Search offers a viable and superior alterative for hyperparameter tuning, not only limited for decision tree model but also for other ML algorithms in healthcare and other applications."}, {"title": "Conclusion", "content": "In this study, we proposed and implemented a novel hybrid search method for hyperparameter tuning for decision tree model for CVDs classification. The hybrid search method combines the strength of Random Search for broad exploration and Grid Search for focused, exhaustive exploitation in promising regions. The study shows that the proposed hybrid approach for hyperparameter tuning can significantly enhance the performance of ML models used in healthcare, especially when traditional methods have failed due to high computational cost and uncertainty. This approach have the potential to be extended further to other ML tasks, providing a balanced solutions for hyperparameter tuning in various applications. In future, we could explore its applications to more complex models and datasets, to asses its utility in addressing real-world challenges in AI and ML."}]}