{"title": "FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness", "authors": ["Yangyang Xiang", "Nannan Wu", "Li Yu", "Xin Yang", "Kwang-Ting Cheng", "Zengqiang Yan"], "abstract": "Federated learning has emerged as a compelling paradigm for medical image segmentation, particularly in light of increasing privacy concerns. However, most of the existing research relies on relatively stringent assumptions regarding the uniformity and completeness of annotations across clients. Contrary to this, this paper highlights a prevalent challenge in medical practice: incomplete annotations. Such annotations can introduce incorrectly labeled pixels, potentially undermining the performance of neural networks in supervised learning. To tackle this issue, we introduce a novel solution, named FedIA. Our insight is to conceptualize incomplete annotations as noisy data (i.e., low-quality data), with a focus on mitigating their adverse effects. We begin by evaluating the completeness of annotations at the client level using a designed indicator. Subsequently, we enhance the influence of clients with more comprehensive annotations and implement corrections for incomplete ones, thereby ensuring that models are trained on accurate data. Our method's effectiveness is validated through its superior performance on two extensively used medical image segmentation datasets, outperforming existing solutions. The code is available at https://github.com/HUSTxyy/FedIA.", "sections": [{"title": "1 Introduction", "content": "Recent progress in federated learning (FL) [13] has facilitated the collaborative training of unified models across multiple decentralized entities in a privacy-preserving manner [2,6,19,22]. In medical domains, FL has seen extensive application in training segmentation models for distinct lesions and organs [18,8,20]. Nevertheless, an essential limitation in current research is the insufficient consideration of the diversity in annotation completeness among clients.\nThis issue primarily stems from the varying standards of annotation adopted by various clients. As depicted in Fig. 1, certain clients (i.e., client k) provide complete annotations for comprehensive diagnosis and analysis. Conversely, others (i.e., client i and j) may possess incomplete annotations where only partial regions are marked, to minimize labeling costs, which are adequate only for basic image-level assessments (e.g., rapid screening).\nGiven this heterogeneity in annotation completeness, training a segmentation model via FL poses significant challenges. The inclusion of clients with incomplete annotations creates a situation where these clients are considered to be of lower quality since partial positive regions are mislabeled as background. Such imperfect annotations can negatively affect the overall performance of the model due to the memory effect of neural networks [12,11]. To tackle this, in this paper, we focus on the important yet under-explored problem: How to pursue better FL under heterogeneity in annotation completeness?\nWithin the realm of FL, there has been some work focusing on data heterogeneity [4,5,7], but the heterogeneity in annotation completeness has been often overlooked. As for strategies to diminish the negative impact of clients with low-quality labels, these solutions predominantly focus on the classification task [23,21], which is suboptimal when applied to the segmentation task. Although FedA3I [20] has recently addressed the heterogeneity in annotation quality specific to segmentation, its underlying assumption, where mislabeled pixels mainly distribute near objects' boundaries, renders it ineffective against the challenge of incomplete annotations. Consequently, developing an effective approach to address this critical issue remains an area in need of further exploration and insight.\nIn this study, we tackle the pressing problem of heterogeneity in annotation completeness by introducing FedIA, a FL solution that is cognizant of and adaptively corrects for client annotation completeness. Our foundational insight is to perceive incomplete annotations as akin to noisy data. We commence by developing an early model robust against the noise associated with incomplete annotations, which then serves as a basis for evaluating each client's level of annotation completeness. Subsequently, our aggregation process prioritizes clients with higher annotation completeness, and clients undertake annotation corrections before local model updating supervised by incomplete annotations. Our"}, {"title": "2 Methodology", "content": "This paper focus on a a single-class multi-lesion\u00b9 segmentation problem in a federated scenario. Given K clients, each client possesses its private dataset Dk =\n{(xi \u2208 X \u2286 RH\u00d7W\u00d7C, \u1ef9\u00bf \u2208 Y = {0,1}H\u00d7W)} 1, where n\u00eb is the size of Dk and\n(xi, \u1ef9i) represents the image-annotation pair characterized by dimensions: height H, width W, and channel C. Contrary to an ideal situation, the annotations in our case are considered imperfect due to incompleteness, with not every lesion being marked. The completeness ratio \u03b1k = \u03a3ciri/ci, indicating the proportion of marked lesions to the total actual lesions within Dk, which remains identical among samples in Dk but differs across clients.\nOur objective is to devise a robust algorithm capable of diminishing the negative effects of incomplete annotations on the global model's accuracy. The cornerstone of our approach involves deriving an initial model that is minimally affected by noise through the utilization of extensive noisy data, followed by assessing each client's annotation completeness ratio based on this initial model. The strategy prioritizes learning from clients with higher completeness rates (i.e., higher-quality data), thereby enhancing the model's performance. Furthermore, a mechanism is incorporated to correct incomplete annotations at a certain stage of the learning process, using a specially designed metric based on Intersection over Union (IoU).\nAssessing the level of annotation completeness across clients is imperative, as it directly influences the tailored handling of each client's data. To accomplish this, obtaining a model that is unaffected by imperfect annotations becomes essential. Our approach begins by interpreting incomplete annotations as noisy labels, with unmarked lesions contributing noise by altering pixel-level labels from 1 to 0. Drawing inspiration from the early learning phenomenon in noisy label learning [11,10,12], which posits that neural networks initially adapt to clean labels in the early stages before progressively accommodating noisy la-bels, we can place confidence in the training process despite the prevalence of\n\u00b9 This means an image can contain multiple lesions, each forming a connected region."}, {"title": "2.3 Annotation Completeness-Aware Aggregation", "content": "Quantity-based aggregation (i.e., FedAvg) is susceptible to noise caused by in-complete annotations, especially when such annotations are numerous [20]. To mitigate this, clients with higher annotation quality should dominate FL more. Therefore, we calculate a completeness-aware aggregation weight wk at round t for each client k, defined as\nwk =\nexp (lk)\nK\n\u03a3k=1 exp (lk)\n(4)\nwhere lk denotes the average loss of client k at round t calculated by\nlk =\n\u03a3(xi,yi)EDk ldc (f (xi; Ot,k), Yi)\nnk\n(5)\nGenerally, the observed loss is lower when annotation completeness is elevated. Consequently, the server prioritizes clients exhibiting lower losses, effectively reducing the negative effects of imprecise estimation of \u03b1k on the weighting process, potentially arising from inappropriate selection of T."}, {"title": "2.4 Client-wise Adaptive Correction", "content": "The volume of data significantly influences the performance of neural networks, and datasets characterized by low annotation completeness represent valuable re-sources that should not be overlooked. Hence, rectifying incomplete annotations to acquire cleaner data for further training of the model is essential. Given that different clients pose datasets with varying levels of annotation completeness, the onset of noise impact and their robustness to noise vary accordingly.\nTo capture this information, in the early learning phase (i.e., 1 \u2264 t \u2264 T), we compute IoU values every round for each client k and fit it with the first-order polynomial function:\nIoUk(t) = lk . t + bk,\n(6)\nwhere lk and bk are two parameters of the polynomial function. After early learning and in sync with the completeness-aware aggregation, we monitor the change of IoUk every round. Any client satisfying the following formula will correct its annotations in the next round:\nIoUk(t) - IoUk(t) > \u039b,\n(7)\nwhere IoUk(t) denotes the actual IoU value of client k at round t. \u039b is an adjustable hyperparameter, set to 0.03 by default. In addition, the client only corrects annotations for which its model output predicted probability has con-fidence above a certain threshold setting of 0.8. It is worth noting that we only correct the pixels with a value of 0 because only false negative lesions and no false positive lesions are presented in this setting."}, {"title": "3 Experiments", "content": "Two public medical image segmentation datasets are included:\n1.  Two real-world multiple sclerosis datasets, focusing on the segmentation of white matter lesions (WML) in 3D magnetic resonance (MR) brain images, denoted as MS, including MSSEG-1 [1] and PubMRI [9]. In the task, we only use the FLAIR modality, in which the lesions are relatively clear.\n2.  The widely-used COVID dataset, aiming at segmentation and quantification of lung lesions caused by SARS-CoV-2 infection from computed tomography (CT) images, denoted as LUNG. [16]\nEach dataset is divided into training and test sets by a ratio of 8:2, whose training set is then randomly split into four clients. For computational efficiency, all 3D samples are converted into 2D slices and resized to 256\u00d7256 pixels.\nTo verify the robustness to different degrees of incompleteness of our method, several settings are used for evaluation. Specifically, for MS, the annotation completeness rate of the k-th client is set as 20% \u00d7 k-10% \u00d7 m + 40%. And we conduct four sets of experiments, i.e., m = 0, 1, 2, 3. For LUNG, three different settings are used, and the completeness rates are formulated as 10% \u00d7k-30% \u00d7 m+70%, where m = 0, 1, 2.\nWhen doctors or other professionals label multi-lesion data, they tend to label one lesion at the 3D volume level before annotating another. Therefore, to simulate real noise and generate incomplete annotation \u00f5j, lesions are randomly removed at the 3D level. This process allows us to mimic real-world conditions more accurately. Specifically, we first set the annotation completeness of each client as \u03b1k, which is unknown during training. Then, we calculate the number of lesion-connected componentsch in each 3D sample vj and randomly choose a lesion regions, where c = c\u03b1k. Only the chosen lesion regions are kept as well-annotated while others are set as background (i.e., incomplete/missing annotation).\nIn this work, U-Net [15] is adopted as the foundational model architecture for FL. The FL training process is designed to include a total of 300 communication rounds, with each local training phase consisting of a single local epoch. During local training, the model undergoes optimization via the Adam optimizer with momentum terms set to (0.9, 0.99), a batch size of 4, and an initial learning rate of 1e-4. To accommodate the early learning strategy, the initial learning round, T, is set as 10 for MS and 40 for LUNG."}, {"title": "3.2 Comparison with State-of-the-art Methods", "content": "In our analysis, we benchmark FedIA against recent leading methods tailored to address label noise in both classification and segmentation tasks, including ELR"}, {"title": "3.3 Ablation Study", "content": "We conduct an ablation study by separately remov-ing the Annotation Completeness-Aware Aggregation (ACAG) and the Client-wise Adaptive Correction (CAC) components from FedIA as summarized in Table 2. We observe that FedAvg can benefit from both components, particularly under the lowest annotation completeness settings. This phenomenon demon-strates the effectiveness of our designs against annotation noise. The best per-formance is typically achieved when both components are incorporated.\nIt is worth noting that the early learning phase, denoted by T, is set differently for the two tasks as LUNG pre-senting a more complex learning challenge compared to MS, essentially requir-ing a longer early learning period. This variation prompts a relevant question regarding the optimal number of training rounds necessary for effective early training. To address this, we perform ablation studies on LUNG under various T settings: 10, 20, 30, and 40 as summarized in Table 3. The results indicate that our method exhibits considerable robustness to changes in T. Notably, Fe-dIA consistently outperforms the baseline FedAvg across all tested T selections, demonstrating its robustness and superior performance irrespective of the early learning duration. More ablation studies are available in the supplementary ma-terial for reference."}, {"title": "4 Conclusion", "content": "In this study, we tackle a significant yet overlooked challenge in federated medi-cal image segmentation: how to enhance FL against heterogeneity in annotation completeness. We approach incomplete annotations as akin to noisy data, em-ploying strategies to mitigate their negative impacts denoted as FedIA. FedIA"}]}