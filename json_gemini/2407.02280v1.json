{"title": "FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness", "authors": ["Yangyang Xiang", "Nannan Wu", "Li Yu", "Xin Yang", "Kwang-Ting Cheng", "Zengqiang Yan"], "abstract": "Federated learning has emerged as a compelling paradigm for medical image segmentation, particularly in light of increasing privacy concerns. However, most of the existing research relies on relatively stringent assumptions regarding the uniformity and completeness of annotations across clients. Contrary to this, this paper highlights a prevalent challenge in medical practice: incomplete annotations. Such annotations can introduce incorrectly labeled pixels, potentially undermining the performance of neural networks in supervised learning. To tackle this issue, we introduce a novel solution, named FedIA. Our insight is to conceptualize incomplete annotations as noisy data (i.e., low-quality data), with a focus on mitigating their adverse effects. We begin by evaluating the completeness of annotations at the client level using a designed indicator. Subsequently, we enhance the influence of clients with more comprehensive annotations and implement corrections for incomplete ones, thereby ensuring that models are trained on accurate data. Our method's effectiveness is validated through its superior performance on two extensively used medical image segmentation datasets, outperforming existing solutions. The code is available at https://github.com/HUSTxyy/FedIA.", "sections": [{"title": "1 Introduction", "content": "Recent progress in federated learning (FL) [13] has facilitated the collaborative training of unified models across multiple decentralized entities in a privacy-preserving manner [2,6,19,22]. In medical domains, FL has seen extensive application in training segmentation models for distinct lesions and organs [18,8,20]. Nevertheless, an essential limitation in current research is the insufficient consideration of the diversity in annotation completeness among clients."}, {"title": "2 Methodology", "content": "This paper focus on a a single-class multi-lesion\u00b9 segmentation problem in a federated scenario. Given K clients, each client possesses its private dataset Dk = {(xi \u2208 X \u2286 RH\u00d7W\u00d7C, \u1ef9\u00bf \u2208 Y = {0,1}H\u00d7W)} 1, where n\u00eb is the size of Dk and (xi, \u1ef9i) represents the image-annotation pair characterized by dimensions: height H, width W, and channel C. Contrary to an ideal situation, the annotations in our case are considered imperfect due to incompleteness, with not every lesion being marked. The completeness ratio \u03b1k = \u03a3cri/ci, indicating the proportion of marked lesions to the total actual lesions within Dk, which remains identical among samples in Dk but differs across clients.\nOur objective is to devise a robust algorithm capable of diminishing the negative effects of incomplete annotations on the global model's accuracy. The cornerstone of our approach involves deriving an initial model that is minimally affected by noise through the utilization of extensive noisy data, followed by assessing each client's annotation completeness ratio based on this initial model. The strategy prioritizes learning from clients with higher completeness rates (i.e., higher-quality data), thereby enhancing the model's performance. Furthermore, a mechanism is incorporated to correct incomplete annotations at a certain stage of the learning process, using a specially designed metric based on Intersection over Union (IoU). The overview of FedIA is illustrated in Fig. 2."}, {"title": "2.2 Annotation Completeness Estimation", "content": "Assessing the level of annotation completeness across clients is imperative, as it directly influences the tailored handling of each client's data. To accomplish this, obtaining a model that is unaffected by imperfect annotations becomes essential. Our approach begins by interpreting incomplete annotations as noisy labels, with unmarked lesions contributing noise by altering pixel-level labels from 1 to 0. Drawing inspiration from the early learning phenomenon in noisy label learning [11,10,12], which posits that neural networks initially adapt to clean labels in the early stages before progressively accommodating noisy labels, we can place confidence in the training process despite the prevalence of"}, {"title": "2.3 Annotation Completeness-Aware Aggregation", "content": "Quantity-based aggregation (i.e., FedAvg) is susceptible to noise caused by incomplete annotations, especially when such annotations are numerous [20]. To mitigate this, clients with higher annotation quality should dominate FL more. Therefore, we calculate a completeness-aware aggregation weight w at round t for each client k, defined as\nwkt =\n \\frac{\\exp \\left(\\frac{l^{t}_{k}}{\\tau}\\right)}{\\sum_{j=1}^{K} \\exp \\left(\\frac{l^{t}_{j}}{\\tau}\\right)} \n(4)\nwhere ltk denotes the average loss of client k at round t calculated by\nlkt = \\frac{\\sum_{(x_{i},y_{i}) \\in D_{k}} l_{dc} (f (x_{i}; \\Theta_{t,k}), y_{i})}{n_{k}} \n(5)\nGenerally, the observed loss is lower when annotation completeness is elevated. Consequently, the server prioritizes clients exhibiting lower losses, effectively reducing the negative effects of imprecise estimation of \u03b1k on the weighting process, potentially arising from inappropriate selection of T."}, {"title": "2.4 Client-wise Adaptive Correction", "content": "The volume of data significantly influences the performance of neural networks, and datasets characterized by low annotation completeness represent valuable resources that should not be overlooked. Hence, rectifying incomplete annotations to acquire cleaner data for further training of the model is essential. Given that different clients pose datasets with varying levels of annotation completeness, the onset of noise impact and their robustness to noise vary accordingly.\nTo capture this information, in the early learning phase (i.e., 1 \u2264 t \u2264 T), we compute IoUk values every round for each client k and fit it with the first-order polynomial function:\nIoUk(t) = lk. t + bk,\n(6)\nwhere lk and be are two parameters of the polynomial function. After early learning and in sync with the completeness-aware aggregation, we monitor the change of IoUk every round. Any client satisfying the following formula will correct its annotations in the next round:\n\\left|IoU_{k}(t) - IoU_{k}(t)\\right| > \\Delta,\n(7)\nwhere IoUk(t) denotes the actual IoU value of client k at round t. \u0394 is an adjustable hyperparameter, set to 0.03 by default. In addition, the client only corrects annotations for which its model output predicted probability has confidence above a certain threshold setting of 0.8. It is worth noting that we only correct the pixels with a value of 0 because only false negative lesions and no false positive lesions are presented in this setting."}, {"title": "3 Experiments", "content": "Two public medical image segmentation datasets are included:\n1.  Two real-world multiple sclerosis datasets, focusing on the segmentation of white matter lesions (WML) in 3D magnetic resonance (MR) brain images, denoted as MS, including MSSEG-1 [1] and PubMRI [9]. In the task, we only use the FLAIR modality, in which the lesions are relatively clear.\n2.  The widely-used COVID dataset, aiming at segmentation and quantification of lung lesions caused by SARS-CoV-2 infection from computed tomography (CT) images, denoted as LUNG. [16]\nEach dataset is divided into training and test sets by a ratio of 8:2, whose training set is then randomly split into four clients. For computational efficiency, all 3D samples are converted into 2D slices and resized to 256\u00d7256 pixels.\nTo verify the robustness to different degrees of incompleteness of our method, several settings are used for evaluation. Specifically, for MS, the annotation completeness rate of the k-th client is set as 20% \u00d7 k-10% \u00d7 m + 40%. And we conduct four sets of experiments, i.e., m = 0, 1, 2, 3. For LUNG, three different settings are used, and the completeness rates are formulated as 10% \u00d7k-30% \u00d7 m+70%, where m = 0, 1, 2.\nWhen doctors or other professionals label multi-lesion data, they tend to label one lesion at the 3D volume level before annotating another. Therefore, to simulate real noise and generate incomplete annotation \u00f5j, lesions are randomly removed at the 3D level. This process allows us to mimic real-world conditions more accurately. Specifically, we first set the annotation completeness of each client as ak, which is unknown during training. Then, we calculate the number of lesion-connected componentsch in each 3D sample vj and randomly choose a lesion regions, where c = cak. Only the chosen lesion regions are kept as well-annotated while others are set as background (i.e., incomplete/missing annotation).\nIn this work, U-Net [15] is adopted as the foundational model architecture for FL. The FL training process is designed to include a total of 300 communication rounds, with each local training phase consisting of a single local epoch. During local training, the model undergoes optimization via the Adam optimizer with momentum terms set to (0.9, 0.99), a batch size of 4, and an initial learning rate of 1e-4. To accommodate the early learning strategy, the initial learning round, T, is set as 10 for MS and 40 for LUNG."}, {"title": "3.2 Comparison with State-of-the-art Methods", "content": "In our analysis, we benchmark FedIA against recent leading methods tailored to address label noise in both classification and segmentation tasks, including ELR"}, {"title": "3.3 Ablation Study", "content": "We conduct an ablation study by separately removing the Annotation Completeness-Aware Aggregation (ACAG) and the Client-wise Adaptive Correction (CAC) components from FedIA as summarized in Table 2. We observe that FedAvg can benefit from both components, particularly under the lowest annotation completeness settings. This phenomenon demonstrates the effectiveness of our designs against annotation noise. The best performance is typically achieved when both components are incorporated.\nIt is worth noting that the early learning phase, denoted by T, is set differently for the two tasks as LUNG presenting a more complex learning challenge compared to MS, essentially requiring a longer early learning period. This variation prompts a relevant question regarding the optimal number of training rounds necessary for effective early training. To address this, we perform ablation studies on LUNG under various T settings: 10, 20, 30, and 40 as summarized in Table 3. The results indicate that our method exhibits considerable robustness to changes in T. Notably, FedIA consistently outperforms the baseline FedAvg across all tested T selections, demonstrating its robustness and superior performance irrespective of the early learning duration."}, {"title": "4 Conclusion", "content": "In this study, we tackle a significant yet overlooked challenge in federated medical image segmentation: how to enhance FL against heterogeneity in annotation completeness. We approach incomplete annotations as akin to noisy data, employing strategies to mitigate their negative impacts denoted as FedIA. FedIA involves initially assessing the level of annotation completeness at the client level through designed indicators. Then, it prioritizes clients with greater annotation completeness and undertakes corrective measures for those with incomplete ones, aiming to ensure that the training process is mainly based on accurate knowledge. After rigorously evaluated through a line of experiments on two extensively utilized medical image segmentation datasets, experimental results affirm the effectiveness of FedIA, showcasing its advantage over current leading approaches. We believe that the issue formulated and the proposed solution will pave the way for more practical FL applications in complex medical scenarios."}]}