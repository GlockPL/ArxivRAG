{"title": "Cross-Domain Transfer Learning using Attention Latent Features for Multi-Agent Trajectory Prediction", "authors": ["Jia Quan Loh", "Xuewen Luo", "Fan Ding", "Hwa Hui Tew", "Junn Yong Loo", "Ze Yang Ding", "Susilawati Susilawati", "Chee Pin Tan"], "abstract": "With the advancements of sensor hardware, traffic infrastructure and deep learning architectures, trajectory prediction of vehicles has established a solid foundation in intelligent transportation systems. However, existing solutions are often tailored to specific traffic networks at particular time periods. Consequently, deep learning models trained on one network may struggle to generalize effectively to unseen networks. To address this, we proposed a novel spatial-temporal trajectory prediction framework that performs cross-domain adaption on the attention representation of a Transformer-based model. A graph convolutional network is also integrated to construct dynamic graph feature embeddings that accurately model the complex spatial-temporal interactions between the multi-agent vehicles across multiple traffic domains. The proposed framework is validated on two case studies involving the cross-city and cross-period settings. Experimental results show that our proposed framework achieves superior trajectory prediction and domain adaptation performances over the state-of-the-art models.", "sections": [{"title": "I. INTRODUCTION", "content": "In the realm of intelligent transportation, the landscape of vehicle trajectory prediction has evolved significantly and gained immense traction in intelligent transportation systems, spanning applications from vehicle design to traffic forecasting and traffic control [1]. This transformation is driven by advancements in vehicle sensor hardware and traffic infrastructure. Consequently, this allows the acquisition of high fidelity sensory and positional data of multiple vehicles, which are crucial for data-driven modelling of the complex spatial-temporal interactions between vehicles in a multi-agent traffic network [2]. In particular, an accurate forecast of the future vehicular trajectories allows a ego vehicle to plan its optimal navigational route within the network and alleviate traffic issues such as congestion and accidents.\nRecent advances in the deep learning paradigm have tremendously enhanced vehicular trajectory prediction in many traffic networks such as arterial roads, boulevards, and interstate highways. A noteworthy example is the graph-based interaction-aware trajectory prediction (GRIP) model [3] which incorporates graph convolutional neural network (GCN) and a recurrent encoder-decoder architecture. The GRIP model exploited graph representation to model complex spatial inter-agent interactions and the sequential encoding modules in recurrent neural network (RNN) to model temporal correlation across the vehicle trajectories. Apart from that, attention mechanism of the Transformer networks [4], [5] has been harnessed to effectively model time-series data. The attention mechanism involves a global treatment of the time-evolving trajectory as a unified sequence, thus mitigating the deficiency of RNNs in retaining long-term temporal dependencies in long vehicle trajectory [6], [7].\nNevertheless, deep trajectory prediction models are often tailored to the available training data, which could be collected on a particular traffic configuration such as time period or fixed location. This adherence to a certain traffic domain inhibits the model from effectively generalizing its prediction to unseen traffic networks [8]. Current domain adaptation approaches for trajectory prediction predominantly rely on semi-supervised techniques [9]. These approaches serve as effective means to transfer existing knowledge within vision models pertaining to road geometry and topology, and in kinematic models for understanding driver maneuvering behaviors. For example, Xu et al. [10] have tackled the domain shift challenge by employing domain adaptation techniques such as similarity losses between source and target domains for distribution alignment in the context of pedestrian trajectory prediction. Nevertheless, a shift in geographical location and distinct traffic conditions could make these models ineffective when applied to comprehensive system-wide network. Moreover, traffic dynamics evolve over time and thus the validity of a trained model would be limited to the given temporal window.\nMotivated by these difficulties, in this paper, we propose a novel sequence-to-sequence graph Transformer-based model (namely Graph Embedded Transformer) to learn the spatial-temporal features of multi-agent trajectory data. Our proposed framework utilizes the embedding capabilities of GCN to help model the spatial features of multi-agent trajectories, while the Transformer performs temporal modelling of the trajectory sequence. To address the issue of co-variate domain shifting due to the differences in traffic distributions in different locations or periods, we introduce a domain adaptation training strategy on top of the spatial-infused attention embedding of the Transformer encoder to adapt the model's attention across multiple traffic domains.\nTo the best of our knowledge, this is the first work that investigates the feasibility of a domain-adaptable graph Transformer-based framework on generalizing trajectory pre-"}, {"title": "II. RELATED WORK", "content": "In earlier studies, the utilization of Recurrent Neural Networks (RNNs) in trajectory prediction architecture was prominent, primarily owing to their adeptness in capturing temporal features and modeling sequential data [12], [13]. Subsequently, Long Short-Term Memory (LSTM) [14] was introduced, and it is proved effective in learning long-term temporal dependencies in traditional RNNs [12]. The LSTM proved particularly suitable for capturing driving experiences characterized by extended temporal delays within the sequence, as showcased by the works [15], [16] which incorporated LSTM or LSTM encoder-decoder models into their vehicle intention prediction frameworks. Furthermore, the Environment-Attention architecture [17] adopted an LSTM encoder-decoder approach to directly forecast the future positions of vehicle trajectories. It is worth noting, however, that LSTM's prediction speed is hindered by the need for individual analysis of each time frame in the trajectory sequences of surrounding vehicles [18], which lengthens computation speed and increases network size as the sequence length increases. To mitigate computational demands, an alternative to LSTM, namely the Gated Recurrent Unit (GRU), was introduced by Li et al. [3] into their existing Graph-based Interaction-aware Trajectory Prediction (GRIP) model. GRU offers the advantage of having lesser model parameters while retaining/without compromising model performance.\nIn recent works, there has been a notable shift towards the adoption of Transformer-based or attention-based networks, which have demonstrated their proficiency in temporal analysis of extended input sequences through their capacity to mimic cognitive attention processes [4], [5], [7], [19]. These networks have emerged as a deep learning solution for effective modeling and extraction of temporal features from sequential data. To achieve this, attention mechanisms have been incorporated into the feature space encoding to prioritize essential node features within specific time frames. For example, [4], [7] have also harnessed the multi-headed attention mechanism during the encoding of trajectory histories in their Transformer networks. This approach enhances the network's stability during training while enabling accurate long-term predictions with reduced inference time. This makes Transformer networks a compelling choice for real-time applications, including autonomous driving. In conjunction with temporal sequence processing, the incorporation of spatial interaction modeling stands as a pivotal element within trajectory prediction models. In the study conducted by Mo et al. [20], Convolutional Neural Networks (CNNs) were incorporated into the framework for single-agent vehicular trajectory prediction. This integration aimed to imbue interaction awareness within the LSTM network, yielding favorable outcomes in trajectory prediction. Notably, the proposed approach demonstrated efficacy, particularly in scenarios characterized by prominent lane-changing dynamics within the traffic environment.\nRecently, Graph Neural Networks (GNNs) have gained popularity as a compelling alternative for modeling spatial interactions among vehicles. Notably, two prevalent models, namely Graph Convolutional Networks (GCNs) [21] and Graph Attention Networks (GANs) [22], have been adopted for deep learning on graph structures. In particular, Li et al. [3] and Sheng [23] have incorporated GCNs into their architectures to extract spatial features in conjunction with various forms of Recurrent Neural Networks (RNNs) to capture temporal features. Additionally, Zhang et al. [24] introduced Graph Attention Transformer (GAT) to incorporate importance and attention into graph edges to effectively model spatial features. Notably, Zhang et al. [24] extended their graph-based approach by passing satellite maps relative to the ego vehicle's location through CNNs into their architecture. This augmentation facilitates obstacle extraction, with the extracted features from the CNN being subsequently encoded into the graph structures of the GAT block. Consequently, their architecture proficiently captures inter-vehicle spatial and temporal interactions, as well as interactions between vehicles and road obstacles during training.\nTrajectory data originating from diverse geographic locations belongs to distinct domains [10]. A model trained on a source domain, when applied to a different target domain,"}, {"title": "III. PROBLEM FORMULATION", "content": "We define the trajectory prediction problem as a forecasting task of the future positions of all vehicles within a given traffic scene. Our prediction horizon spans a 5-second interval, drawing upon trajectory histories encompassing up to 3 seconds. The models are fed with input data denoted as X, which represents the trajectory histories of all vehicles within the scene over a time span of $t_h$ time steps, as follows:\n$X = [p^1, p^2, ..., p^{t_h}],$ (1)\nwhere\n$p^t = [(x^t_0, y^t_0), (x^t_1, y^t_1), ..., (x^t_n, y^t_n)]$ (2)\nare the coordinates of all observed vehicles for a traffic scene at time t, and n is the number of observed vehicles. The output Y of the models are the predicted positions of all the observed objects from time frames $t_h + 1$ to $t_h + t_f$ in the future, as follows:\n$Y = [p^{t_h+1}, p^{t_h+2},...,p^{t_h+t_f}].$ (3)\nThe objective function for predicting trajectories is defined using the Mean Squared Error (MSE) loss, as depicted below\nMSE(Y, \\hat{Y}) = \\frac{1}{N}\\sum_{i=1}^N (Y_i - \\hat{Y_i})^2,$ (4)\nwhere N denotes the batch size (number of trajectories in a batch) used for training."}, {"title": "IV. PROPOSED METHODS", "content": "This section introduces a domain adaptation approach that leverages the latent space representations of the Graph Embedded Transformer. This proposed approach aims to facilitate the transfer of trajectory prediction knowledge from a source domain, characterized by abundant data, to a target domain with limited data availability. A visual representation of the proposed model is depicted in Fig 1.\nGiven the observation of n vehicles over a time span of $t_h$ seconds, the information is structured into a 3D array with dimensions ($t_h \\times n \\times f$) with f = 2 number of features representing the x and y coordinates of each vehicle. Subsequently, the data is subjected to a normalization process, constraining its range to [-1,1].\nIn this subsection, we provide a concise overview of the architectures which serves as the benchmark models as well as the baseline of our proposed framework.\nWe employ an LSTM auto-encoder network wherein each time step inputs data into the encoder LSTM. The hidden features extracted by the encoder block, alongside the vehicle coordinates from the previous time step, are subsequently fed into the decoder LSTM to forecast the positional coordinates for the current time step. This decoding process iterates until the model provides predictions for a specified future time horizon denoted as $t_f$.\nTo introduce interaction awareness, we incorporate CNNs as utilized by [20] to form the CNN-LSTM network. We also implement the GRIP architecture introduced by [3] by incorporating GCNs into the LSTM network.\nWe employ a Sequence-to-Sequence Transformer model, as detailed in [11], which incorporates multi-headed self-attention within its encoder block and decoder block. The input trajectory, spanning $t_h$ time steps, is concatenated to serve as the source input. During the training phase, the target input consists of the right-shifted output trajectory, which is preceded by the final time frame from the input trajectory. In the inference phase, the target input is iteratively derived from the predicted trajectory at each output time frame until all the $t_f$ time frames have been processed. In view of the promising performance of Graph Neural Networks in trajectory prediction [3], [4], our proposed model introduces a Graph Convolution Block to capture spatial dependencies of the input data before feeding them into the Transformer. This architecture design yields the proposed model termed Graph Embedded Transformer, which serve as our baseline for incorporating domain adaptation.\nAs highlighted in [8]-[10], the challenge of domain shift remains a persistent concern in cross-domain trajectory prediction. This issue can render trajectory prediction models ineffective when applied to different geographical locations or varying traffic scenarios. Iterative model training across diverse locations is impractical due to its substantial computational demands. In light of these considerations, our approach seeks to adapt the models to both the source and target domains. We achieve this by extracting the latent space representation of each trajectory and directing it through an MLP discriminatory network, responsible for classifying the latent features into their respective domains. This transfer strategy facilitates the adjustment of the source domain's latent space to align with that of the target domain. Consequently, our primary objective is to minimize the dissimilarity between the latent features of the source and target domains, a goal achieved through the optimization of a binary cross-entropy (BCE) loss as follows:\nL(a_i, \\hat{a_i}) = -\\frac{1}{N}\\sum_{i=1}^N [a_i log(\\hat{a_i}) + (1 - a_i) log(1 - \\hat{a_i})]. (5)\nwhere $a_i \\in {0, 1}$ is the corresponding domain label predicted by the domain classifier, which indicates if the latent attention of the Transformer's encoder belongs to the source or target domain.\nMotivated by the domain adversarial training (DAT) strategy [28], the MSE and BCE losses are backpropagated to optimize the model parameters of the Transformer encoder module and the domain classifier, respectively. Such an adversarial competition between the Transformer's encoder and the MLP classifier is expected to achieve a Nash equilibrium that minimizes the statistical discrepancy between the latent distributions and thus generalizes the learned latent space to both the source and target domains [29]."}, {"title": "V. EXPERIMENTS", "content": "The datasets are evaluated on two trajectory prediction datasets: NGSIM-180 and the NGSIM-US101 dataset. Both datasets were captured at 10 Hz over 45 minutes and segmented into 15 minutes of mild, moderate and congested traffic conditions. These two datasets consist of trajectories of vehicles on real freeway traffic. Each trajectory is segmented into 8 second intervals, in which the first 3 seconds are used as the trajectory history and the remaining 5 seconds are the prediction ground truth. The data is down sampled for each segment by a factor of 2, i.e. 5 Hz as in [3]. This provides 40 frames for each 8 second trajectory, such that $t_h$ spans 15 frames in 3 seconds and $t_f$ spans 25 frames in 5 seconds.\nThe proposed methods are implemented using Python and the Pytorch deep learning library. The settings of model and training hyperparameters used are reported below.\nIn this paper, we process a traffic scene within 30 meters and located in the same lane or at the adjacent lanes of an ego vehicle. All vehicles within this region will be observed and predicted into the future.\nThe Graph Embedded Transformer uses four attention heads with a MLP of size of 2048. Two layers of Transformer encoders and decoders are used. The input embedding model is replaced with a Graph Convolution Network to aid in the spatial modelling of our proposed Graph Embedded Transformer.\nA simple MLP is used for the discriminatory network to classify the latent space of the Graph Embedded Transformer into their respective domains.\nThe model training comprises a regression task for the trajectory prediction and a classification task for the domain classification. The overall regression loss is the MSE and the domain classification loss is the BCE. The models are concurrently trained to minimize these losses."}, {"title": "VI. RESULTS", "content": "Table I and Table II show the accuracy (in terms of RMSE) of the multi-agent trajectory predictions for the cross-city case study in both the source and target domain, respectively. Table III and Table IV show the accuracy of the multi-agent trajectory predictions for the cross-period case study in both source and target domain, respectively. The results show that integration of the cross-domain adaptation strategy on top of our proposed Graph Embedded Transformer model architecture achieves overall improvements on the prediction accuracy (in RMSEs) over the benchmark models, for both the cross-city and cross-period transfer learning scenarios. In particular, our proposed model with cross-domain adaptation strategy showed increasing improvements in percentages over the benchmarks, as the prediction horizon lengthens. This is due to capability of the self and cross attention mechanism of the Transformer encoder-decoder modules in modelling long dependencies, which play an important role when more input features and temporal patterns are accessible to the decoder module as prediction horizon grows.\nMore importantly, the results show that incorporating GCN as the input embedding model of our proposed Graph Embedded Transformer achieved a better prediction accuracy compared to the benchmark models without graph neural network. This is attributed to the competency of the GCN in learning non-Euclidean topological information [3]. The extracted graph feature embeddings thus enhanced the capability of the proposed model in modelling complex spatial interactions between vehicular agents in a traffic scene. Notably, our GCN-enabled model outperforms CNN-LSTM which lacks the ability to capture a global graph-level representation of the system-wide traffic network.\nIn the cross-city case study, our proposed model outperformed the benchmark models after incorporating the domain adaptation strategy. We attribute this gain in performance to the domain adaptation strategy in learning attention feature representation that is adaptable to traffic domains with statistical discrepancy, especially in the cross-city scenario where the 180 (East-West Freeway) and US101 (North-South Freeway) exhibit both distinct spatial and temporal characteristics. With the the integration of domain adversarial training, our proposed model and domain adaptation strategy showed a RMSE improvement of 20.81% and 21.58% over the Graph Embedded Transformer baseline on the source and target domains, respectively. The results thus highlights the necessity of the proposed domain adversarial training in adapting the learning of the attention feature representation in complex multimodal traffic system.\nIn the cross-period case study, however, our proposed model outperforms the benchmark model even without domain adaptation. These initial RMSE improvements in both the time domains are due to the competency of the Transformer model in modelling complex temporal patterns on unimodal traffic system with uniform spatial characteristic, considering that the models are evaluated on a single location, 180 (East-West Freeway). A further integration of domain adversarial training on the baseline allows the attention features to generalize better across time periods, which we observes a further RMSE improvement of 17.94% and 19.64% over the Graph Embedded Transformer baseline on the source and target domains, respectively."}, {"title": "VII. CONCLUSION", "content": "In this study, we introduce a graph-based Transformer network known as the Graph Embedded Transformer with a domain adaptation framework for predicting multi-agent vehicle trajectories of highway traffic scene in encompassing adaptation in different locations and time periods. Agents in the traffic network encompasses vehicles in an urban traffic. Our domain adaptation approach capitalizes on the latent features learning from graph encoding of the GCNs along with self and cross attention features of the Transformer's encoder and decoder modules. Our experimental findings, conducted on the NGSIM-180 and NGSIM-US101 datasets, reveal that the proposed domain adaptation strategy using attention features of the Graph Embedded Transformer significantly improves cross-domain trajectory prediction. Incorporating domain adaptation to our proposed model observes improvement in performances on both source and target domains, over the benchmarks without domain adaptation."}]}