{"title": "ROSMonitoring 2.0: Extending ROS Runtime Verification to Services and Ordered Topics", "authors": ["Maryam Ghaffari Saadat", "Louise A. Dennis", "Angelo Ferrando", "Michael Fisher"], "abstract": "Formal verification of robotic applications presents challenges due to their hybrid nature and dis- tributed architecture. This paper introduces ROSMonitoring 2.0, an extension of ROSMonitoring designed to facilitate the monitoring of both topics and services while considering the order in which messages are published and received. The framework has been enhanced to support these novel fea- tures for ROS1 \u2013 and partially ROS2 environments \u2013 offering improved real-time support, security, scalability, and interoperability. We discuss the modifications made to accommodate these advance- ments and present results obtained from a case study involving the runtime monitoring of specific components of a fire-fighting Uncrewed Aerial Vehicle (UAV).", "sections": [{"title": "Introduction", "content": "The formal verification of robotic applications is a challenging task. Due to their heterogeneous and component-based nature, establishing the correctness of robotic systems can be particularly difficult. Various approaches exist to tackle this problem, ranging from testing methods [8, 21, 9] to static [16, 14] or dynamic [19, 15] formal verification. In this work, we focus on the latter approach to verification, specifically the extension of ROSMonitoring [15], a Runtime Verification (RV) framework developed for monitoring robotic systems deployed in the Robot Operating System (ROS) [2]. ROS is widely used, providing a de facto standard for robotic components. ROS encourages component-based development of robotic systems where individual components run in parallel, may be distributed across several processors, and communicate via messages. We tackle ROSMonitoring because it is a novel, formalism- agnostic, and widely used framework for the runtime monitoring of ROS applications. ROSMonitoring allows the specification of formal properties externally to ROS, without imposing any constraints on the formalism to be used. The properties that can typically be monitored in ROSMonitoring concern mes- sages exchanged between different ROS components, called nodes. Such message communication is achieved through a publish-subscribe mechanism, where some nodes (referred to as publishers) publish messages on a topic and other nodes (referred to as subscribers) subscribe to these topics to listen for the published messages. Through ROSMonitoring, it is possible to specify the communication flow on such topics. For instance, one can determine which messages are allowed in the current state of the system, the correct order amongst them, and other relevant criteria.\nUnfortunately, not all aspects of verifying ROS applications are based solely on message communi- cation. In fact, when developing ROS systems, other communication mechanisms can also be utilised, such as services. Unlike the publish-subscribe mechanism used with topics, services provide a way for nodes in ROS to directly offer functionalities to each other. While topics are typically used to transmit data from sensors, services serve as an interface that enables nodes to offer specific functionalities to others within the ROS system. Unlike topics, services are commonly synchronous, meaning that when a node calls a service, it waits for a response from the receiving node. This is in contrast to topics, where subscription is non-blocking, and the subscriber node is simply notified whenever a new message is published on the topic, without any waiting involved. Services are not supported in ROSMonitoring, restricting the framework's functionality to solely monitoring messages.\nAnother current limitation of ROSMonitoring pertains to the handling of message order. The frame- work orders messages based on the chronological order in which they are received by subscriber nodes. However, this approach only considers the viewpoint of subscribers, which may not always be suitable. In some scenarios, it may be necessary to consider the order of messages based on when they were sent. For instance, if one message was sent before another, the former should be analysed before the latter by the monitor, appearing earlier in the resulting trace of events. Unfortunately, ROSMonitoring does not currently provide a representation of the order in which messages are published and received. Generally, messages on a single topic are received by subscribers in the order they were published. However, if a property needs to monitor several topics, then it is unusual for the messages from more than one topic to be received in the order they were published. Reordering messages according to publication time is necessary if checking conditional actions that respond to specific event patterns.\nIn this paper, we introduce ROSMonitoring 2.0, an extension of ROSMonitoring designed to facili- tate the monitoring of both topics and services while also considering the order in which messages are published and received. The framework has been enhanced to support these novel features for ROS. Some of these features, i.e., service monitoring, have also been ported to ROS2\u00b9 environment as well. We discuss the modifications made to accommodate these advancements and present results obtained from a case study involving the runtime monitoring of specific components of a fire-fighting Uncrewed Aerial Vehicle (UAV)."}, {"title": "Preliminaries", "content": "In this section, we briefly introduce Runtime Verification and the ROSMonitoring framework. We em- phasise the primary distinction between RV and static verification techniques. Additionally, we provide an overview of the ROSMonitoring framework and briefly outline its main features."}, {"title": "Runtime Verification", "content": "Runtime Verification (RV) is a lightweight formal verification technique that checks the behaviour of a system while it is running [23]. Unlike model checking, RV does not suffer from the state space explosion problem typical in static verification methods and is therefore much more scalable [11]. RV is particularly suitable for robotic applications due to resource limitations and system complexity that make full verification at design-time challenging. While static verification techniques focus on abstracting system components, RV checks system behaviour directly. RV addresses the word inclusion problem [5], determining if a given event trace belongs to the set of traces denoted by a formal property (referred to as the property's language). This verification process is polynomial in time relative to the trace length. In contrast, model checking exhaustively verifies if a system satisfies or violates a property by analysing all possible system executions, tackling the language inclusion problem, and is typically PSPACE-complete for non-deterministic finite automata [31]. RV commonly employs runtime monitors, automatically synthesised from formal properties, often expressed using Linear-time Temporal Logic (LTL) [28]. These monitors gather information from system execution traces and conclude whether the system satisfies or violates the property. A monitor returns T if the trace satisfies the property, I if it violates it, and ? if there is insufficient information. Depending on the property's formalism, ? may further split into ? or ? indicating partial satisfaction or partial violation, respectively."}, {"title": "ROSMonitoring", "content": "ROSMonitoring [15] is a framework for performing RV on ROS applications. ROSMonitoring allows the user to add monitors to ROS applications, which intercept the messages exchanged between components, called \"ROS nodes\u201d2, and check whether the relevant messages conform to a given formal property. In the following we describe these three different aspects in more detail."}, {"title": "Instrumentation", "content": "ROSMonitoring starts with a YAML configuration file to guide the instrumentation process required to generate the monitors. Within this file, the user can specify the communication channels, called \"ROS topics\", to be intercepted by each monitor. In particular, the user indicates the name of the topic, the ROS message type expected in that topic, and the type of action that the monitor should perform. After preferences have been configured in config.yaml, the last step is to run the generator script to automatically generate the monitors and instrument the required ROS launch files."}, {"title": "Oracle", "content": "ROSMonitoring decouples the message interception (monitor) and the formal verification aspects (ora- cle) and so is highly customizable. Different formalisms can be used to represent the properties to be verified, including Past MTL, Past STL, and Past LTL (MTL [22], STL [24], and LTL [28] with past-time operators, respectively). Using the formalism of choice, an external entity can be created to handle the trace of events reported by the monitors in ROS (generated through instrumentation). ROSMonitoring requires very few constraints for adding a new oracle. It uses JSON\u00b3 (JavaScript Object Notation) as a data-interchange format for serialising the messages that are observed by the ROS monitor. JSON is commonly used for transmitting data between a server and a web application. In JSON, data is repre- sented as key-value pairs enclosed in curly braces, making it a popular choice for APIs and data storage. An oracle will parse the JSON messages, check whether they satisfy or violate the formal property, and report back to the ROS monitor."}, {"title": "ROS monitor", "content": "The instrumentation process generates monitors to intercept the messages of interest. Each monitor is automatically generated as a ROS node in Python, which is a native language supported in ROS. ROSMonitoring provides two types of monitors: 1) offline monitors which simply log the intercepted events in a specified file to be parsed by the Oracle later to determine whether they satisfy a given set of properties, and 2) online monitors which query the Oracle in real time about whether the intercepted messages satisfy the given properties. While offline monitors only log the observed messages, online monitors could either log messages along with the Oracle verdict updated after each message or filter messages that the Oracle deems have violated the given properties. To clarify the difference, in the case of logging without filtering, if the online monitor finds a violation of the property under analysis, it publishes a warning message containing as much information as possible about the violated property. This warning message can be used by the system to handle the violation and to react appropriately. However, the monitor does not stop the message from propagating further in the system. In contrast, if filtering is enabled, since monitors can be placed between the communication of different nodes, ROSMonitoring monitors enforces the property under analysis by not propagating messages that represent a property violation. This is achieved by directing communication on the monitored topics to pass through the monitors."}, {"title": "Motivating example", "content": "In this section, we explain the rationale behind extending the ROSMonitoring framework. We use, as an example, a Battery Supervisor system 4 designed for a UAV (Uncrewed Aerial Vehicle) with three essential components depicted in Figure 2: the Battery, the Battery Supervisor, and the LED Panel. The Battery periodically reports the remaining battery percentage. The Battery Supervisor is responsible for checking the battery level and reporting its status. It subscribes to the battery percentage updates and analyses them. If the battery percentage is above 40%, it signals a \u2018healthy' status. If it is between 30% and 40%, it flags a 'warning' status. And if it falls below 30%, it indicates a 'critical' status. The LED Panel reflects the battery status through coloured LED lights. The Battery Supervisor is connected to the LED Panel and whenever it detects a change in the battery status, it sends a signal to the LED Panel to adjust the lights accordingly. For instance, if the battery is in a critical state, the red light might flash to indicate urgency5.\nIn this example, we are interested in ensuring that the messages exchanged between different com- ponents correspond correctly. For instance, that every status update provided by the Battery Supervisor accurately reflects the current battery percentage received from the Battery. However, while messages published on a single topic generally arrive at the subscribers according to their publication order, mes- sages on different topics can arrive out of order. As a result, a battery status message could be observed before its corresponding battery percentage. Therefore, we need additional mechanisms to account for this before sending the messages to the Oracle for verification. This motivates our extension to reorder the messages according to their publication time.\nBeyond message correspondence, we are also interested in verifying the interaction between the Battery Supervisor and the LED Panel service. We would like to confirm that every time the LED lights are adjusted based on the battery status, it is triggered by a legitimate status update. Conversely, we would like to check that every change in battery status is promptly followed by a request to adjust the LED lights, maintaining synchronisation between the visual feedback and the actual battery condition. However, services are not supported by the ROSMonitoring framework. This motivates our extension to support services. Since some of the properties we are interested in monitoring include both topics and services, we have also developed support for reordering service requests and responses according to publication time as well."}, {"title": "ROSMonitoring 2.0", "content": "ROSMonitoring 2.0 is fully available for ROS1, while only partially available for ROS2 (service moni- toring has been added but not message reordering). In this section, we present two novel aspects of ROS- Monitoring 2.0. Firstly, in Section 4.1, we detail the mechanism enabling monitoring of ROS services. Secondly, in Section 4.2, we introduce an algorithm for reordering messages based on their publication time, demonstrating its correctness under the assumption that messages on each topic arrive sequentially. Notably, such reordering mechanism is extended to support services in addition to topics."}, {"title": "Service extension", "content": "While ROS topics excel in broadcasting data streams or events asynchronously to multiple nodes, ROS services are designed for synchronous, point-to-point communication to request specific actions or ser- vices from other nodes in the system. Consequently, when monitoring services, our monitor node must directly intervene in the communication between the server and client. The monitor node then assumes the role of a server for the client, and conversely acts as a client for the server. The sequence diagram in Figure 3 illustrates the service verification process in ROSMonitoring 2.0 where message filtering is en- abled (which subsumes the non-filtering scenario). The scenario begins with the Client sending a service request callService(req, res) to the Monitor. Subsequently, the Monitor forwards the request to the Ora- cle for verification via a callback mechanism specific to the service. If the Oracle identifies the request as inconsistent with the defined property, it responds with a negative verdict (i.e. either ? or \u22a5)). In response, the Monitor publishes an error message and notifies the client of the discrepancy, bypassing the service invocation. Conversely, if the Oracle confirms the consistency of the request with the property, it returns a positive verdict (i.e., either ?\u315c or T). The Monitor proceeds to invoke the service and awaits a response from the server. Upon receiving the response, the Monitor relays it back to the Oracle for evaluation. Should the Oracle determine the response to be erroneous (i.e., the returned verdict is either ? or), the Monitor again publishes an error message and notifies the client accordingly. Otherwise, it delivers the response to the client as expected.\nIn contrast to the standard ROSMonitoring behaviour, handling services necessitates additional veri- fication steps. The Monitor must check both the service request and its corresponding response with the Oracle. Verifying the request is crucial to prevent invoking the service in case of a violation. Moreover, the Monitor must act as an intermediary between the client and server. This mechanism mirrors ROS- Monitoring's behaviour when topic filtering is enabled, albeit with an extension in the case of services to invoke the actual service upon successful request verification."}, {"title": "Ordered topics extension", "content": "To recover the publication order of messages in real time, ROSMonitoring 2.0 adds timestamps to each message. These timestamps are then utilised in Algorithm 1 to propagate messages to the Oracle in their original publication order. Moreover, this approach is based on the following assumption.\nAssumption 1. Messages on each single topic arrive at subscribers in the order of publication.\nIn order to use the reordering feature in the ROS monitor, in the callback function for every topic, instead of propagating the message (msg) directly to the Oracle, Algorithm 1 calls addToBuffer(msg,t). Such a procedure accumulates messages from each topic into their respective buffers. Message release is withheld until all buffers contain at least one message, at which point the message with the earliest publication timestamp is released and sent to the Oracle. To prevent more than one thread to change the buffers simultaneously, we use locks to block write-access for a single thread.\nLemma 1. In Algorithm 1, messages in each buffer maintain the order of publication timestamps.\nProof. Suppose there is a topic t such that its corresponding list in dictionary buffers is out of order. Without loss of generality, assume there are two messages m\u2081 and m2 on topic t with m\u2081 published before m2 but stored in buffers[t] in reverse order, i.e. [..,m2,m1,..]. Due to Assumption 1, since both m\u2081 and m2 are on the same topic, they are received by the ROS monitor in the correct order. Therefore, addToBuffer(m1, t) is called before addToBuffer(m2,t). Consequently, m\u2081 is appended to the list buffers[t] before m2. This contradicts our assumption that m2 is stored before m\u2081 in buffers[t]. Thus, it follows, by contradiction, that Lemma 1 holds.\nTheorem 1. Algorithm 1 propagates messages to the Oracle in the order of their publication.\nProof. In order to prove that Algorithm 1 is correct, we assume the opposite, namely that two messages, m\u2081 and m2, were propagated to the Oracle in reverse order of their publication timestamps. Without loss of generality suppose m\u2081 was published earlier than m2 but was propagated to the Oracle after m2.\nIf the messages are on the same topic then, due to Assumption 1, we reach a contradiction which means our assumption is incorrect and the proof is complete. Otherwise, the messages are on distinct topics. Hence, by construction, they are stored in separate lists in buffers. Furthermore, the algorithm only sends messages to the Oracle if the buffers for all topics are non-empty. Therefore, both m\u2081 and m2 must be present in their corresponding buffers at the time m2 is propagated to the Oracle. But the algorithm, by construction, always chooses the message with the smallest timestamp to propagate to the Oracle next. This contradicts our assumption that m2 is propagated before m\u2081 despite having a larger timestamp. Consequently, we can conclude, by contradiction, that Algorithm 1 is correct.\nA successful application of the ordering mechanism necessitates careful consideration to mitigate the risk of deadlocks. Specifically, when a topic t undergoes filtering by the monitor, and another topic or service x relies on it, both t and x should not be concurrently included in the ordering process. Otherwise, the buffering of a message m\u2081 on topic t can lead to a deadlock scenario, as it cannot be released until an x message is buffered. Conversely, an x message cannot be generated until a t message is published, which, in turn, cannot occur until m\u2081 is released from the buffer. Furthermore, it is essential to carefully evaluate dependencies between topics and services when determining which should be ordered based on their publication times."}, {"title": "Experimental evaluation", "content": "In our case study, we illustrate the practical implementation of ROSMonitoring 2.0 through a scenario involving a Battery Supervisor system for a UAV. We developed an online ROS monitor which runs alongside the system and checks its behaviour against a set of properties in real time. The experiments were conducted using ROS1 Noetic distribution. As shown in Figure 2, our case study comprises three interconnected nodes: the Battery, responsible for publishing the remaining battery percentage; the Battery Supervisor, which subscribes to the battery percentage topic and publishes status updates based on predefined thresholds; and the LED Panel, which reflects the battery status through LED lights.\nThe Battery node periodically broadcasts the battery percentage on the /battery_percentage topic. Meanwhile, the Battery Supervisor node, operating at a slower rate than the Battery, subscribes to this topic and publishes status updates on the /battery_status topic. These status updates indicate the battery status as follows: status 1 for a percentage higher than 40%, status 2 for a percentage between 30% and 40%, and status 3 for a percentage between 0% and 30%. Since the Battery Supervisor has a slower publication rate, it may not report the status for every percentage published by the Battery. This is intentional to ensure that while the battery status is reported regularly, energy usage and communications are optimised.\nAs shown in Figure 4, to facilitate monitoring system behaviour, supplementary topics and a ser- vice are added to the original example in Figure 2. For instance, to ensure synchronisation between the Battery and the Battery Supervisor, an additional topic /input_accepted is introduced. This topic tracks which battery percentage messages have been processed by the Battery Supervisor. Further- more, the Battery Supervisor publishes a message on topic /status_change if the battery status changes. The Battery Supervisor node subscribes to the /status_change topic itself to separate the processing of /battery_percentage messages from the invocation of service call to /SetLED . As explained further below, this is a workaround to prevent deadlocks when using the ordering mechanism. Upon detect- ing a change in status by comparing the current status with the previous one, the Battery Supervisor publishes a /status_change message. Once the Battery Supervisor receives a /status_change message, it calls the /SetLED_mon service to update the LED lights on the LED Panel accordingly. After re- ceiving a /SetLED_mon service request, the ROS monitor checks that the request is valid and it calls the /SetLED service. Upon receiving a service call, the LED Panel publishes a message on the /status_accepted topic to record which status update was acknowledged, followed by a message on the /LED_panel topic reporting the current state of the LED lights (green, yellow, and red). The LED Panel also sends a response to the ROS monitor which is relayed back to the Battery Supervisor.\nSubscribing to the /status_change topic may appear peculiar for the Battery Supervisor, which pub- lishes it. While it might seem more straightforward to invoke the /SetLED service where the status calculation occurs based on received /battery_percentage messages, such an approach risks deadlock. The reason is that the buffer is unable to release a service request message until accepting the next per- centage message. But no further percentage messages can be accepted until a service response is received and that can only happen if the service request is released. To resolve this, we separated the publication of topics from the function which initiates service requests so that the service does not block the receipt of messages needed for producing a response.\nThe properties we selected to verify are as follows with formal definitions in Table 1:\n1. Topic only: Correspondence of /battery_status with /battery_percentage and /input_accepted :\n(a) Every /battery_status message corresponds to a /input_accepted message and correctly re- ports the status based on its corresponding /battery_percentage message.\n(b) Every /input_accepted message is followed by a /battery_status message within 100 time steps.\n2. Topic and Service: Correspondence of /SetLED service request with /battery_status :\n(a) Every /SetLED service request corresponds to a /battery_status message and a change in battery status.\n(b) Every change of status reported via /battery_status messages is followed by a /SetLED ser- vice request within 100 time steps.\n3. Service only: Correspondence of /SetLED service request and response:\n(a) Every /SetLED service response corresponds to a /SetLED service request.\n(b) Every /SetLED service request is followed by a /SetLED service request within 100 time steps.\nFormalisation of these properties requires definition of predicates, summarised in Table 2, based on the JSON messages sent to the Oracle. For topics, generic predicates topic and id are defined. Addition- ally, for the /battery_percentage topic, predicate percentage is defined, taking values 1 for percentages between 40% and 100%, 2 for percentages between 30% and 40%, 3 for percentages between 0% and 30%, and \u2018INVALID' for other values. Consistently, the percentage and status predicates share values to enable referencing, as seen in Property 1a. For the /battery_status topic, predicate status holds the String version of message status, with \u2018INVALID' assigned if the status is not 1, 2, or 3. Addition- ally, predicate status_change is defined to be 'True' if the corresponding field in the message is 'true'. Note that the monitor is not subscribed to the /status_change topic which is used to trigger an LED Panel response. The reason for this redundancy is deadlock prevention. If the /status_change topic was ordered, then its release would be contingent on a service request joining the buffers which cannot happen unless the /status_change message is released. Our solution to this potential deadlock was to keep the /status_change topic unordered and add a field status_change to the battery_status topic for the Oracle to determine if the LED panel is responding correctly. Such redundancies could be considered as a general technique to prevent deadlocks. For the /SetLED service, predicates request and response indicate message type. For /SetLED service request messages, predicates req_id and req_status store ad- ditional information used in Properties 2a and 2b to verify legitimate requests triggered by corresponding /battery_status messages.\nA significant concern associated with the implementation of runtime verification is its potential ad- verse effect on overall system performance. To gauge the extent of overhead induced by monitoring services, we modified the client node to measure the time elapsed between dispatching a /SetLED ser- vice request and receiving the corresponding response. All experiments shown in Figures 5, 6, and 7 were conducted over 10 runs, with the results averaged. Each run was terminated once the battery per- centage reached zero. Frequencies for the Battery, Battery Supervisor, and LED Panel were set to 25, 10, and 35 Hertz respectively. The mean and standard deviation are reported for each experiment. As illustrated in Figure 6, the overhead incurred by monitoring /SetLED without ordering appears negligi- ble, but the introduction of ordering substantially delays the process, particularly noticeable during the last status change. To approximate the overhead attributed to the ordering mechanism, we adapted the monitor code to record the time difference between message buffering and transmission to the Oracle (reported in Figure 7). The results depicted in Figure 5 exhibit a similar trend, wherein the release time deviates from the buffering time until the second service request, after which the waiting time stabilises at a minimised level. This is because after the initial service request and response at the beginning of the execution, messages keep accumulating in the buffers since the /SetLED service buffer remains empty until the second service request is triggered by battery percentage reaching 40%. This threshold is reached when the message with ID 60 is sent. With a service request in the corresponding buffer, the algorithm proceeds to release messages from buffers in the order of publication. Since the next service request is triggered when the battery percentage reaches 30%, i.e. message ID 70, the service buffer will not be empty for long. This explains the minimal waiting time between buffering and transmission after the 60th message. Once the battery percentage reaches 0, the execution is interrupted. This allows the remaining messages in the buffers to be released in the order of publication without requiring all buffers to be nonempty. Moreover, as shown in Figure 7, the waiting time for /SetLED service requests escalates over time, whereas response messages appear to be promptly released from the buffer. This is because at the time that a service request is buffered, a number of messages have accumulated in the other buffers which need to be released before the service request. In contrast, since the service response is buffered shortly after the corresponding service request is released, there are only a few messages buffered in between which need to be released before the service response.\nWith regards to verification accuracy, monitoring with ordering consistently yielded accurate ver- dicts without any incorrect assessments. Conversely, in cases where monitoring excluded ordering, /battery_status messages often reached the monitor prior to their corresponding /battery_percentage or /input_accepted signals. Similarly, service request and response messages consistently preceded the cor- responding /status_change signals. These out-of-order message arrivals led to frequent false negative verdicts in each run. Hence, in weighing the trade-off between performance and accuracy, it becomes evident that monitoring with ordering is most suitable for safety-critical systems where time sensitivity is not paramount. On the other hand, monitoring without ordering may offer enhanced performance at the expense of accuracy, making it more suitable for scenarios where real-time constraints are less stringent."}, {"title": "Related Work", "content": "In this section, we discuss the most recent approaches to RV of ROS and position them in relation to ROSMonitoring 2.0.\nROSRV [19] shares similarities with our framework in achieving automatic RV of applications in ROS. Both tools utilise monitors not only to passively observe but also to intercept and handle incor- rect behaviours in message exchanges among nodes. The main difference lies in how they integrate the monitor into the system. ROSRV replaces the ROS Master node with RVMaster, directing all node communication through it and establishing peer-to-peer communication with the monitor as the inter- mediary. In contrast, ROSMonitoring adds the monitor through node instrumentation without altering the ROS Master node. Additionally, the new and extended version ROSMonitoring 2.0 presented in this paper further differentiates the two frameworks, as ROSRV does not support the verification of ser- vices or the customisation of the order of topics. HAROS [30] is a framework dedicated to ensuring the quality of ROS systems. Although HAROS primarily focuses on static analysis, it possesses the capability to generate runtime monitors and conduct property-based testing. Differently from ROSMon- itoring 2.0, HAROS does not support ROS2 (not even partially). Furthermore, one notable distinction between ROSMonitoring 2.0 and HAROS is that our specifications do not incorporate ROS-specific de- tails, and the process for generating monitors does not rely on understanding the topology of the ROS graph. DeROS [4] is a domain-specific language and monitoring system tailored for ROS. Although DeRoS's language incorporates explicit topic notions, it lacks native support for reordering or service handling. Moreover, it is exclusively compatible with ROS. An extension of Ogma supports the runtime monitoring of ROS2 applications [27]. It outlines a formal approach to generate runtime monitors for autonomous robots from structured natural language requirements, expressed in FRET [17]. This exten- sion integrates FRET and Copilot [26] via Ogma to translate requirements into temporal logic formulas and generate monitor specifications. Unlike ROSMonitoring 2.0, which focuses on monitoring and po- tentially filtering topics and services, this extension is limited to detecting and reporting violations only. Nonetheless, [17] provides a lightweight verification solution for complex ROS2 applications, ensuring safe operation. MARVer [13] is an integrated runtime verification system designed to ensure the safety and security of industrial robotic systems. It offers a lightweight yet effective approach to monitoring the behaviour of robotic systems in real-time, enabling the detection of security attacks and potential safety hazards. By being based on ROSMonitoring, MARVer can leverage the new features introduced in this work.\nThe work in [7] introduces TeSSLa-ROS-Bridge, a RV system designed for robotic systems built in ROS. Unlike other RV approaches, TeSSLa-ROS-Bridge utilises Stream-based Runtime Verification (SRV), which specifies stream transformations to detect errors and control system behaviour (currently supported in ROSMonitoring as well). The system allows TeSSLa monitors to run alongside ROS- based robotic systems, enabling real-time monitoring. Compared to ROSMonitoring, which focuses on monitoring and filtering topics and services, TeSSLa-ROS-Bridge offers a different approach by lever- aging stream-based runtime verification to monitor and control robotic systems. RTAMT is an online monitoring library for Signal Temporal Logic (STL), supporting both discrete and dense-time inter- pretations. In [25], RTAMT4ROS is introduced, integrating RTAMT with ROS. This integration en- ables specification-based RV methods in robotic applications, enhancing safety assurance in complex autonomous systems. However, similar to other RV frameworks, RTAMT4ROS solely supports topics monitoring and relies exclusively on ROS. Alternative runtime monitoring systems such as Lola [12], Java-MOP [10], detectEr [3], Hydra [29], DejaVu [18], LamaConv [20], and TraceContract [6] could potentially be applied to robotics applications. However, these systems are not explicitly designed for ROS, and integrating them into ROS would require additional development effort and potentially incur runtime costs."}, {"title": "Conclusions and Future Work", "content": "This paper introduces ROSMonitoring 2.0, an extension of the ROSMonitoring framework designed to enable the Runtime Verification of robotic applications developed in ROS. ROSMonitoring 2.0 expands upon its predecessor by facilitating the verification of services, in addition to topics, and by accommo- dating ordered topics, rather than solely unordered ones. Notably, the new features of ROSMonitoring 2.0 do not necessitate changes to the compositional and formalism-agnostic aspects of ROSMonitoring; only the synthesis of ROS monitors is adjusted. This approach not only leverages all existing features in ROSMonitoring but also ensures full backward compatibility with existing ROS applications based on ROSMonitoring. Furthermore, the proposed ordering algorithm and service interception process hold applicability beyond the scope of ROSMonitoring 2.0, potentially benefiting other systems as well.\nIt is also worth noting that the introduction of ordering messages according to the order they are published does not mutually exclude the standard ROSMonitoring topic checking, based on the order the messages are received. In this sense, in ROSMonitoring 2.0 it is also possible to combine both ordering features to monitor both the publish and receive order of messages. This becomes relevant in scenarios where it is necessary to identify which exact node is the faulty one, rather than being only interested in checking the presence of a property violation (which could be relevant in other scenarios instead).\nAs a future direction, we aim to formally verify that our case study is deadlock-free and establish design principles for ensuring deadlock-freeness. Additionally, threading will be explored as an alter- native solution to address potential deadlock issues. We also plan to extend our research to additional case studies in the robotics domain, focusing on complex systems involving multiple services with strong interdependencies across services, topics, and interfaces.\nMoreover, we intend to expand the framework to support ROS actions. ROS actions allow robots to execute complex, asynchronous tasks by setting goals, providing feedback, and retrieving results, thus facilitating modular and scalable behaviours for navigation, manipulation, and planning. Although actions are asynchronous and non-blocking, which reduces the monitoring burden compared to services, they introduce challenges in tracking progress against runtime goals.\nIn parallel, we plan to enhance our message ordering algorithm by introducing timeouts, preventing messages from waiting indefinitely, particularly in unreliable communication scenarios. However, care- ful consideration is required, as timeouts may disrupt the message order when delays occur, rather than message loss. This could be especially important for scenarios with strict timing requirements, where a balance must be struck between message order and timely delivery.\nFurthermore, a comprehensive performance evaluation of ROSMonitoring 2.0 will be a critical focus. We aim to assess key metrics such as execution time, resource usage, and system overhead, bench- marking our approach against existing alternatives. Such an evaluation will provide deeper insights into the framework's efficiency and scalability and guide further optimisations.\nLastly, our goal is to port all the features presented in this paper to ROS2, which currently only supports service monitoring and lacks message reordering functionality. This migration will proceed once additional evaluations and testing have been completed on the ROS1 version of ROSMonitoring 2.0."}]}