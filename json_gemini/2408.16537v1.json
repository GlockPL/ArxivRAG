{"title": "SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks", "authors": ["Xing Ai", "Guanyu Zhu", "Yulin Zhu", "Yu Zheng", "Gaolei Li", "Jianhua Li", "Kai Zhou"], "abstract": "Graph Neural Networks (GNNs) have demonstrated commendable performance for graph-structured data. Yet, GNNs are often vulnerable to adversarial structural attacks as embedding generation relies on graph topology. Existing efforts are dedicated to purifying the maliciously modified structure or applying adaptive aggregation, thereby enhancing the robustness against adversarial structural attacks. It is inevitable for a defender to consume heavy computational costs due to lacking prior knowledge about modified structures. To this end, we propose an efficient defense method, called Simple and Fast Robust Graph Neural Network (SFR-GNN), supported by mutual information theory. The SFR-GNN first pretrains a GNN model using node attributes and then fine-tunes it over the modified graph in the manner of contrastive learning, which is free of purifying modified structures and adaptive aggregation, thus achieving great efficiency gains. Consequently, SFR-GNN exhibits a 24%-162% speedup compared to advanced robust models, demonstrating superior robustness for node classification tasks.", "sections": [{"title": "Introduction", "content": "Graph Neural Networks (GNNs) have emerged as the leading approach for graph learning tasks across various domains, including recommender system (Zhang and Gan 2024), social networks (Hu et al. 2023), and bioinformatics (Liu et al. 2023). However, numerous studies (Z\u00fcgner, Akbarnejad, and G\u00fcnnemann 2018; Xu et al. 2019; Hussain et al. 2021; Zhu et al. 2022a) have demonstrated the vulnerability of GNNs under adversarial attacks, where an attacker can deliberately modify the graph data to cause the misprediction of GNNs. Among them, structural attacks (Z\u00fcgner, Akbarnejad, and G\u00fcnnemann 2018; Z\u00fcgner and G\u00fcnnemann 2019; Liu et al. 2022) have gained prominence due to the unique structural nature of graph data. Specifically, by solely modifying the edges in a graph, structural attacks hold practical significance in application scenarios where attackers have limited access to the relationships among entities rather than the attributes of the entities themselves.\nTo defend against structural attacks, numerous robust GNN models (Jin et al. 2020; Entezari et al. 2020a; Jin et al. 2021; Zhu et al. 2023) have been proposed recently. The main ideas behind these approaches involve purifying the modified graph structure or designing adaptive aggregation mechanisms to avoid aggregating messages through poisoned structures. Despite these efforts, existing robust GNNs still encounter significant scalability challenges, which hinder their application in practical scenarios. These scalability issues are mainly attributed to two factors: computational complexity and hyper-parameter complexity.\nSpecifically, recent research (Zhu et al. 2021; Lei et al. 2024; Ennadir et al. 2024) reveals that current robust GNN models suffer from high computational complexity due to complex defense mechanisms, such as learning new graph structures or computing edge attention. Moreover, these robust models often introduce additional hyper-parameters (e.g. weighting coefficients and thresholds) beyond the basic ones (e.g. learning rates, dropout ratio, epochs). Unfortunately, effective hyper-parameter tuning often requires extensive background knowledge of the data, which may not always be available due to issues like distribution shifts. The interactions among multiple hyper-parameters compel developers to employ techniques such as grid search or cross-validation to ensure optimal values for all hyper-parameters, complicating model deployment in real-world scenarios (Wang et al. 2021; Chen et al. 2022).\nFig. 1 compares state-of-the-art robust GNNs with the vanilla GCN in terms of training time (per epoch in milliseconds) on Cora dataset and the number of extra hyper-parameters. The results indicate that all robust GNNs require more than twice the runtime of the vanilla GCN and introduce at least two extra hyper-parameters (with our method as an exception). It demonstrates that while existing robust GNNs achieve adversarial robustness, it comes at a significant cost in training time and hyper-parameter complexity.\nIn response, a natural question emerges: can we develop a GNN model that achieves adversarial robustness against structural attacks while also being simple and fast?\nIn this work, we propose a Simple and Fast Robust Graph Neural Network (SFR-GNN) that employs a simple but effective learning strategy: pre-training on node attributes and then fine-tuning on structure information. Specifically, given a positioned graph G' = (X, A', Y) with manipulated structure A', SFR-GNN is initially pre-trained using only node attributes X without structural information involved. Subsequently, the model is fine-tuned over A', devising a specialized graph contrastive learning scheme.\nThe idea behind this strategy is rooted in the analysis of the structural attack: the attacker meticulously generates a modified structure A' based on the given node attributes X, which is detrimental to the performance of GNN with respect to the corresponding X. Theoretically, structural attacks contaminate the mutual information between A' and Y conditioned by X: $I(A'; Y|X)$ to mislead GNN predictions. However, we indicate the \"paired effect\" of structural attacks: A' is most effective alongside the given X, and is not quite effective with any other X' \u2260 X (detailed in Sec.). Therefore, our strategy achieves robustness against structural attacks by disrupting the \"paired effect\". This is achieved by first pre-training on attributes X to obtain node embedding Zp and then fine-tunes it paired with A' to incorporate structural information, which actually pairs A' with Zp instead of X, thus mitigating the impact of the manipulated structure on model performance. Despite its simplicity, we provide theoretical support and insights through a mutual information perspective in Sec. .\nAs a result, SFR-GNN features a lightweight construction with no additional hyper-parameters, significantly alleviating the computational and hyper-parameter complexity associated with building robust GNNs. Fig. 1 illustrates that the computational and hyperparameter complexity of SFR-GNN is close to that of vanilla GCN and outperforms existing robust GNNs, highlighting the simplicity and ease of implementation of SFR-GNN. Datasets and codes of this paper are at the supplements.\nOur major contributions are summarized as follows.\n1) We propose a novel, simple and fast robust GNN model named SFR-GNN that employs an \"attribute pre-training and structure fine-tuning\" strategy to achieve robustness against structural attacks. This approach is efficient in that it requires no extra hyper-parameters and is free of time-consuming operations such as purification or attention mechanisms.\n2) We offer a comprehensive theoretical analysis through mutual information theory to provide insights into the proposed method and substantiate its effectiveness.\n3) The comprehensive evaluation of SFR-GNN against state-of-the-art baselines on node classification benchmarks, encompassing large-scale graph datasets, reveals that it achieves comparable or superior robustness while significantly enhancing runtime efficiency by a range of 24% to 162% compared to state-of-the-art baselines."}, {"title": "Related Works", "content": "Structural Attacks in Graph Learning. Structural attacks are a popular form of attack covering a wide range of graph learning models beyond GNNs, including self-supervised learning (Bojchevski and G\u00fcnnemann 2019; Zhang et al. 2022b), signed graph analysis (Zhou et al. 2023; Zhu et al. 2024), recommender systems (Lai et al. 2023), and so on. The primary idea is to utilize gradient-based methods to search for the optimal graph structure to degrade the performances of various tasks. For instance, Mettack (Z\u00fcgner and G\u00fcnnemann 2019) formulated the global structural poisoning attacks on GNNs as a bi-level optimization problem and leveraged a meta-learning framework to solve it. BinarizedAttack (Zhu et al. 2022b) simplified graph poisoning attacks against the graph-based anomaly detection to a one-level optimization problem. HRAT (Zhao et al. 2021) proposed a heuristic optimization model integrated with reinforcement learning to optimize the structural attacks against Android malware detection. GraD (Liu et al. 2022) proposes a reasonable budget allocation mechanism to enhance the effects of structural attacks.\nRobust GNNs. To defend against structural attacks, a series of robust GNNs are proposed, which typically rely on purifying the modified structure or designing adaptive aggregation strategies. For example, GNNGUARD (Zhang and Zitnik 2020) removes the malicious links during training by considering the cosine similarity of node attributes. Zhao et al. (Zhao et al. 2023) used a conservative Hamiltonian flow to improve the model's performance under adversarial attacks. However, common drawbacks of these approaches include high computational overhead and hyper-parameter complexity. More recently, few works have attempted to develop efficient robust GNNs. For example, NoisyGCN (Ennadir et al. 2024) defends against structural attacks by injecting random noise into the architecture of GCN, thereby avoiding complex strategies and improving runtime. Similarly, EvenNet (Lei et al. 2024) proposes an efficient strategy that ignores odd-hop neighbors of nodes, with a time complexity that is linear to the number of nodes and edges in the input graph. These efforts significantly reduce the time complexity of building robust GNNs but still introduce additional hyper-parameters. NoisyGCN requires careful selection of the ratio of injected noise and EvenNet requires the determination of both the order of the graph filter K and the initialization hyper-parameter a. This motivates us to develop even simpler while robust GNNs."}, {"title": "Background", "content": "We consider the node classification task in a semi-supervised setting. Specifically, let G = (X, A, Y) be an input graph, where X \u2208 Rn\u00d7d denotes node attributes, A \u2208 {0,1}n\u00d7n is the adjacent matrix, and Y represents the partially available labels of the nodes in the training set. A GNN model fo parameterized with \u03b8 is trained to predict the remaining node labels through minimizing the training loss Ltr given the training node labels:\n\u03b8* = arg min Ltr (fo(X, A), Y).  (1)\n\u03b8\nThis training loss Ltr is commonly employed classification loss such as the Negative Log-Likelihood.\nStructural Attacks. Structural attacks against semi-supervised node classification naturally fit within a poisoning attack setting, where the GNN model is trained and makes predictions over a manipulated graph. In a worst-case scenario, it is assumed that the attacker can arbitrarily modify the graph structure (i.e., A) with the goal of degrading classification performance. Specifically, the attacker seeks to find an optimal structural perturbation \u03b4*, resulting in a poisoned graph G' = (X, A' = A + \u03b4*, Y). Mathematically, a structural attack can be formulated as solving a bi-level optimization problem:\n\u03b4* = arg min Latk(fo* (X, (A + \u03b4)), Y)\n\u03b4\ns.t. \u03b8* = arg min Ltr (fo(X, A + \u03b4), Y), (2)\n\u03b8\nwhere Latk quantifies the attack objective. The attacks (Z\u00fcgner and G\u00fcnnemann 2019; Liu et al. 2022; Xu et al. 2019) mainly differ in their specific algorithms to solve the optimization problem.\nRobust GNNs as Defense. Training robust GNN models is a common defense strategy to mitigate structural attacks. In this paper, the defender's goal is to train a robust GNN model from the poisoned graph to maintain node classification accuracy. We note that the defender only has access to the poisoned graph G' = (X, A+\u03b4*, Y), not the clean graph G. Additionally, the defender does not have prior knowledge about how the perturbation \u03b4* was generated."}, {"title": "Methodology", "content": "Design Intuition\nWe propose a novel framework for efficiently learning robust GNNs against structural attacks, which employs a straightforward strategy: attribute pre-training and structure fine-tuning, to alleviate computational and hyper-parameter complexity. We articulate this design and the intuition behind it through an information theoretical perspective. For completeness and better readability, we defer all theoretical analysis to Section .\nOur intuition starts from a key observation of the essence of attacks: structural attacks degrade GNN's performance by contaminating the mutual information between A and Y conditioned on X, denoted as I(A; Y|X) (see Lemma 1 for details). That is, given fixed attributes X, the attacker can generate a poisoned structure A' to effectively attack GNNs. Moreover, the structural attack has a \"paired effect\": the poisoned structure A' is effective with the given X, and is not quite effective with any other X' \u2260 X (see Lemma. 2).\nThe above analysis reveals the key to designing robust GNNs: create a mismatch between A' and the attributes X. Previous works did so by trying to purify A', however, with high computational complexity. We employ a totally different strategy: attribute pre-training and structure fine-tuning essentially involves obtaining a latent node embedding Z through pre-train on X, and then fine-tune Z with A' to incorporate structural information. This approach allows the model to learn from the less harmful I(A'; Y|Z) instead of the contaminated I (A'; Y|X) (see Theorem. 1).\nHowever, since Z is pre-trained from X, there exists overlap between I(A'; Y|Z) and I (A'; Y|X), meaning that structural attacks still affects I(A'; Y|Z). We thus further propose a novel contrastive learning approach to learn structural information from I(A'; Y|Z) while mitigating the attack effect (see Theorem. 2). The detailed constructions are presented in the next section.\nDetailed Construction\nTo implement the intuition in Sec., we propose a novel method, namely Simple and Fast Robust Graph Neural Network (SFR-GNN) consisting of two main stages: attributes pre-training and structure fine-tuning as shown in Fig. 2 and Alg. 1. First, SFR-GNN pre-trains over the node attributes without structural information to generate node embeddings. Subsequently, SFR-GNN fine-tunes the node embeddings with the modified adjacency matrix to incorporate structural information.\nAttributes Pre-training. Attributes pre-training is employed to learn node embeddings solely from node attributes X. Specifically, a randomly initialized GNN model fo with parameters \u03b8 takes node attributes X of the input graph G' = (X, A', Y) and an identity matrix I as inputs and aims to minimize the pre-training loss Lp to learn node embeddings Zp:\n\u03b8p = arg min Lp(fo(X,I), Y), Zp = fop (X,I). (3)\n\u03b8\nThe choice of pre-training loss Lp can be any common classification loss, such as the Negative Log-Likelihood Loss function (NLL). Since the pre-training process completely excludes A' and Zp is learned from X without being modified by structural attacks, Zp is uncontaminated. Lines 3-7 of Alg. 1 shows the attributes pre-training stage.\nAlthough the embeddings Zp learned through attribute pre-training are sufficiently \u201cclean\u201d, the lack of structural information makes Zp insufficient to predict labels accurately. Hence, we propose structure fine-tuning, which adjusts Zp using A' to incorporate some structural information.\nStructure Fine-tuning. In structure fine-tuning, the model is initialized by the pre-trained parameters \u03b8p and minimizes the fine-tuning loss function Lf and contrastive loss function Lc simultaneously:\n\u03b8* = arg min L\u0192(Zp, Y) + Lc(Zip, Zinter),\n\u03b8\u03c1\nZp = fop (Xtrain, A'), Zinter = fop (Xinter, A'), (4)\nwhere the the fine-tuning loss function Lf is as same as Lp, Le is any typical contrastive function such as InfoNCE. Xinter is generated by the proposed Inter-class Node Attributes Augmentation (InterNAA), which replaces the node feature of each node v in the training set with the average node feature of several nodes with the different class as v that are sampled randomly from the training set. The number of samples equals the degree of the node v. The process of InterNAA is shown in Lines 9-17 in Alg. 1.\nThe primary objectives of the structure fine-tuning stage are twofold: to ensure that Z contains structural information and to prevent it from being influenced by contaminated information in structure (I(A'; Y|X)). The former is achieved by minimizing fine-tuning loss Lf, while the latter is achieved by minimizing contrastive loss Lc. A detailed theoretical analysis is provided in Sec. . Here, we offer an intuitive explanation.\nFirstly, the pre-trained parameters \u03b8p are used to initialize the model f. However, unlike the training stage, f receives A' instead of I as input, which means f fine-tunes the pre-trained embeddings Zp using structure information to obtain Z. Besides, by combining contrastive learning techniques to maximize the similarity between Z\u201e and Zinter, we effectively align Z with the less harmful I (A'; Y|Xinter) rather than the contaminated I(A'; Y|X). I(A'; Y|Xinter) is less harmful because we replace X with Xinter generated by InterNAA, akin to reducing the lethality of a gun by providing it with mismatched bullets.\nComputational Complexity. The computational complexity consists of two parts: the attribute pre-training stage (Lines 3-7 in Alg. 1) and the structure fine-tuning stage (Lines 19-24 in Alg. 1). Assuming our network is composed of L layers of graph convolutional layers, with F hidden units per layer, N nodes and E edges in the graph, pretraining epochs ep, and finetuning epochs ef. Since the attributes pretraining does not utilize the adjacency matrix A', its computational complexity can be considered equivalent to that of a multi-layer perceptron (MLP), which is O(epLNF2).\nAs for structure fine-tuning, the nodes in the training set are traversed to generate Xinter (Lines 9-17 in Alg. 1), with computational complexity of O(\u03c3NdF), where o is the training ratio and d is the average degrees. The computational complexity of obtaining Zp and Zinter, is equal to applying twice calculations of GCNs: O(2* (LNF2 + LEF)) (Chen et al. 2020). The computational complexity for computing the contrastive loss is O(\u03c3\u00b2N2F) (Zhang et al. 2022a; Alon et al. 2024).\nThus the overall computational complexity of SFR-GNN is O(epLNF2+\u03c3NdF+ef(2LNF2+2LEF)+\u03c3\u00b2N2F). In the worst case when the graph is fully connected, where d = N and E = N2, the complexity is O(epLNF2 +\n\u03c3\u039d\u00b2F + ef(2LNF2 + 2LN2F + \u03c3\u00b2N2F)). Since the training ratio o is less than 1, ep and ef are constants smaller than N, and their impact on the overall complexity is negligible. Hence, the total complexity of SFR-GNN is O(LNF2 + LN2F), which is on par with that of GCN, and significantly lower than that of existing robust GNNs. The experiments in Sec. substantiate this claim."}, {"title": "Theoretical Analysis", "content": "Our theoretical analysis serves two purposes: first, to analyze the essence of structural attacks and the paired effect from the perspective of mutual information, providing a theoretical explanation for our intuition; second, to theoretically prove the effectiveness of our proposed \"attributes pre-training, structure fine-tuning\" strategy.\nGiven the fundamental properties of mutual information, performance degradation of GNN can be attributed to the maliciously generated adjacency matrix over true node attributes. Accordingly, we provide the understanding of structural attacks from an information-theoretic perspective as in Lemma. 1.\nLemma 1 (Essence of Structural Attacks). Structural attacks degrade GNNs' performance through generating the modified adjacency matrix A' to contaminate the mutual information between the labels Y and A' conditioned by X, which essentially uses the mutual information I(A'; Y|X).\nThe significance of Lemma. 1 lies in highlighting that structural attacks essentially generate modified structure A' according to corresponding node attributes X, which implies the potential relationships between A' and X. Building on Lemma. 1, we propose Lemma. 2 blow to demonstrate the important correspondence between A' and X in I(A'; Y|X). Namely, I(A'; Y|X) can only maximally degrade GNN performance under the condition of X.\nLemma 2 (Paired Effect of Structural Attacks). For any X' \u2260 X, where X',X \u2208 Rn\u00d7d, the mutual information I(A'; Y|X') is less harmful to GNNs than I(A'; Y|X).\nNotably, Lemma. 2 implies a new defense strategy against structural attacks from the root cause. Unlike existing methods that focus on purifying the modified structure or employing adaptive aggregation, our approach does not require any operations on the modified structure. Instead, it replaces the corresponding attributes to disrupt the paired effect, thereby reducing the attack effectiveness of the modified structure on GNNs.\nMotivated by Lemma. 2, SFR-GNN pre-trains node embeddings Zp solely on node attributes X, and force the proposed model to learn information from I(A'; Y|Zp), which actually replaces X with Zp. We provide Theorem. 1 to demonstrate Zp shares mutual information with labels Y and I (A'; Y|Zp) is less harmful compared to I(A'; Y|X).\nTheorem 1. SFR-GNN's pre-training stage maximizes the mutual information I(Zp; Y) between Zp and Y, where I(A'; Y|Zp) is less harmful to GNNs compared to I(A'; Y|X).\nAlthough I (A'; Y|Zp) is less harmful than I(A'; Y|X), there may be an overlap between them since Zp is learned from X, leading to the contamination of I(A'; Y|Zp), as demonstrated in Lemma.3. Lemma.3 essentially explains the reason for employing contrastive learning, i.e., I(A'; Y|Zp) may be contaminated. Based on Lemma.3, we introduce contrastive learning to align I(A'; Y|Zp) to I(A'; Y Xinter) to prevent it from being contaminated, as demonstrated in Theorem. 2.\nLemma 3. There exists an overlap between I(A'; Y|Zp) and I(A'; Y|X), which consequently leads to the contamination of I(A'; Y|Zp).\nTheorem 2. SFR-GNN's structure fine-tuning stage maximizes I(A'; Y|Z) to learn structural information and align it to I(A'; Y|Xinter) to prevent from being contaminated."}, {"title": "Experiments", "content": "Datasets. We conduct experiments on three widely used benchmarks: Cora (McCallum et al. 2000), CiteSeer (Giles, Bollacker, and Lawrence 1998), Pubmed (Sen et al. 2008), and two large-scale graph datasets (ogbn-arxiv, and ogbn-products), with details presented in the Appendix. Furthermore, experimental results on two heterophilic graph datasets, demonstrating the robustness of the proposed method, are provided in the Appendix.\nImplementation and Baselines. We conducted an empirical comparison against eight state-of-the-art baseline defense algorithms, including RGCN (Zhu et al. 2019), GCN-Jaccard (Entezari et al. 2020a), SimP-GCN (Jin et al. 2021), Pro-GNN (Jin et al. 2020), STABLE (Li et al. 2022), EvenNet (Lei et al. 2024), GADC (Liu et al. 2024), and NoisyGCN (Ennadir et al. 2024), which achieve remarkable performance in terms of structure attack defense. We select two representative structure attack methods, i.e., Mettack (Z\u00fcgner and G\u00fcnnemann 2019) and GraD (Liu et al. 2022), to verify the robustness of the proposed method and baselines. Source code and configuration of baselines are obtained from either the public implementation of DeepRobust (Li et al. 2020), or the official implementation of the authors. Detailed configurations are deferred to the Appendix.\nExperiments Settings. Experiments are conducted on a device with 16 Gen Intel(R) Core(TM) i9-12900F cores and an NVIDIA L20 (48GB memory). On Cora, Citeseer and Pubmed, we follow the data splitting method of DeepRobust: randomly selecting 10% of the nodes for training, 10% for validation, and the remaining 80% for testing. As for ogbn-arxiv and ogbn-products, we follow dataset splits provided by OGB (Hu et al. 2020). As for hyper-parameters of baselines, we follow the authors' suggestion to search for the optimal values. Table. 1 shows all hyper-parameters and their ranges. It can be observed that existing robust GNNS require multiple hyper-parameters, and some of them have a large search range. Consequently, existing robust GNNs require many training runs to determine the optimal values of all hyper-parameters.\nDefense Performance. To showcase the effectiveness and efficiency of the proposed method, we compare its robustness (Table. 2) and training time (Table. 4) against two typical attack methods: Mettack and GraD, on three datasets with baselines. It's worth noting that the proposed method always achieves the best performance or the second-best performance on Cora and Citeseer, highlighting its robustness, which is on par with or exceeds state-of-the-art baselines. For instance, the proposed method achieves 82.1% accuracy on Cora dataset under Mettack with 10% perturbation ratio while baselines' accuracy ranges from 69% to 81%. Besides, for Citeseer, the proposed method achieves tiny but continuous improvements compared to baselines under all perturbation ratios. On the Pubmed dataset, while SFR-GNN does not surpass strong baselines like SimP-GCN and Pro-GNN, it still outperforms several other baselines. We speculate that the reason is more complex and larger models tend to have an advantage on larger datasets like Pubmed.\nBesides the robustness improvements, the proposed method also achieves significant training time speedup compared to baselines as shown in Tabel. 4. Upon examining the table, we can observe that compared to the fastest existing methods in their respective categories, such as NoisyGCN and GADC, the proposed method achieves over a 100% speedup on Cora, and Citeseer. Conversely, when compared to slower methods like SimP-GCN and STABLE, the proposed method's speed is nearly 10 times that of theirs. The significant speedup achieved by the proposed method can be attributed to the elimination of time-consuming modified structure identification and processing operations.\nScalability to Large-scale Graph. We conduct experiments on two publicly available large-scale graph datasets, ogbn-arxiv and ogbn-products (Hu et al. 2020), to validate the scalability of the proposed method. Owing to memory overflow issues encountered by structure attack methods like Mettack on large-scale graphs, we employ PRBCD (Geisler et al. 2021) as the attack method for these settings, and compare its performance against four defense methods capable of scaling to large graphs. The tests are performed using the officially provided modified adjacency matrices, with the results presented in Table. 3. Given the substantial memory requirements of the contrastive learning component, to facilitate the scalability of SFR-GNN to large-scale graphs, we introduce a variant of our approach: SFR-GNN (w/o CL), which excludes contrastive learning during the structure fine-tuning stage, thereby enabling its effective application to large-scale graphs without encountering memory constraints.\nResults in Table. 3 demonstrate that SFR-GNN consistently achieves either the top or second-best performance across various perturbation ratios on two large-scale datasets. Notably, it also exhibits the fastest runtime, surpassing even GCN in speed. This efficiency stems from the attributes pre-training stage of SFR-GNN , which is free from structure information related computations. Additionally, EvenNet and Soft Medoid GDC encountered out-of-memory (OOM) issues on ogbn-products. This is attributed to the fact that Soft Medoid GDC incorporates diffusion computations, rendering it less scalable (Geisler et al. 2021), while EvenNet demands a minimum of 70GB of GPU memory, exceeding the capacity of our experiment device, which is limited to 48GB. It's worth noting that the speed advantage of SFR-GNN is particularly pronounced in large-scale graphs compared to tiny graphs, which demonstrates the simplicity and effectiveness of SFR-GNN.\nAblation Study. To validate the effectiveness of the proposed method, we propose two variants: 1) SFR-GNN w/o CL: This variant lacks the contrastive learning technique and directly fine-tunes the model using the modified adjacency matrix. 2) SFR-GNN w/o Fin: This variant lacks the whole structure fine-tuning stage, thereby degenerating into a Multilayer Perceptron (MLP). The results in Fig. 3 (a) and Fig. 3 (b) show that the accuracies of both variants are consistently lower than that of SFR-GNN across all attack ratios. SFR-GNN w/o CL can not performer SFR-GNN and achieves suboptimal results which proves the Lemma. 3 and Theorem. 2 in Sec.. SFR-GNN w/o Fin achieved the worst results because the learned representations only contained attribute information without structure information.\nAdditionally, to validate the effectiveness of the proposed InterNAA, we replace it with commonly used augmentations: Node Dropping (SFR-GNN w/ND), Edge Removing (SFR-GNN w/ER), and Feature Masking (SFR-GNN w/FM). Besides, we provide a variant SFR-GNN w/Ran which replaces InterNAA with random node attributes sampling. The comparison results are shown in Fig. 3 (a) and Fig. 3 (b). Clearly, InterNAA outperforms other augmentations. We believe this is because other augmentations randomly perturb the elements of the graph and cannot prevent the inflect of contaminated mutual information during the fine-tuning stage. Additionally, to validate the effectiveness of the proposed InterNAA, we replace it with commonly used augmentations: Node Dropping (SFR-GNN w/ND), Edge Removing (SFR-GNN w/ER), Feature Masking (SFR-GNN w/FM) and random node attribute sampling (SFR-GNN w/Ran). The comparison results are shown in Fig. 3 (a) and Fig. 3 (b). Clearly, InterNAA outperforms the other augmentations. We believe this is because other augmentations randomly perturb the elements of the graph and cannot prevent the influence of contaminated mutual information during the fine-tuning stage."}, {"title": "Conclusion", "content": "In this paper, we propose a novel robust GNN: Simple and Fast Robust Graph Neural Network (SFR-GNN) against structural attacks. SFR-GNN utilizes the proposed \"attributes pre-training and structure fine-tuning\" strategy, without the need for purification of the modified structures, thus significantly reducing computational overhead and avoiding the introduction of additional hyper-parameters. We conduct both theoretical analysis and numerical experiments to validate the effectiveness of SFR-GNN. Experimental results demonstrate that SFR-GNN achieves robustness comparable to state-of-the-art baselines while delivering a 50%-136% improvement in runtime speed. Additionally, it exhibits superior scalability on large-scale datasets. This makes SFR-GNN a promising solution for applications requiring reliable and efficient GNNs in adversarial settings."}, {"title": "A. Theoretical Analyses", "content": "A.1 Proof of Lemma. 1\nLemma 4. Structural attacks degrade GNNs' performance through generating the modified adjacency matrix A' to contaminate the mutual information between the labels Y and A' conditioned by X, which essentially uses the mutual information I(A'; Y|X).\nProof. For a GNN model fe parameterized by 0, the objective is to predict labels Y as accurately as possible by taking node features X and adjacency matrix A as inputs. From the perspective of information theory, this objective can be viewed as minimizing the conditional entropy H(Y|fo(X, A)):\nmin Ltr (fo(X, A), Y) \u21d2 min H(Y|fo(\u03a7, \u0391)). (5)\nThe conditional entropy H(Y|fo(X, A)) measures the uncertainty of Y given the fo(X, A). An effective fo (X, A) should be able to predict Y with high probability, meaning uncertainty is low. Thus the above equation holds.\nAccording to the principles of mutual information, we have:\nI(fo(X, A); Y) = H(Y) \u2013 H(Y|fo(X, A). (6)\nH(Y) is the information entropy of labels which is determined by Y and fixed. Thus minimizing H(Y|fo(X, A)) is actually maximizing I(fo(X, A); Y):\nmin H(Y|fo(X, A)) \u21d2 max I(fo(X, A); Y). (7)\nTherefore, the learning objective of GNN is actually maximizing the mutual information I(fo (X, A); Y):\nmin Ltr (fo(X, A), Y) \u21d2 max I(fo(X, A); Y). (8)\nmaximizing the mutual information between the labels Y and the model output fo (X, A), which is actually learning information from the mutual information between the labels Y and the joint distribution (X, A) because most of GNNs have been demonstrated that satisfy the injective property (Xu et al. 2018) or linear assumption (Wu et al. 2019; Zhu and Koniusz 2021):\n\u21d2\nmax I(fo(X, A); Y)\nmax I((X, A); Y). (9)\nFurthermore, according to the properties of mutual information, we can decompose I((X, A); Y) into I(X; Y) and I(A; Y|X):\nI((X, A); Y) = I(X; Y) + I(A; Y|X). (10)\nThus GNNs' learning objective is actually maximizing I((X, A); Y) and can be decomposed into the maximization of I(X; Y) and the maximization of I(A; Y|X).\nThe goal of the structural attacker is degrading the prediction accuracy of fe as much as possible. To achieve this goal, the structural attacker employs perturbation \u03b4* to divert the outputs of the victim GNN from the true labels Y to erroneous predictions Y', which can be formulated as the minimization of I((X, (A + \u03b4)); Y) and the maximization of I((X, (A + \u03b4)); \u03a5\u0384):\nA = A + \u03b4*,\n(11)\n\u03b4* = arg min I((X, (A + \u03b4)); Y). (12)\n\u03b4\nAccording to Eq. (9) and Eq. (10), the above goal can be rewritten as:\n\u03b4* = arg min I(X; Y) + I((A + \u03b4); Y|X). (13)\n\u03b4\nDue to I(X; Y) is irrelevant and independent to the structure perturbation 8 thus the actual goal of the attacker is:\n\u03b4* arg min I((A + \u03b4); Y|X). (14)\n\u03b4\nHence, the structural attacker essentially aims to minimize I(A'; Y|X) to hinder the victim GNN from extracting adequate information from this mutual information and compel victim GNN to make wrong predictions. We describe this scenario as the contamination of mutual information I(A'; Y|X)."}, {"title": "A.2 Proof of Lemma. 2", "content": "Lemma 5. For any X' \u2260 X", "as": "nI(A'; Y|X) = I(A'; Y) \u2013 I(A\u0384; Y; X), (1"}]}