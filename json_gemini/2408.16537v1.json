{"title": "SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks", "authors": ["Xing Ai", "Guanyu Zhu", "Yulin Zhu", "Yu Zheng", "Gaolei Li", "Jianhua Li", "Kai Zhou"], "abstract": "Graph Neural Networks (GNNs) have demonstrated com-mendable performance for graph-structured data. Yet, GNNs are often vulnerable to adversarial structural attacks as embedding generation relies on graph topology. Existing efforts are dedicated to purifying the maliciously modified structure or applying adaptive aggregation, thereby enhancing the ro-bustness against adversarial structural attacks. It is inevitable for a defender to consume heavy computational costs due to lacking prior knowledge about modified structures. To this end, we propose an efficient defense method, called Simple and Fast Robust Graph Neural Network (SFR-GNN), sup-ported by mutual information theory. The SFR-GNN first pre-trains a GNN model using node attributes and then fine-tunes it over the modified graph in the manner of contrastive learn-ing, which is free of purifying modified structures and adap-tive aggregation, thus achieving great efficiency gains. Conse-quently, SFR-GNN exhibits a 24%-162% speedup compared to advanced robust models, demonstrating superior robust-ness for node classification tasks.", "sections": [{"title": "Introduction", "content": "Graph Neural Networks (GNNs) have emerged as the leading approach for graph learning tasks across various domains, including recommender system (Zhang and Gan 2024), social networks (Hu et al. 2023), and bioinformatics (Liu et al. 2023). However, numerous studies (Z\u00fcgner, Akbarnejad, and G\u00fcnnemann 2018; Xu et al. 2019; Hussain et al. 2021; Zhu et al. 2022a) have demonstrated the vulnerability of GNNs under adversarial attacks, where an attacker can deliberately modify the graph data to cause the misprediction of GNNs. Among them, structural attacks (Z\u00fcgner, Akbarnejad, and G\u00fcnnemann 2018; Z\u00fcgner and G\u00fcnnemann 2019; Liu et al. 2022) have gained prominence due to the unique structural nature of graph data. Specifically, by solely modifying the edges in a graph, structural attacks hold practical significance in application scenarios where attackers have limited access to the relationships among entities rather than the attributes of the entities themselves.\nTo defend against structural attacks, numerous robust GNN models (Jin et al. 2020; Entezari et al. 2020a; Jin et al. 2021; Zhu et al. 2023) have been proposed recently. The main ideas behind these approaches involve purifying the modified graph structure or designing adaptive aggregation mechanisms to avoid aggregating messages through poisoned structures. Despite these efforts, existing robust GNNs still encounter significant scalability challenges, which hinder their application in practical scenarios. These scalability issues are mainly attributed to two factors: computational complexity and hyper-parameter complexity.\nSpecifically, recent research (Zhu et al. 2021; Lei et al. 2024; Ennadir et al. 2024) reveals that current robust GNN models suffer from high computational complexity due to complex defense mechanisms, such as learning new graph structures or computing edge attention. Moreover, these robust models often introduce additional hyper-parameters (e.g. weighting coefficients and thresholds) beyond the basic ones (e.g. learning rates, dropout ratio, epochs). Unfortunately, effective hyper-parameter tuning often requires extensive background knowledge of the data, which may not always be available due to issues like distribution shifts. The interactions among multiple hyper-parameters compel developers to employ techniques such as grid search or cross-validation to ensure optimal values for all hyper-parameters, complicating model deployment in real-world scenarios (Wang et al. 2021; Chen et al. 2022).\nIn response, a natural question emerges: can we develop a GNN model that achieves adversarial robustness against structural attacks while also being simple and fast?\nIn this work, we propose a Simple and Fast Robust Graph Neural Network (SFR-GNN) that employs a simple but effective learning strategy: pre-training on node attributes and then fine-tuning on structure information. Specifically, given a positioned graph $G' = (X, A', Y)$ with manipulated structure A', SFR-GNN is initially pre-trained using only node attributes X without structural information involved. Subsequently, the model is fine-tuned over A', devising a specialized graph contrastive learning scheme.\nThe idea behind this strategy is rooted in the analysis of the structural attack: the attacker meticulously generates a modified structure A' based on the given node attributes X, which is detrimental to the performance of GNN with respect to the corresponding X. Theoretically, structural attacks contaminate the mutual information between A' and Y conditioned by X: $I(A'; Y|X)$ to mislead GNN predictions. However, we indicate the \"paired effect\" of structural attacks: A' is most effective alongside the given X, and is not quite effective with any other $X' \\neq X$ (detailed in Sec.). Therefore, our strategy achieves robustness against structural attacks by disrupting the \"paired effect\". This is achieved by first pre-training on attributes X to obtain node embedding $Z_p$ and then fine-tunes it paired with A' to incorporate structural information, which actually pairs A' with $Z_p$ instead of X, thus mitigating the impact of the manipulated structure on model performance. Despite its simplicity, we provide theoretical support and insights through a mutual information perspective in Sec. .\nAs a result, SFR-GNN features a lightweight construction with no additional hyper-parameters, significantly alleviating the computational and hyper-parameter complexity associated with building robust GNNs. Datasets and codes of this paper are at the supplements.\nOur major contributions are summarized as follows.\n1) We propose a novel, simple and fast robust GNN model named SFR-GNN that employs an \"attribute pre-training and structure fine-tuning\" strategy to achieve robustness against structural attacks. This approach is efficient in that it requires no extra hyper-parameters and is free of time-consuming operations such as purification or attention mechanisms.\n2) We offer a comprehensive theoretical analysis through mutual information theory to provide insights into the proposed method and substantiate its effectiveness.\n3) The comprehensive evaluation of SFR-GNN against state-of-the-art baselines on node classification benchmarks, encompassing large-scale graph datasets, reveals that it achieves comparable or superior robustness while significantly enhancing runtime efficiency by a range of 24% to 162% compared to state-of-the-art baselines."}, {"title": "Related Works", "content": "Structural Attacks in Graph Learning. Structural attacks are a popular form of attack covering a wide range of graph learning models beyond GNNs, including self-supervised learning (Bojchevski and G\u00fcnnemann 2019; Zhang et al. 2022b), signed graph analysis (Zhou et al. 2023; Zhu et al. 2024), recommender systems (Lai et al. 2023), and so on. The primary idea is to utilize gradient-based methods to search for the optimal graph structure to degrade the performances of various tasks. For instance, Mettack (Z\u00fcgner and G\u00fcnnemann 2019) formulated the global structural poisoning attacks on GNNs as a bi-level optimization problem and leveraged a meta-learning framework to solve it. BinarizedAttack (Zhu et al. 2022b) simplified graph poisoning attacks against the graph-based anomaly detection to a one-level optimization problem. HRAT (Zhao et al. 2021) proposed a heuristic optimization model integrated with reinforcement learning to optimize the structural attacks against Android malware detection. GraD (Liu et al. 2022) proposes a reasonable budget allocation mechanism to enhance the effects of structural attacks.\nRobust GNNs. To defend against structural attacks, a series of robust GNNs are proposed, which typically rely on purifying the modified structure or designing adaptive aggregation strategies. For example, GNNGUARD (Zhang and Zitnik 2020) removes the malicious links during training by considering the cosine similarity of node attributes. Zhao et al. (Zhao et al. 2023) used a conservative Hamiltonian flow to improve the model's performance under adversarial attacks. However, common drawbacks of these approaches include high computational overhead and hyper-parameter complexity. More recently, few works have attempted to develop efficient robust GNNs. For example, NoisyGCN (Ennadir et al. 2024) defends against structural attacks by injecting random noise into the architecture of GCN, thereby avoiding complex strategies and improving runtime. Similarly, EvenNet (Lei et al. 2024) proposes an efficient strategy that ignores odd-hop neighbors of nodes, with a time complexity that is linear to the number of nodes and edges in the input graph. These efforts significantly reduce the time complexity of building robust GNNs but still introduce additional hyper-parameters. NoisyGCN requires careful selection of the ratio of injected noise and EvenNet requires the determination of both the order of the graph filter K and the initialization hyper-parameter \u03b1. This motivates us to develop even simpler while robust GNNs."}, {"title": "Background", "content": "We consider the node classification task in a semi-supervised setting. Specifically, let $G = (X, A, Y)$ be an input graph, where $X \\in R^{n\\times d}$ denotes node attributes, $A \\in \\{0,1\\}^{n\\times n}$ is the adjacent matrix, and Y represents the partially available labels of the nodes in the training set. A GNN model $f_\\theta$ parameterized with \u03b8 is trained to predict the remaining node labels through minimizing the training loss $L_{tr}$ given the training node labels:\n$\\theta^* = \\arg \\min_\\theta L_{tr}(f_\\theta(X, A), Y).$ (1)\nThis training loss $L_{tr}$ is commonly employed classification loss such as the Negative Log-Likelihood."}, {"title": "Structural Attacks", "content": "Structural attacks against semi-supervised node classification naturally fit within a poisoning attack setting, where the GNN model is trained and makes predictions over a manipulated graph. In a worst-case scenario, it is assumed that the attacker can arbitrarily modify the graph structure (i.e., A) with the goal of degrading classification performance. Specifically, the attacker seeks to find an optimal structural perturbation $\u03b4^*$, resulting in a poisoned graph $G' = (X, A' = A + \u03b4^*, Y)$. Mathematically, a structural attack can be formulated as solving a bi-level optimization problem:\n$\u03b4^* = \\arg \\min_\u03b4 L_{atk}(f_{\\theta^*}(X, (A + \u03b4)), Y)$,\ns.t. $\\theta^* = \\arg \\min_\\theta L_{tr}(f_\\theta(X, A + \u03b4), Y),$ (2)\nwhere $L_{atk}$ quantifies the attack objective. The attacks (Z\u00fcgner and G\u00fcnnemann 2019; Liu et al. 2022; Xu et al. 2019) mainly differ in their specific algorithms to solve the optimization problem."}, {"title": "Robust GNNs as Defense", "content": "Training robust GNN models is a common defense strategy to mitigate structural attacks. In this paper, the defender's goal is to train a robust GNN model from the poisoned graph to maintain node classification accuracy. We note that the defender only has access to the poisoned graph $G' = (X, A+\u03b4^*, Y)$, not the clean graph G. Additionally, the defender does not have prior knowledge about how the perturbation $\u03b4^*$ was generated."}, {"title": "Design Intuition", "content": "We propose a novel framework for efficiently learning robust GNNs against structural attacks, which employs a straightforward strategy: attribute pre-training and structure fine-tuning, to alleviate computational and hyper-parameter complexity. We articulate this design and the intuition behind it through an information theoretical perspective. For completeness and better readability, we defer all theoretical analysis to Section .\nOur intuition starts from a key observation of the essence of attacks: structural attacks degrade GNN's performance by contaminating the mutual information between A and Y conditioned on X, denoted as $I(A; Y|X)$ (see Lemma 1 for details). That is, given fixed attributes X, the attacker can generate a poisoned structure A' to effectively attack GNNs. Moreover, the structural attack has a \"paired effect\": the poisoned structure A' is effective with the given X, and is not quite effective with any other $X' \\neq X$ (see Lemma. 2).\nThe above analysis reveals the key to designing robust GNNs: create a mismatch between A' and the attributes X. Previous works did so by trying to purify A', however, with high computational complexity. We employ a totally different strategy: attribute pre-training and structure fine-tuning essentially involves obtaining a latent node embedding Z through pre-train on X, and then fine-tune Z with A' to incorporate structural information. This approach allows the model to learn from the less harmful $I(A'; Y|Z)$ instead of the contaminated $I(A'; Y|X)$ (see Theorem. 1).\nHowever, since Z is pre-trained from X, there exists overlap between $I(A'; Y|Z)$ and $I(A'; Y|X)$, meaning that structural attacks still affects $I(A'; Y|Z)$. We thus further propose a novel contrastive learning approach to learn structural information from $I(A'; Y|Z)$ while mitigating the attack effect (see Theorem. 2). The detailed constructions are presented in the next section."}, {"title": "Detailed Construction", "content": "To implement the intuition in Sec., we propose a novel method, namely Simple and Fast Robust Graph Neural Network (SFR-GNN) consisting of two main stages: attributes pre-training and structure fine-tuning as shown in Fig. 2 and Alg. 1. First, SFR-GNN pre-trains over the node attributes without structural information to generate node embeddings. Subsequently, SFR-GNN fine-tunes the node embeddings with the modified adjacency matrix to incorporate structural information.\nAttributes Pre-training. Attributes pre-training is employed to learn node embeddings solely from node attributes X. Specifically, a randomly initialized GNN model $f_\\theta$ with parameters \u03b8 takes node attributes X of the input graph $G' = (X, A', Y)$ and an identity matrix I as inputs and aims to minimize the pre-training loss $L_p$ to learn node embeddings $Z_p$:\n$\\theta_p = \\arg \\min_\\theta L_p(f_\\theta(X,I), Y), Z_p = f_{\\theta_p}(X,I).$ (3)\nThe choice of pre-training loss $L_p$ can be any common classification loss, such as the Negative Log-Likelihood Loss function (NLL). Since the pre-training process completely excludes A' and $Z_p$ is learned from X without being modified by structural attacks, $Z_p$ is uncontaminated. Lines 3-7 of Alg. 1 shows the attributes pre-training stage.\nAlthough the embeddings $Z_p$ learned through attribute pre-training are sufficiently \u201cclean\u201d, the lack of structural information makes $Z_p$ insufficient to predict labels accurately. Hence, we propose structure fine-tuning, which adjusts $Z_p$ using A' to incorporate some structural information.\nStructure Fine-tuning. In structure fine-tuning, the model is initialized by the pre-trained parameters $\u03b8_p$ and minimizes the fine-tuning loss function $L_f$ and contrastive loss function $L_c$ simultaneously:\n$\\theta^* = \\arg \\min_{\\theta_p} L_f(Z_p, Y) + L_c(Z_p, Z_{inter}),$\n$Z_p = f_{\\theta_p}(X_{train}, A'), Z_{inter} = f_{\\theta_p}(X_{inter}, A'),$ (4)\nwhere the the fine-tuning loss function $L_f$ is as same as $L_p$, $L_c$ is any typical contrastive function such as InfoNCE. $X_{inter}$ is generated by the proposed Inter-class Node Attributes Augmentation (InterNAA), which replaces the node feature of each node v in the training set with the average node feature of several nodes with the different class as v that are sampled randomly from the training set. The number of samples equals the degree of the node v. The process of InterNAA is shown in Lines 9-17 in Alg. 1.\nThe primary objectives of the structure fine-tuning stage are twofold: to ensure that $Z$ contains structural information and to prevent it from being influenced by contaminated information in structure ($I(A'; Y|X)$). The former is achieved by minimizing fine-tuning loss $L_f$, while the latter is achieved by minimizing contrastive loss $L_c$. A detailed theoretical analysis is provided in Sec. . Here, we offer an intuitive explanation.\nFirstly, the pre-trained parameters $\u03b8_p$ are used to initialize the model f. However, unlike the training stage, f receives A' instead of I as input, which means f fine-tunes the pre-trained embeddings $Z_p$ using structure information to obtain $Z$. Besides, by combining contrastive learning techniques to maximize the similarity between $Z_p$ and $Z_{inter}$, we effectively align $Z$ with the less harmful $I(A'; Y|X_{inter})$ rather than the contaminated $I(A'; Y|X)$. $I(A'; Y|X_{inter})$ is less harmful because we replace X with $X_{inter}$ generated by InterNAA, akin to reducing the lethality of a gun by providing it with mismatched bullets.\nComputational Complexity. The computational complexity consists of two parts: the attribute pre-training stage (Lines 3-7 in Alg. 1) and the structure fine-tuning stage (Lines 19-24 in Alg. 1). Assuming our network is composed of L layers of graph convolutional layers, with F hidden units per layer, N nodes and E edges in the graph, pretraining epochs $e_p$, and finetuning epochs $e_f$. Since the attributes pretraining does not utilize the adjacency matrix A', its computational complexity can be considered equivalent to that of a multi-layer perceptron (MLP), which is $O(e_pLNF^2)$.\nAs for structure fine-tuning, the nodes in the training set are traversed to generate $X_{inter}$ (Lines 9-17 in Alg. 1), with computational complexity of $O(\u03c3NdF)$, where \u03c3 is the training ratio and d is the average degrees. The computational complexity of obtaining $Z_p$ and $Z_{inter}$, is equal to applying twice calculations of GCNs: $O(2* (LNF^2 + LEF))$ (Chen et al. 2020). The computational complexity for computing the contrastive loss is $O(\u03c3^2N^2F)$ (Zhang et al. 2022a; Alon et al. 2024).\nThus the overall computational complexity of SFR-GNN is $O(e_pLNF^2+\u03c3NdF+e_f(2LNF^2+2LEF)+\u03c3^2N^2F)$. In the worst case when the graph is fully connected, where d = N and E = $N^2$, the complexity is $O(e_pLNF^2 + \u03c3N^2F + e_f(2LNF^2 + 2LN^2F + \u03c3^2N^2F))$. Since the training ratio \u03c3 is less than 1, $e_p$ and $e_f$ are constants smaller than N, and their impact on the overall complexity is negligible. Hence, the total complexity of SFR-GNN is $O(LNF^2 + LN^2F)$, which is on par with that of GCN, and significantly lower than that of existing robust GNNs. The experiments in Sec. substantiate this claim."}, {"title": "Theoretical Analysis", "content": "Our theoretical analysis serves two purposes: first, to analyze the essence of structural attacks and the paired effect from the perspective of mutual information, providing a theoretical explanation for our intuition; second, to theoretically prove the effectiveness of our proposed \"attributes pre-training, structure fine-tuning\" strategy."}, {"title": "A. Theoretical Analyses", "content": "A.1 Proof of Lemma. 1\nLemma 4. Structural attacks degrade GNNs' performance through generating the modified adjacency matrix A' to contaminate the mutual information between the labels Y and A' conditioned by X, which essentially uses the mutual information I(A'; Y|X).\nProof. For a GNN model $f_\\theta$ parameterized by \u03b8, the objective is to predict labels Y as accurately as possible by taking node features X and adjacency matrix A as inputs. From the perspective of information theory, this objective can be viewed as minimizing the conditional entropy $H(Y|f_\\theta(X, A))$:\n$\\min L_{tr} (f_\\theta(X, A), Y) \\Rightarrow \\min H(Y|f_\\theta(X, A)).$ (5)\nThe conditional entropy $H(Y|f_\\theta(X, A))$ measures the uncertainty of Y given the $f_\\theta(X, A)$. An effective $f_\\theta (X, A)$ should be able to predict Y with high probability, meaning uncertainty is low. Thus the above equation holds.\nAccording to the principles of mutual information, we have:\n$I(f_\\theta(X, A); Y) = H(Y) - H(Y|f_\\theta(X, A).$ (6)\n$H(Y)$ is the information entropy of labels which is determined by Y and fixed. Thus minimizing $H(Y|f_\\theta(X, A))$ is actually maximizing $I(f_\\theta(X, A); Y)$:\n$\\min H(Y|f_\\theta(X, A)) \\Rightarrow \\max I(f_\\theta(X, A); Y).$ (7)\nTherefore, the learning objective of GNN is actually maximizing the mutual information $I(f_\\theta(X, A); Y)$:\n$\\min L_{tr} (f_\\theta(X, A), Y) \\Rightarrow \\max I(f_\\theta(X, A); Y).$ (8)\nmaximizing the mutual information between the labels Y and the model output $f_\\theta (X, A)$, which is actually learning information from the mutual information between the labels Y and the joint distribution (X, A) because most of GNNs have been demonstrated that satisfy the injective property (Xu et al. 2018) or linear assumption (Wu et al. 2019; Zhu and Koniusz 2021):\n$\\Rightarrow \\max I(f_\\theta(X, A); Y) \\Rightarrow \\max I((X, A); Y).$ (9)\nFurthermore, according to the properties of mutual information, we can decompose $I((X, A); Y)$ into $I(X; Y)$ and $I(A; Y|X)$:\n$I((X, A); Y) = I(X; Y) + I(A; Y|X).$ (10)\nThus GNNs' learning objective is actually maximizing $I((X, A); Y)$ and can be decomposed into the maximization of $I(X; Y)$ and the maximization of $I(A; Y|X)$.\nThe goal of the structural attacker is degrading the prediction accuracy of $f_\\theta$ as much as possible. To achieve this goal, the structural attacker employs perturbation $\u03b4^*$ to divert the outputs of the victim GNN from the true labels Y to erroneous predictions Y', which can be formulated as the minimization of $I((X, (A + \u03b4)); Y)$ and the maximization of $I((X, (A + \u03b4)); \u03a5\u0384)$:\n$A' = A + \u03b4^*, \\ \\ $ (11)\n$\u03b4^* = \\arg \\min_\u03b4 I((X, (A + \u03b4)); Y).$ (12)\nAccording to Eq. (9) and Eq. (10), the above goal can be rewritten as:\n$\u03b4^* = \\arg \\min_\u03b4 I(X; Y) + I((A + \u03b4); Y|X).$ (13)\nDue to I(X; Y) is irrelevant and independent to the structure perturbation 8 thus the actual goal of the attacker is:\n$\u03b4^* \\ \\ \\  = \\arg \\min_\u03b4 I((A + \u03b4); Y|X).$ (14)\nHence, the structural attacker essentially aims to minimize I(A'; Y|X) to hinder the victim GNN from extracting adequate information from this mutual information and compel victim GNN to make wrong predictions. We describe this scenario as the contamination of mutual information I(A'; Y|X)."}, {"title": "A.2 Proof of Lemma. 2", "content": "Lemma 5. For any $X' \\neq X$, where $X', X \\in R^{n\\times d}$, the mutual information I(A';Y|X') is less harmful to GNNs than I(A'; Y|X).\nProof. According to properties of mutual information, I(A'; Y|X) can be reformulated as:\n$I(A'; Y|X) = I(A'; Y) - I(A\u0384; Y; X),$ (15)\nwhere I(A'; Y; X) is the mutual information between A', Y and X.\nLemma. 1 indicates attackers degrade victim GNNs' performances by minimizing I(A\u0384; Y|X). Eq. (15) indicates minimizing I(A'; Y|X) can be achieved through minimizing I(A'; Y) and maximizing I(A'; Y; X). Assuming the upper bound of I(A'; Y; X) is donated as \u03c4, an ideal attacker, in pursuit of minimizing I(A'; Y|X), fulfills I(A'; Y; X) = \u03c4.\nSimilarly, for I(A\u0384; Y|X'), we have:\n$I(A\u0384; Y|X') = I(A\u0384; Y) - I(A\u0384; Y; \u03a7\u0384).$ (16)\nTherefore, the difference between I(A'; Y|X') and I(A'; Y|X) is referred as:\n$I(A\u0384; Y|X\u0384) - I(A'; Y|X)$\n= $I(A\u0384; Y) - I(A\u0384; Y; X\u0384) - I(A\u0384; Y) + I(A'; Y; X)$\n= $I(A'; Y;X) - I(A\u0384; Y; X')$ = $\u03c4 - I(A\u0384; Y; X\u0384) \u2265 0, (17)\nbecause $I (A'; Y; X')$ is less than the upper bound \u03c4. The above equation demonstrates $I(A'; Y|X') > I(A'; Y|X)$. That implies $I(A'; Y|X')$ retains more information that could potentially be exploited by GNNs. Thus I (A\u0384; Y|X') is less harmful to GNNs."}, {"title": "A.3 Proof of Theorem. 1", "content": "Theorem 3. SFR-GNN's pre-training stage maximizes the mutual information I(Zp; Y) between Zp and Y, where I(A'; Y|Zp) is less harmful to GNNs compared to I(A'; Y|X).\nProof. $Z_p$ is solely learned from node attributes X, thus Minimizing the pre-training loss $L_p$ is actually pursuing the maximizing\nMinimizing the pre-training loss function $L_p$ aims at ensuring accurate predictions for all nodes, which is maximizing the conditional probability $P(Y_v = C_v | Z_p(v))$ for any node v. It equals minimizing the information entropy $H(Y|Z_p)$. Due to the properties of mutual information, we have:\n$I(Y; Z_p) = H(Y) - H(Y|Z_p).$ (18)\nTherefore, minimizing $H(Y|Z_p)$ equals to maximize $I(Y; Z_p)$, and naturally, minimizing $L_p$ is equal to maximize $I(Y; Z_p)$. Additionally, according to the Lemma. 2, we have:\n$I(A'; Y|Z_p) > I(A'; Y|X) = \u03c4,$ (19)\nwhich proves I(A'; Y|Zp) is less harmful to GNNs compared to I(A'; YX)."}, {"title": "A.4 Proof of Lemma. 3", "content": "Lemma 6. There exists an overlap between I(A';Y|Zp) and I(A'; Y|X), which consequently leads to the contamination of $I(A'; Y|Z_p)$.\nProof. We first demonstrate the existence of overlap between $I(A'; Y|Z_p)$ and $I(A'; Y|X)$. Due to the properties of mutual information, we have:\n$I(A'; Y|Z_p) \\subset I(A'; Y), I(A; Y|Z_p) \\subset I(A'; Y)$ $I(A'; Y|X) = I(A\u0384; Y) - I(A\u0384; Y; X),$ = (20)\nthus $I(A'; Y|Z_p) \\cup I(A'; Y|X) \\neq 0$ if and only if $I(A'; Y|Z_p) = I(A\u0384; Y; X)$, which is not always feasible to guarantee in practice. Consequently, we have:\n$I(A\u0384; Y|Z_p) \\cup I(A'; Y|X) \\neq 0.$ (21)\nTo demonstrate the possible contamination of I(A'; Y|Zp), we abstract the $f_\\theta$ as a Simplified Graph Convolution (SGC), where $f_\\theta$ is a linearized function with parameter Wo:\n$f_\\theta(X) = X \\cdot W_\\theta.$ (22)\nIn structure fine-tuning, the SGC model with K layers convolution can be formulated as:\n$f_{\\theta,}(X) = (A')^k \\cdot X \\cdot W_{\\theta_p}, Z_p = X \\cdot W_{\\theta_p}.$ (23)\nSuppose the parameter update during the fine-tuning process is denoted as $\u0394W$, the output of the function $f_{\\theta,}$ after fine-tuning is:\n$f_{\\theta_p} (X) = (A')^k \\cdot X \\cdot (W_{\\theta_p} + \u0394W)$ $\\ \\  = (A')^k \\cdot X \\cdot W_{\\theta_p} + (A')^k \\cdot X \\cdot \u0394W$ = $(A')^k \\cdot Z_p + (A')^k \\cdot X \\cdot \u0394W.$ (24)\nThe term following the addition can be regarded as the embedding output by a GNN with parameters \u0394W, taking X and A' as inputs. It is actually equal to a victim GNN, whose embedding is contaminated by $I(A'; Y|X)$. That implies that during the fine-tuning stage, $Z_p$ unavoidably incorporates the influence of $I(A'; Y|X)$."}, {"title": "A.5 Proof of Theorem. 2", "content": "Theorem 4. SFR-GNN's structure fine-tuning stage maximizes I (A'; Y|Z) to learn structural information and align it to I(A'; Y|Xinter) to prevent from being contaminated.\nProof. Following the principles of mutual information, we hold:\n$I((X_{inter}, A'); Y) = I(A\u0384; Y) + I(X_{inter}; Y|A\u0384)$ < $I(A'; Y) + I(X_{inter}; Y)$ $\\leq I(A\u0384; Y) + H(Y) - H(Y|X_{inter}),$ (25)\nwhere $H(\u00b7)$ is information entropy. $H(Y)$ is the information entropy of labels which is solely determined by Y and independent of X. As for the conditional entropy $H(Y|X_{inter})$ which measures the uncertainty of Y given the $X_{inter}$. An effective $X_{inter}$ should be able to predict Y well, meaning that knowing $X_{inter}$ allows us to determine the value of Y with great certainty. However, InterNAA intentionally replaces the node features contained in $X_{inter}$ with features from nodes of different classes, leading to an inability to accurately predict Y through $X_{inter}$, leading to a large $H (Y|X_{inter})$. Due to the non-negative characteristic of mutual information:\n$I(X_{inter}; Y) = H(Y) - H(Y|X_{inter}) \u2265 0.$ (26)\nWhen the conditional entropy is sufficiently large, the mutual information $I(X_{inter}; Y)$ tends to be 0, at which point the above equation fulfills:\n$I((X_{inter}, A'); Y) \\Rightarrow I(A\u0384; Y).$ (27)\nwhich means $I(f(X_{inter}, A'); Y))$ is approximately equal to $I(A'; Y))$, and align Zp with $f(X_{inter}, A')$ is actually let $Z_p$ combine structure information from $I(A'; Y)$ instead of the contaminated $I(A'; Y|X)."}, {"title": "B. Experimental Details", "content": "B.1 Dataset Details\nIn this section", "below": "nCora", "GCN": "It is the most representative GNN model which utilizes the graph convolutional layer to propagate node features with the low-pass filter and smooth the features of connected node pairs.\n\u2022 RGCN: It learns the Gaussian distributions for each node feature and employs an attention mechanism to alleviate the potential malicious influence of nodes with high variance.\n\u2022 GCN-Jaccard: It sanitizes the graph data by pruning links that connect nodes with low values of Jaccard similarity of node attributes.\n\u2022 ProGNN: It jointly learns a structural graph and a robust GNN model from the modified graph guided by the three properties: low-rank", "SimP-GCN": "It utilizes a kNN graph to capture the node similarity and enhance the node representation of the GNN.\n\u2022 STABLE: It utilizes the homophily assumption to refine the modified structure and combine contrastive learning techniques to remove adversarial edges. Finally", "EvenNet": "By applying balance theory", "GADC": "Inspired by graph diffusion convolution, it proposes a novel min-max optimization to perturb graph structure based on Laplacian distance.\n\u2022 No"}]}