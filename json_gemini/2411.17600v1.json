{"title": "Making History Readable", "authors": ["Bipasha Banerjee", "Jennifer Goyne", "William A. Ingram"], "abstract": "The Virginia Tech University Libraries (VTUL) Digital Library Platform (DLP) hosts digital collections that offer our users access to a wide variety of documents of historical and cultural importance. These collections are not only of academic importance but also provide our users with a glance at local historical events. Our DLP contains collections comprising digital objects featuring complex layouts, faded imagery, and hard-to-read handwritten text, which makes providing online access to these materials challenging. To address these issues, we integrate AI into our DLP workflow and convert the text in the digital objects into a machine-readable format. To enhance the user experience with our historical collections, we use custom AI agents for handwriting recognition, text extraction, and large language models (LLMs) for summarization. This poster highlights three collections focusing on handwritten letters, newspapers, and digitized topographic maps. We discuss the challenges with each collection and detail our approaches to address them. Our proposed methods aim to enhance the user experience by making the contents in these collections easier to search and navigate.", "sections": [{"title": "I. INTRODUCTION", "content": "The DLP [1] is a cloud-native solution designed to accommodate collections, some as large as 40 TB. Our collections include handwritten letters from the Civil War era, newspapers, and digitized historical maps. Archival materials feature difficult-to-read handwriting, faded or irregular text, and complex layouts, making it challenging for digital libraries to provide online access. These factors hinder accurate text recognition, complicate indexing and metadata generation, and obstruct full-text search functionality, ultimately reducing discoverability. The DLP is designed to address these challenges on a large scale while organizing and preserving our extensive collections of complex digital materials.\n\nThe DLP integrates AI for processing challenging material, including text extraction to convert scanned documents, maps, and other materials into machine-readable form, custom AI agents for handwriting recognition, and large language models (LLMs) for summarization. We implement custom AI agents to extract text from handwritten documents, maps, and newspapers, making these difficult-to-read materials readable, thus enhancing the user experience. LLM-based summarization service enhances historical material by providing simplified summaries that are adapted for modern times. We discuss"}, {"title": "II. BACKGROUND", "content": "Optical Character Recognition (OCR) [2] is a technology that aids in text extraction by converting the text in scanned images and documents into machine-readable form. OCR can often result in noise in the extracted text due to inferior quality input images and the inability to process diversity in fonts and layouts, making it unreliable [3]. Pytesseract [4] is a Python wrapper for Google's tesseract [5] OCR engine that enables users to extract text from scanned documents. While Tesseract is a high-quality open-source solution for extracting text, it often fails to do very well with scanned documents and requires careful pre-processing. AWS Textract [6] is Amazon's proprietary machine learning service designed to extract text from handwriting, layout elements, and data from scanned or born-digital PDF/TIFF files or images. It is a paid service that can be used with the AWS SDK, AWS web interface, or the AWS API key. The detect_document_text API cate-gorizes extracted text into AWS BlockType tags, identifying the structure of the document by recognizing elements such as pages, lines, and words. The API provides us with extracted text, bounding-box information, and confidence scores for the associated block elements. Textract's analyze_document API analyzes documents to extract and detect various ele-ments, such as content, layout, style, and semantic elements.\nLanguage Models, specifically large language models (LLMs), perform exceptionally well on natural language generation tasks, such as automatic summarization. Language models are built using the transformer architecture [7] that uses an attention mechanism that allows retention of contextual relationships across a sequence of texts. Although language models such as BERT [8] can also summarize, they are bound by context length limitation, which can be challenging when summarizing longer documents. Generative Al models such as Llama [9], GPT [10], and Phi-3 [11] have improved their support for longer context lengths of up to 128k. We use Meta's Llama-3.1-8B-Instruct model to generate a summary of handwritten letters."}, {"title": "III. USE CASES", "content": "We added text extraction and summarization services to help make the content buried in these letters more accessible to the public. We addressed some inconsistencies in the extracted text as shown in Fig. 4. The red box highlights an error in the extraction of the word 'hand' as 'fund' and the corresponding confidence score of 66.79%. To mitigate this challenge, we set a threshold for confidence scores that we deem acceptable. If the confidence score for a block of text is below the set threshold, we utilize a language model to predict the top three most probable words and then select the best word. We use Google's bert-large-uncased-whole-word-masking model for sentence correction. The model predicts the top three most probable words in a sentence where a particular word has a confidence score below the threshold. The text correction pipeline ensures that the most accurate text is used in summarization. Our summarization approach uses Llama-3.1-8B-Instruct LLM to generate summaries from the historical letters. An example of the generated summary is shown in Fig. 4. We simplify the words and summarize the content more attuned to current times, making it easier for our readers to understand historical handwritten letters.\nMontgomery Museum [12] is a non-profit organization that houses a diverse array of historical content, such as physical artifacts, books, and newspapers detailing local and regional history in Virginia. By offering this historical newspaper collection online in machine-readable format, users can search and navigate events from historical time periods. The Montgomery Museum newspaper collection presents the text in a multi-column layout, where traditional OCR systems struggle with identifying the correct relative positioning of text in columns. The layout is further complicated by irregular column widths, overlapping text, and the presence of embedded images and advertisements.\nVirginia Tech Digitized Topographic Map Collection [13] is physically located at Virginia Tech University Libraries, which includes a series of maps that have undergone digitization for convenient digital access via the digital library platform. By making this collection online, users can view maps via the web, which previously could only be viewed in person with the assistance of a librarian to locate them physically. These maps introduce challenges due to the non-linear placement of text, where the text is positioned at arbitrary angles or along curved paths around geographical features (see Fig. 3). Traditional OCR models are optimized for rectilinear text, and text is expected to follow a predictable, left-to-right flow. When text is positioned at various angles or along curves, the image-preprocessing techniques required to correct orientation and alignment are not standard in traditional"}, {"title": "IV. DISCUSSION AND FUTURE WORK", "content": "This poster discusses custom Al agents for text extraction and summarization from historical digitized collections. By extracting text from challenging-to-read materials, we improve accessibility, while the summarization service creates clear, concise summaries to enhance user understanding, and thus improve overall engagement with the material. These advances transform previously inaccessible content into searchable material and enrich the digital library platform.\nOur results discussed in Section III indicate that out-of-the-box solutions might need adjustments based on our DLP needs. Our goal is to improve text extraction from the maps collection by using an ensemble method comprising tiling and rotation. This approach involves processing large digital map objects and dividing them into several smaller tiles to accommodate and facilitate the file size requirements in the text extraction process. We then apply rotation and text extraction to the smaller map tiles, ensuring consistent, high-quality results throughout the process. We plan to integrate AI into services, such as automated metadata generation, that create richer and more descriptive metadata that improve categorization and organization. Automatic metadata generation speeds up the otherwise time-consuming process of metadata creation by using AI-driven approaches to identify and extract key elements from collections automatically. By strategically integrating AI into our DLP workflow, we are improving efficiency, enabling accurate large-scale extraction and summarization of complex materials and resulting in collections that are searchable, retrievable, and usable at scale."}]}