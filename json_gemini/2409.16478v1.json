{"title": "ALGORITHMIC DRIFT: A SIMULATION FRAMEWORK TO STUDY THE EFFECTS OF RECOMMENDER SYSTEMS ON USER PREFERENCES", "authors": ["Erica Coppolillo", "Ettore Ritacco", "Francesco Fabbri", "Francesco Bonchi", "Simone Mungari", "Marco Minici", "Giuseppe Manco"], "abstract": "Digital platforms such as social media and e-commerce websites adopt Recommender Systems to provide value to the user. However, the social consequences deriving from their adoption are still unclear. Many scholars argue that recommenders may lead to detrimental effects, such as bias-amplification deriving from the feedback loop between algorithmic suggestions and users' choices. Nonetheless, the extent to which recommenders influence changes in users leaning remains uncertain. In this context, it is important to provide a controlled environment for evaluating the recommendation algorithm before deployment. To address this, we propose a stochastic simulation framework that mimics user-recommender system interactions in a long-term scenario. In particular, we simulate the user choices by formalizing a user model, which comprises behavioral aspects, such as the user resistance towards the recommendation algorithm and their inertia in relying on the received suggestions. Additionally, we introduce two novel metrics for quantifying the algorithm's impact on user preferences, specifically in terms of drift over time. We conduct an extensive evaluation on multiple synthetic datasets, aiming at testing the robustness of our framework when considering different scenarios and hyper-parameters setting. The experimental results prove that the proposed methodology is effective in detecting and quantifying the drift over the users preferences by means of the simulation. All the code and data used to perform the experiments are publicly available2.", "sections": [{"title": "1 Introduction", "content": "Nowadays, people adopt social media as a fundamental medium to share and consume information. With a growing amount of available content, recommender systems represent a viable way to help users navigate large volumes of information by suggesting content that the user may like. As a downside, recommendation algorithms have also been blamed for detrimental effects such as echo chambers [Pariser, 2011] and opinion polarization [Cho et al., 2020], which in turn may lead to pernicious phenomena such as misinformation spreading [Del Vicario et al., 2016], fragmentation [Sunstein, 2018], and radicalization [Sunstein, 1999]. As a natural consequence, measuring the potential side-effects of recommender systems in the emergence of these issues is attracting much interest, with scholars proposing data-driven analysis [Bakshy et al., 2015, De Francisci Morales et al., 2021, Cinelli et al., 2021], model-based methods [Minici et al., 2022], and simulation studies [Fabbri et al., 2020, Santos et al., 2021, Cinus et al., 2022, Tommasel and Menczer, 2022].\nDespite this growing interest, the challenge is still open in the current literature in analyzing and measuring how the algorithm effects on users may evolve over time. Although several models have been proposed [Chaney et al., 2018, Bountouridis et al., 2019, Yao et al., 2021, Coppolillo et al., 2024a], these studies focus on specific topics, such as behavioral homogeneity or items diversity. Indeed, there is still lack of a unified and generalizable methodology which allows to track users preferences' evolution over time, and that is orthogonal to the kind of drift to quantify. Further, most of the existing simulation environments follow a simplistic behavioral model, providing limited flexibility in representing different behavioral patterns.\nTo fill this gap, in this paper, we propose a stochastic model for characterizing time-based interactions between users and recommendation algorithms in operational environments. In our scenario, users interact with various items on a platform, such as media content, news articles, or videos. The platform collects data on user preferences and utilizes this information to generate personalized recommendations. These recommendations are typically provided by ranking items based on their predicted relevance to the user [Agarwal et al., 2019].\nAn important aspect of our formulation consists in accounting for the \"feedback loop\" effect described in the litera-ture [Chaney et al., 2018], where user choices are influenced by the recommendations provided, and the algorithm relies on the user's past interactions rather than aligning with their true interests. Therefore, to accurately simulate user choices, it is essential to characterize user behavior by considering several factors, such as their potential resistance to recommendations (i.e., the autonomous selection of an item from the entire catalog) and their inertia in following the provided suggestions. Starting from this, the research questions we aim to address are the following: Can we quantify the effect of the recommendation algorithm in altering user preferences over the long term? How do different behavioral users pattern affect the influence of the recommender?\nTo answer these questions, we propose a controlled simulated environment where mimicking user-recommender system interactions, along with two novel metrics to evaluate whether and to what extent the recommender system contributes to drifting users' initial preferences. Following from these assumptions, we introduce the concept of \"algorithmic drift\", in order to characterize how the recommendation algorithm contributes in changing user leanings. In practice, the simulation model starts from an initial group of heterogeneous user preferences, from which the recommender system induces initial transition probabilities between item categories. Notably, besides (blindly) following the provided recommendations, our model allows users to either completely ignore the suggestions and pick an item autonomously from the catalog (resistance), or still examine the recommendation list but choose the item still relying on their own preferences (inertia). Further, the user's choice can be influenced by exogenous hence unpredictable factors (randomness), that can lead to spurious interactions. By supporting different behavioral patterns in the users choices, we provide a comprehensive framework that allows for measuring the effects of the recommendation algorithms under different conditions. Notably, the metrics we propose enable such measurements, by tracking and quantifying changes according to predefined criteria.\nAs a paradigmatic example of such criteria, in our experiments we assume that the items available on the platform can be categorized as either harmful or neutral. Simultaneously, users are classified into three categories based on their interactions with these items: non-radicalized, semi-radicalized, or radicalized. This classification is determined by the proportion of harmful interactions they have exhibited. Further, we focus on a collaborative filtering-based scenario, where we consider the implicit connections that can be induced by the collaborative nature of the algorithm, hence exploiting the bridging nature of some users to propagate influences on the adoptions. As a result, the proposed framework allows us to quantify the changes in user leanings.\nOur contributions can be summarized as follows:\n\u2022 We define the concept of algorithmic drift and introduce two metrics for evaluating the impact of recommender systems on user behavior changes in the long term."}, {"title": "2 Related work", "content": "The contribution of this work spans on a variety of research fields, whose literature is explored as follows.\nSimulation-based studies. We can observe a growing research line studying the long-term effects of recommender systems through simulation models. Badami et al. [2018] propose a simulation framework for studying polarization phenomena in a context in which users are binarized into two homogeneous groups.\nChaney et al. [2018] claim that recommenders try to homogenize user behavior without increasing the utility of their suggestions. They argue that the most recent recommendation systems are actually trained over preferences that are already biased by previous recommendations, thus triggering a feedback loop where a suggestion algorithm tries to fit the recommendation history instead of matching the real interests of the users.\nBountouridis et al. [2019] propose a simulation framework for studying the impact of recommender systems in drifting users towards different content topics, thus mainly focusing on items diversity and users serendipity. Similarly, Yao et al. [2021] depicts a simulated environment to assess the actual contribution of recommenders in modifying users habits, particularly focusing on the phenomenon of popularity bias.\nFabbri et al. [2022], Cinus et al. [2022], Santos et al. [2021] show how people-recommenders can exacerbate social media critical issues, such as polarization, misinformation, and pre-existing inequalities in user communities. The authors define a simulation model that highlights the following recommender systems effects: (i) the growth of exposure inequalities at the individual level, strengthening the \u201crich-get-richer\" effect Fabbri et al. [2022], and (ii) the formation of polarized communities and echo chambers within homophilic groups Cinus et al. [2022], Santos et al. [2021]. In a similar vein, de Arruda et al. [2021] devised a model for simulating changes in users' opinions in social networks, showing potential detrimental effects such as polarization and echo chambers formations.\nTommasel and Menczer [2022] focus on the misinformation spread in social networks due to the recommender system capability of influencing the network topology. First, they simulate changes in user misinformation-spreading behavior and define counterfactual scenarios. Then, they simulate an opinion dynamic model over the derived network to estimate how recommendations affect the influence of users spreading misinformation.\nWe would like to emphasize how our work draws inspiration from the discussed literature but substantially differs from it. Indeed, we are not interested in explaining or assessing detrimental phenomena induced by recommender systems, but we aim at providing a controlled environment where the algorithm can be tested before deployment, by simulating its interaction with the users in the long term."}, {"title": "3 Simulation Framework", "content": "The core of our approach consists in devising the simulation framework and a set of metrics for measuring the potential algorithmic drift that a target recommendation algorithm may induce. In the following, we describe such contributions."}, {"title": "3.1 Preliminaries", "content": "Let U (resp. I) be the set of users (resp. items). We consider an implicit-feedback matrix $D \\in {0,1}^{|U|\\times|I|}$ of user-item interactions. $D_{ui}$ is equal to 1 if user u has interacted with item i, and 0 otherwise. With an abuse of notation, we denote by $D_u \\subseteq I$ the set of all items i such that $D_{ui} = 1$. Also, $(u, i) \\in D$ whenever $D_{ui} = 1$.\nWe assume a labeling function $l : I \\rightarrow {C_1, ..., C_N}$ that tags an item i as belonging to a category among $c_1,...,C_N$, thus partitioning I into N disjoint subsets $I_j = {i \\in I|l(i) = c_j }, j = 1, . . . , N$.\nWe adopt a recommender system $R_{\\Theta} : U \\times I \\rightarrow [0, 1]$, parameterized by $\\Theta$ and previously trained on D. Given an unseen user-item interaction (u, i), i.e., $D_{ui} = 0$, $R_{\\Theta}(u, i)$ estimates how likely the user u interacts with an item i once it is exposed to it. Such a likelihood can be exploited to build a ranked recommendation list for a user u, formed by unseen items and sorted by decreasing likelihood."}, {"title": "3.2 Organic Model", "content": "To assess the effect of recommender algorithms in terms of preference alteration, it is crucial to have a counterfactual based on an organic model i.e., assuming users and items interact without any $R_{\\Theta}$. For this purpose, we adopt the organic model proposed by Chang and Ugander [2022]. Assuming to know user and item features, $p_u$ and $a_i$, respectively, preferences are generated according to the measure $||p_u - a_i||$. However, users don't have full knowledge of the actual features $a_i$ for each item i and can only access samples through a Normal distribution $\\hat{a}_i \\sim Normal(a_i, \\Sigma)$, with $\\Sigma = 0.5 \\cdot \\Sigma_{item}$ and $\\Sigma_{item} = a^T a$ being the empirical covariance of the item features. Chang and Ugander [2022]"}, {"title": "3.3 User Behaviour", "content": "Our simulation model mimics how user preferences and recommender system co-evolve in a long-term scenario. In each step, the user selects an item to interact with, by either resorting to the algorithm recommendations, or by autonomously examining the whole catalog. Consequently, the algorithm adapts the next recommendations relying on these new interactions: this tight relationship between users and recommender system models the well-known concept of feedback loop [Chaney et al., 2018]. Further, our framework aims at simulating the user navigation across the whole choice space, instead of a single pathway. For this reason, the procedure consists of T iterative trials, each of which is repeated for B independent rounds. We impose that, in each of the B rounds, a user cannot interact with an item more the once. Within the simulation, for each user u, we instantiate an item-item matrix $S_u \\in \\mathbb{N}^{|I|\\times|I|}$, Intuitively, $S_u$ counts how many times u shifted from item i to item j in two consecutive rounds of the simulation, as explained in the following.\nAt each step t, The recommender system provides a list $L_t \\subset I$ of k items to the user. The latter behaves according to the following process: if their resistance to the suggestions of the recommender system (quantified as $\\gamma$) is high, the user may (stochastically) select an item from the whole catalog, by either relying on their own preferences, or picking it randomly. The random factor $\\eta$ (which we assume to be very low in practice) models the influence of exogenous hence uncontrollable factors that can guide the user's choice in that round. For instance, the user may select a spurious item under the influence of a friend's suggestion, by relying on advertisements, or even by mistake.\nAlternatively, if the user is not highly resistant to the algorithm, they may examine the recommendation list and pick an item. This can occur by either totally relying on the system (high inertia), or under the influence of their own interests (low inertia). Here, the core idea is that the user's choice may be influenced by its own preferences and beliefs, or conversely, they may completely rely on the recommender system, thus resembling the trust bias phenomenon [Agarwal et al., 2019].\nTherefore, the probability for user u to select item i \u2208 I at step t is given by:\n$P_t(i|u) = \\gamma \\cdot P_t^r(i|u) + (1 - \\gamma) \\cdot P_t^o(i|u)$\nwhere\n$P_t^o(i|u) = \\eta \\cdot \\frac{1}{|I|} + (1 - \\eta) \\cdot P^o(i|u)$\n$P_t^r(i|u) = \\begin{cases} \\delta \\cdot P^r(i|u) + (1 - \\delta) \\cdot P^o(i|u) & \\text{if } i \\in L_t \\\\ 0 & \\text{otherwise} \\end{cases}$\nHere, $P_t^r(i|u)$ represents the probability of selecting the item based on the score provided by the recommendation algorithm, while $P^o(i|u)$ is the probability of picking it by following the natural preferences of the user. We define them as:\n$P^r(i|u) = \\frac{R_{\\Theta}(i)}{\\sum_{j\\in L_t} R_{\\Theta}(j)}$\n$P^o(i|u) = \\frac{||p_u - \\hat{a}_i|| - \\min_{j\\in L_t} (||p_u - \\hat{a}_j||)}{\\max_{j\\in L_t} (||p_u - \\hat{a}_j||) - \\min_{j\\in L_t} (||p_u - \\hat{a}_j||)}$\nThe linear combination of these two components is weighted in Equation 2 using the inertia parameter $\\delta \\in [0,1]$. Intuitively, if $\\delta = 1$, the user blindly follows the recommendations provided at each round, resembling the trust bias phenomenon [Agarwal et al., 2019]; conversely, if $\\delta = 0$, the user selects the item based on their preferences only, i.e., by following the organic model; finally, if 0 < $\\delta$ < 1, the choice is conditioned by both the user's interests and the recommendation score. We denote the selected item as $i^*$."}, {"title": "3.4 Evaluation", "content": "Through our simulation framework, we are interested in studying the way user preferences evolve in the long term. We refer to this phenomenon as \"algorithmic drift\", and we further introduce two novel metrics in order to quantify it.\nAlgorithmic Drift Score. As aforesaid, it can be expressed as the tendency of the recommendation algorithm to alter user preferences after multiple interactions. In other words, assuming that content in a platform can be tagged as"}, {"title": "4 Experiments", "content": "In this section, we study how the simulation framework and the proposed metrics act when dealing with different behavioral users patterns. Specifically, we aim at empirically addressing the following research questions:\nRQ1. Can the proposed methodology (simulation framework and related metrics) effectively quantify drifts in users' leaning due to recommendation algorithms?\nRQ2. How robust is such an approach to different behavioral users patterns, i.e., resistance, inertia, and randomness?\nMotivating Use Case. For the experimental evaluation of our methodology, as a practical use case, we devise a scenario where items are categorized as either harmful or neutral, i.e., $i \\in {I_h, I_n}$, and users are divided into three sub-populations: non-radicalized, semi-radicalized, and radicalized, according to the percentage of harmful content they exhibit. Items are here intended as harmful in a broad sense, without referring to any specific semantic field. In other words, they can spread to whatsoever kind of content (noxious, explicit, inappropriate), e.g., violence, misinformation, pornography, and hate speech. In this respect, radicalized users can also be considered as prone to a high consumption rate of harmful content.\nTherefore, in this setting, the objective is evaluating the algorithmic drift induced over users w.r.t. the harmful category, i.e., quantifying the radicalizing pathways encountered by non-radicalized users, after interacting with the algorithm in the long-term. In order to do this, Equation 7 can be easily adapted by fixing the target category as h, as follows:\n$ADS(G^u) = Pr(I_n|I_h) \\cdot Pr(I_n|I_n) - Pr(I_n|I_n) \\cdot Pr(I_n|I_h)$\nNotably, the ADS score can now assume values in the range [-1, 1], these being the corresponding preference poles of non-radicalized and radicalized users, respectively. Therefore, intuitively, the higher the drift effect, the more the"}, {"title": "4.1 Data Generation", "content": "To validate the effectiveness of our framework, we employ synthetically generated data, which allows us to reproduce different scenarios with great flexibility at low cost [Leskovec et al., 2010, Smith et al., 2017, Chaney et al., 2018]. Specifically, we rely on a synthetic procedure introduced by Coppolillo et al. [2024b], where users and items latent features are sampled from a Dirichlet distribution, while Long-Tail distributions are employed to mimic items' popularity and users' engagement. Finally, the likelihood of an interaction between a user u and an item i is proportional to the dot product of the two latent vectors, combined with popularity of i and engagement of u.\nThe aforesaid procedure provides great customizability in terms of both data distributions and users/items group partition. First, we impose users and items to follow power-law patterns, with parameters \u03b1 = 2.2 and \u03b1 = 2.0, respectively. Further, as aforesaid, we split items into two categories: harmful and neutral, respectively, and users into non-radicalized, semi-radicalized, and radicalized, according to the following assumptions: a non-radicalized user shows a percentage of harmful interactions in the range [0, 0.2]; a semi-radicalized user, a percentage in the range (0.2, 0.8); a radicalized user, a percentage in the range [0.8, 1].\nFinally, we ensure that the polarized communities (i.e., non-radicalized and radicalized users) share a certain amount of interactions with the semi-radicalized sub-population, by using the parameters setting as suggested by Coppolillo et al. [2024b].\nTo validate the robustness of our methodology, we generate three data samples exhibiting an increasing portion of semi-radicalized users: (i) 5%, 90%, 5%, (ii) 20%, 60%, 20%, and (iii) 33%, 33%, 33%, respectively for non-radicalized,"}, {"title": "4.2 Settings", "content": "For the experiments, we adopt RecVAE, a collaborative filtering algorithm based on Variational Auto Encoder (VAE) and developed by Shenbin et al. [2020]. The model has been implemented using the Recbole library [Zhao et al.]. We trained the recommender system for 100 epochs setting a hidden dimension equal to 512. To obtain training, validation, and test sets, the dataset has been split with a ratio of 80/10/10. All the code and data used to perform the experiments are publicly available\u00b3."}, {"title": "4.3 Results", "content": "Varying population proportion. First, we investigate the impact of the semi-radicalized sub-population in the sample, which (by construction) is supposed to act as a sort of \"bridge\" between the two polarized communities, by triggering the collaborative filtering nature of the underlying algorithm, and thus fostering the drift effect. To assess if the proposed framework and metrics are able to capture this effect, we fix the resistance (\u03b3) and inertia (\u03b4) parameter across the three sub-populations, and compare the results with the organic model, i.e., the natural evolution of users preferences without the intervention of any recommender system. In particular, we set \u03b3 = 0.1 and \u03b4 = 0.5. Figures 4 and 5 show the results in terms of Algorihmic Drift Score (ADS) and Delta Target Consumption (DTC), respectively.\nNotably, the two metrics provides complementary information with respect to the target category: while the DTC rate quantifies the consumption increment in the final user history, the ADS provides a probabilistic perspective computed over the interactions graph.\nImpact of resistance and inertia. Further, we conduct a more fine-grained analysis on the effects of varying the user behavioral factors \u03b3 (resistance) and \u03b4 (inertia).\nAs mentioned in Sections 1 and 3.3, we denote the resistance as the user hesitancy in relying on the recommender: the higher, the more prone the user is to autonomously select an item from the catalog; conversely, the inertia models"}, {"title": "5 Conclusions and Future Work", "content": "In this paper, we proposed a novel stochastic model for studying potential deviations of users' preferences due to the influence of recommendation systems in the long term. We denote this phenomenon as \u201calgorithmic drift\", and we introduce two novel metrics, namely Algorithmic Drift Score and Delta Target Consumption, in order to quantify it. Further, our framework provides great flexibility in representing user behaviors throughout the simulation process, by modeling behavioral patterns such as user resistance to recommendations, inertia in following the provided suggestions, and choice randomness due to exogenous hence uncontrollable factors.\nOur main contributions can be indeed summarized as follows: (i) the definition of the algorithmic drift concept and the introduction of two novel metrics in order to quantify it; (ii) the implementation of a stochastic model for analyzing the impact of recommender systems in the long term; and (iii) an extensive evaluation through a practical use-case based on a collaborative-filtering algorithm, showing the model's capabilities across different scenarios. The ultimate result is a robust controlled environment for evaluating the recommendation algorithm before deployment.\nThe proposed framework is amenable for further extensions in many different directions. First, we assume the items catalog to be fixed, while a more dynamic setting could be considered where novel items are continuously introduced. Also, the proposed user model does not take into account contextualization. In the depicted use case, items are categorized as either harmful or neutral. However, more realistic scenarios can embrace situations where items are tagged as harmful depending on the user features or the recommendation context. Moreover, radicalization and harmfulness can also be considered according to specific ideological axes upon which users and items can be aligned. A final line of further investigation is the adaptation of the proposed methodology to study other typical weaknesses that can occur in a recommendation setting, such as popularity bias and/or diversity and serendipity."}]}