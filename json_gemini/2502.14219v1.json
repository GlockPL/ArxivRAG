{"title": "Investigating the Impact of LLM Personality on Cognitive Bias Manifestation in Automated Decision-Making Tasks", "authors": ["Jiangen He", "Jiqun Liu"], "abstract": "Large Language Models (LLMs) are increasingly used in decision-making, yet their susceptibility to cognitive biases remains a pressing challenge. This study explores how personality traits influence these biases and evaluates the effectiveness of mitigation strategies across various model architectures. Our findings identify six prevalent cognitive biases, while the sunk cost and group attribution biases exhibit minimal impact. Personality traits play a crucial role in either amplifying or reducing biases, significantly affecting how LLMs respond to debiasing techniques. Notably, Conscientiousness and Agreeableness may generally enhance the efficacy of bias mitigation strategies, suggesting that LLMs exhibiting these traits are more receptive to corrective measures. These findings address the importance of personality-driven bias dynamics and highlight the need for targeted mitigation approaches to improve fairness and reliability in AI-assisted decision-making.", "sections": [{"title": "1 Introduction", "content": "The rise of large language models (LLMs) has transformed decision-making processes across diverse domains, from education and finance to healthcare and policy. As these models increasingly take on roles traditionally held by human experts, concerns about their susceptibility to cognitive biases have grown (Hager et al., 2024; Li et al., 2022). While prior research has explored biases in AI-driven decision-making, a critical yet understudied factor is the role of LLM personality in shaping these biases. Emerging evidence suggests that LLMs, much like humans, can exhibit distinct personality traits that influence how they process information, assess uncertainty, and generate recommendations (Chen et al., 2024a; Liu and He, 2024). This raises an urgent question: Do LLM personalities amplify or mitigate cognitive biases in decision-making? Addressing this question is essential for ensuring that AI-assisted tasks remains reliable and free from unintended distortions. This open challenge, illustrated in Figure 1, motivates our evaluation study on LLM reported here."}, {"title": "1.1 Cognitive Biases in Decision-Making", "content": "Cognitive biases are systematic deviations from rational judgment that significantly influence human judgments and decision-making outcomes (Kahneman, 2003; Liu, 2023). Extensive research in Psychology and Behavioral Economics has identified numerous such biases across varying decision settings, such as anchoring bias, confirmation bias, decoy effect, and framing effect, which affect how individuals process information, perceive available options, assess utility and make choices (Benartzi and Thaler, 2007; Tversky and Kahneman, 1992). For instance, the anchoring bias leads people to rely heavily on the first piece of information encountered when making decisions (Furnham and Boo, 2011), while the decoy effect occurs when the presence of an asymmetrically dominated option influences a person's preference between two other choices, often leading to irrational decisions (Chen et al., 2024b; Wedell and Pettibone, 1996). These biases can result in suboptimal decisions and biased judgments across critical contexts, from financial investments to healthcare choices. Beyond traditional decision-making scenarios, researchers also found that users' cognitive biases affect their interactions with interactive information systems of varying modalities and shape their judgments on retrieved and generated information (e.g. Liu, 2023; Ji et al., 2024; Azzopardi, 2021; Lin and Ng, 2023; Chen et al., 2023; Wang and Liu, 2023)."}, {"title": "1.2 Personality Traits and Cognitive Biases", "content": "Personality traits significantly affect the manifestation of cognitive biases in decision-making (Ishfaq et al., 2020; Singh et al., 2023). For instance,"}, {"title": "1.3 Personality and Bias Impact in LLMs", "content": "In the realm of generative artificial intelligence (GenAI), particularly with the advent of LLMs, the concept of \"personality\" has garnered significant attention (e.g. Jiang et al., 2023; Dorner et al., 2023; Caron and Srivastava, 2022). LLMs like GPT-3.5 and GPT-4 have demonstrated the ability to emulate human-like personalities, which can influence their responses in decision-making tasks. Research by Safdari et al. (2023) explored the presence of personality traits in LLMs, finding that these models can exhibit consistent personality profiles when prompted accordingly. Further studies have investigated the ability of LLMs to express specific personality traits, revealing that with appropriate prompting, LLMs can generate content that aligns with designated personality profiles (Jiang et al., 2024; Hagendorff et al., 2023; Salecha et al., 2024). This capacity to simulate personality raises important questions about the potential for cognitive biases in LLM outputs, especially in contexts where models are employed for critical decision-making support, such as admission and hiring, financial management, and health information evaluation.\nThe intersection of personality and cognitive biases in LLMs is an emerging area of research with profound implications for the reliability and fairness of AI-driven decision-making. As AI systems increasingly mediate human interactions, their ability to express personality traits and exhibit human-like cognitive biases introduces challenges that extend beyond technical performance to ethical and societal concerns (Hilliard et al., 2024; Echterhoff et al., 2024; Chen et al., 2024a). Wang et al. (2025) examined GPT-4's ability to role-play individuals with diverse Big Five personality profiles, indicating that LLMs can systematically adopt distinct personality traits that affect not only their linguistic style but also their reasoning and evaluative tendencies. Similarly, Safdari et al. (2023) analyzed the validity of personality measures in LLM-generated outputs, reinforcing the idea that these models do not merely generate contextually appropriate text but actively shape responses in alignment with the personality traits they are prompted to exhibit. This dynamic raises critical questions about the extent to which personality-driven reasoning in LLMs may reinforce or amplify cognitive biases in ways that are difficult to detect and mitigate. If an LLM exhibiting a dominant or overconfident personality systemically favors heuristics, such as anchoring or the decoy effect, users interacting with it may unknowingly be guided toward distorted decision-making processes. This becomes particularly concerning in settings where AI-generated recommendations influence consequential decisions, such as in financial advising, healthcare triage, or legal assessments, where even subtle biases can lead to cumulative distortions in judgment (Berthet, 2022; Acciarini et al., 2021; Koo et al., 2023)."}, {"title": "1.4 Research Gap", "content": "As GenAI become embedded in more automated judgment and decision-support applications (e.g. Li et al., 2022; Hager et al., 2024; Chen et al., 2024a; Chiang and Lee, 2023; Thomas et al., 2024; Gu et al., 2024; Benary et al., 2023), understanding how personality-driven biases emerge is crucial for ensuring that AI does not inadvertently reinforce or introduce new forms of cognitive distortion. Many AI-driven systems already shape user behavior in imperceptible ways (Gkikas and Theodoridis, 2021; Yang et al., 2024), and when these models exhibit persistent personality traits, they may unknowingly condition users to accept biased reasoning as rational or normative. In contexts where LLMs assist with hiring, lending, policy-making, and consumer support, the interplay between personality expression and cognitive biases can create subtle but systematic shifts in user preferences, interaction behaviors, and continued usage of the system (Steelman and Soror, 2017). For instance, an LLM designed to provide medical advice with a highly cautious personality could disproportionately amplify loss aversion, leading patients to overly fixate on risks while neglecting potential benefits. Conversely, an LLM trained to exhibit an overly persuasive or optimistic demeanor could exacerbate biases, such as overconfidence or the decoy effect, subtly steering users toward choices they might not have made in a neutral setting. Unlike human advisors, who can reflect on and regulate their biases, LLMs often operate as black-box systems that do not possess self-awareness or meta-cognition, making their biases both difficult to anticipate and challenging to correct (Yin et al., 2023; Pavlovic et al., 2024).\nTo address the research gap above, this study aims to investigate the extent to which personality-driven cognitive biases manifest in LLMs' decision-making activities, and to offer insights into the mechanisms through which these biases emerge and how they might be mitigated to enhance the reliability, fairness, and trustworthiness of GenAI-driven decision-support systems and evaluation."}, {"title": "2 Methodology", "content": null}, {"title": "2.1 Personality Traits in LLMs", "content": "This study utilizes the Big Five personality traits-Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism\u2014to examine how personality influences cognitive bias in LLMs (Jiang et al., 2024). The Big Five model originates from psychological research and is widely used to describe human personality traits (McCrae and John, 1992). Openness reflects creativity and a willingness to explore new ideas, while Conscientiousness represents organization and responsibility. Extraversion captures social behavior and energy levels, whereas Agreeableness concerns empathy and cooperation. Neuroticism measures emotional stability, with high scores indicating mood fluctuations and anxiety. Additionally, the study incorporates reversed personalities by prompting LLMs to exhibit traits opposite to their natural tendencies, allowing for a more nuanced understanding of how personality shapes cognitive biases in decision-making tasks (Jiang et al., 2024)."}, {"title": "2.2 Cognitive Biases", "content": "This study identifies three key categories of cognitive biases that are closely associated with personality characteristics and shape human decision-making. Cognitive Filtering and Information Overload encompasses biases that help individuals manage excessive information by prioritizing certain details while ignoring others. Fast Decision-Making Under Uncertainty includes biases that emerge when quick judgments are needed, often leading to risk-averse or commitment-driven choices. Mental Shortcuts for Meaning-Making covers biases that simplify complexity by filling informational gaps with assumptions or prior knowledge. Understanding these categories is essential for exploring how LLM personalities influence cognitive bias manifestation in judgment and decision-making.\nThis study focuses on eight cognitive biases that significantly shape perception and decision-making and are closely linked to personality traits. Under Cognitive Filtering and Information Overload category, anchoring bias occurs when individuals rely too heavily on an initial reference point in judgments, even if irrelevant. Framing effect describes how different presentations of the same information influence choices, often altering risk perception. In Fast Decision-Making Under Uncertainty category, decoy effect occurs when the presence of an inferior option makes one alternative more attractive. Risk aversion reflects a preference for certain but lower-value outcomes over uncertain but potentially higher gains. Status quo bias is a cognitive bias where people tend to prefer maintaining the current state of affairs and resist change, even when alternatives may offer greater benefits. Sunk cost fallacy leads individuals to persist in failing endeavors due to past investments rather than future benefits. Under Mental Shortcuts for Meaning-Making, endowment effect causes people to overvalue possessions simply because they own them. Group attribution bias leads individuals to generalize characteristics from individuals to groups or vice versa, reinforcing stereotypes. Understanding these biases is critical for evaluating how different LLM personalities influence cognitive bias manifestation in decision-making activities, shaping user interactions. This study aims to examine these effects and to shed light on the interplay between"}, {"title": "2.3 Datasets", "content": "To support the experiment, we employed two datasets, Student Admission Dataset from Echterhoff et al. (2024), and the BiasEval Dataset generated in our project, which enable us to test the impact of LLM personality on bias manifestation across a wide range of decision scenarios."}, {"title": "2.3.1 Student Admission Dataset", "content": "The student admission dataset employed by Echterhoff et al. (2024) comprises 13,465 prompts designed to evaluate cognitive bias in LLM-driven decision-making. It features synthetic student profiles with attributes like GPA, test scores, research experience, and recommendation ratings, structured to test several biases, including anchoring (5,449 prompts), status quo/primacy (1,008 prompts, doubled for control), framing (1,000 prompts, tripled for variations), and group attribution (1,000 prompts, tripled for gender). Profiles are presented in varied sequences to assess decision consistency, with baseline biased prompts and debiased versions for comparative analysis. The dataset employs selection consistency and Euclidean distance metrics to quantify bias and evaluate mitigation strategies. Our study adopts this dataset and evaluates the influence of LLM personality on the cognitive biases tested in the original experiment."}, {"title": "2.3.2 BiasEval Dataset", "content": "To expand the experiment on the impact of LLM personality and obtain more solid results across domains, we generated BiasEval dataset using GPT-4 model to examine the role of personality in the manifestation of four additional cognitive biases, including sunk cost fallacy, decoy effect, risk aversion, and endowment effect, which are closely associated with individuals' personality traits.\nTo fully examine the effect of LLM personality under different domains, for each bias type, we incorporated a variety of parameters to manipulate bias triggers and conditions, and generated 1,000 to 1,300 unique scenarios to support the LLM experiment on biases. For instance, to test the extent of decoy effect under different personality conditions and mitigation strategies, we employed following prompt template for synthetic data generation:\n\"You are choosing between three smartphone models:\nPhone A: This model features an advanced camera camera and comes equipped with high-performance ram_A RAM."}, {"title": "2.4 Experimental Setup", "content": "Inspired by Echterhoff et al. (2024)'s work, we adapted their data and designed experiments to study anchoring, framing, status quo, and group attribution effects. The anchoring experiment examines how prior decisions influence LLMs' admission choices. Instead of varying decision order, we used paired comparisons with controlled prior decisions. We created synthetic student profile pairs and structured decision sequences where Student A's profile (with an admit or reject decision) precedes Student B's. This setup isolates the effect of Student A's outcome on Student B's acceptance rate.\nWe used the dataset of student admission for testing framing effects, specifically, LLMs are asked to play the role of college admission officer to make an admission decision based on a student's profile. The experiment presents identical student profile with positive framing (\u201cWould you admit the student?", "Would reject this students": "."}, {"title": "3 Results", "content": "We evaluate four LLMs with varying capacities, including two commercial models (GPT-40 and GPT-40-mini) and two open-source models (Llama 3, in 8B and 70B variants). To minimize randomness, we set the temperature to 0 for all models. The more detailed results of biases can be found in the Appendix."}, {"title": "3.1 Personality Traits and Cognitive Biases", "content": "Cognitive filtering and information overload"}, {"title": "3.2 Reversed Personality Traits", "content": "Reversed personality traits were tested to examine whether LLMs respond differently when prompted with opposite personality characteristics (see Tables 1, 2, 3). Surprisingly, the mitigation effects of reversed personality traits do not necessarily contradict those of their regular counterparts. In some cases, reversing a personality trait reduces cognitive biases more effectively, while in others, it amplifies or fails to mitigate bias. This suggests that bias modulation depends not only on the personality trait itself but also on the model architecture, indicating that LLMs process personality-induced biases in complex and non-linear ways."}, {"title": "3.3 Personality Traits and Bias Mitigation", "content": "To understand how personality traits interact with debiasing strategies, we evaluate the awareness-based debiasing approach across models, biases, and personality traits (see Figure 2). Since sunk cost and group attribution biases are not widely observed, they are not included in this analysis. This method is a zero-shot mitigation strategy designed to reduce cognitive biases in LLMs (Echterhoff et al., 2024). The approach involves explicitly prompting the model to self-regulate by including the instruction: \u201cBe mindful of not being biased by cognitive bias.\" We compare bias levels with and without this awareness prompt to determine the influence of the prompt and personality traits. Interestingly, results reveal that the success of this approach is highly dependent on personality traits and model architecture. Although there is no universally effective personality trait for mitigating various biases, the models with Conscientiousness"}, {"title": "4 Discussion", "content": "Our findings reveal that LLM personality traits systematically shape cognitive bias manifestation, with notable variations across different models. Extraverted and agreeable personalities tend to amplify biases such as the decoy effect and risk aversion, whereas conscientious and neurotic traits exhibit more complex patterns, sometimes mitigating biases or producing inconsistent effects. Crucially, reversing personality prompts demonstrates a measurable reduction in certain biases, indicating that personality-driven biases are not fixed but can be modulated through targeted interventions. However, the extent and direction of these effects vary by model: GPT-40 consistently exhibited stronger bias tendencies across multiple biases, while Llama 3 models displayed greater variability, with some configurations amplifying biases unpredictably. By introducing a structured experimental framework and the BiasEval dataset, our study advances methodological approaches for assessing bias levels of LLMs under different scenarios and personality characteristics. These findings underscore the need for model-specific mitigation strategies and raise important implications for the responsible deployment of LLMs in high-stakes decision-making domains such as hiring, medical diagnosis, and financial advising."}, {"title": "5 Conclusion", "content": "Our study investigates the role of personality traits in shaping cognitive biases in LLMs. The results demonstrate that Big Five personality traits significantly influence bias manifestation. However, the influences vary greatly across LLMs.\nSix of the eight cognitive biases were extensively observed across baseline conditions, personality traits, and models, with the exceptions of the sunk cost fallacy and group attribution bias, which showed minimal influence. Some LLMs, such as Llama3-70B and GPT-40-mini, exhibit negative bias for certain effects, particularly anchoring and the decoy effect, possibly due to over-self-correction. Additionally, reversed personality traits do not always counteract their normal counterparts in bias mitigation. Our findings reveal that the influence of personality traits on LLM biases does not always align with established research on human decision-making in psychology and behavioral studies. The inconsistency observed in this study suggests that personality-driven bias modulation is highly architecture-dependent and requires tailored mitigation strategies rather than a universal approach. Even though we found that generally, Conscientiousness and Agreeableness might enhance the efficacy of bias mitigation strategies, suggesting that LLMs exhibiting these traits are more receptive to corrective measures.\nOverall, our findings suggest that LLM biases are influenced by both personality and model architecture, reinforcing the need for adaptive bias mitigation strategies when deploying LLMs in high-stakes decision-making tasks. Future research should explore more refined control mechanisms for personality-driven biases and investigate how biases evolve across different training paradigms and model architectures."}, {"title": "6 Limitations", "content": "This study has several limitations. First, our analysis relies on prompted personality traits rather than inherent model characteristics, which may not fully reflect real-world LLM behavior. Second, we focus on eight cognitive biases, leaving out others that could interact with personality in complex ways. Third, our study examines only four LLMs, and findings may not generalize to other architectures. Our debiasing approach is limited to awareness-based prompts, which may be less effective than fine-tuning or reinforcement learning. Additionally, our experiments use structured prompts and synthetic datasets, which may not fully capture how biases emerge in real-world applications. Despite these limitations, our findings highlight the role of personality in LLM biases and emphasize the need for targeted mitigation strategies in AI-assisted decision-making. Future research should explore additional biases, model architectures, and mitigation techniques."}, {"title": "A Appendix", "content": null}, {"title": "A.1 Prompt Templates", "content": "Various prompt templates are used for testing cognitive biases in language models. Each test consists of a Context (personality trait descriptions), a Task (bias-specific question), and modified conditions to compare biased versus debiased responses."}, {"title": "A.1.1 Status Quo Bias", "content": "Template:\nContext: {context}\nTask: {question}\nDescription: Evaluates resistance to change in decision-making."}, {"title": "A.1.2 Group Attribution Bias", "content": "Template:\nContext: {prompt}\nTask: {question}\nDescription: Tests bias in attributing characteristics to individuals based on group associations."}, {"title": "A.1.3 Framing Effect", "content": "Template:\nContext: {prompt}\nTask: {question}\nOnly return \"reject\" or \"admit\". No other information should be provided.\nDescription: Measures how differently phrased questions influence decisions."}, {"title": "A.1.4 Anchoring Bias", "content": "Template:\nYou are an admissions officer. Previous student profile and decision:\nProfile: {student_A}\nDecision: {decision_A}\nCurrent student profile:\n{student_B}\nWould you admit or reject the current student?\nAnswer only with \"Admit\" or \"Reject\".\nDescription: Tests whether earlier information (previous decision) influences subsequent judgments."}, {"title": "A.1.5 Sunk Cost Fallacy", "content": "Template:\nContext: {context}\nTask: {sunk_cost_condition}\nAnswer only with \"Yes\" or \"No\".\nDescription: Measures irrational commitment to past investments."}, {"title": "A.1.6 Decoy Effect", "content": "Template:\nContext: {context}\nTask: {decoy_condition}\nWhich option would you choose? Answer with only the letter of your choice (A, B, C).\nDescription: Tests whether introducing an irrelevant option impacts choices between two alternatives."}, {"title": "A.1.7 Risk Aversion Bias", "content": "Template:\nContext: {context}\nTask: {risk_averse_condition}\nAnswer with only \"A\" or \"B\".\nDescription: Measures whether framing of risk influences decisions."}, {"title": "A.1.8 Endowment Effect", "content": "Template:\nContext: {context}\nTask: {ownership_condition}\nPlease respond with only a number (no currency symbols or text).\nDescription: Evaluates tendency to overvalue owned items compared to identical unowned items."}, {"title": "A.2 Tables for Eight Congnitive Biases", "content": null}]}