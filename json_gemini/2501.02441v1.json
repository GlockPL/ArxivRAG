{"title": "A Statistical Hypothesis Testing Framework for Data Misappropriation Detection in Large Language Models", "authors": ["YINPENG CAI", "LEXIN LI", "LINJUN ZHANG"], "abstract": "Large Language Models (LLMs) are rapidly gaining enormous popularity in recent years. However, the training of LLMs has raised significant privacy and legal concerns, particularly regarding the inclusion of copyrighted materials in their training data without proper attribution or licensing, which falls under the broader issue of data misappropria-tion. In this article, we focus on a specific problem of data misappropriation detection, namely, to determine whether a given LLM has incorporated data generated by another LLM. To address this issue, we propose embedding watermarks into the copyrighted train-ing data and formulating the detection of data misappropriation as a hypothesis testing problem. We develop a general statistical testing framework, construct a pivotal statistic, determine the optimal rejection threshold, and explicitly control the type I and type II er-rors. Furthermore, we establish the asymptotic optimality properties of the proposed tests, and demonstrate its empirical effectiveness through intensive numerical experiments.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) are rapidly gaining enormous popularity in the past couple of years, thanks to their transformative ability to process and generate human-like text. The ver-satility and scalability of LLMs are driving widespread adoption, and are revolutionizing fields such as healthcare, education, and finance with applications in content generation, data analy-sis, customer support, and research automation [20]. However, alongside their vast potential, the training of LLMs has raised significant privacy and legal concerns, particularly regarding the inclusion of copyrighted materials in their training data without proper attribution or licens-ing [19, 28]. These concerns fall under the broader issue of data misappropriation, namely, the unauthorized use, access, or exploitation of data by individuals or entities for unintended or unpermitted purposes, often in violation of governing regulations. Data misappropriation has been central to several high-profile debates. One example is the lawsuit between the New York Times and OpenAI [26]. Another example lies in OpenAI's Terms of Service, which explicitly prohibits using ChatGPT's output to develop competing models, raising the need for a mechanism to detect whether a newly trained LLM has incorporated data generated from ChatGPT. Detection of such data misappropriation is challenging though, especially when the probabilistic nature of LLMs generates content that may resemble, but does not directly copy, original works [24, 12]. Such challenges underscore the importance of developing methods to identify and trace machine-generated text, and have recently generated considerable research interest in this area [23, 15, 18, 22, 14, 33, 31]. In this article, we aim to address a crucial question in data misappropriation detection in LLMs, i.e., How can one determines whether a given LLM has used data generated by another LLM as part of its training corpus?\nWatermarking is a technique used to embed identifiable patterns into the generated text, enabling traceability to distinguish AI-generated content from human-authored text [3]. This is typically achieved by subtly modifying token generation probabilities to favor specific words or patterns without compromising text coherence. There have been numerous watermarking techniques developed for LLMs in recent years, which can be broadly categorized as biased techniques [2, 30, 16], and unbiased techniques [1, 11, 8, 13, 32, 29]. The former explicitly alters token probabilities, favoring a predefined set of tokens to embed traceable patterns, and often introducing detectable statistical biases in the text. The latter ensures the watermark signal is embedded without introducing noticeable deviations from the model's natural token distribution, preserving the text's statistical properties.\nIn this article, we focus on a specific problem of data misappropriation detection, i.e., to determine whether a given LLM has incorporated data generated by another LLM. To address this issue, we propose embedding watermarks into the copyrighted training data and formu-lating the detection of data misappropriation as a hypothesis testing problem. We develop a general statistical testing framework, construct a pivotal statistic, determine the optimal rejec-tion threshold, and explicitly control the type I and type II errors. Furthermore, we establish the asymptotic optimality properties of the proposed test, and demonstrate its empirical effec-tiveness through intensive numerical experiments. Our proposal introduces a number of novel components and makes several unique contributions to the field."}, {"title": "Problem Setup", "content": "In this section, we introduce the background and problem setup.\nLanguage models are equipped with a vocabulary W, which consists of words or word fragments called tokens. Typically, a vocabulary contains |W| = 50,000 tokens or more. In this article, we denote the number of tokens in the vocabulary by |W| = m. For the simplic-ity of presentation, we simply assume W = [m] in this article. To generate text, a language model requires a sequence of tokens that constitutes a prompt. In the generated text, the entries with nonpositive indices, W\u2212Lp, W\u2212Lp+1, . . ., W\u2081, represent the prompt, with a length of Lp + 1. The entries with positive indices, w\u2081, . . ., \u03c9\u03c4, are tokens generated by the language model in response to the prompt. A language model for next-token prediction (NTP) is a function f, often parameterized by a neural network, which takes as input a sequence of known tokens, W_Np, W\u2212Np+1,..., Wt\u22121, comprising the prompt and the first t 1 tokens generated by the model. The output is an m-dimensional multinomial distribution, which represents the prob-ability distribution for the next token. Formally, let Pt := (Pt,1, Pt,2, ..., Pt,m) denote this multinomial distribution at step t, conditioned on the prompt and previously generated tokens. As a valid probability distribution, Pt satisfies that $\\sum_{i=1}^{m} P_{t,i} = 1$.\nWatermarking is a technique for adjusting the NTP distribution so that the generated text exhibits specific statistical properties, which can then be leveraged for detection. The key in-sight is that the text generated by a watermarked LLM adheres to the watermarking generation rules, whereas the human-written text does not follow these patterns. In this way, watermarks function as markers of an LLM's generation rules, inspiring a method for distinguishing a wa-termarked LLM from an unwatermarked one based on a given text. This principle forms the"}, {"title": "A Statistical Framework", "content": "In this section, we formally introduce our statistical framework, including the hypotheses, the pivotal statistic, and the derivation of the rejection threshold."}, {"title": "Hypotheses and Pivotal Statistics", "content": "Let n \u2208 N denote the text length. Let W1:n := W\u2081\u00b7\u00b7\u00b7Wn and $1:n := $1\u00b7\u00b7\u00b7 \u00cen denote the gen-erated text and the secret keys, respectively. Given a prompt W\u2212Np:0 and a text W1:n generated by the LLM under investigation, we target the problem of whether this LLM utilizes the data generated by another watermarked LLM, in the form of hypotheses:\n$\\begin{aligned}\nH_0: & \\text{W}_{1:n} \\text{ is generated by the LLM without data misappropriation;} \\\\\nH_1: & \\text{W}_{1:n} \\text{ is generated by the LLM with data misappropriation.}\n\\end{aligned}$ (1)\nIn addition, the secret keys are generated using the hash function A, in that (t = A(w-Np:(t-1)). The knowledge of A is only available to the victim and the detector, but not the suspect. As such, 1:n are regarded as random variables by the suspect, but are viewed deterministic by the victim and the detector, since they can be calculated by previous tokens plus the knowledge of the hash function. Meanwhile, the watermarked LLM generates the next token according to the rule, wt ~ S(Pt, (t), for some decoding function S, and Pt represents the NTP distribution of the unwatermarked LLM given the prompt and previous tokens.\nNext, we mathematically formulate complete inheritance and partial inheritance."}, {"title": "Complete Inheritance", "content": "Definition 1 (Complete inheritance). The suspect's LLM follows the same generation rule as the victim's LLM, in that the hash function A and the decoding function S of both LLMs are the same if data misappropriation occurs.\nUnder the complete inheritance setting, the hypotheses in (1) become\n$\\begin{aligned}\nH_0: & \\text{w}_t |\\zeta_t \\sim P_t, \\\\\nH_1: & \\text{w}_t |\\zeta_t \\sim S(P_t, \\zeta_t), \\\\\n\\end{aligned}$ (2)\nfor t = 1,2,..\u2026\u2026, \u043f.\nIn practice, a newly trained LLM that incorporates data generated by a watermarked LLM produces outputs with a distribution that preserves certain patterns of the watermarked distri-bution, but not identical. This scenario is captured by the following partial inheritance setting."}, {"title": "Partial Inheritance", "content": "Definition 2 (Partial inheritance). There exists an upper bound for the total variation (TV) distance between the probability distribution of data generated by the suspect's LLM under data misappropriation, and the probability distribution of data generated by the victim's wa-termarked LLM, in that $TV_{\\cdot |\\zeta_t} (w_t, S(P_t, \\zeta_t)) \\le 1 - \\theta$, where 1 \u2013 0 quantifies the upper bound on the allowable difference between the two distributions.\nUnder the partial inheritance setting, the hypotheses in (1) become\n$\\begin{aligned}\nH_0: & \\text{w}_t |\\zeta_t \\sim P_t; \\\\\nH_1: & TV_{\\cdot |\\zeta_t} (\\omega_t, S(P_t, \\zeta_t)) \\le 1 - \\theta, \\\\\n\\end{aligned}$ (3)\nfor t = 1,2,...,n. We also briefly remark that, for the detection task to be feasible, the constant @ cannot be too small, as an overly small @ would imply that the two distributions are too similar to differentiate.\nNext, we describe the distribution of \u03c9\u03c2 under H\u2081. In commonly used watermarking techniques, S(P, C) can only take finitely many values. We provide further discussion in later sections when applying this framework to specific watermarking techniques. Let k de-note the total possible values of S(P, C), and partition the space of (P, C) into multiple re-gions, A1, A2, . . ., Ak, such that in each region A\u00bf, the corresponding multinomial distribution S(P, C) is identical, and is represented by a multinomial probability vector (sil, Si2, . Sim), for i \u2208 [k]. We further assume that, for any t \u2208 [n], and all (P, \u03da) \u2208 A, the distribution of w in the partial inheritance setting is the same, which is represented by (qt,i1, qt,i2, ..., qt,im), re-gardless of the exact values of (P, C). This assumption simplifies the theoretical discussion and allows us to represent the extreme points using a feature matrix. Notably, this assumption can be relaxed without compromising the validity of our theoretical results; see a more detailed discussion in Remark 1. Now, we formally define the feature matrix, whose rows describe different possible distributions of \u03c9\u03c2.\nDefinition 3. Define the feature matrix under the null Ho as S = (Sij)kxm, and the feature matrix under the alternative H\u2081 at token t as Qt = (qt,ij)kxm\nThe feature matrix allows us to directly derive the distribution of pivotal statistics under the null and alternative hypotheses. Additionally, the use of the feature matrix helps the represen-tation of extreme points, and provides a more efficient framework for analysis. Importantly, we note that the order of rows in the feature matrix is arbitrary and does not affect the results."}, {"title": "Rejection threshold", "content": "For our testing method, it is crucial to choose an appropriate score function h(\u00b7) and the thresh-old Yn to ensure the optimality of the test. Next, we consider two rejection rule designs sepa-rately. We first fix the type I error at a predefined level and seek to maximize the asymptotic efficiency. We then aim to asymptotically minimize the sum of the type I and type II errors.\nWe first consider the setting of the fixed type I error, where we choose the threshold Yn, such that $P_{H_0} (T_h(Y_{1:n}) = 1) = \\alpha$ for a pre-specified significance level a, while we will choose an optimal score function h(\u00b7) later to maximize the asymptotic power of the test. Our key idea is to turn the hypothesis testing problem to a minimax optimization problem. Toward that end, we have the following theoretical results.\nTheorem 1 (Fixed type I error). We consider the complete inheritance setting and the partial inheritance setting, respectively.\n(a) (Complete inheritance). Suppose Pt \u2208 P for all t. For any h satisfying Eoh < \u221e, where Eo denotes the expectation under Ho, the type II error of the rejection rule Th satisfies that\n$\\lim_{n\\rightarrow \\infty} \\sup_{P} P_{H_1} (T_h (Y_{1:n}) = 0)^{1/n} < e^{-R_P(h)},$ (4)\nwhere $R_P(h) = - \\inf_{\\theta>0} \\sup_{P\\in \\mathcal{P}} {\\theta E_0h(Y) + log \\phi_{P,h}(\\theta)} = - \\inf_{\\theta\\ge 0} {\\theta E_0h(Y)+\\sup_{P} log \\phi_{P, h}(\\theta)}$, $\\phi_{P,h}(\\theta) = E_{1,P}e^{-\\theta h(Y)}$, and $E_{1,P}$ denotes the expectation under H\u2081 that depends on P. Here P is a distribution class whose specific form is specified"}, {"title": "Feature Matrix", "content": "We first derive the feature matrix for the Gumbel-max watermark. Recall that, for the Gumbel-max watermark, the secret key (t consists of |W| i.i.d. copies (Ut,w)wew ~ U(0,1), while the tokens are generated by the rule w\u2081 = arg maxw\u025bw log Ut,w/Pw. As the detector has the knowledge of the hash function, the generating process becomes a deterministic process. In other words, if the detector knows the value of t as well as the NTP distribution Pt, one can directly determine what the next token is. As a result, the corresponding multinomial distribution S(Pt, $t) can at most take |W| = m possible choices, implying that k = m in Definition 3. We now derive the feature matrix in the Gumbel-max watermarking case."}, {"title": "Complete Inheritance", "content": "In the complete inheritance, we choose the pivotal statistic Y\u2081 as the random number Ut,wt, which corresponds to the selected token wt at step t. We derive the distribution of Yt. It is worth noting that the distribution results for Y\u2081 in the complete inheritance setting are already established in the prior literature.\nTheorem 3. (adapted from [21]) Under the null hypothesis Ho, we have Y+ ~ U(0,1), and $P_{H_0}(Y_t \\le r|P_t) = r$, for r \u2208 [0,1]. Under the alternative hypothesis H\u2081, we have $P_{H_1}(Y_t < r/P_t) = \\sum_{w\\in W} P_{t,w} r P_{t,w}$, for r \u2208 [0, 1].\nNext, we obtain the optimal score function for the fixed type I error setting and the sum of type I and type II errors setting, respectively. We choose the distribution class as P\u25b3 := {P : maxi\u2208[m] Pi \u2264 1 \u2013 \u0394} for \u2206 \u2208 [0,1 \u2013 m\u00af\u00b9]."}, {"title": "Partial Inheritance", "content": "Similar to the complete inheritance setting, we choose the pivotal statistic Y\u2081 as the random number Ut,wt, and first derive the distribution of Yt.\nTheorem 6. Under the null hypothesis Ho, we have $P_{H_0}(Y_t < r|P_t, Q_t) = r, for r \\in [0,1]$.\nUnder the alternative hypothesis H\u2081, we have $P_{H_1}(Y_t \\le r|P_t, Q_t) = \\sum_{i=1}^{k} [\\sum_{j \\in A_i} 1{(r - r_i)P_i < Q_j}\\frac{r_j P_j} {m}] q_{ij} +  \\sum_{i=1}^{k} \\frac{1}{m} P_i r_i q_i$  forr \u2208 [0, 1]. Moreover, it holds that $P_{H_1} (Y_t \\le r|P_t, Q_t) \\le r$.\nNext, we derive the optimal score function for both the fixed type I error setting and the setting that minimizes the sum of type I and type II errors. While the approach for deriving the optimal score function under the partial inheritance setting shares similarities with that of the complete inheritance setting, it introduces several new technical challenges, with convexity being the most significant.\nIn the complete inheritance setting, convexity plays a key role in simplifying the problem. Specifically, the problem can be reduced to considering only the extreme points due to the convexity of the objective function. This convexity can be directly demonstrated by the positive"}, {"title": "Feature Matrix", "content": "Recall that, for the red-green-list watermark, the secret key \u015ct is a subset D C {1,2,...,m} satisfying that |D| = \u03b3\u00b7 m for some \u03b3 \u2208 (0,1). In partial inheritance case, the distribution of wt conditional on Pt and \u0120t is given by,\n$S(P_t, \\zeta_t) = (P_{t,1} \\frac{1{1 \\in \\zeta_t}}{\\sum_{i\\in \\zeta_t} P_{t,i}} ,..., P_{t,m}\\frac{1{m \\in \\zeta_t}}{\\sum_{i\\in \\zeta_t} P_{t,i}})$.\nUnder this scheme, wt|Pt, St follows a multinomial distribution,\n$P(\\omega_t = k|P_t, \\zeta_t) = P_{t,k} \\frac{1{k \\in \\zeta_t}}{\\sum_{i\\in \\zeta_t} P_{t,i}}.$\nUnlike the Gumbel-max watermarking technique, the red-green-list watermarking technique is not deterministic, even when conditioned on Pt and St.\nProposition 2. Let k = $\\binom{m}{\\gamma m}$, and A1, A2,..., Ak, k = $\\binom{m}{\\gamma m}$ denote all subsets of {1,2,\u2026, m} containing \u03b3\u00b7 m elements. Then, for for t \u2208 [n], the feature matrices at token t under the null and alternative hypotheses are as follows.\n(a) (Complete inheritance). Under Ho, the feature matrix is Mp = $\\begin{pmatrix}\nP_1 \\\\\n... \\\\\nP_t\n\\end{pmatrix}$ \u2208 Rkxm. Under\nH1, the feature matrix is $\\begin{pmatrix}\nS_{t,1} \\\\\nS_{t,2} \\\\\n...\n\\end{pmatrix}$, where $S_{t,i} = (P_{t,1} \\frac{1{1\\in A_i}}{\\sum_{i\\in A_i} P_{t,i}}, ..., P_{t,m} \\frac{1{m\\in A_i}}{\\sum_{i\\in A_i} P_{t,i}})$.\n(b) (Partial inheritance). Under Ho, the feature matrix is Mp. Under H1, the t-th feature matrix belongs to the class  $\\begin{pmatrix}\nQ_{t,1} \\\\\nQ_{t,2} \\\\\n...\n\\end{pmatrix}: TV(Q_{t,i}, S_{t,i}) \\le 1 - \\theta$. \nIn the following, we analyze the complete inheritance and partial inheritance settings sepa-rately. In both cases, the pivotal statistic is Y\u2081 = 1{wt \u2208 (t}. Since Y\u2081 can only take the value 0 or 1, any score function h(\u00b7) will yield a test statistic equivalent to counting the number of times Y\u2081 = 1. Specifically, the test statistic \u2081h(Y\u2081) corresponds to counting the occurrences of {wt \u2208 (t}. Thus, for this watermarking technique, the specific form of the score function h(.) does not affect the outcome of the hypothesis testing. As a result, the testing procedure is determined by the number of instances where wt \u2208 St."}, {"title": "Complete Inheritance", "content": "In the case of complete inheritance, the distribution of the pivotal statistic Y\u2081 under the null and alternative hypotheses is as follows.\nTheorem 9. For t \u2208 [n], under the null hypothesis Ho, we have P(Y\u2081 = 0) = 1 \u2212 \u03b3, P(Y\u2081 = 1) = y; under the alternative hypothesis, H\u2081, we have P(Y\u2081 = 1) = 1.\nThis result highlights the distinct behavior of Y\u2081 under the two hypotheses. Under Ho, Yt is a Bernoulli random variable with parameter \u03b3, reflecting the random selection process for subsets in the red-green-list watermarking scheme. In contrast, under H\u2081, Y\u0141 always equals 1, as the complete inheritance ensures that every token wt is fully aligned with the watermarking process.\nDenote the rejection set as R = {(W1:n, $1:n): \u03a3=1 Yt \u2265 Yn}. We can change the value of the threshold Yn to determine the rejection rule.\nTheorem 10. We consider the fixed type I error setting and the sum of type I and type II errors setting, respectively.\n(a) In the setting of fixed type I error with a, the optimal threshold value is given by\nYn = n\u00b7 \u03b3 + \u221a\u03b7\u03b3(1 \u2013 \u03b3)\u03a6\u00af\u00b9(1 \u2013 \u03b1).\n(b) In the setting where we aim to minimize the sum of type I and type II errors, the optimal threshold is Yn = n."}, {"title": "Partial Inheritance", "content": "In the partial inheritance setting, the token wt conditional on \u011ci follows a multinomial distribu-tion with parameter Qt = (qt,i1,..., qt,im). The distribution of Y is as follows.\nTheorem 12. Under the null hypothesis Ho, we have P(Y\u2081 = 0) = 1 \u2212 \u03b3, P(Y\u2081 = 1) = \u03b3. Under the alternative hypothesis H\u2081, we have\n$P(Y_t = 1) =  \\sum_{i=1}^{\\binom{m}{\\gamma m}} \\frac{1}{m}\\sum_{j\\epsilon S_i} q_{ij} \\ge \\theta,   P(Y_t = 0) \\le 1 - \\theta.$\nThis result reflects the additional complexity of the partial inheritance setting. Under Ho, Y remains a Bernoulli random variable with parameter \u03b3. However, under H\u2081, the probability P(Y\u2081 = 1) is influenced by the distributions Qt and the constraint TV (wt|St, S(Pt, $t)) \\le 1\u22120. We now introduce our proposed optimal test scheme by specifying te optimal rejection region.\nTheorem 13. We consider the fixed type I error setting and the sum of type I and type II errors setting, respectively. Given \u03b8 \u2265 \u03b3.\n(a) In the setting of fixed type I error with a, the optimal threshold value is given by\nYn = n\u00b7 \u03b3 + \u221a\u03b7\u03b3(1 \u2013 \u03b3)\u03a6\u00af\u00b9(1 \u2013 \u03b1).\n(b) In the setting where we aim to minimize the sum of type I and type II errors, the optimal threshold is given by\n$Y_n = [n \\cdot \\frac{log(1 - \\gamma) - log(1 - \\theta)}{log \\theta + log(1 - \\gamma) - log \\gamma - log(1 - \\theta)}].$ (10)\nNext, we establish the optimality for our proposed tests."}, {"title": "Numerical Studies", "content": "In this section, we numerically investigate the detection of data misappropriation with two watermarking schemes: Gumbel-max and red-green-list. For the Gumbel-max watermarking scheme, we compare the performance of our proposed testing method with baseline testing methods. First, we fix the type I error at a constant level and compare the type II error across all methods. Next, we evaluate the sum of type I and type II errors for each testing scheme. These evaluations are conducted for both the complete inheritance case and the partial inheritance case, corresponding to two distinct datasets."}, {"title": "Gumbel-max Watermark", "content": "In our simulation, we generate a vocabulary W of size 1,000 and evaluate the type I and type II errors in watermark detection methods for generated token sequences. We compare our proposed method with baseline methods with other score functions hars(r) = -log(1 - r) and hiog = logr. Here, we note that hars is the score function proposed by Aaronson that was considered at OpenAI [1]. Recall that our proposed optimal score function is $h_{opt,\\Delta} = log(\\frac{1}{r^{1-\\Delta}+ r^{\\frac{\\Delta}{1-\\Delta}}})$ where $\\Delta = (1 - \\Delta) \\cdot [\\frac{1}{1- \\Delta}]$, as we developed in Theorem 4.\nFor a given text length T, we first generate 5,000 samples of unwatermarked word to-ken sequences. Each unwatermarked token is uniformly sampled from the vocabulary W. Throughout these 5,000 repeated experiments, we compute the average type I error. Similarly,"}, {"title": "Red-Green-list Watermark", "content": "In this section, we present numerical studies for the red-green-list watermarking scheme. Fol-lowing a similar setup to the Gumbel-max watermark experiments, we generate a vocabulary W of size 1,000 and evaluate the Type I and Type II errors in watermark detection methods for generated token sequences. The NTP distributions in both the complete inheritance and partial inheritance cases are 1,000-dimensional multinomial distributions. No restrictions are imposed on these distributions, and the parameter y used for simulation is set to 0.5, meaning that we have green and red lists with equal length.\nIn the complete inheritance case, each secret key (t is a subset of {1, 2, . . ., 1000} contain-ing 500 elements. The secret keys are selected randomly based on a random seed determined by the previous five tokens. Conceptually, this process divides the vocabulary into two groups, with half of the tokens designated as the green list and the other half as the red list.\nGiven NTP distribution Pt = (Pt,1, Pt,2,..., Pt,1000) and the secret key St, the adjusted distribution is calculated as:\n$S(P_t, \\zeta_t) = (P_{t,1} \\frac{1{1 \\in \\zeta_t}}{\\sum_{i\\in \\zeta_t} P_{t,i}} ,..., P_{t,1000}\\frac{1{1000 \\in \\zeta_t}}{\\sum_{i\\in \\zeta_t} P_{t,i}})$.\nThis process effectively samples tokens exclusively from the green list at each step. For unwatermarked texts, tokens are randomly sampled from {1, 2, . . ., 1000}, and secret keys are chosen independently.\nIn the partial inheritance case, the adjusted distribution S(Pt, (t) needs to satisfy the TV distance constraint. We set the parameter 0 = 0.8, and the TV distance constraint between \u03c9\u03c2 and S(Pt, $t) is set to 1 \u2013 0. To satisfy this constraint, we adjust the probabilities for the green and red tokens as follows: the sum of probabilities for the green list is set to 1 0, while the sum for the red list is set to 0. The resulting probability distribution qt = (qt,1, qt,2,..., qt,1000) is\n$q_{t,i} = \\frac{P_{t,i}1{i \\in \\zeta_t}}{\\sum_{i\\in \\zeta_t} P_{t,i}} \\cdot (1 - \\theta) + \\frac{P_{t,i}1{i \\notin \\zeta_t}}{\\sum_{i\\notin \\zeta_t} P_{t,i}} \\cdot \\theta.$\nAs derived in the optimal tests for red-green-list watermarking, the specific form of the score function h(\u00b7) does not influence the hypothesis testing outcome. Any score function will yield a test statistic equivalent to counting the number of instances where Y\u2081 = 1. Conse-quently, in the fixed type I error setting, all test procedures based on different score functions are effectively identical, eliminating the need to compare different score functions. In the fol-lowing, we present numerical evaluations of our method under both the fixed type I error setting and the setting aimed at minimizing the sum of type I and type II errors.\nIn the fixed Type I error setting, Figure 4 demonstrates that the Type I errors empirically align closely with the nominal level of 0.05, converging as the text length increases in both the complete and partial inheritance settings. This behavior aligns with our theoretical guarantees for asymptotic Type I error control. Additionally, in both settings, the Type II errors decrease rapidly to 0. In fact, in our theoretical derivation, it is easy to compute the Type II error of our optimal test, given by $P(Z < \\frac{(\\gamma-\\theta)\\sqrt{n}}{\\sqrt{\\gamma(1-\\gamma)}}  \\frac{\\theta \\sqrt{n}}{\\sqrt{\\gamma(1-\\gamma)}}(1 - \\alpha))$, where Z is a standard normal random variable. When @ is close to 1, $\\frac{\\theta \\sqrt{n}}{\\sqrt{\\gamma(1-\\gamma)}}$ becomes large, leading to a rapid decay of the Type II error. This behavior highlights the efficiency of our testing method, particularly for cases where the TV distance constraint is tight.\nWe now consider the case of minimizing the sum of type I and type II errors. In the setting of complete inheritance, again, we can see the sum of type I and type II errors drop quickly to 0. In the setting of partial inheritance, recall that we generate the data with 0 = 0.8. To construct different testing procedures, we vary the values of @ used for the rejection region threshold in (10). Figure 5 (right) shows the comparison for different testing procedures with \u03b8\u2208 {0.7, 0.8,0.9, 0.95}. As shown in the right figure, the optimal sum of Type I and Type II errors is achieved when the chosen @ matches the true value used for data generation."}]}