{"title": "Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation", "authors": ["Yunwen Xia", "Hui Fang", "Jie Zhang", "Chong Long"], "abstract": "Conversational recommender system (CRS), which combines the techniques of dialogue system and recommender system, has\nobtained increasing interest recently. In contrast to traditional recommender system, it learns the user preference better through\ninteractions (i.e. conversations), and then further boosts the recommendation performance. However, existing studies on CRS ignore\nto address the relationship among attributes, users, and items effectively, which might lead to inappropriate questions and inaccurate\nrecommendations. In this view, we propose a knowledge graph based conversational recommender system (referred as KG-CRS).\nSpecifically, we first integrate the user-item graph and item-attribute graph into a dynamic graph, i.e., dynamically changing during\nthe dialogue process by removing negative items or attributes. We then learn informative embedding of users, items, and attributes by\nalso considering propagation through neighbors on the graph. Extensive experiments on three real datasets validate the superiority of\nour method over the state-of-the-art approaches in terms of both the recommendation and conversation tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommender systems have been widely applied in our daily life, including e-commerce, music and movies, restaurants,\nand online news, etc. Traditional recommender systems infer user's preference based on user's interaction history or\nthe history of similar users, which generally suffers from the cold-start problem and faces the challenge of dynamic\nuser preference. In this case, [5] proposed conversational recommender system (CRS), which integrates the techniques\nof dialogue system and recommender system, and has attracted numerous research interest in recent years. That is,\ncompared to traditional recommender systems, CRS learns user's preference through several turns of communication (i.e.,"}, {"title": "2 RELATED WORK", "content": "In this section, we mainly discuss two folds of related work: (1) conversational recommender system; and (2) knowledge\ngraph (KG)-based recommender system."}, {"title": "2.1 Conversational Recommender System", "content": "As introduced before, the existing studies on CRS can be concluded into two categories, since the work of [5].\nThe first line focuses on the understanding and generation of conversations from the perspectives of NLP and\nconsiders the semantic information in CRS [4]. Specifically, it attempts to understand users' utterances and merge\nrecommended items into textual sentences generated by CRS. Thus, users are allowed to express their questions\nmore freely, meanwhile the system's responses are more in a human language form. For example, Li et al. [15] and\nRadlinski et al. [18] collected datasets consisting of real-world conversations to facilitate the NLP research on CRS. The\nwork of [16] considered the item-attribute graph for multiple recommendation tasks (e.g., both hotel and restaurant\nrecommendations), while Zhou et al. [34] semantically fused both item-oriented graph and word-oriented graph for\nCRS. Yu et al. [28] further combined NLP with visual information.\nThere are two main drawbacks with existing studies of this category: (1) the training process relies heavily on the\nmanually collected natural language data, which might hinder its usability to a new domain where new data should be\ncollected to retrain the corresponding methods from scratch. Besides, it ignores to well explore the \"strategy\" in CRS;\nand (2) user's interaction history is not well utilized in the previous studies in this category. As a result, a CRS system\nmay generate similar conversations for different users, which is thus not personalized.\nAnother line of research emphasizes the effective \"strategy\" in CRS, which includes four main sub-tasks: \"when to\nrecommend\", \"which items to recommend\", \"when to ask\", and \"which attributes to ask\". For example, Zou et al. [35]\nimproved the solution on \"which items to recommend\" via a novel matrix factorization model, and the task \"which\nattributes to ask\" was addressed through Generalized Binary Search (GBS). For the other two sub-tasks, it chooses to\nkeep asking until the size of candidate items is smaller than the size of recommendation list or the maximum number of\nquestions is reached. Such \"strategy\" is similar to Max Entropy in [20] and the method in [2, 36-38], the main difference\nis the recommendation module. Bi et al. [2] utilized the negative feedback during the conversation to improve the"}, {"title": "2.2 KG-based Recommender System", "content": "Traditional recommender system has been widely studied. These studies might be helpful for building an effective CRS,\nwhere the recommendation task is of great importance. We only explore the KG-based ones as they are most relevant to\nour study. Those studies that utilize KG to improve the performance of CRS [14, 16, 27, 34] have been introduced in\nSection 2.1, thus, their recommendation module will not be repeatedly discussed here. We merely review the KG-related\ntraditional recommender systems here.\nSome studies [10, 24, 30] directly utilize mature Knowledge Graph Embedding (KGE) methods to integrate side\ninformation for recommendation. For example, Zhang et al. [30] combined the structural data (graph), textual data\nand visual data to improve the item representations, where the structural data is explored using TransR [17]. Wang et"}, {"title": "3 PROPOSED MODEL", "content": "In this section, we present our KG-CRS model in great detail by first simply formulating the multi-round recommendation\nscenario."}, {"title": "3.1 Problem Formulation", "content": "The same as [13], we focus on the multi-round recommendation scenario where a CRS interacts with a user multiple\ntimes (together arranged as a session) by either asking attributes or recommending items until the user is satisfied\nwith the recommendation or chooses to leave the session without a satisfactory recommendation. It should be noted\nthat, similar to [13, 14, 20, 32], the conversation process adopts \"System ask, User Respond\" pattern. That is to say, a\nconversation session is mostly driven by the system, except for the beginning and the end of the session. More detailed\nprocess is shown in Figure 1, and the main notations are summarized in Table 1.\nSpecifically, at the beginning of each session, user u firstly specifies a favorable attribute p (from the set of attributes\nP describing items on the platform, p \u2208 P), and the CRS shortlists the candidate items containing attribute Vp C V.\nNext, in each round (turn), the CRS conducts an action a \u2208 A: asking attribute or making recommendation. That is, for\nthe action of making recommendation, if the user accepts the recommendation, the session will be terminated at the\ncorresponding round. Otherwise, the recommended items are considered as negative items, and we move to the next\nround. On the other hand, for the action of asking attribute, if the user considers the asked attribute in this round is\nirrelevant to her preference, the attribute will be marked as negative attribute and we also move to the next round,\notherwise the attribute is considered as positive attribute. The action space |A| is equal to Ng + 1, where Nq represents"}, {"title": "3.2 The KG-CRS Framework", "content": "The framework of our KG-CRS is demonstrated in Figure 2. Specifically, it consists of a dynamic knowledge graph\nand two modules, a conversation module and a recommendation module. The dynamic graph consists of three types\nof entities (namely user, item, and attribute) and three types of corresponding relations (denoted as user-item, item-\nattribute, and user-attribute). Its content will change (i.e. removing negative items and negative attributes) during\na conversation session and will be reset when a new session starts. The conversation module encodes the current\nstate and decides an action (asking attribute or making recommendation) according to the current state, while the\nrecommendation module will give recommendations from the candidate items when the conversation module decides\nto make recommendation. Both conversation and recommendation modules rely on the informative embedding learned\nfrom the dynamic graph, i.e., to encode the current state in conversation module, and to calculate the recommendation\nscore of each candidate item. In this framework, a conversation session is both started and ended by a user, and the user\nwill give responses when the CRS agent asks questions. Noted that, similar to [13, 14], we skip the Natural Language\nUnderstanding (NLU) and Natural Language Generation (NLG) in our model."}, {"title": "3.2.1 Graph Embedding Learning", "content": "As shown in Figure 3, there are three types of entities (namely user, item, and\nattribute) and three types of corresponding relations (denoted as user-item, item-attribute and user-attribute) in the\ngraph G = {(h,r,t)|h,t\u22088,r \u2208 R}, where h, t represent entities (head and tail respectively), and v represents\nrelations. Every (entity, relation, entity) triple means that there is a relationship between entity h (e.g., user) and\nentity t (e.g., item), for example, user 'Neil' was interested in item 'Baby Cakes'. Inspired by [8, 25, 26], the learning\nprocess of embedding is divided into two stages, node feature and information propagation. The design of dynamic\ngraph is to prevent negative items and negative attributes from affecting other related entities' representation during the\ninformation propagation process.\nNode Feature. This stage is to learn the vector representation of each entity and relation in the graph. We use a\ntranslation-based method, TransD [7, 11], as it performs better on describing the structure of knowledge graph. TransD\nassumes that er' + er \u2248 et' if triple (h, r, t) exists in the graph, where er', et' are the embedding of entity h, t, and\nex is the embedding of relation . Such assumption is achieved by optimizing the score function:\n\\(f(h, r,t) = ||eh' + er \u2013 et'||2\\) (1)\nwhere eh' = Mrher and et' = Mrtet. Mrh and Mrt, as defined in Equation 2, are the projection matrices, which\nassure that each type of entity have different representations for different relations. er, et are the embedding of entity\nh, t without projection, respectively. The score f(h, r, t) is low if there is a triple (h, r, t), and high otherwise.\n\\(Mrh = mm\u00b2 + I; M\u00f8t = m,m\u00b2 + I\\) (2)\nwhere mh, mt and my represent the projection vectors to determine corresponding projection matrices, and I is the\nidentity matrix to initialize the projection matrices."}, {"title": "2.2.2 Recommendation Module", "content": "The main objective of this module is to obtain recommendation scores of candidate\nitems (Vcand) based on the graph embedding, and simultaneously measure the loss function for graph embedding"}, {"title": "3.2.3 Conversation Module", "content": "Conversation module encodes current state and make decisions, including asking attributes\nor making recommendation, according to the current state. The policy network, which is used to make decisions, is\na multi-layer perceptron and optimized via the policy gradient method of reinforcement learning [22]. We will first\nintroduce the design of the state vector in our KG-CRS, and then explain the details of the policy network. It is to be\nnoted, as we have stated, graph & is dynamic during the conversation process, which might directly affect the result\nof Equation 7, and then further influence the recommendation results and the state vector in conversation module.\nIn particular, in triples (h, r, t), negative entities in Pneg and Vneg are removed from &, so that the information of\nthese negative entities will not influence the recommendation and conversational results. For example, considering\ntwo candidate items 21 and 22 in the current session, and item v\u2081 is much more similar to item 03 than 02. On the other\nhand, item 03 was chosen by user u in the history, but rejected by u in the current session. In this case, if item 03 is still\ninvolved in the graph &, item v\u2081 may get a higher score than v2 because it is more similar to item 03 in the history.\nTherefore, in order to address this issue, we update graph & each turn by removing the negative entities (e.g., item 03)\nand resume it for every new session. In this example, we only remove item 03 but its related attributes will still exist in\nthe graph. Consequently, for every related attribute p, it only loses one relation with 23 in embedding learning, but can\nstill propagate its information by other relations.\nState Vector. As defined in Equation 10, state vector consists of four components, entropy-based probability sent,\nuser-based probability suser, conversation-based probability sconv and dialogue feature sdial. The first three parts\ncalculate the probability of which attribute to ask from three different perspectives. The fourth part records the situation"}, {"title": "3.3 Time Complexity Analysis", "content": "The main operations in our method are listed as follows:\n\u2022 Operation 1: node feature learning. It locates in lines 5-7 in Algorithm 1\n\u2022 Operation 2: information propagation and score calculation. It lies in lines 9-16 in Algorithm 1 and line 6\nin Algorithm 2.\n\u2022 Operation 3: updating weight ah,r,t. It refers to lines 2 and 19 in Algorithm 1.\n\u2022 Operation 4: encoding state vector. This operation locates in line 7 in Algorithm 2.\n\u2022 Operation 5: taking action. It refers to line 8 in Algorithm 2.\n\u2022 Operation 6: updating graph structure (i.e., removing negative items and negative attributes). It lies in\nline 29 in Algorithm 2.\nThe time complexity of these operations are summarized in Table 3, where N = |U| + |V| + |P|, m is the embedding\nsize, n is the batch size, nhid is the hidden size of the policy network and other notations are shown in Table 1. The\nexperiments are conducted with NVIDIA Tesla K80 and 2 CPU core (2.20GHZ)."}, {"title": "4 EXPERIMENTS", "content": "In this section, we conduct experiments on three real-world datasets to validate the effectiveness of our proposed\nKG-CRS, with the goal of answering three research questions:\n\u2022 RQ1: How does our KG-CRS perform compared with other state-of-the-art approaches in terms of both recom-\nmendation task and conversation task?\n\u2022 RQ2: How do different components of KG-CRS contribute to the performance?"}, {"title": "4.1 Experiment Settings", "content": "4.1.1 Datasets. We conduct experiments on three datasets: Yelp2, LastFM\u00b3 and Amazon\u2074. All these datasets provide rich\ninformation about users and items, including user's interaction history with items, item's price, and item's categories."}, {"title": "4.1.2 User Simulator and Conversation Setting", "content": "As our CRS is dynamic and the consideration of real users is costly,\nwe follow [13] to create a user simulator to replace real users for the model training and testing. The user simulator\nrandomly samples an attribute of the ideal item as the beginning of the conversation and gives a response according to\nthe question or the recommendation in the following turns. We use the multi-round recommendation setting, which\nmeans that the user will not quit when the recommendation fails until the predefined maximum number of rounds T\nreaches. Same as [13, 14], the agent will recommend K items (i.e., K = 10) each time. T is set as 15 if not specifically\nidentified in the following experiments.\nAs illustrated in [13], there are generally two kinds of questions in CRS: binary question and enumerated question,\nwhich are also referred to as yes/no question and open question in some other literature [27] respectively. The former\none may ask questions like 'Are you in Washington?' while the latter one may ask like 'Which city are you in?'.\nPlatforms can determine to use which kind of question setting according to their engineering and business needs. For\nfair comparisons, we follow [13] to test our model with both two settings. Specifically, the experiments on Yelp is\nconducted with enumerated question, while on LastFM and Amazon is binary question. Moreover, 590 attributes on\nYelp are categorized into 29 facets given the enumerated setting, which means Nq on Yelp is equivalent to 29, namely\nthe action space equals to 30. Given the binary setting on LastFM and Amazon, one question is related to one attribute\nand Ng on LastFM and Amazon thus equals 33 and 115 respectively, and thus the action space on is equal to 34 and 116\nrespectively."}, {"title": "4.1.3 Baselines", "content": "Although there are numerous works [5, 13-15, 18, 20, 27, 32, 34, 35] on CRS, as discussed in Section 2,\nmany of them [15, 18, 27, 32, 34, 35] have different settings or focuses from our study. For example, [18] constructed a\nsystem which interacts with users like a chat-bot rather than a task-oriented system. [15, 34] focused on the NLP and\nsemantic information. Thus, we compare our performance with the following most related baselines since their settings\nand research focus are much closer to ours:\n\u2022 Abs Greedy [5]: The main idea of the dialogue strategy for this method is to keep making recommendations\nwithout asking any questions. To better compare this rule-based dialogue strategy with the trained policy network\nin KG-CRS, the recommendation module in this method is the same as that in KG-CRS.\n\u2022 Max Entropy [20]: This method is also designed for the dialogue strategy and chooses to ask the attribute that\nhas the maximum entropy among the candidates in each turn. The recommendation is randomly triggered by the\nlength of the candidate item list. While the length gets shorter, it becomes more likely to do the recommendation.\nSimilar to Abs Greedy, the recommendation module in this method is also the same as that in KG-CRS.\n\u2022 CRM [20]: The dialogue strategy in this method is decided by a neural network using a reinforcement learning\nframework, and the recommendation module is fulfilled by Factorization Machine(FM). It is originally designed\nfor the single-round recommendation scenario. We adapt it to the multi-round recommendation scenario by\nfollowing the process of [13].\n\u2022 EAR [13]: Similar to CRM, the conversation module and the recommendation module of this method also\nrely on reinforcement learning and FM respectively. Different from CRM, it is applied in the multi-round\nsetting and proposes a three-stage solution called Estimation-Action-Reflection framework which updates the\nrecommendation module according to the conversation module.\n\u2022 SCPR [14]: This is the state-of-the-art method on CRS under the multi-round setting. It is built on EAR and\nfurther considers the graph-based conversational path reasoning to help narrow the candidate set of attributes\nand items."}, {"title": "4.1.4 Parameters Setup", "content": "Following [13, 20], the parameters of our framework is initialized with offline data firstly and\nthen optimized online through the user simulator. The parameters of graph embedding can be pre-trained using the\ngraph. It is worth mentioning that there is no available conversation data on Yelp, LastFM and Amazon for initializing\nthe parameters of the policy network. The studies of [13, 31] choose to let the policy network mimic the strategy of Max\nEntropy, whereas in our KG-CRS, besides the Max-Entropy strategy, we also propose to let the policy network mimic\nthe ground truth of this problem. Specifically, in policy network pretrained phase, as shown in Figure 4, assuming that\nuser 'Alice' wants to find item 'Lauryn Hill' through the CRS, it is better if the agent can ask attributes relating to\n'Lauryn Hill' precisely and then make the recommendation. As the unstable performance of reinforcement learning, we\nconsider this strategy can better initialize the parameters for the policy network in KG-CRS.\nIn KG-CRS, in graph embedding and recommendation module, the propagation step and embedding size of each step\nare set as 4 and 64 on Yelp, LastFM and Amazon, while the corresponding learning rate is 0.001 with the SGD optimizer.\nFollowing the parameter setting in [7], the margin parameter A in Equation 3 is set as 4. In the conversation module, on\nall datasets, if not specified, we mainly adopt the coarse-grained reward framework, and the rewards of ritem, rattr,\nrturn, and rquit are set as 1, 0.1, \u22120.01, and \u22120.3, respectively. \u1e9e is set as 0.1 for the fine-grained reward. The discount\nfactor y in Equation 15 is set as 0.7. The learning rate and optimizer on Yelp are 0.001 and SGD respectively, while these\ntwo hyper-parameters on LastFM and Amazon are 0.00001 and Adam respectively."}, {"title": "4.1.5 Evaluation Metrics", "content": "For evaluating the performance on recommendation task, we adopt the success rate (SR@T)\n[13, 20] to measure the ratio of conversations which have successfully recommended the ground-truth items by turn T.\nWe also specifically compare the performance of different approaches' recommendation modules on offline dataset\nusing Precision@K, Recall@K, NDCG@K, and AUC (area under ROC curve) metric. For evaluating the performance\non conversation task, similar to [13], we use the average turns (AT) needed to end the conversation-recommendation\nprocess. Besides, we also propose a new metric, the average positive action (APA) (either asking a favorable attribute or\nproviding successful recommendation), to measure users' satisfaction towards the conversation process. For SR, APA,\nPrecision@K, Recall@K, NDCG@K, and AUC, a larger number indicates better performance while smaller AT means\nmore efficient CRS."}, {"title": "4.2 Experimental Results", "content": "Here, we present our experimental results towards the aforementioned research questions."}, {"title": "4.2.1 Comparative Results (RQ1)", "content": "Tables 5 and 6, and Figures 5 and 6 present the comparative results between KG-CRS\nand other baselines."}, {"title": "4.2.2 Ablation Study (RQ2)", "content": "We consider three variants of KG-CRS where '-graphCon', '-graphRec', '-dynamic' denote\nthe model without graph on conversation module, the model without graph on recommendation module, and the\nmodel with static graph, respectively. The experimental results are presented in Table 7. As can be seen, first, under\nmost scenarios, the performance of KG-CRS is better than the other three variants. Specifically, KG-CRS performs"}, {"title": "4.2.3 Sensitivity of Hyper-parameters (RQ3)", "content": "We investigate the impact of the major hyper-parameters, including the\npropagation step, the embedding size of each step, the four numerical rewards in the policy network, the weight \u1e9e and\nthe discount factor y. We apply a grid search in the range of {1, 2, 3, 4}, and {16, 32, 64, 128} to test the impact of the\nfirst two hyper-parameters respectively. Weight \u1e9e is set in the range of {0.01, 0.02, 0.05, 0.07, 0.09, 0.1} to test its impact.\nFor discount factor y, we conduct a grid search in the range of {0.5, 0.7, 0.9, 1.0}. We vary the value of negative rewards\nrturn and rquit both in the range of {-0.3, -0.15, -0.1, 0.05, -0.01, 0}, while the value of positive rewards ritem and\nrattr in the range of {0, 0.1, 0.3, 0.5, 0.7, 1}. Figures 8-10 show the experimental results of the three hyper-parameters:\nthe propagation step, the embedding size, and y, respectively.\nAs can be seen, our approach is relatively insensitive to the three hyper-parameters. Specifically, as the propagation\nstep increases (Figure 8), KG-CRS performs slightly better in terms of SR@15 and APA on LastFM, while the performance\non Yelp, Amazon and AT of LastFM is relatively stable; with the increase of embedding size (Figure 9), KG-CRS gets better\nin terms of SR@15 on LastFM while other metrics are stable; while discount factor increases (Figure 10), the performance\nof KG-CRS will improve on Yelp only in terms of SR@15 and APA. For the reward design in the reinforcement learning,\nFigures 11-15 demonstrate that KG-CRS is relatively insensitive to the five hyper-parameters, except the rattr on Yelp.\nThis might be caused by that, there are originally 590 attributes on Yelp. In this case, a larger rattr is preferred if CRS\nagent identifies a positive attribute."}, {"title": "5 CONCLUSIONS", "content": "In this paper, we designed a knowledge-graph based CRS framework particularly for multi-round recommendation\nscenario to simultaneously improve the recommendation and conversation tasks. Specifically, we combined user-item\ngraph (built on historical interactions) and item-attribute graph, and dynamically updated the graph by removing\nnegative items and attributes identified by previous rounds in a session. We adopted the graph embedding learning\ntechnique on the dynamic graph to better model the interactive relationships among users, items and attributes, where\nthe learned corresponding embedding are integrated into the recommendation module and conversational module.\nExtensive experiments on three datasets validated that KG-CRS can perform better than the state-of-the-art approaches"}]}