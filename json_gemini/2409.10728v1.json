{"title": "Generalized Measures of Anticipation and Responsivity in Online Language Processing", "authors": ["Mario Giulianelli", "Andreas Opedal", "Ryan Cotterell"], "abstract": "We introduce a generalization of classic information-theoretic measures of predictive uncertainty in online language processing, based on the simulation of expected continuations of incremental linguistic contexts. Our framework provides a formal definition of anticipatory and responsive measures, and it equips experimenters with the tools to define new, more expressive measures beyond standard next-symbol entropy and surprisal. While extracting these standard quantities from language models is convenient, we demonstrate that using Monte Carlo simulation to estimate alternative responsive and anticipatory measures pays off empirically: New special cases of our generalized formula exhibit enhanced predictive power compared to surprisal for human cloze completion probability as well as ELAN, LAN, and N400 amplitudes, and greater complementarity with surprisal in predicting reading times.", "sections": [{"title": "1 Introduction", "content": "The prediction of upcoming linguistic units is posited to play a key role in human language comprehension (Federmeier, 2007; Willems et al., 2016; Goldstein et al., 2022). One fruitful method of operationalizing human uncertainty over predictions is through information-theoretic measures. Because human predictive mechanisms leave behavioral and neural traces that are observable during reading and listening (Kutas and Hillyard, 1984; Van Berkum et al., 2005; Forseth et al., 2020), the most common method of vetting an information-theoretic measure of predictive uncertainty is by examining its relationship with such traces. Beyond simply yielding good correlates, information-theoretic measures often provide insight into the human prediction mechanism, and they are thus central to much cognitive and neurobiological research on human language processing (Monsalve et al., 2012; Armeni et al., 2017; Wilcox et al., 2023)."}, {"title": "2 Generalized Surprisal", "content": "This section introduces our framework. First, we establish some key notation and definitions. Then, we present a decomposition of surprisal, which motivates our definition of generalized surprisal."}, {"title": "2.1 Language Modeling", "content": "An alphabet \u2211 is a finite, non-empty set of symbols, and its Kleene closure 2* is the set of all strings formed by concatenating symbols in \u2211, including the empty string \u20ac."}, {"title": "2.2 Generalizing Surprisal", "content": "The surprisal of a target w \u2208 \u03a3* given a context c\u2208 \u03a3* is defined as lp(w; c) def log \u03c0\u03c1(w | c).\nIn constructing our framework, we draw inspiration from the following decomposition of surprisal:\n\nl_{p}(w; c) def log \u03c0\u03c1(w | c)\n= - log \u2211 p(\u03c9\u03bd | c) (2a)\n\u03a5\u0395\u03a3* (2b)\n= - log \u2211 p(v | c)1{w \u2220 v}, (2c)\n\u03c5\u0395\u03a3*"}, {"title": "2.3 Anticipation and Responsivity", "content": "An important distinction between various generalized surprisal models is whether they characterize anticipatory or responsive online processes. These notions have been introduced informally by Pimentel et al. (2023). We give a formal definition of anticipation and responsivity below.\nDefinition 2 (Anticipation and Responsivity). We call a generalized surprisal model (f, g) anticipatory if g is constant in w, i.e., \u2200v, w, w', c \u2208 \u03a3*, we have g(v, w, c) = g(v, w', c). Otherwise, we call (f, g) responsive.\nDef. 2 differentiates anticipation, a state of uncertainty over possible outcomes that is fully determined by the context and the processor's language model, from responsivity, which expresses uncertainty for a specific next outcome."}, {"title": "3 Special Cases of Generalized Surprisal", "content": "In this section, we introduce concrete special cases of generalized surprisal (Eq. (4)), which we evaluate as predictors of human behavior and neural activity recorded during online language processing. Some of these have been previously used to predict such psycholinguistic data, while others are new. All special cases are designed by varying the three core components of our framework-anticipation vs. responsivity, scoring function, and warping function and are meant to exemplify how different hypotheses about online language processing can be instantiated as generalized surprisal models."}, {"title": "3.1 Responsive Measures", "content": "We start by introducing three responsive generalized surprisal models. These are models (f, g) where the scoring function g(v, w, c) is not constant in w (see Def. 2).\nSurprisal. The first generalized surprisal model we will consider is the pair (f, g) corresponding to standard surprisal (Eq. (2a) and (3)):\n\nf(x) = -log(x) (5a)\ng(v, w, c) = 1{w \u2220 v}. (5b)\nThe scoring function captures a binary notion of prediction accuracy, while the logarithmic warping function is classically considered to instantiate a view of online language processing where cognitive costs reflect the magnitude of incremental mental representation updates, which is related logarithmically to prediction accuracy (Levy, 2008)."}, {"title": "Probability", "content": "Replacing standard surprisal's logarithmic warping function with the identity function yields the contextual probability of the next unit:\n\nf(x) = x (6a)\ng(v, w, c) = 1 {w \u2220 v}. (6b)\nThe identity warping function can be seen as instantiating a facilitation view of online linguistic prediction, where prediction accuracy is linearly related to cognitive cost (Brothers and Kuperberg, 2021)."}, {"title": "Information Value", "content": "By replacing the indicator function of surprisal and probability with a scoring function dc: \u03a3* \u00d7 \u03a3* \u2192 R>0 that measures a graded, possibly context-sensitive notion of distance between strings, we obtain information value (Giulianelli et al., 2023):\n\nf(x) = x (7a)\ng(v, w, c) = dc(v, w). (7b)\nWhilst the use of a binary scoring function follows naturally from the surprisal model of cognitive cost, it results in a relatively simplistic notion of prediction accuracy which conflates different aspects of predictive accuracy and does not take into account the communicative equivalence of predictions and observations. In the information value model of cost (Giulianelli et al., 2023, 2024), instead, prediction accuracy is a continuous score that quantifies the representational distance between predictions and observations. For instance, if the predicted continuation is syntactically different but semantically equivalent to the observed next unit, this results in high syntactic and low semantic information value."}, {"title": "3.2 Anticipatory Measures", "content": "We now move to anticipatory generalized surprisal models, where the scoring function g(v, w, c) is constant in w; see Def. 2. We are not aware of any theoretical justifications for using non-linear warping functions for anticipatory measures, so all the special cases presented here will use the identity function f(x) = x.\nExpected Next-symbol Surprisal. We begin with a measure that was recently proposed to study"}, {"title": "3.3 Monte Carlo Simulation", "content": "For tractable estimation of generalized surprisal, which requires taking an expectation over continuations v \u2208 \u03a3*, we use Monte Carlo simulation:\n\ntp(w; c) def (1/N) \u03a3_{n=1}^{N} f(g(v^{(n)}, w, c)), (15)\nwhere v(n) ~ p(\u00b7 | c) are obtained via ancestral sampling. If f is continuous, then Eq. (15) is consistent. Moreover, if f(x) = x, the estimator is additionally unbiased. The variance of Eq. (15) depends on the scoring function g and the sample size N; in \u00a75.1, we study the influence of N on the variance of the estimator for different generalized surprisal models.\nSome special cases of generalized surprisal-in particular, surprisal, probability, and their expected next-symbol versions\u2014can be computed in closed form, and, for those, we do not need to rely on Monte Carlo simulation."}, {"title": "4 Experimental Setup", "content": "Dataset. We use the Aligned dataset (de Varda et al., 2023), which consists of M = 1726 target-context pairs from English novels annotated with several different neural and behavioral measurements. We include most of these in our experiments: cloze completions (probability and entropy), predictability ratings, event-related brain potentials (ELAN, LAN, N400, P600, EPNP, PNP), eye-tracked reading times (first-fixation time, first-pass time, right-bounded time), and self-paced reading times. Details on these measurements are given in App. A.1. Each target-context pair (w(m), c(m)), termed a stimulus, is associated with a real-valued measurement (w(m), c(m)), termed datum, which is an aggregation of per-subject measurements for that stimulus. In our experiments, we will compute generalized surprisal {tp(w(m), c(m))}M_1 for all stimuli in the dataset, and evaluate it as a predictor for the corresponding data {(w(m), c(m))}M_1. The contexts c are strings ranging from 5 to 14 words and targets w are strings corresponding to a single word.\nLanguage Models. We obtain generalized surprisal estimates from GPT-2 Small (Radford et al., 2019) and GPT-Neo 125M (Black et al., 2021). Prior work has shown that, despite exhibiting higher test perplexity, these two models have better psycholinguistic predictive power than larger ones (Oh and Schuler, 2023; Shain et al., 2024). Furthermore, their smaller size incurs a lower computational cost for sampling."}, {"title": "5 Empirical Analysis of Measures", "content": "We begin our experiments with an empirical analysis of Monte Carlo estimation for the measures presented in \u00a73. As alluded to earlier, sampling-based measures introduce variance that does not arise for measures like surprisal, which can be computed in closed form. This variance can be reduced by increasing the sample size (\u00a75.1), but that incurs additional costs in terms of runtime (\u00a75.2). In this section, we provide an empirical analysis of these properties to gain an understanding of their trade-off. We also investigate the correlations between different measures, in App. B, to assess the extent to which various theoretical models of anticipatory and responsive processing lead to divergent empirical uncertainty measurements. The analysis in this section is based on GPT-2 Small; results for GPT-Neo 125M are provided in Appendix App. \u0421."}, {"title": "5.1 Variation in Estimates", "content": "We use bootstrapping (Efron, 1992) to measure the variance of different estimators. For each stimulus (w(m), c(m)) in the Aligned dataset (\u00a74), given an original sample of size N \u2208 {2i | j = 2, 3, . . ., 9}, we obtain B = 1000 resamples of the same size by sampling with replacement. For entropy and expected information value, to yield tractable estimation, we limit the maximum length in tokens L\u2208 {5, 10, 15} of sampled continuations.\nIn a first analysis, we compute \u00b5m and \u03c3m as the mean and standard deviation of a measure of choice across the B resamples and calculate the coefficient of variation CVm = \u03c3m/\u00b5m. Fig. 1 (top) shows how average CV, as expected, decreases with N. The maximum sample length L has a limited effect on the CV of sequence-level measures. In a second analysis, to gauge the robustness of a given measure across a dataset of stimuli, we also calculate correlations between different resamples. For each measure, we obtain a matrix of M \u00d7 B estimates, and then compute a vector of (5) Pearson correlations between all two-column combinations. Fig. 1 (center) shows the average correlation coefficients as a function of increasing sample sizes. With the exception of entropy, which only reaches near-perfect correlation with N = 27, all measures show near-perfect correlation already with N = 25,"}, {"title": "5.2 Runtime", "content": "We study runtime using the same sample sizes N and maximum sequence lengths L as above, and for the same measures. Fig. 1 (bottom) displays the results. As expected, the runtime increases monotonically in both N and L. Comparing these results to those of the variance analysis suggests a good runtime-variance tradeoff can be obtained with a sample size N between 25 and 27."}, {"title": "6 Psycholinguistic Predictive Power", "content": "We now evaluate the generalized surprisal models introduced in \u00a73 in terms of their predictive power for the neural and behavioral data presented in \u00a74."}, {"title": "6.1 Evaluation", "content": "To quantify a measure's predictive power for a given data type {(w(m), c(m))}M_1 in the Aligned dataset, we use regression analysis. We compare a regressor that includes baseline predictors for {(w(m), c(m))}M_1, the baseline regressor, to one that further includes the measure of interest {tp(w(m), c(m))}M_1, the target regressor. Reading time regressors include target and baseline predictors not just for the target string but also the previous two words to account for spillover effects (Just et al., 1982; Frank et al., 2013a).\nFor the experiments on responsive measures (\u00a76.2.1), all regressors include three baseline predictors: the length of the target string w(m), its frequency, and the length of the context string c(m). We call this the default baseline. For the experiments on anticipatory measures (\u00a76.2.2), we use an additional baseline. Because expected next-symbol surprisal has proven to be most effective as a predictor when used in conjunction with surprisal (Pimentel et al., 2023), we compare the other, as yet untested, anticipatory measures against a baseline that includes both surprisal and expected next-symbol surprisal, along with the three baseline predictors mentioned above (the combined baseline). In the target regressor,"}, {"title": "6.2 Results", "content": "We now present our main results, obtained with GPT-2 Small, N = 2\u00ba, and L = 5 tokens."}, {"title": "6.2.1 Responsive Measures", "content": "The main results for responsive measures are visualized in Figs. 2 and 3. See Figs. 10 to 13 in App. D.2 for further results.\nCloze Completions and Predictability Ratings. These are the two types of psycholinguistic data in the Aligned dataset that more explicitly quantify uncertainty for the upcoming unit. Indeed, predictive power here is 1-2 orders of magnitude larger than for ERPs and reading times (Fig. 2 vs. 12). We find surprisal has the highest AR2 for predictability ratings (0.30\u00b10.06), while probability has stronger predictive power for human cloze completion probability (0.48 \u00b1 0.07). This result demonstrates the role of the warping function f in Eq. (4) in fitting a given psycholinguistic construct or data type, even when the scoring function remains unchanged (see Eq. (5b) and (6b)). As further illustrated in Fig. 3, the same binary scoring function provides a good linear fit to human cloze probabilities but not to predictability ratings. In contrast, logarithmic warping of the binary scores, which handles highly surprising outcomes more robustly, results in a better fit to predictability ratings."}, {"title": "6.2.2 Anticipatory Measures", "content": "The main results for anticipatory measures are shown in Fig. 4. See also Figs. 14 to 18 in App. D.2.\nCloze Completions. The most direct quantification of contextual uncertainty in the Aligned dataset is the entropy derived from human cloze completions. Indeed, all anticipatory measures show the strongest predictive power when used in isolation for this data type; see Fig. 14 in App. D.2 (default baseline). Expected next-symbol surprisal and probability have equivalent predictive power for close entropy, followed by expected next-symbol information value. The sequence-level anticipatory measures exhibit lower predictive capacity, with entropy obtaining the lowest AR2. This is not surprising, considering that cloze completions are composed of individual words.\nEvent-related Brain Potentials. Echoing our findings with responsive measures, expected next"}, {"title": "6.3 Main Findings", "content": "Our experiments, conducted across a comprehensive range of psycholinguistic data, demonstrate that different generalized surprisal models-both responsive and anticipatory\u2014provide complementary fit across different data types. For behavioral responses collected in the cloze task (Taylor, 1953), next-symbol probability accurately captures the distribution of human productions, while human predictability ratings are better explained by next-symbol surprisal. For ERP components, the choice of measures has an impact on predictive power for amplitudes recorded at different onsets. Information value is a stronger predictor of early-onset components, while probability and surprisal are more predictive for late-onset ones. Next-symbol information value, both in its responsive and anticipatory form, is consistently the best predictor for N400, an ERP compoment often predicted using surprisal (Frank et al., 2013b; Michaelov et al., 2024) but also known to be associated with semantic uncertainty (Brothers et al., 2020; Lindborg et al., 2023). On the other hand, sequence-level entropy, a measure whose computation involves long-horizon simulations, is predictive of ERP components in the frontal regions of the scalp, which are thought to be implicated in cognitive or executive control (Alexander et al., 1989; Kandel et al., 2000; Fedorenko et al., 2013). Finally, reading times, both self-paced and eye-tracked, are best predicted by responsive measures, with surprisal emerging as the overall best predictor. However, when comparing models that include surprisal alongside an anticipatory predictor, replacing Pimentel et al.'s (2023)'s expected next-symbol surprisal with one of our alternative anticipatory measures yields significant increases in predictive power across all studied reading time variables."}, {"title": "7 Conclusion", "content": "We introduced a generalization over classic information-theoretic measures of predictive uncertainty in online language processing. Our generalized surprisal framework subsumes both responsive and anticipatory measures, including established special cases but providing a vocabulary and the formal tools for experimenters to design new measures and explain psycholinguistic data of interest."}, {"title": "Limitations", "content": "There are several special cases of generalized surprisal that we did not include in our experiments to maintain focus, ensure the interpretability of our results, and keep the scope appropriate for a conference paper. In App. E, we provide a few examples (Rabovsky et al., 2018; Li and Ettinger, 2023; Opedal et al., 2024; Meister et al., 2024).\nOther limitations of our study concern the psycholinguistic data under analysis. We consider only English data and native English speakers, and thus, can only draw conclusions about incremental processing of English as L1. Multilingual datasets exist (e.g., Siegelman et al., 2022; Berzak et al., 2022) and should be used in future work to test our findings for other languages as well as speakers of English with a different L1. Furthermore, the linguistic contexts in the analyzed dataset consist of a single sentence. More experimentation is needed to assess the predictive power of our different measures with more complex linguistic contexts such as whole paragraphs and texts, e.g., with the Natural Stories corpus (Futrell et al., 2018), or sequences of conversational turns, which are known to modulate predictive uncertainty in non-trivial ways (Giulianelli and Fern\u00e1ndez, 2021; Giulianelli et al., 2021; Tsipidi et al., 2024). Generally speaking, contexts are representations of the current state of the world and can include extra-linguistic information (Ankener et al., 2018; Giulianelli, 2022). Future work should also study responsive and anticipatory linguistic processing modulated by visual cues. For visuo-linguistic contexts, estimates of our generalized formula can be calculated using image-conditioned or video-conditioned LMs.\nFinally, while we experiment with increasing the sample size in \u00a75.1, there could be other, more efficient ways to reduce variance. Future work may tackle variance reduction through, for example, importance sampling from altered (e.g., temperature-annealed) language model distributions."}, {"title": "A Details of the Experimental Setup", "content": "A.1 Measurements in the Aligned Dataset\nIn our experiments, we use the Aligned dataset (de Varda et al., 2023), which consists of M = 1726 target-context pairs from English novels annotated with several different neural and behavioral measurements. We present all types of measurements below.\nCloze Completions. In this incremental version of the cloze task (Taylor, 1953), participants are shown a sentence fragment c where the upcoming target word w is masked, and they are asked to guess what that target word will be. Two data types are derived from cloze completions: the cloze probability of the upcoming word, estimated as the Laplace-smoothed (with pseudocount a = 1) proportion of participants who pick that word, and the entropy of the Laplace-smoothed cloze distribution (cloze entropy).\nPredictability Ratings. Participants are presented with a sentence fragment c as well as its corresponding target w. Then, they are asked to rate how likely they think the target is on a Likert scale from 1 to 5 (DeLong et al., 2014). Predictability ratings facilitate the analysis of low-probability words unlikely to appear among cloze completions.\nEvent-related Brain Potentials (ERPs). ERPs are small voltages generated by participants' neural activity and recorded via an electroencephalogram (Donchin, 1979). Participants are tasked with reading a sentence, then their ERPs are post-processed to obtain word-level measurements, where each word in turn is the target w and its preceding words form the context c. For further details, see Frank et al. (2015). The ERP components analyzed here are the N400, often associated with a word's semantic predictability (Brothers et al., 2020), P600, implicated in syntactic integration processes (Kaan et al., 2000), (Early) Left Anterior Negativity (ELAN and LAN), linked to syntactic expectations and working memory (Friederici and Weissenborn, 2007), and (Early) Post-N400 Positivity (EPNP and PNP), thought to reflect lexical expectations (Thornhill and Van Petten, 2012).\nEye-tracked Reading Times. Participants read a sentence and the time spent looking at each word is recorded, so that each word, in turn, is the target w and its preceding words form the context c. The Aligned dataset contains four types of eye-tracked reading time indices: first-fixation time, first-pass time, right-bounded time, and go-past time. For more details, see Frank et al. (2013a). We exclude go-past time, a measurement that includes regressions to previous words, and was found to be noisy in this dataset (de Varda et al., 2023).\nSelf-paced Reading Times. Participants read a sentence one word at a time in a stationary-window paradigm (Just et al., 1982). The time elapsed between the presentation of a word and the participant's key press to proceed to the next word is the self-paced reading time. Contexts c here are taken to be the words preceding the current word w, although these are not physically present on the participants' screen."}, {"title": "A.2 Aggregating Multi-Token Estimates", "content": "When a word is composed of multiple subword tokens, token-level estimates are aggregated. For probability-based measures, we naturally multiply token-level estimates following the chain rule. For surprisal and information value, we sum token-level estimates (which, for surprisal, is equivalent to multiplying token probabilities)."}, {"title": "B Correlation Between Measures", "content": "To understand the potential overlap or complementarity between measures, we calculate their correlation. App. B.1 and App. B.2 below present results in terms of Pearson correlation and Spearman rank-correlation, respectively."}, {"title": "B.1 Pearson Correlation", "content": "Fig. 5 shows Pearson correlation coefficients between estimates obtained with responsive and anticipatory measures. Estimates are computed on the 1726 prefix-continuation pairs of the Aligned dataset (\u00a74) using"}, {"title": "B.2 Spearman Rank-Correlation", "content": "As a complement to App. B.1, we show the Spearman rank-correlation coefficients between responsive and anticipatory measures in Figs. 7 and 8. Note the almost perfect correlation between surprisal and MC surprisal, identical to that of probability and MC probability."}, {"title": "C Variation and Runtime Analysis", "content": "In \u00a75 of the main paper, we presented an empirical analysis of Monte Carlo estimation, with the goal of understanding the trade-off between the variance and runtime of each measure's estimator. Here, in Fig. 9, we display the result of this analysis conducted using GPT-Neo 125M."}, {"title": "D Psycholinguistic Predictive Power", "content": "D.1 Statistical Analysis\nTo evaluate the predictive power of a generalized surprisal model, we use the following procedure. First, we run 10-fold cross-validation, iteratively partitioning the Aligned dataset into a 90% training set and a 10% test set and measuring the coefficients of determination R\u00b2 of the baseline and target regressors on the test set. We repeat this procedure using 100 random seeds, and collect the AR2 scores associated with the target predictor. These are the scores that determine the width of the bars and the confidence intervals in Figs. 2, 4, 10 and 12 to 18. Then, to assess the significance of a measure's predictive power-i.e., of a measure's positive \u2206R2 scores\u2014we run paired permutation tests12 under the null hypothesis that the target regressor's R\u00b2 is smaller or equal to the baseline regressor's R2 and the alternative hypothesis that the target regressor's R2 is greater than the baseline regressor's R2."}, {"title": "D.2 Further Results", "content": "Responsive Measures. To complement Figs. 2 and 3 in the main paper, Figs. 10 and 11 show the results for responsive measures obtained with GPT-Neo 125M. Figs. 12 and 13 show the AR2 scores of our three responsive measures for cloze probability and predictability.\nAnticipatory Measures. To complement Fig. 4 in the main paper, Fig. 16 shows the results for anticipatory measures used in combination with surprisal, with GPT-Neo 125M estimates. Figs. 14 and 15 show the predictive power of anticipatory measures for cloze entropy.\nIn \u00a76.2.2 of the main paper (Fig. 4), we evaluate anticipatory measures against a combined baseline that includes surprisal and expected next-symbol surprisal next to the default baseline variables (target length, target frequency, and prefix length). Here, in Figs. 17 and 18, we show the predictive power results for the anticipatory measures against the default baseline."}, {"title": "E Other Special Cases of Generalized Surprisal", "content": "As noted in the Limitations section, there are several special cases of generalized surprisal that we did not include in our experiments to maintain a focused scope for the paper. Below, we provide a few examples.\nSemantic Update. This model, proposed by Rabovsky et al. (2018), is based on changes in neural representations and is given by:\n\nf(x) = x (16a)\ng(v, w, c) =1{w\u2081 \u2220 v} \u2211 |ai(w1) - ai(c\\c|)|, (16b)\nin which I is an index set corresponding to the neurons at some particular layer in a neural network implementation of a language model, and ai(u) represents the sigmoid activation of neuron i for symbol u.\nPointwise Mutual Information. The pointwise mutual information between a word and its context, which under certain conditions yields expressive power equivalent to surprisal (Opedal et al., 2024), can be written as:\n\nf(x) = log(x) (17a)\ng(v, w, c) = p(c) \u00b7 1{w\u2081 \u2220 v}. (17b)\nSimilarity-adjusted Surprisal. The similarity-adjusted notion of surprisal proposed by Meister et al. (2024) is analogous to information value but uses a similarity function zc: \u03a3* \u00d7 \u03a3* \u2192 [0, 1] as a scoring function and the negative logarithm as a warping function, as given by the following model:\n\nf(x) = -log(x) (18a)\ng(v, w, c) = zc(v,w) (18b)\nLastly, we note that the decomposition introduced by Li and Futrell (2023) is mathematically equivalent to surprisal and is therefore also captured by our framework."}]}