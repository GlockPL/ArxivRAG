{"title": "Self-supervised Monocular Depth and Pose Estimation for Endoscopy with Generative Latent Priors", "authors": ["Ziang Xu", "Bin Li", "Yang Hu", "Chenyu Zhang", "James East", "Sharib Ali", "Jens Rittscher"], "abstract": "Accurate 3D mapping in endoscopy enables quantitative, holistic lesion characterization within the gastrointestinal (GI) tract, requiring reliable depth and pose estimation. However, endoscopy systems are monocular, and existing methods relying on synthetic datasets or complex models often lack generalizability in challenging endoscopic conditions. We propose a robust self-supervised monocular depth and pose estimation framework that incorporates a Generative Latent Bank and a Variational Autoencoder (VAE). The Generative Latent Bank leverages extensive depth scenes from natural images to condition the depth network, enhancing realism and robustness of depth predictions through latent feature priors. For pose estimation, we reformulate it within a VAE framework, treating pose transitions as latent variables to regularize scale, stabilize z-axis prominence, and improve x-y sensitivity. This dual refinement pipeline enables accurate depth and pose predictions, effectively addressing the GI tract's complex textures and lighting. Extensive evaluations on SimCol and EndoSLAM datasets confirm our framework's superior performance over published self-supervised methods in endoscopic depth and pose estimation.", "sections": [{"title": "1. Introduction", "content": "Colorectal cancer (CRC) is a major global health concern, ranking as the third most common cancer worldwide and responsible for approximately 35% of cancer-related deaths [3]. Accurate lesion mapping in colonoscopy is essential for effective CRC diagnosis and treatment but remains challenging due to its reliance on endoscopist expertise [6]. In this context, 3D reconstruction offers a powerful, consistent method for precise lesion mapping and structural assessment, enhancing clinical accuracy [30].\nEffective 3D reconstruction in endoscopy relies on depth and pose estimation. Depth estimation provides spatial information, while pose estimation tracks camera orientation and movement through the GI tract. However, reliable ground truth for depth and pose are difficult to obtain due to the dynamic, constricted nature of the intestines. Additionally, endoscopy typically relies on monocular imaging, which limits depth perception and complicates 3D mapping in the GI tract's variable and occluded environment.\nRecent research has addressed these challenges with synthetic datasets, self-supervised learning, and monocular approaches [4, 9, 17, 29, 46]. Synthetic datasets enable robust training by simulating endoscopic conditions, while self-supervised learning leverages temporal and spatial cues to estimate depth and pose without manual labels.\nWhile stereoscopic endoscopes are being developed they are not being used in routine practice. Hence, self-supervised monocular depth estimation is the preferred approach, framing depth estimation as a view synthesis problem and optimizing image reconstruction to avoid traditional depth labels. Monocular systems rely on a single view and require an additional pose network to infer motion, adding complexity to compensate for limited depth cues.\nDespite recent advances in monocular depth and pose estimation-such as Monodepth [13, 14], Depth Anything [42], and DepthPro [5] current methods struggle with 3D colonoscopy due to the unique challenges of the endoscopic environment, including complex textures, erratic scene contrast, and reliance on synthetic data. To address these issues, we propose a robust approach that incorporates generative latent priors into a joint self-supervised framework for depth and pose estimation, conditioning predictions to overcome these challenges.\nOur self-supervised backbone builds on Monodepth2's principles [14], where a depth network estimates the current scene's depth and a pose network predicts the relative pose transitions between frames. Then, reprojected adjacent frames are wrapped to predict the current frame, forming a self-supervised loop by comparing this prediction with the actual frame. However, Monodepth2's depth and pose predictions are driven solely by reprojection consistency, lacking conditioning for realistic scene depth or camera poses.\nTo improve depth estimation, we incorporate a Generative Latent Bank trained with StyleGAN framework on depth images [8, 21], conditioning the depth network with a prompting-based approach. Here, the depth encoder generates prompts processed by the pretrained latent bank, which incorporates prior knowledge of depth scenes, and the decoder assembles these atoms into the final depth estimate.\nFor pose estimation, we reframe the network as a Variational Autoencoder (VAE) [16, 22] with the pose network as the encoder and the reprojection algorithm as the decoder, using pose estimates themselves as latent variables. This setup regularizes pose estimation, leveraging prior knowledge that colonoscopy pose transitions are generally gentle.\nOur evaluations on SimCol [38] and EndoSlam [36] datasets show improved performance over recent methods, and ablation studies validate the effectiveness of our proposed components."}, {"title": "2. Related work", "content": "Most clinical endoscopy platforms are monocular, so our review focuses on key advances in monocular depth and pose estimation and their application in endoscopy. Monocular depth estimation is inherently challenging and ill-posed, as a single 2D image may correspond to multiple 3D scenes. Supervised deep learning approaches leverage accurate depth labels as supervision, enabling models to learn the relationship between RGB images and depth values. Eigen et al. [11] propose a dual-network model, where one network makes a global prediction, refined by a second network. A multi-scale approach [10] further enhances depth estimation. Performance improvements have also come from novel loss functions, such as the Huber loss [24] and scale-invariant loss [25], as well as by framing depth estimation as a multi-class classification [27] or regression task [12]. Conditional Random Fields (CRFs) have been explored for post-processing [26, 28]. Monocular video sequences can be used as supervised signals, but require the network to learn both depth and camera pose. To optimise model effects others have introduced additional constraints such uncertainty [33, 37, 43], normal consistency [44, 45], semantic segmentation [7, 20, 23], and visual odometry [40]. Remarkably, Monodepth2 [14] enhances model convergence speed and accuracy without additional constraints by optimizing minimum reprojection loss and introducing automatic masking to handle static objects. Several subsequent methods build on Monodepth2, including DualRefine [2], MonoViT [48], and Lite-Mono [47].\nReal depth maps are challenging to obtain in endoscopy due to the need for specialized depth sensors and the variability in measurement quality [34]. Synthetic data and self-supervised learning methods address this by reframing monocular depth estimation as a view synthesis problem, eliminating the need for ground truth depth data. To improve depth and pose estimation in endoscopy, Mahmood et al. [31] proposed a joint CNN-CRF framework trained on synthetic datasets with ground truth and adapted through adversarial training. Widya et al. [41] introduced a generalized luminosity loss to balance depth and pose losses, enhancing model generalization across synthetic and real data. Generative approaches, such as those by Rau et al. [38] and Mahmood et al. [32], employed GANs to generate depth maps, though direct GAN-generated maps often lack accuracy, and supervised learning is impractical given the need for extensive ground truth data in endoscopy.\nSelf-supervised methods, which eliminate the need for ground truth depth maps, have shown promise. Hwang et al. [19] proposed a depth feedback network using self-supervised neighboring frame depth prediction with reconstruction error computation. Ozyoruk et al. [36] combined a residual network with spatial attention and a luminance-aware loss to improve robustness under varying illumination and introduced the EndoSLAM dataset. Liu et al. [29] presented a self-supervised monocular depth estimation model with dual attention, using multi-scale structural similarity and L\u2081 losses to maintain luminance and color invariance."}, {"title": "3. Methodology", "content": "Our model is designed to estimate depth and camera pose for reconstructing endoscopic movement traces and colon tract in a monocular setting. Briefly, our model comprises two main branches, DepthNet and PoseNet, which jointly predict depth and pose in a self-supervised framework, following the principles of Monodepth2 [14]. Our architecture follows an encoding-decoding process (Fig 2). Specifically, DepthNet encodes the current frame's depth, while PoseNet encodes the camera poses of adjacent frames (frames +1 and -1). The encoded outputs are used in a reprojection step that warps adjacent RGB frames to reconstruct the current frame (frame 0). A reconstruction loss is then calculated between"}, {"title": "3.1. DepthNet with Generative Latent Bank", "content": "Our DepthNet consists of an encoder $E_{dep}$, a latent bank $L_{depth}$, and a decoder $D_{dep}$. The input RGB image, $x_i$, is processed by the encoder, which comprises a series of downsampling and convolutional layers, producing a set of output feature maps at decreasing resolutions, $h_i = \\{ h_{i-1}, ..., h_{i-n} \\}$, where n represents the number of resolutions. The output feature map at each resolution is passed to the latent bank. The structure of the latent bank follows the scheme of a StyleGAN generator [21], which takes a latent vector and performs progressive upscaling using transpose convolutions. At each resolution, an additional latent vector is fused with the upscaled feature maps using Adaptive Instance Normalization (AdIN) [18].\nWhen functioning as a latent bank, the feature maps pro-"}, {"title": "3.1.1 Encoder and Decoder", "content": "Our DepthNet consists of an encoder Edep, a latent bank Ldepth, and a decoder Ddep. The input RGB image, xi, is processed by the encoder, which comprises a series of downsampling and convolutional layers, producing a set of output feature maps at decreasing resolutions, h\u2081 = {h-1,...,h}, where n represents the number of resolutions. The output feature map at each resolution is passed to the latent bank. The structure of the latent bank follows the scheme of a StyleGAN generator [21], which takes a latent vector and performs progressive upscaling using transpose convolutions. At each resolution, an additional latent vector is fused with the upscaled feature maps using Adaptive Instance Normalization (AdIN) [18].\nWhen functioning as a latent bank, the feature maps pro-"}, {"title": "3.1.2 Generative Latent Bank", "content": "The latent bank is a pretrained image generation network that follows a StyleGAN-like scheme 3. The core idea is to amortize the depth prediction process by injecting prior knowledge of scene depths (e.g., from natural scenes or other sources where depth data is abundant and easier to obtain compared to endoscopy).\nIn each iteration of the generative pretraining, a random Gaussian latent vector is generated and passed through a series of upsampling blocks using transpose convolutions. At each resolution level, a new Gaussian noise vector is combined with the features via Adaptive Instance Normalization (AdIN), adding variability to the outputs. After upscaling to the target resolution, a final convolutional block reduces the channels to 1, producing the output depth map.\nThe discriminator Dgan is a standard residual CNN trained to classify real vs. synthetic depth maps generated by the generator (i.e., generative latent bank Ldepth). The discriminator takes in a depth map and outputs a binary classification score, where a score of 1 indicates a real depth map, and a score of 0 indicates a synthetic one.\nThe latent bank Ldepth and discriminator Dgan are trained in a GAN framework. The goal is to optimize the latent bank parameters OLB to generate realistic depth maps, while the discriminator parameters \u03b8\u03b1 are optimized to accurately distinguish real from generated depth maps.\nThis is done by solving the following min-max problem:\n$\\min_{\\theta_{LB}} \\max_{\\theta_d} L_{GAN} (\\theta_{LB}, \\theta_d)$\nThe GAN loss LGAN consists of two components: the Wasserstein loss [1], which ensures a smooth measure of the distance between real and generated depth distributions, and a gradient penalty [15] that enforces the Lipschitz constraint on the critic.\n\u2022 $L_{GAN}(\\theta_{LB}, \\theta_d) = E_{x\\sim p_{real}} [D_{gan}(x)]$\n  $- E_{z\\sim p_z} [D_{gan} (L_{depth}(z))]$\n  $+ \\gamma \\cdot E_{\\hat{u}\\sim p_{\\hat{u}}} [(||\\nabla_{\\hat{u}} D_{gan}(x)||^2 - 1)^2]$                                                                                                                                                                                                                                                                                                                                                                                                                            (1)\n\u2022 $E_{x\\sim p_{real}} [D_{gan}(x)]$ is the expected output of the discriminator for real depth maps.\nEzpz [Dgan (Ldepth(z))] is the expected output of the discriminator for generated depth maps.\n\u03b3 is the weight for the gradient penalty term.\n\u2022 Ex~p+[(||Dgan(x)||2 \u2013 1)2] is the gradient penalty term to enforce the Lipschitz constraint [15].\nThe latent bank parameters OLB are optimized to minimize the adversarial loss with gradient penalty, while the discriminator parameters \u03b8\u03b1 are optimized to maximize its ability to classify real vs. generated samples. The training process alternates between minimizing the generator's loss and maximizing the discriminator's classification accuracy.\nLatent bank mode. After the latent bank Ldepth is trained to produce realistic scene depth outputs, its weights are frozen, and it is integrated into the encoder-decoder architecture discussed in section 3.1.1. Note that a new set of trainable Adaptive Instance Normalization (AdIN) blocks is initialized and optimized during the self-supervised training of the depth encoder Edep and the decoder Ddep. The output of the decoder di = Ddep (ai, hi) will be fed to the"}, {"title": "Generative pretraining mode.", "content": "The latent bank is a pretrained image generation network that follows a StyleGAN-like scheme 3. The core idea is to amortize the depth prediction process by injecting prior knowledge of scene depths (e.g., from natural scenes or other sources where depth data is abundant and easier to obtain compared to endoscopy).\nIn each iteration of the generative pretraining, a random Gaussian latent vector is generated and passed through a series of upsampling blocks using transpose convolutions. At each resolution level, a new Gaussian noise vector is combined with the features via Adaptive Instance Normalization (AdIN), adding variability to the outputs. After upscaling to the target resolution, a final convolutional block reduces the channels to 1, producing the output depth map.\nThe discriminator Dgan is a standard residual CNN trained to classify real vs. synthetic depth maps generated by the generator (i.e., generative latent bank Ldepth). The discriminator takes in a depth map and outputs a binary classification score, where a score of 1 indicates a real depth map, and a score of 0 indicates a synthetic one.\nThe latent bank Ldepth and discriminator Dgan are trained in a GAN framework. The goal is to optimize the latent bank parameters OLB to generate realistic depth maps, while the discriminator parameters \u03b8\u03b1 are optimized to accurately distinguish real from generated depth maps.\nThis is done by solving the following min-max problem:\n$\\min_{\\theta_{LB}} \\max_{\\theta_d} L_{GAN} (\\theta_{LB}, \\theta_d)$\nThe GAN loss LGAN consists of two components: the Wasserstein loss [1], which ensures a smooth measure of the distance between real and generated depth distributions, and a gradient penalty [15] that enforces the Lipschitz constraint on the critic.\n\u2022 $L_{GAN}(\\theta_{LB}, \\theta_d) = E_{x\\sim p_{real}} [D_{gan}(x)]$\n  $- E_{z\\sim p_z} [D_{gan} (L_{depth}(z))]$\n  $+ \\gamma \\cdot E_{\\hat{u}\\sim p_{\\hat{u}}} [(||\\nabla_{\\hat{u}} D_{gan}(x)||^2 - 1)^2]$                                                                                                                                                                                                                                                                                                                                                                                                                            (1)\n\u2022 $E_{x\\sim p_{real}} [D_{gan}(x)]$ is the expected output of the discriminator for real depth maps.\nEzpz [Dgan (Ldepth(z))] is the expected output of the discriminator for generated depth maps.\n\u03b3 is the weight for the gradient penalty term.\n\u2022 Ex~p+[(||Dgan(x)||2 \u2013 1)2] is the gradient penalty term to enforce the Lipschitz constraint [15].\nThe latent bank parameters OLB are optimized to minimize the adversarial loss with gradient penalty, while the discriminator parameters \u03b8\u03b1 are optimized to maximize its ability to classify real vs. generated samples. The training process alternates between minimizing the generator's loss and maximizing the discriminator's classification accuracy.\nLatent bank mode. After the latent bank Ldepth is trained to produce realistic scene depth outputs, its weights are frozen, and it is integrated into the encoder-decoder architecture discussed in section 3.1.1. Note that a new set of trainable Adaptive Instance Normalization (AdIN) blocks is initialized and optimized during the self-supervised training of the depth encoder Edep and the decoder Ddep. The output of the decoder di = Ddep (ai, hi) will be fed to the"}, {"title": "3.2. VAE-constrained PoseNet", "content": "For generating pose predictions, we utilize a pose encoder Epos that takes an RGB input and generates a pose estimation, represented as a vector of shape R6\u00d71, consisting of six pose parameters. The pose estimation is computed separately for both the previous frame (-1) and the subsequent frame (+1). After obtaining the pose estimations from Epos, these estimated poses are input to the reprojection algorithm along with the depth output di from DepthNet. The reprojection algorithm, serving as the decoder in this context, takes the estimated poses and depth maps and warps the RGB images of the -1 and +1 frames to produce reprojected RGB images at the current frame. The reprojected images are then compared with the ground truth RGB image of the current frame using MSE loss, ensuring spatial temporal consistency and completing the self-supervision.\nThe key difference in this approach is that we treat the output of PoseNet, which represents the relative pose differences between adjacent frames (-1 and +1) to the current frame, as latent variables in a Variational Autoencoder (VAE). Specifically, the reprojection algorithm acts as the decoder in this setup, constraining these relative pose parameters by enforcing a KL divergence between the predicted pose differences and a Gaussian prior. This regularization suppresses the prominence in z-axis movements while improves the relative sensitivity of x-y pose chamges between adjacent frames, reflecting prior knowledge that endoscopic movements are typically smooth to minimize potential damage to the GI tract.\nEmpirically, we demonstrate that using VAE regularization on the scales of poses along the x, y, and z axes results in a more coherent and sensible reconstruction of the endoscopic movement trace. The overall optimization objective consists of two main components:\nReprojection Loss: This is computed as the mean squared error (MSE) between the ground truth RGB image xgt at the current frame and the reprojected RGB image Xreproj, obtained by warping the adjacent frames using the estimated poses and depth (explained in section 3.3):\n$L_{reproj} = ||x_{gt} - x_{reproj} ||^2$.\nKL Divergence Regularization: The KL divergence between the predicted pose parameters and a Gaussian prior, which smooths the changes in pose estimates:\n$L_{KL} = KL (q(Z_{pos})||N(0, 1))$,\nwhere q(Zpos) represents the distribution of pose parameters estimated by PoseNet, and N(0, I) denotes a standard Gaussian prior."}, {"title": "3.3. Self-supervised Reprojection", "content": "The reprojection algorithm takes the depth map di (output from DepthNet for the current frame), the RGB images of the adjacent frames (x\u22121 and x+1), and the estimated pose differences Zpos,-1 and Zpos,+1 (outputs of PoseNet) that specify the relative pose differences between the current frame and the adjacent frames. The algorithm uses these inputs to warp and interpolate the RGB images of -1 and +1 frames, generating the reprojected RGB image of the current frame, Ireproj. The specific details of the reprojection algorithm follow the implementation in Monodepth2 [14].\nOptimization Objective We define the total optimization objective as minimizing the discrepancy between the current frame's RGB image and the reprojected image, while regularizing the pose estimates with a KL divergence term. The overall loss function for training all subnetworks-DepthNet (with Edep and Ddep) and PoseNet (with Epos) is given by:\nTotal Loss for the VAE-constrained PoseNet:\n$\\mathcal{L}_{total} = \\mathcal{L}_{reproj} + \\beta \\cdot \\mathcal{L}_{KL},$\nwhere $\\beta$ controls the weight for KL divergence.\nThe reprojection algorithm takes the depth map $d_i$ (output from DepthNet for the current frame), the RGB images of the adjacent frames ($x_{-1}$ and $x_{+1}$), and the estimated pose differences $z_{pose,-1}$ and $z_{pose,+1}$ (outputs of PoseNet) that specify the relative pose differences between the current frame and the adjacent frames. The algorithm uses these inputs to warp and interpolate the RGB images of -1 and +1 frames, generating the reprojected RGB image of the current frame, $\\mathcal{I}_{reproj}$. The specific details of the reprojection algorithm follow the implementation in Monodepth2 [14].\nOptimization Objective We define the total optimization objective as minimizing the discrepancy between the current frame's RGB image and the reprojected image, while regularizing the pose estimates with a KL divergence term. The overall loss function for training all subnetworks-DepthNet (with $E_{dep}$ and $D_{dep}$) and PoseNet (with $E_{pos}$) is given by:\n$\\mathcal{L}_{total} (\\mathcal{O}_{dep}, \\mathcal{O}_{pos}) = ||x_0 - Reproj(x_{-1}, z_{pose,-1}, d_i)||^2$\n$+ ||x_0 - Reproj(x_{+1}, z_{pose,+1}, d_i)||^2$\n$+ \\beta \\cdot KL(q(z_{pose}) || N(0, \\mathcal{I}))$\\                                                                                                                                                                                                                                                                                                                                                                                           (2)\n\u2022 $x_0$ denotes the current RGB frame.\n\u2022 $Reproj(\\cdot)$ represents the reprojection operation that uses the pose differences and depth estimates.\n$z_{pose,-1}$ and $z_{pose,+1}$ represent the estimated pose differences between the -1 and +1 frames, respectively, and the current frame.\n\u2022 $\\beta$ is a weighting factor for the KL divergence term.\nq(zpose) denotes the distribution of the estimated poses."}, {"title": "4. Experiments", "content": "Existing research often uses synthetic data generated from 3D models, as these provide RGB images with corresponding ground truth depth maps to evaluate endoscopic depth estimation models. Two main datasets are included: the SimCol and EndoSLAM datasets [36, 39].\nThe SimCol dataset, created by Rau et al. [39] using CT scans of the human colon and rendered in Unity, includes 33 scenes with a total of 37,833 RGB frames, each paired with ground truth depth maps and camera poses. Depth values are scaled to [0, 1] representing [0, 20] cm. For evaluation, three trajectories in Synthetic colon I and II are combined as a test set, while Synthetic colon III serves as a test set."}, {"title": "4.1. Datasets", "content": "Existing research often uses synthetic data generated from 3D models, as these provide RGB images with corresponding ground truth depth maps to evaluate endoscopic depth estimation models. Two main datasets are included: the SimCol and EndoSLAM datasets [36, 39].\nThe SimCol dataset, created by Rau et al. [39] using CT scans of the human colon and rendered in Unity, includes 33 scenes with a total of 37,833 RGB frames, each paired with ground truth depth maps and camera poses. Depth values are scaled to [0, 1] representing [0, 20] cm. For evaluation, three trajectories in Synthetic colon I and II are combined as a test set, while Synthetic colon III serves as a test set.\nThe EndoSLAM dataset [36] includes both synthetic videos generated using the VRCaps simulation environment and real endoscopy videos from porcine GI organs. The synthetic dataset comprises 21,887 colon frames and 12,558 small bowel frames, each with ground truth depth maps and camera poses. These were used as test sets to evaluate model generalization across different GI regions.\nTo pre-train Generative Latent Bank, we utilized the SceneNet RGB-D dataset [35]. It contains more than 15,000 frames of synthesized indoor RGB images and corresponding ground truth depth maps."}, {"title": "4.2. Implementation details", "content": "Hyperparameters: For self-supervised depth and pose estimation, we implemented our method in PyTorch and trained on NVIDIA with a batch size of 12, Adam as the optimizer with the weight decay of, an initial learning rate of 1e 4, input resolution of 480 \u00d7 480 and training epoch of 20. To pre-train the generative latent bank, we used a progressive training approach with a fixed learning rate of 10-4, gradually increasing the output resolution over the course of 100 epochs.\nEvaluation metrics: We report eight commonly used metrics proposed in [11, 39] for evaluating the depth estimation accuracy, which are Abs Rel, Sq Rel, RMSE, RMSE log, \u03b4 < 1.25, \u03b4 < 1.252, \u03b4 < 1.253 and L\u2081 error. Relative Translation Error (RTE) and Rotation Error (ROT) are used for evaluating the pose estimation."}, {"title": "4.3. Results in the SimCol dataset", "content": "The proposed framework is evaluated against other representative methods, including Monodepth2 [14], DualRefine [2], MonoVit [48], Lite-Mono [47], and Depth Pro [5]. The depth estimation results on the SimCol dataset are presented in Table 1. Our method significantly outperforms Monodepth2 across all metrics and demonstrates superior performance compared to other recent methods. Specifically, on the Synthetic Colon III test set, our method achieves an RMSE of 0.505, an Abs Rel of 0.11, and an L1 error of 0.327-reducing RMSE by 0.119 and 0.034 compared to Monodepth2 and Lite-Mono, respectively. Similarly, our method surpasses all other methods on the Synthetic Colon I/II test set. Depth Pro was also evaluated based on transfer learning (i.e., the pretrained foundation model for natural scene depth estimation is directly used to perform inference on the endoscopy datasets), but the results on both test sets were unsatisfactory."}, {"title": "4.4. Results in the EndoSLAM dataset", "content": "The proposed method is evaluated on the EndoSLAM dataset to show its generalization ability. Table shows the results of compared method on EndoSLAM colon and small intestine datasets. Our proposed method achieves lower RMSE values of 0.54 and 0.503 in colon and small intestine datasets, a relative improvement of 0.369/0.056 and 0.385/0.003 over Monodepth2 and Lite-Mono, respectively. We validate compared methods in pose estimation task on synthetic datasets (EndoSLAM Colon and Small Intestine) and porcine colon datasets similar to the human body(EndoSLAMColon-IV, Traj-I). In Table 1, we can see that our method maintains superior performance even in non-virtual datasets. Fig 5 (right) shows the pose estimation results in a humanoid colonoscopy clip, where our method is the only one that predicts the correct orientation. Our method's strength lies in incorporating depth-specific priors via a generative latent bank and VAE-based pose regularization, enhancing robustness in complex endoscopic scenes. This conditioning enables accurate estimation despite challenges like reflective surfaces, colonic folds, and variable lighting, allowing effective generalization across diverse environments without ground truth labels."}, {"title": "5. Ablation Studies", "content": "To further demonstrate the effectiveness of each proposed components in our method, we conducted an ablation study to assess the impact of the generative latent bank and pose VAE modules. By selectively removing modules, we evaluated the resulting performance on the SimCol dataset, as shown in Table 3.\nImpact of the Latent Bank Module: Removing the Latent Bank module led to a marked decrease in all depth estimation metrics, indicating its critical role. The generative latent bank effectively conditions the depth output, enhancing robustness against challenging conditions such as reflective surfaces and varying textures. This module enables the model to produce consistent and accurate depth maps, even within the self-supervised framework.\nImpact of the VAE Module: The removal of the VAE module caused a significant drop in pose estimation accuracy, highlighting its critical role in our design. The VAE-constrained PoseNet effectively regulates the scale of x, y, and z-axis transitions, aligning with the inherent characteristics of endoscopic navigation, such as pronounced z-axis progression and occasional erratic movements. This constraint enhances stability yet improves sensitivity in capturing pose changes, preserving alignment with the natural colonoscopic trajectory. Additionally, removing the VAE module decreases depth estimation metrics, and vice versa. This effect reflects the interdependence of the depth and pose branches in the reprojection process, where both branches contribute to self-supervised learning by warping adjacent frames to predict the current frame, underscoring the interconnected nature of our framework."}, {"title": "6. Conclusion and Future Directions", "content": "This paper presents a novel architecture for depth and pose estimation in endoscopy, leveraging generative latent priors for robust, self-supervised optimization of both tasks. Our approach achieves state-of-the-art performance on the SimCol and EndoSLAM datasets, showing particular strength in handling complex camera pose variations that challenge existing methods. Although our results are encouraging, a comprehensive quantitative validation in fully clinical settings remains constrained by the absence of ground truth data from real colonoscopy. In future work, we plan to integrate real-world data through computational methods to approximate ground truth depth and pose, potentially leveraging CT scans or quantitative validation on physical phantoms. Additionally, we aim to incorporate 3D reconstruction of the colon, which will further substantiate our approach and expand its applicability within clinical workflows."}]}