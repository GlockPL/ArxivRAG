{"title": "CAN KNOWLEDGE GRAPHS MAKE LARGE LANGUAGE MODELS MORE TRUSTWORTHY? AN EMPIRICAL STUDY OVER OPEN-ENDED QUESTION ANSWERING", "authors": ["Yuan Sui", "Bryan Hooi"], "abstract": "Recent works integrating Knowledge Graphs (KGs) have led to promising im-provements in enhancing reasoning accuracy of Large Language Models (LLMs).However, current benchmarks mainly focus on closed tasks, leaving a gap in theassessment of more complex, real-world scenarios. This gap has also obscuredthe evaluation of KGs' potential to mitigate the problem of hallucination in LLMs.To fill the gap, we introduce OKGQA, a new benchmark specifically designedto assess LLMs enhanced with KGs under open-ended, real-world question an-swering scenarios. OKGQA is designed to closely reflect the complexities ofpractical applications using questions from different types, and incorporates spe-cific metrics to measure both the reduction in hallucinations and the enhancementin reasoning capabilities. To consider the scenario in which KGs may have vary-ing levels of mistakes, we further propose another experiment setting OKGQA-Pto assess model performance when the semantics and structure of KGs are de-liberately perturbed and contaminated. OKGQA aims to (1) explore whetherKGs can make LLMs more trustworthy in an open-ended setting, and (2) con-duct a comparative analysis to shed light on methods and future directions forleveraging KGs to reduce LLMs' hallucination. We believe that this study canfacilitate a more complete performance comparison and encourage continuousimprovement in integrating KGs with LLMs.", "sections": [{"title": "INTRODUCTION", "content": "Contemporary LLMs are prone to producing hallucinations due to gaps in their knowledge, primarily when the training data contain misinformation, biases, orinaccuracies. These flaws can arise when we simply maximize the log-likelihood, leading to responsesthat may seem plausible, but are often irrelevant or incorrect . This issue is especiallyconcerning in scenarios where accuracy and reliability are essential, such as healthcare and science.\nTo address this critical limitation, researchers employ diverse strategies to augment the LLMs byintegrating external knowledge graphs (KGs). KGs offer structured, explicit, and up-to-date factual knowledge,including domain-specific knowledge, providing a faithful knowledge source for reasoning. Moreover, each piece of information in KGs can be traced back toits source, providing context and provenance. This traceability not only aids in verifying the reliabilityof the information but also provides clear pathways of reasoning, making the interpretation processtransparent. Due to their reliability and interpretability, KGs are considered a promising method toimprove the reliability of LLM reasoning.\nHowever, current benchmarks for testing the capabilities of these LLM+KG models are predominantlyclosed-ended, restricting responses to a limited set of entities/relations"}, {"title": "RELATED WORK", "content": "Due to the stochastic decoding process of Large language models (LLMs), i.e., sampling the nexttoken in the sequence, LLMs exhibit probabilistic behavior, potentially yielding varied outputs of thesame input across different instances . In addition, they also face challenges inaccurately interpreting phrases or terms when the context is vague and resides in a knowledge gapregion of the model, leading to outputs that may sound plausible but are often irrelevant or incorrect.This \"hallucinations\" undermines the reliability of LLMs. One emerging researchtrend is enhancing LLMs through integrating external knowledge graphs. KGs offer structured, explicit, and up-to-date factual knowledge, including domain-specific knowledge,providing a faithful knowledge source for reasoning.Moreover, each piece of information in KGs can be traced back to its source, providing context and"}, {"title": "OKGQA: A OPEN-ENDED KNOWLEDGE GRAPH QUESTION-ANSWERING BENCHMARK", "content": "OKGQA is a benchmark designed to assess LLMs enhanced with KGs under open-ended, real-worldquestions answering scenarios. OKGQA is designed to closely reflect the complexities of practicalapplications using questions of different types and incorporates specific metrics to measure both thereduction in hallucinations and enhancement in reasoning capabilities. In this section, we discuss theconstruction of the dataset, and the construction of OKGQA-P which is a variant of OKGQA wherethes KGs' semantics and structure are deliberately perturbed and contaminated.\nMotivation of Open-ended QA instead of Close-ended QA: Current benchmarks for testing thecapabilities of LLM+KGs models are predominantly close-ended\u00b9, which demand a short answersuch as 'yes' and 'no'. This restricts the responses to a limited set of entities/relations or a set of logical forms derivedfrom specific KG facts. Hence, they can only test a verylimited subset of the LLM's tendency to hallucinate, leaving a gap in the assessment of more complex,real-world scenarios. Particularly, standard metrics for evaluating thehallucination rate of LLMs require open-ended settings, i.e., questionsare phrased as a statement which requires a longer answer.\nOpen-ended QA Task Definition: The tasks we design require to first understand the scope of thequestion, then optionally retrieve relevant information from multiple parts of the knowledge graph,then finally synthesize a coherent and informative response. The ideal output should be a paragraphthat fully addresses the question with accurate and factual responses. We verify the response basedon the metrics specified in Section 5 to reflect the models' capabilities and faithfulness."}, {"title": "DATASET CONSTRUCTION", "content": "Queries. We utilize a template-based methodology to systematically generate a diverse range ofqueries using LLMs, including categories such as descriptive, explanatory, predictive, comparative,and critical queries. Details regarding the specific templates and example queries can be foundin Table 1, while the corresponding prompts are provided in the Appendix A.1. To ensure thatthe generated queries accurately represent real-world scenarios and complexities, we integrate thecorresponding Wikipedia pages of each entity as contextual information for the LLMs' generation.Furthermore, we follow a human-in-the-loop process to enhance the instructions for generating. Intuitively, starting with an initial instruction, we generate alarge number of query candidates, then use an LLM as automatic evaluator to evaluate the quality of the query, denoted as a set of scores from different metrics \\(S_{auto}\\) ranging from 1 to 10, with higher scores indicating better performance. Then, these queries are manually evaluated and assign a set of human-label score \\(S_{human}\\) correspond to \\(S_{auto}\\), normalized as the same range as \\(S_{auto}\\). We then optimize the input instructions by iteratively generate instructions to minimize the gap between \\(S_{human}\\) and\\(S_{auto}\\). These queries are categorized by difficulty and the naturalness of their phrasing. The statistics of the queries can be found in Figure 1."}, {"title": "OKGQA-P: BENCHMARK WITH NOISE & PERTURBATIONS IN KGS", "content": "To further mimic the real situations where KGs may not be of high quality (i.e., attributes ofnodes/edges may be mislabeled, relations may not exist, etc.), we propose another experiment settingOKGQA-P in this section to assess the model performance under conditions where KGs' semanticsand structure are deliberately perturbed and contaminated. Considering that KGs are typicallyannotated by humans and are generally accurate and meaningful, we introduce perturbations to edgesin the KG to degrade the quality of the KGs, diminishing human comprehensibility. To quantify thedegree of perturbation, we evaluate both the semantic and structual similarity between the originaland the modified KG as defined below.\nNotation. Let \\(F_O\\) be a KG-augmented model, and KG as \\(G = (V, E, T)\\), where \\(V\\) is the set of entities(nodes), \\(E\\) is the set of relation types (edges), and \\(T = \\{(v_1, e, v_2) | v_1, v_2 \\in V, e \\in E\\}\\) is the set oftriplets composed from existing entities and relations. Let \\(G' = (V, E', T')\\) be the KG obtained afterperturbing \\(G\\), where \\(E' \\neq E\\) and \\(T' \\neq T\\). Let \\(f(G, G')\\) be a function that measures the similaritybetween \\(G\\) and \\(G'\\). Let \\(g(G)\\) be the downstream performance when evaluating \\(F_O\\) on data samples \\(X\\)and \\(G\\).\nHigh-level Procedure. First, we test \\(F_O\\) on data samples \\(X\\) and \\(G\\) to get the original performance\\(g(G)\\). Second, we perturb \\(G\\) to obtain \\(G'\\). Third, we evaluate \\(F_O\\) on data samples \\(X\\) and \\(G'\\) to get theperturbed performance \\(g(G')\\). Finally, we measure \\(g(G) - g(G')\\) and \\(f(G, G')\\) to assess how robust\\(F_O\\) is, i.e., to assess the model performance under conditions where KGs' semantics and structure aredeliberately perturbed.\nTo quantify how much the perturbed KG has deviated from the original KG, i.e., \\(f(G, G')\\), weleverage metrics from  for capturing semantics (ATS) and structural (SC2D, SD2)similarity between KGs. Intuitively, ATS leverages an pre-trained LM for link prediction to measurethe probability of each edge from \\(G'\\) existing in \\(G\\), while SC2D and SD2 measures the structuralsimilarity between two KGs based on local clustering coefficient and degree distribution. For each ofthe three metrics, higher value indicates higher similarity.\nFor the perturbation methods, we consider four perturbation heuristics based on as follows: Relation Swapping (RS) randomly chooses two edges from \\(T\\) and swaps their relations.Relation Replacement (RR) randomly chooses an edge \\((v_1, e, v_2) \\in T\\), then replaces \\(e_1\\) with anotherrelation \\(e_2 = \\arg\\min_{r \\in R} S_G(v_1, e, v_2)\\), where \\(S_G(v_1, e, v_2)\\) uses ATS to measure the semanticssimilarity between two edges. Edge Rewiring (ER) randomly chooses an edge \\((v_1, e, v_2) \\in T\\), thenreplaces \\(v_2\\) with another entity \\(v_3 \\in E \\backslash N_1(v_1)\\), where \\(N_1(v_1)\\) represents the 1-hop neighborhood of\\(v_1\\). Edge Deletion (ED) randomly chooses an edge \\((v_1, e, v_2) \\in T\\) and deletes it. We control theperturbation level based on the percentage of KG edges being perturbed."}, {"title": "EVALUATION METRICS", "content": "To quantify the hallucinations of LLMs, we leverage two public metrics, FActScore and SAFE . FActScore is designed to measure factual precision in text by decomposing a long formgeneration into multiple atomic facts and validates each separately against a reliable knowledgebase, such as Wikipedia. We measure the proportion of facts that are supported by the knowledgesource out of the total atomic facts. SAFE, on the other hand, adopts a more dynamic approach tofact-checking. It employs a language model as an investigative agent, which iteratively uses GoogleSearch queries and reasons about whether the search results support or do not support the fact."}, {"title": "GRAPH-GUIDED RETRIEVAL (G-RETRIEVAL)", "content": "The graph-guided retrieval phase focuses on extracting the most relevant elements (e.g., triplets, paths or subgraphs) from KGs to help answer the user query. Initially, the query is transformed into anembedding vector \\(q \\in \\mathbb{R}^d\\) using a language model encoder \\(f_{LM}(\\cdot)\\). For each node \\(v \\in V\\) and edge\\(e \\in E\\), their respective embeddings \\(e_v\\) and \\(e_e\\) are computed using the same language model to mapall the information into the same vector space, and their relevance to the query is quantified usingcosine similarity as: \\(s_v = \\frac{q \\cdot e_v}{||q|| ||e_v||}\\) and \\(s_e = \\frac{q \\cdot e_e}{||q|| ||e_e||}\\). Next, we identify the most relevant nodes andedges for the query based on the corresponding similarity, to yield a set of 'top-k nodes/edges'.\nThe goal of G-retrieval is to retrieve the knowledge that encompasses as many relevant nodes andedges as possible, while keeping the size manageable. To this end, we leverage a 'prize' and 'cost'trade-off strategy to guide the retrieval process, as follows: (1) Prize assignment: based on thecomputed similarity scores, we assign prizes to nodes and edges to quantify their relevance to thequery. Specifically, we assign the top-k nodes/edges with descending prizes values from k to 1, whilenodes and edges outside the top-k receive a prize of 0. Formally: \\(p_v = \\max(0, k - rank(v) + 1)\\)and \\(p_e = \\max(0, k - rank(e) + 1)\\). (2) Cost allocation: to manage the retrieved knowledge size, weassign penalties as cost \\(C_e\\) (by default assign to 1) during the expansion of the retrieved paths orsubgraphs. These prizes and costs will be used in the retrieval process, by aiming to maximize theprizes while minimizing costs.\nTriplet-retrieval: the triplet retrieval approach retrieves a fixed number k of triplets with the highesttotal prize assigned to their respective head entity, relation, and tail entities.\nPath-retrieval: based on the defined prize assignment and cost allocation, the path-retrievalapproach starts from a fix number of k of high-prize nodes to construct sequences \\(P =\\{v_1, e_1, v_2, ..., e_{n-1}, v_n\\}\\) by aiming to greedily maximize their scores: \\(S(P) = \\Sigma_{i=1}^n p_{v_i} +\\Sigma_{i=1}^{n-1} p_{e_i} - \\Sigma_{i=1}^{n-1} C_e\\). We use a priority queue to iteratively extend paths by selecting the highest-scoring extensions while avoiding cycles and adhering to maximum path length and quantity con-straints. Finally, the top-scoring paths are sorted and returned.\nSub-graph retrieval: the sub-graph retrieval approach also leverages the prize assignment and costallocation; we follow  to optimize the process using Prize-Collecting Steiner Tree(PCST) algorithm. The PCST problem seeks to build a connected subgraph \\(S\\) that maximizes thetotal prizes of included nodes and edges while minimizing the total cost of the edges. The score ofthe subgraph is defined as \\(S(S) = \\Sigma_{v_i \\in V_S} p_{v_i} + \\Sigma_{e_i \\in E_S} p_{e_i} - \\Sigma_{e \\in E_S} C_e\\). Unlike in path-retrieval,we only yield one subgraph that maximizes the total score."}, {"title": "GRAPH-GUIDED GENERATION (G-GENERATOR)", "content": "After retrieving \\(Z^*\\), the graph-guided generation phase focuses on learning to leverage this knowledgeto generate the corresponding output to answer the user query. The generation is modeled asa sequential decision-making process as follows, where at each time step t, the next token \\(a_t\\) isgenerated by G-Generator, conditioned on the query q, the retrieved knowledge \\(Z^*\\), and all previously"}, {"title": "EXPERIMENTS", "content": "5.1 RQ1: MAIN RESULTS - CAN KGS REDUCE HALLUCINATION IN LLMS?\nTo explore whether KGs can help reduce hallucination in LLMs, we benchmark the LLMs in differentsettings. We use zero-shot and few-shot prompting as baselines without injecting external knowledge.In addition, compared to adding external knowledge from KGs, we also consider leveraging LLMs'internal knowledge to do Chain-of-thought or self-consistency prompting as baselines. As for LLMs augmented with KGs, we consider three KG retrieval forms:triplets, paths, and subgraphs (as shown in Figure 2) for comparison, to study the impact of G-retrievalfor reducing LLMs' hallucinations."}, {"title": "RQ2: HOW ARE KG-AWARE METHODS AFFECTED BY NOISE / PERTURBATIONS IN KGS?", "content": "We benchmark different KG-augmented LLMs on our OKGQA-P setting, where we deliberatelyperturb and contaminate the semantics and structure of KGs to simulate the real-world situationwhere KGs may not have high quality. Specifically, we consider different perturbation methodsdiscussed in Section 3.2 and control the perturbation level based on the percentage of KG edges beingperturbed. We first illustrate how much the perturbed KG has been deviated from the original KGwith the increase of perturbation level."}, {"title": "CONCLUSION", "content": "In this paper, we present OKGQA, a benchmark tailored for evaluating LLMs enhanced withKGs under open-ended, real-world question answering scenarios. The benchmark extends theassessment from close-ended question answering to the open-ended setting, to support the assessmentof hallucination in LLMs. To further mimic real-world scenarios where KGs may not have high quality,we propose another experiment setup OKGQA-P to assess model performance under conditionswhere KG's semantics and structure are deliberately perturbed and contaminated. We conduct a seriesof experiments on OKGQA and OKGQA-P, analyzing the effectiveness of various retrieval methodsand LLMs of different magnitudes, providing insights for further research and development. Ourresults underscore the significance of integrating KGs with LLMs to help reduce hallucination ofLLMs, even in circumstances where the KGs are contaminated."}]}