{"title": "Automatically Detecting Online Deceptive Patterns in Real-time", "authors": ["Asmit Nayak", "Shirley Zhang", "Yash Wani", "Rishabh Khandelwal", "Kassem Fawaz"], "abstract": "Deceptive patterns (DPs) in digital interfaces manipulate users into making unintended decisions, exploiting\ncognitive biases and psychological vulnerabilities. These patterns have become ubiquitous across various digital\nplatforms. While efforts to mitigate DPs have emerged from legal and technical perspectives, a significant gap\nin usable solutions that empower users to identify and make informed decisions about DPs in real-time remains.\nIn this work, we introduce AutoBot, an automated, deceptive pattern detector that analyzes websites' visual ap-\npearances using machine learning techniques to identify and notify users of DPs in real-time. AutoBot employs\na two-staged pipeline that processes website screenshots, identifying interactable elements and extracting textual\nfeatures without relying on HTML structure. By leveraging a custom language model, AutoBot understands the\ncontext surrounding these elements to determine the presence of deceptive patterns. We implement AutoBot as a\nlightweight Chrome browser extension that performs all analyses locally, minimizing latency and preserving user\nprivacy. Through extensive evaluation, we demonstrate AutoBot's effectiveness in enhancing users' ability to nav-\nigate digital environments safely while providing a valuable tool for regulators to assess and enforce compliance\nwith DP regulations.", "sections": [{"title": "Introduction", "content": "Deceptive patterns (DPs) are design elements that manipulate users into making unintended decisions while in-\nteracting with interfaces on applications or websites. These patterns exploit cognitive biases and psychological\nvulnerabilities to influence user behavior, often in ways that benefit the service provider at the user's expense. They\nhave become increasingly prevalent across digital environments, significantly impacting user experiences on social\nmedia, mobile devices, cookie consent banners, and even gaming applications [33]. Prior works have shown that DPs\ncan result in financial loss [42], privacy breaches [8], or exploitation of vulnerable groups, including children [46]. A\ntypical example of a DP is the intentionally convoluted subscription cancellation process, where users must navigate\nthrough multiple obscure options to terminate a service, as seen on platforms like www.dailymail.co.uk.\nEfforts to mitigate the effect of DPs have emerged from the policy and the technical sides. Regarding policy,\nregulations like CPRA [15] and the GDPR [4] have released guidance on deceptive patterns. On the technical front,\nresearchers have explored classifying the existing types of deceptive patterns [11, 21, 33, 48, 44, 7, 16, 39, 32],\nassessing their effectiveness [30], and compiling different deceptive pattern cases [12]. Despite these ongoing efforts,\ndeceptive patterns continue to pose significant challenges for both users and regulators. Users frequently encounter\nDPs in their digital interactions. For instance, sponsored advertisements are strategically placed at the top of search\nresults, creating a false impression that they are the most relevant or popular items. Furthermore, regulators often\nlack the tools to assess and enforce compliance with regulations concerning deceptive patterns effectively. This\ntechnological gap leaves users vulnerable to sophisticated DPs.\nIn this work, we propose a new paradigm to bridge this gap and improve the usability of online websites by\ndeveloping a solution to detect deceptive patterns and automatically warn users in real time. Our solution makes users\naware of deceptive patterns as they browse and enables regulators to assess and evaluate online services for deceptive"}, {"title": "Background and Related Works", "content": "Deceptive patterns refer to interface design choices that manipulate or deceive users into making decisions they\nmight not otherwise make [11]. In this paper, we focus on deceptive patterns found on websites. Examples of such\npatterns include hidden costs, forced continuity, misdirection in e-commerce websites, and privacy-invasive default\nsettings in social media platforms. In the rest of this section, we survey existing works on detecting deceptive\npatterns on the web and present a taxonomy to categorize them."}, {"title": "Detecting Deceptive Patterns", "content": "Given their effect on users' online privacy, security, and safety, researchers developed several mechanisms to detect\nand measure the prevalence of online deceptive patterns [11, 21, 33, 48, 44, 7, 16, 39, 32]."}, {"title": "Measurements of Deceptive Patterns", "content": "Early efforts to identify online deceptive patterns relied on manual exploration. Brignull et al. [11] manually explored\nthe web to compile a \u201cHall of Shame:"}, {"title": "User facing Solutions", "content": "While most previous works in the field of deceptive patterns focused on creating corpora of websites and apps with\ndeceptive patterns, few have addressed user-facing solutions. To the best of our knowledge, only two works have\nfocused on this aspect: UIGuard by Chen et al. [16] and Ariadne by Adorna et al. [7]. However, both solutions\nare limited by their text-only classifiers and are confined to specific domains - mobile apps for UIGuard and cookie\nnotices for Ariadne. In the broader domain of Privacy, Safety, and Security (PSS), researchers have developed tools\nto help users navigate certain deceptive designs on websites. For instance, works by Khandelwal et al. [25, 26] enable\nusers to find and adjust privacy settings and disable non-essential cookies automatically. Similarly, OptOutEasy by\nKumar et al. [9] automatically finds the opt-out links from privacy policies and surfaces them to the users.\nIn this work, we propose AutoBot, a automated deceptive pattern detector that integrates both the visual signal\nand the text signal to identify deceptive patterns. This allows AutoBot to make users aware of the deceptive patterns\nas they are browsing without impacting the usability of the websites."}, {"title": "UI Element Detection", "content": "Detecting deceptive patterns requires gathering contextual clues from web pages, necessitating a Web Element De-\ntector to identify buttons, checkboxes, radio buttons, and switches [45]. Existing works like the Element Detector\npresented by Wu et al. [50]. do not detect elements such as checkboxes and switches. Detectors like UISketch [43]\nand Roboflow-Universe [3] perform poorly on real-world data. UISketch, designed to detect UI elements on the\nweb, was primarily trained on hand-drawn images to identify UI elements based on their sketches. This training\napproach limits the model's applicability to real-world web elements. Testing on ten popular websites revealed that\nthe model detector failed to identify the most required elements.\nThe ScreenRecognition model presented by Zhang et al. [52] shows promise for this task but was trained on\nmobile screenshots and is closed-source, preventing its use or testing for web generalization. The dataset is also\nprivate, precluding its use for training our detector.\nUEID, a tool developed for GUI Element Detection by Xing et al. [51], performs well by merging text and visual\ndetectors. However, UEID with an average runtime of 4.8s will not fit into a user-friendly solution on the browser\nlevel. The RICO dataset [29] they used contains mobile UIs and thus could not be used to train our detector for\nwebpages.\nIn this work, we build a real-time UI element detector using YOLOv10. In prior work, we also tackled the dataset\nlimitation by generating a synthetic dataset of 62K websites."}, {"title": "Limitations", "content": "Existing techniques for automated detection of deceptive patterns are often limited to tasks solved via rule-based\nheuristic methods [18, 16, 39]. Furthermore, these works usually extract text and icons but do not extract any\ninformation regarding the color of the text or if the text belongs to a button. Due to the lack of this information, these\napproaches can overlook deceptive patterns like nudge. AutoBot addresses these limitations by building on a more\ncomprehensive taxonomy and leveraging recent advancements in Large Language Models (LLMs) to automatically\ndetect a wide range of deceptive patterns on the web."}, {"title": "Taxonomy for Deceptive Patterns", "content": "There have been several attempts at categorizing online deceptive patterns [12, 17, 10, 21, 33, 28, 32, 18]. Below, we\ndiscuss the existing taxonomies and build upon them to propose a more comprehensive and standardized taxonomy\nthat enables AutoBot to identify deceptive patterns on websites."}, {"title": "Existing Taxonomies", "content": "Brignull et al. [12] developed the first taxonomy specifying different types of deceptive\npatterns in 2010. Conti et al. [17] expanded on this taxonomy, including malicious interface designs. B\u00f6sch et al. [10]\nintroduced a similar taxonomy called \u201cprivacy dark patterns\u201d, which included more privacy-centric categories such\nas 'Forced Registration' and \u2018Hidden Legalese Stipulations.'\nGray et al. 2018 created a unified corpus to detect deceptive designs in user interfaces, building on previous\ntaxonomies and categories [21]. Since then, various works have further adapted the taxonomy for specific domains.\nLewis et al. [28] codified dark patterns for mobile apps and games, while Mathur et al. [33] adapted the taxonomy\nto focus on deceptive patterns present in shopping websites. Mansur et al. [32] extended the taxonomy to detect\ndeceptive patterns in mobile and web apps. More recently, Curley et al. [18] created a taxonomy based on how dark\npatterns can be detected in manual, automated, or semi-automated fashion."}, {"title": "Limitations", "content": "The problem of detecting deceptive patterns requires a taxonomy that comprehensively covers the\nrelated practices. Existing taxonomies, however, overlap in some patterns, do not describe the patterns consistently,\nand often miss some patterns described in other taxonomies. For instance, the taxonomy of Chen et al. [16] lacks\nthe categorization for nudge, confirmshaming and jargon, and the taxonomy by Curley et al. [18] does not include\ncategorization for nudge, fake-scarcity/fake-urgency, pre-selection, and disguised ads."}, {"title": "Proposed Taxonomy", "content": "We address this problem by establishing a consistent and comprehensive taxonomy of de-\ntectable deceptive patterns. We instantiated the new combined taxonomy with the Brignull et al. [12] taxonomy\nfrom 2010. We expanded the combined taxonomy with the taxonomies from Conti et al. [17], B\u00f6sch et al. [10],"}, {"title": "System Overview", "content": "We propose AutoBot as an user-facing solution to alert users about online deceptive patterns. In essence, AutoBot is\na browser extension that highlights UI elements that include a deceptive pattern on a webpage the user is visiting.\nIt achieves its objectives in real-time by running our classification models on-device, enhancing user privacy and\nsimplifying deployment. The underlying design approach of AutoBot involves analyzing the rendered webpage,\novercoming challenges related to non-standard and widely varying implementations. AutoBot analyzes a screenshot\nof the webpage to identify and highlight deceptive patterns as per the taxonomy from Table 1.\nRecent advances in multimodal foundational models offer a venue for analyzing screenshots and highlighting\npatterns with proper prompting. To this end, we empirically evaluated how accurately the state-of-the-art models,\nincluding GPT4-V [35] and Gemini 1.5 [20], detect online deceptive patterns. Our experiments showed that while\nthese models can detect deceptive patterns, they often hallucinate and give false positive answers. For example,\nFigure 2 shows how Gemini and GPT-4V struggle to identify the deceptive patterns in screenshots. While Gemini\n1.5 hallucinates about the lack of \u201cMore Options\", which does exist in the screenshot, GPT-4V falsely identifies\nthe \"Apply\" button as a nudge because it is brightly colored compared to its surroundings. Another significant\nshortcoming in current multimodal models is the challenges in deploying them. These models require developers to\nutilize external (non-private) API services or employ large, slow, computationally expensive models locally."}, {"title": "Vision Module", "content": "Prior works analyzing websites [25, 26] have primarily relied on HTML analysis. This method faces significant\nchallenges due to the dynamic nature of websites. Websites increasingly employ JavaScript frameworks that modify\nthe Document Object Model (DOM) on the fly, rendering static HTML analysis insufficient. Furthermore, the\ndiversity in the coding practices and obfuscation techniques provide additional challenges in HTML-based analyses.\nTo overcome these challenges, we adopt a novel approach focusing on the invariant aspect of websites: the\nuser experience. By leveraging the visual signals, our methodology relies on how the users perceive and interact\nwith websites. This approach offers several advantages: (1) It is resilient to change in underlying technologies as\nit captures the actual rendered content. (2) It allows us to analyze the same information that the user encounters,\nproviding a more accurate representation of the potential deceptive patterns.\nThe Vision Module is the foundation of our analysis pipeline, performing three key tasks. First, as it receives the\nscreenshot from the user-facing component (See Section 6), it performs an Optical Character Recognition (OCR)\noperation on the image, extracting the text and generating a CSV file consisting of the text and their bounding box\nlocation and their associated features such as position, font size, and color. We note that color and font can be crucial\nin determining deceptive patterns, like nudging. Next, the Web-UI Element Detector generates a list of the detected\nweb elements and their corresponding bounding boxes. Finally, the Vision Module merges the two outputs to create\nthe comprehensive textual representation of the website, referred to as the TextMap. An example of the process is in\nFigure 4."}, {"title": "Text Extraction", "content": "The Text Extractor module starts by performing Optical Character Recognition (OCR) on the website screenshot.\nFor this task, we employ the Google Vision OCR API [19] as it has high accuracy in extracting text from images of\nvarying scales and resolutions. The API returns detected texts that our OCR module concatenates based on proximity\nto form coherent text blocks. These blocks are a list of bounding boxes with their respective text content. Leveraging\nthese bounding boxes, we derive additional textual features, including font size, font color, and background color,\nas illustrated in Figure 4. We calculate font size by subtracting the bottom y-coordinate from the top y-coordinate\nof the bounding box. To determine color information, we utilize the extcolors [14] package, extracting the most\nprominent color (background) and the second most prominent color (font).\nThis approach addresses a key limitation identified by Soe et al. [44] in the previous ML methods: the lack of\nrepresentation of the UI richness that a user perceives, such as text placement and contrast between the font and\nbackground colors. Our Text Extractor module captures these detailed text features, along with the relative location\nof text elements in the website, providing a comprehensive representation of the textual content experienced by the\nusers.\nTo further contextualize the extracted text, we employ the Web-UI Element Detector to identify the web elements\nlocated within each text block. This provides additional information about the role and significance of each textual\nelement within the larger structure of the webpage."}, {"title": "Web-UI Element Detector", "content": "In order to allow the Language Module to understand the context better, we trained a Web-UI Element Detector to\nidentify UI elements like buttons, unchecked/checked checkboxes, unchecked/checked switches, and unchecked/checked\nradio buttons. This provides context to the extracted text and enables a more comprehensive understanding of the\nwebpage's structure. For instance, distinguishing between a clickable button and a static text block can be signifi-\ncant, as a seemingly simple text might be a deceptive call to action when recognized as a button. Similarly, identified\ncheckbox states (checked or unchecked) can reveal pre-selected options that users might overlook."}, {"title": "Choosing YOLO over CNNS", "content": "Unlike previous works [25, 32, 16] that used Convolution Neural Networks (CNNs) to detect and classify elements\nand icons in the screenshots, we opted for using You Only Look Once (YOLO) model, specifically the YOLOv10\nmodel. While CNNs are effective for object detection tasks, YOLO models offer multiple advantages over CNNs\nthat make them a perfect fit for our goals.\nReal-Time Detection YOLO models are designed for real-time object detection tasks, which is the primary require-\nment for our work. Unlike CNN-based object detection models involving complex multi-stage feature extraction\nand classifications processes, YOLO models perform a single pass to extract the bounding boxes and class predic-\ntions. Previous YOLO models would generate multiple class predictions with similar bounding boxes, requiring\nthe use of the non-maximal suppression (NMS) post-processing step; however, YOLOv10's efficient and optimized\narchitecture can bypass the NMS stage while maintaining similar accuracy, significantly reducing the computational\noverhead [47].\nBalancing Efficiency with Accuracy While CNN-based detectors, like Faster R-CNN, provide predictions with\nhigh accuracy, they are computationally intensive and require considerable computational power and time [40, 41].\nYOLO models, however, are optimized for speed and real-time inference, striking a balance between accuracy and\nefficiency [47]. For our task of locally running a model to detect Web-UI elements with constrained resources, we\nopted for a smaller model with slightly lower accuracy over a resource-intensive model.\nModel Size The YOLOv10 model is comparatively lightweight, around 40MB, allowing for a seamless local in-\nbrowser deployment for users without adversely impacting their resources."}, {"title": "Dataset Creation", "content": "We develop a novel approach to create a diverse and representative dataset to address the lack of suitable Web-UI\nelement dataset for training our Web-UI Element Detector. Instead of relying on manual scraping and labeling [52,\n43, 51], we leverage AI-powered tools to generate a synthetic dataset of over 62K website interfaces that reflect the\ncurrent web landscape. A key advantage of our synthetic approach is its precise control over element positioning\nand labeling.\nOur dataset generation process centered around v0\u00b9, an AI-powered generative user interface system by Vercel\u00b2,\nin conjunction with Astro\u00b3, a JavaScript framework. To scale the generation of diverse prompts for v0, we employ\nGPT-4 and create a wide range of prompts. We then submit these prompts to v0 and collect the three designs\ngenerated for each prompt. We specifically instruct GPT-4 to generate prompts that include the UI elements. Refer"}, {"title": "Training and Performance of YOLOv10", "content": "Using the above methodology, we generated over 60K screenshots along with their ground truth labels. These\nwebsites were then randomly split into training sets consisting of 85% of the images and the remaining 15% in the\ntesting set.\nDuring training, we observed that the YOLOv10 model was able to specialize in detecting a subset of UI Elements\nlike a button and a checkbox. Hence, in order to boost the performance, we adopted a step-by-step approach in\ntraining three different YOLOv10 models, each specializing in detecting 2-3 elements each, which we combined to\nmake an ensemble of models. This ensemble of models achieves near-perfect accuracy on the seven classes on the\ntesting dataset.\nTo measure the accuracy of the ensemble of models on real-life websites, we evaluated the performance of the\nmodels on the deceptive pattern websites dataset curated by Mathur et al. [33]. One of the authors annotated over\n1.3K website screenshots, which were then used to evaluate the models' performance. We note that to compute the precision and recall, we used an IoU value of 0.5 and\na confidence threshold of 0.3. We chose a lower IoU value because while training was done on a synthetic dataset,\nthe evaluation bounding boxes are human-annotated and will not perfectly match with the predicted bounding box,\nand a high IoU score would negatively affect model performance."}, {"title": "Language Module", "content": "The language module identifies the deceptive patterns by describing the UI elements on a webpage. In particular, it\ntakes as input the type of each UI element, its coordinates, its state, and the surrounding text."}, {"title": "Overview", "content": "Previous approaches, such as manual analysis, traditional classifiers, and heuristic or rule-based methods, as dis-\ncussed in Section 2, can be limited in locally identifying deceptive patterns accurately over diverse webpages. Fur-\nthermore, as discussed earlier in Section 3, using out-of-the-box LLMs and Vision Language Models (VLMs) exhibit\ndifferent shortcomings. AutoBot addresses these shortcomings in the following ways:\nHigh False Positive Rate: We empirically observed that LLMs like Gemini [20] and GPT4 [35], when prompted\nto detect deceptive patterns on screenshots of websites, had a high false positive rate and would often miss the\nimportant content on the site Figure 2. Additionally, these LLMs would frequently classify the same deceptive\ndesign with different names due to multiple taxonomies with diverse definitions [21]. To solve this issue, we created\nour taxonomy as stated in Section 2.2. With this taxonomy's help, we could ground the LLMs to persistently\nclassify the deceptive designs with set labels. However, the LLMs would often miss important parts of the website\nscreenshot, leading to misclassification and, ultimately, a high false positive rate.\nSolution: While LLMs can solve specific tasks, they often fail when planning and solving complex tasks [24]. Ad-\nditionally, through empirical experimentation, we observed that LLMs perform poorly in finding deceptive designs\nwhen given a screenshot. To properly leverage the knowledge in LLMs, we devised a setup wherein we provide\na textual representation of the site (Section 4) as a CSV file, along with a finetuned prompt to allow the LLM to\nunderstand how texts on the site are presented to the user.\nSlow Response Time: Another drawback of using LLMs is their slow response time. LLMs normally consist of\ntrillions of parameters [5], which lowers the inference time.\nSolution To achieve real-time results, we focused on distilling the knowledge to smaller LLMs like T5. We detail\nour entire methodology later in this section.\nLocalization Issues LLMs and VLMs, when given a screenshot, cannot provide the bounding boxes for the deceptive\ndesign, even if they can detect them correctly.\nSolution To accomplish this goal, we incorporate the bounding boxes in the textual representation of the site sent\nto the LLM. Since each row of the CSV file represents a unique element in the site, we can quickly look up that\nelement's position when the LLM detects a deceptive design.\nData Privacy Concerns One concern with using external LLM services is that once the data leaves the device, it\nis unknown what happens. The API service has complete access to the queried content and the querying party's IP\naddress. This potentially allows these third-party services to track users as they browse through the web.\nSolution The best possible solution is to confine the end-to-end analysis to a user's local browsers. Our work proposes\na solution that can be deployed locally in the browser with real-time inference.\nTackling these four challenges, we designed a language model that runs completely on-device and can provide\nreal-time results. Given recent advancements in compressing and running optimized ML models on the browser, we\nwere able to run a T5 [38] base model (hereby, referred to as T5) in the browser using the Transformer.js [23]\npackage. However, we cannot use the T5 model out of the box due to its knowledge limitation. To overcome this\nlimitation, we created our deceptive design dataset to finetune T5 further. We followed a similar methodology as\nthat by Hsieh et al. [22], where they extracted rationales from LLMs and then used them as an additional subtask\nwhen finetuning smaller models."}, {"title": "Dataset Creation", "content": "To create the dataset to train and evaluate T5, we crawled the sites in the deceptive pattern dataset from Mathur et\nal. [33]. Out of the 1400 sites mentioned, only 555 were still online. We visited these websites and captured their"}, {"title": "Distilling T5", "content": "To distill the knowledge from LLMs into smaller models like T5, we used the paradigm suggested by Hsieh et\nal. [22]. Here, we formally define the training dataset, $D_{train}$, as:\n$d_i \\in D_{train} \\subset D$\n$d_i = (x_i, y_i, z_i, r_i)$\nWhere $D_{train}$ is a subset of the D3 dataset (D) consisting of a website's textual representation along with its deceptive\npattern classification and reasoning. $x_i$ represents the web-element's text to classify, $y_i$ represents the deceptive\ndesign category, $z_i$ represents the deceptive design subtype, and $r_i$ represents the associated reasoning for the category\nand reasoning.\nUsing the above framework, we train the smaller T5 model, f, on a multi-task problem. The objective of\nthe model is to produce a concatenated label for both category and subtype into a classification label ($\\hat{y_i}$) and the\nreasoning behind that label ($\\hat{r_i}$) and to minimize the prediction loss."}, {"title": "Splitting Dataset", "content": "We split the D3 dataset into an 80% training set and a 20% testing set grouped by the sites the\nsamples were extracted from. This ensures that samples from the same site are not present in training and testing\nsets."}, {"title": "Baseline Approach", "content": "Based on this initial methodology, we train the smaller T5 model to predict the deceptive design\ncategory, subtype as the label, and reasoning as the rationale. We use the task-specific prefix [classify] to generate\nthe label and [reason] for the reasoning.\nWe define the model and loss functions as follows:\n$f(x,t) = \\begin{cases}\n(\\hat{y_i}z_i), & \\text{if t = [category]} \\\\\nr_i, & \\text{if t = [reason]}\n\\end{cases}$\n$L = L_{label} + L_{reason}$\nHere, $L_{label}$ and $L_{reason}$ are the label prediction loss and reason generation loss, defined as:\n$L_{label} = \\frac{1}{N} \\sum_{i=1}^N l(f(x_i, category), y_i \\oplus z_i)$\n$L_{reason} = \\frac{1}{N} \\sum_{i=1}^N l(f(x_i, reason), r_i)$\nWhere l is the cross entropy loss between the predicted and target tokens, and $\\oplus$ is a string concatenation function.\nEach web element that is to be classified, $x_i$, is provided alongside its neighboring web elements, $x_{i-1\\to 0}$ to $x_{i+1\\to N}$.\nThe model's performance is measured as the exact match of its [category] outputs with the ground truth data. An\nexample of the model's sample input and expected output is shown below."}, {"title": "Our Approach", "content": "To overcome the low accuracy in the baseline approach, we split the labeling task into two separate\ntasks: category and subtype, introducing an additional \u201ctask prefix\u201d [subtype] for the new task. We redefine the\nmodel and loss function to:\n$f(x,t) = \\begin{cases}\n\\hat{y_i}, & \\text{if t = [category]} \\\\\nz_i & \\text{if t = [subtype]} \\\\\nr_i, & \\text{if t = [reason]}\n\\end{cases}$\n$L = \\alpha (L_{category} + L_{subtype}) + (1 - \\alpha) L_{reason}$\nWhere \u03b1 is a tuning factor."}, {"title": "Improving Accuracy", "content": "Further Language models cannot directly understand natural language; in order to process\nnatural language, text is converted into tokens. The way prediction loss is calculated is as follows:\nl(a',a) = \\frac{1}{N} \\sum_{i=0}^N (a'_i - a_i)^2\nwhere, a' is the predicted output, a is the target output, and $a_i$ is the $i^{th}$ token of the a.\nIn our training dataset, the target labels are often multi-tokens, due to which noise is often introduced in loss\ncalculations. To reduce this noise, we updated the labels to have single tokens. For instance, the following original\nlabels:"}, {"title": "Performance of Distilled T5", "content": "Using this new methodology, of a single token, we again finetune the T5 model, achieving a final training accuracy\nof ~ 97%. In Table 4, we observe that on the testing set, the T5 model can predict deceptive patterns with a high\nrecall; the model can capture almost all the deceptive patterns in the site. When compared with the baseline approach\nand the predictions by Gemini 1.5, we observe that the recall of our model is the highest."}, {"title": "User-Facing Component", "content": "As discussed in Section 3, the user-facing component of AutoBot is a browser extension for Google Chrome, de-\nsigned to integrate seamlessly into a user's browsing experience. To achieve this, it takes a two-step approach: (1)\nit sends a screenshot to the on-device Vision module; (2) it then parses the results from the Language Module to\nhighlight deceptive patterns for the user as shown in Figure 1.\nThe extension overlays boxes around identified DPs by injecting an empty <div> tag into the DOM tree to bring\nthe deceptive patterns to the users' attention. This div serves as a visual indicator, with a red border around the\ndeceptive element (as shown in Figure 1), ensuring that users can quickly identify areas they should pay attention to.\nWe note here that the user experience is designed with passivity, allowing users to browse without distractions\nor unnecessary engagement. This passive design choice aligns with findings from works like [31, 6], emphasizing\nthat user experiences maximizing functionality without competing for attention are more effective. Moreover, we\nallow users to change the message they see for any deceptive pattern, enhancing the overall user experience.\nOur system integrates seamlessly with the user's browsing experience without burdening the user with unneces-\nsary engagement."}, {"title": "Evaluations", "content": "We perform multiple experiments to evaluate the accuracy and usability of AutoBot, as well as to showcase its utility\non a large-scale dataset. We seek to answer these questions:\nQ1. What is the end-to-end performance of AutoBot?\nQ2. Can AutoBot run in real-time in a browser?\nQ3. What is the impact of AutoBot on the user experience?"}, {"title": "End-to-End Evaluation", "content": "We performed a manual end-to-end evaluation of AutoBot on 200 websites to determine its performance in helping\nusers identify deceptive patterns in the web."}, {"title": "System Level Evaluation", "content": "To assess the real-time performance of AutoBot, we conducted latency evaluations across four distinct machine\nconfigurations. We specifically measured the inference time for both the core Vision Module (YOLOv10) and the\nLanguage Module (T5) under two conditions: utilizing only the CPU and leveraging GPU acceleration, where\navailable.\nMeasurement Setup: The latency of each module's execution was measured on three different systems. For the\nVision Module, we focused on the YOLOv10 object detection model. In the Language Module, we measured the\ninference time of the fine-tuned T5 model when processing our evaluation dataset. We utilized the YOLOv10m model\n(approximately 40MB in size) and a fine-tuned T5 model (approximately 750MB).\nResults: As shown in Figure 6a and Figure 6b, we observe that on modern machines, T5 model inference typically\ncompletes in under 2 seconds when using the CPU and in less than 0.5 seconds when utilizing a GPU. The YOLOv10\nmodel processes images in approximately 1.2 seconds on CPU and under 30 milliseconds with GPU acceleration.\nTakeaway: Our latency evaluations demonstrate that AutoBot can achieve near real-time performance on modern"}, {"title": "User Study", "content": "We perform a user-based evaluation to study the effects of our system's highlighting feature on a website's usability.\nWe recruited 151 participants from Prolific who reside in the United States. We paid each participant $2 to complete\nthe study, with a median time of around 7 minutes. We did not collect demographic data and asked Prolific to\ndistribute the survey evenly across the demographics. The IRB at our institution determined that the proposed\nactivity is not research involving human subjects as defined by DHHS and FDA regulations."}, {"title": "Study Design", "content": "We conducted a within-subject study to measure if highlighting deceptive patterns on websites through our extension,\nAutoBot, affected the website's usability. We informed the participants that the objective of the survey was to test\nthe usability of a web interface. Next, participants were asked to visit two custom-made websites, one with and one\nwithout highlighting, and fill out a System Usability Scale questionnaire [13] after each. In both these websites,\nthe participants were asked to perform one of the four tasks: sign up, download, do shopping, or read a news\narticle. Once the participants visit a website and hover over the highlighted text, a banner cautioning them about the\ndeceptive pattern is shown. Note that the participants interacted with highlighted websites directly without installing\na browser extension.\nThese custom-made websites were created by the authors based on various real websites, available at UXP2\nDark Patterns10, caught using deceptive patterns. An example of such a website is shown in Figure 1. After visiting\neach website, the participant is asked to complete a System Usability Scale questionnaire [13]. After finishing all\nthe tasks, participants are asked to fill out a post-study questionnaire consisting of three questions:\nQ1. Did you find the hints related to the deceptive patterns useful?\nQ2. Did you feel that the highlighted box encouraged you to notice the deceptive patterns?\nQ3. Did you feel that the highlighted box encouraged you to change your choice?\nFinally, there was an open-ended question asking for general comments and feedback at the end of the survey."}, {"title": "Findings", "content": "We measure the effect of highlighting on the user's usability of a site using the SUS metric, and"}]}