{"title": "Heterogeneous Hypergraph Embedding for Recommendation Systems", "authors": ["Darnbi Sakonga", "Viet Hung Vu", "Thanh Trung Huynh", "Phi Le Nguyen", "Hongzhi Yin", "Quoc Viet Hung Nguyen", "Thanh Tam Nguyen"], "abstract": "Recent advancements in recommender systems have focused on integrating knowledge graphs (KGs) to\nleverage their auxiliary information. The core idea of KG-enhanced recommenders is to incorporate rich se-\nmantic information for more accurate recommendations. However, two main challenges persist: i) Neglecting\ncomplex higher-order interactions in the KG-based user-item network, potentially leading to sub-optimal\nrecommendations, and ii) Dealing with the heterogeneous modalities of input sources, such as user-item\nbipartite graphs and KGs, which may introduce noise and inaccuracies. To address these issues, we present\na novel Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). KHGRec cap-\ntures group-wise characteristics of both the interaction network and the KG, modeling complex connections\nin the KG. Using a collaborative knowledge heterogeneous hypergraph (CKHG), it employs two hypergraph\nencoders to model group-wise interdependencies and ensure explainability. Additionally, it fuses signals\nfrom the input graphs with cross-view self-supervised learning and attention mechanisms. Extensive exper-\niments on four real-world datasets show our model's superiority over various state-of-the-art baselines, with\nan average 5.18% relative improvement. Additional tests on noise resilience, missing data, and cold-start\nproblems demonstrate the robustness of our KHGRec framework. Our model and evaluation datasets are\npublicly available at https://github.com/viethungvu1998/KHGRec.", "sections": [{"title": "1. Introduction", "content": "Recommender Systems (RecSys) provide personalized suggestions to users by collecting and analyzing\ntheir past preferences and behaviors such as user profiles and user-item interactions [1, 2, 3, 4]. RecSys\nplays an essential role in various applications such as e-commerce websites, streaming services, social media\nplatforms, news portals, e-healthcare [5]. In these applications, collaborative filtering (CF) methods are\nfrequently employed, where items are recommended by the likes or actions of users with similar tastes. With\nthe recent progression in deep learning structures, notably graph neural networks [6], various strategies\nintegrating graph to conventional CF methods have emerged [7, 8]. These strategies effectively capture\nintricate connections between users and items, offering a comprehensive perspective on the interaction data.\nDespite these advancements, most existing CF techniques rely solely on user-item interaction data. The\ninherent limitation due to the scarcity of these interactions fundamentally restricts further enhancement in\nperformance. In response to this challenge, integrating knowledge graph (KG) [9] has emerged as a prominent\nstrategy in collaborative filtering, referred to as KG-enhanced collaborative filtering RecSys. Such techniques"}, {"title": null, "content": "provide a comprehensive information network for items, consequently resulting in recommendations that are\nenhanced by the knowledge graph (KG) [10, 11]. For example, CKE [12] incorporates both topological and\nmulti-modal information to generate embeddings. KGAT [13] introduces a mechanism to combine both user-\nitem interaction and knowledge signal to construct a unified relational graph. This line of research opens a\nnew direction for personalized Recsys by providing users with contextually relevant recommendations that\nmatch the user's preferences.\nThese models leverage the multiple layers aggregation mechanism to consider high-order interactions to\nan extent. Nevertheless, the current knowledge-enhanced collaborative filtering RecSys models built upon\nclassical graph structures, where each edge primarily connects a pair of nodes, have proven inadequate in\ncapturing the essential higher-order characteristics intrinsic to knowledge graphs (KGs) [14]. In real-world\napplications, the nature of relationships among objects frequently extends beyond simple pairwise interac-\ntions to include triadic, tetradic, or more complex configurations. Simplifying these complex relationships\ninto binary ones results in a loss of critical information and reduces the system's expressiveness. Conse-\nquently, it limits the quality of recommendations as it neglects to identify user item groups sharing common\npatterns. For example, in movie recommendation systems like MovieLens and Netflix, users typically derive\nsatisfaction from films within their preferred genre (e.g., action, horror, romance) or those featuring their\nbeloved actors (as depicted in Fig.1). This highlights the need for integrating group-wise (a.k.a higher-order)\ninteraction within the recommendation process.\nThe integration of external data sources such as KG also raises the challenge of heterogeneous modality\nto the RecSys. Prior research [13] involves dynamic item embedding updates across the user-item and\nthe external knowledge graph, capturing signals from diverse data sources but potentially introducing sub-\noptimal parameters due to noise. Recent methods like KGRec [15] independently learn user-item and\nknowledge graphs for distinct item embeddings, while KGCL [16] employs KG-enhanced item representations\nto guide cross-view contrastive learning, reducing noise. Despite representing the same item nodes, these\nembeddings exhibit varied distributions due to differing graph connectivity. Thus, the integration of data\nwith different modalities requires careful consideration for possible conflict and noises.\nWe argue that a knowledge-assisted recommender system framework should be capable of handling the\nfollowing challenges:\n\u2022 C1: Group-wise dynamics: The collaborative and knowledge graph has group-wise characteristics,\ne.g., a user interacts with multiple items, or an item relates to multiple entities. A solution thus needs\nto be capable of efficiently representing such characteristics.\n\u2022 C2: KG relational dependency: The relations between entities in KG are very complex. For\ninstance, a film could be connected to various other entities through different relations - it could be\ndirected by one entity (a director), starring several others (actors), belong to a certain genre, and so\non. Each of these connections represents a different type of relationship, and together, they form a rich\nand intricate network of relational dependencies. Therefore, a solution should be capable of analyzing\nand understanding these relational dependencies.\n\u2022 C3: Explainability: In conventional collaborative filtering recommendation systems, suggestions are\npredominantly grounded in user-item interactions. This approach may yield recommendations that\nlack transparency and clarity. Consequently, an explainable knowledge-based recommender system is\nnecessitated, one that is capable of providing insights into the rationale behind the selection of specific\nitems.\n\u2022 C4: Consistency: In both collaborative and knowledge graphs, item entities may appear, creating\na unique challenge. Specifically, latent features of the same entity from different latent embeddings\nshould be close in proximity in the embedding space. This is based on the assumption that the same\nentity should have a similar representation across different graphs, reflecting its consistent characteris-\ntics. An effective solution, thus, should be capable of aligning entities of the same item across different\nembeddings."}, {"title": null, "content": "To tackle the outlined challenges, this paper proposes a novel knowledge-based collaborative filtering\nRecsys named Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). Specif-\nically, our method leverages heterogeneous hypergraph to better integrate the user-item bipartite graph\nand knowledge graph under the same modal as well as naturally capture the higher-order characteristics\namong the nodes. We then introduce a heterogeneous hypergraph convolution applied to the constructed\nhypergraph to simultaneously embed the group-wise characteristics of both input graphs and capture the\ncomplex relation-aware connections in the KG.\nThe contributions of this work are summarized as follows:\n\u2022 We propose KHGRec, a novel knowledge-enhanced collaborative filtering Recsys, which is the first\nmethod to couple the hypergraph's group-wise characteristics with the explainability of knowledge-\nenhanced Recsys to improve the recommendation's quality.\n\u2022 Drawing from input data, which includes user-item bipartite and knowledge graphs, we present a\nmethod for constructing a hypergraph data structure known as the Collaborative Knowledge Hetero-\ngeneous Hypergraph. This structure unifies the input graphs without introducing noises and facilitates\nthe later representation learning.\n\u2022 We present a novel relational-aware hypergraph neural network, innovatively designed for mining\nthe nodes' higher-order interactions and highlighting the node significance within hyperedges using\nattention mechanism, taking into account their relationships.\n\u2022 To seamlessly incorporate the signal retrieved from the two input graphs, we leverage the mechanism\nincluding two components. The first component leverages the attention mechanism to learn the optimal\nweight assigned for each latent matrix. Additionally, a cross-view self-supervised learning mechanism\nis employed to align similar entities from different latent spaces.\n\u2022 We perform extensive experiments with nine baselines on two popular datasets to justify the model's\nperformance against state-of-the-art models. Our source code and dataset are publicly available.\nThe remainder of the paper is organized as follows. \u00a72 gives a motivating example, then introduces the\nproblem statement and provides a comprehensive overview of our approach. \u00a73 describes the process of\nconstructing the heterogeneous hypergraph from the user-item bipartite and the knowledge graph. \u00a74 and\n\u00a75 explain the two main components of our proposed framework. \u00a76 reports the experiments we conducted\nto study the performance of our technique compared to the state-of-the-art baselines. \u00a77 reviews related\nwork and \u00a78 concludes the paper."}, {"title": "2. Problem and Approach", "content": "This section first introduces a motivating example and then describes the key structures and problem\nformulation for our paper."}, {"title": "2.1. Motivating example", "content": "In this section, we present an example of knowledge-assisted recommendation, depicted in Fig. 1. For\nthis example, we use data from the MovieLens dataset, a collection of movie ratings and interactions.\nThis dataset is published by Grouplens 3. To add depth to our understanding, we connect the movies in\nthis dataset to Freebase, a vast repository of structured information. Freebase aggregates detailed movie\ninformation, including the actors, directors, and genres, from reliable sources like Wikipedia and IMDB.\nIn this example, three users exhibit interest in four films: \u201cOppenheimer\u201d, \u201cIron Man, \u201cThe Dark Knight\nRises\", and \"Avengers\u201d. Utilizing additional knowledge from the knowledge graph, we categorize the films"}, {"title": "2.2. Problem Formulation", "content": "This section organizes key notations used throughout the paper and formalizes the problem of the\nrecommender system with collaborative and knowledge signals.\nUser-item interaction. To perform recommendations, in most cases, we exploit the information history of\ninteraction between users and items such as the records of clicks, watches, and purchases. Such interaction\ndata can be formed as user-item bipartite graph $G_1$ which is compromised with a set of triplets ${(u, \\mathcal{Y}_{ui}, i)|u \\in\\\\\nU, i \\in I)}$ where the nodes are two disjoint sets U and I(i.e, user and item sets). This can be represented\nin a matrix format $\\mathcal{y}$, where the number of rows and columns corresponds to the number of users and items\nrespectively. Each entry of the interaction matrix $\\mathcal{Y}_{ui}$ = 1 if the user u has interacted with item i, otherwise\n0.\nKnowledge graph. As extra supportive information, we leverage knowledge graph(KG) which represents\nthe intricate relationships between real-world objects based on its own atomic unit, namely triplet. Formally,\neach triplet follows the form of ${(h, r,t)|h, t \\in E, r \\in R)}$, where E and R indicate set of entities and relations\nrespectively. For example, as it is shown in Figure. 1, a triplet (Peter Jackson, isDirectorOf, Lord of the\nRings) states the fact that Peter Jackson is the director of the movie Lord of the Rings. It is worth noting\nthat R involves both canonical(e.g., isDirectorOf) and inverse direction(e.g., isDirectedBy). Based on the\nricher connections between items and their attributes, the interpretability and quality of recommendations"}, {"title": null, "content": "can be enhanced and more intelligible. For instance, a recommendation of a book can be generated based\non its auxiliary information including but not limited to author, genre, or publisher."}, {"title": "Problem 1 (KG-enhanced recommendation)", "content": "Given the knowledge graph $G_2$, set of users U, set of\nitems I, and the user-item interaction matrix $\\mathcal{Y}$, the problem is to learn a recommendation function $\\mathcal{F} =$\n(u, i | $\\mathcal{Y}, G_2, \\Omega$) that predicts the non-interacted item i (i \u2208 I) that user u (u \u2208 U) would inclined to engage\nwith, where $\\Omega$ denotes the learnable parameters of the model."}, {"title": "2.3. Approach Overview", "content": "In light of the above aspects, we propose a novel knowledge-assisted hypergraph recommendation system,\nas illustrated in Figure 2. Overall, we propose a novel recommender system framework that unifies the learn-\ning of user-item interactions and knowledge signals. Initially, raw data, comprising user-item bipartite and\nknowledge graphs, are harnessed to formulate a heterogeneous hypergraph, serving to retain the group-wise\ncharacteristics inherent in the input network, thus addressing challenge C1. However, this data structure\ncannot model the complex relational dependencies between nodes in the input network. Consequently, we\nadvocate for a relation-aware heterogeneous hypergraph attention encoder network to learn the hypergraph\nrepresentations while capturing the attentive bias of relations towards instances, hence resolving C2. By\njoint learning the embedding of user-item interactions and knowledge graphs, our proposed method can\nexploit the high-order dependencies among users and knowledge entities. Moreover, we apply the relation-\naware attention mechanism to generate the attentive score, which allows us to easily capture the reason why\na specific item is chosen, hence solving C3. Finally, our proposed method uses different encoders to encode\ndistinct aspects of the original network that include user, item, and knowledge entity nodes. The node\nembeddings retrieved from different encoders might include common information, such as users, items, or\nknowledge entities. Hence, we developed a two-step method, including attentive aggreation of embeddings\nand cross-view self-supervised training mechanism to solve C4.\nTo this end, we need to realize the following functions to instantiate the framework:\nHeterogeneous hypergraph construction. As mentioned earlier, we combine the raw input data of the\nuser-item bipartite graph and the knowledge graph to construct a heterogeneous hypergraph [17]. Unlike the\nclassical hypergraph, the heterogeneous hypergraph contains different types of nodes and multiple sizes of\nhyperedges so that it can alleviate the restrictive nature of the traditional hypergraph. Nodes can represent\neither users, items, or knowledge entities. Hence, we propose a method to construct the input for the\nhypergraph embedding process. Detailed insights into this component's construction are discussed in \u00a73."}, {"title": null, "content": "Heterogeneous hypergraph representation learning. The constructed heterogeneous hypergraph con-\nsists of several subgraphs, each representing a distinct hypergraph snapshot, namely user, item, and collabo-\nrative knowledge entity. The first two snapshots offer localized views of the user-item interaction graph, while\nthe latter presents a global perspective, encompassing both user-item interactions and knowledge-related\nsignals. To clearly distinguish between these two types of snapshots, we designate them as the \u201cLocal\u201d and\n\u201cGlobal\u201d views of the heterogeneous hypergraph. The \u201cLocal\u201d view focuses on micro-level examinations,\nspecifically analyzing interactions and relationships between individual users and items. This allows for an\nin-depth exploration of specific elements within the hypergraph. On the other hand, the \u201cGlobal\u201d view\nadopts a more expansive scope. It extends beyond the immediate user-item interaction to include collabo-\nrative knowledge entities, integrating all subgraphs into a unified analysis. To effectively learn from these\n\u201cLocal\u201d and \u201cGlobal\u201d views, we introduce two tailored encoder networks: the Local self-aware hypergraph\nencoder and the Global relational-aware hypergraph encoder, respectively. The Local self-aware hypergraph\nencoder integrates a self-attention mechanism with hypergraph embedding to capture the group-wise char-\nacteristics in user-item interactions and to highlight the significance of nodes within their neighborhood.\nConversely, the Global relational-aware hypergraph encoder merges a relational-aware attention mechanism\nwith hypergraph embedding. This combination is designed to foster the understanding of relational ef-\nfects among instances and to capture the high-order dependencies between users and knowledge entities.\nComprehensive details on this learning module are provided in \u00a74.\nFeature fusion module. To facilitate the learning of node embeddings from various hypergraph snapshots,\nwe propose a two-step method that first employs an attention mechanism and then utilizes a cross-view\nself-supervised learning training scheme. This approach differs significantly from the attention mechanisms\nemployed in graph encoders, which primarily focus on enhancing node embeddings. Specifically, the proposed\nattention mechanism functions as an aggregator and aims to combine latent features from different encoders.\nMeanwhile, the cross-view self-supervised learning scheme is designed to align similar entities' latent features\nacross diverse latent spaces. We give more details about this component in \u00a75."}, {"title": "3. Collaborative Knowledge Heterogeneous Hypergraph", "content": "This section first introduces the definition of related data structure, including collaborative knowledge\ngraph (CKG), and heterogeneous hypergraph. After that, we introduce collaborative knowledge hypergraph\n(CKHG) - a novel data structure for unifying the user interaction and knowledge data and capturing the"}, {"title": null, "content": "group-wise characteristics of the network, followed by a detailed description of how to construct it. The\nnotation used is summarised in Tabl. 1."}, {"title": "3.1. Definition of collaborative knowledge heterogeneous hypergraph", "content": "[13] first introduces the concept of CKG, a data structure designed to capture the high-order relation-\nship between users and knowledge entities. Specifically, the detailed explanation of this data structure is\nillustrated in Def. 1."}, {"title": "Definition 1 (Collaborative knowledge graph)", "content": "Let $\\mathcal{G}$ represent the Collaborative Knowledge Graph\n(CKG), a structure encoding both user-item interaction signals and relational knowledge signals as a unified\nrelational graph. The user-item interaction signals are derived from $G_1 = {{(u, \\mathcal{Y}_{ui}, i)|u \\in U, i \\in I)}$, and the\nrelational knowledge signals are obtained from $G_2 = {{(h,r,t)|h,t \\in E,r \\in R)}$. In CKG, each user behavior\nis meticulously represented as a triplet, (u, Interact, i), wherein $\\mathcal{Y}_{ui}$ = 1 is symbolized as an additional\nrelation, termed Interact, existing between user u and item i. Subsequently, the CKG is formally represented\nas $\\mathcal{G} = {{(h, r,t) | h, t \\in E',r \\in R')}$, where $E' = E \\cup U$ and $R' = R \\cup {Interact}$."}, {"title": null, "content": "While the CKG framework effectively integrates user-item bipartite and knowledge graphs into a unified\ngraph, it overlooks the high-order interactions between users and knowledge entities. To address this, we\npropose using a data structure called heterogeneous hypergraph [18]. This data structure, characterized by\nits diverse node and edge types, outperforms other data structures in terms of capturing complex group-wise\ncharacteristics. The specifics of this heterogeneous hypergraph are elaborated in Def. 2."}, {"title": "Definition 2 (Heterogeneous Hypergraph)", "content": "Assume that $\\mathcal{G}(\\mathcal{V},\\mathcal{E})$ is a hypergraph that contains $|\\mathcal{V}|$\nnumber of nodes and $|\\mathcal{E}|$ number of hyperedges. A positive edge weight $w(e)$ is given to each hyperedge\ne \u2208 $\\mathcal{E}$. Note that the assigned weights are positioned in diagonal entries in a diagonal matrix $W\u2208 R^{|\\mathcal{E}|\\times|\\mathcal{E}|}$.\nInformation about the association of nodes with hyperedges is formalized with incidence matrix $A \u2208R^{|\\mathcal{V}|\\times|\\mathcal{E}|}$\nwhich is a binary rectangular matrix, where $A_{ie}$ equals to 1 if node $v_i$ is part of the hyperedge e, otherwise\n0. The sets $\\mathcal{V}$ and $\\mathcal{E}$ encompass $T_v$ and $T_e$ types of nodes and edges, respectively. $\\mathcal{G}$ is classified as a\nheterogeneous hypergraph if either $T_v$ or $T_E$ is greater than 1, signifying the existence of multiple types of\nnodes and edges within the hypergraph."}, {"title": null, "content": "We then introduce a novel data structure, named Collaborative Knowledge Heterogeneous Hypergraph\n(CKHG), specifically tailored for the knowledge-based recommender system challenges. CKHG combines\nuser interactions and item knowledge entities into a unified heterogeneous hypergraph framework. Mirroring\nthe CKG structure, user behavior is represented as a triplet, (u, Interact, i), with the addition of a distinct\nrelation type Interact signifying the linkage between user u and item i. The definition of this proposed data\nstructure is described as follows:"}, {"title": "Definition 3 (CKHG)", "content": "Let $\\mathcal{G}_H (\\mathcal{V}_H, \\mathcal{E}_H)$ represent the CKHG, where the number of node types $T_V$ and edge\ntypes $T_E$ are set to three, respectively. Specifically, the node set $\\mathcal{V}_H$ is defined as $\\mathcal{V}_H = {\\mathcal{V}_u, \\mathcal{V}_i, \\mathcal{V}_e}$, where $\\mathcal{V}_u$,\n$\\mathcal{V}_i$, and $\\mathcal{V}_e$ represent user, item, and knowledge entity nodes, respectively. Likewise, the edge set $\\mathcal{E}_H$ is articu-\nlated as $\\mathcal{E}_H = {\\mathcal{E}_i, \\mathcal{E}_u, \\mathcal{E}_e}$, with $\\mathcal{E}_i, \\mathcal{E}_u$, and $\\mathcal{E}_e$ corresponding to the item, user, and collaborative\nknowledge entity hyperedges, respectively. A fact in CKHG is encapsulated by a tuple $(h,r,t, S_t | h, t \u2208 \\mathcal{V}_H, r \u2208 R')$ with\n$R' = R \\cup{Interact}$. $S_t$ is the set of supporting pairs ${(v_i, r_i)}_{st}$ with $v_i$ and t are neighbours in the same\nhyperedge, and $r_i \u2208 R'$ is the corresponding relation of the triplet $(h, r_i, v_i)$."}, {"title": "3.2. Constructing hypergraph snapshots", "content": "Given the input as a CKHG, we follow the approach from [18] and decompose it into multiple hypergraph\nsnapshots, with each snapshot encoding different information. Specificallly, the authors provide empirical\nevidence indicating that increasing the number of snapshots leads to a significant improvement in the\nmodel's convergence rate and the accuracy of its embeddings. This enhancement can be attributed to the\n\u201cdivide and conquer\" training approach employed by the model. Under this framework, the model learns\nthe embedding of each snapshot independently and concurrently, thereby reducing introduced noise and\""}, {"title": null, "content": "accelerating the learning process. Figure 3 illustrates the process of decomposing the original CKHG into\nmultiple hypergraph snapshots.\nSpecifically, we define three types of hypergraph snapshots using the encoded information as follows:\n\u2022 Item hypergraph: Let $\\mathcal{G}_i(\\mathcal{V}_u, \\mathcal{E}_i)$ is a subgraph of $\\mathcal{G}_H$. Here $\\mathcal{V}_u \u2208 \\mathcal{V}_H$ denotes the user nodes, and\n$\\mathcal{E}_i \u2208 \\mathcal{E}_H$ denotes the item hyperedges, with a hyperedge $e_i \u2208 \\mathcal{E}_i$ connecting users having interactions\nwith item i.\n\u2022 User hypergraph: Let $\\mathcal{G}_u (\\mathcal{V}_i, \\mathcal{E}_u)$ is a subgraph of $\\mathcal{G}_H$. Here $\\mathcal{V}_i\u2208 \\mathcal{V}_H$ denotes the item nodes, and\n$\\mathcal{E}_u \u2208 \\mathcal{E}_H$ denotes the user hyperedges, with a hyperedge $e_u \u2208 \\mathcal{E}_u$ connecting items having interactions\nwith user u.\n\u2022 Collaborative knowledge entity hypergraph: Let $\\mathcal{G}_e(\\mathcal{V}_e, \\mathcal{E}_i \\cup \\mathcal{E}_e)$ is a subgraph of $\\mathcal{G}_H$. This snapshot\ntakes items and knowledge entities as hyperedges, with a hyperedge $e_k \u2208 (\\mathcal{E}_i \\cup\\mathcal{E}_e)$ connecting nodes\n$v_k \u2208 \\mathcal{V}_H$ having relation r \u2208 R' with $e_k$.\nBy dividing the original big networks into smaller snapshots, we can learn these components simultaneously\nusing different encoders, with each tailored for different purposes. This approach can lead to faster conver-\ngence of the model since our model now does not have to learn signals from different types of nodes and\nhyperedges, which often leads to suboptimal learned embedding. We then use different encoders to learn\nnode embeddings in each snapshot and then aggregate these snapshots into a comprehensive representation.\nWe divide the snapshots into two types based on the scope of the information encoded: Local view - in-\ncluding user and item hypergraph snapshots, and Global view, which is the collaborative knowledge entity\nhypergraph snapshot. While the former only encapsulates the user-item interaction, the latter captures both\nthe user-item interaction and the item-entity relation while also demonstrating the high-order dependencies\nbetween the user and the knowledge entity. In order to learn the embedding of different types of snap-\nshots, we use two different architectures: Local Self-aware Hypergraph Encoder and Global Relational-aware\nHypergraph Encoder, which will be discussed in detail in \u00a74."}, {"title": "4. Collaborative Knowledge Hypergraph Encoder", "content": "This section depicts our methodology for encoding both collaborative signals and collaborative knowledge\nsignals using two specially designed encoder networks: Local Self-aware Hypergraph Encoder and Global\nRelational-aware Hypergraph Encoder."}, {"title": "4.1. Local Self-aware Hypergraph Encoder", "content": "In this section, we describe the architecture of the novel hypergraph convolution, e.g., Hypergraph Trans-\nformer Self-Attention Networks, used in the proposed encoder, followed by the overall architecture of this\narchitecture. We then proceed to give a detailed mathematical representation of the mentioned encoder.\nHypergraph Transformer Self-Attention Networks. Inspired by [19], we propose the Hypergraph\nTransformer Self-Attention Networks to capture the impact of neighboring nodes in the hypergraph ef-\nfectively. We first apply the transformer architecture [20] to all nodes in the input hypergraph G, where\n$\\mathcal{G}\u2208 {G_u, G_i}$. Mathematically, the hypergraph $\\mathcal{G}$ can be represented as:\n$\\mathcal{G} = (X, A),                                                                                (1)$\nwhere $X \u2208 R^{|V|\u00d7F}$ represents the node features matrix, $A \u2208 R^{|V|\u00d7|E|}$ is the incidence matrix, with $|\\cdot|$ is\nthe number of nodes of the hypergraph $\\mathcal{G}$.\nThis design choice aims to leverage the self-attention mechanism to learn the node importance in the\ngraph. Specifically, we update the node embeddings with their neighboring nodes by stacking multiple\ngraph transformer layers with a weight-sharing mechanism. Each layer is composed of two key functions:\nthe self-attention and the transition function. Nodes are first passed through self-attention function ATT(\u00b7)\nto weigh varied attention scores to different neighboring nodes, thus encoding dependencies between the\ncurrent node v and its neighbors. More precisely, the output of attention function $\\hat{ATT}-h_t^{l}$ l-th layer\nand t time step can be defined as below:\n$\\hat{ATT}-h_t^{l} = Norm\\big(h_t^{l-1,n} + ATT(h_t^{l-1,n})\\big),                                       (2)$\n$ATT\\big(h_t^{l-1,n}\\big) = \\sum_{n,\u00f1 \\in N_v \\cup{v}} \\alpha_{nn}^{l-1} V(h_t^{l-1,n}),                                          (3)$\n$\\alpha_{nn}^{l-1} = softmax\\bigg(\\frac{(Qh_t^{l-1,n})^T (Kh_t^{l-1,\u00f1})}{\\sqrt{d}}\\bigg).                                                  (4)$\nwhere n, \u00f1 \u2208 $N_v \\cupv$ are neighbor nodes of the given current node v, $h_t^{l-1,n}$ denotes the vector representation of\nn at l-th layer, Norm indicates Layer Normalization, $\\alpha_{nn}^{l-1}$ is attention score, $V^l, Q^l, K^l \u2208 R^{d\u00d7d}$ denotes\nlinear projection matrices for value, query, and key respectively. The learned attention-aware intermediate\nparameters are then transferred to the Feed Forward Neural Network(FNN), which is denoted as Trans(\u00b7),\nfollowed by residual connection as below.\n$Trans - h_t^l = Norm \\big(ATT - h_t^{l-1} + Trans \\big(ATT - h_t^{l-1})\\big)                        (5)$\nNote that, the topological information of input hypergraph $\\mathcal{G}$ vanishes after the propagation through the\nself-attention layer since it naturally connects all possible pairs of nodes with all positions engaging in\ninteractions with one another. To overcome this limitation, we propose using a hypergraph convolution\nHConv(\u00b7) after each transformer self-attention layer, as illustrated in Figure 4.\nFollowing [21], before the propagation through convolution layers, we need to construct Laplacian matrix\n$\\Delta \u2208 R^{d\u00d7d}$ of hypergraph $\\mathcal{G}$, which can be calculated as below:\n$\\Delta = I \u2013 D_v^{-1/2}AD_e^{-1}A^TD_v^{-1/2}                                                            (6)$\nwhere A denotes the incidence matrix, $D_v$ and $D_e$ are the degree matrices of nodes and hyperedges re-\nspectively. In the remainder of this paper, we use term $\\Theta$ for $I \u2013 D_v^{-1/2}AD_e^{-1}A^TD_v^{-1/2}$ for clarity of\npresentation. It is worth noting that the Laplacian matrix can further be transformed into diagonal matrix\n$\\Delta = \\Psi\\Lambda\\Psi^T$, where $\\Psi$ is eigenvector matrix and $\\Lambda$ is a diagonal matrix containing the eigenvalues of $\\Delta$ as\nits diagonal elements. Hence, HGConv(\u00b7) is mathematically represented as:\n$HGConv (X, \\Theta, P) = \\sigma (\\Theta\\cdot X \\cdot P),                                                (7)$"}, {"title": null, "content": "where P is a learnable weight matrix. Formally, we define a Hypergraph Transformer Self-Attention Net-\nworks Convolutional (HGTNConv) layer as:\n$H'^{l} = Transformer \\big(HQ^{l}, HK^{l}, Hv^{l}\\big),                                                   (8)$\n$H^{l+1} = HGConv \\big(H'^{l}, \\Theta, P\\big),                                                                 (9)$\nwhere $H^{(0)} = X$ is the node feature matrix."}, {"title": null, "content": "We then stack multiple layers of HGTNConv on top of each other to construct the complete HGTN. The\nembedding operation of HGTN can be mathematically represented as follows:\n$f(\u011e, A) = HGTNConv^{L} (... HGTNConv^{1} (H^{(0)}, A), A),                                                    (10)$\nwhere l denotes the number of layers in HGTN.\nFurthermore, to strengthen the output signal, we utilize the residual term after the HGTN layer following the\ndesign in [22], which is denoted as Res. The complete mathematical representation of the Local Self-aware\nHypergraph Encoder is as follows:\n$M_i = HGTN(G_i) + Res(X_i),                                                                               (11)$\n$M_u = HGTN(G_u) + Res(X_u),                                                                                (12)$\nwhere $G_i = (X_u, A_i)$ represents the item hypergraph snapshot, $X_u \u2208 R^{|V_u|\u00d7F}$ represents the user embedding,\nand $A_i \u2208 R^{|V_i|\u00d7|V_u|}$ represents the item incidence matrix, with $|V_i|$, $|V_u|$ represent the number of items and\nusers, respectively. Analogously, $G_u = (X_i, A_u)$ represents the user hypergraph snapshot, $X_i \u2208 R^{|V_i|\u00d7F}$\nrepresents the item embedding, and $A_u \u2208 R^{|V_u|\u00d7|V_i|}$ represents the user incidence matrix."}, {"title": "4.2. Global Relational-aware Hypergraph Encoder", "content": "Inspired by the graph attention mechanisms in [? ), we design a relation-aware hypergraph attention\nlayer to capture the relation heterogeneity over collaborative and knowledge graph connection structures\n(Figure 5). Specifically, instead of using the cosine similarity to measure the impact of neighboring nodes as\nin [21], we tailor the attention matrix using the relational-aware attention mechanism, thus better expressing\nthe relational dependency between users-items-entities.\nRelational-aware Attention Mechanism. Given head entity h, the set of triples connected to h forms\nego-centric network, $N_h = {{(h,r,t)|(h,r,t) \u2208 G_e)}$, where h is head node(i.e., ego node) and t denotes the\ntail node [23].\nThen, followed [13], we denote the impact factor of tail entity t regarding the relation r to the head\nentity h as \u03c0(h, r,t), with the mathematical formulation as follows:\n$\\pi(h, r,t) = \\big(W_r e_t\\big)^T tanh \\big((W_r e_h + e_r)\\big),                                    (13)$"}, {"title": null, "content": "where tanh is the activation function, Wr is the learnable matrix. This results in the attention score\nbeing influenced by theproximity between $e_h$ and $e_t$ within the space of relation r, hence, allowing for more\nsubstantial information propagation for entities that are closer together.\nThen, the softmax function is applied to normalize the learned attention scores:\n$\\pi(h, r, t) = \\frac{exp((\\hat{\u03c0} (h, r, t))}{\\sum_{(h,r',t')\u2208N_h} exp (\\hat{\u03c0} (h, r', t'))}\u02d9                                   (14)$\nRelational-aware Hypergraph Attention Convolution. We then propose the Relational-aware Hy-\npergraph Attention Convolution (RHGATConv), where we employ the proposed attention mechanism to\nconstruct the attention matrix B, which is mathematically represented as follows:\n$B_{ij} = \\pi(h_i, r_{ij}, t_j),                                                                             (15)$\nwhere Bij represents the impact factor of the tail entity $t_j$ to the head entity $h_i$ regarding the relation\n$r_{ij}$, which acts as a gating mechanism to control how much information the tail entity can transfer its\ncorresponding head entity. The attention matrix is then multiplied with the original hypergraph incidence\nmatrix to create a more dynamic incidence matrix, thus better revealing the intrinsic relationship between\nvertices. The attention hypergraph incidence matrix is formally denoted as:\n$A = B \\cdot A.                                                                                   (16)$\nDenoting $D^{-1/2}_vAD_e^{-1}A^TD^{-1/2}_v$ by $\\tilde{\\Theta}$, we formally define a RHGATConv layer as follows:\n$H^{(l+1)} = \\sigma (\\Theta. H^{(l)}. P),                                                                     (17)$\nwhere $H^{(0)} = X$ is the feature matrix of all nodes in the input hypergraph, A is the incidence matrix, and l\ndenotes the l-th layer. We then stack multiple RHGATConv layers on each other to construct the complete\nRHGAT model. The embedding operation of RHGAT can be mathematically represented as follows:\n$f(G_e, B, A) = RHGATConv^{(L)} (... RHGATConv^{(1)} (H^{(0)}, B, A), B, A),                                    (18)$\nwhere l denotes the number of layers in RHGAT.\nWe also utilize the residual term after the RHGAT layer. The complete mathematical representation of the\nGlobal Relational-aware Hypergraph Encoder is as follows:\n$M_e = RHGAT(X_e, A_e) + Res(X_e),                                                                   (19)$\nwhere $M_e$ denotes the collaborative knowledge latent feature, $G_e = (X_e, A_e)$ represents the collaborative\nknowledge hypergraph snapshot, $X_e \u2208 R^{|V_e|\u00d7F}$ represents the collaborative knowledge entity embedding;\n$A_e \u2208 R^{|V_e|\u00d7 |V_e|}$ represents the incidence matrix of the corresponding hypergraph, $|V_e|$ represent the total\nnumber of collaborative knowledge entities, and F represents the feature embedding size."}, {"title": "5. Enhance Learned Embedding With Attention-aware Feature Fusion And Cross-view Con- trastive Learning", "content": "In this section, we elaborate on the design of the Attention-aware Feature Fusion Module and the\nKnowledge-guided Cross-view Contrastive Learning mechanism, followed by the loss function used in our\nproposed model."}, {"title": "5.1. Attention-aware Feature Fusion Module", "content": "The item signal can be retrieved from embedding $M_i$ and $M_e$. However, each embedding represents a\ndifferent aspect of the item [25"}]}