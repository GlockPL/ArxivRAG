{"title": "Heterogeneous Hypergraph Embedding for Recommendation Systems", "authors": ["Darnbi Sakonga", "Viet Hung Vu", "Thanh Trung Huynh", "Phi Le Nguyen", "Hongzhi Yin", "Quoc Viet Hung Nguyen", "Thanh Tam Nguyen"], "abstract": "Recent advancements in recommender systems have focused on integrating knowledge graphs (KGs) to leverage their auxiliary information. The core idea of KG-enhanced recommenders is to incorporate rich semantic information for more accurate recommendations. However, two main challenges persist: i) Neglecting complex higher-order interactions in the KG-based user-item network, potentially leading to sub-optimal recommendations, and ii) Dealing with the heterogeneous modalities of input sources, such as user-item bipartite graphs and KGs, which may introduce noise and inaccuracies. To address these issues, we present a novel Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). KHGRec captures group-wise characteristics of both the interaction network and the KG, modeling complex connections in the KG. Using a collaborative knowledge heterogeneous hypergraph (CKHG), it employs two hypergraph encoders to model group-wise interdependencies and ensure explainability. Additionally, it fuses signals from the input graphs with cross-view self-supervised learning and attention mechanisms. Extensive experiments on four real-world datasets show our model's superiority over various state-of-the-art baselines, with an average 5.18% relative improvement. Additional tests on noise resilience, missing data, and cold-start problems demonstrate the robustness of our KHGRec framework. Our model and evaluation datasets are publicly available at https://github.com/viethungvu1998/KHGRec.", "sections": [{"title": "1. Introduction", "content": "Recommender Systems (RecSys) provide personalized suggestions to users by collecting and analyzing their past preferences and behaviors such as user profiles and user-item interactions [1, 2, 3, 4]. RecSys plays an essential role in various applications such as e-commerce websites, streaming services, social media platforms, news portals, e-healthcare [5]. In these applications, collaborative filtering (CF) methods are frequently employed, where items are recommended by the likes or actions of users with similar tastes. With the recent progression in deep learning structures, notably graph neural networks [6], various strategies integrating graph to conventional CF methods have emerged [7, 8]. These strategies effectively capture intricate connections between users and items, offering a comprehensive perspective on the interaction data. Despite these advancements, most existing CF techniques rely solely on user-item interaction data. The inherent limitation due to the scarcity of these interactions fundamentally restricts further enhancement in performance. In response to this challenge, integrating knowledge graph (KG) [9] has emerged as a prominent strategy in collaborative filtering, referred to as KG-enhanced collaborative filtering RecSys. Such techniques provide a comprehensive information network for items, consequently resulting in recommendations that are enhanced by the knowledge graph (KG) [10, 11]. For example, CKE [12] incorporates both topological and multi-modal information to generate embeddings. KGAT [13] introduces a mechanism to combine both user-item interaction and knowledge signal to construct a unified relational graph. This line of research opens a new direction for personalized Recsys by providing users with contextually relevant recommendations that match the user's preferences.\nThese models leverage the multiple layers aggregation mechanism to consider high-order interactions to an extent. Nevertheless, the current knowledge-enhanced collaborative filtering RecSys models built upon classical graph structures, where each edge primarily connects a pair of nodes, have proven inadequate in capturing the essential higher-order characteristics intrinsic to knowledge graphs (KGs) [14]. In real-world applications, the nature of relationships among objects frequently extends beyond simple pairwise interactions to include triadic, tetradic, or more complex configurations. Simplifying these complex relationships into binary ones results in a loss of critical information and reduces the system's expressiveness. Consequently, it limits the quality of recommendations as it neglects to identify user item groups sharing common patterns. For example, in movie recommendation systems like MovieLens and Netflix, users typically derive satisfaction from films within their preferred genre (e.g., action, horror, romance) or those featuring their beloved actors. This highlights the need for integrating group-wise (a.k.a higher-order) interaction within the recommendation process.\nThe integration of external data sources such as KG also raises the challenge of heterogeneous modality to the RecSys. Prior research [13] involves dynamic item embedding updates across the user-item and the external knowledge graph, capturing signals from diverse data sources but potentially introducing sub-optimal parameters due to noise. Recent methods like KGRec [15] independently learn user-item and knowledge graphs for distinct item embeddings, while KGCL [16] employs KG-enhanced item representations to guide cross-view contrastive learning, reducing noise. Despite representing the same item nodes, these embeddings exhibit varied distributions due to differing graph connectivity. Thus, the integration of data with different modalities requires careful consideration for possible conflict and noises.\nWe argue that a knowledge-assisted recommender system framework should be capable of handling the following challenges:\n\u2022 C1: Group-wise dynamics: The collaborative and knowledge graph has group-wise characteristics, e.g., a user interacts with multiple items, or an item relates to multiple entities. A solution thus needs to be capable of efficiently representing such characteristics.\n\u2022 C2: KG relational dependency: The relations between entities in KG are very complex. For instance, a film could be connected to various other entities through different relations - it could be directed by one entity (a director), starring several others (actors), belong to a certain genre, and so on. Each of these connections represents a different type of relationship, and together, they form a rich and intricate network of relational dependencies. Therefore, a solution should be capable of analyzing and understanding these relational dependencies.\n\u2022 C3: Explainability: In conventional collaborative filtering recommendation systems, suggestions are predominantly grounded in user-item interactions. This approach may yield recommendations that lack transparency and clarity. Consequently, an explainable knowledge-based recommender system is necessitated, one that is capable of providing insights into the rationale behind the selection of specific items.\n\u2022 C4: Consistency: In both collaborative and knowledge graphs, item entities may appear, creating a unique challenge. Specifically, latent features of the same entity from different latent embeddings should be close in proximity in the embedding space. This is based on the assumption that the same entity should have a similar representation across different graphs, reflecting its consistent characteris-tics. An effective solution, thus, should be capable of aligning entities of the same item across different embeddings."}, {"title": "To tackle the outlined challenges, this paper proposes a novel knowledge-based collaborative filtering Recsys named Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). Specifically, our method leverages heterogeneous hypergraph to better integrate the user-item bipartite graph and knowledge graph under the same modal as well as naturally capture the higher-order characteristics among the nodes. We then introduce a heterogeneous hypergraph convolution applied to the constructed hypergraph to simultaneously embed the group-wise characteristics of both input graphs and capture the complex relation-aware connections in the KG.\nThe contributions of this work are summarized as follows:\n\u2022 We propose KHGRec, a novel knowledge-enhanced collaborative filtering Recsys, which is the first method to couple the hypergraph's group-wise characteristics with the explainability of knowledge-enhanced Recsys to improve the recommendation's quality.\n\u2022 Drawing from input data, which includes user-item bipartite and knowledge graphs, we present a method for constructing a hypergraph data structure known as the Collaborative Knowledge Heterogeneous Hypergraph. This structure unifies the input graphs without introducing noises and facilitates the later representation learning.\n\u2022 We present a novel relational-aware hypergraph neural network, innovatively designed for mining the nodes' higher-order interactions and highlighting the node significance within hyperedges using attention mechanism, taking into account their relationships.\n\u2022 To seamlessly incorporate the signal retrieved from the two input graphs, we leverage the mechanism including two components. The first component leverages the attention mechanism to learn the optimal weight assigned for each latent matrix. Additionally, a cross-view self-supervised learning mechanism is employed to align similar entities from different latent spaces.\n\u2022 We perform extensive experiments with nine baselines on two popular datasets to justify the model's performance against state-of-the-art models. Our source code and dataset are publicly available.", "content": null}, {"title": "2. Problem and Approach", "content": "This section first introduces a motivating example and then describes the key structures and problem formulation for our paper.\n2.1. Motivating example\nIn this section, we present an example of knowledge-assisted recommendation, depicted in Fig. 1. For this example, we use data from the MovieLens dataset, a collection of movie ratings and interactions. This dataset is published by Grouplens. To add depth to our understanding, we connect the movies in this dataset to Freebase, a vast repository of structured information. Freebase aggregates detailed movie information, including the actors, directors, and genres, from reliable sources like Wikipedia and IMDB. In this example, three users exhibit interest in four films: \u201cOppenheimer\u201d, \u201cIron Man, \u201cThe Dark Knight Rises\", and \"Avengers\u201d. Utilizing additional knowledge from the knowledge graph, we categorize the films"}, {"title": "2.2. Problem Formulation", "content": "This section organizes key notations used throughout the paper and formalizes the problem of the recommender system with collaborative and knowledge signals.\nUser-item interaction. To perform recommendations, in most cases, we exploit the information history of interaction between users and items such as the records of clicks, watches, and purchases. Such interaction data can be formed as user-item bipartite graph $G_1$ which is compromised with a set of triplets $\\{(u, Y_{ui}, i)|u \\in U, i \\in I)\\}$ where the nodes are two disjoint sets U and I(i.e, user and item sets). This can be represented in a matrix format $y$, where the number of rows and columns corresponds to the number of users and items respectively. Each entry of the interaction matrix $Y_{ui} = 1$ if the user u has interacted with item i, otherwise 0.\nKnowledge graph. As extra supportive information, we leverage knowledge graph(KG) which represents the intricate relationships between real-world objects based on its own atomic unit, namely triplet. Formally, each triplet follows the form of $\\{(h, r,t)|h, t \\in E, r \\in R\\}$, where E and R indicate set of entities and relations respectively. For example, as it is shown in Figure. 1, a triplet (Peter Jackson, isDirectorOf, Lord of the Rings) states the fact that Peter Jackson is the director of the movie Lord of the Rings. It is worth noting that R involves both canonical(e.g., isDirectorOf) and inverse direction(e.g., isDirectedBy). Based on the richer connections between items and their attributes, the interpretability and quality of recommendations can be enhanced and more intelligible. For instance, a recommendation of a book can be generated based on its auxiliary information including but not limited to author, genre, or publisher."}, {"title": "Problem 1 (KG-enhanced recommendation)", "content": "Given the knowledge graph $G_2$, set of users U, set of items I, and the user-item interaction matrix Y, the problem is to learn a recommendation function $F = (u, i | Y, G_2, \\Omega)$ that predicts the non-interacted item i ($i \\in I$) that user u ($u \\in U$) would inclined to engage with, where $\\Omega$ denotes the learnable parameters of the model."}, {"title": "2.3. Approach Overview", "content": "In light of the above aspects, we propose a novel knowledge-assisted hypergraph recommendation system, as illustrated in Figure 2. Overall, we propose a novel recommender system framework that unifies the learning of user-item interactions and knowledge signals. Initially, raw data, comprising user-item bipartite and knowledge graphs, are harnessed to formulate a heterogeneous hypergraph, serving to retain the group-wise characteristics inherent in the input network, thus addressing challenge C1. However, this data structure cannot model the complex relational dependencies between nodes in the input network. Consequently, we advocate for a relation-aware heterogeneous hypergraph attention encoder network to learn the hypergraph representations while capturing the attentive bias of relations towards instances, hence resolving C2. By joint learning the embedding of user-item interactions and knowledge graphs, our proposed method can exploit the high-order dependencies among users and knowledge entities. Moreover, we apply the relation-aware attention mechanism to generate the attentive score, which allows us to easily capture the reason why a specific item is chosen, hence solving C3. Finally, our proposed method uses different encoders to encode distinct aspects of the original network that include user, item, and knowledge entity nodes. The node embeddings retrieved from different encoders might include common information, such as users, items, or knowledge entities. Hence, we developed a two-step method, including attentive aggreation of embeddings and cross-view self-supervised training mechanism to solve C4.\nTo this end, we need to realize the following functions to instantiate the framework:\nHeterogeneous hypergraph construction. As mentioned earlier, we combine the raw input data of the user-item bipartite graph and the knowledge graph to construct a heterogeneous hypergraph [17]. Unlike the classical hypergraph, the heterogeneous hypergraph contains different types of nodes and multiple sizes of hyperedges so that it can alleviate the restrictive nature of the traditional hypergraph. Nodes can represent either users, items, or knowledge entities. Hence, we propose a method to construct the input for the hypergraph embedding process."}, {"title": "Heterogeneous hypergraph representation learning", "content": "The constructed heterogeneous hypergraph consists of several subgraphs, each representing a distinct hypergraph snapshot, namely user, item, and collaborative knowledge entity. The first two snapshots offer localized views of the user-item interaction graph, while the latter presents a global perspective, encompassing both user-item interactions and knowledge-related signals. To clearly distinguish between these two types of snapshots, we designate them as the \"Local\" and \"Global\" views of the heterogeneous hypergraph. The \"Local\u201d view focuses on micro-level examinations, specifically analyzing interactions and relationships between individual users and items. This allows for an in-depth exploration of specific elements within the hypergraph. On the other hand, the \"Global\" view adopts a more expansive scope. It extends beyond the immediate user-item interaction to include collaborative knowledge entities, integrating all subgraphs into a unified analysis. To effectively learn from these \"Local\u201d and \"Global\u201d views, we introduce two tailored encoder networks: the Local self-aware hypergraph encoder and the Global relational-aware hypergraph encoder, respectively. The Local self-aware hypergraph encoder integrates a self-attention mechanism with hypergraph embedding to capture the group-wise char-acteristics in user-item interactions and to highlight the significance of nodes within their neighborhood. Conversely, the Global relational-aware hypergraph encoder merges a relational-aware attention mechanism with hypergraph embedding. This combination is designed to foster the understanding of relational ef-fects among instances and to capture the high-order dependencies between users and knowledge entities.\nFeature fusion module. To facilitate the learning of node embeddings from various hypergraph snapshots, we propose a two-step method that first employs an attention mechanism and then utilizes a cross-view self-supervised learning training scheme. This approach differs significantly from the attention mechanisms employed in graph encoders, which primarily focus on enhancing node embeddings. Specifically, the proposed attention mechanism functions as an aggregator and aims to combine latent features from different encoders. Meanwhile, the cross-view self-supervised learning scheme is designed to align similar entities' latent features across diverse latent spaces."}, {"title": "3. Collaborative Knowledge Heterogeneous Hypergraph", "content": "This section first introduces the definition of related data structure, including collaborative knowledge graph (CKG), and heterogeneous hypergraph. After that, we introduce collaborative knowledge hypergraph (CKHG) a novel data structure for unifying the user interaction and knowledge data and capturing the group-wise characteristics of the network, followed by a detailed description of how to construct it. The notation used is summarised in Tabl. 1.\n3.1. Definition of collaborative knowledge heterogeneous hypergraph\n[13] first introduces the concept of CKG, a data structure designed to capture the high-order relation-ship between users and knowledge entities. Specifically, the detailed explanation of this data structure is illustrated in Def. 1.\nDefinition 1 (Collaborative knowledge graph) Let $G$ represent the Collaborative Knowledge Graph (CKG), a structure encoding both user-item interaction signals and relational knowledge signals as a unified relational graph. The user-item interaction signals are derived from $G_1 = \\{(u, Y_{ui}, i)|u \\in U, i \\in I\\}$, and the relational knowledge signals are obtained from $G_2 = \\{(h,r,t)|h,t \\in E,r \\in R\\}$. In CKG, each user behavior is meticulously represented as a triplet, (u, Interact, i), wherein $Y_{ui} = 1$ is symbolized as an additional relation, termed Interact, existing between user u and item i. Subsequently, the CKG is formally represented as $G = \\{(h, r,t) | h, t \\in E',r \\in R'\\}$, where $E' = E\\cup U$ and $R' = R \\cup \\{Interact\\}$.\nWhile the CKG framework effectively integrates user-item bipartite and knowledge graphs into a unified graph, it overlooks the high-order interactions between users and knowledge entities. To address this, we propose using a data structure called heterogeneous hypergraph [18]. This data structure, characterized by its diverse node and edge types, outperforms other data structures in terms of capturing complex group-wise characteristics. The specifics of this heterogeneous hypergraph are elaborated in Def. 2.\nDefinition 2 (Heterogeneous Hypergraph) Assume that $G(V,E)$ is a hypergraph that contains |V| number of nodes and |E| number of hyperedges. A positive edge weight w(e) is given to each hyperedge $e \\in E$. Note that the assigned weights are positioned in diagonal entries in a diagonal matrix $W\\in R^{|E|\\times|E|}$. Information about the association of nodes with hyperedges is formalized with incidence matrix $A \\in R^{V|\\times|E|}$ which is a binary rectangular matrix, where $A_{ie}$ equals to 1 if node $v_i$ is part of the hyperedge e, otherwise 0. The sets V and E encompass $T_V$ and $T_E$ types of nodes and edges, respectively. G is classified as a heterogeneous hypergraph if either $T_V$ or $T_E$ is greater than 1, signifying the existence of multiple types of nodes and edges within the hypergraph.\nWe then introduce a novel data structure, named Collaborative Knowledge Heterogeneous Hypergraph (CKHG), specifically tailored for the knowledge-based recommender system challenges. CKHG combines user interactions and item knowledge entities into a unified heterogeneous hypergraph framework. Mirroring the CKG structure, user behavior is represented as a triplet, (u, Interact, i), with the addition of a distinct relation type Interact signifying the linkage between user u and item i. The definition of this proposed data structure is described as follows:\nDefinition 3 (CKHG) Let $G_H (V_H, E_H)$ represent the CKHG, where the number of node types $T_V$ and edge types $T_E$ are set to three, respectively. Specifically, the node set $V_H$ is defined as $V_H = \\{V_u, V_i, V_e\\}$, where $V_u, V_i$, and $V_e$ represent user, item, and knowledge entity nodes, respectively. Likewise, the edge set $E_H$ is articulated as $E_H = \\{E_i, E_u, E_e\\}$, with $E_i, E_u$, and $E_e$ corresponding to the item, user, and collaborative knowledge entity hyperedges, respectively. A fact in CKHG is encapsulated by a tuple $(h,r,t, S_t | h, t \\in V_H, r \\in R')$ with $R' = R \\cup\\{Interact\\}$. $S_t$ is the set of supporting pairs $\\{(v_i, r_i)\\}_{st}$ with $v_i$ and t are neighbours in the same hyperedge, and $r_i \\in R'$ is the corresponding relation of the triplet (h, $r_i$, $v_i$).\n3.2. Constructing hypergraph snapshots\nGiven the input as a CKHG, we follow the approach from [18] and decompose it into multiple hypergraph snapshots, with each snapshot encoding different information. Specificallly, the authors provide empirical evidence indicating that increasing the number of snapshots leads to a significant improvement in the model's convergence rate and the accuracy of its embeddings. This enhancement can be attributed to the \u201cdivide and conquer\u201d training approach employed by the model. Under this framework, the model learns the embedding of each snapshot independently and concurrently, thereby reducing introduced noise and"}, {"title": "Specifically, we define three types of hypergraph snapshots using the encoded information as follows:", "content": "\u2022 Item hypergraph: Let $G_i(V_u, E_i)$ is a subgraph of $G_H$. Here $V_u \\in V_H$ denotes the user nodes, and $E_i \\in E_H$ denotes the item hyperedges, with a hyperedge $e_i \\in E_i$ connecting users having interactions with item i.\n\u2022 User hypergraph: Let $G_u (V_i, E_u)$ is a subgraph of $G_H$. Here $V_i\\in V_H$ denotes the item nodes, and $E_u \\in E_H$ denotes the user hyperedges, with a hyperedge $e_u \\in E_u$ connecting items having interactions with user u.\n\u2022 Collaborative knowledge entity hypergraph: Let $G_e(V_e, E_i \\cup E_e)$ is a subgraph of $G_H$. This snapshot takes items and knowledge entities as hyperedges, with a hyperedge $e_k \\in (E_i\\cup E_e)$ connecting nodes $v_k \\in V_H$ having relation $r \\in R'$ with $e_k$.\nBy dividing the original big networks into smaller snapshots, we can learn these components simultaneously using different encoders, with each tailored for different purposes. This approach can lead to faster conver-gence of the model since our model now does not have to learn signals from different types of nodes and hyperedges, which often leads to suboptimal learned embedding. We then use different encoders to learn node embeddings in each snapshot and then aggregate these snapshots into a comprehensive representation. We divide the snapshots into two types based on the scope of the information encoded: Local view - including user and item hypergraph snapshots, and Global view, which is the collaborative knowledge entity hypergraph snapshot. While the former only encapsulates the user-item interaction, the latter captures both the user-item interaction and the item-entity relation while also demonstrating the high-order dependencies between the user and the knowledge entity. In order to learn the embedding of different types of snap-shots, we use two different architectures: Local Self-aware Hypergraph Encoder and Global Relational-aware Hypergraph Encoder, which will be discussed in detail in \u00a74."}, {"title": "4. Collaborative Knowledge Hypergraph Encoder", "content": "This section depicts our methodology for encoding both collaborative signals and collaborative knowledge signals using two specially designed encoder networks: Local Self-aware Hypergraph Encoder and Global Relational-aware Hypergraph Encoder."}, {"title": "4.1. Local Self-aware Hypergraph Encoder", "content": "In this section, we describe the architecture of the novel hypergraph convolution, e.g., Hypergraph Trans-former Self-Attention Networks, used in the proposed encoder, followed by the overall architecture of this architecture. We then proceed to give a detailed mathematical representation of the mentioned encoder.\nHypergraph Transformer Self-Attention Networks. Inspired by [19], we propose the Hypergraph Transformer Self-Attention Networks to capture the impact of neighboring nodes in the hypergraph ef-fectively. We first apply the transformer architecture [20] to all nodes in the input hypergraph G, where $\\Tilde{G} \\in \\{G_u, G_i\\}$. Mathematically, the hypergraph $\\Tilde{G}$ can be represented as:\n$\\Tilde{G} = (X, A),$   (1)\nwhere $X \\in R^{|V|\\times F}$ represents the node features matrix, $A \\in R^{|V|\\times|E|}$ is the incidence matrix, with || is the number of nodes of the hypergraph G.\nThis design choice aims to leverage the self-attention mechanism to learn the node importance in the graph. Specifically, we update the node embeddings with their neighboring nodes by stacking multiple graph transformer layers with a weight-sharing mechanism. Each layer is composed of two key functions: the self-attention and the transition function. Nodes are first passed through self-attention function ATT(.) to weigh varied attention scores to different neighboring nodes, thus encoding dependencies between the current node v and its neighbors. More precisely, the output of attention function $\\widehat{ATT}$ l-th layer and t time step can be defined as below:\n$\\widehat{ATT}- h^{(1)}_{t,n} = Norm ( h^{(l-1)}_{t,n}+ ATT (h^{(l-1)}_{t,n})), \\qquad$ (2)\n$ATT (h^{(l-1)}_{t,n}) = \\underset{n,\\Tilde{n} \\in N_v\\cup\\{v\\}}{\\Sigma} \\alpha_{n\\Tilde{n}}^{(l)} (V^{(l)}\\Tilde{h}_{t,\\Tilde{n}}^{(l-1)}) ,$  (3)\n$\\alpha_{n\\Tilde{n}}^{(l)} = softmax \\left( \\frac{(Q^{(l)}h_{t,n}^{(l-1)})^T(K^{(l)}h_{t,\\Tilde{n}}^{(l-1)})}{\\sqrt{d}}\\right) , \\qquad$ (4)\nwhere n,$\\Tilde{n} \\in N_v \\cup v$ are neighbor nodes of the given current node v, $h_{t,n}^{(l-1)}$ denotes the vector representation of n at l-th layer, Norm indicates Layer Normalization, $\\alpha_{n\\Tilde{n}}^{(l)}$ is attention score, $V^{(l)}, Q^{(l)}, K^{(l)} \\in R^{d\\times d}$ denotes linear projection matrices for value, query, and key respectively. The learned attention-aware intermediate parameters are then transferred to the Feed Forward Neural Network(FNN), which is denoted as Trans(\u00b7), followed by residual connection as below:\n$Trans - h^{(l)}_{t,n} = Norm (\\widehat{ATT} - h^{(l)}_{t,n}+ Trans (\\widehat{ATT} - h^{(l)}_{t,n})) , \\qquad$  (5)\nNote that, the topological information of input hypergraph $\\Tilde{G}$ vanishes after the propagation through the self-attention layer since it naturally connects all possible pairs of nodes with all positions engaging in interactions with one another. To overcome this limitation, we propose using a hypergraph convolution HConv() after each transformer self-attention layer, as illustrated in Figure 4.\nFollowing [21], before the propagation through convolution layers, we need to construct Laplacian matrix $\\in R^{d \\times d}$ of hypergraph $\\Tilde{G}$, which can be calculated as below:\n$\\Delta = I \u2013 D_v^{-1/2}AD_e^{-1}A^TD_v^{-1/2} \\qquad$ (6)\nwhere A denotes the incidence matrix, $D_V$ and $D_e$ are the degree matrices of nodes and hyperedges re-spectively. In the remainder of this paper, we use term $\\Theta$ for $I \u2013 D_V^{-1/2}AD_e^{-1}A^TD_v^{-1/2}$ for clarity of presentation. It is worth noting that the Laplacian matrix can further be transformed into diagonal matrix $\\Delta = \\Psi \\Lambda \\Psi^T$, where $\\Psi$ is eigenvector matrix and $\\Lambda$ is a diagonal matrix containing the eigenvalues of $\\Delta$ as its diagonal elements. Hence, HGConv(.) is mathematically represented as:\n$HGConv (X, \\Theta, P) = \\sigma (\\Theta \\cdot X \\cdot P), \\qquad$ (7)"}, {"title": "where P is a learnable weight matrix. Formally, we define a Hypergraph Transformer Self-Attention Net-works Convolutional (HGTNConv) layer as:", "content": "$H^{\\prime(l)} = Transformer (H^{(l)}Q^{(l)}, H^{(l)}K^{(l)}, H^{(l)}V^{(l)}), \\qquad$  (8)\n$H^{(l+1)} = HGConv (H^{\\prime(l)}, \\Theta, P), \\qquad$  (9)\nwhere $H^{(0)} = X$ is the node feature matrix."}, {"title": "We then stack multiple layers of HGTNConv on top of each other to construct the complete HGTN. The embedding operation of HGTN can be mathematically represented as follows:", "content": "$f(\\Tilde{G}, A) = HGTNConv^{(l)} (... HGTNConv^{(1)} (H^{(0)}, A), A), \\qquad$ (10)\nwhere I denotes the number of layers in HGTN.\nFurthermore, to strengthen the output signal, we utilize the residual term after the HGTN layer following the design in [22], which is denoted as Res. The complete mathematical representation of the Local Self-aware Hypergraph Encoder is as follows:\n$M_i = HGTN(G_i) + Res(X_i),\\qquad$ (11)\n$M_u = HGTN(G_u) + Res(X_u),\\qquad$  (12)\nwhere $G_i = (X_u, A_i)$ represents the item hypergraph snapshot, $X_u \\in R^{|V_u|\\times F}$ represents the user embedding, and $A_i \\in R ^{|V_i|\\times|V_u|}$ represents the item incidence matrix, with $|V_i|$, $|V_u|$ represent the number of items and users, respectively. Analogously, $G_u = (X_i, A_u)$ represents the user hypergraph snapshot, $X_i \\in R^{|V_i|\\times F}$ represents the item embedding, and $A_u \\in R^{|V_u|x|V_i|}$ represents the user incidence matrix."}, {"title": "4.2. Global Relational-aware Hypergraph Encoder", "content": "Inspired by the graph attention mechanisms in [? ), we design a relation-aware hypergraph attention layer to capture the relation heterogeneity over collaborative and knowledge graph connection structures (Figure 5). Specifically, instead of using the cosine similarity to measure the impact of neighboring nodes as in [21], we tailor the attention matrix using the relational-aware attention mechanism, thus better expressing the relational dependency between users-items-entities.\nRelational-aware Attention Mechanism. Given head entity h, the set of triples connected to h forms ego-centric network, $N_h = \\{(h,r,t)|(h,r,t) \\in G_e\\}$, where his head node(i.e., ego node) and t denotes the tail node [23].\nThen, followed [13], we denote the impact factor of tail entity t regarding the relation r to the head entity h as $\\pi$(h, r,t), with the mathematical formulation as follows:\n$\\pi (h, r,t) = (W_r e_t)^T tanh ((W_r e_h + e_r)), \\qquad$ (13)"}, {"title": "where tanh is the activation function, Wr is the learnable matrix. This results in the attention score being influenced by the proximity between en and et within the space of relation r, hence, allowing for more substantial information propagation for entities that are closer together. Then, the softmax function is applied to normalize the learned attention scores:", "content": "$\\pi(h, r, t) = \\frac{exp(\\pi(h, r, t))}{\\Sigma_{(h,r',t')\\in N_h} exp (\\pi (h, r', t'))} . \\qquad$  (14)\nRelational-aware Hypergraph Attention Convolution. We then propose the Relational-aware Hy-pergraph Attention Convolution (RHGATConv), where we employ the proposed attention mechanism to construct the attention matrix B, which is mathematically represented as follows:\n$B_{ij} = \\pi (h_i, r_{ij}, t_j), \\qquad$ (15)\nwhere $B_{ij}$ represents the impact factor of the tail entity $t_j$ to the head entity $h_i$ regarding the relation $r_{ij}$, which acts as a gating mechanism to control how much information the tail entity can transfer its corresponding head entity. The attention matrix is then multiplied with the original hypergraph incidence matrix to create a more dynamic incidence matrix, thus better revealing the intrinsic relationship between vertices. The attention hypergraph incidence matrix is formally denoted as:\n$\\widetilde{A} = B \\cdot A.\\qquad$  (16)\nDenoting $D_{\\Tilde{A}}D_e^{-1}\\widetilde{A}^TD_v^{-1/2}$ by $\\Tilde{\\Theta}$, we formally define a RHGATConv layer as follows:\n$H^{(l+1)} = \\sigma (\\Theta \\cdot H^{(l)} \\cdot P), \\qquad$ (17)\nwhere $H^{(0)} = X$ is the feature matrix of all nodes in the input hypergraph, A is the incidence matrix, and l denotes the l-th layer. We then stack multiple RHGATConv layers on each other to construct the complete RHGAT model. The embedding operation of RHGAT can be mathematically represented as follows:\n$f(G_e, B, A) = RHGATConv^{(I)} (... RHGATConv^{(1)} (H^{(0)}, B, A), B, A), \\qquad$ (18)\nwhere I denotes the number of layers in RHGAT.\nWe also utilize the residual term after the RHGAT layer. The complete mathematical representation of the Global Relational-aware Hypergraph Encoder is as follows:\n$M_e = RHGAT(X_e, A_e) + Res(X_e),\\qquad$  (19)\nwhere $M_e$ denotes the collaborative knowledge latent feature, $G_e = (X_e, A_e)$ represents the collaborative knowledge hypergraph snapshot, $X_e \\in R^{|V_e|XF}$ represents the collaborative knowledge entity embedding; $A_e \\in R ^{|V_e|x |V_e|}$ represents the incidence matrix of the corresponding hypergraph, Ve represent the total number of collaborative knowledge entities, and F represents the feature embedding size."}, {"title": "Semantic Representation Enhancement", "content": "To further encapsulate the relation-supported contextual information into the representation", "24": "to learn the plausibility of each triplet in the graph. In particular", "follows": "n$d(h", "relationship": "n$L_{KG} =  \\underset{(h,r,t)\\in T\\underset{(h,r,t')\\in T'}{\\Sigma}} \u2013 lno (d (h, r, t') \u2013 d(h, r,t)), \\qquad$  (21"}]}