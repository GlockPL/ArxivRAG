{"title": "Representation and Interpretation in Artificial and Natural Computing", "authors": ["Luis A. Pineda"], "abstract": "Artificial computing machinery transforms representations through an objective process, to be interpreted subjectively by humans, so the machine and the interpreter are different entities, but in the putative natural computing both processes are performed by the same agent. The method or process that transforms a representation is called here the mode of computing. The mode used by digital computers is the algorithmic one, but there are others, such as quantum computers and diverse forms of non-conventional computing, and there is an open-ended set of representational formats and modes that could be used in artificial and natural computing. A mode based on a notion of computing different from Turing's may perform feats beyond what the Turing Machine does but the modes would not be of the same kind and could not be compared. For a mode of computing to be more powerful than the algorithmic one, it ought to compute functions lacking an effective algorithm, and Church Thesis would not hold. Here, a thought experiment including a computational demon using a hypothetical mode for such an effect is presented. If there is natural computing, there is a mode of natural computing whose properties may be causal to the phenomenological experience. Discovering it would come with solving the hard problem of consciousness; but if it turns out that such a mode does not exist, there is no such thing as natural computing, and the mind is not a computational process.\nKeywords: Computation, Representation, Interpretation, Mode of Computing, Artificial Intelligence, Church Thesis, Consciousness.", "sections": [{"title": "1 Intuitive notions of computing machines", "content": "The Turing Machine (TM) was adopted as the general model of computing very soon after Turing's original paper was published (1). Together with Church's Thesis, stating that the TM computes the full set of functions that can be computed intuitively by people given enough time and material resources, or alternatively that every fully general machine or model of computing is equivalent to the TM (e.g. (2)), defines the notion of computing\n1"}, {"title": "2 Representation and Interpretation", "content": "A representation is a set of marks or distinctions on a physical medium -a material object- that is interpreted as mental content. We do not know what is the ultimate nature of mental contents, but we have introspective access to them: knowledge, beliefs, desires, intentions, feelings, emotions, pain and fear, and every thing that constitutes our psy- chological life, are mental contents. These are private and subjective to every cognitive individual, hence inaccessible to objective scientific investigation directly. However, they can be shared through communication, which provides a window to the mind. If there is communication, there is representation; and if there is representation, there is intentional action and interpretation. In spoken language, mental contents are \"placed on\" the wave sound, the medium, intentionally by the speaker, and are interpreted and \"placed in\" the mind of the listener. The mental contents in the minds of the speaker and hearer are similar to the extent to which communication is successful, but may differ in many respects due to contingencies of the production, transmission, and reception of the message, including the nature of the motor and sensory organs involved in linguistic communication, and the knowledge, beliefs, and expectations of the communicating individuals. Agents also inter- pret directly the signals and forces of the world, and in any case, the mind is constituted by interpretations. The \"transduction\" from material objects into mental contents and vice\n2"}, {"title": "3 Artificial Intelligence", "content": "Turing introduced the so-called imitation game in the 1950 paper, which was popularized as Turing's test, and stated that a machine that won it should be ascribed thought, under- standing, and consciousness (9), supporting that such machines have mental contents. He also advanced the construction of intelligent machines and gave a clear illustration with his chess program Turochamp, that used extensive symbolic search. After almost three decades of research in Artificial Intelligence (AI), Simon and Newell stated the so-called Physical Symbol Hypothesis according to which a system of physical symbols -the TM- has the necessary and sufficient conditions to generate general intelligence (10). Physical symbols are representations; hence, the machines that manipulate them, make interpreta- tions, and have content. Newell went further with such a line of discussion and stated that computing machines should be analyzed at different system levels, such that each level has its own functionality, input and output, and can be studied independently of the others (11). He postulated a hierarchy of system levels that includes the physical world at the bottom, with several physical hardware levels on top of it, supporting the so-called symbol level, which is directly below the knowledge level, as illustrated in Figure 1. The knowledge and the symbol levels correspond roughly to the computational and the algorithmic levels of Marr's system levels hierarchy (12).\n5"}, {"title": "4 Machines versus organisms", "content": "Machines are human inventions: devices that do useful work in predictable ways. Turing stated that the determinism of digital computers is more perfect in practice than that advocated by Laplace in the 1950 paper, and computers are the paradigmatic case of determinate machines. Indeterminacy involves the entropy, which is not included in the definition nor in the functionality of the TM. Living individuals, on their part, are natural organisms produced by evolution -they are not human inventions- and have some level of indeterminacy. Speaking of them as machines may derive from a deterministic conception of the Universe and the unity of science: the Universe is like a clock, and every thing within it is a machine too; hence there is no need to make the distinction between living entities and machines. However, rather than holding strong irreducible positions, the notion of machine may be relaxed, so the less determinate the entity, the lesser its machine-like nature. In particular, intentionality, agency and the mind, may enjoy an indetermination space where the entropy is not too low nor too high (13) (Section 12). Low or very low indeterminacy characterizes machines and automata; conversely, if the entropy is very high, there is very little structure or none, the behavior is chaotic, and life cannot be sustained. Biological organs, such as the heart, controlled by automatic biological mechanisms, such as homeostasis, may be considered standard biological machinery, but biological structures that support intentionality should not. Indeterminacy may be a necessary condition for intentionality, but it is not sufficient because what gives rise to phenomenological experience is still unexplained. Hybrid systems integrate biological with artificial machinery, and may also integrate machinery with the biological organs supporting higher mental function and intentionality. Turing explicitly stated in the presentation of the imitation game that humans are not machines, so the question of whether machines can think has content (9). The opposition between organisms and machines is central to natural and artificial computing, and should be considered in a check list of questions to clarify the positions on machine intelligence (20).\n7"}, {"title": "5 The Mode of Computing", "content": "The are alternative formalisms to the TM, such as the Lambda calculus, the theory of Recursive Functions, and the so-called Abacus Computation, which use registers as in the Von Nuemann architecture (2). Turing himself showed the equivalence between the TM and the Lambda calculus in the appendix of the 1936 paper (1), and all these machines compute the same set of functions and can be reduced to each other. Even recurrent neural networks are argued to be equivalent in this regard (21). All these formalisms use algorithms: a formal or mechanical procedure that transforms the representation of the argument of a function into the representation of its value, hence corresponds to the symbol level, which can be subsumed into a more general level that here we call the algorithmic level. Turing thesis, in its mathematical sense, is based on this equivalence.\n7"}, {"title": "6 The Computational Demon and Church Thesis", "content": "Church Thesis states that the TM computes the set of computable functions. In the intended sense, a function is computable if it has an effective algorithm: an algorithm that produces the value of an argument if it is defined, or a mark indicating that the function has no value for such an argument, for all the objects in the function's domain. To know this in general requires knowing whether the machine will halt or not for each of the function's arguments, and the so-called Halting Machine (HM) would have to be available. It is well known that the HM cannot be a TM (e.g. (2)). Hence, for knowing that a function is computable, it is necessary to find an algorithm that computes it, and show that it is effective in terms of its particular structure. Church Thesis would be refuted if a single function that does not have an effective algorithm were found but computed, as the machine performing such a feat would not be a TM.\nLet us think of computing functions through a mental experiment. Suppose that there is the computational demon. This is an omniscient being, such as Laplace's, who knows and is able to compute instantly all functions, total and partial, with finite and infinite domains\n8"}, {"title": "7 Natural Computing", "content": "If there is natural computing, there should be a natural mode of computing directly above the brain structures involved in cognition and immediately below the knowledge level. The definition of such mode would involve finding the format/s of mental representation/s and\n10"}]}