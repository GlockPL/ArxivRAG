{"title": "A Survey on Neural Architecture Search Based on\nReinforcement Learning", "authors": ["Wenzhu Shao"], "abstract": "Abstract-The automation of feature extraction of machine\nlearning has been successfully realized by the explosive\ndevelopment of deep learning. However, the structures and\nhyperparameters of deep neural network architectures also\nmake huge difference on the performance in different tasks.\nThe process of exploring optimal structures and\nhyperparameters often involves a lot of tedious human\nintervene. As a result, a legitimate question is to ask for the\nautomation of searching for optimal network structures and\nhyperparameters. The work of automation of exploring\noptimal hyperparameters is done by Hyperparameter\nOptimization. Neural Architecture Search is aimed to\nautomatically find the best network structure given specific\ntasks. In this paper, we firstly introduced the overall\ndevelopment of Neural Architecture Search and then focus\nmainly on providing an overall and understandable survey\nabout Neural Architecture Search works that are relevant with\nreinforcement learning, including improvements and variants\nbased on the hope of satisfying more complex structures and\nresource-insufficient environment.", "sections": [{"title": "I. INTRODUCTION", "content": "In the last decade, the process of feature extraction in\nmachine learning, which used to need a lot of expert work,\nhas been automated by the development of deep learning.\nHowever, the design of network architecture still rely heavily\non human's expertise and rich experience gained from\nnumerous experiments. In deep learning,\nhyperparameters play a significant role in the performance of\nthe network. Many networks that are proposed in some novel\npapers are hard for other researchers to implement. One of\nthe most important reasons for that is it also requires much\ntedious fine-tuning work done by experts to explore the\noptimal hyperparameters for their networks. Hence, it is\nrequired that machine take on the task of designing better\nnetwork architectures.\nBefore the deep learning became famous, the automation\nof searching the optimal hyperparameters mainly focused on\nthe parameters in traditional machine learning algorithms.\nThere existed some classical search strategies, such as\nrandom search, grid search, Bayesian optimization,\nreinforcement learning, and evolutional algorithms. All of\nthe strategies mentioned above are called as Hyperparameter\noptimization.\nThe hyperparameters in deep learning include training\nparameters and architecture parameters. The training\nparameters, such as learning rate, batch size and weight\ndecay, define how to train a deep neural network. The\narchitecture parameters define what the neural network\nconsists of. For example, the numbers of layers, the type of\neach layer and filter size in convolutional networks, these\nparameters decide the structure of the network. The\nchallenge is that these architecture hyperparameters are high-\ndimensional, discrete and mutual-related. The work of\nNeural Architecture Search (NAS) is trying to find the\noptimal architecture hyperparameters, even exploring novel\narchitectures which have not been proposed by human\nresearchers.\nSince the researchers first proposed the concept of Neural\nArchitecture Search, it has been a promising research project.\nThe overall steps of Neural Architecture Search are shown in\nFig. 1, and the descriptions are as follows:\n1) define a search space, in which, different network\nlayers and operations are represented as some embedding\nsuch as strings and vectors.\n2) apply a search strategy to search for the candidate\nnetwork architectures.\n3) build networks according to the search results and\nevaluate their performance in some tasks.\n4) begin next search iteration based on the evaluation of\nthe last generated networks."}, {"title": "II. CLASSICAL RESEARCHES ABOUT NEURAL\nARCHITECTURE BASED ON REINFORCEMENT LEARNING", "content": "In this section, different RL algorithms which have been\nincorporated in NAS as optimization methods will be\ndiscussed. Q-learning [9] is one of the most common\nalgorithms that is used to solve neural architecture search,\nwhich is often combined with epsilon-greedy and experience\nreplay. Q-learning was first used by researchers to propose\nMetaQNN which will be talked about with more detail in this\nsection [10]. Q-learning was also incorporated to search in a\ncell-based search space [2], which will also be mentioned in\nsection III. Policy gradient methods also function as an\nalternative as optimization methods. The Neural Architecture\nSearch going to be talked about in detail later in this section\nis the neural architecture search with reinforcement learning.\nIt was one of the first two pioneering researches that tried to\nuse reinforcement learning to solve neural architecture search\nproblems. It used a policy gradient method called\nREINFORCE [11] to update the parameters of the controller\n[6][12][13]. Policy gradient approaches like Proximal Policy\nOptimization (PPO) update rule [14] have also been applied\nto train the sampled architectures and update the controller\nsearching in cell-based search spaces [9], which will be\nmentioned later in section III. Monte Carlo method [15] is\nanother alternative way to search optimal structures. One of\nthe popular algorithms in Monte Carlo methods is the UCT\nalgorithm [16], which has been applied in several NAS\nresearch works [17]."}, {"title": "A. Neural Architecture Search", "content": "NAS uses a recurrent neural network as a controller to\nsample from a search space to generate new convolutional\nneural networks. The controller is trained with reinforcement\nlearning. Specifically, the controller acts as an agent to take\nactions to maximize the rewards by decide which description\nstring is generated in each recurrent network layer. The"}, {"title": "B. MetaQNN", "content": "The other one of the first two pioneering researches that\ncombined neural architecture search with reinforcement\nlearning is MetaQNN. It models neural architecture search\nproblems as Markov Decision process. The main procedures\nof MetaQNN are very similar with NAS which is mentioned\nabove. What is different is that the reward in MetaQNN is\nused to train the Q-learning algorithm. The researchers\ntrained NAS in datasets like SVHN, CIFAR-10 and MNIST\nwith 10 GPUs for 8 to 10 days. The best performance of the\ngenerated neural network can beat the same-scale networks\nwhich are build by human experts [10]."}, {"title": "III. IMPROVEMENT IN THE SPEED AND COMPUTATIONAL\nCOST", "content": "The two pioneering works of NAS with RL [6][10] need\ntoo much computational resource and are trained for too long.\nOn the one hand, the two models need to train the generated\nmodels on the validation dataset from scratch every time in\norder to get accuracy as the reward of the reinforcement\nlearning algorithms. And on the other hand, search space is\ntoo large when NAS search the optimal structures for the\nwhole architecture. The speed and computational cost are the\nmain obstructions for the NAS with RL to be experimented\nand applied widely. To solve these problems, more studies\nhave endeavored to improve the speed and reduce the\ncomputational cost have been published. Weight sharing is\none of the popular directions of improvement, which is\naimed to reuse the weights of existed networks. Hierarchical\nrepresentations can also accelerate the searching process by\nreducing the scale of search space."}, {"title": "A. Weight sharing", "content": "The researchers were inspired by Network Morphism, a\nmethod of transform the network without changing its\nfunction [20] to reuse the previously trained weights instead\nof training the weights from scratch. The Efficient\nArchitecture Search (EAS) generates new networks which\ncan represent the same functions as the given networks and\nare reparameterized to improve the performance. In this case,\nthere is no need for the new networks to be trained from\nscratch. Hence, it can greatly accelerate the training speed of\nthe generated networks. The meta-controller of EAS\nfunctions as a reinforcement learning agent, which takes\nactions for network transformation [12]."}, {"title": "B. Hierarchical Representation", "content": "Due to the fact that the deep neural networks started to\ninclude repeated sub-structures called cells or blocks in\nrecent years, researchers have been considering searching\nbased on cells, which means that NAS only search the\nstructures of the cells. But how to connect these cells is pre-\ndefined [1][2][3]. The search space is therefore reduced to\ninclude cells of identical structure but different weights.\nThe researchers of NASNet [3] designed a search space\ncalled NASNet search space to make the complexity of the\narchitecture unrelated with the depth of the network and the\nsize of input images. Searching for optimal blocks or cells\nnot only accelerates the speed of training, but also improves\nthe generalization ability of the generated models. Faster\nBlockQNN was further proposed with network performance\nprediction [1]."}, {"title": "C. Performance Prediction", "content": "The most time-consuming process of NAS is training the\ngenerated networks, which is aimed to evaluate the accuracy\nof the generated networks. To get the accuracy of the\nnetworks more time-efficiently, proxy metrics were used as\nthe approximation of the accuracy. For example, the\naccuracy of networks training in some smaller datasets or\ntraining for less epochs can function as an approximation [3].\nThough it may commonly underestimate the true accuracy of\nmodels, the target of this process is comparing performance\namong different networks instead of obtaining the absolute\nmetrics. Due to its efficiency, performance prediction has\nbecome more significant in NAS.\nFrom another perspective, it is possible to predict the\nperformance of the networks directly based on the structure\nof the models. A surrogate model was built to guide the"}, {"title": "IV. EXTENSIONS AND VARIANTS OF NEURAL ARCHITECTURE\nWITH REINFORCEMENT LEARNING", "content": "With the emerge of the need of applying artificial\nintelligence on platform devices such as mobile phones,\nmore light-weighted networks which are suitable for\nenvironments with limited resources such as MobileNet and\nShuffleNet started to be proposed and widely researched.\nNAS also evolved from single objective which only\nconsiders accuracy to multiple objectives which consider\naccuracy, compute intensity, memory, power consumption,\nlatency and so on. However, one of the challenges of the\nmulti-tasks optimization problems is that single solution\nwhich can reach the optimal situation of all the subtask"}, {"title": "A. Multi-objective NAS", "content": "Mobile neural architecture search (MNAS) approach [25]\ntakes model latency into consideration of the main objective\nso that the search can identify a model that balances well\nbetween accuracy and latency. Resource-efficient neural\narchitect (RENA) [26] takes computational resource use into\nconsideration of automated NAS targets. RENA can find\nnovel architectures that perform competitively even with\ntight resource constraints. Multi-objective neural\narchitectural search (MONAS) [27] optimizes both accuracy\nand other objectives that are brought about by numerous\ndevices such as embedded systems, mobile devices and\nworkstations."}, {"title": "V. CONCLUSION", "content": "Although the automation of deep learning can generate\narchitectures that perform better than the state-of-the-art\nhand-crafted networks, the gap is not as large as it is\nsupposed to. One reason for this is too much restrictions that\nare imposed on the search space. Common search space\nconsists of existing human-designed blocks such as\nconvolutional layers and pooling layers. It is less possible for\nthe neural architecture search to automatically generate novel\nbuilding blocks. It may increase the performance of the\nautomatically generated models substantially by reducing the\nlimitations on the search space. Hence, the searching for\ninnovative elements of new architectures will be desirable."}]}