{"title": "It Cannot Be Right If It Was Written by AI:\nOn Lawyers' Preferences of Documents Perceived\nas Authored by an LLM vs a Human", "authors": ["Jakub Harasta", "Tereza Novotn\u00e1", "Jaromir Savelka"], "abstract": "Large Language Models (LLMs) enable a future in which certain types of legal\ndocuments may be generated automatically. This has a great potential to stream-\nline legal processes, lower the cost of legal services, and dramatically increase\naccess to justice. While many researchers focus their efforts on proposing and\nevaluating LLM-based applications supporting tasks in the legal domain, there\nis a notable lack of investigations into how legal professionals perceive content if\nthey believe it has been generated by an LLM. Yet, this is a critical point as over-\nreliance or unfounded skepticism may influence whether such documents bring\nabout appropriate legal consequences. This study is the necessary analysis in the\ncontext of the ongoing transition towards mature generative AI systems. Specifi-\ncally, we examined whether the perception of legal documents' by lawyers (n=75)\nvaries based on their assumed origin (human-crafted vs AI-generated). The par-\nticipants evaluated the documents focusing on their correctness and language\nquality. Our analysis revealed a clear preference for documents perceived as\ncrafted by a human over those believed to be generated by AI. At the same time,\nmost of the participants are expecting the future in which documents will be gen-\nerated automatically. These findings could be leveraged by legal practitioners,\npolicy makers and legislators to implement and adopt legal document genera-\ntion technology responsibly, and to fuel the necessary discussions into how legal\nprocesses should be updated to reflect the recent technological developments.", "sections": [{"title": "1 Introduction", "content": "This paper analyzes the differences in lawyers' perceptions of documents believed to\nbe either generated by AI or authored by humans. The aim of this study is to react\nto the revolution brought about by the recent advances in Large Language Models\n(LLMs), and provide crucial insights necessary for responsible design, development,\nand adoption of LLM-powered applications focused on automated generation of legal\ndocuments. Should it be known it is LLM-generated, potential distortions in the per-\nception of a legal document present a serious ethical concern. For example, it would\nbe highly undesirable if a judge denies a rightful claim because they perceive the argu-\nments in a complaint as less persuasive, knowing the document has been automatically\ngenerated. To investigate this pressing concern, we had a large group of lawyers (n=75)\nevaluate documents marked as AI-generated or human-crafted in terms of their cor-\nrectness and language quality. Further, we surveyed the participants on their beliefs\non the ability of LLMs generating legal documents in the future.\nChatGPT\u00b9 was launched on November 30, 2022, and it immediately sensitised the\ngeneral public to the capabilities of LLMs to write fluent texts and lead conversations\nin natural language. While the foundational GPT-3 model has been available since\n2020 (Brown et al, 2020), it was the accessibility of the ChatGPT service that made\nlegal practitioners, educators, and scholars alike engage in heated discussions as to\nhow the legal profession may change in the near future. There have been numerous\nexamples of applications of the technology to tasks traditionally reserved exclusively\nfor legal experts. For example, Perlman (2022) claims that ChatGPT requires re-\nimagining how to obtain legal services and prepare lawyers for their careers he does\nso in a human-authored abstract to a scholarly article automatically generated with\nChatGPT. Katz et al (2024) tested GPT-4 on the Uniform Bar Examination (UBE),\nreporting the system passed the exam. Blair-Stanek et al (2024) show how even smaller\nLLMs can achieve near perfect performance on basic tasks involving legal texts, if they\nare fine-tuned. Such use cases hint at future applications of LLMs in providing legal\nservices and increasing access to justice, namely answering legal questions, providing\nlegal information, and importantly drafting legal documents.\nThe potential for automation, enhancement or support through LLMs is grow-\ning. Due to user-friendly access to LLMs through applications and interfaces (e.g.,\nChatGPT, Bard, Copilot), the experimentation with AI-based tools is available to\nmasses desiring to become early adopters of the disruptive technology. However, the\nchallenge of the wide use of LLMs lies in more than just its ability to achieve high\n(even human-like) accuracy when engaging in various tasks. If the output of LLMs\nis not acknowledged or perceived as accurate by the relevant actors, it may become\ninconsequential even if objectively accurate. The reception and perception of LLMs'\noutput, which is tied to various societal and psychological aspects of communication,\nis a pressing and understudied issue.\nExisting interdisciplinary research suggests generally negative sentiment towards\ntechnology, ranging from hesitancy (von Eschenbach, 2021) to aversion (Jussupow\net al, 2020; Castelo and Ward, 2021). Studies focusing on technology acceptance in"}, {"title": "2 Related Work", "content": "Experiments by Bubeck et al (2023) and a survey by Naveed et al (2024) have shown\nthat LLMs offer possibilities and promises in various domains, including law. Law is\nbased mainly on written language and is often lauded for its overwhelming production\nof information and documents. With the ever-increasing interest in NLP in the legal\ndomain noted by Katz et al (2023), significant advances in law-related NLP research\nwere brought by pre-trained Transformed-based Language Models (TLMs) reviewed\nby Greco and Tagarelli (2023). The subsequent introduction of LLMs to the public\nfueled significant interest in its law-related applications noted by Lai et al (2023).\nWe present an overview of the related work in three broadly defined areas:\n1. Perception of AI-generated Content in Various Domains (Subsection 2.1) is focused\non the crucial underlying issue of the perception of AI-generated content by pub-\nlic and other relevant actors. The issue must be separated from the performance\ndemonstrated by LLMs when engaging in various tasks."}, {"title": "2.1 Perception of AI-generated Content in Various Domains", "content": "Research on attitudes toward AI spans various contexts. Hancock et al (2020) concep-\ntualized AI-mediated communication, highlighting risks, such as undermining trust,\nand opportunities, such as augmenting natural communication abilities. von Eschen-\nbach (2021) observed a general hesitancy to trust AI, while Castelo and Ward (2021)\nnoted aversion toward AI echoing algorithm-related concerns raised by Jussupow et al\n(2020). These risks and opportunities are also expected to arise in the legal domain.\nIncreased aversion is reported when algorithms are involved in moral decision-\nmaking, particularly in domains deemed morally significant such as medicine and\nlaw Bigman and Gray (2018). Laakasuo et al (2021) demonstrated that decisions\nmade by human-like robots are perceived as less moral compared to robots without\nresemblance to humans. Interestingly, AI-mediated communication provides flexibility\nin interpersonal interactions, as users are inclined to attribute part of the responsibility\nfor negative feelings to the AI (Hohenstein and Jung, 2020).\nLower evaluations of AI-generated content have been reported across various\ndomains, including Airbnb profiles (Jakesch et al, 2019), emails (Liu et al, 2022),\nartworks (Ragot et al, 2020), music (Shank et al, 2023), translations (Asscher and\nGlikson, 2023), news articles (Waddell, 2018) or health prevention messages (Lim and\nSchm\u00e4lzle, 2024). The level of aversion to algorithms differs between tasks perceived\nas subjective and objective, with perceived task objectivity leading to greater accep-\ntance (Castelo et al, 2019). In healthcare, people tend to prefer human practitioners\nover AI-based technologies (Miles et al, 2021), expressing concerns over insufficient\npersonalization of care and incompetence (Longoni et al, 2019). Wang et al (2023b)\nemphasized the necessity of incorporating essential soft skills and core principles, such\nas professionalism, explainability, and empathy, into GPT-based tools for medical\nconsultations to overcome the aversion. Understanding the impact of AI-generated\ncontent on interactions within the legal domain is of utmost importance to ensure safe\ndeployment of AI-based tools and applications."}, {"title": "2.2 Automated Content Generation by LLMs in Legal Domain", "content": "Summarization Fine-tuning summarization models for niche domains may be pro-\nhibitively costly, which makes the use of LLMs (especially ChatGPT) appealing,\nparticularly in the health domain (Shaib et al, 2023; Tang et al, 2023), and will most\nprobably extend to the law as well. LLMs perform on par with human written sum-\nmaries in news summarization (Zhang et al, 2023; Goyal et al, 2023). Deroy et al (2023)\nexplored using pre-trained abstractive summarization models and LLMs for summa-\nrization in the legal domain. They acknowledged the limitations of fully automatic\napproaches and proposed a human-in-the-loop approach with legal experts monitoring\nthe quality of outcomes. LLMs have been utilized to create court decision summaries,\ncontributing to enhanced public trust in judicial outcomes (Ash et al, 2024). AI-\ngenerated summaries offer increased accessibility and lower the cognitive effort needed\nfor understanding, especially for non-experts. The logical progression includes sum-\nmarising legal and regulatory documents akin to transformer-based summarization\nmethods (Klaus et al, 2022). Ramprasad et al (2024) have reported efforts in this\ndirection, focusing on the factuality of zero-shot summaries across three domains,\nincluding legal bills. Additionally, Gesnouin et al (2024) introduced LLaMandement,\na fine-tuned model for generating neutral summaries of legislative proposals. The per-\nformance of LLM-based summarization models presents a significant potential benefit"}, {"title": "2.3 Use of LLMs in Legal Domain", "content": "Legal Reasoning The survey by Huang and Chang (2023) notes the significant\nprogress in NLP caused by the introduction of LLMs. However, the authors point out\nthat the extent to which LLMs can properly reason remains unclear. Blair-Stanek et al\n(2023) evaluated GPT-3 on the statutory-reasoning dataset SARA. The authors noted\napparent limitations due to imperfect prior knowledge of U.S. statutes and poor per-\nformance on synthetic statutes not encountered during training. Studies by Nguyen\net al (2023a,c,d) reported further limitations of using LLMs for legal reasoning. Addi-\ntionally, Nguyen et al (2023b) analysed the performance of GPT-3.5 and GPT-4 on\nthe COLIEE Task 4 dataset. The authors raised concerns about the GPT models'\nability to generalize and learn adaptable rules for unknown cases. During the prelim-\ninary exploration of the ability of GPT-3.5 for reasoning about the FOIA requests,\nBaron et al (2023) reported ChatGPT performing below the level of an experienced\nFOIA reviewer. On the other hand, ChatGPT exhibited the ability to bring valuable\nrecommendations accompanied by legal reasoning. Yu et al (2023) suggested that the\nreasoning capabilities of LLMs can be significantly improved by Chain-of-Thought\nprompting and fine-tuning with explanations. The research indicates that the best\nresults are achieved using prompts directly derived from specific legal reasoning tech-\nniques (e.g., IRAC). Guha et al (2023) prepared a robust typology for organizing legal\ntasks and evaluating 20 LLMs from 11 different families to provide a benchmark for\nthe legal reasoning capabilities of LLMs. Following the modified IRAC structure, the\nevaluation revealed diverging performance levels, with GPT-4 emerging as the most\nsuccessful model. Generally, LLMs perform better on classification tasks than those\nfocused on application. Kang et al (2023) evaluated GPT-3.5's ability to conduct IRAC\nanalysis. The research found that powerful LLMs can provide reasonable answers but\nmostly fail to yield correct reasoning paths. Finally, Janatian et al (2023) suggest using\nGPT-4 to extract pathways from real-world legislation to support the development\nof legal expert systems. Their evaluation yielded that 60% of the generated pathways\nwere equivalent or superior to manually created ones.\nSupport for Legal Research and eDiscovery Various tasks related to legal\nresearch, legal information retrieval or eDiscovery can be supported by LLMs. Savelka\net al (2023b) demonstrated the effectiveness of GPT-4 augmented with a legal infor-\nmation retrieval module, which significantly improved the accuracy of explanations\nof legal concepts. These findings correspond with Blair-Stanek et al (2024), who used\nnon-augmented models. The authors reported poor performance of most state-of-the-art\nLLMs (including GPT-4) in basic legal text-handling tasks, referring to them as\n'sloppy paralegals'. Integrating LLMs with knowledge bases (Cui et al, 2023) and\nother tools allowing, e.g., factual lookups (Schick et al, 2023) and gathering refer-\nences (Nakano et al, 2022) can boost performance. However, the existing research is\nfocused on domains outside of law. Huang et al (2023) emphasized the importance\nof domain-specific knowledge over the general experiences distilled from ChatGPT,"}, {"title": "3 Evaluation Experiment", "content": "We conducted an evaluation experiment of two documents (Brief and Verbose) detailed\nin Subsection 3.1 and two groups of evaluators described in Subsection 3.2. Group A\nreceived the Brief document labelled as AI-generated and the Verbose one labelled\nHuman-crafted. Group B received the documents with opposite labelling. Participants\nwere instructed to evaluate the language quality and correctness of the documents\nthrough a survey. They were allowed to provide open-ended comments to their\nevaluation. Details about the survey can be found in Subsection 3.3."}, {"title": "3.1 Documents", "content": "We prepared two written acknowledgements of debt. Both documents were drafted to\nfit on one page. One document was prepared to be as brief as possible (Brief), while the\nother was drafted to contain some additional information (Verbose). Both documents\nwere prepared to comply with standard practices (e.g., designation of parties, legal\njargon used).\nThe Brief document contained the headline 'Acknowledgement of Debt' followed\nby the designation of both the debtor and the creditor (name, surname, date of birth,\naddress). The following part outlined the origin of the debt (failure to pay the lease).\nSubsequently, the document contained an explicit acknowledgement of debt required\nby law and the due date. Finally, there was a confirmation that the acknowledgement\nwas not written under duress. The brief document was approximately 200 words in\nlength.\nThe Verbose document contained the structured designation of the debtor and\nthe creditor (name, surname, date of birth, address) followed by the headline 'Acknowl-\nedgment of Debt'. The document contained an explicit acknowledgement of debt\nrequired by law. Subsequently, the document outlined the origin of the debt (failure\nto pay the lease) in a structured and more detailed manner. Finally, the document\ncontained the due date and the confirmation that it was not written under duress.\nThe verbose document was approximately 250 words in length.\nFurther, each document was modified into two versions. One version was labelled\n'AI-GENERATED DOCUMENT' in both the header and the footer in blue high-\nlight. The other version was labelled 'HUMAN-CRAFTED DOCUMENT' in both the\nheader and the footer in yellow highlight. We avoided using green and red highlights\nfor their well-known associations to correct and incorrect options."}, {"title": "3.2 Participants", "content": "We recruited participants through a mailing campaign at an R1 university in Europe,\nand calls for participants distributed via Facebook and Twitter, reaching approxi-\nmately 1,200 people. A total of 89 prospective subjects expressed their interest in\nparticipating. Of the 89 participants, 53 were law students enrolled in a law degree\ngranting program, and 36 were lawyers. We used stratified random sampling to divide\nparticipants into two groups: Group A and Group B.\nGroup A comprised 26 law students and 18 lawyers, totaling 44 participants. We\nreceived completed surveys from 39 participants (88.6%) 22 law students (84.6%)\nand 17 lawyers (94.4%). Five participants failed to complete the survey.\nGroup B comprised 27 law students and 18 lawyers, totalling 45 participants. We\nreceived completed surveys from 36 participants (80%) \u2013 20 law students (74.1%) and\n16 lawyers (88.9%). Nine participants failed to complete the survey.\nOriginally, we planned to discard the answers from participants who completed the\nsurvey in under ten minutes. We did not discard any answers for this reason as all of\nthe participants took longer to finish the survey."}, {"title": "3.3 Survey", "content": "The evaluation was conducted online via Microsoft Forms. Group A was presented with\nthe Brief document labelled as AI-generated and the Verbose document labelled as\nHuman-crafted. Group B was presented with the Brief document labelled as Human-\ncrafted and the Verbose document labelled as AI-generated. Participants were not\nmade aware that both documents were Human-crafted. Survey was distributed to\nall the participants on January 30, 2024. Participants were requested to finish their\nevaluation by February 11, 2024.\nParticipants were to score the documents on a scale of 1 (worst) to 5 (best) in\nterms of the following categories:\n1. Language Quality: The degree to which the document conforms with the language\nexpectations associated with legally binding documents. The participants were\ntasked to check for grammatical and stylistic errors or the use of inappropriate\nwords within a given context.\n2. Correctness: The degree to which the document is correct. The participants were\ntasked to consider the fulfilment of legally required conditions and factual and\nformal coherence.\nParticipants were also asked to provide short explanations (100 words suggested)\nfor each scoring question. Finally, the evaluation included an open-ended question to\ncollect participants' opinions on the possibility of generating debt acknowledgement\nautomatically and achieving output quality comparable to humans.\nIn summary, the participants encountered the following questions:\n\u2022 Question 1: Score the language quality of the AI-generated document\n\u2022 Question 2: Briefly explain the score given in Question 1\n\u2022 Question 3: Score the correctness of the AI-generated document\n\u2022 Question 4: Briefly explain the score given in Question 3"}, {"title": "4 Results", "content": "While both documents were authored to be of comparable quality it appears that the\nverbose one was preferred by the participants, especially in terms of correctness. The\nmean overall correctness rating of the brief document was 4.24 (39\u00d7 presented as AI-\ngenerated and 36\u00d7 as human-authored) compared to the 4.67 of the verbose one (36\u00d7\nAI and 39\u00d7 human). Seen side-by-side, the participants judged the verbose document\nas more correct than the brief one 34 times (out of 75). The brief document was\ndeemed as more correct only 9 times. In the remaining 32 times the documents were\nevaluated as comparable. In terms of language, the trend was still there (4.39 verbose\nversus 4.13 brief) where the verbose document was preferred 26 times compared to\n12 preferences for the brief one (37 neither).\nWhile the comparison of the\ndocuments is not the subject of this study it presents an important aspect that needs\nto be considered when interpreting the results below."}, {"title": "4.2 Correctness", "content": "Figure 4 shows the overall evaluation of the documents in terms of correctness, focusing\non whether a document was labeled as human-crafted or AI-generated. It appears that\nthe participants clearly preferred a document when it was presented as human-crafted\nover a document labeled as AI-generated. Specifically, the mean evaluation of the two\ndocuments when labeled as human-crafted was 4.69 as compared to 4.21 when the\nsame documents were marked as AI-generated. The side-by-side comparison presents\na clear message when the human-crafted designation yielded 35 preferences over the\nmere 7 of the documents perceived as generated by AI (33 neither). This difference is\nstatistically significant by Fisher exact test (p < 10\u22125).\nFigure 5 provides insight into the interaction between the AI/human-authored\ndesignation and the individual documents. While the verbose document appears to\nbe clearly preferred by the participants overall (Figure 3), the effect is negated if it\nis marked as AI-generated, and the brief document as authored by a human. In that\ncase, we can even observe that the brief document was deemed as slightly more correct\non average (4.5 brief versus 4.44 verbose). In terms of the side-by-side comparisons,"}, {"title": "4.4 Beliefs in the Possibility of Automatic Generation", "content": "After evaluating the documents, the participants were asked to answer an open-ended\nquestion on the possibility of the fully automated generation of the documents similar\nto those they have just seen. The overwhelming majority of 93% of the participants\nanswered that they believed this is going to be possible. Only 5% remained uncertain,\nand merely 2% believed this to be impossible. We further explored the reasons that\nled the evaluators to believe in the possibility of future automation. Responses to this\nquestion were thematically coded following the methodology described in Subsections\n3.3. The codes were then collated into five higher-level themes as follows:\n\u2022 Documents Indistinguishable the evaluators claimed that they found human-\ncrafted and AI-generated documents practically indistinguishable and thus full\nautomation was possible.\n\u2022 Expected Legal Consequences - the evaluators argued that if, despite some reserva-\ntions, the document is capable of producing the expected legal consequences, then\nit is very likely that full automation of such documents is possible."}, {"title": "5 Discussion", "content": "The results of our study reveal several significant trends that are of utmost importance\nto the legal profession and researchers in AI and law.\nBefore we approach individual issues, we must address the overarching trend,\nwhich, while not the subject of our study, is noteworthy. The documents were\nprepared to be of comparable quality, terminology, and structure, established via\ncross-validation within the authors' team and by approaching an experienced attorney\noutside the authors' team. However, the Verbose document, on average, outperformed\nthe Brief document in the evaluation, both in terms of correctness and language qual-\nity. Detailed investigation of the trend reveals though that, e.g., a Brief document\nlabelled as Human-crafted outperforms Verbose documents labelled as AI-generated.\nHowever, the difference is not significant enough to overcome the general preference\nof the Verbose document by both lawyers and law students. Such a preference may be\nrooted in the tendency of legal professionals to associate length with precision.\nAdditionally, it reflects the tacit nature of legal knowledge. Civil law, of which the\nacknowledgement of debt we used in the study is the prime example, uses dispositive\nnorms. Unlike cogent norms, dispositive norms allow contracting parties to reach an\nagreement which is, in detail, different from the law. It might be that lawyers preferred\nthe Verbose document in their expectation that it captures the will of the parties\nexpressly and fully and does not leave any part of the contract tacitly bound to the\nCivil Code. While we noted the general preference for the Verbose document over\nthe Brief one, the AI-generated Verbose document was rated worse than the Brief\ndocument labelled Human-crafted. Lawyers expect longer Human-crafted documents\nto be a sign of eloquence, while longer AI-generated documents indicate uncertainty"}, {"title": "6 Implications for Legal Practice", "content": "The disruptive potential of LLMs is immense. The most often appearing opportunities\nare decreasing costs associated with legal services and increasing access to justice.\nChatGPT's appeal partly lies in the democratization of legal services. Lawyers' services\nare often perceived as prohibitively costly. Laymen already use LLMs to address their\nlegal needs (Hagan, 2024), and the trend is likely to grow.\nTwo major issues stand in the way:\n1. the accuracy of the provided information and generated documents, and\n2. perceptions and attitudes towards AI-generated content."}, {"title": "7 Limitations", "content": "While our study provides valuable insight into preferences and perceptions regarding\nAI-generated legal documents, limitations must be acknowledged.\nThe participants of our study, law students and lawyers, are a relevant demographic\nfor evaluating legal documents. However, it is important to note that the results may\nnot generalize well in other contexts, such as among officials, judges, prosecutors, or\nthe general population. These groups may perceive AI-generated documents differently\ndue to their varying levels of prior knowledge and different encounters with legal issues.\nOur study's limited number of participants may have introduced some bias to\nthe results. As a result, some of the reported results, particularly those related to\n'correctness' and 'language quality', may not be statistically significant. This limited\nevaluation does not provide a sufficiently detailed look at the various properties of\nthe documents. A more comprehensive thematic analysis is a necessity to address this\nlimitation."}, {"title": "8 Conclusions and Future Work", "content": "Our study evaluated the acknowledgement of debt documents. While the document\nis commonly used and is a relevant case study, our findings may not extend to other\nlegal documents. Additionally, acknowledgement of debt is simple. Different document\ntypes have more complex legal requirements or linguistic and structural properties.\nExploring a more comprehensive range of legal documents would lead to more robust\ndata.\nWe did not address the issue of prior use or exposure to AI when recruiting the par-\nticipants. Such a variable may prove significant regarding expectations and perceptions\nof AI-generated documents.\nFinally, we evaluated the documents in the Czech language. As a demographic,\nCzech lawyers and law students may have been less exposed to LLMs and less accus-\ntomed to their use than other nationalities. Additionally, Manvi et al (2024) reported\nLLMs to be geographically biased because of used training corpora and demonstrated\nlanguage capabilities. Expectations tied to AI-generated documents in Czech as one\nof the minor languages - may have influenced the results reported above.\nAddressing these limitations in future research will be crucial to achieving more\ngeneralizable and potentially practical results.\nOur study shed light on how lawyers perceive AI-generated legal documents compared\nto Human-crafted documents. Participants rated the AI-generated documents worse\nthan their Human-crafted counterparts.\nParticipants were more critical of language quality than correctness, with AI-\ngenerated documents receiving significantly more negative comments. The aversion\nto AI-generated legal content aligns with existing research on algorithmic aversion in\nother domains. Documents labelled as human-crafted received higher overall scores and\nmore positive comments, reflecting a possible general preference for the involvement\nof human experts in producing legal content.\nDespite the prevalent negative perception, our study reveals significant optimism\namong the participants about the future of automating legal content production.\nThey highlighted factors such as the indistinguishability between Human-crafted\nand AI-generated content and the ability of AI-generated content to produce legal\nconsequences, indicating a potential shift in perception in the future.\nOur study is the first effort to understand the perception of AI-generated content\non its recipients in the legal domain. Our study confirms the negative perception of\nAI-generated content and the general preference for Human-crafted documents.\nWhile our findings are significant, they should be a starting point for further\nresearch. The potential repercussions for providing legal services, particularly for\nlower-income groups and the mandatory designation of AI-generated documents,\nrequire careful evaluation. Further research must focus on other populations, larger\nsamples, and more complex documents, as well as a nuanced understanding of doc-\numents' objective and subjective properties and the prior knowledge of intended\nrecipients."}]}