{"title": "It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human", "authors": ["Jakub Harasta", "Tereza Novotn\u00e1", "Jaromir Savelka"], "abstract": "Large Language Models (LLMs) enable a future in which certain types of legal documents may be generated automatically. This has a great potential to streamline legal processes, lower the cost of legal services, and dramatically increase access to justice. While many researchers focus their efforts on proposing and evaluating LLM-based applications supporting tasks in the legal domain, there is a notable lack of investigations into how legal professionals perceive content if they believe it has been generated by an LLM. Yet, this is a critical point as over-reliance or unfounded skepticism may influence whether such documents bring about appropriate legal consequences. This study is the necessary analysis in the context of the ongoing transition towards mature generative AI systems. Specifically, we examined whether the perception of legal documents' by lawyers (n=75) varies based on their assumed origin (human-crafted vs AI-generated). The participants evaluated the documents focusing on their correctness and language quality. Our analysis revealed a clear preference for documents perceived as crafted by a human over those believed to be generated by AI. At the same time, most of the participants are expecting the future in which documents will be generated automatically. These findings could be leveraged by legal practitioners, policy makers and legislators to implement and adopt legal document generation technology responsibly, and to fuel the necessary discussions into how legal processes should be updated to reflect the recent technological developments.", "sections": [{"title": "1 Introduction", "content": "This paper analyzes the differences in lawyers' perceptions of documents believed to be either generated by AI or authored by humans. The aim of this study is to react to the revolution brought about by the recent advances in Large Language Models (LLMs), and provide crucial insights necessary for responsible design, development, and adoption of LLM-powered applications focused on automated generation of legal documents. Should it be known it is LLM-generated, potential distortions in the per- ception of a legal document present a serious ethical concern. For example, it would be highly undesirable if a judge denies a rightful claim because they perceive the argu- ments in a complaint as less persuasive, knowing the document has been automatically generated. To investigate this pressing concern, we had a large group of lawyers (n=75) evaluate documents marked as AI-generated or human-crafted in terms of their cor- rectness and language quality. Further, we surveyed the participants on their beliefs on the ability of LLMs generating legal documents in the future.\nChatGPT\u00b9 was launched on November 30, 2022, and it immediately sensitised the general public to the capabilities of LLMs to write fluent texts and lead conversations in natural language. While the foundational GPT-3 model has been available since 2020 (Brown et al, 2020), it was the accessibility of the ChatGPT service that made legal practitioners, educators, and scholars alike engage in heated discussions as to how the legal profession may change in the near future. There have been numerous examples of applications of the technology to tasks traditionally reserved exclusively for legal experts. For example, Perlman (2022) claims that ChatGPT requires re- imagining how to obtain legal services and prepare lawyers for their careers he does so in a human-authored abstract to a scholarly article automatically generated with ChatGPT. Katz et al (2024) tested GPT-4 on the Uniform Bar Examination (UBE), reporting the system passed the exam. Blair-Stanek et al (2024) show how even smaller LLMs can achieve near perfect performance on basic tasks involving legal texts, if they are fine-tuned. Such use cases hint at future applications of LLMs in providing legal services and increasing access to justice, namely answering legal questions, providing legal information, and importantly drafting legal documents.\nThe potential for automation, enhancement or support through LLMs is grow- ing. Due to user-friendly access to LLMs through applications and interfaces (e.g., ChatGPT, Bard, Copilot), the experimentation with AI-based tools is available to masses desiring to become early adopters of the disruptive technology. However, the challenge of the wide use of LLMs lies in more than just its ability to achieve high (even human-like) accuracy when engaging in various tasks. If the output of LLMs is not acknowledged or perceived as accurate by the relevant actors, it may become inconsequential even if objectively accurate. The reception and perception of LLMs' output, which is tied to various societal and psychological aspects of communication, is a pressing and understudied issue.\nExisting interdisciplinary research suggests generally negative sentiment towards technology, ranging from hesitancy (von Eschenbach, 2021) to aversion (Jussupow et al, 2020; Castelo and Ward, 2021). Studies focusing on technology acceptance in"}, {"title": "2 Related Work", "content": "Experiments by Bubeck et al (2023) and a survey by Naveed et al (2024) have shown that LLMs offer possibilities and promises in various domains, including law. Law is based mainly on written language and is often lauded for its overwhelming production of information and documents. With the ever-increasing interest in NLP in the legal domain noted by Katz et al (2023), significant advances in law-related NLP research were brought by pre-trained Transformed-based Language Models (TLMs) reviewed by Greco and Tagarelli (2023). The subsequent introduction of LLMs to the public fueled significant interest in its law-related applications noted by Lai et al (2023). We present an overview of the related work in three broadly defined areas:\n1. Perception of AI-generated Content in Various Domains (Subsection 2.1) is focused on the crucial underlying issue of the perception of AI-generated content by pub- lic and other relevant actors. The issue must be separated from the performance demonstrated by LLMs when engaging in various tasks.\n2. Automated Content Generation by LLMs in the Legal Domain (Subsection 2.2) focuses on related work reporting the use of LLMs to create summaries, translations and answers to legal questions.\n3. The Use of LLMs in the Legal Domain (Subsection 2.3) summarizes related work reporting the use of LLMs for various tasks, such as legal reasoning, legal research, access to justice, annotation, and legal judgment prediction.\nThe related work clearly demonstrates a need for empirical studies regarding the perception of AI-generated documents in the legal domain. The overview below con- tains dozens of papers on supporting, enhancing or automating a plethora of tasks inherently perceived as requiring human attention. While the authors often report lower-than-human performance, GPT-4 significantly improves the already impressive capabilities. As a result, the use of LLMs is likely to penetrate every aspect of law. The remarkable breadth of the research conducted in the short time since November 2022 demonstrates the inevitability of AI, even in the legal domain. As such, the issue of the perception of AI-generated content in the legal domain becomes even more pressing."}, {"title": "2.1 Perception of AI-generated Content in Various Domains", "content": "Research on attitudes toward AI spans various contexts. Hancock et al (2020) concep- tualized AI-mediated communication, highlighting risks, such as undermining trust, and opportunities, such as augmenting natural communication abilities. von Eschen- bach (2021) observed a general hesitancy to trust AI, while Castelo and Ward (2021) noted aversion toward AI echoing algorithm-related concerns raised by Jussupow et al (2020). These risks and opportunities are also expected to arise in the legal domain.\nIncreased aversion is reported when algorithms are involved in moral decision- making, particularly in domains deemed morally significant such as medicine and law Bigman and Gray (2018). Laakasuo et al (2021) demonstrated that decisions made by human-like robots are perceived as less moral compared to robots without resemblance to humans. Interestingly, AI-mediated communication provides flexibility in interpersonal interactions, as users are inclined to attribute part of the responsibility for negative feelings to the AI (Hohenstein and Jung, 2020).\nLower evaluations of AI-generated content have been reported across various domains, including Airbnb profiles (Jakesch et al, 2019), emails (Liu et al, 2022), artworks (Ragot et al, 2020), music (Shank et al, 2023), translations (Asscher and Glikson, 2023), news articles (Waddell, 2018) or health prevention messages (Lim and Schm\u00e4lzle, 2024). The level of aversion to algorithms differs between tasks perceived as subjective and objective, with perceived task objectivity leading to greater accep- tance (Castelo et al, 2019). In healthcare, people tend to prefer human practitioners over AI-based technologies (Miles et al, 2021), expressing concerns over insufficient personalization of care and incompetence (Longoni et al, 2019). Wang et al (2023b) emphasized the necessity of incorporating essential soft skills and core principles, such as professionalism, explainability, and empathy, into GPT-based tools for medical consultations to overcome the aversion. Understanding the impact of AI-generated content on interactions within the legal domain is of utmost importance to ensure safe deployment of AI-based tools and applications."}, {"title": "2.2 Automated Content Generation by LLMs in Legal Domain", "content": "Summarization Fine-tuning summarization models for niche domains may be pro- hibitively costly, which makes the use of LLMs (especially ChatGPT) appealing, particularly in the health domain (Shaib et al, 2023; Tang et al, 2023), and will most probably extend to the law as well. LLMs perform on par with human written sum- maries in news summarization (Zhang et al, 2023; Goyal et al, 2023). Deroy et al (2023) explored using pre-trained abstractive summarization models and LLMs for summa- rization in the legal domain. They acknowledged the limitations of fully automatic approaches and proposed a human-in-the-loop approach with legal experts monitoring the quality of outcomes. LLMs have been utilized to create court decision summaries, contributing to enhanced public trust in judicial outcomes (Ash et al, 2024). AI- generated summaries offer increased accessibility and lower the cognitive effort needed for understanding, especially for non-experts. The logical progression includes sum- marising legal and regulatory documents akin to transformer-based summarization methods (Klaus et al, 2022). Ramprasad et al (2024) have reported efforts in this direction, focusing on the factuality of zero-shot summaries across three domains, including legal bills. Additionally, Gesnouin et al (2024) introduced LLaMandement, a fine-tuned model for generating neutral summaries of legislative proposals. The per- formance of LLM-based summarization models presents a significant potential benefit"}, {"title": "2.3 Use of LLMs in Legal Domain", "content": "Legal Reasoning The survey by Huang and Chang (2023) notes the significant progress in NLP caused by the introduction of LLMs. However, the authors point out that the extent to which LLMs can properly reason remains unclear. Blair-Stanek et al (2023) evaluated GPT-3 on the statutory-reasoning dataset SARA. The authors noted apparent limitations due to imperfect prior knowledge of U.S. statutes and poor per- formance on synthetic statutes not encountered during training. Studies by Nguyen et al (2023a,c,d) reported further limitations of using LLMs for legal reasoning. Addi- tionally, Nguyen et al (2023b) analysed the performance of GPT-3.5 and GPT-4 on the COLIEE Task 4 dataset. The authors raised concerns about the GPT models' ability to generalize and learn adaptable rules for unknown cases. During the prelim- inary exploration of the ability of GPT-3.5 for reasoning about the FOIA requests, Baron et al (2023) reported ChatGPT performing below the level of an experienced FOIA reviewer. On the other hand, ChatGPT exhibited the ability to bring valuable recommendations accompanied by legal reasoning. Yu et al (2023) suggested that the reasoning capabilities of LLMs can be significantly improved by Chain-of-Thought prompting and fine-tuning with explanations. The research indicates that the best results are achieved using prompts directly derived from specific legal reasoning tech- niques (e.g., IRAC). Guha et al (2023) prepared a robust typology for organizing legal tasks and evaluating 20 LLMs from 11 different families to provide a benchmark for the legal reasoning capabilities of LLMs. Following the modified IRAC structure, the evaluation revealed diverging performance levels, with GPT-4 emerging as the most successful model. Generally, LLMs perform better on classification tasks than those focused on application. Kang et al (2023) evaluated GPT-3.5's ability to conduct IRAC analysis. The research found that powerful LLMs can provide reasonable answers but mostly fail to yield correct reasoning paths. Finally, Janatian et al (2023) suggest using GPT-4 to extract pathways from real-world legislation to support the development of legal expert systems. Their evaluation yielded that 60% of the generated pathways were equivalent or superior to manually created ones.\nSupport for Legal Research and eDiscovery Various tasks related to legal research, legal information retrieval or eDiscovery can be supported by LLMs. Savelka et al (2023b) demonstrated the effectiveness of GPT-4 augmented with a legal infor- mation retrieval module, which significantly improved the accuracy of explanations of legal concepts. These findings correspond with Blair-Stanek et al (2024), who used non-augmented models. The authors reported poor performance of most state-of-the-art LLMs (including GPT-4) in basic legal text-handling tasks, referring to them as 'sloppy paralegals'. Integrating LLMs with knowledge bases (Cui et al, 2023) and other tools allowing, e.g., factual lookups (Schick et al, 2023) and gathering refer- ences (Nakano et al, 2022) can boost performance. However, the existing research is focused on domains outside of law. Huang et al (2023) emphasized the importance of domain-specific knowledge over the general experiences distilled from ChatGPT,"}, {"title": "3 Evaluation Experiment", "content": "We conducted an evaluation experiment of two documents (Brief and Verbose) detailed in Subsection 3.1 and two groups of evaluators described in Subsection 3.2. Group A received the Brief document labelled as AI-generated and the Verbose one labelled Human-crafted. Group B received the documents with opposite labelling. Participants were instructed to evaluate the language quality and correctness of the documents through a survey. They were allowed to provide open-ended comments to their evaluation. Details about the survey can be found in Subsection 3.3."}, {"title": "3.1 Documents", "content": "We prepared two written acknowledgements of debt. Both documents were drafted to fit on one page. One document was prepared to be as brief as possible (Brief), while the other was drafted to contain some additional information (Verbose). Both documents were prepared to comply with standard practices (e.g., designation of parties, legal jargon used).\nThe Brief document contained the headline 'Acknowledgement of Debt' followed by the designation of both the debtor and the creditor (name, surname, date of birth, address). The following part outlined the origin of the debt (failure to pay the lease). Subsequently, the document contained an explicit acknowledgement of debt required by law and the due date. Finally, there was a confirmation that the acknowledgement was not written under duress. The brief document was approximately 200 words in length.\nThe Verbose document contained the structured designation of the debtor and the creditor (name, surname, date of birth, address) followed by the headline 'Acknowl- edgment of Debt'. The document contained an explicit acknowledgement of debt required by law. Subsequently, the document outlined the origin of the debt (failure to pay the lease) in a structured and more detailed manner. Finally, the document contained the due date and the confirmation that it was not written under duress. The verbose document was approximately 250 words in length.\nFurther, each document was modified into two versions. One version was labelled 'AI-GENERATED DOCUMENT' in both the header and the footer in blue high- light. The other version was labelled 'HUMAN-CRAFTED DOCUMENT' in both the header and the footer in yellow highlight. We avoided using green and red highlights for their well-known associations to correct and incorrect options."}, {"title": "3.2 Participants", "content": "We recruited participants through a mailing campaign at an R1 university in Europe, and calls for participants distributed via Facebook and Twitter, reaching approxi- mately 1,200 people. A total of 89 prospective subjects expressed their interest in participating. Of the 89 participants, 53 were law students enrolled in a law degree granting program, and 36 were lawyers. We used stratified random sampling to divide participants into two groups: Group A and Group B.\nGroup A comprised 26 law students and 18 lawyers, totaling 44 participants. We received completed surveys from 39 participants (88.6%) 22 law students (84.6%) and 17 lawyers (94.4%). Five participants failed to complete the survey.\nGroup B comprised 27 law students and 18 lawyers, totalling 45 participants. We received completed surveys from 36 participants (80%) \u2013 20 law students (74.1%) and 16 lawyers (88.9%). Nine participants failed to complete the survey.\nOriginally, we planned to discard the answers from participants who completed the survey in under ten minutes. We did not discard any answers for this reason as all of the participants took longer to finish the survey."}, {"title": "3.3 Survey", "content": "The evaluation was conducted online via Microsoft Forms. Group A was presented with the Brief document labelled as AI-generated and the Verbose document labelled as Human-crafted. Group B was presented with the Brief document labelled as Human- crafted and the Verbose document labelled as AI-generated. Participants were not made aware that both documents were Human-crafted. Survey was distributed to all the participants on January 30, 2024. Participants were requested to finish their evaluation by February 11, 2024.\nParticipants were to score the documents on a scale of 1 (worst) to 5 (best) in terms of the following categories:\n1. Language Quality: The degree to which the document conforms with the language expectations associated with legally binding documents. The participants were tasked to check for grammatical and stylistic errors or the use of inappropriate words within a given context.\n2. Correctness: The degree to which the document is correct. The participants were tasked to consider the fulfilment of legally required conditions and factual and formal coherence.\nParticipants were also asked to provide short explanations (100 words suggested) for each scoring question. Finally, the evaluation included an open-ended question to collect participants' opinions on the possibility of generating debt acknowledgement automatically and achieving output quality comparable to humans.\nIn summary, the participants encountered the following questions:\n\u2022 Question 1: Score the language quality of the AI-generated document\n\u2022 Question 2: Briefly explain the score given in Question 1\n\u2022 Question 3: Score the correctness of the AI-generated document\n\u2022 Question 4: Briefly explain the score given in Question 3\n\u2022 Question 5: Score the language quality of the Human-crafted document\n\u2022 Question 6: Briefly explain the score given in Question 5\n\u2022 Question 7: Score the correctness of the Human-crafted document\n\u2022 Question 8: Briefly explain the score given in Question 7\n\u2022 Question 9: After comparing the AI-generated and Human-crafted documents, assess to what extent full automation is possible and the human-level performance achievable\nParticipants were required to answer all four scoring questions (Questions 1, 3, 5, and 7) before the survey could be submitted. Answering open-ended questions (Questions 2, 4, 6, 8, and 9) was not mandatory.\nThe evaluation of the survey was done at the level of scoring and open-ended questions. The scoring questions were evaluated quantitatively, and in particular in terms of average scores and in terms of preference for human-crafted or AI-generated documents with respect to the brief or verbose nature of the documents.\nThe responses to the open-ended questions were subjected to a qualitative the- matic analysis methodologically following Braun and Clarke (2006) and applied, for instance, in Liffiton et al (2023). The thematic analysis was conducted by grouping responses to open-ended questions according to the characteristics assessed - language and correctness - across documents (human-crafted, AI-generated) and groups (A and B). As a result, two sets of responses were created: one consisting of responses to the language quality and the other to responses to the correctness. These two sets of responses were thematically coded, i.e. we were looking for similar elements across the set of responses. These elements were then assigned a sentiment, i.e., whether they were mentioned positively or negatively. The elements were then grouped into meta- categories, called themes, according to their situational and semantic proximity. Thus, a schema of themes emerged, defined by their sub-elements. In addition, each theme can have a positive or negative attribute."}, {"title": "4 Results", "content": "While both documents were authored to be of comparable quality it appears that the verbose one was preferred by the participants, especially in terms of correctness. The mean overall correctness rating of the brief document was 4.24 (39\u00d7 presented as AI- generated and 36\u00d7 as human-authored) compared to the 4.67 of the verbose one (36\u00d7 AI and 39\u00d7 human). Seen side-by-side, the participants judged the verbose document as more correct than the brief one 34 times (out of 75). The brief document was deemed as more correct only 9 times. In the remaining 32 times the documents were evaluated as comparable. In terms of language, the trend was still there (4.39 verbose versus 4.13 brief) where the verbose document was preferred 26 times compared to 12 preferences for the brief one (37 neither). Figure 3 provides additional detail into how the two documents were rated by the participants. While the comparison of the documents is not the subject of this study it presents an important aspect that needs to be considered when interpreting the results below."}, {"title": "4.2 Correctness", "content": "Figure 4 shows the overall evaluation of the documents in terms of correctness, focusing on whether a document was labeled as human-crafted or AI-generated. It appears that the participants clearly preferred a document when it was presented as human-crafted over a document labeled as AI-generated. Specifically, the mean evaluation of the two documents when labeled as human-crafted was 4.69 as compared to 4.21 when the same documents were marked as AI-generated. The side-by-side comparison presents a clear message when the human-crafted designation yielded 35 preferences over the mere 7 of the documents perceived as generated by AI (33 neither). This difference is statistically significant by Fisher exact test (p < 10\u22125).\nFigure 5 provides insight into the interaction between the AI/human-authored designation and the individual documents. While the verbose document appears to be clearly preferred by the participants overall (Figure 3), the effect is negated if it is marked as AI-generated, and the brief document as authored by a human. In that case, we can even observe that the brief document was deemed as slightly more correct on average (4.5 brief versus 4.44 verbose). In terms of the side-by-side comparisons,"}, {"title": "4.4 Beliefs in the Possibility of Automatic Generation", "content": "After evaluating the documents, the participants were asked to answer an open-ended question on the possibility of the fully automated generation of the documents similar to those they have just seen. The overwhelming majority of 93% of the participants answered that they believed this is going to be possible. Only 5% remained uncertain, and merely 2% believed this to be impossible. We further explored the reasons that led the evaluators to believe in the possibility of future automation. Responses to this question were thematically coded following the methodology described in Subsections 3.3. The codes were then collated into five higher-level themes as follows:\n\u2022 Documents Indistinguishable the evaluators claimed that they found human- crafted and AI-generated documents practically indistinguishable and thus full automation was possible.\n\u2022 Expected Legal Consequences - the evaluators argued that if, despite some reserva- tions, the document is capable of producing the expected legal consequences, then it is very likely that full automation of such documents is possible."}, {"title": "5 Discussion", "content": "The results of our study reveal several significant trends that are of utmost importance to the legal profession and researchers in AI and law.\nBefore we approach individual issues, we must address the overarching trend, which, while not the subject of our study, is noteworthy. The documents were prepared to be of comparable quality, terminology, and structure, established via cross-validation within the authors' team and by approaching an experienced attorney outside the authors' team. However, the Verbose document, on average, outperformed the Brief document in the evaluation, both in terms of correctness and language qual- ity. Detailed investigation of the trend reveals though that, e.g., a Brief document labelled as Human-crafted outperforms Verbose documents labelled as AI-generated. However, the difference is not significant enough to overcome the general preference of the Verbose document by both lawyers and law students. Such a preference may be rooted in the tendency of legal professionals to associate length with precision.\nAdditionally, it reflects the tacit nature of legal knowledge. Civil law, of which the acknowledgement of debt we used in the study is the prime example, uses dispositive norms. Unlike cogent norms, dispositive norms allow contracting parties to reach an agreement which is, in detail, different from the law. It might be that lawyers preferred the Verbose document in their expectation that it captures the will of the parties expressly and fully and does not leave any part of the contract tacitly bound to the Civil Code. While we noted the general preference for the Verbose document over the Brief one, the AI-generated Verbose document was rated worse than the Brief document labelled Human-crafted. Lawyers expect longer Human-crafted documents to be a sign of eloquence, while longer AI-generated documents indicate uncertainty"}, {"title": "6 Implications for Legal Practice", "content": "The disruptive potential of LLMs is immense. The most often appearing opportunities are decreasing costs associated with legal services and increasing access to justice. ChatGPT's appeal partly lies in the democratization of legal services. Lawyers' services are often perceived as prohibitively costly. Laymen already use LLMs to address their legal needs (Hagan, 2024), and the trend is likely to grow.\nTwo major issues stand in the way:\n1. the accuracy of the provided information and generated documents, and\n2. perceptions and attitudes towards AI-generated content."}, {"title": "7 Limitations", "content": "While our study provides valuable insight into preferences and perceptions regarding AI-generated legal documents, limitations must be acknowledged.\nThe participants of our study, law students and lawyers, are a relevant demographic for evaluating legal documents. However, it is important to note that the results may not generalize well in other contexts, such as among officials, judges, prosecutors, or the general population. These groups may perceive AI-generated documents differently due to their varying levels of prior knowledge and different encounters with legal issues.\nOur study's limited number of participants may have introduced some bias to the results. As a result, some of the reported results, particularly those related to 'correctness' and 'language quality', may not be statistically significant. This limited evaluation does not provide a sufficiently detailed look at the various properties of the documents. A more comprehensive thematic analysis is a necessity to address this limitation."}, {"title": "8 Conclusions and Future Work", "content": "Our study shed light on how lawyers perceive AI-generated legal documents compared to Human-crafted documents. Participants rated the AI-generated documents worse than their Human-crafted counterparts.\nParticipants were more critical of language quality than correctness, with AI- generated documents receiving significantly more negative comments. The aversion to AI-generated legal content aligns with existing research on algorithmic aversion in other domains. Documents labelled as human-crafted received higher overall scores and more positive comments, reflecting a possible general preference for the involvement of human experts in producing legal content.\nDespite the prevalent negative perception, our study reveals significant optimism among the participants about the future of automating legal content production. They highlighted factors such as the indistinguishability between Human-crafted and AI-generated content and the ability of AI-generated content to produce legal consequences, indicating a potential shift in perception in the future.\nOur study is the first effort to understand the perception of AI-generated content on its recipients in the legal domain. Our study confirms the negative perception of AI-generated content and the general preference for Human-crafted documents.\nWhile our findings are significant, they should be a starting point for further research. The potential repercussions for providing legal services, particularly for lower-income groups and the mandatory designation of AI-generated documents, require careful evaluation. Further research must focus on other populations, larger samples, and more complex documents, as well as a nuanced understanding of doc- uments' objective and subjective properties and the prior knowledge of intended recipients."}]}