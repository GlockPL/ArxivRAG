{"title": "CLIQUEFORMER: MODEL-BASED OPTIMIZATION WITH STRUCTURED TRANSFORMERS", "authors": ["Jakub Grudzien Kuba", "Pieter Abbeel", "Sergey Levine"], "abstract": "Expressive large-scale neural networks enable training powerful models for pre- diction tasks. However, in many engineering and science domains, such models are intended to be used not just for prediction, but for design\u2013e.g., creating new proteins that serve as effective therapeutics, or creating new materials or chemi- cals that maximize a downstream performance measure. Thus, researchers have recently grown an interest in building deep learning methods that solve offline model-based optimization (MBO) problems, in which design candidates are op- timized with respect to surrogate models learned from offline data. However, straightforward application of predictive models that are effective at predicting in-distribution properties of a design are not necessarily the best suited for use in creating new designs. Thus, the most successful algorithms that tackle MBO draw inspiration from reinforcement learning and generative modeling to meet the in-distribution constraints. Meanwhile, recent theoretical works have observed that exploiting the structure of the target black-box function is an effective strategy for solving MBO from offline data. Unfortunately, discovering such structure remains an open problem. In this paper, following first principles, we develop a model that learns the structure of an MBO task and empirically leads to improved designs. To this end, we introduce Cliqueformer\u2014a scalable transformer-based architec- ture that learns the black-box function's structure in the form of its functional graphical model (FGM), thus bypassing the problem of distribution shift, previ- ously tackled by conservative approaches. We evaluate Cliqueformer on various tasks, ranging from high-dimensional black-box functions from MBO literature to real-world tasks of chemical and genetic design, consistently demonstrating its state-of-the-art performance.", "sections": [{"title": "1 INTRODUCTION", "content": "Most of the common use cases of deep learning (DL) so far have taken the form of prediction tasks (Hochreiter & Schmidhuber, 1997; He et al., 2016; Krizhevsky et al., 2017; Vaswani et al., 2017). However, in many applications, e.g. protein synthesis or chip design, we might want to use powerful models to instead solve optimization problems. Clearly, accurate predictions of a target score of an object could be used to find a design of the object that maximizes that score. Such a methodology is particularly useful in engineering problems in which evaluating solution candidates comes with big risk. For example, synthesizing a proposed protein requires a series of wet lab experiments and induces extra cost and human effort (G\u00f3mez-Bombarelli et al., 2018; Brookes et al., 2019). Thus, to enable proposing de-novo generation of strong solution candidates, researchers have drawn their attention to offline black-box optimization (BBO), often referred to as model-based optimization (MBO). In this paradigm, first, a surrogate model of the score is learned from offline data. Next, a collection of designs is trained to maximize the surrogate, and then proposed as candidates for maximizers of the target score (G\u00f3mez-Bombarelli et al., 2018; Kumar et al., 2021).\nUnfortunately, model-based optimization (MBO) introduces unique challenges not encountered in classical prediction tasks. The most significant issue arises from the incomplete coverage of the design space by the data distribution. This limitation leads to a phenomenon known as distribution shift, where optimized designs drift away from the original data distribution. Consequently,"}, {"title": "2 PRELIMINARIES", "content": "In this section, we provide the necessary background on model-based optimization. Additionally, we cover the basics of functional graphical models on top of which we build Cliqueformer."}, {"title": "2.1 MODEL-BASED OPTIMIZATION", "content": "We consider a model-based optimization problem, where we are given a dataset $\\mathcal{D} = \\{x,y\\}_{i=1}^N$ of examples $x \\in \\mathcal{X}$, following distribution $p(x)$, and their values $y = f(x) \\in \\mathbb{R}$ under an unkown (black-box) function $f : \\mathcal{X} \\rightarrow \\mathbb{R}$. Our goal is to optimize this function offline to find its maximizer\n$x^* = \\arg \\max_{x \\in \\mathcal{X}} f(x)$"}, {"title": "2.2 FUNCTIONAL GRAPHICAL MODELS", "content": "An FGM of a high-dimensional function $f(x)$ is a graph over individual components of $x$ that separates $x_i, x_j \\in x$ if their con- tributions to $f(x)$ are independent of each other. Knowing such a structure of $f$ one can eliminate interactions between independent variables from a model that approximates it, and thus prevent an MBO algorithm from exploiting them. We summarize basic prop- erties of FGMs below. In what follows, we denote $X_{-i}$ as the design (input) space without the $i$th subspace, and $x_{-i}$ as its element \u00b9. We also write $[K]$ to denote the set $\\{1, ..., K\\}$.\nDefinition 1. Let $x = (x_v | v \\in V)$ be a joint variable with index set $V$, and $f(x)$ be a real-valued function. An FGM $G = (V,E)$ of $f(x)$ is a graph where the edge set $E \\subset \\mathcal{X}^2$ is such that,\n$\\exists f_{-i}: \\mathcal{X}_{-i} \\rightarrow \\mathbb{R}$ and $\\exists f_{-j}: \\mathcal{X}_{-j} \\rightarrow \\mathbb{R}$, with $f(x) = f_{-i}(x_{-i}) + f_{-j}(x_{-j})$, implies $(i, j) \\notin E$.\nThe basic result about FGMs is that they allow for decomposition of the target function into sub- functions with smaller, partially-overlapping inputs, from the FGM's set of maximal cliques $C$,\n$f(x) = \\sum_{c \\in C} f_c(x_c)$.\nIntuitively, the decomposition enables more efficient learning of the target function since it can be constructed by adding together functions defined on smaller inputs, which are easier to learn. This, in turn, allows for more efficient MBO since the joint solution $x^*$ can be recovered by stitching individual solutions $x$ to smaller problems. This intuition is formalized by the following theorem.\nTheorem 1 (Grudzien et al. (2024)). Let $f(x)$ be a real-valued function, $C$ be the set of maximal cliques of its FGM, and $\\Pi$ be a policy class. Let $C_{stat}$ and $C_{cpx}$ be constants that depend on the probability distribution of $x$ and function approximator class's complexity, respectively, defined in Appendix A. Then, the regret of MBO with the FGM information is given by,\nFor example, if $X = X_1 \\times X_2 \\times X_3$ and $x = (X_1, X_2, X_3)$, then $X_{-2} = X_1 \\times X_3$, and $x_{-2} = (X_1, X_3)$."}, {"title": "3 CLIQUEFORMER", "content": "This section introduces a neural network model designed to solve MBO problems through standard end-to-end training on offline datasets. We present a new theoretical result, outline the key desiderata for such a model, and propose an architecture\u2014Cliqueformer\u2014that addresses these requirements."}, {"title": "3.1 NON-UNIQUENESS OF STRUCTURE DISCOVERY", "content": "The regret bound from Theorem 1 applies to methods that use the target function's FGM in their function approximation. It implies that such methods can solve even very high-dimensional problems if their underlying FGMs have low-dimensional cliques or, simply speaking, are sparse. Since, in general, no assumptions about the input can be made, this motivates learning a representation of the input for which one can make distributional assumptions and infer the FGM with statistical tests. Following this reasoning, Grudzien et al. (2024) offer a heuristic technique for discovering an FGM over learned, latent, normally-distributed variables. However, as we formalize with the following theorem, even such attempts are futile in dealing with black-box functions.\nTheorem 2. Let $d > 2$ be an integer and $x \\in \\mathbb{R}^d$ be a random variable with positive density in $\\mathbb{R}^d$. There exists a function $f(x)$ and two different reparameterizations, $z = z(x)$ and $v = v(x)$, of $x$, that both follow a standard-normal distribution, but the FGM of $f$ with respect to $z$ is a complete graph (has all possible edges), and with respect to $v$ it is an empty graph (has no edges).\nThe theorem implies that FGM is not a fixed attribute of a function that can be estimated from the data, but instead should be viewed as a property of the input's reparameterization. Furthermore, different reparameterizations feature different FGMs with varied levels of decomposability, some of which may not significantly simplify the target function. This motivates a reverse approach that begins from defining a desired FGM and learning representations of the input that align with the graph. In the next subsection, we introduce Cliqueformer, where the FGM is specified as a hyperparameter of the model and a representation of the data that follows its structure is learned."}, {"title": "3.2 ARCHITECTURE", "content": "The goal of this subsection is to derive an MBO model that can simultaneously learn the target function as well as its structure, and thus be readily applied to MBO. First, we would like the model to decompose its prediction into a sum of models defined over small subsets of the input variables in the manner of Equation (3). As discussed in the previous subsection, efforts to discover such a structure are impractical since there exists a plethora of reparameterizations of the data and their"}, {"title": "3.3 OPTIMIZING DESIGNS WITH CLIQUEFORMER", "content": "Once Cliqueformer is trained, we use it to optimize new designs. Typically, MBO methods initialize this step at a sample of designs $\\{x^{(i)}\\}_{i=1}^B$ drawn from the dataset (Trabucco et al., 2021). Since in our algorithm the optimization takes place in the latent space $Z$, we perform this step by encod- ing the sample of designs with Cliqueformer's encoder, $z \\sim e_\\theta(z|x^{(i)})$. We then optimize the representation $z^i$ of design $x^i$ to maximize our model's value,\n$\\mathcal{L}_{MBO}(z^{(i)})\\_{i=1}^B = \\frac{1}{B}\\sum\\_{b=1}^B f_\\theta(z)$.\nat the same time minding the enumerator of the regret bound from Theorem 1. That is, we don't want the optimizer to explore regions under which the marginal densities $e_\\theta(z_c) = \\mathbb{E}\\_{x\\sim D}[e_\\theta(z_c|x)]$ are small. Fortunately, since the encoder was trained with standard-normal prior on the cliques, $p(z_c) = N(0^{d_{clique}}, I_{d_{clique}})$, we know that values of $z$ closer to the origin have unilaterally higher marginals. This simple property of standard-normal distribution allows us to confine the optimizer's exploration to designs with in-distribution cliques by exponentially decaying the design at every optimization step. Thus, we use AdamW as our optimizer (Loshchilov et al., 2017). We provide the pseudocode of the whole procedure of designign with Cliqueformer in Algorithm 1."}, {"title": "4 RELATED WORK", "content": "The idea of using machine learning models in optimization problems has existed for a long time, and has been mainly cultivated in the literature on Bayesian optimization (Williams & Rasmussen, 2006; Brochu et al., 2010; Snoek et al., 2012, BO). The BO paradigm relies on two core assumptions: availability of data of examples paired with their target function values, as well as access to an oracle that allows a learning algorithm to query values of proposed examples. Thus, similarly to"}, {"title": "5 EXPERIMENTS", "content": "In this section, we provide the empirical evaluation of Cliqueformer. We begin by benchmarking Cliqueformer against prior methods on tasks from the MBO literature. Then, we finish by evaluating the benefit of the novel FGM decomposition layer in Cliqueformer through an ablation study."}, {"title": "5.1 BENCHMARKING", "content": "We compare our model to three classes of algorithms, each represented by a proven prior method. As a na\u00efve baseline, we employ gradient ascent on a learned model (Grad. Asc.). To compare to exploratory methods, we use Reward-Weighted Regression (Peters & Schaal, 2007, RWR) which learns by regressing the policy against its most promising perturbations. To represent the recently proposed conservative algorithms, we compare to state-of-the-art Conservative Objective Models (Trabucco et al., 2021; Kumar et al., 2021, COMs). Additionally, to evaluate the importance of the novel elements of our architecture and training, we evaluate gradient ascent with the transformer backbone (Vaswani et al., 2017, Transformer). For COMs and other methods, we use the recom- mended hyperparameter setting from (Trabucco et al., 2021). While Cliqueformer can be tuned for each task, we keep most of the hyperparameters the same: refer to Appendix B for more details.\nFor every method, we report an empirical estimate of its 100th percentile, similarly to Trabucco et al. (2021). We estimate it by averaging the values of the top 10 designs out of 1000 candidates, averaged across 5 seeds. In the following paragraphs, we introduce benchmark tasks, from MBO literature, that we use in our experiments, and analyze their results.\nLatent Radial-Basis Functions (Lat. RBF). This is a suite of tasks designed to expose vulnera- bility of MBO models (Grudzien et al., 2024). The data pairs (x, y) are generated by first drawing a standard normal vector $z \\sim N(0_{d_z}, I_{d_z})$, where $d = \\{11, 31, 41, 61\\}$, then computing $y$ as a sum of radial-basis functions of $d_e$-dimensional cliques of a pre-defined FGM. The observed vector $x$ is a non-linear transformation of $z$, i.e., $x = T(z) \\in T \\subset \\mathbb{R}^d$, where $d > d_z$, while $z$ itself is hidden from the data. Such tasks allow us to study whether an MBO method learns to produce valid designs by verifying that ground-truth inputs $z$ can be recovered from them. That is, a design $x$ for which the map $T^{-1}(x)$ is ill-defined is considered invalid. In our experiments, an invalid design receives a value of -\u221e. We report the average validity of designs produced by the methods in blue. The results in Table 1 show that the most able method at keeping its proposals at the manifold of valid de- signs is Cliqueformer. Importantly, this ability does not diminish even in higher-dimensional tasks, while the second-best such method, COMs, gradually loses this ability. We also use these tasks to study if a model is capable of exploiting the RBF's structure in the optimization step by varying the effective dimensionality $d_z$ of the data while keeping $d_e$ fixed. While the naive, the exploratory, and Transformer baselines perform poorly on these tasks overall, COMs's performance clearly drops as the task dimension increases. Meanwhile, as predicted by Theorem 1, Cliqueformer attains similar, strong performance across all tasks.\nSuperconductor. This task poses a challenge of designing a superconducting material, represented by an 81-dimensional vector, with as high critical temperature as possible (Hamidieh, 2018). It tests abilities of MBO models in real-world continuous problems. As the very high score of gradient as-"}, {"title": "5.2 ABLATION", "content": "While the decomposing mechanism of Cliqueformer is entirely novel, other components, such as transformer blocks (Vaswani et al., 2017) and variational-information bottlenecks (Kingma & Welling, 2013; Alemi et al., 2016) are known and powerful deep learning tools. In this subsection, we verify the utility of the decomposing component with an ablation study, in which we sweep over the number of cliques of Cliqueformer for a few representative tasks. In each of the tested tasks we fix the size of the latent variable $z$ and sweep over the number of cliques $N_{clique}$ into which it can be decomposed. We cover the case $N_{clique} = 1$ to compare Cliqueformer to an FGM-oblivious VAE with transformer backbone and AdamW design optimizer.\nResults in Figure 5 show that Cliqueformer does benefit from the FGM decomposition in all tested tasks. However, the results suggest that the optimal number of cliques varies between tasks, e.g. 4 for TFBind-8 and Superconductor, but 2 for Lat. RBF 41. In our experiments, we consistently obtained good performance by setting the clique size to $d_{clique} = 3$ and choosing the number of cliques so that the total latent dimension approximately matches that of the design. In DNA Enhancers, we doubled the clique size and halved the number of cliques to decrease the computational cost of attention. More details of hyperparameters can be found in Appendix B. An in-depth analysis of the relation between hyperparameters and the performance is an exciting avenue of future work."}, {"title": "6 CONCLUSION", "content": "In this work, we proposed Cliqueformer\u2014a scalable neural model for model-based optimization. We derived its building blocks following recent advances in MBO theory centered in functional graph- ical models, equipping it with an ability to acquire structure of the black-box target function. This ability sets the model free from requiring explicit conservative regularization or iterative retraining to propose in-distribution designs. Empirically, Cliqueformer achieves state-of-the-art performance, which it sustains across all tested tasks. Cliqueformer opens an exciting avenue of research in MBO focused on scaling design datasets and large neural networks."}, {"title": "APPENDIX", "content": ""}, {"title": "A THEORETICAL DETAILS", "content": "The full statement of the following theorem considers an MBO algorithm with function clas F = FC1... FCNclique, so that every of its element has form\n$f(x) = \\sum_{i=1}^{N_{clique}} f_c (X_c)$.\nAs described in Section 3, Cliqueformer's architecture forms such a function class on top of the learned latent space. We define the statistical constant as\n$C_{stat} = \\frac{1}{1-\\sigma}$, where $\\sigma = \\max_{c_i c_j \\in \\{C\\}} Corr_{x \\sim p[f_{c_i} (x_c) , f_c]}$.\nand the function approximation complexity constant as\n$C_{cpx} = \\frac{N_{clique} \\sqrt{\\sum_{c=1}^{clique} log(|F_{c_i}|/\\delta)}}{\\sqrt{N}}$\nwhere $\\delta$ is the PAC error probability (Shalev-Shwartz & Ben-David, 2014).\nTheorem 1 (Grudzien et al. (2024)). Let $f(x)$ be a real-valued function, C be the set of maximal cliques of its FGM, and $\\Pi$ be a policy class. Let $C_{stat}$ and $C_{cpx}$ be constants that depend on the probability distribution of $\\times$ and function approximator class's complexity, respectively, defined in Appendix A. Then, the regret of MBO with the FGM information is given by,\n$\\eta(\\pi*) \u2013 \\eta(FGM) \u2264 C_{stat}C_{cpx} \\max_{\\pi \\in \\Pi, x\\in \\mathcal{X}, c\\in C} \\frac{\\pi(x_c)}{p_c(x_c)}$.\nTheorem 2. Let $d > 2$ be an integer and $x \u2208 R^d$ be a random variable with positive density in $R^d$. There exists a function $f(x)$ and two different reparameterizations, $z = z(x)$ and $v = v(x)$, of $x$, that both follow a standard-normal distribution, but the FGM of $f$ with respect to $z$ is a complete graph (has all possible edges), and with respect to $v$ it is an empty graph (has no edges).\nProof. Since the density of $x$ is positive and continuous, we can form a bijection that maps $x$ to another random variable $z \u2208 R^l$, where $l < d$, that follows the standard-normal distribution (Dai & Wipf, 2019, Appendix E). We denote this bijection as $\\mathcal{Z}(x)$. Let us define\n$y = f^\u2217(x) = exp(\\sum_{i=1}^l z_i)$.\nThen, the FGM of $f^\u2217$ has an edge between every two variables since each variable's partial derivative\n$\\frac{\\partial f_z}{\\partial z_i} = \\frac{1}{l} exp(\\frac{1}{\\sqrt{\\sum_{i=1}^l z_i}})$.\nis also a function of all others (Grudzien et al., 2024, Lemma 1). Consider now a rotation $\\rho: z \u2192 v = (v_1, . . . , v_l)$ such that $v_1 = \\frac{1}{\\sqrt{\\sum_{i=1}^l z_i}}$. Then, $v \\sim N(0_l, I_l)$, and y can be expressed in terms of v as $y = f^u(v) = exp(v_1)$. Then, the FGM of $f^u$ has no edges, since it depends on only one variable, inducing no interactions between any two variables. Recall that $x = \\mathcal{Z}^{-1}(z)$. Then, x be represented by standard-normal z and v, obtainable by\nz = \\mathcal{Z}(x) and v = \\rho(z) = \\rho(\\mathcal{Z}(x)).\nFurthermore, we can define\nf(x) = f^\u2217(\\mathcal{Z}(x))\nwhich is identically equal to $f^\u2217(z)$ and $f^u(v)$, which have a complete and an empty FGM, respec- tively, thus fulfilling the theorem's claim."}, {"title": "B EXPERIMENTAL DETAILS", "content": "Datasets. We use the implementation of Grudzien et al. (2024) to generate data with latent radial- basis functions. Also, we initially wanted to use Design Bench (Trabucco et al., 2022) for experi- ments with practical tasks. However, at the time of this writing, the benchmark suite was suffering a data loss and was not readily available. To overcome it, we manually found the data and im- plemented dataset classes. TFBind-8 (Trabucco et al., 2022) could be fully downloaded since the number of possible pairs (x, y) is quite small. Hence, a design can be evaluated by looking up its score in the dataset. For Superconductor (Hamidieh, 2018), we pre-trained an XGBoost oracle on the full dataset, and trained our model and the baselines to predict the labels produced by the oracle. The proposed designs of the tested models are evaluated by calling the oracle as well. We obtained DNA Enhancers dataset from the code of Uehara et al. (2024), available at\nhttps://github.com/masa-ue/RLfinetuning\\_Diffusion\\_Bioseq/tree/master.\nFollowing the procedure in\nhttps://github.com/masa-ue/RLfinetuning\\_Diffusion\\_Bioseq/blob/master/\ntutorials/Human-enhancer/1-Enhancer\\_data.ipynb.\nwe additionally filter the dataset to keep only sequences featured by chromosomes from 1 to 4. We use their pre-trained oracle for generating labels and evaluation of proposed designs. Following Fannjiang & Listgarten (2020) and Trabucco et al. (2022), we train our models on the portions of the datasets with values below their corresponding 80th. Upon evaluation, we obtain the ground- truth/oracle value of the proposed design y, and normalize it as\n$\\overline{y} = \\frac{y - y_{min}}{y_{max} - y_{min}}$\nand report $\\overline{y}$. $y_{min}$ and $y_{max}$ are the minimum and the maximum of the training data. This normal- ization scheme is different than, for example, the one in the work by Trabucco et al. (2022). We choose this scheme due to its easy interpretability a score of $\\overline{y} > 1$ implies improvement over the given dataset, which is the ultimate objective of MBO methods. However, we note that a score of less than 1 does not imply failute of the algorithm, since we initialize our designs at a random sample from the dataset, which can be arbitrarily low-value or far from the optimum. For some functions, like in latent RBFs, the optima are very narrow spikes in a very high-dimensional space, being nearly impossible to find (see Figure 1a). We choose such an evaluation scheme due to its robustness that allows us to see how good ut improving any design our algorithms are overall.\nHyper-parameters. For baselines, we use hyper-parameters suggested by Trabucco et al. (2021). We decreased the hidden layer sizes (at no harm to performance) for Lat. RBF 31 and DNA En- hancers tasks where the performance was unstable with larger sizes. Also, we haven't tuned most of the Cliqueformer's hyper-parameters per-task. We found, however, as set of hyper-parameters that works reasonably well on all tasks.\nOn all tasks, we use 2 transformer blocks in both the encoder and the decoder, with transformer dimension of 64, and 2-head attention. The predictive model $f_\\theta(z)$ is a multi-layer perceptron with 2 hidden layers of dimension 256. We change it to 512 only for DNA Enhancers. The best activation function we tested was GELU (Hendrycks & Gimpel, 2016), and LeakyReLU(0.3) gives similar results. We use dropout of rate 0.5 (Srivastava et al., 2014). In all tasks, weight of the MSE term to $\\tau =10$ (recall Equation (5)). Additionally, we warm up our VIB term linearly for 1000 steps (with maximal coefficient of 1). We train the model with AdamW (Loshchilov et al., 2017) with the default weight decay of Pytorch (Paszke et al., 2019). We set the model learning rate to 1e-4 and the design learning rate to 3e-4 in all tasks. We train the design with AdamW with high rates of weight decay (ranging from 0.1 to 0.5).\nIn all tasks, we wanted to keep the dimension of the latent variable z more-less similar to the di- mension of the input variable x, and would decrease it, if possible without harming performance, to limit the computational cost of the experiments. The dimension of z can be calculated from the clique and knot sizes as\ndim(z) = d_{knot} + N_{clique} (d_{clique} - d_{knot})."}]}