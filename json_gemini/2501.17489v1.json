{"title": "Neural Spelling: A Spell-Based BCI System for Language Neural Decoding", "authors": ["Xiaowei Jiang", "Charles Zhou", "Yiqun Duan", "Ziyi Zhao", "Thomas Do", "Chin-Teng Lin"], "abstract": "Brain-computer interfaces (BCIs) present a promising avenue by translating neural activity directly into text, eliminating the need for physical actions. However, existing non-invasive BCI systems have not successfully covered the entire alphabet, limiting their practicality. In this paper, we propose a novel non-invasive EEG-based BCI system with Curriculum-based Neural Spelling Framework, which recognizes all 26 alphabet letters by decoding neural signals associated with handwriting first, and then apply a Generative AI (GenAI) to enhance spell-based neural language decoding tasks. Our approach combines the ease of handwriting with the accessibility of EEG technology, utilizing advanced neural decoding algorithms and pre-trained large language models (LLMs) to translate EEG patterns into text with high accuracy. This system show how GenAI can improve the performance of typical spelling-based neural language decoding task, and addresses the limitations of previous methods, offering a scalable and user-friendly solution for individuals with communication impairments, thereby enhancing inclusive communication options.", "sections": [{"title": "I. INTRODUCTION", "content": "BRAIN-COMPUTER interfaces (BCIs) have emerged as a pivotal area of research within human-computer interaction (HCI), distinguished by their capacity to seamlessly integrate neural signals with external systems. Pioneering studies such as those by Guo et al. [1], Chen et al.[2], Cao et al.[3], and Lin et al.[4] underscore BCIs' role in advancing neuroscience and technology. These interfaces create direct communication pathways that are especially beneficial for individuals with limited speech or motor functions. Language decoding represents a critical domain within BCI research, aimed at deciphering the neural correlates of speech and language processing. This capability not only enhances interaction paradigms but also opens new avenues for communication, offering significant improvements in quality of life for those with severe communicative impairments.\nInitially, BCI research focused on visual-based decoding approaches, such as steady-state visually evoked potentials (SSVEP)[1], which, despite their reliability, demand high cognitive effort and are unsuitable for prolonged use[2]. These methods often fail to align with natural human language patterns, posing significant usability challenges. The advent of invasive neural decoding technologies marked a significant advancement, allowing for direct interpretation of brain signals via electrocorticography (ECOG) or stereo-EEG (sEEG)[5, 6]. These methods have demonstrated substantial improvements in user performance, significantly enhancing communicative capacities for patients with speech impairments. However, the invasive nature, high cost, and ethical concerns limit their general applicability[7]. In contrast, non-invasive BCIs, predominantly utilizing electroencephalography (EEG), offer a more accessible alternative. These systems are less obtrusive and more cost-effective, broadening potential user demographics [8]. Despite the challenges of signal noise and the extensive training required for users, recent studies have demonstrated EEG's potential in effective language decoding [9, 10].\nWith the rise of Generative AI (GenAI), the integration of large language models (LLMs) into BCI research has opened new avenues for enhancing language decoding [11]. This integration can be implemented within two distinct frameworks: directly synthesizing speech or text from brain signals using pre-trained LLMs, as illustrated in Fig. 1(A) and Fig. 1(C) respectively; and decoding brain signals into minimal language units such as phonemes, as shown in Fig. 1(B), or letters, as depicted in Fig. 1(D), followed by text generation through natural language processing (NLP) models.\nThe first framework often faces limitations due to the disparity in data scales between brain data and text/image datasets, which can restrict the system to operating within predefined datasets, merely retrieving sentences rather than generating novel content. The second approach, known as the spell-based method [12, 13], operates by initially decoding neural signals into their minimal representational units, such as the 26 letters, or even nine-key input (T9) [14]. It subsequently employs GenAI to construct coherent text in a second stage."}, {"title": "II. RELATED WORK", "content": "Recent advances in Language Neural Decoding have significantly enhanced BCI systems. RNN-based models have achieved a 23.8% word error rate on a 125,000-word vocabulary using chronic ECoG signals, highlighting their potential as speech neuroprostheses [7]. ECoG-based Speech BCIs have demonstrated stable control of assistive devices for up to three months with minimal calibration, supporting daily unassisted use [19]. Additionally, speech synthesis from ECoG signals enables decoding spoken sentences [5], while contrastive learning models have decoded perceived speech from non-invasive recordings like EEG and MEG, enriching decoding techniques [9]. To better predict the text, a novel task, named Cross-Modal Cloze (CMC) task [20], which is to predict the target word with a context as prompt, are proposed, achieving 28.91% accuracy.\nSpelling-based BCIs have also progressed, with high-speed systems like the JFPM-based SSVEP speller [12] and Neu-roAiR, which uses ICA and EEGNet to achieve 44.04% accuracy in recognizing airwritten letters [17]. Efforts in tonal language decoding and synthesis [21], handwriting tasks [13], and CNN-based classifiers for letter decoding, such as \u201cHELLO, WORLD!"}, {"title": "III. PRELIMINARIES", "content": "In this section, we introduce the foundational concepts and notation used to describe our two-step neural processing system for EEG-based sentence generation. The system consists of two sequential modules: an encoder for EEG signal processing and a GenAI model to synthesize sentences.\nLet \\( X \\in \\mathbb{R}^{T\\times C} \\) represent the EEG input where T denotes the number of time steps and C the number of channels. The encoder function, denoted as fenc, transforms X into a probability vector \\( p \\in \\mathbb{R}^{26} \\), with each component pi of p representing the probability of the corresponding letter i from the English alphabet:\n$$ p = f_{\\text{enc}} (X; \\theta_{\\text{enc}}) $$\\where denc are the parameters of the encoder. The encoder utilizes a neural network architecture optimized for temporal and spatial features inherent in EEG data.\nUpon generating the letter probabilities p, these are inputted into a GenAI model, gtrans, which outputs a coherent sentence y. This model is based on a pretrained LLM that has been fine-tuned for the task of converting sequences of letter probabilities into grammatically correct and contextually relevant sentences:\n$$ y = g_{\\text{trans}} (p; \\theta_{\\text{trans}}) $$\\where trans represents the parameters of the translation model. The model leverages advanced natural language processing techniques to ensure semantic coherence and syntactic accuracy in the generated sentences.\nThese components are integrated to form a robust system for interpreting EEG signals and producing textual outputs, aiming to bridge the gap between neural activities and language expression."}, {"title": "IV. METHODOLOGY", "content": "This section introduces the Curriculum-based Neural Spelling (CNS) Framework, a novel approach to enhancing the spelling accuracy from neural signals using a two-stage model. Initially, the model utilizes a Convolutional EEG Encoder to transform raw EEG data into a letter classification schema employing minimal neural samples and a tailored set of character categories. In the second stage, we integrate Curriculum Learning with large language models (LLMs) within a sequence-to-sequence framework to generate fluent sentences despite inherent noise and variability in EEG signals. This combination aims to leverage the strengths of advanced neural network architectures and sophisticated natural language processing techniques to overcome the challenges posed by low signal-to-noise ratios and the complex nature of EEG-based letter decoding. The architecture and its components are depicted in Fig. 2, and this comprehensive setup promises significant advancements in brain-to-text communication technologies.\nThe Convolutional EEG Encoder is designed as a two-layer Convolutional Neural Network (CNN), which is adept at processing EEG data for the purpose of embedding generation, as shown in Fig. 2D. This encoder operates in conjunction with CL techniques to enhance the discriminative power of the embeddings. The trajectory data is processed by a pre-trained ResNet18 [48] model, which serves as a trajectory encoder. The core of our learning strategy is based on minimizing the contrastive learning loss (lossCL), which is calculated as follows:\nThe loss function is defined as:\n$$ \\text{loss}_{\\text{CL}} = 1 - \\text{cos}(\\theta_{\\text{EEG}}, \\theta_{\\text{Traj}})^2 $$\\where \\( \\theta_{\\text{EEG}} \\) and \\( \\theta_{\\text{Traj}} \\) represent the embedding vectors from EEG data and trajectory data, respectively.\nThe letter classification component is an integral part of the CNS Framework. It includes a fully connected linear layer that maps its input to a 26-node output layer, where each node represents a letter of the English alphabet. After this. This arrangement enables the system to predict letters based on the processed EEG data. A softmax function is applied to the output layer to obtain a probability distribution over the alphabet, as shown in Fig. 2E, which is critical for the system's accuracy in spelling prediction. The classifier utilizes the cross-entropy loss to measure the discrepancy between the predicted probabilities and the actual distribution of the target letters. The crossentrypy loss (losSCE) function is defined as follows:\n$$ \\text{loss}_{\\text{CE}} = - \\sum_{c=1}^{M} y_{o,c} \\log(p_{o,c}) $$\\where M is the number of classes (letters), yo,c is a binary indicator (0 or 1) if class label c is the correct classification for observation o, and po,c is the predicted probability of observation o being of class c. This loss function effectively guides the learning process by penalizing deviations from the true label distribution, thus enhancing the system's ability to generate accurate and reliable spelling predictions from EEG signals.\nIn training phase, the finial loss (losstotal) is calculated by:\n$$ \\text{loss}_{\\text{total}} = 0.35 \\times \\text{loss}_{\\text{SCE}} + 0.65 \\times \\text{loss}_{\\text{SCL}} $$\nThe inherently low SNR of EEG signals combined with the rigorous demands of experimental protocols exacerbates the challenges of prediction biases and data scarcity in letter-level classification. These limitations significantly impede the capacity of classifiers to decode fluent sentences. To mitigate these challenges, we propose the integration of LLMs within a sequence-to-sequence (seq2seq) framework aimed at enhancing sentence fluency and readability.\nTraditional NLP models often struggle with inputs characterized by significant letter-level noise due to their reliance on sub-word-level tokenization and training predominantly on well-curated texts. As depicted in Table I, without a nuanced understanding of the behaviors specific to subject-based letter classifiers, models like ChatGPT4 can generate sentences that diverge significantly from the intended content, typically relying on generalized knowledge of language structure and common phrases.\nTo address these constraints, we introduce a curriculum learning strategy tailored for pretrained LLMs. This strategy is designed to adapt the models to the latent distributions specific to subject-based handwriting patterns. By progressively increasing the relevance to the domain and the complexity of the tasks during training, our curriculum learning approach methodically fine-tunes LLMs. This targeted training enables the models to achieve better alignment with the idiosyncratic characteristics of subject-specific letter decoders, thereby enhancing their capacity to handle noisy inputs and improving overall sentence generation:\n1) Initial Phase: Start with tasks involving high-frequency, low-noise samples to establish baseline language structures.\n2) Intermediate Phase: Gradually introduce more complex and noisier data, increasing exposure to real-world variability.\n3) Advanced Phase: Focus on fine-tuning with the highest noise levels and the most challenging samples to ensure robustness and fluency under the most adverse conditions."}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "We recruited thirty-two right-handed, healthy individuals (P1-P32), all native English speakers from Australia, comprising 16 males and 16 females with an average age of \\( M_{\\text{age}} = 24.94 \\pm 0.29 \\) years. Each participant had normal or corrected-to-normal vision and reported no history of mental health disorders. 4 subjects are removed from the dataset due to their misunderstanding of the experiment design. Ethical approval was granted by the University of Technology Sydney's Ethics Committee (Approval No. UTS HREC REF: ETH23-8036). Informed consent was obtained in writing from each participant prior to the experiment.\nHandwriting movements and EEG signals were recorded simultaneously at sampling rates of 60 Hz and 1000 Hz, respectively. Handwriting trajectories were captured using a custom-developed application built on the PsychoPy platform, integrated with a Wacom Intuos Pro Medium tablet and Wacom Pro Pen 2 stylus featuring 8192 levels of pressure sensitivity. This application was designed to log critical events and features of each handwriting motion, including timestamps, x- and y-coordinates, rotation angles, force, and pen state codes for pen-down (contact with the surface), pen-move, and pen-up (lifting from the surface) for each digitalized point along the trajectory.\nEEG signals were recorded using a 64-channel Neuroscan amplifier (Curry 9), with electrode placements following the 10-20 international system [49]. A ground electrode was referenced to maintain signal consistency.\nSynchronization of handwriting trajectories with EEG signals was achieved by embedding time markers of key events within the EEG stream. Specifically, each first pen-down event of symbols written within each block on the tablet was marked for temporal alignment, as illustrated in Fig. 2(B).\nThe experiment was conducted in a sound-attenuated room. Participants were seated comfortably at a desk, positioned approximately 35 cm from a tablet, which was placed in an optimal location on the desk for each individual.\nThe task followed an event-related design, with extended breaks provided after every 10 trials. During these breaks, participants could rest for an unlimited duration, initiating the next trial by pressing the space key. Each trial, as illustrated in Fig. 2A, began with a fixation cross displayed for 1000 ms with a random jitter of \u00b1 500 ms. Subsequently, a letter was presented for 2000 ms, cueing the character participants were to write in the handwriting task. During this phase, participants used a stylus to write the letter slowly within a 3000 ms time frame. A 2000 ms relaxation interval followed each handwriting task.\nThe sequence of the 26 letters was randomized for each participant, with each letter repeated 25 times, resulting in a total of 650 trials (25 \u00d7 26) per participant. The entire session lasted approximately 2 hours.\nEEG data preprocessing was performed using MNE (version 1.6.0) [50] in Python 3.10.13. The machine learning pipeline began with a bandpass filter between 1 and 70 Hz to reduce general noise. This was followed by notch filtering at 50, 100, and 150 Hz to mitigate interference from power lines. Next, epochs were created, defining time intervals from -1 sto 3 s around each event of the first pen-down in each trial. Independent Component Analysis (ICA) was applied with the auto-reject method [51] to remove artifacts from the data. Finally, the EEG data was re-referenced by averaging and baseline correction was applied to ensure consistency across channels.\nPower Spectral Density (PSD) was extracted as the primary feature for model prediction. To compute PSD, an Fast Fourier Transform (FFT) was used, capturing frequencies between 1 Hz and 70 Hz, as shown in Fig. 2C. The PSD for a given signal x(t) was calculated using the formula:\n$$ \\text{PSD}(f) = \\frac{1}{N} \\Big| \\sum_{t=0}^{N-1} x(t)e^{-i2\\pi ft/N} \\Big|^2 $$\\where f represents the frequency, and N is the total number of time points in the signal. This approach provided a detailed frequency profile of the EEG signals, essential for downstream analyses.\nTrajectory data was processed by applying min-max normalization to the x(t) and y(t) coordinates, which were subsequently mapped onto a 28 x 28 pixel grid. To represent temporal progression, the intensity values along the trajectory were scaled from 50 to 255, illustrating the passage of time, as shown in Fig. 2B. This approach allowed the temporal aspects of each handwriting movement to be visually represented in the spatial grid format.\nIn this section, we evaluate the efficacy of different neural network architectures for EEG-based encoding by comparing a CNN with both Long Short-Term Memory (LSTM) networks and Transformer-based models, each equipped with and without CL module. The comparative analysis is rooted in statistical testing and performance metrics across three classification accuracies: Top 1, Top 3, and Top 5.\nThe CNN augmented with the CL module significantly outperformed the other models. Specifically, the CNN w/ CL achieved a Top 1 accuracy of 33.10% \u00b1 11.54%, a Top 3 accuracy of 57.77% \u00b1 12.89%, and a Top 5 accuracy of 71.46% \u00b1 11.11%. Statistical analyses, including pairwise t-tests, revealed that the CNN with CL model was superior to the LSTM w/ CL (t(334) = 9.505, p < 0.001) and the Transformer w/ CL (t(334) = 12.028, p < 0.001). All tests are corrected by Benjamini-Hochberg False Discovery Rate (FDR_BH) to avoid multi-comparison issues, ensuring robustness in reporting statistically significant differences.\nThis section investigates the impact of different ROIs and frequency bands on the Top 1 accuracy of a CNN model augmented with CL. The analysis focuses on the PSD extracted from specific bands and ROIs to determine their relative importance in performance metrics.\nUtilizing all features from all bands and ROIs yields the highest Top 1 accuracy, indicating the advantage of a comprehensive feature set. The Gamma band stands out among the frequency bands, showing the largest performance improvement, underscoring its significance in EEG-based models. Regarding the ROIs, the PFC achieves the first-highest Top 1 accuracy, followed by the whole frontal cortex. Subsequent analyses show that the temporal and sensorimotor cortices rank lower, yet they contribute to overall model accuracy."}, {"title": "VI. DISCUSSION", "content": "This study presents a Curriculum-based Neural Spelling Framework comprising a Convolutional EEG Encoder and a CL module, demonstrating the feasibility of recognizing handwritten letters using non-invasive technologies. Furthermore, the system highlights the potential for real-world applications by integrating LLMs to generate free-form sentences based on spelling-based designs.\nHandwriting involves complex neural coordination, engaging multiple brain regions. Figure 8 illustrates how specific letters correspond to neural activation (A) and handwriting trajectory (B). Some letters, such as TWY, BFE, ZK, and OC, show similar patterns in both neural and trajectory patterns. The small distance of these letters, suggests a shared representation in neural processing spaces.\nSignificant neurophysiological variations are highlighted in Fig. 6, where the F-statistics reveal prominent differences across cerebral regions at specific frequency bands. In particular, the alpha band shows substantial activity in the occipital and parietal lobes (p < 0.05), underscoring their roles in visual processing and spatial integration [52, 53], essential for interpreting letter shapes and trajectories.\nAs demonstrated in Fig. 8(C), the neural pattern differences between letters exhibit complex and diverse styles across different brain regions and frequency bands (p < 0.05). Specifically, the differences between letters A and Z are predominantly observed in the Gamma band within the Frontal and Parietal cortices (p < 0.05). In contrast, the patterns for B and L are distinctly marked by Alpha band activity in the Parietal and Central cortices (p < 0.05). Interestingly, the neural patterns for B and J are similar to those of B and L but feature less Gamma band activity in the Frontal cortex (p < 0.05). Moreover, the patterns for O and Z resemble those between A and Z, albeit with a reduced difference in Gamma activity (p < 0.05). These observations highlight the unique neurophysiological pathways for each letter pair, reflecting varied motor and cognitive demands, and suggesting differences in cognitive processing levels.\nThe frontal cortex demonstrates increased gamma-band activity, reflecting its integrative function across sensory modalities and its pivotal role in higher cognitive processes, such as memory and decision-making [54\u201357], which are crucial for language processing and handwriting execution.\nMoreover, the prefrontal cortex (PFC) emerges as a critical node, facilitating the integration of multi-modal information and mediating complex cognitive functions including executive control and working memory [58, 59]. Similarly, temporal cortex activations are closely tied to language processing, with gamma activity playing a significant role in the neural decoding of language elements [5, 7]. Additionally, the sensorimotor cortex's involvement aligns with its role in governing motor control and sensory processing, fundamental to handwriting [60]. The broad gamma activity across these regions suggests a high-level synchronization of cortical activity, facilitating coherent cognitive representations necessary for complex tasks like letter recognition and differentiation [61-63]."}, {"title": "VII. CONCLUSIONS", "content": "This study introduces a Curriculum-based Neural Spelling Framework (CNS) that leverages the advanced capabilities of GenAI to enhance spell-based neural language decoding tasks. Our approach is distinct in integrating a CNN with a curriculum-driven LLM, promoting an innovative hybrid method in the domain of BCIs. The framework's effectiveness is demonstrated through its application to EEG-based handwriting of all 26 letters, a novel endeavor in the field. The CNS framework notably achieves exemplary top-k accuracy across all subjects, underscoring the robustness of the EEG encoding model. Furthermore, our curriculum supervised fine-tuning method significantly advances the state of the art by enabling the LLM to effectively learn subject-specific letter transition patterns. This methodological innovation not only enhances sentence synthesis quality but also sets a new benchmark for assistive communication technologies. By seamlessly merging non-invasive EEG with GenAI, this study not only addresses the immediate needs of individuals with diverse physical abilities but also sets the stage for future explorations in sophisticated, accessible communication solutions. As we continue to refine these integrations, the potential to expand the capabilities of BCIs and improve the quality of life for users worldwide remains vast and inspiring."}, {"title": "VIII. LIMITATIONS", "content": "Despite its notable strengths, the proposed framework exhibits several limitations that warrant further investigation. Firstly, there is a need to collect and validate online sentence data to ascertain the framework's efficacy in real-world applications. Secondly, the current task framework is primarily based on within-subject analyses, limiting its generalizability across different subjects. The capacity for cross-subject transfer learning remains underexplored and requires significant enhancement to ensure broader applicability. Thirdly, the dataset size for individual subjects is relatively small, which constrains the training of a more extensive and robust brain encoder necessary for a high-performing letter classifier. Future work should focus on collecting more comprehensive data sets and developing a robust, transferable model that can operate effectively across subjects in real-world, online applications."}]}