{"title": "Detect an Object At Once without Fine-tuning", "authors": ["Junyu Hao", "Jianheng Liu", "Yongjia Zhao", "Zuofan Chen", "Qi Sun", "Jinlong Chen", "Jianguo Wei", "Minghao Yang"], "abstract": "When presented with one or a few photos of a previously unseen object, humans can instantly recognize it in different scenes. Although the human brain mechanism behind this phenomenon is still not fully understood, this work introduces a novel technical realization of this task. It consists of two phases: (1) generating a Similarity Density Map (SDM) by convolving the scene image with the given object image patch(es) so that the highlight areas in the SDM indicate the possible locations; (2) obtaining the object occupied areas in the scene through a Region Alignment Network (RAN). The RAN is constructed on a backbone of Deep Siamese Network (DSN), and different from the traditional DSNs, it aims to obtain the object accurate regions by regressing the location and area differences between the ground truths and the pre-dicted ones indicated by the highlight areas in SDM. By pre-learning from labels annotated in traditional datasets, the SDM-RAN can detect previously unknown objects without fine-tuning. Experiments were con-ducted on the MS COCO, PASCAL VOC datasets. The results indicate that the proposed method outperforms state-of-the-art methods on the same task.", "sections": [{"title": "Introduction", "content": "Given one or a couple of photos of an object unseen before, machines are expected to detect it quickly and accurately in various scenes. This ability is advantageous in a variety of applications, such as quickly detecting unfamiliar ob-jects [17,26,21,34], autonomous exploration in unknown environments [7], rapid count for density objects scenes [31,8], etc. Although humans have this ability,"}, {"title": "Related Work", "content": null}, {"title": "Few-shot Object Detection", "content": "Few-Shot Object Detection (FSOD) is different from mainstream deep architec-ture detection methods in its goal to detect new objects by using either one or a few annotated images. Meanwhile, unlike early methods that relied on small sample sizes and object retrieval techniques, such as category-related template [11], point distributed model [2], or shape-invariant strategie [22], etc., FSOD can detect targets without the need for tedious feature or template selection.\nThere are three main categories of fine-tuning FSOD methods: transfer learn-ing, metric-learning, and meta-learning. Transfer learning approaches refer to the reuse of network weights pre-trained on a source domain to improve gener-alization capabilities on a few novel images [1,18]. Recent work has introduced semantic relations between novel base classes [9] and contrastive proposals [5]. However, transfer learning is highly dependent on the source domain and is difficult to extend to very different scenarios.\nMetric-learning aims to learn the appropriate strategies, or embedding spaces, where similar content is encoded in features with small distances to each other, while the encoded features of dissimilar inputs should be far apart [15,6,3]. Since the training samples are constructed in pairs, triplets or quadruplets, there is"}, {"title": "Few-shot Object Detection At Once (FSOD-AO)", "content": "Unlike FSOD, FSOD-AO requires machines to identify a novel, previously unseen object in different scenes without fine-tuning. FSOD-AO has three core require-ments: finding the candidate regions of target objects, retaining the correct cate-gories by suppressing the false ones, and accurately identifying the target regions.\nThese steps are required for processing without fine-tuning. Attention-Region Proposal Network (A-RPN) [26] is an early pioneering method proposed for the FSOD-AO task. It uses the region proposal network (RPN) originally proposed in Faster-RCNN [27] to find the class-agnostic relational regions, and then uses a multi-relational classifier to suppress errors. Another pioneering work, AirDet [7], also uses RPN to obtain possible regions, and then uses Global-Local Re-lation (GLR) and Relation Embedding (PRE) for location regression. However, both methods lack an accurate mechanism for refining regions, as we introduced in the first section.\nA related work to FSOD-AO is visual counting. It aims to obtain the overall number of a particular category at a time, even if the novel objects are very dense in the scene [8]. FamNet [31] takes multiple objects from the query image and predicts a density map for the presence of all objects of interest in the query image. Although FamNet can quickly count the novel visual category by estimating the number of highlight points in the density map, it only presents the center points of the targets and ignores the occupied areas of the targets in the scene.\nGiven an object patch and its position in the previous video frame, Deep Siamese Networks (DSN) can determine its new position in subsequent frames [23,4]. The proposed FSOD-AO method is partly inspired by the idea of FamNet and DSN, namely we consider the detection of an unseen object as two phases: exploring the possible locations of new objects in the scenes, and immediately determining their regions using DSN."}, {"title": "Methodology", "content": null}, {"title": "Framework", "content": "Before introducing the proposed method, we first give the prelim-inary concepts. In this work, all targets are divided into two classes: $C_B$ and $C_F$ ($C_B \\cap C_F = \\emptyset$), where $C_B$ is the bases classes, and $C_F$ is the few shot de-tection set containing N novel categories. During the training process, images from the base classes $C_B$ are split into query images $C_B^q$ and support images $C_B^s$ ($C_B = C_B^q + C_B^s$). Given all support images $C_B^s$, the model learns to detect ob-jects in query images $C_B^q$. In the test phase, images from the few shot detection set $C_F$ are split into query images $C_F^q$ and support images $C_F^s$ ($C_F = C_F^q + C_F^s$).\nThe model detects objects in unknown query images $C_F^q$ by only providing k (1 \u2264 k \u2264 K) support images in $C_F^s$ without fine-tuning (the values of K are usually in the range of 1-5) [7]."}, {"title": "Location Prediction (SDM)", "content": "Inspired by [31], we use the Few Shot Adaptation and Matching Network (Fam-Net) to obtain objects possible center locations. FamNet mainly contains a feature extraction module and a density prediction module. The feature extrac-tion module consists of a general feature extractor capable of handling a large"}, {"title": "Region Prediction using Region Proposal Network (RPN)", "content": "The density map indicates the potential locations of novel objects. However, the possible regions of the novel objects are absent in SDM. To this end, we adopt Region Proposal Network (RPN) to generate potential bounding boxes for the novel objects. RPN is originally proposed in Faster-RCNN [27], used to generate class-agnostic proposals from the dense anchors."}, {"title": "Object Identification", "content": "The object identification consists of two steps: Class-specific Region Purification and Region Alignment. Class-specific Region Purification aims to remove the obvious partial false detections, while Region Alignment is used to align the regions."}, {"title": "Class-specific Region Purification", "content": "SDM outputs the novel objects\u2019 pos-sible locations and RPN obtains region candidates in the query images. The re-gions indicated by RPN are class-agnostic proposals, while the Location Predic-tions presented by dot annotations in SDM are related to the object categories.\nLet $I_{SDM}$ be the SDM for a assigned query images, and $P_F^{(j)}$ ($0 \\leq j \\leq J$) ($P_F^{(j)} \\in C$) is the $j^{th}$ candidate box in C, then the Class-specific Regions are given by (1).\n$\\frac{H(P_F^{(j)})}{A(P_F^{(j)})} \\geq h$ (1)\nIn (1), the function $H(.)$ is used to accumulate the highlighted intensity pixies in $I_{SDM}$ within the box given by $P_F^{(j)}$. The intensity values in the dense map for each pixel are normalized to [0, 1). The function$A(.)$ presents the total number of pixels in the region given by $P_F^{(j)}$. If the value of (1) is true, an object is possibly contained in $P_F^{(j)}$, where $h$ is a threshold. In this work, we follow the article [31], and set its value as 0.1 empirically."}, {"title": "Region Alignment Network (RAN)", "content": "After the false detections are removed from the proposal boxes using Class-specific Region Purification, the left pro-posals are needed to judge whether they are category-related. Meanwhile, the category-related regions are necessarily aligned to the ground truth according to their central locations, widths, and heights. To this end, we propose a Region Alignment Network (RAN) to combine these two functionalities simultaneously.\nThe proposed RAN is construed on a Deep Siamese Networks (DSN) struc-ture. Siamese networks consist of twin networks with sharing weights, where each network is respectively fed with a support image and a query one [13]. Early,"}, {"title": "Experiments", "content": "In the the experiments, we first discuss the previous training of the proposed method before applying it to FSOD-AO. Then we compare the proposed method with the pioneer FSOD-AO ones on MS COCO [30] and PASCAL VOC [24] datasets."}, {"title": "Pre-training for RAN before being Employed to FSOD-AO", "content": "Following prior works [7,26,14], the 80 classes in COCO are split into 60 non-VOC base classes and 20 novel classes. During training, the base class images from COCO trainval2014 are considered available. Let $P_{RPN}^r$ ($1 \\leq r < R$) be an image patch given by a region proposal and $P_{GT}^r$ ($1 \\leq r < R, R < R$) be the cor-responding image patch which owns the ground truth region labeled by humans.\nThen in the training, the image pair $P_{RPN}^r$ and $P_{GT}^r$ is similar to the pair of $C_F^{(i)}$ and $P_F^{(j)}$ (section \u201cRegion Alignment Network\u201d). The location distances between their centers, the scale differences between their width and height are calculated by (3)-(6), and used to guide the training of Region Alignment Net-work. There are quite a few cases in that no object (background) or only a very small part of objects are contained in the image patches in region proposals. In these cases, the objects in $P_{RPN}^r$ (or $P_{GT}^r$) do not belong to any categories of the objects in $P_{GT}^r$ (or $C_F^{(i)}$). These image pairs are also used in the training of RAN, where the parameter $c$ is set to 0. In this way, a total of 21018 image pairs are used to train RAN. The training of RAM is carried out on a computer with an Intel(R) Core(TM) i9-9900K 3.60GHz CPU, 32G memory, and V100 GPU card with 16G memory. And in the test phase, the models are deployed on a computer with 2.60GHz CPU, 8.0G RAM, and 2 NVIDIA Titan-X GPUs.\nIn the RAN test phase, 6728 pairs of $P_{RPN}^r (x_r, y_r, w_r, h_r)$ and $P_{GT}^r (x_{gt}, y_{gt}, w_{gt}, h_{gt})$ are used to analyze the performance of RAN for 20 novel class objects after it was trained on 60 base classes (21018 image pairs). Let $P_{RAN}^r (x_r, y_r, w_r, h_r)$ be the aligned region for $P_{RPN}^r$ after it is processed by RAN, where $x_r, y_r, w_r, h_r$ are the aligned values for $x_r, y_r, w_r, h_r$ respectively. In these 6728 pairs, the categories of 5645 pairs are correctly classified. The classification accuracy of RAN is 83.90%.\nWe continuously discuss the performance of the RAN on region alignment."}, {"title": "Efficiency Comparison", "content": "Table 3 shows the efficiency comparison between SDM-RAN and the SOTA methods with the official source code. Similar to the SOTA methods, SDM-RAN also runs at a setting of 3 shots per class using 2 NVIDIA Titan-X GPUs (AirDet was employed on 4 NVIDIA Titan-X GPUs). Without fine-tuning, SDM-RAN and AirDet can make direct inferences on novel objects with comparable speed, while the other methods require a fine-tuning time of about 3-11 minutes. Dis-like the relatively complex multi-relation detector in A-PRN and multiple time-consuming modules (Global-Local Relation, Embedded Location Regression) in AirDet, the proposed method consists of three straightforward phases, including SDM (a lightweight convolution procedure), PRN (region prediction), and RAN (region alignment). Each module runs independently in less than 0.013 seconds per frame. Therefore, SDM-RAN operates at a speed of 0.043 seconds per frame, which is significantly faster than AirDet and A-RPN."}, {"title": "Ablation Studies", "content": "We conduct a series of ablation experiments on COCO dataset."}, {"title": "Discussions", "content": "The proposed FSOD-AO method is tested experimentally and compared with the state-of-the-art methods on COCO and VOC datasets. In general, the results on COCO and VOC datasets clearly show that the proposed method outperforms A-RPN and AirDet with 1, 2, 3 and 5 shots on $AP_{50}$. Partially, compared to the two pioneering works (A-RPN and AirDet), the proposed method gains higher $AP_{75}$ scores with 1, 2 and 3 shots on COCO, and obtain better AP values with 1, 3, 5 shots on VOC. In addition, the proposed method also archives compet-itive results on $AP_{50}$ compared to the SOTA methods with fine tuning, such as FSOD-VFA [16], DiGeo [17], FSOD-GCN [14], TFA [32] on COCO dataset.\nOur proposed method provides a novel solution for the FSOD-AO task by si-multaneously evaluating both the object locations and region proposals. It is noticeable that when selecting one or two support images for novel classes, it is recommended to choose the most commonly seen ones as supported images. However, for 3, 5 or more shots, randomly selected images work well.\nIt is noticeable that we set the values of $h, \u03bb\u03c9$ and $\u03bb\u03b7$ empirically to 0.1, 2.0. The threshold $h$ is used to determine whether a highlighted intensity region in SDM could be selected as a candidate. And $\u03bb\u03c9$ and $\u03bb\u03b7$ are used to limit the maximum and minimum size scale for the objects in the query images to"}, {"title": "Conclusions", "content": "This work presents a novel technical realization for the task of correctly identi-fying the categories of new objects, while simultaneously extracting their precise regions without fine-tuning. We first adopt an attention-based structure (SDM) to locate the novel object. Additionally, we incorporate RPN into our frame-work to obtain object regions. The combination of SDM and RPN enables the natural generation of approximate positions and regions for novel objects. To ac-curately match and align the approximate candidates with the supported images (patches), we propose a Deep Siamese Networks based structure (RAN). This structure serves to eliminate false candidates and synchronously align the region by analyzing the differences in location and range scale between the predicted and ground truth boxes. With the pre-learning on the annotated labels given by traditional datasets, the proposed SDM-RAN can identify a previously unseen object immediately without fine tuning. Experiments are conducted on the MS COCO and PASCAL VOC datasets, and the results show that the proposed method outperforms the SOTAs on the FSOD-AO task. Furthermore, it offers the advantage of faster execution compared to traditional FSOD-AO methods."}]}