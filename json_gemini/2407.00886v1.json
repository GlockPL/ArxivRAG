{"title": "Mechanistic Interpretation through Contextual Decomposition in Transformers", "authors": ["Aliyah Hsu", "Yeshwanth Cherapanamjeri", "Anobel Y. Odisho", "Peter R. Carroll", "Bin Yu"], "abstract": "Transformers exhibit impressive capabilities but are often regarded as black boxes due to challenges in understanding the complex nonlinear relationships between features. Interpreting machine learning models is of paramount importance to mitigate risks, and mechanistic interpretability is in particular of current interest as it opens up a window for guiding manual modifications and reverse-engineering solutions. In this work, we introduce contextual decomposition for transformers (CD-T), extending a prior work on CD for RNNs and CNNs, to address mechanistic interpretation computationally efficiently. CD-T is a flexible interpretation method for transformers. It can capture contributions of combinations of input features or source internal components (e.g. attention heads, feed-forward networks) to (1) final predictions or (2) the output of any target internal component. Using CD-T, we propose a novel algorithm for circuit discovery. On a real-world pathology report classification task: we show CD-T distills a more faithful circuit of attention heads with improved computational efficiency (speed up 2x) than a prior benchmark, path patching. As a versatile interpretation method, CD-T also exhibits exceptional capabilities for local interpretations. CD-T is shown to reliably find words and phrases of contrasting sentiment/topic on SST-2 and AGNews datasets. Through human experiments, we demonstrate CD-T enables users to identify the more accurate of two models and to better trust a model's outputs compared to alternative interpretation methods such as SHAP and LIME.", "sections": [{"title": "1. Introduction", "content": "Transformers (Vaswani et al., 2017) have recently demonstrated impressive predictive capabilities (Brown et al., 2020) by learning intricate nonlinear relationships between features. However, the challenge of comprehending these relationships has resulted in transformers largely considered as black boxes. Despite this, transformers are increasingly utilized in high-stakes domains such as medicine (e.g. medical image analysis (He et al., 2023)) and science (e.g. protein structure prediction aiding drug discovery (Jumper et al., 2021)). This underscores the necessity of understanding and anticipating potential model behaviors. To strengthen trust in the deployment of advanced black-box models like transformers, researchers emphasize the urgent need for reliably interpreting them (Hendrycks et al., 2023; R\u00e4uker et al., 2023) to mitigate risks and address issues like fairness (Nemani et al., 2024). Mechanistic interpretability, a study to explain behaviors of machine learning (ML) models in terms of their internal components, is at the frontier of interpretability research (Geiger et al., 2021; Geva et al., 2020; R\u00e4uker et al., 2023), as it uniquely provides an avenue for guiding manual modifications (Elhage et al., 2021; Vig et al., 2020) and reverse-engineering solutions (Elhage et al., 2022; Meng et al., 2023).\nIn this work, we introduce contextual decomposition for transformers (CD-T) \u00b9, a novel interpretation method that enables mechanistic interpretation. It explains contributions of combinations of input features or source internal components (e.g. attention heads, feed-forward networks) to (1) final predictions or (2) the output of arbitrary target internal component, without any modifications to the underlying model. Our proposed method, CD-T, is a general technique that can be applied to a wide range of standard transformer-based models and data types.\nThis work consists of three novel contributions. First, the development of CD-T, which is a generalization of CD, a previous method for obtaining importance scores for CNNs and RNNs (Murdoch et al., 2018; Singh et al., 2018), to transformers. As transformers became a dominant deep learning (DL) architecture in state-of-the-art applications, this generalization ensures CD-T benefits a broader group"}, {"title": "2. Related Work and Connections to Our Work", "content": "Interpreting deep neural networks (DNNs) is a growing field (Adadi & Berrada, 2018; Murdoch et al., 2019; R\u00e4uker et al., 2023) which encompasses a broad set of techniques including adversarial techniques (Carmichael & Scheirer, 2023; Chen et al., 2019), input attribution methods (Sundararajan et al., 2017; Ribeiro et al., 2016), mechanistic interpretability methods (Zhao et al., 2020; Wang et al., 2023), and others (Mao et al., 2019; Hsu et al., 2023). Our work focuses on both local interpretations (i.e. interpret individual predictions made by a DNN) and mechanistic interpretability (i.e. explain behaviors of DNNs in terms of their internal components).\nLocal interpretation The majority of previous research has concentrated on attributing local importance to individual features, such as pixels in an image or words in a document. Various methods exist to assign feature-level importance for different architectures, including gradient-based (Sundararajan et al., 2017; Springenberg et al., 2014; Selvaraju et al., 2016; Baehrens et al., 2009), decomposition-based (Murdoch & Szlam, 2016; Shrikumar et al., 2016; Bach et al., 2015) and others (Dabkowski & Gal, 2017; Fong & Vedaldi, 2017; Ribeiro et al., 2016; Zintgraf et al., 2017). Ancona et al. (2017) and Lundberg & Lee (2017) discussed rigorously the similarities among the methods.\nSpecifically for LSTMs, Murdoch et al. (2018) highlighted the shortcomings of previous interpretation methods relying on word-level scores. They introduced contextual decomposition (CD), an algorithm capable of extracting feature interactions learned by LSTMs by generating phrase-level importance scores. Singh et al. (2018) extended CD to RNNs and CNNs, and proposed an hierarchical interpretation method using feature clustering. To capture feature interactions in transformers, Tsang et al. (2020) proposed an axiomic feature attribution framework and Hao et al. (2020) proposed a self-attention attribution method.\nHowever, no existing work is versatile enough to be able to provide individual prediction analysis while enabling mechanistic interpretability to interpret interactions of internal components in DNNs. Such interpretation tool would benefit practitioners greatly because of its diverse use cases. To address this problem, this work introduces CD-T as a principled way to, for the first time, provide both local interpretation and mechanistic interpretability for transformers, a critical DL architecture in state-of-the-art applications.\nMechanistic interpretation Work in mechanistic interpretability aims to explain and predict behaviors of DNNs by understanding the inner-working of the models. Previous research has focused on understanding features learned by DNNs (Olah et al., 2017; Elhage et al., 2022), developing mathematical frameworks for understanding DNNs (Elhage et al., 2021), and discovering circuits (computational sub-graphs) in DNNs (Nanda et al., 2023; Cammarata et al., 2021; Chughtai et al., 2023; Wang et al., 2023). Most existing work on circuit discovery require extensive feature visualizations or multiple passes of inference runs to perform causal interventions, both demanding much manual effort and computation resource. To remedy this, we develop a computationally efficient procedure (speed up 2x compared to a prior benchmark, path patching (Wang et al., 2023)) using CD-T to iteratively trace important components back from the logits to discover circuits in transformers."}, {"title": "3. Our Method: CD-T and Mechanistic Interpretability", "content": "In this section, we describe the extension of contextual decomposition to transformers, CD-T, and its use in mechanistically interpreting the behavior of these models. When given a set of source and target activations in the network, CD-T produces a decomposition of the target activations into two components one reflecting the contributions of the source activations and the other, the contributions of the rest of the network. While we describe CD-T specifically for BERT-based models, it generalizes straightforwardly to more general attention-based models including decoder-only models such as GPT-4. Since contextual decompositions are computed by propagating a decomposition of the input through the nodes of the network, our primary contribution here will concern with the propagation of an input decomposition through the (self-)attention module. This is because all other modules in a typical transformer (such as linear transformations and the application of element-wise nonlinear activation functions) have been addressed by prior work (Murdoch et al., 2018).\nFor the rest of the section, we first recall the basic operations of BERT-based models (Section 3.1). We then present the extension of the contextual decomposition framework to transformers (Section 3.2) before concluding with a description of its use in a circuit building algorithm for mechanistic interpretability (Section 3.3)."}, {"title": "3.1. Transformers", "content": "In BERT-based models, the input is typically represented as a sequence of tokens where the first token is always the classification token, usually denoted by [CLS]. For each token in the sequence of length l, {ti}i=1, a d-dimensional embedding is constructed {xi}i=1 with xi \u2208 Rd. This embedding encodes information from the value of the token ti as well as its position in the sequence i. These embeddings are then propagated through a series of encoder modules where each encoder module takes as input a sequence of embeddings {xi}i=1 and outputs another sequence {xi}i=1 with x\u2032i \u2208 Rd. Since, the number and dimensionality of the token embeddings remain constants through any encoder module, a series of these may be applied to obtain progressively more sophisticated representations of the input sequence. The key component that enables sharing of information across the various tokens in the sequence is the self-attention module which we describe in detail. The self-attention module comprises NA independent attention heads with each one taking as input a sequence {xi}i=1 with xi \u2208 Rd and producing an output {yi}i=1 with yi \u2208 Rda where da = d/NA. For each attention head, a, there exists key fk : Rd \u2192 Rk, query fq : Rd \u2192 Rk, and value fv: Rd \u2192 Rda. In most transformer models, these are either simple linear transformations or a linear transformation followed by a position-wise non-linearity. The output of the attention-head is now defined by the following equations:\n\u2200i \u2208 [l] : ki = fk(xi), qi = fq(xi), vi = fv(xi)\n\u2200i, j \u2208 [l] : ai,j =  exp(qiTkj/\u221adk) / \u03a3m\u2208[l] exp(qiTkm/\u221adk)\n\u2200i \u2208 [l] : yi = \u2211j=1lai,jvj.\nIn the above display, the last equation computes the output of attention head as a linear combination of the value vectors, vj, with the weights determined by inner product of the ith query vector qi with the key vectors, kj. Stacking the outputs of each of the attention heads, we obtain the output of the self-attention module."}, {"title": "3.2. Contextual decomposition for transformers (CD-T)", "content": "We will now describe our implementation of Contextual Decomposition. Contextual Decomposition (CD) propagates a decomposition of the input (or of the activation of the transformer at any layer of the transformer) through the model. Formally, given a decomposition of an input vector x = \u03b2 + \u03b3 \u2208 Rd where \u03b2 represents the relevant portion and \u03b3 the irrelevant portion, Contextual Decomposition defines a set of rules which determine the decomposition of the output of a module f : Rd \u2192 Rk which operates on x. For instance, for the case of element-wise ReLU activation function, the output decomposition of Contextual Decomposition (f(x) = \u03b2\u00ba + \u03b3\u00ba) is defined as follows:\n\u03b2\u00b0 = 1/2([ReLU(\u03b2)] + [ReLU(\u03b2 + \u03b3) \u2013 ReLU(\u03b3)])\n\u03b3\u00b0 = 1/2([ReLU(\u03b3)] + [ReLU(\u03b2 + \u03b3) \u2013 ReLU(\u03b2)])\nWe refer the interested reader to Murdoch et al. (2018) for decompositions of other modules such as linear transformations. As previously explained, the only module not accounted for in the context of transformers is the self-attention module described in Section 3.1.\nIn the context of transformers, we assume a decomposition of the input to the attention head, {xi = \u03b2i + \u03b3i}i=1 where \u03b2i and \u03b3i denote the relevant and irrelevant portions of the input. We index the decomposition with the position in the sequence for ease of presentation. We compute the decomposition of the output of the attention head {yi = \u03b2a + \u03b3a}i=1 as follows:\n\u2200i \u2208 [l] : fv(xi) = \u03b2v + \u03b3v\n\u2200i \u2208 [l] : \u03b2a = \u03a3j=1lai,j\u03b2vj, \u03b3a = \u03a3j=1lai,j\u03b3vj\nNote that we do not decompose the attention weights, ai,j, into relevant and irrelevant components. While it is possible to do so within the framework, we found that a simple"}, {"title": "3.3. Mechanistic interpretation with CD-T", "content": "Having formally defined CD-T in Section 3.2, we now introduce a novel, computationally efficient algorithm for mechanistic interpretation in transformers via circuit discovery using CD-T. Before delving into our algorithm, we first formally define a circuit. If we view a model as a computational graph M, where nodes are activations of the model components in its forward pass (e.g. input embeddings, attention heads) and edges are the interactions between those components (e.g. an attention module, position-wise feed-forward networks), a circuit C is a subgraph of M responsible for the behavior of some component of the network, such as the output logits of a prediction task. Given an input x, similarly as to how the entire model defines a function M(x) from inputs to logits, we also associate each circuit C with a function C(x), defined by ablating away the effect of all components in M\\C (i.e. the components not included in C) leading up to the target component of the circuit C. This method improves the interpretability of the entire model by distilling it into a small-sized circuit which nevertheless, faithfully explains most of its behavior.\nNext, we present our algorithm for constructing circuits with CD-T where we focus specifically on computing circuits with the output logits as the target component. Our algorithim, starting from the output logits of the network, constructs a circuit by iteratively identifying vital internal components through the various layers of the network. In each iteration, we define a source component s and a target set of receivers R, a set of internal components (for instance, these are the output logits in the first iteration), and our goal is to measure the direct effect of s on R. Here, we impose the restriction that all components in R have to be downstream of s i.e. we only search for influential s in the same layer or layers before (with layer index smaller than or equal to) the components in R. In path patching (Wang et al., 2023), a prior method proposed for circuit discovery in GPT-2 small, this is achieved by ablating s with its mean response, computing the resulting activations of R after this change (with one inference pass), and measuring the difference in the output logits with another inference pass after substituting the activations of R with the new values just computed. In other words, path patching requires two passes of inference runs to measure the direct effect on R for just one s, which could lead to large computational costs"}, {"title": "Algorithm 1 Building a Circuit using CD-T", "content": "Input: data x, mean activations M, number of top attention heads to extract N\nCompute all activations on x\nDenote activation(s, x) as the activation of s\nInitialize C to store the circuit\nInitialize circuit level counter k \u2190 0\n{# Base case}\nSet R to be the output logits of the model\nrepeat\nfor each attention head s upstream of R do\nSet the relevant and irrelavant decomposition of s to activation(s, x) \u2013 M[s] and M[s] respectively\nPropagate decomposition to nodes in R with CD-T\nUse decomposition to compute H(s, R) (Eq. (1))\nend for\nSet Rnew to be the top N heads with highest H(s, R)\nR = Rnew, C[k] = Rnew, k+ = 1\nuntil no upstream attention heads to R are available\nreturn C\nwhen iterating through all possible choices for s to decide which components have the most influence on R.\nBy mathematically decomposing activations of arbitrary internal components at any level and the output logits in one pass, CD-T enables more efficient measurement of the direct effect of s on R. To measure the direct effect of s on R, we mean-ablate s by designating the mean response of s to the irrelevant part of its decomposition and move the residual (difference between its original activation and the mean) to the relevant part, and average the (absolute values of the) propagated relevant parts of the activations of R as the direct effect of s on R. This can be done in just one inference run, providing a speed-up of 2x over path-tracing. Formally, letting for any r\u2208 R, \u03b2', \u03b3' \u2208 Rdr denote the relevant and irrelevant decomposition provided by CD-T measuring the effect of s on r, the contribution score of s on R is defined as follows:\nH(s, R) := 1/dr \u03a3r\u2208R \u03a3i=1dr |\u03b2'i|"}, {"title": "4. Experimental Results", "content": "We now present empirical validation of CD-T on BERT-based models. In Sec. 4.2, we distill an attention head circuit using CD-T in BERT trained on real-world pathology reports. Our algorithm is then evaluated against a prior benchmark called path patching (Wang et al., 2023), qualitatively through circuit visualizations, and quantitatively through comparisons of computational efficiency and faithfulness (how much full model performance can a circuit achieve for the task). In Sec. 4.3 and Sec. 4.4, we focus on CD-T's ability to provide local interpretations for BERTS trained on SST-2 and AGNews. The two datasets were chosen to demonstrate CD-T's capabilities on tasks with different levels of difficulty, with SST-2 being a simpler binary classification task with shorter samples, and AGNews a harder classification task with longer texts and diverse topics."}, {"title": "4.1. Experimental setups", "content": "To understand the utility of CD-T for real-world use cases in critical domains such as medicine, we collected a corpus of 2907 structured pathology reports under an institutional review board (IRB) approval. The corpus includes pathology reports for patients that had undergone radical prostatectomy for prostate cancer at the University of California, San Francisco (UCSF) from 2001 to 2018. The reports contain an average of 471 tokens, much longer than samples in SST-2 or AGNews. Our pathology reports dataset is not publicly available due to protected patient information; however, we provide a few anonymized samples in Appendix A.1 as illustrations. We fine-tune an uncased base BERT model on primary Gleason score classification using standard best practices (See Appendix A.2 for fine-tuning details), and the model attains an accuracy of 85.8%.\nIn the circuit discovery experiment, we obtained mean activations of all components in the model for mean ablations by averaging over 500 pathology report samples. To ensure stability, we extracted 20 candidate circuits 2 by running Alg. 1 on 20 randomly selected report samples, and a final circuit was determined by groups of attention heads that appear with the highest frequency among the candidate circuits for each level. In this paper, we show results from extracting 6 attention heads for each level of the circuit by setting N = 6 in Alg. 1. We experimented with N = 1, 3, 6, and empirically found setting N = 6 yielded a more stable circuit composition.\nFor SST-2 and AGNews, we use the fine-tuned models initialized with uncased base BERT that are available on TextAttack (Morris et al., 2020). They attain accuracies of 92.4% and 95.1% separately. The weakened models for the human evaluations are obtained from the original models by randomly permuting a small percentage of their weights, following a similar setup as in Singh et al. (2018). For SST-2 and AGNews, 5% and 10% of weights are randomized, reducing test accuracy from 92.4% and 95.1% to 60.9% and 66.7%."}, {"title": "4.2. Discovering circuits of attention heads in transformers", "content": "In this experiment, we focus on building a circuit of attention heads for a real-world primary Gleason classification task, and evaluate our algorithm against a prior method, path patching (Wang et al., 2023), qualitatively on circuit visualizations, and quantitatively on computational efficiency as well as circuit faithfulness (how much of a full model's performance can a circuit account for)."}, {"title": "4.2.1. CIRCUIT VISUALIZATIONS", "content": "After distilling the final circuit in the fine-tuned BERT for primary Gleason classification, we investigate the functionality of attention head groups at each level of the circuit qualitatively by inspecting word clusters each of the attention head group pays most attention to. In Wang et al. (2023), this is done in a more nuanced fashion with positions information also taken into account, on their custom indirect object identification dataset, which comes with word-level labels. However, our pathology reports dataset is a more general case without the rigid structural restrictions of Wang et al. (2023) and such word-level labels are not available. As a remedy, we introduce a novel procedure to aid the interpretation of attention head groups in such general cases.\nGiven a group of attention heads from a level in the final circuit, we first compute their average attention map, standardize the map, and select words with attention scores that are \u22653 standard deviations higher than the mean. Next, we convert the selected words to their word2vec (Mikolov et al., 2013) embeddings and run k-means clustering after performing PCA on the embeddings to obtain influential word clusters for the given attention head group. We visualize the final circuit obtained using CD-T and its influential word clusters in Fig. 1."}, {"title": "4.2.2. \u0421\u043eMPUTATIONAL EFFICIENCY AND FAITHFULNESS", "content": "Having interpreted the circuit obtained using CD-T and compared it with the circuit obtained using path patching qualitatively in the previous section, we now perform quantitative evaluation of the two methods to showcase the benefits of CD-T for aiding mechanistic interpretability. We evaluate the two methods in terms of (1) computational efficiency and (2) faithfulness (how much of the full model's performance can a circuit account for). For computational efficiency, we simply measure the average system runtime for each method to complete one iteration of the direct effect computation for building one level in the circuit. For faithfulness, we measure the recovery percentage for full model performance as Ex C(x)/M(x) \u00d7 100% over 200 report samples where only the logits of the true label-class are used to compute the ratio.\nIn Table 1, we observe CD-T is almost two times more efficient in the computation for building circuits compared to path patching, which is due to the fact that CD-T halves the amount of inference runs needed in the algorithm, as described in Sec. 3.3. In Table 2, with only a small total amount of attention heads (0.04% of the attention heads in the full model), we show the circuit obtained using CD-T, outperforms path patching by being able to recover 46.0% of the full model performance, while path patching only achieves 41.9% of that using 0.03% of the attention heads in the full model. We additionally provide the faithfulness performance of two random baselines, denoted as Random (N), obtained by randomly selecting N attention heads in the model to form circuits, where we set N to match the amount of attention heads in the two circuits using CD-T (N = 30) and path patching (N = 18). Both CD-T and path patching substantially outperform their corresponding random baselines. The performance of random baselines is averaged over 10 random seed runs."}, {"title": "4.3. Identifying top-scoring phrases", "content": "Mechanistic interpretation while providing more information, is often challenging due to the range of user choices in their definition which frequently require sophisticated un-"}, {"title": "4.4. Human experiments", "content": "In this section, we demonstrate through human experiments that CD-T allows users to better trust and reason about the accuracy of transformers. Human subjects consist of eleven graduate students at the author's institution, and all of them have a research background in ML. Each of the human subjects was asked to fill in a survey with two types of questions: (1) whether, using a given interpretation method, they could identify the more accurate of two models, and (2) whether the method led them to trust a model's output, following a similar protocol as prior work (Singh et al., 2018). These two types of questions were asked on two datasets: SST-2 and AGNews, and CD-T was compared against three baselines: LIME (Ribeiro et al., 2016), SHAP (Lundberg & Lee, 2017), and Integrated Gradients (Sundararajan et al., 2017). The exact survey prompts can be found in Appendix A.4."}, {"title": "4.4.1. IDENTIFYING AN ACCURATE MODEL", "content": "In this experiment, to avoid variance due to samples, we collected the same two sets of samples that were used across all interpretation methods from the two datasets. For each question, we presented two visualizations of a given interpretation method (one generated from the model with higher predictive accuracy, and the other from the weakened version of that same model), and a subject was asked to identify which of the two visualizations were from the more accurate model. Each subject was asked to make this comparison for each combination of dataset and interpretation method, for 24 total comparisons. The samples shown were chosen to maximize disagreement between models: for each question, only either the first model predicts correctly or the second model predicts correctly.\nFig 2A shows the results of the survey. For both SST-2 and AGNews, humans were better able to identify the strongly predictive model using CD-T compared to baselines such as LIME and SHAP, which only perform similar or even slightly worse to the random chance (50%). Overall CD-T exhibits comparable performance with integrated gradients, except for on AGNews, where integrated gradients (IG) perform better at helping to identify the more accurate model."}, {"title": "4.4.2. EVALUATING TRUST IN A MODEL", "content": "In this experiment, for each question, subjects were shown interpretations of the same prediction from the four interpretation methods, and were asked to rank the interpretations from 1 to 4 based on how much the interpretations led them to better trust the model, with 1 being the most trustworthy. Subjects were asked to rank for five different samples in each dataset, for 10 total rankings. The interpretations were generated from the more accurate model described in Sec. 4.4, and the samples used were chosen from the ones correctly predicted by the more accurate model. We provide a random subset of interpretation visualizations used in the survey in Appendix A.5.\nFig 2B shows the average rankings received by each method on the two datasets, where a lower value corresponds to a better ranking (i.e. 1 is the best ranking). From the result, CD-T outperforms prior baselines such as LIME and SHAP, with an average rank of 2.1 out of 4, and performs slightly better or comparably to integrated gradients (IG)."}, {"title": "Limitations", "content": "Despite having shown both qualitative and quantitative evidence of the benefits of CD-T, our results is limited in scale and to the datasets and prior interpretation methods evaluated. More work is needed to generalize these findings to a broader set of models, datasets, and interpretation methods. Although our proposed algorithm for building circuits using CD-T works for constructing circuits of any internal components, we only discussed and interpreted circuits built with purely attention heads to be comparable with prior methods. Circuits built with different/heterogeneous internal components (e.g. feed-forward networks, layer norms) can be a promising direction for further investigation. Finally, our proposed algorithm for circuit discovery is limited in that it requires manual effort to define the number of attention heads to extract for each level, and that it extracts a fixed number of attention heads for every level in the circuit. A fully automated and more flexible circuit discovery algorithm is an important direction for future work."}, {"title": "5. Conclusions", "content": "In this work, we adapted contextual decomposition to transformers (CD-T), and proposed a novel algorithm for circuit discovery using CD-T to computationally efficiently enable mechanistic interpretability. Our proposed algorithm is agnostic to transformer types and is able to construct circuits of arbitrary internal components in a model. On a real-world pathology reports dataset, we demonstrate that the attention head circuit built using CD-T is not only computationally more efficient (speed up 2x) but more faithful (achieves 46% of full model performance with only 0.04% of attention heads in the full model, compared with 41.9% using 0.03% of the attention heads) than a prior mechanistic interpretation method, path patching.\nAdditionally, we propose a pipeline to interpret the extracted circuits by capturing influential word clusters for each group of attention heads in the circuit in an unsupervised fashion. The result reveals, first, attention heads at different levels of the circuit typically focus on the same three groups of concepts: punctuation/numbers, biomedical terms, and helper words (i.e. words that often exist in the vicinity of actual Gleason scores, such as 'grade' and 'pattern'), and second, attention heads closer to the output logits, at layers 11 or 10, focus more on helper words and punctuation, and that it was only until backtracking to attention heads at layers 7-9 that we start to see Gleason scores (e.g. '3', '4', '5') become influential. Circuit visualization obtained from path patching overall exhibits the same trend as what we see in the circuit obtained using CD-T, except that the middle level attends much less medical terms relevant to prostate cancer. From the circuit analysis, we demonstrate how CD-T helps disentangle different aspects of knowledge about the reports encoded in attention heads, and the hierarchy of the knowledge learned by the model.\nFinally, with CD-T being a versatile interpretation method, we showcase its capability for local interpretations both qualitatively and quantitatively on two datasets, SST-2 and AGNews. We first show CD-T is able to reliably find words and phrases of contrasting sentiment/topic on SST-2 and AGNews. Through human experiments, we demonstrate CD-T enables users to identify the more accurate of two models and to better trust a model's outputs compared to alternative interpretation methods such as SHAP and LIME."}, {"title": "6. Impact Statement", "content": "The proposed algorithm, Contextual Decomposition for Transformers (CD-T), provides a general mechanistic interpretation method for deep neural networks called transformers, which are the fundamental architectures in chatGPT and GPT4. CD-T has good computational efficiency, and can be used to understand the inner workings of transformers for human understanding and inspection, in order to help ensure safety of deep learning models in AI, especially in high-stakes areas such as medicine and cyber-security"}]}