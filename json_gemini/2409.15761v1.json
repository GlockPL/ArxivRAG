{"title": "TFG: Unified Training-Free Guidance for Diffusion Models", "authors": ["Haotian Ye", "Haowei Lin", "Jiaqi Han", "Minkai Xu", "Sheng Liu", "Yitao Liang", "Jianzhu Ma", "James Zou", "Stefano Ermon"], "abstract": "Given an unconditional diffusion model and a predictor for a target property of interest (e.g., a classifier), the goal of training-free guidance is to generate samples with desirable target properties without additional training. Existing methods, though effective in various individual applications, often lack theoretical grounding and rigorous testing on extensive benchmarks. As a result, they could even fail on simple tasks, and applying them to a new problem becomes unavoidably difficult. This paper introduces a novel algorithmic framework encompassing existing methods as special cases, unifying the study of training-free guidance into the analysis of an algorithm-agnostic design space. Via theoretical and empirical investigation, we propose an efficient and effective hyper-parameter searching strategy that can be readily applied to any downstream task. We systematically benchmark across 7 diffusion models on 16 tasks with 40 targets, and improve performance by 8.5% on average. Our framework and benchmark offer a solid foundation for conditional generation in a training-free manner. 1", "sections": [{"title": "1 Introduction", "content": "Recent advancements in generative models, particularly diffusion models [61, 21, 62, 66], have demonstrated remarkable effectiveness across vision [65, 48, 52], small molecules [74, 73, 24], proteins [1, 72], audio [35, 29], 3D objects [40, 41], and many more. Diffusion models estimate the gradient of log density (i.e., Stein score, [67]) of the data distribution [65] via denoising learning objectives, and can generate new samples via an iterative denoising process. With impressive scalability to billions of data [58], future diffusion models have the potential to serve as foundational generative models across a wide range of applications. Consequently, the problem of conditional generation based on these models, i.e., tailoring outputs to satisfy user-defined criteria such as labels, attributes, energies, and spatial-temporal information, is becoming increasingly important [63, 2]. Conditional generation methods like classifier-based guidance [66, 7] and classifier-free guidance [23] typically require training a specialized model for each conditioning signal (e.g., a noise-conditional classifier or a text-conditional denoiser). This resource-intensive and time-consuming process greatly limits their applicability. In contrast, training-free guidance aims to generate samples that align with certain targets specified through an off-the-shelf differentiable target predictor without involving any additional training. Here, a target predictor can be any classifier, loss function, probability function, or energy function used to score the quality of the generated samples. In classifier-based guidance [66, 7], where a noise-conditional classifier is specifically trained to predict the target property on both clean and noisy samples, incorporating guidance in the diffusion"}, {"title": "2 Background", "content": "Generative diffusion model. A generative diffusion model is a neural network that can be used to sample from an unconditional distribution \\(p_0(x)\\) with the support on any continuous sample space \\(\\mathcal{X}\\) [21, 62, 64, 27]. For instance, \\(\\mathcal{X}\\) could be \\([-1,1]^{d\\times d\\times 3}\\) representing the RGB colors of \\(d \\times d\\) images [4, 22], or \\(\\mathbb{R}^{3d}\\) representing the 3D coordinates of molecules with \\(d\\) atoms [24, 74, 73]. Given a data \\(x\\) sampled from \\(p_0(x)\\), a time step \\(t \\in [T] \\cong \\{1,\\ldots,T\\}\\), a corresponding noisy datapoint is constructed as \\(x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1-\\bar{\\alpha}_t} \\epsilon\\) where \\(\\epsilon \\sim \\mathcal{N}(0, I)\\) and \\(\\{\\bar{\\alpha}_t\\}_{t=1}^T\\) is a set of pre-defined monotonically decreasing parameters used to control the noise level. Following [21], we further define \\(\\alpha_t = \\bar{\\alpha}_t / \\bar{\\alpha}_{t-1}\\) for \\(t>1\\) and \\(\\alpha_1 = \\bar{\\alpha}_1\\). The diffusion model \\(\\epsilon_{\\theta} : \\mathcal{X} \\times [T] \\rightarrow \\mathcal{X}\\) parameterized by \\(\\theta\\) is trained to predict the noise \\(\\epsilon\\) that was added on \\(x_t\\) with p.d.f \\(p_t(x_t) = \\int_{x_0} p_0(x_0) p_{t|0}(x_t|x_0) dx_0^2\\). In theory, this corresponds to learning the score of \\(p_t(x)\\) [65], i.e.,\n\\[\\underset{\\theta}{\\text{arg min }} \\sum_{t=1}^T \\mathbb{E}_{x_0\\sim p_0(x_0),\\epsilon \\sim \\mathcal{N}(0,I)} ||\\epsilon_{\\theta}(x_t, t) - \\epsilon||^2 = -\\sqrt{1-\\bar{\\alpha}_t} \\nabla_{x_t} \\log p_t.\\]\nFor sampling, we start from \\(x_T \\sim \\mathcal{N}(0, I)\\) and gradually sample \\(x_{t-1} \\sim p_{t-1|t}(x_{t-1}|x_t)\\). This conditional probability is not directly computable, and in practice, DDIM [62] samples \\(x_{t-1}\\) via\n\\[x_{t-1} = \\sqrt{\\bar{\\alpha}_{t-1}} x_{0|t} + \\sqrt{1 - \\bar{\\alpha}_{t-1} - \\sigma_t^2} \\frac{x_t - \\sqrt{1-\\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}} + \\sigma_t \\epsilon,\\]\nwhere \\(\\{\\sigma_t\\}_{t=1}^T\\) are DDIM parameters, \\(\\epsilon \\sim \\mathcal{N}(0, I)\\), and\n\\[x_{0|t} = \\frac{x_t - \\sqrt{1-\\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}}\\]\nis the predicted sample given \\(x_t\\). According to the Tweedie's formula [11, 51], \\(x_{0|t}\\) equals to the conditional expectation \\(\\mathbb{E}[x_0|x_t]\\) under perfect optimization of \\(\\epsilon_{\\theta}\\) in Equation (1). It has been theoretically established that the above sampling process results in \\(x_0 \\sim p_0(x)\\) under certain assumptions.\nTarget predictor. For a user required target \\(c\\), we use a predictor \\(f_c(x) : \\mathcal{X} \\rightarrow \\mathbb{R}^+ \\cup \\{0\\}\\) to represent how well a sample \\(x\\) is aligned with the target (higher the better). Here \\(f_c(x)\\) can be a conditional probability \\(p_0(c|x)\\) for a label \\(c\\) [62, 14], a Boltzmann distribution \\(\\exp -e_c(x)\\) for any pre-defined energy function \\(e_c\\) [31, 63, 38], the similarity of two features [47], or even their combinations. The goal is to samples from the conditional distribution\n\\[p_0(x|c) = \\frac{p_0(x)f(x)}{\\int p_0(x) f(x) dx}.\\]"}, {"title": "2.1 Existing algorithms", "content": "Most existing methods take advantage of the predicted sample \\(x_{0|t}\\) defined in Equation (3) and use the gradient of \\(f(x)\\) for guidance. We review and summarize five existing approaches below, and provide a schematic and a copy of pseudo-code in Appendix B for the sake of reference. Due to the variety in underlying intuitions and implementations, coupled with a lack of quantitative comparisons among these methods, it is challenging to discern which operations are crucial and which are superfluous, a problem we address in Section 3.\nDPS [6] was initially proposed to solve general noisy inverse problems for image generation: for a given condition \\(y\\) and a transformation operator \\(A\\), we aim to generate image \\(x\\) such that \\(||A(x)-y||_2\\) is small. For instance, in super-resolution task [71], the operator \\(A\\) is a down-sampling operator, and \\(y\\) is a low-resolution image. DPS replaces \\(\\nabla \\log f(x_t, t)\\) in Equation (5) by \\(\\nabla_{x_t} \\log f(x_{0|t})\\). As suggested in [63], this corresponds to a point estimation of the conditional density \\(p_{0|t}(x_0|X_t)\\).\nLGD [63] replaces the point estimation in DPS and proposes to estimate \\(f (x_t, t)\\) with a Gaussian kernel \\(\\mathbb{E}_{x \\sim \\mathcal{N}(x_{0|t}, \\sigma_{\\gamma}I)} f (x, t)\\), where the expectation is computed using Monte-Carlo sampling [59].\nFreeDoM [78] generalizes DPS by introducing a \u201crecurrent strategy\" (called \u201ctime-travel strategy\" [39, 10, 70]) that iteratively denoises \\(x_{t-1}\\) from \\(x_t\\) and adds noise to \\(x_{t-1}\\) to regenerate \\(x_t\\) back and forth. This strategy empirically enhances the strength of the guidance at the cost of additional computation. FreeDoM also points out the importance of altering guidance strength at different time steps \\(t\\), but a comprehensive study on which schedule is better is not provided.\nMPGD [18] is proposed for manifold preserving tasks, e.g., the target predictor is supposed to generate samples on a given manifold. It computes the gradient of \\(\\log f (x_0|t)\\) to \\(x_{0|t}\\) instead of \\(x_t\\), i.e., \\(\\nabla_{x_{0|t}} \\log f(x_0|t)\\) to avoid the back-propagation through the diffusion model \\(\\epsilon_{\\theta}\\) that is highly inefficient. This strategy is effective in manifold-preserving problems, but whether it can be generalized to general training-free problems is unclear. In addition to the computation difference, theoretical understanding on the difference between gradients to \\(x_0|t\\) and \\(x_t\\) is missing.\nUGD [2] builds on FreeDoM, with the difference that it additionally solves a backward optimization problem \\(\\triangle_t = \\underset{\\triangle}{\\text{arg max}} f(x_{0|t}+ \\triangle)\\) and guides \\(x_{0|t}\\) and \\(x_t\\) simultaneously. UGD also implements the \u201crecurrent strategy\" to further improve generation quality."}, {"title": "3 TFG: A Unified Framework for Training-free Guidance", "content": "Despite the array of algorithms available and their reported successes in various applications, we conduct a case study on CIFAR10 [30] to illustrate the challenging nature of training-free guidance and the insufficiency of existing methods. Specifically, for each of the ten labels, we use the pretrained diffusion model and classifiers from [7, 9] to generate 2048 samples, where the hyper-parameters are selected via a grid search for the fairness of comparison. We compute the FID and the label accuracy evaluated by another classifier [20] and present results in Figure 1. Even in such a relatively simple setting, all training-free approaches significantly underperform training-based guidance, with a significant portion of generated images being highly unnatural (when guidance is strong) or irrelevant to the label (when guidance is weak). These findings reveal the fundamental challenges and highlight the necessity of a comprehensive study. Unfortunately, comparisons and analyses of existing approaches are missing or primarily qualitative, limiting deeper investigation in this field."}, {"title": "3.1 Unification and extension", "content": "This sections introduces our unified framework for training-free guidance (TFG, Algorithm 1) and formally defines its design space in Definition 3.1. We demonstrate the advantage of TFG by drawing connections between TFG and other algorithms to show that existing algorithms are encompassed as special cases. Based on this, all comparisons and studies of training-free algorithms automatically become the study within the hyper-parameter space of our framework. This allows us to analyze the techniques theoretically and empirically, and choose an appropriate hyper-parameter for a specific downstream task efficiently and effectively."}, {"title": "3.2 Algorithm and design space analysis", "content": "We now present a concrete analysis of TFG and its design space H in detail. Similar to standard classifier-based guidance, TFG guides \\(x_t\\) at each denoising step \\(t\\). To provide appropriate and informative guidance, TFG essentially leverages four techniques for guidance: Mean Guidance (Line 8) controlled by \\(N_{iter}, \\mu\\), Variance Guidance (Line 7) controlled by \\(\\rho\\), Implicit Dynamic (Line 4) controlled by \\(\\gamma\\), and Recurrence (Line 5) controlled by \\(N_{recur}\\).\nMean Guidance computes the gradient of \\(f(x)\\) to \\(x_{0|t}\\) and is the most straightforward approach. However, this method can yield inaccurate guidance. To show this, notice that under perfect optimization we have \\(x_{0|t} = \\mathbb{E}[x_0|x_t]\\), and when \\(p_0(\\mathbb{E}[x_0|x_t])\\) is close to zero, the predictor has rarely been trained on data from the region close to \\(x_{0|t}\\), making the gradient unstable and noisy. To mitigate this, one can iteratively add gradients of \\(f(x)\\) to \\(x_{0|t}\\), encouraging \\(x_{0|t}\\) to escape low-probability regions.\nVariance Guidance provides an alternative approach for improving the gradient estimation. The reason why we dub it variance guidance might be ambiguous, as the only difference is that the gradient is taken with respect to \\(x_t\\) (Line 7) instead of \\(x_{0|t}\\) (Line 8). The lemma below demonstrates that this essentially corresponds to a covariance re-scaled guidance.\nLemma 3.3. If the model is optimized perfectly, i.e., \\(\\epsilon_{\\theta}(x,t) = -\\sqrt{1-\\bar{\\alpha}_t} \\nabla \\log p_t(x)\\), we have\n\\[\\triangle_t = \\frac{\\sqrt{\\bar{\\alpha}_t}}{1-\\bar{\\alpha}_t} S_{0|t} \\nabla x_{0|t} f(x_{0|t}),\\]\nwhere \\(S_{0|t} = \\int x_0 p_{0|t}(x|x_t) (x - \\mathbb{E}[x_0|x_t])(x - \\mathbb{E}[x_0|x_t])^T dx\\) is the covariance of \\(x_0|x_t\\).\nLemma 3.3 suggests that variance guidance refines mean guidance by incorporating the second-order information of \\(x_{0|xt}\\), specifically considering the correlation among components within \\(x_{0|t}\\). Consequently, positively correlated components could have guidance mutually reinforced, while negatively correlated components could have guidance canceled. This also implies that mean guidance and variance guidance are intrinsically leveraging different orders of information for guidance. In TFG, variance guidance is controlled by \\(\\rho_t\\).\nImplicit Dynamic transforms the predictor \\(f\\) into its convolution via a Gaussian kernel \\(\\mathcal{N}(0,\\gamma (1-\\bar{\\alpha}_t)I)\\). This operation is initially introduced by LGD [63] to estimate \\(p_{0|t}(x_0|x_t)\\). However, it is unclear why the form is pre-selected as a Gaussian distribution. We argue that this technique is effective because it creates an implicit dynamic on \\(x_{0|t}\\). Specifically, starting from \\(x_{0|t}\\), it iteratively adds noise to \\(x_{0|t}\\), evaluates gradient, and moves \\(x_{0|t}\\) based on the gradient. The repeating process converges to the density proportional to \\(f(x)\\) when \\(N_{iter}\\) goes to infinity, driving \\(x_{0|t}\\) to high-density regions. This explanation is"}, {"title": "4 Design Space of TFG: Analysis and Searching Strategy", "content": "Admittedly, a more extensive design space only yields a better performance if an effective and robust hyper-parameter searching strategy can be applied. For example, arbitrarily complex neural networks are guaranteed to have better optimal performance than simple linear models, but finding the correct model parameters is significantly more difficult. This section dives into this core problem by comprehensively analyzing the hyper-parameter space structure of HTFG, and further proposing a general searching algorithm applicable for any general downstream tasks.\nThe hyper-parameters of HTFG can be categorized into two parts: time-dependent vectors \\(\\rho, \\mu\\), and time-independent sacalars \\(N_{recur}, N_{iter}, \\gamma\\). While a grid search can potentially result in the best performance, performing such an extensive search in HTFG is highly impractical, especially considering the vector parameters \\(\\rho, \\mu\\). Fortunately, below we demonstrate that, if we decompose \\(\\rho\\) into \\(\\rho s_{\\rho}(t)\\) (same for \\(\\mu\\)) where \\(\\rho\\) is a scalar and \\(s_{\\rho}(t)\\) is a \u201cstructure\" (a non-negative function) such that \\(\\Sigma_{t=1}^T s_{\\rho}(t) = T\\), then some structures are consistently better than others regardless of the other hyper-parameters. This allows us to pre-locate an appropriate structure for the given task and efficiently optimize the rest of the scalar hyper-parameters. Our analysis is conducted on the label guidance task on CIFAR-10 [30] and ImageNet [55], with experimental settings identical to Section 3.\nStructure analysis. Motivated by the default structure selected in UGD and LGD, we consider three structures for both \\(s_{\\rho}(t)\\) and \\(s_{\\mu}(t)\\) as\n\\[s(t) = \\frac{\\sum_{\\tau = 1}^t \\alpha_{\\tau}}{\\sum_{t=1}^T \\alpha_t} (increase), s(t) = \\frac{\\sum_{\\tau=t}^T (1 - \\alpha_{\\tau})}{\\sum_{\\tau=1}^T(1 - \\alpha_{\\tau})} (decrease), s(t) = 1 (constant).\\]\nThese structures are selected to be qualitatively different, while each is justified to be reasonable under certain conditions [18, 78, 2]. We leave the study of more structures to future works. The rest of the parameters are grid-searched for the comprehensiveness of the analysis. For \\(s_{\\rho}(t)\\), we set \\(N_{recur} = \\{1,2,4\\}\\) and \\(\\rho = \\{0.25, 0.5, 1.0, 2.0, 4.0\\}\\); and for \\(s_{\\mu}(t)\\), we set \\(N_{iter} = \\{1,2,4\\}\\) and \\(\\mu = \\{0.25, 0.5, 1.0, 2.0, 4.0\\}\\). We run label guidance for each configuration and each of the ten labels on CIFAR10 (four labels on ImageNet, due to computation constraints).\nAs presented in Figure 2, the relationship between different structures remains unchanged when the rest of the parameters vary. For instance, on both datasets, the Validity-FID performance curves consistently move top-left (implying a better performance) when we switch from \"decrease\" structure (red lines) to \"constant\" structure (yellow lines) to \"increase\" structure (blue lines) for both \\(\\rho, \\mu\\) and different values of \\(N_{recur}\\) and \\(N_{iter}\\). This invariant relationship is essential as it allows for an efficient hyper-parameters search in HTFG by first determining appropriate structures for \\(s_{\\rho}(t), s_{\\mu}(t)\\) under a simple subspace, and then selecting the rest scalar parameters."}, {"title": "A The Motivation of Studying Training-free Guidance", "content": "In this section, we argue that training-free guidance using off-the-shelf models is a crucial and timely research problem deserving more attention and effort. We begin by providing an illustrative analysis that highlights the limitations of current strong text-to-image generative models, underscoring the necessity for training-free guidance. Furthermore, we assert that training-free guidance remains a significant challenge, with previous literature underestimating its complexity. Given its necessity and inherent difficulties, we call for increased focus from the research community on this problem and offer our benchmarks and code base to help accelerate progress in this area."}, {"title": "A.1 Failure case of image generation with GPT4", "content": "It's hard for GPT4 to understand targets. In Figure 4, we ask GPT-4 to generate a molecule with polarizability a = 3, which is a task we use to evaluate training-free guidance (refer to Figure 16 for visualization). We found that the GPT-4 generated molecule is apparently invalid and unrealistic: the generated molecule contains many carbon atoms with more than 4 bonds (the maximum allowed number is 4); and the generated molecule is apparently not a benzene which is claimed by the text outputs. From this case we may understand that it is hard to follow diverse user-defined instructions for the foundational generative models, where the user-defined targets may be subtle, fine-grained, combinatorial, and open-ended."}, {"title": "A.2 The fundamental challenge of training-free guidance", "content": "Despite the array of algorithms available and their reported successes in various applications, we conduct a case study on CIFAR10 [30] to illustrate the challenging nature of training-free guidance and the insufficiency of existing methods. Specifically, we compare the training-based approach and training-free approach for the label guidance task on CIFAR10, with the diffusion model pretrained by [7], the training-based time-dependent classifier f(x, t) by [7], and the training-free standard label classifier f (x) pretrained only on clean CIFAR10 by [9]. and a \u201cfake\u201d training-free classifier defined as \\(f(x,t)|_{t=0}\\). The first serves as the oracle benchmark, while the second corresponds to the standard training-free guidance. The third setting, as considered in LGD [63], uses a \u201cfake\u201d training-free classifier since its parameters are shared across different time steps t during training, resulting in an implicit regularization that is not available for practical predictors. This setting serves as a comparison to help identify the difficulty of training-free guidance.\nQuantitative and qualitative results are shown in Figure 6. All training-free approaches significantly under-perform training-based guidance, with a significant portion of generated images being highly unnatural (when guidance is strong) or irrelevant to the label (when guidance is weak). A more clear illustration on this can be found in Figure 7. In terms of \"fake\" classifiers, it leads to a remarkable difference from real training-free classifiers even under identical experimental settings. It generates"}, {"title": "B Pseudo-code and schematics", "content": "We have presented the pseudo-code of TFG in Algorithm 1. Below, we provide a copy of the DPS (Algorithm 2), MPGD (Algorithm 3), FreeDoM (Algorithm 4), UGD (Algorithm 5), and LGD (Algorithm 6). Notice that LGD does not provide a pseudo-code, and we present their algorithm following their paper as a modification of DPS. We do not change the original algorithms' notations for reference. Please see the proof in Appendix C for the equivalence analysis. We provide a schematic of existing algorithms in Figure 8."}, {"title": "C Proofs", "content": "We prove Theorem 3.2 and Lemma 3.3 below."}, {"title": "C.1 Proof of Theorem 3.2", "content": "Proof. For each algorithm, we prove the equivalence of design space separately below. Notice that when \\(\\gamma = 0\\), \\(f\\) degrades back to \\(f\\).\nMPGD (Algorithm 3). Below we demonstrate that any hyper-parameter \\(\\{c_t\\}_{t=1}^T\\) in Algorithm 3 is equivalent to the TFG with \\(f(x_{0|t}) = \\exp\\{-\\mathcal{L}(x_{0|t}; y)\\} \\) and hyper-parameter\n\\[N_{recur} = 1, N_{iter} = 1, \\gamma= 0, \\rho= 0, \\mu = (c_1, \\ldots, c_T)^T.\\]\nTo show this, notice that since both \\(\\rho\\) and \\(\\gamma\\) are zero, Line 4 and Line 7 take no effect. When using the identical sampling function (Line 9), TFG generates \\(x_{t-1}\\) using\n\\[x_{t-1} = Sample(x_t, x_{0|t}, t) + c_t\\sqrt{\\alpha_{t-1}}\\nabla_{x_{0|t}} \\log f(x_{0|t})\\]\n\\[ = \\sqrt{\\alpha_{t-1}}x_{0|t} + \\sqrt{1 - \\bar{\\alpha}_{t-1} - \\sigma_t^2} \\frac{x_t - \\sqrt{1-\\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}} + \\sigma_t \\epsilon + c_t\\sqrt{\\alpha_{t-1}}\\nabla_{x_{0|t}} \\log f(x_{0|t})\\]\n\\[ = \\sqrt{\\alpha_{t-1}}(x_{0|t} - c_t\\nabla_{x_{0|t}} \\mathcal{L}(x_{0|t}; y)) + \\sqrt{1 - \\bar{\\alpha}_{t-1} - \\sigma_t^2} \\epsilon_{\\theta}(x_t, t) + \\sigma_t \\epsilon,\\]\nwhich is exactly the formula used in MPGD.\nDPS (Algorithm 2) and FreeDoM (Algorithm 4). We prove both algorithms together as DPS is a special case of FreeDoM (without recurrence). Specifically, any hyper-parameter \\(\\{\\rho_t\\}_{t=1}^T\\), time travel step \\(r\\) and distance function \\(D(c, \\cdot)\\) in Algorithm 4 is equivalent to TFG with \\(f(x_{0|t}) = \\exp\\{-\\mathcal{D}(c, x_{0|t})\\}\\) and hyper-parameter\n\\[N_{recur} = r, N_{iter} = 0, \\gamma= 0, \\rho = (\\sqrt{\\alpha_1}\\rho_1,\\ldots, \\sqrt{\\alpha_T}\\rho_T), \\mu = 0.\\]\nTo show this, notice that both algorithms have the identical resampling step from \\(x_{t-1}\\) to \\(x_t\\), so it suffices to prove that the formula to generate \\(x_{t-1}\\) in each recurrent step is the same. For FreeDoM, we have\n\\[x_{t-1} = Sample(x_t, x_{0|t}, t) - \\rho_t \\nabla_{x_t} \\mathcal{D}(c, x_{0|t})\\]\n\\[= Sample(x_t, x_{0|t}, t) - (\\sqrt{\\alpha_t}\\rho_t) \\nabla_{x_t} \\log f(x_{0|t})/\\sqrt{\\alpha_t},\\]\nand the last line equals the combination of Line 7 and Line 7 in TFG.\nLGD (Algorithm 6). Any hyper-parameter \\(\\{\\zeta_t\\}_{t=1}^T\\), \\(\\eta\\) in LGD is equivalent to TFG with \\(f(x) = \\exp\\{-|y(x)\\} \\), sample size \\(\\eta\\) in Line 4, and hyper-parameter\n\\[N_{recur} = 1, N_{iter} = 0, \\gamma = 1, \\rho = 0, \\mu = (\\zeta_1,\\ldots, \\zeta_T)^T.\\]\nNotice that \\(\\alpha_t\\) in TFG equals 1/(1 + \\(\\sigma_t\\)) in the DPS algorithm. With this, the equivalence is clear from the pseudo-code of both algorithms.\nUGD (Algorithm 5). Any hyper-parameter \\(k\\), \\(m\\), \\(s(t)\\) in UGD is equivalent to TFG with \\(f(x) = \\exp\\{-l(c, f(x))\\}\\) and hyper-parameter\n\\[N_{recur} = k, N_{iter} = m, \\gamma = 0,\\]\n\\[\\rho = (-\\sqrt{\\alpha_1}s(1)\\delta_1,\\ldots, -\\sqrt{\\alpha_T}s(T)\\delta_T), \\mu = (-\\sqrt{\\frac{\\alpha_1}{1-\\alpha_1}} \\delta_1,\\ldots, -\\sqrt{\\frac{\\alpha_T}{1-\\alpha_T}} \\delta_T)^T,\\]\nwhere \\(\\delta_t\\) is the coefficient of \\(\\epsilon_{\\theta}(x_t, t)\\) in sampler \\(S\\) in the UGD algorithm (which is negative). To show this, notice that \\(\\triangle_t = \\rho_t \\nabla_{x_t} \\log f (x_{0|t}) = -\\rho_t\\nabla_{x_t}l(c, f(x_{0|t})) = \\sqrt{\\alpha_t}s(t)\\delta_t \\nabla_{x_t}l(c, f(x_{0|t}))\\). By replacing this into Line 9, the equivalence of guidance Variance Guidance can be easily observed. A similar deduction can be made for the mean guidance as well."}, {"title": "C.2 Proof of Lemma 3.3", "content": "Proof. Recall that \\(x_{0|t} = \\frac{x_t - \\sqrt{1-\\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}}\\. According to a simple chain rule, we have\n\\[\\triangle_t = \\rho_t \\nabla_{x_t} \\log f (x_{0|t})\\)\\]\n\\[ = \\frac{\\rho_t \\sqrt{\\bar{\\alpha}_t}}{I - \\sqrt{1 - \\bar{\\alpha}_t} \\nabla_{x_t}}\\epsilon_{\\theta}(x_t, t)} \\nabla_{x_{0|t}} \\log f(x_{0|t}).\\]\nThe perfect optimization assumption implies the relationship between \\(\\epsilon_{\\theta}\\) and the score of \\(p_t(x_t)\\), which we leverage and obtain\n\\[\\triangle_t = \\frac{\\rho_t\\sqrt{\\bar{\\alpha}_t}}{I - \\sqrt{1 - \\bar{\\alpha}_t} \\nabla_{x_t}}\\epsilon_{\\theta}(x_t, t)} \\nabla_{x_{0|t}} \\log f(x_{0|t}),\\]\n\\[ = \\rho_t \\frac{I+ (1-\\bar{\\alpha}_t)\\nabla_{x_t}}\\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}} \\nabla_{x_{0|t}} \\log f (x_{0|t})\\]\nThus, it remains to draw a connection between the conditional covariance between \\(\\Sigma_{0|t}\\) and \\(\\nabla^2 \\log p_t(x_t)\\). Omit the subscript \\(x_t\\) in \\(\\nabla_{x_t}\\), we have\n\\[\\nabla^2 \\log p_t(x_t) = \\frac{\\nabla^2 p_t(x_t)}{p_t(x_t)} = \\frac{\\nabla_x log p_t (x_t) (\\nabla \\log p_t(x_t))^T}{\\sqrt{\\bar{\\alpha}_t}}\\]"}, {"title": "D Task details", "content": ""}, {"title": "D.1 Gaussian Deblur", "content": "In computer vision", "33": ".", "A_{blur}": "x \\rightarrow y\\)", "that": "n\\[\\underset{x_0}{\\text{max }} p(x) = \\underset{x_0}{\\text{max }} exp(-\\|A_{blur}(x_0) - y\\|_2),\\"}]}