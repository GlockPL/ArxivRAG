{"title": "A Novel Unified Parametric Assumption for Nonconvex Optimization", "authors": ["Artem Riabinin", "Ahmed Khaled", "Peter Richt\u00e1rik"], "abstract": "Nonconvex optimization is central to modern machine learning, but the general framework of nonconvex optimization yields weak convergence guarantees that are too pessimistic compared to practice. On the other hand, while convexity enables efficient optimization, it is of limited applicability to many practical problems. To bridge this gap and better understand the practical success of optimization algorithms in nonconvex settings, we introduce a novel unified parametric assumption. Our assumption is general enough to encompass a broad class of nonconvex functions while also being specific enough to enable the derivation of a unified convergence theorem for gradient-based methods. Notably, by tuning the parameters of our assumption, we demonstrate its versatility in recovering several existing function classes as special cases and in identifying functions amenable to efficient optimization. We derive our convergence theorem for both deterministic and stochastic optimization, and conduct experiments to verify that our assumption can hold practically over optimization trajectories.", "sections": [{"title": "1. Introduction", "content": "There is a large disconnect between the theory and practice of nonconvex optimization with first-order methods. The theory for nonconvex optimization allows us only to guarantee convergence to a stationary point, or at most, a higher-order stationary point (Carmon et al., 2017a;b). In practice, neural scaling laws show smooth decreases in the loss function value as the number of training steps increases (Kaplan et al., 2020). In contrast, convex optimization theory typically allows us to derive tight guarantees on the function value (Nesterov, 2018), but is too restrictive to apply to nonconvex models directly. This discrepancy has motivated researchers to develop intermediate theoretical frameworks that allow us to obtain stronger convergence guarantees without losing too much applicability. These developments include star convexity (Nesterov & Polyak, 2006), quasiconvexity (Hardt et al., 2016; Bu & Mesbahi, 2020), the Polyak-\u0141ojasiewicz (PL) condition (Polyak, 1963; Liu et al., 2022), Aiming (Liu et al., 2023), and the \u03b1-\u03b2 conditions (Islamov et al., 2024).\nProblem statement. We are primarily concerned with the minimization problem\n$\\min_{x \\in \\mathbb{R}^d} f(x)$,\nwhere $f(x) : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ is a differentiable objective function. We focus on variants of gradient descent of the form\n$x^{k+1} = x^k \u2013 \\gamma_k \\nabla f (x^k)$,\nwhere $\\gamma_k > 0$ is a stepsize, and $\\nabla f(x^k)$ represents the gradient of the function f at the current point $x^k$. Our analysis also extends to stochastic gradient descent.\nA novel unified assumption. We build on this line of work by introducing a new assumption that allows us to obtain convergence guarantees for nonconvex optimization. Our unified framework is broadly applicable- it subsumes prior assumptions on nonconvex optimization and allows for unified analysis of convex and nonconvex objectives. The main idea of our framework is that even in complex nonconvex landscapes, effective optimization algorithms rely on the gradient possessing a degree of directional alignment towards the set of solutions. To formalize this, we first make the assumption that a set of solutions exists.\nAssumption 1.1. The function f is continuously differentiable and has a nonempty set $S \\subseteq \\mathbb{R}^d$ of global minimizers. Let $f^*$ denote the minimum value of the function f.\nWe now introduce our main assumption, an inequality that relates the gradient at any point x to its projection onto a subset S of optimal solutions, using a progress function $P(x; S)$ to quantify proximity to this set.\nAssumption 1.2. There exists constants $c_1 > 0$ and $C_2 \\geq 0$ such that for all $x \\in \\mathbb{R}^d$,\n$\\langle \\nabla f (x), x \u2013 \\text{proj}_{S}(x) \\rangle \\geq c_1 P(x; S) \u2013 C_2$,"}, {"title": "1.1. Brief literature review", "content": "The challenge of bridging the gap between theory and practice in nonconvex optimization has spurred significant research into developing more refined analytical frameworks. Classical convex optimization theory provides strong convergence guarantees, but its assumptions are often too restrictive for modern machine learning. Conversely, standard nonconvex optimization results guarantee convergence to stationary points and do not reflect the empirical success of first-order methods in deep learning. Convexity can be seen as controlling the lower curvature of a function while smoothness controls the upper curvature. The literature has explored generalizations and alternatives to both.\nAlternatives to convexity. The Polyak-\u0141ojasiewicz (PL) condition (Polyak, 1963; Liu et al., 2022) is a prominent example that relates the function value to the gradient norm, provides a lower bound on the function growth, and ensures linear convergence under certain conditions. Quasiconvexity (Hardt et al., 2016) and star-convexity (Nesterov & Polyak, 2006) represent other relaxations of convexity that have been studied in optimization. More recently, conditions like the Aiming property (Liu et al., 2023) and the \u03b1-\u03b2 conditions (Islamov et al., 2024) have emerged as tools to characterize the loss landscapes of neural networks and analyze the convergence of optimization algorithms in these settings.\nAlternatives to smoothness. Recent work has explored alternatives to smoothness that may more accurately describe neural network optimization, e.g. generalized smoothness (Zhang et al., 2020a; Xie et al., 2024), directional sharpness or smoothness (Pan & Li, 2022; Mishkin et al., 2024), and local smoothness (Berahas et al., 2023).\nAssumptions on the stochastic gradients. Another line of work has considered the various properties of the stochastic gradient noise, and its effect on the convergence of gradient-based methods, see e.g. (Khaled & Richt\u00e1rik, 2020; Faw et al., 2022; Zhang et al., 2020b). Our work is primarily aimed at relaxing convexity and is therefore orthogonal to these results."}, {"title": "2. Main Theory & Results", "content": "In this section, we first discuss further Assumption 1.2 and its implications, then present our convergence theory for gradient descent under this assumption, followed by stochastic gradient descent.\n2.1. Discussion of Assumption 1.2\nTo analyze Assumption 1.2, we start by considering the simpler setting $c_2 = 0$. In this case, Assumption 1.2 takes the form\n$\\langle \\nabla f(x),x - \\text{proj}_{S}(x) \\rangle \\geq c_1 P(x; S) \\geq 0 \\text{ for all } x \\in \\mathbb{R}^d$.\nThis means that the negative gradient $-\\nabla f(x)$ points toward S in the sense that $-\\nabla f(x)$ is nontrivially correlated with the direction $\\text{proj}_{S}(x) - x$. The term $c_1 P(x; S)$ can tighten or relax this correlation depending on the choices of $c_1$ and $P(x; S)$, leading to narrower or wider classes of functions. Introducing $C_2$ relaxes the correlation, possibly allowing the inner product to be negative at certain points.\nNow, consider the case where $x \\in \\mathbb{R}^d$ is a stationary point of f, i.e., $\\nabla f(x) = 0$. From Assumption 1.2 we have that $P(x; S) \\leq \\frac{C_2}{c_1}$. This implies, in terms of the measure $P(x; S)$, the stationary point x is not too far from the set S.\nA specific, natural choice for the progress function in Assumption 1.2 is $P(x; S) = f(x) \u2013 f^*$, as an example. We define the constants $c_1 = 1$, $C_2 = 0$, and set $S = \\{x^*\\}$, $x^* \\in S$. With these choices, Assumption 1.2 becomes\n$\\langle \\nabla f(x), x - x^* \\rangle \\geq f(x) - f^* \\text{ for all } x \\in \\mathbb{R}^d$,\nwhich is a simple consequence of the convexity of f from standard convex analysis.\nFor additional examples of various classes of functions derived from Assumption 1.2 that yield meaningful convergence results, please refer to Section 2.2.1 and 2.4, where by adjusting the parameters of Assumption 1.2, we can recover many well-known function classes as special cases, including convex, strongly convex, weak quasi-convex functions"}, {"title": "2.2. Main Convergence Theorem", "content": "In this section, we examine the convergence guarantees we can obtain under the proposed Assumption 1.2.\nTheorem 2.1. Let Assumptions 1.1 and 1.2 be satisfied. Further assume that the stepsize $\\gamma_k$ satisfies the relations\n$0 < \\gamma_k \\leq (2-a) \\frac{\\langle \\nabla f (x^k), x^k - x \\rangle + C_2 + \\beta_k}{\\|\\nabla f (x^k) \\|^2}$\nthat holds for all $k \\geq 0$, where $0 < a < 2$, $\\beta_k > 0$, $x^* > 0$, $x_p := \\text{proj}_{S}(x)$. Then we have the following descent inequality that holds for all $k \\geq 0$\n$\\|x^{k+1} - x^{k+1}_p \\|^2 \\leq \\|x^{k} - x^{k}_p \\|^2 \u2013 a c_1 \\gamma_k P(x^k; S) + (2 \u2013 a) \\beta_k \\gamma_k + 2 C_2 \\gamma_k$,\nand\n$\\min_{k \\in \\{0,...,K\\}} P(x^k; S) \\leq \\frac{\\frac{\\|x^0 - x^* \\|^2}{a c_1}}{\\sum_{k=0}^K \\gamma_k} + \\frac{\\sum_{k=0}^K \\gamma_k (2-a) \\beta_k}{a c_1 \\sum_{k=0}^K \\gamma_k} + \\frac{2 C_2}{a c_1}$.\nwhere $C_K := \\frac{\\sum_{k=0}^K \\gamma_k (2-a) \\beta_k}{a c_1 \\sum_{k=0}^K \\gamma_k} + \\frac{2 C_2}{a c_1}$.\nTheorem 2.1 provides convergence guarantees for $P(x; \\Tilde{S})$ within a neighborhood $C_K$, given that the sum of the stepsizes, $\\sum_{k=0}^K \\gamma_k$, is sufficiently large. However, achieving a precise convergence rate to the neighborhood requires additional assumptions on $P(x; \\Tilde{S})$, the function f, or the stepsizes $\\gamma_k$.\nFor instance, under assumptions such as $P(x; \\Tilde{S}) = f(x) \u2013 f^*$ and smoothness (Corollary 2.2), bounded gradients (Corollary 2.3), or decreasing stepsizes (Corollary 2.4), we can establish convergence to a neighborhood within the framework of Theorem 2.1. However, the latter two results-bounded gradients and decreasing stepsizes-are only meaningful if $P(x; \\Tilde{S})$ satisfies certain regularity properties, which are discussed in detail in Section 2.2.1.\nCorollary 2.2. Under the assumptions of Theorem 2.1 with $P(x; \\Tilde{S}) = f(x) \u2013 f^*$, if we additionally assume that f is L-smooth, and choose $\\gamma_k = \\frac{c_1(f(x^k)-f^*)}{\\|\\nabla f(x^k)\\|^2}$, $a = 1$, $\\beta_k = 0$, then we obtain\n$\\min_{k \\in \\{0,...,K\\}} f(x^k) - f^* \\leq \\frac{\\frac{2L \\|x^0 - x^* \\|^2}{c_1}}{(K + 1)} + \\frac{2C_2}{c_1}$.\nNote that for $\\Tilde{S} = \\{x^*\\}$, $x^* \\in S$, $c_1 = 1$, $C_2 = 0$, Corollary 2.2 presents a well-known result from standard convex analysis for the Polyak stepsize (Polyak, 1987).\nCorollary 2.3. Under the assumptions of Theorem 2.1, if we additionally assume that f has bounded gradients, i.e., $\\|\\nabla f (x) \\| \\leq G$ for all $x \\in \\mathbb{R}^d$, and choose $\\gamma_k = \\frac{c_1P(x^k;S)+\\beta_k}{\\|\\nabla f (x^k) \\|^2}$, then we obtain\n$\\min_{k \\in \\{0,...,K\\}} P(x^k; S) \\leq \\frac{\\frac{G \\|x^0 - x_p\\|}{\\sqrt{(2 \u2013 a) a c_1}}}{\\sqrt{K + 1}} + \\frac{C_K}{\\sqrt{K + 1}}$,\nwhere $C_K := \\frac{\\sum_{k=0}^K \\gamma_k (2-a) \\beta_k}{a c_1 \\sum_{k=0}^K \\gamma_k} + \\frac{2C_2}{a c_1}$.\nCorollary 2.4. Under the assumptions of Theorem 2.1, if we additionally assume that $\\gamma_k < \\gamma_{k-1}$ for $k = 1, . . ., K$, then we obtain\n$\\min_{k \\in \\{0,...,K\\}} P(x^k; S) \\leq \\frac{\\frac{D^2_{\\text{max}}}{a c_1 \\gamma_K}}{(K + 1)} + \\Tilde{C}_K$\nwhere $\\Tilde{C}_K := \\frac{\\sum_{k=0}^K \\gamma_k (2-a) \\beta_k}{a c_1 \\sum_{k=0}^K \\gamma_k} + \\frac{2C_2}{a c_1}$ and $D^2_{\\text{max}} := \\max_{k \\in \\{0,...,K\\}} \\|x^k - x_p \\|^2$."}, {"title": "2.2.1. SPECIAL CASES", "content": "Let us consider some examples of stepsizes that satisfy Theorem 2.1 for a specific choice of $P(x; \\Tilde{S}) = f(x) \u2013 f^*$ and $S = \\{x^*\\}$, $x^* \\in S$. These results are summarized in Table 2. From the table, we observe that for various stepsizes of the Polyak type (Polyak, 1987; Loizou et al., 2021; Orvieto et al., 2022), convergence is achieved up to a neighborhood under the assumptions of Theorem 2.1, along with additional conditions such as the smoothness of the function f or the boundedness of its gradients, i.e., $\\|\\nabla f (x) \\| \\leq G$ for all $x \\in \\mathbb{R}^d$ (see Section C for details)."}, {"title": "2.3. Examples of function classes", "content": "Next, let us consider some choices of $P(x; S)$, $c_1$, and $C_2$ in Assumption 1.2 that describe specific classes of functions and lead to meaningful convergence results. Our first example is one we have already mentioned before.\nExample 1. Let $P(x; \\Tilde{S}) = f(x) - f^*$.\nNote that if $S = \\{x^*\\}$, $x^* \\in S$, $c_2 = 0$, then Assumption 1.2 is equivalent to the definition of $c_1$-weak quasiconvex functions (Hardt et al., 2016). If additionally $c_1 = 1$, then Assumption 1.2 follows from the convexity of the function f.\nConsider using the Polyak stepsize $\\gamma_k = \\frac{c_1 P(x^k;\\Tilde{S})}{\\|\\nabla f (x^k) \\|^2} = \\frac{c_1 (f(x^k) \u2013 f^*)}{\\|\\nabla f (x^k) \\|^2}$, with $a = 1$, and $\\beta_k = 0$. If we additionally assume that f is L-smooth, then from Corollary 2.2 we get\nthe following convergence result\n$\\min_{k \\in \\{0,...,K\\}} f(x^k) - f^* \\leq \\frac{\\frac{2L \\|x^0 -x^* \\|^2}{c_1}}{(K + 1)} + \\frac{2C_2}{c_1}$.\nIf $C_2 = 0$, then we obtain an $O(\\frac{1}{K})$ convergence rate for $\\min_{k \\in \\{0,...,K\\}} f(x^k) \u2013 f^*$ under Assumptions 1.1, 1.2, and the smoothness of f.\nIf, instead of the smoothness of f, we assume that f has bounded gradients, then from Corollary 2.3, we get the following convergence result\nIf $C_2 = 0$, then we obtain an $O(\\frac{1}{\\sqrt{K}})$ convergence rate for $\\min_{k \\in \\{0,...,K\\}} f(x^k) \u2013 f^*$ under Assumptions 1.1, 1.2, and the boundedness of the gradients of f.\nExample 2. Let $P(x; \\Tilde{S}) = f(x) - f^* + \\frac{\\mu}{2} \\|x - x_p\\|^2$, $\\mu > 0$.\nNote that if $\\Tilde{S} = \\{x^*\\}$, $x^* \\in S$, $C_2 = 0$, then Assumption 1.2 is equivalent to the definition of $\\mu$-strongly $c_1$-weak quasi-convex functions (Bu & Mesbahi, 2020). If additionally $c_1 = 1$, then Assumption 1.2 follows from the $\\mu$-strong convexity of the function f.\nLet us choose $\\gamma_k = \\frac{c_1 P(x^k;\\Tilde{S})}{\\|\\nabla f (x^k) \\|^2} = \\frac{c_1 (f(x^k) \u2013 f^* + \\frac{\\mu}{2} \\|x \u2013 x_p\\|^2)}{\\|\\nabla f (x^k) \\|^2}$. Then, by setting $a = 1$, $\\beta_k = 0$, $\\gamma^k$ satisfies the relations of Theorem 2.1\n$0 < \\gamma_k \\leq \\frac{\\langle \\nabla f(x^k), x^k - x \\rangle + C_2}{\\|\\nabla f (x^k) \\|^2} \\leq \\frac{c_1 P(x;\\Tilde{S})}{\\|\\nabla f (x^k) \\|^2}$.\nSimilar to the previous example, assuming that f is L-smooth, we can show that\n$\\min_{k \\in \\{0,...,K\\}} f(x^k) - f^* + \\frac{\\mu}{2} \\|x^k - x_p\\|^2 \\leq \\frac{\\frac{2L \\|x^0 - x_p\\|^2}{c_1}}{(K + 1)} + \\frac{2C_2}{c_1}$\nand assuming that f has bounded gradients, we get\n$\\min_{k \\in \\{0,...,K\\}} f(x^k) - f^* + \\frac{\\mu}{2} \\|x^k - x_p\\|^2 \\leq \\frac{\\frac{G \\|x^0 - x_p\\|}{c_1}}{\\sqrt{K + 1}} + \\frac{2C_2}{c_1}$.\nIf $C_2 = 0$, then we obtain an $O(\\frac{1}{K})$ convergence rate for $\\min_{k \\in \\{0,...,K\\}} f(x^k) - f^* + \\frac{\\mu}{2} \\|x^k - x_p\\|^2$ under Assumptions 1.1, 1.2, and the smoothness of f, and an $O(\\frac{1}{\\sqrt{K}})$\nconvergence rate for $\\min_{k \\in \\{0,...,K\\}} f(x^k) - f^* + \\frac{\\mu}{2} \\|x^k - x_p\\|^2$ under Assumptions 1.1, 1.2, and the boundedness of the gradients of f."}, {"title": "2.4. Extension to the stochastic setting", "content": "Problem formulation. In this subsection, we extend our results to the stochastic optimization problem\n$\\min_{x \\in \\mathbb{R}^d} \\{f(x) := \\mathbb{E}_{\\xi \\sim \\mathcal{D}} [f_\\xi(x)]\\}$,\nwhere $\\xi$ are samples from some distribution $\\mathcal{D}$. We consider the stochastic gradient method\n$x^{k+1} = x^k \u2013 \\gamma_k \\nabla f_\\xi (x^k)$,\nwhere $\\gamma_k > 0$ is a stepsize.\nAssumptions. To facilitate our convergence analysis, we make the following assumption on $f_\\xi$.\nAssumption 2.5. The function $f_\\xi$ is such that for all $x \\in \\mathbb{R}^d$ and some constants $c_{1\\xi} > 0$, $C_{2\\xi} \\geq 0$\n$\\langle \\nabla f_\\xi (x),x \u2013 \\text{proj}_{S}(x) \\rangle \\geq c_{1\\xi} P_\\xi(x; \\Tilde{S}) \u2013 C_{2\\xi}$,\nwhere $S \\subseteq \\Tilde{S}$, $\\Tilde{S} \\subseteq \\mathbb{R}^d$ is a set of global minimizers of f, $\\Tilde{S} \\neq \\emptyset$, $\\text{proj}_{S}(x) \\in \\arg \\min_{y \\in \\Tilde{S}} \\|x - y\\|^2$, and $P_\\xi(x; \\Tilde{S})$ is a nonnegative function of the argument $x \\in \\mathbb{R}^d$.\nTheorem 2.6. Let Assumptions 1.1 and 2.5 be satisfied. Further assume that the stepsize $\\gamma_k = \\min{\\{\\tilde{\\gamma}_k, \\gamma_b\\}}$, where $\\tilde{\\gamma}_k$ satisfies the relations\n$\\gamma_k \\leq \\tilde{\\gamma}_k \\leq (2-a) \\frac{\\langle \\nabla f_\\xi (x^k), x^k - x \\rangle + C_{2\\xi} + \\beta}{\\|\\nabla f_\\xi (x^k) \\|^2}$\nthat holds for all $k > 0$, where $0 < a < 2$, $\\beta > 0$, $x > 0$, $\\gamma_b > 0$, $x_p := \\text{proj}_{S}(x)$. Then we have the following descent inequality that holds for all $k \\geq 0$\n$\\|x^{k+1} - x^{k+1}_p \\|^2 \\leq \\|x^{k} - x^{k}_p \\|^2 \u2013 a \\gamma_k c_{1\\xi} P_\\xi(x^k; \\Tilde{S})\n+ (2 \u2013 a) \\gamma_k \\beta + 2\\gamma_k C_{2\\xi}$,\nand\n$\\min_{k \\in \\{0,...,K\\}} \\mathbb{E} [c_{1\\xi} P_\\xi(x^k; \\Tilde{S})] \\leq \\frac{\\mathbb{E} [\\frac{\\|x^0 - x^* \\|^2}{a \\gamma_{\\min}}]}{(K + 1)} + \\frac{C_{K_{\\text{stoc}}}}{a \\gamma_{\\min} (K + 1)}$\nwhere $C_{K_{\\text{stoc}}} := \\sum_{k=0}^K \\mathbb{E} [\\beta \\frac{(2-a) \\gamma_k}{\\gamma_{\\min}}] + 2 \\gamma_b C_{2\\xi}]$,\n$\\gamma_{\\min} := \\min{\\{\\tilde{\\gamma}_k, \\gamma_b\\}}$.\nCorollary 2.7. Under the assumptions of Theorem 2.6 with $P(x; S) = \\mathbb{E}_{\\xi}[f_\\xi(x) \u2013 f_\\xi(x_p)], c_{1\\xi} = c_1 > 0$, if we additionally assume that $f_\\xi$ are bounded from below, i.e, $f_\\xi := \\min_{x} f_\\xi(x) > 0$, $f_\\xi$ are L-smooth, and choose $\\gamma_k = \\frac{c_1(\\mathbb{E}_{\\xi}(x^k)-f_{\\xi})}{\\|\\nabla f_\\xi(x^k) \\|^2}$, $a = 1$, $\\beta = c_1(\\mathbb{E}_{\\xi}(x_p) - f_\\xi)$, then\nwe obtain\n$\\min_{k \\in \\{0,...,K\\}} \\mathbb{E}_{\\xi} [f(x) - f^*] \\leq \\frac{\\mathbb{E} [\\frac{\\|x - x_p\\|^2}{c_{1\\gamma_{\\min}}}]}{(K + 1)} + \\frac{\\sum_{k=0}^{K} \\mathbb{E} \\Big[C_2 \\xi \\Big]}{\\gamma_{\\min}} + \\frac{\\sigma^2}{\\gamma_{\\min}} + \\frac{\\sum_{k=0}^{K} \\gamma_k}{\\gamma_{\\min}c_{1}}$\nwhere $\\gamma_{\\min} := \\min\\{\\frac{c_1}{\\frac{2\\xi}{L}}, \\gamma_b\\}$, $\\sigma^2 := \\mathbb{E} [f_\\xi(x_p) \u2013 f_\\xi]^2$."}, {"title": "4. Impact Statement", "content": "Our contribution is primarily theoretical and we do not expect any negative impacts."}, {"title": "Appendix", "content": "A. Proofs from Section 2.1\nWe consider different examples of functions $f(x)$, $x \\in \\mathbb{R}$:\n$f_1 = x^2$,\n$f_2 = \\begin{cases}\nf_1, & x > -1 \\\\\n4\\sqrt{-x} \u2013 3, & x < -1\n\\end{cases}$,\n$f_3 = \\frac{x^4}{2} \u2013 x^2 + \\frac{1}{2}$,\n$f_4 = x^4 - \\frac{10}{3} x^3 + 3x^2$,\n$f_5 = \\begin{cases}\nf_4, & x \\geq 0 \\\\\nf_2, & x < 0\n\\end{cases}$,\nthat belong to a particular class of functions. We denote each class of function in Table 2 as $F_1, F_2, F_3, F_4, F_5,$ and $F_6$.\nAssumption 1.2 for $P(x, S) = f(x) \u2013 f^*$, where $f^* = 0$, $\\Tilde{S} \\subseteq S$, and for different choices of $(c_1, C_2, S)$. Here, $S \\subset \\mathbb{R}$ is a set of global minimizers of f, $x^* \\in S$.\n1.  Obviously, since f\u2081 is a convex function, we have $f_1 \\in F_i$ for $i = 1, 2, 3, 4, 5, 6$.\n2.  The function $f_2 \\in F$ for $i = 3, 4, 5, 6$, since\n$(\\nabla f_2(x), x) = 2\\sqrt{-x} \\geq c_1 f(x) = c_1 \\frac{(4\\sqrt{-x} \u2013 3)}{c_1=1/2}$, for $x < -1$.\nWith c\u2081 = 1, it can be shown that it is not possible to satisfy this inequality by choosing any constant c2 \u2265 0.\n3.  The function $f_3 \\in F$ for $i = 2, 4, 6$. It is easy to show f3 has two global minima: a global minimum at x = 1 with $f^* = 0$ and a global minimum at x = -1 with $f^* = 0$. Then, choosing $c_1 = 1$ and $C_2 = 0.5 (it is the smallest C2 when c\u2081 = 1), we can show that\n$(\\nabla f_3(x), x - 1) - c_1 f_3(x) = (2x^3 \u2013 2x)(x \u2013 1) - c_1 (\\frac{x^4}{2} \u2013 x^2 + \\frac{1}{2}) \\geq -C_2$, for $x \\geq 0$,\n$(\\nabla f_3(x), x + 1) - c_1 f_3(x) = (2x^3 \u2013 2x)(x + 1) - c_1 (\\frac{x^4}{2} \u2013 x^2 + \\frac{1}{2}) \\geq -C_2$, for $x < 0$.\nWith $C_2 = 0$, it can be shown that it is not possible to satisfy these inequalities by choosing any constant c1 > 0.\nBy choosing $c_1 = 1$ and $C_2 \\approx 1.437$ (it is the smallest c2 when c\u2081 = 1), we have\n$(\\nabla f_3(x), x - 1) - c_1 f_3(x) = (2x^3 \u2013 2x)(x \u2013 1) - c_1 (\\frac{x^4}{2} \u2013 x^2 + \\frac{1}{2}) \\geq -C_2$, for $x \\in \\mathbb{R}$."}]}