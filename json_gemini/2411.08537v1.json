{"title": "MLV2-Net: Rater-Based Majority-Label Voting for Consistent\nMeningeal Lymphatic Vessel Segmentation", "authors": ["Fabian Bongratza,b", "Markus Karmanna", "Adrian Holza", "Moritz Bonhoeffera", "Viktor Neumaiera", "Sarah Delia", "Benita Schmitz-Koepa", "Claus Zimmera", "Christian Sorga", "Melissa Thalhammera", "Dennis M. Heddericha", "Christian Wachingera,b"], "abstract": "Meningeal lymphatic vessels (MLVs) are re-\nsponsible for the drainage of waste products\nfrom the human brain. An impairment in their\nfunctionality has been associated with aging\nas well as brain disorders like multiple sclero-\nsis and Alzheimer's disease. However, MLVs\nhave only recently been described for the first\ntime in magnetic resonance imaging (MRI), and\ntheir ramified structure renders manual seg-\nmentation particularly difficult. Further, as\nthere is no consistent notion of their appear-\nance, human-annotated MLV structures con-\ntain a high inter-rater variability that most au-\ntomatic segmentation methods cannot take into\naccount. In this work, we propose a new rater-\naware training scheme for the popular nnU-\nNet model, and we explore rater-based ensem-\nbling strategies for accurate and consistent seg-\nmentation of MLVs. This enables us to boost\nnnU-Net's performance while obtaining explicit\npredictions in different annotation styles and a\nrater-based uncertainty estimation. Our final\nmodel, MLV2-Net, achieves a Dice similarity co-\nefficient of 0.806 with respect to the human ref-\nerence standard. The model further matches\nthe human inter-rater reliability and replicates\nage-related associations with MLV volume.", "sections": [{"title": "1. Introduction", "content": "The lymphatic system\npart of the immune sys-\ntem and responsible for the drainage of waste prod-\nucts stretches across the entire human body and\ncan often be found alongside blood vessels of the cir-\nculatory system. In the brain, the glymphatic sys-\ntem takes a similar role in that it\nclears waste products. To this end, meningeal lym-\nphatic vessels (MLVs), located alongside the dural\nvenous sinuses, transfer interstitial fluids and macro-\nmolecules to deep cervical lymph nodes. An impairment in the MLVs' function-\nality, potentially coupled with morphological changes\nsuch as thickening, has been linked to aging as well as to clinical condi-\ntions like Alzheimer's, mul-\ntiple sclerosis, and Parkin-\nson's disease. Yet, MLVs have\nonly recently been described in 3D FLAIR MRI and their segmentation has only\nbeen done manually so far. However, manual annota-\ntion of MLVs is difficult and time-consuming due to\ntheir ramified structure, cf. Figure 1. Moreover, the\ntraining of automatic segmentation models on expert-\nannotated data is challenging due to the high inter-\nrater variability.\nRelated work Deep neural networks for medical\nimage segmentation are commonly trained to remove\nthis variablility. However, this ap-\nproach does not model the reality where disagree-\nment about the true contours of a structure often\nexists. This issue is espe-\ncially problematic for newly discovered structures,\nsuch as MLVs, which bear enormous potential for\ninnovative findings but for which a common notion\nof their appearance does not (yet) exist. Notably,\na few dedicated methods for rater-aware segmenta-\ntion were developed. These approaches yielded effective results for certain\nstandard applications, e.g., skin lesion or brain tumor segmentation, but transferring them to new tasks is\ndifficult due to the large number of hyperparameters\ninvolved. These choices are non-trivial, not repro-\nducible, and subject to the developer's experience and\npreferences. At the same time,\nthe best segmentation results are typically obtained\nwith nnU-Net, which provides\na versatile framework for hyperparameter selection.\nUnfortunately, nnU-Net cannot model the variabil-\nity in segmentations provided by different raters\na functionality essential for trustworthy and compre-\nhensible clinical predictions. We close this gap and\ndevelop a rater-based ensembling strategy for nnU-"}, {"title": "2. Methods", "content": "Net that keeps its architecture intact and augments\nit with the ability to replicate individual raters' an-\nnotation styles.\nContribution We present the first automatic\nmethod for segmentation of MLVs from 3D FLAIR\nMRI. To achieve accurate and reliable segmentation\nof the ramified structure, we made the following tech-\nnical contributions. First, we developed an innovative\nrater-aware training scheme for the popular nnU-Net\nmodel that takes into account the different raters in-\nvolved in the creation of the training set. This en-\nables nnUNet to learn individual raters' segmenta-\ntion styles and to explicitly predict a set of plausi-\nble segmentations. In a second step, we aggregate\nthe predictions with a weighted majority-label voting\nscheme for best segmentation accuracy. In addition,\nwe obtain a rater-based uncertainty prediction from\nthe model. Finally, since the volume of MLVs is usu-\nally of utmost importance for downstream analyses,\nwe derive error boundaries of the model's predicted\nvolumes with respect to the ground-truth volume."}, {"title": "2.1. MLV2-Net architecture", "content": "Figure 2 shows an overview of MLV2-Net, which\nstands for rater-based majority-label-voting-network\nfor meningeal lymphatic vessels. MLV2-Net builds\nupon nnU-Net and takes a 3D\nimage of shape H\u00d7W\u00d7D as input. In addition, we\nincorporate a unique encoding of the rater (rater en-\ncoding) of the same shape as the image. The rationale\nbehind this encoding is that it provides relevant infor-\nmation about the rater, in our case a neuroanatomical\nexpert who provides annotations of MLVs, without\nany architectural changes that might derange nnU-\nNet's hyperparameter search strategy. As output, the\nnetwork yields voxel-wise segmentation maps, sep-\narated by foreground class and rater. Eventually,\nall predictions are aggregated via weighted majority-\nlabel voting as shown in Figure 3. Apart from the\ninput and output, we keep nnU-Net intact; hence, we\nbenefit from its structured parameter selection and\nobtain a reproducible setup."}, {"title": "2.2. Rater-aware training and inference", "content": "During the training and inference of MLV2-Net, we\nconsider the different raters in the input and the out-\nput of the model.\nRater as input To enable the network to learn\nthe styles of different raters from the training data,\nwe provide this information as input to the net-\nwork. Technically, we assign a zero-centered one-hot-\nencoded ID to each rater and concatenate it as addi-\ntional channels to the input image volume as depicted\nin Figures 2 and 3. Namely, we assign the four raters\nin our setting the codes [1, 0], [-1, 0], [0, 1], and [0,\n-1]. In general, this scheme leads to R/2 additional\ninput channels for R raters, which can be well pro-\ncessed by nnU-Net's initial convolutional layer. Im-\nportantly, we disable the per-channel z-score normal-\nization in nnU-Net for the rater-encoding channels,\nwhich would set them to zero and essentially erase\nthe rater information.\nRater as output To enforce the model to con-\nsider the rater, i.e., to coerce the network to pre-\ndict the correct structure as annotated by a certain\nrater, we create rater-specific foreground labels for\nthe loss computation (a combination of cross-entropy\nand Dice loss as in nnUNet). These are also the la-\nbels predicted by MLV2-Net during inference. Specif-\nically, we use labels \"Anterior MLV/Rater 1\", \"An-\nterior MLV/Rater 2\", \"Anterior MLV/Rater 3\", and\n\"Anterior MLV/Rater 4\" instead of one label \"An-\nterior MLV\". Likewise for labels \"Middle MLV\" and\n\u201cPosterior MLV\u201d. This results in RF + 1 labels, i.e.,\nthe cartesian product of R rater and F foreground\nlabels, and the background. We do not create rater-\nspecific background labels, as this would be redun-\ndant."}, {"title": "2.3. Weighted majority-label voting", "content": "To aggregate the segmentation maps in the styles of\ndifferent raters, we employ a weighted majority-label\nvoting, which we illustrate in Figure 3. As shown,\nwe multiply the number of votes from rater-specific\nforeground predictions by a weight wfg > 1. Com-\npared to the standard majority vote (wfg = 1), this\nincreases the sensitivity to foreground labels, which\nwe found to correspond best to human consensus\ndecision-making (cf. Section 3.3). In the rare case of\na tie, we choose the class with the lowest index. By\ndefault, nnU-Net also creates an ensemble of mod-\nels via cross-validation and aggregates the voxel-wise\nmean of the predicted logits. We keep this mecha-\nnism untouched, i.e., cross-validation ensembling is\npart of the nnU-Net blocks in Figure 3, and com-\npute the majority-label vote externally, treating each\ncross-validation ensemble as one voting model."}, {"title": "2.4. Rater-based uncertainty", "content": "Apart from the consensus prediction, we obtain a\nrater-based uncertainty map in MLV2-Net. The un-\ncertainty is based on the agreement of rater-based\npredictions of the model, i.e., the uncertainty is\nhigher the more rater-based predictions speak against\nthe majority label for a certain voxel. This provides\nus with an estimate of the reliability of the predic-\ntion, which renders the model more faithful as it\ncan be used to detect potential failure cases. Un-\nlike alternative uncertainty estimation methods, e.g.,\nMonte Carlo Dropout, MLV2-Net does not require a variational network ar-\nchitecture but keeps nnU-Net overall intact. An-\nother advantage of our explicit rater-based modeling\nis that individual, potentially flawed, or deprecated\nsegmentation styles can easily be ignored post hoc,\ni.e., without re-training. This is typically impossible\nwith variational approaches that implicitly model the\ndata variability."}, {"title": "2.5. Boundaries on segmented volume based\non Dice", "content": "The performance of segmentation models is com-\nmonly evaluated with the Dice similarity coefficient\n(DSC). However, in the end, the segmented volume\nis often of utmost importance in medical imaging.\nTherefore, in the following, we derieve error bound-\naries on the predicted volume relative to the ground-\ntruth or reference volume.\nTheorem 1 Given the Dice similarity coefficient\n(DSC) of a segmentation model, the predicted vol-\nume relative to the ground-truth volume is bounded\nby $\\frac{DSC}{2-DSC}$ from above and by $\\frac{2-DSC}{DSC}-1$ from be-\nlow."}, {"title": "Proof.", "content": "The DSC and the relative predicted volume\n$V_{rel}$ can be calculated from a confusion matrix com-\nprising false negative (FN), true positive (TP), false\npositive (FP), and true negative (TN) voxels. By\ndefinition, the DSC is calculated as\n$DSC = \\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP} = \\frac{2 \\cdot TP}{1 + TP + FP}$, (1)\nwhere we utilized the fact that TP + FN = 1 when\nnormalized to the ground-truth (GT) volume. The\nrelative predicted volume, i.e., the predicted relative\nto the GT volume, is given by\n$V_{rel} = \\frac{\\text{Predicted volume}}{\\text{GT volume}} = \\frac{TP + FP}{TP + FN} = TP + FP$. (2)\nRearranging Equation (1) to $FP = \\frac{2 \\cdot TP}{DSC} - 1$\nand inserting it into Equation (2) yields\n$V_{rel} = \\frac{2 \\cdot TP}{DSC} - 1$. (3)\nFrom TP \u2264 1, we obtain $V_{rel} < \\frac{2}{DSC} - 1$. Similarly,\nwe get $V_{rel} \\ge \\frac{2-DSC}{DSC} - 1$ by rearranging Equation (1)\nto $TP = \\frac{DSC}{2} (FP + 1)$ and FP \u2265 0."}, {"title": "3. Results", "content": ""}, {"title": "3.1. Experimental setting", "content": "We implemented MLV2-Net into nnU-Net (v2, 3D\nFullres), based on Python (v3.11), PyTorch (v2.1),\nand CUDA (v12.1). As there is no reference\nmethod for automatic segmentation of MLVs, we\ncompare MLV2-Net to a diverse set of baseline\nmethods. Namely, we implemented a registration-\nbased segmentation propagation algorithm that aggregates all train-\ning references through an optimized threshold, Uni-\nverSeg, a recent foundation model\nfor medical image segmentation that we adapted for\n3D images by fusing overlapping patches from all\nthree image planes, and the standard nnU-Net con-\nfigurations (2D and 3D Fullres). In addition, we implemented an ensemble of sepa-\nrate, rater-specific models (not to be confused with\nnnU-Net's cross-validation-based ensembling strat-\negy), and we ablate the weighted majority-label vot-\ning and the rater-specific labels. We ran all methods\nconsistently on a single Nvidia GeForce RTX 3090\ngraphics card with 24GB VRAM. All experiments\nwere conducted with the data described in the ini-\ntial paragraph about data and code availability."}, {"title": "3.2. Inter-rater reliability and rater-based\nuncertainty", "content": "As a measure of inter-rater reliability (IRR), we com-\npute a Fleiss' kappa score based on\nour IRR dataset. This dataset contains an annota-\ntion from each rater for each image. Considering all\nthree foreground labels as a single entity, we obtain\na Fleiss' kappa of \u043a = 0.73/0.79 for the two IRR im-\nages, respectively. The ensemble of separate, rater-\nspecific nnU-Net models closely replicates the expert\nraters' IRR (\u043a = 0.74/0.80). With the single-model"}, {"title": "3.3. Accuracy and consensus decision-making", "content": "While annotation variability among human raters is\nnatural and unavoidable, most applications demand\nconsistent segmentation. In our held-out consensus\ntest set, we tried to remove the variability as much\nas possible through all four raters' joint annotation\nof the images. This is the reference standard for con-\nsensus decision-making but, unfortunately, it is only\nfeasible for a few images. In Table 2, we report the\naverage accuracy of all implemented methods on this\nconsensus set and in a 5-fold cross-validation on our\ntraining set, separated by anterior, middle, and poste-\nrior regions. Qualitative predictions are in Figure 6."}, {"title": "3.4. Ablation study", "content": "From the ablation study in Table 3, we infer that\nthe most important design choice in MLV2-Net is the\nweighted majority-label voting. It makes the model\nmore sensitive to foreground voxels than the stan-\ndard, equally weighted majority vote. Other method-\nological choices, such as using a single-model ap-\nproach and rater-specific labels, seem to have only\na minor positive effect on segmentation accuracy.\nFor our setting with four raters, we can deduce ex-\nplicit segmentation thresholds in dependence of the\nforeground weight wfg. In words, wfg = 3 means\nthat a voxel is segmented as foreground if no more\nthan two out of the four rater-specific predictions an-\nticipate it to be background (with three background\nvotes, the voxel is predicted as background due to our\npolicy to choose the lower-label index in case of a tie,\ncf. Section 2.3). With wfg = 2, two votes on the back-\nground can only be overruled if the other two votes\nare on the same MLV sub-label (anterior, middle,\nposterior), which makes it slightly less foreground-\nsensitive than wfg = 3. Increasing the sensitivity\nto foreground votes further by setting wfg\n4 re-\nduces the performance to the standard majority vote.\nThus, we deduce that a moderately increased fore-\nground sensitivity emulates human consensus-finding\nbest based on the given data.\n="}, {"title": "3.5. Downstream analysis of MLV volume", "content": "Finally, we apply our model in a downstream analy-\nsis of MLV volume using unlabeled imaging data. Re-\ncently, found a positive associ-\nation of age with MLV volume based on manual anno-\ntations. Using our MLV2-Net model, we can replicate\nthis finding based on a group of adults (n = 4, age\n51-62) and a larger young reference cohort (n = 18,\nage 22-34), see Figure 8. The difference is significant\nbased on p < 0.05 (two-sided t-test). This result indi-\nrectly confirms the accuracy of our model and proves\nits applicability for analyzing real-world study data."}, {"title": "4. Discussion", "content": "MLV segmentation task The task of MLV seg-\nmentation is new and challenging due to the rami-\nfied structure, the thin diameter, and the high inter-\nrater variability among experts on the voxel level.\nThe difficulty of segmenting these structures is re-\nflected in the high inter-rater variability in the expert-\nannotated data (Fleiss' kappa of \u043a = 0.73/0.79),\ncf. Section 3.2. According to, this corresponds to a substantial agreement\n(0.6 < \u043a \u2264 0.8), which is inferior to perfect agree-\nment (\u043a > 0.8). Nonetheless, we achieved a high ac-\ncuracy of DSC = 0.806 on our consensus test set. As\nno established baselines exist for this task, we tried\nto cover various methods ranging from segmentation\npropagation over supervised learning to recent foun-\ndation models, cf. Section 3.3. Yet, future research\nshould investigate and compare alternative model ar-\nchitectures and training paradigms to draw a more\ncomplete picture of the task at hand.\nDataset size We are aware that the number of an-\nnotated scans (n = 33) used in this study is com-\nparably small, especially when compared to recent\nsegmentation datasets with annotations of thousands\nof anatomies. Yet, datasets\nwith around 30 annotated scans are not uncommon\nfor 3D medical image segmentation. In fact, creating much larger segmentation\ndatasets manually for MLV structures is impossible\ndue to their complex shape, the low contrast even in\nFLAIR imaging, and the required high resolution of\n0.5mm in sagittal and vertical axes. In our experi-\nments, we tried to account for the small dataset size\nby tuning hyperparameters based on extensive cross-\nvalidation on the training set. Moreover, we indi-\nrectly assessed our model's performance on n = 22\nunannotated scans (cf. Section 3.5) by replicating\nknown age-related associations with MLV volume.\nFinally, we put particular effort into assessing the\ninter-rater reliability (cf. Section 3.2) and created a\nconsensus test set to ensure the used annotations are\nof high quality.\nForeground bias in ensemble decision-making\nIn our ablation study in Section 3.4, we found a fore-\nground weight of wfg = 3 to work best for the given\nMLV datasets. This essentially creates a bias to-\nward foreground labels, which seems to mimic human\nconsensus decision-making to a certain degree in our\ncase. However, it is unclear how this observation gen-\neralizes to other data, structures, and rater groups.\nAlbeit an analysis of this relation is out of scope for\nthis paper, it could be an interesting starting point\nfor follow-up research to investigate the observed fore-\nground annotation bias and its implications."}, {"title": "5. Conclusion", "content": "In summary, we presented the first automatic method\nfor MLV segmentation from 3D FLAIR imaging.\nOur model, MLV2-Net, outperformed state-of-the-art\nbaselines by embracing the styles of all annotators in-\nvolved in the creation of the training set. In contrast\nto most segmentation methods, MLV2-Net provides\na rater-based uncertainty estimation. Together with\nthe derived theoretical bounds on the segmented vol-\nume, we expect MLV2-Net to be a valuable tool for\nclinical researchers that study the glymphatic system.\nYet, the technical contributions and code are generic\nand could be beneficial for other applications as well."}]}