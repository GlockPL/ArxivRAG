{"title": "DiffNMR2: NMR Guided Sampling Acquisition Through Diffusion Model Uncertainty", "authors": ["Etienne Goffinet", "Sen Yan", "Fabrizio Gabellieri", "Laurence Jennings", "Lydia Gkoura", "Filippo Castiglione", "Ryan Young", "Idir Malki", "Ankita Singh", "Thomas Launey"], "abstract": "Nuclear Magnetic Resonance (NMR) spectrometry uses electro-frequency pulses to probe the resonance of a compound's nucleus, which is then analyzed to determine its structure. The acquisition time of high-resolution NMR spectra remains a significant bottleneck, especially for complex biological samples such as proteins. In this study, we propose a novel and efficient sub-sampling strategy based on a diffusion model trained on protein NMR data. Our method iteratively reconstructs under-sampled spectra while using model uncertainty to guide subsequent sampling, significantly reducing acquisition time. Compared to state-of-the-art strategies, our approach improves reconstruction accuracy by 52.9%, reduces hallucinated peaks by 55.6%, and requires 60% less time in complex NMR experiments. This advancement holds promise for many applications, from drug discovery to materials science, where rapid and high-resolution spectral analysis is critical.", "sections": [{"title": "1. Introduction", "content": "Nuclear Magnetic Resonance (NMR) spectroscopy is a powerful tool for identifying the molecular structures, providing insights into the arrangement of atoms within complex molecules. It has become an indispensable tool in chemistry, biochemistry, and structural biology from its introduction in 1938 (Giunta & Mainz, 2020). However, acquiring NMR spectra requires long acquisition times to reconstruct high-resolution information (Fig. 1). Traditional acquisition methods can be prohibitively slow in applications involving large biomolecules or when time is bounded, such as in drug discovery (Pellecchia et al., 2002; 2008) or metabolomics (Markley et al., 2017; Emwas et al., 2019). For example, acquiring a 4D NMR spectrum (CCNOESY) of the phycobilisome linker polypeptide domain of CpcC takes up to 90 hours (Ramelot et al., 2011).\nNon-uniform sampling (NUS) addresses this challenge by randomly sub-sampling the scanned signal while enabling high-quality spectral reconstructions (Fig. 1). Instead of sampling every data point in a regular pattern, NUS collects a subset of data points based on a pseudo-random or optimized sampling schedule (Marvasti, 1993). The advantage of NUS lies in its capacity to significantly accelerate acquisition, but its effectiveness relies on robust reconstruction algorithms capable of handling incomplete data. Several methods have been developed for reconstructing spectra from NUS data, including Low-Rank Approximation (LR) (Qu et al., 2015), Compressed Sensing (CS) (Kazimierczuk & Orekhov, 2011), and Deep Learning (DL)-based methods (Qu et al., 2020; Zhan et al., 2024; Zheng et al., 2022; Karunanithy & Hansen, 2021).\nIn this study, we introduce an AI-based approach that dynamically adapts the acquisition strategy. By integrating acquisition and reconstruction, the method leverages the uncertainty of the diffusion model (i.e., the degree of variability in the model's reconstruction) to refine sampling in real-time, significantly reducing the acquisition burden. Using a real-life protein 2D NMR dataset (Klukowski et al., 2024), we demonstrate that our method outperforms state-of-the-art sampling techniques and reconstruction methods, delivering accurate high-resolution spectral reconstructions from substantially reduced datasets. This work establishes a new paradigm in NMR spectroscopy by combining the strengths of NUS and advanced machine learning, enabling rapid, high-quality spectral analysis for time-sensitive applications."}, {"title": "2. 2D NMR Data", "content": "Two-dimensional nuclear magnetic resonance spectroscopy provides detailed structural and dynamic information about molecules by resolving spectral data along two frequency axes. This is achieved by extending the principles of 1D NMR with the additional time domain, offering insights into interactions between nuclei."}, {"title": "2.1. The Acquisition Process", "content": "A 2D NMR experiment consists of three primary stages: preparation, evolution, and acquisition. During the preparation phase, tailored radio-frequency pulse sequences excite the nuclear spins and establish coherence pathways to encode the desired interactions. The preparation stage is followed by the evolution phase, where nuclear spin information is read during an evolution time (te), Revealing the chemical environment, such as chemical shifts and spin-spin couplings. The encoded magnetization is subsequently recorded during the acquisition time (ta), generating dual time-domain data (te, ta). These data are processed to produce a 2D frequency spectrum, where the indirect dimension (te) typically reflects spin-spin interactions, and the direct dimension (ta) corresponds to the resonance frequencies of individual nuclei.\nPulse sequences are carefully designed radiofrequency pulses and delays that manipulate spin states to achieve specific coherence transfers and magnetization pathways. For example, a simple COSY (Correlation Spectroscopy) experiment uses a two-pulse sequence to correlate chemical shifts of coupled nuclei, highlighting scalar (J) coupling. More complex sequences like HSQC (Heteronuclear Single Quantum Coherence) include additional steps, such as heteronuclear decoupling, to correlate proton and heteronucleus (e.g., 13C or 15N) chemical shifts. These advanced techniques are particularly valuable for analyzing larger biomolecules. Finally, to enhance the signal-to-noise ratio, it is common practice to perform multiple scans of the same spectrum and average them to obtain the final resonance map."}, {"title": "2.2. Data Processing", "content": "The raw data from a 2D NMR experiment is initially represented as a 2D array of signal intensities varying over te and ta. This data is transformed into a frequency domain using a two-dimensional Fourier transform (see Fig. 1 (a). Before the transform, techniques like phase correction and apodization are applied to improve spectral resolution and signal-to-noise ratio. The resulting 2D spectrum is plotted on the frequency axes of the evolution axis and acquisition axis, with cross-peaks indicating interactions between nuclei."}, {"title": "2.3. Non-Uniform Sampling (NUS)", "content": "Non-Uniform Sampling (NUS) is a technique used to improve the efficiency of 2D NMR data acquisition by selectively sampling a subset of the evolution times (te) rather than collecting the full Nyquist grid. Instead of acquiring data at every increment of te, only a fraction of the points are sampled at random. One standard strategy is the Sine-Weighted Poisson-Gap sampling (Hyberts et al., 2010), which assumes a Poisson distribution for the gap size between evolution times.\nThe reconstruction of the full spectrum from sparsely sampled data requires advanced computational algorithms. One prominent method is Low-Rank Approximation (LRA) (Qu et al., 2015), which represents the data as a Hankel matrix and approximates it with a low-rank reconstruction that best fits the sampled points. While computationally efficient, the LRA struggles to capture highly complex spectral features or systems with noise, leading to artifacts in the reconstruction. Compressed Sensing (Kazimierczuk & Orekhov, 2011) is another standard that leverages the sparsity of NMR signals in the time-time domain to reconstruct the complete dataset. However, CS requires careful tuning of regularization parameters and may exhibit limitations in reconstructing spectra with dense peaks or overlapping signals.\nIn recent literature, Qu et al. (Qu et al., 2020) introduced a dense Convolutional Neural Network (CNN) (LeCun et al., 2015) with a spectrum consistency block for Poisson-Gap NUS data, achieving promising results for 2D and 3D spectra. Zhan et al. (Zhan et al., 2024) employed SEPSNet, an attention-based network, to enhance pure shift NMR reconstruction from a 2D resonance map. Zheng et al. (Zheng et al., 2022) developed PS-ResNet, a ResNet-based model, for denoising 1D spectra. Karunanithy et al. (Karunanithy & Hansen, 2021) applied dilated convolutions through Fid-net, inspired by WaveNet, for synthetic NMR data analysis. Despite these advancements, these deep learning methods share a common limitation: they are primarily trained on synthetic datasets, which may not fully capture the complexity and variability of real-life NMR data. As a result, their performance has not consistently surpassed the established CS baseline for NUS reconstruction, particularly when applied to experimental datasets (Yan et al., 2024)."}, {"title": "3. Proposed Method: Guided Sampling", "content": "In contrast to existing methods, our approach employs a diffusion model in the frequency-time domain to reconstruct spectra with high precision, offering a novel perspective on NUS data reconstruction. By leveraging the uncertainty of the diffusion model in the reconstructed spectrum, we introduce an adaptive sampling strategy that dynamically prioritizes the evolution times iteratively. This method enhances data acquisition efficiency, reduces overall acquisition time, and ensures high-quality spectral reconstructions, providing a practical and effective solution for experimental NMR data."}, {"title": "3.1. NUS Reconstruction with Diffusion Model inpainting", "content": "Denoising Diffusion Probabilistic Models (DDPM) (Ho et al., 2020), are a class of neural networks originally inspired by non-equilibrium thermodynamics processes (Sohl-Dickstein et al., 2015). These models are trained by progressively destroying data with noise and then learning to reverse the process and regenerate the original data. The first phase (i.e., the diffusion process) consists of generating noisy data such that:\n$q(x_t|x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_t\\epsilon I)$,\nwhere xo represents the original spectrum, xt is the noisy spectrum at time step t, and $ \\beta_t $ is a variance parameter term controlling the amount of noise added at each step.\nThe second phase (i.e., denoising process), involves training a UNet (Ronneberger et al., 2015) to minimize the difference between the predicted noise and the actual noise added in the forward process. This can be formulated as optimizing the Mean Reconstruction Error loss:\n$\\mathcal{L} = ||\\epsilon - \\epsilon_\\theta (x_t, t)||^2$\nThe same model and architecture can also be used for inpainting in the context of incomplete image reconstruction.\nIn our experiments, we perform the inpainting using a diffusion model trained for denoising combined with the Repaint pipeline (Lugmayr et al., 2022). This pipeline works by combining the information of the unmasked area during the denoising step. This is illustrated in Fig. 2."}, {"title": "3.2. Guided Sampling Workflow", "content": "Instead of revealing all evolution times of the frequency-time input as in regular NMR experiments (i.e., applying the whole pulse sequence) or scanning a random selection of evolution times as NUS (i.e., selecting a subset of input rows), Guided Sampling is an iterative approach that, at each step, prioritizes evolution times (input rows) to be scanned by the NMR machine.\nOur proposed Guided Sampling approach is illustrated in Fig. 1 (c). Row-wise Scan. At each iteration, a small percentage (e.g., 2%) of the input rows is revealed (unmasked) by the NMR machine. 1D Fourier Transform. After performing a 1D Fourier Transform along the acquisition time axis, the data domain switches from Time-Time to Frequency-Time. Row Inpainting. The diffusion model predicts the masked parts of this map by generating and averaging multiple outputs. Row-wise Uncertainty. Alongside the average, the pixel-wise uncertainty is calculated using the variance in the reconstructed map. For a given evolution time e and frequency f, the pixel-wise variance is defined as:\n$\\sigma_{f,e}^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_{f,e}^{(i)} - \\mu_{f,e})^2$,\nwhere n is the number of reconstructed samples, $x_{f,e}^{(i)}$ is the pixel-wise value of the i-th sample, and $ \\mu_{f,e} $ is the mean pixel-wise value. The row-wise uncertainty for an evolution time e is computed as the sum of the pixel-wise uncertainties:\n$U_e = \\sum_{f=1}^{f_a} \\sigma_{f,e}$\nwhere fa represents the total number of frequency points. Uncertain Rows Selection. The rows with the highest uncertainty are then selected and scanned by the NMR machine in the next iteration. For initialization, the initial subset of input rows is selected using Poisson-Gap sampling, as row-wise uncertainty is not yet available."}, {"title": "3.3. Data", "content": "Recent advancements in diffusion models for image generation rely on massive datasets containing hundreds of millions of images (Schuhmann et al., 2021; Rombach et al., 2022). In contrast, large-scale datasets for 2D NMR protein spectra are scarce, with only a few public repositories available. The standard approach has been to train models on synthetic spectra (Zhan et al., 2024; Qu et al., 2020; Karunanithy & Hansen, 2021; Zheng et al., 2022), which often fail to capture the complex noise patterns and signal variations present in real-life data. This limitation also explains why Compressed Sensing (Kazimierczuk & Orekhov, 2011) and Low-Rank Approximation (Qu et al., 2015) remain the state-of-the-art methods for reconstructing real-world NMR spectra. To address this gap, our study focuses on training models exclusively on real-life NMR spectra, providing a more realistic and reliable basis for evaluation.\nIn this study, we use the 100-protein NMR spectra dataset (Klukowski et al., 2024), comprising 1329 spectra in 2D, 3D, and 4D formats. These spectra, derived from 100 proteins, were sampled using NMR machines operating at frequencies ranging from 600 to 950 MHz. We augmented the dataset by including 2D spectra obtained by projecting higher-dimensional (3D or 4D) spectra into 2D representations. This technique, commonly used in NMR workflows for visualization purposes, increases the total number of samples to over 3500. The process maintains the integrity of the original signals while significantly enriching the dataset for training. Finally, the spectra are transformed with a 1D Inverse Fourier Transform to obtain their representation in the frequency-time domain where each row corresponds to a 1D NMR spectrum, and to an evolution time."}, {"title": "3.4. Training", "content": "We split the dataset into training, validation, and test sets with respective proportions of 80%, 10%, and 10%, ensuring the test set independence and avoiding data leakage. The diffusion model is trained by optimizing the Mean Reconstruction Error (MSE) loss of the predicted noised applied to the frequency-time representation of the spectrum. We trained for 200 epochs and kept the model optimizing the validation loss."}, {"title": "4. Experiments and Results", "content": "After inpainting the frequency-time representation, we obtain the reconstructed spectrum with a 1D Fourier Transform on the evolution time axis. All experiments and benchmark metrics are based on the quality of this final reconstructed spectrum since this is the output analyzed by NMR users. We simulate the partial acquisition by masking rows of the frequency-time representation, which is a fair approximation applied in the partial NMR acquisition (Qu et al., 2020; Karunanithy & Hansen, 2021; Zheng et al., 2022; Yan et al., 2024; Zhan et al., 2024)."}, {"title": "4.1. Metrics", "content": "The evaluation approach balances both a global perspective, assessing the overall agreement between the original and reconstructed spectra, and a local perspective, focusing on the accuracy of spectral peaks, which are essential for compound characterization in NMR spectroscopy."}, {"title": "4.1.1. GLOBAL METRICS", "content": "Given our goal of developing a method to reliably reconstruct the raw signal outputted by an NMR machine before any expert signal processing. We use the Mean Squared Error (MSE, lower is better) and the coefficient of determination (R2, higher is better) to globally evaluate the quality of the predictions. MSE is a standard reconstruction metric (Hyberts et al., 2010) that quantifies the magnitude of prediction errors, ensuring accuracy in capturing critical spectral features like peak intensities and positions. R2 complements this by assessing how well the model explains the variance in the data, providing a normalized measure of fit. Together, these metrics ensure a robust evaluation of the method's precision and reliability."}, {"title": "4.1.2. PEAK-FOCUSED METRICS", "content": "We also introduce two metrics specifically designed to assess the integrity of spectral peaks: Peak Hallucination Ratio (lower is better) and Missed Peak Ratio (lower is better). The Peak Hallucination Ratio, analogous to the False Detection Rate, measures the proportion of peaks detected in the predicted spectrum that do not correspond to peaks in the reference spectrum. Conversely, the Missed Peak Ratio, analogous to the False Negative Rate, evaluates the proportion of peaks in the reference spectrum absent in the predictions. These metrics are calculated based on peaks identified by a consistent expert system using the same parameters for all spectra and all methods, ensuring fair and unbiased comparisons. By incorporating these peak-specific metrics, we address the critical importance of preserving key spectral features essential for downstream analysis."}, {"title": "4.2. Guided Sampling Parameters tuning", "content": "The Guided Sampling process depends on several parameters, some being linked to the diffusion model inference and some others to the sampling algorithm. We identified the main important parameters to be the number of denoising timesteps and the proportion per step. In the following experiments, we always put aside the data point at 95% masking (i.e., 5% acquisition completion ), which is the state initialized at random and does not reflect the performances of the guided sampling. We optimize these parameters using a greedy approach while keeping all other parameters fixed."}, {"title": "4.2.1. PERCENTAGE OF MASKING AND PERCENTAGE OF COMPLETION", "content": "Throughout this work, the term 'masking proportion' refers to the fraction of data still not acquired, defined as one minus the acquisition completion. For instance, 90% masking indicates 10% acquisition completion. Metric plots are interpreted from right to left, starting at 100% masking (0% completion) and progressing iteratively. In the Guided Sampling, each iteration updates the mask by revealing a fixed additional proportion of rows (e.g., 70% masking is derived from 75% by completing an additional 5%)."}, {"title": "4.2.2. NUMBER OF DENOISING TIMESTEPS", "content": "Diffusion model inpainting is an iterative process that performs several denoising timesteps to obtain the final representation (see Fig. 3). We performed a sensitivity analysis on the number of time steps to understand their impact on the Guided Sampling performances. We observed that the timestep number has a strong effect on the spectrum reconstruction. Increasing the number of time steps leads to better results of the global metrics and hallucination ratio on average after the first guiding step.\nThe missed peaks ratio, however, seems to be negatively impacted by this number, which we attribute to the fact that a higher timestep number is associated with more accurate uncertainty estimation. The model gains in precision but loses in terms of exploration capacities."}, {"title": "4.2.3. PERCENTAGE OF COMPLETION PER STEP", "content": "In this experiment, we observe the impact of the percent of the spectrum acquired at each step (pcps), corresponding to the proportion of evolution times scanned by the NMR machine at each iteration of the guided sampling.\nShown in Fig. 4, after 20% completion, the iteration step (pcps) parameter seems to have a marginal impact on the global reconstruction metrics (MSE and R2), which tend to converge to the same levels, except pcps 1%, which exhibits worse peak-related metrics overall.\nHowever, smaller pcps values unlock better performances at high masking levels by leveraging earlier uncertainty guidance. For instance, at 10% completion, pcps 2% achieves a 2x lower MSE than pcps 5%, which in turn has a 2x lower"}, {"title": "4.3. Baselines", "content": "To show the full capabilities of the Guided Sampling approach and based on the number of time step experiment from Sec.4.2.2, we consider two versions of our Guided Sampling with timestep numbers 200 and 400, denoted as GS200 and GS400, respectively.\nWe compare our versions with two other sampling methods from the literature, Uniform random sampling, which samples evolution time from a uniform distribution, and Poisson-Gap sampling (Hyberts et al., 2010). This last method has been established as a state-of-the-art sampling method regarding reconstruction quality. It operates by sampling gaps between evolution time from a Poisson-Gap distribution weighted with a sinus function that gives more importance to lower frequencies.\nThe sampling approaches are compared based on the reconstructed spectrum quality after inpainting the associated frequency-time domain with our pre-trained diffusion model."}, {"title": "5. Discussion", "content": "In this section, we analyze the spectra reconstructed from the independent test set, focusing on two key aspects: the comparison of sampling strategies (i.e., Guided Sampling, Poisson-Gap Sampling, Uniform Sampling) and the comparison of inpainting methods (i.e., Diffusion model, Compressed Sensing (Kazimierczuk & Orekhov, 2011), Low-Rank Approximation (Qu et al., 2015)). Together, these comparisons provide a comprehensive understanding of the strengths of our approach in improving NMR spectrum spectroscopy."}, {"title": "5.1. Cross-sampling and cross-model comparisons", "content": "As shown in Fig. 5, the evaluation is based on acquisition completion from 2% to 50% (i.e., from 98% to 50% of masking).\nCross-sampling comparison. Within the same diffusion model framework, different sampling strategies show clear differences in performance. Guided Sampling (GS200 and GS400) consistently achieves the best results across all metrics, underscoring the advantages of our proposed sampling strategy. Generally, GS400 slightly outperforms GS200 due to more inference time steps, suggesting a trade-off between computational efficiency and precision. Poisson-Gap performs comparably in MSE and R2 after 20% of acquisition completion. For the peak reconstruction, Poisson-Gap generates more hallucinated peaks and omits more peaks (Missed Peaks) than Guided Sampling. However, there is always a performance gap between Uniform Sampling and all NUS strategies (GS and Poisson-Gap).\nNote that in terms of Missed Peaks, at low acquisition completion, the best one seems to be uniform sampling, which is actually misleading, as its noise inflates peak counts artificially. Among the other methods, GS200 consistently outperforms, while GS400 is slightly worse than Poisson-Gap for acquisition completion lower than 10%. After 10% of acquisition completion, GS200 and GS400 follow the same trend and converge.\nCross-model comparison. While CS (Kazimierczuk & Orekhov, 2011) and LR (Qu et al., 2015) use Non-Uniform Sampling, their reconstruction relies on specialized algorithms that fall short of the diffusion model (Guided Sampling, Poisson-Gap, and Uniform Sampling) in terms of MSE, R2 and Hallucination Ratio. LR reconstructs fewer Missed Peaks than the diffusion model after 15% of acquisition completion. As aforementioned, this is due to noise being misidentified as peaks."}, {"title": "5.2. Performance with scarce information", "content": "Table 1 presents the metrics at 10% of acquisition completion (i.e., 90% of the information is unknown.) GS200 and GS400 achieve an MSE of 2.4e-3, which represents a 52.9% reduction compared to Poisson-Gap strategy (5.1e-3). Guided Sampling also achieves the highest R2 values (> 0.7), indicating high accuracy and correlation with the reference data. GS400 achieves the lowest Hallucination Ratio (0.12), a 55.6% reduction compared to Poisson-Gap (0.27), followed by GS200 (0.15). Both methods effectively suppress false peaks, making them reliable for practical use. The diffusion model with uniform sampling, Compressed Sensing, and Low-Rank Approximation perform the worst.\nImplications of standard deviations Guided Sampling strategy also exhibits greater stability. At 10% of acquisition completion, GS200 has relatively low variability across all metrics, particularly in MSE (3.2e-4), ensuring consistent performance. GS400, while slightly more variable, remains reliable. Poisson-Gap shows moderate variability, while the Uniform sampling, CS, and LR exhibit higher standard deviations, reflecting its instability and inconsistent results."}, {"title": "5.4. Wall Time Comparison", "content": "All training and inference were conducted on an Nvidia H100 GPU (80 GB memory). Guided sampling steps, including sample generation and uncertainty prediction, took 1 min 8 s for GS200 and 2 min 12 s for GS400.\nUsing the average wall times for fully sampled 2D NMR acquisitions (nmr), we estimated the total wall time (diffusion model inference + pulse sequence acquisition) required for each NUS strategy to achieve a hallucination ratio below 10% (Fig. 8).\nGS200 and GS400 consistently outperformed Poisson-Gap sampling in experiments where fully sampled acquisition times exceeded 87 and 62 minutes, respectively. These time advantages covered most experiments with more than eight scans. Compared to Poisson-Gap, GS200 achieved time reductions of 10.2%, 19.2%, and 23.7%, while GS400 achieved 28.6%, 39.1%, and 44.3% for 2-hour, 3-hour, and 4-hour experiments, respectively.\nThese time savings can be further enhanced by optimizing GPU utilization. For example, running two NMR acquisitions in parallel would allow the GPU to process the guiding step of one experiment while the NMR machine acquires data for another, effectively removing GPU time from the total wall time. Alternatively, sample reconstructions for uncertainty estimation could be distributed across multiple GPUs."}, {"title": "5.3. Case study", "content": "Applied to the CCNOESY NMR spectrum of the phycobilisome linker polypeptide domain of CpcC - 2L8V - nuclei H1 H2 (Ramelot et al., 2011), the reconstructed results (displayed in Fig. 6) show the practical effects of the method choice. After collecting 10% of the pulse sequences, Uniform sampling, CS and LR show a high proportion of noise, which severely compromise the peak analysis. Poisson-Gap strongly improves the signal reconstruction and retains most of the signal information, but contains a small amount of missed peak and hallucinations. The Guided Sampling approach (especially GS400) contains the least hallucinations and recovers most of the signal.\nInterestingly, the Guided Sampling mask in the frequency-time domain resembles the Poisson-Gap mask, with significant weight distributed at long and short evolution times (Fig. 7). However, Guided Sampling amplifies this pattern, leaving nearly no rows sampled in the central region of the mask (medium evolution times). This highlights that most information needed to reconstruct the spectrum is concentrated at the edges of the frequency-time domain."}, {"title": "6. Conclusion", "content": "In this work, we introduced diffusion models to NMR spectroscopy for the first time, demonstrating their ability to reconstruct sub-sampled 2D spectra with reconstruction performance surpassing state-of-the-art methods. We also proposed a novel adaptive sampling strategy that leverages the uncertainty of the diffusion model to dynamically prioritize sampling regions, achieving more efficient sampling while maintaining superior reconstruction quality.\nGuided Sampling delivered better reconstruction metrics with fewer hallucinated and missed peaks compared to existing methods. By adjusting the denoising timestep parameter, users can balance the trade-off between computational efficiency and precision, tailoring the method to specific experimental needs. Additionally, Guided Sampling exhibited lower variability across metrics, highlighting its stability and reliability. We also analyzed acquisition time as a function of the duration of the full sample scan, showing clear benefits for experiments lasting more than 62 minutes or involving more than 8 scans.\nThis approach is highly promising for higher-dimensional spectra, where acquisition times increase exponentially with dimensions. Furthermore, it opens new avenues for refined sampling strategies based on uncertainty distribution analysis, such as prioritizing extreme evolution times. Finally, diffusion models hold significant potential for other NMR optimizations, including artificial resolution enhancement and efficient spectrum-to-structure matching."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here."}, {"title": "A. Appendix", "content": "We illustrate the Row-wise Uncertainty with different pcps in Fig. 9. The x-axis represents the row-wise uncertainty. If the distribution is closer to the left, it means that the uncertainty is lower."}, {"title": "A.2. Wall Time Comparison", "content": "We add the comparison for the wall time on the missed peaks ratio below 10%. The gains are even more pronounced for missed peak ratios than for hallucination ratios. In this case, GS200 is more efficient than other methods for experiments exceeding 39 minutes. For 1-hour, 2-hour and 3 hour experiments, GS200 is respectively 20%, 35%, and 50%, faster than Poisson-Gap sampling."}]}