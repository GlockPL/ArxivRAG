{"title": "Deep image-based Adaptive BRDF Measure", "authors": ["Wen Cao"], "abstract": "Efficient and accurate measurement of the bi-directional reflectance distribution function (BRDF) plays a key role in high quality image rendering and physically accurate sensor simulation. However, obtaining the re-flectance properties of a material is both time-consuming and challenging. This paper presents a novel method for minimizing the number of samples required for high quality BRDF capture using a gonio-reflectometer setup. Taking an image of the physical material sample as input a lightweight neural network first estimates the parameters of an analytic BRDF model, and the distribution of the sample locations. In a second step we use an image based loss to find the number of samples required to meet the accuracy required. This approach significantly accelerates the measurement process while maintaining a high level of accuracy and fidelity in the BRDF representation.", "sections": [{"title": "1 INTRODUCTION", "content": "The bidirectional reflectance distribution function (BRDF), is a fundamental concept in computer graphics, representing the interaction of light with a materials. It is a four-dimensional function that defines the relationship between incoming and outgoing light directions at a material. BRDFs can be represented either by analytic models or by tabulated measurements for every pair of incident and outgoing angles, with each approach having its own advantages and disadvantages. Capture of real, physical BRDFs is an important tool in many applications ranging from photo-realistic image synthesis and predictive appearance visualization in e.g. additive manufacturing to accurate sensor simulation and modeling of scattering behaviours in industrial processes. However, detailed BRDF measurement is a time-consuming process because it typically requires dense mechanical scanning of light sources and sensors across the entire hemisphere. Several studies (Nielsen et al., 2015; Dupuy and Jakob, 2018) have been conducted to reduce capture time by taking fewer measurements. Recently, neural approaches (Zhang et al., 2021) have been proposed to represent synthetic BRDFs from images, primarily by estimating the material's BRDF parameters.\nThe objective of this paper is to accelerate BRDF measurements using gonio-reflectometer setups. To incorporate prior knowledge of the material sample, our method uses a small neural network that takes an image of the sample as input to estimate the configuration of a small set of sampling directions to enable efficient BRDF measurement. Specifically, we employ an encoder network to estimate the reflectance parameters of analytic BRDF models from the input image, which are used to adapt the BRDF measurement directions. The method leverages both analytic BRDF models and image-based neural decomposition as priors. These two priors are essential for efficiently utilizing small networks to estimate the adaptive sample distribution."}, {"title": "2 RELATED WORK", "content": "In this section, we review previous work related to BRDF measurement and neural SVBRDF capture."}, {"title": "2.1 BRDF Measure", "content": "Generally, people use gonioreflectometers to capture the reflectance of realistic materials by controlling mechanical light sources and camera motions. For ex-ample, acquiring the MERL dataset requires densely sampling 180 azimuth angles, 90 elevation angles, and 90 outgoing directions, totaling approximately 1.46 million samples. To accelerate the acquisition, several methods and devices have been developed.\nSome research focuses on learning sample patterns from BRDF models to reduce the number of sample locations needed by the measurement apparatus.\nNielsen etc.(Nielsen et al., 2015) and Miandji etc.(Miandji et al., 2024) use the measured BRDF Dataset to train basis to linearly reconstruct the full BRDF samples to accelerate the measurements.\nTong(Tongbuasirilai et al., 2017) use a novel prame-terization to acceleratly measure the istropic BRDFS within a single 2D slice. However,Jonathan (Dupuy and Jakob, 2018)used a laser machine to measure the NDF values of materials to adaptive sample the hemisphere domain. Liu(Liu et al., 2023a) ues meta-learning method to optimize the sampling count of different brdf models."}, {"title": "2.2 Neural (SV)BRDF Capture", "content": "Researchers are exploring deep learning methods to develop lightweight approaches for measuring (SV)BRDF values(noa, a). Generally, these methods involve training a network to predict (SV)BRDF parameters such as albedo, diffuse reflection, and rough-ness.\nValentin(Deschaintre, 2023) use encoder-decoder network to estimate the normal,diffuse albedo,and roughness images from phone-captured images. Xi-uming(Zhang et al., 2021) uses images as input to predict BRDF values for each pixel based on NeRF output. Zhen(Zheng, 2024) use a diffusion framework to decomposite RGB images to normal, albedo, roughness, metallicity and diffuse maps.\nWe use a small network to accelerate the measure process and validate our method in MERL dataset."}, {"title": "3 APPROACH", "content": "Typically, BRDF model encompass both analytic functions and empirically measured values. Our method employs a Convolutional Neural Network (CNN) encoder to estimate the BRDF parameters of an analytic model from a single image. Subsequently, importance sampling techniques are used to derive an adaptive sampling pattern for the input material.\nFurthermore, these sampling values are used to render the estimated image, and the image loss is calculated to determine the optimal sample number, as illustrated in Fig. 2. In this work, we present a novel lightweight approach for sampling the mea-sured BRDF based on an analytic model. To validate the accuracy of our approach, we conduct a virtual acquisition experiment using the MERL database."}, {"title": "3.1 BRDF Estimation", "content": "Drawing inspiration from deep learning techniques used in SVBRDF capture from images, we train a convolutional neural network to encode isotropic material images into their corresponding appearance pa-rameters for a set of analytical models. We focus on small network architectures and train them using a combination of synthetically generated image and BRDF data, and fine tune with real captured data. The architecture of the BRDF estimation network is illus-trated in Fig. 3 and employs sigmoid activation func-tions for the parameter outputs."}, {"title": "3.1.1 Ward BRDF model", "content": "We use the Ward BRDF model parameterized by its specular $p_s=1-p_d$,roughness $\\alpha$ and albedo $p_d$ to train the network. The isotropic Ward BRDF $f_r(i, o)$ with incoming direction i and outgoing directin o is:\n\n$f_r(i, o) = \\frac{p_d}{\\pi} + \\frac{p_s}{4\\pi\\alpha^2 \\sqrt{\\cos \\theta_i \\cos \\theta_o}} e^{-\\frac{tan^2 \\theta_n}{\\alpha^2}}$\n\nwhere $\\theta_i$,$\\theta_o$, $\\theta_n$ is the incoming angle, outgoing angle, half angle."}, {"title": "3.1.2 Merl Dataset", "content": "We also use Measured BRDFs Dataset (MERL) to validate this work. We predict alpha $\\alpha$ for each im-age by training from scratch the nerual brdf network.\n\n$f_r(i,o) = f_{ggx}(\\alpha)$\n\nwhere $f_{ggx}$ is microfacet brdf model to represent the reflectance. We optimize the network to minimize the loss between estimation and ground truth of alpha value and images.\n\n$L_{loss} = ||\\hat{I}-I||_1 + || (\\hat{\\alpha}) - (\\alpha) ||_2$\n\nThe ground truth alpha values for each MERL mate-rial are derived by fitting their respective total BRDF data to microfacet BRDF model (Zhang et al., 2021; Zheng et al., 2022). Based on the BRDF parameters estimated by the network, the estimated images $\\hat{I}$ are rendered using the Microfacet BRDF model. We em-ployed an L1 loss between the predicted images $\\hat{I}$ and the ground truth images $I$, while an L2 loss was ap-plied to the parameter estimates."}, {"title": "3.2 Adaptive Reflectance Sample", "content": "Using the BRDF estimation network, we are able to derive the BRDF parameters from an input image. We draw inspiration from prior work and utilize the inverte BRDF importance sampling to drive a adap-tive sampling distribution of the outgoing hemisphere similar with Jakob's and YAOYI 's research (Bai et al., 2023). This adaptive sampling strategy effec-tively minimizes measurement time by targeting only those directions specified by the input BRDF material pattern. For instance, in the case of a mirror-like ma-terial, sampling is concentrated on the delta regions directly opposite the incoming light direction. In con-trast, for diffuse materials, a uniform sampling pattern is implemented throughout the hemisphere. In prac-tice, the BRDF sampling pattern for most materials typically falls between these two extremes.For more detailed explanation of importance sample, we can re-fer to Bai et al. (Bai et al., 2023).\nThe rendering equation of general BRDF model is as follows:\n\n$I(i) = \\int_{\\Omega} f_p fr (i,g(u)) L_i(g(u)) ||Jg (u) || du$\n\n$L_i$ is the incident radiance, $I_i$ is the intensity of integra-tion, where $Jg$ is the Jacobian of $g$.\n\n$p (\\omega_o) = w_d \\cdot P_d (\\omega_o) + w_s \\cdot P_s (\\omega_o)$\n\nwhere $w_d + w_s = 1$, $p(\\omega_o)$ is the PDF of outgoing di-rection $\\omega_o$. The diffuse PDF $p_d$ is a simple cosine-"}, {"title": "3.2.1 Ward Importance Sampling", "content": "For Ward brdf model, the importance sampling equa-tion is as below:\n\n$\\theta_h = arctan(\\alpha\\sqrt{-log u_1})$\n\n$\\Phi_h = 2\\pi u_2$\n\nwhere $\\theta_h, \\theta_h$ is the half angle; $u_1,u_2$ is the uniform variates on $[0,1]^2$. Then,we compute the inverse of the function 7, to evaluate the measured brdf values in rendering equation by equation 8.\n\n$u_1 = e^{\\frac{-tan^2 \\theta_h}{\\alpha}}$\n\n$u_2 = \\frac{\\Phi_h}{2\\pi}$\n\nThen, we use $\\omega_o = 2(W_h\\cdot W_i)W_h - W_i$ to determines the outgoing direction $\\omega_o (\\phi_h, \\theta_h)$."}, {"title": "3.2.2 MERL Dataset", "content": "Not similarly to the Ward model, an analytical func-tion for obtaining the probability density function (PDF) values is not available for the MERL dataset. Therefore, we approximate the PDF using the mi-crofacet BRDF model (Dupuy,) and employ its im-portance sampling method to achieve adaptive mea-surements. Additionally, we utilize the inverse of this function in the rendering process. Detailed functions and methodologies can be found in (Dupuy, ).\nFinally, we adaptive sampled the outgoing direc-tion according to PDF values is employed to get the measurements of BRDF. These measurements can guide the goniometers, facilitating precise and effi-cient measurement of the input material, meantime reducing capture time.The incoming directions are uniformly sampled within the cosine-weighted hemi-sphere."}, {"title": "4 Implemantation", "content": "We use Mitsuba 3.0 (noa, b)and its Python bindings to render these 256 \u00d7 256 images and PyTorch to im-plement the network."}, {"title": "4.1 Dataset", "content": "To train the neural network of Ward BRDF model, we create a dataset covering the full range of Ward BRDF parameter-a. Images with varying roughness and diffuse values were rendered using the Ward BRDF function, a single point light source, and a sphere in Mitsuba. The dataset consists of 4,000 training im-ages and 100 test images.\nSimilarly, for the MERL dataset, we fit each ma-terial to the Microfacet BRDF model. We first cre-ate datasets by rendering images with varying alpha and albedo values using the Microfacet BRDF model. These images are used to pretrain the BRDF estima-tion network, addressing the limited amount of mea-sured data in the MERL dataset. We then fine-tune the BRDF estimation network using the MERL training images, with the fitted alpha values serving as ground truth. The Microfacet dataset comprises 40,000 train-ing images and 100 test images, while the MERL dataset includes 85 training images and 15 test images rendered with different materials. Images from these datasets are provided in the supplementary materials."}, {"title": "4.2 Estimation", "content": "The BRDF estimation network are depicted in Fig. 3 We train the network in Nivida Geforce RTX 4080 with 15GB memory.\nWe demonstrate that our BRDF estimation net-work accurately predicts BRDF parameters for both the Ward model and the MERL dataset, as illustrated"}, {"title": "4.3 Sample Count", "content": "We treat the number of outgoing directions as hy-per parameters of the entire pipeline. For each ma-terial, we optimize samples numbers by the image loss between the rendered images by the measure-ments and the ground truth. In Fig. 7, we show rendered images of Aluminum bronze using sample counts ranging from 2 \u00d7 2 to 34 \u00d7 34. The images demonstrate that performance improves as the num-ber of samples increases. However, once the sample count reaches 16 \u00d7 16, performance no longer contin-ues to improve. Therefore, we select 16 \u00d7 16 as the fi-nal sample count for our measurements of Aluminum bronze.\nHowever we observe that the plot lines vary across different materials, as shown in Fig. 6. Generally, ma-terials with higher specular reflections require more samples. To minimize the size of the measurements, we set the maximum direction count to 32 \u00d7 32, as increasing the number of samples beyond this point yields visually negligible improvements for most ma-terials.\nFor the number of incident directions, we use one $ point and eight 0 points sampled from a uniform co-sine distribution, adhering to the rotational symmetry of isotropic materials. The number of directions was determined based on previous work in (Dupuy and Jakob, 2018)."}, {"title": "5 Results", "content": "In this section, we present the qualitative results and comparisons with state-of-the-art methods for BRDF acquisition. For quantitative evaluations, we em-ploy metrics as Peak Signal-to-Noise Ratio (PSNR), Root Mean Square Error (RMSE), and mean ALIP error (Andersson et al., 2020). Additionally, we use ALIP error maps to visualize the errors in the rendered images."}, {"title": "5.1 Rendered Results", "content": "To evaluate the two components of our method-BRDF estimation (Sec. 3.1) and adap-tive measurements (Sec. 3.2)-we present the rendered images corresponding to each section using the Ward BRDF model and MERL material in Fig. 8 and Fig. 9.\nIn Fig. 8,we show the rendered images under point lighting for visual comparison.The last image is rendered under an environment lighting to evalu-ate our measurements under novel lighting. We com-pare the rendered images obtained from ground truth BRDF values, Ward BRDF parameters estimated by the BRDF network, and adaptive sampling measure-ments-all of which appear visually almost identical.\nIn Fig. 9,we use the Merl Material-Alum-bronze- to show the rendered images under point lighting. In the first row, we compare the images rendered using the ground truth measurements and our adaptive mea-surements, which appear almost visually identical. In the second row, we show the rendered image of our measurements under a novel environment light and the corresponding ILIP error image compared to the ground truth under the same environment lighting."}, {"title": "5.2 Comparison", "content": "Here, we compare our method with the state of the art method meta-learning brdf sampling method (Liu et al., 2023a).Since Liu's method learns sample pat-terns for all materials, its performance does not im-prove with increased sample counts once highlights are captured. Additionally, it requires the implemen-tation of a fixed sample count. In contrast, we derive adaptive sampling pattern for each specific input ma-terial, allowing the performance to progressively in-crease as more samples are added. We show the com-parison of our method and Liu's method in Table 1, using the four overlapping test materials from each other's test datasets derived from the MERL dataset. And for quantitative comparison, we select results from Liu's method and our results with same sample numbers.\nThe main results of the comparison is shown in Table 1.We set same sample count for all methods. Specifically, Liu's method uses from 32 to 512 sam-ples within the Rusinkiewicz parameterization, while our approach adopts a configuration of 1 \u00d7 8 incom-ing directions($\\theta_{in}$, $\\phi_{in}$) and from 2 \u00d7 2 to 8 \u00d7 8 outgo-ing directions($\\Theta_{out}$, $\\Phi_{out}$) in spherical coordinates. We observe that our method produces rendered images for all tests with high fidelity, whereas Liu's method performs well only on specific materials. Except for pink fabric, our method outperforms Liu's approach, as demonstrated by the results shown in Table 1."}, {"title": "5.3 Evaluation on Different Materials", "content": "We show more visual results in Fig. 10 with five different materials. We observe that diffuse materi-als achieve high-quality results with fewer samples, whereas highly specular materials require a larger number of samples to produce good outcomes.The first row and second row are the rendered images us-ing our adaptive measurement method under point lighting and environment lighting, respectively. The fourth rows of Fig. 10 shows the ALIP Error im-age comparing the second row (rendered images from our method) with the third row (ground truth), where specular materials generally exhibit higher errors.The last row presents the plot of the performance metrics based on sample numbers, illustrating how the sam-ple count is selected for each material as described in section 4.3. Additional more rendered images of test materials are available in the supplementary materi-als."}, {"title": "6 Conclusion", "content": "We propose an image-based adaptive BRDF sampling method that significantly accelerates BRDF measure-ments while maintaining high accuracy and fidelity through a lightweight neural network. We validate our approach using both the MERL dataset and the Ward BRDF model. Additionally, we compare our method against the state-of-the-art method by Liu et al (Liu et al., 2023b). Our method outperforms in compari-son."}, {"title": "7 Disscusion and Limitation", "content": "Moreover, additional variants can be explored in this approach.\nSample method Normalizing Flows (M\u00fcller et al., 2019) is a possible alternative for our adaptive sampler as it can generate samples in inverse and for-ward way.Exploring the integration of Normalizing Flows into our sampling strategy could be a valuable direction for future research.\nBRDF analytic model We evaluated the Ward BRDF model and the Microfacet model. We believe that other BRDF models can also be effectively incor-porated into our approach.\nTraining and Test Dataset For our experiments, we use spherical geometry to produce rendered im-ages for both the training and test datasets. We antici-pate that replacing the sphere with a planar geometry could be feasible within our method.\nLimitation We see that the BRDF estimation net-work is sensitive to variations in light intensity. Ad-dressing this sensitivity to enhance the network's ro-bustness against different lighting conditions repre-sents an important area for future work."}]}