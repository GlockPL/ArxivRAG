{"title": "Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks", "authors": ["Ammar Ahmed Pallikonda Latheef", "Alberto Santamaria-Pang", "Craig K Jones", "Haris I Sair"], "abstract": "Brain networks display a hierarchical organization, a complexity that poses a challenge for existing deep learning models, often structured as flat classifiers, leading to difficulties in interpretability and the 'black box' issue. To bridge this gap, we propose a novel architecture: a symbolic autoencoder informed by weak supervision and an Emergent Language (EL) framework. This model moves beyond traditional flat classifiers by producing hierarchical clusters and corresponding imagery, subsequently represented through symbolic sentences to improve the clinical interpretability of hierarchically organized data such as intrinsic brain networks, which can be characterized using resting-state fMRI images. Our innovation includes a generalized hierarchical loss function designed to ensure that both sentences and images accurately reflect the hierarchical structure of functional brain networks. This enables us to model functional brain networks from a broader perspective down to more granular details. Furthermore, we introduce a quantitative method to assess the hierarchical consistency of these symbolic representations. Our qualitative analyses show that our model successfully generates hierarchically organized, clinically interpretable images, a finding supported by our quantitative evaluations. We find that our best performing loss function leads to a hierarchical consistency of over 97% when identifying images corresponding to brain networks. This approach not only advances the interpretability of deep learning models in neuroimaging analysis but also represents a significant step towards modeling the intricate hierarchical nature of brain networks.", "sections": [{"title": "1 Introduction", "content": "Resting-state fMRI (rs-fMRI) has emerged as a key method for investigating brain connectivity, facilitating the study of the brain's functional networks. [5]. Traditional computational techniques, including General Linear Models (GLM) [11], Independent Component Analysis (ICA) [12], and Graph Theoretical approaches [3], have been used"}, {"title": "2 Dataset", "content": "Our study utilized the Beijing cohort dataset from the publicly accessible 1000 Functional Connectomes Project [25]. This dataset comprises resting-state fMRI (rs- fMRI) data from 198 young adults, including 76 males and 122 females, all aged between 18 and 26 years. The fMRI data for each participant consisted of 33 slices captured over 225 timepoints. We employed the FMRIB Software Library (FSL) [24] for data processing, adhering to established protocols for motion correction, spatial smoothing, temporal high-pass filtering, and aligning the data with the Montreal Neurological Institute (MNI) standard space. After processing, we performed a visual assessment of the data quality. This meticulous evaluation led to a refined dataset comprising 176 subjects [28].\nTo identify brain networks, we applied group Independent Component Analysis (ICA) [19], with the ICA order-representing the number of components-treated as a variable. We conducted five distinct runs of group ICA at varying component orders: 20, 40, 60, 80, and 100. To integrate the group ICA findings back into individual participant data, we used dual regression [20], a technique that projects the group ICA maps onto the individual fMRI data of each subject. For our analysis, the input ICA maps were generated by back-projecting these group ICA results onto the individual subject maps using dual regression, covering Axial, Sagittal, and Coronal views. These views were then combined into a single RGB image-Axial in red, Sagittal in green, and Coronal in blue-to produce composite input ICA maps that visually represent the brain networks."}, {"title": "3 Emergent Language Symbolic Autoencoder (ELSA)", "content": "Previous research on Emergent Language (EL) introduced Symbolic Semantic Segmentation and Symbolic Variational Autoencoders [10]. These approaches utilize sender-receiver framework to produce symbolic sentences. These sentences contain semantic details of segmentation or image content. In our current work, we aim to further explore the potential of EL by focusing on the semantic and hierarchical structures inherent in brain networks. Specifically, we seek to create semantic images that accurately reflect the learned hierarchical organization of resting-state brain networks, thereby extending the interpretability and application of EL in neuroradiology.\nWe formalize ELSA as the process of integrating symbolic sequences with corresponding visual representations through a hierarchical generative model. Let the vocabulary, \u03a3 = {S1, S2, ..., Sn}) denote a set of symbols from which sequences are formed. A sequence S = (S1, S2, ..., Sk), with s\u2081 \u2208 \u2211, 1 \u2264 i \u2264 k and k \u2264 n represents a specific arrangement of symbols. The task for the generative model involves producing a mapping M: S \u00d7 N \u2192 I, where S is a sequence of symbols, N is the natural numbers denoting the sequence's length, and I represents the space of generated images. For a given sequence S, the mapping is defined as:\n1. For each prefix of S, denoted S = (S\u2081, ..., s\u2081), there exists a corresponding image Is\u2081 that visually encapsulates the information contained in S\u012f.\n2. The mapping M thus generates a set of pairs {(Si, Is\u2081)}=1,, where each pair consists of a prefix of the sequence S and its associated image Is\u2081.\nThis model requires the generative network to not only recognize and encode the symbolic information within S but also to iteratively construct a visual representation for each incremental addition to the sequence. The final output is a collection of images {Is\u2081}=1that represent the hierarchical structure embedded within the sequence S, showcasing the network's capability to translate symbolic data into coherent visual signals. The loss function is estimated from the collection of images {Is\u2081}=1 which represent a hierarchical structure.\nThe mathematical description of the CNN-Based Encoder-Decoder architecture within the Emergent Language (EL) framework is detailed as follows:\nCNN-Based Encoder: Let us define_P = {Is\u2081}=1 as the sequence of images corresponding to different Independent Component Analysis (ICA) component maps. The encoder is composed of four Convolutional Neural Network (CNN) layers [21] followed by two linear layers, mathematically represented by: Encoded = L2\u3002CNN\u2084\u3002...\u3002CNN\u2081(P) where CNN; is the jth CNN layer and L\u012f is the ith linear layer. This structure distills the features from P into a compact latent representation.\nTransmission to EL Encoder (Sender): This encoded representation is then passed to the EL encoder (sender), transforming it into a sequence of discrete symbols, represented as EL_Encoded = Sender(Encoded). The sender network converts the CNN-encoded ICA maps into sequences of discrete categorical variables [16][17], forming symbolic sentences that encapsulate hierarchical information [8][10].\nEL Decoder (Receiver) Processing: Diverging from models where the receiver only processes the final hidden state [18], our receiver decodes every hidden state from the sender, allowing for iterative image reconstruction at each symbol in the sentence. For each symbol si and its corresponding hidden state hi, the decoder produces a partial reconstruction Ri, iterating over the sentence length N: R\u2081 = Decoder(hi), Vie {1, ..., N}. This iterative decoding permits the reconstruction of multiple images, each correlating to the cumulative sequence of symbols.\nCNN-Based Decoder: The output from the EL decoder is then processed through a CNN-based decoder, comprising two linear layers and four CNN layers, tasked with the final reconstruction of the ICA map. This process can be denoted as:\nReconstructed ICA Map = CNN\u012b\u00b9\u3002...\u3002CNN\u00af\u00b9\u3002L\u00af\u00b9(EL_Decoded) . Here, CNN;\u00af\u00b9 and L\u012b\u00b9 represent the inverse operations of the CNN and linear layers in the decoder, respectively, with EL_Decoded as the output from the EL decoder.\nWe introduce a general framework allows us to specify the type of loss calculation based on the model's current training objective and the hierarchical nature of the data being processed. We define a hierarchical generalized loss function Lh that can adapt based on two key parameters: a and \u03b2. These parameters control the scope of the loss computation (over the entire sequence or progressively) and the strictness of the evaluation (considering each output versus the final output). Given a sequence S =\n(S1, S2, ..., Sk) and its corresponding generated images {Is\u2081}}=1, and the original input image X, the generalized loss function can be represented as:\n$L_h(X, {I_{s_i}}; \u03b1, \u03b2) = L_{cb}(X, I_{s_{\u03b1k}}) + \u03b2 \u00b7 \\sum_{i=1}^{\\alpha k - 1} L_{cb}(X, I_{s_i})$ (1)\nWhere, a is a parameter that determines the coverage of the sequence. For a = 1, the loss is calculated over the entire sequence. For 0 < a < 1, the loss calculation is progressively limited to the first ak terms of the sequence, where k is the total length of the sequence. \u03b2 is a binary weight that decides whether the loss function considers the first ak - 1 terms.\nThe term Lcb is a containing bias term to encourage the model to create broader representations when suitable, i.e., in the initial symbols of a sentence. We apply Wlarge weight when a pixel in the output image is larger than the corresponding pixel in the input image, and Wsmall when a corresponding pixel in the output image is smaller than the corresponding pixel in the input image. Given input image X and an output image I, both flattened and consisting of N pixels, the containing bias loss, Lcb is expressed as:\n$L_{cb}(X, I) = (1/N) ( \\sum_{i=1}^{N} W_{small} (I_i - X_i)^2, I_i < X_i + \\sum_{i=1}^{N} W_{large} (I_i - X_i)^2, I_i \u2265 X_i)$ (2)"}, {"title": "4 Experiments and Results", "content": "The hierarchical generalized loss function accommodates various training objectives and data hierarchies by adjusting a and \u03b2. We apply the \"regular\" loss function used in previous works by setting a = 1 and \u03b2 = 0. We create the \"strict\" loss function by setting \u03b1 = 1 and \u03b2 = 1. We create the \"progressive\" loss function by setting a according to the ICA order of input image and \u03b2 = 0. Finally, our \u201cprogressive strict\u201d loss function is created by setting a according to input image ICA order and \u03b2 = 1.\nWe use our model to generate hierarchical sentences, which can be systematically organized. They represent input ICA maps and vary in length according to the granularity of the group ICA orders applied to the fMRI data (20, 40, 60, 80, 100). With increasing ICA orders, the components represent more specific brain network subcomponents or functions. The hierarchical nature means that sentences of different lengths correspond to ICA maps of different orders. The capability of ELSA to generate hierarchical sentences mirrors the granularity inherent in the input ICA maps, informed by the group ICA orders (20, 40, 60, 80, 100) applied to the fMRI data (detailed in Section 2). These ICA orders establish a tiered model that unveils increasingly precise features of brain network components or functions. For example, a broader correlation among brain networks is observed with 20 independent components, whereas more detailed representations emerge at 100 independent components. This tiered approach results in sentences of variable lengths that correspond to distinct ICA orders. As illustrated in Figure 2, segments of each sentence are highlighted to signify their relevance to the represented ICA order, with the unhighlighted portions considered as expansions by the model. Each dataset entry correlates with a unique ICA component derived from individual participants, with the model crafting a specific five-word sentence for each analyzed ICA volume. For instance, the Default Mode Network (DMN) is represented by the sentence (12), and its association with the Inferior Parietal Lobule (DMN-IPL) is articulated through the sentence (12, 33). Notably, in the context of an ICA order of 100, all sentence symbols are accentuated, whereas for an ICA order of 80, only 80% of the symbols (4 out of 5) are emphasized, as demonstrated in Figure 2.\nPast works in EL did not evaluate the hierarchical consistency within generated sentences. To measure hierarchical consistency at a given ICA order (or sentence length as defined in fig 2), we calculate the percentage of sentences of the given ICA order with shared common prefix (of length defined by the given ICA order) with sentences of ICA order 100, that also have the same parent network. Thus, we calculate an accuracy value for each ICA order.\nQualitative Results: Figure 3 shows the progressive reconstructions of two ICA input images, the first is an Attention Dorsal IPS Lateral Right network and the second is an Attention Dorsal IPS Mid network using the progressive strict with containing bias loss function. The result shows the capability of our model to create interpretable, hierarchical progressions of images from their parent-like networks in the initial symbols to the specific network by the final symbol. But we do observe that from symbol 1 to symbol 2, the activations do not become more specific, instead they shift. Suboptimal reconstructions for symbol 1 were common across various images, indicating one of the limitations of our work. Figure 4 shows the effect of our newly introduced loss functions. Note that the regular loss function does not create sequences that can be interpreted as a hierarchical progression from parent-like to the specific network. Utilizing the strict loss function yields interpretable progression, however it does not seem hierarchical. On the other hand, our progressive strict with containing bias loss function does give such a hierarchical sequence of images, going from broad parent-like representations to more specific representations."}, {"title": "5 Conclusion", "content": "Our study presents an innovative method for modeling hierarchical brain networks using a weakly supervised deep learning framework, enriched with Emergent Language (EL). Through the introduction of progressive loss functions and a novel evaluation method for assessing hierarchical consistency, we have successfully applied EL to hierarchically structured medical imaging data. Our findings reveal that these progressive loss functions result in more interpretable hierarchical reconstructions than those achieved with traditional loss functions."}]}