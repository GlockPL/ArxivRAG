{"title": "Vision-Integrated LLMs for Autonomous Driving Assistance : Human Performance Comparison and Trust Evaluation", "authors": ["Namhee Kim", "Woojin Park"], "abstract": "Traditional autonomous driving systems often struggle with reasoning in complex, unexpected scenarios due to limited comprehension of spatial relationships. In response, this study introduces a Large Language Model (LLM)-based Autonomous Driving (AD) assistance system that integrates a vision adapter and an LLM reasoning module to enhance visual understanding and decision-making. The vision adapter, combining YOLOv4 and Vision Transformer (ViT), extracts comprehensive visual features, while GPT-4 enables human-like spatial reasoning and response generation. Experimental evaluations with 45 experienced drivers revealed that the system closely mirrors human performance in describing situations and moderately aligns with human decisions in generating appropriate responses. Semantic similarity metrics, including METEOR and BERT scores, validated the system's reasoning capabilities, while Trust in Automation (TiA) assessments showed increased user trust after interaction. Despite challenges in replicating the diverse cognitive processes of human drivers, this system demonstrates significant potential for augmenting human decision-making in autonomous driving technologies and provides a foundation for further development toward practical deployment.", "sections": [{"title": "I. INTRODUCTION", "content": "AUTONOMOUS driving (AD) technologies have advanced significantly, demonstrating their transformative potential in transportation systems [8], [11], [30], [50]. The integration of AI has been instrumental in enabling critical functionalities such as perception, decision-making, and motion planning [18], [23], [24], [29], [38]. However, achieving higher levels of autonomy and real-world deployment still faces persistent challenges, particularly in handling complex and unstructured driving scenarios [7], [8], [19], [21].\nIn recent years, the application of Large Language Models (LLMs) in AD research has gained attention due to their advanced reasoning and common-sense understanding capabilities [1], [9], [15]. Studies have shown that LLMs can support autonomous systems by interpreting multimodal data and generating human-like responses in decision-making processes [49], [53]. Despite this potential, LLM-based systems often struggle with spatial reasoning, which is crucial for navigating dynamic environments [3], [10], [39]. This limitation highlights the need for novel approaches to enhance their ability to understand and act upon spatial relationships in real-world scenarios [58].\nTo address these challenges, this study proposes a vision-integrated LLM-based AD assistance system and evaluates its effectiveness by comparing its reasoning and decision-making capabilities to those of human drivers. Through this comparison, the study aims to provide insights into how such systems can complement human cognitive processes, enhance trust in autonomous technologies, and advance the broader understanding of Al-assisted decision-making in complex driving scenarios. This research seeks not to replicate human behavior but to explore the potential of vision-integrated LLMs in supporting and augmenting human decision-making in autonomous driving contexts."}, {"title": "B. Related Works", "content": "Autonomous driving systems have long relied on AI-driven advancements to address challenges in perception, decision-making, and control. Deep Neural Networks (DNNs), for instance, have significantly enhanced the capabilities of AD systems in tasks such as object detection, scene understanding, and trajectory prediction [23], [32], [34], [36]. Similarly, Deep Reinforcement Learning (DRL) has proven effective in optimizing motion planning and decision-making processes, enabling vehicles to adapt to dynamic and uncertain environments [6], [25], [27]. These advancements have laid the foundation for the development of Level 1 and Level 2 ADAS, which provide essential safety and convenience features in commercial vehicles [2]. Despite these achievements, higher levels of autonomy present new challenges that require more sophisticated approaches [17], [20], [26].\nRecent research has explored the potential of LLMs to enhance the cognitive capabilities of AD systems [33]. LLMs are known for their advanced reasoning abilities, common-sense understanding, and human-like communication skills, making them promising candidates for improving decision-making in autonomous vehicles [1], [12], [16], [53]. Studies have demonstrated their utility in deriving driving decisions through prompt engineering, where textual descriptions of the environment guide the system's responses [43], [45], [51]. Moreover, fine-tuning LLMs on multimodal datasets has further expanded their applicability. For example, DriveGPT4 and RAG-Driver use real-world driving videos to predict throttle and steering angles, while DriveMLM and LMDrive incorporate simulation data to plan trajectories and understand contextual elements [44], [49], [53], [54]."}, {"title": "C. Contribution", "content": "This study examines the potential of a vision-integrated LLM-based framework for AD assistance systems to address challenges in spatial reasoning and decision-making in complex driving environments. By integrating a vision adapter, which combines YOLOv4 and ViT, with an LLM reasoning module, the proposed system enhances its ability to interpret spatial relationships and generate contextually appropriate responses. The focus of this research is on evaluating its performance in comparison to human drivers to explore its alignment with human cognitive processes.\nTo this end, the study compares the outputs of the vision-integrated LLM system with human reasoning across scenarios involving unexpected driving situations. Using experimental designs that involve image-video pairs, the research investigates the system's ability to describe situations accurately and make decisions that are consistent with human responses. By analyzing similarities and differences, this study provides insights into how such systems can support and augment human decision-making rather than replicate it.\nThis research emphasizes the broader implications of integrating vision and language models in autonomous driving, contributing to a deeper understanding of how these systems can enhance trust and reliability in real-world applications. Through its evaluation-driven approach, the study lays the groundwork for designing AD assistance systems that better align with human cognitive expectations, fostering safer and more adaptive autonomous technologies."}, {"title": "D. Paper Organization", "content": "The remainder of this paper is organized as follows.\nSection II describes the methodologies, focusing on the design of the model architecture, the datasets used, and the training process. Section III outlines the experimental setup and data collection methods, including participant tasks and the procedures for gathering and preparing data. Section IV presents the results and analysis, covering system performance, human-Al response similarity, and the impact of the system on user trust levels. Section V discusses the implications of the findings and highlights areas for future work. Finally, the paper is concluded in Section VI."}, {"title": "II. METHODOLOGIES", "content": "This section describes the model framework that is used in this study. Specifically, Section II-A presents the system's architecture, integrating vision and language components, while Section II-B outlines the training process, including preprocessing and evaluation strategies."}, {"title": "A. Model Architecture and Datasets", "content": "The proposed LLM-based autonomous driving assistance system consists of two core components: a vision adapter and a LLM. The vision adapter processes visual inputs and extracts relevant features, which are then used by the LLM to generate situation descriptions and determine appropriate responses.\nThe vision adapter integrates YOLOv4 for object detection and a pre-trained ViT for spatial relationship analysis [22], [31], [55]. YOLOv4 employs a grid-based approach to detect objects, while ViT divides the input image into patches and identifies relationships between them. The extracted features are aligned with the LLM's embedding space using a linear projection layer, facilitating seamless interaction between the visual and language components [56].\nThe LLM, based on GPT-4, is used as the reasoning module to convert visual features into text-based outputs. During deployment, the temperature parameter of GPT-4 was set to 0.7, balancing creativity and precision in the generated responses. A higher temperature (e.g., >0.9) was avoided as it could lead to overly varied and inconsistent outputs, while a lower temperature (<0.5) risked generating overly deterministic responses, limiting adaptability to diverse driving scenarios. The selected temperature ensured the system provided coherent yet contextually flexible outputs, aligning with the requirements for autonomous driving scenarios.\nFor training, the Berkeley DeepDrive (BDD100k) dataset was utilized, offering a diverse range of real-world driving scenarios, including variations in geography, weather, and traffic conditions [52]. This dataset contains annotated data for 10 object classes, such as cars, pedestrians, traffic lights, and bicycles, making it suitable for both object detection and contextual reasoning tasks. The dataset's comprehensive coverage of urban and highway driving scenarios allowed the model to generalize effectively to various environments."}, {"title": "B. Model Training", "content": "The model training process adhered to a supervised learning framework, where the system was trained to map input data to corresponding outputs. To ensure robust evaluation and prevent data leakage, the dataset was divided into training (80%) and validation (20%) subsets. This commonly used partitioning ratio balances model optimization during training with performance assessment on unseen data [14], [57].\nBefore training, the dataset underwent preprocessing to standardize image pixel values to a [0, 1] range. To improve the model's robustness and generalizability, data augmentation techniques such as flipping, rotation, cropping, and brightness adjustment were applied. These steps ensured that the model could adapt to diverse driving scenarios, including variations in lighting, weather, and traffic density.\nThe training process employed the Adam optimizer, with the initial learning rate set to 0.001, enabling efficient weight updates for object detection tasks [40]. YOLOv4, designed for grid-based object detection, was trained using this setup, while the ViT, pre-trained on ImageNet, was fine-tuned with the BDD100k dataset to adapt its spatial reasoning capabilities to real-world driving environments [13]. Batch normalization and dropout techniques were applied throughout training to mitigate overfitting, ensuring the model's generalizability across diverse inputs.\nThe integration of the Vision Adapter and GPT-4 was achieved by aligning visual features with the language model's embedding space through a linear projection layer. This alignment allowed GPT-4 to effectively reason about spatial relationships and generate contextually appropriate outputs.\nThe temperature parameter of GPT-4 was set to 0.7 during deployment, striking a balance between creativity and precision in the generated responses. Lower temperatures (<0.5) were avoided to ensure adaptability in diverse scenarios, while higher temperatures (>0.9) were avoided to maintain response consistency.\nModel performance was continuously monitored during training using standard metrics, including precision, recall, and F1-score. Validation was conducted after every epoch to assess the model's ability to generalize to unseen data. To prevent overfitting and ensure optimal convergence, early stopping was implemented, halting training if validation loss did not improve for five consecutive epochs.\nBy combining rigorous preprocessing, robust training methodologies, and a high-performance computing environment, the system was optimized for accurate and reliable operation in complex driving scenarios."}, {"title": "III. EXPERIMENT AND DATA COLLECTION", "content": "This section describes the experimental design and data processing for evaluating the proposed system's performance and its impact on user trust. It outlines the experimental procedure, including participant tasks and assessments, as well as the methods for data collection and analysis."}, {"title": "A. Experimental Procedure and Participants", "content": "The experimental procedure was designed to evaluate the performance of the proposed system and its influence on user trust. Participants were invited to interact with the system by observing visual stimuli, including images and videos depicting unexpected and challenging driving scenarios, and performing cognitive reasoning tasks based on the observed content. The experiment was structured into three sequential stages to ensure a comprehensive assessment of user trust and system performance.\nFirst, participants underwent an Initial Trust Assessment to establish baseline trust levels in the system. For this purpose, they completed the Trust in Automation (TiA) scale [28], a validated instrument designed to evaluate multiple dimensions of trust in automated systems. The TiA scale measures trust across six components: reliability/competence, understanding/predictability, familiarity, intention of developers, propensity to trust, and overall trust in automation. By addressing these dimensions, the TiA scale provided a nuanced understanding of participants' initial trust levels, offering a baseline against which changes in trust could be measured throughout the experiment.\nNext, during the Task Execution phase, participants were presented with three distinct driving scenarios, each representing a unique and high-stakes situation designed to reflect real-world challenges. The first scenario, An Abrupt Lane Change Necessitated by an Accident Ahead, involved a sudden maneuver required to avoid a blocked lane caused by a traffic accident. The second scenario, A Vehicle Rollover Accident due to a Sudden Obstacle, described a situation where a vehicle lost control and overturned after encountering an unexpected obstacle. The third scenario, A Multi-Vehicle Collision Caused by Severe Weather Conditions, depicted a chain-reaction crash initiated by low visibility and hazardous weather. For each scenario, participants were instructed to provide a detailed situation description, outlining their observations of the key elements and context of the event. In addition, they were required to articulate at least two appropriate responses for each case, proposing effective strategies to address the challenges presented. These responses needed to draw on their personal driving experience and consider both immediate actions and long-term preventative measures.\nFinally, in the Final Trust Assessment, participants were shown the AI-generated responses for the same driving scenarios they had previously analyzed. After reviewing the system's outputs, they completed a post-trust evaluation using the TiA scale to reassess their trust levels. This step facilitated a direct comparison between participants' initial trust levels and their perceptions after interacting with the system's outputs.\nA total of 45 participants were recruited, comprising both men and women with a minimum of five years of driving experience. Ethical approval for the study was granted by the Institutional Review Board of Seoul National University (Protocol 2407/004-009), and informed consent was obtained from all participants before the experiment."}, {"title": "B. Experimental Data Collection", "content": "Experimental data were collected to evaluate the system's reasoning capabilities and its effect on user trust. Participants generated textual situation descriptions and appropriate responses for three driving scenarios. These responses were compared with the system's outputs to assess semantic similarity [41].\nTo measure trust levels, the TiA scale was administered both before and after the experiment. The TiA scale consists of 19 items covering five dimensions: reliability/competence, familiarity, trust, understanding, and intention of developers. Each item was rated on a 5-point Likert scale ranging from 1 (strongly disagree) to 5 (strongly agree). This provided a quantitative measure of changes in trust resulting from interaction with the system."}, {"title": "IV. EXPERIMENT RESULTS AND ANALYSIS", "content": "This section presents the results and analysis of the experiment, focusing on system performance, human-AI response similarity, and changes in user trust. Key findings include the evaluation of the vision adapter's performance, the semantic alignment of AI-generated outputs with human reasoning, and statistical analysis of trust level differences."}, {"title": "A. Experimental Data Analysis", "content": "The analysis of experimental data was conducted using the following approaches:\n1) Vision Adapter Performance: The vision adapter's object detection and classification capabilities were evaluated using precision, recall, and F1-score, which are standard performance metrics in computer vision [14]. These metrics provided insights into the system's ability to accurately identify and describe objects within driving scenarios. Data analysis for this evaluation was performed using Python libraries to compute the performance metrics.\n2) Human-AI Similarity: Two independent experts assessed the semantic similarity between human-written and AI-generated responses using a 5-point Likert scale. This evaluation determined how closely the system's outputs aligned with human reasoning, with scores ranging from 1 (completely dissimilar) to 5 (highly similar).\n3) Trust Level Analysis: Changes in trust levels were analyzed using paired t-tests, comparing pre- and post-experiment TiA scores. Statistical significance was determined at a 95% confidence level (p < 0.05). Effect sizes (Cohen's d) were calculated to assess the magnitude of trust changes, providing additional insights into the system's influence on user confidence [16]. Data analysis was performed using Python libraries and SPSS."}, {"title": "B. Evaluation of Vision Adapter Performance", "content": "The proposed LLM-based autonomous driving assistance system was tested on three unexpected driving scenarios: abrupt lane changes due to accidents ahead (case 1), vehicle rollovers caused by sudden obstacles (case 2), and multi-vehicle collisions under severe weather conditions (case 3). Each scenario was selected to evaluate the system's ability to generate accurate situation descriptions and appropriate responses.\nThe vision adapter, combining YOLOv4 and ViT, demonstrated high accuracy in object detection and spatial relationship analysis. For object detection, the adapter achieved a precision of 89.5%, recall of 91.2%, and an F1-score of 90.3%. These metrics indicate the system's robust performance in identifying objects such as \"white pickup truck\" and \"cargo truck\" and providing detailed descriptions including directions \"left,\" \"right,\" and \"front\"."}, {"title": "C. Evaluation of Human-AI Response Similarity", "content": "To evaluate the similarity between human and Al responses, two independent experts analyzed the textual outputs for 45 participants across three scenarios. Each participant provided both a situation description and an appropriate response, yielding a total of 540 evaluation scores (45 participants \u00d7 3 images \u00d7 2 response categories \u00d7 2 experts).\nThe analysis revealed an average similarity score of 4.20 (SD = 0.80, SE = 0.05) for situation descriptions, indicating strong alignment with human-generated outputs. For appropriate responses, the average similarity score was 3.38 (SD = 0.95, SE = 0.06), suggesting moderately lower agreement (Table III). Fig. 2. visualizes these results, emphasizing the AI system's strength in visual recognition while also highlighting its reliance on standardized responses. This reliance limits the variability and contextual adaptability observed in human responses."}, {"title": "D. Analysis of Trust Level Differences", "content": "To measure changes in user trust, pre- and post-experiment scores were collected using the TiA scale, consisting of 19 items rated on a 5-point Likert scale. A paired samples t-test revealed a statistically significant increase in trust, with mean scores rising from 50.70 (SD = 12.18) to 59.97 (SD = 15.16) (t(44) = 5.030, p < .001) (Table VI). This corresponds to an average trust increase of 9.27 percentage points (95% CI [5.55, 12.98]), demonstrating the AI system's positive influence on user confidence (Table VII). Effect size analysis further supported the significance of this improvement, with a Cohen's d value of 0.750 (95% CI [0.415, 1.078]) and Hedges' g of 0.737 (95% CI [0.408, 1.059]) (Table VIII). Additionally, a moderate positive correlation was observed between pre- and post- experiment trust levels (r = 0.610, p < .001), indicating that participants with higher initial trust were more likely to maintain or improve their confidence. This trend is visualized in Fig. 3. No significant correlations were found between trust levels and demographic variables such as age or gender, suggesting consistent trust improvements across diverse participant groups. These findings highlight the potential of user-friendly AI systems to foster trust, particularly in safety-critical applications like autonomous driving."}, {"title": "V. DISCUSSION", "content": "This study developed and evaluated a vision-integrated LLM-based AD assistance system, demonstrating its potential to enhance reasoning processes in complex driving scenarios. The findings revealed that the system achieved high similarity to human performance in situation description tasks, showcasing its ability to effectively recognize and interpret objects and their spatial relationships in visual scenes. However, the system demonstrated moderately lower similarity in generating appropriate responses, highlighting the inherent complexity and variability of human decision-making, which the current system has yet to fully replicate.\nThe gap in performance between situation descriptions and appropriate responses underscores the challenges of developing Al systems capable of handling diverse and dynamic contexts. While the integration of LLMs has significantly improved reasoning capabilities, the system's reliance on standardized outputs limits its adaptability to unpredictable and context-specific situations. Future research should prioritize enhancing the system's contextual reasoning by incorporating reinforcement learning techniques and expanding training datasets to include a wider variety of scenarios. These advancements will enable the system to handle more diverse situations and provide responses that better align with human decision-making processes.\nAnother key finding of this study was the system's positive impact on user trust. Interaction with the system resulted in a statistically significant increase in trust levels, demonstrating its ability to enhance user confidence in autonomous technologies. A moderate positive correlation between initial and final trust scores indicates that participants with higher initial trust levels experienced greater confidence gains. Importantly, no significant correlations were observed between trust and demographic factors such as age or gender, suggesting the system's universal applicability across diverse participant groups."}, {"title": "VI. CONCLUSION", "content": "This study successfully developed and evaluated an LLM-based AD assistance system that integrates GPT-4 with a vision adapter, demonstrating its potential to contribute to the development of autonomous driving assistance systems. The system excelled in structured tasks, particularly in situation description, effectively recognizing and interpreting spatial relationships in visual scenes. However, its lower performance in generating appropriate responses highlights the need for further refinement to handle diverse and context-rich scenarios.\nThe findings underline the system's strengths in structured reasoning but also reveal its reliance on standardized outputs, which limits its adaptability to dynamic and unpredictable contexts. Future research should prioritize improving the system's contextual reasoning by expanding training datasets and incorporating advanced techniques to better address the variability of human decision-making.\nThese results provide a foundation for advancing LLM-based AD assistance systems. By focusing on real-world validation, leveraging advancements in LLM technologies, and addressing ethical considerations, future iterations can help develop more adaptable, reliable, and human-centered autonomous driving assistance technologies."}]}