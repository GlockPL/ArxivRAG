{"title": "A Survey on LLM-powered Agents for Recommender Systems", "authors": ["Qiyao Peng", "Hongtao Liu", "Hua Huang", "Qing Yang", "Minglai Shao"], "abstract": "Recommender systems are essential components of many online platforms, yet traditional approaches still struggle with understanding complex user preferences and providing explainable recommendations. The emergence of Large Language Model (LLM)-powered agents offers a promising approach by enabling natural language interactions and interpretable reasoning, potentially transforming research in recommender systems. This survey provides a systematic review of the emerging applications of LLM-powered agents in recommender systems. We identify and analyze three key paradigms in current research: (1) Recommender-oriented approaches, which leverage intelligent agents to enhance the fundamental recommendation mechanisms; (2) Interaction-oriented approaches, which facilitate dynamic user engagement through natural dialogue and interpretable suggestions; and (3) Simulation-oriented approaches, which employ multi-agent frameworks to model complex user-item interactions and system dynamics. Beyond paradigm categorization, we analyze the architectural foundations of LLM-powered recommendation agents, examining their essential components: profile construction, memory management, strategic planning, and action execution. Our investigation extends to a comprehensive analysis of benchmark datasets and evaluation frameworks in this domain. This systematic examination not only illuminates the current state of LLM-powered agent recommender systems but also charts critical challenges and promising research directions in this transformative field.", "sections": [{"title": "1 Introduction", "content": "In the era of information explosion, recommender systems [Wu et al., 2022] have become an indispensable component of digital platforms, helping users navigate through massive amounts of content across e-commerce, social media, and entertainment domains. While traditional recommendation approaches [He et al., 2017] have achieved considerable success in providing personalized suggestions through analyzing user preferences and historical behaviors, they still face significant challenges in real-world applications, such as limited understanding of complex user intents, insufficient interaction capabilities, and the inability to provide interpretable recommendations [Zhu et al., 2024b].\nRecent advancements in Large Language Models (LLMs) [Achiam et al., 2023] have sparked increasing interest in leveraging LLM-powered agents [Wang et al., 2024a] to address the aforementioned challenges in recommender systems. The integration of LLM-powered agents into recommender systems offers several compelling advantages over traditional approaches [Zhu et al., 2024b]. First, LLM agents can understand complex user preferences and generate contextual recommendations through their sophisticated reasoning capabilities, enabling more nuanced decision-making beyond simple feature-based matching. Second, their natural language interaction abilities facilitate multi-turn conversations that proactively explore user interests and provide interpretable explanations, enhancing both recommendation accuracy and user experience. Third, these agents revolutionize user behavior simulation by generating more realistic user profiles that incorporate emotional states and temporal dynamics, enabling more effective system evaluation. Furthermore, the pre-trained knowledge and strong generalization capabilities of LLMs facilitate better knowledge transfer across domains, addressing persistent challenges such as cold-start [Shu et al., 2024] with minimal additional training.\nIn this survey, we present a comprehensive review of LLM-powered agents for recommender systems. First, we introduce the background of traditional recommender systems and discuss their limitations in understanding complex user intents, interaction capabilities, and interpretability. We then systematically examine how LLM-powered agents address these challenges through three main paradigms: recommender-oriented (e.g., [Wang et al., 2024b; Wang et al., 2024c]), interaction-oriented (e.g., [Zeng et al., 2024; Friedman et al., 2023]), and simulation-oriented (e.g., [Yoon et al., 2024; Guo et al., 2024]) approaches. Following that, we propose a unified agent architecture consisting of four core modules (Profile [Cai et al., 2024; Zhang et al., 2024c], Memory [Shi et al., 2024; Fang et al., 2024], Planning [Wang et al., 2023b; Shi et al., 2024], and Action [Zhu et al., 2024a; Zhao et al., 2024]) and analyze how existing methods implement these"}, {"title": "2 Background", "content": ""}, {"title": "2.1 Traditional Recommendation", "content": "In conventional recommendation systems, the problem is typically formulated over a user space $U = [U_1, U_2, ..., U_m]$, an item space $I = [I_1, I_2, ..., I_n]$, and their interaction matrix $D \\in R^{m \\times n}$. The fundamental goal is to learn a preference function $p : U \\times I \\rightarrow R$ that predicts user preferences:\n$\\min_{\\theta} \\sum_{(u,i) \\in D} L(p_{\\theta}(u, i), Y_{u,i}),$ (1)\nwhere $p_{\\theta}(u, i)$ represents the predicted preference and $Y_{u,i}$ denotes the ground truth interaction. While various approaches have been proposed, from matrix factorization [Hu et al., 2008] to deep learning [He et al., 2017], these traditional methods face several inherent limitations. First, they struggle to understand complex user intents beyond numerical interactions. Second, they lack the ability to engage in meaningful interactions to explore user preferences. Third, their recommendations often appear as a \"black box\" without clear explanations for users."}, {"title": "2.2 LLM as Agent", "content": "Large Language Model (LLM) as an agent is an emerging research direction that has garnered significant attention [Park et al., 2023]. By transcending the traditional static prompt-response paradigm, it establishes a dynamic decision-making framework [Patil et al., 2023] capable of systematically decomposing complex tasks into manageable components. A typical LLM-powered agent architecture integrates four fundamental modules [Wang et al., 2024a]: (1) the Profile module,"}, {"title": "2.3 LLM Agents for Recommendation", "content": "In LLM-powered agent for recommender systems, we formulate the recommendation process through an agent-centric framework. Let $a \\in A$ denote an agent equipped with a set of functional modules $F = F_1, F_2, ..., F_K$, where each module $F_k$ represents a specific capability. The recommendation process for a user $u$ can be formally expressed as:\n$\\hat{y}_u = f(F_k(X_u)), k = 1...K,$ (2)\nwhere $X_u \\in X$ represents the input space containing user-specific information (e.g., interaction history, contextual features), and $\\hat{y}_u \\in R^N$ denotes the predicted preference distribution over the item space. The integration function $f : F_k(X_u) \\rightarrow R^N$ synthesizes module outputs to generate final recommendations. Building upon the previously introduced four functional module (Profile, Memory, Planning, and Action), this formulation provides a flexible framework that can accommodate various LLM-powered agent recommendation approaches. These modules operate in a closed-loop framework, where interaction data continuously enriches user profiles and system memory, informing planning strategies that ultimately manifest as personalized recommendations through action execution and feedback collection."}, {"title": "3 Methods", "content": "In this section, we sort out existing LLM-powered agent recommendation works based on the overall objective of the method and the agent components of different methods."}, {"title": "3.1 Method Objective", "content": "In Table 1, we classify method objectives of existing methods into three categories: recommender-oriented approaches, interaction-oriented methods, and simulation-oriented methods. The illustrations of categories are shown in Figure 1.\n(1) Recommender-oriented approaches focus on developing intelligent recommendation equipped with enhanced planning, reasoning, memory, and tool-using capabilities. In these approaches, LLMs leverage users' historical behaviors to generate direct recommendation decisions. For instance, as shown in Figure 1, when a user demonstrates recent engagement with technology news and AI-related content, the system might strategically recommend: \u201cHere are 5 articles about latest large language model breakthroughs, 3 introductory articles about machine learning basics, and 2 popular science pieces about AI's impact on society.\u201d This paradigm demonstrates how agents can effectively combine their core capabilities to deliver direct item recommendations.\n(2) Interaction-oriented methods focus on enabling natural language interaction and enhancing recommendation interpretability through conversational engagement. These approaches utilize LLMs to conduct human-like dialogues or explanation while making recommendations. For example, as shown in Figure 1, an LLM might respond to a user query with: \"I noticed that you like science fiction movies, especially after watching The Descent and Star Trek recently. Considering this preference, I would like to recommend Space Odyssey 2001, a classic film that also explores profound themes about human and alien civilizations. What do you think?\" Such interactive recommendations showcase the agent's ability to not only track user preferences but also articulate recommendations in a conversational manner, explaining the reasoning behind suggestions.\nAutoConcierge [Zeng et al., 2024] uses natural language conversations to understand user needs and collect user preferences, and uses LLM to understand and generate language, ultimately providing explainable personalized restaurant recommendations. RAH [Shu et al., 2024] is a human-computer interaction recommendation framework based on LLM agents. It realizes personalized recommendations and user intent understanding through the ResSys-Assistant-Human tripartite interaction and the Learn-Act-Critic loop mechanism.\n(3) Simulation-oriented methods aim to authentically replicate user behaviors and preferences through sophisticated simulation techniques. These approaches leverage LLMs to generate realistic user responses to recommendations. For instance, when simulating user feedback, an LLM might generate: \u201cAs a user who is keen to explore new music, I will click on this new song that combines jazz and electronic elements because it matches my interest in experimental music while maintaining the rhythmic style that I like.\u201d These methods focus on using agents to simulate user behaviors and item characteristics in RSS.\nAgent4Rec [Zhang et al., 2024a] utilizes LLM-empowered generative agents as user simulators to model authentic interactions between users and recommender systems, aiming to replicate and evaluate realistic user behaviors in recommendation environments. AgentCF [Zhang et al., 2024c] models both users and items as LLM-powered agents that autonomously interact and collaboratively learn from each other to simulate authentic user-item interactions in recommender systems. UserSimulator proposes [Yoon et al., 2024] an evaluation protocol to assess LLMs as generative user simulators in conversational recommendation through five tasks to measure how closely these simulators can emulate authentic user behaviors."}, {"title": "3.2 Agent Components", "content": "The LLM-based agent recommendation architecture consists of four main modules: Profile Module, Memory Module, Planning Module, and Action Module. Figure 2 illustrates the core components of the architecture and corresponding functions.\n(1) Profile Module is a fundamental component that constructs and maintains dynamic representations of users and items in recommender systems. Through continuous analysis of historical interactions, it captures temporal and contextual patterns in user behavior. For example, when the system observes that a user often browses technology news on weekday mornings and likes to watch travel content on weekends, the Profile Module will build a user profile of \"focusing on technology news on weekdays and preferring leisure content on weekends\". This adaptive profiling approach integrates behavioral patterns, user preferences, and external knowledge to enable highly personalized recommendations.\nThe profile module in Agent4Rec [Zhang et al., 2024a] incorporates dual components: quantifiable social traits (activity, conformity, and diversity) and personalized preferences extracted via LLM, enabling a comprehensive simulation of user characteristics. MACRec [Wang et al., 2024c] incorporates a user and item analyst, which play a crucial role in understanding user preferences and item characteristics. AgentCF [Zhang et al., 2024c] constructs natural language-based user profiles to capture dynamic user preferences and item profiles to represent item characteristics and potential adopters' preferences, enabling personalized agent-based collaborative filtering.\n(2) Memory Module serves as a contextual brain that manages and leverages historical interactions and experiences to enhance recommendation quality. It maintains a structured repository of past interactions, emotional responses, and conversational context to enable more informed decisions. For example, in a restaurant recommendation scenario, when a user comments \u201cthat Sichuan restaurant was too spicy last time\", the Memory Module retrieves the specific restaurant reference from historical interactions and incorporates this preference signal into future recommendations, helping avoid overly spicy options. Through this continuous accumulation and utilization of experiential knowledge, the module enables more personalized and context-aware recommendations that reflect users' past experiences and preferences.\nRecAgent [Wang et al., 2023a] comprises three hierarchical levels: sensory memory, short-term memory, and long-term memory. The sensory memory processes environmental inputs, while short-term memory serves as an intermediate layer that can be transformed into long-term memory through repetitive reinforcement. Long-term memory stores crucial reusable information and facilitates self-reflection and knowledge generalization. Agent4Rec [Zhang et al., 2024a] consists of factual memory (recording interactive behaviors) and emotional memory (capturing psychological states), stored in both natural language and vector representations, and managed through three mechanisms: retrieval, writing, and reflection.\n(3) Planning Module outputs intelligent recommendation strategies by designing multi-step action plans that balance immediate user satisfaction with long-term engagement goals. It dynamically formulates recommendation trajectories through careful strategy generation and task sequencing. For example, in video recommendation, the system might construct a strategic plan: \"first recommend a popular video to establish user interest, and then gradually introduce niche but high-quality related content, while maintaining the diversity of genres, and ultimately achieve the goal of both satisfying user interest and expanding horizons\u201d. Through this planning approach, the module optimizes resource allocation and adapts recommendation sequences to achieve both user engagement and item discovery.\nBiLLP [Shi et al., 2024] planning mechanism employs a hierarchical structure with two levels: macro-learning (Planner and Reflector LLMs) generates high-level strategic plans and guidelines from experience, while micro-learning (Actor-Critic) translates these plans into specific recommendations. MACRS [Fang et al., 2024] uses a multi-agent planning system where a Planner Agent coordinates three Responder Agents (Ask, Recommend, Chat) through multi-step reasoning. The system adjusts its dialogue strategy through a feedback mechanism, enabling reflective planning based on user interactions.\n(4) Action Module serves as the execution engine that transforms decisions into concrete recommendations through systematic interaction with various system components. For example, in an e-commerce scenario, when receiving the directive \"recommend entry-level camera for new user\" from the Planning Module, the Action Module executes a coordinated sequence: analyzing purchase patterns of similar users, querying the product database with specific price and feature constraints, generating targeted recommendations, and capturing user feedback. This execution enables the system to deliver contextually appropriate recommendations while continuously learning from interaction outcomes.\nRecAgent [Wang et al., 2023a] orchestrates naturalistic agent interactions within recommender systems and social environments through a unified prompting framework, incorporating six action modalities (encompassing search, browse, click, pagination, chat, and broadcast functionalities). InteRecAgent [Huang et al., 2023] action module integrates three core tools (information querying, item retrieval, and item ranking) while leveraging a Candidate Bus for sequential tool communication, enabling an end-to-end interactive process from user queries to final recommendations.\""}, {"title": "4 Datasets and Evaluations", "content": "In this section, we report the datasets and evaluation metrics used by various methods. The dataset information comes from the original source or paper."}, {"title": "4.1 Datasets", "content": "Traditional Recommendation Dataset In Table 2, we list several traditional recommendation datasets for evaluating model performance. These datasets provide comprehensive interaction data from various platform, including user-item interactions, timestamps, and review text, enabling the assessment of recommendation models. Several state-of-the-art methods have demonstrated their effectiveness using these datasets.\nFor instance, the \"Books\" dataset (10.3M users, 4.4M items) from Amazon Review data [McAuley et al., 2015] has been used to evaluate Agent4Rec [Zhang et al., 2024a] and BiLLP [Shi et al., 2024] performance on large-scale tasks, while the \"Video Games\" dataset (2.8M users, 137.2K items) has validated DRDT [Wang et al., 2023b] and RAH [Shu et al., 2024] capabilities. The \u201cBeauty\" dataset (632K users, 112.6K items) has been utilized by IntcRecAgent [Huang et al., 2023] and DRDT [Wang et al., 2023b] to demonstrate their proficiency in recommendation. These diverse applications underscore the datasets' crucial role in advancing LLM-powered agent recommender systems and providing a foundation for evaluating various of algorithms.\nThe MovieLens datasets, introduced by [Harper and Konstan, 2015], represent another crucial benchmark for evaluating LLM-powered agents recommenders, offering different scales of movie rating data from the MovieLens platform. These datasets range from MovieLens-100K (0.9K users, 1.6K items) to MovieLens-20M (138.5K users, 27.3K items), providing researchers with flexibility in testing their methods across different data scales. Various state-of-the-art approaches have utilized these datasets: FLOW [Cai et al., 2024] and MACRS [Fang et al., 2024] have been validated on the smaller MovieLens-100K dataset, while Agent4Rec [Zhang et al., 2024a], DRDT [Wang et al., 2023b], and MACRS [Fang et al., 2024] have demonstrated their capabilities on MovieLens-1M. The larger variants like MovieLens-10M and MovieLens-20M have been employed by InteRecAgent [Huang et al., 2023] and RecAgent [Yoon et al., 2024] respectively, showcasing the scalability of their approaches. This hierarchical structure of MovieLens datasets makes them particularly valuable for systematically evaluating recommendation algorithms at different scales.\nThe Steam, Lastfm, Anime, and Yelp datasets provide diverse domain-specific evaluation scenarios for LLM-powered agent recommender systems. The Steam dataset, introduced by [Kang and McAuley, 2018], contains 3.7M interactions between 334.7K users and 13K gaming items, and has been extensively used by methods such as Agent4Rec [Zhang et al., 2024a], BiLLP [Shi et al., 2024], FLOW [Cai et al., 2024], and InteRecAgent [Huang et al., 2023] to validate their effectiveness in game recommendation. The Lastfm dataset [Cantador et al., 2011], focusing on music recommendation, comprises 73.5K interactions from 1.2K users on 4.6K music items, and has been specifically utilized by FLOW [Cai et al., 2024] to demonstrate its capabilities in the music domain. Additionally, the Yelp dataset, containing 316.3K interactions between 30.4K users and 20.4K items, has been employed by RecMind [Wang et al., 2024b] to evaluate its performance in recommendations. These domain-specific datasets offer unique evaluation opportunities in specialized recommendation contexts."}, {"title": "Conversational Recommendation Dataset", "content": "In addition to the above traditional recommendation datasets, some works [Zhu et al., 2024a] evaluate the model performance on conversational datasets. In Table 2, we list three widely-adopted datasets: ReDial [Li et al., 2018], Reddit [He et al., 2023], and OpenDialKG [Moon et al., 2019]. The ReDial dataset comprises 11348 multi-turn dialogues involving 6925 movies, where participants engage in seeker-recommender interactions. The Reddit dataset is derived from movie recommendation discussions within Reddit communities, where users post recommendation requests and receive responses with movie suggestions, often accompanied by explanatory rationales. This extensive dataset encompasses 634392 conversations, 1669720 dialogue turns, 36247 users, and 51203 movies. CSHI [Zhu et al., 2024a] employs ReDial (movie domain, including 10006 dialogues) and OpenDialKG (multiple domains, including 13802 dialogues) for performance evaluation. UserSimulator [Yoon et al., 2024] evaluates on the Redial and Reddit datasets in a variety of ways, including behavior simulation and memory module believability, etc. These authentic human-human conversations serve as crucial benchmarks for assessing the model capabilities of LLM-powered agents recommender systems.\nIt is worth mentioning that considering the agent recommender system based on LLMs, it is necessary to frequently call LLMs or APIs when the model is running. In order to save resources and time, some methods sample data from the original dataset for performance evaluation. For instance, AgentCF [Zhang et al., 2024c] randomly samples two subsets (one dense and one sparse), with each subset containing 100 users. DRDT [Wang et al., 2023b] randomly samples 200 users from each dataset and uses the target items along with 19 randomly sampled items as the candidate item set."}, {"title": "4.2 Evaluation", "content": "In Table 3, we summary the evaluation metrics used by recent representative methods.\nStandard Recommendation Metrics Most existing methods employ standard recommendation evaluation metrics to assess model performance. The commonly utilized metrics including Normalized Discounted Cumulative Gain (NDCG@K), Recall@K and Hit Ratio@K (HR@K), etc. For instance, AgentCF [Zhang et al., 2024c] evaluates its performance using NDCG@K and Recall@K on the MovieLens-1M dataset. Similarly, DRDT [Wang et al., 2023b] conducts comprehensive evaluations using Recall@10,20 and NDCG@10,20 across multiple datasets including ML-1M, Games, and Luxury datasets. Hit Ratio@K (HR@K) is another crucial metric for evaluating recommendation performance. RecMind [Wang et al., 2024b] employ that for evaluating the recommendation tasks on Amazon Reviews (Beauty) and Yelp datasets.\nLanguage Generation Quality Some methods [Wang et al., 2024b] consider the evaluation of language generation quality (e.g., recommendation explanation generation, review summarization), which primarily rely on BLEU and ROUGE metrics. BLEU measures the precision of generated text against references, while ROUGE evaluates recall-based similarity, enabling comprehensive assessment of language generation capabilities in recommendation scenarios. PMS [Thakkar and Yadav, 2024a] utilizes the ROUGE to evaluate the quality of its generated textual recommendations.\nReinforcement Learning Metrics In evaluating LLM-powered agent recommender systems for long-term engagement, BiLLP [Shi et al., 2024] employs three key metrics adopted from reinforcement learning: trajectory length, average single-round reward, and cumulative trajectory reward. Similarly, LUSIM [Zhang et al., 2024d] uses the total reward to reflect the overall user engagement during the entire interaction process, and the average reward to represent the average quality of a single recommendation. These metrics are to evaluate both immediate recommendation quality and long-term engagement effectiveness.\nConversational Efficiency Metrics Recent research has introduced more comprehensive metrics to evaluate the efficiency of conversational interactions in recommender systems. For instance, MACRS [Fang et al., 2024] employs key interaction-focused metrics such as Success Rate (proportion of successful recommendations) and Average Turn (AT) (number of interaction rounds needed to reach a recommendation) per session. These metrics assess how effectively the system can understand user preferences and deliver accurate recommendations while minimizing the number of interaction turns.\nCustom Indicators Beyond conventional metrics, some methods [Yoon et al., 2024] propose customized evaluation frameworks. AutoConcierge [Zeng et al., 2024] presents six evaluation metrics for task-driven conversational agents: proactivity, economy, explainability, correctness, consistency, and efficiency. RecAgent [Wang et al., 2023a] proposes simulated user behaviors believability and Agent memory believability, to assess the credibility of LLM-simulated user interactions and memory mechanism effectiveness. These metrics assess system engagement, dialogue efficiency, answer interpretability, response accuracy, requirement fulfillment, and response time, respectively.\nIn all, these metrics prioritize a holistic understanding of conversational performance, emphasizing balance between efficient recommendation delivery, and maintaining high-quality dialogue throughout the recommendation process."}, {"title": "5 Related Research Fields", "content": "LLM-powered Recommender Systems In recent years, recommender systems based on Large Language Models (LLMs) have attracted widespread attention. Such systems make full use of the powerful language understanding and generation capabilities of LLMs, bringing a new paradigm to traditional recommender systems. Most existing methods are primarily designed for rating prediction [Bao et al., 2023] and sequential recommendation [Hou et al., 2024; Shao et al., 2024; Zheng et al., 2024]. CoLLM [Zhang et al., 2023] captures and maps the collaborative information through external traditional models, forming collaborative embeddings used by LLMs. LlamaRec [Yue et al., 2023] fine-tunes Llama-2-7b for list-wise ranking of the pre-selected items. However, these methods would face significant limitations: the inability to simulate authentic user behaviors for enhanced personalization, the lack of effective memory mechanisms for long-term context awareness, and the rigid pipeline structure that prevents flexible task decomposition and seamless integration with external tools.\nConversational Recommender Systems Conversational recommender systems (CRS) have emerged as a significant research direction in recent years [Jannach et al., 2021], which are similar to the LLM-powered agent recommender systems. However, traditional methods [Lei et al., 2020] have two main drawbacks: attribute-based approaches are limited by rigid dialogue patterns, while generation-based methods suffer from restricted knowledge and poor generalization capabilities of small language models."}, {"title": "6 Future Directions", "content": "Optimization of System Architecture The integration between traditional recommendation methods and LLMs remains insufficient, with challenges in multi-agent collaboration and system interpretability. Future developments should explore flexible architectural designs, enhance agent cooperation efficiency, while ensuring transparency in recommendation.\nRefinement of Evaluation Framework There is a notable absence of unified and comprehensive evaluation standards for accurately measuring dialogue quality and recommendation effectiveness. Future research necessitates the establishment of robust evaluation frameworks, development of novel performance metrics, and consideration of privacy and security concerns in practical applications.\nSecurity Recommender System [Ning et al., 2024] reveals the vulnerability of LLM-empowered recommender systems to adversarial attacks. In future, the researchers could develop robust adversarial detection methods, investigate multi-agent defensive architectures, and integrating domain-specific security knowledge into defense mechanisms."}, {"title": "7 Conclusion", "content": "The integration of LLM-powered agents into recommender systems has emerged as a significant advancement in recent years. In this survey, we systematically categorize existing approaches into three paradigms: recommender-oriented, interaction-oriented, and simulation-oriented. We comprehensively analyze these methods through a unified four-module architecture and review current datasets and evaluation methodologies. Finally, we identify three promising directions for future research."}]}