{"title": "SNAP: Sequential Non-Ancestor Pruning for Targeted Causal Effect Estimation With an Unknown Graph", "authors": ["M\u00e1ty\u00e1s Schubert", "Tom Claassen", "Sara Magliacane"], "abstract": "Causal discovery can be computationally demanding for large numbers of variables. If we only wish to estimate the causal effects on a small subset of target variables, we might not need to learn the causal graph for all variables, but only a small subgraph that includes the targets and their adjustment sets. In this paper, we focus on identifying causal effects between target variables in a computationally and statistically efficient way. This task combines causal discovery and effect estimation, aligning the discovery objective with the effects to be estimated. We show that definite non-ancestors of the targets are unnecessary to learn causal relations between the targets and to identify efficient adjustments sets. We sequentially identify and prune these definite non-ancestors with our Sequential Non-Ancestor Pruning (SNAP) framework, which can be used either as a preprocessing step to standard causal discovery methods, or as a standalone sound and complete causal discovery algorithm. Our results on synthetic and real data show that both approaches substantially reduce the number of independence tests and the computation time without compromising the quality of causal effect estimations.", "sections": [{"title": "INTRODUCTION", "content": "Causal inference [Pearl, 2009] is fundamental to our scientific understanding and practical decision-making. In many settings, we do not know the causal relations between the variables, which we can learn with causal discovery methods [Glymour et al., 2019]. These methods can be computationally demanding for large numbers of variables. In many cases, we are only interested in estimating the causal effects on a small subset of variables, which does not require recovering the causal graph over all variables. We formalize this setting as targeted causal effect estimation with an unknown graph, a task that focuses on identifying the causal effects \\(P(T_i|do(T_j))\\) between pairs of target variables \\(T_i, T_j \\in T\\), where \\(T\\) is a subset of all variables \\(V\\) in a computationally and statistically efficient way.\nWe assume that we are in a causally sufficient setting, i.e., there are no unobserved confounders or selection bias. Under these assumptions, we can use constraint-based causal discovery algorithms [Spirtes et al., 2000] to identify the Markov equivalence class (MEC) of the causal graph [Verma and Pearl, 1990], represented by a mixed graph, called the complete partially directed acyclic graph (CPDAG). The CPDAG can then be used to identify valid adjustment sets for causal effect estimation [Perkovi\u0107 et al., 2015]. However, discovering the CPDAG over all variables can scale poorly in terms of conditional independence (CI) tests for large numbers of nodes [Mokhtarian et al., 2021].\nLocal causal discovery methods [Wang et al., 2014, Gupta et al., 2023] address this issue for a pair of targets, a treatment and an outcome, by identifying the parent adjustment set of the treatment, but they cannot learn other types of adjustments that are statistically more efficient. Maasch et al. [2024] learn to group nodes according to their ancestral relationship to a treatment-outcome pair, which can be used to identify various adjustment sets, but not necessarily optimal ones. These algorithms focus only on two target variables and assume that we know the causal relations between them. Watson and Silva [2022] propose an algorithm to discover the causal relations between multiple targets, which they call foreground variables, but assume that the other variables, the background variables, are all non-descendants of the target variables.\nIn this paper we propose Sequential Non-Ancestor Pruning (SNAP), an approach that efficiently discovers the ancestral relationships between multiple target vari-"}, {"title": "2 PRELIMINARIES", "content": "We focus on graphs \\(G = (V, E)\\) with nodes \\(V\\) and edges \\(E\\). The edges \\(E\\) can be undirected edges \\(X - Y\\), directed edges \\(X \\rightarrow Y\\) or \\(X \\leftarrow Y\\) and bidirected edges \\(X \\leftrightarrow Y\\) that are directed both towards \\(X\\) and \\(Y\\). If two nodes are connected by an edge in a graph \\(G\\), we say that they are adjacent, and denote the set of nodes adjacent to \\(X\\) as \\(Adj_G(X)\\). An undirected graph is a graph with only undirected edges, and a directed graph is a graph with only directed edges. A mixed graph can contain undirected, directed and bidirected edges.\nA path between two nodes \\(X\\) and \\(Y\\) is a sequence of distinct adjacent nodes that starts at \\(X\\) and ends at \\(Y\\). A directed path from \\(X\\) to \\(Y\\) is a path where each edge on the path is directed towards \\(Y\\). A directed cycle is a directed path from a node to itself. A directed acyclic graph (DAG) is a graph with only directed edges and without directed cycles. If there is a directed path from a node \\(X\\) to another node \\(Y\\) in a graph \\(G\\), then we say that \\(X\\) is an ancestor of \\(Y\\) and \\(Y\\) is a descendant of \\(X\\). We denote the set of ancestors of \\(Y\\) as \\(An_G(Y)\\) and the set of descendants of \\(X\\) as \\(De_G(X)\\). We say that a set of nodes \\(V' \\subseteq V\\) is an ancestral set in a DAG \\(D\\) if for all \\(V \\in V'\\) it holds that \\(An_D(V) \\subseteq V'\\).\nA causal graph \\(D\\) is a DAG that describes the data generating process of a joint observational distribution \\(p\\) over variables \\(V\\) [Pearl, 2009]. We assume causal sufficiency, i.e., the distribution \\(p\\) is over all variables \\(V\\) and there are no latent confounders or selection"}, {"title": "3 SEQUENTIAL NON-ANCESTOR PRUNING", "content": "Causal effect estimation requires knowledge about the causal graph. If causal relations are not known a priori, we can use causal discovery methods to learn them from data. In many settings, we might have access to a large set of variables, but we are only interested in the causal effects between a small set of target variables. Standard global causal discovery on all variables can estimate the identifiable causal effects between targets, as well as valid adjustment sets, but it might be computationally inefficient, since it might also learn parts of the graph that are uninformative for the causal effects of interest. Alternatively, focusing on the target variables and only learning the causal relations between them might lead to confounded causal effects and less identifiable causal relations than we would learn in global causal discovery.\nOur goal is to estimate the identifiable causal effects between the targets as statistically efficiently as global causal discovery methods, but in a more computationally efficient way than estimating the complete graph. We formalize this goal as a specific task as follows:\nDefinition 3.1. Given a joint distribution \\(p\\) over variables \\(V\\) and targets \\(T \\subset V\\), we define targeted causal effect estimation with an unknown graph as the task of estimating in a computationally and statistically efficient way the interventional distributions \\(P(T_i|do(T_j))\\), for all possible pairs \\(T_i, T_j \\in T\\).\nLocal causal discovery methods, such as [Wang et al., 2014, Gupta et al., 2023, Maasch et al., 2024], address the computational efficiency by only learning a local structure in the neighborhood of a pair of target variables for which we know which is the cause and which is the effect a priori. On the other hand, these methods are not as statistically efficient as global causal discovery, since they cannot identify optimal adjustment sets. In particular, they either learn local adjustment sets relying on the parents of the treatment, which are suboptimal in terms of variance, or other valid adjustment sets based on groups of variables, which might not include the optimal adjustment sets.\nIn this work, we address this task by progressively pruning definite non-ancestors of the target variables. We first show that definite non-ancestors of the targets are not needed to identify valid and statistically efficient adjustment sets. While Guo et al. [2023] show that non-ancestors of the outcome are uninformative, our results show that they are also unnecessary to identify the causal structure between the targets and their (optimal) adjustment sets. Then, we present Sequential Non-Ancestor Pruning (SNAP), a framework to progressively identify definite non-ancestors, inspired by low-order constraint-based causal discovery. We provide all proofs for the following results in App. B."}, {"title": "3.1 Possible Ancestors Are All You Need", "content": "In this section, we show that definite non-ancestors of the target variables are not needed to identify statistically efficient adjustment sets for the causal effects between the targets. Guo et al. [2023] show that non-ancestors of the target variables are not needed as part of the statistically efficient adjustment sets for the targets. Here, we do not know the non-ancestors of the target variables, since we learn the causal structure as a CPDAG \\(G\\) and we can at best identify the set of possible ancestors of the targets \\(PossAn(T)\\). Additionally, we show that definite non-ancestors of the targets will not have any effect on the orientations of the causal structure for the targets or their possible ancestors, and hence they can be safely ignored.\nIn general, we might not be able to estimate the possible ancestors of the targets without reconstructing the whole CPDAG. On the other hand, we can overestimate this set and consider a set \\(V^*\\) that contains \\(PossAn(T)\\). If \\(V^*\\) also contains all its possible ancestors, we then"}, {"title": "3.2 The SNAP Framework", "content": "If the possibly ancestral set \\(V^*\\), which contains the possible ancestors of the targets, is much smaller than the total number of nodes, then discovering only \\(G(V^*)\\), instead of the full CPDAG \\(G(V)\\), can save considerable computational resources. Furthermore, \\(G(V^*)\\) allows us to use statistically efficient adjustment sets. Without background knowledge on a suitable \\(V^*\\), we approach the discovery of \\(G(V^*)\\) using an iterative framework, which we call Sequential Non-Ancestor Pruning. We propose two implementations of this framework: SNAP(k) (Alg. 1) and SNAP(\u221e) (Alg. 2).\nSNAP(k) is a causal discovery algorithm that uses information about ancestry to progressively eliminate definite non-ancestors of targets, removing them from \\(V^*\\). In particular, SNAP(k) adapts the PC-style skeleton search, iteratively increasing conditioning set sizes of CI tests. At every iteration \\(i\\), SNAP(k) computes a partially oriented graph \\(\\hat{G}^i\\) by orienting v-structures according to the intermediate skeleton \\(\\hat{U}^i\\) and separating sets discovered so far. Then, \\(\\hat{G}^i\\) is used to identify and eliminate a subset of the definite non-ancestors of the targets, and SNAP(k) continues to the next iteration only on the remaining variables \\(V^{i+1}\\). Thus, SNAP(k) considers fewer and fewer variables as the size of the conditioning set increases. In practice, we see that many non-ancestors are identified already by marginal tests, leading to significantly fewer higher order tests.\nIn SNAP we orient v-structures in \\(G\\) using only conditional independence of a maximum order \\(i\\) to identify definite non-ancestors. This requires particular care, since in general CI test results restricted to a maximum order can lead to conflicting v-structure orientations, which are oriented as bidirected edges. Wien\u00f6bst and Liskiewicz [2020] show that if all CI test results up to order \\(k\\) are available, then these bidirected edges indicate that neither variable is the possible ancestor of the other. Surprisingly, if we instead only perform a subset of CI tests based on the skeleton search up to order \\(k\\), as in anytime FCI [Spirtes, 2001], and then orient v-structures as in PC (Alg. 3), this can lead to incorrect information about possible ancestry, as shown in this example:\nTo overcome this, we show in App B that orienting v-structures as in RFCI [Colombo et al., 2012] (Alg. 4) leads to correct information about possible ancestry at any order of the PC-style skeleton search, in the causally sufficient case. Since the RFCI orientation involves performing additional CI tests, we show that it is only required above order 1, which greatly reduces its overhead. Then, as Theorem 3.1 states, SNAP(k) only removes definite non-ancestors of targets, and the remaining nodes form a possibly ancestral set."}, {"title": "3.3 Complexity Analysis", "content": "In this section, we show that the worst-case computational complexity of SNAP(\u221e) in terms of CI tests matches the complexity of PC for graphs with maximum degree \\(d_{max} \\geq 2\\). The worst-case complexity for PC is determined by its skeleton search, which is \\(O(|V|^{d_{max}+2})\\) [Spirtes et al., 2000], where \\(|V|\\) is the number of nodes and \\(d_{max}\\) is the maximum degree.\nThe worst-case complexity of SNAP(\u221e) is given by the complexity of the skeleton search and the RFCI orientation rules (Algorithm 4). We present a lemma that states that the worst-case complexity of the RFCI orientation rules is polynomial in the number of nodes."}, {"title": "4 RELATED WORK", "content": "Causal discovery is the task of identifying causal relations between variables from data [Glymour et al., 2019]. We limit our scope to observational data and assume causal sufficiency, meaning there are no unobserved confounders or selection bias. Under these assumptions, there are multiple algorithms in the literature that can be used to learn an equivalence class of causal graphs. In this paper, we mostly focus on constraint-based algorithms, which use CI tests to constrain the possible causal relations. PC [Spirtes et al., 2000] is one of the most famous constraint-based methods, but it also suffers from scalability issues and reliability.\nSeveral methods have been proposed to reduce the number of CI tests needed, e.g., MARVEL [Mokhtarian et al., 2021], or to only consider CI tests of low order,"}, {"title": "5 EXPERIMENTS", "content": "Baselines. We evaluate SNAP(\u221e), along with global algorithms PC [Spirtes et al., 2000], MARVEL [Mokhtarian et al., 2021] and FGES [Ramsey et al., 2017], the modified versions of local algorithms MB-by-MB [Wang et al., 2014] and LDECC [Gupta et al., 2023], and their combination with SNAP(0). We choose SNAP(0) as it is the simplest prefiltering method, and it is already very effective in practice,\nas shown in App. D.6. We do not compare to CBL [Watson and Silva, 2022], since it requires that all non-target nodes are non-descendants of the targets. Similarly, we do not compare to LDP [Maasch et al., 2024], since it requires known ancestral relationships between targets to estimate the groups of variables that can be used for adjustment.\nThe local structure discovered by LDECC and MB-by-MB is sound regardless of the ancestral relationships between targets. However, knowledge about the ancestral relationships is still needed for causal effect estimation. Thus, we apply these methods on all targets separately and estimate if a target X is an ancestor of another target Y by testing their independence conditioned on the identified definite parents of X.\nMetrics. We compare the constraint-based algorithms in terms of the CI tests they perform, and compare all algorithms, including FGES, in terms of computation time. To estimate the quality of the joint causal discovery and causal effect estimation, we report the intervention distance, i.e., the distance between the ground truth causal effect from the target T to the target T', and the predicted causal effect \\(\\Theta_{T,T'}\\) for the same pair given an adjustment, which we define"}, {"title": "5.1 Experimental Results", "content": "We evaluate four settings: oracle CI d-separation tests,\nFisher-Z tests for the linear setting, KCI tests [Zhang\net al., 2011] for the linear setting, and \\(\\chi^2\\) test on binary\ndata. For FGES, we use BIC [Schwarz, 1978] for the\nlinear setting and BDeu [Heckerman et al., 1995] for\nthe binary setting. For KCI tests, we consider smaller\ngraphs with \\(n_V = 5,..., 20\\) nodes, because of com-\nputational constraints. Fig. 2 shows our results for\n\\(n_T = 4, d = 3, d_{max} = 10\\) and \\(n_D = 1000\\) in terms of\nthe number of CI tests performed and the execution\ntime, over graphs with various number of nodes.\nUnder both metrics, SNAP(\u221e) performs consistently\nas one of the best methods across all domains, while\nthe performance of other methods varies based on the\nsetting. In particular, PC and LDECC* perform sub-\nstantially more tests and are substantially slower for\nthe oracle setting, while the gap is smaller for par-\ntial correlation and KCI tests. For the binary setting,\nLDECC* performs fewer tests, but is computationally\ncomparable to SNAP(\u221e). On the contrary, MARVEL"}, {"title": "6 CONCLUSIONS", "content": "We propose SNAP, an efficient method for discovering the relevant portion of the CPDAG for causal effect estimation between target variables. SNAP does not require prior knowledge of ancestral relationships and identifies statistically efficient adjustment sets. We introduce two variants: SNAP(k), which can be used as a preprocessing step for other discovery algorithms, and SNAP(\u221e), a stand-alone sound and complete discovery algorithm. Our experiments show that both variants significantly reduce the number of CI tests and computation time while maintaining a comparable intervention distance. Future work will explore extending SNAP to causally insufficient settings."}]}