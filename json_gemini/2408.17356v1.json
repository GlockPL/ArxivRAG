{"title": "C-RADAR: A Centralized Deep Learning System\nfor Intrusion Detection in Software Defined\nNetworks", "authors": ["Osama Mustafa", "Khizer Ali", "Talha Naqash"], "abstract": "The popularity of Software Defined Networks\n(SDNs) has grown in recent years, mainly because of their\nability to simplify network management and improve network\nflexibility. However, this also makes them vulnerable to various\ntypes of cyber attacks. SDNs work on a centralized control plane\nwhich makes them more prone to network attacks. Research\nhas demonstrated that deep learning (DL) methods can be\nsuccessful in identifying intrusions in conventional networks,\nbut their application in SDNs is still an open research area.\nIn this research, we propose the use of DL techniques for\nintrusion detection in SDNs. We measure the effectiveness of our\nmethod by experimentation on a dataset of network traffic and\ncomparing it to existing techniques. Our results show that the\nDL-based approach outperforms traditional methods in terms\nof detection accuracy and computational efficiency. The deep\nlearning architecture that has been used in this research is a\nLong Short Term Memory Network and Self-Attention based\narchitecture i.e. LSTM-Attn which achieves an F1-score of 0.9721.\nFurthermore, this technique can be trained to detect new attack\npatterns and improve the overall security of SDNs.", "sections": [{"title": "I. INTRODUCTION", "content": "This study focuses on intrusion detection in software defined\nnetworks. Software Defined Networking (SDN) [1] is an\nimportant research dimension because it has the potential to\nrevolutionize the way networks are managed and operated.\nIn SDN, the control plane, responsible for making decisions\non traffic forwarding, is separated from the data plane, which\nphysically forwards the traffic. This separation allows for\nmore flexibility, programmability and centralized control of\nthe network [2].\nSDNs and the current networking scenario has a direct\nrelation with the emerging technologies. Artificial Intelligence\napplications have started to become more common especially\non common user devices and as Al systems are closely\ndependent on large amounts of data there is a need of robust\nand scalable networking infrastructure that can support this\ntechnology. As due to data privacy concerns the concept of\nfederated learning has started to become more common, we\nneed a system that is more robust and scalable. In order to\nsupport all these emerging technologies, there are some issues\nin conventional networks such as customization, programma-\nbility and scalability. In conventional networks in order to\ndo some customization, it has to be done on the firmware\nlevel. Software Defined Networks cover all these issues and\noffer customization and scalability [3] A python application\nin the form of a software is easily deployable on an SDN\ncontroller. Software-Defined Networking (SDN) is a rapidly\nemerging field that is changing the way networks are managed\nand controlled. Instead of traditional networks, which rely on\nproprietary hardware and closed systems, SDNs use software\nto control and manage the flow of data across a network. One\nof the key benefits of SDNs is their flexibility and programma-\nbility. Because the control plane is separated from the data\nplane in SDN architecture, network administrators can easily\nmake changes to the network without having to reconfigure\nhardware. This allows for more efficient and faster deployment\nof new services and applications. Another advantage of SDNs\nis the ability to automate network management tasks. By\nusing software-based controllers, network administrators can\ncreate policies and rules that automatically manage the flow\nof data across the network. This can lead to more efficient\nuse of network resources and improved security. The current\nnetworking requirements, such as the increasing number of\nconnected devices, the need for faster and more reliable\nnetworks and the need for more secure networks, all favor\nthe need for SDNs. With the ability to easily scale and adapt\nto changing requirements, SDNs can provide a more efficient\nand cost-effective solution for modern networks. In conclusion,\nSoftware-Defined Networking (SDN) is an emerging field that\noffers many benefits over traditional networking approaches.\nIts flexibility, programmability, and automation capabilities\nmake it an ideal solution for meeting the current and future\nnetworking requirements. As the demand for more efficient,\nreliable, and secure networks continues to grow, the adoption\nof SDN technology is likely to increase in the future.\nThere are some security challenges that come along with\na centralized control plane [4]. A centralized control plane in\nSoftware Defined Networking (SDN) can present a security"}, {"title": "II. RELATED WORK", "content": "Researchers in the field of intelligent network intrusion de-\ntection (NID) typically use techniques such as dimensionality\nreduction, clustering, and classification to differentiate normal\nnetwork traffic from abnormal traffic, in order to identify and\ndetect malicious attacks [5], [6]. Pervez et al. put forward a\ntechnique for combining feature selection and classification for\nthe multi-class NSL-KDD Cup99 dataset using Support Vector\nMachine (SVM) and evaluated the classification accuracy of\nthe classifiers under various feature dimensions [7]. Sheraz\nemployed the K Farthest Neighbor (KFN) and K Nearest\nNeighbor (KNN) algorithms to classify the data, and in\ncases where the nearest and farthest neighbors had the same\nclass label, he used the Second Nearest Neighbor (SNN) for\nclassification [8]. Similarly, Bhattacharya et al. proposed a ML\ntechnique that combines Principal Component Analysis (PCA)\nand Firefly algorithm. The model first applies one key coding\nto the IDS dataset, then reduces the dimensionality of the\ndataset using the hybrid PCA-Firefly algorithm, and finally\nuses the XGBoost algorithm to classify the reduced dataset\n[9].\nAs deep learning has revolutionized other research areas like\nNatural Language Processing, and Computer Vision, there-\nfore, its also been used recently by researchers for intrusion\ndetection. Generally, the neural networks learn the features\nfrom the labeled dataset during the training of the model.\nTorres utilized Recurrent Neural Network (RNN) to detect\nmalicious network traffic by first converting network traffic\ncharacteristics into characters and then analyzing their tempo-\nral characteristics [10]. Wang et al. proposed a classification\nalgorithm for malicious software traffic using a Convolutional\nNeural Network (CNN) [11]. Another team conducted re-\nsearch on deep learning, focusing on techniques such as data\nsimplification, dimension reduction, and classification. They\nproposed a Fully Convolutional Network (FCN) model as a\nresult of their research [12]. Tama and their team proposed an\nIntrusion Detection System (IDS) that uses a two-stage meta-\nclassifier for anomaly-based detection. The authors employed a\ncombination of feature selection techniques to obtain precise\nfeature representations and found that it enhanced detection\nrates when evaluating on the NSL-KDD and UNSW-NB15\nintrusion datasets [13]."}, {"title": "III. DATASET", "content": "In this study, experimentation is conducted on CSE-CIC-\nIDS2018\u00b9 [14].\nIn this study, availability of data that is a proper rep-\nresentation of attack patterns is a common challenge since\nthe organizations try to keep it internal for privacy concerns.\nThis dataset contains the feature set for 15 different types of\nattack types, some of them are: Benign, SSH-Bruteforce, DoS\nattacks-GoldenEye, FTP-BruteForce, DoS attacks-Slowloris.\nThe dataset used in this study consists of network traffic\ncaptures and system logs from each machine, as well as 80\ncharacteristics extracted from the captured traffic through the\nuse of CICFlow Meter-V3. There are total 80 features in the\ndataset, a few can be seen in Table I. Figure 1 illustrates the\nclass distribution of each class from the dataset."}, {"title": "A. Data Preprocessing", "content": "In this study, while the availability of dataset is a challenge\nsimilarly preprocessing of available dataset is also a major\nchallenge. This dataset contains data for multiple classes as\ndetailed above and the data distribution is highly unbalanced.\nWe have converted the dataset from multiclass to binary\nclass by assigning all the attack values the label: malicious,\nand remaining values label: non-malicious. This problem is\napproached as a binary class problem considering the real\nworld scenario where a malicious network traffic can be a\ncombination as a hybrid attack. By training the model as\na binary classifier it would be able to detect and flag any\nmalicious network traffic flow.\nThis dataset is imbalanced and for balancing the dataset\nreduction approach has been used. There are two classes\nin the dataset after conversion to binary class: benign and\nmalicious. The proportion of benign data points is greater\nthan malicious, therefore in order to balance the dataset the\nnumber of benign data samples has been reduced in each\nfile respectively. This prevents information loss as the model\nhas to learn the patterns of malicious traffic. In recent work,\nSMOTE [15] has been used extensively to solve the imbalance\nproblem but comparison presented in section IV validates that\nutilizing SMOTE for this purpose reduces the performance on\ninference.\nThe dataset is initially available in multiple files respective\nto days as the attacks were conducted on different days. We\nconcatenated all the data into a single csv file as part of\npre-processing. The feature 'time-stamp' is removed from the"}, {"title": "IV. METHODOLOGY", "content": "In this study, deep learning based neural network architec-\nture is utilized for the task of malicious traffic classification. A\nfurther class of neural networks i.e Long Short Term Memory\nNetwork (LSTM) [16] and Self-attention [17] based architec-\nture has been utilized in this study. In this research, attack\npatterns are complex and difficult to identify due to their slow\nand passive approach. LSTMs are a type of recurrent neural\nnetwork [18] that are well-suited for tasks involving sequential\ndata. In the context of intrusion detection in software-defined\nnetworks, LSTMs can be trained to analyze network traffic\nand identify patterns that indicate malicious activity. They\nare particularly useful for this task because they are able\nto \"remember\" information from previous time steps and\nuse it to inform their analysis of current data. Additionally,\nLSTMs can also handle variable-length sequences of data,\nwhich makes them well-suited for analyzing network traffic\nwhere the number of packets in a given session can vary.\nUsing self-attention in conjunction with LSTMs can improve\nthe performance of an intrusion detection system for several\nreasons.\n\u2022\nSelf-attention allows the model to focus on specific parts\nof the input sequence, which can be useful for identifying\nimportant features in the network traffic data that indicate\nmalicious activity\n\u2022\nSelf-attention mechanisms can learn to weight the im-\nportance of different parts of the input sequence, which\ncan be useful in intrusion detection where some parts of\nthe network traffic may be more important than others in\ndetermining whether an attack is occurring\n\u2022\nBy using self-attention, model can understand the rela-\ntionship between different parts of the input sequence,\nwhich is useful in intrusion detection as it allows the\nmodel to identify patterns of malicious activity across\ndifferent parts of the network traffic data"}, {"title": "A. Architecture", "content": "This section details the architecture of the model used in\nthis study. We have utilized an LSTM-Attn based model in\nthis study. As illustrated in Figure 2 the system pipeline\nis comprised of a backbone (for feature extraction) and a\nprediction head (for decision making). Table II details the\nsummary of the architecture utilized in this study. In the\nbackbone, two Long Short Term Memory Network (LSTM)\nlayers are stacked on top of each other, the output from this\nstack is forwarded as an input to the self attention layer and\nfinally an LSTM layer on top of it. The backbone performs the\ntask of feature extraction after which these features are passed\nto a prediction head for the purpose of decision making. The"}, {"title": "B. Train Configuration", "content": "This section details the training configuration followed\nduring the training of above mentioned architecture. In LSTM\nblock, the configuration followed can be referred to in Table\nIII"}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "This section details the experimentation setting, evaluation\nmetrics used and results achieved from experimentation."}, {"title": "A. Evaluation Metrics", "content": "In order to quantify the experimentation outputs and per-\nform analysis & comparison we have used following evalua-\ntion metrics: accuracy, F1-score, precision and recall. Equa-\ntions 1-4 show how each of the evaluation metric is computed\n$Accuracy = \\frac{TP+TN}{TP+TN+FP + FN}$ (4)\n$Precision = \\frac{TP}{TP + FP}$ (5)\n$Recall = \\frac{TP}{TP + FN}$ (6)\n$F1 = \\frac{2* Precision * Recall}{Precision + Recall} = \\frac{2*TP}{2*TP+FP+FN}$ (7)\nWe have specifically used weighted f1-score:\n\u2022\nF1-Score (Weighted): The F1 score is calculated by\ntaking the average of the F1 scores for each class, with\nthe weight being determined by the number of instances\nof that class in the dataset, known as the support."}, {"title": "B. Results and Analysis", "content": "This section presents the results and analysis. Table IV\npresents the quantified experimentation outputs that were\nachieved as a result of rigorous experimentation conducted in\nthis research. The proposed system outperforms SOTA with\nan F1-score of 0.9721 in intrusion detection for SDNs. Table\nV [19] presents the performance comparison of our proposed\nmodel architecture with other SOTA models used for this task\non the same dataset. The training and validation graphs in\nFigure 3 show that the learning improves as a function of\nincreasing epochs."}, {"title": "VI. CONCLUSION", "content": "In conclusion, the proposed LSTM-Self-attention model\noutperforms state-of-the-art intrusion detection in SDN, by\neffectively identifying malicious traffic with an F1-score of\n0.9721. This study makes a notable contribution to the area\nof intrusion detection systems (IDS) based on deep learning\nfor Software Defined Networks (SDN). The model effectively\nleverages the temporal dependencies and attention mechanisms\nto accurately identify malicious network traffic. The experi-\nmentation results and analysis validate that in this case the per-\nformance drops by using synthetic data generation techniques\nfor class balancing such as SMOTE. The proposed model\ncan serve as an effective tool for securing software defined"}]}