{"title": "WHY COMPANIES \u201cDEMOCRATISE\u201d ARTIFICIAL INTELLIGENCE: THE CASE OF OPEN SOURCE SOFTWARE DONATIONS", "authors": ["Cailean Osborne"], "abstract": "Companies claim to \u201cdemocratise\u201d artificial intelligence (AI) when they donate AI open source software (OSS) to non-profit foundations or release AI models, among others, but what does this term mean and why do they do it? As the impact of AI on society and the economy grows, understanding the commercial incentives behind AI democratisation efforts is crucial for ensuring these efforts serve broader interests beyond commercial agendas. Towards this end, this study employs a mixed-methods approach to investigate commercial incentives for 43 AI OSS donations to the Linux Foundation. It makes contributions to both research and practice. It contributes a taxonomy of both individual and organisational social, economic, and technological incentives for AI democratisation. In particular, it highlights the role of democratising the governance and control rights of an OSS project (i.e., from one company to vendor-neutral, open governance) as a structural enabler for downstream goals, such as attracting external contributors, reducing development costs, and influencing industry standards, among others. Furthermore, OSS donations are often championed by individual developers within companies, highlighting the importance of the bottom-up incentives for AI democratisation. The taxonomy provides a framework and toolkit for discerning incentives for other AI democratisation efforts, such as the release of AI models. The paper concludes with a discussion of future research directions.", "sections": [{"title": "1 Introduction", "content": "Companies are increasingly \"democratising\" artificial intelligence (AI). However, \u201cAI democratisation\" remains an ambiguous term, encompassing a variety of goals and methods (Seger et al., 2023b), including the release of AI open source software (OSS) (Langenkamp and Yue, 2022; Srnicek, 2022), its donation to non-profit foundations (Yue and Nagle, 2024), and the release of AI models (henceforth: open models) (Osborne et al., 2024; Widder et al., 2023), among others. While press releases celebrate a myriad of benefits that AI democratisation promises for research and innovation, the commercial incentives driving such efforts are often obscured from public view. Given the ever-increasing impact of AI on society and the economy, understanding the commercial incentives for AI democratisation efforts is crucial so that we can ensure these efforts serve broader societal interests beyond commercial agendas.\nTowards this end, this study presents an exploratory investigation of why companies democratise AI with a focus on OSS donations as one method, among others, of AI democratisation. Through a mixed-methods approach, combining the analysis of pre-donation technical pitches, post-donation blog posts, a questionnaire, and semi-structured interviews, it investigates commercial incentives for 43 AI OSS donations to the Linux Foundation (LF), making contributions to both research and practice. It makes contributions to both research and practice. It contributes a taxonomy of both individual and organisational social, economic, and technological incentives for AI democratisation. In particular, it highlights the role of democratising the governance and control rights of an OSS project (i.e., from one company to vendor-neutral, open governance) as a structural enabler for downstream goals, such as attracting external contributors, reducing development costs, and influencing industry standards, among others. Furthermore, it sheds light on the role of individual developers within companies, who champion and coordinate OSS donations, thus highlighting the relevance"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 \"Democratising AI\u201d: Narratives and Practices", "content": "In the context of concerns about industry concentration and influence on AI research and development (R&D) (Ahmed et al., 2023; Kak and Myers West, 2023; Whittaker, 2021; Varoquaux et al., 2024), it has become en vogue for companies to claim to \"democratise AI\u201d\u2014an altruism-laden term that is notoriously ambiguous. Prior work finds that it used as a catch-all term to encompass a variety of goals and practices (Seger et al., 2023b), including the following:\n\u2022 Democratising AI use: Lowering entry barriers for the use of AI technologies, including but not limited\nto commercial products like OpenAI's ChatGPT or GitHub's Copilot, access to AI models through APIs or\npublicly available model weights, and the release of AI OSS like PyTorch and TensorFlow.\n\u2022 Democratising AI development: Lowering the entry barriers for the development of AI technologies,\nincluding but not limited to the release of AI models and AI OSS.\n\u2022 Democratising AI profits: Redistributing the economic value accrued to companies from their use of AI\ntechnologies to the respective users and impacted populations.\n\u2022 Democratising AI governance: Distributing the decision-making power in the development or use of AI\ntechnologies to a wider community of stakeholders and impacted populations.\nIn most cases, AI democratisation is used to refer to the lowering of barriers for the use or the development of AI\ntechnologies, leading Seger et al. (2023b) to conclude that, \u201cAI democratisation' is a (mostly) unfortunate term\". Open\nsource technologies and collaboration methods have been integral to AI democratisation efforts, offering the means of\nenabling both access to and participation in the development of AI. Commercial releases of AI OSS (Langenkamp and\nYue, 2022; Srnicek, 2022) and open models (Osborne et al., 2024; Widder et al., 2023) have contributed to the rapid\ngrowth of the open source Al ecosystem, which now comprises over 300 AI OSS libraries (Haddad, 2022), hundreds of\nthousands of open models (Osborne et al., 2024), and over a million AI OSS repositories (GitHub, 2023).\nThe prevalence of AI democratisation efforts begs the questions of why companies release their AI software and models,\nand what are the impacts thereof on the norms, practices, and potential trajectories of AI developer communities. Prior\nwork hints at a number of incentives. Scholars contend that industry giants promote open source as an alternative to\ntheir concentrated power in the AI industry, whilst using it as a means to shape industry standards, benefit from user\ninnovation, and ultimately extend their influence the norms and tools used by researchers and developers around the\nworld (Widder et al., 2023; Srnicek, 2022). Nick Srnicek argues that \u201cthe seemingly non-capitalist practice of releasing\ntheir AI software for free in fact obscures a significant capitalist battle between the major companies\u201d (Srnicek, 2022).\nThis was evident in a leaked Google memo, which claimed that \"open source solutions will out-compete companies\nlike Google or OpenAI\" and for this reason they should \"own the ecosystem and let open source work for us\" (Patel\nand Ahmad, 2023). As discussed below, this leaked memo highlights the ethical tensions that emerge from company's\nattempts to exploit the collective efforts of OSS developer communities (Birkinbine, 2020; Li et al., 2022).\nOther companies, such as Meta, have been outspoken about the drivers of their open source AI strategy: by releasing AI\nsoftware like PyTorch and large language models (LLM) like their LLaMA models, Meta seeks to increase adoption\nof its technology, improve their performance and safety through distributed feedback and innovation, and ultimately\nbenefit from ecosystem effects. For example, upon releasing LLaMA 2, Nick Clegg, Meta's President of Global Affairs,\nexplained that", "safer and better": "ecause it will benefit from the", "crowds.": "legg added that, \u201cA mistaken\nassumption is that releasing source code or model weights makes systems more vulnerable. On the contrary, external\ndevelopers and researchers can identify problems that would take teams holed up inside company silos much longer.", "been very valuable for us": "ecause it has facilitated their use of external AI research"}, {"title": "2.2 Commercial Incentives for OSS Development", "content": "Companies have participated in the development of OSS in a myriad of ways since the late 1990s (Broca, 2021; Li et al.,\n2024), including by deploying developers to contribute to projects as part of their job responsibilities or corporate social\nresponsibility initiatives (Dahlander and Magnusson, 2005; Dahlander and Wallin, 2006; Lee and Herstatt, 2015; Zhang\net al., 2021), funding projects (O'Brien, 2019; Osborne, 2024), or joining project steering committees (Butler et al.,\n2018; Wagstrom, 2009), among others. These are popular strategies through which companies seek to influence projects\nthat develop maintain OSS that they use Dahlander and Wallin (2006); Osborne (2024). It is also common for companies\nto spin-out proprietary software as company-hosted OSS, where the host company controls the intellectual property\nof the project (e.g., by requiring contributors to sign a contributor license agreement) and employs the maintainers of\nthe project (Zhou et al., 2016; Yue and Nagle, 2024). This is a proven commercial strategy to increase adoption of\ntheir software, benefit from external contributions, win market share, or reduce a competitor's market share (West and\nO'Mahony, 2005). In some cases, a handful of companies share control of a project; for example, in 2017, Facebook\nand Microsoft jointly released the Open Neural Network Exchange (ONNX) to enable interoperability between various\ndeep learning frameworks like PyTorch and TensorFlow (Candela, 2017).\nAn extensive literature discusses the diverse incentives for commercial adoption and development of OSS at both the\nindividual level (see Table 1) and the organisational level (see Table 2). Bonaccorsi and Rossi's (2006) taxonomy\nof social, economic, and technological incentives at the individual and organisational levels provides an enduring\nframework for categorising these diverse incentives. In addition, they find that divergent incentives between individuals\nand organisations. While individuals are mostly driven by social and technological incentives, such as their personal\ninterest (Benkler, 2006; Raymond, 2001a; von Krogh et al., 2012), values (Kelty, 2008; Lakhani and von Hippel, 2003;\nShah, 2006), or needs (Franke and Hippel, 2003; Hars and Ou, 2002; Roberts et al., 2006), companies are chiefly\nmotivated by economic and technological factors, such as influencing industry standards (Lerner, 2002; Lindman et al.,\n2009), reducing development costs (Birkinbine, 2020; Chesbrough, 2023), and recruiting external developers (Agerfalk\nand Fitzgerald, 2008; Fink, 2003). However, the incentives of individuals vary based on factors such as whether they\nare volunteers or paid (Lakhani and Wolf, 2003; Dahlander and Wallin, 2006), the governance structure of the OSS\nproject (Shah, 2006), and their geography and cultural norms (Subramanyam and Xia, 2008; Takhteyev, 2012), among"}, {"title": "3 Study Design", "content": ""}, {"title": "3.1 Research Aims", "content": "The objective of this study is to identify and categorise commercial interests for AI democratisation and thus contribute\nto advancing the nascent research agenda on the political economy of open source AI (Widder et al., 2023; Srnicek,\n2022; Liesenfeld and Dingemanse, 2024). Specifically, it examines the following research question (RQ): Why do\ncompanies democratise AI? Given the various methods of AI democratisation (Seger et al., 2023b), it focuses on AI OSS\ndonations to foundations\u2014that is, the transfer of an OSS project from a company's ownership to a non-profit foundation\n(O'Mahony and Ferraro, 2007)\u2014which in the AI industry are commonly presented as acts of AI democratisation.\nWhile this narrow scope enables an in-depth analysis of one method of AI democratisation, it naturally limits the\ngeneralisability of the findings to others, such as the increasingly common releases of open models (see Section 5.3).\nWithin this scope, a mixed-methods approach was employed to investigate the incentives for 43 OSS donations between\nMay 2018 and October 2022 by a range of companies, from startups to multinational corporations, to the LF AI & Data\nFoundation and PyTorch Foundation, two foundations under the LF that host OSS for data science and AI. The range of\nprojects and companies form a diverse sample (see Table 5), accounting for various project maturity levels, company\nsizes, sectors, and countries (Runeson and H\u00f6st, 2008; Easterbrook et al., 2008). Furthermore, the mixed-methods\napproach to multiple cases mitigates the uniqueness of single cases (Herriott and Firestone, 1983; Eisenhardt, 1989)\nand data sources or methods (Yin, 2018; Lehdonvirta et al., 2019), thus enhancing the validity of the findings. The\nstudy received ethical clearance by the University of Oxford CUREC review board prior to data collection."}, {"title": "3.2 Case Presentation", "content": ""}, {"title": "3.2.1 LF AI & Data Foundation", "content": "The LF AI & Data Foundation was founded in March 2018 as the LF Deep Learning Foundation and rebranded as the\nLF AI Foundation in May 2019, broadening its scope to encompass various AI sub-fields. In October 2020, it merged\nwith the ODPi, an organisation promoting a big data software ecosystem. The foundation subsequently rebranded\nas the LF AI & Data Foundation, acknowledging the vital role of data in AI R&D. At the point of data collection\n(October 2022), the foundation had 51 member companies from North America, Europe, and East Asia. It hosted 42\nOSS projects that had been donated by diverse organisations, including startups (e.g., AI Squared), research institutes\n(e.g., the Beijing Academy of AI), consortia (e.g. ONNX), management consultancies (e.g., McKinsey & Co.), and\ntechnology giants (e.g., IBM, Samsung, and Tencent). When a company seeks to donate an OSS project to the LF\nAI & Data Foundation, they must be a member organisation of the LF or be endorsed by a member and submit their\nproposal for review by the technical advisory council (TAC). The TAC comprises representatives from the various\nprojects at the foundation and premier member companies, who vote on the approval of donation proposals. The LF\nAI & Data Foundation segregates business and technical governance of hosted OSS projects, ensuring that developers\nretain technical control in their projects whilst the foundation assumes responsibility for funding, marketing, and license\ncompliance, among others, and enforces open community governance (Dolan, 2023)."}, {"title": "3.2.2 PyTorch Foundation", "content": "The PyTorch Foundation was established in September 2022 to host the popular PyTorch deep learning framework\nthat had been donated by Meta (PyTorch, 2023). Its mission is to \"driv[e] the adoption of AI tooling by fostering\nand sustaining an ecosystem of open source, vendor-neutral projects integrated with PyTorch\u201d and \u201cto democratise\nstate-of-the-art tools, libraries, and other components to make these innovations accessible to everyone\" (PyTorch,\n2023). The PyTorch Foundation similarly maintains a separation between business and technical governance for the\nPyTorch project and wider ecosystem, with the PyTorch project retaining its technical governance structure while the\nfoundation is responsible for funding, hosting expenses, and events, among others. The PyTorch Foundation manages\nthe project's assets, including its website, GitHub repository, and social media accounts, and enforces open community\ngovernance. Upon its launch, it formed a governing board comprising representatives from its initial members: AMD,\nAmazon Web Services, Google Cloud, Hugging Face, IBM, Intel, Meta, Microsoft, and Nvidia (PyTorch, 2023). The\ngoverning board members shape PyTorch's strategic direction through voting rights, contribute to the project's technical\ndevelopment and roadmap, and gain benefits such as early feature access and increased visibility in the PyTorch\necosystem, while being expected to actively support and promote PyTorch's growth and adoption."}, {"title": "3.3 Data & methods", "content": ""}, {"title": "3.3.1 Data Collection", "content": "This study comprises two sources of primary data and two sourcs of secondary data. First, two types of secondary data\nwere collected from the Internet for 43 AI OSS donations to the LF (42 donations to the LF AI & Data Foundation\nand 1 donation to the PyTorch Foundation). First, pre-donation technical pitches to the TAC were collected from the\nLF AI & Data Foundation wiki page (LFAI&Data, 2023). Second, post-donation blog posts by the LF and respective\ncompanies were collected from the LF AI & Data Foundation website and through Google search queries in the format\nof \"[company name] + [project name] + [LF AI & Data Foundation]. This yielded 40 presentations (95%) and 37 (88%)\nblog posts for the 42 projects donated to the LF AI & Data Foundation. It was not possible to collect a pre-donation\ntechnical pitch for the PyTorch donation because, as an inaugural project of its namesake foundation, it did not follow\nthis process. Blog posts were accessed via the PyTorch Foundation website and Google search queries using the\naforementioned format. A full list of the 43 OSS projects, donors, and respective document links is provided in Table 5.\nSubsequently, primary data was collected through questionnaires and 12 semi-structured interviews with ten project\nmaintainers who had donated the project and two foundation employees. First, a brief questionnaire was distributed\nto the maintainers to gather information on the donation process, incentives, and outcomes, as well as to recruit\ninterviewees. It was distributed via the LF AI & Data Foundation's mailing list and to the PyTorch maintainers via\nthe Executive Director of the PyTorch Foundation, resulting in 16 responses from the maintainers of 16 projects at the\nLF AI & Data Foundation and 0 responses from the maintainers of PyTorch (in total, 37% of the 43 projects). Ten\nmaintainers were recruited for interviews through the questionnaire, who worked for 9 companies, diverse by geography,\nsize, and sector (see Table 3). In addition, the Executive Director of the foundations (N.B. same person) and a LF AI &\nData Foundation project coordinator were interviewed. The 12 interviews lasted between 30 and 60 minutes and were\nsemi-structured, combining standardised questions about the donation process with tailored questions based on their\nquestionnaire responses, adding depth to the quantitative findings in Figure 1. The interviews were conducted digitally,\nand were recorded to aid analysis and to enhance the validity of the research findings (Yin, 2018)."}, {"title": "3.3.2 Data Analysis", "content": "Thematic analysis was applied to systematically identify commonalities, patterns, and relationships in the qualitative\ndata (Cruzes and Dyba, 2011). A systematic six-step procedure was followed to enhance the reliability of this analysis\n(Braun and Clarke, 2006). The initial coding procedure involved an integrated approach, combining the inductive\ncoding (Charmaz, 2006) and a deductive coding informed by prior work on incentives that exist at the levels of\nindividual developers (see Table 1) and organisations (see Table 2). This approach allowed for the identification of\nboth commonalities with prior work and novel findings concerning open source AI democratisation efforts. The coding\nwas conducted by the author until reaching saturation (Charmaz, 2006), then merged codes into 25 distinct themes\n(i.e., social, economic, and technological incentives at the level of individual developers and companies shown in\nTable 4). To address the limitation of single-author analysis, each step was rigorously documented, and the results\nwere member-checked with the interviewees and discussed with two academic advisers (Edwards and Holland, 2013;\nKing, 2009). Furthermore, the interviewees were invited to review the quotes attributed to their anonymised IDs and to\nstate their attribution preference, ensuring consent for the inclusion of statements. Only three interviewees proposed\nrevisions (e.g., to enhance specificity), indicating the resonance of the findings with the practitioners."}, {"title": "3.3.3 Reflexivity", "content": "In social science research, it is critical that one as a researcher engages in critical self-evaluation of the one's positionality\nand disiplinary conventions, and how they may influence one's research, from its initial design through to the reporting\nof and presentation of research findings (Finlay, 2002). The exercise of reflexivity was particularly important for the\ncredibility of this study, given the author's affiliation with the LF as a research contractor. A social identity map was\nemployed as a tool to encourage reflection on positionality and to address potential biases in three areas (Jacobson and\nMustafa, 2019). First, at the outset, it was used to consider the effects of the LF affiliation on data access and potential\nthreats to reproducibility, recognising that the LF affiliation likely increased the willingness of foundation staff and\nproject maintainers to participate in the study. To enhance reproducibility, the data collection strategy relied primarily\non publicly available information (e.g., mailing lists) and information sheets sent with invitations explicitly stated the\nindependent purpose and funding for the research. Second, to minimise social desirability bias in interview responses,\nthe research's independent purpose and funding mentioned in the information sheet were explained to interviewees\nat the beginning of each interview. Third, a journal was maintained during the thematic analysis to document coding\nchoices, and the findings were shared with two academic advisers to review the interpretations. While these actions\ncontribute to enhancing the credibility and reliability of the research process, it must be acknowledged that it is difficult,\nif not impossible, to perform bias-free research and, therefore, it should be understood as an imperfect, yet best-effort\nattempt by the author to control for and mitigate potential biases in the research process (Jacobson and Mustafa, 2019)."}, {"title": "4 Results", "content": "The findings reveal an interplay of social, economic, and technological incentives at both individual and organisational\nlevels for OSS donations to foundations (see Table 4). This section presents these findings, contributing a more nuanced\nunderstanding of the bottom-up and top-down incentives behind AI democratisation efforts by companies."}, {"title": "4.1 Individual-level Incentives", "content": "Individual employees often play a crucial role in championing and coordinating the donation process within their\ncompanies. 38% of questionnaire respondents stated that the decision to donate was driven from the bottom up by\ndevelopers, while 13% of respondents stated the decision was made by individuals who held both developer and\nmanagerial roles (e.g., startup founders). These findings underscore the importance of understanding individual\nincentives in shaping commercial decisions to donate OSS projects to foundations."}, {"title": "4.1.1 Social Incentives", "content": "At the individual level, social incentives are as a significant driver for OSS donations. Two key themes stood out:\nreciprocity and personal reputation. Many developers expressed a deep-seated ethos of 'giving back\u201d to the community\nthat supports their work. For instance, Respondent A (BeyondML) stated:\nThe vast majority of proprietary models and software in data science and machine learning are built\non open source, so being part of that and contributing to that is really important to me personally\nand to our company.\nThis sentiment was echoed by Respondent H (NNStreamer), who noted that their donation was", "dream of having your big open source project with 1000s of stars.": "espondent I (ONNX-MLIR) added\nthat improving one's reputation also leads to career benefits, as one can be hired based on one's reputation, and that\nindividuals' aspirations align with company's goals to improve their corporate reputation as an OSS-friendly workplace."}, {"title": "4.1.2 Economic Incentives", "content": "Two primary economic incentives at the individual level are career benefits and access to foundation support services.The\nreputational gains from OSS contributions often translate into tangible career benefits. For example, respondent I\n(ONNX-MLIR) noted that achievements in OSS projects make developers more competitive in the AI job market,\nas their expertise at the intersection of software engineering and AI becomes both known and knowable in the wider"}, {"title": "4.1.3 Technological Incentives", "content": "Technological incentives at the individual level include ensuring project sustainability and enabling the use of collabora-\ntion tools. Project sustainability is a significant concern for maintainers. Respondent G (Ludwig) provided a compelling\nexample, describing how he donated his project to ensure its survival following organisational restructuring and his\npersonal departure from the company. He viewed the transition to a foundation as an effective strategy to ensure the\nproject's continuation. This case demonstrates how personal attachment to projects, which he described as his \"baby\",\ncan drive individuals to seek sustainable governance models for their OSS projects, especially when their affiliation\nwith the company comes to an end. It also highlights the use of OSS donations as a mechanism to preserve source code\nthat might otherwise be lost due to corporate changes or neglect.\nThe ability to use preferred collaboration tools is another technological incentive. Respondents D and E (Kedro)\nexplained that transitioning the project to the LF AI & Data Foundation made it easier to use tools like Slack and\nDiscord, which were either forbidden or difficult to get approval for at their company. As Respondent E (Kedro)\nexplained, \u201cIt untied our hands from our own bureaucracy.\" They elaborated that this freedom from corporate constraints\nconcerning collaboration tools not only enhances developer productivity and satisfaction but also aligns with broader\norganisational goals of fostering innovation and efficiency, thus representing a win-win scenario for them.\""}, {"title": "4.2 Organisational-level Incentives", "content": "While individual employees play a crucial role in championing OSS donations within their companies, organisational\nincentives (i.e., corporate strategies) ultimately matter above all in the decision-making process, with 44% of respondents\nstating that the donation was a top-down decision by managers and 13% respondents stating that the decision was made\nby individuals who held both developer and managerial roles within their company."}, {"title": "4.2.1 Social Incentives", "content": "At the organisational level, three primary social incentives emerged: adopting open governance, reciprocating to the\nOSS ecosystem, and building the company's reputation. The adoption of open governance upon donating a project to a\nfoundation is a salient incentive, with 81% of respondents reporting it as important. This change in governance model\nis viewed as a structural enabler for downstream goals. For example, Detakin's press release highlighted this incentive:\nThe LF AI & Data provides a vendor-neutral governance structure that can help the project grow\nbroad industry collaboration. Even more importantly, becoming a LF AI & Data project ensures that\nOpenLineage can never belong to a company.\nSimilarly, Lyft emphasised the importance of a \"neutral holding ground\" when donating both Amundsen and Flyte.\nThese statements underscore the perceived value of neutral governance in fostering collaboration and ensuring the\nindependence of projects.\nSimilar to individuals, reciprocity to the OSS ecosystem is a key social incentive at the organisational level. Several\nrespondents cited the critical importance of OSS dependencies in their companies' proprietary products and services,\nand perceived the donation of their OSS project as one way to \"give back\u201d, as explained by Respondent A (BeyondML).\nIn a similar vein, Respondent C (Elyra) underscored the impact of OSS for advances in AI as a reason for why he\nchampions giving back to the ecosystem:"}, {"title": "4.2.2 Economic Incentives", "content": "Several economic incentives at the organisational level inform the decision to donate OSS projects, including attracting\nexternal contributors, reducing development costs, diversifying project funding, and harnessing foundation support\nservices. Indeed, being able to attract new contributors to their project is a critical incentive for OSS donations, with\n100% respondents reporting it as important. Respondent J (ONNX-MLIR) described OSS donations as a strategic trade-\noff, where companies exchange full control of their OSS project for the aspired for benefits of distributed development\ninvolving a community of contributors. He noted the self-interested logic:\nWe continue doing the same work as we would if it wasn't an open source project, but there's this\nexpectation that we're going to benefit from a community helping us achieve our own goals.\nRespondent G (Ludwig) explained that above all it is beneficial for attracting contributors from other companies, who", "view": "nIn reality, in all the projects that I've seen, they are still driven by the main inventors. Open governance\njust means that the feedback comes from additional contributors ... It's more like a community project.\nHowever, respondents cautioned that changing the governance model does not guarantee more or useful external\ncontributions. Respondent D (Kedro) explained she had rejected pull requests \u201cbecause they were not up to scratch", "company": ""}, {"title": "4.2.3 Technological Incentives", "content": "At the organisational level, several technological incentives were identified, including ecosystem integration and\nadoption, software improvements, faster innovation, and influencing industry standards. Respondents highlighted that\njoining a foundation offered ecosystem benefits. For example, respondent C (Elyra) noted:\nTogether with [open governance], we thought being in an ecosystem of other machine learning and\nAl projects would foster collaboration and integration, exposing Elyra to more use cases.\nThis perspective illustrates how companies view foundation ecosystems as platforms for enhanced collaboration and\nproject visibility, potentially leading to more adoption and more diverse applications of their software. This was\nconfirmed by 88% of respondents who reported increasing adoption as an important incentive for their company.\nSoftware improvements and faster innovation were also identified as significant technological incentives. Respondent\nB (Elyra) observed that \u201cThat's something which is one strength of open source; it's much more properly tested\nthan [proprietary] software.", "commented": "nI think that move was actually made to destroy TensorFlow because TensorFlow [does not have]\nopen governance.\nRespondent D (Kedro) suggested that Meta was seeking to beat TensorFlow out of the market since Google would\nstruggle to compete with the strategic alliance of industry giants that had formed under the PyTorch Foundation's\ngoverning board (which even includes Google). Respondent B (Elyra) was more direct, describing it as \u201ca death knell to\nTensorFlow.", "explained": "nEvery company may have a different set of incentives but what's common across all of them is the\ndesire to make sure that the project becomes successful in the long term and becomes the de facto\nproject for its given functionality.\nThese findings reveal a complex interplay of social, economic, and technological incentives driving companies to donate\nAI OSS to foundations. The incentives span both individual and organisational levels, highlighting the multifaceted\nnature of AI democratisation efforts. These insights provide a nuanced understanding of the strategies and considerations\nthat shape commercial decisions, practices, and strategies in the open source Al ecosystem."}, {"title": "5 Discussion", "content": ""}, {"title": "5.1 Implications for Research", "content": ""}, {"title": "5.1.1 Disambiguating \u201cAI Democratisation\" Narratives", "content": "The findings shed light on the inconsistent use of \"AI democratisation\" in commercial narratives surrounding OSS\ndonations, extending the work of Seger et al. (2023b). They show that in the context of OSS donations, the most\nrelevant interpretation is the democratisation of governance, as companies transfer already open-sourced software\nfrom their single-vendor governance to open governance provided by vendor-neutral foundations. This transition of\ngovernance and control rights, however, is not an end in itself but a strategy that aims to realise goals, such as increasing\nadoption and recruiting new contributors to the project. It is often the companies seek, in particular, participation by\nother companies, who previously would hesitate to contribute to a company's OSS project, confirming prior findings\non \"hold-up\" problems (Yue and Nagle, 2024). These findings challenge the"}]}