{"title": "Statistical Reachability Analysis of Stochastic Cyber-Physical\nSystems under Distribution Shift", "authors": ["Navid Hashemi", "Lars Lindemann", "Jyotirmoy V. Deshmukh"], "abstract": "Reachability analysis is a popular method to give safety guarantees for stochastic cyber-\nphysical systems (SCPSs) that takes in a symbolic description of the system dynamics and uses\nset-propagation methods to compute an overapproximation of the set of reachable states over\na bounded time horizon. In this paper, we investigate the problem of performing reachability\nanalysis for an SCPS that does not have a symbolic description of the dynamics, but instead\nis described using a digital twin model that can be simulated to generate system trajectories.\nAn important challenge is that the simulator implicitly models a probability distribution over\nthe set of trajectories of the SCPS; however, it is typical to have a sim2real gap, i.e., the actual\ndistribution of the trajectories in a deployment setting may be shifted from the distribution as-\nsumed by the simulator. We thus propose a statistical reachability analysis technique that, given\na user-provided threshold 1 \u2013 \u20ac, provides a set that guarantees that any reachable state during\ndeployment lies in this set with probability not smaller than this threshold. Our method is based\non three main steps: (1) learning a deterministic surrogate model from sampled trajectories, (2)\nconducting reachability analysis over the surrogate model, and (3) employing robust conformal\ninference using an additional set of sampled trajectories to quantify the surrogate model's dis-\ntribution shift with respect to the deployed SCPS. To counter conservatism in reachable sets,\nwe propose a novel method to train surrogate models that minimizes a quantile loss term (in-\nstead of the usual mean squared loss), and a new method that provides tighter guarantees using\nconformal inference using a normalized surrogate error. We demonstrate the effectiveness of our\ntechnique on various case studies.", "sections": [{"title": "1 Introduction", "content": "Safety-critical cyber-physical systems operate in highly dynamic and uncertain environments. It is\ncommon to model such systems as stochastic dynamical systems where given an initial configuration\n(or state) of the system, system parameter values, and a sequence of exogenous inputs to the system,\na simulator can provide a system trajectory. Several executions of the simulator can generate a sam-\nple distribution of the system trajectories, and such a distribution can then be studied with the goal\nof analyzing safety and performance specifications of the system. In safety verification analysis, we\nare interested in checking if any system trajectory can reach an unsafe state. A popular approach for\nsafety verification considers only bounded-time safety properties using (bounded-time) reachability\nanalysis [1-5]. Here, the typical assumption is that the symbolic dynamics of the simulator (i.e.\nthe equations it uses to provide the updated state from a previous state and stimuli) are known.\nMost reachability analysis methods rely on a deterministic description of the symbolic dynamics\nand use set-propagation methods to compute a flowpipe or an overapproximation of the set of states\nreachable over a specified time horizon. Other methods allow the system dynamics to be stochastic,\nbut rely on linearity of the dynamics to propagate distributions over initial states/parameters to\ncompute probabilistic reach sets [6-9].\nHowever, for complex cyber-physical systems, dynamical models may be highly nonlinear or\nhybrid with artifacts such as look-up tables, learning-enabled components, and proprietary black-\nbox functions making the symbolic dynamics either unavailable, or difficult for existing (symbolic)\nreachability analysis tools to analyze them. To address this issue, we pursue the idea of model-free\nanalysis, where the idea is to compute reachable sets for the system from only sampled system\ntrajectories [10, 11]. The main idea of data-driven reachability analysis in [10] consists of the fol-\nlowing main steps: Step 1. Sample system trajectories based on a user-specified distribution on a\nparametric set of system uncertainties (such as the set of initial states). Step 2. Train a data-driven\nsurrogate model to predict the next K states from a given state (for example, a neural network-based\nmodel). Step 3. Perform set-propagation-based reachability analysis using the surrogate dynamics.\nStep 4. Inflate the computed flowpipe with a surrogate error term that guarantees that any actu-\nally reached state is within the inflated reach set with probability not smaller than a user-provided\nthreshold.\nThere are three main challenges in this overall scheme: (1) In [10], a simple training loss based\non minimizing the mean square error between the surrogate model and the actual system is used.\nThis may lead to the error distribution to have a heavy tail, which in turn leads to conservatism\nin the inflated reach set. (2) The approach in [10] uses the uncertainty quantification technique of\nconformal inference to construct the inflated flowpipes, but quantifies surrogate error per trajectory\ncomponent (i.e, per state dimension and per trajectory time-step). These per-component-wise\nprobabilistic guarantees are then combined using union bounding, i.e., using that $P(A \\cup B) \\le P(A) + P(B)$, leading to conservatism. This is because requiring a 1 \u2013 \u0454 probability threshold on\nthe inflated reach set requires stricter probability thresholds in the conformal inference step per\ncomponent, i.e., thresholds 1 \u2013 e' with $e' = \\frac{\\epsilon}{nK}$, where n is the number of dimensions and K is the\nnumber of time-steps in the trajectory. A stricter probability threshold induces a larger uncertainty\nset, which implies greater conservatism. (3) The most significant real-world challenge is that the\nsurrogate model is usually learned based on the trajectories sampled from the simulator, and thus\ndistributed according to the assumptions on stochasticity made by the simulator. However, the\nactual trajectory distribution in the deployed system may change. Typically, such distribution\nshifts can be quantified using divergence measures such as an f-divergence or the Wasserstein\ndistance [12].\nTo address these challenges, we propose a robust and efficient approach to computing proba-\nbilistic reach sets for stochastic systems, with the following main contributions: (1) We propose\nnovel training algorithms to obtain surrogate models to forecast trajectories from sampled initial\nstates (or other model parameters). Instead of minimizing the mean square loss between predicted\ntrajectories and the training trajectories, we allow minimizing an arbitrary quantile of the loss func-\ntion. This provides our models with better overall predictive performance over the entire trajectory\nspace (i.e., over different state dimensions and time steps). (2) Similar to [10], we utilize conformal\ninference (CI) to quantify prediction uncertainty. However, inspired by work in [13], we compute\nthe maximum of the weighted residual errors to compute the nonconformity score to use with CI\nwhich has the effect of normalizing component-wise residuals. In contrast to [13], which solves a lin-\near complementarity problem to compute these weights, we obtain these weights when training the\nsurrogate model using gradient descent and backpropagation. (3) Finally, to address distribution"}, {"title": "2 Problem statement and Preliminaries", "content": "Notation. We use bold letters to represent vectors and vector-valued functions, while calligraphic\nletters denote sets and distributions. The set {1,2,\u2026, n} is denoted as [n]. The Minkowski sum is\nindicated by\u2295. We use $x \\sim X$ to denote that the random variable x is drawn from the distribution\n\u03a7.\nStochastic Dynamical Systems. We consider discrete-time stochastic dynamical systems. While\nit is typical to describe such systems using symbolic equations that describe how the system evolves\nover time, we instead simply model the system as a stochastic process. In other words, let $S_0, ..., S_K$\nbe a set of $K + 1$ random vectors indexed by times 0, ..., K. We assume that for all times k, each\n$S_k$ takes values from the set of states $S \\subset \\mathbb{R}^n$. A realization of the stochastic process, or the system\ntrajectory is a sequence of values $s_0, ..., s_k$, denoted as $s_{0:K}$. The joint distribution over $S_0, ..., S_K$\nis called the trajectory distribution $\\mathcal{D}_{S,K}^{\\text{real}}$ of the system, and the marginal distribution of $S_0$ is called\nthe initial state distribution $W$. We assume that the initial state distribution W has support over\na compact set of initial states $I$, i.e., we assume that W is such that $Pr[s_0 \\notin I] = 0$. For example,\nsuch a stochastic dynamical system could describe a Markovian process, where for any $k \\ge 1$, the\ndistribution of $S_k$ only depends on the realization of $S_{k-1}$ and not the values taken at any past time.\nHowever, it is worth noting that the techniques presented in this paper can be applied to systems\nwith non-Markovian dynamics.\nIn the rest of the paper, we largely focus on just the system trajectories, so we abuse notation\nto denote $s_0 \\sim W\\vert_I$ to signify that $s_0$ is a value sampled from $I$ using the initial state distribution\n$W$.\\footnote{W is assumed to be uniform or truncated Gaussian distributed in practice.}\nSimilarly, $s_{0:K} \\sim \\mathcal{D}_{S,K}^{\\text{real}}$ is used to denote the sampling of a trajectory from the trajectory\ndistribution.\nQuantification of Distribution Shift. In practice, we usually do not have knowledge of the\ndistribution $\\mathcal{D}_{S,K}^{\\text{real}}$. However, one may have access to trajectories sampled from a distribution $\\mathcal{D}_{S,K}^{\\text{sim}}$\nthat is \"close\" to $\\mathcal{D}_{S,K}^{\\text{real}}$, e.g., a simulator. Given a distribution $D$, we use the notation $P(D)$ to\ndenote a set of distributions close to $D$, where the notion of proximity is defined using a suitable\ndivergence measure or metric quantifying distance between distributions. Common examples include\nf-divergence measures (such as KL-divergence, total variation distance) and metrics such as the\nWasserstein distance [12,35]. In this paper, we assume that $\\mathcal{D}_{S,K}^{\\text{sim}}$ comes from the ambiguity set\n$P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}})$ that is centered at $\\mathcal{D}_{S,K}^{\\text{sim}}$ using f-divergence balls around $\\mathcal{D}_{S,K}^{\\text{sim}}$ [35]. Given a convex\nfunction $f: \\mathbb{R} \\rightarrow \\mathbb{R}$ satisfying $f(1) = 0$ and $f(z) = +\\infty$ for $z < 0$, the f-divergence [16] between\nthe probability distributions $\\mathcal{D}_{S,K}^{\\text{sim}}$ and $\\mathcal{D}_{S,K}^{\\text{real}}$ that both have support $Z$ is\n$D_f (\\mathcal{D}_{S,K}^{\\text{real}} || \\mathcal{D}_{S,K}^{\\text{sim}}) = \\int_Z f(\\frac{d\\mathcal{D}_{S,K}^{\\text{real}}}{d\\mathcal{D}_{S,K}^{\\text{sim}}}) d\\mathcal{D}_{S,K}^{\\text{sim}}$\nHere, the argument of f is the Radon-Nikodym derivative of $\\mathcal{D}_{S,K}^{\\text{real}}$ w.r.t. $\\mathcal{D}_{S,K}^{\\text{sim}}$. We define the set\n$P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}})$ as a f-divergence ball of radius $\\tau > 0$ around $\\mathcal{D}_{S,K}^{\\text{sim}}$ as\n$P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}}) = \\{\\mathcal{D} | D_f(\\mathcal{D} || \\mathcal{D}_{S,K}^{\\text{sim}}) \\le \\tau\\}.$\nThe radius $\\tau$ and the function $f$ are both user-specified parameters that quantify the distribution\nshift between $\\mathcal{D}_{S,K}^{\\text{real}}$ and $\\mathcal{D}_{S,K}^{\\text{sim}}$ that we have to account for in our reachability analysis. Specifically, we\nhave to perform reachability analysis for random trajectories $s_{0:K}^{\\text{real}} \\sim \\mathcal{D}_{S,K}^{\\text{real}}$ for all $\\mathcal{D} \\in P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}})$.\nConformal Inference. Conformal inference [36\u201338] is a data-efficient statistical tool proposed for\nquantifying uncertainty, particularly valuable for assessing the uncertainty in predictions made by\nmachine learning models [39,40].\nConsider a set of random variables $z_1, z_2, \u2026, z_{m+1}$ where $z_i = (x_i, y_i) \\in \\mathbb{R}^n \\times \\mathbb{R}$ for $i \\in [m + 1]$.\nAssume that $z_1, z_2,\u2026\u2026, z_{m+1}$ are independent and identically distributed (i.i.d.). Let $\\mu(x_i)$ be a\npredictor that estimates outputs $y_i$ from inputs $x_i$. With a pre-defined miscoverage level $\\epsilon \\in (0,1)$,\nconformal inference enables computation of a threshold $d > 0$ and a probabilistic prediction interval\n$C(x_{m+1}) = [\\mu(x_{m+1}) \u2212 d, \\mu(x_{m+1}) + d] \\subseteq \\mathbb{R}$ for $y_{m+1}$ that guarantees that $Pr[y_{m+1} \\in C(x_{m+1})] \\ge$\n$1 - \\epsilon$. To compute the threshold d, we reason over the empirical distribution of the residual errors\nbetween the predictor and the ground truth data. Let $R_i := |y_i - \\mu(x_i)|$ be the residual error\nbetween $y_i$ and $\\mu(x_i)$ for $i \\in [m + 1]$. Since the random variables $z_1, z_2, ..., z_{m+1}$ are i.i.d., the\nresiduals $R_1, ..., R_{m+1}$ are also i.i.d. If m satisfies $l := [(m + 1)(1 \u2212 \\epsilon)] \\le m$, then we take the $l$th\nsmallest error among these m values which is equivalent to\n$R_{1-\\epsilon} = Quantile_{1-\\epsilon} \\{R_1, ..., R_m,\\infty\\},$\n(2.1)\ni.e., the (1 \u2013 \u20ac)-quantile over $R_1,..., R_m, \u221e$, see [41].\nConformal inference uses this quantile to obtain the probability guarantee $Pr[R_{m+1} < R_{1-\\epsilon}] \\ge$\n(1 - \\epsilon)$, see [36,41]. For the choice of $R_i := |y_i - \\mu(x_i)|$, this can be rewritten as\n$Pr [y_{m+1} \\in [\\mu(x_{m+1}) \u2013 R_{1-\\epsilon}, \\mu(x_{m+1}) + R_{1-\\epsilon}]] \\ge 1 \u2212 \\epsilon.$\n(2.2)\nThe guarantees in (2.2) are marginal$^3$, i.e., over the randomness in $R_{m+1}, R_1, R_2, ..., R_m$. Note\nthat $R_{1-\\epsilon}$ is a provable upper bound for the (1 \u2013 \u20ac)-quantile of the error distribution.\nRobust Conformal Inference. Unlike conformal inference, which assumes the data-point $z_{m+1}$ is\nsampled from the same distribution as the calibration samples $z_i, i \\in [m]$, robust conformal inference\nrelaxes this assumption and allows $z_{m+1}$ to be sampled from a different distribution. Let us denote\nthe distribution of $z_i$ for $i \\in [m]$ as $U$ and the distribution of $z_{m+1}$ as $V$. As illustrated before, the\nresidual $R_i$ is a distribution and defined as a function of $z_i$. Let us denote the distribution of $R_i$ for\n$i \\in [m]$ with $P$ and the distribution of $R_{m+1}$ with $Q$. Further, assume $Q$ is in $P_{f,\\tau}(P)$. Utilizing\nthe results from [14] that assumes the distribution of residual $R_{m+1}$ is within a f-divergence ball of\nthe distributions for $R_1, ..., R_m$ with radius $\\tau > 0$, for the miscoverage level $\\epsilon \\in (0,1)$, we obtain:\n$Pr[R_{m+1} < R_{1-\\epsilon,\\tau}] \\ge 1 \u2212 \\epsilon$\nwhere $R_{1-\\epsilon,\\tau} = Quantile_{(1-\\bar{\\epsilon})} \\{R_1,...,R_m,\\infty\\}$ is a robust (1 \u2013 \u20ac)-quantile that is equivalent to\nthe (1 - \u20ac)-quantile. We refer to $ \\bar{\\epsilon}$ as the adjusted miscoverage level which is computed as $\\bar{\\epsilon} =$\n$1-g_{f,\\tau}^{-1}(1-g_{f,\\tau}(\\epsilon_m))$ where $\\epsilon_m$ is obtained as the solution of a series of convex optimizations problems\nas$^5$:\n$\\epsilon_m = 1-g_{f,\\tau}^{-1}((1+\\frac{1}{m})g_{f,\\tau}(\\epsilon))$\n$g_{f,\\tau}(\\beta) = inf \\{x \\in [0, 1] | \\beta f(\\frac{x}{\\beta})+(1-\\beta)f(\\frac{1-x}{1-\\beta})\\le\\tau\\}$\n$g_{f,\\tau}^{-1}(\\gamma) = sup \\{\\beta \\in (0,1) | g_{f,\\tau}(\\beta) \\le \\gamma\\}$\n(2.3)\nComputation of $g_{f,\\tau}$ and $g_{f,\\tau}^{-1}$ is efficient since they are both solutions to one dimensional convex\noptimization and therefore admit efficient binary search procedures. In some cases, we have also\naccess to a closed form solution [14].\nExample 1. For the total variation, $f(z) = \\frac{1}{2}|z - 1|$, we have $g_{f,\\tau}(\\beta) = max (0, \\beta \u2013 \\tau), g_{f,\\tau}^{-1}(\\gamma) =$\n$\\gamma + \\tau, \\gamma \\in (0,1 \u2013 \\tau)$. This implies that given radius $\\tau \\in [0,1]$ an adjusted miscoverage level \u00e8 is\ninfeasible if $ \\epsilon \\le \\tau$, and $\\bar{\\epsilon}$ is computed as:\n$\\bar{\\epsilon} = 1- \\frac{(1+ \\frac{1}{m}) \\frac{1}{2} (1-\\epsilon+\\tau)}{(1+\\frac{1}{m})}, \\epsilon \\in (\\tau, 1], \\tau \\in [0,1]$\n(2.4)\nProblem Definition. We are given a black-box stochastic dynamical system as the training\nenvironment with the trajectory distribution $\\mathcal{D}_{S,K}^{\\text{sim}}$. We assume that when this system is deployed\nin the real world, the trajectories satisfy $s_{0:K}^{\\text{real}} \\sim \\mathcal{D}_{S,K}^{\\text{real}} \\in P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}})$. Given a user-specified failure\nprobability $\\varepsilon \\in (0, 1)$ and an i.i.d. dataset of trajectories sampled from $\\mathcal{D}_{S,K}^{\\text{sim}}$, the problem is to obtain"}, {"title": "3 Learning A Surrogate Model Suitable for Probabilistic Reacha-bility Analysis", "content": "As we do not have access to the system dynamics in symbolic form, our approach to characterize\nthe trajectory distribution is to use a predictor, called the surrogate model.\nDefinition 1. A surrogate model $F : \\mathbb{X} \\times \\Theta \\rightarrow \\mathbb{Y}$ is a function that approximates a given function\n$f : \\mathbb{X} \\rightarrow \\mathbb{Y}$. Let $d_y$ be some metric on $Y$, then the surrogate model guarantees that for some value of\n$\\theta \\in \\Theta$, and for any $x$ sampled from a distribution over $\\mathbb{X}$, the induced distribution over the random\nvariable $d_y(F(x;\\theta), f(x))$ has good approximation properties, such as bounds on the moments of the\ndistribution (e.g. mean value) or bounds on the quantile of the distribution.\nIn our setting, the set $\\mathbb{X}$ is the set of states $S$ with the distribution over $\\mathbb{X}$ being $\\mathcal{D}_{S,K}^{\\text{sim}}$ and\n$\\mathbb{Y}$ is the set of K-step trajectories $\\mathbb{S}^K$, i.e., F maps a given initial state (or an uncertain model\nparameter) to the predicted K-step trajectory of the system. The metric $d_y$ can be any metric on\nthe trajectory space. One example surrogate model is a feedforward neural network (NN) with n\ninputs and Kn outputs, represented as $\\bar{s}_{0:K} = F(s_0;\\theta)$ where $\\theta$ is the set of trainable parameters.\nTo train the surrogate model, we need to define a specific residual error between a set of sampled\ntrajectories and those predicted by the model. While most surrogate models are trained using the\ncumulative squared loss across a training dataset [42], we consider a loss function that helps us\nreduce conservatism in computing the probabilistic reach set of the system.\nTraining a Lipschitz-bounded NN based surrogate model. Training is a procedure to identify\nthe parameter value @ which makes the surrogate model a good approximation; we use a data-driven\nmethod to train the surrogate by sampling K-step trajectories from the simulator of the original\nmodel. We call this dataset $\\mathcal{T}^{trn}$. The surrogate model predicts the trajectory $\\bar{s}_{0:K}^{\\text{sim}}$ starting from\nan initial state sampled from $s_0 \\sim W\\vert_I$. We denote the predicted trajectory $\\bar{s}_{0:K}^{\\text{sim}}$ corresponding to $s_{0:K}^{\\text{sim}}$\nas:\n$\\bar{s}_{0:K} = [s_0, F(s_0;\\theta)], \\text{ where, } F(s_0 ; \\theta) =$\n$[F_1^1(s_0),\u2026\u2026\u2026, F_n^1(s_0), \u2026\u2026\u2026, F_{(K-1)n+1}^K(s_0),\u2026\u2026, F_{nK}^K(s_0)]$.\nHere, $F_{(i-1)n+r}^i(s_0)$ is the $r^{th}$ state component at the $i^{th}$ time-step in the trajectory. In other words,\nwe stack the dimension and time in the trajectory into a single vector$^6$. We remark that a trained\nsurrogate model with a non-restricted Lipschitz constant is problematic for reachability analysis, as"}, {"title": "4 Scalable Data-Driven Reachability Analysis", "content": "In this section, we show how we can compute a robust probabilistically guaranteed reach set or\nflowpipe $X \\subset \\mathbb{R}^{n(K+1)}$ for a stochastic dynamical system. Given a miscoverage level e, we wish to be\nat least (1-6)-confident about the reach-set that we compute. For brevity, we introduce d = (1\u2212\u0454).\nIn the procedure that we describe, we compute a probabilistically guaranteed d-confident flowpipe,\ndefined as follows:\nDefinition 3 (d-Confident Flowpipe). For a given confidence probability \u03b4\u2208 (0, 1), a distribution\n$\\mathcal{D}_{S,K}^{\\text{sim}}$, the radius \u315c, and a f-divergence ball $P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}})$, we say that $X \\subset \\mathbb{R}^{n(K+1)}$ is a d-confident\nflowpipe if we have $Pr[s_{0:K}^{\\text{real}} \\in X] > d$ for any random trajectory $s_{0}^{\\text{real}} \\sim W\\vert_I, s_{0:K}^{\\text{real}} \\sim \\mathcal{D}_{S,K}^{\\text{real}}$ with\n$\\mathcal{D}_{S,K}^{\\text{real}} \\in P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}})$.\\footnote{In case we replace $\\mathcal{L}_2$ with q, the trivial solution for scaling factors is $\\alpha_j = 0, j \\in [nK]$. Therefore, the proposed\nsecondary loss function $\\mathcal{L}_2$ also results in avoiding the trivial solution for scaling factors.}\nOur objective is to compute X while being limited to sample trajectories from the training\nenvironment $\\mathcal{D}_{S,K}^{\\text{sim}}$. We will demonstrate that we can compute X with formal probabilistic guarantees\nby combining reachability analysis on the surrogate model trained from $\\mathcal{T}^{trn}$ and error analysis on\nthis model via robust conformal inference.\nDeterministic Reachsets for the Surrogate Models. Using the surrogate model from Section\n3, we show how to perform deterministic reachability analysis to get surrogate flowpipes.\nDefinition 4 (Surrogate flowpipe). The surrogate flowpipe $X \\subset \\mathbb{R}^{n(K+1)}$ is defined as a superset of\nthe image of $F(I ;\\theta)$. Formally, for all $s_0 \\in I$, we need that $[s_0, F(s_0 ;\\theta)] \\in \\tilde{X}$.\nThus, to compute the surrogate flowpipe, we essentially need to compute the image of I w.r.t.\nthe F. This can be accomplished by performing reachability analysis for neural networks, e.g., using\ntools such as [3, 34, 45, 46].\nRobust f-Confident Flowpipes. In spite of training the surrogate model to maximize prediction\naccuracy, it is still possible that a predicted trajectory is not accurate, especially when predicting\nthe system trajectory from a previously unseen initial state. Note also that we trained the surrogate\nmodel on trajectory data from $\\mathcal{D}_{S,K}^{\\text{sim}}$. We thus cannot expect the predictor to always perform well\non trajectories drawn from $\\mathcal{D}_{S,K}^{\\text{real}}$. We now show how to quantify this prediction uncertainty using\nrobust conformal inference. To do so, we first sample an i.i.d. set of trajectories from the training\nenvironment $\\mathcal{D}_{S,K}^{\\text{sim}}$, which we again denote as the calibration dataset.\nDefinition 5 (Calibration Dataset). The calibration dataset $\\mathcal{R}^{calib}$ is defined as:\n$\\mathcal{R}^{calib} = \\{(s_{0,i}, R_i) | s_{0,i} \\sim W\\vert_I, s_{0:K}^{\\text{sim}} \\sim \\mathcal{D}_{S,K}^{\\text{sim}}, R_i = max(\\alpha_1 R_i^1,..., \\alpha_{nK} R_i^{nK})\\}.$\nHere, $s_{0:K}^{\\text{sim}}$ refers to the trajectory starting at the $i^{th}$ initial state sampled from W and the resulting\ntrajectory from $\\mathcal{D}_{S,K}^{\\text{sim}}$, and R is as defined in equation (3.1).\nRemark 1. It is worth noting that although the data points within a single trajectory may not\nbe i.i.d., the trajectory $s_{0:K}^{\\text{sim}}$ can be treated as an i.i.d. random vector in the $\\mathbb{R}^{n(K+1)}$-space, and\nsubsequently the residuals are also i.i.d. This is crucial to apply robust conformal inference, which\nrequires that the calibration set is exchangeable (a weaker form of i.i.d.).\nLet $\\mathcal{I}_{S,K}^{\\text{sim}}$ be the distribution over trajectory-wise residuals for trajectories from $s_{0:K}^{\\text{sim}} \\sim \\mathcal{D}_{S,K}^{\\text{sim}}$.\nHowever, we wish to get information about the trajectory-wise residual R for a trajectory sampled\nfrom $\\mathcal{D}_{S,K}^{\\text{real}} \\in P_{f,\\tau}(\\mathcal{D}_{S,K}^{\\text{sim}})$. Let the distribution of $R$ induced by $\\mathcal{D}_{S,K}^{\\text{real}}$ be denoted by $\\mathcal{I}_{S,K}^{\\text{real}}$. As a\ndirect result from the data processing inequality [47], the distribution shift between $\\mathcal{D}_{S,K}^{\\text{real}}$ and $\\mathcal{D}_{S,K}^{\\text{sim}}$\nis larger than the distribution shift between $\\mathcal{I}_{S,K}^{\\text{real}}$ and $\\mathcal{I}_{S,K}^{\\text{sim}}$ so that we have $\\mathcal{I}_{S,K}^{\\text{real}} \\in P_{f,\\tau}(\\mathcal{I}_{S,K}^{\\text{sim}})$.\nKnowing that $\\mathcal{I}_{S,K}^{\\text{real}} \\in P_{f,\\tau}(\\mathcal{I}_{S,K}^{\\text{sim}})$, we can utilize robust conformal inference in [14] to find a\nguaranteed upper bound for the d-quantile of R. We call this guaranteed upper bound as robust\nconformalized d-quantile, and we denote it with $R_{\\delta,\\tau}$, where, $Pr[R < R_{\\delta,\\tau}] \\ge \\delta$. Specifically, we\nutilize equation (2.3) to compute $R_{\\delta,\\tau}$ from the calibration dataset $\\mathcal{R}^{calib}$.\nNext we show that our definition of residual error introduced in (3.2) allows us to use a sin-\ngle trajectory-wise nonconformity score for applying robust conformal inference (instead of the\ncomponent-wise conformal inference as in [10])."}, {"title": "5 Experimental Results", "content": "To mimic real-world systems that can produce actual trajectory data, we use stochastic difference\nequation-based models derived from dynamical system models. In these difference equations, we\nassume additive Gaussian noise that models uncertainty in observation, dynamics, or even modeling\nerrors.\nOur theoretical guarantees depend on knowledge of the distribution shift \u03c4. In practice, however,\nTis usually not known a priori but can be estimated from the data. For the purpose of providing\nan empirical examination of our results, we fix a priori to compute the f-confident flowpipe and\nconstruct a system $\\mathcal{D}_{S,K}^{\\text{real}}$ from $\\mathcal{D}_{S,K}^{\\text{sim}}$ by varying system parameters such that $\\mathcal{I}_{S,K}^{\\text{real}} \\in P_{f,\\tau}(\\mathcal{I}_{S,K}^{\\text{sim}})$.\nWe ensure that this holds by estimating the distribution shift, denoted by 7, as the f-divergence\nbetween $\\mathcal{I}_{S,K}^{\\text{sim}}$ and $\\mathcal{I}_{S,K}^{\\text{real}}$ and by making sure that $\\bar{\\tau} \\le \\tau$. In our experiments, we used the total\nvariation distance for f, and used $3 \\times 10^5$ trajectories to estimate 7.\nWe use ReLU activation functions in our surrogate NN-based models motivated by recent ad-\nvances in NN verification with ReLU activations. We specifically use the NNV toolbox from [34]\nfor reachability analysis of the surrogate model. While other activation functions could be used, we\nexpect more conservative results in case we utilize non-ReLU activation functions. The approach\nin [34] uses star-sets (an extension of zonotopes) to represent the reachable set and employs two main\nmethods: (1) the exact-star method that performs exact but slow computations, (2) the approx-star\nmethod that is conservative but faster. To mitigate the runtime of the exact-star technique and the\nconservatism of the approx-star technique, set partitioning can be utilized [48], where initial states\nare partitioned into sub-regions and reachability is done on each sub-region in parallel.\nAs per Theorem 4.1, our results are guaranteed to be valid with a confidence of \u03b4. To determine\nhow tight this bound is, we will empirically examine the computed probabilistic flowpipes. We do\nso by sampling i.i.d. trajectories from $\\mathcal{D}_{S,K}^{\\text{real}}$$^{10}$ and computing the ratio of the trajectories that are\nincluded in the probabilistic flowpipes, which we denote by \u2206. Additionally, to check the coverage\nguarantee & for $R_{\\delta,\\tau}$, directly, we also report the ratio of the trajectories that provide a residual less\nthan $R_{\\delta,\\tau}$, which we denote with d. We emphasize that \u2206 and \u2642 are both expected to be greater"}, {"title": "6 Conclusion", "content": "Conclusion. This paper addresses challenges in data-driven reachability analysis for stochastic dy-\nnamical systems, specifically focusing on distribution shifts between training and test environments.\nBy leveraging a dataset of K-step trajectories, the approach constructs a probabilistic flowpipe, en-\nsuring that the probability of trajectory violation remains below a user-defined threshold even in\nthe presence of distribution shifts. We propose the reliable guarantees with higher data-efficiency\ncompared to the existing techniques assuming knowledge of an upper bound for distribution shift.\nThe methodology relies on three key principles: surrogate model learning, reachability analysis using\nthe surrogate model, and robust conformal inference for probabilistic guarantees. We illustrated the\nefficacy of our approach via reachability analysis on high-dimensional systems like a 12-dimensional\nquadcopter and unstable systems like the time-reversed van Der Pol oscillator."}]}