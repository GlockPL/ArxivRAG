{"title": "Meaning Typed Prompting: A Technique for Efficient, Reliable Structured Output Generation", "authors": ["Chandra Irugalbandara"], "abstract": "Extending Large Language Models (LLMs) to advanced applications requires reliable structured output generation. Existing methods which often rely on rigid JSON schemas, can lead to unreliable outputs, diminished reasoning capabilities, and increased computational overhead, limiting LLMs' adaptability for complex tasks. We introduce Meaning Typed Prompting (MTP), a technique for efficient structured output generation that integrates types, meanings, and abstractions, such as variables and classes, into the prompting process. By utilizing expressive type definitions, MTP enhances output clarity and reduces dependence on complex abstractions, simplifying development, and improving implementation efficiency. This enables LLMs to understand relationships and generate structured data more effectively. Empirical evaluations on multiple benchmarks demonstrate that MTP outperforms existing frameworks in accuracy, reliability, consistency, and token efficiency. We present Semantix, a framework that implements MTP, providing practical insights into its application\u00b9.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) have enabled the development of sophisticated applications, including complex task automation and domain-specific solutions (Xia et al., 2024) where strict adherence to formatting standards is crucial. Structured outputs improve AI integration into development tools by offering consistent output structures, simplifying error handling, and making LLM-generated responses more reliable for real-world use. With the rise of agentic frameworks (Wu et al., 2023; Mitra et al., 2024), having structured outputs is particularly important for seamless data parsing without an external output validator."}, {"title": "Related works", "content": "Structured output generation from LLMs is essential for ensuring consistency and efficiency (Parnin et al., 2023; Fan et al., 2023). Several frameworks tackle this challenge using different approaches. OpenAI's structured outputs (Pokrass et al., 2024) employ JSON Schema-based constrained decoding to ensure outputs align with predefined formats.\nHowever, this method is restricted to closed-source APIs, limiting transparency, flexibility, and adaptability in diverse environments. Outline (Willard and Louf, 2023) extends this concept to open-source models by incorporating regular expressions, making it more accessible for developers.\nMarvin (Perfect, 2024), ModelSmith (Olivier, 2024), Instructor (Liu, 2023), and Fructose (BananaML, 2023) rely on JSON schemas, leveraging JSON Mode or function-calling APIs, which are typically available only in closed-source LLM APIs. Fructose offers a simplified interface for these APIs but lacks a novel structural approach. DSPy (Khattab et al., 2023) also employs JSON schemas, operating independently of JSON Mode or function-calling APIs, and uses Pydantic models with post-generation assertions to correct output inconsistencies. However, the reliance on JSON schemas and Pydantic models increases development complexity and token consumption across these frameworks.\nLMQL (Beurer-Kellner et al., 2022) introduces a"}, {"title": "Meaning Typed Prompting", "content": "We present Meaning Type Prompting (MTP), At its core we extend traditional built-in types and custom classes to expressive type definitions written in natural language. Moreover, we opt out from using popular JSON schema for structured output requests by using Pythonic class representations. Along with the expressive type definitions and Pythonic class representation, our final prompt consists of Goal, Information & Context, Output Type Definition, Inputs, and Instructions as shown in Figure 2.\nTo clarify the components of the MTP final prompt, we use the example of generating a person's information using a language model, as shown in Figure 2."}, {"title": "Pythonic Class Representation", "content": "Instead of relying on JSON Schema for defining output format like other frameworks, we leverage the LLM's capability to generate structured outputs directly using Pythonic class representations. By moving away from JSON Schema for hierarchical data representation, we omit the need for exces-"}, {"title": "Expressive Type Definitions", "content": "Expressive type definitions enhance traditional built-in types by adding context through natural language. For example, the yob: int can be extended to yob: int - Year of Birth to provide more clarity to the LLM. While using descriptive attribute names such as year_of_birth instead of yob is possible, it still may be insufficient for the LLM to grasp the context. Moreover, from the programmer's perspective, the extra-long identifiers can cause cluttered codes. To address this, the earlier Person class definition can be extended as follows:"}, {"title": "Goal", "content": "While explicitly defining a Goal is optional, it can be used to define the intended task for the LLM clearly and more descriptively. If not provided, the function name will be automatically used as the Goal.\nFor example, an explicit goal will appear in the final prompt as follows:\nGet the Famous Person for the Given Name"}, {"title": "Information & Context", "content": "Information and Context optionally provide additional data to assist the LLM in generating accurate outputs.\nInformation includes task-related elements or examples that guide the LLM in producing correctly formatted outputs which can be used to simulate few-shot prompting (Brown et al., 2020). For example, additional information provided by the user will appear in the system prompt as follows:\nWikipedia Information (wiki_info) = \"Albert Einstein was a German-born theoretical physicist...\"\nExample Famous People (examples) (list[Person]) = []\nContext provides simplified, static instructions for output generation. For example, if only the person's likes outside their profession are needed the context can be specified as follows in the final prompt:\nOnly consider their life outside their profession to identify likes"}, {"title": "Output Type Definition", "content": "This section specifies the function's output type hint. For example, to generate structured data about a famous person, the output type can be defined as:\nPerson"}, {"title": "Inputs", "content": "Inputs are the dynamic fields of a task. For example, when generating structured data about a famous person, the input could be their name. Inputs may vary in type (e.g., str, int) and quantity, with some tasks requiring multiple inputs or none. They can also carry meanings to guide generation. In MTP, inputs are defined as:\nName of the Person (name) (str) = \"Albert Einstein\""}, {"title": "Instructions", "content": "Instructions are directives for generating the output. In MTP, we guide the LLM to produce results within a Markdown code block (```). Additional prompting methods, such as chain-of-thought reasoning, and reflexion can be used to enhance output quality."}, {"title": "Final Prompt", "content": "The Final Prompt is a combination of Goal, Type Definitions, Information and Context, Output Type Definition, Inputs, and Instructions in Markdown format. The prompt is intended to be used with the chat message style, including system messages and user messages. However, due to the structured nature of the prompt, it is also usable in a standard text completion setting."}, {"title": "Semantix", "content": "Semantix is a Python library that automates the generation of meaning-typed prompts. Semantix allows developers to enhance simple functions to enhanced functions simply by adding a decorator named enhance. Semantic type hint allows developers to add expressive type definitions."}, {"title": "Semantic type hint.", "content": "Semantic is an optional type hint provided by Semantix to add expressive type definitions to a variable, argument of a class, or a parameter of a class in the MTP. Our observations indicate that explicit type definitions help the LLM generate outputs in the intended type or unit more reliably. For instance, when adding temperatures x"}, {"title": "Execution.", "content": "During execution, Semantix dynamically generates a Meaning Typed Final Prompt to query the language model, retrieve the output, and transform it into the desired result (see Figure 4). The Object Transformation Process consists of two parts:\nOutput Extraction. The prompt instructs the model to return output within a markdown block labeled \"output\". Although regular expressions typically extract the content, deviations from the expected format trigger a fallback to LLM-based extraction, where the model regenerates the output to ensure accuracy.\nObject Transformation. The extracted output is then processed using Python's Abstract Syntax Tree (AST) within the function's context to return the final object. In case of errors, such as syntax issues or unmatched brackets, the LLM is employed to debug and regenerate the output, improving reliability through iterative correction."}, {"title": "Experiments", "content": "This study evaluates Semantix in comparison to a variety of open-source frameworks, including Instructor, Modelsmith, Llamaindex, and Marvin, with OpenAI Structured Output as the closed-source benchmark. Each framework is assessed with retries \u2208 {0, 2}, where \u201cretries\u201d signifies the number of supplementary attempts permitted if the framework does not succeed on the initial trial."}, {"title": "Benchmarks", "content": "We assess Semantix utilizing the LLM Structured Output Benchmarks (Leo, 2024), which encompass Multi-label Classification, Named Entity Recognition (NER), and Synthetic Data Generation. Multi-label Classification applies the Alexa intent detection dataset (FitzGerald et al., 2022; Bastianelli et al., 2020), requiring the framework to predict the labels associated with a given text. The text exemplifies a natural language command (e.g., wake me up at nine am on Friday), with the ground truth label (e.g., \"alarm set\u201d) representing the intent of the command selected from a set of 60 labels. The synthetic test set, developed to evaluate the framework following (Leo, 2024), consolidates multiple commands and necessitates the intent labels for all commands to be addressed in a single framework request. Named-entity Recognition is predicated on the Synthetic PII Finance Dataset (Watson et al., 2024), whereby the framework must identify all entities corresponding to a set of labels for a specific text. Synthetic Data Generation is dedicated to the generation of fictitious personal information constrained to a strict format. More details on the exact required output format, dataset examples and sample outputs can be found at Appendix A.1.1."}, {"title": "Evaluation Metrics", "content": "We present an analysis of Reliability and Token Usage for all aforementioned experiments. Reliability is quantified as the percentage of instances where the framework successfully returns valid labels without errors in the exact required format as described in (Leo, 2024). Token Usage is the total of prompt and completion tokens per query. For multi-label classification and named entity recognition tasks, micro-precision, micro-recall, and micro-F1 scores are reported, with provisions for partial credit in cases where the output is partially correct. Furthermore, we introduce the metric of exact accuracy, which assesses the degree to which the output entirely corresponds to the ground truth. We utilize the metric of variety to denote the percentage of unique names relative to the entirety of names generated by the framework during synthetic data generation experiments.\nGiven the obvious challenge of directly compar-"}, {"title": "Results and Analysis", "content": "We evaluated various frameworks across three tasks: Multi-label Classification, Named Entity Recognition (NER), and Synthetic Data Generation. The GMS and consistency metrics are shown in Table 2, with detailed results provided in Figure 5 and Tables 4, 5, and 6."}, {"title": "Multi-label Classification", "content": "Semantix achieved the highest GMS scores for both retries = 0 and 2, demonstrating its ability to provide correct labels in the requested format while using only half the tokens compared to Fructose. All frameworks, except Marvin, reached perfect reliability when the number of retries increased."}, {"title": "Named Entity Recognition Task", "content": "As shown in Figure 5(b), Semantix, Fructose, and OpenAI achieved perfect reliability with retries. Instructor and Semantix had the highest precision for retries = 0 and 2, respectively, reflecting their effectiveness in entity identification. Semantix reported the best GMS score and the lowest token usage among all frameworks."}, {"title": "Synthetic Data Generation Task", "content": "In the synthetic data generation task (Figure 5(c)), most frameworks achieved high reliability. Fruc-"}, {"title": "Analysis", "content": "We highlight several key findings from our evaluation:\nSemantix reports the lowest token usage. Meaning Typed Prompting (MTP) enables more concise and semantically rich prompts, leading to lower token usage compared to frameworks relying on JSON schemas or complex templates. This advantage is evident in tasks requiring larger outputs, such as NER, where Semantix reported the lowest token usage while achieving top performance.\nReliability improves with retries. Most frameworks increased their reliability in generating correctly formatted outputs when the number of retries rose from 0 to 2. Semantix achieved perfect or near-perfect reliability across all tasks, even without retries, suggesting that MTP provides clearer instructions to the language model, reducing invalid outputs.\nGenerating synthetic data with a wide variety. Fructose reported the highest variety in the synthetic data generation task and the best GMS for retries = 0, making it the leading framework for generating new data. Nevertheless, Semantix offered comparable results with high consistency.\nVision Support. Utilizing type annotations, Semantix can accommodate various input data types such as text, images, and videos. This capability allows applications to preprocess inputs into formats suitable for the LLM. For instance, OpenAI's vision LLMs require images to be converted into base64 strings, while videos should be transformed into sequences of base64-encoded images. For qualitative results, refer to Appendix B.2.\nSemantix excels in reasoning tasks. We evaluated the frameworks on the GSM8K and MMMU benchmarks to assess the impact of the language model's reasoning abilities (Table 3). GSM8K comprises mathematical problems in natural language, with outputs as integers or sets of integers. MMMU is a visual question-answering benchmark evaluated in the Accounting section. We compared OpenAI Structured Outputs, Fructose, and Semantix;"}, {"title": "Conclusion", "content": "We introduced Meaning Typed Prompting (MTP), the core of Semantix\u2014a framework that enhances structured output generation by embedding semantic types directly into prompts. Semantix offers a flexible alternative to JSON schema methods, surpassing them in token efficiency, reasoning capabilities, and output reliability. Notably, even without constrained decoding or models specifically trained for MTP, our approach performs exceptionally well, demonstrating that MTP's object representation is a viable alternative to JSON outputs. Our evaluations show that Semantix outperforms existing frameworks in tasks like multi-label classification, named entity recognition, and synthetic data generation while maintaining lower token usage and high consistency. With the implementation of constrained decoding for MTP and fine-tuning LLMs specifically for MTP, we anticipate outperforming JSON-based methods in every category. Future work will expand MTP to diverse LLM architectures, refine constrained decoding for better performance, and explore lightweight deployments for scalability and practical applications."}, {"title": "Limitations", "content": "Semantix has several limitations to consider. First, it requires explicit type hints even for simple tasks, increasing the initial setup effort. However, this overhead diminishes in the projects where well-structured outputs are essential.\nSecond, it is still susceptible to hallucinations like all other frameworks. Since Semantix relies on standard prompting techniques without constrained decoding, LLMs may occasionally produce hallucinated outputs. While MTP shows potential for improved structured generation, addressing this issue remains a goal for future research.\nThird, our testing has been limited to GPT-4o-mini. While we are confident that it works with other closed-source models like GPT-4, GPT-4o, Claude, and Gemini 1.5 Pro, we have not yet tested it with open-source models. Future work will explore MTP's performance with open-source LLMs such as LLaMA, Mistral, and Gemma.\nLastly, there is limited runtime type checking. As Python lacks native runtime type enforcement, Semantix currently offers limited type handling beyond developer-defined constructs. While Pydantic provides runtime validation, our framework aims to support greater flexibility. We are exploring the use of pytypes to enhance type checking and ensure more reliable outputs."}, {"title": "Ethics Statement", "content": "We obtained the necessary permissions to use the dataset provided by (Watson et al., 2024; Bastianelli et al., 2020; FitzGerald et al., 2022). We have utilized AI assistants, specifically Grammarly and ChatGPT, to correct grammatical errors and rephrase sentences."}, {"title": "Case Study: CV Analyzer", "content": "In this case study, we explore how Semantix, in collaboration with MTP, addresses the challenge of interpreting Curriculum Vitae (CV) documents to generate robust, structured profiles characterized by nested data types. The objective is to leverage large language models (LLMs) to automate the extraction of relevant information from CVs and facilitate a straightforward job-matching process by comparing the structured profiles with job descriptions."}, {"title": "Case Study: Food Analyzer", "content": "The Food Analyzer case study focuses on utilizing a multimodal LLM to interpret a given food image through Chain-of-Thought reasoning and subsequently provide nutritional information and ingredient lists in a structured format.\nThe system employs Semantix's LLM capabilities to analyze images, specifically targeting the identification of food items and their nutritional components. By incorporating the Chain-of-Thought methodology, the LLM is guided to think step-by-step, enhancing its ability to reason about the contents of the image and produce more accurate and detailed outputs."}]}