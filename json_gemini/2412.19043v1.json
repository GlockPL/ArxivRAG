{"title": "INDONESIAN-ENGLISH CODE-SWITCHING SPEECH SYNTHESIZER\nUTILIZING MULTILINGUAL STEN-TTS AND BERT LID", "authors": ["Ahmad Alfani Handoyo", "Chung Tran", "Dessi Puji Lestari", "Sakriani Sakti"], "abstract": "Multilingual text-to-speech systems convert text into speech\nacross multiple languages. In many cases, text sentences may\ncontain segments in different languages, a phenomenon\nknown as code-switching. This is particularly common in\nIndonesia, especially between Indonesian and English.\nDespite its significance, no research has yet developed a\nmultilingual TTS system capable of handling code-switching\nbetween these two languages. This study addresses\nIndonesian-English code-switching in STEN-TTS. Key\nmodifications include adding a language identification\ncomponent to the text-to-phoneme conversion using fine-\ntuned BERT for per-word language identification, as well as\nremoving language embedding from the base model.\nExperimental results demonstrate that the code-switching\nmodel achieves superior naturalness and improved speech\nintelligibility compared to the Indonesian and English\nbaseline STEN-TTS models.", "sections": [{"title": "1. INTRODUCTION", "content": "Global connectivity has drastically reduced the time required\nfor message delivery between parties. This heightened\nconnectivity fosters mutual cultural influence among\nsocieties, particularly impacting languages. A significant\ncultural aspect influenced by this connectivity is code-\nswitching the alternation between two or more languages\nwithin a single discourse.\nText-to-Speech (TTS) systems such as FastSpeech 2 [1]\nand Tacotron 2 [2] traditionally operate within a single\nlanguage. However, the need for multilingual TTS systems\nthat can handle Indonesian-English code-switching is\nincreasing, driven by sociolinguistic factors like cultural\nassimilation and the frequent use of English expressions in\nIndonesian. As a result, code-switching has become prevalent\nin everyday Indonesian conversations. TTS systems that\nsupport code-switching are particularly useful in applications\nlike navigation systems and automated audiobook reading,\nespecially for content that blends both languages.\nDespite advancements, existing research lacks a dedicated\neffort in developing a multilingual TTS system capable of\nIndonesian-English code-switching. Prior studies have\nexplored multilingual TTS for other language pairs. A study\n[3] proposed an end-to-end TTS with cross-lingual language\nmodels for Mandarin-English, achieving improved\nnaturalness in code-switching speech through shared\ncontextual embeddings across languages. Another study [4]\nintroduced a speech chain framework for semi-supervised\nlearning in Japanese-English TTS, enabling automatic speech\nrecognition (ASR) and TTS to learn from each other with\nminimal parallel data. Later, the same authors extended this\nframework to handle multiple language pairs, including zero-\nshot learning for unseen languages [5].\nA major challenge in developing an Indonesian-English\ncode-switching TTS system is the lack of a suitable dataset.\nCreating such a dataset would require recordings from\nmultilingual speakers fluent in both Indonesian and English.\nAn alternative which is to use mixed datasets from different\nlanguages with different speakers would result in inconsistent\nspeech output, with each language sounding as though it is\nspoken by a different person. To address this, a cross-lingual\nTTS model that can maintain speaker consistency is needed\nto leverage existing multilingual datasets and apply them to\nIndonesian-English code-switching.\nSTEN-TTS [6] is a non-autoregressive multilingual TTS\nmodel based on FastSpeech 2. It has demonstrated effective\ncross-language adaptation across five languages-English,\nMandarin, Japanese, Indonesian, and Vietnamese-and is\nable to utilize short reference speaker audio. While it does not\nyet support code-switching, its promising cross-language\nperformance and speaker adaptation capabilities make it a\npromising foundation for building an Indonesian-English\ncode-switching TTS system.\nIn this work, we build upon STEN-TTS and integrate a\nlanguage identification (LID) component using BERT to\ndevelop a system capable of synthesizing Indonesian-English\ncode-switching speech. We evaluate the system's\nperformance by analyzing the output speech's intelligibility\nand naturalness."}, {"title": "2. RELATED WORKS", "content": "The development of Indonesian TTS systems has evolved\nsignificantly over the years. The initial Indonesian TTS was\ndeveloped by utilizing a diphone concatenation approach\nwith a single speaker, monolingual model [7]. This was\nfollowed by the introduction of Hidden Markov Model\n(HMM)-based which also employed a single speaker and was\nlimited to monolingual capabilities [8]. Recent advancements\ninclude neural network-based TTS models such as those\nusing Tacotron 2 for expressive synthesis [9], and generative\nadversarial network-based systems for improved audio\nquality [10]. STEN-TTS introduced a multilingual adaptive\nTTS model, though its application remains predominantly\nmonolingual despite its potential for multilingual adaptation\n[6]. As observed, most existing Indonesian TTS systems are\nmonolingual and do not address Indonesian-English code-\nswitching.\nOn the other hand, code-switching in Indonesian-English\ncontexts has been explored, but primarily in ASR systems.\nFor instance, a study proposed rule-based models to improve\nrecognition accuracy [11], while another study used machine\nspeech chain to enhance ASR performance [12]. However,\nIndonesian-English code-switching in TTS systems remains\nlargely unexplored.\nTo the best of our knowledge, this study is the first to\npropose a multi-speaker multilingual TTS system specifically\ndesigned to handle Indonesian-English code-switching. This\nnovel approach leverages STEN-TTS to integrate\nmultilingual and adaptive capabilities."}, {"title": "3. METHOD", "content": "To allow for code-switching between Indonesian and\nEnglish, a model based on STEN-TTS is proposed as shown\nin Figure 1.\n3.1. Monolingual Components in STEN-TTS\nWhile inherently multilingual, STEN-TTS has an internal\nstructure which includes components tailored to specific\ntarget languages, limiting output to one language at a time."}, {"title": "3.2. LID Approach for Phonemizer Invocation", "content": "STEN-TTS employs Phonemizer [13] to transform text from\ngrapheme to phoneme form, essential for TTS input in\nphoneme embedding format. However, STEN-TTS's current\nconfiguration restricts Phonemizer calls to predefined\nlanguages among English, Mandarin, Japanese, Indonesian,\nand Vietnamese.\nChallenges arise when the model encounters code-\nswitching, such as between Indonesian and English. In such\nscenarios, words in code-switched sentences are converted to\nphoneme sequence according to the model's configured\nlanguage, disregarding the actual language of each word. For\ninstance, if the model is set to Indonesian, English words are\nconverted to phonemes based on Indonesian phoneme rules,\nresulting in incorrect pronunciation and stress.\nTo address this, modifications to Phonemizer invocation\nare necessary to convert each word to phonemes according to\nits actual language. A solution involves integrating a\nLanguage Identification (LID) component capable of\nclassifying the language of each word before passing it to the\nPhonemizer for phoneme sequence generation.\nHowever, existing LID models like FastText, trained on a\ndiverse set of 176 languages [14], may misclassify words as\nlanguages other than Indonesian or English. Therefore, a\nmore tailored LID approach is needed- -one that accounts for\nthe distinct linguistic characteristics of both Indonesian and\nEnglish to enhance classification accuracy. Recent studies in\nmultilingual LID development have found that using fine-\ntuned BERT demonstrate superior performance compared to\ntraditional LID methods [15].\nIn this study, the LID is developed using fine-tuning with\nmBERT, trained on 104 languages including Indonesian and\nEnglish [16]. This choice leverages mBERT's ability to\nrepresent tokens from both languages effectively. By fine-\ntuning mBERT, token representations are fed into a two-class\nfully connected layer, distinguishing tokens as either\nIndonesian or English. This approach ensures robust\nlanguage classification, critical for accurate phonetization in\ncode-switched contexts."}, {"title": "4. EXPERIMENTS", "content": "4.1. Dataset\nIn this study, we utilized several corpora: Wiki-40B [17], ID-\nEN Code-Mixed [18], Common Voice [19], and CoVoST 2\n[20]. The Indonesian portion of Wiki-40B is referred to as the\nLID-ID dataset, while the English portion is designated as the\nLID-EN dataset. The ID-EN Code Mixed corpus is labeled as\nthe LID-CS dataset. Transcriptions from Common Voice\nversion 4 in Indonesian were utilized as the Test-ID dataset,\nwhereas CoVoST 2, which translates Indonesian into\nEnglish, was designated as the Test-EN dataset. Common\nVoice version 4 was selected due to its direct alignment with\nthe transcribed segments used in CoVoST 2.\nThe LID-ID, LID-EN, and LID-CS datasets were utilized\nfor fine-tuning the mBERT based LID. The Test-ID and Test-\nEN datasets served as the foundation for constructing the\ncode-switching evaluation dataset named TestSet, which was\nused to evaluate both LID and the overall code-switching\nmodel. Test-ID and Test-EN consisted solely of transcription\ntexts without audio segments, as the base STEN-TTS model\ncannot be trained on new audio data. Therefore, these datasets\nwere employed solely for testing LID and code-switching\nmodel performance.\nThe development of the code-switching evaluation\ndataset, TestSet, was crucial for assessing the LID and code-\nswitching model performance in this study. TestSet was\nconstructed from Test-ID and Test-EN datasets, involving the\nconstruction of seven distinct cases. Each case represented\ndifferent scenarios of text code-switching between English\nand Indonesian:\n1. EN: Entirely in English.\n2. ID: Entirely in Indonesian.\n3. ID CS 1 word EN: Code-switched text with mostly\nIndonesian and one English word.\n4. ID CS 2 word EN: Code-switched text with mostly\nIndonesian and two English words.\n5. EN CS 1 word ID: Code-switched text with mostly\nEnglish and one Indonesian word.\n6. EN CS 2 word ID: Code-switched text with mostly\nEnglish and two Indonesian words.\n7. Half-Half: Mixed code-switched text with equal\nparts Indonesian and English.\nThe construction of the TestSet dataset was carried out in\ntwo stages. The first stage involved labelling the language of\neach word in the Test-ID and Test-EN datasets. The second\nstage focused on creating the complete dataset for all seven\ncases, which included assigning language labels to every\nword in the text."}, {"title": "4.2. Implementation", "content": "The experiments in this research were conducted on a\nmachine with CUDA acceleration, running Ubuntu 20.04.6\nLTS with an NVIDIA Tesla V100 SXM2 GPU (32GB\nHBM2). A Miniconda virtual environment was set up with\nvarious Python tools and libraries to support the experiments.\nPyTorch version 1.12.1 was selected due to its compatibility\nwith CUDA version 11.4 that was available on the machine.\nThe LID was developed by fine-tuning the mBERT\nMultilingual Cased model [16]. However, the imbalance in\nrow counts among the LID-ID, LID-EN, and especially the\nLID-CS datasets posed a risk of overfitting to the larger\ndatasets. To address this, undersampling was applied to all\nthree datasets, ensuring proportional row counts in line with\nthe smallest dataset, LID-CS. The LID model was developed\nusing a data row proportion of 5:5:1 for LID-ID:LID-\nEN:LID-CS, with fine-tuning conducted over 10 epochs.\nThe texts in the datasets were tokenized into\nrepresentations understandable by the mBERT model input.\nTo allow the model to identify the language of each token,\nevery token was labeled as either Indonesian or English.\nSubsequently, mBERT was fine-tuned using these tokens\nalong with their language labels. A two-dimensional fully\nconnected layer was added to mBERT to classify the\nlanguage of each token in the input text. This fully connected\nlayer was trained from scratch during the fine-tuning process.\nNext, the CS-TTS code-switching model was developed,\nintegrating the modified STEN-TTS without the language\nembedding component and the selected LID system from the\nprevious stage. The development involved modifying STEN-\nTTS by removing the language embedding component and\nthen integrating this modification with the previously fine-\ntuned LID system."}, {"title": "4.3. Evaluation", "content": "This phase aimed to evaluate the developed code-switching\ntext-to-speech model. The models used in the evaluation\nwere:\n1. STEN-TTS EN: Baseline STEN-TTS model for\nEnglish.\n2. STEN-TTS ID: Baseline STEN-TTS model for\nIndonesian.\n3. CS-TTS: Developed code-switching TTS model.\n4. CS-TTS Topline: Developed code-switching TTS\nmodel assuming correct language labels from LID\nto assess the impact of LID.\nThe evaluation focused on two key aspects: speech\nnaturalness and intelligibility. Both are subjective measures\nthat required participants to listen to outputs from the code-\nswitching models. The evaluation was structured using\nsurvey questionnaires divided into two sections-one\nassessing naturalness and the other intelligibility. In total,\nthere were 7 survey questionnaires, each completed by 5\nrespondents, totaling 35 respondents.\nSpeech naturalness was quantitatively measured using\nMean Opinion Score (MOS). Respondents listened to audio\nsegments and rated the naturalness of speech from the four\ntested models on a scale from 1 to 5. A score of 1 indicated\nhighly unnatural speech, while a score of 5 indicated speech\napproaching human-like quality. These scores are averaged\nfor each model across each code-switching case. Speech\nnaturalness was also qualitatively assessed through ranking\nmodels by respondents. To ensure evaluation objectivity,\nrespondents were not informed of the types of models being\ntested, and the order of models was randomized.\nTo measure speech naturalness, the TestSet dataset was\nused. Seven text samples were selected from TestSet for the\n7 code-switching cases pronounced by the four models,\nresulting in a total of 49 texts tested. Each speech naturalness\nsection in the survey questionnaire contained 7 questions,\neach for each code-switching case. For each question,\nrespondents rated the speech naturalness of outputs from the\nfour models and ranked them for one code-switching case.\nWith 7 questions and four models, each respondent listened\nto a total of 28 audio segments. With 7 questionnaires, a total\nof 196 audio segments were evaluated. The allocation of\ncode-switching cases to survey questions was structured so\nthat each of the 196 audio segments was listened to by exactly\n5 respondents in one survey questionnaire.\nSpeech intelligibility was assessed using the Sentence\nUnderstanding Score (SUS) method. Respondents listened to\nsentences designed to be syntactically sensible but\nsemantically nonsensical. They were then asked to transcribe\nwhat they heard. The transcribed text was compared against\nthe intended text to calculate the Word Error Rate (WER), to\nevaluate the intelligibility of speech produced by the models.\nTo measure speech intelligibility, a set of 14 SUS\nsentences containing Indonesian-English code-switching was\ncreated. Each speech intelligibility section in the survey\nquestionnaire contained 8 randomized questions, with each of\nthe four models tested by 2 questions. For each question,\nrespondents were asked to transcribe SUS sentence outputs\nof Indonesian-English code-switching produced by one of the\nfour models. With 14 SUS sentences spoken by 4 models, a\ntotal of 56 audio segments were evaluated. The allocation of\n14 sentences for 4 models to survey questions was structured\nso that each of the 56 audio segments was listened to by\nexactly 5 respondents in one survey questionnaire.\nThe questionnaires were distributed to 35 students and\nalumni from the Computer Science and Information Systems\nand Technology Information Study Programs at the Bandung\nInstitute of Technology (ITB). All respondents were native\nIndonesian speakers who regularly use English in both\nprofessional and academic settings."}, {"title": "5. RESULTS AND DISCUSSION", "content": "5.1. Speech Naturalness\nThe Mean Opinion Score (MOS) results in Table 1 reveal\nvarying performance among TTS models depending on the\nlanguage and code-switching scenarios. In monolingual\nEnglish cases (EN), the baseline STEN-TTS EN model\nsurpasses both the CS-TTS Topline and CS-TTS code-\nswitching models by around 0.4 MOS points. In contrast, for\nmonolingual Indonesian cases (ID), the MOS score of the\nbaseline STEN-TTS ID model is comparable to CS-TTS\nTopline and CS-TTS, with the STEN-TTS ID model scoring\nbetween the two and outperforming CS-TTS. This suggests\nthat in monolingual cases, the developed CS-TTS Topline\nand CS-TTS models perform comparably to their respective\nbaseline models for each language.\nIn unbalanced code-switching cases-ID CS 1 word EN,\nID CS 2 word EN, EN CS 1 word ID, and EN CS 2 word\nID-there is an improvement in MOS scores for the CS-TTS\nTopline model followed by CS-TTS, compared to both\nbaseline models. Specifically, in the ID CS 1 word EN case,\nthe CS-TTS model achieves an MOS score of 3.714, which\nis higher than CS-TTS Topline at 3.6. However, this 0.114\ndifference is relatively small and negligible.\nIn balanced code-switching cases like Half-Half, both CS-\nTTS and CS-TTS Topline models also show increased MOS\nscores over baseline models, indicating that these models\nhandle language transitions better than baseline models.\nOverall, CS-TTS and CS-TTS Topline models demonstrate\nmore consistent and superior performance across various\nlanguage scenarios compared to baseline models.\nReferring to the model ranking results in Figure 2, it can\nbe observed that CS-TTS Topline is frequently selected as the\ntop-ranked model in terms of speech naturalness, followed by\nCS-TTS in second place, with baseline models ranked lower.\nThis qualitative ranking suggests that the developed code-\nswitching models excel compared to baseline models.\n5.2. Speech Intelligibility\nThe Word Error Rate (WER) results for SUS sentence\ntranscriptions, presented in Table 2, show that the CS-TTS\nTopline model achieves the best performance with a WER of\n12.87%. It is followed by CS-TTS with a WER of 17.43%,\nSTEN-TTS EN at 42.18%, and STEN-TTS ID at 36.44%.\nThe superior WER of the CS-TTS Topline model compared\nto CS-TTS can be attributed to the impact of the LID\ncomponent in CS-TTS, which may misclassify language\nlabels. The improved performance of both the CS-TTS and\nCS-TTS Topline models over the STEN-TTS EN and STEN-\nTTS ID baseline models indicates that the code-switching\napproach significantly reduces sentence pronunciation errors."}, {"title": "6. CONCLUSION", "content": "The handling of Indonesian-English code-switching in\nSTEN-TTS involved removing the language embedding\ncomponent and adding an LID component, which identifies\nthe language of the input text on a per-word basis using fine-\ntuning of BERT. This approach effectively improved speech\nnaturalness, as evidenced by the increase in MOS score of the\ncode-switching model compared to the English and\nIndonesian baseline STEN-TTS models. Additionally, the\ncode-switching model demonstrated better speech\nintelligibility, reflected by a decrease in WER on SUS\nsentences relative to the baseline models."}, {"title": "7. ACKNOWLEDGMENT", "content": "Part of this work is supported by JSPS KAKENHI Grant\nNumbers JP21H05054 and JP23K21681, as well as JST\nSakura Science Program."}]}