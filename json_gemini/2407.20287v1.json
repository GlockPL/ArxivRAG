{"title": "Variational Inference Using Material Point Method", "authors": ["Yongchao Huang"], "abstract": "A new gradient-based particle sampling method, MPM-ParVI, based on material point method (MPM), is proposed for variational inference. MPM-ParVI simulates the deformation of a deformable body (e.g. a solid or fluid) under external effects driven by the target density; transient or steady configuration of the deformable body approximates the target density. The continuum material is modelled as an interacting particle system (IPS) using MPM, each particle carries full physical properties, interacts and evolves following conservation dynamics. This easy-to-implement ParVI method offers deterministic sampling and inference for a class of probabilistic models such as those encountered in Bayesian inference (e.g. intractable densities) and generative modelling (e.g. score-based).\nKeywords- Material point method; interacting particle system; sampling; variational inference.", "sections": [{"title": "Introduction", "content": "Solid and fluid material simulations can be carried out using mesh-based or mesh-free approaches. Mesh-based methods, e.g. finite element method (FEM [8]), finite difference method (FDM [9]), and finite volume method (FVM [76]), involve discretizing the space into a finite number of non-overlapping elements (i.e. a rigid mesh), which are popular but may not be applicable to large deformations as elements are distorted and accuracy lost [13]. The mesh granularity trades off efficiency and accuracy, as discretized differential equations (e.g. the Navier-Stokes equations) are evaluated at grids. Computation suffers from curse of dimentionality as the number of particles increases exponentially in response to dimension increase. Meshless or mesh-free methods [47], e.g. smoothed particle hydrodynamics (SPH [19, 50]) and material point method (MPM [68, 70]), avoid these issues by discretizing the space into a set of particles , and each particle interacts with its neighboring particles in a flexible manner [13]. MPM represents one of the latest developments in particle-in-cell (PIC [20, 7, 90]) methods developed in the early 1950s for simulating solids [71, 41, 39, 42, 28, 38], fluids [7, 83, 84, 18, 43, 36], and gases [52, 74] and many other continuum materials. Recent years have witnessed vast developments and applications of MPM and its variants in physics [49, 34], engineering [84, 56, 30, 5, 11, 48, 17] and computer graphics [90, 66, 34, 33, 31] for simulating physical behaviours of deformable materials such as elastic, plastic, elasto-plastic and viscoelastic materials, snow, lava and sand, etc.\nRepresenting a continuum as a set of discrete particles and evolving (i.e. deforming or flowing) them according to exact or approximate physics 2 motivates the design of new particle-based variational inference (ParVI) algorithms. Among these are the recently proposed physics-based ParVI algorithms which formulate an inference problem as a deterministic physical simulation process, following principles of electrostatics (e.g. EParVI [25]) or fluid mechanics (e.g. SPH-ParVI [26]). Spotting the expressive power of MPM in representing and calculating an interacting particle system (IPS), we can, with a similar spirit of SPH-ParVI, modify MPM for use of inferring probability densities. This can be achieved by incorporating the target density as a virtual, external force field applied to the particles in MPM simulation. MPM evolves the particles towards a transient or steady state which resembles the target geometry following embedded physics. Simulation correctness 3 and tractability are ensured by the well-established MPM mechanism, although assumptions and approximations may be set to trade off accuracy and efficiency.\nStatistical inference is relevant to many machine learning tasks. In diffusion and generative modelling, for example, estimating the gradients of the log density is a prerequisite. Density 4 estimation plays a central role in modern probabilistic approaches. Bayesian inference, for example, yields uncertainty quantification which is beneficial for many decision-making scenarios (e.g. probabilistic state estimation in reinforcement learning). In general, densities can be obtained either from an exact, analytic probabilistic model (e.g. a Bayesian posterior), or, in the presence of analytical intractability (e.g. high dimensional integration), via approximate, numerical schemes such as Markov chain Monte Carlo (MCMC) sampling or variational inference. The later have been successful and versatile though, still, efficient and accurate inference methods are in demand, particularly for inferring complex (e.g. multi-modal), high-dimensional geometries."}, {"title": "Related work", "content": "As this work concerns about MPM and inference methods, we introduce some related work on both aspects. For clarity, readers can refer to a full list of the abbreviations of terminologies used in this context in Appendix.1.\nMeshless particle simulation methods Meshless particle methods divide a material into a set of discrete particles. They are well suited for simulations of granular materials with complex geometries because body-fitted meshes are not needed [13]. Some of the meshless methods include SPH [19, 50], the generalized finite difference method [44], the discrete element method (DEM [10], the diffuse element method"}, {"title": "MPM-based sampling: methodology", "content": "The basic problem setting is, we have a deformable body, e.g. a solid or fluid, characterized by its initial position X, current position x, displacement u(x, t), velocity v(X, t), acceleration a(x, t), as well as other physical quantities derived from these. Under the action of an external force fext (X) field 12, we would like to know the configuration of the body, i.e. distribution of particles in the language of MPM, at a transient or terminal time t. This transient or steady state of the deformable body can be numerically predicted following deterministic physics such as continuum mechanics"}, {"title": "Discussions", "content": "As the MPM-ParVI method is built on classic MPM, here we discuss some topics related to both.\nLagrangian and Eulerian descriptions of motion Both Eulerian (spatial) and Lagrangian (material) descriptions are used in solid and fluid mechanics to describe material deformation or flow. Lagrangian description assumes observer flows with the observation element (e.g. the particle). The grid, if any, is attached to the element and therefore deforms (can be distorted) during the simulation process. This facilitates tracking of element deformation history. As computation is mainly performed on particles, Lagrangian methods (e.g. SPH) are very efficient. Eulerian description, on the other hand, issues a fixed grid in space and material flows through the grid. It avoids grid distortion but induces expensive computation. Lagrangian description focuses on individual particles, it uses the initial configuration (i.e. t=0) to describe the physical quantities and the deformation state of a continuum body. The Eulerian description focuses on a specific position in space at current time t, it describes the motion of a continuum body with respect to the current coordinates and time [37]. MPM takes a hybrid Lagrangian and Eulerian view: dynamics are solved on the computational Eulerian grid while particles act as quadrature points [33]. For a comprehensive read about the Lagrangian and Eulerian descriptions of fluids, see e.g. [72].\nTime step size MPM allows for larger time step size \u0394t than other particle-based simulation methods such as SPH, as the \u0394t in MPM relies on the cell size (i.e. the grid spacing) rather than the particle space (as in SPH) [13]. Both Algo.1 and Algo.2 use explicit time integration which is easy to implement but requires smaller \u0394t. Implicit time integration [66] requires solving a linear system but allows for larger \u0394t [34].\nMulti-modal inference Inference of multi-modal densities require particles to separate and form local groups, which is similar to fracture or cracks modelling using MPM: there are multiple internal surfaces across which the displacement field is discontinuous, and multiple velocity fields at nodes whose supports are cut by the cracks. MPM is efficient for modelling problems with moving discontinuities such as fracture evolution [58], and well suited for large motion and shape change problems."}, {"title": "Conclusion and future work", "content": "Conclusion We propose the MPM-ParVI algorithm for sampling and variational inference. It formulates sampling fully as a physical simulation process. By incorporating the gradient field of a target density into the MPM method, it drives a chosen material, represented as a system of interacting particles, to deform towards a geometry which approximates the target distribution. Particle motions are governed by principled, deterministic physics, concentration and diversity of particles are naturally maintained by the MPM formulation. This easy-to-implement ParVI method offers deterministic sampling and inference for a class of probabilistic models such as those encountered in Bayesian inference (e.g. intractable densities) and generative modelling (e.g. score-based). As a hybrid Lagrangian-Eulerian method, it suffers from curse of dimensionality.\nFuture work There are active innovations to enhance the capability (e.g. efficiency, stability, etc) and applicability [21, 80] of MPM. The bottleneck for scaling MPM-ParVI to high dimensions lies in the exponential growth of computational efforts w.r.t the dimension d, therefore improving the scalability of MPM-ParVI may deserve some future attention. Also, formal analysis of the physics-guided particle evolution from an optimisation perspective may be a future direction, as well as theoretically proving the existence and potentially uniqueness of the optimal solution. Undergoing work includes experimental validation of the MPM-ParVI method, particularly its efficacy in inferring complex densities."}, {"title": "MPM formulation", "content": "MPM is a hybrid Eulerian-Lagrangian method for modelling material deformation, with particles (arguably) being the primary material representation [34]. Two coordinate systems, i.e. the Lagrangian or material coordinate X and the Eulerian or spatial coordinate x, are employed in MPM to coherently describe particle motions and material deformation 13. More details about Lagrangian and Eulerian methods can be found in Section.4. In MPM, each Lagrangian particle"}, {"title": "The interpolation function", "content": "Unlike in SPH and electrostatics which model the IPS via direct interactions, MPM models indirect interactions between particles via use of a background grid. One can imagine the Eulerian grid as a medium to propagate interactions; in fact, the interpolation function, as described here, plays a similar role as the kernel function used in SPH - they account for the influences of, and weight the contributions from, neighbourhood particles."}, {"title": "Representing the target score as external body force", "content": "We now know how to calculate and transfer the quantities needed for solving the momentum equation (cc.Eq.17, 18). The next step is to introduce external effects, i.e. information about the target density p(x), to the dynamics, as our final goal is to move the particles to form the target geometry. In MPM, external forces can be conveniently applied on grid nodes and/or particles. For example, the gravitational force \\(f_{ext} = m_pg\\), with particle mass \\(m_p\\) and the gravitational acceleration \\(g\\), is normally applied in MPM simulations. To infer a target density \\(p(x)\\) with \\(x \\in \\mathbb{R}^d\\), we can represent the gradient field of log \\(p(x)\\), also termed score [16, 24] in statistics, as a time-invariant, external force field 21, i.e. \\(f_{ext}(x) = \\nabla_x \\log p(x)\\), and use MPM to evolve the IPS under internal"}, {"title": "ParVI methods", "content": "Particle-based variational inference (ParVI) methods provide some of the most flexible and expressive density inference methods. They don't presume any parametric form for the variational distribution, instead, they issue a set of particles and evolve them towards the target configuration following dynamics driven by the target. Stein variational gradient descent (SVGD [45]), for example, evolves a set of particles from an initial configuration (the prior distribution) till a converged state, following the gradient field of the log target density 11. ParVI methods are capable of capturing complex geometries such as those with high curvature, heavy-tail and multi-modal characteristics. Most, if not all, of them can scale to large datasets and high dimensions - they in general don't suffer much from curse of dimensionality.\nConventional ParVI methods, e.g. SVGD [45], sequential Monte Carlo (SMC [14]), particle-based energetic variational inference (EVI [78]), etc, explicitly or implicitly optimize certain discrepancy measure (e.g. KL divergence or ELBO [54]) based on statistical principles (e.g. the Stein's identity). Purely physical simulation based ParVI approaches are recently proposed. Huang [25] designed the EParVI algorithm which applies electrostatics principles to evolve a system of charges under a target electric field. This method is tested effective on low dimensional inference problems including Bayesian logistic regression and dynamic system identification. Huang [26] proposed the SPH-ParVI method which uses the SPH method to simulate particle movements, under external pressure or force field aligned with the target. These recently invented physics-based ParVI methods formulate the sampling problem as a physical simulation process which generates (quasi) samples at transient or terminal time. The simulation process is governed by physical laws such as conservation of mass, momentum and energy. Mass conservation is, in general, automatically satisfied in these particle-based simulations, as each particle carries constant amount of mass over time. Particle movement is described by, depending on the physics adapted, e.g. the Poisson's equation [25], Navier-Stokes equations [26], and so on.\nMPM, as a particle simulation methodology, has not been applied in any probabilistic machine learning setting. We therefore extend MPM to arbitrary dimensions and devise the MPM-ParVI method for variational inference. This work is by no means an innovation of the MPM method, but rather an application to the area of statistical inference. In the following, we describe the fundamental principles of MPM and demonstrate how it can be applied to statistical sampling and inference; experiments to validate the proposed methodology will be presented in future work."}, {"title": "Evolving the IPS", "content": "We have now prepared the basic ingredients for simulating an IPS. To evolve the particles, we solve the momentum equation at grid nodes at discrete times, which means in each iteration, as the particles move, particle quantities such as particle velocity vp, particle position xp, the deformation gradient matrix Fp, as well as the APIC transfer tensors Bp and Dp (if APIC rather than PIC transfer is used), and nodal quantities such as nodal mass mi, nodal momentum mivi, velocity vi, internal nodal force fint, as well as the interpolation weights wip, are updated. Note that while nodal masses mi are dynamically changing, particle masses mp are never changed (mass preserving). Also no need to update nodal positions xi.\nWe start with M initialised particles and N grid nodes, each of them are assigned with the aforementioned properties. Assuming we are at iteration t = n, we first prepare the interpolation weights \\(w_{in}^p\\) and weight gradients \\(\\nabla w_{in}^p\\) using current grid position \\(x_i\\) and particle position \\(x_p\\) (Eq.1 and Eq.2). Both values are stored on particles for later property states transfer. Then we transfer particle states to grid nodes (particle-to-grid, P2G), i.e. calculating grid node mass \\(m_i^n\\) and momentum \\(m_i v_i^n\\) via the particle-in-cell (PIC) [34] or affine particle-in-cell (APIC) [32] routine both transfer methods map the particle mass \\(m_p\\) and momentum \\(m_p v_p^n\\) to (nearby) nodes:\nPIC: \\(m_i^n = \\sum_{p=1}^M w_{ip} m_p\\), \\(m_i v_i^n = \\sum_{p=1}^M w_{ip} m_p v_p^n\\) (cc.Eq.25)\nAPIC: \\(m_i^n = \\sum_{p=1}^M w_{ip} m_p\\), \\(m_i v_i^n = \\sum_{p=1}^M w_{ip} m_p [v_p^n + B_p (D_p)^{-1} (x_i - x_p^n)]\\) (cc.Eq.27)\nwhere \\(D_p\\) and \\(B_p\\) are tracked (only in APIC) as per:\n\\(D_p = \\sum_{i=1}^N w_{ip} (x_i - x_p^n)(x_i - x_p^n)^T\\) (cc.Eq.28), \\(B_p = \\sum_{i=1}^N w_{ip}v_i^n (x_i - x_p^n)^{-1}\\) (cc.Eq.29)\nGrid node velocities vi can be be calculated using the aggregated nodal momentum:\n\\(v_i = \\frac{m_iv_i}{m_i}\\) (6)\nand internal nodal forces calculated by aggregating all stress contributions induced by the deformation gradients at particles:\n\\(f_{int,i}^n = - \\sum_{p=1}^M V_p^{o} \\nabla w_{ip}^n \\sigma_p^{n}\\) (cc.Eq.31)\nSumming up all internal and external forces, we can follow Newton's second law (a.k.a the momentum equation) to update nodal velocities:\n\\(v_i^{n+1} = v_i^n + \\Delta t \\cdot (f_{int,i}^n + f_{ext})/m_i\\) (cc.Eq.4)\nthe updated nodal velocities are then propagated back to particles (grid-to-particle, G2P) for updating particle property states (Eq.26, Eq.29, Eq.32):"}, {"title": "Memory and complexity", "content": "In d-dimensional space, the deformation gradient matrix Fp, the 1st PK stress matrix P, the APIC tensors Bp and Dp, are all of dimension dxd. One need to store \\(d^2\\) numbers for each matrix at each particle. In addition, each vector-valued particle and nodal quantity, e.g. position, velocity, momentum and force, requires d numbers to be stored. If we use a regular Cartesian grid and assign k nodes along each dimension, in total we have \\(N = k^d\\) nodes. In each iteration n, we need O((N + M)d+ Md\u00b2) space for storing these vectors and matrices.\nThe time cost for each MPM step has been attached in each step in both algorithms, taking into account matrix inversion, transpose, matrix-matrix and matrix-vector multiplications 26. Overall, the MPM algorithm takes 27 O(Md\u00b2(d+N)), which is about O(MNd\u00b2) as normally we have d \u00ab N. It is smaller than O(MNd\u00b3) but larger than O(MNd). For low dimensions (i.e. d=1,2,3), normally we have M > N; in high-dimensions, however, M \u00ab N = kd.\nThe bottleneck therefore lies in the two multiplicative factors N = kd and d\u00b2. It is suspicious to say that, by modelling indirect particle interactions, MPM reduces the computational burden from O(M\u00b2) to O(MN).\nAdvantages of MPM-ParVI (1) Advantages of MPM. MPM provides a particle simulation framework which enjoys the advantages of both Lagrangian and Eulerian descriptions [58]: no element distortion happens and no remeshing is required during simulation. The Lagrangian formulation allows particle motion and material deformation histories to be tracked throughout the simulation process, while the Eulerian grid enables automatic treatment of self-collision and fracture [33]. Further, it is free of mesh-entanglement problems, and allows for both explicit [32] and implicit 28 [33, 88, 89] time integration schemes. More advantages of MPM are listed in e.g. [13]. (2) Physics-based and deterministic. MPM-ParVI follows deterministic physics to generate samples, the results are trackable and reproducible. Interactions between particles are modelled in a principled manner which preserves mass, momentum and energy. (3) Handling complex geometries. As MPM is efficient in modelling discontinuities, large motion and shape change problems, MPM-ParVI may be of advantage for inferring complex (e.g. multi-modal) densities. (4) Ease of implementation. MPM-ParVI has few hyper-parameters to tune (typically, the mesh spacing and time step) 29, which is convenient as compared to SPH, and it can be easily implemented for parallel and distributed computing. (5) Speed and accuracy. It is reported [53, 13] that, MPM is faster and more accurate than SPH due to larger time step size and no neighbourhood searching. However, as a new class of ParVI methods, comparison of these physics-based ParVI methods with other ParVI/VI methods has not been studied.\nLimitations of MPM-ParVI (1) Disadvantages of MPM. MPM is generally less accurate than FEM. Particles in MPM can suffer from numerical fracture, grid-crossing instability 30, the null space issue and no convergence for very fine meshes [13]. Large memory is required for computation at grid and particles. Analysis of convergence, error and stability is challenging [13]. The convergence rate is rarely of second order [13]. Boundary conditions are difficult to enforced. More disadvantages of MPM are listed in e.g. [13]. (2) Reduced flexibility as compared to SPH due to the hybrid Lagrangian-Eulerian nature of MPM. Although both SPH and MPM requires choosing a proper kernel (for different purposes), in MPM the modeller also has to choose a constitutive model (e.g. the energy density function \u03a8) for simulation, and the choice of which can have impact on the inference results. There is some flexibility though, for devising MPM-ParVI. For example, one can apply a time variant, external body force, in an annealing style, to control convergence. Also, one may formulate the information from the target density as boundary condition(s). (3) Limited scalability. MPM was developed for real-world simulations which are typically low-dimensional. Statistical inference problems, however, can range from low to high dimensions, and MPM-ParVI suffers from curse of dimensionality as a background mesh grid is needed for the simulation. The computational efforts increases as O(Md\u00b3 + MNd\u00b2) where N = kd, k being the number of grid nodes along each dimension. This intrinsic exponential growth may prevent it from being applied to high dimensions.\nPhysical statistics This work extends the author's previous work on physics-based ParVI methods [25, 26], which forms a new branch of physical statistics (against the long standing statistical physics which applies statistics to physics) and coins the term science for AI (against the trending AI for science). There have been many physically and biologically inspired AI algorithms, e.g. the genetic algorithm [23], particle swarm optimization (PSO [35, 81]) and HMC. This series of work, however, is first of this kind which formulates a statistical inference problem fully as a physical simulation process. Unlike traditional ParVI methods which use statistical and optimisation principles to perform inference, these new ParVI methods are purely based on physics 31. SPH-ParVI, for example, employs the Navier-Stokes equations, which represent mass, momentum and energy conservation, as deterministic dynamics to guide the inference procedure. EParVI, on the other hand, utilizes principles of electrostatics to model the IPS.\nApplications Similar to other gradient-based sampling methods such as Hamiltonian Monte Carlo (HMC), Langevin Monte Carlo (LMC), SVGD, and SPH-ParVI"}, {"title": "Particle-in-cell (PIC) transfer", "content": "Here we follow pp.42-43 in [34]. At any iteration (ignoring the iteration number superscript n), we transfer mass and momentum from particles to grid nodes:\n\\(m_i = \\sum_{p=1}^M w_{ip} m_p\\), \\(m_i v_i = \\sum_{p=1}^M w_{ip} m_p v_p\\) (25)\nwhere \\(w_{ip} = K(x_p - x_i)\\) are the interpolation weights. We can then calculate the grid nodal velocity vi and update it using the forces acting on the particle (Newton's second law). The updated nodal velocity is then interpolated back to the particle to obtain particle velocity:\n\\(v_p = \\sum_{i=1}^N w_{ip} v_i\\) (26)\nwhere N is the total number of grid nodes. The issue with PIC is loss of angular momentum, which leads to rotational motion damping.\nAffine particle-in-cell (APIC) transfer Here we mainly follow pp.41-42 in [33]. At any iteration, the transfer of mass and momentum from particles to grid, derived by preserving affine motion during the transfers, is:\n\\(m_i = \\sum_{p=1}^M w_{ip} m_p\\), \\(m_i v_i = \\sum_{p=1}^M w_{ip} m_p [v_p + B_p (D_p)^{-1} (x_i - x_p)]\\) (27)\nwhere \\(w_{ip}\\) is the interpolation weight for particle p and grid node i. The particle affine tensor Bp, stored at each particle, is a dxd matrix which represents an affine transformation that approximates the local, linear velocity gradients (i.e., how velocity changes in space around the particle). Dp is calculated as\n\\(D_p = \\sum_{i=1}^N w_{ip} (x_i - x_p) (x_i - x_p)^T\\) (28)\nwhich is a d\u00d7 d matrix capturing the spatial distribution of the grid nodes around the particle. For quadratic interpolation stencils, we have \\(D_p = h^2 I\\); for cubic interpolation stencils, \\(D_p = \\frac{h^2}{6} I\\), with h being the grid spacing. Therefore, \\((D_p)^{-1}\\) becomes a scaling factor in Eq.27.\nInversely, we have the transfer from grid back to particles:\n\\(v_p = \\sum_{i=1}^N w_{ip} v_i\\) (cc.Eq.26)\n\\(B_p = \\sum_{i=1}^N w_{ip}v_i (x_i - x_p)^T\\) (29)\nNote that, the motion of grid nodes are virtual we never compute a new grid, we only explicitly store the grid velocities [33]."}, {"title": "Forces", "content": "Here we mainly follow pp.43-44 in [33]. Forces are calculated on grid nodes. At iteration n, the internal force \\(f_{int,i}^n\\) acting on grid node i can be derived from the weak form of momentum equation:\n\\(f_{int,i}^n = f_{int}^n (x_i) = - \\sum_{p=1}^M V_p^{o} \\nabla w_{ip}^n \\sigma_p^{n}\\) (30)\nwhere \\(V_p^{o}, \\sigma_p^{n}\\) are the volume of and Cauchy stress acting on particle p, respectively. Forces can also be derived via total potential energy [33], i.e. aggregating all stress (Eq.21) contributions:\n\\(f_{int,i}^n = f_{int}^n (x_i) = - \\sum_{p=1}^M V_p^{o} \\nabla \\frac{d \\Psi (F)}{dF}|_{t^n} (\\nabla w_{ip}^n)^T\\) (31)\nwhere \\(V_p^{o}\\) is the volume originally occupied by the particle p, it can be related to \\(V_p^n\\) via \\(V_p^n = det(F_p) V_p^{o}\\), which makes Eq.31 equivalent to Eq.30 with reference to Eq.21. \\(\\Psi\\) is the energy density function. The summation is over all particles p that contribute to the force at grid node i. On the RHS, the product \\( \\nabla \\frac{d \\Psi (F)}{dF}|_{t^n} (\\nabla w_{ip}^n)^T\\) results in a second-order tensor (stress tensor); \\(V_p^{o} \\nabla w_{ip}^n\\) is a vector.\nUpdate of deformation gradient F Here we mainly follow pp.42-43 in [33]. At any iteration t = n, we can update the deformation gradient F for each particle as follows [33]:\n\\(F_p^{n+1} = (I + \\Delta t \\sum_{i=1}^N v_i^{n+1} (\\nabla w_{ip}^n)^T)F_p^{n}\\) (32)"}, {"title": "Interpolation kernels", "content": "Here we follow pp.33 in [33] and present 3 commonly used interpolation kernels with r = \\((x_p - x_i)/h\\). Some other interpolation functions can be found in e.g. [13].\n1. Linear kernel\n\\(K(r) = \\begin{cases} 1 - |r| & 0 \\leq |r| < 1,\\\\ 0 & 1 \\leq |r|. \\end{cases}\\) (33)\n2. Quadratic kernel\n\\(K(r) = \\begin{cases} \\frac{3}{4} - r^2 & 0 \\leq |r| < \\frac{1}{2},\\\\ \\frac{1}{2} (\\frac{3}{2} - |r|)^2 & \\frac{1}{2} \\leq |r| < \\frac{3}{2},\\\\ 0 & \\frac{3}{2} \\leq |r|. \\end{cases}\\) (34)\n3. Cubic kernel\n\\(K(r) = \\begin{cases} \\frac{1}{6} [ -|r|^3 + \\frac{3}{2} r^2 + \\frac{4}{3}] & 0 \\leq |r| < 1,\\\\ \\frac{1}{6} [2 - |r|]^3 & 1 \\leq |r| < 2,\\\\ 0 & 2 \\leq |r|. \\end{cases}\\) (35)"}, {"title": "Alternative MPM-ParVI implementation", "content": "MPM-based sampling (APIC transfer, part 1)\n\u2022 Inputs: a differentiable target density p(x) with magnitude amplification constant \u03b1, total number of particles M, particle (density) dimension d, initial proposal distribution \\(p^0(x)\\), total number of grid nodes N, total number of iterations T, step size \u0394t. An energy density function \u03a8 specifying the constitutive model, and an interpolation function K.\n\u2022 Outputs: Particles located at positions \\({x_p \\in \\mathbb{R}^d\\}_{p=1}^M\\) whose empirical distribution approximates the target density p(x).\n1. Initialise particles and grid. [O(max(M, N)d)]\nInitialise M particles from \\(p^0(x)\\), each with mass mp, volume \\(V^o\\), initial position xp, initial velocity vp, affine matrix Bp, and material-related parameters. Some default values can be set to be 0 [34]. [O(Md)]\nInitialise a grid with N nodes. Grid node locations xi, i = 1,2,..., N are on a undeformed regular grid and are time-invariant. Initialise grid data, i.e. nodal mass mi, velocity vi, to default values of 0. [O(Nd)]\n2. Update particle positions.\nFor each iteration t = 1, 2, ..., T, repeat until optimal configuration:\n(1) Compute the interpolation weights \\(w_{ip}^n\\) and weight gradients \\(\\nabla w_{ip}^n\\) for each particle p:\n\\(w_{ip}^n = K(x_i - x_p^n)\\), \\(\\nabla w_{ip}^n = \\nabla K(x_i - x_p^n)\\)\nThese location-dependent weights and weight gradients are computed once and stored on the particles in each iteration.\n(2) Transfer particle quantities to the grid (P2G.). Compute the grid mass and momentum using APIC (Eq.27): [O(Md\u00b3 + MNd\u00b2)]\n\\(m_i^n = \\sum_{p=1}^M w_{ip}^n m_p\\), \\(m_i v_i^n = \\sum_{p=1}^M w_{ip}^n [v_p^n + B_p (D_p)^{-1} (x_i - x_p^n)]\\)\nwhere \\(D_p = \\sum_{i=1}^N w_{ip}^n (x_i - x_p^n) (x_i - x_p^n)^T\\) (Eq.28).\n(3) Compute grid velocities (Eq.6): [O(Nd)]\n\\(v_i = \\frac{m_i v_i^n}{m_i}\\)\n(4) Compute explicit grid forces \\(f_{int,i}^n\\) (Eq.30 or Eq.31): [O(Md\u00b3 + MNd\u00b2)]\n\\(f_{int,i}^n = - \\sum_{p=1}^M V_p^{o} \\nabla w_{ip}^n \\sigma_p^{n}\\) or \\(f_{int,i}^n = - \\sum_{p=1}^M V_p^{o} \\nabla \\frac{d \\Psi (F)}{dF}|_{t^n} (\\nabla w_{ip}^n)^T\\)\nwhere \\(\\sigma_p^{n} = det (F_p) F^{-T} \\frac{d \\Psi (F)}{dF}|_{t^n}\\) (Eq.21)."}]}