{"title": "Variational Inference Using Material Point Method", "authors": ["Yongchao Huang"], "abstract": "A new gradient-based particle sampling method, MPM-ParVI, based on material point method (MPM), is proposed for variational inference. MPM-ParVI simulates the deformation of a deformable body (e.g. a solid or fluid) under external effects driven by the target density; transient or steady configuration of the deformable body approximates the target density. The continuum material is modelled as an interacting particle system (IPS) using MPM, each particle carries full physical properties, interacts and evolves following conservation dynamics. This easy-to-implement ParVI method offers deterministic sampling and inference for a class of probabilistic models such as those encountered in Bayesian inference (e.g. intractable densities) and generative modelling (e.g. score-based).", "sections": [{"title": "Introduction", "content": "Solid and fluid material simulations can be carried out using mesh-based or mesh-free approaches. Mesh-based methods, e.g. finite element method (FEM [8]), finite difference method (FDM [9]), and finite volume method (FVM [76]), involve discretizing the space into a finite number of non-overlapping elements (i.e. a rigid mesh), which are popular but may not be applicable to large deformations as elements are distorted and accuracy lost [13]. The mesh granularity trades off efficiency and accuracy, as discretized differential equations (e.g. the Navier-Stokes equations) are evaluated at grids. Computation suffers from curse of dimentionality as the number of particles increases exponentially in response to dimension increase. Meshless or mesh-free methods [47], e.g. smoothed particle hydrodynamics (SPH [19, 50]) and material point method (MPM [68, 70]), avoid these issues by discretizing the space into a set of particles , and each particle interacts with its neighboring particles in a flexible manner [13]. MPM represents one of the latest developments in particle-in-cell (PIC [20, 7, 90]) methods developed in the early 1950s for simulating solids [71, 41, 39, 42, 28, 38], fluids [7, 83, 84, 18, 43, 36], and gases [52, 74] and many other continuum materials. Recent years have witnessed vast developments and applications of MPM and its variants in physics [49, 34], engineering [84, 56, 30, 5, 11, 48, 17] and computer graphics [90, 66, 34, 33, 31] for simulating physical behaviours of deformable materials such as elastic, plastic, elasto-plastic and viscoelastic materials, snow, lava and sand, etc.\nRepresenting a continuum as a set of discrete particles and evolving (i.e. deforming or flowing) them according to exact or approximate physics motivates the design of new particle-based variational inference (ParVI) algorithms. Among these are the recently proposed physics-based ParVI algorithms which formulate an inference problem as a deterministic physical simulation process, following principles of electrostatics (e.g. EParVI [25]) or fluid mechanics (e.g. SPH-ParVI [26]). Spotting the expressive power of MPM in representing and calculating an interacting particle system (IPS), we can, with a similar spirit of SPH-ParVI, modify MPM for use of inferring probability densities. This can be achieved by incorporating the target density as a virtual, external force field applied to the particles in MPM simulation. MPM evolves the particles towards a transient or steady state which resembles the target geometry following embedded physics. Simulation correctness and tractability are ensured by the well-established MPM mechanism, although assumptions and approximations may be set to trade off accuracy and efficiency.\nStatistical inference is relevant to many machine learning tasks. In diffusion and generative modelling, for example, estimating the gradients of the log density is a pre-requisite. Density estimation plays a central role in modern probabilistic approaches. Bayesian inference, for example, yields uncertainty quantification which is beneficial for many decision-making scenarios (e.g. probabilistic state estimation in reinforcement learning). In general, densities can be obtained either from an exact, analytic probabilistic model (e.g. a Bayesian posterior), or, in the presence of analytical intractability (e.g. high dimensional integration), via approximate, numerical schemes such as Markov chain Monte Carlo (MCMC) sampling or variational inference. The later have been successful and versatile though, still, efficient and accurate inference methods are in demand, particularly for inferring complex (e.g. multi-modal), high-dimensional geometries."}, {"title": "Related work", "content": "As this work concerns about MPM and inference methods, we introduce some related work on both aspects. For clarity, readers can refer to a full list of the abbreviations of terminologies used in this context in Appendix.1.\nMeshless particle simulation methods Meshless particle methods divide a material into a set of discrete particles. They are well suited for simulations of granular materials with complex geometries because body-fitted meshes are not needed [13]. Some of the meshless methods include SPH [19, 50], the generalized finite difference method [44], the discrete element method (DEM [10], the diffuse element method (DEM [57]), the element free Galerkin method (EFG [3]), the material point method (MPM [68]), the reproducing kernel particle method (RKPM [46]), the natural element method [67], the meshless local Petrov Galerkin method (MLPG [1]), the particle finite element method (PFEM [29]), the optimal transport meshfree method (OTM [40]), etc. Meshfree methods in general avoids element distortion and expensive remeshing during material deformation.\nParticle-in-cell (PIC) methods were developed by Harlow [20], primarily for applications in fluid mechanics [13]. Later Brackbill and Ruppel [7, 6] introduced the fluid implicit particle (FLIP) method which improves early PIC methods. The FLIP method was further developed by Sulsky et al. [68, 71] for applications in solid mechanics which has since been termed the material point method (MPM). While PIC and MPM use both Lagrangian particles and a background Eulerian grid simultaneously, particles in PIC carry only position and mass, MPM allows particles to carry full physical state [13]. Some MPM variants include the generalized interpolation material point method (GIMP [2, 51]), B-splines MPM (BSMPM [63]), the convected particle domain interpolation (CPDI [62]), the dual domain MPM (DDMPM [85]), weighted least square MPM [77], moving least square MPM [15], improved MPMs (iMPM [69, 79, 75]), the total Lagrangian MPM (TLMPM [12]) and discontinuous Galerkin MPM (DGMPM [60, 61], isogeometric MPM (IGA-MPM [55]), local maximum-entropy MPM (LME-MPM [58]), affine matrix-based MPM (AM-MPM, [21]), etc. To model fluids and gases, weakly compressible [82] and incompressible [65] MPMs have also been developed. These variants differ in the basis functions used (e.g. $C^0$ or $C^1$ smoothness), the time integration scheme used (explicit or implicit solvers ), the type of grid used (uniform Cartesian grid or unstructured mesh ), and so on.\nSPH, developed in the 1970s and 1980s [19], is a fully meshfree method; it is applicable to a space with arbitrary dimensions. Particles in SPH directly interact with each other (through the smoothing kernel), while in MPM, particle interactions are propagated through the background Eulerian grid. Both SPH and MPM are used in continuum mechanics to model solids and fluids at macroscopic level, and variables can be calculated using smooth functions over the space [13]. It has been shown [53, 13] that MPM and SPH predictions are quite similar, but MPM is faster (as it avoids direct computation of particle interactions) and more accurate than SPH. Also, MPM simulation requires less tricky ad hoc parameters than SPH [13]; typical hyper-parameters for MPM are the mesh spacing and time step. A combined SPH-MPM method, which exhibits superior performance over SPH and MPM, has been developed [59, 22]. There are efforts [86] to develop hybrid methods which couple MPM with other particle modelling methods for improved efficiency, e.g. the explicit material point finite element method (MPFEM [87]), molecular dynamics with MPM [49], and so on."}, {"title": "ParVI methods", "content": "Particle-based variational inference (ParVI) methods provide some of the most flexible and expressive density inference methods. They don't pre-assume any parametric form for the variational distribution, instead, they issue a set of particles and evolve them towards the target configuration following dynamics driven by the target. Stein variational gradient descent (SVGD [45]), for example, evolves a set of particles from an initial configuration (the prior distribution) till a converged state, following the gradient field of the log target density. ParVI methods are capable of capturing complex geometries such as those with high curvature, heavy-tail and multi-modal characteristics. Most, if not all, of them can scale to large datasets and high dimensions - they in general don't suffer much from curse of dimensionality.\nConventional ParVI methods, e.g. SVGD [45], sequential Monte Carlo (SMC [14]), particle-based energetic variational inference (EVI [78]), etc, explicitly or implicitly optimize certain discrepancy measure (e.g. KL divergence or ELBO [54]) based on statistical principles (e.g. the Stein's identity). Purely physical simulation based ParVI approaches are recently proposed. Huang [25] designed the EParVI algorithm which applies electrostatics principles to evolve a system of charges under a target electric field. This method is tested effective on low dimensional inference problems including Bayesian logistic regression and dynamic system identification. Huang [26] proposed the SPH-ParVI method which uses the SPH method to simulate particle movements, under external pressure or force field aligned with the target. These recently invented physics-based ParVI methods formulate the sampling problem as a physical simulation process which generates (quasi) samples at transient or terminal time. The simulation process is governed by physical laws such as conservation of mass, momentum and energy. Mass conservation is, in general, automatically satisfied in these particle-based simulations, as each particle carries constant amount of mass over time. Particle movement is described by, depending on the physics adapted, e.g. the Poisson's equation [25], Navier-Stokes equations [26], and so on.\nMPM, as a particle simulation methodology, has not been applied in any probabilistic machine learning setting. We therefore extend MPM to arbitrary dimensions and devise the MPM-ParVI method for variational inference. This work is by no means an innovation of the MPM method, but rather an application to the area of statistical inference. In the following, we describe the fundamental principles of MPM and demonstrate how it can be applied to statistical sampling and inference; experiments to validate the proposed methodology will be presented in future work."}, {"title": "MPM-based sampling: methodology", "content": "The basic problem setting is, we have a deformable body, e.g. a solid or fluid, characterized by its initial position $X$, current position $x$, displacement $u(x, t)$, velocity $v(X, t)$, acceleration $a(x, t)$, as well as other physical quantities derived from these. Under the action of an external force $f_{\text{ext}}(X)$ field, we would like to know the configuration of the body, i.e. distribution of particles in the language of MPM, at a transient or terminal time $t$. This transient or steady state of the deformable body can be numerically predicted following deterministic physics such as continuum mechanics."}, {"title": "MPM formulation", "content": "MPM is a hybrid Eulerian-Lagrangian method for modelling material deformation, with particles (arguably) being the primary material representation [34]. Two coordinate systems, i.e. the Lagrangian or material coordinate $X$ and the Eulerian or spatial coordinate $x$, are employed in MPM to coherently describe particle motions and material deformation . More details about Lagrangian and Eulerian methods can be found in Section.4. In MPM, each Lagrangian particle carries physical properties such as position $x_p$, mass $m_p$, density $\\rho_p$, velocity $v_p$, deformation gradient $F_p$, Cauchy stress tensor $\\sigma_p$, and other state variables [13]. A background Eulerian grid, with certain meshing space $h$, is defined to discretize the continuous fields. The Lagrangian coordinate is used to track particle positions and states, while the Eulerian grid is used to solve the governing equations. Material points interact with the grid, transfer their states of properties to grid nodes for computation and then update their states based on grid solutions.\nThe motion of a deformable body is schematically shown in Fig.1. Initially particles are at position $X$ at time t=0, at current time t they are located at position $x$. In Lagrangian description, these two configurations are related through a mapping function:\n$x = \\phi(X, t) \\qquad (cc.Eq.7)$\nand we have $X = \\phi(X, 0)$. Common physical quantities used to describe motion, e.g. displacement $u$, velocity $v$, acceleration $a$ and the deformation gradient $F$, can be expressed as:\n$u(x, t) := \\phi(X, t) - \\phi(X, 0) = x - X, v(x, t) := \\frac{\\partial \\phi(X, t)}{\\partial t} \\qquad a(X, t) := \\frac{dv(x,t)}{\\partial t} \\qquad F(X, t) := \\frac{\\partial x(x, t)}{\\partial X} \\qquad (cc.Eq.8~11)$\nParticle movements, or body deformations, are governed by conservation and constitutive equations. Two governing equations of interest are the conservation of mass and (linear) momentum:\n$\\frac{D \\rho}{Dt} + \\rho \\nabla \\cdot v = 0 \\qquad (Continuity equation) \\qquad (cc.Eq.17, 18)$\n$\\rho \\frac{Dv}{Dt} = \\nabla \\cdot \\sigma + f_{\\text{ext}} \\qquad (Linear momentum equation) \\qquad (cc.Eq.17, 18)$\nwhere $\\rho(x, t)$ is the density, $\\sigma(X, t)$ is the symmetric Cauchy stress tensor, $f_{\\text{ext}}$ is the external body force per unit volume, e.g. the gravitational force $f_{\\text{ext}} = \\rho g$ with $g$ being the gravitational acceleration. $\\frac{D \\rho}{Dt} = \\frac{\\partial \\rho}{\\partial t} + (\\rho)v$ is the material derivative of the density. Conservation of mass is also called mass continuity, which is automatically satisfied for an IPS as particles carry constant mass. The momentum equation, which echoes the Newton's second law on a continuum body, governs the motion of particles.\nGiven the governing equations, we are now faced with two questions for deforming a material: first, how to derive the quantities, e.g. stress $\\sigma$, from an observable quantity such as particle position $X$ or associated quantities? Second, how to solve the differential equations in discrete time and space? The first question can be solved by a constitutive model which relates stress to a deformation field. The second concerns about the discretization of the differential equations. There exist explicit and implicit time integration schemes to compute these quantities on a grid of mesh points at discrete times. MPM, in particular, calculates some of these quantities on a grid and propagates them back to the particles.\nMPM relies on a proper constitutive model to relate stress and strain, or force and deformation. A constitutive relation is similar to the equation of state (EoS) used in SPH, which defines how a material responds to internal and external effects. It differentiates different types of materials, e.g. elastic, hyper-elastic, plastic, visco-elastic, elasto-plastic, etc. In particular, it distinguishes solids and fluids behaviours. The constitutive model for isotropic, linear elastic materials, for example, writes:\n$\\sigma = (\\lambda tr e)I + 2 \\mu e \\qquad (cc.Eq.19)$\nConstitutive relation can be derived from the energy density function $\\Psi$ which is normally defined as a function of the deformation gradient $F$ in continuum mechanics. Hyper-elastic materials, for example, have\n$P = \\frac{\\Psi(F)}{\\partial F} \\qquad \\sigma = \\frac{1}{det(F)} \\frac{\\partial \\Psi(F)}{\\partial F} F^T \\qquad (cc.Eq.20, 21)$\nwhere $P$ is the first Piola-Kirchoff stress (1st PK), $\\sigma$ the Cauchy stress, and $J = det(F)$ is the determinant of the matrix (second-order tensor) $F$. We observe $\\sigma = PF^T/J$.\nFor example, the energy density function of the Neo-Hookean model, a simple non-linear hyper-elastic model for describing isotropic elastic materials (particularly for large deformations), is\n$\\Psi(F) = \\frac{\\mu}{2} (tr(F^TF) - d) - \\mu log(J) + \\frac{\\lambda}{2} log^2(J) \\qquad (cc.Eq.22)$\nwhere $d$ is the dimension. The first Lam\u00e9 parameter (i.e. the shear modulus) $\\mu$ and the second Lam\u00e9 parameter $\\lambda$ can be derived from the Young's modulus and Poisson's ratio of the material (see Eq.23 in Appendix.C). Differentiating $\\Psi(F)$, we obtain the 1st PK stress, and then Cauchy stress, for Neo-Hookean materials [33]:\n$P = \\mu(F - F^{-T}) + \\lambda log(J)F^{-T}, \\qquad \\sigma = \\frac{1}{J} [(FF^T - I) + \\lambda log(J)I] \\qquad (cc.Eq.24)$\nthis internal stress (denoted as $f_{\\text{int}}$), together with external force, is plugged in the momentum conservation equation (cc.Eq.17, 18) to update particle velocities.\nThe interpolation function Unlike in SPH and electrostatics which model the IPS via direct interactions, MPM models indirect interactions between particles via use of a background grid. One can imagine the Eulerian grid as a medium to propagate interactions; in fact, the interpolation function, as described here, plays a similar role as the kernel function used in SPH - they account for the influences of, and weight the contributions from, neighbourhood particles."}, {"title": "Representing the target score as external body force", "content": "We now know how to calculate and transfer the quantities needed for solving the momentum equation (cc.Eq.17, 18). The next step is to introduce external effects, i.e. information about the target density $p(x)$, to the dynamics, as our final goal is to move the particles to form the target geometry. In MPM, external forces can be conveniently applied on grid nodes and/or particles. For example, the gravitational force $f_{\\text{ext}} = m \\rho g$, with particle mass $m \\rho$ and the gravitational acceleration $g$, is normally applied in MPM simulations. To infer a target density $p(x)$ with $x \\in R^d$, we can represent the gradient field of log $p(x)$, also termed score [16, 24] in statistics, as a time-invariant, external force field, i.e. $f_{\\text{ext}}(x) = \\nabla_x log p(x)$, and use MPM to evolve the IPS under internal and external effects . It is expected that, some transient or terminal (steady) configuration of the particles, i.e. $\\Omega$ in Fig.1, shall approximate the target geometry, i.e. particles cluster and concentrate around high density regime(s) while maintaining certain degree of dispersion (diversity), as a result of external (dominating) and internal (e.g. friction or inertia, as determined by the constitutive model) effects. Formulating the inference problem as a physical simulation process guarantees some nice properties aligned with statistical inference: at an optimal state, particles shall distribute in space proportionally to the strength of the applied external driving force, and our design ensures particles flow towards high density regime(s) following the score field. Particles can distribute around multiple modes if the material constitutive model is properly defined (e.g. allowing for fracture). Particles won't collapse into single points (i.e. point estimates) unless the solid or fluid material being simulated is extremely deformable (e.g. negative Poisson's ratio). These guarantees, i.e. multiple-modality and high density concentration with diversity, are desired for designing an inference method for use in e.g. Bayesian inference and generative modelling where both accuracy and uncertainty are desired. In extra, employing physics to model the IPS yields deterministic inference. In fact, the physics-guided evolution process is implicitly minimizing the potential of the particle system - an objective similar to the KL divergence or ELBO as used in classic VI formulations.\nFor example, if we apply the following time-invariant, external body force on all grid nodes\n$f_{\\text{ext}}(x_i) = \\alpha \\nabla_x log p(x_i), \\qquad (3)$\nwhere $\\alpha$, either positive or negative, is a magnitude amplification constant to weight the external force, in each iteration t = n, the combined external and internal forces can then be used to update grid velocities $v_i$ via e.g. an explicit Euler time integration scheme:\n$v_i^{n+1} = v_i^n + \\Delta t \\cdot \\frac{(f_{\\text{int}}^n + f_{\\text{ext}})}{m_i} \\qquad (4)$\nwhere $m_i$ is the nodal mass, $\\Delta t$ is the time step size, and $f_{\\text{int}}$ is the propagated internal force induced by deformation gradients (cc.Eq.20, 21). Using interpolation functions, the updated grid node velocities are then mapped back to particles (i.e. grid to particle, G2P) to update particle velocities $v_p$:\n$v_p^{n+1} = \\sum_{i=1}^{N} w_{ip}^{n+1} v_i^{n+1} \\qquad (cc.Eq.26)$\nIf the external body force is applied to particles rather than to grid nodes, in each iteration, we need to transfer its impact to the grid nodes (i.e. particle to grid, P2G):\n$f_{\\text{ext}}^i = \\sum_{p=1}^{M} w_{ip} f_{\\text{ext}}^p \\qquad (5)$"}, {"title": "Evolving the IPS", "content": "We have now prepared the basic ingredients for simulating an IPS. To evolve the particles, we solve the momentum equation at grid nodes at discrete times, which means in each iteration, as the particles move, particle quantities such as particle velocity $v_p$, particle position $x_p$, the deformation gradient matrix $F_p$, as well as the APIC transfer tensors $B_p$ and $D_p$ (if APIC rather than PIC transfer is used), and nodal quantities such as nodal mass $m_i$, nodal momentum $m_i v_i$, velocity $v_i$, internal nodal force $f_{\\text{int}}^i$, as well as the interpolation weights $w_{ip}$, are updated. Note that while nodal masses $m_i$ are dynamically changing, particle masses $m_p$ are never changed (mass preserving). Also no need to update nodal positions $x_i$.\nWe start with $M$ initialised particles and $N$ grid nodes, each of them are assigned with the aforementioned properties. Assuming we are at iteration $t = n$, we first prepare the interpolation weights $w_{in}^p$ and weight gradients $w_{in}^p$ using current grid position $x_i$ and particle position $x_p$ (Eq.1 and Eq.2). Both values are stored on particles for later property states transfer. Then we transfer particle states to grid nodes (particle-to-grid, P2G), i.e. calculating grid node mass $m_i^n$ and momentum $m_i v_i^n$ via the particle-in-cell (PIC) [34] or affine particle-in-cell (APIC) [32] routine both transfer methods map the particle mass $m_p$ and momentum $m_p v_p$ to (nearby) nodes:\n$PIC: m_i^n = \\sum_{p=1}^M w_{ip} m_p, \\qquad m_i v_i^n = \\sum_{p=1}^M w_{ip} m_p v_p \\qquad (cc.Eq.25)$\n$APIC: m_i^n = \\sum_{p=1}^M w_{ip} m_p, \\qquad m_i v_i^n = \\sum_{p=1}^M w_{ip} m_p [v_p + B_p (D_p)^{-1} (x_i - x_p)] \\qquad (cc.Eq.27)$\nwhere $D_p$ and $B_p$ are tracked (only in APIC) as per:\n$D_p^n = \\sum_{i=1}^N w_{ip} (x_i - x_p) (x_i - x_p)^T \\qquad (cc.Eq.28), \\qquad B_p^n = \\sum_{i=1}^N w_{ip} v_i (x_i - x_p)^T \\qquad (cc.Eq.29)$\nGrid node velocities $v_i$ can be be calculated using the aggregated nodal momentum:\n$v_i = \\frac{m_i v_i}{m_i} \\qquad (6)$\nand internal nodal forces calculated by aggregating all stress contributions induced by the deformation gradients at particles:\n$f_{\\text{int}}^n = - \\sum_{p=1}^M V_p \\sigma (\\frac{\\partial \\Psi(F)}{\\partial F}) \\nabla_{win} \\qquad (cc.Eq.31)$\nSumming up all internal and external forces, we can follow Newton's second law (a.k.a the momentum equation) to update nodal velocities:\n$v_i^{n+1} = v_i^n + \\Delta t \\cdot (f_{\\text{int},i}^n + f_{\\text{ext}})/m_i \\qquad (cc.Eq.4)$\nthe updated nodal velocities are then propagated back to particles (grid-to-particle, G2P) for updating particle property states (Eq.26, Eq.29, Eq.32):"}, {"title": "Discussions", "content": "As the MPM-ParVI method is built on classic MPM, here we discuss some topics related to both.\nLagrangian and Eulerian descriptions of motion Both Eulerian (spatial) and Lagrangian (material) descriptions are used in solid and fluid mechanics to describe material deformation or flow. Lagrangian description assumes observer flows with the observation element (e.g. the particle). The grid, if any, is attached to the element and therefore deforms (can be distorted) during the simulation process. This facilitates tracking of element deformation history. As computation is mainly performed on particles, Lagrangian methods (e.g. SPH) are very efficient. Eulerian description, on the other hand, issues a fixed grid in space and material flows through the grid. It avoids grid distortion but induces expensive computation. Lagrangian description focuses on individual particles, it uses the initial configuration (i.e. t=0) to describe the physical quantities and the deformation state of a continuum body. The Eulerian description focuses on a specific position in space at current time t, it describes the motion of a continuum body with respect to the current coordinates and time [37]. MPM takes a hybrid Lagrangian and Eulerian view: dynamics are solved on the computational Eulerian grid while particles act as quadrature points [33]. For a comprehensive read about the Lagrangian and Eulerian descriptions of fluids, see e.g. [72].\nTime step size MPM allows for larger time step size $\\Delta t$ than other particle-based simulation methods such as SPH, as the $\\Delta t$ in MPM relies on the cell size (i.e. the grid spacing) rather than the particle space (as in SPH) [13]. Both Algo.1 and Algo.2 use explicit time integration which is easy to implement but requires smaller $\\Delta t$. Implicit time integration [66] requires solving a linear system but allows for larger $\\Delta t$ [34].\nMulti-modal inference Inference of multi-modal densities require particles to separate and form local groups, which is similar to fracture or cracks modelling using MPM: there are multiple internal surfaces across which the displacement field is discontinuous, and multiple velocity fields at nodes whose supports are cut by the cracks. MPM is efficient for modelling problems with moving discontinuities such as fracture evolution [58], and well suited for large motion and shape change problems."}, {"title": "Memory and complexity", "content": "In d-dimensional space, the deformation gradient matrix $F_p$, the 1st PK stress matrix $P$, the APIC tensors $B_p$ and $D_p$, are all of dimension dxd. One need to store $d^2$ numbers for each matrix at each particle. In addition, each vector-valued particle and nodal quantity, e.g. position, velocity, momentum and force, requires d numbers to be stored. If we use a regular Cartesian grid and assign k nodes along each dimension, in total we have $N = k^d$ nodes. In each iteration n, we need $O((N + M)d+ Md^2)$ space for storing these vectors and matrices.\nThe time cost for each MPM step has been attached in each step in both algorithms, taking into account matrix inversion, transpose, matrix-matrix and matrix-vector multiplications. Overall, the MPM algorithm takes $O(Md^2(d+N))$, which is about $O(MNd^2)$ as normally we have $d \\ll N$. It is smaller than $O(MNd^3)$ but larger than O(MNd). For low dimensions (i.e. d=1,2,3), normally we have $M > N$; in high-dimensions, however, $M \\ll N = k^d$.\nThe bottleneck therefore lies in the two multiplicative factors $N = k^d$ and $d^2$. It is suspicious to say that, by modelling indirect particle interactions, MPM reduces the computational burden from $O(M^2)$ to $O(MN)$.\nAdvantages of MPM-ParVI (1) Advantages of MPM. MPM provides a particle simulation framework which enjoys the advantages of both Lagrangian and Eulerian descriptions [58]: no element distortion happens and no remeshing is required during simulation. The Lagrangian formulation allows particle motion and material deformation histories to be tracked throughout the simulation process, while the Eulerian grid enables automatic treatment of self-collision and fracture [33]. Further, it is free of mesh-entanglement problems, and allows for both explicit [32] and implicit time integration schemes. More advantages of MPM are listed in e.g. [13]. (2) Physics-based and deterministic. MPM-ParVI follows deterministic physics to generate samples, the results are trackable and reproducible. Interactions between particles are modelled in a principled manner which preserves mass, momentum and energy. (3) Handling complex geometries. As MPM is efficient in modelling discontinuities, large motion and shape change problems, MPM-ParVI may be of advantage for inferring complex (e.g. multi-modal) densities. (4) Ease of implementation. MPM-ParVI has few hyper-parameters to tune (typically, the mesh spacing and time step), which is convenient as compared to SPH, and it can be easily implemented for parallel and distributed computing. (5) Speed and accuracy. It is reported [53, 13] that, MPM is faster and more accurate than SPH due to larger time step size and no neighbourhood searching. However, as a new class of ParVI methods, comparison of these physics-based ParVI methods with other ParVI/VI methods has not been studied.\nLimitations of MPM-ParVI (1) Disadvantages of MPM. MPM is generally less accurate than FEM. Particles in MPM can suffer from numerical fracture, grid-crossing instability , the null space issue and no convergence for very fine meshes [13]. Large memory is required for computation at grid and particles. Analysis of convergence, error and stability is challenging [13]. The convergence rate is rarely of second order [13]. Boundary conditions are difficult to enforced. More disadvantages of MPM are listed in e.g. [13]. (2) Reduced flexibility as compared to SPH due to the hybrid Lagrangian-Eulerian nature of MPM. Although both SPH and MPM requires choosing a proper kernel (for different purposes), in MPM the modeller also has to choose a constitutive model (e.g. the energy density function $\\Psi$) for simulation, and the choice of which can have impact on the inference results. There is some flexibility though, for devising MPM-ParVI. For example, one can apply a time variant, external body force, in an annealing style, to control convergence. Also, one may formulate the information from the target density as boundary condition(s). (3) Limited scalability. MPM was developed for real-world simulations which are typically low-dimensional. Statistical inference problems, however, can range from low to high dimensions, and MPM-ParVI suffers from curse of dimensionality as a background mesh grid is needed for the simulation. The computational efforts increases as $O(Md^3 + MNd^2)$ where $N = k^d$, $k$ being the number of grid nodes along each dimension. This intrinsic exponential growth may prevent it from being applied to high dimensions.\nPhysical statistics This work extends the author's previous work on physics-based ParVI methods [25, 26], which forms a new branch of physical statistics (against the long standing statistical physics which applies statistics to physics) and coins the term science for AI (against the trending AI for science). There have been many physically and biologically inspired AI algorithms, e.g. the genetic algorithm [23], particle swarm optimization (PSO [35, 81]) and HMC. This series of work, however, is first of this kind which formulates a statistical inference problem fully as a physical simulation process. Unlike traditional ParVI methods which use statistical and optimisation principles to perform inference, these new ParVI methods are purely based on physics . SPH-ParVI, for example, employs the Navier-Stokes equations, which represent mass, momentum and energy conservation, as deterministic dynamics to guide the inference procedure. EParVI, on the other hand, utilizes principles of electrostatics to model the IPS.\nApplications Similar to other gradient-based sampling methods such as Hamiltonian Monte Carlo (HMC), Langevin Monte Carlo (LMC), SVGD, and SPH-ParVI MPM-ParVI can be used to infer partially known densities, e.g. an intractable Bayesian posterior known up to the normalising constant. By plugging the gradient of log pdf, i.e. the score which eliminates the unknown constant, into the MPM formulation, one can recover the target density approximately. Also, It can be used to sample score-based generative models [16, 24] in which the score can be empirically estimated via score-matching [27]."}, {"title": "Conclusion and future work", "content": "Conclusion We propose the MPM-ParVI algorithm for sampling and variational inference. It formulates sampling fully as a physical simulation process. By incorporating the gradient field of a target density into the MPM method, it drives a chosen material, represented as a system of interacting particles, to deform towards a geometry which approximates the target distribution. Particle motions are governed by principled, deterministic physics, concentration and diversity of particles are naturally maintained by the MPM formulation. This easy-to-implement ParVI method offers deterministic sampling and inference for a class of probabilistic models such as those encountered in Bayesian inference (e.g. intractable densities) and generative modelling (e.g. score-based). As a hybrid Lagrangian-Eulerian method, it suffers from curse of dimensionality.\nFuture work There are active innovations to enhance the capability (e.g. efficiency, stability"}]}