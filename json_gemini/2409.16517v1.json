{"title": "SYNCHART: SYNTHESIZING CHARTS FROM LANGUAGE MODELS", "authors": ["Mengchen Liu", "Qixiu Li", "Dongdong Chen", "Dong Chen", "Jianmin Bao", "Yunsheng Li"], "abstract": "With the release of GPT-4V(O), its use in generating pseudo labels for multi-modality tasks has gained significant popularity. However, it is still a secret how to build such advanced models from its base large language models (LLMs). This work explores the potential of using LLMs alone for data generation and develop competitive multi-modality models focusing on chart understanding. We construct a large-scale chart dataset, SynChart, which contains approximately 4 million diverse chart images with over 75 million dense annotations, including data tables, code, descriptions, and question-answer sets. We trained a 4.2B chart-expert model using this dataset and achieve near-GPT-4O performance on the ChartQA task, surpassing GPT-4V.", "sections": [{"title": "Introduction", "content": "Since the release of GPT-4V(O), using them to generate pseudo labels for multi-modality tasks has become more and more popular [1] While we often \"stand on the shoulders of giants,\" the process of building the giant itself-specifically, constructing GPT-4V(O) from its foundational large language model (LLM), GPT-4\u2014remains a mystery. In this work, we explore the potential of using LLMs alone to build a competitive multi-modality model. Given budget constraints, we focus on a specific domain-chart understanding-rather than building a general multi-modality model.\nSince the quantity and quality of data are key determinants of model performance, this work focuses on building a large-scale chart dataset and applying well-established training pipelines. There are two major challenges in constructing such a dataset: first, collecting a diverse set of chart images, and second, the more critical and difficult task of obtaining high-quality labels for these images. To address these challenges, we explored various dataset-building alternatives and carefully analyzed the trade-offs between data quality and quantity. This analysis led us to our data generation approach: synthesizing data from LLMs.\nUsing this scalable data generation process, we developed a large-scale chart dataset called SynChart, which contains approximately 4 million diverse chart images. Each image is accompanied by rich annotations, including the underlying data table, the code used to generate the chart, detailed descriptions, and a set of questions and answers. The dataset card is shown in Table. 2. Leveraging SynChart, we trained a chart-specific multi-modality model by combining Phi3.5 (3.8B) and CLIP-L (0.3B). As illustrated in Figure 1, the model's performance on the ChartQA benchmark is close to GPT-4O and surpasses GPT-4V."}, {"title": "Design Rationales", "content": "Our primary objective is to create a large-scale chart dataset specifically for training multi-modality models. This dataset must include two key components: (1) a substantial collection of chart images, and (2) high-quality annotations that accompany these images.\nDesign Alternatives. To collect chart images and corresponding labels, previous literature proposed two main approaches.\nOne approach is to collect chart images from specific domains. For example, Chart-to-text [2] gathered approximately 30K chart images from two sources:: Pew [3] and Statista [4]. The advantage of this method is the high-quality associated labels, such as human-written summaries and human-annotated data tables. However, the limitation lies in the relatively small number of available chart images. Based on our estimates, fewer than 1 million charts are accessible across the websites we surveyed. For example, Gallup [5] offers around 80K chart images.\nThe second approach involves synthesizing chart images using chart-drawing libraries like Matplotlib. For example, ChartLLAMA [6] generated 11K chart images by leveraging GPT-4's coding capabilities to produce Matplotlib code. This method has the potential to scale well beyond millions of chart images. Moreover, obtaining high-quality labels for these generated images is straightforward, as the ground truth data is inherently available in the code. The main challenge with this approach, however, is ensuring that the generated charts are both representative and diverse.\nIn addition to the two approaches mentioned earlier, we can also extract chart images from large-scale general image-text interleaved datasets, such as Obelics [7] and MINT-1T [8]. We started with Obelics to assess the potential data scale and label quality. To extract chart images, we developed a cascaded image classifier composed of three consecutive sub-classifiers: (1) a classifier to filter out natural images, (2) a classifier to remove non-chart images, and (3) a final classifier to exclude \"science charts\" like waveform diagrams. We opted for a cascaded approach rather than a single classifier due to its higher precision (96.7% on our held-out, human-annotated test set, compared to less than 90% with a single classifier). As a result, we obtained approximately 3 million chart images from Obelics.\nIn image-text interleaved datasets, surrounding text naturally serves as labels for chart images. To assess the quality of these labels, we randomly selected 100 chart images and manually annotated the relevant text from the two surrounding paragraphs. An example is shown in Figure 4 . Our analysis revealed a weak correlation (less than 50% token-level relevance) between the chart images and their surrounding paragraphs in the samples we examined.\nTable 1 summarizes the trade-offs between quality and quantity for the aforementioned approaches. Based on this analysis, we have chosen synthesized chart data as our primary data source due to its scalability. Additionally, we have integrated publicly available datasets to leverage their high-quality labels."}, {"title": "SynChart Dataset", "content": "In multi-modality model training, the primary requirements for the training dataset are scale, diversity, representativeness, and label density. As outlined in Section 2, we focus on synthesizing data to meet these needs. Our approach to generating pretraining data involves three key stages as shown in Figure 2.\nIn Stage 1, we create a set of diverse data tables that accurately represent real-world scenarios. In Stage 2, we employ LLMs to generate suitable code for visualizing the data as chart images. Finally, in Stage 3, we utilize LLMs to produce a set of question-answer pairs for post-training."}, {"title": "Data Generation", "content": "In this stage, we aim to generate a set of diverse data tables that accurately reflect real-world data. To achieve this, we first establish essential constraints tailored to different types of charts, as each chart type has its own specific requirements and is suited for various kinds of data."}, {"title": "chart generation", "content": "Based on the generated data tables, we employ a variety of data visualization engines to produce the code for drawing charts. We select these engines according to two main criteria: (1) the LLM's demonstrated ability to generate code using each engine, and (2) the engine's capacity to create a wide range of chart types relevant to SynChart. As a result, we choose four commonly used engines: Matplotlib, Seaborn, Plotly, and Bokeh. The chart types supported by each engine are listed in Table 7.\nCombining the available engines, chart types, and generated data tables, we use the LLM to produce code snippets for creating the corresponding charts. These code snippets are then executed to generate the chart images. Throughout this process, we employ a human-in-the-loop approach to correct common errors in the code snippets. This iterative refinement leads to an increase in the success rate of generating chart images, rising from 64.0% to 76.8% for Matplotlib. This iterative refinement process enabled us to collect approximately 600K more chart images."}, {"title": "question answer pair generation", "content": "To prepare SynChart for post-training use, we utilize LLMs to generate a set of question-and-answer pairs for each chart image. Specifically, we create two types of questions. The first type consists of simple questions that require only a single word or phrase as the answer. The second type includes more complex questions that necessitate a reasoning process to arrive at the correct answer."}, {"title": "Dataset Card", "content": "The dataset card is shown in Table 2. An example from the dataset can be found in Appendix A."}, {"title": "Experiments", "content": "Settings. Since our focus in this work is on data building, the training pipeline follows a well-established framework [11]. Specifically, we utilize Phi-3.5-mini-instruct (3.8B) as the base LLM and CLIP ViT-L/14 as the vision encoder. The maximum image resolution is set at 1344\u00d71344 pixels."}, {"title": "Main Results", "content": "As shown in Table 3, the model trained on SynChart achieves performance levels close to GPT-4O on the ChartQA [12] benchmark, outperforming all public small models. Notably, the majority of improvements over ChartLlama come from human-created splits. Furthermore, when compared to large public models with over 70 billion parameters, our model remains competitive. These results underscore the effectiveness of the SynChart dataset."}, {"title": "Ablations", "content": "Table 4 illustrates the contributions of each data component used in our training process. We use the \u201cBaseline*\u201d from ChartLlama as a strong reference point for our work. The baseline model, with 7 billion parameters, is larger than our model and is pretrained on image captioning data, followed by fine-tuning on the ChartQA training split. From this starting point, we systematically add data components and evaluate their contributions. As shown in in Table 4, we achieve approximately a 30% improvement in ChartQA performance. This enhancement is primarily attributed to pretraining and post-training with SynChart, while incorporating public datasets from similar domains also proves beneficial. Consequently, the construction of high-quality yet small-scale datasets remains essential for improving model performance and aligning with human understanding."}, {"title": "Scaling Property", "content": "To demonstrate the scaling properties of SynChart, we conduct two ablations focused on data and training costs. As shown in Table 5, utilizing more data from SynChart during post-training leads to improved performance. Notably, at the maximum training cost we tested, the model's performance has not yet plateaued. This finding addresses a critical concern regarding synthetic datasets: that models may quickly reach saturation due to limited data diversity."}, {"title": "Related Work", "content": "Among the various chart dataset building papers [6, 13, 14, 15, 16], the most closely related work is ChartLlama [6]. Both studies share the fundamental approach of using LLMs to generate synthetic chart data. However, this work offers two significant contributions.\nFirst, we provide a detailed analysis of alternative data collection methods. The results of this analysis underscore the necessity of a synthesizing process in chart dataset construction. Second, we achieve a substantially larger data scale; for instance, SynChart contains over 300 times more chart images (3.93 million compared to 11,000 in ChartLlama). In the scaling process, we focused on maximizing data diversity by incorporating a range of chart metadata, including types, themes, data constraints, trends, and engines."}, {"title": "Conclusion", "content": "In this work, we construct a large-scale chart dataset, SynChart, by synthesizing data from LLMs. The dataset comprises approximately 4 million diverse chart images, accompanied by dense annotations, including data tables, code, descriptions, and question-answer sets. We trained a 4.2 billion parameter chart-expert model using this dataset, achieving performance levels close to GPT-40 on the ChartQA task.\nLooking ahead, there are several research directions to enhance the quality of the dataset. These include expanding the variety of chart types, filtering chart images based on visual quality, and incorporating support for dashboards with multiple sub-charts."}, {"title": "Prompts", "content": null}, {"title": "Prompt for Theme Generation", "content": "Generate a set of themes for this topic: Generate a set of themes for this topic: \"{topic}\", topic definiton: {definition}\nEach theme is a phrase. Return as json format."}, {"title": "Prompt for Trend Generation", "content": "List possible trends found in this type of chart: {chart_type}. Return as json format."}, {"title": "Prompt for Col/Row Constraints Generation", "content": "For a tabular data, to visualize it with a {chart_type}, what is the suitable range of number of rows and columns?\nRespond with conclusion first, followed by an explanation."}, {"title": "Prompt for Data Generation", "content": "You are an expert at generating data in csv format. You receive several key characteristics about the data. Your final output should include data in CSV format for the chart, and a comprehensive description of the chart data and figure.\n##Expected characteristics of the data in the chart. The chart is {chart_type}. The theme of the chart is {theme}.\nDifferent series of data in the chart can have different trends. The trends in the chart data should include as many of the given trends as possible: {trends}. The data should be diverse and contain several outliers. The numbers of columns and rows should satisfy: {row_column}. {data_constraints} You can list the nouns you know, which are related with the theme, along the first column and row of the table.\n## Requirement about the description The description should focus on several key elements: the chart's theme, the general trend of the data, individual trends within the data, the comparison between data, and any outliers present in the chart.\n## Requirement about the output Your output should comprise the generated data wrapped in <data start> and <data end>, and detailed descriptions about the chart wrapped in <description start> and <description end>."}, {"title": "Prompt for Code Generation", "content": "You are a specialist in two aspects, drawing charts with {engine}, and providing detailed descriptions about the chart. You receive the data in the format of csv table. You need to generate Python code to plot the given data as a chart figure and providing detailed description about the figure.\nAdditional requirements:\nYou can freely set the chart styles to increase the diversity, including title, legend, labels on x-axis and y-axis. You can annotate data values above the point on the chart figure.\nDo not use show function to show the figure. Save the figure as a jpg file, with filename \"{filename}\" The csv data should be listed in the code.\nThe output contains two parts. The first part is the generated Python code wrapped in <code> start> and <code> end>. Next is the detailed description about the chart wrapped in <description start> and <description end>. The code should be able to be executed without external files.\nDraw a {chart_type} with the given data:\n{data}"}, {"title": "Prompt for Simple Question Answering Generation", "content": "You are an AI visual assistant that can analyze chart figures. You receive two detailed descriptions, raw data, and the python code drawing the figure about the same chart. The first description is the information about the raw data in the chart. The second description is about the chart figure based on Python code. In addition, raw data values within the chart is given. The python code generating the chart is given as well. Answer all questions as you are seeing the chart figure. Design a question-answer pair between you and a person asking about this chart figure. The answers should be a single word or phrase, and in a tone that a visual AI assistant is seeing the chart figure and answering the question.\nAsk diverse questions and give corresponding answers. The number of questions needs to be between 3 and 20. Include questions asking about {Characteristics} and so on. Only include questions that have definite answers:(1) one can see in the chart figure that the question asks about and can answer confidently;(2) one can determine confidently from the chart figure that it is not in the chart figure.\nDo not ask any question that cannot be answered confidently. The answers should be a single word or phrase."}, {"title": "Prompt for Complex Question Answering Generation", "content": "You are an AI visual assistant that can analyze chart figures. You receive two detailed descriptions, raw data, and the python code drawing the figure about the same chart. The first description is the information about the raw data in the chart. The second description is about the chart figure based on Python code. In addition, raw data values within the chart is given. The python code generating the chart is given as well. Answer all questions as you are seeing the chart figure. Design a question-answer pair between you and a person asking about this chart figure. The answers should be a single word or phrase, and in a tone that a visual AI assistant is seeing the chart figure and answering the question.\nAsk diverse questions and give corresponding answers. The number of questions needs to be between 2 and 10. Include questions asking about {Characteristics} and so on.\nOnly include questions that have definite answers:(1) one can see in the chart figure that the question asks about and can answer confidently;(2) one can determine confidently from the chart figure that it is not in the chart figure.\nDo not ask any question that cannot be answered confidently. You need to follow the steps below to reason before generating the answer:\n(1) Describe the relevant information from the image needed to answer the question. (Do not mention the 'raw data', 'code', 'table' and so on, use 'chart' or 'figure' instead)\n(2) Use the information described in (1) to reason about the problem by working step by step to arrive at the final answer.\n(3) state the final answer."}, {"title": "Dataset Details", "content": null}, {"title": "Types of Charts", "content": "9 Types of charts in SynChart:\nbar chart, line chart, radar chart, stacked bar plot (stacked bar chart), doughnut chart, pie chart, scatter plot, boxplot, stacked area chart."}, {"title": "Col/Row Constraints", "content": null}]}