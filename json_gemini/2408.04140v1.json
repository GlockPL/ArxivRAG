{"title": "UNLEARN\nEfficient Removal of Knowledge in Large Language Models", "authors": ["Tyler Lizzo", "Larry Heck"], "abstract": "Given the prevalence of large language models (LLMs) and the prohibitive cost of train-ing these models from scratch, dynamicallyforgetting specific knowledge e.g., private orproprietary, without retraining the model hasbecome an important capability. This paper pro-poses a novel method to achieve this objectivecalled UNLEARN. The approach builds uponsubspace methods to identify and specificallytarget the removal of knowledge without ad-versely affecting other knowledge in the LLM.Results demonstrate 96% of targeted knowl-edge can be forgotten while maintaining per-formance on other knowledge within 2.5% ofthe original model, significantly outperform-ing the discriminatory abilities of the previousstate-of-the-art. A dual method called LEARNis also proposed for targeted knowledge ad-dition. Results show LEARN can match thefine-tuning accuracy of Low-Rank Adaptation(LORA) without adversely affecting similartasks.", "sections": [{"title": "1 Introduction", "content": "The swift advancement and widespread deploy-ment of large language models (LLMs) havebrought many challenges including the inabilityto remove knowledge from the LLMs at will. Ef-ficient removal of knowledge has become increas-ingly important with 'Right to be Forgotten' laws(Goldman, 2020) and Europe's General Data Pro-tection Regulation (Goddard, 2017). Traditionaltraining methodologies often lack the flexibilityand efficiency required to address both tasks, es-pecially when rapid model adaptation is neededwithout comprehensive retraining.\nThis paper introduces UNLEARN, a novel algo-rithm that can forget or unlearn knowledge withinan LLM without adversely affecting related knowl-edge. UNLEARN leverages subspace techniques toidentify the subspaces spanned by particular knowl-edge (tasks) and discrimination methods to separatethat subspace from subspaces of similar tasks. Thisallows the algorithm to prevent performance degra-dation when there are similar tasks, a commonissue with traditional methods and of particular im-portance to data privacy regulations. Further, thistechnique uses a unified set of operators, whereduction where the task matrices are identical and used to eitherenhance or reduce the model's performance for agiven task.\nUNLEARN achieves 96% forgetting on thetask of interest while maintaining performanceon dissimilar tasks within 2.5% of the originalmodel. When the tasks are similar, UNLEARNstill achieves nearly 80% forgetting on the task ofinterest while preserving performance on similartasks within 10%. These results significantly out-perform the state-of-the-art, which achieves similarforgetting but is accompanied by significant degra-dation on similar tasks.\nThe forgetting of UNLEARN can easily be con-verted to add knowledge to the LLM. This newmethod LEARN matches the fine-tuning accuracyof the LORA method (Hu et al., 2021) withoutaffecting related tasks, demonstrating its dual na-ture across both knowledge unlearning and fine-tuning scenarios.\nThe contributions of this work are as follows:\n\u2022 An efficient method to identify the subspaceof specific knowledge within an LLM.\n\u2022 A novel approach called subspace discrimina-tion and task removal to selectively target andremove specific knowledge without adverselyaffecting other knowledge in the LLM.\n\u2022 The introduction of LEARN, a dual algorithmto UNLEARN that provides a new approach to adding new knowledge to the LLM withoutaffecting its other knowledge.\nThis paper presents the UNLEARN algorithm anddemonstrates its performance in removing knowl-edge represented as tasks. Section 2 reviews the"}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 Parameter Efficient Fine-Tuning", "content": "Parameter Efficient Fine-Tuning (PEFT) is used tofine-tune large models without modifying most ofthe original pre-trained weights, resulting in signif-icant computational and storage savings.\nOne of the most significant PEFT methods isLow-Rank Adaptation (LoRA; Hu et al., 2021),which decomposes weight updates into two low-rank matrices. While reducing trainable parame-ters by 10,000 times and GPU memory usage by 3times, LoRA is still able to maintain the fine-tuningperformance of a systems. Quantized Low-RankAdapation would build upon LoRA's performancegains by quantizing model weights (Dettmers et al.,2023).\nOther notable PEFT methods include prompttuning (Lester et al., 2021; Qin and Eisner, 2021),tuning hidden states (IA\u00b3; Liu et al., 2022a), addinglayers (Houlsby et al., 2019), tuning the embed-ding layer inputs (An et al., 2022), and hybrid approaches (Mahabadi et al., 2021). These extendprior work on domain adaptation of deep neuralnetworks for Natural Language Processing (Jaech\net al., 2016)."}, {"title": "2.2 Machine Unlearning", "content": "Machine unlearning is the process of removing theinfluence of data on an already trained model, cre-ating a model that behaves as if it was never trainedon that data (Xu et al., 2023). Its origins are inregulation such as the California\ndata protection regulations, such as the CalifornialossConsumer Privacy Act (CCPA; Goldman, 2020)and the European Union's General Data Protec-tion Regulation (GDPR; Goddard, 2017), whichassert a user's 'Right to be Forgotten,' the right to"}, {"title": "2.3 LLM Unlearning", "content": "There is an increasing interest in machine unlearn-ing in the context of LLMs (Jang et al., 2022;Meng et al., 2023; Liu et al., 2024c). Importantworks have demonstrated the need for machine un-learning within LLMs, showing clear motivationsfrom both regulatory and application-specific stand-points (Zhang et al., 2023a; Liu et al., 2024b).\nExisting methods for LLM unlearning includegradient ascent to reascend the learning curve (Janget al., 2022; Chen and Yang, 2023; Yao et al.,2024), preference optimization using alternativeresponses (Eldan and Russinovich, 2023; Mainiet al., 2024), and input-based approaches (Pawelczyk et al., 2024; Thaker et al., 2024).\nHowever, these methods face significant chal-lenges. There are the aforementioned cost and timerestraints. The vast amounts of training data usedfor LLM training adds to the complexity, as iden-tifying and isolating the specific data points to beunlearned is a non-trivial task (Eldan and Russinovich, 2023; Ilharco et al., 2023). The scope ofunlearning is generally underspecified; unlearningshould remove knowledge within the scope of thetargeted data while maintaining performance onother data (Mitchell et al., 2022). Finally, there isa lack of comprehensive evaluation methods to as-sess the effectiveness of unlearning in LLMs (Patilet al., 2023; Shi et al., 2024)."}, {"title": "3 UNLEARN Method", "content": "The method proposed in this paper consists of threemain tasks: subspace identification, discrimina-"}, {"title": "3.1 Subspace Identification", "content": "This step identifies the subspace of a specific taskwithin the LLM weight space. The method utilizesa general training that is implemented layer-by-layer, starting with the first layer (l = 1). Alltraining is performed with a train/validation/testsplit of 0.6/0.2/0.2: The train set is used for trainingthe network, the validation set determines when tostop training for a specific layer in our sequentialprocess, and all evaluations are performed on thefinal test set:\n0. Model: The original pretrained weights ofthe LLM are removed and the weights for alllayers are randomly initialized.\n1. Layer Freezing: Except for the weights atlayer l, all other weights for the subsequentlayers of an LLM are frozen to isolate thetraining to one layer at a time.\n2. Training: Training is completed on the taskdataset with the l-th layer unfrozen. This isachieved by maximizing the conditional lan-"}, {"title": "3.2 Subspace Discrimination", "content": "Once a task-dependent subspace has been identi-fied, it could be removed by subtracting it fromthe entire weight space (layer-by-layer). Whilethis may be effective at removing the task of in-terest, it leads to performance loss when similartasks are also evaluated, i.e. ones that occupy sim-ilar subspaces. Therefore, a method is requiredthat maintains the mutual information betweenthese two subspaces, only removing the informa-tion unique to the task of interest. We call thissubspace discrimination.\nTo achieve subspace discrimination, we utilizea variation of the Gram-Schmidt process. Gram-Schmidt is used to orthogonalize a set of vectorsin an inner product space. Given the subspaceU spanned by vectors u\u2081,\u2026\u2026,un, we can findthe orthogonal subspace to a vector vk with thefollowing:\n$U_k = U_k - \\sum_{j=1}^{N} \\frac{(U_k, U_j)}{(U_j, U_j)} U_j$.\nA proof that v is orthogonal to all uj is offered inAppendix A. For our application, we compute:\n$SV(T) = SV(T) - \\sum_{j=1}^{N}  \\frac{SV(T_i) \\cdot SV(T_0)}{SV(T_i) \\cdot SV(T_0)} SV(T_j)$.\nwhere Ti represents the identified subspace to beremoved, To represents a similar task, and SVk(T)\nrepresents the k-th singular vector of matrix T\u00bf forone of the Transformer layers l. When applied totwo tasks, every pair of weight matrices is decom-posed and separated in this manner. For three ormore tasks, the other task matrices; To,1, To,2,\u2026\u2026,Ton, are added into one To matrix, then the aboveequation is applied. We chose to use Euclidean in-ner products, inspired by the original LORA paper(Hu et al., 2021), which demonstrated that effi-cient training could be achieved with linear rankdecompositions. While neural network parameterspaces are non-Euclidean, the practical success ofthe LORA method justified our approach.\nInitially, the similarity of tasks was determinedsubjectively. However, this subspace discrimina-tion method allows us to quantify task similarity,as there will be more overlap in the weight spaceof two similar sets of matrices. For two dissimi-lar tasks, the discrimination process will have noeffect, as they are already orthogonal.\nSubspace discrimination is essential to theUNLEARN algorithm, allowing for the precise sep-aration of task-specific information within sharedweight spaces and ensuring that the removal of onetask does not undesirably impact the performanceon similar tasks. Consequently, subspace discrim-ination enhances the algorithm's adaptability androbustness."}, {"title": "3.3 Task Removal", "content": "The final step removes the task subspace. Toachieve this, our approach uses SVD reconstruc-tion to reconstitute the modified task matrix, Tfrom the singular values of Ti and singular vectorsSV(T) above. Once T is computed, we subtractit from W' for each matrix in the LLM:\n$W' = W' \u2013 T$"}, {"title": "4 Experiments", "content": "All experiments in this section use the same setup,with Llama 2 70b serving as the LLM. For thetraining step in the subspace identification method(Section 3.1) as illustrated in Figure 2, we usedthe Python package LORALIB (Hu et al., 2021)but, rather than training a fine-tuning adapter, wemodified it to train the bottleneck in Figure 2 fromscratch. We used a rank of k = 16. Only theattention matrices were modified during training.This was inspired by the original LORA paper (Huet al., 2021), where they only adapted the attentionweights."}, {"title": "4.1 Datasets", "content": "A diverse selection of benchmarks is essentialto evaluate performance degradation across sim-ilar tasks when modifying task-specific subspaceswithin LLMs. This study used two significationcollections of benchmarks: Holistic Evaluationof Language Models (HELM; et al., 2023c) andthe Beyond-the-Imitation-Game Benchmark (BIG-Bench; et al., 2023a).\nHELM evaluates a wide range of use cases andmetrics, encompassing general language abilities"}, {"title": "4.2 Single Task Removal", "content": "The first trio of experiments evaluated theUNLEARN method using only subspace identi-fication (Section 3.1) and task removal (Section3.3) without the subspace discrimination method(Section 3.2). In these experiments, a single taskwas removed and performance across a set of taskswas observed. We will refer to these experimentsas 'UNLEARN w/o D', where 'w/o D' refers tothe absence of subspace discrimination.\nIn the first experiment, the math word prob-lem dataset GSM8K (Cobbe et al., 2021) wasremoved using the \u2018UNLEARN w/o D'method.This is the first Targeted Task in Table 1. Thefirst six columns under Evaluation Tasks were cho-sen because they are very different tasks fromGSM8K, ranging from question-answering (Nar-rativeQA; Kocisky et al., 2017) to more generalbenchmarks (MMLU; Hendrycks et al., 2021). Be-cause these tasks are dissimilar, they theoreticallyhave little overlap in their weight subspaces. Eval-uating the six chosen benchmarks on both thebase model and 'UNLEARN w/o D' model showsour approach successfully forgets (dropped per-formance) by 96.5% on the desired GSM8K task,while all other tasks had minimal degradation (less"}, {"title": "4.3 Task Discrimination", "content": "Prompted by the shared degradation seen on arith-metic and GSM8K in Section 4.2, these experi-ments explore the connection between closely re-lated tasks and evaluate the efficacy of the subspace These experiments aimed to orthongonally separate discrimination method proposed in Section 3.2.\nIn the forgetting setting, the UNLEARN algorithmthe subspaces corresponding to two tasks, allow-ing us to manipulate one subspace while preserv-ing the integrity of the other. These experimentsfocus on two sets of overlapping tasks: Narra-tiveQA/NaturalQuestions and arithmetic/GSM8K.\nIn the forgetting setting, the UNLEARN algorithmis able to successfully discriminate between twosimilar tasks and only remove the task of interest."}, {"title": "4.4 Optimal Rank", "content": "We explore the impact of varying the rankof the rank-deficient matrices during subspaceidentification"}, {"title": "4.5 Using UNLEARN to LEARN", "content": ""}, {"title": "4.5.1 LEARN methodology", "content": "The UNLEARN methodology, initially designedfor the selective removal of task-specific informa-tion from LLMs, also presents a versatile frame-work that can be adapted for the enhancement ofmodel performance on particular tasks. This sec-tion explores 'LEARN,\u201d the application of our ear-lier UNLEARN algorithm for training on new in-formation. This method aims to add knowledgeand/or amplify the representation of a given taskwithin the model, leading to improved performanceon that task.\nThe LEARN approach uses the same principlesas UNLEARN but inverts the application to focuson task enhancement. Specifically, the methodinvolves identifying the subspace associated witha desired task using the approach in Section 3.1;this step is identical to UNLEARN. The differencecomes with task addition instead of task removal;the only necessary change is flipping the equationfor task removal from Section 3.3:\n$W' = W + T$\nThis addition should bolster performance on a newtask, as the T sits on top of the existing weight ma-trix, similar to the function of most LLM adapters.In addtion, due to subspace discrimination (Section3.2), adding the new knowledge should have mini-mal adverse effects on other knowledge already inthe LLM."}, {"title": "4.5.2 LEARN evaluation", "content": "To evaluate the effect of the LEARN method, exper-iments were conducted on tasks where pre-trainedmodels showed suboptimal performance but hadthe potential to perform well if fine-tuned. Identify-ing tasks that meets these criteria for larger LLMs(50 B+ parameter) is challenging because they aretrained on such extensive datasets that it is moredifficult to find data not included in the trainingset. Therefore, by restricting the size of the LLM,we limit the total learning capacity of the model,allowing us to squeeze out additional learning thatthe LLM should be able to handle.\nThese experiments used a similar setting to be-fore, with the exception of using Llama 2 7b. Thedataset of interest is LegalBench, a benchmark builtby a collaboration between lawyers and ML engi-neers to measure legal reasoning in LLMs (et al.,"}, {"title": "5 Comparison to Existing Methods", "content": "This section presents a comparative analysis of theUNLEARN/LEARN methodology against existingmethods, with a focus on generality and task per-formance."}, {"title": "5.1 Generality and Efficiency", "content": "A key advantage of UNLEARN/LEARN is its oper-ational flexibility. It offers a generalized frameworkthat can be applied to full fine-tuning or any PEFTmethod for fine-tuning. UNLEARN/LEARN ap-plies the same underlying principles in any setting-either adding or subtracting task-specific matricesfrom the model's weight matrices-to both enhance(LEARN) and diminish (UNLEARN) the model'sperformance on specific tasks. Because the sameset of matrices are being used regardless of algo-rithm, this simplifies model management and re-duces the computational and storage overhead."}, {"title": "5.2 Task Performance", "content": "In scenarios involving similar tasks, the differencesbetween UNLEARN/LEARN and existing meth-ods become even more pronounced. In the LEARNsetting of Table 3, both methods show comparableimprovements in task performance, demonstratingtheir efficacy for bolstering model performance. In"}, {"title": "6 Future Works", "content": "This paper has laid the groundwork for several in-triguing avenues for future research. First, whileour initial work focused on removing broad domainknowledge, future efforts will extend this method-ology to the removal of specific knowledge andfacts. We are currently collecting datasets that willfacilitate this extension, particularly in scenariosinvolving private or harmful information.\nThere are some scalability concerns if UN-LEARN is applied to a large number of tasks.While the current work targets the selective re-moval of a small number of unwanted tasks, futureresearch will investigate strategies to efficientlyhandle discrimination between larger sets of simi-lar tasks."}, {"title": "7 Conclusion", "content": "This paper introduces UNLEARN, a novel ap-proach for forgetting selected knowledge in LargeLanguage Models. This method relies on subspaceidentification for tasks and subspace discrimina-tion between similar tasks. The experimental re-sults demonstrate significant performance gains,highlighting the effect of UNLEARN on removingunwanted knowledge without having deleteriouseffects on related tasks. The method's ability toisolate and remove specific subspaces within themodel ensures precise unlearning, making it a valu-able tool for managing the complexities of taskforgetting.\nCompared to state-of-the-art methods like Gra-dient Ascent, UNLEARN offers substantial advan-tages in terms of generality, efficiency, and pre-cision. UNLEARN achieves 96% forgetting onthe task of interest while maintaining performanceon other tasks within 2.5% of the original model.When similar tasks are considered, UNLEARNachieves nearly 80% forgetting on the task of in-terest while preserving performance on the similartask within 10% of the original model. The dis-criminative ability of UNLEARN far outpaces thatof the existing state-of-the-art, ensuring targetedunlearning without compromising the performanceon related tasks."}, {"title": "Ethics Statement", "content": "While UNLEARN has significant potential bene-fits, such as improving model flexibility and effi-ciency, we are also mindful of the ethical implica-tions. By allowing models to forget specific tasks,we enhance privacy and security by ensuring thatsensitive information can be effectively removed.This is particularly important in contexts wheremodels are trained on private or confidential data.Further, UNLEARN can promote fairness by re-moving biased or harmful information.\nHowever, there is also a risk that such methodscould be misused to intentionally modify impor-tant information, leading to biased outputs. Weadvocate for the transparent and responsible use ofthis technology, with appropriate safeguards andpolicies to prevent such misuse."}, {"title": "A Proof of Orthogonality of $v_k$", "content": "We offer a quick proof that $v_k^\\perp$ is orthogonal to theorthogonal components of $U$: $u_1,\\dots,u_N$. Webegin with our orthogonality definition in an innerproduct space:\nu, v are orthogonal if $\\langle u, v \\rangle = 0$\nNext, we consider $v_k^\\perp$ and arbitrary $u_l$:\n$v_k^\\perp = v_k - \\sum_{j=1}^N \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle}u_j$\nWe need to show that $\\langle v_k^\\perp, u_l \\rangle = 0$. We proceedwith the following calculation:\n$\\begin{aligned} &\\langle v_k^\\perp, u_l \\rangle \\\\ &= \\Biggl\\langle v_k - \\sum_{j=1}^N \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle}u_j, u_l \\Biggr\\rangle \\\\ &= \\langle v_k, u_l \\rangle - \\Biggl\\langle \\sum_{j=1}^N \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle}u_j, u_l \\Biggr\\rangle \\\\ &= \\langle v_k, u_l \\rangle - \\sum_{j=1}^N \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle}\\langle u_j, u_l \\rangle \\end{aligned}$\nSince $u_1,\\dots,u_N$ are orthogonal components, wehave $\\langle u_j, u_k \\rangle = 0$ for $j \\neq k$. This simplifies thesummmation as follows:\n$\\begin{aligned} &\\langle v_k^\\perp, u_l \\rangle = \\langle v_k, u_l \\rangle - \\sum_{j=1}^N \\frac{\\langle v_k, u_j \\rangle}{\\langle u_j, u_j \\rangle} \\langle u_j, u_l \\rangle \\\\ &= \\langle v_k, u_l \\rangle - \\frac{\\langle v_k, u_l \\rangle}{\\langle u_l, u_l \\rangle} \\langle u_l, u_l \\rangle \\\\ &= \\langle v_k, u_l \\rangle - \\langle v_k, u_l \\rangle \\\\ &= 0 \\end{aligned}$\nThus, we have shown that $\\langle v_k^\\perp, u_l \\rangle = 0$ for any$u_l$, proving that $v_k^\\perp$ is orthogonal to the orthogonalcomponents, $u_1,\\dots,u_N$, of $U$."}]}