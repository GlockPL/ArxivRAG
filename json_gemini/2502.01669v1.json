{"title": "Addressing Delayed Feedback in Conversion Rate Prediction via Influence Functions", "authors": ["Chenlu Ding", "Jiancan Wu", "Yancheng Yuan", "Junfeng Fang", "Cunchun Li", "Xiang Wang", "Xiangnan He"], "abstract": "In the realm of online digital advertising, conversion rate (CVR) prediction plays a pivotal role in maximizing revenue under cost-per-conversion (CPA) models, where advertisers are charged only when users complete specific actions, such as making a purchase. A major challenge in CVR prediction lies in the delayed feedback problem-conversions may occur hours or even weeks after initial user interactions. This delay complicates model training, as recent data may be incomplete, leading to biases and diminished performance. Although existing methods attempt to address this issue, they often fall short in adapting to evolving user behaviors and depend on auxiliary models, which introduces computational inefficiencies and the risk of model inconsistency. In this work, we propose an Influence Function-empowered framework for Delayed Feedback Modeling (IF-DFM). IF-DFM leverages influence functions to estimate how newly acquired and delayed conversion data impact model parameters, enabling efficient parameter updates without the need for full retraining. Additionally, we present a scalable algorithm that efficiently computes parameter updates by reframing the inverse Hessian-vector product as an optimization problem, striking a balance between computational efficiency and effectiveness. Extensive experiments on benchmark datasets demonstrate that IF-DFM consistently surpasses state-of-the-art methods, significantly enhancing both prediction accuracy and model adaptability.", "sections": [{"title": "Introduction", "content": "In online digital advertising, predicting conversion rate (CVR) is crucial for maximizing revenue under the cost-per-conversion (CPA) model [25, 31, 32], where advertisers pay only after users complete predefined actions, such as purchases. However, unlike user clicks that typically happen within minutes of ad impressions, conversions can occur hours to weeks after a user clicks an ad, highlighting the delayed feedback issue [3, 24, 44] in CVR modeling. To address this, online platforms commonly set a time window to await the conversion signal and periodically update the prediction model [9]. In this context, clicks resulting in conversions within this window are labeled as positive samples, while those not leading to conversions, or where the conversion delay surpasses the window, are considered as negative [17, 24, 26]. Consequently, such a delay in conversions introduces a trade-off between label correctness and model freshness.\nMany efforts have been made to mitigate the delayed feedback issue in CVR, which can be roughly categorized into offline and online approaches. Offline methods [36, 46, 47] rely on historical data to train models, usually with an extra component to model the distribution of the delay time [3] or adjust for the correct labels [42]. They generally work under the i.i.d assumption that future data distributions will remain consistent with historical patterns. On the other hand, online methods [5, 13, 26] attempt to update the model by ingesting newly observed data and correcting labels in near real-time or waiting short intervals. Such updates are conducted on the duplicated data with corrected labels [44] or using a surrogate loss, to approach the oracle model [9, 24]. The framework of offline CVR methods, online CVR methods can be found in Figure 1.\nDespite effectiveness, current approaches suffer from two significant limitations:\n\u2022 Inadequate Adaptation to Evolving User Interest. The dynamic nature of user interests challenges the assumption of an unchanged data distribution, which may not hold in environments characterized by evolving user behavior [9]. Offline methods, operating under the i.i.d assumption, struggle to capture users' emerging behaviors and preference shifts. Online methods, while adapting more swiftly by incorporating new data, often suffer from sample reduplication during the label correction process, which can lead to model confusion and hinder the effective integration of accurate label information.\n\u2022 Reliance on Auxiliary Models. The mainstream approaches typically incorporate auxiliary components to estimate potential label reversals for observed negatives or to model the probabilities of fake negatives as latent variables. However, developing these additional components can be as complex as constructing the primary CVR model. Moreover, their effectiveness are limited by the quality and quantity of historical data. This dependency may result in computational inefficiencies and add additional complexities to the CVR prediction task.\nIn this work, we explore a new paradigm for mitigating the delayed feedback issue, which can naturally adapt to new data without requiring auxiliary models. Although retraining models from scratch with correctly labeled data is intuitive, it becomes prohibitively resource-intensive, particularly in large-scale CVR scenarios. To overcome this, we propose to leverage the influence function, a concept rooted in robust statistics but drawing increasing attention in machine learning [23]. The basic idea of the influence function is to estimate parameter changes induced by modifications to a sample (e.g., removing a sample [49] or editing its feature [43]) by up-weighting the individual loss w.r.t. the target sample, resulting in the formulation of inverse Hessian-vector-products. Conceptually, incorporating the influence function to mitigate the delayed feedback problem offers a notable benefit: it allows for the direct modification of model parameters based on the estimated impact of newly injected data.\nHowever, given the significant computational and space complexities of inverting the Hessian matrix, integrating the influence function also presents its unique challenge: How to efficiently get model parameter changes for CVR tasks? In most cases, CVR tasks have much larger datasets and model sizes compared to traditional tasks using the influence function.\nIn this paper, we introduce an influence function-empowered framework for delayed feedback modeling (IF-DFM). At its core is to leverage the influence function to estimate the impact of newly injected data and directly modify model parameters without retraining. Specifically, for a deployed CVR model, IF-DFM utilizes the influence function to calculate the parameter changes induced by transitioning from mislabeled samples to their correct counterparts. This correction is performed by removing the sample with the incorrect label and adding its correct version, thus avoiding sample duplication and eliminating the need for auxiliary models. Importantly, IF-DFM also supports the incorporation of newly arrived behavioral data (e.g., clicks occurred post-deployment), allowing the model to adapt to the latest user interactions. This effectively updates the model parameters to capture current user preferences, thus improving the prediction accuracy. To mitigate the computational cost, we propose a novel strategy that accelerates the calculation of parameter changes by reformulating the inverse Hessian-vector-product computation as a finite-sum quadratic programming problem. This enables us to solve it using efficient stochastic optimization algorithms, such as stochastic gradient descent (SGD) [35] and its variants [10, 21], eliminating the need for full-batch gradient computations. We conduct extensive experiments on two benchmark datasets, demonstrating the superiority of the proposed method. Our main contributions can be summarized as follows:\n\u2022 We propose a novel paradigm IF-DFM for mitigating the delayed feedback problem. It utilizes the influence function to estimate the impact of fake label correction and new behavior data integration, and directly modify model parameters without retraining.\n\u2022 We propose to compute the influence function by formulating the inverse Hessian-vector-product calculation as an optimization problem, achieving a balance between computational efficiency and effectiveness.\n\u2022 Extensive experiments on benchmark datasets demonstrate the superiority of IF-DFM."}, {"title": "Preliminaries", "content": "2.1 Problem Formulation\nThe fundamental task of CVR prediction is to estimate the rate of conversion from the user clicks into purchases, based on historical data. Throughout this paper, we represent the i-th training sample as $z_i = (x_i, y)$, where $x_i$ encompasses the features, $y$ is the observed label. Furthermore, in CVR prediction, each sample is also associated with a true label $y^\\star$, which is inaccessible within the training dataset. The feature set $x_i$ typically comprises temporal components - click timestamp $c_i$, payment timestamp $p_i$, and the elapsed time $e_i$ from the click to a model-training-start timestamp $T$ along with user/item characteristics. Here, the default value of $p_i$ is -1 if no conversion has occurred before $T$. The training set accumulated up to $T$ can be described as $Z = \\{z_i | i = 1, 2, ..., n\\}$, where $n$ is the sample size. Due to the delayed feedback issue, where the ground truth $y^\\star$ is absent, the training process could be misled by fake negative samples. The relationship between the sample label and the timeline can be found in Figure 2. Specifically, if the conversion happens before T (i.e., $p_i < T$), the sample is labeled as $y = 1$ and $y = y^\\star$, indicating a true positive; In contrast, if the conversion is unobserved (i.e., $p_i > T$), the sample is labeled as $y = 0$, which may not reflect $y^\\star$, creating a 'fake negative' - a delayed conversion might happen later. That is, the delayed feedback is only caused by the fake negative issue, implying that only negative samples may turn into positive samples after T. The CVR model trained with such data will be evaluated at timestamp T', using only the test samples with their true labels.\n2.2 Vanilla and Retrain Versions of Loss\nThe CVR model, $f(x, \\theta)$ parameterized by $\\theta$, operates as a binary classifier, predicting whether a click action $x$ will result in a conversion. Training such models typically employs binary cross-entropy loss [9, 42]. We first describe its Vanilla version [3, 46], wherein all observed non-converting instances are considered negatives:\n$L_v(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n} L_{BCE}(z_i, \\theta),$ (1)\nwhere for any sample z = (x, y) and model parameter $\\theta$,\n$L_{BCE}(z, \\theta) = -[y \\log f(x, \\theta) + (1 - y) \\log (1 - f(x, \\theta))]$ is the commonly used binary cross-entropy loss.\nThe vanilla version calculates loss over the observed labels without label adjustments, thereby serving as the lower bound of CVR prediction performance. Conversely, the Oracle version, which presumes access to the true labels $y^\\star$, represents the upper performance bound. Let $z_i^\\star = (x_i, y_i^\\star)$. The oracle loss is defined as:\n$L_o(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n} L_{BCE}(z_i^\\star, \\theta).$ (2)\nIn fact, many conversions occur long after the testing phase, making it unrealistic to assume that the true labels of all are known during testing. Based on this, we propose a practically achievable Retrain version, and the loss function is as follows:\n$L_R(\\theta) = \\frac{1}{n}\\sum_{i=1}^{n} L_{BCE}(\\tilde{z_i}, \\theta),$ (3)\nwhere $\\tilde{z_i} = (x_i, \\tilde{y_i})$ and $\\tilde{y_i}$ is defined as:\n$\\tilde{y_i} = \\begin{cases} y_i^\\star \\quad \\text{the sample was not converted before testing}, \\\\ y_i \\quad \\text{the sample converted before testing}.\\end{cases}$\nIn other words, the retrain loss has access to all true conversions that happened up to the testing time, which is the best possible practical retrain model."}, {"title": "Influence Function", "content": "Influence function [18], which is a classical tool in robust statistics for measuring the changes of the model parameters to small changes in the weights of training samples, has been recently introduced in the machine learning community for understanding black-box predictions and beyond [23]. Given a training data set $Z = \\{z_1, z_2, ..., z_n\\}$, we consider the following empirical risk minimization problem:\n$\\theta \\in arg \\min_{ \\theta} R(\\theta) := \\frac{1}{n} \\sum_{i=1}^{n} L(z_i, \\theta),$ (4)\nwhere $L(\\cdot, \\cdot)$ is the loss function (e.g., Equatioins (1) (2)), $\\theta$ is the model parameter.\nWe are interested in estimating the model parameter change $\\Delta \\theta(\\epsilon) = \\hat{\\theta}_{new}(\\epsilon) - \\hat{\\theta}$ if some training sample $z_j$ is slightly reweighted by $\\epsilon$, where\n$\\hat{\\theta}_{new}(\\epsilon) \\in arg\\min_{ \\theta} \\hat{L}(z_j;\\theta, \\epsilon) = R(\\theta) + \\epsilon L(z_j, \\theta).$ (5)\nWhen $\\epsilon \\approx 0$, the influence function provides an elegant tool for estimating $\\Delta \\theta(\\epsilon)$ without solving (5) as\n$\\Delta \\theta(\\epsilon) \\approx -H^{-1}\\nabla_{\\theta}L(z_j, \\hat{\\theta})$ and $\\frac{d\\Delta \\theta(\\epsilon)}{d\\epsilon}|_{\\epsilon=0} = -H^{-1}\\nabla_{\\theta}L(z_j, \\hat{\\theta}),$ (6)\nwhere $H = \\nabla_{\\theta}^2R(\\hat{\\theta})$ is the Hessian matrix of $R(\\cdot)$ at $\\theta = \\hat{\\theta}$. A detailed derivation of the expression in (6) can be found in [23].\nThe key for applying the influence function to estimate $\\Delta \\theta$ is to calculate the right-hand side of (6) accurately and efficiently, which is challenging in real applications with an extremely high-dimensional model parameter $\\theta$ and a huge number of data. As one of the key contributions of this paper, we will design a novel stochastic algorithm to address this computational challenge and release the power of the influence function in real applications."}, {"title": "Method", "content": "The CVR prediction with delayed feedback problem urgently requires addressing the challenges from label reversal and new data integration over time. Although retraining the model provides a straightforward solution, the high computational cost and low retraining frequency make it impractical to meet the requirements in real applications. In this paper, we propose a novel IF-DFM paradigm that can address the challenges in a unified manner without retraining. We further propose a new stochastic algorithm to address the computational challenges in the influence function evaluation.\n3.1 IF-DFM\nOur core idea to model both label reversal and new data integration as data perturbations and the huge scale training data involved in the CVR prediction problem make the influence function a natural and elegant tool for estimating the changes of model parameters without retraining the model. Next, we present our IF-DFM paradigm in detail.\n3.1.1 Label Reversal. The delay between conversion behavior and click behavior is common in CVR prediction problems, where the label reversal may happen for some fake negative samples after the training phase. The label reversal phenomenon thus can be naturally modeled as the data perturbation. More specifically, if the label reversal happens for a training sample $z_i$, it is equivalent to perturb $z_i$ to $z_i^\\prime = (x_i, y + \\delta)$. Since the observed positive samples are with accurate labels, the perturbation $\\delta = 1$ for the CVR prediction problem. Without loss of generality, we consider the case where the label reversal happens for a training sample $z_i$. We are interested in the perturbed empirical risk minimization problem by reweighting the perturbed training sample $z_i$:\n$\\hat{\\theta}_{ \\epsilon}(\\epsilon) \\in arg\\min_{ \\theta} (L_v(\\theta) + \\epsilon L_{BCE}(z_i^\\prime, \\theta) - \\epsilon L_{BCE}(z_i, \\theta)).$ (7)\nNote that the right-hand side of (7) coincides with the retrain loss (3) if we take $\\epsilon = 1/n$. When $\\epsilon \\approx 0$ (which is true if $\\epsilon = 1/n$ and n is sufficiently large), following the derivation of influence function (e.g., see [23]), we can obtain that\n$\\frac{d \\hat{\\theta}_{ \\epsilon}}{d \\epsilon}|_{\\epsilon=0} = -[\\nabla_{\\theta}^2 L_v(\\hat{\\theta})]^{-1} [\\nabla_{\\theta} L_{BCE}(z_i^\\prime, \\hat{\\theta}) - \\nabla_{\\theta} L_{BCE}(z_i, \\hat{\\theta})],$ (8)\nwhere $\\hat{\\theta}$ is a minimizer of (1) (which is available if the Vanilla model is trained).\nTherefore, after aggregating the gradients of all label-reversed samples, we can estimate the changes of the model parameter from (8) by taking $\\epsilon = 1/n$ as\n$\\Delta \\theta_{delay} = \\frac{1}{n} \\sum_{j \\in J} -[\\nabla_{\\theta}^2 L_v(\\hat{\\theta})]^{-1} [\\nabla_{\\theta} L_{BCE}(z_j^\\prime, \\hat{\\theta}) - \\nabla_{\\theta} L_{BCE}(z_j, \\hat{\\theta})],$ (9)\nwhere $J$ is the index set of samples that clicked before $T$ and converted during the $[T, T^\\prime]$ interval (i.e., samples with label reversal).\n3.1.2 Newly Arrived Behavioral Data Integration. Conventionally, the influence function focuses on how model parameters or test sample loss change when a sample is deleted or modified. In our proposed IF-DFM paradigm, we also handle the new data integration for those behavioral data arriving during the $[T, T^\\prime]$ time interval. To achieve this goal, without loss of generality, we consider the following new perturbed loss function for a new sample $z = (x, y)$ and $0 \\leq \\epsilon < 1$:\n$\\theta_{z}(\\epsilon) \\in arg\\min_{ \\theta} ((1 - \\epsilon)L_v(\\theta) + \\epsilon L_{BCE}(z, \\theta)).$ (10)\nNote that we can recover the retrain loss for integrating the additional new sample z by taking $\\epsilon = 1/(n + 1)$.\nBy careful calculations (which can be found in Appendix A), we can find an approximation to $\\Delta_{z,\\epsilon} = \\theta_{z}(\\epsilon) - \\hat{\\theta}$ for sufficiently small $\\epsilon > 0$ as\n$\\Delta_{z,\\epsilon} \\approx \\frac{\\epsilon}{1 - \\epsilon} - [\\nabla_{\\theta}^2 L_v(\\hat{\\theta})]^{-1} \\nabla_{\\theta} L_{BCE}(z, \\hat{\\theta}).$ (11)\nTherefore, for sufficiently large n, we obtain an approximation to the change of model parameter for integrating the new data sample z as\n$\\Delta \\theta_{add} = \\theta(\\frac{1}{n+1}) - \\hat{\\theta} \\approx \\frac{1}{n} - [\\nabla_{\\theta}^2 L_v(\\hat{\\theta})]^{-1} \\nabla_{\\theta} L_{BCE}(z, \\hat{\\theta}),$ (12)\nConsidering both the label reversed data and the newly arrived data, the equation for the total parameter change can be given as\n$\\Delta \\theta_{total} = \\Delta \\theta_{delay} + \\Delta \\theta_{add}.$ (13)\nMore specifically, we need to estimate\n$\\Delta \\theta_{total} \\approx [\\nabla_{\\theta}^2 L_v(\\hat{\\theta})]^{-1} (\\frac{1}{n} \\sum_{k \\in K} \\nabla_{\\theta} L_{BCE}(z, \\hat{\\theta}) - \\frac{1}{n} \\sum_{j \\in J} [\\nabla_{\\theta} L_{BCE}(z_j^\\prime, \\hat{\\theta}) - \\nabla_{\\theta} L_{BCE}(z_j, \\hat{\\theta})]),$ (14)\nwhere J and K are the index sets for the label reversed data samples and newly arrived data samples, respectively.\nAddressing problem (14) poses significant computational challenges. When the Hessian matrix $\\nabla_{\\theta}^2 L_v(\\hat{\\theta})$ is positive definite, we can apply the conjugate gradient (CG) method to estimate $\\Delta \\theta_{total}$, where only Hessian-vector products are required. For $\\theta \\in \\mathbb{R}^p$ (where p is usually huge in applications), the CG method requires at most p iterations to calculate the right-hand side of (14) and it usually requires much fewer iterations to obtain an approximate solution if the condition number of $\\nabla_{\\theta}^2 L_v(\\hat{\\theta})$ is close to 1 [33]. However, the CG method typically requires full-batch gradient and Hessian matrix computations, making it impractical for large-scale datasets. To address the computational challenges of the CG method, an approximation of $[\\nabla_{\\theta}^2 L_v(\\hat{\\theta})]^{-1}$ via its truncated power series has been widely used to estimate $\\Delta \\theta_{total}$ [23]. However, its accuracy is often compromised. Finding a more precise and efficient solution for (14) remains a challenge. Next, we will address this challenge by designing an efficient and scalable stochastic algorithm.\n3.2 An Efficient and Scalable Method for Calculating $\\Delta \\theta_{total}$\nIn this section, we will address the computational challenges for calculating $\\Delta \\theta_{total}$. Our core idea is to compute $\\Delta \\theta_{total}$ by converting (14) into an equivalent finite-sum optimization problem. Consequently, we can apply popular scalable algorithms, such as the stochastic gradient descent [35] and its variants [10, 20, 21], to calculate $\\Delta \\theta_{total}$ efficiently. The definition of $\\Delta \\theta_{total}$ implies that it is a solution to the linear system\n$\\nabla_{\\theta}^2 L_v(\\hat{\\theta})\\Delta = b$ (15)\nwith\n$b= \\frac{1}{n} \\sum_{k \\in K} \\nabla_{\\theta} L_{BCE}(z, \\hat{\\theta}) - \\frac{1}{n} \\sum_{j \\in J} [\\nabla_{\\theta} L_{BCE}(z_j^\\prime, \\hat{\\theta}) - \\nabla_{\\theta} L_{BCE}(z_j, \\hat{\\theta})].$ (16)\nSince $\\hat{\\theta}$ is a minimizer of (1), which must satisfy the second-order necessary optimality condition [33]. In other words, the matrix $\\nabla_{\\theta}^2 L_v(\\hat{\\theta})$ is symmetric and positive semidefinite. Therefore, $\\Delta \\theta_{total}$ is a minimizer of the following convex quadratic optimization problem:\n$min_{\\Delta} F(\\Delta) := \\frac{1}{2} \\Delta^T \\nabla_{\\theta}^2 L_v(\\hat{\\theta})\\Delta - \\langle b, \\Delta \\rangle.$ (17)\nIt follows from the finite-sum structure of $L_v$ that\n$F(\\Delta) = \\frac{1}{n} \\sum_{i=1}^n f_i(\\Delta),$ (18)\nwhere\n$f_i(\\Delta) = \\frac{1}{2} \\Delta^T \\nabla_{\\theta}^2 L_{BCE}(z_i, \\hat{\\theta}) + \\langle b, \\Delta \\rangle.$ (19)\nTherefore, we have converted the calculation of $\\Delta \\theta_{total}$ equivalently to minimizing an optimization problem with a finite-sum objective function. Note that the function value and the gradient of $f_i$ can be efficiently evaluated via the built-in auto-differentiation and the Hessian vector product modules implemented by popular frameworks, such as PyTorch. Consequently, we can apply efficient and scalable optimization algorithms to calculate $\\Delta \\theta_{total}$. In particular, we choose ADAM [21] in this paper. We summarize the details in Algorithm 1.\n3.3 Discussions\nWe include some necessary discussions before we close this section. First of all, we want to compare our proposed perturbed loss function (10) to the commonly used perturbed loss in the form of (5). An important motivation for us to propose the perturbed loss function (10) is that it can fully recover the retrain loss for a newly arrived data integration by picking $\\epsilon = 1/(n + 1)$, which is not the case for (5) by choosing some particular value of $\\epsilon$. This issue has been discussed in [12], where the authors mentioned that the perturbed loss (5) can handle the newly arrived data integration by assuming the new data z matches an existing training example. Indeed, we realize that we can choose $\\epsilon = 1/n$ and multiplying $\\hat{L}(z; \\theta, \\epsilon)$ by n/(n + 1) to recover the retrain loss. Since it will derive the same approximation $\\Delta \\theta_{add}$ as in (12), we will use the more natural perturbed loss function (10) for handling newly arrived data integration.\nWe also want to discuss briefly the assumption that $\\nabla_{\\theta}^2 L_v(\\hat{\\theta})$ is invertible. As aforementioned, by the second-order necessary condition, $\\nabla_{\\theta}^2 L_v(\\hat{\\theta})$ must be symmetric and positive semidefinite [33]. If the second-order sufficient condition (SOSC) holds for $L_v$ at $\\hat{1}$, then $\\nabla_{\\theta}^2 L_v(\\hat{\\theta})$ is symmetric and positive definite, which is invertible. It is worthwhile mentioning that the SOSC is possible to hold at $\\hat{\\theta}$ even if the loss function is nonconvex. In our implementation, we add a regularization term $\\lambda/2||\\Delta||^2$ to (18) to stabilize the computation. Indeed, this regularization term will contribute to finding the minimum norm solution to (15) [11]. Other assumptions in the influence function have been discussed in [23, 37]."}, {"title": "Experiment", "content": "In this section", "questions": "n\u2022 RQ1: How does our method's performance compare to state-of-the-art methods in CVR prediction?\n\u2022 RQ2: Can our method adapt to dynamic changes in user interests over time?\n\u2022 RQ3: How efficient is our method in calculating parameter changes?\n4.1 Experimental Settings\n4.1.1 Datasets. To evaluate the effectiveness of our proposed method", "datasets": "the Criteo dataset and the Taobao User Behavior dataset. The statistics of these datasets are summarized in Table 1.\n4.1.2 Metrics. We employ three widely-used metrics [9", "42": "to evaluate CVR prediction performance:\n\u2022 AUC (Area Under the ROC Curve): It measures how well the model ranks positive versus negative samples.\n\u2022 PRAUC (Precision-Recall AUC): It assesses model performance across different precision and recall thresholds.\n\u2022 LL (Log Loss): It evaluates prediction accuracy by the logarithmic loss of probabilities. Lower LL means predictions are closer to actual labels.\nWe also report the relative improvements (RI) of these metrics. For a method f on a metric M", "as": "n$RIM = \\frac{M(f) - M(Vanilla)"}, {"comparison": "nOFFLINE methods:\n\u2022 Vanilla: This baseline model is trained solely on data with observed conversion labels", "Retrain": "It updates labels with conversions occurring before the testing phase and retrains the model", "3": "It is trained with delayed feedback loss and introduces a probabilistic model to capture conversion delay.\n\u2022 FSIW [46", "45": "It is trained with nnDF loss.\n\u2022 ULC [42", "methods": "n\u2022 Pretrain: It is trained using the Vanilla loss with historical data", "Retrain-online": "It retrained CVR model with true label information and newly arrived data.\n\u2022 FNC [24", "24": "Different from FNC", "9": "It uses the DDFM loss during training and fine-tunes the pretrained model by incorporating both delayed positive samples and the latest behavior data.\n\u2022 ES-DFM [44", "5": "It leverages a dynamic weight adjustment mechanism to counteract the effects of delayed feedback.\nFollowing [42", "backbones": "n\u2022 MLP: It is the basic fully connected neural networks.\n\u2022 DeepFM [15", "38": "It utilizes multi-head self-attention mechanisms to capture complex feature interactions.\n\u2022 DCNV2 [41", "128": "with ReLU as the activation function. For the AutoInt model", "1e-6": "and L2 regularization coefficients in [1e-7", "1e-4": ".", "observations": "n\u2022 Retrain consistently outperforms Vanilla", "40": "and Microsoft [29", "conclusions": "n\u2022 There is a notable degradation in the performance of both ULC and DFM methods as time progresses. Notably", "that": "n\u2022 Compared to pretraining, online CVR models can mitigate the delayed feedback problem to some extent. This can be attributed to their fine-tuning pipeline using new data and delayed conversion data.\n\u2022 IF-DFM outperforms IF-DFM-w/o-add, showing a 0.36% increase in AUC and a 0.47% improvement in PRAUC. This suggests that IF-DFM efficiently utilizes information from new data to update model parameters.\n\u2022 IF-DFM surpasses all baseline methods and nearly matches the performance of retraining. This highlights IF-DFM's capacity to seamlessly incorporate the true label information from delayed conversions, together with new data, enabling it to adapt to changes in user interests.\n4.4 Efficiency of Calculating Parameter Changes (RQ3)\nEnsuring rapid updates of model parameters is crucial for maintaining the freshness of a CVR model. Due to"}]}