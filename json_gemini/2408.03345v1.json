{"title": "ARTIFICAL INTELLIGENCE AND INHERENT MATHEMATICAL DIFFICULTY", "authors": ["WALTER DEAN", "ALBERTO NAIBO"], "abstract": "This paper explores the relationship of artificial intelligence to the task of resolving open questions in mathematics. We first present an updated version of a traditional argument that limitative results from computability and complexity theory show that proof discovery is an inherently difficult problem. We then illustrate how several recent applications of artificial intelligence- inspired methods \u2013 respectively involving automated theorem proving, SAT- solvers, and large language models \u2013 do indeed raise novel questions about the nature of mathematical proof. We also argue that the results obtained by such techniques do not tell against our basic argument. This is so because they are embodiments of brute force search and are thus capable of deciding only statements of low logical complexity.", "sections": [{"title": "1. INTRODUCTION", "content": "We write at a time when many endeavors are being called upon to reflect on the challenges brought about by recent developments in artificial intelligence. It"}, {"title": "2. THE PROOF DISCOVERY PROBLEM", "content": "Here is an initial formulation of our main thesis:\n(N1) Advances in computing theory or technology \u2013 inclusive of those currently understood to exemplify artificial intelligence \u2013 will not radically alter the following aspect of our current understanding of mathematics and its prac- tice: Settling the status of open questions is an inherently difficult problem.\nIn this section we will clarify this claim relative to what we refer to as the proof discovery problem and explain why we take this to be a central aspect of mathe- matical practice. This requires also clarifying what we mean by \"open questions\" and \"inherent difficulty\".\nBy an open question we mean a mathematical statement for which we currently lack a proof or a refutation which we take to establish that the statement in question is true or false. This notion is readily exemplified by what are often called \"sub- stantial\" or \"non-trivial\" open questions of the sort exemplified by those appearing on lists such as the Millennium Problems (Carlson et al., 2006) or those of Hilbert (1900), Landau (1912), Smale (1998), or Nash & Rassias (2016). Such collections include statements with elementary number-theoretic formulations (the existence\n(1) PROV = {\u03c6\u2208 Lr : \u0393\u251cs \u03c6}\nPROV can thus be compared to other decision problems like primality checking. This is similarly represented as a set PRIMES = {n\u2208N:n is prime} which gives rise to infinitely many individual yes/no questions of the form n \u2208 PRIMES.\nDeciding membership in PRIMES is a task we typically perform using a primality algorithm e.g. trial division or the sieve of Eratosthenes. By applying such an"}, {"title": "3. THE BASIC ARGUMENT", "content": "The story of artificial intelligence is often presented as beginning in the late 1950s with the work of figures such as Newell & Simon, Wang, Davis, and Putnam which we will discuss in the next section. Already at this time, the prospects for applying computing technology to proof discovery in mathematics were widely discussed. It was in the context of these developments that the optimistic predictions illustrated by the second and third quotes in the epigraph began to be announced.\nProgress was slow throughout the 1970s, during which the phenomenon of NP- completeness was discovered. This is now regarded as a characterization of an intractable (or inherently difficult) problem \u2013 a concept which had come into greater focus during the 1960s along with the availability of digital computers and the desire to apply them to problems of practical import. This class includes many classic examples about planning and search which originated in artificial intelligence. It was within this context that the phrase \"combinatorial explosion\" was coined by Lighthill (1973) in the course of presenting a form of the argument \u2013 which was then formulated more incisively by Rabin (1974) we are about to consider.\nThese observations contributed to the first of the so-called \"AI winters\". We are evidently living in the midst of a subsequent summer. Nonetheless, our con- tention is that the following updated form of the Lighthill-Rabin argument remains relevant for the prospects of artificial intelligence in mathematics:\n(P1) i) Proof discovery is a central goal of mathematical practice.\nii) The difficulty of proof discovery is accurately measured by the classi- fication of the decision problem PROVs with respect to the hierarchies of computability theory and computational complexity theory.\n(P2) For a wide range of relevant choices of \u0393 and Es, the problem PROV\u251cs is of high computational complexity in the sense of (P1.ii).\n(P3) If a problem is of high computational complexity in the sense of (P2), then it is inherently difficult (or intractible) to decide arbitrary instances of it using computing hardware which we can construct and apply in practice.\nBy combining P1, P2, and P3 we reach a restatement of our original thesis:"}, {"title": "3.1. Considerations from computability theory.", "content": "An initial observation un- derlying (P2) is that for the most evident choices of \u0393and \u251cs, the decision problem PROV is formally undecidable. This is so because of familiar considerations sur- rounding G\u00f6del's First Incompleteness Theorem and Church and Turing's negative solution to the original Enstscheindungsproblem for first-order logic. But it will still be useful to collect together several related extensions as follows:\nTheorem 1. Suppose that a) Es is a computably enumerable derivability relation which extends that of classical first-order logic [FOL] and b) \u0393 is a consistent, computably axiomatizable theory that interprets Q (i.e. Robinson arithmetic) and which is additionally \u2211\u2081-sound relative to such an interpretation. Then:\ni) \u0393 is incomplete relative to the definition of derivability \u251cs. In particular, there will exist Lr-sentences y such that \u0393\u251cs \u00a2 and \u0393\u251cs \u00ab6. Furthermore, it is possible to find such y which are provably equivalent I-statements in the language La of first-order arithmetic.\nii) PROV\u251cs is not \u25b3\u2081-definable and thus formally undecidable as a decision problem.\niii) PROVE\u251cs is El-complete relative to many-one reductions.\nFor the sort of consensus choices for I and Es for formalizing core mathematics envisioned in \u00a72, conditions a) - b) will typically satisfied in a paradigmatic man- ner. It thus follows that for a wide range of relevant mathematical theories and notions of derivability, the proof discovery problem is as hard as its metamathe- matical definition allows in the sense measured by the arithmetical hierarchy. This can be further glossed as follows:\n(P2.1) Conditions a) and b) are sufficient to ensure that Provf is in the class of problems which can be defined as a Ei-formula of the language La of\nPROV = {[4] \u2208N :\u2203xProof(x,\u0393\u03c6\u00ac)}\n(P2.2) On the other hand, part ii) of Theorem 1 reports that this classification can- not be improved to Al-definability - i.e. the prior classification is optimal with respect to the arithmetical hierarchy.\n(P2.3) If we consider the set A = {[\u03c6\u00ac : \u03c6 \u20ac PROV} \u2286 N, then every other E-definable set B C N is definable from A as a parameter in the form B = {n : \u03c8(n, A)} where \u03c8(x, X) is a \u25b3\u2081-formula.\n(P2.1') PROV is a computably enumerable (or semi-decidable) set i.e. there exists a Turing machine M(x) such that if \u0393\u251cs 4, then M(\u0393\u03c6\u00ac) will eventually halt outputting \"yes\" and fail to halt otherwise.\n(P2.2') PROV is not a computable (or decidable) set i.e. there is no Turing machine M(x) such that for all \u03c6\u2208 Lr, M(\u0393\u03c6\u00ac) halts outputing \"yes\" if \u0393 \u251c and if \u0393\u0397s 4, then M(\u03c6\u00ac) halts outputting \u201cno\u201d.\n(P2.3') The existence of a decision algorithm for PROV would imply a decision algorithm for every E-set B in the following sense: there exists a Turing computable function f(x) such that for all n\u2208 N, n\u2208 B iff f(n) is the G\u00f6del number of a Lr formula y such that \u0393\u0395\u03c2 \u03c6.\n for a suitable arithmetized proof predicate involving only bounded quanti- fiers and G\u00f6del numbering \u00af. of Lr."}, {"title": "3.2. Considerations from complexity theory.", "content": "The foregoing points are famil- iar and were appreciated early on. But the potential applications of artificial intelligence to proof discovery require us to proceed more carefully in arguing for (P3). This is so in light of at least two concerns. First, at least one of the applica- tions we will consider in \u00a74 pertains to choices of Iands which do not directly fall within the scope of Theorem 1. Second, one might also think advances in com- puting technology which will themselves be brought about by artificial intelligence will make the sub-argument (P3.1-4) obsolete."}, {"title": "3.3. On reasonable models and artificial intelligence.", "content": "Before concluding our defense of (P3) \u2013 and thus of the basic argument itself \u2013 one other caveat should be noted. When we transition from understanding \"difficulty\" from the perspective of computability theory to that of complexity theory, more care also needs to be taken in regard to the models of computation to which the (putatively) limitative theorems apply. For to read off concrete consequences about what we can and cannot prove in practice from Theorems 2 and 3 we need to restrict attention to the narrower class of reasonable models of computation in order to employ a complexity-theoretic analogue of (P3.3).\nThe notion of such a model plays a heuristic role in complexity theory similar to that played by an effective procedure in the early history of computability theory. Just as computability theorists have come to accept the equation of the class of problems decidable by effective procedures with those computable by a Turing machine (i.e. Church's Thesis), complexity theorists have come to accept a similar equation of the class of feasibly (or practically) decidable problems with those in the class P decidable in polynomial time by a deterministic Turing machine with a suitably efficient representation of inputs and outputs (i.e. the Cobham-Edmond's Thesis)."}, {"title": "4. CASE STUDIES", "content": "To reiterate, the crux of the basic argument is that the proof discovery problem in mathematics is (provably) computationally complex and thus inherently difficult. But again, this argument concerns proof discovery understood as a decision problem with infinitely many instances. On this understanding, it seems there is little room to challenge the argument on its own terms. But we would be drawn to question its relevance if the specific cases we cared about in practice ended up being significantly easier than the worst case reported by results like Theorems 1, 2, and 3. It would, for instance, be highly germane if automated techniques already had resolved a longstanding open question or appeared to be on the cusp of doing so.\nAt the time of writing, we are unaware of any instances in which the application of computing technology can be reasonably credited with resolving a high profile open question of the sort described in \u00a72. But there been several instances of lower profile results obtained in part or whole by the use of artificial intelligence-related methods. The best known examples to date have been obtained via traditional automated theorem proving techniques. But there has also been a recent success employing SAT-solvers and large language models in a manner reminiscent of ap- plications which are currently fueling public debates."}, {"title": "4.1. Automated theorem proving and the Robbins Problem.", "content": "Artificial in- telligence and automated theorem proving have been connected since their begin- nings. For instance at the 1956 conference where the expression \"artificial intelli- gence\" was coined, the only functioning system presented was the Logic Theorist of Newell, Shaw, and Simon (1957). This was a program for proving statements of propositional logic in a manner intended to mimic how humans approached logic problems. But as this method was incomplete, Newell, Shaw and Simon them- selves described it as heuristic and contrasted it with algorithmic methods which are complete but need to return an output in a feasible number of steps.\nThis situation was further addressed by Wang (1960) who developed a sound and complete method for propositional derivability but abandoned the goal of model- ing human reasoning. Wang's approach was based on an operationalization of Gentzen's sequent in which the rules are both cut free and invertible. This makes it possible to systematically perform proof search by working backwards from the main connective of the statement to be proved. Wang's method set the stage for the formulation of the Davis-Putnam algorithm which serves as the basis of con- temporary SAT-solvers of the sort discussed in \u00a74.2. But this method is itself based on the yet more fundamental rule of resolution which also remains at the core of most automated theorem proving systems for first-order logic.\nRecall first that a propositional formula o can be efficiently transformed into a logically equivalent formula 1 in conjunctive normal form i.e. so that 41 is a conjunction of clauses each comprised of a disjunction of literals which are themselves either atoms por negated atoms p. If 1 contains distinct clauses of the respective forms Vp and pVX, then any valuation which makes 41 true must also make & V X true. This allows us to obtain a simpler formula 42 which is still equivalent to in terms of satisfiability by removing all occurrences of p from 41. This idea is captured by the resolution rule:\n(2)\n\u03c6 V p \u00acp V\u03c8\n\u03c6\u03bd \u03c8\nR\nAs resolution-based theorem provers operate solely via this rule, they are sim- pler to implement than methods which have rules involving multiple propositional"}, {"title": "4.2. SAT solvers and finite combinatorics.", "content": "Recall that SAT denotes the satis- fiability problem for propositional logic - i.e. that of checking if a formula is true in some row of its truth table. A SAT-solver is a decision algorithm satisfying:\ni) Totality: \u03b1(\u03c6) returns output 1 - i.e. \"satisfiable\" or 0 - i.e. \"unsatisfiable\" - for all propositional formulas 4.\nii) Soundness: If \u03b1(\u03c6) = 1, then y\u2208 SAT.\niii) Completeness: If \u03b1(\u03c6) = 0, then \u00a2 \u00a3 SAT \u2013 i.e. \u03c6\u2208 SAT.\nRecall also that if is unsatisfiable i.e. false in all rows of its truth table then is a tautology and thus provable from no premises in the propositional calculus (by the completeness theorem). As such, an algorithm a satisfying (4i-iii) also serves as a decision method for PROVOL.\nAs we have discussed, SAT is NP-complete. Presuming that P \u2260 NP, there thus cannot exist an algorithm satisfying (4i-iii) implementable by a reasonable model of computation which always returns an output in time polynomial in the number of propositional variables in 4. And in fact no procedure with better than exponential worst case running time in the general case is known to exist. It is thus striking that a number of algorithms which perform well on large classes of SAT instances are currently being investigated.\n(4)\ni) cap(8) \u2265 512\nii) 2.2194\u2033 < cap(n)"}, {"title": "4.3. Large language models and the cap set problem.", "content": "It is a commonplace that a distinction should be drawn between automated theorem proving and ma- chine learning techniques. But such a classification falls short of a precise character- ization of the difference between what we will call logic-based and statistics-based methods. This in turn complicates systematically addressing the topical question: How might the latter class novelly contribute to proof discovery beyond the former?\nIn approaching this we may also distinguish between what might be called sys- tematic and non-systematic applications of statistic-based methods to proof discov- ery. The former seek to find applications of machine learning within the framework of automated theorem proving surveyed in \u00a74.1. This is exemplified by attempts to refine the so-called method of hammers - i.e. general purpose techniques to fill in gaps in proofs by consulting libraries of previously formalized theorems in a manner reminiscent of expert systems (see, e.g., Blanchette et al., 2016).\n(6)\n Does there exist c < 3 such that cap(n) < cn?"}, {"title": "5. CONCLUSION", "content": "The argument of \u00a73 concludes that proof discovery in mathematics is inherently difficult i.e. resistant to automation using techniques which can be carried out using computing machinery which can be constructed and and applied in practice. On the other hand, the case studies reported in \u00a74 have been repeatedly reported as breakthroughs for the application of artificial intelligence in mathematics. But as we can now see, these are also of exactly the form which one would have predicted before the fact were amenable to automated resolution. In particular, the state- ments obtained can all be formulated as statements of low logical complexity. Thus not only do we known in advance that they are amenable to brute force search, but this is in fact how the demonstrations in question proceeded.\nBrute force, is of course, also a method for which we have already ample evidence that computers outperform human mathematicians. This is aptly illustrated by traditional \"computer proofs\" which do not involve techniques directly associated with artificial intelligence. As such, our case studies also suggest that while the role of techniques like SAT-solvers and machine learning may come to play a larger role in mathematics, their influence will remain evolutionary rather than revolutionary.\nWe will now adduce two additional observations refining our prior claim that the examples of \u00a74 are indeed special cases of proof discovery:\n(C1') Brute force search is not characteristic of how longstanding open questions in mathematics have historically been resolved.\n(C2') The logical complexity of many open questions is greater than 21.\n P\u2260 NP"}]}