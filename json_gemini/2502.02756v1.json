{"title": "Adaptive Voxel-Weighted Loss Using L1 Norms in Deep Neural Networks for Detection and Segmentation of Prostate Cancer Lesions in PET/CT Images", "authors": ["Obed Korshie Dzikunu", "Shadab Ahamed", "Amirhossein Toosi", "Xiaoxiao Li", "Arman Rahmim"], "abstract": "This study proposes a new loss function for deep neural networks, L1-weighted Dice Focal Loss (L1DFL), that leverages L1 norms for adaptive weighting of voxels based on their classification difficulty, towards automated detection and segmentation of metastatic prostate cancer lesions in PET/CT scans. We obtained 380 prostate-specific membrane antigen (PSMA) [18F]DCFPyL PET/CT scans of patients diagnosed with biochemical recurrence metastatic prostate cancer. We trained two deep neural networks with 3D convolutional neural network backbone Attention U-Net and SegResNet \u2014 and concatenated the PET and CT volumes channel-wise as input. The performance of our custom loss function was evaluated against the Dice and Dice Focal Loss functions. For clinical significance, we considered a detected region of interest (ROI) as a true positive if at least the voxel with the maximum standardized uptake value falls within the ROI. We assessed the models' performance based on the number of lesions in an image, tumor volume, activity and extent of lesion spread. The L1DFL outperformed the comparative loss functions by at least 13% on the test set. In addition, the F1 scores of the Dice Loss and the Dice Focal Loss were lower than that of L1DFL by at least 6% and 34%, respectively. The Dice Focal Loss yielded more false positives, whereas the Dice Loss was more sensitive to smaller volumes and struggled", "sections": [{"title": "1. Introduction", "content": "Semantic segmentation involves mapping every pixel of an image to a class, whether an object or a background [1]. It requires both a local and contextual understanding of the image [2], making it particularly difficult since neighboring pixels are highly related; thus, information on the spatial context and the boundary's smoothness is essential in a segmentation model [3]. Particularly in medical image analysis, higher accuracy levels are required for tumor segmentation since false detections may significantly impact patient management [4]. However, medical images are fraught with an imbalance in the proportion of voxels belonging to the regions of interest (ROIs) compared to the background making a balance in precision and sensitivity in automated segmentation a challenging task.\nWhole body positron emission tomography (PET) scans of cancer patients are an example of such medical images where voxels corresponding to the foreground class are overwhelmingly outnumbered by background voxels. These images are characterized by high variability in lesion size, shape, and intensity, as well as significant heterogeneity in tracer uptake [5]. In the case of metastatic prostate cancer (mPCa) images, lesions can range from small, low-contrast regions barely distinguishable from surrounding tissues to large, high-uptake areas with well-defined boundaries, and may occupy different anatomical sites [6]. In localizing these lesions, the prostate-specific"}, {"title": null, "content": "membrane antigen (PSMA) is often targeted due to its high expression by tumor cells. However, PSMA expression is not exclusive to prostate cancer lesions; it is also found in other tissues, including salivary glands, kidneys, and the small intestine, as well as in certain non-prostatic malignancies and inflammatory processes [7]. This broad expression can lead to radiotracer uptake in non-cancerous or non-prostatic regions challenging the specificity of computer-aided detection algorithms. Thus, the challenge in artificial intelligence (AI) based lesion detection and segmentation in PET scans of metastatic prostate cancer lesions is avoiding false-positive segmentation of anatomical structures and other artifacts while maintaining accurate lesion detection.\nWith most of the automated approaches, improved sensitivity of mPCa lesions often comes at the cost of specificity, yet both extremes pose potential risks. One commonly used strategy for limiting false positive rate is standardized uptake value (SUV) thresholding, which involves defining all voxels with SUV greater than some value, typically considering the background uptake of the liver to be foreground and all other voxels as background [8]. This method may be included as part of the automated segmentation process or as a post-processing step and has been shown to reduce false positive counts [9]. Yet, its major drawback is the potential of having a reduced sensitivity for lesions that exhibit lower avidity for the radiotracer, or in patients with extensive liver metastases [10].\nLoss function design is another strategy that has received much attention and has led to an improvement in the performance of AI-based segmentation methods. The widely used loss function is the Dice Loss. It is based on the Dice Similarity Coefficient (DSC) and penalizes pixel-wise discrepancies between the predicted maps and their corresponding ground truth for each class [11]. A model trained using the Dice Loss objective maximizes DSC inherently incorporating a balance in sensitivity and specificity [12]. Nevertheless, the Dice Loss is not well-suited for handling another type of imbalance caused by a difference in the difficulty in classifying pixels [13]. Within a class, be it the minority foreground class or majority background class, some pixels might be easier to classify, with models achieving greater than 50% probability of correctly classifying such pixels [13]. However, others may be more challenging to predict, yielding lower probabilities [13] and are therefore designated hard to classify. Without a focusing strategy implemented, the Dice Loss can be easily overwhelmed by the easy-to-classify samples and may perform poorly on the harder ones [14]. Besides, it exhibits an inconsistent"}, {"title": null, "content": "performance when segmenting multiple lesions of varying sizes in an image [15].\nThese limitations have prompted the development of alternative loss functions. Distribution-based loss functions like Focal and Cross-Entropy losses are frequently used alternatives due to their dynamic focusing ability. They are often combined with the Dice Loss and its variants to form compound loss [11] since the losses based on overlap measurements are more robust for medical segmentation tasks [16]. With an additional ability to control the model's focus on detecting ROIs, these combo losses generalize well [11, 17]. The challenge, however, remains on the balance of sensitivity and specificity as these compound losses tend to lose the Dice Loss component, potentially leading to more false positive segmentation [18]. Thus, various regularizations and additional constraints are required to improve model accuracy for a medical lesion segmentation task [19].\nThis work proposes a new loss function, L1-weighted Dice Focal Loss (L1DFL), with a dynamic weighting strategy based on L1 norms of predicted probabilities and ground truth labels. Using L1 norms, the loss function considers the difficulty of each sample and the prevalence of similar samples in the dataset. In medical image segmentation tasks, datasets are often imbalanced (disproportionately higher number of background voxels than ROIs) and dominated by easy samples (voxels that are easily classified correctly); the L1 norms of these easy samples tend to approach zero. Our technique focuses on down-weighting both easy samples and those with high L1 norm counts, which are likely to represent the background. We demonstrate the efficiency of L1DFL by experiments on [18F]DCFPyL PET/CT scans of patients with biochemical recurrence metastatic prostate cancer, for which lesions have varied sizes, primarily small, with low uptake values.\nThe main contributions of this work are as follows: (i) we introduce a novel loss function, L1-weighted Dice Focal Loss (L1DFL), incorporating a dynamic weighting strategy; (ii) we evaluate the performance of L1DFL, Dice Loss, and Dice Focal Loss functions in handling false positives and false negative rates; (iii) we compare the segmentation performance of the loss functions based on different lesion scenarios: single-lesion, and multiple lesions. These scenarios are based on the number of lesions in an image; (iv) we evaluate the performance of these loss functions on different clinical metrics like molecular tumor volumes and the extent of lesion spread in the body; and (v) we assess performance using two network architectures, Attention U-Net [20] and SegResNet [21]."}, {"title": "2. Materials and Methods", "content": "2.1. Dataset\nWe analyzed 380 prostate-specific membrane antigen (PSMA) [18F]DCFPyL PET/CT scans of patients diagnosed with biochemical recurrence metastatic prostate cancer as part of an ongoing clinical trial (NCT02899312) with informed written consent obtained from the subjects. The image data collection was approved by the University of British Columbia \u2013 BC Cancer Ethics Board. The inclusion criteria for the patients were: (1) histologically proven prostate cancer with biochemical recurrence after initial curative therapy with radical prostatectomy, with a PSA > 0.4 ng/mL and an additional PSA measurement confirming an increase; and (2) histologically proven prostate cancer with biochemical recurrence after initial curative radiotherapy, with a PSA > 2 ng/mL after therapy, with five or fewer lesions identified on [18F]DCFPyL PET/CT [22].\nEach patient received an average dose of 350 MBq [18F]DCFPyL after fasting for four hours, with dose adjustments based on body weight. Imaging was conducted 120 minutes after injection using a GE Discovery 600 or 690 scanner (GE Healthcare, USA). A non-contrast-enhanced CT scan was acquired for localization and attenuation correction (120 kV, automatic mA adjustment from 30\u2013200 mA, and a noise index of 20). Following CT acquisition, a whole-body PET scan was conducted at 2\u20134 minutes per bed position, depending on the participant's size, with reconstruction performed using an ordered subset expectation maximization algorithm and point-spread function modeling. Each transaxial PET image had a matrix resolution of 192 \u00d7 192 pixels, with a physical pixel size of 3.64mm\u00b2. An expert nuclear medicine physician performed manual segmentation on all active lesions [22].\nThere were a total of 684 prostate cancer (PCa) lesions across the entire dataset with a mean active lesion volume of 6.68 \u00b1 10.20 ml. The lesions varied in uptake with the average maximum standardized uptake value (SUVmax) and mean standardized uptake value (SUVmean) being 12.65\u00b114.46 and 4.62 \u00b1 3.88, respectively.\n2.2. Ground Truth Annotation\nThe ground truth segmentations were performed by a board-certified nuclear medicine physician from the BC Cancer Research Institute. All lesions were annotated using the PET Edge tool, a semi-automated gradient-based segmentation tool, and contours refined using the 3D Brush tool. Both tools"}, {"title": null, "content": "are available in the MIM workstation (MIM software, Ohio, USA). These segmentations served as the ground truth labels for training the models.\n2.3. Data Preprocessing and Augmentation\nAfter acquiring the images, PET activity values were converted to decay-corrected standardized uptake values (SUV), and the CT intensity values (in Haunsfield units) were clipped to the range [-1000, 3000] before normalizing to a uniform range of [0, 1]. The PET images however, were left in their absolute SUV values. We resampled all images, including PET, CT and ground truth (GT) masks to an isotropic voxel spacing of [2 mm, 2 mm, 2 mm] using bilinear interpolation for the CT and PET images and nearest-neighbor interpolation for the GT masks. For augmentation, we applied random cropping and affine transformations for the training images, including translations in (-10,10) voxels in every spatial dimension, rotations of up to 15, and scaling by a factor of up to 1.1. We obtained cubic patches of dimensions 128 \u00d7 128 \u00d7 128 voxels with an 80% probability of being centered around a foreground voxel. The augmented CT and PET patches were channel-concatenated and fed as input to the networks.\n2.4. Architectures\nIn this work, we implemented and studied two convolutional neural network architectures: Attention U-Net [20] and SegResNet [21]. These networks, built on top of a 3D-CNN backbone, comprise encoder and decoder blocks. The SegResNet uses residual blocks with skip connections for feature propagation and maintaining gradient stability during training [21]. The encoder path contained blocks with the following number of layers: 1, 2, 2, and 4, allowing for increasing levels of feature extraction at different resolutions. The initial filter size was set to 16 channels, then doubled through each down-sampling step to capture progressively higher-level features. Each convolutional layer employs a ReLU activation function, and Group Normalization [23]. The decoder path, containing one layer in each block, gradually reconstructs the segmented output while leveraging skip connections to preserve spatial details from the encoder. The input and output channels were set to 2, accommodating multi-channel input images and dual-class segmented outputs.\nOn the other hand, Attention U-Net extends the U-Net architecture to include attention gates along the encoder-decoder path, allowing the network"}, {"title": null, "content": "to selectively pay attention to essential features [20]. The encoder path consisted of five layers, with each layer increasing in channel depth from 16, 32, 64, 128, to 256 channels, and each layer downsampled by a stride of 2. These attention gates guide the network in emphasizing regions that contribute significantly to the segmentation task. Each convolutional layer employs a ReLU activation function, and Batch Normalization as in the original implementation [20]. The output layer matched the input with two channels for multi-modal inputs and dual-class output, representing background and foreground classes.\n2.5. Model Training\nWe divided the dataset into training, validation, and testing sets containing 258, 65, and 57 samples, respectively. The training objective was to minimize the loss functions in the training set. We used AdamW optimizer with weight decay of 10-5 to optimize the loss functions. We adopted a cosine annealing scheduler to decay the learning rate from 2 \u00d7 10-4 to zero for 1000 epochs. The loss was first computed for each batch within an epoch and the overall loss for an epoch was calculated by taking a mean over all the batch losses. The model with the highest mean DSC in the validation phase was chosen for further evaluation of the test set. The code for the implementations is made available at: https://github.com/ObedDzik/pca_segment.git\n2.6. Loss Functions\nDice Loss (DL): The Dice Loss maximizes the overlap between the predicted segmentation and the ground truth. In this work, for a specific cubic patch of an image, the Dice Loss for a batch was computed as,\nLDice = 1 - \\frac{1}{2} \\sum_{c \\in {0,1}} \\frac{2 \\sum_{i} p_i(c) g_i(c)}{\\sum_{i} p_i(c) + \\sum_{i} g_i(c) + \\epsilon}\n(1)\nwhere pi and gi are, respectively, the predicted probability and ground truth for a given class c of the voxel i, and e is a small constant to prevent division by zero.\nFocal Loss: The Focal Loss [24] helps focus on hard-to-classify examples by down-weighting the easy ones. In this work, the Focal Loss for an image patch was computed over a batch as,"}, {"title": null, "content": "LFocal = \\frac{1}{2} \\sum_{c \\in {0,1}} \\sum_{i} \\alpha_c(1 - p_i(c))^{\\gamma}log(p_i(c))\n(2)\nwhere pi is the predicted probability for a given class c of a voxel i, \\alpha is a factor defining the balance between background and foreground classes in a binary segmentation task, and \\gamma is the focusing parameter that adjusts the rate at which easy examples are down-weighted.\nDice Focal Loss (DFL): The Dice Focal Loss [25] combines the Dice Loss and the Focal Loss forming a compound loss function:\nLDFL = LDice + LFocal\n(3)\nFor the Dice Focal Loss formulation, we set \\gamma = 2 and \\alpha = 1 in all our experiments similar to the implementation reported in [26].\nL1-weighted Dice Focal Loss (L1DFL): The L1-weighted Dice Focal Loss (L1DFL) applies a weighting strategy to the Dice Loss (DL) based on the L1 norm between the predicted probabilities and the ground truth labels and combines it with the Focal Loss (FL). The Dice Loss generally has two variants, one with squared terms in the denominator [27] and one without [12]. In L1DFL, we employ the Dice Loss with the squared denominator which was preferred over the non-squared version following its performance in [28]. We describe the mathematical formulation of the weighting strategy next.\nFirst, we compute the L1 norm, \u2206, between the predicted probabilities p and the ground truth labels g,\n||gi - pi||_1, \\text{ for } i = 1, 2, ...N\n(4)\nwhere N is the total number of samples. Next, we partition the range of L1 norm values A into bins of a consistent nominal bin width of \u0393. Each bin B is defined by its center Bk:\nBk = \u0393 \\cdot k, \\text{ for } k = 0, 1, 2, ...n \u2013 1\n(5)\nwhere n = [ \\frac{1}{\\Gamma} + 1] is the total number of bins. For instance, with a bin width of \u0393 = 0.1 and a total of n = 11 bins, Bk takes values at regular"}, {"title": null, "content": "intervals in the range [0,1], such that for k = 0, 1, 2, . . ., 10, bin centers (Bk) = [0, 0.1, 0.2, . . ., 1.0].\nWe then calculate the count of values that fall within each bin:\nC(Bk) = \\sum_{i=1}^{N} \\delta_k (B_k, \\Delta_i)\n(6)\nwhere \u03b4\u03ba(\u0392\u03ba, \u0394\u2081) is an indicator function defined as:\n\\delta_k(B_k, \\Delta_i) = \\begin{cases} 1, & \\text{if } |B_k - \\Delta_i| < \\frac{\\Gamma}{2} \\\\ 0, & \\text{otherwise} \\end{cases}\n(7)\nTo account for potential truncation near the boundaries of [0,1], we calculate the effective bin width for each bin as:\n\\lambda_k(B_k) = \\min \\{B_k + \\frac{\\Gamma}{2}, 1\\} - \\max \\{B_k - \\frac{\\Gamma}{2}, 0\\}\n(8)\nUsing \u03bb\u03ba(Bk), the norm density, D(B), for each bin is defined as:\nD(B_k) = \\frac{C(B_k)}{\\lambda_k(B_k)}\n(9)\nThe density D(Bk) represents the concentration of samples around the bin center Bk. For Bk values close to 0, the L1 norm values (\u0394\u2081) are also close to 0, indicating easy samples where the predictions align closely with the ground truth. In contrast, bins with centers near 1 represent L1 norms closer to 1, indicating hard-to-classify samples where predictions deviate significantly from the ground truth. Thus, based on the norm density, we can evaluate how common or rare a particular prediction difficulty is, allowing the weighting to be adjusted accordingly. This adjustment ensures that less frequent and difficult samples, which often correspond to foreground samples in an imbalanced scenario receive higher weights than the easy-to-classify samples. The weight for each bin is then calculated as:\nw(B_k) = \\frac{N}{D(B_k)}\n(10)\nThese weights are applied to the numerator and the denominator of the Dice Loss to account for the imbalances caused by the variations in"}, {"title": null, "content": "L_{wDice} = 1 - \\frac{2\\sum_{i=1}^{N} w_i y_i p_i + \\epsilon}{\\sum_{i=1}^{N} w_i (y_i^2 + p_i^2) + \\epsilon}\n(11)\nwhere wi = w(Bk) if \u2206i belongs to bin Bk. If the L1 norms of the examples are uniformly distributed, the density D(Bk) will be the same for all bins, resulting in equal weights w(Bk) for all bins. In this case, the weighted Dice Loss, (LwDice), will reduce to the standard Dice Loss.\nFinally, we combine LwDice with the Focal Loss. The full expression of L1DFL thus is:\nL1DFL = L_{wDice} + L_{Focal}\n(12)\nWe illustrate the dynamic weighting strategy of L1DFL below. For a given 4x4 matrix, Figure 1 highlights how L1DFL downweights contributions from the background class and focuses on regions of classification difficulty. Specifically, the figure shows that higher weights are applied for voxels with L1 norm (\u0394) close to 1, but for voxels with L1 norms close to 0, representing that those voxels are easily classified, lower weights are applied. Thus, regions corresponding to false positives and negatives receive much attention from the model. In our experiments, we empirically selected a constant bin width, \u0393, of 0.1 and y of 2 for the focal loss component of the loss function.\n2.7. Model Evaluation\nWe assessed the performance of the loss functions on the overall test data. We made predictions on the PET/CT whole-body images using the sliding-window technique [29] with a window of dimension (128, 128, 128) for all networks. The test set predictions were resampled to the coordinates of the original ground truth masks to compute the evaluation metrics. In addition to assessing performance on the overall test set, we performed evaluations based on two different lesion scenarios, single and multiple lesion scenarios. First, we categorized the set of images (I) into two subsets: images with a single-lesion (S) and images with multiple-lesion (M). For an image x with n(G1) ground truth lesions, we defined these groups as follows:\nS = {x \\in I | n(G_i) = 1}\nM = {x \\in I | n(G_i) \\geq 2}\n10"}, {"title": null, "content": "ignated as an FP. Similarly, a false negative occurs when G\u0131,SUVmax \u2229 P\u2081 = 0. We provide a visual illustration of the definition of the detection metrics in Figure 2. The F1 score is thus computed as:\nF1 = \\frac{TP}{TP + \\frac{1}{2}(FP + FN)}\n(14)\nClinical Metrics: For each scenario, we analyzed the performance of the loss functions across different groupings of molecular tumor volume. Specifically, we evaluated the performance of the loss functions on DSC on different thresholds of total molecular tumor volume (TMTV). We computed thresholds (t) based on the inter-quartile range from 0 to the 85th percentile of the ground truth TMTV values and calculated median DSC for all lesions (l) where volume (v\u03b9 > t). Additionally, for the multiple-lesion scenario only, we assessed the loss function performance based on the spatial extent of lesion distribution, Dmax, which is measured as the maximum distance between any pair of foreground voxels in the image.\nFor a given ground truth mask, let vi denote foreground voxels, where i = 1, 2, . . ., N and N is the total number of lesion voxels. We calculated the Euclidean distance between every pair of lesion voxels, vi and vj, accounting for voxel spacing in each dimension. For voxel coordinates (xi, Yi, Zi) and (xj, Yj, zj) with spacing (Sx, Sy, sz), the distance dij is given by equation (15) below:"}, {"title": null, "content": "d_{ij} = \\sqrt{(S_x(x_i - x_j))^2 + (S_y(y_i - y_j))^2 + (S_z(z_i - z_j))^2}\n(15)\nThe lesion dissemination, Dmax, is calculated as the maximum distance among all calculated distances; Dmax = maxi,j dij. We categorized the calculated distances into inter-quartile ranges (IQR) indicating the first, second, third and fourth IQR and analyzed the performance of the loss functions on each group.\n2.7.2. Lesion-Level Analysis\nSegmentation Metrics: For lesion-level analysis, we defined the DSC based on the overlap between each predicted lesion mask and its corresponding ground truth mask. We identified which predicted lesion voxels corresponded to the ground truth voxels, especially in the scenario of multiple lesions in an image, based on a voxel-wise matching strategy. Specifically, lesions were segmented as individual connected components in both the ground truth and predicted masks using 18-connectivity to ensure spatial continuity within each identified lesion. This produced unique integer labels for each lesion. Each connected component in the predicted mask was then assessed for spatial overlap with each connected component in the ground truth mask.\nFor each pair of ground truth and predicted lesions, a match was defined if there was any voxel overlap between the components (i.e., if any voxels in a predicted lesion occupied the same spatial locations as those in a ground truth lesion). This was computed by checking if any intersecting voxels existed between the two labeled components. When an overlap was identified, the corresponding pair of ground truth and predicted lesion labels was recorded as a matched lesion pair. These matches were used to compute lesion-wise metrics, including lesion-level DSC, by comparing the voxel distributions in each matched pair of lesions. We defined the lesion-wise DSC as:\nDSC_l = \\frac{2|G_l \\cap P_l|}{|G_l| + |P_l|}\n(16)\nwhere Gl and Pl denote the ground truth and predicted masks of a specific lesion. For a given ground truth lesion with no match, G\u2081 \u2229 P\u2081| = 0 yielding a DSC of 0.\nClinical Metrics: At the lesion level, analysis was performed only on the molecular tumor volumes of the lesions. Similar to the threshold analysis"}, {"title": null, "content": "performed at the patient level, we calculated thresholds (t) based on the inter-quartile range from 0 to the 85th percentile of the ground truth MTV values (molecular volume of individual lesions) and calculated median DSC for all lesions (l) where volume (v\u03b9 > t). For each scenario, we analyzed the performance of the loss functions across different groupings of MTV.\n3. Results\n3.1. Segmentation performance across different networks\nIn this section, we present results for the segmentation performance of the three loss functions, Dice Loss (DL), Dice Focal Loss (DFL), and L1-weighted Dice Focal Loss (L1DFL) using the Attention U-Net and SegResNet architectures (Table 1). We report the average and median DSCs at the patient level, with mean values of true positive, false positive, and false negative counts on the test set and the F1 score performance. A one-tailed paired Wilcoxon signed-rank test was performed to evaluate the significance of the performance of L1DFL from those of DL and DFL separately, with corresponding p-values reported."}, {"title": "3.2. Performance in single and multiple lesion scenarios", "content": "We evaluated the performance of the loss functions in two different lesion scenarios: multiple lesions in one PET/CT volumetric image and only one lesion in the volume constituting the single lesion scenario. Figure 4 shows that the loss functions performed differently under these scenarios; a wider spread of DSC values is observed in the single lesion scenario than in the multiple scenario for both networks. Also, the DSCs beyond the 75th percentile for each loss function in the single lesion scenario were higher than those in the multiple lesion scenario, with more cases achieving DSCs greater than 0.8.\nDespite this observation, each loss function with Attention U-Net had higher median DSCs in the multiple-lesion scenario than in the single-lesion scenario (Figure 4a). Besides, in the single lesion case, all the loss functions have more lower outliers, reflecting occasional underperformance. On"}, {"title": null, "content": "the other hand, for all the loss functions, there are fewer outliers in the multiple-lesion scenario. While similar observations are made on the Seg-ResNet architecture, the median DSC of L1DFL in the single lesion scenario remained slightly higher than the median DSC in the multiple lesion case (Figure 4b)."}, {"title": null, "content": "Dice Loss generally had higher median DSC for both architectures when compared with DFL, although there were variations in performance between lesion scenarios and architectures. In a single lesion scenario using the Attention U-Net architecture, for example, DL demonstrated more consistent performance as evidenced by an IQR of 0.33 compared to DFL with an IQR of 0.45. However, on SegResNet, DL's performance became highly incoherent, with a wider IQR of 0.72 compared to the DFL's narrower IQR of 0.37.\nIn the case of multiple lesions, while both loss functions showed similar IQRs of 0.26 with SegResNet, on Attention U-Net, however, the DSC values from DL are more spread out with lower values in the lower quartile range"}, {"title": null, "content": "compared to DFL and L1DFL. Thus, Dice Loss may not be consistent in some scenarios and architectures, particularly where the cases are more complex.\nIn contrast, L1DFL outperformed DL and DFL in both lesion scenarios on the Attention U-Net. Its median DSCs on the multiple and single lesions were 0.67 and 0.65, respectively. These values are at least 11% higher than the median DSCs of DL in both cases. Similarly, on SegResNet in the single lesion case, L1DFL achieved a median DSC of 0.69, while DL and DFL had 0.56 and 0.55, respectively. However, in the multiple lesion scenario, Dice Loss slightly outperformed L1DFL by 4%, although they both had similar IQR.\n3.3. Performance based on lesion molecular volume\nFor each lesion scenario, we evaluated the performance of the loss functions across different TMTV thresholds at both the patient and lesion levels (Figure 5). Higher DSC values were generally observed when assessing the performance at the lesion level while the patient-level DSC values tended to be slightly lower due to false-positive segmentations. Notably, the Dice and Dice Focal Losses were more susceptible to false positives, resulting in a reduction of their median DSC by at least 10% in the patient-level assessment. The results further highlight differences in the performance of the loss functions based on tumor volumes. For volumes above 5 ml, considering the single lesion scenario, even though there was a corresponding increase in lesion activity evident by increased TLA values, there was a decline in segmentation accuracy with the Dice Loss being the most impacted. Although generally, brighter and larger lesions are easier to segment [31], as tumor volume increases the proportion of the volume of occupied by the high uptake voxels decreases, potentially leading to a decline in segmentation accuracy. In contrast, for smaller lesions, the high uptake voxels represents a larger fraction of the lesion volume, resulting in higher DSCs when segmentation focuses on this voxel. Thus, the results suggest that the Dice Loss tends to focus on segmenting regions with the highest uptake values and as lesion volume increases with a corresponding reduction in the volume proportion of high-uptake voxels, segmentation performance declines.\nMoreover, the results obtained from using the SegResNet architecture highlight additional complexities that may contribute to lesion segmentation accuracy beyond size and uptake value. For example, at the patient assessment level and within the threshold range 0 \u2013 10 ml, higher TLA values were observed in the multiple lesion scenario compared to the single lesion"}, {"title": null, "content": "case due to the summed TLA values of individual lesions. Yet, higher DSC values were achieved in the single lesion scenario than the multiple lesion scenario, indicating that beyond TLA, lesion count also affects performance."}, {"title": null, "content": "Consequently, this points to the influence of other factors, such as anatomical location of lesions, proximity to organs like the bladder, and extent of lesion spread impacting segmentation accuracy. With multiple lesions in an image, the effect of these factors may be more pronounced leading to more variability in performance.\nThe Dice Loss performed better on SegResNet than on Attention U-Net, outperforming Dice Focal Loss at the patient level in both scenarios due to Dice Focal Loss' higher false positive rate. However, both loss functions showed similar trends at the lesion level. The Dice Focal Loss on the other hand yielded more accurate segmentations with the Attention U-Net outperforming the Dice Loss at both scenarios. Nevertheless L1DFL maintained stable performance across both architectures and lesion scenarios. This consistency suggests the effectiveness of L1DFL's dynamic weighting strategy, making it more robust to false positives at the patient level and achieving better overlap with the ground truth at the lesion level.\n3.4. Performance based on lesion dissemination\nTo quantify the spatial distribution of lesions, we calculated Dmax, the maximum Euclidean distance between any two lesions in the image. For the performance assessment of the loss functions based on the Dmax, we categorized the distances into the following groups: 0-9 cm (G0), 9-11 cm (G1), 11-14 cm (G2), and 14-60 cm (G3), representing the first, second, third and fourth quartile ranges, respectively. Patient-level analysis of DSC showed consistent improvement across these ranges (Figure 6). The figure also shows differences in performance across the different architectures. Generally, the Dice Loss performed better on SegResNet than on Attention U-Net but the Dice Focal Loss performed better on the latter architecture. The L1DFL on the other hand, yielded more consistent performance across the two networks, yet had a wider IQR on SegResNet than on Attention U-Net.\nOn Attention U-Net, initially, median DSC values for all loss functions ranged from 0.4 to 0.6 (G0), increasing in the third quartile to 0.6-0.8 (G2). The results with SegResNet also show a similar trend; there is a general increase in DSC values up to the third quartile. For both networks, in the last quartile (G3), representing a more expansive lesion spread, all loss functions showed a drop in their performance metrics. Specifically, on Attention U-Net, the Dice Focal Loss performed the worst in this group, and L1DFL and Dice Loss presented similar performances, with a median of 0.62. Yet, the Dice Focal Loss had a smaller interquartile range, reflecting less spread across"}, {"title": null, "content": "DSCs in that category. The median DSC of L1DFL dropped from 0.76 to 0.62 by 18.4%, and that of Dice Focal Loss dropped from 0.65 to 0.58 by 10.3%. Dice Loss also slightly declined in performance with a broader spread in IQR of its DSCs. On SegResNet, the Dice Loss had the worst performance in this group with L1DFL achieving the best segmentation accuracy.\nThe performance of the loss functions in the lower Dmax ranges (GO - G2) which characterize less lesion spread in the body further highlight network-specific variations. While the Dice Loss achieved similar high median DSC as L1DFL in these ranges with the SegResNet, it had the worst performance with Attention U-Net. Similarly, the SegResNet model trained with the Dice Focal Loss had a decline in obtaining accurate segmentations while pairing"}, {"title": null, "content": "this loss function with Attention U-Net yielded competitive results. L1DFL remained robust to these architecture-specific variations consistently outperforming the baseline models. Figure 6 also depicts a higher median total lesion activity (TLA) across the different"}]}