{"title": "A Survey on Diffusion Models for Recommender Systems", "authors": ["JIANGHAO LIN", "JIAQI LIU", "JIACHEN ZHU", "YUNJIA XI", "CHENGKAI LIU", "YANGTIAN ZHANG", "YONG YU", "WEINAN ZHANG"], "abstract": "The rapid advancement of online services has positioned recommender systems (RSs) as crucial tools for mitigating information\noverload and delivering personalized content across e-commerce, entertainment, and social media platforms. While traditional\nrecommendation techniques have made significant strides in the past decades, they still suffer from limited generalization performance\ncaused by factors like inadequate collaborative signals, weak latent representations, and noisy data. In response, diffusion models\n(DMs) have emerged as promising solutions for recommender systems due to their robust generative capabilities, solid theoretical\nfoundations, and improved training stability compared with other generative modeling techniques like variational autoencoders (VAEs)\nor generative adversarial networks (GANs). To this end, in this paper, we present the first comprehensive survey on diffusion models\nfor recommendation, and draw a bird's-eye view from the perspective of the whole pipeline in real-world recommender systems. We\nsystematically categorize existing research works into three primary domains: (1) diffusion for data engineering & encoding, focusing\non data augmentation and representation enhancement; (2) diffusion as recommender models, employing diffusion models to directly\nestimate user preferences and rank items; and (3) diffusion for content presentation, utilizing diffusion models to generate personalized\ncontent such as fashion and advertisement creatives. Our taxonomy highlights the unique strengths of diffusion models in capturing\ncomplex data distributions and generating high-quality, diverse samples that closely align with user preferences. We also summarize\nthe core characteristics of the adapting diffusion models for recommendation, and further identify key areas for future exploration,\nwhich helps establish a roadmap for researchers and practitioners seeking to advance recommender systems through the innovative\napplication of diffusion models. To further facilitate the research community of recommender systems based on diffusion models, we\nactively maintain a GitHub repository for papers and other related resources in this rising direction\u00b9.", "sections": [{"title": "1 INTRODUCTION", "content": "With the rapid development of online services, recommender systems (RSs) have become increasingly indispensable\nto mitigate information overload problem [19, 31, 85] and match users' information needs [36, 80]. They provide\npersonalized suggestions across various scenarios such as movie [35], e-commerce [112], music [118], etc. Despite\nthe different forms of recommendation tasks (e.g., sequential recommendation, top-N recommendation), the common\nobjective for recommender systems is to precisely estimate a given user's preference towards each candidate item\nbased on diverse source data (e.g., interaction data, user profile, item content), and finally arrange a ranked list of items\npresented to the user [79, 141].\nAs illustrated in Figure 1, in the past decades, we have witnessed significant progress in the research on recommender\nsystems, shifting from traditional techniques like collaborative filtering (CF) [41] to more advanced deep learning\nmethodologies [83]. However, they usually suffer from limited generalization performance on account of inadequate\ncollaborative signals [80], weak latent representations [27], noisy data scenarios [129]. Therefore, the generative\nmodels, e.g., variational autoencoders (VAEs) [57, 108] and generative adversarial networks (GANs) [7, 34, 56], turn\nout a promising solution to mitigate the above challenges for recommendation due to their generative nature and\nsolid theoretical foundation. However, these models still have their own limitations such as restricted representation\ncapability [133] and training instability [5].\nRecently, diffusion models (DMs) [42, 119] have emerged as the state-of-the-art of generative modeling, achieving\nsubstantial success in various domains including computer vision [91], audio generation [63], natural language pro-\ncessing [3], and reinforcement learning [167]. Unlike other earlier generative models like VAEs and GANs, diffusion\nmodels leverage a denoising framework to effectively reverse a multi-step noising process to generate synthetic data\nthat aligns closely with the distribution of the training data. This ensures the remarkable capabilities of diffusion models\nin capturing the multi-grained feature representations and generating high-quality samples, as well as maintaining\nenhanced training stability. As a consequence, as shown in Figure 1, an increasing range of pioneer attempts has\nbeen made to employ diffusion models for recommendation, achieving notable progress in boosting the performance\nof different canonical recommendation processes, e.g., data augmentation [135], user modeling [162], and content\npersonalization [148], etc. We summarize the three main characteristics that make diffusion models attractive in the\ncontext of recommender systems:\n(1) Distinguished generative capability. As one of the state-of-the-art generative paradigms, diffusion models are\nable to effectively capture the underlying distribution of the source data and fulfill various generative tasks to\nassist the downstream recommendation tasks, e.g., data imputation [164], user behavior simulation [87], sample\nsynthesis [151], and image creation [148].\n(2) Superior representation learning. Diffusion models are known for their remarkable abilities to learn high-\nquality, low-dimensional representations of the source data in a probabilistic generative manner [32, 150]. In the\ncontext of recommender systems, they can effectively capture the underlying latent factors and representations\nbased on multi-modal data (e.g., interaction data, complex user behaviors, and item attributes), thus making more\naccurate predictions about user preferences and generating recommendations tailored to individual tastes.\n(3) Flexible internal structure. As a general learning framework for generative modeling, the internal structures\nof diffusion models (i.e., the backbone design) are fairly flexible, and can be integrated with other deep learning\nmodels like U-Net [42] and Transformers [106]. This allows for flexible backbone designs of diffusion models to\neffectively incorporate different types of heterogeneous information (e.g.user demographics, temporal dynamics,\nand contextual cues) into the recommendation process.\nGiven the advantages of applying diffusion models to recommendation, as well as the proliferation of research in the\ncommunity, we believe that the time is right to conduct a comprehensive survey to systematically summarize the\ncurrent research progress and provide inspirations for the future exploration, in terms of the adaption of diffusion\nmodels in recommender systems.\nDiffusion models are closely related to generative modeling and self-supervised learning. There exist several related\nsurvey works that delve into the potential of generative models [21, 22, 65, 71, 76, 144, 157] or self-supervised learning\ntechniques [52, 86, 155] for recommender systems. For example, Liu et al. [86] and Yu et al. [155] conduct reviews\non the self-supervised learning (SSL) based techniques for recommendation like contrastive learning and sequence\nmodeling. Deldjoo et al. [22] centers on adversarial recommender systems, where the generative adversarial networks\n(GANs) are widely employed for security and robustness. Liang et al. [76] investigate the applications of variational\nautoencoders (VAEs) in recommender systems based on their generative Bayesian nature. There is also a range of\nsurveys [21, 65, 71, 144] focus on the generative recommendation with the assistance of large language models (LLMs),\nwhich serve as the most popular foundation models for various downstream scenarios in the past years. However,\nnone of these surveys concentrate on the applications of diffusion models for recommendation. There still lacks a\nbird's-eye view of how recommender systems can embrace diffusion models and integrate them into different parts of\nthe recommendation pipeline, which is essential in building a technical roadmap to systematically guide the research,\nas well as industrial practice, of recommender systems empowered by diffusion models.\nTo this end, in this paper, we aim to conduct a timely and comprehensive survey on the adaption of diffusion models\nto recommender systems. As depicted in Figure 3, we analyze the latest research progress and categorize the existing\nworks according to different roles that diffusion models play at different parts of the modern deep learning based\nrecommender system pipeline:\n\u2022 Diffusion for data engineering & encoding. Data engineering & encoding is generally referred to as the\nprocess of manipulating and transforming the raw data collected online into structured data or neural embeddings\nfor the downstream recommenders. As a powerful class of generative models, diffusion models have shown\nremarkable capabilities in both data augmentation and representation enhancement, both of which help improve\nthe downstream recommendation performance.\n\u2022 Diffusion as recommender model. The recommender aims to estimate a given user's preference towards each\ncandidate item, and finally arrange a ranked list of items presented to the user. According to different types of\ntasks the recommender aims to solve, we classify the diffusion-model-based (DM-based) recommenders into three\ncategories: collaborative recommendation, context-aware recommendation, and cross-domain recommendation.\n\u2022 Diffusion for content presentation. Equipped with diffusion models, we can move one step further from\npersonalized recommendation to individualized content generation. That is, every single item can obtain different\npresentation contents (e.g., creatives, thumbnails) produced by diffusion models for different users or groups,\nwhich can largely promote the user satisfaction.\nBased on the taxonomy above, we can identify burgeoning trends within this rapidly evolving landscape, and therefore\npropose feasible and instructive suggestions for the evolution of existing online recommendation platforms considering\nthe help of diffusion models. The main contributions of this paper can be summarized as follows:\n\u2022 Comprehensive and up-to-date review. To the best of our knowledge, this is the first comprehensive, up-to-\ndate and forward-looking survey on diffusion models for recommendation. Our survey highlights the suitability\nof diffusion models for recommender systems and discusses the advantages they bring about from various aspects,\nvarying from personalized recommendation to individualized content presentation.\n\u2022 Unified and structured taxonomy. We introduce a well-organized categorization to classify the existing\nresearch works into three major types according to the different roles the diffusion models play: diffusion for data\nengineering & encoding, diffusion as recommender model, and diffusion for content presentation. This taxonomy\nprovides the readers with a coherent roadmap, and helps recognize the trend in applications of diffusion models\nto recommender systems from multiple perspectives."}, {"title": "2 PRELIMINARY", "content": "Before elaborating on the details of our survey, we would like to introduce the following background and basic concepts:\n(1) the formulation and essential components of modern recommender systems, and (2) the general workflow and\ntypical variants of diffusion models with the theoretical formula derivations.\n2.1 Modern Recommender Systems\nThe core task of recommender systems is to arrange a ranked list of items $[i_k]^N_{k=1}, i_k \\in I$ for the user $u \\in U$ given a\ncertain context $c \\in C$, where $U$, $I$ and $C$ are the universal feature sets of users, items and contexts (e.g., device, time,\nseason), respectively. Note that scenarios like next item prediction are special cases for such a formulation with $N = 1$.\nWe formulate the goal of recommendation as follows:\n$[i_k]^N_1 \\leftarrow RS(u, c, I), i_k \\in I, u \\in U, c \\in C$.\n(1)\nAs shown in Figure 2(a), there are generally three key components in deep learning based recommender systems:\n\u2022 Data engineering & encoding. As the foundational pillar of modern deep learning based recommender systems,\ndata engineering & encoding consists of two primary processes: (1) data engineering and (2) data encoding.\nData engineering generally encompasses selecting, manipulating, transforming, and augmenting the raw data\ncollected online into structured data that is suitable as inputs of neural recommendation models. It does not only\ninvolve feature-level manipulation, but also includes sample-level augmentation and synthesis. The outputs of\ndata engineering possess various forms of features with different modalities, e.g., IDs, texts, images, audio, etc.\nThe data encoding process takes as input the processed structured data, and produces the corresponding neural\nembeddings for the downstream deep recommender models. Various encoders are employed depending on the\ndata modality. Typically, this process is designed as an embedding layer for one-hot encoded categorical features\nfor traditional recommender models. Features of other modalities further require different encoders for the data\nencoding process, e.g., vision models for visual features, language models for textual features.\n\u2022 Recommender Model. The deep recommender model is the core algorithmic engine of a recommender system,\ntasked with selecting or ranking the top-relevant items to satisfy users' information needs based on the structured\ndata or neural embeddings produced by the data engineering & encoding stage. Researchers develop a variety of\nneural methods to accurately estimate the user interests and behavior patterns based on various techniques like\nsequence modeling [12, 84, 88] and graph neural networks [127, 134]. According to the task types and input data\nformats, the design of deep recommender models can be generally classified into three categories: (1) collaborative\nrecommendation, (2) context-aware recommendation, and (3) cross-domain recommendation\u00b2. The collaborative\nrecommendation is generally referred to as the collaborative filtering (CF) based methods simply based on\nthe user-item co-occurrence matrix. The context-aware recommendation takes into account the contextual\ninformation surrounding a user's request to provide more precise suggestions, e.g., user behavior sequence for\nuser profiling, or knowledge graph for item content understanding. The cross-domain recommendation further\nintroduces transfer learning among multiple domains or scenarios to enhance the recommendation performance,\nwhich is particularly helpful to overcome the data sparsity issue.\n\u2022 Content presentation. After arranging the ranked list of items with the recommender model, the content\npresentation serves as the final touch that brings the recommendations to life, ensuring the recommended items\nare delivered in a manner that is engaging, accessible, and contextually relevant to the target user. Conventionally,\nit involves the strategic placement of recommended items, the manual usage of visual elements such as images,\nvideos, and text to attract user attention, and the implementation of interactive features that encourage users\nto be more willing to explore and interact with the displayed items. Nowadays, with the rapid development\nof generative models (e.g., large language models [163], diffusion models [42]), we can take one step further\nfrom personalized recommendation to individualized content generation. That is, the concrete content of each\nrecommended item (e.g., creatives, titles, thumbnails) can be dynamically edited or generated based on user\nprofiles, device types, and environmental contexts, thereby increasing the likelihood of user satisfaction and\nconversion.\n2.2 Foundations of Diffusion Models\nTypically, as illustrated in Figure 2(b), the training procedure of diffusion models includes two stages: the forward\nprocess (diffusion) and the reverse process (denoising). In the forward diffusion process, the model turns a data sample\ninto pure random noise by incrementally adding noise for multiple steps, which is usually a Markov process with each\nstep depending only on the preceding one. Then, the reverse denoising process learns to remove the noise to reconstruct\nthe original data sample, essentially reversing the forward process. In this way, the model learns to remove the noise\nadded during the diffusion process, and thereby generates samples from the same distribution as the training data.\nAccording to different designs of the forward and backward processes, the common frameworks for diffusion models"}, {"title": "2.2.1 Denoising Diffusion Probabilistic Models (DDPMs)", "content": "Denoising diffusion probabilistic models (DDPMs) are built\nupon a well-defined probabilistic process with dual Markov chains that consist of two parts: (1) the forward diffusion\nprocess that gradually transforms the data into pure noise with pre-determined noise (e.g., Gaussian noise), and (2) the\nreverse denoising process that aims to recover the original data via deep neural networks.\nForward Diffusion Process. Assume that there is an initial clean data $x_0 \\sim q(x_0)$ sampled from a given data\ndistribution $q(x)$. The ensuing forward diffusion process adulterates the initial data $x_0$ by incrementally superimposing\nGaussian noise, ultimately aiming to progress towards convergence with the standard Gaussian distribution (i.e., pure\nnoise). During the forward process with maximum steps up to $K$, we will materialize a sequence of distributed latent\ndata $[x_1, x_2,...,x_K]$, which can be formulated as a Markov chain transforming from $x_{k-1}$ to $x_k$ with a diffusion\ntransition kernel:\n$q(x_k|x_{k-1}) = N(x_k; \\sqrt{1 - \\beta_k}x_{k-1}, \\beta_kI), \\forall k = 1, ..., K,$\n(2)\nwhere $\\beta_k \\in (0, 1)$ serves as a variance schedule to control the step size, $I$ is the identity matrix with the same dimension\nas the input data $x_{k-1}$, and $N(x; \\mu, \\sigma)$ is a Gaussian distribution of $x$ with the mean $\\mu$ and the standard deviation $\\sigma$.\nAccording to the property of the Gaussian kernel, we can get $x_k$ directly from $x_0$ by applying a series of transition\nkernels of Eq. 2:\n$q(x_k|x_0) = \\prod^k_{t=1} q(x_t|x_{t-1})$\n$= N(x_k; \\sqrt{\\bar{\\alpha}_k}x_0, \\sqrt{1 - \\bar{\\alpha}_k}I)$,\n(3)\nwhere $\\alpha_k = 1 - \\beta_k$, and $\\bar{\\alpha}_k = \\prod^K_{K=1} \\alpha_i$. Hence, we have:\n$x_K = \\sqrt{\\bar{\\alpha}_K}x + \\sqrt{1 - \\bar{\\alpha}_K}e,$\n(4)\nwhere $e \\sim N(0, I)$ is the Gaussian noise. Specifically, it is designed $\\bar{\\alpha}_k \\approx 0$ so that\n$q(x_K|x_0) = \\int q(x_K|x_0)q(x_0)dx_0 \\approx N(x_K; 0, 1)$.\n(5)\nThat is, the reverse denoising process can start with any Gaussian noise. To sum up, the forward diffusion process\ngradually injects noise into the initial data $x_0$ until it nearly aligns with the standard Gaussian distribution.\nReverse Denoising Process. During the reverse denoising process, a series of Markov chain based transformations\nis employed until the original data $x_0$ is reconstructed. To be specific, the series of reverse Markov chains should begin\nwith a distribution $p(x_K) = N(x_K; 0, I)$. Then, we maintain a learnable Gaussian transition kernel $p_{\\theta}(x_{k-1}|x_k)$ to\ngenerate $p_{\\theta}(x_0)$:\n$P_{\\theta}(x_{k-1}|x_k) = N(x_{k-1}; \\mu_{\\theta}(x_k, k), \\sigma_{\\theta}(x_k, k)I),$\n(6)\nwhere the mean $\\mu_{\\theta}(\\cdot)$ and variance $\\sigma_{\\theta}(\\cdot)$ are parameterized by $\\theta$. The model aims to learn the data distribution via the\nmodel distribution $p_{\\theta}(x_0)$ during the reverse denoising process.\nTraining. In order to approximate the ground-truth data distribution $q(x_0)$, DDPM is trained to minimize the\nvariational upper bound on the negative log-likelihood (NLL):"}, {"title": "2.2.2 Score-based Generative Models (SGMs)", "content": "Score-based generative models (SGMs) [119] further generalize DDPM's\ndiscrete diffusion processes to a continuous framework based on stochastic differential equations (SDEs). For clarity,\nhere we adopt the notation $t \\in [0, T]$ for SGMs instead of the step size $k = 1, ..., K$ in DDPMs. Consequently, the\nsequence $x_0, ..., x_K$ is replaced with a continuous function $x(t)$.\nForward Diffusion Process. The continuous diffusion process can be formulated based on SDEs, consisting of a\nmean shift and a Brownian motion (i.e., standard Wiener process) as follows:\n$dx = f(x, t)dt + g(t)dw, t \\in [0, T]$,\n(13)\nwhere $f(\\cdot, t)$ denotes the drift coefficient for the stochastic continuous process $x(t)$, and $g(\\cdot)$ is the diffusion coefficient\ninterwined with the Brownian motion $w$.\nSimilar to DDPMs, $x_0$ and $x_T$ are sampled from the clean distribution $p_0 = N(x_0; 0, I)$ and the standard Gaussian\ndistribution $p_T = N(x_T; 0, I)$, respectively. The generalized continuous version of DDPM, also known as Variance\nPreserving SDE (VP-SDE), can be written as:\n$dx = -\\frac{1}{2}\\beta(t)xdt + \\sqrt{\\beta(t)}dw$.\n(14)\nReverse Denoising Process. We can synthesize the new sample from the known prior distribution $p_T$ by solving\nthe reverse-time SDE:\n$dx = [f(x, t) - g^2(t)\\nabla_x log p_t(x)] dt + g(t)dw,$\n(15)\nwhere $w$ is the reverse Brownian motion [125], $p_t(x)$ is the probability density of $x(t)$, and $s(x) = x log p_t(x)$ is called\nthe score function of $p_t(x)$. In practice, we would maintain a parameterized time-dependent neural network $s_\\theta(x, t)$ to\nestimate the score function, which can be optimized by minimizing:\n$L = E_{t,x_0,x_t} [\\lambda(t)||s_{\\theta}(x_t, t) - \\nabla_{x_t} log p(x_t|x_0)||^2]$,\n(16)\nwhere $\\lambda(t)$ is the weighting function, and $x_0$ is sampled from the clean distribution $p_0$. In this way, we avoid the direct\nestimation of the impractical score function by calculating the transition probability which adheres to a Gaussian\ndistribution throughout the forward diffusion process [119].\nUpon finishing the training process, we can generate samples based on various techniques like the Euler-Maruyama\n(EM) [99], Prediction-Correction (PC), or Probability Flow ODE method [119]."}, {"title": "2.2.3 Diffusion Model Guidance", "content": "In the previous sections, we have introduced the DDPMs and SGMs from an un-\nconditional perspective, where they generate the data samples based on the learned distribution of the source data\nwithout any explicit guidance or conditions. However, the ability to control the generation process by passing explicit\nguidance or conditions is an important characteristic of generative models. The diffusion models are able to generate\nthe data samples not only from an unconditional distribution $p_0$, but also from a conditional distribution $p_\\theta(x|c)$ given\na condition $c$. The conditioning signals can have a variety of modalities, ranging from class labels to features (e.g., text\nembeddings) related to the input data $x$ [109]. More specifically, there are various sampling algorithms designed for\nconditional generation [149], e.g., label-based guidance [23], label-free guidance [43], text-based conditions [33, 61],\ngraph-based conditions [113], etc.\nClassically, the sampling under the conditions of labels and classifiers involves using gradient guidance at each step,\ntypically requiring an additional differential classifier $p_\\theta(c|x)$ (e.g., U-Net [111] and Transformer [123]) to generate\ncondition gradients for specific labels [23]. These guidance labels are flexible, and can be textual, categorical, or task-\nspecific feature embeddings [23, 46, 103, 153]. This is referred to as the classifier guidance, whose conditional reverse\nprocess can be written as:\n$P_{0,\\theta}(x_{k-1} | x_k, c) = Zp_\\theta(x_{k-1} | x_k)p_p(c | x_{k-1}),$\n(17)\nwhere $Z$ is the normalization factor.\nAlthough classifier guidance is a common and versatile approach to improve the sample quality, it heavily relies on\nthe availability of a noise-robust pre-trained classifier $p_p(c|x)$. This requirement largely depends on the existence of\nannotated data to well train the classifier network, which is impractical in many real-world data-hungry applications.\nTo this end, the classifier-free guidance is proposed. Compared to the high accuracy of the labeled conditional diffusion\nmodel, the sampling under unlabeled conditions solely relies on self-information for guidance, and is better at generating\ninnovative, creative and diverse data samples [8, 14, 28, 58]."}, {"title": "3 DIFFUSION MODELS FOR RECOMMENDATION: \u03a4\u0391\u03a7\u039f\u039dOMY", "content": "Based on the decomposition of modern recommender systems discussed in Section 2.1, we introduce the taxonomy\nframework of diffusion models for recommendation according to different roles that diffusion models play at different\nparts of the modern deep learning based recommender system pipeline: (1) diffusion for data engineering & encoding,\n(2) diffusion as recommender model, and (3) diffusion for content presentation. The overall taxonomy framework is\ndepicted in Figure 3.\n3.1 Diffusion for Data Engineering & Encoding\nData engineering and encoding encompass the sophisticated processes of refining and converting the vast array of raw\ndata gathered from online sources into structured formats or advanced neural embeddings, tailored for the efficient\nfunctioning of downstream recommendation systems. While the current recommender systems generally suffer from\nproblems like data sparsity [140] and noisy data [162], diffusion models emerge as an exceptionally potent category of\ngenerative models to mitigate such issues during the data engineering and encoding stage. They exhibit outstanding\nprowess in the dual realms of data augmentation and representation enhancement, which are pivotal in significantly\nbolstering the overall effectiveness and precision of downstream recommendation performance. Diffusion for data\naugmentation refers to the process of manipulating and augmenting the original raw training data (e.g., ID features,\nuser behavior sequences, and user-item interactions), while diffusion for feature enhancement primarily focuses on\nstrengthening and enhancing the neural embeddings (e.g., user & item embeddings, and multi-modal representations)\nduring the data encoding phase for downstream recommendation models."}, {"title": "3.1.1 Diffusion for Data Augmentation", "content": "As a powerful class of generative models, diffusion models are able to capture\nthe underlying distribution of given data and synthesize realistic samples for the downstream recommenders. By\naugmenting the original training data, diffusion models can thereby improve the recommender systems from various\nperspectives, e.g., handling sparsity, enhancing diversity, reducing noise, and improving model generalization. In the\nfollowing, we will discuss leveraging diffusion models for data augmentation according to different data modalities to\nbe generated for augmentation, i.e., sequential data augmentation, feature imputation, user-item interaction synthesis,\nand side information editing."}, {"title": "3.1.2 Diffusion for Representation Enhancement", "content": "Different from directly augmenting the raw input data during the\ndata engineering phase as introduced above, diffusion for representation enhancement generally focuses on capturing\nthe underlying distribution of raw input data and transforming it into dynamic and robust feature embeddings to\nassist the training of downstream recommendation models. As a unique instance of self-supervised learning paradigms\nwith explicit denoising process, diffusion models are capable of establishing generalized latent spaces for enhanced\nrepresentations and therefore addressing the key challenges of recommender systems, e.g., the multi-interest and\never-evolving user preference [85, 142], the multiple latent aspects of items [29, 30], and the noise and uncertainty of\ninteraction data [47, 130]. A range of related studies [40, 67, 97, 135, 154, 161, 162, 168] have been proposed in this line\nof research, each of which incorporates diffusion models for enhanced representation learning under different goals\nand scenarios. We briefly introduce these research works as follows.\nDDRM [162], DiffGT [154] and MISD [67] aim to denoise the implicit user feedback. DDRM [162] attempts to\nrobustify the user and item representations for arbitrary recommendation models. It injects controlled Gaussian noise\ninto user and item embeddings during a forward phase and then iteratively removes this noise during a reverse denoising\nphase, guided by a specialized denoising module utilizing the collaborative signals. Besides, in the inference stage,\nDDRM leverages the average embeddings of the user's historically interacted items as the starting point rather than a\npure noise vector to further promote the personalization. DiffGT [154] further considers handling the noisy implicit\nuser feedback for neural graph recommenders. The authors showcase the anisotropic nature of recommendation data\nand propose to incorporates anisotropic directional Gaussian noise to improve the diffusion process, ensuring that the\nforward noise better aligns with the observed characteristics of recommendation data. The model also integrates a graph\ntransformer architecture with a linear attention module to efficiently robustify the noisy embeddings, which is guided\nby personalized information to improve the estimation of user preferences. MISD [67], on the other hand, leverages\ndiffusion models to address the noisy feedback during multi-interest user modeling for multi-behavior sequential\nrecommendation.\nCausalDiffRec [161] employs causal diffusion models to address the out-of-distribution (OOD) data in the field of\ngraph-enhanced recommendation. It incorporates backdoor adjustment and variational inference to capture the real\nenvironmental distribution, and then uses it as prior knowledge to guide the reverse phase of the diffusion process\nfor invariant representation learning, which eliminates the impact of environmental confounders. The authors also\nprovide theoretical derivations to prove that the proposed objective of CausalDiffRec encourages the model to learn\nenvironment-invariant graph representations, achieving excellent generalization performance in recommendations\nunder distribution shifts and OOD data.\nRDRec [40] focuses on improving the review-based textual embeddings to better model the diverse and dynamic\nuser interests when facing different items. The model corrupts the user representations by adding noises to the original\nreview-based textual features of the user interaction sequence, and the perturbed user representations undergoes\ndenoising via a transformer approximator with the awareness of target item information. Consequently, the model learns\nto capture the dynamic user preferences and produce generalized user interest embeddings for final recommendation.\nMCDRec [97] tailors diffusion models to fuse the multi-modal knowledge for representation learning in multi-\nmodal recommendation. Specifically, it incorporates the pre-extracted multi-modal information as conditions for\nthe diffusion training process, aiming to fuse the conditional multi-modal knowledge into the generation of item\nrepresentations. Moreover, the multi-modal diffused representations can be further utilized to denoise and reconstruct\nthe user-item bipartite graph by computing the diffusion-aware interaction probability and filtering the occasional\ninteractions. In this way, diffusion models serve as the core bridge to mitigate the bias between the multi-modal features\nand collaborative signals, and thereby enhance the item representations for improved recommendation performance.\nDiff-MSR [135] concentrates on the cold-start problem in multi-scenario recommendation, and utilize the\ntransfer capabilities of diffusion models to enhance the representation learning of long-tail cold-start scenarios with the\nhelp of other scenarios with sufficient training data. Built upon a pretrained multi-scenario recommendation model, the\nauthors design a piece-wise variance schedule, and then train a cold-or-rich domain classifier to obtain the candidates\nfrom rich domains (if incorrectly classified) to generate high-quality and informative embeddings for cold-start domains.\nIt turns out that diffusion models are capable of capturing the commonality and distinction of various scenarios, enabling\neffective knowledge transferring among cold-start and rich domains."}, {"title": "3.1.3 Discussion", "content": "When adapting diffusion models for the data engineering & encoding stage, the diffusion models\nhave showcased various impressive characteristics, e.g., powerful and controllable generative capability, high-quality\nand diverse output, robust latent space representation, and high flexibility. Among them, we argue that the flexibility\nserves as the core characteristic, where diffusion models generally play the role of a bridge and a connector, being\ncompatible with different upstream input data types (e.g., texts, images, and user-item interactions) and different\ndownstream recommendation models (e.g., collaborative recommenders, sequential recommenders, and graph-enhanced\nrecommenders). This is attributed to the fact that diffusion models are actually a general self-supervised learning\nparadigm with the fundamental design principle of gradually transforming noise into structured data through an\niterative denoising process, which makes the diffusion model a versatile plug-in toolkit for recommender systems."}, {"title": "3.2 Diffusion as Recommender Model", "content": "The recommender model serves as the core component of the recommender system pipeline to select or rank the\ntop-relevant items to satisfy users' information needs based on the outcome of the previous data engineering & encoding\nstage. When adapting diffusion models as recommender models, the input for this stage can be structured data (e.g., user\nbehavior sequence), neural embeddings from other encoders, or a combination of both, depending on the architecture\ndesign of the diffusion-based recommender. In this section, as shown in Figure 3, we mainly focus on the input formats\nand task formulations of diffusion-based recommender models, and thereby classify related research works into three\ncategories: (1) collaborative recommendation, (2) context-aware recommendation, and (3) other applications.\nIn general, collaborative recommendation, also known as collaborative filtering, is the basic recommendation task of\nmodeling user preference primarily based on the user-item interaction records (i.e., user-item co-occurrence matrix).\nIt is simple, straightforward, yet effective to capture the overall user preferences via the user behavior history. Built\nupon the basic collaborative signals, context-aware recommendation further considers the context information to enable\nmore dynamic and more accurate user interest modelings. In this paper, the definition scope of context information is\nrelatively broad, including but not limited to circumstances (e.g., time, location, and device), user temporal dynamic\n(e.g., behavior sequences instead of a set of records), and item attributes (e.g., textual descriptions and thumbnails).\nLastly, other applications is referred to the tasks that are closely related to the recommendation scenarios but somehow\ndiffer from the aforementioned two categories in problem formulations and solution paradigms, such as cross-domain\nrecommendation, learning to ranking, and computational advertising."}, {"title": "3.2.1 Diffusion for Collaborative Recommendation", "content": "When adapted for collaborative recommendation, diffusion models\ngener"}]}