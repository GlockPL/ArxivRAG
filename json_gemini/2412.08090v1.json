{"title": "Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages", "authors": ["Ashutosh Bajpai", "Tanmoy Chakraborty"], "abstract": "The unwavering disparity in labeled resources between\nresource-rich languages and those considered low-resource\nremains a significant impediment for Large Language Mod-\nels (LLMs). Recent strides in cross-lingual in-context learn-\ning (X-ICL), mainly through semantically aligned examples\nretrieved from multilingual pre-trained transformers, have\nshown promise in mitigating this issue. However, our investi-\ngation reveals that LLMs intrinsically reward in-language se-\nmantically aligned cross-lingual instances over direct cross-\nlingual semantic alignments, with a pronounced dispar-\nity in handling time-sensitive queries in the X-ICL setup.\nSuch queries demand sound temporal reasoning ability from\nLLMs, yet the advancements have predominantly focused on\nEnglish. This study aims to bridge this gap by improving tem-\nporal reasoning capabilities in low-resource languages. To\nthis end, we introduce mTEMPREASON a temporal reason-\ning dataset aimed at the varied degrees of low-resource lan-\nguages and propose Cross-Lingual Time-Sensitive Semantic\nAlignment (CLITSSA), a novel method to improve tempo-\nral reasoning in these contexts. To facilitate this, we construct\nan extension of mTEMPREASON comprising pairs of paral-\nlel cross-language temporal queries along with their antici-\npated in-language semantic similarity scores. Our empirical\nevidence underscores the superior performance of CLITSSA\ncompared to established baselines across three languages\nRomanian, German, and French, encompassing three tempo-\nral tasks and including a diverse set of four contemporaneous\nLLMs. This marks a significant step forward in addressing\nresource disparity in the context of temporal reasoning across\nlanguages.", "sections": [{"title": "Introduction", "content": "In the evolving landscape of Large Language Models\n(LLMs), temporal reasoning requires models to comprehend\nand interpret the significant subtleties inherent in time-time,\ntime-event and event-event correlations (Chen, Wang, and\nWang 2021). Temporality is a crucial dimension of informa-\ntion that evolves through creation, maintenance, and obso-\nlescence. Enhancing LLMs with this faculty augments their\nanalytical capabilities, paving the way for addressing intri-\ncate challenges prevalent in domains sensitive to temporal\ndynamics, such as finance, healthcare, legal studies, and ar-\nchaeology. Furthermore, addressing low-resource languages\nin LLMs is crucial for computational linguistics, given their\npaucity of data and digital infrastructure (Cahyawijaya et al.\n2023; Asai et al. 2023; Adilazuarda et al. 2024). Enhanc-\ning LLMs for these languages improves not just genuine\nlinguistic inclusivity but also their application and accep-\ntance across diverse cultural landscapes. The discourse on\nenhancing temporal reasoning in LLMs has, until now, been\npredominantly focused on English. Our work seeks to alle-\nviate this disparity by propelling temporal reasoning in low-\nresource languages."}, {"title": "Cross-Lingual In-Context Prompting.", "content": "Recent advance-\nments in in-context learning (ICL), prompted by the ad-\nvent of LLMs, have shown promising results (Zhao et al.\n2021; Lin et al. 2022b; Liu et al. 2022; Zhang et al. 2022).\nThe stark contrast in annotated data availability among lan-\nguages accentuates the usage of high-resource linguistic\ncontexts for addressing tasks in low-resource languages. The\nICL approach was adapted by Winata et al. (2021) for cross-\nlingual (X-ICL) applications by randomly selecting exam-\nples from a resource-rich language to support queries in a\nlanguage with limited resources."}, {"title": "Challenges in Cross-Lingual Semantic Alignment.", "content": "Cross-lingual in-context approaches rely on the contextual\nsemantic profoundness embedded within multilingual\npre-trained encoder-only transformers, reflected through\ntheir embedding space, for retrieving semantically akin\nexamples. Nonetheless, the disparity in linguistic distribu-\ntion within the pre-training dataset, favoring resource-rich"}, {"title": "Our Proposed Method.", "content": "We start with the development\nof first-of-its-kind a comprehensive benchmark dataset,\nmTEMPREASON, to evaluate temporal reasoning for limited\nresource languages \u2013 Romanian, German, and French across\na diverse set of LLMs. Further, we endeavor to devise an\nefficacious novel cross-lingual retriever, CLITSSA (Cross-\nLingual Time-Sensitive Semantic Alignment), for handling\ntime-sensitive queries from low-resource languages, ad-\ndressing the aforementioned challenges in a cross-lingual\ncontext. To achieve this, drawing inspiration from Yamada\nand Ri (2024), we elect to apply the transfer of profound\nsemantic space knowledge within a language to a cross-\nlingual semantic space for queries influenced by temporal-\nity. Consequently, we adopt a supervised fine-tuning ap-\nproach that necessitates an additional dataset to facilitate\nthis transition. To this end, we curate an extension of the\nMTEMPREASON dataset comprising parallel sentences for\nRomanian-English, German-English, and French-English\npairs, accompanied by their anticipated similarity scores in\nthe semantic space of the low-resource language. By em-\nploying this curated dataset, the transition of the semantic\ncontext from a monolingual to a cross-lingual embedding\nsphere is attained.\nRemarkably, for temporal queries, CLITSSA outper-\nforms the arbitrary cross-lingual in-context benchmark,\ndemonstrating relative mean F1 score enhancements of\n11.41%, 30.77%, and 62.92% for Romanian, German, and\nFrench, respectively. Additionally, it evidences a significant\nimprovement in relative mean F1 score of 6.38%, 5.98%\nand 20.93% compared to the contemporary cross-lingual in-\ncontext baselines for Romanian, German, and French."}, {"title": "Our contributions are summarized below", "content": "- \n\u2022 We develop a dataset centered around temporal reason-\ning, mTEMPREASON, elusively designed for varying de-\ngrees of limited resource languages.\n\u2022 Our findings reveal that multilingual transformers ex-\nhibit superior in-language semantic similarity over cross-\nlingual similarity context for temporal queries, especially\nexplicit ones, in the X-ICL setup.\n\u2022 We introduce CLITSSA to enhance temporal reason-\ning capabilities within LLMs for low-resource lan-\nguages. Consequently, we develop an extension of\nMTEMPREASON comprised of paired cross-lingual time-\nsensitive queries with corresponding similarity scores.\nOur empirical analysis demonstrates that CLITSSA sig-\nnificantly outperforms the contemporary baselines."}, {"title": "Benchmark For Low-Resource Temporal Reasoning", "content": "In our study of temporal reasoning, the TEMPREASON\n(Tan, Ng, and Bing 2023) stands out as a recent, comprehen-\nsive resource, providing multifaceted temporality across an\nextended time frame. Therefore, we select it to develop the\nfirst multilingual, low-resource dataset for temporal reason-\ning. To this end, we employ the T5 model (Raffel et al. 2023)\nto automatically translate the dataset from English language\nto Romanian, German and French languages."}, {"title": "The mTEMPREASON Dataset", "content": "TEMPREASON encompasses tasks categorized into three\nlevels of temporal complexity, namely time-time, time-\nevent, and event-event relationships, corresponding to Lev-\nels L1, L2, and L3, respectively. The dataset's statistical in-\nformation, along with the partition into training (Train), de-\nvelopment (Dev), and test set (Test), is detailed in Table 2.\nEmploying a concise prompt prefix, \u201cTranslate the following\nsentences from English to the {Target Language},\u201d we em-\nploy the T5 model to translate this dataset into a selection of\nlanguages with varying degrees of limited resources, specifi-\ncally French, German, and Romanian. We opt for these three\nlanguages in this work as they provide varied levels of lim-\nited resources compared to English. Romanian, German, and\nFrench have 98.3%, 89.5%, and 78% fewer speakers com-\npared to English\u00b2, respectively."}, {"title": "Data Quality", "content": "The mTEMPREASON dataset was constructed by a linguist\nwho specialized in NLP3. We employed back-translation-\nbased (Miyabe and Yoshino 2015) evaluation to ensure the\nsuperior quality of the proposed dataset. A random selec-\ntion of 100 query examples was made from mTEMPREASON\nfor each of the translated languages Romanian, German,\nand French, across temporal tasks within the test dataset.\nThese queries underwent back-translation into the source\nlanguage (English) and were subsequently compared to their\noriginal counterparts in the resource-rich language (English)\nto assess fidelity and coherence. The analysis employed the\nBLEU-3 metric for quantitative evaluation. In addition, suc-\ncessful translation from the source to the target languages\nwas noted, regardless of translation quality. The translation\nsuccess rate was documented using an automated approach\nby employing a language detection library across the en-\ntire test dataset. In Table 3, the mean automated translation\nsuccess rate was recorded at 98.11 \u00b1 1.83%. Concurrently,\na mean BLEU-3 score of 50.41 was observed for assessing\nback-translation-based accuracy."}, {"title": "Problem Setting", "content": "The Time-Sensitive Question Answering (TSQA) task re-\nquires that the LLMs generate an accurate answer in re-\nsponse to a temporal query. This answer may be a tem-\nporal delineation or an event, depending on the structure\nof the query, which can include time-time, time-event, and\nevent-event scenarios. Our experiments are conducted in a\nclosed-book environment, requiring LLMs to deliver precise\nfacts without reliance on external contexts. As illustrated\nin Figure 1, to demonstrate the prompt in a cross-lingual\nin-context learning framework, a few-shot example from a\nresource-rich language, accompanied by the query in a low-\nresource language, is provided.\nIn this study, we consider the following baselines-\n\u2022 Cross-Lingual In-Context Learning (X-ICL) (Winata\net al. 2021). The model is primed with limited examples\nfrom resource-rich language serving as demonstrations,\nalong with a query in low-resource language.\n\u2022 X-InSTA (Semantic Aligner) (Tanwar et al. 2023). X-\nInSTA has advanced the X-ICL method by introducing a"}, {"title": "Method", "content": "In this section, we outline the step-by-step formulation of\ncross-lingual time-sensitive semantic alignment method."}, {"title": "Primer", "content": "Let us consider a resource-rich source dataset Dr, contain-\ning pairs of queries and answers (q,a) for each i \u2208 m, with\nm representing the total number of samples within Dr. Ad-\nditionally, let Di be a low-resource language dataset, which\nsimilarly comprises query and answer pairs (q,a) for each\nj\u2208n, where n signifies the total sample count in Di.\nWithin a conventional ICL framework, K arbitrary instances\nof question-answer pairs are selected from Dr, designated as\ncontext C for a low-resource query q from Di, with x \u2208 n.\nThe goal is to optimize the expected value of al a, given con-\ntext C and the query input as illustrated in Equation 1, where\nAl represents the vocabulary space corresponding to query\nq\u2208 Di.\n$a^{x} = \\arg \\max_{a^{l} \\in A_{l}} p(a^{l}|C, q^{x})$\nIn the case of a semantic aligner, C is constructed to maxi-\nmize the semantic alignment between query q and context\nC. Hence, we introduce eqt as a dense embedding represen-\ntation produced by a multilingual pre-trained transformer for\nquery q. Correspondingly, for each i \u2208 m, eqr represents\nthe embeddings for queries within a resource-rich dataset\nDr. Furthermore, f(s) and f(d) denote similarity and dis-\ntance functions, respectively, such that for cosine similarity,\nf(s) = 1 \u2212 f(d); a lesser distance implies greater similar-\nity. The overarching goal is to identify a set of K examples,\ndenoted as SK, where the semantic similarity surpasses that\nof other dataset examples, as shown in Equation 2.\n$S_{K} = \\{(q_{k},a_{k}) \\forall k \\in \\{1, ..., K\\},\\\\if f(s)_{q_{x},q_{k}} \\geq f(s)_{q_{x},q_{l}} \\forall z \\in m \\text{ and } z \\notin K\\}$"}, {"title": "Cross-Lingual Time-Sensitive Semantic Alignment (CLITSSA)", "content": "Objective. We introduce CLITSSA to augment the se-\nmantic similarity context of time-sensitive queries within\nthe cross-lingual embedding space. We elect to employ\nthe transfer of the comprehensive time-sensitive semantic\nknowledge from an in-language embedding space to a cross-\nlingual embedding space. For this purpose, we have em-\nbraced a supervised fine-tuning approach, making use of a\ntraining dataset comprised of sentence pairs along with their\nassociated labeled scores, quantifying the expected time-\nsensitive semantic similarity among pairs of queries. The ob-\njective is to achieve an effective cross-lingual time-sensitive\ncontextual alignment of temporal queries for LLMs, thus\nboosting in-context performance.\nTraining Dataset. A training dataset Dt is constructed\ncomprising pairs of sentences alongside their asso-\nciated similarity scores. Specifically, Dt consists of\n(qu, qv|f(s)u,v), where qu denotes a low-resource query\nderived from D\u2081 with u \u2208 n, q indicates a query from\na resource-rich dataset Dr with v \u2208 m, and f(s)u,v rep-\nresents the similarity score between these queries within a\nlow-resource monolingual embedding space.\nHere, we present a systematic approach to construct\nDt. Initially, we delineate D', a transformed resource-rich\ndataset in a low-resource language using translation. Sub-\nsequently, we determine the temporal semantic alignment\nscores f(s) among the queries in Di and D'r. The utiliza-\ntion of all example pairs in the fine-tuning procedure incurs\nquadratic complexity in terms of |Dt|, rendering it resource-\nintensive. Drawing inspiration from Rubin, Herzig, and Be-\nrant (2022), this issue is addressed by selecting the top-\nh analogous examples from D'r for each query in Di. To\ncounteract training data bias due to high similarity scores,\nwe randomly select w examples from the remaining dataset\nto capture the whole similarity distribution. Consequently,\nfor every query qu\u2208 Di, the resultant set Su comprises\n(h + w) sentence pairs, each accompanied by their temporal\nsemantic similarity scores as postulated in Equation 3.\n$S_{u} =\\{(q_{u}, q_{1}|f(s)_{u,1}),..., (q_{u}, q_{h}|f(s)_{u,h}), \\\\(q_{u}, q_{h+1}|f(s)_{u,h+1}),..., (q_{u}, q_{h+w}|f(s)_{u,h+w})\\}$"}, {"title": "Fine-tuning the Retriever.", "content": "CoSENT (Cosine Sentence)\nloss is employed for the fine-tuning of sentence pairs\nalong with similarity scores as labels, utilizing multilingual\nSentence-BERT as base retriever. CoSENT loss generates a\nmore robust training signal for optimizing the cosine value\nthan the traditional cosine similarity loss function. This loss\nfunction is shown in Equation 4.\n$L = log(1 + exp(f(s)^{+}(q_{a},q_{b}) - f(s)^{-}(q_{x},q_{z})+exp...))$"}, {"title": "Experimental Results And Analysis", "content": "Primarily, we employ LLaMA3-8B (AI@Meta 2024) for\nall experimental works. A three-shot ICL approach is used\nthroughout the experimental setting, demonstrating superior\noutcomes compared to both one-shot and two-shot config-\nurations. The value of h and w is set empirically at 30\nand 10, respectively. To fine-tune the CLITSSA retriever\nmodel, the 'distiluse-base-multilingual-cased-v1' serves as\nthe foundational model. This method is systematically ap-\nplied to each low-resource language across temporal tasks \u2013\nL1, L2 and L3, to ensure optimum performance. Addition-\nally, an integrated CLITSSA retriever is fine-tuned across\nlanguages and temporal tasks. The Train and Dev datasets\nfrom mTEMPREASON are used to construct the parallel cor-\npus to fine-tune the CLITSSA retriever, with a separate\nheld-out test set employed to benchmark all outcomes. We\nuse word level F1 scores and exact match (EM) standards\nto quantify the LLM's responses. Please refer to the techni-\ncal appendix for ablations on few-shots, parameters h & w,\nalong with hyperparameters in detail."}, {"title": "CLITSSA Advancements Over Precedence", "content": "The comprehensive comparison of CLITSSA with baselines\nhighlights the effectiveness of incorporating cross-lingual\ntime-sensitive semantic alignment compared to a conven-\ntional semantic aligner (X-InSTA), as evidenced in Table\n4 across a variety of low-resource languages and temporal\ntasks. The mean values of metrics were compared across\nthree iterations by varying the model's parameter top-p (1.0,\n0.8, 0.6). The parameter indicates the cumulative probability\nthreshold for token selection. Notably, CLITSSA achieves\na mean increase of 5.32, 1.62, and 1.43 points in the F1-\nscore for French, German, and Romanian, respectively, with\na p-value of 0.05. Specifically, the most significant improve-\nments in F1-score\u201410.53, 3.31, and 2.13 points for tasks\nL1, L2, and L3, respectively are observed in the French set-\nting. A similar enhancement is discernible concerning the\nEM metric. Moreover, the overall analysis does not yield a\ndefinitive conclusion for an integrated CLITSSA retriever"}, {"title": "Robustness Across LLMS", "content": "The assessment of CLITSSA across a variety of dis-\ntinct, contemporary LLMs namely, an English-dominant\ninstruction-tuned model, Vicuna (Zheng et al. 2023), a\nmodel fluent in French and German, Mistral (Jiang et al.\n2023), and a cross-lingual specialized LLM, Bloomz (Muen-\nnighoff et al. 2023), demonstrates the robustness of the\nmethod. This evaluation highlights the versatility and ef-\nfectiveness of CLITSSA in engaging with and analyzing\nlinguistic data across different languages and model archi-\ntectures. The findings, as detailed in Table 9, reveal that\nCLITSSA surpasses the baseline by margins of 9.68, 2.33,\nand 0.58 points in mean F1-score for L1, L2, and L3, respec-\ntively, across LLMs.\nTo further substantiate the statistical significance of find-\nings, a comparison is drawn through a box plot analysis of\nthe F1-scores under two scenarios: firstly, by plotting F1-\nscores across LLMs and temporal tasks with a focus on the\nFrench language and secondly, through a box plot that con-\ntrasts F1-scores across various languages and temporal tasks\ncentered around a specific LLM, namely LLaMA3-8B. Fig-\nure 2 shows that CLITSSA notably extends the upper quar-\ntile by 10.01 and 5.26 points in terms of F1-score, with a\nmean increase of 4.20 and 2.79 points in the F1 scores,\nacross these scenarios, respectively. Additionally, embed-\nding space evolution under CLITSSA, presented in techni-\ncal appendix, further elucidates the noted enhancement."}, {"title": "Cross-Task CLITSSA Performance", "content": "Here, we evaluate the CLITSSA retriever's generalization\nacross temporal tasks to see if semantic alignment, sensitive\nto temporal variation achieved in one task, facilitates the res-\nsolution of another temporal task without necessitating a re-\nfine-tuning. The CLITSSA model, once fine-tuned on a spe-\ncific temporal task, is assessed on two other temporal tasks,\ni.e., the retriever optimized on the L1 task is employed to\nretrieve time-sensitive semantic examples for the L2 and L3\ntasks. Figure 3 presents the outcomes of this investigation.\nNote that tasks L1, L2, and L3 are sequentially arranged in\norder of temporal complexity, with L3 being the most in-\ntricate. The findings reveal that the temporal alignment ac-\nquired through the lower-level temporal task (L1) can signif-\nicantly enhance the relative F1-score of the more complex\ntasks L2 and L3 by 13.5% and 14.0%, respectively. How-\never, the reverse scenario is inapplicable. Moreover, more\ncomplex tasks, L2 and L3, can exchange learning, thereby\nimproving their F1-score relatively by 27.1% and 13.6%, re-\nspectively. French is employed as the low-resource language\nin this study. The results corroborate that fine-tuning the\nCLITSSA with a low-level temporal task (L1) could serve\nas a superior alternative to any semantic-based example re-\ntriever across temporal tasks."}, {"title": "Cross-Linguality vs. Monolinguality", "content": "The complexity of the prompt increases with the incorpo-\nration of multiple languages, which detrimentally impacts\nthe performance of ICL in cross-lingual contexts when con-\ntrasted with monolingual scenarios. This experiment delin-\neates the CLITSSA's effectiveness in notably diminishing\nthis discrepancy. As shown in Figure 4, CLiTSSA amelio-\nrates the performance differential between the French mono-\nlingual environment and cross-lingual context by 10.53,\n3.31, and 2.13 absolute points in terms of F1-score for the\nL1, L2, and L3 tasks, respectively, thereby comparing the\nresults to those observed in a monolingual context. Con-\ntrastingly, the English monolingual scenario exhibits a sig-\nnificant divergence from its French counterpart for L1 and\nL2 tasks, underscoring the imperative for speedy enhance-\nments to bolster performance in monolingual contexts for\nlanguages with limited resources."}, {"title": "Error Analysis", "content": "Table 6 shows a couple of instances underscoring the chal-\nlenges of semantic alignment. Initially, the heightened time-\nsensitive alignment offered by our model does not rectify\nthe inaccuracies in the foundational knowledge of the un-\nderlying LLM. The first example elucidates that the fac-\ntual inaccuracies inherent in the LLaMA3-8B model within\na resource-rich linguistic context (i.e., English monolin-\ngual, Enm) persist despite the application of CLITSSA\nin a French cross-lingual setting (Frc). Additionally, our\nproposed methodology is contingent on the semantic con-\ntext within the monolingual embedding space, aligning the\ncross-lingual space accordingly. Consequently, inaccura-\ncies in expected responses may propagate from the mono-\nlingual to the cross-lingual space notwithstanding the en-\nhanced query alignment. A subsequent example illustrates\nthis phenomenon in the contexts of French monolingual\n(Frm) and French cross-lingual scenarios. Furthermore,\nnotwithstanding the semantic alignment ingrained in cross-\nlingual queries, the implicit aspect of temporality persis-\ntently presents a challenge, as observed for the L3 task."}, {"title": "Related Works", "content": "In NLP, significant foundational efforts in temporal reason-\ning encompass the creation of TimeBank (Pustejovsky et al.\n2003), TempEval (Verhagen et al. 2010), and Time-stamped\nLanguage Models (Rajaby Faghihi and Kordjamshidi 2021),\neach contributing significantly to the understanding and pro-\ncessing temporal data. Concurrently, the evolution of knowl-\nedge graphs (KGs) has accentuated the importance of tem-\nporal relations therein, catalyzing the emergence of Tem-\nporal Knowledge Graph Completion (TKGC) as a distinct\narea of study. This progression has given rise to notewor-\nthy question-answering datasets predicated on TKG, in-\ncluding TEQUILA (Jia et al. 2018), TimeQuestions (Jia\net al. 2021), and CronQuestions (Saxena, Chakrabarti, and\nTalukdar 2021). The widespread use of language models\nin the public sphere further underscores the necessity for\nboth temporal accuracy and consistency within generated re-\nsponses. In response to this demand, several time-sensitive\nQA datasets, such as TEMPLAMA (Dhingra et al. 2022) and\nTEMPREASON (Tan, Ng, and Bing 2023), have been intro-\nduced to assess and benchmark the temporal reasoning ca-\npabilities inherent in LLMs. Among these, TEMPREASON\nstands out as a comprehensive benchmark for temporal rea-\nsoning, spanning a broad spectrum of temporal periods and\nincorporating three levels of temporal relations.\nFurthermore, most LLMs are trained on multilingual\ndatasets (Wenzek et al. 2020), a practice that was once a\nrarity given the dominance of extensive English corpora\n(Radford et al. 2019). Despite this, LLMs have proven their\nmettle in considerable languages. While there have been\nsignificant advancements in the multilingual capabilities of\nLLMs (Lin et al. 2022a; Qin et al. 2024), they still face\nsignificant challenges when dealing with low-resource lan-\nguages (Cahyawijaya, Lovenia, and Fung 2024), especially\nin task-specific contexts (Enis and Hopkins 2024). To ad-\ndress this, innovative approaches such as prompting for gen-\nerating intermediate English contexts (Huang et al. 2023),\ncross-lingual prompting (Winata et al. 2021), and Linguisti-\ncally Diverse Prompting (LDP) (Nguyen et al. 2024) have\nbeen introduced. In the cross-lingual prompting domain,\nspecific developments like semantic label-based alignment\n(Tanwar et al. 2023), query-based alignment via transla-\ntion semantic similarity (Cahyawijaya, Lovenia, and Fung\n2024), and a model-specific fine-tuned retriever (Lin, Mar-\ntins, and Sch\u00fctze 2024) have further enhanced LLMs' capa-\nbilities. Yet, the exploration of temporal reasoning within\nlow-resource languages remains scant, presenting a com-\npelling area for further research. This study proposes to pio-\nneer advancements in this under-explored domain."}, {"title": "Conclusion", "content": "In this paper, we introduced a pivotal dataset,\nMTEMPREASON, aimed at improving temporal reason-\ning assessment in low-resource languages using LLMs.\nOur analyses identified that multilingual LLMs inherently\nreward in-language time-sensitive semantic alignment over\nthe cross-lingual similarity context in the X-ICL method.\nTo overcome this, we proposed CLITSSA, a novel method\nthat enhances the retrieval of time-sensitive contextually\nrelevant examples across low-resource languages. Our\nresults demonstrated that this approach effectively improves\nLLMs' temporal reasoning in low-resource languages,\nwhich we believe will aid in promoting linguistic diversity\nand the development of more inclusive LLMs. Future en-\ndeavors may benefit from examining the alignment between\nan implicit temporal query's semantics and its implied\nsemantic space to enhance intricate L3 task performance."}, {"title": "Technical Appendix", "content": "In this section, we present a few more supplementary evi-\ndence in support of CLITSSA. Specifically, the evolution of\nembedding space under CLITSSA, extended experimental\nresults, and outlining hyperparameters.\nCross-Lingual In-Context Few-Shot Performance\nIn this experiment, we introduce an ablation concerning\nthe k-shot cross-lingual in-context X-InSTA performance\nspanning temporal tasks, specifically focusing on French\nas a low-resource language on LLaMA-3 [8B], where k \u2208\n{1, 2, 3}. The outcomes delineated in Table 7 demonstrate\nsuperior performance in a three-shot scenario with reaching\nat a saturation level. This finding led to the selection of this\nconfiguration across all experiments in this work."}, {"title": "Ablation For Parameters h and w", "content": "In this section, the emphasis lies on identifying the optimal\nvalues for parameters h and w, which are pivotal in con-\nstructing the training data for CLITSSA fine-tuning. This\nexploration is performed using the French dataset for exper-\nimental ablation. The determination of the optimal values\nfor h and w is guided by three primary objectives: Firstly,\nto minimize the divergence in similarity contexts between\nthe subsample space and the entire sample space; Secondly,\nto emphasize the similarity contexts for positive pairs more\nthan for other pairs, given that the goal is to retrieve the fine-\ngrained top-k semantically similar examples\u2014this emphasis\nassists in learning the nuanced differences among positive\nsemantic contexts. Lastly, to adhere to a limitation on the\noverall size of the training sample."}, {"title": "Evolution Of Embedding Space Under CLITSSA", "content": "In this experiment, we endeavor to scrutinize the implica-\ntions of fine-tuning a retriever model on its cross-lingual,\ntime-sensitive semantic embedding space across languages\nand temporal tasks. The methodology employed utilizes a\ntest set and S-BERT as foundational retriever to evaluate the\naforementioned model. Precisely, our analysis is predicated\non charting the temporal and semantic similarity among\npaired sets of cross-lingual queries, categorized into positive\nand antagonistic pairs. For the procurement of positive pairs,\nwe systematically select queries in English and their cor-\nresponding translations in assorted low-resource languages.\nConversely, the delineation of antagonistic pairs, herein re-\nferred to as 'antagonistic pairs,' is achieved by sampling an\nequal number of query pairs whose pre-fine-tuning semantic\nsimilarity scores do not exceed a threshold of 0.5, presup-\nposing these pairs exhibit a substantive dissimilarity.\nThe empirical outcomes, as depicted in Figures refer-\nenced as Figure 5 (for Romanian), Figure 6 (for Ger-\nman), and Figure 7 (for French), across varied temporal\ntasks, unequivocally demonstrate the augmented capacity\nof CLITSSA, in heightening the semantic congruence for\npositively aligned query pairs while concurrently diminish-\ning the semantic connection for antagonistic pairs. This en-\nhancement in the model's embedding space unequivocally\nsubstantiates its improved performance in terms of F1 scores\nacross the temporal tasks and low-resource languages."}, {"title": "Hyperparameters", "content": "In this study, the This study used the Huggingface\u201d repos-\nitory to stack various open-source large language models\n(LLMs). The development and fine-tuning of CLITSSA\nwere carried out using the PyTorch library, serving as the\nfoundational framework. Minimal post-processing was ap-\nplied to the outputs generated by the LLMs, entailing the\nremoval of special characters and sequential indicators (e.g.,\n\"1)\", \"a)\"), as well as the standardization of month names,\nparticularly for Task L1, prior to the derivation of the final\nresponse. To fine-tune the CLITSSA model, 1,000 samples\nfrom the validation set and all samples from the training set\nwere utilized to create a parallel corpus. To precisely cap-\nture the expected time-sensitive cross-lingual similarity dis-\ntributions, the parameters h and w were heuristically deter-\nmined to be 30 and 10, respectively. This configuration facil-\nitated the generation of sufficient 40,000 query pairs, each"}]}