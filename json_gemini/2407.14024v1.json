{"title": "TTA-OOD: Test-time Augmentation for Improving Out-of-Distribution Detection in Gastrointestinal Vision", "authors": ["Sandesh Pokhrel", "Sanjay Bhandari", "Eduard Vazquez", "Tryphon Lambrou", "Prashnna Gyawali", "Binod Bhattarai"], "abstract": "Deep learning has significantly advanced the field of gastrointestinal vision, enhancing disease diagnosis capabilities. One major challenge in automating diagnosis within gastrointestinal settings is the detection of abnormal cases in endoscopic images. Due to the sparsity of data, this process of distinguishing normal from abnormal cases has faced significant challenges, particularly with rare and unseen conditions. To address this issue, we frame abnormality detection as an out-of-distribution (OOD) detection problem. In this setup, a model trained on In-Distribution (ID) data, which represents a healthy GI tract, can accurately identify healthy cases, while abnormalities are detected as OOD, regardless of their class. We introduce a test-time augmentation segment into the OOD detection pipeline, which enhances the distinction between ID and OOD examples, thereby improving the effectiveness of existing OOD methods with the same model. This augmentation shifts the pixel space, which translates into a more distinct semantic representation for OOD examples compared to ID examples. We evaluated our method against existing state-of-the-art OOD scores, showing improvements with test-time augmentation over the baseline approach.", "sections": [{"title": "1 Introduction", "content": "Out of all the reported diseases worldwide, diseases with a digestive etiology have burdened the field of medicine with over seven billion incidents reported in 2019 alone [20]. Owing to technological advancements, the fatality rates for most diseases have decreased; however, the number of deaths from gastrointestinal diseases increased from 2000 to 2019 [20]. Invasive endoscopic procedures are"}, {"title": "2 Method", "content": "We study how test time augmentations can improve OOD detection methods in identifying out-of-distribution instances, particularly in gastrointestinal settings. While existing methods effectively distinguish in-distribution from OOD examples, they struggle with near-OOD cases that have close semantic similarity. We explore how test time augmentations on robust models create drift for test samples, enhancing OOD detection performance. Our method integrates easily with existing architectures and OOD detection approaches without changing their processes.\nProblem Formulation: We focus on supervised multi-class classification where, X is input space, Y = {1,2,..., C} is label space and $D_{in}$ = $(x_i, y_i)_{i=1}$ is training set (i.i.d. from $P_{x,y}$), composed of healthy gastrointestinal images (in-distribution data). A neural network $f: X \\rightarrow R^{|Y|}$ is trained on ID data using cross-entropy loss to classify healthy classes. The penultimate layer $\\phi: X \\rightarrow \\mathbb{R}^M$ produces feature vector $\\phi(x)$ for feature-based OOD detection. Logits-based methods use the final linear layer output for OOD detection.\nData Augmentations: A set of pre-defined transformations is employed to generate augmented versions of each test-time sample. These transformations can be broadly categorized into:\nIndividual Augmentations (IA): These base operations modify a single aspect of the data. Examples include horizontal flip (H), vertical flip (V), and color jittering (CJ). For ID samples, these pixel-level transformations often result in only minor changes to the semantic representations learned by the model. However, for OOD samples, the same augmentations can lead to more significant shifts in the feature space representation, as the model has not encountered these types of images during training. This discrepancy in the model's response to augmented ID and OOD samples can be leveraged to enhance the performance of OOD detection methods.\nComposite Augmentations (CA): These combine multiple individual augmentations to create more diverse variations. A composite augmentation can be"}, {"title": "3 Experiments", "content": "We utilized the Kvasirv2 [12] multi-class endoscopy dataset annotated which is verified by experienced endoscopist and is designed for a range of tasks including Gastrointestinal Disease Detection.\nDataset: The Kvasirv2[12] dataset consists 8 categories of upper and lower GI tract anatomical landmarks, most common pathological findings, or endoscopic procedures within the gastrointestinal (GI) tract. The three anatomical landmarks provided in this dataset are the Z-line, Pylorus, and Cecum. Pathological finding in the dataset include Esophagitis(ESO), Polyps(POL), and Ulcerative colitis(UC). In addition to normal and anatomical findings this dataset also consist of images related to polyp removal, the \"dyed and lifted polyp\" (DLP) class and the \"dyed resection margins\" (DRM). For our experimental settings, the anatomical landmarks are our classification task classes(ID-data) that represent healthy GI regions. The remaining five classes are marked as OOD as they constitute of some form of abnormality that you would see in the abdomen. For model training, we selected 2400 in-distribution images(80%) and used 600 in-distribution images (20%), combined with 5000 out-of-distribution images, to assess the model's final performance on OOD capabilities.\nImplementation Details: The Resnet-18 model was trained for 20 epochs. The ViT-Small model was also trained for 20 epochs with a patch size of 16. The batch size in training was 32 and we used the Adam optimizer with an initial learning rate of 1\u00d710-4 for both models. The models were initialized with Imagenet pre-trained weights for better accuracy. The input image size for both models is resized to 224x224 pixels and the standard cross-entropy loss function was used to train the models. The models were trained and tested in PyTorch v2.1.0 with an NVIDIA A100 GPU."}, {"title": "3.2 Results", "content": "Our study presents enhancing out-of-distribution (OOD) detection methods by employing test time augmentations in gastrointestinal contexts. We assessed the capabilities of established OOD detection techniques, logit-based methods like MSP [4], ODIN [7], Energy [8], Entropy [1], MaxLogit [3], feature-based methods like Mahalanobis [6], and method like Vim [19] which combine both feature as well as logit information and investigated how test time augmentations induce subtle drift in test samples and exploited this phenomenon to improve OOD detection performance of respective methods. The model deemed optimal for downstream classification task was selected as the feature extractor for OOD detection task shown in Table 1.\nQuantitative Results: AUC and FPR95 are the most commonly used metrics to evaluate the OOD detection performance. AUC measures the area under the Receiver Operator Characteristic curve, with higher values indicating better performance. FPR represents the false positive rate when the true positive rate is 95%, with smaller values indicating better performance.\nTables 2 and 3 show that test-time augmentation significantly improves out-of-distribution (OOD) detection performance. For Resnet-18, ViM achieves the lowest False Positive Rate (FPR) of 26.7% with Vertical flipping, a 3.16% improvement over the baseline. For ViT-small, ViM achieves a 20.3% FPR with Horizontal flipping, Vertical flipping, and Color Jitter, a 6.04% enhancement. It's evident that the application of test-time augmentations consistently enhances the performance of all OOD detection baseline methods. Achieving a"}, {"title": "Qualitative Results", "content": "The qualitative results in Fig 2 shows the improvement in performance of MaxLogit method on different OOD classes when subject to augmentation. The effect of different augmentations and their predictions either OOD or misclassified as healthy organs are presented in Fig 2.a. It is evident from these results that Test Time Augmentation introduces drift in representation space allowing existing OOD metrics to distinguish ID and OOD better. Moreover, the drift introduced in representation space is different for different augmentations owing to difference in pixel space perturbation. In general, composite augmentations are stronger and create a larger drift as seen in the predictions."}, {"title": "Ablation Study", "content": "Ablation experiments were performed to assess the impact of different augmentation methods on out-of-distribution (OOD) scoring performance. Table 4 shows that Horizontal Flip (Hflip), Vertical Flip (Vflip), and Color Jitter improve OOD detection for both logit-based and feature-based methods. Conversely, Equalize and Invert exhibit a detrimental effect, reducing the performance for both methods. In addition, Table 5 demonstrates that augmenting OOD images causes a drift in representation space, aiding in distinguishing OOD data. The mean OOD score, higher for OOD data, increases with augmentation. ViM shows an average drift of 2.71, raising the mean OOD score from 6.70 to 9.41 with Horizontal and Vertical Flipping. Similar results are observed in logits-based methods like MaxLogit."}, {"title": "4 Conclusion", "content": "We reformulate abnormality detection in gastrointestinal images as an out-of-distribution (OOD) problem, enabling the recognition of abnormalities in the GI tract using a model trained solely on normal anatomical findings. To achieve this, we introduce test-time augmentation (TTA), which significantly improves OOD detection performance by augmenting the input data during inference. This approach, when combined with existing OOD detection methods from the OOD literature, enhances their generalization and robustness regarding OOD detection. Overall, our findings highlight the considerable potential of supervised models in OOD detection, serving as a versatile tool for identifying abnormalities in endoscopy images from gastrointestinal settings an area largely unexplored in medical imaging research."}]}