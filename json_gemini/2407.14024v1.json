{"title": "TTA-OOD: Test-time Augmentation for Improving Out-of-Distribution Detection in Gastrointestinal Vision", "authors": ["Sandesh Pokhrel", "Sanjay Bhandari", "Eduard Vazquez", "Tryphon Lambrou", "Prashnna Gyawali", "Binod Bhattarai"], "abstract": "Deep learning has significantly advanced the field of gas- trointestinal vision, enhancing disease diagnosis capabilities. One major challenge in automating diagnosis within gastrointestinal settings is the detection of abnormal cases in endoscopic images. Due to the spar- sity of data, this process of distinguishing normal from abnormal cases has faced significant challenges, particularly with rare and unseen condi- tions. To address this issue, we frame abnormality detection as an out- of-distribution (OOD) detection problem. In this setup, a model trained on In-Distribution (ID) data, which represents a healthy GI tract, can accurately identify healthy cases, while abnormalities are detected as OOD, regardless of their class. We introduce a test-time augmentation segment into the OOD detection pipeline, which enhances the distinction between ID and OOD examples, thereby improving the effectiveness of existing OOD methods with the same model. This augmentation shifts the pixel space, which translates into a more distinct semantic represen- tation for OOD examples compared to ID examples. We evaluated our method against existing state-of-the-art OOD scores, showing improve- ments with test-time augmentation over the baseline approach.", "sections": [{"title": "1 Introduction", "content": "Out of all the reported diseases worldwide, diseases with a digestive etiology have burdened the field of medicine with over seven billion incidents reported in 2019 alone [20]. Owing to technological advancements, the fatality rates for most diseases have decreased; however, the number of deaths from gastrointesti- nal diseases increased from 2000 to 2019 [20]. Invasive endoscopic procedures are"}, {"title": "2 Method", "content": "We study how test time augmentations can improve OOD detection methods in identifying out-of-distribution instances, particularly in gastrointestinal settings. While existing methods effectively distinguish in-distribution from OOD exam- ples, they struggle with near-OOD cases that have close semantic similarity. We explore how test time augmentations on robust models create drift for test sam- ples, enhancing OOD detection performance. Our method integrates easily with existing architectures and OOD detection approaches without changing their processes.\nProblem Formulation: We focus on supervised multi-class classification where, $X$ is input space, $Y = \\{1,2,..., C\\}$ is label space and $D_{in} = (x_i, y_i)_{i=1}^n$ is training set (i.i.d. from $P_{x,y}$), composed of healthy gastrointestinal images (in- distribution data). A neural network $f : X \\rightarrow \\mathbb{R}^{|Y|}$ is trained on ID data using cross-entropy loss to classify healthy classes. The penultimate layer $\\phi : X \\rightarrow \\mathbb{R}^{M}$ produces feature vector $\\phi(x)$ for feature-based OOD detection. Logits-based methods use the final linear layer output for OOD detection.\nData Augmentations: A set of pre-defined transformations is employed to generate augmented versions of each test-time sample. These transformations can be broadly categorized into:\nIndividual Augmentations (IA): These base operations modify a single as- pect of the data. Examples include horizontal flip (H), vertical flip (V), and color jittering (CJ). For ID samples, these pixel-level transformations often re- sult in only minor changes to the semantic representations learned by the model. However, for OOD samples, the same augmentations can lead to more signifi- cant shifts in the feature space representation, as the model has not encountered these types of images during training. This discrepancy in the model's response to augmented ID and OOD samples can be leveraged to enhance the performance of OOD detection methods.\nComposite Augmentations (CA): These combine multiple individual aug- mentations to create more diverse variations. A composite augmentation can be"}, {"title": "3 Experiments", "content": "We study how test time augmentations can improve OOD detection methods in identifying out-of-distribution instances, particularly in gastrointestinal settings. While existing methods effectively distinguish in-distribution from OOD exam- ples, they struggle with near-OOD cases that have close semantic similarity. We explore how test time augmentations on robust models create drift for test sam- ples, enhancing OOD detection performance. Our method integrates easily with existing architectures and OOD detection approaches without changing their processes.\nProblem Formulation: We focus on supervised multi-class classification where, $X$ is input space, $Y = \\{1,2,..., C\\}$ is label space and $D_{in} = (x_i, y_i)_{i=1}^n$ is training set (i.i.d. from $P_{x,y}$), composed of healthy gastrointestinal images (in- distribution data). A neural network $f : X \\rightarrow \\mathbb{R}^{|Y|}$ is trained on ID data using cross-entropy loss to classify healthy classes. The penultimate layer $\\phi : X \\rightarrow \\mathbb{R}^{M}$ produces feature vector $\\phi(x)$ for feature-based OOD detection. Logits-based methods use the final linear layer output for OOD detection.\nData Augmentations: A set of pre-defined transformations is employed to generate augmented versions of each test-time sample. These transformations can be broadly categorized into:\nIndividual Augmentations (IA): These base operations modify a single as- pect of the data. Examples include horizontal flip (H), vertical flip (V), and color jittering (CJ). For ID samples, these pixel-level transformations often re- sult in only minor changes to the semantic representations learned by the model. However, for OOD samples, the same augmentations can lead to more signifi- cant shifts in the feature space representation, as the model has not encountered these types of images during training. This discrepancy in the model's response to augmented ID and OOD samples can be leveraged to enhance the performance of OOD detection methods.\nComposite Augmentations (CA): These combine multiple individual aug- mentations to create more diverse variations. A composite augmentation can be represented as the sequential application of individual transformations (e.g. H \u2192 V \u2192CJ, H \u2192 V). In contrast to individual augmentation, composite augmenta- tions can induce more complex and diverse perturbations to the input data which leads to more significant shift in the feature space. This desired perturbation cause more pronounced drifts for OOD samples than ID samples, which results in larger separations between ID and OOD data representations and ultimately enhancing the OOD detection performance. This idea is also empirically verified by Table 2, Table 3 and Figure 2(a), where composite augmentation seems to be more effective in enhancing the OOD detection algorithm's ability to dif- ferentiate between in-distribution (ID) and out-of-distribution (OOD) samples, highlighting the utility of composite augmentations in improving OOD detection methods. The equation below formalizes the generation of an augmented sample (x'):\n$x' = T(x)$ (1)\nwhere, x is original input sample and T is transformation, which can be either an individual augmentation (IA\u00bf) or a composite augmentation (C(IAj, ..., IAk)).\nOOD Score Calculation: Augmented samples are processed through a neu- ral network trained on in-distribution (ID) data. The model's output is used to compute an OOD score for test samples, with the specific calculation method varying based on model architecture and desired properties. This approach ex-\nFollowing this, the decision for whether a test image is OOD or not can be formulated as\n$g(x) = \\begin{cases} OOD, \\text{ if score } \\geq \\lambda \\\\ ID, \\text{ otherwise } \\end{cases}$ (2)\nwhere A is the threshold that is decided ensuring that the validation set retains at least a given true-positive rate."}, {"title": "3.1 Datasets and Implementation Details", "content": "We utilized the Kvasirv2 [12] multi-class endoscopy dataset annotated which is verified by experienced endoscopist and is designed for a range of tasks including Gastrointestinal Disease Detection.\nDataset: The Kvasirv2[12] dataset consists 8 categories of upper and lower GI tract anatomical landmarks, most common pathological findings, or endoscopic procedures within the gastrointestinal (GI) tract. The three anatomical land- marks provided in this dataset are the Z-line, Pylorus, and Cecum. Pathological finding in the dataset include Esophagitis(ESO), Polyps(POL), and Ulcerative colitis(UC). In addition to normal and anatomical findings this dataset also consist of images related to polyp removal, the \"dyed and lifted polyp\" (DLP) class and the \"dyed resection margins\" (DRM). For our experimental settings, the anatomical landmarks are our classification task classes(ID-data) that rep- resent healthy GI regions. The remaining five classes are marked as OOD as they constitute of some form of abnormality that you would see in the abdomen. For model training, we selected 2400 in-distribution images(80%) and used 600 in-distribution images (20%), combined with 5000 out-of-distribution images, to assess the model's final performance on OOD capabilities.\nImplementation Details: The Resnet-18 model was trained for 20 epochs. The ViT-Small model was also trained for 20 epochs with a patch size of 16. The batch size in training was 32 and we used the Adam optimizer with an ini- tial learning rate of 1\u00d710-4 for both models. The models were initialized with Imagenet pre-trained weights for better accuracy. The input image size for both models is resized to 224x224 pixels and the standard cross-entropy loss function was used to train the models. The models were trained and tested in PyTorch v2.1.0 with an NVIDIA A100 GPU."}, {"title": "3.2 Results", "content": "Our study presents enhancing out-of-distribution (OOD) detection methods by employing test time augmentations in gastrointestinal contexts. We assessed the capabilities of established OOD detection techniques, logit-based methods like MSP [4], ODIN [7], Energy [8], Entropy [1], MaxLogit [3], feature-based methods like Mahalanobis [6], and method like Vim [19] which combine both feature as well as logit information and investigated how test time augmentations induce subtle drift in test samples and exploited this phenomenon to improve OOD detection performance of respective methods. The model deemed optimal for downstream classification task was selected as the feature extractor for OOD detection task shown in Table 1.\nQuantitative Results: AUC and FPR95 are the most commonly used metrics to evaluate the OOD detection performance. AUC measures the area under the Receiver Operator Characteristic curve, with higher values indicating better performance. FPR represents the false positive rate when the true positive rate is 95%, with smaller values indicating better performance.\nTables 2 and 3 show that test-time augmentation significantly improves out- of-distribution (OOD) detection performance. For Resnet-18, ViM achieves the lowest False Positive Rate (FPR) of 26.7% with Vertical flipping, a 3.16% im- provement over the baseline. For ViT-small, ViM achieves a 20.3% FPR with Horizontal flipping, Vertical flipping, and Color Jitter, a 6.04% enhancement. It's evident that the application of test-time augmentations consistently en- hances the performance of all OOD detection baseline methods. Achieving a low FPR95 is particularly crucial as it directly contributes to reducing false pos- itives and thereby increasing the trustworthiness of the model's predictions. By incorporating test-time augmentations, we not only strengthen the robustness of the model but also equip it with better generalization capabilities in terms of OOD detection, which are paramount for real-world applications where unseen data instances are common.\nQualitative Results: The qualitative results in Fig 2 shows the improvement in performance of MaxLogit method on different OOD classes when subject to augmentation. The effect of different augmentations and their predictions either OOD or misclassified as healthy organs are presented in Fig 2.a. It is evident from these results that Test Time Augmentation introduces drift in represen- tation space allowing existing OOD metrics to distinguish ID and OOD better. Moreover, the drift introduced in representation space is different for differ- ent augmentations owing to difference in pixel space perturbation. In general, composite augmentations are stronger and create a larger drift as seen in the predictions.\nAblation Study: Ablation experiments were performed to assess the impact of different augmentation methods on out-of-distribution (OOD) scoring perfor- mance. Table 4 shows that Horizontal Flip (Hflip), Vertical Flip (Vflip), and Color Jitter improve OOD detection for both logit-based and feature-based methods. Conversely, Equalize and Invert exhibit a detrimental effect, reduc- ing the performance for both methods. In addition, Table 5 demonstrates that augmenting OOD images causes a drift in representation space, aiding in dis- tinguishing OOD data. The mean OOD score, higher for OOD data, increases with augmentation. ViM shows an average drift of 2.71, raising the mean OOD score from 6.70 to 9.41 with Horizontal and Vertical Flipping. Similar results are observed in logits-based methods like MaxLogit."}, {"title": "4 Conclusion", "content": "We reformulate abnormality detection in gastrointestinal images as an out-of- distribution (OOD) problem, enabling the recognition of abnormalities in the GI tract using a model trained solely on normal anatomical findings. To achieve this, we introduce test-time augmentation (TTA), which significantly improves OOD detection performance by augmenting the input data during inference. This approach, when combined with existing OOD detection methods from the OOD literature, enhances their generalization and robustness regarding OOD detection. Overall, our findings highlight the considerable potential of supervised models in OOD detection, serving as a versatile tool for identifying abnormalities in endoscopy images from gastrointestinal settings an area largely unexplored in medical imaging research."}]}