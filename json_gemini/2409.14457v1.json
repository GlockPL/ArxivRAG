{"title": "Large Model Agents: State-of-the-Art, Cooperation Paradigms, Security and Privacy, and Future Trends", "authors": ["Yuntao Wang", "Yanghe Pan", "Quan Zhao", "Yi Deng", "Zhou Su", "Linkang Du", "Tom H. Luan"], "abstract": "Large Model (LM) agents, powered by large foundation models such as GPT-4 and DALL-E 2, represent a significant step towards achieving Artificial General Intelligence (AGI). LM agents exhibit key characteristics of autonomy, embodiment, and connectivity, allowing them to operate across physical, virtual, and mixed-reality environments while interacting seamlessly with humans, other agents, and their surroundings. This paper provides a comprehensive survey of the state-of-the-art in LM agents, focusing on the architecture, cooperation paradigms, security, privacy, and future prospects. Specifically, we first explore the foundational principles of LM agents, including general architecture, key components, enabling technologies, and modern applications. Then, we discuss practical collaboration paradigms from data, computation, and knowledge perspectives towards connected intelligence of LM agents. Furthermore, we systematically analyze the security vulnerabilities and privacy breaches associated with LM agents, particularly in multi-agent settings. We also explore their underlying mechanisms and review existing and potential countermeasures. Finally, we outline future research directions for building robust and secure LM agent ecosystems.", "sections": [{"title": "I. INTRODUCTION", "content": "In the 1950s, Alan Turing introduced the famous Turing Test to assess whether machines could exhibit intelligence comparable to that of humans, which laid the foundation in the evolution of Artificial Intelligence (AI). These artificial entities, commonly known as \"agents\", serve as the core components of AI systems. Generally, AI agents are autonomous entities capable of understanding and responding to human inputs, perceiving their environment, making decisions, and taking actions in physical, virtual, or mixed-reality settings to achieve their goals [1]. AI agents range from simple bots that follow predefined rules to complex and autonomous entities that learn and adapt through experience [2]. They can be software-based or physical entities, functioning independently or in collaboration with humans or other agents.\nSince the mid-20th century, significant progress has been made in the development of AI agents [3]\u2013[5], such as Deep Blue, AlphaGo, and AlphaZero, as shown in Fig. 1. Despite these advances, prior research primarily concentrated on refining specialized abilities such as symbolic reasoning or excelling in certain tasks such as Go or Chess, often neglecting the cultivation of general-purpose capabilities within AI models such as long-term planning, multi-task generalization, and knowledge retention. The challenge of creating AI agents that can flexibly adapt to a broad range of tasks and complex environments remains largely unexplored. To push the boundaries of AI agents further, it is crucial to develop powerful foundational models that integrate these critical attributes, offering a versatile basis for next-generation AI agents.\nWith the rise of Large Models (LMs), also known as large foundation models, such as OpenAI GPT-40, Google PaLM 2, and Microsoft Copilot, LMs open up new possibilities in comprehensively enhancing the inherent capabilities of AI agents [6], [7]. As illustrated in Fig. 2, an LM agent, either in software or embodied form, generally consist of four key components: planning, action, memory, and interaction. These agents can seamlessly operate within physical, virtual, or mixed-reality environments [1], [8]\u2013[10]. Particularly, LMs serve as the \"brain\" of AI agents and empower them with powerful capabilities in human-machine interaction (HMI), complex pattern recognition, knowledge retention, reasoning, long-term planning, generalization, and adaptability [9]. Moreover, via advanced reasoning and few/zero-shot planning techniques such as Chain-of-Thought (CoT) [11], Tree-of-Thought (ToT) [12], and reflection [13], LM agents can form intricate logical connections, enabling them to solve complex, multifaceted tasks effectively. For example, AutoGPT [14], a promising LLM agent prototype, can decompose complex tasks into several manageable sub-tasks, facilitating structured and efficient problem-solving. Integrating LMs with Retrieval-Augmented Generation (RAG) technologies [15] further allows agents to access external knowledge sources and enhance"}, {"title": "B. Roadmap and Key Characteristics of LM Agents", "content": "Fig. 3 illustrates a future vision of LM agents, characterized by three key attributes: autonomous, embodied, and connected, paving the way toward AGI.\nAutonomous intelligence in LM agents refers to their ability to operate independently, making proactive decisions without continuous human input. As depicted in Fig. 2(a), an LM agent can maintain an internal memory that accumulates knowledge over time to guide future decisions and actions, enabling continuous learning and adaptation in dynamic environments [25]. Additionally, LM agents can autonomously utilize a variety of tools (e.g., search engines and external APIs) to gather information or or create new tools to handle intricate tasks [26]. By collaborating or competing with humans or other agents, LM agents can effectively enhance their decision-making capabilities [27].\nDespite recent advancements, LMs typically passively respond to human commands in the text, image, or multimodal domain, without engaging directly with the physical world [7]. Embodied agents, on the other hand, can actively perceive and act upon their environment, whether digital, robotic, or physical, using sensors and actuators [21], [25]. The shift to LM-empowered agents involves creating embodied AI systems capable of understanding, learning, and solving real-world challenges. As depicted in Fig. 2(b), LM agents actively interact with environments and adapt actions based on real-time feedbacks. For example, a household robot LM agent tasked with cleaning can generate tailored strategies by analyzing the room layout, surface types, and obstacles, instead of merely following generic instructions.\nConnected LM agents extend beyond the capabilities of individual agents, playing a critical role in tackling complex, real-world tasks [28]. For example, in autonomous driving, connected autonomous vehicles, serving as LM agents, share real-time sensory data, coordinate movements, and negotiate passage at intersections to optimize traffic flow and enhance safety. As depicted in Fig. 3, by interconnecting numerous LM agents into the Internet of LM agents, connected LM agents can freely share sensory data and task-oriented knowledge. By fully harnessing the computational power of various specialized LMs, it fosters cooperative decision-making and collective intelligence. Theereby, the collaboration across data, computation, and knowledge domains enhances individual"}, {"title": "C. Motivation for Securing Connected LM Agents", "content": "Despite the bright future of LM agents, security and privacy concerns remain significant barriers to their widespread adoption. Throughout the life-cycle of LM agents, numerous vulnerabilities can emerge, ranging from adversarial examples [31], agent poisoning [32], LM hallucination [33], to pervasive data collection and memorization [34].\nLM agents are prone to \"hallucinations\", where their foundational LMs generate plausible but incorrect outputs not grounded in reality [33]. In multi-agent settings, the hallucination phenomenon can propagate misinformation, compromise decision-making, cause task failures, and pose risks to both physical entities and human. Moreover, maintaining the integrity and authenticity of sensory data and prompts used in training and inference is crucial, as biased or compromised inputs can lead to inaccurate or unfair outcomes [35]. Attacks such as adversarial manipulations [31], poisoning [36], and backdoors [37] further threaten LM agents by allowing malicious actors to manipulate inputs and deceive the models. In collaborative environments, agent poisoning behaviors [32], where malicious agents disrupt the behavior of others, can undermine the collaborative systems. Additionally, integrating LM agents into Cyber-Physical-Social Systems (CPSS) expands the attack surface, enabling adversaries to exploit vulnerabilities within interconnected systems.\nLM agents' extensive data collection and memorization processes raise severe risks of data breaches and unauthorized access. These agents often handle vast amounts of personal and sensitive business information for both To-Customer (ToC) and To-Business (ToB) applications, raising concerns about data storage, processing, sharing, and control [38]. Additionally, LMs can inadvertently memorize sensitive details from their training data, potentially exposing private information during interactions [34]. Privacy risks are further compounded in multi-agent collaborations, where LM agents might inadvertently leak sensitive information about users, other agents, or their internal operations during communication and task execution."}, {"title": "D. Related Surveys and Contributions", "content": "Recently, LM agents have garnered significant interest across academia and industry, leading to a variety of research exploring their potential from multiple perspectives. Notable survey papers in this field are as below. Andreas et al. [29] present a toy experiment for AI agent construction and case studies on modeling communicative intentions, beliefs, and desires. Wang et al. [39] identify key components of LLM-based autonomous agents (i.e., profile, memory, planning, and action) and the subjective and objective evaluation metrics. Besides, they discuss the applications of LLM agents in engineering, natural science, and social science. Xi et al. [9] present a general framework for LLM agents consisting of brain, action, and perception. Besides, they explore applications in single-agent, multi-agent, and human-agent collaborations, as well as agent societies. Zhao et al. [2] offer a systematic review of LLMs in terms of pre-training, adaptation tuning, utilization, and capacity assessment. Besides, background information, mainstream technologies, and critical applications of LLMs are introduced. Xu et al. [40] provide a tutorial on key concepts, architecture, and metrics of edge-cloud AI-Generated Content (AIGC) services in mobile networks, and identify several use cases and implementation challenges. Huang et al. [1] offer a taxonomy of AI agents in virtual/physical environments, discuss cognitive aspects of AI Agents, and survey the applications of AI agents in robotics, healthcare, and gaming. Cheng et al. [10] review key components of LLM agents (including planning, memory, action, environment, and rethinking) and their potential applications. Planning types, multi-role relationships, and communication methods in multi-agent systems are also reviewed. Masterman et al. [8] provide an overview of single-agent and multi-agent architectures in industrial projects and present the insights and limitations of existing research. Guo et al. [41] discuss the four components (i.e., interface, profiling, communication, and capabilities acquisition) of LLM-based multi-agent systems and present two lines of applications in terms of problem solving and world simulation. Durante et al. [42] introduce multimodal LM agents and a training framework including learning, action, congnition, memory, action, and perception. They also discuss the different roles of agents (e.g., embodied, simulation, and knowledge inference), as well as the potentials and experimental results in different applications including gaming, robotics, healthcare, multimodal tasks, and Natural Language Processing (NLP). Hu et al. [20] outline six key components (i.e., perception, thinking, memory, learning, action, and role-playing) of LLM-based game agents and review existing LLM-based game agents in six types of games. Xu et al. [43] provide a comprehensive survey of enabling architectures and challenges for LM agents in gaming. Qu et al. [44] provide a comprehensive survey on integrating mobile edge intelligence (MEI) with LLMs, emphasizing key applications of deploying LLMs at the network edge along with state-of-the-art techniques in edge LLM caching, delivery, training, and inference.\nExisting survey works on LM agents mainly focus on the general framework design for single LLM agents and multi-agent systems and their potentials in specific applications. Distinguished from the above-mentioned existing surveys, this survey focuses on the networking aspect of LM agents, including the general architecture, enabling technologies, and collaboration paradigms to construct networked systems of LM agents in physical, virtual, or mixed-reality environments. Moreover, with the advances of LM agents, it is urgent to study their security and privacy in future AI agent systems. This work comprehensively reviews the security and privacy issues of LM agents and discusses the existing and potential defense mechanisms, which are overlooked in existing surveys. Table I compares the contributions of our survey with previous related surveys in the field of LM agents.\nIn this paper, we present a systematic review of the state-of-the-arts in both single and connected LM agents, focusing on security and privacy threats, existing and potential countermeasures, and future trends. Our survey aims to 1) provide a broader understanding of how LM agents work and how they interact in multi-agent scenarios, 2) examine the scope and impact of security and privacy challenges associated with LM agents and their interactions, and 3) highlight effective strategies and"}, {"title": "E. Paper Organization", "content": "The remainder of this paper is organized as below. Section II discusses the working principles of single LM agents, while Section III presents the cooperation paradigms for connected LM agents. Section IV and Section V introduce the taxonomy of security and privacy threats to LM agents, respectively, along with state-of-the-art countermeasures. Section VI outlines open research issues and future directions in the field of LM agents. Finally, conclusions are drawn in Section VII. Fig. 4 depicts the organization structure of this survey.\nIn this section, we first introduce existing standards of LM agents. Then, we discuss the general architecture of connected LM agents including key components, communication modes, key characteristics, and enabling technologies. Next, we introduce typical prototypes and discuss modern applications of LM agents."}, {"title": "A. Standards of LM Agents", "content": "We briefly introduce two existing standards on LM agents: IEEE SA-P3394 and IEEE SA-P3428.\nThe IEEE SA - P3394 standard\u00b9, launched in 2023, defines natural language interfaces to facilitate communication between LLM applications, agents, and human users. This standard establishes a set of protocols and guidelines that enable applications and agents to effectively communicate with LLM-enabled agents. These protocols and guidelines include, but are not limited to, API syntax and semantics, voice and text formats, conversation flow, prompt engineering integration, LLM thought chain integration, as well as API endpoint configuration, authentication, and authorization for LLM plugins. The standard is expected to advance technological interoperability, promote AI industry development, enhance the practicality and efficiency of LMs, and improve AI agent functionality and user experience.\nThe IEEE SA - P3428 standard, launched in 2023, aims to develop standards for LLM agents in educational applications. The primary goal is to ensure the interoperability of LLM agents across both open-source and proprietary systems. Key areas of focus include the integration of LLMs with existing educational systems and addressing technical and ethical challenges. This includes ensuring that LLMs can seamlessly interact with other AI components, such as Adaptive Instructional Systems (AIS), while also addressing issues of bias, transparency, and accountability within educational contexts. The standard is intended to support the widespread and effective application of LLMs in the field of education, thereby enabling more personalized, efficient, and ethically sound AI-driven educational experiences."}, {"title": "B. Architecture of Connected LM Agents", "content": "According to [45], [46], the OS architecture of LM agents consists of three layers: application, kernel, and hardware.\nThe application layer hosts agent applications (e.g., travel, coding, and robot agents) and offers a SDK that abstracts system calls, simplifying agent development.\nThe kernel layer includes the ordinary OS kernel and an additional LM agent kernel, with a focus on without altering the original OS structure. Key modules in the LM agent kernel [45], [46] include the agent scheduler for task planning and prioritization, context manager for LM status management, memory manager for short-term data, storage manager for long-term data retention, tool manager for external API interactions, and access manager for privacy controls.\nThe hardware layer comprises physical resources (CPU, GPU, memory, etc.), which are managed indirectly through OS system calls, as LM kernels do not interact directly with the hardware."}, {"title": "II. LARGE MODEL AGENTS: WORKING PRINCIPLES", "content": "In this section, we first introduce existing standards of LM agents. Then, we discuss the general architecture of connected LM agents including key components, communication modes, key characteristics, and enabling technologies. Next, we introduce typical prototypes and discuss modern applications of LM agents."}, {"title": "2) Constructing Modules of LM Agents:", "content": "According to [1], [8]\u2013[10], there are generally five constructing modules of LM agents: planning, action, memory, interaction, and security modules (details in Sect. II-C). These modules together enable LM agents to perceive, plan, act, learn, and interact efficiently and securely in complex and dynamic environments.\nEmpowered by LMs, the planning module produces strategies and action plans with the help of the memory module, enabling informed decision-making [7], [10].\nThe action module executes these embodied actions, adapting actions based on real-time environmental feedback to ensure contextually appropriate responses [9], [42].\nThe memory module serves as a repository of accumulated knowledge (e.g., past experiences and external knowledge), facilitating continuous learning and improvement [10].\nThe interaction module enables effective communication and collaboration with humans, other agents, and environment.\nThe security module is integrated throughout LM agents' operations, ensuring active protection against threats and maintaining integrity and confidentiality of data and processes."}, {"title": "3) Engine of LM Agents:", "content": "The engine of LM agents is powered by a combination of cutting-edge technologies including large foundation models, knowledge-related technologies, interaction, digital twin, and multi-agent collaboration (details in Sect. II-D).\nLarge foundation model such as GPT-4 and DALL-E 2 serves as the brain of an LM agent, which enables high-level pattern recognition, advanced reasoning, and intelligent decision-making, providing the cognitive capabilities of LM agents [6], [7].\nKnowledge-related technologies enhance LM agents by incorporating Knowledge Graphs (KGs), knowledge bases, and RAG systems, allowing agents to access, utilize, and manage vast external knowledge sources, ensuring informed and contextually relevant actions [47].\nHMI technologies enable seamless interaction between humans and agents through NLP, multimodal interfaces, and Augmented/Virtual/Mixed Reality (AR/VR/MR), facilitating dynamic and adaptive interactions [48].\nDigital twin technologies allows efficient and seamless synchronization of data and statuses between the physical body and the digital brain of an LM agent through intra-agent communications [49].\nMulti-agent collaboration technologies empower LM agents to work together efficiently, sharing data, resources, and tasks to tackle complex problems by developing cooperation, competition, and coopetition strategies through inter-agent communications [28]."}, {"title": "4) Communication Mode of LM Agents:", "content": "Every LM agent consists of two parts: (i) the LM-empowered brain located in the cloud, edge servers, or end devices and (ii) the corresponding physical body such as autonomous vehicle. Every LM agent can actively interact with other LM agents, the virtual/real environment, and humans. For connected LM agents, there exist two typical communication modes: intra-agent communications for seamless data/knowledge synchronization between brain and physical body within an LM agent, and inter-agent communications for efficient coordination between LM agents. summarizes the comparison of the two communication modes.\nrefer to the internal data/knowledge exchange within a single LM agent. This type of communication ensures that different components of the LM agent, including planning, action, memory, interaction, and security modules, work in harmony. For example, an LM agent collects multimodal sensory data through its physical body, which then communicates the interpreted information to the LM-empowered brain. The planning module in the brain formulates a response or action plan, which is then executed by the action module. This seamless flow of information is critical for maintaining the LM agent's functionality, coherence, and responsiveness in real-time and dynamic scenarios.\ninvolve information and knowledge exchange between multiple LM agents. It enables collaborative task allocation, resource sharing, and coordinated actions among agents to foster collective intelligence. For example, in a smart city application, various LM agents managing traffic lights, public transportation, and emergency services share real-time data to optimize urban mobility and safety. Effective inter-agent communications rely on standardized protocols to ensure compatibility and interoperability, facilitating efficient and synchronized operations across the network of LM agents."}, {"title": "5) Information Flow Between Human World and LM Agents:", "content": "Humans interact with LM agents through natural language, mobile smart devices, and wearable technology, enabling LM agents to comprehend human instructions and address real-world issues effectively. LM agents, in turn, acquire new knowledge and data from human inputs, which aids in their continuous improvement and learning. This ongoing process of updating and optimizing their models allows LM agents to provide increasingly accurate and useful information. In AR and VR environments, LM agents can work collaboratively with human users in virtual settings, such as architectural design, for enhanced overall efficiency and creativity [50]."}, {"title": "6) Information Flow Between Physical World and LM Agents:", "content": "Empowered by digital twin technologies, LM agents are allowed to synchronize data and statuses between their physical bodies and their digital brains, creating a seamless interaction loop. LM agents can also monitor and act upon real-time inputs from their environments. This bidirectional synchronization allows LM agents to perceive and respond to their surrounding environments\u2014whether virtual or real\u2014with a high degree of precision and responsiveness, thus bridging the gap between the digital and physical realms. By continuously learning from environmental feedbacks, LM agents can accumulate knowledge and develop an understanding of physical laws, which empowers them to solve complex real-world problems. This iterative learning process"}, {"title": "7) Information Flow Between Cyber World and LM Agents:", "content": "In the cyber world, LM agents are interconnected into the Internet of LM agents through efficient cloud-edge networking, facilitating seamless data and knowledge sharing that promotes multi-agent collaboration. By deploying LMs across both cloud and edge infrastructures, it allows LM agents to leverage the strengths of both cloud and edge computing for optimized performance and responsiveness [51]. The cloud provides substantial computational power and storage, enabling the processing of vast amounts of data and the training of sophisticated models. Meanwhile, the edge offers real-time data processing capabilities closer to the source, reducing latency and ensuring timely decision-making. In the Internet of LM agents, LM agents can collaboratively share data, knowledge, and learned experiences with others in real-time, creating a robust and adaptive network of intelligence across multiple domains. For example, in a smart city, embodied LM agents in various locations can work together to optimize traffic flow, manage energy resources, and enhance public safety by sharing real-time data and coordinating their actions."}, {"title": "C. Key Components of LM Agent", "content": "As depicted in Fig. 7, it generally contains five key modules to construct a connected LM agent [1], [8]\u2013[10].\nThe planning module serves as the core of an LM agent [7], [10]. It utilizes advanced reasoning techniques to enable LM agents to devise efficient and effective solutions to complex problems. The working modes of the planning module include the following types.\nFeedback-free planning: The planning module enables LM agents to understand the complex problems and find reliable solutions by breaking them down into necessary steps or"}, {"title": "2) Memory Module:", "content": "The memory module is integral to LM agent's ability to learn and adapt over time [39]. It maintains an internal memory that accumulates knowledge from past interactions, thoughts, actions, observations, and experiences with users, other agents, and the environments. The stored information guides future decisions and actions, allowing the agent to continuously refine its knowledge and skills. This module ensures that the agent can remember and apply past lessons to new situations, thereby improving its long-term performance and adaptability [10]. There are various memory formats such as natural language, embedded vectors, databases, and structured lists. Additionally, RAG technologies [15] are employed to access external knowledge sources, further enhancing the accuracy and relevance of LM agent's planning capabilities. In the literature [10], [39], memory can be divided into the following three types.\nShort-term memory focuses on the contextual information of the current situation. It is temporary and limited, typically managed through a context window that restricts the amount of information the LM agent can learn at a time.\nLong-term memory stores LM agent's historical behaviors and thoughts. This is achieved through external vector storage, which allows for quick retrieval of important information, ensuring that the agent can access relevant past experiences to inform current decisions [58].\nHybrid memory combines short-term and long-term memory to enhance an agent's understanding of the current context and leverage past experiences for better long-term reasoning. Liu et al. [59] propose the RAISE architecture to enhance ReAct for conversational AI agents by integrating a dual-component memory system, where Scratchpad captures recent interactions as short-term memory; while the retrieval module acts as long-term memory to access relevant examples. HIAGENT [60] employs cross-trial and in-trial memory, where cross-trial memory stores historical trajectories and in-trial memory captures current trials. Instead of retaining all action-observation pairs, HIAGENT uses sub-goals as memory chunks to save memory, each containing summarized observations. LLM generates subgoals, executes actions to achieve them, and updates the working memory by"}, {"title": "3) Action Module:", "content": "The action module equips the LM agent with the ability to execute and adapt actions in various environments [9], [42]. This module is designed to handle embodied actions and tool-use capabilities, enabling the agent to interact with its physical surroundings adaptively and effectively. Besides, tools significantly broaden the action space of the agent.\nThe action module empowers LM agents to perform contextually appropriate embodied actions and adapt to environmental changes, facilitating interaction with and adjustment to physical surroundings [21], [25]. As LLM-generated action plans are often not directly executable in interactive environments, Huang et al. [25] propose refining LLM-generated plans for embodied agents by conditioning on demonstrations and semantically translating them into admissible actions. Evaluations in the VirtualHome environment show significant improvements in executability, ranging from 18% to 79% over the baseline LLM. Besides, SayCan [21] enables embodied agents such as robots to follow high-level instructions by leveraging LLM knowledge in physically-grounded tasks, where LLM (i.e., Say) suggests useful actions; while learned affordance functions (i.e., Can) assess feasibility. SayCan's effectiveness is demonstrated through 101 zero-shot real-world robotic tasks in a kitchen setting. PaLM-E [61] is a versatile multimodal language model for embodied reasoning, visual-language, and language tasks. It integrates continuous sensor inputs, e.g., images and state estimates, into the same embedding space as language tokens, allowing for grounded inferences in real-world sequential decision-making.\nBy leveraging various tools (e.g., search engines and external APIs) [62], LM agent can gather valuable information to handle assigned complex tasks. For example, AutoGPT integrates LLMs with predetermined tools such as web and file browsing. InteRecAgent [63] integrates LLMs as the brain and recommender models as tools, using querying, retrieval, and ranking tools to handle complex user inquiries. Beyond using existing tools, LM agents can also develop new tools to enhance task efficiency [9]. To optimize tool selection with a large toolset, ReInvoke [64] introduces an unsupervised tool retrieval method featuring a query generator to enrich tool documents in offline indexing and an intent extractor to identify tool-related intents from user queries in online inference, followed by a multi-view similarity ranking strategy to identify the most relevant tools."}, {"title": "4) Interaction Module:", "content": "The interaction module enables the LM agent to interact with humans, other agents, and the environment [41]. Through these varied interactions, the agent can gather diverse experiences and knowledge, which are essential for comprehensive understanding and adaptation.\nThe interaction module allows LM agents to communicate and collaborate with other agents, fostering a cooperative network where information and resources are shared [62]. This interaction can include coordinating efforts on shared tasks, exchanging knowledge"}, {"title": "5) Security Module:", "content": "The security module is crucial to ensure the secure, safe, ethical, and privacy-preserving operations of LM agents [42]. It is designed to monitor and regulate the LM agent's actions, interactions, and decisions to prevent harm and ensure compliance with legal and ethical standards. This module employs technologies such as hallucination mitigation, anomaly detection, and access control to identify and mitigate potential security/privacy threats. It also incorporates ethical guidelines and bias mitigation techniques to ensure fair and responsible behaviors. The security module can dynamically adapt to emerging threats by learning from new security/privacy incidents and integrating updates from security/privacy databases and policies.\nThe key components of an LM agent are interconnected to create a cohesive and intelligent system. Particularly, the planning module relies on the memory module to access past experiences and external knowledge, ensuring informed decision-making. The action module executes plans generated by the planning module, adapting actions based on real-time feedback and memory. The interaction module enhances these processes by facilitating communication and collaboration, which provides additional data and context for the planning and memory modules. Besides, security considerations are seamlessly integrated into every aspect of the LM agent's operations to ensure robust and trustworthy performance."}, {"title": "D. Enabling Technologies of LM Agents", "content": "As illustrated in Fig. 8, there are five enabling technologies underlying the engine of connected LM agents.\nLMs, such as LLMs and LVMs, serve as the core brains or controllers, providing advanced capabilities for AI agents across diverse applications [6], [57].(i) Multimodal capability: By employing multimodal perception (e.g., CLIP [69]) and tool utilization strategies, LM agents can perceive and process various data types from virtual and real"}, {"title": "III. NETWORKING LARGE MODEL AGENTS: PARADIGMS", "content": "For connected LM agents, multi-agent interactions refer to the dynamic and complex interactions between multiple autonomous LM agents that operate within a shared environment. As depicted in Fig. 9, these interactions can be categorized into cooperation, partial cooperation, and competition [62], [98], each of which involves different strategies to jointly optimize the collective or individual outcomes."}, {"title": "3) Cooperation:", "content": "For connected LM agents, cooperation is a fundamental interaction mode where LM agents work together to achieve common goals, share resources, and optimize collective outcomes. This involves data cooperation, computation cooperation, and information (including knowledge) cooperation."}, {"title": "B. Data Cooperation for LM Agents", "content": "The data cooperation among LM agents involves the modality perspective, the temporal perspective, and the spatial perspective. Effective data cooperation ensures that LM agents can seamlessly integrate and utilize data from diverse sources and modalities, enhancing their capabilities and performance in various applications."}, {"title": "1) Multimodal Data Cooperation:", "content": "Multimodal data cooperation iemphasizes the fusion of data from various modalities, such as text, images, audio, and video, to provide a comprehensive understanding of the environment. This cooperation allows LM agents to process and interpret information from multiple sources, leading to more accurate and robust decision-making.\nBy combining data from different modalities, it helps create a unified representation that leverages the strength of each type of data. For example, Wu et al. [106] propose a multi-agent collaborative vehicle detection network named MuDet, which integrates RGB and height map modalities for improved object identification in dense and occluded environments such as post-disaster sites. Gross et al. [81] discuss the use of multimodal data to model communication in artificial social agents, emphasizing the importance of verbal and nonverbal cues for natural human-robot interaction.\nBy enabling LM agents to retrieve relevant information across different modalities, it enhances their ability to respond to complex queries and scenarios. For example, Gur et al. [107] design an alignment model and retrieval-augmented multi-modal transformers for efficient image-caption retrieval in visual Question-Answering (QA) tasks. By considering the intra-modality similarities in multi-modal video representations, Zolfaghari et al. [72] introduce the contrastive loss in contrastive learning process for enhanced cross-modal embedding. The effectiveness is"}, {"title": "2) Spatio-temporal Data Cooperation:", "content": "Spatio-temporal data cooperation for LM agents involves the integration and synchronization of spatial and temporal data across various modalities and sources, enabling LM agents to achieve a comprehensive and dynamic understanding of the environment over time. This cooperation ensures that LM agents can effectively analyze patterns, predict future states, and make informed decisions in real-time, based on both spatial distribution and temporal evolution of data.\nYang et al. [109] introduce SCOPE, a collaborative perception mechanism that enhances spatio-temporal awareness among on-road agents through end-to-end aggregation. SCOPE excels by leveraging temporal semantic cues, integrating spatial information from diverse agents, and adaptively fusing multi-source representations to improve accuracy and robustness. However, [109] mainly works for small-scale scenarios. By capturing both spatial and temporal heterogeneity of citywide traffc, Ji et al. [110] propose a novel spatio-temporal self-supervised learning framework for traffic prediction that improves representation of traffic patterns. This framework uses an integrated module combining temporal and spatial convolutions and employs adaptive augmentation of traffic graph data, supported by two auxiliary self-supervised learning tasks to improve prediction accuracy. To further address data noises, missing information, and distribution heterogeneity in spatio-temporal data, which are overlooked in [109], [110], Zhang et al. [111] devise an automated spatio-temporal graph contrastive learning framework named AutoST. Built on a heterogeneous Graph Neural Network (GNN), AutoST captures multi-view region dependencies and enhances robustness through a spatio-temporal augmentation scheme with a parameterized contrastive view generator.\nDynamics with topological reasoning: Chen et al. [82] propose a temporally dynamic multi-agent collaboration framework that organizes agents using directed acyclic graphs to facilitate interactive reasoning, demonstrating superior performance across various network topologies and enabling collaboration among thousands of agents. A key finding in [82] is the discovery of the collaborative scaling law, where solution quality improves in a logistic growth pattern as more agents are added, with collaborative emergence occurring sooner than neural emergence."}, {"title": "C. Computation Cooperation for LM Agents", "content": "The computation cooperation paradigm of LM agents includes horizontal/vertical cooperation and cross-layer cooperation.\nIt can be classified into three modes: horizontal cooperation, vertical cooperation, and hybrid cooperation."}, {"title": "1) Horizontal collaboration", "content": "refers to multiple LM agents completing the same task independently at the same time, and then summarizing and integrating their respective outputs to generate the final result. It allows the collaborative system to scale horizontally by adding more LM agents to handle complex and dynamic tasks. The parallel processing and multi-angle perspectives contribute to increased robustness and diversity, minimizing errors and biases that could arise from a single model's limitations. As depicted in Fig. 12, each LM agent independently analyzes different aspects of stock including trend, news, and industry to determine whether it is a good investment. Horizontal collaboration has been applied in various LM agent systems. For example, ProAgent [85] designs a framework where LM agents work as teammates, analyzing each other's intentions and updating their own beliefs based on the observed behaviors of their peers. This enhances collective decision-making by allowing agents to adapt dynamically in real time. Similarly, DyLAN [114] assembles a team of strategic agents that communicate through task-specific queries in a dynamic interaction architecture, enabling multiple rounds of interaction to improve both efficiency and overall performance. However, the independent analysis of each LM agent may lead to inconsistent outputs, making it difficult to aggregate the final conclusions. Therefore, horizontal collaboration requires effective mechanisms to handle disagreements between LM agents and ensure that their contributions complement each other, which may increase the complexity of the coordination process."}, {"title": "2) Vertical collaboration", "content": "is to decompose complex tasks into multiple stages, and different LM agents complete the tasks of each stage in turn. After each agent completes the task of its own stage, it passes the result to the next agent until the entire task is successfully solved. As depicted in Fig. 13, for medical image analysis, the first agent may extract basic visual features, the second agent analyzes these features in more depth, and the final agent produces a diagnosis. This sequential process enables a step-by-step refinement, allowing complex problems to be broken down and tackled more efficiently by leveraging specialized"}, {"title": "3) Hybrid collaboration.", "content": "In practical LM agent environments, real-world applications often involve both horizontal and vertical collaboration paradigms, resulting in the hybrid collaboration. For example, in addressing highly complex tasks, the problem is first broken down into manageable sub-tasks, each assigned to specialized LM agents. Here"}]}