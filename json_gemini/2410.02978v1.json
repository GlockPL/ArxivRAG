{"title": "AN EXPLAINABLE APPROACH TO DETECT CASE LAW ON HOUSING AND EVICTION ISSUES WITHIN THE HUDOC DATABASE", "authors": ["M. Mohammadi", "M. Wieling", "M. Vols"], "abstract": "Case law is instrumental in shaping our understanding of human rights, including the right\nto adequate housing. The HUDOC database provides access to the textual content of case\nlaw from the European Court of Human Rights (ECtHR), along with some metadata. While\nthis metadata includes valuable information, such as the application number and the articles\naddressed in a case, it often lacks detailed substantive insights, such as the specific issues\na case covers. This underscores the need for detailed analysis to extract such information.\nHowever, given the size of the database - containing over 40,000 cases - an automated solution\nis essential.\nIn this study, we focus on the right to adequate housing and aim to build models to detect\ncases related to housing and eviction issues. Our experiments show that the resulting models\nnot only provide performance comparable to more sophisticated approaches but are also\ninterpretable, offering explanations for their decisions by highlighting the most influential\nwords. The application of these models led to the identification of new cases that were\ninitially overlooked during data collection. This suggests that NLP approaches can be\neffectively applied to categorise case law based on the specific issues they address.", "sections": [{"title": "1 Introduction", "content": "Interpreting human rights in light of current conditions and developments in international law is crucial,\nrequiring legal scholars to continuously follow these changes [1]. In this context, courts' decisions play a\nfundamental role in legal research. Legal scholars often rely on these decisions to track the evolution of human\nrights interpretation, which adapts in response to societal changes and international consensus. Consequently,\nscholars frequently need to retrieve case law relevant to specific issues, such as housing problems.\nThe European Convention on Human Rights (ECHR) and the European Court of Human Rights (ECHR)\nplay an important role in the interpretation and protection of human rights across Europe. While the ECHR\nprovides a framework for protecting fundamental rights, the ECtHR ensures these rights are enforced in real\nlife by interpreting and applying the convention in specific cases. Thus, the HUDOC database, comprising\nthe decisions of the ECtHR, is an essential resource for legal scholars studying human rights in Europe. It\nprovides both textual content of cases and some metadata. While metadata contains useful information, such\nas the application number, articles, and citations, it does not have information such as what substantive issue\na case law covers which makes it difficult for a scholar who is interested in a specific topic. Due to the size of\nthe database, it is demanding to find efficient ways to extract such information.\nIn this paper we focus on one of these specific topics, namely housing. In the context of housing issues,\nprevious research has shown that Article 8 and Article 1 of Protocol 1 are particularly relevant, with the"}, {"title": "2 Data", "content": "For this paper, we collected all cases (judgments and decisions) within the HUDOC database published up to\nand including January 2023 for which (English) texts are available. This yields 41,621 cases. As the most\nrelevant articles within the ECHR concerning housing-related issues are Article 8 (right to respect for private,\nfamily life, home and correspondence) and Article 1 of Protocol No. 1 (right to protection of property), we\nfocused on these (13,343) cases for the creation of a dataset for building an automated system to detect\nhousing-related cases within the case law of the ECtHR.\nFollowing the methodology introduced in [11], we employed a combination of textual analysis and citation\npatterns to collect a set of cases potentially addressing housing issues. From this procedure, we collected\n1,108 potentially housing-related cases. Then, each decision/judgement was annotated manually to determine\nits relevance to housing issues and whether it addressed eviction specifically. The annotaters looked in\nthe facts of the case and the complaint of the applicant. If the facts or complaint predominantly concern\nsomeone's house, home, residence or accommodation the case was characterized as housing-related. The same\napplies if the case dealt with issues regarding landlords and tenants. The annotators also coded whether the\ncase is eviction-related or not. Eviction was defined as the loss of one's home, and a tenure-neutral broad\ndefinition was applied. As a result, tenants, homeowners, squatters and illegal occupiers could all be subject\nto an eviction. The annotaters were trained and used a code book. The inter-annotator agreement for these\nvariables was measured using Fleiss' kappa score. The kappa values varied between 0.81 and 0.89, which can\nbe considered to be (almost) perfect (0.81\u20131.00) agreement levels.\nAs expected, the majority (78%) of the 1,108 cases in our manually annotated dataset was housing-related,\nresulting in an imbalanced dataset. This can lead to the existence of bias in the model toward predicting\ncases as a housing-related case. To reduce this effect, we randomly selected 507 additional cases linked to\nArticle 8 ECHR or Article 1 of Protocol No. 1 ECHR which were not found to be related to housing-related\ncases using our textual analysis method [11]. A summary of the resulting dataset is presented in Table 1.\nWhile the majority of the new cases are indeed unrelated to housing issues, there are still quite a few cases\non housing that were not identified previously (12%). This shows that unsupervised methods, such as those\nin [11], may miss relevant cases. Therefore, it is necessary to assess whether new (supervised) models can be\ndeveloped that identify the characteristics of housing cases through a machine learning approach."}, {"title": "3 Method", "content": "In this section, we present an overview of the Adaptive Chordal Distance-based Subspace Learning Vector\nQuantization (AChorDS-LVQ) method, which we use to classify case law. To achieve this, we begin with a\nbrief introduction to the Generalized Learning Vector Quantization (GLVQ) framework, the foundation for\nthe AChorDS-LVQ method. We then give a summary of AChorDS-LVQ which combines the power of word\nembedding models with the explainability of GLVQ, offering a robust solution for applications that require\nboth accuracy and interpretability."}, {"title": "3.1 Generalized Learning Vector Quantization", "content": "Generalized Learning Vector Quantization (GLVQ) [24] represents a family of classifiers known for their\nintrinsic ability to explain their decisions. It utilizes a set of labelled prototypes, which are representative\nexamples summarizing the characteristics of each class. Because of its transparency, it has been applied in\ndifferent fields where it is necessary to have a transparent model, ranging from healthcare [25, 26, 27] and\neducation [28], to astronomy [29].\nLet ${\\{(Zi, yi)\\}}_{i=1}^N$ be the training set where $Zi \\in R^D$ is a training example and $yi$ is its corresponding label.\nGiven the training set, a GLVQ classifier models classes through a set of labelled prototypes, i.e.:\n${\\{(Wi, c(Wi)}\\}}_{i=1}^M$\nwhere $wi \\in R^D$ denotes a prototype vector and $c(\u0e1e\u0e35\u2081)$ is its corresponding label. As can be seen in the left\nvisualization presented in Fig. 1, prototypes capture major characteristics of each class and their distribution"}, {"title": "3.2 Adaptive Chordal Distance-based Subspace Learning Vector Quantization", "content": "The first step towards the classification of textual data such as case law of the ECtHR is to convert the\ntextual data to a numerical representation. In other words, we need to transform words into numbers such\nthat these numbers capture the meaning of the words. In simpler terms, if two words have similar meanings,\ntheir numerical representations (i.e. two series of numbers contained in two vectors) also need to be close to\neach other. With the advancement in word embedding techniques, several approaches have been developed to\ncapture the semantic meaning of words in numerical vectors. This has started with Word2Vec [30] and GloVe\n[31] which use the co-occurrence of words to determine similarity (e.g., 'cat' will more often co-occur with\n'dog' than with 'judge', and therefore the vector representations of 'cat' and 'dog' will be more similar than\nthat of 'cat' and 'judge'). These approaches therefore are an efficient and effective way to represent words\nand text through numbers.\nLet $doc = (word_1, word_2, ..., word_n)$ be a text with n words. A word embedding model assigns a vector\nrepresentation to each word, resulting in the text being represented as a set of vectors:\n$(word_1, word_2,..., word_n) \\xrightarrow{Glove} (V_1, V_2,..., V_n)$\nwhere $vi$ is the numerical representation for the i-th word $word_i$, called an embedding vector.\nThe conventional machine learning approaches, such as Support Vector Machines (SVM) and GLVQ, accept\none vector per example as input. To apply these methods to textual data, it is therefore necessary to\nsummarize an entire text into a single vector instead of a set of vectors. A common practice to prepare\ndata is to use the mean vector, i.e. $1/n \\sum_{i=1}^n Vi$. However, this summarization can result in losing valuable\ninformation needed to differentiate documents effectively.\nTo address this issue, AChorDS-LVQ [32] instead uses a set of vectors to represent a text. This approach\naligns better with the nature of texts, which consist of many words rather than a single word, thus preserving\nmore information and improving classification accuracy. Since the number of words n in documents can vary\nbetween documents, AChorDS-LVQ employs a dimension reduction technique, Singular Value Decomposition\n(SVD), to represent each document with a fixed number of vectors d:\n$(word_1, word_2,..., word_n) \\xrightarrow{Glove} (V_1, V_2,..., V_n) \\xrightarrow{SVD} (U_1, U_2,..., U_d)$\nBeing a member of the GLVQ family, AChorDS-LVQ defines a set of labeled prototypes ${\\{(Wi, Yi)}\\}}_{i=1}^M$. Unlike\nGLVQ, a prototype Wi consists of d vectors, instead of a single vector. The flexibility introduced by using\nseveral vectors for prototypes and documents results in a document-classification-model achieving comparable\nresults to Large Language Models (LLM) models. However, it requires less computational power [32], and\nmore importantly, AChorDS-LVQ provides insights about its decisions by quantifying the effect each word\nhas on its classification. As such, the model's logic is well-aligned with human expectations, as one can\ninspect which words have the highest impact on the model's decisions."}, {"title": "4 Experiment", "content": "In the following, we aim to develop classifiers to identify cases dealing with housing and eviction issues from\nArticle 8 ECHR and Article 1 of the First Protocol ECHR. First, we create and evaluate models that classify\ncase law based on whether they concern a housing issue or not on the basis of our constructed dataset. Then,\nwe used the obtained models to classify new cases not in our constructed dataset to identify potential new\nhousing-related cases. Specifically, we first apply our models to unseen cases addressing Article 8 and Article\n1 of Protocol No. 1. This is followed by using our models to identify housing-related cases from the set of\ncases not linked to these articles. This second approach aims to evaluate how much the knowledge learned by\nmodels from Article 8 and Article 1 of Protocol No. 1 is transferable to identifying housing-related case law\nfrom the other articles in the ECHR."}, {"title": "4.1 Experimental Setup", "content": "Our goal is to develop binary classifiers to label case law documents as either not addressing a housing-related\nissue (0), or addressing a housing-related issue (1). Similarly, we create binary classifiers labeling case law\ndocuments as eviction-related or not. In order to generate the training and test sets, we randomly select 80%\nof the cases in our manually annotated dataset as training examples, and we use the rest of the dataset to\nevaluate our approach. This results in 1,292 cases used for training (728 on housing and 561 on evictions)\nand 323 cases for testing (200 on housing and 143 on evictions).\nGiven the limited amount of annotated data available (fewer than 2000 cases), we use two strategies for\nbuilding our classifiers:\n\u2022 Learning from scratch: this approach involves training models from the ground up using our annotated\ndataset. However, due to the small size dataset, only models with lower complexity are feasible, such\nas SVM, GRLGQ[33] and AChorDS-LVQ[32].\n\u2022 Fine-tunning Large Language Models (LLM): Through technological advances, we have access to\nmore complex models with millions (or billions) of parameters. These models are trained on large\ncorpora of texts, seemingly obtaining somewhat of an understanding of the structure of human\nlanguage. These models can subsequently be fine-tuned with smaller datasets for specific tasks, such\nas in this case classifying legal documents.\nIn this study, we trained SVM, GRLGQ[33] and AChorDS-LVQ[32] models from scratch. Additionally,\nwe fine-tuned three large pre-trained models: a) Bidirectional Encoder Representations from Transformers\n(BERT) pre-trained on general texts, b) Legal-BERT pre-trained on legal data, and c) Longformer pre-trained\non general texts but designed to accept longer texts.\nTo train our models, we first need to prepare the documents appropriately. For simpler models, we must\nconvert the text into numerical representations. A common method for this is to use word embedding models,\nsuch as Word2Vec and GloVe. Following the approach outlined in [32], we use the GloVe model to represent\nthe text. The preprocessing steps are as follows:\n1. Stop words removal: We begin by removing all stop words (i.e. uninformative function words), such\nas 'and' and 'is', to reduce the influence of common words that add little value to the document's\nmeaning.\n2. Word embedding: Using the GloVe model, we generate a vector representation for each word in the\ndocument.\n3. Case law representation:\n\u2022 SVM: We represent each document by calculating the mean vector of all the word vectors\ngenerated by GloVe.\n\u2022 GRLGQ and AChorDS-LVQ: For these models, we apply Singular Value Decomposition (SVD)\nto the word vectors to generate the appropriate document representation with multiple vectors.\nThis process generates the required input for SVM, GRLGQ and AChorDS-LVQ.\nDue to the computational complexity, transformer-based language models, such as BERT, have a limit on\nthe length of text they can process, known as the context window. For instance, BERT and LegalBERT are\nrestricted to a maximum of 512 tokens. There are several approaches to address this limitation. A common\napproach to tackle this challenge is to segment the long text into smaller pieces and then perform prediction"}, {"title": "4.2 Model performance", "content": "Table 4.2 shows the performance of the different approaches in the classification of case law. For the classifier\nthat detects housing-related cases, we see that the AChorDS-LVQ and GRLGQ provide comparable results\nto the transformer-based models, with the more computationally efficient AChorDS-LVQ yielding the best\nperformance. This suggests that AChorDS-LVQ and GRLVQ offer a cost-effective solution for creating models\nto detect relevant cases, making them suitable for applications using large legal databases.\nFor the eviction classifier, all models achieve a lower performance compared to the housing classifiers. This\ndifference is due to the smaller number of eviction-related examples in the training set. In this context,\nLegalBERTlong outperforms the others. One possible reason for this is that LegalBERT, which was pre-trained\non legal data, already has a general understanding of legal texts, enabling it to achieve a higher accuracy\neven with small datasets. Despite providing slightly lower accuracy, AChorDS-LVQ still delivers acceptable\nresults, offering a good balance between accuracy and computational cost. As it also allows for explainable\nresults, we have opted to use AChorDS-LVQ in our analysis of the HUDOC database.\nAs previously mentioned, AChorDS-LVQ is a transparent model, which means that it specifies the impact of\neach word from the case law document on its final decision. To illustrate this, we consider one case from each\nclass and demonstrate which words have a high impact on the model's decision.\nSpecifically, we applied the model to the decision with application number 11185/84. The model correctly\npredicts that the case involves a housing-related issue, and it also assigns a numerical value to each word,\nindicating its influence on our model's decision. The left graph shown in Fig. 2 displays several words with the\nhighest impact. The blue bar represents the extent to which a word supports the correct class (i.e. \u2018housing').\nThe larger (i.e. more towards the right) the blue bar, the more important the word is for the correct class\n'housing'. Conversely, the smaller (i.e. more towards the left) the blue bar, the more important the word is\nfor the incorrect class 'non-housing'. It can be seen that words such as property, home, residence, and bunker\nare important for housing-related cases, aligning well with our intuition. Additionally, we observe that while\nhousing-related terms correctly support the claim that the case covers a housing issue, procedural terms such\nas 'convention', 'article', and 'court' do not.\nSimilarly, we utilized the model to analyze the ECtHR's decision with application number 1088/10. The\nmodel correctly classifies this case as non-housing-related. The right graph shown in Fig. 2 highlights the\nmost important words influencing this prediction. For this particular case, words such as 'prison', 'cell' and\n'detainee' are highlighted by the model. These terms suggest that this case is related to prison conditions,\nthereby reinforcing the model's classification. This detailed analysis confirms the model's capability to\naccurately interpret and classify case law based on the specific terminology used, thereby also showcasing its\nreliability and transparency."}, {"title": "4.3 Detection of new housing-related cases within Article 8 and Article 1 of Protocol No. 1", "content": "In the HUDOC database, there are 13,343 cases addressing Article 8 or Article 1 of Protocol 1 ECHR. As\nindicated, we have manually coded 1,615 cases of these cases (12%). To identify other housing-related cases,\nwe applied the same model, used in the previous section, to all these cases. This resulted in the detection\nof 1,738 cases which are potentially related to housing issues. Given the large number of newly detected\ncases and the time-consuming process of manual annotation, it may be useful to prioritize the cases with the\nhighest likelihood of being housing-related. We therefore developed a way to convert the model's outputs\ninto probability scores. These scores represent the likelihood that a given case is related to housing, allowing\nus to rank the cases accordingly. As a result, we can more effectively focus on the most relevant cases.\nFollowing the definition of the cost function in Equation 1, we use the calculated distances to prototypes to\ndefine the probability of a case being related to housing as follows:\n$P(case is on housing) = sgd\\left(\\frac{`d(xi, W_{NH}) \u2013 d(xi, W_{H})}{d(xi, W_{NH}) + d(xi, W_{H})}\\right)$\nwhere $d(x_i, W_{NH})$ and $d(x_i, W_{H})$ represent the distance between the document $i$ and the prototypes of\nnon-housing (NH) and housing (H), respectively.\nThe left graph shown in Fig. 4 shows the distribution of probability scores for cases being housing-related.\nAs expected, most cases receive low scores, indicating that they are most likely not related to housing. Using\nthese scores, we can set a threshold to identify cases with a high likelihood of being housing-related. By\ndefault, the model predicts a case to be about housing if its score is above 0.5.\nTo identify the appropriate threshold, we have calculated the percentile associated with each score. In this\nway, we found that the 88th percentile was associated with a score of 0.502. We then randomly selected and\nannotated 20 cases from each of the top 13 percentiles. The right graph of Fig. 4 shows the results of the\nmanual check. Specifically, these results illustrate a direct relationship between the scores and the likelihood\nof being a housing-related case. Setting a high score threshold will thus result in most of the selected cases\nbeing housing-related, whereas a lower threshold may include more non-related cases. For example, setting\nthe score threshold to 0.91 would result in cases which are more than 95% likely to be housing-related. Of"}, {"title": "4.4 Detection of new cases from other articles in the ECHR", "content": "While Article 8 and Article 1 of Protocol No. 1 ECHR are typically the primary articles addressing housing-\nrelated issues, other articles may also deal with housing and eviction-related issues. Thus, to improve the\ncomprehensiveness of our housing-related dataset, we applied our model also to the remaining HUDOC\ndatabase, which comprises 28,278 cases, aiming to detect potentially housing-related cases from other articles.\nAmong these, the model predicted 567 new cases (with probability scores higher than 0.5) that are likely\nrelated to housing.\nSimilar to the previous experiment, we computed the probability scores representing the likelihood of cases\nbeing related to housing. The left graph shown in Fig. 5 illustrates the distribution of these scores. The\nmajority of cases receive low scores, with only the top two percentiles receiving scores above 0.5.\nTo assess the model's performance across different score ranges, we randomly selected and annotated 40 cases\n(per percentile) from the top six percentile (i.e. scores greater than 0.21). The right graph shown in Fig. 5\npresents the annotated results. As expected, the model's performance is lower for these cases compared to\nthose under Article 8 and Article 1 of Protocol 1, reflecting the specific training focus. Nevertheless, this\nmodel remains valuable by detecting relevant cases from other articles that might otherwise be overlooked,\nparticularly if a higher threshold is used (i.e. using a threshold of 0.71 would result in an expected 82.5% of\ncases being related to housing).\nAdditionally, we observe that the probability of a case being housing-related generally also appears to decrease\nas scores decrease (i.e. a score of 0.52 has only a 47.5% chance of being housing-related, whereas this is only\n7.5% for a score of 0.25). We also observe that the percentage of correctly classified relevant cases experiences\na sharp drop from 82.5% (for cases with scores above 0.71) to 47.5% (for cases with scores between 0.52 and\n0.71). This shows the importance of setting a higher threshold to focus on cases the model is more confident\nabout (i.e. above 0.71), although cases with lower scores can still be reviewed when human annotators are\navailable (as the probability of identifying housing-related cases, even for the percentiles associated with\nlower scores is greater than 0).\nThis experiment again shows the model's utility in identifying and prioritizing cases based on their likelihood\nof being relevant, enabling legal scholars to identify housing-related decisions across various legal articles and\nthereby gaining deeper insights into judicial decisions when analyzing this larger set of cases."}, {"title": "5 Conclusion", "content": "As international human rights conventions are considered 'living instruments', legal scholars must continuously\ntrack the developments of conventions to enhance our understanding of human rights. In this context,\nempirical research on court decisions plays an important role in our understanding of the interpretation and\napplication of these conventions. However, this task is challenging given the large legal databases, and it is\ntherefore necessary to be able to automatically identify relevant case law on specific issues. In this study, we\ndeveloped and evaluated models specifically designed to retrieve housing and eviction-related cases from the\nHUDOC database. Our primary objective was to improve the retrieval of relevant cases, thereby helping\nlegal scholars in their analysis of housing rights within the European Convention on Human Rights (ECHR).\nTo achieve this, we first created a dataset on housing issues using an unsupervised process introduced in [11],\nwhich was manually corrected and extended. We then created various machine learning models to classify\ncase law based on whether it covered the subject of interest (i.e. housing). Through our experiments, we\ndemonstrated that the AChorDS-LVQ model provides comparable performance to transformer-based models\nwhile offering more transparency and requiring a lower computational cost.\nWe then applied our models to the unannotated data within the HUDOC database, resulting in the detection\nof many new cases related to housing and eviction issues. Specifically, we identified 1.738 potentially new\ncases addressing Article 8 and Article 1 of Protocol No. 1 (our subsequent manual analysis of a subset of size\n260 indicates that about 226 of these will actually be housing-related), and 567 cases from other articles are\npotentially housing-related (our manual analysis on 240 of these cases, reveals that 84 of these are expected\nto be actually housing-related). Importantly, our model provides scores that can be used to prioritize cases.\nThis scoring system allows for a more efficient allocation of resources, ensuring that the most relevant cases\nare reviewed and annotated first. Our method is therefore quite effective in enriching datasets with new cases\nwhich are not easily identified through other (unsupervised) automatic means.\nIn conclusion, our work highlights the potential of the AChorDS-LVQ model in the legal domain, offering a\npractical and effective tool for legal case classification and retrieval. This approach enhances the comprehen-\nsiveness of empirical legal research on case law by helping the retrieval of more relevant cases. Future studies\ncould further explore the applicability of AChorDS-LVQ to other legal classification tasks."}]}