{"title": "Transforming the Hybrid Cloud for Emerging AI Workloads", "authors": ["Deming Chen", "Alaa Youssef", "Ruchi Pendse", "Andr\u00e9 Schleife", "Bryan K. Clark", "Hendrik Hamann", "Jingrui He", "Teodoro Laino", "Lav Varshney", "Yuxiong Wang", "Avirup Sil", "Reyhaneh Jabbarvand", "Tianyin Xu", "Volodymyr Kindratenko", "Carlos Costa", "Sarita Adve", "Charith Mendis", "Minjia Zhang", "Santiago N\u00fa\u00f1ez-Corrales", "Raghu Ganti", "Mudhakar Srivatsa", "Nam Sung Kim", "Josep Torrellas", "Jian Huang", "Seetharami Seelam", "Klara Nahrstedt", "Tarek Abdelzaher", "Tamar Eilam", "Huimin Zhao", "Matteo Manica", "Ravishankar lyer", "Martin Hirzel", "Vikram Adve", "Darko Marinov", "Hubertus Franke", "Hanghang Tong", "Elizabeth Ainsworth", "Han Zhao", "Deepak Vasisht", "Minh Do", "Fabio Oliveira", "Giovanni Pacificit", "Ruchir Puri", "Priya Nagpurkar"], "abstract": "This white paper, developed through close collaboration between IBM Research and University of Illinois Urbana-Champaign researchers within the IBM-Illinois Discovery Accelerator Institute (IIDAI), envisions transforming hybrid cloud systems to meet the growing complexity of Al workloads through innovative, full-stack co-design approaches, emphasizing usability, manageability, affordability, adaptability, efficiency, and scalability. By integrating cutting-edge technologies such as generative and agentic Al, cross-layer automation and optimization, unified control plane, and composable and adaptive system architecture, the proposed framework addresses critical challenges in energy efficiency, performance, and cost-effectiveness. Incorporating quantum computing as it matures will enable quantum-accelerated simulations for materials science, climate modeling, and other high-impact domains. Collaborative efforts between academia and industry are central to this vision, driving advancements in foundation models for material design and climate solutions, scalable multimodal data processing, and enhanced physics-based Al emulators for applications like weather forecasting and carbon sequestration. Research priorities include advancing Al agentic systems, LLM as an Abstraction (LLMaaA), Al model optimization and unified abstractions across heterogeneous infrastructure, end-to-end edge-cloud transformation, efficient programming model, middleware and platform, secure infrastructure, application-adaptive cloud systems, and new quantum-classical collaborative workflows. These ideas and solutions encompass both theoretical and practical research questions, requiring coordinated input and support from the research community. This joint initiative aims to establish hybrid clouds as secure, efficient, and sustainable platforms, fostering breakthroughs in Al-driven applications and scientific discovery across academia, industry, and society.", "sections": [{"title": "Executive Summary", "content": "Our goal over the next 5-10 years is to identify new computing, storage, and communication elements, sub-systems, and innovations across all stack levels to transform the hybrid cloud for emerging artificial intelligence (AI) workloads. In this white paper, we intend to answer the following two key questions: (1) What is possible? (2) What would be the outcome? We envision a reimagined hybrid cloud system featuring a fully integrated and optimized stack that supports a wide range of Al frameworks, runtimes, tools, and various hardware resources, including cache-coherent interconnects, SmartNiCs, Al accelerators, and quantum computers - just to name a few. This will ensure that Al remains a dynamic and transformative force in years to come. Our aspiration is to achieve a 100-1000x improvement in performance/watt when all the pieces come together.\nGenerative Al (Gen Al), foundation models (FMs), and large language models (LLMs) represent significant advancements in Al technology. These innovations have the potential to revolutionize various sectors by enabling more sophisticated and context-aware applications. Market research anticipates substantial growth in the Al sector over the next 5-10 years. The demand for Al-driven solutions is expected to skyrocket as industries recognize the potential of Gen Al, FMs, and LLMs to drive efficiency, innovation, and competitive advantage.\nThese Al models need terabytes or petabytes of data to train and often require more advanced memory architectures and storage solutions to handle the vast amounts of data and model parameters. Meanwhile, given the layers of such Al models are interdependent, and transformer architectures and attention mechanisms require close coordination between tokens in a sequence, such tightly coupled computations necessitate high-speed interconnections and synchronization across numerous hardware components. In addition, such Al models are rapidly advancing and evolving, experiencing exponential increase in model size and data, requiring heterogenous hardware environment with various Al accelerators, and demanding high throughput, high energy efficiency, and dependable performance and accuracy. All these differ from traditional high-performance computing (HPC) workloads in their complexity, computational demands, infrastructure needs, and breadth of applications.\nMost importantly, the compute system to support such Al workloads must be affordable to ensure broad accessibility and adoption. Cost-effective solutions leveraging cloud-based technologies and scalable hardware systems are essential to support the widespread use of the advanced Al models. Additionally, the complexity of these systems necessitates innovative approaches to manage and simplify their design, deployment, and operation. Overall, managing complexity, ensuring cost-effectiveness, maintaining sustainability and efficiency, and being adaptive for rapidly changing workload characteristics and demands are key challenges that must be addressed to drive the momentum of Al advancements.\nTo address these key challenges, we call upon the research community to optimize and redesign application, middleware, platform, infrastructure, and hardware layers of cloud systems, while also implementing intelligent and scalable full-stack system management solutions. Incorporating new enabling technologies, such as agentic Al, unified control plane, cross-layer automation and integration, and composable and adaptive design approaches, will be critical to support these advancements.\nTo maximize the usability of Al technologies, it is important to develop new application interfaces that make it easier for users (and developers) to interact with and use Al models and frameworks. We propose LLM-as-an-Abstraction (LLMaaA), which relies on agentic Al frameworks to enable a natural language-based user interface for building, deploying, and managing complex applications. Efficient scaling and optimization of emerging Al models are essential for maximizing their impact on real-world applications. New reconfigurability and adaptability features should be explored across various system levels to dynamically optimize cloud resources for specific workload requirements and integrate emerging technologies efficiently. The expansion of cloud computing to the edge, and the development of smart cooperative edge-to-cloud computing models, further enhances the capabilities of Al systems, enabling real-time processing and decision making at the point of need. This evolution brings additional challenges related to data distribution, security, privacy, and latency."}, {"title": "Introduction", "content": "IBM and the Grainger College of Engineering at the University of Illinois Urbana-Champaign launched the IBM-Illinois Discovery Accelerator Institute in 2021 to combine the strengths of academia and industry to spur breakthroughs in the rapidly growing areas of hybrid cloud, Al, quantum computing, and Al-driven scientific computing applications for material discovery, climate and sustainability. Subsequently, the Institute announced a new call for proposals for multi-year projects in March of 2023.\nIn this white paper, for each of the focus areas, we outline challenges and opportunities, state-of-the-art solutions based on ongoing IBM-Illinois collaborations, and the long-term vision and the technical approach and research priorities of the Institute.\nThe growing adoption of Al-driven applications is leading to a significant surge in demand for high-performance computing resources. Recently, LLMs, with billions of parameters and trained on terabytes of data, have shown outstanding capabilities in handling a plethora of tasks. We expect this trend to continue with increase in number of parameters, amount of training data, and modalities of foundation models. The demand for more performant and optimized cloud platforms and infrastructure continues to rise, driven by the need for efficient training, fine-tuning, and inference of advanced Al models. Simultaneously, the maturation of quantum computing technologies necessitates thinking about their integration, challenges, and expected potential in the context of hybrid cloud systems. In this paper, we show how the resulting cost, complexity, and fragmentation of existing technologies and solutions cannot meet such demand, and we lay out our grand vision for a converged, adaptive, high-performant, affordable, consumable, and ubiquitously accessible hybrid cloud system.\nOver the past sixty years, supercomputing has been instrumental to fundamental discoveries in scientific areas such as physics, astronomy, and medicine. Researchers and engineers have used supercomputing to study, simulate, and predict complex systems such as weather, financial systems, air travel, and more. Over the last fifteen years, supercomputing has enabled new fields, such as big data analytics and Al foundation models. Today, more than ever, the ability to drive new drugs or material discoveries, understand and manage complex systems like the earth's climate, or create ever more powerful intelligent automation depends on the ever-increased power of Al-enabled applications and systems.\nHowever, the growing power of Al systems is being increasingly challenged by their rising complexity and cost. When developing future Al-enabled applications, teams must navigate the intricacies of large distributed systems, manage heterogeneous platforms and infrastructures, and now face the added complexity introduced by quantum computing. Balancing these demands while ensuring efficiency and affordability presents a significant challenge for future development. As a result, such applications require large teams and development cycles spanning months and years. What is even more problematic, the cost and amount of specialized computing resources required have grown significantly over time, making it no longer affordable for many university and scientific institutions. Furthermore, the energy required to train large Al models and run today's Al-enabled applications makes them unsustainable. The effort to build the Al platforms and applications of tomorrow will likely reach a regime of diminishing returns in multiple dimensions unless new ideas arise.\nIn this paper, we will highlight a new research program that the IBM-Illinois Discovery Accelerator Institute (IIDAI) has launched to tackle these challenges and change the current path of Al computing to make it more efficient, affordable, and accessible to enable the next generation of Al-enabled applications.\nWe are committed to fostering and developing a new generation of ideas that will revolutionize how we conceptualize, design, and operate the future hybrid cloud for emerging Al workloads. Our vision focuses on creating cloud systems that prioritize ease of use, affordability, adaptability, and ubiquity at massive scales. These ideas encompass both theoretical foundations and applied research questions, which require the collective input and support of the broader research community. Our role is to lead, catalyze, and nurture the conditions for these innovations to come to fruition."}, {"title": "Evolution of High-Performance Computing", "content": "For many years, the field of High-Performance Computing (HPC) has been dedicated to enabling scientific exploration and discovery through large-scale simulations and modeling in domains such as physics, biology, climate science, and many other fields. Traditional HPC applications were often developed as monolithic programs written in languages like FORTRAN and ran on single, large systems, such as those provided by Cray supercomputers.\nDistributed computing clusters built with x86 machines emerged and delivered the needed performance for HPC simulations using frameworks for parallel processing like MPI. Such systems were crucial to fulfill the potential of supercomputers anticipated by the Atkins report in 2003 [1]. Initiatives such as TeraGrid and XSEDE then made these compute resources accessible to thousands of research scientists, reinvigorating science as a whole. This in turn enabled widespread access to modeling and simulation, a de facto third leg of science [2] alongside theory and experiment. Scientific computing applications continued to evolve and started to encompass new areas such as data analytics and machine learning (ML), which introduced corresponding heterogeneity in supporting platforms and infrastructures."}, {"title": "Today's Al-infused Scientific Computing Applications, Platforms, and Infrastructures", "content": "Today, scientific computing applications span multiple computing paradigms, many platforms, and a variety of heterogeneous infrastructure requirements, as shown in Figure 1. Besides classical simulations, big data analytics, Al and machine learning are being used heavily. Each application component requires dedicated platform-level support, for instance, Spark for data analytics, PyTorch for Al training, and Ray for machine learning processing and model serving. Additionally, the rise of massively parallel distributed clusters and specialized hardware accelerators like GPUs, TPUs, and FPGAs has enabled highly efficient processing of specific tasks. These resources, essential for handling Al workloads, are now readily accessible in the cloud, making the combination of Cloud + Al a promising approach for advancing many HPC applications.\nAl-infused simulation is a fast-growing application paradigm in HPC. For example, in a cancer research application that simulates protein interactions at different scales of resolution with physics and molecular dynamics ensembles, the infusion of Al techniques in simulations accelerates search-space exploration by orders of magnitude. To accomplish such complex tasks, the combination of batch schedulers, such as Flux and Slurm, on massively parallel computers like IBM Summit [54], along with specialized accelerators and distributed cloud clusters for Al model training and inference, is essential."}, {"title": "Al-centric Hybrid Cloud Computing of the Future", "content": "Tomorrow, the future hybrid cloud will enable next-generation applications, which embrace fast-growing Al workloads, such as large language models and other types of Gen-Al workloads, big data analysis, Al-driven simulations, quantum resources and algorithms, to tackle new challenging problems in more efficient and integrated ways.\nMore precisely, we envision systems that exhibit the following properties:\n\u2022 Easy to consume by scientists, and will need to seamlessly leverage Classical, Al, and Quantum computing capabilities, from within the same hybrid cloud context. They will automatically map high-level task descriptions to the low-level optimized constructs.\n\u2022 Affordability of such systems is a critical requirement to democratize access to resources. We envision a new breed of systems and specialized computing elements with 100x cost/performance improvements over today's technology.\n\u2022 Ubiquitous access to ensure demand fulfilment with abundant resource availability everywhere, is yet another requirement for these systems. Accessing these systems will be more similar to plugging into a standardized outlet than performing a request based on a detailed specification.\nThe table below highlights how evolving needs in HPC systems have been incrementally addressed through specific technical advancements. Despite the success of these responses, continued reliance on traditional approaches will fall short when scaling to more complex hybrid systems. We believe that new, innovative ideas are essential to tackle the future challenges of ease of use, adaptability, affordability, and ubiquity at greater problem and system scales."}, {"title": "Challenges of Al-centric Hybrid Cloud Computing", "content": "Al-centric hybrid cloud systems are complex, difficult to model at operationally relevant levels of detail, costly, and unsustainable due to the inherent challenges of their massive scale. These issues, which will be explored in the following subsections, present significant barriers to future progress. In short, current knowledge, infrastructure, and tools are insufficient to propel future computing systems forward by orders of magnitude without encountering severely diminishing returns. Addressing these challenges requires fresh approaches to sustain scalability and efficiency at larger system scales."}, {"title": "Complexity and Difficult Consumability", "content": "In the words of the late Richard Hamming, \"the purpose of computing is insight, not numbers\" [3]. The co-evolution of scientific goals and computational infrastructure has been a defining factor in shaping research-driven software and hardware over the past 80 years. We've progressed from calculating non-elementary integrals with a few parameters to analyzing petabytes of video streams in near real-time, thanks to a positive feedback loop between the ever-growing challenges in research and the continuous advancements in computational capacity. In essence, as the complexity, volatility, and uncertainty of today's major research challenges continue to grow, the development and application of future computing systems are poised to generate significant, transformative insights.\nHardware heterogeneity in contemporary Al-centric hybrid cloud computing has been on the rise, causing increased complexity for the acquisition, integration, programming and administration of these systems. A mix of CPUs, GPUs, TPUs, FPGAs, and other specialized hardware accelerators that provide higher performance at higher energy efficiency entails multiple programming paradigms, new physical and logical constraints, and even higher hardware procurement uncertainty across market value chains. To make matters worse, the need to access increasingly scarce compute resources requires bursting from on-premise private clouds to multiple cloud providers, which do not offer a uniform management interface and introduce variance in the offered resource types, their cost, and cost models.\nThese distributed computing platforms come with their own challenges in scaling, distributed data movement, consistency and synchronization, scheduling and resource management, fault tolerance, and resiliency, just to name a few. Management and operations of each of these distributed computing platforms require deep talent and skills. A single team having to manage multiple of these platforms might find the task daunting.\nHPC and Al systems today use a variety of programming models, frameworks, and libraries at different layers of abstraction. This wide range includes low-level GPU programming models like CUDA and NCCL, all the way to higher-level frameworks and abstractions like OpenMP, PyTorch, Spark and Ray. In addition, many workflow managers are in use today, such as Airflow, Makeflow, Pegasus, Argo, Parsl, etc. Moreover, a mixture of schedulers for bare-metal (e.g., LSF, Slurm), virtualized, and container systems (e.g., Kubernetes, OpenShift) are used. There is no single, unified, easy way to program or administer these systems. Such a diverse composition of interfaces, programming models, runtimes, and infrastructure systems leads to difficult consumability. A unified abstraction layer is therefore needed."}, {"title": "Complexity of Engineering Very Large-scale Systems", "content": "Increasing demands on Al and computing infrastructure have affected the resilience, operation, programmability, and design of Al-centric cloud systems. We anticipate that future systems will achieve unprecedented levels of integration, growing by orders of magnitude compared to today's systems. Reflecting on the behavior of these systems, we can draw the following key observations.\nVery high hardware and data volumes necessitate thinking at the thermodynamic limit. Current error rates per bit reach 10^(-24) in the best-case scenario. In a system running at 1 exaflop (10^(18)), one would need 10^(6) seconds (~11.6 days) to observe an error. These error rates and number of bits are commensurate with Avogadro's number and Boltzmann's constant respectively, which justify thinking about computing as a phenomenon at thermodynamic limit through the tools of statistical physics. Moving from exaflops to zettaflops and beyond will justify even more such treatment into higher data units (e.g., bits to bytes).\nVery large hybrid hardware platforms and complex software workflows follow known scaling laws driven by constraints. As the number and diversity of processing elements grow, the structure and communication patterns of these computing systems converge to hierarchical modularity. In particular, patterns of specialization and information integration have been shown to follow Rent's rule [4]. Rentian scaling arises in systems whose evolution is driven by the economics of constraints (e.g., energy consumption, complexity) and utility (e.g., efficiency, functionality).\nVery large hybrid hardware platforms and complex software workflows also emerge compositionally. The properties of individual nodes and processing elements determine the ability of an entire system to compute at scale. The laws that govern the result depend to a large extent on the resources and modes of interaction these elements provide. For instance, space and time comprise the main resources for CPU, GPU, TPU, AIU, and FPGA architectures, while QPUs (Quantum Processing Units) add superposition, interference and entanglement. The ability to understand and predict system properties based on those of its components will be essential, yet increasingly complex as more diverse elements are introduced.\nVery large hybrid hardware platforms increase software complexity. The number of possible bugs in a program appears to be directly proportional to the number of lines of code and the number of different kinds of compute elements involved. Beyond correctness, this growing complexity produces two classes of bottlenecks: one in which the probability of finding the skill set to write scientific software decreases as more technologies are added, and another one in which optimizing code execution becomes increasingly difficult and can fall outside of human ability in the future."}, {"title": "Limited Affordability and Adaptability", "content": "Al-centered computing is expensive. Moreover, the total expenses of running the system are not fixed, but depend on various factors that change over time and are influenced by market forces. These include the costs of operation, maintenance, and energy consumption, which may increase (typically) or decrease (seldom) depending on the demand and supply.\nWe believe that an industrial-academic collaboration is the best approach to achieve the best advanced technical results at reasonable cost. We have seen many successful cases of this model, where the synergy between the two sectors led to breakthroughs that would not have been possible otherwise. It is encouraging to see that very large-scale academic collaboration has led to results matching focused"}, {"title": "Transforming the Hybrid Cloud for the Future", "content": "The IBM-Illinois shared vision for IIDAI is to transform the hybrid cloud systematically, addressing the various challenges outlined in Section 3. Our goal is to identify new computing, storage, and communication elements, sub-systems, and innovations across the various layers of the whole cloud computing stack. We envision a reimagined hybrid cloud platform and infrastructure featuring a fully integrated and optimized stack that supports a wide range of Al frameworks, runtime middleware, tools, and hardware. This will ensure that Al remains a dynamic and transformative force in the years to come, while understanding how quantum technologies will integrate to it with a more strategic outlook. Our aspiration is to achieve a 100-1000x improvement in performance/watt when all the pieces come together. Our focus is on ease of use, affordability, adaptability, and ubiquity at very large scales.\nEmerging compute-intensive workloads, especially driven by the disruptive new Al/ML techniques, are increasingly complex workflows with wide-ranging compute and data requirements. From the remarkable rise of large-scale distributed training leading to self-supervised models (also known as foundation models), to complex workflows mixing workloads with different characteristics, such as asynchronous, batch jobs (e.g., data ingestion, pre-processing, and training), and synchronous, interactive computations (e.g., model inference), these workloads commonly span multiple steps in different computing environments. They leverage and benefit from an increasingly wide range of computing resources, from commodity CPUs, to high-end GPUs, to specialized Al accelerators, and upcoming quantum devices.\nCloud computing technology has transformed how heterogenous computing resources can be used through multiple layers of abstraction, from programming models to platform and infrastructure. Cross-layer orchestration technology, driven by these abstractions, enables elasticity, fault-tolerance, and flexibility. Historically, however, the majority of distributed, large-scale applications and commonly used libraries have been written with programming models developed for a fixed, homogeneous architecture in a contained environment (e.g., MPI). While this fixed topology is efficient, it prevents the new class of emerging Al/ML applications to benefit from cloud-native computing's key underlying characteristics, such as elasticity, fault-tolerance, cost and resource efficiency, and portability.\nMeanwhile, with the rapid growth of emerging Al/ML applications, existing cloud-native solutions are facing significant challenges to their relevance for these applications, especially in terms of consumability, affordability, adaptability, and complexity, as outlined in Section 3. Looking ahead, we envision the development of a next-generation hybrid cloud system designed to tackle these multi-dimensional challenges posed by the evolving workflows in AI/ML and Al-centric scientific computing domains. This future system must be capable of addressing the growing application demands while providing greater flexibility, robustness, efficiency, affordability, and sustainability.\nAs illustrated in Figure 6, this new vision spans across multiple layers of the system stack. First of all, we propose a groundbreaking computing paradigm that fundamentally transforms how humans interact with complex computer systems. At its core is the concept of LLM as an Abstraction (LLMaaA), which leverages advanced language models to create a natural, intuitive interface between humans and machines. This vision centers on an enhanced cloud-native system that integrates heterogeneous computing resources under the governance of LLMaaA. This new cloud system will incorporate Al-driven middleware/runtime for sophisticated workflow orchestration, provide dynamic resource allocation and robust error handling to ensure continuous operation, offer a unified interface and abstraction to diverse computing environments, from edge devices to powerful servers and accelerators, and enable seamless communication and coordination between different system layers, from hardware to application.\nThe key to realizing this future vision lies in the development of intelligent Al agents that leverage large language models, including a newly proposed framework called THINKagents. These agents will plan and execute complex workflows, debug issues across the system stack, generate comprehensive reports, observe system behavior and performance, control resource allocation and task scheduling, and communicate with each other and with human users.\nTo fully harness the power of LLMaaA, we must reimagine and re-engineer existing abstractions and tools. This involves implementing intelligent, vertical cross-layer automation flows to optimize resource utilization and workflow execution, developing mechanisms across different system components and layers for integration, efficiency, and adaptability, as well as creating comprehensive monitoring and analytics capabilities that span the entire system stack, thus providing accurate assessment and timely delivery of desired quality of results. Our aim is to ensure efficient scheduling, adaptive workload management and orchestration, flexible laaS (Infrastructure as a Service) and PaaS (Platform as a Service), cross-layer robustness and security, and guaranteed SLOs (Service Level Objectives).\nHorizontally, a unified control plane (Figure 6) is essential for managing heterogeneous computing resources across different environments, such as on-prem data center, private cloud, public cloud, and edge. As resource managers like Kubernetes and LSF/Slurm become specialized for distinct workloads, there is a need for Al-powered middleware/runtime to automatically orchestrate resources across these systems while working with different platforms seamlessly and efficiently, enabled by this unified control plane. A multi-cloud broker can decompose computing jobs and map them to the most appropriate resource managers across the edge-cloud system.\nAt the infrastructure and hardware level, emerging cache-coherent interconnects like Compute Express Link (CXL) and Ultra Accelerator Link (UAL) offer revolutionary potential for improving data transfer and enabling cooperative heterogeneous computing. These technologies provide cache-coherent host-to-device and device-to-host memory access, simplifying data movement with load/store semantics rather than complex DMA transfers. Coupled with software-defined interface between the infrastructure and hardware layers, future systems can integrate memory, storage, and network devices with near-data processing (NDP) capabilities, allowing fine-grained cross-device cooperation. This approach promises to dramatically reduce ML training and inference costs by optimizing resource use across devices based on specific computational requirements of individual ML model layers, offering unprecedented efficiency and flexibility with better affordability.\nOverall, we desire to offer a more cohesive, forward-looking approach to address the challenges and opportunities in hybrid cloud environments for emerging Al/ML workloads and enhance and reinvent the latest hardware and software technologies, while ensuring the systems are scalable, highly performant, energy-efficient, and robust enough to handle increasingly complex workloads distributed across the edge and cloud systems. With this broad vision, we have identified the following important future research directions to drive the next generation of innovation and creativity."}, {"title": "THINKagents: A Research Framework for Agentic Systems", "content": "A major research focus is improving Al agent collaboration through transactive memory, enhancing specialization and group intelligence. We propose THINKagents \u2013 a new agentic Al research framework. Leveraging this framework, future research should explore how Al agents collaborate like human collective intelligence, enabling them to avoid collective mistakes and achieve higher levels of intelligence. By leveraging memory systems, specialized tools, and planning mechanisms, future agentic Al systems should achieve better task decomposition, chaining, and self-improvement, offering new research pathways in cognitive and Al systems design."}, {"title": "LLM-as-an-Abstraction (LLMaaA)", "content": "Our newly proposed system interface, called LLMaaA, is a novel paradigm for engaging with cloud computing and services in the future, with a natural language-based interface for building, deploying, and managing complex applications. The system uses a Master Agent \u2013 an LLM-based orchestrator that intelligently coordinates LLM and non-LLM agents (e.g., simulation agents, solvers) to perform tasks efficiently. This architecture ensures scalability, security, and continuous evolution by tracking agent performance. Future research should focus on enhancing agent collaboration, improving the adaptive programming model, and advancing secure, scalable cloud systems that flexibly integrate LLM and specialized agents for evolving real-world applications."}, {"title": "Al Compilers and Runtimes", "content": "Scaling foundation models to handle larger context lengths is crucial for advancing Al applications in areas like NLP, climate prediction, and geospatial data. Achieving this requires innovations in neural architectures, Al frameworks, and compiler optimizations. Additionally, sparse machine-learning models play a pivotal role in predictive analytics for fields like drug and material discovery and quantum chemistry, but are challenging to scale due to irregular data. Future research should focus on compiler, framework-level optimizations, common accelerator abstractions and higher-level kernels (e.g., Triton) as well as hardware innovations with a focus on cross-stack co-design to unlock synergies that will enable efficient scaling and optimization of emerging Al models, thus maximizing their impact on real-world applications."}, {"title": "Adaptive Middleware and Runtime in Hybrid Cloud Systems", "content": "Future research should focus on developing adaptive and intelligent middleware and runtime solutions to optimize the interplay between compute and communication across distributed Al workloads. The goal is to make future hybrid cloud dynamically adjust to real-time workload demands, evolving system topologies, and edge-cloud coordination, through Al-driven workload management prioritizing efficiency, scalability, and fault tolerance. One important direction is to design a unified control plane for Al-powered management of the resources in heterogeneous and dynamic cloud environments."}, {"title": "Cross-Layer Automation and Integration", "content": "To optimize cloud infrastructure for complex computations, cross-layer automation, integration, and observability are essential. Automation across layers of the cloud stack enables efficient resource allocation, scheduling, and SLO optimization, ensuring minimal delays and maximum availability. Cross-layer observability provides crucial performance monitoring, helping identify bottlenecks and automate diagnostics. Future research should focus on developing automated frameworks for seamless orchestration and monitoring across cloud layers, which will improve efficiency, flexibility, robustness, adaptability, and scalability in next-generation cloud systems."}, {"title": "Unified, Programmable, and Al-Optimized Networking for Distributed Al Workloads", "content": "Future research should focus on designing unified, reconfigurable, and Al-optimized networking infrastructures that facilitate smooth and efficient data transfer across hybrid cloud environments, eliminating inefficiencies in inter-node and intra-node communications. One important direction is to develop Al-driven network orchestration schemes that intelligently allocate bandwidth and resources, minimizing latency and cost while maximizing throughput for Al frameworks like PyTorch and TensorFlow, and ensuring secure data flow across diverse networking protocols (e.g., RoCE v2, InfiniBand)."}, {"title": "Data Management and Storage Efficiency for Large Models", "content": "Future large-scale Al training will rely on techniques to automatically place and migrate data in real-time, ensuring efficient storage use while reducing bottlenecks not just within a single cloud, but also across edge devices, private clouds, and public clouds. Additionally, new Al-enhanced security frameworks should ensure data integrity and encryption during data transfers across these environments. Future research should focus on innovating data management systems that intelligently distribute and manage a large amount of data (e.g., those used by foundation models and LLMs) across Al-Accelerator/CPU memory, SSDs, and node-local storage in hybrid cloud environments securely and efficiently."}, {"title": "Advancing Al Systems through Co-Design and Emerging Hardware Innovations", "content": "In order to dramatically enhance Al system performance and energy efficiency, leveraging system co-design and emerging hardware technologies such as Compute Express Link (CXL), Advanced Matrix Extensions (AMX), and GPUDirect will be essential. These technologies will streamline data transfer, optimize memory access, and facilitate cooperative heterogeneous computing. Future research should focus on novel data compression, memory management, and orchestration techniques for efficient AI/ML training and inference with lower cost. Software-defined interface and cache-coherent interconnects need to be co-designed to improve fine-grained computational efficiency across Al workloads."}, {"title": "End-to-end Edge-Cloud Transformation and Optimization", "content": "The future of Al system design lies in flexible SLOs, optimizing the balance between edge and cloud computation, and fine-grained, composable acceleration. Emerging applications like extended reality and robotics require a better understanding of trade-offs between latency, accuracy, and power. The design of fine-grained accelerators will boost energy efficiency without the recurring cost of monolithic designs. Research should focus on unified programming models, specialized data communication methods, co-design of neural architectures and accelerators, and integrated offline and online optimization techniques. End-to-end system prototypes and benchmarking are essential to validate these ideas, driving the future of Al systems with advanced flexibility, functionality, performance, and energy efficiency."}, {"title": "Robustness, Security, and System Health Monitoring for Al in Hybrid Cloud", "content": "Future cloud systems should include advanced fault detection, intrusion detection and containment, and self-healing algorithms and mechanisms to ensure their long-term health, resiliency, and dependability. Future research should focus on developing Al-driven robustness and security solutions for Al models running in hybrid cloud environments. Additionally, robust security protocols must be integrated into the Al orchestration layer, leveraging Al-enhanced intrusion detection, encryption, and access control techniques to prevent data breaches and system attacks. These mechanisms should be designed to allow systems to adapt to evolving security threats and ensure the integrity of distributed Al workloads."}, {"title": "Energy-Efficient Al Workloads and Sustainability in Hybrid Cloud Systems", "content": "Next-generation novel approaches will allow Al frameworks (e.g., Triton, PyTorch, Ray/CodeFlare) to make energy-aware decisions during model training and inferencing, contributing to carbon efficiency while maintaining high performance. Future research should focus on developing Al-driven energy management systems that dynamically optimize energy consumption across hybrid multi-cloud systems powered by diversified energy sources, including renewable sources, while working with various Al frameworks. This includes creating adaptive techniques to balance energy and performance, efficient compute/memory/storage management, and smart workload distribution between edge devices and multi-cloud resources."}, {"title": "Adaptive and Reconfigurable Cloud Infrastructures for Al Workloads", "content": "One exciting future direction is to enhance reconfigurability and adaptability in hybrid cloud system through technologies such as programmable SmartNiCs and in-network switches, reconfigurable hardware and interconnects, software-defined programmable interface, and workload-adaptive control strategies. Coordinated reconfiguration and specialization tailored towards specific workload characteristics will enable clouds to achieve significant performance gains (e.g., up to 100x). These innovations will allow smart and flexible adaptation to various workloads, from lightweight services to large-scale Al tasks, positioning future clouds as highly efficient, affordable, dynamic platforms."}, {"title": "THINKagents: A Research Framework for Agentic Systems", "content": "Agentic Al is a class of Al systems that are designed to act autonomously \u2013 as agents \u2013 to perform general-purpose work like completing a task end-to-end using planning and software tool-calling skills. Building on base Al technologies such as LLMs or reinforcement learning, these larger systems are constructed so they can make decisions, interact with their environments without constant human vigilance, and even interact in a multi-agent manner to learn from each other, cooperate, perhaps even developing their own language. As an example, Al agents have been created to model each role on a software development team and collected into a functioning multi-agent structure. These agents then collaborate using standardized operating procedures and a shared memory to complete complex tasks, to produce software engineering artifacts such as project requirements, design documents, and functional code. As another example, Al agents can be used to run large-scale simulations in a game-theoretic formulation to address notoriously difficult policy design questions such as design of dynamic tax codes, regulations to protect information environments, or optimize supply chains to ensure reliability and resilience. Going forward, one might imagine automating cybersecurity, where agents would scan for vulnerabilities, patch them, and further develop/test possible solutions in controlled environments. There is strong interest going forward in automated design of agentic systems (ADAS) where one combines building blocks to automate design.\nBroadly, agentic workflows empower generative Al models to tackle more complex, real-world problems by providing them with a structured approach, increased autonomy, and the ability to learn and adapt. As Al continues to advance, agentic workflows will likely play a crucial role in unlocking the full potential of generative Al technologies. Indeed, as compared to current foundation generative Al that often requires step-by-step human guidance, Al-enabled agents may take a prompt, break the goal down into subtasks, take action, check work, and adapt the approach as needed. Recent research on software engineering tasks, such as resolving Github issues [8-9", "17": "with modern foundation models, e.g. GPT-4, perform much worse than agentic workflows with the same underlying LLM.\\"}]}