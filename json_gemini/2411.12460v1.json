{"title": "Guide-to-Explain for Controllable Summarization", "authors": ["Sangwon Ryu", "Heejin Do", "Daehee Kim", "Yunsu Kim", "Gary Geunbae Lee", "Jungseul Ok"], "abstract": "Recently, large language models (LLMs) have demonstrated remarkable performance in abstractive summarization tasks. However, controllable summarization with LLMs remains underexplored, limiting their ability to generate summaries that align with specific user preferences. In this paper, we first investigate the capability of LLMs to control diverse attributes, revealing that they encounter greater challenges with numerical attributes, such as length and extractiveness, compared to linguistic attributes. To address this challenge, we propose a guide-to-explain framework (GTE) for controllable summarization. Our GTE framework enables the model to identify misaligned attributes in the initial draft and guides it in explaining errors in the previous output. Based on this reflection, the model generates a well-adjusted summary. As a result, by allowing the model to reflect on its misalignment, we generate summaries that satisfy the desired attributes in surprisingly fewer iterations than other iterative methods solely using LLMs.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) have demonstrated superior performance in abstractive summarization, outperforming traditional encoder-decoder models by generating more contextually appropriate and natural summaries (Goyal et al., 2023; Zhang et al., 2024; Pu et al., 2023; Ryu et al., 2024b). In addition, recent studies aimed to generate higher-quality summaries by leveraging the self-correction capabilities of LLMs (Zhang et al., 2023a; Sun et al., 2024). However, given individuals' diverse preferences for summary styles, it is essential to generate summaries that adjust personal needs (Zhang et al., 2023b). For instance, some users may prefer concise summaries or retain exact phrases from the original text.\nTherefore, controllable summarization has recently garnered attention (Zhong et al., 2021; Xu et al., 2023; Zhang et al., 2023b). Previous research employed encoder-decoder models to control attributes (Mao et al., 2022; Zhang et al., 2022; Vig et al., 2022; Pagnoni et al., 2023; Wang et al., 2023; Urlana et al., 2024). Although LLMs excel in generating high-quality summaries, they still face challenges in controlling attributes (Yuan et al., 2024; Tang et al., 2023), and their controllability has been underexplored (Liu et al., 2024).\nThus, we analyze LLMs' ability to control various attributes in summarization and refine the measurements to more accurately assess these attributes. We reveal that while LLMs excel at controlling linguistic attributes such as topic and speaker, they severely struggle with numerical attributes such as extractiveness and length. To address this challenge, we propose a guide-to-explain (GTE), which enables precise attribute control solely through LLMs without relying on external modules or training. We first design an attribute-identification step to calculate misaligned attributes in LLM-generated summaries, subsequently guiding the model to explain the sources of its errors. By self-reflecting its own errors, the model can adequately adjust attributes in subsequent iterations. We introduce the self-refine strategy, primarily used in reasoning tasks with LLMs (Weng et al., 2023; Madaan et al., 2023; Dhuliawala et al., 2024; Gou et al., 2024), to controllable summarization.\nAdditionally, we evaluate GTE on mixed attribute control datasets, MACSumDoc and MACSum Dial (Zhang et al., 2023b). GTE successfully controls each attribute with minimal iterations solely using LLMs, outperforming other iteration methods. We also demonstrate the high quality of the controlled summaries via multiple evaluation metrics. In addition, we analyzed whether LLMs can control multiple attributes simultaneously. We found out that LLMs struggle with jointly controlling correlated numerical attributes. Our contributions are as follows:"}, {"title": "2 Evaluating controllability of LLMs", "content": "We investigate the controllability of LLMs for four attributes: extractiveness, length, topic, and speaker. Extractiveness evaluates how much of the summary's content directly overlaps with the original text. A highly extractive summary is required when users need to retain the original context, such as in academic papers; however, paraphrasing is applied to tailor the summary in general cases. The length counts the ratio between the main text and the summary. The preferred summary length varies depending on the information density of the text and user preferences. For topics or speakers, users may prefer summaries focused on a specific topic or speakers from a long document or dialogue.\nPrevious methods have not effectively accounted for attribute-focused aspects. In the case of extractiveness, it is straightforward to determine how much of the summary's content directly overlaps with the original text. However, for length, prompts suggested by earlier works specify a fixed number of sentences, e.g., \"3 sentences,\" but this approach fails to account for variations in sentence length and does not accurately reflect the summary's actual length (Goyal et al., 2023; Liu et al., 2024; Yuan et al., 2024). Thus, we calculate the summary length as a ratio relative to the main text. For topics, Zhang et al. (2023b) calculated the frequency of topic-related words in the summary. However, even if topic words do not explicitly appear, the summary can still reflect the core context of the topic, especially for LLM-generated summaries, which tend to paraphrase the content. Therefore, we compute the embedding similarity B between the topic word and each word in the summarys: $\\frac{1}{n} \\sum_{i=1}^{n} B(topic, word_i)$, where n is the number of words in the summary. If multiple topics k are present, we use the average embedding similarity across all topics: $\\frac{1}{k} \\sum_{j \\epsilon k} \\frac{1}{n} \\sum_{i=1}^{n} B(topic_k, word_i)$. For speakers, Zhang et al. (2023b) calculate the frequency of the"}, {"title": "2.1 Controllable attributes", "content": "We investigate the controllability of LLMs for four attributes: extractiveness, length, topic, and speaker. Extractiveness evaluates how much of the summary's content directly overlaps with the original text. A highly extractive summary is required when users need to retain the original context, such as in academic papers; however, paraphrasing is applied to tailor the summary in general cases. The length counts the ratio between the main text and the summary. The preferred summary length varies depending on the information density of the text and user preferences. For topics or speakers, users may prefer summaries focused on a specific topic or speakers from a long document or dialogue."}, {"title": "2.2 Controllablility assessment", "content": "We evaluate the ability of LLMs to adjust their outputs based on specified attributes (Table 1, 2). Our assessment includes two evaluations: (1) the failure rate upon reaching the predefined maximum iterations without achieving the desired modifications and (2) the average iterations required to adjust an attribute, calculated only for successful cases.\nWe denote the naive iteration approach, which simply adjusts attributes repeatedly, as Iter. Most LLMs effectively control linguistic attributes, such as topic and speaker. However, LLMs struggle with numerical attributes, including extractiveness and length. Both Llama-70B and GPT-40-Iter"}, {"title": "3 GTE", "content": "Therefore, we introduce a guide-to-explain (GTE) framework (Figure 1) to adjust the challenging numerical attributes. We provide an attribute identification step to adjust incorrectly generated responses and guide the LLMs to reflect by explaining the reasons behind these errors. Our approach allows the model to make appropriate corrections in subsequent iterations."}, {"title": "3.1 Attribute identification step", "content": "We first prompt the LLM to generate an initial draft s' that reflects the specified attributes i. If the LLM fails to control the instructed attributes accurately, we provide attribute identification step (AIS) to guide the model on how to adjust the attributes. LLM may have difficulty measuring attributes such as extractiveness or the length ratio relative to the original text. Thus, we provide a step-by-step approach to instruct the model on revising its summary based on the generated output."}, {"title": "3.2 Guidance step", "content": "After providing instructions AIS on revising the summary, we supply guidance step (GS) to the model to explain why it initially failed to adjust the attributes correctly. This process is similar to how humans solve complex problems by reviewing their mistakes to produce more accurate responses in the future. Receiving [a; i, s'; AIS; GS] as inputs, where a denotes the article, the model first reflects on the reasons for the initial error before generating a revised summary. If the revised summary still fails to satisfy the attributes, GTE repeats until the model produces an attribute-compliant summary. As LLMs are known to struggle with number-related tasks (Thawani et al., 2021; Imani et al., 2023), our guidance to explain why their calculation is incorrect, followed by generating summaries assists in effectively controlling the numeric attributes. The used prompts are in Appendix B."}, {"title": "4 Experimental setup", "content": "We evaluate the controllability of various LLMs, including Phi-3 (Abdin et al., 2024), Llama3 (Dubey et al., 2024), and GPT series (Brown, 2020; Achiam et al., 2023). To analyze model performance by size, we use both the 8B and quantized 70B versions 1 of Llama3, and GPT-3.5 and GPT-4.\nWe used two datasets, the MACSumDoc and the MACSum Dial datasets (Zhang et al., 2023b), which comprise committee meetings and news contents each. Both datasets are for mixed-attribute summarization that control multiple attributes simultaneously, but only MACSumDial has speaker attribute. Since we evaluate LLM performance on"}, {"title": "5 Results and Discussions", "content": "Main results We define the strategy solely providing attribute identification steps as AIS and denote our full guiding framework as GTE. As a result, our GTE demonstrates remarkably lower failure rates and fewer iterations when adjusting summaries across all attributes, including challenging numerical attributes in MACSum Doc (Table 1). Notably, while applying GTE to smaller models such as Phi-3 and Llama3-8B resulted in significant performance improvements, we observed that failures were almost nonexistent when applied to larger models such as Llama-70B or GPT-40.\nLLMs encounter more difficulties with the MACSum Dial dataset (Table 2). The dataset, which is derived from QMSum (Zhong et al., 2021), consists of lengthy and diverse content parliamentary and committee meetings, making it more challenging compared to the CNN-news-based MACSumDoc. Notably, both the GPT-40-Iter and GPT-40-AIS failed to adjust for long length, whereas our GPT-40-GTE demonstrated a commendable success rate. Regarding extractiveness, the Iter and AIS of GPT-40 exhibit relatively low iteration counts since the models mostly exceed the maximum iteration (O). While they fail nearly 80%, our GTE demonstrates a significantly lower failure rate at 17.28% with low iterations.\nQuality of controlled summary Instead of ROUGE score(Lin, 2004), which does not adequately evaluate the quality of the summaries (Zhong et al., 2022; Scialom et al., 2021; Ryu et al., 2024a), we use UniEval (Zhong et al., 2022) and QuestEval (Scialom et al., 2021) to assess both the inherent quality of the summaries and their factual consistency with the source text. UniEval, a multi-dimensional evaluator with high human correlation, assesses dimensions such as coherence, consistency, fluency, and relevance, and QuestEval evaluates factuality via question answering. Table 3 shows that our method's summaries outperform all"}, {"title": "Mixed attributes controllability", "content": "We observed that when generating summaries controlled for all attributes simultaneously, the model effectively handled linguistic attributes but faced challenges with numerical attributes. Notably, satisfying all attributes within the maximum number of iterations proved challenging for all methods, including GTE."}, {"title": "Sequential-planning", "content": "Discovering the challenges in precisely controlling all attributes in parallel, we introduce a sequential-planning strategy, which gradually adjusts attributes from the ill-controlled with the initial draft using GTE. However, modifying one attribute often disrupted previously adjusted attributes due to correlations. For example, controlling length first would still lead to changes in length when adjusting extractiveness. Consequently, sequential adjustments result in a modest performance gap compared to the initial draft (Figure 2). We assess the attributes using the root mean squared error (RMSE) between the instructed values and those in the generated summaries."}, {"title": "6 Conclusion", "content": "In this work, we revisit the measurement of controllable summarization with various attributes. We evaluate the controllability of multiple attributes in summary generation with LLMs, finding that LLMs struggle to adjust numeric attributes compared to linguistic ones. To address this limitation, we propose a guide-to-explain (GTE) approach, where the model is guided to explain its misalignments and then grounded this explanation to produce better-controlled summaries in subsequent iterations. GTE enables LLMs to control challenging numerical attributes with lower failure and fewer iterations. Further, we validate the quality of the controlled summaries via a multi-dimensional evaluation, demonstrating the high-quality generation."}, {"title": "Limitation", "content": "We evaluated the controllability of various attributes in LLMs and introduced a novel guide-to-explain (GTE) framework to address challenges in numerical attributes. While GTE enhanced control over numerical attributes, it still struggled with highly correlated mixed numerical attributes. Additionally, sequential planning, which adjusts attributes in order of least alignment, also faced difficulties achieving precise control. Even after properly adjusting one attribute, modifying the correlated numerical attribute caused the previously adjusted attribute to change. We believe further research could explore more effective methods for addressing these challenges."}, {"title": "Ethics", "content": "We used publicly available MACSum datasets for our research, conducting experiments with Phi-3, Llama3 2, GPT-3.5, and GPT-40 from April to October 2024."}, {"title": "A Attribute details", "content": "We analysis the data distributions in the MACSumDoc and MACSumDial (Zhang et al., 2023b) datasets. The attributes used in the original datasets are described as follows:"}, {"title": "A.1 Attribute analysis", "content": "We analysis the data distributions in the MACSumDoc and MACSumDial (Zhang et al., 2023b) datasets. The attributes used in the original datasets are described as follows:\n\u2022 Extractiveness: Controls how much of the summary is directly extracted from the source text. It is evaluated using the average of ROUGE-2 and ROUGE-3 precision scores.\n\u2022 Length: The number of words in the summary. It is evaluated based on token length.\n\u2022 Topic: Control the summary to align with the given topic, and multiple topics can be present. The evaluation is based on the proportion of topic words appearing in the summary.\n\u2022 Speaker: Control the summary to focus on the speech of a specific speaker. It is evaluated by the ratio of the speaker's words included in the summary.\n\u2022 Specificity: Controls the level of detail or descriptive content in the summary. The evaluation formula is: Specificity = (0.1 \u00d7"}, {"title": "A.2 Iteration threshlold", "content": "We set attribute-specific thresholds and iteratively adjusted them until the criteria were satisfied. For extractiveness and length, iterations were considered successful if the values fell within a relabeled value \u00b15 range. For the topic and speaker, we set the minimum embedding similarity score as"}]}