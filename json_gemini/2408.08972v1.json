{"title": "ASGM-KG: UNVEILING ALLUVIAL GOLD MINING THROUGH KNOWLEDGE GRAPHS", "authors": ["Debashis Gupta", "Aditi Golder", "Luis Fernendez", "Miles Silman", "Greg Lersen", "Fan Yang", "Bob Plemmons", "Sarra Alqahtani", "Paul Victor Pauca", "Sakib Imtiaz"], "abstract": "Artisanal and Small-Scale Gold Mining (ASGM) is a low-cost yet highly destructive mining practice, leading to environmental disasters across the world's tropical watersheds. The topic of ASGM spans multiple domains of research and information, including natural and social systems, and knowledge is often atomized across a diversity of media and documents. We therefore introduce a knowledge graph (ASGM-KG) that consolidates and provides crucial information about ASGM practices and their environmental effects. The current version of ASGM-KG consists of 1,899 triples extracted using a large language model (LLM) from documents and reports published by both non-governmental and governmental organizations. These documents were carefully selected by a group of tropical ecologists with expertise in ASGM. This knowledge graph was validated using two methods. First, a small team of ASGM experts reviewed and labeled triples as factual or non-factual. Second, we devised and applied an automated factual reduction framework that relies on a search engine and an LLM for labeling triples. Our framework performs as well as five baselines on a publicly available knowledge graph and achieves over 90% accuracy on our ASGM-KG validated by domain experts. ASGM-KG demonstrates an advancement in knowledge aggregation and representation for complex, interdisciplinary environmental crises such as ASGM.", "sections": [{"title": "1 Introduction", "content": "Artisanal and small-scale gold mining (ASGM) and the global demand for gold constitute an emerging threat to the conservation and preservation of tropical systems worldwide [1, 2]. ASGM is a rudimentary mining practice that extracts gold particles from alluvial sediments. This involves removing all above-ground vegetation and soil, using large quantities of water and low-tech equipment, such as suction pumps, to wash large quantities of sediment down a sluice, and finally employing mercury to amalgamate the gold particles. All remaining mercury-contaminated material are vaporized to the air or released to soil and water before moving the operation to another site. Shallow water tables quickly fill any excavations, leaving behind a mixture of ponds and bare earth [3] (See Figure 1).\nRemote sensing data, such as airborne and satellite imagery, have been primary data sources for investigating the scale and effects of ASGM [4, 1, 5, 6]. Studies of historical satellite imagery have shown that the pace of ASGM activity has increased significantly over the past decade. Landsat data products have demonstrated that ASGM was responsible for the removal of over 120, 000 hectares of primary tropical forest (approximately 1.5 times the size of New York City) in"}, {"title": null, "content": "the Madre de Dios department of Peru, from 1984 to 2017 [4]. Similar satellite data also shows ASGM expanding in many other countries in South America [7, 8], Africa [9], and Southeast Asia [10, 6]. Other remote sensing studies have found its impact on biodiversity, water quality and human health to be profound at a global scale [5, 11, 12].\nMany important questions involving smaller-scale changes, such as state of forest recovery, repeated mining over previously worked sites, and forecasting future mining activity remain difficult to address via remote sensing alone. Despite the large amounts of multimodal and multiresolution data acquired in a daily basis for land cover monitoring, the information needed to answer these questions is hard to disambiguate without the use of additional contextual information. Meanwhile, research findings published in scientific venues are hard for the general public to interprete from a governance and policy standpoint to yield meaningful information and robust evidence to support policy recommendations. Thus, new approaches are needed to support the combination of disparate data and sources of relevant knowledge [13].\nIn this resource paper, we introduce ASGM-KG, a knowledge graph specifically designed to help better understand the effects of ASGM in tropical forests, such as in the Amazon Basin that includes most countries in South America. This effort is led by a team of computer scientists, ecologists, and domain experts with decades of expertise in ASGM and extensive field work in the tropical forests of Madre de Dios, Per\u00fa, one of the world's hotspots for legal and illegal alluvial gold mining. Through the Center for Amazonian Scientific Innovation (CINCIA) and collaboration with local"}, {"title": null, "content": "governmental and non-governmental organizations, the team has been able to characterize several aspects of ASGM concerning deforestation, mercury contamination, and ecosystem restoration and recovery.\nOur work in developing ASGM-KG has two main objectives. First, it aims to provide a publicly available resource for government officials, local agencies and organizations to help guide their decision processes and to design successful interventions [14]. Second, it seeks to build a source of accurate information from reputable sources, validated by domain experts, to leverage advancement in knowledge-infused deep learning and neuro-symbolic computing."}, {"title": "1.1 Related Work", "content": "Knowledge graphs are increasingly being used in remote sensing for various purposes. Deng et al. [15] introduced GAKG, a large-scale multimodal academic knowledge graph, to comprehensively integrate knowledge found in the geoscience literature. WorldKG [16] is a new geographic knowledge graph built from the OpenStreetDataset to provide semantic representation of geographic entities.\nAs is the case in alluvial gold mining, accurate prediction of future events is a key objective in many remote sensing applications. Forest fire prediction [17], landslide prediction [18, 19], exploration of iron and gold deposits [20, 21], and agriculture [22, 23] are some specific areas where knowledge graphs and domain expertise are being utilized, often in conjunction with other types of data. However, resources, such as GAKG and WorldKG, and prediction techniques developed so far are not tailored specifically for the study of ASGM."}, {"title": "2 The ASGM Knowledge Graph", "content": "The ASGM-KG was constructed using 9 documents selected by a domain expert at CINCIA. These documents contain approximately 930-pages in total with an average word count of 500 words per page. Links to these documents are provided in Table 1 and can also be found in our Github repository 1.\nThis initial version of ASGM-KG consists of 1650 unique entities and 785 unique relationships. A total of 43% of entities and 29% relations are newly discovered, i.e., they are not found in Wikidata [24]. There are 1899 triples (subject, predicate, object) stored in Resource Description Framework (RDF) format. The corresponding data can be obtained, explored, and visualized via the ASGM-KG online portal 2. Three downstream tasks are implemented:query answering, subgraph summarization, and chat via natural language.\nNext, we describe the two major steps involved in the construction of ASGM-KG: 1) extraction of RDF statements using a large language model (LLM), and 2) factual reduction of the RDF statements using an unsupervised approach, Data Assessment Semantics (DAS), developed specifically for this task."}, {"title": "2.1 RDF Statement Extraction Using LLMS", "content": "We extract RDF statements in entity-relation-entity format by querying an LLM using a specified ontology schema [25], which instructs the LLM the steps to extract RDF statements from raw text. (See Algorithm 1.)\nThe application of this prompt tuning process resulted in 2, 653 RDF triples. This approach to extracting RDF statements is becoming prevalent due to the remarkable capabilities of LLMs for natural language understanding, contextual processing, and semantic reasoning [26]."}, {"title": "2.2 Factual Reduction via DAS", "content": "We developed an unsupervised framework, called Data Assessment Semantics (DAS), for factual validation of the RDF statements extracted in the previous step. The objective is to minimize the work of domain experts during the knowledge graph construction process. Figure 2 illustrates how the framework can be used to label triples as factual or non-factual. The first step is to use a given RDF statement as a query in a search engine and then using the search engine's API to retrieve the top N hits containing the same keywords as in the RDF statement. The second step is to use a web page ranking tool to compute a relevance score for each retrieved page. Only the top K pages with scores above a specific threshold are considered. The third step uses an LLM model to summarize the content of each web page and infer whether the RDF statement is factually correct based on the K top ranked web pages. The last step uses majority voting to determine whether the RDF is factual or not. The process is outlined in Algorithm 2."}, {"title": "3 Validation Results", "content": "Using a systematic approach to classify RDF triples as factual or non-factual is essential to our work, given the limited amount of time domain experts can dedicate to this task. As designed, the DAS framework is agnostic to a specific domain. To verify this claim, we compare its triple classification performance against other methods on CoDEx-S, a publicly available and recently published dataset derived from Wikidata and Wikipedia [27]. CoDEx-S includes 1838 positive (factually correct) and 1838 hard negative (factually incorrect) RDF triples. Results of this comparison are shown in Table 3. The numbers in rows 1 - 5 are obtained from Table 6 in [27]."}, {"title": "3.1 Validation of DAS Against Benchmark", "content": "Using a systematic approach to classify RDF triples as factual or non-factual is essential to our work, given the limited amount of time domain experts can dedicate to this task. As designed, the DAS framework is agnostic to a specific domain. To verify this claim, we compare its triple classification performance against other methods on CoDEx-S, a publicly available and recently published dataset derived from Wikidata and Wikipedia [27]. CoDEx-S includes 1838 positive (factually correct) and 1838 hard negative (factually incorrect) RDF triples. Results of this comparison are shown in Table 3. The numbers in rows 1 - 5 are obtained from Table 6 in [27]."}, {"title": "3.2 Validation of ASGM-KG", "content": "As of this writing, our ASGM domain experts have been able to manually verify 579 of the 1899 DAS-validated triples in ASGM-KG as factual or non-factual. A comparison of DAS versus domain experts on this 579 triples yields 90% matching accuracy. The set of triples used for this comparison is admittedly small. Yet, the matching accuracy on this ground truth and on CoDEx-S are highly encouraging. As a result, it was decided to keep all 1899 triples validated via DAS as part of ASGM-KG."}, {"title": "3.3 Downstream Tasks", "content": "We have implemented three downstream tasks to facilitate interaction with ASGM-KG: query answering, subgraph summarization, and chat via natural language. For query answering we use Neo4J [28] and implemented 4 different query types: by subject, by object, by relation, and by subject-object. For subgraph summarization, we implemented k-hop distance summarization from a given source entity and summarization of path traversal between given source and target entities. Finally, we used Llama-3-70b-chat model for chat interaction via natural language. Sample queries performed in ASGM-KG and subgraph summarization results can be found in our Github repository. Readers can also use our online portal 3 to interact with ASGM-KG directly via any of these downstream tasks."}, {"title": "4 Discussion", "content": "The use of LLMs for building knowledge graphs is becoming a predominant practice in natural language processing (NLP) [29, 30, 31]. For ASGM-KG, we compared the relative performances of 3 LLMs and chose GPT 4 due to its contextual understanding and high performance on ambiguous text. This choice is likely to change as newer LLM technology becomes available. Similarly, the choice of specific tools for factual reduction is not fixed.\nThe DAS framework was created as a means to help reduce the workload of ASGM domain experts. It systematizes a standard process that many people use to determine veracity of a natural language statement. Others have proposed and are using similar approaches, see e.g. [32]. It is entirely possible that for a given statement, DAS may output no classification at all, e.g., if a web search yields no results. It is also possible that DAS may output an erroneous classification. Concerning cases include the unintended use of web misinformation. But it is unreasonable to expect a domain expert to factually verify by hand the large number of statements that can be generated by an LLM, or that any one expert, no matter how well versed in the material, is omniscient.\nThe resource presented in this paper is currently hosted online and implemented via standard tools. It performs several down-stream tasks including QnA, graph summarization, and natural language interaction. ASGM is a large and ever-growing global environmental and social issue, particularly in the global tropics [e.g. [5]], and we expect stakeholders in Madre de Dios and other areas around the globe where ASGM is prevalent to explore our knowledge base and extract useful information, and to contribute to its growth. How this resource influences future policy is an important topic of interest. Our CINCIA partners are committed to maintaining this resource and collecting use statistics. We are also committed to increasing the size of ASGM-KG with the inclusion of additional documents curated by domain experts worlwide."}, {"title": "5 Conclusion", "content": "In this paper, we have introduced a novel resource, ASGM-KG, an application of knowledge graphs to help understand the growing threat to the environment and to human populations by artisanal and small-scale gold mining. ASGM-KG"}, {"title": null, "content": "was constructed in collaboration with ASGM domain experts. It is currently deployed as a freely available web application implementing three important downstream tasks: QnA, graph summarization, and natural language dialog.\nExpanding ASGM-KG is an important objective to support both stakeholders as well as the research community. New approaches, such as expert-in-loop [33, 34], may be considered to help domain experts curate the large amounts of information that can be extracted and summarized via tools such as the DAS framework or inferred via link prediction [35, 36].\nAt the same time, there is still a great need for intelligent methods that can help accurately forecast future land cover change, loss of habitat, and water quality resulting from human activity and natural phenomena. These approaches should be capable of dealing with and extracting information from the large amounts of complex and uncertain data available for the study of ASGM, such as multimodal, multi-resolution, time- and geolocation-dependent image data, in addition to text data from reports, news media, interviews, etc. Neuro-symbolic methods can be explored to effectively integrate such data types for improved interpretability, explainability, and contextual awareness."}]}