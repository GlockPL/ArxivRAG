{"title": "Artificial intelligence techniques in inherited retinal diseases: A review", "authors": ["Han Trinha", "Jordan Viceb", "Jason Charnga", "Zahra Tajbakhsha", "Khyber Alama", "Fred K. Chen", "Ajmal Mianb"], "abstract": "Inherited retinal diseases (IRDs) are a diverse group of genetic disorders that lead to progressive vision loss and are a major cause of blindness in working- age adults. The complexity and heterogeneity of IRDs pose significant chal- lenges in diagnosis, prognosis, and management. Recent advancements in artificial intelligence (AI) offer promising solutions to these challenges. However, the rapid development of AI techniques and their varied applications have led to fragmented knowledge in this field. This review consolidates ex- isting studies, identifies gaps, and provides an overview of AI's potential in diagnosing and managing IRDs. It aims to structure pathways for advancing clinical applications by exploring AI techniques like machine learning and deep learning, particularly in disease detection, progression prediction, and personalized treatment planning. Special focus is placed on the effectiveness of convolutional neural networks in these areas. Additionally, the integra- tion of explainable AI is discussed, emphasizing its importance in clinical settings to improve transparency and trust in AI-based systems. The re- view addresses the need to bridge existing gaps in focused studies on AI's role in IRDs, offering a structured analysis of current AI techniques and outlining future research directions. It concludes with an overview of the challenges and opportunities in deploying AI for IRDs, highlighting the need for interdisciplinary collaboration and the continuous development of robust, interpretable AI models to advance clinical applications.", "sections": [{"title": "1. Introduction", "content": "Vision allows us to interpret and interact with our surroundings. Vision impairment affects 216.6 million people worldwide [1], and is associated with significant economic burden [2], as well as higher mortality and rates of de- pression and anxiety compared with normally-sighted people [3, 4]. The retina is a critical structure in the eye that plays a key role in vision. It converts light into electrical signals, which are transmitted via the optic nerve to the brain for processing. Composed of multiple cell layers (Figure 1), the retina's health is essential for functional vision. Any diseases or con- ditions affecting the retina can lead to impaired vision.\nInherited retinal diseases (IRDs) are a group of heterogenous genetic ocular conditions that cause vision impairment due to degeneration of retinal layers leading to dysfunction or abnormal development. IRDs are estimated to af- fect over 5.5 million people worldwide (0.072%) [5], and is the leading cause of blindness in working age adults [6].\nIRDs are caused by pathogenic variants in nuclear and mitochondrial genes, with over 250 genes implicated in this heterogeneous group of diseases [7]. This genetic diversity leads to varied pathophysiology and affects different retinal layers. Even among individuals with the same mutation, disease onset and severity can vary, making it challenging for clinicians to manage uncer- tainties in disease progression. Retinitis pigmentosa (RP) and Stargardt disease are among the most commonly studied IRDs, with approximately 29.6% and 24.8% of IRD-related genes associated with these conditions re- spectively [8].\nIn optometry and ophthalmology clinics, patients are assessed for IRDs us- ing a wide range of methods. Structural measures include photographs of the retina, known as fundus photographs, which provide en face views across the entire structure. Fundus autofluorescence (FAF) uses short wave- length and/or near-infrared excitation stimuli to produce en face images of the retinal pigment epithelium (RPE), a layer of the retina responsible for metabolism. This allows for identification of retinal areas of hyperautofluo- rescence associated with accumulation of lipofuscin and melanin[9, 10], which indicate harm to the retina, and areas of hypoautofluorescence associated"}, {"title": "2. Background", "content": "The field of AI has risen in popularity in recent years. Fundamentally, A\\u0399 is driven by machine learning (ML) to infer patterns and relationships from"}, {"title": "2.1. Artificial Intelligence", "content": "The field of AI has risen in popularity in recent years. Fundamentally, A\\u0399 is driven by machine learning (ML) to infer patterns and relationships from training data. This allows AI-equipped computer systems to perform com- plex problem-solving tasks. Effective training of AI models allows them to make predictions on new unseen data - based on these learned representations [40]."}, {"title": "2.1.1. Machine learning", "content": "The field of AI encompasses a range of ML techniques (or models) that vary in architecture, size and algorithmic complexity.\nDecision trees are intuitive models that recursively partition data into sub- sets based on features, leading to a final decision or prediction at the leaf nodes. They are valued for their interpretability and applicability in various domains. Support Vector Machines (SVMs) are another powerful ML tool, focusing on finding the optimal hyperplane that separates different classes of data with the largest possible margin [41]. SVMs exploit various kernel functions [42] to handle linear and non-linear classification tasks. ML mod- els also typically include data pre-processing and transformation layers to supplement and improve learning processes. Such transformations are often utilized for data with distinguishable patterns and less noise [43]."}, {"title": "2.1.2. Deep learning", "content": "Conversely, modern applications of AI often employ deep neural networks in learning processes typically referred to as deep learning (DL), which is an evolutionary sub-class of ML. DL refers to neural networks with many layers and the ability to learn intricate patterns and complex relationships from large amounts of data [44]. DL leverages backpropagation and gradient de- scent functions, which allows the network to learn from itself and optimize weight functions [45, 46]. The \u2018depth' of DL alludes to the architectural complexity of these algorithms, which are often based on neural networks as described below. This focus on deep learning is particularly relevant for IRDs due to its ability to capture intricate patterns in large datasets, which is essential for accurately classifying and potentially predicting disease pro- gression."}, {"title": "Multilayer perceptrons", "content": "One of the simplest forms of DL models is the multilayer perceptron (MLP), which is a type of neural network. An MLP consists of multiple layers of nodes, each layer fully connected to the next one [44]. The layers include"}, {"title": "Transformers", "content": "Transformers represent a significant advancement in the field of DL, par- ticularly in natural language processing but increasingly in other domains, including computer vision. Transformers are neural networks that use self- attention mechanisms to weigh the importance of different input elements dynamically [48]. This architecture allows transformers to process sequences of data, such as text or time-series data [49]. The self-attention mechanism enables transformers to capture long-range dependencies and interactions within the data, leading to superior performance in tasks like language trans- lation [50], text generation [51], and even image recognition when adapted for vision tasks [52]. Exploiting sequential data structures has also proved beneficial for transformer-based genome analysis and sequence labelling [53]."}, {"title": "Convolutional neural networks", "content": "Convolutional neural networks (CNNs) are a type of neural network inspired by the mammalian visual cortex [54]. They use the concept of receptive fields in order to extract features from input images [55]. CNNs are typically com- prised of a wide range of functional 'layers'. For example, convolution and pooling layers extract features, whereas connected layers map these features to output [56]. Neural networks represent a series of repeating layers which enhance recognition of complex features and relations. Many CNN models have been proposed in the literature, with varying architectures differing in size and number of repetitions within layers [57, 58, 59]. For example, U-Net [27], widely used in medical imaging, is composed of 23 layers and follows a symmetric encoder-decoder structure. The encoding path consists of re- peated convolutional layers and max-pooling operations, which reduce the spatial dimensions while increasing the depth of feature maps. The decoding path uses up-convolutions (or transposed convolutions) to gradually restore the original spatial resolution. U-Net also incorporates skip connections be- tween corresponding layers in the encoder and decoder paths, allowing for the"}, {"title": "2.2. Artificial intelligence in eye health", "content": "The utility of AI in eye care has been increasingly explored in recent years. AI aims to enhance disease detection and diagnosis, support clinical- decision making, screening patients, and advancing teleophthalmology [62, 63]. Techniques ranging from more traditional, ML-based random forest and SVM models to deep learning models like CNNs and transformers, display a promising trend toward improving image-based analysis for segmentation, classification, and risk prediction in the ophthalmology domain.\nImage segmentation is a critical step in data interpretation, extracting mean- ingful components from inputs to isolate relevant areas based on specific at- tributes [64]. This process is crucial for the retina, which consists of multiple layers and features requiring accurate delineation for analysis, classification and image registration. Segmentation has been applied to OCT images [65], fundus photos [33, 66] and FAF images. Following segmentation, AI models can be leveraged to classify input samples, labelling them with specific dis- eases or disease stages, depending on how the model was trained. AI models"}, {"title": "3. AI techniques in inherited retinal diseases", "content": null}, {"title": "3.1. Machine learning", "content": null}, {"title": "3.1.1. Segmentation", "content": "IRDs manifest a spectrum of clinical signs, highlighting the necessity for accurate segmentation crucial for precise diagnosis. Detailed segmentation of OCT images is crucial for clinicians to analyze affected retinal layers, which is pivotal for the diagnosis and management of IRDs [83]. Similarly, accurate segmentation of en face images, particularly FAF, is clinically significant, as key features in IRDs - such as pigmentation or autofluorescence changes -"}, {"title": "3.1.2. Classification", "content": "Classification for IRD refers to an AI model identifying a particular geno- type or disease stage. A hierarchical soft-voting ensemble model was deployed by Glinton et al. [32], combining: (i) SVM, (ii) AdaBoost, (iii) decision trees and, (iv) logistic regression to classify ERG phenotypes in patients with Star- gardt disease. For patients with this disease, ERG results vary depending on which types of photoreceptor cells (i.e., rods and/or cones) are affected. The ensemble model successfully differentiated between normal tracings and gen- eralized photoreceptor dysfunction, achieving high R-squared values of 0.967 and 0.938 respectively compared to ground truths. However, classification of generalized cone dysfunction proved challenging due to the small sample size"}, {"title": "3.1.3. Prediction of visual function", "content": "For predicting visual function, random forests were utilized to estimate retinal sensitivity measured by perimetry in RP and Leber congenital amau- rosis [85]. Additionally, random forest regression was applied to OCT images of patients with recessive Stargardt disease to predict retinal sensitivity using microperimetry [86]. While machine learning plays a significant role in IRDs, the literature emphasises a shift towards deep learning-based methodologies, particularly when handling large image datasets."}, {"title": "3.2. Deep Learning", "content": null}, {"title": "3.2.1. Convolutional neural networks", "content": null}, {"title": "Segmentation", "content": "CNNs have been pivotal in segmenting critical features of various IRDs, in- cluding Stargardt disease. A hallmark feature of Stargardt disease is alter- ations in FAF, such as hyperautofluorescent retinal flecks indicating buildup of abnormal melanin or lipofuscin, or areas of decreased autofluorescence indicating retinal layer atrophy (Figure 4). Accurate detection and quan- tification of hyperautofluorescent flecks are clinically significant for monitor- ing disease progression [87]. A modified U-Net architecture incorporating a ResNet encoder-decoder has successfully segmented hyperautofluorescent flecks [21]. This adaptation replaced the traditional U-Net encoder with ResNet-34. As fleck appearance can vary, this model was tested on FAF images displaying a wide variety of presentations of Stargardt disease, and demonstrated higher Dice scores when estimating fleck number and area in discrete flecks compared to diffuse speckled patterns. This study utilized subjects with confirmed ABCA4 genetic diagnosis, thus strengthening the validity of ground truth images, however contrast limited adapted histogram"}, {"title": "Classification", "content": "CNNs have been effectively deployed for detection and classification of var- ious IRDs across a range of imaging modalities. Chen et al. [33] developed three CNNs to detect the presence of RP from color fundus photos. These DL models were based on Inception V3, Inception Resnet V2 and Xception architectures, pre-trained on the ImageNet dataset. The Xception model achieved the highest area under the receiver operating characteristic curve (AUROC) at 80%, likely due to its additional residual connection and use of depthwise separable convolutions compared to Inception models [97]. Fine- tuning the number of convolution layers further increased the AUROC to 99.46%. This model matched retinal and IRD specialists in accuracy, preci- sion, and sensitivity. Grad-CAM [77] showed that contrast between macular and peripheral retinal regions is significant in early RP identification. How- ever, the model's performance is limited by its small, homogeneous sample and lack of external validation.\nResNet 101 has been successful in multi-class classification of Stargardt dis-"}, {"title": "Prediction of visual function", "content": "From a patient perspective, visual function is one of the most clinically rel- evant outcomes to measure and predict, as it directly impacts daily life and wellbeing [98]. Studies have attempted to use CNNs to predict visual acu- ity (VA) and visual field (VF) sensitivity in RP. Four pre-trained CNNs (AlexNet, DenseNet-161, ResNet-50, and ResNet-152) were used to estimate VA as better or worse than 6/12 (a common cutoff for driving standards worldwide) based on OCT and/or infrared images [37]. ResNet-152 per- formed best during 10-fold cross-validation. Grad-CAM results suggested that the model relied more on OCT data than infrared data. The AUROC for the binary classification of VA better or worse than 6/12 was 0.87 for OCT only and 0.85 for combined OCT and infrared.\nAnother recent study used various ensemble DL models comprising Efficient- NetB0, InceptionV3, and VGG-16 to estimate VA, central VF sensitivity, and mean deviation (MD, an indication of how sensitive a patient's VF is com- pared to age-normative data) in patients with RP [38]. Score-CAM-generated heatmaps indicated that the fovea, AF rings, and degeneration margins were most salient when estimating MD, consistent with ophthalmologists' assess- ments of RP. While this study was purposeful in using multimodal imaging and functional assessment, the sampling excluded atypical presentations of RP."}, {"title": "Prediction of disease progression", "content": "Aside from visual function, disease progression is another significant con- cern for patients with IRDs. The progression of retinal atrophy in Stargardt disease was predicted using FAF images from 206 eyes with 12-month longi- tudinal data [39]. A U-Net architecture with embedded self-attention mech- anisms achieved a Dice score of 0.76 in predicting atrophy after 12 months. Similarly, Veturi et al. [99] attempted to predict the rate of progression of Stargardt disease using OCT and FAF images from 237 eyes with 12-month longitudinal data. The authors used a modular series of U-Nets to produce a probability map for the predicted atrophy region, achieving Dice scores of 0.83 and 0.828 for six- and 12-month predictions, respectively. Despite these promising results, 12-month predictions may be insufficient for lifelong conditions like IRDs, limiting the ability to provide comprehensive patient education and counseling.\nAlthough significant progress has been made in investigating visual function,"}, {"title": "Prediction of causative genes", "content": "Recent interest in gene therapy for inherited retinal diseases (IRDs) has been highlighted by the FDA's approval of Luxturna (voretigene neparvovec-rzyl), the first ocular gene therapy for RPE65-associated retinal dystrophy [98]. De- spite this progress, genetic testing can be time and financially prohibitive. CNNs have shown promise in predicting causative genes for various IRDs, aiding in genetic diagnosis, counseling, family planning, and clinical trial re- cruitment.\nOne study utilized the Medic Mind platform, leveraging the Inception V3 ar- chitecture, to predict causative genes for ABCA4, RP1L1, and EYS-associated retinopathies based on OCT images [37]. Mean test accuracy was 100% for ABCA4, 78.0% for RP1L1, 89.8% for EYS, and 93.4% for normal. The au- thors suggest that overfitting may explain the model's lower performance for RP1L1 and EYS, attributed to the small, homogenous sample sizes of 20 and 28 patients, respectively.\nThe Eye2Gene project [100] aims to predict causative genes based on OCT and infrared/FAF imaging. This initiative developed an ensemble of fifteen Inception V3 CNNs, trained on the largest IRD dataset to date (44,817 scans from 1907 patients) and tested on four external datasets. Early re- sults [39] show accurate predictions for the 36 most common IRD genes, matching expert standards. The model also identified the most pertinent imaging modalities for specific genes and demonstrated improved accuracy when considering the age of first presentation and mode of inheritance."}, {"title": "3.2.2. Generative adversarial networks", "content": "A notable outcome of the Eye2Gene project was the creation of Synth- Eye, a generative adversarial network (GAN) designed to generate synthetic FAF images [99]. This StyleGAN2-ADA model was trained on FAF images from 36 IRD classes, producing novel, diverse images of high visual fidelity. When these synthetic images were used to train Inception V3-based models for image classification, the performance of the classifiers remained consis- tent, neither improved nor degraded by the addition of synthetic images. The use of GANs to generate synthetic images may help address class imbal-"}, {"title": "3.2.3. Recurrent neural networks", "content": "While CNNs are suited for analysing spatial data, recurrent neural net- works (RNNs) are more appropriate for temporal and sequential information. Given the emphasis on imaging in IRDs, RNNs are less prominent in current literature compared to CNNs. However, some studies have utilized RNNs for segmentation tasks. For example, a multidimensional RNN with convo- lutional layers was used to localize cones in AOSLO images of Stargardt dis- ease [101]. The authors suggest that unlike CNNs, multidimensional RNNs provide global context at every pixel throughout classification, learning de- pendencies between pixels while detecting pertinent local features through convolutional layers. This network demonstrated strong performance in lo- calizing cones in AOSLO images of Stargardt disease, achieving an average Dice score of 0.94, and was capable of detecting cones in other pathologies such as RP and achromatopsia. Despite these promising results, the clini- cal utility is limited since adaptive optics SLO is not commonly available in general optometry and ophthalmology practices."}, {"title": "4. AI techniques in other eye conditions", "content": "While research into AI and inherited retinal diseases (IRDs) has made significant progress, notable gaps still exist in terms of predicting visual function, risk prediction and applying explainable AI principles in ML- and DL-based models. This section delves into AI techniques applied to more common eye conditions, aiming to explore potential applications in the field of IRDs. It should be noted that the techniques described in this section are not the only AI models utilized for their corresponding conditions, nor are they exclusively used for these conditions. They have been selected to highlight potential ways to bridge the knowledge gap in IRDs"}, {"title": "4.1. AI techniques in glaucoma", "content": "Glaucoma is a condition that causes damage to the optic nerve and can lead to VF loss [102]. There are various types of glaucoma, including pri- mary open-angle glaucoma (POAG) and normal-tension glaucoma (NTG) [103]. Ocular hypertension refers to when patients have high intraocular"}, {"title": "4.1.1. Machine learning in prediction of visual field progression", "content": "Various ML techniques have been used to predict the progression of perimetry results in glaucoma patients. Kalman filtering, for instance, has been used to predict the two-year trajectory of glaucomatous VF loss in NTG patients [110]. The study found that Kalman filtering predicted future mean deviation (MD) more accurately than simple and modified regression models, especially in mild NTG cases. However, the study's homogenous sample and need for multiple baseline measurements limit generalizability. Predicting VF progression on a point-wise basis, indicating specific areas of vision loss, may be more valuable to patients than global VF loss indicators.\nArchetypal analysis (AA), a form of unsupervised ML, has also been used to predict VF progression [111, 112, 113] and risk of glaucoma progression [114] in POAG and ocular hypertensive patients with abnormal VF results. AA identified archetypes associated with structural glaucomatous changes in the retinal nerve fibre layer [111], classified various patterns of glaucomatous VF loss [113], and quantified central VF loss to improve prediction of future glaucomatous VF loss [112]. More recently, AA identified baseline VF result archetypes that may increase the risk of VF progression and POAG onset in ocular hypertensive patients, even before detectable structural glaucomatous damage [114]. This study used data collected over 20 years, demonstrating AA's potential for analysing longitudinal conditions, including IRDs."}, {"title": "4.1.2. Neural networks in prediction of visual field progression", "content": "The performance of convolutional neural networks (CNNs) compared to linear regression models in predicting VF progression in POAG patients has been assessed in [115]. Here, pointwise linear regression and regression on global indices were compared to a proposed CNN. The architecture of this CNN comprised of three blocks, each containing a 3D convolution, batch normalization and ReLu activation layers, followed by two fully connected"}, {"title": "4.2. AI techniques in age-related macular degeneration", "content": "Age-related macular degeneration (AMD) is a condition that can cause central vision loss [120]. Visual loss occurs in late stages through two pro- cesses: dry (atrophic) AMD involves progressive retinal layer atrophy [121], while wet (neovascular) AMD involves new blood vessel growth that can leak fluid and blood into the retina [122]. Anti-complement factor thera- pies have been shown to reduce the expansion rate of atrophic area [123]. Anti-vascular endothelial growth factor (anti-VEGF) therapies can stabilize"}, {"title": "4.2.1. Machine learning in prediction of future visual function", "content": "Most studies use VA as a measure of visual function due to its routine measurement in practice and repeatability as an indicator of macular func- tion [125]. Five ML algorithms (AdaBoost.R2, Random Forests, Extremely Randomised Trees, least absolute shrinkage and selection operator [Lasso] and Gradient Boosting) were compared to predict VA at three and 12 month timepoints in patients with neovascular AMD following treatment with three anti-VEGF injections [36]. In addition to VA, models were also trained on OCT measurements. Of the models tested, Lasso had the lowest mean abso- lute error in predicting VA after 12 months. Accuracy was further improved by adding additional data from previous visits.\nVarious decision trees have also been used in this area. AutoML and XG- Boost predicted whether VA in neovascular AMD patients would be above or below driving standard cutoffs after one year of anti-VEGF treatment [126]. Both models achieved AUROCs of around 0.85. Using the What-if Tool (an XAI technique) [127], the model's tendency to overpredict negative outcomes in Asian patients was identified and adjusted, improving accuracy. This ability to calibrate models based on explainable findings is valuable for IRDs due to their heterogeneity."}, {"title": "4.2.2. Neural networks in prediction of future visual function and disease progression", "content": "A recent study used a CNN to model the progression of geographic atro- phy lesion growth, utilizing FAF and OCT images from 184 eyes, with areas of geographic atrophy manually delineated [67]. Patients were followed up every three months for over 12 months. In order to predict progression at certain time points, the model estimates the time derivative for each OCT scan with a smaller neural network, which is embedded with a linear clas- sification layer. This model achieved an R-squared value of 0.37 compared to ground truths for predicting progression rates over three years, however"}, {"title": "4.3. AI techniques across multiple eye conditions", "content": "Although previous sections of this review have explored the utility of AI in specific ocular conditions, AI can also differentiate between a range of con- ditions. This generalizability is particularly useful for IRDs, as this group of conditions comprises many different diseases and presentations. Most stud- ies applying AI across multiple ocular conditions have used CNNs for their efficacy in handling large datasets and image classification [57]. CNNs have been used to grade and distinguish between diabetic retinopathy (DR), AMD, glaucoma, retinal vessel occlusions [130, 131, 132], and more specific macular conditions such as diabetic macular oedema (DMO), drusen, and choroidal neovascularisation (CNV) [133, 134], however these studies often lack XA\\u0399"}, {"title": "5. Conclusion", "content": "The current literature has been successful in segmenting and classifying IRDs using various AI techniques, however more research is required to pre- dict visual function and future progression. Most research in the field of AI and IRDs has been conducted on imaging data, such as OCT and fundus photos, hence it may prove beneficial to further investigate VA, VF, and even ERG data. It may also be of use to incorporate patient data such as medical history, demographics, and genetic information for a more holistic approach. AI can process large amounts of data and infer patterns, which provides opportunity for disease modelling and prediction, which is not cur- rently available for IRDs.\nThis can aid in providing personalized care and assisting with clinical de- cision making. Techniques used to investigate other ocular conditions may be translatable to IRDs. The role of XAI is emerging as crucial to not only strengthen clinician and patient trust in the models, but also to facilitate troubleshooting of the model, enhance accountability and alleviate ethical and legal concerns. Patient and practitioner feedback and acceptance must also be assessed prior to implementing any AI tools in practice.\nThere is much potential for the use of XAI techniques in IRDs. Although there is still considerable research to be done, it paves the way for greater data-driven patient care."}]}