{"title": "SafeDrive: Knowledge- and Data-Driven Risk-Sensitive Decision-Making for Autonomous Vehicles with Large Language Models", "authors": ["Zhiyuan Zhou", "Heye Huang", "Boqi Li", "Shiyue Zhao", "Yao Mu"], "abstract": "Recent advancements in autonomous vehicles (AVs) leverage Large Language Models (LLMs) to perform well in normal driving scenarios. However, ensuring safety in dynamic, high-risk environments and managing safety-critical long-tail events remains a significant challenge. To address these issues, we propose SafeDrive, a knowledge- and data-driven risk-sensitive decision-making framework, to enhance AV safety and adapt-ability. The proposed framework introduces a modular system comprising: (1) a Risk Module for comprehensive quantification of multi-factor coupled risks involving driver, vehicle, and road interactions; (2) a Memory Module for storing and retrieving typical scenarios to improve adaptability; (3) a LLM-powered Reasoning Module for context-aware safety decision-making; and (4) a Reflection Module for refining decisions through iterative learning. By integrating knowledge-driven insights with adaptive learning mechanisms, the framework ensures robust decision-making under uncertain conditions. Extensive evaluations on real-world traffic datasets characterized by dynamic and high-risk scenarios, including highways (HighD), intersections (InD), and roundabouts (RounD), validate the framework's ability to enhance decision-making safety (achieving a 100% safety rate), replicate human-like driving behaviors (with decision alignment exceeding 85%), and adapt effectively to unpredictable scenar-ios. The proposed framework of SafeDrive establishes a novel paradigm for integrating knowledge- and data-driven methods, highlighting significant potential to improve the safety and adaptability of autonomous driving in long-tail or high-risk traffic scenarios. Project page: https://mezzi33.github.io/SafeDrive/.", "sections": [{"title": "I. INTRODUCTION", "content": "UTONOMOUS vehicles (AVs) have advanced significantly in recent years, achieving the ability to operate safely in most traffic scenarios [1]. To enhance their capacity to handle diverse scenarios and progress toward higher levels of automation, data-driven paradigms leverage vast real-world driving data and learning algorithms, achieving remarkable accuracy in tasks such as prediction and decision-making [2], [3].\nHowever, data-driven paradigms face several limitations: 1) data bias, which prioritizes common scenarios while neglecting rare corner cases; and 2) a lack of interpretability, with AVs operating as black boxes, making causal relationships unclear and safety difficult to guarantee. These limitations hinder AVs' ability to make rational, human-acceptable decisions in rare and unpredictable long-tail scenarios [4], [5].\nTo achieve fundamental progress in autonomous driving, enabling AVs to acquire human-like interactive driving abilities through understanding and learning from human behavior is crucial [6]. With their human-like experience and common sense, large language models (LLMs) as decision-making agents present a promising direction [7]. By incorporating the human-like capabilities of learning and reasoning into the system, LLM-based agents aim to enhance the contextual understanding and adaptability of AVs.\nDespite the promising capabilities of LLM-powered agents, they can occasionally display overconfidence, leading to risky actions [8]. While the safety performance of LLM-driven agents has been studied extensively, most research focuses on simple simulated highway environments, where risk sources are limited, and interactions are minimal. However, real-world traffic is complex, dynamic, and coupled, with frequent potential conflicts, making it more challenging for LLM-based agents to accurately identify all potential risks and ensure safety [6]. Consequently, the following research questions are crucial for advancing higher-level LLM-based driving agents:\n1) RQ1. How can we effectively model and quantify the coupled risks in safety-critical environments?\n2) RQ2. How can we guide the LLM-based agents to derive safe and human-like driving behavior?\nTo address the two key questions, this paper proposes a novel knowledge- and data-driven risk-sensitive decision-making framework: SafeDrive. It introduces a comprehensive risk quantification model that considers multiple risk sources from the human, vehicle, and road, providing precise and uni-versally applicable risk assessments. Additionally, it leverages real-world driving data and scenario-risk knowledge to enable LLM-based safe decision-making. The SafeDrive Framework operates through a four-module loop, with OpenAI ChatGPT-4 (GPT-4) as the driving agent. The modules are as follows:\n1) Risk Module: outputs comprehensive and accurate risk assessments for various scenarios.\n2) Memory Module: stores and retrieves relevant past expe-riences according to the scene description and risk levels output by the Risk Module."}, {"title": "II. RELATED WORKS", "content": "Risk Quantification. Risk quantification is essential for collision prevention in AVs. Classical methods considering vehicle dynamics such as Time to Collision (TTC) [12], Time Headway (THW) [13], Time to React (TTR) [14], and Lane-Crossing Time (TLC) [15] are widely applied in traffic scenarios due to their simplicity and ease of implementation. However, these methods often fall short in dynamic, multi-dimensional environments, where risk factors change rapidly and interact in complex ways [13]. To address these limi-tations, Shalev-Shwartz et al. propose responsibility-sensitive safety (RSS) [16], a model designed for more interpretable, white-box safety assurance. However, dilemmas still exist, such as the determination of a large number of parameters.\nTo overcome these limitations, advanced methods have been proposed. The Artificial Potential Field (APF) method [17] uses potential fields to model vehicle risks, enabling basic collision avoidance. Gerdes et al. [18] extended the APF by incorporating lane markings to create detailed risk maps. Wang et al. [19], [20] integrate road potential fields with vehicle dynamics and driver behavior, improving the accuracy of risk simulations and reducing collision risks in complex scenarios. However, these approaches often focus on current traffic states, rely on numerous parameters, and lack adaptabil-ity in uncertain environments. Kolekar et al. [21] introduce the Driver's Risk Field (DRF), a two-dimensional model that incorporates drivers' subjective risk perceptions based on probabilistic beliefs. By integrating subjective risk assess-ments, these improved APF and DRF methods better simulate traffic system dynamics and enhance multi-dimensional risk evaluation. However, the DRF proposed by Kolekar et al. [22] only accounts for the risk in the heading direction, the forward-facing half circle of the vehicle, falling short in providing a comprehensive omnidirectional risk quantification. This limitation can be compensated by the risk quantification model introduced in this paper.\nLLM in Decision Making. Decision-making is crucial for autonomous driving, as it directly determines the vehi-cle's ability to navigate complex, dynamic, and high-conflict traffic scenarios safely and efficiently [23]. Traditional data-driven decision-making methods have inherent limitations. These algorithms are often regarded as black boxes, and their sensitivity to data bias, difficulty in handling long-tail scenarios, and lack of interpretability present significant challenges in providing human-understandable explanations for their decisions, especially when adapting to data-scarce long-tail scenarios [24], [25].\nAdvancements in LLMs offer valuable insights for address-ing decision-making challenges in autonomous driving. LLMs demonstrate human-level capabilities in perception, prediction, and planning [26]. LLMs, when coupled with a vector database as memory, showcase impressive enhancements in analytical capabilities in certain areas [27]. Li et al. propose the concept of knowledge-driven autonomous driving, showing that LLMs can enhance real-world decision-making through common-sense knowledge and driving experience [28]. Wen et al. proposed the DiLu framework, which integrates reasoning and reflection for knowledge-driven, continuously evolving decision-making, outperforming reinforcement learning methods [29]. Jiang et al. employ DiLu as the foundation and develop a knowledge-driven multi-agent framework for autonomous driving, demonstrating its efficiency and accuracy across var-ious driving tasks [30]. Fang et al. [31] focus on using LLMs as agents for cooperative driving in different scenarios. Recent advancements also highlight LLMs' potential for multimodal reasoning. Hwang et al. [32] introduce EMMA, an End-to-End Multimodal Model using pretrained LLMs for motion planning, achieving state-of-the-art results with nuScenes and WOMD. However, its reliance on image inputs and high computational costs pose challenges. Sinha et al. [33] propose a two-stage framework combining a fast anomaly classifier with fallback reasoning for real-time anomaly detection and reactive planning, demonstrating robustness in simulations. These studies emphasize the potential of LLMs in decision-making of AVs, where real-time reasoning and adaptability are essential. However, most research focuses on simple scenarios and lacks adaptability in high-conflict environments. This pa-per explores LLMs' knowledge-driven capabilities to address decision-making challenges in dynamic and highly-uncertain scenarios, filling a critical gap in the field."}, {"title": "III. FRAMEWORK", "content": "In this section, we propose SafeDrive, a knowledge- and data-driven risk-sensitive decision-making framework based on LLM, as shown in Fig. 1. SafeDrive combines naturalistic driving data and high-risk scenarios to enable AVs to make adaptive, safe decisions in complex, dynamic environments.\nThe framework begins with massive data input (Figure 1a), combining all-road users, all-condition scenarios, and full-coverage data into a comprehensive database of typical and high-risk driving scenarios. In the coupled risk quantification module (Fig. 1b), advanced risk modeling, including cost maps and multi-dimensional risk fields, dynamically quantifies risks, providing detailed inputs for decision-making. The LLM decision-making module (Fig. 1c) uses data-driven generation, risk prior knowledge, and chain-of-thought (CoT) reasoning to generate real-time, risk-sensitive decisions. Additionally, adaptive memory updates ensure that similar experiences can be recalled to refine the decision process. These decisions are embedded into a risk-sensitive driving agent (Fig. 1d) that delivers accurate risk warnings, recalls past experiences, and makes adaptive decisions. The self-adjusting system ensures real-time risk identification and enables continuous updates to driving policies through a closed-loop reflection mechanism.\nOverall, SafeDrive enhances real-time responsiveness, de-cision safety, and adaptability, addressing challenges in high-risk, unpredictable scenarios."}, {"title": "IV. METHODOLOGY", "content": "In this section, we aim to address the two crucial research questions for achieving higher-level AVs. First, we introduce a coupled risk quantification model. Second, we propose a risk-sensitive decision-making method with the integration of LLM and the risk model."}, {"title": "A. Coupled Risk Quantification", "content": "RQ1. How can we effectively model and quantify the coupled risks in safety-critical environments?\nThe concept of perceived risk, as defined by Naatanen and Summala et al. [34], is the product of the subjective probability that an event will occur and the consequence of that event. In this paper, we employ a dynamic Driver Risk Field (DRF) model that adapts to vehicle speed and steering dynamics, inspired by Kolekar et al. The DRF represents the driver's subjective belief about future positions, assigning higher risk near the ego vehicle and decreasing with distance. Event consequences are quantified by assigning experimentally determined costs to objects in the scene based on their dan-ger level, independent of subjective assessments. The overall Quantified Perceived Risk (QPR) is computed as the sum of the event costs and the DRF across all grid points. This approach effectively captures uncertainties in driver perception and actions, offering a comprehensive measure of driving risk.\nDriver Risk Field. This work extends the DRF to account for dynamic changes based on vehicle speed and steering angle. The DRF is computed using a kinematic car model, where the predicted path depends on the vehicle's position (Xcar, Ycar), heading car, and steering angle \u03b4. The radius of the predicted travel arc, assuming a constant steering angle, is given by:\n$R_{arc} = \\frac{L}{tan(\\delta)}$\nwhere L is the car's wheelbase. Using the vehicle's position and arc radius, the center of the turning circle (xc, yc) is found, which is used to compute the arc length s, representing the distance along the path.\nThe DRF is modeled as a torus with a Gaussian cross-section:\n$z(x,y) = a exp \\left(-\\frac{((x - x_c)^2 + (y - y_c)^2 - R_{arc})^2}{2\\sigma^2}\\right)$"}, {"title": "V. EXPERIMENT RESULTS", "content": "The experiment section of this study is divided into two parts: one focusing on the robustness of the risk quantification model and the other on the performance of SafeDrive."}, {"title": "A. Performance on Risk Quantification", "content": "Datasets Preparation. To evaluate the robust performance of our model across diverse environments, we used the HighD [9], RounD [11], and InD [10] datasets. The HighD dataset (60 recordings from six highways) tested the model's handling of car-following and lane-changing on highways. The InD dataset (11,500 trajectories at urban intersections) assessed its ability to manage diverse participants and un-predictable urban behaviors. The RounD dataset (13,700 road users in roundabouts) evaluated its performance in high-risk maneuvers and interactions. Together, these datasets provided a robust framework for testing the model across highways, intersections, and roundabouts, ensuring reliability in varied real-world scenarios.\nRisk Quantification Process. The process is designed to ac-curately capture and assess the intricate risk behind real-world driving scenarios, as shown in Fig. 5. It presents autonomous driving risk quantification and behavioral analysis across three distinct driving scenarios: a highway, a roundabout, and an intersection. For instance, in the highway scenario, the ego vehicle (ID 469) performs a left lane change while facing the risk of high-speed overtaking vehicles in the target lane. These scenarios are visualized with risk quantification heatmaps that clearly highlight high-risk areas, providing critical support for decision-making optimization and safety enhancement.\nFirst, we demonstrate that our risk quantification aligns with common traffic logic. The continuous QPR variation of the ego vehicle as it passes through an urban intersection in the InD dataset. The QPR increases as the vehicle approaches the intersection with other vehicles waiting to merge, and returns to normal levels after the ego vehicle clears the intersection. This behavior accords with common traffic sense. Furthermore, if we integrate this result into a control system, the ego vehicle will decelerate as it approaches the intersection to mitigate the risk, then idle or accelerate after passing when the QPR normalizes. This mirrors a safe, human-like driving behavior, which is a desirable property for autonomous driving system, as shown in Fig. 6.\nSecond, we analyzed the QPR distribution using 500,000 random samples from surrounding vehicles. Thresholds for low, medium, and high risk levels were determined based on the 30th and 70th percentiles: risks below the 30th percentile were classified as low, between the 30th and 70th as medium, and above the 70th as high. It ensures accurate risk assessment and effective conversion into prompts for LLM input.\nTo validate the reliability of our established thresholds, we compared them with commonly accepted safety metrics. We analyzed QPR against THW to evaluate longitudinal risk quantification. A safe THW, typically considered to be 2 seconds, helps maintain adequate following distances and reduces the risk of potential collisions. As shown in Fig. 7 (a), most samples categorized as low risk fall within this range. Furthermore, the distinct separation between the three risk levels in the graph demonstrates the effectiveness of our model in quantifying longitudinal risk.\nIn complex multi-lane environments, vehicles in adjacent lanes or at intersections significantly affect driving decisions and safety. Unlike traditional systems focused on longitudinal safety, our model incorporates lateral risk quantification. As shown in Fig. 7 (b), the relationship between QPR and lateral distance confirms the model's effectiveness. By accounting for both longitudinal and lateral risks, the system predicts and mitigates side maneuver and lane-change risks, frequent causes of accidents. Our risk model differentiates between various road participants, such as sedans and trucks, to account for their unique risk profiles. Trucks, for instance, are classified as higher risk due to their larger size and the more severe consequences of potential collisions. Fig. 7 (c) demonstrates that our model effectively captures these nuances, enhancing the precision and safety of its responses in complex urban environments."}, {"title": "B. Performance on Reasoning and Decision-Making", "content": "We begin by showcasing a sample of the decision-making process. As shown in Fig. 8, our agent successfully follows navigation instructions while maintaining safety. The process starts with scenario description, which outlines the vehicle's state, traffic dynamics, and available actions. Dynamic risk quantification follows, using heatmaps and textual notifications to identify high-risk traffic components. Finally, the reasoning module integrates these inputs to assess lane-change feasibility and determine the optimal driving strategies. By incorporating all relevant environmental details, this streamlined process ensures comprehensive decision-making.\nOur results are based on the average performance over ten experimental episodes. Table I presents the average response time, token count, and number of pre-loaded memories.\nSafety Rate Improvement: The safety rate is defined as the probability that a vehicle takes safety measures to avoid accidents. We conduct a comparative analysis of our method against several standard approaches and evaluate the system's safety performance with and without the Risk Module using the same datasets. An action is deemed safe if it does not disrupt the behavior of other vehicles, such as causing sudden braking or unexpected maneuvers. Specifically, IDM [35] employs the Intelligent Driver Model to maintain safe distances from other agents and adhere to the reference lane.\nAs shown in Fig. 9 (a), and Table II, for Safety Rates, IDM achieves 76.00%, 92.50%, and 86.67% on the InD, HighD, and RounD datasets, respectively, while GPT-4 performs lower at 77.27%, 77.46%, and 69.23%. Adding the Memory Module improves safety rates to 86.36%, 81.84%, and 80.77%. With the Risk Module, safety rates reach 100% in HighD and RounD, and 95.46% in InD. Combining both modules achieves 100% safety across all datasets, demonstrating comprehensive safety assurance in diverse and complex scenarios.\nThese enhancements highlight the Risk Module's effec-tiveness in improving system safety, with no unsafe actions generated throughout the entire experimental process. The results further emphasize the module's adaptability and risk mitigation capabilities, ensuring robust performance across different driving environments, even in challenging conditions.\nFig. 10 presents a typical example demonstrating the safety enhancement of our framework. It compares performance with and without the safety module. Without the safety module, the model shows overconfidence in high-risk scenarios, failing to identify potential threats, leading to unsafe lane-change decisions. In contrast, with the safety module, the GPT-4 agent better understands potential risk sources in the environment, accurately identifying high-risk targets (e.g., Vehicle 6) and making more cautious decisions (e.g., staying in the current lane). This extra caution provided by risk module helps prevent the agent generate risky behaviors, thus significantly improving decision safety and reliability.\nTrue Decision Alignment Enhancement: The decision alignment refers to the percentage of decisions output by the LLM agent that align with the subsequent real-world human driver decisions. In this part of the experiment, we conducted tests to compare the system's decision accuracy with and without both the risk and memory modules, using the same datasets for both conditions. A generated decision is considered correct if it aligns with the true actions taken by real-world human drivers in the subsequent few frames in our hand-labeled datasets.\nBy integrating the Risk Module and Memory Module, the system's decision alignment percentage has increased significantly, as demonstrated in Fig. 9 (b) and Table II. For decision alignment, IDM achieves 72.00%, 76.25%, and 73.33% on the InD, HighD, and RounD datasets, respectively. GPT-4 decreases to 68.18%, 70.42%, and 53.85%. Adding the Memory Module significantly improves alignment to 81.82%, 87.32%, and 76.93%. While the Risk Module alone performs slightly lower, combining both modules achieves 86.36%, 86.21%, and 84.61%, demonstrating the best consistency and stability. This improvement highlights the effectiveness of our framework in achieving decisions aligned with real-world optimal outcomes. By integrating risk assessment and memory recall, the system mimics human-like decision-making, ensur-ing safer and more reliable performance. The high alignment across diverse datasets-highway, urban intersections, and roundabouts-demonstrates the framework's robustness and adaptability in navigating dynamic traffic environments and varying decision-making challenges.\nDuring our experiments, we observed that adjusting the system's focus on risk levels through modified prompt oc-casionally led the agent to exhibit higher-level human-like driving behavior. For instance, in a scenario where a following vehicle overtakes the ego vehicle at high speed on a highway, increasing the LLM's focus on quantified risk level guided the system to shift to the right lane, clearing the path for the following vehicle and thus mitigating the risk. This re-sponse mirrors the behavior of experienced human drivers on highways, further demonstrating the effectiveness of our risk quantification model in emulating such actions. This surprising finding indicates that our system not only addresses immediate risks, but also fosters decisions that consider long-term safety, a valuable property for AVs. Such higher-level, human-like behavior is a critical feature, positioning our system as a versatile solution for advancing autonomous driving."}, {"title": "VI. CONCLUSION", "content": "In this paper, we introduce SafeDrive, a knowledge-and data-driven framework for AVs' risk-sensitive decision-making, addressing the critical challenges of safety in un-predictable, high-risk and long-tail scenarios. By proposing a unified risk quantification model capable of omnidirectional evaluation of multi-factor coupled risks, the framework effec-tively models the complexities of stochastic urban environ-ments (RQ1). Integrating this risk model into an LLM-driven decision-making framework, powered by GPT-4, enables safe, human-like decision-making and continuous adaptability in uncertain traffic conditions (RQ2). Extensive evaluations using real-world datasets (HighD, InD, and RounD) demonstrate the framework's robust performance, achieving a 100% safety rate and over 85% alignment with human driving behaviors. This highlights the framework's effectiveness in replicating human-like strategies while ensuring long-term reliability across di-verse and challenging scenarios.\nIn the future, we will enhance the risk quantification model by incorporating more detailed environmental features, such as road boundaries and obstacles. Additionally, transitioning to advanced LLMs with improved reasoning capabilities, such as ChatGPT 01-preview [36], will enable more nuanced decision-making. By leveraging fine-tuning techniques emphasized in recent research [37], we aim to further improve the system's expertise in specific domains, such as traffic knowledge, making it a more mature and capable driving agent."}]}