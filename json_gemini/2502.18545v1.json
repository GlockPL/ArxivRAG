{"title": "PII-Bench: Evaluating Query-Aware Privacy Protection Systems", "authors": ["Hao Shen", "Zhouhong Gu", "Haokai Hong", "Weili Han"], "abstract": "The widespread adoption of Large Language Models (LLMs) has raised significant privacy concerns regarding the exposure of personally identifiable information (PII) in user prompts. To address this challenge, we propose a query-unrelated PII masking strategy and introduce PII-Bench, the first comprehensive evaluation framework for assessing privacy protection systems. PII-Bench comprises 2,842 test samples across 55 fine-grained PII categories, featuring diverse scenarios from single-subject descriptions to complex multi-party interactions. Each sample is carefully crafted with a user query, context description, and standard answer indicating query-relevant PII. Our empirical evaluation reveals that while current models perform adequately in basic PII detection, they show significant limitations in determining PII query relevance. Even state-of-the-art LLMs struggle with this task, particularly in handling complex multi-subject scenarios, indicating substantial room for improvement in achieving intelligent PII masking.", "sections": [{"title": "1 Introduction", "content": "Recent years have witnessed the widespread adoption of Large Language Models (LLMs), with an increasing number of users directly interacting with these models through APIs for various tasks, ranging from daily conversations to complex analytical work (Sun et al., 2023; Yang et al., 2024b; Wong et al., 2023). Despite the convenience these services offer, users often overlook a significant privacy risk: the prompts submitted to LLMs frequently contain substantial personally identifiable information (PII) (Achiam et al., 2023). Such information is vulnerable not only to interception by malicious actors during transmission (Parast et al., 2022) but also to potential misuse by unethical service providers who might collect and incorporate it into subsequent model training, leading to permanent privacy breaches (Liu et al., 2023).\nCurrent practices reveal that the vast majority of users adopt a zero-protection approach when utilizing LLM services, submitting original prompts containing PII directly to the LLMs. While an obvious protection strategy would be to mask all PII (Nakamura et al., 2020; Biesner et al., 2022;Lukas et al., 2023), as shown in Fig. 1, this approach significantly compromises service quality. An ideal Privacy Protection System should maintain LLMs' functionality while maximizing user privacy protection. For instance, when a user inquires about a candidate's suitability for a senior researcher position, masking their educational background and work experience would render the LLM incapable of making an effective assessment.\nThis observation motivates our proposal of a query-unrelated PII masking strategy: Masking only the PII irrelevant to user queries while retaining essential information. In the aforementioned example, this approach would preserve the candidate's educational and professional information while masking unrelated personal details such as contact information.\nThe implementation of query-unrelated PII masking stragety faces two-tier challenges. The first involves accurate identification of all PII within the prompt, serving as foundational work."}, {"title": "2 Related Work", "content": "Text privacy protection has emerged as a critical challenge in natural language processing applications. Papadopoulou et al. (2022) proposed text sanitization that combines entity detection with privacy risk assessment to guide masking decisions. Shen et al. (2024) extended this approach with an end-to-end framework that preserves task utility during privacy protection. Exploring information preservation, Meisenbacher and Matthes (2024) introduced differential privacy techniques for text modification, demonstrating improved semantic retention over traditional masking methods. While these approaches have advanced privacy protection techniques, they primarily focus on document-level sanitization without considering the dynamic nature of user interactions. Our work introduces query-aware privacy protection that adaptively balances information utility with privacy requirements."}, {"title": "2.2 Query-Aware PII Detection", "content": "Traditional PII detection has evolved from rule-based systems (Ruch et al., 2000; Douglass et al., 2005) to neural architectures (Deleger et al., 2013; Dernoncourt et al., 2017; Johnson et al., 2020), with recent work demonstrating the effectiveness of transformer-based models in identifying sensitive information (Asimopoulos et al., 2024). Large language models have shown promising results in recognizing diverse PII types (Singhal et al., 2024; Bubeck et al., 2023), yet they treat all sensitive information with uniform importance. Our framework introduces a novel dimension to PII detection by incorporating query relevance assessment. Rather than applying uniform protection measures, we focus on identifying which PII elements are essential for addressing user queries. This approach enables more nuanced privacy protection by distinguishing between query-related and query-unrelated sensitive information, though the actual masking or protection mechanisms are left to downstream applications."}, {"title": "2.3 Privacy Protection Benchmarks", "content": "Existing benchmarks for evaluating privacy protection methods have primarily focused on general PII detection capabilities. Pil\u00e1n et al. (2022) introduced TAB, a benchmark based on legal court cases, which evaluates text anonymization performance. However, it does not assess the model's ability to distinguish query-related information. The recent work by Sun et al. (2024) proposed evaluation metrics for privacy-preserving prompts, but their focus remains limited to general desensitization effectiveness. Li et al. (2024) developed LLM-PBE to assess privacy risks in language models, though their emphasis is on model-side privacy rather than input text protection."}, {"title": "3 PII-Benchmark", "content": "Privacy Protection Systems target at maintaining LLM functionality while maximizing user privacy protection. Let \\(p\\) be a prompt consisting of a user description \\(d\\) and a query \\(q\\). The description \\(d\\) contains information about multiple subject individuals \\(S = \\{s_1, ..., s_m\\}\\). For each subject \\(s_i\\), there exists an associated set of PII entities \\(E_i = \\{e_1, ..., e_{n_i}\\}\\). The complete set of PII entities in prompt \\(p\\) is defined as \\(E = \\bigcup_{i=1}^{m} E_i\\), where each entity \\(e \\in E\\) belongs to a predefined PII type from set \\(T\\) (see Appendix A.2). Let \\(E_q \\subseteq E\\) denote the subset of PII entities that are necessary for answering query \\(q\\).\nBased on this definition, we propose three fundamental evaluation tasks for Privacy Protection Systems:"}, {"title": "3.1 Task Definition", "content": "(1) PII Detection Task: Given prompt \\(p\\), the model needs to: identify the minimal text spans for all PII entities \\(e \\in E\\); establish associations between each entity \\(e\\) and its corresponding subject \\(s \\in S\\); assign the correct PII type \\(t \\in T\\) to each entity \\(e\\).\n(2) Query-Related PII Detection Task: Given prompt \\(p\\), the model needs to determine the minimal subset of PII entities \\(E_q \\subseteq E\\). This subset should only contain PII entities necessary to answer query \\(q\\), maximizing protection of non-relevant personal information.\n(3) Query-Unrelated PII Masking Task: This task is what we propose the optimal form of privacy protection system. Given prompt \\(p\\), the model should generate a modified description \\(d'\\) where query-unrelated PII entities are masked while preserving the necessary ones. Formally, the model should identify \\(E_q\\) and generate \\(d'\\) where all PII entities in \\(E \\setminus E_q\\) are masked while preserving those in \\(E_q\\). The masking operation should maintain text coherence and readability while ensuring effective privacy protection for non-essential personal information. The resulting prompt \\(p' = (d', q)\\) should enable LLMs to accurately address the query while minimizing exposure of irrelevant personal information."}, {"title": "3.2 PII-Bench Construction", "content": "Based on the task definition above, we designed an automated process for constructing the PII evaluation dataset, as illustrated in Fig. 2."}, {"title": "3.2.1 PII Entity Generation", "content": "Following Papadopoulou et al. (2022), we expanded the PII type set \\(T\\) into 55 subcategories (see Appendix A), employing two complementary strategies for entity generation:\n(1) Rule-based Generation: Applicable for deterministic PII types with fixed formats or enumerable value sets, such as phone numbers, email addresses, and standardized ID numbers. (2) LLM-based Generation: Applicable for non-deterministic PII types requiring contextual understanding and real-world knowledge, such as occupation descriptions and detailed addresses. This method leverages GPT-4-0806 to generate semantically appropriate and contextually relevant entities."}, {"title": "3.2.2 User Description Generation", "content": "The construction of single-subject descriptions follows a three-stage process:\n(1) Entity Selection: For subject \\(s\\), randomly sample \\(n\\) entities (\\(4 < n < 16\\)) from different PII types to construct entity set \\(E_i\\). The sampling process ensures diversity of PII types while considering their natural distribution in real-world scenarios. (2) Consistency Optimization: Ensure logical compatibility among entities in \\(E_i\\) through designed verification rules. For example, verifies reasonable correspondence between age and educational history as shown in Fig. 2. (3) User Desc Generation: Selects appropriate expression styles to generate the user description. It employs formal description formats like job resumes and employee records in professional scenarios; casual expressions like personal profiles and self-introductions in social scenarios.\nThe construction process for multi-subject related descriptions includes these key steps:\n(1) Entity Selection: Construct relationship network \\(R(s_i, s_j)\\) for subject pairs \\((s_i, s_j)\\). Relationship types include intersection relationships like colleagues and alumni, hierarchical relationships like parent-child and teacher-student, and non-intersection relationships with no direct connection. (2) Consistency Optimization: This stage first establishes entity dependency rules based on relationship type \\(R\\). Then ensures consistency of shared attributes among related subjects, such as company address for employees of the same company. This stage also derives related attributes based on relationship type, such as age differences in parent-child relationships. And finally remove the sample which contains contradictions. (3) User Desc Generation: This stage designs natural interaction environments matching relationship characteristics, placing subjects in realistic scenarios (like meetings, family activities) and constructing multi-party dialogue flows to reflect interactive relationships."}, {"title": "3.2.3 Query Construction", "content": "For each description \\(d\\), query construction follows a four-phase process:\n(1) Entity Selection: Randomly sample \\(k\\) entities (\\(1 \\leq k \\leq 3\\)) from \\(E\\) to form query-relevant entity set \\(E_q\\). (2) Scenario Design: Construct query contexts that align with real-world application sce-\nnarios. The goal is to simulate actual user needs for PII information in specific situations. For example, when \\(E_q\\) contains \u201cWork Experience\u201d: \"5 years as Machine Learning Engineer\u201d, \u201cEducation Background\u201d: \u201cStanford University Ph.D. in Computer Science\u201d, this stage generates query scenarios like \u201cAs a hiring manager, I need to verify if this candidate's education and relevant work experience meet the requirements for the Senior Researcher position\u201d. (3) Entity Abstraction: Map specific PII entities in \\(E_q\\) to abstract representations, maintaining basic semantic properties while enhancing privacy protection. (4) Query Generation: Integrate abstract entities into corresponding scenarios through GPT-4-0806 model to generate natural queries \\(q\\) that fit practical application scenarios."}, {"title": "3.2.4 Human Verification", "content": "All content generated by GPT-4-0806 undergoes rigorous verification by five professional annotators and the authors, focusing on: (1) Completeness and accuracy of PII entity annotations in description \\(d\\). (2) Correspondence between query \\(q\\) and query-relevant entity set \\(E_q\\). (3) Overall semantic coherence and scenario authenticity. Complete annotation guidelines and quality control procedures are detailed in Appendix E."}, {"title": "3.3 Dataset Partitioning and Statistics", "content": "Table 3 presents the partition and key statistics of PII-Bench, which comprises two main datasets (PII-single and PII-multi) and two specialized test sets (PII-hard and PII-distract). Each sample follows a consistent JSON structure containing four key components: user description, query, comprehensive PII entity annotations, and query-relevant PII labels, as illustrated in Fig. 3."}, {"title": "PII-Single and PII-Multi:", "content": "Based on the number of subjects in descriptions, the dataset is divided into two main subsets. PII-Single contains 2000 description-query pairs involving single subjects, focusing on model performance in handling individual information. PII-Multi contains 2000 description-query pairs involving multiple related subjects, evaluating model capability in handling privacy information within complex interpersonal networks."}, {"title": "Test-Hard Construction:", "content": "Select 200 challenging instances from PII-Single and PII-Multi to construct Test-Hard dataset, based on criteria including: (1) Maximum character length of description text \\(d\\). (2) Highest PII entity density (\\(|E|/|d|\\)). (3) Samples with the most query-relevant entities (\\(E_q|\\))."}, {"title": "Test-Distract Construction:", "content": "Construct 200 samples simulating complex multi-user interaction scenarios. Each sample integrates five different descriptions \\((d_1, ..., d_5\\)\\) from PII-Single and PII-Multi, and constructs queries \\(q\\) involving three of these descriptions based on professional networks, knowledge platforms, and community forum interaction templates. The generation process employs specific dialogue flow transformation strategies to ensure natural transitions and semantic coherence between multiple descriptions. Scenario design particularly emphasizes simulating real-world information interference and complex interaction patterns."}, {"title": "3.4 Human Performance", "content": "To establish a human baseline for PII-Bench, we recruited 25 graduate students specializing in data security from top universities across China. All participants had at least two years of research experience in privacy protection and information security. Before the formal evaluation, participants completed a comprehensive training session and passed a qualification test (detailed in Appendix C). We designed two evaluation sets: a main test set comprising 400 randomly sampled instances (200 each from PII-single and PII-multi), and a challenging set of 100 instances from PII-distract. Each instance underwent independent assessment by five participants through our online evaluation platform. Participants performed two sequential tasks: PII recognition, which involved determining minimal text spans, associated subjects, and PII types for all entities in the user description, followed by query-relevant PII detection to identify entities essential for addressing the given query. The result of the human baseline is shown in Table 2."}, {"title": "4 Experiments", "content": "The evaluation encompassed both API-based and open-source large language models. API-based models included GPT-40-2024-0806 (GPT4o) (OpenAI, 2024), Claude-3.5-Sonnet (Claude3.5) (Anthropic, 2024), and DeepSeek-Chat DeepseekV3 (Liu et al., 2024), accessed through their respective official APIs between January 1 and February 10, 2025. Open-source alternatives comprised Llama-3.1-70B-Instruct (Llama3.1) (Dubey et al., 2024), and Qwen-2.5-72B-Instruct (Qwen2.5) (Yang et al., 2024a).\nTo investigate scaling effects, we included two small-scale language models: Llama-3.1-8B-Instruct (Llama3.1-SLM) and Qwen-2.5-7B-Instruct (Qwen2.5-SLM). All experiments utilized default parameters with temperature set to 0 to ensure reproducibility.\nThe assessment incorporated multiple prompting strategies for query-related PII detection. Naive inputs the user description and query. Naive /w Choice includes a list of candidate PII entities to constrain the selection space. Self-CoT (Wei et al., 2022) incorporating step-by-step reasoning prompts. Auto-CoT (Zhang et al., 2022), which automates the generation of chain-of-thought demonstrations through three-shot setting. Self-Consistency (SC) (Wang et al., 2022), which synthesizes multiple reasoning paths to derive the final output. Plan-and-Solve CoT (PS-CoT) (Wang et al., 2023) develops a strategic plan before executing the solution process. Appendix D.3 provides details of each prompts.\nThe PII detection task evaluates model performance through two sets of metrics: Strict-F1 measures the accuracy of subject identification, entity span detection, and PII type classification simultaneously. Ent-F1 focuses on entity span detection independent of subject attribution and type classification. For query-related detection, model performance is measured through Precision, Recall, and F1. Considering the inherent variation in entity expressions and potential partial matches, RougeL-F is employed for both tasks to complement the exact matching metrics. Detailed computation procedures are provided in Appendix D.1."}, {"title": "4.1 Overall Setup", "content": "We implemented BILSTM-CRF as a traditional sequence labeling baseline, following the architecture proposed by Huang et al. (2015). We trained the model using Adam optimizer with a learning rate of le-3 and batch size of 32 for 50 epochs on the PII-Bench training set."}, {"title": "4.2 Performance on Query-Unrelated PII Masking", "content": "We evaluate models' performance on the query-unrelated PII masking task, which requires both accurate PII detection and relevance assessment.\nNotably, models achieve higher F1 scores in this combined task compared to individual query-relevance tasks. GPT40 reaches 0.77 F1 with Self-Consistency prompting, suggesting that the joint objective may provide complementary signals. Open-source models demonstrate comparable capabilities, with both Llama3.1 and Qwen2.5 achieving 0.76 F1 using Auto-CoT."}, {"title": "4.3 Performance on PII Detection", "content": "API-based LLMs achieve strong performance across standard datasets, with DeepSeekV3 and GPT40 leading in Strict-F1 scores (0.903 and 0.891 on PII-Single and PII-Multi, respectively). The open-source Llama3.1 shows competitive performance, particularly in entity recognition (Ent-F1: 0.942 on PII-Multi), while traditional BiLSTM-CRF maintains reasonable entity detection capabilities despite its simpler architecture."}, {"title": "4.4 Performance on Query-Related PII Detection", "content": "State-of-the-art LLMs exhibit limited performance in this task, with GPT4o achieving only 0.627 F1 score with naive prompting\u2014substantially below human performance (0.951 F1). Open-source alternatives demonstrate competitive performance, with Qwen2.5 reaching 0.615 F1.\nChain-of-thought approaches generally improve performance, with Self-Consistency and Auto-CoT proving most effective for different models (0.716 F1 for GPT40 with Self-Consistency; 0.710 F1 for Qwen2.5 with Auto-CoT). However, these benefits are highly dependent on model scale\u2014smaller models often show degraded performance with complex prompting strategies, indicating insufficient reasoning capabilities.\nThe provision of candidate PII entities (Naive w/ Choice) substantially improves performance across all models (e.g., GPT4o improves from 0.627 to 0.842 F1). However, the practical applicability of this approach is limited, as candidate entities are rarely available in real-world scenarios."}, {"title": "4.5 In-depth Performance Analysis", "content": "Analysis reveals consistent performance gaps between large and small models across tasks. Small-scale variants show 13-33% lower F1 scores in PII detection, with wider gaps in the query-related task (Llama3.1-SLM: 0.328 F1 vs. GPT4o: 0.627 F1) and query-unrelated masking task (0.42-0.54 F1 vs. 0.70-0.72 F1).\nAs shown in Fig. 5, models perform better at recognizing structured information (PER, CODE) compared to contextual entities (LOC, ORG), suggesting models have stronger capability in identifying patterns with clear structural characteristics.\nFig. 4 reveals several critical factors affecting model accuracy: performance degrades sharply beyond 5 subjects (F1 drops from 0.85 to 0.52), 33 PII entities, or 3000 characters in text length. Query-related entity count shows modest impact, with gradual decline from 1 to 7 entities.\nResults on specialized test sets (Table 5) reveal significant performance degradation in complex scenarios. On Test-Hard, featuring high PII density and long texts, even the best-performing Self-Consistency approach achieves only 0.463 F1. Test-Distract's multi-subject scenarios pose similar challenges."}, {"title": "5 Conclusion", "content": "This paper introduces PII-Bench, a comprehensive evaluation framework comprising 2,842 test samples, along with a query-unrelated PII masking strategy. Our evaluation reveals that while current LLMs achieve strong performance in basic PII detection (F1>0.90), they show limited capability in query-relevance assessment (F1<0.63) and struggle with complex multi-subject scenarios. Small-scale models demonstrate substantially lower performance across all tasks. These findings establish important benchmarks for privacy-preserving systems and highlight critical challenges in intelligent PII handling."}, {"title": "Limitations", "content": "Despite PII-Bench's contributions to privacy protection evaluation, several limitations merit acknowledgment. While the current dataset encompasses common privacy scenarios, it requires expansion into specialized domains such as medical records and financial transactions. Our automated synthesis methodology mitigates this limitation by enabling flexible dataset expansion across domains, languages, and cultural contexts, supporting continuous refinement of PII categories to meet evolving application requirements. The evaluation framework primarily assesses the accuracy of PII entity detection and query relevance determination, but lacks systematic evaluation of models' reasoning processes. Specifically, it does not fully capture how models interpret queries, derive information requirements, and make relevance judgments about sensitive information. This gap in assessment methodology limits our understanding of models' reasoning capabilities in real-world privacy protection scenarios."}, {"title": "Ethical Concerns", "content": "Throughout the development and implementation of PII-Bench, ethical considerations have remained our paramount priority. To ensure the evaluation dataset itself does not compromise privacy, we have implemented rigorous data synthesis and review protocols, with all sample data undergoing multiple rounds of scrutiny by professional security teams to guarantee the absence of real personal information. During the data generation process, we have carefully engineered our algorithms to ensure equitable representation across different demographic groups, establishing comprehensive human review mechanisms to verify that generated data remains free from bias and discriminatory content."}, {"title": "A Details about PII", "content": "In this section, we follow previous work by categorizing Personally Identifiable Information (PII) into the following two categories(Elliot et al., 2016,Domingo-Ferrer et al., 2022, Papadopoulou et al., 2022):\n\\textbullet Direct identifiers: Information that can uniquely identify an individual within a dataset(e.g. name, social security number, email address, etc).\n\\textbullet Quasi identifiers: Information that cannot uniquely identify an individual on their own but can do so when combined with other quasi-identifiers(e.g. age, gender, occupation, etc.\nBecause of their high sensitivity or the potential to indirectly identify an individual, both direct and quasi-identifiers are governed by strict legal and privacy standards to ensure personal privacy."}, {"title": "A.1 PII Definition", "content": "Unlike the PII types presented by Papadopoulou et al.'s (2022), our classification does not include the MISC category. This exclusion is due to the ambiguous definition of the MISC category and its unclear boundaries with other categories.\nThe definitions of the seven categories are as follows:\nPER: Refers to individuals' names, including full names, aliases, and social media usernames.\nCODE: Encompasses identifying numbers and codes like social security numbers, phone numbers, passport numbers, email addresses, etc.\nLOC: Covers geographical locations such as home or work addresses, cities, countries, etc.\nORG: Pertains to the names of entities like companies, schools, public institutions, etc.\nDEM: Represents demographic information including age, gender, nationality, occupation, education level, etc.\nDATETIME: Indicates specific dates, times, or durations, such as birthdates, appointment times, etc.\nQUANTITY: Refers to significant numerical data like monthly income, expenditures, loan amount, credit score, etc."}, {"title": "A.3 Statistics of PII Types", "content": "Figure 6 and Table 8 present the distribution of PII types across our datasets: PII-single (1,214 samples), PII-multi (1,228 samples), PII-hard (200 samples), and PII-distract (200 samples).\n\\textbullet Type Frequencies: Organization (ORG) and Code-based identifiers (CODE) constitute significant portions across all datasets, with 17.09% and 15.74% in PII-single, and 13.47% and 15.31% in PII-multi, respectively. This distribution reflects the prevalence of institutional affiliations and digital identifiers in real-world scenarios.\n\\textbullet Dataset Composition: PII-multi contains 16,136 PII entities across all categories, maintaining balanced proportions ranging from 13.47% to 15.77% for most types. PII-single follows a similar pattern with 9,303 entities, demonstrating consistent coverage across different PII categories.\n\\textbullet Specialized Test Sets: PII-distract, despite comprising only 200 samples, contains 10,211 PII entities due to its multi-description design. PII-hard maintains balanced type coverage with 1,834 entities, with proportions varying from 12.10% to 16.58%."}, {"title": "BPII Entity Generation Methods", "content": "The generation of PII entities requires careful consideration of both structural constraints and semantic plausibility. We employ two complementary approaches for entity generation: rule-based generation for structured PII types and language model-based generation for context-dependent information."}, {"title": "B.1 Rule-based Generation", "content": "For PII types with well-defined formats or enumerable value sets, we implement deterministic generation methods. These methods encompass both custom rule-based algorithms and the Faker library's standardized functions. The rule-based approach is particularly effective for:\n1. Identification Numbers: Generating valid formats for social security numbers, passport numbers, and employee IDs while maintaining regional compliance."}, {"title": "3.  Evaluation Metrics", "content": "The evaluation framework employs distinct metrics for PII detection and query-related detection tasks. For PII detection, let \\(P = \\{p_1, ..., p_m \\}\\) denote the predicted subject set and \\(G = \\{g_1, ..., g_n\\}\\) denote the ground truth subject set. Each subject \\(p_i\\) or \\(g_j\\) contains a set of entity-type pairs \\(\\{(e,t)\\} \\), where \\(e\\) represents the entity span and \\(t\\) represents its PII type.\nFor each subject pair \\((p_i, g_j)\\), we compute three types of evaluation metrics:"}, {"title": "D.1", "content": "Strict Matching: Both entity spans and their types must match exactly:\n\\[P_{strict}(p_i, g_j) = \\frac{\\left| E_{p_i} \\cap E_{g_j} \\right|}{\\left| E_{p_i} \\right|} \\]\n\\[R_{strict}(p_i, g_j) = \\frac{\\left| E_{p_i} \\cap E_{g_j} \\right|}{\\left| E_{g_j} \\right|} \\]\n\\[F1_{strict}(p_i, g_j) = \\frac{2 \\cdot P_{strict}(p_i, g_j) \\cdot R_{strict}(p_i, g_j)}{P_{strict}(p_i, g_j) + R_{strict}(p_i, g_j)} \\]\nwhere \\(E_{p_i}\\) and \\(E_{g_j}\\) are the sets of entity-type pairs."}, {"title": "1.  Entity-only Matching:", "content": "Only entity spans need to match:\n\\[P_{ent}(p_i, g_j) = \\frac{\\left| S_{p_i} \\cap S_{g_j} \\right|}{\\left| S_{p_i} \\right|} \\]\n\\[R_{ent}(p_i, g_j) = \\frac{\\left| S_{p_i} \\cap S_{g_j} \\right|}{\\left| S_{g_j} \\right|} \\]\n\\[F1_{ent}(p_i, g_j) = \\frac{2 \\cdot P_{ent}(p_i, g_j) \\cdot R_{ent}(p_i, g_j)}{P_{ent}(p_i, g_j) + R_{ent}(p_i, g_j)} \\]\nwhere \\(S_{p_i}\\) and \\(S_{g_j}\\) are the sets of entity spans.\nThe optimal subject matching \\(M^*\\) is determined by maximizing the strict F1 score:\n\\[M^* = \\underset{M \\in \\mathcal{M}}{\\text{max}} \\sum_{(p_i,g_j) \\in M} F1_{strict}(p_i, g_j) \\]\nwhere \\(\\mathcal{M}\\) denotes all possible one-to-one mappings between predicted and ground truth subjects.\nThe final recognition scores are computed over the optimal matching pairs:\n\\[P_{strict} = \\frac{1}{|P|} \\sum_{(p_i,g_j)\\in M^*} P_{strict}(p_i, g_j) \\]\n\\[R_{strict} = \\frac{1}{|G|} \\sum_{(p_i,g_j)\\in M^*} R_{strict}(p_i, g_j) \\]\n\\[F1_{strict} = \\frac{1}{\\text{max}(|P|,|G|)} \\sum_{(p_i,g_j)\\in M^*} F1_{strict}(p_i, g_j) \\]\n\\(P_{span}\\), \\(R_{span}\\), and \\(F1_{span}\\) are computed analogously.\nFor query-related detection, given a predicted entity set \\(E_p\\) and ground truth set \\(E_g\\), we compute:\n\\[P_{query} = \\frac{|E_p \\cap E_g|}{|E_p|} \\]\n\\[R_{query} = \\frac{|E_p \\cap E_g|}{|E_g|} \\]\n\\[F1_{query} = \\frac{2 \\cdot P_{query} \\cdot R_{query}}{P_{query} + R_{query}} \\]\nFor both PII detection and query-related detection tasks, we additionally employ Rouge-L based fuzzy matching to handle partial matches between entity spans. Instead of using exact set intersection, the Rouge-L score is used to measure textual similarity between entities:\n\\[P_{fuzzy} = \\frac{1}{|E_p|} \\sum_{e_p \\in E_p} \\underset{e_g \\in E_g}{\\text{max}} Rouge-L(e_p, e_g) \\]\n\\[R_{fuzzy} = \\frac{1}{|E_g|} \\sum_{e_g \\in E_g} \\underset{e_p \\in E_p}{\\text{max}} Rouge-L(e_p, e_g) \\]\n\\[F1_{fuzzy} = \\frac{2 \\cdot P_{fuzzy} \\cdot R_{fuzzy}}{P_{fuzzy} + R_{fuzzy}} \\]\nwhere Rouge-L\\((e_p, e_g)\\) computes the longest common subsequence-based F-score between predicted entity \\(e_p\\) and ground truth entity \\(e_g\\)."}, {"title": "D.2 Additional Results", "content": "Table 9 compares different prompting strategies on PII-multi dataset."}, {"title": "E PII Annotation System", "content": "We developed a specialized web-based annotation platform to facilitate the systematic evaluation of PII detection and query-related detection capabilities. The platform implements a two-stage annotation process, ensuring comprehensive coverage of both fundamental PII entity identification and contextual relevance assessment."}, {"title": "E.1 PII Detection Interface", "content": "As shown in Figure 7, the PII detection interface enables annotators to identify and categorize PII entities within user descriptions. The interface provides the following key functionalities:\n\\textbullet Entity Detection: Annotators can highlight text spans containing PII entities directly in the user description.\n\\textbullet Type Classification: Each identified entity is assigned a specific PII type (e.g., PER for person names, ORG for organizations, LOC for locations).\n\\textbullet Subject Association: Entities are linked to their corresponding subjects using alphabetical identifiers (e.g., A, B) to maintain relationship clarity in multi-subject scenarios.\n\\textbullet Span Verification: The interface displays start and end positions for each entity span, ensuring precise boundary detection."}, {"title": "E.2 Query-Related Detection Interface", "content": "Figure 8 illustrates the interface for query-related PII detection", "relevance": "n\\textbullet Query Context: The interface presents both the user description and the associated query", "Selection": "Annotators identify PII entities crucial for addressing the query", "Verification": "For selected query-related entities, annotators must verify the subject associations to ensure consistency across tasks.\n\\"}]}