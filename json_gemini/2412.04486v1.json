{"title": "THE GLOBAL AI VIBRANCY TOOL", "authors": ["Loredana Fattorini", "Vanessa Parli", "Nestor Maslej", "John Etchemendy", "Katrina Ligett", "Raymond Perrault", "Yoav Shoham"], "abstract": "This paper presents the latest version of the Global AI Vibrancy Tool (GVT),\nan interactive suite of visualizations designed to facilitate the comparison of AI\nvibrancy across 36 countries, using 42 indicators organized into 8 pillars. The tool\noffers customizable features that allow users to conduct in-depth country-level\ncomparisons and longitudinal analyses of AI-related metrics, all based on publicly\navailable data. By providing a transparent assessment of national progress in AI,\nit serves the diverse needs of policymakers, industry leaders, researchers, and the\ngeneral public. Using weights for indicators and pillars developed by AI Index's\npanel of experts and combined into an index, the Global AI Vibrancy Ranking\nfor 2023 places the United States first by a significant margin, followed by China\nand the United Kingdom. The ranking also highlights the rise of smaller nations\nsuch as Singapore when evaluated on both absolute and per capita bases. The\ntool offers three sub-indices for evaluating Global AI Vibrancy along different\ndimensions: the Innovation Index, the Economic Competitiveness Index, and the\nPolicy, Governance, and Public Engagement Index.", "sections": [{"title": "INTRODUCTION", "content": "This paper introduces the latest version of the Global AI Vibrancy Tool (GVT), a comprehensive\ncollection of publicly available time series data and a suite of interactive visualizations that allow\ncomparisons for up to 36 countries across 42 indicators related to Artificial Intelligence (AI). This\nupdate expands on previous versions, covering more countries and metrics. It now features one of\nthe most extensive collections of AI-specific indicators\u00b9 available, collectively assessing country-\nspecific AI activity from 2017 to 2023. The revamped tool enhances the user experience with\nintuitive navigation, customizable visualizations, and download options. Additionally, the tool is\nstructured to provide detailed and nuanced comparisons of countries through a user-customizable\nindex of indicators in the Global and National AI Vibrancy Rankings section. The new GVT also\noffers an in-depth look at the evolution of specific indicators over time for selected countries in\n\u00b9In this framework, the terms \u201cindicator\u201d and \u201cmetric\u201d are used interchangeably."}, {"title": "RELATED WORK", "content": "The development and refinement of composite indicators involve aggregating multiple individual\nmetrics into a single comprehensive measure. This process draws on a diverse set of methodologies\nfrom statistics, economics, and technology assessment. Notable examples include the Human\nDevelopment Index (HDI), introduced by the United Nations in 1990 [2], which integrates health,\neducation, and income levels, and the Gender Inequality Index (GII), which measures gender\ndisparities in health, empowerment, and labor market participation [36]. As the AI landscape"}, {"title": "CONCEPTUAL FRAMEWORK", "content": "The primary objective of the Global AI Vibrancy Tool (GVT) is to facilitate cross-country com-\nparisons of AI vibrancy in the field of AI. AI vibrancy can be defined as the level of activity,\ndevelopment, and impact of AI technologies within a country. This assessment provides a compre-\nhensive understanding of the progress different countries are making in AI thereby highlighting\nstrengths and areas for potential improvement.\nThe GVT captures country-level AI vibrancy through several key dimensions, each representing\na critical aspect of AI development. The dimensions, henceforth referred to as pillars, include:\nResearch and Development (R&D), Responsible AI, Economy, Education, Diversity, Policy and"}, {"title": "Research and Development (R&D)", "content": "R&D is the foundation of AI advancement, driving the creation of new algorithms, models,\nand technologies that in turn foster AI innovation. According to Furman et al. [17], national\ninnovative capacity, defined as the long-term ability to produce and commercialize innova-\ntive technology, is significantly influenced by R&D efforts. Measures of innovative output,\nsuch as patenting activities and journal publications, serve as key indicators of this capacity."}, {"title": "Responsible AI", "content": "Building AI systems that adhere to ethical standards is important for gaining public trust\nand preventing harm. Responsible AI covers several dimensions including data governance,\nexplainability, fairness, privacy, security and safety, and transparency among others [25].\nThe volume of conference submissions related to these aspects affiliated with a country\ncan serve as a quantitative measure of ongoing research and discussion on responsible AI\npractices.\u00b2"}, {"title": "Economy", "content": "The economic landscape surrounding AI is a key factor influencing how AI is developed\nand deployed. In their work on the economic implications of AI, Agrawal et al. [6] highlight\nfactors such as research investment, infrastructure, applications, and labor market condi-\ntions, all of which play an important role in guiding AI innovation. Trends in investment\nvolumes and job markets can capture some of these aspects."}, {"title": "Education", "content": "Education is essential for preparing a skilled AI workforce. As Pedro et al. [28] state, prepar-\ning the future workforce for AI involves more than just adopting advanced technologies. It\nnecessitates a shift in curricula to emphasize \u201cAI competencies.\u201d Tracking the growth of\nAI-related degree programs can provide insights into the effectiveness of these efforts."}, {"title": "Diversity", "content": "Diversity in AI development means accommodating and working with a wide range of\nperspectives which can potentially reduce biases in AI systems. It includes gender, ethnicity,\nand socioeconomic diversity within the AI community. Integrating diversity and inclusion\nprinciples throughout the AI lifecycle is important for creating fair and transparent AI\ntechnologies [37]. Diverse teams bring varied experiences and viewpoints, which can be\nimportant in identifying and mitigating biases. One way to capture diversity is by measuring\nAI skills across genders.\u00b3"}, {"title": "Policy and Governance", "content": "Policy and governance frameworks set the base for AI ecosystems, influencing everything\nfrom innovation and ethical standards to investments and education. National AI strategies,\nwhich are policy plans created by governments to guide the development and deployment"}, {"title": "Public Opinion", "content": "Public perception of AI influences its adoption and development. Understanding public\nopinion helps address concerns and improve AI literacy. The framing of AI in media affects\npublic sentiment and, consequently, regulatory decisions and technology acceptance. Com-\nprehending public opinion, including analyzing media conversations in terms of volume and\nsentiment, can reveal important insights on the level of public support for AI development\nwithin a nation. [33]."}, {"title": "Infrastructure", "content": "Robust infrastructure is a critical prerequisite for advancing AI research and deployment,\nwith significant variations observed across countries. Infrastructure includes computa-\ntional resources, data availability, and network connectivity. Amodei and Hernandez [9]\ndemonstrate that the computational power used in the largest AI training runs has been\nincreasing exponentially. Countries with superior data centers and cloud infrastructure gain\na significant advantage in conducting large-scale AI experiments. Moreover, the quality and\nquantity of available data sets vary widely between nations, directly impacting their ability\nto develop accurate and generalizable AI models. Network connectivity further amplifies\nthese disparities. Nations that possess faster and more reliable internet connections can\nmore quickly process real-time data [22]. The number of supercomputers, compute capacity,\nand high-speed internet can capture some infrastructure-related concepts essential for AI\nadvancements."}, {"title": "Sub-Indices for Granular Comparison", "content": "To facilitate the comparative analysis of countries at a granular level, we introduce sub-indices\nwithin the GVT. These sub-indices provide a more nuanced perspective on particular aspects of AI"}, {"title": "Innovation Index", "content": "This index measures a country's innovation potential by assessing its research and develop-\nment (R&D) activities, academic output, technological advancements, intellectual property\ngeneration, and supporting technological infrastructure. It highlights a country's capacity\nto produce new knowledge, innovate, and contribute to global AI advancements. The index\noffers insights into which countries are leading in AI development and have the necessary\ninfrastructure to support future progress."}, {"title": "Economic Competitiveness Index", "content": "This index measures the economic strength and market dynamism of a country in the AI\nsector by analyzing investment flows, talent concentration, and job creation. It captures how\ncountries are leading in integrating AI into their economies, enhancing their competitive\nedge, and creating robust ecosystems for AI-driven growth."}, {"title": "Policy, Governance, and Public Engagement Index", "content": "This index evaluates the level of activity related to AI-related policies, legislative actions,\nand the broader public discourse surrounding AI. It identifies which countries are leaders\nin creating an enabling policy environment for AI and how public opinion is shaping the\nadoption and acceptance of AI technologies. Countries with a national strategy on AI and\npositive public sentiment are better positioned to leverage AI for national development,\nwhile those lagging may face challenges in governance, public trust, and AI deployment."}, {"title": "METHODOLOGY", "content": "Our data collection strategy works to achieve comprehensive and reliable data. We gather informa-\ntion from sources like CSET, QUID, GitHub, and LinkedIn, as well as our prepared datasets.\nMaintaining data integrity is a top priority. Our approach includes implementing rigorous\nvalidation processes to cross-check data from multiple sources, in order to maintain consistency and\naccuracy. We periodically update our database to incorporate the most recent and comprehensive\ndata, in order to guarantee that our tool reflects current trends and developments.\nThe selection of data to be included in our tool is based on the following criteria:\n\u2022 Relevance: The data must be directly relevant to the dimensions of AI vibrancy we aim to\nmeasure, such as R&D, Economy, Education, etc.\n\u2022 Significance: Indicators should have a significant impact on AI vibrancy, providing mean-\ningful insights into a country's AI capabilities and development.\n\u2022 Accuracy: Data must be accurate and reliable, sourced from reputable providers or validated\nthrough rigorous self-collection methods.\n\u2022 Coverage: Indicators should have good geographical and temporal coverage, allowing for\ncomprehensive comparisons across different countries and over time.\n\u2022 Traceability: Data should be easy to track and updated annually, ensuring that our tool\ncan provide up-to-date and consistent evaluations.\nDespite our attentive data collection strategy, several challenges arise. Some indicators have\nlimited coverage across countries or over time. For example, we considered including the percentage\nof businesses using AI technology as an indicator. However, available surveys containing this data"}, {"title": "Al Vibrancy Index Construction", "content": "The index construction process involves several key steps:\u2077 (1) normalizing the data, (2) calculating\nthe pillar scores, and (3) aggregating these scores to form the overall AI vibrancy index. Below is a\ndetailed explanation of each step.\nNormalization. To ensure comparability across different scales and units of measurement, we use\nmin-max normalization for all indicators. This method scales the values within the [0, 100] range.\nThe normalized value for the $i$\u1d57\u02b0 indicator is calculated using the formula:\n$x_{ijk} = \\frac{x^{\\text{raw}}_{ijk} - x_{ij,\\text{min}}}{x_{ij,\\text{max}} - x_{ij,\\text{min}}} \\cdot 100$                                                        (1)\nwhere:\n\u2022 $x^{\\text{raw}}_{ijk}$ is the original value of the $i$\u1d57\u02b0 indicator for pillar $j$ and country $k$.\n\u2022 $X_{ij,\\text{min}}$ and $X_{ij,\\text{max}}$ are the minimum and maximum values of indicator $i$ in pillar $j$ across all\ncountries.\nPillar Score Calculation. Let $p_{jk}$ denote the score of pillar $j$ for country $k$. This score is computed as\nthe weighted average of various indicators associated with the pillar and the country. Specifically,\nthe score is given by the formula:\n$p_{jk} = \\frac{\\sum_{i=1}^{N_j}(w_{ij} \\cdot x_{ijk})}{\\sum_{i=1}^{N_j} w_{ij}}$                              (2)\nwhere:\n\u2022 $N_j$ is the number of indicators for pillar $j$.\n\u2022 $w_{ij}$ is the weight assigned to the $i$\u1d57\u02b0 indicator for pillar $j$, ranging from 0 to 10, with higher\nvalues indicating greater importance of the indicator. We assume that these weights are\nnon-negative and their sum is non-zero.\n\u2022 $X_{ijk}$ is the normalized score of the $i$\u1d57\u02b0 indicator for pillar $j$ and country $k$.\nAl Vibrancy Index Calculation. The AI vibrancy index for a country $k$, denoted as $V_k$, is calculated\nas the weighted average of the scores of all the pillars as follows:\n$V_k = \\frac{\\sum_{j=1}^{M}(W_j \\cdot p_{jk})}{\\sum_{j=1}^{M} W_j}$                                                                                                                                                                                   (3)\nwhere:\n\u2022 $M$ is the total number of pillars.\n\u2022 $W_j$ is the weight assigned to pillar $j$, ranging from 0 to 10, with higher values indicating\ngreater importance of the pillar. We assume that these weights are non-negative and their\nsum is non-zero.\n\u2022 $P_{jk}$ is the score of pillar $j$ for country $k$, as calculated above.\nThis formulation allows for a comprehensive assessment of a country's vibrancy, taking into\naccount a range of factors across different dimensions."}, {"title": "Implementation", "content": "Handling Missing Values. Missing values have been imputed with the median of each indicator\nacross all countries for each year. If an indicator is missing for all countries in a specific year, it\nis excluded from the calculation and its weight is proportionally redistributed among the other\navailable indicators. As a result, the total weight assigned to the remaining indicators sums to the\noriginal total, thus maintaining the overall balance of importance among indicators.\nThis approach ensures that the data remains as complete as possible, minimizing the loss of\ninformation due to missing values. By imputing with the median, we preserve the integrity of\nthe data while reducing potential biases that might arise from more complex imputation methods.\nExcluding indicators entirely when data is unavailable for all countries in a year prevents the\nintroduction of inaccuracies and ensures that the analysis reflects the best available data.\nHowever, this methodology has its trade-offs, including the potential exclusion of key indicators\nthat could impact the overall assessment. Additionally, variability in data availability across years\nmay complicate temporal comparisons. Future enhancements could include a feature for users to\nrun sensitivity analyses, allowing them to assess the impact of different imputation strategies on\nthe ranking. Promoting comprehensive and consistent data reporting across more countries will\nfurther enhance the tool's accuracy and reliability over time.\nWeights Selection. The inclusion of all indicators in the GVT is based on the criteria defined\nin Section 4.1. However, in assessing a country's level of AI vibrancy, some pillars and indicators are\nadmittedly more relevant than others. We set the default weights of the GVT using an expert budget\nallocation approach, where four senior AI Index team members individually allocated weights\naccording to their relative perceived relevance, while also considering specific features of some\nindicators, such as coverage. For instance certain pillars such as Education and Responsible AI were\ndeemed to be relatively important by the \u201cexpert group\u201d as components of a nation's AI vibrancy.\nHowever, because the data for these pillars was limited in its international coverage (certain nations"}, {"title": "TOOL INTERFACE OVERVIEW", "content": "In this section we present an overview of the tool interface, highlighting its components and\nfunctionalities. The interface is designed to be user-friendly and interactive. Users can explore and\ncustomize views according to their preferences."}, {"title": "Main Components", "content": "This section allows users to toggle between global\nand national rankings, providing a comparative view of AI vibrancy across different countries. The\n\u201cView Type\u201d component of the tool interface allows users to choose how to visualize the data that\nbest suits their needs. The available view types are:\n\u2022 Bar: The bar chart (Figure 1) view presents the AI vibrancy ranking of different countries\nfor a selected year. This view is particularly useful in comparing where each country stands\nin the ranking and which countries are leading or lagging in specific pillars.\n\u2022 Table: The table view (Figure 2) allows for comparisons of AI vibrancy across up to four\nselected countries simultaneously for a selected year. It includes information on each\nindicator within corresponding pillars, such as raw data values, normalized indicator scores,\neach country's overall rank, and the contribution of each indicator relative to other countries.\n\u2022 Slope: The slope view (Figure 3) displays changes in the global AI vibrancy ranking over\ntime, showing the trajectory of each country."}, {"title": "Al Metrics Over Time", "content": "This section provides users with a dynamic way to analyze changes in\nmetrics included in the AI vibrancy index over time. Users can choose a country from a drop-down\nmenu and select a metric from a specific pillar, allowing for a more focused analysis of a particular\narea of interest.\nThe tool offers two chart types for visualization:\n\u2022 Bar: This option shows AI metrics in a bar chart format (Figure 5), making it easy to compare\nvalues over different years.\n\u2022 World Map: This option provides a geographical visualization of AI Metrics, showing the\ndistribution and intensity of AI-related activities across countries (fig. 6)."}, {"title": "RESULTS OF COUNTRY RANKINGS", "content": "In this section, we present the results of the 2023 Global AI Vibrancy Ranking. Figure 8 provides a\nsnapshot of the current state of AI vibrancy in the top ten countries, evaluated across the eight\nkey dimensions introduced in section 3.1. Each country's overall score is a weighted sum of these\ndimensions, computed using the absolute values of the metrics, reflecting their performance in\nAI-related activities and infrastructure."}, {"title": "Insights from the Sub-Indices", "content": "A closer examination of the AI Vibrancy Index's sub-indices introduced in Section 3.1, reveals a\nnuanced landscape where national strengths vary across dimensions. In the Innovation domain\nfor 2023 (Figure 11), the United States leads with a score of 79.20, substantially outperforming its\nnearest competitor, China (53.08). The U.S. especially excels in both R&D and infrastructure. India\ncomes in third place. The gap between Japan (16.96) the fourth place country and Spain, which\ncomes in tenth (11.18) is fairly small in comparison to the gap that exists between the U.S. and\nChina or U.S. and India. This contrast highlights a closer grouping among countries outside the\ntop three, suggesting that modest investments in AI capacity could lead to substantial shifts in\nrankings."}, {"title": "United States and China", "content": "As AI has gained geopolitical importance, commentators and policymakers have increasingly\nfocused on the comparative strengths of the two leading AI nations: the United States and China.\nThis focus is evident in popular discussions about the geopolitical race between these countries and\nits implications, as well as in policy actions like the CHIPS and Science Act which were designed\nto bolster the U.S.-made semiconductor ecosystem [8, 16, 35]. Given this context, it is natural to\nclosely compare the AI positioning of these two nations and examine how it has evolved over time.\nIn 2018, the United States overtook China as the nation with the greatest global AI vibrancy.\nSince then, it has further reinforced its lead position. In 2017, the two countries were relatively\nclose in several key areas, including research and development and investment. However, by 2023,\nthe United States had pulled ahead, achieving a vibrancy index score of 70.06, nearly double China's\nscore of 40.17 (Figure 14).\nThe relative strength of the United States in comparison to China is evident when you look at\na selection of significant AI indicators. The United States outpaced China in private investment,\nreaching $67.22$ billion in 2023 compared to China's $7.76$ billion (Figure 16). It also led in developing\nnotable machine learning models, producing 61 models in 2023 compared to China's 15 (Figure\n18). However, China showed strong growth in AI innovation, particularly in patent generation,\ngranting nearly three times as many AI patents as the United States (Figure 17). Additionally, the\nUnited States took a proactive stance in AI regulation, passing a total of 23 AI-related laws since\n2017 (Figure 19)."}, {"title": "Additional Notes and Limitations", "content": "When interpreting the AI vibrancy rankings, it is essential to consider a few nuances. As outlined\nin the Methodology section, the rankings heavily rely on the weighting schema applied to each\npillar and indicator. The AI Index has selected a weighting approach that it believes best represents\nthe significance and coverage of the various components. However, users of the vibrancy tool\nmay have different views on the relative importance of specific pillars or indicators. The AI Index\nencourages users to explore the weight adjuster feature in the live tool to tailor the rankings to\ntheir own perspectives.\nFor many countries outside the top two or three in any given index in this paper, the score gaps\nbetween neighboring countries are relatively small. For instance, while the gap between the United\nStates and China (the top two countries) was roughly 30 points on the weighted index score, the\ndifference between the United Kingdom and Singapore (ranked third and tenth) was only about 9\npoints. As such, the rankings for countries outside the top positions (e.g., top three or ten) should\nbe interpreted with more flexibility than those in the top few spots. Countries in the middle or\nlower tiers of the Index are often closely grouped, meaning that slight adjustments in weighting\ncan significantly affect their ranks. This close clustering also indicates that countries can improve\ntheir standings through active policies and strategic planning that directly improve the strength of\ntheir Al ecosystem.\nSince the AI Index provides annual rankings, it is also important to recognize that a country's\nyearly position can be sensitive to outlier values. A high or low score in certain indicators one\nyear might place a country out of alignment with its historical rankings. Future versions of the AI\nVibrancy tool will include three- or five-year weighted averages to offer a more stable view of each\ncountry's average position over time.\nFinally, the AI Index recognizes that some data sources contributing to the rankings provide\nmore comprehensive coverage for certain types of nations than others. To address this potential\nimbalance, the AI Index has down-weighted indicators or pillars with limited coverage. Efforts are\nunderway to expand data coverage, and the AI Index encourages collaboration from governments\nand representatives worldwide to improve the representativeness of these rankings."}, {"title": "CONCLUSION", "content": "The Global AI Vibrancy Tool (GVT) is a robust and versatile platform for assessing and comparing\nAl vibrancy across countries. By incorporating a comprehensive set of indicators across various\ndimensions, it provides a nuanced and dynamic understanding of over time trends in AI development\nat the national level. This tool is intended to serve as a valuable resource for policymakers, industry\nleaders, researchers, and the general public in guiding their understanding of the geopolitical\ndynamics that surround the AI ecosystem. The interactivity and customizability of the Global\nVibrancy Tool allows users to explore and interpret AI data in meaningful ways, which can facilitate\ninformed, flexible and strategic decision-making. As AI continues to evolve rapidly, the GVT will\ngrow and expand in scope, with the intention of remaining an essential resource for tracking\nprogress and identifying areas for improvement.\nFuture work will focus on expanding the range of indicators and countries, and improving\ndata collection methods to ensure greater accuracy and coverage. Additionally, incorporating user\nfeedback and enabling more sophisticated analytics capabilities will be important in maintaining"}, {"title": "LIST OF COUNTRIES", "content": "To ensure the quality and representativeness of the analysis, a data coverage threshold of 70%,\naveraged over the last three years, was applied. This threshold was chosen to balance the need\nfor comprehensive data with the goal of including a diverse set of countries. However, Estonia,\nMalaysia, Mexico, Russia, Saudi Arabia, and Turkey did not meet this threshold but have been\nincluded due to their strategic importance such as geopolitical influence, economic impact, or\ncontributions to global trends. Therefore, these countries are included, but users should interpret\ntheir results with caution. For more details, see tables 11 and 12."}, {"title": "LIST OF INDICATORS AND DESCRIPTIONS", "content": null}, {"title": "INDICATORS INCLUDED IN SUB-INDICES", "content": null}, {"title": "WEIGHTING: BUDGET ALLOCATION METHOD", "content": "In assigning weights to pillars and indicators, careful consideration was given to data availability,\nquality, and the scope of coverage across countries to ensure a reliable representation of AI vibrancy.\nIndicators with limited coverage\u2014such as Academia-Industry Model Production Concentration, Open\nAccess Foundation Models, and AI Job Postings (% of Total)\u2014were assigned a weight of zero, as their\navailability (only covering 33%, 36%, and 39% of countries respectively in 2023) undermines their\nutility in cross-country comparisons. Data enhancement efforts are underway for these indicators\nto improve future analyses. Similarly, weights for indicators like AI Hiring Rate YoY Ratio, Relative\nAI Skill Penetration, AI Talent Concentration, and Net Migration Flow of AI Skills were reduced due to\npartial data coverage (69% in 2023). Further, foundational AI indicators, including Foundation Models\n(count), Foundation Model Applications, and Foundation Model Datasets, were assigned a moderate\nweight of 3 to balance their importance with the underrepresentation of some countries due to the\npredominance of English-language data sources, with ongoing efforts to enhance data accuracy\nacross more countries. Pillar weights were also adjusted to reflect data quality and relevance. For\nexample, the Responsible Al pillar was assigned a low weight of 2 due to potential overlap with\nthe R&D pillar, though the search for additional country-specific metrics continues. The Economy\npillar's weight was adjusted to 8 to indicate a need for more indicators on AI technology adoption,\nwhile the Education pillar, weighted at 2, requires further development to mitigate English-language\nbiases. Other adjustments include reducing the weight of the Diversity pillar to 1, due to its limited\nindicators and low data coverage, and the Policy and Governance pillar to 4, addressing the gap in\nboth qualitative and quantitative metrics, such as AI-dedicated government budgets. The Public\nOpinion pillar received a weight of 2, acknowledging its lesser relevance compared to pillars like\nPolicy and Governance, while the Infrastructure pillar was weighted at 6. Although critical, this\nadjustment reflects missing metrics on infrastructure specifics, like data center availability, with\nplans to expand data collection underway. This calibration provides a comprehensive view of global\nAl vibrancy, accounting for some data limitations. The approach prevents skewed assessments\nfrom data gaps or overemphasis, resulting in a more balanced analysis."}, {"title": "METRICS CALCULATION", "content": "The Academia-Industry Model Production Concentration indicator quantifies the balance between\nthe number of notable machine learning models produced by academia and industry within each\ncountry and year. The indicator is calculated using the inverted Herfindahl-Hirschman Index (HHI),\na measure commonly used to assess market concentration.\nInverted HHI = 1 \u2212 (\u03b1\u00b2 + \u03b9\u00b2)                            (4)\nwhere:\n\u2022 a is the proportion of models produced only by academia.\n\u2022 1 is the proportion of models produced only by industry.\nA higher normalized value indicates a more balanced model production environment, suggesting\na favorable condition for AI development due to collaboration and diversity between academia and\nindustry. Conversely, a lower normalized value indicates a concentration in model production by\neither academia or industry, suggesting less diversity.\nThe Al Talent Concentration Gender Equality Index measures how evenly the proportion of LinkedIn\nmembers who are AI talent are distributed between female and males in a country k. The index\nis calculated using the following formula:\n$\\frac{\\min (Femalek, Malek)}{\\max (Femalek, Malek)}$                                                             (5)\nwhere:\n\u2022 Femalek is the AI talent concentration of females.\n\u2022 Malek is the AI talent concentration of males.\nThe index ranges from 0 to 1, where 1 means perfect equality and 0 means complete inequality.\nA higher value of the index means a more balanced distribution of AI talent between females and\nmales, reflecting greater gender equality in AI talent concentration within that country."}, {"title": "DATA COVERAGE", "content": null}]}