{"title": "DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization", "authors": ["Zhuoyue Wan", "Yuanfeng Song", "Shuaimin Li", "Chen Jason Zhang", "Raymond Chi-Wing Wong"], "abstract": "Data visualization (DV) is the fundamental and premise tool to improve the efficiency in conveying the insights behind the big data, which has been widely accepted in existing data-driven world. Task automation in DV, such as converting natural language queries to visualizations (i.e., text-to-vis), generating explanations from visualizations (i.e., vis-to-text), answering DV-related questions in free form (i.e. FeVisQA), and explicating tabular data (i.e., table-to-text), is vital for advancing the field. Despite their potential, the application of pre-trained language models (PLMs) like T5 and BERT in DV has been limited by high costs and challenges in handling cross-modal information, leading to few studies on PLMs for DV. We introduce DataVisT5, a novel PLM tailored for DV that enhances the T5 architecture through a hybrid objective pre-training and multi-task fine-tuning strategy, integrating text and DV datasets to effectively interpret cross-modal semantics. Extensive evaluations on public datasets show that DataVisT5 consistently outperforms current state-of-the-art models on various DV-related tasks. We anticipate that DataVisT5 will not only inspire further research on vertical PLMs but also expand the range of applications for PLMs.", "sections": [{"title": "I. INTRODUCTION", "content": "Data visualizations (DVs) utilize graphical representation to convey insights to summarize the massive raw data, which is a common practice in existing big data era [1], [2]. Popular data analysis and database applications, such as Google Sheets\u00b9 and Microsoft Power BI\u00b2, all support DV features. Many institutions realize the value of DV and have applied it as their daily fundamental tools. Thus the ability of creating suitable DVs has become a necessary skill for data analysts, engineers, and data scientists [3]-[5]. However, creating appropriate DVs remains challenging, even for experts, since it requires visual analysis expertise and familiarity with the domain data. Furthermore, users must master the complex grammar of Declarative Visualization Languages (DVLs), such as Vega-Lite [6], ggplot2 [7], and Vega-Zero [8], to accurately define DV specification in the visualization engine.\nTo lower the barriers to creating DVs and further unlock the power of DV for the general public, researchers have proposed a variety of DV-related tasks that have attracted significant attention from both industrial and academic researchers. Numerous studies on these topics have been presented in leading conferences and journals such as VLDB [2], [9], [10], ICDE [11], [12], SIGMOD [13]\u2013[15], and TKDE [16], [17]. These tasks include text-to-vis (i.e., automatically generating DVs from natural language questions) [8], [15], vis-to-text [18] (i.e., automatically generating interpretations of complex DVs for educational purposes), FeVisQA [12] (i.e., free-form question answering over data visualization), and table-to-text (i.e., describing a given table) [19].\nA vivid example is given in Figure 1, which shows four important tasks central to the domain knowledge of DV: text-to-vis, vis-to-text, FeVisQA and table-to-text. The figure presents a natural language (NL) question, \u201cGive me a pie chart about the proportion of the number of countries in the artist table.\u201d This example demonstrates the text-to-vis task\u2019s capability to interpret the NL question and transform it into a Vega-Lite specification, resulting in a pie chart. The DV query, introduced by [15], serves as a bridge in the text-to-vis process, encapsulating visualization details and data operations with a grammar akin to SQL. Translations between DV queries and DVLs are seamless, with text-to-vis tasks primarily focusing on converting NL questions into DV queries. Conversely, the vis-to-text task aims to generate accessible and user-friendly explanations of complex visualizations for individuals without expertise in the field. The FeVisQA task addresses user inquiries regarding DV by providing detailed answers to common questions. We present four typical DV-related questions, including understanding the semantics of a DV query, resolving numerical issues within a chart, and evaluating the compatibility of a DV query with a given database. Lastly, the table-to-text task generates informative NL description of tabular data, which are essential for visual analytics, thereby reducing the perceptual effort needed for data interpretation.\nMeanwhile, PLMs such as BERT [20] and T5 [21] have received considerable attention in the realms of natural language processing (NLP) and data mining, becoming widely recognized for their efficacy. These PLMs greatly promote the development of effective text-driven applications, since they show dominating performance in understanding the semantics in natural language. The operational paradigm for these PLMs typically unfolds in two stages: initially, they undergo unsupervised pre-training on expansive, open-domain datasets (such as Wikipedia) to acquire foundational capabilities in language representation and comprehension; subsequently, they are fine-tuned on specialized corpora pertinent to targeted downstream tasks, thereby enhancing task-specific performance. Despite their success [22]-[24], there are still significant challenges when it comes to the DV field : (i) Limited studies have been conducted to explore the effectiveness of PLMs in capturing the DV semantics. (ii) Since there is a substantial modal gap between the DV modality and the text modality, satisfied performances cannot be achieved by directly applying existing PLMs (e.g., T5) to DV-related tasks mentioned above. (iii) In the DV area, a possible PLM needs the ability of handling cross-modal information (i.e., text and DV), while also being capable of managing multiple distinct tasks.\nTo alleviate above-mentioned problems, we propose a novel PLM for jointly understanding text and DV, refereed as DataVisT5 in this paper. Based on text-centric T5 architecture, we enhance the pre-training process by incorporating a comprehensive array of cross-modal datasets that integrate natural language with DV knowledge, encompassing DV queries, database schemas, and tables. Inspired by large language models that incorporate programming code into their pre-training data [25], [26], which demonstrate formidable generalization capabilities, we employ CodeT5+ [27] as the starting checkpoint in our work, as it has been trained on code data. Building on this foundation, we apply table-level database schema filtration to reduce training complexity. Addressing the challenges of format consistency between DV and textual modalities, we introduce a unified encoding format for DV knowledge that facilitates the convergence of text and DV modalities. To eliminate stylistic discrepancies in manually curated datasets, we adopt standardized encoding.\nAdditionally, the pre-training objectives for DataVisT5 are twofold: (i) the span corruption approach of Masked Language Modeling (MLM) as utilized by the original T5 model, and (ii) a Bidirectional Dual-Corpus objective that operates on source-target pairings. After the mixed-objective pre-training, we conduct multi-task fine-tuning of our DataVisT5 on DV-related tasks including text-to-vis, vis-to-text, FeVisQA, and table-to-text. To substantiate the rationale behind our proposed model, we performed comprehensive experimental evaluations on various public datasets. The results consistently demonstrate that DataVisT5 surpasses the state-of-the-art (SOTA) models. In summary, our main contributions are as follows:\n\u2022 We introduce and release DataVisT5: the first Pre-trained Language Model (PLM) tailored for the joint understanding of text and DV. This innovation opens avenues for future research on task-specific PLMs and enriches the landscape of PLM designs.\n\u2022 We enhance the text-centric T5 architecture to handle cross-modal information. Our novel hybrid pre-training objectives are conceived to unravel the complex interplay between DV and textual data, fostering a deeper integration of cross-modal insights.\n\u2022 Extensive experiments on public datasets for diverse DV tasks including text-to-vis, vis-to-text, FeVisQA, and table-to-text demonstrate that DataVisT5 excels in multi-task settings, consistently outperforming strong baselines and establishing new SOTA performances."}, {"title": "II. PRELIMINARY", "content": "This section provides the foundational concepts and definitions pivotal to DV-related tasks, with the objective of cultivating a more profound understanding.\nNatural Language Question. An NL question enables users, even those with a minimal background in DV and programming skills, to formulate queries intuitively. Figure 1 demonstrates such an instance, with the user\u2019s request articulated as, \u201cGive me a pie chart about the proportion of the number of countries in the artist table\u201d."}, {"title": "Declarative Visualization Language.", "content": "Transforming data into a graphical representation typically involves the use of a declarative visualization language (DVL). This kind of language provides a set of specifications that determine the construction of visualizations. These specifications include various elements such as chart type, colors, sizes, and mapping functions, as well as properties for visual marks like canvas dimensions and legends. Several DVLs are prevalent in the field, such as Vega-Lite [6], ggplot2 [7], ZQL [10], ECharts [28], Vega-Zero [8], and VizQL [13], each offering unique features to facilitate the visualization process."}, {"title": "Visualization Specification.", "content": "A visualization specification comprises a JSON format object that delineates the dataset and its visual attributes (such as chart types and data transformation functions) in accordance with the syntax of a specific DVL. It is noteworthy that each DVL possesses a unique grammar, necessitating distinct visualization specifications for rendering the same DV chart."}, {"title": "Data Visualization Query.", "content": "Introduced by [11], [14], a framework for querying a database for visual data representations seeks to encapsulate the full spectrum of potential DVLs. As depicted in Figure 1, a DV query specifies a \"pie\" chart and integrates SQL-like operations (e.g. Count and Order By). This versatile DV query format can be converted into visualization specifications for different DVLs, enabling visualization engines to render the specified chart."}, {"title": "Data Visualization Chart.", "content": "The DV charts are the visual representations such as scatters, bars, or maps used to convey the data summary and insights defined by the visualization specification. In Figure 1, the final visualization result is the bar chart that corresponds to the NL question."}, {"title": "III. OUR PROPOSED MODEL: DATAVIST5", "content": "We present our proposed DataVisT5 model, with the pipeline overview in Section III-A. This is followed by details on database schema filtration in Section III-B, DV knowledge encoding in Section III-C, and standardized encoding in Section III-D. We discuss our hybrid pre-training objectives in Section III-E and conclude with our multi-task fine-tuning strategy in Section III-F."}, {"title": "A. Pipeline Overview", "content": "Figure 2 provides an overview of the complete pipeline, comprising five main stages: (1) Database schema filtration, (2) DV knowledge Encoding, (3) Standardized Encoding, (4)Model Pre-training, and (5) Model Fine-tuning. The Database schema filtration process involves comparing n-grams extracted from the given database schema with those present in the text under consideration, enabling us to identify referenced tables in the question and acquire a sub-database schema that aligns semantically. During the DV knowledge Encoding phase, we linearize DV knowledge encompassing DV queries, database schemas, and tables. Subsequently, in the Standardized Encoding phase, we normalize the DV knowledge to facilitate more efficient learning. The resulting corpus, in its unified form, is then employed to train our proposed DataVisT5 model."}, {"title": "B. Database Schema Filtration", "content": "Before the integration of DV and text modalities, it is critical to recognize that NL questions can incorporate keywords related to the database schema. This requires the explicit identification of references to columns, tables, and conditional values within the NL questions. To address this challenge, we employ N-gram matching as a method due to its simplicity of implementation and notable effectiveness for a variety of applications. In an effort to minimize information loss, our primary focus is at the table level, where we compare N-grams extracted from the NL questions to those present in the database tables. Following the initial comparison, we refine the obtained sub-schema by considering the implicated tables and their respective columns.\nExample. Our Database Schema Filtration technique, demonstrated in Figure 3, matches n-grams between the NL question \"Give me a pie chart about the proportion of the number of countries in the artist table\u201d and the database tables artist and exhibition_record. It then extracts a sub-schema centered on the artist table."}, {"title": "C. DV Knowledge Encoding", "content": "To address the disparity between text and DV modalities, we propose investigating unified formats for DV knowledge. The connection between natural language and DV knowledge poses challenges due to limited data accessibility. Nevertheless, a unified format allows models to capitalize on extensive pretraining for smaller datasets. Employing consistent formatting, as recommended by [29], offers advantages in multi-task training and mitigates performance decline caused by data heterogeneity compared to single-task training. The subsequent sections provide a comprehensive introduction to the unified representation of three distinct types of DV knowledge: DV queries, database schemas, and tables.\nEncoding DV query. While most existing NLP models, such as [20], consider NL inputs as flat text sequences, we adopt a similar approach for modeling a DV query by treating it as a plain text sequence in a straightforward manner.\nEncoding Database schema. The database schema comprises tables and columns. For each table in the schema, the table name is followed by a list of its columns formatted as \u201ctable : column1, ... columnn\u201d. Different tables are joined using the symbol \u201c|\u201d. Additionally, the database name is prefixed to the generated sequence with boundaries indicated by \u201c<>\u201d.\nEncoding Table. Following [30], we employ a sequential representation of tables, akin to the schema encoding technique, which uses distinctive tokens to delineate table structure. The table is linearly represented as \u201ccol : C1 |\u00b7\u00b7\u00b7|CN row 1 : v11 |\u00b7\u00b7\u00b7| U1N ... row M: VM1|\u00b7\u00b7\u00b7| UMN\u201d, with N indicating the total column count and M representing the row count.\nExample. An presented in Figure 4, where (1) the DV query is sequentially encoded into text sequences based on the data manipulation operations: Visualize, Select, Count, and Grouping, (2) the filtered database sub-schema, including the database name (theme_gallery), table name (artist), and columns, is encoded into a corresponding text sequence, and (3) the table content is linearly encoded in the format \u201ccol: Country | COUNT(Country)\u201d, along with the remaining three rows of the table."}, {"title": "D. Standardized Encoding", "content": "Due to the manual generation of queries by multiple annotators with diverse annotation habits, subtle stylistic differences are prevalent in the final annotated DV queries within NVbench, including variations in the capitalization of keywords. Similar to issues encountered with SQL queries, these stylistic inconsistencies, while not affecting the model\u2019s execution results, pose an additional learning challenge that must be addressed.\nTo address the stylistic variations in DV queries, a pre-processing strategy was implemented before training. This strategy includes: (1) affixing the primary table name T to the selected columns col, resulting in the notation T.col across DV queries; particularly, for instances where the wildcard symbol * is employed in a COUNT function, COUNT(*) is replaced with COUNT(T.col) to maintain uniformity; (2) the insertion of spaces surrounding parentheses and the replacement of double quotes with single quotes; (3) the inclusion of the ASC keyword subsequent to the ORDER BY clause when ordering is not explicitly specified; (4) the elimination of the AS clause and the substitution of table aliases (e.g., T1, T2) with their actual table names; (5) the lowercase conversion.\nExample. In a DV query with a Join operation, as depicted in Figure 5, standardization involves renaming table aliases T1 and T2 to player and team, respectively. The query\u2019s COUNT(*) is specified as COUNT(player.years_played), 'Columbus Crew' is quoted with single quotes, the ASC keyword is appended if sort order is absent, and the entire query is cast to lowercase.\nIn alignment with the standardization of DV queries, similar encoding steps are applied to database schemas and tables to ensure consistency. This includes affixing the table name T to each column name col and converting them to T.col.\nExample. As depicted in Figure 4, within a specific database schema, column names such as \u201cage, name, country, year_join, and artist_id\u201d are transformed to \u201cartist.age, artist.name, artist.country, artist.year_join, and artist.artist_id\u201d, respectively. Similarly, within the table context, an entry like \u201ccol : Country | COUNT(Country)\u201d is reformulated to \u201ccol : artist.country | count(artist.country)\u201d."}, {"title": "E. Hybrid Pre-training Objectives", "content": "Bidirectional Dual-Corpus Objectives. We utilize a bidirectional dual-corpus strategy in our research methodology where both source and target corpora are randomly selected with an equal probability (0.5) during model training as the input. The remaining corpus is then used as the output for translation purposes. Accordingly", "follows": "n$$L_{BD"}, "theta) = \\sum_{i=1}^{T} -log P_{\\theta}(t_i | s, t_{<i}),$$\nwhere s signifies the source input, $t_{<i}$ represents the sequence of tokens generated by the decoder up to but not including the i-th token, and $t_i$ is the token that the decoder is tasked with predicting. The term $\\theta$ denotes the model parameters.\nAs depicted in Figure 6, the segment highlighted by arrows elucidates the deployment of the Bidirectional Dual-Corpus Objectives, encompassing four discrete tasks germane to DV. A comprehensive definition of these tasks is deferred to Section V. To enhance task-specific processing and facilitate knowledge transfer across different modalities, we introduce unique special tokens. For example, as demonstrated in Figure 6, the Text-to-Vis task utilizes a special token <NL> to prefix the NL question corpus and <VQL> for the DV query corpus. In contrast, for the FeVisQA task, DV question-answer pairings are delineated with the tokens  and  to signify their respective components.\nT5-based MLM Objectives. The application of Masked Language Modeling (MLM) as a pretraining objective is pivotal for pretraining encoder-decoder models. In our study, we employed the span corruption MLM strategy from [21"], "as": "n$$L_{MLM} (\\theta) =  \\sum_{n=1}^{N} -log P_{\\theta} (x_m | x_{\\backslash m} , x_n),$$ \nwhere $\\theta$ are the model parameters, $x_m$ is the masked token predicted by the decoder, $x_{\\backslash m}$ represents the unmasked encoded inputs, and $x_n$ is the sequence of tokens generated by the decoder up to but not including the n-th token.\nAn illustration is presented in Figure 6, where the segments linked by dashed lines pertain to the T5-based MLM Objectives. This figure showcases the application of span denoising targets to a DV query. Within this query, the terms \"bar\", \"people group\", \"by\", and \"desc\" are selected at random. Subsequently, a subset of these terms is replaced by sentinel tokens, illustrated as , , , and .\nH"}