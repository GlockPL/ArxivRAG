{"title": "From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs", "authors": ["Ruxiao Chen", "Chenguang Wang", "Yuran Sun", "Xilei Zhao", "Susu Xu"], "abstract": "Evacuation decision prediction is critical for efficient and effective wildfire response by helping emergency management anticipate traffic congestion and bottlenecks, allocate resources, and minimize negative impacts. Traditional statistical methods for evacuation decision prediction fail to capture the complex and diverse behavioral logic of different individuals. In this work, for the first time, we introduce FLARE, short for facilitating LLM for advanced reasoning on wildfire evacuation decision prediction, a Large Language Model (LLM)-based framework that integrates behavioral theories and models to streamline the Chain-of-Thought (CoT) reasoning and subsequently integrate with memory-based Reinforcement Learning (RL) module to provide accurate evacuation decision prediction and understanding. Our proposed method addresses the limitations of using existing LLMs for evacuation behavioral predictions, such as limited survey data, mismatching with behavioral theory, conflicting individual preferences, implicit and complex mental states, and intractable mental state-behavior mapping. Experiments on three post-wildfire survey datasets show an average of 20.47% performance improvement over traditional theory-informed behavioral models, with strong cross-event generalizability. Our complete code is publicly available at https://github.com/SusuXu-s-Lab/FLARE", "sections": [{"title": "1 Introduction", "content": "Wildfires are emerging as a significant natural hazard worldwide (Jain et al., 2020; Zahura et al., 2024). In the January 2025 Southern California wildfires, more than 200,000 residents received evacuation orders to leave their homes (Stelloh et al., 2025). There is an urgent demand for emergency planners and policymakers to develop effective evacuation strategies to mitigate wildfire impacts (Mockrin et al., 2018; Tapley et al., 2023). However, successful evacuations require a clear understanding of the human evacuation decision-making process and outcomes (i.e. whether individuals will follow the order to evacuate or stay) during these events to help policymakers improve evacuation order design, develop more efficient emergency response strategies, and build more resilient communities (Collins et al., 2018; Lovreglio et al., 2020; Hong and Frias-Martinez, 2020; Sun et al., 2024c).\nPrevious studies often construct evacuation choice models through a conceptual framework, Protective Action Decision Model (PADM) (Strahan and Watson, 2019; Lovreglio et al., 2019; Santana et al., 2021; Sun et al., 2024a), which are designed to incorporate psychological factors, like individual risk perception and threat assessment, into the prediction process. Based on the PADM framework, past methods may employ various statistical models (e.g., logistic regression (Forrister et al., 2024a), multinomial logistic regression (McCaffrey et al., 2018)) to predict individual-evacuation decisions using socio-demographic information as inputs, trained on post-wildfire survey data. However, these traditional PADM-type statistical models lack reasoning capabilities to capture the diverse and complex logic underlying human decision-making due to limited data and restrictive modeling structure, even when the survey design is grounded in established behavioral theories. In addition, these statistical methods struggle to integrate qualitative descriptions \u2013 such as narrative accounts of wildfire dynamics or contextual details which are critical for understanding evacuees' perceptions and the rationale behind their evacuation decisions. To address these limitations, the recent emergence of Large Language Models (LLMs) provides exceptional reasoning capabilities to model and predict evacuation decision-making processes (Huang and Chang, 2022; Li et al., 2024e,d; Nguyen et al.,"}, {"title": "2 Related Work", "content": "2.1 Wildfire Evacuation Decision Prediction\nRecent research has employed multiple methods to predict wildfire evacuation decisions. McCaffrey et al. (2018) employed a multinomial logistic model based on PADM, enhanced by a latent class approach, to predict diverse evacuation decisions in three U.S. fire-prone counties. Forrister et al. (2024a) applied logistic and linear regression to predict risk perception, evacuation decision, and delay time. Xu et al. (2023) benchmarked seven machine learning approaches (e.g., Random Forest, Classification And Regression Trees (CART), Extreme Gradient Boosting) and identified CART as the top-performing model for predicting evacuation behavior from the 2019 Kincade Fire survey. Meanwhile, Lovreglio et al. (2020) introduced the Wildfire Decision Model (WDM) calibrated via Hybrid Choice Models (HCM), incorporating latent factors like risk perception and prior experience for more accurate evacuation decision predictions. Sun et al. (2024c) further integrates risk perception and threat assessment as latent variables into an HCM framework, improving prediction accuracy. Traditional statistical models do not account for the logical flow of decision-making. HCM, in contrast, considers this process.\n2.2 LLMs for Human Decision and Behavior Prediction\nCurrent work increasingly leverages LLMs to model and predict human decisions. Big-TOM (Gandhi et al., 2024) evaluates LLMs' Theory-of-Mind (ToM) reasoning via causal templates and finds that GPT-4 partially matches human ToM performance while other models lag behind. Similarly, SUVA (Leng and Yuan, 2023) utilizes probabilistic modeling and behavioral economics games, revealing that larger LLMs display stronger prosocial and group-identity effects. DEBATunE (Li et al., 2024a) utilizes a multi-agent debate process for data synthesis on controversial debate topics and utilizes supervised fine-tuning to simulate behaviors on controversial topics. Extending these insights, ToM (Amirizaniani et al., 2024) focuses on open-ended social reasoning from Reddit's Change-MyView posts, showing prompt tuning with human intentions and emotions boosts performance but remains below human-level comprehension. Although these models can infer mental states, T4D (Zhou et al., 2023) highlights the challenge of converting such inferences into strategic action, as even GPT-4 struggles without structured guidance. In parallel, LELMA (Mensfelt et al., 2024) integrates symbolic AI to verify logical consistency in social simulations like the Prisoner's Dilemma, demonstrating that self-refinement methods can improve the reliability of LLM-generated reasoning. Meanwhile, SimpleToM (Gu et al., 2024) underscores that while LLMs can predict mental states and behavior, they often require deliberate prompting for accurate moral or behavioral judgments. Kang et al. (2023) propose the Value Injection Method (VIM), embedding human core values to enhance opinion and choice prediction. However, Kuribayashi et al. (2024) caution that instruction tuning and prompting do not inherently offer better alignment with human cognition than direct probability outputs from base LLMs. Zhu et al. (2024) reveal that arithmetic-trained LLMs can surpass classic decision-theoretic models when evaluating risky and time-delayed choices, demonstrating that specialized numerical training augments behavioral prediction. Liu et al. (2024) emphasizes a core limitation: LLMs systematically assume people behave more rationally than they do, underestimating well-documented human biases and highlighting a persistent gap between model predictions and real-world decision-making."}, {"title": "3 Method", "content": "In this section, we present the development of our LLM-based pipeline for evaluating evacuation decisions using post-wildfire survey data. The pipeline is shown in Figure 1.\n3.1 Preliminary\nEvacuation Decision Prediction: The Protective Action Decision Model (PADM) is a conceptual framework designed to explain human cognitive processes and decision-making behaviors in response to hazards and disasters. At its core, PADM emphasizes perceptions(e.g., threat perceptions, protective action perceptions, and stakeholder per-ceptions) that shape individuals' decisions on how"}, {"title": "3.2 Reasoning Process Formulation", "content": "In this section, we describe how we construct classifiers based on PADM that identify the most probable reasoning patterns from survey data variables. These patterns are derived from the previously introduced risk perception and threat assessment. Once the appropriate reasoning pattern is determined, we demonstrate how an LLM generates the corresponding perception and integrates it into a CoT template, yielding the finalized CoT for evacuation prediction.\n3.2.1 Variable Selection for Perceptions\nBuilding on the HCM framework based on PADM for wildfire evacuation decision prediction (Lovreglio et al., 2020; Sun et al., 2024c), our approach aims to develop a unified statistical method to automatically select the key variables that contribute to risk perceptions and threat assessment by examining all available survey questions. As briefly mentioned in Section 3.1, the survey includes questions capturing socio-demographic data, awareness and understanding, and decision-related factors such as prior wildfire risk awareness, emergency preparedness, evacuation experience, warning system awareness, personal injury perceptions, household income, employment status, and medical conditions. In the HCM method (Sun et al., 2024c), threat assessment and risk perceptions are validated using specific indicators derived from survey questions, requiring manual selection of variables, fitting them to indicators, and evaluating their alignment. Our approach automates this process by incorporating all available variables into the fitting process and selecting those with the highest weights, ensuring the strongest contributions to risk perceptions and threat assessments. This minimizes bias in manual selection and enhances the model's ability to capture key evacuation decision factors.\nFormally, we regress each perception indicator on all survey variables:\n$Y_k = W_1X_1 + W_2X_2+... +W_nX_n+\\epsilon$, (1)\nwhere $Y_k$ is the dependent variable (with k = Th for threat assessment or k = R\u0127 for risk perception), $w_i$ are the weights for the variables $X_i$, and $\\epsilon$ is an error term. Once all variables are fitted in this regression, We then select a subset X' of variables whose cumulative weight meets a predefined threshold $\\theta$. Mathematically, this criterion is:\n$\\sum_{X_i\\in X'} w_i \\geq \\theta\\cdot \\sum_{i=1}^{n} w_i$ (2)\nEmpirically, $\\theta$ corresponds to the elbow point in the weight distribution, ensuring key variables are retained while filtering out less significant ones. The empirical results visualizing this elbow point"}, {"title": "3.2.2 CoT Construction based on Perceptions", "content": "In this section, we describe how we construct the CoT by leveraging the variable subsets selected earlier. First, we develop a universal CoT template that structures reasoning into two stages \u2013 threat assessment followed by risk perception \u2013 to enforce a behaviorally grounded reasoning path. We then introduce a reasoning pattern classifier that selects the most probable reasoning pattern for each individual based on the prediction success rate of each reasoning pattern. Finally, we prompt the LLM to generate textual threat assessments and risk perceptions along with their quantitative perception scores for each case, calibrating consistency and establishing a foundation for subsequent evacuation decision prediction.\nReasoning Pattern Classifier: We classify individuals into the four reasoning patterns through a statistical machine learning classifier (e.g., random forest), training it on quantified survey data as input and using the LLM's prediction performance across reasoning patterns as labels to automate pattern selection. For each individual, we first populate all four reasoning patterns using their survey responses to generate corresponding perceptions, which are then inserted into the CoT template to form a temporary CoT for prediction. We then conduct multiple inference trials for each temporary CoT, with each trial producing a predicted evacuation decision (evacuate or stay) that is compared to the individual's actual response to the evacuation decision. The success rate for each pattern is computed as the proportion of correct predictions, and the pattern with the highest success rate is considered the most probable reasoning pattern for that individual.\nWe further use the estimated most probable pattern as the label for individuals and train the classifier on these labels and relevant survey variables (e.g., socio-demographics, evacuation order awareness). This classifier automates pattern selection, ensuring that the model dynamically adapts to psychological and situational factors, enabling personalized and interpretable evacuation predictions.\nPerception Inference: After selecting each individual's most probable reasoning pattern, we refine the generation of risk perceptions and threat assessments to construct a complete CoT for evacuation decision prediction. The LLM first generates textual threat assessment and risk perceptions while explicitly assigning quantitative perception scores (1-5) as calibration indicators. This dual representation enhances consistency between inferred perceptions and key survey variables. To refine this calibration, we use the first 70% of the dataset to establish a knowledge base mapping LLM-generated perceptions to survey-derived scores, allowing the model to align qualitative reasoning with numerical assessment.\nIn the inference stage, we employ Retrieval-Augmented Generation (RAG) to maintain score consistency. The LLM-generated perceptions are compared to stored examples using semantic similarity, retrieving the two most similar instances (based on cosine similarity) along with their scores. This retrieval process aligns predicted scores with established reasoning patterns, ensuring consistency and accuracy in perception inference.\nOnce robust textual perceptions and their corresponding numerical scores are obtained, we integrate them into the CoT templates along with external information such as environment context derived from survey questions (e.g., \u201cI'm not in the area ordered to evacuate.\") and user inputs, forming the complete CoT for evacuation decision prediction. This construction process ensures that the CoT consistently adapts to each individual's most probable reasoning pattern while leveraging textual information.\nWith this complete CoT in place, we establish a reasoning process that accommodates multiple threat-risk scenarios, setting the stage for aligning the reasoning process more closely with human decision-making through the memory-based RL module.\""}, {"title": "3.3 Memory-based RL", "content": "Extending the previously described CoT construction for inference, we further align the reasoning process with human decision-making by incorporating an RL strategy during the LLM inference phase. Inspired by the verbal-based RL methodology in Reflexion (Shinn et al., 2024), our approach introduces a dedicated Memory component that records inference errors along with the corresponding LLM-generated rationales. This Memory mechanism enables the model to learn from past mistakes and adapt its decision-making, bridging the gap between the metal state prediction (i.e. perceptions) and evacuation decision prediction.\nWe begin with a training stage to construct the Memory for subsequent use. During this stage, the actual evacuation decision reported by each respondent serves as the ground-truth reward signal. Whenever the LLM's predicted decision is incorrect, we store the CoT for inference, the environment context, the LLM-generated rationale, and the correct decision in Memory. The model is then prompted to regenerate its reasoning and reflect on the source of the error, with these self-reflection notes also appended to Memory. For subsequent data samples, we retrieve the top-k most similar past entries \u2013 determined via cosine similarity over relevant variable representations \u2013 and integrate these entries as contextual information into the current inference. This retrieval mechanism allows the LLM to leverage prior cases with comparable circumstances or error patterns, refining its predictions over time.\nAfter accumulating sufficient history in Memory during the training phase, we transition to inference on new data. At this stage, self-reflection and error logging are disabled; instead, the Memory's contextual information is directly incorporated into the input, guiding the LLM's reasoning process. The final output comprises the predicted evacuation decision and a supporting rationale derived from the CoT and contextual information retrieved from similar cases in Memory. This comprehensive output ensures accurate predictions while providing interpretable insights into individual evacuation decisions."}, {"title": "4 Experiment", "content": "FLARE, leverages both a combined dataset and the individual post-disaster survey datasets from the 2018 Carr Fire (Wong et al., 2020), 2019 Kincade Fire (Kuligowski et al., 2022b), and 2021 Marshall Fire (Forrister et al., 2024b). The characteristics of each dataset, including evacuation ratio, and utilized variables ratio, are detailed in Table 4. By integrating these data sources, we facilitate a comprehensive prediction of evacuation behavior while also preserving the unique characteristics of each event through separate analyses. The whole framework is implemented via LangChain. A detailed evaluation using metrics such as Accuracy, Precision, Recall, F1-score, Macro F1-score, and Weighted F1-score MSE is provided, with further details available in Appendix A.\n4.1 Main Results\nIn this section, we present a comparative analysis between our approach and several widely adopted methods for wildfire evacuation decision prediction. Specifically, we perform experiments on a consistent dataset to showcase the superior performance of our method, and we further validate its generalizability through cross-dataset testing.\nIn the consistent dataset experiments , we compare the performance of our method, FLARE\u2014which employs three distinct backbones (GPT-03-mini (OpenAI, 2025), GPT-40 (Hurst et al., 2024), and Claude-3.5 (Anthropic, 2024)) separately with four widely adopted prediction methods: Logistic Regression, Random Forest, LLM Inference with GPT-40, and HCM. These comparisons focus on predicting evacuation decisions on a combined dataset. The combined dataset is curated by merging survey data from multiple wildfire events. Detailed results for the single-event dataset are provided in Appendix C. The results consistently demonstrate that FLARE achieves superior accuracy in evacuation prediction compared to the baseline methods. In contrast, the baseline approaches not only deliver lower overall accuracy but also struggle with balanced detection across various predictions, as evidenced by their F1 scores. Moreover, FLARE exhibits notable adaptability across different state-of-the-art LLMs, consistently enhancing performance when employing various backbones. Notably, when using Claude-3.5 as the backbone, FLARE improves accuracy by 13.2%, Macro F1 by 12.7%, and Weighted F1 by 11.9%. These improvements indicate that advancements in LLM reasoning capabilities (Anthropic, 2024) could further elevate the performance of FLARE.\nIn the cross-dataset generalization tests, FLARE consistently outperforms the baseline methods. The experiments were conducted using the Kincade Fire and Marshall Fire datasets in a cross-validation setup, where one dataset served as the training set and the other as the test set. This setup is designed to account for the fact that the wildfire occurred in two different states, as illus-"}, {"title": "4.2 Ablation Study", "content": "We conduct ablation experiments on the combined dataset using the GPT-40 model to assess the impact of the CoT formulation and memory-based RL module on FLARE's performance. As shown in Table 3, removing both components leads to a 13.45% performance drop, confirming their necessity. When only the RL module is removed, the decline is less severe, highlighting the CoT formulation's robust reasoning capability. Furthermore, removing only the RL module results in better performance than both the CoT and RL removed, highlighting the effectiveness of the RL module. These findings validate that both components are essential for optimizing predictive accuracy and solidifying"}, {"title": "5 Discussion - Why It Works", "content": "The framework's effectiveness is driven by the meticulous design of each component, enabling LLMs to generate accurate evacuation predictions and perform complex reasoning based on survey data. One critical aspect is the use of CoT reasoning is crucial for the prediction. Research shows that without carefully designed instructions, LLMs struggle to grasp human mind states, underscoring the need for advanced mechanisms to improve real-world understanding (Xu et al., 2024a). Moreover, the evacuation decision process demands complex reasoning, and CoT enables LLMs to mimic human problem-solving\u2014effectively addressing this complexity while enhancing accuracy and robustness (Wei et al., 2022; Wang et al., 2022; Kojima et al., 2022). Thus, our CoT design integrates both inferred perceptions and external information, establishing a strong foundation for accurate evacuation decision prediction.\nAnother key component is the design of the RL module, which aligns the reasoning process with human thoughts. Although LLMs can closely approximate human performance in mental state prediction with well-crafted CoT, their accuracy drops in behavior prediction without detailed cues (Gu et al., 2024). However, providing extensive detail increases the input sequence length, straining the LLM's limited attention and memory and disrupting the coherent CoT required for accurate multi-step reasoning (Li et al., 2024c,f; Levy et al., 2024;"}, {"title": "6 Conclusion", "content": "In this study, we introduced FLARE, a novel framework that integrates the reasoning capabilities of LLMs with a well-established behavior theory to address the complexities of human mental states in wildfire evacuation decision prediction. By systematically classifying variables and constructing CoT grounded in threat assessments and risk perceptions, our approach captures evacuees' heterogeneous preferences and interprets essential perceptions. Moreover, we integrate a memory-based RL module that serves as a dynamic repository of"}, {"title": "Limitation", "content": "Although FLARE demonstrates promising capabilities in analyzing wildfire evacuation decisions, it is subject to several important limitations. LLMs using CoT reasoning often lack transparency and can produce misleading outputs (Turpin et al., 2023). This issue undermines trust and limits their adoption in policy planning and decision-making, where reliability and interpretability are essential. Another concern is the research relies on self-reported survey data. Although the post-wildfire surveys used in this study adhere to strict data collection protocols and provide valuable insights, they were self-reported data, which may introduce potential recall bias and inaccuracies, which could affect the robustness of the conclusions. A further issue is that, although the PADM framework accounts for geographical, meteorological, and logistical factors (e.g., perception of wildfire impact forecasts, awareness of shelter availability, and knowledge of route alternatives), our survey design did not include these elements. Consequently, our framework may not capture all factors influencing individuals' decision-making processes. Future work will incorporate these variables into the survey to facilitate more precise decision-making. Future work should address these limitations by incorporating richer datasets that encompass a broader population and greater geographical diversity, as well as integrating more extensive environmental and logistical variables."}, {"title": "A.3 Evaluation Metrics", "content": "To evaluate the model's effectiveness in predicting evacuation decisions, we compare the predicted results with actual evacuation decisions using a set of well-established metrics: Accuracy, Precision, Recall, F1-score, Macro F1-score, and Weighted F1-score. Accuracy measures the overall correctness of predictions, while Precision and Recall assess the trade-off between false positives and false negatives, respectively. The F1 score combines Precision and Recall into a single metric to balance their trade-offs. Given the potential class imbalance in evacuation decisions, we also utilize the Macro F1-score, which averages F1-scores across all classes equally, and the Weighted F1-score, which accounts for class frequency by weighting each class's F1-score accordingly. This comprehensive multi-metric approach ensures a thorough understanding of the model's reliability and effectiveness in supporting evacuation decision-making.\nDetailed formulation of evaluation metrics shows as follow:\nAccuracy measures the proportion of correctly classified instances among all instances and is suitable for balanced datasets. However, it may be misleading for imbalanced data. It is defined as:\n$Accuracy = \\frac{TP+TN}{TP+TN+FP + FN}$ (3)\nPrecision calculates the fraction of correctly predicted positive cases out of all predicted positives. It is crucial in scenarios where false positives are costly. The formula is:\n$Precision = \\frac{TP}{TP+FP}$ (4)\nRecall measures the proportion of actual positive instances correctly identified by the model. A high recall is essential when missing positive cases is more critical than incorrectly classifying negatives. It is given by:\n$Recall = \\frac{TP}{TP+FN}$ (5)\nF1-score is the harmonic mean of precision and recall, balancing both metrics to provide a single performance measure, especially useful in imbalanced datasets. It is computed as:\n$F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$ (6)\nMacro F1-score computes the F1-score for each class independently and averages them, treating all classes equally. Since this is a binary classification task, it is equivalent to the standard F1-score:\n$Macro F1 = \\frac{F1_{pos} + F1_{neg}}{2}$ (7)\nWeighted F1-score averages F1-scores across classes but assigns a weight based on class frequency, making it more reliable for imbalanced datasets:"}, {"title": "D.1 Carr Fire", "content": "On July 23, 2018, the Carr Fire ignited in Shasta County, California, when sparks from a vehicle's flat tire set nearby dry vegetation ablaze.By August 30, 2018, the Carr Fire had been fully contained after burning over 229,000 acres, destroying approximately 1,600 structures, forcing the evacuation of around 39,000 people, claiming eight lives, and inflicting an estimated $1.5 billion in damages. The affected area map is shown in Figure 6. As it advanced rapidly to the east, the fire prompted the evacuation of French Gulch, Old Shasta, and Keswick, and worsening conditions led officials to evacuate several urban neighborhoods in Redding. Furthermore, the Carr Fire jumped the Sacramento River-partly due to fire whirls induced by the wildfire system. Ultimately, the combined efforts of 4,500 firefighting personnel and favorable weather conditions slowed its progression through Redding and surrounding rural communities, leading to its eventual containment at the end of August 2018 (Wong et al., 2020)."}, {"title": "D.2 Kincade Fire", "content": "On October 23, 2019, at 9:27 P.M., the Kincade Fire ignited northeast of Geyserville in Sonoma County, California, and was ultimately contained on November 6, 2019, at 7:00 P.M. As the largest wildfire of the 2019 California season, it burned 77,758 acres, damaged 60 structures, completely destroyed 374 structures, and injured four individuals. The event prompted the evacuation of more than 186,000 people-the largest evacuation in Sonoma County's history. To manage this process, emergency officials partitioned the county into designated zones, issuing a mandatory evacuation order in Geyserville on October 26, followed by subsequent orders and warnings extending to areas along the Pacific Ocean and northern sections of Santa Rosa. Figure 7 illustrates the wildfire's spatial impact, the delineated evacuation zones, and additional key fire parameters (Sun et al., 2024a)."}, {"title": "D.3 Marshall Fire", "content": "The Marshall Fire ignited shortly before 10:30 a.m. on December 30, 2021, in Boulder County, Colorado, from two distinct ignition points.From these points, the fire rapidly spread into several suburban areas across Boulder, Jefferson, and Adams Counties, affecting counties such as Louisville, Superior, Broomfield, Lafayette, Arvada, and Westminster. The preceding unusually humid spring, followed by a warm, dry summer and fall, produced dry fuel conditions that, combined with strong dry winds, accelerated the fire's spread. Recognized as the most destructive wildfire in Colorado's history, the Marshall Fire burned over 6,200 acres, destroyed 1,084 homes, damaged 149 additional homes, and resulted in two fatalities. In Boulder County alone, the estimated residential damage exceeded $513 million. On the day of the fire, more than 30,000 residents in Boulder, Jefferson, and Adams Counties were evacuated. Figure 8 illustrates the affected evacuation and pre-evacuation zones for these communities (Forrister et al., 2024a)."}, {"title": "E Weight Distribution for Different Perceptions", "content": "To ensure an objective selection of key variables for each perception type, we use a logistic regression model to derive variable weights and identify an appropriate cutoff threshold. Figure 9 illustrates the weight distribution trends for each perception category: Threat Assessment (Injury and Death) and Risk Perception (Home and Neighborhood). Each plot displays a sharp decline in variable importance, followed by a gradual flattening, indicating the presence of an elbow point. This elbow point serves as the threshold for variable selection, ensuring that the most influential variables are retained while filtering out less significant ones."}, {"title": "F Selected Questions for Different Perceptions", "content": "The selection of specific wildfire survey questions based on PADM for each threat assessment and risk perception reflects different reasoning processes in evacuation decision-making. An example The selected variables (i.e questions) are detailed in Table 6 and Table 7\nThe questions in the two types of threat assessment reflect two distinct aspects. The first type is driven by direct sensory input\u2014whether individuals observed flames or embers and their subjective assessment of wildfire likelihood. Factors like residency duration influence familiarity with local fire risks. In contrast, the second type incorporates external cues such as warnings from social networks and educational background. Residents receiving evacuation advice from acquaintances or managing livestock may prioritize economic and logistical concerns alongside personal safety.\nThe questions in risk perception also follow two distinct patterns. The first emphasizes immediate physical harm, shaped by health conditions, household demographics, and emergency communications. Those with medical conditions or older adults in the household may perceive higher injury risk, while direct evacuation orders heighten urgency. The second type focuses on long-term preparedness, considering financial stability, employment, and proactive fire mitigation efforts. Residents with emergency plans or prior protective measures may perceive lower risk due to a greater sense of control.\nOverall, threat assessment is reactive, shaped by real-time environmental and social cues, whereas risk perception is anticipatory, centered on future consequences and preparedness. Structuring these perceptions into distinct reasoning pathways enables LLMs to model diverse decision-making profiles more effectively, improving accuracy and interpretability in wildfire evacuation predictions."}, {"title": "Prompt for Threat Assessment", "content": "[Threat Assessment]\nSystem Prompt\nYou are an expert at rational reasoning.\nUser Prompt\nAnalyze the following scenario: A resident is deciding whether to evacuate during a wildfire. Based\non their responses to a wildfire survey, provide a brief summary of the resident's threat assessment.\nResponse to a wildfire survey: Survey"}, {"title": "Prompt for Risk Perception", "content": "[Risk Perception]\nSystem Prompt\nYou are an expert at rational reasoning.\nUser Prompt\nConsider the following scenario: A resident is deciding whether to evacuate during a wildfire. Based on\ntheir Threat Assessment and their responses to a wildfire survey, briefly summarize the resident's Risk\nPerception. Threat Perception is: Perception.\nResponse to a wildfire survey: Survey."}, {"title": "Prompt for Evacuation Prediction", "content": "[Making Decision]\nSystem Prompt\nYou are an advanced reasoning agent that can enhance your capabilities by reflecting on your own\nthought processes.\nUser Prompt\nYou have access to a post-wildfire survey completed by local residents who experienced a specific\nwildfire event. Your task is to generate a logical, step-by-step chain of thought to infer whether the\nresident evacuated during the wildfire. Ensure each step is clearly connected. You must conclude with\na definitive YES or NO answer regarding whether the resident evacuated. You will be provided with\nprevious successful examples that have similar information. You may reference the rationale from these\nexamples in your analysis.\nPrevious Examples: Examples\nRisk Perception Summary: Risk.\nExternal information: Extras\nRe-flexion Prompt\nDuring the fire, this resident label from the wildfire. Please reconsider and rethink the original questions\nto provide another clear and logical rationale on why the resident Label:"}, {"title": "C More result", "content": "The accuracy of heatmaps for risk perceptions and threat assessment predictions reveals key trends in the model's performance. Overall, the LLM demonstrates moderate accuracy, with better performance in predicting mid-range values (scores 2-4) while struggling with extreme values (scores 1 and 5). For instance, in risk perception prediction, the model performs best when the actual values are within the 2\u20134 range, with the highest accuracy (80%) observed when the actual risk perception is 5, but the model predicts 3, indicating a systematic underestimation of extreme risk perceptions. Similarly, in threat assessment prediction, the model achieves its highest accuracy (50%) when the actual threat assessment is 1, frequently predicting 2 instead. This pattern suggests that the model is biased toward moderate assessments and struggles to distinguish individuals with extremely high or low-risk perceptions or threat assessments.\nThis finding suggests that while the LLM can generate reasonable approximations of threat assessment and risk perception (which are components of mental states), it struggles with capturing the extreme values that often drive actual evacuation decisions In real-world scenarios, individuals who perceive very high risks are more likely to evacuate, whereas those with very low perceived risks may ignore warnings entirely. However, the model systematically underestimates these extremes, favoring moderate scores instead. This suggests that although it can infer general reasoning patterns, it does not fully capture the high-stakes decision-making process that translates perceptions into action. These findings align with previous research indicating that LLMs perform well in predicting human mental states but have difficulty translating those inferences into precise behavioral predictions. The model's tendency to underestimate extreme scores suggests the need for further calibration, like incorporating the evacuation behavioral model, reinforcement learning, and contextual variables during inferences, which is what we did in this paper."}, {"title": "Weighted F1", "content": "$Weighted\\ F1 = \\frac{N_{pos} \\times F1_{pos} + N_{neg} \\times F1_{neg}}{N_{pos} + N_{neg}}$ (8)\nwhere $N_{pos}$ and $N_{neg}$ are the number of positive and negative samples, respectively.\nMean Squared Error (MSE) measures the average squared difference between predicted and actual values, commonly used in regression tasks. It penalizes larger errors more heavily, making it sensitive to outliers. The formula is:\n$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2$ (9)\nwhere $y_i$ represents the actual value, $\\hat{y}_i$ is the predicted value, and n is the total number of samples."}]}