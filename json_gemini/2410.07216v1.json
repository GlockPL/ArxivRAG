{"title": "Evaluating Financial Relational Graphs: Interpretation Before Prediction", "authors": ["Yingjie Niu", "Lanxin Lu", "Valerio Poti", "Rian Dolphin", "Ruihai Dong"], "abstract": "Accurate and robust stock trend forecasting has been a crucial and challenging task, as stock price changes are influenced by multiple factors. Graph neural network-based methods have recently achieved remarkable success in this domain by constructing stock relationship graphs that reflect internal factors and relationships between stocks. However, most of these methods rely on predefined factors to construct static stock relationship graphs due to the lack of suitable datasets, failing to capture the dynamic changes in stock relationships. Moreover, the evaluation of relationship graphs in these methods is often tied to the performance of neural network models on downstream tasks, leading to confusion and imprecision. To address these issues, we introduce the SPNews dataset, collected based on S&P 500 Index stocks, to facilitate the construction of dynamic relationship graphs. Furthermore, we propose a novel set of financial relationship graph evaluation methods that are independent of downstream tasks. By using the relationship graph to explain historical financial phenomena, we assess its validity before constructing a graph neural network, ensuring the graph's effectiveness in capturing relevant financial relationships. Experimental results demonstrate that our evaluation methods can effectively differentiate between various financial relationship graphs, yielding more interpretable results compared to traditional approaches. We make our source code publicly available on GitHub to promote reproducibility and further research in this area 1.", "sections": [{"title": "1 Introduction", "content": "Stock market prediction using machine learning techniques has garnered significant attention in recent years [9, 17, 18]. Aside from being influenced by its own momentum, a stock's price is also affected by the momentum spillovers among related companies, indicating that the dynamics of related firms' stock prices can exert an impact [1]. The advent of graph neural networks (GNNs) has enabled researchers to model these momentum spillover effects by constructing corporate relationship graphs and training GNN models on them [5, 19]. However, most prior works rely on predefined, static relationships to construct these graphs, which may not capture the dynamic nature of inter-company relationships in fast-paced stock markets. Predefined relationships may become outdated and no longer applicable to the current market. Some recent studies have explored building dynamic relationship graphs using historical market signals [25]. Still, due to data limitations, these graphs are often constructed solely from quantitative data without leveraging alternative data that could help define company relationships. News, as a high-frequently updated information source, can serve as a good resource for capturing the changing of corporate relationships. Thus, there is a need for a news dataset that can assist dynamic relationship graph construction. To solve this problem we introduce the SPNews dataset, consisting of a news dataset collected based on S&P500 Index Stocks. This dataset will help future researchers explore more possibilities for building dynamic relationship graphs that incorporate alternative data.\nMoreover, existing approaches for evaluating relationship graphs primarily rely on their performance on downstream tasks, which can be misleading. When concurrently appraising graphs and graph neural network models, a robust model might obscure deficiencies within the constructed graph. Furthermore, another issue arising from selecting graphs based on downstream task performance is the limited generalization ability of such graphs. Graphs selected in this manner may only prove effective for the specific task or even solely within the confines of the dataset used for selection. Thus, we claim that: selecting the graph solely based on its performance in downstream tasks amounts to conflating the evaluating the graph itself (an upstream task) and assessing its suitability for downstream tasks. Keeping these tasks separate not only enhances the interpretability of the graph but also improves its generalization ability, because a graph that yields satisfactory results in a limited dataset may not generalize well if the collinearities among nodes are unstable over time."}, {"title": "2 Related Work", "content": "Statistical and machine learning techniques have been widely applied to stock trend forecasting, leveraging both time series data and alternative data sources. Traditional models, such as the Autoregressive Integrated Moving Average (ARIMA) model, have long been used to capture the temporal dependencies in stock returns [2], while more recently, deep learning models, such as Long Short-Term Memory (LSTM) networks [14], have demonstrated strong performance in capturing complex patterns and non-linear relationships in financial time series data [23]. Many researchers explored the possibility of applying Natural Language Processing (NLP) techniques in the financial field resulting in notable success [11, 20]. In addition to time series data, alternative data sources such as news articles [8], social media posts [21, 27], company filings, and audio data from earnings calls [28] have been utilized to extract relevant features for stock price prediction.\nWith recent advances in graph-based machine learning and representation learning, relational information within financial markets is being explored in more detail to move away from treating assets independently [10]. Researchers start to model the momentum spillover effect through corporate relationship graphs and graph neural networks (GNN) [22, 26]. More advanced GNN-based techniques like Graph Attention Networks (GAT) [24], for example, have recently gained traction in stock returns forecasting, as they can effectively capture the complex relationships and dependencies among stocks [9, 16, 19]. Among these studies, a common practice in graph construction is that they build a static corporate relation graph based on predefined relations. Few attempts have been made to capture dynamic relationships based on the correlation of historical data [25].\nMoreover, the evaluation of financial relationship graphs remains a challenging task, with most existing approaches relying on the performance of graph-based models on downstream tasks [6, 19, 25]."}, {"title": "3 Problem Definition and Graph Construction", "content": "In this section, we conceptualize the financial relationship graphs and introduce the way we construct the dynamic relationship graph set G based on our SPNews dataset.\nProblem Definition In contrast to conventional graph-based methodologies, which manually create static graphs through predefined relationships, we conceptualize the company relation graph set as an assemblage of temporal evolutional graphs. Within these graphs, each node signifies a firm, and the edges encapsulate their relations. Figure 1 (a) illustrates the temporal evolution of a company relationship graph on a three-dimensional coordinate axis. Each X-Y plane corresponds to a specific relationship graph $G_t$ at time t. The T-axis signifies time, capturing the progressive changes in the relationship graph over temporal intervals. And we name all the relationship graphs within a certain period T as a relationship graph set G.\nGraph Construction Table 1 summarizes the symbols introduced in this paper. The graph set G consists of a series of relationship graphs at different timestamps. A relationship graph $G_t = (V, E_t)$ where V is the set of nodes which is constant through the whole period, and $E_t$ is the set of edges in $G_t$. Let A and B represent a pair of nodes, the edge between A and B at time t is represented as $E_t (A, B) = (\\mu(A,B), \\nu(A,B))$ where $\\mu_{(A,B)}$ is a boolean value indicates whether there exists an edge between A and B at time t. $v_{(A,B)}$ is a float number attached to an edge to record the strength of the connection. To construct an edge $E_t (A, B)$ based on the SPNews dataset, we look for news that mentioned both A and B among all the news on day t. If such news exists, we count the number of these news as k and compare k with a pre-defined threshold \u03c4. If $k > \u03c4$, we assign the edge $E_t (A, B) = (1, Norm_{Gt} (k))$, otherwise,"}, {"title": "4 Graph Evaluation Methods", "content": "In this section, we introduce the proposed graphs evaluation methods, named Financial Relationship-graph Interpretation (FRI) framework which contains 4 indicators. We utilize the graph to interpret inter-company financial phenomena, substantiating the efficacy of the constructed relationship graph. To comprehensively evaluate the entire graph set G, we conduct the evaluation on two dimensions:\n4.1\n\u2022 Horizontal: Within each graph $G_t$, analyse and compare the difference between connected nodes $V^m$ and isolated nodes $V^r$ to interprate the relationships built at time t.\n\u2022 Vertical: Along the T axis, for each pair of firms A and B, analyse the change of their relationship (edges) along time evolution [$E_0 (A, B), E_1 (A, B), E_2 (A, B), ..., E_T (A, B)$].\nReturn Correlation Stability\nThe correlation coefficient derived from stock historical return data typically serves as a measure of the relationship between the two firms. Denoting the correlation coefficient between firm A and firm B during the period $[t, t + \\epsilon]$ as $\\sigma_{t,t+\\epsilon}(A, B)$, the alteration in correlation before and after $E_t (A, B)$ is established can be expressed as\n$\\delta_t(A, B) = \\sigma_{t-\\epsilon, t}(A, B) - \\sigma_{t, t+\\epsilon}(A, B)$     (1)\nwhere $\\epsilon$ is the window length (21 trading days in our experiment) used to calculate the correlation coefficient. To evaluate the edges (relationships) within a relationship graph $G_t$, we have the following assumptions: 1. the correlation between two companies without any relationship always fluctuates randomly. 2. The correlation between two companies with a relationship is usually affected by changes in their relationship. Therefore, by comparing the correlation changes before and after an edge is established, we can evaluate whether this edge effectively captures the true relationship and its changes. We anticipate that changes in correlation between companies with established edges will be significantly larger than that between companies lacking such connections. Consequently, we propose the following null hypothesis.\n\u2022 Ho The change in the correlation of connected nodes is lower than that of the non-connected nodes.\nHo can be formulated mathematically as\n$|\\delta_t(A_1, B_1)| <= |\\delta_t(A_2, B_2)|$     (2)\nwhere $A_1, B_1 \\in V^m$ and $A_2, B_2 \\in V^r$ with notation following the definitions in Table 1.\nBy comparing the difference in correlation stability between connected nodes and unconnected nodes in $G_t$, it can be demonstrated whether the relationship graph effectively captures the company pairs in which true relationships exist. We first test the null hypothesis on each $G_t$ to calculate the Correlation Stability (CS) on $G_t$.\n$CS_{G_t} =\n\\begin{cases}\n1, & \\text{if H0 is rejected} \\\\\n0, & \\text{otherwise}\n\\end{cases}$ (3)\nThen we propose Correlation Stability Score (CSS) to formulate the return correlation stability as a quantitative indicator of the entire graph set G.\n$CSS_G = \\frac{1}{T}\\sum_{G_t \\in G}CS_{G_t}$      (4)\nwhere T represents the number of trading days in G, which is also the number of graphs in the graph set. As such, CSS can be interpreted as the proportion of graph $G_t$ where the correlation change of connected nodes is significantly greater than that of unconnected nodes.\n4.2 Event Detection\nIn order to comprehensively evaluate a dynamic company relationship graph, it is not only necessary to conduct horizontal comparisons among companies within $G_t$, but also to analyze how the relationship between two companies evolves over time, so as to evaluate whether the dynamic graph adequately captures the changes of the relationship between the two companies during that period.\nThrough observation, it is found that two firms usually co-occur in many news articles during some periods, but not at all at other times. We define the periods that have continued co-occurrence of two firms as an event period, that is $[day_t, ..., day_{t+T_e}]$ where t is the starting date of the event period, and $T_e$ is the number of trading days in this period. In this notation, the period of the entire graph set G is $[day_0, ..., day_T]$. If a significant change in the correlation of the two firms is observed during the event period, it means some breaking events have happened which affects the correlation of the two firms. For example, if the correlation of firm A and firm B decreased from 0.7 to 0.3 during an event period, we can infer that some breaking events happened, which led to a drop in the correlation strength. The news articles associated with the edges between firms A and B built during that event period can explain the drop in correlation. In order to quantify how well a graph set G captures events, we propose the Average Event Capture Rate (AECR). Let firm A and firm B represent a pair of firms within the graph set G, the maximum correlation difference of firm A and B over whole period is\n$\\Delta_T (A, B) = max([\\sigma_{t=0}(A, B), ..., \\sigma_{t=T}(A, B)])\u2013min([\\sigma_{t=0}(A, B), ..., \\sigma_{t=T}(A, B)])$   (5)\nThe maximum correlation difference over one event period is\n$\\Delta_{T_e} (A, B) = max([\\sigma_{t=t}(A, B), ..., \\sigma_{t=t+T_e}(A, B)])-min([\\sigma_{t=t}(A, B), ..., \\sigma_{t=t+T_e}(A, B)])$       (6)\nwhere t is the starting date of the event period. The event-capturing indicator $EC_{(A,B),T_e}$ of the event period is\n$EC_{(A,B), T_e}=\n\\begin{cases}\n1, & \\text{if } \\frac{\\Delta_{T_e}(A,B)}{\\Delta_T (A,B)}> std([\\sigma_{t=0}(A, B), ...,  \\sigma_{t=T}(A, B)])\\\\\n0, & \\text{otherwise}\n\\end{cases}$ (7)"}, {"title": "4.3 Edge Factor Model: Explain Return Correlation", "content": "The Fama-French Three Factor model is a formula to describe the rate of return on a stock investment [13]. This model evaluates the anticipated rate of return on investment by considering three factors: overall market risk, the relative outperformance of small-cap over large-cap companies, and the extent to which high-value companies outperform low-value ones. Drawing inspiration from the Fama-French Three Factor model, we introduce a relationship factor, i.e. HMLR, to elucidate the return correlation or co-movement between two firms. Our assumption is that during period $[day_0, ..., day_T]$, the higher the density of edges established between two companies, the higher the correlation between the two companies. The relationship factor construction process is demonstrated in Algorithm 1 and Figure 1 (b). In the Algorithms, we use lower case letter(s) to represent scalar, bold lower case letter(s) to represent vector, and bold upper case letter(s) to represent matrix. To evaluate the effectiveness of the HMLR factor, we conduct the test on a group of node pairs different from the 1200 pairs used in factor construction. The factor testing process is demonstrated in Algorithm 2 and Figure 1 (c) which returns a series of coefficient \u03b2. In the testing phase, node pairs were grouped based on the number of edges, and a regression analysis using the HMLR factor was conducted on the return correlation within each group. If a noticeable upward trend is observed in the \u03b2 values, it serves as evidence supporting our assumption. Thus, we propose the averaged \u03b2 difference as the quantitative indicator of the explanatory capacity of G to the return correlation. The higher \u0394\u03b2 indicates the better explanatory capacity.\n$\\Delta\\beta = \\frac{1}{h-1}\\sum_{i=1}^{h-1} (\\beta_{i+1} - \\beta_i)$    (10)"}, {"title": "4.4 Edge Factor Model: Explain Volatility Correlation", "content": "The HMLR factor evaluates the ability of the company relationship graph set G to explain the relationship between the rate of return among its nodes, which is very helpful for tasks such as stock trend prediction. However, relationship graphs can be widely applied to a variety of downstream tasks, and it is one-sided to only focus on the relationship between returns. The Dynamic Conditional Correlation Generalized Autoregressive Conditional Heteroscedasticity (DCC-GARCH) model [12] was introduced as an extension of the CCC-GARCH model [3] which focuses on modelling the volatility of individual financial time series. Therefore, we include the DCC-GARCH model in our assessment instruments that focus on the volatility correlation between firms. The implementation of DCC-GARCH model in this paper follows [4].\nThe evaluation of the dynamic relationship graph utilizing the DCC-GARCH model commences with the execution of steps 1 through 17 as delineated in Algorithm 1, culminating in the categorization of company pairs into three distinct groups. Specifically, $group_{high}$ comprises node pairs exhibiting a notably strong correlation within the relational graph G, akin to $group_{medium}$ and $group_{low}$ denoting varying degrees of relational strength. Subsequently, the DCC-GARCH model is applied to the returns of each node pair, yielding coefficients denoted as \u03b1 and \u03b2. Averaging these coefficients within each group yields six group-level outcomes: $\\alpha_{high}, \\beta_{high}, \\alpha_{medium}, \\beta_{medium}, \\alpha_{low}, \\beta_{low}$. Within the context of DCC-GARCH results, the condition $\\alpha + \\beta < 1$ denotes model stability, signifying the efficacy of the dynamic correlation relationship.\nHere, \u03b1 represents the degree of influence of residuals on the correlation coefficients, which in economic terms means the degree of influence of new information on the correlation of market volatility. \u03b2 represents the degree of influence of past market volatility on current market volatility, that is, the persistence degree of market volatility correlation. Thus, we proposed the $A_{DCC}$ as an indicator:\n$A_{DCC} = \\alpha_{high} \u2013 \\alpha_{low} + \\beta_{low} \u2013 \\beta_{high}$    (11)\nwhere $\u03b1_{high}$ and $\u03b1_{low}$ indicate the averaged \u03b1 within the $group_{high}$ and $group_{low}$. $\u03b2_{high}$ and $\u03b2_{low}$ represent the averaged \u03b2 value within $group_{high}$ and $group_{low}$. A positive value of $\u03b1_{high} \u2013 \u03b1_{low}$ signifies that the volatility correlation among company pairs in $group_{high}$ is more responsive to new information compared to that in $group_{low}$. Conversely, a positive value of $\u03b2_{low} - \u03b2_{high}$ suggests that the volatility correlation among company pairs in $group_{low}$ is more influenced by past volatility correlations than those in $group_{high}$. Thus, a higher $A_{DCC}$ value indicates a greater discriminatory capacity of the graph set G in identifying firms with higher volatility correlation."}, {"title": "5 Data Collection", "content": "In this section, we introduce our SPNews dataset and discuss the advantages of our dataset compared to the existing financial news datasets.\n5.1 Existing Financial News Dataset\nBusiness news is sourced from various outlets. This work leverages open-source datasets mentioned in prior research for comparative analysis."}, {"title": "5.2 SPNews Dataset Description", "content": "In this work, we choose stocks within the SP500 index, collect publicly available financial news articles from Yahoo Finance\u00b2 during September 2022 and October 2023, and publish our dataset named SPNews. We omit the stocks with incomplete records during this period, which leaves 431 stocks remaining. For each stock, we download 8 news that are labelled to this stock every day through Yahoo Finance API\u00b3. Table 2 compares existing open-sourced financial news datasets with the SPNews dataset.\nThe SPNews dataset serves as a valuable resource for the development of dynamic financial relationship graphs, presenting several noteworthy advantages. Firstly, it maintains a targeted focus on stocks by exclusively featuring news pertaining to companies within the SP500 Index, thus eliminating the presence of irrelevant information. Secondly, the dataset incorporates timestamps in the collection of news entries, facilitating a temporal analysis that is pivotal for capturing the temporal evolution of financial relationships. Lastly, the dataset annotates companies associated with each news item, providing a structured framework for the construction of inter-company relationships in financial modelling and analysis."}, {"title": "6 Experiment Setup", "content": "In this section, we present experimental results that convey the effectiveness of the proposed FRI matrix. In order to verify the utility of the FRI framework, we conducted downstream experiments on the same set of graphs. The effectiveness of the FRI framework can be demonstrated by comparing the experimental results on downstream tasks and the FRI metric.\n6.1 Graph Dataset Construction\nIn our experiment, we implemented five methods to construct the financial relationship graphs:\n\u2022 StaticGraph: Construct a relationship graph at the beginning of T and the graph remains constant during the entire period, i.e. $[G_0 = G_1 = ...= G_T]$. In our experiment, T = 236 trading days.\n\u2022 DynamicGraphCorr: The edges between nodes is determined according to the value of each element of the correlation matrix [25].\n\u2022 DynamicGraphSPNewst=0 (Ours): The edges between nodes are built based on their co-occurrence in the SPNews dataset. \u03c4 = 0 means we build an edge between two companies if they co-occurred in any news at least once on day t.\n\u2022 DynamicGraphSPNewst=1 (Ours): \u03c4 = 1 means we build an edge between two companies if they co-occurred in any news more than once on day t.\n\u2022 DynamicGraphSPNewst=2 (Ours): \u03c4 = 2 means we build an edge between two companies if they co-occurred in any news more than twice on day t.\n6.2 Downstream Task\nWe select the stock trend prediction as the downstream task and regard it as a three-class classification task. The training set, validation set, and test set are distributed in a ratio of 8:1:1. For a node $V(i)$ in graph $G_t$, the label y is\n$y=\n\\begin{cases}\nnegative, & \\text{if } r_{t+1} < -std(r_i) \\\\\nneutral, & \\text{if } -std(r_i) < r_{t+1} < std(r_i) \\\\\npositive, & \\text{if } r_{t+1} > std(r_i)\n\\end{cases}$    (12)\nwhere $r_{t+1}$ represents the rate of return of node $V(i)$ on day t+1, $r_i$ represents the time series of node $V(i)$'s returns during the whole dataset period, and $std(r_i)$ represents the standard deviation of the time series $r_i$. The benefit of labelling three classes is that, from the investment management point of view, the investors focus more on the firms with large positive or negative returns because these firms have room for profit. Slightly positive or negative returns are usually regarded as normal fluctuations.\nWe select the Graph Attention Network (GAT) model as the baseline model, which is commonly used in graph-based stock trend prediction tasks [6, 25]. Inspired by [19], we add a Long-Short Term Memory (LSTM) on top of GAT to encode the historical information as the node embedding. Following previous research [6], we implement a 2-layer GAT followed by a multi-layer perceptron(MLP) as the classifier to get the classification results of the nodes. The softmax activation function is used for the last layer. We use cross-entropy as the loss function which is formulated as follows:\n$L = - \\sum_{i \\in V}\\sum_{k=1}^{K} y_i^{(k)} log(\\hat{y_i}^{(k)})$  (13)\nwhere K represents the number of classes, k represents individual label k. $y_i^{(k)}$ indicates whether the node i belongs to label k at time t. $\\hat{y_i}^{(k)}$ is the model predicted probability of node i belonging to label k. The Adam [15] optimizer is used to update model parameters. We keep the model architectures and hyper-parameters constant"}, {"title": "7 Results and Discussion", "content": "We evaluate the constructed relationship graphs using both the FRI framework and the downstream task performance.\n7.1 Result Comparison\nTable 3 presents the evaluation results of different graphs under the FRI framework. Notably", "results": "n\u2022 Table 3: \u03c4 = 0 > \u03c4= 1 > \u03c4 = 2 > Corr > StaticGraph\n\u2022 Table 4: \u03c4 = 1 > \u03c4= 2 > \u03c4 = 0 > Corr > StaticGraph\nFrom the sorting results, we can see that the results of FRI framework and downstream task evaluation are in the same trend. We don't suggest that our proposed FRI framework should replace downstream task evaluation, but rather that it can augment the decision making process, which is particularly useful if downstream evaluation is computationally expensive. The framework serves as a guide to which graphs are likely to perform well in downstream tasks. We believe that the interpretability and evaluation of graphs is a direction worth exploring, and this work may inspire future researchers to think beyond downstream tasks when evaluating financial graphs.\n7.2 Discussion\nIn this section, we provide a discussion aimed at enhancing the readers understanding of the FRI framework. To do this, we present a case study and an examination of the framework's limitations.\nCase Study To provide readers with a deep understanding of the FRI framework, we conducted a case study focusing on the Average Event Capturing Rate (ACER). Figure 2 illustrates the variations in the rolling 21-day return correlation between Apple Inc and JPMorgan Chase & Co over the entire period covered by our dataset. The scatter points distributed along the vertical axis at 0 and 1 represent whether an edge exists between Apple and JP Morgan in our relationship graph at time t. For instance, if an edge exists between these two companies in our graph $G_t$ on day t, i.e. $\\mu_{(AAPL,JMP)}= 1$, then a point will be plotted at the position (t, 1) in Figure 2. Conversely, if $\\mu_{(AAPL,JPM)}= 0$, a point will be plotted at the position (t, 0) in the figure. A continuous series of scatter points at the vertical coordinate of 1 represents an event period. We observe that periods in which the return correlation fluctuates significantly generally occur within our event period, aligning with our intuition and assumptions. In contrast, correlations tend to experience smaller fluctuations outside of event periods. For example, between March 2023 and April 2023, there was a sharp decline in the return correlation between Apple and JP Morgan. During this period, our SPNews dataset contains news items that may have led to divergent stock trends for these two companies, thereby weakening their correlation. Consequently, the Event Capture (EC)"}]}