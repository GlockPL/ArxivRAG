{"title": "ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework", "authors": ["Xiaoyu Deng", "Ye Zhang", "Tianmin Guo", "Yongzhe Zhang", "Zhengjian Kang", "Xintao Li", "Hang Yang"], "abstract": "The astonishing performance of large language models (LLMs) and their remarkable achievements in production and daily life have led to their widespread application in collaborative tasks. However, current large models face challenges such as hallucination and lack of specificity in content generation in vertical domain tasks. Inspired by the contrast and classification mechanisms in human cognitive processes, this paper constructs an adversarial learning-based prompt framework named ChallengeMe, which includes three cascaded solutions: generation prompts, evaluation prompts, and feedback optimization. In this process, we designed seven core optimization dimensions and set the threshold for adversarial learning. The results of mixed case studies on the text summarization task show that the proposed framework can generate more accurate and fluent text summaries compared to the current advanced mainstream LLMs.\nKeywords: LLMs, Prompt Engineering, Adversarial learning, human cognitive processes", "sections": [{"title": "Introduction", "content": "The development of artificial intelligence stems from researchers' contemplation and exploration of human-biological machines (Cheok & Cheok, 2016). Inspired by the characteristics of biological appearance (Panagoulias et al., 2024), living habits (Barthlott et al., 2016), and cognitive habits(Hertel & Brozovich, 2010), a large number of bionic research designs and innovations have provided valuable explorations for the development of artificial intelligence. Among them, natural language processing technology aims to simulate human communication habits and construct human-like agents, which have extensive applications in fields such as question-answering systems. In recent years, with explosive growth of computing power and data, the development of large language models has been significant, showing superior performance and strong generalization and scalability in fields such as intelligent agents (Wooldridge, 1999), service systems(Beuren et al., 2013), and healthcare (Daniels, 2001), thereby significantly improving the efficiency of production and life.\nAlthough general-purpose large language models (LLMs) have demonstrated astonishing performance, these models often perform poorly in vertical domain tasks, facing challenges such as generating nonspecific content (Pillitteri et al., 2012),"}, {"title": "Related Works", "content": "The cognitive characteristics of achieving adversarial learning through classification and comparison are not rare in nature, such as in primates (Firestone, 2020), cetaceans (Connor & Mann, 2006), and humans(Firestone, 2020). With the significant progress made by Wang in introducing adversarial learning into the field of computer science (Wang et al., 2017), there has now been a wealth of exploratory practices in research on adversarial sample learning. In the area of computer vision, adversarial learning has primarily been used to enhance model robustness against adversarial attacks. For instance, Goyal introduced adversarial training as a defense mechanism, where models are trained on adversarial examples to improve their robustness (Goyal et al., 2023). Meanwhile, Goyal's framework has been extended to improve generative tasks, such as image synthesis and style transfer, leveraging frameworks like Generative Adversarial Networks (GANs) (Goodfellow et al., 2020). For example, Su demonstrated the utility of adversarial examples in domain adaptation tasks (Su et al., 2020), and the result indicates that such method enables models to generalize better across diverse datasets. Adversarial learning has also been widely adopted in natural language processing (NLP) tasks. For example, Zhang explored adversarial attacks to reveal vulnerabilities in text classification models and achieved great performance (W. E. Zhang et al., 2020). Beyond attacks, adversarial learning has been employed to improve the generalization and robustness of NLP models. For instance, adversarial data augmentation has been utilized to train models that are less sensitive to noise in input text. Moreover, adversarial robust methods have been developed to mitigate biases in text generation and sentiment analysis tasks, as Textbugger proposed by Li et al. had demonstrated great performance on text generation tasks.\nWith the widespread application of Large Language Models (LLMs), some studies have indicated that LLMs possess the potential to pass the Turing Test (Sejnowski, 2023). Even more optimistically, certain research suggests that LLMs have, to a certain extent, already passed the Turing Test (Sejnowski, 2023). However, the current cognitive level of LLMs still lags significantly behind that of humans and has considerable room for improvement. Therefore, many studies explore the differences between AI and humans, hoping to conduct comparative research through these differences to promote the development of AI (Djeffal et al., 2022). Existing studies have sought to compare AI and human information processing from a cognitive science perspective and obtain valuable insights. For instance, recent work has focused on the discrepancies between LLMs and humans in reasoning tasks, particularly in commonsense reasoning and contextual understanding. These studies often design adversarial datasets or specific cognitive tasks to evaluate the logical consistency and generalization capabilities of LLMs (Gu et al., 2024; Ying et al., 2023). Such comparative research not only highlights the weaknesses of AI models but also offers guidance for their optimization (Surianarayanan et al., 2023).\nSecond, some research efforts have drawn inspiration from human learning mechanisms to enhance AI models. Techniques like meta-learning and analogy-based reasoning have been applied to improve the performance of LLMs in few-shot learning tasks (Yuan et al., 2023). Humans' ability to reason by analogy has inspired researchers to integrate this cognitive trait into LLMs, significantly boosting their performance in low-resource or unfamiliar domains (P. Guo et al., 2024). Additionally, other work has focused on addressing the differences between AI and humans in handling ambiguity and uncertainty, leading to the development of more robust model architectures (Chander et al., 2024). Overall, these works demonstrate that leveraging insights from the differences between AI and humans can not only drive the advancement of AI models but also enhance their value in real-world applications. This research builds upon this foundation by introducing a bidirectional improvement mechanism inspired by generative adversarial networks (GANs), simulating \u201cmutual learning\" between AI and humans to optimize the generation capabilities of the model."}, {"title": "Method", "content": "To achieve high-quality text summarization tasks, we mimic the classification and comparison features in the human learning process to construct ChallengeMe, an adversarial prompt-driven text summarization framework. Unlike existing prompt schemes, this framework adopts a multi-round optimization strategy to enhance the consistency and fluency of the output content. The proposed framework consists of three modules, namely input prompts, adversarial prompts, and feedback optimization strategies, as shown in the figure below."}, {"title": "Framework", "content": "This paper proposes a generation framework based on adversarial prompts. The core idea of the framework is to guide the LLM to follow specific goals and constraints during text summarization by designing appropriate prompts. First, the model needs to accept the input text:"}, {"title": null, "content": "T_{in} = t_1, t_2,...,t_n (1a)\nwhere $t_i$ represents the i-th word in the text, and the text length is n. The prompt part guides the model through explicit task requirements. On this basis, we define the summarization target as:"}, {"title": null, "content": "Prompt target (2a)\n\"Summarize the following text to highlight key points:\"\nThis prompt statement clearly instructs the model to extract key information from the text for summarization. In addition, to ensure that the generated summary is concise, we add a summary length constraint to the prompt, setting the maximum number of words in the summary to Lmax:"}, {"title": null, "content": "Promptlength = (3a)\n\"The summary should not exceed \"\nFurthermore, this study sets a language style constraint for the model-generated text, and in this paper, the target style is a concise and formal language style:"}, {"title": null, "content": "Prompt length = (4a)\n\u201cThe summary should not exceed $L_{max}$words.\"\nThe final generated prompt is as follows:"}, {"title": null, "content": "Prompt = Prompt_{target} + Prompt_{length}+Prompt_{style} (5a)\nUnder this prompt framework, the model generates the summary Sout based on the input text Tin and the prompt. The specific generation process can be represented as:"}, {"title": null, "content": "S_{out} = g(f(T_{in}), Prompt) (6a)\nwhere f (Tin represents the encoding of the input text Tin by the model, and the obtained representation is used to guide the decoder to generate the summary, while g() is the generation process of the decoder."}, {"title": null, "content": "To ensure the quality of the generated summaries, this paper designs a prompt detector to evaluate from multiple dimensions: Consistency, Coherence, Relevance, Fluency, Readability, Naturalness, and Factuality, with the score range for each evaluation dimension being 1 to 10. For fluency, this paper defines it as F fluency, which is used to assess whether the language of the generated text is natural and smooth. The fluency score is calculated by the following formula:"}, {"title": null, "content": "F_{fluency} = \\frac{1}{m} \\sum_{i=1}^{m} fluency(S_{out_i}) (7a)\nwhere $S_{out_i}$ represents the i-th sentence in the summary, fluency($S_{out_i}$) is the fluency score of that sentence, and m is the number of sentences in the summary.\nFor Consistency, this paper defines it as $F_{consistency}$, which is used to assess whether the summary accurately reflects the"}, {"title": null, "content": "key information of the original text. The consistency score is calculated by comparing the overlap between the generated summary and the original text, with the formula being:"}, {"title": null, "content": "F_{consistency} = \\frac{S_{out} \\cap T_{in}}{|T_{in}|} (8a)\nwhere $|S_{out} \\cap T_{in}|$ is the number of overlapping words between the generated summary and the input text, and $|T_{in}|$ is the total number of words in the original text.\nFor language Naturalness, this paper defines it as $F_{naturalness}$, which is used to assess whether the language expression of the generated summary is concise and elegant. Its score calculation formula is:"}, {"title": null, "content": "F_{naturalness} = \\frac{1}{m} \\sum_{i=1}^{m} naturalness(S_{out}) (9a)\nwhere naturalness(Souti) is the naturalness score of the i-th sentence, and m is the number of sentences in the summary.\nTo determine whether the generated summary meets the requirements, the detection model will give scores according to the above three dimensions. Let the scores for each dimension be F fluency, Fconsistency, and Fnaturalness, the detection model will give a score for each dimension, with the score range being 1 to 10. Only when the scores for all evaluation dimensions meet the minimum threshold will the output of the generation model be accepted as a valid summary. Specifically, assuming that the threshold for each dimension is Tmin=7, the output Sout of the generation model will only be accepted under the following conditions:"}, {"title": null, "content": "F_{fluency} \\geq T_{min}, F_{consistency} \\geq T_{min}, F_{naturalness} \\geq T_{min} (10a)"}, {"title": "Feedback Optimization Strategy", "content": "To further enhance the quality of the generated summaries, we have designed an adaptive feedback optimization strategy. When the detection model evaluates the output of the generation model, if the score in a certain dimension does not reach the preset minimum threshold, the generation model will adjust itself based on the feedback to optimize the generation process. This section takes the parameter control of three dimensions: fluency, consistency, and naturalness as examples to conduct analysis:"}, {"title": null, "content": "If the fluency score $F_{fluency}$ is lower than 7, the generation model will receive feedback prompts to improve the sentence structure of the summary, making it more natural and fluent:"}, {"title": null, "content": "Prompt fluency (11a)\n\"Rewrite the summary with more natural sentence structures.\""}, {"title": null, "content": "If the consistency score $F_{consistency}$ is lower than 7, the generation model will be prompted to increase the coverage of key information to ensure the summary is more accurate:"}, {"title": null, "content": "Prompt consistency (12a)\n\"Ensure all key points are included in the summary.\""}, {"title": null, "content": "If the language naturalness score Fnaturalness is lower than 7, the generation model will be prompted to optimize the language style to make the summary more concise and elegant:"}, {"title": null, "content": "Prompt naturalness = (13a)\n\"Make the language more naturalness and concise.\"\nSpecifically, assuming ASout is the adjustment of the summary generation process by the generation model after receiving feedback, the optimized output can be represented as:"}, {"title": null, "content": "S_{out}^{new} = S_{out} + \\Delta S_{out} (14a)\nWhen the scores in all evaluation dimensions reach the minimum threshold, the final output content is generated."}, {"title": "Formation of Prompts", "content": "As shown in Figure 2, the prompt provided to the generation model (LLMgen) includes a scenario description, an SAP prompt, a list of actions, and an example plan. The SAP prompt aims to elicit complex reasoning by encouraging the model to thoroughly consider the different needs and potential interactions between people, animals, and objects. By explicitly prompting the model to infer the needs of other entities and predict how the situation might dynamically evolve, the prompt promotes empathy and holistic thinking, which are crucial for designing comprehensive plans. This one-time example illustrates the required plan structure in code format without providing solutions specific to the evaluation scenario. In contrast, the prompt for the evaluation model (LLMeval) includes an FSM plan generated by LLMgen, a benchmark high-quality plan, and a description of the scoring criteria for assessing plan quality through iterative improvement (see Appendix Figure 17). Initially, the benchmark plan includes manually written solutions, but in subsequent iterations, they include the highest-scoring automatically generated plans from the previous round."}, {"title": "Results", "content": "During the experimental process, we utilized the Win/Mac operating systems and deployed/tested the prototype on Pycharm version 13.2. The study selected GPT-40, Zhipu AI, Claude, Doubao, and Mistral-7b as baselines for comparative research with ChallengeMe. The aforementioned baselines are widely used general large models, and their performance"}, {"title": "Ablation Evaluation", "content": "To verify the rationality of the proposed framework and the effectiveness of the synergistic effect, we conducted ablation experiments for research. The discrimination threshold was set to 8.0-8.8 respectively, and experiments were carried out with a step length of 0.2 to verify the output performance of the model, and the results shown in the following table were obtained. It is not difficult to see from it that with the continuous increase of the threshold, the performance of the model gradually increases, and when the discrimination threshold exceeds 8.8, the performance of the output content tends to be stable, which indicates that the threshold (8.8) set by this solution can reduce the resource consumption on the basis of ensuring the quality of the output content."}, {"title": "Qualitative Evaluation", "content": "To further evaluate the superiority of the proposed solution, we invited 19 human subjects to conduct qualitative assessments. Specifically, we used a 7-point Likert scale to evaluate the quality of text summaries generated by the frameworks under the guidance of Doubao, GPT, Claude, Zhipu, Mistral-7b, and ChallengeMe on the arXiv Summarization Dataset, BillSum, and CNN/Daily Mail datasets. The higher the score, the higher the quality of the generated text. The experimental results are shown in the table below."}, {"title": "Discussion and Conclusion", "content": "With the rapid development of AI, the relationship between humans and AI has become increasingly close. However, existing research indicates that there are differences between A\u0399 and humans in understanding the real world and cognitive behavior (Konar, 2018). Human cognition is a complex and dynamic process involving multiple aspects such as perception, memory, emotion, and logical reasoning, and its cognitive abilities are formed through long-term biological evolution and individual experience accumulation. When facing problems, humans can flexibly use intuition, emotion, and past experiences to make judgments and decisions, and this cognitive style has high adaptability and flexibility. For example, when facing complex social situations, humans can make appropriate responses based on the perception and understanding of others' emotions. The cognitive behavior of AI large models mainly depends on the data they are trained on and the algorithms. By learning from a vast amount of data, they establish complex pattern recognition and prediction capabilities. Al demonstrates extremely high efficiency and accuracy in processing data and performing tasks, but when facing situations beyond its training scope, it often encounters difficulties in understanding and adaptation.\nBy comparing the cognitive patterns of humans and AI, and examining their similarities and differences, such as the flexibility and adaptability of human cognition, albeit with relatively lower efficiency; while AI excels in efficiency and accuracy, but lacks the flexibility and emotional understanding"}, {"title": "Exploring AI Optimization Strategies through Cognitive Mechanisms", "content": "In the exploration of AI optimization solutions, adversarial learning has become one of the key research directions. From the perspective of cognitive mechanisms, the human thinking process has a high degree of flexibility and creativity, and can make inferences and innovations based on limited data and experience. In contrast, the cognitive behavior of AI large models mainly relies on data-driven statistical learning, lacking the reasoning ability of humans based on theories and hypotheses. This difference provides important insights for A\u0399 optimization: by simulating an adversarial environment, AI models can enhance their robustness and adaptability in the process of continuous challenge and being challenged. By exploiting the model's own weaknesses to generate adversarial samples, it helps the model learn more comprehensive and complex feature representations. Adversarial learning provides new ideas for the performance improvement of AI models. By simulating human adaptability and creativity, AI can demonstrate stronger robustness and flexibility in complex environments. Future research should further combine the advantages of human cognition to develop more innovative and interpretable AI systems."}, {"title": "Limitations & Futurework", "content": "Despite the valuable conclusions and findings obtained from the experiments, this study still has certain limitations. First, the case studies in the experiments focused on the text summarization task. Although comparative studies were conducted on multiple datasets and AI models, research on more tasks will further enhance the reliability of the research conclusions. In addition, during the experimental process, we selected the 4th generation models (based on the GPT series as the standard) for comparative studies. This is because they represent the most advanced large model solutions currently available. However, with the continuous iteration of technology, research on larger-scale parameters and more modal tasks will further increase value. Moreover, in future research, conducting studies with a larger number of participants and exploring variables that potentially affect cognitive levels, such as gender and age, will help further explore the similarities and differences between AI and humans and obtain inspiring insights, thereby constructing more advanced models."}, {"title": "Conclusion", "content": "Inspired by contrastive learning, this paper constructs an adversarial prompt framework named ChallengeMe, to tackle the limitations of large language models in content generation, such as hallucination and non-specific content. By conducting analysis using text summarization tasks as case studies, we compared the proposed framework's performance with current advanced large language models in three public text summarization datasets, and verifying the advancement and superiority of the proposed framework through quantitative, qualitative, and ablation experiments. The results and findings reveals potential ideas for the future evolution of large models."}]}