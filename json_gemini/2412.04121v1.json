{"title": "DeepFEA: Deep Learning for Prediction of Transient Finite Element Analysis Solutions", "authors": ["Georgios Triantafyllou", "Panagiotis G. Kalozoumis", "George Dimas", "Dimitris K. Iakovidis"], "abstract": "Finite Element Analysis (FEA) enables the simulation of physical phenomena under various conditions. This is usually a computationally expensive and time-consuming process since it involves the numerical solution of partial differential equations. To accelerate FEA, effective surrogate methods based on Artificial Neural Networks (ANNs) have been recently proposed. However, these methods still have several limitations, mainly with respect to the dynamic prediction of accurate solutions independently from the original finite element model and/or respective ground truth data. This study proposes a deep learning-based framework for FEA (DeepFEA) that copes with these limitations. It is based on a novel ANN architecture composed of a multilayer Convolutional Long Short-Term Memory (ConvLSTM) network branching into two parallel convolutional neural networks with tensor outputs used to infer predictions related to the nodes and elements of FEA models. The architecture of the proposed network is optimized using a novel adaptive learning algorithm, called Node-Element Loss Optimization (NELO), which minimizes the error occurring at both of its branches. DeepFEA relies only on the initial and boundary conditions, as well as the external load of the modeled structure, which are provided as input to predict the transient solutions of an entire FEA simulation. The experimental evaluation of DeepFEA is performed on three datasets in the context of structural mechanics, generated to serve as publicly available reference datasets. The results indicate that it can accurately predict the outcome of multi-timestep FEA simulations, while offering a significant solution acceleration of at least two orders of magnitude.", "sections": [{"title": "1 Introduction", "content": "Physical phenomena can often be described by a system of equations, such as Partial Differential Equations (PDEs) or Ordinary Differential Equations (ODEs). PDEs are equations containing partial derivatives that encapsulate physical quantities of natural processes. The solution of these equations is provided by a function, the exact solution of which cannot be analytically calculated or is not unique. In research fields, such as mechanical and biomedical engineering, the behavior of objects that are subject to a system of PDEs is simulated via computational modeling tools that are able to solve these PDEs in a computationally efficient way. Finite Element Analysis (FEA) is often used to divide such objects into a finite number of discrete elements and nodes, enabling dedicated FEA software to solve the PDEs in a more efficient manner [1].\nFEA-based simulations rely on iteratively solving PDEs that correspond to specific physical models. Usually, the duration of the problem to be simulated needs to be discretized into a number of timesteps; a large number of timesteps results in a solution of a higher resolution in the time domain and it usually entails a higher computational cost. At each timestep, FEA relies on the predictions of the previous state to predict the solution for the current state. These simulations can also become computationally expensive as the order of the PDEs and the density of the mesh increase. Reduced-order modelling (ROM) and surrogate models have been considered to address this problem. ROM solutions are mostly employed to reduce the dimensionality of high-order models [2\u20134], while surrogate models are used to replace FEA. Traditional ROM methods, e.g., the proper orthogonal decomposition method and the principal component analysis method [5], are constrained by their linear nature; thus, Al-based solutions, such as Artificial Neural Networks (ANNs) that include Multilayer Perceptrons"}, {"title": "2 Methods", "content": "DeepFEA is a deep learning framework, which, given a set of initialization parameters of a FEA simulation, can be used to simultaneously predict node- and element-related output parameters of the FEA after multiple timesteps. The core component of DeepFEA is a novel network architecture, which is trainable. The network can provide very accurate predictions after being trained with NELO, which is a novel training algorithm especially designed to minimize the error in transient FEA simulations. An overview of the proposed framework, comprising three stages, namely, the dataset generation phase (Fig. 1a), training phase (Fig. 1b) and testing phase (Fig. 1c), is presented in Fig. 1."}, {"title": "2.1 Node-Element-based Network Architecture", "content": "The Node-Element Prediction (NEP) network architecture of DeepFEA consists of two modules, a Feature Extraction Module (FExM) and a Prediction Module (PM). FExM is implemented using a multilayer ConvLSTM network, which receives as input the FEA model characteristics and the initialization parameters for the FEA in the form of a tensor. FExM is tasked to automatically extract spatiotemporal features in the form of multiple feature maps extracted over consecutive timesteps. More specifically, the feature maps encode spatial information regarding the nodes and elements of the FEA model along with the respective physical properties considered in the FEA simulation. This information is propagated through each layer of the ConvLSTM network, allowing it to progressively extract complex spatial and physics-related information of the simulation in various degrees of abstraction. The output of the final ConvLSTM layer encapsulates the overall spatial structure of the mesh, the information retained from previous timesteps, as well as extracted information about the physics of the simulation, serving as a high-level representation of the FEA simulation. Given a set of extracted features by FEXM, PM predicts the output parameters of the simulation. PM comprises two parallel CNN branches, producing two output tensors that follow the structure of the input tensor. These output tensors have different dimensions corresponding to the node- and element-related parts of the FE mesh."}, {"title": "2.1.1 Input and Output Tensors", "content": "The geometry of the structure to be analyzed with FEA is first discretized into a digital representation, called FE mesh, which is composed of a finite number of nodes (discretized points) and elements (area or volume that connects the nodes of the mesh). Each node and element of the mesh stores information related to the FEA model, e.g., coordinates or stress/strain in each node or element, respectively. The FEA model is created by specifying a mesh structure, the initial conditions, the boundary conditions, and the externally applied load. In this study, the coordinates of the mesh are considered as the initial conditions, the positions of the constrained nodes as the boundary conditions, and the forces applied on the outer nodes as the externally applied load. A FEA simulation is tasked to predict the output parameters for each node and element of the mesh based on the initial conditions corresponding to each node, external load, and boundary conditions.\nIn Fig. 2, the input tensor size is H\u00d7W\u00d7L, where H, W, and L denote the height, width, and length of each input feature map, respectively, whereas M denotes the number of the different parameters considered for solving a specific problem. For a 3D mesh, H\u00d7W\u00d7L correspond to the dimensions of the input mesh. The notation He\u00d7We\u00d7Le refers to the dimensions of a tensor that contains information regarding the elements of the mesh. In the 2D mesh case, only the height and the width of the mesh are considered, i.e., H and W. The output tensor of the node branch is of shape H\u00d7W\u00d7Kn or H\u00d7W\u00d7L\u00d7K for 2D and 3D models, respectively. In this paper, the 2D and 3D FEA models are meshed with quadrilateral and hexahedral elements, respectively. Hence, the output tensor of the element branch is of shape He \u00d7We\u00d7Ke for 2D or He\u00d7We\u00d7Le\u00d7Ke for 3D FEA models, with He = H-1, We = W-1, and Le = L-1. Variables Kn and Ke denote the number of different output targets estimated by the dedicated node and element branches, respectively, e.g., displacement across the x-axis, displacement across the y-axis, etc. For example, considering the input referring to the position of each node for a 2D FE mesh, i.e., a pair of x and y coordinates, the information of the x and y coordinates is structured into two different matrices, as illustrated in Fig. 3. In contrast to traditional CNN-based frameworks that employ padding techniques to accommodate structural changes in the input tensor, DeepFEA utilizes the FE mesh coordinates as input features. This approach enables the prediction of FEA solutions whilst the structure of the mesh changes due to deformation."}, {"title": "2.1.2 Feature Extraction Module", "content": "The FExM utilizes r ConvLSTM layers, each responsible for extracting important spatiotemporal features of the FEA model that are identified by its kernels. Contrary to traditional CNN-"}, {"title": "2.1.3 Prediction Module", "content": "PM utilizes two CNN branches in a parallel topology. Each CNN branch comprises one or more CNN layers; in this study, one CNN layer is utilized for each branch. One branch is used to map the extracted feature maps to node tensors and the other is used to map the extracted feature maps to output tensors representing the elements of the FEA model. Furthermore, the CNN layers of each PM branch utilize the same kernel dimensions as the ConvLSTM layers of the FExM. Each branch is dedicated to predicting node- and element-related parameters. The distinction between the branches dedicated to node- and element-related predictions is mandatory, since they refer to outputs that are represented by tensors of different sizes. Therefore, for a 3D FEA model with hexahedral elements, the CNN layer of the node branch would utilize a 1\u00d71\u00d71\u00d7Kn kernel, whereas that of the element branch would utilize a 2\u00d72\u00d72\u00d7Ke kernel, with Kn and Ke denoting the number of output features for each branch, respectively.\nThe activation function of the CNN layers of each branch is determined by the data normalization process. For instance, if the input data are normalized within the interval of [-1, 1], then the hyperbolic tangent (tanh) can be considered as an appropriate activation function for each output layer of each branch. This is a requirement for DeepFEA, since the output of the NEP network at the timestep t is used as input for the next timestep t+1."}, {"title": "2.2 Training Phase", "content": "The NEP network is trained using data generated from conventional FEA simulations, i.e., using commercial or in-house software to simulate the behavior of a structure under different conditions, e.g., applying forces with different magnitudes and angles on a structure of a given material. The training dataset contains representative FEA simulations of the examined model that will enable the NEP network to learn the examined behavior without being trained on the whole spectrum of possible FEA simulations. Subsequently, the trained NEP network can be used to predict the solutions for new FEA simulations of the examined FEA model with varying conditions, such as external load applied at different nodes of the mesh. Furthermore, the training phase relies on a NELO algorithm to address the error accumulation problem that occurs through the traditional training approach of deep learning models and a novel additive loss function to account for both node- and element-related errors produced by the NEP network."}, {"title": "2.2.1 Node-Element Loss Optimization Algorithm", "content": "The NELO algorithm is inspired by the SSM, which is an NLP technique used for the training of sequence-to-sequence models such as RNNs. These models generate an output text sequence (e.g., a translation or a text prediction) based on an input sequence (e.g., a source sentence). During training, the model uses the ground truth tokens (words or characters) at each step to predict the next token. However, during inference (generation of output sequences), the model uses its own predictions as inputs, which may lead to errors accumulating over time, similar to surrogate models of transient FEA simulations. Therefore, the NELO algorithm adopts a SSM optimization approach adapted to the domain of transient FEA simulations and tackles the error accumulation problem by gradually transitioning from using ground truth data to using model predictions as inputs during training. The NELO algorithm can be described as follows:"}, {"title": "2.2.2 Node-Element Loss Function", "content": "Considering the nature of the PM in the NEP network, the error of both the node and element branch need to be incorporated in the same loss function. Hence, a novel additive loss function, hereinafter called Node-Element (NE) loss, is devised. The formulation of the NE loss is inspired by the Mean Squared Error (MSE) metric; thus, it places greater emphasis on larger errors, accommodating discrepancies across the entire value spectrum of the output parameters and the squaring effect balances the impact of outliers, proving beneficial for handling noisy or irregularly distributed FEA simulation data [6]. The NE loss function employed in this study can be described as follows:\n$L_{total} = \\zeta_n \\cdot \\frac{\\sum_{t=1}^{T} \\sum_{n=1}^{N} (y_{nt} - \\hat{y}_{nt})^2}{T \\cdot N} + \\zeta_e \\cdot \\frac{\\sum_{t=1}^{T} \\sum_{e=1}^{E} (y_{et} - \\hat{y}_{et})^2}{T \\cdot E}$", "latex": true}, {"title": "3 Experiments and Results", "content": "For the purposes of this study, three different datasets of FEA simulations that predict the deformation of an object under different conditions were considered. In detail, two 2D model datasets utilizing material models with linear elastic (LEM) and hyperelastic (HM) characteristics, as well as one 3D LEM dataset were developed. The objects in each dataset were subjected to an external load applied at different outer nodes of the mesh under different angles and magnitudes over a period of 1 s. The software utilized for the generation of the datasets was ANSYS LS-DYNA. The outputs of all simulations were recorded every 5 ms, resulting in datasets comprising 200 datapoints, i.e., 200 timesteps. The generated meshes contained 9\u00d79 nodes and 64 elements for the 2D cases and 9\u00d79\u00d73 nodes and 128 elements for the 3D case. The force was randomly applied on one external node of each mesh and was linearly increased until the end of the simulation. The force was applied at four different angles {0\u00b0, 45\u00b0, 90\u00b0, 135\u00b0} and three different maximum force magnitudes were considered {5\u00d7105, 106, 2\u00d7106} N. The non-constrained nodes of the 2D and 3D meshes had 4- and 6-Degrees-Of-Freedom (DOFs), respectively. The bottom nodes of the meshes were set as constrained. The LEM and HM had a mass density of 1200 kg/m\u00b3 each. The Young's modulus and Poison ratio of LEM were 5\u00d7106 Pa and 0.495, respectively. Regarding HM, the Ogden model was adopted with a Poisson's ratio, first shear modulus, and first exponent parameters of 0.495, 5.978\u00d7104 Pa, and 12.97, respectively. At each timestep, FEA was tasked to predict the deformation, i.e., node displacement, and the effective stress and strain of the objects. This resulted in generating three different datasets containing 450 2D LEM, 450 2D HM, and 2,256 3D LEM simulation cases."}, {"title": "3.2 Evaluation metrics", "content": "To quantify the effectiveness of DeepFEA, the R\u00b2 metric, known as coefficient of determination, has been selected, since it is widely used for the evaluation of regression models [43]. R\u00b2 is a statistical measure that indicates the goodness of fit of a regression model, i.e., how well the model's predictions align with the ground truth values. R\u00b2 is usually confined in the [0,1] interval, where 1 indicates that the predictions of a model perfectly fit the ground truth data, whereas 0 indicates a baseline model that always predicts the mean of the ground truth data. R\u00b2 can take negative values in cases where the model is worse than the baseline model. R\u00b2 is defined as:\n$R^2 = 1- \\frac{\\sum_j(y_j - \\hat{y}_j)^2}{\\sum_j(y_j - \\overline{y})^2}$", "latex": true}, {"title": "3.3 Experimental Setup", "content": "The performance of the method was evaluated in the context of predicting the effective stresses and strains and the displacement (dx, dy, dz) in each Cartesian axis (x, y, and z (for 3D)). The displacements predicted for each axis were also utilized to calculate the resultant displacement (Ra) of the nodes. An ablation study was conducted based on the 2D LEM dataset to determine the best combination of layers and channels using a 3\u00d73 kernel size for the convolutional layers. The best architecture was selected based on the quantitative evaluation metrics. Subsequently, the selected architecture was used to demonstrate the capabilities of DeepFEA across a variety of FEA simulation scenarios. More specifically, DeepFEA was trained on the 2D LEM, 3D LEM, and 2D HM datasets, and the results were assessed both quantitatively and qualitatively.\nTo evaluate the performance of DeepFEA, the datasets were divided into training and testing subsets with proportions of 80% and 20%, respectively. The networks for the 2D and 3D FEA simulation predictions were trained with a batch size of 32 and 16, respectively. The optimizer used in the experiments was the Adam optimizer with a variable learning rate associated with the value of the NELO factor Ps. The scaling factors (n and \u00c7e of the loss function were set to 104. Moreover, the y factor of the NELO algorithm was set to 0.7, \u03b2p was set to 0.01, and the Ps was reduced every 40 epochs. The model was implemented using the PyTorch v1.12 framework [44] and it was trained with a GeForce RTX 3090 24GB."}, {"title": "3.4 Ablation study", "content": "An ablation study was conducted to identify the best architecture through extensive experimentation. DeepFEA was trained on a subset of the 2D LEM dataset with different numbers of layers of varying channel sizes, whereas the kernel size was kept constant to 3\u00d73. As it can be seen in Table 1, the overall best model comprised three ConvLSTM layers with 64, 128, and 256 channels. It can be observed that DeepFEA can consistently predict the effective stress and strain of the FEA simulations with great accuracy across all timesteps, with the best model achieving an R\u00b2 of ~0.99. It is worth noting that, according to the results presented in Table 1, the node displacement prediction is a more complex task and thus the utilization of a network with higher complexity benefits the overall performance.\nNevertheless, based on the same results, it can be observed that an architecture with more layers is not necessarily beneficial for the performance of the method, i.e., the three layer variant outperforms the four layer ones."}, {"title": "3.5 2D Datasets (shell elements)", "content": "Based on the results of the ablation study, the model with the best architecture using 80% of the dataset was used for the quantitative and qualitative evaluation of the method. The results in Table 2 indicate that DeepFEA was able to predict all the parameters with great accuracy, exhibiting great consistency throughout the simulation (R2 > 0.95). The values of d\u2081 were predicted with less accuracy compared to those of dy, which can be attributed to the wider displacement range in the x-axis. Although the predictions for Ra were similar to those for dy, the normalized errors were higher due to the increased error in the x-axis.\nTo qualitatively evaluate the predictions of DeepFEA, three simulation cases were randomly selected from the dataset. Figure 8 presents representative snapshots (five timesteps) of the output parameters (deformation, strain, and stress evolution) predicted for each simulation case."}, {"title": "3.5.2 HM Dataset", "content": "DeepFEA was also tasked to predict the solutions of simulation cases from the 2D HM dataset. The quantitative results in Table 3 further validate the ability of DeepFEA to accurately predict the simulation outcome of FEA models with non-linear material properties. Notably, the predicted displacement was on par with the results in Table 2, with the only exception that the normalized errors"}, {"title": "3.6 3D LEM Dataset (solid elements)", "content": "To assess the capability of the proposed method in the 3D domain, DeepFEA was also evaluated on the 3D LEM dataset. The quantitative evaluation is summarized in Table 4. Despite the increased complexity of the problem due to the additional DOFs, DeepFEA was able to accurately predict o and \u025b, with R2 = ~0.99, NMAE = ~0.49%, and NRMSE = ~0.78%. DeepFEA inferred the resultant displacement of the nodes with high accuracy. Notably, the predicted dy was less accurate in terms of R2 compared to the other displacement axes, while the normalized errors were comparable. In addition, the predicted Ra demonstrated a closer alignment with the ground truth for all metrics. Thus, it can be inferred that, while the predicted displacement along a specific axis might deviate from the ground truth, DeepFEA can accurately capture the resultant deformation.\nFigure 10 illustrates representative snapshots (five timesteps) of the predicted output parameters (deformation, strain, and stress evolution) of three simulation cases that were randomly selected from the dataset. In the first case, a compression force was applied on an outer node of the mesh with magnitude of 10\u00b0 N, and angle of 0\u00b0 relative to the z-axis. In the second case, a compression force was applied with a magnitude of 106 N and angle of 135\u00b0 with respect to the x- and y-axis. In the third case, a compression force was applied with a magnitude of 5\u00d7105 N and angle of 0\u00b0 with respect to the x-axis."}, {"title": "3.7 Inference Time", "content": "The results have demonstrated the performance of DeepFEA in terms of accuracy. Hence, a comparative analysis of the average CPU- and GPU-enabled inference times of DeepFEA and the CPU-enabled data generation time of FEA for each experimental scenario was conducted (Table 5). The resulted average inference times were obtained on a computer system with an Intel(R) Core(TM) i7-9750H CPU at 2.60GHz, a GeForce RTX 3090 24GB, and a 16 GB RAM. As regards the 2D datasets, DeepFEA could predict the solution of a FEA simulation in 0.20 s and 2.35 s on average using a GPU and CPU, respectively, whereas FEA needed 24 s. As regards the 3D LEM dataset, the inference time of DeepFEA for one simulation was 0.23 s (GPU) and 15.30 s (CPU) on average, whereas FEA required 40 s. This indicates that under the same conditions and the utilization of a GPU, the proposed method is up to two orders of magnitude faster than FEA for the 2D and 3D scenarios. Furthermore, the average inference time of DeepFEA was consistent for both the 2D and 3D domains when a GPU was employed, in contrast to the average solution time of FEA that exhibited a two-fold increase."}, {"title": "4 Discussion", "content": "In this study, a novel deep learning surrogate model for transient FEA simulations has been proposed. FEA-related studies have focused on surrogate models for steady-state analysis [2, 7, 16, 19\u201322, 24]. Nevertheless, there have been only few early studies on surrogate models that are aimed for transient FEA simulations and have provided insight into the current progress and limitations [12, 30-33, 36, 39]. Limitations of these approaches include failure to account for spatiotemporal features, applicability limited to the 2D domain, and dependency on FEA for calculating part of the solution. To address these issues, DeepFEA was designed to predict the solutions of the entire transient FEA simulation given only the initial conditions, the external load, and the boundary conditions.\nMesh deformation is a crucial factor involved in structural mechanics [6, 12, 17, 19, 21, 39]. In transient FEA simulations, the deformation of the mesh depends on the predictions of the previous timesteps. Therefore, the core problem addressed by DeepFEA is the efficient prediction of RPs (here, node displacement). Related studies have proposed solutions for predicting such parameters, but are limited to the 2D domain and account for single-output predictions [36]. DeepFEA provides a framework that is capable of accurately predicting both RPs and NRPs of FEA simulations in the 2D and 3D domains. This is achieved by the implementation of a data-driven approach that incorporates the physical properties of the model in the input tensor (coordinates of the nodes, external load, and boundary conditions) and the utilization of the SSM training scheme. Thus, DeepFEA can be trained for FEA simulations with an arbitrary number of input and output parameters. In addition, DeepFEA is not limited to a specific problem, and, with proper adjustments, it can be applied to FEA models with various characteristics and properties."}, {"title": "5 Conclusions", "content": "This work presented a novel deep learning approach for predicting the solution of transient FEA simulations. DeepFEA is able to recurrently predict the output parameters for all timesteps in a simulation by utilizing a ConvLSTM-based network with two parallel convolutional branches and an NLP-inspired training scheme. To the best of our knowledge, this is the first time that the SSM training scheme has been used for predicting outputs of FEA simulations. The proposed method was evaluated in the domain of structural mechanics via 2D and 3D FEA models, as well as for two different material models (linear elastic and hyperelastic). The results indicated that DeepFEA can predict the evolution of the output parameters with great accuracy in all scenarios, being up to two orders of magnitude faster than FEA. The efficient inference time combined with the accurate predictive performance of DeepFEA in estimating solutions for FEA simulations across multiple timesteps underscores that, after training, it is able to predict the evolution of RPs and NRPs in a simulation without the assistance of FEA. DeepFEA can be trained to predict the solutions of several simulations involving models with varying boundary conditions and external loads, handle distorted meshes (caused by deformation), and adapt to different material models. Moreover, the ablation study showcased the potential of DeepFEA to accurately predict the solutions of FEA simulations when trained with fewer training samples. In addition, DeepFEA does not require the provision of pre-calculated or approximated internal loads. This achievement lays a robust foundation for future research in the field of transient FEA by utilizing similar approaches. Despite its advantages, DeepFEA can be trained to predict the solutions of transient FEA simulations for FEA models with the same mesh size and density. This limitation is due to the fixed dimensions of the weights in the ConvLSTM layers of the FExM. Thus, a different NEP network needs to be trained each time for FEA models with different mesh characteristics. Future studies will address this issue by enhancing the NEP network, enabling it to perform mesh-size independent predictions while minimizing the computational cost. Furthermore, the trade-off between accuracy and dataset generation time should be further investigated. Lastly, future research will focus on exploring the capabilities of DeepFEA in CFD and FSI simulations, as well as in real-life application scenarios."}, {"title": "CRedit authorship contribution statement", "content": "Georgios Triantafyllou: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Validation, Visualization, Writing-original draft. Panagiotis G. Kalozoumis: Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Resources, Software, Supervision, Validation, Visualization, Writing-original draft, Writing- review & editing. George Dimas: Conceptualization, Formal analysis, Investigation, Methodology, Resources, Software, Supervision, Validation, Writing-original draft, Writing- review & editing. Dimitris K. Iakovidis: Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Supervision, Validation, Writing- review & editing."}, {"title": "Declaration of competing interest", "content": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."}, {"title": "Acknowledgements", "content": "This work has been funded by the European Union, under grant agreement No 101099145, project SoftReach, (https://softreach.eu/)."}]}