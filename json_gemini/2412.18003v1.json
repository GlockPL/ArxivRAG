{"title": "Integrated Learning and Optimization for Congestion Management and Profit Maximization in Real-Time Electricity Market", "authors": ["Imran Pervez", "Ricardo Pinto Lima", "Omar Knio"], "abstract": "We develop novel integrated learning and optimization (ILO) methodologies to solve economic dispatch (ED) and DC optimal power flow (DCOPF) problems for better economic operation. The optimization problem for ED is formulated with load being an unknown parameter while DCOPF consists of load and power transfer distribution factor (PTDF) matrix as unknown parameters. PTDF represents the incremental variations of real power on transmission lines which occur due to real power transfers between two regions. These values represent a linearized approximation of power flows over the transmission lines. We develop novel ILO formulations to solve post-hoc penalties in electricity market and line congestion problems using ED and DCOPF optimization formulations. Our proposed methodologies capture the real-time electricity market and line congestion behavior to train the regret function which eventually train unknown loads at different buses and line PTDF matrix to achieve the afore-mentioned post-hoc goals. The proposed methodology is compared to sequential learning and optimization (SLO) which train load and PTDF forecasts for accuracy rather than economic operation. Our experimentation prove the superiority of ILO in minimizing the post-hoc penalties in electricity markets and minimizing the line congestion thereby improving the economic operation with noticeable amount.", "sections": [{"title": "1. Introduction", "content": "The shift towards renewables comes with several additional challenges like system operation challenges (high rate of change of frequency (RoCoF), netload (demand - renewable generation) below base load, and violation of system ramping requirements), non-dispatchibility due to high-variability, forecasting challenges due to unpredictability, and reduced revenue recovery (market price - production price) of conventional generators leading to significantly high production prices during peak or mid-peak hours. In addition to renewable-related challenges, the load demand also exhibits unpredictability issues (eg., electric vehicles (EVs) may bring additional variability/uncertainty).\n\nThe above-mentioned challenges need to be tackled for an economic and reliable operation of power systems. At the heart of economic and reliable power systems operations lies economic dispatch (ED) and DC optimal power flow (DCOPF) optimization problem formulations which generates power-dispatching decisions based on various forecasts like renewable generation, load demand, power transfer distribution factor (PTDF), etc.\n\nThe ED/DCOPF follow learning and optimization (LO) pipeline. In LO, the learning phase learns/trains unknown parameters like renewable and load forecasts in the ED/DCOPF optimization model. The ED/DCOPF optimization problem using trained forecasts is then solved to generate decisions. The LO pipeline thus directly influence ED/DCOPF decisions and needs to be designed well for economic power system operations.\nOne of the crucial applications of power systems is the electricity market mechanisms that decide production and consumption schedules and their pricing. The electricity market operations are largely dependent on ED/DCOPF decisions which are based on different unknowns in the ED/DCOPF formulations. Inaccuracy in the forecasts of load, renewable and other unknowns in the optimization problem leads to incorrect dispatch decisions, which may significantly impact market operations and revenues. Thus, the LO pipeline must be designed to train forecasts/unknowns in the optimization problem setting to generate optimal ED decisions.\n\nThe LO pipelines in the literature are mainly classified as sequential learning and optimization (SLO) pipeline and integrated learning and optimization (ILO) pipelines as detailed in Section 2. The commonly used pipeline for power system problems is SLO which focuses on training accurate forecasts for use in optimization problems. In this work, we develop novel ILO formulations for electricity market applications.\n\nElectricity markets are of various types like day-ahead market (DAM), intraday market (IM), real-time market (RTM), etc. The current work mainly deals with DAM and RTM where the former involves scheduling market decisions prior to real-time operation and depends on different forecasts while the latter involves scheduling real-time market operations.\n\nSince the DAM or other future market transactions depend on weather, load and other forecasts, actual production and consumption is likely to deviate from market-cleared schedules in real-time resulting in a supply-demand imbalance, line congestion, etc. The deviation of actual generation and demand from baseline needs to be balanced in near to real-time or real-time to avoid user inconvenience, blackouts, etc.\n\nMOs and ISOs use smaller time-grid market mechanisms like the intraday market (IDM) and balancing market (BM) to balance supply and demand in near to real-time and real-time. The IDM and BM mechanisms solve ED/DCOPF problems in real-time to make purchasing/selling decisions for electricity from different market traders willing to generate/consume extra to ramp up/down the total system power for total supply and demand balancing and line congestion improvement.\n\nDeviations from nominations come at higher prices thereby reducing market participant's overall revenue. Consequently, inaccuracies in forecasts will result in reduced total revenue of market participants. The forecast models in the optimization setting needs to be trained to minimize the impact of deviations from nomination. The forecast models thus require decision focused training instead of accurate training. The decision focused training will train forecasts to produce optimization decisions favoring minimizing extra costs on market participants due to supply-demand imbalance and line congestion. The concept of decision focused training is such that two forecast models with equal errors with respect to target value, one trained for better decisions while another trained for accuracy, the optimization decisions using decisively trained forecast will pose lesser extra costs on market participants compared to the model trained for accuracy. This concept is further elaborated in Section 4.\n\nVarious supervised learning algorithms have been proposed in the literature for training forecasts in the ED/DCOPF optimization setting. In [1], the authors used a Levenberg-Marquardt back-propagation (LM-BP) neural network (NN) to improve the load prediction accuracy. This is achieved by combining the gradient descent and Quasi-Newton method to ensure faster speed, accuracy, and stability. The authors in [2] used auto-machine learning (auto-ML) for feature extraction and look-ahead window (prediction horizon) size selection for look-ahead (multi-time) load forecasting. They show that the overall forecasting accuracy can be improved by optimizing hyperparameter selection. The authors in [3] proposed a transfer learning- and temporal fusion transformer (TFT) approach to train prediction models for users and buildings with small load consumption data sets. The trained model provides significant improvement in accuracy compared to existing approaches despite less data availability.\n\nThe authors in [4] used a deep neural network with an unsupervised learning algorithm for feature extraction from the data. In [5], a deep convolutional neural network (DCNN) was proposed which uses convolutional layers and extra dense layers to generate accurate load forecasting accuracy. In [6], the authors proposed a hybrid algorithm that uses convolutional neural network (CNN) to establish the load trend learning capability and long short term memory (LSTM) to capture patterns from the time-series data. A Gaussian process (GP) based load forecasting method was proposed in [7]. The proposed GP regression model employs compositional kernels to deal with the high di-mensional data by giving weightage to the most important input features. Training with the most important features addresses high data dimensionality and enhances the overall prediction accuracy.\n\nThe authors in [8] proposed a homogeneous ensemble-based method (random forest (RF)) for load prediction. Moreover, the authors also analyzed the importance of different features in the dataset. The overall RF algorithm outperformed other algorithms in terms of accuracy. The authors in [9] used a gradient boosting (GB) algorithm which iteratively combines several weak models (less accurate) to obtain an additive model using numerical optimization that minimizes the loss function. The proposed method was found to improve the load forecasting accuracy. The authors in [10] proposed a vector field-based support vector regression method that maps a high-dimensional feature space using a vector field to find the optimal feature space The proposed algorithm improved the accuracy and robustness of the load prediction.\n\nThough the above-mentioned methods improved the prediction accuracy, none of them trained the forecasts to learn better decisions.\n\nIn this work, we propose to train forecasts to learn better decisions using an integrated learning and optimization (ILO) pipeline. This, unlike SLO, offers the possibility of solving power systems problems requiring better optimization decisions rather than better forecast accuracy (eg., electricity market problems).\n\nThe literature also includes stochastic optimization techniques where supervised learning methods are used to learn forecasts in the stochastic setting of ED/DCOPF models.\n\nThe authors in [11] used stochastic model predictive control (MPC) for distributed non-linear multi-objective ED which uses data-driven scenario generation using dynamic programming (DP) by including uncertainty realizations from energy price, availability of renewable resources, and demand. Another work in [12] used stochastic MPC using data-driven scenario generation with dynamic programming (DP) for centralized ED at different time horizons including uncertainty realizations from energy price, availability of renewable resources, and demand behavior.\n\nIn [13], the authors developed centralized stochastic MPC using Monte Carlo (MC) simulation and Roulette wheel mechanism (RWM) for a contingency-constrained demand response (DR) problem by including uncertainty realizations from the availability of renewable resources, and the demand behavior. The authors in [14] developed a centralized stochastic MPC using probability distribution functions (PDFs) for multi-objective ED with several different kinds of energy sources in a networked microgrid (MG), namely by including uncertainty realizations from the availability of renewable resources. In [15], the authors proposed a centralized stochastic MPC method using the Markov chain Monte Carlo (MCMC) method for a multi-objective DR problem by including uncertainty realizations from the availability of wind resources and consumer demand.\n\nThe authors in [16] proposed centralized stochastic economic MPC for non-linear ED with balance responsible parties (BRPs) using Monte Carlo for scenario generation by including uncertainty realizations from the availability of wind resources. The authors in [17] proposed a centralized stochastic economic hybrid with reference tracking (ERT) MPC with multi-objective ED formulation using sampling-based scenario generation by including uncertainty realizations from energy price, renewables, and demand. In [18], the authors proposed a stochastic ERT MPC for multi-objective ED using a sampling-based scenario generation approach by including uncertainty realizations from energy price and demand.\n\nThe authors in [19] proposed a centralized stochastic economic MPC for ED using Gaussian process (GP) regression for uncertainty propagation. In [20], the authors proposed a centralized stochastic economic MPC for non-linear multi-objective ED problem using scenario-based uncertainty propagation by including electricity prices, weather, and demand as uncertain variables.\n\nThe above-mentioned techniques used different stochastic MPC programming methods for various types of ED objectives. The application of stochastic MPC methods in all the above works outperformed the deterministic MPC and improved the ED optimum decision. However, the stochastic MPC and stochastic-robust MPC methods require significant computational efforts which may hamper their real-time use. Moreover, the stochastic methods are SLO-based and do not incorporate means to correct decisions so as to train the forecasts favouring better decisions.\n\nAs previously mentioned, in this work we propose to use an integrated learning and optimization (ILO) pipeline which focuses more on learning forecasts for better decisions rather than learning accurate forecasts. Moreover, the forecast after being trained is directly used for online decision-making using a deterministic setting rather than a stochastic approach which makes computationally complex online decision-making.\n\nThe application of ILO in different applications in the literature is scarce. In [26], the authors proposed a new regret function for ILO training, smart predict then optimize plus (SPO+). The authors used the SPO+ function to train the shortest path problem and compared it with SLO in terms of optimum decisions. The authors in [27] proposed an interior point (IP) algorithm-based gradient calculation for the ILO loss function and applied it to train the 0-1 knapsack problem, unit commitment, and shortest path problem. The above-mentioned works mainly used ILO to train unknown parameters in the objective function.\n\nThe authors in [28] proposed to train unknown parameters in the constraints using an IP-based gradient calculation of loss function. The authors proposed generic gradient formulations for two categories of linear programs (LPs), namely packing LP and covering LP. The authors applied their gradient formulation to train unknown parameters in the max flow transportation problem, alloy production problem, and fractional knapsack problem. In [29], the authors proposed an end-to-end wind power forecasting method to optimize the energy system by estimating wind forecasts to optimize decisions rather than wind forecasting accuracy. In [30], the authors used decision-focused learning for combinatorial optimization; however, their learning approach was based on decision rule optimization (DRO) which parametrizes both unknowns in the optimizaion model and the decision/policy. The decision/policy being an unknown and learned integratedly with another unknown in the optimizaion model may not represent the true decision/policy. The authors in [31] proposed an end-to-end approach using an energy based model to avoid calculating gradient of the regret function at each epoch and applied for load forecasting in power systems.\n\nNone of the works in the literature as per best of our knowledge formulated ILO for ED/DCOPF with multiple unknown parameters (load forecast and PTDF) in constraints. Moreover, though the work in [28] trained ILO for unknown parameters in constraints for a different application than ED, only inequality constraints were trained. The authors in [31] designed ILO formulation for forecasting the load; however, it only includes single unknown while analysing the impact of multiple equality constraints is missing. Moreover, none of the works analysed and explained the sensitivity analysis when multiple unknown parameters are included in the constraints. The application of ILO to DCOPF with multiple unknown parameters (load forecast and PTDFs) in constraints, their correlations, sensitivity analysis, their impact at different stages of market applications and ILO training formulations for multiple equality constraints in general is missing in the above-mentioned literatures.\n\nIn this work, for the first time to the best of our knowledge we develop ILO formulations to achieve economic operation in real-time market operation and non-real time generator scheduling together. The ILO formulation is designed to capture the real-time market and generator scheduling procedures to be used as a feedback for training certain unknown parameters in the equality constraints of ED/DCOPF formulations unlike SLO based open-loop training. The ILO formulation for ED is developed to obtain mainly the real-time cost-effective market operations while ILO formulation for DCOPF is developed to obtain hour-ahead and real-time cost-effective economic market operations. The training and testing results were compared with the SLO based training of ED/DCOPF unknowns and the results demonstrate a significant performance of ILO over SLO."}, {"title": "2. Approach", "content": "This section mainly explains the functioning of the three pipelines which clarifies the rationale for choosing ILO.\n\nAs illustrated in Fig. 1(a), the SLO pipeline has two phases, the training phase and the decision estimation phase. The training phase trains the prediction model instances ($f_\\theta(\\Lambda)$) with respect to ground truth/true parameter instances ($y_i$) by minimizing estimation error. The trained $f_\\theta(\\Lambda)$ is used to solve the optimization problem in the next phase making the pipeline sequential (predict and optimize sequentially).\n\nAs depicted in Fig. 1(b), the DRO pipeline trains the prediction model instances ($f_\\theta(\\Lambda)$) using policy approximation algorithms. The policy ($\\pi_{\\theta_1,\\theta_2}(f_{\\theta_1})$) contain parameters for prediction and policy models. The corresponding regret function ($L_{regret}$) is minimized to update parameters $\\theta_1$ and $\\theta_2$ corresponding to prediction model and policy model respectively.\n\nAs shown in Fig. 1(c), the ILO pipeline, the ith contextual information $\\Lambda^i$ is used to evaluate the prediction $f_\\theta(\\Lambda^i)$. The true parameter $y_i$ and the predicted parameter $f_\\theta(\\Lambda^i)$ are used to formulate the optimization problems using (3) and (4) respectively. The solution to optimization problems using $f_\\theta(\\Lambda^i)$ and $y_i$ generate corresponding decisions $x^*(f_\\theta(\\Lambda^i))$ and $x^*(y_i)$ respectively. The decisions are used to calculate the regret function ($L_{regret}$) using (5). The gradient to $L_{regret}$ is evaluated using subgradient methods like part predict then optimize plus (SPO+), interior point-based gradient, etc. The gradient of $L_{regret}, \\frac{\\partial L_{regret}}{\\partial \\theta}$ is used to update prediction model parameters $\\theta$.\n\nBased on above comparisons, the SLO pipeline learns the load forecast model to minimize error concerning the ground truth load. The load forecast model trained accurately instead of being trained decision focusedly when used in optimization problem may not yield decisions favouring better power system operations despite good forecast accuracy.\n\nThe closest in decision based learning concept to ILO is the decision rule optimization (DRO) pipeline (eg., deep reinforcement learning (DRL)) which, similar to ILO, learns the forecast model to optimize decisions. However, DRO maps the context to an approximated/parameterized decision. The DRO thus involves two approximations, forecast of optimization problem unknowns and forecast of optimization problem decisions. The parameterized DRO decisions learned integratedly with other problem unknowns may not represent the true problem decisions."}, {"title": "3. System under Study", "content": "The current work studies the grid side operations where an independent system operator (ISO) balances supply-demand deviations from market clearing schedules in real-time by ramping-up and -down generators. The deviations from market clearing schedules are due to inaccurate load forecasts on the demand side. Moreover, real-time congestion management is done by correcting PTDF matrix coefficients to within a true PTDF range (range for which the DCOPF solution gives ED solution). The PTDF matrix represents the system topology and varies with different line and bus configurations and different system sizes. Moreover, it also represents correlations between different line impedances. The PTDF matrix therefore cannot be directly approximated using a neural network (NN) and requires transforming NN output to represent power increments and specific transmission line impedance combinations along with obeying a specific system topology which include specific line and bus configurations and different system sizes.\n\nThe grid system under study is an IEEE-14 bus system consisting of seven electricity producers/supply participants (seven generation sources) and eight consumers/demand participants (eight loads) competing in the market to supply electricity to the consumers/demand participants at MCP. ISO solves the economic dispatch (ED)/ DC optimal power flow (DCOPF) problem to supply consumer loads by scheduling different generators using load forecast. After the true load is known, the ISO corrects supply-demand imbalances and line congestion due to inaccurate load forecasts and line PTDF by solving auction balancing problem to ramp-up or -down different generators in the market at prices different than the MCP. The ISO also trades electricity with different regions if the generators within the same region cannot ramp-up/-down corresponding to load inaccuracies.\n\nDue to price differences from MCP, the demand participants are subjected to extra payments (indirect penalty) for both over and underestimations in the load. Moreover, differences in true and forecasted PTDFs lead to higher operational costs during hour-ahead scheduling and also higher ramping costs during real-time correction. The current study thus, instead of minimizing load and PTDF forecast errors, minimizes extra payments on demand participants due to inaccurate load and PTDF forecasts using integrated learning and optimization (ILO). The ILO as explained in the upcoming sections integrates learning and optimization to capture ISO real-time correction procedures to be used as a feedback to learn the load and PTDF forecasts."}, {"title": "4. ILO Formulations for Economic Dispatch and DC Optimal Power Flow", "content": "The previous subsection explains the role of ISO in scheduling generation resources to supply demand based on the market clearing results. The ISO schedules generation resources at minimum generation cost by solving economic dispatch (ED) and DC optimal power flow (DCOPF) problems.\n\nED is an optimization problem for optimum resource scheduling to serve consumer electric demand while meeting various system-wide constraints at minimum generation cost. The ED optimization problem can be formulated as follows:\n\n$\\min\\limits_{P} \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} C_i(P_{i,t}) + \\sum\\limits_{t=0}^{T-1} C_{ext}(S_t)$\n\nsubject to $\\sum\\limits_{i=1}^{NG} P_{i,t} = f_{true,t} - S_t$\n\n$P_{i,min} \\leq P_{i,t} \\leq P_{i,max}, \\forall i$\n\nwhere $N_G$ denotes the number of dispatchable units, $P$ denotes the vector of generator power set-points, $C_i(P_{i,t})$ represents the cost of power generation for a specific generation unit which can be linear or non-linear (linear in the current study) at time step t, $f_{true,t}$ represents the total load from consumers at time step t, $P_{i,min}$ and $P_{i,max}$ respectively denotes the minimum and maximum power capacity of $i^{th}$ generation unit, $s_t$ denotes the amount of power supplied by the grid at time-step t, and $C_{MCP,ext,t}(S_t)$ is the penalty associated with $s_t$ amount of power-sharing from the grid at time-step t, T is the time-period of the look-ahead window (T=1 and T=24 for two parts of case study 1).\n\nThe above explained ED optimization model does not include line capacity constraints and does not take restraining power flow into account. Thus, another model known as DC optimal power flow (DCOPF) is needed as follows,\n\n$\\min\\limits_{P} \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} C_i(P_{i,t}) + \\sum\\limits_{t=0}^{T-1} C_{ext,t}(S_t)$\n\nsubject to $\\sum\\limits_{i=1}^{NG} P_{i,t} = f_{true,t} - S_t$ (2)\n\n$P_{line,t} = PTDF_t P_{inj,t}$\n\n$P_{i,min} \\leq P_{i,t} \\leq P_{i,max}, \\forall i$\n\n$P_{line,i,min} \\leq P_{line,i,t} \\leq P_{line,i,max}, \\forall i$\n\nwhere $P_{line,t}$ denotes the vector of line flows, PTDF (power transfer distribution factor) is a matrix to map injected power $P_{inj}$ to line flows, $P_{line,i,min}$ and $P_{line,i,max}$ respectively denotes the minimum and maximum line flows for each line, all at time step t."}, {"title": "4.2. Integrated Learning and Optimization", "content": "The ILO involves training a prediction model by mapping context to decisions to minimize the downstream cost. An optimization problem can be formulated as\n\n$x^* = \\min\\limits_{X} C(x) \\text{ s.t. } g(x)$ (3)\n\nwhere $x \\in \\mathbb{R}^d$ is a decision variable in d space, C(x) is the objective/cost function, and g(x) represent the set of constraints. The optimization problem may contain unknown parameters in its objective and constraints. The optimization problem in (3) can be reformulated as a parameterized optimization problem, according to\n\n$x^*(y, h) = \\min\\limits_{X} C(x, y) \\text{ s.t. } g(x, h)$ (4)\n\nwhere y, h $\\in \\mathbb{R}$ represent parameters in the objective and constraints of the optimization problem (4). The optimization problem objective and constraints depend on these parameters. In several real-world problems, the true parameters are unknown during online solving but corresponding side information (context/feature) is available to approximate the true parameters. The context is used to train unknown parameters $y_\\theta$ and $h_\\theta$ to approximate y and h respectively. The training dataset to learn, say, $y_\\theta$ can be represented as {$((\\Lambda^1, y^1), (\\Lambda^2, y^2), ... ,(\\Lambda^D, y^D))$}, where $\\Lambda \\in \\mathbb{R}^{m \\times n}$ represents contextual information matrix/feature matrix with m \\times n feature dimension. The feature matrix is mapped as $\\mathbb{R}^{m \\times n} \\rightarrow \\mathbb{R}^n$ to train n dimensional predictions $y_\\theta$ (or $h_\\theta$). In ILO, the neural network (NN) parameters are trained by minimizing a regret function ($L_{regret}$) which is the difference between the cost of predicted decisions with the true cost and cost of optimal decisions obtained with the true cost(see (5)).\n\n$L_{regret} = C(x^*(y_\\theta), y) - C(x^*(y), y)$ (5)\n\nThe $L_{regret}$ is minimized to find a predictor f from a class of hypothesis functions F using the empirical risk minimization (ERM) principle in (6).\n\n$f^* = \\min\\limits_{f \\in F} \\frac{1}{D} \\sum\\limits_{i=1}^{D} L_{regret} (y_\\theta(\\Lambda^i), y^i)$ (6)\n\nThe ILO pipeline describing the above-mentioned procedures is shown in Fig. 1."}, {"title": "4.3. ILO for ED and DCOPF", "content": "The concept of ILO can be extended to train unknown parameters in the ED and DCOPF optimization models using feedback information from real power system operations. The ED optimization model have load demand ($f_{true,t}$) (demand participant load) as an unknown parameter in the power-balancing equations representing equality constraints. The DCOPF has $f_{true,t}$ and PTDF as unknown parameters in its equality constraints. The unknown load and PTDF in the power-balancing equations are trained using ILO to minimize the cost of purchasing extra electricity by demand participants to balance supply and demand in real-time and minimize line congestion related costs."}, {"title": "4.3.1. Post-hoc (a posteriori) Analysis", "content": "The load and PTDF estimation using ILO to minimize extra costs on demand participants and line congestion is based on the concept of post-hoc analysis. The post-hoc analysis involves correcting decisions corresponding to forecasts using real-time true decisions.\n\nFor load training using ILO, the ED problem is initially solved using the load forecast model. Once the true load is known in real-time, the ILO minimizes an objective-specific regret function ($L_{regret}$ (minimizing extra costs on demand participants in the current study)). The regret function is minimized by updating load forecast model parameters using gradient descent (GD) which eventually minimizes extra costs on demand participants.\n\nFor load and PTDF training, the DCOPF problem is solved using load and PTDF forecasts and corrected in real-time. The correction for DCOPF training contains two unknown parameters and thus require understanding of the impact of one parameter over the other to design the regret function as explained in the following subsection."}, {"title": "4.3.2. Regret Function Design for ED and DCOPF", "content": "Regret Function for ED: The $L_{regret}$ for ED load training in this study is designed based on the concept of minimizing extra costs on consumers/demand participants due to ramping-up and -down of generators to tackle load forecast inaccuracy. The ramping-up price (bidding price (BP)) and ramping-down price (offer price (OP)) must hold the following relation with MCP\n\nBP > MCP\n\nOP < MCP\n\nThe above-pricing relations indicate the extra price to be paid by the demand-side market participant for incorrect load estimations to the regulation market participants willing to ramp-up or down their generation for supply-demand balancing. The regulation market players pay less when buying energy from ISO while charging more when selling energy to the ISO thereby imposing extra price/penalty to the demand participants. Inspired by the extra price/penalty concept, the $L_{regret}$ for ILO in this work is designed as follows.\n\nThe $L_{regret}$ (Fig. 3) for load training includes the costs corresponding to the amount of ramped-up and ramped-down powers for underestimation and overestimations in demands and their respective sub-scenarios respectively as shown in (7),\n\n$L_{regret} = \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} CBP(S_i) + \\sum\\limits_{t=0}^{T-1} CBP_{ext,t} (S_{ext,t}) + \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} CMP(S_i) + \\sum\\limits_{t=0}^{T-1} (COP(S_{ext})) + \\sum\\limits_{t=0}^{T-1} (CMCP_{ext,t} (S_{ext}))$ with following constraints\n\n$S_i \\geq P_i(f_\\theta) - P_i(f_{true}) \\forall i,t$\n\n$S_{i,t} \\geq P_{i,t} (f_{true}) - P_i(f_\\theta) \\forall i,t$\n\n$S_{ext,t} \\geq S_i(f_\\theta) - S_i (f_{true}) \\forall i, t$\n\n$S_{ext,t} \\geq S_{i,t}(f_{true}) - S_i(f_\\theta) \\forall i,t$\n\n$S \\geq 0 \\forall i,t$\n\n$S \\geq 0 \\forall i,t$\n\n$S_{ext,t} \\geq 0 \\forall i,t$\n\n$S_{ext,t} \\geq 0 \\forall i,t$ (7)\n\nwhere $CBP_{i,t}(.)$, $COP_{i,t}(.)$, $CMCP_{i,t}(.)$ and $CBP_{ext,t}(.)$, $COP_{ext,t}(.)$, $CMCP_{ext,t}(.)$ denotes cost functions to calculate the cost of power ramping-up at BP, cost of power ramping-down at OP, cost of power production at MCP within the same region and power ramping-up at BP, cost of power ramping-down at OP, cost of power production at MCP within the different region respectively. $S^+$ and $S^-$ respectively denotes over- and under-estimation variables representing the non-negative difference between predicted and true ED decisions for generators, $S_{ext,t}$ and $S_{ext,t}$ similarly represent the non-negative differences between predicted and true ED decisions for external region. Since the cost functions in this study are assumed to be linear, the costs $CBP_{i,t}(S_i)$, $COP_{i,t}(S_i)$, $CMCP_{i,t}(S_i)$, $CBP_{ext,t}(S_\\theta)$, $COP_{ext,t}(S_\\theta)$, and $CMCP_{ext,t}(S_\\theta)$ respectively are $BPiS, OPS, MCPiS, BP_{ext,t}S_{ext,t}, OP_{ext,t}S_{ext,t}$, and $MCP_{ext,t}S_{ext,t}$. Similar cost calculation relation holds for $S^{-}_{ext,t}$.\n\nThe terms $\\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} CBP(S_i)$ and $\\sum\\limits_{t=0}^{T-1} CBP_{ext,t}(S_{ext,t})$ represents penalty on the demand participants when regulation market players selling power to ISO at higher than MCP. The terms $\\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} (CMCP(S_i))$ and $\\sum\\limits_{t=0}^{T-1} (COP_{ext,t}(S_{ext}))$+$CMCP_{ext,t}(S_{ext})$) represent penalty to demand participants when regulation market participants purchasing power from ISO at less than MCP.\n\nIn both cases demand participant will be penalized which in other words also means paying higher than MCP by a certain amount. The above relation thus in terms of cost due to MCP can be written as (8). The terms $$\\$1,i,t and $\\$ext1,t represent penalty factors with respect to MCP for ramping-down, while the terms $\\$2,i,t and $\\$ext2,t represents the penalty factors with respect to MCP for ramping-up.\n\nGenerally, the extra price for ramping-up is higher than the amount paid for ramping-down power generation. The $L_{regret}$ thus, in addition to minimizing the costs for incorrect load estimations is designed to penalize more load underestimations (require ramping-up) compared to load overestimations (require ramping-down) to further enhance the extra cost minimization."}, {"title": "4.3.3. Regret Function Gradient Calculation", "content": "To train the load", "as": "n\n$L_{regret} = \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} \\phi_{1,i,t} CMCP_{i,t} (S_i) (max(P_i(f_\\theta) - P_i(f_{true}), 0)) + \\sum\\limits_{t=0}^{T-1} \\phi_{ext1,t} CMCP_{ext,t}(S_{ext,t}) (max(s (f_\\theta) - s (f_{true}), 0)) + \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} \\phi_{2,i,t} CMCP_{i,t} (S_i) (max(P_i(f_{true}) - P_i(f_\\theta), 0)) + \\sum\\limits_{t=0}^{T-1} \\phi_{ext2,t} CMCP_{ext, t} (S_{ext,t}) (max(s (f_{true}) - s(f_\\theta), 0))$(9)\n\nThe differential to (9) using the total law of derivatives can be calculated as follows\n\n$\\frac{\\partial L_{regret} (f_\\theta, f_{true})}{\\partial f_\\theta} = \\frac{\\partial L_{regret} (f_\\theta, f_{true})}{\\partial P^*(f_\\theta)} \\frac{\\partial P^*(f_\\theta)}{\\partial f_\\theta} + \\frac{\\partial L_{regret} (f_\\theta, f_{true})}{\\partial s^*(f_\\theta)} \\frac{\\partial s^*(f_\\theta)}{\\partial f_\\theta} = \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} \\phi_{1,i,t} CMCP_{i,t}(S_i) \\frac{\\partial P^*(f_\\theta)}{\\partial f_\\theta} (max(P_i(f_\\theta) - P_i (f_{true}), 0)) \\frac{P_i(f_\\theta) - P_i(f_{true})}{\\partial f_\\theta} + \\phi_{ext1,t} CMCP_{ext,t}(S_{ext,t}) \\frac{\\partial s^*(f_\\theta)}{\\partial f_\\theta} (max(s(f_\\theta) - S(f_{true}), 0)) \\frac{s(f_\\theta) - S(f_{true})}{\\partial f_\\theta} + \\sum\\limits_{i=1}^{NG} \\sum\\limits_{t=0}^{T-1} \\phi_{2,i,t} CMCP_{i,t} (S_i) \\frac{\\"}]}