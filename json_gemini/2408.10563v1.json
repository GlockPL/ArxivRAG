{"title": "The Stable Model Semantics for Higher-Order Logic Programming", "authors": ["Bogaerts Bart", "Charalambidis Angelos", "Chatziagapis Giannos", "Kostopoulos Babis", "Pollaci Samuele", "Rondogiannis Panos"], "abstract": "We propose a stable model semantics for higher-order logic programs. Our semantics is developed using Approximation Fixpoint Theory (AFT), a powerful formalism that has successfully been used to give meaning to diverse non-monotonic formalisms. The proposed semantics generalizes the classical two-valued stable model semantics of (Gelfond and Lifschitz 1988) as-well-as the three-valued one of (Przymusinski 1990), retaining their desirable properties. Due to the use of AFT, we also get for free alternative semantics for higher-order logic programs, namely supported model, Kripke-Kleene, and well-founded. Additionally, we define a broad class of stratified higher-order logic programs and demonstrate that they have a unique two-valued higher-order stable model which coincides with the well-founded semantics of such programs. We provide a number of examples in different application domains, which demonstrate that higher-order logic programming under the stable model semantics is a powerful and versatile formalism, which can potentially form the basis of novel ASP systems. This work is under consideration for acceptance in TPLP.", "sections": [{"title": "1 Introduction", "content": "Recent research (Charalambidis et al. 2013; 2018a;b) has demonstrated that it is possible to design higher-order logic programming languages that have powerful expressive capabilities and simple and elegant semantic properties. These languages are genuine extensions of classical (first-order) logic programming: for example, Charalambidis et al. (2013) showed that positive higher-order logic programs have a Herbrand model intersection property and this least Herbrand model can also be produced as the least fixpoint of a continuous immediate consequence operator. In other words, crucial semantic results of classical (positive) logic programs transfer directly to the higher-order setting.\nThe above positive results, created the hope and expectation that all major achievements of first-order logic programming could transfer to the higher-order world. Despite this hope, it was not clear until now whether it is possible to define a stable model semantics for higher-order logic programs that would generalize the seminal work of Gelfond and Lifschitz (1988). For many extensions of standard logic programming, it is possible to generalize the reduct construction of Gelfond and Lifschitz to obtain a stable model semantics, as illustrated for instance by Faber et al. (2011) for an extension of logic programs with aggregates. For higher-order programs, however, it is not clear whether a reduct-based definition makes sense. The most important reason why it is challenging to define a higher-order reduct, is that using the powerful abstraction mechanisms that higher-order languages provide, one can define negation inside the language, for instance by the rule neg X \u2190 ~X and use neg everywhere in the program where otherwise negation would be used, rendering syntactic definitions based on occurrences of negation difficult to apply.\nApart from scientific curiosity, the definition of a stable model semantics for higher-order logic programs also serves solid practical goals: there has been a quest for extending the power of ASP systems (Bogaerts et al. 2016; Amendola et al. 2019; Fandinno et al. 2021), and higher-order logic programming under the stable model semantics may prove to be a promising solution.\nIn this paper we define a stable model semantics for higher-order logic programs. Our semantics is developed using Approximation Fixpoint Theory (AFT) (Denecker et al. 2004). AFT is a powerful lattice-theoretic formalism that was originally developed to unify semantics of logic programming, autoepistemic logic (AEL) and default logic (DL) and was used to resolve a long-standing open question about the relation between AEL and DL semantics (Denecker et al. 2003). Afterwards, it has been applied to several other fields, including abstract argumentation (Strass 2013), active integrity constraints (Bogaerts and Cruz-Filipe 2018), stream reasoning (Antic 2020), and constraint languages for the semantic web (Bogaerts and Jakubowski 2021). In these domains, AFT has been used to define new semantics without having to reinvent the wheel (for instance, if one uses AFT to define a stable semantics, well-known properties such as minimality results will be automatic), to study the relation to other formalisms, and even to discover bugs in the original semantics (Bogaerts 2019). To apply AFT to a new domain, what we need to do is define a suitable semantic operator on a suitable set of \"partial interpretations\". Once this operator is identified, a family of well-known semantics and properties immediately rolls out of the abstract theory. In this paper, we construct such an operator for higher-order logic programs. Since our operator coincides with Fitting's (2002) three-valued immediate consequence operator for the case of standard logic programs, we immediately know that our resulting stable semantics generalizes the classical two-valued stable model semantics of Gelfond and Lifschitz (1988) as well as the three-valued one of Przymusinski (1990).\nThe main idea of our construction is to interpret the higher-order predicates of our language as three-valued relations over two-valued objects, i.e., as functions that take classical relations as arguments and return true, false, or undef. We demonstrate that such relations are equivalent to appropriate pairs of (classical) two-valued relations. The pair-"}, {"title": "2 A Motivating Example", "content": "In this section, we illustrate our higher-order logic programming language on the max-clique problem. A complete solution is included in Listing 1. We will assume an undirected graph is given by means of a unary predicate v (containing all the nodes of the graph) and a binary predicate e representing the edge-relation (which we assume to be symmetric). Lines 2 and 3 contain the standard trick that exploits an even loop of negation for simulating a choice, which in modern ASP input formats (Calimeri et al. 2020) would be abbreviated by a choice rule construct {pick X : v X}. Line 6 defines what it means to be a clique. In this line the (red) variable P is a first-order variable; it ranges over all sets of domain elements, whereas (blue) zero-order variables such as X in Line 2 range over actual elements of the domain. A set of elements is a clique if it (i) is a subset of v, and (ii) contains no two nodes without an edge between them. Failures to satisfy the second condition are captured by the predicate hasNonEdge. The predicate clique is a second-order predicate. Formally, we will say its type is $(\u03b9 \u2192 0) \u2192 o$: it takes as input a relation of type \u03b9 \u2192 o, i.e., a set of base domain elements of type i and it returns a Boolean (type o). In other words, the interpretation of clique will be a set of sets. Next, line 8 defines the second-order predicate maxclique, which is true precisely for those sets P that are subset-maximal among the set of all cliques, and line 10 asserts, using the standard trick with an odd loop over negation that pick must indeed be in maxclique.\nThis definition of maxclique makes use of a third-order predicate maximal which works with an arbitrary binary relation for comparing sets (here: the subset relation), as well as an arbitrary unary predicate over sets (here: the clique predicate). Listing 2 provides"}, {"title": "3 HOL: A Higher-Order Logic Programming Language", "content": "In this section we define the syntax of the language HOL that we use throughout the paper. For simplicity reasons, the syntax of HOL does not include function symbols; this is a restriction that can easily be lifted. HOL is based on a simple type system with two base types: o, the Boolean domain, and \u03b9, the domain of data objects. The composite types are partitioned into predicate ones (assigned to predicate symbols) and argument ones (assigned to parameters of predicates).\nDefinition 3.1\nTypes are either predicate or argument, denoted by aand p respectively, and defined as:\n$\\pi := o | (\\rho \u2192 \\pi)$\n$\\rho := \u03b9|\\pi$\nAs usual, the binary operator \u2192 is right-associative. It can be easily seen that every predicate type \u03c0 can be written in the form \u03c1\u2081 \u2192 \u00b7\u00b7\u00b7 \u2192 \u03c1n \u2192 o, n \u2265 0 (for n = 0 we assume that \u03c0 = o). We proceed by defining the syntax of HOL.\nDefinition 3.2\nThe alphabet of HOL consists of the following: predicate variables of every predicate type \u03c0 (denoted by capital letters such as P, Q, . . .); predicate constants of every predicate type \u03c0 (denoted by lowercase letters such as p,q, . . .); individual variables of type \u03b9 (denoted by capital letters such as X, Y, . . .); individual constants of type 1 (denoted by lowercase letters such as a,b,...); the equality constant \u2248 of type \u03b9 \u2192 \u03b9 \u2192 o for comparing individuals of type 1; the conjunction constant / of type o \u2192 o \u2192 o; the rule operator constant \u2190 of type o \u2192 o \u2192 o; and the negation constant ~ of type \u043e \u2192 \u043e.\nArbitrary variables (either predicate or individual ones) will usually be denoted by R.\nDefinition 3.3\nThe terms and expressions of HOL are defined as follows. Every predicate variable/constant and every individual variable/constant is a term; if E\u2081 is a term of type \u03c1 \u2192 \u03c0and E2 a term of type \u03c1 then (E1 E2) is a term of type \u03c0. Every term is also an expression; if E is a term of type o then (~E) is an expression of type o; if E\u2081 and E2 are terms of type 1, then (E\u2081 \u2248 E2) is an expression of type \u043e.\nWe will omit parentheses when no confusion arises. To denote that an expression E has type \u03c1 we will often write E : \u03c1.\nDefinition 3.4\nA rule of HOL is a formula p R\u2081\u00b7\u00b7\u00b7 Rn \u2190 E\u2081\u2227...\u2227Em, where p is a predicate constant of type \u03c11 \u2192 \u00b7\u00b7\u00b7 \u2192 \u03c1n \u2192 0, R1, ..., Rn are distinct variables of types \u03c11, ..., \u03c1n respectively and the Ei are expressions of type o. The term p R\u2081\u00b7\u00b7\u00b7Rn is the head of the rule and E1A... Em is the body of the rule. A program P of HOL is a finite set of rules.\nWe will often follow the common logic programming notation and write E\u2081,..., Em instead of E\u2081 ^\u00b7\u00b7\u00b7> Em for the body of a rule. For brevity reasons, we will often denote a rule as p R \u2190 B, where \u20a8 is a shorthand for a sequence of variables R\u2081\u00b7\u00b7\u00b7Rn and B represents a conjunction of expressions of type o."}, {"title": "4 The Two-Valued Semantics of HOL", "content": "In this section we define an immediate consequence operator for HOL programs, which is an extension of the classical Tp operator for first-order logic programs. We start with the semantics of the types of our language. In the following, we denote by Up the Herbrand universe of P, namely the set of all constants of the program.\nThe semantics of the base type o is the classical Boolean domain {true,false} and that of the base type \u03b9 is Up. The semantics of types of the form \u03c1 \u2192 \u03c0is the set of all functions from the domain of type \u03c1 to that of type \u03c0. We define, simultaneously with the meaning of every type, a partial order on the elements of the type.\nDefinition 4.1\nLet P be an HOL program. We define the (two-valued) meaning of a type with respect to Up, as follows:\n\u2022 $[0]_{Up} = \\{true, false \\}$. The partial order \u2264\u3002 is the usual one induced by the ordering false <o true\n\u2022 $[\u03b9]_{Up} = Up$. The partial order \u2264 is the trivial one defined as d \u2264 d for all d \u2208 Up\n\u2022 $[\u03c1 \u2192 \u03c0]_{Up} = [\u03c1]_{Up} \u2192 [\u03c0]_{Up}$, namely the set of all functions from [\u03c1]U, to [\u03c0]\u03c5\u03c1. The partial order \u2264\u03c1\u2192\u03c0 is defined as: for all f,g \u2208 [\u03c1 \u2192 \u03c0]Up, f \u2264\u03c1\u2192\u03c0g iff f(d) \u2264 g(d) for all d\u2208 [\u03c1]Up.\nThe subscripts from the above partial orders will be omitted when they are obvious from context. Moreover, we will omit the subscript Up assuming that our semantics is defined with respect to a specific program P.\nAs we mentioned before, each predicate type \u03c0 can be written in the form \u03c1\u2081 \u2192 \u00b7\u00b7\u00b7 \u2192 \u03c1n \u2192 o. Elements of [\u03c0] can be thought of, alternatively, as subsets of [\u03c11]\u00d7\u00b7\u00b7\u00b7\u00d7 [\u03c1n] (the set contains precisely those n-tuples mapped to true). Under this identification, it can be seen that \u2264 simply becomes the subset relation.\nProposition 4.1\nFor every predicate type \u03c0, ([\u03c0], \u2264\u33a2) is a complete lattice.\n\u03a3\u03c0\nIn the following, we denote by V\u2264 and < the corresponding lub and glb operations of the above lattice. When viewing elements of ras sets, V< is just the union operator and < the intersection. We now proceed to define Herbrand interpretations and states.\nDefinition 4.2\nA Herbrand interpretation I of a program Passigns to each individual constant cof P, the element I(c) = c, and to each predicate constant p: \u03c0\u03bff P, an element I(p) \u2208 [\u03c0].\nWe will denote the set of Herbrand interpretations of a program P with Hp. We define a partial order on Hp as follows: for all I, J \u2208 Hp, I \u2264 J iff for every predicate constant p: \u03c0 that appears in P, I(p) \u2264\u03c0 J(p). The following proposition demonstrates that the space of interpretations is a complete lattice. This is an easy consequence of Proposition 4.1.\nProposition 4.2\nLet P be a program. Then, (Hp, \u2264) is a complete lattice.\nDefinition 4.3\nA Herbrand state s of a program P is a function that assigns to each argument variable R of type \u03c1, an element s(R) \u2208 [\u03c1]. We denote the set of Herbrand states with Sp.\nIn the following, s[R1/d1,...,Rn/dn] is used to denote a state that is identical to s the only difference being that the new state assigns to each R\u00bf the corresponding value di; for brevity, we will also denote it by s[R/d].\nWe proceed to define the (two-valued) semantics of HOL expressions and bodies.\nDefinition 4.4\nLet P be a program, I a Herbrand interpretation of P, and s a Herbrand state. Then, the semantics of expressions and bodies is defined as follows:\n1. $[R]_{s}(I) = s(R)$\n2. $[c]_{s}(I) = I(c) = c$\n3. $[p]_{s}(I) = I(p)$\n4. $[(E_{1} E_{2})]_{s}(I) = [E_{1}]_{s}(I) [E_{2}]_{s}(I)$"}, {"title": "5 The Three-Valued Semantics of HOL", "content": "In this section we define an alternative semantics for HOL types and expressions, based on a three-valued truth space. As in first-order logic programming, the purpose of the third truth value is to assign meaning to programs that contain circularities through negation. Since we are dealing with higher-order logic programs, we must define three-valued relations at all orders of the type hierarchy. These three-valued relations are functions that take two-valued arguments and return a three-valued truth result.\nDue to the three-valuedness of our base domain o, all our domains inherit two distinct ordering relations, namely \u2264 (the truth ordering) and < (the precision ordering).\nDefinition 5.1\nLet P be a program. We define the (three-valued) meaning of a type with respect to Up, as follows:\n\u2022 $[0]^{*}_{Up} = \\{false, undef, true\\}$. The partial order \u2264\uff61 is the one induced by the ordering false <o undef <\u3002true; the partial order \u4eba\u3002is the one induced by the ordering undef\u4eba\u3002false and undef\u4eba\u3002true.\n\u2022 $[\u03b9]^{*}_{Up} = Up$. The partial order \u2264, is defined as d \u2264 d for all d \u2208 Up. The partial order is also defined as d \u2264 d for all d\u2208 Up.\n\u2022 $[\u03c1 \u2192 \u03c0]^{*}_{Up} = [\u03c1]_{Up} \u2192 [\u03c0]^{*}$. The partial order \u2264\u03c1\u2192\u03c0 is defined as follows: for all f,g \u2208 [\u03c1 \u2192 \u03c0]p, f \u2264\u03c1\u2192\u03c0g iff f(d) \u2264 g(d) for all d\u2208 [\u03c1]up. The partial order <p\u2192\u03c0 is defined as follows: for all f, g\u2208 [\u03c1 \u2192 \u03c0]Up, f \u2264\u03c1\u03c0g iff f(d) \u2264 g(d) for all d\u2208 [\u03c1]up.\nWe omit subscripts when unnecessary. It can be easily verified that for every pit holds $[p] \u2286 [p]^{*}$. In other words, every two-valued element is also a three-valued one. Moreover, the \u2264, ordering in the above definition is an extension of the \u2264 ordering in Definition 4.1.\nProposition 5.1\nFor every predicate type \u03c0, ($[\u03c0]^{*}$, \u2264\u33a2) is a complete lattice and ($[\u03c0]^{*}$, \u2220\u33a2) is a complete meet-semilattice (i.e., every non-empty subset of $[\u03c0]^{*}$ has a \u2220\u33a2-greatest lower bound).\n\u03c0\nWe denote by V, and < the lub and glb operations of the lattice ($[\u03c0]^{*}$, \u2264\u33a2); it can easily be verified that these operations are extensions of the corresponding operations implied by Proposition 4.1. We denote by the glb in ($[\u03c0]^{*}$, \u2220\u33a2). Just like how a two-valued interpretation of a predicate \u03c0of type \u03c1\u2081 \u2192 \u00b7\u00b7\u00b7 \u2192 \u03c1n \u2192 o can be viewed as a set, an element of $[\u03c0]^{*}$ can be viewed as a partial set, assigning to each tuple in [\u03c11]\u00d7\u2026\u00d7[\u03c1n] one of three truth values (true, meaning the tuple is in the set, false meaning it is not in the set, or undef meaning it is not determined if it is in the set or not). This explains why the arguments are interpreted classically: a partial set decides for each actual (i.e., two-valued) object whether it is in the set or not; it does not make statements about partial (i.e., three-valued) objects. Due to the fact that the arguments of relations are interpreted classically, the definition of Herbrand states that we use below, is the same as that of Definition 4.3. A three-valued Herbrand interpretation is defined analogously to a two-valued one (Definition 4.2), the only difference being that the meaning of a predicate constant p: \u03c0is now an element of $[\u03c0]^{*}$. We will use caligraphic fonts (e.g., I, I) to differentiate three-valued interpretations from two-valued ones. The set of all three-valued Herbrand interpretations is denoted by Hp. Since $[\u03c0] \u2286 [\u03c0]^{*}$ it also follows that Hp Hp.\nDefinition 5.2\nLet P be a program. We define the partial orders < and < on Hp as follows: for all I, I \u2208 Hp, I \u2264 I (respectively, I < J) iff for every predicate type and for every predicate constant p : \u03c0\u03bff P, I(p) \u2264\u30f5 I(p) (respectively, I(p) \u2264\u30f5 I(p)).\nDefinition 5.3\nLet P be a program, I a three-valued Herbrand interpretation of P, and s a Herbrand state. The three-valued semantics of expressions and bodies is defined as follows:\n1. $[R]^{*}_{s}(I) = s(R)$\n2. $[c]^{*}_{s}(I) = I(c) = c$"}, {"title": "6 Approximation Fixpoint Theory and the Stable Model Semantics", "content": "We now define the two-valued and three-valued stable models of a program P. To achieve this goal, we use the machinery of approximation fixpoint theory (AFT) (Denecker et al. 2004). In the rest of this section, we assume the reader has a basic familiarity with (Denecker et al. 2004). As mentioned before, the two-valued immediate consequence operator Tp: Hp \u2192 Hp can be non-monotone, meaning it is not clear what its fixpoints of interest would be. The core idea behind AFT is to \u201capproximate\u201d Tp with a function Ap which is \u4eba-monotone. We can then study the fixpoints of Ap, which shed light to the fixpoints of Tp. While we already have such a candidate function, namely Tp, AFT requires a function that works on pairs (of interpretations). Therefore, we show that there is a simple isomorphism between three-valued relations and (appropriate) pairs of two-valued ones. This isomorphism also exists between three-valued interpretations and (appropriate) pairs of two-valued ones.\nDefinition 6.1\nLet (L, \u2264) be a complete lattice. We define L\u00ba = {(x,y) \u2208 L \u00d7 L | x \u2264 y}. Moreover, we define the relations \u2264 and \u4eba, so that for all (x, y), (x', y') \u2208 L\u00ba: (x,y) \u2264 (x', y') iff x \u2264 x' and y \u2264 y', and (x, y) \u2264 (x', y') iff x \u2264 x' and y' \u2264 y.\nProposition 6.1\nFor every predicate type \u03c0there exists a bijection \u315c\u3160 : $[\u03c0]^{*} \u2192 [\u03c0]\u02da with inverse \u03c4\u3160\u00b9 : $[\u03c0]\u02da \u2192 [\u03c0]^{*}$, that both preserve the orderings < and \u2220 of elements between $[\u03c0]^{*}$ and [\u03c0]. Moreover, there exists a bijection \u03c4 : Hp \u2192 Hf with inverse \u03c4\u00af\u00b9 : H\u0151 \u2192 Hp, that both preserve the orderings \u2264 and < between Hp and Hp.\nWhen viewing elements of $[\u03c0]^{*}$ as partial sets and elements of [\u03c0] as sets, the isomorphism maps a partial set onto the pair with first component all the certain elements of the partial set (those mapped to true) and second component all the possible elements (those mapped to true or undef). Using these bijections, we can now define Ap which, as we demonstrate, is an approximator of Tp. Intuitively, Ap is the \u201cpair version of Tp\" (instead of handling three-valued interpretations, it handles pairs of two-valued ones).\nDefinition 6.2\nFor each program P, Ap : Hf \u2192 Hf is defined as Ap(I, J) = \u03c4(Tp(\u03c4\u00af\u00b9(I, J))).\nLemma 6.1\nLet P be a program. In the terminology of Denecker et al. (2004), Ap : H \u2192 He is a consistent approximator of Tp.\nSince Ap is \"the pair version of Tp\", it is not a surprise that it also captures all the three-valued models of P.\nLemma 6.2\nLet P be a program and (I, J) \u2208 Hf. Then, (I, J) is a pre-fixpoint of Ap if and only if \u03c4-1(I, J) is a three-valued model of P.\nDue to the above lemma, by stretching notation, when (I, J) is a pre-fixpoint of Ap we will also say that (I, J) is a model of P."}, {"title": "7 Properties of the Stable Model Semantics", "content": "In this section we discuss various properties of the stable model semantics of higher-order logic programs, which demonstrate that the proposed approach is indeed an extension of classical stable models. In the following results we use the term \"classical stable models\" to refer to stable models in the sense of (Gelfond and Lifschitz 1988), \u201cclassical three-valued stable models\" to refer to stable models in the sense of (Przymusinski 1990) and the term \"(three-valued) stable models\u201d to refer to the present semantics.\nTheorem 7.1\nLet P be a propositional logic program. Then, M is a (three-valued) stable model of P iff M is a classical (three-valued) stable model of P.\nProof\nIn (Denecker et al. 2004, Section 6, pages 107-108), the well-founded semantics of propositional logic programs is derived. The language used there allows arbitrary nesting of conjunction, disjunction and negation in bodies of the rules which fully encompasses our syntax when we restrict our programs to be propositional. In addition, the immediate consequence operator Tp is the same and so is the approximation space which we have denoted as Hf in this work.\nIt is easy to see that the approximator Ap we give in our approach and the one given in Denecker et al. (2004) fully coincide for propositional programs therefore produce equivalent semantics. Notice how our three-valued operator Tp fully coincides with the three-valued immediate consequence operator in Denecker et al. (2004) since the fourth rule in Definition 5.3 is never used.\nIn order to establish Theorem 7.2, we use the following proposition which is a restatement of Proposition 3.14 found in Denecker et al. (2004) that refers to pre-fixpoints of the approximator Ap instead of fixpoints. The proof is almost identical but is presented here, nonetheless, for reasons of completeness.\nProposition C.1\nA stable fixpoint (x, y) of Ap is a \u2264-minimal pre-fixpoint of Ap. Furthermore, if (x, x) is a stable fixpoint of Ap then x is a minimal pre-fixpoint of Tp.\nProof\nLet (x, y) be a stable fixpoint of Ap and let (x', y') such that (x', y') \u2264 (x, y) and (x', y') is a pre-fixpoint of Ap, so Ap(x', y') \u2264 (x', y'). We have that x' \u2264 y' < y which gives us that Ap(x',y)1 \u2264 Ap(x', y')1 \u2264 (x', y')1 = x'. Therefore, x' is a pre-fixpoint of the operator Ap(, y)\u2081 and since x is its least fixpoint we get that x \u2264 x'. By the assumption that x'x we conclude that x = x'.\n= = x'.\nSince we have shown that x = x' we have that x x' \u2264 y' and Ap(x,y')2 \u2264 Ap(x', y')2 \u2264 (x',y')2 = y' which makes y' a pre-fixpoint of Ap(x,\u00b7)2. Since y is its least fixpoint we have that y \u2264 y' and by assumption y' < y. We conclude that y = y' and finally (x, y) = (x', y').\nAssume that x' \u2264 x and x' is a pre-fixpoint of Tp therefore Tp(x') \u2264 x'. Since Ap is an approximator of Tp we have that Ap(x', x') = (Tp(x'), Tp(x')) \u2264 (x', x'). But then (x', x') is a pre-fixpoint of Ap and (x', x') \u2264 (x,x). By the result of the previous paragraph we conclude that (x', x') = (x, x) and x' = x.\nTheorem 7.2\nAll (three-valued) stable models of a HOL program Pare <-minimal models of P.\nProof\nLet M be a three-valued stable model of P and M' a three-valued model of P, such that M' \u2264 M which also implies \u0442(\u041c') \u2264 \u0442(M). By Lemma 6.2, \u03c4(M') is a pre-fixpoint"}, {"title": "8 Additional Examples", "content": "In this section we present two examples of how higher-order logic programming can be used. First, we showcase reasoning problems arising from the field of abstract argumentation, next we model a PSPACE-complete problem known as Generalized Geography.\n8.1 Abstract Argumentation\nIn what follows, we present a set of standard definitions from the field of abstract argumentation (Dung 1995). Listing 3 contains direct translations of these definitions into our framework; the line numbers with each definition refer to Listing 3. Listing 4 illustrate how these definitions can be used to solve reasoning problems with argumentation.\nAn abstract argumentation framework (AF) \u0398 is a directed graph (A, E) in which the nodes A represent arguments and the edges in E represent attacks between arguments. We say that a attacks b if (a,b) \u2208 E. A set S \u2286 A attacks a if some s \u2208 S attacks a (Line 2). A set S C A defends a if it attacks all attackers of a (Line 4). An interpretation of an AF O = (A, E) is a subset S of A. There exist many different semantics of AFs that each define different sets of acceptable arguments according to different standards or intuitions. The major semantics for argumentation frameworks can be formulated using\ntwo operators: the characteristic function Fe (Line 5) mapping an interpretation S to\n$F_{e}(S) = \\{a \u2208 A | S defends a\\}$\nand the operator Ue (U stands for unattacked; Line 6) that maps an interpretation S to\n$U_{e}(S) = \\{a \u2208 A | a is not attacked by S\\}$.\nThe grounded extension of O is defined inductively as the set of all arguments defended by the grounded extension (Line 8), or alternatively, as the least fixpoint of Fe, which is a monotone operator. The operator Ue is an anti-monotone operator; its fixpoints are called stable extensions of \u0472 (Line 9). An interpretation S is conflict-free if it is a postfixpoint of U\u0473 (i.e., if S \u2286 Ue(S); Line 10). A complete extension is a conflict-free fixpoint of Fe (Line 11). An interpretation is admissible if it is a conflict-free postfixpoint of Fe (Line 12). A preferred extension is a C-maximal complete extension (Line 13).\nListing 4 shows how these definitions can be used for reasoning problems related to argumentation. There, we search for an argumentation framework with five elements where the grounded extension does not equal the intersection of all stable extensions.\n8.2 (Generalized) Geography\nGeneralized geography is a two-player game that is played on a graph. Two players take turn to form a simple path (i.e., a path without cycles) through the graph. The first player who can no longer extend the currently formed simple path loses the game. The question whether a given node in a given graph is a winning position in this game (i.e., whether there is a winning strategy) is well-known to be PSPACE-hard (see, e.g., the proof of Lichtenstein and Sipser (1980)). This game can be modelled in our language very compactly: Line 2 in Listing 5 states that X is a winning node in the game V, E if there is an outgoing edge from X that leads to a non-winning position in the induced graph obtained by removing X from V. This definition makes use of the notion of an"}, {"title": "9 Related and Future Work", "content": "There are many extensions of standard logic programming under the stable model semantics that are closely related to our current work. One of them is the extension of logic programming with aggregates, which most solvers nowadays support. Aggregates are special cases of second-order functions and have been studied using AFT (Pelov et al. 2007; Vanbesien et al. 2022) and in fact our semantics of application can be viewed as a generalization of the ultimate approximating aggregates of Pelov et al. (2007). Also, higher-order logic programs have been studied through this fixpoint theoretic lens. Dasseville et al. (2015) defined a logic for templates, which are second-order definitions, for which they use a well-founded semantics. This idea was generalized to arbitrary higher-order definitions in the next year (Dasseville et al. 2016). While they apply AFT in the same space of three-valued higher order functions as we do, a notable difference is that they use the so-called ultimate approximator, resulting in a semantics that does not coincide with the standard semantics for propositional programs whereas our semantics does (see Theorem 7.1).\nIn 2018, a well-founded semantics for higher-order logic programs was developed using AFT (Charalambidis et al. 2018a). There are two main ways in which that work differs from ours. The first, and arguably most important one, is how the three-valued semantics of types is defined. While in our framework $[p \u2192 o]^{*}$ consists of all functions from [p] to $[o]^{*}$, in their framework $[p \u2192 o]^{*}$ would consist of all <-monotonic functions from $[p]^{*}$ to $[o]^{*}$. This results, in their case, to more refined, but less precise, and more complicated, approximations. As a result, an extension of AFT needed to be developed to accommodate this. In our current work, we show that we can stay within standard AFT, but to achieve this, we needed to develop a new three-valued semantics of function application; see Item 4 in Definition 5.3. The formal relationship between the two approaches remains to be further investigated. The second way in which our work differs from that"}, {"title": "A Proofs of Section 4 and Section 5", "content": "In the following, we provide the proofs of a few propositions contained in Sections 4 and 5. Notice that most of the results of these two sections are rather straightforward. Propositions 4.1 and 5.1 are algebraic consequences of Definitions 4.1 and 5.1, respectively.\nProposition 4.1\nFor every predicate type \u03c0, ([\u03c0], \u2264\u33a2) is a complete lattice.\nProof\nWe proceed by induction on the predicate type \u03c0.\nLet \u03c0 = o. Clearly, the set [0] = {true, false} with the order \u2264\u3002 is a complete lattice, with bottom element false and top element true.\nNow let \u03c0 = \u03c1 \u2192 \u03c0', and assume [\u03c0'] is a complete lattice. We have to show that the set of functions [p] \u2192 [\u03c0'] with the order <p\u2192\u03c0 is a complete lattice. Since [\u03c0'] is a complete lattice, for each subset S \u2286 [\u03c0] we can define f\u0245s, fys\u2208 [\u03c0] by f\u0245s(x) := {g(x) | g \u2208 S} and fys(x) := \u221a{g(x) | g \u2208 S}, respectively. By the definition of <p\u2192\u03c0', it is immediate to see that ^ S = f^s and \u2228 S = f\u2228 s. Hence, [\u03c0] is a complete lattice, as desired.\nThe following proposition draws the correspondence between the two-valued Herbrand models of a program and the pre-fixpoints of its immediate consequence operator.\nProposition 4.3\nLet P be a program and I \u2208 Hp. Then, I is a model of P iff I is a pre-fixpoint of Tp.\nProof"}, {"title": "B Proofs of Section 6", "content": "In this appendix", "\u03c0": {"\u03c0": "of pairs of two-valued ones. We first provide the definition of such functions", "\u03c4\u03c0": ["\u03c0"]}}, {"\u03c0": "and \u03c4\u3160\u00b9 : [\u03c0"}, {"\u03c0": {"follows": "n$\\bullet$ $\u03c4_{o}(false)"}}]}