[{"title": "Asymmetrical Latent Representation for Individual Treatment Effect Modeling", "authors": ["Armand Lacombe", "Mich\u00e8le Sebag"], "abstract": "Conditional Average Treatment Effect (CATE) estimation, at the heart of counterfactual reasoning, is a crucial challenge for causal modeling both theoretically and applicatively, in domains such as healthcare, sociology, or advertising. Borrowing domain adaptation principles, a popular design maps the sample representation to a latent space that balances control and treated populations while enabling the prediction of the potential outcomes. This paper presents a new CATE estimation approach based on the asymmetrical search for two latent spaces called Asymmetrical Latent Representation for Individual Treatment Effect (ALRITE), where the two latent spaces are respectively intended to optimize the counterfactual prediction accuracy on the control and the treated samples. Under moderate assumptions, ALRITE admits an upper bound on the precision of the estimation of heterogeneous effects (PEHE), and the approach is empirically successfully validated compared to the state of the art.", "sections": [{"title": "Introduction", "content": "In the Neyman-Rubin framework Rubin (2005), causal inference focuses on a simple question: how different would the outcome have been if the treatment had been different? Answering this question, however, raises considerable difficulties, as the true answer is inevitably unknown: the i-th individual either is treated (with outcome $y_i^1$) or not (with outcome $y_i^0$). In both cases, observation of the difference $y_i^1 - y_i^0$ remains inaccessible. Overall, the estimation of the individual causal effect, acknowledged as the fundamental problem of causal inference (Holland, 1986), addresses a machine learning problem with missing values.\nA most natural approach consists in independently modeling outcome $Y^1$ (respectively $Y^0$) from the treated (resp. untreated, or control) samples as functions of their covariate description $X$, allowing the individual causal effect to be estimated from the difference of both models. This approach is valid subject"}, {"title": null, "content": "to a key assumption, stating that treated and control samples are drawn from the same distribution $P(X)$; in other words, the treatment assignment must follow the randomized control trial methodology.\nIn real-life applications however, this assumption rarely holds true. In the medical field the treatment variable $T$ is generally assigned by the doctor, depending on the severity of the individual's condition. In the field of education, the decision of e.g. following a curriculum depends on the individual's background. In such cases, the treated and control distributions $P_1(X) = P(X|T = 1)$ and $P_0(X) = P(X|T = 0)$ are different.\nEstimating the potential outcome models based on the joint distributions $P(X, Y^1)$ and $P(X, Y^0)$ can thus be cast as a learning across domain problem (Ben-David et al., 2006; Ganin et al., 2016), where the two support distributions $P(X|T = 0)$ and $P(X|T = 1)$ differ. Building upon the state of the art (Ben-David et al., 2006), it thus comes naturally to integrate the space of original covariates into a latent space aligning both support distributions (Johansson et al., 2016; Shalit et al., 2017) (more in Section 2).\nA main claim of the paper is that the $CATE$ problem however significantly differs from the mainstream learning across domain setting. Specifically, estimating $P(Y^1|X).P(X)$ from $P(Y^1|X).P_1(X)$ requires all control samples to be 'sufficiently close' from some treated samples (A). Likewise, estimating $P(Y^0|X).P_1(X)$ from $P(Y^0|X).P_0(X)$ requires all treated samples to be 'sufficiently close' from some control samples (B)."}, {"title": "State of the art", "content": "As large datasets become increasingle available, they support the estimation of causal effects at individual or group level, reflecting the heterogeneity of treatment impacts. The state of the art commonly distinguishes several categories of $CATE$ learners, depending on the main features of the models and notably how these models account for the treatment assignment variable K\u00fcnzel et al. (2019); Nie and Wager (2021); Kennedy (2023).\n2.1 S-learners\nS(ingle)-learners fit a single model with treatment assignment $T$ and covariates $X$ as inputs. The potential outcome models are learned along classical supervised learning, with:\n$\\mu(x, t) \\approx \\mu^t(x) = E[Y|X = x, T = t]$\nand the treatment effect is defined as: $f(x) = \\mu(x, 1) - \\mu(x, 0)$. In the Balancing Neural Network ($BNN$) approach Johansson et al. (2016), an embedding is used to map the covariate space onto a latent representation, merging the (image of) control and treatment distributions along the domain adaptation principles (Ben-David et al., 2006). The potential outcome $\\hat{\\mu}(x, t)$ is sought as a single neural net, operating on the concatenation of $f(x)$ and the treatment variable $t$. However, the fact that the treatment assignment variable is given no particular role tends to bias the $CATE$ estimate toward 0 according to K\u00fcnzel et al. (2019).\nBayesian Additive Regression Trees ($BART$) are built along the same prin-ciples, using regression trees instead of neural nets; in Athey and Imbens (2016), the $BART$ approach is extending to yield confidence intervals. In Wager and Athey (2018), $BART$ is learned using Causal Forests ($CF$) where the last split of the forest trees corresponds to the treatment assignment."}, {"title": "T-learners", "content": "T(wo)-learners differ from S-learners in that they learn different models for both potential outcomes. Inspired by domain adaptation Johansson et al. (2022),"}, {"title": "Asymmetrical Latent Regularization for Individual Treatment Effect Modeling", "content": "This section first presents the intuition underlying the proposed ALRITE approach. After an overview of ALRITE, the theoretical analysis of the approach, upper bounding the estimation error under mild assumptions, is described and its scope is discussed.\n3.1 Intuition\nFollowing the above discussion, our claim is that CATE must define two latent spaces, allowing counterfactual modeling for both control and treatment samples, i.e. with low counterfactual variance for each distribution. With no loss of generality let us characterize the counter-factual variance w.r.t. treated samples, with an embedding from input space X onto latent space Z.\nGiven $(x_i, t_i = 1, y_i)$ a treated sample, the aim is to estimate $E[Y^1 - Y^0|X = x_i]$. Under the assumption that $\\phi$ is injective, this estimate coincides with $E[Y^1 - Y^0|\\phi(X) = \\phi(x_i)]$ (the injectivity requirement is relaxed in section 3.5). The variance of the counter-factual estimate for $(x_i, t_i = 1, y_i)$ depends on how far $\\phi(x_i)$ is from $\\phi(x_j)$ for $x_j$ among the control samples.\nAs illustrated in Fig. 3, when a treated point is away from control points in latent space, estimating its counter-factual outcome can be viewed as an out-of-distribution estimation problem. The estimate can be arbitrarily inaccurate (unless strong assumptions, e.g., linearity or high smoothness, are made on the potential outcome models). The high uncertainty on the counter-factual estimate is all the greater the higher the dimension of covariate X and the smaller the number n of samples (as is generally the case). This suggests that no treated (respectively, control) sample should be isolated from the control (resp., treated) samples in latent space."}, {"title": "Overview of Alrite", "content": "3.2.1 Counter-factualizability\nExtending (Johansson et al., 2016; Wu et al., 2023a), with an embedding from the covariate space X onto latent space Z we define the latent mirror twin of sample $(x_i, t_i, y_i)$ noted $(x_i^{m,\\phi}, 1 - t_i, y_i^{m,\\phi})$ as the nearest sample with different treatment assignment in latent space:\n$(x_i^{m,\\phi}, 1 - t_i, y_i^{m,\\phi}) = argmin{\\||\\phi(x_i) - \\phi(x_j) \\||, (x_j, t_j = 1 - t_i, y_j) \\in D\\}$ (3)\nwhere the superscript $\\phi$ is omitted when clear from the context.\nThe counter-factualizability of $x_i$ is defined as its Euclidean distance in latent space to its latent mirror twin $(\\|\\phi(x_i) - \\phi(x_i^m)\\|)$: the smaller the better. As said, $x_i^m$ is used to estimate the counter-factual outcome for its twin $x_i$. Accordingly, a sample that is mirror twin for several other samples matters more for counter-factual estimation, everything else being equal. This intuition is formalized by defining the counter-factual importance weight, noted $w_j$, as:\n$w_j = \\#{i \\in [1,n] s.t. (x_i^{m,\\phi}, 1 - t_i, y_i^{m,\\phi}) = (x_j, t_j, y_j)\\}$\nThe notions of latent mirror twin, and counterfactual importance weight are used to estimate the quality of the latent space. Informally speaking, a latent space allowing good counterfactual estimation of the treated samples is such that: i) the treated examples are close to their mirror twin; ii) the $\\mu^0(x) \\approx E[Y|T = 0, X = x]$ model learned on this latent space is of good quality, especially for control x; with a high $w_j$ (since the quality of $\\mu^0(x_j)$ has an impact on the counterfactual estimation of many treated $x_i$)."}, {"title": "Model architecture", "content": "As said (Section 3.1), the accurate counter-factual estimate of samples requires these samples to be counter-factualizable, i.e. close to their mirror twins. As depicted on Fig. 1 however, the requirements of control and treated samples being counter-factualizable are not necessarily satisfied by the same change of representation.\nConsequently, we consider two latent spaces, aimed at ensuring counterfac-tualization of treated and control samples. More formally, the treatment-driven pipeline $P_1$ focuses on $CATE$ for treated samples, while the control-driven pipeline $P_0$ focuses on $CATE$ for control samples.\nThe combination of the CATE estimates built from $P_0$ and $P_1$ is classically defined as:\n$\\tau : x \\in X \\mapsto (1 - \\eta(x))\\tau_0(x) + \\eta(x)\\tau_1(x)$ (4)\nwith $\\eta(x)$ estimating the propensity score $P(T = 1|X = x)$ and $\\tau_0$ and $\\tau_1$ denoting the $CATE$ estimates derived from pipelines $P_1$ and $P_0$.\nNote that ALRITE bridges the gap between T-learners and X-learners: each pipeline ($P_0$ and $P_1$) defines a T-learner and a causal estimate; these causal estimates are combined as in X-learners (Eq. 4)."}, {"title": "Training loss", "content": "Let us present the loss used to train control pipeline $P_0= (\\phi, h^0, h^1)$ (the $P_1$ loss follows by symmetry). $P_0$ is trained end-to-end by minimizing a compound"}, {"title": "Algorithm", "content": "The ALRITE algorithm finally involves three modules: learning $P_0$ (Eq. 5); learning $P_1$; learning the propensity estimate $\\hat{\\eta}$. Finally, the CATE estimates derived from $P_0$ and $P_1$ are aggregated using $\\hat{\\eta}$ (Eq. 4)."}, {"title": "Formal guarantees", "content": "As said, a main contribution of the approach is to provide formal guarantees on the $PEHE$ error of ALRITE, considering the within-sample setting, i.e. when the treatment variable $T$ is known. Remind that the within-sample error is not trivial contrarily to the training error in supervised learning as counter-factual $Y^{1-T}$ is not observed. All proofs are given in Appendix A.1. Our first result states that the PEHE loss associated with a T-learner is upper bounded depending on the counter-factualizability of the samples.\nTheorem 1. Let $\\phi : X \\rightarrow Z$ be an embedding from $X$ to a latent space $Z$. Let us assume that the sought outcome models $\\mu^0$ and $\\mu^1$ can be expressed as $\\mu^0 = \\nu^0 \\circ \\phi$ and $\\mu^1 = \\nu^1 \\circ \\phi$, with $\\nu^0$ and $\\nu^1$ two functions defined on $Z$ with Lipschitz constant $L$.\nLet $\\hat{\\mu}^0, \\hat{\\mu}^1 : Z \\rightarrow R$ be two models trained to approximate $\\nu^0$ and $\\nu^1$ with Lipschitz"}, {"title": null, "content": "constant $\\hat{L}$. Then the empirical $PEHE$ associated with $(\\hat{\\mu}^1 - \\hat{\\mu}^0) \\circ \\phi$ is upper bounded by $M_1$ with:\n$M_1 = \\frac{4}{n} [\\sum_{i=1}^{n}(1 + w_i)(\\hat{\\mu}^{t_i} \\circ \\phi)(x_i) - Y_i)^2 + (L^2 + \\hat{L}^2) \\sum_{i=1}^{n} ||x_i - x_i^m||^2]$\nBound $M_1$ depends on two terms: i) the factual accuracy on every sample $x_i$, all the more important the higher its counter-factual importance weight $w_i$, and ii) the counter-factualizability of the samples. This bound establishes the soundness of the training loss (Eq. 5), built on both terms.\nBuilding on this result, our second result concerns the hybrid X-learner T-learner scheme of ALRITE.\nTheorem 2. Let $P_0$ and $P_1$ be a control and a treatment pipeline, respectively involving embeddings $\\phi_0$ and $\\phi_1$. Let us further assume that the sought outcome models $\\mu^0$ and $\\mu^1$ can be expressed on the top of each embedding ($\\mu^0 = \\nu^i \\circ \\phi_0 = \\nu^0 \\circ \\phi_1$ and $\\mu^1 = \\nu^0 \\circ \\phi_0 = \\nu^1 \\circ \\phi_1$), with all $\\nu^{i}$ of Lipschitz constant $L$ for $i, j \\in \\{0,1\\}$.\nLet $\\hat{h}_0^0$ and $\\hat{h}_0^1$ (respectively $\\hat{h}_1^0$ and $\\hat{h}_1^1$) denote the learned models of $\\nu_0^i$ and $\\nu_1^j$ in $P_0$ (resp. $\\nu_0^0$ and $\\nu_1^0$ in $P_1$), with Lipschitz constant $\\hat{L}$.\nFor any i-th sample in the observation dataset D, define\n$\\overline{\\tau}_i = (1 - t_i) ((\\hat{h}_0^0 \\circ \\phi_0)(x_i) - Y_i) + t_i (Y_i - (\\hat{h}_1^1\\circ \\phi_1)(x_i))$\nLet us further define the counter-factual importance weight of sample $(x_j,t_j,Y_j)$ as the number of samples $(x_i,t_i,Y_i)$ such that $t_i = 1 - t_j$ and $x_i$ is the nearest neighbor of $x_j$ according to $\\phi_{t_i}$:\n$w_j = \\#\\{(x_i, t_i, y_j) \\in D s.t. (x_j, t_j, y_j) = (x_i^{m,\\phi_{t_i}}, 1 - t_i, y_i^{m,\\phi_{t_i}})\\}$.\nThen, the within-sample $PEHE$ defined by $\\sqrt{\\frac{5}{n}\\sum_{i=1}^{n} (\\overline{\\tau}_i - \\tau(X_i))^2}$ is upper bounded by $M_2$, with\n$M_2 = \\frac{5}{n}[\\sum_{t_i=0, i=1}^{n} w_i((\\hat{h}_0^0 \\circ \\phi_0) (x_i) - Y_i)^2 + \\sum_{t_i=1, i=1}^{n} w_i((\\hat{h}_1^1 \\circ \\phi_1) (x_i) - Y_i)^2 + (L^2 + \\hat{L}^2) \\sum_{i=1}^{n} ||\\phi_{t_i} (x_i) - \\phi_{t_i} (x_i^{m,\\phi_{t_i}})||^2 + k_Y]$\nwhere $k_Y = \\sum_{i=1}^{n} (1 + w_i) (Y_i - \\mu^{t_i} (x_i))^2$.\nAs said, Thm. 2 holds in the within-sample setting, as it requires knowledge of the treatment assignment T. It does not generalize directly to the out-of-sample setting, where the (unknown) $t_i$ and $y_i$ are respectively estimated using the propensity and the outcome models."}, {"title": null, "content": "Theorem 3. There exists a hyper-parameter setting $(\\alpha_0, \\alpha_1, \\beta_0, \\beta_1)$ such that the within-sample empirical $PEHE$ is upper bounded by $M_3$, with:\n$M_3 =\\frac{5}{n}[L(P_1) + L(P_0) - \\gamma_0\\|\\Omega_{P_0}\\| - \\gamma_1\\|\\Omega_{P_1}\\| + k_Y$\\n$- \\frac{1}{n}(\\sum_{t_i=0, i=1}^{n} w_i((\\hat{h}_0^0 \\circ \\phi_0) (x_i) - Y_i)^2 - \\sum_{t_i=1, i=1}^{n} w_i((\\hat{h}_1^1 \\circ \\phi_1) (x_i) - Y_i)^2$\\n$- \\frac{1}{n}(\\sum_{t_i=1, i=1}^{n} w_i((\\hat{h}_0^1 \\circ \\phi_1) (x_i) - Y_i)^2 + \\sum_{t_i=0, i=1}^{n} w_i((\\hat{h}_1^0 \\circ \\phi_0) (x_i) - Y_i)^2)]$\nNote that this result is not constructive in the sense that it does not give the hyper-parameter setting. Nevertheless, the relation between this bound on the PEHE and the terms in the pipeline loss confirms the soundness of the approach. This bound also depends on the Lipschitz constants of the learned models and of the target models (which only depend on the problem)."}, {"title": "Discussion", "content": "The formal guarantees established by Thm 1-3 contrast with the main result of Shalit et al. Shalit et al. (2017) in two ways. A first difference is that Shalit et al. (2017) relies on the invertibility of embedding $\\phi$. In contrast, ALRITE only assumes that the considered embeddings $\\phi$ are such that the sought models can be expressed with no loss of information (there exists $\\nu^0$ and $\\nu^1$ s.t. $\\mu^i = \\nu^i \\circ \\phi$). As a result, ALRITE can fully benefit of the celebrated opportunities offered by a change of representation (Cayton, 2008; Bengio et al., 2013), e.g. to achieve feature selection or dimensionality reduction."}, {"title": "Experimental validation", "content": "After describing the two benchmarks we considered, IHDP and ACIC2016, and the experimental setting, this section reports on the empirical validation of ALRITE. The ALRITE code is publicly available."}, {"title": "Benchmarks", "content": "The IHDP dataset is the baseline dataset commonly used for benchmarking causal inference models (Shalit et al., 2017; Du et al., 2021; Zhou et al., 2021). The ACIC2016 benchmark originates from the 2016 Atlantic Causal Inference Challenge (Dorie et al., 2017).\n4.1.1 IHDP\nThe IHDP dataset, introduced by Hill (2011), is based on a real-life randomized experiment dataset, the Infant Health and Development Program (Brooks-Gunn et al., 1992). The treatment consists of quality child care and home visits on the health and development of preterm children. While the treatment assignment is randomized in the collected data, treatment imbalance is enforced by Hill (2011), by removing a subpopulation (treated group children with non-white mothers) from the dataset.\nThe dataset contains 747 individuals, 139 of whom are treated; these are described by 25 covariate features, among which 6 are continuous and 19 binary.\nThe major difference between the original survey results and Hill (2011)'s IHDP dataset lies in the replacement of the initial outcome with simulated outcomes, making it possible to access counter-factual quantities and ensuring that conditional exchangeability holds. The selected simulation method consists in defining two response surfaces $\\mu^t : x \\in X \\mapsto E[Y^t|X = x], t \\in \\{0,1\\}$, to which Gaussian noise is added.\nWe consider the IHDP-100 benchmark, involving 100 datasets (referred to as problem instance or instance when no confusion is to fear), where each dataset is generated by: i) drawing $\\beta$ in $[0, 1]^{25}$; ii) setting the surface responses as:\n$Y^0 \\sim exp\\{(X + 0.5, \\beta)\\} + N(0, 1)$\n$Y^1 \\sim (X + 0.5, \\beta) + \\omega + N(0,1)$, with $\\omega$ s.t. average treatment effect $ATT = 4$\nEach dataset is split into a training (90% of samples) and a testing (10%) subset, the split being fixed to enable a fair comparison among the algorithms. Following the state of the art, 30% of the training set is held out to form a validation set.\nThe main performance indicators are the within-sample and out-of-sample PEHE, respectively computed on the training samples (where the treatment assignment and factual outcome are known, and the counter-factual outcome is unknown) and on the test set (where the treatment assignment and both outcomes are unknown). Following the state-of-the-art (Shalit et al., 2017; Du et al., 2021; Zhou et al., 2021), the results are averaged over the 100 datasets.\nA secondary performance indicator on the IHDP benchmark is the mean absolute error on the ATE estimation $CATE$ (Eq. 1). Note that ATE is notorious for being subject to systemic estimation bias: $\\epsilon_{ATE}$ favors low-bias models (as opposed to $PEHE$, that favors low-variance models).\nSome criticisms have been presented in the literature concerning IHDP (Curth et al., 2021b):"}, {"title": "ACIC2016", "content": "ACIC2016, designed for the 2016 Atlantic Causal Inference Challenge (Dorie et al., 2017), aims to compare different causal inference protocols. Like IHDP, ACIC2016 is a set of problem instances, generated as follows: 77 data generation"}, {"title": "Alrite: Hyper-parameter setting", "content": "The detail of the hyper-parameters and computational framework is given in Appendix B. Pipelines $P_0$ and $P_1$ are trained independently, and implemented as neural networks with Exponential Linear Units (ELU) activation functions (Clevert et al., 2015).\nThe architecture hyper-parameters include the number $L$ of layers and the layer width $W$ (same for all layers), with normalization of the last layer of the embeddings and of the outcome models.\nThe training hyper-parameters include the initial learning rate, the batch size and the number of epochs. Training is conducted using Adam (Kingma and Ba, 2014), with exponential weight decay. Overfitting is prevented using a validation set $D_V$ including 30% of the training set, and using the factual error to select the model after a fixed number of epochs.\nThe propensity estimate is trained using mainstream supervised learning; logistic regression, k-nearest neighbors, and decision trees are considered. The model retained is determined by grid-search using a cross-validation scheme for each considered dataset."}, {"title": "Experimental results", "content": "The average performance of ALRITE on all IHDP instances is reported on Table 1, compared with all other baselines13. On this dataset, ALRITE ranks first on within-sample $PEHE$ and second on out-of-sample $PEHE$. Indeed, ALRITE is designed to optimize the $PEHE$ performance indicator, as motivated by Thm. 1. The comparatively lesser performance regarding within-sample and out-of-sample $\\epsilon_{ATE}$ is blamed on the L2 regularization (more in Section 4.5), tending to bias the estimates toward 0, as noted by Laan and Rose (2011).\nAs could be expected Breiman (2001), ensemble variants of ALRITE intro-duced in Section 3.3 improve on ALRITE. The $PEHE$ and (factual) accuracy depending on their hyperparameters (number $K$ of models in the top-K ensemble, temperature $\\Lambda$ for the softmax weighted combination) are reported on Fig. 7 (one point per value of the hyperparameter).\nThis figure suggests that the factual accuracy can reliably be used to select the hyperparameter ($K = 4$ for the top-K ensemble and $\\Lambda = 100$ for the softmax ensemble) yielding the best $PEHE$. For these selected hyperparameters, the $PEHE$ is statistically significantly better than ALRITE with p-value= 1.3e \u2013 3 on a one-sided paired t-test.\nLikewise, the average performance of ALRITE on all ACIC2016 instances is reported on Table 2, compared with all other baselines. On this dataset, ALRITE ranks second for $PEHE$ both within-sample and out-of-sample, behind"}, {"title": "Discussion", "content": "As we said, the comparatively poorer performance of ALRITE over ATE, compared to PEHE, is blamed on the regularization term (term $\\gamma\\|\\Omega_{P_1}\\|$ of the training loss, Eq. 5), which aims to avoid overfitting. This interpretation is confirmed by complementary experiments Lacombe (2024)."}, {"title": "Conclusion", "content": "The main contribution of the proposed approach lies in the observation that, when treatment assignment is not uniform, counterfactual estimation for control and treated samples induces two distinct problems. ALRITE takes this observation into account through an original neural architecture, hybridizing X-learners and T-learners.\nTwo quantities are thus defined to characterize the quality of a change of representation: the counter-factualizability of a sample, i.e. its distance from its twin in latent space; and the weight of the counterfactual importance of a sample x, counting how many samples admit x as a twin. Finally, the models are learned by optimizing a learning loss that imposes a good change of representation: the aim is to ensure good counter-factualizability of all samples, and to ensure that the factual model is all the more accurate on examples with higher counterfactual importance weights.\nLearned models benefit from theoretical guarantees, noting that the upper bound of PEHE involves the same terms as those involved in the learning loss. Last, the merits of the approach are experimentally demonstrated on the main two benchmarks of the domain, compared with the prominent approaches of the state of the art. A word of caution: the approach is not suited to uniform treatment assignment: in this case, the two counterfactual estimation problems are in fact the same, and the two-pipeline ALRITE runs the risk of overfitting.\nSeveral research perspectives are opened up by ALRITE. One short-term per-spective is to jointly learn both pipelines, thus promoting their complementarity.\nAnother perspective is to revise the notion of latent twin, which currently involves only the nearest neighbor of the sample under consideration. A more robust approach would be to consider several nearest neighbors of a sample in the latent space (e.g. using a Gaussian kernel) and revise the counterfactual importance weight of neighboring samples accordingly.\nA third perspective concerns the notion of uncertainty. The minimization of CATE uncertainty is at the heart of the proposed change of representation, which aims to strengthen the counter-factualizability of samples. An alternative could be based on the different models involved in the ALRITE ensemble, using them to assess uncertainty on factual and counterfactual estimates for any particular sample.\nLastly, the extension of the approach to the multi-level treatment setting can be tackled, considering one pipeline per treatment level, plus one for the control setting."}, {"title": "Appendix", "content": "A.1 Proofs\nA.1.1 Proof of Thm. 1\nProof. Let (x", "comes": "n$|(\\hat{\\mu"}, 1, "hat{\\mu}^0)(z) \u2013 (\\nu^1-\\nu^0)(z)|^2$\n= $|[\\hat{\\mu}^1 (z)-\\nu^1 (z)"], "representations": "phi_1(x_i) = z_i", "comes": "n$(\\overline{\\tau"}, {"comes": "n$\\frac{1}{n}\\sum_{t_i=1}^{n} (\\overline{\\tau"}]