{"title": "GPT for Games: An Updated Scoping Review (2020-2024)", "authors": ["Daijin Yang", "Erica Kleinman", "Casper Harteveld"], "abstract": "Due to GPT's impressive generative capabilities, its applications in games are expanding rapidly. To offer researchers a comprehensive understanding of the current applications and identify both emerging trends and unexplored areas, this paper introduces an updated scoping review of 131 articles, 76 of which were published in 2024, to explore GPT's potential for games. By coding and synthesizing the papers, we identify five prominent applications of GPT in current game research: procedural content generation, mixed-initiative game design, mixed-initiative gameplay, playing games, and game user research. Drawing on insights from these application areas and emerging research, we propose future studies should focus on expanding the technical boundaries of the GPT models and exploring the complex interaction dynamics between them and users. This review aims to illustrate the state of the art in innovative GPT applications in games, offering a foundation to enrich game development and enhance player experiences through cutting-edge AI innovations.", "sections": [{"title": "I. INTRODUCTION", "content": "THE advent of large language models (LLMs) presents new opportunities for games. Leveraging their powerful natural language processing and generative capabilities [1], LLMs have demonstrated remarkable versatility across various applications [2], including information extraction [3], question-answering [4], [5], text generation [6], programming tasks [7], and creativity support [8], [9]. This versatility underscores their potential to impact various aspects of games [10], where many tasks such as programming, story writing, and game-player interactions involve a large amount of text-based work. Moreover, the unique generative capabilities of LLMs present distinct opportunities for both game design and gameplay, enabling them to potentially move beyond pre-set, mechanical content and introduce innovative, dynamic elements that bring fresh ideas to both game designers and players.\nAmong all LLM models, the Generative Pre-trained Transformer (GPT) series including GPT-2 [11], GPT-3 [12], ChatGPT, GPT-3.5, and GPT-4 [1] has seen the most frequent and widespread applications in games [10]. This is largely due to their early release dates [2], [13] and superior performance [14], [15]. Given GPT's strong language processing capabilities [1], [12], it has been extensively used to generate and manage text-based game content, such as character dialogue [75] and entire stories [76], and employed for creative purposes, such as generating design ideas for board games [77] or assisting with programming [78], [79].\nAs the use of GPT in games continues to expand rapidly [10], reviewing emerging cases can help researchers differentiate between recent developments and earlier work, allowing for a more comprehensive understanding of the current state of GPT in gaming and highlighting key trends and gaps. While existing reviews have explored the application of LLMs in games, they often lack systematic searches of published studies [16], focus on a single application area [17], [18], or miss recent research [19], potentially overlooking significant cases from major databases. Our previous review [10] of 55 GPT-for-games papers included a systematic search of mainstream databases but did not capture the most recent studies. Thus, an updated review that incorporates the latest research is essential to provide researchers with a current and informed perspective.\nIn this work, we extend our previous review [10] using the same methodology. We identified 76 new articles that were published in 2024 and incorporated them into this updated version, resulting in 131 papers. Through open coding of the new papers and classifying the generated codes, we did not identify any new use case categories compared to our previous review. Consequently, we assigned these papers to the existing five categories: procedural content generation, mixed-initiative game design, mixed-initiative gameplay, playing games, and game user research. For each category, we present relevant examples, highlight the trends and differences between recent and earlier studies, and suggest new directions."}, {"title": "II. METHODOLOGY", "content": "In our review, we used the keywords \"game\" and \"GPT\" to search for relevant articles across the following databases: ACM Digital Library, IEEE Xplore, Springer, and AAAI. These databases were selected due to their strong reputation in computer science and AI research, offering comprehensive access to papers focused on games and GPT [20], [21]. For ACM, IEEE, and Springer, we performed searches directly through the search engines on their respective websites. However, for AAAI papers, since the AAAI online library lacks an advanced search function, we used Google Scholar as an alternative, restricting the results to articles from aaai.org. In all cases, we conducted full-text searches within the databases.\nAs shown in Figure 1, the preliminary search using the aforementioned keywords resulted in 4,424 papers (2,326 new"}, {"title": "III. RESULTS", "content": "A. General Research Trends of GPT for Games"}, {"title": "B. Use Cases of GPT for Games", "content": "As shown in Figure 3, 49 papers focused on using GPT for procedural content generation (PCG). 29 papers focused on using GPT for mixed-initiative game design and development (MIGDD). 34 papers used GPT for mixed-initiative gameplay (MIG). 14 papers used GPT to playing games (PG). Finally, nine papers used GPT for game user research (GUR). Three papers were counted in both PCG and MIG. One paper was counted in both PCG and GUR.\n1) GPT for Procedural Content Generation (PCG): In this use case, GPT generated game content during gameplay according to constraints defined by the designers during development, without any iteration or human input involved in the generation process [24].\nIn 2024, the majority of research focused on utilizing the latest GPT models for PCG, with ten studies using GPT-4, four using ChatGPT, and nine using GPT-3.5. Only two studies employed GPT-3, and none used GPT-2. In contrast, while 2023 saw an increase in studies using newer GPT models (n = 13), GPT-2 remained a popular choice, particularly for story (n = 2), quest (n = 2), and level generation (n = 2). Prior to 2023, only GPT-2 had been used in this category (n = 6).\nGPT for story generation (n = 23, [75], [76], [80]\u2013[100]). In 2024, nine studies focused on this category, all utilizing the latest GPT models (either GPT-4 or GPT-3.5). Compared to previous work, these new studies demonstrate a stronger connection between GPT-generated stories and game-play. Rather than merely focusing on language style or world-building, the models now incorporate additional game-related information, such as changes in world state or player input, allowing the narrative to adapt to the player's current gameplay context. For example, in [93], the authors implemented a generative broadcasting system using GPT-3.5. In this system, GPT generates news reports, stories, ads, and interviews based on the current game state (events and player actions) as well as a general knowledge base (game setting, characters, and story background). In another example ( [100]), GPT-4 is used in a simulation game to generate career development events by combining player input with real alumni data to create personalized career choices. This high adaptability of text generation presents additional challenges for GPT models, as they must process and respond to real-time game content while generating consistent output. To address these challenges, these studies often integrate GPT with other technologies. For instance, in [100], the authors leveraged various modules from the LangChain [25] framework to enhance GPT-4's capabilities in retrieving career data, generating career plans, and tracking interaction history.\nResearch that enhances GPT's text generation by integrating it with other technologies draws inspiration from earlier studies using GPT-2. Compared to more advanced GPT models, using GPT-2 (n = 5) for story generation required additional efforts, such as fine-tuning and employing supplementary techniques. All studies involving GPT-2 needed fine-tuning to better align the model's output with specific contexts, which demanded a dataset closely related to the research goals [84]. For instance, in [91], GPT-2 was fine-tuned using fantasy stories to create narratives for a Dungeons and Dragons (D&D) game. To address GPT-2's limitations in language processing and memory capacity, additional techniques were employed, such as [76] using a knowledge graph alongside GPT to generate more consistent stories. As shown in Figure 4, the authors first use another AI model called AskBERT to extract a knowledge graph consisting of locations, characters, and objects. Then, GPT-2 is used to generate consistent descriptions of these entities based on the relationships in the graph. Additionally, in [91], BertScore [26] was applied to evaluate GPT-2's outputs, ensuring that only high-quality texts were presented to players, mitigating issues with low-quality content. These techniques are not limited to enhancing GPT-2's performance \u2014 they also hold potential for improving the capabilities of the latest models.\nGPT for quest generation (n = 4, [101]\u2013[104]). Unlike a story, a quest involves a series of actions the player must complete [27]. This distinction makes generating quests using GPT a different task from generating stories. Since there was no new work specifically focusing on quest generation in 2024, we report on earlier studies.\nGPT-2 was the primary model used for quest generation. Common approaches across these studies involved fine-tuning the GPT-2 model on annotated datasets specific to RPG quests and applying prompt engineering to guide the model's output towards objectives and dialogues that align with the structure and style of existing game content. For instance, in [101], the authors experimented with GPT-2 to generate quests within a \"World of Warcraft\" setting. They fine-tuned the model using a quest text corpus, enabling it to produce quests that not only aligned with the game's themes but also retained logical consistency and creativity. Additionally, in [102], researchers explored integrating knowledge graphs for quest generation, allowing the model to incorporate game-world elements such as locations, NPCs, and items into the quests. This method ensured quests were contextually relevant and personalized,\nenhancing player immersion by tailoring content to the game's lore and the player's actions.\nGPT for level generation (n = 6, [105]\u2013[110]). In recent research, published in 2024, the latest GPT models (GPT-3.5, ChatGPT, and GPT-4) have been used to generate levels using only prompt engineering. For example, in [109], the authors discuss how different prompting methods affect the quality of level generation in Angry Birds [28], a physics-based game where players launch birds to knock down pigs. They found that the data store and retrieval method, which involves pre-storing level components and allowing GPT to retrieve the appropriate ones, resulted in the most stable and high-quality levels. Beyond 2D level generation, [108] introduces a method for generating 3D Minecraft [29] buildings, which could potentially be adapted for 3D level generation. GPT-4 converts a simple user description (such as specifying only building materials) into a detailed description that includes the size, structure, and materials of the building. It then transforms this detailed description into a JSON file, which is used by Python to build the structure in Minecraft. The model also includes a repair module to fix errors, ensuring accurate generation of elements like walls and doors. However, the integration of 3D level generation with gameplay still requires further exploration.\nOlder models like GPT-2 and GPT-3 require fine-tuning with text-encoded designs for game level generation. For example, [105] presents MarioGPT, a fine-tuned GPT-2 model used to generate Super Mario Bros levels, as shown in Fig. 5. By utilizing text-based representations of level elements, this model allows levels to be created through natural language prompts, offering precise control over design elements like enemy placement and terrain features. This highlights the potential of text-based representations to enhance procedural content generation and suggests possibilities for combining them with newer models to improve performance.\nGPT for character generation (n = 15, [90], [111]\u2013[124]). In 2024, the use of GPT to generate in-game characters has attracted significant research attention (n = 12). Unlike previous approaches that focused only on generating character descriptions and settings, most recent work (n = 10) used GPT to drive characters in games, enabling them to act in ways consistent with their personality and backstory. This includes generating behaviors such as dialogue, actions, and adjustments to relationships with other NPCs. For example, in [115], the authors assigned each NPC a backstory, personality, and a series of ordered goals and conditions. GPT-4 then used this information to generate dialogues for these characters. Beyond simply providing basic character information, other techniques were introduced to preserve the characters' personalities better and prevent hallucinations over extended gameplay. In [120], for instance, the authors implemented a behavior tree, ensuring GPT only generates dialogue when a player triggers specific actions, thus maintaining control over the output. In [113], a unique memory storage mechanism was designed, where GPT summarizes recent conversations (stored in a short-term memory), transfers a condensed version to a long-term memory, and then removes the recent dialogue. When generating new dialogue, GPT retrieves data from both memory storage, producing responses that reflect its accumulated experiences. This human-like memory behavior helps ensure continuity in long-term interactions, allowing GPT to generate more human-like responses. Furthermore, in [122], the authors considered interactions between multiple NPCs. As shown in Fig. 6, they designed a social simulation system where NPCs exist in various states. GPT generates dialogues based on these states, which in turn influence and alter the states of other NPCs based on the conversation's outcome. Besides generating dialogue, GPT can also assist in character animation. For example, in [114], the authors use GPT-3.5 to generate facial expression descriptions based on the Facial Action Coding System [30] (FACS) and body movement descriptions based on Laban Movement Analysis [31] (LMA), considering the dialogue and the character's personality. Game engine plugins can further process these descriptions to create the actual facial expressions and body movements for NPCs. GPT can also be used to generate characters' backstories and settings. For instance, in [90], ChatGPT was employed to generate various character attributes in a D&D game, including race, alignment, gender, ability scores, and equipment. In [123], ChatGPT"}, {"title": "generated key traits for characters, such as likes, dislikes, and abilities, which defined their behavior and personality in the game. It was also used to generate prompts, which were fed to the Stable Diffusion model [32], for character image creation.", "content": "GPT for other PCG Uses (n = 2, [125], [126]). Our previous review revealed two other instances of GPT being used to generate content for games. No new research focused on other PCG uses. In the first case [125], GPT was employed for music generation. The authors introduced Bardo Composer, a system that creates background music for tabletop role-playing games. It utilizes a speech recognition system to convert player dialogue into text, which is then classified based on an emotional model. The system generates music that conveys the desired emotion using a novel Stochastic Bi-Objective Beam Search algorithm [33]. In the second case [126], GPT was used to generate real-time commentary. The authors developed a prompt engineering approach with GPT-3.5 to produce dynamic commentary for fighting games. Their work highlighted the significant impact of prompt design on the quality of the generated commentary, with users show-ing a preference for simpler prompts to create more engaging experiences.\n2) GPT for Mixed-Initiative Game Design and Development: Similar to the previous category, GPT was employed to generate content for design and development purposes. However, unlike the previous category, the content generation followed an iterative process, where the designer collaborated with GPT through multiple rounds to create the final content, which was later incorporated into the game [34]. In 2024, the number of papers in this category slightly increased, with 18 papers published. Of these, five used GPT-4, seven used GPT-3.5, three used ChatGPT, and one each utilized GPT-3 and GPT-2."}, {"title": "GPT assistance in creating game scenarios (n = 15, [127]-[141]). The most direct application uses GPT to assist with writing scenarios for game stories. A simple exam-ple can be found in [140], where the authors used GPT-3.5 to generate stories directly and deliberately retained certain hal-lucinations (incorrect information) produced by the language model. This was done as part of a game designed to investigate players' perceptions of deceptive behavior. In [139], the au-thors created a visual narrative structure diagram to assist users in story writing. The story generated by GPT included multiple branches, and users could adjust parameters like the number of branches by modifying the diagram's settings. Another noteworthy example is in [141], where the authors designed two distinct story creation modes for scriptwriters with varying levels of experience. For less experienced writers, GPT offered more extensive support, allowing them to input only minimal story details as a starting point, while GPT actively generated elements such as characters and scenes. For more experienced writers, GPT played a more passive role, providing summaries and assistance without interfering with their creative process. This demonstrates that GPT's support can be adjusted to better serve different user needs in game design [35].", "content": "In addition to text outputs, GPT can assist in generating game scene layouts. For example, in [132], GPT-4 is used to help design 2D tile maps based on natural language de-scriptions. GPT-4 first understands the rules for placing tiles by interpreting different pre-designed tiles from the natural language input, and then selects suitable tiles according to the user's description to create a text-represented 2D map. GPT has also been employed to assist in creating 3D scenes, as shown in Fig. 7. In [136], multiple GPT-4 agents are used. When the user inputs a natural language description requesting changes to the scene, one agent breaks down the description into several subtasks while another analyzes the objects in the current scene and selects the appropriate skills from an existing library (such as finding existing models or generating textures for models). This framework not only allows users to generate a 3D scene from scratch but also enables them to modify existing scenes.\nBeyond assisting with simple scene creation, GPT is used to aid in designing levels, which are scenes related to game mechanics. While level design does not require generating new game mechanics, it does require GPT to understand and apply existing mechanics to create coherent scenes. For instance, in [134], the authors used GPT-3.5 to interpret natural language inputs from users and call predefined functions (such as adding rooms or modifying enemies) based on user requests to help design levels in the style of Darkest Dungeon 1 [36]. Through multiple interactions, users collaboratively designed each element of the level step by step with GPT, including rooms, enemies, and treasure chests.\nGPT assistance in designing game mechanics and rules (n = 7, [77], [142]\u2013[147]). Two studies published in 2024 used GPT to assist in designing game mechanics and rules [146], [147]. In [146], the authors applied few-shot prompting (where a few examples are included in the prompt) to guide GPT-4 in generating a game description using VGDL [37], a game description language framework for both rules and levels. The interaction was achieved by providing GPT-4 with a simple game description and a few VGDL examples. In [147], ChatGPT was employed to suggest additional mechanics for simple games. For example, GPT added teleportation and"}, {"title": "time manipulation mechanics to a space shooter game that originally featured only movement and shooting. GPT was also used to assist in programming these mechanics. The authors further conducted a user study of the improved games and found that GPT's suggestions enhanced the playability of simple games and inspired human designers.", "content": "However, recent research has not yet explored combining GPT with other technologies or design frameworks to generate game mechanics, which we discovered in our previous review. For example, in [143], GPT was leveraged to design gamified mechanics for debugging and troubleshooting activities in software engineering, using prompt engineering based on Dal Sasso et al.'s [38] gamification design framework. [144] used an evolutionary algorithm with GPT to create playable board games. GPT generated a set of random game design proposals, which were scored by players. Using tournament selection [39], two designs were combined to form a new proposal, and mutations were introduced to modify the de-sign. This process repeated for 30 cycles, resulting in 40 game design proposals. Alternatively, in [77], GPT followed the Design Sprint framework [40] for board game design.\nGPT performed tasks in five phases: research existing games (understand and diverge), create a constrained board game (converge and prototype), reflect on the design (test), and update the game based on reflections and player feedback through iterative mixed-initiative interaction.\nGPT assistance with programming tasks (n = 10, [78], [79], [136], [145], [147]\u2013[152]). Some studies [136], [145], [147] have integrated programming support directly into tools for scene creation or game mechanics development. For in-stance, the research discussed in previous sections on 3D scene creation [136] and suggestions for basic game mechanics [147] included code implementation and programming assistance within their systems. Regarding programming assistance, [78] provides a detailed account of the opportunities and challenges of using GPT for programming support in VR development. They found that GPT can significantly assist novice developers by offering guidance on coding, troubleshooting, and feature implementation, helping them overcome common challenges in Unity-based VR development. However, for more complex VR tasks, such as handling interactive elements and real-time physics, GPT may provide inaccurate advice or incomplete responses, requiring additional user oversight.\nBeyond direct coding support, three examples are worth mentioning [149], [151], [152]. In [149], the authors intro-duced GlitchBench, a new benchmark designed to test the ability of multimodal LLMs to detect glitches in video games. In this benchmark, the LLM must identify and report visual inconsistencies or anomalies, such as rendering errors, object misplacement, and physics glitches in game screenshots. The authors found that GPT-4 achieved the highest accuracy, although it could correctly detect only 43.4% of the glitches. In the future, enhancing the model's detection capabilities could facilitate its use in game quality testing and debug programming. In [151], the authors use ChatGPT to generate reward functions for a deep reinforcement learning (DRL) algorithm [41] based on in-game information, assisting in the training of DRL agents. ChatGPT first generates initial reward functions based on textual descriptions of the game and environmental variables. The DRL agents then interact with the game environment using these reward functions, gradually optimizing their strategies. In [152], the authors used GPT-3.5 to generate dialogue data based on character and scene cards, which provided detailed descriptions of person-alities, speaking styles, goals, and obstacles within the Call of Cthulhu (CoC) settings. These generated dialogues were then used to fine-tune Baichuan-7B, a smaller language model. This ultimately enabled Baichuan-7B to produce contextually consistent, character-coherent, and narratively rich dialogues, comparable in quality to GPT-3.5.\n3) GPT for Mixed-initiative Gameplay: Unlike the previous section, which leverages GPT to aid in design, this section focuses on GPT as an aid during play. Compared to previous years, 2024 has seen a significant increase in attention to this category, with 24 new papers published. All except one of these works utilize the latest models, including GPT-4, GPT-3.5, and ChatGPT, aligning with our previous review's prediction that this category would trend toward using cutting-edge models [10].\nGPT to aid story co-creation in games (n = 19, [153]-[171]). Story co-creation involves players and GPT taking turns to contribute to a story, adding sentences or paragraphs to the narrative. The process typically begins with a prompt, either provided by GPT or the players, to start the story. GPT then generates new content by using the existing story as input for its next contribution. For example, in [164], the authors designed Snake Story, a story co-creation game combined with the mechanics of the classic Snake game. As shown in Figure 8 GPT offers two text options based on the story so far, which appear as food for the snake in the game. The player must control the snake to \u201ceat\u201d one of the options, thereby adding it to the story.\nIn 2024, new research has started to move beyond simply co-creating stories with GPT. For instance, in [162], the author developed Eternagram, a story co-creation game that assesses players' attitudes toward climate change through story co-creation. As players progress, they gradually develop a future world devastated by climate change with GPT-4. The research showed that this gamified approach could explore players' perspectives on climate issues in depth. In the context of education, in [170], the authors developed Mathemyths,"}, {"title": "where children learn mathematical language through story co-creation. The main plot structure is based on an \u201cadventure\u201d genre, where children, alongside GPT-4, help the protagonist complete tasks (like finding treasure) while answering simple math questions (such as addition and subtraction) related to the story. Similarly in the educational space,, [171] presented Hacc-Man, a game centered around the concept of \"jail-breaking\" LLMs. Players interact with GPT through a retro arcade-style computer, attempting to coax GPT into unethical or unsafe behavior, such as tricking it into revealing another patient's health information in a hospital scenario. Overall, these studies highlight the potential of GPT-driven games to engage the public in reflections on and discussions about serious topics.", "content": "GPT for providing feedback and guidance to players in games (n = 12, [117]\u2013[119], [172]\u2013[180]). In 2024, feedback and guidance, especially within educational games, have gar-nered significant attention, with all papers in this subcategory published this year. For instance, in [176], the authors discuss the integration of GPT into game-based learning environments to offer personalized, subject-specific feedback on players' in-game actions, answer their questions during gameplay, and provide relevant explanations or demonstrations based on the game's tasks and learning content. The study shows that players in GPT-assisted environments exhibit stronger intrinsic motivation and cognitive engagement compared to those in purely game-based settings. Additionally, some work has combined this approach with PCG characters, as intro-duced in Section III-B1, allowing in-game characters to deliver feedback rather than relying on an external system, which enhances the game's immersion. For example, in [119], GPT takes on the role of Chang'e, the Moon Goddess from Chinese mythology. Through correspondence with Chang'e, players learn about astronomy and environmental science. Throughout the interaction, GPT maintains the character's linguistic style, using phrases like \"with lunar love\" to reinforce Chang'e's identity and increase the believability of the character.\nAside from serious games, two works are worth mentioning. In [175], the authors used GPT to simulate a player's inner monologue in a 3D creepy hotel game environment. When players triggered events, such as opening doors or inspecting objects, GPT-4 would generate insights, comments, or sugges-tions in the form of self-talk, aiding the player's progression and advancing the narrative. In [174], the authors utilized GPT-3.5 to handle natural language commands given by players to NPCs, adjusting the NPCs' strategic priorities accordingly. For instance, when a player says, \u201cprotect me,\" the system increases the priority of defensive goals for the NPC. In all, these works demonstrate the potential of GPT to transform gameplay and enhance the overall player experience.\nGPT to support game masters (n = 3, [181]-[183]). In this category, with one new study published in 2024 [183], GPT was applied to assist Game Masters (GMs) in Dun-geons & Dragons (D&D) or other tabletop role-playing games (TTRPGs). These studies explored how GPT-3 and ChatGPT can provide creative support by generating enemy descriptions and configurations, summarizing game scenarios, and brain-storming narrative elements. For instance, in [181], GPT-3 was used to simplify and summarize the descriptions of monsters from the D&D rulebook, helping DMs quickly grasp key details. Additionally, ChatGPT was employed to assist DMs in brainstorming encounter storylines. The authors developed separate interfaces for each function and created distinct prompts to enable GPT to perform these tasks effectively. Notably, in a recent study [183], the authors explored the use of ChatGPT as an independent GM for D&D without human assistance. They configured different characteristics for GPT-based GMs, including a base model, one agent inclined to support any player requests, and another that adhered strictly to the original story settings. The results showed that both specialized agents enhanced player experience compared to the base model, highlighting new potential interactions between GPT, GMs, and TTRPG players.\n4) GPT as a Game Player: Works in this category explored how GPT can autonomously play games or serve as a virtual opponent. In 2024, most work (n = 7) used the latest GPT models, including GPT-4 and GPT-3.5, except one that used GPT-2. In previous years, most of the work (n = 4) in this category utilized GPT-2.\nGPT for playing text-based games (n = 10, [184]-[193]). In 2024, six studies explored GPT playing text-based games, focusing on logical reasoning and social cognition. For instance, in [109], the authors used prompt engineering to enable GPT-4 to play Codenames, a cooperative word-guessing game. In this game, one agent provides clues to help another agent guess target words. The research revealed that while different prompts did not significantly impact GPT's reasoning or natural language understanding abilities, they did influence its play style. In [190], GPT was tasked with playing several games related to theory of mind [42] to assess its social cognition. The authors found that GPT-4 demonstrated stronger social reasoning abilities compared to models like ERNIE-Bot [43] and ChatGLM [44], using social relationships to infer the actions of others. Previous research has also featured gameplay scenarios such as deducing a word from its description [184] and compelling a defender to utter a specific word while they attempt to avoid doing so [185].\nGPT for playing non-text-based games (n = 4, [194]\u2013[197]). We identified four studies that utilized GPT for playing various games, including 3 published in 2024 [194]-[197] and one published in 2020 [194]. In [195], the authors in-troduced Verbal Apprentice Learner (VAL), a GPT-powered system designed to learn from users through natural language interactions. VAL was tested in a simplified version of the cooking game Overcooked [45], where players guided it using natural language instructions, progressively teaching it how to perform game actions (e.g., picking up an onion, placing it in a pot, turning on the stove). The results showed that VAL could incrementally acquire knowledge from a small number of examples and apply it to new situations. In another example, [196] employed GPT to play a simplified version of the card game Slay the Spire [46]. Game states such as card draw information, mana consumption, status effects, and deck descriptions were provided to GPT as part of the prompt to assist in decision-making. The authors found that GPT showed potential as an automated testing agent for card games,"}, {"title": "potentially reducing the workload involved in game testing. As a third example, in [197], GPT was used to play Angry", "content": "Birds [28", "194": "presented an approach where GPT-2 was used to generate plausible strategic moves in the game of Go. By training on a dataset of Go game records in Smart Game Format (SGF)", "Research": "Even with the inclusion of six new papers from 2024, studies focusing on GPT for game user research remain scarce, with only nine papers in total addressing this category. These studies predominantly utilize newer models, with GPT-2 not used in this category.\nGPT for processing game reviews (n = 3, [198", "200": ".", "198": "."}, {"198": "the authors used ChatGPT to generate recommended reviews for the Ant Forest game, a mobile game that rewards eco-friendly actions with virtual energy, which is then used to plant real trees in reforestation projects. The study found that recommendations generated by ChatGPT were perceived to have higher content quality, and users tended to prefer AI-generated recommendations over human-generated ones. From the previous review, in [199", "47": "based on players' game reviews. In another example from the previous review, [200", "115": [201], "202": ".", "201": "GPT was employed to assess whether players' actions in a TTRPG aligned with their character settings. The authors used controlled chain of thought prompting (CCoT) for the purpose. First, GPT generated several possible behaviors based on the character's faction setting, then, GPT analyzed the player's actual in-game dialogue to check if it matched the predicted behaviors. Finally, GPT was asked to summarize its findings and develop a more general understanding of the character's faction. In [202"}, {"115": "the authors used GPT to summarize interaction logs from a story co-writing game. Based on these summaries, they built narrative graphs to describe player behavior in the game. By comparing these graphs with the original game narrative, they could identify emerging nodes-new, unplanned strategies or interactions introduced by the players. While these studies demonstrate GPT's potential to analyze and interpret player behavior in unique ways, they also highlight its limitations in fully cap-turing emotional intensity and nuanced player strategies.\nGPT for other game user research. (n = 3, [203", "205": ".", "203": [204]}, {"203": "GPT-4 was used to classify toxic messages in games. The authors applied the Prompt Evolution Through Examples (PETE) method to optimize the prompt. Specifically, the system started with an initial prompt, generated variant versions, and selected the most effective one based on performance in the task. Through multiple iterations, the prompt was gradually optimized, improving the model"}]}