[{"title": "Dy-mer: An Explainable DNA Sequence Representation Scheme using Sparse Recovery", "authors": ["Zhiyuan Peng", "Yuanbo Tang", "Yang Li"], "abstract": "DNA sequences encode vital genetic and biological information, yet these unfixed-length sequences cannot serve as the input of common data mining algorithms. Hence, various representation schemes have been developed to transform DNA sequences into fixed-length numerical representations. However, these schemes face difficulties in learning high-quality representations due to the complexity and sparsity of DNA data. Additionally, DNA sequences are inherently noisy because of mutations. While several schemes have been proposed for their effectiveness, they often lack semantic structure, making it difficult for biologists to validate and leverage the results. To address these challenges, we propose Dy-mer, an explainable and robust DNA representation scheme based on sparse recovery. Leveraging the underlying semantic structure of DNA, we modify the traditional sparse recovery to capture recurring patterns indicative of biological functions by representing frequent K-mers as basis vectors and reconstructing each DNA sequence through simple concatenation. Experimental results demonstrate that Dy-mer achieves state-of-the-art performance in DNA promoter classification, yielding a remarkable 13% increase in accuracy. Moreover, its inherent explainability facilitates DNA clustering and motif detection, enhancing its utility in biological research.", "sections": [{"title": "1. Introduction", "content": "DNA sequences harbor the genetic and biological information imperative for the development and functioning of organisms, dictating traits and orchestrating biochemical processes Dictionary [2002]. Typically, DNA adopts a double helix structure composed of two intertwined alternating deoxyribonucleotide strands. A nucleotide comprises a sugar (deoxyribose), a phosphate group, and one of four nucleobases-adenine (A), cytosine (C), guanine (G), or thymine (T). Biologists assert that permutations of nucleotides encode vital biological information crucial for RNA transcription and protein synthesis. However, raw DNA sequences are inherently variable in length, which cannot be inputted into common data mining models. Hence, researchers design various DNA representation schemes to transform DNA sequences into numerical representations of equal length and decipher DNA sequences for multiple DNA-related tasks, including DNA similarity analysis Jin et al. [2017] and classification Sun et al. [2021a].\nThough designing a representation scheme is crucial, it also presents several challenges. DNA sequences inherently possess a high-dimensional structure characterized by their diverse composition, permutations, and varying lengths. However, high-quality DNA datasets are often limited. It is challenging for DNA representation schemes to extract abundant features from such complex and sparse data. Furthermore, DNA sequences are inherently noisy, because of frequent mutations, such as insertions, deletions, and point mutations. Therefore, the DNA representation scheme should be effective and robust, otherwise, it could significantly undermine representation quality.\nEven with such challenges present, many works have recently been proposed. For instance, A scheme employed Empirical Mode Decomposition to extract features from original nucleotide permutations, enabling the identification of characteristic segments within DNA sequences Bai et al. [2011]. Le et al. Le et al. [2019] utilized sliding windows to obtain subsequences, known as K-mers Chor et al. [2009], Mapleson et al. [2017] and applied FastText N-Grams to convert them into vectors. Finally, the model aggregates all vectors to represent each DNA sequence. Although existing representation schemes demonstrate promising performance in downstream tasks, they frequently lack interpretable data structures, instead relying on attention or gradient mechanisms of application-specific data-mining algorithms Xiao et al. [2021], Santorsola and Lescai [2023] to implicitly measure each feature's contribution. It hinders biologists' ability to validate and leverage the insights derived from these representations.\nIn this paper, we propose Dy-mer, an explainable and robust DNA representation scheme based on sparse recovery Cand\u00e8s et al. [2006], Donoho [2006], Chu and Stormo [2022] to address these challenges. The main idea of sparse recovery is to recover the underlying sparse structure from raw data and obtain the sparse representation, under the assumption that the original signal can be sparsely represented by a well-designed basis. While classic sparse recovery methods Cui et al. [2023], Zhou et al. [2021], Xie et al. [2018] enhance the robustness of representations by leveraging various mathematical techniques to ensure the low rank and sparsity of the representation based on a randomly initialized basis, their interpretability is often compromised for obtaining unstructured and dense basis.\nOur method innovates upon the traditional sparse recovery framework. In our approach, basis vectors represent a subset of K-mers encoding potential DNA underlying structure and biological information. Basis vectors are initialized with frequent K-mers observed in real-world settings and are optimized to capture the most frequent and semantically meaningful ones. This idea originates from the observation of patterns in DNA sequences: Biologists have identified several recurring K-mers consistently performing analogous functions, such as transcription factor binding sites (TFBS). These recurring patterns, represented as motifs D'haeseleer [2006], Schneider [2002], play a crucial role in DNA regulation. Therefore, it is appropriate to reconstruct DNA sequences as concatenations of semantic local K-mers. For batch DNA processing, Dy-mer introduces a tensor-based data structure and corresponding mathematical operations. The tensor records the positional assignment relationship of K-mers and the operations are designed to simulate the concatenation.\nHowever, in the previous sparse recovery based representation scheme, a well-constructed basis is essential to obtain a high-quality representation for the accurate reconstruction of original DNA sequences and the elucidation of their intrinsic semantic meaning. However, in the sparse recovery based approach, the basis is sampled frequent K-mers from DNA sequences, which is heavily influenced by the configuration of hyperparameters, which introduces uncertainty regarding the attainment of an optimal basis and may affect the quality of learned representations. Sampling too many K-mers can lead to redundant and dependent K-mers such as AAAAAA and AAAA, unnecessarily increasing the basis size and representation dimensionality. Conversely, sampling too few may fail to capture the complexity of DNA sequences. Moreover, the sampling process is both time-intensive and space-consuming, compromising efficiency. In addition, the SR-based scheme may struggle to obtain a high-quality basis and generate effective representations in small-scale datasets or resource-limited scenarios. To address this limitation, we propose another method based on the sparse dictionary learning algorithm. Sparse dictionary learning algorithm aims at learning a dictionary from the input data, to map each data into its corresponding sparse representation. Many works have already utilized sparse dictionary learning to obtain the optimal sparse numerical representation Zheng et al. [2015]. For instance, Castro Castro [2023] utilized a dictionary learning algorithm to learn an optimal dictionary for the sparse recovery on the image superresolution task. Inspired by sparse dictionary learning, we could regard the sampled static basis as a learnable dictionary, which allows for the simultaneous optimization of the dictionary and sparse representations. Since we don't limit the dictionary elements to specific K-mers, these elements could be viewed as position weight matrices of motifs associated with particular biological functions. Motif, as a recurring pattern in DNA sequences could represent K-mers of similar biological functions and analogous structure. It is clear that the motif is more representative and generalizable than specific K-mers and is more effective and efficient for DNA representation learning compared to the previous method. Additionally, our experiments demonstrate that SDL-based schemes excel on limited-size datasets, effectively handling data scarcity. SDL-based scheme could generate lower-dimensional representations with comparable effectiveness to higher-dimensional SR-based representations, along with a more compact dymer dictionary. Moreover, SDL significantly enhances computation efficiency by eliminating the data preprocessing section and obtaining a more compact dictionary.\nOur approaches have demonstrated their effectiveness in downstream applications, notably achieving state-of-the-art performance in DNA promoter classification. By enhancing the interpretability of robust DNA representations, our methods also facilitate tasks like DNA clustering and motif detection. In summary, the main contributions of our research are as follows:\n\u2022 We leverage a modified Sparse Recovery framework to establish an effective and explainable DNA representation scheme by using frequent K-mers as the basis and representing each DNA sequence as the concatenation of K-mers.\n\u2022 We utilize a sparse dictionary learning algorithm to develop a more computationally efficient and effective DNA representation scheme on limited-resource settings by optimizing the dictionary and representation together.\n\u2022 We formulate the problem using tensor formats to boost batch computational efficiency and preserve the semantic structures of DNA.\n\u2022 We demonstrate the effectiveness of our DNA representations through their successful application in various downstream tasks.\nThe subsequent sections of this article are structured as follows: Section 2 is the literature review of DNA representation schemes. Section 3 provides essential background knowledge necessary for our representation scheme. Section 4 introduces the explainable representation structure of our scheme. Sections 5 and 6 elaborate on our methodology based on sparse recovery and sparse dictionary learning, respectively. Finally, we offer conclusions and insights derived from our research in Section 7."}, {"title": "2. Literature Review", "content": "2.1. DNA Representation Scheme\nDNA representation schemes serve a pivotal role in computational biology, transforming dynamic-length DNA sequences into fixed-length representations compatible with data-mining models. Different schemes are designed for specific applications, but their common objective is to extract meaningful features-such as chemical properties, composition, and permutation of nucleotides-to generate effective representations. Biologists have concluded several criteria to judge whether a representation scheme is well-designed, including accuracy, robustness, succinctness, and adaptability Jin et al. [2017]. Adhering to these criteria entails avoiding information loss, artifacts, or inconsistencies; extracting invariants to represent specific genetic information across different functions or species; effectively compressing the expression to facilitate downstream applications; and accommodating various DNA sequence lengths while considering both local and global features. All DNA representation schemes can be broadly categorized into graphical and numerical schemes.\nGraphical schemes aim at mapping important biochemical features to different geometrical alternatives, including 2-dimensional, 3-dimensional, and higher-dimensional graphical schemes. For example, a 2-dimensional model Randi\u0107 et al. [2003] was proposed to map the four DNA nucleotides to the Cartesian coordinate axes. Despite excelling in visualization, graphical schemes become less practical as sequences grow longer and more features are selected.\nOn the contrary, numerical schemes encode sequence information mathematically, offering effectiveness and scalability in high-dimensional and high-throughput settings. Traditionally, researchers have focused on individual nucleotides, dinucleotides, or trinucleotides, mapping them into numerical representations. For instance, integer encoding maps each nucleotide type to a numeric value Afreixo et al. [2011], Cristea [2001], Kwan and Arniker [2009]. Subsequently, a frequency-based encoding method Alaku\u015f [2023] substitutes the mapped integer with the corresponding nucleotide's frequency, leading to about 10% increase in accuracy in the DNA enhancer classification task. However, these single-nucleotide mapping methods are too simple to represent the complex and high-dimensional structure within the DNA sequences. Many advanced approaches aim to capture more complex subsequences for more comprehensive representations of DNA sequences. For instance, a method employing Empirical Mode Decomposition obtains several intrinsic mode functions from primitive permutations as subcomponents indicating DNA features Bai et al. [2011]. Additionally, the emergence of deep learning methods provides a powerful tool for DNA representation learning. For example, Le et al. Le et al. [2019] utilized sliding windows to obtain K-mers of varying lengths and applied FastText N-Grams to convert them into DNA representations. dna2vec Ng [2017], utilizes the word embedding model word2vec on DNA sequences to obtain representations by capturing meaningful subsequences.\nHigh-quality DNA representation schemes not only contribute to decoding the biochemical information embedded within DNA sequences but also facilitate various DNA-related tasks. For example, researchers designed an efficient coding technique inspired by Huffman coding to compute DNA sequence similarity Jin et al. [2016]. The performance of downstream applications is one of the common evaluation metrics for the effectiveness of representation schemes. Although existing representation schemes have achieved promising performance in many DNA-related applications, there still exist some challenges left unsolved. DNA sequences present inherent challenges in representation learning due to their high dimensionality and complexity, stemming from diversity in composition, length, and permutations. Compounding this complexity is the difficulty in acquiring high-quality datasets, which are essential for training effective representations. This scarcity of data further complicates the task of learning meaningful representations from DNA sequences. Additionally, DNA sequences are inherently noisy due to frequent mutations. To address these challenges, a robust and effective representation scheme is crucial. Such a scheme should be able to extract semantic features from noisy and sparse data, enabling its applicability in important downstream tasks such as DNA classification Li and Lin [2006], Sun et al. [2021b], Le et al. [2019], DNA clustering Randi\u0107 et al. [2003], Randi\u0107 et al. [2003], lan Bai et al. [2007], motif detection Chu and Stormo [2022], and more. By accurately capturing the underlying structure and meaning of DNA sequences, the representation scheme can provide valuable insights into biological processes and facilitate various genomic analyses."}, {"title": "2.2. Explainability in DNA Representation Schemes", "content": "Explainability in DNA representation learning refers to interpreting the biochemical semantic meaning under captured features, which helps biologists comprehend and leverage the knowledge from the extracted features and validate the process of the decision behind the data-mining algorithm.\nPrevious DNA representation schemes primarily relied on explainable artificial intelligence (XAI) to enhance the explainability, such as post-hoc techniques Santorsola and Lescai [2023]. For instance, Li Xue et al. Xue et al. [2019] developed a convolution neural network to predict single-guide RNA function, utilizing convolutional kernel visualization to identify RNA motifs. Besides, models incorporating attention techniques demonstrate effectiveness. AttCRISPR Xiao et al. [2021] incorporates attention modules into the model to indicate the model's decisions on global and local level, which offers great interpretability to the DNA representations. Additionally, some metrics have also been designed to measure the contribution of each element in the representation towards the result of specific applications Lin et al. [2014]. These measurements could be viewed as an indicator of the importance of each feature.\nDespite these advancements, many existing models generate representations that lack an interpretable data structure. Instead, they often rely on attention mechanisms or gradient-based approaches within downstream data-mining algorithms. These complicated techniques challenging for biologists to validate explanations and comprehend insights from the representations. In contrast, our scheme aims to provide DNA sequence representations with an explainable structure by reconstructing DNA sequences as the concatenation of extracted semantic K-mers, which facilitates biologists' understanding and utilization of captured features."}, {"title": "3. Preliminary", "content": "Our main objective is to develop robust and explainable representations derived from DNA sequences. As highlighted by Badri et al. Badri et al. [2014], integrating sparsity constraints significantly improves the robustness of representations, especially in handling outliers and noise inherent in the data. Therefore, we provide concise explanations of two Two widely utilized sparse representation learning frameworks sparse recovery and sparse dictionary learning"}, {"title": "3.1. Sparse Recovery", "content": "In the beginning, Sparse Recovery serves as a potent technique for representing signals of interest by harnessing sparse vectors derived from a restricted set of measurements or observations Cand\u00e8s et al. [2006], Donoho [2006]. In other words, it entails identifying and reconstructing a signal \\(y \\in \\mathbb{R}^{d_y}\\) characterized by a sparse representation \\(x \\in \\mathbb{R}^{d_x}\\) within a high-dimensional space \\(\\Phi \\in \\mathbb{R}^{d_y\\times d_x}\\) : \\(\\Phi = [\\phi_1,...,\\phi_{d_x}]\\). Essentially, the problem could be conceptualized into an optimization problem:\n\\[\\begin{aligned}\n& \\underset{x\\in \\mathbb{R}^{d_x}}{\\text{arg min }} \\Psi(x) \\\\\n& \\text { s.t. } \\Phi x=y\n\\end{aligned}\\]\nHere, \\(\\Psi(x)\\) represents a sparsity constraint on \\(x\\).\nOptimization algorithms can be broadly classified into four categories Crespo Marques et al. [2019], Arjoune et al. [2017]: Convex Relaxation, Non-convex Optimization, Greedy Tropp and Gilbert [2007], Wang et al. [2011], Blumensath and Davies [2008], Kumar and Sahoo [2022], and Bayesian approaches Arjoune et al. [2017], Ji and Carin [2007], Subramaniam et al. [2015]. Convex Relaxation category methods are usually efficient in computation leveraging the optimization instruments. For example, Basis Pursuit (BP) Chen and Donoho [1994] employs the \\(l_1\\) norm as a sparsity constraint to acquire the optimal sparse representation, as formulated below:\n\\[\\begin{aligned}\n& \\underset{x \\in \\mathbb{R}^{d_x}}{\\text{arg min }} ||x||_1 \\\\\n& \\text { s.t. } \\Phi x=y\n\\end{aligned}\\]\nAlternatively, the original formulation can be transformed using the Lagrange multiplier, and then be solved using either Karush-Kuhn-Tucker (KKT) conditions or gradient descent."}, {"title": "3.2. Sparse Dictionary Learning", "content": "Another important sparse representation learning framework is Sparse Dictionary Learning (SDL), which aims at learning a well-constructed dictionary \\(D \\in \\mathbb{R}^{d_y\\times d_x}\\) to map each input data \\(y \\in \\mathbb{R}^{d_y}\\) as a linear combination of dictionary elements. A high-quality dictionary should consist of n elements \\(D=[d_1, . . ., d_n]\\) that effectively approximate the original data and transform each input data into a sparse representation \\(x \\in \\mathbb{R}^{d_x}\\) Zheng et al. [2015], which could be formulated as the following optimization problem:\n\\[\\begin{aligned}\n& \\underset{D \\in C, x \\in \\mathbb{R}^{d_x}}{\\text{arg min }} ||y - Dx||_2 + \\lambda \\Psi(x), \\\\\n& \\text { s.t. } \\lambda>0 \\\\\n& \\text { where } C=\\{D \\in \\mathbb{R}^{d_y \\times d_x} :||d_i||_2 \\leq 1, \\forall i=1, ..., n\\}\n\\end{aligned}\\]\nMany researchers Hongyi et al. [2021], Tang et al. [2023], Xu et al. [2017] have leveraged sparse dictionary learning for image denoising, representation learning, and so on. Various algorithms have been devised to optimize the original multivariate optimization problem alternatively Zheng et al. [2015]. Among the alternating optimization techniques, Coordinate Gradient Descent (CGD) Wright [2015], Boyd and Vandenberghe [2004], Nesterov [2012], Tseng and Yun [2009] stands out for its simplicity and ability to handle large-scale problems efficiently. The coordinate descent iteratively updates the solution in one dimension at a time, holding the other dimensions constant.\n\\[x_i^{(k)}=x_i^{(k-1)} - \\alpha_k i \\frac{\\partial f(x_1^{(k)}, x_2,...,x_i^{(k)}, x_{i+1}^{(k-1)},...,x_n^{(k-1)})}{\\partial x_i}\\]"}, {"title": "4. Explainable DNA Representation Structure", "content": "In the previous sections, we clarified that the pursuit of an effective and explainable representation scheme for DNA sequences is paramount but challenging. To achieve this, Dy-mer firstly introduces an explainable representation structure for DNA by extracting and preserving the underlying semantic structure. In this section, we first clarify some imperative concepts. Later, the explainable representation structure is designed.\nA DNA sequence usually is a string of l permuted nucleotides \\(b_i \\in \\{A, T, G, C\\}, 0 \\leq i \\leq l\\). We could use one-hot code to represent DNA as a matrix \\(d = [\\delta(b_1) \\delta(b_2) \\delta(b_l)]_{4 \\times l}\\). Here, \\(\\delta(b_i)\\) denotes the one-hot mapping. For example, DNA AATTCGAT could be written as a matrix d, where each row represents a type of nucleotide and each column represents a position.\nIn biology, the subsequence of a DNA is denoted as a K-mer. A substring of length k within a DNA d is called a K-mer \\(b_1b_2...b_k\\) where \\(k \\in \\mathbb{Z}^+\\)\nSimilarly, each K-mer could be written as a matrix \\(\\phi = [\\delta(b_1) \\delta(b_2) \\delta(b_k)]_{4 \\times k}\\). For example, a 4-mer in AATTCGAT can be AAT, the matrix \\(\\phi\\) is\nStudies indicate that biological functions are often associated with K-mers, with similar K-mers typically sharing comparable biochemical properties and functions. Furthermore, researchers have summarized patterns of similar K-mers into motifs. Biologists typically represent motifs using a position weight matrix (PWM) \\(P \\in [0, 1]^{4 \\times l}\\), that each row represents a nucleotide and each column represents each position. Essentially, a position weight matrix illustrates the positional distribution of nucleotides within a motif. Each element \\(p_{ij} \\in \\{0, 1\\}\\) means the likelihood that ith nucleotide appears at the jth position of the motif. Motif P, compared to specific K-mer \\(\\phi\\), offers greater generalizability and representativeness.\nHowever, not all K-mers are semantic and significant. It is important to select semantic ones to represent DNA sequences. We define the collection of all possible K-mers for DNA d as the K-mer spectrum \\(\\Phi\\). A subset of \\(\\Phi\\) containing n distinct semantic K-mers for DNA representation is termed a basis \\(\\Phi \\subset \\Phi\\). A basis is termed a dymer dictionary D if it consists of significant K-mers for DNA representation. Each K-mer within the basis is a dymer, representing a K-mer of dynamic length.\nWe could represent DNA sequences with a well-constructed basis (or dymer dictionary) by representing each DNA \\(d_i\\) as a concatenation of matched semantic K-mers \\(d_i = \\phi_1 \\phi_2...\\phi_s\\), where \\(\\phi_i \\in \\Phi, 0 \\leq j \\leq s\\). Furthermore, we could define it as a mathematical operation to facilitate computational convenience. Initially, a data structure is defined to record the assignment of different K-mers to their respective positions to restore the original DNA sequence. This data structure is referred to as an assignment matrix.\nDefinition 1 (Assignment Matrix). Given a DNA sequence d and a basis \\(\\Phi\\), an assignment matrix \\(A \\in \\{0,1\\}^{n \\times l}\\) is defined as an n x l matrix. Each row represents a K-mer \\(\\phi\\) fro\u0442 \\(\\Phi\\), while each column represents a position in d. At ith row and jth column of A, \\(a_{ij}\\) is a binary variable meaning whether the ith K-mer i starts at position j in the given DNA.\nThe assignment matrix of d can be denoted as \\(A_d\\). Similarly, \\(A_{\\phi}\\) denotes the row corresponding to K-mer \\(\\phi\\) of \\(A_d\\). Now, considering m assignment matrices of n DNA \\(\\{d_1,..., d_m\\}\\) based on a well-constructed basis \\(\\Phi\\), we can collect the row corresponding to K-mer \\(\\phi \\in \\Phi\\) from each DNA's assignment matrix \\(A_d\\) and stack them along a new dimension as a new matrix \\(A_{\\phi}\\), which describes the assignment of K-mer \\(\\phi\\) towards each DNA. Similar to PWM, if we withdraw the binary limitation and turn the assignment matrix into a real-number matrix within [0, 1]. Each entry indicates the likelihood of selecting the corresponding K-mer at a specific position for a DNA sequence. It could be regarded as a probability distribution of all K-mers for a DNA sequence.\nFinally, we could rewrite the reconstruction operation. Given a DNA sequence d with l nucleotides and a well-constructed basis \\(\\Phi\\) of n K-mers, the DNA sequence matrix d has dimensions 4xl, and each K-mer matrix \\(\\phi \\in \\Phi\\) has dimensions n\u00d7L, where L means the length of the longest K-mer. And we have obtained the assignment matrix \\(A_d\\) for DNA d. With these elements in place, the DNA sequence can be reconstructed using a two-step operation, a 1D convolution operation followed by a sum-up operation. See Figure 1 for a specific example.\n\\[\\begin{aligned}\n&d = A \\circledast \\Phi \\\\\n& \\widehat{d}=\\sum_{\\phi \\in \\Phi} \\Phi_A \\circledast A_{\\phi} \\\\\n& \\widehat{d} _b= \\left[ \\sum_{i=1}^l \\Phi_{A_b^d}[b, b+1, . . . , b+L-1] \\right] \\\\,\n& \\text { where } A_b^d \\text { is } \\Phi .\\\\\n\\end{aligned}\\]\nHere, \\(\\phi\\) represents a K-mer, and \\(\\phi_b\\) is the bth row of the matrix \\(\\phi\\), on behalf of the bth nucleotide. * is the 1D convolution operator. [] is the stacking operation that stacks the inner vectors b, b+1,..., B along a new dimension.\nIf one assignment matrix could reconstruct the DNA sequence accurately, it records all the semantic K-mers with their positional information of the DNA, which could serve as its explainable representation. Therefore, our representation scheme, named after Dy-mer, aims to construct a good basis and obtain"}, {"title": "5. Methodology", "content": "5.1. Methodology\n5.1.1. Overview\nThis section mainly introduces the optimization algorithm. Firstly"}]}, {}, {}, {}, {}, {}, 0, "constraints", "objectives", 3.0, {}, "is,\n\\[\\"]