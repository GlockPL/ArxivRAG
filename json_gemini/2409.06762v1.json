{"title": "Generative Hierarchical Materials Search", "authors": ["Sherry Yang", "Simon Batzner", "Ruiqi Gao", "Muratahan Aykol", "Alexander L. Gaunt", "Brendan McMorrow", "Danilo J. Rezende", "Dale Schuurmans", "Igor Mordatch", "Ekin D. Cubuk"], "abstract": "Generative models trained at scale can now produce text, video, and more recently, scientific data such as crystal structures. In applications of generative approaches to materials science, and in particular to crystal structures, the guidance from the domain expert in the form of high-level instructions can be essential for an automated system to output candidate crystals that are viable for downstream research. In this work, we formulate end-to-end language-to-structure generation as a multi-objective optimization problem, and propose Generative Hierarchical Materials Search (GenMS) for controllable generation of crystal structures. GenMS consists of (1) a language model that takes high-level natural language as input and generates intermediate textual information about a crystal (e.g., chemical formulae), and (2) a diffusion model that takes intermediate information as input and generates low-level continuous value crystal structures. GenMS additionally uses a graph neural network to predict properties (e.g., formation energy) from the generated crystal structures. During inference, GenMS leverages all three components to conduct a forward tree search over the space of possible structures. Experiments show that GenMS outperforms other alternatives of directly using language models to generate structures both in satisfying user request and in generating low-energy structures. We confirm that GenMS is able to generate common crystal structures such as double perovskites, or spinels, solely from natural language input, and hence can form the foundation for more complex structure generation in near future.", "sections": [{"title": "1. Introduction", "content": "Modern technologies increasingly rely on the development of materials, such as semiconductors (Berger, 2020), solar cells (Green et al., 2014), and lithium batteries (Mizushima et al., 1980). Large-scale generative models, trained on expansive internet data, exhibit intriguing generalization capabilities. For example, these models can synthesize a highly realistic image of \u201can astronaut riding a horse\" by merging two distant concepts (Ramesh et al., 2021). This raises a compelling question: can the generalization capabilities of large generative models, pretrained on existing materials science knowledge, be harnessed to combine knowledge from existing materials systems to propose candidate crystals?\nPrevious research has demonstrated that generative models can output crystal structures that are not in the the training data (Xie et al., 2021; Yang et al., 2023a; Zeni et al., 2023). However, these works typically require either a vast number of unconditional samples to generate an unknown material (Flam-Shepherd and Aspuru-Guzik, 2023; Xie et al., 2021) or a chemical formula provided during inference (Antunes et al., 2023; Yang et al., 2023a). It is difficult for end users to come up with new chemical formulae, as it is hard to know which compositions will result in what material properties. Therefore, it is highly desirable to develop an interface that allows users to describe the desired characteristics of crystal structures such as properties, compositions, space groups, and geometric characteristics \u2014 in natural language. For example, a user might specify \u201ca stable chalcogenide with atom ratio 1:1:2 that is not on ICSD.\" Ideally, a model should automatically interpret these high-level language instructions to search for, generate, and validate a wide range of potential structures, ultimately producing one that best meets the user's specifications.\nHowever, developing an end-to-end language-to-structure generative model presents several challenges, for which we make a few key observations. First, there are no existing labeled datasets"}, {"title": "2. Generative Hierarchical Materials Search", "content": "We begin by formulating the problem of generating crystal structures from high-level language as a multi-objective optimization task. Given this formulation, we then propose a hierarchical, multi-modal tree search algorithm that leverages language models, diffusion models, and graph neural networks as submodules. Lastly, we discuss the specific design choices for each of the submodules."}, {"title": "2.1. Language to structure as a multi-objective optimization", "content": "Given some high-level language description $g \\in G$ of desired structures, we want to learn a conditional crystal structure generator $\\pi(\\cdot|g) : G \\rightarrow \\Delta(X)$ that can be used to sample crystal structures $x \\in X$ conditioned on language. One option is to parametrize $\\pi$ with a pretrained LLM. However, pretrained LLMs alone are not able to predict sufficiently accurate crystal structures, due to the lack of low-level structural information about crystals (e.g., 3D atom coordinates) in the pretraining data.\nIf we had access to a paired language-to-structure dataset, $D = \\{g_i, x_i\\}_{i=1}^{N}$, $\\pi$ could be trained using a maximum likelihood objective. However, materials data naturally exist at different levels of abstraction and are segregated into different sources: high-level symbolic knowledge is documented in sources like Wikipedia articles, research papers, and textbooks, whereas detailed low-level crystal information, including continuous-valued atom positions, is stored in specialized crystal databases like the Materials Project (Jain et al., 2013) and ICSD (Hellenbrandt, 2004). Even though a direct language-to-structure dataset $D$ remains unavailable, the pretraining data for LLMs, including Wikipedia articles, research papers, and textbooks, can be viewed as a high-level symbolic dataset $D_{hi} = \\{g_i, z_i\\}_{i=1}^{m}$, where $z \\in Z$ denotes symbolic textual information such as chemical formulae. Meanwhile, many crystal databases already feature paired data, $D_{lo} = \\{z_i, x_i\\}_{i=1}^{m}$, linking chemical formulae to detailed crystal structures.\nGiven this observation, we propose to factorize the crystal generator as $\\pi = \\pi_{hi} \\circ \\pi_{lo}$, where $\\pi_{hi}: G \\leftrightarrow \\Delta(Z)$ and $\\pi_{lo}: Z \\leftrightarrow \\Delta(X)$, so that $\\pi_{hi}$ and $\\pi_{lo}$ can be trained using different datasets $D_{hi}$ and $D_{lo}$. Furthermore, we consider two heuristic functions, $R_{hi}(g, z): G \\times Z \\rightarrow \\mathbb{R}$ and $R_{lo}(z, x): Z \\times X \\rightarrow \\mathbb{R}$, where the high-level heuristic function $R_{hi}$ can be used to select formulae that satisfy the language input at a high level, and the low-level heuristic function $R_{lo}$ can be used to select structures that are both valid and exhibit desirable properties such as low formation energy. To this end, we propose to search for crystal structure given language input by finding a chemical formula / space group $z$ with a corresponding crystal structure $x$ that jointly optimize\n$z^*, x^* = \\arg \\max\\limits_{z,x \\sim \\pi_{hi}, \\pi_{lo}} E_{z\\sim \\pi_{hi},x\\sim \\pi_{lo}(z)}[\\lambda_{hi} \\cdot R_{hi}(g, z) + \\lambda_{lo} \\cdot R_{lo} (z, x)],$ \nwhere $\\lambda_{hi}$ and $\\lambda_{lo}$ are hyperparameters to control how much weight to put on high and low-level heuristics. Note that $R_{hi}$ and $R_{lo}$ can also be combinations of multiple objectives. For instance, $R_{hi}$ can be a weighted sum of instruction following and simplicity, where $R_{lo}$ can be a weighted sum of properties such as band gap, conductivity, and formation energy."}, {"title": "2.2. Searching through language and structure", "content": "Given the objective in Equation 1, it is clear that a pretrained LLM (even with finetuning) is insufficient to optimize for the best structure $x^*$. Instead, we propose to first sample a set of intermediate chemical"}, {"title": "3. Experimental Evaluation", "content": "We now evaluate the ability of GenMS to generate low-level crystal structures from high-level language descriptions. First, we evaluate the success of end-to-end generation in Section 3.1. We then investigate the individual components of GenMS in Section 3.2. See details of experimental setups in Appendix A."}, {"title": "3.1. End-to-end evaluation", "content": "Baselines and metrics. We aim to evaluate GenMS's ability to generate unique, valid, and potentially stable crystal structures from well-known crystal families that satisfy high-level language specifications. We consider few-shot prompting of LLMs to generate crystal information files (CIF) as a baseline. Specifically, we give the Gemini long context model (Reid et al., 2024) a number of CIF files from a particular crystal family, as specified by language input as prompt, with the number of CIF files ranging from 1, 5, 25 to as many as can fit in the context. We ask the LLM to generate 100 samples given each language instruction. See additional details of baselines in Appendix A.2. We do not compare to finetuning LLMs to generate CIF files in this section, as there are no high-level language to low-level crystal structure datasets available for finetuning such an instruction following LLM. Nevertheless, we will compare the diffusion model in GenMS to formula-conditioned structure generation using finetuned LLM in Section 3.2. We consider language input that directs the model to generate unique and stable crystals from a particular crystal family (perovskite, pyrochlore, and spinel). We consider the following metrics for evaluation: (i) CIF validity, which measures whether the generated CIF file can be properly parsed by pymatgen parser (Ong et al., 2013). (ii) Structural and composition validity, which verify atom distances and charge balances using SMACT (Davies et al., 2019), following Xie et al. (2021). (iii) Formation energy ($E_f$), which measures the stability of predicted structures using a pretrained GNN. We further conduct DFT calculations to compute $E_f$ (see details in Appendix A.4) for structures predicted by GenMS. (iv) Uniqueness, which measures the percentage of generated formulae that do not exist in Materials Project (Jain et al., 2013) or ICSD (Hellenbrandt, 2004). Finally, (v) the match rate, which measures the percentage of generated structures that can be matched (according to the pymatgen structure matcher) to one of the structures of the corresponding family in Materials Project. More details of these metrics can be found in Appendix A.1.\nResults on specifying crystal family. The evaluation of GenMS and baselines are shown in Table 1. Since GenMS does not rely on an LLM to directly generate CIF files, the compact crystal representation (described in Section 2.3) always results in structures that can be parsed by pymatgen (100% CIF validity). In addition, structures generated by GenMS have a much higher validity and match rate compared to those generated by the baselines. GenMS struggles slightly with uniqueness, as less than half of the generated formulae for pyrochlore and spinel are unique with respect to MP and ICSD. Structures produced by GenMS have lower average $E_f$. Increasing the number of CIF files in the context generally improves the performance of the baselines (1, 5, and 25-shot), but including too many files in the context can hurt performance (Prompting CIF Max).\nQualitative evaluation. In addition to the three families of structures evaluated above, we qualita- tively evaluated GenMS's ability to generate structures that satisfy ad hoc user requests, such as \u201ca pyrochlore"}, {"title": "3.2. Evaluating individual components of GenMS", "content": "Next, we evaluate the individual component of GenMS, including the effect of using language to narrow down the search space, the choice of the compact representation of crystal structures, and finally the best-of-N sampling strategy for choosing the crystal structures with low formation energy.\nEffect of language. We want to understand whether GenMS can provide effective control over formulae proposed by the LLM at the semantic-level through natural language. In Table 3, we first show that requesting a particular element to be in the formula always results in formulas with that particular element being proposed by the pretrained LLM $\\pi_{hi}$. We then show that when a user requests for metal, the model is 4 times more likely to generate formulae for metal. The model also respects a user's request for the generated formulae to be unique (with respect to either a user provided list of known formulae in the context of the LLM, or the name of some crystal database).\nNext, we study the effect of retrieval augmented generation (RAG). We use GenMS with and without RAG to propose 25 formulae for each of the three major crystal families from Section 3.1 and generates 4 structures per formula using the diffusion model. We report the rate of valid formulae proposed by the LLM and the structures that can be matched with existing structures from the corresponding family in Table 4. RAG improves both the rate of valid formulae and matched structures."}, {"title": "4. Related work", "content": "Hierarchical and latent image and video generation. Image and video generative models have ex- hibited an impressive ability to synthesize photorealistic images or videos when given text description as input. Many of the state-of-the-art models adopt a hierarchical modeling approach that inspired the design of with GenMS. For example, latent diffusion models (Rombach et al., 2022; Vahdat et al., 2021) contains (1) a language model that converts text to high-level text embeddings, (2) a diffusion model takes the text embeddings as input and output latents in a compressed latent space, and (3) a feed forward decoder network (Rombach et al., 2022) or a diffusion decoder Brooks et al. (2024); et al (2022) that given the generated latents generates full-resolution signals in the pixel space. Cascaded diffusion models Ho et al. (2022a,b); Saharia et al. (2022) instead proposed to generate signals at the lowest resolution with a standard diffusion model, followed by a few super-resolution models that successively upsample signals and add high-resolution details. Similar to GenMS, by breaking down complicated image or video generation into a hierarchy of less challenging problems, these models can generate high quality samples more efficiently and effectively."}, {"title": "5. Conclusion and future work", "content": "We have introduced GenMS, an initial attempt at enabling end-to-end generation of candidate crystal structures that look physically viable and satisfy instructions expressed in natural language. GenMS can generate examples from families such as pyrochlores and spinels purely from natural language prompts. We hope the design principles of GenMS will initiate broad interest in exploiting language as a natural interface for flexible design and generation of crystal structures that meet user-specified criteria, and enable the domain experts to work more efficiently. GenMS has a few limitations that call for future work:\nGenerating complex structures. While GenMS is able to generate simple structures such as those shown in Figure 3, we found that GenMS is less effective in generating complex structures such as\n\u2022\n\u2022\n\u2022\n\u2022"}, {"title": "Appendix", "content": "In this section, we provide additional experimental details, including metrics used for evaluation, baselines, architecture and training of the diffusion model with the compact crystal representation, and details of the setup for the DFT calculations."}, {"title": "A.1. Details of evaluation metrics", "content": "Structure and composition validity. The structure and composition validity metrics follow Xie et al. (2021). The structure validity determins that a structure is valid as long as the shortest distance between any pair of atoms is larger than 0.5 \u00c5 (Court et al., 2020). The composition is valid if the overall charge is neutral as computed by SMACT (Davies et al., 2019).\nUniqueness. We determine a generated formula is unique if the reduced form of the formula does not exist in either Materials Project (Jain et al., 2013) or ICSD (Hellenbrandt, 2004). For instance, if ICSD contains formula in the form of AB2, we consider A2B4 generated by the model as a duplicate (thus not unique) structure.\nMatch rate. To compute the match rate, we use the StructureMatcher module from pymatgen's analysis package. We set the hyperparameters of the matcher following Antunes et al. (2023), specifically with stol = 0.5, ltol = 0.3, angle_tol = 10. For each family of crystals in perovskite, pyrochlore, and spinel, we first curate the reference set by downloading CIF files from Materials Project (Jain et al., 2013) that is likely to belong to each family based on formula and space group. We then use fit_anonymous method of the matcher to compare each generated structure to the structures in the reference set. A generated structure is considered matched if fit_anonymous returns true for at least one reference structure of the corresponding family. Note that this approach might result in false positive matches. For example, when we selected the reference set for pyrochlore, we downloaded CIF files Material Project that have composition A2B2O7. However, not all A2B207 are pyrochlore, so generated structures may still not be a pyrochlore despite being matched to one of the reference structures."}, {"title": "A.2. Details of baselines", "content": "We use the following prompts in Table 7 to generate the CIF files for the end-to-end prompting baseline or to generate the chemical formulae for GenMS."}, {"title": "A.3. Compute, architecture, and training", "content": "We repurpose the 3D U-Net architecture (\u00c7i\u00e7ek et al., 2016; Ho et al., 2022c) into modeling atoms within a crystal structure by their x, y, z locations concatenated with atom number (number of protons) a. As a result, we can represent each crystal structure using an Ax4 matrix where A is the total number of atoms in the structure, and the dimension with size 4 represents the x, y, z location and atom number of each atom. We repurpose the spatial downsampling and upsampling passes from typical U-Net for images or videos, and keep the resolution (number of points) the same, but still employ residual network with concatenating skip connections (see Figure 2 from the main text). Below we show the architecture and hyperparameters used in the diffusion model for crystals with compact representation."}]}