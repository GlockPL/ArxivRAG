{"title": "One-step Structure Prediction and Screening for Protein-Ligand Complexes using Multi-Task Geometric Deep Learning", "authors": ["Kelei He", "Tiejun Dong", "Jinhui Wu", "Junfeng Zhang"], "abstract": "Understanding the structure of the protein-ligand complex is crucial to drug development. Existing virtual structure measurement and screening methods are dominated by docking and its derived methods combined with deep learning. However, the sampling and scoring methodology have largely restricted the accuracy and efficiency. Here, we show that these two fundamental tasks can be accurately tackled with a single model, namely LigPose, based on multi-task geometric deep learning. By representing the ligand and the protein pair as a graph, LigPose directly optimizes the three-dimensional structure of the complex, with the learning of binding strength and atomic interactions as auxiliary tasks, enabling its one-step prediction ability without docking tools. Extensive experiments show LigPose achieved state-of-the-art performance on major tasks in drug research. Its considerable improvements indicate a promising paradigm of AI-based pipeline for drug development.", "sections": [{"title": "1 Introduction", "content": "Small organic molecule (SOM) plays an important role in clinical treatment, accounting for about 72% FDA-approved drugs in 2018 ~ 2022[1]. Its efficacy is achieved by binding to the target (usually a protein) as a ligand, to produce a protein-ligand complex. Understanding the structural details of the protein-ligand complexes at the atomic level reveals the bioactivities of the proteins and ligands, thus guiding the structure-based drug development, e.g., drug screening[2, 3, 4] and lead optimization[4, 3, 5]. Conventional methods use experimental measurements (e.g., X-ray diffraction[6] and cryo-electron microscopy[7]) to analyze novel protein-ligand complexes, however, are time and resource-expensive.\nTo alleviate this problem, virtual measurement by molecular docking[8, 2, 9, 4] has been widely adopted in the past decades to predict the native-like ligand-binding conformations with the respective protein-binding sites. Typically, a docking tool first samples a set of binding conformations (namely poses), and then ranks them using a scoring function to select a top-scored pose[9] (Fig. 1b). As reported, popular docking tools generate native-like poses with accuracies from approximately 40% to 60% in terms of success rate[10], which were far from satisfactory. Since deep learning has impacted the field of drug development, many researchers attempted to build hybrid methods by regarding it as a more expressive scoring function to rank the poses sampled by conventional docking tools [11, 12, 13, 14, 15, 16]. Nevertheless, the performance of these hybrid methods has a constrained upper bound, as limited by the sampling time and space of docking tools[15].\nRecently, several deep learning methods, i.e., AlphaFold[17], RoseTTAFold[18], and ESMFold[19], have shown great capacity to predict protein structures that outperformed previous methods by a large margin. These methods provided a novel computational approach to generate protein structures directly from their chemical sequences, rethinking the structure prediction paradigm in a data-driven perspective without following the conventional force-field assumption[20]. Recent progresses[21, 22, 23, 24] demonstrated that using these methods as the protein/peptide structure estimator can predict precise structures for amino acid-based complexes such as the protein-protein and protein-peptide complexes, showing the general-izability of deep learning methods to the downstream tasks. However, these methods are not specifically designed for SOM ligands, which inevitably restricts the related applications such as protein-ligand complex structure prediction and virtual screening. As these two fundamental tasks have heavily relied on docking tools in the past four decades [25, 26, 27, 28], developing a deep learning model that provides refined atomic complex structure and screening for the protein-ligand pairs is highly demanded.\nTo this end, we introduce LigPose, a novel docking-free geometric deep learning method to accurately predict the native-like conformation of ligands with their corresponding protein targets and the respective binding strengths in one step (Fig. 1c). Specifically, for a given protein and ligand pair, the"}, {"title": "2 Results", "content": ""}, {"title": "2.1 LigPose pipeline", "content": "LigPose predicts the 3-D structure of the ligand-binding conformation with its protein target in an end-to-end manner. As shown in Fig. 1c, a given protein and ligand are jointly represented by a complete undirected graph, where each atom is denoted as a node, representing its chemical feature and coordinate, and all nodes are mutually connected. Since the entire protein-ligand graph is large, LigPose (Fig. 1d) first adopts a sampling and recycling strategy, to predict with multiple cycles, where each cycle updates a randomly sampled sub-graph. The features and coordinates within the sub-graph are then pro-cessed by the proposed feature and coordinate update blocks. These two blocks are built on the graph neural network and stacked 6 times with unshared weights. The key design of these two blocks is to leverage the inter-atom distances during network forwarding for maintaining the spatial information, making the predicted atom coordinates insensitive to their initial positions, but influenced by the inter-atom correlations. Finally, a symmetric-aware loss is proposed to optimize the network, combined with a stochastic coordinate initialization strategy for the ligands, to enable the method of distinguishing the ligand atoms with the same chemical features. The affinity and screening efficacy are learned by two additional prediction heads as auxiliary tasks. More-over, we adopt self-supervised learning of the atomic correlations on large-scale unlabeled data including millions of random protein-ligand pairs without char-acteristics, to improve the generalizability of LigPose to unknown molecules.\nAn ablation study of LigPose is illustrated in Suppl. Sec. A.9.3. Please refer to Methods, Suppl. Methods and Fig. A3 for more details of the method."}, {"title": "2.2 Predicting accurate complex structures", "content": "In experiments, we first focus on the flexible-ligand prediction with the determined protein pockets, a widely used setting in structure-based drug development[30], to demonstrate its effectiveness. We compare LigPose with 12 popular docking tools on the refined set of PDBbind database[31, 10]. The PDBbind database collects a large set (N = 19443) of 3-D biomolecular com-plex structures from the PDB database. The refined set (N = 5316) and the"}, {"title": "2.3 Ligands with various flexibilities", "content": "To solve the ligands with high flexibilities (i.e., with many rotatable bonds), the strategies of sub-graph sampling and recycling are combined to progres-sively refine the predictions. We visualize the ligand atoms and plot the RMSD trajectories for two representative samples in Fig. 3a, where one is heavier with more rotatable bonds (PDB code: 1EBY) than the other (PDB code: 105B). As a hard example, the prediction of 1EBY reaches the threshold of 2\u00c5 after 16 updates, which is much slower than that of 5087 (with 5 updates), indicating the effectiveness of the proposed recycling strategy.\nTo quantify the performance of LigPose concerning the number of rotatable bonds, we plot the results of LigPose and Smina on the refined set in terms of RMSD (b) and success rate (c) in Fig. 3. One can observe is the difficulty of prediction is positively correlated with the number of rotatable bonds. We sup-pose the reason is that more rotatable bonds indicate higher flexibility of the ligand. Although the success rates of LigPose and Smina are both decreased when predicting ligands with many rotatable bonds, LigPose performed con-sistently better than Smina through the dataset. Moreover, Smina failed to predict with more than 24 rotatable bonds, indicating the limited processing power of the docking methods. By contrast, LigPose correctly predicted 20% of them, showing the merit of our learning-based methodology. Similar findings were discovered from the core set, as shown in Suppl. Fig. A7.\nThe efficiency is also a core factor of drug development[40], caused by a large number of drug-like molecules for screening and measurement. We then plot the inference time per ligand with respect to the number of ligand rotatable bonds for LigPose and Smina in Fig. 3d. For a fair comparison, we use a single CPU core to implement docking tools and LigPose (CPU), with only an additional common GPU device (Nvidia GTX 2080Ti) for the GPU version (LigPose (GPU)). From the figure, we observed the inference time of LigPose is constant, in contrast to that of docking tools, which is positively correlated with the number of rotatable bonds. On average, LigPose inferences 4-26 (CPU) / 303 \u2013 1851 (GPU) times faster than docking tools. For ligands with more than 10 rotatable bonds, LigPose can infer 7299x times faster than docking tools, and up to 14256x faster for ligands with more than 20 rotatable bonds."}, {"title": "2.4 Accurate and fast screening", "content": "Accurate prediction of the complex structure is an essential procedure, and ideally beneficial for the virtual screening task. Therefore, we validate the screening power of LigPose using the CASF-2016 benchmark, which contains 57 proteins, each having at least 5 true binders with a wide range of affinities. Therefore, for each SOM-protein pocket pair, LigPose predicts the potential binding strength of SOMs to the protein pockets as the screening score, through the multiplication of the predicted binding probability and affinity.\nAs suggested by Fig. 4, LigPose outperformed the state-of-the-art methods in all three metrics with a very large performance gap, compared with recent deep learning-based methods and popular conventional methods. Concretely, for the forward screening, i.e., the task of identifying true binding SOMs for a certain protein, LigPose gets an average enhancement factor (EF) of 36.4%, and a success rate of 86.0% on top 1%-ranked SOMs. These results are greatly higher than that of the second best performing method RTMScore[36] (with EF of 28.0% and success rate of 66.7%), with improvements of 8.4% and 19.3% on EF and success rate, respectively. It also largely outperforms recent deep learning-based methods, i.e., DeepDock[12] (with EF of 16.4% and success rate of 43.9%) and PIGNet[41] (with EF of 19.36% and success rate of 55.4%). Besides, the results show huge gaps to conventional methods (with EFs ranging from 0.8% to 11.9% and success rates ranging from 1.8% to 42.1%). For top-5% and top-10% ranked SOMs, similar conclusions can be made. Notably, LigPose reaches very high success rates of 96.5% and 98.2% on top-5% and top-10% ranked SOMs, suggesting that nearly all true SOM binders are settled at the top of the predictions. Similarly, for the reverse screening, i.e., the task of identifying true binding proteins for a certain SOM, LigPose obtains success rates of 50.5%, 77.9%, and 87.0% in top-1%, top-5%, and top-10% ranked"}, {"title": "2.5 Validating on the SARS-CoV-2 Mpro", "content": "We further validate LigPose on the main protease (MPro) of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) to demonstrate its efficacy in real-world applications. Mpro plays a critical role in virus replication as a"}, {"title": "2.5.1 Learning non-covalent interactions", "content": "In addition to the effectiveness and efficiency, LigPose also showed good interpretability by investigating its ability to reconstruct the non-covalent interactions. We used a metric, namely interaction reproducibility, to quantify this ability, following the workin [48] (see Methods for details).\nFrom Fig. 6a, we observed the interactions are well reconstructed by Lig-Pose on predictions with RMSD < 2\u00c5, and have lower scores on predictions with RMSD\u2265 2\u00c5. For each type of interaction (Fig. 6b), LigPose performed best for hydrogen bond and water bridge and showed insensitive to r-cation and halogen bond. We suppose the reason is the lack of respective lig-and samples. We further compared the performance of LigPose with Smina (Suppl. Figs. A8 and A9), and found that LigPose showed consistently better performance for all the seven types of interactions.\nIn addition to the high quantitative scores, we further inspected the atten-tion weights, by visualizing three representative complexes with respect to three non-covalent interactions (i.e., hydrophobic interactions, salt bridge, and \u03c0-stack) in Fig. 6(c-f). We observed from the figure that LigPose can capture some potential interactions between ligands and proteins, without explicitly using related physical or chemical prior knowledge."}, {"title": "3 Discussion", "content": "In this work, we propose LigPose, which can predict protein-ligand complex structure, affinity, and screening probability simultaneously using multi-task geometric deep learning. The protein-ligand pair is first presented by one complete undirected graph, then, LigPose with a graph transformer network structure, directly predicting the complex structure in three-dimensional space. To precisely predict the complex structure with atomic accuracy, LigPose is"}, {"title": "4 Methods", "content": ""}, {"title": "4.1 Data collection", "content": ""}, {"title": "4.1.1 Benchmark Dataset", "content": "Training and validation dataset. We use the general set of PDBbind database (version 2020)[31] to develop and validate LigPose, consisting native structures of 19443 protein-ligand complexes. Within the general set, two sub-sets are used for evaluation, i.e., the refined set and the core set, which are of better data quality for evaluating docking tools and scoring functions in exist-ing works. We used the refined set to validate the performance of LigPose with five-fold cross-validation. In each fold, the rest of the samples in the general set with non-overlapping to the validation set are used for training. Performance for 2002 selected complexes in the refined set as adopted in [10] under a similar setting is also reported. For the core set we obtain the training data following the previous deep learning-based methods, e.g., DeepDock[12], RTMScore[36].\nThe peptide-like SOMs are identified by the Biologically Interesting Molecule Reference Dictionary (BIRD)[80]. 2200 random selected samples in the training set are used for hyper-parameter search, and the selected archi-tecture is used for all tasks. The unsuccessfully processed data by RDKit[81] is removed. None of the samples in the core set but 14 samples in the refined set failed to be processed. Finally, only a minor proportion of the entire PDBbind database (153, < 1%) is dropped.\nAuxiliary unlabeled dataset. The structure-determined complexes are only a tiny portion of the complex family. To enhance the performance and general-izability of LigPose, we add a task to LigPose to train it under a self-supervised learning scheme, which models the data structures from large-scale unlabeled data, i.e., with unknown complex structures and protein/ligand properties. To this end, we collected a large unlabelled dataset, including a total num-ber of 2147477 SOMs and 171789 proteins. The SOMs are derived from two databases, i.e., DrugBank[82] (11290) and ChEMBL [83] (2136187), with diver-sified drug/drug-like compounds that are widely used for the pre-training of SOM features[84]. The proteins are derived from the PDB database[85].\nTest dataset. The whole core set and the benchmark dataset CASF-2016[86] derived from the core set with carefully designed poses are used for testing. We adopt four main tasks, i.e., scoring power (the ability to estimate binding affin-ity), ranking power (the ability to identify near-native pose), docking power (the ability to identify near-native pose), forward screening power (the ability to identify potential ligands for a target protein) and reverse screening power (the ability to identify potential target proteins for a SOM), to comprehen-sively assess the performance of LigPose. As abovementioned, all complexes in the core set are removed from the training set to make them non-overlapped."}, {"title": "4.1.2 Real-world dataset", "content": "To demonstrate the ability of LigPose in real applications, we perform it on two major tasks (i.e., complex structure prediction and screening) for the drug development of SARS-CoV-2 Mpro.\nMpro structure dataset. We adopt the dataset as reported in [43], which contains 44 non-covalent and non-surface-bound ligands with Mpro from SARS-CoV-2.\nMpro screening dataset. The screening set (N = 344) contains SOM binding data by experimentally measuring the enzymatic activity of MPro, which is collected from DrugCentral[46], followed with a processing protocol introduced in ImageMol[47]."}, {"title": "4.2 Pre-processing", "content": "In this work, the protein pocket was adopted as the binding target, since obtaining the atomically refined structure is the major concern in drug development[87, 4]. Besides, many methods have been successfully developed to predict the ligand-binding pockets with high accuracies[66, 67, 68, 69, 88, 89].\nThe protein pockets are the surrounding amino acids of the ligands in 3-D space. For the unlabeled data, we complete the missing atoms with modeler[90] and search the pockets using the Fpocket[91] method with the default setting. All pockets are filtered with a Druggability Score of > 0.5, therefore, 631687 pockets are finally used. Fpocket recognizes the pocket and represents the pocket center as virtual atoms. A residue is selected as the part of a pocket when its Ca atom is within 13\u00c5 to the nearest virtual atom. For the labeled data, a residue is selected as the part of a pocket when its Ca atom is within 15\u00c5 to the nearest ligand atom. Water molecules are not considered in this study.\nFor a given protein-ligand pair, i.e., a random pair in the unlabeled dataset or a native complex in the PDBbind dataset, a complete undirected graph is firstly constructed using RDKit[81], with each node representing an atom, and all nodes (including themselves) are mutually connected. We initialize the graph by features listed in Suppl. Table A3. In particular, the nodes are initial-ized as vectors with a length of 79 for a protein and 45 for a ligand, containing the chemical features. Edges are also initialized as vectors with a length of 7 including covalent bond features and distance. Distances connecting different rigid parts are masked with -1. To enable the ability of SE(3)-equivalence for the method, and also augment the data, we implement a stochastic strategy to initialize the coordinates of the ligands. In this case, the protein nodes are kept in their original positions, while the positions of the ligand nodes are ran-domly initialized inside the pocket with an empirical distance. In this work, we initialize them in a Gaussian distribution with a standard deviation of 10\u00c5."}, {"title": "4.3 LigPose architecture", "content": "LigPose directly predicts the structure of the ligand-binding conformations with their target protein pockets in the 3-D space in an end-to-end manner. As shown in Fig. 1c, LigPose has a graph transformer architecture, with three major components, (1) a sampling and recycling strategy, (2) a feature update block followed by a coordinate update block to forward the features and coordi-nates through the graph, and the two blocks are stacked 6 times with unshared weights, and (3) a stochastic initialization method for ligand nodes and a novel symmetric-aware loss. We will then illustrate them below."}, {"title": "4.3.1 Sampling and recycling", "content": "Typically, a protein pocket contains hundreds of atoms. Using all of them as the input is inefficient and memory unaffordable for common GPU devices. Therefore, we adopt a sampling strategy to generate a sub-graph consisting of all core atoms and some randomly selected context atoms, with their respec-tive edges, to feed to the network. Specifically, the core atoms involve all ligand atoms, and the Ca, C\u03b2 atoms of the protein, as they are enough to determine the position and orientation of the amino acids and protein backbone[92, 93]. The other protein atoms are regarded as the context atoms to describe the structural details of the amino acids. Since the nodes are not fully used, we further introduce a recycling strategy, to enhance the representability of the method, as inspired by [17]. In each cycle, a new sub-graph is sampled and for-warded, then, the updated graph is reused in the next cycle. In the next cycle, the newly sampled graph directly inherits the coordinates of corresponding nodes from the last cycle, and its features of the core atoms are combined with the last updated features by using an element-wise gate on the new features, implementing a partial update. (See details in Suppl. Sec. A.2.2)"}, {"title": "4.3.2 Feature Update Block", "content": "The feature update block maintains a graph Transformer-based architecture to forward the node and edge features. It iteratively performs two operations, i.e., message aggregation and feedforward. In message aggregation, information is aggregated from neighboring nodes to a central node using the multi-head attention (MHA) mechanism (Fig. A3)[94]. In addition, the edge features are also incorporated to enhance the representation.\nWe use conventional cross-attention to calculate the MHA in the network, according to Query (denote as q), Key (denote as k), and Value (denote as v)[94] (See details in Suppl. Sec. A.2.2). Briefly, q and v are produced by the features of the central nodes and the neighboring nodes, respectively (see Fig. A3b). k is extracted from the edge feature and a linearly transformed neighboring node feature (Fig. A3a-b). The edge feature here is enhanced by the spatial information using the distance between the central node and its neighboring node (Fig. A3a). A softmax layer is then applied to the product of q and k to get attention masks for each v. The central node aggregates the"}, {"title": "4.3.3 Coordinate Update Block", "content": "The coordinate update block updates the coordinates of the nodes (atoms) in 3-D space based on the attentions derived from the feature update block, as also introduced in [95] (Fig. A3e-f). To be specific, the attention is transformed to a one-dimensional distance gradient, indicating the change in distance between the central node and each of its neighboring nodes. Then, the coordinate of a certain central node is updated by the sum of these distance gradients calculated with all neighboring nodes, as written by,\n\u0394h = \u2211x \u2212 xixj \u03a6 (q, k),\nj\u2208Neighbor(i) ||x \u2212 x||2\nx = xl + \u2211\u03bbh\u0394h,\nh\u22081,...,Nh\nwhere xi denote the coordinate of a central node i, xj denote the coordinate of a neighbouring node j, qij and kij are the Query and Key for i and j, respectively, as obtained in the feature update block. The element-wise multi-plication (\u2299) of qij and kij are then transformed to a single distance variable by a linear layer \u03a6, and multiplied by the direction of a central node\u2019s coor-dinate (x) to one of its neighboring node\u2019s coordinate (xj). The coordinate update \u0394h for node i is then obtained by aggregating \u0394 for all i\u2019s neighbour-h nodes (Neighbor(i)), where i is not equal to j. xi is then updated by the h weighted sum of all \u0394 to x. Finally, the coordinates were updated using h MHA with \u03bb\u03b7 weighted Nh heads."}, {"title": "4.4 Correlation-enhanced graph learning", "content": "We introduce a novel training paradigm, namely correlation-enhanced biomolecular graph learning, that simultaneously learns both the graph fea-tures and the 3D structures for proteins and SOMs. In brief, in each training iteration, the network is trained with a half-to-half chance by a labeled sample (i.e., a native complex) or an unlabeled sample (i.e., a randomly paired protein and ligand). We use the Monte Carlo method to choose one cycle to opti-mize the network parameters, as also adopted by [17]. Details of the training schedule can be found in Suppl. Sec.A.3"}, {"title": "4.4.1 Training with native complexes", "content": "Given a ligand containing Nlig atoms (nodes). In each iteration, an index is created for mapping the nodes from the predicted pose to the native pose,"}, {"title": "4.4.2 Training with randomly paired proteins and ligands", "content": "For an unlabeled sample, the loss function (denote as Lsemi) consists of two parts, i.e., the Masking-based Complex Modeling (MCM, denote as Lmask) and the Denoising-based Protein structure Reconstruction (DPR, denote as Lnoise). Then, Lself can be formally written as,\nLself = Lmask + Lnoise.\nThese losses are designed to prepare the network parameters in two aspects. First, the MCM loss Lmask is proposed to guide the model to recognize the atom properties. A portion of nodes and edges are masked with a specific token, that encourages the model to predict the original classes of the nodes and edges, as shown in Fig. A5a. Next, the DPR loss Lnoise aims to learn representative features for the experimentally solved protein structures, in which random spatial noises are applied to part of the protein nodes, that encourage the model to predict the original position of these nodes, as shown in Fig. A5b."}, {"title": "4.4.3 Training & evaluation for different tasks", "content": "CASF-2016. For the screening power, the model starts with the model eval-uated on the core set for the structure prediction task, where an additional task is included, i.e., predicting the probability of the SOM to be a true lig-and of a protein, to be complementary to the structure prediction task. The"}, {"title": "4.5 Metrics", "content": "The Root Mean Square Deviation (RMSD) value between the predicted and native structures is used to evaluate the structure predictions. The RMSD value of 2\u00c5 is widely adopted in related works[10, 86] as a standard to determine the success or failure of the prediction, as also adopted in this work.\nThe screening power was evaluated on 57 proteins coupled with 285 SOMs in CASF-2016. In this dataset, each protein has 5 ligands as true binding cases, then, the rest of the ligands are regarded as negative ones. The performance was assessed by the percentage of best ligands included in 1%, 5%, and 10% of the top-ranked ligands[86], and the best ligand is the ligand of the highest affinity among 5 true ligands for each protein. Besides, the enhancement factor (EF) is also used to assess the ability of screening which was introduced in Ref.[86]. In brief, EF is used to assess the ability to rank the true ligands on the top ranking position which also uses 1%, 5%, and 10% as cutoffs."}, {"title": "4.6 Configurations of docking tools", "content": "For docking tools, the ligands were firstly rotated 180\u00b0 through the Z-axis with their original conformation[10], followed by energy minimization with Open Bable toolbox[96]. The docking sites were determined by the native positions of ligands. The amount of generated poses for a certain ligand was set to 20, as also adopted in other works[13, 10, 15]. The number of CPU cores was set to 1 to calculate the time cost for prediction (i.e., inference time). The outputs were analyzed using RDKit[81]. Settings details of all docking tools are introduced in Suppl. Sec. A.7."}, {"title": "4.7 Data availability", "content": "PDBbind (version 2020) and CASF-2016 are available at http://www.pdbbind.org.cn. The PDBbind-CrossDocked-Core set is available"}, {"title": "4.8 Code availability", "content": "The source code of LigPose is available under an open-source license at https://gitfront.io/r/LigPose/kMWuV4DW6JpE/LigPose4Review/.\nSupplementary information. This paper accompanies supplementary information in the \"Supplementary Material\"."}, {"title": "4.3.4 Coordinate Update Block", "content": "The coordinate update block updates the coordinates of the nodes (atoms) in 3-D space based on the attentions derived from the feature update block, as also introduced in [95] (Fig. A3e-f). To be specific, the attention is transformed to a one-dimensional distance gradient, indicating the change in distance between the central node and each of its neighboring nodes. Then, the coordinate of a certain central node is updated by the sum of these distance gradients calculated with all neighboring nodes, as written by,\n\u0394lh = \u03a3 xj\u2212xixj \u03a6(qij \u2299 kij),\nj\u2208Neighbor(i) ||xi \u2212 xj ||2\nxl = xl + \u03a3 \u03bbh\u0394lh,\nh\u22081,...,Nh"}, {"title": "A.2.3 Coordinate update block", "content": "The coordinate update block updates the coordinate of the nodes (atoms) in 3-D space along with the feature update block, as inspired by [95]. Specifically, for the Ith block, the coordinates are updated as follows,\n\u0394h = \u03a3 x\u22121 \u2212 x\u22121W ah,\nj\u2208Neighbor(i) ||x\u22121 \u2212 x\u22121||2 ij\nx = xl\u22121 + \u03a3\u03bbh\u0394h\nh\u22081,..., Nh"}]}