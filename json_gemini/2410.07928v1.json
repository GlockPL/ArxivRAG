{"title": "The Function-Representation Unification Framework", "authors": ["Alfredo Ibias", "Hector Antona", "Guillem Ramirez-Miranda", "Enric Guinovart", "Eduard Alarcon"], "abstract": "Cognitive Architectures are the forefront of our research into developing an artificial cognition. However, they approach the problem from a separated memory and program model of computation. This model of computation poses a fundamental problem: the knowledge retrieval heuristic. In this paper we propose to solve this problem by using a new model of computation, one where the memory and the program are united: the Function-Representation. We propose a whole framework about how to implement and use these Function-Representations, and we explore their potential through mathematical definitions and proofs. We also talk about different ways to organise multiple Function-Representations, and explore the kind of functions that these Function-Representations can implement. Finally, we also explore the limitations of our proposal.", "sections": [{"title": "I. INTRODUCTION", "content": "Cognitive Architecture is a model of how the mind is though to work, that has an implementation in the form of computer instructions. Thus, the end goal of any Cognitive Architecture is to be able to reproduce cognition inside a computer. To solve this problem, most Cognitive Architectures are based on the model of computation our computers use, where there is a memory that stores the knowledge, and separately there is a set of programs that update, manipulate and work with the memory. This memory usually stores the knowledge in the form of representations, that are either prototypes or exemplars of the knowledge that is being represented. This kind of Cognitive Architecture is what has been termed a symbolic Cognitive Architecture, whose more famous examples are SOAR [1], [2] and ACT-R [3]. An alternative model of computation is the connectionist approach, also known as parallel distributed processing, where there is a bunch of processing units from which the functional behaviour of the system emerges. However, in this approach usually the processing units also separate memory from program, where they have a smaller memory full of partial representations and the manipulation functions are apart. The most famous example of the connectionist approach is Copycat [4], [5],\nalthough Artificial Neural Networks also could fall in this category if considered as a Cognitive Architecture.\nThe main problem of using separated memory and program is that, when needing to retrieve knowledge to work with, there is no clear integrated solution that will provide the right representations from memory. Moreover, there is a need for complex heuristics that, given the context, try to guess what are the representations that are needed to be retrieved from the memory. This poses a huge problem, as we are basically looking for a general algorithm that can, in front of any eventuality, find the correct representations in a constantly evolving memory. This is in fact like looking for the algorithm that solves any problem, as any knowledge retrieval algorithm has to know the solution for any problem that cognition aims to solve. This has not impeded each Cognitive Architecture to propose its own heuristics to perform this task, with more recent developments even proposing using a collection of heuristics instead of only one [6], [7]. But also none of those Cognitive Architectures have been able to recreate cognition in a computer.\nIn this paper we want to address this problem from a different optic. Instead of looking for such heuristic, we go back to the fundamental model of computation of the Cognitive Architecture and propose a radical change. Instead of developing Cognitive Architectures that separate memory and program, we propose to build Cognitive Architectures where the representation is the function. In this new setting, we will have a set of representations (memory) that at the same time will constitute the function (program) of the Cognitive Architecture. In that regard, we would need a connectionist approach, where each processing unit is a representation, and the function is determined by such representation. Then, from the connections between different processing units will emerge the intelligent behaviour.\nThis approach is not actually novel, as Artificial Neural Networks actually follow it. There, each neuron is a repre-sentation (their weights) and they process their inputs with their representation and produce an output that is passed onto the next neuron. In this paper we aim to provide a theoretical foundation to this approach, proving mathematically some of"}, {"title": "II. RELATED WORK", "content": "Cognitive Architectures can be roughly divided into three types, based on their knowledge processing patterns [8]: symbolic, emergent or hybrid. The symbolic Cognitive Archi-tectures store their representations as symbols and usually op-erate with formal logic. The emergent Cognitive Architectures focus on reproducing the human brain, and usually adopt a hierarchical structure. Finally, hybrid Cognitive Architectures try to find a middle ground between both, having hierarchical structures, behaviour emergence and symbolic processing.\nThe symbolic Cognitive Architectures build over the idea that our brains work with symbols and abstractions. Thus, all of them represent the environment as symbols and store them in a consistent knowledge base. To operate with the symbols, they tend to use formal logic, although more modern proposals try to exploit the advantages of fuzzy logic. Thus, due to their properties, they are mainly used for system control problems, like the ones found in robotics. Inside this group, there are some Cognitive Architectures designed to solve con-crete problems, like the control of military unmanned vehicles (4D/RCS [9], [10]), the control of robots (ADAPT [11], [12], CARACAS [13], REAPER [14]), the processing of images (DSO-CA [15], [16]), the support of decision-making for crisis response (NARS [17], [18]), and the interaction with humans (DIARC [19]). There is also a group of Cognitive Architec-tures that aim to solve the general intelligence problem, like Adaptive Control of Thought-Rational (ACT-R) [3], Belief-Desire-Intention (DBI) [20], Reflective Evolutionary Mind (REM) [21] and State, Operator, and Result (SOAR) [1], [2].\nThe emergent Cognitive Architectures try to \"reproduce\" the process of human cognition from bottom up. To that end, they adopt a hierarchical structure where the lower levels deal with perception while the highest level try to simulate an active consciousness. In that regard, the lower levels tend to run concurrently while the highest level solves the possible conflicts of consistency and chooses the behaviour to perform. This setup allows them to deal with uncertainty conditions quite well. Inside this group we also have the split between Cognitive Architectures designed to solve concrete problems, like the control of robots (ASMO [22], DAC [23], MDB [24]), and Cognitive Architectures that aim to solve the general intelligence problem, like Adaptive, Reflective Cognition in an Attention-Driven Integrated Architecture (ARCADIA) [25], Learning Intelligent Distribution Agent (LIDA) [26], and Sensory-Motor, Episodic Memory and Learning, and Central Executive (SEMLC) [27]. Additionally, there is an additional set of Cognitive Architectures that are based on computational neuroscience, like Brain-Based Device (BBD) [28] and Hier-archical Temporal Memory (HTM) [29], that aim to simulate the brain's function.\nFinally, the hybrid Cognitive Architectures take the best parts of each alternative, and try to blend them into a consistent architecture able to produce a cognition. To that end, they usu-ally adopt a hierarchical structure and contain both behaviour emergence from bottom up and direct symbolic processing. Inside this group there are mainly Cognitive Architectures that aim to solve the general intelligence problem, like Chunk Hierarchy Retrieval Structures (CHREST) [30], Connection-ist Learning With Adaptive Rule Induction Online (CLAR-ION) [31], and Synthesis of ACT-R and Leabra (SAL) [32].\nWhat all these Cognitive Architectures have in common is that they tend to use the same terms to refer to its different parts. Short Term Memory (STM), Long Term Memory (LTM) and Working Memory (WM) are the main kinds of memory explored, all in a model of computation where the memory is independent of the program. Perception and actuation are the main methods to interact with the world, while learning and attention are the main methods to update the memories and the reasoning functions. However, all these Cognitive Ar-chitectures follow the separated memory and program model of computation presented in Section I, and thus all of them are limited by their knowledge retrieval heuristics. The only approach to human intelligence that has avoid this problem is the Artificial Neural Networks. However, those have never been presented as a Cognitive Architecture, but instead as an optimisation method. Thus, they have not tried to build the commonplace elements that all Cognitive Architectures aim to develop."}, {"title": "III. THE FUNCTION-REPRESENTATION UNIFICATION FRAMEWORK", "content": "In this section we aim to present the broad aspect of our framework, and we will provide some examples of implemen-tations to illustrate it.\nOur framework revolves around the idea that the represen-tation has to be the function. Thus, its main component is\nthis Function-Representation. A Function-Representation has to have a special form, as not any representation can be used as a function. For example, a set of weights (like in an Artificial Neural Network) is a good Function-Representation because those weights can process any input and produce an output. However, a word or symbol is not a valid Function-Representation as some inputs cannot be processed with them.\nIn a more general sense, a representation that can be used as a function needs to fulfil a fundamental requisite: that it can be used to process an input and produce an output. This, usually, leads to the fact that the representation has to be in a numeric form. This is due to the fact that any function we know deals with numbers, with very few functions dealing with other kind of data types. However, if such a function exists and can be used to produce an output from any input, then nothing impedes for it to be used as the function of a representation that contains the data type it deals with.\nIn the end, a representation that is also a function can be distilled to a pair of data type and function, where the data type defines the kind of values the representation will store, and the function will use those values to process any input to produce an output. An example would be an image (that is, a vector of numbers) and an average function, that for an input image would produce an output image that is the average of the representation image and the input image. In a more formal way, a Function-Representation is a function parameterised by a set of values of a certain data type.\nThe other aspect of our framework is the need for con-nectionism. A processing unit by itself can only contain a Function-Representation and produce an output for each input it receives, but that is not enough to build a Cognitive Architecture. Thus, there is a fundamental need for connecting multiple processing units with one another. The specific con-figuration of the connections is not defined, as each kind of Function-Representation will have its own reasons to connect some processing units between themselves and not others. For example, in Artificial Neural Networks, the connections are done by layers, but not between the neurons in the same layer.\nThe only requirement for the connections is that they provide the output of a Function-Representation to another one, thus using the output of a Function-Representation as input of the following one. This in turn creates a hierar-chical structure that produces a higher level behaviour that emerges from the individual behaviour of each Function-Representation. In the previous image example, connecting one Function-Representation with the following one in turn produces a pattern matching algorithm.\nFinally, there is the question of learning. A Function-Representation needs to be learned, and new Function-Representations can be created if needed. However, these mechanisms depend a lot on the kind of Function-Representation that is being built. For example, Artificial Neu-ral Networks use backpropagation to learn based on an error measure, and do not create new Function-Representations, but in the previous image example, we may do not want to update the Function-Representation with the processed input, but instead create new Function-Representations at some point to expand the stored knowledge and improve the pattern matching capability.\nIn the end, the goal is to follow a novel model of com-putation where individual Function-Representations are the fundamental units of computation, with very simple com-putational mechanisms, and the complex behaviours arise from the interactions between those Function-Representations. To that end, it is critical to avoid global algorithms that organise or modify the Function-Representations, but instead develop mechanisms inside the Function-Representations that allow them to auto-organise and self-modify. For example, in Artificial Neural Networks, even backpropagation (commonly though to be a global learning algorithm) can be translated into a function of the own neurons, fulfilling the Function-Representation definition. We argue that this fact is key to explain why the Artificial Neural Networks have been able to obtain the outstanding results they have obtained, in so different scenarios, without needing to change the fundamental algorithm.\nHowever, we are aware that changing the computational paradigm is difficult. For example, the Artificial Neural Net-works have been developed following this model of computa-tion unconsciously, but instead applying the current separated memory and program model of computation and obtaining an algorithm that is equivalent in both models of computation. However, learning to program in this novel model of computa-tion is fundamental to develop Cognitive Architectures able to eventually emerge cognition, because the alternative is almost impossible."}, {"title": "IV. PROOFS", "content": "In this section we will explore some properties of our framework. Specifically, we will explore how Function-Representations contain knowledge, how that knowledge can be accessed without heuristics, and how higher-level behaviour emerges from the connectionism.\nTo begin with this, we need to find a definition for knowl-edge. As this is more of a philosophical question that we do not aim to solve in this paper, we decided to use a more pragmatic approach and define knowledge based on its utility, that is, in its capacity to transform data. Thus, we will define knowledge as a function that can be used to transform any input set into information. To that end, we will measure information following Shannon's Information Theory [33], so let us start by defining entropy:\nDefinition 1. Let A be a finite set and $\u03be_A$ be a random variable over A. We denote by $\u03c3_\u03be$ the probability distribution induced by A. The entropy of the random variable $\u03be_A$, denoted by $H(\u03be_A)$, is defined as:\n$H(\u03be_A) = -\\sum_{\u03b1\\in A} \u03c3_\u03be(\u03b1) \\cdot log_2(\u03c3_\u03be(\u03b1))$\nThe set A is said to contain information if and only if $H(\u03be_A) > 0$. If $H(\u03be_A) = 0$ then the set A is said to not contain information.\nNow, with this definition, let us define how a function over a set transforms random variables."}, {"title": "Theorem 1", "content": "Given two sets I and O and a function $f : I\\rightarrow O$. Let $\u03be_I$ be a random variable over I such that it induces an uniform probability distribution $\u03c3_{\u03be_I}$, then the function f transforms $\u03be_I$ into a random variable $\u03be_O$ over the set O such that it induces another probability distribution $\u03c3_{\u03be_O}$.\nProof. Given the random variable $\u03be_I$, as it produces an uni-form probability distribution $\u03c3_{\u03be_I}$, over I, it implies that you can pick each element of I with the same probability. If we then process those elements of I with f, we get a set of elements of O, each one with its own probability based on how many elements of I are transformed via f into such element of O. Thus, this produces a probability distribution $\u03c3_{\u03be_O}$ that has to come from a random variable $\u03be_O$ over O. Therefore, f transforms $\u03be_I$ into $\u03be_O$."}, {"title": "Theorem 2", "content": "Given two sets I and O and a function $f : I\\rightarrow O$. Let $\u03be_I$ be a random variable over I such that it induces an uniform probability distribution $\u03c3_{\u03be_I}$, and let the function f transform $\u03be_I$ into a random variable $\u03be_O$ over the set O such that it induces another probability distribution $\u03c3_{\u03be_O}$. Then, the output set O contains information via f if and only if the entropy of $\u03be_O$ is greater than 0.\nProof. By Definition 1, as $\u03be_O$ is a random variable over O (produced from the random variable $\u03be_I$ over I via f), then it is said to contain information if and only if $H(\u03be_O) > 0$. Thus, by extension, O contains information via f due to f being the function producing $\u03be_O$.\nNow, let us define a function as knowledge if and only if its output set has more than one value."}, {"title": "Theorem 3", "content": "Given two sets I and O and a function $f : I \\rightarrow O$, then f is knowledge if it transform inputs $i \\in I$ into outputs $o \\in O$ and the size of the output set O is greater than 1. That is, $|O| = |\\{o|f(i) = o, with i \\in I, o \\in O\\}| > 1$.\nProof. Let us start assuming a uniform distribution over I. By Theorem 1 f produces a random variable $\u03be_O$ over the set O. As the set O is defined by the possible values that f can produce from the set I, then |O| = 1 if and only if all the elements of I are transformed into the same element. By Theorem 2 the output set O contains information via f if and only if the entropy of $\u03be_O$ is greater than 0. And that only happens when $|O| > 1$ by Definition 1.\nThis knowledge definition allows us to say that any function that transforms inputs into outputs is knowledge, as long as the output set size is greater than 1. That implies that an Artificial Neural Network neuron whose set of weights is all zeros is not knowledge, because they transform any input into the same output value: 0.\nNow, we need to define a Function-Representation with its data type and its function."}, {"title": "Definition 2", "content": "Given a data type D with a set of possible values D, and a function $f : D \\times D \\rightarrow D$, then a Function-Representation is the function f parameterised by a value (or set of values) $v \\in D$.\nThis basic definition allows for the data type D to be any kind of data type, as long as a function f exists."}, {"title": "Theorem 4", "content": "Given a Function-Representation r with data type D (with a set of possible values D) and function $f: D\\times D \\rightarrow D$, then r contains knowledge if and only if f is not a constant function.\nProof. First, let us prove that if f is not a constant function, then r contains knowledge. Let us assume that r does not contain knowledge, then, by Theorem 3, the size of the output set should be 1. That is, $|O| = |\\{o|f(i,v) = o, with i \\in D, v \\in D, \u03bf \\in D\\}| = 1$. Now, as f is not a constant function, then $\u2203c_1, c_2 \\in D, i_1, i_2 \\in D|f(i_1, v) = c_1$ and $f(i_2,v) = c_2$. Thus, $|O| > 1$ and therefore r contains knowledge.\nNow, let us prove that if r contains knowledge, then f is not a constant function. Let us assume that f is a constant function. The fact is that, as f is a constant function, then it always returns the same value for any input. Thus, $\u2203c \\in D|f(i, v) = c \u2200i \\in D, v \\in D$ for a specific c $\u2208$ D. Now, as r contains knowledge, $|\\{o|f(i, v) = o, with i \\in D, v \\in D, o \\in D\\}| > 1$. This means that f has an output set with a size higher than 1, thus f can not be a constant function.\nThis result is critical, as this is the base over which the rest of proofs are built. This also implies that any kind of Function-Representation has the potential to contain knowledge.\nNow, let us explore how we can access the knowledge in a Function-Representation without using complex heuristics. This stems easily from the fact that the representations include their own functions, thus, for any input, they process them with their function and retrieve the output, that is, the input has been processed with the knowledge that the Function-Representation contains."}, {"title": "Lemma 1", "content": "Given a Function-Representation r with data type D (with a set of possible values D), values v \u2208 D, and non-constant function $f : D \\times D \\rightarrow D$, and given an input $i\u2208D$, then the output $o = f(i,v)$ has been processed with the knowledge contained in r.\nProof. As r is composed of the function f and the set of values v by Definition 2, and f is knowledge by Theorem 4 because it is not constant with the values v. Then, $o = f (i, v)$ has been processed by the knowledge stored in f and v, that is, the knowledge contained in r. It is actually a transformation of i by the knowledge of f and v.\nThis shows both how the knowledge is easily accessed, but at the same time how limited is the use of such knowledge, as it can only be used to perform the transformation defined by function f. This in fact is a limitation that impedes the use"}, {"title": "Definition 3", "content": "Given two Function-Representations $r_1$ and $r_2$ both with data type D (with a set of possible values D), with values $v_1 \\in D$ and $v_2 \\in D$ respectively, and with functions $f_1: D\\times D \\rightarrow D$ and $f_2 :D \\times D \\rightarrow D$ respectively, a connection forms a pipeline in which, for any input $i \\in D$, $r_1$ is applied first producing an output $o_1 \\in D$ and then $r_2$ is applied over such output to produce a final output $o \\in D$. That is, a connection is the function $f_2(f_1(i, v_1), v_2) = o$.\nWith this definition, we can see how connections work to compose the individual functions of each Function-Representation into a global, bigger function. Here it is important to notice that, for example, in the case of Artificial Neural Networks, the function is not only the multiplication of the weights by the input and the sum of the results, but also the application of the activation function.\nFinally, we just need to explore what is needed for the func-tion result of connecting multiple Function-Representations to produce an emergent behaviour. In that sense, we will consider that there is emergent behaviour if none of the individual Function-Representations could have produced such function."}, {"title": "Definition 4", "content": "A composition f' of different parameterisations of function f with parameters $v_1, v_2$ produces emergent be-haviour if and only if $f' = f(v_2) \\circ f (v_1)$ cannot be simplified to a parameterisation of f.\nWe are aware that this definition of emergent behaviour does not cover all possible kinds of emergent behaviour, but it covers at least one kind of them, and that is enough for us to prove that some kind of emergent behaviour is produced."}, {"title": "Theorem 5", "content": "Given two Function-Representations $r_1$ and $r_2$ both with data type D (with a set of possible values D), with values $v_1 \\in D$ and $v_2 \\in D$ respectively, and with function $f : D\\times D \\rightarrow D$, and a connection between them that produces the function $f'(i) = f(f(i, v_1), v_2)$, then the function f' produces emergent behaviour if and only if f is not a linear function.\nProof. Let us start by proving that if f' produces emergent behaviour, then f should not be a linear function. Let us assume that f is a linear function, then its composition can be simplified to a linear function. Now, as f' produces emergent behaviour, then $f' = f \\circ f$ cannot be simplified to a linear function by Definition 4, and thus f should not be lineal.\nLet us now prove that if f is not linear, then f' produces emergent behaviour. Let us assume that f' does not produce emergent behaviour, then by Definition 4 $f' = f \\circ f$ can be simplified to a linear function. As f is not a linear function, the composition $f \\circ f$ cannot be simplified to a linear function due to the non-linearity present in it. Thus, f' should produce emergent behaviour."}, {"title": "Definition 5", "content": "Given a parameterised function $f : D\\times D \\rightarrow D$, and a function $f' = f \\circ f$, then f' is self-similar if and only if $f' = f$.\nThis definition will be useful to generalise our findings, as what we are going to explore is not limited to lineal functions."}, {"title": "Theorem 6", "content": "Given a parameterised linear function $f : D \\times D \\rightarrow D$, and a function $f' = f \\circ f$ that is the composition of two parameterisations of f, then f is self-similar.\nProof. Let us get two parameterisations $v_1 \\in D$ and $v_2 \\in D$ of f such that $f' = f(v_2) \\circ f(v_1)$. Then $f'(i) = f(f(i, v_1), v_2)$, but as f is a lineal function, then $\u2203v' \\in D|f(f(i, v_1), v_2) = f(i, v') \u2200i \\in D$. This makes $f'(i) = f(i,v')$, and thus f' is equivalent to a parameterisation of f. By Definition 5, that means that f' is self-similar, and thus f is self-similar by equivalence."}, {"title": "Theorem 7", "content": "Given two Function-Representations $r_1$ and $r_2$ both with data type D (with a set of possible values D), with values $v_1 \\in D$ and $v_2 \\in D$ respectively, with self-similar function $f: D\\times D \\rightarrow D$, and a connection between them, then the resulting structure is equivalent to have a single Function-Representation.\nProof. As the function f is self-similar, then for the function $f'(i) = f(f(i, v_1), v_2)$ produced by the connection we have that $f' = f$ by Definition 5. As f' = f then $\u2203v' \\in D|f'(i) = f(i, v') \u2200i \\in D$. Then, there exists a Function-Representation r with values v' and function f that is equivalent to the con-nection between $r_1$ and $r_2$. Thus, the connection is equivalent to have a single Function-Representation."}, {"title": "V. CASE STUDIES", "content": "In this Section we will introduce some case studies that show how this theory can be implemented. Specifically, we will explore the different cases based on how the Function-Representations are connected. We will start with the sequen-tial case, where we will use Artificial Neural Networks as an example. We will continue with the parallel case, where we present a very basic proposal of Function-Representation. And we will finish with the hybrid case between sequential and parallel, where we will present a more complex proposal of Function-Representation. It is important to note that this section will be more of a thought experiment, where we will try to base our thoughts in the theory outlined in the previous sections."}, {"title": "A. The Sequential Case", "content": "Let us explore first the sequential case. This case is defined by organising a set of Function-Representations connecting one after another in a sequential fashion. As an example of a sequential Function-Representation we will explore the Artificial Neural Networks. They are a well known implemen-tation of Function-Representation where each neuron is an individual Function-Representation whose representation are the weights and whose function is comprised of three steps: the multiplication of each weight for the value of the input, the sum of all the resulting values, and the application of a non-linear function to the result. As can be derived from this definition, in the end each neuron is a parameterised function, whose parameters are the internal representation of the acquired knowledge. In the case of neurons, the Function-Representation aims to build any kind of mapping function from a space of inputs to a space of outputs. Thus, the set of inputs typically has a different dimension size than the set of outputs and the training focuses on minimising the error between the produced output and the expected output. This setup is more suited for optimisation and generalisation, although not so useful for building a Cognitive Architecture.\nThe fact that the dimension size of the input and output of a neuron is not the same allows the neurons to be placed in parallel to process differently the same input, and thus being able to provide an input of dimension higher than 1 to the next layer of neurons. However, this does not make the Artificial Neural Networks a sample of the parallel case, because in the end all this structure works like a sequential set of Function-Representations, as the output is unique for each input."}, {"title": "B. The Parallel Case", "content": "Let us explore now the parallel case. In this case, the determining factor is that multiple Function-Representations process the same input in parallel and produce multiple outputs, from which later we have to decide which one to keep. To propose a Function-Representation suited for this case, we would like to explore different alternatives, maybe more suited for Cognitive Architectures. For example, one could think on a Function-Representation whose goal is to refine the input, ideally archetyping it. To that end, the representation will be a set of weights as in the previous case, but the function will be a multiplication of each value of the input and their corresponding weight. Same as before, this way we will have a parameterised function, whose parameters are the internal representation of the acquired knowledge. However, in this case, the training would focus on generating an abstraction or archetype of the input. This proposal lacks the non-linearity, and thus connecting multiple Function-Representations of this kind would be useless. However, in a setup where we have multiple non-connected Function-Representations in parallel, each one with a different set of weights, we can select as output of the system the one most similar to the input. This would work as a memory, where each Function-Representation would be a memory of an archetype and the result of the whole system would be the retrieval of the archetypal memory of the input."}, {"title": "C. The Hybrid Case", "content": "Finally, let us explore a hybrid case between the parallel and sequential ones. In this case, the defining factor is that we will have multiple Function-Representations that would process the same input, but at the same time there will be another set of Function-Representations, connected to the first ones, that would provide depth to the structure. In that sense, we will have again a set of outputs from which later we will have to decide which one to keep as output. To propose a Function-Representation suited for this case, and following the idea of the parallel case, we can propose a more complex Function-Representation. For example, we can propose a Function-Representation where the representation are still a set of weights, but the function is the multiplication of the weights by their corresponding input value, and then apply a non-linear function to the result. To that end, we would need to define similarity and non-linear functions, and thus there would be multiple alternatives of this kind of Function-Representation based on the different alternatives of similarity and non-linear functions. In this case, we still have a parameterised function, whose parameters are the internal representation of the acquired knowledge, and training would focus again on generating an abstraction or archetype of the input. However, thanks to the non-linearity of this Function-Representation, we can connect multiple Function-Representations one after another in order to build more complex abstractions of the input. Additionally, we can also build multiple non-connected Function-Representations and choose between them based on the most similar representation to the input, like in the previous case but this time with an additional depth due to multiple Function-Representations being connected in chain to build more complex abstractions."}, {"title": "VI. THE FUNCTION", "content": "A fundamental element of any Function-Representation is its function, as it will limit and bound its capabilities. In this sense, a very limiting function will allow to develop systems able to solve a specific kind of problems, but not general enough to solve any other problem. For example, if your function is a simple linear function, then you will be able to solve problems whose solution space can be divided by a linear function. To generalise this notion, the fact is that the chosen function acts like a generator, where depending on the function the generated function space is different. This function space will be the space of all the functions that the Function-Representation can represent, thus limiting the problems it can solve. If the connection of functions generates new functions through emergence, it can overcome the limitations of the generated function space by increasing it with new generators, but this requires a very specific kind of functions.\nRegarding the types of base functions we can produce, we propose a difference between reversible and not reversible functions, what we call associative or additive functions respectively. Associative functions will be those that keep intact the associations between the inputs, and thus are able to retrieve those associations also from the output. To fulfil this description, the function needs to be bijective, as we will prove later. In that sense, the function is respecting the association between the input data, hence the name associative. If the function is not bijective, then we have a function that will comprise the initial data into the output without option for reversibility. In that sense, this kind of functions adds the input data to produce the output, not respecting the association between the data, hence the name additive. More formally, we need to define additive and associative function."}, {"title": "Definition 6", "content": "Given a data type D with a set of possible values D, and a function $f : D \\times D \\rightarrow D$, then f is associative if and only if it keeps the associativity between the input values in the output, that is, the input values are transformed into reversible output values."}, {"title": "Definition 7", "content": "Given a data type D with a set of possible values D, and a function $f : D \\times D \\rightarrow D$, then f is additive if and only if it collides the values of the input into non-reversible output values.\nThis two definitions will allow us to differentiate between different kinds of functions for our Function-Representations, but first, let us define them in mathematical terms."}, {"title": "Theorem 8", "content": "Given a data type D with a set of possible values D", "f": "D \\times D \\rightarrow D$, then f is an associative function if and only if it is bijective.\nProof. Let us start by proving that if f is bijective, then f is associative. Let us assume that f is not associative, then there exists an input value i whose output value o = f(i) is not reversible, that is, there is no f' such that f'(o) = i. Now, as f is bijective, then it is injective and surjective. As it is injective, there exists $f' = f^{-1}$ such that $f'(o) = f'(f(i)) = i \u2200i \\in D$, and thus f should be reversible.\nLet us now prove that if f is associative, then f is bijective. Let us assume that f is not bijective, then it is either not injective or not surjective. Now"}]}