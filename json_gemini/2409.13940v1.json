{"title": "Learning Recourse Costs from Pairwise Feature Comparisons", "authors": ["Kaivalya Rawal", "Himabindu Lakkaraju"], "abstract": "This paper presents a novel technique for incor- porating user input when learning and inferring user preferences. When trying to provide users of black-box machine learning models with ac- tionable recourse, we often wish to incorporate their personal preferences about the ease of mod- ifying each individual feature. These recourse finding algorithms usually require an exhaustive set of tuples associating each feature to its cost of modification. Since it is hard to obtain such costs by directly surveying humans, in this paper, we propose the use of the Bradley-Terry model to automatically infer feature-wise costs using non-exhaustive human comparison surveys. We propose that users only provide inputs compar- ing entire recourses, with all candidate feature modifications, determining which recourses are easier to implement relative to others, without explicit quantification of their costs. We demon- strate the efficient learning of individual feature costs using MAP estimates, and show that these non-exhaustive human surveys, which do not nec-essarily contain data for each feature pair com- parison, are sufficient to learn an exhaustive set of feature costs, where each feature is associated with a modification cost.", "sections": [{"title": "1. Introduction", "content": "As machine learning models have come to be deployed in more and more fields concerning daily human life, interest has grown commensurately in understanding these models and making them interpretable to end users. One way to do this is to construct a counterfactual explanation (Wachter et al., 2018) which represents a small modification to the model inputs in order to obtain a desirable output. When they incorporate user preferences regarding the mutability of features, these explanations can be thought of as providing actionable recourse, as they enable the users of the models learn about the modifications required to obtain desirable outcomes (Ustun et al., 2019).\nIn high stakes decision settings such as credit scoring, pro- cessing bail applications, or making hiring decisions, appli- cants often seek recourse to correct unfavourable predicted outcomes for the future. In these scenarios, since there can be multiple possible recourses for each individual, fea- sibility considerations, user preferences, and heuristics to minimize the size of the proposed modifications are used to guide the search for appropriate recourses (Poyiadzi et al., 2020; Pawelczyk et al., 2020; Joshi et al., 2019). Recourse search algorithms thus return the best possible recourse based on these considerations by performing a search over the feature-space of the model.\nSpecific techniques used by various recourse search algo- rithms are beyond the scope of this paper, however a re- course search algorithms can be generalized to involve users directly deciding the relative costs of modifying each fea- ture. For example, in figure 1 above, if we do not use any proxy reliant on data distributions or heuristics, human in- put is necessary to gauge whether Recourse 1 is easier than Recourse 2. However, it is hard for users to place exact num- bers on how easy it is to modify one feature versus another. For instance, it can be notoriously difficult to survey people for the value of n from the following question: Modifying address is 'n' times easier than modifying income. What is an appropriate value of 'n'?. By comparison, the ques- tion: Is modifying address easier than modifying income? is much more human friendly, as people are much more comfortable ranking, ordering, and comparing quantities than explicitly assigning numeric values to them (Chaganty & Liang, 2016).\nContributions: In this paper, we first show that compar-"}, {"title": "2. Methods", "content": "In this section we provide a brief description of our solu- tion leveraging the Bradley-Terry model, which finds the MAP estimates of the ease-of-modification costs for every feature used in the model, using pairwise comparison data surveyed from human users. We initially assume this survey to be exhaustive and contain a human response indicating the easier-to-modify feature between all possible pairs of features. Later we relax this condition and instead only use human inputs to decide which of two recourses as a whole (potentially consisting of multiple feature modifica- tions each) is easier to implement.\nThe Bradley-Terry Model: Consider a trained black-box model B, which operates upon vectors consisting of fea- tures F to output a binary classification +1 or -1. Any given recourse modifies some features RCF to change the classifier prediction. The Bradley-Terry model is a proba- bilistic model based upon Luce's choice axiom (Luce, 1959; Bradley & Terry, 1952). It works by assigning a strength parameter Bf to each feature f \u2208 F employed by the model. Let f > g denote that feature f is easier to modify than feature g for any two arbitrary features f, g \u2208 F, where f \u2260 g. The probability $p_{f>g}$ that a feature f is easier to modify than g is then defined using the strength parameters Bf and Bg of the two features, respectively, as:\n$P_{f>g} = \\frac{e^{\\beta_f}}{e^{\\beta_f} + e^{\\beta_g}}$\n(1)\nThe Bradley-Terry model thus probabilistically captures comparison relationships between features, and maintains transitive relations (that is, if feature f is probably easier to modify than feature g, which is probably easier to modify than feature h, then feature f is also probably easier to modify than feature h). We can survey users with different pairs of features f, g \u2208 F asking which of the two is easier to modify. In our probabilistic setting, we presume that the result of surveying the comparison between the same two features f and g can provide differing results f > g and g > f at different times. If this survey is exhaustive and consists of all possible pairs of features, then we can estimate pfg using its relative frequency by simply counting the occurrences of #(f > g) and dividing by the total comparisons between f and g, $P_{fg} = \\frac{\\#(f>g)}{\\#(f>g)+\\#(g>f)} $.\nThere exist many algorithms to infer the Bradley-Terry strength parameters from this data. Minorization- maximization algorithms provide Maximum Likelihood Es- timates (MLE) for the Bradley-Terry strength parameters. However, since the MLE is not guaranteed to be unique for Bradley-Terry models, in this paper we prefer to use the Maximum A Posteriori (MAP) estimate, obtained after assuming uniform priors (Caron & Doucet, 2012; Hunter, 2004). Gibbs samplers have been found to work well for MAP parameter estimation of Bradley-Terry models. Indi- vidually, the strength parameters B\u2081 can be understood to represent the ease of modification of each individual fea- ture. Thus, starting with a set of pairwise comparisons of the ease-of-modification, we can find the MAP estimates of the Bradley-Terry model strength parameters, and con- sider the additive inverse of these to be the feature costs Vf \u2208 F, Cost(f) = -Bf.\nThe Bradley-Terry model explicitly yields the probability of a single feature being easier-to-modify than another. This can be extended to represent the probability of an entire set of features together being easier-to-modify than another. Consider two different recourses (sets of features) to mod- ify: R1 C F and R2 \u2286 F. If |R1| = m and |R2| = n, and assuming 0 \u2264 k \u2264 min(m, n) features are common between both recourses, we have (m-k) \u00d7 (n-k) pairwise comparisons across the two possible recourses. For each feature pair f \u2208 R1,g \u2208 R2, we can compute pf>g and use these to compute the corresponding probability that R1 is easier to modify than R2 defined as PR\u2081>R2 using the following formula (assuming k = 0):\n$P_{R_1>R_2} = \\frac{\\sum_{f\\in R_1, g\\in R_2} P_{f>g}}{\\sum_{f\\in R_1, g\\in R_2} P_{f>g} + \\sum_{f\\in R_1, g\\in R_2} P_{g>f}} = \\frac{\\sum_{f\\in R_1, g\\in R_2} P_{f>g}}{m \\times n}$\n(2)\nIntuitively, PR\u2081>R2 represents the overall probability that, with f\u2208 R\u2081 and g \u2208 R2, more feature pairs (f, g) are of the form f > g than g > f. In practice, this can be easily computed using a Monte Carlo simulation. The case when"}, {"title": "3. Simulations", "content": "In this section we describe the simulations we ran to ver- ify if our approach could learn numeric feature costs from only pairwise comparisons. Instead of surveying real hu- man users, we chose to simulate the data generation process algorithmically. We ran 4 different simulations postulating a Bradley-Terry model over different possible feature sets F of varying sizes. The strength parameters were drawn uniformly between 0 and 1 and used to generate the com- parison data consisting of statements of the form f > g for arbitrary f, g \u2208 F. Finally we computed MAP estimates of"}, {"title": "4. Conclusion", "content": "In this work we have shown the importance of having numer- ical costs to measure the ease of modification for each fea- ture, when generating recourse. We have also demonstrated how these costs can be inferred using the Bradley-Terry model, without requiring them to be supplied directly by users. Further, our technique only requires users to indicate which among the finally generated recourses are easier to implement, rather than explicitly compare inane features. While our simulation shows that these comparisons of sets of features are enough to learn costs over individual features, the theoretical proof for this remains to be found as future work."}, {"title": "Importance of Numeric Costs:", "content": "We show here that, in order to select between multiple potential recourses, it is insufficient to have access only to pairwise comparisons without explicit numeric costs on every feature. The feature- wise Bradley-Terry strength parameters Bf can, however, be used to compare the overall ease of modification of two different potential recourses. Thus, this provides us with a way to guide our recourse search algorithms to find the best possible recourses for end users. Consider a given data instance I with corresponding recourse R. We define recourse R to be ideal if no other recourse R' exists for the same data instance I such that PR>R' < PR'>R. Intuitively, R thus represents a recourse of minimal cost. Finally, we define a recourse R to be disambiguated if it can be asserted with certainty whether R is ideal or non-ideal.\nTheorem 2.1. Given an order over feature costs, without their exact values, not all possible recourses can be disam- biguated.\nProof. To show that not all possible recourses can be disam- buguated is the same as showing that there exists at least one recourse R that cannot be disambiguated - that is R cannot be shown necessarily to be ideal or non-ideal. Thus we wish to construct a recourse that is not possible to disambiguate. We can demonstrate that a recourse cannot be disambibuated if there exist two sets of costs C\u2081 and C2 over the same set of features F such that the features always have the same order, when sorted by cost, and R is determined to be ideal using one C1, but non-ideal using C2. In this case, since both sets of costs would follow the same order, but differ only in numeric value, it would become necessary to know the numeric value of the costs in order to disambiguate the recourses.\nWe construct such a scenario using the example recourses in Figure 1. Consider F = {amt, add, inc, age}, with one set of costs being C\u2081 = \u2212ln(10), \u2212ln(3), \u2212ln(2), -ln(1) for each feature, respectively, and another set being C2 = -ln(10), -ln(9), \u2212ln(8), \u2212ln(1). Even though C1 \u2260 C2, the order of the relative order of the feature costs is the same in both cases. We consider Recourse 1 from the figure to be R, and Recourse 2 to be R'. Thus each recourse modifies two features, R\u2081 = {amt, age} and R2 = {add, inc}. Using feature costs from C1, we can now compute $P_{amt>add} = \\frac{e^{ln(10)}}{e^{ln(10)}+e^{ln(3)}} = \\frac{10}{10+3} = \\frac{10}{13} = 1$.  Similarly, we get $p_{amt>inc} = \\frac{10}{10+2}$, $P_{inc>add} $,and $p_{age>inc}$. These quantities can be used to calculate PR>R' = 0.55, and similarly PR'>R = 0.45, that is PR>R' > PR'>R(1). However, using feature costs from C2, we get PR>R' = 0.32, and PR'>R = 0.68, which indicates PR>R' < PR'>R(2), showing that R is not ideal. Equation (1) indicates, however, that provided R and R' are the only possible recourses, R is ideal. Since"}, {"title": "Comparing Recourses instead of Features:", "content": "We have now shown the theoretical need for numeric costs associated with individual features, so that recourse generation algorithms can effectively find meaningful recourses for end users. We have also shown how existing techniques, leveraging MAP estimation algorithms for the Bradley-Terry model, can re- trieve these numeric costs when provided with survey data consisting of pairwise comparisons over all possible pairs of features. We now briefly postulate an extension to our proposed solution so far. An underlying assumption we have made is that users will be able to provide meaningful comparisons between all sets of features. This can be ex- tremely hard in real world scenarios. For instance, it can be hard to decide which of two immutable features such as race and national-origin is less easy to modify. Since we are postulating that the Bradley-Terry model applies over features, we believe the latent strength parameters Bf exist for every feature f \u2208 F, but that users might find it dif- ficult to actually provide the comparison data for certain features. To make our survey mechanism robust to poten- tially inane choices that can arise when comparing single features, we propose the comparison of two recourses rather than two features. Thus, instead of asking humans to pro- vide ease-of-modification comparisons f > g or g > f of single features f \u2208 F and g \u2208 F, we instead ask them provide comparisons R1 > R2 or R2 > R1 between entire recourses (subsets of features) R\u2081 C F and R2 C F. In- stead of observing pf>g values from our surveys, we thus aim to directly observe PR\u2081>R2 values, and use these to infer individual Bradley-Terry strength parameters for each single feature. When running MAP inference algorithms for the strength parameters Bf, we parse each occurrence R1 > R2 in our survey data as f > g\u2200f \u2208 R1,9 \u2208 R2. We demonstrate experimentally in the following section that this approach can indeed retrieve individual Bradley-Terry parameters without pairwise comparisons."}]}