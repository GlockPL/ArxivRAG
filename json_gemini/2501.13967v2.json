{"title": "FedDAG: Federated Domain Adversarial Generation Towards Generalizable Medical Image Analysis", "authors": ["Haoxuan Che", "Yifei Wu", "Haibo Jin", "Yong Xia", "Hao Chen"], "abstract": "Federated domain generalization aims to train a global model from multiple source domains and ensure its generalization ability to unseen target domains. Due to the target domain being with unknown domain shifts, attempting to approximate these gaps by source domains may be the key to improving model generalization capability. Existing works mainly focus on sharing and recombining local domain-specific attributes to increase data diversity and simulate potential domain shifts. However, these methods may be insufficient since only the local attribute recombination can be hard to touch the out-of-distribution of global data. In this paper, we propose a simple-yet-efficient framework named Federated Domain Adversarial Generation (FedDAG). It aims to simulate the domain shift and improve the model generalization by adversarially generating novel domains different from local and global source domains. Specifically, it generates novel-style images by maximizing the instance-level feature discrepancy between original and generated images and trains a generalizable task model by minimizing their feature discrepancy. Further, we observed that FedDAG could cause different performance improvements for local models. It may be due to inherent data isolation and heterogeneity among clients, exacerbating the imbalance in their generalization contributions to the global model. Ignoring this imbalance can lead the global model's generalization ability to be sub-optimal, further limiting the novel domain generation procedure. Thus, to mitigate this imbalance, FedDAG hierarchically aggregates local models at the within-client and across-client levels by using the sharpness concept to evaluate client model generalization contributions. Extensive experiments across four medical benchmarks demonstrate FedDAG's ability to enhance generalization in federated medical scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "WITH the continuous advancement of medical research and clinical practice, the medical field generates substantial data [1], [2]. However, these data are often scattered across different healthcare institutions. Due to legal and regulatory restrictions, centralizing these data for training is probably infeasible [3], [4]. Federated Learning (FL) [5] enables multiple clients to collaborate on training models without data centralizing or sharing, ensuring that patient privacy is protected throughout the process. However, the existing methods of FL are sensitive to domain shifts, which occur when the target domain has a different data distribution than the source domains [6]. Neglecting the influence of domain shifts may limit the applications of FL models in real-world scenarios [7]. For instance, when a healthcare institution outside the federation aims to use the model trained by multiple other institutions inside the federation, the model often performs poorly due to the significant domain shifts [8], [9], [10].\nRecently, Federated Domain Generalization (FedDG) has emerged as a new focus [8]. Unlike the setting of Domain Generalization (DG), FedDG aims to train a model from multiple source domains without data centralization and enable the model to generalize well on the unseen target domains [8]. To achieve this generalization objective, various pioneered methods have been proposed [8], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27]. For example, some existing methods primarily focus on model structure and aggregation strategies, aiming to effectively improve the generalization ability of the global model [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25]. Although these methods typically exhibit good generalization ability on known source domains, their performance on unseen target domains is often sub-optimal when significant domain shift occurs [28]. Other methods focus on increasing data diversity and simulating potential domain gaps by sharing and recombining local domain-specific attributes from different clients [8], [11], [12], [13], [14], such as the distribution of images and features. However, these domain attributes contain local private information. Although it is challenging to reconstruct the training data from such attributes, their leakage remains prohibited due to regulatory constraints [4]. Moreover, recombining local domain attributes merely expands the local data yet still within the global distribution rather than touching the out-of-distribution of global data. This implies the difficulty for these methods to approximate the domain shifts, which limits their generalization capability on unseen target domains.\nNovel domain generation is a promising solution to approximate the domain shifts and improve the model generalization ability to unseen target domains [29], [30], [31], [32], [33], [34], [35], [36], [37], [38]. These methods can generate novel-style images with significant visual differences compared to source domains, through domain-level adversarial generation or the diffusion model with domain-related prompts. The distribution of these generated images could differ from not only the local data distribution but also the global data distribution. They expand the training data distribution, which can reflect domain shifts between target and source domains. Therefore, effectively leveraging these generated images can improve model generalization capability. However, introducing novel domain generation into federated medical scenarios is non-trivial and faces challenges from two aspects. As for medical scenarios, the gaps among the different clients are more ambiguous than natural scenarios [39], [40], [41]. Thus, it may be insufficient to perform effective novel domain generation by the conventional learning paradigm, i.e., adversarial generating via domain labels or domain-related prompts [29], [30]. Moreover, constraining the semantics is essential, which are susceptible in the generated process. Uncontrolled generation may lead to the loss of some key semantics, significantly affecting the generalization performance of the model [42], [43], [44], [45]. As for federated scenarios, conducting novel domain generation on different clients can cause divergent performance improvements of client models, due to the data isolation and heterogeneity [46]. It can exacerbate the generalization contribution imbalance of local models to the global model, neglecting such imbalance may lead the model generalization to be sub-optimal [18]. As can be imagined, the sub-optimal model can limit generation effectiveness since it plays an important role in the adversarial generation paradigm.\nThis paper proposes Federated Domain Adversarial Generation (FedDAG), a simple-yet-efficient framework to address the above challenges and improve the model generalization ability by adversarially generating data different from global data distribution. Specifically, it performs adversarial generation on each client locally, aiming to generate novel-style images with similar semantics but different visual styles. To encourage the generation of images with novel styles beyond the global rather than merely local distribution, FedDAG shares generators from different clients. Besides, to tackle the challenges raised by medical scenarios, FedDAG generates images by performing instance-level adversarial learning, bypassing the challenges caused by ambiguous labels in the medical scenarios. FedDAG maintains the semantics consistency of generated images by dual-level semantic constraints"}, {"title": "II. RELATED WORK", "content": null}, {"title": "A. Domain Generalization", "content": "Domain Generalization (DG) aims to train a model that can generalize under the domain shifts between the target and source domains by centralizing data from multiple data distributions [41]. Some existing DG methods aim to learn domain-invariant representations by reducing the focus on style information of source data [47], [48], [49]. For example, some methods utilize contrastive loss to mitigate the disparity between data from different domains [47], [48], and some conduct meta-learning based on the potential domain shifts simulated by dividing the source data into disjoint meta-train and meta-test sets [49]. Moreover, some methods improve model generalization from the perspective of increasing data diversity [29], [30], [31], [32]. Representatively, DDAIG trains a generator to generate images that are recognizable by the task classifier but not by the domain classifier [30], while ATS maintains the difference between generated and source data based on a teacher-student paradigm, thereby increasing source data diversity [31]. From this perspective, generative adversarial networks (GANs) or diffusion methods can also be used to solve DG problems based on their effectiveness in creative generation [33], [34], [35], [36], [37], [38]. However, despite potentially improving generalization on the unseen target domain, these methods typically benefit from or necessitate data centralization during training, which is infeasible in FL due to privacy concerns. Thus, although these DG methods can be performed without data centralization [30], [31], [32], [33], [34], [35], [36], [37], merely exploiting information from a single client leads the model to be sub-optimal [14]. In contrast, this paper focuses on training a federated model with good generalization under data isolation, which is more challenging than centralized DG. Among these works, novel domain generation [29], [30], [31], [32] inspires FedDAG the"}, {"title": "III. METHODOLOGY", "content": null}, {"title": "A. Preliminaries", "content": "1) Learning Objective: We denote the set of source domains in this paper as $\\mathcal{D} = \\{D_1, D_2, ..., D_n\\}$, with client $i$ holding a set of $N_i$ image and label pairs $D_i = \\{(x, y)\\}_{j=1}^{N_i}$, drawn from a data distribution $(\\mathcal{X}, \\mathcal{Y})$. This paper aims to leverage n distributed client data to train a federated model $F$ that can generalize well to the unseen target domain $U$ by generating novel-style images and further leveraging these images.\n2) Overall Framework: As shown in Fig. 2, FedDAG follows a server-client architecture. It performs novel domain adversarial generation to generate images with similar semantics but different styles via maximizing instance-level feature discrepancy, and improves the task model generalization capability by leveraging these generated images via minimizing the"}, {"title": "B. Novel Domain Adversarial Generation", "content": "To tackle the challenge of applying novel domain generation in medical scenarios, we introduce two-stage novel domain adversarial generation (NDAG) in each local client training. It first trains a generator to generate novel-style images by maximizing instance-level feature discrepancy from original and generated images while leveraging dual-level semantic constraints to ensure the semantics of generated images. Then, it further leverages generated images to train a generalizable model by minimizing instance-level feature discrepancy from original and generated images. These two steps are executed in each mini-batch training, which can be viewed as a mutually adversarial process. FedDAG solves the challenges of domain label ambiguity and semantic sensitivity by repeating the above training process on the client side, effectively introducing novel domain generation into medical scenarios.\n1) Instance-level Adversarial Generation Stage: NDAG utilizes instance-level adversarial learning to generate novel-style images and approximate domain shifts, thus bypassing the requirement of domain labels and avoiding the influence of their ambiguity. Specifically, each client has three local models: a local generator $G_{\\varphi_i}^t$, a local teacher model $T_{\\theta_i}^t$, and a local student model $S_{\\omega_i}^t$. During this stage, only $G_{\\varphi_i}^t$ is allowed to update, while the $T_{\\theta_i}^t$ and $S_{\\omega_i}^t$ are kept frozen. Given an image $x$ and its one-hot label $y$, NDAG trains $G_{\\varphi_i}^t$ by exploiting the instance-level feature discrepancy between $x$ and its generated version $\\hat{x}$. Once $G_{\\varphi_i}^t$ generates $\\hat{x}$, $\\hat{x}$ is processed by $S_{\\omega_i}^t$, i.e., $\\hat{f} = S_{\\omega_i}^t(\\hat{x})$. Simultaneously, the original image $x$ is input into $T_{\\theta_i}^t$, i.e., $f = T_{\\theta_i}^t(x)$. As can be imagined that when there is no significant difference between $S_{\\omega_i}^t$ and $T_{\\theta_i}^t$, the feature discrepancy between $\\hat{f}$ and $f$ highly correlated with the image visual difference between $x$ and generated $\\hat{x}$. Thus, NDAG trains $G_{\\varphi_i}^t$ to generate novel-style images, by maximizing the discrepancy loss $L_{dis}$ between the normalized $\\hat{f}$ and $f$, as\n$\\max_{G_{\\varphi_i}} L_{dis} (f, \\hat{f}) = \\min (\\frac{f}{\\|f\\|^2} - \\frac{\\hat{f}}{\\|\\hat{f}\\|^2}\\_2, m).$ (1)\nHere, $m$ is a hyperparameter to avoid the unlimited maximization of $L_{dis}$, which is set to 0.1 in our experiments. It can also be seen as a controlling factor for the difference between the generated images and the original images. Through the above process, the $G_{\\varphi_i}^t$ tackles the challenge of domain label ambiguity and generates images with novel styles by utilizing instance-level adversarial gradients.\n2) Dual-level Semantics Constraints: Another essential design of NDAG is to constrain the semantics of susceptible medical images in the generation process, which requires preserving the original image information during the generation process. Although the semantics changing of generated images may means achieve the significant domain shift approximation, this semantic changing may lead to difficulty in leveraging generated images. Therefore, NDAG performs a dual-level semantic constraint in the task and image pixels to avoid semantic changes in the generated process. As for the image level, NDAG leverages a controllable image perturbation solution in the $G_{\\varphi_i}^t$, represented as\n$\\hat{x} := x + \\alpha \\cdot G_{\\varphi_i}^t(x),$ (2)\nwhere $\\alpha$, lying within the range of [0, 1], is designed to modulate the intensity of image perturbation. Compared to direct generation solutions [31], [53], [54], [57], this design enables the generation of novel-style images by adding perturbations and thus effectively preserving their original semantic content and reducing the demand for training data [30]. As for the task level, NDAG train $G_{\\varphi_i}^t$ to ensure that the generated image $\\hat{x}$ can be accurately classified by the $S_{\\omega_i}^t$, as\n$\\min_{\\varphi_i} L_{cls} (\\hat{x}, y) = \\text{CrossEntropy} (S_{\\omega_i}^t(\\hat{x}), y).$ (3)\nThrough performing the dual-level semantic constraint, the semantics of the generated images can remain unchanged, which provides the foundation for learning the domain-invariant representation using these generated images.\n3) Domain-invariant Representation Learning Stage: After the generation, it is crucial to effectively leverage generated images. NDAG uses generated and original images to train $S_{\\omega_i}^t$ to resist the influence of perturbation, aiming to improve model generalization capability via learning domain-invariant features. Specifically, the $S_{\\omega_i}^t$ is activated to be trainable, while both the $G_{\\varphi_i}^t$ and $T_{\\theta_i}^t$ are kept frozen. The idea is straightforward: when there is a significant difference between $\\hat{x}$ and $x$ due to the presence of perturbations, if $S_{\\omega_i}^t$ can generate a feature representation similar to $T_{\\theta_i}^t$, it indicates that $S_{\\omega_i}^t$ possesses domain-invariant generalization capabilities. NDAG achieves this objective by minimizing the feature similarity loss $L_{sim}$ of normalized $\\hat{f}$ and $f$, as\n$\\min_{\\omega_i} L_{sim} (f, \\hat{f}) = \\frac{f}{\\|f\\|^2} - \\frac{\\hat{f}}{\\|\\hat{f}\\|^2}\\_2^2.$ (4)\nSuch a minimization guides $S_{\\omega_i}^t$ to resist image perturbations and thus enhances its capability to learn domain-invariant feature representations. Alongside, a task loss $L_{cls}$, similar to Eq. 3, is implemented to prevent $S_{\\omega_i}^t$ overfitting only to feature similarity while maintaining its Generalization performance. Furthermore, to avoid the learning collapse arising from a significant knowledge gap between $T_{\\theta_i}^t$ and $S_{\\omega_i}^t$, NDAG follows the teacher-student paradigm [31], the Exponential Moving Average (EMA) [59] is employed to update $T_{\\theta_i}^t$ by progressive distillation of knowledge from $S_{\\omega_i}^t$.\nIn summary, FedDAG employs NDAG on each client, enabling $G_{\\varphi_i}^t$ to generate images with similar semantics but different styles. It further leverages these images to train the student model $S_{\\omega_i}^t$, aiming to learn domain invariant representation. FedDAG deploy the teacher-student paradigm to balance the knowledge between $S_{\\omega_i}^t$ and $T_{\\theta_i}^t$, and make the $T_{\\theta_i}^t$ as the final task model. The whole training process in local clients is described at Alg. 1."}, {"title": "C. Sharpness-aware Hierarchical Aggregation", "content": "To mitigate the NDAG-exacerbated imbalance of generalization contributions and further promote the novel domain generation procedure, we propose Sharpness-aware Hierarchical Aggregation (SHA). Through the evaluation of generalization contributions based on the concept of sharpness, each task model $T_{\\theta_i}^t$ receives a corresponding generalization score $s_i^t$ that reflects its generalization capability. Based on these scores, SHA performs hierarchical aggregation to mitigate the imbalance within and across clients, thereby improving the global model's generalization capability. It can be foreseen that due to the improved generalization ability of the global model, a better teacher model will be used to the next round of model distribution, which can further promote domain adversarial generation on the client side.\n1) Sharpness-aware Model Evaluation: SHA first evaluates the generalization contributions by the concept of sharpness [60], [61], [62], [63]. Different from other evaluation methods, the sharpness-aware evaluation assesses the model's generalization ability toward unseen target domains by focusing on the flatness in loss landscapes. SHA quantifies the generalization ability of the model and performs densely weighted aggregation by simply adding small perturbations and observing the degree of change in generalization performance. Specifically, each client computes a model perturbation $\\epsilon$ based on the dual norm of the last batch gradient $\\nabla_{\\omega_i^t} (L_{cls} + L_{sim})$, following [60]. The perturbed $T_{\\theta_i}^t$ is obtained by adding $\\epsilon$ to its parameters as $\\theta_i^t := \\theta_i^t + \\rho \\cdot \\epsilon$, where $\\rho$ within [0, 1] controls the perturbation intensity. Further, the generalization scores $s_i^t$ of $T_{\\theta_i}^t$ is evaluated by other clients against their local validation sets $D_j$ as\n$s_i^t = 1/(\\sum_{(x',y') \\in D_j} [L_{cls} (T_{\\theta_i}^t (x'), y')]).$ (5)\nThrough the sharpness-aware evaluation, each pair of $T_{\\theta_i}^t$ and $G_{\\varphi_i}^t$ receives a generalization score $s_i^t$, which reflects the model generalization contribution and is used for hierarchical model aggregation. Then, this score with the corresponding $T_{\\theta_i}^t$ and $G_{\\varphi_i}^t$ will be uploaded to the server.\n2) Across-client Weighted Aggregation: As previously analyzed, NDAG may exacerbate the generalization contribution imbalance among clients. Due to data isolation and heterogeneity, it can lead to different improvements in model generalization ability. Thus, SHA performs weighted aggregation among clients based on generalization scores to mitigate such imbalances and obtain generalizable global models. Specifically, the server aggregates $T_{\\theta}^t$ and $G_{\\varphi}^t$ based on the generalization score $s_i^t$ from different clients by using an adaptive soft-balancing weight [39] as\n$w^i = \\frac{s_i^t}{\\sum_{j=1}^n s_j^t}, \\quad \\Theta := \\sum_{i=1}^n w^i \\cdot \\theta, \\quad \\Phi := \\sum_{i=1}^n w^i \\cdot \\varphi,$ (6)\nwhere $\\beta$ is related to the calculation of model aggregation weights $w^i$, which represents the aggregation weight of models from client i. By weighing the model aggregation, SHA mitigates the imbalances of generalization contribution among clients. In summary, the aggregation of $G_{\\varphi}^t$ is aimed to encourages the generation of novel-style images whose styles differ from the global distribution.\n3) Within-client Densely Aggregation: As can be imagined, the generator continually generates different style images across local training rounds, and thus, corresponding task models in historical rounds may also contain diverse generalization knowledge. Therefore, merely aggregating the latest round models from each client may be insufficient. To effectively leverage the diverse generalization knowledge in historical rounds, SHA balances generalization contributions from different communication rounds for each client before aggregating across clients. Therefore, inspired by seeking flat minima via model averaging [64], [63], SHA aggregate models from historical training rounds within the same client to obtain the generalizable model. Specifically, SHA retains the latest k local models with scores exceeding $\\bar{s^t}$, integrates them with $T_{\\theta_i}^t$ via model averaging, and recalculates the average score. SHA mitigates the imbalance from different communication rounds for each client by averaging aggregation local model $T_{\\theta_i}^t$, thereby fully utilizing the generation effects of the NDAG.\nIn conclusion, SHA mitigates the NDAG-exacerbated imbalance of generalization contribution by evaluating the generalization contributions based on the concept of sharpness and aggregating models within and across clients hierarchically. By utilizing SHA, the model with more generalizable than simple average can be obtained, which further promotes the adversarial generation process of NDAG in the next round."}, {"title": "D. Federated Domain Adversarial Generation", "content": "FedDAG can be divided into four stages: model initialization, model distribution, local training and uploading (Alg. 1), model evaluation and aggregation (Alg. 2). Model Initialization: As the same as FedAvg, FedDAG initializes global models on the server before the first model distribution. Model Distribution: FedDAG distributes $G_{\\varphi}$ and $T_{\\theta}$ to local clients as $G_{\\varphi_i}^t$ and $S_{\\omega_i}^t$. Local Training and Uploading: FedDAG performs NDAG in each client to train $T_{\\theta_i}^t$ and $G_{\\varphi_i}^t$ locally, and after the training, the $T_{\\theta_i}^t$ and $G_{\\varphi_i}^t$ will be uploaded to the server. Model Evaluation and Aggregation: FedDAG evaluates the generalization capability of $T_{\\theta_i}^t$ and $G_{\\varphi_i}^t$ based on the concept of flat minima, and then it hierarchically aggregates these models to obtain $T_{\\theta}$ and $G_{\\varphi}$ based on this evaluation results. Then, the aggregated models are prepared for the next round of model distribution. As can be seen, different from standard distribution and uploading, FedDAG introduces a chain: it distributes the $T_{\\theta}$ to the $S_{\\omega_i}^t$, and further the client transfers the knowledge of $S_{\\omega_i}^t$ to $T_{\\theta_i}^t$ during training and finally uploads $T_{\\theta_i}^t$ to obtain $T_{\\theta}$. Such a design aims to maintain the proper knowledge difference between the $T_{\\theta_i}^t$ and $S_{\\omega_i}^t$, which can promote the generation of novel-style images."}, {"title": "IV. EXPERIMENT", "content": null}, {"title": "A. Datasets, Implementation and Evaluation Metrics", "content": "1) Datasets: We evaluated the effectiveness of FedDAG on four renowned DG benchmarks, which contain two pathological image datasets, one fundus dataset, and one skin lesions image dataset, where each benchmark covers a spectrum of medical diagnosis problems. 1) WILDS-Camelyon17 [71] comprises 455,954 histopathology slides from five distinct hospitals. The labels signify whether the central region contains any tumor tissue. We randomly sampled 10% of the data for our experiments. 2) MIDOG2022 [72] comprises regions of interest selected from five tumor types. All tumors have in common that mitotic figures are relevant for the diagnosis. 3) GDRBench [39] encompasses 11,357 Fundus images from six hospitals. Labels categorize the diabetic retinopathy (DR) severity, ranging from no DR to proliferative DR. 4) FLamby-ISIC2019 [73] encompasses 23,247 skin lesions images from four centers using six imaging modalities [74], [75], [76]. The labels of this dataset contain eight different types of skin lesions.\n2) Implementation Details: We deployed ImageNet-pretrained ResNet50 as backbones, linear fully-connected layer as classifiers, fully convolutional networks (FCN) as generators, and adopted SGD with momentum as optimizers. For the pathological datasets, i.e., WILDS-Camelyon17 and MIDOG2022, our experiments utilized a GeForce GTX 1080Ti. We resized all images to 96x96 and applied normalization using ImageNet's parameters. Our training protocol spanned 35 communication rounds with five warmup rounds [8], [11]. We employed a learning rate of 0.001, paired with a momentum of 0.9, and introduced a weight decay of 5\u00d710-4. The batch size was 32, and we standardized all loss weights to 1. For the fundus and skin lesions datasets, the experiments in this section harnessed the capabilities of a GeForce RTXTM 2080Ti. We resized all images to 224x224 and also employed ImageNet normalization parameters. Our training spanned 50 communication rounds with five warmup rounds, consistent with the frameworks presented in [8], [11]. The model's learning rate was 0.005, supplemented with a momentum of 0.9. We also implemented a weight decay of 5 \u00d7 10-4 and used a batch size 16. In terms of the dataset split, we follow the original data dividing, which divides the data on each client into the training set and the validation set. For datasets without a clear division of training and validation sets, such as MIDOG2022 and WILDS-Camelyon17, we randomly divide the training and validation sets in a ratio of 9 : 1. We determined the hyperparameters for our experiment based on the results of the model on the validation set. For all datasets, uniformly, all loss weights were set as 1, and our hyperparameters, i.e., \u03b1, \u03b2, k, and \u03c1, were set to 0.3, 0.3, 4, and 10-7, respectively. To maintain fairness with other comparison methods, we selected the same hyperparameters on multiple datasets and demonstrated the effect of hyperparameter values on model performance in subsequent experiments.\n3) Evaluation Metrics: For all benchmarks, we utilized a federated leave-one-domain-out evaluation protocol following [8]. We reported the results of weighted accuracy (ACC), the weighted area under the ROC curve (AUC), and the weighted F1-score (F1). The top two scores are denoted in bold and by underlining. If there is no special mention, we mainly analyze experiments via AUC results in this paper."}, {"title": "B. Main Results", "content": "1) Compared Methods: We compared FedDAG with extensive state-of-the-art (SOTA) personalized federated learning (PFL), DG, and FedDG methods. These PFL methods include FedBN [65], FedProx [66], FCCL [67], Per-FAvg [68], and FedDG methods include CCST [11], ELCSF [8], FedGA [18], CSAC [19], G2G [25] and FedSR [15]. For the DG methods such as RSC [69], Mixstyle [70], ATS [31], and DDAIG [30], we established data isolation for different clients and applied FedAvg[5] as the communication algorithm.\n2) Evaluation on Pathological Benchmarks: Table I exhibits the comparison results of FedDAG against other SOTA methods on WILDS-Camelyon17. Due to the data isolation in FL scenarios, DG methods may be sub-optimal for generalization capability under the federated setting. This view is proved by the results of ATS and DDAIG, which perform on FL scenarios and merely bring 2.8% and 2.9% performance increases, respectively. Simultaneously, we can observe the limited improvement of PFL approaches, such as FCCL and Per-FAvg. This may be because PFL focuses on enhancing the generalization to source clients, which neglects the generalization of the target client. As for the FedDG approaches, FedGA enhances 3.1% relative to baseline, where the advancement can be attributed to its emphasis on mitigating distinct contributions among clients [18]. CCST and ELCFS focus on increasing data diversity and simulating potential domain gaps [8], [11], which effectively and stably improved the generalization ability of the model. They brought performance improvements of 3.7% and 4.0%, respectively, proving the effectiveness of recombining domain attributes. However, these methods are sub-optimal in generalizing to the unseen target domain because they do not touch the out-of-distribution of global data distribution. FedDAG, while building upon these insights, surpasses these methods markedly, which achieves a performance improvement of 5.3%. The experimental results of MIDOG2022 are displayed in Table II. We can observe results and conduct conclusions similar to those on WILDS-Camelyon17. However, due to more ambiguous domain gaps than WILDS-Camelyon17, there are some different trends. For example, FedGA only brings 0.1% performance improvement, which may be due to the local model biases towards the local data distribution, resulting in limited improvement in the generalization ability of the global model. The limited performance improvement of ELCFS also illustrates that recombining domain attributes is insufficient to approximate the unseen domain shifts when ambiguous domain gaps exist. However, despite the ambiguous domain gap, FedDAG still performs well and shows 4.3% improvement over the baseline. The experimental results on two pathology datasets illustrate that FedDAG can significantly improve performance regardless of the presence or absence of ambiguous domain gaps. This superior performance improvement of FedDAG is credited to the holistic design of mutual boost between NDAG and SHA.\n3) Evaluation on GDRBench: The comparison results of FedDAG and other SOTA methods on GDRBench are shown in Table III. We can observe some similar conclusions to pathological benchmarks, and there are also some different conclusions. For example, ELCFS is an extremely limited improvement compared to the baseline. This may be since recombining frequency domain information only expands the local data without touching the out-of-distribution of global data. Consequently, it fails to approximate unseen domain shifts. The methods of novel domain generation merely within the local data distribution and perform well, i.e., ATS and DDAIG, were enhanced by 2.6% and 2.1% in this dataset, respectively. FedDAG also leverages novel domain generation strategies, which provide 8.1% performance improvement. FedDAG's significant performance improvement on GDR-Bench demonstrates its effectiveness not only in pathological diagnosis but also in other potential modalities such as Fundus.\n4) Evaluation on the Real-world FL Dataset: To analyze the performance of FedDAG on the real-world federated medical dataset, we conducted a comprehensive comparative experiment on the FLamby-ISIC2019. The experimental results in Table IV show that on the three clients Vidir Molemax, HAM Vidir Modern, and HAM Vienna Dias, the performance improvement of FedDAG over FedAvg is notably limited. The explanation for this phenomenon is simple: the data of these three clients come from the same hospital and may contain similar data distributions, although different imaging methods are used [73]. During the training, the model has been exposed to the data distribution of these three clients, which destroys the original domain shift, making FedAvg perform well on the corresponding target clients. For clients from different hospitals such as MSK, BCN, and HAM Rosendahl, when these three hospitals are used as target clients, FedAvg performs poorly due to domain shifts. However, for FedDAG, the effective generation of NDAG on the client, coupled with the further enhancement of the model's generalization ability through SHA, allows for better performance on these target clients. The results on the FLamby-ISIC2019 dataset further demonstrate that the performance of traditional FL degrades when facing real-world domain shifts. However, FedDAG can effectively mitigate this problem, which implies its potential usage in real-world federated medical applications."}, {"title": "C. Ablation Studies", "content": "1) Ablation of Proposed Components: We conducted an ablation study to understand the significance of our introduced components", "Strategies": "We investigated the effect of hyperparameters", "strategies": 1, "Generation": "We compare FedDAG with other NDG methods as delineated in Fig. 4 (left), aiming to demonstrate the effectiveness of NDAG. The limitation of ATS is evident as its generated views significantly diverge from the original images, potentially leading to semantic inconsistencies. Additionally, DDAIG struggles with learning functional perturbations, which are impeded by domain labels due to ambiguous domain gaps among clients in medical images. In contrast, FedDAG generates images with different styles and similar semantics, proving that the NDAG can effectively generate novel-style images."}]}