{"title": "Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games", "authors": ["Chiu-Chou Lin", "Wei-Chen Chiu", "I-Chen Wu"], "abstract": "Defining and measuring decision-making styles, also known as playstyles, is crucial in gaming, where these styles reflect a broad spectrum of individuality and diversity. However, finding a universally applicable measure for these styles poses a challenge. Building on Playstyle Distance, the first unsupervised metric to measure playstyle similarity based on game screens and raw actions by identifying comparable states with discrete representations for computing policy distance, we introduce three enhancements to increase accuracy: multiscale analysis with varied state granularity, a perceptual kernel rooted in psychology, and the utilization of the intersection-over-union method for efficient evaluation. These innovations not only advance measurement precision but also offer insights into human cognition of similarity. Across two racing games and seven Atari games, our techniques significantly improve the precision of zero-shot playstyle classification, achieving an accuracy exceeding 90% with fewer than 512 observation-action pairs-less than half an episode of these games. Furthermore, our experiments with 2048 and Go demonstrate the potential of discrete playstyle measures in puzzle and board games. We also develop an algorithm for assessing decision-making diversity using these measures. Our findings improve the measurement of end-to-end game analysis and the evolution of artificial intelligence for diverse playstyles.", "sections": [{"title": "Introduction", "content": "The pursuit of diversity in decision-making is one of the intrinsic motivations that drive human behavior, resulting in individuality and creativity (Rheinberg, 2020). This is evident in the context of games, where decision-making manifests as various playstyles, each reflecting unique strategies and characteristics (Bean & Groth-Marnat, 2016; Yannakakis et al., 2013). Alongside the pursuit of diversity, another central aspect of decision-making focuses on achieving optimal performance. Significant advances in decision-making performance have been witnessed, especially with the development of Deep Reinforcement Learning (DRL) (Russell & Norvig, 2020). The effectiveness of DRL was first showcased in arcade video games (Mnih et al., 2015). Subsequent applications to board games emphasized its potential, achieving superhuman skills (Silver et al., 2018). This success expanded into various types of games, from Agent57's superhuman performance in Atari games to groundbreaking feats in Dota 2 and StarCraft II (Badia et al., 2020; Berner et al., 2019;"}, {"title": "Background and Related Works", "content": "In this section, we discuss playstyle in depth, provide a historical overview, and highlight the importance of discrete representation in the creation of general playstyle measures."}, {"title": "Playstyle and Measurement", "content": "Establishing a universally accepted playstyle measure is a formidable challenge, as perceptions of playstyle are influenced by myriad factors and often harbor subjective nuances. Consequently, any playstyle measure should specify its evaluative parameters transparently to ensure that its measurements are persuasive. Historically, tailored metrics, characterized by heuristic rules or specific in-game features, often presented the most precision for dedicated case studies. For example, the study by Lample & Chaplot (2017) used measures such as object counts, kills, and deaths in shooting games. However, due to their inherent manual nature, these measures are often domain-specific and limited to specific behaviors.\nFor video games, methods in player modeling can help us find interesting player behaviors and personality (Yannakakis et al., 2013; Costa Jr & McCrae, 1995). A key problem in these behavior analyses is how to define effective input features and the corresponding target outputs. Even if we can detect and taxonomize some behaviors, a real playstyle can be a complex combination of several behaviors. For example, the Bartle taxonomy in game character theory, where players can be separated into four types: achievers, explorers, socializers, and killers (Bartle, 1996), is a high-level concept of playstyles and the detailed behaviors of these taxonomies can be different in different genres of games. The true playstyle can be represented as the characteristic of playing behavior sets to fuse into a holistic intention of players (Lin et al., 2021); thus, processing all possible information from raw gameplay should be included in playstyle measurements.\nTo achieve such wider applicability, some researchers have resorted to supervised learning to identify styles (Brombacher et al., 2017). However, this method requires labeled training data and may encounter difficulties in detecting styles not present in the training set. Unsupervised clustering offers a different angle, emphasizing latent feature distances for classification (Drachen et al., 2009; 2013; Ferguson et al., 2020). But this approach may obscure the semantic meaning of the measures, particularly when image data is the primary source that is common in video games. A notable approach is the Behavioral Stylometry proposed by McIlroy-Young et al. (2021) using the idea of contrastive learning. This measure, designed for chess, encodes chess moves into a game vector, aggregates these vectors to represent a style, and then compares this representation against a reference set. Central to this method is the contrastive learning technique Generalized End-to-End (Wan et al., 2018) used to learn latent features to identify the most similar player in the given datasets.\nFor a more generalized measurement of playstyle, one could consider measuring the similarity of policies. Methods that extend to specify similarity or diversity by comparing the action distribution of two policies have also been explored (Agarwal et al., 2021; Lupu et al., 2021). Notably, these methods often require a parametrized policy for comparisons. This limitation is addressed by the Playstyle Distance measure (Lin et al., 2021). Instead of emphasizing latent features or parametrized policies, Playstyle Distance focuses on the action distributions of given samples. Raw observations, such as game screens, are discretized and then used for determining which action samples are comparable. Such a method resonates more with human instinct, echoing the case-by-case assessment we often deploy."}, {"title": "Framework of Playstyle Distance", "content": "To delve deeper into the generality and importance of the Playstyle Distance in playstyle measurement, we examine its foundation as follows. A pivotal component of its methodology is the use of the Vector Quantized-Variational AutoEncoder (VQ-VAE), which specializes in discrete representations by mapping continuous encodings to the nearest vectors in a predefined codebook (van den Oord et al., 2017). Building upon VQ-VAE, the Hierarchical State Discretization (HSD) in Playstyle Distance ensures a concise and hierarchical state space. This is essential for identifying overlapping discrete states while preserving the feature integrity of observation reconstruction and gameplay details."}, {"title": "Discrete Playstyle Measures", "content": "In this section, we delve into a series of discrete playstyle measures derived from Playstyle Distance. We first discuss the limitations of Playstyle Distance. We then expand it into a multiscale approach by leveraging the hierarchical structure of states. Subsequently, we explore converting the action distribution distance into a perceptual similarity rooted in cognitive psychology, utilizing a perceptual kernel function. Thirdly, we broaden our scope from merely intersection states to the union of states, aiming for a more efficient estimation of all observed data. Concluding the section, we integrate these improvements into a comprehensive measure we term as Playstyle Similarity."}, {"title": "Effect of Multiscale States", "content": "Playstyle Distance hinges on discrete states for performing style measurements. Consequently, it resorts to a constrained state space sourced from the HSD model. A sample count threshold is applied to the intersection state to ensure the quality of action distribution, necessitating at least t samples in both datasets under comparison; failing which, the state is excluded from the intersection. This filtering sometimes discards important information and the trade-off between using small or large state spaces also poses a dilemma for singular state space; thus, we propose using multiscale analysis to alleviate these problems.\nHuman cognition perceives similarity as a convergence of multiple attributes leading to a holistic understanding (Goldstone & Barsalou, 1998). Hence, we advocate for employing varied granularity of discrete states to augment measurement capabilities, analogous to human judgment that varies from a broad view to intricate details. The HSD model's design inherently possesses a large state space for observational reconstruction and the discernment of gameplay nuances (Lin et al., 2021). Though the state space may be large, intersections are not void if observations are sufficiently similar or come from identical gameplay. It is worth noting that Lin et al. (2021) were able to identify intersection states even with unprocessed screen pixels in Atari games. In a different scenario, when treating each state as the same, we can invariably find the single intersection state. In this context, distance simply gauges the action distribution over the entirety of the game, akin to traditional methods deploying post-game action statistics.\nBroadly speaking, we can enhance the original state encoder function, \u03c6, evolving it into a state encoder mapping, \u03a6, wherein  is an assemblage of mapping functions, \u03c6 \u2208 \u03a6, S : \u03a6(o) \u2192 {\u03c6(o) \u2208 S\u03c6|\u03c6 \u2208 \u03a6}. Consequently, the projected state of dataset M is defined as: \u03a6(M) \u2192 {\u03c6(o) \u2208 S\u03c6|o \u2208 M, \u03c6 \u2208 \u03a6}. We can then reinterpret Equation 1 as:\n$d_{O}(M_A, M_B) = \\frac{d_{O}(M_A|M_B) + d_{O}(M_B|M_A)}{2}$,\nwhere $d_{O}(M_X|M_Y) = \\frac{1}{\\Phi} \\sum_{\\phi \\in \\Phi} d_{\\phi}(M_X|M_Y)$"}, {"title": "Perception of Similarity", "content": "One potential shortcoming of the Playstyle Distance stems from the nature of distance itself. While distance is a common measure for determining similarity, a larger distance value conveys primarily that two entities are different, without giving much insight into the degree of their similarity. For example, given a point in 2D space, the candidate points with the same distance to the given point form a circle. As the distance increases, the size of this candidate circle also increases, and the similarity information is diluted as illustrated in Figure 2a. This phenomenon has been observed in human decision-making as the Magnitude Effect, suggesting diminished sensitivity to larger numbers (Kahneman & Tversky, 1979). This aligns with the Weber-Fechner Law in psychophysics, where the relationship between stimulus and perception is logarithmic; as the magnitude of stimuli increases, sensitivity diminishes (Fechner, 1966). Drawing from the concept of similarity, we can infer that a smaller distance provides more definitive information about similarity. As distance grows, the distinction becomes vaguer. Therefore, we argue for a measure that reflects higher sensitivity to smaller distances, emulating human perceptual behaviors.\nWe propose a probability-based model for similarity. In this model, greater similarity (i.e., smaller distance) corresponds to a probability closer to 100%, while lesser similarity (larger distance) approaches 0%. This proposed probability function aligns with the logarithmic human perceptual sensitivity to differences. Specifically, we use the exponential kernel to describe the probability of similarity, with the mapping function given by P(d) = d, where d is the distance value from the policy distance function D(\u03c0\u03c7,\u03c0\u03b3) with 2-Wasserstein distance. This perceptual relation is the only relation under our assumptions from human cognition and probability. We provide a proof using differential equations in Appendix A.1.\nThis exponential transformation can also be found in the radial basis function (Vert et al., 2004) and Bhattacharyya coefficient (Bhattacharyya, 1946). The Bhattacharyya coefficient BC(P,Q) measures the similarity between two probability distributions P and Q, and it is related to the overlapping region between these two distributions. It is defined as BC(P,Q) = \u222bx \u221aP(x)Q(x)dx. The Bhattacharyya distance, derived from the coefficient, is DB(P,Q) = \u2212ln(BC(P,Q)), and the inversion is BC(P,Q) = exp(-DB(P,Q)).\nThus, we define a new playstyle measure $PS(M_A, M_B)$ with probability of similarity in Equation 3:\n$PS(M_A, M_B) = \\frac{\\sum_{S \\in \\phi} \\sum_{o \\in \\Phi(M_A) \\cap \\Phi(M_B)} P(D_{M}(\\pi_{M_A}(S), \\pi_{M_B}(S)))}{\\mid \\bigcup_{\\phi \\in \\Phi} \\Phi(M_A) \\cup \\Phi(M_B)\\mid}$ ,\nwhere $D_{M}(\\pi_X, \\pi_Y) = \\frac{D(\\pi_X, \\pi_Y)}{D_O}$ .\nThe measure has been simplified by adopting a uniform average distance instead of an expected value. This not only streamlines calculations but also underscores the significance of encoder granularity. In particular, an intricate encoder with a vast state space may be accorded greater weight, especially if the intricate encoder reveals more intersection states. To match our probabilistic framework (Appendix A.1) we rescale the distances with a constant, Do, ensuring the expected distance converges to 1. The constant Do can be calculated by averaging all observed distance on each discrete state in comparisons. Collectively, our revamped measure provides a probabilistic lens to interpret similarity, firmly rooted in cognitive theory and tailored for human comprehension. There is more discussion about the role of the distance metric in Appendix A.2.1, including the implications of adopting the Bhattacharyya distance metric."}, {"title": "Beyond Intersection", "content": "Before presenting our final measure, it is pertinent to revisit the foundational concept of the Playstyle Distance: the intersection of states. Identifying comparable states before measuring policy similarities encounters challenges when the intersecting samples are limited. A smaller intersection proportion can result in unstable or insufficient samples for measuring playstyles. Such a small intersection could indicate two scenarios. First, distinct state-visiting distributions might signify different playstyles. In contrast, uncontrollable factors external to playstyles, such as environmental randomness or decisions from other players, may also play a role, indicating the necessity for more extensive sampling.\nA prudent approach would assess the proportion of intersecting samples relative to the total observed samples. In the realm of collection comparison, the Jaccard index (Murphy, 1996), also known as Intersection over Union, emerges as a prevalent similarity measure. The Jaccard index can serve as an effective playstyle measure under specific conditions. It is particularly apt when game observations clearly delineate playstyle distinctions. For instance, in deterministic environments where states can be distinctly segmented by different actions, the Jaccard index appears to be a fitting measure. However, complications arise when certain states recur due to game rules or every state is visited. The task of distinguishing different playstyles based solely on observations becomes considerably challenging. This is evident in single-state games, such as K-arm bandits (Sutton & Barto, 2018), where measuring playstyles only from states becomes an impractical endeavor.\nDespite potential challenges, our empirical findings suggest that the Jaccard index serves as a handy measure, when the state space is large and the randomness in the game is low. The incorporation of the Jaccard index into a playstyle measure with a multiscale state space is expressed in Equation 4:\n$J_{\\Phi}(M_A, M_B) = \\frac{\\mid \\bigcup_{\\phi \\in \\Phi} \\phi(M_A) \\cap \\phi(M_B)\\mid }{\\mid \\bigcup_{\\phi \\in \\Phi} \\Phi(M_A) \\cup \\Phi(M_B)\\mid}$"}, {"title": "Playstyle Similarity", "content": "Throughout our exploration, we have derived and discussed various discrete playstyle measures. Collating these insights, we introduce a comprehensive measure termed as the Playstyle Similarity. Defined as PS(MA, MB), it synthesizes our earlier discussions into a singular measure as illustrated below:\n$PS(M_A, M_B) = J_{\\Phi}(M_A, M_B) \\times PS_{\\Phi}(M_A, M_B) = \\frac{\\sum_{S \\in \\phi} \\sum_{o \\in \\Phi(M_A) \\cap \\Phi(M_B)} P(D_{M}(\\pi_{M_A}(S), \\pi_{M_B}(S)))}{\\mid \\bigcup_{\\phi \\in \\Phi} \\Phi(M_A) \\cup \\Phi(M_B)\\mid}$ \nWhat makes this measure novel is its unique treatment of intersection states. While the Jaccard index assigns a uniform weight (of 1) to each intersecting state regardless of the similarity between the action distributions, our approach infuses a more nuanced probability-based weighting. The values range between 0 and 1, increasing proportionally with similarity. This modification alleviates the potential limitation of using the Jaccard index for playstyle measurements.\nFurthermore, our approach ensures a consistent interpretation of zero values. For states not part of the intersection, where the distance between action distributions is maximal (approaching infinity), they can be understood as totally dissimilar. Playstyle Distance cannot directly incorporate with the Jaccard index due to its nature as a negative similarity measure. The overview of the transformation from Playstyle Distance to Playstyle Similarity is illustrated in Figure 2b."}, {"title": "Experiment Settings", "content": "In this section, we explain the specifics of our experiment setup, focusing on the datasets, sources of encoder models, and our playstyle classification methodology."}, {"title": "Game Platforms, Datasets, and Model Source", "content": "Our study encompasses three distinct game platforms, as depicted in Figures 3a, 3b, and 3c:\n1. TORCS: This racing game features stable, controlled rule-based AI players (Yoshida et al., 2017). The datasets derived from TORCS include a total of 25 playstyles based on 5 different target driving speeds and 5 different action noise levels. Each observation consists of a sequence of 4 consecutive RGB images with a size of 64 x 64. The action space is 2-dimensional and continuous.\n2. RGSK Racing Game Starter Kit: This racing game, available on the Unity Asset Store (Juliani et al., 2020), showcases human players. From RGSK, we have data from a total of 24 players, exhibiting individual playstyles. Human players are told to follow one specific style factor in 4 different style dimensions, including using nitro acceleration or not, driving on road surface or the grass surface, keeping the car in the inner or outer of the track, and passing a corner via drifting or slowing down with a brake. Each style dimension includes 6 players. Each observation from this game comprises 4 consecutive RGB images of size 72 \u00d7 128, with 27 discrete actions.\n3. Atari games with DRL agents: The dataset spans 7 different Atari games (Bellemare et al., 2013) from this platform. Each game includes 20 AI models, all of which demonstrate varied playstyles. These AI models originate from the DRL framework, Dopamine (Castro et al., 2018). Each observation involves 4 consecutive grayscale images of resolution 84 \u00d7 84. The action space is discrete and varies depending on the game.\nIt is crucial to clarify that our research did not involve the training of new encoder models. Instead, we leveraged three pretrained encoder models and corresponding datasets for each game, provided by Lin et al. (2021). The associated resources are available in their official release. The game details are listed in Table 1."}, {"title": "Playstyle Classification and State Space Levels", "content": "Our playstyle classification adheres to the zero-shot methodology. As depicted in Figure 3d, we start with a query dataset N, sampled from a playstyle Stylen. We then compare this to multiple reference datasets M, each sampled from different playstyles Style. We perform 100 rounds of random subsampling for each playstyle; our primary performance metric for this task is the accuracy of playstyle classification. If dataset N exhibits the highest similarity to a reference dataset Mi, it suggests that Stylen = Styler. The reported accuracy represents an average, derived from results obtained using the three discrete encoder models."}, {"title": "Results in Video Games", "content": "In this section, we assess the efficacy of our methods on two racing games and seven Atari games. Initially, we demonstrate how a multiscale state space can aid in the selection of proper state spaces and potentially enhance the accuracy of Playstyle Distance. Subsequently, we compare several baselines, illustrating that probabilistic values for measuring similarity offer a viable alternative to distance values. Next, we incorporate all observed data to evaluate measures across all platforms. Furthermore, we discuss the continuous playstyle spectrum, demonstrating the consistency of measure values under slightly different behaviors. Lastly, we compare potential unsupervised measures beyond discrete playstyle measures, using observation latent features common in generative styles. Overall, our intention in this section is to determine whether new measures can enhance playstyle measurement in video games."}, {"title": "Multiscale State Space Efficacy", "content": "We evaluate the proposed multiscale state space and compare it with the singular state space used by Playstyle Distance in Table 2. We record the mean accuracy and corresponding standard deviation over 100 rounds of random subsampling for each discrete encoder. Each dataset sampled from the given playstyles comprises 1024 observation-action pairs. For example, in TORCS, there are 25 playstyles; we poll on 25 query sets, and each dataset has 1024 observation-action pairs sampled from its playstyle. We compute this query set with another 25 candidate sets, each having 1024 pairs sampled from their playstyles. When this round of polling is finished, we count whether the most similar candidate set has the same playstyle as the query set. This polling process will run over 100 times for sampling different subsets of actual playstyle datasets. Additionally, we examine the intersecting states' sample threshold count t, where an intersecting state requires at least t samples in both compared datasets for a stable action distribution estimation.\nIn our comparisons, conventional methods, such as supervised learning and contrastive learning, fall short for this classification due to the lack of playstyle labels or groups in the training datasets, resulting in a random model. Thus, we focus our comparisons on Playstyle Distance, as detailed in Equation 2. For the multiscale version, which incorporates three discrete state spaces-{1, 220, 256res}-we simplify our terminology by using the label \"mix.\" The results, as shown in Table 2, indicate that using a multiscale discrete state space not only simplifies the selection of a proper state space by using all spaces and potentially yields superior results but also obviates the need for a sample threshold count t for intersecting states in some games requiring a stable action distribution, such as TORCS, Asterix, and Breakout."}, {"title": "Probability vs. Distance", "content": "In addition to introducing the multiscale discrete state space, another key contribution of our work is the proposal to use probabilistic similarity from a perceptual perspective rather than employing negative distance as a measure of similarity. To elucidate the benefits of this modification, we examine the relationship between accuracy and dataset size of the sampled observation-action pairs. These pairs are evaluated under a single discrete state space {220}, without employing a sample count threshold, to provide a clear assessment of the transformation from distance to similarity. Further comparisons with different discrete state spaces can be found in Appendix A.2.\nWe evaluate several measures in this comparison:\n\u2022 Playstyle Distance: -d"}, {"title": "Full Data Evaluation", "content": "Based on the previous evaluations, we further perform a comprehensive evaluation of various playstyle measures, including leveraging full data with union operations. The evaluation method mirrors the one presented in Section 5.2, but expands the scope beyond racing games and adopts a multiscale state space.\nDetailed results for each Atari game have been moved to Appendix A.3.2. Instead, leveraging the consistent observation and action space shared across Atari games, we propose a unified Atari console evaluation. This"}, {"title": "Continuous Playstyle Spectrum in TORCS", "content": "This experiment investigates the response of similarity measure values to variations in a continuous playstyle spectrum within the TORCS environment. It particularly focuses on whether these measures can accurately rank playstyles, ensuring precise predictions for the closest playstyle (Top-1 similarity) and maintaining a correctly ordered sequence of playstyles based on similarity measures.\nUtilizing the TORCS dataset, which includes five levels of target speeds (60, 65, 70, 75, 80) and five levels of action noise, provides a broad spectrum for examining continuous playstyle changes. To illustrate, consider"}, {"title": "Comparison of Potential Unsupervised Similarity Measures", "content": "With previous experiments, we have verified the effectiveness of these discrete playstyle measures. Although there are few methods for unsupervised playstyle measurement before Playstyle Distance, there are some measures popular in generative styles with latent feature similarity. For example, the two most popular measures for research in generative adversarial networks (GAN) with styles (Karras et al., 2019) are the Inception Score and Fr\u00e9chet Inception Distance (FID) (Salimans et al., 2016; Heusel et al., 2017). These are based on using an image classification model, Inception (Szegedy et al., 2015), for scoring the generated images. The Inception Score is based on the prediction distribution of the classifier to detect real or generated images, which diverges from the target of playstyle measurement as all observations are real images from game environments. FID measures the 2-Wasserstein distance on the latent features of images and could be incorporated into playstyle measurement if we assume a playstyle features a unique observation distribution. However, calculating the W2 distance for high-dimensional continuous latent distributions is computationally intensive and does not yield good results in the game TORCS (Lin et al., 2021). The major complexity arises from the calculation related to the covariance matrix. A time-feasible alternative is using the similarity of the mean vector of these latent features. We can first average those latent features of observations into a mean vector to represent the playstyle and compare the similarity to candidate vectors obtained from the same process, which is analogous to the method in Behavior Stylometric (McIlroy-Young et al., 2021). These latent features used in the following experiments are the continuous latent features before vector quantization to the 220 state space in the HSD models with 500 dimensions. The discrete version of these latents with information loss has already shown effectiveness in playstyle measurements, so we compare using continuous latents with two popular similarity measures for playstyle measurements: Euclidean Distance (L2 distance) and Cosine Similarity. Cosine Similarity is especially common in latent similarity applications (Chung et al., 2022; McIlroy-Young et al., 2021).\nWe assess the following measures:\n1. Playstyle Distance with a 220 state space\n2. Playstyle Jaccard Index with a mixed state space\n3. Playstyle Similarity with a mixed state space\n4. Playstyle BC Similarity with a mixed state space\n5. Random, the uniform random baseline\n6. Euclidean Distance, using L2 distance as the similarity measure for observation latent features\n7. Cosine Similarity, using Cosine Similarity as the similarity measure\nfor observation latent features\nWe first check the results for TORCS and RGSK in Figure 6. It is clear that Euclidean Distance and Cosine Similarity do not provide good predictions, which is not surprising since the observations in the TORCS practice track are monotonous, and the playstyles are not directly correlated to observations. In contrast, playstyles in RGSK, such as nitro acceleration or preferred road surface, have a high correlation to visual features and even perform better than Playstyle Similarity under a few samples. When we further examine"}, {"title": "Playstyle Measures Under High Uncertainty Games", "content": "To further assess the efficacy of our playstyle measures in games characterized by high uncertainty, we conducted experiments with the puzzle game 2048 and the board game Go (Figure 8)."}, {"title": "2048: High Randomness Puzzle Game", "content": "Known for its single-player format and high degree of randomness, 2048 presents challenges in generating identical trajectories. We trained a reinforcement learning agent (Szubert & Jaskowski, 2014) over 10 million episodes, creating 10 distinct players by saving the model every 1 million episodes. For each player, we collected 1000 episodes, using the first 500 as the reference dataset and the remaining 500 as separate query datasets. This resulted in a total of 5000 query datasets for the experiment. The setup aimed to test the accuracy of playstyle measures in scenarios marked by high randomness and similar behaviors across small query datasets, simulating conditions that could challenge discrete playstyle measures. In this case, we directly utilized the 4 x 4 full board as the discrete states, which is equivalent to raw game screens in 2048 in terms of state information. The experimental settings used for this analysis are listed in Appendix A.6.\nThe results in Table 5 demonstrate that measures incorporating the Jaccard index negatively impact accuracy. In games with high randomness and large observation space, it is crucial to evaluate whether discrete states can identify key style factors while maintaining a manageable state space to find comparable samples."}, {"title": "Go: Two-Player Board Game", "content": "In addition to the inherent randomness of game environments, the inclusion of other players introduces further uncertainty in measuring playstyles. Consequently, we undertook a human playstyle identification task using the two-player board game, Go, which is known for its high game tree and state space complexity (Van Den Herik et al., 2002). This complexity can challenge discrete playstyle measures.\nWe implemented a variant of the HSD encoder (Lin et al., 2021) to obtain a discrete state encoder for this task. The major difference from the original HSD is that the reconstruction objective is replaced by predicting the win value, with prediction policy and value being the standard objectives in Alpha Zero series algorithms (Silver et al., 2018). The details about this discrete encoder are described in Section A.7. The Go dataset used in this study was sourced from Fox Go (Fox Go, 2024a;b) and provided by the team of the MiniZero framework (Wu et al., 2024). It includes 45,000 games from players with 9 Dan Go skill for training the encoder, with corresponding actions but without player information or style labels. Another dataset includes 200 human players with Go skill ranging from 1 Dan to 9 Dan, each contributing 100 games to the query datasets and 100 games to the candidate datasets. The discrete state space used for training the encoder includes {48, 168, 256361}."}, {"title": "Diversity Measurement in DRL", "content": "With these discrete playstyle measures, we can design an algorithm to quantify the diversity among DRL models, which is challenging to measure and quantify formally in environments with high-dimensional observations. Algorithm 1 provides a simple method to quantify diversity in decision-making by measuring the similarity between a new trajectory and observed trajectories. If a new trajectory is not similar enough to any observed trajectories, we count it as a different one.\nWe conducted experiments to evaluate this algorithm using the Atari DRL agent dataset. Each DRL algorithm (DQN, C51, Rainbow, IQN, (Mnih et al., 2015; Bellemare et al., 2017; Hessel et al., 2018; Dabney et al., 2018)) includes 5 models, each contributing 5 trajectories, resulting in 25 trajectories per algorithm. Using Algorithm 1, we assessed the diversity of trajectories produced by each algorithm. Results in Table 7, averaged across three discrete encoder models with a similarity threshold of t = 0.2, show the capacity of models trained under the same DRL algorithm to generate diverse game episodes within 25 attempts. The"}, {"title": "Conclusion and Future Works", "content": "In this research, we introduced three techniques to enhance discrete playstyle measures: adopting a multiscale state space, using perceptual similarity rooted in human cognition, and applying the Jaccard index to observed data. These advancements have been incorporated into playstyle measurement for the first time and collectively give rise to our playstyle measure, Playstyle Similarity. This measure stands out in terms of accuracy and explainability, requiring minimal predefined rules and data. Notably, the integration of a multiscale state space expands the measure's applicability, particularly for games that have a trade-off between small and large state spaces for game details. Furthermore, our literature review and theoretical proof about human perception bridge the gap between distance similarity and human cognition in playstyle.\nIn addition to the common accuracy evaluations in our experiments, we also conducted a series of statistical tests using McNemar's test (McNemar, 1947) to report some results in the main paper with p-values in Section A.8. These tests help to determine whether two results have statistical significance rather than showing differences due to sampling uncertainty.\nThe Playstyle Similarity measure offers new potential for end-to-end game analysis and AI training with specific playstyles, such as diversity analysis or human-like behaviors (Fujii et al., 2013). As an example, we propose an algorithm to quantify the diversity among DRL models, and the playstyle classification tasks on human playstyles in RGSK and Go also support future applications for human-like agents. These insights emphasize that AI development can extend beyond simple measures like scores or win rates in games with"}, {"title": "Appendix", "content": null}, {"title": "A Proof of the Perceptual Kernel", "content": "In the main paper", "X": "X(d) = -d. The probability of similarity", "follows": "n$F_x(x) = \\int_{-\\infty"}, {"becomes": "n$F_D(d) = \\int_{d"}, {"equation": "n$dp = k \\frac{dS"}, {"obtain": "n$p = k ln S + C$\nWhere C is a constant of integration, and it is defined in Fechner's law assuming that the perceived stimulus becomes zero at some threshold stimulus So, where"}]}