{"title": "What is the Right Notion of Distance between Predict-then-Optimize Tasks?", "authors": ["Paula Rodriguez-Diaz", "Lingkai Kong", "Kai Wang", "David Alvarez-Melis", "Milind Tambe"], "abstract": "Comparing datasets is a fundamental task in machine learning, essential for various learning paradigms\u2014from evaluating train and test datasets for model generalization to using dataset similarity for detecting data drift. While traditional notions of dataset distances offer principled measures of similarity, their utility has largely been assessed through prediction error minimization. However, in Predict-then-Optimize (PtO) frameworks, where predictions serve as inputs for downstream optimization tasks, model performance is measured through decision regret minimization rather than prediction error minimization. In this work, we (i) show that traditional dataset distances, which rely solely on feature and label dimensions, lack informativeness in the PtO context, and (ii) propose a new dataset distance that incorporates the impacts of downstream decisions. Our results show that this decision-aware dataset distance effectively captures adaptation success in PtO contexts, providing a PtO adaptation bound in terms of dataset distance. Empirically, we show that our proposed distance measure accurately predicts transferability across three different PtO tasks from the literature.", "sections": [{"title": "1. Introduction", "content": "Comparing datasets is a fundamental task in machine learning and a crucial component of various downstream tasks. Understanding the similarity (or dissimilarity) of datasets can inform decisions in transfer learning (Tran et al., 2019;\nBen-David et al., 2010), multitask learning (Janati et al., 2019; Shui et al., 2019), and data valuation (Just et al., 2023;\nJiang et al., 2023), among other applications. For example, selecting a pre-training dataset that is similar to a data-poor target domain can lead to better fine-tuning performance.\nNotions of dataset distance have emerged as a principled way of quantifying these similarities and differences (Mercioni and Holban, 2019; Janati et al., 2019; Alvarez-Melis and Fusi, 2020). Such distances provide insights into the relation and correspondence between data distributions, help in evaluating model performance, and guide the selection of appropriate learning algorithms.\nThe concept of dataset can vary based on context and objectives. In classical statistics, it generally refers to feature vectors, focusing on the distribution and relationships within a feature space X. Traditional statistical tests, such as the chi-squared test for categorical variables (Pearson, 1900) and the Kolmogorov-Smirnov test for numerical variables (Massey, 1951), quantify similarity based on features alone. Additionally, classic distributional distances offer formal measures of dataset similarity: the Total Variation distance (Verd\u00fa, 2014) quantifies the maximum discrepancy between distributions; Wasserstein distance, or Earth Mover's Distance, measures the cost of transforming one distribution into another (Villani, 2008); and Integral Probability Metrics (IPM) measures how well a class of classifiers can distinguish samples from the two distributions (M\u00fcller, 1997).\nIn supervised learning, datasets include both features from space X and labels from space Y. The distance between two such datasets involves measuring both the feature and label differences. This can be challenging when the label space y is not a metric space. Approaches such as those proposed by Courty et al. (2014), Alvarez-Melis et al. (2018), and Alvarez-Melis and Fusi (2020) offer a principled method for computing dataset distances considering the joint feature-label distribution P(X \u00d7 V). These methods ensure that both the features and labels are adequately accounted for in the distance measure, offering a more holistic comparison between datasets.\nHowever, the Predict-then-Optimize (PtO) framework introduces a unique challenge by using machine learning predictions as inputs for a downstream optimization problem, shifting the focus from minimizing prediction error to minimizing decision regret (Agrawal et al., 2019;\nAmos and Kolter, 2017; Elmachtoub and Grigas, 2022;\nMandi et al., 2023). This results in PtO tasks involving not just a feature-label dataset, but also a decision space \u03a9 of optimization solutions, creating a feature-label-decision dataset with samples in X \u00d7 Y \u00d7 \u03a9. The decision space"}, {"title": "2. Related Work", "content": "Dataset Distances via Optimal Transport Optimal\nTransport (OT)-based distances have gained traction as an effective method for comparing datasets. These methods characterize datasets as empirical probability distributions supported in finite samples, and require a cost function be-tween pairs of samples to be provided as an input. Most OT-based dataset distance approaches define this cost function solely in terms of the features of the data, either directly or in a latent embedding space. For example, Muzellec and Cuturi (2018) proposed representing objects as elliptical distributions and scaling these computations, while Frogner et al. (2019) extended this to discrete measures. Delon and Desolneux (2020) introduced a Wasserstein-type distance for Gaussian mixture models. These approaches are useful mostly in unsupervised learning settings since they do not take into account labels or classes associated with data points. To address this limitation, a different line of work has proposed extensions of OT amenable to supervised or semi-supervised learning settings that explicitly incorporate label information in the cost function. Courty et al. (2014) used group-norm penalties to guide OT towards class-coherent matches while Alvarez-Melis et al. (2018) employed sub-"}, {"title": "Predict-then-Optimize (PtO)", "content": "In recent years, the PtO framework has advanced significantly in integrating machine learning with downstream optimization. The frameworks proposed by Amos and Kolter (2017); Donti et al. (2017); Wilder et al. (2018); Elmachtoub and Grigas (2022) have been instrumental in this integration. Subsequent contributions have focused on differentiating through the parameters of optimization problems with various structures, including learning appropriate loss functions\n(Wang et al., 2020; Shah et al., 2022; 2023; Bansal et al.,\n2023) and handling nonlinear objectives (Qi et al., 2023;\nElmachtoub et al., 2023). Recently, attention has also been given to data-driven challenges within the PtO framework, including robustness to adversarial label drift (Johnson-Yu et al., 2023) and active learning for data acquisition (Liu et al., 2023). These works introduce learning-based algorithms tailored to specific challenges, yet they converge on a common underlying paradigm: dataset similarity. For label drift, the issue centers on the (dis)similarity between training and test datasets. In data acquisition, it involves assessing the (dis)similarity, in terms of diversity and\ninformativeness (Cacciarelli and Kulahci, 2023), between the training dataset and the acquisition source."}, {"title": "3. Background", "content": "OT theory provides an elegant and powerful mathematical framework for measuring the distance between probability distributions by characterizing similarity in terms of correspondence and transfer (Villani, 2008; Kantorovitch, 1942). In a nutshell, OT addresses the problem of transferring probability mass from one distribution to another while minimizing a cost function associated with the transportation.\nFormally, given two probability distributions a and \u03b2 defined on measurable spaces X and Y, respectively, the OT problem seeks a transport plan \u03c0 (defined as a coupling between a and \u03b2) that minimizes the total transportation cost. According to the Kantorovich formulation (Kantorovitch, 1942), for any coupling \u03c0, the transport cost between a and\n\u03b2 with respect to \u03c0 is defined as:\n$d_\\pi(\\alpha, \\beta; \\pi) := \\int_{X \\times Y} c(x, y) d\\pi(x, y)$ (1)\nwhere c(x, y) is the cost function representing the cost of transporting mass from point x \u2208 X to point y \u2208 Y. The"}, {"title": "3.2. Dataset Distances via Optimal Transport", "content": "In supervised machine learning, datasets can be represented as empirical joint distributions over a feature-label space\nX x Y. OT distances can be used to measure the similarity between these empirical distributions, thus providing a principled way to compare datasets. Given two datasets D and D' consisting of feature-label tuples (x, y) and (x', y'), respectively, the challenge of defining a transport distance between D and D' lies in the challenge of defining an appropriate cost function between (x, y) and (x', y') pairs. A straightforward way to define the feature-label pairwise cost is via the individual metrics in X and Y if available. If\ndx and dy are metrics on X and Y, respectively, the cost function can be defined as:\n$c((x, y), (x', y')) = (d_X(x, x')^p + d_Y(y, y')^p)^{1/p}$\nfor p \u2265 1. This point-wise cost function defines a valid metric on X x Y. However, it is uncommon for dy to be readily available. To address this, Courty et al. (2017) propose replacing dy (y, y') with a loss function L(y, y') that mea-sures the discrepancy between y and y' while Alvarez-Melis and Fusi (2020) suggest using a p-Wasserstein distance between the conditional distributions of features defined by y and y' as an alternative to dy (y, y')."}, {"title": "3.3. Predict-then-Optimize", "content": "The Predict-then-Optimize (PtO) framework involves two sequential steps: prediction and optimization. First, a pre-dictive model f is used to predict costs based on some fea-tures X1,..., XN \u2208 X, represented as \u0177 = [\u01771,\u2026\u2026,\u00dbN] =\n[f(x1),..., f(x)]. Second, an optimization model uses these predicted costs \u0177 as the objective function costs:\n$\\mathcal{M}(\\hat{y}) := \\underset{w}{\\text{argmax}} g(w; \\hat{y}), \\quad \\text{s.t.} \\quad w \\in \\Omega$ (3)\nwhere is the space of feasible solutions. We assume that w* : Rd \u2192 \u03a9 acts as an oracle for solving this optimization problem, such that w*(y) represents the"}, {"title": "4. Decision-aware Dataset Distances", "content": "Our primary objective is to develop a formal notion of dis-tance between PtO tasks. Specifically, we aim to define a distance d(D, D') between datasets D and D' that reflects task similarity in the context of PtO, and hence, is predictive of decision regret transferability. To achieve this, we con-sider datasets D and D' consisting of feature-label-decision tuples (x, y, z) \u2208 X \u00d7 Y \u00d7 \u03a9, where X is the feature space,\nY the label space, and \u03a9 the decision space. For a decision space defined by a downstream optimization problem M(\u00b7)\n(Eq. 3), the decision space \u03a9 can be considered as the set of feasible solutions of the optimization problem M(y) for all y \u2208 Y. We will refer to the joint feature-label-decision space as W := X \u00d7 Y \u00d7 \u03a9.\nGiven two distributions P and P' over W, we con-sider two datasets drawn from these distributions: D ={(Xi, Yi, zi)}=1 ~ P and D' = {(xi, Yi, zi)}=1 ~ P'.\nOur objective is to ensure that the distance d(D, D') accu-rately predicts transferability between P and P', with trans-ferability assessed in terms of decision regret minimization."}, {"title": "4.1. Incorporating Decision into OT Distances", "content": "A dataset for a PtO task consists of feature-label-decision triplets (x, y, z) \u2208 X \u00d7 Y \u00d7 \u03a9. \u03a4\u03bf compute an OT-based dataset distance (as defined in Section 3.2) between PtO datasets, we need a suitable metric for the joint space\nZ := X \u00d7 Y \u00d7 \u03a9 to serve as the ground cost function in the OT problem.\nPairwise distances between feature-label samples can be computed using metrics on the feature space X and the label space Y. If Y lacks a natural metric, we can use the metric on X to compare labels based on their association with features (Alvarez-Melis and Fusi, 2020). Defining a metric for the decision space \u03a9 is also challenging, as it may not inherently form a metric space. For example, decisions related to resource allocation or scheduling may not align with traditional metrics. Even when \u03a9 is equipped with a metric, it might not reflect decision quality regret effectively a key aspect for PtO tasks. For instance, in comparing paths in a p \u00d7 q grid, Euclidean or Manhattan distances will not capture differences under different goals like minimizing cost versus maximizing safety.\nTherefore, the metric in Z must accurately reflect decision quality regret, as outlined in Equation 4. This means the metric should not only measure distances between feature-label-decision triplets but also incorporate the quality and impact of decisions. To facilitate this, we define the decision quality disparity to compare decisions z and z' in 2 with respect to their quality under a pair of labels y and y':\nDefinition 4.1 (Decision quality disparity). For an opti-mization problem M with objective function g, the decision quality disparity function lg ( \u00b7 ; y, y') : \u03a9\u00b2 \u2192 R measures the difference in decision quality between two decisions z, z' \u2208 \u03a9 given the labels y, y' \u2208 V. It is defined as:\n$l_g(z, z'; y, y') := |g(z; y) - g(z'; y')|$ (5)\nNote that decision quality regret (defined in Section 3.3) is a special case of decision quality disparity, where qreg (\u0177, y) =\nlg(w* (\u0177), w*(y); y, y) for an optimizatin oracle w*. We use this measure of difference led by decisions to define a point-wise notion of distance in X \u00d7 Y \u00d7 \u03a9 that accounts for differences in features, labels, and decisions:\n$c_{pto} ((x, y, z), (x', y', z')) \\equiv \\alpha_x \\cdot d_x(x, x') $\n$+ \\alpha_y d_y(y, y') $\n$+ \\alpha_w \\cdot l_g(z, z'; y', y')$\n$\\alpha>0$\n(6)\nfor a = [\u03b1\u03c7, \u03b1\u03b3,\u03b1w] \u2208 R30 such that ||a|| = 1. Here,\ndx and dy correspond to a metric in the feature space X and"}, {"title": "4.2. Adaptation Bound", "content": "Given source and target distributions Ps and PT over XXY, along with a downstream optimization problem M(\u00b7) and a corresponding optimization oracle w*, we tackle the domain adaptation problem within the PtO framework. Our goal is to bound the expected decision quality regret of a labeling function f on the target domain PT, based on its distance to the source distribution Ps. We achieve this by leveraging the decision-aware distance introduced in Section 4.1.\nPrevious work has bounded target error using expressions where the adjustable terms, minimized to achieve tighter bounds, correspond to dataset distances considering only features and labels (Courty et al., 2017). These types of bounds, with dataset distance terms, have been applied to loss functions that are bounded, symmetric, k-Lipschitz, and satisfy the triangle inequality. However, in PtO tasks, the error is measured as decision quality regret qreg, which\nis inherently non-symmetric.\nTo address this, we use our proposed measure, the deci-sion quality disparity lq, to bound qreg by fixing the labels against which decision quality is assessed. Then, under Assumption 4.3, which ensures that the decision quality function has a bounded rate of change with respect to both"}, {"title": "4.3. Weighting Ground Cost Components", "content": "In our approach, the weights on the ground cost compo-nents, a in Eq. 6, are pivotal in defining the dataset distance, offering a flexible framework to account for the varying importance of features, labels, and decisions in PtO tasks. Unlike previous OT-based dataset distances that did not differentiate between the weights of feature and label com-ponents in the ground cost function often because both were measured in the same space (Alvarez-Melis and Fusi, 2020) or were weighted equally (Courty et al., 2017)\u2014 our method allows for distinct weights, enabling a more nuanced evaluation of dataset similarity tailored to each specific task.\nThis flexibility ensures that the distance metric reflects the relative significance of each dataset component according to its impact on the PtO task, which can vary widely in prac-tice depending on the application. Indeed, our experiments show that different choices of weights can lead to significant changes in the behavior of the dataset distance in terms of capturing task-specific similarities and differences."}, {"title": "5. Experiments", "content": "In this section, we compare OT-dataset distances based on feature-label dimensions to our decision-aware OT-dataset distance, which also includes decision dimensions. A primary motivation for introducing a dataset distance that is informative of PtO performance was to offer a learning-free criterion for selecting a source datasets to train model on. We evaluate the extent to which these distances effectively compare PtO tasks in terms of their transferability."}, {"title": "5.1. Experimental settings", "content": "We conduct our experiments using three predict-then-optimize tasks, chosen for their diverse domains and varying sensitivity to distribution shifts, making them ideal for ana-lyzing dataset distances in domain adaptation contexts."}, {"title": "Linear Model Top-K", "content": "This setting, first proposed by Shah et al. (2022), involves training a linear model to map fea-tures xn ~ U[-1,1] to true utilities based on a cubic poly-nomial p(xn) = 10(x2 \u2013 0.65xn). The downstream task involves selecting the K elements with the highest utility from the predicted values. We introduce synthetic distribu-tion shifts by modifying the original feature-label distribu-tion P = (Id, p)*U[-1,1]. Specifically, for various values\nof \u03b3\u2208 [0,1.3], we define the feature-label distributions\nPy = (Id, py)*U[-1,1] where py(xn) = 10(x \u2013 xn),\nusing P0.65 as the target distribution."}, {"title": "Warcraft Shortest Path", "content": "Adapted from Mandi et al. (2023) and Tang and Khalil (2023), this setting involves finding the minimum cost path on d \u00d7 d RGB grid maps from the Warcraft II tileset dataset (Vlastelica et al., 2020), where each pixel has an unknown cost. The task is to predict these costs and then determine the minimum cost path from the top-left to the bottom-right pixel. The original distribu-tion P, which we treat as the target distribution, is defined\nover Rdxd \u00d7 RP\u00d7P, where d = 96 and p = 12. Here, Rdxd\nrepresents the feature space depicting maps, while RP\u00d7P\nrepresents the traveling costs on these maps. We induce a target shift for Py by uniformly sampling the costs for\ndifferent pixel classes from the same range as P ([0.8, 9.2]\nfor the Warcraft II tileset dataset)."}, {"title": "Inventory Stock Problem", "content": "Adapted from Donti et al. (2017), this problem involves determining the optimal or-der quantity z of a product to minimize costs given a stochastic demand y, which is influenced by observed features x. The cost structure in-"}, {"title": "5.3. Impact of Target Shift on PtO Similarity", "content": "Target shift, where target label distributions change while feature distributions remain constant, challenges domain adaptation in supervised learning by causing mismatches between source and target domains, often leading to poor transferability (Japkowicz and Stephen, 2002; Zhang et al., 2013). However, out experimental results show that some source datasets with high feature-label distance due to significant target shift, exhibit low PtO transferability (Fig.3 [left]). This suggests that the impact of target shift may not directly correlate with PtO transferability (Fig.4a), and can be less pronounced in PtO contexts.\nTo further explore the impact of target shift on PtO similarity, we analyze the Warcraft setting under two\nPtO tasks: minimizing path cost alone and minimizing both path cost and length. Using the same experimental procedure as in Section 5.2, we apply it to these tasks while considering target shifts in feature-label datasets. Although the same target shifts are applied, their effect on PtO transferability is less severe for minimizing both path cost and length compared to minimizing cost alone (Fig. 5). Our decision-aware dataset distance, using weights from Section 5.2, effectively captures this behavior. The distance distribution for the task less impacted by the target shift is more left-skewed (Fig. 5b). In contrast, the dataset distance that only accounts for features and labels, is unable to differentiate between these two tasks (Fig. 5a)."}, {"title": "6. Discussion", "content": "In this work, we introduce the first notion of dataset dis-tances specifically tailored to PtO tasks. Our decision-aware dataset distance integrates features, labels, and decisions, enhancing the evaluation of prediction-to-decision similar-ities across tasks. Experiment results show that including the decision component significantly boosts transferability, particularly in complex environments where label changes\ndo not clearly correlate with decisions. This integration allows our metric to effectively capture nuances dictated by the structure of downstream optimization problems, demon-strating robust reflection of task dynamics without direct analysis of these structures.\nOur framework is adaptable and can handle diverse PtO\ntasks, allowing for flexible weighting of each component\nto provide meaningful comparisons across a broad range of applications. This adaptability is crucial for realistic applications where datasets vary not only in features and\nlabels but also in the nature of the decisions they inform.\nLooking forward, there are several promising avenues for expanding our framework. Extending our framework to handle decision components of varying structures and di-mensions using techniques like the Gromov-Wasserstein distance or approaches such as those in Alvarez-Melis and Fusi (2020) for comparing unrelated labels, could bridge gaps between non-comparable decision spaces. Further re-fining the weights assigned to features, labels, and decisions, and exploring tuning methods independent of transferabil-ity measures, could greatly improve the utility of our met-ric, especially in unlabeled scenarios. Additionally, adapt-ing our approach to more intricate PtO structures\u2014such as when multiple feature-label pairs define a single deci-sion through a hierarchical OT framework (Yurochkin et al., 2019) could extend its applicability, enhancing the\nrobustness and versatility of our method across various PtO scenarios. By establishing this initial notion of dataset dis-tance designed for PtO tasks, our work provides a founda-tional step for future research in this area."}, {"title": "A. Our decision-aware distance is a well defined metric", "content": "Proposition A.1. For any a = (ax,ay,aw) with\n\u03b1\u03c7,\u03b1\u03b3,\u03b1w > 0, the decision-aware dataset distance\ndor(D, D'; cpto) defines a valid metric on P(X \u00d7 Y \u00d7 \u03a9),\nwhere P(X \u00d7 Y \u00d7 \u03a9) represents the space of probability\nmeasures over joint distributions of features X, labels\nY, and decisions \u03a9. If \u03b1\u03b3 = 0, then the decision-aware\ndataset distance is still at least a pseudometric.\nProof. To demonstrate that dor(\u00b7,\u00b7; cpto) is a valid met-\nric, it is sufficient to verify that the ground cost function\nCPtO used in the optimal transport problem is a metric on\nX \u00d7 Y \u00d7 \u03a9. If Cpto is indeed a metric, then dor(\u00b7, \u00b7; CPtO)\ncorresponds to the Wasserstein distance (Villani, 2008). In\nEquation 6, dot(\u00b7,\u00b7; cpto) is defined as a convex combi-\nnation of dx and dy, which are metrics on X and Y re-\nspectively, and the decision quality disparity lq. To show\nthat cpto is a metric, it suffices to show that la satisfies\nthe four metric properties: non-negativity, identity of indis-\ncernibles, symmetry, and the triangle inequality. If lq does\nnot individually satisfy these properties, we must demon-\nstrate that the convex combination of dx, dy, and la satis-\nfies these properties collectively under the assumption that\n\u03b1\u03c7, \u03b1\u03b3, aw > 0.\nFirst, la is clearly non-negative because it is defined as an absolute value. It is symmetric in the convex combination of\ncpto because it is taken as the absolute difference between two decision qualities with fixed true costs.\n$l_g(z, z'; y', y') = |q(z; y') - q(z'; z')|$\n$= |q(z'; y') - q(z; z')|$\n$= l_g(z', z; y', y')$\nMoreover, la satisfies triangle inequality due to the triangle inequality property of the absolute value.\n$l_g(z_1, z_2; y_1, y_2) + l_g(z_2, z_3; y_2, y_3)$\n$= |g(z_1; y_1) - g(z_2; y_2)| + |g(z_2; y_2) - g(z_3; y_3)|$\n$\\leq |g(z_1; y_1) - g(z_2; y_2) + g(z_2; y_2) - g(z_3; y_3)|$\n$= |g(z_1; y_1) - g(z_3; y_3)|$\n$= l_g(z_1, z_3; y_1, y_3)$\nLastly, while la might not satisfy the identity of indis-cernibles in isolation (specifically, lq(y, y'; z, z)\ndoes not necessarily imply y = y'; meaning two dif-ferent decisions can lead to the same objective value),\nCPto does satisfy this property for \u03b1\u03c7, \u03b1\u03b3, aw > 0. If (x, y, z) = (x', y', z'), then l\u338f(z, z';y',y') = |g(z;y) \u2014\ng(z';y)| = 0 because z = z' implies g(x;y) = g(z';y)\nand hence cpto ((x, y, z), (x', y', z')) = 0. Conversely,\nif cpto((x, y, z), (x', y', z')) = 0, then dx(x,x')\n= 0, dy(y, y') = 0, and lq(y, y'; z, z) = 0 because\n\u03b1\u03c7,\u03b1\u03b3,aw > 0. Since dy(y, y') = 0 implies y = y'\n(because dy is a metric), it follows that w*(y) = w*(y')\nand hence z = z'.\nTherefore, CPto satisfies the identity of indiscernibles. Con-sequently, since la satisfies non-negativity, symmetry, and the triangle inequality, and since cpto satisfies the identity of indiscernibles, dot(\u00b7, \u00b7; cpto) is indeed a valid metric\nwith cpto a valid metric on X \u00d7 \u03a5 \u03a7 \u03a9."}, {"title": "B. Implications of Assumption 4.3", "content": "Assumption 4.3 The decision quality function is k1, k2-Lipschitz. This means that for any y, y*, z, z* \u2208 Y the following inequality holds:\n$|q(y, y*) - q(z, z*)| \\leq k_1||y - z|| + k_2||y* - z*||$.\nTo establish the bound presented in Theorem 4.4, we rely\non the fact that lg is k1,k2-Lipschitz under Assumption 4.3. The following proposition demonstrates that lg indeed satisfies the Lipschitz condition given this assumption.\nProposition B.1. If g, the objective function of the down-stream optimization problem, is k1,k2-Lipschitz (Assump-tion 4.3), then lg is also k1,k2-Lipschitz.\nProof.\n$|l_g(z, z_1; y, y_1) - l_g(z, z_2; y, y_2)|$\n$= ||g(z; y) - g(z_1; y_1)| - |g(z; y) - g(z_2; y_2)||$\n$\\leq |g(z; y) - g(z_1; y_1) - g(z; y) + g(z_2; y_2)|$\n$= |g(z_2; y_2) - g(z_1; y_1)|$ (8)\n$= |g(z_2; y_2) - g(z_1; y_2) + g(z_1; y_2) - g(z_1; y_1)|$\n$\\leq |g(z_2; y_2) - g(z_1; y_2)| + |g(z_1; y_2) - g(z_1; y_1)|$ (9)\n$\\leq k_1||z_1 - z_2||+ k_2||y_1 - y_2||$\n(10)\nInequalities (8) and (9) are a result of the triangle inequality of the absolute value. Inequality (10) is due to the k\u2081 - k2-lipschitzness of g.\nAssumption 4.3 imposes a specific structure on the down-stream optimization problem by assuming that the decision\nquality function has a bounded rate of change with respect\nto both the predicted and true cost vectors. This is a reason-able assumption for certain downstream optimization tasks,\nas highlighted in the following lemmas."}, {"title": "C. Proof of Theorem 4.4", "content": "Definition C.1 (Probabilistic Transfer Lipschitzness (Courty et al.", "\u03c6": "R \u2192 [0", "1": ".", "f": "X \u2192 R is $-Lipschitz transferable with respect to II if for all x > 0:\n$Pr_{(x_1", "x_2)": "leq \\varphi(\\lambda)$\nTheorem C.2. Suppose Assumption 4.3 holds. For a feature space X", "let\nW": "X x Y \u00d7 \u03a9. Let Ps and Pr be the source and target distributions over X \u00d7 Y respectively. For any\nlabeling function f : X \u2192 Y", "Pf": "x", "and\nP5": "x", "that": "n$err(f;q_{reg"}, "mathcal{P}_T) \\leq err(f;q_{reg},\\mathcal{P}_S) + err(f;q_{reg},\\mathcal{P}_T) + k_1L\\varphi(1) + (1/\\alpha_w)dot(\\mathcal{P}_f, \\mathcal{P}_S; c_{pto})$\nProof.\n$err(f; q_{reg}, P_T)$\n$= E_{(x,y)\\sim P_T} l_g(w^*(f(x)), w^*(y); y, Y)$\n$< E_{(x,y)\\sim P_T} l_g(w^*(f(x)), w^*(f(x)); y, Y) + E_{(x,y)\\sim P_T} l_g (w^*(f(x)), w^*(y); y, y)$\n$= E_{(x,y)\\sim P_T} l_g(w^*(f(x)), w^*(f(x)); y, y) + E_{(x,y)\\sim P_T} l_g (w^*(f(x)), w^*(y); y, y)$\n$= E_{(x,y,z)\\sim P_{T_{f}}} l_g(w^*(f(x)), z; y, y) + E_{(x,y)\\sim P_T} l_g(w^*(f(x)), w^*(y); Y, Y)$\n$= E_{(x,y,z)\\sim P_{T_{f}}} l_g(w^*(f(x)), z; y, y) - err(f; q_{reg}, P_S) + err(f; q_{reg}, P_S) + err(f; q_{reg}, P_T)$\n$= E_{(x,y,z)\\sim P_{T_{f}}} l_g (w^*(f(x)), z; y, y) - E_{(x,y,z)\\sim P_{\\mathcal{S}} } l_g(w^*(f(x)), z; y, y) + err(f; q_{reg}, P_S) + err(f; q_{reg}, P_T)$\n$\\leq E \\mid E_{(x,y,z)\\sim P_{T_{f}}} l_g(w^*(f(x)), z; y, y) - E_{(x,y,z)\\sim P_{\\mathcal{S}}} l_g(w^*(f(x)), z; y,y)\\mid + err(f; q_{reg}, P_S) + err(f; q_{reg}, P_T)$\n(11)\n(12)\n(13)\nInequality (11) uses the fact that l\u2084( \u00b7 ; y, y) satisfies the triangle inequality and line (12) is due to the symmetry of lg ( \u00b7 ; y, Y) for any y \u2208 V. Line (13) comes from the fact that Pf := (x, f(x), y)(x,y)~Pr. We continue by bounding"]}