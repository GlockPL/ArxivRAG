{"title": "HARBOR: Exploring Persona Dynamics in Multi-Agent Competition", "authors": ["Kenan Jiang", "Li Xiong", "Fei Liu"], "abstract": "We investigate factors contributing to LLM agents' success in competitive multi-agent environments, using auctions as a testbed where agents bid to maximize profit. The agents are equipped with bidding domain knowledge, distinct personas that reflect item preferences, and a memory of auction history. Our work extends the classic auction scenario by creating a realistic environment where multiple agents bid on houses, weighing aspects such as size, location, and budget to secure the most desirable homes at the lowest prices. Particularly, we investigate three key questions: (a) How does a persona influence an agent's behavior in a competitive setting? (b) Can an agent effectively profile its competitors' behavior during auctions? (c) How can persona profiling be leveraged to create an advantage using strategies such as theory of mind? Through a series of experiments, we analyze the behaviors of LLM agents and shed light on new findings. Our testbed, called HARBOR, offers a valuable platform for deepening our understanding of multi-agent workflows in competitive environments.", "sections": [{"title": "1 Introduction", "content": "LLMs' advanced reasoning skills make them indispensable for decision-making in competitive environments (Eigner and H\u00e4ndler, 2024; Lu et al., 2024; DeepSeek-AI et al., 2025). For instance, they may act as proxies for job candidates competing for limited positions or assist homebuyers in strategizing their purchases (An et al., 2024). Candidates have unique skills and job preferences, while homebuyers have distinct preferences and budgets (Samuel et al., 2024). Without thoroughly understanding the persona dynamics shaping LLMs' behavior in competitive environments, designing optimal strategies can be challenging.\nExisting research largely focuses on enhancing LLM agents' core capabilities, such as reasoning, planning, tool use, grounding, and multi-modal perception (Qin et al., 2023; Valmeekam et al., 2023; Bohnet et al., 2024; Li et al., 2024, 2025b). They also seek to improve agents' interactions with external environments, such as navigating the web or physical world, using APIs, querying databases, or retrieving documents (Zhou et al., 2024; Xie et al., 2024; Xu et al., 2024a; Agashe et al., 2025). Some studies have explored research from a multi-agent perspective (Li et al., 2023b; Guo et al., 2024; Zhang et al., 2024c). We are particularly interested in this direction, where the agents must seamlessly integrate personalized preferences and anticipate others' behaviors to compete effectively.\nWe present HARBOR, a new testbed for studying persona dynamics in competitive environments. HARBOR simulates real house bidding, where buyers' preferences, budgets, and competitors' choices significantly influence purchasing outcomes. Unlike prior studies of games such as the Prisoner's Dilemma or poker (Yim et al., 2024; Wang et al., 2024c; Hua et al., 2024), in which agents lack individual preferences and outcomes are based on Nash equilibria, our research emphasizes persona dynamics among multiple agents. We profile various buyer types, from first-time homebuyers to flippers and downsizers, using real data from Redfin.com. Further, our work extends human-human negotiation conversations (He et al., 2018; Yang et al., 2021; Dutt et al., 2021; Lin et al., 2024) into a multi-agent setting to assess the strengths and weaknesses of agents equipped with personas.\nOur platform enables the analysis of multi-agent decision-making in competitive settings. When bidding for multiple items, agents must plan their actions, decide which items to prioritize, manage budgets, and sometimes give up lower-priority items to secure higher-value ones (Chen et al., 2023). Agents must also analyze competitors' behavior and adapt their tactics accordingly. This paper does not focus on training multi-agent RL systems (Yao et al., 2025). Instead, we explore how injecting personas into LLM agents shapes their behavior in auctions. We examine how aggressively an agent bids (e.g., the number of attempts and amount raised) and how personas influence bidding outcomes, measured by profitability and success in securing persona-aligned items. These results have important implications for competitive scenarios, such as companies bidding for contracts, advertisers competing for ad space, or individuals negotiating deals. Our contributions in this paper are summarized as follows:\n\u2022 HARBOR enhances auction dynamics by incorporating personas, allowing us to study LLM agents beyond traditional game theory. We explore three key questions: (a) How does a persona influence an agent's behavior? (b) Can an agent effectively profile its competitors' behavior during auctions? (c) How can persona profiling help in developing strategies such as the theory of mind?\n\u2022 We introduce a new approach to evaluating agents through persona profiling (measured by KL divergence (Kullback and Leibler, 1951)) and competence (assessed via profitability and TrueSkill (Herbrich et al., 2007)). Profitability measures an agent's gains relative to all possible profit margins, while TrueSkill factors in both wins and opponent competitiveness. Through a series of experiments, we analyze agent behavior and uncover new insights."}, {"title": "2 Related Work", "content": "Multi-Agent Frameworks LLM agents are employed in advanced tasks for their ability to reason over diverse inputs and generate responses in complex scenarios (Wei et al., 2022; Fan et al., 2024; Liu et al., 2024c; Shinn et al., 2024). Past studies have explored different evaluation frameworks (Debenedetti et al., 2024; Ye et al., 2024; Asgari et al., 2024), emphasizing the need for rigorous practices in developing productized LLM agents. While these agents have shown remarkable success, their experiments are often limited by a lack of dynamic interactions.\nMulti-agent systems explore LLMs' capabilities in complex environments (Wu et al., 2024a; Huang et al., 2024; Zhao et al., 2024; Wu et al., 2024b). For instance, Gu et al. (2024) examined simulations where agents interact and collaborate within group chat settings, while Zhang et al. (2024c) explored social simulations and board games, finding that even advanced models struggle to fully utilize their reasoning potential. Huang et al. (2024) introduced an evaluation metric to assess LLMs' gaming abilities in multi-agent settings through game-theoretic experiments. Shinn et al. (2024) proposed a method to enhance LLMs through linguistic feedback, and Huang et al. (2024) developed methodologies to evaluate their decision-making capabilities.\nOur work extends AucArena (Chen et al., 2023) by exploring persona dynamics in a bidding framework that enables multiple agents to compete for maximum profit in an auction. Our framework aims for a deeper investigation of a single agent's ability to profile other agents. Moreover, we explore how theory of mind influences an agent's performance in a competitive multi-agent setting.\nPersona in LLM Agents Personas function as identities assigned to LLM agents, enhancing their ability to generate personalized or specialized outputs (Xu et al., 2024b; Chen et al., 2024a; Sun et al., 2024; Li et al., 2025a). Prior research has extensively examined the influence of personas across various roles (Hu and Collier, 2024a; Samuel et al., 2024; Kim et al., 2024; Dong et al., 2024). Leveraging their role-playing nature, some studies have applied personas to social simulations by assigning diverse identities to entire agent populations (Lee et al., 2024; Tseng et al., 2024; Hu and Collier, 2024b). Yang et al. (2024b) find that persona prompting can introduce shortcut learning, causing LLM agents to deviate from rational objectives. Building on this work, we incorporate persona into a multi-agent auction to examine its effects in competitive settings.\nTheory of Mind (ToM) Theory of Mind, the ability to understand and infer one's own and others' mental states, is fundamental to human social interaction and a crucial capability for LLMs to achieve human-like reasoning (Leslie et al., 2004; Sap et al., 2022; van Duijn et al., 2023; Cross et al., 2024; Chan et al., 2024). An accurate ToM in others' intentions and actions provides significant advantages (Street, 2024; Amirizaniani et al., 2024). Past studies have applied ToM to simulate social behaviors. De Weerd et al. (2017) explored its role in negotiation tasks, while Wang et al. (2024a) proposed an interactive learning environment to train LLMs in social interactions.\nPrevious studies have examined collaborative multi-agent settings. For example, Li et al. (2023a) and Li et al. (2023b) explored LLMs using ToM for task collaboration, while others demonstrated its effectiveness in structured games with rules and rewards. Light et al. (2023) investigated how LLMs infer players' motives in the Avalon board game, highlighting ToM capabilities within a constrained and predefined context. Similarly, Yim et al. (2024) evaluated ToM in cooperative scenarios through a poker game called Guandan. In contrast, our work investigates whether ToM can enhance agent performance in competing multi-agent environments with auction as the testbed."}, {"title": "3 Our HARBOR Framework", "content": "We introduce HARBOR\u2014a Housing Auction for Reasoning, Bidding, and Opponent Recognition to explore how persona-driven agents perceive competitors and employ ToM in multi-agent systems.\n3.1 Basic Auction Setup\nIn an auction, multiple agents N compete for a series of items H through an open bidding process. Agents can observe each other's actions in real time. While these agents are profit-driven, they may also be assigned personas, such as urban dwellers or investment buyers. These personas shape bidding behaviors by creating preferences for specific items while still prioritizing overall profit maximization.\nEach agent has access to the complete list of items H, including their publicly announced starting prices $V_{EH}$ and item descriptions. However, the true values of items $V_{EH}$ remain hidden from the agents. Instead, each agent estimates an item's worth based on an overhead percentage applied to the true value. For instance, if an item has a known starting price of $200 but an undisclosed true value of $500, and the agent's overhead estimation is 10%, it will perceive the item's value as $550. In the bidding process, agents must begin at the stated starting price and can either place a higher bid than the current leading offer or withdraw from that round. The bidding continues until only one agent remains, at which point it secures ownership of the item, and the final bid amount is deducted from the winner's budget. The profit and the maximum possible profit for item h is computed as:\nProfit = $V_h^*- V_h$   (1)\nmax Profit = $V_h^*- V_h$   (2)\nwhere $V_h$ represents the winning bid paid only by the agent who wins the item. The auction concludes once all items have undergone the bidding process.\nThe entire auction provides a comprehensive evaluation of an agent's performance from multiple perspectives. This environment enables a quantifiable assessment through three key metrics: Profit Ratio R, TrueSkill Score S (Herbrich et al., 2007), and Matched-Item Acquisition Rate A.\nThe Profit Ratio measures an agent's earnings relative to the maximum possible profit, which is achieved by winning all items at their starting prices. This metric evaluates an agent's ability to maximize financial gains while accounting for price and item variations across auctions."}, {"title": "3.2 Priority Planning", "content": "During an auction, an agent constructs and continuously updates a priority list L, a dynamic rating system that assigns a score $l_h \\in {1,2,3}$ to each item h, where 3 represents the highest priority and 1 the lowest. This evolving priority list guides the agent's bidding decisions throughout the auction. The agent places more bids on high-priority items and may withdraw on low-priority ones.\nBefore bidding, the agent initializes $L_0$ based on its initial budget $B_0$, persona $\\pi$, available items $H_0$, and the objective of maximizing the profit ratio, max R. Each item $h\\in H_0$ is assigned an initial priority score in a single prompt, generating the initial priority list $L_0$ with length $|H_0|$:\n$L_0$ = LLM({$l_h$}$_{h \\in H_0}$|$B_0$, $\\pi$, $H_0$, max R)\nThis ensures that the agent starts the auction with a well-defined strategic priority structure aligned with its objectives.\nAfter completing the bidding process for an item $h_t$, the agent updates its priority list $L_{t-1}$ to reflect its new planning. This update is determined by the agent's remaining budget $B_t$, the set of available items $H_t$. It also incorporates the status of all agents, denoted as $S_t$, which has their acquired items and profits. Additionally, the update considers $P_t$, a collection of vectors containing the agent's estimate of its competitors' personas. The priority list update process can be formalized as:\n$L_t$ = LLM({$l_h$}$_{h \\in H_t}$|$B_t$, $\\pi$, $H_t$, $S_t$, $P_t$, $L_{t-1}$)\nThis iterative process enables agents to continuously refine their strategies in real time, adjusting their decisions to better align with their objectives. We provide the prompt for planning in Appendix E.\nAt the conclusion of the auction, let $H_r$ denote the set of items won by agent b, and let $H_r^*$ represent the subset of items that align perfectly with agent b's persona $\\pi$. Define $I_{b,h} \\in {0,1}$ as a binary indicator, where $I_{b,h}$ = 1 if agent b wins item h, and $I_{b,h}$ = 0 otherwise. The performance metrics for agent b are defined as follows:\n$R_b = \\frac{\\Sigma_{h \\in H} I_{b,h}(V_h^* - V_h)}{\\Sigma_{h \\in H} (V_h^* - V_h)}$ (3)\n$A_b = \\frac{\\Sigma_{h \\in H^*} I_{b,h}}{|H^*|}$  (4)\nwhere Proft Ratio $R_b$ and Matched-Item Acquisition Rate $A_b$ quantifies the profit-driven and persona-driven objectives of agent b repectively.\nIn an auction setting with agents $b_1$, $b_2$, and $b_3$, the agent's TrueSkill Score $S_{b_1}$ is directly proportional to the ranking of the agents' profitability.\n$S_{b_1} \\propto rank(R_i : i \\in {b_1, b_2, b_3})$\nThese metrics offer a comprehensive framework for assessing an agent's profitability, competitive standing, and effectiveness in achieving persona-driven objectives within the auction."}, {"title": "3.3 Persona-Driven Bidders and Houses", "content": "HARBOR is designed to simulate realistic auctions by incorporating diverse personalities that reflect real-world motivations. In addition to initial budget constraints and value estimation overhead, one agent can also have one or more personas, such as a first-time homebuyer, downsizing homeowner, or environmental activist. These personas influence bidding strategies, introducing behavioral variability into the auction. In practice, a persona-driven bidder is created by directly embedding the persona into the system prompt, as shown in Appendix E. Similarly, a bidder with a mix of two personas can be created by sequentially injecting both personas into the system prompt.\nWe curate houses tailored to different profiles to align with proposed personas. Through sampling from these personas and corresponding houses, we generate diverse auction simulations. We mimic our items to real housing data from Redfin.com to further enhance realism and explainability. We provide two bidders and their matching houses as an example in Figure 2."}, {"title": "3.4 Persona Profiling", "content": "The profiling module maintains a k-dimensional vector $P_c$ for each competitor c, where k represents the number of personas. Each value $p_i^c \\in P^c$ ranges from [-1,1], indicating the weight of a persona, with higher values indicating stronger alignment. Before the auction begins, the agent initializes each competitor's profiling vector $P^c$ as a zero vector. At the end of bidding round t, the agent updates $P_{t-1}^c$ based on the current item h and its bidding history $T_h$, which records all agents' bidding actions for h. If a competitor bids heavily on h, the profiling module increases weights for personas likely drawn to h; otherwise, it decreases them, potentially assigning negative weights. The profiling update process can be formalized as:\n$P_t^c$ = LLM({$P_{t,i}^c$}$_{\\forall i \\in [1,k]}$ | $P_{t-1}$, h, $T_h$)\nAggregating all vectors $P_t^c$ forms the complete profiling knowledge $P_t$ at round t. This profiling knowledge is a key input in adjusting the agent's priority list (Section 3.2). The profiling prompt and an example output are provided in Appendix C.\nConstructing vector representations for personas enables precise evaluation. At the end of the auction, profiling performance is measured by comparing inferred profile vector $P^c$ against ground truth persona vector $G^c$. For single-persona agents, $G^c$ is an one-hot vector with $G_i^c$ = 1 in the competitor c's true persona dimension. Similarly, for mix-of-two persona agents, $G^c$ has two active dimensions, each weighted at 0.5. To ensure a positive probability distribution, we shift $P^c$ by adding | min($P^c$)| and normalize it. A smoothing factor $\\epsilon$ = $10^{-12}$ is applied to both $G^c$ and $P^c$. Profiling accuracy is then evaluated using KL divergence:\n$D_{KL}(G^c || P^c) = \\sum G_i^c log(\\frac{G_i^c}{P_i^c})$"}, {"title": "3.5 Strategic Module", "content": "Optimal bidding goes beyond budget management, requiring strategic exploitation of opponents' behaviors. Our strategic module provides a controlled setting to assess an agent's use of profiling knowledge. It evaluates whether the agent applies higher-level reasoning rather than simply bidding or withdrawing based on budget constraints. Activated whenever the agent makes a bidding decision, this module ensures that each action, whether bidding or withdrawing, is strategically justified. The strategic prompt takes the recent status $S_{t-1}$, most updated profile knowledge $P_{t-1}$ and planning $L_{t-1}$, and the bidding context, including item details and the current price, to generate a chosen strategic option from a predefined list in Table 1. This structured approach prevents na\u00efve bidding, ensuring rational, profit-maximizing decisions. The prompt and an example output are provided in Appendix D."}, {"title": "4 Experiments", "content": "We conduct a series of experiments to address three key questions: (a) How does a persona influence an agent's behavior in competitive settings? (b) Can the agent effectively profile its competitors' behavior? (c) How can persona profiling be leveraged to create an advantage using strategies such as theory of mind? These experiments aim to improve our understanding of persona dynamics in multi-agent competitive scenarios. Our \u2018Master' agent undergoes various modifications and competes against two agents, Rival 1 and Rival 2, in ten-item auctions. Each agent is randomly assigned a persona that shapes its prioritization of items. Any deviations from this default setup are noted as needed. To enhance robustness, each experiment runs five times; we report the average results. All agents use the same foundational LLM; we do not compare different LLMs due to resource constraints. Further experiment details are in Appendix B."}, {"title": "4.1 Impact of Persona on Agent Behavior", "content": "This experiment demonstrates how an assigned persona influences an agent's behavior in auctions. We assign a unique persona to each of Rival 1 and Rival 2. Among ten items, each rival has three items matching their assigned persona. The Master Agent operates without a persona for comparison. Figure 3 shows heatmaps of priority scores for the items across bidding rounds. Rival Agents 1 and 2 consistently assign the highest priority scores (3) to their matched items across all bidding rounds. The Master Agent, lacking a persona, determines item priority based on auction order, giving the highest priority to the first remaining items.\nFigure 4 further supports this pattern by showing the average number of engagements, measured by how often each agent raises bids for an item across five trials. The results illustrate that Rivals 1 and 2 consistently favor items aligned with their personas and repeatedly increase bids. They not only assign high-priority scores to these items but also repeatedly increase their bids. Our findings indicate that persona prompting influences agents' decisions and diverts them from rational, profit-driven bidding."}, {"title": "4.2 Impact of Persona on Profitability", "content": "Does assigning a persona to an agent affect its profitability? How does competition impact earnings when multiple agents share the same persona? All agents start with the same budget. Persona agents have two aligned items. The Master Agent is tested under four conditions: (a) Master w/o Persona: the Master Agent has no persona; (b) Master w/ Persona: the Master has a persona different from both Rival Agents; (c) Some Competition: the Master shares a persona with one rival (Rival 2), creating direct competition for persona-aligned items; (d) More Competition: all agents share the same persona, intensifying competition. To ensure results are persona-independent, we rotate agent personas in a round-robin manner and report the averaged results.\nResults in Table 2 suggest that persona prompting affects the agent's core profit-driven objective. The Master Agent prioritizes items that align with its persona, making it less competitive for higher-profit items and leading to lower overall profits. Without a persona, the Master Agent achieves the highest profit rate of 34.56%. Increased competition among agents further reduces overall profit rates. This effect is illustrated in the average profit rate decline from 29.23% to 21.95%. These results support the common intuition that entering a profit-driven auction with emotional or preferential biases can undermine a bidder's financial success."}, {"title": "4.3 Profiling Rival Personas", "content": "To evaluate profiling accuracy, we use KL divergence to measure the difference between the inferred and ground truth persona distributions. Recall from Section 3.4, ground truth for single-persona agents is an one-hot vector, while mixed-persona agents distribute weights equally across two dimensions. Lower KL divergence implies more accurate persona inferences by the Master, while higher values suggest greater deviation.\nWe explore whether personas become more evident as more items align with an agent's persona. If an agent consistently bids on preferred items, their persona should be fully revealed. To test this, we analyze two Rival agents with their number of matched houses M ranging from 0 to 4. For example, at M = 4, each Rival Agent has four matched houses; at M = 0, none matches their personas. The Master Agent, without a persona, aims to infer the personas of both Rivals.\nFigure 5 (left) shows the KL divergence scores, illustrating the Master Agent's ability to infer competitors' personas. As the number of matched items increases, the Master Agent becomes more accurate in profiling competitors, suggesting that effective inference depends on persona-driven behaviors. When no matched items are present, the lack of clear behavioral patterns leads to less accurate profiling. Profiling a mix of two personas results in lower KL divergence than profiling a single persona. This is expected, as a balanced mix creates a more neutral agent\u2014one that is less distinct and more evenly interested in different houses. As a result, its behavior is more predictable. In contrast, a single dominant persona leads to stronger preferences, making profiling more challenging. Figure 5 (right) shows how the Master's profiling of a Rival Agent evolves after each bidding round."}, {"title": "4.4 Profiling Capacity", "content": "The Master Agent's profiling ability diminishes as more bidders join. Increased interactions generate extensive bidding logs, making it harder for the Master to accurately infer competitor personas. In this experiment, we vary the number of competitors in an auction from {2, 3, 4, 5, 6}, with one Master Agent. Figure 5 (middle) shows the Master's profiling results. We observe that the Master's profiling remains effective when there are fewer than five bidders. As more agents join, the Master agent struggles to infer personas accurately, as reflected by increasing KL divergence scores."}, {"title": "4.5 Theory of Mind (ToM) Strategy", "content": "We examine whether the Master Agent can use ToM with persona knowledge from the profiling module (\u00a73.4) to gain an advantage and whether the strategic module (\u00a73.5), which applies advanced auction techniques, enhances competitiveness. We conduct the experiment using Claude-3.5-Sonnet. To ensure results are persona-independent, we rotate agent personas in a round-robin manner and report averaged results. Each agent has two items that align with their personas, making them the expected winners of those items while still aiming to maximize overall profit.\nOur ToM experiments consist of five settings: (a) Baseline: the Master operates without any ToM capabilities; (b) First-order ToM (w/ True Persona): the Master has the true personas of competing agents to assess whether persona knowledge enhances bidding performance; (c) First-order ToM (w/ Inferred Persona + Strategy): instead of receiving true persona information directly, the Master infers competitors' personas using its profiling module and applies a strategic module to leverage this knowledge; (d) Optimal setting: the Master has true knowledge of rivals' personas and strategies, representing the best possible scenario; (e) Second-Order ToM: the Master is equipped with second-order ToM, allowing it to predict how rivals perceive its beliefs. All agents can infer other agents' personas and apply strategic modules. Details of these experimental setups and prompts, are provided in the Appendix F.\nTable 3 presents the results of our ToM experiments. We observe that equipping the Master Agent with first-order ToM, allowing it to perceive competitors' true personas, increases its profit rate from 23.45% (Baseline w/o ToM) to 26.18%, while its TrueSkill remains at a similar level. When the agent relies solely on profiling without strategy, the profit increase is moderate. Applying strategy leads to a substantial improvement in both Profit Rate and TrueSkill score, boosting the profit rate from 26.18% to 35.81%. This emphasizes the need for expert strategy to help the Master Agent outperform competitors. When using inferred profiles instead of true personas, the Master experiences a modest performance gain, with its profit rate rising from 23.45% to 32.54%. This outcome aligns with expectations, suggesting that higher profitability requires more accurate profiling of competitors' preferences. Across all ToM settings, the Master demonstrates a higher item acquisition rate compared to the baseline, indicating the potential benefits of ToM in securing desired items.\nSecond-Order ToM Master Agent with second-order ToM predicts how Rival Agents perceive its beliefs and persona. For example, if the Master Agent believes that Rival 2 has identified its farming preference, it may strategically bid on non-farming properties to mislead competitors. If rivals avoid bidding on its persona-aligned properties, the Master can secure them at lower prices.\nTable 3 shows that when all agents infer each other's beliefs, competition intensifies, making auctions more aggressive. While the Master Agent has a higher-order ToM, this does not always lead to higher profits. This suggests that ToM (understanding others' intentions) alone is not enough; it must be paired with expert strategies (taking the right actions accordingly) to maximize benefits."}, {"title": "5 Conclusion", "content": "HARBOR provides a controlled environment for studying how LLM agents balance personal objectives with competitive strategy. Through extensive experiments, we demonstrate that persona-driven bidding significantly influences agent behavior. We show that LLM agents can infer competitors' personas with reasonable accuracy, though profiling effectiveness declines as the number of rivals increases. Our strategic module enhances decision-making by leveraging profiling insights."}, {"title": "Limitations", "content": "Our testbed, HARBOR, is a flexible tool for studying how AI agents interact in competitive auctions. While it helps uncover key insights about decision-making, there are limitations. HARBOR uses LLM-based agents, which possess strong reasoning skills, and their decision-making is influenced by their training data and inherent biases. These agents can mimic strategic behaviors effectively, yet they may lack the creative problem-solving abilities that humans show in real-world auctions. This means their strategies might differ from those used by people in actual bidding scenarios. Our current evaluation metrics establish a foundation for measuring agent performance. Future versions of HARBOR may incorporate additional features, such as modeling long-term trust between agents, simulating deception in negotiations, and addressing ethical considerations in competitive AI behavior. These improvements will contribute to a comprehensive understanding of multi-agent interactions in competitive environments."}]}