{"title": "NeuroStrata: Harnessing Neurosymbolic Paradigms for Improved Design, Testability, and Verifiability of Autonomous CPS", "authors": ["Xi Zheng", "Ziyang Li", "Ivan Ruchkin", "Ruzica Piskac", "Miroslav Pajic"], "abstract": "Autonomous cyber-physical systems (CPSs) leverage AI for perception, planning, and control but face trust and safety certification challenges due to inherent uncertainties. The neurosymbolic paradigm replaces stochastic layers with interpretable symbolic AI, enabling determinism. While promising, challenges like multisensor fusion, adaptability, and verification remain. This paper introduces NeuroStrata, a neurosymbolic framework to enhance the testing and verification of autonomous CPS. We outline its key components, present early results, and detail future plans.", "sections": [{"title": "1 CONTEXT, MOTIVATION, AND AIMS", "content": "The integration of machine learning (ML) into CPS has driven innovations in autonomous vehicles [43, 47, 48], delivery drones [2, 21, 52], and robotic surgeries [11, 33, 35]. While ML enhances autonomy and intelligence, its uncertain and brittle nature, as witnessed in softmax-based classifications and regression-based control, undermines traditional formal verification, necessitating novel solutions. Neurosymbolic approaches combine symbolic reasoning with neural learning, addressing challenges in autonomous CPSs by enabling co-training of neural components with symbolic logic through probabilistic logic programming and differentiable reasoning [10, 29, 32, 34]. Advanced methods, such as program synthesis using Domain-Specific Languages (DSLs), demonstrate promise by supporting both deterministic and probabilistic programs [5, 18, 36]. However, significant bottlenecks persist, including unseen data in real-world deployments [19], multi-sensor fusion challenges [42], and the lack of neural component verification. Determinism at the decision level of perception and mission planning is also missing, which can enable the applicability of decades-long formal verification and testing techniques. Ensuring system-level safety and liveness requires systematic co-design of perception, planning, and control  a critical aspect missing in current methods.\nThis paper summarizes state-of-the-art neurosymbolic paradigms, using autonomous driving as a case study to highlight gaps in adaptability to unseen environments, multi-sensor complexity, systematic validation of neural components, and determinism at the decision level, critical for reliable autonomous CPS.\nTo address these issues, we put forward NeuroStrata a neurosymbolic framework for designing and assuring autonomous CPSs. Our vision integrates neurosymbolic distillation and corner-case test generation using LLMs to enable data-driven specification mining, top-down synthesis of symbolic and neurosymbolic components, and runtime bottom-up adaptation via program induction. This approach evolves symbolic programs dynamically for decision-making in perception and planning/control modules. Building on prior work, we aim to transform the testability and verifiability of autonomous CPSs through the neurosymbolic paradigm."}, {"title": "2 MOTIVATING SYSTEM AND THE\nSTATE-OF-THE-ART", "content": "State-of-the-art autonomous CPSs, such as autonomous driving systems (ADS), are typically built on middleware frameworks like Robot Operating System (ROS) with proprietary extensions (e.g., Baidu's CyberRT) to reduce message latency [16, 30, 31, 37, 51]. As shown in Figure 1, these systems integrate perception, prediction, planning, and control modules. The perception module processes multi-modal sensor data (e.g., LiDAR, cameras, IMU) for obstacle detection, traffic light recognition, and localization. The prediction module forecasts dynamic object trajectories, while the planning module computes the ego vehicle's trajectory. The control module generates actuation commands, such as steering and braking. AI components are pervasive across these modules, enabling object detection, trajectory prediction, and real-time control.\nRecent advancements in verifying machine learning models and testing learning-enabled CPS have utilized methods like NNV star sets [46], Sherlock [17], Reluplex [27], and Branch-and-Bound [7]."}, {"title": "3 NEUROSTRATA: OUR VISION FOR\nHIERARCHICAL NEUROSYMBOLIC\nFRAMEWORK FOR AUTONOMOUS SYSTEMS", "content": "To address the challenges of designing, testing, and verifying autonomous CPS, we propose a new neurosymbolic framework, NeuroStrata, tailored to the unique requirements of such systems. As shown in Figure 2, NeuroStrata combines neural adaptability with symbolic reasoning to enforce formal specifications across hierarchical DSLs that capture underlying safety and liveness properties. The framework structures Perception and Planning & Control capabilities into high-level (symbolic-only) and middle- and low-level (neurosymbolic) modules. It ensures runtime reliability and adaptation via a two-phase process: top-down synthesis, propagating symbolic specifications to neurosymbolic modules, and bottom-up adaptation, where neurosymbolic outputs refine symbolic programs. Modules. At design time, Specification Mining, built on neurosymbolic distillation [1, 6, 41], extracts formal safety and liveness specifications from training datasets. To cover more diverse safety and liveness violations and out-of-distribution scenarios beyond existing training data, we leverage recent work using large language models to analyze multi-modal sensor data [15, 51], such as front-facing cameras in vehicles, to generate additional real-world crashes and unusual cases from various angles. These specifications are propagated hierarchically across the system. In the perception stack, a high-level Scene Graph encodes semantic relationships and interactions between objects (e.g., \"pedestrian crossing road\"), represented as differentiable, adaptable programs that can be verified using formal tools like theorem provers. The middle-level Semantic Map encodes spatial and semantic information such as road layouts and drivable areas, ensuring consistency with the scene graph via symbolic rules. The low-level Sensor Fusion and Signal Processing integrates multi-modal sensor data (e.g., LiDAR, cameras, GPS) while enforcing constraints on accuracy and consistency, leveraging neurosymbolic reasoning for fusion and processing. Similarly, the planning and control stack follows a hierarchical structure. The high-level Global/Mission Planner synthesizes deterministic programs to achieve overall system objectives, verified with formal methods such as theorem proving. The middle-level Local Planner generates short-term trajectories that align with global plans while adapting to local changes, guided by symbolic reasoning. The low-level Actuation Control converts trajectories into control"}, {"title": "4 EARLY RESULTS AND FUTURE PLAN", "content": "We conducted a preliminary case study to investigate a key Research Question (RQ): \u201ccan neurosymbolic reasoning complement neural-network training to align with underlying specifications?\u201d.\nWe also outline our future plans, along with the potential challenges and proposed solutions.", "subsections": [{"title": "4.1 Assessing neurosymbolic reasoning to align\nneural network training with specifications", "content": "In this study, we investigate the capability of differentiable neurosymbolic reasoning to align perceptual neural networks with"}, {"title": "4.2 Future Research Plan", "content": "To advance NEUROSTRATA, we propose a six-step future plan with concrete steps to address challenges at each stage.\nFirst, generating diverse training datasets will leverage recent advancements in model-based testing that utilize LLMs to analyze multi-modal sensor data [15, 51]. The multi-faceted challenge lies in ensuring the generated datasets are diverse, representative of\nreal-world scenarios, and capable of addressing edge cases. Solutions can be tailored around prior work by accessing diverse sensor datasets and logs, leveraging advanced multi-modal LLMs, and integrating domain-specific constraints with iterative refinement based on industrial partner feedback.\nSecond, designing suitable DSLs is essential for capturing hierarchical and semantically rich specifications. These DSLs enable experts to encode operational constraints for sensor fusion, signal processing, and physical actuation control. Challenges include ensuring the DSLs are intuitive for domain experts while expressive enough to handle complex requirements. Solutions involve co-designing DSLs with autonomy and robotics specialists, developing language automation, and designing usable visual interfaces. By providing a bridge between formal methods and practical application, these DSLs empower experts to play an active role in system design.\nThird, developing a specification mining module based on neurosymbolic distillation will extract formal safety and liveness specifications from training datasets and LLM interactions. Aligning mined specifications with real-world requirements and handling noisy/hallucinated data are key challenges. Hybrid approaches that combine symbolic reasoning with neural embeddings, as well as active learning techniques, can iteratively refine the mined specifications to ensure accuracy and physical grounding.\nFourth, for design-time synthesis and verification, we will enforce multi-level specifications for perception and planning/control modules, leveraging the hierarchical structure defined in our DSL. Modular architectures will enable scalable top-down synthesis of symbolic and neurosymbolic components, while formal verification ensures compliance with specifications. Parallelized processes and adaptive abstraction techniques will address scalability challenges, ensuring robustness across diverse scenarios and high-dimensional inputs.\nFifth, for runtime adaptation and validation, we will develop mechanisms to dynamically refine symbolic programs for real-world changes while ensuring specification compliance. Inspired by program induction approaches like DreamCoder [18], NEUROSTRATA will iteratively refine symbolic representations using real-time data. Challenges include maintaining computational efficiency and real-time guarantees. To address these, we will optimize runtime validators, integrate lightweight symbolic reasoning for faster adaptation, and implement efficient runtime verification to ensure reliability and compliance with minimal overhead. These advancements will enable NEUROSTRATA to adapt to dynamic environments and evolving operational conditions.\nFinally, for industrial deployment, NEUROSTRATA will be applied to autonomous driving systems, delivery drones, cargo drones, and passenger aircraft as facilitated by our partners. Key challenges include seamless integration into existing systems, adherence to stringent safety standards, and building trust among stakeholders. Solutions include close collaborative projects, iterative deployment in increasingly open environments, and the creation of comprehensive documentation and training programs to facilitate adoption."}]}, {"title": "5 CONCLUSION", "content": "This paper explores the potential and challenges of neurosymbolic paradigms for designing, testing, and verifying autonomous CPS.\nWe propose NeuroStrata, a framework enabling top-down synthesis of symbolic and neurosymbolic components for perception and planning/control, and bottom-up adaptation of symbolic programs for real-time decisions. Early results validate neural alignment with specifications. We outline challenges and solutions for implementing NeuroStrata, aiming to bridge theoretical advancements and practical applications, transforming autonomous CPS testing and verification in real-world scenarios."}]}