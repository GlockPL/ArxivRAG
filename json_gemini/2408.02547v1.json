{"title": "The Role of Functional Muscle Networks in Improving Hand Gesture\nPerception for Human-Machine Interfaces", "authors": ["Costanza Armanini", "Tuka Alhanai", "Farah E. Shamout", "S. Farokh Atashzar"], "abstract": "Developing accurate hand gesture perception models\nis critical for various robotic applications, particularly for\ninteractive robots and neurorobots. Such models enable more\nintuitive and effective communication between humans and\nmachines, directly impacting neurorobotics. Recently, surface\nelectromyography (sEMG) has been widely explored due to its\nrich informational context and accessibility when combined with\nadvanced machine learning approaches and wearable systems. The\nliterature has explored numerous approaches to boost performance\nwhile ensuring robustness for neurorobots using SEMG. However,\nthese efforts often result in models requiring high processing\npower, large datasets, and less scalable solutions. This paper\naddresses this challenge by proposing the decoding of muscle\nsynchronization rather than individual muscle activation. We\ninvestigate coherence-based functional muscle networks as the\ncore of the computational process for our perception model. We\nhypothesize that functional synchronization between muscles and\nthe corresponding graph-based network of muscle connectivity\nencodes contextual information about intended hand gestures. This\ncan be decoded using shallow machine learning approaches (e.g.,\nsupport vector machines) without the need for deep temporal\nnetworks, which demand high computational resources. Our\ntechnique could impact myoelectric control of neurorobots by\nsignificantly reducing computational burdens and enhancing\nefficiency. The proposed approach is benchmarked using the\nNinapro DB-2 database, which contains 12 EMG signals from 40\nsubjects performing 17 hand gestures. The approach achieves an\noverall accuracy of 85.1%, demonstrating improved performance\ncompared to existing methods while requiring much less computa-\ntional power. The results support the hypothesis that a coherence-\nbased functional muscle network encodes critical information\nrelated to gesture execution, significantly enhancing hand gesture\nperception with potential applications for neurorobotic systems\nand interactive machines.", "sections": [{"title": "I. INTRODUCTION", "content": "Neurorobotics and interactive robotics stand out among the\nresearch fields in which Hand Gesture Recognition (HGR)\nmodels have been predominantly applied. Such models are at\nthe core of the control strategies, as they facilitate intuitive and\neffective communication between humans and machines, which\nis crucial for the seamless interaction. Surface electromyog-\nraphy (sEMG) has been widely studied for their applications\nin control of prosthetic devices, neurorobotics, and human-\ncomputer interfaces [1], [2], [3], [4]. This is driven by the\npotential in recognizing and predicting hand gestures in a\nwearable, non-invasive way.\nWhen combined with Machine Learning (ML), SEMG biosig-\nnals offer great potential for developing accurate perception\nmodels, enhancing their interpretation and enabling more\neffective hand gesture recognition models [5], [6]. In these\napproaches, the features are usually extracted from the time\n(such as root mean square, variance, mean absolute value,\nzero crossings, histogram) or frequency (such as short-time\nFourier transform, cepstral coefficients) domain of the sEMG,\nand these can then be fed into conventional classifiers, such\nas Support Vector Machines (SVMs) or Linear Discriminant\nAnalysis (LDA) [7], [8], [9], [10]. One of the main limitations\nof conventional ML methods is in the simplicity of the extracted\nfeatures and the utilized models. Thus, they can struggle\nto maintain high accuracy as the complexity and variety of\ngestures increase. With the advent of big data, researchers\nhave leaned towards Deep Learning (DL) approaches, which\nhave shown promise in improving the performance of sEMG-\nbased gesture recognition tasks. These models leverage vast\namounts of data and sophisticated neural network architectures\nto achieve superior accuracy and robustness. In particular,\nConvolutional Neural Networks (CNN) remove the need for\nfeature engineering, improving the model performance [2],\n[11]. Long Short-Term Memory (LSTM) Recurrent Neural\nNetworks (RNN) have also been considered for their potential\nin capturing the gesture temporal dynamics [12], [13]. More\nrecently, our team has shown the potential of more advanced\nDL models, such as vision transformers, combined with transfer\nlearning, which enhanced the performance and generalizability\nof such neural interfaces [14], [15]. Despite their potential,\nDL models come with their own set of challenges. Most of\nthem were originally designed for text processing applications\nand are computationally heavy, requiring extensive datasets\nand substantial processing power, which can be a barrier to\ntheir practical implementation in real-time systems. In this\nletter, we introduce a novel approach centered on the concept\nof functional muscle networks, with the aim of providing an\naccurate HGR model that is capable of balancing performance\nand computational efficiency.\nRecently, the concept of coherence-based functional muscle\nnetworks from neuroscience has aimed to model the synergistic\ncoupling between various muscles, mainly for application in"}, {"title": "II. DATA AND PREPROCESSING", "content": "Different SEMG datasets have been presented and made\npublicly available in the literature [29] [30] [31] [32], and\namong these, the NinaPro initiative [28] stands out for its\npopularity in the scientific and robotics community. Short for\nNon-Invasive Adaptive Prosthetics, NinaPro is an extensive\nresearch project that provides a comprehensive collection of\nSEMG recordings gathered from both intact and trans-radial\nhand amputees performing a range of hand and wrist gestures.\nIt is composed of 10 collections, varying in the number of\nsubjects, movements, and acquiring methods.\nIn particular, we employ the Ninapro DB-2 dataset, which\ncontains SEMG, inertial, kinematic, and force data from 40 able-\nbodied subjects (28 males, 12 females; age 29.9 \u00b1 3.9 years;\n34 right-handed and 6 left-handed). Specifically, the kinematic\ndata were gathered with a Cyberglove 2 data glove, while the\nsEMG data were collected using 12 Delsys Trigno electrodes,\nplaced as follows: eight electrodes were evenly spaced around\nthe forearm near the radio humeral joint, two electrodes were\nplaced on the primary activity sites of the flexor and extensor\ndigitorum muscles, and two electrodes were placed on the main\nactivity spots of the biceps and triceps muscles. The sEMG\nsignals were sampled at a 2000 Hz frequency.\nDuring data collection, the subjects were asked to follow\nseveral movements represented by movies shown on a laptop\nscreen. All subjects performed the movements with their right\nhand for 5 seconds, followed by 3 seconds of rest, and the\nprotocol included 6 repetitions. While the full dataset includes\n49 hand and wrist movements, here we only focus on the 17\ngestures from Exercise B, which are presented in Fig. 2."}, {"title": "A. Pre-processing", "content": "We use each gesture's full data duration of 5 seconds,\nincluding the transient phase (which is represented by the\nfirst 1 second for the movement activation [33]) and the steady-\nstate of the contraction, which corresponds to the remaining\n4 seconds. The train and test sets for gesture classification\nare split based on the repetition number, as in [28] and other\nexisting studies that we use as baseline: repetitions 1, 3, 4, and\n6 are used as the training set, while repetitions 2 and 5 are\nused as the test set.\nTo ensure the quality and usability of the sEMG data, a series\nof pre-processing steps are performed using digital filters. The\npre-processing involves two primary filtering operations:\n\u2022 Bandpass Filtering: a fourth-order Butterworth filter is\ndesigned with the specified passband (10 Hz to 900 Hz)\nto retain the relevant SEMG signal frequencies while\nattenuating those outside this range.\n\u2022 Notch Filtering: a notch filter removes the powerline\ninterference at 50 Hz.\nZero-phase filtering is also applied to avoid phase distortion.\nWe then applied Z-score normalization, where the data is\nnormalized to have a mean of 0 and a standard deviation of 1,\nbased on the training set only. This ensures that the data is on\na common scale, which is essential for effective analysis and\ncomparison."}, {"title": "III. MUSCOLAR COHERENCE ANALAYSIS", "content": "Muscular coherence indicates how well one muscle signal's\nfrequency components align with another's over time. High\ncoherence values suggest that the muscles are working together\nin a coordinated manner, while low coherence values imply\nlower synergy. The coherence between signal pairs can be\nquantified using the Magnitude-Squared Coherence (MSC).\nGiven two signals x(t) and y(t), their MSC is defined as:\n$MSC(f) = \\frac{|P_{xy}(f)|^2}{P_{xx}(f) \\cdot P_{yy}(f)}$, (1)\nwhere:\n\u2022 $P_{xy}(f)$ is the cross-spectral density of signals x and y at\nfrequency f;\n\u2022 $P_{xx}(f)$ and $P_{yy}(f)$ are the power-spectral densities of\nsignals x and y at frequency f.\nThe MSC value ranges from 0 to 1, where MSC = 1\nindicates perfect linear correlation at that particular frequency\n(or, in other words, the signals are identical at this frequency),\nwhile MSC = 0, indicates no linear correlation at a particular\nfrequency (the signals are completely uncorrelated at this\nfrequency). By analyzing MSC values across different muscle\npairs and frequencies, we can gain insights into the coordination\npatterns of muscle activity during the considered gestures.\nTo compute the power spectral densities in equation 1, the\nWelch's method is applied with a window size of 600 samples\n(which, given the sampling frequency of 2 kHz, corresponds\nto 300 ms timesteps) and 50% overlap. Finally, we obtained\nthe adjacent coherence matrices containing the MSC values\nover the frequency domain for each signal combination."}, {"title": "IV. GESTURE CLASSIFICATION MODEL", "content": "In this section, we introduce the proposed model, discussing\nprevious works that used the same dataset and that represent our\nbaseline. The NinaPro DB-2 dataset has been widely employed\nfor sEMG-based gesture classification through both traditional\nmachine learning methods, such as random forest, SVM, k-\nnearest neighbors [28], and advanced deep learning techniques,\nincluding CNNs [34], [11], LSTMs [35], hybrid approaches\n[36], and the dilated efficient Capsule Neural Network (Cap-\nsNet) [33]. Table II outlines the characteristics and accuracy of\nthe approaches using the same dataset that we consider here\n(Exercise B with 17 gestures), establishing the baseline for our\nmethod. In this paper, we aim to demonstrate that, leveraging\nthe concept of muscular coherence can achieve comparable\nor superior classification results. Our approach focuses on\nextracting meaningful features from the magnitude-squared\ncoherence of the sEMG signals, reducing the complexity of\nthe model without compromising its accuracy. This can be\naccomplished using a traditional machine learning model, such"}, {"title": "A. Results", "content": "The SVM classifier is trained and tested on each subject\nindividually. Table I presents the average accuracy, precision,\nrecall, F1 score and the Area Under the receiver operating\ncharacteristic curve Curve (AUC) obtained for each considered\ngesture. Finally, Fig. 5 presents the average confusion matrix\nacross all subjects. For each gesture, the test set consists\nof 2 repetitions. On average, 28.9 samples were correctly\npredicted out of the total 34 samples. Class 9 (wrist supination\nalong the middle finger axis) presents one of the highest\nmisclassification rates, and it was mostly confused with Class\n11 (wrist supination along the little finger axis). This could also\nbe predicted from Figs. 3 and 4, where these two classes present\nsimilar values of MSC. Class 15 (wrist radial deviation) was\nalso confused with Class 3 (ring and little fingers flexion with\nthe extension of the remaining ones), and, from the results of\nSubject 19 in Fig. 3, it can be noted that the two corresponding\nMSC matrices are, in fact, similar."}, {"title": "V. CONCLUSION", "content": "In this paper, we introduce a novel machine learning\nclassifier that leverages coherence based functional muscle\nnetworks to enhance hand gesture perception. By analyzing the\norchestration of functional muscles during hand movements,\nour approach provides a low-dimensional gesture classifier"}]}