{"title": "UNVEILING REDUNDANCY IN DIFFUSION TRANSFORMERS (DITS): A SYSTEMATIC STUDY", "authors": ["Xibo Sun", "Jiarui Fang", "Aoyu Li", "Jinzhe Pan"], "abstract": "The increased model capacity of Diffusion Transformers (DiTs) and the demand for generating\nhigher resolutions of images and videos have led to a significant rise in inference latency, impacting\nreal-time performance adversely. While prior research has highlighted the presence of high similarity\nin activation values between adjacent diffusion steps (referred to as redundancy) and proposed various\ncaching mechanisms to mitigate computational overhead, the exploration of redundancy in existing\nliterature remains limited, with findings often not generalizable across different DiT models. This\nstudy aims to address this gap by conducting a comprehensive investigation into redundancy across a\nbroad spectrum of mainstream DiT models. Our experimental analysis reveals substantial variations\nin the distribution of redundancy across diffusion steps among different DiT models. Interestingly,\nwithin a single model, the redundancy distribution remains stable regardless of variations in input\nprompts, step counts, or scheduling strategies. Given the lack of a consistent pattern across diverse\nmodels, caching strategies designed for a specific group of models may not easily transfer to others.\nTo overcome this challenge, we introduce a tool for analyzing the redundancy of individual models,\nenabling subsequent research to develop tailored caching strategies for specific model architectures.\nThe project is publicly available at https://github.com/xdit-project/DiTCacheAnalysis", "sections": [{"title": "1 Introduction", "content": "In recent years, diffusion models have emerged as predominant tools in the realms of image and video generation owing\nto their profound comprehension of user prompts, capacity for high-resolution generation, and alignment with real-world\nconsistency. A notable trend in model architecture involves a transition from the conventional U-Net backbone [1] to\nthe innovative Diffusion Transformer (DiT) [2]. Concurrently, the parameter count in DiT models grows remarkably,\nenabling the handling of higher-resolution images and videos with increased frame counts. However, the expansion in\nboth model parameters and input sequence length has significantly escalated the inference latency of DiT models. The\ngeneration of a single high-resolution image typically demands minutes due to this heightened latency, thereby bringing\nnot only challenges for model deployment and application but also unfeasibility to real-time services.\nIn response to this challenge, numerous research is focused on mitigating the inference latency of DiT models.\nLeveraging the transformer backbone of DiT, existing methodologies aimed at accelerating transformer computations,\nsuch as pruning [3], distillation [4], quantization [5], and parallelization [6, 7] can be repurposed. These efforts aim to\nenhance time efficiency for each diffusion step, thereby reducing the overall latency. Furthermore, a separate line of\nresearch has identified similarities in activations between adjacent steps in the diffusion process, identifying a concept\nknown as redundancy [8, 9, 10]. Researchers in this domain have proposed adopting a caching mechanism, wherein\nmodel outputs from early diffusion steps are preserved and later reused to minimize computational overhead. By\nleveraging these methodologies, researchers aim to streamline the inference process of DiT models, paving the way for\nmore efficient and practical applications in real-world scenarios.\nWhile diffusion transformers (DiT) have demonstrated promising results, there remains a notable gap in exploring\nthe impact of the DiT structure on generation, alongside the absence of a tailored acceleration framework for the DiT"}, {"title": "2 Background & Related Work", "content": "Diffusion Models: Diffusion models utilize a noise-prediction deep neural network (DNN) denoted by \u20ac\u03b8 to generate\na high-quality image. The process starts from pure Gaussian noise x\u0442 ~ N(0, I) and involves numerous iterative\ndenoising steps to produce the final meaningful image 20, with T representing the total number of diffusion time steps.\nAt each diffusion time step t, given the noisy image xt, the model e takes xt, t, and an additional condition c (e.g., text,\nimage) as inputs to predict the corresponding noise et within xt. At each denoising step, the previous image xt-1 can\nbe obtained from the following equation:\nXt-1 = Update(xt, t, et), Et = \u20ac0 (xt, t, c).\nIn this context, Update denotes a function that is specific to the sampler, i.e. DDIM [11] and DPM [12], generally\ninvolves operations such as element-wise operations. After multiple steps, we decode 20 from the Latent Space to the\nPixel Space using a Variational Autoencoder (VAE) [13]. Consequently, the predominant contributor to diffusion model\ninference latency is attributed to the forward propagation through the model \u03b5\u03b8.\nDiffusion Transformers (DiTs): The architecture of diffusion model ee is undergoing a pivotal transition from\nU-Net [1] to Diffusion Transformers (DiTs) [14, 15, 16], driven by the scaling law demonstrating increased model\nparameters and training data with enhanced model performance. Unlike U-Nets, which apply convolutional layers\ncapturing spatial hierarchies, DiTs segment the input into latent patches and leverage the transformer's self-attention\nmechanism to model relationships within and across these patches.\nIn DiTs, the input noisy latent representation is decomposed into patches. These patches are embedded into tokens and\nfed into a series of DiT blocks. DiT blocks generally incorporate Multi-Head Self-Attention, Layer Norm, and Pointwise\nFeedforward Networks. However, the specifics of different DiT models may vary. For instance, the incorporation of\nconditioning can be achieved through various methods such as adaptive layer norm [2], cross-attention [15], and extra\ninput tokens [17]. As diffusion models tackle higher-resolution images and longer visual sequences, they impose a\nquadratic computational burden on inference.\nInput Temporal Redundancy: Diffusion Model entails the iterative prediction of noise from the input image or video.\nRecent research has highlighted the concept of input temporal redundancy, which refers to the similarity observed in"}, {"title": "3 Previous Observations on DiT's Input Temporal Redundancy", "content": "This section provides an overview of three seminal works that investigate the input temporal redundancy within DiTs.\nL2C. [8] To the best of our knowledge, L2C is the first method studying the input temporal redundancy between\nconsecutive diffusion steps in DiT inference. L2C compares the difference in activation values of each DiT layer\nbetween diffusion steps, and finds that the performance varies significantly across steps, even at the same layer. The\ndifference is markedly higher in the later steps compared to the early denoising steps, and is greater in multi-head\nattention layers than in feed-forward layers.\nTGATE. [9] TGATE endeavors to unveil the functionality of cross-attention in the diffusion process of a pre-trained DiT.\nBy examines the disparities in cross-attention maps in SD-2.1 between two consecutive diffusion steps, TGATE unveils\na distinct trend characterized by elevated values in the initial stages that gradually converge towards zero within the 5 to\n10 step range.\nPAB. [10] Addressing the substantial computational overhead inherent in video generation, PAB investigates the\nattention discrepancies between diffusion steps in video generation models like Open-Sora. The findings reveal a\ndiscernible U-shaped pattern, with values approximating zero in intermediate steps while peaking at both ends. Various\nattention mechanisms, such as spatial, temporal, and cross-attention, exhibit diverse degrees of stability throughout the\ndiffusion process."}, {"title": "4 Our Systematic Study", "content": "As evident from Section 3, disparities exist in previous observations regarding the redundancy distribution among\ndiffusion steps, with certain conclusions even conflicting. Consequently, this section undertakes extensive experiments\nfocusing on input temporal redundancy."}, {"title": "4.1 Experimental Setup.", "content": "To make our work systematic, we incorporate a diverse array of mainstream DiT models, each introduced below:\n\u2022 Flux.1-dev. [22] Flux.1-dev, a rectified flow transformer with 12 billion parameter, excels in generating images\nfrom textual descriptions.."}, {"title": "4.2 Varying Prompts", "content": "Given model M, layer j, and diffusion step i, we calculate a list of L1 distance for X (X \u2208 {K, V, A}), denoted\nas [AXM(p1), (p2), ..., XM (PN)], where each element corresponds to a prompt in [p1, P2,..., PN]. To\ninvestigate whether the input prompt influences the redundancy distribution, we compute the coefficient of variation\nover the array of L1 distance. This coefficient is defined as the ratio of the standard deviation to the mean of the array.\nSubsequently, we calculate the average coefficient of variation across all layers and diffusion steps for each model,\npresenting the results in Table 2. The table reveals that the choice of prompt impacts the L1 distance of K, V, and\nA by approximately 10% to 15% on average. This suggests that while the DiT model predominantly determines the\nredundancy distribution, the contribution from prompts is limited. Therefore, in subsequent experiments, instead of\nexamining redundancy for each prompt individually, we report the average L1 distance across all prompts to provide a\ncomprehensive overview."}, {"title": "4.3 Varying DiT models", "content": "This subsection compares the distribution of redundancy across diffusion steps in various DiT models.\nFlux.1-dev. Figure 2 illustrates the distribution of L1 distance in K, V, and A in Flux.1-dev. Each subfigure represents\nthe L1 distance distribution over diffusion steps for a specific layer of the model. Overall, the redundancy in K, V,"}, {"title": "4.4 Varying Number of Diffusion Step", "content": "In the FLUX.1-dev model, the default number of inference step is 28. To investigate the impact of the length of the\ndiffusion process on redundancy distribution, we conducted two additional experiments on FLUX.1-dev by varying the\nnumber of inference steps to 56 and 14 while keeping all other settings constant. Figure 9 and 10 depict the trends of L1\ndistance across all layers in the model, respectively.\nAnalysis of the figures reveals that when using 56 diffusion steps, the overall trends closely resemble those observed in\nthe default setting. Notably, a significant change in L1 distances occurs around the 34th diffusion step, maintaining a\nconsistent relative position throughout the diffusion process.\nOn the other hand, when reducing the number of inference steps to 14, the plots in the figures exhibit smoother patterns\ncompared to those with 28 or 56 steps. However, the trends in L1 distances remain stable. Consequently, we can infer\nthat the number of diffusion steps does not significantly alter the redundancy distribution in DiT models."}, {"title": "4.5 Varying Scheduler", "content": "Upon observing that both FLUX.1-dev and Stable-Diffusion-3 employ the Flow Match Euler Discrete Scheduler with\ndistinct configurations, we opted to replace the scheduler of FLUX.1-dev with that of Stable-Diffusion-3 to explore its"}, {"title": "4.6 Conclusion", "content": "This study delves into the examination of redundancy within Diffusion-in-Transformer (DiT) models throughout the\ndiffusion process. Commencing with a thorough review of existing research insights, we progress to present our\nsystematic investigation. Encompassing a diverse array of mainstream DiT models, we conduct ablation studies\ninvolving varying prompts, models, diffusion steps, and schedulers. The key findings derived from our experimental\nanalyses are outlined as follows:\n1. The redundancy distribution within each DiT model exhibits distinct trends.\n2. In the context of a singular model, the redundancy distribution demonstrates stability irrespective of alterations\nin input prompts, step counts, or scheduling strategies.\nOur results suggest that caching strategies tailored for specific subsets of models may not seamlessly transfer to others.\nConsequently, we introduce a lightweight tool for exploring redundancy in DiT models, facilitating the development of\ncustomized caching strategies tailored to specific model architectures in subsequent research endeavors.\nFuture work: This paper aims to clarify the redundancy distribution to aid researchers in diminishing the latency of\nindividual diffusion steps through appropriate approximations. However, it would be interesting to investigate whether\nwe can maintain comparable generation quality while decreasing the number of inference steps without resorting to\napproximations. Furthermore, rather than crafting caching methods tailored to each distinct DiT model based on its\nredundancy patterns, an engaging avenue for research involves dynamically capturing redundancy behavior during DiT\noperation and adjusting the caching strategy based on ongoing observations."}]}