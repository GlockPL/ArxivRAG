{"title": "Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation", "authors": ["Bolei He", "Nuo Chen", "Xinran He", "Lingyong Yan", "Zhenkai Wei", "Jinchang Luo", "Zhen-Hua Ling"], "abstract": "Recent Retrieval Augmented Generation (RAG) aims to enhance Large Language Models (LLMs) by incorporating extensive knowledge retrieved from external sources. However, such approach encounters some challenges: Firstly, the original queries may not be suitable for precise retrieval, resulting in erroneous contextual knowledge; Secondly, the language model can easily generate inconsistent answer with external references due to their knowledge boundary limitation. To address these issues, we propose the chain-of-verification (CoV-RAG) to enhance the external retrieval correctness and internal generation consistency. Specifically, we integrate the verification module into the RAG, engaging in scoring, judgment, and rewriting. To correct external retrieval errors, CoV-RAG retrieves new knowledge using a revised query. To correct internal generation errors, we unify QA and verification tasks with a Chain-of-Thought (CoT) reasoning during training. Our comprehensive experiments across various LLMs demonstrate the effectiveness and adaptability compared with other strong baselines. Especially, our CoV-RAG can significantly surpass the state-of-the-art baselines using different LLM backbones.", "sections": [{"title": "1 Introduction", "content": "Recent advancements in Large Language Models (LLMs) (Brown et al., 2020; Zhang et al., 2022; Zeng et al., 2022; Chowdhery et al., 2023; Touvron et al., 2023) have significantly transformed the landscape of natural language understanding technology. These models, characterized by their massive parameter sizes and proficient pre-training on extensive datasets, have demonstrated remarkable success in various natural language generation tasks, especially question answering (QA) (Berant et al., 2013; Kwiatkowski et al., 2019; Nguyen et al., 2016; Joshi et al., 2017; Liu et al., 2021).\nIn practice, even the most advanced LLMs often face hallucination problems (Rawte et al., 2023; Ji et al., 2023a; Ye et al., 2023; Maynez et al., 2020), generating answers with factual errors due to persistent inappropriate knowledge. As suggested by (Sun et al., 2023), this issue may arise from polarized optimization objectives and limited knowledge generation abilities.\nTo address the hallucination problem, the retrieval augmented generation (RAG) has emerged by introducing retrieval knowledge from external sources (Guu et al., 2020b; Lewis et al., 2020; Izacard et al., 2022; Nakano et al., 2021). Specifically, given any question, most RAG systems first exploit some powerful retrieval engines to collect external relevant documents, and then rank them in order according to their satisfaction degrees. After that,"}, {"title": "2 Methods", "content": "As depicted in Figure 2, model CoV-RAG, is composed of two foundational elements: the generator, and the chain-of-verification(CoV). By integrating CoV, we introduce a novel mechanism for enhancing the factuality and consistency in RAG."}, {"title": "2.1 The RAG Framework", "content": "In RAG, external knowledge k, also referred to as \"references\", is first retrieved based on its relevance to the input query x using a retriever module R, formulated as k =R(x). Subsequently, a language model M generates a response to the query x by utilizing external knowledge k, following the standard next token prediction objective:\n$\\max_M E_{(x,k,y)\\sim D} \\log p_M(y|x, k)$ (1)\nHowever, directly optimizing the above objective may encounter the following problems: the generator M might produce answers y that are inconsistent or repetitive, and the retriever R could retrieve incorrect external knowledge k due to the query x not apt for effective retrieval."}, {"title": "2.2 CoV-RAG Inference", "content": "To provide a comprehensive understanding of CoV-RAG, we present the inference in Algorithm 1.\nRetrieval Augmented Generation Following Equation (1), the retriever R retrieves references k based on the question x (Liu et al., 2023). Then, the model of CoV-RAG M predicts an answer \u0177 using both the question and the references."}, {"title": "3 Experiments", "content": "COV-RAG is evaluated on the domain of factual Open-Domain Question Answering, where it generates responses to factual queries using external knowledge. For test datasets, we utilize Natural Questions\u00b2(Kwiatkowski et al., 2019), Web Questions\u00b3(Berant et al., 2013) following (Liu et al., 2023). Moreover, we randomly selected samples from each dataset in TriviaQA4(Joshi et al., 2017) and Mintaka (Sen et al., 2022)."}, {"title": "3.2 Models and Methods", "content": "We use three categories of models as baselines:\nNaive LLMs The group generates answer solely on internal knowledge. We referenced the capabilities of GPT-3(Liu et al., 2023) inaccessible online now.\nRAG Models The category includes popular RAG methods such as ChatGPT(gpt-3.5-turbo-0125) with external knowledge, Perplexity.ai(pplx-7b) and WebGLM(GLM-10b)(Liu et al., 2023). We also trained WebGLM on Vicuna-7b/13b, Llama2-7b/13b, and ChatGLM2-6b.\nVerification/Rewriting Augmented RAG This group includes RAG enhanced by verification or rewriting, such as Self-RAG7(Asai et al., 2023a) with the best-performing Llama2-13b, RRR8(Ma et al., 2023) with ChatGPT(gpt-4-1106-preview), and models trained on CoV-RAG with various parameters and type. Additionally, we conducted detailed experiments on verification, including single-turn RAG with/without reflection (Figure 4), rewriting position (before or after RAG, Table 5), and the influence of chain-type verification (direct rewriting or chained rewriting such as scoring -> judgement -> rewriting, Table 6)."}, {"title": "3.3 Metrics and Retrieval", "content": "Metrics Performance is evaluated with Accuracy, following (Liu et al., 2023), standardizing text capitalization and removing punctuation. Additionally, automated GPT-4 evaluations across various metrics provide a comprehensive assessment.\nRetrieval CoV-RAG employs a two-stage retrieval(Liu et al., 2023): coarse-grained web search (Chrome) and fine-grained LLM-augmented retrieval. Additionally, to validate adaptability across retrieval tools, we also utilize Bing Search, as detailed in Section 4.4."}, {"title": "4 Results and Analysis", "content": null}, {"title": "4.1 Main Results", "content": "Our experiments validate CoV-RAG's effectiveness and adaptability, as shown in Table 2 and Figure 4.\nEffectiveness CoV-RAG outperforms popular methods, including naive LLMs (GPT-3), RAG models (ChatGPT with the same retrieval, Perplexity.ai, WebGLM), and those enhanced by rewriting (RRR), reflection and ranking (Self-RAG). This superiority is demonstrated across four datasets in open-domain question-answering tasks (Table 2). Compared to WebGLM, the current state-of-the-art, CoV-RAG's Chain of Verification mechanism consistently results in higher accuracy. Notably, COV-RAG with ChatGLM2-6b achieved 72.2% accuracy, surpassing WebGLM with Vicuna-13b at 71.1%, demonstrating CoV-RAG's superior performance across different model sizes.\nAdaptability We evaluated model size and version effects by comparing WebGLM, CoV-RAG-S (single iteration without re-retrieval), and COV-RAG across various models: Llama2-13b/7b, Vicuna-13b/7b, and ChatGLM2-6b (Figure 4). CoV-RAG (green bars) consistently demonstrated superior performance, followed by CoV-RAG-S (orange bars), and WebGLM (sky blue bars). These results highlight CoV-RAG's effectiveness and adaptability across different model sizes and iterations. CoV-RAG-S uses the same inference process"}, {"title": "4.3 Ablation of Chain-of-Verification", "content": "We conducted experiments to evaluate the effectiveness of CoV in RAG.\nRevising Position\n\u2022 We evaluated revising positions within RAG using the DuckDuckGoSearchAPIWrapper retriever and ChatGPT (gpt-4-1106-preview) for generation (Ma et al., 2023). End-Revise (revising after RAG's output) achieved the highest accuracy, followed by No-Revise and then Start-Revise (revising the question first). No-Revise refers to the model without the query revision mechanism, while End-Revise includes the full revision process at the end of RAG process."}, {"title": "4.4 Further Analysis on Retriever", "content": "We evaluated the improvement of CoV-RAG in retrieval accuracy with two retriever tools (Bing and Chrome) in Table 7. Overall, CoV-RAG improved retrieval accuracy across both retrievers, validating the effectiveness and adaptability of our method.\nOur retrieval process is based on WebGLM (Liu et al., 2023), which includes coarse-grained web search and fine-grained LLM-augmented retrieval. In the first stage, URLs are retrieved via web engines (e.g., Google/Bing), HTML content is crawled, and relevant text is extracted. In the second stage, an LLM refines the extracted content to identify the most relevant information.\nThe results show that multi-iteration retrieval consistently outperforms single-iteration retrieval."}, {"title": "5 Related Work", "content": "Numerous studies indicate that most large language models(LLMs) usually suffer from the hallucinations (Rawte et al., 2023; Ji et al., 2023a; Ye et al., 2023; Maynez et al., 2020). Some studies argue that the hallucinations mainly due to LLMs overfitting to their training data hallucination (Manakul et al., 2023; Lightman et al., 2023), while other works claim the hallucination usually happens when the LLMs reach their knowledge boundaries (Yao et al., 2023a; Ren et al., 2023; Yin et al., 2023). Currently, there are various methods proposed to address the hallucination problem, such as hallucination detection (Ji et al., 2023b; Manakul et al., 2023; M\u00fcndler et al., 2023), data augmentation(Dai et al., 2023), and retrieval-augmented generation (RAG)(Guu et al., 2020a,b; Lewis et al., 2020; Izacard et al., 2022; Nakano et al., 2021).\nCompared with other methods, RAG's advantage lies in that it can leverage real-time retrieval results to expand the knowledge boundaries of LLMs and thus enhance their generation quality. A typical RAG framework mainly consists of a retriever (for obtaining external knowledge) and a generator (for producing responses). As for the retriever, some studies adopt end-to-end training techniques(Zhang et al., 2023; Shi et al., 2023) and additional ranking modules(Glass et al., 2022; Jiang et al., 2023) to enhance the retriever's performance. Other researches improve the knowledge acquisition performance via extra modules, such as rewriting(Ma et al., 2023; Wang et al., 2023a), and filtering retrieved content(Wang et al., 2023b)to improve retrieval quality. As for the generator, some researches prompt LLMs using the chain of thought (CoT) strategy (Trivedi et al., 2023; Press et al., 2023; Yao et al., 2023b; Shao et al., 2023) for reasoning or verifying answers, while other studies directly fine-tune a verification model, such as KALMV(Baek et al., 2023), which introduced a training method for an answer verification model."}, {"title": "Limitations", "content": "There are also limitations in the COV-RAG framework, we will discuss below to provide valuable insights for future research.\nFirst, in the data collection stage for the generator, to reduce time and financial costs, we distill a small size LM from GPT-4 and employ it to generate training data for the generator. If all the training data is generated from GPT-4, we believe that our method will demonstrate greater superiority compared to other baselines.\nSecond, for the consideration of efficiency, the retriever re-retrieves new relevant references in the verification stage, then the LM predict final answer and output directly. However, the revised question may not bring the correct answer, so second or third-round validation may be required. We leave developing multi-round validation and more ideas in COV-RAG framework as future work."}, {"title": "Ethics Statement", "content": "In our research, we strictly adhere to all ethical standards, the evaluation criteria for all methods in experiments are standardized, and there are no artificial modifications to the metrics, we make the data and code from the paper publicly available."}, {"title": "6 Conclusion", "content": "In this paper, we introduce a novel retrieval augmented generation method, CoV-RAG. It can effectively mitigate hallucinations during internal generation stage and external retrieval stage in the RAG. Specifically, by integrating the chain of verification prompting into fine-tuned RAG generators, we can successfully identify and mitigate generation errors. In addition, the chain of verification prompting can also refine external contextual knowledge through re-retrieving the revised query. We conduct a various experiments to assess the effectiveness of CoV-RAG over different language model backbones. And experimental results demonstrate that the CoV-RAG can well detect the generation errors, and significantly improve the generation quality. Looking ahead, CoV-RAG paves the way for further research in refining knowledge augmentation strategies, contributing to the improvement of reliability and accuracy of RAG."}]}