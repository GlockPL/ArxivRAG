{"title": "Enabling Autonomic Microservice Management through Self-Learning Agents", "authors": ["Fenglin Yu", "Fangkai Yang", "Xiaoting Qin", "Zhiyang Zhang", "Jue Zhang", "Qingwei Lin", "Hongyu Zhang", "Yingnong Dang", "Saravan Rajmohan", "Dongmei Zhang", "Qi Zhang"], "abstract": "The increasing complexity of modern software systems necessitates robust autonomic self-management capabilities. While Large Language Models (LLMs) demonstrate potential in this domain, they often face challenges in adapting their general knowledge to specific service contexts. To address this limitation, we propose SERVICE ODYSSEY, a self-learning agent system that autonomously manages microservices without requiring prior knowledge of service-specific configurations. By leveraging curriculum learning principles and iterative exploration, SERVICEODYSSEY progressively develops a deep understanding of operational environments, reducing dependence on human input or static documentation. A prototype built with the Sock Shop microservice demonstrates the potential of this approach for autonomic microservice management.", "sections": [{"title": "1 Introduction", "content": "Modern software systems are becoming increasingly distributed and large-scale, posing significant management challenges. This growing complexity underscores the importance of autonomic self-management capabilities [21]. Recent advancements in Large Language Models (LLMs), known for their exceptional contextual understanding and adaptive decision-making capabilities [47], have inspired new approaches of developing LLM-based agents for autonomic software service management [18]."}, {"title": "2 Design of the SERVICEODYSSEY System", "content": "The SERVICEODYSSEY system architecture, shown in Figure 1, is built on a microservice system augmented by a data layer and a management layer. This design enables efficient self-learning and task execution within microservices. The data layer serves as a repository for critical data, including system running state and interaction history. This information is passed to the management layer in self-learning processes. Additionally, the data layer stores data during self-learning such as tasks and execution plans, which are subsequently executed in the operational environment. The data layer works as an intermediate layer, bridging the microservice system and the LLM-enhanced management layer. The management layer consists of three key LLM-enhanced modules:\n1 Curriculum Builder (CB) module progressively generates tasks, aiming to explore and learn the microservice system. 2 Execution Planner (EP) module is responsible for generating executable plans and actions by translating tasks generated by CB into actionable strategies. These strategies are executed within the microservice environment, with real-time feedback and interaction history being collected. The 3 Knowledge Curator (KC) module consolidates the feedback and interaction history from task execution into a comprehensive skill library. This growing collection of skills can be utilized by EP to tackle increasingly complex management tasks in the microservice system."}, {"title": "2.1 Curriculum Task Generation", "content": "When facing a new microservice system, humans often apply their existing knowledge to explore and understand the unfamiliar environment. This process, known as discovery learning in educational theory [4], involves actively using their prior knowledge to independently explore new concepts. Inspired by this approach, we designed Curriculum Builder (CB) to generate tasks that facilitate the exploration and learning of new microservice systems.\nTask generation principles. We design directives to prompt LLMs to generate diverse tasks with principles, helping explore and discover the system. The generated tasks should reflect the progressive learning mechanism, building upon previous experienced tasks:\n(1) from easy to hard: Following the curriculum learning methodology [3, 39], tasks are generated in a sequence that progresses from easy to hard. The CB reviews previously completed tasks to generate new ones, building on successful experiences by adding incremental challenges. Successful tasks guide the creation of similar, yet more challenging tasks. In the meanwhile, failed tasks prompt the generation of easier or alternative tasks that could potentially be solved.\n(2) from observation to action: Following the DevOps practices [5, 17], the transition from observation to action is a fundamental aspect of managing microservice systems. Initially, tasks focus on observing the system to gather insights into its performance and configuration, using monitoring tools and metrics. These observation tasks are safe and do not alter the system state. Once a comprehensive understanding is achieved, the focus shifts to action tasks, where changes are implemented to optimize the system based on observations. These actions may include configuration tuning, resource scaling, and service refactoring to address issues like latency reduction and resource efficiency. This curriculum task building, central to DevOps, ensures continuous understanding and management of the microservice system.\nContext for task generation. To better prompt LLMs to generate curriculum tasks, the input consists of several parts:\n(1) System running state: This includes contextual information such as traffic load, system health status, etc. The dynamic nature of the running state allows CB to create tasks that are highly relevant to the current status of the microservice. For instance, a normal running state might prompt monitoring and logging tasks, while an anomalous state could lead to tasks focused on diagnosis and mitigation.\n(2) Interaction history: This records the details and outcomes of previous interactions between agents and the managed microservice, reflecting the current management capabilities and self-learning progress. Including it in CB would provide detailed context to generate new tasks"}, {"title": "2.2 Solution Refinement with Feedback", "content": "Once the tasks are generated from CB and put into the task queue, Execution Planner (EP) aims to generate executable solutions leveraging previously learned skills and feedback. However, LLMs have challenges to ensure solutions to be executable in specific microservice environment [36]. To address this challenge, we design a solution refinement mechanism that incorporates collective feedback to iteratively reflect and refine the generated solutions to make them executable and valid in the microservice system. High-quality solutions are crucial for KC to create valid and useful skills.\nAgentic microservice system. We first introduce the environment where the solution is executed. For illustration, we adopt the Sock Shop microservice [7], which simulates an e-commerce platform for selling socks, as a representative microservice environment. To enable LLMs to provide feedback in the solution refinement, the Sock Shop microservice system turns into an agentic microservice system with each system component managed by an LLM-enhanced agent [50] (as shown in Figure 2). For example, the Catalogue component turns into the Catalogue agent, supporting natural language-based management and communication. These agents form the low-level agents layer in Figure 2. Above it, an LLM-based high-level manager is designed as an entry point to decompose tasks into subtasks and coordinate low-level agents [22, 30].\nSolution initialization. The solution generation process begins with the high-level manager analyzing the task description and retrieving pertinent skills from the skill library [10] for task decomposition. If no suitable skills are available, the high-level manager leverages the inherent knowledge of LLMs. Subtasks are then allocated to low-level agents in order to generate executable actions to address these subtasks. Once all subtasks are completed, their solutions are ensembled to form the final solution. In practice, it is challenging to generate an executable and valid solution in one attempt, and it often requires reflection and refinement from feedback to make solutions executable and valid.\nReflection and refinement from feedback. There are typical three types of feedbacks, each type providing specific refinement suggestions:\n(1) Environment feedback: This feedback contains syntax and execution errors from the microservice system, providing direct and reliable feedback to improve solution quality and fix bugs. LLMs can learn from system error messages to refine solutions [8, 41]. Such environment feedback reveals the microservice properties such as configurations, enabling syntax corrections and solution adaptations to suit the microservice environment.\n(2) Peer feedback: Task completion often involves multi-agent collaboration [13, 42]. Peer feedback occurs from the collaboration among \u201cpeer\u201d agents at the same hierarchical level (or neighboring agents in the decentralized setting). The execution of a subtask can depend on the execution results from the former agent. An agent might self-verify its solution to resolve an assigned subtask limited to the knowledge scope of itself. However, the feedback from downstream agent provides extra requirements to refine the solution. One typical example is the format of the execution results from an agent does not meet the input requirement of the downstream agent, and the format requirement feedback helps modify the solution to ensure the ensembled solution from involved agents to be valid and executable.\n(3) Hierarchical feedback: The high-level manager oversees the entire subtask completion process and dynamically alters the task decomposition and allocation based on the task execution process. In practice, the initial task decomposition is not always optimal [16], the high-level manager do re-decomposition and re-planning in an interleaving manner and modifies the subtask allocation and content. Additionally, the hierarchical feedback provides global and indirect information, which the peer feedback cannot support. For example, a task of reducing the overall system's latency requires the collaboration of low-level agents to reduce latency. Different low-level agents have diverse capabilities in latency reduction, and"}, {"title": "2.3 Knowledge Creation and Validation", "content": "The aim of Knowledge Curator (KC) is to consolidate the knowledge from the successfully executed tasks with related solutions into a skill library. The skill library represents the knowledge of the microservice system after self-learning and is valuable for self-management of the system. We define three skill schemas: Command, Reflection, and Configuration in the Sock Shop microservice for KC to better extract skills. Below shows skill examples with each type:"}, {"title": "2.4 SERVICEODYSSEY in Action", "content": "The three modules work together to self-learn the real-world microservice systems. This workflow supports diverse deployment setups. Ideally, if a canary environment is available, SERVICE ODYSSEY runs in full functionality and adjusts the system state freely. In settings without such a sandbox, it restricts itself to safer observation tasks (e.g., monitoring) while still learning system structures and component properties. Additionally, if manual diagnosis and mitigation logs exist, KC can convert these into new skills, reducing future human intervention whenever similar issues recur."}, {"title": "3 Prototype Implementation", "content": "We implemented a prototype of SERVICEODYSSEY in Python, applying it to the Sock Shop microservice. Building on the codebase of [50], we incorporated additional components, including the Curriculum Builder, Knowledge Curator modules, and data-layer elements like the skill library. Hierarchical agent architecture is also adopted for the Execution Planner, while removing Sock Shop-specific instructions in prompts for broader microservice applicability (e.g., the label selector \u201c-l name=Catalogue\u201d). Given the Execution Planner's main role in managing routine operations, we employ GPT-40 [28] as its base LLM to prioritize its low-latency requirement. Meanwhile, the 01 model [29], with its advanced reasoning capabilities, is integrated into Curriculum Builder and Knowledge Curator, as their self-learning processes are often confined to non-peak service periods. The other system deployment replicated the setup described in [50].\nIn this preliminary study, we evaluate how agents acquire service-specific knowledge through observation-driven exploration tasks from the ground up. As in [50], we utilized a three-agent system comprising a high-level manager overseeing two agents for Catalogue and Front-end, respectively. Three experimental trials were conducted, each starting with"}, {"title": "4 Related Work", "content": "Self-Learning Agent. A pivotal advancement in agent design lies in the integration of memory modules [49], which enable agents to retain and build upon past experiences. This capability enables agents to develop more robust and adaptive behaviors over time. In the context of LLM agents, exploration-based self-learning has been explored cross various domains, including gaming [37, 43], web automation [14], computer control [35], smartphone usage [45], social interactions [12], and robotics [25, 38]. These studies emphasize agents interacting with their environments to autonomously gather feedback and refine their capabilities. Such a learning paradigm aligns closely with reinforcement learning, where agents iteratively improve their performance through experience and reward-based feedback loops [9, 11, 46]. Curriculum learning are also effective learning strategies [27, 34, 37]. The integration of memory and self-learning mechanisms represents a critical step forward in enabling agents to operate effectively in real-world scenarios. This foundation sets the stage for developing more autonomous, intelligent systems capable of handling increasingly complex and varied tasks. Encouraged by these advancements, we aim to further explore the potential of self-learning agents in the domain of microservice management.\nLLM for Microservice Management. Key operations in service management include data collection and anomaly detection [19, 20, 23, 44], root cause analysis [1, 6, 33, 40, 48], and incident mitigation [2, 32]. Recent study have also explored the potential of fully autonomous, end-to-end service management systems. Though promising, existing LLMs still face challenge in addressing the complexity and variability of these systems [50]. In this work, we take a first step by introducing an agent-based system designed to autonomously manage mciroservices from a self-learning perspective. Unlike prior approaches, our system operates without any initial knowledge of the microservices, progressively building and refining its service management capabilities over self-exploration with the service. This work aims to reduce reliance on specific domain knowledge while emphasizing adaptability and continuous learning. By presenting this work, we aim to inspire research interest within the community toward developing intelligent, self-learning agent systems capable of managing microservices autonomously."}, {"title": "5 Conclusion", "content": "We present SERVICEODYSSEY, a self-learning agent system for autonomic microservice management, reducing reliance on human input or static documentation. Through curriculum learning and iterative exploration, it progressively builds operational understanding and efficiently adapts to complex environments, as demonstrated with the Sock Shop prototype. Compared to manual efforts, SERVICEODYSSEY offers"}, {"title": "A Prompts", "content": "The specific system prompts used for the task generation, and the memory mechanism are presented in Tables 1, and 2, respectively. The skills extracted via self-exploration in Trail 1 after 15 rounds is presented in Table 3, decoded for better human comprehension."}]}