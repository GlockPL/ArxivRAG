{"title": "Interplay of ISMS and AIMS in context of the\nEU AI Act", "authors": ["Jordan P\u00f6tsch"], "abstract": "The EU AI Act (AIA) mandates the\nimplementation of a risk management system (RMS) and a\nquality management system (QMS) for high-risk Al systems.\nThe ISO/IEC 42001 standard provides a foundation for\nfulfilling these requirements but does not cover all EU-specific\nregulatory stipulations. To enhance the implementation of the\nAIA in Germany, the Federal Office for Information Security\n(BSI) could introduce the national standard BSI 200-5, which\nspecifies AIA requirements and integrates existing ISMS\nstandards, such as ISO/IEC 27001. This paper examines the\ninterfaces between an information security management system\n(ISMS) and an Al management system (AIMS), demonstrating\nthat incorporating existing ISMS controls with specific Al\nextensions presents an effective strategy for complying with\nArticle 15 of the AIA. Four new Al modules are introduced,\nproposed for inclusion in the BSI IT Grundschutz framework to\ncomprehensively ensure the security of Al systems.\nAdditionally, an approach for adapting BSI's qualification and\ncertification systems is outlined to ensure that expertise in\nsecure Al handling is continuously developed. Finally, the paper\ndiscusses how the BSI could bridge international standards and\nthe specific requirements of the AIA through the nationalization\nof ISO/IEC 42001, creating synergies and bolstering the\ncompetitiveness of the German Al landscape.", "sections": [{"title": "I. INTRODUCTION", "content": "The EU AI Act (AIA) mandates, among other things, the\nimplementation of a risk management system (RMS) (Article\n1 + Article 8 + Article 9) and quality management systems\n(QMS) (Article 1, Article 16, Article 17, Annex VII) for high-\nrisk AI systems [1, 2]."}, {"title": "A. ISO/IEC 42001 and the EU AI Act", "content": "To implement the AIA requirements, standards are\nnecessary [3]. The ISO/IEC 42001 standard, published in\nDecember 2023, which describes an AI management system\n(AIMS), includes essential elements for fulfilling the\naforementioned AIA articles [4]. However, the report by Soler\nGarrido et al. [5] shows that while ISO/IEC 42001, ISO/IEC\n42005, and ISO/IEC 42006 are globally recognized standards,\nthey do not directly address specific EU regulatory\nrequirements mandated by the AIA. Soler Garrido et al. [6]\ndiscuss harmonized standards for the AIA and highlight the\nchallenges involved.\nThe advantage of ISO/IEC 42001 lies in its High Level\nStructure (HLS), which facilitates the integration of a\nmanagement system with minimal effort [3]. It builds on\nexisting management systems, such as ISO/IEC 9001 and\nISO/IEC 27001 [7]. To create synergies in practice, it is\npractical to build on existing risk processes within an\norganization when implementing an RMS for AI as required\nby the AIA [8]. The ISMS can serve as a foundation and\nstarting point for integrating additional dimensions of\ntrustworthy Al as part of the RMS [9]. This approach\ndifferentiates between existing ISMS controls that address AI\nsecurity risks, supplements to these controls, and new controls\nneeded to address novel security risks introduced by AI [8]."}, {"title": "B. Cybersecurity in the AI Act", "content": "The report by Soler Garrido et al. [5] states that an ISMS\nbased on ISO/IEC 27001 is regarded as a fundamental basis\nfor meeting the requirements of Article 15 of the AIA.\nHowever, the following challenges must be considered:\nIntegration of management standards: ISO/IEC\n27001 needs to be aligned with other standards, such\nas ISO/IEC 42001, and future European standards on\nAl risk management.\nExpansion of Al-specific cybersecurity aspects:\nCurrent standards lack emphasis on Al-specific\ncybersecurity risks.\nInclusion of international standardization efforts:\nEmerging standards like ISO/IEC 27090 provide\nguidance on AI\ncybersecurity. European\ncontributions should align with the AIA to address\nspecific Al-related risks.\nNolte et al. [10] conclude that the AIA leaves open the\nquestion of whether organizational measures under Article\n15(5)(ii) and (iii) AIA are mandatory. Junkelwitz et al. [11]\nbelieve that both organizational and technical solutions must\nbe implemented to meet the cybersecurity objectives of\nArticle 15 AIA. ISO/IEC 27001 should serve as a foundation,\nwith the addition of AI-specific security controls. ENISA's\nframework for Al good cybersecurity practices (FAICP) [12],\nwhich extends ISMS controls with Al-specific elements, is\npresented as an appropriate approach for complying with\nArticle 15 AIA. Soler Garrido et al. [13] analyze IEEE\nstandards in relation to AIA requirements and find that IEEE\nP2841 most closely meets these requirements. Kalodanis et al.\n[14] investigate why special security controls are necessary\nfor Al and conclude that extending the ISO/IEC 27-family is\nan effective strategy for AIA compliance."}, {"title": "C. Goal of this Paper \u2013 Interplay between ISMS and AIMS", "content": "This paper offers an initial approach to address the\nfollowing gaps:\nClarification of the interface between ISMS and\nAIMS through AI security controls within ISMS:\nA demonstration of the German national ISO 27001-\ncompliant ISMS, specifically the Grundschutz\nframework of the BSI (Federal Office for\nInformation Security in Germany). Due to its\ntechnical detail, this standard is highly illustrative for\nthe purpose of this paper.\nNational situation in Germany: Identifying\nnecessary actions for the BSI in regulating AI\naccording to the AIA."}, {"title": "II. METHODOLOGY", "content": "The comparison between the target and actual state of the\nInformation and Communications Technology (ICT)\ninfrastructure as outlined in the ENISA \"Multilayer\nframework for good cybersecurity practices for AI\" [12], also\nknown as the FAICP framework, and the existing\nGrundschutz framework (2023 edition) [15] is carried out in\nfour steps:\nIdentification of commonly used use cases of\nclassical and generative AI systems: Various\nstudies exist that explore real-world applications of\nAl in different industries. The developed regulations\nare not future-oriented but as practical as possible.\nCharacteristics and attributes of identified use\ncases: What does the ICT infrastructure look like for\nthe respective use cases? This includes IT\ninfrastructure and hardware, Al models, processes,\ndata, and more.\nModeling using existing modules: Identification of\nrelevant modules from the Grundschutz framework.\nAI assets that cannot be modeled with existing\nmodules must be covered by newly developed AI-\nspecific modules (target-actual comparison).\nRisk analysis: Defining module content by setting a\nreasonable scope, identifying threats, and defining\nrequirements. This also includes creating a cross-\nreference table. Additional Al-security standards are\nused to identify controls [16, 17, 18, 19, 20, 21, 22,\n23, 24, 25].\nTo revise personnel competencies, the following steps are\nperformed:\nInitial review of existing areas and associated\npersonnel groups and their curricula: This step\nexamines whether existing areas can be\nmeaningfully supplemented with Al content.\nIdentification of non-integrable Al content:\nAnalysis of Al content that cannot be effectively\nincorporated into existing personnel groups and\nshould be distributed to new groups. A target-actual\ncomparison between competency requirements in\nthe EU AI Act and standards like ISO 42006 is\nconducted with the current scopes of department SZ\n12."}, {"title": "III. RESULTS", "content": "The comparison reveals that existing modules can be\nutilized and new Al-specific modules are necessary to model\nthe ICT infrastructure effectively. The outcome:\nsubstantively, the BSI has established a comprehensive basis\nfor implementing the EU AI Act with minimal effort and, as\nthe first regulatory body in the EU, adopting the ISO/IEC 42x\nseries as a national standard. Depending on the application,\nexisting modules such as CON.2 Data Protection, CON.3 Data\nBackup Concept, APP.4.4 Kubernetes, OPS.2.2 Cloud Use,\nOPS.2.3 Outsourcing Use, or APP.6 General Software can be\nused for AI system modeling. Additionally, the introduction\nof the following four Al modules is recommended to\nsupplement the Grundschutz framework:\nAI Cyber Governance Module: This module\ndescribes the requirements for the secure\nimplementation and use of Al services. It targets all\ninstitutions that already use or intend to develop and\ndeploy such services. The requirements pertain to\nessential aspects of AI governance, compliance, and\nmonitoring, contributing to the identification and\nmitigation of potential threats to operations. This\nmodule aims to link the EU AI Act's requirements\nwith the Grundschutz framework, ensuring risks\nremain manageable for institutions. Governance\nwithin AIMS should also consider transparency\ndimensions that are beyond the scope of the CISO's\npurview.\nData Module: This module addresses the data used\nin Al applications, including training data utilized for\ninitial model setup and metadata such as source\ninformation, quality metrics, and usage logs. Central\nconsiderations include data protection and privacy.\nSensitive data in Al datasets must be secured per\nlegal requirements to protect user privacy. Robust\nsecurity measures are necessary to guard Al data\nagainst unauthorized access, loss, or manipulation,\nensuring data integrity. The provenance and usage of\nAI data should be documented to build user and\nstakeholder trust. Continuous monitoring is required\nto maintain the effectiveness and security of Al\napplications, as data and threats evolve over time. An\nAIMS should ensure that data quality, timeliness,\nprovenance, ethical standards, and relevance are\nmaintained.\nAI Model Module: This module focuses on Al\nmodels, which are characterized by their ability to\ncreate and apply mathematically computable models\nbased on data and adapt these models using\nalgorithms. Al uses data and the patterns they contain\nas learning foundations and, potentially, for\ngenerating its own data. The use of AI should be\nassessed for risks related to information security,\nmanipulation, and environmental impact, following\nthe requirements detailed in this module. An AIMS\nshould build on this to include aspects such as\ntransparency and traceability.\nAI Platform Module: This module outlines the\nrequirements for the secure setup and operation of AI\nservices (AI Function-as-a-Service). It supports\ninstitutions in the planning, execution, and control of\nthe entire Al system lifecycle, covering both\ntechnical and organizational aspects of information\nsecurity.\nWith the Grundschutz framework edition 2023 and these\nfour new modules, a broad range of Al systems can be\neffectively modeled. The newly developed Al modules\nemphasize the information security aspects of trustworthy AI\n(dimension: security). Both product and organizational\nperspectives are considered, analogous to the FAICP\nframework, covering the entire AI lifecycle from the user's\nstandpoint. These modules complement the C5 and AIC4\ncatalogs, which are focused on the provider perspective.\nGrouping these four AI modules into a dedicated module set\nis logical as they are thematically linked and address specific\nAl security aspects such as governance, data management,\nmodel management, and platform operation. This structured\ngrouping facilitates the consistent handling of complex and\ninterdependent security requirements for AI systems, supports\nthe implementation of the EU AI Act, and simplifies future\nextensions for emerging technologies or use cases."}, {"title": "IV. DISCUSSION", "content": "The Member States of the European Union are obligated\nunder the EU AI Act to designate national competent\nauthorities by August 2025 to oversee the implementation of\nthe requirements set forth in the AI regulation [26]. The tasks\nof national oversight of AI essentially encompass three main\nareas:\nThe authority is responsible for appointing\nindependent auditing bodies tasked with the\nevaluation and control of high-risk AI systems.\nThe authority is also in charge of market\nsurveillance, serving as a point of contact for Al\nproviders who identify flaws in their systems.\nThe authority should promote and foster innovation\nand competition.\nArticle 70 of the EU AI Act establishes the framework for\nthe national competent authorities of the Member States,\nwhich are responsible for the implementation and supervision\nof the regulation [1]. It is conceivable that multiple\ninstitutions could jointly assume these responsibilities. In\nGermany, potential candidates for these tasks include the\nFederal Office for Information Security (BSI), the Federal\nNetwork Agency (BNetzA), data protection authorities, or a\nnewly established agency [27]. So far, no political decision\nhas been made, and there are numerous arguments for each\noption.\nIn the past, the BSI has already published studies, the AI\ncriteria catalog AIC4, and various guidelines for the secure\nimplementation of AI. Even if the BSI is not assigned an\nofficial role under the AI Act due to political decisions, it is\ncertain that the agency will continue to play an important role\nin Al regulation. The BSI is actively establishing itself in\ncurrent regulatory initiatives. An example of this is the\nworking group CEN-CENELEC JTC 21. Furthermore, a\nhorizontal standard for high-risk and so-called GPAI \u0391\u0399\nsystems and their use cases is being developed to\noperationalize and certify the requirements of the EU AI Act\nfor these categories.\nWhether or not the BSI will be chosen as the supervisory\nauthority under the EU AI Act, a measure emerges for the\nagency from the aforementioned points: the introduction of a\nnew standard, BSI 200-5 (KIMS), which would adopt the\nessential structure of ISO/IEC 42001, thereby creating a\nspecification of the European Al regulation based on\nISO/IEC 42001. While the interfaces between ISMS and\nAIMS are not clearly defined in the ISO standards, the BSI\ncould delineate these interfaces by introducing new \u0391\u0399\nmodules and BSI 200-5, avoiding content gaps. This interface\nwould involve extending the ISMS to include Al-specific\ncontrols that are part of the Grundschutz framework or\nISO/IEC 27001 certification.\nA significant challenge is also addressed: by nationalizing\nISO/IEC 42001 through BSI 200-5, operationalized\ndimensions of trustworthy AI can be introduced, and\ntechnical controls can be made more concrete. The new BSI\nstandard 200-5 could serve as a certification basis for an\nAIMS in the long term.\nIn this context, new personnel certifications would be\nnecessary, such as an ISO/IEC 42001 Lead Auditor based on\nBSI 200-5. The BSI differentiates between the scope of\ncompetency assessment and certification of individuals\nacross three areas: competency assessments without\nindividual certification, certification for conducting\nexaminations without aiming for (system) certification, and\ncertification for conducting audits aimed at (system)\ncertification.\nIn conclusion, the BSI could play a pivotal role in\nimplementing the EU AI Act in Germany by intelligently\nusing and expanding existing standards and processes. By\nintroducing a new BSI standard 200-5, the BSI could create a\nbridge between international standards, such as ISO/IEC\n42001, and the specific requirements of the EU AI Act. This\napproach would not only create synergies and reduce\ncomplexity but also enhance the competitiveness and\ninnovation potential of the German Al landscape. Tailored\nadjustments to existing certification and competency\nassessment systems would ensure that the necessary skills\nand expertise for securely handling AI are built and\ncontinuously developed in Germany. Assuming that the BSI\ndevelops horizontal CC/evaluation criteria to meet the EU AI\nAct requirements, a specialized AI deepening for CC\nevaluators would be advantageous. Such specialized\nknowledge of the CC evaluator related to a product type,\ntechnology, or site type, depending on the area of application,\nis desired by the BSI. For example, there are already two\nspecialization directions in certain technology areas:\nTechnical Domain \"Smartcards and Similar Devices\" and\nTechnical Domain \"Hardware Devices with Security Boxes.\"\nA technical domain for \"High-Risk AI Systems\" would make\nsense in the context of an evaluation basis. Alternatively, or\nin addition, a new group of individuals (Trusted AI\nEvaluators for High-Risk Systems) could be introduced. It\nshould be noted that these groups do not only focus on the\nsecurity objectives of AI in terms of security. In parallel with\nthe high-risk category in the AI Act, safety and ethical aspects\nare prioritized.\nFrom a consulting perspective (\u201cGrundschutz-Berater\"),\nsupplementing existing personnel groups is sufficient. The\npersonnel groups of penetration testers and incident experts\nfocus on the trinity of Al and cybersecurity. For GS\npractitioners and GS consultants, supplements regarding new\nAl laws and standards are important. Once the BSI introduces\nthe 200-5 standard as the national basis for implementing an\nAl management system, audit and audit team leaders for\ncertification, analogous to ISO 42006, will be required.\nThis national German solution described in this chapter\ncould also be adapted to other European frameworks that are\nbased on ISO/IEC 27001.\""}, {"title": "V. CONCLUSION AND FUTURE DIRECTION", "content": "A comparison between the Grundschutz framework 2023\nedition and the ICT infrastructure of the FAICP framework\nshows that four additional Al modules are necessary to\naddress security risks comprehensively. These modules\nwould be part of the BSI IT Grundschutz certification in the\nfuture. With the AI modules, the interfaces between ISMS\nand AIMS are clearly defined for the first time. The new BSI\nstandard 200-5 would integrate ISO/IEC 42001 and 42006\nand adapt them to meet the EU AI Act requirements.\nCorrespondingly, BSI's personnel competencies and\ncertifications should be adjusted. Through a compatible\napproach with the international standard ISO/IEC 27001,\nother European countries could similarly adapt their\nframeworks following the recommendations of this paper.\nIt is essential to eliminate ambiguities concerning the\nobligatory nature of organizational security controls under\nArticle 15 of the AIA. Additionally, there is a need to specify\nthe operationalized dimensions of trustworthy AI and the\ncontrols in the national standard 200-5 to introduce a\nEuropean AIMS compliant with the AIA. The\noperationalization proposals provided by Fraunhofer IAIS\ncan be used as a basis for this approach [28]. Harmonized\nstandards that may be published by the EU Commission and\nits institutions in the future should be taken into account. The\nFederal Office for Information Security (BSI) is currently\ndeveloping the new \"Grundschutz++\" framework, and it\ncould be beneficial to incorporate the new Al modules and\nthe new AI standard as integral components. Fundamentally,\nhowever, it remains to be seen what role the BSI will play in\nthe future regulation of AI. Although regulatory oversight by\nthe BSI appears reasonable from a technical perspective, it\nultimately remains a political decision."}]}