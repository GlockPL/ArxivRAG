{"title": "On the Diagram of Thought", "authors": ["Yifan Zhang", "Yang Yuan", "Andrew Chi-Chih Yao"], "abstract": "We introduce Diagram of Thought (DoT), a framework that models iterative reasoning in large language models (LLMs) as the construction of a directed acyclic graph (DAG) within a single model. Unlike traditional approaches that represent reasoning as linear chains or trees, DoT organizes propositions, critiques, refinements, and verifications into a cohesive DAG structure, allowing the model to explore complex reasoning pathways while maintaining logical consistency. Each node in the diagram corresponds to a proposition that has been proposed, critiqued, refined, or verified, enabling the LLM to iteratively improve its reasoning through natural language feedback. By leveraging auto-regressive next-token prediction with role-specific tokens, DoT facilitates seamless transitions between proposing ideas and critically evaluating them, providing richer feedback than binary signals. Furthermore, we formalize the DoT framework using Topos Theory, providing a mathematical foundation that ensures logical consistency and soundness in the reasoning process. This approach enhances both the training and inference processes within a single LLM, eliminating the need for multiple models or external control mechanisms. DoT offers a conceptual framework for designing next-generation reasoning-specialized models, emphasizing training efficiency, robust reasoning capabilities, and theoretical grounding\u00b9.", "sections": [{"title": "Introduction", "content": "The capabilities of large language models (LLMs) have expanded significantly, yet their proficiency in complex reasoning tasks remains limited. Traditional approaches like Chain-of-Thought (CoT) (Wei et al., 2022) represent reasoning as linear sequences of intermediate steps, enabling models to \"think aloud.\" While effective for some tasks, this linear structure may not capture the complexities of human reasoning, which often involves revisiting and refining ideas.\nExtensions such as Tree-of-Thought (ToT) (Yao et al., 2023) and Graph-of-Thought (GoT) (Besta et al., 2024) introduce branching structures to explore multiple reasoning pathways. Cumulative Reasoning (CR) (Zhang et al., 2023) orchestrates an iterative process involving different specialized LLMs fulfilling roles such as proposer, verifier, and reporter. However, these methods often rely on external control mechanisms or multiple models, complicating both training and deployment.\nIn this paper, we introduce Diagram of Thought (DoT), a framework that models logical deduction as the construction of a directed acyclic graph (DAG) within a single LLM. DoT incorporates natural language critiques, offering richer, more informative feedback than binary signals. This allows the"}, {"title": "Related Work", "content": "Chain-of-Thought (CoT) (Wei et al., 2022) introduced the concept of enabling LLMs to generate intermediate reasoning steps, effectively allowing the model to \u201cthink aloud\". This linear decomposition of reasoning tasks has been shown to improve performance on complex problem-solving tasks by making the latent reasoning process explicit. However, the linear nature of CoT may not adequately capture the non-linear and iterative aspects of human reasoning.\nTree-of-Thought (ToT) (Yao et al., 2023) extends CoT by allowing the exploration of multiple reasoning paths in a tree structure, accommodating branching possibilities and enabling backtracking. Graph-of-Thought (GoT) (Besta et al., 2024) further generalizes this idea by representing reasoning processes as graphs, capturing more complex relationships between reasoning steps. These approaches, while flexible, often require managing multiple reasoning trajectories, which can be computationally intensive and challenging to implement within a single LLM framework. Cumulative Reasoning (CR) (Zhang et al., 2023) introduces a collaborative reasoning process involving multiple specialized LLMs, each fulfilling a distinct role-proposer, verifier, and reporter. This framework mirrors human problem-solving by iteratively building upon previous propositions and validations but adds complexity by involving multiple models and external orchestration.\nDiagram of Thought (DoT) distinguishes itself by integrating the strengths of these approaches into a unified framework within a single LLM. By modeling reasoning as the construction of a DAG, DoT captures the non-linear and iterative aspects of logical deduction while maintaining computational efficiency. The use of auto-regressive next-token prediction enables the model to internally manage role transitions and reasoning steps, streamlining the reasoning process and simplifying implementation."}, {"title": "Diagram of Thought", "content": "The Diagram of Thought (DoT) framework models logical reasoning as the cumulative construction of a directed acyclic graph (DAG) within a single LLM. This DAG consists of nodes representing propositions, critiques, refinements, and verifications, and edges denoting logical relationships or dependencies between them. The acyclic nature ensures the reasoning process progresses without circular dependencies, mirroring well-founded logical deduction."}, {"title": "Roles and Next-Token Prediction", "content": "Within the DoT framework, the LLM internally manages three roles using auto-regressive next-token prediction with role-specific tokens:\n\u2022 Proposer (\\<proposer>): Generates propositions or reasoning steps, contributing new nodes to the DAG.\n\u2022 Critic (\\<critic>): Evaluates propositions, identifying errors, inconsistencies, or logical fallacies, and adds critique nodes.\n\u2022 Summarizer (\\<summarizer>): Synthesizes validated propositions into a coherent chain-of-thought, effectively performing a topological sort of the DAG to produce the final reasoning output.\nThese roles are delineated within the model's output through the use of special tokens. The LLM transitions between these roles seamlessly during generation, leveraging its auto-regressive capabilities to predict the next token based on the context."}, {"title": "Reasoning Process", "content": "The reasoning process unfolds as follows:\n1. The Proposer introduces a proposition, adding a node to the DAG.\n2. The Critic evaluates the proposition, either validating it or providing a critique. If a critique is provided, a new node is added, and an edge is established between the proposition and the critique.\n3. Based on the critique, the Proposer generates a refined proposition, represented as a new node in the DAG."}, {"title": "Topos-Theoretic Formalization of DoT", "content": "The Diagram of Thought (DoT) framework can be formalized using Topos Theory, a branch of category theory that provides a unifying framework for mathematics and logic (MacLane & Moerdijk, 2012). By leveraging the structures of toposes and PreNet categories, we can represent the reasoning processes in DoT, ensuring logical consistency and soundness."}, {"title": "Mathematical Foundations", "content": "A topos $\\mathscr{E}$ is a category that behaves like the category of sets but with additional structure supporting internal logic. Specifically, a topos has all finite limits and colimits, exponentials, and a subobject classifier $\\Omega$, which encapsulates the notion of truth values within the internal logic (Lambek & Scott, 1988).\nIn the DoT framework, propositions, inferences, and critiques are represented within the internal language of a topos $\\mathscr{E}$. Each proposition is modeled as a subobject $P \\rightarrow 1_{\\mathscr{E}}$ of the terminal object, representing the conditions under which the proposition holds true. Logical relationships and inferences between propositions are depicted as morphisms in $\\mathscr{E}$. An edge from proposition $P$ to proposition $Q$ corresponds to a morphism $f : P \\rightarrow Q$, indicating that $P$ logically entails $Q$ within the internal logic.\nCritiques are represented as morphisms to the subobject classifier, $c_P : P \\rightarrow \\Omega$, assigning truth values to propositions and evaluating their validity. Refinements of propositions based on critiques are modeled by morphisms $r: P \\rightarrow P'$, representing the transformation or correction of the original proposition."}, {"title": "Iterative Reasoning, Colimits, and PreNet Categories", "content": "The cumulative and dynamic nature of iterative reasoning in DoT is captured using the concepts of colimits and PreNet Categories from category theory. A diagram in a topos $\\mathscr{E}$, represented as a functor $D: \\mathscr{I} \\rightarrow \\mathscr{E}$, models the reasoning DAG constructed during the reasoning process, where $\\mathscr{I}$ is an index category reflecting the structure of the DAG.\nThe colimit of the diagram D, denoted $\\varinjlim D$, aggregates all propositions, critiques, refinements, and inferences into a single coherent object within $\\mathscr{E}$. This aggregation corresponds to the cumulative reasoning process in DoT, ensuring that all valid reasoning steps are incorporated into the final conclusion. The role of the Summarizer (\\<summarizer>) in the DoT framework is analogous to taking the colimit in category theory. Just as the summarizer synthesizes verified propositions into"}, {"title": "Ensuring Logical Consistency and Soundness", "content": "The topos-theoretic formalization, combined with PreNet categories, ensures that the reasoning process in DoT is logically consistent and sound. The internal logic of the topos allows for precise manipulation of logical propositions, with morphisms representing valid logical inferences. The acyclic structure of the DAG, reflected in the diagram $D$, prevents circular dependencies, aligning with the requirement for well-founded logical deductions.\nBy aggregating propositions and inferences via colimits in the context of PreNet categories, we coherently assemble the cumulative reasoning process, incorporating all valid inferences without contradictions. This formalism guarantees that the final reasoning output is logically consistent and derived through valid inferences, even when concurrent reasoning paths are considered."}, {"title": "Implications for the DoT Framework", "content": "Formalizing the DoT framework within Topos theory and PreNet categories provides a robust mathematical foundation for the reasoning processes modeled by DoT, ensuring precision and rigor in the representation of logical deductions. By integrating critiques as morphisms to the subobject classifier and modeling concurrent reasoning paths with PreNet categories, the feedback mechanism and dynamic aspects of reasoning are embedded directly into the logical framework.\nThis formalism ensures that the reasoning process is both consistent-free of contradictions-and complete, meaning all valid inferences are included, which is crucial for reliable reasoning in LLMs. The correspondence between the colimit and the summarizer role highlights how category theory can inform the design of reasoning mechanisms in LLMs, bridging the gap between theoretical concepts and practical implementation."}, {"title": "Conclusion", "content": "In this paper, we presented the Diagram of Thought (DoT) framework, which models iterative reasoning in large language models as the construction of a directed acyclic graph within a single LLM. By integrating propositions, critiques, refinements, and verifications into a unified DAG structure, DoT captures the complexities of logical deduction beyond linear or tree-based models. The framework leverages auto-regressive next-token prediction with role-specific tokens to manage role transitions seamlessly, enabling the model to generate detailed reasoning processes without external intervention.\nWe further provided a topos-theoretic formalization of the DoT framework, offering a mathematical foundation that clarifies the relationship between the reasoning processes and categorical logic. By representing propositions, inferences, and critiques within the structures of a topos, we ensured logical consistency and soundness in the reasoning process. This theoretical grounding validates the efficacy of DoT in enhancing the reasoning capabilities of large language models and bridges the gap between practical implementation and mathematical rigor."}]}