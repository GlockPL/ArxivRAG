{"title": "Geo-LLaVA: A Large Multi-Modal Model for Solving Geometry Math Problems with Meta In-Context Learning", "authors": ["Shihao Xu", "Yiyang Luo", "Wei Shi"], "abstract": "Geometry mathematics problems pose significant challenges for large language models (LLMs) because they involve visual elements and spatial reasoning. Current methods primarily rely on symbolic character awareness to address these problems. Considering geometry problem solving is a relatively nascent field with limited suitable datasets and currently almost no work on solid geometry problem solving, we collect a geometry question-answer dataset by sourcing geometric data from Chinese high school education websites, referred to as GeoMath. It contains solid geometry questions and answers with accurate reasoning steps as compensation for existing plane geometry datasets. Additionally, we propose a Large Multi-modal Model (LMM) framework named Geo-LLaVA, which incorporates retrieval augmentation with supervised fine-tuning (SFT) in the training stage, called meta-training, and employs in-context learning (ICL) during inference to improve performance. Our fine-tuned model with ICL attains the state-of-the-art performance of 65.25% and 42.36% on selected questions of the GeoQA dataset and GeoMath dataset respectively with proper inference steps. Notably, our model initially endows the ability to solve solid geometry problems and supports the generation of reasonable solid geometry picture descriptions and problem-solving steps. Our research sets the stage for further exploration of LLMs in multi-modal math problem-solving, particularly in geometry math problems.", "sections": [{"title": "1 Introduction", "content": "There has been an increased interest in using deep learning models, especially LMMs, for addressing computer vision challenges recently. Aligning image adapters with large language models has achieved remarkable success in image captioning and visual question answering (VQA), highlighting their powerful reasoning and visual understanding capabilities [8]. Despite their accomplishments in these areas, there has been limited investigation into utilizing LLMs for more complex multi-modal math problems, particularly geometry-related ones.\nThe debate between symbolic and probabilistic approaches in mathematical reasoning persists. Traditionally, solving geometry problems involves analyzing diagrams and texts, converting them into logical expressions using formal symbolic language, and applying predefined geometry theorems to find solutions [11, 33]. Alternatively, geometry problem-solving can be viewed as text generation with multi-modal input, which is more generalized and applicable to a broader range of mathematical problems, including trigonometry and vector graphics. By examining probabilistic approaches, we can better understand their strengths and limitations, leading to more effective strategies for solving geometry problems.\nCurrent Large Multi-modal Models (LMMs) have shown promising capabilities in visual understanding and question-answering tasks, as demonstrated by models such as BLIP-2 [20], LLaVA [22], Flamingo [3], MiniGPT4 [34], and InstructBLIP [12]. However, these models still lack a deep comprehension of geometry images, which is crucial for solving geometry problems. Additionally, existing small language models often lack the mathematical reasoning abilities to solve complex math problems effectively.\nIn this paper, we propose a solution to the challenges of multi-modal math problem-solving by introducing an LLM framework called Geo-LLaVA. The main contributions of this paper include:\n\u2022 We form a geometry question-answer dataset, GeoMath, with reasoning steps from Chinese high school education websites and expand the dataset by collecting more data from existing datasets such as GeoQA+ [11], Unigeo [10], and PGPS9K [33], and creating reasoning steps for them.\n\u2022 We employ a new LLM framework named Geo-LLaVA with around 13 billion parameters. It can effectively generate reasoning steps and answers, which is the first model exploring both plane and solid geometry problems."}, {"title": "2 Related Work", "content": "Meta-Training Approaches. The general issue of meta-training [28], which encompasses few-shot learning, has been studied for numerous years. Recently, meta-training has emerged as a significant technique in machine learning. Using prior knowledge, it aims to create models that can swiftly adapt to new tasks with minimal data. meta-training is particularly pertinent in geometry problem-solving, where the diversity of problems can vary greatly. The most recent meta-training models, such as MAML [15], Hypernetworks [18], and [27], have shown promise in rapidly adapting to new tasks with few-shot learning capabilities.\nMulti-Modal Large Language Model. Concurrently, the success of LLMs has inspired investigations into vision-language interaction, resulting in the development of multi-modal large language models (MLLMs) [1, 7, 12, 20, 22, 32]. These models have demonstrated remarkable abilities in generating detailed descriptions and engaging in dialogue based on visual inputs. Nonetheless, we observe that even the most advanced MLLMs struggle with resolving geometric problems using diagrams and figures."}, {"title": "3 Method", "content": "The Geo-LLaVA model, illustrated in Figure 1, consists of a retrieval network and an LMM backbone. The retrieval network's role is to fetch similar questions and their solutions as in-context samples during the training and inference phases. In the following section, we offer a comprehensive overview of the design process for our retrieval network. Next, we delve into our method of fine-tuning the model using image captioning, question-answering, and geometry math-solving datasets through Meta in-context learning. Lastly, we will describe how we have integrated a multi-modal chain of thoughts (CoT) during the inference phase to boost the model's performance even further."}, {"title": "3.1 Retrieval Network", "content": "In this study, similar to CLIP [26], we implemented a dual-tower network framework for retrieval tasks. Specifically, the pre-trained ViT-L-14 [14] and Bert [13] (Bert-base-uncased) models were applied as the image and language encoders, respectively. We integrated two adapter layers into each encoder to ensure compatibility between these encoders. These adapter layers comprise three linear layers with ReLU activation functions, designed to harmonize the embedding dimensions of both encoders.\nThe Bert model [13] was chosen as the language encoder due to its strong performance in natural language processing tasks. Importantly, we transformed math-specific tokens absent in the BERT pre-trained vocabulary into words (e.g., \u25b3 \u2192 triangle, \u22a5 \u2192 perpendicular to) during the preprocessing stage. We believe the BERT model can effectively grasp the meaning of inputs related to geometric problems. Similarly, the ViT-L-14 [14] model was selected as the image encoder for its outstanding performance in image recognition tasks. This model employs a transformer-based architecture, which is particularly adept at processing visual information. However, the pre-trained ViT model may not generalize well to geometric math images. As a result, we retrained the parameters of the two adapter layers and the ViT model from scratch using question-image pairs with the InfoNCE loss, a contrastive learning technique recognized for its efficacy in training neural networks for retrieval tasks. This loss function encourages the model to learn meaningful representations of the input question and the corresponding image, promoting accurate information retrieval."}, {"title": "3.2 LMM backbone", "content": "This study utilized the pre-trained LLaVA1.5-13B [22] as the LMM backbone. This model leverages the renowned LLAMA-2 [29] for advanced language processing tasks and incorporates the CLIP [25] visual encoder ViT-L/14 [14] for sophisticated visual comprehension. The integration involves a Multi-Layer Perceptron (MLP) based vision-language connector that aligns the outputs of the vision encoder with the language model. This alignment is crucial as it significantly enhances the model to handle and understand multi-modal data effectively."}, {"title": "3.3 Datasets for Multi-Modal Geometric Concepts and Reasoning", "content": "To address the limitations of existing models in understanding and reasoning about multi-modal geometric concepts, we developed three specialized geometry datasets:\n\u2022 GeoMath-IC (Image-Context): This dataset includes images paired with simple yet comprehensive descriptions and aims to bridge the gap between visual inputs and textual descriptions in geometric concepts.\n\u2022 GeoMath-QA (Question-Answer): This dataset focuses on providing questions with detailed reasoning steps. The questions are designed to challenge the model's understanding and reasoning capabilities regarding geometric concepts.\n\u2022 GeoMath-Meta: This dataset includes a range of geometry problems that require the model to generalize from its learning on GeoMath-IC and GeoMath-QA.\nThese datasets were subsequently used to fine-tune the model using Low-Rank Adaptation (LoRA) [19]. Detailed information about the dataset creation process and examples can be found in Section 4.2.1.\nWe adopted the input format from the original Flamingo model, which efficiently integrates visual and linguistic elements to enhance their synergistic interaction. This structured input format involves specific templates and prompts that guide the model in understanding the context and relationships between the visual and textual components."}, {"title": "3.4 Enhancing In-Context Learning", "content": "To further improve the model's in-context learning capabilities, especially for smaller models, we explored using meta-training [24]. This approach enhances the performance of the model by providing relevant context during the fine-tuning stage. The procedure involves the following steps: 1) Contextual Retrieval: For each input sample, we retrieved the K most similar samples from the training data, ensuring that the input sample itself is excluded, where K is set to 1 in this paper. This retrieval is based on semantic similarity metrics, ensuring the context is highly relevant. 2) Concatenation and Fine-Tuning: The retrieved texts and corresponding images are concatenated with the input sample. This concatenated form is used to fine-tune the LMM, aligning it better with the reasoning required for tasks. Since the pre-trained LLaVA only supports single-image input, we vertically merge K images into a single image.\nThe detailed methodologies and the careful orchestration of these components can be referenced throughout the underlying sections of the study, particularly in Section 4.2.1 and Figure 2."}, {"title": "4 Experiment", "content": "In this study, we collected about 10K solid geometry multimodal QA datasets from the 21st-century education website in China, named GeoMath dataset. All Chinese contents in these datasets are"}, {"title": "4.1 Dataset", "content": "automatically translated to English using ChatGPT3.5. The detailed statistics of these three datasets are shown in Table 1. In addition, to supplement the data of solid geometry, we formed the geometry data from two existing datasets (GeoQA+ [9] and PSDK9K), which include images of plane geometry as well as questions and answers."}, {"title": "4.2 Setup Details", "content": "4.2.1 Data Augmentation. Paraphrasing by LLMs can generate a more diverse set of training examples and has been widely used for data augmentation. Similarly, we adopt GPT3.5 [2] for image caption and question-answering samples followed by a translation from Chinese to English and employ text rewriting to increase variety. We utilize an LLM to rephrase the input text in 5 different ways, resulting in a six times larger sample size for image caption and QA. For the GeoMath-Meta dataset, the retrieval model selects the top 5 samples with the highest similarity to construct the data for Metatraining. This ensures consistency in the quantity of the final samples and QA pairs.\n4.2.2 Training settings. We select LLaVA-1.5 [22], a large multi-modal model that combines the strengths of LLaMA-2 [29] and fine-tuned retrieval model [25], for our experiments. All experiments are conducted with consistent parameter settings during the LORA fine-tuning phase. Specifically, we use a learning rate of 2 \u00d7 10-4 with a cosine learning rate scheduler and train the model for 5 epochs. The maximum token generation length is 2048. The batch size per GPU is 4, and we use gradient accumulation steps set to 4. We initially evaluate the experiments on the validation set to identify the best results, which are subsequently tested on the test set."}, {"title": "4.3 Experiment results", "content": "Table 2 summarizes the main results on GeoQA+ and GeoMath datasets. Three small-size LMMs (G-llava [16], OpenFlamingo [5] and LLaVA [22]) for both zero-shot and finetuning and two extremely large LMMs (Bard [17] and ChatGPT-4V [1]) are chosen as baseline models. We finetuned the model 5 times to calculate the mean and standard deviation of the evaluation metric.\nThe experiment results, summarized in Table 2, demonstrate the performance of various models across the GeoQA+ and GeoMath datasets, alongside an ablation study exploring the incremental application of techniques in our model. The proposed Geo-LLaVA-13B model showed significant improvements compared to the GPT-4V and Bard through the sequential addition of the GeoMath-IC, GeoMath-QA, and GeoMath-Meta datasets, with final accuracies of 65.25% and 42.36% on the respective datasets.\nThe results indicate that the proposed Geo-LLaVA-13B model outperforms several other models in solving geometry mathematics problems, particularly when using a combination of the GeoMath-IC, GeoMath-QA, and GeoMath-Meta datasets on the solid geometric problems. The step-by-step improvements highlight the effectiveness of sequentially incorporating these datasets and techniques. Additionally, the model's performance further benefits from ICL, suggesting that providing few-shot examples during inference significantly enhances its accuracy."}, {"title": "5 Conclusion", "content": "In conclusion, this paper presents a novel approach to address the challenges inherent in multi-modal math problem-solving on geometry. Our research emphasizes the pivotal role of integrating meta-learning into models, enabling them to accurately interpret and reason through complex visual and textual inputs-an essential capability for resolving geometric problems effectively. Recognizing the limitations posed by the small size and the absence of reasoning steps in current geometry datasets, we have developed a pioneering dataset called GeoMath. This dataset amalgamates reasoning steps drawn from pre-existing datasets and materials sourced from a Chinese high school educational website, thereby filling a critical gap in available resources.\nThis study not only provides significant contributions to the domain of multi-modal geometry problem-solving but also paves the way for future research endeavors. The application of LLMs and LMMs to this domain promises to unlock new potential and methodologies. The development of GeoMath stands as a notable milestone, offering robust strategies for addressing the complexities of geometry problems. Future research could explore refining these models further, expanding the dataset with additional problem types, and investigating their applicability across various educational contexts, potentially transforming how multi-modal mathematical reasoning is approached in both academic and practical settings."}]}