{"title": "Crystal Structure Generation Based On Material Properties", "authors": ["Chao Huang", "JiaHui Chen", "HongRui Liang", "ChunYan Chen", "Chen Chen"], "abstract": "The discovery of new materials is very important to the field of materials science. When researchers explore new materials, they often have expected performance requirements for their crystal structure. In recent years, data-driven methods have made great progress in the direction plane of crystal structure generation, but there is still a lack of methods that can effectively map material properties to crystal structure. In this paper, we propose a Crystal DiT model to generate the crystal structure from the expected material properties by embedding the material properties and combining the symmetry information predicted by the large language model. Experimental verification shows that our proposed method has good performance.", "sections": [{"title": "1 Introduction", "content": "Material science plays a crucial role in the development of modern technology and industrial production, with high-performance materials serving as the foundation for the manufacture of various advanced equipment. The generation of crystal structures is a central process driving the advancement of material science. As periodic materials, crystals are widely used in many important fields, including catalysts, alloys, and molds.\nIn recent years, data-driven methods have made great progress in the task of crystal structure generation (Nouira et al. (2018); Hoffmann et al. (2019); Hu et al. (2020); Ren et al. (2022)). Among various methods, diffusion model-based methods have been"}, {"title": "2 Related works", "content": "Diffusion models. Diffusion modeling is a powerful generative model that generates data by simulating a gradual process of introducing noise and then learning how to reverse the process (Yang et al. (2024)). This approach has yielded significant results in several computer vision tasks such as image generation, image super-resolution, and image restoration. Subclasses of diffusion models include denoising diffusion probabilistic model (DDPM), noisy conditional score network (NCSN), and stochastic differential equation (SDE). The DDPM (Ho et al. (2020)) approach involves a forward propagation and a backward propagation. The forward process can be concluded as:\n$q(x_t/x_{t-1}) = N(x_t; \\sqrt{1 \u2013 \\beta_t}x_{t-1}, \\beta_tI)$,\n(1)\nthe backward process can be concluded as:\n$P_\\theta(x_{t-1}|X_t) = N(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t,t))$,\n(2)\nand the loss function is:\n$L(\\theta) = E_{x_0\\sim p_{data}}E_{t\\sim [1,T]} \\frac{1}{\\sigma_t^2} ||\u20ac \u2013 \u20ac_\\theta (\\sqrt{\\bar{a_t}}x_0 + \\sqrt{1 \u2013 \\bar{a_t}} \\epsilon_t)||^2_2$,\n(3)\nwhere N denotes the normal distribution, $\\beta_t$ is the noise level parameter, $a_t$ and $\\bar{a_t}$ are the coefficients associated with the noise level, e is the noise, \u0454\u0189 is the noise predicted by the model, and $ut$ and $Et$ are the mean and covariance predicted by the inverse process, respectively.\nThe NCSN (Song and Ermon (2019)), is also utilized in the crystal structure generation task. The diffusion process and loss (Song and Ermon (2020)) can be summarized as follows:\n$p(x_t/x_0) = N_w (x_t|x_0, \u03c3^2I)$,\n(4)\n$\\frac{1}{2L}\\sum^L_{i=1}E_{p_{data}(x_0)E_{p_{\\sigma_i(x_t|x_0)}} \\frac{||x_t - x_0||^2}{\\sigma_i^2} + ||s_{\\theta}(x_t, \\sigma_i)||^2$,\n(5)\nwhere $E_{p_{data} (x_0)}$ denotes the expectation under the data distribution $p_{data}$, i.e., averaged over all possible data samples $x_0$, and $E_{p_{\\sigma_i}(x_t|x_0)}$ denotes the expectation under the noise distribution $p_{\\sigma_i}$ given a data sample $x_0$, i.e., averaging over all possible noise perturbations $x_t$. In addition, \u03c3\u00a1 denotes the i-th noise level. As for the $s_\\theta(x_t, \\sigma_i)$, it denotes the score network, parameterized by 0, which estimates the score (gradient) given the noisy data $x_t$ and the noise level \u03c3\u2081. The goal of this loss function is to train the score network $s_\\theta$ to be able to accurately estimate the gradient of the data distribution so that the original data can be recovered from the noise during the generation process. By minimizing this loss function, NCSN can learn how to generate high quality samples from noisy data.\nLarge language model. Traditional language model like the T5 (Raffel et al. (2020)) and BERT (Devlin et al. (2018)) models have demonstrated certain performance in the field of crystallography. Several vertical domain models based on T5 and BERT (Rubungo et al. (2023);Das et al. (2023)) have been used to encode crystal structure"}, {"title": "3 Our method", "content": "Crystal symmetry information is very important in the description of crystal geometry. a part of methods consider reference space group and wyckoff position as input when generating crystal structure, and get good results. However, for some crystal structures with high symmetry, the fixation of symmetry information can already determine most of the crystal parameters. Moreover, compared with establishing the connection between symmetry information and crystal structure, establishing the"}, {"title": "3.1 Large language model for crystal symmetry information prediction", "content": "The open source GLM4 large language model is already close to the world's strongest models Gemini Ultra and GPT-4. Its GLM4-9B version has shown superior performance over Llama-3-8B in semantic, mathematical, reasoning, code, knowledge and other aspects of the data set evaluation, and has better multilingual learning ability. Therefore, we chose GLM4-9b as the base model for training.\nSince the GLM4-9B model has been pre-trained on a large number of text data, including the text of materials science, it has already understood a lot of basic knowledge of materials science, including the characteristics of individual atoms, the characteristics of spatial groups in crystal structures, and the meaning of wyckoff positions.\nTherefore, we considered using the prompt engineering to create datasets and fine-tune the GLM4-9B model to allow the large language model to learn the correspondence between atomic properties, material properties and crystal symmetry information. The model prompt word is \"output a crystal structure space group and wyckoff position based on the type of input element and the required properties.' Then, the input text information contains atomic properties and required material properties, and the output answer generates the required result in a way similar to the chain of thought: first find the most suitable space group, then get the candidate wyckoff position based on the space group, and finally select the appropriate wyckoff position."}, {"title": "3.2 Crystal structure diffusion model with transformers", "content": "In this section, we mainly introduce the designed crystal structure DiT model, which is responsible for receiving the symmetry information output from the large language model and generating the expected crystal structure according to the initial input atoms and material properties. The overall structure of the model is shown in Figure 3.Our model is mainly modified from the DiffCSP++Jiao et al. (2024b) model. This method mainly introduces symmetry information in the decoding part of the model to make the crystal structure the constraints of space group and wyckoff position after diffusion. We followed this idea and the edge feature extraction method of this method, and improved the overall network's ability to fit lattices and element coordinates by adding a crystal transformer block to the decoding module of the neural network. In particular, we designed a crystal multi-head attention module to fuse crystal features and expected material properties.The feature fusion module designed as\n$F_{ij} = \\varphi_m(h_i, h_j, \\varphi_h(k, \\psi_{FT}(f_j \u2013 f_i)))$\n(6)\n$F^{0} = F^{n} + \\varphi_c(F^{n}, \\sum_{j=1}^{N}F)$\n(7)\nwhere $qm$ and $qh$ are MLPs,and $\u03c8_{FT}$ : (\u22121,1)3 \u2192 [\u22121,1]3\u00d7K is the Fourier transforma-tion with K bases relative fractional coordinate fj \u2013 fi. K is the unique O(3)-invariant representation of L. F, Fn and F\u00ba Respectively represent the extracted edge features, node features and crystal features of the network.The node features are obtained by the embedding module in Figure 3(b).h\u2081 and hj calculated from node features.\nThe attention module design is as\n$head_{i} = Attention(F^{l}W_{i}^{Q}, \\varphi_k(F^{l}W_{i}^{K}, PembW_i^{K}), \\varphi_v(F^{l}W_{i}^{V}, PembW_i^{V})))$\n(8)"}, {"title": "4 Experiments", "content": "In this paper, we trained and tested two material properties: band gap and formation energy.In the large language model fine-tuning, we fine-tuned both performances in a separate way, and the fine-tuned models are called GLM4-9B(BG) and GLM4-9B(FM). In Crystal DiT, we trained two versions of the model, the Crystal DiT version with the embedding band gap as a condition is Crystal DiT(BG), and the version with the embedding formation ability as a condition is Crystal DiT(FM).\nCrystal symmetry information prediction.In order to fine-tune the GLM4-9B large model, we crawled 152,823 material datasets from the Materials Project(2024.10.12), and obtained the space group and wyckoff position of each material in the dataset through the SpacegroupAnalyzer class in pymatgen and the pyxtal, and made a prompt engineering and constructed a new dataset in the way of subsection 3.1. After removing some data with too large atom numbers, the new dataset was constructed with a training test and validation set of 8:1:1, and the accuracy of the model-generated data was measured by Rouge-1, Rouge-2, and Rouge-1.To our knowledge, there are relatively few methods for generating symmetric information from material properties via autoregressive methods or large language models, so there is no baseline for comparison in this part.\nCrystal structure generation.We use the SpacegroupAnalyzer class of the pymatgen Ong et al. (2013) and the pyxtal to obtain the space group and wyckoff position of each material in the test dataset, and obtain the corresponding material properties. Inputting the above data into the Crystal DiT model, and get a crystal structure.\nFor each generated crystal structure, we calculate the match rate through the Structure-Matcher class in pymatgen, with thresholds stol=0.5, angle tol=10, ltol=0.3.The match rate represents the ratio of matched structures relative to the total number within the testing set, and the RMSD is averaged over the matched pairs, and normalized by $\\sqrt{V/N}$,where V is the volume of the lattice, N is the number of atom.We compared our approach with two classes of methods. The first class is the optimization-based methods including Random Search (RS), Bayesian Optimization (BO), and Particle Swarm Optimization (PSO). The second class considers three types of generative methods. P-cGSchNet (Gebauer et al. (2022)), CDVAE (Xie et al. (2021)) and DiffCSP++ (Jiao et al. (2024b)). The data for other methods are from DiffCSP++."}, {"title": "5 Conclusion", "content": "In this work, we propose Uni-MDM, a crystal generation method based on large language models and DiT, which effectively integrates material properties and space group constraints. We divide the entire crystal generation process into the prediction of symmetry information and the diffusion of crystal structure, and introduce material property constraints in both processes to ensure that the generated crystal structure meets expectations. Experimental results on the MP dataset show that our method has stable crystal structure generation results."}]}