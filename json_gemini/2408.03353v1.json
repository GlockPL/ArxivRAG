{"title": "Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning", "authors": ["Xiaozhou Ye", "Kevin I-Kai Wang"], "abstract": "Human Activity Recognition (HAR) plays a crucial role in various applications such as human-computer interaction and healthcare monitoring. However, challenges persist in HAR models due to the data distribution differences between training and real-world data distributions, particularly evident in cross-user scenarios. This paper introduces a novel framework, termed Diffusion-based Noise-centered Adversarial Learning Domain Adaptation (Diff-Noise-Adv-DA), designed to address these challenges by leveraging generative diffusion modeling and adversarial learning techniques. Traditional HAR models often struggle with the diversity of user behaviors and sensor data distributions. Diff-Noise-Adv-DA innovatively integrates the inherent noise within diffusion models, harnessing its latent information to enhance domain adaptation. Specifically, the framework transforms noise into a critical carrier of activity and domain class information, facilitating robust classification across different user domains. Experimental evaluations demonstrate the effectiveness of Diff-Noise-Adv-DA in improving HAR model performance across different users, surpassing traditional domain adaptation methods. The framework not only mitigates distribution mismatches but also enhances data quality through noise-based denoising techniques.", "sections": [{"title": "I. INTRODUCTION", "content": "Human Activity Recognition (HAR) is a critical component of human-computer interaction, ubiquitous computing, and the Internet of Things. The primary objective of HAR is to accurately classify human activities using sensor data and contextual information [1]. Despite extensive research efforts, developing an effective HAR model remains challenging. A significant issue in current HAR methodologies, particularly those dealing with time series sensor data, is the presumption that training and testing data originate from identical distributions. This assumption is frequently invalidated by the diversity of real-world data and the occurrence of out-of-distribution (o.o.d.) instances [2]. This discrepancy, caused by factors such as sensor heterogeneity [3], evolving data patterns [4], varying sensor layouts [5], and individual behavioral differences [6], severely impairs the generalizability of HAR models. Our research specifically addresses the o.o.d. challenge in sensor-based HAR, focusing on the cross-user HAR problem arising from individual behavioral variances, commonly encountered in healthcare applications.\nTransfer learning and domain adaptation [7] present promising solutions for bridging the data distribution gap between different domains. In cross-user Human Activity Recognition (HAR), these approaches aim to leverage knowledge from a source domain (e.g., activities of one group of users) to enhance performance in a target domain (e.g., activities of a different group of users). Techniques such as Maximum Mean Discrepancy [8] and Optimal Transport [6] are utilized to align domain features, while more advanced methods like Deep Generative Domain Adaptation [9] and Deep Conditional Adaptation Network [10] focus on deeper, non-linear alignments. Recent advancements in generative modeling have incorporated diffusion models into domain adaptation tasks, showcasing their potential to bridge the gap between source and target domains. These models facilitate smooth, controlled transitions while preserving critical data features, as demonstrated by the Domain-Adaptive Diffusion method [11]. Moreover, their capacity to generate high-fidelity samples enhances accurate domain translation and feature adaptation, as evidenced by the Data Augmentation with Diffusion Models [12]. Moreover, IoT sensor data such as human activity recognition data often contains significant noise due to various environmental and operational factors. Diffusion models, which simulate the process of information spreading or diffusing through a system, are highly effective at noise reduction. They iteratively refine the sensor data, making it smoother and more accurate by filtering out random fluctuations and disturbances. This denoising capability enhances the quality of the data, leading to more reliable activity recognition [13]. By applying diffusion models, the integrity and quality of sensor data can be significantly improved for better domain adaptation.\nHowever, existing diffusion-based domain adaptation methods often neglect the crucial role of noise in improving domain adaptation, which can carry valuable information in both the forward diffusion process and the reverse diffusion denoising process. To address these overlooked aspects, we propose a novel approach that harnesses the potential of noise within diffusion models for domain adaptation, termed Diffusion-based Noise-centered Adversarial Learning Domain Adaptation (Diff-Noise-Adv-DA). Our method integrates noise-centered learning into the diffusion process, enabling the model to develop robust activity classification models that generalize effectively across different user domains by enhancing the utilization of noise. This method transforms the forward diffusion and reverse denoising processes into adversarial learning phases, aligning feature distributions between source"}, {"title": "2) Innovative Generative Model Architecture", "content": "We introduce an innovative generative model architecture, incorporating unique constraint conditions and network structures that facilitate data distribution alignment between source and target domains. This enhances the generalization capability of the diffusion model and its classification performance."}, {"title": "3) Noise-centered Adversarial Learning", "content": "We develop a unique noise-centered adversarial learning mechanism that transforms the noise in both forward and reverse diffusion processes into critical information carriers for classification tasks. By integrating activity and domain class information into the noise, we enable the model to extract and leverage embedded information, significantly enhancing the robustness and adaptability of HAR models across different user domains."}, {"title": "II. RELATED WORK", "content": "The paper is organized as follows: it starts with a review of related work in sensor-based cross-user HAR and state-of-the-art methods in transfer learning and domain adaptation. Next, it delves into the specifics of the Diff-Noise-Adv-DA method, detailing its design principles and emphasis on noise-centered adversarial domain adaptation. Following this, we describe our experimental setup and compare Diff-Noise-Adv-DA with existing methods, highlighting its effectiveness in leveraging noise information within diffusion models. The paper concludes with a discussion of our findings and suggestions for future research directions in this field. The Diff-Noise-Adv-DA implementation is available at https://github.com/helloworld1973/diffusion_models."}, {"title": "A. Sensor-based Cross-user Activity Recognition", "content": "Sensor-based Human Activity Recognition (HAR) has emerged as a key component in the field of ubiquitous computing, providing deep insights into human behaviors by analyzing sensor data and contextual clues. This technology employs a variety of sensor types, each suited to different contexts, and can be grouped into five primary categories: smartphones and wearables, ambient sensors, device-free sensing, vision-based systems, and miscellaneous sensor types, as indicated in several studies [2] [14]. Our research specifically focuses on the use of wearable sensors for HAR.\nIn machine learning, the problem of HAR using sensors is viewed as a challenge in time series classification [15]. Several classification techniques have been suggested, including Bayesian networks, Support Vector Machines, and Hidden Markov Models (HMM). Additionally, deep learning models have shown impressive results across many tasks. In the context of HAR, these deep learning methods [16] can automatically learn to identify and extract relevant features from extensive datasets. However, these methods typically rely on the assumption that both training and testing data share the same distribution, conforming to the independent and identically distributed (i.i.d.) assumption [2]. Yet, this assumption is often violated in practical applications, where training and testing data sets usually differ significantly, falling into what is known as out-of-distribution (o.o.d.) scenarios [17]. Our study explores the challenges of sensor-based HAR in these o.o.d. conditions."}, {"title": "B. Transfer Learning and Domain Adaptation", "content": "The issue of 0.0.d. in sensor-based HAR presents itself in multiple ways. Firstly, there could be discrepancies in data from different sensors, which might differ in format and distribution due to varying sensor types, platforms, manufacturers, and modalities [3]. Secondly, data patterns can change over time-a phenomenon known as concept drift [4]. This might be observed in modifications to walking patterns due to health changes. Thirdly, there are substantial variations in behavior among individuals [6], such as differences in walking speeds. Finally, the specific placement of sensors on different body parts can affect data distributions [5]. Our research primarily targets the challenges posed by individual behavioral variations in these 0.0.d. conditions in HAR.\nTransfer learning and domain adaptation have been widely studied to improve model generalization across different domains. Methods like adversarial training, feature alignment, and fine-tuning have shown promise in reducing domain shifts. This paper [18] introduces a method for identifying transferable parameters in deep unsupervised domain adaptation (UDA) networks. It focuses on optimizing the source hypothesis by including an unsupervised objective function to ensure learning of domain-invariant information. The method determines important parameters using gradient flows and weights, which are crucial for learning domain-invariant features. This work [19] presents a cross-domain contrastive learning framework for UDA, using contrastive loss to align the distributions of source and target domains. By bringing similar instances closer and pushing dissimilar ones apart, the framework learns domain-invariant representations. This paper [20] explores the use of Vision Transformers for UDA, proposing the Transferable Vision Transformer (TVT). TVT uses self-attention mechanisms to learn domain-invariant features, enhancing generalization across domains. Extensive experiments show that TVT outperforms traditional convolutional neural networks in domain adaptation tasks. The authors [21] propose AdaGCN, a graph transfer learning framework based on adversarial domain adaptation with graph convolutional networks (GCNs). AdaGCN combines semi-supervised learning for discriminative node representations with adversarial learning for domain invariance.\nRecent advancements in generative modeling have led to the integration of diffusion models into domain adaptation tasks. Diffusion models, originally proposed by [22] and further developed by [23], have shown remarkable potential in bridging the gap between source and target domains. Diffusion models offer several advantages in domain adaptation tasks, including gradual transformation, which ensures smooth and controlled transitions between domains while preserving critical data features [11]. Moreover, the ability of diffusion models to generate high-fidelity samples enables more accurate domain translation and feature adaptation [12].\nThis paper [24] introduces StyleGAN-Fusion, a novel method that leverages pre-trained text-to-image diffusion models for domain adaptation of GAN generators without requiring ground truth samples from target domains. The key innovation is the use of classifier-free guidance from diffusion models as a critic to guide GANs in generating images aligned with text prompts. The method also introduces a diffusion directional regularizer to prevent model collapse and maintain diversity. This framework [25] leverages diffusion models to adapt features from the source to the target domain by training a generation model on source data and using it to project target domain inputs back to the source domain for classification during inference. This paper [26] introduces a novel method, DPMs-ANT (Diffusion Probabilistic Models with Adversarial Noise-Based Transfer Learning), to address the limited data problem in diffusion probabilistic models (DPMs) used for image generation. The method incorporates two key strategies: similarity-guided training which uses a classifier to estimate domain divergence, and adversarial noise selection which adaptively chooses noise based on the input image.\nThis paper [11] presents a novel method for unsupervised domain adaptation using diffusion models. It introduces the Domain-Adaptive Diffusion (DAD) module, which gradually transforms source domain features into the target domain while preserving semantic integrity. Alongside, a Mutual Learning Strategy (MLS) is utilized to facilitate bidirectional learning between the classification model and the DAD module, enhancing the model's adaptability through iterative feedback. The methods employed in this paper [27] utilize a combination of diffusion-based models and active learning techniques for uncertainty estimation and domain adaptation. The approach centers around selecting informative target samples for annotation by applying a t-test-based selection strategy to address predictive uncertainties. The training process integrates the use of a diffusion classifier, which is trained on the target domain samples with a specific focus on modeling the probabilistic distribution of predictions."}, {"title": "III. DIFFUSION-BASED NOISE-CENTERED ADVERSARIAL LEARNING DOMAIN ADAPTATION", "content": null}, {"title": "A. Problem formulation", "content": "In the task of cross-user HAR domain adaptation, the term 'domain' refers to the 'user'. Domain adaptation, in this case, means transferring knowledge between different users.\nGiven a labelled source user $S^{Source} = \\{(x^{Source}_i, y^{Source}_i)\\}_{i=1}^{n_{Source}}$ drawn from a joint probability distribution $P^{Source}$ and a target user $S^{Target} = \\{(x^{Target}_i, y^{Target}_i)\\}_{i=1}^{n_{Target}}$ drawn from a joint probability distribution $P^{Target}$, where $n_{Source}$ and $n_{Target}$ are the number of source and target samples respectively. $S^{Source}$ and $S^{Target}$ have the same feature spaces (i.e. the set of features that describes the data from sensor readings) and label spaces (i.e. the set of activity classes). The source and target users have different distributions, i.e., $p^{Source} \\neq P^{Target}$, which means that even for the same activity, the sensor readings look different between the two users. Given source user data $\\{(x^{Source}_i, y^{Source}_i)\\}_{i=1}^{n_{Source}}$ and target user data $\\{(x^{Target}_i)\\}_{i=1}^{n_{Target}}$, the goal is to obtain the labels for the target user activities."}, {"title": "B. An overview of the Diff-Noise-Adv-DA method", "content": "Diffusion models, inspired by processes in physics, have recently shown great potential in various machine learning tasks. These models iteratively transform data from a simple distribution to a more complex one through a series of gradual steps, enabling the capture of intricate data structures. Diffusion models are particularly effective for domain adaptation due to their ability to learn complex transformations and smooth transitions between data distributions. By modeling the progressive changes needed to align source and target data distributions, diffusion models can effectively bridge the gap between different users' activity data.\nIn the forward diffusion process, data is gradually transformed into noise that resembles random fluctuations. This noise, however, is often underutilized. By incorporating activity and domain class information into the noise, we make it follow various Gaussian distributions based on these conditional inputs, thereby enriching the noise with classification details. Therefore, we design a component of Noise Generator as illustrated in Figure 2, to empower the new capability on noise. This component learns a projection from features to a Gaussian distribution, then the noise is sampled from this Gaussian distribution based on the activity classes and users label information. These noise is added to the feature that maps the feature to the direction of activity classes and users label.\nDuring the reverse diffusion denoising process, this noise, now linked to classification features, carries significant information about the classification labels. By accurately predicting this reverse noise, the model can extract and use this embedded information effectively, as illustrated in Figure 2. It is worthy to highligh that the noise predictor makes use of the the Gradient Reversal Layer (GRL) technique [28]. The GRL adversarial learning method works by reversing the gradients during training. Its main objective is to ensure that the noise predicted by the model are not overly specific to individual users but instead contribute to a more generalized model. This approach helps the model create representations that are invariant to user-specific details. As a result, this technique is incorporated as a constraint in the denoising process to guide the model's learning process.\nMoreover, both the forward diffusion and reverse denoising processes of Diff-Noise-Adv-DA method function as adversarial learning phases. In the forward diffusion phase, the goal is to differentiate between user and activity classes, acting as a discriminator to help the model recognize dis-"}, {"title": "C. Forward Diffusion Process", "content": "tinct characteristics of different users and their activities. In contrast, the reverse denoising phase aims to obscure the classification-related data distribution, acting as a generator. This adversarial setup helps the model better align feature distributions across different users, reducing discrepancies and improving generalization.\nIn this section, we compare the origianl design of forward diffusion process of diffusion model to our novel design of Diff-Noise-Adv-DA."}, {"title": "1) Original Forward Diffusion Process", "content": "The forward diffusion process is designed to incrementally add noise to data over multiple timesteps."}, {"title": "1. Forward Diffusion Process Definition", "content": "$\\begin{equation} q(x_t | x_{t-1}) = \\mathcal{N}(x_t | \\alpha_t x_{t-1}, \\beta_t I) \\end{equation}$\nwhere $ \\beta_t = 1 - \\alpha_t$ and I represents the identity matrix.\nThis equation defines the forward diffusion process. It specifies that the distribution of $x_t$ given $x_{t-1}$ is a Gaussian distribution with mean $ \\alpha_t x_{t-1}$ and variance $ \\beta_t I$. $ \\alpha_t$ and $ \\beta_t$ are parameters controlling the noise added at each time step. $ \\beta_t = 1 - \\alpha_t$ determines the variance of the noise. As t increases, $x_t$ becomes progressively noisier, transitioning from a signal to pure noise."}, {"title": "2. Mean of Forward Process", "content": "$\\begin{equation} E[x_t | x_{t-1}] = \\alpha_t x_{t-1} \\end{equation}$\nThis equation provides the mean of the Gaussian distribution for $x_t$ given $x_{t-1}$. The mean is $ \\alpha_t x_{t-1}$, showing that $x_t$ is a scaled version of $x_{t-1}$, with the scaling factor $ \\alpha_t$. The mean is scaled by $ \\alpha_t$, meaning the influence of $x_{t-1}$ on $x_t$ decreases as $ \\alpha_t$ changes. This scaling factor controls how much of the previous state influences the current state."}, {"title": "3. Variance of Forward Process", "content": "$\\begin{equation} Var[x_t | x_{t-1}] = \\beta_t I \\end{equation}$\nThis equation provides the variance of the Gaussian distribution for $x_t$ given $x_{t-1}$. The variance represents the amount of noise added at each step. As t increases, $ \\beta_t$ generally increases, making $x_t$ more noisy and less similar to $x_{t-1}$."}, {"title": "4. Forward Noising Process", "content": "$\\begin{equation} x_t = \\alpha_t x_{t-1} + \\sqrt{\\beta_t} \\epsilon \\end{equation}$\nwhere $ \\epsilon \\sim \\mathcal{N}(0, I)$ is the noise added to the process. This equation describes how $x_t$ is generated from $x_{t-1}$ by adding noise. $ \\epsilon$ is drawn from a standard normal distribution $ \\mathcal{N}(0, I)$. $x_t$ is obtained by adding noise to a scaled version of $x_{t-1}$. $ \\alpha_t x_{t-1}$ represents the signal component, and $ \\sqrt{\\beta_t} \\epsilon$ represents the noise component. As the process progresses, the noise component becomes more significant, making $x_t$ increasingly noisy and different from $x_{t-1}$."}, {"title": "2) Forward Diffusion Process with Classification Information", "content": "In our new design, we incorporate classification information directly into the forward diffusion process. This integration allows the model to utilize activity labels and user labels to better guide the orientation of noise addition process, empowering the noise as a carrier of the classification information."}, {"title": "1. Forward Diffusion Process Definition", "content": "$\\begin{equation} q(x_t | x_{t-1}, c_a, c_u) = \\mathcal{N}(x_t | \\alpha_t x_{t-1} + \\sqrt{\\beta_t} (c_a \\cdot \\gamma_a + c_u \\cdot \\gamma_u), \\beta_t I) \\end{equation}$\nwhere $ \\beta_t = 1 - \\alpha_t$.\nThis equation defines the forward diffusion process with the inclusion of classification information. The distribution of $x_t$ given $x_{t-1}$, activity label $c_a$, and user label $c_u$ is a Gaussian distribution with a mean that combines the scaled previous data $ \\alpha_t x_{t-1}$ and additional terms $c_a \\cdot \\gamma_a + c_u \\cdot \\gamma_u$ based on the classification labels, and variance $ \\beta_t I$. $c_a$ and $c_u$ represent the activity and user labels, respectively. $ \\gamma_a$ and $ \\gamma_u$ are vectors that encode the influence of the activity and user labels on the data. The mean of the Gaussian distribution now incorporates these classification labels to guide the noising process. $ \\beta_t = 1 - \\alpha_t$ determines the amount of the noise added."}, {"title": "2. Mean of Forward Process with Classification", "content": "$\\begin{equation} E[x_t | x_{t-1}, c_a, c_u] = \\alpha_t x_{t-1} + \\sqrt{\\beta_t} (c_a \\cdot \\gamma_a + c_u \\cdot \\gamma_u) \\end{equation}$\nThis equation provides the mean of the Gaussian distribution for $x_t$ given $x_{t-1}$, activity label $c_a$, and user label $c_u$. The mean is a combination of the scaled previous data and the contributions from the classification labels. The mean now includes additional terms $c_a \\cdot \\gamma_a$ and $c_u \\cdot \\gamma_u$ that encode the influence of the activity and user labels. This incorporation helps align the data with the classification information."}, {"title": "3. Variance of Forward Process", "content": "$\\begin{equation} Var[x_t | x_{t-1}, c_a, c_u] = \\beta_t \\end{equation}$\nThis equation provides the variance of the Gaussian distribution for $x_t$ given $x_{t-1}$, activity label $c_a$, and user label $c_u$. The variance remains $ \\beta_t$, as it is independent of the classification labels. The variance of the noise is not affected by the classification information; it remains as $ \\beta_t$, which governs the amount of noise added at each step."}, {"title": "4. Forward Noising Process with Classification", "content": "$\\begin{equation} x_t = \\alpha_t x_{t-1} + \\sqrt{\\beta_t} \\epsilon \\end{equation}$\nwhere $ \\epsilon \\sim \\mathcal{N}(c_a \\cdot \\gamma_a + c_u \\cdot \\gamma_u, I)$ is the noise added to the process.\nThis equation describes the forward noising process with the integration of classification information. The data $x_t$ is generated from $x_{t-1}$ by adding noise with the information that incorporate activity and user labels. The term $ \\alpha_t x_{t-1}$ represents the scaled previous data. $c_a \\cdot \\gamma_a$ and $c_u \\cdot \\gamma_u$ add classification-specific information to the noise. $ \\sqrt{\\beta_t} \\epsilon$ adds random noise to the process. This design improves how well the model aligns noise with classification labels."}, {"title": "D. Reverse Denoising Process", "content": "In this section, we compare the origianl design of reverse denoising process of diffusion model to our novel design of Diff-Noise-Adv-DA."}, {"title": "1) Original Reverse Denoising Process", "content": "The original reverse denoising process aims to reconstruct the original data from the noisy data by learning the mean and variance parameters at each step. This process gradually removes the added noise and retrieves the underlying clean data."}, {"title": "1. Reverse Process Definition", "content": "$\\begin{equation} p_\\theta(x_{t-1} | x_t) = \\mathcal{N}(x_{t-1} | \\mu_t(x_t), \\beta_t I) \\end{equation}$\nwhere $ \\mu_t(x_t)$ is the learned mean and $ \\beta_t$ is the learned variance.\nThis equation defines the reverse denoising process. The distribution of $x_{t-1}$ given $x_t$ is a Gaussian distribution with mean $ \\mu_t(x_t)$ and variance $ \\beta_t I$. The reverse process aims to recover $x_{t-1}$ from the noisy $x_t$. $ \\mu_t(x_t)$ is the mean that is learned by the model, which represents the most probable value of $x_{t-1}$ given $x_t$. $ \\beta_t$ is the variance that the model learns, indicating the uncertainty in the prediction of $x_{t-1}$."}, {"title": "2. Learned Mean of Reverse Process", "content": "$\\begin{equation} \\mu_t(x_t) = \\frac{1}{\\alpha_t} (x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\epsilon) \\end{equation}$\nwhere $ \\epsilon$ is the noise term.\nThis equation provides the learned mean $ \\mu_t(x_t)$ for the reverse process. It is computed by adjusting $x_t$ based on the learned noise $ \\epsilon$ and the parameters $ \\alpha_t$ and $ \\beta_t$. $ \\mu_t(x_t)$ represents the estimate of the clean data $x_{t-1}$. The term $ \\frac{1}{\\alpha_t}$ scales $x_t$ to account for the signal contribution. The term $ \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}$ adjusts for the noise added during the forward process. $ \\epsilon$ represents the noise term that is used to estimate the noise component in the reverse process."}, {"title": "3. Learned Variance of Reverse Process", "content": "$\\begin{equation} \\beta_t = \\frac{\\beta_t (1 - \\alpha_{t-1})}{\\sqrt{1-\\bar{\\alpha}_t}} \\end{equation}$\nThis equation provides the learned variance $ \\beta_t$ for the reverse process. It is computed based on the variance $ \\beta_t$ and the cumulative product of $ \\alpha_t$ values, denoted $ \\bar{\\alpha}_t$. $ \\beta_t$ represents the variance of the noise added during the reverse process. It is derived from the variance $ \\beta_t$ used in the forward process and adjusted by the ratio of cumulative $ \\alpha$ terms. This ensures that the noise level added during the reverse process is consistent with the noise level added during the forward process."}, {"title": "4. Reverse Noising Process", "content": "$\\begin{equation} x_{t-1} = \\mu_t(x_t) + \\sqrt{\\beta_t} \\eta \\end{equation}$\nwhere $ \\eta \\sim \\mathcal{N}(0, I)$ is the noise sampled in the reverse process. This equation describes the reverse noising process. The clean data $x_{t-1}$ is obtained from $x_t$ by adding noise sampled from a standard normal distribution to the learned mean $ \\mu_t(x_t)$. $x_{t-1}$ is reconstructed by starting from the learned mean $ \\mu_t(x_t)$ and adding noise $ \\sqrt{\\beta_t} \\eta$. $ \\sqrt{\\beta_t}$ scales the noise term $ \\eta$ to account for the variance in the reverse process. $ \\eta$ is sampled from a standard normal distribution and represents the random noise added during the reverse process. This process iteratively denoises $x_t$ to recover the original clean data as $x_{t-1}$."}, {"title": "2) Reverse Denoising Process with Adversarial Regularization", "content": "In our new design, we enhance the reverse denoising process by incorporating adversarial regularization, which aims to improve the alignment between source and target distributions during the denoising process."}, {"title": "1. Reverse Process Definition with Adversarial Regularization", "content": "$\\begin{equation} p_\\theta(x_{t-1} | x_t, c_a, c_{cu}, c_{as}) = \\mathcal{N}(x_{t-1} | \\mu_t(x_t, c_a, c_u, c_{as}), \\beta_t I) \\end{equation}$\nwhere $ \\mu_t(x_t, c_a, c_u, c_{as})$ incorporates adversarial regularization.\nThis equation defines the reverse denoising process with adversarial regularization. The distribution of $x_{t-1}$ given $x_t$, activity label $c_a$, user label $c_u$, and source user activity label $c_{as}$ is a Gaussian distribution with a learned mean $ \\mu_t(x_t, c_a, c_u, c_{as})$ and variance $ \\beta_t I$. The reverse process aims to recover $x_{t-1}$ from the noisy $x_t$. The learned mean $ \\mu_t$ now incorporates adversarial regularization to ensure better alignment between source and target distributions. $ \\beta_t$ is the learned variance, representing the uncertainty in the prediction of $x_{t-1}$."}, {"title": "2. Learned Mean of Reverse Process with Adversarial Regularization", "content": "$\\begin{equation} \\mu_t (x_t, c_a, c_u, c_{as}) = \\frac{1}{\\alpha_t} (x_t - \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}(AR(c_a \\cdot \\gamma_a + c_u \\cdot \\gamma_u) + c_{as} \\gamma_{as})) \\end{equation}$ (1)\nwhere AR($ \\cdot$) denotes the adversarial mechanism of Gradient Reversal technique applied to $c_a \\cdot \\gamma_a + c_u \\cdot \\gamma_u$\nThis equation provides the learned mean $ \\mu_t$ for the reverse process, incorporating adversarial regularization. The mean is computed by adjusting $x_t$ based on the learned noise and adversarial terms. The adversarial regularization AR($ \\cdot$) is applied to the classification information to ensure feature user-invariant. $ \\mu_t (x_t, c_a, c_u, c_{as})$ represents the estimate of the clean data $x_{t-1}$ with adversarial adjustments. The term $ \\frac{1}{\\alpha_t}$ scales $x_t$ to account for the signal contribution. The term $ \\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}}$ adjusts for the noise component. AR($c_a \\cdot \\gamma_a + c_u \\cdot \\gamma_u$) applies adversarial regularization to ensure that the activity and user labels do not bias the learned mean. $c_{as} \\cdot \\gamma_{as}$ represents the adversarial signal related to the source user activity label, helping to align features between the source and target domains."}, {"title": "3. Learned Variance of Reverse Process", "content": "$\\begin{equation} \\beta_t = \\frac{\\beta_t (1 - \\alpha_{t-1})}{\\sqrt{1-\\bar{\\alpha}_t}} \\end{equation}$\nThis equation provides the learned variance $ \\beta_t$ for the reverse process. It is computed based on the variance $ \\beta_t$ and the cumulative product of $ \\alpha_t$ values, denoted $ \\bar{\\alpha}_t$. $ \\beta_t$ represents the variance of the noise added during the reverse process. It is derived from the forward process variance $ \\beta_t$ and adjusted by the ratio of cumulative $ \\alpha$ terms. This ensures that the noise level added during the reverse process is consistent with the forward process, while incorporating adversarial adjustments if needed."}, {"title": "4. Reverse Noising Process with Adversarial Regularization", "content": "$\\begin{equation} x_{t-1} = \\mu_t(x_t, c_a, c_u, c_{as}) + \\sqrt{\\beta_t} \\eta \\end{equation}$\nwhere $ \\eta \\sim \\mathcal{N}(0, I)$ is the noise sampled in the reverse process. This equation describes the reverse noising process with adversarial regularization. The clean data $x_{t-1}$ is reconstructed from $x_t$ by adding noise sampled from a standard normal distribution to the learned mean $ \\mu_t$. $x_{t-1}$ is obtained by starting from the learned mean $ \\mu_t$ and adding noise $ \\sqrt{\\beta_t} \\eta$. $ \\sqrt{\\beta_t}$ scales the noise term $ \\eta$ to account for the variance in the reverse process. $ \\eta$ is sampled from a standard normal distribution and represents the random noise added during the reverse process. Adversarial regularization helps align features between different users, improving the quality of the reconstructed data and ensuring consistency with the source and target distributions.\nBy incorporating adversarial regularization terms into the learned mean, the reverse denoising process is guided to focus"}, {"title": "E. Training Objectives", "content": "on minimizing the discrepancy between source and target distributions. This approach leverages adversarial learning to enhance the robustness of the reverse process and improve the final reconstructed data quality."}, {"title": "1) Original Training Objectives", "content": "The original training objective for diffusion models is to maximize the data likelihood by minimizing the reconstruction error between the original data and the denoised data. This objective aims to ensure that the learned mean and variance parameters effectively reverse the noise addition process."}, {"title": "Noise Prediction Objective", "content": "$\\begin{equation} L_{total} = L_{noise} = E_{x_0,\\epsilon,t} [||\\epsilon - \\hat{\\epsilon}(x_t, t)||^2] \\end{equation}$\nwhere $ \\hat{\\epsilon}(x_t, t)$ is the predicted noise from the model.\nThis objective function measures the difference between the true noise $ \\epsilon$ and the predicted noise $ \\hat{\\epsilon}(x_t, t)$ at a given timestep t. The goal is to minimize this difference. The expectation $E_{x_0,\\epsilon,t}$ is taken over the original data $x_0$, the noise $ \\epsilon$, and the time step t. The term $||\\epsilon - \\hat{\\epsilon}(x_t, t)||^2$ represents the squared error between the true noise and the predicted noise. By minimizing $L_{noise}$, the model learns to accurately predict the noise added during the forward diffusion process. Accurate noise prediction ensures that the model can effectively reverse the noise addition during the reverse process, recovering the original data."}, {"title": "2) New Training Objectives", "content": "In our new design, we introduce an adversarial regularization term to the training objective. This term encourages the model to generate denoised data that aligns more closely with the target distribution."}, {"title": "1. Noise Prediction Objective", "content": "$\\begin{equation} L_{noise} = E_{x_0,\\epsilon,t} [||\\epsilon - \\hat{\\epsilon}(x_t, t) ||^2"}]}