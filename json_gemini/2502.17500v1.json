{"title": "Generalized Exponentiated Gradient Algorithms Using the Euler Two-Parameter Logarithm", "authors": ["Andrzej CICHOCKI"], "abstract": "In this paper we propose and investigate a new class of Generalized Exponentiated Gradient (GEG) algorithms using Mirror\nDescent (MD) approaches, and applying as a regularization function the Bregman divergence with two-parameter deformation of\nlogarithm as a link function. This link function (referred to as the Euler logarithm) is associated with a wide class of generalized\nentropies. In order to derive novel GEG/MD updates, we estimate generalized exponential function, which closely approximates\nthe inverse of the Euler two-parameter logarithm. The characteristic/shape and properties of the Euler logarithm and its inverse\ndeformed exponential functions are tuned by two or even more hyperparameters. By learning these hyperparameters, we can\nadapt to distribution of training data, and we can adjust them to achieve desired properties of gradient descent algorithms. The\nconcept of generalized entropies and associated deformed logarithms provide deeper insight into novel gradient descent updates.\nIn literature, there exist nowadays over fifty mathematically well-defined entropic functionals and associated deformed logarithms,\nso impossible to investigate all of them in one research paper. Therefore, we focus here on a wide-class of trace-form entropies\nand associated generalized logarithm. We applied the developed algorithms for Online Portfolio Selection (OPLS) in order to\nimprove its performance and robustness.", "sections": [{"title": "I. INTRODUCTION", "content": "Many fundamental formulations of gradient updates have been considered in the optimization, machine learning and AI\nincluding additive gradient descent (GD) [23], [49], its stochastic version (SGD), multiplicative updates (MU) [16]\u2013[18],\nexponentiated gradient (EG) descent [7], [35] and mirror descent (MD) updates [6], [8], [23], [49], [53]. The (additive) gradient\ndescent and the multiplicative (exponentiated) gradient update method are the most popular algorithms in machine learning.\nThe exponentiated gradient descent updates belong to the class of multiplicative gradient updates [17] and simultaneously to\nmirror descent (MD) algorithms (see e.g., [6], [23]). EG algorithms were proposed by Kivinen and Warmuth [35], [36] and\nhave been adopted for various applications by many researchers [27], [23], [28], [44], [45], [50], [62].\nExponentiated Gradient (EG) descent and Mirror descent (MD) [6]\u2013[8], [23], [49], [53] are becoming increasingly popular\nin a variety of settings in optimization and machine learning. One reason for their success is the fact that mirror descent can\nbe adapted to fit the geometry of the optimization problem at hand by choosing suitable strictly convex potential functions\n(mirror maps). EG and MD have been extensively studied for convex optimization problems and also in non-convex setting,\nand it is based on the Bregman divergence associated to the mirror map [6], [8], [49].\nThe additive gradient descent updates are nowadays the most commonly used algorithms, but they are often not appropriate\nwhen all entries of the target weight vector have to be nonnegative. Moreover, in learning and optimization via additive gradient\n(GD), it incurs well-known problems like vanishing and exploding gradients, making careful and precise learning rate tuning\nessential for real-world applications [49]. The EG weight updates may alleviate some of these problems without the need for\nprecise learning rate tuning. Moreover, Exponentiated gradient (normalized-EGU and normalized-EG) updates can converge\nfaster than GD, especially when target weight vectors are sparse [6], [28], [35]. It is also interesting to note, that recent\nfindings about synapses of neurons in brains indicate that EG updates are more biologically plausible in learning process than\nadditive GD updates [19]. The standard EG updates are typically viewed as appropriate for problems where the geometry of the\noptimization domain is described by the Kullback\u2013Leibler divergence or relative entropy, as is often the case when optimizing\nover probability distributions. The main disadvantage of existing EG updates is that they do not have the possibility to adapt\nto data with various distributions due to the lack of hyperparameters which control convergence properties and performance\nof the algorithms.\nWe propose in this paper, that generalized EG updates may arise under a broader principle: By exploiting two (or more)\nparameters link function which allow us to adapt to data with various geometry and probability distributions. Particularly, for\nthe online portfolio selection problem, this allows the proposed algorithms to adapt to different market conditions and investor\npreferences more effectively than the existing standard EG algorithms [27], [44]."}, {"title": "II. PRELIMINARIES: MIRROR DESCENT AND STANDARD EXPONENTIATED GRADIENT (EG) UPDATE", "content": "Notations. Vectors are denoted by boldface lowercase letters, e.g., w \u2208 RN, where for any vector w, we denote its i-th\nentry by wi. For any vectors w,v \u2208 RN. The N-dimensional real vector space with nonnegative real numbers is denoted by\nRY. We define the Hadamard product as w \u2299 v = [w\u2081v\u2081,...,wNvN]T and w\u00ba = [w\u2081, ..., w\u00f5]T. All operation for vectors\nlike multiplications and additions are performed componentwise. The function of a vector is also applied for any entry of\nthe vectors, e.g., f(w) = [f(w\u2081), f (w2), ..., f(wN)]T. We let w(t) denote the weight or parameter vector as a function of\ntime t. The learning process advances in iterative steps, where during step t we start with the weight vector w(t) = wt and\nupdate it to a new vector w(t+1) = wt+1. We define [x]+ = max{0, x}, and the gradient of a differentiable cost function as\n\u2207wL(w) = dL(w)/dw = [dL(w)/dw1,...,dL(w)/dwn]T. In contrast to generalized logarithms defined later the classical\nnatural logarithm will be denoted by ln(x).\nProblem Statement: Suppose we want to minimize a loss/cost function L(w) with respect to the weight vector w =\n[W1,...,WN]T \u2208 R, i.e., we want to solve the following optimization problem:\n$$w_{t+1} = \\arg \\min_{w \\in \\mathbb{R}^N_{+}} \\{L(w)+\\frac{1}{\\eta}D_f(w||w_t)\\},$$\nwhere L(w) is a differentiable loss function, \u03b7 > 0 is the learning rate and Df(w||wt) is the Bregman divergence [11].\nThe Bregman divergence can be defined as [6], [11]\n$$D_f(w||w_t) = F(w) \u2013 F(w_t) \u2013 (w \u2013 w_t)^T f(w_t),$$\nwhere generative function (mirror map) F(w) is a continuously-differentiable, strictly convex function defined on the convex\ndomain, while f(w) = \u2207wF(w), which is often called the link function. The Bregman divergence can be understood as the\nfirst-order Taylor expansion of F around w evaluated at wt. The Bregman divergence Df(w||wt) arising from generator\nfunction F(w) referred here as mirror map can be viewed as a measure of curvature.\nThe Bregman divergence includes many well-known divergences commonly used in practice, e.g., the squared Euclidean\ndistance, Kullback-Leibler divergence (relative entropy), Itakura-Saito distance, beta divergence and many more [17]\nThe derivatives of the Bregman divergence Df(w||wt) w.r.t. the first and second arguments yield\n$$\\nabla_w D_f(w||w_t) = f(w) \u2013 f(w_t), \\qquad \\nabla_{w_t} D_f(w||w_t) = -H_f(w_t)(w \u2013 w_t),$$\nwhere\n$$H_f(w_t) = \\nabla_w^2 F(w_t) = \\frac{d^2 F(w_t)}{dw_t^2} = \\frac{d f(w_t)}{dw_t},$$\nis the Hessian of F(wt evaluated at wt. It should be noted that in this paper the Hessian matrix is a diagonal positive-definite\nmatrix with positive entries by proper selection the range of hyper-parameters.\nComputing the gradient for Eq. (1) and setting it at wt+1 at zero yields the so-called prox or implicit MD update\n$$f(w_{t+1}) = f(w_t) \u2013 \\eta \\nabla_w L(w_{t+1}),$$\nor equivalently\n$$w_{t+1} = f^{(-1)} [f(w_t) \u2013 \\eta \\nabla_w L(w_{t+1}],$$\nwhere f(-1)(w) is inverse function of the link function f(w).\nIn practice, assuming that \u2207wL(Wt+1) \u2248 \u2207wL(wt), the implicit iteration in (6) can be approximated by the explicit update\n[6], [53]:\n$$w_{t+1} = f^{(-1)} [f(w_t) \u2013 \\eta \\nabla_w L(w_{t})].$$\nThe continuous time mirror descent update (mirror flow) can be represented by ordinary differential equation (ODE) (as\n\u0394t \u2192 0) [6]\n$$\\frac{d f(w(t))}{dt} = -\\mu \\nabla_w L(w(t))$$\nwhere \u03bc = \u03b7/\u0394t > 0 is the learning rate for continuous-time learning, and f(w) = VF(w) is a suitably chosen link function\n[6], [23]. Hence, we can obtain alternative form of continuous-time MD update in general form:\n$$\\frac{dw}{dt} = -\\mu [\\nabla_w^2F(w)]^{-1} \\nabla_w L(w)$$\nIn the special case, for F(w) = \u2211i=1 Wi ln wi - wi and corresponding (component-wise) link function f(w) = ln(w) we\nobtain (multiplicative) unnormalized Exponentiated Gradient (EGU) updates [35].\n$$\\frac{d \\ln(w(t))}{dt} = -\\mu \\nabla_w L(w(t)), \\qquad w(t) > 0, \\forall t.$$"}, {"title": "III. THE EULER (a, b)-LOGARITHM AND ITS FUNDAMENTAL PROPERTIES", "content": "In this paper we investigate the application of the following generalized logarithm as a link function in mirror descent:\n$$\\log_{a,b}^E(x) = \\frac{x^a \u2013 x^b}{a-b}, \\qquad x > 0, a \\neq b, a < 1, 0 < b < 1, \\text{ or } b < 1, 0 < a < 1,$$\nwhich has been investigated firstly by Euler [21] in 1779, who was inspired by Lambert research [38], [31].\nHistorical remarks: The above function have long history. First of all, the related algebraic equation studied by Lambert\nwas xn x + q = 0, which Euler transform in [38], [21]:\n$$x^a \u2212 x^b = (a \u2013 b)v x^{a+b}, x > 0,$$\nwhere he used here the following function\n$$v(x,a,b) = \\frac{x^{a}-x^{b}}{a-b}, x > 0.$$\nEuler considered also special cases, including b = 0 and limiting case a = b = 0 [21], [31]. For b = 0 and a \u2260 0 he obtained\nv(x,a) = (1 \u2212 x\u00af\u00ba)/a and its inverse function (-1) (x, a) = [1 - ax]-1/a, which in fact are closely related to the Amari\nlogarithm [2]- [5] and its inverse, investigated in information geometry and implicitly related to Harvda-Charvat [25] and\nTsallis entropy (with a = q - 1) [59], [60]. For the second case he assumed a = b + X and obtained as the limit the natural\nlogarithm (for b = 0: limx\u21920+ = (x^ \u2212 1)/x = ln(x). For these reasons, we will name the generalized logarithm defined by\nEq. (16) the Euler (a, b)-logarithm or simply the (a, b)-logarithm.\nThe Euler logarithm has been independently and implicitly re-introduced by Sharma-Taneja [54], [57] and Mittal [47] often\ncalled Sharma-Taneja-Mittal (STM)-entropy in the fields of information theory, and successively proposed by Borges-Roditi\n[10] and Kaniadakis-Lissia-Scarfone (KLS) to define and investigate a wide class of generalized trace-form entropies [32],\n[33], in the fields of statistical physics and discussed more recently by Wada and Scarfone [63]."}, {"title": "IV. PROPERTIES OF GENERALIZED (a, b)-EXPONENTIAL", "content": "In general, for arbitrary set of parameters, the Euler (a, b)-logarithm cannot be inverted analytically, thus it is impossible\nto define explicitly the corresponding generalized exponential expressed by some basic functions (except of some important\nspecial cases discussed above). However, we found least two solutions.\nThe first approach, which we propose, is to express the generalized (a,b)- exponential functions in terms of the Lambert-\nTsallis Wq-functions [20], which are the solution of equations W\u2084(z)[1 + (1 - q)Wq(z)]1/(1-9)\n= z:\n$$\\exp_{a,b}(x) = \\frac{W_{\\frac{A+1}{4}} \\frac{1}{4} (\\frac{A-1}{4})}{\\lambda},$$\nwhere x = (a - b)/a, x = (a \u2013 b)x, q = (x + 1)/\u03bb = (2a - b)/(a \u2013 b) and Wq is the Lambert-Tsallis function [20].\nThe second alternative approach, is to use Lagrange's inversion theorem around 1. Applying the Lagrange inversion, we\nobtained the following power series approximation\n\\begin{align*}\n\\exp_{a,b}(x) &= 1 + x + \\frac{1}{2} (1 - a - b)x^2 + \\frac{1}{6} ((1-a-b)^2+(-2+3a-a^2 + 3b - ab-b^2))x^3\\\\\n&=1 + x + \\frac{1}{2} (1 - a - b)x^2 + \\frac{1}{6} (1 \u2013 3a \u2013 3b + 2a^2 + 5ab + 2b^2)) x^3\\\\\n&=\\frac{\\exp(x)}{1-\\frac{1}{2}(a+b) x^2-\\frac{1}{6}(3a + 3b-2a^2-5ab-2b^2) x^3 + O(x^4)},\n\\end{align*}"}, {"title": "V. MD AND GEG ALGORITHMS", "content": "A. Unnormalized GEG Updates\nLet assume that the link function is defined as f(w) = loga,b(w) and its inverse f(\u22121)(w) = expa,&(w), then using a\ngeneral MD formula (7), and fundamental properties described above, we obtain a generalized EG/MD update:\n$$w_{t+1} = \\exp_{a,b} [\\log_{a,b}(w_t) \u2013 \\eta_t \\nabla L(w_t)]$$\n$$= w_t \\otimes_{a,b} \\exp_{a,b} [-\\eta_t \\nabla L(w_t)], \\qquad w_t > 0,$$\nwhere the generalized (a, b)-multiplication is defined/determined componentwise for two vectors x and y as follows\n$$x \\otimes_{a,b} y = \\exp_{a,b} (\\log_{a,b}(x) + \\log_{a,t}(y)) \\text{ for } x > 0, y > 0, \\text{ with } x \\otimes_{a,b} 1 = x, \\,\\otimes_{a,b} y = y$$\n$$x \\otimes_{a,b} y = \\exp_{a,b} (\\log_{a,b}(x) + y), \\text{ } x > 0.$$\nIn the special case, for a = b = 0 the developed GEG update simplifies to the standard unnormalized EG (EGU) (11)\n$$w_{t+1} = w_t \\exp [-\\eta_t \\nabla L(w_t)], \\qquad w_t > 0,$$"}, {"title": "VI. APPLICATION OF GENERALIZED EXPONENTIATED GRADIENT ALGORITHM FOR ONLINE PORTFOLIO SELECTION", "content": "In this section, we propose a new generalized EG (GEG) algorithms for Online Portfolio Selection (OLPS). The OLPS is\na fundamental research problem in the area of computational finance [39]- [43], [58], which has been extensively investigated\nin both machine learning and computational finance communities, especially for high-frequency trading where it is necessary\nto use relatively fast and robust on-line algorithms. OLPS has become increasingly popular in recent years, particularly with\nthe growth of online trading platforms and availability of real-time market data. In general, the aim of portfolio selection is to\ndetermine combinations (mix) of assets like stocks or bonds that are optimal with respect to performance measures, typically,\ncapital gains, subject to reducing risks. A portfolio selection model is a quantitative decision rule that tells us how to invest.\nIn other words, the goal of portfolio selection is to find the optimal mix of assets that provides the highest expected total\nreturn with limited risk. The online portfolio selection (OLPS) problem differs from classical portfolio model problems, as it\ninvolves making sequential investment decisions.\nWe consider a self-financed, discrete-time, no-margin, and non-short investment environment with N assets for T trading\nperiods. This period can be chosen arbitrarily, such as a fraction of seconds, minutes, hours, days, or weeks. In the t-th period,\nthe performance of assets can be described by a vector of price relatives, denoted by xt = [X1,t, X2,t,..., XN,t]T \u2208 R, where\nXi,t, (i = 1,2,..., N) is the closing price (pi,t) of the i-th asset in period t divided by its closing price in the previous period\n(Pi,t-1),\n$$X_{i,t} = P_{i,t}/P_{i,t-1}.$$\nThe portfolio, which reflects the investment decision in the t-th period, is denoted by a weight vector wt = [W1,t,..., WN,t]T \u2208\nR, with the constraint that wi,t \u2265 0, \u2200i, t and ||wt||1 = 1. The i-th element of wt specifies the proportion of the total portfolio\nwealth invested in i-th asset in the t-th period.\nWe assume that the cumulative return obtained at the end of the t-th period (e.g., one day) is completely reinvested at the\nbeginning of period t + 1-th and no additional wealth can be taken into the portfolio. Initially, we assume that the portfolio is\nuniformly allocated; that is, wo = u = \u20a91. In the t-th period, portfolio wt is adopted and the price relative vector \u00e6t occurs\nat the end of this period. The increase in wealth during this period is proportional to the convex combination of relative prices\nwxt = i=1 Wit Xi,t. In the absence of transaction costs, the final cumulative wealth is expressed as:\n$$CWT = CW_0 \\prod_{t=1}^T [w_t^Tx_t],$$\nwhere CWo denotes the initial wealth, which, for simplicity, was be set to one (e.g., one thousand dollar for the initial\ninvestment). Therefore for OLPS as online loss function has been typically used linear L\u2081(w) = -w\u00b9xt or logarithmic\nL2(w) = - ln(wTxt functions. In practice, in order to improve performance and improve robustness the relative price is often\npreprocessed as follows [40], [41], [29], [14]:\n$$x_t =\\begin{cases}\n\\overline{x_t} = \\frac{x_t}{P_t}  \\frac{P_{t-1}}{\\underline{P_t}} \\text{ no preprocessing}\\\\\n\\frac{x_t}{\\text{mean}(p_t,..., P_{t-n})}  \\frac{P_{t-1}}{\\underline{P_t}} \\text{ estimate online mean value}\\\\\n\\frac{x_t}{l1-\\text{norm}, \\text{median}(P_t,..., P_{t-n})}  \\frac{P_{t-1}}{\\underline{P_t}} \\text{ estimate online median value}\\\\\n\\end{cases}$$\nwhere refers to the component-wise division of vector elements. Such preprocessing has be applied, for example, in OLMAR\nalgorithm [41], and RMR algorithm [29].\nSince in a typical market the wealth grows exponentially fast (but with a various factor depending on a market conditions),\nthe formal analysis of our algorithm will be presented in terms of the normalized generalized logarithm of the wealth achieved.\nWe propose a novel cost/loss function to easier to adopt to real data and provide more flexibility and robustness to outliers:\n$$L(w) = - \\log_q (w^Tx_t) = -\\frac{(w^Tx_t)^{1-q} \u2013 1}{q-1}, \\qquad w^Tx_t > 0.$$\nMoreover, it can continuously interpolate between two, typically used loss functions: L\u2081(w) = -wTxt and L\u2082(w) =\n- In(wTxt.\nRemark: Other generalized logarithms discussed in this paper can be applied including the most general Euler (a, b)-\nlogarithm.\nThe OLPS problem is formulated as the following constrained optimization problem:\n$$J_1(w) = \\hat{L}(w) + \\lambda D_f(w||w_t), \\text{ subject to } ||w_t||_1 = 1, w_{i,t} > 0, \\forall i,t$$\nwhere L(w) = L(w/||w||1) is normalized loss function, \u03bb = 1/\u03b7 is a regularizer or penalty parameter that controls the\nsmoothness of the solution and it can takes positive and small negative values in our practical implementations and Df(w||wt)\nregulizer/penalty is the Bregman divergence:\n$$D_f(w||w_t) = F(w) \u2013 F(w_t) \u2013 (w \u2013 w_t)^T f(w_t)$$\nwith\n$$f(w_t) = \\log_{a,b}(w_t), \\quad (f_i(w_t) = \\frac{w_t^{a} \u2013 w_t^{b}}{a \u2013 b}, i = 1, 2, ..., N),$$\nand\n$$F(w_t) = \\sum_{i=1}^N F(w_{i,t}) = \\sum_{i=1}^N (\\frac{w_{i,t}^{a+1}}{a+1} \u2013 \\frac{w_{i,t}^{b+1}}{b+1}).$$"}, {"title": "VII. CONCLUSIONS", "content": "In this paper, we have developed a new generalized multiplicative Mirror Descent, which can be considered as an extension\nand generalization of the standard Exponentiated Gradient (EG) algorithms. The proposed algorithm can be considered as\na flexible and robust generalization of existing exponentiated gradient updates and alternative to additive gradient descent\nalgorithms, especially for sparse representations. The developed generalized EG updates can take many different forms\ndepending on selection of (a,b) hyperparameters. They may find applications in AI, especially in learning of deep neural\nnetworks and in machine learning for classification, clustering and predication. The proposed updates unveil new perspectives\non the applications of generalized logarithmic and exponential functions and associated generalized entropies, especially in\nMirror Descent and gradient descent updates in a wide spectrum of applications formulated as optimization problems. It is of\ngreat importance to understand the mathematical structure of the generalized logarithm and its inverse generalized exponential\nin order to obtain more insight into the proposed update schemes. Motivated by this fact, we systematically revised and extended\nfundamental properties of the generalized Euler logarithm and its inverse, generalized exponentials."}]}