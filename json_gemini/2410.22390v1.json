{"title": "FNDEX: Fake News and Doxxing Detection with Explainable AI", "authors": ["Dorsaf Sallami", "Esma A\u00efmeur"], "abstract": "The widespread and diverse online media platforms and other internet-driven communication technologies have presented significant challenges in defining the boundaries of freedom of expression. Consequently, the internet has been transformed into a potential cyber weapon. Within this evolving landscape, two particularly hazardous phenomena have emerged: fake news and doxxing. Although these threats have been subjects of extensive scholarly analysis, the crossroads where they intersect remain unexplored. This research addresses this convergence by introducing a novel system. The Fake News and Doxxing Detection with Explainable Artificial Intelligence (FNDEX) system leverages the capabilities of three distinct transformer models to achieve high-performance detection for both fake news and doxxing. To enhance data security, a rigorous three-step anonymization process is employed, rooted in a pattern-based approach for anonymizing personally identifiable information. Finally, this research emphasizes the importance of generating coherent explanations for the outcomes produced by both detection models. Our experiments on realistic datasets demonstrate that our system significantly outperforms the existing baselines.", "sections": [{"title": "1 Introduction", "content": ""}, {"title": "1.1 Background", "content": "The internet has effectively turned the entire world into a global village, easily and quickly connecting people from different corners of the globe. However, it has also heightened various social harms, such as bullying and harassment, hate speech, disinformation, and radicalization. The exacerbation of these problems has wide-reaching impacts on individuals, communities, and society [21]. Indeed, the online landscape has become a battleground where privacy, truth, and trust are continually tested. Within this volatile environment, the convergence of two troubling phenomena, doxxing and fake news, has raised serious concerns about the safety, security, and veracity of online communities."}, {"title": "1.2 Motivations: The Intersection of Doxxing and Fake News", "content": "While fake news and doxxing are distinct, instances of intersection do exist. False information disseminated through fake news can contribute to the motivations behind doxxing. Conversely, doxxing may be employed as a form of retaliation against individuals associated with the creation or dissemination of fake news. Both phenomena give rise to substantial ethical and legal concerns, emphasizing the challenges of responsibly navigating the digital landscape.\nThe correlation between fake news and doxxing warrants in-depth investigation. A notable example to highlight is the \u2018Pizzagate' conspiracy theory (Figure 1). This conspiracy, which falsely implicated Hillary Clinton in a pedophilia ring, gained momentum through the spread of disinformation on social media, eventually leading to the exposure of personal information about innocent individuals (employees at the pizza parlor), leading to a dangerous armed incident [42]. This case underscores how the dissemination of fake news can contribute to doxxing, and potentially subjecting individuals to harm and harassment.\nFurthermore, the convergence of COVID-19 vaccine disinformation and doxxing campaigns, which target vaccine researchers and healthcare professionals, has instilled a pervasive atmosphere of fear and reluctance to speak out within the healthcare sector. This correlation can be observed in the case of \"Plandemic\" [19]. This video disseminated misleading information about the COVID-19 pandemic and vaccines, ultimately culminating in the exposure of Dr. Anthony Fauci, a distinguished infectious disease expert, to doxxing. Dr. Fauci's private details were posted online, resulting in harassment and threats [19].\nFake news and doxxing often intertwine when false narratives are used to justify or legitimize the exposure of someone's private information. For instance, during a political campaign, fake news about a candidate's alleged misdeeds may be used to justify doxxing their personal details, aiming to harm their reputation or incite harassment. Fake news creators use private information to tailor their content to the beliefs, fears, and desires of target voters, making it more likely to resonate with them and deceive them [14]. By leveraging personal data, fake news purveyors can deceive the public by enabling the personalization of content"}, {"title": "1.3 Contributions", "content": "While there are separate studies dedicated to fake news and doxxing, to the best of our knowledge, there is currently no research that addresses both of these issues simultaneously. This research endeavor aims to delve into the complex realm of doxxing and fake news. Our objectives encompass not only the development of effective detection strategies for identifying these threats but also the implementation of anonymization techniques to safeguard individuals' privacy. Additionally, we propose an ethical and transparent pathway forward by incorporating eXplainable AI (XAI) methods to ensure that our solutions are both effective and accountable. Hence, our main contributions are:"}, {"title": "2 Literature Review", "content": "The current study is grounded in two established research paradigms. Firstly, it encompasses methodologies aimed at automated fake news detection. Secondly, it encompasses the identification of doxxing and the exposure of private information. In this section, we will provide a concise overview of the pertinent literature in both of these domains."}, {"title": "2.1 Fake News Detection", "content": "Fake news has a long history with roots that predate even the invention of the printing press. While Google Trends Analysis\u00b9 reveals that the term \"fake news\" reached its peak in popularity during the 2016 US presidential election, its origins can be traced back to a time long before that [9]. Nevertheless, the concept of fake news remains a contentious issue, lacking a clear and universally accepted definition. The very definition of this concept and the way it is interpreted have increasingly become subjects of debate [15,48]. The term \"fake news\" often encompasses disinformation, misinformation, and malinformation in public discourse, as highlighted by the Council of Europe [62]. Moreover, fake news may lead to a wide-ranging spectrum of harms and consequences, including malicious intents such as attempting to defraud individuals [53], manipulate public opinion [13], or influence political processes [33].\nFake news detection is an ever-expanding research topic that is gaining a lot of attention since there are still multiple challenges that need to be investigated. There are various research studies on fake news detection proposing different approaches. For instance, within the research community, various techniques have been employed to address this challenge. These include Natural Language Processing techniques [49], data mining approaches [52], machine learning methods [5,29], recommender systems [47], social context-based techniques [63], and fake news propagation path [45]."}, {"title": "2.2 Doxxing and Private Information Detection", "content": "The term \"dox\" has a somewhat ambiguous origin, but a widely accepted theory suggests it may have emerged as a condensed form of the word \"documents,\" particularly in the context of \"dropping documents\". Its initial usage dates back to the 1990s [18], when it came to signify the act of exposing someone's private and sensitive information online, often with the intention of embarrassing or intimidating them. Consequently, doxxing, also known as dropping doxx, is the act of releasing private, or personally identifiable information on the internet, often with malicious intentions [6].\nDouglas [18] presents a comprehensive typology that delves into the multifaceted nature of doxxing, categorizing it into three distinct forms: deanonymizing doxxing, targeting doxxing, and delegitimizing doxxing. Within this framework, Douglas highlights the diverse losses or harm experienced by individuals subjected to these different forms of doxxing. Deanonymizing doxxing exposes the target's loss of anonymity, whether it pertains to their professional or personal life. In contrast, targeting doxxing results in the loss of obscurity as the doxxer typically reveals the individual's home address or other personal details online. Delegitimizing doxxing places the target's credibility in jeopardy, often by releasing evidence suggesting their involvement in deceptive or 'immoral' activities. Douglas' typology provides a nuanced understanding of the varied consequences and dimensions of doxxing.\nSeveral approaches have been proposed by different researchers for detecting sensitive information disclosures on X (formerly known as Twitter). Caliskan-Islam et al. [10] introduced a method that scores users based on the disclosure of private information in their tweets, utilizing the detection of private information and subsequent calculation of privacy scores for users' timelines. Mehdy et al. [36] developed a sentiment-aware privacy disclosure detection framework centered on neural networks, employing machine learning algorithms to identify sensitive information based on the sentiment expressed in the text. Confora et al. [12] devised 97 heuristics rooted in recurrent patterns to uncover location and emotion information disclosures, relying on the identification of specific text patterns to detect sensitive information. In contrast, Deodhar et al. [16] proposed an approach that not only identifies private information but also categorizes it. This approach includes the extraction of topics and features based on the dependency graph structures of tweets, as well as the consideration of location information and user mentions.\nOther researchers have focused on detecting doxxing. For instance, researchers in [30] propose a set of approaches for automatically detecting the disclosure of sensitive personal information, specifically doxxing, on X. It compares nine different approaches based on string-matching, heuristics, word embeddings, and contextualized string embeddings. In a separate study [54], the authors address a significant knowledge gap surrounding doxxing by offering comprehensive, quantitative insights into this form of online harassment. The authors crafted and implemented a specialized tool capable of identifying dox files and quantifying various aspects of doxxing, including its prevalence, content, targets, and the consequences observed on well-known dox-posting platforms.\nThe intersection between fake news and doxxing forms a deeply concerning and multifaceted issue, posing a significant threat to both the integrity of online information ecosystems and the personal safety and privacy of individuals. While the existing body of literature has separately addressed both fake news and doxxing threats, a comprehensive approach that combines these two distinct issues has not been previously explored. Therefore, the present study represents"}, {"title": "3 Proposed Methodology", "content": ""}, {"title": "3.1 Problem Statement", "content": "Given a dataset N consisting of news posts, where N = {n1, n2, ..., nn}, with each news post nx containing text content tx and an authenticity label px (where Px = 0 for real news and px = 1 for fake news), we aim to develop functions and strategies to address the challenges of fake news and doxxing detection and prevention. Specifically, we intend to design a fake news detection function F that maps the input text tx to the predicted authenticity label: px = F(tx). Additionally, we introduce a doxxing detection function D to identify doxxing within the text content: dx = D(tx).\nFor prevention, we introduce a text anonymization process denoted by the function A. Given the input text tx, the anonymization function A transforms it to a protected text tx: fx = A(tx). The aim of text anonymization is to safeguard sensitive information within the text content while preserving the overall message, reducing the risk of privacy breaches and harm associated with doxxing.\nTo ensure transparency and interpretability in our methodology, we incorporate XAI techniques. For the fake news detection model, denoted as F, we introduce an explanation function EF that takes the input text tx and produces an explanation ef for the authenticity prediction Px: eF\u2082 = EF(tx). Similarly, for the doxxing detection model D, we employ another explanation function ED to generate an explanation en for the doxxing prediction dx: eD\u2082 = ED(tx). These explanations er and ep provide insights into how the models arrive at their predictions, ensuring transparency and helping users understand the decision rationale."}, {"title": "3.2 Approach overview", "content": "In Figure 2, our proposed framework is depicted, comprising primarily of two phases: the classification phase and the post classification processing phase. The initial step involves the reception of news posts as input, at which point two pre-defined classifiers are applied one for detecting fake news and another for identifying doxxing. Subsequently, in the ensuing phase, the outcomes of these two modes are presented, indicating whether the news is genuine or not, and whether it has been doxxed or not. If the news is deemed to be doxxed, an anonymization process is employed to safeguard against the disclosure of private information. Finally, the explainer component offers comprehensive explanations for both classifiers."}, {"title": "3.3 Classification phase", "content": "The initial phase involves the application of two classifiers designed for the identification of fake news and doxxing. Both of these models undergo offline training. Figure 3 provides a zoomed-in view of the training process. Starting with separate datasets for each task, specifically for fake news detection and doxxing identification, an identical process is systematically executed. This process encompasses preprocessing and transformer training, ultimately yielding a distinct classifier for each task."}, {"title": "3.3.1 Preprocessing", "content": "To ensure the dataset is suitably preprocessed for input into our models, we applied standard data processing techniques. This encompassed employing Huggingface's AutoTokenizer [20] to tokenize the text as per our specific requirements, performing lemmatization, and removing both stop words and punctuation. Furthermore, we conducted label encoding to effectively convert categorical data into a numerical format."}, {"title": "3.3.2 Transformer training", "content": "Our research builds upon the use of transformers.\nTransformer architecture: The Transformer architecture, as described in [23], employs an encoder-decoder structure. It takes an input sequence denoted as X = (x1,...,xN) and generates a corresponding latent representation referred to as Z = (21,..., ZN). Notably, owing to the autoregressive nature of this model, the output sequence \u04ae\u043c = (y1, \u2026\u2026\u2026, \u0443\u043c) is produced incrementally, with each element, such as y\u043c, relying on both the latent representation Z and the previously generated sequence \u04ae\u043c\u22121 = (y1,..., \u0423\u043c\u22121) for its creation.\nBoth the Encoder and the Decoder components utilize an identical Multi-Head Attention layer. This specific Attention layer functions by mapping a query denoted as Q and a set of keys represented as K to a weighted sum of corresponding values denoted as V. It is important to note that, for technical considerations, a scaling factor of $\\frac{1}{\\sqrt{d_k}}$ is applied in the computation [23], as mentioned in the following equation:\nAttention(Q, K, V) = Softmax$\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$\nTransformers used: In our experimentation, we explored the capabilities of three different transformer models. First, we employed BERT (Bidirectional Encoder Representations from Transformers) [17], a language representation model that utilizes bidirectional pre-training by considering both the left and right contexts of unlabeled text. BERT's pre-training process involves two primary objectives: Masked Language Modeling (MLM), where 15% of the words in a sentence are randomly masked and the model predicts these masked words, and Next Sentence Prediction (NSP), where the model assesses whether two concatenated masked sentences follow each other. Fine-tuning BERT for specific"}, {"title": "3.4 Post classification processing phase", "content": "As previously stated, following the classification phase, the outcomes will be presented to the user. Additionally, in the event that the text is categorized as containing personally identifiable information (PII), the anonymization process will be initiated to protect sensitive data. Subsequently, the explainer module will provide explanations."}, {"title": "3.4.1 Anonymizer", "content": "The anonymizer is based on a pattern-based PII anonymization method to protect sensitive information in text data. It involves three different steps:\n1. Pattern Identification: The first step in this anonymization technique is to identify specific patterns or regular expressions that correspond to different types of PII. These patterns are designed to match the structure of PII, such as a name's format, an email address format, or a social security number format.\n2. Anonymization Placeholders: Following this identification step, we establish anonymization placeholders, which are used to replace the identified PII patterns in the text. These placeholders do not reveal any specific individual's identity but retain the format and structure of the original data.\n3. Pattern Replacement: Lastly, we replace PII patterns in the text with their corresponding anonymization placeholders. This process is accomplished through the use of regex pattern matching and replacement functions."}, {"title": "3.4.2 Explainer", "content": "In the realm of artificial intelligence applications, establishing trust is paramount to facilitate informed decision-making, as a lack of trust can lead to the disregard of AI-generated advice [51]. Here, Explainable AI methods play a pivotal role by unraveling the complex mathematical underpinnings behind model-generated predictions [26]. These explainable models offer users coherent and meaningful explanations, ultimately aiming to foster confidence in the system's outcomes. This enhanced understanding not only raises awareness of the dangers associated with such content but also influences users' future behavior. Recognizing the significance of transparency and interpretability in AI systems, we ensure that both our fake news detection model and doxxing detection model are explainable, enabling users to understand the decision-making processes behind these models.\nIn our methodology, we employ LIME (Local Interpretable Model-Agnostic Explanations) [46], an algorithm designed to faithfully elucidate the predictions of any classifier or regressor. It accomplishes this by creating a localized approximation of the model in question using an interpretable model. One of the standout features of LIME is its remarkable accessibility and simplicity. LIME's model-agnostic nature allows it to seamlessly integrate with virtually any machine learning model. It accomplishes this by treating the model as a distinct black-box entity and generating explanations for it. Furthermore, LIME goes beyond providing mere model-level explanations, offering insightful, granular explanations for each individual observation. Additionally, LIME's interpretability shines through in its capacity to furnish explanations that are grounded in the input features, avoiding the use of abstract or obscure attributes.\nThe rationale for this framework is deeply rooted in the urgency of addressing the combined threats of fake news and doxxing. With our methodology, we not only protect online safety and information integrity but also fortify the foundations of a thriving digital society where accurate information, privacy, and security are cherished and upheld."}, {"title": "4 Experimental Implementation", "content": ""}, {"title": "4.1 Datasets", "content": "To evaluate the performance of the fake news detection task, we conducted an experiment on the Kaggle dataset [3]. This dataset is in the English language and comprises two main subsets: the training set and the test set. The training set contains 35,918 data samples, while the test set has 8,980 data samples. These samples are news articles, and they are categorized into two classes: Fake and Real news. Within the dataset, there are 23,481 articles classified as fake news and 21,417 articles classified as real news. This dataset is ideal for natural language processing tasks, especially for classifying text to differentiate between fake and real news articles.\nIn the domain of Doxxing detection, a significant challenge we faced revolved around the absence of an openly accessible dataset. This scarcity can be ascribed to the paramount need to protect the privacy of individuals who engage with online platforms. Recognizing the critical importance of this matter, we"}, {"title": "4.2 Experimental Setup", "content": "The experimental setup involved utilizing Google Colab Pro and PyTorch to conduct the experiments. For the pre-trained models, we used the Hugging Face library. The specific hyperparameters used can be found in Table 3."}, {"title": "4.3 Evaluation Metrics", "content": "The performance of the algorithms for each task is measured in terms of detection accuracy, precision, recall, F1-score, which are calculated using the equations (1)-(4), respectively.\nDetection accuracy = $\\frac{TN+TP}{TN+TP+FN + FP} \\times 100$\nPrecision = $\\frac{TP}{TP + FP} \\times 100$\nRecall = $\\frac{\u03a4\u03a1}{TP + FN} \\times 100$\nF1-Score = $\\frac{2 x Precision \\times Recall}{Precision + Recall} \\times 100$\nwhere TP is true positive, TN is true negative, FN is false positive, and FN is false negative."}, {"title": "4.4 Baselines", "content": "To assess the performance of the two models, we compared them against established baselines:\nThe different baselines for fake news detection are: (1) Triple BERT [37], which employs multiple BERT models with shared weights to effectively handle a range of inputs and leverage additional contextual information, including justifications and metadata. (2) FNR [22] relies on similarity and transformer-based methods to detect fake news, utilizing both textual and image content from news sources. (3) SENAD [57] introduces an authenticity scoring mechanism and incorporates user-centric metrics such as Following-followers ratio, account age, bias, and more to evaluate the credibility of user engagement with news articles.\nThe baselines for doxxing detection are: (1) In [30], a stratified 10-fold cross-validation method is used to ensure an equitable representation of both classes in the training and testing datasets, preventing overfitting or bias in the Support Vector Machines classifier. (2) [12] detects sensitive information in social network posts by identifying recurring patterns in natural language frequently used by users to disclose private details. (3) [16] incorporates the Stanford Dependency Parser for dependency parsing, which captures grammatical relations between words in sentences. The Chi-square method is used to select informative features while eliminating irrelevant and redundant attributes from the data."}, {"title": "5 Results and Discussion", "content": ""}, {"title": "5.1 Assessing Performance", "content": "Table 4 offers a comprehensive breakdown of the performance metrics for each model across various datasets.\nIn the Doxxing Detection task, the comparison between baseline models and transformer-based models reveals a striking disparity in performance. The best-performing baseline model achieved respectable results with an accuracy of 96.61%, precision of 97.74%, recall of 97.28%, and an F1 score of 97.51%. However, the transformer-based models, including BERT, DistilBERT, and RoBERTa, exhibited remarkable superiority. RoBERTa, in particular, stood out with an astonishing accuracy of 99.99%, precision of 100%, recall of 100%, and an F1 score of 99.98%. These results clearly demonstrate that transformer-based models outclass the baseline models, providing significantly higher accuracy and precision in the challenging task of Doxxing Detection.\nIn the realm of Fake News Detection, a similar pattern emerges when comparing baseline models to transformer-based models. The best-performing baseline model achieved a reasonably strong performance, boasting an accuracy of 93.7%, precision of 92.6%, recall of 95%, and an F1 score of 93.7%. However, the transformer-based models, including BERT, DistilBERT, and RoBERTa, once again demonstrated their prowess. For instance, RoBERTa achieved an impressive accuracy of 99.65%, precision of 99.89%, recall of 99.44%, and an F1 score of"}, {"title": "5.2 Interpreting Transformers' Attention", "content": "In order to delve deeper into the performance of the three transformer models, we undertook a comprehensive visual analysis of attention weights in pre-trained models with the aid of the BertViz library [58]. This interactive tool is designed for visualizing attention in Transformer language models, offering multiple perspectives that provide unique insights into the attention mechanism."}, {"title": "5.3 Privacy Utility Trade-Off", "content": "In this section, we present the results obtained through the Anonymizer. Table 5 showcases illustrative examples that demonstrate the transformation of the original text into an anonymized version after applying the Anonymizer. It is important to note that these examples are synthetic and are not representative of real-world data, they are solely generated for the purpose of demonstrating the anonymization process."}, {"title": "5.4 Models Interpretability Through LIME", "content": "For the explainer phase, we employ the LIME Text Explainer [46]. We introduce an independent textual instance to the interpreter. Multiple iterations of the original text are generated, wherein a specified number of randomly selected words are systematically omitted. This newly generated synthetic data is subsequently categorized into distinct groups, differentiating between \"fake\" and \"real\" or \"doxxed\" and \"not doxxed\". Consequently, by observing the impact of specific keywords' presence or absence, we can assess their influence on the classification of the designated text.\nThe LIME output comprises a set of explanations delineating the individual feature's influence on the prediction of a given data sample. The resultant value provides a concise representation of each word's contribution to the classification"}, {"title": "5.5 Impact on Online Safety", "content": "The proposed framework offers a holistic solution that holds the potential to enhance online safety by addressing the intersection of fake news and doxxing. By proactively detecting and responding to these dual threats, the framework aims to mitigate the risks associated with online harassment, privacy violations, and the spread of misinformation, thus creating a safer and more secure digital environment. It contributes to a significant reduction in online harassment, safeguarding individuals from the emotional distress and fear that often accompanies such incidents. By protecting privacy through the identification and prevention of doxxing attempts, it empowers users to navigate online spaces with a greater"}, {"title": "5.6 Ethical Considerations", "content": "Ethical considerations are at the heart of our framework, and we recognize the importance of transparency in addressing the specific ethical concerns our study addresses. The anonymization component is inherently designed to safeguard individuals' privacy, a central ethical concern in our research. Our foremost ethical concern is the preservation of individuals' privacy. We acknowledge that the data we collected and analyzed can be sensitive, and our primary goal is to prevent any potential harm, especially in the case of doxxing targets included in our research. By ensuring the privacy of these individuals, we are adhering to ethical principles related to data protection and individual rights. Moreover, to maintain ethical integrity, we meticulously adhered to a rigorous data collection policy. This policy mandates the exclusive use of publicly available information, thereby respecting the privacy boundaries of individuals and complying with data access restrictions. As an additional ethical precaution, we refrained from presenting the exact content of tweets or revealing any personal data contained within our dataset. This decision aligns with ethical guidelines related to non-disclosure of personal information without consent and minimizes the risk of unintended exposure. Our meticulous approach underscores our unwavering commitment to mitigating any possible harm that may result from our research. This includes potential harm to the individuals involved as well as broader societal implications. By taking these precautions, we aim to uphold the highest ethical standards throughout the study.\nOur study addresses specific ethical concerns related to privacy preservation, data collection, avoidance of inadvertent exposure, and harm mitigation. We are dedicated to upholding these ethical principles as we conduct our research, ensuring that our work aligns with the values of responsible and ethical research practices."}, {"title": "6 Conclusion and Future work", "content": "While free speech is a fundamental right, the use of false information or the exposure of private data often has legal consequences, highlighting the need for effective detection and enforcement mechanisms. Within the scope of this paper, we present fake news and doxxing detection with an explainable AI approach. FNDEX is a novel system designed for the dual purpose of detecting fake news and identifying doxxing instances within online text. This system not only anonymizes sensitive data but also offers detailed explanations to users, explaining the reasoning behind system decisions. Our proposed framework, while"}]}