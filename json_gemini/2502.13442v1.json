{"title": "TREECUT: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation", "authors": ["Jialin Ouyang"], "abstract": "Large language models (LLMs) now achieve near-human performance on standard math word problem benchmarks (e.g., GSM8K), yet their true reasoning ability remains disputed. A key concern is that models often produce confident, yet unfounded, answers to unanswerable problems. We introduce TREECUT, a synthetic dataset that systematically generates infinite unanswerable math word problems and their answerable counterparts, by representing each question as a tree and removing chosen necessary conditions. Experiments show TREECUT effectively induce hallucinations in large language models, including GPT-40 and o3-mini, with rates of 61% and 42% in their respective worst-case scenarios. Further analysis highlights that deeper or more complex trees, composite item names, and removing necessary condition near the middle of a path all increase the likelihood of hallucinations, underscoring the persistent challenges LLMs face in identifying unanswerable math problems.", "sections": [{"title": "1 Introduction", "content": "Mathematical reasoning is a crucial part of human intelligence. Recent years have witnessed remarkable advancements in the mathematical reasoning capabilities of large language models (LLMs). By leveraging techniques such as chain-of-thought prompting (Wei et al., 2022), state-of-the-art LLMs (e.g., Achiam et al. (2023); Team et al. (2024); Dubey et al. (2024)) achieved human-level performance on benchmarks like GSM8K (Cobbe et al., 2021). However, it remains controversial whether this performance implies reasoning capability beyond pattern matching.\nA substantial body of research highlights the capability of Large Language Models in mathematical reasoning. Achiam et al. (2023); Team et al. (2024); Dubey et al. (2024); Yang et al. (2024), among others, achieved over 90% accuracy on GSM8K (Cobbe et al., 2021), a dataset consists of 8K grade school math word problems. Yang et al. (2024); Zhou et al. (2023), among others, achieved over 80% accuracy on the more difficult MATH dataset (Hendrycks et al., 2021), which consists of 12.5K high school math competition problems.\nMeanwhile, there is a line of research questioning the reasoning ability of LLMs by showing their vulnerability under superficial changes of the input that do not alter the underlying logic. Works like Shi et al. (2023); Jiang et al. (2024) find that LLMs are easily distracted by irrelevant context or token level perturbation that does not change the underlying logic of the reasoning task. Mirzadeh et al. (2024) further demonstrate that the performance of LLMs declines when numerical values are altered in the questions from the GSM8K dataset.\nThere is yet another line of research that challenges the ability of LLMs to refrain from answering unanswerable problems. Ma et al. (2024); Li et al. (2024); Sun et al. (2024); Zhou et al. (2024a); Saadat et al. (2024) introduce minor modifications to existing math word problems to create unanswerable variants, and find that LLMs often generate hallucinatory answers for these unanswerable questions, even when they perform well on the original answerable datasets. However, these efforts rely on pre-existing math word problem sources, making them susceptible to training data contamination, limited in scope, and lacking rich structures for extended research.\nTo address these shortcomings, we propose TREECUT, a synthetic dataset capable of systematically generating an infinite number of unanswerable math word problems and their answerable counterparts. Our unanswerable dataset proves to be challenging even for GPT-40 and o3-mini. In addition, TreeCut allows precise control over the structural components of each problem, enabling detailed investigations into when and why LLMs produce hallucinations. We will release the dataset generation code upon publication."}, {"title": "2 Related Work", "content": "Math Word Problem Benchmark Numerous math word problem datasets of different difficulty have been proposed in previous research, most notable examples including GSM8K (Cobbe et al., 2021) and MATH (Hendrycks et al., 2021).\nMany benchmarks have been developed to measure the robustness of mathematical reasoning. (Li et al., 2024; Zhou et al., 2024b; Yu et al., 2023; Shi et al., 2023) perturb or rewrite math word problems to measure the robustness of mathematical reasoning. Mirzadeh et al. (2024) developed GSM-Symbolic, a new benchmark derived from the GSM8K dataset by modifying numerical values, entity names, and question complexity.\nRecently, Opedal et al. (2024) introduced Math-GAP, a framework for evaluating LLMs using synthetic math word problems with controllable proof tree characteristics. In contrast to their approach, the tree structure in our problem-generation procedure is fundamentally different. In our work, each node represents a variable, and the questioned variable appears as a leaf. In their work, however, each node represents a logical statement, with the answer represented by the root. More importantly, we focus on unanswerable math word problems, an aspect that their study did not address.\nUnanswerable Math Problems Yin et al. (2023) introduced SelfAware, consisting of unanswerable questions from five diverse categories. It includes less than 300 unanswerable mathematical problems. Li et al. (2024) and Zhou et al. (2024a) generate unanswerable questions by prompting GPT4 to eliminate a necessary condition from the original problem, an then the modified questions are further checked or refined by human annotators. Sun et al. (2024) task human annotators to modify original questions in existing MWP datasets to make them unanswerable, creating a dataset composed of 2,600 answerable questions and 2,600 unanswerable questions. Ma et al. (2024) prompt GPT4 to modify problems from GSM8K, generating the Unreasonable Math Problem benchmark."}, {"title": "3 TREECUT: a Synthetic (Un)answerable Math Word Problem Dataset", "content": "For the purpose of our investigation, we aim to have full control over the various aspects that determine the underlying structure of a math word problem: the name of the entities, the numeric values, and the complexity of the problem. Furthermore, we seek to reliably generate unanswerable problems by precisely removing specific necessary conditions of our choosing.\nTo this end, we start with a special kind of answerable math word problem that can be represented as a tree, as illustrated in Figure 1. Within such a tree, each non-root node represents a variable, while the root is a uniquely reserved node. An edge from root gives value to a variable, while an edge between two variables represents a linear formula of the two neighboring nodes. Given such a tree, any variable can be calculated following the unique path from the root to the node that represents the variable. Such a solving procedure does not require solving a linear equation system, as the solution only consists of carrying out basic arithmetic operations along the path. To guarantee that the arithmetic operations are well within the capacity of current frontier LLMs, we further restrict the unit price of each food item to be an integer between 5 and 15, and the coefficients of each linear equation taking non-zero integer values between -3 and 3. Finally, variables are randomly mapped to items, and then the formulas are translated to natural language using templates.\nFrom an answerable math word problem described above, we generate an unanswerable problem by removing an edge along the path from the root to the questioned variable. In Figure 1, $x_3$ is the questioned variable. Along the path to the root, we remove the edge between $x_1$ and $x_2$ (denoted by a cut), rendering $x_2$ and $x_3$ undetermined, thus making the question unanswerable, as all we know about $x_2$ and $x_3$ is one single linear equation. A key benefit of such a generation procedure is that the distance from the questioned variable to the cut is also fully controlled, as we will see that this factor plays an important role in triggering LLM hallucination.\nIn summary, we can control the structure of problems via the following parameters:\nnumVars: total number of variables,\nansDepth: distance from the root to the questioned variable,\ncompositeName: boolean, whether the items in the question have composite names (e.g. \u201ca burger at Bistro Nice\u201d versus \u201ca burger\u201d),\ncutDepth: distance from the questioned variable to the cut, if an unanswerable problem is to be generated.\nAppendix A contains the detailed problem generation algorithm."}, {"title": "4 Experiments", "content": "We evaluate several state-of-the-art LLMs using TREECUT. Additionally, we analyze the hallucination rate of GPT-40 on unanswerable problems generated under different parameter configurations of TREECUT.\n4.1 Experimental Setup\nFor each set of generation parameters, we randomly generate 100 problems. During evaluation, we employ a zero-shot prompting template that explicitly directs the model to indicate when a question is unanswerable due to insufficient conditions. A chain-of-thought system message is incorporated for all models except o3-mini\u00b9.\n4.2 Evaluating LLMs\nIn the first set of experiments, we generate unanswerable math word problems of varying difficulty to evaluate the following LLMs: Llama 3.1 Instruct with 8B and 70B parameters(Dubey et al., 2024), Qwen2.5 Instruct with 7B and 72B parameters(Yang et al., 2024), GPT-40(Achiam et al., 2023), and o3-mini(OpenAI, 2025).\nTable 1 summarizes the results. None of the LLMs gives satisfactory results. Llama 3.1 8B, Qwen2.5 7B and 72B barely have any success identifying unanswerable problems. Llama 3.1 70B and GPT-40 struggle with more complex problems (ansDepth = 6,8). 03-mini has the lowest hallucination for ansDepth = 6,8. However, for the easiest case where ansDepth = 2 (in this setting, only 4 variables are mentioned in each problem), 03-mini displays a bias of making hallucinatory assumptions (see Appendix C.2 for examples).\nTo investigate whether the unsatisfactory accuracy of identifying unanswerable problems comes from the incapability of the necessary mathematical operations, we evaluate the LLMs on the answerable counterparts of the unanswerable questions using the same prompting template. We observe that almost every model displays a significant gap between its ability of solving answerable problems and identifying unanswerable problems. For instance, GPT-40 correctly solves 84% of answerable problems for ansDepth = 8, but only correctly recognizes 39% of unanswerable problems.\n4.3 Unanswerable Problem Structure and Hallucination\nFor a more fine-grained investigation of LLM's hallucination behavior under different structures of unanswerable problems, we analyze GPT-40's hallucination rate on unanswerable problems generated under different parameter choices of numVars, ansDepth, compositeName and cutDepth."}, {"title": "Tree Structure and Item Names", "content": "To investigate the effect of (i) a deeper tree structure, (ii) a more complex tree structure, and (iii) composite item names, we consider the following parameter configurations:\n\u2022 ansDepth \u2208 {4, 5, 6, 7, 8}, which controls the depth of the questioned variable,\n\u2022 cutDepth = [ansDepth/2]\n\u2022 numVars = ansDepth + 2 (generates a more complex tree structure) or numVars = ansDepth (the tree structure degenerates into a single path),\n\u2022 compositeName: true or false.\nThere are 5 \u00d7 2 \u00d7 2 = 20 configurations in total. We randomly generate 100 unanswerable problems for each configuration, and summarize GPT-40's hallucination rate in Figure 2. In the figure,\n* Orange line represents complex tree structure,\n* blue line represents simple tree structure,\n* Solid line stands for composite item names,\n* Dashed line stands for simple item names.\nExamining each line individually, we observe that the hallucination rate increases as the depth of the questioned variable grows. Comparing solid and dashed lines of the same color, a more complex tree structure consistently results in a higher likelihood of hallucination across different ansDepth values. Comparing orange and blue lines of the same linestyle, composite item names consistently lead to a higher likelihood of hallucination compared to simple item names.\nLocation of the Cut For each unanswerable problem, the cut always happens along the path from the root to the questioned variable. Does the location of the cut change hallucination ratio? We vary cutDepth from 1 to 7 while keeping ansDepth = 8 and other parameters fixed. In the right panel of Figure 3, we see that cutDepth = 3,4, 5, 6 all trigger over 60% hallucination for GPT-40 (with cutDepth = 5 triggering over 70%), but a cutDepth = 1,2,7 only triggers less than 50% of hallucination, which means that GPT-40 is more confused when the cut happens around the middle point along the path, comparing to that happens near the root or the questioned variable.\n4.4 Conclusion of Experiments\nOur findings indicate that the unanswerable math word problems generated by TREECUT effectively induce hallucinations in large language models, including GPT-40 and o3-mini, with rates of 61% and 42% in their respective worst-case scenarios. Focusing on GPT-40, we further observe that hallucinations are more likely to occur when the problem exhibits (i) a deeper tree structure, (ii) a more complex tree structure, (iii) composite item names, or (iv) a cut positioned around the middle of the path. These results underscore the challenges LLMs face in handling unanswerable math problems."}, {"title": "5 Limitations", "content": "Our synthetic dataset is specifically designed for math word problems, representing only a small subset of the broader field of mathematics. Additionally, our evaluations are based solely on zero-shot chain-of-thought prompting. We do not explore alternative prompting techniques commonly used in LLM-based mathematical reasoning studies, which may impact performance comparisons."}, {"title": "A Generation of the Math Word Problems", "content": "Algorithm 1 generates formulaList, which contains the formulas that will serve as the conditions of the problem. To translate that into natural language, item names will be sampled according to the compositeName option. Then, formulaList can be translated to natural language using pre-defined templates. The question sentence will simply be \u201cwhat is the price of {item name of the questioned variable}\u201d.\nWe want to point out that although all the variables are assigned a value in varDict, this is purely for the sake of (i) subsequently generating the random formulas (ii) guaranteeing that all calculable variables will have values between 5 and 15. When unanswerable = true, the cut will guarantee that the problem is unanswerable.\nIn the following, we also detail the simple breadth-first traversal algorithm for getting all the edges from the tree, which enables us to control the order of the conditions in the problem.\nAlgorithm 2 requires:\n1: edgeList \u2190 [ ], q \u2190 a queue containing root\n2: while q is not empty do\n3: node \u2190 q. dequeue()\n4: for child \u2208 node.children do\n5: Add (node, child) to edgeList\n6: Add child to q\n7: end for\n8: end while\nB Details of Experiments\nB.1 Prompt Template\nBelow is the prompt template used for evaluation, which is a 0-shot prompting template with chain-of-thought system message. For reasoning models like o3-mini, we do not use the chain-of-thought system message.\nB.2 Evaluation\nFor all the models other than o3-mini, we set {max_tokens=4000, temperature=0}. 03-mini does not allow setting temperature, and we set {max_completion_tokens=32000, reasoning_effort=\u201chigh\u201d}. GPT-40 and 03-mini are evaluated via calling OpenAI API.\nWhen evaluating model's answer to an unanswerable problem, we change the response to all lower case, and if \"unknown\u201d is mentioned after the last occurrence of the trigger word \"answer\u201d, it is counted as a correct answer."}, {"title": "C Examples of Hallucinatory Answers", "content": "C.1 GPT-40\nExample 1: A BLT sandwich at Urban Plate costs 13 dollars. 3 burgers at Taste Good Cuisine cost 6 dollars more than 3 fruit tarts at Taste Good Cuisine. A BLT sandwich at Taste Good Cuisine costs 5 dollars. A fruit tart at Taste Good Cuisine costs 9 dollars less than 3 burgers at Urban Plate. 2 burgers at Taste Good Cuisine cost 8 dollars more than a fruit tart at Urban Plate. Question: how much does a burger at Taste Good Cuisine cost?\nModel answer:\nTo solve this problem, we need to set up equations based on the information given and solve for the unknowns.\nLet's define the variables:\nLet \\(B_T \\) be the cost of a burger at Taste Good Cuisine.\nLet \\(F_T \\) be the cost of a fruit tart at Taste Good Cuisine.\nLet \\(B_U \\) be the cost of a burger at Urban Plate.\nLet \\(F_U \\) be the cost of a fruit tart at Urban Plate.\nWe are given the following information:\n1. A BLT sandwich at Urban Plate costs 13 dollars.\n2. 3 burgers at Taste Good Cuisine cost 6 dollars more than 3 fruit tarts at Taste Good Cuisine.\n\\[\n3B_T = 3F_T + 6\n\\]\n3. A BLT sandwich at Taste Good Cuisine costs 5 dollars.\n4. A fruit tart at Taste Good Cuisine costs 9 dollars less than 3 burgers at Urban Plate.\n\\[\nF_T = 3B_U - 9\n\\]\n5. 2 burgers at Taste Good Cuisine cost 8 dollars more than a fruit tart at Urban Plate.\n\\[\n2B_T = F_U + 8\n\\]\nWe need to find the cost of a burger at Taste Good Cuisine, \\( B_T \\).\nFrom equation (2), we can express \\(F_T \\) in terms of \\( B_T \\):\n\\[\nF_T = B_T - 2\n\\]\nSubstitute this expression for \\(F_T \\) into equation (4):\n\\[\nB_T - 2 = 3B_U - 9\n\\]\n\\[\nB_T = 3B_U - 7\n\\]\nNow, let's substitute \\(F_T = B_T - 2 \\) into equation (5):\n\\[\n2B_T = (B_T - 2) + 8\n\\]\n\\[\n2B_T = B_T + 6\n\\]\n\\[\nB_T = 6\n\\]\nThus, the cost of a burger at Taste Good Cuisine is 6 dollars.\nAnswer: 6\nMistake: When the model did \"Now, let's substitute F_T = B_T - 2 into equation (5)", "1": "A pizza at Taste Good Cuisine and 3 lasagnas at Taste Good Cuisine cost 48 dollars. A lasagna at Urban Plate costs 6 dollars. 3 lasagnas at Urban Plate and 3 pizzas at Urban Plate cost 63 dollars. Question: how much does a lasagna at Taste Good Cuisine cost?\nModel answer:\nLet p be the price of a pizza at Taste Good Cuisine and 1 be the price of a lasagna at Taste Good Cuisine.\nWe are given:\n1. p + 31 = 48. (Taste Good Cuisine)\n2. A lasagna at Urban Plate costs 6 dollars.\n3. 3 lasagnas at Urban Plate and 3 pizzas at Urban Plate cost 63 dollars.\nFrom (3), the total cost of 3 lasagnas at Urban Plate is 3 x 6 = 18 dollars. This means that the 3 pizzas at Urban Plate cost 63 - 18 = 45 dollars, so one pizza at Urban Plate costs 45/3 = 15 dollars.\nA common (though unstated) assumption in these puzzles is that dishes with the same name cost the same across restaurants. Thus, we assume that a pizza at Taste Good Cuisine also costs 15 dollars. Substitute p = 15 into equation (1):\n15 + 31 = 48\n31 = 48 - 15 = 33\n1 = 33/3 = 11\nAnswer: 11\nMistake: The model made an assumption: \u201cA common (though unstated) assumption in these puzzles is that dishes with the same name cost the same across restaurants.\u201d However, this cannot be a mathematically valid assumption because following this assumption, it arrives at the conclusion that the price for lasagna at Urban Plate is not the same as that at Taste Good Cuisine (6 dollars versus 11 dollars).\nWe randomly selected 20 problems from the ansDepth = 2 set that triggered hallucinatory answer from 03-mini and manually checked the model answer, all of them shares this same mistake. Below is a similar example:\nExample 2: A scrambled egg at Bistro Nice and a piece of cheese cake at Mike's Place cost 21 dollars. 2 scrambled eggs at Bistro Nice cost 6 dollars more than 2 pieces of cheese cake at Bistro Nice. A scrambled egg at Mike's Place costs 6 dollars. Question: how much does a scrambled egg at Bistro Nice cost?\nModel answer:\nLet S_B = price of a scrambled egg at Bistro Nice,\nC_B = price of a piece of cheesecake at Bistro Nice,\nC_M = price of a piece of cheesecake at Mike's Place.\nThe problem gives:\n1. S_B + C_M = 21 dollars.\n2. Two scrambled eggs at Bistro Nice cost 6 dollars more than two cheesecakes at Bistro Nice:\n2S_B = 2C_B + 6 \u2192 S_B = C_B + 3.\n3. A scrambled egg at Mike's Place costs 6 dollars (this is extra information).\nWithout further assumptions the system involves three unknowns (S_B, C_B, C_M) and only two equations. However, it is common in these problems to assume that when the same item is mentioned (here", "cheesecake": "it has a consistent price from one restaurant to the other. That is, we assume C_M = C_B.\nUnder that assumption the first equation becomes:\nS_B + C_B = 21.\nThen using S_B = C_B + 3 we substitute:\n(C_B + 3) + C_B = 21 \u2192 2C_B + 3 = 21 \u2192 2C_B = 18 \u2192 C_B = 9.\nThus, S_B = 9 + 3 = 12.\nAnswer: 12\nMistake: Same as above.\nExample 3: 3 BLT sandwiches at Bistro Nice cost 6 dollars more than 3 pieces of cheese cake at Urban Plate. 3 burgers at Urban Plate cost 18 dollars less than 3 pieces of cheese cake at Bistro Nice. 2 BLT sandwiches at Urban Plate and 2 scrambled eggs at Urban Plate cost 34 dollars. A BLT sandwich at Urban Plate costs 8 dollars. 3 pieces of cheese cake at Bistro Nice cost 12 dollars more than 3 burgers at Bistro Nice. 2 burgers at Urban Plate cost 10 dollars less than 2 scrambled eggs at Bistro Nice. 3 pieces of cheese cake at Bistro Nice and a piece of cheese cake at Urban Plate cost 54 dollars. Question: how much does a piece of cheese cake at Urban Plate cost?\nModel answer:\nLet CC_U be the cost of one piece of cheese cake at Urban Plate.\nStep 1. From \"3 BLT sandwiches at Bistro Nice cost 6 dollars more than 3 pieces of cheese cake at Urban Plate\":\n3\u00b7BLT_B = 3\u00b7CC_U + 6 \u2192 BLT_B = CC_U + 2 (1)\nStep 2. From \"3 burgers at Urban Plate cost 18 dollars less than 3 pieces of cheese cake at Bistro Nice\":\n3\u00b7BUR_U = 3\u00b7CC_B - 18 \u2192 With BUR_U determined later, we use this after finding BUR_U.\nStep 3. \"2 BLT sandwiches at Urban Plate and 2 scrambled eggs at Urban Plate cost 34 dollars\":\n2\u00b7BLT_U + 2\u00b7Eggs_U = 34 and we are given in Step 4 that BLT_U = 8.\nThus, 2\u00b78 + 2\u00b7Eggs_U = 34 \u2192 16 + 2\u00b7Eggs_U = 34 \u2192 2\u00b7Eggs_U = 18 \u2192 Eggs_U = 9.\nStep 4. \"A BLT sandwich at Urban Plate costs 8 dollars\":\nBLT_U = 8.\nStep 5. \"3 pieces of cheese cake at Bistro Nice cost 12 dollars more than 3 burgers at Bistro Nice\":\n3\u00b7CC_B = 3\u00b7BUR_B + 12 \u2192 CC_B = BUR_B + 4 (2)\nStep 6. \"2 burgers at Urban Plate cost 10 dollars less than 2 scrambled eggs at Urban Plate\":\n2\u00b7BUR_U = 2\u00b7Eggs_U - 10 \u2192 2\u00b7BUR_U = 18 - 10 \u2192 2\u00b7BUR_U = 8 \u2192 BUR_U = 4.\nStep 7. Now return to the burgers at Urban Plate in Step 2:\n3\u00b7BUR_U = 3\u00b7CC_B - 18 With BUR_U = 4,\n3\u00b74 = 3\u00b7CC_B - 18 \u2192 12 = 3\u00b7CC_B - 18\n\u2192 3\u00b7CC_B = 30 \u2192 CC_B = 10.\nStep 8. \"3 pieces of cheese cake at Bistro Nice and a piece of cheese cake at Urban Plate cost 54 dollars\":\n3\u00b7CC_B + CC_U = 54 \u2192 3\u00b710 + CC_U = 54 \u2192 30 + CC_U = 54 \u2192 CC_U = 24.\nThe question asks: \"how much does a piece of cheese cake at Urban Plate cost?\"\nAnswer: 24\nMistake: Step 6. \u201c2 burgers at Urban Plate cost 10 dollars less than 2 scrambled eggs at Urban Plate\u201d. That is a hallucinatory condition. The actual condition is \"2 burgers at Urban Plate cost 10 dollars less than 2 scrambled eggs at Bistro Nice\"."}]}