{"title": "Gravitational Duals from Equations of State", "authors": ["Yago Bea", "Raul Jimenez", "David Mateos", "Shuheng Liu", "Pavlos Protopapas", "Pedro Taranc\u00f3n-\u00c1lvarez", "Pablo Tejerina-P\u00e9rez"], "abstract": "Holography relates gravitational theories in five dimensions to four-dimensional quantum field theories in flat space. Under this map, the equation of state of the field theory is encoded in the black hole solutions of the gravitational theory. Solving the five-dimensional Einstein's equations to determine the equation of state is an algorithmic, direct problem. Determining the gravitational theory that gives rise to a prescribed equation of state is a much more challenging, inverse problem. We present a novel approach to solve this problem based on physics-informed neural networks. The resulting algorithm is not only data-driven but also informed by the physics of the Einstein's equations. We successfully apply it to theories with crossovers, first- and second-order phase transitions.", "sections": [{"title": "Introduction", "content": "Holography [1-3] provides a valuable tool to study strongly coupled gauge theories with a large number of colors. In this limit, the duality maps the quantum properties of the gauge theory to the classical properties of a gravitational theory in one dimension higher. This geometrization has profound consequences. A celebrated one is the fact that the equilibrium, thermodynamic properties of the gauge theory are encoded in properties of black hole horizons in the dual gravitational solutions. Not surprisingly, near-equilibrium aspects of the gauge theory, such as transport coefficients, are then encoded in small per-turbations of the corresponding black hole horizons. Yet, the most dramatic consequence of the holographic map is that even the arbitrarily-far-from-equilibrium dynamics of the gauge theory can be determined by evolving in time the dual Einstein's equations.\nThe equilibrium regime can be studied from first principles with conventional methods such as the lattice formulation of gauge theories. In contrast, in the far-from-equilibrium regime holography is often the only tool with which systematic, first-principle calculations are possible. A fruitful strategy is therefore to construct a holographic model that repro-duces the equilibrium properties of a gauge theory of interest, and then use the holographic side to study the far-from-equilibrium dynamics. From this perspective, one can think of holography as model building of a unique type, namely, one with the right to access the far-from-equilibrium regime.\nAs we will see, implementing this strategy requires solving a challenging inverse prob-lem. Early (semi)analytical attempts include [4-6] (see [7] for a review). In this paper we will solve the problem using Physics-Informed Neural Networks (PINNs). With the ex-ception of [8-10], previous applications of NNs to holography [11\u201331] have focused on the reconstruction of a specific solution of the dual gravitational theory. In contrast, our algo-rithm reconstructs the gravitational theory itself. Although we will illustrate the method in a simple setup, we expect it to be generally applicable to inverse problems involving highly non-linear partial differential equations. We envisage many potential applications that will be explored elsewhere.\nTo illustrate our method, we will consider a four-dimensional Conformal Field Theory (CFT) deformed by a relevant operator O. For concreteness, in this paper we will assume that has conformal dimension three, but this is easily generalized. The holographic dual consists of five-dimensional gravity coupled to a scalar field with an appropriate potential V(\u00d8) [32, 33]. The existence of an ultraviolet (UV) fixed point in the gauge theory translates into anti-de Sitter space (AdS) boundary conditions on the gravity side. Despite their simplicity, this type of models capture the essence of many fundamental gauge theory properties such as thermal phase transitions [34], confinement [35], etc.\nAll the properties of the gauge theory, in particular its thermodynamics, are encoded in the scalar potential V(\u00d8). Given the potential, in order to determine the thermodynamics one needs to solve a direct problem. This consists of finding all the static, regular black hole solutions of the Einstein-Klein-Gordon (EKG) equations. This set of solutions can be conveniently parameterized by the value of at the horizon, \u03a6H. For each solution one computes the area density and the surface gravity of the horizon. From them one extracts the Bekenstein-Hawking entropy density S(H) and the Hawking temperature T(H). These quantities are then identified with the entropy density and the temperature of the corresponding thermal state in the gauge theory. The result is an equation of state S(T). Any other thermodynamic property such as the energy density, the pressure, etc. can be obtained from S(T) via thermodynamic identities.\nSince the scalar potential enters the EKG equations that must be solved to determine the thermodynamics, it is clear that the function S(T) is a functional of the function V(\u00d8). The determination of S(T) from V(\u00d8) is a direct problem because it can be done algorithmically, as we have just described. The inverse problem consists of finding a potential V(\u00d8) that reproduces a given S(T). The fact that the EKG equations are highly"}, {"title": "Holography and the direct problem", "content": "As explained above, we will focus on an EKG theory in five dimensions. The action takes the form\n$S = \\int d^5x \\sqrt{-g} [R - \\frac{1}{2} (\\nabla \\phi)^2 - V(\\phi)]$, (2.1)\nwhere \u03ba5 is the gravitational coupling and V(\u03c6) is the scalar potential.\nThe thermodynamics of the gauge theory is determined by finding all the static, planar black hole solutions of (2.1). Because of their translation invariance along the gauge theory directions, these solutions are usually referred to as \"black brane\" solutions. In order to find them, we consider an asymptotically AdS spacetime and we choose coordinates t, x, y, z for the Minkowski metric at the boundary. We then write the bulk metric in Eddington-Finkelstein coordinates as\n$ds^2 = -Adt^2 + \\Sigma^2 (dx^2 + dy^2 + dz^2) - \\frac{u^2}{2} dtdu$, (2.2)\nwhere u is the null holographic coordinate. The AdS boundary is located at u = 0. This region corresponds to the UV of the gauge theory. The metric functions A and \u03a3, as well as the scalar field \u03c6, are functions of u. Substituting the ansatz (2.2) into the equations of motion derived from (2.1) we obtain four ordinary differential equations (ODES)\n$\\Sigma'' + \\frac{3\\Sigma'}{\\Sigma} \\phi'^2 = 0$, (2.3a)\n$A'' + \\frac{8}{3} V(\\phi) + A'(\\frac{A'}{A} + \\frac{3\\Sigma'}{\\Sigma}) = 0$, (2.3b)\n$\\phi'' + \\frac{1}{A} \\frac{\\partial V(\\phi)}{\\partial \\phi} + (\\frac{A'}{A} + \\frac{3\\Sigma'}{\\Sigma})\\phi' = 0$, (2.3c)\n$A' + 2 A'\\frac{\\Sigma'}{\\Sigma} - \\frac{8u^2}{3} (\\frac{A'}{A} - \\frac{V(\\phi)}{A^2}) = 0$, (2.3d)\nwhere a prime indicates differentiation with respect to u. The last equation is first-order in derivatives because it is a constraint associated to our gauge choice for the u-coordinate. As a consequence, the four equations (2.3) are not all independent: two of the second-order equations plus the constraint imply the third second-order equation. This redundancy will be useful for our PINN."}, {"title": "Inverse problem", "content": "It is clear from Sec. 2 that solving the direct problem is algorithmic. Solving the inverse problem is not. In the inverse problem the only input is the thermodynamic curve S(T). Through equations (2.7), each pair of values (T, S) determines a pair (A\u2081, \u03a3\u2080). In turn, each of these pairs provides boundary conditions at the horizon through equations (2.6). Given this knowledge, the inverse problem consists of finding a unique potential V(\u03c6) such that the EKG equations with this same potential admit black brane solutions for all these boundary conditions.\nOur goal is thus to construct a PINN able to solve this inverse problem. In order to test its accuracy, we will ask the PINN to find the potentials for a family of equations of state Stheory(T) constructed in [36] and labeled by one parameter dubbed \u03c6M. As an illustration, Fig. 1 shows the equations of state for \u03c6M = 5, 1.08 and 1. The reason why we choose these examples is that they cover the three possible cases of a crossover, a second-order or a first-order phase transition.\nIn the high-temperature limit, the entropy density behaves as\n$S_{theory}(T) = \\frac{\\pi^4}{45} T^3 + \\frac{3\\pi^4}{64} T + ....$, (3.1)\nComparing with Eq. (A.5), we see that this corresponds to a CFT deformed by an operator O of dimension (2.5), in agreement with the boundary condition (2.4c) that we imposed on the dual scalar field \u03c6. Solving the EKG equations (2.3) perturbatively near the boundary, it can be shown that, in our conventions, the form of the entropy density (3.1) implies the following conditions on the scalar potential at \u03c6 = 0:\nV'(0) = 0, V''(0) + 3 = 0. (3.2)\nThe fact that these conditions can be imposed at \u03c6 = 0 can always be achieved by a shift in \u03c6. The first condition fixes the coefficient of the T\u00b3 term in S theory. The last two conditions state that \u03c6 = 0 is a maximum of the potential. On the gravity side, this corresponds to"}, {"title": "Methodology", "content": "In this section we describe our procedure to solve the EKG equations and reconstruct the potential non-parametrically, i.e. as a free-form function, using our implementation of PINNS to solve ODEs. First, we review some general aspects about the use of NNs to solve differential equations.\nA neural network (NN) is a machine-learning algorithm that produces a structure of in-terconnected nodes, or neurons, disposed in a layered structure, which can be trained to"}, {"title": "Background", "content": "A neural network (NN) is a machine-learning algorithm that produces a structure of in-terconnected nodes, or neurons, disposed in a layered structure, which can be trained to"}, {"title": "Solving the Einstein-Klein-Gordon equations", "content": "We now proceed to implement the EKG equations (2.3) in the NN. For this purpose, it is convenient to redefine the functions A, \u03a3, \u03c6 in such a way that the solutions are finite in the entire computational domain u \u2208 [0,1]. In view of the asymptotic behavior (2.4), this can be achieved through the following redefinitions:\n$\\overline{\\Sigma} = u \\Sigma, \\overline{A} = u^2 A$. (4.1)\nIt is also convenient to transform the EKG equations into first-order ODEs by thinking of the first-derivatives of \u0100, \u03a3 and \u03c6 as independent variables. Together with the constraint"}, {"title": "ODE setup", "content": "We now proceed to implement the EKG equations (2.3) in the NN. For this purpose, it is convenient to redefine the functions A, \u03a3, \u03c6 in such a way that the solutions are finite in the entire computational domain u \u2208 [0,1]. In view of the asymptotic behavior (2.4), this can be achieved through the following redefinitions:\n$\\overline{\\Sigma} = u \\Sigma, \\overline{A} = u^2 A$. (4.1)\nIt is also convenient to transform the EKG equations into first-order ODEs by thinking of the first-derivatives of \u0100, \u03a3 and \u03c6 as independent variables. Together with the constraint (2.3d), this results in 6 functions (\u03bd\u03a3, \u03bd\u03b1, \u03bd\u03c6, \u03a3, \u0100, \u03c6) subject to the following seven, coupled, first-order ODES\n$E_\\alpha = 0, \\qquad \\alpha = 1,..., 7,$, (4.2)\nwhere\n$E_1 = \\nu_\\Sigma - \\Sigma'$, (4.3a)\n$E_2 = \\nu_A - \\overline{A}'$, (4.3b)\n$E_3 = \\nu_\\phi - \\phi'$, (4.3c)\n$E_4 = \\nu_\\Sigma' + \\frac{3}{2} \\frac{\\Sigma'}{\\Sigma} \\phi'^2$, (4.3d)\n$E_5 = u^2 \\Sigma \\nu_A' + \\frac{8}{3} V(\\phi) \\Sigma + \\nu_A (3u^2 \\nu_\\Sigma - 5u^2 \\phi'^2) + \\overline{A} (8u^2 \\nu_\\Sigma - 6 \\nu_\\Sigma)$, (4.3e)\n$E_6 = u^2 \\overline{A} \\phi' \\nu + \\overline{A} \\Sigma \\frac{dV}{d \\phi} + \\frac{3\\Sigma'}{\\Sigma} (-3u^2 \\overline{A} \\Sigma' + u^2 \\Sigma \\overline{A}' + 3u^2 \\nu_\\Sigma \\overline{A})$, (4.3f)\n$E_7 = (u \\nu_\\Sigma' - \\Sigma') (u^2 \\nu_A' + 2u^2 \\overline{A} \\nu - 4u \\overline{A} \\Sigma') - \\frac{2}{3} (u^2 \\overline{A} \\nu - 2V(\\phi))$. (4.3g)\nIn terms of these variables, the boundary conditions discussed in Sec. 2 translate into\n$\\overline{A}|_{u=0} = 1$, (4.4a)\n$\\Sigma|_{u=0} = 1$, (4.4b)\n$\\phi|_{u=0} = 0$, (4.4c)\n$\\nu_\\phi|_{u=0} = 1$, (4.4d)\n$\\overline{A}|_{u=1} = 0$, (4.4e)\n$\\nu_A|_{u=1} = -4 \\pi T$, (4.4f)\n$\\Sigma|_{u=1} = (S/ \\pi)^{1/3}$, (4.4g)\nThe conditions (4.4a)-(4.4c) correspond to imposing that the solution approaches AdS at u = 0, in agreement with (2.4). Condition (4.4d) corresponds to imposing the fact that the dual operator has dimension (2.5) and the convention (2.8) for the scale of the boundary theory. The condition (4.4e) corresponds to imposing that the horizon is at u = 1, consistently with (2.6a). Finally, (4.4f) and (4.4g) correspond to conditions (2.6b), (2.6c) and (2.7).\nIn the direct problem, we choose a value of the scalar field, we obtain the numerical solution of the black brane, and we read off the entropy and the temperature. In contrast, in the inverse problem we start from the equation of state S(T) and use it as a boundary condition: S and T in (4.4f)-(4.4g) are related by the equation of state. In the inverse problem we do not impose a condition for the scalar field at the horizon. The reason is that this information is not directly contained in the equation of state but can only be determined in combination with the potential itself."}, {"title": "Technical aspects of setup and training", "content": "In this section, we describe in detail the main technical aspects of our method. The setup is shown in Fig. 3. As already mentioned, the NN-solver takes as inputs both the sampling of points of the independent variable u, and pairs of points (T, S) along the thermodynamic curve, each of them corresponding to different boundary conditions on the functions \u00c9 and VA. Let us describe some aspects of each input separately."}, {"title": "Independent variable generator", "content": "The independent variable u runs from the AdS boundary (u = 0) to the location of the black brane horizon (u = 1). Since this is the independent variable of the differential equations and one of the inputs of our model, we first need to sample it in such a way that it covers the range of interest. To do so, we have decided to select 48 points sampled using Chebyshev of the second kind nodes, that is, by placing a higher density of points near the endpoints of the interval. This results in a better resolution of the value of the functions near both boundaries.\nWe have also explored the possibility of sampling a different number of points, and using a different sampling technique. The main advantage of reducing the number of points in the u-direction is that the training process is faster but, in general, we obtain less precise solutions to the differential equations and, thus, a less precise reconstruction of the unknown potential. We have also explored the possibility of using an equally spaced distribution of points randomly displaced a small quantity (noise) at each training epoch. However, this sampling technique does not allow us to resolve the boundary region as well as with Chebyshev sampling and it results in slightly worse results."}, {"title": "Points on the equation of state", "content": "An important aspect regarding the inputs of the network is the number of points sampled along the S(T) curve. On the one hand, a large number of points will lead to long training times. On the other hand, a small number of points will not provide the network with enough information to reconstruct the potential correctly. We have found that the number of points that provides a good balance between training time and precise recovered poten-tials is in between 65 \u2013 70, sampled for values of the temperatures ranging from T/\u039b = 0 to T/\u039b ~ 0.6. This range of temperatures translates into a range of entropies from S/\u039b\u00b3 = 0 to S/\u039b\u00b3 ~ 30. The maximum value of the temperature is chosen so that it is higher than the transition/crossover temperature, which is Tc/\u039b ~ 0.4, but not so high as to generate too large a hierarchy for the values of the entropy density. Moreover, this sampling is not uniformly done for all values of the temperature. Instead, a higher density of points is chosen in the phase transition or crossover regions, as well as in the IR region of the curve see Fig. 4. The reason for this is that the UV region of the potential is easily constrained, whereas more precision is needed in order to resolve correctly the parts of the potential that control the transition and the IR physics."}, {"title": "Architecture and activations", "content": "As illustrated in Fig. 3, the architectures of each of the two NNs are different. The first one, NN-Solver, is composed of 6 different nets, each one of them taking u and the boundary conditions (T, S) as inputs and giving the solutions to the DEs as outputs. These nets have 3 hidden layers with 32 neurons each. The second NN, NN-V, acts as the scalar potential function V(\u00d8), taking the solution (u) coming from solving the DEs as input and giving the scalar potential as an output. This net is composed of 4 hidden layers with 16 neurons each. In summary, we have:\n[NN-Solver]i : [32, 32, 32]i, with i = 1,...,6;\nNN-V : [16, 16, 16, 16]\nWe have chosen the standard hyperbolic tangent, tanh(x), for the activation functions of all neurons in the ODE nets NN-Solver. In contrast, we use the Sigmoid-weighter Linear Unit function (SiLU, a.k.a. Swish), SiLU(x) = x(1 + e\u00afx)\u22121, as the activation for the neurons in the hidden layers of the potential net NN-V. The fact that the SiLU function is not bounded from above, as opposed to tanh(x), allows for more general behavior of the output V(\u00d8). This is a desirable property when predicting free-form functions that could a priori be extremely complicated, since they must reproduce the thermodynamics of a variety of different theories."}, {"title": "Gaussian localization in V-NN", "content": "We have developed a novel feature that we have dubbed \u201cGaussian localization\" (GL), pictorially shown in Fig. 3, that has improved the reconstructed potential. Here we will describe the method and in Sec. 6 we will discuss its effect. The NN-V network is composed of 4 layers whose response can be expressed as\nh\u2081 = SiLU {hi-1. WVi}, (4.6)\nwhere hi is the output vector of the i-th layer. In the case of h\u2081 (response of the first hidden layer of NN-V), ho = \u00d8, where \u00f8 is the scalar field that is one of the outputs of the solver network. WVi is the weight matrix (except WV0 which is a vector).\nThis general framework is modified as follows by our GL: we multiply the output given by (4.6) of the first hidden layer by a Gaussian function, resulting in\n$\\hat{h_1} = h_1 \\times exp \\Big [ - (\\frac{h_1 - \\mu}{\\sigma})^2 \\Big ]$, (4.7)\nwhere \u0125\u2081 the output vector of neurons of the first layer after the localization. The difference is thus that the Gaussian multiplies the output of the neurons from the 1st layer, which is (4.6) after passing it through the activation SiLU. The parameters \u03bc and \u03c3 are vectors of the means and standard deviations of the Gaussians corresponding to the localization"}, {"title": "Numerical tests", "content": "Here we perform two numerical checks of the model. First, we verify that the NN is solving the DEs correctly. For this purpose, rather than reconstructing the potential, we fix it to be one of the potentials in Fig. 2. Then we ask the NN-Solver to solve the direct problem with this potential, namely, to solve the system of ODEs (4.2) for three different points along the S(T)-curve. We then compare these solutions with their \"theoretical\" values obtained"}, {"title": "Results", "content": "We test our NN algorithm using boundary conditions associated to the S(T)-curves in Fig. 1. Different values of OM correspond to different theories with a crossover, a second- or a first-order phase transition. These differences are encoded in the different shapes of the thermodynamic curves S(T), as can be seen in Fig. 1. As explained in Secs. 2 and 4, we find solutions for the dependent variables \u03a3(u), A(u) and (u), one for each boundary condition, i.e. one for each point in S(T). These are solutions to the system of ODEs (4.2), which depends on the unknown potential V(\u00d8). This potential is the same for, and is informed about, all the boundary conditions, and we find it (necessarily) at the same time as the rest of the functions. We obtain the following results."}, {"title": "Loss function", "content": "Our method is based on minimizing the loss function (4.5). Fig. 5 shows the typical form of this function, in this case for the best run for the \u0444\u043c = 1 model, which possesses a first-order phase transition case. We see how L greatly decreases in the first half a million epochs and keeps doing so at an increasingly slower rate for the next 2.5 million epochs. It is interesting to note that, for our choice of hyperparameters, the 1.5% decrease in the learning rate every 5000 epochs (see Sec. 4.3.2) makes the training more efficient only up to a certain point, after which the learning rate becomes too small compared to the value"}, {"title": "Recovered potential and equation of state", "content": "In the top panels of Figs. 6, 7 and 8 we show the potentials produced by our method when supplied with the S(T) curves corresponding to theories with a crossover, a second- and a first-order phase transition, respectively. For each case, we run 10 realizations, and we select the best run as the one with the lowest value of the loss function. The resulting potentials for these best runs are shown as solid red curves in the figures. The remaining 9 runs are shown as dash-dotted green curves. The small dispersion between these curves illustrates the robustness of our method. Finally, the theoretical potentials (3.3) are shown as dashed blue curves. As is clear from the curves, the recovered potential is in general in excellent agreement with the exact one. For reasons discussed in Sec. 6, the precision of the recovery degrades as we move from a crossover to a second- to a first-order phase transition. We quantify this with the relative error\n|\u03b4V(\u03c6)| = \\frac{|V_{theory}(\u03c6) - V_{PINN}(\u03c6)|}{V_{theory}(\u03c6)}, (5.1)"}, {"title": "Solutions to the ODEs", "content": "The correct reconstruction of the potential requires solving the EKG accurately. Here we show the results for these solutions, namely, for the functions \u03a3(u), A(u) and (u). There is one solution for each boundary condition, i.e. for each point in S(T). We show these solutions for the theories with \u03c6M = 1 (Fig. 10) and \u03c6M = 5 (Fig. 11). For each theory, we show the solutions for 3 different points on the S(T) curve that correspond to high, intermediate and low temperature in the language of Sec. 4.5. We can see an excellent agreement for both theories between the \u201ctheoretical\" solutions (dash-dotted curves) and the NN-predicted ones (solid curves), with a mean squared error (MSE) of order 10-6 \u2013 10-5. Note that, since the functions \u03a3(u), A(u) and (u) take values of order unity in most of their domain, the square root of the MSE is a good measure of the relative error between the theoretical and the NN-reconstructed functions."}, {"title": "Discussion", "content": "Holography maps the quantum properties of a gauge theory in four dimensions to the classical properties of a gravitational theory in five dimensions. If the gravitational theory is known, the equation of state of the dual gauge theory can be found by solving a direct problem, i.e. by finding all the black hole solutions of the gravitational theory. The inverse problem, namely to determine a gravitational theory that gives rise to a prescribed equation of state, is much more challenging. We have shown that this problem can be solved using Physics Informed Neural Networks. The resulting algorithm reconstructs not just a specific black hole solution but the gravitational theory itself. We have illustrated the method in a simple setup in which the gravitational theory is completely specified by one function, the potential V(\u00d8) for a scalar field . However, we expect that the method can be generalized to gravitational theories with a general field content, as well as to inverse problems outside the holographic context involving highly non-linear partial differential equations.\nFigs. 6, 7 and 8 illustrate the reconstructed potentials, as well as the equations of state that they yield upon solving the direct problem with them. The quality of the results is quantified in Fig. 9, where we see that the relative error is at the sub-per cent level for the potential and of a few per cent for the equation of state. To obtain these results we provided the PINN with the boundary conditions (3.2) for the potential. These are encoded in the high-temperature behaviour (3.1) of the equation of state and correspond to the fact that the gauge theory is a CFT deformed by a relevant operator of dimension (2.5).\nWe have also trained the PINN without providing it with the boundary conditions (3.2) for the potential. In Fig. 12 we compare the results to those obtained by providing the PINN with (3.2) for the theory with \u03c6M = 1. We see that, when the PINN is not provided with (3.2), it is still able to recover the entire potential with high precision. In particular, it is able to identify the presence of a maximum in V(\u00d8) at \u00d8 = 0, and to estimate V(0) and V\u2033(0) with good precision. This means that not only does the PINN \"discover\" by itself the presence of an UV fixed point deformed by a relevant operator, but it also estimates with good precision the number of degrees of freedom at the fixed point, Nuv, and the dimension of the relevant operator, \u0394. These two quantities can be extracted from V(0) and V\u2033(0). Based on these, we find that the relative errors in the values reconstructed by the PINN are in the following ranges for theories with 1 < \u03c6M \u2264 5:\n10^{-6} \\leq \\frac{\\delta N_{UV}}{N_{UV}} \\leq 10^{-5}, \\qquad 10^{-3} \\leq \\frac{\\delta \\Delta}{\\Delta} \\leq 10^{-2}. (6.1)\nIn the case of V\u2033(0), this error is illustrated in Fig. 12(middle). Fig. 12(bottom) compares the reconstructed equations of state when the PINN is or is not provided with the boundary conditions (3.2). We see that the result is more precise in the first case. This illustrates the high sensitivity of the S(T) curve to the value of V\u2033(0) or, equivalently, to the dimension of the relevant operator that triggers the RG flow.\nOverall, we regard the results summarized in the previous paragraphs as a remarkable success given the challenges implied by the multi-entangled and multi-scale nature of the"}, {"title": "High-temperature behaviour", "content": "Consider a four-dimensional CFT deformed by a relevant operator of conformal dimen-sion A with source \u039b. The action takes the form\nS = SCFT + \u222b d\u2074x A O(x). (A.1)\nFor consistency, A must have dimension 4 - \u0394. For homogeneous, thermal equilibrium states, the trace Ward identity takes the form\nE - 3P = A <O>. (A.2)\nwith E and P the energy density and the pressure, respectively. The existence of a con-formal, UV fixed point implies that the trace of the stress tensor must vanish at leading order at high temperatures. In this limit, all thermodynamic quantities scale with the temperature as dictated by dimensional analysis, so we have:\nE \u223c 3P \u223c T\u2074. (A.3)\nAssuming that <O> vanishes in the undeformed theory, its value at leading order in the deformed theory must be linear in the deformation parameter A, i.e.\n<O> \u221d A T^{2\u0394-4} (A.4)\nwhere the power of T is fixed by dimensional analysis. Through the Ward identity (A.2), this fixes the leading-order correction to the asymptotic behaviour (A.3) and, together with the thermodynamic identity S = \u2202P/\u2202T, it results in the entropy density\nS = c\u2081 T\u00b3 + c\u2082 T^{2\u0394-5} + ... (A.5)\nwhere c\u2081, c\u2082 are numerical coefficients. The main conclusion is that the dimension of the operator responsible for triggering the flow is encoded in the thermodynamic curve S(T). In particular, A can be extracted from the subleading term in the high-temperature expansion of the equation of state."}]}