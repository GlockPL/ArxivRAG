{"title": "Faster Optimal Coalition Structure Generation via Offline Coalition Selection and Graph-Based Search", "authors": ["Redha Taguelmimt", "Samir Aknine", "Djamila Boukredera", "Narayan Changder", "Tuomas Sandholm"], "abstract": "Coalition formation is a key capability in multi-agent systems. An important problem in coalition formation is coalition structure generation: partitioning agents into coalitions to optimize the social welfare. This is a challenging problem that has been the subject of active research for the past three decades. In this paper, we present a novel algorithm, SMART, for the problem based on a hybridization of three innovative techniques. Two of these techniques are based on dynamic programming, where we show a powerful connection between the coalitions selected for evaluation and the performance of the algorithms. These algorithms use offline phases to optimize the choice of coalitions to evaluate. The third one uses branch-and-bound and integer partition graph search to explore the solution space. Our techniques bring a new way of approaching the problem and a new level of precision to the field. In experiments over several common value distributions, we show that the hybridization of these techniques in SMART is faster than the fastest prior algorithms (ODP-IP, BOSS) in generating optimal solutions across all the value distributions.", "sections": [{"title": "1 Introduction", "content": "One of the main challenges in coalition formation is the coalition structure generation (CSG) problem: partitioning the agents into disjoint exhaustive coalitions so as to maximize social welfare. (A coalition structure is a partitioning of agents into coalitions.) This is a central problem in artificial intelligence and game theory that captures a number of important applications such as collaboration among trucking companies [Sandholm and Lesser, 1997], distributed sensor networks [Dang et al., 2006], etc.\nMany algorithms have been developed for this problem. Dynamic programming algorithms [Yeh, 1986; Rahwan and Jennings, 2008;\nMichalak et al., 2016;\nChangder et al., 2019; Taguelmimt et al., 2022b] find an optimal solution if it is computationally feasible to run them to completion. Anytime algorithms [Sandholm et al., 1999; Dang and Jennings, 2004;\nRahwan et al., 2009;\nUeda et al., 2010; Taguelmimt et al., 2022a] pro-vide intermediate solutions during the execution and allow premature termination. Heuristic algorithms [Sen and Dutta, 2000;\nUeda et al., 2010;\nKrausburg et al., 2021; Taguelmimt et al., 2021a] focus on speed and do not guarantee that an optimal solution is found.\nEven though those algorithms perform well in practice in some cases, hybrid algorithms [Michalak et al., 2016; Changder et al., 2020;\nChangder et al., 2021;\nTaguelmimt et al., 2023; Taguelmimt et al., 2024] that combine dynamic programming with integer partition graph search have emerged as the dominant approach to find optimal solutions to this problem. The fastest exact algorithms to date are hybrid solutions called ODP-IP [Michalak et al., 2016], ODSS [Changder et al., 2020], and BOSS\n[Changder et al., 2021] that com-bine IDP [Rahwan and Jennings, 2008] and IP [Rahwan et al., 2009]. IDP is based on dynamic programming and computes the optimal solution for n agents by computing an optimal partition of all the coalitions C of size $|C| \\in \\{2, ..., 27, n\\}$. In contrast, IP uses an integer representation of the search space and computes the optimal solution by traversing in a depth-first manner multiple search trees and uses branch-and-bound to speed up the search. However, the worst-case run time of the state-of-the-art hybrid algorithms is determined by their respective dynamic programming parts, which still need improvement. Also, the hybridization of IDP and IP in these algorithms relies heavily on the effectiveness of IP. Thus, the time required by the algorithms grows considerably when IP is not fast enough."}, {"title": "2 Preliminaries", "content": "The input to a CSG problem is a set of agents A and a characteristic function v. We say that a CSG problem $A = \\{a_1, a_2,..., a_n\\}$ is of size n. A coalition C in A is any non-empty subset of A. The size of C is |C|, which is the number of agents it contains. A size set is a set of coalition sizes. In a CSG problem, a characteristic function v assigns a real value to each coalition C. A coalition structure CS is a partition of the set of agents A into disjoint coalitions. Given a set of non-empty coalitions $\\{C_1, C_2, ..., C_k\\}$, $CS = \\{C_1, C_2, ..., C_k\\}$, where k = |CS|, $\\bigcup_{i=1}^{k} C_i = A$ and for all i, j \u2208 {1, 2, ..., k} where i \u2260 j, $C_i \u2229 C_j = \u00d8$. \u03a0(A) denotes the set of all coalition structures. The value of a coalition structure CS is $V(CS) = \\sum_{C \\in CS} v(C)$. The optimal solution of the CSG problem is the most valuable coalition structure $CS^* \\in \\Pi(A)$, that is, $CS^* = \\text{argmax}_{CS \\in \\Pi(A)}V(CS)$.\nThe integer partition graph [Rahwan et al., 2007] divides the search space into subspaces that are represented by integer partitions of n. Given n agents, each integer partition of n is represented by a node, where the nodes are divided into levels. Each level $l \\in \\{1, 2, .., n\\}$ contains nodes representing integer partitions of n that contain l parts. For instance, level 3 contains nodes where integer partitions of n have 3 parts. Two adjacent nodes are connected if the integer partition in level l can be reached from the one in level l-1 by splitting only an integer. Each integer partition P represents a set of coalition structures in which the sizes of the coalitions match the parts of P. For example, the node [1,1,2] represents all coalition structures that contain two coalitions of size 1 and one coalition of size 2."}, {"title": "3 SMART: A Novel CSG Algorithm", "content": "The SMART algorithm is based on three techniques (CDP, GRAD and DIPS) that combine dynamic programming with integer partition graph search. SMART introduces new ways of searching the integer partition graph of solutions.\n3.1 Complementarity-Based Dynamic\nProgramming (CDP)\nCDP is an algorithm that determines the optimal coalition structure. To compute the optimal structure, CDP evaluates different sets of coalitions through two processes , and computes the best partition of each coalition, meaning the best way to split it into potentially multiple subcoalitions. The highest valued coalition structure returned by these processes is an optimal solution. To determine the coalitions to evaluate (that is, for which to compute the best partitions) and ensure that the optimal solution is found, the CDP algorithm uses an offline phase of preprocessing. This phase defines the best pair of coalition size sets to evaluate, such that when combined, the entire solution space is searched. This means that by evaluating these specific sets of coalitions, the CDP algorithm can guarantee that it has considered every possible grouping of agents.\nCDP's Offline Phase\nThe offline phase is one of the key components of the CDP algorithm, which is responsible for determining the coalitions to evaluate in the two processes of the algorithm. This is done by considering the coalition sizes, as illustrated on the integer"}, {"title": "Algorithm 1: Size Sets Definition (SSD) Algorithm", "content": "These steps are all executed offline, meaning that we run the SSD algorithm only once for each problem size n (not once for each problem instance) to set up CDP. For example with ten agents, the best pair of coalition size sets that SSD returns is BS1 = {2,4,6,10} and BS2 = {2, 8, 10}, which together search all the subspaces.\nCDP's Online Phase\nThe CDP algorithm uses these sets to compute the optimal coalition structure each time a problem instance is to be solved. CDP starts, in a first step, by constructing two tables, the partition table Pt that stores the optimal partition of each coalition C in Pt(C) and the value table Vt that stores the optimal value of each coalition C in Vt(C). Pt(C) and Vt(C) are computed for each coalition C by evaluating all possible ways of splitting C into two coalitions and checking whether it is beneficial to split it or not. For example, for a coalition of size 4, we evaluate its splitting into a coalition of size 1 and a coalition of size 3 (4=1+3) and into two coalitions of size 2 (4=2+2). This evaluation is done by the two CDP processes, which each consider the coalitions whose sizes belong to the sets returned by SSD. In each process, CDP starts evaluating the smallest coalitions first, as the result of this evaluation is used for evaluating larger coalitions (see Algorithms 2 and 3). In a second step, each process of CDP computes the best"}, {"title": "Theorem 1", "content": "Theorem 1 establishes that when considering any pair of coalition size sets, the presence of a path between each node and the bottom node in one of the two integer partition graphs associated with the respective size sets guarantees finding an optimal coalition structure.\nTheorem 1. When considering any pair of coalition size sets to evaluate, if there is a path between each node and the bottom node of one of the two integer partition graphs generated by the two size sets, CDP will fully search the solution subspaces. Thus it finds an optimal coalition structure.\nProof. The splitting operations of CDP are represented with edges in the integer partition graph . An edge that connects two adjacent nodes, and results from splitting an integer x into two, represents the evaluation of all coalitions of size x by CDP. If there is a path between the bottom node of the integer partition graph and a node N, then all the coalitions that need to be split to find the best solution in N are evaluated. As all the nodes are at least connected to one of the bottom nodes of the two integer partition graphs generated by the pair of size sets, CDP fully searches each subspace. \u03a0\nAlgorithms 2 and 3 detail the pseudocode of CDP. CDP runs in parallel on the two coalition size sets obtained from the offline phase. In Algorithm 3, CDP computes the optimal coalition structure that belongs to the subspaces searched considering each set. Then, the optimal solution is the highest valued solution of the two (see lines 3-7 of Algorithm 2)."}, {"title": "3.2 Gradual Search with Dynamic Programming (GRAD)", "content": "The GRAD algorithm uses multiple parallel processes to search for the optimal solution, each with a set of coalition sizes as input with which it explores a certain percentage of the search space. These percentages that we detail in Section 6 are hyperparameters that can be adjusted to fine-tune the algorithm.\nGRAD's Offline Phase\nGRAD also uses an offline phase to compute, for each considered percentage w, the best coalition size set that allows one to search this percentage of subspaces with the shortest run time. To find these sets, we introduce the Size Optimization for different percenTages (SOFT) algorithm. For each size set S, SOFT constructs the corresponding integer partition graph Gs by only dividing the integers that belong to the set S. Gs is thus partial, as shown in the example of Figure 2. If this number of generated nodes in Gs is at least an w fraction of the total number of subspaces and S minimizes the run time, then S becomes the best set. Algorithm 4 shows how SOFT computes the best coalition size sets. For example with n = 10 agents and w = 90%, the best coalition size set that SOFT returns is {2, 4, 6, 10}; it searches 92.86% of subspaces.\nGRAD's Online Phase\nOnce these size sets are computed by the SOFT algorithm, each process of GRAD is tuned with the corresponding size set. To solve the problems, GRAD builds a partial integer partition graph with all subspaces and no edges and launches each process with its size set and this partial graph as input . Each process of GRAD evaluates all the coalitions whose sizes belong to the best size set obtained from the offline phase and computes their best partitions. The GRAD process evaluates all possible ways of splitting each coalition of the selected sizes into two coalitions and tests whether it is beneficial to split or not. The coalitions are evaluated starting with the smallest ones (Figure 2.a). The result of this evaluation is stored in the partition table Pt and the value table Vt. Once all the coalitions have been evaluated, the GRAD process returns the best coalition structure among the searched subspaces. This is determined by computing the best partition of the grand coalition A using the partition and value tables generated during the evaluation process.\nWhen the optimal solution is in the subspaces explored by a process of GRAD that searches a specific percentage of sub-"}, {"title": "3.3 Distributed Integer Partition Graph Search (DIPS)", "content": "DIPS searches the solution subspaces using the integer partition graph. First, DIPS computes the upper bounds of the subspaces and searches them based on their upper bounds. Then, whenever a CDP or GRAD process finishes, while there are still unexplored nodes, DIPS uses that process for a different problem space to parallelize its search. The new process uses the same search technique in DIPS. Thus, the subspaces of"}, {"title": "4 Hybridization: The SMART Algorithm", "content": "We combine CDP, GRAD, and DIPS to make the coalition-Size optiMization and subspAce ReconfiguraTion (SMART) algorithm. Initially, SMART sorts the subspaces by their upper bounds. The DIPS algorithm starts searching with the subspace that has the highest upper bound. Then, DIPS prunes out the subspaces that are either already searched by CDP or GRAD, or that do not have a better upper bound than the last best solution found. CDP and GRAD evaluate the coalitions of the computed sizes obtained from their respective offline phases and allow subspace pruning through intermediate solutions. Whenever a process in CDP or GRAD finishes evaluating the coalitions of any size, they prune out the subspaces that are connected to the bottom node of the integer partition graph through a series of edges because the optimal coalition structure among these subspaces is found by CDP or GRAD. Hence, DIPS does not need to search them.\nAlgorithm 7 shows the pseudocode of SMART. We now introduce the following results.\nLemma 1. CDP is faster than or at least as fast as IDP.\nProof. Let SIDP be the set of sizes used by IDP [Rahwan and Jennings, 2008]. SIDP is hand tuned and is always equal to {2, 3, .., 27, n} for n agents. Let S\u2081"}, {"title": "Theorem 2", "content": "Theorem 2. In the worst case, SMART is faster than or at least as fast as ODP-IP, ODSS, and BOSS.\nProof. SMART uses the CDP algorithm, which relies on having the best pair of coalition size sets that enables fast search of optimal results. By Lemma 1, CDP is faster than IDP. Recall that the fastest exact algorithms are the hybrid solutions, ODP-IP, ODSS, and BOSS, that combine IDP and an integer partition-based algorithm. However, this combination is highly dependent on the efficiency of the integer partition-based algorithm, which in the worst case requires searching all the coalition structures in O(nn) time [Rahwan et al., 2009], which is infeasible in a reasonable time. Thus, in the worst case, the run time of such hybrid algorithms is determined by the dynamic programming approach. Hence, for hard problems, SMART represents the fastest solution as the dynamic programming algorithm used (CDP) is faster than IDP used by the other algorithms. Formally, let TSMART be the time complexity of SMART, where $TSMART = min(O(n^n), time(GRAD), time(CDP)) < time(CDP)$ and let Tother be the time complexity of the other algorithms, where Tother = min(O(n\"), time(IDP)) = time(IDP). Given that time(CDP) < time(IDP) by Lemma 1, TSMART < Tother. \u03a0\nThe result of this hybridization is threefold: (1) CDP is faster than the dynamic programming algorithm IDP (results reported in Section 6). This allows SMART to be faster in the worst case than the state-of-the-art algorithms ODP-IP [Michalak et al., 2016] and BOSS [Changder et al., 2021] because the CDP part of SMART is faster than the IDP algorithm used by ODP-IP and BOSS, and the worst case time performance of these algorithms is determined by their dynamic programming parts; (2) GRAD gradually searches the best size sets for each percentage of solution subspaces. This allows SMART to reach the number of subspaces needed to guarantee finding an optimal solution with the best run time; (3) The integer partitions are distributed among several processes, enabling an efficient and faster search in the integer partition graph.\""}, {"title": "5 Analysis of SMART", "content": "In this section, we prove that the SMART algorithm is complete in Theorem 3. Then, we analyze the computational complexity of the algorithms in detail.\nTheorem 3. The SMART algorithm always finds the optimal solution.\nProof. Each node in the integer partition graph is searched by SMART using the CDP, GRAD, and DIPS algorithms. A node represents a subspace, which contains a number of coalition structures that match the parts of the subspace. The SMART algorithm returns the final solution when all nodes have been searched or pruned. For a particular node that contains the optimal coalition structure, the only way for SMART not to search it is for DIPS or GRAD to prune it without any of the three algorithms searching it. However, DIPS or GRAD will only prune nodes that have no chance of containing the optimal solution. Thus, such a node would never be pruned, and one of the three algorithms would always completely search the node that contains an optimal solution. \u03a0\nTime complexity of the SSD algorithm. For each problem size n, the SSD algorithm tests all possible pairs of coalition size sets. For each set of coalition sizes, SSD reconstructs the integer partition graph by dividing only the integers that belong to that set and tests whether it is beneficial to pair that set with another set or not. To test this for one set, CDP pairs it with all the other sets. The total number of sets that SSD evaluates is 2n-2 \u2212 1. We denote by I(s) the number of integer splits performed for a set s and by p(n, s), the number of subspaces generated by the set s. The total number of operations performed by SSD for one set is $T(n) = \\sum_{s=1}^{2^{n-2}} I(s) = \\sum_{s=1}^{2^{n-2}} \\sum_{N} I(N, s)$, where I(N, s) is the number of integer splits performed on node N. The number of splits into two for a certain integer i is n, the highest integer to split is n, and the highest possible number of integers in a single node is n, which is the number of integers of the node that represents the singleton coalition structure. Thus, $I(N,s) \u2264 n \u00d7 \\binom{n}{s}$, and $T(n) \u2264 \\sum_{s=1}^{2^{n-2}} \\sum_{s=1}^{2^{n-2}} p(n, s) \u00d7 n \u00d7 \\binom{n}{s}$. However, the growth rate of the number of nodes in the integer partition graph, which is the same as the growth rate of integer partitions of n, is is $O(\\frac{1}{n})$ [Wilf, 2000]. Hence, $T(n) \u2264 \\sum_{s=1}^{2^{n-2}} \\sum_{s=1}^{2^{n-2}} O(\\frac{1}{\\sqrt{n}}) \u00d7 n \u00d7 \\binom{n}{s} \\leq (2^{n-2} \u2212 1) \u00d7 \\sum_{s=1}^{2^{n-2}} O(\\frac{1}{\\sqrt{n}}) \u00d7 n \u00d7 \\binom{n}{s}$. As a result, the total number of operations of SSD when testing one set is $O(n^2 \\frac{1}{\\sqrt{n}} \\times 2^n \u00d7 \\sqrt{n})$. SSD tests $2^{n-2} - 1$ different sets. Thus, the time complexity of SSD is $O(2^{2n} \\frac{1}{n^2} \\times \\frac{2^n}{\\sqrt{n}})$.\nTime complexity of the SMART algorithm. SMART combines three algorithms-CDP, GRAD, and DIPS, and runs them in parallel. The worst-case run time of dynamic programming on this problem is $O(3^n)$ [Yeh, 1986]. CDP and GRAD are based on dynamic programming. They run in parallel on several sets of sizes and terminate when all sets are fully evaluated. Thus, the time complexity of both CDP and GRAD is O(3", "min(O(3": "O(3", "O(3": "."}, {"title": "6 Empirical Evaluation", "content": "We now evaluate the effectiveness of SMART by comparing it to the prior state-of-the-art algorithms ODP-IP and BOSS. We implemented SMART in Java and for ODP-IP and BOSS, we used the codes provided by their authors for the comparisons. They are also written in Java. The algorithms were run on an Intel Xeon 2.30GHz E5-2650 CPU with 256GB of RAM. For GRAD, we considered values of w \u2208 {10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%}. We also designed and tested a different version of ODP-IP, namely POI (Parallel ODP-IP), that we developed to integrate parallelism in the baseline version of ODP-IP in order to improve its performance. It uses the same number of processes as SMART (see the appendix for more details). This does not affect the theoretical guarantees but improves the practical performances of the algorithm.\nWe conducted the experiments on common benchmark problems. We show results on nine value distributions. Results on other distributions are in the appendix. We compared the algorithms using the following value distributions: Modified Normal [Rahwan et al., 2012], Beta, Exponential, Gamma [Michalak et al., 2016], Normal [Rahwan et al., 2007], Uniform [Larson and Sandholm, 2000], Modified Uniform [Service and Adams, 2010], Zipf, SVA Beta and Weibull [Changder et al., 2020]. The experiments shown in the remainder of the paper are also representative of those in the appendix. For each distribution and number of agents, we ran each algorithm 50 times. Figure 4 reports the run times of SMART, BOSS, ODP-IP and POI. On all distributions, SMART was the fastest for all numbers of agents. For example, after 2 seconds, with the Normal distribution for 24 agents, SMART returns optimal solutions roughly 92% faster than BOSS, 91% faster than ODP-IP and 54% faster than POI, while outperforming them by multiple orders of magnitude as can be seen in Figure 4. The reason for this is twofold. First, when problems are hard to solve (see, for instance, the results for Exponential), the CDP part of SMART finishes before the other algorithms as it presents the best worst-case time performance. The second reason is that for problems where the search of a specific percentage of the solution subspaces is sufficient to find the optimal solution, the combination of GRAD and DIPS achieves the best run time. On one hand, GRAD searches that percentage of subspaces with the best run time. On the other hand, DIPS distributes the search to further accelerate it. Notice that the relative contribution of each technique depends on the specific problem instance. Generally, for easier-to-solve instances, DIPS and GRAD play a more significant role in finding the optimal solution, as they target specific subspaces with the upper bound for DIPS and percentages for GRAD. As the problem becomes more difficult, CDP becomes increasingly important for searching a larger portion of the solution space, as it aims to search the entire solution space. In the worst-case scenario, CDP is the fastest technique to search the entire solution space. Hence, all algorithms have a goal and help each other achieve it as explained in Section 4. Additional experimental insights are described in the appendix.\nWe also report the empirical performance of CDP, which, as discussed earlier in this paper, determines the worst-case run time of SMART. We compared CDP to the dynamic pro-gramming algorithm IDP [Rahwan and Jennings, 2008] used by prior hybrid algorithms, and to the fastest dynamic pro-"}, {"title": "7 Conclusion", "content": "In this paper, we developed an optimal algorithm, SMART, for the coalition structure generation problem. Our method"}, {"title": "A Related Work", "content": "In this appendix"}, {"title": "Faster Optimal Coalition Structure Generation via Offline Coalition Selection and Graph-Based Search", "authors": ["Redha Taguelmimt", "Samir Aknine", "Djamila Boukredera", "Narayan Changder", "Tuomas Sandholm"], "abstract": "Coalition formation is a key capability in multi-agent systems. An important problem in coalition formation is coalition structure generation: partitioning agents into coalitions to optimize the social welfare. This is a challenging problem that has been the subject of active research for the past three decades. In this paper, we present a novel algorithm, SMART, for the problem based on a hybridization of three innovative techniques. Two of these techniques are based on dynamic programming, where we show a powerful connection between the coalitions selected for evaluation and the performance of the algorithms. These algorithms use offline phases to optimize the choice of coalitions to evaluate. The third one uses branch-and-bound and integer partition graph search to explore the solution space. Our techniques bring a new way of approaching the problem and a new level of precision to the field. In experiments over several common value distributions, we show that the hybridization of these techniques in SMART is faster than the fastest prior algorithms (ODP-IP, BOSS) in generating optimal solutions across all the value distributions.", "sections": [{"title": "1 Introduction", "content": "One of the main challenges in coalition formation is the coalition structure generation (CSG) problem: partitioning the agents into disjoint exhaustive coalitions so as to maximize social welfare. (A coalition structure is a partitioning of agents into coalitions.) This is a central problem in artificial intelligence and game theory that captures a number of important applications such as collaboration among trucking companies [Sandholm and Lesser, 1997], distributed sensor networks [Dang et al., 2006], etc.\nMany algorithms have been developed for this problem. Dynamic programming algorithms [Yeh, 1986; Rahwan and Jennings, 2008;\nMichalak et al., 2016;\nChangder et al., 2019; Taguelmimt et al., 2022b] find an optimal solution if it is computationally feasible to run them to completion. Anytime algorithms [Sandholm et al., 1999; Dang and Jennings, 2004;\nRahwan et al., 2009;\nUeda et al., 2010; Taguelmimt et al., 2022a] pro-vide intermediate solutions during the execution and allow premature termination. Heuristic algorithms [Sen and Dutta, 2000;\nUeda et al., 2010;\nKrausburg et al., 2021; Taguelmimt et al., 2021a] focus on speed and do not guarantee that an optimal solution is found.\nEven though those algorithms perform well in practice in some cases, hybrid algorithms [Michalak et al., 2016; Changder et al., 2020;\nChangder et al., 2021;\nTaguelmimt et al., 2023; Taguelmimt et al., 2024] that combine dynamic programming with integer partition graph search have emerged as the dominant approach to find optimal solutions to this problem. The fastest exact algorithms to date are hybrid solutions called ODP-IP [Michalak et al., 2016], ODSS [Changder et al., 2020], and BOSS\n[Changder et al., 2021] that com-bine IDP [Rahwan and Jennings, 2008] and IP [Rahwan et al., 2009]. IDP is based on dynamic programming and computes the optimal solution for n agents by computing an optimal partition of all the coalitions C of size $|C| \\in \\{2, ..., 27, n\\}$. In contrast, IP uses an integer representation of the search space and computes the optimal solution by traversing in a depth-first manner multiple search trees and uses branch-and-bound to speed up the search. However, the worst-case run time of the state-of-the-art hybrid algorithms is determined by their respective dynamic programming parts, which still need improvement. Also, the hybridization of IDP and IP in these algorithms relies heavily on the effectiveness of IP. Thus, the time required by the algorithms grows considerably when IP is not fast enough."}, {"title": "2 Preliminaries", "content": "The input to a CSG problem is a set of agents A and a characteristic function v. We say that a CSG problem $A = \\{a_1, a_2,..., a_n\\}$ is of size n. A coalition C in A is any non-empty subset of A. The size of C is |C|, which is the number of agents it contains. A size set is a set of coalition sizes. In a CSG problem, a characteristic function v assigns a real value to each coalition C. A coalition structure CS is a partition of the set of agents A into disjoint coalitions. Given a set of non-empty coalitions $\\{C_1, C_2, ..., C_k\\}$, $CS = \\{C_1, C_2, ..., C_k\\}$, where k = |CS|, $\\bigcup_{i=1}^{k} C_i = A$ and for all i, j \u2208 {1, 2, ..., k} where i \u2260 j, $C_i \u2229 C_j = \u00d8$. \u03a0(A) denotes the set of all coalition structures. The value of a coalition structure CS is $V(CS) = \\sum_{C \\in CS} v(C)$. The optimal solution of the CSG problem is the most valuable coalition structure $CS^* \\in \\Pi(A)$, that is, $CS^* = \\text{argmax}_{CS \\in \\Pi(A)}V(CS)$.\nThe integer partition graph [Rahwan et al., 2007] divides the search space into subspaces that are represented by integer partitions of n. Given n agents, each integer partition of n is represented by a node, where the nodes are divided into levels. Each level $l \\in \\{1, 2, .., n\\}$ contains nodes representing integer partitions of n that contain l parts. For instance, level 3 contains nodes where integer partitions of n have 3 parts. Two adjacent nodes are connected if the integer partition in level l can be reached from the one in level l-1 by splitting only an integer. Each integer partition P represents a set of coalition structures in which the sizes of the coalitions match the parts of P. For example, the node [1,1,2] represents all coalition structures that contain two coalitions of size 1 and one coalition of size 2."}, {"title": "3 SMART: A Novel CSG Algorithm", "content": "The SMART algorithm is based on three techniques (CDP, GRAD and DIPS) that combine dynamic programming with integer partition graph search. SMART introduces new ways of searching the integer partition graph of solutions.\n3.1 Complementarity-Based Dynamic\nProgramming (CDP)\nCDP is an algorithm that determines the optimal coalition structure. To compute the optimal structure, CDP evaluates different sets of coalitions through two processes , and computes the best partition of each coalition, meaning the best way to split it into potentially multiple subcoalitions. The highest valued coalition structure returned by these processes is an optimal solution. To determine the coalitions to evaluate (that is, for which to compute the best partitions) and ensure that the optimal solution is found, the CDP algorithm uses an offline phase of preprocessing. This phase defines the best pair of coalition size sets to evaluate, such that when combined, the entire solution space is searched. This means that by evaluating these specific sets of coalitions, the CDP algorithm can guarantee that it has considered every possible grouping of agents.\nCDP's Offline Phase\nThe offline phase is one of the key components of the CDP algorithm, which is responsible for determining the coalitions to evaluate in the two processes of the algorithm. This is done by considering the coalition sizes, as illustrated on the integer"}, {"title": "Algorithm 1: Size Sets Definition (SSD) Algorithm", "content": "These steps are all executed offline, meaning that we run the SSD algorithm only once for each problem size n (not once for each problem instance) to set up CDP. For example with ten agents, the best pair of coalition size sets that SSD returns is BS1 = {2,4,6,10} and BS2 = {2, 8, 10}, which together search all the subspaces.\nCDP's Online Phase\nThe CDP algorithm uses these sets to compute the optimal coalition structure each time a problem instance is to be solved. CDP starts, in a first step, by constructing two tables, the partition table Pt that stores the optimal partition of each coalition C in Pt(C) and the value table Vt that stores the optimal value of each coalition C in Vt(C). Pt(C) and Vt(C) are computed for each coalition C by evaluating all possible ways of splitting C into two coalitions and checking whether it is beneficial to split it or not. For example, for a coalition of size 4, we evaluate its splitting into a coalition of size 1 and a coalition of size 3 (4=1+3) and into two coalitions of size 2 (4=2+2). This evaluation is done by the two CDP processes, which each consider the coalitions whose sizes belong to the sets returned by SSD. In each process, CDP starts evaluating the smallest coalitions first, as the result of this evaluation is used for evaluating larger coalitions (see Algorithms 2 and 3). In a second step, each process of CDP computes the best"}, {"title": "Theorem 1", "content": "Theorem 1 establishes that when considering any pair of coalition size sets, the presence of a path between each node and the bottom node in one of the two integer partition graphs associated with the respective size sets guarantees finding an optimal coalition structure.\nTheorem 1. When considering any pair of coalition size sets to evaluate, if there is a path between each node and the bottom node of one of the two integer partition graphs generated by the two size sets, CDP will fully search the solution subspaces. Thus it finds an optimal coalition structure.\nProof. The splitting operations of CDP are represented with edges in the integer partition graph . An edge that connects two adjacent nodes, and results from splitting an integer x into two, represents the evaluation of all coalitions of size x by CDP. If there is a path between the bottom node of the integer partition graph and a node N, then all the coalitions that need to be split to find the best solution in N are evaluated. As all the nodes are at least connected to one of the bottom nodes of the two integer partition graphs generated by the pair of size sets, CDP fully searches each subspace. \u03a0\nAlgorithms 2 and 3 detail the pseudocode of CDP. CDP runs in parallel on the two coalition size sets obtained from the offline phase. In Algorithm 3, CDP computes the optimal coalition structure that belongs to the subspaces searched considering each set. Then, the optimal solution is the highest valued solution of the two (see lines 3-7 of Algorithm 2)."}, {"title": "3.2 Gradual Search with Dynamic Programming (GRAD)", "content": "The GRAD algorithm uses multiple parallel processes to search for the optimal solution, each with a set of coalition sizes as input with which it explores a certain percentage of the search space. These percentages that we detail in Section 6 are hyperparameters that can be adjusted to fine-tune the algorithm.\nGRAD's Offline Phase\nGRAD also uses an offline phase to compute, for each considered percentage w, the best coalition size set that allows one to search this percentage of subspaces with the shortest run time. To find these sets, we introduce the Size Optimization for different percenTages (SOFT) algorithm. For each size set S, SOFT constructs the corresponding integer partition graph Gs by only dividing the integers that belong to the set S. Gs is thus partial, as shown in the example of Figure 2. If this number of generated nodes in Gs is at least an w fraction of the total number of subspaces and S minimizes the run time, then S becomes the best set. Algorithm 4 shows how SOFT computes the best coalition size sets. For example with n = 10 agents and w = 90%, the best coalition size set that SOFT returns is {2, 4, 6, 10}; it searches 92.86% of subspaces.\nGRAD's Online Phase\nOnce these size sets are computed by the SOFT algorithm, each process of GRAD is tuned with the corresponding size set. To solve the problems, GRAD builds a partial integer partition graph with all subspaces and no edges and launches each process with its size set and this partial graph as input . Each process of GRAD evaluates all the coalitions whose sizes belong to the best size set obtained from the offline phase and computes their best partitions. The GRAD process evaluates all possible ways of splitting each coalition of the selected sizes into two coalitions and tests whether it is beneficial to split or not. The coalitions are evaluated starting with the smallest ones (Figure 2.a). The result of this evaluation is stored in the partition table Pt and the value table Vt. Once all the coalitions have been evaluated, the GRAD process returns the best coalition structure among the searched subspaces. This is determined by computing the best partition of the grand coalition A using the partition and value tables generated during the evaluation process.\nWhen the optimal solution is in the subspaces explored by a process of GRAD that searches a specific percentage of sub-"}, {"title": "3.3 Distributed Integer Partition Graph Search (DIPS)", "content": "DIPS searches the solution subspaces using the integer partition graph. First, DIPS computes the upper bounds of the subspaces and searches them based on their upper bounds. Then, whenever a CDP or GRAD process finishes, while there are still unexplored nodes, DIPS uses that process for a different problem space to parallelize its search. The new process uses the same search technique in DIPS. Thus, the subspaces of"}, {"title": "4 Hybridization: The SMART Algorithm", "content": "We combine CDP, GRAD, and DIPS to make the coalition-Size optiMization and subspAce ReconfiguraTion (SMART) algorithm. Initially, SMART sorts the subspaces by their upper bounds. The DIPS algorithm starts searching with the subspace that has the highest upper bound. Then, DIPS prunes out the subspaces that are either already searched by CDP or GRAD, or that do not have a better upper bound than the last best solution found. CDP and GRAD evaluate the coalitions of the computed sizes obtained from their respective offline phases and allow subspace pruning through intermediate solutions. Whenever a process in CDP or GRAD finishes evaluating the coalitions of any size, they prune out the subspaces that are connected to the bottom node of the integer partition graph through a series of edges because the optimal coalition structure among these subspaces is found by CDP or GRAD. Hence, DIPS does not need to search them.\nAlgorithm 7 shows the pseudocode of SMART. We now introduce the following results.\nLemma 1. CDP is faster than or at least as fast as IDP.\nProof. Let SIDP be the set of sizes used by IDP [Rahwan and Jennings, 2008]. SIDP is hand tuned and is always equal to {2, 3, .., 27, n} for n agents. Let S\u2081"}, {"title": "Theorem 2", "content": "Theorem 2. In the worst case, SMART is faster than or at least as fast as ODP-IP, ODSS, and BOSS.\nProof. SMART uses the CDP algorithm, which relies on having the best pair of coalition size sets that enables fast search of optimal results. By Lemma 1, CDP is faster than IDP. Recall that the fastest exact algorithms are the hybrid solutions, ODP-IP, ODSS, and BOSS, that combine IDP and an integer partition-based algorithm. However, this combination is highly dependent on the efficiency of the integer partition-based algorithm, which in the worst case requires searching all the coalition structures in O(nn) time [Rahwan et al., 2009], which is infeasible in a reasonable time. Thus, in the worst case, the run time of such hybrid algorithms is determined by the dynamic programming approach. Hence, for hard problems, SMART represents the fastest solution as the dynamic programming algorithm used (CDP) is faster than IDP used by the other algorithms. Formally, let TSMART be the time complexity of SMART, where $TSMART = min(O(n^n), time(GRAD), time(CDP)) < time(CDP)$ and let Tother be the time complexity of the other algorithms, where Tother = min(O(n\"), time(IDP)) = time(IDP). Given that time(CDP) < time(IDP) by Lemma 1, TSMART < Tother. \u03a0\nThe result of this hybridization is threefold: (1) CDP is faster than the dynamic programming algorithm IDP (results reported in Section 6). This allows SMART to be faster in the worst case than the state-of-the-art algorithms ODP-IP [Michalak et al., 2016] and BOSS [Changder et al., 2021] because the CDP part of SMART is faster than the IDP algorithm used by ODP-IP and BOSS, and the worst case time performance of these algorithms is determined by their dynamic programming parts; (2) GRAD gradually searches the best size sets for each percentage of solution subspaces. This allows SMART to reach the number of subspaces needed to guarantee finding an optimal solution with the best run time; (3) The integer partitions are distributed among several processes, enabling an efficient and faster search in the integer partition graph.\""}, {"title": "5 Analysis of SMART", "content": "In this section, we prove that the SMART algorithm is complete in Theorem 3. Then, we analyze the computational complexity of the algorithms in detail.\nTheorem 3. The SMART algorithm always finds the optimal solution.\nProof. Each node in the integer partition graph is searched by SMART using the CDP, GRAD, and DIPS algorithms. A node represents a subspace, which contains a number of coalition structures that match the parts of the subspace. The SMART algorithm returns the final solution when all nodes have been searched or pruned. For a particular node that contains the optimal coalition structure, the only way for SMART not to search it is for DIPS or GRAD to prune it without any of the three algorithms searching it. However, DIPS or GRAD will only prune nodes that have no chance of containing the optimal solution. Thus, such a node would never be pruned, and one of the three algorithms would always completely search the node that contains an optimal solution. \u03a0\nTime complexity of the SSD algorithm. For each problem size n, the SSD algorithm tests all possible pairs of coalition size sets. For each set of coalition sizes, SSD reconstructs the integer partition graph by dividing only the integers that belong to that set and tests whether it is beneficial to pair that set with another set or not. To test this for one set, CDP pairs it with all the other sets. The total number of sets that SSD evaluates is 2n-2 \u2212 1. We denote by I(s) the number of integer splits performed for a set s and by p(n, s), the number of subspaces generated by the set s. The total number of operations performed by SSD for one set is $T(n) = \\sum_{s=1}^{2^{n-2}} I(s) = \\sum_{s=1}^{2^{n-2}} \\sum_{N} I(N, s)$, where I(N, s) is the number of integer splits performed on node N. The number of splits into two for a certain integer i is n, the highest integer to split is n, and the highest possible number of integers in a single node is n, which is the number of integers of the node that represents the singleton coalition structure. Thus, $I(N,s) \u2264 n \u00d7 \\binom{n}{s}$, and $T(n) \u2264 \\sum_{s=1}^{2^{n-2}} \\sum_{s=1}^{2^{n-2}} p(n, s) \u00d7 n \u00d7 \\binom{n}{s}$. However, the growth rate of the number of nodes in the integer partition graph, which is the same as the growth rate of integer partitions of n, is is $O(\\frac{1}{n})$ [Wilf, 2000]. Hence, $T(n) \u2264 \\sum_{s=1}^{2^{n-2}} \\sum_{s=1}^{2^{n-2}} O(\\frac{1}{\\sqrt{n}}) \u00d7 n \u00d7 \\binom{n}{s} \\leq (2^{n-2} \u2212 1) \u00d7 \\sum_{s=1}^{2^{n-2}} O(\\frac{1}{\\sqrt{n}}) \u00d7 n \u00d7 \\binom{n}{s}$. As a result, the total number of operations of SSD when testing one set is $O(n^2 \\frac{1}{\\sqrt{n}} \\times 2^n \u00d7 \\sqrt{n})$. SSD tests $2^{n-2} - 1$ different sets. Thus, the time complexity of SSD is $O(2^{2n} \\frac{1}{n^2} \\times \\frac{2^n}{\\sqrt{n}})$.\nTime complexity of the SMART algorithm. SMART combines three algorithms-CDP, GRAD, and DIPS, and runs them in parallel. The worst-case run time of dynamic programming on this problem is $O(3^n)$ [Yeh, 1986]. CDP and GRAD are based on dynamic programming. They run in parallel on several sets of sizes and terminate when all sets are fully evaluated. Thus, the time complexity of both CDP and GRAD is O(3", "min(O(3": "O(3", "O(3": "."}, {"title": "6 Empirical Evaluation", "content": "We now evaluate the effectiveness of SMART by comparing it to the prior state-of-the-art algorithms ODP-IP and BOSS. We implemented SMART in Java and for ODP-IP and BOSS, we used the codes provided by their authors for the comparisons. They are also written in Java. The algorithms were run on an Intel Xeon 2.30GHz E5-2650 CPU with 256GB of RAM. For GRAD, we considered values of w \u2208 {10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%}. We also designed and tested a different version of ODP-IP, namely POI (Parallel ODP-IP), that we developed to integrate parallelism in the baseline version of ODP-IP in order to improve its performance. It uses the same number of processes as SMART (see the appendix for more details). This does not affect the theoretical guarantees but improves the practical performances of the algorithm.\nWe conducted the experiments on common benchmark problems. We show results on nine value distributions. Results on other distributions are in the appendix. We compared the algorithms using the following value distributions: Modified Normal [Rahwan et al., 2012], Beta, Exponential, Gamma [Michalak et al., 2016], Normal [Rahwan et al., 2007], Uniform [Larson and Sandholm, 2000], Modified Uniform [Service and Adams, 2010], Zipf, SVA Beta and Weibull [Changder et al., 2020]. The experiments shown in the remainder of the paper are also representative of those in the appendix. For each distribution and number of agents, we ran each algorithm 50 times. Figure 4 reports the run times of SMART, BOSS, ODP-IP and POI. On all distributions, SMART was the fastest for all numbers of agents. For example, after 2 seconds, with the Normal distribution for 24 agents, SMART returns optimal solutions roughly 92% faster than BOSS, 91% faster than ODP-IP and 54% faster than POI, while outperforming them by multiple orders of magnitude as can be seen in Figure 4. The reason for this is twofold. First, when problems are hard to solve (see, for instance, the results for Exponential), the CDP part of SMART finishes before the other algorithms as it presents the best worst-case time performance. The second reason is that for problems where the search of a specific percentage of the solution subspaces is sufficient to find the optimal solution, the combination of GRAD and DIPS achieves the best run time. On one hand, GRAD searches that percentage of subspaces with the best run time. On the other hand, DIPS distributes the search to further accelerate it. Notice that the relative contribution of each technique depends on the specific problem instance. Generally, for easier-to-solve instances, DIPS and GRAD play a more significant role in finding the optimal solution, as they target specific subspaces with the upper bound for DIPS and percentages for GRAD. As the problem becomes more difficult, CDP becomes increasingly important for searching a larger portion of the solution space, as it aims to search the entire solution space. In the worst-case scenario, CDP is the fastest technique to search the entire solution space. Hence, all algorithms have a goal and help each other achieve it as explained in Section 4. Additional experimental insights are described in the appendix.\nWe also report the empirical performance of CDP, which, as discussed earlier in this paper, determines the worst-case run time of SMART. We compared CDP to the dynamic pro-gramming algorithm IDP [Rahwan and Jennings, 2008] used by prior hybrid algorithms, and to the fastest dynamic pro-"}, {"title": "7 Conclusion", "content": "In this paper, we developed an optimal algorithm, SMART, for the coalition structure generation problem. Our method"}, {"title": "A Related Work", "content": "In this appendix, we provide supplementary material. The extensive related work section has been included in the appendix to offer a thorough exploration of existing algorithms.\nEfficiently solving the coalition structure generation prob-lem is computationally expensive when using a naive ap-proach that involves enumerating all possible coalition struc-tures [Sandholm et al., 1999]. To overcome this challenge, various representations of the search space have been pro-posed to reduce the time required to generate optimal coali-tion structures.\nA.1 Coalition Structure Graph\nThe coalition structure graph, first introduced by[Sandholm et al., 1999], is a way to represent the searchspace as a graph composed of nodes representing the coali-tion structures. For a given set of n agents, these nodesare organized into n levels, where each level consists ofnodes representing coalition structures that contain exactly icoalitions (i \u2208 {1, .., n}). Each edge of this graph connectstwo nodes belonging to two consecutive levels, such thateach coalition structure at level i can be obtained by dividinga coalition from a coalition structure at level i \u2212 1 into twocoalitions. The graph of the coalition structures of fou"}]}]}