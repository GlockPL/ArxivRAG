{"title": "Conditional Synthesis of 3D Molecules with Time Correction Sampler", "authors": ["Hojung Jung", "Youngrok Park", "Laura Schmid", "Jaehyeong Jo", "Dongkyu Lee", "Bongsang Kim", "Se-Young Yun", "Jinwoo Shin"], "abstract": "Diffusion models have demonstrated remarkable success in various domains, including molecular generation. However, conditional molecular generation remains a fundamental challenge due to an intrinsic trade-off between targeting specific chemical properties and generating meaningful samples from the data distribution. In this work, we present Time-Aware Conditional Synthesis (TACS), a novel approach to conditional generation on diffusion models. It integrates adaptively controlled plug-and-play \"online\" guidance into a diffusion model, driving samples toward the desired properties while maintaining validity and stability. A key component of our algorithm is our new type of diffusion sampler, Time Correction Sampler (TCS), which is used to control guidance and ensure that the generated molecules remain on the correct manifold at each reverse step of the diffusion process at the same time. Our proposed method demonstrates significant performance in conditional 3D molecular generation and offers a promising approach towards inverse molecular design, potentially facilitating advancements in drug discovery, materials science, and other related fields.", "sections": [{"title": "Introduction", "content": "Discovering molecules with specific target properties is a fundamental challenge in modern chemistry, with significant implications for various domains such as drug discovery and materials science [49, 44, 7]. While diffusion models have shown great success in the generation of real-world molecules [55, 31], their primary goal is often simply to generate realistic molecules without considering specific properties, which can lead to producing molecules with undesirable chemical properties.\nExisting works address this issue by leveraging controllable diffusion frameworks to generate molecules with desired properties [23, 5]. One approach is to use classifier guidance [54], which utilizes auxiliary trained classifiers to guide the diffusion process [5]. An alternative is to use classifier-free guidance (CFG) [19], which directly trains the diffusion models on condition-labeled data. While both approaches can generate stable molecules, they struggle to generate truly desirable molecules due to the complex structures and the discrete nature of atomic features [24].\nOn the other hand, recent works [51, 18] have introduced training-free guidance for controllable generation in a plug-and-play manner, which we hereafter refer to as online guidance (OG). This approach can directly estimate the conditional score with unconditional diffusion model. However, our analysis shows that applying online guidance into the molecular generation can result in generating samples with significantly low molecular stability and validity due to the stepwise enforcement of specific conditions without considering the original distribution at each timestep."}, {"title": "Related Works", "content": "Diffusion models Diffusion models have achieved great success in a variety of domains, including generation of images [12, 46], audio generation [30], videos [21, 36, 42], and point clouds [8, 37]. A particular highlight in the success of diffusion models is their potential to generate molecules that can form the basis of new, previously unseen, medical compounds. Multiple approaches have been explored to achieve this. For instance, graph diffusion such as GeoDiff [57], GDSS [26], and Di-Gress [54] can generate graph structures that correspond to molecular candidates. Additionally, some approaches incorporate chemical knowledge tailored to specific applications, such as RFdiffusion for protein design [55], a method based on the RoseTTAFold structure prediction network [31]. Other previous literature considers different domain-specific applications, such as diffusion for molecular docking [11], or molecular conformer generation [25]. Most relevant to our work, diffusion models have also shown promising results in synthesizing 3D molecules [23, 58, 27], generating stable and valid 3D structures.\nConditional molecular generation Deep generative models [38, 23, 58] have made considerable progress in synthesizing 3D molecules with specific properties. Specifically, conditional diffusion models [23, 5, 58, 18] have achieved noticeable improvements in synthesizing realistic molecules. EDM [23] trains separate conditional diffusion models for each type of chemical condition, while EEGSDE [5] trains an additional energy-based model to provide conditional guidance during the inference. GeoLDM [58] utilizes a latent diffusion model [46] to run the diffusion process in the latent space. MuDM [18] applies online guidance to simultaneously target multiple properties. However, existing methods either produce unstable and invalid molecular structures or are unable to accurately meet the target conditions. To overcome these limitations, we propose TACS, a novel framework which ensures the generative process remains faithful to the learned marginal distributions in each timestep while effectively guiding the samples to meet the desired quantum chemical properties."}, {"title": "Preliminaries", "content": "Diffusion models Diffusion models [50, 20, 52] are a type of generative model that learn to reverse a multi-step forward noising process applied to the given data. In the forward process, noise is gradually injected into the ground truth data, xo ~ po, until it becomes perturbed into random noise, xT ~ N(0, I), where T is the total number of diffusion steps. We follow the Variance Preserving stochastic differential equation (VP-SDE) [52, 20] where the forward process is modeled by the following SDE:\n$dx_t = -\\frac{1}{2} \\beta(t) x_t dt + \\sqrt{\\beta(t)} dw_t,$\nwhere $\\beta(t)$ is a pre-defined noise schedule and wt is a standard Wiener process. Then, the reverse of the forward process in Eq. (1) is also a diffusion process that is modeled by the following SDE [2]:\n$dx_t = [\\frac{1}{2} \\beta(t)x_t - \\beta(t)\\nabla_{x_t} \\log p_t(x_t)] dt + \\sqrt{\\beta(t)}dw_t,$\nwhere pt is the probability density of xt and wt is a standard Wiener process with backward time flows. The reverse process in Eq. (2) can be used as a generative model when the score function \u25bdx log pt (x) is known. To estimate the score function from given data, a neural network se is trained to minimize the following objective [52]:\n$\\mathcal{L}(\\theta) = \\mathbb{E}_{t,x_0} [\\lambda(t) ||s_\\theta(x_t, t) - \\nabla_{x_t} \\log p_t(x_t)||^2],$ \nwhere t~U [0, T], x0 is sampled from the data distribution, and \u5165 : [0, T] \u2192 R+ is a positive weight function.\nOnline guidance Recent works [17, 9, 51] leverage a conditional diffusion process where the conditional probability pt(xt|c) is modeled without training on labeled pairs (xt, c). To understand this approach, observe that for the conditional generation, the reverse SDE of Eq. (2) can be rewritten as follows:\n$dx_t = [\\frac{1}{2} \\beta(t)x_t - \\beta(t)\\nabla_{x_t} \\log p_t(x_t|c)] dt + \\sqrt{\\beta(t)}dw_t.$\nFrom Bayes' rule, the conditional score x log pt (xt|c) can be decomposed as follows:\n$\\nabla_{x_t} \\log p_t(x_t|c) = \\nabla_{x_t} \\log p_t(x_t) + \\nabla_{x_t} \\log p_t(c|x_t).$"}, {"title": "Time-Aware Conditional Synthesis", "content": "In this section, we propose our framework, Time-Aware Conditional Synthesis (TACS). Section 4.1 presents the key component of TACS: the Time Correction Sampler, a novel sampling technique that leverages corrected time information during the generation process. Section 4.2 introduces the overall framework of TACS, which accurately integrates online guidance into the diffusion process using our sampling technique to generate stable and valid molecules that meet the target conditions."}, {"title": "Time Correction Sampler", "content": "Diffusion models are known to have an inherent bias, referred to as exposure bias, where the marginal distributions of the forward process do not match the learned marginal distributions of the backward process [40]. To mitigate exposure bias in the diffusion models, we propose the Time Correction Sampler (TCS), which consists of two parts: time prediction and time correction.\nTime Predictor During conditional generation process of diffusion model, a sample follows the reverse SDE as in Eq. (4). However, due to error accumulation during the generation process [33, 6], a sample at timestep t of the reverse process of diffusion may not accurately reflect the true marginal distribution at timestep t. This discrepancy between forward and reverse process can especially increased when applying online guidance for every denoising steps and consequently lead to the generation of molecules with low stability and validity. We aim to mitigate this issue by correcting the time information based on the sample's current position.\nTo achieve this, we train a neural network, a time predictor, to estimate the proper timestep of a given noised data. Specifically, given a random data point x with unknown timestep, time predictor models how likely x ~ pt for each timestep in [0, T]. For training, we parameterize a time predictor"}, {"title": "Unified guidance with time correction", "content": "Finally, we present TACS in Algorithm 1, which is a novel diffusion sampler for conditional generation that integrates TCS with online guidance. For each timestep of the reverse diffusion process (Eq. 4), we apply online guidance (Eq. 8) to guide the process toward satisfying the target condition. Subsequently, TCS is applied to correct the deviation from the proper marginal distribution induced by online guidance. This ensures the samples follow the correct marginal distribution during the generative process, as shown in Fig. 1. In Section 5, we experimentally validate that TACS is capable of generating valid and stable molecules satisfying the target condition."}, {"title": "Experiments", "content": "In this section, we present comprehensive experiments to evaluate the performance of TACS and demonstrate its effectiveness in generating 3D molecular structures with specific properties while maintaining stability and validity. In Section 5.1, we present synthetic experiment with H molecules, where the ground state energies are computed using the variational quantum eigensolver (VQE). In Section 5.2, we assess our method using QM9, a standard dataset in quantum chemistry that includes molecular properties and atom coordinates. We compare our approach against several state-of-the-art baselines and provide a detailed analysis of the results."}, {"title": "Synthetic experiment with H", "content": "Quantum online guidance We present quantum online guidance as a modified version of online guidance where quantum machine learning algorithm for the property estimation of generating molecules. Specifically, we use VQE [53] when calculating the ground state energy of generated molecules. Contrary to prior works [23, 5], which train auxiliary classifiers to estimate each condition, this quantum computational chemistry-based approach can leverage exact calculation of the condition for a given estimate. This, in turn, is expected to generate molecules with accurate target ground state energies. A detailed explanation of this approach is provided in Appendix A.2.\nSetup We first construct synthetic H as follows. For each molecule, a hydrogen atom is placed uniformly at random within the 3-D unit sphere. We then augment our sample by rotating each molecule randomly to satisfy the equivariance property [23]. Then the ground state energy of each molecule is measured with VQE in order to provide conditional labels. Finally, we train unconditional diffusion model and CFG-based conditional diffusion model with the constructed data. For evaluation, we measure the ground state energy and calculate MAE (Mean Absolute Error) with the target energy. Also, we measure the average L2 distance between position of each atom and its projection to the unit sphere.\nResults The results in Figure 2 indicate that while online guidance correctly guides the samples to the target condition, it can lead to the samples deviated from the original data distribution. In contrast, molecules sampled from TACS can satisfy both low MAE and low L2 distance. Further details and additional discussions are provided in Appendix B.1."}, {"title": "Conditional generation for target quantum chemical properties", "content": "Dataset We evaluate our method on QM9 dataset [45], which contains about 134k molecules with up to 9 heavy atoms of (C, N, O, F), each labeled with 12 quantum chemical properties. Following previous works [1, 23], we test on 6 types of quantum chemical properties and split the dataset into 100k/18k/13k molecules for training, validation, and test. The training set is further divided into two disjoint subsets of 50k molecules each: Da for property predictor training and D\u2081 for generative model training. Further details are provided in Appendix B.2.\nEvaluation To evaluate how generate samples meet the desired target condition, a property pre-diction model $\u03a6_p$ [47] is trained on Da. Then, MAE for K number of samples is calculated as $\\frac{1}{K}\\sum_{i=1}^K |\u03a6_p(x^{(i)}) \u2013 c^{(i)}|$, where x(i) represents i-th generated molecule and c(i) is corresponding target quantum chemical properties. Molecular stability (MS) and validity (Valid) [23] are used to measure how generated samples satisfy basic chemical properties. Details of the evaluation metrics are provided in Appendix B.2.\nBaselines We use Equivariant Diffusion Models (EDM) [23] and Equivariant Energy Guided SDE (EEGSDE) [5] for the baselines. Following [23], we put additional baselines including \"Naive Upper-Bound\" (randomly shuffled property labels), \"#Atoms\" (properties predicted by atom count), and \"L-Bound\" (lower bound on MAE using a separate prediction model).\nResults Table 1 shows the result of conditional generation of TACS and TCS with baselines. We generate K=104 samples for the evaluation in each experiment and the average values and standard deviations are reported across 5 runs. For all of the quantum chemical properties, TACS achieves lower MAE while maintaining comparable or higher molecular stability (MS) and validity compared to other baselines. Notably, when comparing with the baseline methods that maintains the MS above 80%, the MAE of TACS is significantly lower than the baselines. The result demonstrates the effectiveness of TACS in balancing the objectives of generating molecules with desired properties and ensuring their structural validity.\nTCS achieves high validity and atom stability and molecular stability, surpassing the unconditional generation performance of the baselines, but with a higher MAE compared to TACS. This highlights the importance of online guidance for precise property targeting. However, applying only online guidance yields samples with low MAE but suffers from reduced validity and stability, occasionally failing to generate valid molecules due to numerical instability. This shows the ability of TACS which places the samples on the correct data manifold at each denoising step, even if they deviate from the true time-manifold due to the online guidance. Finally, we put the results of different methods with 9 different runs for each method and plot the MAE and MS in Figure 3a. The result clearly shows"}, {"title": "Target structure generation", "content": "We conduct experiments on target structure generation with QM9 as in [5]. For evaluation, we report Tanimoto similarity score [16] which captures similarity of molecular structures by molecular fingerprint and molecular stability to check whether basic properties of molecules are satisfied during the conditional generation process. We put additional details of the experiment in Appendix B.3.2.\nResults Table 2 shows that TACS significantly outperforms baseline methods both in Tanimoto similarity and molecular stability. Interestingly, performance of TACS is robust in the online guidance strength z. This demonstrates TACS's ability to generalize on different tasks."}, {"title": "Unconditional generation on Geom-Drug dataset", "content": "To verify the scalability of time correction sampler, we use Geom-Drug [4] as our dataset. Geom-Drug consists of much larger and complicate molecules compared to the QM9. For fair comparisons, we follow [23, 5] to split the dataset for training, validation and test set include 554k, 70k, and 70k samples respectively. We test the performance of TCS on unconditional generation of 3D molecules when using Geom-Drug. For evaluation, we use atom stability (AS) and validity of generated samples. The result in Table 3 shows that samples generated by TCS satisfy the highest atom stability and the validity with high margin compared to the baselines. Details of the experiments are in Appendix B.3.1."}, {"title": "Ablation Studies", "content": "Time prediction function We investigate how the the design of time prediction function affects the performance of TACS. Specifically, for line 6 in Alg. 1, rather than using argmax function to obtain corrected timestep tpred, we choose to use expectation value by tpred = E[\u03a6(x)]. Table 4 shows the comparison between two methods in six different types of quantum chemical properties. Expectation based time prediction results in molecules with higher MAE and higher molecular stability.\nOnline guidance strength z To analyze the effect of online guidance strength z in Eq. (9), we measure MAE, molecular stability, and validity of samples generated by TACS for different z values. Table 5 shows the result with target condition on ELUMO values. One can observe while trade-off occurs for different z values, performance of TACS is robust in varying z. Interestingly, our experiment shows that there exists an optimal value of z which generates samples with the lowest MAE that is even compara-ble to applying online guidance without time correction (OG). As expected, using z = 0 (TCS) generates molecules with the highest MS and validity but with the highest MAE.\nTime window length \u25b3 We measure how the perfor-mance of TACS varies with time winodw length \u25b3. Table 6 shows the MAE, molecular stability values for dif-ferent window sizes when the target property is a. The result shows that the performance of TACS is robust when using moderate window size but decreases when window size becomes larger than certain point. We set \u25b3 = 10 for other experiments.\nIn Appendix C, we provide the results of further ablation studies including the effect of mc sampling and effective diffusion steps for TACS. Overall, the results show that our method is robust in the choice of hyperparameters and generalizable to different datasets and tasks."}, {"title": "Discussion", "content": "Exploiting quantum chemistry In Section 5.1, we demonstrate that quantum computing-based guidance can serve as an accurate property predictor for the online guidance. Currently, in the absence of a non-noisy quantum computer, scaling up this exact guidance to the QM9 dataset is close to impossible due to compounding noise [43, 10]. However, future fault-tolerant quantum technology is expected to provide quantum advantage in calculating chemical properties. This can be incorporated into our algorithm when using online guidance and therefore, further improvements of our TACS are on the horizon.\nConnection to other fields Recent works point out the exposure bias exists for diffusion mod-els [40], where there is a mismatch between forward and reverse process. Our experiments in 5.2 indicate that Time Correction Sampler can provide a solution to the exposure bias problem during the sampling process in diffusion models. Moreover, since time predictor can gauge this mismatch during inference, one might leverage this information for future works."}, {"title": "Conclusion", "content": "In this work, we introduce Time-Aware Conditional Synthesis (TACS), a novel approach for conditional 3D molecular generation using diffusion models. Our algorithm leverages a Time Correction Sampler (TCS) in combination with online guidance to ensure that generated samples remain on the correct data manifold during the reverse diffusion process. Our experimental results clearly demonstrate the advantage of our algorithm, as it can generate molecules that are close to the target conditions while also being stable and valid. This can be seen as a significant step towards precise and reliable molecular generation.\nDespite multiple advantages, several open questions remain. For example, how can we more efficiently use the Time Correction Sampler, or more generally, whether this method improves performance in other domains such as in image generation. We expect that our work will open various opportunities across different domains, such as quantum chemistry and diffusion models.\nLimitation Although we demonstrate the effectiveness of our algorithm on multiple datasets and tasks, we use a trained neural network to estimate chemical properties of each molecule for main experiments. Using exact computational chemistry-based methods might improve our algorithm.\nSocietal impacts We believe that our framework can assist in drug discovery, which requires synthesizing stable and valid molecules that satisfy target conditions. However, our work could unfortunately be misused to generate toxic or harmful substances."}, {"title": "Method details", "content": "A.1 Time Predictor\nFor model architecture, we use EGNN [47] with L = 7 layers, each with hidden dimension hf = 192. We use the same split of training / test dataset of QM9.\nTime predictor training For completeness, we restate the training of the time predictor (Eq. 10) here. The time predictor is trained for minimizing the cross-entropy loss between the predicted logits \u00eep and one-hot vector of the forward timestep t:\n$\\mathcal{L}_{time-predictor}(\\phi) = -\\mathbb{E}_{t,x_0} [\\log (p_\\phi(x_t)_t)],$\nwhere t is uniformly drawn from the interval [0, T].\nFor conditional diffusion model, we train separate time predictor for each of the target property by concatenating conditional information c to the input xt.\nThe rationale behind using cross-entropy loss rather than simple regression loss is because p(tx) can not be estimated from the point estimate if there exists intersection between support of marginal distributions pt and ps which is from different timesteps s and t, respectively. In other words, this implies there exists x \u2208 Rd such that pt(x) > 0 and ps(x)>0 simultaneously holds.\nFinally, we train the time predictor within 24 hours with 4 NVIDIA A6000 GPUs.\nA.2 Quantum online guidance\nQuantum Machine Learning Quantum computing is expected to become a powerful computa-tional tool in the future [14]. While at its early stage, various of quantum machine learning algorithms are proved to have advantage over classical methods [3]. In computational chemistry, these advantages are indeed expected to have huge potential since classically intractable computations like finding ground state for big molecules are expected to become feasible with exponential speed-ups [48] of quantum machines.\nVariational Quantum Eigensolver Variational Quantum Eigensolver (VQE) [41] is a near term quantum machine learning algorithm which leverages variational principle to obtain the lowest energy of a molecule with given Hamiltonian. For the given Hamiltonian \u0124, trial wave function |\u03c8(\u03b8)\u3009 which is parameterized by a quantum circuit (0) is prepared to obtain ground state energy Eo with following inequality:\n$E_o < \\frac{\\langle \\psi(\\theta)|\\hat{H}|\\psi(\\theta) \\rangle}{\\langle \\psi(\\theta)|\\psi(\\theta) \\rangle}$\nSpecifically, parameters in quantum circuit is iteratively optimized to minimize the following objective:\n$\\mathbb{E}(\\theta) = \\frac{\\langle \\psi(\\theta)|\\hat{H}|\\psi(\\theta) \\rangle}{\\langle \\psi(\\theta)|\\psi(\\theta) \\rangle}$\nWhen quantum circuit 0 is expressive enough, one can see that |(0*)), where 0, is a minimizer of Eq. (14), gives the ground state of the given system. For more comprehensive review with its potential advantages, one may refer to [53].\nQuantum online guidance Quantum online guidance is a type of online guidance algorithm where we use VQE-based algorithm to calculate exact values of quantum chemical properties instead of using classifier which is usually a neural network.\nIn each denoising step of diffusion model, we first apply Tweedie's formula (Eq. 7) to estimate clean molecule x0. Then we use VQE to calculate ground state energy of the estimated molecule by iteratively updating 0 for E(x0, 0) = (\u03c8(0)|H(xo)|4(0)). After obtaining 0+(x0) which minimizes E(x0, 0), we obtain target property value E0(x0). To obtain gradient in Eq. (8), we use zeroth-order method [35] with respect to the position of atoms to obtain gradient as follows:\n$\\nabla_{x_t} \\log \\mathbb{E}_{x_0 \u223c p(x_0 | x_t)} P(c | x_0) \u2248 \u2212\u2207_{x_t} E_0(x) \u2248 \\sum_{i=1}^k \\frac{E_0 (x + h_i) \u2212 E_0 (x \u2212 h_i)}{2h_i},$"}, {"title": "Properties of the Zero-Center-of-Mass Subspace", "content": "Let X = {x \u2208RM\u00d73: \u2211i=1M xi = 0} be the subspace of RM\u00d73 where the center of mass is zero. Here we discuss some properties of X that are used in the TACS framework. First, note that X is a linear subspace of RM\u00d73 with dimension (M \u2013 1) \u00d7 3. There exists an isometric isomorphism : R(M-1)\u00d73 \u2192 X, i.e., a linear bijective map that preserves distances: ||$(x)|| = |||| for all \u00c2\u2208 R(M\u22121)\u00d73. Intuitively, $ allows us to map between the lower-dimensional space R(M-1)\u00d73 and the constrained subspace X without distortion. If x \u2208 X is a random variable with probability density q(x), then the corresponding density of x = $\u00af\u00b9(x) in R(M-1)\u00d73 is given by \u011d(x) = q($(x)). Similarly, a conditional density q(x|y) on X can be written as \u011d(x|\u0177) = q($(x)|$(\u0177)). In practice, computations involving probability densities on X can be performed in R(M-1)\u00d73 and mapped back to X using & as needed. This allows TACS to efficiently learn and sample from distributions on molecular geometries while preserving translation invariance. For further mathematical details on subspaces defined by center-of-mass constraints, we refer the reader to [29] and [47]."}, {"title": "Classfier-free guidance", "content": "For conditional generation, we need conditional score \u2207x log pt (xt|c) where c is our target condition. Classifier-free guidance (CFG) [19] replaces conditional score with combination of unconditional score and conditional score. Here, diffusion model is trained with combination of unlabeled sample (x0, 0) and labeled samples (x0, c). The reverse diffusion process (Eq. 2) in CFG changes as follows:\n$dx_t = [-\\frac{1}{2} \\beta(t)x_t - \\beta(t) (-\\omega \\nabla_{x_t} \\log p_t(x_t) + (1 + \\omega) \\nabla_{x_t} \\log p_t(x_t | c)) ] dt+ \\sqrt{\\beta(t)} dw_t$\nHere, w is a conditional weight which controls the strength of conditional guidance. When w = \u22121, the process converges to the unconditional generation and with larger w, one can put more weights on conditional score. In the experiments, we use w = 0 following [23, 5]."}, {"title": "Synthetic experiment with H", "content": "Here, we provide experimental results on our synthetic experiment. Our results show that TACS is robust through different online guidance strength z and outperforms naive mixture of CFG and OG.\nGeometric Optimization It is known that H molecule has a ground state energy around -1.34Ha. Assuming we don't have any prior knowledge of this information, we try to generate molecules with conditioning on the target ground state energy -2.0Ha. Applying TACS proves to be strong in this case also, which implies that our method can robustly guide the molecule without destroying distances."}, {"title": "When to apply TCS and OG", "content": "We ablate when to start the time-corrected sampling (TCS) and online guidance (OG) during the reverse diffusion process. The notation tres and tog indicates we apply TCS after timestep trcs and OG after the timestep tog in the reverse diffusion process. We report results for property ELUMO in Table 11. The result shows that applying TACS from early steps (t = 600, 800) generates samples best satisfying the target condition but with less molecular stability and validity. In contrast, when we start applying TACS after later step t = 400, generated samples have higher MAE, MS, and Validity. Interstingly, if we apply TACS only in the later part (after t = 200), MAE, MS, and validity decreases again. We leave further investigation on this phenomenon and explanation for future works.\nIn our experiments, we use trcs = tog = 600 as our default setting."}, {"title": "Number of MC samples", "content": "Additional experiments are conducted on the effect of number of MC samples m in Eq. (8). LGD [51] estimates xo assuming q(x0|xt) is a normal distribution with mean \u00c20 (Eq. 7) and variance \u03c3\u00b2 which is a hyperparameter.\nFirst, we investigate the effect of varying the variance o in MC sampling. Table 12 shows that the result is robust in the small values of o but when o is larger than some point, quality of generated samples decreases (higher MAE and lower MS).\nNext, we test how the performance of TACS is affected by number of MC samples m. Table 13 shows that performance of TACS is robust in number of MC samples but we did not observe any performance increase with the number of MC samples as in [18]."}, {"title": "Results on Novelty, Uniqueness", "content": "We report additional metrics on the novelty, uniqueness of generated molecules in Table 14 following previous literature [5, 23, 58]. Novelty measures the percentage of generated molecules not seen in the training set. Uniqueness measures the proportion of non-isomorphic graphs within valid molecules. Higher values indicate better quality for both metrics. The result shows that TACS generates molecules with decreased novelty. This shows that TACS is effective in making generated molecules that stick to the original data distribution while satisfying to meet the target condition."}, {"title": "Mathematical Derivations", "content": "In our derivation of equivariance properties of the time predictor, we closely adhere to the formal procedures outlined in [23, 57, 47].\nDefinition 1 (E(3) Equivariance). A function f : RN\u00d73 \u2192 RN\u00d7d is E(3)-equivariant if for any orthogonal matrix R \u2208 R3\u00d73 and translation vector v \u2208 R\u00b3,\nf (RX + v1T) = R \u00b7 f(X),\nwhere X \u2208 RN \u00d73 and 1 \u2208 RN is the all-ones vector.\nDefinition 2 (Permutation Invariance). A function g : RN\u00d7d \u2192 Rd is permutation-invariant if for any permutation matrix P \u2208 {0,1}N\u00d7N,\ng(PH) = g(H),\nwhere H\u2208 RNxd\nProposition 1. Let f : RN\u00d73 \u2192 RN\u00d7d be an E(3)-equivariant function and g : RN\u00d7d \u2192 Rd be a permutation-invariant function. Then, the composition h = go f : RN\u00d73 \u2192 Rd is invariant to E(3) transformations, i.e.,\nh(RX + v1T) = h(X).\nProof. For any orthogonal matrix R \u2208 R3\u00d73 and translation vector v \u2208 R\u00b3,\nh(RX + v1T) = g(f(RX + v1))\n= g(R. f(X)) (E(3) equivariance of f)\n= g(f(X)) (Permutation invariance of g)\n= h(x).\nTheorem 1 (Time Predictor Equivariance). Let G = (V,E) be a graph representing a molecule, where V = {1, . . ., N} is the set of nodes (atoms) and E \u2286 V \u00d7 V is the set of edges (bonds). Let Xt \u2208 RN\u00d73 denote the atomic coordinates and c \u2208 Rd be a condition vector at diffusion timestep t. Consider a time predictor po(t|Xt, c) = softmax(f(Xt, c)) parameterized by a composition of an E(3)-equivariant graph neural network EGNN\u2084 : RN\u00d73 \u00d7 RN\u00d7dh \u00d7 Rd \u2192 RN\u00d7d', a permutation-invariant readout function p : RN\u00d7d' \u2192 Rd', and a multilayer perceptron \u03c8 : Rd' \u2192 RT, i.e.,\nf(Xt, c) = \u03c8(p(EGNN\u2084(Xt, Ht, c))),\nwhere Ht \u2208 RN\u00d7dh are node features and T is the total number of diffusion timesteps. Then, the time predictor po(t|X\u2081, c) is invariant to E(3) transformations, i.e., for any orthogonal matrix R \u2208 R3\u00d73 and translation vector v \u2208 R\u00b3,\npo(t|RXt + v1, c) = p(t|Xt, c),\u2200t \u2208 {1, ...,T}."}, {"title": "Comparison with other related works", "content": "While with different motivations and methods, here, we list some of the relevant works and compare their algorithms with ours.\nComparison with DMCMC DMCMC [28] trains a classifier to predict noise levels of the given data during the reverse diffusion process which is similar to our time predictor. However, they use the classifier to estimate the current noise state when conducting MCMC on the product space of the data and the noise. In contrast, our time predictor directly predicts timesteps for correction in diffusion sampling itself. Moreover, while the purpose of noise prediction in DMCMC is for fast sampling, our work use time predictor to accurately produce samples from the desired data distribution.\nComparison with TS-DPM Time-Shift Sampler [34] targets to reduce exposure bias targets similar approach of fixing timesteps during the inference as our time correction method. However, while our method directly selects timesteps based on the time predictor, which has demonstrated robustness in our experiments [34] selects timesteps by calculating variance of image pixels at each step and matching the noise level from the predefined noise schedule which is often inaccurate and expensive. Moreover corrected timestep in [34] is used directly for the start of the next step, while our approach maintains the predefined timestep after accurately estimate clean sample by corrected time step (line 9 in Algorithm 1). By taking every single diffusion step while carefully using predicted time, TACS / TCS can generate samples closer to the target distribution.\nTo further validate our approach, we provide additional experimental results comparing TS-DDPM [34] and TACS on the QM9 dataset with step size 10. The result in Table 15 shows consistent improvements across various quantum properties which shows the robustness of our approach."}]}