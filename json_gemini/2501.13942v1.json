{"title": "Prompt-Based Monte Carlo Tree Search for Mitigating Hallucinations in Large Models", "authors": ["Zhihua Duan", "Jialin Wang"], "abstract": "Abstract-With the rapid development of large models in the\nfield of artificial intelligence, how to enhance their application\ncapabilities in handling complex problems in the field of scientific\nresearch remains a challenging problem to be solved. This study\nproposes an improved Monte Carlo Tree Search (MCTS) method\nbased on prompt words. In the simulation search stage, it intro-\nduces dynamic adjustment of exploration parameters and adap-\ntive selection strategies, which can better balance exploration and\nexploitation, thereby reducing the hallucination phenomenon.\nThis paper takes the four subsets of the SciEval dataset as the test\nobjects, and compares the Glm-4-flash+Improved MCTS method\nwith the methods of several existing models. The results show\nthat the Improved MCTS method performs better, providing new\nideas and methods for the application of large models in the field\nof scientific research.", "sections": [{"title": "I. INTRODUCTION", "content": "In the field of artificial intelligence, the development of\nLarge Language Models (LLMs) is advancing at an unprece-\ndented pace, with their capabilities in language understanding\nand generation continuously improving. However, effectively\nenhancing the application capabilities of large models in the\nfield of scientific research, especially when dealing with com-\nplex problems, remains a challenge. To address this challenge,\nthis study proposes an improved Monte Carlo Tree Search\n(MCTS) algorithm based on prompt words. By dynamically\nadjusting exploration parameters and adaptively selecting sim-\nulation strategies, the efficiency of LLMs in solving scientific\nproblems is enhanced.\nThe Monte Carlo Tree Search (MCTS) algorithm is a\ncombination of the Monte Carlo method and tree search,\nwidely used in decision-making processes and game problems.\nThrough four steps of selection, expansion, simulation, and\nbackpropagation, it explores and evaluates the decision tree\nto find the optimal action plan. This study improves upon\nthe existing MCTS by introducing a function for dynamically\nadjusting exploration parameters and a function for adaptively\nselecting simulation strategies during the simulation search\nphase. These functions determine whether to use a greedy\nstrategy or a random strategy based on the complexity of the\nproblem and preset thresholds."}, {"title": "II. RELATED WORK", "content": "A. Chain of Thought Prompt\nPropose a chain of thought method that uses Scratchpads\nfor multi-step calculations [1].Enhance complex reasoning\nabilities by generating a chain of thought prompts consisting\nof a series of intermediate reasoning steps [2].\"Let's think step\nby step,\" can demonstrate good zero-shot reasoning ability\n[3].Selecting more complex reasoning chains and prompts with\na greater number of reasoning steps improves the performance\non multi-step reasoning tasks [4].\nB. Monte Carlo Tree Search (MCTS) method\nPositioning large models as world models and reasoning\nagents, the planning algorithm based on Monte Carlo Tree\nSearch (MCTS) has achieved efficient solutions to complex\nreasoning problems [5].The Tree of Thoughts (ToT) has been\nproposed, which enables large models to explore different\nreasoning paths and self-assess for selection [6].A reasoning\nmethod called rStar is proposed, which can significantly\nenhance the reasoning capabilities of small models [7].An"}, {"title": "III. METHODS", "content": "As shown in Figure 1, it is an improved Monte Carlo\nmethod based on prompt words. The Monte Carlo Tree Search\n(MCTS) algorithm is a combination of the Monte Carlo\nmethod and tree search, mainly consisting of four steps:\nselection, expansion, simulation, and backpropagation.\n\u2022\n\u2022\nSelection: Starting from the root node, recursively select\nthe optimal child node until a leaf node is reached.\n\u2022 Expansion: If the current leaf node is not a terminal node,\nthen create one or more child nodes and select one of\nthem for expansion.\nSimulation: Starting from the expanded node, run a\nsimulated outcome until the end of the game.\n\u2022 Backpropagation: Propagate the simulation results back\nto the root node of the tree, updating the information of\neach node along the path, including the number of visits\nand node value.\nBy iteratively cycling through these four steps, the MCTS\nalgorithm can effectively explore and evaluate the decision tree\nto find the optimal action plan.\nThis study makes improvements based on existing Monte\nCarlo work: during the simulation search phase, a function\nis dynamically adjusted to reduce the exploration parameter\naccording to the number of visits. An adaptive function for\nselecting simulation strategies is used, which decides whether\nto employ a greedy strategy or a random strategy based\non the complexity of the problem and a preset threshold.\nDynamic adjustment of exploration parameters: A function\nfor dynamically adjusting exploration parameters is defined,\nwhich adjusts the exploration parameters dynamically accord-\ning to the number of visits to a node. In the early stages of\nexploration, when the number of visits to a node is low, the\nexploration parameter is larger, leading to more exploration\nand trying out different paths to avoid prematurely falling\ninto local optimal solutions. As exploration progresses and\nthe number of visits to a node increases, the exploration\nparameter gradually decreases, causing the algorithm to lean"}, {"title": "IV. EXPERIMENTAL DESIGN", "content": "A. Dataset\nThe SciEval dataset is a comprehensive and multi di-\nmensional evaluation benchmark designed specifically for the\ncapabilities of large - scale language models in the field of\nscientific research. By covering four major dimensions of basic\nknowledge, knowledge application, scientific computing, and\nresearch ability, and combining diverse data sources and rich\ndata types, including both objective and subjective questions, it\nprovides a comprehensive, reliable, and challenging evaluation\ntool for the application capabilities of large - scale language\nmodels in the scientific field. This study tested four subsets of\nSciEval: part1, part2, part3, and part4.\nB. Experimental Results\nAs shown in Table I, this study compared the perfor-\nmance of GPT-3.5-Turbo+CoT, GPT-3.5-Turbo+ToT, GPT-3.5-\nTurbo+ReST-MCTS, and Glm-4-flash+Improved MCTS on\nthe four subsets of SciEval. The CoT (Chain of Thought)\nstrategy is a method of solving problems through step-by-step\nreasoning. The ToT (Tree of Thoughts) strategy is a structured\nmethod for problem-solving and reasoning, which decomposes\nproblems into multiple branches and levels, explores possible\nsolutions step by step, and ultimately selects the optimal\npath. It is capable of handling complex decision-making and\nmulti-step reasoning tasks. The ReST-MCTS (Reinforcement\nLearning with Monte Carlo Tree Search) strategy combines re-\ninforcement learning and Monte Carlo tree search techniques.\nThis paper is based on the evaluation of the Glm-4-lash large\nscale model. Glm-4-lash performs well in real - time web\nsearch, long context processing, and multilingual support\nmaking it suitable for a variety of application scenarios such\nas intelligent question - answering, summary generation, and\ntext data processing. This paper adopts an improved Glm-4-\nlash+MCTS (Monte Carlo Tree Search) strategy, which is an\nimproved Monte Carlo method. The experimental results show\nthat the improved MCTS strategy has an average score of 65.6\non the four subsets of SciEval, outperforming existing models"}, {"title": "V. LIMITATIONS AND FUTURE WORK", "content": "Although this study has made some progress in enhanc-\ning the application capabilities of LLMs in the field of\nscientific research, there are still some potential directions\nfor improvement: 1.Further optimize the dynamic adjustment\nmechanism: More complex dynamic adjustment functions can\nbe explored to better adapt to different types of scientific\nproblems. 2.Expand the evaluation dataset: In addition to\nthe SciEval dataset, more scientific domain datasets can be\nconsidered to comprehensively evaluate the generalization\nability of the improved MCTS algorithm. 3.Combine with\nother optimization techniques: The improved MCTS algorithm\ncan be combined with other optimization techniques (such as\nreinforcement learning) to further enhance the performance of\nreasoning.\nA. Use LangGraph to enhance the Improved MCTS\nLangGraph can be used to enhance the improved Monte\nCarlo Tree Search (MCTS).\n1. Integration of Cyclical Workflows\nThe MCTS process naturally involves iterative cycles of\nselection, expansion, simulation, and backpropagation. Lang-\nGraph's core strength in supporting cycles and branching\nmakes it an ideal framework for implementing MCTS work-\nflows. Benefit: Streamlined development of the iterative pro-\ncess, ensuring consistency in handling the dynamic adjust-\nments and adaptive selection strategies described in the paper.\n2. State Persistence and Recovery\nLangGraph's built-in persistence can save the state of MCTS\nat each node, including intermediate scores, exploration pa-\nrameters, and simulation strategies. Application: If the process\nis interrupted (e.g., due to resource constraints or the need for\nhuman intervention), LangGraph allows seamless resumption\nwithout reinitializing the MCTS workflow. Example: When\ndynamically adjusting exploration parameters, persistent states\nensure that transitions between high exploration and exploita-\ntion phases are reliably managed.\n3. Human-in-the-Loop for Dynamic Adjustments\nThe paper emphasizes the use of adaptive simulation strate-\ngies based on problem complexity. LangGraph enables human\noversight to validate or refine these strategies in real time. Use\nCase: A human reviewer can intervene during simulation or\nbackpropagation to verify results or adjust the thresholds for\nexploration parameters."}, {"title": "VI. CONCLUSION", "content": "This study proposes an improved Monte Carlo Tree Search\n(MCTS) algorithm based on prompt words, aiming to en-\nhance the application capabilities of Large Language Mod-\nels (LLMs) in the field of scientific research, especially in\nterms of efficiency when dealing with complex problems. By\ndynamically adjusting exploration parameters and adaptively\nselecting simulation strategies, the improved MCTS algorithm\ncan more flexibly balance exploration and exploitation during\nthe simulation search phase, providing new perspectives and\nmethods for the application of LLMs in the field of scientific\nresearch. Although this study has made some progress in\nenhancing the application capabilities of LLMs in the field\nof scientific research, there are still some potential directions\nfor improvement. Future work will continue to explore and\noptimize these methods to further improve the model's per-\nformance in solving complex scientific problems."}]}