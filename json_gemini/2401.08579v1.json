{"title": "Curve-based Neural Style Transfer", "authors": ["Yu-hsuan Chen", "Levent Burak Kara", "Jonathan Cagan"], "abstract": "This research presents a new parametric style transfer framework specifically\ndesigned for curve-based design sketches. In this research, traditional challenges\nfaced by neural style transfer methods in handling binary sketch transformations\nare effectively addressed through the utilization of parametric shape-editing rules,\nefficient curve-to-pixel conversion techniques, and the fine-tuning of VGG19 on\nImageNet-Sketch, enhancing its role as a feature pyramid network for precise\nstyle extraction. By harmonizing intuitive curve-based imagery with rule-based\nediting, this study holds the potential to significantly enhance design articulation\nand elevate the practice of style transfer within the realm of product design.", "sections": [{"title": "1 Introduction", "content": "The process of designing product exteriors often begins with sketch-like, curve-based images [1-6],\nwhere aesthetic and stylistic considerations frequently emerge as explicit rule-based operations\n[7-10]. However, conventional neural style transfer methods [11], while successful in converting\ntextures from a given style image to the content image, often struggle to significantly alter the shapes\nof binary sketches according to a given style image. Bridging this gap, this research introduces a\nnovel parametric rule-based style transfer framework that operates directly on scalar vector graphics\n(SVGs), with a primary focus on the style transformation of curves. By combining the intuitive nature\nof curve-based imagery with the explicit curve editing rules, this approach offers a promising avenue\nfor enhancing style transfer in design, aligning more closely with how designers conceptualize and\narticulate their ideas through curves."}, {"title": "2 Method", "content": "The goal of this research is to perform style transfer directly on SVGs in a rule-based workflow,\nshown in Figure 1. The key components and challenges are elaborated in the following paragraphs."}, {"title": "Rules Design for Effective Shape Editing.", "content": "The initial challenge centers on creating curve-\nediting rules that are both prominent yet stable. This research addresses this challenge by devising\ndifferentiable modification rules encompassing rigid body motions, shear, curvature alterations, and\nsmoothing operations, all contributing to the attainment of the desired outcomes."}, {"title": "Sketch to Pixelated Canvas Transformation.", "content": "The second challenge involves transforming curves\ninto pixelated canvases in a differentiable and efficient manner without overburdening the GPU. To\ntackle this, differentiable rendering is adopted and modified to rasterize curves using ReLU activation\nfunction [12]. In practice, SVG data are homogenized into cubic Bezier representations, and for each\nBezier curve, N+1 control points are sampled to approximate the curve with N line segments. Given\nthe impracticality of rendering curves one at a time using the CPU, batch rendering is opted. To\nfurther mitigate potential GPU overload for generic SVGs that can have numerous curves, dropout is\nalso used during the optimization process."}, {"title": "Fine-Tuning Feature Pyramid Network (FPN).", "content": "After rendering both style and content images,\nan FPN is used to calculate style similarity. It is found that pretrained VGG19 [13] is not the ideal\nFPN for sketch style extraction. To improve the outcomes, this research fine-tunes VGG19 on\nImageNet-Sketch data [14], as it most closely aligns with binary sketch images."}, {"title": "3 Results and Conclusions", "content": "Figure 2 shows and compares style transfer results between curve-based and pixel-based methods\n(Image sources: [15-17]). Notably, our approach excels in translating style objectives into content\nimages, demonstrating a superior ability to modify product shapes. In contrast, pixel-based neural\nstyle transfer primarily focuses on transferring color textures without substantial shape alteration.\nConclusively, this research showcases the potential of our innovative style transfer framework for\nSVGs, surpassing traditional neural style transfer. By directly manipulating SVGs using parametric\ncurve-editing rules, differentiable rendering curves as multiple line segments, and a fine-tuned VGG19\nFPN on sketch images, this approach aims to automatically convey and transfer SVGs' styles by\nemphasizing curve manipulation.\nThis work bridges the realms of design aesthetics and computational artistry, offering a promising\navenue for curve-based imagery and design in style transfer. Future directions involve exploring\nadvanced shape rules, enhancing stability, imposing geometric constraints, venturing into 3D applica-\ntions, and conducting human perceptual studies to further enrich design aesthetics."}, {"title": "4 Ethical Implications", "content": "Because of the transformative capabilities this methodology offers in design articulation and style\ntransfer within the realm of product design, it may carry important ethical implications. First and\nforemost is the concern regarding the displacement of designers' roles. It is crucial to clarify that\nthis technology is not designed to replace designers but rather to augment their capabilities. Design\nexperts remain essential in making intelligent decisions, selecting appropriate design rules, and\ncreatively using this generative design tool to explore novel ideas.\nAnother ethical dimension pertains to copyright and intellectual property. It is imperative that users\nadhere to ethical standards and cite both the original source images and the style images when\nsharing the generated content. This practice not only safeguards the rights of creators but also ensures\nresponsible and ethical use of the technology, addressing potential copyright issues effectively."}]}