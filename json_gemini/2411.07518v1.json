{"title": "LLM App Squatting and Cloning", "authors": ["Yinglin Xie", "Xinyi Hou", "Yanjie Zhao", "Kai Chen", "Haoyu Wang"], "abstract": "Impersonation tactics, such as app squatting and app cloning, have posed longstanding challenges in mobile app stores, where malicious actors exploit the names and reputations of popular apps to deceive users. With the rapid growth of Large Language Model (LLM) stores like GPT Store and FlowGPT, these issues have similarly surfaced, threatening the integrity of the LLM app ecosystem. In this study, we present the first large-scale analysis of LLM app squatting and cloning using our custom-built tool, LLMappCrazy. LLMappCrazy covers 14 squatting generation techniques and integrates Levenshtein distance and BERT-based semantic analysis to detect cloning by analyzing app functional similarities. Using this tool, we generated variations of the top 1000 app names and found over 5,000 squatting apps in the dataset. Additionally, we observed 3,509 squatting apps and 9,575 cloning cases across six major platforms. After sampling, we find that 18.7% of the squatting apps and 4.9% of the cloning apps exhibited malicious behavior, including phishing, malware distribution, fake content dissemination, and aggressive ad injection.", "sections": [{"title": "I. INTRODUCTION", "content": "Mobile app squatting [19], where attackers publish apps with identifiers (e.g., app or package names) that mimic popular apps, such as through typosquatting (e.g., changing \u201cFacebook\u201d to \u201cFecebook\u201d), is a growing threat in the mobile ecosystem. Hu et al.[19] identified over 10,553 squatting apps targeting the top 500 apps on Google Play, with more than 51% classified as malicious and some reaching millions of downloads. These counterfeit apps pose serious risks, including data theft and malware infections. Despite mitigation efforts by platforms, the sheer number of apps and sophisticated squatting tactics make detection and prevention difficult.\nInspired by the extensive research on mobile app squatting, we have turned our attention to similar threats within emerging Large Language Model (LLM) app stores [45]. With the rise of LLMs, such as ChatGPT [27], Gemini [14], and Claude [10], there has been a proliferation of applications that leverage these models in diverse domains, including chatbots, content generation tools, and virtual assistants [6], [9], [11], [13], [28], [29]. LLM-powered applications have gained immense popularity due to their ability to perform complex tasks, leading to the creation of entire app ecosystems around them. However, as these LLM app stores continue to expand rapidly, we observe that they are becoming fertile ground for LLM app squatting attacks similar to those in traditional mobile app markets, as shown in Figure 1. In this context, squatting primarily occurs at the app identifier level, where attackers create apps with names that closely mimic legitimate ones to deceive users. For example, squatting could manifest as subtle name changes or the addition of enticing words, such as \"Canva Pro\", tricking users into believing they are using an official or enhanced version of a popular app. Moreover, LLM app stores have significantly lowered the barrier to entry for developers. This democratization of development allows individuals from various backgrounds, even those with limited programming experience, to create and publish apps. While this inclusivity fosters innovation, it also makes it easier for attackers to clone the entire LLM app not only the app's name but also its functionality and behavior. We refer to this more insidious form of attack as LLM app cloning, where the cloned app mirrors the legitimate one in nearly every aspect, making it even harder for users to discern the difference.\nTo comprehensively investigate squatting and cloning in LLM app stores, we focus on six prominent LLM app stores (i.e., GPT Store [28], FlowGPT [13], Poe [29], Coze [11], Cici [9], and Character.AI [6]) that have gained significant traction due to the widespread adoption of LLM-powered applications. In our study, we develop a tool, LLMappCrazy, designed to automatically detect squatting and cloning instances within these ecosystems. Using LLMappCrazy, we systematically examine app identifier variations and functional cloning across GPT Store, identifying potential 5,834 name squatting apps and 6094 name cloning apps. And we also detect other features of apps in six LLM app stores. Our results reveal the scope of the problem: we found 3,509 squatting apps, and 9,575 cloned apps, confirming that this phenomenon is not isolated to mobile app markets but is rapidly spreading into the LLM domain. The findings indicate that 18.7% of the squatting apps and 4.9% of the cloning apps exhibited malicious behavior, and some of them had amassed significant user downloads, further exacerbating the security risks faced by users of LLM-based applications.\nContributions. We make the following main contributions:\n1) To the best of our knowledge, this is the first detailed investigation into squatting and cloning attacks within LLM app stores.\n2) We develop LLMappCrazy, a tool that detects squatting and cloning apps using 14 squatting-generation tech- niques and advanced semantic analysis.\n3) Using LLMappCrazy, we find 5,834 name squatting apps and 6094 name cloning apps; We conduct a large-scale empirical study across six LLM app stores, identifying 3,509 squatting apps, and 9,575 cloning apps.\n4) We find that 18.7% of the identified squatting apps and 4.9% of cloning apps exhibit malicious behavior, including phishing, malware, and ad injection. And we identify 227 apps that exhibit a high degree of similarity in various features to other apps in GPT Store.\n5) We study the impact of LLM app squatting and cloning, discovering that these apps have reached up to 2.7 million conversations, posing significant risks to platform trust."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "A. LLM App Store\nLLMs are advanced AI systems designed to understand and generate human language. Trained on vast datasets, they produce coherent, contextually relevant responses to a wide range of prompts. As LLM technology has progressed, LLM apps [45] have emerged. These are software applications pow- ered by LLMs, designed to perform specific tasks such as text generation, translation, and conversational interactions. At the same time, LLM app stores act as centralized platforms for discovering, distributing, and managing these apps. Platforms like OpenAI's GPT Store [28] have become key hubs for users and developers to access and share LLM apps.\nSeveral studies explored the ecosystem and security of LLM app stores. Zhao et al. [45] provided a vision and roadmap for the analysis of LLM app stores, outlining the future directions for research. Zhang et al. [44] conducted an initial analysis of GPTs distribution and potential vulnerabilities, while Su et al. [33] provided comprehensive mining of the GPT Store, examining app characteristics and user engage- ment. Additionally, Yan et al. [41] explored the GPT Store ecosystem, focusing on distribution, deployment, and security aspects. To support further research, Hou et al. [18] introduced GPTZoo, a dataset containing over 730,000 GPT instances.\nIn terms of security, Hou et al. [17] examined the security of LLM app stores, highlighting critical vulnerabilities and security challenges in these platforms. Tao et al. [35] dis- cussed the risks associated with custom GPTs, Hui et al. [21] uncovered vulnerabilities related to prompt leaking attacks. Antebi et al. [5], [24] analyzed the misuse of custom GPTs and malicious services integrated with LLMs, respectively. However, while these works cover various aspects of LLM apps, the issues of LLM app impersonation, such as squatting and cloning, remain underexplored. These emerging threats pose significant risks to the expanding LLM app ecosystem and warrant further investigation.\nB. Squatting Attack.\nDomain squatting[40] involves registering domains similar to legitimate ones with malicious intent. A common form, typosquatting, exploits users' typographical errors when typ- ing domain names, diverting traffic from legitimate sites. Agtenet al. [3], [32] provide detailed analyses of typosquat- ting, with the latter highlighting the effectiveness of character permutations and substitutions in deceiving users."}, {"title": "C. Cloning Detection", "content": "Cloning has been widely studied in software development, especially in mobile app ecosystems, where cloned apps raise significant security concerns such as malware distribu- tion, intellectual property theft, and privacy violations. Rat- tan et al. [30] reviewed software clone detection, highlighting challenges like bug propagation and maintenance issues. In mobile apps, various studies have focused on detecting clones in both official and unofficial markets. Crussell et al. [12] first addressed the issue with detection methods based on app meta- data and code similarity. Wang et al. [39] introduced Wukong, a scalable two-phase approach using static and dynamic anal- ysis. Chen et al. [7] proposed a hybrid method balancing accuracy and scalability, while Lyu et al. [25] developed SuiDroid, a system resilient to obfuscation. Niu et al. [26] combined static and dynamic analysis for clone detection, and Hu et al. [20] introduced a UI-based approach to detect clones mimicking the visual design of legitimate apps.\nRecent advancements in clone detection have utilized ma- chine learning and deep learning models. Zhang et al. [43] highlighted the vulnerabilities of machine learning-based de- tectors when faced with semantic-preserving code transfor-"}, {"title": "III. MOTIVATING STUDY", "content": "The aforementioned research highlights the potential risks posed by LLM app squatting and cloning, indicating these threats may be widespread in the LLM app ecosystem. To explore this, we conduct a preliminary study to (1) confirm the presence of these threats and (2) assess whether existing squatting detection techniques can effectively identify them. This serves as the foundation for our later methodology.\nA. Methodology\nTo detect potential squatting in LLM apps, we generate variations of several popular app names from the GPT Store and check for their existence in online repositories.\nGenerating squatting names. We begin by selecting the top 10 recommended LLM apps from the GPT Store, each with significant user engagement, as shown in Table I. For each app, we manipulate the names to create potential squatting variations that attackers could exploit. We use AppCrazy[19], a tool inspired by domain squatting generators like URL- Crazy [2] and DNSTwist [1]. AppCrazy includes 11 models tailored for mobile app ecosystems, such as punctuation dele- tion (e.g., \"DALL\u00b7E\u201d to \u201cDALLE\u201d), character insertion (e.g., \"DALL\u00b7E\" to \"DALLLEE\u201d), and substitution (e.g., \"DALL\u00b7E\" to \"DALL3\"). Using these models, we generate 625 variations from the app names of the 10 selected apps.\nVerifying squatting names. To verify whether these squatting names exist in the wild, we rely on GPTZoo [18], a metadata dataset that tracks over 730,000 LLM apps from the GPT Store. We run an automated search using the 625 generated squatting names in the GPTZoo dataset. This search returns 32 results that match our squatting name variations. We then manually verify these apps using the GPT Store to determine whether the apps are legitimate or potential squatting attempts. This manual review is crucial for eliminating false positives. Through this process, we identify 28 apps that appear to be squatting on popular LLM app names, demonstrating the prevalence of squatting in the LLM app ecosystem.\nB. Motivating Results\nAs shown in Table I, we identified 28 squatting apps. Of the 11 generation models used by AppCrazy, only 4 proved effec- tive in generating squatting apps. Out of the 625 name strings generated, only 28 matched real squatting apps, meaning that more than 95.52% of the generated strings did not identify any squatting cases. Interestingly, during this process, we also encountered squatting apps not directly identified by the names generated by AppCrazy. For instance, when querying the GPTZoo dataset, we found several \"related\" apps. Manually reviewing these results, we identified 34 squatting apps that did not directly match the names generated by AppCrazy.\nC. Observations\nOur study confirms the existence of squatting and cloning threats in the LLM app ecosystem but also reveals significant limitations in current detection methods, including missed squatting apps and inefficiencies in name-generation models. Manual review, while effective in reducing false positives, is not scalable, emphasizing the need for improved, automated filtering techniques. Additionally, due to structural differences between LLM and traditional apps, existing cloning detection methods are inadequate, prompting the need for more tailored approaches, which we explore in the following sections.\nD. Terminology\nIn LLM app stores, attackers often employ two primary impersonation techniques: LLM app squatting and LLM app cloning. These methods enable attackers to mislead users, either by creating apps with names similar to legitimate ones or by replicating the functionality of popular apps. Below, we define these two forms of impersonation in detail.\n1) Squatting LLM apps: Apps that have either identical or slightly altered names to legitimate LLM apps.\n2) Cloning LLM apps: Apps that replicate the functionality and overall user experience of legitimate LLM apps.\nSquatting generation models generate potential squatting names by applying techniques like character modifications to legitimate app names. In contrast, cloning detection models identify cloned apps by analyzing functional similarities and detecting apps that replicate key features of legitimate ones."}, {"title": "IV. APPROACH", "content": "Our approach to identifying squatting and cloning LLM apps consists of three main steps: data collection, squatting generation, and cloning detection, as shown in Figure 2.\nA. Data Collection\nWe collected app information by scraping data from six LLM app stores: GPT Store [28], FlowGPT [13], Poe [29], Coze [11], Cici [9], and Character.AI [31]. Then, we applied several processes to ensure its accuracy and quality, including filtering, deduplication, and standardization. First, filtering was necessary because certain LLM apps might have common names not exclusive to any specific app or brand. Both the complete dataset and the filtered apps were retained and used in subsequent experiments to detect name duplication or squatting (reasons discussed \u00a7 VII-B). Next, we performed deduplication by comparing app ids, which are unique to each app, to ensure that the dataset contained unique entries. Finally, we standardized the data into JSON format to facilitate the smooth execution of experiments and ensure reliable results. Our analysis focused on three key fields: app name, description, and instructions. The app name was used in experiments to detect dupli- cate or squatting names, while both the description and instructions were utilized for cloning detection, with the description showcasing the app's public-facing features and the instructions serving as its behavioral guide, similar to source code.\nB. Squatting Generation Models\nInspired by the squatting name techniques introduced in Ap- pCrazy [19], we developed LLMappCrazy, a tool tailored for detecting squatting in the emerging ecosystem of LLM apps. While LLMappCrazy builds upon the foundation of AppCrazy, our preliminary investigation revealed several key differences between mobile app squatting and LLM app squatting. To address this, we extended AppCrazy introducing methods like emoji and string expansions. Additionally, we adapted several package name squatting techniques from AppCrazy to suit LLM apps. As illustrated in Figure 3, LLMappCrazy employs 14 squatting generation models.\nMutation-based models. We retain six mutation-based mod- els from AppCrazy, which generate squatting names by ex-"}, {"title": "C. Cloning Detection Models", "content": "We employed Levenshtein distance and BERT-based se- mantic similarity to detect plagiarism or app cloning in LLM app descriptions and instructions. Levenshtein dis- tance identified exact or near-exact matches by measuring min- imal edits, while the BERT model captured deeper semantic similarities, even with different wording. By analyzing both these components, we effectively detected cloning attempts, revealing instances of content replication ranging from direct copying to subtle paraphrasing, and highlighting the preva- lence of cloning in the LLM app ecosystem.\n1) Levenshtein distance calculation\nTo detect cases of content cloning with minor variations, we employed Levenshtein distance algorithm [42], which calculates the minimum number of single-character edits (insertions, deletions, or substitutions) required to transform one string into another. For each app pair, we computed the Levenshtein distance between their instructions fields, which act as the core content or behavioral guide of the LLM app, similar to the source code.\nLevenshtein Similarity = 1 \u2212 Levenshtein Distance Maximum String Length (1)\nwhere the Maximum String Length is the length of the longer string. This allowed us to compare app pairs with different text lengths. We focused on app pairs where the Levenshtein sim- ilarity scored between 0.95 and 1.0, excluding exact matches (similarity = 1). For example, with an instructions field of 500 characters, fewer than 25 modifications (5% of the total length) would flag potential plagiarism, and for fields of 1000 characters, fewer than 50 changes would trigger detection. This threshold effectively captured minor variations while avoiding false positives due to insignificant changes. To ensure the rigor of our analysis, we excluded comparisons where the instructions field was shorter than 50 characters, filtering out trivial entries such as single words or short phrases. This ensured that our analysis focused on substantial content repli- cation. Focusing on high-similarity pairs enabled us to detect apps with minimal textual differences, suggesting potential attempts to clone content while avoiding exact duplication.\n2) BERT-based semantic similarity calculation\nTo detect more nuanced instances of app cloning, where the wording might vary while the underlying meaning re- mains consistent, we employed a BERT-based model [23] to compute semantic similarity. Unlike character-based methods, this model utilizes contextual embeddings to capture the semantic closeness between two pieces of text, allowing for the detection of deeper, more subtle forms of copying. The BERT model maps each input text into a high-dimensional vector space, where semantically similar texts have closer vec- tor representations. Given two texts, t1 and t2, their semantic similarity score is calculated using the cosine similarity of their vector embeddings:\nCosine Similarity ( t 1 , t 2 ) = V 1 \u22c5 V 2 | | V 1 | | \u22c5 | | V 2 | | (2)\nwhere v1 and v2 are the embedding vectors generated by the BERT model for texts t1 and t2, respectively. The cosine sim- ilarity score ranges from 0 to 1, with higher values indicating greater semantic similarity.\nWe set a threshold of 0.95 for semantic similarity, meaning that if two texts scored above this value, they were flagged as having a strong semantic resemblance. This high threshold ensures precision, reducing the likelihood of false positives, while still capturing relevant instances of duplication. Similar to the Levenshtein distance method, we excluded LLM apps where the instructions fields were shorter than 50 char- acters. Additionally, due to model limitations, we excluded"}, {"title": "V. MEASURING IMPERSONATION APPS", "content": "In this section, we use LLMappCrazy to analyze imper- sonation apps in LLM app stores, focusing on squatting and cloning. Our investigation is guided by the following RQs:\nRQ1 To what extent are squatting apps present? Do they primarily target popular apps? We aim to analyze the prevalence of squatting apps in LLM app stores and determine whether they target more popular apps.\nRQ2 How widespread is cloning apps, as another form of impersonation, in LLM app stores? The low barrier to creating LLM apps has allowed cloning apps in LLM app stores to emerge. Our goal is to investigate the prevalence of these apps and understand their potential impact on users and the ecosystem.\nRQ3 How many cases of potential cross-platform pla- giarism exist? What are the situations in different stores? This RQ aims to understand how app duplication across platforms impacts the uniqueness and integrity of LLM apps, and whether certain stores are more vulnerable to this issue than others.\nA. RQ1: Distribution of Squatting LLM Apps.\nIn response to RQ1, we explore the prevalence and charac- teristics of app squatting among LLM apps. Our experiments rely on data from GPTS APP [15], the largest third-party GPT store, which provides rankings for the top 1000 LLM apps. This platform is essential for our analysis as it offers a ranking system not available in the official GPT Store [27], making it a representative source. To refine the results and minimize false positives, we applied a filtering process. Apps signed by the same developer but with slight name variations, such as platform-specific versions, were excluded. For example, different releases of an \"Image Generator\" app by the same developer across platforms were not considered squatting. Additionally, apps with common, non-branded names, like \u201cImage Generator\", were filtered out unless their package names followed predefined squatting patterns.\nOnce the data was extracted, we systematically compared it against the GPT dataset to identify instances of name duplication. This comparison revealed that 7,119 apps shared their names with those found in the top 1000 apps, sug- gesting a widespread occurrence of potential app squatting behavior. Notably, the most frequently duplicated app name was \"Prompt Engineer\" [4], which appeared 214 times across different records and was ranked 137th, indicating its signif- icant popularity and the possible intent to capitalize on its recognition. Table II below provides an overview of the five apps with the highest number of duplicate names, offering insights into the scale of this phenomenon and the types of apps most often targeted.\nTo further examine the prevalence of app squatting, we utilized our tool LLMappCrazy, to generate various name variations for the top 1000 apps, incorporating common\""}, {"title": "VI. THREAT AND IMPACT", "content": "we then examine the threat posed by impersonation apps and their impact on users and the LLM app ecosystem by exploring the following research questions:\nRQ4 How many impersonation (squatting and cloning) apps are malicious? Understanding how many of these squatting and cloning apps are malicious will provide insight into the extent of harm they can cause, such as spreading malware or conducting phishing attacks.\nRQ5 What is the impact of these impersonation apps on users and the LLM app ecosystem? This RQ seeks to assess how impersonation apps affect user trust and security, as well as their broader impact on the LLM app ecosystem's integrity.\nA. RQ4: Malware Presence\nWhen certain apps exhibit a very high degree of sim- ilarity in the fields of app name, description, and instructions, it is clear that these apps are deliberately imitating others, strongly suggesting an intent to impersonate. ting apps, we found 18.7% violating LLM app usage poli- cies [17]. Of these, 2% provided instructions encour- aging guideline violations, and 0.3% linked to an unknown website, raising phishing concerns. Alarmingly, 16.4% apps directed users to generate inappropriate content, including sexual, violent, or illegal material. In the 370 cloned apps, 4.9% were non-compliant with LLM policies. Among them, 0.5% encouraged violations, and 3.5% promoted inappropriate content. Notably, 0.8% exhibited fraudulent behavior, claiming to operate \"fully automated with a high win rate\" to lure users with false promises. As shown in Figure 10, the malicious be- haviors detected in our study fall into three categories: policy violations, inappropriate content, and disinformation, with inappropriate content being the most prevalent. Apps promot- ing illegal content, misleading users, or encouraging policy violations pose serious risks to user safety and data security, undermining trust in LLM platforms and the app ecosystem. If left unchecked, these apps could normalize unethical practices and attract more malicious actors. Our findings highlight the urgent need for stricter regulations and robust monitoring in LLM app stores to ensure user protection and maintain ethical standards, fostering a secure and trustworthy environment.\nAnswer to RQ4. We found that 227 apps exhibited high simi- larity in app name, description, and instructions, indicating deliberate impersonation. Additionally, among the examined apps, 65 out of 347 squatting apps and 18 out of 370 cloning apps were found to be non-compliant. These apps often provided instructions that violated policies, gener- ated inappropriate content, or engaged in fraudulent practices, underscoring significant security risks and the urgent need for stronger regulations to protect users and the ecosystem.\nB. RQ5: Impact on Users\nSquatting apps in LLM app stores have reached high usage levels, significantly affecting users. Of the 3,509 identified squatting apps, 2,835 had conversation counts between 0 and 1,000, showing a large portion with lower engagement. How- ever, 674 apps exceeded 1,000 conversations, and 50 surpassed 50,000, demonstrating substantial user interaction. In particu- lar, the top squatting app had 12,969,368 conversations, while another app with nearly identical instructions ranked third"}, {"title": "VII. DISCUSSION", "content": "A. Mitigation & Implications\nWe propose strategies to address the challenges of LLM app squatting and cloning, focusing on three key stakeholders:\nLLM app store managers. Platforms should enhance their app review processes by incorporating automated and manual checks to detect duplicate or similar apps. Advanced pla- giarism detection tools can help identify potential plagiarism during the submission process. Additionally, recommendation algorithms should be improved to prioritize unique, high- quality content and reduce the visibility of cloned apps, en- suring that users encounter a wider variety of original options.\nLLM app developers. Developers should take an active role in protecting their apps from squatting and cloning. This includes selecting distinct, non-conflicting app names and regularly monitoring for potential infringements. If unautho- rized replicas are found, developers should report these to the platform maintainers to ensure prompt action.\nEnd users. Educating users about the risks of cloned or unauthorized apps is crucial. They should be taught to identify suspicious apps and use tools to verify legitimacy. Developers and platforms can help by offering resources like tutorials and reports to guide users in avoiding squatting attacks and choosing legitimate apps.\nB. Threat to Validity\nIdentical app name detection. Unlike traditional mobile app squatting detection, our approach includes identical app names in LLM app stores, where duplicates are allowed. Squatting attackers tend to use exact names to mimic legitimate apps and deceive users. Including identical names helps detect as many squatting apps as possible. As many developers choose names casually, this can lead to unintentional duplication and false positives. To better distinguish intentional squatting from accidental duplication, we combine squatting and cloning detection based on both name and instruction similarity.\nPopular app selection. Our detection of LLM app squatting focuses mainly on the GPT Store, as it is the only platform with app ranking data. This research targets popular apps, which we believe is appropriate since attackers tend to fo- cus on well-known applications. However, future work will examine how to generalize our findings to more LLM apps.\nTool limitation. Although LLMappCrazy is specifically tai- lored for LLM apps, the generation model may still be in- complete, leaving room for other complex squatting methods. To address this, we designed the squatting generation models in LLMappCrazy as an easily extensible tool, allowing new patterns to be added seamlessly. In cloning detection models, due to input length limitations, we only analyzed instructions of a specified length, potentially missing cloning in apps with longer instructions. However, our results still provide initial evidence of cloning in the LLM app ecosystem, and we plan to improve our detection methods in the future.\nCross-platform deduplication Different authors may use different names across platforms, and in our cross-platform plagiarism analysis, we can only accurately identify cases where the author names are identical. This limitation highlights the need for additional verification processes to distinguish be- tween legitimate cross-platform distribution and unauthorized replication by third parties."}, {"title": "VIII. CONCLUSION", "content": "In this study, we conducted the first large-scale analysis of LLM app squatting and cloning using our tool, LLMappCrazy. Through the detection of 14 squatting generation techniques and leveraging both Levenshtein distance and BERT-based semantic analysis, we identified over 5,000 squatting apps from variations of top app names. Across six major platforms, we found 3,509 squatting apps and 9,575 cloning cases. Our sampling revealed that 18.7% of the squatting apps and 4.9% of the cloning apps exhibited malicious behavior, highlighting significant risks to user security and the integrity of LLM app stores. These findings underscore the need for stronger oversight and protective measures in the LLM app ecosystem."}]}