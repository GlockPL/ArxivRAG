{"title": "Boolean Matrix Logic Programming", "authors": ["Lun Ai", "Stephen H. Muggleton"], "abstract": "We describe a datalog query evaluation approach based on efficient and composable boolean matrix manipulation modules. We first define an overarching problem, Boolean Matrix Logic Programming (BMLP), which uses boolean matrices as an alternative computation to evaluate datalog programs. We develop two novel BMLP modules for bottom-up inferences on linear dyadic recursive datalog programs, and show how additional modules can extend this capability to compute both linear and non-linear recursive datalog programs of arity two. Our empirical results demonstrate that these modules outperform general-purpose and specialised systems by factors of 30x and 9x, respectively, when evaluating large programs with millions of facts. This boolean matrix approach significantly enhances the efficiency of datalog querying to support logic programming techniques.", "sections": [{"title": "Introduction", "content": "A great body of work has focused on datalog programs as specifications of first-order logic in AI and an essential language for querying knowledge bases. Traditional datalog query evaluations primarily concentrate on symbolic computations. However, matrix operations have been shown to provide high-performance datalog query evaluations. As shown in Figure 1, boolean matrix logic programming could allow AI developers to combine efficient operations to evaluate complex datalog programs in reasoning about perceptions, inductive and abductive learning. Many studies have explored first-order logic program evaluation in tensor spaces. Despite the compatibility with off-the-shelf tensor frameworks, embedding recursive datalog programs has been difficult for tensor techniques. Bounded-depth queries of linear recursive datalog programs have been approximated but it is known that determining the boundedness is undecidable. Rewriting linear datalog programs in linear tensor algebra has only been possible for dyadic programs where every variable in a clause appears exactly in two literals . Exact arithmetic solutions for multilinear datalog programs cannot be effectively computed and are not composable. In contrast, boolean matrix operations provide the correctness guarantee and modularisation in evaluating datalog programs.\nIn this paper, we explore an alternative logic programming approach to datalog query answering based on boolean matrices. To start, we propose Boolean Matrix Logic Programming (BMLP) as a general query answering problem with boolean matrices. We focus on datalog programs where clauses contain predicates of arity at most two (P\u2081 as an example program). Arity-two datalog programs extended with predicates that encode function input-output pairs have Universal Turning Machine expressivity . The BMLP problem is the first formalisation of this kind as a broad logic programming task. Theoretically, we prove BMLP modules can be combined to evaluate arity-two linear and non-linear recursive datalog programs. To showcase composability, we evaluate a non-linear program by combining a BMLP module with boolean matrix operations and explain how BMLP modules relate to second-order datalog programs. Implementation-wise, we created two BMLP modules for programs having the same form as P1, repeated"}, {"title": "Related work", "content": "Bottom-up datalog evaluation. Most approaches employed traditional symbol manipulations. Obtaining the least model of graph-like datalog programs can be reduced to computing the transitive closure of boolean matrices. Fischer and Meyer (1971) studied a logarithmic divide-and-conquer computation technique by viewing relational databases as graphs and showed a significant computational improvement over direct concatenation of matrix operators. A similar approach was explored by Ioannidis (1986) for computing the fixpoint of recursive Horn clauses. Compared with traditional Inductive Logic Programming (ILP) which searches for generalisable rules symbolically, Muggleton (2023) employed the logarithmic technique in the DeepLog ILP system. It constructs the bottom clause iteratively through repeated squaring of boolean matrices.\nDatalog evaluation in tensor space. Grefenstette (2013) developed a tensors-based calculus to represent truth values of domain entities, logical relations and operators for first-order logic but this did not treat the quantifiers in datalog programs. Nickel et al. (2011) represented semantic webs' binary relations in bilinear form and truth values of ground atoms as tensors. Rocktaschel et al. (2015) computed the inner product between one-hot vectors encoding entity pairs and binary relations for the truth values. Unlike our approach, they only approximated linear datalog queries and did not model recursions. As previously mentioned, Sato showed that a subset of linear recursive datalog programs with arity two can be embedded in tensor space as linear algebraic equations. Sato et al. (2018) established a linear algebra abduction framework based on this approach. Here, in contrast to BMLP, arithmetic solutions of algebraic systems do not apply non-linear datalog programs and require all-in-one-piece implementations.\nFirst-order rule learning with tensors. While a substantial body of work explored rule learning using tensors, most only approximated first-order inference. Neural-symbolic methods approximated first-order datalog queries through differentiable unification operators to construct neural networks. In a similar approach, Cohen et al. (2020) used beliefs propagation for bounded-depth probabilistic inferences in stochastic logic programs using off-the-shelf deep learning frameworks. Others only applied tensors to induction but not for query answering. The SILP framework developed by Evans and Grefenstette (2018) utilises program templates to invent predicates and perform gradient descent in binary neural networks to optimise weights of candidate rules. Dai and Muggleton (2021) combined ILP with neural networks to extract probabilistic facts from sub-symbolic data and search for first-order theories based on second-order program templates."}, {"title": "Background", "content": "A variable is a character string beginning with an uppercase letter. A predicate or constant is a character string starting with a lowercase letter. A Horn clause is a disjunctive clause with at most one positive literal. We consider a term to be either a constant or a variable. A definite clause is a Horn clause with one positive literal. A query is a user-posted Horn clause without a positive literal. A fact is a definite clause with only a positive literal and no variables. A first-order definite clause has the form, $A_0 \\leftarrow A_1, ..., A_n$ and $A_0$ is the head and each $A_i$ is a body literal. $A_i = r_i (X_1, ..., X_k)$ has arity k and $r_i$ is a predicate symbol applied to a tuple of terms $x_j$. A second-order definite clause contains second-order variables that can be bound to predicate symbols. A definite clause is range-restricted if every variable in $A_0$ appears among variables in $A_k$ for $1 \\leq k \\leq n$. All non-range-restricted definite clauses have equivalent range-restricted forms. We refer to a definite clause as a clause.\nA recursive clause has a predicate in its body that also appears in the head of some clause. A linear recursive clause (e.g. the second clause in P\u2081) has at most one predicate in its body that appears in the head of some clause . A datalog program is a set of definite clauses without function symbols. A recursive datalog program has a recursive clause. A linear datalog program (e.g. P\u2081) only contains linear clauses. This definition differs from piecewise linear programs which can be decomposed into multiple linear programs. H\u207f datalog programs contain predicates of arity at most two and at most n literals in the body of each clause. A clause \u03b1 entailed by a program P is written as $P \\models \\alpha$. The least model is the minimal set containing all facts that are entailed by P."}, {"title": "Boolean matrix logic programming", "content": "In contrast to traditional logical inferences that manipulate symbols, BMLP emphasises programming boolean matrix operators. As we will explain in the rest of the paper, combining modules facilitates diverse architectures for efficient first-order query answering in datalog programs. In addition, each BMLP module corresponds to a second-order datalog program, which provides an alternative perspective of Inductive Logic Programming. We present an example of the boolean matrix encoding and implementations of two BMLP modules."}, {"title": "Problem definition", "content": "Definition 1 (BMLP problem). Let P be a H\u2082 datalog program containing a set of clauses with predicate symbol r. The goal of Boolean Matrix Logic Programming (BMLP) is to output a boolean matrix R encoded in datalog such that $(R)_{ij} = 1$ if $P \\models r(c_i, c_j)$ for constants $c_i, c_j$ and $(R)_{ij} = 0$ otherwise.\nBoolean Matrix Logic Programming (BMLP) is general for monadic predicates which can be expressed via dyadic predicates by repeating the single argument. Stored higher-arity predicates are expressible via multiple binary predicates. An arbitrary predicate representing input-output pairs of a computation can be mapped to composite constants such as $c_1 -c_2$. A subset of H2 programs, namely the H3 program"}, {"title": "Boolean matrix representation", "content": "A bijective function maps constants in a datalog program P to a subset of natural numbers N\u2080. Mapped constants are totally ordered by the \u201c<\u201d relation so each constant is uniquely identified. We encode a boolean matrix R in datalog to express a clause r. Every matrix row $(R)_{i,*}$ is a fact $v(i, b_i)$ and $b_i$ is denoted by a binary code such that the j-th bit $(b_i)_j$ is 1 if $P \\models r(c_i, c_j)$ and 0 otherwise.\nExample 1. Consider P\u2081 in Section 1. A boolean matrix R is created from {edge(a,b), edge(b, c)} \u222a P\u2081. Constants {a,b,c} are mapped to row and column indices {0,1,2}. The v facts on the right represent rows in R.\nWhen $c_i$ and $c_j$ ($0 \\leq i, j < n$) come from the same set of constants, a boolean matrix created this way is an n \u00d7 n square matrix and an operator with the same domain and range. Vectors are treated as single-row matrices."}, {"title": "BMLP modules", "content": "From a high level, each BMLP module aims to map one set of facts to another set via multiple boolean matrix operations. $2^\\mathbb{C}$ denotes the set of all derivable k-arity facts in a datalog program P.\nDefinition 2 (BMLP module). A BMLP module is an operator $f: 2^\\mathbb{C} \\rightarrow 2^\\mathbb{C}$ where $\\mathbb{C}$ is encoded by boolean matrices.\nLet $r_1$ be a stored or directly derivable non-recursive predicate. $r_2$ is a recursive predicate that depends on $r_1$. BMLP-SMP and BMLP-RMS evaluate queries for the following linear recursive H2 datalog program P2:\n$r_2(X, Y) \\leftarrow r_1(X,Y)$.\n$r_2(X, Y) \\leftarrow r_1(X, Z), r_2(Z, Y)$.\nBoolean matrices $R_1$ and $R_2$ encode $r_1$ and $r_2$. BMLP-RMS evaluates all derivable groundings of $r_2$, while the BMLP-SMP module only finds derivable facts from a partially grounded query $r_2(c, Y)$ given some constant c."}, {"title": "BMLP composability", "content": "Multiple BMLP modules can be combined by computing, storing and reusing the output of modules. The simplest modules compute linear H\u2082 datalog programs.\nDefinition 3 (Linear BMLP modules). A BMLP module is called linear if it computes a linear H\u207f datalog program.\nBMLP-RMS and BMLP-SMP are linear modules by construction. Recall the relational operator in the set S, namely cross product, selection and projection. Boolean matrix operations in BMLP-RMS and BMLP-SMP have equivalent relation operators. Boolean matrix multiplications and additions can be viewed as cross products with projections and selections.\nTheorem 1. Every linear H\u207f datalog program can be computed by some composition of linear BMLP modules.\nProof. Every linear datalog program with range-restricted or non-range-restricted clauses can be computed by concatenations or unions of linear relational operators from S. A BMLP module corresponding to linear binary relation operators is linear by Definition 3. Owing to the closed semiring of linear relational operators, the concatenation or union of linear BMLP modules is also linear.\nWe then prove the composibility of linear BMLP modules for multilinear recursive datalog programs. A clause with m recursive predicates is m-linear if fixing a subset of m \u2212 1 predicates as non-recursive would make this clause linear.\nTheorem 2. Every m-linear H\u207f datalog program is computable by some composition of linear BMLP modules.\nProof. This follows from Theorem 1. A m-linear recursive datalog program contains m-linear clauses and can be reduced to m \u2212 1 bilinear clauses. Every bilinear clause (m = 2) can be evaluated by interleaving computation of linear programs with respect to some partial ordering on the predicates ."}, {"title": "BMLP modules as second-order programs", "content": "BMLP modules are quantified on matrices compatible in size where each can be bound to a predicate as in a second-order recursive clause. For example, the BMLP-RMS module can represent the following program:\n$P(X, Y) \\leftarrow Q(X,Y)$.\n$P(X, Y) \\leftarrow Q(X, Z), P(Z,Y)$.\nwhere {P, Q} are existentially quantified second-order variables that are instantiated by hasPlace and contains in in Figure 3. The composition of matrix operations and BMLP-RMS represents additional predicates to the stored contains and adjoins facts. Recent ILP system invents predicates via"}, {"title": "Implementation", "content": "BMLP-SMP and BMLP-RMS modules are implemented in general-purpose Prolog system SWI-Prolog to accommodate accessibility and reusability for other architectures. Boolean matrix addition, multiplication, transpose and negation are implemented based on boolean operations in SWI-Prolog. In SWI-Prolog, all binary codes are written compactly as equivalent decimal integers whose length can be flexibly extended. BMLP does not exclude infinite domains theoretically but practically machines have finite memory so we limit our implementations to finite-size relations. Matrices are treated as compiled predicates in SWI-Prolog and can be re-consulted if they have changed. Modules store intermediate computation results to be reused. This saves computation resources but would trade off storage.\nBMLP-RMS uses addition and multiplication to compute the transitive closure in Equation (4) via Algorithm 1."}, {"title": "Experiments", "content": "Our experiments examine the computational efficiency of BMLP-RMS and BMLP-SMP modules when evaluating large datalog programs with up to multiple millions of facts."}, {"title": "Benchmarks", "content": "We evaluated BMLP modules on synthetic benchmarks of directed graphs with cycles and Freebase 15K, a dataset created from Freebase widely used for knowledge graph completion. We use a variant of Freebase 15K where inverse relations are not given and have to be evaluated. Directed graphs reachability is computed by the linear recursive H\u2082 datalog program P1. Direct graph datasets were prepared for two tasks, all derivable groundings (DG) and partially grounded query (DG+partial). In DG, all systems computed reachable nodes for all nodes from the query path(X, Y). In DG+partial, all systems evaluated reachable nodes from one specific node path(c, Y). From Freebase 15K , we extracted the contains and adjoins facts and constants are wrapped by location predicate. We used the combined datalog program P3 \u222a P4 \u222a P5 to evaluate derivable isForeign facts."}, {"title": "Compared systems", "content": "Non-BMLP systems include the state-of-the-art datalog engine Souffle, general-purpose Prolog systems SWI-Prolog and B-Prolog, and Answer Set Programming (ASP) system Clingo. ASP differs from datalog programs, which searches over grounded stable models. Both SWI-Prolog and B-Prolog implement tabling to ensure termination and faster query evaluation, and B-Prolog has state-of-the-art tabling performance. We did not compare with Sato's work on datalog evaluation in tensor spaces due to the source code not being accessible. All non-BMLP systems were their latest versions prior to the paper submission."}, {"title": "Preparation", "content": "Table 1 shows the size of benchmarks. In each dataset, the number of derivable facts is O(n\u00b2). In DG and DG+partial, we varied the size of programs by $p, p_t \\in [0,1]$ where $p$ is randomly sampled to decide if an edge exists between two nodes $p < p_t$. A directed graph with k edges and n nodes is a datalog program of k edge facts and n constants. DG, DG+partial and FB15k-237 datasets were then compiled into boolean matrices for BMLP modules. We recorded each method\u2019s mean CPU time in evaluating various queries, which was capped at 15000 seconds. All experiments have been performed on a single thread with Intel(R) Core(TM) i9-7900X CPU @ 3.30GHz and 32GB RAM."}, {"title": "Results", "content": "Table 2 shows that BMLP module runtimes were not significantly affected by the number of facts in the program as we changed pt. In DG, BMLP-RMS is 9x faster than Souffle, 33x faster than B-Prolog and at least 49x faster than Clingo or SWI-Prolog when pt = 0.5. Interestingly, BMLP-RMS's runtimes also reduced after pt > 0.01. In graphs with more edges, the shortest paths between nodes have lengths closer to 1, therefore fewer squaring operations are needed to reach transitive closure. This is more explicitly shown in Figure 4 where BMLP-RMS runtime has a clear upper bound. This supports Proposition 1 since its time complexity is not affected by the number of facts. We suspect the dip in runtime"}, {"title": "Conclusion and future work", "content": "We utilised boolean matrices encoding of datalog and proposed Boolean Matrix Logic Programming (BMLP) as an overarching logic programming problem. Two composable BMLP modules, BMLP-RMS and BMLP-SMP, are implemented to evaluate linear recursive datalog programs. Theoretically, we showed a combination of BMLP modules can evaluate linear and non-linear dyadic datalog programs. BMLP modules can also be applied to invent predicates. Our results empirically showed that BMLP modules are significantly faster than state-of-the-art general and special-purpose systems for evaluating large programs with millions of facts.\nLimitation and future work: BMLP modules do not perform as well on sparse matrices, so we will focus on computation improvements in the future. To the best of our knowledge, no bilinearisation framework of multilinear programs exists that uses boolean matrices. This gap could be filled to systematically create non-linear BMLP architectures. Modules that consider dynamic databases would be more robust. Related work has not explored matrix operations. The DeepLog system showed the feasibility of involving boolean matrices to represent H2 second-order programs for induc-"}, {"title": "BMLP source code and examples", "content": "We refer readers to the GitHub repository for the complete implementation of BMLP methods and modules. For showcasing, we use the datalog program ex.pl with facts in Example 1 in Section 4.2. The monadic node predicate describes the type of constants:\nnode (a). node(b). node(c).\nedge(a,b). edge(b,c)."}, {"title": "Initialisation and compilation", "content": "BMLP modules need to be initialised to a folder to save intermediate computation results and the default folder is \"BMLP/temp/\". If a database has not been encoded as a boolean matrix, it can be compiled via the compile(+String,+DB,-Matrix) method. The string input is the path to a *.pl file. Target relation and entity types in this file need to be defined by the db term. In this case, it contains the name of the dyadic predicate edge, and the type of constants node.\nIf a matrix has been encoded, it can be loaded using lm_consult method. We can print the matrix M1.\nM1 is an encoded boolean matrix, represented by a matrix term of signature matrix(+List, +TypeList,+DimensionList, +Options). For example, M1 is a term matrix([edge, 1], [node, node], [3, 3], []), and all entities are 3 nodes and its dimension is 3 x 3. This initial matrix has not been used by any operations yet, so we have given it an identifier \"1\". Every matrix returned by boolean matrix operations would be given a unique suffix identifier. One can convert from a Matrix back to a List of Facts using lm_to-facts(+Matrix, +List) by adding the following body to the above. This would print out the list [path(a,b), path(a,c), path(b,c)]."}, {"title": "Computation", "content": "All boolean matrix operations, including the two BMLP modules, automatically load input matrices if they have not been loaded before. BMLP-RMS and BMLP-SMP are computed by rms and smp methods, which we illustrate below.\nBMLP-RMS example. BMLP-RMS's method signature is rms(+Matrix1, -Matrix2, +Options). BMLP-RMS module takes a square boolean matrix as Matrix1. The output square boolean matrix Matrix2 is computed using additional and multiplication, as shown in Figure 2. The following example computes the transitive closure of paths from ex.pl. A series of matrix operations creates multiple matrices and a unique identifier \u201c3\u201d has been assigned to the output matrix.\nBMLP-SMP example. Recall that BMLP-SMP evaluates a subset of the derivable facts by iteratively adding and multiplying a square boolean matrix with a vector. Its signature is smp((+Vector1,+Matrix), \u2013Vector2). A vector is also a matrix term but its first dimension is always 1. We create a vector from a compiled matrix using the lm_select method. For example, if we want to know derivable facts from the query path(a, Y), where a is a node and its edges have been encoded by matrix M1, we can call lm_select to get a vector V1 that encodes a. The output vector V2 encodes all nodes reachable via some path from a."}, {"title": "Experimentation details", "content": "We record the CPU runtime statistics of all methods in evaluating queries and repeat each experiment with 10 repeats. B-Prolog and SWI-Prolog have methods, cputime and call_time, respectively for reporting runtimes. Runtime"}, {"title": "Directed graphs", "content": "Directed graph datasets, DG and DG+partial, allow us to investigate the runtime variations as a function of the number of facts and the number of constants in the datalog program. These datasets contain dyadic edge and monadic node facts. We only show programs for the benchmark DG since we replaced parts of those programs for the DG+partial benchmark (see commented sections below). Prolog systems do not directly compute the least model, so for B-Prolog and SWI-Prolog, we call the clause closure in the following program to compute derivable facts of path and store them in a table:\nIt is more straightforward with Clingo which searches for models, we used the answer set program to evaluate and show only path:"}, {"title": "Freebase 15K", "content": "We use the Freebase 15K variant because it does not contain the inverse of relations. BMLP architecture would perform with boolean matrix transpose operations to invert relations. In addition, the extensive set of constants but a relatively small amount of facts provides a good stress test for BMLP methods. As mentioned in Section 6.1, we extracted the contains and adjoins facts from FB15k-237 and constants are wrapped by location predicate.\nNon-BMLP systems used the program P3 U P4 U P5 in Section 4.4. We focused on grounding isForeign predicate but derivable facts of involved predicates were also computed by tabling, Clingo or BMLP methods. For SWI-Prolog, we allocated 10GB table space using set_prolog-flag. We did not have to allocate table space for B-Prolog because it automatically expands it. For both B-Prolog and SWI-Prolog, we used:\nFor Souffle, the inputs are contains, adjoins and location. The output is isForeign."}]}