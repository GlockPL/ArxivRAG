{"title": "PixLift: Accelerating Web Browsing via AI Upscaling", "authors": ["YONAS ATINAFU", "SARTHAK MALLA", "HYUNSEOK DANIEL JANG", "NOUAR ALDAHOUL", "MATTEO VARVELLO", "YASIR ZAKI"], "abstract": "Accessing the internet in regions with expensive data plans and limited connectivity poses significant challenges, restricting information access and economic growth. Images, as a major contributor to webpage sizes, exacerbate this issue, despite advances in compression formats like WebP and AVIF. The continued growth of complex and curated web content, coupled with suboptimal optimization practices in many regions, has prevented meaningful reductions in web page sizes. This paper introduces PixLift, a novel solution to reduce webpage sizes by downscaling their images during transmission and leveraging AI models on user devices to upscale them. By trading computational resources for bandwidth, PixLift enables more affordable and inclusive web access. We address key challenges, including the feasibility of scaled image requests on popular websites, the implementation of PixLift as a browser extension, and its impact on user experience. Through the analysis of 71.4k webpages, evaluations of three mainstream upscaling models, and a user study, we demonstrate PixLift's ability to significantly reduce data usage without compromising image quality, fostering a more equitable internet.", "sections": [{"title": "1 Introduction", "content": "In many developing regions, internet access remains prohibitively expensive, with individuals constrained by limited data plans [22, 31]. This digital divide hinders access to information, restricts economic opportunities, and exacerbates inequality [15, 28]. Images are a major factor in the large sizes of modern webpages, accounting for a median of 40% of total page weight on desktops and 37% on mobile devices [10]. While advanced image formats like WebP [18] and AVIF [13] have significantly improved compression efficiency, the overall size of webpages continues to grow due to increasingly complex and curated content [10].\nPrevious research has explored innovative image optimization techniques, focusing on strategies such as fetching only a portion of the image (e.g., 50%) and reconstructing it via mirroring [26], reducing quality for progressive images [26], or even replacing images with semantically similar alternatives [33]. Inspired by this body of work and the recent advances in generative AI [9, 11, 12, 19, 25], we propose a novel approach: request scaled down version of images on webpages during transmission and leverage an AI model running on a user's device to scale them back up. This approach (PixLift) trades local resources (GPU and CPU cycles, which are relatively cheap) for bandwidth (which is expensive and limited in developing regions). Despite its simplicity, this idea has several challenges addressed in this paper.\nImage Scaling Support. The first challenge we address is assessing the availability of image scaling in the wild. Specifically, which percentage of web servers are capable of responding to modified requests for reduced image sizes?. To answer this question, we conduct a large-scale crawl of the top 71.4k websites listed in the HTTP Archive [10], testing various request strategies inspired by [26]. We find that 10% of these webpages have at least some partial support for remote image downscaling, with up to full support for 1.5% of the webpages."}, {"title": "2 Related Work", "content": "Many researchers have investigated methods to enhance web browsing performance and user experience, but fewer have focused specifically on the role of images. We identify and briefly summarize three key studies in this area. WebLego [33] proposes an innovative solution that races semantically similar images, trading strict content fidelity for faster loading speeds. However, WebLego tends to increase the overall page size, making it unsuitable for developing regions with limited bandwidth. ScaleUp [29] is a browser extension that dynamically adjusts browser scaling to reduce the number of objects loaded above the fold. While ScaleUp is designed for low-bandwidth networks, its effectiveness is limited when websites load substantial content below the fold, as we observed in Pakistan (see Figure 1(c)). Moreover, ScaleUp can serve as a complementary approach to PixLift. BrowseLite [26] is a client-side tool that optimizes web images for data savings by opportunistically requesting alternative image encodings or partial image data. PixLift builds on the ideas from BrowseLite by introducing a novel approach: requesting highly compressed images and leveraging local AI models for upscaling, further enhancing data savings and performance."}, {"title": "3 Image Scaling Support", "content": "Methodology. We use BigQuery to analyze the HTTP Archive [24], querying data for the top 50,000 webpages (as per the site popularity in the Chrome User Experience Report (CrUX) [1]). From these webpages, we extract the URLs of all embedded images, resulting in a comprehensive set of 3,185,097 unique images hosted by 54,754 unique domains. Inspired by BrowseLite's methodology [26], we analyze these unique image URLs to identify common patterns embedded in the URLs that might be related to image resizing, e.g., \u201cwidth=\u201d, \u201cresize/(large or small or medium)\u201d, \u201c300x300\u201d, etc. This analysis identifies 35 regular expression patterns, 5 more than BrowseLite which though only analyzed 1,200 webpages. To investigate whether these 54,754 domains \u201cactually\u201d support image resizing, we further select one random image URL per domain and test against these 35 regular expressions."}, {"title": "4 PixLift Design", "content": "To integrate super-resolution capabilities into a user's web browsing experience, we develop PixLift as a Chromium extension (Manifest V3 [4]). This approach simplifies deployment by avoiding browser modifications and facilitates easy installation on all Chromium-based desktop browsers, and few mobile browsers (e.g., Yandex and Kiwi). The extension operates transparently, processing images on-the-fly as users navigate webpages, and privately, ensuring that no raw image data or sensitive metrics are left in the browser environment.\nGiven the goal of PixLift to upscale images via super-resolution, we first integrate several of the most promising image upscaling models into the browser. To ensure compatibility and efficient deployment of the super-resolution models, we employ a three-stage conversion pipeline transforming these models from PyTorch (.pth) [8] to TensorFlow.js (.tfjs) [17]:\n(1) Conversion to ONNX: Export PyTorch models to the Open Neural Network Exchange (ONNX) format (.onnx) [16], enabling interoperability between machine learning frameworks.\n(2) Conversion to TensorFlow: Convert ONNX models to TensorFlow (.tf), integrating them within TensorFlow's ecosystem.\n(3) Conversion to TensorFlow.js (TFJS): Convert TensorFlow models to TensorFlow.js (.tfjs), including quantization to Float16 for improved performance and compatibility on mobile.\nModel Conversion Process. To ensure compatibility and efficient deployment of super-resolution models in the browser, we implement the following three-stage pipeline. First, we export the PyTorch (.pth) models [8] to the Open Neural Network Exchange (ONNX) format (.onnx) [16] for interoperability. Second, we convert ONNX models to TensorFlow (.tf) format [17]. Finally, we transform TensorFlow models into TensorFlow.js (.tfjs) [17] with Float16 quantization [14] for enhanced performance on mobile devices.\nCurrently, PixLift supports three mainstream super-resolution models: a) SESR-M5 [12], a lightweight transformer-inspired model for efficient super-resolution on mobile platforms; b) SR_Sub-Pixel CNN [19], an optimized CNN using sub-pixel convolution for fast and accurate super-resolution; c) QuickSRNet Small 4X [11], which is suitable for real-time applications on less powerful devices.\nEnvironment Configuration. Our solution is implemented as a browser-based extension lever-aging TensorFlow.js for real-time enhancement. We configure TensorFlow.js to leverage WebGL [5] - await tf.setBackend(\u2018webgl') \u2013 for GPU acceleration. We disable WEBGL_FORCE_F16_TEXTURES to balance between performance and memory usage. Finally, we use await tf.ready() to confirm a successful model setup and deployment.\nModel Loading and Validation.\nModels are loaded asynchronously using TensorFlow.js's tf.loadGraphModel(modelURL), a process designed to minimize blocking of the browser's main thread. During this loading phase, we record the initialization time as a metric to evaluate the model's loading efficiency and readiness. After the models are loaded, we perform a validation"}, {"title": "5 PixLift Evaluation", "content": "This section evaluates PixLift with respect to: 1) user QoE quantified by image quality assessment and page load times, 2) resource usage measured via data, CPU/GPU, and memory utilization."}, {"title": "5.1 Methodology", "content": "Our evaluation is composed of three parts: controlled and in-the-wild experiments, and a user study.\nControlled. We equip three testing devices with the Kiwi browser and the PixLift addon. The three devices cover a range of entry-level to mid-range mobile phones [21, 23, 32]: Galaxy A03s an entry-level phone that costs ~$100 with an Octa-core CPU (4x2.35 GHz Cortex-A53 & 4x1.8 GHz Cortex-A53), a PowerVR GE8320 GPU, and 4GB RAM; Galaxy A12 a low-end phone that costs ~$130 with an Octa-core CPU (4x2.35 GHz Cortex-A53 & 4x1.8 GHz Cortex-A53), a PowerVR GE8320 GPU, and 4GB RAM; and Galaxy A34 a mid- to high-end phone that costs ~$210 with an Octa-core (2x2.6 GHz Cortex-A78 & 6x2.0 GHz Cortex-A55), a Mali-G68 MC4 GPU, and 4GB RAM. For each super-resolution model-device pairing, we conduct 500 experiments where we load 50 times a testing webpage we created that includes between 1 and 10 visible images, i.e., above the fold. The images are randomly chosen from a pool of 100 images with various sizes and image formats.\nIn-the-Wild. For these experiments, we aim to test the performance of PixLift with real websites today, i.e., given current support of image scaling (see Section 3) as we all as assuming full support, i.e., all served images can be requested with a smaller size. We develop a testing tool based on Puppeteer [7] to automate the loading of testing webpages via the Brave browser [6]. We choose Brave because of its support for adblocking which removes noise from experiment runs. Our tool loads a testing webpage while intercepting all the requested images within a Page Load time (PLT) [2], which measures the amount of time it takes for a webpage to fully load. For each image, it then performs local resizing while keeping the same compression quality. It then uses this data savings to derive potential size and time savings assuming full PixLift support. Next, it uses the strategy from Section 3 to test whether such smaller images could already be requested today, and adjust such savings.\nWe build a dataset of the 1,000 most popular Pakistani webpages, identified from Tranco's top 1 million list [27] by filtering for webpages with the .pk domain. Each webpage is loaded five times with network conditions set to \u201c3G Fast\u201d (1.6 Mbps downlink/768 Kbps uplink with 150ms RTT) [30]. This network condition reflects the \u201caverage\" configuration based on Google's Lighthouse standard recommendation for mobile throttling, simulating the 85th percentile of mobile connection speeds [30]. We emulate a typical modern viewport (393x852 pixels as in recent iPhone\""}, {"title": "5.2 Results", "content": "Resource Usage and Image Quality. Figure 1(a) shows the total upscaling time as a function of model, mobile device, and number of images located above the fold of a webpage. The upscaling time is mainly composed of the time required to transfer image data back and forth between the CPU and GPU, and the GPU processing time. Each parameter combination in the figure is visualized as a boxplot referring to 50 runs. Given boxplots from different devices/models overlap, to improve the plot visibility we use a shade to indicate to which model a boxplot refers to.\nAt a high level, the figure shows that \u201cQuickSRNet Small 4X\u201d is the most time-efficient model, almost 10x faster than \u201cSR_Sub-Pixel CNN\u201d which is instead the least time-efficient model. Device-wise, the A03s and A12 perform quite similarly, while the A34 is, on average, 2x faster; e.g., it can upscale 10 images in 2.5 seconds versus 5 and 6 seconds for the A03s and the A12, respectively.\nFigure 1(a) also shows a linear upscale duration growth between 1 and 2 images, followed by sublinear growth next. When considering a single image, the CPU-to-GPU transfer time is \u201cwasted,\u201d meaning that no GPU processing is possible at this time. The same is true with two images, given that we allow for two concurrent images to be handled by the GPU concurrently (see Section 4). However, if the GPU is powerful enough to handle two images concurrently, then the GPU processing time would drop. Indeed, the upscaling time lasts 1.2 seconds with 1 image and 2 seconds with 2 images, or a 16% time reduction for both the A03s and the A12, whereas a 33% time reduction is measured for the more powerful A34. As we increase the number of images to be upscaled past three, PixLift's queuing mechanism ensures that a new image is transferred to the GPU as soon as an image is completed, while another image is being processed, thus amortizing the GPU transferring time. This behavior explains the sublinear growth realizing an average processing time of 0.2-0.6 seconds per image when considering batches of 10 images, and variable GPU performance.\nFigure 1(b) shows the CPU memory (RAM) usage as a function of device and model under test. Each boxplot refers to experiments with variable number of images, hence the variability. The plot shows that QuickSRNet has the lowest memory usage due to its efficient design with a simpler architecture, fewer parameters, and minimal intermediate data. Conversely, R Sub-Pixel CNN has the highest memory usage because its sub-pixel convolution layers significantly expand intermediate feature maps during pixel rearrangement. More powerful devices like the A34 further amplify memory usage by allocating more resources for computations, providing faster upscaling times as shown in Figure 1(a). With respect to CPU usage, PixLift is quite light only accounting for a 10-20% CPU increase depending on model complexity.\nFinally, Figure 1(c) shows the Cumulative Distribution Function (CDF) of the average score per image for each of the 20 images and per super resolution model. The key takeaway is that for 50% of the images with the highest scores (4 or higher), there are no significant score differences among models. However, for the remainder of the images with lower scores, \u201cQuickSRNet Small 4X\" achieves lower scores, e.g., 40% of scores lower than 3 versus 20% for \u201cSR_Sub-Pixel CNN.\u201d Given the 10x reduction in upscaling time achieved by \u201cQuickSRNet Small 4X\u201d (see Figure 1(a)), we conclude that such quality reduction affecting a subset of the images might be tolerable by PixLift users. Nevertheless, an interesting avenue of future work is to design a model selection algorithm capable of switching between super-resolution models based on the observed trade-off between upscaling time and image quality.\nPerformance. Building on the previous results, and given the space limitations, we here investigate PixLift performance assuming \u201cQuickSRNet Small 4X\". Figure 2(a) shows several CDFs of delta Page Load Time (PLT), i.e., the difference between original PLT and PLT via PixLift. We consider two versions of PixLift: today, which can only leverage downscaled images if currently supported by a server, and full, which emulates full image downscaling support. For upscaling duration, we uses the empirical times from Figure 1(a) considering one low-end (A12) and one high-end device (A34).\nOverall, Figure 2(a) shows that PixLift, when assuming full support, can significantly speedup the PLT by more than 7 seconds for the majority of webpages, and even tens of seconds for 30% of the webpages. Slowdowns are rare (less than 7% of webpages), suggesting that the GPU upscaling time rarely lasts longer than PLT. As expected from the analysis in Section 3, most pages (75%) have no support for remote image downscaling. Neverthelees, 20% of the tested Pakistani webpages\""}, {"title": "6 Conclusion", "content": "This work proposes PixLift, a novel approach to reduce webpage sizes by downscaling images during transmission and leveraging AI models on user devices for upscaling, which can enable more affordable and inclusive web access. PixLift trades computational resources for bandwidth, addressing the challenges of expensive data plans and limited connectivity in many developing regions. In summary, the key contributions and findings of this study are:\n\u2022 Feasibility of Image Scaling: An analysis of 71.4k websites revealed that 10% of webpages have partial support for remote image downscaling, with 1.5% offering full support, indicating the potential to leverage existing server capabilities.\n\u2022 Browser Extension Implementation: PixLift is implemented as a Chromium extension, en-suring compatibility with most desktop browsers and some mobile browsers, operating transparently and privately.\n\u2022 AI Upscaling Models: Three mainstream super-resolution models were evaluated, with \u201cQuick-SRNet Small 4X\" demonstrating the best time efficiency, being almost 10x faster than \u201cSR_Sub-Pixel CNN\u201d. However, this efficiency comes at a quality reduction for about 40% of the more challenging images.\n\u2022 User Experience Improvement: PixLift significantly reduces webpage loading times, with a median page load time (PLT) reduction of 7 seconds and even tens of seconds for 30% of webpages when assuming full support for image downscaling. This is achieved with a minimal 10-20% increase in CPU usage and 1 GB memory usage, offloading upscaling to the GPU.\n\u2022 Performance on Diverse Devices: Experiments on a range of devices showed that PixLift significantly speeds up PLT, and the extra time needed by low-end devices to upscale images can be absorbed within a PLT.\n\u2022 Data Savings: PixLift can achieve significant data savings by downscaling images, reducing the overall page size.\n\u2022 Image Characteristics: The analysis of 1,000 Pakistani webpages showed a discrepancy between the number of images fetched (22 at the median) and the number of visible images (2 at the median), which suggests a large potential to reduce data usage by downscaling a large number of images.\n\u2022 User Perception of Quality: A user study revealed that while 50% of images showed no significant quality differences among models, 40% of images showed lower quality scores when using the \u201cQuickSRNet Small 4X\u201d model.\nIn conclusion, PixLift demonstrates the viability of trading computational resources for bandwidth to enhance web browsing, especially in areas with limited and expensive internet access. The \u201cQuickSRNet Small 4X\u201d model offers a practical balance between upscaling speed and image quality, making it suitable for real-world deployment. Further research could explore dynamic model selection based on the trade-offs between upscaling time and image quality. The results of this study suggest that PixLift can significantly reduce data usage and improve page load times, contributing to a more equitable internet."}]}