{"title": "Uncovering Capabilities of Model Pruning in Graph Contrastive Learning", "authors": ["Junran Wu", "Xueyuan Chen", "Shangzhe Li"], "abstract": "Graph contrastive learning has achieved great success in pre-training graph neural networks without ground-truth labels. Leading graph contrastive learning follows the classical scheme of contrastive learning, forcing model to identify the essential information from augmented views. However, general augmented views are produced via random corruption or learning, which inevitably leads to semantics alteration. Although domain knowledge guided augmentations alleviate this issue, the generated views are domain specific and undermine the generalization. In this work, motivated by the firm representation ability of sparse model from pruning, we reformulate the problem of graph contrastive learning via contrasting different model versions rather than augmented views. We first theoretically reveal the superiority of model pruning in contrast to data augmentations. In practice, we take original graph as input and dynamically generate a perturbed graph encoder to contrast with the original encoder by pruning its transformation weights. Furthermore, considering the integrity of node embedding in our method, we are capable of developing a local contrastive loss to tackle the hard negative samples that disturb the model training. We extensively validate our method on various benchmarks regarding graph classification via unsupervised and transfer learning. Compared to the state-of-the-art (SOTA) works, better performance can always be obtained by the proposed method.", "sections": [{"title": "1 Introduction", "content": "In light of the depletion of labeled data and the hardness of annotation, plenty of research attention has been moved from supervised learning to unsupervised learning [18, 55, 73, 75]. While in graph domain, the same issue exists [22]. Correspondingly, referring to the design for unlabeled data training in natural language processing [64, 71] and computer vision [18], several solutions have been dug out through plenty of research efforts and collectively called graph contrastive learning, such as GraphCL [67] and AD-GCL [50].\nIn general, graph contrastive learning sticks to the twin-tower architecture of contrastive learning [7, 59], in which two augmented views are generated from the input graph, and the model loss (i.e., NT-Xent loss [7]) maximizes the mutual information between the two output embeddings of the two augmented views. With this design, the trained model is capable of capturing the essential information of graphs [34, 57, 72]. Moreover, researchers have found that the quality of views influences the performance of contrastive learning models [52]. Therefore, plenty of research efforts have been devoted to the generation of effective views that lead to better performance for graphs through the data augmentation [50, 66].\nContrastive data augmentation on graphs presents a significant challenge compared to images due to the complex structural information and diverse contexts inherent in graph data [10]. Inspecting prior studies on graph contrastive learning, we can systematize the two common paradigms for view generation. The first category is the random or learnable data corruption, such as the four types of general augmentations (node dropping, edge perturbation, attribute masking, and subgraph) in GraphCL [67] and learnable edge dropping in AD-GCL [50]. Despite the effectiveness of these graph views on various tasks, the proposed data augmentations via random corruption or learning suffer from structural damage and artificially introduced noise, which could alter the fundamental property of input graphs. Based on predefined sub-structure substitution rules [49] or contrasted with 3-dimensional geometric views [33, 45], the second way is to integrate the domain knowledge to alleviate the issue of semantic alteration with data corruption. However, the fusion of domain knowledge inevitably undermines the generalization of the pre-trained model to other domains [32]."}, {"title": "2 Related Works", "content": "Graph contrastive learning has been broadly adopted for tasks without ground-truth labels, such as graph classification [32, 67], node classification [10, 20], and link prediction [70]. Here, we devote our attention to contrastive learning for graph classification, the most relevant topic of this work."}, {"title": "2.1 Graph Contrastive Learning", "content": "Great success has been achieved by graph contrastive learning in self-supervised graph representation learning. Among various research, the study of the contrastive view is a key issue in graph contrastive learning. Recently, based on the data augmentation on images, numerous works have explored the feasibility of augmentations on graphs [32, 50, 66\u201368]. While gratifying, the proposed data augmentations via random perturbation or learning suffer from structural damage and noisy information [50, 67]. To tackle this issue, several works have attempted to preserve the graph semantic structure by resolving profound domain knowledge into augmentations, such as MoCL [49], KCL [9], GraphMVP [33] and 3D-Infomax [45] However, this domain knowledge only exists on molecules, which significantly limits the generality. Moreover, beyond the general contrastive learning framework, DGCL [31] disentangles the graph encoder, and OEPG [63] explores the semantic structure of datasets. Although they present excellent performance, they still rely on the graph augmentations and thus are orthogonal to these works that keep the general contrastive learning framework; put differently, other models can work with the framework of DGCL and OEPG to produce superior performance. Among recent works, SimGRACE [60] preserves semantics by disturbing the model weight with Gaussian noise. However, the introduced noise is data-agnostic, which could degenerate the model performance when the actual data distribution goes beyond the Gaussian distribution and explain the sub-optimal performance of SimGRACE in the experiment section."}, {"title": "2.2 Model Pruning", "content": "In the early stage, pruning is generally a technique to improve model efficiency, which aims to shrink model size at surprisingly little sacrifice of model performance [28], and various pruning techniques have been proposed and effective for that goal [16, 19, 30]. Recently, besides the inherent function of model compression, several works explored its deeper connection with model generalization [11, 69]. Moreover, the capability of pruning on model memorization has also been validated with long-tail distribution dataset [23]. In this paper, we particularly investigate contrastive learning via model pruning for graph representation learning. Note that, model pruning is first employed in this work to address the issue of semantics alteration caused by data augmentation."}, {"title": "3 Notations and Preliminaries", "content": "Before the elaboration of LAMP, here, some preliminary concepts and notations are given. Let $\\mathcal{E}$ and $\\mathcal{V}$ be the sets of edges and vertices, a simple graph can be formally written as $G=(\\mathcal{V}, \\mathcal{E})$.\nGraph representation learning. Generally, GNNs based on a message-passing scheme serve as the graph encoder [14]. A GNN learns an embedding $h_v \\in \\mathbb{R}^d$ for each node and a vector $h_G \\in \\mathbb{R}^d$ is produced by a READOUT function for graph $G$. For an $L$-layer GNN, each node vector is decorated with the $L$-hop information from its neighbors. The hidden vector of node $v$ in layer $c$ is:\n$h^{(c)}_v = f^{(c)} \\Big(h^{(c-1)}_v, f_\\mathcal{M}^{(c)} \\big(\\big\\{(h^{(c-1)}_u, h^{(c-1)}_v) | u \\in \\mathcal{N}(v)\\big\\}\\Big)$, (1)\nwhere $f^{(c)}_\\mathcal{M}$ aims to update each node vector in current layer, $f^{(c)}$ is the designed function for message-passing on graphs, the first-order neighbor nodes of $v$ is represented as $\\mathcal{N}(v)$, and $h^{(c)}_v$ denotes the hidden feature of $v$ in the $c$-th layer. After $L$ iterations, the entire graph representation can be written as\n$h_G = f_R(\\big\\{h^{(L)}_v | v \\in \\mathcal{V}\\big\\}),$ (2)\nwhere $f_R$ pools the final set of node representations and is generally a summation or averaging function.\nGraph contrastive learning. A typical unsupervised model via contrastive learning takes two views from one graph as input, and the two views are produced by two data augmentation operators and serve as a positive pair. At the phase for pre-training, a GNN-based encoder is used for structural information modeling of the input views, and a projection head is further employed to embed the two views into the same feature space for contrast. Output feature vectors $h_1$ and $h_2$ from the same graph are expected to identify themselves from the others. Thus, the NT-Xent loss [7] is adopted to achieve this goal via maximizing the consensus of a positive pair:\n$L_i = -log \\frac{e^{sim(h_i, h_i')/\\tau}}{\\sum_{1, j \\neq i}^{N}e^{sim(h_i, h_j')/\\tau}},$ (3)\nwhere $N$ is the batch size, $\\tau$ controls the temperature parameter, and $sim(h_1, h_2)$ generally refers to a cosine similarity function. In particular, there are two types of negative pairs; put differently, $h_i$ can pair with all $h_j'$, and $h_i'$ can pair with all $h_j\\}$.\nThe mutual information maximization principle. Graph contrastive learning leverages the principle of mutual information maximization (InfoMax) to enhance the correspondence between a graph representation and its corresponding views from various augmentations. The graph representation $h_G$ is supposed to contain the feature underlying $G$, because the representation is expected to distinguish the graph $G$ from others within the same batch. The principle of mutual information maximization can formally be\n$InfoMax: max I(G; h_G), where G \\sim p_G,$ (4)\nwhere $p_G$ denotes the distribution defined over the graph $G$ and $I(\\cdot)$ refers to the mutual information."}, {"title": "4 Methodology", "content": "In this section, by turning the attention from data augmentation to model pruning, we bring about the proposed graph contrastive learning framework, termed LAMP. Before the detailed description, we first give the motivation from the quantification of structural damage caused by general graph augmentation."}, {"title": "4.1 Quantification of Structural Damage from Data Augmentation", "content": "In previous works regarding graph contrastive learning, data augmentation is a general technique to help the graph encoder identify the essential information of input graphs [56, 65, 67]. Despite various forms, they are mostly built upon the concept of topology corruption, such as node dropping, edge perturbation, and learn-able graph generation. Although these works have shown some extent of effectiveness on the actual tasks, the underlying structural damage remains, which inevitably leads to semantics alteration and undermines the model performance.\nNow, based on structural entropy [29], we are the first to give the quantitative illustration of structural damage caused by data augmentations. Given a simple graph $G=(\\mathcal{V}, \\mathcal{E})$, the structural information underlying $G$ can be measured by:\n$H(G) = - \\sum_{v \\in \\mathcal{V}} \\frac{vol(v)}{vol(\\mathcal{V})} log \\frac{vol(v)}{vol(\\mathcal{V})},$ (5)\nin which $vol(\\mathcal{V})$ denotes the sum of all node degrees and $g_v$ is the node degree of $v$. Among various forms of data augmentation proposed in previous works, here, we give the quantitative illustration of structural damage by three ubiquitous rules from GraphCL [67], including subgraph, edge perturbation, and node dropping. In particular, the augmentation strength is consistent with the setting in GraphCL, that is, 20%. The structural damage of graph $G$ is measured by the percent change of its structural entropy. Formally, given any data augmentation function $t$, the percent change of structural entropy will be\n$LSE = 1 - \\frac{H(t(G))}{H(G)}.$ (6)\nThe quantitative illustrations of structural damage caused by three data augmentation rules on a social network dataset (i.e., REDDIT-BINARY) and a bioinformatic dataset (i.e., MUTAG) are shown in Figure 2. 1 The effect of structural damage varies with the augmentation rules. Specifically, node dropping and subgraph lead to different degrees of structural damage, and the information loss caused by subgraph is the largest and generally over 50%. Besides the simple information loss, the structure damage composition of edge perturbation is more complex; put differently, in light of the distribution of REDDIT-BINARY, edge perturbation even introduces external data noise with the additional edges, which further interferes with the model from learning the actual structural information. Therefore, we naturally wonder: Can we design a more advanced model with effective contrastive pairs without structural damage? Next, to tackle our expectations, we present the superiority of model pruning in contrast to data augmentation."}, {"title": "4.2 Theoretical Superiority of Model Pruning", "content": "Through theoretical analysis, in this subsection, we present the property of graph encoder trained from model pruning.\nTHEOREM 4.1. Suppose the graph encoder $f$ is implemented by a GNN with at least 2 layers and $f^*$ is the optimal version. Given a general data augmentation function $t$, the optimal pruned encoder $\\widetilde{f}$ satisfies,\n1. $I(\\widetilde{f}(G); Y) \\geq I(f^*(t(G)); Y)$;\n2. $I(f^* (G); f^*(G)) \\geq I(f^*(t_1(G)); f^*(t_2(G)))$.\nStatement 1 in Theorem 4.1 guarantees a lower bound of the mutual information between the learned representations and the labels of the downstream task; put differently, the learned essential information via the sparse encoder is more than views from augmentations.\nStatement 2 in Theorem 4.1 suggests that the training performance of LAMP is better than the models based on augmentations in the architecture of graph contrastive learning.\nPROOF. Suppose $\\mathcal{G}$ is a set of graphs. According to the definition, $f^* = argmax_f I(f(G); G)$, $f^*$ should be injective. Given some graph $G \\in \\mathcal{G}$, $G \\Rightarrow f^*(G)$ is an injective deterministic mapping. Thus, for any random variable $Q$,\n$I(f^* (G); Q) = I(G; Q).$ (7)\nWhen there is $Q = Y$, we will have,\n$I(f^* (G); Y) = I(G; Y).$ (8)\nMoreover, in light of theoretically proof in [35], a depth-two network can be approximated by pruning a random-weighted sub-network $\\widetilde{f}$ for as follows:\n$sup_{G \\in \\mathcal{G}} |f^*(G) - \\widetilde{f}(G)| \\leq \\epsilon.$ (9)\nAccordingly, we have the following proof:\n$I(f^* (G); Y) - I(\\widetilde{f}(G); Y) = \\mathbb{H}(f^* (G)) + \\mathbb{H}(Y) - \\mathbb{H}(f^* (G), Y) - \\mathbb{H}(\\widetilde{f}(G)) - \\mathbb{H}(Y) + \\mathbb{H}(\\widetilde{f}(G), Y) = \\mathbb{H}(f^* (G)) - \\mathbb{H}(\\widetilde{f}(G)) - (\\mathbb{H}(f^* (G), Y) - \\mathbb{H}(\\widetilde{f}(G), Y)) \\stackrel{(a)}{<} 2\\epsilon^2,$ (10)\nwhere (a) is because of the arbitrariness of $\\epsilon$ and the continuity of the entropy $\\mathbb{H}(\\cdot)$. Meanwhile, because $\\epsilon$ can be arbitrarily small, we can achieve\n$I(f^* (G); Y) = I(\\widetilde{f}(G); Y).$ (11)\nNow, introducing the data processing inequality [51] for data augmentation,\n$I(\\widetilde{f}(G); Y) = I(G; Y) \\geq I(t(G); Y) = I(f^* (t(G)); Y).$ (12)\nCombining above equations, we have the statement 1:\n$I(\\widetilde{f}(G); Y) = I(\\widetilde{f}(G); Y) \\geq I(f^*(t(G)); Y).$ (13)\nNext, we come to proof the second statement,\n$I(f^* (t_1(G)); f^* (t_2(G))) = I(f^* (t_1(G)); (f^* (t_2(G)), Y)) - I(f^* (t_1(G)); (Y|f^* (t_2(G)))) \\leq I(f^* (t_1(G)); (f^* (t_2(G)), Y)) = I(f^* (t_1(G)); Y) + I(f^* (t_1(G)); (f^*(t_2(G))|Y)).$ (14)\nThen, according to the data processing inequality [51], we move forward to\n$I(f^* (t_1(G)); Y) + I(f^* (t_1(G)); (f^* (t_2(G))|Y)) \\leq I(f^* (G); Y) + I(f^* (t_1(G)); (f^* (t_2(G))|Y)) \\leq I(f^* (G); Y) + I(f^* (G); (f^*(G)|Y)) = I(f^* (G); Y) + I(f^* (G); (f^* (G)|Y)) = I(f^* (G); (f^* (G), Y)).$ (15)\nFinally, for the reason of $f_P(G) \\bot f^* (G) \\vert Y$,\n$I(f^* (G); (f^* (G), Y)) = I(f^* (G); (f^* (G), Y)) - I(f^* (G); (Y|f^*(G))) = I(f^* (G); f^* (G)),$ (16)\nwhich concludes the proof of the statement 2."}, {"title": "4.3 Instantiation of LAMP", "content": "With the superiority of pruning in graph contrastive learning, now, we move from theory to practice. Instead of producing contrastive pairs via data augmentation, here, we give our model design via model pruning. Figure 1 general pictures the workflow of LAMP. As can be seen, LAMP sticks to the twin-tower architecture of GraphCL [67], while gets rid of its trail-and-error data augmentation rules. Especially, LAMP feeds the original graph into the dense graph encoder and its pruned version to contrast their embeddings. Formally, let $G = (A,X)$ be the input graph, $A$ is the adjacency matrix, and $X$ is the initial node features. For the $l$-th layer of graph encoder, the node representations of $G$ via Equation 1 will be:\n$H_v^{(l)} = f \\Big(f_\\mathcal{M}^{(l)} (A, H_v^{(l-1)}); \\mathcal{W}^{(l)}\\Big),$ (17)\n$\\widetilde{H}_v^{(l)} = f \\Big(f_\\mathcal{M}^{(l)} (A, \\widetilde{H}_v^{(l-1)}); p(\\mathcal{W}^{(l)})\\Big),$ (18)\nwhere $\\mathcal{W}^{(l)}$ is the weight matrix of update function $f_\\mathcal{M}^{(l)}$ and $p(\\cdot)$ is the pruning function on model weight $\\mathcal{W}$.\nIn practice, we prune the dense graph encoder according to a pre-defined ratio $\\gamma$ with the given pruning strategy, that is, the weight values of $\\mathcal{W}^l$ will be masked if they are ranked below $\\gamma$. In particular, the sparse degree of the graph encoder can be controlled by tuning the pruning ratio $\\gamma$, which meets various demands of different datasets. Detailed discussion about the pruning ratio is conducted in the ablation study. Moreover, to avoid drastic gradient changes and save computations, the wight matrix will be pruned at the beginning of each epoch. Since the sparse encoder is always obtained and updated from the latest dense version, the two branches will co-evolve during training.\nRemark. To avoid possible confusion, we emphasize that the adoption of pruning is not aimed at enhancing model efficiency, but rather at boosting the performance of contrastive learning. Furthermore, our approach in this study is not tied to a specific pruning strategy, but is compatible with any given pruning methods. Specifically, we have implemented our method using two distinct pruning techniques: magnitude pruning [16] and soft filter pruning [19], which are referred to as LAMP-Mag and LAMP-Soft, respectively."}, {"title": "4.4 Hard Negative Samples", "content": "Among the research on contrastive learning, hard negative samples are quite ubiquitous and have great potential to improve model performance[41]. However, little attention has been drawn to the hard negative samples within current contrastive learning for graph classification. As shown in Figure 3, there are two kinds of hard negative samples. In Figure 3a, this negative pair has the same topology but different features. Let $h_{color}$ ($g$ for green, $b$ for blue) denote the node features, the graph representations would be similar after pooling as $f_R (4 \\times h_g + h_b) = f_R(4 \\times h_g + h_p)$. In Figure 3b, this negative pair has different topology and node features. Let $h_l = 2 h_g$, the graph representations would be also similar through summation or maximization pooling function. Given the common design of current contrastive learning for graph classification, the model is encouraged to enlarge the distance of negative pairs via graph representations, which may fail with the two kinds of negative samples in Figure 3 and deteriorate model performance."}, {"title": "5 Experiments", "content": "In this section, we are devoted to evaluating LAMP with extensive experiments. Under the setting of unsupervised and transfer learning, LAMP empirically shows its superiority compared to the SOTA competitors. Ablation studies regarding hyper-parameters are further conducted to make an in-depth analysis."}, {"title": "5.1 Experimental Setup", "content": "Datasets. For unsupervised learning, various benchmarks are adopted from TUDataset [37], including COLLAB, REDDIT-BINARY, REDDIT-MULTI-5K, IMDB-BINARY, NCI1, MUTAG, PROTEINS and DD. For transfer learning, ZINC15 [46] dataset is adopted for pre-training. In particular, a subset with two million unlabeled molecular graphs are sampled from the ZINC15. We employ the eight ubiquitous benchmarks from the MoleculeNet dataset [58] as the downstream experiments regarding transfer learning. Further details are shown in Appendix B.\nLearning protocol. Following the learning setting in GraphCL [67], the corresponding learning protocols are adopted for a fair comparison. (a) In unsupervised representation learning, all data is used for model pre-training and the learned graph embeddings are then fed into a non-linear SVM classifier to perform 10-fold cross-validation. (b) In transfer learning, we first pre-train the model on ZINC15. Then, we finetune and evaluate the model on MoleculeNet dataset using the scaffold split scheme [6].\nConfiguration. To keep in line with GraphCL [67], the same GNN architectures are employed with their original hyper-parameters under individual experiment settings. Specifically, in unsupervised learning, GIN [61] with 32 hidden units and 3 layers is set up. In transfer learning, GIN is used with 5 layers and 300 hidden dimensions. The pruning ratio for sparse encoder is selected from 5% to 95% with a step of 5%. For local contrastive loss balance, \u03b1 is tuned among {0.01, 0.1, 1, 10, 100}. Hyper-parameters are selected by the grid search on the validation sets. Additional details are shown in the Appendix C.\nPruning strategy. To demonstrate the compatibility of our framework, LAMP, with a variety of pruning methodologies, in this study, we adopt two distinct pruning techniques for the implementation of our method: magnitude pruning [16] and soft filter pruning [19], denoted as LAMP-Mag and LAMP-Soft, respectively."}, {"title": "5.2 Results Compared with SOTAs", "content": "Unsupervised learning. The baselines in unsupervised learning have three categories. The first set is three SOTA kernel-based methods that include GL [44], WL [43], and DGK [62]. The second set is four heuristic self-supervised methods, including node2vec [15], sub2vec [3], graph2vec [4], and InfoGraph [48]. The final category comes from the graph contrastive learning domain, including MV-GRL [17], GraphCL [67], AD-GCL [50], JOAO [66], AutoGCL [65], RGCL [32], SimGRACE [60], SEGA [55] and GCS [54].\nThe classification accuracies of LAMP against the SOTA competitors are shown in Table 1, and a significant performance improvement from the disappearance of the data augmentation can be witnessed as opposed to the baselines. Before the specific performance description of LAMP, here, we first glance at SimGRACE, which first attempts to transfer the contrastive attention from data augmentation to model perturbation via introducing Gaussian noise to model weights. Although SimGRACE reveals its effectiveness on various datasets, the introduced Gaussian noise still degenerates the model performance; put differently, SimGRACE does not defeat the models with data augmentations.\nWe now present a comprehensive analysis of the superior performance of LAMP. As indicated by the final column for average rank, LAMP-Mag and LAMP-Soft secure the top two positions and exhibit the highest average accuracies among all baseline models. Notably, as evidenced by the column for average accuracy, LAMP-Soft surpasses the second-best model (i.e., GCS) with an accuracy improvement of 1.43%. Specifically, LAMP-Soft achieves the best performance on six out of eight benchmarks, while still maintaining the second-best performance on the remaining two datasets."}, {"title": "5.3 Ablation Study", "content": "Here, we make an in-depth analysis about the performance of LAMP under the setting of unsupervised learning. In particular, the magnitude pruning is adopted for ablation study.\nEffectiveness of local contrastive loss. Besides the contrastive angle from the ubiquitous NT-Xent loss for unsupervised learning, we take another step to help model be capable of handling hard negative samples from the perspective of nodes. As shown in Table 3, LAMP-Mag obtains better performance with a 1.16% average accuracy gain when decorated with the proposed local contrastive loss, which suggests the effectiveness of the proposed local loss in addressing hard negative samples and improving model performance. In particular, LAMP-Mag w/o $L_{LocalC}$ has an average accuracy of 76.83% on eight benchmarks, which not only outperforms current SOTAs for view generation but also defeats SimGRACE which disturbs the model weight with Gaussian noise. Thus, we can reaffirm the effectiveness of pruning on graph contrastive learning.\nSensitivity regarding pruning ratio. The pruning ratio controls the information that the sparse encoder captures; thus, a proper ratio would help the model identify the essential structure of input graphs. As shown in Figure 4, the datasets in the first row prefer a lower pruning ratio, while the other datasets would like a sparser encoder. Moreover, regardless of the optimal pruning ratio, the performances of all datasets quickly deteriorate when the sparsity goes above 75%, due to limited capacity.\nSensitivity regarding loss balance. As we have validated the effectiveness of the proposed local contrastive loss, we further inspect the influence of its hyper-parameter (i.e., \u03b1) on model performance. The unsupervised results of LAMP-Mag with candidate \u03b1 on eight benchmarks are shown in Figure 5. As can be seen, DD and NCI1 show a positive correlation with \u03b1, while MUTAG is not sensitive to the choice of \u03b1, which is consistent with the stable performance of MUTAG w/o $L_{LocalC}$ in Table 3. The other datasets show a trade-off within the given selections, and generally obtain the best performance with \u03b1 around 1.\nA further comprehensive analysis from Figure 4 and Figure 5 shows that a suitable pruning ratio is particularly important for datasets such as PROTEIN, RED-M5K, and IMDB-B, whereas datasets like NCI1 and DD depend more on local contrastive loss. The varying preferences indeed reflect the unique characteristics of different datasets. Social datasets may rely on pruning, potentially due to information redundancy. Conversely, datasets such as NCI1 and DD might depend more on local contrastive loss, which may be because the characteristics of bioinformatics datasets are more evident in local functional groups, and the efficacy of local contrastive loss on hard negative samples."}, {"title": "6 Conclusion", "content": "In this work, we reformulate the problem of graph contrastive learning from the angle of model compression. To avoid the loss of semantics caused by data augmentation, we present a novel method based on model pruning, termed LAMP, rather than relying on profound domain knowledge. Before the empirical validation, we theoretically explain the superiority of model pruning compared to data augmentation. Extensive experiments under unsupervised and transfer learning show that LAMP suppresses the current SOTA methods based on data augmentations. An automatic pruning ratio and more advanced pruning strategies shed light on the future research direction. Furthermore, node classification and link prediction tasks are also important areas in graph-related tasks. There are many excellent works in these two directions, and we see this as an opportunity for future exploration and learning."}, {"title": "A Quantification of Structural Damage from Data Augmentation", "content": "Data Augmentations on Graphs. Follow the data augmentations in GraphCL [67], we adopt three types of general data augmentations for graph-structured data:\n\u2022 Node dropping. Given the graph G, node dropping will randomly discard certain portion of vertices along with their connections. The underlying prior enforced by it is that missing part of vertices does not affect the semantic meaning of G. Each node's dropping probability follows a default i.i.d. uniform distribution (or any other distribution).\n\u2022 Edge perturbation. It will perturb the connectivities in G through randomly adding or dropping certain ratio of edges. It implies that the semantic meaning of G has certain robustness to the edge connectivity pattern variances. We also follow an i.i.d. uniform distribution to drop each edge.\n\u2022 Subgraph. This one samples a subgraph from G using random walk. It assumes that the semantics of G can be much preserved in its (partial) local structure.\nThe quantitative illustrations of structural damage caused by three data augmentation rules on eight datasets are shown in Figure A.1. As can be seen, the effect of structural damage varies with the augmentation rules. Specifically, node dropping and subgraph lead to different degrees of structural damage, and the information loss caused by subgraph is the largest and generally over 50%. Besides the simple information loss, the structure damage composition of edge perturbation is more complex; put differently, edge perturbation even introduces external data noise with the additional edges, which further interferes with the model from learning the actual structural information."}, {"title": "B Summary of Datasets", "content": "A wide variety of datasets from different domains for a range of graph property prediction tasks are used for our experiments. Here, we present detailed descriptions of the 8 benchmarks utilized in this paper."}, {"title": "B.1 Datasets for Unsupervised Learning", "content": "Social Network Datasets. IMDB-BINARY is derived from the collaboration of a movie set. In this dataset, every graph consists of actors or actresses, and each edge between two nodes represents their cooperation in a certain movie. Each graph is derived from a prespecified movie, and its label corresponds to the genre of this movie. Similarly, COLLAB is also a collaboration dataset but from a scientific realm, which includes three public collaboration datasets (i.e., Astro Physics, High Energy Physics and Condensed Matter Physics). Many researchers from each field form various ego networks for the graphs in this benchmark. The label of each graph is the research field to which the nodes belong. REDDIT-BINARY and REDDIT-MULTI-5K are balanced datasets, where each graph corresponds to an online discussion thread and nodes correspond to users. An edge is drawn between two nodes if at least one of them responds to another's comment. The task is to classify each graph into the community or subreddit to which it belongs."}, {"title": "B.2 Details of Molecular Datasets", "content": "Input graph representation. For simplicity, we use a minimal set of node and bond features that unambiguously describe the two-dimensional structure of molecules. We use RDKit [27] to obtain these features.\n\u2022 Node features:\nAtom number: [1, 118]\nChirality tag: {unspecified, tetrahedral cw, tetrahedral ccw, other}\n\u2022 Edge features:\nBond type: {single, double, triple, aromatic}\nBond direction: {-, endupright, enddownright}\nDownstream task datasets. 8 graph classification datasets from MoleculeNet [58] are used to evaluate model performance.\n\u2022 BBBP [36]. Blood-brain barrier penetration (membrane permeability), involves records of whether a compound carries the permeability property of penetrating the blood-brain barrier.\n\u2022 Tox21 [2]. Toxicity data on 12 biological targets, which has been used in the 2014 Tox21 Data Challenge and includes nuclear receptors and stress response pathways.\n\u2022 ToxCast [40]. Toxicology measurements based on over 600 in vitro high-throughput screenings.\n\u2022 SIDER [26]. Database of marketed drugs and adverse drug reactions (ADR), grouped into 27 system organ classes and also known as the Side Effect Resource.\n\u2022 ClinTox [13, 38]. Qualitative data classifying drugs approved by the FDA and those that have failed clinical trials for toxicity reasons."}, {"title": "C Detailed Experiment Setup", "content": "Datasets. Eight benchmarks are adopted from TUDataset [37] and summarized in Table A.1, including IMDB-BINARY, REDDIT-MULTI-5K, NCI1, MUTAG, PROTEINS, DD, REDDIT-BINARY, and COLLAB.\nConfiguration. Hidden dimension is chosen from {32, 64}, and batch size is chosen from {32, 128}. An Adam optimizer [25] is employed to minimize the contrastive lose with {0.01, 0.005, 0.001} learning rate.\nLearning protocols. In unsupervised representation learning [48], all data is used for model pre-training and a non-linear SVM is adopted as classifier to perform to perform 10-fold cross-validation on learned graph embeddings. For graph representation learning, models are trained 20 epochs and tested every 10 epochs. The 10-fold evaluation are performed 5 times in total with different random seeds as [48]. At last, we report the average accuracy and standard deviation (%)."}, {"title": "C.2 Setting for Transfer Learning", "content": "Pre-training dataset. ZINC15 [46", "22": "GIN [61", "25": "is employed to minimize the integrated losses produced by the 5-layer GIN"}]}