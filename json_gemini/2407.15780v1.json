{"title": "Explaining Decisions in ML Models:\na Parameterized Complexity Analysis", "authors": ["Sebastian Ordyniak", "Giacomo Paesani", "Mateusz Rychlicki", "Stefan Szeider"], "abstract": "This paper presents a comprehensive theoretical investigation into the parameterized complexity of explanation problems in various machine learning (ML) models. Contrary to the prevalent black-box perception, our study focuses on models with transparent internal mechanisms. We address two principal types of explanation problems: abductive and contrastive, both in their local and global variants. Our analysis encompasses diverse ML models, including Decision Trees, Decision Sets, Decision Lists, Ordered Binary Decision Diagrams, Random Forests, and Boolean Circuits, and ensembles thereof, each offering unique explanatory challenges. This research fills a significant gap in explainable AI (XAI) by providing a foundational understanding of the complexities of generating explanations for these models. This work provides insights vital for further research in the domain of XAI, contributing to the broader discourse on the necessity of transparency and accountability in AI systems.", "sections": [{"title": "Introduction", "content": "As machine learning (ML) models increasingly permeate essential domains, understanding their decision-making mechanisms has become central. This paper delves into the field of explainable AI (XAI) by examining the parameterized complexity of explanation problems in various ML models. We focus on models with accessible internal mechanisms, shifting away from the traditional black-box paradigm. Our motivation is rooted in establishing a comprehensive theoretical framework that illuminates the complexity of generating explanations for these models, a task becoming increasingly relevant in light of recent regulatory guidelines that emphasize the importance of transparent and explainable AI [7, 24].\nThe need for transparency and accountability in automated decision-making drives the imperative for explainability in AI systems, especially in high-risk sectors. ML models, while powerful, must be demystified to gain trust and comply with ethical and regulatory standards. Formal explanations serve this purpose, providing a structured means to interpret model decisions [4, 13, 20].\nOur exploration focuses on two types of explanation problems, abductive and contrastive, in local and global contexts [20]. Abductive explanations [15], corresponding to prime-implicant explanations [28] and sufficient reason explanations [10], clarify specific decision-making instances, while contrastive explanations [16, 22], corresponding to necessary reason explanations [10], make explicit the reasons behind the non-selection of alternatives. The study of contrastive explanations goes back to the Lipton's work in 1990. Conversely, global explanations [15, 27] aim to unravel models' decision patterns across various inputs. This bifurcated approach enables a comprehensive understanding of model behavior, aligning with the recent emphasis on interpretable ML [19].\nIn contrast to a recent study by Ordyniak et al. [25], who consider the parameterized complexity of finding explanations based on samples classified by a black-box ML model, we focus on the setting where the model together with its inner workings is available as an input for computing explanations. This perspective, initiated by Barcel\u00f3 et al. [1], is particularly appealing, as it lets us quantify the explainability of various model types based on the computational complexity of the corresponding explanation problems."}, {"title": "Preliminaries", "content": "For a positive integer i, we denote by [i] the set of integers {1, . . ., i}.\nParameterized Complexity (PC). We outline some basic concepts refer to the textbook by Downey and Fellows [12] for an in-depth treatment. An instance of a parameterized problem Q is a pair (x, k) where x is the main part and k (usually an non-negative integer) is the parameter. Qis fixed-parameter tractable (FPT) if it can be solved in time \\(f(k)n^c\\) where n is the input size of x, c is a constant independent of k, and f is a computable function. If a problem has more then one parameters, then the parameters can be combined to a single one by addition. FPT denotes the class of all fixed-parameter tractable decision problems. XP denotes the class of all parameterized decision problems solvable in time \\(n^{f(k)}\\) where f is again a computable function. An fpt-reduction from one parameterized decision problem Q to another Q' is an fpt-computable reduction that reduces of Q to instances of Q' such that yes-instances are mapped to yes-instances and no-instances are mapped to no-instances. The parameterized complexity classes W[i] are defined as the closure of certain weighted circuit satisfaction problems under"}, {"title": "Considered Problems and Parameters", "content": "We consider the following types of explanations (see Marques-Silva's survey [20]). Let M be a model, e an example over F(M), and let c \u2208 {0, 1} be a classification (class). We consider the following types of explanations for which an example is illustrated in Figure 1.\n\u2022 A (local) abductive explanation (LAXP) for e w.r.t. M is a subset A \u2286 F(M) of features such that M (e) = M(e') for every example e' that agrees with e on A.\n\u2022 A (local) contrastive explanation (LCXP) for e w.r.t. M is a set A of features such that there is an example e' such that M(e') \u2260 M(e) and e' differs from e only on the features in A."}, {"title": "Overview of Results", "content": "As we consider several problems, each with several variants and parameters, there are hundreds of combinations to consider. We therefore provide a condensed summary of our results in Tables 2, 3, 4.\nThe first column in each table indicates whether a result applies to the cardinality-minimal or subset-minimal variant of the explanation problem (i.e., to Xc or X\u2286, respectively). The next 4 columns in Tables 2 to 4 indicate the parameterization, the parameters are explained in Table 1. A \"p\" indicates that this parameter is part of the parameterization, a \"-\" indicates that it isn't. A \u201cc\u201d means the parameter is set to a constant, \u201c1\u201d means the constant is 1.\nBy default, each row in the tables applies to all four problems LAXP, GAXP, GCXP, and LCXP. However, if a result only applies to LCXP, it is stated in parenthesis. So, for instance, the first row of Table 2 indicates that DT-LAXPC, DT-GAXPC, DT-GCXPC, and DT-LCXPC, where the ensemble consists of a single DT, can be solved in polynomial time.\nThe penultimate row of Table 2 indicates that DTMAJ-LAXP, DTMAJ-GAXP\u2286 and DTMAJ-GCXP\u2286 are co-NP-hard even if mnl_size + size_elem + xp_size is constant, and DTMAJ-LCXP is W[1]-hard parameterized by xp_size even if mnl_size + size_elem is constant. Finally, the * indicates a minor distinction in the complexity between DT-LAXP and the two problems DT-GAXP\u2286 and DT-GCXP\u2286. That is, if the cell contains NP-h* or pNP-h*, then DT-LAXP is NP-hard or pNP-hard, respectively, and neither DT-GAXP nor DT-GCXP are in P unless FPT = W[1].\nWe only state in the tables those results that are not implied by others. Tractability results propagate in the following list from left to right, and hardness results propagate from right to left.\n-minimality \u21d2 \u2282-minimality\nset A of parameters \u21d2 set B \u2283 A of parameters\nensemble of models \u21d2 single model\nunordered OBDD ensemble \u21d2 ordered OBDD ensemble\nFor instance, the tractability of X\u2286 implies the tractability of X\u2282, and the hardness of X\u2282 implies the hardness of X\u2282."}, {"title": "Algorithmic Results", "content": "In this section, we will present our algorithmic results. We start with some general observations that are independent of a particular model type.\nTheorem 2. Let M be any model type such that M(e) can be computed in polynomial-time for M\u2208 M. M-LCXP\u2286 parameterized by xp_size is in XP.\nProof. Let (M, e, k) be the given instance of M-LCXP\u2286 and suppose that A \u2286 F(M) is a cardinality-wise minimal local contrastive explanation for e w.r.t. M. Because A is cardinality-wise minimal, it holds the example \\(e_A\\) obtained from e by setting \\(e_A(f) = 1-e(f)\\) for every f \u2208 A and \\(e_A(f) = e(f)\\) otherwise, is classified differently from e, i.e., \\(M(e) \u2260 M(e_A)\\). Therefore, a set A \u2286 F(M) is a cardinality-wise minimal local contrastive explanation for e w.r.t. M if and only if \\(M(e) \u2260 M(e_A)\\) and there is no cardinality-wise smaller set A' for which this is the case. This now allows us to obtain an XP algorithm for M-LCXP\u2286 as follows. We first enumerate all possible subsets A \u2286 F(M) of size at most k in time \\(O(|F(M)|^k)\\) and for each such subset A we test in polynomial-time if \\(M(e_A) \u2260 M(e)\\). If so, we output that (M, e, k) is a yes-instance and if this is not the case for any of the enumerated subsets, we output correctly that (M, e, k) is a no-instance.\nThe remainder of the section is organized as follows. First in Section 5.1, we provide a very general result about Boolean circuits, which will allow us to show a variety of algorithmic results for our models. We then provide our algorithms for the considered models in Subsections 5.2 to 5.4"}, {"title": "A Meta-Theorem for Boolean Circuits", "content": "Here, we present our algorithmic result for Boolean circuits that are allowed to employ majority circuits. In particular, we will show that all considered explanation problems are fixed-parameter tractable parameterized by the so-called rankwidth of the Boolean circuit as long as the Boolean circuit uses only a constant number of majority gates. Since our considered models can be naturally translated into Boolean circuits, which require majority gates in the case of ensembles, we will obtain a rather large number of algorithmic consequences from this result by providing suitable reductions of our models to Boolean circuits in the following subsections.\nWe start by introducing Boolean circuits. A Boolean circuit (BC) is a directed acyclic graph D with a unique sink vertex o (output gate) such that every vertex v \u2208 V(D) \\ {o} is either:\n\u2022 an input gate (IN-gate) with no incoming arcs,\n\u2022 an AND-gate with at least one incoming arc,\n\u2022 an OR-gate with at least one incoming arcs,\n\u2022 a majority-gate (MAJ-gate) with at least one incoming arc and an integer threshold \\(t_v\\), or\n\u2022 a NOT-gate with exactly one incoming arc.\nWe denote by IG(D) the set of all input gates of D and by MAJ(D) the set of all MAJ-gates of D. For an assignment \\(a: IG(D) \u2192 {0,1}\\) and a vertex v \u2208 V(D), we denote by val(v, D, a) the value of the gate v after assigning all input gates according to a. That is, val(v, D, a) is recursively defined as follows: If v is an input gate, then val(v, D, a) = a(v), if v is an AND-gate (OR-gate), then val(v, D, a) = \\(\\Lambda_{n\u2208N^-(v)} val(n, D, a)\\) (val(v, D, a) = \\(\bigvee_{n\u2208N^-(v)} val(n, D, a)\\)), and if v is a MAJ-gate, then val(v, D,a) = |{n|n \u2208 N-(v) \u2227 val(n, D, a) = 1 }| > \\(t_v\\). Here and in the following N-(v) denotes the set of all incoming neighbors of v in D. We set O(D, a) = val(o, D, a). We say that D is a c-BC if c is an integer and D contains at most e MAJ-gates.\nWe consider Monadic Second Order (MSO\u2081) logic on structures representing BCs as a directed (acyclic) graph with unary relations to represent the types of gates. That is the structure associated with a given BC D has V(D) as its universe and contains the following unary and binary relations over V(D):\n\u2022 the unary relations I, A, O, M, and N containing all input gates, all AND-gates, all OR-gates, all MAJ-gates, and all NOT-gates of D, respectively,\n\u2022 the binary relation Exy containing all pairs x, y \u2208 V(D) such that (x, y) \u2208 A(D).\nWe assume an infinite supply of individual variables and set variables, which we denote by lower case and upper case letters, respectively. The available atomic formulas are Pg (\u201cthe value assigned to variable g is contained in the unary relation or set variable P\u201d), Exy (\u201cvertex x is the head of an edge with tail y\u201d), x = y (equality),"}, {"title": "DTs and their Ensembles", "content": "Here, we present our algorithms for DTs and their ensembles. We start with a simple translation from DTs to BCs that allow us to employ Theorem 4 for DTs.\nLemma 5. There is a polynomial-time algorithm that given a DT T = (T, \u03bb) and a class c produces a circuit C(T, c) such that:\n(1) for every example e, it holds that T(e) = c if and only if (the assignment represented by) e satisfies C(T, c) and\n(2) \\(rw(C(T,c)) \u2264 3. 2^{|MNL(T)|}\\)\nProof. Let T = (T, X) be the given DT and suppose that MNL(T) is equal to the number of negative leaves; the construction of the circuit C(T, c) is analogous if instead MNL(T) is equal to the number of positive leaves. We first construct the circuit D such that D is satisfied by e if and only if T(e) = 0. D contains one input gate gf and one NOT-gate gf, whose only incoming arc is from gf, for every feature in F(T). Moreover, for every l \u2208 Lo(T), D contains an AND-gate gl, whose incoming arcs correspond to the partial assignment af, i.e., for every feature f assigned by af, gl has an incoming arc from gf if af(f) = 1 and an incoming arc from gf otherwise. Finally, D contains the OR-gate o, which also serves as the output gate of D, that has one incoming arc from gl for every l \u2208 Lo. This completes the construction of D and it is straightforward to show that D is satisfied by an example e if and only if T(e) = 0. Moreover, using Lemma 1, we obtain that D has treewidth at most |MNL(T)| +1 because the graph obtained from D after removing all gates gl for every l \u2208 Lo(T) is a tree and therefore has treewidth at most 1. Therefore, using Lemma 1, we obtain that D has rankwidth at most \\(3 \u00b7 2^{|MNL(T)|}\\). Finally, C(T, c) can now be obtained from D as follows. If c = 0, then C(T, c) = D. Otherwise, C(T, c) is obtained from D after adding one OR-gate that also serves as the new output gate of C(T, c) and that has only one incoming arc from o.\nWe now provide a translation from DTMAJS to 1-BCs that will allow us to obtain tractability results for DTMAJS.\nLemma 6. There is a polynomial-time algorithm that given a DTM\u0100J F and a class c produces a circuit C(F, c) such that:\n(1) for every example e, it holds that F(e) = c if and only if (the assignment represented by) e satisfies C(F, c) and"}, {"title": "DSs, DLs and their Ensembles", "content": "This subsection is devoted to our algorithmic results for DS, DLs and their ensembles. Our first algorithmic result is again based on our meta-theorem (Theorem 4) and a suitable translation from DSMAJ and DLMAJ to a Boolean circuit.\nLemma 13. There is a polynomial-time algorithm that given a DS/DL L and a class c produces a circuit C(L, c) such that:\n\u2022 for every example e, it holds that L(e) = c if and only if e satisfies C(L, c)\n\u2022 \\(rw(C(L,c)) \u2264 3.2^{3|L|}\\)\nProof. Since every DS can be easily transformed into a DL with the same number of terms, it suffices to show the lemma for DLs. Let L be a DL with rules \\((r_1 = (t_1, c_1), . . ., r_l = (t_l, c_l))\\). We construct the circuit D = C(L, c) as follows. D contains one input gate \\(g_f\\) and one NOT-gate \\(\\neg g_f\\), whose only incoming arc is from \\(g_f\\), for every feature in F(L). Furthermore, for every rule \\(r_i = (t_i, c_i)\\), D contains an AND-gate \\(g_{r_i}\\), whose in-neighbors are the literals in \\(t_i\\), i.e., if \\(t_i\\) contains a literal f = 0, then \\(g_{r_i}\\) has \\(\\neg g_f\\) as an in-neighbor and if \\(t_i\\) contains a literal f = 1, then \\(g_{r_i}\\) has \\(g_f\\) as an in-neighbor. We now split the sequence p = \\((r_1 = (t_1, c_1), ..., r_l = (t_l, c_l))\\) into (inclusion-wise) maximal consecutive subsequences \\(p_i\\) of rules that have the same class. Let \\((p_1,..., p_r)\\) be the sequence of subsequences obtained in this manner, i.e., \\(p_1 \\circ p_2 \\circ \\dots \\circ p_r = p\\), every subsequence \\(p_i\\) is non-empty and contains only rules from one class, and the class of any rule in \\(p_i\\) is different from the class of any rule in \\(p_{i+1}\\) for every i with \\(1 < i < r\\). Now, for every subsequence \\(p_i\\), we add an OR-gate \\(g_{p_i}\\) to D, whose in-neighbors are the gates \\(g_r\\) for every rule r in \\(p_i\\). Let C be the set of all subsequences \\(p_i\\) that only contains rules with class c and let \\(\\overline{C}\\) be the set of all other subsequences, i.e., those that contain only rules whose class is not equal to c. For every subsequence p in \\(\\overline{C}\\), we add a NOT-gate \\(\\neg g_{p_i}\\) to D, whose in-neighbor is the gate \\(g_{p_i}\\). Moreover, for every subsequence p in C, we add an AND-gate \\(g_o\\) to D whose in-neighbors are \\(\\neg g_{p_i}\\) as well as \\(\\neg g_{p_j}\\) for every \\(p_j \\in C\\) with j < i. Finally, we add an OR-gate o to D that also serves as the output gate of D and whose in-neighbors are all the gates \\(g_o\\) for every p \u2208 C. This completes the construction of D and it is easy to see that L(e) = c if and only if e satisfies D for every example e, which shows that D satisfies (1). Towards showing (2), let G be the set of all gates in D apart from the gates o and \\(g_f\\) and \\(\\neg g_f\\) for every feature f. Then, |G| \u2264 3|L| and D \\ G is a forest, which together with Lemma 1 implies (2).\nLemma 14. Let M\u2208 {DSMAJ, DLmaj}. There is a polynomial-time algorithm that given an M L and a class c produces a circuit C(L, c) such that:\n(1) for every example e, it holds that L(e) = c if and only if e satisfies C(L, c)\n(2) \\(rw(C(L,c)) \u2264 3.2^{3 \\sum_{L \\in L} |L|}\\)\nProof. We obtain the circuit C(L, c) from the (not necessarily disjoint) union of the circuits C(L, c), which are provided in Lemma 13, for every L\u2208 L after adding a new MAJ-gate with threshold [|L|/2] + 1, which also serves as the output gate of C(L, c), that has one incoming arc from the output gate of C(L, c) for every LE L. Clearly, C(L, c) satisfies (1). Moreover, to see that it also satisfies (2), recall that every circuit C(L, c) has only 3|L| gates apart from the input gates, the NOT-gates connected to the input gates, and the output gate. Therefore, after removing 3|L| gates from every circuit C(L, c) inside C(L, c), the remaining circuit is a tree, which together with Lemma 1 implies (2).\nThe following corollary now follows immediately from Lemma 14 and Theorem 4.\nCorollary 15. Let M\u2208 {DSMAJ, DLmaj} and let P\u2208 {LAXP, LCXP, GAXP, GCXP}. M-P\u2286(ens_size +\nterms_elem) is FPT.\nUnlike, DTs, where DT-LCXP is solvable in polynomial-time, this is not the case for DS-LCXP\u2286. Nevertheless, we are able to provide the following result, which shows that DS-LCXP\u2286 (and even DL-LCXP\u2286) is fixed-parameter tractable parameterized by term_size and xp_size. The algorithm is based on a novel characterization of local contrastive explanations for DLs.\nLemma 16. Let M \u2208 {DS,DL}. M-LCXP\u2286for M \u2208 M and integer k can be solved in time O(\\(a^k ||M||^2\\)), where a is equal to term_size."}, {"title": "OBDDs and their Ensembles", "content": "In this subsection, we will present our algorithmic results for OBDDs and their ensembles OBDDMAJ and OBDDMAJ. Interestingly, while seemingly more powerful OBDDs and OBDDMAJS behave very similar to DTs and DTMAJS if one replaces mnl_size with width_elem. On the other hand, allowing different orderings for every ensemble OBDD makes OBDDMAJS much more powerful and harder to explain (see Section 6.3 for an explanation of this phenomenon).\nWe start by providing reductions of OBDDs and OBDDMAJS to Boolean circuits, which will allow us to employ Theorem 4. The following lemma follows from [17, Lemma 4.1] since the rank-width is upper bounded by the path-width.\nLemma 19 ([17, Lemma 4.1]). There is a polynomial-time algorithm that given a OBDD O and a class c produces a circuit C(O, c) such that:\n\u2022 for every example e, it holds that O(e) = c if and only if e satisfies C(O, c)\n\u2022 \\(rw(C(O,c)) \u2264 5width(O)\\)\nLemma 20. There is a polynomial-time algorithm that given an OBDDM\u0100J O and a class c produces a circuit C(O, c) such that:\n(1) for every example e, it holds that O(e) = c if and only if e satisfies C(O, c)\n(2) \\(rw(C(O,c)) < 3. 2^{|O|}5 max_{O \\in O} width(O)\\)\nProof. We obtain the circuit C(O, c) from the (not necessarily disjoint) union of the circuits C(O, c), which are provided in Lemma 19, for every O \u2208 O after adding a new MAJ-gater with threshold [|O|/2] + 1, which also serves as the output gate of C(O, c), that has one incoming arc from the output gate of C(O, c) for every O \u2208 O. Clearly, C(O, c) satisfies (1). Moreover, to see that it also satisfies (2), we first need to provide the construction for C(O, c) given in [17, Lemma 4.1]."}, {"title": "Hardness Results", "content": "In this section, we provide our algorithmic lower bounds. We start by showing a close connection between the complexity of all of our explanation problems to the following two problems. As we will see the hardness of finding explanations comes from the hardness of deciding whether or not a given model classifies all examples in"}, {"title": "Conclusion", "content": "We have developed an in-depth exploration of the parameterized complexity of explanation problems in various machine learning (ML) models, focusing on models with transparent internal mechanisms. By analyzing different models and their ensembles, we have provided a comprehensive overview of the complexity of finding explanations in these systems. These insights are crucial for understanding the inherent complexity of different ML models and their implications for explainability.\nAmong our findings, some results stand out as particularly unexpected. For instance, while DTMAJ and OBDDMAJS are seemingly different model types, our results show that they behave similarly w.r.t. tractability for explanation problems. On the other hand, it seems surprising that many of the tractability results that hold for DTs and OBDDs do not carry over to seemingly simpler models such as DSs and DLs. For instance, while all variants of LCXP are polynomial-time for DTs and OBDDs, this is not the case for DSs or DLs. Nevertheless, we obtain interesting FPT-algorithms for DL-LCXP (Theorem 18). OBDDMAJ stands out as the hardest model for computing explanations by far, which holds even for models with only two ensemble elements. From a complexity point of view, DT-GAXP\u2286 provides the rare scenario where a problem is known as W[1]-hard but not confirmed to be NP-hard (Theorem 33).\nLooking ahead, there are several promising directions for future research. First, we aim to extend our complexity classification to Sequential Decision Diagrams [9] or even FBDDs, which offer a more succinct representation than OBDDs [3]. This extension could provide further insights into the complexity of explanations in more compact ML models. Secondly, we propose to explore other problem variations, such as counting different types of explanations or finding explanations that meet specific constraints beyond just the minimum ones [1]. Lastly, the concept of weighted ensembles presents an intriguing avenue for research. While the hardness results we established likely still apply, the tractability in the context of weighted ensembles needs to be clarified and warrants further investigation. It would be interesting to see how our results hold up when considering polynomial-sized weights.\nIn summary, our work marks a significant stride in the theoretical understanding of explainability in AI. This research responds to the practical and regulatory demand for transparent, interpretable, and trustworthy AI systems by offering a detailed complexity analysis across various ML models. As the field of XAI evolves, our study lays a foundational groundwork for future research and the development of more efficient explanation methods in AI."}]}