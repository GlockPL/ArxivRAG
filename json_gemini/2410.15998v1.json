{"title": "1024m at SMM4H 2024: Tasks 3, 5 & 6 - Self Reported Health Text Classification through Ensembles", "authors": ["Ram Mohan Rao Kadiyala", "M.V.P. Chandra Sekhara Rao"], "abstract": "Social media is a great source of data for users reporting information regarding their health and how various things have had an effect on them. This paper presents various approaches using Transformers and Large Language Models and their ensembles, their performance along with advantages and drawbacks for various tasks of SMM4H\u201924 - Classifying texts on impact of nature and outdoor spaces on the author's mental health (Task 3), Binary classification of tweets reporting their children's health disorders like Asthma, Autism, ADHD and Speech disorder (task 5), Binary classification of users self-reporting their age (task 6).", "sections": [{"title": "1 Introduction", "content": "Social media has become a key way for people to share their experiences and feelings. This has opened up new opportunities for researchers to understand how different aspects of life affect our well-being. The paper explores three tasks of SMM4H 2024(Xu et al., 2024) - 4-way classification of texts based on effect of nature, outdoor spaces and activities on author's mental health (Task 3), Binary classification of texts reporting health disorders in author's child including ADHD, Autism, Asthma and Speech disorder (Task 5)(Klein et al., 2024), Binary classification of texts self-reporting author's exact age directly / indirectly (Task 6).The paper explores usage of transformer models like RoBERTa(Liu et al., 2019), DeBERTa(He et al., 2021), Longformer(Beltagy et al., 2020) and LLs including both proprietary and open-source like GPT-4(OpenAI, 2024), Claude-Opus(Anthropic, 2024), Llama-3 8B(Touvron et al., 2023), Mistral 7B(Jiang et al., 2023), Gemma 7B(GemmaTeam, 2024), and ensembles along with advantages and drawbacks of each approach using the models. Similar previous works can be found in (Weissenbacher et al., 2022), (Magge et al., 2021) and (Klein et al., 2020)."}, {"title": "2 Datasets", "content": "The dataset for Task 3 consists of 3000 reddit posts from r/socialanxiety belonging to four classes based on self reported impact of outdoor spaces and activities on the author's mental health 0: unrelated to the task, 1: had a positive impact, 2: is neutral or had no effect, 3: had a negative effect. The dataset for Task 5 consists of 9734 tweets belonging to two classes - 1: users reporting having a child having ADHD, Asthma, Autism or Speech disorder and the rest as class 0. Similarly for Task 6, the dataset of 21200 texts consists of both tweets and reddit posts from r/AskDocs for two classes - Class 1 being texts through which the author's current age in years may be determined and rest as Class 0. The distribution of labels for the three tasks can be seen in Table 1, Table 2 and Table 3."}, {"title": "3 Systems Description", "content": "For Task 3, two approaches were tested. One where classification was done directly in a 4-way and the other where classification was done is two stages, this involved first classifying the text whether it is related to the task or not i.e class 0 or not and then classifying the effect on the user in the second stage. For Task 5 and 6 it was done directly as a binary classification task12. In LLM approaches, The proprietary versions were used as zero-shot and the rest of the LLMs were tested in a zero-shot and fine-tuned manner. Additionally they were tested in a two stage classification for Task 3. In the case of ensembles, It was through majority voting in a set of models, through and-rule for high precision requirement and through or-rule for high recall requirements. For Task 5 and 6, while using LLMs, classification was done by dividing the criteria into parts and aggregating the individual results. i.e In the case of Task 5, individual prompts test for each condition that needed to be satisfied to classify as positive and AND-rule is used for generating final label. Similarly OR-rule was used for Task 6. The performance of different approaches can be seen in Table 7, Table 8 and Table 9.The data during training was shuffled after every epoch and also internally in each mini-batch."}, {"title": "4 Error Analysis", "content": "The LLMs performed equally good on all kinds of data while transformers models performed less effectively when the kind of language used is off from rest of the data or when criteria for classification was mentioned in one sentence and referred to the conditions indirectly later on. It was observed that positively labelled samples were predicted correctly by either the LLM approach or transformers, hence ensembles of both had recall over 0.99 with just 1 percent drop in F1 scores in Task 5 and 6. Many of the positively misclassified samples were in the format of advertisements where the title appears to match the criteria for positive classification. This is one area where LLMs were still able to distinguish effectively while other models did not."}, {"title": "5 Conclusion", "content": "the performance of some of the models compared to others on the test set can be seen in Table 4, Table 5 and Table 6. The LLM approach did yield comparatively good results despite using in a 4bit precision due to lack of computational resources. It is likely the performance would be better that the current models in full precision. Many of the positive label texts have been filtered out during the data collection process. For example, texts self-reporting age in text format instead of numerical. Due to this, a higher focus on recall is necessary. A custom metric with higher importance to recall is better suited for Task 5 and 6 compared to F1 scores. Ensemble approaches like majority voting and filtering guaranteed positive label texts using LLM predictions could improve performance without a significant drop in the F1 scores. Finally, the performance improved on all the tasks while using dev set as additional training data compared to just the training data, hinting at the possibility of improving the performance by adding more training data. Augmentation through paraphrasing existing data however did not improve the results."}, {"title": "A Task 3 System Overview", "content": "Classifying the class of unrelated texts (class 0) from the other 3 separately had improved the performance by reducing mis-classification between Class 0 and others. The overview of the process can be seen in Figure 1. The fine-tuned transformer models used had the best results with a learning rate of 0.00002 and weight decay of 0.01 over 30 epochs for 2-stage classification and 50 epochs for direct classification. In case of the fine-tuned LLMs, the base models were loaded in 4-bit configuration due to computational limitations, later fine-tuned and used in 16-bit precision for inference. During training, ROPE scaling was used for texts longer than 2048 tokens. They were fine-tuned over 3 epochs with a learning rate of 0.0002 and weight decay of 0.01 using Alpaca prompts.\nThe prompts ussed over the LLMs were as follows:\n\u2022 2-stage 1st prompt : \"Did outdoor spaces or activities get mentioned? Respond only with a 1 for yes or 0 for no. Only one character (0/1) nothing else.\"\n\u2022 2-stage 1st prompt : \"What impact did outdoor spaces or activities have on the user's mental health ? Respond only with a 1 for positive or 2 for neutral or 3 for negative. Only one character (1/2/3) nothing else.\"\n\u2022 Direct classification prompt : \"What impact did outdoor spaces or activities have on the user's mental health ? Respond only with a 1 for positive or 2 for neutral or 3 for negative or 0 for no mention. Only one character (1/2/3/0) nothing else.\"\n\u2022 Fine-tuned LLMs prompt : \"What impact did outdoor spaces or activities have on the user's mental health ? Respond only with a 1 for positive or 2 for neutral or 3 for negative or O for no mention. Only one character (1/2/3/0) nothing else\"\nThe models that resulted in the best performance on the test set are available at :\n\u2022 https://huggingface.co/1024m/SMM4H-Task3-BartL-1A30\n\u2022 https://huggingface.co/1024m/SMM4H-Task3-BartL-1B30"}, {"title": "B Task 5 System Overview", "content": "The overview of the process can be seen in Figure 2. The fine-tuned transformer models used had the same hyper-parameters as used in Task 3, and were fine-tuned over 20 epochs. In case of the fine-tuned LLMs, the process is same as what was used in task 3. The proprietary systems were tested additionally using multiple separate prompts for each sub-condition that is to be true to be classified as a positive class text. In case of And-rule approach, the texts were marked as positive (class 1) if all of the conditions were met to achieve higher F1 with a lower recall trade-off.\nThe prompts used over the LLMs were as follows :\n\u2022 Direct classification prompt: \"The tweets already mention at least one of the following: attention-deficit/hyperactivity disorder (ADHD), autism spectrum disorders (ASD), delayed speech (speech disorder), or asthma. In some cases, the tweets discuss hypothetical cases or the possibility of having the condition. It might be about someone else's child or an adult son/daughter. Respond with '1' if the tweet explicitly mentions an existing formal diagnosis of one of those conditions AND it concerns a child/baby AND the child is the user's own. In all other cases, respond with a '0'. Respond with only one character ('0'/'1') and nothing else.\"\n\u2022 AND-rule prompt 1 : \"The tweets already mention at least one of the following: attention-deficit/hyperactivity disorder (ADHD), autism spectrum disorders (ASD), delayed speech (speech disorder), or asthma. In some cases, the tweets discuss hypothetical cases or the possibility of having the condition. Respond with '1' if the tweet explicitly mentions an existing formal diagnosis of one of those conditions. In all other cases, respond with a '0'. Respond with only one character ('0'/'1') and nothing else.\"\n\u2022 AND-rule prompt 2: \"The tweets already mention... ...Respond with '1' if the tweet explicitly mentions it concerns a child/baby having one of those conditions. In all other cases, respond with a '0'. Respond with only one character ('0'/'1') and nothing else.\""}, {"title": "C Task 6 System Overview", "content": "The overview of the process can be seen in Figure 3. The fine-tuned transformer models used had the same hyper-parameters as used in Task 3, and were fine-tuned over 20 epochs. In case of the fine-tuned LLMs, the process is same as what was used in task 3. The proprietary systems were tested additionally using multiple separate prompts for each sub-condition that can be true to be classified as a positive class text. In case of OR-rule approach, the texts were marked as positive (class 1) if at least one of the conditions were met to achieve higher F1 with a lower recall trade-off. The classification was done separately fro twitter and reddit posts with separate models i.e one for each platform's posts.\nThe prompts used over the LLMs were as follows :\n\u2022 Direct classification prompt : \"Respond only with 0 or 1 and nothing else: based on whether current age of the AUTHOR in years can be known from the texts. The texts have a two digit number which is likely an age if not clear. The age needed to know in context is current age of THE author and not someone else. In some cases formats like 25m, 24f are used where m refers to Male and f refers to Female.\"\n\u2022 OR-rule prompt 1 : \"Respond only with 0 or 1 and nothing else based on whether the current age of the author was reported in the given text.\"\n\u2022 OR-rule prompt 2 : \"Respond only with 0 or 1 and nothing else based on whether the current age of the author can be determined from the given text.\"\n\u2022 OR-rule prompt 3 : \"Respond only with 0 or 1 and nothing else based on whether the current age of the author was expressed using formats like 25m, 24f are used where 'm' refers to Male and 'f' refers to Female.\"\nThe models that resulted in the best performance on the test set are available at :\n\u2022 https://huggingface.co/1024m/SMM4H-Task6-BartL-A20 For Reddit texts\n\u2022 https://huggingface.co/1024m/SMM4H-Task6-BartL-B20 For Twitter texts"}]}