{"title": "MADGEN MASS-SPEC ATTENDS TO DE NOVO MOLECULAR GENERATION", "authors": ["Yinkai Wang", "Xiaohui Chen", "Liping Liu", "Soha Hassoun"], "abstract": "The annotation (assigning structural chemical identities) of MS/MS spectra remains a significant challenge due to the enormous molecular diversity in biological samples and the limited scope of reference databases. Currently, the vast majority of spectral measurements remain in the \"dark chemical space\" without structural annotations. To improve annotation, we propose MADGEN (Mass-spec Attends to De Novo Molecular GENeration), a scaffold-based method for de novo molecular structure generation guided by mass spectrometry data. MADGEN operates in two stages: scaffold retrieval and spectra-conditioned molecular generation starting with the scaffold. In the first stage, given an MS/MS spectrum, we formulate scaffold retrieval as a ranking problem and employ contrastive learning to align mass spectra with candidate molecular scaffolds. In the second stage, starting from the retrieved scaffold, we employ the MS/MS spectrum to guide an attention-based generative model to generate the final molecule. Our approach constrains the molecular generation search space, reducing its complexity and improving generation accuracy. We evaluate MADGEN on three datasets (NIST23, CANOPUS, and MassSpecGym) and evaluate MADGEN's performance with a predictive scaffold retriever and with an oracle retriever. We demonstrate the effectiveness of using attention to integrate spectral information throughout the generation process to achieve strong results with the oracle retriever.", "sections": [{"title": "1 INTRODUCTION", "content": "Metabolomics, the measurement and identification of small molecules in biological samples, plays a critical role in numerous fields, including drug discovery, biomarker discovery, and environmental science. By analyzing the molecular composition of complex biological samples, metabolomics provides insights into cellular processes, metabolic pathways, and the effects of environmental changes on biological systems. Tandem mass spectrometry (MS/MS) has emerged as a powerful, widely used analytical technique that can separate and fragment molecules within a biological sample, thus producing rich spectra that can be further analyzed to annotate the measurements within the sample (Kind et al., 2018).\nDespite the utility of metabolomics, assigning a chemical structural identity to a measured spectrum remains a significant challenge. Currently, most MS/MS spectra cannot be linked to known molecular structures due to the vast chemical diversity in biological samples and the limited scope of reference databases. Spectral databases that catalogue molecules and their measured spectra, e.g., MoNA (Davis) and GNPS (Wang et al., 2016), are used for identifying a close match to the measured spectra. However, such databases remain relatively small. Molecular databases such as PubChem (Kim et al., 2016) and KEGG (Kanehisa et al., 2021) are often utilized to provide candidate molecular structures when using computational methods such as SIRIUS (D\u00fchrkop et al., 2019), MLP or GNN-based approaches (Wei et al., 2019; Zhu et al., 2020) to predict the molecular structure that most likely produced the measured spectrum. Despite the success of these tools and the increased size of such databases, the \"dark chemical space\" of unknown molecules remains large, and hinders the interpretation of metabolomics data. De novo molecular structure generation from"}, {"title": "2 RELATED WORK", "content": "De novo structure generation guided by mass spectra. De novo molecular generation offers a promising alternative to database-dependent methods by directly (without the use of candidate molecules from databases) predicting or generating molecular structures from mass spectrometry data. MSNovelist (Stravs et al., 2022) relies on CSI:FingerID (D\u00fchrkop et al., 2015) to predict molecular fingerprints from the query mass spectrum, and then uses a LSTM model to reconstruct molecules. Spec2Mol (Litsa et al., 2023) employs a convolutional neural network to map MS/MS spectra to a latent space, generating molecular structures as SMILES strings. MassGenie (Shrivastava et al., 2021) uses a transformer-based model trained on real and synthetic spectra to generalize to unseen compounds, leveraging transformers' strength in handling sequential data. MS2Mol (Butler et al., 2023) extends these approaches with a transformer-based encoder-decoder, incorporating byte-pair encoding and precursor mass, to improve accuracy. There were no consistent datasets that were used to evaluate these models. For example, MSNovelist is evaluated on 3,863 MS/MS spectra from the GNPS library (Wang et al., 2016), while Spec2Mol is evaluated on the NIST2020 dataset. Further, not all these tools are available in the public domain. Recently, The MassSpecGym dataset (Bushuiev et al., 2024) was developed as a benchmark dataset to standardize the evaluation on de novo generation, retrieval, and spectra simulation tasks. We utilize this dataset, and two others, to report the performance of MADGEN. We also compare our results with the best reported results so far on the MassSpecGym dataset.\nGenerative frameworks for molecular generation. Generative models have become essential in molecular generation due to their ability to approximate complex distributions in the chemical space. These models, such as VAES, GANs, and Diffusion models, treat molecules as graphs, enabling"}, {"title": "3 METHODS", "content": "Direct generation of molecules from mass spectra is a hard problem. In this work, we propose to divide the problem into two simpler sub-problems (see Figure 1): we first retrieve the molecular scaffold from the mass spectrum and then generate the target molecule conditioned on both the mass spectrum and the scaffold. We conjecture that the scaffold prediction problem is easier than predicting the target molecule because the scaffold usually has a simpler structure than the target molecule. Consequently, the molecule generation task becomes easier when the scaffold is known."}, {"title": "3.1 SCAFFOLD RETRIEVAL", "content": "The goal of scaffold retrieval is to identify the scaffold of the target molecule. Denote an MS/MS spectrum and its chemical formulate as $X = (X_{ms}, X_{cf})$. Scaffold retrieval takes $X$ as input and retrieves the core scaffold that represents the fundamental backbone of the molecule, including its ring systems and central framework. With a correct scaffold served as the starting point for further molecular generative process, the complexity of the search space is significantly reduced.\nHowever, predicting the scaffold from spectral data is a challenging problem due to the non-linear relationship between fragmentation patterns and the scaffold substructures. In this work, we explore two scaffold retrieval strategies - predictive retrieval and oracle retrieval."}, {"title": "Predictive retrieval", "content": "We formulate the scaffold retrieval as a ranking problem. Given a set of scaffold candidates $S$, the goal is to use a neural network to score each candidate $S\\in S$ given $X$ such that scaffold with highest score $S^*$ maximally resembles the correct scaffold $S_{gt}$.\nA straightforward approach is to directly train a binary classifier that tells whether the given pair $(X, S)$ is matched or not. However, to fully leverage the relationship between the spectrum and scaffold modalities, we adopt a contrastive learning framework similar to CLIP (Radford et al., 2021). In this framework, the spectrum $X$ is treated as one modality, while the scaffold $S$ is treated as the other. Contrastive learning aligns the embeddings of these two modalities in a shared latent space, enabling the model to learn a meaningful representation of their relationships.\nThis paradigm has been widely employed in multimodal information retrieval frameworks (Luo et al., 2021; Bain et al., 2022; Lei et al., 2021; Fang et al., 2021; Ma et al., 2022; Hendriksen et al., 2022), where embedding similarity is used to determine the most likely paired item based on a query. Similarly, in our framework, we align the embeddings of mass spectra and scaffolds to facilitate scaffold retrieval. Specifically, we employ contrastive learning techniques inspired by JESTR (Kalia et al., 2024), which was designed to align the embeddings of mass spectra with their corresponding molecules.\nTo achieve this alignment, we introduce two separate encoders to project the mass spectra and scaffold graphs into a shared latent space. Specifically, the mass spectra $X$ are projected using a multi-"}, {"title": "Oracle retrieval", "content": "We maintain a lookup table as an oracle which always yields the correct scaffold given the MS/MS spectrum and the chemical formula. We construct the lookup table by extracting the scaffold from the molecular graph representation using RDKit.This lookup table serves as an idealized oracle, simulating perfect scaffold retrieval. It allows us to focus on assessing the second stage of molecular generation: the task of adding side chains and functional groups to the scaffold-independently from any potential errors that could occur in scaffold retrieval."}, {"title": "3.2 SCAFFOLD-CONDITIONED DE NOVO MOLECULE GENERATION WITH SPECTRA GUIDANCE", "content": ""}, {"title": "3.2.1 NOTATIONS AND PROBLEM FORMULATION", "content": "We represent a molecule $G$ as a graph $G = (V,E)$. Its scaffold $S = (V_S, E_S)$ is a subgraph of $G$. Since the atom set $V$ can be directly inferred from the chemical formula, the task of molecular generation involves determining the appropriate edge set $E \\ E_S$ that connects the scaffold to the remaining isolated atoms $V \\ V_S$. While there are combinatorially many valid edge sets that could complete the molecule from the scaffold, we utilize spectral data $X$ to guide the edge generation process and ensure the structure aligns with the observed spectra."}, {"title": "3.2.2 SCAFFOLD-CONDITIONED GENERATION VIA MARKOV BRIDGE", "content": "We frame the molecule prediction task as generating graphs given a scaffold. Specifically, starting from a scaffold $S$, we are interested in modeling the distribution $p(G|S) = p(E|E_S, V_G)$ with the following Markov decomposition:\n$p(\\varepsilon|\\varepsilon_S, V_G) = \\sum_{\\varepsilon_{0:\\varepsilon_{T-1}}} \\prod_{t=0}^{T-1} P(\\varepsilon_{t+1} | \\varepsilon_t, \\varepsilon_S, V_G),$ (3)\nwhere $\\varepsilon = \\emptyset$ can be considered the case where no bonds are formed from isolated atoms to others, and $\\varepsilon_T = E$. The sequence of random variables $\\varepsilon_{0:T}$ can be viewed as progressively connecting atoms to form the final molecules.\nLet $e_t$ be an arbitrary edge entry in $\\varepsilon_t$, $e_t$ can be represented as a D-dimensional one-hot vector, with 0 class being non-edge and 1 to D-1 classes being the bond types. Following Austin et al. (2021), we formulate the transition probabilities $p(e_{t+1}|e_t, e_T)$ conditioned on the endpoint $e_T$:\n$p(e_{t+1} | e_t, e_T) = Categorical(e_{t+1}; Q_t(e_T) e_t),$ (4)\nwhere $Q_t (e_T) \\in \\mathbb{R}^{D \\times D}$ is an absorbing transition matrix conditioned on the endpoint data $e_T$ (Igashov et al., 2023).\nWith the defined model, we now approximate it with a parameterized distribution:\n$P_{\\theta} (e_{t+1} | e_t, E_S, V_G) = Categorical (e_{t+1}; Q_t(\\hat{e_T}) e_t), where \\hat{e_T} = nn_{\\theta}(E_t, E_S, V_G)$ (5)\nis the endpoint prediction via a neural network $nn_{\\theta}(\\cdot)$. Given a pair (S, G) from the dataset, we train $nn_{\\theta}(\\cdot)$ by optimizing the evidence lower bound (ELBO)\n$\\mathcal{L}_{\\theta}(S, G) := -TE_{u(t;0,T-1)} E_{p(e_t|e_0,e_T)} KL( p(e_{t+1}/e_t, e_T)||P_{\\theta} (e_{t+1}|e_t, E_S, V_G)).$ (6)"}, {"title": "3.2.3 CLASSIFIER-FREE GUIDANCE FROM MASS SPECTRUM", "content": "We introduce the mass spectrum $X^{ms}$ as an additional conditioning term to refine the search space during the generation of $G$ from $S$. The neural network $nn_{\\theta}(\\cdot)$ is designed to condition on $X$ when computing the logits.\nTo integrate spectrum information throughout the generation process, we utilize classifier-free guidance (CFG) (Ho & Salimans, 2022). At each inference step, for each edge entry, we compute the logit $l_c$ conditioned on the spectrum $X$, and the logit $l_u$ without conditioning. The final logit $l_g$ is then obtained by combining the two using a guidance scale $\\lambda_t$:\n$l_g = (1 + \\lambda_t)l_c - \\lambda_t l_u$ (7)\nDuring training, we randomly remove the spectrum condition with a probability of 0.1 to enable CFG. Since CFG tends to prioritize generation quality over diversity, increasing $\\lambda_t$ helps reduce the search space and improves the success rate of generating target molecules based on the given spectrum.\nWe provide further details on how the CFG techniques are integrated into our framework (see Figure 2), particularly within the network architecture $nn_{\\theta}(\\cdot)$. We treat the graph as fully connected, where non-edges are considered a specific type of edge, and apply a fully connected graph neural network (FC-GNN) to compute on this structure. The detailed design of the FC-GNN is provided in the Appendix A.1. Two key components to highlight are the encoding of the mass spectrum $X$ and the conditioning mechanism."}, {"title": "4 EXPERIMENTS", "content": "We evaluate the performance of MADGEN on three datasets (Table 1). The NIST23 dataset (National Institute of Standards and Technology (NIST), 2023) is curated by the National Institute of Standards and Technology to provide reference spectral data for a wide range of chemical molecular standards to support research and development. It is available for purchase. Each molecule is measured using various mass spectrometry instruments, and under various instrument settings, thus contributing to the high number of spectra/molecule. The CANOPUS dataset is the smallest dataset, and it was designed to train and evaluate the CANOPUS tool (D\u00fchrkop et al., 2021), which predicts compound classes, e.g., alcohols, phenol ethers, and others, from spectra. It has a 1:1 spectra to molecule ratio. It was used recently to benchmark other metabolomics tools such as MIST(Goldman et al., 2023) and ESP(Li et al., 2024). The newly developed MassSpecGym benchmark dataset (Bushuiev et al., 2024) is collected from many public reference spectral databases and curated uniformly. The MassSpecGym is the largest publicly available labeled mass spectra dataset. For all three datasets, few molecules shared the same scaffold.\nAll datasets were preprocessed by normalizing the intensities of the MS/MS spectra and removing low-intensity peaks below a predefined threshold to reduce noise. The NIST23 and CANOPUS datasets were split into training, validation, and test sets based on the scaffold, ensuring that scaffolds are unique to each split. This split prevents data leakage and ensures robust evaluation of model performance. For MassSpecGym, we utilized the split suggested by the benchmark (Bushuiev et al., 2024), which is based on the Maximum Common Edge Substructure (MCES). This split allows assessing the model generalization on novel molecules."}, {"title": "4.2 EXPERIMENTAL SETUP AND EVALUATION METRICS", "content": "The model was trained using a graph transformer with 5 layers and 50 diffusion steps. We employed the AdamW optimizer with a learning rate of $1 \\times 10^{-5}$. Full training details and hyperparameters can be found in Appendix A.2.\nFor candidate pool selection, the following approaches were employed:"}, {"title": "4.3 RESULTS", "content": "Our experiments, summarized in Table 2, evaluate model performance on three datasets: NIST23, CANOPUS, and MassSpecGym, using both predictive and oracle retrievers. For the scaffold prediction task, we report a Scaffold Prediction Accuracy (SPA) for the predictive retriever ranging from 34.8% to 57.8%. Notably, the NIST23 dataset achieves the highest SPA of 57.8%, reflecting its lower scaffold diversity compared to CANOPUS and MassSpecGym, which have more complex scaffolds.\nThe metrics for the scaffold-based generation task reveal that the low scaffold prediction accuracy of the predictive retriever constrains molecular generation performance. For instance, on the NIST23 dataset, the predictive retriever yields a top-1 accuracy of 10.3%, while for CANOPUS and MassSpecGym, the top-1 accuracies are 1.0% and 0.8%, respectively. Despite these challenges, the predictive retriever demonstrates moderate performance improvements compared to baseline methods like Spec2Mol and random generation.\nIn contrast, the oracle retriever, which has access to the correct scaffold, dramatically boosts performance. On NIST23, MADGEN achieves a top-1 accuracy of 49% and a top-10 accuracy of 65.5%, demonstrating the model's capacity to generate accurate molecular structures if the scaffold is known. Similarly, when using the oracle retriever, the performance on CANOPUS and MassSpecGym is significantly higher than the predictive retriever, with top-1 accuracies of 8.9% and 18.8%, respectively, showing the clear advantage of having access to correct scaffold information. Importantly, MADGEN outperforms the best published state-of-the-art performance (last row in Table 2) reported for the MassSpecGym dataset (Bushuiev et al., 2024) when using random chemical generation. The high top-1 and Top10 accuracy for the NIST23 dataset can be attributed to its smaller number of free atoms. MADGEN's task of completing the target molecule by adding edges to these free atoms is easier with a smaller number of free atoms. CANOPUS has the highest number of average free atoms, and the lowest top-1 and top-10 accuracies.\nBaseline methods like Spec2Mol and MSNovelist are also included in the comparison. As shown in Table 2, MSNovelist results are limited to accuracy metrics, as other measures are not available. The \"-\" in the table denotes this lack of data, while underlined values highlight the best results achieved by predictive retrievers, serving as a benchmark against the oracle retriever."}, {"title": "4.4 ABLATION STUDY ON CONDITIONING MECHANISM", "content": "We conducted an ablation study to assess the impact of different encoding strategies, conditioning methods, and the use of CFG (Table 3) on the performance of MADGEN. Conditioning using"}, {"title": "4.5 SENSITIVITY ANALYSIS OF FREE ATOM NUMBERS ON ACCURACY", "content": "We analyze how the number of free atoms will affects the generation accuracy of MADGEN. Figure 3 shows MADGEN's accuracy@1 and accuracy@10 on different number of free atoms across three datasets. We can observe that having more free atoms yields worse predictive accuracy, which is as expected as the learning complexity increases."}, {"title": "5 CONCLUSION & FUTURE WORK", "content": "De novo annotation of mass spectrometry data is notoriously difficult, with a current best accuracy of 0% on the MassSpecGym dataset. MADGEN offers a novel two-stage framework for spectra-guided de novo annotation. The first stage, scaffold retrieval, is a new problem formulation whose solution can provide partial insight in regard to the molecular backbone of the measured spectra. Such insights may shed light on the molecule's class or properties. Our results show that this problem is challenging, achieving a scaffold prediction accuracy of 34.8%-57.8% for the three datasets. The second stage, de novo generation from an existing scaffold showed excellent results when using an oracle scaffold predictor, achieving an accuracy of 8.9%-49% across the three dataset. For the MassSpecGym benchmark, we were able to achieve an accuracy of 0.8%, an almost 50% increase in accuracy over MassSpecGym baseline. As with other tools, e.g., (Goldman et al., 2023), we conjecture that performance of MADGEN can be increased by incorporate additional data in the form of peak chemical formulae or molecular properties that correlate with fragmentation patterns. Potentially, the scaffold problem can be made easier if larger more distinct scaffold structures were utilized instead of the Murcko scaffold used herein. A bigger scaffold can in turn facilitate the de novo generation task. Further, an end-to-end MADGEN may reduce the compounding of errors across the two stages."}, {"title": "A APPENDIX", "content": ""}, {"title": "A.1 MODEL ARCHITECTURES AND ALGORITHMS", "content": "In this section, we describe the architecture of our proposed scaffold-conditioned molecular generation guided by mass spectra data. The process consists of two main stages: scaffold retrieval (Stage 1) and scaffold-conditioned molecular generation (Stage 2). The model integrates node, edge, and spectral features, updated iteratively through cross-attention and self-attention mechanisms."}, {"title": "A.1.1 STAGE 1: SCAFFOLD RETRIEVAL", "content": "The first stage of the process involves predicting a scaffold that is most consistent with the input MS/MS spectrum. This stage utilizes a contrastive learning framework that aligns molecular graphs with their corresponding mass spectra. We use the 'MLP_BIN' model for encoding the spectral data."}, {"title": "Molecular encoder", "content": "We employ a Graph Neural Network (GNN) to encode the molecular structures:\n*   Node Features: The molecular graph nodes (atoms) are encoded using GNN layers, where each node is associated with a feature vector that encodes atom type and other properties.\n*   Edge Features: Bonds between atoms are represented by edge features, which are also encoded by the GNN.\n*   Graph Pooling: The output node embeddings from the GNN are pooled using a MaxPooling layer to create a graph-level representation."}, {"title": "Spectral encoder (MLP_BIN)", "content": "For encoding the MS/MS spectra, we use the 'MLP_BIN' encoder:\n*   The input spectra are represented as bins of mass-to-charge (m/z) ratios and intensities.\n*   The 'MLP_BIN' model processes these binned inputs through multiple fully connected layers, where each layer applies a ReLU activation and dropout to prevent overfitting.\n*   The output of the 'MLP_BIN' encoder is a vector representing the spectral data in an embedding space suitable for contrastive learning."}, {"title": "Interaction model", "content": "Once the molecular and spectral embeddings are computed, they are concatenated and passed through an interaction MLP, which predicts the interaction score between the molecule and the scaffold. The interaction score is used to rank candidate scaffolds. The molecular encoder and spectral encoder are trained jointly in a contrastive learning framework, where the goal is to align the embeddings of correct molecular-scaffold pairs."}, {"title": "A.1.2 STAGE 2: SCAFFOLD-CONDITIONED MOLECULAR GENERATION", "content": "In Stage 2, the retrieved scaffold is used as the foundation for generating the full molecular structure, guided by the mass spectra data. This stage employs a Graph Transformer to integrate node, edge, and spectral features iteratively across multiple layers."}, {"title": "Input representation", "content": "The inputs to the Graph Transformer in this stage consist of:\n*   Node Features (V): Each node represents an atom in the molecular scaffold, and the feature vector encodes atom type and properties.\n*   Edge Features (E): Bonds between atoms in the scaffold are represented as edge features.\n*   Spectral Features (S): The MS/MS spectra provide pairs of mass-to-charge (m/z) ratios and intensities."}, {"title": "Multi-head attention", "content": "Each layer of the Graph Transformer applies a Node-Edge Block, where both node and edge features are updated using attention mechanisms.\n*   Self-Attention: The model computes queries, keys, and values for each node and edge, allowing it to focus on relevant parts of the molecular graph during the update process.\n*   Cross-Attention: Cross-attention between the node/edge features and the spectral features enables the generation process to be conditioned on the spectral data, ensuring that the generated molecular structure aligns with the spectra."}, {"title": "Feedforward networks", "content": "After the attention layers, a FeedForward Network processes the updated node and edge features, further refining the representations."}, {"title": "Layer normalization and residual connections", "content": "Each attention block is followed by Layer Normalization and residual connections to stabilize training and maintain information flow across the layers."}, {"title": "Final output", "content": "After the final transformer layer, the updated node and edge features are passed through an output MLP to generate the final molecular structure. This process ensures that the generated molecule is consistent with both the scaffold and the spectral data."}, {"title": "A.2 TRAINING HYPERPARAMETERS", "content": "The model is trained with a batch size of 64 and employed 47 workers for data loading. The learning rate is set to $1 \\times 10^{-5}$, while weight decay is configured at $1 \\times 10^{-12}$. Training proceeds for 1000 epochs, with the model logging progress every 40 steps.\nA Markov bridge process with 50 steps is employed during training, and a cosine noise schedule is employed.\nThe model consists of 5 layers, with node, edge, and spectral features set at 64 dimensions each. The MLP hidden dimensions are configured to 256 for nodes, 128 for edges, and 256 for spectral features. The model also employs 8 attention heads for cross-attention and self-attention mechanisms. The feedforward dimensions are set to 256 for nodes, 128 for edges, and 128 for global features. This architecture enables efficient handling of both molecular structure and spectral data during training."}, {"title": "A.3 VARIATION DISTRIBUTION AND ELBO", "content": "We first show the full derivation of the ELBO, which introduces a forward transition distribution $p(e_{t+1} | e_t, e_T)$ as the variational distribution. Then we discuss the formulation of the variational"}, {"title": "A.4 OVERALL WORKFLOW", "content": "The two stages work together to form a scaffold-conditioned molecular generation system. In the first stage, the model retrieves a scaffold using contrastive learning and the 'MLP_BIN' spectral encoder, and in the second stage, the Graph Transformer uses this scaffold to generate a complete molecule, conditioned on the spectral data. This two-step approach ensures that the molecular generation process is both accurate and guided by experimentally observed spectra."}]}