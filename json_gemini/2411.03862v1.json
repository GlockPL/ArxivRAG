{"title": "ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization", "authors": ["Huayang Huang", "Yu Wu", "Qian Wang"], "abstract": "Watermarking generative content serves as a vital tool for authentication, ownership protection, and mitigation of potential misuse. Existing watermarking methods face the challenge of balancing robustness and concealment. They empirically inject a watermark that is both invisible and robust and passively achieve concealment by limiting the strength of the watermark, thus reducing the robustness. In this paper, we propose to explicitly introduce a watermark hiding process to actively achieve concealment, thus allowing the embedding of stronger watermarks. To be specific, we implant a robust watermark in an intermediate diffusion state and then guide the model to hide the watermark in the final generated image. We employ an adversarial optimization algorithm to produce the optimal hiding prompt guiding signal for each watermark. The prompt embedding is optimized to minimize artifacts in the generated image, while the watermark is optimized to achieve maximum strength. The watermark can be verified by reversing the generation process. Experiments on various diffusion models demonstrate the watermark remains verifiable even under significant image tampering and shows superior invisibility compared to other state-of-the-art robust watermarking methods.", "sections": [{"title": "1 Introduction", "content": "Diffusion models (DMs) are revolutionizing content creation and generating stunningly realistic imagery across diverse domains [17, 33, 60]. The advent of text-to-image diffusion models [31, 30, 58], coupled with personalized generation techniques [53, 7, 32, 15, 41, 59], enables the creation of highly specific content by virtually anyone. However, it has raised concerns about authenticity and ownership, including the risk of plagiarism [34, 22] and the potential misuse of images of public figures [39, 5]. Consequently, governments and businesses are increasingly advocating for robust mechanisms to verify the origins of generative content [19, 45].\nWatermarking offers a proactive approach to authenticate the source of generated content. This technique embeds imperceptible secret messages within the generated content. These messages serve as unique identifiers, confirming the image's origin while remaining invisible to the human eye. They also need to be robust enough to withstand potential distortions encountered during online sharing.\nExisting watermarking techniques face a significant challenge in striking a balance between conceal- ment and robustness. Traditional post-processing methods [46, 9] employ an empirical approach to identify an invisible and robust watermark and embed it within the generated image. They passively achieve concealment by limiting the watermark strength, consequently compromising robustness. Conversely, stronger watermarks, while enhancing robustness, can introduce visible artifacts into the generated image. Recent advancements in in-processing watermarking for diffusion models expect"}, {"title": "2 Related work", "content": "Diffusion generation and inversion. Diffusion models [17, 12, 36, 37] operate by iteratively transforming pure noise $x_T \\sim N(0, I)$ into increasingly realistic images $x_0 \\sim q(x)$ through $T$ steps of denoising. The learning process involves a stochastic Markov chain in two directions. The forward process diffuses the sample $x_o$ by adding random noise:\n$q(x_t|x_{t-1}) = N(\\sqrt{1 - \\beta_t}x_{t-1}, \\beta_tI),$\nwhere ${\\{t\\}}_{t=1}^T$ is the scheduled variance. $x_t$ can also be generated from $x_0$ as:\n$x_t =\\sqrt{\\bar{a}_t}x_o + \\sqrt{1 - \\bar{a}_t}\\epsilon,$\nwhere $\\bar{a}_t = \\Pi_{i=1}^t(1 - \\beta_t)$ and $\\epsilon \\sim N(0, I)$. Then a network $\\epsilon_{\\theta}$ is learned to predict the noise in each step, following the objective:\n$\\min_{x_o,t\\sim\\text{Uniform}(1,T),\\epsilon\\sim N(0,I)} ||\\epsilon - \\epsilon_{\\theta}(x_t, t, \\psi(p))||^2,$\nwhere $x_t$ is the noise latent at timesteps $t$ and $\\psi(p)$ is the embedding of the text prompt $p$.\nDDIM (Denoising Diffusion Implicit Model) [35] introduces the ODE solver for deterministic sampling by constructing the original one as a non-Markov process. It computes the $x_{t-1}$ from $x_t$ by predicting the estimation of $x_0$ and the direction pointing to $x_t$:\n$x_0 = \\frac{x_t - \\sqrt{1 - \\bar{a}_t}\\epsilon_{\\theta}(x_t, t, \\psi(p))}{\\sqrt{\\bar{a}_t}}$\nWatermarking generative models. The content watermark of generative models can be introduced either after the generation (post-processing) or during the sampling process (in-processing). Post- processing methods can adopt traditional digital image watermarking technology. Popular methods include frequency domain watermarking, which modifies the image representation in domains like Discrete Wavelet Transform (DWT) [47] or Discrete Cosine Transform (DCT) [8]. DwtDct watermarking [3] is applied in open sourced model Stable Diffusion. Frequency domain watermarks can be designed to be robust against common image manipulations like cropping, scaling, and even compression [38]. HiDDeN [57] pioneered the end-to-end approach, utilizing an encoder-decoder architecture to directly generate watermarked images. RivaGAN [52] leverages adversarial training to incorporate perturbations and image processing during model training for increased robustness.\nIn-processing methods make the watermark become part of the generated image by interfering with the generation process. Early approaches explored adding watermarks to training data [50, 55, 10, 13, 48], essentially building a watermark encoder into the model. Stable Signature [14] simplified this process by fine-tuning only the external decoder of latent diffusion models. However, these methods all treated watermarking as a separate goal from the generation task, limiting their flexibility. The recent Tree-Ring watermarking [44] shares similarities with our approach, modifying the initial noise to encode information semantically within the image. However, the semantic modifications induced by Tree-Ring watermarks are random and may compromise the faithfulness of the original model. Therefore, we aim to preserve the original semantics exactly to guarantee a similar level of text alignment compared to the original generation. Our work shows that embedding the watermark within the intermediate diffusion state and guiding the model to hide it can achieve the secret embedding of strong watermarks without model retraining."}, {"title": "3 Methodology", "content": "3.1 Overview of ROBIN\nTask definition. Diffusion model watermarking aims to embed an invisible and verifiable watermark $w_i$ within the generated image $x_o$, using a watermark implantation function $I$. During Internet transmission, the generated content may be subjected to various image transformation operations $T$. The model owner aims to leverage a watermark extraction algorithm $E$ to verify the presence of $w_i$ within the distorted sample $T(x_0)$, thereby establishing image ownership.\nPipeline of ROBIN. Watermark generation. We first generate a hiding prompt guidance signal $w_p$ for each watermark $w_i$ using the adversarial optimization algorithm, which is detailed in Section 3.2.\nWatermark implantation. ROBIN implants $w_i$ into an intermediate generation state $x_t$ after the semantics have been formed as\n$x'_t= I(x_t, w_i, M),$\nwhere $I$ injects $w_i$ into the frequency domain of $x_t$ and $M$ is the coverage area of the watermark. During the remaining DDIM generation, ROBIN incorporates the optimized prompt guidance signal $w_p$ to direct the model towards hiding the watermark $w_i$ to maintain the similarity between the generated image $x_o'$ and its unwatermarked counterpart $x_0$. Let $t_{injection}$ be the watermark injection point, the generation of the watermarked image is as follows:\n$p_{\\theta}(x_{t-1}|x_t) = \\begin{cases}\\frac{\\sqrt{\\bar{a}_{t-1}}x_t + \\sqrt{1 - \\bar{a}_{t-1}}\\epsilon_{\\theta}(x_t, t, \\psi(p))}{\\sqrt{\\bar{a}_t}} & \\text{if } T \\geq t > t_{injection} \\\\ \\frac{\\sqrt{\\bar{a}_{t-1}}x_t + \\sqrt{1 - \\bar{a}_{t-1}}\\epsilon_{\\theta}(x'_t, t, \\psi(p), w_p)}{\\sqrt{\\bar{a}_t}} & \\text{if } t_{injection} \\geq t\\end{cases}$"}, {"title": "3.2 Adversarial optimization algorithm", "content": "We employ an adversarial optimization algorithm to generate the watermark and the corresponding hiding prompt guidance signal. The prompt signal is optimized in the embedding space and guides the model to conceal the embedded image watermark, while the watermark tries to be as strong as possible while allowing for its targeted hiding by the prompt signal.\nThe objective of the prompt guiding signal is to minimize the impact of the watermark on the final generated image. We define the image retaining loss $l_{ret}$, which penalizes excessive deviations from the original images:\n$l_{ret} = MSE(x_o^* - x_o),$\n$x_t = \\frac{x_t^* - \\sqrt{1 - \\bar{a}_t}\\epsilon_{\\theta}(x_t^*, t, \\psi(p), w_p)}{\\sqrt{\\bar{a}_t}}$\nFurthermore, as the loss incurred during DDIM inversion increases proportionally with the guidance strength [25], we introduce a constraint term $l_{cons}$ to prevent excessive prompt guidance:\n$l_{cons} = MSE(\\epsilon_{\\theta}(x_t^, t, w_p) - \\epsilon_{\\theta}(x_t^*,t,\\psi(p))).$\nTo achieve robustness, we embed the watermark in the frequency domain of the image [44]. Frequency domain signals are more resistant to spatial operations compared to spatial domain signals [43]. Similar to [44], we set the watermark as multiple concentric rings, but we further optimize its value to the maximum within the aforementioned constraints for greater strength and better robustness. The optimization losses of $w_p$ and $w_i$ become\n$L_{w_p} = \\alpha l_{ret} + \\beta l_{cons},$\n$L_{w_i} = \\alpha l_{ret} + \\beta l_{cons} - \\lambda ||w_i|| .$\nSince the watermark and the prompt guiding signal are interdependent, we employ an alternating optimization method, in which we iteratively optimize one while fixing the other. More details about the watermark design and optimization algorithm are presented in Appendix A."}, {"title": "3.3 Finding keypoints for implantation", "content": "The selection of the optimal stage for watermark embedding within the diffusion process is crucial for achieving both high image fidelity and semantic consistency with the input text prompt. We delve into the sensitivity of the predicted noise to frequency domain disturbances in different diffusion steps. According to classifier-free guidance method [27], the predicted noise in each step can be depicted as $Full = Uncondition + s\\cdot (Condition - Uncondition)$. $Condition$ and $Uncondition$ are predicted noise with and without text conditions. Parameter $s$ is the scaling factor and the second term of the addition is called $Guidance$. $Full$ noise is the final noise to be removed in the current step.\nTherefore, we strategically choose the watermark insertion point between steps 300 and 200. This stage offers the sweet spot: frequency perturbations have minimal impact on the mean of the predicted noise, allowing for watermark integration without sacrificing image quality and disruption to the core semantics."}, {"title": "3.4 Watermark validation", "content": "In the watermark verification phase, we reverse the diffusion process to get the state $x_t$ at the watermark injection step. We extract the $M$ region of $x_t'$ Fourier space and calculate its $L1$ distance from the implanted watermark $w_i$. However, the original prompt used for image generation is unknown during verification of online images. Similar to [44], we use the null-text prompt as the condition text embedding and set the guidance scale to 1.0. We also found unexpectedly that introducing the optimized prompt signal during inversion hinders the watermark recovery, which we aim to explore in future work. Our watermark verification requires a reversible generation process, making it compatible with any reversible samplers such as DPM-Solver [23], DPM-Solver++ [24], PNDM [21], and AMED-Solver [56]."}, {"title": "4 Experiments", "content": "4.1 Experimental setting\nModel and dataset. We conducted experiments on two distinct diffusion models operating in latent and image domains. For the latent diffusion model, we utilize the widely available Stable Diffusion-v2 [31] and the stable-diffusion-prompts dataset from Gustavosta [1]. We also test on a guided diffusion model [2] trained on the ImageNet [12], which operates directly on the pixel domain and can generate images of size $256 \\times 256$ based on the category provided.\nEvaluation metrics. To assess the effectiveness of ROBIN, we compute the Area Under the ROC Curve (AUC-ROC) based on the L1 distance to measure the effectiveness of watermark verification. Specifically, we compute AUC using 1,000 watermarked and 1,000 clean images. For the quality of watermarked images, we employ a suite of diverse metrics. We utilize classic measures like PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and MSSIM (Multiscale SSIM) [42] to quantify the pixel-level differences between watermarked and original images. We employ the Fr\u00e9chet Inception Distance (FID) [16] to evaluate the fidelity of the watermarked image distribution. We also leverage the CLIP score [29] to measure the alignment between generated images and their corresponding text prompts. More details are provided in Appendix B.1.\nImplementation details. We utilize 50 steps of deterministic sampling for both models. Stable Diffusion employs the second-order multistep DPM-Solver algorithm [23] with a default guidance scale of 7.5. ImageNet diffusion model leverages the DDIM sampling algorithm [35]. We optimize the watermark and the hiding prompt using 50 generated images. The learning rates for the image watermark and prompt guidance are 0.8 and 5e-04, respectively, with a total of 1,000 optimization rounds. The default image watermark covers 70% of the image frequency domain. All experiments are conducted on an NVIDIA GeForce RTX 3090 GPU."}, {"title": "4.2 Effectiveness and robustness", "content": "We compare our method with five baselines: DwtDct [4], DwtDctSvd [26], RivaGAN [52], Stable Signature [14], and Tree-Ring watermarks [44]. To ensure the watermark's resilience in real-world scenarios, we delve into its robustness under various image transformations. These include Gaussian blur with radius 4, Gaussian noise with intensity 10%, jpeg compression with quality 25, color jitter with brightness 6, random rotation of 75 degrees, and random cropping of 75% and rescaling. These settings are strict for watermark verification because the image has been significantly altered. ROBIN is also evaluated under a combination of attacks where we randomly selected various combination of the six transformations. The processed samples are shown in Figure 6 in the Appendix."}, {"title": "4.3 Quality of watermarked image", "content": "Traditional post-hoc watermarking methods introduce subtle visual distortions into the generated images. In contrast, the objective of ROBIN aligns with the Tree-Ring in constructing a \"content watermark\": seamlessly embedding the watermark within the image content without altering its semantics. Due to this fundamental shift in watermarking philosophy, we only compare the image quality with Tree-Ring watermarks.\nThe Tree-Ring approach aims to find another watermarked image that aligns with the text prompt, even if it differs from the original image. However, it is more akin to random semantic modifications and does not guarantee the same level of text alignment as the original generation. Figure 3 shows that the Tree-Ring approach significantly alters the generated image's semantics, sometimes even failing to fulfill the text prompt's intent. This occurs because it disrupts the essential Gaussian characteristics of the initial noise, hindering the generation process. In contrast, ROBIN excels at preserving the overall image content and semantic structure, providing a better lower bound for faithfulness by preserving the original semantics. Table 4 provides the quantitative results. ROBIN demonstrates significant improvements in PSNR, SSIM, MSSSIM, and CLIP score, while a slight increase in FID is observed. This is because the position of the watermark implanted in our scheme is at a later stage of generation, resulting in a slightly greater influence on the overall generation distribution. This implies a negligible trade-off for achieving a strong watermark with minimal degradation of the overall quality of the generated image."}, {"title": "4.4 Ablation study", "content": "To gain further insights into the effectiveness of ROBIN, we conduct an ablation study, exploring the influence of different design choices. We additionally introduce the Mean Squared Error of Watermark (MSE) to represent the verification accuracy in some settings where the AUC is always equal to 1. It is calculated as the mean of L1 distance between the extracted and original watermark.\nSetting variations. To explore the individual contributions of various components in our scheme, we conduct a series of experiments presented in Table 5. Experiments in Settings 1 and 2 demonstrate that the introduction of prompt-based watermark hiding signals improves image quality, as evidenced by a 1.6 increase in PSNR and a 1.44 decrease in FID score compared to Setting 1. Setting 3 emphasizes the importance of the $l_{ret}$ in controlling watermark strength. Without $l_{ret}$, ROBIN prioritizes creating a highly robust watermark, leading to significant image distortion (PSNR: 18.95, SSIM: 0.48). Setting 4 presents that removing $l_{cons}$ allows for stronger prompt guidance, but this results in increased DDIM inversion loss and a decrease of 0.013 in adversarial AUC. Setting 5 prioritizes minimal impact on the generated image by weakening the watermark. This approach leads to poorer watermark robustness and a decrease of 0.017 in adversarial AUC. Experiments under Settings 2 and 6 demonstrate that in the presence of the hiding prompt signal, the image watermark can be optimized to achieve stronger robustness while maintaining invisibility.\nPoint of implantation. We evaluate the impact of implanting the watermark at different stages in the diffusion process. The results are presented in Figure 4. Watermark verification accuracy improves with later implantation due to fewer DDIM inversion steps and reduced information loss. Early implantation, while initially maintaining image quality (low FID), can significantly change the image content (low SSIM/PSNR) by disrupting semantic formation. Conversely, late implantation may leave the watermark visible due to insufficient space for hiding, leading to high FID and deviation from the original image (low SSIM). This empowers us to pinpoint the optimal embedding stage (steps 15-10) for balancing visual quality and semantic preservation.\nWatermark strength. We also verify the influence of different watermarking strengths and the results are shown in Figure 4. Higher watermark strength (proportional coverage in the frequency domain) generally benefits verification accuracy, as the watermark becomes more prominent. The CLIP score and FID remain stable due to strategic embedding and guided hiding. Traditional metrics (SSIM, PSNR) decrease with stronger watermarks due to increased content modification. The watermarked images under different strengths are shown in Figure 5. Compared to Tree-Ring, the quality of generated images with ROBIN watermarks is less sensitive to watermark strength. More qualitative results are presented in Appendix C.5."}, {"title": "5 Conclusion & Discussion", "content": "This paper proposes a novel watermarking method for the diffusion model, which embeds a watermark in the intermediate diffusion state and guides the model to conceal the watermark. By explicitly introducing the active hiding process, we can implant stronger watermarks without compromising image quality. We believe this method holds promise for expanding the possibilities of reliable watermarking in diffusion models."}, {"title": "Appendix", "content": "A Scheme details\nA.1 Image watermark design\nTo make the watermark less visible and more resistant to alterations, we embed the watermark into the frequency domain of the selected diffusion latent. Frequency domain watermarks are proven to be robust against common manipulations like cropping and compression and resilient against geometric distortions, such as scaling and rotation. Draw inspiration from Tree-Ring watermarks, we use a radiating watermark pattern, where the watermark information within each frequency band holds equal values. This design choice enhances the watermark's robustness against image rotations. Specifically, after each optimization round of the image watermark, the values within a specific frequency band are averaged. This averaged pattern is then used for further prompt signal optimization and another round of adversarial optimization.\nA.2 Prompt signal design\nOur scheme is based on the classifier-free guidance technique, where the generation relies on both unconditional and conditional predictions. The predicted noise of $x_t$ at step $t$ is defined as:\n$\\tilde{\\epsilon_{\\theta}}(x_t,t,\\psi(p)) = \\eta \\cdot {\\epsilon_{\\theta}}(x_t, t, \\psi(p)) + (1 - \\eta) \\cdot {\\epsilon_{\\theta}}(x_t, t, \\psi(\\O)),$\nwhere $\\eta$ is the guidance scale parameter and p is the input text condition. In this way, the model can maintain its original ability to remove noise and the new function of generating specific content.\nA.3 Optimization algorithm design\nThe details of the adversarial optimization algorithm are presented in Algorithm 1. Initially, the image watermark $w_i$ is randomly sampled, and guidance $w_p$ is set to NULL (representing no text prompt). In each round, we randomly select a generated sample $x_0$ and obtain the noise representation $x_t$ at the watermark embedding point. Then both $w_i$ and $w_p$ are optimized alternatively in an adversarial manner. We experimentally set the hyperparameters $\\alpha$ as 1.0, $\\beta$ as 1.0, and $\\lambda$ as 0.005."}]}