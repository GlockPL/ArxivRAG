{"title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models", "authors": ["Rui Zhang", "Fei Liu", "Xi Lin", "Zhenkun Wang", "Zhichao Lu", "Qingfu Zhang"], "abstract": "Automated heuristic design (AHD) has gained considerable attention for its potential to automate the development of effective heuristics. The recent advent of large language models (LLMs) has paved a new avenue for AHD, with initial efforts focusing on framing AHD as an evolutionary program search (EPS) problem. However, inconsistent benchmark settings, inadequate baselines, and a lack of detailed component analysis have left the necessity of integrating LLMs with search strategies and the true progress achieved by existing LLM-based EPS methods to be inadequately justified. This work seeks to fulfill these research queries by conducting a large-scale benchmark comprising four LLM-based EPS methods and four AHD problems across nine LLMs and five independent runs. Our extensive experiments yield meaningful insights, providing empirical grounding for the importance of evolutionary search in LLM-based AHD approaches, while also contributing to the advancement of future EPS algorithmic development. To foster accessibility and reproducibility, we have fully open-sourced our benchmark and corresponding results.", "sections": [{"title": "1 Introduction", "content": "Automated heuristic design (AHD) aims to automatically select, refine, or construct effective heuristics, thereby obviating the necessity for rich domain expertise traditionally required in manual heuristic design [1-3]. Considerable effort has been dedicated to employing machine learning techniques for AHD [4-6]. Among them, genetic programming (GP) [7] is one of the most widely used techniques for handling AHD tasks, owing to its flexible representation and efficacy across various domains [3,8-10]. However, GP necessitates specifying a set of permissible primitives and mutation operations, which unfortunately are non-trivial and problem-dependent [11]."}, {"title": "2 Background", "content": "Automated Heuristic Design (AHD) is also known as hyper-heuristics [1, 2,20], aiming to search over a space of heuristics rather than the solutions to a specific problem directly. Most of the AHD approaches incorporate a learning mechanism [4,21], such as reinforcement learning [5], Bayesian learning [6], case-based reasoning [22], and evolutionary computation methods [23-26].\nIn particular, genetic programming (GP) [7] has emerged as a promising approach to automate the design of heuristics. In essence, GP maintains a set of computer programs in the form of trees, instructions, graphs, etc., where better programs are evolved through genetic operations, such as crossover and mutation. GP-based AHD approaches have been applied in a number of different application domains, such as combinatorial optimization [27-29], scheduling [3,9], among other areas [30,31]. Although GP-based AHD approaches have"}, {"title": "3 Preliminaries", "content": "In this section, we describe the experimental setup in terms of benchmark problems, baselines, and choices of LLMs, among other settings.\nBenchmark Problems. We consider three types of applications for AHD.\nAdmissible Set (AS) [13] is a variation of the cap set problem from mathematics [57]. Formally, admissible set problems, denoted as A(n, w), are collections of vectors in {0,1,2}n that satisfy: (1) Each vector has the same number w of non-zero elements but a unique support. (2) For any three distinct vectors there is a coordinate in which their three respective values are {0,1,2}, {0, 0,1}, or {0,0,2}. The objective of the admissible set problem is to maximize the size of the set while fulfilling all the aforementioned criteria. In this work, we set n = 15 and w = 10, i.e., A(15, 10), to be consistent with prior works [12].\nOnline Bin Packing (OBP). The objective of bin packing problems is to allocate a collection of items with varying sizes into the fewest possible bins of fixed capacity of C. We consider the online scenario where items are packed as they arrive, in contrast to the offline scenario where all items are known beforehand. In this work, we consider two widely used datasets for OBP: the OR dataset [58] and the Weibull dataset [59]. To guide various LLM-based EPS methods in designing heuristics, we use 20 instances where each comprises 250 items with sizes sampled from [20, 100] for the OR dataset [12]; and we use five instances where each comprises 5K items with sizes sampled from a Weibull distribution of f(45, 3) for the Weibull dataset [12,60]. The capacity C of each bin is set to 150 and 100 for OR and Weibull datasets, respectively.\nTraveling Salesman Problem (TSP) aims to find the shortest route to visit all the given locations once and return to the starting location [16]. It is considered one of the most important CO problems and a widely used test bed for heuristic design approaches. We use a set of 64 TSP100 instances [61] where the coordinates of locations to be visited are randomly sampled from [0,1] to guide the compared LLM-based EPS methods in designing heuristics [15,60].\nBaseline. An adequate baseline is essential for understanding the relative im- provements made by the various methods (at least empirically). Existing LLM-based EPS methods were mostly compared against random search (i.e., uniform"}, {"title": "4 Experimental Results and Analyses", "content": "4.1 Performance of Standalone LLMs on AHD\nMotivation. Standalone LLMs have consistently showcased exceptional performance across a diverse array of AI applications, reaching a point where the research community has come to expect impressive results from them on new"}, {"title": "4.1.1 Angle I: Impact of Query Budget", "content": "Experimental Design. Firstly, we aim to validate the performance of standalone LLMs on AHD problems under different query budgets, i.e., maximum # of queries allowed to be sent to LLMs. Given an AHD problem, we provide the problem context along with the template heuristic (i.e., hr in Algorithm 1) as prompts to a LLM, and we ask it to keep generating new heuristics until query budgets are exhausted. Note that we do not proactively check for duplicate heuristics simply because no effective tools for functionality-level duplicate detection are readily available.\nResults. Fig. 2 depicts the aggregated performance (i.e., mean Ad over four AHD problems) of the heuristics generated by standalone GPT-3.5 with various query budgets. We also include the performance of the heuristics obtained by our baseline (1+1)-EPS as a reference. Due to space constraints, more detailed results on individual AHD problems with different LLMs are discussed in Appx. \u00a7C.2.\nOur analysis reveals that while the performance of standalone LLMs on AHD problems generally improves with increasing query budgets, several critical observations emerge:\n\u2022 There remains a significant gap between the performance of heuristics generated by standalone LLMs and the best-known performance (indicated by \u0394\u03b1 = 0, i.e., x-axis in Fig. 2), even with a substantial query budget of 100,000.\n\u2022 Although there is a steady improvement in the mean performance of the top- ranked heuristics, the performance of the best individual heuristics (repre- sented by the lower bars of the boxes) shows minimal enhancement as query budgets increase."}, {"title": "4.1.2 Angle II: Impact of More Capable LLMs", "content": "Experimental Design. Next, we attempt to understand the relationship between LLMs' capacity and their performance on AHD problems. In this work, we consider the model size (in terms of # of parameters), the coding performance (in terms of HumanEval scores [62]), and the general performance across"}, {"title": "4.1.3 Summary and Implications", "content": "Observations from the previous sections have converged to a consensus that the inherent generative capability of LLMs alone is insufficient for AHD problems, which holds true under increased query budget (\u00a74.1.1 Angle I) and model capacity (\u00a74.1.2 Angle II), suggesting the necessity of coupling LLMs with a search strategy to tackle AHD problems effectively.\nGiven the modular yet flexible framework, we believe that the LLM-based EPS paradigm, synergizing LLMs with an evolutionary search strategy, is a meaningful approach to addressing the general AHD problems."}, {"title": "4.2 Performance of Existing LLM-based EPS Methods on AHD", "content": "We decompose our investigations into the following two angles to establish an empirical understanding of the progress made by the existing LLM-based EPS methods on AHD."}, {"title": "4.2.1 Angle I: Relative Improvements over Adequate Baseline", "content": "Motivation. Existing LLM-based EPS methods incorporate a variety of complications in the search and the prompt components (see \u00a72 for more details). The relative improvements contributed by these modifications are primarily evaluated against random search or simple heuristics derived through human intuitions. On the one hand, whether the observed improvements over these naive baselines meaningfully capture the advancement in algorithmic design remains questionable; while on the other hand, the general utility of the enhancements introduced by various EPS methods also remains to be further evaluated."}, {"title": "4.2.2 Angle II: Dependency on the Choice of LLMS", "content": "Motivation. Existing LLM-based EPS methods are typically evaluated using only one particular choice of LLMs [15,60,67]. This raises uncertainty regarding the extent to which performance enhancements suggested by these methods can be applied to other LLM choices. Compounding this issue, the predominant LLM utilized in these EPS methods, i.e., GPT-3.5, is closed-source in nature. Should the efficacy of existing EPS methods hinge significantly on closed-source LLMs,"}, {"title": "4.2.3 Summary and Implications", "content": "The empirical observations from previous sections jointly suggest that the LLM- based EPS algorithmic development is still in the early stages. We hypothesize that more diverse benchmarks and applications are needed to establish a better understanding of this emergent paradigm for AHD. Nevertheless, these prelim- inary results also prompt us to (i) rethink the general efficacy of various com- ponents (such as prompt engineering and search strategy) within the overall paradigm, (ii) consider incorporating domain knowledge to LLM-based EPS al- gorithm design, and (iii) use a variety of LLMs to gain a more robust evaluation of the performance of EPS methods."}, {"title": "4.3 Search Cost", "content": "Computational Time. We present the computation time of each independent run. The computation time is estimated under the following settings:\n1. Our evaluator for the admissible set and online bin packing problems uses single-threaded evaluation, while for the TSP problem, we use eight CPU processes to perform parallel acceleration at the TSP instance level.\n2. We deploy and infer the open-source LLMs locally on a Tesla V100 GPU. We load the LLM's weights using float16 precision and generate responses using the transformers library. We set the sampling temperature to the default value of 1.0 and disable batch inference during text generation.\n3. For each independent run, we use a single evaluator and LLM. The LLM inference and function evaluation process is synchronous."}, {"title": "5 Conclusion", "content": "This work presents a large-scale benchmark study comprising all existing LLM- based EPS methods along with a new proposed baseline and four AHD problems over (up-to) nine different LLMs and five independent runs. Based on the anal- yses from multiple comparison angles, we reveal novel insights into the necessity and the current progress of the LLM-based EPS paradigm for AHD. On top of them, we summarize a few tangible implications for future research directions for LLM-based EPS, along with the fully released source codes for fostering future development."}, {"title": "A Background Continued", "content": "A.1 Connection to Genetic Programming\nEvolutionary program search (EPS) is conceptually similar to GP from the perspective of problem modeling (i.e., representing candidate solutions as executable computer programs). One of the key differences between EPS and GP lies in the representation of programs. GP uses relatively more abstract representations (such as tree, graph, list, etc.) to encode programs, while EPS directly uses executable source codes to represent programs. Another key difference between EPS and GP lies in the creation of new solutions. As the name suggested, GP uses genetic operators (e.g., crossover, mutation, etc.) to generate new offspring in an explicit manner; while EPS utilize large language models (LLMs) to drive the search implicitly. This new way of using LLMs to create programs mitigates several limitations regarding GP-based approaches [11]:\n\u2022 GP cannot leverage knowledge from descriptions or doc-string in natural language that describes what the program is intended to do, and neither can it generate language-based summarizations or hints to guide the following evolution process [48]. However, LLMs have been trained on a number of natural language data and can easily understand the given instructions as well as do summarizations.\n\u2022 GP requires defining several problem-specific parameters, such as the function and the primitive sets. Designing such a set of operations is non-trivial and requires domain knowledge about the problem. In contrast, vast amounts of coding knowledge have been encoded within the LLM through pre-training and finetuning on an extensive unlabeled code corpus. Therefore, LLM possesses the capability to design code akin to human-like proficiency.\n\u2022 Designing effective crossover and mutation operators for increasingly complicated GP programs can be hard in practice [11,48]. Whereas state-of-the-art LLMs can analyze code examples through in-context learning to generate potentially improved code. Therefore, by combining parent programs as well as contexts with reasonable prompting strategies, LLMs are able to generate more diverse and effective programs.\nTherefore, while modeling problems as computer programs are initially pioneered by GP, the advent of LLM has significantly enhanced the ability to search under this representation paradigm.\nA.2 Existing EPS Methods\nFunSearch [12] evolves heuristics for mathematical and combinatorial optimiza- tion problems, achieving superior results compared to existing solutions on the cap set [57] and admissible set problems [13]. The input to FunSearch consists of a code template (called \"specification\"), which defines a template heuristic to be evolved and a function for evaluating the searched heuristics. FunSearch"}, {"title": "C More Results and Analysis", "content": "C.1 Ablation Study for EoH under Different Experimental Settings\nIn this section, we present an ablation study on the different experimental set- tings of EoH. As mentioned in Sec. \u00a73, we modified the default EoH settings to standardize the initialization method across all EPS methods:\n- The template program is not required for the default EoH settings, as it fills the population by sampling from LLM according to the task-specific prompt. In our benchmark, we initially incorporate a template heuristic into the initial population, and repeatedly apply crossover and mutation operators to the existing individuals in the population to generate new individuals until the desired population size is achieved.\n- We also increase the default population size from 20 to 100 considering that more sampled heuristics are obtained (2,000 in default EoH settings and 10,000 in our benchmark).\nWe use EoH-D to denote EoH with default settings, where the template heuristic is not provided during initialization, and the population size is set to 20. However, we maintain the maximum number of sampled heuristics to 10,000 to promise consistency with our benchmark settings. We notice that the performance variation is notable in the admissible set problem, while it is marginal in the other problems. This suggests that applying the default settings, i.e., initializing the population by fully sampling from LLM, and a relatively smaller population size, should be a more effective setting for EoH.\nC.2 More Results on the Impact of Query Budget\nThis section is a continuation of Sec. \u00a74.1.1, where we demonstrate detailed results on individual AHD problems and LLM choices under different query budges. The standalone"}, {"title": "C.3 Performance in Each AHD Problem and LLM Choice", "content": "This section is a continuation of Sec. \u00a74.1.2, we present more elaborated results comparing the performance of various LLM choices on individual AHD problems. is provided as a reference. The performance results that: - In the online bin packing problem, the performance differences between different LLMs are minimal. However, in the admissible set and especially in traveling salesman problems, the disparities are more explicit."}, {"title": "C.4 Top-1 Performance Results", "content": "In this section, we present extensive experimental results comparing the performance of the top-1 heuristics obtained by standalone LLMs and four LLM-based EPS methods on four AHD tasks and seven LLM models. The performance is measured by the relative distance to the best-known optimum (Ad, lower is better). are particularly - The heuristic obtained by (1+1)-EPS with 500 query budgets can outperform standalone LLM with 10,000 query budgets under most LLM choices and AHD tasks."}]}