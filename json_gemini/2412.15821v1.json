{"title": "\u03c0-YALLI: UN NOUVEAU CORPUS POUR LE NAHUATL", "authors": ["Juan-Manuel Torres-Moreno", "Juan-Jos\u00e9 Guzm\u00e1n-Landa", "Graham Ranger", "Martha Lorena Avenda\u00f1o Garrido", "Miguel Figueroa-Saavedra", "Ligia Quintana-Torres", "Carlos-Emiliano Gonz\u00e1lez-Gallardo", "Patricia Vel\u00e1zquez Morales", "Elvys Linhares Pontes", "Luis-Gil Moreno Jim\u00e9nez"], "abstract": "Le projet NAHU2 est une collaboration franco-mexicaine qui vise \u00e0 construire le corpus \u03c0-YALLI adapt\u00e9 \u00e0 l'apprentissage automatique et qui permettra par la suite de d\u00e9velopper des ressources informatiques pour la langue nahuatl [1]. Le nahuatl est une langue qui dispose de peu de ressources informatiques, bien qu'il s'agisse d'une langue vivante parl\u00e9e par environ 2 millions de personnes. Nous avons d\u00e9cid\u00e9 de construire \u03c0-YALLI, un corpus qui permettra de mener des recherches sur le nahuatl afin de d\u00e9velopper des Mod\u00e8les de Langue (ML) dynamiques ou pas, qui permettront \u00e0 leur tour de d\u00e9velopper des outils de Traitement Automatique des Langues (TAL) tels que : a) un unificateur de graph\u00e8mes, b) un segmenteur de mots, c) un analyseur grammatical POS, d) un r\u00e9sumeur automatique de texte bas\u00e9 sur le contenu [2] ; et \u00e9ventuellement, e) un traducteur nahuatl-fran\u00e7ais (probabiliste ou bas\u00e9 sur l'apprentissage).", "sections": [{"title": "1 Introduction", "content": "Le nahuatl, nawatl ou mexicano (ou encore nahuatlahtolli en nahuatl) est une langue autochtone de la famille Uto-Nahua [3, 4], parl\u00e9e par un grand nombre de personnes au Mexique et dans d'autres r\u00e9gions d'Am\u00e9rique Centrale. C'est une langue parl\u00e9e au M\u00e9soam\u00e9rique depuis le V\u00e8me si\u00e8cle, \u00e9tant la langue nationale la plus parl\u00e9e au Mexique, apr\u00e8s l'espagnol, avec 1.651.958 nahuaphones [5] et plus de 2,5 millions de personnes dans la nahuaphonie ou monde nahuaphone.\nDes nos jours, le nahuatl est une langue dit vuln\u00e9rable ou en danger de disparition, selon les vari\u00e9t\u00e9s concern\u00e9es, [6]. Ceci malgr\u00e9 les efforts continus que les communaut\u00e9s Nahua ont d\u00e9ploy\u00e9s depuis 2003 \u2013ann\u00e9e de la reconnaissance du nahuatl comme langue nationale- pour que leur langue soit utilis\u00e9e \u00e0 l'oral et \u00e0 l'\u00e9crit, dans l'industrie \u00e9ditoriale, dans l'enseignement sup\u00e9rieur, les m\u00e9dias et les r\u00e9seaux sociaux [7, 8, 9, 10].\nLe nahuatl est une langue polysynth\u00e9tique et agglutinante, c'est-\u00e0-dire que les mots sont compos\u00e9s d'une racine verbale ou nominale et de morph\u00e8mes divers qui permettent de construire une signification. Un exemple d'agglutination est le suivant :\n\u2022 Cuauhtochtontli (\u00ab Petit lapin sauvage \u00bb) cuahuitl+tochtli+ton+tli (bois+lapin+diminutif+substantif)\nLes relations syntaxiques entre mots sont \u00e9tablies par le biais de la valence du verbe et des connecteurs (particules). Ceux-ci peuvent \u00e9galement \u00eatre compos\u00e9s par des regroupements \u00e9tablissant des nuances de sens, en plus des connecteurs discursifs. Certains de ces mots sont appel\u00e9s mots-phrases, puisque leur morphologie inclut le sujet et le pr\u00e9dicat, en plus d'informations sur les actants, et d'\u00e9l\u00e9ments modaux, relationnels et directionnels. Un exemple de polysynth\u00e8se est:\n\u2022 Axcan timitzoncochtiah (\u00ab Maintenant nous te faisons dormir loin \u00bb) axcan ti+mitz+on+cochi+tia+h (main-tenant nous+toi+directionnel+dormir+causatif+pluriel)\nMalgr\u00e9 son riche h\u00e9ritage, de nos jours le nahuatl fait face \u00e0 des d\u00e9fis importants en raison de son statut de langue minoritaire et de la p\u00e9nurie de ressources informatiques disponibles pour sa pr\u00e9servation et sa diffusion. Or, plut\u00f4t de faire r\u00e9f\u00e9rence au nahuatl comme une langue minoritaire, qui pourrait donner lieu \u00e0 des interpr\u00e9tations biais\u00e9es, nous pr\u00e9f\u00e9rons consid\u00e9rer que le nahuatl fait partie de la cat\u00e9gorie des \u03c0-langues, ou langues peu dot\u00e9es de ressources informatiques [11] 4."}, {"title": "2 Corpus \u03c0-YALLI", "content": "On rel\u00e8ve plusieurs efforts pass\u00e9s pour d\u00e9velopper des corpus en nahuatl. Un exemple en est le corpus Axolotl [12] disponible en ligne 5, cr\u00e9e comme un corpus parall\u00e8le nahuatl-espagnol, et qui porte sur deux vari\u00e9t\u00e9s de nahuatl. Cependant, des facteurs tels que le caract\u00e8re oral de cette langue, le manque de standardisation des graphies ou encore le nombre important de vari\u00e9t\u00e9s, font que l'on dispose de peu de documents.\nPour palier ce manque de ressources, nous avons d\u00e9cid\u00e9 de d\u00e9velopper un nouveau corpus pour le nahuatl. Nous avons collect\u00e9 un ensemble de documents provenant de plusieurs sources et en diff\u00e9rents formats (pdf, texte, doc/docx, odt, html, wiki) et encodages (iso-latin, us-ascii, utf8, utf16), ce qui a pos\u00e9 un certain nombre de probl\u00e8mes dans le traitement informatique. La structure des documents \u00e9tant h\u00e9t\u00e9rog\u00e8ne, nous les avons trait\u00e9s semi-automatiquement afin d'\u00e9liminer les informations non pertinentes. Ainsi les en-t\u00eates, les indices, les tables, plusieurs r\u00e9f\u00e9rences bibliographiques et, \u00e9galement des paragraphes \u00e9crits dans des langues autres que le nahuatl ont \u00e9t\u00e9 supprim\u00e9s des documents."}, {"title": "3 Mod\u00e8les", "content": "Un Mod\u00e8le de Langue (ML) est un outil computationnel con\u00e7u pour traiter et repr\u00e9senter les langues humaines. Au c\u0153ur de ces mod\u00e8les r\u00e9side l'utilisation des repr\u00e9sentations vectorielles de mots, \u00e9galement appel\u00e9es repr\u00e9sentations denses, qui sont indispensables pour capturer les significations et les relations entre les mots dans un format adapt\u00e9 aux machines. Les repr\u00e9sentations denses offrent un moyen puissant d'encoder \u00e0 la fois des informations s\u00e9mantiques et syntaxiques [14]. Ces repr\u00e9sentations sont essentielles pour des applications n\u00e9cessitant une compr\u00e9hension s\u00e9mantique avanc\u00e9e, telles que la reconnaissance des entit\u00e9s nomm\u00e9es, l'analyse de sentiments [15] et la classification et cat\u00e9gorisation automatiques des textes.\nDans notre \u00e9tude, nous nous concentrons initialement sur les Mod\u00e8les de Langue statiques Word2Vec [16] et Fast-Text [17]; par la suite nous allons utiliser un Grand Mod\u00e8le de Langue l\u00e9ger (LLM, Large Language Model) du type BERT [18], tel qu'ALBERT, par exemple 11. Word2Vec, avec ses architectures CBOW et Skip-Gram, capture les relations s\u00e9mantiques bas\u00e9es sur les co-occurrences de mots dans de grands corpus, produisant ainsi des repr\u00e9sentations vectorielles stables. FastText int\u00e8gre des informations sur les sous-morph\u00e8mes12, ce qui le rend particuli\u00e8rement efficace pour les langues morphologiquement riches, agglutinantes et pour le traitement de termes rares.\nLes mod\u00e8les BERT g\u00e9n\u00e8rent de plongements des mots ou embeddings dynamiques et contextuels, en tenant compte des nuances syntaxiques et s\u00e9mantiques des phrases enti\u00e8res. Cependant, ces mod\u00e8les ont besoin d'une grande quantit\u00e9 de donn\u00e9es textuelles pour \u00eatre performants. C'est une \u00e9tude approfondie que nous m\u00e8nerons avec des mod\u00e8les de type BERT afin de construire le LM BERTL (BERt en nahuaTL) et de pouvoir ainsi mesurer l'impact de la taille sur l'apprentissage et la performance dans des t\u00e2ches sp\u00e9cifiques.\nChaque mod\u00e8le ayant ses sp\u00e9cificit\u00e9s, la performance varie selon la langue, le domaine, les nuances s\u00e9mantiques et la taille du corpus \u00e9tudi\u00e9. Nous \u00e9valuerons donc ces mod\u00e8les pour le nahuatl afin de mesurer leur capacit\u00e9 \u00e0 produire des repr\u00e9sentations pr\u00e9cises et coh\u00e9rentes (intrins\u00e8que). Ces \u00e9valuations ne se limiteront pas \u00e0 des mesures quantitatives, mais incluront \u00e9galement des applications en aval pour mieux comprendre l'efficacit\u00e9 du mod\u00e8le dans des t\u00e2ches concr\u00e8tes (extrins\u00e8que). Les applications en aval incluront des t\u00e2ches telles que la classification de texte, la classification des sentiments, la reconnaissance des entit\u00e9s nomm\u00e9es, le resum\u00e9 automatique et la traduction automatique."}, {"title": "4 \u00c9valuation", "content": "Nous avons \u00e9tabli un protocole de similitude s\u00e9mantique pour r\u00e9aliser une premi\u00e8re \u00e9valuation de la qualit\u00e9 du corpus \u03c0-YALLI. \u00c9tant donn\u00e9 23 termes de r\u00e9f\u00e9rence, chacun ayant associ\u00e9 une liste de 5 termes candidats, il a \u00e9t\u00e9 demand\u00e9 \u00e0 27 nahuaphones13 de trier s\u00e9mantiquement la liste de termes candidats, du plus proche au plus \u00e9loign\u00e9 de la r\u00e9f\u00e9rence [1]. Chaque terme candidat a re\u00e7u une note de 1 \u00e0 5 (\u00e9tant 1 jug\u00e9 le terme candidat le plus proche s\u00e9mantiquement \u00e0 la r\u00e9f\u00e9rence et 5 le plus \u00e9loign\u00e9). Ceci a permis de cr\u00e9er un ensemble de rangs.\nLa s\u00e9lection des termes (r\u00e9f\u00e9rences et candidats) a \u00e9t\u00e9 r\u00e9alis\u00e9e selon diff\u00e9rents crit\u00e8res : d'abord, les mots d'usage courant exprim\u00e9s dans trois cat\u00e9gories grammaticales (substantifs, verbes et particules) comprenant les noms d'ustensiles, d'aliments, de v\u00eatements, de couleurs, de go\u00fbts, de qualit\u00e9s, de termes de parent\u00e9 et de parties du corps. Ensuite, nous avons consid\u00e9r\u00e9 des actions quotidiennes -au moyen des verbes transitifs, intransitifs, verbes d'\u00e9tat et de mouvement fl\u00e9chis en num\u00e9ro et formes verbales-, les particules adverbiales de nature quantitative et locative spatio-temporelle, et enfin des expressions de salutation. Ces mots ont \u00e9t\u00e9 exprim\u00e9s dans diff\u00e9rentes vari\u00e9t\u00e9s dialectales, y compris des formes caract\u00e9ristiques du nahuatl central, du nahuatl de La Huasteque et du nahuatl du sud, ainsi que dans des formes caract\u00e9ristiques du nahuatl savant ou litt\u00e9raire (tecpillahtolli), et en utilisant des diff\u00e9rents alphabets employ\u00e9s par les locuteurs, mais avec une majorit\u00e9 de formes caract\u00e9ristiques du nahuatl central, \u00e9crites avec un alphabet modernis\u00e9.\nDans certains cas, o\u00f9 il y avait variation formelle, l'association a \u00e9t\u00e9 r\u00e9alis\u00e9e en fonction des aspects morphologique ou compositionnel. Dans d'autres cas, il est possible que des sens figur\u00e9s, symboliques ou m\u00e9taphoriques aient \u00e9t\u00e9 reconnus \u00e0 partir d'une lecture plut\u00f4t culturelle. On a donc d'autres types d'association logique qui s'\u00e9loignent de l'association s\u00e9mantique. Par exemple, dans le cas de la r\u00e9f\u00e9rence noyollo, \u00ab mon c\u0153ur \u00bb, o\u00f9 une association avec des termes comme nomah, \u00ab ma main \u00bb ou noyoliknih, \u00ab mon ami du c\u0153ur \u00bb, \u00e9tait attendue, il y a eu une forte pr\u00e9f\u00e9rence pour le terme yoli, \u00ab vivre \u00bb, tout simplement parce qu'il \u00e9tait associ\u00e9 \u00e0 son origine \u00e9tymologique (yol-) et donc \u00e0 un certain sens originel du mot yollotl, \u00ab coeur \u00bb ou \u00ab ce qui a de la vivacit\u00e9 \u00bb. D'un autre c\u00f4t\u00e9, on pense parfois \u00e0 partir d'une traduction espagnole; tel est le cas de nemi, \u00ab habiter, marcher \u00bb, qui a tendance \u00e0 \u00eatre associ\u00e9 \u00e0 yoli, \u00ab \u00eatre vivant \u00bb, plut\u00f4t qu'\u00e0 chantia, \u00ab y r\u00e9sider \u00bb. associ\u00e9 \u00e0 des formes qui peuvent composer une phrase pleine de signification, comme associer tlahtolli, \u00ab mot, r\u00e9cit, langue \u00bb, \u00e0 onikkak, \u00ab je l'ai \u00e9cout\u00e9 \u00bb, et composer onikkak tlahtolli, \u00ab je ai \u00e9cout\u00e9 un r\u00e9cit \u00bb, ou noyollo avec paki, \u00ab \u00eatre heureux \u00bb, pour construire noyollo paki, <<< mon c\u0153ur est heureux \u00bb, une salutation habituelle. Ainsi, nous trouvons des r\u00e9ponses qui montrent une diff\u00e9rence culturelle entre ce que nous comprenons comme une association s\u00e9mantique logique de nos langues, une extension des significations \u00e0 partir d'usages culturels, une interf\u00e9rence s\u00e9mantique dans des contextes de bilinguisme. Ce type d'association n'\u00e9tait pertinent que pour certains mots bien sp\u00e9cifiques. Les termes de r\u00e9f\u00e9rence eux-m\u00eames n'avaient pas de signification complexe, mais ils n\u00e9cessitaient un profil de locuteur familier avec d'autres variantes et graphies. Le profil des annotateurs a \u00e9t\u00e9 \u00e9tabli en tenant compte de cette condition, puisqu'il s'agit d'universitaires et d'\u00e9tudiants de Master qui utilisent la langue nahuatl \u00e0 l'oral et \u00e0 l'\u00e9crit dans le cadre de leurs activit\u00e9s professionnelles, de formation et de communication."}, {"title": "4.1 Coefficient W de Kendall", "content": "Le coefficient W de Kendall permet d'\u00e9valuer la coh\u00e9rence entre plus de deux classements, et repr\u00e9sente une extension du coefficient de corr\u00e9lation 7 de Kendall, con\u00e7u sp\u00e9cifiquement pour mesurer le degr\u00e9 de concordance entre deux classements. \u00c9tant donn\u00e9 n \u00e9l\u00e9ments \u00e0 classer et m rangs ind\u00e9pendants (venant du m\u00eame nombre de juges ou annotateurs) on calcule le coefficient de Kendall avec la formule suivante:\n$$W = \\frac{12\\sum_{i=1}^{n} (R_i \u2013 R)^2}{m^2(n^3 \u2013 n)}$$\n o\u00f9 Ri est la somme des rangs assign\u00e9s \u00e0 l'\u00e9l\u00e9ment i et R la moyenne de ces sommes. Une valeur de W = 1 indique une concordance parfaite o\u00f9 tous les classements sont identiques, et une valeur de W = 0 indique une absence totale de concordance, ce qui signifie que les positions dans les classements sont compl\u00e8tement incoh\u00e9rentes."}, {"title": "4.2 Entropie H de Shannon", "content": "Le coefficient d'entropie de Shannon est utilis\u00e9 pour d\u00e9terminer l'incertitude ou h\u00e9t\u00e9rog\u00e9n\u00e9it\u00e9 d'un ensemble. Dans un ensemble de rangs, il renseigne sur la coh\u00e9rence ou la diversit\u00e9 entre les rangs. La statistique d'entropie de Shannon a \u00e9t\u00e9 calcul\u00e9e en utilisant la formule suivante:\n$$H(x) = - \\sum_{i=1}^{n} p_i log_2(p_i)$$\no\u00f9 pi est la probabilit\u00e9 (ou fr\u00e9quence relative) que l'\u00e9l\u00e9ment x soit dans la position i. Les valeurs sont entre 0 (coh\u00e9rence totale entre les rangs) et la valeur maximale possible Hmax = log2(n) (divergence totale entre les rangs qui a lieu quand toutes les positions sont \u00e9quiprobables, c'est-\u00e0-dire ).\nNous avons normalis\u00e9 la sortie de la m\u00e9trique de Shannon entre [0, log2(n)], o\u00f9 n = 5 correspond au nombre de candidats par r\u00e9f\u00e9rence de la t\u00e2che s\u00e9mantique. Dans le cas de Kendall nous avons employ\u00e9 directement sa valeur de sortie, car le coefficient W est d\u00e9j\u00e0 normalis\u00e9e entre [0,1]."}, {"title": "4.3 Exemple", "content": "Nous pr\u00e9sentons ci-apr\u00e8s un exemple du protocole d'\u00e9valuation pour le terme de r\u00e9f\u00e9rence tototl (oiseau). La table suivante r\u00e9sume cette information. Soient les n mots candidats {avion, aigle, coyote} et les m annotateurs {J1, J2, J3} qui ont annot\u00e9 les rangs suivants:"}, {"title": "4.4 \u00c9valuation des Mod\u00e8les de Langue via un Rang par consensus", "content": "En utilisant la m\u00e9thode de Borda Count 17, nous avons construit un Rang par consensus (CR), qui repr\u00e9sente la majorit\u00e9 des rangs pour chacune des r\u00e9f\u00e9rences. Puis, nous avons calcul\u00e9 la distance entre chacun des rangs des annotateurs et le rang par consensus CR. Ce consensus nous a servit principalement \u00e0 deux choses:\n1. \u00e0 estimer l'\u00e9loignement d'un annotateur donn\u00e9 par rapport \u00e0 l'ensemble des m annotateurs; et\n2. \u00e0 \u00e9valuer l'accord (via le coefficient de corr\u00e9lation 7 de Kendall) entre le consensus et les ML Word2Vec et FastText.\nIl faut pr\u00e9ciser que, dans le cas des annotateurs les plus \u00e9loign\u00e9s du Rang consensus, nous avons d\u00e9cid\u00e9 de les supprimer du protocole d'\u00e9valuation pour deux raisons: d'abord, car le rang induit par ces annotateurs peut constituer un biais au calcul des mesures, et ensuite, de mani\u00e8re plus importante, pour avoir un nombre impair (27) d'annotateurs, ce qui \u00e9vite les potentiels ex-\u00e6quo entre les rangs."}, {"title": "5 Discussion", "content": "Nous avons constat\u00e9 que les deux mesures que nous avons employ\u00e9es montrent une corr\u00e9lation par rapport au - relativement- faible accord entre les annotateurs (voir les Figures 2 et 3). Or, dans l'\u00e9tat de l'art, la m\u00e9trique la plus adapt\u00e9e et la plus utilis\u00e9e pour mesurer l'accord entre plusieurs rangs, est la statistique W de Kendall. Nous avons donc focalis\u00e9 sur cette m\u00e9trique. Le coefficient W de Kendall varie de 0,1896 pour la r\u00e9f\u00e9rence Melawak (correct), qui a obtenu la valeur la plus basse, jusqu'\u00e0 0,598 pour la r\u00e9f\u00e9rence noyollo (mon c\u0153ur), avec la valeur la plus \u00e9lev\u00e9e.\nD'apr\u00e8s nos autres r\u00e9sultats, nous constatons que certaines r\u00e9f\u00e9rences ayant des valeurs basses de Kendall (et \u00e9galement d'entropie) n'ont pas obtenu les r\u00e9ponses attendues. En effet, quelques choix de classement montrent que certains mots candidats n'ont pas \u00e9t\u00e9 clairement identifi\u00e9s. Cela peut s'expliquer en raison de leur emploi tr\u00e8s localis\u00e9 qui a donc fauss\u00e9 les \u00e9valuations d'association s\u00e9mantique. Il en va de m\u00eame pour certains mots qui ont pu \u00eatre consid\u00e9r\u00e9s comme des archa\u00efsmes et ou qui n'\u00e9taient pas connus. Dans d'autres cas, l'association semble avoir \u00e9t\u00e9 faite sur la base d'une logique syntaxique, selon laquelle les verbes sont appari\u00e9s avec des substantifs pouvant \u00eatre objet ou sujet."}, {"title": "6 Conclusions", "content": "Bien que le corpus \u03c0-YALLI ait une taille r\u00e9duite vis-\u00e0-vis de corpus d'autres langues, et qu'il soit encore en cours de d\u00e9veloppement, nous pensons qu'il s'agit d'une ressource int\u00e9ressante pour \u00e9tudier la langue nahuatl [1]. On pourra, par exemple, \u00e9tudier l'impact de la taille du corpus dans l'apprentissage \u2013profond ou pas\u2013 de Mod\u00e8les de Langue nahuatl. Par ailleurs, nous augmentons constamment le volume du corpus \u03c0-YALLI. Ce corpus permettra de d\u00e9velopper des outils d'analyse TAL classiques, des Mod\u00e8les de Langue (ML) et probablement des Grands Mod\u00e8les de Langue (LLM) d'Intelligence Artificielle l\u00e9gers que nous diffuserons \u00e0 la communaut\u00e9 scientifique. De plus, l'utilisation \u00e9mergente et croissante du nahuatl dans les r\u00e9seaux sociaux, dans l'\u00e9dition, dans les programmes universitaires et dans la diffusion scientifique rend ces outils de plus en plus n\u00e9cessaires pour l'acc\u00e8s et la gestion de l'information num\u00e9rique disponible.\nAinsi, cette accessibilit\u00e9 permettra de relier diff\u00e9rentes communaut\u00e9s de nahuaphones situ\u00e9es dans des r\u00e9gions et des pays diff\u00e9rents, ainsi que de faire circuler les connaissances exprim\u00e9es dans cette langue aupr\u00e8s des \u00e9tudiants et des sp\u00e9cialistes. Il s'agit donc d'un \u00e9lan puissant pour faire mieux conna\u00eetre cette importante \u03c0-langue."}]}