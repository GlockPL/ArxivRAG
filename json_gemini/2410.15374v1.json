{"title": "Explainability of Point Cloud Neural Networks Using SMILE: Statistical Model-Agnostic Interpretability with Local Explanations", "authors": ["Seyed Mohammad Ahmadi", "Koorosh Aslansefat", "Rub\u00e9n Valcarce-Di\u00f1eiro", "Joshua Barnfather"], "abstract": "In today's world, the significance of explainable AI (XAI) is growing in robotics and point cloud applications, as the lack of transparency in decision-making can pose considerable safety risks, particularly in autonomous systems. As these technologies are integrated into real-world environments, ensuring that model decisions are interpretable and trustworthy is vital for operational reliability and safety assurance. This study explores the implementation of SMILE, a novel explainability method originally designed for deep neural networks, on point cloud-based models. SMILE builds on LIME by incorporating Empirical Cumulative Distribution Function (ECDF) statistical distances, offering enhanced robustness and interpretability, particularly when the Anderson-Darling distance is used. The approach demonstrates superior performance in terms of fidelity loss, $R^2$ scores, and robustness across various kernel widths, perturbation numbers, and clustering configurations. Moreover, this study introduces a stability analysis for point cloud data using the Jaccard index, establishing a new benchmark and baseline for model stability in this field. The study further identifies dataset biases in the classification of the 'person' category, emphasizing the necessity for more comprehensive datasets in safety-critical applications like autonomous driving and robotics. The results underscore the potential of advanced explainability models and highlight areas for future research, including the application of alternative surrogate models and explainability techniques in point cloud data.", "sections": [{"title": "Introduction", "content": "Since the invention of the first machine, humankind has long aspired to create a fully automated world where all tasks are performed by machines. Recently, advancements in artificial intelligence, particularly with large language models like ChatGPT, which can communicate and respond in human language, have brought humankind closer than ever to realizing this long-held dream. However, achieving this vision requires another critical advancement: the development of machines capable of performing physical activities. Progress in the field of robotics appears to be the gateway to entering a fully automated world as the next step.\nInternational Federation of Robotics (IFR) reported a record high of 517,385 new industrial robots installed in factories worldwide in 2021, with over 3.5 million units currently performing industrial tasks [1]. The advancement of robotics requires improved visual interpretation and 3D object representation techniques to enable robots to accurately perceive and interact with their environments.\nVoxel grids, 3D meshes, multi-view camera projections and point clouds are the four primary forms of 3D objects representations [2]. A point cloud is a set of data points defined in a 3D coordinate system, which has recently gained more attention from the scientific community and is employed in a variety of areas, including 3D shape classification, 3D segmentations and object detection and tracking. This is because point clouds are not only easier to collect using LiDAR and RGB-D sensors but also provide a more thorough representation of objects compared to other forms. Moreover, point cloud data can efficiently store various attributes such as temperature, colour, and other specific parameters of an object at each point [3]. Most of the point cloud segmentation and classification techniques rely on deep neural networks (DNNs). However, these methods are more complicated and time-consuming than typical 2D DNNs used for images. This complexity arises from the disordered nature of point clouds, meaning there is no inherent order between data structures and spatial coordinates in the neighbourhood [2].\nUntil now, various methods are used for point cloud classification, categorised based on their feature learning architectures. The most notable ones include continuous and discrete convolution-based methods, Graph-based methods, pointwise MLP methods, and hierarchical data structure-based methods [2-4]. These methods have used different datasets with varying numbers and types of classes, some synthetic and others from the real world. Their representations include point clouds and other types like RGB-D and mesh, which are converted into point clouds before use [5-11].\nNevertheless, most DNN methods are not transparent and are often regarded as a black box, despite their satisfactory performance in classification tasks. On the other hand, the use of point cloud data in expensive and critical applications such as robotics and autonomous driving has become increasingly common. Therefore, the low decision confidence and poor interpretability of these models can significantly jeopardize people's lives and property [12].\nThe domain of explainable artificial intelligence (XAI) has recently gained traction. Various interpretability techniques have been proposed, and there are different methods to categorize XAI models, each focusing on specific parameters [13]. Some techniques operate at the individual level (IL), concentrating on the prediction for a single instance, while model-level (ML) or global-level models aim to describe the overall logic and behaviour of the models across the entire dataset. Certain models require training and learning another model, such as a surrogate model. Additionally, there are model-agnostic (MA) approaches that can be used with any type of machine learning model, irrespective of its internal structure, as well as model-specific (MS) techniques designed for specific model types. Some interpretability methods follow a backward flow, starting with the model's prediction and working"}, {"title": "State of the Art", "content": "backward to understand how the input features influenced these predictions, while others follow a forward flow [14].\nWhile much progress has been made in XAI, particularly concerning DNNs for 2D images, there remains a lack of studies focused on the interpretability and explainability of 3D data, underscoring the need for further research in this area [15]. This study introduces a recent technique, SMILE [16], for use with point cloud data. SMILE, which has shown strong performance on 2D and tabular data, is derived from LIME [17] and involves generating perturbations of an instance from the dataset and training a simple, more interpretable surrogate model based on the distances and predictions of the main complex model. Although LIME has previously been applied to point cloud data [18], SMILE differs by utilizing Empirical Cumulative Distribution Function (ECDF)-based statistical distances, which offer greater stability compared to the cosine distances used in LIME.\nThe primary goal of this study is to enhance surrogate explainable models by introducing SMILE for point cloud data. The study's contributions include generating saliency maps for 3D objects, comparing the most important features influencing model predictions using LIME and various versions of SMILE under different parameter sets, and, also, evaluating the use of Bayesian Ridge as the surrogate model. The models are compared using fidelity parameters, and their stability is assessed by introducing noise into the point cloud object. Additionally, the study explores the classification of one of the most critical objects, the 'person' class, and examines its misclassified samples.\nThe structure of this study is as follows: Section 2 reviews related work, Section 3 outlines the algorithm and methodology of the proposed approach, Section 4 details the experimental results and discusses the findings, and Section 5 concludes the study.\nAs mentioned earlier, explainable models deployed in the realm of point clouds are relatively few. Table 1 provides a summary of these models, with this study's approach included, and compares them across different XAI parameters. The models are explained in more detail in this section.\nPointHop was one of the pioneering attempts to make AI applied to point clouds more understandable [12]. Their work tackled the unordered nature of point clouds by employing PointHop units to make them compatible with traditional classifiers, serving as a pre-processing step rather than a post hoc explanation method. [19] proposed a method for generating saliency maps in point cloud recognition models by identifying non-contribution factors. This technique incorporates a different evaluation strategy that involves randomizing both the network weights and labels. In [18] the author employed a local surrogate model-based method to identify which factors play a role in classification. They also propose quantitative fidelity measurements for interpretability and compare the fidelity and plausibility of the surrogate model under different condition, as opposed to relying on a subjective approach relying on human judgment. In another study, [20] extended gradient-based methods including Vanilla Gradients, Guided Backpropagation, and Integrated Gradients to 3D point cloud and voxel data for the PointNet++ and Voxception-ResNet (VRN) models. They found that edges and corners are important features, while planar surfaces contribute less to classification decisions. Their results demonstrated that integrated gradients provided more uniform and meaningful attribution maps compared to the noisier vanilla gradients, especially for voxel-based inputs. In a novel framework named BubblEX, a new approach is proposed to enhance the explainability of deep learning models for 3D point-cloud classification [21]. The authors utilized t-SNE and UMAP techniques for dimensionality reduction to visualize high-dimensional feature data in a 2-D space and employed Grad-CAM for interpretability."}, {"title": "Methodology", "content": "In another work, [22] introduces generative model-based Activation Maximization (AM) techniques to enhance the global explainability of point cloud neural networks, addressing the limitations of traditional methods in capturing the irregular and sparse structure of point clouds. Recently, [23] proposed DAM a novel method using Denoising Diffusion Probabilistic Models (DDPM) to generate high quality AM global explanations. Furthermore, DAM employs a Point Diffusion Transformer (PDT) with dual-classifier guidance, demonstrating superior performance in perceptibility, representativeness, and diversity, while also significantly reducing the time needed for explanation generation. In another recent approach, Feature Based Interpretability (FBI), a fast and simple XAI method for point cloud data are introduced [24]. Their method computes pointwise importance, allowing for better understanding of network properties. They demonstrated that pre-bottleneck computation is preferred over post-bottleneck, offering smoother and higher quality importance ranking. The FBI method is significantly faster than other XAI methods, making it scalable for large point clouds and extensive network architectures [24]."}, {"title": "Implementation Details", "content": "The primary difference between LIME and SMILE lies in their distance calculation methods: SMILE uses Empirical Cumulative Distribution Function-based (ECDF) statistical distances, whereas LIME employs Cosine distances [16]. As depicted in Figure 1, these stages include generating randomly perturbed inputs around a given sample, predicting labels using a black-box classifier, calculating distances between the sample and each perturbation, determining feature weights using a kernel function, and deploying a weighted linear regression as a surrogate model.\nTo manage computational complexity when explaining point cloud data, the points are clustered into super points using 3D K-Means clustering and Farthest Point Sampling (FPS) [18]. The core concept of FPS involves iteratively choosing the point that is most distant from the previously selected points. These chosen points create a subset that closely represents the original set, reducing the total number of points while retaining the key features of the original data [25].\nPerturbations are then generated using a binary mask matrix, The mask perturbation matrix M is generated using a binomial distribution with a success probability of 0.5, ensuring each cluster has an equal chance of being turned on or off independently. These perturbations are fed into the black-box model to generate class probabilities.\nIn SMILE, ECDF statistical distances, such as Wasserstein Distance (WD), are calculated to capture the geometry-related features of the distributions between the main instance and perturbations. The WD calculates the distance between two univariate distributions $F_1(x)$ and $F_2(x)$ as follows [26]:\n$WD = \\int_{-\\infty}^{+\\infty} |F_1(x) - F_2(x)|dx$ (1)"}, {"title": "Evaluation Metrics", "content": "Here, $F_1(x)$ represents the ECDF of the target point and its surrounding local distributed samples, while $F_2(x)$ represents the ECDF of the clustered random points relative to their class labels. Other ECDF-based measures, including Kolmogorov-Smirnov and Anderson-Darling distances, are also considered [16].\nThe total distance across all coordinates is computed, and the resulting distances are mapped to weights using an exponential smoothing kernel function:\n$W_i = exp(-\\frac{WD^2}{\\sigma^2})$ (2)\nThe kernel width $\\sigma$ is crucial in determining the sensitivity of the weights, with a range of $\\sigma$ values explored for optimal results.\nFinally, a simple model is trained using the features, predicted labels, and calculated weights. The model's coefficients provide insights into the impact of each feature on the different classes."}, {"title": "Fidelity:", "content": "To measure the alignment between the black-box model and the explainable model, fidelity is employed as a metric. Given $f(Z_i)$ and $g(Z_i)$ as their respective predictions for the i-th perturbation, various loss and coefficient metrics assess the similarity between the regression scores and predictions. One such metric is mean loss, defined as [18]:\n$L_m = \\frac{1}{N_p} |\\sum_{i=1}^{N_p} (\\frac{f(Z_i)}{N_p}) - \\sum_{i=1}^{N_p} (\\frac{g(Z_i)}{N_p})|$ (3)\nAdditional metrics include the Mean $L_1$ and $L_2$ losses:\n$L_1 = \\frac{1}{N_p} \\sum_{i=1}^{N_p} |f(Z_i) - g(Z_i)|$ (4)\n$L_2 = \\frac{1}{N_p} \\sum_{i=1}^{N_p} (f(Z_i) \u2013 g(Z_i))^2$ (5)\nWeighted versions of these losses are also used:\n$LY = \\frac{1}{N_p} \\sum_{i=1}^{N_p} (|f(Z_i) \u2013 g(Z_i)|.w)$ (6)\n$L = \\frac{1}{N_p} \\sum_{i=1}^{N_p} (((f(Z_i) \u2013 g(Z_i))^2).w)$ (7)\nThe weighted coefficient of determination is given by:\n$R^2_w = 1 - \\frac{\\sum_{i=1}^{N_p}(f(Z_i) \u2013 g(Z_i))^2}{\\sum_{i=1}^{N_p}(f(Z_i) \u2013 f_w(Z_i))^2}$ (8)"}, {"title": "Stability:", "content": "Moreover, the weighted adjusted coefficient of determination is defined as:\n$R = 1- (1-R_w) \\frac{N_p-1}{[N_p \u2013 N_s \u2013 1}$ (9)\nwhere w represents kernel weights, and $f_w(Z_i)$ is the weighted average.\nDiscrepancies in predicted scores are quantified using $L_m$, $LW$ and $L$, while $R_w$ evaluates the correlation between the proxy model and the neural network. Given that $R_w$ is susceptible to positive bias in small sample sizes, $R\u016b$ adjusts for sample size and variable count [27].\nAn explainable model should exhibit stability, meaning that minor changes to the input should not affect the model's predictions or explanations [28]. An explanation $m_i$ for an input graph $g_i$ is regarded as the ground truth. The input graph $g_i$ is then perturbed by minor changes, such as adding new cluster of points, resulting a new graph $g'_i$ having the same prediction. The explanations for $g'_i$ are obtained and denoted as $m'_i$. Therefore, by comparing the differences between $m_i$ and $m'_i$ the stability can be calculated.\nPrevious research has highlighted that local surrogate models may be unstable across various data types, including text, tabular, and image data [29]. This study extends stability analysis to point cloud data, employing the Jaccard index as the metric. The Jaccard index, defined as:\n$Jaccard(A, B) = \\frac{A \u2229 B}{A \u222a B}$ (10)\nmeasures the similarity between two sets A and B as the ratio of their intersection to their union with values bounded between 0 and 1."}, {"title": "Experiments and Discussion", "content": "While the proposed SMILE model is model-agnostic and can be extended to any point cloud model, this study examines one of the most well-known models, PointNet [30]. PointNet, based on pointwise MLP networks, achieved an accuracy of 89.2% on the ModelNet40 dataset. A previous study [18] used this model to demonstrate the capability of LIME on 3D point cloud data, making it as the only work in the literature that has applied an XAI model to the ModelNet40 dataset in a manner directly comparable to our study. Additionally, Kernel SHAP (SHapley Additive explanations) [31] was explored for a more comprehensive comparison between XAI methods. Although specific objects and results from the referenced study were not accessible, the LIME and Kernel SHAP results are referenced here due to alignment with their cited methodologies."}, {"title": "Cluster Number Comparison", "content": "To obtain the saliency map and fidelity measurements, an object from the airplane class is selected from the dataset and converted to point cloud data with 1024 points. The object is then examined under different cluster numbers (32, 64, 128, and 1024) using the K-means clustering algorithm along with FPS. The number of perturbations is set to 1000, with weighted regression used as the surrogate model. After sorting the clusters by importance, the top 20% of the most significant ones are highlighted in red to indicate the critical features used by the main model for classification.\nAs depicted in Figure 2, the saliency maps for LIME and SMILE are identical. Both methods highlight the tail and wings of the airplane as the most important features for predicting the labels, which aligns logically with human intuition. However, it is noteworthy that when the number of clusters is set to 1024, both models fail to identify the most important features. This indicates that for this number of clusters, the number of perturbations should be increased to achieve suitable results [18]. In contrast, SHAP's saliency maps become inconsistent as cluster numbers increase, suggesting it may require more perturbations or adjustments for point cloud data."}, {"title": "Kernel width Comparison", "content": "To enable a more comprehensive comparison, fidelity parameters are employed to evaluate the SMILE model using ECDF statistical distances, including Wasserstein (SMILE-WD), Anderson-Darling (SMILE-AD), and Kolmogorov-Smirnov (SMILE-KS) distances, alongside LIME, which uses cosine distance. The results, summarized in Table 2, indicate that all SMILE methods generally exhibit higher weighted ($R^2_w$) and weighted adjusted ($R$) coefficients, suggesting superior performance. Furthermore, SMILE-AD demonstrates significantly lower mean loss compared to all other methods and also attains the highest $R^2_w$ performance among the methods. However, as the number of clusters increases, both $R^2_w$, $R$ decrease across all models, suggesting that the accuracy of the explainable models diminishes with higher cluster counts. This trend indicates a potential need to increase the number of perturbations when working with higher cluster sizes to maintain accuracy.\nRegarding $L_1$, $L_2$, $LW$, $L\u00bd$, some inconsistencies in the results are observed, which stem from the nature of the comparisons. Specifically, the formulation compares the probabilities generated by the models rather than the predicted classes. As these parameters compare probabilities on a one-to-one basis, it can lead to inconsistencies in the results."}, {"title": "Perturbation Number Comparison", "content": "To evaluate the impact of kernel width on model performance, a range from 0.1 to 0.7, with 0.1 increments, was tested. Figure 3 shows the saliency maps generated by SMILE and LIME across different kernel widths. Notably, all SMILE variants produced identical saliency maps, indicating consistency across the methods.\nRegarding fidelity, as shown in Figure 4 increasing kernel width generally reduced Mean Loss and improved the $R^2_w$ score, reflecting enhanced performance. SMILE-AD, using the Anderson-Darling distance, consistently maintained a high $R^2_w$ score of 0.54 and a Mean Loss in the order of $10^{-9}$, demonstrating superior stability compared to LIME. This stability, likely due to the AD distance's sensitivity to the tails of distributions, indicates that SMILE-AD provides consistent explanations without the need for fine-tuning the kernel width.\nAnother examination was conducted to assess the effect of the number of perturbations on approach model, using a cluster count of 32 and a kernel width of 0.5. The fidelity scores of models are compared in Figure 5. The loss metrics fluctuated without significant differences across models when compared to themselves. However, $R^2_w$ generally decreased with higher perturbations, except for a surprising increase at 450 perturbations. This trend occurs because fidelity scores compare probabilities, making them sensitive to the number of perturbations. In other words, as the number of perturbations increases, more comparisons are made, leading to higher loss and, consequently, lower $R^2_w$.\nWhen comparing saliency maps across different perturbation counts, the maps for all models were identical. Therefore, only a single SMILE map is presented in Figure 6. The saliency maps varied among models with fewer than 750 perturbations, but remained consistent beyond this threshold, indicating that a minimum of 750 perturbations is sufficient for stable results with 32 clusters. This suggests an acceptable baseline for perturbations in this setting."}, {"title": "Surrogate Model Comparison", "content": "In another experiment, LIME, SMILE-WD, SMILE-AD, and SMILE-KS were evaluated using Bayesian Ridge as the surrogate model instead of weighted regression, with a kernel width of 0.5, 32 clusters, and 1000 perturbations. Comparing the results in Table 3 with those in Table 2 indicates that $R^2_w$ values for all SMILE variants and LIME were slightly higher with weighted regression compared to Bayesian Ridge. Notably, SMILE-AD, which was the best model with weighted regression, experienced a significant drop in $R^2_w$ with Bayesian Ridge, making it the worst-performing model among the others."}, {"title": "Stability", "content": "To further evaluate the stability of the proposed model, a cluster of 30 points, shaped like a ball, was randomly inserted into various locations on the object. LIME and SMILE were then employed to identify the clusters with the most significant contribution to the model's predictions. As shown in Figure 7, critical features, including clusters on the tail and wings of the airplane, generally remained stable even after the introduction of the bulk. However, the importance of features shifted noticeably when the bulk itself was identified as the most significant feature. This shift likely occurs because the model prioritizes the bulk when it is positioned near crucial features, indicating the model's reliance on the spatial proximity of points within the point cloud.\nBy comparing 10 perturbed samples using the Jaccard index, a mean value of 0.78 was obtained for both the LIME and SMILE methods. This value suggests a moderate level of stability, indicating that while the model's explanations are somewhat influenced by perturbations, the overall consistency remains acceptable. These results highlight the robustness of the model and the reliability of explanations provided by both LIME and SMILE, even with minor input changes."}, {"title": "Computation Complexity", "content": "Since the number of perturbations directly influences running time, a fixed 1000 perturbations were used to compare the running times of all models with 32, 64, and 128 clusters, using either weighted regression or Bayesian Ridge as the surrogate model. As shown in Figure 8, models using Bayesian Ridge exhibit slightly shorter running times compared to those using weighted regression. Among the models, LIME is the most time-efficient, while SMILE-KS is the least, with a difference of approximately 3 seconds."}, {"title": "SMILE Analysis of Misclassified Objects", "content": "Failure analysis is a crucial application of explainable models, as it aids in identifying incorrect areas of focus by the classifier, thereby providing insights for potential model or dataset improvements. In this study, the 'person' object was selected as one of the most important categories for classification, given its significance in improving the reliability and safety of autonomous robots and vehicles. The ModelNet40 dataset [7] contains only 18 objects of this class in its test set, with PointNet correctly predicting 11 of them [30]. However, a more detailed examination of the dataset revealed that most 'person' objects are depicted holding items resembling a sword or gun. Notably, the model struggled to correctly classify those \u2018person' objects that displayed a normal gesture without any additional objects. Using SMILE to identify the most important features the model focuses on for correctly labelled 'person' objects, as shown in Figure 9, indicates that the presence of objects like a gun or sword, along with the person, are considered critical features by the model. This suggests that the model incorrectly prioritizes these additional objects, leading to misclassification when they are absent.\nThis analysis suggests that ModelNet40 may not be an ideal dataset for detecting humans. Future models intended for point cloud classification should consider exploring other available datasets or augmenting ModelNet40 with a more comprehensive set of 'person' objects."}, {"title": "Conclusion", "content": "In response to the increasing demand for more interpretable and explainable AI models, this study evaluates the novel SMILE approach, a refinement of LIME that uses Empirical Cumulative Distribution Function (ECDF) statistical distances, within the context of point cloud data. Comparative analysis with LIME reveals that SMILE consistently offers superior fidelity scores, particularly with the Anderson-Darling distance (SMILE-AD), which demonstrates robust stability unaffected by kernel width. Perturbation analysis indicates that the surrogate models remain stable with over 700 perturbations and 32 clusters, and linear regression outperforms Bayesian Ridge as a surrogate model in terms of fidelity. Although LIME is more computationally efficient, all tested models operate within acceptable time limits. Stability assessments, indicated by a Jaccard index of 0.78, affirm a suitable level of stability for the SMILE approach, setting a new benchmark for measuring the stability of point cloud models and establishing a standard for future research in this area.\nMoreover, the application of SMILE to classify 'person' objects exposed dataset biases, highlighting the need for more comprehensive and contextually relevant data, particularly for critical applications such as autonomous driving and robotics.\nThis study underscores the importance of further research into both explainability methods and dataset improvements to enhance model interpretability and robustness. There is significant potential for advancing explainability in point cloud DNNs through the exploration of alternative surrogate models and other explainable approaches."}]}