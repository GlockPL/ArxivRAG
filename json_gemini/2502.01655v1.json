{"title": "A Binary PSO Based Ensemble Under-Sampling Model\nfor Rebalancing Imbalanced Training Data", "authors": ["Jinyan Li", "Yaoyang Wu", "Simon Fong", "Antonio J. Tall\u00f3n-Ballesteros", "Xin-she Yang", "Sabah Mohammed"], "abstract": "Ensemble technique and Under-sampling technique are both effective tools for resolvig imbalanced dataset\nclassification problems, which commonly denotes the quantitative imbalance of a binary class dataset where\nminority class is the target class. In this paper, a novel ensemble method absorbing the advantages of both ensemble\nlearning for biasing classifiers and a new evolutional under-sampling method is proposed. The under-sampling\nmethod is named Binary PSO instance selection, it gathers with ensemble classifiers to find the most suitable length\nand combination of majority class samples to build a new dataset with minority class samples. The proposed method\nadopts multi-objective strategy, objectives of this method is to improve the performances of imbalanced\nclassification and to guarantee the maximum integrity of the original dataset. We examined our proposed method,\nthe Binary PSO instance selection by comparing its performance of processing imbalanced dataset with several other\nconventional basic ensemble methods. Experiments are also conducted with Binary PSO instance selection\nwrapping with ensemble classifiers for further improvement of imbalanced classification. Based on comaprison\nexperiments, our proposed methods outperform single ensemble methods, state-of-the-art under-sampling methods\nas well as their combinations with traditional PSO instance selection algorithm.", "sections": [{"title": "1. Introduction", "content": "Classification is a main task in data mining and machine learning. Classification algorithms build classification\nmodels through training datasets, where models are used for prediction of unknown class samples. Nowadays, many\nclassifiers could obtain significant results of classifying balanced distributed datasets. However, there are many\ndatasets in real life that are imbalanced, which conventional classifiers might not be able to provide satisfactory\nperformance on imbalanced classifications. Essentially, in imbalanced datasets, the quantity of samples from some\nclasses is far more than others, these type of classes are usually called majority class, and the alternative is minority\nclass. For research purposes, the minority classes are usually the ones that we are interested in, and binary class\nimbalanced datasets are the most commonly processed type of imbalanced classification. For example, satellite\nradar position [22], telecom customer problem [13], fraud cases [16], network intrusion [31] and detection of\nbiological datasets [38], the interesting class has only very few samples.\n\nThe reason why conventional classifiers might not be suitable for imbalanced classifications is that most\nclassifiers assume the classified dataset is balanced to seek the maximum accuracy of classification model. However,\nthe prediction effect of minority class is poor since minority class is scarce. For instance, in a binary class dataset,\nthe minority class samples accounts for 1% of the total and the rest samples belong to majority class, in the process\nof classification, classifiers are commonly biased towards majority class and they neglect minority class, the\naccuracy of this training classification model can be as high as 99%. Yet this classification model is useless for"}, {"title": null, "content": "identifying and predicting our interested minority class samples. This phenomenon presents a based problem of\nimbalanced classification, and this high accuracy is called high pseudo-accuracy [34]. Therefore, the robustness of\nimbalanced classification model for the meaningful minority class samples is very low, which can be reflected by\nsome metrics, like Kappa statistics, G-mean, BER, etc.\n\nIn this paper, we propose a new evolutional under-sampling method called Binary PSO Instance selection, and\ncombine it with ensemble methods to solve imbalanced classification problems. Under-sampling technique reduces\nthe number of majority class samples to diminish the imbalanced ratio of the original dataset and improve\nperformance of imbalanced classification. If there are N samples of majority class, then there are 2^N combinations to\nstructure the candidate solutions. Moreover, under-sampling method needs to consider both the length and elements\nof these candidate solutions. That means the computational cost is big. In addition, ensemble methods could slightly\nchange the tendency of conventional classifiers therefore promoting the performance of the classification model.\nThat depends on the effect of ensemble methods influenced by the parameter setting and the highly imbalanced\ndistribution of the original dataset. Instance selection is necessary for removing some possible gibberish in original\ndataset in order to improve the performance of the classification model and diminish the imbalanced ratio. However,\nwe also need to respect the original data in data science, in order to reflect the objective results. Thereby, Binary\nPSO Instance selection is designed to increase the performance of imbalanced classification and ensure the\nmaximum integrity of the original dataset, simultaneously. It was implemented through controlling multi-objective.\nFurthermore, ensemble methods could improve the imbalanced classification without changing the original dataset.\nHence, finally, wrapping Binary PSO Instance selection with ensemble classifiers is a useful method capable of\nforming a higher performance of classification model while obtaining a most integral dataset possible along the\nprocess.\n\nThe paper is organized as follows. Section 2 reviews the previous methods that are used to solve imbalanced\nclassification problems. In Section 3, details and process of the proposed method solving imbalanced dataset is\ndescribed. Section 4 contains the benchmark dataset description, experimental procedure and result analysis. Section\n5 summarizes this paper."}, {"title": "2. Related works", "content": "Imbalanced classification problem is a popular topic in the in data mining, machine learning and pattern recognition\nfields. There are many leading conferences held special workshop for discussion and studying for this problem, like\nin ACM SIGKDD 2004[6], AAAI 2000 [21], ICML 2003 [44][10], etc. Present days, the researches for solving\nimbalanced classification can be roughly recognized as two categories: data level and algorithm level. Previous\nresearcher proposed that there are four main factors for tackling imbalanced classification problems, they are:\ntraining set size, class priors, cost of errors in different classes and placement of decision boundaries [5]. The data\nlevel aims to reduce the imbalanced ratio of imbalanced classification model by adjusting the distribution of samples\nin dataset. Another level of the algorithm makes the classifier more inclined towards the minority class through\nmodifying conventional classifier.\n\nFrom the design of most conventional classifiers, previous researchers found that the performance of balanced\ndataset is better than that of imbalanced classification [12]. Therefore, people proposed many methods for\nrebalancing the imbalanced dataset, in order to change the distribution of samples and rebalance the imbalanced\ndataset. Over-sampling and down-sampling respectively increase the number of minority class samples and decrease\nthe number of majority class samples. Random over-sampling means randomly repeat minority class samples to\nincrease the number of minority class samples, but this method will easily cause over-fitting [7]. Chawla proposed\nsynthetic minority over-sampling technique (SMOTE), which is the most widely and effectively used over-sampling\nmethod, it synthetics new minority samples through learning from several neighbors in the same class of each\nminority class sample, in order to generate minority samples and rebalance the imbalanced dataset. Although over-\nsampling technique is able to reduce the imbalanced ratio, the original minority class samples may be diluted by a\nlarge amount of synthetic samples. Down-sampling discards a part of majority class samples to rebalance the dataset"}, {"title": null, "content": "[40]. Random down-sampling could cause the loss of some valuable and characteristic samples. Balance Cascade\n[29] is a classical under-sampling method. Through iteration strategy, it removes the useless majority class samples\nstep by step.\n\nThe algorithm level contains two main approaches to improve imbalanced classification, cost-sensitive learning\nand ensemble learning. In the classification process, they make the base classifiers favor more the minority class\nsamples than majority class ones through assigning different weights or voting or iteration.\n\nAs we know, in most cases, minority class samples are our targets to explore and study. Therefore, it is more\nvaluable to correctly identify the minority class samples than the majority class samples. In other words, it would\ncost more for misclassifying minority class samples. Hence, it is the basic idea of cost-sensitive learning [11],\nwhich assigns different costs of misclassified classes. For example, in binary class imbalanced dataset, assuming\nnegative is the minority class and the cost of misclassified minority class samples is higher. Therefore, in the\ntraining of classifier, the classifier will be forced to have a higher recognition rate for negative class samples since\nthere will be greater punishment for misclassified negative class. The paper will mention confusion matrix and the\ncost matrix in the following section and give an example to introduce how the cost-sensitive learning is achieved to\nchange the tendency of classifiers.\n\nThe basic idea behind the ensemble learning is that the algorithm will get a number of base classifiers from the\ntraining set, and then it uses some ensemble techniques to integrate them to improve the performance of\nclassification. Bagging [39], boosting [18], random forest [8] are the most commonly used methods. Bagging\nimproves the performance of classification through the vote of several single classifiers, which classifies the re-\nsampled (with replay) datasets from the original dataset. Its final results are combined by each sample which gets the\nmost votes. Boosting methods are the most popular ensemble methods, its implementation is a process of iteration.\nAdaptive Boosting (AdaBoosting) is the representative in the family of boosting methods [41]. It adaptively changes\nthe distribution of the training sample by assigning different and vibrational weights to each sample in iteration. We\nwill introduce this algorithms in the next section in detail.\n\nAdaBoosting and cost-sensitive learning were combined by some researchers to build AdaCost [15] series\nalgorithms, AdaC1, AdaC2, and AdaC3 [42]. This kind of algorithm absorbs the benefits of Adaboosting and cost-\nsensitive learning. Moreover, SMOTEBoost algorithm [9] combines SMOTE method with boost method further\nimproves the performance of imbalanced classification. It uses SMOTE to synthetic minority class samples in the\niteration of AdaBoosting, in order to make the sub-classifiers pay more attention to minority class samples. The\nSupport Vector Machines (SVM) [3] and feature selection [4] are also helpful for tackling class imbalance problem.\nMoreover, people also adopted some evolutionary algorithms to tackle imbalanced problem previously [20]."}, {"title": "3. Methodology", "content": "In this section, we will describe the proposed new ensemble under-sampling method. Ensemble and Under-\nsampling are effective techniques for tackling imbalanced dataset classification problem, which commonly denotes\nthe quantitative imbalance of a binary class dataset where minority class is the target class. Here, we propose a new\nensemble method which combines the benefits of both ensemble methods for biasing classifiers and a new\nevolutional under-sampling method. Therefore, the \u201censemble\u201d has two meanings in our paper, the first meaning is\nthe ensemble techniques, like bagging, boosting and stacking; the second implication is the proposed method binds\nprevious ensemble techniques and undersampling techniques. The under-sampling method is named Binary PSO\ninstance selection, it gathers with ensemble classifiers to find the most suitable length and combination of majority\nclass samples to build a new dataset with minority class samples. The proposed method adopts multi-objective\nstrategy, which simultaneously improves the performances of imbalanced classification and guarantees the\nmaximum integrity of the original dataset. We examine the effect of Binary PSO instance selection by comparing\nthe performance of processing imbalanced dataset with several other conventional basic ensemble methods. In the"}, {"title": null, "content": "next step, Binary PSO instance selection is wrapped with ensemble classifiers for further tackling imbalanced\nclassification."}, {"title": "3.1 Particle Swarm Optimization", "content": "Particle Swarm Optimization (PSO) [24] [45] is a widely used meta-heuristic algorithm which imitates the feeding\nprocess of birds. It has the advantages of easy implementation, faster convergence and fewer parameters. Moreover,\nsince the simple requirement of the objective function and constraint conditions, it offers new solution and approach\nto solve non-linear and NP hard problems in different fields [35] [1]."}, {"title": null, "content": "Above-mentioned pseudo code describe the process of PSO. Assuming there is a population X = (X_1, X_2, ..., X_n)\nwhich is grouped by n particles in D dimension search space, the i^{th} particle in this space is expressed as a vector X\nwith d dimension, X_i = (X_{i1}, X_{i2}, ..., X_{id}), and the position of the i^{th} particle in the search space represents a potential\nsolution. As the objective function, the program can calculate the corresponding fitness of position X_i of each\nparticle, where the speed of the i^{th} particle is V_i = (V_{i1}, V_{i2}, ..., V_{id})^T, the extremum value of each agent is P_i = (P_{i1},\nP_{i2}, ..., P_{id})^T and the extremum of the population is P_g = (P_{g1}, P_{g2}, ..., P_{gd})^T. In the process of iteration, the extremum\nvalue of each agent and the population will update their position and speed. Equations (2) and (3) show the\nmathematical process as follows:\n\n$V_{id}^{k+1} = \\omega V_{id}^{k} + c_1 r_1 (P_{id}^{k} - X_{id}^{k})+c_2 r_2 (P_{gd}^{k} - X_{id}^{k}), \\qquad(2)$\n\n$X_{id}^{k+1} = X_{id}^{k} + V_{id}^{k+1}.\\qquad(3)$\n\nIn the Equation (2), \u03c9 is inertia weight and a nonnegative number; d = 1, 2, ..., D; i = 1, 2, ..., n; k is the current\niteration time; c_1 and c_2 are non-negative constants as the velocity factor, r_1 and r_2 are random values between 0 to 1\nand V_{id} is the particle speed."}, {"title": "3.2. Binary Particle Swarm Optimization Instance selection for Multi-objective problem.", "content": ""}, {"title": "3.2.1. Swarm Instance Selection.", "content": "As we know, under-sampling for majority class is a useful method to solve imbalanced data classification problem.\nFurthermore, it is generally known that in the process of data collection, bad or error samples in a dataset are\ninevitable. Consequently, data cleaning of instance selection is essential. Swarm Instance selection for majority class\nsamples is a kind of under-sampling method. There are non-linear relationships between different groupings of\nmajority class and minority class samples, and Swarm instance selection adopts wrapper strategy to find the best\ncombinations of majority class and minority class with the best classification results. Wrapper approach [32] is a\ncommonly used method in evolutional computation [25] [14]. It uses the selected solution to directly train the\nmachine learning algorithm and evaluate the performance of the selected solution through testing the corresponding\nmachine learning algorithm. Therefore, the effect of the wrapper approach is affected by the chosen machine\nlearning algorithm. Wrapping swarm intelligence algorithms and machine learning algorithms (classifier) are able to\nobtain a significant solution.\n\nFigure 2 presents the concept of swarm instance selection for majority class to tackle the imbalanced\nclassification problem. As mentioned above, if the number of majority class is N, there are 2^N candidate solutions.\nThat means it is an N-P problem and brute-force is not achievable. Therefore, we choose swarm intelligence\nalgorithms to search the optimal solution. The original imbalanced dataset is divided into two parts, one is minority\nclass samples and the other is majority class samples for selection. For each particle we get a sub-majority class set,\nwhich will be gathered with original minority class samples to build a new dataset, then the classification\nperformances of these new datasets will be tested. The population will move towards the global optimal, which is\nthe combination of selected majority class samples and original minority class samples with maximum performance\nfrom the wrapped machine learning algorithm."}, {"title": "3.2.2. Binary Particle Swarm Optimization Instance Selection", "content": "The concept of Binary Particle Swarm Optimization (BPSO) was proposed by Kenny and Eberhart [23], it is used to\ndiscretely handle discrete binary optimization problems. Based on PSO, the movement track and velocity of each\nparticle are defined by probability, which is the probability of 0 or 1 in each particle's position and velocity in the\nprocess of iteration. They used new Equation (3) to replace Equation (2):\n\nX_{id}^{k+1} =\\begin{cases}\n1, & \\text{rand()} \\le S(V_{id}^k) \\\\\n0, & \\text{otherwise}\\end{cases}\\qquad(4)\n\nrand() is a random number in the open interval of 0 and1.  S(V_{id}^k) is a sigmoid function:\n\nS(V_{id}^{k+1}) = \\frac{1}{1+\\exp(-V_{id}^{k+1})}.\\qquad(5)\n\nThere is no doubt that swarm instance selection is a typical discrete binary optimization method. With traditional\nswarm instance selection approaches, one needs to consider both the length and elements of a selected majority class\nset simultaneously. While our proposed BPSO integrates these two parts through coding for particles. In this paper,\nthe proposed BPSO inherited the idea of above method from Kenny and Eberhart [23] that the position of each\nparticle can be given in binary form (0 or 1)., However, the new proposed BPSO in this paper introduces the\ninstance selection process into a binary optimization problem. The numbers of majority class instances stand for the\ndimensions. This means that in our BPSO instance selection, the position of each individual particle can be given\nin binary form (0 or 1), which adequately reflects the straightforward 'yes/no' choice of whether a majority class\nsample should be selected. The scope of a position is from -0.5 to 1.5. Then, Equation (6) is used to calculate the\nbinary value of the position [27]. It uses round function to simplify original BPSO.\n\nX_{id}^{k+1}= \\begin{cases}\nround(X_{id}^k)=1 & 0.5<X_{id}^k <1.5 \\\\\nround(X_{id}^k)=0 & -0.5<X_{id}^k <0.5\\end{cases}\\qquad(6)"}, {"title": null, "content": "Where the round() function calculates the binary value X_{id}^{k+1}of the corresponding position to achieve the binary\noptimisation operation. Based on original PSO, Equation (6) is the follow set of Equation (3), however, both the\nposition and velocity are a 1\u00d7N matrix, N is the number of majority class."}, {"title": "3.2.3. Multi-objective problem.", "content": "As mentioned, because of the imbalanced distribution of classes in imbalanced dataset, accuracy lost its\neffectiveness for evaluating imbalanced classification model. If the wrapper approach adopts accuracy as the fitness\nfunction, the high pseudo-accuracy from base learner will not be able to truly reflect the result of classification\nmodel to swarm. The binary confusion matrix [34] offers basic elements for calculating all metrics of classification\nmodel. Assuming negative class (N) is minority class, since the quantity of negative class samples is of low\nproportion in the dataset, the classifier would highly likely misclassify most, if not all of them into the wrong classes.\nThat means if we use an all-negative class dataset as a testing dataset, the credibility of the trained classification\nmodel will be extremely low, because the classifier is under-trained with the minority class data. Therefore even the\nclassification result presents a high accuracy of the model, it will all be meaningless when it comes to classifying\nimbalanced datasets. Equation (7) presents the mathematical formula to calculate a newly defined accuracy of\nclassification model.\n\n$Accuracy = \\frac{True Positive + True Negative}{P + N}\\qquad(7)$\n\n$Sensitivity = TPR = \\frac{True Positive}{P}\\qquad(8)$\n\n$Specificity = TNR = \\frac{True Negative}{N}\\qquad(9)$\n\nSensitivity and Specificity respectively corresponding to the true positive rate and true negative rate. Assuming\nnegative class (N) is minority class. True positive means majority class samples are correctly identified as majority\nclass and true negative means minority class samples are correctly identified as minority class. Sensitivity and\nSpecificity respectively refers to the test's ability to correctly detect the samples in majority class and minority class,\nthey can be expressed as Equation (8) and (9). In other words, Sensitivity is high and specificity is very low in\nconventional imbalanced classification. However, Sensitivity and Specificity justly reflect the correctness of the\nclassifications for both class samples. So we use the product of Sensitivity and Specificity as our first objective and\nfitness function in the search process of particles, in order to pursue the high results of Sensitivity and Specificity,\nsynchronously. Figure 4, an imbalanced dataset is used as an example and it used random under-sampling methods\nwith different under-sampling rate of majority class samples to demonstrate the Snapshot of fluctuating values of\nTPR, TNP, TPR*TNR, Integrity of Majority class and Imbalanced ratio(min/maj) during random under-sampling\nwith 20 different under-sampling rates. The performance is evaluated based on the mean value of ten times repeated\ntrials of random under-sampling with different sampling rate.\n\nIn addition, although under-sampling could effectively reduce the number of majority class samples, there may\nstill exist some impurity data in majority class. In data science, we have to respect the original dataset with\nmodifying the original dataset structure as little as possible. Hence, integrity of original majority class samples is the\nsecond objective of our proposed method. Integrity is calculated using the amount of selected majority class samples\ndivided by the number of original majority class samples. Therefore, our proposed method is designed to solve dual\nobjectives problems. The final dataset could obtain the highest possible Sensitivity*Specificity with the best\nintegrity of original majority class samples.\n\nThe product of Sensitivity multiply by Specificity and the integrity of majority class are inversely in proportion.\nThe red line and blue line in Figure 4 illustrate this situation. Therefore, there is non-unique global best solution and\nthe suitable solutions are all recorded in a solution set, it is called non-inferior set or Pareto optimal set [36] [26].\nThis set contains the solutions meeting one of these conditions: 1. the solution has better performances for achieving\ndual objectives; 2. the solution could improve one objective and the other one does not degrade too much (1.0e-4).\nThe decision marking of our experiment is to select a solution which produces the best Kappa statistics and\nAccuracy as the final results from the non-inferior set [26]."}, {"title": "3.2.4. Why choose ensemble classifier?", "content": "Ensemble techniques were mentioned in section 2, it is another main approach for solving imbalanced classification.\nEnsemble techniques change the tendency of classifiers to minority class through voting or assigning weights or\niteration. Therefore, ensemble techniques don't need to modify the structure of the original dataset, but they indeed\nimprove the performance of imbalanced classification. Essentially, classifying the same imbalanced dataset,\nensemble classifiers are able to get better results than conventional classifiers. Furthermore, since integrity of\nmajority class samples is one of our objectives, ensemble classifiers could maintain a higher integrity than\nconventional classifier even when performance of imbalanced classification for both types of classifiers are similar.\nThat's why we adopt ensemble classifiers in our wrapper structure with BPSO. The aim of our proposed method is\nto improve the imbalanced classification to best performance possible while maintaining minimum damage for the\noriginal data structure through the improvement of the two main elements of the wrapper approach: searching\nalgorithm and machine learning algorithm.\n\nIn our experiment, decision tree is selected as base learner (classifier), because it has good performance in\nimbalanced classification based on the experience from many other fellow researchers, for example in the special\nworkshop in ICML-KDD 2003 [44] [10]. We respectively combined four commonly used ensemble methods of\ndecision tree with BPSO: Bagging, AdaBoosting, Cost-sensitive and AdaCost."}, {"title": "5. Conclusion", "content": "This paper proposed a new ensemble method to solve imbalanced classification problems. The proposed method\nabsorbs the advantages of under-sample and ensemble learning through wrapping a new BPSO instance selection\nwith ensemble classifiers. BPSOIS is a multi-objective algorithm, it maximally improves the classification\nperformance while minimizes the damage to the integrity of original samples in dataset through constantly and\ntrajectory searching for particles. Furthermore, BPSO transforms the NP hard problem of instance selection into a\nbinary function optimization problem to improve the efficiency and correctness. The first experimental results\nobviously show that, BPSOIS has significantly better performance comparing to the other conventional basic\nensemble methods experimented, while it adopts single classifier as base learner. In addition, the proposed method\noutperformed three state-of-the-art under-sampling methods, validated by experimental results, and the\nperformances of BPSO are also comprehensively better than PSO in whole. The results of second experiment\nillustrate the power and effectiveness of the combination of BPSOIS and ensemble classifiers and the statement in\nSection 3.2.3 is validated. Experiments show that, the ensemble of BPSOIS and Bagging could obtain the best\nresults of all."}]}