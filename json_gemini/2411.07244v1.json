{"title": "A Tutorial on Teaching Data Analytics with Generative AI", "authors": ["Robert L. Bray"], "abstract": "This tutorial addresses the challenge of incorporating large language models (LLMs), such as ChatGPT, in a data analytics class. It details several new in-class and out-of-class teaching techniques enabled by AI. For example, instructors can parallelize instruction by having students interact with different custom-made GPTs to learn different parts of an analysis and then teach each other what they learned from their Als. For another example, instructors can turn problem sets into AI tutoring sessions, whereby a custom-made GPT guides a student through the problems, and the student uploads the chatlog for their homework submission. For a third example, you can assign different labs to each section of your class and have each section create AI assistants to help the other sections work through their labs. This tutorial advocates the programming in the English paradigm, in which students express the desired data transformations in prose and then use AI to generate the corresponding code. Students can wrangle data more effectively by programming in English than by manipulating in Excel. However, some students will program in English better than others, so you will still derive a robust grade distribution (at least with current LLMs).", "sections": [{"title": "Introduction", "content": "I thought my class was set. Over the prior two years, I had made an entirely new analytics course: I wrote a textbook on data science with R for MBA students (Bray 2023) and created a corresponding set of interactive R Markdown slide decks. The class went well in the previous year, and I was planning on coasting for the next few years.\nHow wrong I was. ChatGPT debuted on November 30, 2022, a mere 120 days before my 2023 class was to begin. The terrible implications this AI had for my class dawned on me seven weeks later. I remember the moment the harsh reality set in. I copied the following exercise from my textbook into ChatGPT without further explanation or context:\nExercise 3.43 We will now subject our sample to 10 data filters.\n\u2022 Start with alibaba_long and group_by() order.\n\u2022 filter() the grouped tibble accordingly:\n\u2022 Remove the orders with any() \"FAILURE\" action. For example, you should remove all the order = 87717 observations since this order's 12th action was a \"FAILURE\".\n\u2022 Remove orders without exactly one \"ORDER\" action, one \"SIGNED\" action, and one \"CONSIGN\" action.\n\u2022 Remove orders that have an action before the \"ORDER\" action or after the \"SIGNED\" action. In other words, there should be an \"ORDER\" action at time = 0 and a \"SIGNED\" action at time = 1.\n\u2022 Remove orders that correspond to multiple shipper values.\n\u2022 Remove orders with day_count > 8.\n\u2022 Remove orders with more than 10 or fewer than 5 posted actions.\n\u2022 Remove observations with \"ORDER\" and \"SIGNED\" actions, because their time values are degenerate (mechanically being either 0 or 1).\n\u2022 ungroup() the filtered tibble and <- it into alibaba_long.\n\u2022 alibaba_long should have 102331 rows after this step.\nThis was the most challenging question from my Alibaba lab, which replicates the analysis of Bray (2020). In 2022, around two dozen students visited my office hours to discuss this question. So you can imagine my astonishment when the chatbot produced a correct code solution on its first attempt a fact that's all the more impressive when you consider that alibaba_long is left undefined. I soon discovered that ChatGPT could solve nearly every question in my quizzes, lectures, and labs. Three weeks before students were slated to bid on it, ChatGPT had rendered my class an obsolete farce.\nI despaired, but not for long, as it soon dawned on me that I could teach one of the first-ever classes on coding with ChatGPT. What an opportunity! The first order of business was to rename the class to OPNS451 Data Science with Large Language Models and update the syllabus, which now begins with the following:\nLarge Language Models (LLMs) such as ChatGPT are powerful. To maximize your productivity\u2014and stay relevant you should aim to delegate as much of your workflow to these language engines as possible. This means you should become comfortable processing and analyzing data with a computer language such as R-that LLMs excel at reading and writing. For instance, ChatGPT can answer nearly every question in the R textbook I wrote. Switching to R equips you with the software equivalent of a genie in a bottle, capable of implementing and explaining almost every data transformation. The tool is a great equalizer; an MBA with an LLM can accomplish almost anything that an experienced data scientist can. I believe that MBAs now stand out as the finest data scientists since the critical analytics differentiator has shifted from technical expertise to business insight. MBAs will excel as data analysts because they understand the most meaningful questions to pursue.\nThis class will teach you how to use LLMs to process and analyze data. The only challenge is transitioning from spreadsheets to a language. However, once you master the lingua franca of data science, you will be capable of communicating and collaborating with a machine of immeasurable power.\nThis message struck a chord: in less than three years, my elective MBA class swelled from 21 students in one section to 162 students in three sections. (Besides these elective sections, I have one compulsory section for whom my class is a degree requirement.)\nI proposed to my students that we treat the class as experiment in AI an opportunity to collectively anticipate how analytics education and practice will respond to generative AI. This experiment taught me several techniques for teaching data analytics with AI:\n\u2022 Recast homework assignments as AI tutoring sessions doing so increase student satisfaction, engage-ment, and learning (Section 2.2.2).\n\u2022 Use the programming with English (PIE) method, which uses AI to translate the students' natural language into a computer language. Students won't believe it, but this method makes them more effective with R than with Excel (Section 2.1.2). Further, allowing PIE on formal assessments will not make the grade distribution degenerate (Section 2.1.3).\n\u2022 For graphs, have students program by picture, uploading to ChatGPT a hand-drawn mockup of a plot, and asking the chatbot to create the corresponding ggplot code (Section 2.3.2).\n\u2022 Have students teach the class content to a GPT, and then quiz these chatbots to assess the quality of the students' instruction. For example, I have students train GPTs on logistic regression, and then I pit the students' GPTs against each other, determining which can best answer logistic regression questions (Section 2.3.3).\n\u2022 Have students teach each other by creating AI assistants for other students. Students love designing AI experiences-custom-made GPTs are an excellent creative outlet (Section 2.2.6).\n\u2022 Create a set custom-made GPTs to teach different things to different students, and then have students teach each other what they learned from their Als, say, by recording a video for the rest of the class (Section 2.3.2).\n\u2022 Have students pitch solutions to a custom-made GPT, and then have the chatbot quickly identify the proposals that warrant the class' attention (Section 2.3.2).\n\u2022 Create a GPT obstacle course: load different GPTs on different laptops scattered throughout the class and have students run between the various workstations (Section 2.3.3).\n\u2022 Use AI assistants for quick, in-class demonstrations (Section 2.3.4).\n\u2022 Wrap a GPT around your lecture and students will diligently keep up, as they hate when their chatbot instance falls out of sync.\nThe experiment also taught me a few practical lessons:\n\u2022 Emphasize learning over thinking in homework assignments, as students will outsource the latter to the AI (Section 2.2.5).\n\u2022 Use AI to fill the void in your class left by AI (Section 2.2.5).\n\u2022 Don't make AI assignments overly creative (Section 2.2.8).\n\u2022 Don't overlook the programming language instruction (Section 2.1.4).\n\u2022 Halve homework group sizes, since every student now contributes two voices: their own and their AI's (Section 2.2.9).\n\u2022 Explain that working with AI is a skill that improves with practice (Section 2.2.4).\n\u2022 Do not hire tutors, and by all means do not write a textbook (Section 2.2.7).\nMy final advice is to incorporate AI into your class with confidence. There's such a hunger for AI in the classroom that even failed LLM initiatives will earn you goodwill."}, {"title": "Lessons", "content": "ChatGPT has unlocked a new paradigm for analytics education: programming in English (PIE). Students describe the desired data transformations in words, and ChatGPT translates their descriptions into code. It's surprisingly effective, and MBA students love it. In a 2023 post-class survey, 63% of compulsory and 86% of MBAs reported at least a 5 out of 7 agreement with the statement, \"This class has convinced me that it's better to analyze data with code.\" Since computer languages better complement large language models, business schools should transition from GUI-based tools, such as Excel or SPSS, to text-based approaches, such as R or Python."}, {"title": "The Approach Makes Advanced Topics Accessible", "content": "To illustrate the power of PIE, I asked the students to use ChatGPT to (i) construct a random forest model in R, (ii) identify its most predictive variables, (iii) test whether it provides a better in-sample fit than OLS, and (iv) test whether it provides a better out-of-sample fit than OLS. We accomplished all of this in 45 minutes in the very first class. Most students had no R experience, yet they could still build a random forest model and evaluate its performance using a hold-out sample, all within an hour. I even incorporated missing data in the sample to ensure that the initial random forest run would yield an error message, which students would in turn share with ChatGPT.\nFor another example, ChatGPT enabled my students to create an interactive Shiny dashboard, upload it to the cloud, and make it shareable via URL all within half an hour. Using a package as complex as Shiny in an MBA class would have been inconceivable without ChatGPT."}, {"title": "Students Are More Productive Programming in English Than Mousing in Excel", "content": "In the past, analytics instructors faced a trade-off: R offered more power, while Excel promised simplicity. But now, R is more powerful and more straightforward because students can better leverage large language models if they manipulate their data with a computer language. To illustrate this point, I conducted an experiment. I divided the students into two groups: the first group solved a set of analytics problems with R and ChatGPT and then solved the same problems with Excel and ChatGPT. Conversely, the second group began with Excel and ChatGPT before moving on to R and ChatGPT. I instructed the students to record the number of questions they could correctly answer in 30 minutes with each method. Overall, the students correctly solved more than ten times as many questions with R than with Excel. Unfortunately, I couldn't get a reliable estimate of the Excel + ChatGPT productivity rate because the students soon realized that they could not elicit sensible Excel instructions from ChatGPT and gave up.\nFor a taste of these worthless Excel instructions, consider the following exchange:\nStudent:\nI have a table of data called alibaba_long, with column names order score item brand category sub_category merchant quantity action_num action time facility shipper day_count. Remove all observations that correspond to an order with a \"FAILURE\" action. For example, you should remove all the order = 87717 observations since this order's 12th action was a \"FAILURE\". Use Excel\n\u0391\u0399:\nTo remove all observations that correspond to an order with a \"FAILURE\" action in Excel, follow these steps:\n\u2022 Open your CSV file in Excel.\n\u2022 Click on the top left cell (A1) to select the entire dataset.\n\u2022 Go to the 'Data' tab in the Excel ribbon.\n\u2022 Click on 'Filter' in the 'Sort & Filter' group. This will add filter arrows to the header row of your dataset.\n\u2022 Click on the filter arrow in the 'action' column header.\n\u2022 In the filter dropdown menu, uncheck 'Select All' and then check all options except 'FAILURE'.\n\u2022 Click 'OK' to apply the filter. This will hide all rows with 'FAILURE' in the 'action' column.\n\u2022 To remove these rows completely, select the visible dataset (excluding the header row) by clicking and dragging.\n\u2022 Right-click on the selected dataset and choose 'Delete Row' from the context menu.\n\u2022 Go to the 'Data' tab and click on 'Filter' again to turn off the filter.\n\u2022 Save your modified CSV file.\nNow, your CSV file will not have any observations with an order that has a \u201cFAILURE\" action.\nStudent:\nThat is eliminating all the lines that have that FAILURE flag, but not the orders associated with that flag.\n\u0391\u0399:\nApologies for the confusion. To remove all observations corresponding to an order with a \"FAILURE\" action in Excel, follow these steps:\n\u2022 Open your CSV file in Excel.\n\u2022 Add a new column to the right of the 'order' column (column B).\n\u2022 In cell B2, type the following formula and press Enter: =IF(C2=\"FAILURE\", A2, \"\"). This will mark the orders associated with the\" FAILURE\" action.\n\u2022 Click on the bottom-right corner of cell B2, then drag it down to fill the entire column B with the formula.\n\u2022 Select the entire dataset, including the new column B (click on cell A1, then press Ctrl+Shift+Right Arrow+Down Arrow).\n\u2022 Copy the selected dataset (press Ctrl+C).}\n\u2022 Open a new sheet in Excel.\n\u2022 Right-click on cell Al in the new sheet and choose 'Paste Special'> 'Values' to paste the data without the formulas.\n\u2022 Click on the 'Data' tab in the Excel ribbon.\n\u2022 Click on 'Filter' in the 'Sort & Filter' group to add filter arrows to the header row of your dataset.\n\u2022 Click on the filter arrow in the 'action' column header (column C in the new sheet).\n\u2022 In the filter dropdown menu, uncheck 'Select All' and then check all options except 'FAILURE'.\n\u2022 Click 'OK' to apply the filter. This will hide all rows with 'FAILURE' in the 'action' column.\n\u2022 Click on the filter arrow in the new column B header.\n\u2022 In the filter dropdown menu, uncheck 'Select All', and then check 'Blanks'.\n\u2022 Click 'OK' to apply the filter. This will show only the rows not associated with the \"FAILURE\" action orders.\n\u2022 Select the entire visible dataset (excluding the header row), right-click, and choose \u2018Copy'.\n\u2022 Open a new sheet in Excel and paste the data in cell A1 (right-click, choose 'Paste', or press Ctrl+V).\n\u2022 Delete the extra column B (which was used to mark the orders with \u201cFAILURE\u201d action) by right-clicking on the column header and choosing 'Delete'.\n\u2022 Save your modified CSV file.\nNow, your CSV file will not have any observations corresponding to an order with a \"FAILURE\" action.\nThese mousing instructions are not only tedious, but they are also incorrect, as they retain all rows without a \"FAILURE\" rather than all rows from orders without a \"FAILURE\". The student attempted to explain this to ChatGPT, but the chatbot repeated the error on its second attempt.\nNow contrast the exchange above with the one that follows. For this case, the student replaced \"Use Excel\" with \"Use R\" at the end of the prompt:\nStudent:\nI have a table of data called alibaba_long, with column names order score item brand category sub_category merchant quantity action_num action time facility shipper day_count. Remove all observations that correspond to an order with a \"FAILURE\" action. For example, you should remove all the order = 87717 observations since this order's 12th action was a \"FAILURE\". Use R\n\u0391\u0399:\nTo achieve this, you would need to subset the dataframe to remove the observations that correspond to a \"FAILURE\" action. Here's how you might do that in R using the dplyr package:\nFirstly, install the required package if you haven't already.\ninstall.packages(\"dplyr\")\nThen load the package:\nlibrary (dplyr)\nAssuming \"order\" and \"action\" are two of the columns in your dataframe, you can filter out the \"FAILURE\" actions like so:\nalibaba_long <- alibaba_long %>%\ngroup_by(order) %>%\nfilter(!any(action == \"FAILURE\"))\nThis code groups the data by \"order\", and then removes any groups/orders where any of the \"action\" values are \"FAILURE\".\nIf you want to create a new data frame without modifying the original one, you could do:"}, {"title": "Still Teach the Syntax", "content": "I began my 2024 classes by establishing two facts: (i) students are faster at processing data with R + ChatGPT than with Excel + ChatGPT and (ii) effectively processing data with R + ChatGPT requires learning R. I proved the first claim with the experiments discussed in Section 2.1.2, and I proved the second claim with Figure 1, which illustrates that students who better guide their Als earn higher grades. Taken together, these two points make a compelling case for learning R.\nAnother reason to teach the computer language is that PIE is unsatisfying if students can't follow along. For example, asking students to construct a random forest model in the first class was the least popular AI innovation I introduced in 2023 (see Table 6). When I expressed my dismay over this, one of my top students sent me the following explanation via Slack:\nBtw this is random, but I wanted to share rationale for why me and many other students had a tough time with the random forest experiment at the beginning of the course. We were just starting to get our hands around GPT-lot of nervousness. I didn't even know the difference between 3.5 and 4 really at the time. When we had GPT assist us with simple code in the first few classes it was great because we could read the output and make some sense of it. Analogous to language immersion with simple words. The random forest was scary because few students had any idea what they were actually doing. I don't think random forests are part of the standard DECS we all take. So the code it generated was essentially hieroglyphics. It was nerve-wracking trying to \"debug\" inscrutable code doing something we couldn't explain. The error messages to console were not helping. And they were caused in retrospect by GPT 3.5's poor ability to do such complicated tasks. If we did it now, we'd all know to use GPT-4 and could probably even make sense of the code, but it felt like way too much all at once. I was worried after that experience that the \"prior knowledge\" bar was too high. Quite wrong thankfully! I hope that helps I remember this experiment was a negative outlier last time we polled student experience and wanted to share the anecdotal perspective.\nThis quote convinces me that AI complements R familiarity. In other words, ChatGPT accentuates the gap between a student who knows nothing about a language and one who knows its rudiments, as the former will have the \"nerve-wracking\" experience of debugging what is \"essentially hieroglyphics,\" whereas the latter \"could probably even make sense of the code.\" That said, the PIE paradigm increases the importance of teaching basic computer programming: knowing a bit of R code is more valuable now than five years ago."}, {"title": "Using Github Copilot Could Prevent AI Overreliance", "content": "The results in Section 2.1.3 corroborate the findings of Bastani et al. (2024) that ChatGPT can inhibit learning since\nstudents attempt to use GPT-4 as a \"crutch\" during practice problem sessions, and when successful, performworse on their own. Thus, to maintain long-term productivity, we must be cautious when deploying generative AI to ensure humans continue to learn critical skills.\nSpecifically, Bastani et al. (2024) found that the Turkish high school students they experimented on scored 17% worse on AI-free math exams when they learned the material with ChatGPT.\nBien and Mukherjee (2024) provide a graceful solution to the problem of AI overexposure: instead of a chatbot, give students Github Copilot. The authors explain that\nWhile our approach is similar in spirit to [PIE], we opted for using Copilot rather than ChatGPT because we were concerned that making the class \"open ChatGPT\" would open the Pandora's box too wide-\u2014that students would use ChatGPT not just for generating code but for providing a complete solution to a problem. Github Copilot being embedded in a coding environment makes it less convenient for students to try to get the AI to guide the solution and makes it more likely that students conceive of the AI as a tool for generating code rather than as a tool for reasoning. Our goal was to use AI to obviate the need for discussing code syntax while leaving all other elements of the class intact.\nBien and Mukherjee do not report the AI dependence I found in my class, although their limited AI was powerful enough to\nput students in the driver's seat, allowing them to interact with data guided by their curiosity rather than constrained by a limited set of operations they had been taught. The absence of a prespecified list of operations highlighted for the students the boundless nature of the tool."}, {"title": "Analytics Classes will Require an AI Retrofit", "content": "Students will soon expect your class to grapple with AI. For example, consider the following Slack message from one of my elective MBA students:\nI thought you'd like this one I'm currently in a SQL coding class. I went ahead and finished 2.5 hours of labs in 20 minutes. I've never used SQL before and this is being taught like it's a pre-ChatGPT world; knowing what I now know, it's immeasurably frustrating. I feel like I'm in the film Don't Look Up.\nHowever, many analytics classes have yet to adapt to the new reality. For example, I presented the PIE paradigm at Columbia's Future of Analytics Education workshop in May 2023, and few analytics instructors seemed aware of this approach. For example, one professor at the seminar presented a set of Excel plug-ins he created to enable his students to use higher-level statistical tools, such as k-means clustering, because \"although teaching data analytics really requires teaching coding, teaching coding to MBAs is too heavy a lift.\" To challenge this claim, I demonstrated how to k-means cluster with PIE. I performed a live demo, copying the following prompt into ChatGPT:\nstore_coordinates is a tibble with columns store, long, and lat. Use the k-means clustering function of R to cluster the store values by long, and lat.\nAnd looking through my history, I see that ChatGPT responded with the following:\nTo cluster the `store` values in the `store_coordinates` tibble using the k-means clustering function in R based on the `long` and `lat` columns, you can follow these steps:\n# Load the required library\nlibrary(dplyr)\nlibrary (cluster)\n# Perform k-means clustering\nk <3 # Specify the number of clusters you want\n# Select only the relevant columns for clustering\ncoordinates <- store_coordinates %>% select (long, lat)\n# Perform k-means clustering\nclusters <- kmeans (coordinates, centers = k)\n# Add the cluster labels to the original tibble\nstore_coordinates <- store_coordinates %>%\nmutate (cluster = clusters$cluster)\n# View the resulting tibble\nprint(store_coordinates)\nIn this example, `k` is set to 3, which means the data will be clustered into three groups. You can modify this value to match the desired number of clusters. The resulting `store_coordinates` tibble will have an additional column `cluster` containing the cluster labels assigned by the k-means algorithm.\nNote that in order to run this code, you'll need to have the `dplyr` and `cluster` packages installed in your R environment. If you haven't installed them yet, you can use the following commands:\ninstall.packages(\"dplyr\")\ninstall.packages(\"cluster\")\nMake sure to run these commands before running the code for clustering.\nI then executed this code in R to confirm that it properly clusters the stores. The whole process took around 20 seconds."}, {"title": "Turn Homeworks into AI Tutoring Sessions", "content": "LLMs give rise to a new homework modality: the AI tutoring session. Rather than save a homework as a PDF or a Canvas assignment, you can embed it in an AI assistant that walks students through the assignment, like a tutor. For example, I asked students to collaborate with a custom-made GPT on a set of study questions before each class in 2024. Students would \"submit\" these assignments by sending the grader a link to the chat transcripts. Table 1 establishes the popularity of these AI homework assignments. For example, 62% and 79% of compulsory and elective students rated their agreement with the statement \"I believe that the interactive ChatGPT homeworks were a real strength of the class\" as either six or seven, on a seven-point scale.\nNote, these AI homeworks provide a richer form of tutoring than Cribben and Zeinali (2023) had in mind when they wrote that\nThere are several ways in which ChatGPT can be used in Management Science Education. One example is to use ChatGPT as a virtual tutor, allowing students to ask questions and receive instant feedback. This can be especially helpful for students who are studying online or who do not have access to a tutor.\nCribben and Zeinali referred to basic ChatGPT since they wrote this before users could create custom-made GPTs. However, having students confer with base ChatGPT is less effective than tailor-making a GPT for a specific tutoring session. Creating custom-made GPT assignments enables instructors to control the topics and how they are covered (e.g., the problems, solutions, and notation the AI uses)."}, {"title": "Illustration of AI Homework", "content": "The excerpt below", "assignment.\nStudent": "ncontinue\n\u0391\u0399:\nFirst", "URL": "nlibrary (tidyverse)\ncourt_data <-\nstr_c(\n\"https://www.dropbox.com/scl/fi/pp6zaelks5gfd9lruhidh/\"", "ifDllliccclil\")\nAfter running this, please let me know how it looks or if you encounter any issues, and then we can proceed with the first practice problem!\nQuestion 1\nIn the lab, we used bind_rows() to combine fdate and hdate into a single date column. Use a similar bind_rows() technique to convert this treated_settled tibble": "ntreated_settled <-\ntribble(\n~cid", "this": "ntribble(\n~cid", "treated\",\n2, TRUE, \"treated\",\n3, TRUE, \"treated\",\n4, FALSE, \"treated\",\n5, TRUE, \"treated\",\n1, FALSE, \"settled\",\n2, FALSE, \"settled\"\n3, TRUE, \"settled\",\n4, FALSE, \"settled\",\n5, FALSE, \"settled\"\n)\nPlease try to solve this by using the bind_rows() function along with some data manipulation commands in R. Let me know if you need any hints or guidance!\nStudent": "ntreatedtrib <-\ntreated_settled %>%\nselect (cid", "treated\") %>%\nrename (value = \"treated\")\nsettledtrib <-\ntreated_settled %>%\nselect (cid, settled) %>%\nmutate (name = \"settled\") %>%\nrename (value = \"settled\")\nnewtrib <- bind_rows(treatedtrib, settledtrib)\n\u0391\u0399": "nYou're on the right track! Your approach is correct"}, {"this": "ntribble(\n~cid", "treated\",\n2, TRUE, \"treated\",\n3, TRUE, \"treated\",\n4, FALSE, \"treated\",\n5, TRUE, \"treated\",\n1, FALSE, \"settled\"\n2, FALSE, \"settled\",\n3, TRUE, \"settled\",\n4, FALSE, \"settled\",\n5, FALSE, \"settled\"\n)\nGo ahead and run your script to see if the output matches the expected result. If everything looks good, you're ready to move on to the next question! Let me know if you need any further assistance or if you're ready for the next problem.\nStudent": "nok\n\u0391\u0399:\nLet's move on to the next practice problem.\nQuestion 2\nCreate a tibble with two columns: cid and duration", "days.\nStudent": "nq2tib <-\ncourt_data %>%\nfilter (closed & treated) %>%\ngroup_by(cid) %>%\nmutate (duration = as.integer(max(date)) + 1 as.integer(min (date))) %>%\nungroup %>%\nselect (cid", "ndistinct\nq2tib\n\u0391\u0399": "nYour approach to creating the duration tibble looks mostly correct", "expected": "n1. Date Conversion: The calculation for duration needs to handle the dates properly. Ensure that date is being correctly interpreted as a date object. If date is already in a date format", "Code": "You can simplify your code by using summarise() instead of mutate() when calculating duration since you only need one result per group (cid).\nHere is a revised version of your code:\nq2tib <-\ncourt_data %>%\nfilter (closed & treated) %>%\ngroup_by(cid) %>%\nsummarise(duration = as.integer(max(date) + days (1) - min(date))) %>%\nungroup()\nq2tib\nThis code filters the court_data for cases where both closed and treated are TRUE", "ask!\nStudent": "nwhy is ungroup necessary at the end\n\u0391\u0399:\nThe ungroup() function in R is used after operations that involve grouping data with group_by(). When you group data in dplyr", "necessary": "n1. Performance: Keeping a tibble grouped can slow down subsequent operations that don't need the grouping", "Errors": "If you continue to use the data for further analysis that doesn't require the original grouping", "Safety": "Explicitly ungrouping the data makes your code clearer to others (and to future you)", "script": "nq2tib <-\ncourt_data %>%\nfilter (closed & treated) %>%\ngroup_by(cid) %>%\nsummarise(duration = as.integer(max (date) + days (1) - min(date))) %>%\nungroup()\nHere", "operations.\nStudent": "nok\n\u0391\u0399:\nSure", "problem": "nGreat! If you're ready", "this!\nStudent": "nq2tib %>%\nfilter(percent_rank(duration) >= .95) %>%\nglimpse\n\u0391\u0399:\nYour approach to filtering the cases whose duration falls within the top 5% is mostly correct", "code": "nq3tib <-\nq2tib %>%\nmutate (duration_rank = percent_rank (duration)) %>%\nfilter (duration_rank >= 0.95)\nglimpse (q3tib)\nThis version of the code first adds a new column duration_rank that stores the percentile rank of duration for each case. Then it filters to include only those cases where duration_rank is 0.95 or greater"}, {"ask!\nStudent": "nbut you didn't tell me to add a new column\n\u0391\u0399:\nYou're right", "this": "nq3tib <-\nq2tib %>%\nfilter (percent_rank(duration) >= 0.95)\nglim"}]}