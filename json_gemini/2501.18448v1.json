{"title": "Autonomy and Safety Assurance in the Early Development of Robotics and Autonomous Systems", "authors": ["Dhaminda B. Abeywickrama", "Michael Fisher", "Frederic Wheeler", "Louise Dennis"], "abstract": "This report provides an overview of the workshop titled \"Autonomy and Safety Assurance in the Early Development of Robotics and Autonomous Systems\", hosted by the Centre for Robotic Autonomy in Demanding and Long-Lasting Environments (CRADLE) on September 2, 2024, at The University of Manchester, UK. The event brought together representatives from six regulatory and assurance bodies across diverse sectors to discuss challenges and evidence for ensuring the safety of autonomous and robotic systems, particularly autonomous inspection robots (AIR). The workshop featured six invited talks by the regulatory and assurance bodies. CRADLE aims to make assurance an integral part of engineering reliable, transparent, and trustworthy autonomous systems. Key discussions revolved around three research questions:\n1) Challenges in Assuring Safety for AIR: There are several challenges, such as managing human-robot interactions effectively and the need for transparency and explain-ability so that users can understand AI decision-making. Ensuring testing and verification and validation (V&V) is essential as well as the need for tailored assurance approaches. Furthermore, established benchmarks and standards are essential.\n2) Evidence for Safety Assurance: Heterogeneous V&V methods, including simulations, physical testing, and real-world experiments, are needed to ensure safe operation under diverse conditions. Risk management processes and adherence to industry standards are important. Additionally, there is a need for human oversight and evidence to demonstrate that operators can effectively intervene.\n3) How Assurance Cases need to differ for Autonomous Systems: As AIR operates in environments with dynamic, unpredictable conditions, assurance cases need to em-", "sections": [{"title": "I. INTRODUCTION", "content": "The Cross-Sector Workshop\u00b9, titled \u201cAutonomy and Safety Assurance in the Early Development of Robotics and Autonomous Systems\", took place on 2 September 2024 at The University of Manchester, UK. Hosted by the Centre for Robotic Autonomy in Demanding and Long-Lasting Environments (CRADLE), the event brought together a diverse group of six regulatory and assurance bodies: the Health and Safety Executive (HSE), the Office for Nuclear Regulation (ONR), the Rail Safety and Standards Board (RSSB), the Maritime and Coastguard Agency (MCA), the Environment Agency (EA), and the Civil Aviation Authority (CAA).\nThe CRADLE Prosperity Partnership [2] combines Amentum's extensive industrial experience in applied robotics and autonomous systems across sectors with the University of Manchester's unique expertise in Robotics and AI research, creating an internationally leading, sustainable, collaborative research centre. Within CRADLE, we aim to move assurance from being an afterthought to becoming an integral part of engineering reliable, transparent, and trustworthy autonomous systems that demonstrate the behaviours and evidence that regulators require. This workshop provided an important step in shaping the direction of CRADLE's work, and marked the start of an ongoing series of engagements with regulators, which will continue in the coming years.\nThe workshop began with Michael Fisher, Academic Director of CRADLE, welcoming all invited guests and participants. James Kell and Simon Watson, the Industry and Academic Co-Directors, introduced the CRADLE programme. Louise Dennis, Academic Lead for the Assurance Work Package, provided an overview of assurance activities conducted within CRADLE, while Kayleigh Jackson, Industry Project Manager, moderated the sessions. The two main plenary sessions featured invited talks by six representatives: Nicholas Hall (HSE), Vincent Ganthy (RSSB), Tom Eagleton and Paolo Picca (ONR), Sam Hodder (MCA), Nicholas Bloomfield (EA), and Helen Leadbetter (CAA). Additional regulators in attendance included Mary Marshall (HSE) and Clive Tunley (ONR). After the invited talks, participants joined breakout sessions exploring a range of use case domains being investigated within CRADLE, with a focus on autonomous inspection robots (AIR) for ground, nuclear, underwater, and aerial applications. The breakout sessions were facilitated by Frederic Wheeler (Industry Lead for the Assurance Work Package), Louise Dennis, Michael Fisher, and Harry Newton (Industry Co-Lead for Assurance). The workshop concluded with a summary of key outcomes, and a lab tour led by Paul Baniqued, Academic Project Manager.\nThe rest of this report is organised as follows. Section II provides definitions used in this report and describes the four case studies utilised during the breakout sessions. Section III details the key points addressing the three main research questions, and identifies some areas of common ground across sectors. Finally, Section IV offers concluding remarks and outlines future perspectives."}, {"title": "II. BACKGROUND", "content": "A. Definitions\nAutonomy is defined as \"the capacity of a system to achieve goals while operating independently from external control\" [3]. An autonomous system is \u201cone that makes and executes a decision to achieve a goal without full, direct human control\" [4]. Sheridan and Verplank [5] describe ten levels of automation, with the final level being able to operate without human supervision, which could be construed as fully autonomous. Topcu et al. [6] define assured autonomy as \"understanding and mitigating risks of operating autonomous systems in our society\". These risks can encompass the safety, security, and reliability of an autonomous system. In this workshop, our focus was primarily on safety.\nAssurance involves providing justified confidence that a component, system, or service has the necessary assurance properties [7]. Assurance activities include complying with standards, achieving certification, and performing appropriate verification and validation (V&V) [8]. An assurance case provides a structured argument, supported by evidence, to justify some key property (e.g., safety, security) of a system [7].\nB. Case Studies\nWe now describe the four case studies that were used during the breakout sessions to explore the three research questions (expanded in Section III).\n1) Ground (Rail) Autonomous Inspection Robot Use Case:\nThis scenario involves inspecting landslips and vegetation around railway lines. An unmanned ground vehicle (UGV) such as the Clearpath Husky, equipped with Light Detection and Ranging (LiDAR) and cameras, patrols a section of track to monitor any changes in the terrain. The system can autonomously provide early warnings of potential landslips and report on overgrown vegetation that could interfere with railway tracks or obscure geotechnical features. The UGV must avoid obstacles and maintain the required safety distance during navigation at all times. Additionally, it must prevent its battery charge from reaching a critical threshold. If the UGV detects any signs of landslips or vegetation growth, it must report these to the central server. Drone technology can additionally be employed to conduct an aerial inspection of the site and collect mapping data through an onboard sensor package. These identified locations can then be used to guide the deployment of ground inspection. Other inspection scenarios include the inspection of rail integrity and train wagons. For rail integrity, a robot mounted on the rail tracks (e.g., RIIS005 railway inspection robot) can perform inspections to ensure their integrity. It can track the geometry of the rails, monitor the rail profile, measure wear, assess clearances, and detect defects in fasteners or on the rail surface. For train wagons, a robot dog (e.g., ANYmal) equipped with high-resolution cameras and sensors can detect minor cracks and signs of wear on the wheel axles.\n2) Nuclear Autonomous Inspection Robot Use Case: The mission here involves performing regular inspections in a space containing radioactive material, with the primary objective of capturing high-quality images for analysis and assessment. A study of risk mitigation strategies has identified an autonomous ground robot as a suitable solution, effectively balancing mission effectiveness with safety considerations [9]. An AgileX Scout Mini is used for this mission, which is a commercial robot that includes a 4WD mobile chassis and a Robot Operating System (ROS) development kit. It is equipped with high-performance industrial control, high-precision LiDAR, and multiple sensors based on the AgileX Robot ROS ecosystem. These features enable it to perform various functions, such as mobile robot motion control, communication, navigation, and map building [10]. The system architecture integrates a traditional control system developed"}, {"title": "III. RESEARCH QUESTIONS", "content": "Before the workshop, we targetted three research questions.\n1) RQ1: What challenges do you foresee in assuring the safety of an 'autonomous' robot (e.g., an autonomous inspection robot)?\n2) RQ2: What types of evidence do you expect to see in an assurance case supporting the safety claims of an 'autonomous' robot (e.g., an autonomous inspection robot)?\n3) RQ3: Should an assurance case for an 'autonomous' robot (e.g., an autonomous inspection robot) differ from traditional safety cases for human-operated systems? If so, how?\nThe six invited talks focused on the first two research questions, while the breakout session discussed all three.\nTo maintain the anonymity of the regulatory and assurance bodies, we have organised the participants' responses to the three research questions according to the CRADLE project's work packages referred to as 'themes' throughout this report: Components, Architectures, Interactions, Assurance, and Demonstrators [2]. The Components theme focuses on improving the reliability of subsystems to ensure mission success in resilient robotic autonomy [2]. The Architectures theme focuses on designing resilient and verifiable software architectures to enable the reliable deployment of autonomous robots in demanding and long-lasting scenarios [2]. Meanwhile, the Interactions theme addresses challenges in human-robot interactions, aiming to foster trustworthy and effective teamwork [2]. The Assurance theme is dedicated to generating stronger evidence and arguments to support the ethical, safe, and secure design and implementation of robotics and autonomous systems [2]. Finally, the Demonstrators theme showcases next-generation solutions across a range of cyber-physical environments, paving the way for the real-world deployment of robotic platforms [2].\nKey insights on RQ1-RQ3 are detailed in subsections IIIA-IIIC, while subsection IIID highlights areas of common ground for each research question across sectors.\nA. RQ1: Key Challenges for Assured Autonomy\nThe safety assurance of AIR can present numerous chal-"}, {"title": "IV. CONCLUSION AND OUTLOOK", "content": "This workshop offered a valuable opportunity for representatives from industry, academia, and regulatory bodies to come together and discuss challenges of assured autonomy. Feedback from participants indicated a strong willingness to adopt a design-for-assurance process to ensure that robots are developed and verified to meet regulatory expectations.\nAs discussed, assuring AIR presents significant challenges due to their inherent complexity, the unpredictability of emergent behaviours, and the uncertainties inherent in their operating environment. Traditional methods of V&V are often inadequate for systems that learn and adapt, underscoring the need for innovative approaches. Concurrently, regulatory frameworks face increasing pressure to evolve and address these unique challenges. In this context, structured frameworks or templates can offer a practical approach to standardising the development of assurance cases across industries.\nA reference assurance case serves as a template or exemplar, encompassing a repository of accepted practices, logical arguments, and evidential standards [1]. These templates can be tailored to specific projects or systems, providing multiple benefits: reducing the time required to develop new assurance cases, improving quality through broad coverage of critical areas, and streamlining regulatory approvals [1]. Furthermore, reference cases can bridge the gap between innovative capabilities and evolving regulatory requirements. They could foster alignment among key stakeholders\u2014engineers and regulators. By integrating emerging good practices [13], such as modular system designs, these frameworks could establish a baseline for navigating the complexities of assuring AIR.\nAt CRADLE, we aim to build upon this foundation through the concept of reusable assurance patterns [1]. Inspired by design patterns, these assurance patterns enable the reuse of safety argument structures. By adopting a corroborative assurance approach [14] and leveraging mission specification patterns, our research seeks to address the complex V&V requirements of instantiated assurance cases for AIR, taking a step toward addressing the challenges posed by autonomy [1]."}]}