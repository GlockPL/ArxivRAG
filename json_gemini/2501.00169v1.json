{"title": "DeepLL: Considering Linear Logic for the Analysis of Deep Learning Experiments", "authors": ["Nick Papoulias"], "abstract": "Deep Learning experiments have critical requirements regarding the careful handling of their datasets as well as the efficient and correct usage of APIs that interact with hardware accelerators. On the one hand, software mistakes during data handling can contaminate experiments and lead to incorrect results. On the other hand, poorly coded APIs that interact with the hardware can lead to sub-optimal usage and untrustworthy conclusions. In this work we investigate the use of Linear Logic for the analysis of Deep Learning experiments. We show that primitives and operators of Linear Logic can be used to express: (i) an abstract representation of the control flow of an experiment, (ii) a set of available experimental resources, such as API calls to the underlying data-structures and hardware as well as (iii) reasoning rules about the correct consumption of resources during experiments. Our proposed model is not only lightweight but also easy to comprehend having both a symbolic and a visual component. Finally, its artifacts are themselves proofs in Linear Logic that can be readily verified by off-the-shelf reasoners.", "sections": [{"title": "1 Introduction", "content": "Deep Learning Requirements\nThe increased usage of Deep Learning [10, 8, 2] experiments in all areas of science and engineering, necessitates the careful study of current experimental practices. This is a pressing concern, especially because most practitioners are domain experts in their respective fields and not software engineers or computer scientists. Moreover, the increased usage of generated code in experiments can introduce problems that are harder to detect.\nIn this work we observe that experimental settings [4, 9] in Deep Learning, have both:\na. Critical data-provenance requirements that mandate the careful handling of datasets during different experimental phases (such as training, validation and testing) and\nb. Strong correctness and efficiency requirements for the usage of modern APIs that interact with hardware accelerators (such as GPUs and TPUs [19])\nOn the one hand, software mistakes during data handling can contaminate experiments and lead to incorrect results. Indeed if data-structures (such as lists, sets, tensors, etc) that are meant to be used in different parts of the experiments are not handled correctly, they can invalidate all metrics relating to accuracy and generalization of a model. Consider for example the crucial separation between training and validation datasets. If data from the validation set is used for training or if data from the training set are leaked into the validation set, then (i) all metrics regarding overfitting\nerroneous usage of a train sample during validation. For example if augmentation [9, 4] operations to enrich the dataset is performed before slicing, then we may not have an exact sample leaked but a variation of it. This variation still contains information that can invalidate our training. Resources wasted from these mistakes are not mere computational but also economic, since a lot of these experiments have runtimes measured in months that require expensive hardware.\nOn the other hand, poorly coded APIs that interact with accelerator hardware can lead to sub-optimal usage (with significant economic cost) but also to incorrect conclusions, if there is no way to verify their correctness. These problems become even more pressing with the increased usage of generated code in experiments (such as code generated by Large Language Models [1, 15]) that can suffer from subtle bugs, version mismatches and hallucinations [14] that are harder to detect."}, {"title": "Linear Logic Reasoning", "content": "Inference rules in sequent calculus\nThe inference rules for left (1) or right (r) introduction of multiplicative conjunction (resource-and), can be expressed as follows:\n\u2022\n$\n\\Pi\\\\\nM, A, B \\vdash \\gamma\\\\\nM, A \\otimes B \\vdash \\gamma\n$\n1\n\u2022\n$\n\\Pi\\\\\nM_1 \\vdash A \\quad M_2 \\vdash B\\\\\nM_1, M_2 \\vdash A \\otimes B\n$\nr\nThe inference rules for introducing linear implication (lolli) :-\n\u2022\n$\n\\Pi\\\\\nM_1 \\vdash A \\quad M_2, B \\vdash \\gamma\\\\\nM_1, M_2, A \\multimap B \\vdash \\gamma\n$\n-\\circ\nThe inference rules for additive conjunction (choice / fork) &, can be expressed as:\n\u2022\n$\n\\Pi\\\\\nM, B \\vdash \\gamma\\\\\nM, A\\&B \\vdash \\gamma\n$\n&l_A\n\u2022\n$\n\\Pi\\\\\nM, A \\vdash \\gamma\\\\\nM, A\\&B \\vdash \\gamma\n$\n&l_B\nFinally, the equivalent of an identity axiom can be expressed as:\n$\n\\Pi\\\\\n\\gamma \\vdash \\gamma\n$\nid\nIn this work, in order to mitigate these issues, we investigate the use of Linear Logic for the analysis of Deep Learning experiments. We show that primitives and operators of Linear Logic [7] can be used to express: (i) an abstract representation of the control flow of an experiment, (ii) a set of available experimental resources, such as API calls to the underlying data-structures and hardware as well as (iii) reasoning rules about the correct consumption of resources during experiments. Equipped with these three components, we can use Linear Logic to statically validate desired properties of experiments. Compared to other methods of static analysis, our proposed model is not only lightweight but it is also easier to comprehend having both a symbolic and a visual component.\nContrary to classical or intuitionistic logic, Linear Logic explicitly models resources by enabling the creation and consumption of ephemeral facts [5, 11]. This application of Linear Logic enables us to precisely express and verify the expected usage pattern of API calls for each experimental phase of interest. Moreover it allows us to automatically verify the correctness of our desired properties, by producing as output Linear Logic proofs that can be verified by off-the-shelf reasoners (such as Celf [17]). This fact in turn limits the size of the software base that needs to be trusted for our verification process."}, {"title": "2 Analyzing Experiments with Linear Logic", "content": "In this Section we present the main intuition behind our verification approach using a simplified example. We then provide our readers with enough background on Linear Logic to understand the underlying structure of proofs involving experimental properties in linear logic.\nFigure 1 shows a common template for Deep Learning experiments involving the training, validation and testing of neural networks. We can distinguish the following parts in this and similar settings:\n\u2022 An #Experimental Environment section, shown in lines 2 to 6 of Figure 1, which define the main experimental entities of interest. These entities form a global state for the experiment. In this simple example, we have included the different dataset slices, such as the training_slice, validation_slice testing_slice as well as the model itself. These are mere definitions at this point and can take many forms (global variables, class or instance members of dedicated classes etc.). Without loss of generality we have restricted ourselves to entities that we discuss as examples in this paper. For reference, the experimental environment typically includes numerous and more involved entities such as devices, loss_functions, optimizers, schedulers, metrics etc.\n\u2022 A #Data Processing section, as shown on lines 8 to 16 of Figure 1, which typically includes the pre-processing steps and slicing of a dataset into the training, validation and testing sets. Here we show example signatures of slicing functions, such load_training_slice which given a dataset, will pre-process and load training samples into the experimental environment. Considering here that in the majority of experimental setups all slices ultimately come from the same dataset, it is imperative to be able to reason about data isolation and potential information leaks between these sets.\n\u2022 A #Model Design & API section, as shown on lines 18 to 26 of Figure 1. This section is responsible for defining the architecture of model, and a series of helper API calls for dealing with said model. In our example we show examples of simple forward passes through models, with two different calls forward_pass and forward_sampling_pass.\n\u2022 An #Experimental Phases section, as shown on lines 29 to 41 of Figure 1. This section contains logic for the different phases of the experiment, such as the training, validation and testing phases. In our example we show a small snippet that is part of the training phase (on lines 31 to 35), that depending on whether the model architecture needs_sampling or not, will call a different API helper function."}, {"title": "2.1 Analysis with propositional Linear Logic", "content": "In the upper right part of Figure 1 we see the possible execution paths of an invocation the training phase (starting on line 29) of our experiment. These possible execution paths starting from training form a directed graph, which we model as a petri net [12, 13], i.e. a directed graph consisting of (a) places (e.g. the execution points e, t, f1, f2 and m in Figure 1), (b) transitions (e.g. $\\pi_1$, $\\pi_2$, $\\pi_3$ and $\\pi_4$) between the aforementioned execution points and (c) tokens (e.g. the black marks seen in places e and m of Figure 1). The choice of petri nets as a graphical representation of the execution graph is not coincidental. Our goal in this first example is to show how both resources and execution flow can be modeled through Linear Logic (i.e. the substructural logic introduced by Jean-Yves Girard [6]), seen in the lower right part of Figure 1. Petri nets, have been formally shown to accurately depict (in a graphical way) simple propositional Linear Logic models [11, 3]. These graphical depictions can indeed help practitioners build a basic intuition while working with Linear Logic models.\nThe execution graph of the training phase proceeds as follows: The environment first invokes the training method, with the current execution point represented by the token starting at e This input token will subsequently cause the firing of the petri net transition $\\pi_1$ This transition has an equivalent expression in propositional Linear Logic (in the bottom right part of Figure 1). We can translate one to the other, if we consider petri net transitions as named logical implications and petri net places as linear logic propositions. For example in the case of transition $\\pi_1$, we get the equivalent logical implication $\\pi_1$, where the places e and t become the linear propositions e and t. The firing of transition $\\pi_1$, consuming the input token in e and producing a new token in t can be represented as a linear implication ($\\multimap$) between the propositions e and t, as follows: $e \\multimap t$. Finally, since this implication is part of a static petri net structure (i.e. that is not consumed), we annotate it with the linear bang (!) operator, signaling that it is a permanent resource which can be re-used: !(e$\\multimap t).\nSubsequently, from (for the petri net transition $\\pi_2$) there are two distinct paths that can be taken (depending on the value of the boolean needs_sampling), leading to either the f1 or f2 states. This transition $\\pi_2$ is predicated on the availability of the m token, which in this case models the availability of the forward pass calls model(x) and model(x,t), respectively. Both alternatives (i.e $\\pi_{2\\alpha}$ and $\\pi_{2\\beta}$) can be modeled in Linear Logic as a single formula, thusly: !(t & m $\\multimap$ f1&f2). Here the linear multiplicative conjunction connective ($\\otimes$) is used, to group the input tokens together in the left part of the implication. Whereas, in the right part of the implication the additive conjunction connective (&) is used, to model the two alternative outputs f1 and f2. From there and only if the needed resources are available and properly consumed, are we able to successfully return back to the environment e, through the $\\pi_3$ and $\\pi_4$ transitions, expressed in Linear Logic as!(f1 $\\multimap$ e) and !(f2 $\\multimap$ e) respectively. Finally, if we define the initial state of the tokens for our petri net as M = e, m and our transitions as the set of linear logic implications \u03a0 = $\\pi_1$, $\\pi_2$, $\\pi_3$, $\\pi_4$, then the sequent: II, M\u251ce, asks if the training phase can successfully return (i.e. as a reachability problem for e), given the available initial resources for each path and model.\nThis first simple modeling example conveys one of the basic intuitions behind our approach. Linear Logic can simultaneously model the control flow of our experiments (see the petri net token starting at linear proposition e in Figure 1) as well as all available resources and their consumption (see the petri net token at proposition m in the same Figure). In fact this is achieved with a small number of logical operators ($\\otimes$, &, $\\multimap$, !) reasoning over all execution paths and resources. As we will later see a more detailed approach requires us to describe this model in predicate rather than propositional Linear Logic, but this basic intuition will remain the same. More precisely our model can be extended with predicates for an execution stack in a way akin to abstract machines and transition systems, while logging the specific paths we are visiting and the resources we consume."}, {"title": "3 Linear Logic in Perspective", "content": "We will now use the example we introduced in Figure 1, to provide a more detailed background on Linear Logic as it relates to our verification approach. Linear Logic can be seen as a formal system describing resource production, consumption and availability [16, 7]. Contrary to classical or intuitionistic logic, Linear Logic explicitly models resources by disallowing structural rules of contraction and weakening [5]. We briefly provide some basic definitions, before proving the reachability sequent: II, M\u2523e that we saw earlier, where: M = e, m represents the initial state of the tokens for our petri net (in Figure 1) with e modeling the control-flow and m the resources of our model. Moreover, \u03a0 = $\\pi_1$, $\\pi_2$, $\\pi_3$, $\\pi_4$ represent our program transitions (modeled as linear logic formulas in the bottom right of Figure 1). It thus follows that the sequent: I\u041f, \u041c\u251ce, asks if the training phase can successfully return, given the available initial resources for each path and each model. This corresponds to a petri-net reachability problem, with e as the target.\nFor the purposes of our application, a fruitful way to describe reasoning in linear logic is as a rewriting process operating over a multiset. In this setting, truths can be thought of as transient resources if they are currently available, and can be consumed. The content of the multiset can be formally represented through a multiplicative conjunction connective ($\\otimes$), grouping the transient resources together. For instance, in order to describe that both A and B hold, we can write A$\\otimes$B. The bang operator ! is used to represent permanent resources stored in the multiset, that persist even"}, {"title": "3.1 Structuring proofs in Linear Logic", "content": "$\n\\frac{\\frac{\\frac{\\frac{\\frac{e \\vdash e}{t,m \\vdash t \\otimes m}id} {\\pi_1, e, m \\vdash t, m}-\\circ 1(\\pi_1)} {\\frac{\\pi_2, \\pi_3, t, m \\vdash e}{\\pi_1, \\pi_2, \\pi_3 \\vdash e, m}} -\\circ 1(\\pi_2)} {\\frac{\\pi_3, f_1 \\vdash e}{\\pi_3, f_1 \\& f_2 \\vdash e } \\&1(f_2)} -\\circ 1(\\pi_3)}\n{\\Pi} {\\pi_1, \\pi_2, \\pi_3 \\in \\Pi}\n$\nIn order to present the inference rules for the subset of Linear Logic (based on CLF [20]) we presented above, we give the following definitions:\n\u2022 Let II be a multiset of permanent linear implications. In our case II will be used to model a program in memory. Here the permanency of the implications naturally represents the permance of statements. We label such linear implications as $\\pi_i$. From our running example from Figure 1 (bottom right corner) we have II = $\\pi_1\\pi_2\\pi_3\\pi_4$ where:\n$\\pi_1$ = !(e$\\multimap$t)\n$\\pi_2$ = !(t$\\otimes$m$\\multimap$ f1&f2)\n$\\pi_3$ = !(f1$\\multimap$ e)\n$\\pi_4$ = !(f2$\\multimap$e)\nAs we previously explained, these correspond to the control-flow and resources of our experiment in the left-side of Figure 1, expressed graphically with the petri-net in the top-right part of the same figure. From now on, we will using II to describe any similar multiset of program statements ($\\pi_i$) expressed as linear implications.\n\u2022 Let M be a multiset of resources, modeling a program's memory state. From our running example in Figure 1 we have: M = e, m. From now on, we will be using M to describe the execution state of a program (Ms) as well as its initial resources (Mp) that are available at runtime."}, {"title": "4 Conclusion & Future Work", "content": "We have shown how and why Deep Learning experiments have critical requirements regarding data provenance and correctness of API calls that interact with hardware accelerators. These requirements can have a significant impact to the validity, efficiency and economics of Deep Learning experiments that nowdays permeate all areas of science and engineering. Indeed software mistakes relating to dataset slicing can contaminate experiments and lead to incorrect results. Moreover incorrect handling of APIs that interact with the hardware can lead to sub-optimal usage and untrustworthy conclusions.\nWith these problems in mind we have investigated the use of Linear Logic for the analysis of Deep Learning experiments. We showed that primitives and operators of Linear Logic can be used to express: (i) an abstract representation of the control flow of an experiment, (ii) a set of available experimental resources, such as API calls to the underlying data-structures and hardware as well as (iii) reasoning rules about the correct consumption of resources during experiments. We further noted that our proposed model is not only lightweight but also easy to comprehend having both a symbolic and a visual component. In terms of future work, we intend to expand upon our current presentation that relied on propositional Linear Logic, to include our full predicate model that covers monitoring of the execution stack and automatic tracing of our proofs."}]}