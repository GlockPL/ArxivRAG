{"title": "Robust Counterfactual Explanations under Model Multiplicity Using Multi-Objective Optimization", "authors": ["Keita Kinjo"], "abstract": "In recent years, explainability in machine learning has gained importance. In this context, counterfactual explanation (CE), which is an explanation method that uses examples, has attracted attention. However, it has been pointed out that CE is not robust when there are multiple machine-learning models. These problems are important when using machine learning to make safe decisions. In this paper, we propose robust CEs that introduce a new viewpoint-Pareto improvement and a method that uses multi-objective optimization to generate it. To evaluate the proposed method, we conducted experiments using both simulated and actual data. The results demonstrate that the proposed method is robust and useful. We believe that this research will contribute to a wide range of research areas, such as explainability in machine learning, decision-making, and action planning based on machine learning.", "sections": [{"title": "1 Introduction", "content": "Artificial intelligence (AI), including machine learning, is used in many domains. However, although many machine-learning methods have high prediction accuracy, they are often considered 'black boxes' because the processes involved are unclear owing to their complex combination of nonlinearities and interactions. Explainable AI or interpretable machine learning has become an important issue in addressing these problems [1,7,18]. Several such methods are available. One such method is white-box machine learning. There are also methods for ensuring the interpretability of black-box machine learning. They examine which variables are important in the overall data and which variables are important in individual data. Among these methods, one is called the counterfactual explanation (CE) [10, 14,27].\nCEs are outputs that indicate that, for a trained supervised machine-learning model, the minimum changes to the original data (explanatory variables) are needed to achieve a particular desired predictive outcome. This clarifies the factors influencing the forecast and improves the explainability of the model. For example, if a person is denied a loan by machine learning owing to a feature, the CE will suggest which features should be changed (e.g., annual income) to be approved for a loan. This method is important because it can provide suggestions for machine learning users regarding the actions they should take.\nCEs are also called algorithmic recourse [14]. It has also been noted that CEs are related to adversarial examples [9,21].\nWhen extracting CEs, the basic condition is to make the original data and generated CEs as close as possible. In addition, various other conditions have been proposed for CEs, such as closeness to the training data/plausibility, actionability (feasibility), sparsity, diversity, and so on [10]. In addition, several extraction methods have been developed depending on the availability of access to the model and the assumptions of the model's functions (linearity, differentiability, etc.) [27].\nHowever, the robustness of CEs has long been problematic [27]. Robustness can be considered in various ways. Jiang et al. classified the robustness of CEs into four categories [12].\n(i) Robustness against model changes [16,21,26]: Robust (unchanged) CEs are extracted when the model changes owing to changes in data.\n(ii) Robustness against model multiplicity [22]: Robust CEs are ex-tracted when there are multiple models with the same accuracy for the same dataset of classification tasks. Specifically, the formulation uses an aggregated model to make predictions and then a subset of models to generate CEs that differ from those predictions.\n(iii) Robustness against noisy executions [23]: Robust CEs are ex-tracted such that, even if their attributes change slightly, the predictions do not change significantly.\n(iv) Robustness against input changes [25]: Robust CEs are extracted under the condition that if the predictions of two similar data points are identical, then the CEs of the data are also similar.\nRegarding (ii), the existence of multiple models with similar accuracy, which is the premise of the problem, is an important issue because it is sometimes observed when comparing a large number of learners using automated machine-learning tools such as Google Cloud AutoML or PyCaret. Furthermore, in such situations, CE is an important task for social applications because it can be used to identify important variables without selecting a model and to ensure safety when making further decisions. For example, it is important to select the most effective CEs when making decisions based on CEs for risky issues such as medical care or issues involving huge costs such as marketing. However, the number of relevant studies is limited [12,17,22].\nPawelczyk et al. [22] conducted a theoretical study on the relationship be-tween several features of CE under model multiplicity. For example, it discusses the cost of CE (the minimum amount of change required to alter the predicted result from the original input data) under model multiplicity and shows that, while the sparse method (which minimizes the L1 or L2 norm of changes to the data) has a lower cost, the data support method (which generates explanations closer to the data distribution) is more robust in handling model multiplicity.\nAdditionally, in the work of Leofante et al. [17], it is defined such that the pre-dicted categories were the same in all models. Specifically, model multiplicity in class classification using a homogeneous feedforward neural network (FFNN) was analyzed using mixed-integer optimization and other methods. Jiang et al. [13] proposed an algorithm for extracting CEs that can be used universally. The CEs in this study correspond to the prediction discrepancies in model mul-tiplicity. Specifically, after generating CEs for each model, the algorithm uses the computational argumentation method to extract CEs that satisfy several requirements such as nonemptiness and majority voting. Although there have been some studies, they have been limited to the analysis of white-box models or classifications [17] or have not proposed general-purpose solutions that could be applied to cases where the target variable is continuous and constraints can be included. In addition, there is little theoretical foundation for a consistent CE in multiple models.\nIn game theory, welfare economics and multi-objective optimization, the con-cept of Pareto efficiency describes a state in which any attempt to improve at least one objective function inevitably worsens at least one other function [20]. Once a state is Pareto efficient, no further Pareto improvements changes that benefit one or more functions without harming others are possible. In other words, a Pareto improvement moves the previous state closer to a Pareto-efficient outcome. However, once this efficiency is reached, no further improve-ments can be made. As will be discussed in more detail below, this idea can be used to define a CE that improves at least one in all models; that is, it improves consistently in all models. This idea is important when choosing safe and un-controversial solutions based on the CE, which is a costly and risky problem in society.\nIn this paper, we propose a robust CE for model multiplicity by introducing a new viewpoint, Pareto improvement, and multi-objective optimization. In addition, we devised a validation index and verified its robustness through the validation of simulated data and its usefulness through the validation of real data. The proposed method has four key features. The first is the use of the concept of Pareto improvement to address the problem of model multiplicity; the second is that it can be used in practice to select safe solutions based on CE for risky problems; the third is that it can be applied not only to class classification but also to continuous target variables, such as in regression, and is sufficiently versatile to allow the free inclusion of constraint conditions; and fourth, by extracting a variety of CEs, it is possible to select a solution according to the user's preference.\nLeofante et al. [17] also defined a CE that was consistent among all models, similar to that in the present study. However, their analysis was limited to white-box models. Another difference is that a consistent CE is defined as a Pareto solution. Jiang et al. [13] extracted and refined CEs from their model and then refined them [13]. However, the method used in this study extracted multiple consistent CEs directly from multiple models. These differences include the flexibility to handle regression, incorporate constraints on CEs, and the possibility of extracting a variety of CEs.\nSimilar studies have used MOO for CEs. They primarily focus on detecting CEs to satisfy multiple conditions (e.g., Validity, Proximity, Sparsity) in the generation of CEs in one model [3]. However, this study focuses on the model multiplicity problem and uses MOO to ensure the robustness of CEs. Therefore, the problem settings, research positioning, and procedures of the proposed methods differ.\nBy introducing the concepts of Pareto improvement and multi-objective op-timization, this research contributes to a wide range of areas, including the study of explainability in machine learning, decision-making, and action plan-ning based on machine learning.\nSection 2 presents the proposed method. Section 3 presents the validation using simulated and real data, and Section 4 provides a discussion."}, {"title": "2 Method", "content": "In the following sections, Section 2.1 describes the problem setup, Section 2.2 explains the multi-objective optimization as a prerequisite for the proposed method, Section 2.3 describes the proposed method, and Section 2.4 explains the evaluation method."}, {"title": "2.1 Problem Setting", "content": "We set up our problem as follows. We have data D, consisting of n pairs of $y_i$ (scalars) and $X_i$ (r-dimensional vectors), where i is an index per sample. Let $Y_i \\in Y \\subseteq R$ and $X_i \\in X \\subseteq R^r$. Y and X are feature spaces.\n$D = \\{(y_i, X_i)\\}_{i=1}^n$\nThere are m machine-learning models $f_{j=1,...,m} : X \\rightarrow Y$ estimated from D, above a certain accuracy. Based on the above, the objective of this study is to obtain the solution $X_{cf}$ to the following problem:\n$X_{cf}^* = \\underset{X_{cf} \\in X}{\\operatorname{argmin}} (loss(y_t, f_1(X_{cf})), loss(y_t, f_2(X_{cf})), ..., loss(y_t, f_m(X_{cf})))$\nsubject to\n$d(X_b, X_{cf}) \\leq C$,\n$g_j(X_{cf}) \\geq 0, j = 1, ..., J,$\n$h_k(X_{cf}) = 0, k = 1, ..., K.$\nwhere $y_t \\in Y$ is a target value, $X_b \\in X$ is a base data to be explained, and $X_{cf}$ is a candidate for counterfactual explanations. loss is the loss function"}, {"title": "2.2 Multi-Objective Optimization", "content": "In this section, we provide a basic explanation of multi-objective optimization and Pareto solutions [6]. We introduce L (l = 1,...,L) objective functions $F_l: E \\rightarrow R$ corresponding to r-dimensional variables $\\theta \\in E$. Let E be a domain and $E \\subseteq R^r$. Let $F : E \\rightarrow R^L$ be the function that summarizes them. We solve the following optimization problem:\n$\\underset{\\theta \\in E}{\\operatorname{min}} F(\\theta)$, where $F(\\theta) = (F_1(\\theta), F_2(\\theta), ..., F_L(\\theta))$.\nConstraints can also be included. The Pareto solution, which is the solution to this problem, refers to a $\\theta^*$ such that there exists no $\\theta$ for which $F(\\theta) < F(\\theta^*)$ and $F(\\theta) \\neq F(\\theta^*)$. This is also called a non-dominated or efficient solution. The condition $F(\\theta) \\leq F(\\theta^*)$ means that $F_l(\\theta) < F_l(\\theta^*)$ for all l. The Pareto solution set $\\Theta^*$ = {$\\theta^*$} is also called the Pareto front in the objective function space.\nThere are many methods for computing Pareto solutions in multi-objective optimization. For example, there are methods that use a weighted sum of multiple objective functions and the $\\epsilon$-constraint method, which optimizes a specific objective function and defines all other functions as constraints. In addition to those that seek a specific optimal solution, there are also those that seek a set of Pareto solutions, as described above [4].\nRecently, several methods have been proposed for computing Pareto solution sets, including evolutionary computation and descent methods. A well-known method that uses evolutionary computation is the fast elitist non-dominated sorting genetic algorithm (NSGA-II) [5,8]. This method identifies a set of so-lutions by iteratively performing ranking, selection, crossover, and mutation operations on a population of candidate solutions. During this process, the crowding distance metric is utilized to ensure a diverse spread of solutions across the Pareto front.\nBecause evolutionary computation is an approximate solution method (heuristic), there is no guarantee that a Pareto solution set can be obtained. Therefore, the output is often a non-dominated, non-inferior solution set among the solution sets obtained in the solution search process. However, methods using evolutionary computation have the advantage of being able to extract"}, {"title": "2.3 Proposed Method", "content": "We describe the procedures proposed in this paper based on this setup.\n1. Split D into training data $D_{train} \\subseteq D$ and test data $D_{test} \\subseteq D$ ($D_{train} \\cap D_{test} = \\emptyset$).\n2. Set up M models in advance. Estimate each model $f_i$ based on $D_{train}$ and calculate the accuracy of prediction using $D_{test}$.\n3. Select m models based on their accuracy.\n4. Derive S solutions $X_{cf,s}^* (s = 1,..., S)$ for m models by multi-objective optimization.\nIn Process 2, M various models were prepared in advance. The MSE was used for accuracy because continuous variables were used for y in this study. In Process 3, sorting was performed based on accuracy, and the top m models were used. Another possible method is to set a threshold value and select models that exceed it. This selection may be a response to the increase in dissimilarity caused by the introduction of a Pareto solution. For Processes 1-3, it is possible to select the top m models from a large number of models using automated machine learning. In Process 4, evolutionary computation is used because the machine-learning function is nonlinear, model-independent, and derives a wide variety of solutions. After Process 4, it is possible to select a solution among the S solutions according to the user's preference or to select the solution closest to all solutions (medoid, close to centroid, etc.) to select a safer solution."}, {"title": "2.4 Evaluation Method", "content": "In this study, we developed evaluation indices. When there were S counterfac-tual explanations (CEs) for a base dataset, we used the average value described below to evaluate the method. When evaluating the method as a whole, we compared the mean values of the CEs for multiple base datasets.\nValidity(Val): This is an evaluation of the closeness of the prediction by CE to the desired value [27]. Specifically, the value of the loss function was used. The smaller this value, the better the CE. However, since $y_t = \\infty$ is set in this study, alternatively, a larger predicted value $y_t = \\infty$ is a good CE.\n$Val_j = \\frac{\\sum_{s=1}^{S} |y_t - f_j(X_{cf,s})|}{S}$\nDissimilarity (Dissim): This indicator is the opposite of proximity. The"}, {"title": "3 Experiment", "content": "In Experiment 1, the robustness of the CE extracted by the proposed method was verified using simulated data; in Experiment 2, it was applied to real data, and its usefulness was discussed."}, {"title": "3.1 Experiment 1: Simulation Data", "content": "Here, we apply this method and other methods to the simulation data for which the true function is known and compare them. A comparison was performed on data with complex nonlinear functions.\nThe four models used are:\nModel 1: Linear regression\nModel 2: Random Forest regression with 100 trees\nModel 3: LightGBM regression with 100 boosting rounds [15]\nModel 4: Multilayer perceptron regression (MLP) with one layer of 100 units and ReLU activation\nwhich are commonly used in machine learning. The following three methods of extracting CEs are compared:\n\u2022 Method 1: Multiple CEs are generated by changing the initial value of each model. Specifically, the following optimization problem is solved using nonlinear optimization (COBYLA) [24] to generate CEs:\n$X_{cf}^* = \\underset{X_{cf} \\in X}{\\operatorname{argmin}} (loss(y_t, f_1(X_{cf})) + \\lambda d(X_b, X_{cf}))$,\nsubject to $d(X_b, X_{cf}) \\leq C$,\n$g_j(X_{cf}) \\geq 0, j = 1, ..., J,$\n$h_k(X_{cf}) = 0, k = 1,..., K.$\nwhere $\\lambda$ is the degree of importance of $d(X_b, X_{cf})$.\n\u2022 Method 2: Multiple CEs are generated by changing the initial values based on a stacking model (multiple regression) using the predictions of the above models. The generation method is the same as described above.\n\u2022 Method 3: Multiple CEs are generated using the proposed multi-objective optimization-based method. Specifically, we compare cases in which the number of models is set to 2, 3, and 4, in descending order of accuracy. For the multi-objective optimization algorithm, we adopt NSGA-II [2], which is a type of evolutionary computation described in Section 2.3. NSGA-II is suitable for this study because it can be applied to complex functions and enables diverse solutions to be obtained by uti-lizing the crowding distance.\nThe model and the results used in the simulations are described below. The model incorporates interactions and nonlinear functions as follows:\n(1) Model with interactions and nonlinearity\n$y_i = \\begin{cases}\n2x_{i,1} - 3x_{i,2} + 0.5x_{i,3} + 1.5x_{i,1}x_{i,2} - 2x_{i,3}x_{i,4} + sin(x_{i,4})x_{i,5} + \\epsilon_i & \\text{if } x_{i,1} > 0 \\\\\n-5 & \\text{if } x_{i,1} \\leq 0\n\\end{cases}$\n(2) Model with interactions and nonlinearity\n$y_i = sin(x_{i,1}x_{i,2}) + sin(x_{i,3}x_{i,4}) + x_{i,5}^2 - 0.5x_{i,1}x_{i,3}^2 + 0.7x_{i,2}x_{i,4}x_{i,5} + \\epsilon_i$\nwhere $x_{i,1}, x_{i,2}, x_{i,3}, x_{i,4}, x_{i,5}$ are uniform random numbers in the range [-10, 10], and $\\epsilon_i$ is a standard normal random variable with a mean of 0 and a variance of 1. The index i = 1,..., 1000 represents a sample. The mean and standard deviation for (1) are 1.733 and 84.931, respectively, whereas those for (2) are 36.262 and 188.296, respectively.\nFirst, the accuracies of the models were compared (Table 1, Table 2). The dataset was randomly split 20 times with a training size of 0.7 and a test size of 0.3. The mean MSEs obtained from these splits are compared below.\nNext, we evaluated these methods (Table 3,Table 4). Specifically, we set $y_t = \\infty$. Twenty CEs were generated for each randomly selected base. Us-ing these multiple CEs, the evaluation metrics described in Section 2.2 were calculated. Finally, the mean values of 50 cases were compared.\nThe parameters were set as $\\lambda = 2$ and C = 3. For the calculation of val, since $y_t = \\infty$, this study simply used the predicted values of y, where higher values indicated better evaluations. Moreover, as val and dissim or plaus tended to increase together, the ratios of their average values, ave val/ave dissim and ave val/ave plaus, were calculated to compare their balance. For Method 3, the"}, {"title": "3.2 Experiment 2: Real Data", "content": "The proposed method is applied to real-world data, where the true model is un-known. This allowed us to investigate the impacts of specific variables, evaluate their usefulness, and examine their potential applications in practical scenarios.\nFollowing is an overview of the data. The purpose of this survey was to investigate the factors influencing academic achievement among Japanese high school students. The survey was conducted in February 2022. The survey was conducted on 500 subjects (males and females aged 15 to 18) throughout Japan. The survey method was an Internet survey, and the sample was collected so that the sex and age ratios matched those of the national census. The specific sur-vey item was academic achievement (deviation value); in Japanese educational assessments, the deviation value is commonly used to standardize scores, sex, age, and intervention (19 types) (See Appendix), using academic achievement as the target variable (V) and other items as features (sex, age, $T_1$,..., $T_{19}$). Below are the descriptive statistics of the data (Table 5).\nThe four models listed in Section 3.1 are used. Based on this setup, we describe the results of our analysis. First, the accuracy of the model is verified (Table 6). Based on these results, we used Model 1, Model 2, and Model 4. Next, we evaluated these methods (Table 7). Specifically, we set $y_t = 8$. For 50 randomly selected base cases, 20 CEs were generated for each case. Using these multiple CEs, the evaluation metrics described in Section 2.2 were calcu-lated. Finally, the mean values of these metrics across 50 cases were compared.\nThe parameters were set to $\\lambda = 2$ and C = 5. In addition, we set the condition that the improvement is negative when the value is 1 and positive when the value is 0 in $T_1$-$T_{19}$. It is important to flexibly incorporate such conditions."}, {"title": "4 Discussion", "content": "In this study, we investigated a robust CE for machine learning, particularly for the problem of model multiplicity, which has become an issue in recent years. Specifically, we introduced the concept of Pareto improvement for a robust CE against model multiplicity and proposed the extraction of a robust CE using MOO. In addition, we propose a robustness index.\nThe experiments were conducted using simulated and real data. In the experiment with simulated data, all of the val was improved, although some of them were low, and it was clear that dissim was low, plaus was low, and FIR was high. The experiments with real data also showed val was improved, although the val were low, and both dissim and plaus were low.\nIn an applied case study, we detected the variables that were important as a whole, checked the Pareto front for one case study, and confirmed that all three models improved the results. The CE selection method is also addressed.\nThe novelty and distinctiveness of this study lie in the following points: (1) It employs the concept of Pareto improvement to tackle issues related to model multiplicity and robustness. (2) Unlike existing CE studies that deal with model multiplicity, this approach allows the target variable to be quantitative and can flexibly incorporate constraints. (3) CE can be applied when selecting safe and effective actions for expensive and risky practical problems. (4) Extracting various CEs enables the selection of solutions that align with user preferences.\nThis study also shows that the concept of Pareto improvement and multi-objective optimization can be applied to a wide range of areas, such as ex-plainability in machine learning, decision-making, and action planning based on machine learning.\nFuture work will include determining which MOO is more optimal [11] and setting the optimization hyperparameters. In addition, different results may be obtained for method1 and method2 if the optimization method is changed. In addition, MOO has the problem of increasing computation time as the number of attributes increases and when comparing different MOO algorithms, including the descent method. Finally, the effects of the obtained CEs were tested by conducting actual intervention experiments.\nAnother potential avenue for future research is to incorporate causality to enhance the model's robustness [10]. Causality is related to the invariant struc-ture of the underlying data, which can ultimately contribute to robustness."}]}