{"title": "Uplifting Lower-Income Data: Strategies for Socioeconomic Perspective Shifts in Vision-Language Models", "authors": ["Joan Nwatu", "Oana Ignat", "Rada Mihalcea"], "abstract": "To address this issue, we formulate translated non-English, geographic, and socioeconomic integrated prompts and evaluate their impact on VL model performance for data from different countries and income groups. Our findings show that geographic and socioeconomic integrated prompts improve VL performance on lower-income data and favor the retrieval of topic appearances commonly found in data from low-income households. From our analyses, we identify and highlight contexts where these strategies yield the most improvements. Our model analysis code is publicly available at Analysis for Uplifting lower-income data.", "sections": [{"title": "Introduction", "content": "The overrepresentation of Western data and lack of diversity are common issues in many popular datasets (Shankar et al., 2017). Even though the size and quality of pre-training datasets greatly impact the performance of today's AI models, there is insufficient research attention given to this area. Furthermore, there is even less attention given to data curation methods that can improve representation in AI datasets (Sambasivan et al., 2021).\nToday, vision-language (VL) models are leveraged to filter uncurated data repositories into training datasets by assessing the association strength between images and text (Fang et al., 2023). For example, Open AI's ViT-B/32 (Radford et al., 2021) was used to filter web-scraped images to create the LAION-5B dataset (Schuhmann et al., 2022). However, many VL models like CLIP have been shown to perform unequally for data from different cultures and socioeconomic classes (Nwatu et al., 2023).\nSince datasets filtered using this technique reflect the VL model used for filtering (Fang et al., 2023), this practice can exacerbate the lack of diversity in Al models and datasets. This is evident in Ignat et al. (2024), which shows that data from the LAION-5B dataset is most similar to data from Western countries, like the United States and Canada, while it is dissimilar to data from many non-Western countries.\nTo mitigate the lack of representation in AI, we address the issue of performance inequality in VL models (Radford et al., 2021; Visheratin, 2023) through prompting that leverages the cultural knowledge embedded in language (Ventura et al., 2023; Buettner et al., 2024; Nguyen et al., 2024). Our goal is to improve the performance of VL models on the diverse representations of topic labels especially found in data from households with non-Western and lower socioeconomic status. Specifically, we pose several research questions to evaluate the effects of non-English languages and geographic and socioeconomic attribute-integrated prompts on retrieving diverse images. We focus on identifying which strategies improve performance on lower-income data, while also noting their effects on higher-income data.\nOur contributions are summarized as follows. First, we show that prompts translated to the native language (referred to as the non-English major language) of a country currently do not yield improved Recall performance on images from that country compared to English prompts."}, {"title": "Related Work", "content": "Addressing AI Performance Inequality. Class imbalances in training data contribute greatly to bias propagation in AI models (Ferrara, 2024; Shankar et al., 2017; He and Garcia, 2009; Pouget et al., 2024). This bias manifests in the disparate impact of these models on users in applications such as facial recognition (Buolamwini and Gebru, 2018), healthcare (Obermeyer et al., 2019), and hiring (Raghavan et al., 2020). Since creating balanced diverse datasets is difficult and expensive (Ignat et al., 2024; Ramaswamy et al., 2023), the research community has explored alternative methods of dealing with bias. Some of these methods involve pre-processing and in-processing techniques such as data augmentation, feature importance tuning, regularization, and adversarial training (Yan et al., 2020; Zafar et al., 2017; Ignat et al., 2024; Maudslay et al., 2019; Sharma et al., 2020; Navarro et al., 2024; Zhang et al., 2018). However, our work is most similar to post-processing techniques such as Ferrara (2023); Hardt et al. (2016); Kamiran et al. (2012); Pleiss et al. (2017) that adjust model outcomes using a set of criteria to fit diversity standards across race, gender, and culture for the benefit of disadvantaged groups. Pouget et al. (2024); Nwatu et al. (2023) show that vision-language models consistently perform badly on data from lower socioeconomic status. Our analysis seeks to identify and analyze the effects of non-invasive post-processing techniques that mitigate this issue.\nMultilingual AI Models. Language is often referred to as a vehicle for propagating cultural knowledge and norms (Callies, 2024; Sharifian, 2014; Karsdorp and Fonteyn, 2019; Norton, 1997). This is exemplified in AI research, where models often pick up on biases contained in the language of their training data (Stanczak and Augenstein, 2021; Rogers et al., 2021), and model outputs can be controlled by specifying a cultural shift in perspective (Ventura et al., 2023) to improve diversity.\nFurthermore, Arora et al. (2023); Cao et al. (2023); AlKhamissi et al. (2024); Liu et al. (2021) have shown that while LLMs and vision-language models contain a decent amount of cultural information regarding cultures present in English data (predominantly Western), for cultures contained in non-English language data, not as much cultural information can be extracted. Major reasons for this disparity include differences in the quantity and quality of training data available for these languages compared to English, information loss due to language translation, and model design decisions (Arora et al., 2023; Hershcovich et al., 2022; Nasif et al., 1991).\nSimilar to De Vries et al. (2019) and Nguyen et al. (2024) that demonstrate how language can improve data diversity by retrieving images using translated captions, our work seeks to identify how current multilingual VL models and non-English languages can improve representation in vision-language models and datasets across regions and income groups.\nPrompting AI Models. Prompting techniques for large language models have been extensively studied in recent years. Both hard prompting (Petroni et al., 2019; Zhou et al., 2023) and soft prompting (Huang et al., 2023; Goswami et al., 2023) are useful in adapting models for downstream tasks, instruction tuning, and value alignment. Prompts have also been used in vision-language models for similar purposes (Lu et al., 2022; Yao et al., 2024; Zhou et al., 2022). Most similar to our work, Buettner et al. (2024) incorporates geographic and physical attributes of objects into prompts to improve retrieval of diverse images. However, we extend the investigation to non-English language prompts and socioeconomic attributes and then perform further analysis to highlight insights into how VL models encode representations of different topics across not only regions but also socioeconomic status."}, {"title": "Methodology", "content": "We apply three types of text prompting techniques to a geographically and socio-economically diverse dataset and analyze how these changes affect the performance of a multilingual VL model on data across different socio-economic groups, especially focusing on lower-income data."}, {"title": "Dollar Street Dataset", "content": "We use the Dollar Street (Rojas et al., 2022), which contains 38, 479 images of household items (e.g., \"stoves\", \"cutlery\u201d, \u201ctoothbrush\") spanning a large number of countries and several income levels. The dataset images were sourced from households in 63 countries on four continents (Africa, America, Asia, and Europe). The number of images ranges from 45 in Canada to 4, 704 in India, with a median of 407 images per country. Size and image resolutions vary slightly across data from different regions; however, the mean and median image properties per region are relatively similar.\nIncome Classes. We categorize the images and countries on Dollar Street based on their income information as described below.\nImage Income Classes. Each image is accompanied by the monthly household income value in U.S. dollars, calculated to reflect monthly consumption and adjusted for purchasing power parity to match the variance in cost of living across the different regions. The monthly income values range from 26.9$ to 19, 671.0$.\nFor fair comparison across bins, we group the images using the quartile binning method which splits the data into an approximately equal number of images per bin as shown in Rojas et al. (2022). We group the images into four income classes (\"poor\u201d, \u201clow-mid\u201d, \u201cup-mid\u201d, and \u201crich\u201d ) using quartiles as shown in Table 1. We further categorize the lowest two image income classes as lower-income images and the highest two income groups as higher-income images.\nCountry Income Classes. We group all the 63 countries from Dollar Street into country income classes based on their World Bank income classification. All the countries and their income classes are shown in Appendix A.2. We further categorize the lowest two country income classes as lower-income countries and the highest two income groups as higher-income countries.\nTopic Representations. There are 291 unique topics that reflect common household objects and human actions (e.g., \u201ctoilet paper\u201d, \u201cget water", "next big thing I plan to buy": "favorite sports clubs\u201d, \u201cmost loved item\"). Following De Vries et al. (2019) and Nwatu et al. (2023), we remove nineteen subjective topics from the dataset.\""}, {"title": "Prompt Design", "content": "Default English Topic Prompt. Using the topics, we formulate an English prompt without any modifications (e.g., \u201cThis is a photo of cutlery\u201d), as described in Radford et al. (2021), to which we refer to as the default English prompt. The performance obtained using these prompts is set as our baseline.\nTranslated Topic Prompt. For our multilingual experiments, we investigate the impact of non-English language prompts on the Dollar Street dataset. We use the term non-English major language to refer to the non-English language that is most widely spoken or most commonly used in a particular country or region.\nSpecifically, we pair each country with their non-English major language (e.g., Spanish for Brazil, French for Cameroon) following the country and language information provided by official sources.\nWe identify 59/63 countries in Dollar Street where one or more non-English major languages are spoken. We also select languages covered by state-of-the-art machine translation and multilingual vision-language models. There are 40 such non-English major languages, and they are listed in Appendix A.2.\nFinally, we translate the default English prompts to these 40 languages using the NLLB-200-distilled-600M (Costa-juss\u00e0 et al., 2022), a state-of-the-art neural machine translation model. If an image prompt is translated into the non-English major language of the image's country of origin, it is referred to as a native translated prompt."}, {"title": "State-of-the-art Vision-Language Model", "content": "For our evaluation, we chose NLLB-CLIP-SigLIP (Visheratin, 2023), a state-of-the-art multilingual vision-language model, due to its wide reach across many low-resource languages and superior performance among other models. The model consists of an image encoder from the SigLIP model (Beyer et al., 2022; Zhai et al., 2023) and a text encoder from the NLLB model (Costa-juss\u00e0 et al., 2022). The model supports the 201 languages of the Flores-200 (Costa-juss\u00e0 et al., 2022) and has recorded groundbreaking results on the Crossmodal-3600 dataset (Thapliyal et al., 2022), especially on low-resource languages."}, {"title": "Research Questions", "content": "We perform several analyses to answer three research questions that uncover and mitigate limitations in the performance of VL models across different countries and socioeconomic groups."}, {"title": "Do translated prompts improve performance for lower-income images?", "content": "We calculate the cosine similarities between the NLLB-CLIP-SigLIP image embeddings and the text embeddings of the translated prompts for each image and topic pair and the 40 non-English languages. This process yields 40 image-topic alignment scores for each image across all non-English languages.\nAs a baseline, we compute the alignment scores between the images and the default English prompts. We use the alignment scores to compute the Recall scores for each topic. Specifically, we select the top N images with the highest alignment scores for the given topic, where N represents the number of ground truth images corresponding to that topic. We group and analyze the Recall scores across different countries and image income classes and present our findings below.\nNative translated prompts perform consistently worse than English prompts on lower-income images from their respective countries. We focus our analysis on images from the two lowest image income groups, i.e., poor and low-middle. We filter out countries with no data for these income groups (e.g., Russia, Turkey) and obtain 39/59 countries and 28/40 non-English languages. We pair up each of the remaining countries with the results from their respective non-English native languages and compare the Recall scores obtained using the native translated prompts with those obtained using the default English prompts.\nWe find that native translated prompts consistently perform worse than default English prompts. This is shown in Figure 2, where we compute the average Recall across all countries for English and the native translated prompts. We also show examples from four countries, one from each of the four continents: Africa, America, Asia, and Europe.\nFor 36/39 countries, the native translated prompts yield worse performance compared to default English prompts. The exceptions are Indonesia, where Recall for the Indonesian native translated prompt is 1.0 higher than Recall for the English prompt, and Pakistan, where Recall for the Urdu native translated prompt is 0.7 higher than Recall for the English prompt.\nThe best-performing non-English language is often not the country's language. We analyze the Recall scores for lower-income images from each of the 28 language prompts used in different countries. We observe that the best-performing language prompts for these countries are often not their own non-English major language. Specifically, for 24/39 countries, the best-performing non-English languages have better results than the default English prompts. However, surprisingly, in most cases, these languages are not spoken in these countries. The results are shown in Figure 3, where for 37/39 countries the language with the highest Recall (highlighted in yellow) is different from the non-English major language of the country (highlighted in cyan). The only exceptions are Indonesia and Pakistan, where the highest-performing languages and the non-English major languages are the same (highlighted in bold red).\nTranslated prompts decrease performance for all image income classes across all countries. We analyze the effect of the 40 non-English languages on all images from Dollar Street, regardless of which country the data was collected from. We include all 59 countries and results from all 40 translated prompts for this analysis. We aggregate Recall across all topics and countries for each set of non-English language prompts and group the scores according to image income classes. We measure the difference between Recall scores with default English prompts and the scores with translated prompts to determine the effect of each language on the four different image income classes."}, {"title": "Does adding country information improve performance for lower-income data?", "content": "We calculate cosine similarity scores between the NLLB-CLIP-SigLIP image embeddings and the text embeddings of the 63 country suffix prompts. This results in 63 image-topic alignment scores for each image across all country suffixes. Similar to RQ1, as a baseline, we use the alignment scores between the images and the default English prompts.\nFollowing the same procedure described in Section 4, we calculate the Recall scores for each topic using each of the 63 country suffix prompts. We analyze the effects of adding country suffixes to text prompts and present our findings below.\nCountry-suffix prompts perform consistently better than default English prompts on lower-income images. Given our focus for this analysis on low-income data, we filter out the 21 countries with no images from poor or low-mid income class households and focus on the remaining 42 countries.\nIn Figure 4, we show the average Recall scores across all countries using the default English and country-suffix prompts. We also show Recall scores from four sample countries from different continents. From our results, we find that for most countries (38/42), adding the country suffix to the text prompts improves Recall performance for lower-income images compared to default English prompts. Countries where this does not hold are Bolivia, Brazil, Jordan, and the United States.\nThe country-suffix prompt performance across different image income classes is influenced by the country's economic status. While country suffix prompts improve the performance of vision-language models on lower-income household data (poor), they simultaneously reduce performance on higher-income data.\nWe measure the Recall of all data for each country suffix, group them into image income classes (based on household income), and place them into categories based on the World Bank income classification of that country suffix (e.g., Recall of data from poor households using country suffixes of poor countries is 31.2) For each image income class category, we calculate and show in Table 3 the average Recall of the country suffixes across the different country income levels and the average change in Recall compared to results obtained using the default English prompts. We show an extended table with results for all 63 country suffixes in the Appendix Table 8 and Table 9.\nThe differences in Recall between the country suffixes and default English prompts indicate which income group's data benefits from an increase and vice versa. We find that country suffixes from countries that belong to the poor, low-mid, and up-mid World Bank Income categories lead to an increase in Recall for images with poor household income, as shown in green in Table 3. On the other hand, adding country suffixes to prompts leads to a decrease in Recall for images from the other household income groups (low-mid, up-mid, and rich).\nInterestingly, we observe that country suffixes tend to favor image retrieval from income groups that are the same or close to their World Bank income classification. The default English prompts favor the retrieval of up-mid income level data as the Recall for up-mid images is higher than the Recall for the other 3 income groups. We highlight in bold the average Recall that is highest among other income groups for each country suffix classification in Table 3, and show that poor country suffixes, low-mid country suffixes, and up-mid country suffixes produce the highest Recall scores for data from their corresponding income class. Rich country suffixes are the exception as they produce the highest Recall for data from the up-mid income level as opposed to the rich. We analyze the individual country suffix results and group lower-income images as images belonging to either the poor or lower-middle income group and higher-income images as images belonging to the upper-middle or rich income groups. We then find that 48/63 countries produce the highest Recall for lower-income data and are lower-income countries, or they have the highest Recall for higher-income data and are higher-income countries.\nThe best-performing country suffixes for lower-income data from a continent are from the same continent. We analyze Recall results for lower-income data (from poor and low-mid households) from 42 countries when prompted using each of the 42 country suffixes and group these countries according to their respective continents. We categorize the data further into data from different World Bank Income classes within a continent. Then we display the average Recall and Recall difference (with respect to Recall using default English prompts) of each data group when prompted using country suffixes from different continents. For example, we show that lower-income data from poor African countries have a Recall of 36.6 and a performance increase of 15.7 when prompted using African country suffixes.\nWe find that the best-performing country suffixes for images from a continent are from the same continent, as shown by the diagonal of bold values in Table 4. We also see that lower-income data from African countries benefit most from the addition of country suffixes to prompts, while data from America and Asia do not experience Recall improvements.\nMeanwhile, for higher-income data, there are no Recall improvements even when images and country suffixes belong to the same continent (see Appendix Table 10)."}, {"title": "Does adding income information improve performance for lower-income groups?", "content": "We create three categories of income suffixes, poor, rich, and neutral, as described in Section 3.2. We repeat the image retrieval experiments from previous research questions to determine the Recall for images from each topic. We group and analyze the these results across countries and income groups.\nPoor income suffixes yield the best performance on most lower-income images. We find that the poor income suffix prompt obtains the best performance in 26/42 countries with lower-income images. For 12/42 countries, the default English prompts perform better than all the income suffixes. However, most countries experience Recall improvement from one of the income suffixes. We show the results in Figure 5. The average Recall score is aggregated across all 42 countries for the default English and income suffix prompts. The income suffix poor achieves the best recall.\nImages from the poor income group benefit the most from income suffixes. We group the data into four income groups and further categorize them according to the World Bank income classification of the countries they were obtained. In Table 5, we show the Recall scores and performance increase with respect to the default English prompts for each data group.\nWe find that income suffixes benefit most data from poor households and some from lower-income families, while data from other income groups do not see an increase in Recall. In addition, there is no clear trend between the World Bank's income classification of the country and the effect of income suffixes on Recall for the images. Further details about the income classification by World Bank for each country can be seen in Appendix A.2.\nFinally, an interesting finding is that for higher-income images, i.e., up-mid and rich, all income suffixes, including rich and neutral suffixes, lead to drops in Recall. This means that the default English prompts obtain the best results for higher-income images. This could be due to the high representation of higher-income images in AI models and datasets as the \u201cstandard representation\". Therefore, including additional information, such as socioeconomic status, causes the model to favor the retrieval of lower-income images over higher-income images. This can be seen in the results that achieve Recall improvements on lower-income images while reducing Recall for higher-income images. Such effects could result from these prompts shifting the VL's perspective away from its understanding of the default representation of a topic."}, {"title": "Lessons Learned", "content": "Current multilingual VL models do not contribute significant improvements to diversity and representation. Our results from Section 4 demonstrate that English prompts obtain better performance on lower (and higher) income data compared to prompts translated to a non-English that is widely spoken in the region where the data was collected from. Since the quality of translations, quantity of training data available for these languages, and consequently, the performance of AI models in these languages is lower than that of English, these findings are not very surprising. We can look forward to better non-English language performance as multilingual VL models improve.\nThe addition of extra information to prompts shifts the focus of model inferences from higher-income images. We find that adding geographical and socioeconomic attributes (including neutral attributes) to prompts leads to an increased model preference for lower-income images over higher-income images as demonstrated in Section 4.\nImages with less standard topic appearances are retrieved using income suffix and country suffix prompts. Inspection of the retrieved images reveals that images with topic appearances commonly found in lower-income households previously not retrieved by the default English prompts are being retrieved with these prompts as shown in Figure 1. For example, pit latrines and forest-style toilets previously left out by the default English prompts are retrieved using country suffixes (Burundi and Cameroon) and the poor income suffixes. Another example is \"leaves\" as \u201ctoilet paper\u201d retrieved by Liberia and Cameroon country suffixes but excluded by the default English prompt."}, {"title": "Conclusion", "content": "In this paper, we addressed the uneven performance of VL models across different countries and different income levels. We explored three attribute-integrated prompting strategies: (1) translation of text prompts to native non-English languages, (2) addition of geographic information, and (3) addition of socioeconomic attributes. We found that integrating geographical and socioeconomic information into prompts enhances the performance on data from lower-income households and retrieves more diverse label representations. Furthermore, we identified and highlighted the contexts where the proposed prompting techniques work best and shared our insights to improve representation in vision-language models and datasets. Our code can be used to evaluate the performance of other VL models and datasets and is publicly available at Analysis for Uplifting lower-income data."}, {"title": "Limitations", "content": "Translation Quality We note that, while NLLB-200-distilled-600M is reputed as a SOTA machine translation model, it does not have perfect accuracy on machine translation across all the languages it supports. We acknowledge that the quality of translations obtained from NLLB-200-distilled-600M greatly impacts our results.\nData Coverage Our study is constrained by the reach of the Dollar Street dataset and the number of contributions obtained from each region. therefore we do not account for data from other regions not included in the dataset.\nChoice of Attributes We acknowledge that other attributes (e.g., physical attributes like color and material) of the objects in the images could be integrated into prompts to improve performance. However, we choose to focus on geographic and socioeconomic attributes since they are broad enough to include all possible topic appearances related to that attribute and their impact on data belonging to different countries and income groups can measured directly.\nDiverse Data Availability While our methods facilitate the improvement of diversity during dataset annotation, these strategies cannot overcome the representation issues within the actual pool of images available for annotation."}, {"title": "Ethics Statement", "content": "Through this work, we aim to contribute toward improving diversity in AI models and even out the disparate impact of these models on the public, especially on underrepresented groups. The strategies discussed in our work can be used to prioritize the retrieval of lower-income images for balancing skewed data representation or domain-specific applications in AI. However, we do not encourage the use of these strategies to promote over-representation or inclusion of one group over the other in contexts that affect all members of the general public.\nOur decision to use the NLLB-SigLIP model exemplifies our commitment to using inclusive models that benefit as many people as possible, especially underrepresented groups. While researching technologically advanced communities is easier and less resource-intensive, we stress the importance of making AI design decisions that do not exclude communities with limited access to technology."}]}