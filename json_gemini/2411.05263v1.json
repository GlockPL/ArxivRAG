{"title": "Minimal Conditions for Beneficial Neighbourhood Search and Local Descent", "authors": ["Mark G. Wallace"], "abstract": "This paper investigates what properties a neighbourhood requires to support beneficial local search. We show that neighbourhood locality, and a reduction in cost probability towards the optimum, support a proof that search among neighbours is more likely to find an improving solution in a single search step than blind search. This is the first paper to introduce such a proof. The concepts underlying these properties are illustrated on a satisfiability problem class, and on travelling salesman problems. Secondly, for a given cost target t, we investigate a combination of blind search and local descent termed local blind descent, and present various conditions under which the expected number of steps to reach a cost better than t using local blind descent, is proven to be smaller than with blind search. Experiments indicate that local blind descent, given target cost t, should switch to local descent at a starting cost that reduces as t approaches the optimum.", "sections": [{"title": "Introduction", "content": null}, {"title": "Neighbourhood search and local descent", "content": "There is a wide variety of techniques for tackling large scale combinatorial optimisation problems. Incomplete search methods are typically used to achieve the required scalability. Indeed [Christensen and Oppacher, 2001] write: \u201cMost 'general-purpose' optimization techniques rely on some sort of hill climbing at the lowest level. These techniques include golden section search, Brent's method, the downhill simplex method, direction-set methods, conjugate gradient methods, quasi-Newton methods, simulated annealing, evolution strategies, evolu-"}, {"title": null, "content": "tionary programming and various types of hill climbers themselves\". All these techniques involve a sub-algorithm where a current solution, or set of solutions, are modified in some way to produce new candidate solutions. We call this neighbourhood search.\nWe examine the benefit of neighbourhood search and therefore why these techniques deploy them.\nIn our analysis of neighbourhood search, we make the conservative assumption that the search for an improving neighbour uniformly at random selects neighbours to evaluate until an improving neighbour is found.\nBlind search selects candidate solutions from the search space as a whole, uniformly at random, evaluating the cost of each one until a solution with a desired cost (or better) has been found.\nWe say that neighbourhood search performs better than blind search if the probability the next candidate solution has better cost than the current solution is higher than the probability a better solution is selected by blind search.\\u00b9 This is the first paper to show minimal general conditions on neighbourhoods under which neighbourhood search is expected to outperform blind search. The result is proven to hold for a range of starting cost levels.\nWhen when neighbourhood search finds an improving solution, it becomes the current point, and local descent continues from there. If there is no such point in the neighbourhood, then local descent has reached either a local optimum or a plateau.\nModern heuristic and metaheuristic methods [Alorf, 2023] include ways to avoid or escape from plateaux and local optima. However, this paper focusses on the progress made by local descent towards a target cost level, and does not introduce new methods to escape it.\nHowever, even if neighbourhood search had higher probability of improvement, the expected amount of improvement with blind search can be greater than with neighbourhood search. Indeed this is illustrated with an example on page 17.\nThis paper addresses local descent in two contexts. In the first context the current point is the best found so far. In this context every improving neighbour yields a new best solution. The question addressed is how fast local descent is expected to improve on the current solution.\nIn the second context, the current point has a poorer cost than the cost t of the best point found previously. In this context an improving neighbour may still have a cost no better than t. The question to be addressed in the second context is how quickly local descent is expected to find a point with cost better than t.\nWe say local descent is beneficial if, under the chosen measure, local search is better than blind search. This paper investigates the conditions under which local descent is beneficial in each of the two contexts given above. In particular,"}, {"title": null, "content": "a contribution of this paper is to establish specific conditions under which a na\u00efve form of local descent is proven to be beneficial."}, {"title": "Structure of the paper", "content": "The related work section introduces some previous research related to this paper; the next section introduces the properties needed for neighbourhood search to be beneficial,including Neighbours Similar Cost (NSC) and gives the formal underpinnings of our proofs; the section titled \"Probability of Improvement\" gives theorems and some proofs that neighbourhood search is beneficial; the next two sections give theoretical and practical examples (2-SAT and TSP) illustrating and investigating NSC and other properties; the section \"Rate of improvement\" investigates the rate of improvement with local descent and blind search; the section \"Local blind search\" analyses the expected number of steps to reach a target cost, assuming NSC; the final section concludes."}, {"title": "Related Work", "content": null}, {"title": "Cost Function", "content": "For \"blackbox\" optimisation problems, the objective function is unknown, unex-ploitable or non-existent [Alarie et al., 2021]. This has the same implications as the \"No Free Lunch\" (NFL) theorems [Wolpert and Macready, 1997], where the objective function is an unknown member of a set of functions, and is revealed only by evaluating its value point by point. In this paper we call the value of the objective function, applied to a point in a problem's search space, the cost of the point.\nWe assume that, as for blackbox objective functions, the cost of a point cannot be predicted without selecting and evaluating it. We also assume there is no access to an improving \"direction\" in which neighbours would tend to have better cost than the current solution. However we admit neighbourhoods with a locality property, discussed in the next section, thereby escaping from the conditions and conclusions of NFL."}, {"title": "Locality", "content": "Consider the cost values of neighbours of a current solution. Supposing their distribution is the same as the distribution of cost values in the problem search space as a whole. In this case neighbourhood search cannot outperform blind search.\nTo be precise, suppose, for any given current solution the probability that a neighbour of that solution has any given cost k is the same as the probability that any point in the search space has cost k. In this case, searching uniformly at random in the neighbourhood of any previous solution is no more likely to yield a solution with cost better than the current solution than evaluating a point selected randomly from the whole search space."}, {"title": null, "content": "Hence, the key general condition under which neighbourhood search is ben-eficial is a locality property. Essentially, a candidate solution chosen from the neighbourhood of the current solution is more likely to have a cost similar to the current solution than a candidate solution chosen from the search space as a whole [McDermott, 2020]. This alone is sufficient to escape from the negative conclusions of the NFL theorems [Streeter, 2003].\nLocality is a property of well-known neighbourhoods used in solving many combinatorial problems. For example in a maximum satisfiability problem flip-ping the truth value of a single variable can change only the truth of those clauses in which the variable appears; in a travelling salesman problem a 2-opt changes only the cost of 2 links; and in a graph partitioning problem the swap changes only the edges attached to the swapped node. In each case only a few of the terms in the objective function are affected, so that the new cost tends to be similar to the previous cost.\nLocality is arguably the simplest useful condition that a neighbourhood can be constructed to satisfy in a combinatorial problem. Variants of locality have been introduced in the literature, based on the average cost of neighbours, the maximum difference between neighbours, and the change in cost along paths where successive points are neighbours.\nMany studies have focussed on the expected cost value of the neighbours of any point with a given cost. [Grover, 1992] analysed the average difference between a candidate solution and its neighbours, for five well-known combina-torial optimisation problems. Since this difference is positive for candidates with less than average cost it implies that any local optima must have a bet-ter than average cost. These ideas were generalised to \"elementary landscapes\" [Whitley et al., 2008]. If x is an arbitrary element of the problem search space and y is drawn uniformly at random from the neighbours of x, then the expected cost of y is a fixed fraction of the distance between f(x) and f - the mean value of f(s) : s \u2208 S:\n $$E[f(y)] = f(x) + (k/d)(f \u2212 f(x))$$\nThis supports conclusions about the expected value of neighbours as the search space scales up, and about plateaus in the landscape. However it does not yield the probability that a neighbour has better cost than the current point, or support conclusions about the benefits of neighbourhood search.\nFor each cost difference we constrain the probability that two neighbours differ by this amount. Specifically we define the property of neighbours' similar cost (NSC) in terms of the increase in probability that neighbours have a cost difference d over the probability an arbitrary pair of points in the search space have this cost difference.\nGiven a measure of distance between points in a problem search space, the L-Lipschitz condition imposes the following condition between any pair of points, x and y:\n $$|f(x) \u2212 f(y)| \u2264 L \u00d7 |x - y|$$"}, {"title": null, "content": "do not have a measure of distance between search space points: only between their cost values. However a condition on the maximum cost difference between neighbours can be expressed as a form of L-Lipschitz condition Applying this condition to neighbouring points in a search space, it imposes that given a cost difference L, for every point x and neighbour y of x:\n $$|f(x) \u2212 f(y)| <L$$\nWe will investigate the impact of this condition in some benchmark problems on pages 17 and 25 below.\nMany researchers have explored conditions on points connected by a path in which successive points are neighbours. These include basins and funnels [Zou et al., 2022], fitness distance [Jones and Forrest, 1995], auto-correlation [Weinberger, 1990], niching [Horn et al., 1994] among others. Search algorithms successfully ex-ploiting these properties of landscapes have been investigated, for example subthreshold-seeking local search [Whitley and Rowe, 2006], which exploits the number of basins of attraction in a landscape.\nFor the results of this paper, no conditions on paths or on global properties of landscapes such as the number of local optima, are required.\nInstead we define the property of Neighbours' Similar Cost (NSC) in terms of the increase in probability that neighbours have a small cost difference d over the probability an arbitrary pair of points in the search space have this cost difference."}, {"title": "Local descent", "content": "Over 30 years ago, Johnson et.al. asked \"How easy is neighbourhood search?\" [Johnson et al., 1988]. They investigated the complexity of finding locally op-timal solutions to NP-hard combinatorial optimisation problems. They show that, even if finding an improving neighbour (or proving there isn't one) takes polynomial time, finding a local optimum can take an exponential number of steps.\n[Tovey, 1985] considers hill-climbing using flips of n zero-one variables. If the objective values are randomly generated the number of local optima tends to grow exponentially with n, and the expected number of successful flips to reach a local optimum from an arbitrary point grows linearly with n. A more general analysis of neighbourhood search in [Tovey, 2003] explores a variety of algorithms to reach a local optimum. More recently [Cohen et al., 2020] showed that this still holds even if the objective is a sum of terms, each comprising no more than seven variables. However the number of steps to reach a local optimum does not enable us to infer the number of steps to reach a given cost level.\nTo compare local descent with blind search we use the expected number of steps to reach a given level of cost. A step (in both local descent and blind search) is the selection and evaluation of a single point. This paper is the first to give conditions under which the expected number of steps using a na\u00efve version of local descent is lower than under blind search."}, {"title": "Properties needed for neighbourhood search to be beneficial", "content": "In the following, for uniformity, we assume that optimisation is cost minimi-sation. We assume a finite range of integer cost values, and without loss of generality, we set the optimum cost kopt to be 0."}, {"title": "Definitions", "content": "The probability a point has a given cost is its cost probability. The cost proba-bility is directly related to the concept of the density of states which applies to continuous cost measures encountered in solid state physics [Ros\u00e9 et al., 1996]. That work additionally shows how to estimate the density of states for a problem using Boltzmann strategies.\nThe expression neighbour of cost k means a member of the set of neighbours of points with cost k. These neighbours typically have costs close to k, if the neighbourhoods have the NSC(k) property. The neighbour's cost probability is the probability that a neighbour of cost k\u2081 has a given cost k2."}, {"title": "Neighbourhood search symbols", "content": "We introduce the following definitions:\n\u2022 The cost range is the set of integers, K = kopt...kmax, where kopt = 0 is the optimal cost (or cost), and kmax the worst.\n\u2022 p(k) is the probability a point has cost k \u2208 K. We extend the range of p by writing \u2200 integers k \u2209 K : p(k) = 0\n\u2022 The probability that a neighbour of a cost k\u2081 \u2208 K has cost k\u2082 is pn(k1,k2). If k2 & K then pn(k1,k2) = 0.\n\u2022 If 8 > 0 then p(k\u00b1 8) = p(k + d) + p(k \u2013 \u03b4). p(k \u00b1 0) = p(k). Similarly for pn(k, k\u00b1 \u03b4).\n\u2022 p<(k) is the probability blind search selects a point better than k. We call it the blind probability of improving:\n $$p^{<}(k) = \\sum_{\\delta=1}^{k}p(k - \\delta)$$\n\u2022 pn(k) is the probability neighbourhood search, starting from cost k, se-lects a point better than k. We call it the neighbourhood probability of improving:\n $$p_{n}^{<}(k) = \\sum_{\\delta=1}^{k}p_{n}(k, k - \\delta)$$"}, {"title": "Neighbourhood Weight", "content": "We have already given examples of neighbourhoods designed for local descent, such a 2-opt, where neighbours have similar cost. One way to formalise the property that neighbours have similar cost, would be \"the probability neigh-bours have a cost difference of d increases with decreasing \u03b4\". Unfortunately even where neighbours have similar cost - if the search space has very few points with cost near the optimum 0, then the probability a neighbour of an optimal point has cost 0+8 might not increase with decreasing \u03b4. More generally, despite neighbours having similar cost, if k\u2081 is near the optimum then pn(k1,k\u2081 \u00b1 \u03b4) (the probability a neighbour of a point with cost k\u2081 differs from k\u2081 by d) might also not increase with decreasing \u03b4.\nConsequently, in order to formalise the neighbours similar cost property NSC(k), we use the increased probability a neighbour of a point with cost k has cost k\u00b1d over the cost probability p(k + d) that an arbitrary point in the search space has cost k - 8 or cost k + \u03b4.\nWe introduce the function r(k, d) which is a weighting associated with cost distance & for points in the neighbourhood of any point with cost k. Accordingly pn(k, k \u00b1 \u03b4) = p(k \u00b1 \u03b4) \u00d7 r(k, d). We call r the NWeight."}, {"title": null, "content": "Definition 1 (NWeight). The NWeight r(k, d) for cost k and cost difference \u0431 gives probability a neighbour of a point with cost k has cost k\u00b1 \u03b4:\n $$p_{n}(k, k \u00b1 \\delta) = p(k \u00b1 \\delta) \u00d7 r(k, \\delta)$$\nClearly, summing all the disjoint probabilities for a given k:\n $$\\sum_{\\delta\\in K}p_{n}(k\u00b1 \\delta) = \\sum_{\\delta\\in K}(r(k, \\delta) \u00d7 p(k \u00b1 \\delta)) = 1$$\nThe Neighbourhood Similar Cost NSC(k) property holds if the NWeight r(k, \u03b4) increases as d decreases.\nWe made the point earlier that there is no access to an improving \"direction\" in which neighbours would tend to have better cost than the current solution. Consequently the probability that any neighbour with cost c\u2208 {k+d, k \u2013 d} has cost k-d is no different from the probability any point with cost c\u2208 {k+d, \u03ba-\u03b4} has cost k - \u03b4. Specifically. for each cost level k \u2208 K, for each cost difference \u03b4\u2208 K where p(k \u00b1 \u03b4) > 0,\n $$\\frac{p_{n}(k, k - \\delta)}{p_{n}(k,k\u00b1 \\delta)} > \\frac{p(k \u2013 \\delta)}{p(k\u00b1 \\delta)}$$\nUsing the NWeight r(k, d) this is equivalent to the condition"}, {"title": null, "content": "Definition 2. The neighbourhood of k is unbiased if\n $$\\forall\\d : p_{n}(k, k \u2212 \\delta) \u2265 r(k, \\delta) \u00d7 p(k \u2013 \\d)$$"}, {"title": null, "content": "We say the neighbourhood of k is positively biased if pn(k, k \u2212 d) > r(k, d) \u00d7 p(k - \u03b4).\nThe Neighbourhood Similar Cost NSC(k) property introduced in definition 3 is a property of a cost level rather than a point in the search space. At a given cost level, some points may have improving neighbours, while other might be local optima. Unless it is globally optimal, a locally optimal point does not have the same proportion of better and worse neighbours as there are in the search space as a whole. Only on average, over all points at one cost level, does NSC require the proportion of improving neighbours to be as good or better than in the whole search space. NSC(k) is defined as follows.\nDefinition 3. NSC(k) holds if the neighbourhood of k is unbiased, and the NWeight r(k, d) increases as d decreases:\n $$\\forall\\d : p_{n}(k, k \u2013 \\delta) \u2265 r(k, \\delta) \u00d7 p(\u03ba \u2013 \\b)\n\\\\\\delta_{1} \u2264 \\delta_{2} : r(k, \\delta_{1}) \u2265 r(k, \\delta_{2})$$\nWe argue that neighbourhoods designed for local search on combinatorial problems typically have the NSC(k) property, becoming increasingly positively biased for costs towards the optimum. We illustrate this below with two neigh-bourhoods, flipping the truth value of a binary variable in satisfiability problems (2-SAT) and the 2-swap operator in travelling salesmen problems. This is the property of locality deployed below in the proofs that local search outperforms blind search."}, {"title": null, "content": "A simple direct consequence of this definition is that, if NSC(k) and r(k, k) \u2265 1, then neighbourhood search starting at a point with fitness k is beneficial.\nProof. Since, by NSC(k), \u2200d < k : r(k,d) \u2265 r(k,k) \u2265 1, and pn(k, k \u2212 \u0431) \u2265 r(k, d) xp(k-d) therefore pn(k, k\u2212d) \u2265 p(k\u2212\u03b4). Thus Vi \u2208 0..k : pn(k, i) \u2265 p(i) Consequently, by definition:\n $$r(k, k) \u2265 1 \\rightarrow p_{n}^{<}(k) \u2265 p^{<}(k)$$\nStarting cost\nNeighbourhood search is unlikely to improve any faster than blind search start-ing from a very poor cost.\nWe therefore consider neighbourhood search from a current solution which is already of reasonably good cost.\nWe have seen that neighbourhoods with similar cost have neighbourhood operators that only change a small proportion of terms from an objective func-tion that is the sum of many terms. Such objective functions occur in the well-known problems listed by Grover [Grover, 1992] above, as well as most"}, {"title": null, "content": "(Polynomial time Local Search) PLS-complete problems [Michiels et al., 2007], and NP-hard problems whose cost is the weighted sum of violated constraints.\nFor a problem instance with such an objective function, the cost probability typically reduces sharply towards the optimum. If unconstrained, the optimum is reached when all the terms take their minimum value: there is just one such point. Then there are () ways that x out of n terms take their minimum value, and this number increases by a factor of - when x decreases by one. Thus, as the cost increases away from the optimum, the number of combinations of values that reach that sum increases dramatically, thus increasing its probability. On the other hand, if there are constraints, which exclude a similar proportion of points at each cost level, the same reduction in cost probability occurs towards the optimum. For VLSI problems, for example, [White, 1984] showed that the solution costs have a normal distribution over the interval between their minimal and maximal cost, having few solutions with cost near the extremes.\nOur proof of the benefit of neighbourhood search, requires that in the current neighbourhood, the cost probability should be decreasing with cost level towards the optimum. Specifically such problem classes have a moderate cost level, kmod, better than which this thinning out occurs.\nDefinition 4. The cost level kmod is the highest cost below than which p(k) is monotonically decreasing\u00b2 with decreasing cost:\n $$\\forall k_{1} \u2264 k_{2} \u2264 k_{mod}: p(k_{1}) \u2264 p(k_{2})$$\nFor many problems kmod lies about halfway between 0 and kmax. However, for a problem class whose cost probabilities are uniform (Vi, j : p(i) = p(j)), the modal cost is the maximum cost, so kmod = kmax.\nSpecifically if ke is the current cost, for beneficial neighbourhood search we require that p(k) should be monotonically increasing with k in the range 0...2 * kc. For such a cost kc, p(kc + d) : \u03b4 < kc monotonically increases with increasing d, while p(kc \u2013 d) decreases.\nDefinition 5. A cost k is good enough, and we write GE(k), if for all d \u2264 k, p(k \u2013 \u03b4) decreases with increasing \u03b4, and p(k + d) increases with increasing \u03b4\nThus GE(k) holds whenever 2 \u00d7 k \u2264 kmod."}, {"title": "Neighbours with no cost difference", "content": "Neighbours' similar cost includes the chance that neighbours have the same cost. If pn(k, k) is large enough (i.e. a high enough proportion of the neighbours of a given cost k also have cost k), then neighbourhood search may not outperform blind search.\nThe proofs in the next section include a limit on this proportion sufficient to ensure neighbourhood search is beneficial."}, {"title": "Probability of Improvement", "content": null}, {"title": "Definitions and Lemmas", "content": "Let us write (k) for the average value of r(k, \u03b4) : \u03b4 \u2208 1..k. This is the average NWeight for cost differences up to the optimum:\n $$r(k) = \\sum_{\\delta=1}^{k}r(k, \\delta)/k$$\nSecondly let us write pbr<(k) for the NWeighted probability of selecting a neighbour with cost lower than k.\n $$pbr^{<}(k) = \\sum_{\\delta=1}^{k}p(k \u2013 \\delta) \u00d7 r(k, \\delta)$$\nThis is the minimum probability a neighbour of cost k is improving, assuming the neighbourhood is unbiased.\nFor the proof the neighbourhood search is beneficial, we start with three lemmas. The first is that for a good enough current cost k, and assuming neigh-bourhood similar cost, the neighbourhood probability of improving is greater than the probability of improving with blind search times the average NWeight."}, {"title": null, "content": "Lemma 1. Assuming:\n $$2xkk_{mod}$$\n(GE)\n $$\\forall\\delta_{1} < \\delta_{2} : r(k, \\delta_{1}) \u2265 r(k, \\delta_{2})$$\n(NSC)\n $$\\sqrt{d} : p_{n}(k, k \u2212 \\delta) \u2265 r(k, \\delta) \u00d7 p(k \u2013 \\delta) (NSC)$$\nit follows that\n $$p_{n}^{ <}(k) \u2265 r(k) xp^{<}(k)$$\nThe result that pbr<(k) \u2265 r(k)\u00d7p<(k) is proven in the technical appendix. Since the neighbourhood is unbiased it follows that: pn<(k) \u2265 pbr<(k) \u2265 r(k)\u00d7p<(k).\nWe now introduce the probability of picking a worse neighbour. Let us define pn>(k) and pbr>(k) for neighbours with worse cost:\n $$p_{n}^{>}(k) = \\sum_{\\delta=1}^{k}p_{n}(k, k + d) & pbr^{>}(k) = \\sum_{\\delta=1}^{k}p(k + \\delta) \u00d7 r(k, \\delta)$$\nThe second and third lemmas reveal that for a good enough current cost k, and assuming neighbourhood similar cost, the probability of selecting worse neighbour is less than than the probability of selecting a worse point with blind search, times the average NWeight."}, {"title": null, "content": "Lemma 2. Assuming:\n $$2xk k_{mod}$$\n(GE)\n $$\\sqrt{\\delta_{1}} < \\delta_{2} : r(k, \\delta_{1}) \u2265 r(k, \\delta_{2}) (NSC)$$\nit follows that\n $$\\forall d > k : r(k, d) <r(k)$$\n $$pbr^{>}(k) \u2264 r(k) \u00d7 p^{2}(k)$$\nResult 3 follows immediately. The second result 4 is proven in the technical appendix. Finally, the following lemma follows from our definitions.\nLemma 3. If the neighbourhood of k is unbiased, then:\n $$p_{n}^{>}(k) \u2264 pbr^{>}(k)$$\nProofs that neighbourhood search is beneficial\nThe monotonicity conditions GE and NSC are only needed to prove the two lemmas 1 and 2. The condition GE, that the cost probability is monotonically decreasing towards the optimum, can be violated by a single high cost proba-bility. Similarly the condition NSC, that NWeight is monotonically decreasing with increasing cost-difference, can also be violated by a single high NWeight. Thirdly an almost unbiased neighbourhood may be violated at a single distance \u03b4."}, {"title": null, "content": "To prove that neighbourhood search is beneficial we shall therefore use the conclusions of these lemmas, equations 2, 3, 4 and 5, which hold consistently even in the above cases which strictly violate GE, NSC and/or unbiased.\nThe first beneficial neighbourhood theorem:\nTheorem 4. Beneficial neighbourhood search when average NWeight > 1\nIf equation 2 is satisfied and r(k) \u2265 1 then\n $$p_{n}^{}(k) \u2265 p^{}(k)$$\nProof. of theorem 4\n $$p_{n}^{ <}(k) \u2265 r(k) \u00d7 p^{<}(k) \u2265 p^{<}(k)$$\nIn case r(k) \u2265 1, above, there is no limit on the value of pn(k,k). We next tackle the case r(k) < 1. In this case there may be a high proportion of neighbours with the same cost as the current point - in short pn(k, k) may be high. Assuming the consequence of lemma 2, we can infer a limit on pn(k,k) below which pn<(k) \u2265 p<(k). In particular if pn(k, k) \u2264 p(k), the result follows."}, {"title": null, "content": "Let us write\n $$p^{>}(k) for \\sum_{\\delta=1}^{k}p(k + d)$$\n $$p^{>>}(k) for \\sum_{\\delta>k}p(k + \\delta)$$\nand define pn>>(k), pbr>>(k) similarly.\nThen\n $$1 = p^{<}(k) +p^{>}(k) + p^{>>}(k) + p(k)\n= p_{n}^{}(k) + p_{n}^{>}(k) + p_{n}^{>>}(k) + p_{n}(k,k)$$\nSO\n $$p_{n}^{<}(k) = p^{<}(k) + (p^{>}(k) \u2013 p_{n}^{>}(k))+\n(p^{>>}(k) \u2013 p_{n}^{>>}(k)) + (p(k) \u2013 p_{n}(k,k))$$\nDefinition 6. a> and a>>\nIn the light of the above equation, we define a>(k) and a>>(k) as follows:\n $$a^{>}(k) = (p^{>}(k) \u2013 p_{n}^{>}(k))$$\n $$a^{>>}(k) = (p^{>>}(k) \u2013 p_{n}^{>>}(k))$$\nLemma 5. If equations 3, 4 and 5 all hold, and r(k) < 1 then\n $$a^{>}(k) +a^{>>}(k) \u2265 0$$\nProof. of lemma 5\nBy equation 5, pn>(k) < pbr>(k) and, by equation 4, since r(k) < 1, then pbr>(k) <p>(k), and it follows that:\n $$a^{>}(k) = (p^{>}(k) \u2013 p_{n}^{>}(k)) \u2265 0$$\nMoreover, if \u03b4 > k then p(k \u2013 8) = 0 which means pn(k, k + \u03b4) = p(k + d) \u00d7 r(k, \u03b4). By equation 3 and by assumption, Vd > k : r(k, d) < r(k) < 1 and therefore \u2200d > k : pn(k, k + d) < p(k + d) so p>>(k) \u2265 pn>>(k). Consequently:\n $$a^{>>}(k) = (p^{>>}(k) \u2013 p_{n}^{>>}(k)) \u2265 0$$\nThe second beneficial neighbourhood theorem follows. This theorem shows that for a good enough cost k, if NSC(k) holds, then local search is beneficial unless too many neighbours have the same cost k. Indeed equation 7 gives a bound on this number."}, {"title": "Theorem 6. Beneficial neighbourhood search when average NWeight < 1", "content": "If equations 3, 4, 5 all hold and p(k) \u2265 pn(k,k) then even if r(k) < 1\n $$p_{n}^{}(k) \u2265 p^{}(k)$$\nProof. of theorem 6\nFrom equation 6 above, we have:\n $$p_{n}^{<}(k) = p^{<}(k) + (p^{>}(k) \u2013 p_{n}^{>}(k))+\n(p^{>>}(k) \u2013 p_{n}^{>>}(k)) + (p(k) \u2013 p_{n}(k, k))$$\nso, by definition:\n $$p_{n}^{<}(k) = p^{<}(k) + a^{>}(k) + a^{>>}(k) + (p(k) \u2013 p_{n}(k, k))$$\nBy lemma 5, a>(k) + a>>(k) \u2265 0, and by assumption p(k) \u2013 pn(k,k) \u2265 0 therefore:\n $$p_{n}^{}(k) >p^{}(k)$$\nNote that the same proof shows that, even if (k) < 1, the neighbourhood search is beneficial under the weaker condition that\n $$(p_{n}(k, k) \u2013 p(k)) \u2264 (a^{>}(k) + a^{>>}(k))$$\nIn general, the value of a>(k) + a>>(k) is far larger than the value of pn(k, k) \u2013 p(k) because they sum the difference between pn(k, d) and p(k + \u03b4) over the whole range of \u03b4 \u2208 0 . . . kmax - k, whereas pn(k, k) \u2013 p(k) is simply this difference when 8 = 0."}, {"title": "Calculating neighbourhood properties for a problem class", "content": "In this section we take a very simple example of a problem class, and show how we can infer its specification and properties. In particular we show it has the Neighbour Similar Cost property at all costs from 0 to the modal cost.\nThe class is a subclass of MAX-2-SAT, where there is a given number of variables and clauses.\nSince the same neighbourhood operator - flipping a boolean - applies to all instances of this class, we can model the search for an unknown instance of the class. Assuming the instance is drawn uniformly at random from the class, the expected values of p, pn and rare the same as for the class as a whole.\nSpecifically we take the class of MAX-2-SAT problems with 50 variables and 100 2-variable clauses, in which each variable appears in exactly 4 distinct clauses. Each variable can take the value true or false, so there are 250 can-didate solutions. The cost of a solution is the number of violated constraints,"}, {"title": null, "content": "so the range of cost values is 0...100. This completes the specification of our example problem class.\nBased on the above specification we calculate p, kmod, pn and r.\nEach clause is true with probability 3/4 and false with probability 1/4. The probability that C clauses are false is\n $$p(C) = = (1/4)^{C} \u00d7 (3/4)^{(100-C)} \u00d7\\binom{100}{C}$$\nThe most likely cost is p(25) = 0.092, and this is the modal cost kmod. The"}, {"title": null, "content": "The neighbours of a solution result from flipping the value of a single variable. Since a variable only appears in 4 clauses, pn(C, \u03b4) = 0 for all C and any \u03b4 > 4. Flipping a variable in a clause that is false always makes it true - thus increasing the cost by 1. Flipping a variable in a true clause makes it false with a probability of 1/3. If the current cost is C, the probability that the variable to be flipped is in a false clause is C/100, and a for true clause it is (100 \u2013 C)/100. Thus, for example, pn (C, C \u2013 4) =\n $$(C/100) * ((C \u2212"}]}