{"title": "Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities", "authors": ["Qirun Dai", "Dylan Zhang", "Jiaqi W. Ma", "Hao Peng"], "abstract": "Selecting appropriate training data is crucial for effective instruction fine-tuning of large language models (LLMs), which aims to (1) elicit strong capabilities, and (2) achieve balanced performance across a diverse range of tasks. Influence-based methods show promise in achieving (1) by estimating the contribution of each training example to the model's predictions, but often struggle with (2). Our systematic investigation reveals that this underperformance can be attributed to an inherent bias where certain tasks intrinsically have greater influence than others. As a result, data selection is often biased towards these tasks, not only hurting the model's performance on others but also, counterintuitively, harms performance on these high-influence tasks themselves.\nAs a remedy, we propose BIDS, a Balanced and Influential Data Selection algorithm. BIDS first normalizes influence scores of the training data, and then iteratively balances data selection by choosing the training example with the highest influence on the most underrepresented task. Experiments with both Llama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities show that BIDS consistently outperforms both state-of-the-art influence-based algorithms and other non-influence-based selection frameworks. Surprisingly, training on a 15% subset selected by BIDS can even outperform full-dataset training with a much more balanced performance. Our analysis further highlights the importance of both instance-level normalization and iterative optimization of selected data for balanced learning of diverse capabilities.", "sections": [{"title": "1 Introduction", "content": "Supervised instruction finetuning (SFT) plays a crucial role in eliciting strong capabilities from large language models (LLMs). Typically, a pre-trained LLM is finetuned on a mixture of different datasets to achieve strong and balanced perfor-"}, {"title": "2 Background and Preliminaries", "content": "Influence-based instruction tuning data selection. Estimating the influence of individual training examples on model predictions is critical for understanding model behavior and selecting influential training data to improve model performance. Traditional methods, including retraining-based and gradient-based approaches, have proven effective but are computationally prohibitive when scaling to LLMs, as they either require retraining on a large number of subsets, or computing at least a forward and backward pass for each training example in order to obtain its gradient. Several recent advances have sought to address these challenges by extending gradient-based approaches to scale more effectively. Given a large training dataset to select from and a validation set representing some targeted capabilities, LESS models the influence between each pair of training and validation examples through LoRA-based low-dimensional gradient similarity, and then selects training points with highest influence on the validation set. LOGRA leverages a low-rank gradient projection algorithm to further improve the efficiency. MATES formulates the pointwise data influence between each training point and the whole validation set, and uses a small data influence model to learn this pointwise influence.\nUpon closer inspection, these LLM-scale influence-based selection methods share a similar problem formulation. They all need a validation set to represent a targeted data distribution and require the computation of pointwise data in-"}, {"title": "3 Existing Influence-based Selection Fails at Balancing Diverse Tasks", "content": "We first show that LESS leads to significantly unbalanced and weak performance in a multi-task learning setup. This is quantitatively revealed by our analysis framework, which identifies inherent biases in the scale of influence values across different tasks. Insights drawn in this section pave the"}, {"title": "4 BIDS: Selecting Influential Data for Balanced Capability Learning", "content": "In this section, we introduce BIDS, a Balanced and Influential Data Selection algorithm to address the issues identified in \u00a73. BIDS has two key design choices: (1) instance-level normalization, and (2) iterative selection favoring underrepresented tasks.\nAt a higher level, this technique aims to address the scale difference of influence values across different validation instances. This can be achieved by applying a column-wise normalization to the Attribution Matrix. Specifically, for validation instance vj, the influence of each training example ti is normalized by $A_{norm} = (A_{ij} \u2212 \u03bc_j)/\u03c3_j$, where \u00b5j and \u03c3j are the sample mean and standard deviation of all values in column j of A. This normalization step ensures that the influence scores of different columns are on the same scale. In other words, if two influence scores of different columns have similar intra-column rankings, then they should also have similar values.\nWe further propose an iterative greedy selection algorithm to promote the balance over different capabilities. It begins with an empty set. In each iteration, the algorithm first computes the average influence distribution of the current selected subset T, denoted as $A_T \\frac{1}{|T|} \\sum_{k\\:t_k \\in T} A_{kj}$. Then it iterates through each training example t\u2081 in the"}, {"title": "5 Experiments", "content": "Basic setup. We follow the experimental setup outlined in \u00a73, including the same set of LLMs, datasets, tasks, and influence estimation implementations. To further validate the generalizability of BIDS, we also perform experiments on base models from different model families, which is detailed in Appendix A.6.\nBaselines. We compare with a couple of intuitive variants applicable to the Attribution Matrix, beyond the original task-wise max algorithm used by LESS. In addition, we also compare with a strong non-influence-based method. These additional baselines are summarized below."}, {"title": "6 Analysis", "content": "This section presents ablation studies and analyses of the two key components of BIDS, in terms of their contributions to BIDS' performance improvements and their effect on the selected data."}, {"title": "6.1 Ablation", "content": "The ablation results are summarized in Table 3. We compare BIDS with the - Iter baseline to ablate iterative selection, and with - (Norm + Iter) to further ablate both normalization and iterative selection. In other words, - (Norm + Iter) is the naive instance-wise max algorithm applied to the unnormalized Attribution Matrix, and - Iter additionally applies the instance-level normalization proposed by BIDS to the AM. From the table, we observe that normalization alone can already consistently improve the overall performance of selected data under various budgets. And applying the iterative selection not only further elevates the macro-average score, but also improves the balance of cross-task performance. These two observations confirm that both design choices of BIDS contribute positively to the performance gains."}, {"title": "6.2 Changes in Influence Distribution of Selected Data", "content": "After confirming the positive contribution from both components of BIDS, we then proceed to explore how they affect the influence distribution of selected data, and whether such effects can provide insights into why BIDS advances balanced learning of diverse capabilities.\nWe compare the same models as in \u00a76.1, using a slightly modified version of the two types of data analysis metrics defined in \u00a73. For better AID comparisons, we report influence values after instance-level normalization. We also replace task-wise average influence with instance-wise influence in the THI calculation, since the three algorithms we are comparing are all built upon the instance-wise max approach. Concretely, for each selected training example ti, if its influence on validation instance vk is the highest across all |V| validation instances and vk \u2208 Vj, then the THI frequency for task j increases by one.\nComparing 4a with 4b and 4c, we see that after normalization the task frequency distribution becomes much more balanced. The frequencies for tasks such as MMLU, GSM-Plus, MATH and IFEval all increase by a great extent, while those for BBH and the two coding tasks decrease. This is fairly surprising when compared with the experimental results in Table 3, where - Iter and BIDS actually show improvements in tasks with both de-"}, {"title": "7 Related Work", "content": "Data Selection for Instruction Finetuning. Since the pioneering work LIMA showed that a mere 1000 carefully curated high-quality instruction data can already lead to significant performance improvement, many works have been exploring automatic data selection pipelines guided by different metrics. Quality-guided selection mostly defines the quality for each data point based on natural language indicators , quality scores from strong evaluators such as GPT-4 , or principled metrics derived from various learning dynamics. Diversity-guided methods usually apply clustering algorithms based on certain informative representation of each data point, and also take inspiration from traditional core-set selection approaches . Both of these dimensions have been proved effective for instruction finetuning of LLMs, and we remark that our method BIDS considers both quality and diversity metrics by applying an iterative selection algorithm to influence distributions.\nInfluence Estimation. Influence estimation has long been an important type of data attribution method, which can be classified into gradient-based and retraining-based approaches. Gradient-based influence estimation focuses on the gradient trace of each training point, and assesses the gradient alignment between training and validation examples. Retraining-based estimation usually trains a large number of models on different training subsets, and then inspects how their performance changes when a training example is added to these subsets . Recently both lines of works have been extended to LLM-scale applications, covering various aspects including pretraining and instruction tuning."}, {"title": "8 Conclusion", "content": "In this work, we introduce BIDS, an influence-based instruction tuning data selection algorithm specifically designed for balanced learning of multiple diverse capabilities. Motivated by the observation of an inherent bias in influence across various tasks, BIDS first applies column-wise normalization to the Attribution Matrix that contains pairwise data influence. Together with an iterative selection algorithm favoring underrepresented tasks, BIDS consistently outperforms various selection algorithms as well as full-dataset training with much more balanced performance. Our analysis further provides insight into the properties of an influential dataset with balanced capabilities."}, {"title": "Limitations", "content": "Though this work focuses on the imbalance issue of influence-based data selection methods, the results of RDS in Table 2 also show significant bias towards the two coding tasks, at the cost of severely degraded performance on almost all others. These observations suggest the possibility that the imbalance of utility scores may generally exist for both influence- and non-influence-based data selection approaches. However, the focus of this paper limits a broader investigation into the more general imbalance of utility scores for data selection under a multi-capability learning setup. We hope it can be discussed and addressed in future work."}, {"title": "A Appendix", "content": "A.1 Influence Estimation Pipeline of LESS\nWe briefly introduce the influence estimation pipeline of LESS in this section. For more detailed motivation and step-by-step mathematical deduction, we suggest referring to.\nAssume a model Ms which scores and selects data, and another model Mt which is trained on the selected data. For a training dataset D and validation dataset V, LESS formulates the pairwise influence between each training example ti \u2208 D and validation instance vj \u2208 V with the following three steps.\nStep 1: Warmup training with LoRA. LESS first trains Ms on a random subset Dwarmup CD for N epochs using the parameter-efficient finetuning method LoRA, and checkpoints the model after each epoch to store LoRA parameters {\u03b8t}t=1N.\nStep 2: Gradient computation and projection. For each checkpoint \u03b8t of LoRA-trained Ms, LESS computes the SGD gradient of validation instance vj, and further uses random projection to project the gradient to a tractable lower dimension. The resulting projected gradient is denoted as \u2207l(vj; \u03b8t) . LESS also computes and projects the gradient of training example ti, but uses the Adam gradient defined as follows:\n$\u0393(ti, \u03b8t) = \\frac{m^{t+1}}{\\sqrt{v^{t+1}} + \u03b5}$ \nwhere mt+1 and vt+1 are the first and second moments in the parameter update rule for Adam optimizer.\nStep 3: Gradient matching and influence calculation. Finally, LESS employs the following cosine-similarity-based approach to calculate the alignment between the gradient of each training and validation example, accumulated over all the warmup training epochs:\n$Inf Adam (ti, vj) = \\sum_{t=1}^{N} \u1fc6_t cos(\u2207l(vj; \u03b8t), \u0393(ti, \u03b8t))$\nwhere \u1fc6t is the average learning rate in the t-th epoch.\nA.2 Details of Training and Evaluation Setups\nBased on the LESS pipeline described above, we further introduce the implementation details of the training and evaluation setups in this work. All the experiments are carried out on 2 H100 GPUs with 80 GB memories."}, {"title": "A.3 Mathematical Definition of Influence-based Selection Algorithms", "content": "In this section, we specify the mathematical definition of all the three influence-based selection algorithms used in this work. They share the same framework of first assigning an overall influence score si to each training example ti and then selecting examples with the highest scores, and only differ in the specific definition of si.\nTask-wise Max: $s_i = max_{k=1,...,m}{\\{\\sum_{v_j \\in V_k} A_{ij}\\}\\}.$\nInstance-wise Max: $s_i max_{j=1,...,|V|}\\{A_{ij}\\}$.\nSum: $s_i = \\sum_{j=1}^{|V|} A_{ij}.$"}, {"title": "A.4 Effect of Normal Standardization on the Attribution Matrix", "content": "In \u00a74 we introduce the instance-level normalization technique of BIDS. One potential issue with this normal standardization approach is that it may not work sufficiently well when the distribution of unnormalized influence scores differs much from an approximate normal distribution. In this section we aim to justify the application of normal standardization to the Attribution Matrix (AM). Specifically, we randomly select five validation instances (i.e., five columns in the AM) from each task, and compare their empirical distributions after normalization with a standard normal distribution. The results show that almost all of the sampled columns approximate a standard normal distribution after the instance-level normalization, which justifies the use of normal standardization as the normalization method in BIDS."}, {"title": "A.5 Algorithmic Illustration of the Iterative Selection in BIDS", "content": "Algorithm 1 provides a step-by-step illustration of the iterative selection algorithm in BIDS (\u00a74 and Figure 3). As is shown in line 4, at each iteration, the utility of each candidate example ti is defined as\n$\u0394^{(i)} = \\underset{1 \u2264 j \u2264 |V|}{max} \\{A_{ij} - \\frac{1}{|T|} \\underset{k \\in \\{k | t_k \\in T\\}}{\u03a3} A_{kj}\\}$\ni.e., the largest component of Ai \u2013 AT. And the candidate example ti* with the highest utility \u25b3(i*) is selected for this iteration."}, {"title": "A.6 Results with Different Base Models", "content": "In order to further validate the generalizability of BIDS, we compare BIDS with other baseline data selection algorithms using Mistral-7B-v0.3 as the backbone for both selection and training. The results are presented in Table 4. The two algorithms compared here, - (Norm + Iter) and \u2013 Iter, follow the same definition in \u00a76.1. And the random baseline is also the average result of two different random seeds."}, {"title": "A.7 Discussion on the Computational Cost of BIDS", "content": "In this section, we aim to discuss and show that BIDS does not incur much memory or latency overhead, and can thus serve as an efficient plug-and-play module. In our training and evaluation setup, the |D| dimension for the Attribution Matrix is about 288 K , and the |V| dimension is 350. Therefore, the memory cost for storing the AM using FP 64 precision is less than 800 MB. The latency cost for running the whole BIDS algorithm is less than 1 minute with CUDA acceleration of a single H100 GPU. More generally, since many popular mixtures of instruction finetuning data are maintained on the scale of hundreds of K , the memory and latency cost of BIDS should be light for most practical training setups."}, {"title": "A.8 Qualitative Analysis", "content": "In this section, we aim to demonstrate the following two properties of BIDS with some qualitative examples, and thus better illustrate the effectiveness of BIDS.\n1. Models trained on BIDS-selected data can indeed achieve a stronger balance between mastering task-specific skills (e.g., math reasoning, coding knowledge, etc.) and fully understanding various types of instructions given by the user (e.g., format-following, response style, etc.).\n2. Such a stronger balance is indeed helpful to improving the accuracy or human-perceived quality of model response.\nConcretely, we present three sets of model responses in the task of coding (Table 5), math (Table 6) and general instruction-following (Table 7) respectively. Each set contains a correct response by a Mistral-7B-v0.3 model trained on top-15% BIDS-selected data, and a false response by the same base model trained on the full (i.e., 100%) UltraInteract, both to exactly the same prompt. We analyze how the BIDS-trained model correctly answers all these prompts due to the greater balance of capabilities it achieves."}]}