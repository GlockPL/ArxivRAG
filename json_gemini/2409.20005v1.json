{"title": "Model Selection with a Shapelet-based Distance Measure for Multi-source Transfer Learning in Time Series Classification*", "authors": ["Jiseok Lee", "Brian Kenji Iwana"], "abstract": "Transfer learning is a common practice that alleviates the need for extensive data to train neural networks. It is performed by pre-training a model using a source dataset and fine-tuning it for a target task. However, not every source dataset is appropriate for each target dataset, especially for time series. In this paper, we propose a novel method of selecting and using multiple datasets for transfer learning for time series classification. Specifically, our method combines multiple datasets as one source dataset for pre-training neural networks. Furthermore, for selecting multiple sources, our method measures the transferability of datasets based on shapelet discovery for effective source selection. While traditional transferability measures require considerable time for pre-training all the possible sources for source selection of each possible architecture, our method can be repeatedly used for every possible architecture with a single simple computation. Using the proposed method, we demonstrate that it is possible to increase the performance of temporal convolutional neural networks (CNN) on time series datasets.", "sections": [{"title": "1 Introduction", "content": "Neural networks have widespread usage in time series recognition. For example, temporal Convolutional Neural Networks (CNN) [19] have been shown to be effective across many time series domains [38,2]. However, often, neural networks require large amounts of data [10,15]. Also, acquiring large amounts of annotated data can take time and effort.\nSeveral ideas exist to solve the problem of the requirement of large amounts of annotated data, such as transfer learning, self-supervised learning, data augmentation, etc. In particular, transfer learning has become a popular method of initializing neural networks. In transfer learning, to alleviate the need for data, neural networks can be trained on larger source datasets and fine-tuned for target datasets. In this way, the weights of the neural network can be trained to"}, {"title": "2 Related Works", "content": "Transfer learning has been used for various applications in image recognition [46]. Furthermore, transfer learning has become the standard practice for training networks, as pre-trained weights are available for the most popular image recognition network architectures.\nConversely, transfer learning is less common for time series recognition and temporal neural networks [10] outside of Natural Language Processing (NLP). However, there have been a few works that demonstrate the usefulness of transfer learning in the time series domain [10,39,36]. Other examples include using transfer learning with health data [4], human activity recognition [1], prediction"}, {"title": "2.1 Transfer Learning for Time Series", "content": "Transfer learning has been used for various applications in image recognition [46]. Furthermore, transfer learning has become the standard practice for training networks, as pre-trained weights are available for the most popular image recognition network architectures.\nConversely, transfer learning is less common for time series recognition and temporal neural networks [10] outside of Natural Language Processing (NLP). However, there have been a few works that demonstrate the usefulness of transfer learning in the time series domain [10,39,36]. Other examples include using transfer learning with health data [4], human activity recognition [1], prediction"}, {"title": "2.2 Multi-Source Transfer Learning", "content": "There have been a few works that use multiple source datasets for transfer learning. For example, Yao and Doretto [41] extend TrAdaBoost [6], a method of boosting transfer learning, to use with multiple sources. Huang et al. [13] improve on this and propose SharedBoost for multiple source transfer learning. Multi-transfer [34] combines multi-view and multi-source transfer learning. For multi-source transfer learning, Song et al. [32] use the conditional probability difference to weight source domains.\nMulti-source transfer learning has also been used for time series data. One of the typical methods of multi-source transfer learning is to use a preliminary classifier to select the sources. For example, for electroencephalogram (EEG) data, Jinpeng Li et al. [20] trained each source individually, and then they tested the target domain on each and selected the top-performing models. Ren et al. [26] classify EEG data using a multi-source model. Huiming Lu et al. [22] use an ensemble model to implement multi-source transfer learning for building energy prediction.\nAlso, Yao et al. [40] use multi-source transfer learning with Variational Mode Decomposition to improve PM2.5 concentration forecasting while selecting sources using Euclidean Distance and Maximum Mean Discrepancy. Lotte and Guan [21] use a search algorithm to combine different datasets. Senanayaka et al. [29] used a similarity-based approach for multi-source transfer learning to generate a mixed domain of multiple sources and targets in the pre-training stage."}, {"title": "3 Transferability Measure", "content": ""}, {"title": "3.1 Problem Setting", "content": "Given source dataset S = {(s1, z1), ..., (sm, zm),..., (SM, zM)}, where (sm, zm) is the m-th pair of pattern sm and respective label zm, transfer learning aims to train a network f with S, so that it will be a practical starting point for target dataset T = {(x1,y1),..., (x,y), ..., (x,y)}, where (xn, zn) is the n-th pair of pattern xn and respective label yn. Unlike domain adaptation, there is no assumption that the task of the source and target datasets are related.\nAs Fawaz et al. [10] found, not all source datasets are useful for transfer learning with time series. Thus, a suitable source dataset S for each target dataset T should be determined. Under the problem setting, this determination should"}, {"title": "3.2 Transferability Estimation", "content": "Transferability estimation measures attempt to predict how effective transfer learning will be for model f, pre-trained on source dataset S, for target dataset T. These methods first use models f pre-trained on datasets S to predict target dataset T. Specifically, prediction f(xn) is done using the data in of T with the source labels c\u2208 C and the features F(xn) \u2208 F are extracted from model f trained by S. While the source labels C might be unrelated to the target task, the outputs are used for the transferability estimation. In other words, models trained for S are used as-is with dataset T, and the amount of information inferred by the model is measured and used as a transferability estimation measure. Some transferability estimation measures include, Log Expected Empirical Prediction (LEEP) [24], Negative Conditional Entropy (NCE) [37], Log Maximum Evidence (LogME) [45], Transrate [12], and H-score [3].\nFor example, LEEP [24] first predicts the target dataset T using trained f. LEEP is then calculated by:\nLEEP(S,T) = \\frac{1}{N} \\sum_{n=1}^{N} log (\\sum_{c \\in C} P(y_n|c)f(x_n)),\nwhere P(y_n|c) is the empirical conditional distribution calculated by:\nP(y_n/c) = \\frac{P(y_n, c)}{P(c)} = \\frac{\\sum_{n:y_n=c} f(x_n)}{\\sum_{i=1}^{N} f(x_n)}\nLEEP is the average log-likelihood of the prediction of T in trained network f multiplied by P(y_n|c) for each source class c.\nDataset Similarity Measure for Source Selection As an alternative to transferability estimation, dataset similarity can also be used to predict transferability. The previous methods are helpful because only the pre-trained network f and not the original dataset S is needed to calculate transferability. However, unlike image recognition, standard models with downloadable weights for time series recognition are lacking. Therefore, requiring pre-trained networks is a detriment because it requires training many networks before pre-training the actual network for the task.\nConversely, measuring the distance between datasets only requires access to the datasets. Following this, Fawaz et al. [10] proposed to use DTW [27] between representative time series patterns from each class in the target and"}, {"title": "4 Multi-Source Transfer Learning", "content": "We propose a simple yet effective method of combining multiple source datasets for transfer learning. As shown in Fig. 1, to perform multi-source pre-training, we compile multiple source datasets S1, ..., Si, . . ., Si,..., S\u2081 into one super dataset SMulti = {S1, . . ., Si, . . ., S\u2081}. In order to transfer knowledge from a model trained with multiple sources, the datasets are pre-processed so that they have the same number of time steps as the target dataset. Note that by resampling the source datasets, the features and characteristics of the datasets might not be preserved. However, this fact is optional because the purpose of the pre-training is to acquire a robust set of initial weights for transfer learning and not the classification accuracy of the source datasets. In addition to resampling, SMulti is balanced so that each sub-dataset has the same number of time series. To balance SMulti, oversampling is performed while preserving the class ratios. This is done due to the discrepancy in the size of possible source datasets; it ensures that every dataset has an equal contribution to the transfer learning.\nAs shown in Fig. 1, in order to train a network with multiple datasets, the one-hot vector of the ground truth of each source dataset Si are concatenated, and the output nodes are extended accordingly. In this way, the network is then trained using SMulti for a classification task using all of the classes from all of"}, {"title": "5 Shapelet Similarity-based Source Selection", "content": "In order to use the proposed transfer learning method effectively, some source datasets need to be selected. However, as mentioned, selecting the source datasets needs to be performed. Thus, we propose a new method of measuring the transferability of networks through a novel dataset similarity measure using discriminative shapelets."}, {"title": "5.1 Shapelet", "content": "A shapelet refers to a subsequence extracted from time series data that are maximally representative of a class [42]. These subsequences are intended to encapsulate fundamental patterns or discriminative features within a class. For example, the circled subsequences in Fig. 2 are well discovered within a class and represent differences between the two classes. In the figure, the circled shapelets are segments of the time series unique to each class."}, {"title": "5.2 Matrix Profile for Shapelet Discovery", "content": "Since a shapelet can be any subsequence from a time series, finding the maximum representative shapelet would be too costly with brute force. In order to overcome"}, {"title": "5.3 Shapelet Similarity-based Source Selection", "content": "Now that the representative shapelets P(S) and P(T) can be found for each source dataset S and target dataset T, respectively, we use them as a basis for a dataset distance measure. We propose two shapelet distance measure schemes, Average Shapelet, and Minimum Shapelet distances. Fig. 3 represents an overview of Average Shapelet and Minimum Shapelet.\nAverage Shapelet takes the average distance for each combination of PS) and PT), or:\nDas = \\frac{1}{i,j} \\sum ||P^{(S)}_i - P^{(T)}_j||,\nwhere P(S) and P(T) are the i-th and j-th shapelet in P(S) and P(T), respectively. By using the average distance between shapelets, this measure compares all of the discriminative features of the datasets simultaneously. The general idea of this measure is that if all of the shapelets of the datasets are similar, then the datasets might be similar.\nMinimum Shapelet is defined as the distance between the most similar pair of shapelets of S and T, or:\nDms = min_{i,j} ||P^{(S)}_i - P^{(T)}_j||."}, {"title": "6 Experimental Result", "content": ""}, {"title": "6.1 Dataset", "content": "The experiments were conducted using all of the UCR Archive [7], which consists of 128 datasets. We use the predetermined training and test set split provided by the archive. Also, no pre-processing was performed except for resizing datasets through Gaussian smoothing with different lengths."}, {"title": "6.2 Settings and Architecture", "content": "For the experiment, we adopted a 1-dimensional CNN model based on the VGG architecture [31]. The convolutional network used three blocks of convolutional layers and a pooling layer. The first block has two convolutional layers of size 3, and the subsequent blocks have three convolutional layers. Max pooling is used with the first two blocks, and global average pooling (GAP) is used with the final block. While GAP is not required for the proposed method, it is required for LEAP, NCE, H-score, Transrate, and LogMe due to having different-sized datasets; thus, we used it for all evaluations.\nFor training, we pre-train the network for 10,000 iterations with Adaptive Moment Estimation (Adam) optimizer [17] with an initial learning rate of 0.0001. For transfer learning, we then fine-tune the network for 5,000 iterations. The batch size is set to 32 for both pre-training and fine-tuning. For statistical validity, we fine-tuned the model three times in order to have the mean of"}, {"title": "6.3 Comparative Evaluation", "content": "To evaluate the proposed method, we compared it to not using transfer learning, to using transfer learning using a dataset selected by a shapelelt-based distance measure, and to using a dataset selected by the other transferability metrics. The comparative measures used for source selection include using DTW between DBA class representatives (DBA-DTW) [10], LEEP [24], NCE [37], Transrate [12], LogME [45], and H-score [3]."}, {"title": "7 Discussion", "content": ""}, {"title": "7.1 Ablation Study", "content": "We compared the classification performances with multi-source pre-training with shapelet-based source selection, multi-source pre-training with random source selection, and without transfer learning. Fig. 6 compares the performances of each dataset of the UCR Archive. Our proposed method showed significantly better results than the random initialized model and multi-source transfer learning with random source selection. Specifically, the result on the right figure demonstrates that our proposed shapelet similarity-based source selection is effective for source selection on multi-source transfer learning. Also, according to the t-test, our proposed method is effective with most datasets, p < 0.001."}, {"title": "7.2 Number of Datasets", "content": "In order to examine how the hyperparameters for the proposed method affect performance, we examined the number of shapelet candidates, the number of source datasets, and the two shapelet similarity-based distance measures. For the number of shapelet candidates, we discovered three, five, and ten shapelet candidates for every dataset. For the number of source datasets, we selected 1, 2, 4, 6, 8, 10, 12, 14, 16, 18, and 20 datasets according to shapelet-based distance measures. Finally, we examined the Average Shapelet and the Minimum Shapelet for the shapelet-based distance measure.\nThe experimental results in Fig. 7 showed better performance with more sources for all selection methods, including Random multi-source selection. Thus, increasing the number of datasets using our multi-source transfer learning method effectively increases the effect of pre-training while alleviating the risk of negative transfer. However, there was no significant difference when the"}, {"title": "7.3 Similarity Based Source Selection", "content": "Generally, with a small-scale target dataset, pre-training with a closely related source dataset allows for more efficient training while reducing the risk of overfitting. However, many time series tasks such as EGG, Speeches, and Gestures have different features and usually contain a small number of patterns. Thus, selecting a source dataset for time series transfer learning is often a big challenge, and transfer learning with non-related tasks is usually not helpful.\nAccording to the experimental result, as depicted in Table 1, selecting a source dataset based on dataset ranking metrics of DBA-DTW and Minimum Shapelet resulted in superior performance compared to a random source selection and even to the classic transferability measures. Therefore, for time series classification, where lack of data is a frequent challenge, measuring time series similarity can serve as a valuable indicator of transferability."}, {"title": "7.4 Computational Time", "content": "Regarding computational time, shapelet similarity-based source selection has a huge benefit compared to other transferability estimation metrics. Shapelet similarity-based dataset ranking has two steps of calculation: one step is to generate shapelet, and the other is to calculate the similarity among generated shapelets. Thus, the shapelet similarity-based source selection requires"}, {"title": "8 Conclusion", "content": "In this paper, we suggest using transfer learning for temporal neural networks using a proposed multi-source pre-training. Specifically, we demonstrate that by combining multiple datasets into a super dataset using pre-processing and adjusting the classification task with the concatenation of the classes, it is possible to pre-train a network using a large amount of data and classes.\nFurthermore, in order to select appropriate datasets out of the large number of possible datasets that exist, we propose a new transferability measure based on shapelets. Our novel method calculates the distance between datasets using a shapelet similarity. The shapelet-based distance compares the class-discriminative shapelets between classes of the target dataset and the source dataset. We demonstrate that by using multi-source transfer learning with our shapelet similarity-based source selection, it is possible to increase the time series classification accuracy with little downside.\nIn future work, we will investigate the combinations of source datasets to optimize our proposed method further. We hope to contribute to the time series classification community by continuing to expand upon these techniques."}]}