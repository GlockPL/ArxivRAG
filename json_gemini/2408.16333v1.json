{"title": "Self-Improving Diffusion Models with Synthetic Data", "authors": ["Sina Alemohammad", "Ahmed Imtiaz Humayun", "Shruti Agarwal", "John Collomosse", "Richard Baraniuk"], "abstract": "The artificial intelligence (AI) world is running out of real data for training increasingly large generative models, resulting in accelerating pressure to train on synthetic data. Unfortunately, training new generative models with synthetic data from current or past generation models creates an autophagous (self-consuming) loop that degrades the quality and/or diversity of the synthetic data in what has been termed model autophagy disorder (MAD) and model collapse. Current thinking around model autophagy recommends that synthetic data is to be avoided for model training lest the system deteriorate into MADness. In this paper, we take a different tack that treats synthetic data differently from real data. Self-IMproving diffusion models with Synthetic data (SIMS) is a new training concept for diffusion models that uses self-synthesized data to provide negative guidance during the generation process to steer a model's generative process away from the non-ideal synthetic data manifold and towards the real data distribution. We demonstrate that SIMS is capable of self-improvement; it establishes new records based on the Fr\u00e9chet inception distance (FID) metric for CIFAR-10 and ImageNet-64 generation and achieves competitive results on FFHQ-64 and ImageNet-512. Moreover, SIMS is, to the best of our knowledge, the first prophylactic generative AI algorithm that can be iteratively trained on self-generated synthetic data without going MAD. As a bonus, SIMS can adjust a diffusion model's synthetic data distribution to match any desired in-domain target distribution to help mitigate biases and ensure fairness.", "sections": [{"title": "1 INTRODUCTION", "content": "Thanks to the ongoing rapid advances in the field of generative artificial intelligence (AI), we are witnessing a proliferation of synthetic data of various modalities that have been rapidly integrated into popular online platforms. The voracious appetite of generative models for training data has caused practitioners to train new models either partially or completely using synthetic data from previous generations of models. Synthetic training data is actually hard to avoid, because many of today's popular training datasets have been inadvertently polluted with synthetic data.\nUnfortunately, there are hidden costs to synthetic data training. Training new generative models with synthetic data from current or past generation models creates an autophagous (self-consuming) loop that can have a detrimental effect on performance. In the limit over many generations of training, the quality and/or diversity of the synthetic data will decrease, in what has been termed Model Autophagy Disorder (MAD) and Model Collapse. MAD generative models also have major fairness issues, as they produce increasingly biased samples that lead to inaccurate representations across the attributes present in real data (e.g., related to demographic factors such as gender and race).\nMADness arises because synthetic data, regardless of how accurately it is modeled and generated, is still an approximation of samples from the real data distribution. An autophagous loop causes any approximation errors to be compounded, ultimately resulting in performance deterioration and bias amplification.\nSafely advancing the performance of generative AI systems in the synthetic data era requires that we make progress on both of the following open questions:\nQ1. How can we best exploit synthetic data in generative model training to improve real data modeling and synthesis?\nQ2. How can we exploit synthetic data in generative model training in a way that does not lead to MADness in the future?\nIn this paper, we develop Self-IMproving diffusion models with Synthetic data (SIMS), a new learning framework for generative models that addresses both of the above issues simultaneously. Our key insight is that, to most effectively exploit synthetic data in training a generative model, we need to change how we employ synthetic data. Instead of na\u00efvely training a model on synthetic data as though it were real, SIMS guides the model towards better performance but away from the patterns that arise from synthetic data training.\nWe focus here on SIMS for diffusion models in the context of image generation, because their robust guidance capabilities enable us to efficiently guide them away from their own generated synthetic data. In particular, we use a base model's own synthetic data to obtain a synthetic score function associated with the synthetic data manifold and use it to provide negative guidance during the generation process. By doing so, we steer the model's generative process away from the non-ideal synthetic data manifold and towards the real data distribution."}, {"title": "2 BACKGROUND", "content": "Diffusion models. Let $p$ denote the distribution we seek to model. Diffusion models gradually diffuse the training data over time $t \\in [0, T]$ and sample from $p$ by inversely modeling the forward diffusion process. Typically, this diffusion process involves transforming instances drawn from $p$ into noisy versions with scale schedule $a_t$ and noise schedule $\\sigma_t$ at time $t$. Hence, the conditional distribution of the noisy sample $x_t$ at time $t$ can be formalized as\n$q_t(x_t|x_0) = N(x_t | \\mu = a_tx_0, \\Sigma = \\sigma_t I),$ (1)\nwhere $x$ is the data instance drawn from $p$. The diffusion process can be formalized using a stochastic differential equation (SDE)\n$dx = f(x,t)dt + g(t)dw,$ (2)\nwhere $w$ is the standard Wiener process. Different choices for $f(x, t)$ and $g(t)$ result in different scaling $a_t$ and noise $\\sigma_t$ schedules in (1). We refer the reader to for more details on different SDE formulations for diffusion models.\nThe solution to the SDE in (2) is another SDE described by\n$dx = [f(x, t) - g^2(t)\\nabla_{x_t} log q_t(x_t)]dt + g(t)d\\bar{w},$ (3)\nwhere $d\\bar{w}$ is the standard Wiener process when time flows in the reverse direction, and $q_t$ is the unconditional distribution in (1) obtained by the forward SDE through (2). The solution of the SDE in (3) starting from the samples of $x_T \\sim q_T$ results in samples $x \\sim q(x_0)$ that enable data generation from $p$.\nSince the score function $\\nabla_{x_t} log q_t(x_t)$ is unknown, the objective is to train a neural network with parameters $\\theta$ to approximate the score function $s_\\theta(x_t, t) \\approx \\nabla_{x_t} log q_t (x_t)$ through\n$\\min_\\theta \\frac{1}{D} \\sum_{x_0 \\in D} E_{t \\in [0,1], x_t \\sim q_t (x_t|x_0)}[\\lambda(t)||$s_\\theta (x_t, t) - \\nabla_{x_t}log q_t (x_t)||^2],$ (4)\nwhere $D$ is the training set containing samples from $p$, and $\\lambda(t)$ is a temporal weighting function. The SDE in (3) can be solved by replacing $\\nabla_{x_t} log q_t(x_t)$ with $s_\\theta(x_t, t)$ and performing numerical integration. For conditional generation, one can also impose a condition on the score function during training to obtain the conditional score.\nSelf-consuming generative models. Let $A(\\cdot)$ represent an algorithm that, given a training dataset $D$ as input, constructs a generative model with distribution $G$, i.e., $G = A(D)$. Consider a sequence of generative models $G_t = A(D_t)$ for $t \\in N$, where each model approximates some reference (typically real data) probability distribution $p_r$.\nDefinition 1. Self-consuming (autophagous) loop: An au-tophagous loop is a sequence of distributions $(G_t)_{t\\in N}$ where each generative model $G_t$ is trained on data that includes samples from previous generation models $(G_{t'})_{t'=1}^{t-1}$.\nDefinition 2. Model Authophagy Disorder (MAD): Let $dist(\\cdot, \\cdot)$ denote a distance metric on distributions. A MAD generative process is a sequence of distributions $(G_t)_{t\\in N}$ such that $E[dist(G_t, p_r)]$ increases with $t$."}, {"title": "3 SIMS: SELF IMPROVEMENT WITH SYNTHETIC DATA", "content": "In this section, we develop the Self-IMproving diffusion models with Synthetic data (SIMS) framework for improving the performance of a diffusion model using its own synthetic data; we term this self-improvement. Note that while we explain SIMS in the context of unconditional diffusion models, our method extends to conditional diffusion models as well.\nSIMS: Extrapolating to Self-Improvement. Let us unpack the SIMS steps outlined in Algorithm 1 in the Introduction. Consider a base diffusion model characterized by the score function $s_{\\theta_1}(x_t, t)$"}, {"title": "4 EXPERIMENTAL RESULTS", "content": "In this section, we present the results of an array of computational experiments with SIMS. In Section 4.1 we demonstrate that SIMS makes significant progress on open question Q1 from the Introduction by self-improving the modeling performance of large-scale diffusion models using self-synthesized data. In Section 4.2 we demonstrate that SIMS makes significant progress on open question Q2 from the Introduction by acting as a prophylactic against MADness. In Section 4.3 we show how SIMS can adjust a diffusion model's synthetic data distribution to match any desired in-domain target distribution to mitigate biases and ensure model fairness."}, {"title": "4.1 SELF-IMPROVING DIFFUSION MODELS", "content": "Experimental Setup. We use four diverse real image datasets $D_r$ for performance evaluation: 32 \u00d7 32 resolution CIFAR-10 (50k images) , 64 \u00d7 64 resolution FFHQ-64 (70k images) , 64 \u00d7 64 resolution ImageNet-64 (1.2M images), and 512 \u00d7 512 resolution ImageNet-512 (1.2M images).\nFor CIFAR-10 and FFHQ-64, we use the unconditional Variance Preserving (VP) variant of the EDM diffusion model from as the base model for SIMS. For ImageNet-64 and ImageNet-512, we use the conditional EDM2-S model from . While we use RGB-space diffusion models for CIFAR-10, FFHQ-64, and ImageNet-64, the ImageNet-512 model operates as a latent diffusion model with a latent space dimensionality of 64 \u00d7 64 \u00d7 4. For all experiments with ImageNet-512, we keep the encoder-decoder VAE fixed and use Stability VAE as in . For all models, we use Heun's second-order solver for the de-noising process as proposed in ."}, {"title": "4.2 MAD PREVENTION USING SIMS", "content": "A fundamental assumption in training a generative model is that the training dataset $D$ consists exclusively of data that aligns with the ground-truth target distribution. When synthetic data generated by previous models is na\u00efvely included in $D$ in a self-consuming loop, the the supposed \"ground-truth\" distribution becomes increasingly distorted and ultimately goes MAD. In this section we study the abilities of SIMS to mitigate and even prevent MADness."}, {"title": "4.2.1 TWO DIMENSIONAL GAUSSIAN DATA IN A SYNTHETIC AUGMENTATION LOOP", "content": "We now use a simple low-dimensional experiment to demonstrate the effectiveness of SIMS in preventing the negative impacts of synthetic data training that can lead to MADness. Recall from Section 2 that demonstrating that SIMS prevents MAD for a sequence of models $(G_t)_{t\\in N}$ in a self-consuming loop requires showing that $E[dist(G_\\infty, p_r)] \\leq E[dist(G_1, P_r)]$.\nExperimental Setup. We start with the task of learning a simple two-dimensional Gaussian distribution $p_r = N(\\mu, \\Sigma)$ with mean $\\mu = [0,0]^T$ and covariance $\\Sigma = [2, 1; 1, 2]$ using a DDPM diffusion model. We sample a real dataset $D_1$ of size $|D_1| = 1000$ from $N (\\mu, \\Sigma)$ and train the base model $G_1 = A(D_r)$. We then form a synthetic augmentation loop, where for generation t of the loop, $G_t = A(D_r \\cup D_{t-1})$, where $D_{t-1}$ is synthetic data generated from the previous generation model $G_{t-1}$. We quantify the performance of the models in terms of the Wasserstein distance $dist(\\cdot, \\cdot)$ between the synthetic and real data distributions $E[dist(G_t, p_r)]$.\nWe compare two different training approaches:\n*   Standard training, where we train the generation-t model on the dataset $D^t = D_r \\cup D_{t-1}^S$ in which the real data is polluted with synthetic data from the previous generation.\n*   SIMS, where we train the generation-t base model on the polluted dataset $D^t$.\nFor both approaches, we trained the base model for 100 epochs on $D_r$. For SIMS, we obtained the auxiliary model at generation t by fine-tuning the base model for 50 epochs using $n_s = |S| = 2000$ data points synthesized from the base model. We calculated expectations over 1000 independent runs, with each run starting with a new real dataset $D_r$ drawn from $p_r$ and continuing the synthetic augmentation loop for 100 generations. When there is no guidance ($w = 0$), standard training and SIMS coincide and produce identical models."}, {"title": "4.2.2 REALISTIC DATA IN A SYNTHETIC AUGMENTATION LOOP", "content": "We continue our exploration of self-improvement and MADness prevention using realistic image data from the CIFAR-10 and FFHQ-64 datasets, large-scale diffusion models, and more pragmatic contexts regarding how the synthetic data enters the synthetic augmentation loop.\nWe compare four different training scenarios. The real dataset Dr (either CIFAR-10 or FFHQ-64) is the same in each scenario.\n*   First generation, standard training with purely real data, GST-1: This scenario corresponds to training a primordial model using standard training and exclusively real data Dr. As an archetype of today's lax data curation practices, data synthesized from GST-1, which we denote by Dp, pollutes the \u201creal\u201d training data of the last two second-generation models below.\n*   Second generation, ideal SIMS training with purely real data, G\u015cIMS-1: This wishful, idealized scenario corresponds to how synthetic data training should be performed: by applying SIMS to self-improve the base model GST that was trained on purely real data.\n-I\n*   Second generation, standard training with polluted real data, G\u015dr.p: This practical scenario corresponds to training a model using standard training with the polluted training data comprising the purely real data D\u2081 combined with synthetic data Dp generated by GST-1. We know from that this approach leads to MADness.\n*   Second generation, SIMS training with polluted real data, GSIMs-p: This practical scenario cor-responds to training a model using SIMS training with the same polluted training data comprising the purely real data D\u2081 combined with synthetic data Dp generated by GST-1\n2\nExperimental setup. For GST-1, we used the EDM-VP models pre-trained on CIFAR-10 and FFHQ-64 from . For CIFAR-10, we trained both GST-p and the base model in GSIMS-P from scratch for 200Mi. For FFHQ-64, to reduce computational costs, we fine-tuned GST-P and the base model in GSIMS-p for 100Mi rather than training from scratch. For the training sets S of the auxiliary models in SIMS, we generated |S| = 100k data from the corresponding base models. For each Dp, we report the best FID for G\u015cIMS-p over various values of guidance w and training budget B of the auxiliary model. The procedure for GSIMS-1 is identical to the self-improved models for CIFAR-10 and FFHQ-64 in Section 4.1, so we re-use those results here."}, {"title": "4.3 DISTRIBUTION SHIFTS WITH SIMS", "content": "Often, the datasets used for training AI models follow a distribution p that differs from some desired target distribution p. Consequently, the synthetic data distribution generated by a model will also reflect this discrepancy. This technical issue underlies why generative models tend to synthesize biased samples related to demographic factors such as gender and race, which leads to inaccurate representations across these attributes and potentially decreased fairness.\nIn this section, we demonstrate that SIMS can align the distribution of its generated images with an arbitrary in-domain target distribution that is distinct from the model's training data distribution p. Simultaneously, we aim to enhance the quality of individual samples. By doing so, SIMS has the potential to not only self-improve but also mitigate extant biases in a base model by shifting the model distribution towards a different distribution that promotes fairness.\nWe highlight SIMS' abilities for simultaneous self-improvement and distribution shifting with an example of altering group representation frequency using the FFHQ-64 dataset. This dataset comprises 70k images of faces varying in gender, age, and race, with an almost equal split of male and female subjects (51% female and 49% male). The pre-trained EDM-VP model trained on FFHQ-64 in generate synthetic samples that are 50.3% perceived female and 49.7% perceived male . This type of generation is arguably fair to both genders, but to demonstrate SIMS' ability to adapt to an arbitrary target distribution, our goal is to construct a model"}, {"title": "5 DISCUSSION", "content": "In this paper, we have developed Self-IMproving diffusion models with Synthetic data (SIMS), a new training algorithm for generative AI models designed to enhance the performance of diffusion models by using their own synthetic data. The key idea is to avoid aggregating the real and synthetic data together into one training dataset which can lead to a divergence between the model's distribution"}, {"title": "A ABLATION STUDIES FOR SIMS", "content": "In this section, we present ablations on the synthetic dataset size used for training the auxiliary model, FID for different number of function evaluations, and strategies for reducing number of function evalutions during inference.\nSynthetic dataset size. For ImageNet-64, we change the dataset size used for training the auxiliary model score function $s_{\\theta_2}(x,t)$, and present the FID over training budget. In Figure 8 (left), we see that increasing the dataset size allows obtaining better FID. However note that if $D_s \\rightarrow \\infty, s_{\\theta_2}(x,t) \\rightarrow s_{\\theta_1}(x, t)$, i.e., the score functions become identical and negative guidance yields no gain. Therefore increasing the synthetic dataset further to very large numbers may result in an decrease in FID.\nNumber of function evaluations. Number of function evaluations (NFE) refer to the number of times a score function is evaluated during denoising. For ImageNet-64 we compare NFE for the EDM2-S base model with and without SIMS. In Figure 8 (middle left), we see that naturally, with SIMS we need more function evaluations to achieve the lowest FID. At NFE= 40, FID for both with and without guidance cases are almost equal to 1.70. For the SIMS we use a guidance strength of w = 0.9 and the best FID auxiliary model trained upto 56 Mi seen during training.\nReducing number of function evaluations. For a fixed denoising step, SIMS uses twice the number of function evaluations (NFE) compared to the baseline method without any guidance. This results in doubling the inference time computation. We propose two strategies to reduce the NFE overhead.\nThe EDM model architecture consists of an encoder and a decoder, each responsible for half of the computations for one function evaluation. As illustrated in Figure 8 (middle right), during the fine-tuning of the base model, we froze the weights of the encoder and trained only the decoder part. At inference time, the encoder is shared between the base model and the auxiliary model, differing only in the decoder. Consequently, the effective number of function evaluations decreases from 2x to 1.5x. We observe that training only the decoder to obtain the auxiliary model slightly increases the minimum FID from 0.92 to 1.01 during fine-tuning while reducing the NFE from 2 to 1.5.\nThe second strategy involves applying guidance from the auxiliary model for a limited interval. To assess the impact of this guidance at different denoising steps, we compute the FID for SIMS with guidance applied to a limited interval $(t_1, t_h)$, rather than the default setting of (0, 32). As shown in Figure 8 (right), guidance is more crucial during the final denoising steps compared to the earlier ones. The results indicate that we can exclude the first 10 steps in the denoising process with only a minimal drop in FID, from 0.93 to 0.96. Utilizing the auxiliary model for guidance over a smaller number of intervals can effectively reduce inference time and costs."}, {"title": "F STANDARD TRAINING", "content": "Algorithm 2 Standard Training Procedure\nInput: Training dataset D\n1: Train diffusion model: Use dataset D to train the diffusion model using standard training, resulting in the score function $s_\\theta(x_t, t)$.\nSynthesize: Generate synthetic data from the model using the score function $s_\\theta(x_t,t)$.\nThe procedure of standard training is shown in Algorithm 2. Compared to SIMS (Algorithm 1), standard training is essentially the same as using only the base diffusion model's score function to generate synthetic data, which is equivalent to setting w = 0 in SIMS. It's important to note that if you already have a model trained using the standard approach, you can still apply steps 2-4 of SIMS to develop a self-improved model."}]}