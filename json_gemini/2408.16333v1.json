{"title": "Self-Improving Diffusion Models with Synthetic Data", "authors": ["Sina Alemohammad", "Ahmed Imtiaz Humayun", "Shruti Agarwal", "John Collomosse", "Richard Baraniuk"], "abstract": "The artificial intelligence (AI) world is running out of real data for training in- creasingly large generative models, resulting in accelerating pressure to train on synthetic data. Unfortunately, training new generative models with synthetic data from current or past generation models creates an autophagous (self-consuming) loop that degrades the quality and/or diversity of the synthetic data in what has been termed model autophagy disorder (MAD) and model collapse. Current thinking around model autophagy recommends that synthetic data is to be avoided for model training lest the system deteriorate into MADness. In this paper, we take a different tack that treats synthetic data differently from real data. Self-IMproving diffusion models with Synthetic data (SIMS) is a new training concept for diffusion models that uses self-synthesized data to provide negative guidance during the generation process to steer a model's generative process away from the non-ideal synthetic data manifold and towards the real data distribution. We demonstrate that SIMS is capable of self-improvement; it establishes new records based on the Fr\u00e9chet inception distance (FID) metric for CIFAR-10 and ImageNet-64 generation and achieves competitive results on FFHQ-64 and ImageNet-512. Moreover, SIMS is, to the best of our knowledge, the first prophylactic generative AI algorithm that can be iteratively trained on self-generated synthetic data without going MAD. As a bonus, SIMS can adjust a diffusion model's synthetic data distribution to match any desired in-domain target distribution to help mitigate biases and ensure fairness.", "sections": [{"title": "1 INTRODUCTION", "content": "Thanks to the ongoing rapid advances in the field of generative artificial intelligence (AI), we are witnessing a proliferation of synthetic data of various modalities that have been rapidly integrated into popular online platforms. The voracious appetite of generative models for training data has caused practitioners to train new models either partially or completely using synthetic data from previous generations of models. Synthetic training data is actually hard to avoid, because many of today's popular training datasets have been inadvertently polluted with synthetic data.\nUnfortunately, there are hidden costs to synthetic data training. Training new generative models with synthetic data from current or past generation models creates an autophagous (self-consuming) loop that can have a detrimental effect on performance. In the limit over many generations of training, the quality and/or diversity of the synthetic data will decrease, in what has been termed Model Autophagy Disorder (MAD) and Model Collapse. MAD generative models also have major fairness issues, as they produce increasingly biased samples that lead to inaccurate representations across the attributes present in real data (e.g., related to demographic factors such as gender and race).\nMADness arises because synthetic data, regardless of how accurately it is modeled and generated, is still an approximation of samples from the real data distribution. An autophagous loop causes any approximation errors to be compounded, ultimately resulting in performance deterioration and bias amplification.\nSafely advancing the performance of generative AI systems in the synthetic data era requires that we make progress on both of the following open questions:\nQ1. How can we best exploit synthetic data in generative model training to improve real data modeling and synthesis?\nQ2. How can we exploit synthetic data in generative model training in a way that does not lead to MADness in the future?\nIn this paper, we develop Self-IMproving diffusion models with Synthetic data (SIMS), a new learning framework for generative models that addresses both of the above issues simultaneously. Our key insight is that, to most effectively exploit synthetic data in training a generative model, we need to change how we employ synthetic data. Instead of na\u00efvely training a model on synthetic data as though it were real, SIMS guides the model towards better performance but away from the patterns that arise from synthetic data training.\nWe focus here on SIMS for diffusion models in the context of image generation, because their robust guidance capabilities enable us to efficiently guide them away from their own generated synthetic data. In particular, we use a base model's own synthetic data to obtain a synthetic score function associated with the synthetic data manifold and use it to provide negative guidance during the generation process. By doing so, we steer the model's generative process away from the non-ideal synthetic data manifold and towards the real data distribution."}, {"title": "2 BACKGROUND", "content": "Diffusion models. Let p denote the distribution we seek to model. Diffusion models gradually diffuse the training data over time t \u2208 [0, T] and sample from p by inversely modeling the forward diffusion process . Typically, this diffusion process involves transforming instances drawn from p into noisy versions with scale schedule $a_t$ and noise schedule $\\sigma_t$ at time t. Hence, the conditional distribution of the noisy sample $x_t$ at time t can be formalized as\n$q_t(x_t|x_0) = N(x_t | \\mu = a_tx_0, \\Sigma = \\sigma_tI),$ (1)\nwhere $x_0$ is the data instance drawn from p. The diffusion process can be formalized using a stochastic differential equation (SDE)\ndx = f(x,t)dt + g(t)dw, (2)\nwhere w is the standard Wiener process. Different choices for f(x, t) and g(t) result in different scaling $a_t$ and noise $\\sigma_t$ schedules in (1). We refer the reader to  for more details on different SDE formulations for diffusion models.\nThe solution to the SDE in (2) is another SDE described by\ndx = [f(x, t) - g^2 (t)\\nabla_{x_t} log q_t (x_t)]dt + g(t)dw, (3)\nwhere $\\bar{dw}$ is the standard Wiener process when time flows in the reverse direction, and $q_t$ is the unconditional distribution in (1) obtained by the forward SDE through (2). The solution of the SDE in (3) starting from the samples of $x_T \\sim q_T$ results in samples $x \\sim q(x_0)$ that enable data generation from p.\nSince the score function $\\nabla_{x_t} log q_t(x_t)$ is unknown, the objective is to train a neural network with parameters $\\theta$ to approximate the score function $s_\\theta(x_t, t) \\approx \\nabla_{x_t} log q_t (x_t)$ through\n$\\min_{\\theta} E_{t\\in[0,T], x_0 \\sim D} [\\lambda(t)||s_\\theta(x_t, t) - \\nabla_{x_t}log q_t (x_t)||^2],$ (4)\nwhere $D$ is the training set containing samples from p, and $\u03bb(t)$ is a temporal weighting function. The SDE in (3) can be solved by replacing $\\nabla_{x_t} log q_t (x_t)$ with $s_\\theta(x_t, t)$ and performing numerical integration. For conditional generation, one can also impose a condition on the score function during training to obtain the conditional score.\nSelf-consuming generative models. Let $A(\\cdot)$ represent an algorithm that, given a training dataset $D$ as input, constructs a generative model with distribution $G$, i.e., $G = A(D)$. Consider a sequence of generative models $G_t = A(D_t)$ for $t \\in N$, where each model approximates some reference (typically real data) probability distribution $p_r$.\nDefinition 1. Self-consuming (autophagous) loop : An autophagous loop is a sequence of distributions $(G_t)_{t\\inN}$ where each generative model $G_t$ is trained on data that includes samples from previous generation models $(G_{t-1})_{t=1}$.\nDefinition 2. Model Authophagy Disorder (MAD) : Let dist(\u00b7, \u00b7) denote a distance metric on distributions. A MAD generative process is a sequence of distributions $(G_t)_{t\\inN}$ such that $E[dist(G_t, p_r)]$ increases with t."}, {"title": "3 SIMS: SELF IMPROVEMENT WITH SYNTHETIC DATA", "content": "In this section, we develop the Self-IMproving diffusion models with Synthetic data (SIMS) framework (recall Algorithm 1) for improving the performance of a diffusion model using its own synthetic data; we term this self-improvement. Note that while we explain SIMS in the context of unconditional diffusion models, our method extends to conditional diffusion models as well.\nSIMS: Extrapolating to Self-Improvement. Let us unpack the SIMS steps outlined in Algorithm 1 in the Introduction. Consider a base diffusion model characterized by the score function $s_{\\theta_1} (x_t, t)$"}, {"title": "F STANDARD TRAINING", "content": "The procedure of standard training is shown in Algorithm 2. Compared to SIMS (Algorithm 1), standard training is essentially the same as using only the base diffusion model's score function to generate synthetic data, which is equivalent to setting w = 0 in SIMS. It's important to note that if you already have a model trained using the standard approach, you can still apply steps 2-4 of SIMS to develop a self-improved model."}]}