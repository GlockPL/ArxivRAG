{"title": "Network evasion detection with Bi-LSTM model", "authors": ["Kehua chen", "JingPing Jia"], "abstract": "Network evasion is a way to disguise data traffic by confusing network intrusion detection systems. Network evasion detection is designed to distinguish whether a network traffic from the link layer poses a threat to the network or not. At present, the traditional network evasion detection method does not extract the characteristics of network traffic and the detection accuracy is relatively low. In this paper, a novel network evasion detection framework has been proposed to detect eight atomic evasion behaviors which are based on deep recurrent neural network. Firstly, inter-packet and intra-packet features are extracted from network traces. Then a bidirectional long short-term memory (Bi-LSTM) neural network is trained to encode both the past and the future traits of the network traces. Finally, on the top of the Bi-LSTM network, a Softmax layer is used to classify the trace into the correct evasion class. The experimental results show that the average detection accuracy of the framework reaches 96.1%.", "sections": [{"title": "1 Introduction", "content": "Evasions can be applied to normal traffic, as well as to attacks. However, advanced evasion is able to disguise attacks to avoid detection and blocking by the network security system. Evasions are considered successful as long as the delivery mechanism succeeds in gaining access to victim computers while the security device fails to detect or respond to the attack. However, there are not effective ways to detect network evasions. When faced with a large volume of network flows, existing methods have various deficiencies.\nCheng [1] described five common techniques that can evade the examination of an IPS. They are DOS, packet splitting, duplicate insertion, payload mutation and shell code mutation. Varghese and Antichi [2-3] proposed to cut the signature into splits and match them in the split signatures without reassembly, but their methods are still vulnerable to other evasion techniques. Zigang, XIONG [4] proposed a two-phased method for the detection of malware communication channels, but it's still limited to detect limited evasion types in a small TCP/IP network.\nIn this paper, we propose to tackle the evasion problem from the view of machine learning and present a network evasion detection framework based on deep recurrent neural network. First, we describe the features extracted from evasion flows. Then we take an overview of Long Short Term Memory Network (LSTM) [5] and Bidirectional Recurrent Neural Network (Bi-RNN). Both of them were proposed in 1997 by Mike Schuster and Kuldip K. Paliwal[6] which successfully had overcome the deficiency of long term dependencies."}, {"title": "2 Features", "content": "Normal network flows were extracted from an intranet network flows. Eight evasion techniques, which are ip_chaff, ip_frag, ip_opt, ip_ttl, ip_tos, tcp_chaff, tcp_opt and tcp_seg were applied to the normal network flows. Intra-packet and inter-packet features were extracted from trace files of each type of evasion technique to form samples of each evasion class. The choice of features aims to reflect the characteristics of each evasion technique."}, {"title": "3 Evasion Detection Model", "content": "In our evasion detection model, a deep recurrent neural network based on LSTM is built to encode the feature sequences extracted from network flows. As a variant of RNN, LSTM just replaces RNN cells with LSTM cells. A bidirectional recurrent neural network (bi-RNN) is an extension of RNN that learns the input information twice from left to right and from right to left. Bidirectional LSTM (Bi-LSTM) is a bi-RNN counterpart based on LSTM.\nAs described previously, an LSTM cell only has a forward conduction and each unit is influenced only by the previous unit. However, in network evasion, the future part of information is equally important with the past one. The structure of a Bi-LSTM shows in Figure 1-\n(a). In that way, Bi-LSTMs can effectively make use of past states and future states in a specific period.\nSpecifically, we adopt Bi-LSTM combining the Softmax [7] for evasion detection as illustrated in Figure 1-(b). The input is a feature sequence of time-series from a series of evasion, $(x_{(1)},x_{(2)},...,x_{(t)})$, the input is divided into a fixed structure and accordingly fed to the LSTM unit one by one. When finishing feeding one batch size network flow, the whole network model begins the backpropagation to complete training."}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Dataset", "content": "Experiments were carried out based on the databases crawled on the network. We transformed crawled data and then saved the features into numpy files separately. Each file contains a feature sequence with its length ranging from 3 to 7, holding 16 dimensions. We randomly split them into a training set with 183411 numpy files and a testing set with 45853 numpy files for subsequent works."}, {"title": "4.2 Experimental setup", "content": "To update the network parameters fast, we set the train batch size to 50, the frame size to 5, and the number of hidden layer cells to 128 with Adam optimizer initially. The experimental results show that the Adam optimizer can ensure stable convergence and average accuracy of 97.01%. Since the dataset is large enough, there is no need to apply dropout."}, {"title": "4.3 Learning Rate and Batch size", "content": "The learning rate determines the speed which the parameter moves to the optimal value. Excessive learning rates probably lead to consequences missing the optimal parameters, while with lower learning rates, optimization efficiency is likely to be unsatisfactory and algorithm takes a long time (as shown in Table 2 and Figure 3) to converge.\nA fixed two-layer network was chosen, and different numbers of hidden cells were tested, but without observable differences. However, it is obvious that the higher the batch size in the experiment is, the shorter the required time it needs. As shown in Figure 3-(d), using different numbers of hidden layers does not cause significant differences."}, {"title": "4.4 Optimization methods and Regularization methods", "content": "Seemingly the Adam and RMS out-perform other optimizers whatever lr(learning rate) and dropout are. In all training results, the classification accuracy is the lowest when the frame size is 3, which is caused by insufficient information. There is a slightly degradation when frame size comes to 7, which is because the original files were scarce and lots of data were dropped out. We also tried both dropout and standard L2 regularization in the initial experiments. It is trustable that dropout can beat the over-fitting when a larger dataset is accessible in the future."}, {"title": "5 Conclusions", "content": "In this paper, we addressed the network evasion detection problem from the view of sequence classification task. Specifically, we proposed to use Bi-LSTM network to encode both past and future features of the produced evasion network flows and classify new network traces to correct evasion type. Conclusions are as follows: 1) Bi-LSTM significantly outperforms unidirectional LSTM in network evasion detection. 2) Model with one or two layers achieves superior performance. 3) The performance varies on different tricks such as learning rate, optimization and regularization method. Further study may consider the detection of combination of two or more atomic evasions."}]}