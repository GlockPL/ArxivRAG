{"title": "Chain-of-Strategy Planning with LLMs: Aligning the Generation of Psychotherapy Dialogue with Strategy in Motivational Interviewing", "authors": ["Xin Sun", "Xiao Tang", "Abdallah El Ali", "Zhuying Li", "Xiaoyu Shen", "Pengjie Ren", "Jan de Wit", "Jiahuan Pei", "Jos A. Bosch"], "abstract": "Recent advancements in large language models (LLMs) have shown promise in generating psychotherapeutic dialogues, especially in Motivational Interviewing (MI). However, how to employ strategies, a set of motivational interviewing (MI) skills, to generate therapeutic-adherent conversations with explainability is underexplored. We propose an approach called strategy-aware dialogue generation with Chain-of-Strategy (CoS) planning, which first predicts MI strategies as reasoning and utilizes these strategies to guide the subsequent dialogue generation. It brings the potential for controllable and explainable generation in psychotherapy by aligning the generated MI dialogues with therapeutic strategies. Extensive experiments including automatic and human evaluations are conducted to validate the effectiveness of the MI strategy. Our findings demonstrate the potential of LLMs in producing strategically aligned dialogues and suggest directions for practical applications in psychotherapeutic settings.", "sections": [{"title": "1 Introduction", "content": "Motivational interviewing (MI) is a client-centered counseling technique aimed at encouraging individuals to change behaviors (Miller and Rollnick, 2002). It can boost intrinsic motivation and collaboration between therapists and clients by effectively addressing ambivalence and enhancing self-efficacy (Martins and McNeil, 2009a), improving clients' adherence to the interventions (Alperstein and Sharpe, 2016). Key to ensuring MI's effectiveness are strategic schemes, such as motivational interviewing skill code (MISC) (Miller et al., 2002). Traditional psychotherapy (e.g., MI) chatbots produce therapeutic dialogues through expert-written scripts and rules (Xu and Zhuang, 2020; Park et al., 2019; Zhang et al., 2020a; Sun et al., 2023). The reliance on scripted content not only yields dialogues that are rigid and lack diversity but also necessitates extensive domain expertise and efforts for conversational design. The advent of Natural Language Generation (NLG) (Dong et al., 2022) marks a shift from these pre-scripted applications. Several MI chatbots focus on rephrasing client utterances and generating MI dialogues with templates (Almusharraf F, 2020; He et al., 2022; Min et al., 2023). Works in natural language generation (NLG) (Dong et al., 2022; Gatt and Krahmer, 2018) explore how to integrate therapeutic expertise, such as counseling strategies, into dialogue generation process (Welivita and Pu, 2023; Tu et al., 2022; Li et al., 2023). However, this is limited by reliance on domain-specific data required by traditional approaches in NLG. The emergence of Large language models (LLMs) (Naveed et al., 2023) presents new prospects for generating diverse, flexible, and engaging dialogues. Besides, in-context learning with few-shot capabilities enables the integration of MI expertise into the generation process (Madotto, 2020; Peng et al., 2020). However, LLMs-generated dialogues face challenges in being controllable and explainable in sensitive contexts like psychotherapy (Sun et al., 2024). Inspired by prior work about strategy-aware dialogue generation (Welivita and Pu, 2023; Tu et al., 2022; Li et al., 2023) and the concept of Chain-of-Thoughts (Wei et al., 2023; Wang et al., 2023a), we explore utilizing LLMs to predict the next therapist's MI strategy, i.e., MISC behavioral code with its definition as internal reasoning, and generate the subsequent utterance strictly following the planned MI strategy. We thereby seek to answer the following research questions:"}, {"title": "(RQ1) Can LLMs generate dialogues that (a) align with MI strategies and (b) are comparable to those from human therapists?", "content": null}, {"title": "(RQ2) How effective the CoS planning with LLMs is for MI dialogue generation?", "content": "To address them, we conduct extensive experiments to assess the effectiveness of strategy-aware dialogue generation with CoS planning through automatic and human evaluations. MI experts assess both effectiveness of CoS planning and the alignment between generated dialogues and LLM-planned MI strategies. Our findings demonstrate that MI strategy can effectively instruct LLMs to generate dialogues adherent to MI principles. It enables the controllability and explainability of utilizing LLMs in real-world MI applications. The contributions of this work are three-fold: 1) We propose an approach to generate psychotherapeutic dialogues with LLMs in a controllable and explainable manner using MI strategies. 2) We conduct extensive experiments to validate the proposed approach through both automatic and human evaluations. 3) We provide theoretical proof and analysis for the empirical findings."}, {"title": "2 Related Work", "content": null}, {"title": "2.1 NLG in Motivational Interviewing", "content": "Motivational Interviewing (MI) is a therapeutic counseling technique aimed at encouraging intrinsic motivation to change behaviors (Miller and Rollnick, 2002; Martins and McNeil, 2009b). Experts examine MI with strategic schemes such as the Motivational Interviewing Skill Code (MISC) (Miller et al., 2002), which help assess the effectiveness of MI sessions, focusing on essential counseling skills and adherence to MI principles. The role of NLG in MI has revolutionized the way therapeutic support is provided. Initially, NLG in MI was limited to replicating ongoing conversations, relying on pre-scripted templates from MI experts (Almusharraf F, 2020; He et al., 2022; Welivita and Pu, 2023). However, the rapid advancements in LLMs enable these models can rephrase what clients say, reflecting their words or even emotions, in ways that feel empathetic (Dieter et al., 2019; Rose et al., 2022; Shen et al., 2020), showing promising results in enhancing client engagement and adherence to therapeutic goals. Despite these benefits, the integration of NLG in MI applications faces significant challenges, particularly in ensuring the generated content adherent to MI principles."}, {"title": "2.2 Strategy-Aware Dialogue Generation", "content": "The strategy-aware dialogue generation (Li et al., 2023) marks a significant shift in NLG, moving from focusing on linguistic fluency to incorporating strategic dialogue objectives. This transition is evident in the progression from rule-based systems, which rely on static dialogue scripts, to generative models that adapt to dialogue contexts and strategic instructions (Welivita and Pu, 2023; Li et al., 2023). These work on making generative models \"strategy-aware\u201d and able to engage in \u201cmixed-initiative\" dialogues (Tu et al., 2022; Deng et al., 2023), where the models and users can both lead the conversation with specific instructions. In the realm of therapeutic dialogue generation, strategy-aware approaches have taken on significant efforts by (Yang et al., 2024; Shah et al., 2022; Rashkin et al., 2019; Gao et al., 2023) highlight the importance of embedding psychological and empathetic principles into responses, aiming for alignment with therapeutic goals while maintaining conversational empathy (Sharma et al., 2023). It inspires the applications of LLMs in MI. Through instructing LLMs with MI strategies, we expect LLMs can generate more strategically aligned and MI-adherent dialogues, thereby controlling LLMs with MI principles. Besides, the advanced reasoning capabilities of LLMs such as (Wei et al., 2023) enable LLMs to do the next strategy prediction as internal reasoning following the work in (Cao et al., 2019)."}, {"title": "2.3 Chain-of-Thought Reasoning with LLMs", "content": "There have been explorations in prior work about the Chain-of-Thought concept (CoT) (Wei et al., 2023), aimed at enhancing the reasoning process in LLMs. Innovations such as auto-cot (Zhang et al., 2022; Shum et al., 2023), self-consistency by (Wang et al., 2023b), and active prompt by (Diao et al., 2023) have sought to enhance the LLMs by refining various reasoning process. Besides, in-context learning highlighted by (Brown et al., 2020), has emerged as a critical approach for leveraging LLMs effectively, focusing on the strategic selection of informative prompts (Fu et al., 2023). For dialogue generation, these advancements are pushing the capabilities of LLMs further, with the CoT technique enabling dialogue generation that is not only effectively instructed but also coherent and contextually accurate (Wang et al., 2023a). This signals a promising direction for future conversational applications to engage users in interactions in sensitive domains such as psychotherapy, by leveraging advanced reasoning and tailored expertises."}, {"title": "3 Method", "content": null}, {"title": "3.1 Strategy-Aware Dialogue Generation with Chain-of-Strategy Planning", "content": "Inspired by (Li et al., 2023), we develop an approach to generate MI dialogues with LLMs guided by domain-specific MISC strategies (Miller et al., 2002), thereby making LLMs align to strategies with controllability and explainability. We employ the concept of Chain-of-Thought (CoT) (Wei et al., 2023; Zhang et al., 2022), enabling LLMs to internally reason the next MI strategies as the prediction based on dialogue context, which we call \"Chain-of-Strategy (CoS) Planning\". LLMs subsequently generate dialogues guided by the predicted MI strategy. For example, LLMs can generate empathetic utterances to promote therapeutic support guided by MI strategies \u201cReflection\". Figure 1 demonstrates our proposed approach \"strategy-CoS\", which is a combination of strategy-aware MI dialogue generation with CoS Planning."}, {"title": "3.2 Prompt Design", "content": "We design three prompting methods for our experimental purpose, including the Standard Prompt, Strategy-CoS Prompt, and Strategy-GT (abbr. for Ground Truth) Prompt as illustrated in Figure 1. Detailed prompt design is attached in Appendix."}, {"title": "3.2.1 Standard Prompt", "content": "For the standard prompt, we only include the dialogue context and task instruction to generate the next therapist's utterances. The objective is defined as below. \"c\" represents the MI dialogue context; \"u\" represents the next utterance of the therapist we expect the LLM to generate; \u201ck\u201d is the number of dialogue sizes in the context and we choose it as 5:\n$M: C_{i-k,i-1} \\rightarrow U_i$    (1)"}, {"title": "3.2.2 Strategy-CoS", "content": "Compared with the standard prompt, the strategy-CoS prompt is dynamic to give more specific information to LLMs. Specifically, We first ask LLM to predict the next MISC strategy for therapists as the internal reasoning and use this strategy as the internal state in subsequent MI dialogue generation process. Strategy-CoS has three elements: 1) the MI dialogue context; 2) the definition of MISC strategies (Miller et al., 2002). 3) the LLM-predicted MI strategy for the next therapist's response by \u201cCOS Planning\" (i.e., the type of MI strategy we expect the LLM to generate). We define the objective as follows, in which \u201cs\u201d stands for MISC strategies; \"d\" stands for the definition of MISC strategies:\n$M: C_{i-k,i-1}, S_{i-k,i-1}, d_{str} \\rightarrow S_i \\rightarrow U_i$   (2)"}, {"title": "3.2.3 Strategy-GT", "content": "The strategy-GT prompt is a special case of strategy-CoS, which utilizes the ground-truth strategy of the next therapist's response pre-annotated in datasets instead of the LLM-predicted one. It includes three elements: 1) the MI dialogue context; 2) the ground-truth MISC strategy for the next therapist's response. 3) the definition of the MISC strategies. The objective is as follows:\n$M: C_{i-k,i-1}, S_{i-k,i}, d_{str} \\rightarrow U_i$    (3)"}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Task Definition", "content": "We conduct comparative experiments across benchmark LLMs under prompting types to understand their performances in generating MI-adherent dialogues. Therefore, we define the experimental tasks in two steps: (RQ1) we first explore whether MI strategy can guide LLMs for controllable and strategic-aligned MI dialogues \u201cgeneration\"; (RQ2) we then examine the performance of Chain-of-Strategy (CoS) planning with LLMs, which is a \"prediction\" task, and whether CoS planning as the internal reasoning can enhance LLMs for the subsequent MI dialogue generation. The procedure of experiments is illustrated in Figure 2"}, {"title": "4.2 Datasets", "content": "Two MI datasets are used with MI conversations and MI strategy annotated by the scheme called MISC (Miller et al., 2002). The first dataset is \"AnnoMI\" (Zixiu et al., 2022; Wu et al., 2023) which has MI conversations and a single coarse-grained MI strategy per utterance. The second dataset is \"BiMISC\" (Sun et al., 2024) with MI conversations and multiple fine-grained MI strategies per utterance. Table 1 is an example of MI dialogues and MI strategies in two datasets. Detailed MI strategies are attached in Appendix."}, {"title": "4.3 Benchmark LLMS", "content": "We benchmark several prominent LLMs, focusing on LLMs renowned for their size, performance, and open-source nature. We select six open-sourced LLMs: Flan-t5-xxl, Vicuna-13B, Qwen-14B, Qwen2-7B, Llama-2-13B, and Llama-3-8B. All these open-sourced LLMs are recognized for their capability to align closely with human instructions (Ouyang et al., 2022), particularly in dialogue interactions. Additionally, we choose GPT-4 as a commercial benchmark, noted for its superior performance in dialogue scenarios."}, {"title": "4.4 Automatic Evaluation Metrics", "content": "To objectively evaluate the quality of generations, we apply following automatic evaluation metrics.\n\u2022 BLEU-n (Papineni et al., 2002) assesses the accurate alignment of words. We measure n = 1, 4.\n\u2022 ROUGE-L (Lin, 2004) measures the overlap of n-grams between the generation and reference.\n\u2022 METEOR (Banerjee and Lavie, 2005) evaluates semantic and syntactic accuracy, including synonym and paraphrase use for linguistic precision.\n\u2022 BERTScore (Zhang et al., 2020b) assesses semantic similarity by BERT embeddings, measuring contextual relevance of generations.\n\u2022 Entropy (Wikipedia, 2024) quantifies the unpredictability and assesses the effectiveness of strategy in controlling generation. Lower entropy indicates more aligned responses.\n\u2022 Belief (Wei et al., 2022) is for hypothesis testing updates posterior probabilities of generations under both hypotheses ($H_0$: MI strategies are effective, and $H_1$: they are not). The mathematic derivation is in Appendix."}, {"title": "4.5 Human Evaluation", "content": "We employ expert evaluation to capture the therapeutic alignment of generated dialogues and adherence to LLM-planned strategy with MI principles. We select 100 MI dialogue contexts from datasets. The expert assessment involving five experts explores the nuanced effectiveness of strategy-aware MI dialogue generation by LLMs integrating CoS planning. The expert assessment focuses on six criteria (EC): (EC1+) how effectively the MI strategy guides the generation of utterance; (EC2-) how independent the generated utterance is with the MI strategy; (EC3+) how well the generated utterance aligns with the dialogue context; (EC4+) how well the generated utterance aligns with the MI principles; (EC5+) how the quality of the generated utterance compares to that of a human therapist. (EC6+) how well the MI strategy aligns with the dialogue context and MI principles. The first five criteria (EC1-EC5) assess the strategic alignment of the generated utterances with the MI strategy. The sixth criterion (EC6) assesses the effectiveness of Chain-of-Strategy (CoS) planning with LLMs adherent to MI principles. Detailed assessing statements of these criteria are in Table 3. Moreover, we are interested in client perceptions."}, {"title": "5 Outcomes", "content": null}, {"title": "5.1 Empirical Analysis on Automatic Metrics", "content": "Table 2 indicates the standard prompt yields the lowest scores in automatic metrics. This outcome shows that strategy-aware generation with MI strategy can effectively instruct LLMs to generate dialogue following specific MI principles (RQ1.a). Besides, the commercial GPT-4 model consistently achieves the highest scores across metrics. However, notable is the performance of open-sourced LLMs Flan-T5, Vicuna-13B and Qwen2, which closely rivals that of GPT-4. This highlights the significant advancements in open-sourced LLMs. To comprehensively evaluate the effectiveness of MI strategy for MI-adherent dialogue generation, we employ Bayesian inference (Wei et al., 2022). It allows to update belief for the hypothesis by considering multiple automatic metrics in Table 2 (i.e., BLEU, ROUGE, BERTScore and Entropy). During the experiment, we calculate the likelihood of each generation for both hypotheses: Ho (MI strategy is effective for dialogue generation) and H1 (MI strategy is not effective). By iteratively updating the posterior probabilities of all generations, we derive an empirical measure of belief in the effectiveness of MI strategy for controlling LLMs. Moreover, to understand how LLMs utilize MI strategies in dialogue generation, Figure 3 visualizes the attention distribution of the LLM generations with and without the MI strategy. The attention distribution for the strategy-aware generation shows a significantly denser focus on the MI strategy compared to other prompting components (task instruction and conversational context)."}, {"title": "5.2 Role of Strategy in Guiding MI Dialogue Generation (RQ1)", "content": "In experts evaluation, MI experts assess the alignment and quality of dialogues generated by LLMs with three prompting methods in Section 3.2. The expert assessments focus on how well the generated utterances align with the MI strategies and dialogue context. Figure 4 shows that \u201cstrategy-GT\" and \u201cstrategy-CoS\" are more effective in guiding the generation of utterances than standard prompt by criteria EC1 and the generated utterances have more dependence on MI strategy (EC2), proving the effectiveness of MI strategy in aligning dialogue generation with MI principles (RQ1.a). Besides, the quality of generated utterances across all prompts remains comparably high (EC3 & EC4), each achieving above-average scores compared to human therapist's utterances (EC5) (RQ1.b), indicating the potential of LLMs in generating therapeutic dialogues in MI. One-way ANOVA analysis (Girden, 1992) on expert ratings shows that MI strategy has significantly positive influences on generations across prompting methods, with p = .05 in AnnoMI and p = .03 in BiMISC. Thus, expert evaluation solves our first research question that MI strategy can guide LLMs to generate dialogues that are strictly aligned with MI principles and are comparable to those of human therapists. Laypeople's evaluations offer insights into client perceptions. Figure 5 shows that Vicuna's generations using \"strategy-GT\" scored higher than the standard prompt and references, while GPT-4 shows the opposite trend. However, these differences were not statistically significant. Further analysis reveals that although strategy-aware generations align better with MI principles, they may not resonate as well with lay evaluators, particularly in the dimension of 'empathy,' which scored lower in strategy-aware generations."}, {"title": "5.3 CoS Planning as Reasoning Step (RQ2)", "content": "For RQ2, we aim to explore whether Chain-of-Strategy (CoS) planning can enhance LLM reasoning for subsequent MI-aligned dialogue generation. Building on prior work (Cao et al., 2019), we first compare benchmark LLMs for CoS planning (i.e., the prediction task). As shown in Table 4, the GPT-4 model achieves the highest prediction accuracy. The accuracy drops in BiMISC with multiple fine-grained strategies compared to AnnoMI with single coarse-grained strategy, indicating higher complexity of multi-label prediction in this context. \"Case Study\" gives an example of how an LLM-planned MI strategy could be still aligned with context and MI principle, although the strategy is incorrectly classified compared to ground truth."}, {"title": "6 Case Study", "content": "This case study aims to shed light on: 1) nuanced discrepancy between therapeutic strategic alignment and client perception; 2) how LLM-planned strategies can still align with MI principles and context, even if they differ from ground-truth strategy. As shown in Table 5, experts give higher scores for alignment between generated utterances and strategy in \"strategy-GT\u201d and \u201cstrategy-CoS\u201d compared to standard prompt, indicating that strategy-aware generations are more aligned with MI principles. However, lay evaluators rate generations of standard prompt higher, especially in dimension of \"empathy\". The utterance \u201cHave you noticed [...] since you reduced the cigarettes you smoke?\u201d generated by \"strategy-GT\u201d is strictly aligned with MI strategy \"closed question\", whereas the standard prompt generates \"That's good to hear. [...], every small step is progress.\" reflects more empathy as it is MI strategy of \"reflection.\" Laypeople may perceive dialogues incorporating strict MI strategies as rigid or lacking emotional nuances, suggesting a gap between strategic alignment and client perceptions. This underscores the complexity of translating MI adherence into dialogues perceived as empathetic, highlighting the need for LLMs to balance MI strategies with greater flexibility and naturalness in psychotherapeutic conversations. Moreover, LLM-planned strategy \u201caffirm; closed question\" in \"strategy-CoS\" receives a higher alignment score (5.0) than the ground-truth strategy (3.0), indicating its effectiveness and empathy, and illustrating the potential of CoS planning with LLMs. Therefore, expert evaluations argue that while the prediction accuracy of CoS planning may not be extremely high (Table 4), some inaccurately predicted strategies are still appropriate and adhere to MI principles within the specific dialogue context, due to the non-uniqueness of next MI strategy."}, {"title": "7 Discussion", "content": null}, {"title": "7.1 Strategy-Aware MI Dialogue Generation", "content": "Current MI applications rely heavily on expert pre-scripted dialogues, which are effort-consuming and require significant domain expertise. These pre-scripted dialogues often lack diversity, which is crucial in MI. LLMs present a promising solution by generating diverse and coherent dialogues, reducing dependency on pre-scripted content. This not only saves time and resources but also introduces a greater variety of responses, enhancing the personalized and adaptive nature of MI dialogues. However, the uncontrollable nature of LLMs poses risks in sensitive areas like psychotherapy. LLM-generated dialogues can deviate from MI principles and therapeutic goals, potentially leading to inappropriate outputs. This is where strategic alignment with MI principles becomes critical. Ensuring LLM-generated content adheres to MI guidelines safeguards against deviations that could undermine the therapeutic process. Integrating MI strategies into dialogue generation helps LLMs produce utterances that are both relevant and consistent with MI principles. Additionally, therapeutically strategic alignment provides explainability in MI dialogue generation, which is essential for applying LLMs in sensitive contexts like psychotherapy. It enhances the safety and perceived trustworthiness of LLM-generated outputs, making the integration of LLMs into MI applications more acceptable. Extensive evaluations in this work indicate the great potential of our proposed approach, \u201cstrategy-CoS\", for MI dialogue generation. Ensuring that LLMs follow MI strategies bridges the gap between automated dialogue generation and the therapeutic requirements of effective MI. Incorporating CoS planning enhances the capability of LLMs by internal reasoning, making generated dialogues more effectively aligned with MI strategies."}, {"title": "7.2 Challenges of Applying LLMs in MI", "content": "Applying LLMs in MI presents distinct challenges. This work indicates that strategy can effectively guide generated dialogues adherent to MI principles. While strategy-instructed utterances are technically precise within therapeutic goals, they may lack naturalness and empathy, which laypeople may prioritize (Syed et al., 2024). This highlights the need for a balance between empathetically engaging utterances and those aligned with MI principles. Achieving this balance is crucial for the success of LLM-assisted psychotherapeutic tools. These tools must meet professional standards while authentically resonating with people, ensuring both technical accuracy and genuine human connection. Moreover, the way LLM-generated utterances influence dialogue flow is pivotal. For instance, the generated question utterances could alter the expected course of therapist-led interactions, affecting the ongoing dialogue flow in MI. CoS planning provides the potential to ensure that dialogues are contextually relevant and adhere to MI principles. It makes the generative and mixed-initiative systems (Tu et al., 2022) more controllable and aligned with domain expertise. However, inappropriately planned strategies could lead dialogues in unintended directions, detracting from the therapeutic goals. Enhancing LLMs' ability to accurately understand and plan MI strategies at each reasoning step is key to ensuring dialogues remain on course. Future advancements in LLM reasoning enhanced by domain adaption and fine-tuning are crucial to overcoming these challenges and maximizing the potential of LLM-generated therapeutic dialogues."}, {"title": "8 Conclusion", "content": "This work tackles the challenge of utilizing LLMs in the sensitive domain of psychotherapy, confronted by the uncontrollable nature of LLMs. We come up with an approach to guide LLMs in generating MI strategy-aligned dialogues. We conduct extensive experiments and analyses with automatic and human evaluations to validate that the MI strategy can effectively instruct LLMs to generate dialogues adherent to MI principles. The findings also highlight the need for balancing strategic alignment with empathetic engagement in psychotherapeutic interactions. We provide a controllable and explainable solution for MI dialogue generation by LLMs, setting a foundation for future research to enhance the efficacy of LLMs in psychotherapy."}, {"title": "Limitations", "content": "While this work provides valuable insights, several limitations should be acknowledged. First, the generalizability of our findings is limited by the specific datasets used, which may not cover the entire spectrum of MI scenarios. Expanding the dataset to include a more diverse range of MI scenarios and client demographics could improve the generalizability of the findings. Second, while \u201cstrategy-CoS\" offers a feasible approach to guide LLMs in MI dialogue generation, it may not fully capture the dynamic nature of human therapeutic communication and emotional nuances of client and therapist interaction. Enhancing the models with advanced techniques like domain adaption, fine-tuning, or grounded with domain-specific knowledge bases to better capture these dynamic and emotional nuances could help. Third, the reliance on subjective human evaluations and traditional automatic metrics might not capture the full mental resonance and therapeutic effectiveness of the dialogues. To develop and incorporate more nuanced and comprehensive evaluation metrics could help. Fourth, while the study assesses strategic alignment with MI principles, it does not measure the impact of generated dialogues on actual therapeutic outcomes like client motivation or behavior change. The practical application of LLM-empowered MI in real-world settings remains untested, and their effectiveness in live sessions needs empirical validation. Additionally, deploying LLMs in therapeutic contexts raises further ethical concerns, including handling sensitive information and potential biases in the generated content. Future research could conduct longitudinal studies to evaluate long-term effects, pilot studies or controlled trials to test real-world effectiveness with comprehensive ethical considerations. Future work will focus on expanding datasets, refining LLM capabilities to capture nuanced human conversational interactions, and conducting empirical studies to validate the effectiveness and ethical deployment of LLMs in live therapeutic settings."}]}