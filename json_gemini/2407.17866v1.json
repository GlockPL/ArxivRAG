{"title": "Financial Statement Analysis with Large Language Models", "authors": ["Alex G. Kim", "Maximilian Muhn", "Valeri V. Nikolaev"], "abstract": "We investigate whether an LLM can successfully perform financial statement analysis in a way similar to a professional human analyst. We provide standardized and anonymous financial statements to GPT4 and instruct the model to analyze them to determine the direction of future earnings. Even without any narrative or industry-specific information, the LLM outperforms financial analysts in its ability to predict earnings changes. The LLM exhibits a relative advantage over human analysts in situations when the analysts tend to struggle. Furthermore, we find that the prediction accuracy of the LLM is on par with the performance of a narrowly trained state-of-the-art ML model. LLM prediction does not stem from its training memory. Instead, we find that the LLM generates useful narrative insights about a company's future performance. Lastly, our trading strategies based on GPT's predictions yield a higher Sharpe ratio and alphas than strategies based on other models. Taken together, our results suggest that LLMs may take a central role in decision-making.", "sections": [{"title": "1 Introduction", "content": "Can large language models (LLMs) make informed financial decisions or are they simply a support tool? Their advanced capabilities to analyze, interpret, and generate text enable LLMs to excel across a wide range of tasks, including summarization of complex disclosures, sentiment analysis, information extraction, report generation, compliance verification, etc. (e.g., Bernard et al., 2023; Bybee, 2023; Choi and Kim, 2023; Kim et al., 2023a,b; Lopez-Lira and Tang, 2023). All these tasks, however, involve the textual domain and require specialized training or fine-tuning of the model.\u00b9 The boundaries of this disruptive technology outside of the textual domain and with respect to more general tasks that require numeric analysis and judgment are yet to be understood. We probe these boundaries in the financial analysis domain.\nWe study whether an LLM can successfully perform financial statement analysis in a way similar to what professional human analysts do. The answer to this question has far-reaching implications for the future of financial analysis and whether financial analysts will continue to be the backbone of informed decision-making in financial markets. The answer is far from obvious, given that an LLM lacks the deep understanding of the financials of a company that a human expert would have. Further, one of the most challenging domains for a language model is the numerical domain, where the model needs to carry out computations, perform human-like interpretations, and make complex judgments (Brown et al., 2020). While LLMs are effective at textual tasks, their understanding of numbers typically comes from the narrative context and they lack deep numerical reasoning or the flexibility of a human mind.\nFinancial statement analysis (FSA), sometimes referred to as fundamental analysis, is a particularly useful setting to examine the role of LLMs in future decision-making. Traditionally, financial statement analysis is performed by financial analysts and investment professionals with the primary objective to understand the financial health of a company and determine whether its performance is sustainable. Unlike a typical task performed by an LLM, FSA is a quantitative task that involves analyzing trends and ratios. At the same time, it also requires critical thinking, reasoning, and ultimately, complex judgments. Importantly, unlike in other applications, such as answering bar or CPA exam questions (Choi et al., 2022; Eulerich et al., 2023), an LLM cannot rely on its memory for the correct answer.\nOur research design involves passing a balance sheet and income statement in a standardized form to the large language model, GPT 4.0 Turbo, and asking the model to analyze"}, {"title": "2 Conceptual Underpinnings", "content": "Financial statement analysis, or fundamental analysis, has long been considered of critical importance for informed decision-making (e.g., Graham and Dodd, 1934). It uses the numbers reported in financial statements to gain insights into the financial health of the company, aiming to reveal information about a firm's future prospects and valuation (Ou and Penman, 1989; Piotroski, 2000; Sloan, 2019).\nFinancial statement analysis underlies the work performed by financial analysts, who play a pivotal role in financial markets.10 One of their primary tasks involves predicting"}, {"title": "3 Methodology and Data", "content": "In this section, we outline how we approach the primary task of using an LLM to analyze and predict earnings changes. Earnings prediction is a complex task that combines qualitative and quantitative analyses and involves professional judgment. We model how analysts make earnings predictions with a chain-of-thought prompt using GPT 4."}, {"title": "3.1 Financial Statement Analysis and Earnings Prediction", "content": "Overview Earnings prediction derived from financial statement analysis is of considerable importance to accounting information users. For example, such predictions help investors to make inferences about the cross-section of expected stock returns (Fama and French, 2015) or to pick the best-performing stocks (Piotroski, 2000). However, earnings are hard to predict as they are influenced by many exogenous factors such as macroeconomic shocks (Ball et al., 2022), product market demand shocks, changes in accounting standards (Ball et al., 2000), and many other factors. Therefore, predicting earnings is challenging even for state-of-the-art ML models (see Bochkay and Levine, 2019; Chen et al., 2022, for example).\nFinancial analysts approach this complex task by performing financial statement analysis. They first analyze financial statements, identifying notable changes or trends in accounting information. They choose which financial ratios to compute to obtain further insights. Their analysis is enriched by contextual information, such as industry information, understanding of the competitive landscape, and macroeconomic conditions (Bouwman et al., 1987). Based on this information, they apply professional judgments to determine whether a company's earnings will grow or contract in the future.\nIn this study, we specifically focus on a relatively narrow information set that includes numerical information reported on the face of two primary financial statements. While this lacks textual information or broader context and thus puts an LLM at a disadvantage relative to a human, it presents a well-defined information set of exclusively numeric data. This approach allows us to test the limits of the model when analyzing financials and deriving insights from the numeric data \u2013 something that an LLM is not designed nor trained to do.\nTo approach FSA-based earnings prediction based on a Large Language Model, we implement two types of prompts. First, we use a \"simple\" prompt that instructs an LLM to analyze the two financial statements of a company and determine the direction of future earnings. This prompt does not provide further guidance on how to approach the prediction task, however.13 Second, we implement a Chain-of-Thought prompt that breaks down the"}, {"title": "3.2 Data", "content": "We use the entire universe of Compustat annual financial data from the 1968 to 2021 fiscal years. We also set aside data for 2022 to predict 2023 fiscal year earnings to test for"}, {"title": "4 How Does an LLM Perform Compared to Financial Analysts?", "content": "In this section, we evaluate the performance of a large language model in the analysis of financial statements aimed at predicting the direction of future earnings by using human analysts as a benchmark. All prediction models have a binary target variable, which indicates an increase or decrease in EPS in the subsequent year."}, {"title": "4.1 Prediction Methods and Evaluation Metrics", "content": "Naive Model First, as a naive benchmark, we assume that the directional change in earnings will stay the same. In particular, if EPS has increased (decreased) in year t relative to year t 1, the naive prediction for year t + 1 is also \u201cincrease\u201d(\u201cdecrease\u201d).\nAnalysts' Forecasts We use a consensus analyst forecasts of year t + 1 EPS published following the announcement of year t earnings. If there are multiple forecasts issued by a single analyst, we use the closest one to the year t earnings release dates. This approach helps us to ensure that human analysts are making predictions of one-year-ahead earnings based on financial statements published in the current year. Then we take the median value of analysts' forecasts and compare it to the actual year t EPS. We require at least three analyst forecasts in a given firm-year to compute median values. If the median forecasted EPS value is larger than the year t EPS, we label the prediction as \u201cincrease\u201d and vice versa. Analyst forecast accuracy is then obtained in an analogous manner.\nAs a comparison, we also collect analyst forecasts issued at least three and six months after the release of year t financial statements. This ensures that the analysts have enough time to process the reported financials. However, this also means that the analysts will have access to one or two quarterly financial statements and other contextual information generated during the year t + 1. Therefore, human analysts generally have an informational advantage relative to the models that rely on time t information only.\nEvaluation Metrics We report two common metrics to evaluate the quality of the prediction method: accuracy and F1-score. Accuracy is the percentage of correctly predicted cases scaled by the total number of predictions made. F1-score is the harmonic mean of precision and recall. Precision measures the proportion of true positive predictions in the total positive predictions, while recall measures the proportion of true positive predictions out of all actual positives. In particular, F1-score is defined as follows:\n$$F1 = \\frac{2 \\times TP}{2 \\times TP + FP+FN}$$"}, {"title": "4.2 Main Results", "content": "Table 2 compares GPT's prediction accuracy with that achieved by financial analysts. Based on the first-month forecast following the release of prior year financial statements, analysts' accuracy is 52.71% and F1 score is 54.48% when predicting the direction of one-year-ahead earnings. As expected, this is better than predictions based on a naive model (accuracy = 49.11% and F1 score = 53.02%). However, these results also reiterate the notion that changes in earnings are very hard to predict, even for sophisticated financial analysts. As expected, the analysts' prediction accuracy improves through the course of the year t + 1, achieving an accuracy of 55.95% and 56.58% for month-three and month-six forecasts, respectively.\nTurning to GPT's predictions, we observe the following: Using a simple prompt instructing GPT to analyze financial statements and predict the direction of future earnings yields an accuracy of 52.33% and an Fl-score of 54.52%. Thus, without CoT reasoning, the model's performance is on par with the first-month consensus forecasts by financial analysts, following the earnings release. However, the performance markedly improves when we utilize CoT-based GPT forecasts. With chain-of-thought prompts, GPT achieves an accuracy of 60.35%, or a 7 percentage points increase compared to analyst predictions one month after the earnings release.16 This edge is particularly noteworthy since we do not provide to the language model any available to the analysts narrative or contextual information beyond the balance sheet and income statement.\nTaken together, our results suggest that GPT can outperform human analysts by performing financial statement analysis even without any specific narrative contexts. Our results also highlight the importance of a human-like step-by-step analysis that allows the model to follow the steps typically performed by human analysts. In contrast, simply instructing the model to analyze complex financial statements does not yield strong prediction results."}, {"title": "4.3 Complementarity Between Human Analysts and GPT", "content": "Given that GPT outperforms human analysts in predicting future earnings, this finding raises the question of whether an LLM can largely replace human analysts. In our context, humans are expected to rely on a broader information set and hence should have an advantage over an LLM that does not have access to qualitative information, for example. More"}, {"title": "Sources of Incorrect Answers", "content": "We start with the analysis of instances where forecasts are erroneous. We estimate a simple linear regression to examine whether firm characteristics have systematic associations with prediction accuracy. I(incorrect = 1) is an indicator variable that equals one when the earnings prediction does not match the actual change in earnings. We then estimate the following OLS regression:\n$$I(incorrect = 1)_{it} = \\beta X_{it} + S_{year} + d_{ind} + E_{it}$$\nXit is a vector of firm i's year t characteristics: asset size, leverage, book-to-market ratio, earnings volatility, loss indicator, and property, plant, and equipment scaled by total assets. dyear and find denote year and industry (SIC two-digit) fixed effects, respectively. All continuous variables are winsorized at the 1% level and standard errors are clustered at the SIC two-digit industry level.\nWe present the results in Table 3, Panel A, and Figure 2. In column (1), we document that GPT's predictions are more likely to be inaccurate when the firm is smaller in size, has a higher leverage ratio, records a loss, and exhibits volatile earnings. These results are intuitive and, notably, prior studies find these characteristics to be economically associated with earnings quality. 17 For comparison, in columns (2), (3), and (4), we report the determinants of analysts' inaccurate predictions. Several interesting differences emerge compared to column (1). First, even though analysts face difficulties in predicting small firms' earnings, the magnitude of these coefficients is nearly half compared to the coefficient in column (1) (p-value is less than 1% for all three comparisons). Considering that analysts have access to narrative information and broader context, this result is consistent with Kim and Nikolaev (2023b), who show that context matters more for prediction tasks when the firm is smaller in size. Another notable difference is that analysts are less likely to make errors relative to"}, {"title": "Incremental Informativeness", "content": "We next test whether analysts' forecasts, despite lower accuracy, add useful insights incremental to GPT's predictions. We regress an indicator I(Increase = 1), which equals one when subsequent period earnings increase and zero otherwise, on the direction of future earnings predicted by GPT and/or analysts. Specifically, we estimate the following OLS regression:\n$$I(Increase = 1)_{it} = \\beta_1Pred\\_GPT_{it} + B_2Pred\\_Analyst_{it} + S_{year} + d_{ind} + E_{it}$$\nwhere Pred_X is an indicator that equals one when \"X\" (which is either \u201cGPT\u201d or \u201cAnalyst\") predicts an increase in earnings, and zero otherwise. Syear and Sind are year and industry (SIC two-digit level) fixed effects. Standard errors are clustered at the industry level.\nThe results are presented in Table 3, Panel B. In column (1), we find that GPT's prediction, on a standalone basis, is positively associated with future outcomes while controlling for industry and year-fixed effects. The same result holds for individual analysts' forecasts as can be seen in columns (2), (3), and (4). Consistent with the results in Table 2, analysts' forecasts issued six months after the earnings release exhibit stronger associations with the actual outcomes than the forecasts issued one month after the earnings release (the adjusted R-squared in column (4) is 0.044, which is almost twice the adjusted R-squared value in column (2)).\nIn columns (5), (6), and (7), we include both GPT and analyst forecasts simultaneously in a single regression. Across all models, both coefficients are statistically significant. We observe that the coefficient on GPT is largely unchanged (its t-statistics marginally decreases from 2.99 to 2.67) and the coefficient on analysts' predictions increases in magnitude when both variables are used simultaneously (e.g., from 0.073 in column (2) to 0.110 in column (5)). The adjusted R-squared value also increases from 0.070 in column (1) to 0.089 in column (5). These results indicate that GPT and human analysts are complementary, corroborating our results in Table 3.\""}, {"title": "Does GPT Do Well When Humans Struggle?", "content": "To explore the relative advantage of an LLM compared to human analysts, we examine instances when human analysts are likely to struggle with accurately forecasting earnings. In particular, we identify instances where analyst forecasts are likely to be biased or inefficient ex ante. We also consider instances in which analysts tend to disagree about future earnings (exhibit dispersion).\nTo estimate ex-ante bias (inefficiency) in analysts' forecasts, we run cross-sectional regressions of analyst forecast errors on the same firm characteristics as in Equation 2. We then take the absolute value of the fitted values from this regression.18 Consistent with prior literature, forecast errors are defined as the difference between actual EPS and forecasted EPS, scaled by the stock price at the end of the last fiscal year. In addition to ex-ante bias, we measure the disagreement in analysts' forecasts. Specifically, we use the standard deviation of analysts' forecasted EPS values, scaled by the stock price at the end of the preceding fiscal year.\nWe then partition the sample based on the quartile values of analyst bias and estimate Equation 3 for each group. The results are presented in Panel C of Table 3. By comparing the coefficients in columns (1) and (2), we observe important differences. When the analysts\u2019 bias is expected to be relatively low, GPT's predictions receive a smaller weight (compared to that in column (2) when the bias is expected to be higher), and the coefficient on analysts\u2019 predictions is relatively large. These differences are statistically significant at the 1% level. They suggest that GPT is more valuable in situations when human analysts are likely to be biased. Similar results follow in columns (3) and (4) when we partition the sample on analyst disagreement: GPT's prediction receives more weight when analysts' disagreement is high and vice versa.\nTaken together, our results indicate that GPT's forecasts add more value when human biases or inefficiencies are likely to be present."}, {"title": "5 Comparison with Specialized ML Models", "content": "So far, we have shown that GPT's predictions largely outperform human analysts. As human analysts are known to have a systematic bias in their forecasts, we raise the bar and turn to more sophisticated benchmarks, including state-of-the-art machine learning models."}, {"title": "5.1 Methodology", "content": "Following Ou and Penman (1989) and Hunt et al. (2022), we focus on 59 financial variables obtained from the Compustat Annual database to predict future earnings but exclude"}, {"title": "5.2 Main Results", "content": "Overall Results We report the results in Table 4, Panel A, and Figure 3. Stepwise logistic regressions following Ou and Penman (1989) achieve an accuracy of 52.94% and an F1 score of 57.23%. We observe a considerably higher prediction accuracy using the ANN model. The model achieves a 60.45% accuracy and an F1-score of 61.62%. This result highlights the importance of non-linearities and interactions among financial variables for the predictive ability of numerical information.\nConsistent with the results in the analyst sample, our CoT-based GPT predictions achieve an accuracy of 60.31%, which is on par with the specialized ANN model. In fact, in terms of the F1-score, GPT achieves a value of 63.45%, which is the highest among all prediction"}, {"title": "5.3 Confidence, Magnitude, and Generalizability", "content": ""}, {"title": "5.3.1 LLM's Confidence", "content": "Method We estimate the confidence of LLM's answers based on two methods. First, we explicitly instruct the model to report a confidence score on its earnings prediction, with one being perfect confidence and zero being a pure guess (Bybee, 2023). Second, we compute an alternative confidence score based on token-level logistic probability values, which we directly take from the probability vector provided by the model. Specifically, we average the logistic probability values across all output tokens to measure the overall certainty of the"}, {"title": "5.3.2 Magnitude", "content": "Method Recall that we also instruct the model to provide the expected magnitude of earnings change: \"large\", \"moderate\u201d, or \u201csmall.\" As in Ou and Penman (1989) and Hunt et al. (2022), we expect the model to be more accurate in determining the directional change when it predicts large rather than immaterial changes.\nResults We present the results in Figure 5 and columns (5) and (6) of Table 5. We find that the average accuracy is 62.03% when the model predicts large changes whereas it decreases to 60.22% for small changes. We document a similar pattern for F1 scores: 61.16% for large changes vs. 57.95% for small changes. Overall, when the model expects a larger change, its directional predictions are more accurate."}, {"title": "5.3.3 LLM type", "content": "Method We also test whether the capabilities associated with a specific LLM type determine its predictive ability. In the main analysis, we use the most recent version of GPT, GPT-4-turbo. We also experimented with a less powerful LLM version from the same family, GPT-3.5-turbo, and otherwise used the same experimental settings. In addition, we also explored another family of LLMs provided by Google, namely, Gemini Pro 1.5 (also with the same experimental settings). Due to considerable processing time, we choose a random 20% sample for this set of analyses.\nResults We present the results in Figure 5 and Table 5, columns (7) to (9). GPT 4 achieves the best performance, followed by Gemini 1.5, and GPT 3.5. Gemini 1.5 achieves an overall accuracy of 59.15%, which is close to that of GPT 4 (61.05%) in the same 20%"}, {"title": "6 Where Does an LLM's Predictive Ability Come From?", "content": "In this section, we aim to understand the sources of GPT's predictive ability. We explore two broad explanations. The first explanation is that GPT's performance comes from its memory, e.g., due to the model's ability to identify the company based on numeric data. We aim to rule out this possibility as it undermines the integrity of the model's predictions. Another explanation is that the strength of the model is in its ability to generate narrative insights based on its analysis of numeric data. We explore each of these possibilities next."}, {"title": "6.1 Is There a Look-ahead Bias in the Model?", "content": "An important concern with the reliance on a pre-trained large language model in a prediction task is its potential for a look-ahead bias (e.g. Sarkar and Vafa, 2024). For example, the model may have been trained on the company-specific financial data and, hence, already may \u201cknow\u201d the answer as to whether earnings increased or decreased in the future (or have a general sense of how well the company did over time). Our research design is relatively immune from this potential bias (e.g. Glasserman and Lin, 2023) because we use a consistent anonymized format of financial statements across firms. This makes it virtually impossible for the model to infer a firm's identity from the structure of financial statements or specific account names. We also ensure the statement does not contain any dates and use relative years, i.e., t or t \u2212 1. This later mitigates the concern that the model has knowledge about macroeconomic trends in a specific year and uses it to predict future earnings. To appreciate this issue, imagine that the model was able to match a given set of financials to 2007. In this case, the model could draw on its knowledge of the major economic downturn in 2008 and adjust its prediction accordingly.\nEven though the anonymous nature of financial statements should prevent the model from \u201cguessing\u201d the entity, we perform two formal analyses to further rule out this concern.23"}, {"title": "6.2 Are LLM-Generated Texts Informative?", "content": "Next, we explore whether the model's predictive ability comes from its ability to generate narrative insights about the financial health and future performance of the company, in line with its objective to analyze financial statements. We leverage the fact that our CoT prompts instructed the model to provide information besides the prediction itself: narrative description and interpretations of trend and ratio analyses, as well as the rationale behind the binary predictions. We start with descriptive analyses of the generated texts. Subsequently, we evaluate the information content of texts generated by GPT."}, {"title": "Descriptive Bigram Analysis", "content": "We begin with a descriptive approach, performing a content analysis of the texts generated by the model. This analysis involves counting the most common bigrams in the ratio analysis and the most common monograms (single words) in the rationale section. This method allows us to discern patterns and dominant themes that may contribute to the model's analytical performance.\nWe present the results in Figure 7. In the left panel, we report the top ten most frequently used bigrams in the ratio analysis. We calculate the frequency by scaling the bigram counts with the total number of bigrams generated by the model. We find that the model most commonly refers to the operating margin. In addition to the profitability information, the model also frequently computes efficiency (asset and inventory turnover) and liquidity (current ratio, current assets, and current liability). The model's rationale in making fi-"}, {"title": "Information Content of Generated Text", "content": "We hypothesize that GPT is capable of predicting future earnings because it distills narrative insights about the financial health of the company from the numeric data. We thus examine whether GPT-generated texts contain information that is useful for predicting the direction of future earnings. To do so, we process each GPT output with a BERT-base-uncased model to obtain its 768-dimensional vector representation (note that GPT does not allow retrieving native embeddings, and thus, we use BERT).25 We then design a new ANN model that uses these textual embeddings as inputs and train the ANN to predict the direction of future earnings (target variable). The model has two hidden layers, with dimensions of 256 and 64, and an output layer with two dimensions: probabilities of earnings increase vs. decrease (p1, p2). We classify the outcome as an increase when p\u2081 > P2 and vice versa. The model is otherwise analogous to the ANN models we estimated earlier.26 We refer to this model as the embeddings-based model.\nWe report the accuracy, F1-score, and the area under the ROC curve (AUC) of the trained model in Table 7, Panel B (note that we were not able to measure AUC for GPT forecasts and thus did not report it previously). Our embedding model achieves an accuracy of 58.95%, an F1-score of 65.26%, and an AUC of 64.22%. It is noteworthy that this model achieves the highest F1 score among all classification methods we examined previously. For comparison purposes, the second row of the table repeats the results of the ANN model based on variables from the two financial statements, which was previously reported in Table 4. This model achieves only a somewhat higher accuracy of 60.12%, but a considerably lower F1-score (61.30%) and AUC (59.13%). Overall, our results indicate that narrative text generated by GPT contains a significant amount of information useful in predicting future earnings, i.e., it indeed represents narrative insights derived from numeric data based on the CoT prompt. This result suggests that the narrative insights serve as the basis for GPT's"}, {"title": "7 Asset Pricing Tests", "content": "Having demonstrated that GPT's predictions of the earnings direction have high accuracy and stem from the model's ability to generate insights rather from memory, we now investigate the practical value of an LLM-based financial statement analysis by evaluating trading strategies based on GPT's output.\nIn particular, signals that are informative about future expected profits should exhibit a positive association with expected stock returns in the cross-section of firms (Fama and French, 2015). The asset pricing models typically use the current level of profitability as a"}, {"title": "7.1 Methodology", "content": "Because our sample includes firms with December 31 fiscal year-end, their financial results are released by the end of March. Following prior literature, we allow approximately three months for the market to fully process the reported information and form portfolios on June 30 of each year. We hold the portfolio for one year and measure their Sharpe ratios and monthly alphas. We compare three types of strategies. The first strategy sorts stocks into portfolios based on GPT forecasts, and the other two perform sorts based on ANN and logistic regression forecasts that rely on numeric information.\nANN and Logistic Regressions ANN and logistic regressions yield probabilities that earnings will increase in the subsequent year. We use these predicted probabilities to sort the stocks into ten portfolios. Then on June 30, each year, we take long positions in the top decile stocks and short stocks in the bottom decile.\nGPT Because GPT does not provide probabilities that earnings will increase or decrease, we follow a different approach to form portfolios. We rely on three pieces of information: binary directional prediction, magnitude prediction, and average log probability of tokens. In particular, for each fiscal year, we select stocks predicted to experience an \u201cincrease\u201d in earnings with the predicted magnitude (of the change in earnings) of either \u201cmoderate\" or \"large.\" Then we sort those stocks on the average log probability values associated with the generated text. This allows us to choose stocks with relatively more confident forecasts (recall that model answers with high certainty are more accurate than the ones with low certainty). We then retain stocks with the highest log probabilities such that the number of firms retained each year constitutes 10% of our sample in that year (our goal is to construct an equivalent to a decile portfolio). We also do the same for the stocks predicted to experience a \u201cdecrease\u201d in earnings. We filter stocks with a predicted magnitude of either \"moderate\u201d or \"large\", and sort them on log probability values. We then short the same number of stocks as that in the long portfolio, i.e., retain 10% from the total number of observations in that year with the highest expected confidence. By doing so, we match the number of stocks to the number of stocks included in ANN or logit-based portfolios."}, {"title": "7.2 Results", "content": "Sharpe Ratios To compute Sharpe ratios, we form equal-weighted and value-weighted portfolios. For value-weighted portfolios, we rebalance the portfolio weights each month. Although value-weighted portfolios are less sensitive to small market capitalizations, it is difficult to rebalance the portfolios based on the stocks' time-varying market caps in practice (Jiang et al., 2022). Recall that our prior findings suggest that GPT appears to have an advantage in analyzing smaller and relatively more volatile companies. We thus present the outcome of both the value- and equal-weighted strategies.\nThe results are presented in Table 8, Panel A. We find that equal-weighted portfolios based on GPT predictions achieve a Sharpe ratio of 3.36, which is substantially larger than the Sharpe ratio of ANN-based portfolios (2.54) or logistic regression-based portfolios (2.05). In contrast, for value-weighted portfolios, we observe that ANN performs relatively better (Sharpe = 1.79) than GPT (1.47). Both dominate the logistic regressions (0.81).27 This result is consistent with our finding in Table 4 that both GPT and ANN contain incremental information and are thus complementary. Overall, this analysis shows potential for using GPT-based financial statement analysis to derive profitable trading strategies.\nAlphas Next, we compute monthly alphas for each of the three investment strategies described above based on five different factor models, from CAPM to Fama and French (2015)'s five factors plus momentum. We present the results in Table 8, Panel B.\nConsistent with the results in Panel A, equal-weighted portfolios generate higher alphas in general. As expected, we observe a significant reduction in alphas when we include the profitability factor in column (4) (from 1.29 to 0.97 for portfolios based on GPT predictions), which is another proxy for future profitability. However, even after controlling for five factors and momentum, portfolios based on GPT's predictions generate a monthly alpha of 84 basis points (column (5)), or 10% annually. Portfolios based on ANN and logistic regression estimates also generate positive alphas. However, their magnitudes and economic significance are smaller (60 basis points with a t-statistic of 1.89 for ANN and 43 basis points with a t-statistic of 1.96 for logistic regressions)."}, {"title": "8 Conclusion", "content": "In this paper, we probe the limits of large language models by providing novel evidence on their ability to analyze financial statements. Financial statement analysis is a traditional quantitative task that requires, critical thinking, reasoning, and judgment. Our approach involves providing the model with structured and anonymized financial statements and a sophisticated chain-of-thought prompt that mimics how human analysts process financial information. We specifically do not provide any narrative information.\nOur results suggest that GPT's analysis yields useful insights about the company, which enable the model to outperform professional human analysts in predicting the direction of future earnings. We also document that GPT and human analysts are complementary, rather than substitutes. Specifically, language models have a larger advantage over human analysts when analysts are expected to exhibit bias and disagreement, suggesting that AI models can assist humans better when they are under-performing. Humans, on the other hand add value when additional context, not available to the model is likely to be important.\nFurthermore and surprisingly, GPT's performance is on par (or even better in some cases) with that of the most sophisticated narrowly specialized machine learning models, namely, an ANN trained on earnings prediction tasks. We investigate potential sources of the LLM's superior predictive power. We first rule out that the model's performance stems from its memory. Instead, our analysis suggests that the model draws its inference by gleaning useful insights from its analysis of trends and financial ratios and by leveraging its theoretical understanding and economic reasoning. Notably, the narrative financial statement analysis generated by the language model has substantial informational value in its own right. Building on these findings, we also present a profitable trading strategy based on GPT's"}]}