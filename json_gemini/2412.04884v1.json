{"title": "Al-Driven Non-Invasive Detection and Staging of Steatosis in Fatty Liver Disease Using a Novel Cascade Model and Information Fusion Techniques", "authors": ["Niloufar Delfan", "Pardis Ketabi Moghadam", "Mohammad Khoshnevisan", "Mehdi Hosseini Chagahi", "Behzad Hatami", "Melika Asgharzadeh", "Mohammadreza Zali", "Behzad Moshiri", "Amin Momeni Moghaddam", "Mohammad Amin Khalafi", "Khosrow Dehnad"], "abstract": "Non-alcoholic fatty liver disease (NAFLD) is one of the most widespread liver disorders on a global scale, posing a significant threat of progressing to more severe conditions like nonalcoholic steatohepatitis (NASH), liver fibrosis, cirrhosis, and hepatocellular carcinoma. Diagnosing and staging NAFLD presents challenges due to its non-specific symptoms and the invasive nature of liver biopsies. Our research introduces a novel artificial intelligence cascade model employing ensemble learning and feature fusion techniques. We developed a non-invasive, robust, and reliable diagnostic artificial intelligence tool that utilizes anthropometric and laboratory parameters, facilitating early detection and intervention in NAFLD progression. Our novel artificial intelligence achieved an 86% accuracy rate for the NASH steatosis staging task (non-NASH, steatosis grade 1, steatosis grade 2, and steatosis grade 3) and an impressive 96% AUC-ROC for distinguishing between NASH (steatosis grade 1, grade 2, and grade3) and non-NASH cases, outperforming current state-of-the-art models. This notable improvement in diagnostic performance underscores the potential application of artificial intelligence in the early diagnosis and treatment of NAFLD, leading to better patient outcomes and a reduced health-care burden associated with advanced liver disease.", "sections": [{"title": "I. INTRODUCTION", "content": "Nonalcoholic fatty liver disease (NAFLD) is a widespread chronic liver disorder, impacting about 25% of the population in North America and roughly 30% in Asia [1]\u2013[3]. It involves excess fat accumulation in the liver, making up at least 5% of its weight, in individuals with minimal alcohol consumption and no other liver diseases. NAFLD can progress from nonalcoholic fatty liver (NAFL) to more severe conditions like nonalcoholic steatohepatitis (NASH), cirrhosis, and hepatocellular carcinoma (HCC) [2]. While NAFL involves steatosis without cell damage, NASH includes inflammation and liver damage, potentially leading to cirrhosis and other complications. NASH is also linked to higher risks of cardiovascular disease and cancer due to its association with metabolic syndrome [2].\nDespite its health impact, NASH is underdiagnosed due to vague symptoms and limited reliable biomarkers. While liver biopsy remains the definitive diagnostic tool, noninvasive methods such as ultrasound, CT, MRI, and blood tests have been developed. Additionally, patient demographic analysis, which examines factors such as age, gender, and medical history, is used to enhance diagnostic accuracy and tailor treatment plans [4]. However, these noninvasive imaging techniques come with their own set of limitations. The accuracy of ultrasound, CT scans, and MRI heavily depends on the skill and experience of the analysts interpreting the images, which can lead to variability in diagnostic results [5]. A more practical and broadly accepted non-invasive method leverages clinical and laboratory results, particularly blood tests. Blood tests, like the NAFLD fibrosis score (NFS) and fibrosis-4 index (FIB-4), offer a practical approach to detecting advanced fibrosis with high diagnostic accuracy [4].\nElevated levels of alanine aminotransferase (ALT) and aspartate aminotransferase (AST) are commonly observed in patients with NAFL/NASH. However, they do not correlate well with disease progression[4]. Various laboratory parameters must be combined to aid in identifying NASH, fibrosis, and steatosis. Notably, the NAFLD fibrosis score (NFS) and the fibrosis-4 index (FIB-4), recommended by the American Association for the Study of Liver Diseases (AASLD) in 2017, were commonly utilized to identify advanced fibrosis [2]. Additional risk factors associated with NASH to liver fibrosis include fasting blood sugar (FBS), insulin resistance, hemoglobin (HB), and weight gain [6]. The NFS and FIB-4 are distinguished by their high diagnostic accuracy for advanced fibrosis, with AUROC values of 80-85%, utilizing readily available clinical and biochemical parameters [6].\nEarly intervention through lifestyle changes can reverse disease progression in patients with mild fibrosis. However, current scoring methods do not account for long-term data, limiting their accuracy [4], [6]. Machine learning (ML) models, incorporating clinical and laboratory data, offer a promising alternative for diagnosing and predicting disease stages [7]. This capability allows physicians to make more informed decisions complemented by these models' insights [8]. Various ML algorithms have been employed in the detection and classification of NAFLD, including Classification Trees [9], Random Forest (RF) [10], Na\u00efve Bayes (NB) [11], Neural Networks (NN) [12], and Logistic Regression (LR) [13], K-Nearest Neighbor (KNN) [11], Support Vector Machine (SVM) [11], Adaptive Boosting (AdaBoost) [11], and XGBoost [14]. Clinical data used in ML models included patient demographics, electronic health records (EHRs), and blood biomarkers, which help accurately diagnose different stages of liver disease [15].\nHowever, existing studies focus on binary classification to determine the presence of NAFLD or NASH. However, accurately distinguishing between the various stages of NAFLD is equally critical. While prediction models show high accuracy when anthropometric data like waist circumference and BMI are available, their use in large-scale epidemiological research is limited due to the frequent absence of these specific parameters in many datasets. Compiling a comprehensive dataset with the necessary features and biomarkers across many samples remains a significant challenge. Therefore, developing an NAFLD prediction model that relies solely on routine clinical and laboratory parameters, which are more readily available in health databases, is essential.\nThis paper introduces an innovative cascade model that utilizes ensemble learning, data, and feature fusion techniques to effectively handle missing data and enhance predictive accuracy. This ensemble-based methodology integrates diverse data sources and model predictions, ensuring that handling missing data does not compromise overall performance. As a result, our model attains superior accuracy and enhanced resilience, making it an invaluable tool for numerous applications where data quality and completeness are crucial.In summary, the primary advantages of the proposed method are:\n1) Innovative Information Fusion: The method introduces a novel stacking model that integrates data and feature fusion techniques to enhance performance.\n2) Enhanced Data Enrichment: The model optimizes input for the meta-classifier by combining data and feature-level information, improving its predictive capabilities.\n3) Diverse Dataset: The dataset, sourced from two medical centers representing rural and urban populations, ensures the model's applicability across different demographic settings, increasing its generalizability.\n4) Comprehensive Evaluation: The model's effectiveness is rigorously tested using a wide range of performance metrics and 10-fold cross-validation (CV), ensuring a thorough assessment.\n5) Robust and Reliable System: By leveraging multiple ML models, the approach overcomes individual model limitations, achieving 86% accuracy in multiclass tasks and a 96% AUC for binary classification, ensuring high reliability and performance.\n6) Effective Handling of Missing Data: The ensemble model efficiently manages incomplete data, a common issue in clinical settings, maintaining strong performance despite data gaps."}, {"title": "II. METHODS AND MATERIALS", "content": "A. Data Acquisition and Annotation\nThe Shahid Beheshti University of Medical Sciences (SBMU) ethics committee approved this study, granting it the ethical code I.R.SBMU.RIGLD.REC.1403.025. All participants provided informed consent before participating. This cross-sectional study was conducted from June 2023 to June 2024, involving 1,812 patients from the primary healthcare center in Bomehen city (a suburb of Tehran) and the family medicine group at Taleghani Hospital. These two centers were chosen to capture a diverse sample population, representing rural and urban settings, to examine differences in healthcare access, lifestyle, and metabolic diseases.\nParticipants included adults over 18 without underlying liver conditions, hepatobiliary cancers, excessive alcohol consumption, or comorbidities like diabetes and cardiovascular diseases. Demographic data, medical history, and lifestyle factors such as smoking and alcohol use were collected through questionnaires. Laboratory tests included measurements of various biomarkers such as ALT, AST, cholesterol levels, and the FIB-4 index. Anthropometric data, including waist-to-hip ratio and BMI, were also recorded. After a 12-hour fasting period, participants underwent laboratory tests and B-mode ultrasound to assess liver steatosis, graded from absent to severe based on liver brightness and the visibility of intrahepatic structures. Table I provides a detailed review of the variables available within both datasets used in the study.\nAll participants underwent laboratory tests after a 12-hour fast, and patients with liver diseases were excluded based on hepatic viral marker screenings. Liver steatosis was evaluated using B-mode ultrasound to assess fatty infiltration in the liver. The ultrasound grading system was based on liver brightness, the contrast between the liver and kidney, and the visibility of intrahepatic vessels, parenchyma, and diaphragm. Liver steatosis was classified as follows: Grade 0 (absent) with normal liver echotexture; Grade 1 (mild) with slightly increased echogenicity and standard diaphragm and portal vein visibility; Grade 2 (moderate) with moderate echogenicity and slightly impaired visualization; and Grade 3 (severe) with significant echogenicity and poor or no visibility of critical structures [16].\nB. Data Preprocessing\nSince the datasets were collected retrospectively from different sources, some features, such as BMI, waist, and hip circumferences, are missing for certain subjects, leading to incomplete data. Managing missing values is crucial in data preprocessing for ML and statistical analysis, as it can affect model accuracy and lead to biased estimates. Common methods for addressing missing values include deletion, imputation, and using algorithms that can handle missing data directly [17].\nDeletion removes instances or features with missing data but risks losing valuable information. Imputation fills in missing values using statistical methods like the mean, median, or more advanced techniques such as k-nearest neighbors or regression. Some ML algorithms can directly handle missing data, ensuring incomplete datasets don't significantly impact performance [17]. To minimize biases and maintain data integrity, we created three different datasets, grouping subjects based on the available features. Categorical features were converted to numerical values in all datasets. Dataset 1 includes essential features like Age, Sex, FBS, AST, ALT, Bil T, Bil D, TG, Chol, LDL, HDL, and ALB. Dataset 2 adds WBC, HB, PLT, and FIB-4, while Dataset 3 includes Height, Weight, BMI, Waist, Hip, and W/H Ratio. After splitting the data, categorical features were converted to numerical values, and z-score normalization was applied to ensure consistency across datasets.\nC. The Proposed Model\nThis project utilizes two tiers of fusion techniques: data-level fusion and feature-level fusion [18], [19]. Data-level fusion involves merging raw data from various sources before any feature extraction or processing, thus capitalizing on complementary information from different sources and enhancing model performance. For instance, sensor data fusion combines information from various sensors to create a unified and complete dataset. In this project, merging laboratory test results with anthropometric metrics provides a more detailed and holistic view of a patient's condition [20]. Feature-level fusion, or early fusion, involves extracting features independently from each data source and merging them into a single feature vector for model training. In our research, we concatenated classifier outputs and created a unified feature set for further model enhancement [20].\nFig. 1 depicts the architecture of the proposed model. The model architecture evaluated various classifiers, selecting the best-performing ones. Seven ML models were tested: KNN, SVM, RF, NN, AdaBoost, LightGBM, and XGBoost. SVM excels in high-dimensional spaces and resists overfitting, while RF, an ensemble of decision trees, is known for its accuracy and robustness. NN models mimic the brain's pattern recognition and handle complex data, though they require large datasets and computational resources. AdaBoost improves weak classifiers by giving more weight to misclassified instances, but it is sensitive to noise. LightGBM, optimized for large datasets, offers faster training and higher efficiency. At the same time, XGBoost, known for its flexibility and regularization, reduces overfitting and handles sparse data effectively.\nThe proposed model utilizes a sophisticated three-layer stacked ensemble learning framework, integrating multiple datasets and feature sets to enhance prediction accuracy. In the first layer, a feature stacking technique is employed. Feature stacking involves training various models on the original feature sets and then using the predictions from these models as input features for the next layer model. This approach helps capture more complex relationships between the features. Accordingly, a diverse set of classifiers\u2014 KNN, SVM, RF, NN, AdaBoost, LightGBM, and XGBoost are trained on Dataset 1 using Feature-set 1 (F\u00b91) (Equation 1). The training employed a 10-fold CV to ensure robust performance and mitigate overfitting. Classifiers with an average test accuracy exceeding 70% were selected, resulting in a final set of five classifiers (SVM, RF, AdaBoost, LightGBM, and XGBoost). Each classifier generates an output, forming an output set that captures diverse perspectives from different algorithms (Equation 2).\nFor first layer training:\nInput (Layer 1): $I\u2081 = {F\u00b9, F\u00b2, . . .,F\u2075}$ (1)\nOutput (Layer 1) : $O\u2081 = {SVM(I\u2081), RF(I\u2081), XGBoost(I1), LightGBM(I1), AdaBoost(I1)}$ (2)\nFor training the second-layer classifier, first, the intersection of Feature-set 1 (F1) and Feature-set 2 (F2) was fed into the first-layer classifiers (Equation 3). The outputs from these classifiers and Feature-set 2 were combined and fed into the second-layer classifier (Equations 4, 5, 6). This classifier synthesized the information from the diverse models and Feature-set 2 (F2) to make second-layer predictions. The output from this layer represents an integrated prediction, combining the strengths of various models and feature sets. All seven base classifiers were also tested for the second layer, with the NN showing the highest average accuracy and thus being selected.\nFor second layer training:\nInput (Layer 1) : $I\u2081 = {F\u00bf | F\u00bf \u2208 (F1 \u2229 F2)}$ (3)\nOutput (Layer 1) : $O\u2081 = {SVM(I\u2081), RF(I\u2081), XGBoost(I\u2081), LightGBM(I\u2081), AdaBoost(I\u2081)}$ (4)\nInput (Layer 2) : $I\u2082 = {F\u00bf | F\u00bf \u2208 (F2||O\u2081)}$ (5)\nOutput (Layer 2) : $O'\u2082 = {NN(I\u2082)}$ (6)\nIn the third layer (meta-classifier), the intersection of Feature-set 1 (F1) and Feature-set 3 (F3) was processed by the first-layer classifiers (Equations 7 and 8). The outputs from these classifiers and the intersection of Feature-set 2 (F2) and Feature-set 3 (F3) was combined and input into the second-layer classifier (Equations 9 and 10). The output of the second layer was then merged with Feature-set 3 (F3) and fed into the third-layer classifier (Equation 11). This final classifier processed the combined information to produce the final prediction (Equation 12). Again, all seven base classifiers were tested for this layer, with NN achieving the highest average accuracy and being selected.\nFor third layer training:\nInput (Layer 1) : $I\u2081 = {F\u00bf | F\u00bf \u2208 (F1 \u2229 F\u00b3)}$ (7)\nOutput (Layer 1) : $O\u2081 = {SVM(I\u2081), RF(I), XGBoost(I), LightGBM(I'), AdaBoost(I')}$ (8)\nInput (Layer 2): $I\u2082 = {F\u00bf | F\u00bf \u2208 (F2 \u2229 F\u00b3||O", "2)": "O\u2082 = {NN(I\u2082)}$ (10)\nInput (Layer 3) : $I\u2083 = {F\u00bf | F\u00bf \u2208 (F\u00b3||O", "3)": "O= {NN(I"}, {"title": "III. RESULTS", "content": "A. Model statistics\nThe effectiveness of this method is evaluated using performance metrics such as accuracy (Acc), sensitivity (Sens), and specificity (Spec). Accuracy is the ratio of correctly classified cases (true positives and true negatives) to the total number of cases. Sensitivity measures the proportion of true positives out of all actual positives, while specificity is the proportion of true negatives out of all actual negatives. Additionally, the model's performance is summarized with the area under the ROC curve (AUC-ROC), where values closer to 1 indicate better performance. These metrics comprehensively assess the model's accuracy, reliability, and robustness in diagnosing and predicting outcomes.\nB. Experiment results\nThe proposed method for detecting and staging NAFLD was evaluated using performance metrics such as accuracy, sensitivity, and specificity to assess predictive accuracy and reliability. Multiple ML models-LightGBM, XGBoost, AdaBoost, SVM, RF, and NN-were tested using 10-fold CV. A three-layer stacking model was developed, with each layer trained and validated independently. Table IV summarizes the performance of each model, showing improved results with each layer. The third layer achieved the best performance, with an accuracy of 86.9%, sensitivity of 87.3%, and specificity of 95.9%. The AUC-ROC was plotted to compare the performance of various classification models. Fig. 2 displays the ROC curves at different levels, providing a summary of their comparative effectiveness."}, {"title": "IV. DISCUSSION", "content": "The study presents a significant advancement in NAFLD diagnosis using ensemble learning techniques. The proposed multi-layer stacking model outperforms conventional models, particularly in sensitivity and specificity, essential for accurately detecting the disease. By leveraging multiple ML algorithms and integrating diverse data sources, the model uses advanced information fusion techniques to enhance its predictive capabilities.\nThe model's design incorporates advanced information fusion techniques, enhancing its ability to utilize available data comprehensively. This ensures a more robust and accurate diagnostic tool. One key advantage of this methodology is its effective handling of missing data. In real-world clinical settings, incomplete datasets are common and can undermine the performance of traditional models. The multi-layer stacking model addresses this issue by maintaining overall performance even when some features are unavailable. This improves the reliability of diagnostic predictions and increases the model's resilience and adaptability to varying data conditions.\nThe Use of information fusion and ensemble learning in healthcare has demonstrated substantial promise for improving diagnostic accuracy, forecasting patient outcomes, and customizing treatment plans. Data fusion methods combine various data sources, including EHRs, imaging data, genomics, and sensor data, to offer a holistic view of a patient's health status. This holistic approach enables more precise and timely interventions. Recent studies have demonstrated the efficacy of combining data fusion with ensemble learning to enhance the robustness and generalizability of predictive models in intricate clinical settings [22]. For example, the fusion of clinical and imaging data using ensemble techniques has enhanced the early diagnosis of diseases such as cancer and cardiovascular conditions [23]-[25]. Previously, Authors of [26] developed an ensemble learning framework for detecting all-cause advanced hepatic fibrosis. Nonetheless, as far as we know, this research is the first to integrate information fusion techniques and ensemble learning for staging liver steatosis.\nTable V extensively reviews multiple studies employing ML to diagnose NASH-related diseases using clinical data. The studies are categorized based on the classification tasks they address, the features they use, their ML methods, and the number of subjects involved. To distinguish NASH cases from non-NASH cases, [10] applied an RF model to a cohort of 1,525 patients. In [9], a comparative analysis of multiple ML methods, including LR, Linear Discriminant Analysis, RF, AdaBoost, KNN, SVM, Multilayer Perceptron (MLP), and DT, was conducted on 181 patients. Ma et al. [27] applied a BN on a sample of 10,508 subjects to diagnose NASH. Authors of [26] and [28] classified subjects with or without NASH using XGBoost. Although numerous articles developed ML models based on biopsy [29], ultrasound images [30], or Dual-energy X-ray absorptiometry features [31] for staging liver steatosis, there was only one paper that utilized clinical data for this purpose. Razmpour et al. [11]] utilized various ML methods, including KNN, SVM, Radial Basis Function (RBF) SVM, Gaussian Process (GP), RF, NN, AdaBoost, and NB to classify NAFLD based on body composition and anthropometric measurements.\nTheir results indicated that the RF generated the most accurate model for staging the steatosis. These studies showcase various ML techniques and features for classifying NAFLD and its related conditions. Common classifiers such as XGBoost and RF are frequently employed, utilizing features ranging from primary demographic data to detailed clinical and biochemical markers. The sample sizes in these studies vary significantly, affecting the models' generalizability and robustness. These studies underscore both the potential and challenges of applying ML in the clinical diagnostics of liver diseases. In summary, the primary benefits of the suggested approach are:\n1) The novel stacking model uses information fusion techniques at data and feature levels, improving predictive accuracy and robustness.\n2) Classifiers in each stacking layer are chosen based on test performance, achieving 86% accuracy and a 96% AUC, making it more reliable than single classifiers due to its use of multiple models and information fusion.\n3) The model's performance is thoroughly evaluated using various metrics and 10-fold CV, ensuring a comprehensive assessment.\n4) By integrating multiple classifiers, the model addresses individual model weaknesses, resulting in a more robust system that performs well even with incomplete data.\n5) The architecture allows flexibility in incorporating different classifiers and features, making it adaptable to various datasets and clinical scenarios.\n6) The ensemble method effectively handles missing data, making it highly useful in clinical settings where incomplete datasets are common.\nHowever, several limitations should be addressed in future studies:\n1) The multi-layer stacking model increases computational complexity, and future work could optimize it to reduce resource demands without losing performance.\n2) Further validation of external datasets is needed to confirm their generalizability across different populations.\n3) The model's complexity may hinder interpretability, so future research should focus on enhancing its transparency for clinical use.\n4) Expanding the model to assess fibrosis stages and diagnose early-stage hepatocellular carcinoma in NASH patients would be beneficial."}, {"title": "V. CONCLUSION", "content": "This study underscores the importance of developing non-invasive and reliable diagnostic models for NAFLD, notably NASH, to address the limitations of current diagnostic methods. By integrating clinical data and laboratory test results into machine learning models, the proposed stack-based ensemble classifier improves accuracy and robustness in diagnosing various stages of NAFLD. The cascade model effectively mitigates the issues associated with missing data through ensemble learning and information fusion techniques, making it a valuable tool for clinical and epidemiological applications. This development shows potential for improving patient outcomes by enabling early diagnosis and management of NAFLD, minimizing the need for invasive procedures, and enhancing overall disease monitoring and treatment approaches."}]}