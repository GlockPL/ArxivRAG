{"title": "TOWARDS GENERAL DEEPFAKE DETECTION WITH DYNAMIC CURRICULUM", "authors": ["Wentang Song", "Yuzhen Lin", "Bin Li"], "abstract": "Most previous deepfake detection methods bent their efforts to discriminate artifacts by end-to-end training. However, the learned networks often fail to mine the general face forgery information efficiently due to ignoring the data hardness. In this work, we propose to introduce the sample hardness into the training of deepfake detectors via the curriculum learning paradigm. Specifically, we present a novel simple yet effective strategy, named Dynamic Facial Forensic Curriculum (DFFC), which makes the model gradually focus on hard samples during the training. Firstly, we propose Dynamic Forensic Hardness (DFH) which integrates the facial quality score and instantaneous instance loss to dynamically measure sample hardness during the training. Furthermore, we present a pacing function to control the data subsets from easy to hard throughout the training process based on DFH. Comprehensive experiments show that DFFC can improve both within- and cross-dataset performance of various kinds of end-to-end deepfake detectors through a plug-and-play approach. It indicates that DFFC can help deepfake detectors learn general forgery discriminative features by effectively exploiting the information from hard samples.", "sections": [{"title": "1. INTRODUCTION", "content": "Deepfake techniques [1-3] refer to a series of deep learning-based facial forgery techniques that can swap or reenact the face of one person in a video to another. They can lead to the dissemination of false information or even political manipulation. Thus, detecting deepfakes has become a crucial research topic in recent years.\nEarly works [4-7] treat deepfake detection as a binary classification problem, and commonly use deep neural networks to distinguish fake faces. In order to improve the detection performance, some works [8-10] introduce auxiliary modalities or supervision information for learning subtle forgery artifacts. However, these methods can not mine the general face forgery information efficiently due to ignoring the data hardness, resulting in poor generalization performance under the real-world scenario. To address this issue, some works introduce pseudo-forgery augmentations [11-14]\nAs shown in Figure 1, the judgment of real/fake facial images/videos by human vision is difficult due to the visual qualities. Take the post-processing for example, the post-processing on real faces can be misinterpreted as forgery artifacts. Besides, the post-processing on fake faces can erase the forgery artifacts. By analogy, the discriminative deepfake detectors vary with different samples. However, most existing detection methods treat all samples the same during the training. Thus, we argue that the hardness of samples should be taken into account for training the general deepfake detector.\nCurriculum learning (CL) [15\u201317], which involves presenting training samples to the model in a specific order of hardness, is an effective scheme for hard sample mining [18-20]. Inspired by such a paradigm, we present a novel simple yet effective strategy, named Dynamic Facial Forensic Curriculum (DFFC) that makes the model gradually focus on hard samples during the training. We introduce Dynamic Forensic Hardness (DFH), a novel approach that integrates the facial quality score and instantaneous instance loss to dynamically assess sample hardness throughout the training phase. Additionally, we present a pacing function that guides the progression of training subsets from easy to hard based on the DFH score throughout the training iterations. Experimental results demonstrate that DFFC can improve both within- and cross-dataset performance of various kinds of deepfake detectors through a plug-and-play approach. The main contributions of our work are summarized as follows:\n\u2022 To the best of our knowledge, the proposed DFFC is the first work that introduces the curriculum learning paradigm to mine hard samples for the deepfake detection task. DFFC can be plug-and-plays for any end-to-end deepfake detectors.\n\u2022 To measure the sample hardness, we propose the DFH score that integrates the instantaneous instance loss and facial quality score dynamically during the training."}, {"title": "2. METHODOLOGY", "content": "In this section, we introduce the proposed Dynamic Facial Forensics Curriculum (DFFC). Specifically, the overall pipeline (See in Figure 2) mainly consists of two components: 1) Dynamic Forensic Hardness (DFH) is proposed to measure the sample hardness during the training; 2) Pacing Function is presented to control the pace of presenting data from easy to hard according to DFH. Each component will be detailed subsequently."}, {"title": "2.2. Dynamic Forensic Hardness", "content": "The difficulty score plays a key role in curriculum learning as it describes the relative \"hardness\" of each sample. In this work, we propose Dynamic Forensic Hardness (DFH), which considers the dynamic model behavior and the static facial quality. Let $X = \\{(x_i, y_i)\\}_{i=1}^N$ be the training dataset with N samples, $x_i$ and $y_i$ represent the i-th data and its ground-truth label, respectively. Let $f(\\cdot, \\theta_t)$ be the deepfake detector model with the parameter $\\theta_t$ at t-th epoch. We regard the loss (i.e., the binary entropy loss denoted as $l(f(x_i, \\theta_{t-1}), y_i)$) of i-th sample at t \u2212 1-th epoch as an indicator for the current hardness of this sample judged by the current state of the model before conducting the training step. Thus, we propose the instantaneous hardness $s_t(i)$ that normalized the current loss with the learning rate $\\eta_t$, formulated as:\n$s_t(i) = l(f(x_i; \\theta_{t-1}), y_i) \\cdot \\eta_{max}/\\eta_t,$\t(1)\nwhere $\\eta_{max}$ is the max learning rate during the training. Inspired by Dynamic Instance Hardness (DIH) [21], we measure the dynamic hardness $d_t(i)$ through a moving average of the instantaneous hardness $s_t(i)$ over training history, defined and computed recursively as:\n$d_t(i) = \\begin{cases}\n\\gamma \\times s_t(i) + (1 - \\gamma) \\times d_{t-1}(i), & \\text{if } i \\in H_t\\\\\nd_{t-1}(i), & \\text{otherwise,}\n\\end{cases}$\t(2)\nwhere $\u03b3\u2208 [0, 1]$ is a discount factor, and $H_t$ is the subsets of hard samples at t-th epoch selected by the pacing function.\nAs mentioned in Section 1, detecting low-quality faces is harder than high-quality ones for deepfake detectors. We regard that the facial visual quality can be a prior hardness for deepfake detection tasks. To achieve this, we utilize a pre-trained facial quality assessment model IFQA [22] as a teacher to guide the prior hardness as $q(i) = 1 \u2013 IFQA(x_i)$. Finally, we get DFH by integrating $d_t(i)$ and $q(i)$ as:\n$DFH_t(i) = d_t(i) + \\alpha_f q(i)$\t(3)\nwhere $\u03b1_f$ is a balance weight."}, {"title": "2.3. Pacing Function", "content": "To control the learning pace of presenting data from easy to hard, we design a pacing function to determine the sample pool $X'$ of training data according to DFH. The pipeline is summarized in Algorithm 1. Like human education, if a teacher presents materials from easy to hard in a very short period of time, students would become confused and will not learn effectively. Thus, we define a pacing sequence $T = [T_0,..., T_N]$ to represent n + 1 milestones(i.e., n episodes) in total training epoch T. During the first $T_0$ epochs, we utilize all the samples in X for the warm-up training. After epoch $T_0$, we only change the size of X at every milestone $T_n$. Specifically, at each epoch t of episode n, we select $k_n$ samples with top DFH in X (i.e., hardest samples) as a hard sample pool $H_t$. Along with the training, we reduce the size of $H_t$ by $k_n\u2190 a_k \u00d7 k_{n\u22121}$ with discount factor $a_k$ to make it gradually focus on harder samples. To further enlarge the diversity of the data, we also select the $E_t$ samples with bottom DFH in X (i.e., easiest samples) as a easy sample pool $E_t$ and then conduct lightweight data augmentations $D_A(.)$ (e.g., Gaussian blur, brightness adjustment, and affine transformation) on them. Finally, we get the sample pool X by mixing the $H_t$ and $D_A(E_t)$, i.e, $X'\u2190 H_t \u222a D_A(E_t)$. After that, we sample mini-batch in X' and then conduct a vanilla training step to update the model parameter as $\u03b8_t$."}, {"title": "3. EXPERIMENTS", "content": "3.1. Experiment Settings\nDatasets and pre-processing. In this paper, we mainly conducted experiments on the FaceForensics++ (FF++) dataset [5]. The samples were split into disjoint training, validation, and testing sets at the video level follows the official protocol. As for pre-processing, we utilized MTCNN to detect and crop the face regions (enlarged by a factor of 1.3) from each video frame, and resized the them to 256 \u00d7 256.\nImplementation detail. We employed a SGD optimizer with a cosine learning rate scheduler with $\\eta_{max}$ = 0.1. As for DFFC, we set 20 epoch for totally training, the pacing sequence T = [2, 5, 8, 12, 15] and hyper-parameters $\u03b3 = 0.9, \u03b1_f = 0.5, a_k = 0.9, E = 1000."}, {"title": "3.2. Evaluation of Detection Performances", "content": "In this part, we deployed the proposed DFFC on several end-to-end deepfake detectors for evaluation. We considered three typical kinds of detection methods: 1) Spatial detector, i.e., Xception [23], EfficientNet (ENb4) [24], SwinTransformerV2 (Swin) [25] and MAT [7]; 2) Frequency detector, i.e., SPSL [8]; 3) Detector contained spatial and frequency branches, i.e., SRM [9]. We reproduced the aforementioned methods by their official codes and initialized them with imagenet weights.\nWithin datasets evaluations. We evaluated the performance on detecting five manipulation methods on FF++ (LQ). As shown in Table 1, the proposed DFFC can improve performance for all benchmarks.\nCross datasets evaluations. We evaluated the generalization capability of the proposed DFFC by training on FF++/DF (HQ) and testing on several benchmark datasets, i.e., Celeb-DF (CDF) [26] WildDeepfake(Wild) [27], Deepfake Detection (DFD)\u00b9 and Deepfake Detection Challenge preview (DFDC-p) [28]. As shown in Table 2, our DFFC can improve detection performance for all benchmarks.\nCross manipulation evaluations. We conducted the cross-manipulation experiment on FF++, where our model was trained on the DF(HQ) subset and tested on the remaining four manipulations. Take Xception as an example, the result is shown in Table 3, our DFFC can improve detection performance for all benchmarks.\nAblation studies of facial quality hardness. In this part, we investigated the impact of facial quality hardness. We only used DIH [21], which removes facial quality hardness q(i) compared to DFFC, to train detectors. As shown in Table 1 and Table 2, we can observe that only introducing DIH still improve both within and cross datasets performance for most benchmarks, while introducing the facial quality hardness improve further. It demonstrates that both introducing dynamic hardness and facial quality priors are beneficial to training deepfake detectors.\nComparison with other training strategies. In this part, we"}, {"title": "3.3. Analysis Properties of DFFC", "content": "In this part, we analyze some properties of DFFC. We conduct the subsequent experiments by utilizing Xception trained on FF++/DF(HQ).\nHow DFH changes during the training? In this part, we explored the properties of the training process of DFFC. We respectively selected samples with top (hard samples), bottom (easy samples) and median DFH and illustrated the variations of their DFH during the training. As shown in Figure 4, we can observe that DFH decreases along the training for all samples. We can also find that DFH of easy samples remains small throughout training. This is because deepfake detectors can learn to identify easy samples in the early stages of training so that DFFC does not tend to update their DFH. However, the detectors needs more time to mine the forged clues of the difficult samples. It indicates that as learning continues, easy samples become less informative so that we can select and train on fewer hard samples.\nWhat do hard samples look like? We explored the properties of samples with different hardness mined by DFFC. We respectively illustrated the samples with top and bottom DFH in Figure 5. We can observe that the fake faces with top DFH are relatively high-quality compared to those with bottom DFH, which cannot be easily distinguished. These fake samples with bottom DFH always contain more clear forgery clues, such as color inconsistency. For real faces, top DFH samples usually have heavy post-processing which is easy to confuse with fake faces. It demonstrates that the DFH score mined by our DFFC is in line with human visual perception. We also computed the pixel-level tampering ratio (TAR) and SSIM [31] metrics for fake samples with their corresponding real faces. As shown in the Table 4, fake faces with top DFH involve low TAR and high SSIM, which indicates these samples have less forgery artifacts and higher similarities to the corresponding real faces. It makes sense that deepfake detectors would have difficulty identifying these samples."}, {"title": "4. CONCLUSION", "content": "In this paper, we propose DFFC as a general training strategy for deepfake detection. First, we present DFH, an innovative metric that integrates the facial quality score and instantaneous instance loss to dynamically evaluate the sample hardness during the training process. Furthermore, we introduce a pacing function that controls the training subsets from easy to hard basd on DFH throughout the iterations of training. It makes deepfake detectors gradually focus on hard samples to mine the general forgery clues during the training."}]}