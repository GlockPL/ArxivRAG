{"title": "Criteria-Aware Graph Filtering: Extremely Fast Yet Accurate Multi-Criteria Recommendation", "authors": ["Jin-Duk Park", "Jaemin Yoo", "Won-Yong Shin"], "abstract": "Multi-criteria (MC) recommender systems, which utilize MC rating information for recommendation, are increasingly widespread in various e-commerce domains. However, the MC recommendation using training-based collaborative filtering, requiring consideration of multiple ratings compared to single-criterion counterparts, often poses practical challenges in achieving state-of-the-art performance along with scalable model training. To solve this problem, we propose CA-GF, a training-free MC recommendation method, which is built upon criteria-aware graph filtering for efficient yet accurate MC recommendations. Specifically, first, we construct an item-item similarity graph using an MC user-expansion graph. Next, we design CA-GF composed of the following key components, including 1) criterion-specific graph filtering where the optimal filter for each criterion is found using various types of polynomial low-pass filters and 2) criteria preference-infused aggregation where the smoothed signals from each criterion are aggregated. We demonstrate that CA-GF is (a) efficient: providing the computational efficiency, offering the extremely fast runtime of less than 0.2 seconds even on the largest benchmark dataset, (b) accurate: outperforming benchmark MC recommendation methods, achieving substantial accuracy gains up to 24% compared to the best competitor, and (c) interpretable: providing interpretations for the contribution of each criterion to the model prediction based on visualizations.", "sections": [{"title": "1 Introduction", "content": "Multi-criteria (MC) recommender systems, which leverage detailed criteria ratings for each item, have become increasingly important across various online service areas, including travel, restaurants, hotels, movies, and music [11, 17, 20, 22, 31, 38]. MC recommender systems generally excel in recommending relevant items to users compared to single-criterion recommender systems, as they capture user preferences more exquisitely [5, 11, 17, 22, 31, 47]. For example, as illustrated in Figure 1a, in a restaurant domain, a user can provide four criteria ratings, which include an overall rating as well as other MC ratings for food, service, and location.\nNonetheless, the inclusion of MC ratings in MC recommender systems often significantly increases computational demands compared to single-criterion counterparts, due to the complexity of processing and analyzing multi-dimensional user feedback [18, 42]. For instance, given N user-item interactions with 8 criteria, training-based collaborative filtering (CF) methods having a computational complexity of $O(N^2)$ increase the training time by approximately 64 times over the single-criterion case. As shown in Figure 1b, the time required for identical epochs in training substantially escalates when MC ratings are incorporated into three benchmark deep neural network (DNN)-based MC recommendation methods, including AEMC [31], ExtendedSAE [35], and CPA-LGC [25]. Acknowledging that user preferences evolve quickly due to trends, personal circumstances, and exposure to new content, such latency in training time may not be desirable [1, 13, 26, 28].\nUnlike earlier studies on learning models such as graph convolution for recommendations in a parametric manner [7, 8, 40, 41, 46], our study is inspired by recent advances in non-parametric,"}, {"title": "2 Preliminaries", "content": "2.1 Problem Definition\nWe formally define the top-K MC recommendation, along with basic notations. Let $u \\in U$ and $i \\in I$ denote a user and an item, respectively, where $U$ and $I$ denote the sets of all users and all items, respectively. $N_u \\subset I$ denotes a set of items interacted by user u. Compared to single-criterion recommender systems, MC recommender systems comprise of a number of rating criteria. We denote $R_c \\in \\mathbb{R}^{|U|\\times|I|}$ as the rating matrix (i.e., the user-item interaction matrix) for criterion c. In particular, $R_0 \\in \\mathbb{R}^{|U|\\times|I|}$ refers to the overall rating matrix. Then, the top-K MC recommendation problem is formally defined as follows:\nDefinition 1. (Top-K MC recommendation) [25]: Given $u \\in \\text{\u0418}$ and $i \\in I$, and $C + 1$ user-item rating matrices $R_0 \\times R_1 \\times ... x R_C$ including an overall rating matrix $R_0$, the top-K MC recommendation aims to recommend top-K items that user $u \\in U$ is most likely to prefer among his/her non-interacted items in $I \\setminus N_u$ w.r.t. the overall rating by using all $C + 1$ user-item MC ratings.\n2.2 Graph Signal Processing\nWe introduce basic concepts of graph signal processing. First, we consider a weighted undirected graph $G = (V, E)$, represented by an adjacency matrix $A \\in \\mathbb{R}^{|V|\\times|V|}$. A graph signal is a function $f : V \\rightarrow \\mathbb{R}^d$ that encodes the set of nodes into a d-dimensional vector $x = [x_1, x_2,...,x_{|v|}]^T$, where $x_i$ represents the signal strength of node i. The smoothness of x on G is quantified by the graph quadratic form, a measure based on the graph Laplacian $L = D - A$, where $D = diag(A\\mathbf{1})$ is the degree matrix. The smoothness measure $S(x)$ is formally expressed as follows [32, 33]:\n$S(x) = \\sum_{i,j} A_{i,j} (x_i \u2013 x_j)^2 = x^T Lx$.\n(1)\nThe smaller the value of $S(x)$, the smoother the signal x is on the graph. Next, we formally define the graph Fourier transform (GFT) for a graph signal x as:\n$\\hat{x} = U^T x$,\n(2)"}, {"title": "3 Proposed Method: CA-GF", "content": "3.1 Overview\nThe objective of our study is to judiciously incorporate MC ratings into graph filtering without losing its computational efficiency. To this end, we propose CA-GF, a not only training-free but also matrix decomposition-free graph filtering method. In particular, in CA-GF, criteria-aware graph filters built upon an MC user-expansion graph are accommodated to effectively capture the collaborative signal in complex contextual semantics across MC ratings.\nTo achieve the aforementioned goals G1-G3 in Section 1, the proposed CA-GF consists of the following components:\n(1) Graph construction: To accomplish G1, we initially construct an MC user-expansion graph that enables us to capture complex contextual semantics in MC ratings. Next, we construct an item-item similarity graph to design a new graph filtering method with regulated edge weights (see Section 3.2).\n(2) Graph filtering harnessing criteria awareness: To accomplish G2, due to the fact that the optimal filter can be found differently for each criterion, we propose criterion-specific graph filtering (see Section 3.3.1). Moreover, we perform criteria preference-infused aggregation that combines the smoothed signals from each criterion to enrich the criteria awareness (see Section 3.3.3).\n(3) Polynomial graph filtering: To accomplish G3, we propose to use polynomial graph filtering [26], which is performed without costly matrix decomposition to achieve extremely fast recommendation when accommodating multiple graph filters (see Section 3.3.2).\nWe elaborate on the technical details of the proposed CA-GF method in the following subsections, where the schematic overview is illustrated in Figure 2.\n3.2 Graph Construction\n3.2.1 MC user-expansion graph construction. As stated in Section 3.1, graph filtering-based CF methods in single-criterion recommender systems [3, 19, 32, 43] typically utilize the rating matrix to construct the item-item similarity graph. However, as long as MC ratings are associated, it is not straightforward how to construct an item-item similarity graph. As the primary component of our study, the first step of CA-GF is to create an MC user-expansion graph, where each user is expanded to $C + 1$ different criterion-user nodes to capture complex semantics inherent in MC ratings. Precisely, the rating matrix $R_{MC} \\in \\mathbb{R}^{(C+1)|U|\\times|I|}$ for our MC user-expansion graph is designed by concatenating the $C + 1$ rating matrices as follows:\n$R_{MC} = R_0 || R_1 || ... || R_C,$\n(7)\nwhere the operator $||$ denotes the concatenation of matrices, which enables us to explore complex high-order connectivity among criterion-user nodes and item nodes [25]. Then, we normalize $R_{MC}$"}, {"title": "3.2.2 Item-item similarity graph with adjustment", "content": "To perform graph filtering, we construct the normalized item-item similarity graph $P_{MC} \\in \\mathbb{R}^{|I|\\times|I|}$ using $\\hat{R}_{MC}$ in Eq. (8) as follows:\n$P_{MC} = \\hat{R}_{MC}^T \\hat{R}_{MC},$\n(9)\nwhich represents the degree of similarity between each pair of items. Note that, compared to the case of expanding each item node to $C + 1$ criterion-item nodes [25], our approach effectively prevents the high dimensionality problem of the item-item similarity graph, while achieving G1 by constructing a unified graph structure across MC ratings towards graph filtering. Next, according to the type of graph filters that we use based on $P_{MC}$, the corresponding filtered signals are over-smoothed or under-smoothed, depending on the intensity of connections between nodes in $P_{MC}$. For instance, using a linear LPF (i.e., $P_{MC}$) would be less prone to over-smoothing since it is associated only with the first-order connectivities. Thus, we aim to adjust the filtered signals differently for each graph filter $f(.)$. To this end, similarly as in [26], we employ an additional adjustment process for the graph $P_{MC}$. This process utilizes the Hadamard power $P_f$ by raising each edge weight of $P_{MC}$ to the power of $s_f$, which is formulated as\n$(P_f)_{ij} = (P_{MC})_{ij}^{s_f},$\n(10)\nwhere $(P_f)_{ij}$ is the (i, j)-th element of matrix $P_f$ and $s_f$ is the adjustment parameter for graph filter $f(\u00b7)$, which will be specified in Section 3.3."}, {"title": "3.3 Graph Filtering Harnessing Criteria Awareness", "content": "We describe how to perform graph filtering based on the adjusted item-item similarity graph $P_f$.\n3.3.1 Criterion-Specific Graph Filtering. In single-criterion recommender systems, it is required to discover only a single optimal LPF that promotes smoothness of the graph signals for denoising [32]. In MC recommendations, however, the optimal LPF for each criterion is often different. For instance, for relatively subjective"}, {"title": "3.3.2 Polynomial Graph Filtering", "content": "We now specify the criterion-specific graph filter $f(P_f, c)$ in Eq. (11) that is decided depending on each criterion c. As stated in G3, using multiple filters for MC ratings naturally produces additional computation costs caused by a matrix decomposition process in Eq. (6). To bypass the high computation overhead, a recent study [26] proposed to use polynomial graph filters for CF. Inspired by this, we also employ multiple polynomial graph filters, applying a distinct polynomial LPF for each criterion. The polynomial graph filter up to the K-th order can be expressed as\n$f(P_{f. c}) = \\sum_{k=1}^{K}a_{c,k}P_f^k,$\n(12)\nwhere $f(P_f, c)$ is the polynomial graph filter specific to criterion c; $a_{c,k}$ is the coefficient of a matrix polynomial; and $K$ is the maximum order of the matrix polynomial basis. Note that, using Eq. (12), any LPFs can be designed by adjusting $a_{c,k}$. To design universal polynomial LPFs, we establish the following lemma:\nLEMMA 4. [26, 32]: The matrix polynomial $\\sum_{k=1}^{K}a_{c,k}P_f^k$ is a graph filter for graph $P_f$, with the frequency response function of $h(\\lambda) = \\sum_{k=1}^{K} a_{c,k} (1 \u2013 \\lambda)^k$.\nAccording to Lemma 4, one can find the optimal polynomial LPF by extensively searching for ${a_{c,k}}_{k=1}^K$ using the validation set, which however comes at the expensive computation costs and thus violates our design goal G3. Alternatively, we present three representative (i.e., predefined) polynomial LPFs, namely linear ($P_f$), inward ($P_f^2$), and outward ($2P_f \u2013 P_f^2$) LPFs, which essentially embrace a broad set of LPFs. These three types of graph filters are implemented within second-order polynomials (i.e., $K = 2$)."}, {"title": "3.3.3 Criteria Preference-Infused Aggregation", "content": "One can aggregate the smoothed signals in Eq. (11) by simply summing up the smoothed signals for all criteria. However, users often exhibit different criteria preferences [25, 34]. For instance, in a hotel domain, a user tends to make decisions based on the cleanliness aspect of a hotel, while another user decides based on the service aspect. To accommodate such personalized information into our CA-GF method, we additionally devise a novel criteria preference-infused aggregation technique for elaborately capturing the criteria preferences of each user. From the fact that the number of ratings often differs from each criterion [25], we claim that, if a user gave more and/or higher ratings on a certain criterion, then he/she tends to reveal a higher preference for the criterion, which will be empirically validated via ablation studies in Section 4.4. Based on this claim, we formalize our aggregation technique as follows:\n$\\hat{C} = X T; T_{ij} = T_{ji}; T = \\hat{X}^T \\hat{X};$\n$\\hat{X} = X D^{-1} \\hat{X} = (R_0\\mathbf{1})||(R_1\\mathbf{1})||\u00b7\u00b7\u00b7||(R_C\\mathbf{1});$\n(16)\nwhere $X \\in \\mathbb{R}^{|U|\\times(C+1)}$ represents the sum-rating matrix for each criterion whose (u, c)-th element refers to the sum of ratings given by a user u to all relevant items for criterion c; $X$ is the normalized matrix of $X$ along $D^{-1} = diag(X\\mathbf{1})$; $T = \\hat{X}^T\\hat{X} \\in \\mathbb{R}^{(C+1)\\times(C+1)}$ is the criterion-criterion similarity graph; $T_{ij}$ is the (i, j)-th element of the adjacency matrix of criterion-criterion similarity graph $T$ adjusted with the parameter sf; and $\\hat{C} \\in \\mathbb{R}^{|U|\\times(C+1)}$ is the criteria preference matrix in which $X$ serves as signals for graph filtering. Then, the matrix $\\hat{C}$ is used for weights during aggregation to infuse the criteria preferences of users. Finally, as illustrated in Figure 2, the predicted rating of user u after the criteria preference-infused aggregation is expressed as\n$\\hat{s}_u = \\frac{1}{C+1}\\sum_{c=0}^{C} \\hat{C}_{u,c}\\hat{s}_{u,c};$\n$\\hat{s}_u = \\frac{1}{C+1}\\sum_{c=0}^{C} C_{u,c};$\n(17)\nwhere $C_{u,c}$ is the preference of user u on the criterion c in $\\hat{C}$."}, {"title": "4.1 Experimental Settings", "content": "Datasets. We carry out experiments on three public datasets, which are widely used in studies on MC recommendation [5, 18, 22, 25, 31, 35]: TripAdvisor (TA), Yahoo! Movie (YM), and BeerAdvocate (BA). Statistics of the three datasets are summarized in Table 1.\nCompetitors. To comprehensively demonstrate the superiority of CA-GF, we present six benchmark MC recommendation methods (including ExtandedSAE [35], AEMC [31], DMCF [22], CFM [4, 5], CPA-LGC [25], and GF-CFMC). Additionally, to observe the potential benefits of MC ratings, we include four representative single-criterion recommendation methods (namely NGCF [40], LightGCN [7], GF-CF [32], and DiffRec [39]), where only overall ratings are used due to the incapability of using MC ratings as input. In our study, to show the results by a na\u00efve extension of GF-CF to MC settings, we additionally introduce a variant of GF-CF, termed GF-CFMC. This variant employs GF-CF [32] to each of $C + 1$ item-item similarity graphs constructed from MC ratings, and then aggregates the output through summation for the final prediction. We refer to Appendix E.2 for further details of GF-CFMC.\nEvaluation protocols. We randomly select 80% of the interactions of each user for the training set and the remaining 20% as the test set. From the training set, we randomly select 10% of interactions as the validation set for hyperparameter tuning. To evaluate the accuracy of top-K MC recommendation, we use benchmark metrics that are widely used in literature [6-9, 24, 36, 40, 41, 45, 46], such as recall and normalized discounted cumulative gain (NDCG), where K is set to 5 and 10 by default. In the test phase, we treat user-item interactions with overall ratings that are higher than the median rating in the test set as positive, following the protocols in other studies on the MC recommendation [22, 25, 31, 35]. For each metric, we report the average taken over 10 independent runs except for deterministic methods (i.e., GF-CF, GF-CFMC, and CA-GF).\nImplementation details. We use the best hyperparameters of competitors obtained by extensive hyperparameter tuning on the"}, {"title": "4.2 RQ1: Efficiency Analysis", "content": "Table 2 showcases the computational efficiency on the BA dataset, the largest dataset with more than 3M MC ratings. Moreover, to validate the scalability of CA-GF, we present a runtime comparison on different device configurations, i.e., cases without GPU (i.e., CPU only) and with GPU, using various synthetic datasets with C = 4 in Figure 3; in this experiment, we generated seven synthetic datasets whose sparsity level is controlled to 98.5%, where the numbers of (users, items, MC ratings) are set to {(1.5K, 3K, 0.3M), (2.5K, 5.5K, 1M), (4K, 6K, 1.8M), (5K, 9K, 3.4M), (8K, 10K, 6M), (10K, 15K, 11M), (25K, 20K, 38M)}. Our findings are as follows:\n(i) Notably, Table 2 demonstrates that training-free methods, GF-CFMC and CA-GF, outperform training-based methods such as ExtendedSAE, AEMC, and CPA-LGC in terms of runtime efficiency. Specifically, CA-GF achieves the runtime of 0.2 seconds, whereas other training-based methods require over 1,000 seconds for the model convergence.\n(ii) Furthermore, Table 2 shows that, although GF-CFMC alleviates the computational demands of matrix decomposition using the generalized power method [12, 32], CA-GF is over 2,160\u00d7 faster than GF-CFMC on the BA dataset. This is owing to the use of matrix decomposition-free polynomial filters in CA-GF, which efficiently utilize GPU resources for achieving G3. Moreover, Figure 3 demonstrates that, while GF-CFMC is a training-free solution, CA-GF consistently and significantly outperforms GF-CFMC in terms of runtime across the datasets of various sizes.\n(iii) Figure 3 reveals the scalability of CA-GF. By fully utilizing the parallel computing capabilities of GPU, CA-GF runs consistently within 2 seconds for datasets containing up to 6M MC ratings. Even when the size of the loaded data exceeds GPU memory limits, CA-GF demonstrates robust performance on CPU, maintaining runtime below 2 minutes for datasets exceeding 38M MC ratings. This highlights the computational efficiency of CA-GF, especially in handling large-scale datasets."}, {"title": "4.3 RQ2: Recommendation Accuracy", "content": "We compare the accuracy of CA-GF against the competitors specified in Section 4.1. For the methods that were originally designed for single-criterion recommender systems (NGCF, LightGCN, GF-CF, and DiffRec), we use single ratings (i.e., overall ratings). Table 3 shows the results of all the competitors and CA-GF. Our findings are as follows:\n(i) CA-GF consistently outperforms all the competitors regardless of the performance metrics and datasets. In particular, CA-GF achieves state-of-the-art performance with significant gains up to 24% in terms of the NDCG@5 on TA.\n(ii) The use of MC ratings remarkably boosts the performance, with CPA-LGC and CA-GF surpassing their single-criterion counterparts, namely LightGCN and GF-CF, respectively.\n(iii) MC recommendation methods that are built upon DNNs or matrix factorization (ExtendedSAE, AEMC, DMCF, and CFM) show comparatively inferior performance to that of GCN (CPA-LGC) or graph filtering (GF-CFMC and CA-GF). This implies that explicitly exploiting the complex structural information for MC recommendations is indeed beneficial for accurate recommendations.\n(iv) Meanwhile, performance comparison between CA-GF and GF-CFMC reveals that, while graph filtering-based methods generally yield superior results, the gain of CA-GF over GF-CFMC is also significant. This underscores that the mere adoption of graph filtering for MC recommendations is insufficient to achieve optimal accuracy."}, {"title": "4.4 RQ3: Ablation Studies", "content": "To analyze the contribution of each component in CA-GF, we conduct an ablation study in comparison with four variants depending on which components are taken into account for designing the end-to-end CA-GF method. The performance comparison among the four methods is presented in Table 4 w.r.t. the Recall@10 using three datasets.\n\u2022 CA-GF: corresponds to the original CA-GF method without removing any components;\n\u2022 CA-GF-m: removes the MC user-expansion graph. That is, only a single criterion (i.e., overall ratings) is used for graph construction;\n\u2022 CA-GF-s: replaces all sf's by 1. That is, the adjustment parameter is ablated;"}, {"title": "4.5 RQ4: Sensitivity Analysis", "content": "We investigate the impact of key parameters in CA-GF on the recommendation accuracy, which include the selection of graph filters $f(P_f, c)$ for criterion c and the adjustment parameter sf for each $f(P_f, c)$. For notational simplicity, we denote the three polynomial LPFs (i.e., linear, inward, and outward LPFs) as L, I, and O, respectively. When each parameter varies so that its effect is revealed, other parameters are set to the pivot values specified in Appendix E.3."}, {"title": "4.6 RQ5: Interpretability", "content": "Unlike canonical black-box recommendation methods based on DNNS, CA-GF offers significant advantages in model interpretability, allowing an in-depth understanding of each prediction process. For instance, we generate an attribution map that quantifies the influence of MC on the model predictions, Specifically, the attribution map of the user-item interaction (u, i) visualizes the i-th component of $\\hat{C}_{u,c}\\hat{s}_{u,c} \\in \\mathbb{R}^{|I|}$ in Eq. (17) for different c's. It represents each user's criteria preferences for certain items, which provides insight into the importance of each criterion. For instance, Figure 6 illustrates two attribution maps for the two different interactions of (user, item), including (1, 7) and (1844, 1) on the TA dataset. The following observations are made.\n(i) These two instances display different patterns, which verifies that each criterion makes a different contribution to the model prediction.\n(ii) It is likely that the two criteria check-in and rooms contribute less to the prediction of CA-GF, compared to the other criteria.\nThis level of interpretability is invaluable, not just for comprehending the model's functionality but also for guiding strategic business decisions, thus enabling model refinement and enhancement."}, {"title": "5 Related Work", "content": "Graph filtering-based approaches. Within the realm of graph signal processing, GCN is regarded as a parameterized graph convolutional filter [16, 32]. As a representative approach, NGCF [40] was introduced by learning appropriate LPFs while capturing high-order collaborative signals inherent in user-item interactions [32]. LightGCN [7] achieved convincing performance by eliminating"}, {"title": "6 Conclusions and future work", "content": "In this paper, we explored how fast and accurate graph filtering can be developed in MC recommender systems. To this end, we introduced CA-GF, the first attempt to design a graph filtering-based MC recommendation method that is not only training-free but also matrix decomposition-free, thereby circumventing the problem of the computational burden that MC ratings entail. Through extensive experiments on three benchmark datasets, we demonstrated the impact and benefits of CF-GF from various perspectives, including (a) the extraordinarily computational efficiency with the runtime of less than 0.2 seconds on BA, the largest dataset, (b) the superior accuracy over other competing MC recommendation methods, (c) the impact of using different optimal LPFs for each criterion, (d) the effectiveness of each component, and (e) the interpretability via visualizing each user's criteria preferences for certain items. Potential avenues of our future research include the design of an adaptive graph filter such that the optimal LPF for each criterion is found more effectively."}, {"title": "A Definition of LPF", "content": "We formally define the LPF as follows:\nDefinition 5. (LPF) [29, 32, 37]: For k = 1,\u00b7\u00b7\u00b7, |V| and 1 \u2264 \u06f0\u06f0\u06f0 \u2264 $\\lambda_{|V|}$, the graph filter H(L) is k-low-pass if and only if $\u03b7_k \u2208 [0, 1]$, where\n$\u03b7_k := \\frac{max{\\{|h(\\lambda_{k+1})|,\u00b7\u00b7\u00b7,|h(\\lambda_{|V|})|\\}}}{min{\\{|h(\\lambda_{1})|,\u00b7\u00b7\u00b7,|h(\\lambda_{k})|\\}}}$,\n(18)"}, {"title": "C Proofs of Corollaries", "content": "Proof of Corollary 4.1. Although the proof of Corollary 4.1 is presented in [19], we provide the full proof for completeness. First, the Laplacian matrix L can be decomposed as\n$L = U \u039b U^T = U diag(\u03bb_1, \u03bb_2, . . ., \u03bb_m)U^T,$\n(19)\nwhich indicates that L is a graph filter with the frequency response function of $h(\u03bb) = \u03bb$. Then, we have\n$\\hat{L} = I - P_f$.\n(20)\nSuppose that $U_i$ is the eigenvector of L corresponding to the eigenvalue $\u03bb_i$, Then, using Eq. (20), we have\n$L\\hat{U}_i = \u03bb_i \\hat{U}_i = (I - P_f)\\hat{U}_i,$\n(21)\nresulting in\n$P_f \\hat{U}_i = (1 - \u03bb_i) \\hat{U}_i$.\n(22)\nThis means that $L$ and $P_f$ have the same eigenvectors and the corresponding eigenvalues have the following relationship:\n$(P_f)_i = 1 \u2212 \u03bb_i,$\n(23)"}, {"title": "E.1 Dataset Description", "content": "We describe the details of the datasets used in our experiments.\nTripAdvisor (TA): The TA dataset, released by [38], comprises hotel rating information, including an overall rating as well as ratings for seven comprehensive criteria: business, check-in quality, cleanliness, location, rooms, service, and value. The ratings are on a scale of 1 to 5 for all criteria.\nYahoo!Movie (YM): The YM dataset, first introduced by [11], comprises movie rating information, including an overall rating as well as ratings for four specific criteria: story, acting, direction, and visuals. The ratings are on a scale of 1 to 5 for all criteria.\nBeerAdvocate (BA): The BA dataset, released by [20, 21], comprises beer rating information, including an overall rating as well as ratings for four specific criteria: appearance, aroma, taste, and palate. The ratings range from 1 to 5 for all criteria."}, {"title": "E.2 Details of GF-CFMC", "content": "Figure 7 illustrates the schematic overview of GF-CFMC. Given MC rating matrices $R_c$ for criterion $c \u2208 {0, 1,, C}, GF-CFMC first separately construct C + 1$ bipartite graphs, and performs GF-CF [32] on each of $C + 1$ different criteria. Then, the predicted ratings $\\hat{s}_{u,c}$ for each criterion are aggregated by simple summation for the final prediction. This approach differs from CA-GF, which uses an integrated graph, called the MC user-expansion graph, for graph filtering. Moreover, while GF-CFMC uses the same graph filter across the criteria, CA-GF leverages a different optimal graph filter depending on the criterion, which effectively harnesses criteria awareness."}]}