{"title": "Efficient Feature Extraction and Classification Architecture for MRI-Based Brain Tumor Detection", "authors": ["Plabon Paul", "Md. Nazmul Islam", "Fazle Rafsani", "Pegah Khorasani", "Shovito Barua Soumma"], "abstract": "Abstract-Uncontrolled cell division in the brain is what gives rise to brain tumors. If the tumor size increases by more than half, there is little hope for the patient's recovery. This emphasizes the need of rapid and precise brain tumor diagnosis. When it comes to analyzing, diagnosing, and planning therapy for brain tumors, MRI imaging plays a crucial role. A brain tumor's development history is crucial information for doctors to have. When it comes to distinguishing between human soft tissues, MRI scans are superior. In order to get reliable classification results from MRI scans quickly, deep learning is one of the most practical methods. Early human illness diagnosis has been demonstrated to be more accurate when deep learning methods are used. In the case of diagnosing a brain tumor, when even a little misdiagnosis might have serious consequences, accuracy is especially important. Disclosure of brain tumors in medical images is still a difficult task. Brain MRIs are notoriously imprecise in revealing the presence or absence of tumors. Using MRI scans of the brain, a Convolutional Neural Network (CNN) was trained to identify the presence of a tumor in this research. Results from the CNN model showed an accuracy of 99.17%. The CNN model's characteristics were also retrieved. In order to evaluate the CNN model's capability for processing images, we applied the features via the following machine learning models: KNN, Logistic regression, SVM, Random Forest, Naive Bayes, and Perception. CNN and machine learning models were also evaluated using the standard metrics of Precision, Recall, Specificity, and F1 score. The significance of the doctor's diagnosis enhanced the accuracy of the CNN model's assistance in identifying the existence of tumor and treating the patient.", "sections": [{"title": "I. INTRODUCTION", "content": "Brain is a core part of CNS (Central Nervous System), which regulates all physiological and cognitive activities i.e. thought, emotion, touch, motor skils, vision, respiration etc. [1]. Brain tumor is uncontrolled cell division in brain or other parts of the CNS that causes malfunctioning. The malignancy of a tumor depends on how fast the cell repro- duces. Non-malignant (benign and not cancerous) tumors grow slowly and do not spread into other tissues. Malignant brain tumors are cancerous. Most of the time, they multiply and invade neighboring healthy tissues [2] [3]. In USA, there are an estimated 20,500 primary brain tumors identified each year; 3750 of these instances include people under the age of 19 and 2870 involved children under the age of 15 [4]. In comparison to tumors in any other organ of the human body, diagnosing a tumor in the brain is particularly difficult. The blood-brain barrier (BBB) surrounds the brain, making it impossible for regular radioactive markers to detect the tumor cells' increased activity. Additionally, tumor size, shape, location, and type make early detection more challenging [3] [5]. Brain tumor incident is more common in developed countries. Australia, North America, and Northern Europe have the highest rates of brain tumors. On the other hand, Africa has the lowest rate [6].\nDeep learning and machine learning are two new tech- nologies that have significantly developed different fields of applications [7]-[10]. In particular, a vast field of study has been opened up in medical image processing, and several studies are currently being conducted in this field of study. An important aspect of this study area involves automating the segmentation and categorization of brain tumors. Akram et. al [11] introduced a computer-aided method for identifying tumors in which they segmented tumors using the global thresholding methodology. Sharjar et al [12] presented an automated method for detecting brain tumor. The photos were preprocessed using image enhancement filters, followed by additional segmentation and the extraction of characteristics to identify the tumor. Parasuraman et al [13] used a feed-forward neural network to classify tumor and normal regions. The method involves four steps: pre-processing with filters, image segmentation with clustering, feature extraction using gray- level co-occurrence matrix (GLCM), and tumor classification with ensemble classifier. Irmak et al. [14] developed three CNN models for three different datasets. Accuracy for the three datasets was 99.33%, 92.66%, and 98.14% respectively. Although multi classification accuracy wasn't as good as binary classification."}, {"title": "II. MATERIALS AND METHODS", "content": "We implemented a CNN model from scratch, three pre- trained models, and five traditional ML models in our proposed method. Our main objective is to diagnose brain tumors effec- tively and precisely by sending MRI pictures of the tumors to a CNN. Fig. 1 represents the workflow of our study. Labeled MRI images are supplied into a CNN feature extractor after minimum preprocessing, and the retrieved features are fed into a classification layer. Finally, we compared the performance of our trained model to the current state of the art in various aspects."}, {"title": "A. Dataset", "content": "The Brain Tumor Detection 2020 (BR35H) [15] dataset, which includes two unique classes of MRIs of brain tu- mors (1500 negative and 1500 positive), is utilized to train CNN.80% of the images from this dataset are used for training the model. Fig 2 displays a few samples from datasets that includes data from two different types of brain MRI."}, {"title": "B. Data Preprocessing", "content": "All the images are preprocessed before being fed to CNN, as described in Fig. 1 These images are initially transformed into single-channel images, sometimes referred to as greyscale images. The dimension of each image is different in the dataset. Therefore, these images are reshaped into a fixed size. Then, every image is converted to a two-dimensional array. After that, each image is normalized so that the value of each array element is converted to the range [0,1]."}, {"title": "C. Feature Extraction", "content": "1) Modified DenseNet: DenseNet is a type of network architecture in which each layer is directly connected to every other layer (within each dense block) [16]. For each layer, the feature maps of all preceding layers are treated as separate inputs, whereas its own feature maps are passed on as inputs to all subsequent layers. The original network's inputs are 256*256 in size. This model has 707 layers and it is fine tuned after 500 layer for better performance. A global average pooling layer and a dense layer have also been added, which enhance the performance of the original model.\n2) Modified ResNet50: The Residual Networks, or ResNet for short, took first place in the 2015 ImageNet competition [17] and is now employed for a variety of computer vision- related applications. Here, solving the issue of vanishing gradients and drastically reducing the number of parameters is the major objective of training a very deep neural network. As shown in Fig. 3c,The layer connections are skipped. The size of the inputs in the original architecture was 224*224. It requires 175 layers where after 125 layer rest of them are fine tuned. A global average pooling layer and a dense layer have been added, which enhance the performance of the original model.\n3) Modified EfficientNetB0: Tan et al. developed the Ef- ficientNetB0 architecture to make scaling models simpler by balancing the network's height, depth, and input resolution to increase accuracy [18]. This study uses the underlying EfficientNet-B0 network, which is based on the MobileNet- V2 inverted bottleneck residual blocks. The size of the inputs in the original network is 224*224 and here in the modified network it has been changed to 64*64. Having 237 layers in this architecture, rest of the layer after 150th layer were fine tuned. In addition, a dense layer and a global average pooling layer have been added to the original model to improve its performance.\n4) CNN model from Scratch: Fig. 3a shows the architecture of a twelve layer CNN model that is built from scratch to classify brain tumors. This model was built by trying different ways to tune the hyper-parameters. The best one is selected by running a random search on various combinations of the model's hyper-parameters while using Keras Tuner. The model has four convolution layers, four max pooling layers, one batch normalization layer, one flatten layer, and one dropout layer. Here the input size is 32*32. After passing through all the convolution, max pooling, batch normalization, and dropout layers, the input size finally becomes width*height. In every convolution layer, the RELU activation function was utilized. And for optimization, the Adam optimizer was used with the Sparse Categorical cross-entropy loss function."}, {"title": "D. Machine Learning Classifiers", "content": "1) KNN: KNN is a Supervised learning algorithm which can solve both classification and regression predicting prob- lems. It is a lazy algorithm because it uses all of the data for training during classification and lacks a training phase. In this algorithm, the number K of the neighbors has been chosen. Then the Euclidean distance between K neighbors has been calculated and K nearest neighbors were chosen based on distance value. Then, for each category, the number of data points among those K neighbors has been counted. Finally, the category with the highest neighbor count has been given to the new data points.\n2) SVM: Parametric classification aims to describe the usual feature space values or distribution of each class. SVM, in contrast, focuses solely on the training samples that are situated closest to the ideal class border in the feature space [19] [20]. The name of the approach comes from these samples, which are known as support vectors. The SVM classifier is fundamentally binary in that it recognizes only one distinction between two classes.\n3) Naive Bayes: Naive Bayesian networks (NB) are the most basic types of Bayesian networks. They are made up of DAGs with a single parent (representing the invisible node) and a large number of children (corresponding to the visible nodes), and they make a strong assumption that each child node is independent of the other child nodes.As a result, the independence model (Naive Bayes) is based on estimating:\n$R=\\frac{P(i|X)}{P(j|X)}=\\frac{P(i)P(X|\u0456)}{P(j)P(X|j)} = \\frac{P((i)\\prod P(X_r|i))}{P((j)\\prod P(X_r|j)}$\nIf R>1, then the Naive Bayes model will predict i, else it will predict j. Typically, Bayes classifiers perform less accu- rately than other, more advanced learning algorithms (such as ANNs).\n4) Random Forest: Random Forest is a classifier that em- ploys several decision trees on various subsets of the input dataset and averages the outcomes to improve the projected"}, {"title": "III. RESULTS AND DISCUSSION", "content": "In this paper, we have implemented four different models which are Densenet, Resnet50, EfficientnetB0, and our own CNN model. For optimization of our deep learning model, we used Adam algorithm. First, the performance is evaluated using several performance metrics. During the training of a model, we concentrated on reducing loss while simultaneously boosting accuracy. Table I displays the validation accuracy of each model. Here, we can observe that the validation accuracy was best achieved by our own CNN model. Fig. 7b also displays the outcome graphically. Then, using these models, extracted features are sent to various machine learning mod- els. And the outcome is revealed on Fig 7a. From the Ta- ble II, we can conclude that Scratch+SVM, DenseNet+SVM, ResNet+SVM, and EfficientNet+Logistic Regression perform better than any other combination of machine learning and pretrained models and the comparison is illustrated in Fig. 7a."}, {"title": "A. Performance metrics", "content": "Evaluation metrics are used to measure the quality of a model. Evaluating models or algorithms is essential for any project. A model can be tested using a wide variety of evaluation metrics. Confusion metrics had been applied in this scenario. An N*N matrix, where N is the number of expected classes, is a confusion matrix. Since N=2 applies to our issue, we receive a 2*2 matrix. True Positive (TP) indicates the number of accurately categorized attack records. True Negative (TN) is the proportion of correctly categorized normal records. False Positive (FP) is the quantity of typical records that were misclassified. False negatives (FN) is the number of attack records that were wrongly categorised.\n\u2022 Accuracy (AC):\n$AC = \\frac{TP+TN}{TP+TN+FP+ FN}$\n\u2022 Precision (P):\n$P = \\frac{TP}{TP+FP}$\n\u2022 Recall (R):\n$R = \\frac{TP}{TP+FN}$\n\u2022 F1 Score (F):\n$F = (\\frac{recall^{-1} + precision^{-1}}{2})^{-1}$\n\u2022 Spicificity (SP):\n$SP = \\frac{TN}{TN + FP}$"}, {"title": "1) Comparison with other works:", "content": "We will now compare our conclusions to a variety of other approaches that were suggested in the literature review. The comparative result is shown in Table III. It covers the findings of some of the newest methods suggested for locating brain tumors. The table demonstrates that WCNN was used to achieve the highest accuracy, which was 99.3. The other methods are less accurate than this. Even if the accuracy of our own CNN model is less accurate than that of the Sarhan et al. [23], it is still more accurate than alternative approaches. A number of pretrained models that we also trained showed impressive accuracy. Then, in order to increase the accuracy of our models, we mix these models with machine learning models. The highest accuracy we can achieve is 99.83%, which is higher than the paper by Sarhan et al. [23]."}, {"title": "IV. FUTURE WORKS AND CONCLUSION", "content": "In this paper, we explore different models to detect brain tumor more effectively and precisely. We have surpassed all previously investigated methods with an accuracy of 99.83%. Since brain tumor can lead to cancer, the impact of brain tumors are terrible for us and endanger our lives. We believe that our approach has the potential to reduce the risk of developing cancer and save many lives. In the future, we hope to develop a model that can accurately detect all types of tumors. Although our model solely analyzes MRI dataset, we also wish to take into account other medical imaging methods, such as CT (Computed Tomography) scan, PET (Positron-Emission Tomography) etc."}]}