{"title": "Symbolic Knowledge Extraction and Injection with Sub-symbolic Predictors: A Systematic Literature Review", "authors": ["Giovanni Ciatto", "Federico Sabbatini", "Andrea Agiollo", "Matteo Magnini", "Andrea Omicini"], "abstract": "In this paper we focus on the opacity issue of sub-symbolic machine learning predictors by promoting two complementary activities-namely, symbolic knowledge extraction (SKE) and injection (SKI) from and into sub-symbolic predictors. We consider as symbolic any language being intelligible and interpretable for both humans and computers. Accordingly, we propose general meta-models for both SKE and SKI, along with two taxonomies for the classification of SKE and SKI methods. By adopting an explainable artificial intelligence (XAI) perspective, we highlight how such methods can be exploited to mitigate the aforementioned opacity issue. Our taxonomies are attained by surveying and classifying existing methods from the literature, following a systematic approach, and by generalising the results of previous surveys targeting specific sub-topics of either SKE or SKI alone. More precisely, we analyse 132 methods for SKE and 117 methods for SKI, and we categorise them according to their purpose, operation, expected input/output data and predictor types. For each method, we also indicate the presence/lack of runnable software implementations. Our work may be of interest for data scientists aiming at selecting the most adequate SKE/SKI method for their needs, and also work as suggestions for researchers interested in filling the gaps of the current state of the art, as well as for developers willing to implement SKE/SKI-based technologies.", "sections": [{"title": "1 INTRODUCTION", "content": "In the context of artificial intelligence (AI), more and more critical applications that rely on machine learning (ML) are being developed. This promotes a data-driven approach to the engineering of intelligent computational systems where hard-to-code tasks are (semi-)automatically learned from data rather than manually programmed by human developers. Tasks that can be learned this way range from text [197] to speech [186] or image recognition [295], stepping through time series forecasting, clustering, and so on. Applications are manifold, and make our life easier in many ways-e.g., via speech-to-text applications, email spam and malware filtering, customer profiling, automatic translation, virtual personal assistants, and so forth.\nLearning, in particular, is automated via ML algorithms, often implying numeric processing of data-which in turn enables the detection of fuzzy patterns or statistically-relevant regularities in the data, that algorithms can learn to recognise. This is fundamental to support the automatic acquisition of otherwise hard-to-formalise behaviours for computational systems. However, flexibility comes at the cost of poorly-interpretable solutions, as state-of-the-art sub-symbolic predictors \u2013 such as neural networks are often exploited behind the scenes.\nThese predictors are commonly characterised by opacity [40, 154], as the interplay among the complexity of the data and the algorithms they are trained upon/with makes it hard for humans to understand their behaviour. Hence, by \u2018interpretable' we here mean that the expert human user may observe the computational system and understand its behaviour. Even though the property is not always required, there exist safety-, value-, or ethic-critical applications where humans must be in full control of the computational systems supporting their decisions or aiding their actions. In those cases, the lack of interpretability is a no-go.\nState-of-the-art ML systems rely on a collection of well-established data mining predictors, such as neural networks, support vector machines, decision trees, random forests, or linear models. Despite the latter sorts of predictors being often considered as interpretable in the general case, as the complexity of the problem at hand increases (e.g., dimensionality of the available data) trained predictors become more complex, hence harder to contemplate, and therefore less interpretable. Nevertheless, these mechanisms have penetrated the modern practices of data scientists because of their flexibility, and expected effectiveness-in terms of predictive performance. Unfortunately, a number of experts have empirically observed an inverse proportionality relation among interpretability and predictive performance [43, 213]. This is the reason why data-driven engineering efforts targeting critical application scenarios nowadays have to choose between predictive performance and interpretability as their priority: we call this the interpretability/performance trade-off.\nIn this paper we focus on the problem of working around the interpretability/performance trade-off. We do so by promoting two complementary activities, namely symbolic knowledge extraction (SKE) and injection (SKI) from and into sub-symbolic predictors. In both cases, \u2018symbolic' refers to the way knowledge is represented. In particular, we consider as symbolic any language that is intelligible and interpretable for both human beings and computers. This includes a number of logic formalisms, and excludes the fixed-sized tensors of numbers commonly exploited in sub-symbolic ML.\nIntuitively, SKE is the process of distilling the knowledge a sub-symbolic predictor has grasped from data into symbolic form. This can be exploited to provide explanations for otherwise poorly-interpretable sub-symbolic predictors. More generally, SKE enables the inspection of the sub-symbolic predictors it is applied to, making it possible for the human designer to figure out how they behave. Conversely, SKI is the inverse process of letting a sub-symbolic predictor follow the symbolic knowledge possibly encoded by its human designers. It enables a higher degree of control over a sub-symbolic predictor and its behaviour, by constraining it with human-like common-sense-suitably encoded into symbolic form.\nApart from insights, notions such as SKE and SKI have rarely been described in general terms into the scientific literature-despite the multitude of methods falling under their umbrellas. Hence, the aim of this paper is to provide general definitions and descriptions of these topics, other than providing durable taxonomies for categorising present and future SKE/SKI methods. Arguably, these contributions should take into account the widest possible portion of scientific literature, so as to avoid subjectivity. Accordingly, in this paper we propose a systematic literature review (SLR) following the three-folded purpose of (i) collecting and categorising existing methods for SKE and SKI into clear taxonomies, (ii) providing a wide overview of the state of the art and technology, and (iii) detecting open research challenges and opportunities. In particular, we analyse 132 methods for SKE and 117 methods for SKI, classifying them according to their purpose, operation, expected input/output data and predictor types. For each method, we also probe the existence/lack of software implementations.\nTo the best of our knowledge, our survey is the only systematic work focusing on both SKE and SKI algorithms. Furthermore, w.r.t. other surveys on these topics, our SLR collects the greatest number of methods. In doing so, we elicit a meta-model for SKE (resp. SKI) according to which existing and future extraction (resp. injection) methods can be categorised and described. Our taxonomies may be of interest for data scientists willing to select the most adequate SKE/SKI method for their needs, and also work as suggestions for researchers interested in filling the gaps of the current state of the art, or developers willing to implement SKE or SKI software technologies. Accordingly, the remainder of this paper is organised as follows. Section 2 recalls the state of the art for machine learning, symbolic AI, and explainable AI (XAI), aimed at providing readers with a fast-track access to most of the concepts and terms used in the paper. Section 3 delves into the details of what we mean by SKE and SKI, and explains how this SLR is conducted: there, we declare our research questions and describe our research methodology. Then, Section 4 answers our research questions, summarising the results of the analysis of the surveyed literature. The same results are then discussed in Section 5, where major challenges and opportunities are elicited. Finally, Section 6 concludes the paper."}, {"title": "2 BACKGROUND", "content": ""}, {"title": "2.1 Machine Learning", "content": "A widely adopted definition of machine learning by [182] states:\na computer program is said to learn from experience $E$ with respect to some class of tasks $T$ and performance measure $P$ if its performance at tasks in $T$, as measured by $P$, improves with experience $E$.\nThis definition is very loose, as it does not specify (i) what are the possible tasks, (ii) how performance is measured in practice, (iii) how/when experience should be provided to tasks, (iv) how exactly the program is supposed learn, and (v) under which form learnt information is represented. Accordingly, depending on the particular ways these aspects are tackled, a categorisation of the approaches and techniques enabling software agents to learn may be drawn.\nThree major approaches to ML exist: namely, supervised, unsupervised, and reinforcement learning. Each approach is tailored on a well-defined pool of tasks, which may, in turn, be applied in a wide range of use case scenarios. Accordingly, differences among three major approaches can be understood by looking at the sorts of tasks $T$ they support \u2013 commonly consisting of the estimation of some unknown relation \u2013, and how experience $E$ is provided to the learning algorithm.\nIn supervised learning, the learning task consists of finding a way to approximate an unknown relation given a sampling of its items\u2014which constitute the experience. In unsupervised learning, the learning task consists of finding the best relation for a sample of items \u2013 which constitute the experience -, following a given optimality criterion intensionally describing the target relation. In reinforcement learning, the learning task consists of letting an agent estimate optimal plans given the reward it receives whenever it reaches particular goals. There, the rewards constitutes the experience, while plans can be described as relations among the possible states of the world, the actions to be performed in those states, and the rewards the agents expects to receive from those actions.\nSeveral practical AI problems \u2013 such as image recognition, financial and medical decision support systems can be reduced to supervised ML-which can be further grouped in terms of either classification or regression problems [141, 260]. Within the scope of sub-symbolic supervised ML, a learning algorithm is commonly exploited to approximate the specific nature and shape of an unknown prediction function (or predictor) $\\pi^* : X \\rightarrow Y$, mapping data from an input space $X$ into an output space $Y$. There, common choices for both $X$ and $Y$ are, for instance, the set of vectors, matrices, or tensors of numbers of a given size\u2014hence the sub-symbolic nature of the approach.\nWithout loss of generality, in the following we refer to items in $X$ as n-dimensional vectors denoted as $x$, whereas items in $Y$ are m-dimensional vectors denoted as $y$-despite matrices or tensors may be suitable choices as well.\nTo approximate function $\\pi^*$, supervised learning assumes that a learning algorithm is in place. This algorithm computes the approximation by taking into account a number $N$ of examples of the form $(x_i, y_i)$ such that $x_i \\in \\mathcal{X} \\subseteq X$, $y_i \\in \\mathcal{Y} \\subseteq Y$, and $|\\mathcal{X}| = |\\mathcal{Y}| = N$. There, the set $D = \\{(x_i, y_i) \\mid x_i \\in \\mathcal{X}, y_i \\in \\mathcal{Y}\\}$ is called training set, and it consists of $(n + m)$-dimensional vectors. The dataset can be considered as the concatenation of two matrices, namely the $N \\times n$ matrix of input data $(\\mathbf{X})$ and the $N \\times m$ matrix of expected output data $(\\mathbf{Y})$. There, each $x_i$ represents an instance of the input data for which the expected output value $y_i = \\pi^*(x_i)$ is known or has already been estimated. Notably, such sorts of ML problems are said to be \u2018supervised' because the expected outputs $Y$ are available. Furthermore, the function approximation task is called regression if the components of $Y$ consist of continuous or numerable \u2013 i.e., infinite \u2013 values, classification if they consist of categorical \u2013 i.e., finite \u2013 values."}, {"title": "2.1.1 On the Nature of Sub-Symbolic Data", "content": "ML methods, and sub-symbolic approaches in general, represent data as (possibly multi-dimensional) arrays (e.g., vectors, matrices, or tensors) of real numbers, and knowledge as functions over data. This is particularly relevant as opposed to symbolic knowledge representation approaches, which represent data via logic formul\u00e6 (cf. Section 2.2).\nIn spite of the fact that numbers are technically symbols as well, we cannot consider arrays and their functions as means for symbolic knowledge representation (KR). Indeed, according to [262], to be considered as symbolic, KR approaches should (a) involve a set of symbols, (b) which can be combined (e.g., concatenated) in possibly infinite ways, following precise grammatical rules, and (c) where both elementary symbols and any admissible combination of them can be assigned with meaning-i.e., each symbol can be mapped into some entity from the domain at hand. Below, we discuss how sub-symbolic approaches most typically do not satisfy requirements (b) and (c).\nVectors, matrices, tensors. Multi-dimensional arrays are the basic brick of sub-symbolic data representation. More formally, a $D$-order array consists of an ordered container of real numbers, where $D$ denotes the amount of indices required to locate each single item into the array. We may refer to 1-order arrays as vectors, 2-order arrays as matrices, and higher-order arrays as tensors.\nIn any given sub-symbolic data-representation task leveraging upon arrays, information may be carried by both (i) the actual numbers contained into the array, and (ii) their location into the array itself. In practice, the actual dimensions $(d_1 \\times ... \\times d_D)$ of the array play a central role as well. Indeed, sub-symbolic data processing is commonly tailored on arrays of fixed sizes-meaning that the actual values of $d_1, ..., d_D$ are chosen at design time and never changed after that. This violates requirement (b) above, hence we define sub-symbolic KR as the task of expressing data in the form of rigid arrays of numbers.\nLocal vs. distributed. When data is represented in the form of numeric arrays, the whole representation may be local or distributed [262]. In local representations, each single number into the array is characterised by a well-delimited meaning-i.e., it is measuring or describing a clearly-identifiable concept from a given domain. Conversely, in distributed representations, each single item of the array is nearly meaningless, unless it is considered along with its neighbourhood-i.e., any other item which is \u2018close' in the indexing space of the array, according to some given notion of closeness. So, while in local representations the location of each number in the array is mostly negligible, in distributed representations it is of paramount importance. Notably, distributed representations violate the aforementioned requirement (c). In recent literature, authors call \u2018sub-symbolic' those predictors who rely on distributed representations of data."}, {"title": "2.1.2 Overview on ML Predictors", "content": "Depending on the predictor family of choice, the nature of the admissible hypothesis spaces and learning algorithms may vary dramatically, as well as the predictive performance of the target predictor, and the whole efficiency of learning.\nIn the literature of machine learning, statistical learning, and data mining, a plethora of learning algorithms have been proposed along the years. Because of the 'no free lunch' (NFL) theorem [276], however, no algorithm is guaranteed to outperform the others in all possible scenarios. For this reason, the literature and the practice of data science keeps leveraging on algorithms and methods whose first proposal was published decades ago. Most notable algorithms include, among the many others, (deep) neural networks (NN), decision trees (DT), (generalised) linear models, nearest neighbours, support vector machines (SVM), and random forests.\nThese algorithms can be categorised in several ways, for instance depending (i) on the supervised learning task they support (classification vs. regression), or (ii) on the underlying strategy adopted for learning (e.g., gradient descent, least square optimisation).\nSome learning algorithms (e.g., NN) naturally target regression problems \u2013 despite being adaptable to classification, too \u2013, whereas others (e.g., SVM) target classification problems\u2014while being adaptable to regression as well. Similarly, some target multi-dimensional outputs ($y \\in \\mathbb{R}^m$, and $m > 1$), whereas others target mono-dimensional outputs ($m = 1$). Regressors are considered as the most general case, as other learning tasks can usually be defined in terms of mono-dimensional regression.\nThe learning strategy is inherently bound to the predictor family of choice. NN, for instance, are trained via back-propagation [215] and stochastic gradient descent (SGD), generalised linear models via Gauss' least squares method, decision trees via methods described in [37], etc. Even though all the aforementioned algorithms may appear interchangeable in principle \u2013 because of the NFL theorem \u2013, their malleability is very different in practice. For instance, the least square method involves inverting matrices of order $N$ \u2013 where $N$ is the amount of available examples in the training set \u2013, making the computational complexity of learning more than quadratic in time. Furthermore, in practice, convergence of the method is not guaranteed in the general case; instead, it is guaranteed for generalised linear models\u2014hence it is not adopted elsewhere. Thus, learning by least square optimisation may become impractical for big datasets or for predictor families outside the scope of generalised linear models. Conversely, the SGD method involves arbitrarily-sized subsets of the dataset (a.k.a. batches) to be processed a finite (i.e., controllable) amount of times. Hence, the complexity of SGD can be finely controlled and adapted to the computational resources at hand-e.g., by making the learning process incremental, and by avoiding all data to be loaded in memory. Moreover, SGD can be applied to several sorts of predictor families (there including NN and generalised linear models), as it only requires the target function to be differentiable w.r.t. its parameters. For all these reasons, despite the lack of optimality guarantees, SGD is considered as very effective, scalable, and malleable in practice, hence it is extensively exploited in the modern data science applications.\nIn the remainder of this subsection we focus on two families of predictors \u2013 namely, DT and NN -, and their respective learning methods. We focus precisely on them because they are related to many surveyed SKE/SKI methods. DT are noteworthy because of their user friendliness, whereas NN are mostly popular because of their predictive performance and flexibility.\nDecision trees. Decision trees are particular sorts of predictors supporting both classification and regression tasks. In their learning phase, the input space is recursively partitioned through a number of splits (a.k.a. decisions) based on the input data $X$, in such a way that the prediction in each partition is constant, and the error w.r.t. the expected outputs $Y$ is minimal, while keeping the total amount of partitions low as well. The whole procedure then synthesises a number of hierarchical decision rules to be followed whenever the prediction corresponding to any $x \\in X$ must be computed. In the inference phase, decision rules are orderly evaluated from the root to a leaf, to select the portion of the input space $X$ containing $x$. As each leaf corresponds to a single portion of the input space, the whole procedure results in a single prediction for each $x$.\nUnlike other families of predictors, the peculiarity of DT lies in the particular outcome of the learning process \u2013 namely, the tree of decision rules \u2013 which is straightforwardly intelligible for humans and graphically representable in 2D charts. As further discussed in the remainder of the paper, this property is of paramount importance whenever the inner operation of an automatic predictor must be interpreted and understood by a human agent.\nNeural networks. Neural networks are biologically-inspired computational models, made of several elementary units (neurons) interconnected into a graph (commonly, directed and acyclic, a.k.a. DAG) via weighted synapses. Accordingly, the most relevant aspects of NN concern the inner operation of neurons and the particular architecture of their interconnection.\nNeurons are very simple numeric computational units. They accept $n$ scalar inputs $(x_1, ..., x_n) = x \\in \\mathbb{R}^n$ weighted by as many scalar weights $(w_1, ..., w_n) = w \\in \\mathbb{R}^n$, and they process the linear combination $x \\cdot w$ via an activation function $\\sigma : \\mathbb{R} \\mapsto \\mathbb{R}$, producing a scalar output $y = \\sigma(x. w)$. The output of a neuron may become the input of many others, possibly forming networks of neurons having arbitrary topologies. These networks may be fed with any numeric information encoded as vectors of real numbers by simply letting a number of neurons produce constant outputs.\nWhile virtually all topologies are admissible for NN, not all are convenient. Many convenient architectures \u2013 roughly, patterns of well-studied topologies \u2013 have been proposed in the literature [263] to serve disparate purposes-far beyond the scope of supervised machine learning. However, identification of the most appropriate architecture for any given task is non-trivial: recent efforts propose to learn their construction automatically [2, 157].\nMost common NN architectures are feed-forward, meaning that neurons are organised in layers, where neurons from layer $i$ can only accept ingoing synapses from neurons of layers $j < i$. The first layer is considered the input layer, which is used to feed the whole network, while the last one is the output layer, where predictions are drawn. In NN architectures inference lets information flow from the input to the output layer \u2013 assuming the weights of synapses are fixed \u2013, while training lets information flow from the output to the input layer-causing the variation of weights to minimise the prediction error of the overall network.\nThe recent success of deep learning [105] has proved the flexibility and the predictive performance of deep neural networks (DNN). \u2018Deep' here refers to the large amount of (possibly convolutional) layers. In other words, DNN can learn how to apply cascades of convolutional operations to the input data. Convolutions let the network spot relevant features into the input data, at possibly different scales. This is why DNN are good at solving complex pattern-recognition tasks\u2014e.g., computer vision or speech recognition. Unfortunately, however, unprecedented predictive performances of DNN come at the cost of their increased internal complexity, non-inspectability, and greater data greediness."}, {"title": "2.1.3 General Supervised Learning Workflow", "content": "Briefly speaking, an ML workflow is the process of producing a suitable predictor for the available data and the learning task at hand, with the purpose of exploiting the predictor later so as to draw analyses or to drive decisions. Hence, any ML workflow is commonly described as composed of two major phases, namely training \u2013 where predictors are fitted on data \u2013 and inference\u2014where predictors are exploited. However, in practice, further phases are included, such as data provisioning and pre-processing, as well as model selection and assessment.\nIn other words, before using a sub-symbolic predictor in a real-world scenario, data scientists must ensure it has been sufficiently trained and its predictive performance is sufficiently high. In turn, training requires (i) an adequate amount of data to be available, (ii) a family of predictors to be chosen (e.g., NN, K-nearest neighbours, linear models, etc.), (iii) any structural hyper-parameter to be defined (e.g., amount, type, size of layers, K, maximum order of the polynomials, etc.), (iv) any other learning-parameter to be fixed (e.g., learning rate, momentum, batch size, epoch limit, etc.). Data must therefore be provisioned before training, and, possibly, pre-processed to ease training itself-e.g., by normalising data or by encoding non-numeric features into numeric form. The structure of the network must be defined in terms of (roughly) input, hidden, and output layers, as well as their activation functions. Finally, hyper-parameters must be carefully tuned according to the data scientist's experience, and the time constraints and computational resources at hand. Thus, from a coarse-grained perspective, an ML workflow can be conceived as composed of six major phases, enumerated below:\n(1) sub-symbolic data gathering: the first actual step of any ML workflow, where data is loaded in memory for later processing;\n(2) pre-processing: the application of several bulk operations to the training data, following several purposes, such as: (i) homogenise the variation ranges of the many features sampled by the dataset, (ii) detect irrelevant features and remove them, (iii) construct relevant features by combining the existing ones, or (iv) encoding non-numeric features into numeric form;\n(3) predictor selection: a principled search for the most adequate sort of predictor to tackle the data and the learning task at hand. This is where hyper-parameters are commonly fixed;\n(4) training: the actual tuning of the selected predictor(s) on the available data. This is where parameters are commonly fixed;\n(5) validation: measuring the predictive performance of trained predictors, with the purpose of assessing if and to what extent it will generalise to new, unseen data;\n(6) inference: the final phase, where trained predictors are used to draw predictions on unknown data-i.e., different data w.r.t. the one used for training."}, {"title": "2.2 Computational Logic", "content": "Symbolic KR has always been regarded as a key issue since the early days of AI, as no intelligence can exist without knowledge, and no computation can occur in lack of representation. When compared to arrays of numbers, symbolic KR is far more flexible and expressive, and, in particular, more intelligible-both machine- and human-interpretable. Historically, most KR formalisms and technologies have been designed on top of computational logic [160], that is, the exploitation of formal logic in computer science. Consider, for instance, deductive databases [109], description logics [9], ontologies [62], Horn logic [179], higher-order logic [261], just to name a few."}, {"title": "2.2.1 Formal Logics", "content": "Many kinds of logic-based KR systems have been proposed over the years, mostly relying on first-order logic (FOL) \u2013 either by restricting or extending it \u2013, e.g., on description logics and modal logics, which have been used to represent, for instance, terminological knowledge and time-dependent or subjective knowledge. Here, we briefly recall the state of the art of FOL and its most relevant subsets.\nFirst-order logic. FOL is a general-purpose logic which can be used to represent knowledge symbolically, in a very flexible way. More precisely, it allows both human and computational agents to express (i.e., write) the properties of \u2013 and the relations among \u2013 a set of entities constituting the domain of the discourse, via one or more formul\u00e6\u2014and, possibly, to reason over such formul\u00e6 by drawing inferences. There, the domain of the discourse $D$ is the set of all relevant entities which should be represented in FOL to be amenable of formal treatment, in a particular scenario.\nInformally, the syntax for the general FOL formula is defined over the assumption that there exist: (i) a set of constant or function symbols, (ii) a set of predicate symbols, and (iii) a set of variables. Under such assumption, a FOL formula is any expression composed of a list of quantified variables, followed by a number of literals, i.e., predicates that may or may not be prefixed by the negation operator ($\\neg$). Literals are commonly combined into expressions via logic connectives, such as conjunction ($\\land$), disjunction ($\\lor$), implication ($\\rightarrow$), or equivalence ($\\leftrightarrow$).\nEach predicate consists of a predicate symbol, possibly applied to one or more terms. Terms may be of three sorts, namely constants, functions, or variables. Constants represent entities from the domain of the discourse. In particular, each constant references a different entity. Functions are combinations of one or more entities via a function symbol. Similarly to predicates, functions may carry one or more terms. Being containers of terms, functions enable the creation of arbitrarily complex data structures combining several elementary terms into composite ones. Such kind of composability by recursion is what makes the aforementioned definition of \u2018symbolic' valid for FOL. Finally, variables are placeholders for unknown terms-i.e., for either individual or groups of entities.\nPredicates and terms are very flexible tools to represent knowledge. While terms can be used to represent or reference either entities or groups of entities from the domain of the discourse, predicates can be used to represent relations among entities, or the properties of each single entity.\nIntensional vs. extensional. In logic, one may define concepts \u2013 i.e., describe data \u2013 either extensionally or intensionally. Extensional definitions are direct representations of data. In the particular case of FOL, this implies defining a relation or set by explicitly mentioning the entities it involves. Conversely, intensional definitions are indirect representations of data. In the particular case of FOL, this implies defining a relation or set by describing its elements via other relations or sets. Recursive intensional predicates are very expressive and powerful, as they enable the description of infinite sets via a finite (and commonly small) amount of formul\u00e6\u2014and this is one of the key benefits of FOL as a means for KR."}, {"title": "2.2.2 Expressiveness vs. Tractability: Notable Subsets of FOL", "content": "Tractability deals with the theoretical questions: 'can a logic reasoner compute whether a logic formula is true (or not) in reasonable time?'. Such aspects are deeply entangled with the particular reasoner of choice. Depending on which and how many features a logic includes, it may be more or less expressive. The higher the expressiveness, the more the complexity of the problems which may be represented via logic and processed via inference increases. This opens to the possibility, for the solver, to meet queries which cannot be answered in practical time, or by relying upon a limited amount of memory\u2014or just cannot get an answer at all. Roughly speaking, more expressive logic languages make it easier for human beings to describe a particular domain \u2013 usually, requiring them to write less and more concise clauses \u2013, at the expense of a higher difficulty for software agents to draw inferences autonomously-because of computational tractability. This is a well-understood phenomenon in both computer science and computational logic [36, 146], often referred to as the expressiveness/tractability trade-off.\nFOL, in particular, is considered very expressive. Indeed, it comes with many undecidable, semi-decidable, or simply intractable properties. Hence, several relevant subsets of FOL have been identified into the literature, often sacrificing expressiveness for tractability. Major notions concerning these logics are recalled below.\nHorn logic. Horn logic is a notable subset of FOL, characterised by a good trade-off among theoretical expressiveness and practical tractability [166].\nHorn logic is designed around the notion of Horn clause [123]. Horn clauses are FOL formul\u00e6 having no quantifiers, and consisting of a disjunction of predicates, where only at most one literal is non-negated-or, equivalently, an implication having a single predicate as post-condition and a conjunction of predicates as pre-condition: $h \\leftarrow b_1, ..., b_n$. There, $\\leftarrow$ denotes logic implication from right to left, commas denote logic conjunction, and all $b_i$, as well as $h$, are predicates of arbitrary arity, possibly carrying FOL terms of any sort\u2014i.e., variables, constants, or functions. Horn clauses are thus if-then rules written in reverse order, and only supporting conjunctions of predicates as pre-conditions.\nEssentially, Horn logic is a very restricted subset of FOL where: (i) formul\u00e6 are reduced to clauses, as they can only contain predicates, conjunctions, and a single implication operator, therefore (ii) operators such as $\\lor$, $\\leftrightarrow$, or $\\neg$ cannot be used, (iii) variables are implicitly quantified, and (iv) terms work as in FOL.\nDatalog. Datalog is a restricted subset of FOL [4], representing knowledge via function-free Horn clauses-defined in the previous paragraph. So, essentially, Datalog is a subset of Horn logic where structured terms (i.e., recursive data structures) are forbidden. This is a direct consequence of the lack of function symbols.\nSimilarly to Horn logic, Datalog\u2019s knowledge bases consist of sets of function-free Horn clauses.\nDescription logics (DL). Description logics are a family of subsets of FOL, generally involving some or no quantifiers, no structured terms, and no n-ary predicates such that $n \\ge 3$. In other words, description logics represent knowledge by only leveraging on constants and variables, other than atomic, unary, and binary predicates.\nDifferences among specific variants of DL lay in which and how many logic connectives are supported, other than, of course, whether negation is supported or not. The wide variety of DL is due to the well known expressiveness/tractability trade-off. However, depending on the particular situation at hand, one may either prefer a more expressive ($\\approx$ feature rich) DL variant at the price of a reduced tractability (or even decidability) of the algorithms aimed at manipulating knowledge represented through that DL, or vice versa.\nRegardless of the particular DL variant of choice, it is common practice in the scope of DL to call (i) constant terms, as \u2018individuals' \u2013 as each constant references a single entity from a given domain \u2013, (ii) unary predicates, e.g., as either \u2018classes' or \u2018concepts' \u2013 as each predicate groups a set of individuals, i.e., all those individuals for which the predicate is true \u2013, (iii) binary predicates, e.g., as either \u2018properties' or \u2018roles'\u2014as each predicate relates two sets of individuals. Following such a nomenclature, any piece of knowledge can be represented in DL by tagging each relevant entity with some constant (e.g., an URL), and by defining concepts and properties accordingly.\nNotably, binary predicates are of particular interest as they support connecting couples of entities altogether. This is commonly achieved via subject-predicate-object triplets, i.e., ground binary predicates of the form $\\langle a f b \\rangle$ or, alternatively, $f(a, b)$ \u2013, where $a$ is the subject, $f$ is the predicate, and $b$ is the object. Such triplets allow users to extensionally describe knowledge in a readable, machine-interpretable, and tractable way.\nCollections of triplets constitute the so-called knowledge graphs (KG), i.e., directed graphs where vertices represent individuals, while arcs represent the binary properties connecting these individuals. These may explicitly or implicitly instantiate a particular ontology, i.e., a formal description of classes characterising a given domain, and of their relations (inclusion, exclusion, intersection, equivalence, etc.), as well as the properties they must (or must not) include.\nPropositional logic. Propositional logic is a very restricted subset of FOL, where quantifiers, terms, and non-atomic predicates are missing. Hence, propositional formul\u00e6 simply consist of expressions involving one or many 0-ary predicates \u2013 i.e., propositions \u2013, possibly interconnected by ordinary logic connectives. There, each proposition may be interpreted as a Boolean variable \u2013 which can either be true or false \u2013, and the truth of formul\u00e6 can be computed as in the Boolean algebra. So, for instance, a notable example of propositional formula could be as follows: $p \\land \\neg q \\rightarrow r$ where $p$ may be the proposition \u2018it is raining', $q$ may be the proposition \u2018there is a roof', whereas $r$ may be the proposition 'the floor is wet'.\nThe expressiveness of propositional logic is far lower than the one of FOL. For instance, because of the lack of quantifiers, each relevant aspect/event should be explicitly modelled as a proposition. Furthermore, because of the lack of terms, entities from a given domain cannot be explicitly referenced. Such lack of expressiveness, however, implies computing the satisfiability of a propositional formula is a decidable problem-which may be a desirable property in some application scenarios. Despite propositional logic may appear too trivial to handle common decision tasks where non-binary data is involved, it turns out a number of apparently complex situations can indeed be reduced to a propositional setting. This is the case for instance of any expression involving numeric variables or constants, arithmetical comparison operators, logic connectives, and nothing more than that. In fact, formul\u00e6 containing comparisons among variables or constants (or among each others) can be reduced to propositional logic by mapping each comparison into a proposition."}, {"title": "2.3 eXplainable Artificial Intelligence", "content": "Modern intelligent systems are increasingly adopting sub-symbolic predictive models to support their intelligent behaviour. These are commonly trained following a data-driven approach. Such wide adoption is unsurprising, given the unprecedented availability of data characterising the last decade. ML algorithms enable the detection of useful statistical information buried in data, semi-automatically. Information, in turn, supports decision-making, monitoring, planning, and forecasting virtually in any human activity where data is available.\nHowever, despite its predictive capabilities, ML comes with some drawbacks making it perform poorly"}]}