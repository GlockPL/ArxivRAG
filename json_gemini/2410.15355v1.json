{"title": "LAC: GRAPH CONTRASTIVE LEARNING WITH LEARNABLE\nAUGMENTATION IN CONTINUOUS SPACE", "authors": ["Zhenyu Lin", "Hongzheng Li", "Yingxia Shao", "Guanhua Ye", "Yawen Li", "Quanqing Xu"], "abstract": "Graph Contrastive Learning frameworks have demonstrated success in generating high-quality node representa-\ntions. The existing research on efficient data augmentation methods and ideal pretext tasks for graph contrastive\nlearning remains limited, resulting in suboptimal node representation in the unsupervised setting. In this paper,\nwe introduce LAC, a graph contrastive learning framework with learnable data augmentation in an orthogonal\ncontinuous space. To capture the representative information in the graph data during augmentation, we introduce\na continuous view augmenter, that applies both a masked topology augmentation module and a cross-channel\nfeature augmentation module to adaptively augment the topological information and the feature information\nwithin an orthogonal continuous space, respectively. The orthogonal nature of continuous space ensures that the\naugmentation process avoids dimension collapse. To enhance the effectiveness of pretext tasks, we propose an\ninformation-theoretic principle named InfoBal and introduce corresponding pretext tasks. These tasks enable\nthe continuous view augmenter to maintain consistency in the representative information across views while\nmaximizing diversity between views, and allow the encoder to fully utilize the representative information in\nthe unsupervised setting. Our experimental results show that LAC significantly outperforms the state-of-the-art\nframeworks.", "sections": [{"title": "1 Introduction", "content": "Graph Contrastive Learning (GCL) [1, 2] enhances gener-\nalization performance by leveraging multiple augmented\nviews to learn latent information in graph data. GCL serves\nas a powerful tool to address challenges associated with\nlabel sparsity and unlabeled data. It alleviates the expen-\nsive data labeling cost while significantly enhancing the\ngeneralization capabilities of graph neural network models\nacross diverse downstream tasks.\nTypically, GCL frameworks typically consist of pretext\ntasks, view augmenters, and encoders. The pretext tasks\nguide the view augmenter and encoder to utilize represen-\ntative information related to downstream tasks. The view\naugmenters transform input graphs into multiple correlated\naugmented views [3]. The encoders get representations\nfrom different augmented views. The augmenters and\nencoders mutually influence each other [4]. Specifically,\nhigh-quality augmented views contribute to the training of\nmore powerful and generalized encoders [5, 6, 7], and the\nquality of encoders assists in learning effective augmenters\nas well.\nGCL plays a pivotal role in various domains, including\nemotion recognition [8, 9], multi-modal recommendation\nsystems [10, 11, 12], and anomaly detection [13, 14, 15].\nDespite these capabilities, existing GCL frameworks still\nencounter two significant challenges in the unsupervised\nsetting:\nExisting augmentation methods are not sufficient. View\naugmenters in GCL frameworks fall into two categories:\nmanual augmentation and learnable augmentation. The\nmanual augmentation [5, 7, 16, 17, 18, 19, 20, 21] in-\nvolves selecting augmenters and their hyperparameters\nempirically from predefined options through numerous\ntrial-and-error experiments per dataset [6]. The learnable\naugmentation [4, 22, 3, 23, 24, 25, 26, 27, 28] automat-\nically learns from data and generates augmented views.\nAlthough this approach avoids the laborious [23] and time-\nconsuming [25] process of numerous trial-and-error ex-\nperiments, it augments the original graph data discretely,\nyielding non-ideal augmented views. This non-ideal situ-\nation lies in both topology augmentation and feature aug-\nmentation. Firstly, the discrete perturbation of topological\ninformation leads to non-ideal views. Even the slightest\nperturbation to the topology such as removing an edge or\ndropping a node can destroy the representative information"}, {"title": "2 Preliminaries", "content": ""}, {"title": "2.1 Notions", "content": "An undirected and connected graph is denoted as G =\n(V,E), where V represents the node set and E CV \u00d7\nrepresents the edge set. The topological adjacency matrix\nis $A\\in R^{N\\times N}$, the node feature matrix is $X \\in R^{\u00d1\\times d}$, and\n$x_i$ denotes the feature of node i, Vi \u2208 V. The normalized\nLaplacian matrix of the graph G is given as $L = I-\nD^{-1/2} AD^{-1/2}$, where \u010e denotes the degree matrix of the\nnormalized adjacency matrix \u00c3. In contrastive learning,\neach graph can also be denoted as view V."}, {"title": "2.2 Graph Contrastive Learning", "content": "The objective of graph contrastive learning is to distinguish\nbetween latent representative information in the data [33]\nand to learn embeddings for downstream tasks. View aug-\nmenters can either be manually selected from predefined\npools [5, 7, 18, 17, 19, 20, 21] or designed as learnable and\ngenerative [4, 6, 22, 3, 23, 24, 25, 26]. The augmenters\ngenerate one or multiple augmented views. For example,\ngiven original data, data augmenters $g_1, g_2$, original data\nview V, the augmented view V' can be denoted as:\n$V' = (A', X') = g(V) = g((A, X))$.\n(1)\nSubsequently, based on the positive and negative sample\npairs defined across multiple views, GCL frameworks train\nthe encoders to obtain embeddings for downstream tasks."}, {"title": "2.3 Theorems", "content": "In linear algebra, the spectral theorem [32] establishes a\nstandard framework for decomposition vector space and\ngives the condition that a matrix can be diagonalized.\nTheorem 1. (Spectral Theorem). Let P be a symmetric\nmatrix on Rn\u00d7n, then P can be decomposed into:\n$P = UAUT$,\n(3)\nwhere U \u2208 Rnxn is a set of orthogonal eigenvectors\nof P, A \u2208 Rn\u00d7n is the corresponding diagonal matrix\nof eigenvalues, and UT is the transposed matrix of U,\nsatisfying:\n$UUT = In$,\n(4)\nwhere $I_n \\in R^{n\\times n}$ is an identity matrix.\nIn approximation theory [32], an arbitrary complicated\nmultivariate function can be approximated by a series of\nsimple univariate functions.\nTheorem 2. (Kolmogorov-Arnold Theorem) [37]. An\narbitrary multivariate function $f : [0, 1]^N \\rightarrow R(N > 0)$\ncan be modeled using the following expression :\n$f(x_1, ..., X_N) = \\rho(\\sum_{p=1}^{N}a_{i,p}\\varphi(x_p))$,\n(5)\nwhere $p : R^d \\rightarrow R$, $\u00a2 : R \\rightarrow R^d$, d > 0 and dip is the\nweight.\nTheorem 3. (Information Inequality). The upper bound\nof mutual information between the representations of the\naugmented view V' and original view V is given by:\n$I(f(V); f(V')) \\le min{I(V; V'), I(V'; f(V')), I(V; f(V))}$,\n(6)\nwhere f is an information encoder.\nProof. We have a Markov chain: V \u2192 V' = g(V) \u2192\nf(g(V)), the first arrow means augmentation, and the sec-\nond arrow denotes information encoding. According to the\ndata process inequality [38], we infer that:\n$I(V; f(V')) \\le min{I(V; V'), I(V'; f(V')}$.\n(7)\nMeanwhile, there is another Markov chain: f(V) \u2190 V \u2192\nf(V'), which is Markov equivalent to f(V) \u2192 V \u2192\nf(V') since f(V) and f(V') are conditionally indepen-\ndent after observing V. Thus, the following equation\nholds:\n$I(f(V); f(V')) \\le min{I(V; f(V')), I(V; f(V))}$\n$\\le min{I(V; V'), I(V'; f(V')), I(V; f(V))}$.\n(8)\nAbove all, Theorem 3 is proven."}, {"title": "3 LAC Framework Overview", "content": "Figure 1 provides an overview of LAC, which includes\nthe Continuous View Augmenter, the Shared Information\nEncoder, and the pretext tasks built on the InfoBal.\nContinuous View Augmenter (CVA). The CVA augments\nboth topological and feature information in an orthog-\nonal continuous space, generating augmented views ac-\ncordingly. In CVA, we propose the Masked Topology\nAugmentation module for topology augmentation and the\nCross-channel Feature Augmentation module for feature\naugmentation, respectively. The continuous augmentation\nmethod employed by the CVA minimizes information loss\ntypically associated with discrete augmentation methods,\nthereby enhancing suitability for graph data. The detailed\ndesign of CVA is presented in Section 4.\nShared Information Encoder. The shared information\nencoder extracts information from the original view and\nthe augmented view to learn the node embeddings. The\nencoder f comprises a K-layer Graph Neural Network\n(GNN). The shared information encoder is a common and\nwidely adopted technique in existing works [19, 18]. The\nembeddings Z for nodes in view V and the embeddings\nof nodes in augmented views Z' are yielded by shared\ninformation encoder f:\n$Z = f(V) = f(A, X), Z' = f(V') = f(A\u0384, X').$\n(9)\nInfoBal Pretext Task. To achieve high-quality node repre-\nsentations in unsupervised scenarios, the InfoBal pretext\ntask is proposed. The InfoBal framework comprises two\ncomponents. Firstly, it introduces diversity, and consis-\ntency constraints for the CVA, and guides the CVA to\ngenerate appropriate augmented views with adequate aug-\nmentation variances while preserving representative infor-\nmation. Secondly, InfoBal imposes a sufficiency constraint\non the training of the shared encoder. This helps the shared\nencoder to extract more representative information from\nviews. In contrast to InfoMin [36], which is typically em-\nployed for training augmenters, InfoBal emphasizes the\nbalance of consistency and diversity among augmented\nviews. As opposed to InfoMax [35], traditionally used for\nencoder training, InfoBal boosts the sufficiency of utiliz-\ning representative information in augmented views. Thus,\nInfoBal allows the model to generate high-quality node\nrepresentations in the unsupervised scenario. The detailed\ndesign of InfoBal is presented in Section 4.\nIn the InfoBal pretext tasks, we use InfoNCE [34] to mea-\nsure the mutual information between two views. We regard\nthe embeddings of same node in the original view V and\naugmented view V' as positive pairs (e.g., (zi, z\u00bf | i \u2208 V)).\nOn the other hand, we consider the embeddings of differ-\nent nodes in the two views as negative pairs (e.g., (zi, Zk\n| i, k \u2208 V,i \u2260 k)). We define the mutual information\nextracted from two views by encoder as follows:\n$I(f(V); f(V')) = \\frac{1}{2N} \\sum_{i=1}^{N}log\\frac{e^{s(z_i,z_i')/\\tau}}{\\sum_{k \\in V}e^{s(z_i,z_k')/\\tau}}$.\n(10)"}, {"title": "4 Continuous View Augmenter", "content": "In this section, we introduce the Continous View Aug-\nmenter (CVA). It first transforms the original graph data\ninto the representations in an orthogonal continuous space\nrepresented by the bases U. On basis of the continous rep-\nresentation, CVA applies Masked Topology Augmentation\n(MTA) and Cross-channel Feature Augmentation (CFA)\nto generate augmented topology and feature of the graph\ndata, respectively. Finally, CVA transforms the augmented\nresults back to the original discrete space to get the final\naugmented views."}, {"title": "4.1 Representation in Orthogonal Continuous Space", "content": "To represent information in a continuous space, establish-\ning a coordinate system with orthogonal vector bases is\ncritical. This approach allows topological data A and fea-\nture data X to be expressed as linear combinations of these\nbases, preserving data integrity and preventing dimensional\ncollapse during perturbations.\nTopology representation. The undirected graph topologi-\ncal information is denoted as a symmetric and real matrix"}, {"title": "4.2 Masked Topology Augmentation", "content": "MTA augments the topological information represented\nby the A matrix in continuous space. It's worth noting"}, {"title": "4.3 Cross Channel Feature Augmentation", "content": "The continuous representation of feature information C =\nUTX is modeled as the coordinate coefficient of X in the\northogonal continuous space represented by U, as depicted\nin Figure 3. Specifically, ci,j represents the projected value\nof the j-th channel graph signal x:,j onto basis u. Each\ncolumn of C delineates the distribution of projected values\nfor a channel of the graph signal across various bases.\nRandomly masking specific node features or feature di-\nmensions can result in dimensional collapse [41, 29]. To\nanalyze this phenomenon, we provide empirical results on\nthe Cora. As shown in Figure 5, the blue line represents the\ncoefficients C, which exhibits a long-tail distribution. The\nimbalance of the distribution of projected values causes a\nfew channels to dominate the feature information in the\ncontinuous space [29]. For example, the projected val-\nues across certain channels in C are very small, while\nthe projected values across other channels are very large.\nConsequently, these former channels become negligible\nin their capacity to describe information compared to the\nlatter channels, leading to their invalidation. This causes\na phenomenon that the high-dimensional representations\nof node features in continuous space collapse [41] into\nlow-dimensional representations, which makes it difficult\nto distinguish between different nodes [29].\nTo avoid the dimensional collapse problem, cross channel\nfeature augmentation (CFA) is introduced. This method"}, {"title": "4.4 Discussion of CVA", "content": "The A\u0384 and C' generated by the MTA and CFA cannot be\ndirectly applied in the GNN-based information encoder.\nWe convert A' and C' from the continuous space back to\nthe original space to obtain the final augmented view V'\nas follows:\n$V' = (A\u0384, \u03a7\u0384) = (UA'UT, UC').$\n(26)\nSuch augmented view can be utilized across various types\nof encoders."}, {"title": "4.4.1 Relationship with the Augmentation in the Original Space", "content": "We next analyze the connection between CVA and view\naugmentation in the original space. In the original space,\ntopological perturbations generate edges in A with integer\nweights of 0 or 1, while discrete feature perturbations\nmask random dimensions in X to zeros. Every discrete\naugmentation in the original space has a corresponding\naugmentation in our proposed continuous space, as proven\nby Theorem 4.\nTheorem 4. Any topological augmentation in discrete\nspace and augmentation of discretized features has a cor-\nresponding augmentation on the topological and feature\ninformation in continuous space of LAC."}, {"title": "5 The Pretext Tasks Based on InfoBal", "content": "In this section, we introduce a universal principle known\nas InfoBal. According to its sub-principles, we design two\nspecific pretext tasks for the continuous view augmenter\nand the shared information encoder."}, {"title": "5.1 InfoBal Principle", "content": "The InfoBal principles enable the GCL framework to main-\ntain consistency of representative information across mul-\ntiple augmented views, while ensuring diversity, thereby\nfacilitating efficient extraction of representative embed-\ndings by the encoder. Specifically, InfoBal adheres to two\nsub-principles that guide the augmenter and the encoder.\nThe objectives of the two sub-principles are as follows: 1)\nthe view augmenter should create diverse views (diversity\nconstraint) while maintaining representative information\n(consistency constraint). 2) the encoder should extract as\nmuch representative information as possible from these\nviews (sufficiency constraint) to get embeddings while\nfulfilling the goal of maximizing mutual information."}, {"title": "5.2 Pretext Task for CVA", "content": "In semi-supervised contrastive learning, the InfoMin prin-\nciple is usually used to train the augmenter. It optimizes\nthe balance between view consistency and view diversity,\nextracting representative information from raw graph data\nwith the help of labels [36]. In unsupervised scenarios,\nextracting as much representative information as possi-\nble is equivalent to finding a set of views with maximal\naugmented variances (diversity constraint) while preserv-\ning sufficient representative information (consistency con-\nstraint). However, in the absence of labels, InfoMin, as\nutilized in unsupervised GCL frameworks [22, 3, 23, 25],\ncannot guarantee the consistency of label-related infor-\nmation between augmented views when the encoders are\ntrained using the InfoMax principle. It causes the corrup-\ntion of representative information in the augmented views\nduring augmentation. Theorem 5 formalizes the above\nproblem:"}, {"title": "5.3 Pretext Task for the Shared Information Encoder", "content": "The InfoMax principle is a widely used approach for train-\ning encoders. However, training an encoder using only the\nInfoMax principle in LAC can lead to shortcut problems.\nAccording to Theorem 3, we have:\n$I(f(V); f(V')) \\le I(V'; f(V'))$,\n(33)\n$I(f(V); f(V')) \\le I(V; f(V))$.\n(34)\nIt shows that the representative information in augmented\nviews utilized by the encoder with the InfoMax is lim-"}, {"title": "6 Experiments", "content": "We begin this section with the introduction of the experi-\nmental setup, which includes the details of datasets, eval-\nuation protocols, and baselines. Then we conduct exper-\niments to evaluate LAC by addressing the following re-\nsearch questions:\n\u2022 RQ1. (Effectiveness) Does LAC perform better\nthan the SoTA GCL frameworks in the unsuper-\nvised setting for node classification task?\n\u2022 RQ2. (Generalization Ability) How well does\nLAC generalize on various types of graphs and\nother tasks?\n\u2022 RQ3. (The necessity of each component) Are\nthe view augmenter CVA and InfoBal based pre-\ntext tasks in LAC both necessary?\n\u2022 RQ4. (Model Analysis) Does the effect of MTA\nand CFA meet the design expectations?\n\u2022 RQ5. (Sensitivity) Is LAC sensitive to hyperpa-\nrameters like \u03b1, \u03b3, \u03c4, and mask ratio in MTA?"}, {"title": "6.1 Experimental Setup", "content": "Datasets. We evaluate our approach using seven sparse\nand homogeneous datasets, including Cora [47], CiteSeer\n[47], PubMed [47], CS [48], Phy [48], Photo [48] and"}, {"title": "6.2 Effectiveness of LAC", "content": "Table 2 lists the accuracy of node classification using LAC\nand baselines to learn node embeddings in the unsuper-\nvised setting on seven sparse & homogeneous datasets. We\nobserve that LAC achieves state-of-the-art (SoTA) accu-\nracy on the node classification task. Specifically, we have\nthe following observations:\n(1) LAC achieves average improvements of 2.45% and\n4.42% compared to the best graph representation learning\nmethod and the best graph generative learning method,\nrespectively. This indicates the effectiveness of LAC as a\ngraph-contrastive learning framework.\n(2) The LAC framework demonstrates an average accuracy"}, {"title": "6.3 Generalization of LAC", "content": "The generalization ability of LAC on different datasets.\nTable 3 reports the performance of LAC on heterogeneous\nand dense datasets with the node classification task, demon-\nstrating its generalization capability to various types of\ndatasets. We select Chameleon and Texas as the representa-\ntives of heterogeneous datasets, which have heterogeneity\nscores of 0.77 and 0.89, respectively, and choose Cornell\nand Texas as dense datasets, whose sparsity is around\n0.9%. We compare a few of the best models in manual\nGCL frameworks (BGRL), statistical GCL frameworks\n(CCA-SSG), automated GCL frameworks (ADGCL), and\nspectral frameworks (GCL-SPAN) as the baselines. The\nresults clearly demonstrate that LAC consistently outper-\nforms baselines across different types of graphs.\nThe generalization ability of LAC on different tasks.\nWe conduct unsupervised node clustering experiments on\nthe Cora, Cornell, and Chameleon datasets to demonstrate\nLAC's advantages on other tasks. The results are reported\nin Table 4. NMI (Normalized Mutual Information score)\nand ARI (Adjusted Rand Information score) are used to\nevaluate the performance of node clustering. The results\ndemonstrate that LAC achieves the best performance on\ndifferent types of graphs."}, {"title": "6.4 Ablation Study", "content": "This section presents an ablation analysis of the various\ncomponents within LAC to demonstrate the necessity of\nthe proposed techniques.\nThe Effectiveness of the Continuous View Augmenter.\nTo evaluate the effectiveness of the augmentation of both\ntopological and feature information, we have developed\ntwo new variants of LAC. These variants are LAC-w/o-\nMTA, which excludes the MTA module, and LAC-w/o-\nCFA, which removes the CFA module from the framework."}, {"title": "6.5 Model Analysis", "content": "The Analysis of the MTA and CFA designed for CVA.\nWe conduct experiments on MTA and CFA to assess\nwhether these carefully designed architectures outperform\nsimpler architectures, such as MLPs. Specifically, we sub-\nstitute the MTA in the CVA with a two-layer MLP. During\nthe augmentation of views, the MLP does not consider the\npotential multivariate relationships between different val-\nues on the diagonal of the topological information matrix A\ncompared to MTA. Similarly, we replaced the CFA module\nwith a two-layer MLP, which cannot capture relationships\nbetween features in different channels. The two variants\nare named MTA-MLP and MLP-CFA, respectively. Fur-\nthermore, we replace both modules with two-layer MLP,\nresulting in the MLP-MLP model. To demonstrate the\nadvantages of augmenting feature information within a\ncontinuous space, we also directly perturb node features\nX instead of perturbing C, and we denote this model as\nMTA-rawX. Our experimental results are summarized in\nFigure 4.\nIn our study, we compare the accuracy of the CVA with\nthat of MTA-MLP. Across three datasets, CVA exhibits\nan average accuracy improvement of 0.95% compared to\nMTA-MLP. This suggests that the CFA module effectively\naugments node features by learning and perturbing the\ndistribution of cross-channel node features in continuous\nspace. Additionally, we compare the performance of the\nCVA with MLP-CFA. We find that CVA achieved an av-\nerage accuracy improvement of 2.57% across the three\ndatasets, indicating the effectiveness of the MTA module\ndesign. Finally, when comparing the original architec-\nture to MLP-MLP, we observe that CVA produces higher-\nquality augmented views across three datasets, achieving\nan average accuracy improvement of 3.03%. Addition-\nally, on average, CVA outperformed MTA-rawX by 0.15%,\nindicating the advantage of perturbing C over directly per-\nturbing X. These results validate the effectiveness of the\nMTA and CFA designs."}, {"title": "7 Related Works", "content": ""}, {"title": "7.1 Data Augmentation Methods in GCL", "content": "Graph data augmentation encompasses two primary as-\npects: topology and features. For topology, traditional\nmethods involve manually selecting probabilities for node\ndeletion [3], edge perturbation [19], subgraph selection\n[16], and graph diffusion [5] based on trial-and-error exper-\niments. Recent works have shifted towards automated GCL\nframeworks that optimize augmentation strategies strate-\ngies through data-driven techniques. JOAO [6] utilizes\nmin-max optimization to determine the optimal weights\nfor various discrete data augmentation methods. AutoGCL\n[3] learns the probability of node masking from the data.\nADGCL [22] learns the Bernoulli distribution probability\nfor each edge. GPA [4] learns the optimal combination\nweights of discrete data augmentation methods for each\ngraph based on JOAO. Ada-MIP [26] uses hybrid augmen-\ntation strategies. However, the above methods all use a\ndiscrete way to augment the topology information. For\nfeature information, the existing work usually masks cer-\ntain node features or dimensions [19, 5, 6]. These methods\ndo not continuously change the value of the node feature.\nThe random projection of the feature matrix by COSTA is\nequivalent to adding an orthogonal continuous unbiased\nnoise to the feature matrix. Through SVD decomposition\nof the feature matrix and rebalancing of the singular val-\nues, SFA [29] generates a continuous perturbation of the\nfeature information, thereby avoiding dimension collapse.\nHowever, they still overlook the continuous augmentation\nof topological information."}, {"title": "7.2 Pretext Tasks in GCL", "content": "The pretext tasks within the GCL framework are catego-\nrized into two main types [30]. The first type is based\non information theory principles. In this category, mutual\ninformation (MI) estimators calculate MI across multiple\nviews or representations. The most commonly used princi-\nple is InfoMax [35], which aims to maximize consistency\nin the representation across various views. Conversely,\nInfoMin [36] seeks to enhance the diversity of information\nbetween views in unsupervised settings [22, 25, 3]. They\nignore the consistency of information between multiple\nviews and finally produce completely different augmented"}, {"title": "8 Conclusion", "content": "GCL is an effective methodology for learning latent infor-\nmation in graph data. However, existing GCL frameworks\ngenerate inappropriate augmentations and utilize the rep-\nresentative information in graph data insufficiently. We\nproposed a novel framework for GCL called LAC. The\nCVA within LAC simultaneously augments topology and\nfeature information in an orthogonal continuous space,\nthereby generate appropriate augmented views. The In-\nfoBal pretext task applied in LAC sufficiently utilizes the\nrepresentative information in the graph data by adding a\nconsistency constraint on InfoMin and a sufficiency con-\nstraint on InfoMax. Our experimental results demonstrate\nthat LAC significantly outperforms existing GCL frame-\nworks."}]}