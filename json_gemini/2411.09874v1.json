{"title": "A Hybrid Artificial Intelligence System for Automated EEG Background Analysis and Report Generation", "authors": ["Chin-Sung Tung", "Sheng-Fu Liang", "Shu-Feng Chang", "Chung-Ping Young"], "abstract": "Electroencephalography (EEG) plays a crucial role in the diagnosis of various neurological disorders. However, small hospitals and clinics often lack advanced EEG signal analysis systems and are prone to misinterpretation in manual EEG reading. This study proposes an innovative hybrid artificial intelligence (AI) system for automatic interpretation of EEG background activity and report generation. The system combines deep learning models for posterior dominant rhythm (PDR) prediction, unsupervised artifact removal, and expert-designed algorithms for abnormality detection. For PDR prediction, 1530 labeled EEGs were used, and the best ensemble model achieved a mean absolute error (MAE) of 0.237, a root mean square error (RMSE) of 0.359, an accuracy of 91.8% within a 0.6 Hz error, and an accuracy of 99% within a 1.2 Hz error. The Al system significantly outperformed neurologists in detecting generalized background slowing (p=0.02; F1: Al 0.93, neurologists 0.82) and demonstrated improved focal abnormality detection, although not statistically significant (p=0.79; F1: Al 0.71, neurologists 0.55). Validation on both an internal dataset and the Temple University Abnormal EEG Corpus showed consistent performance (F1: 0.884 and 0.835, respectively; p=0.66), demonstrating generalizability. The use of large language models (LLMs) for report generation demonstrated 100% accuracy, verified by three other independent LLMs. This hybrid Al system provides an easily scalable and accurate solution for EEG interpretation in resource-limited settings, assisting neurologists in improving diagnostic accuracy and reducing misdiagnosis rates.", "sections": [{"title": "I. INTRODUCTION", "content": "ELECTROENCEPHALOGRAPHY (EEG) plays a crucial role in clinical neurology, aiding in the diagnosis of various neurological disorders such as epilepsy, dementia, brain lesions, and localized cerebral structural abnormalities [8], [26]. With the advent of an aging society, the incidence of neurodegenerative diseases and cerebral structural disorders, including dementia, stroke, traumatic subdural hemorrhage, and brain tumors, is gradually increasing [25]. In small hospitals or neurological clinics, EEG serves as a first-line diagnostic tool due to its relative low cost, non-invasiveness, absence of radiation exposure, and repeatability. The interpretation of EEG background activity, which includes PDR, symmetry, and the presence of focal slow waves, is an essential method for assessing cerebral cortical function and facilitates the diagnosis of these disorders [1]. In healthcare facilities lacking radiological equipment such as Computed Tomography or Magnetic Resonance Imaging, EEG becomes even more important. However, a significant proportion of hospitals or clinics lack the capability for quantitative analysis and assisted interpretation of EEG features and reports often rely on the experience of clinicians. Low inter-rater agreement among neurologists interpreting clinical EEG is a significant problem and may lead to inconsistencies in diagnosis and treatment decisions [17].\nThe SCORE-AI system [17] uses an artificial intelligence (AI) approach for automatic interpretation of clinical EEG, providing a solution to these challenges in EEG interpretation. The model employs a convolutional neural network architecture trained on a large dataset of 30,493 highly annotated EEGS to classify recordings as normal or into clinically relevant abnormal categories. One limitation is that the SCORE-AI system requires a large amount of training data labeled by experts, which may not be feasible for small hospitals and clinics. Furthermore, the complexity of EEG labeling is relatively high, and the SCORE program may not be easily integrated into existing EEG and hospital information systems, making it less suitable for small healthcare institutions.\nAdditionally, the presence of numerous artifacts in clinical EEG and the inability to achieve the same quality as research-grade EEG pose significant challenges for EEG preprocessing. Currently, there is no single unsupervised and efficient method that can effectively address these issues [27]. Furthermore, structured EEG features were difficult to obtain in small institutions because commercial systems generally do not provide access to such data. Considering these challenges, this study aims to develop an AI-based automatic reporting algorithm for EEG background, which we refer to as the Hybrid AI system, using a smaller dataset based on routine clinical EEG for training and focusing on EEG background analysis."}, {"title": "II. METHODS", "content": "This study was reviewed and approved by the Institutional Review Board (IRB) of National Cheng Kung University Hospital (NCKUH) (IRB No: B-ER-113-214). The requirement for informed consent was waived by the IRB, as the study involved the retrospective analysis of EEG data and medical records from March 1, 2020, to May 15, 2024, at Min-Jhong Hospital. The study was conducted in accordance with the Declaration of Helsinki and the ICH-GCP guidelines."}, {"title": "B. EEG Data", "content": "1) Acquisition: This study utilized a single-center retrospective clinical dataset, including all raw EEG files recorded at Pingtung Min-Jhong Hospital in Taiwan from March 2020 to May 2024. After excluding files without reports, unreadable files, or files that could not be opened, the total number of usable EEG recordings was 2,491.\n2) EEG Equipment and Recording: The study employed a Nicolet digital EEG machine for clinical use. Non-invasive methods were used to record EEG signals through standard scalp electrodes at 21 locations according to international 10-20 system. Each recording lasted approximately 10 minutes and included photic stimulation and hyperventilation procedures. The sampling rate was 125 Hz and the reference electrode was placed on the Fpz position. Fig. 1 illustrates the entire system processing workflow."}, {"title": "C. EEG Data Preprocessing", "content": "1) EEG File Conversion: Since our EEG format is not directly readable in the Python environment, MATLAB [24] and the FieldTrip toolbox [9] were used to convert Nicolet EEG raw files to the EDF format, and annotations were saved as plain text files. The primary EEG processing environment was Python 3.10, and the main EEG processing software was the open-source MNE-python [3].\n2) Rebuilding EEG Reference: There is no absolute standard for EEG reference electrode placement. The Reference Electrode Standardization Technique (REST) [18], [19] approximates standardization to an infinite reference point and is a good choice for clinical EEG. In this study, the first step was to rebuild the reference electrode using the REST method and then segment the EEG into 4-second epochs.\n3) EEG Frequency Bands: Digital EEG is a type of multichannel time-series data [14]. EEG research began with the discovery of alpha waves, which range from 8 to 13 Hz and are most prominent during eyes-closed resting states, particularly in the posterior occipital region. This awake background alpha rhythm is referred to as the posterior dominant rhythm (PDR). Other clinically relevant EEG waves include beta waves (13 to 30 Hz), associated with active cognitive activity, anxiety, and drug use, and slow waves, including theta (4 to 8 Hz) and delta (<4 Hz). Slow waves can be present in EEGs of healthy individuals, but persistent slow waves are associated with cortical dysfunction. Widespread slow waves may be related to metabolic brain disorders, degenerative brain diseases, or extensive brain injury, while focal slow waves may indicate focal brain lesions or epileptiform abnormalities.\n4) Awake, Eyes-Closed EEG Segment Selection: Rigorous experiments use eyes-open and eyes-closed markers to determine awake, eyes-closed stages. However, in clinical settings, accurate labeling of awake resting-state EEG may be challenging due to factors such as patient non-compliance or omission of markers by busy technicians. Therefore, for automated analysis, we first calculated the band power of each EEG frequency to exclude segments that did not belong to the awake, eyes-closed state. Segments meeting the following criteria were removed: epochs that included annotations of eye open or close labels by the technicians during the examination, epochs with high original signal values (>150\u00b5V), and epochs with a high beta or delta band power ratio (>mean band power + 2.2 SD). The removed segments might have severe artifacts or a PDR that was too high or too low, indicating non-eyes-closed EEG. After removing these segments, the remaining EEG segments had higher alpha power."}, {"title": "D. EEG Artifact Handling", "content": "EEG artifacts, such as eye movements, electrode instability, subject's body movements, and external electromagnetic interference, can easily contaminate the EEG. To achieve fully automated EEG analysis, a method that can automatically handle artifacts without manual labeling is necessary.\nIn this study, an unsupervised outlier anomaly detection method [11] was adopted and improved. In the original unsupervised method, 58 EEG features were applied, and we use 31 EEG features extracted here from the segmented EEG. Then, using this features, the Histogram-based Outlier Score (HBOS) [2] model was applied, along with our custom-designed neighboring electrode comparison method shown in fig. 2, to detect artifact-contaminated electrodes. If the artifact originates from a single electrode, the artifact signal is less likely to propagate to adjacent electrodes. Therefore, using the HBOS method, artifact-contaminated electrodes can be detected. This neighboring electrode comparison method, as opposed to the previous and subsequent epoch comparison method, can directly detect single-electrode artifacts. If an electrode is determined to be artifact-contaminated, the signals from neighboring electrodes are averaged to repair the affected portion.\nAdditionally, if the proportion of artifact-contaminated epochs for a single electrode exceeds 30%, the electrode is listed as an artifact channel. During the experimental process, it was observed that alpha waves have the highest power in the occipital region and this may lead to false positives being considered as anomalies. Therefore, before detection, epochs with alpha power exceeding a threshold are excluded from anomaly detection. The threshold value is determined based on the mean and median values of the data, and empirically, values between these two values yield better results."}, {"title": "E. Obtaining Features for Interpreting EEG Background", "content": "1) Posterior Dominant Rhythm (PDR) Prediction::\na) Dataset: 1,547 EEG data with expert-labeled background dominant rhythm were collected in this paper. After excluding 17 EEGs that were difficult to determine the dominant rhythm, 1,530 data remained. The data were divided into training and testing sets using artifact-repair, artifact-non-repair, and mixed data, with 70% for training and 30% for testing (Fig. 4). The file name was used as the clustering index, and the data were evenly distributed according to the label value to ensure balanced data clustering and prevent duplication in the training or testing sets. The PDR of the left and right EEG were labeled separately. With this approach, the mixed dataset could be expanded to 6,120 data.\nb) Labeling: PDR prediction was realized by training a supervised deep learning model. Experienced neurologists labeled the background PDR at 0.5 Hz intervals, with a range of 4 to 12 Hz, which covers the PDR range for most adults [12]. All 1,530 included EEG recordings were labeled with the dominant rhythm.\nc) Features: The features used were the band power spectrum of the EEG, obtained from 6 posterior electrodes bilaterally (T6, O2, P4, T5, P3, O1). The sampling frequency range was 3 to 15 Hz, using the multitaper method with a sampling interval of 0.25 Hz, resulting in a 6x48x1 feature matrix (Fig. 3). The multitaper method was chosen for its advantages of providing high frequency resolution and low variance estimates of the power spectral density [15], [28]. For data predicting the right EEG PDR, the right electrodes were placed in the first 3 rows of the matrix (T6, O2, P4, T5, O1, P3), and for predicting the left EEG PDR, the order was reversed (T5, O1, P3, T6, O2, P4). The features were standardized to a range of 0 to 1. These features were used as X, and the frequency values of the labels were used as Y for deep learning training.\nd) Models: Recent studies utilizing deep learning models, especially convolutional neural networks (CNNs), have demonstrated success in multi-task classification for EEG applications such as time-frequency analysis [31], prediction of stroke patient recovery [32], epileptic EEG diagnosis [34], and motor brain-computer interfaces [33]. Therefore, CNN models were chosen for PDR prediction. Due to the small feature dimension, three relatively low-weight neural network architectures were used, including a custom-defined CNN [10], GoogleNet [13], ResNet [5], and an ensemble model architecture. Both GoogleNet and ResNet were used without pre-trained weights. Regression-based CNN models were chosen for PDR prediction, as they allow for more precise frequency predictions compared to classification, given the continuous nature of EEG frequencies. The labels were normalized from their original 0.5 Hz interval range of [4, 12] Hz to [0, 1] to match the sigmoid output activation function used in the final layer of each model. All models use the Mean Squared Error (MSE) loss function and the Adam optimizer. Table I provides a detailed overview of each model's architecture."}, {"title": "F. Algorithm for Interpreting EEG Abnormalities", "content": "The EEG background abnormality algorithm, based on guidelines [6] and quantified techniques [7], relies on carefully determined thresholds for effective anomaly analysis. Table II outlines key parameters, thresholds, and determination methods, derived from expert knowledge, literature, and dataset analysis. The algorithm consists of three main components:\n1) Generalized Background Slowing (GBS): GBS is an important EEG abnormality that indicates global cerebral dysfunction [30]. GBS is characterized by the presence of slowing in the theta (4 to 8 Hz) or delta (1.5 to 4 Hz) frequency ranges, which can be of high or low amplitude. In our algorithm, GBS is considered present if any of the following criteria are met:\n\u2022 Right PDR and left PDR <7.5 Hz\n\u2022 Right PDR and left PDR <8 Hz and Slow band power ratio > 50%\n2) Background Asymmetry: Background asymmetry is divided into two parts: a frequency difference that is too large (left-right PDR difference >1Hz) or an amplitude difference greater than 50%. The following method is used to determine background asymmetry, and any of the conditions is considered asymmetric.\n\u2022 PDR difference > 1 Hz\n\u2022 Alpha amplitude score > 1.6 (Algorithm 1): The left-right alpha band power ratio is used as an indicator, taking 14 electrodes F8, F4, C4, T4, T6, P4, O2, F7, F3, C3, T3, T5, P3, and O1, and excluding electrodes identified as artifacts. The score is calculated for the left and right sides. If the absolute alpha band ratio > 0.5, the absolute ratio is added to the corresponding side. If the score is greater than 1.6, the background is considered asymmetric.\n3) Focal Slow Waves: Focal slowing is another important EEG abnormality that indicates focal cerebral dysfunction. It can be continuous or intermittent and is characterized by the presence of slow waves in a specific brain region [30]."}, {"title": "Algorithm 1 Alpha Amplitude Score Algorithm", "content": "Require: $R_a$ {Left-right alpha band power ratios}\nRequire: artifacts {Set of artifact electrodes}\nRequire: electrodes {Set of all electrodes}\nEnsure: $score_{left}$, $score_{right}$ {Left and right alpha amplitude scores} Initialization :\n$score_{left}$\u2190 0\n$score_{right}$ \u2190 0\nfor each electrode i \u2208 electrodes do\nif i \u2209 artifacts then\nif $|R_a[i]|> 0.5$ then\nif $R_a[i] > 0$ then\n$score_{left}$ \u2190 $score_{left} + |R_a[i]|$\nelse\n$score_{right}$ \u2190 $score_{right} + |R_a[i]|$\nend if\nend if\nend if\nend for\nif $score_{left} > 1.6$ or $score_{right} > 1.6$ then\nreturn Asymmetric background amplitude\nelse\nreturn Symmetric background amplitude\nend if"}, {"title": "Algorithm 2 Focal Slow Waves Algorithm", "content": "Require: $R$ {Left-right theta and delta band power ratios, with R[i, 0] representing theta and R[i, 1] representing delta for electrode i}\nRequire: artifacts {Set of artifact electrodes}\nEnsure: $score_{left}$, $score_{right}$ {Left and right focal abnormality scores}\nEnsure: $E_{abn}$ {Set of abnormal electrodes} Initialization :\n$score_{left}$\u2190 0\n$score_{right}$ \u2190 0\n$E_{abn}$ \u2190 {}\nfunction neighbors(i)\nreturn adjacent electrodes of i\nend function\nfor each electrode i do\nif i \u2209 artifacts then\nif $(|R[i, 0]|> 0.5 or |R[i, 1]| > 0.5)$ and $\\exists j \\epsilon neighbors(i): (|R[j, 0]| > 0.5 or |R[j, 1]| > 0.5)$ then\n$E_{abn}\u2190 E_{abn} \\cup {i}$\nend if\nend if\nend for\nfor each electrode i \u2208 $E_{abn}$ do\nfor k\u2208 {0,1} do\nif $|R[i, k] > 0.5$ then\nif $R[i, k] > 0$ then\n$score_{left} \u2190 score_{left} + |R[i, k]|$\nelse\n$score_{right} \u2190 score_{right} + |R[i, k]|$\nend if\nend if\nend for\nend for\nif $score_{left} > 2.4$ or $score_{right} > 2.4$ then\nreturn Focal slow waves present, $E_{abn}$\nelse\nreturn No focal slow waves\nend if"}, {"title": "G. Validating the Accuracy of the Hybrid Al System", "content": "1) Data Sources and Methodology: Two datasets were used for validation:\na) Custom Validation Dataset: The validation dataset consisted of 100 EEG recordings that were not used in the PDR model development. The ground truth labels were established by majority agreement among three neurologists who independently reviewed the EEGs. The two categories of abnormalities labeled were: 1) generalized background slowing (GBS), and 2) focal abnormalities, which included background asymmetry or focal slow waves. The neurologists were all blinded to the patients' information, original reports, and the results of the hybrid Al system. The original EEG reports, as interpreted by neurologists were retrieved. Each report was manually labeled to indicate whether its content mentioned the two aforementioned abnormality indicators. The AI hybrid system was then used to analyze the EEGs to output the inicaters of GBS and focal abnormalities. The system's output was compared to the neurologists' labels and the original reports to assess its accuracy.\nb) Public TUAB Dataset: 276 EEG recordings from evaluation set of Temple University Abnormal EEG Corpus v3.0.1 [36]. The initial dataset consisted of 150 normal and 126 abnormal EEGs. After a rigorous review process involving three neurologists, who unanimously agreed on the reclassification, 28 EEGs were relabeled to ensure consistency with our study's focus on background abnormalities. This expert review and reclassification resulted in a final dataset comprising 178 normal and 98 abnormal EEGs. The abnormal group is corresponded to any of the GBS or focal abnormalities. The hybrid AI system was used to analyze the TUAB EEGs, and the output was compared to the expert-labeled ground truth to evaluate the system's performance.\nc) TUAB Dataset Preprocessing: The TUAB recordings were cropped to the first 600 seconds for several key reasons:\n\u2022 To maintain consistency with our custom dataset's average duration (548.80 \u00b1 44.16 seconds vs. TUAB's original 1372.40 \u00b1 594.60 seconds).\n\u2022 To focus on the most diagnostically relevant portion of the EEG. Recordings after 600 seconds often showed signs of subject sleepiness, resulting in a slower background that could potentially confound the analysis of non-epileptic background abnormalities.\n\u2022 Preliminary analysis of the PDR of the TUAB dataset showed a significant decrease after 600 seconds (8.64 \u00b1 1.80 Hz to 8.45 \u00b1 1.75 Hz, p < 0.001), suggesting the onset of drowsiness and supporting our decision to crop recordings at 600 seconds."}, {"title": "2) Performance Metrics and Statistical Analysis:", "content": "a) Custom Dataset: Gwet's AC1 coefficient was used to assess inter-rater agreement for the neurologists' ground truth labels. Metrics for comparing the AI system's performance to the neurologists' original reports included confusion matrices, F1 score, accuracy, precision, recall. McNemar's test was used for statistical significance testing of the performance differences between the AI system and the neurologists.\nb) TUAB Dataset: EEG features across normal, abnormal, and relabeled groups analyzed using mean and standard deviation. Statistical significance was determined using two-tailed t-tests. The performance metrics used for the TUAB dataset were the same as those for the custom dataset. Z-tests were used to compare the AI system's performance between the custom dataset and the TUAB dataset."}, {"title": "H. Generating EEG Background Reports", "content": "Figure 5 illustrates the workflow for generating and verifying EEG reports. The system uses a large language model (LLM), specifically the Google Gemini 1.5 Pro API [21] for its state-of-the-art performance across a wide range of tasks, including long-context retrieval, reasoning, and real-world applications, while maintaining high compute efficiency.\n1) Input Processing: The system takes as input the structured EEG features generated by our hybrid AI algorithm. These features are formatted as a JSON object, containing key metrics such as background frequency, amplitude, symmetry, and any detected abnormalities.\n2) Prompt Engineering: A carefully designed prompt is crucial for guiding the LLM to generate accurate and clinically relevant reports. Our prompt structure includes:\n\u2022 Role Definition: Establishes the LLM as a neurologist with access to comprehensive neurological databases.\n\u2022 Data Provision: Incorporates the structured EEG features and their interpretations.\n\u2022 Task Specification: Directs the LLM to generate a detailed, structured EEG report.\n\u2022 Report Structure: Outlines the required sections (Findings, Conclusion, Clinical Correlation, Advanced Strategies).\n\u2022 Guidance: Provides examples and instructions for handling normal and abnormal findings.\n3) Report Generation: The system sends the constructed prompt to the Google Gemini API, which then generates the EEG report. The resulting report adheres to the specified structure instructed by the prompt. To illustrate the process, we present a real example of JSON features and the corresponding generated report:"}, {"title": "I. LLMs Verification of Report Accuracy", "content": "The accuracy of 512 EEG reports generated by the hybrid AI algorithm and LLM were verified using few-shot prompting with three LLM models: OpenAI GPT-40 mini [23], Google Gemini 1.5 Flash [21], and Claude 3.5 Sonnet [22]. Few-shot prompting was performed on the report content to verify accuracy. The prompt instructed the LLM to classify the report content as 1 or 0 based on the presence of two indicators: GBS and focal abnormality. The LLM was instructed to return the values in an array format. The verification result was determined by the majority agreement of the three LLM models. The inter-rater agreement among the three LLMs was evaluated using Gwet's inter-rater reliability coefficients (AC1) [29]. All 512 LLM verification results were compared with the results output by the hybrid AI algorithm on the two indicators of GBS and focal abnormality, and a confusion matrix was calculated to verify accuracy using the F1 score, accuracy, precision, and recall metrics. Finally, to ensure the accuracy of the AI-generated reports, human experts verified all the 512 reports generated by the hybrid Al system."}, {"title": "III. RESULTS", "content": "A total of 2,491 usable EEG recordings were included in the preprocessing. Experiments were conducted separately with artifact removal and without artifact removal procedures, obtaining two sets of features for report generation: one with artifact correction and one without artifact correction. The comparison of EEG features between the artifact-repair and non-repair groups is shown in Table III."}, {"title": "a) Feature Analysis Results of Our Full Dataset:", "content": "Most EEG features did not show significant differences between the artifact-repair and non-repair groups. Features that exhibited statistically significant differences (p<0.05) included lower anterior-posterior gradient (AP gradient) in the Repair group, higher left-right hemisphere theta ratio in the Repair group, and higher left-right hemisphere alpha ratio in the Repair group. The Repair group had lower amplitude values in the beta, theta, and delta frequency bands, while the difference in alpha band amplitude was marginally significant. These differences indicate that the artifact removal process may affect certain aspects of the EEG signal, particularly the anterior-posterior gradient, hemisphere ratios of theta and alpha, and amplitude values of different frequency bands."}, {"title": "b) Feature Analysis Results of TUAB dataset:", "content": "Analysis of EEG features in the TUAB dataset revealed significant differences in nine of the thirteen features between abnormal and both normal groups, while only one feature showed a significant difference between the original and relabeled normal groups. These findings underscore the robustness of certain EEG characteristics, particularly slow wave features, in distinguishing abnormal from normal non-epileptic background EEG patterns and highlight the importance of precise labeling in EEG analysis."}, {"title": "B. PDR Prediction Results", "content": "Fig. 6 shows the distribution of the posterior dominant rhythm (PDR) in the dataset. The deep learning model used 1,530 EEG recordings with labeled PDR to train. The labeled PDR results had a mean of 8.6Hz, max of 12Hz, min of 4Hz, and a standard deviation of 1.66Hz.\n1) K-Fold Cross-Validation Results: Table V presents the best MAE model results for each fold, along with the pairwise significance test results. The results show consistent performance across all folds, with MAE ranging from 0.255 to 0.281, ACC0.6 from 0.885 to 0.910, and ACC1.2 from 0.976 to 0.988. Pairwise significance tests revealed no statistically significant differences between folds for any evaluation metric (p > 0.05). These findings demonstrate the models' ability to generalize well to unseen data. The consistent performance across different data subsets and the lack of statistically significant differences between folds further confirm the robustness and generalizability of the proposed PDR prediction models.\n2) Smaller Dataset Validation Results: Results from 10 runs of each dataset proportion are shown in Fig. 7. Performance generally improved with increasing dataset size, with the most significant improvements observed when increasing from 20% to 40% (RMSE p = 0.905, MAE p = 0.058, ACC0.6 p = 0.195, ACC1.2 p = 0.210). Further increases led to more gradual improvements, with non-significant differences between 60%-80% and 80%-100% ratios. These findings suggest that 40% of the original dataset (approximately 612 samples) may be sufficient for reasonably accurate PDR predictions. However, using 60% to 80% of the data (918\u20131,224 samples) provides better overall performance, with diminishing returns beyond 80%.\n3) Performance on Different Datasets: (Table VI) The mixed dataset (combining artifact-repair and non-repair EEG) achieved the best overall performance (RMSE: 0.365, MAE: 0.252, R-squared: 0.951, ACC0.6: 90.8%, ACC1.2: 99.4%). The non-repair dataset showed very similar results, with only slightly lower ACC0.6 (90.5%) and ACC1.2 (99.2%). The repair-only dataset demonstrated comparable performance (RMSE: 0.370, MAE: 0.256, R-squared: 0.949, ACC0.6: 91.6%, ACC1.2: 98.7%), notably achieving the highest ACC0.6. Pairwise significance tests (t-test for RMSE and MAE, McNemar's test for ACC0.6 and ACC1.2) revealed no significant differences between the datasets for any metric (p > 0.05). This suggests that the model performs consistently across different EEG preprocessing approaches, demonstrating robustness in PDR prediction across various data conditions.\n4) Performance of Different Model Architectures: (Table VII) The ensemble model achieved the best overall performance (RMSE: 0.359, MAE: 0.237, R-squared: 0.952, ACC0.6: 91.8%, ACC1.2: 99.0%), followed closely by GoogleNet (RMSE: 0.365, MAE: 0.252, R-squared: 0.951, ACC0.6: 90.8%, ACC1.2: 99.4%). CNN and ResNet performed relatively weaker but acceptably. Fig 8 shows the scatter plot of the ensemble model's predicted values and true PDR values. Pairwise significance tests revealed that the ensemble model significantly outperformed CNN and ResNet in RMSE (p < 0.001) and ACC1.2 (p < 0.01). It also showed significantly lower MAE than CNN (p < 0.001) and higher ACC0.6 than both CNN (p = 0.04) and ResNet (p = 0.02). GoogleNet significantly outperformed CNN in RMSE (p = 0.07) and ACC1.2 (p = 0.03), and ResNet in MAE (p < 0.001) and ACC0.6 (p = 0.91). No significant differences were found between GoogleNet and the ensemble model (p > 0.05). While artifact repair had limited impact, all models demonstrated considerable performance, validating the effectiveness of the proposed deep learning architectures for EEG PDR prediction."}, {"title": "C. Impact of Artifact Removal on EEG Dataset", "content": "There are no reference indicators for artifact repair in the literature. Since the artifact removal uses unsupervised learning models, it is a challenging task to label the epochs with artifacts. In addition to presenting actual examples to observe the effect and correctness of artifact removal and signal restoration, another aspect is to see if there are differences in the PDR prediction results using the corrected dataset. Here, we assume that improper or excessive artifact correction will lead to poorer performance in PDR prediction. Another proof is to observe the accuracy of the AI algorithm's final abnormality prediction, which will be explained below."}, {"title": "D. Accuracy Comparison between Hybrid Al System and Neurologist Interpretation", "content": "The inter-rater agreement among the three neurologists was evaluated using Gwet's Agreement Coefficient (AC1). The results were as follows:\n\u2022 For generalized background slowing (GBS), the AC1 was 0.61 (95% CI: 0.49 to 0.73).\n\u2022 For focal abnormalities, the AC1 was 0.80 (95% CI: 0.7 to 0.88).\nThese results indicate substantial agreement among the neurologists for focal abnormalities and moderate agreement for GBS, based on the interpretation of AC1 values [29].\nTable VIII presents a comprehensive comparison between the Hybrid AI system and neurologist reports in detecting EEG abnormalities. For generalized background slowing (GBS), both AI models (with and without repair) significantly outperformed neurologists (p = 0.02), achieving higher F1 scores (0.93 vs. 0.82), precision (0.95 vs. 0.74), and accuracy (0.94 vs. 0.83). However, neurologists showed slightly higher recall (0.93 vs. 0.90) for GBS. In focal slowing abnormality detection, the AI models demonstrated improvements, particularly in the repair mode. The AI-repair model achieved higher F1 score (0.71 vs. 0.55), recall (0.91 vs. 0.55), and accuracy (0.92 vs. 0.90) compared to neurologists, with a trade-off in precision (0.59 vs. 0.55). Notably, the AI-repair model showed substantial improvement over the non-repair version, especially in precision (0.59 vs. 0.48) and F1 score (0.71 vs. 0.62). However, the differences in focal slowing detection were not statistically significant (p = 0.79)."}, {"title": "E. Performance Comparison on TUAB Dataset", "content": "Table IX presents the confusion matrices and performance metrics for each dataset, along with the p-values obtained from Z-tests comparing the metrics between AI hybrid model's performance on the TUAB and our validation datasets. The proposed model achieved F1 scores of 0.835 and 0.884, precisions of 0.827 and 0.857, recalls of 0.844 and 0.913, and accuracies of 0.884 and 0.890 on the TUAB and our validation datasets, respectively. Z-tests conducted for each performance metric yielded p-values ranging from 0.59 to 0.76, all exceeding the 0.05 significance level. This indicates no statistically significant differences in model performance between datasets. These results demonstrate the model's consistent performance and generalizability across different datasets, supporting its robustness and potential for real-world applications."}, {"title": "F. Accuracy of LLM Report Generation", "content": "Table X shows the accuracy verification results of the AI-generated EEG reports by three LLMs. The inter-rater agreement among the three LLMs was assessed using Gwet's AC1 coefficient. For GBS, the AC1 coefficient was 0.97 (95% CI: 0.95-0.98), and for focal abnormality, it was 0.99 (95% CI: 0.98-1.0), indicating strong agreement in verifying report accuracy. Performance metrics for both GBS and focal abnormality showed F1 scores, precision, recall, and accuracy all at 1.0. These results confirm that the EEG reports generated by the hybrid AI algorithm and LLM were highly accurate and consistent across the three LLM models. Furthermore, these LLM-validated results were subsequently reviewed by human experts, who confirmed the 100% accuracy of the generated reports, providing an additional layer of validation to the AI system's performance."}, {"title": "IV. DISCUSSION", "content": "This study proposes an innovative hybrid artificial intelligence system for automatic interpretation of EEG background activity, addressing the clinical challenges faced by small hospitals and clinics that lack advanced EEG signal analysis systems and are prone to misinterpretation in manual EEG reading. In terms of PDR prediction, the system achieved a very high accuracy using only 1,530 EEG files as deep learning"}]}