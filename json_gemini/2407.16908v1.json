{"title": "GENERATION CONSTRAINT SCALING CAN MITIGATE\nHALLUCINATION", "authors": ["Georgios Kollias", "Payel Das", "Subhajit Chaudhury"], "abstract": "Addressing the issue of hallucinations in large language models (LLMs) is a critical challenge. As the\ncognitive mechanisms of hallucination have been related to memory, here we explore hallucination\nfor LLM that is enabled with explicit memory mechanisms. We empirically demonstrate that by\nsimply scaling the readout vector that constrains generation in a memory-augmented LLM decoder,\nhallucination mitigation can be achieved in a training-free manner. Our method is geometry-inspired\nand outperforms a state-of-the-art LLM editing method on the task of generation of Wikipedia-like\nbiography entries both in terms of generation quality and runtime complexity.", "sections": [{"title": "Introduction and Background", "content": "While large language models exhibit remarkable performance in language generation and machine translation, their\ngenerations suffer from the issue of hallucinations. Model editing techniques provide a path to mitigate such issues,\nwhich involve modifying model parameters such that model outputs are changed to desired responses for specific\nquestions without compromising the accuracy for others. Context-grounding has been proposed as another means,\nwhere desired response (the actual fact) is included in the context within the prompt, with the expectation that the\ndecoder will utilize the information included in the prompt. Given the relation between memory and hallucination\nin psychology Berberette et al. (2024), it is believed that LLMs with explicit memory mechanism will help lowering\nhallucination. Here, we investigate if that is indeed the case, by employing Larimar Das et al. (2024), a recently proposed\nLLM decoder that is augmented with an external memory with read/write access. In the memory-augmented LLM,\nthe encodings of arguments to their memory primitives serve only as intermediate representations in their generation\npipeline to condition the decoding: and then they are silently discarded, they are not further explored. Departing from\nthis practice, we inspect the geometry of these representations and leverage our findings to devise a simple yet effective\napproach for mitigating hallucination. Here we use Larimar as the memory-augmented language model and compare its\nperformance on a hallucination benchmark with GRACE Hartvigsen et al. (2022) as a baseline, which is an existing\nmodel editing technique."}, {"title": "Larimar", "content": "Larimar is a class of LLMs augmented with an external episodic memory controller. In its base instantiation, Larimar\narchitecture includes (i) an encoder, (ii) an associative memory module and (iii) a decoder. The encoder computes\nlatent representations of sets of textual inputs (episodes) and queries. These can be respectively used for updating the\nmemory and querying it to return readout encodings. The decoder generates output text from a prompt, constrained by\nthe readout.\nNote that a readout vector serves as a special compressed key-value (KV) cache at the decoder, which expands to\nkey-value vector pairs for each of its layers via a weight matrix learnt during Larimar training. It can also be interpreted\nas the latent vector that is injected for adapting the decoder to arbitrary conditional input without retraining the model\nagain as in Optimus Li et al. (2020)."}, {"title": "GRACE", "content": "GRACE is a method for LLM editing without altering its weights. It works by installing a special adapter at one or\nmore of its layers: a GRACE adapter is basically a dynamically expanding key-value codebook. A key is the layer's\ninput activation; its value is the input to the next layer that, if substituted, would render the correct output for the current\ninput-output sample pair. Codebook values are learnt by minimizing a task-specific loss function."}, {"title": "Experiments", "content": ""}, {"title": "Data and Models", "content": "WikiBio is a hallucination benchmark dataset of Wikipedia-like biographies for 238 subjects generated by prompting\nGPT-3 Manakul et al. (2023). It includes annotations for the factuality accuracy for each of the generated sentences by\ncomparing them to the actual Wikipedia biography article sentences (accurate, major/minor inaccurate).\nIn Hartvigsen et al. (2022), authors finetune GPT2-XL on WikiBio dataset mixed with sentences from OpenWebText\nAaron Gokaslan and Tellex (2019), a public version of GPT2's training data and use the resulting model in hallucination\nmitigation experiments. We apply edits on the same model and adapter configuration for GRACE benchmarks.\nFor Larimar-based experiments, we employ Larimar-1.3B model. This comprises a BERT large encoder Devlin et al.\n(2018) combined with a GPT2-large Radford et al. (2019) decoder and a memory matrix (512x768), trained over 7.6\nmillion examples constructed by splitting WikiText Merity et al. (2016) texts to small chunks of 64 tokens."}, {"title": "WikiBio hallucination task", "content": "We organize the sequence of $n_i$ sentences in the actual and GPT-3 generated (hallucinating) texts for the $i^{th}$ WikiBio\nentry, $i \\in [238]$, in two lists: $[WB_i(j)]$ and $[WB_{hal}(j)]$, $j \\in [n_i]$. Then for each WikiBio entry $i$ we form $n_i - 1$\nsentence pairs of the form $(WB_{hal}(j), WB_i(j + 1))$, $j \\in [n_i - 1]$. The first sentence in the pair (also referred to as\nprompt in the sequel) is a GPT-3 generated sentence (with index $j$) in the entry and the second sentence (alternate name:\ninput) is the \u201cnext\u201d one (index: $j + 1$), however the latter in the sequence of the sentences in the actual Wikipedia\nentry.\nWe can then use these pairs to generate output sentences from a model. In particular, we:\n1. Inform the model of a pair (prompt, input). In Larimar this can be achieved by writing this pair to its\nmemory. For GRACE this will be an edit operation typically updating the codebook in one of its adapters.\n2. Ask the informed model to generate an output sentence based on the prompt only; input is no longer\naccessible. In Larimar this will be implemented by (i) querying the memory with the prompt to get a readout\nvector and (ii) generating model output initialized to prompt and constrained by readout. For the edited\nGRACE model this translates to generating output starting from prompt.\n3. Concatenate the sequence of output sentences - here initialized with the first prompt sentence - resulting in\na newly-built and model-specific WikiBio entry.\nAn actual Wikipedia entry serves as our non-hallucinating baseline. We quantify hallucination in WikiBio entries\nsynthesized by Larimar and GRACE using this baseline as our reference text. Two metrics are employed: RougeL score\nand Jaccard similarity index between reference and synthesized texts. For Jaccard, set operations are computed on\ntokenized texts: tokenizers respectively from Larimar encoder and GRACE model are used.\nBase case: initial explorations. By averaging over $i = [238]$ we obtain:\n\u2022 RougeL scores: 0.39 \u00b1 0.14 for Larimar and 0.49 \u00b1 0.18 for GRACE.\n\u2022 Jaccard similarity scores: 0.33 \u00b1 0.13 for Larimar and 0.44 \u00b1 0.17 for GRACE.\nIdeal case: $Z_{write} = Z_{readout}$. Note that ideally, if latent vector representations for readout and write coincide\n($Z_{write} = Z_{readout}$), the decoder will have the luxury to attend to a (compressed) representation of what was originally\nwritten in memory, (the (prompt, input) pair). So then, intuitively, when prompted with prompt, the decoder will be\neffectively constrained towards generating a textual output that will be similar to input, the second element of the"}, {"title": "Observations", "content": "Figures 2, 3, 4, are panels of histograms capturing geometric properties (distance, angle in degrees, $l_2$-norm) of latent\nvector representations for pairs of texts in various stages of our Larimar pipeline as in Figure 1: x-axis depicts the\naverage of the property for each of the 238 biographies, suitaby binned, and y-axis is the count for the bin.\n\u2022 We observe that Larimar decoder arbitrarily distorts both the direction and the magnitude of incoming $Z_{readout}$\nvectors: $Z_{generate}$ vectors tend to increase in magnitude and deviate over a broad range of acute angles from\ntheir decoder inputs. This makes it hard to connect the two vector types (Figure 2). Similarly, when we enforce\na random prompt in querying the memory - which is a way of muting the constrained generation advantage in\nLarimar - then $Z_{write}$ and corresponding $Z_{readout}$ vectors significantly deviate from each other (Figure 3), so\nwe cannot connect them: lengths contract by an approximate factor of $\\times 10$ and their angles distribute wildly\nover the full 0\u00b0-180\u00b0 range.\n\u2022 There is a clear alignment between $Z_{write}$ and $Z_{readout}$ vectors when standard constrained generation is in\neffect in Larimar; equivalently when we query its memory with the actual prompt (Figure 4). Although there\nis still a relative decrease in vector length by a factor of $\\times 3$ to $\\times 4$, the two vectors are very well aligned (their\nangles are tiny fractions of 1\u00b0).\nThis last observation provides a very interesting avenue for constraining generation in Larimar so that hallucination is\nmitigated: we can scale up the length of $Z_{readout}$ vector by the reported factor (a fixed number $s$ in the range 3 to 4\nfor all samples). Then its distance to $Z_{write}$ can be kept approximately to a minimum and subsequently expect to get\nhallucination-optimized generations (similar to the ideal case above)."}, {"title": "Complexity considerations", "content": "GRACE learns codebooks via minimization of a loss function during edits. This is an expensive iterative operation\nsince a number backpropagation steps are necessary. GRACE model has 1,557,611,200 parameters. It takes 162.5 secs\nto synthesize a GRACE WikiBio entry. If we do not include the time necessary to reinitialize the model for each pair\nprocessing, this can go down to 37.8 secs.\nLarimar uses memory writes and reads. These are implemented as pairs of matrix multiplications (i) for computing the\ncoordinates of distributed memory slots to write to / read from and (ii) for computing the low-rank memory matrix\n(while writing) or extracting readout representation (while reading). These are lightweight operations. Larimar encoder\nhas 335,152,128 parameters; Larimar decoder has 810,406,400 parameters. It takes 3.1 secs on average to synthesize a\nLarimar WikiBio entry."}, {"title": "Discussion", "content": "The ability to constrain generation in the decoder by using lightweight memory primitives as in Larimar encoder-\nmemory-decoder architecture, offers an excellent, training-free opportunity for mitigating hallucination. Simple,\ngeometry-inspired operations (here: vector scaling) on selected encodings (here: memory readouts), although inherently\nlimited to models which, like Larimar, are augmented with explicit memory mechanism, can be much more effective\nthat training-based approaches (here: GRACE, learning adapter layers parameters by training)."}, {"title": "Example of WikiBio generation", "content": ""}]}