{"title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost", "authors": ["Sania Nayab", "Giulio Rossolini", "Giorgio Buttazzo", "Nicolamaria Manes", "Fabrizio Giacomelli"], "abstract": "Today's large language models (LLMs) can solve\nchallenging question-answering tasks, and prompt\nengineering techniques, such as chain-of-thought\n(CoT), have gained attention for enhancing the\nexplanation and correctness of outputs. Neverthe-\nless, models require significant time to generate\nanswers augmented with lengthy reasoning de-\ntails. To address this issue, this paper analyzes\nthe impact of output lengths on LLM inference\npipelines and proposes novel metrics to evaluate\nthem in terms of correct conciseness. It also ex-\namines the impact of controlling output length\nthrough a refined prompt engineering strategy,\nConstrained-CoT (CCoT), which encourages the\nmodel to limit output length. Experiments on\npre-trained LLMs demonstrated the benefit of the\nproposed metrics and the effectiveness of CCOT\nacross different models. For instance, constrain-\ning the reasoning of LLaMA2-70b to 100 words\nimproves the accuracy from 36.01% (CoT) to\n41.07% (CCoT) on the GSM8K dataset, while\nreducing the average output length by 28 words.", "sections": [{"title": "1. Introduction", "content": "In recent years, large language models (LLMs) have demon-strated remarkable capabilities in tackling complex question-answering tasks, making significant strides in natural lan-guage understanding and generative AI (Taori et al., 2023;Chiang et al., 2023; Dolly, 2023; Geng et al., 2023). Thecontinuous advancements made in architectures and trainingmethods played a crucial role in enhancing the performanceof these models. Alongside these developments, prompttechniques have also seen substantial evolution. One suchtechnique that has attracted considerable attention is chain-of-thought (CoT) prompting (Wei et al., 2022; Fu et al.,2023). This approach enhances the explanation and correct-ness of the output by encouraging the LLM to articulate itsanswer through intermediate reasoning steps.\nDespite the mentioned advantages, the CoT prompting canlead to longer outputs, increasing the time required for themodel to generate a response. This is due to the natureof autoregressive transformers, which decode text word byword, each time running a new inference pass of the decodermodule (Vaswani et al., 2017; Shekhar et al., 2024). Thisimplies that the time required to generate a response isheavily influenced by the length of the reasoning provided,which can also vary depending on the prompt. Such longand variable delays in the responses are undesirable whenthe LLM has to relate with a user through an interactiveconversation. This issue highlights the need to consider i)metrics for evaluating the conciseness of the outputs and ii)solutions to avoid excessively long chains of reasoning.\nTo this end, the first part of this work presents some moti-vational experiments to show the relation between outputlength and inference time of an LLM. Then, it proposes threenovel metrics to account for the conciseness and correct-ness of a generated answer. The objective of the proposedmetrics is to reweight the accuracy of a given model byconsidering aspects related to output lengths that affect theinference time of the model and its time predictability.\nTo address the significant increase in output length caused byCoT techniques, the second part of this work examines howto control the length of CoT reasoning with specific prompt-ing requests. Specifically, we introduce a refined promptengineering strategy called constrained-CoT (CCoT), de-signed to encourage an LLM to limit the output length andcontrol the reasoning process. The main idea is to explicitlyask the model to provide an output with a length less than agiven bound, thus pushing the LLM to produce concise rea-soning. In this case, we must ensure that the model outputsremain accurate and time-bound.\nThe proposed technique is evaluated through experimentsto explore the impact of CCoT on both generation timesand the correctness of the responses while simultaneouslydemonstrating the benefits of measuring this trade-offthrough the proposed metrics. Experiments conducted onvarious pre-trained LLMs of different sizes in a zero-shotquestion-answering (QA) setting highlighted that the per-formance of the CCoT method strongly depends on thespecific LLM and the type of task. For example, using"}, {"title": "2. Related Work", "content": "To the best of our knowledge, most recent works on LLMsfocused on increasing their accuracy (Jiang et al., 2020; Ka-plan et al., 2020; Zhu et al., 2023). However, as models scaleup, they tend to generate more extensive and articulated re-sponses (Bhargava et al., 2023), which can introduce otherproblems, such as hallucinations (where the model producesinformation that appears plausible but not grounded (Kada-vath et al., 2022), or unnecessarily long explanations (Qiuet al., 2024; Azaria and Mitchell, 2023), which can obscurekey information, making it difficult for users to extract rele-vant content efficiently (Khashabi et al., 2021; Wang et al.,2024). To filter out useless reasoning, Li et al. (Li et al.,2021) proposed a multi-hop processing technique, where anextraction task on the encoder to obtain the rationale for ananswer, which is the most relevant piece of text in an inputprompt to a given question.\nTo further improve the accuracy of LLMs, several promptengineering approaches have been presented in recent years(Qin and Eisner, 2021). Prompt engineering involves thestrategic design of input patterns to guide the model towardgenerating more accurate and relevant responses (Reynoldsand McDonell, 2021; Marvin et al., 2023). However, mostof these approaches have been conceived to enhance modelaccuracy, increasing the output length. For instance, loet al. (Lo, 2023) and strobelt et al. (Strobelt et al., 2022)introduced prompt-based approaches by adding task-specificpatterns to frame the input data. While these methods allowboosting accuracy, they can also produce longer outputsdue to the additional context and detail introduced by theprompt, making it challenging to provide factual and conciseanswers (Shi et al., 2023).\nAnother form of prompt engineering was proposed to im-prove reasoning within the conclusive answer. In this con-text, Chain-of-Thought (CoT) prompting (Wei et al., 2022)is one of the most notable methods, showing significantbenefits in QA tasks by requiring the model to provide astep-by-step explanation along with the final response. How-ever, as also highlighted in Section 3, answers generatedwith CoT tend to be lengthy, hence increasing the generationtime (Liu et al., 2018; Takase and Okazaki, 2019).\nGiven the substantial amount of work focused on improvingthe accuracy of LLMs, it is not surprising that most of theadopted metrics (Lin, 2004; Stallings and Gillmore, 1971)and benchmarks (Clark et al., 2018; Lin et al., 2021) onlyaddress the correctness of the responses, without payingattention to conciseness and response times (Bhargava et al.,2023). As already mentioned in Section 1, these propertiesare instead desirable in applications that require an interac-tive conversation with the user.\nThis work. To face these challenges, this work proposesnovel metrics that account for both the conciseness and thecorrectness of the responses. Furthermore, to understandthe capability of LLMs to control the length of reasoningin their outputs, this work proposes a revised version of theCoT prompting (Wei et al., 2022), Constrained Chain-of-Thought (CCoT), which explicitly asks the model to controlthe length of its reasoning. We support the analysis by eval-uating the novel metrics and testing the proposed promptingapproach, understanding how it affects the quality of theanswers and, specifically, the response time of the LLMs."}, {"title": "3. Motivational considerations", "content": "The output generation time of an LLM depends on vari-ous factors, including the model architecture, the pre-andpost-processing steps, the answer decoding process, andthe question posed, also considering the use of prompt en-gineering approaches. While the computational cost due"}, {"title": "4. Metrics for concise correctness", "content": "Motivated by the previous considerations, this sectionpresents three novel metrics to evaluate the capability ofan LLM to provide correct as well as concise responses.The idea is to redefine the classic accuracy metric to inte-grate conciseness aspects into the LLM output's correctness.Formally, an answer \u0177 is considered correct if the conclu-sion extracted through a post-processing function \u0393 matches the given ground truth y. Thus, the accuracy of an LLM canbe computed as\n$A = \\frac{1}{N} \\sum_{i=1}^{N} 1(\\Gamma(\\hat{y}_i), y),$\nwhere N is the number of tested samples and 1 (u, v) isthe indicator function that returns 1 if u = v, 0 otherwise.Please note that I represents a user-defined function thatcan be implemented based on a regular expression (e.g.,by extracting specific patterns from the sentence (Fu et al.,2023)) or using pseudo-judge approaches (e.g., by using asecondary large model as a judge (Zheng et al., 2024)).\nStarting from Equation (2), the conciseness of an output\u0177i can be integrated with its correctness by multiplyingthe indicator function by a penalty term $p(\\hat{y}_i) \\in [0, 1]$ thatdecreases its value for long outputs:\n$\\frac{1}{N} \\sum_{i=1}^{N} [1(\\Gamma(\\hat{y}_i), y_i) \\cdot p(\\hat{y}_i)] .$\nThe following defines three specific metrics by setting aproper penalty function.\nHard-k Concise Accuracy: HCA(k). It measures thefraction of correct outputs that do not exceed a user-specifiedlength k:\n$HCA(k) = \\frac{1}{N} \\sum_{i=1}^{N} [1(\\Gamma(\\hat{y}_i), y_i) \\cdot p_{hard}(\\hat{y}_i, k)],$\nwhere\n$p_{hard} (\\hat{y}_i, k) =  \\begin{cases}\n1 & \\text{if } N(\\hat{y}_i) \\leq k \\\\\n0 & \\text{otherwise}.\n\\end{cases}$\nThis metric does not account for responses that exceed thespecified maximum length, thereby promoting conciseness.We believe it could be particularly useful in scenarios wherestrict adherence to length constraints is essential, such asin real-time systems or environments with limited computa-tional resources.\nSoft-k Concise Accuracy: SCA(k, a). It generalizes theprevious metric by penalizing the correct answers that ex-ceed the maximum length k with a term that decreasesexponentially with a decay factor a:\n$\\frac{1}{N} \\sum_{i=1}^{N} [1(\\Gamma(\\hat{y}_i), y_i) \\cdot p_{soft}(\\hat{y}_i, k, \\alpha)],$\nwhere\n$p_{soft} (\\hat{y}_i, k, \\alpha) = min \\Big(1, e^{\\frac{k-N(\\hat{y}_i)}{\\alpha}} \\Big).$\nIn the formula, the user-defined decay \u03b1 \u2265 0 can be consid-ered a sort of tolerance that controls how much the lengthimpacts the overall accuracy; the higher the value of \u03b1,the higher the tolerance for answers exceeding the speci-fied length k. Note that for \u03b1 = 0, SCA(k, 0) reduces toHCA(k).\nConsistent Concise Accuracy: CCA(k, \u03b1, \u03b2). It furthergeneralizes the previous metrics by also accounting for thevariation in the lengths among all the outputs obtained:\n$CCA(k, \\alpha, \\beta) = SCA(k, \\alpha) \\cdot p_{var}(\\sigma, \\beta)$\nwhere\n$p_{var}(\\sigma, \\beta) = min \\Big(1,e^{-\\frac{\\sigma}{\\beta}} \\Big).$\nIn Equation (6), \u03c3 denotes the standard deviation of theoutput length distribution, whereas \u03b2 is a parameter thatcontrols the tolerance for having large length variations; thehigher the value of \u03b2, the higher the tolerance. Note that,given a tolerance \u03b2, pvar(\u03c3, \u03b2) = 1 for \u03c3 < \u03b2, while itdecreases exponentially for \u03c3 > \u03b2.\nThe CCA metric aims to promote consistency in the lengthsof the responses. A low standard deviation o indicatesthat the model produces responses of uniform length. Incontrast, a high value of o denotes a model with a largeresponse variability, making predicting its timing responsetime difficult."}, {"title": "5. CCoT Prompting", "content": "From the results presented in Section 3, it is clear that therelationship between output length and inference time neces-sitates deeper awareness. To this end, this section focuses onimproving the use of CoT, aiming to preserve the benefits of"}, {"title": "6. Experiments", "content": "This section presents a set of experiments carried out to eval-uate the effectiveness of the the proposed CCoT approachunder classic metrics, as well as illustrate the benefits of theproposed metrics in evaluating a concise correctness. Specif-ically, the following research questions are investigated inthe next experiments:\n\u2022 RQ1. Is the CCoT approach beneficial in terms of effi-ciency and accuracy?\n\u2022 RQ2. Which models benefit from CCoT, compared toclassic CoT?\n\u2022 RQ3. How capable is an LLM of controlling the outputlength based on an explicit prompt request?\n\u2022 RQ4. Are the proposed metrics helpful in addressingboth efficiency and accuracy aspects? Is the impact ofCCoT reflected in the proposed metrics?\n6.1. Experimental Setup\nAll the experiments have been carried out with the TextGeneration Inference (TGI) platform\u00b2 on 8 NVIDIA A100GPUs. Specifically, we evaluated five publicly availablepre-trained LLMs from Hugging Face\u00b3, such as Vicuna-13b-v1.5 (Zheng et al., 2024), instruction-tuned models Falcon-40b-instruct, Falcon-7b-instruct (Almazrouei et al., 2023),and two models trained and reinforced by utilizing private"}, {"title": "6.2. Cost and performance evaluation of CCOT", "content": "This experiment was carried out to evaluate the impact ofCCoT on computation time and accuracy. Then, the resultswere used to provide insights on its suitability for variousLLM architectures.\nImpact of CCoT (RQ1). Each of the selected LLM wasevaluated on the GSM8K test dataset using plain prompt(base), CoT, and CCoT with different length constraints(namely, 15, 30, 45, 60, 100). The obtained results arereported in Figure 4. In particular, Figure 4a shows theimpact of the different prompt settings in terms of generationtime, while Figure 4b shows the corresponding accuracy."}, {"title": "On the effectiveness of CCoT prompting (RQ2)", "content": "Thedifferent effect of CCoT prompting on the output length andaccuracy illustrated in Figure 4 can be attributed to variousfactors, such as the training data, the approach used to trainthe model, the model size, and the technique adopted dur-ing training. For instance, Llama2-70b is an autoregressivelarge-scale language model fine-tuned with human feedback,trained on a diverse combination of generic and open-sourcedatasets. Such technical measures contribute to makingCCoT effective in controlling the output length while im-proving the model accuracy. The Falcon-40b model, incontrast, is smaller than Llama2-70b and trained on a differ-ent dataset (the dedicated RefinedWeb data (Penedo et al.,2023)). While CCoT does not improve the accuracy ofthe model with respect to CoT, it still performs better thanthe base plain prompting, offering a trade-off by reducinggeneration times compared to CoT. Vicuna-13b also pro-vides competitive results across different prompts, as it is afine-tuned version of Llama2 and smaller than the previousLlama2-70b.\nConversely, small-scale LLMs, such as Falcon-7b andLlama2-7b, are not capable of properly handling the con-strained prompting conditions in CCoT, resulting in highergeneration times (as shown for Falcon-7b with large lengthvalues in CCoT) or incorrect answers with short CCoT val-ues in Llama2-7b. This suggests that model size and trainingstrategies severely impact the effectiveness of CCoT.\nConsidering the observations presented above, we focused"}, {"title": "6.3. Ability to control the output length (RQ3", "content": "The previous experiments looked at how CCoT strategiescan affect the accuracy and generation time in the average.However, despite the discussed benefits, it is also crucialto understand how CCoT prompting can effectively limitthe output length for each addressed sample. This can beuseful for better tuning the length parameter in the CCoTprompt or identifying the conditions in which the proposedprompting strategy fails to compress the output.\nTo evaluate the ability of an LLM to produce concise an-swers in response to a given prompting approach, we an-alyzed the output length for each sample under differentCCoT length constraints. Figure 5 shows the statistics onthe length of the answers provided by three models (Vicuna-13b, Falcon-40b, and Llama2-70b) that were feeded with allthe inputs taken from the GSM8K test set, using differentprompt strategies (base, CoT, and CCoT). As done in theprevious experiment, the CCoT prompt was tested for dif-ferent length constraints (15,30,45,60,100). Each box plotrepresents the output lengths between the 5th and the 95thpercentiles of all tested samples, the blue line representsthe provided CCoT length constraint, the red line denotesthe median, while the greed dot the mean. Ideally, a modelrespecting the given length constraint for each tested sampleshould have the entire distribution below the blue line.\nAs clear from Figure 5, using CoT without an explicit lengthrequest produces lengthy answers that significantly impactthe generation time. The imposed length constraint in theCCoT prompt significantly affects the output length, al-though in practice LLMs are not always able to respect thegiven limit, especially for smaller values, such as 15, 30, or40, which are more challenging for an LLM.\nTo summarize, given the nature of the CCoT prompting, it isreasonable to consider a tolerance margin in respecting the"}, {"title": "6.4. Evaluation of the correct conciseness (RQ4", "content": "The metrics proposed in Section 4 are applied to assess thebenefit of CCoT from a new perspective, which considersboth the capability of the model to reduce the output lengthwhile maintaining a certain level of correctness.\nHCA evaluation. The Hard-k concise accuracy evaluatesthe accuracy considering only the correct answers whoselength is less than a specified value k. Figure 6 reports thevalue of this performance index achieved on Llama2-70b(Figure 6a) and Falcon-40b (Figure 6b), when using thedifferent prompt approaches and for different values of k.Please note, k = \u221e is equivalent to the classic accuracy.\nAs expected, the HCA values are always less than or equalto those related to the classic accuracy (k = \u221e), but such areduction is less pronounced under the application of CCoTprompting. Specifically, for Llama2-70b, the use of CCoTis beneficial with respect to base and CoT prompts, for allvalues of k, although the increase is more significant forvalues of k equal to 100, 80, and 60. This suggests that, ifthe length constraint is not too stringent, the capability ofthe model to produce correct answers is higher with CCoT.Conversely, for lower values of k, there is a strong reductionin performance for CoT prompts, mainly because they pushthe model to produce a reasoning part in the output withoutpaying attention to its length.\nSimilar considerations apply to Falcon-40b, where the ap-plication of CCoT yields a good trade-off between CoT andbase prompting. Note that the HCA values under CCoTget higher than those achieved under CoT, also for smallvalues of k (e.g., 60 and 40), meaning that CCoT promptingis effective for this model."}, {"title": "SCA evaluation.", "content": "We also evaluated the Llama2-70bmodel using the Soft Conciseness Accuracy (SCA), acrossdifferent k and a values, where a represents a tolerance foraccepting answers longer than the desired limit k. This met-ric is a generalization of the HCA, giving more flexibility inconsidering correct answers that are larger but still close tothe desired length k.\nThe SCA values computed for Llama2-70b and Falcon-40bon the questions of the GSM8K test set are reported inFigure 7 for different values of k and two different tolerancevalues (\u03b1 = 1 and a = 10). For both models, the SCAvalues in CCoT settings are often comparable to HCA valuesfor high values of k, such as 80 or 100. This is because,as shown in Figure 5, for these lengths, the CCOT promptsare effective at returning outputs below the desired limit,making the tolerance less necessary.\nConversely, for smaller k values, such as k = 40, SCAstarts exceeding HCA, indicating that some correct answershave a length greater than k. For these values of k, usinga larger a results in more pronounced improvements forCCoT prompts compared to Base and CoT. This meansthat, although many correct outputs are longer than k, underCCoT the model is still encouraged to constrain them closeto k, thus achieving a higher score. This effect is partic-ularly noticeable on Llama2-70b, which is more capableof controlling the length and produce correct outputs thanFalcon-40b."}, {"title": "CCA evaluation.", "content": "The Consistent Concise Accuracy mea-sures the capability of a model to generate correct answerswhose lengths do not vary significantly, and therefore areconsistent with the specified constraint. The CCA requires athird parameter \u03b2 (in addition to k and a), denoting a toler-ance on the output length variability. In particular, if o is thestandard deviation of the length distribution, we have that\n$CCA(k, \\alpha, \\beta) = SCA(k, \\alpha)$, if $\\sigma \\leq \\beta$, otherwise CCAdecreases exponentially for $\\sigma > \\beta$."}, {"title": "6.5. Illustration of CCOT", "content": "To better illustrate the benefits of CCoT, Figure 9 showsthe answers produced by Llama2-70b when applying base,CoT, and CCoT prompts (with length constraint of 15, 45,and 100) for two different questions taken from GSM8K.In both questions, we observe that in the base case, themodel automatically proposes a reasoning process due tothe characteristics of the model used (specifically Llama2-70B-chat). However, under CoT, the reasoning process isextended, loosing control of its length."}, {"title": "7. Discussion and Conclusions", "content": "This work discussed the importance of addressing the con-ciseness of the answers provided by LLMs in text-to-textgeneration tasks and investigated the possibility of control-ling the output length through a suitable prompt engineeringapproach, called Constrained Chain-of-Thought (CCoT).Then, the impact of CCoT on the generation time andthe correctness of the responses was evaluated consideringquestion-answer benchmarks, with respect to plain prompt-ing and CoT. To this end, three novel metrics have beenproposed to account for both conciseness and correctness ofthe output as a function of user-specified parameters. Sev-eral experiments were conducted to evaluate how differentLLMs are able to control conciseness while ensuring cor-rectness, and how they could benefit from more concisenessin terms of generation time.\nFrom the findings emerged by the conducted experiments,a first observation is that not all models are able to con-trol the length of their outputs (RQ2). In particular, smallmodels, as Falcon-7b, LLama2-7b, and Vicuna-13b, havemore difficulty in respecting the length constraints given inthe CCoT prompts, while larger models, as Falcon-40b andLlama2-70b, show a greater control capability (Section 6.2).Such a difficulty of smaller LLMs could be influenced byvarious factors, as the dataset used during training and thenumber of model parameters. Understanding these issuesand evaluating a possible integration of the proposed met-ric in a fine-tuning process requires a deeper investigation,which is part of our future work.\nOn the other hand, for larger models, such as Falcon-40b"}]}