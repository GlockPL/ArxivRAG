{"title": "Hybrid Firefly-Genetic Algorithm for Single and Multi-dimensional 0-1 Knapsack Problems", "authors": ["Aswathi Malanthara", "Ishaan R Kale"], "abstract": "This paper addresses the challenges faced by algorithms, such as the Firefly Algorithm (FA) and the Genetic Algorithm (GA), in constrained optimization problems. While both algorithms perform well for unconstrained problems, their effectiveness diminishes when constraints are introduced due to limitations in exploration, exploitation, and constraint handling. To overcome these challenges, a hybrid FAGA algorithm is proposed, combining the strengths of both algorithms. The hybrid algorithm is validated by solving unconstrained benchmark functions and constrained optimization problems, including design engineering problems and combinatorial problems such as the 0-1 Knapsack Problem. The proposed algorithm delivers improved solution accuracy and computational efficiency compared to conventional optimization algorithm. This paper outlines the development and structure of the hybrid algorithm and demonstrates its effectiveness in handling complex optimization problems.", "sections": [{"title": "1. Introduction", "content": "Nature-inspired optimization methods have become crucial techniques for solving complex optimization problems (Cheng et al., 2014) by leveraging principles from natural and biological systems. Heuristics approaches (Newell et al., 1958) use problem-specific, rule-based strategies. Whereas, metaheuristics approaches (Glover and Kochenberger, 2003) provide more flexible frameworks that adapt to various optimization tasks. Algorithms like Genetic Algorithm (GA) (Holland, 1975; Bernardino et al., 2007), which mimics natural phenomenon through selection, crossover, and mutation, are known for maintaining diversity, although might face challenges with longer time for convergence while not ensuring to reach the optimal solution. Particle Swarm Optimization (PSO) (Kennedy and Eberhart 1995; Datta and Figueira, 2011), based on the behavior of bird flocks, is known for fast convergence. However, it may become trapped in local optima if exploration is insufficient. Other algorithm includes, Ant Colony Optimization (ACO) (Dorigo et al., 1996), which simulates ant foraging and is particularly effective for discrete problems, however may become costly with larger datasets. Differential Evolution (DE) (Storn and Price, 1995; Karabo\u011fa and \u00d6kdem, 2004) models the process of evolutionary adaptation and is effective for continuous optimization, yet may require precise parameter adjustments. The Bat Algorithm (BA) (Yang 2010; Chakri et al., 2017), inspired by bat echolocation, offers versatility yet encounter difficulties in tuning its randomness. Harmony Search (HS) (Geem et al., 2001; Yang, 2009), draws from the concept of musical improvisation, is simple and effective although exhibit slow convergence on more complex problems. Cuckoo Search (CS) (Yang and Deb, 2009), which imitates the parasitic nesting or egg parasitism behavior of cuckoos, excels at global optimization, even so it struggles with convergence speed when constraints are high. The Firefly Algorithm (FA) (Yang, 2010; Gandomi et al., 2011), based on firefly bioluminescence, performs well in multimodal scenarios while face challenges like early convergence, balancing exploration and refinement. Simulated Annealing (SA) (Kirkpatrick et al, 1983), reflecting the physical process of annealing metals, is easy to implement though might be slow in high-dimensional spaces. These algorithms share common drawbacks, such as significant computational cost, parameter sensitivity, and potential for becoming trapped in local solution. They effectively manage non-linear and multi-modal problems. However, their unconstrained nature may limit their efficiency in constrained or combinatorial problems (Blum and Roli, 2003).\nHybrid algorithms in optimization integrate multiple algorithms to enhance performance by combining their strengths. The Genetic Algorithm-Tabu Search (GA-TS) hybrid algorithm (Lin et al., 2010) illustrates this integration by leveraging GA's broad search capabilities, including selection, crossover, and mutation, while Tabu Search (TS) performs local searches and uses a memory structure to avoid revisiting past solutions, promoting a balance between exploration and exploitation. Hybrid genetic algorithm and simulated annealing approach (GA-SA) (Li et al., 2002) explores a wide search space using GA, with simulated annealing refining solutions to avoid local optima. The PSO-GA algorithm (Garg, 2016) combines PSO's rapid global search, driven by particle movement and position updates, with GA's genetic operations to enhance optimization. Genetic algorithm - differential evolution (GA-DE) (Lin, 2011) integrates GA's exploration capabilities with DE's adaptive parameter control, achieving robust performance in global optimization. Despite these strengths, each hybrid algorithm has limitations: GA-TS faces challenges with high computational costs and complex coordination between algorithms; GA-SA demands significant computational resources due to the combination of two iterative methods; PSO-GA struggles with balancing exploration and exploitation, occasionally leading to premature convergence; and GA-DE faces challenges in parameter tuning, which impacts convergence speed and solution accuracy in some applications. The Ant Colony Optimization-Genetic Algorithm (ACO-GA) (Ghanbari et al., 2013) blends ACO's pheromone-based navigation with GA's genetic diversity from crossover operations, enhancing exploration and reducing early convergence risk. This approach is similar to Firefly and Particle swarm optimization (HFPSO) (Aydilek, 2018), which combines the global search ability of the FA with the local search and optimization strengths of PSO. The FA in HFPSO attracts particles toward brighter solutions, ensuring effective global search, while PSO guides particles based on their individual and collective experiences to refine the search locally. However, HFPSO lies in its computational cost, especially for large-scale or high-dimensional optimization problems, and its sensitivity to initial conditions due to the complex interaction between FA and PSO parameters, which impacts the balance between global exploration and local exploitation. The Hybrid Firefly algorithm and Harmony search (HS-FA) (Guo et al., 2013) combines the global exploration strength of the Firefly Algorithm with the local search power of Harmony Search, where FA explores the search space by moving toward brighter solutions, and HS refines these solutions by adjusting harmony memory and applying pitch adjustment operations. Although, HS-FA face the challenge of fine-tuning the harmony memory size and pitch adjustment parameters, leading to computational demands that increase with problem size and slow convergence in complex search spaces. The Imperialist competitive algorithm and Firefly algorithm (ICA-FA) (Chen et al., 2018) integrates the exploration power of the ICA with the FA search capabilities. ICA directs the search towards high-potential regions through imperialistic competition, while the FA intensifies the search around the best solutions by attracting to brighter solutions. ICA-FA lies in its reliance on imperialist competition, which results in premature convergence, particularly in multi-modal problems, with parameter dependencies complicating its implementation and fine-tuning. The Firefly Algorithm-Cuckoo Search (FA-CS) (Yang, 2014) hybrid combines the global random exploration of Cuckoo Search using Levy flights with the Firefly Algorithm's local search ability to enhance exploration while refining solutions in promising regions. However, the combination of both algorithms results in increased computational complexity and requires extensive parameter tuning. Overall, Hybrid algorithms improve performance over single-method algorithms, but they introduce challenges such as higher computational costs, parameter sensitivity, and complex implementation. Achieving optimal performance requires careful parameter tuning and balancing the strengths and weaknesses of the combined methods.\nThis paper introduces a hybrid algorithm that combines the FA (Yang, 2010; Gandomi et al., 2011) and the GA (Holland, 1975; Bernardino et al., 2007) to address complex real-world problems, such as the 0-1 Knapsack Problem, benchmark functions, and engineering design problems. An earlier approach (Nand and Sharma, 2019) segmented the optimization process into two phases: first, FA is used for global exploration in the first half, followed by GA for local refinement in the second half. While this approach achieved reasonable success in balancing global and local search strategies, it also had limitations, such as slower convergence rates and reduced solution diversity. These issues arose because FA and GA are executed independently in different stages, limiting their ability to fully complement each other. By operating in isolation, the algorithms could not leverage their respective strengths effectively throughout the entire optimization process. In contrast, the proposed hybrid algorithm integrates FA and GA in a simultaneous, continuous manner, allowing both to work together throughout the optimization process. This concurrent framework addresses the limitations of the earlier method by enabling FA to continuously refines the population. Whereas, GA enhance the population's exploration through selection, crossover, and mutation. This dynamic interaction helps maintain diversity and prevents premature convergence. The significant enhancement of the proposed algorithm is the seamless integration of FA's bioluminescence inspired movement with GA's genetic operations. Through which it guides the algorithm towards better diversity and more efficient solution refinement. This integration enables a balance exploration and exploitation over the optimization process, resulting in faster convergence and higher-quality solutions compare to previous methods. To evaluate the performance of the proposed algorithm, it is tested on a wide range of optimization problems. These include the benchmark optimization functions (Zhang et al., 2016; Qi et al., 2017), such as the Sphere function (unimodal function), the Ackley function, Rosenbrock's function, and the Rastrigin function (multimodal functions). These unconstrained functions are commonly used to test the performance of optimization algorithms. Additionally, the FAGA hybrid has been applied to real-world engineering design optimization problems (Kale and Kulkarni, 2018; Kale and Kulkarni, 2021), including the helical spring design problem, pressure vessel optimization, cantilever beam optimization, gear train ratio, and I-beam vertical deflection. These problems involve both continuous and discrete variables, making them highly suitable for testing the versatility and robustness of the proposed algorithm. Furthermore, the 0-1 Knapsack Problems (Beasley and John, 1990; Kulkarni and Shabir, 2016; Poonawala et al., 2024), examples of combinatorial optimization, are also addressed. The SKP (Single Knapsack Problem) involves selecting a subset of items to maximize the total value without exceeding a given weight limit, while the MKP (Multidimensional Knapsack Problem) introduces additional constraints by increasing the number of knapsacks, making the problem significantly more complex. These types of problems are crucial in areas like cargo loading, financial investment planning, and resource allocation, where multiple constraints must be satisfied simultaneously. The results demonstrate that the proposed FAGA hybrid consistently outperforms, matches, or achieves near-optimal performance, both in terms of solution quality and convergence speed.\nThe paper is organized as follows: Sect. 2 introduces the basic principles and mathematical formulation of the FA, along with its characteristics and pseudo code. In Sect. 3, described GA's evolutionary operators, pseudo code, and characteristic ability to maintain diversity during the search process. The hybrid FAGA algorithm is proposed in Sect. 4, where the integration of FA and GA is explained along with its flowchart. In Sect. 5, explanation about integration of static penalty function to handle constraint violations. In Sect. 6, the significance and formulation of the 0-1 Knapsack Problem are presented, focusing on maximizing profit while staying within weight limits. The methodology employed by FAGA to solve the 0-1 Knapsack problem is detailed, showing how FA's exploration is combined with GA's crossover and mutation strategies, along with a flowchart In Sect. 7, various optimization problems are solved, including benchmark functions, design engineering problems, and the 0-1 single and multidimensional knapsack problems using the FAGA algorithm. A statistical analysis of the FAGA algorithm, along with a comparison to other algorithms, is presented to evaluate its performance, accompanied by its convergence graphs. The list of 0-1 SKP test cases is provided in the \"Appendix\" at the end of the paper."}, {"title": "2. Firefly Algorithm (FA)", "content": "The Firefly Algorithm (Yang, 2010; Gandomi et al., 2011), introduced by Xin-She Yang, is a nature-inspired metaheuristic that draws on the principles of swarm intelligence. The algorithm is influenced by the behavior of fireflies, using randomization to search for a set of solutions, and is thus classified as a stochastic algorithm. The flashing behavior of fireflies is modeled as a mechanism to attract prey or mates. The fitness or intensity represents the brightness of a solution; a firefly is considered brighter when it has a better solution compared to others. Less bright fireflies move toward the brighter ones, helping them move in the direction of a better solution in the search space.\nAdditionally, distance plays a major role, as the attractiveness between fireflies decreases with increasing distance. This is crucial in determining the level of attraction one firefly has towards another. The pseudo code of the FA is presented in Fig. 1. Following are the characteristics of Firefly Algorithm:\n(1) Fireflies are drawn to each other without regard to gender, as they are unisex.\n(2) The level of attractiveness increases with the intensity of brightness.\n(3) Fireflies will move toward the brighter ones, however if no other firefly is brighter or if brightness levels are equal, they will move randomly.\n(4) Attractiveness diminishes with increasing distance, meaning it is inversely related to the distance between fireflies.\nThe FA is mathematically expressed as follows:\nStep 1: Consider a population consisting of n fireflies, where each firefly $x_i$ (for i = 1, 2, ..., n) is defined by a vector of decision variables representing its position in the search space. Initially, the positions of the fireflies are generated randomly within specified lower (lb) and upper (ub) bounds. The initial position of each firefly is given by:\n$X_n = lb + (ub \u2013 lb) \u00d7 rand(1, M),$ (2.1)\nwhere, M denotes the number of decision variables for each firefly. This equation ensures that each firefly starts at a valid location in the search space, effectively initializing their positions based on the specified boundaries.\nStep 2: After initializing the n fireflies, the $f(X_n)$ for each firefly is calculated. The algorithm then determines the current best fitness value among all the fireflies in the population.\nStep 3: Each firefly i is compared with every other firefly j in the population based on intensity. If firefly i has a higher intensity than firefly j, no change occurs, and it moves to the next firefly However, if firefly j has a greater intensity, indicating a better solution, firefly i moves toward firefly j. The movement of firefly i towards firefly j is influenced by three key factors: attractiveness, randomness, and distance. These factors combine to guide the firefly's movement and position update. The movement equation is formulated as follows:\n$X_{inew} = X_i + B_0e^{-y r_{i}.}(X_j \u2013 X_i) + a(rand \u2013 0.5),$ (2.2)\nwhere,\n$B_0$ is the highest possible attraction when the distance between fireflies is zero,"}, {"title": null, "content": "$\\alpha$ is the randomization parameter, regulating the amount of randomness in the movement\n$\\gamma$ is the light absorption coefficient, which controls how quickly attractiveness diminishes with distance,\n$r_{ij} = |X_i - X_j| = \\sqrt{\\sum_{k=1}^M (X_{ik} - X_{jk})^2},$ (2.3)\nis the Euclidean distance between firefly $i$ and firefly $j$,\nrand is a random vector with values between 0 and 1,\n$X_i$ and $X_j$ are the current positions of firefly i and firefly j, respectively.\nThis equation updates the position of firefly i by moving it towards the brighter firefly j, while the random component helps to avoid being trapped in local minima.\nStep 4: The algorithm halts if there has been no improvement in the best solution over a defined number of iterations. The termination condition is also based on reaching the maximum number of iterations, max_iter.\nThe FA (Yang, 2010; Gandomi et al., 2011) is successfully validated on various continuous, discrete, and mixed-variable optimization problems. It had been widely applied in design engineering problems, multi-modal optimization, and structural optimization problems. It is observed that the convergence rate of the FA varies depending on the complexity of the problem and the parameters chosen, such as attractiveness, randomness and absorption coefficient. In the standard FA, the brightest firefly moves randomly, which may lead to a decrease in brightness depending on the direction. As a result, the performance of the algorithm diminishes. Furthermore, researchers had proposed various enhancements to the FA, leading to better performance and faster convergence. One such modification is the Modified Firefly Algorithm (MFA) (Yelghi et al., 2018), which integrates adaptive mechanisms where the brightest firefly moves only in a direction that improves its brightness. This helps fireflies explore the search space efficiently and avoids premature convergence. The MFA has been successfully validated by solving test problems that include multimodal, unimodal, stochastic, continuous and discontinuous benchmark problems."}, {"title": "3. Genetic Algorithm (GA)", "content": "The Genetic Algorithm (Holland, 1975; Bernardino et al., 2007), proposed by John Holland, is an adaptive metaheuristic algorithm inspired by the principles of natural selection. In this algorithm, Selection process is typically probabilistic, favoring individuals with higher fitness. Further, Selected individual undergo mating, where recombination of the genetic information of two parents creates new, better offspring that inherits beneficial characteristics from the parents. The child having the certain characteristics of both parents, is mutate to introduce variability and diversity, which help to enhance a broader exploration of the search space, ensuring to reach optimal solution across a range of possibilities. The pseudo code of the GA is presented in Fig. 2. Following are the characteristics of GA:\n1) Genetic Algorithms operate on group of potential solutions rather than single solutions while simultaneously exploring multiple points in the search space.\n2) Individuals are evaluated using a fitness function, and the best performing solutions are selected for reproduction.\n3) Crossover combines genes from two parents to create child, while mutation integrate random changes. This ensures diversity and exploration.\nThe GA is mathematically expressed as follows:\nStep 1: An initial population of n individuals, denoted as $x_i$ (for i = 1, 2, ..., n), is generated randomly within the defined search space. Each individual is represented by a set of decision variables, and their initial positions are established using the same formula as shown in Equation (2.1).\nStep 2: The fitness or objective function $f(X_n)$ is computed for each individual in the population to evaluate their performance in the optimization process.\nStep 3: Parents are selected using the Tournament Selection method. A predefined number of individuals, referred to as the tournament size T, are randomly chosen from the population. The individual with the highest fitness within this group is selected as a parent. It is mathematically expressed as:\n$P_{winner} = arg_{i \\in Tournament} max f (x_i),$ (3.1)\nWhere $P_{winner}$ represents the chosen parent, Tournament is the set of randomly selected individuals, and $f(x_i)$ is the fitness of individual i. This process is repeated until the required number of parents is selected for crossover.\nStep 4: Crossover is performed based on the defined crossover rate. Two parents, $p_1$ and $p_2$, are chosen to create offspring. The children are generated using crossover points, which is mathematically represented as:\n$c = a.p_1 + (1 \u2212 a). p_2,$ (3.2)\nwhere a is a mixing parameter ranging from 0 to 1. If the offspring's fitness is superior to that of its parents, the child is kept; otherwise, the parents are retained for the next generation.\nStep 5: A mutation process is conducted according to the specified mutation rate. Individuals are randomly selected, and a mutation operator is applied to introduce variation into the population. For Gaussian mutation, this is be expressed as:\n$x = x_i + \u039d(0, \u03c3),$ (3.3)\nWhere N(0, \u03c3) denotes a random value sampled from a normal distribution with mean 0 and standard deviation \u03c3, influencing the mutation strength.\nStep 6: The fitness of the new population is compared to that of the previous population. If the new fitness values show improvement, the new population is accepted; if not, the original population is retained.\nStep 7: If no significant changes are observed, it suggests that the solution has stabilized, and the fitness of the original population is accepted, resulting in termination of the algorithm. If changes continue to be evident, the process loops back to Step 2 for further iterations."}, {"title": null, "content": "GA (Holland, 1975; Bernardino et al., 2007) had proven to be an effective method for solving real-world optimization challenges. GA maintains population diversity exploration to prevent the loss of relevant information, resulting in a balanced search. GA performs well as a global search method; it may take time to converge and may not guarantee to reach optimal solution. Further, GA was enhanced by integrating it with two gradient descent (GD)-based algorithms (Ruder, 2016), leading to the development of the Gradient-based Genetic Algorithm (GGA) (D'Angelo et al., 2021). This algorithm has the capability to identify the optimal solution with fewer generations and individuals. The basic idea involves leveraging GD's capabilities to refine local solutions and employing them as more favorable starting points. This approach enables GGA to escape local optima and progressively converge toward the global solution. The GGA has been successfully validated by solving test functions characterized by multi-modality, flatness, and convexity, as well as in addressing a real-world use case: the welded beam design problem."}, {"title": "4. Framework of FAGA", "content": "The standard Firefly Algorithm (FA) has been validated across a diverse array of optimization problems. However, it faces several limitations, such as an imbalance between exploration and exploitation, reduced local convergence when the randomization factor is high, and a tendency to fail in finding the optimal solution due to limited local and global search capabilities. To address these issues, key characteristics of the Genetic Algorithm (GA) are integrated into the FA. The GA helps to balance exploration and exploitation by generating diverse solutions. Essential GA operators - Selection, Crossover, and Mutation are incorporated into the FA to enhance local search and convergence. In the FAGA framework (refer to Fig. 3), the FA primarily facilitates global search, where fireflies are attracted to those with higher intensities (better solutions), while the GA introduces genetic diversity through crossover and mutation. This integration enhances the learning ability of the FA. The FAGA is mathematically outlined as follows:\nStep 1: Consider a population of N individuals, where each individual n (for n = 1,2, ..., N) is characterized by a set of decision variables $X_n = (x^,x^2, ..., x_m)$, representing the individual's position in the search space. The intensity of each individual is calculated based on an objective function f(X). The initial position of each individual is randomly generated within the specified lower (lb) and upper (ub) bounds, using the same approach as shown in equation (2.1).\nStep 2: Each firefly is compared with every other firefly in the population. If the intensity of firefly i is better than that of firefly j, no movement occurs, and firefly i proceeds to next firefly. However, if firefly j has a higher intensity (better solution) than firefly i, firefly i will move towards firefly j. The movement of firefly i towards fireflyj is influenced by three key factors: attractiveness, randomness, and distance. The movement equation is formulated as shown in equation (2.2).\nStep 3: Once all comparisons are complete, the intensities $f (X_n)$ of the fireflies updated positions are calculated, resulting in the generation of a new population of fireflies.\nStep 4: After generating the new population and calculating their fitness, the best-performing individuals are selected using tournament selection, as described in equation (3.1), for crossover. The crossover rate is maintained between 60% and 90% to ensure diversity. For two selected parents, $p_1$ and $p_2$, crossover is executed by combining their characteristics to create a child c. This crossover operation is mathematically represented in equation (3.2). After crossover, the fitness $f(X)$ of each child is evaluated. If the child's intensity surpasses that of its parents, the child proceeds to mutation; otherwise, the original individuals are retained.\nStep 5: Following crossover, a mutation rate of 1-10% is applied to mutate individuals. During mutation, some attributes are altered to enhance diversity in the population. Gaussian mutation is employed, as represented in equation (3.3). The mutated child then replaces the worst-performing individual in the population. The intensity of the new individual is calculated, and the top solutions are carried over to the next iteration.\nStep 6: The algorithm terminates when there is no further change in the solution, indicating stagnation, or when the termination criteria (number of iterations) are met.\nTo validate the proposed FAGA algorithm, the problems considered here are sourced from the design engineering (Kale and Kulkarni, 2018; Kale and Kulkarni, 2021), non-linear test problems (Zhang et al., 2016), Single Knapsack Problem (Kulkarni and Shabir, 2016) and Multidimensional Knapsack Problem (Poonawala et al., 2024). The FAGA algorithms are implemented in Python 3, and simulations are conducted on a Windows platform. Additionally, each individual problems are run 30 times to ensure robustness. The solutions obtained from the proposed algorithm, along with comparisons to existing algorithms, are discussed in Sect 7."}, {"title": "5. Static Penalty Function (SPF)", "content": "In a constrained optimization problem (Li et al., 2011; Yu et al., 2010), the objective is to minimize or maximize a function:\n$f(X) = (x_1, x_2,..., x_n)$ (5.1)\nSubject to a set of constraints, which may include both inequality and equality constraints:"}, {"title": null, "content": "$g_i(X) \u2264 0, i = 1,2,..., m$ (5.2)\n$h_j(X) = 0, j = 1,2,..., p$ (5.3)\nwhere:\n$g_i(X)$ are the inequality constraints,\n$h_j(X)$ are the equality constraints."}, {"title": null, "content": "To handle constraint violations, a Static Penalty Function (SPF) approach (Kale and Kulkarni, 2021) is commonly used. This approach adds a penalty term, PF, to the objective function to discourage violations of both inequality and equality constraints. The penalty function is defined as:"}, {"title": null, "content": "$PF = \u0398 \u00d7 (\\sum_{i=1}^m g_i(X) + \\sum_{j=1}^p h_j(X))$ (5.4)\nwhere:\n@ is a constant penalty parameter that controls the intensity of the penalty,\n$( \\sum_{i=1}^m g_i(X) + \\sum_{j=1}^p h_j(X))$ is summation of violated constraints.\nIn this formulation, if all constraints are satisfied, both terms in the summation will be zero, resulting in no penalty. However, if there are violations, the penalty PF increases in proportion to the degree of violation.\nThe penalized objective function is then given by:\n$(X) = f(X) + PF$ (5.5)\nwhere $(X)$ represents the objective function adjusted with the penalty term. This penalized objective function guides the optimization process by imposing a high cost for constraint violations, thereby encouraging feasible solutions that satisfy both the inequality and equality constraints."}, {"title": "6. 0-1 Knapsack Problem", "content": "The 0-1 Knapsack Problem (KP) (Martello and Toth, 1990; Poonawala et al., 2024; Kulkarni and Shabir, 2016) is a well-known combinatorial optimization problem where the objective is to select items with the maximum possible value without exceeding a given weight limit. Each item either be chosen (1) or drop (0), which gives the problem its \"0-1\" nature. The KP is categories into the Single Knapsack Problem (SKP), which involves a single knapsack, and the Multidimensional Knapsack Problem (MKP), where multiple constraints are present, such as different weight or size limits. The 0-1 KP has both theoretical and practical significance, with applications in areas like resource allocation, finance, and logistics. In this paper, different variations of the 0-1 knapsack problem are solved by the proposed algorithm. The performance of the FAGA hybrid algorithm is evaluated by examining solution accuracy, convergence speed, and robustness. 0-1 Knapsack problem formulation and the methodology for solving using the FAGA hybrid are illustrated in the following sections."}, {"title": "6.1 Problem Formulation", "content": "The 0-1 Knapsack Problem involves selecting a subset of items, each having a specific weight $W_i$ and profit $v_i$, with the goal of maximizing the total profit while ensuring that the total weight does not exceed the knapsack's capacity. The task is to identify which items to include so that the total weight stays within the allowed limit, and the combined profit is as high as possible. Various versions of the 0-1 Knapsack Problem exist, where each item is either included in the knapsack ($x_i$ = 1) or excluded ($x_i$= 0). The mathematical formulation for this problem is:\n$Maximize Z = \\sum_{i=1}^n v_i x_i$ (6.1.1)\nsubject to $\\sum_{i=1}^n W_i x_i \u2264 W, x_i \u2208 { 0, 1}, \u2200i= 1, ..., n$ (6.1.2)\nwhere,\nZ represents the total profit to be maximized.\n$v_i$ is the profit of item i.\n$w_i$ is the weight of item i.\n$x_i$ is a binary decision variable\nW is the maximum capacity of the knapsack."}, {"title": null, "content": "The objective is to maximize the total profit Z, subject to the constraint that the total weight of the selected items does not exceed W. Each item is either included or excluded from the solution, reflecting the binary nature of the problem.\nThe Multidimensional Knapsack Problem (MKP) extends this formulation by involving multiple knapsacks, each with its own capacity, where the goal is to distribute the items across several knapsacks while maximizing the overall profit and adhering to the capacity constraints of each knapsack."}, {"title": "6.2 Methodology to solve 0-1 Knapsack Problem using FAGA", "content": "The hybrid approach combining the FA and GA effectively optimizes item selection for maximum profit while ensuring that weight constraints are not violated. In this method, each firefly symbolizes a potential solution which is represented as a binary vector that indicates whether an item is selected. Fireflies are attracted to brighter (maximum) values, with their movement directed toward these solutions during iterations. The brightness is based on the fitness of the solution, which, in this case, is the total profit relative to the knapsack's capacity. The FA emphasizes local search by refining promising solutions while still exploring new areas randomly to enhance the selection process. On the other hand, the GA evolves a population of potential solutions through selection, crossover, and mutation. Selection favors the fittest individuals for reproduction, crossover combines the genetic material of parent solutions to create new offspring, and mutation introduces diversity by randomly altering item selections, which prevents stagnation in local optima. By integrating these methodologies, the hybrid FAGA approach harnesses FA's strength in local optimization and GA's ability for broader exploration, allowing for an efficient search for near-optimal solutions to the 0-1 Knapsack Problem while balancing exploration and exploitation. Detail explanation is shown in Fig 4 and mathematically is expressed as follows:\nStep 1: Each individual in the population represents a solution to the knapsack problem, where an individual is a binary vector $x = [x_1, x_2, ..., x_n]$ with $x_i$ = 1 if the item is selected and $x_i$ = 0 otherwise. The size of the population, N, is predefined, and each solution vector is initialized randomly as:\n$x_i = round(lb_i + rand(N) \u00d7 (ub_i \u2013 lb_i))$ (6.2.1)\nWhere:\n$lb_i$ and $ub_i$ are the lower and upper bounds, respectively (typically lb = 0 and ub = 1 for the 0-1 Knapsack problem).\nrand(N) generates random numbers between 0 and 1, ensuring diversity in the initial population.\nStep 2: The sorting of items is based on their profit-to-weight ratio to prioritize more valuable items. After sorting, each item's value is normalized: if the item's value after sorting is less than 0.5, it is set to 0 (unselected); if greater than or equal to 0.5, it is set to 1 (selected). The normalization for a fitness value $f(x_i)$ of an individual is done by scaling the fitness to arrange between 0 and 1. This is mathematically expressed as:\n$f_{norm}(x_i) = \\frac{f(x_i)-f_{min}}{f_{max}-f_{min}}$ (6.2.2)\nWhere:\n$x_i =$ 1 if $x_i \u2265 0.5$  0 if $x_i < 0.5$ (6.2.3)\nHere, $f_{min}$ and $f_{max}$ are the minimum and maximum fitness values in the population, and $x_i$ is the normalized selection for item i."}, {"title": null, "content": "Step 3: The fitness function for each individual is calculated based on the profit and weight of selected items. If the total weight exceeds the knapsack capacity W, a penalty is applied. The fitness function f(x) is defined as:\n$f(x) = \\sum p_i x_i \u00d7 (\u0398 \u00d7 max(0, \\sum w_i x_i \u2013 W))$ (6.2.4)\nWhere:\n$p_i$ is the profit of item i,\n$w_i$ is the weight of item i,\nW is the knapsack capacity,\n\u0398 is the static penalty parameter."}, {"title": null, "content": "Step 4: In the Firefly Algorithm (FA), each individual (firefly) is attracted to brighter (maximum) fireflies. The movement of a firefly i towards a more attractive firefly is governed by the equation (2.2).\nStep 5: After the firefly movement, two individuals (parents) are selected randomly for crossover to produce child. A one-point crossover is performed where a random crossover point is chosen, and the genes are swapped between parents to create the child:\n$Child = Parent1[: crossoverpoint] + Parent2[crossoverpoint:]$ (6.2.5)\nIf the child solution has better fitness than both parents, the child is kept; otherwise, the parents are retained.\nStep 6: Mutation is applied to the solution returned from the crossover step. A small mutation probability $P_{mut}$ is used to flip some of the bits (change 0 to 1 or 1 to 0) in the binary solution. This helps introduce diversity and prevents premature convergence. And it is expressed as:\n$x'_i = $ 1-x_i if $random() < P_{mut}$ x_i otherwise (6.2.6)\nWhere $x_i$ is the mutated value.\nStep 7: The algorithm iterates over the steps of FA movement, GA crossover, and mutation until a predefined stopping criterion is met. This criterion is a fixed number of iterations or converges to an optimal solution."}, {"title": "7. Results and discussion", "content": "The FAGA algorithm is applied to solve four nonlinear benchmark test problems (Zhang et al., 2016; Qi et al., 2017), including both convex"}]}