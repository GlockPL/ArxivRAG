{"title": "Poetry2Image: An Iterative Correction Framework for Images Generated from Chinese Classical Poetry", "authors": ["Jing Jiang", "Yiran Ling", "Binzhu Li", "Pengxiang Li", "Junming Piao", "Yu Zhang"], "abstract": "Text-to-image generation models often struggle with key element loss or semantic confusion in tasks involving Chinese classical poetry. Addressing this issue through fine-tuning models needs considerable training costs. Additionally, manual prompts for re-diffusion adjustments need professional knowledge. To solve this problem, we propose Poetry2Image, an iterative correction framework for images generated from Chinese classical poetry. Utilizing an external poetry dataset, Poetry2Image establishes an automated feedback and correction loop, which enhances the alignment between poetry and image through image generation models and subsequent re-diffusion modifications suggested by large language models (LLM). Using a test set of 200 sentences of Chinese classical poetry, the proposed method-when integrated with five popular image generation models-achieves an average element completeness of 70.63%, representing an improvement of 25.56% over direct image generation. In tests of semantic correctness, our method attains an average semantic consistency of 80.09%. The study not only promotes the dissemination of ancient poetry culture but also offers a reference for similar non-fine-tuning methods to enhance LLM generation.", "sections": [{"title": "1 Introduction", "content": "Text-to-image generation combines natural language understanding with image generation models, which synthesize realistic images conditioned on natural language descriptions. When text-to-image generation models deal with prompts requiring professional knowledge, such as Chinese classical poetry, they are prone to losing key elements or causing semantic confusion. It is challenging to accurately describe the precise meaning of poetry as illustrated in Fig. 1."}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 Text-to-Image Generation", "content": "Text-to-image generation is the task of synthesizing images conditioned on natural language prompts. Recent advancements in diffusion models have significantly improved the quality of text-to-image generation, such as Dreambooth and DALL-E 3. Despite their impressive visual quality, these models struggle with complex prompts, which tend to generate images lacking core semantic elements and cause semantic confusion. Some recent studies incorporate bounding boxes as conditional controls to the diffusion process. Several recent papers leverage image understanding feedback, which builds a general-purpose reward model to refine diffusion models for text-image alignment. Despite their progress, there are two limitations in handling image generation with complex prompts: (i) open-loop generation in a single iteration cannot guarantee the alignment between generated images and prompts; (ii) these methods result in additional training costs. To address these issues, we introduce a training-free cyclic self-correction framework to enhance the alignment of images with complex prompts."}, {"title": "2.2 Text-Guided Image Editing", "content": "Text-guided image editing synthesizes images from a given image and text descriptions. Classic image editing aims at fine-grained manipulation by in-painting masked regions while keeping the remaining areas. Studies show that using user-generated masks for spatial editing in image generation is a straight-forward yet effective method. Another method focuses on predicted masks for spatial editing, demonstrating that manipulating image-text cross-attention masks is also effective. Evolved from spatial editing, text-guided image editing accepts direct commands, allowing editing without regional masks. Despite some progress, these works mainly focus on diffusion models but often suffer from complicated prompts or image understanding. Recent advancements have demonstrated the capabilities of incor-"}, {"title": "3 Method", "content": "In this section, we introduce the iterative correction framework for poetry generation, as shown in Fig. 2. Compared to common texts, poetry is semantically implicit. Firstly, the implicit semantic elements should be extracted. Secondly, an image semantic error correction mechanism should be established to alleviate potential semantic inconsistencies in the images."}, {"title": "3.1 Extract Implicit Semantics Based on LLM", "content": "Dataset construction should consider the meanings of poems, completeness of translation annotations, and cultural popularity. We consider rhetorical techniques involved in literature with semantic implicit features such as metaphor, personification, hyperbole, and allusion. Then, we allocate 200 well-known sentences with their modern Chinese translations, keyword annotations, and phrase explanations from the largest public platform of Chinese classical poetry, GuShiWen.com\u00b9."}, {"title": "Algorithm 1 Key Elements Extraction", "content": "Input: Poetry p; Poetry Database S\n1: dmin \u2190 0\n2: Pfind = \u00d8 // Query list initialization\n3: for i = 1 to N do\n4:\td = Fsimularity(p, S[i])\n5:\tif d < dmin then\n6:\t\tdmin \u2190 d\n7:\t\tPfind.append(S[i])\n8:\tend if\n9: end for\n10: tfind = FTranslation (Pfind)\n11: Nfind = FAnnotation(Pfind)\n12: Ekey = LLMextract(Pfind, t find, N find)\n13: Initial image: Porigin = Diff (t find)\nOutput: Key elements Ekey; Initial image Porigin\nData extension involves processing the dataset to match the input features required for detection and ensuring generality for prompts from different image generation models. Key elements of the poetry are extracted along with their translations, appreciations, and annotations, to facilitate monitoring of the elements completeness in the generated images. To automate the extraction process and achieve high extraction accuracy, we use GPT-4 for key element extraction, and design prompts for the LLM, as illustrated in Fig. 3."}, {"title": "3.2 Automated Iterative Correction Framework", "content": "Initial image generation focuses on using translations of poetry as inputs for generating images instead of original poems. This approach ensures the images accurately reflect the poems' meanings, avoiding ambiguities caused by historical linguistic changes and complex rhetorical devices such as metaphors and personifications.\nDetecting and correction involves identifying where the key elements of the image are located. We use the Open Vocabulary Detector (OVD), an open-source recognition method based on an open corpus, to build the front part of our image correction component. The input to this part includes the initial generated images, and the recognition labels derived. After the OVD performs these extractions, feedback suggestions on the bounding boxes is generated, which will be transmitted to LLM for analysis in the form of labels and region annotations, as illustrated in Fig. 4. The LLM suggester provides modification suggestions and proposes a new box for the image elements. The extracted elements need to be compared with the labels of the elements in the bounding box to detect whether complete and correct elements are in the initial generation of the diagram. Algorithm 2 shows the procedure in detail."}, {"title": "Algorithm 2 Image Feedback Correction", "content": "Input: Key elements Ekey; Initial image Porigin\n1: key elements detection: E' \u2190 0\n2: Pfeedback\u2190 Porigin\n3: while E' \u2260 Ekey do\n4:\tL' = OVD(Pfeedback)\n5:\tL\" = LLMsuggester (L', Ekey)\n6:\tL'\" = LLMtransform(L\")\n7:\tPfeedback = Diff(L'\")\n8:\tE' \u2190 OVD(Pfeedback)\n9: end while\n10: return Pout \u2190 Pfeedback\nOutput: Final generated image Pout\nL represents a list of intermediate calculation results. E represents a list of key elements in the semantics of poetry.\nFor all the bounding boxes in the image, the element labels are compared with the results from the LLM Extractor to determine whether a bounding box need to be retained or modified. This is discussed in the following scenarios:\n1. Retain: Keep the bounding box unchanged if it is included in the LLM Extractor's result, which is key elements.\n2. Remove: Delete the bounding box based on the LLM analysis of the poetic imagery.\n3. Add: If an key element from the LLM Extractor's result is missing in the current generated image, the LLM selects a new rectangular area and adds the missing key element label based on the poetry translation."}, {"title": "4 Experiment", "content": ""}, {"title": "4.1 Key Elements Extraction", "content": "In our image generation process, the initial stage uses LLM Extractor to semantically extract key elements from the database corpus. The accuracy of LLM Extractor is crucial to the subsequent process and needs to be evaluated in detail.\nSettings. We select a dataset of 200 Chinese poems with implicit semantics and manually annotated them to establish a benchmark for element extraction. The poems are then processed using five LLMs: GPT-4-Turbo, GPT-3.5-Turbo, Claude-3, GLM-4, and"}, {"title": "4.2 Verification of Self-Correcting Cycles Across Different Generation Models", "content": "Settings. We evaluate our image error correction method using elemental completeness and semantic consistency. Poetry2image is applied to five text-to-image generation models to validate the effect: DALL-E-3, CogView3, Midjourney, Wenxin Yige, and Stable Diffusion. Each model is assessed using a dataset of 200 Chinese poems with complex semantics, as shown in Fig. 5. Utilizing Open-vocabulary Detector OWL-ViT v2, we quantify key elements in both the initial and corrected images to determine elemental completeness. Employing BERT-Chinese, we measure semantic consistency by comparing the image content with the corresponding translation.\nResult. The full-process evaluation results are shown in Tab. 2. In the key elemental completeness test, Peotry2Image achieved an accuracy improvement ranging from 17.59% to 33.87%. Moreover, the elemental completeness of DALL-E has reached 90.20%, demonstrating good performance. In the semantic correctness test, the average semantic consistency reached 81.64%. Peotry2Image maintained stability in semantic consistency, indicating that it meets the standards for consistency between image content and poem sentiment. This stability also suggests that the improvement in image quality primarily results from enhanced element integrity."}, {"title": "4.3 Comparison of Iteration Rounds", "content": "Settings. To ensure the improvement in elemental completeness and ascertain the maximum efficacy of our method, we conduct an iterative comparison experiment. Observation points are established within the automated process, sequentially recording improvements in elemental completeness as the number of image iteration rounds increased."}, {"title": "arg maxs,e \u03b1(s)+\u03b2(e)\u03b1 + \u03b2", "content": "arg maxs,e \u03b1(s)+\u03b2(e)\u03b1 + \u03b2(1) is the quantitative measure for assessing generated images of ancient poems, considering semantic features s and key elements e, with upper thresholds se and ee respectively. Linear parameters \u03b1 and \u03b2 dictate the focus: \u03b2 = 0 evaluates semantic compliance, while \u03b1 = 0 evaluates key elemental completeness."}, {"title": "4.4 Ablation Experiment", "content": "Settings. In order to verify the effect of the initial generation on correction, we perform an ablation experiment, removing additional information such"}, {"title": "5 Discussion", "content": ""}, {"title": "5.1 The Influence of the Number of Key Elements in Poetry", "content": "To evaluate the performance of Poetry2Image in processing Chinese classical poetry with different numbers of key elements, we design a series of experiments and use elemental completeness as the evaluation indicator.\nThe experimental results, as illustrated in Tab. 5, indicate that with fewer key elements, such as 3, the initial generation covers most elements, resulting in minimal improvement in overall elemental completeness. As the number of key elements increases, the initial generation's missing rate escalates. However, Poetry2Image compensates for this by completing elements more rapidly than they are missed, resulting in a 15% to 20% improvement in elemental completeness. Specifically, for information-intensive poems containing up to six elements, the elemental completeness improvement rate reaches 23.73%. This demonstrates Poetry2Image's efficacy in improving elemental completeness. However, when the number of elements exceeds seven, the image fails to achieve the desired elemental completeness, posing a challenge in balancing the aesthetics of the image with the improvement of elemental completeness."}, {"title": "5.2 The Influence of Poetry Language Types", "content": "To further assess the generalizability and applicability of Poetry2Image, we extended its application to multilingual poetry. We test Poetry2Image on 100 classical Japanese and English poems representing diverse linguistic and cultural backgrounds.\nThe results, as detailed in Appendix A, demonstrate that our method is effective not only with Chinese classical poetry but also with Japanese and English poetry.This confirms the wide applicability"}, {"title": "6 Limitations", "content": "The limitations of Poetry2Image stem from the intrinsic characteristics of poetry, as illustrated in Fig. 6. The poems corresponding to the images can be found in Appendix B. When the genre of the poem is lyrical or didactic, the key elements in the sentence are scarce or abstract, so both the initial image and the corrected image fail to capture the key elements used for generation, leading to unsatisfactory correction results. In addition, when dealing with proper nouns such as historical personal names (e.g. 'Zhou Yu') in the poems, the elements cannot be recognized and understood by the OVD and diffusion models, resulting in suboptimal correction results."}, {"title": "7 Conclusion", "content": "We propose Poetry2Image, an iterative correction framework that integrates image generation, error correction and feedback. This framework enhances image generation quality for specialized texts like Chinese classical poetry and addresses core issues such as element loss and semantic confusion. Our method is adept at element-rich or multi-lingual poems and is compatible with other image generation models.Additionally, our approach provides a reference for similar non-fine-tuning methods to enhance LLM generation."}]}