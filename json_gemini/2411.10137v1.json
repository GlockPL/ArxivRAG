{"title": "Legal Evalutions and Challenges of Large Language Models", "authors": ["Jiaqi Wang", "Huan Zhao", "Zhenyuan Yang", "Peng Shu", "Junhao Chen", "Haobo Sun", "Ruixi Liang", "Shixin Li", "Pengcheng Shi", "Longjun Ma", "Zongjia Liu", "Zhengliang Liu", "Tianyang Zhong", "Yutong Zhang", "Chong Ma", "Xin Zhang", "Tuo Zhang", "Tianli Ding", "Yudan Ren", "Tianming Liu", "Xi Jiang", "Shu Zhang"], "abstract": "In this paper, we review legal testing methods based on Large Language Models (LLMs), using the OPENAI 01 model as a case study to evaluate the performance of large models in applying legal provisions. We compare current state-of-the-art LLMs, including open-source, closed-source, and legal-specific models trained specifically for the legal domain. Systematic tests are conducted on English and Chinese legal cases, and the results are analyzed in depth. Through systematic testing of legal cases from common law systems and China, this paper explores the strengths and weaknesses of LLMs in understanding and applying legal texts, reasoning through legal issues, and predicting judgments. The experimental results highlight both the potential and limitations of LLMs in legal applications, particularly in terms of challenges related to the interpretation of legal language and the accuracy of legal reasoning. Finally, the paper provides a comprehensive analysis of the advantages and disadvantages of various types of models, offering valuable insights and references for the future application of AI in the legal field.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the breakthrough of deep learning tech- nology in natural language processing (NLP), particularly the rapid advancement of Transformer technology, has led to the flourishing of LLMs [1]. Models like OpenAI's GPT series have demonstrated exceptional capabilities in NLP, excelling not only in traditional NLP tasks such as machine translation and Question Answering, but also in some multimodal tasks, such as image-to-text translation, speech recognition, and subtitle generation [2], [3], [4], [5]. These models are capable of accurately understanding relationships between various data forms and enabling cross-modal information transformation, significantly enhancing automation and efficiency across these fields.\nIn the legal field, LLMs are seen as a transformative force with the potential to revolutionize traditional legal services, owing to their comprehensive legal knowledge base and ex- ceptional capabilities in natural language understanding and generation [6]. Some studies have explored the application of LLMs in the analysis and generation of legal texts, eval- uating their performance in tasks such as legal reasoning, case retrieval, and legal question answering, and investigating their potential to improve the efficiency and accuracy of legal work [7]. Meanwhile, other researchers have focused on developing LLMs specifically tailored for legal domains, enabling these models to better understand legal terminology, apply legal provisions accurately, and adapt to the nuances of different legal systems. This specialization aims to increase the practical value of LLMs in legal practice [8], [9], [10]. How- ever, effectively evaluating the performance of LLMs across various legal systems and linguistic environments remains a significant challenge. Additionally, addressing the technical and ethical concerns associated with their application is an urgent issue that requires further attention and resolution.\nThe application of LLMs in the legal field also faces numerous challenges and issues. First, legal language is highly specialized and precise, making it crucial to ensure the accu- racy and legality of the content generated by these models [11], [12]. Second, LLMs may absorb biases and inaccuracies from their training data, which can have serious repercussions when applied in the legal context [13], [14], [15]. Additionally, the automation of legal decision-making processes could lead to ethical concerns and disputes over legal accountability [16], [17].\nAs shown in Fig 1 Based on this background, this work aims to provide a comprehensive overview of the performance of LLMs in the legal field, offering valuable insights for both the academic community and legal practitioners. The study is structured as follows:\nSection 1: This Section explains the background, purpose, and significance of the study, outlining the motivations and objectives behind the research.\nSection 2: This Section provides a detailed analysis of legislation related to large models on a global scale, exploring the similarities and differences in policies and regulations across various countries.\nSection 3: The focus is on models specifically tailored to the legal domain, examining their technical features and evaluating their potential applications in legal practice.\nSection 4: This Section presents a comprehensive assess- ment of the models discussed in Section 3 using thirteen Chi- nese and thirteen English legal cases. The cases were selected to include a complete set of four components: judgment, back- ground, analysis and conclusion. The Section systematically evaluates the performance and applicability of each model"}, {"title": "II. REVIEW OF LLMS IN THE LEGAL FIELD", "content": "The rapid advancement of LLMs has catalyzed signifi- cant breakthroughs in NLP and across sectors like medi- cal healthcare [18], [19], [20], education [21], [22], [23]. Encouraged by these successes, researchers are increasingly exploring LLM applications in the legal domain. LLMs hold substantial potential to assist legal professionals in tasks such as summarization, drafting (e.g., contract clauses or initial document drafts), and legal research [24]. Summarization tasks can range from generating concise contract summaries [25], summarizing complex litigation filings in case dockets [26], to producing automatic summaries of judicial opinions [27]. In drafting, LLMs can review and suggest language improvements in documents and contracts [28], as well as enrich drafting options [29]-for example, modifying clauses to switch between singular and plural forms or appending additional elements [29]. Legal research applications leverage LLMs to provide plain language responses to legal queries, synthesizing case law and offering clear, accessible answers to intricate legal questions, including those related to securities law [30]. Furthermore, LLMs can generate tailored research memoranda in response to specific queries [31] and facilitate the development of chatbots capable of answering questions on Supreme Court rulings. These capabilities underscore LLMs' transformative role in enhancing efficiency, precision, and accessibility in legal practice.\nResearch has increasingly focused on assessing the ca- pabilities of LLMs in the legal domain. For instance, [9] investigated the zero-shot performance of GPT-3.5 Turbo on the LexGLUE benchmark [32], utilizing a templated, instruction-based approach. Their findings indicate that while ChatGPT achieves an average micro-F1 score of 49.0% across LexGLUE tasks\u2014surpassing baseline guessing rates\u2014it still demonstrates overall poor performance in legal text clas- sification, suggesting limitations in handling nuanced legal language.\nExtending these evaluations, [33] examined the potential of LLMs for generating abstractive summaries of case judge- ments, applying both domain-specific and general-domain models to Indian court rulings. Their results indicate that while these models can generate coherent summaries, neither pre- trained abstractive summarization models nor general-purpose LLMs are yet suitable for fully automated case judgement summarization, due to quality inconsistencies and domain- specific limitations.\nSimilarly, [34] assessed GPT-4's performance in generating precise, relevant explanations for legal terminology, specifi- cally within legislation. Although initial impressions of GPT- 4's output were favorable, closer analysis revealed inaccu- racies, highlighting current limitations in factual precision within legal text generation. Further research on structured improvements may thus be needed before deploying LLMs for critical, domain-specific tasks like case summarization and legislative interpretation.\nTo explore broader capabilities, [35] leveraged the common-sense reasoning abilities of LLMs for zero-shot crime detec- tion based on descriptive summaries of surveillance videos. Their study underscores that, given accurate textual descrip- tions, LLMs achieve state-of-the-art results in crime detection and classification through zero-shot reasoning. However, they identify that the accuracy of video-to-text conversion remains a significant obstacle to practical deployment.\nThese aforementioned models have been applied extensively"}, {"title": "III. OVERVIEW OF LEADING LANGUAGE MODELS", "content": "In recent years, with the advancement of computing power and the accumulation of massive amounts of data, LLMs have demonstrated immense potential in the field of artificial intel- ligence. They have made significant strides in various domains such as natural language processing and computer vision, capable of handling complex tasks like text generation, image recognition, and machine translation. Closed-source models like OpenAI's GPT-4 [47], with their massive parameter counts and high-quality training data, have showcased exceptional abilities in understanding and generating human language, setting new benchmarks for AI technology. However, their capabilities in legal case adjudication remain to be explored.\nGPT-4[47] is the fourth iteration of the Generative Pre- trained Transformer (GPT) series developed by OpenAI. With a colossal 1.8 trillion parameters, it significantly surpasses its predecessors. GPT-4 employs 16 mixed-expert models, each consisting of 1.11 trillion parameters. Trained on mas- sive amounts of multimodal data, GPT-4 exhibits exceptional performance in tasks such as text generation and image understanding. Notably, GPT-4 possesses emergent abilities, enabling it to learn complex patterns from data without explicit programming, leading to more flexible and powerful task han- dling. GPT-40, an optimized version of GPT-4, builds upon its predecessor's strengths and introduces technical improvements to significantly enhance efficiency and cost-effectiveness in specific scenarios, making it more suitable for practical appli- cations.\nGemini, a multimodal LLM developed by Google AI, demonstrates exceptional performance in processing text, im- ages, and other modalities. By directly mixing different modal- ities during pre-training, Gemini [48] establishes a deep under- standing of the relationships between them. Gemini 1.5 further enhances its capabilities by supporting ultra-long contexts of up to millions of tokens. To improve efficiency and scalabil- ity, Gemini 1.5 [49] leverages a Mixture-of-Experts (MoE) architecture and is trained on Google's TPU v5e chips. This design enables the model to handle complex tasks efficiently and accurately. Gemini represents a significant advancement in the field of AI, paving the way for new applications and possibilities.\nClaude 3.5 Sonnet[50], developed by Anthropic, is a pow- erful language model that strikes a balance between speed and performance. Positioned as an intermediate model in the Claude 3 series, it offers exceptional coding and visual processing capabilities while maintaining efficiency. With an ultra-long context window of 200K tokens, the model can handle complex and lengthy legal texts and has outperformed its peers in various benchmarks. Its unique ability to \"control a computer\" gives it a distinct advantage in legal case analysis, enabling it to interact with computers like a human and process cases involving multimodal information such as images and diagrams. Moreover, the model has been carefully designed with security in mind, meeting the confidentiality requirements of legal case analysis. The emergence of Claude 3.5 Sonnet opens up new possibilities in legal AI, promising to play a significant role in legal text analysis, contract review, and case law retrieval.\nYi-Large[51] is a LLM designed to handle multimodal data, including text and images. It incorporates Vision Transformer (ViT) and text encoders to achieve deep fusion of visual and textual features, enabling the model to understand and reason about multimodal information. With a context win- dow of 200K tokens, Yi-Large can process long sequences"}, {"title": "A. Overview of leading non-open source LLMs", "content": "In recent years, with the advancement of computing power and the accumulation of massive amounts of data, LLMs have demonstrated immense potential in the field of artificial intel- ligence. They have made significant strides in various domains such as natural language processing and computer vision, capable of handling complex tasks like text generation, image recognition, and machine translation. Closed-source models like OpenAI's GPT-4 [47], with their massive parameter counts and high-quality training data, have showcased exceptional abilities in understanding and generating human language, setting new benchmarks for AI technology. However, their capabilities in legal case adjudication remain to be explored.\nGPT-4[47] is the fourth iteration of the Generative Pre- trained Transformer (GPT) series developed by OpenAI. With a colossal 1.8 trillion parameters, it significantly surpasses its predecessors. GPT-4 employs 16 mixed-expert models, each consisting of 1.11 trillion parameters. Trained on mas- sive amounts of multimodal data, GPT-4 exhibits exceptional performance in tasks such as text generation and image understanding. Notably, GPT-4 possesses emergent abilities, enabling it to learn complex patterns from data without explicit programming, leading to more flexible and powerful task han- dling. GPT-40, an optimized version of GPT-4, builds upon its predecessor's strengths and introduces technical improvements to significantly enhance efficiency and cost-effectiveness in specific scenarios, making it more suitable for practical appli- cations.\nGemini, a multimodal LLM developed by Google AI, demonstrates exceptional performance in processing text, im- ages, and other modalities. By directly mixing different modal- ities during pre-training, Gemini [48] establishes a deep under- standing of the relationships between them. Gemini 1.5 further enhances its capabilities by supporting ultra-long contexts of up to millions of tokens. To improve efficiency and scalabil- ity, Gemini 1.5 [49] leverages a Mixture-of-Experts (MoE) architecture and is trained on Google's TPU v5e chips. This design enables the model to handle complex tasks efficiently and accurately. Gemini represents a significant advancement in the field of AI, paving the way for new applications and possibilities.\nClaude 3.5 Sonnet[50], developed by Anthropic, is a pow- erful language model that strikes a balance between speed and performance. Positioned as an intermediate model in the Claude 3 series, it offers exceptional coding and visual processing capabilities while maintaining efficiency. With an ultra-long context window of 200K tokens, the model can handle complex and lengthy legal texts and has outperformed its peers in various benchmarks. Its unique ability to \"control a computer\" gives it a distinct advantage in legal case analysis, enabling it to interact with computers like a human and process cases involving multimodal information such as images and diagrams. Moreover, the model has been carefully designed with security in mind, meeting the confidentiality requirements of legal case analysis. The emergence of Claude 3.5 Sonnet opens up new possibilities in legal AI, promising to play a significant role in legal text analysis, contract review, and case law retrieval.\nYi-Large[51] is a LLM designed to handle multimodal data, including text and images. It incorporates Vision Transformer (ViT) and text encoders to achieve deep fusion of visual and textual features, enabling the model to understand and reason about multimodal information. With a context win- dow of 200K tokens, Yi-Large can process long sequences effectively. To improve efficiency and performance, Yi-Large adopts grouped query attention and a three-stage training strategy. Experimental results show that Yi-Large outperforms state-of-the-art models on various multimodal tasks, including visual question answering and image generation."}, {"title": "B. Overview of leading open source LLMs", "content": "While closed-source models like OpenAI's GPT-4 have demonstrated exceptional performance in the realm of LLMs, the contributions from the open-source community are equally noteworthy. Open-source LLMs, such as Meta's Llama 3[52] and models from Mistral AI[53], have provided researchers and developers with vast opportunities for innovation due to their openness and accessibility. These models excel in various tasks including text generation and translation, and in some cases, their performance is on par with closed-source models. In the legal domain, open-source models have also shown immense potential. By learning from massive amounts of legal text, these models can provide strong support for legal research and practice. To thoroughly evaluate the application prospects of these models in the legal field, we have conducted in-depth research on the current mainstream open-source models.\nMeta's newly released Llama 3 LLM[52] marks a significant advancement in the field of AI. Built upon the auto-regressive Transformer architecture, Llama 3 incorporates optimizations in tokenization, attention mechanisms, and other key com- ponents. Through techniques such as supervised fine-tuning and reinforcement learning from human feedback, Llama 3 has achieved notable improvements in both performance and safety. Capable of handling multiple languages, long-form text, and complex reasoning, Llama 3 excels in tasks ranging from mathematical problem-solving to legal text analysis. Its open- source nature fosters innovation by empowering developers to customize the model for specific applications. By demonstrat- ing state-of-the-art performance across various benchmarks, Llama 3 solidifies Meta's position as a leader in Al research. Moreover, Meta's commitment to responsible AI development is exemplified by the safety measures integrated into Llama 3. With its potential to revolutionize fields such as legal research, contract analysis, and case law retrieval, Llama 3 represents a promising step forward in the evolution of LLMs.\nMistral AI, a burgeoning AI startup founded by former employees of DeepMind and Meta, has made significant strides in the field of LLMs. Within a year of its inception, Mistral AI unveiled its inaugural model, Mistral 7B[53], which promptly outperformed all other open-source models of the same parameter scale. Remarkably, it even surpassed larger models, demonstrating superior performance in tasks such as reasoning, mathematics, and code generation. Subsequent iterations, including Mistral 8x7B and Mistral Large 240B, have continued to push the boundaries of LLM capabilities, closing the gap with industry benchmarks like GPT-4. These models leverage advanced techniques such as GQA, ROPE, and SWA to enhance their ability to process long texts, perform complex reasoning, and generate code. The rapid growth and exceptional performance of Mistral AI have garnered significant attention within the AI community. By pioneering innovative approaches to LLMs, Mistral AI is shaping the future of natural language processing.\nGemma[54] is an open-source family of models based on Google's Gemini model, inheriting its strong generalization, understanding, and reasoning abilities. Trained on a massive dataset of up to 6 trillion tokens, the Gemma family achieves remarkable results in text generation, understanding, and rea- soning. The series offers two model sizes, 7 billion and 20 billion parameters, to cater to various computational resources and application scenarios. Gemma 2[55], the latest addition to the series, adopts a decoder-only architecture and intro- duces several innovative techniques such as sliding window attention, soft-max, RMSNorm normalization, and grouped query attention, further enhancing the model's performance and efficiency. These innovations enable Gemma 2 to handle longer context windows while maintaining powerful language capabilities and improving training stability. The open-source nature of the Gemma models provides researchers and devel- opers with a powerful tool, driving advancements in natural language processing.\nMicrosoft's newly released open-source Phi-3.5 series [56] of AI models have achieved significant breakthroughs in performance and functionality. Among them, Phi-3.5-mini- instruct, designed for resource-constrained environments, ex- cels in code generation and mathematical reasoning. Phi-3.5- MoE-instruct adopts a Mixture-of-Experts (MoE) architecture, ensuring efficient computation while handling complex tasks. Phi-3.5-vision-instruct combines text and image processing ca- pabilities, demonstrating superior performance on multi-modal tasks. This model series has surpassed competing products in multiple benchmarks, setting new performance standards.\nQwen2[57] is a family of LLMs encompassing a wide range of parameter sizes, from 0.5B to 72B. This series excels in multilingual support, handling extra-long contexts, and com- putational efficiency. Built upon the Transformer architecture, Qwen2 incorporates techniques such as SwiGLU activation, QKV bias, and a mixture of SWA and Full Attention to enhance performance. Supporting 29 languages including Chi- nese and English, the model can process up to 128K tokens. Additionally, all models in the Qwen2 series employ the Grouped Query Attention (GQA) mechanism to reduce com- putational complexity and improve efficiency. These features make Qwen2 highly suitable for natural language processing tasks that require multilingual support, long-text processing, and complex reasoning.\nThe GLM-4 series [58], developed by Zhipu AI, is a state-of- the-art family of pre-trained language models, offering various parameter sizes to cater to diverse application needs. This series excels in multilingual support, extra-long context pro- cessing, and multi-modal capabilities. GLM-4-9B and its dia- logue variant, GLM-4-9B-Chat, outperform their counterparts in semantics, mathematics, reasoning, coding, and knowledge. GLM-4-9B-Chat further offers advanced functionalities such as web browsing, code execution, and custom tool calling. To address the need for extremely long context processing, we have introduced GLM-4-9B-Chat-1M, which supports a context length of up to 1 million tokens. Additionally, GLM- 4V-9B, the multi-modal variant, demonstrates superior perfor-"}, {"title": "C. Overview of legal-specific LLMs", "content": "The legal domain demands a high degree of specialization from its models. Beyond general-purpose LLMs, we have evaluated models specifically tailored for legal tasks. These models, fine-tuned on extensive legal corpora, exhibit superior capabilities in understanding legal concepts, conducting legal reasoning, and generating legal text. Evaluating these models not only helps us assess their potential applications in the legal field but also provides valuable insights for advancing the development of legal artificial intelligence.\nLexNLP[59] is an open-source natural language processing toolkit specifically designed for legal text. It offers a com- prehensive suite of text analysis capabilities, including text cleaning, tokenization, feature extraction, entity recognition, and text classification, enabling deep understanding of com- plex legal terminology and structures. Its modular design and flexible API allow users to customize functionalities based on their specific needs and seamlessly integrate it into various legal applications. LexNLP's strength lies in its profound understanding of legal text and its efficient information extrac- tion capabilities, making it a valuable tool for legal research, contract analysis, and regulatory compliance.\nDesigned as a versatile legal language model, LawGPT[8] is fine-tuned on ChatGLM-6B LoRA 16-bit instructions and trained on a substantial corpus of Chinese legal text. The model has been enhanced with ChatGPT to refine and ex- pand its training data, enabling it to provide comprehensive and accurate responses to complex legal inquiries. Moreover, LawGPT is being developed with a specialized legal knowl- edge base and a reliable self-instruction method to ensure the highest quality of legal advice. Distinguished by its ex- ceptional performance in the Chinese legal domain, LawGPT offers a deeper understanding of Chinese legal nuances and provides more precise legal recommendations compared to other models.\nChatLaw[40] is a cutting-edge legal AI assistant that com- bines knowledge graphs, mixed expert models, and multi- agent systems to provide comprehensive legal services. The ChatLaw model family includes a diverse range of models, from the BERT-based ChatLaw-Text2Vec to the large-scale pre-trained models ChatLaw-13B and ChatLaw-33B. Through extensive training on high-quality legal datasets, ChatLaw has developed exceptional capabilities in addressing complex legal questions and conducting in-depth legal reasoning. The ChatLaw2-MOE model, in particular, leverages a mixture- of-experts approach and a multi-agent system to enhance accuracy and reliability, surpassing other models including GPT-4 in various legal benchmarks. ChatLaw is particularly well-suited for the Chinese legal landscape, offering users tailored and expert legal advice."}, {"title": "IV. EVALUATION OF LLMS ON LEGAL CASES", "content": "This study selected 26 representative legal cases as research subjects, with 13 from China and 13 from the United States, respectively using Chinese and English. To ensure the objec- tivity and fairness of the research, we strictly anonymized all personal privacy information in the cases.\nThe Chinese case dataset was constructed based on the Chinese Judgments Online database, covering civil, criminal, and administrative cases, and including a variety of judicial documents such as first-instance judgments, second-instance judgments, and rulings. The establishment of this dataset aims to comprehensively present the application of laws, judicial standards, and standardized expressions of judicial documents in various types of cases in Chinese judicial practice. Each case in the dataset contains detailed information, including basic information such as case number, court, trial date, and party identity, as well as the background, disputed issues, court's interpretation of legal provisions, evidence review, and final judgment with reasons for the case. Through this dataset, we can gain a deep understanding of the operation of the Chinese judicial system and provide rich data support for the study of Chinese law.\nThe US case dataset is sourced from the well-known Court Listener legal database, which collects a large number of judgment documents from federal and state courts in the United States. We carefully selected 13 representative cases from this vast database, covering multiple important legal areas such as immigration, criminal law, and administrative law. Each case provides rich and detailed information, including the social and legal background of the case, the focal issues that have attracted public attention, the core legal issues disputed by both parties, the final judgment of the court and detailed reasons for the judgment. If the case involves an appeal, we will also describe in detail the appeal process and the judgment of the higher court. In addition, the judgment provides related laws, regulations, precedents, and scholarly opinions to enable readers to conduct more in-depth research and understanding of these cases. Through this dataset, we can comprehensively understand the practices and basis of the US judicial system in handling different types of cases.\nBy comparing and studying the legal cases of China and the United States, we can not only deeply examine the large model's understanding and application capabilities in different legal systems but also deeply understand the similarities and differences between the two countries in terms of legislative concepts, judicial practices, and legal culture, and analyze the convergence and divergence of different legal systems in facing common legal issues in a globalized context. This research provides valuable experience for the application of large models in the legal field and can also provide rich first-hand data for legal scholars, judges, lawyers, and others, thereby promoting the continuous improvement of legal theory research and judicial practice."}, {"title": "A. Scope of the Study and Used Datasets", "content": "This study selected 26 representative legal cases as research subjects, with 13 from China and 13 from the United States, respectively using Chinese and English. To ensure the objec- tivity and fairness of the research, we strictly anonymized all personal privacy information in the cases.\nThe Chinese case dataset was constructed based on the Chinese Judgments Online database, covering civil, criminal, and administrative cases, and including a variety of judicial documents such as first-instance judgments, second-instance judgments, and rulings. The establishment of this dataset aims to comprehensively present the application of laws, judicial standards, and standardized expressions of judicial documents in various types of cases in Chinese judicial practice. Each case in the dataset contains detailed information, including basic information such as case number, court, trial date, and party identity, as well as the background, disputed issues, court's interpretation of legal provisions, evidence review, and final judgment with reasons for the case. Through this dataset, we can gain a deep understanding of the operation of the Chinese judicial system and provide rich data support for the study of Chinese law.\nThe US case dataset is sourced from the well-known Court Listener legal database, which collects a large number of judgment documents from federal and state courts in the United States. We carefully selected 13 representative cases from this vast database, covering multiple important legal areas such as immigration, criminal law, and administrative law. Each case provides rich and detailed information, including the social and legal background of the case, the focal issues that have attracted public attention, the core legal issues disputed by both parties, the final judgment of the court and detailed reasons for the judgment. If the case involves an appeal, we will also describe in detail the appeal process and the judgment of the higher court. In addition, the judgment provides related laws, regulations, precedents, and scholarly opinions to enable readers to conduct more in-depth research and understanding of these cases. Through this dataset, we can comprehensively understand the practices and basis of the US judicial system in handling different types of cases.\nBy comparing and studying the legal cases of China and the United States, we can not only deeply examine the large model's understanding and application capabilities in different legal systems but also deeply understand the similarities and differences between the two countries in terms of legislative concepts, judicial practices, and legal culture, and analyze the convergence and divergence of different legal systems in facing common legal issues in a globalized context. This research provides valuable experience for the application of large models in the legal field and can also provide rich first-hand data for legal scholars, judges, lawyers, and others, thereby promoting the continuous improvement of legal theory research and judicial practice."}, {"title": "B. Results and Analysis", "content": "In this section, we evaluate the performance of various LLMs (LLMs) on legal case judgment tasks, using both algorithmic and human evaluation metrics. We tested state- of-the-art models, including open-source, closed-source, and legal domain-specific models, across Chinese and English legal texts. For each model, the performance is assessed using the following metrics:\nROUGE and BLEU Scores: Algorithmic metrics like ROUGE and BLEU scores, both ranging from 0 to 1, are commonly used to evaluate text similarity between generated and reference outputs. ROUGE measures the overlap of n- grams between the model's output and a reference legal text, while BLEU calculates a modified form of precision for the generated output in comparison with human-generated text. Higher scores indicate closer alignment with reference cases, suggesting better model accuracy in generating relevant legal content.\nHuman Evaluation Score: To supplement automated met- rics, we conducted a human evaluation to assess the quality of the model-generated judgments against actual case judgments made by legal professionals. Law students, trained in legal analysis, scored each model's decision output on a scale from 1 to 5, with 5 representing a high degree of alignment with the legal reasoning and outcomes in real-world cases. Human scores offer insight into how well model outputs mimic human judgment in complex legal scenarios.\nIn the results tables, scores are reported for each model across Chinese, English, and All cases, representing perfor- mance in Chinese and English texts as well as an overall average.\nPerformance on Chinese Legal Texts: We evaluated the performance of various LLMs on Chinese legal texts using the metrics ROUGE-1, ROUGE-2, ROUGE-L, BLEU, and human evaluation scores. The results are summarized in Table I.\nHuman Evaluation Results: The GPT-40, Qwen2-7B-Instruct, and 01-preview models received the highest human evaluation scores of 3.85, suggesting a high degree of alignment between their generated judgments and the legal reasoning in actual case outcomes. Notably, despite achieving only modest scores on automated metrics (with ROUGE-1 scores around 0.13 and BLEU scores of 0.00), these models demonstrate an ability to produce coherent and contextually appropriate responses in legal contexts, as perceived by human evaluators. This underscores the potential of these models to offer valuable insights in complex legal scenarios, even when their textual similarity to reference judgments is limited.\nAutomated Evaluation Results: Examining the ROUGE and BLEU scores reveals a different dimension of model performance. Gemma2-9B, Phi-3.5-mini-instruct, and Mistral-7B-instruct-v0.3 achieved the highest scores on ROUGE-1 (0.39, 0.38, and 0.38 respectively), indicating strong overlap with n-grams in reference texts. However, their BLEU scores remain relatively low (around 0.03 to 0.07), suggesting that while these models generate segments similar to reference texts, they may lack fluency or consistency throughout the entire output. Interestingly, lawyer-llama-13b-v2 scored the highest on ROUGE-2 (0.19) and achieved a BLEU score of 0.05, reflecting slightly better cohesion in the generated text.\nAmong the evaluated models, GPT-40, Qwen2-7B-Instruct, and 01-preview are distinguished by their high human evaluation scores, suggesting a better understanding of legal case nuances. On the other hand, models like Gemma2-9B and lawyer-llama-13b-v2 exhibit superior ROUGE scores, indicating precise lexical overlap but possibly lacking in broader contextual accuracy as judged by human evaluators. These results suggest that while algorithmic scores provide useful benchmarks, human assessments are essential to evaluate the actual applicability of LLMs in the legal domain, where interpretative accuracy is critical.\nPerformance on English Legal Texts: The performance of each model on English legal texts was assessed using ROUGE-1, ROUGE-2, ROUGE-L, BLEU, and human eval- uation scores. Below, we discuss the findings, emphasizing both algorithmic and human evaluation outcomes.\nHuman Evaluation Results: The highest human evalu- ation score of 4.08 was achieved by 01-preview in the English legal text analysis, with Qwen2-7B-Instruct fol- lowing closely at 3.85, and several models (Gemma2-9B, GLM-4-9B-chat, and GPT-40) each scoring 3.54. These high scores indicate that these models are capable of producing judgments that align closely with human reasoning in real cas case scenarios, especially in English. Notably, 01-preview also achieved the highest human evaluation score for Chinese legal texts, tying with GPT-40 and Qwen2-7B-Instruct at 3.85, which highlights its robustness across both languages. However, a comparison reveals that overall, models tended"}, {"title": "V. CHALLENGES", "content": "Cases in the legal domain often involve individuals' sensi- tive information, including personal identity, financial status, and medical records. When using this data for model training, there is a risk that the model may unintentionally expose people' sensitive information during content generation, po- tentially leading to data leakage. To effectively safeguard data privacy, the design and training processes of the model must prioritize the protection of data. It is essential to ensure that the output results do not disclose personal information. Addi- tionally, the research and development team should implement a rigorous data processing and review mechanism for the model's outputs. This will help minimize risks and ensure compliance and security in the application of LLMs in the legal field.\nThe delineation of legal liability when utilizing LLMs for legal advice and decision-making remains unclear. Although"}, {"title": "A. Data privacy", "content": "Cases in the legal domain often involve individuals' sensi- tive information, including personal identity, financial status, and medical records. When using this data for model training, there is a risk that the model may unintentionally expose people' sensitive information during content generation, po- tentially leading to data leakage. To effectively safeguard data privacy, the design and training processes of the model must prioritize the protection of data. It is essential to ensure that the output results do not disclose personal information. Addi- tionally, the research and development team should implement a rigorous data processing and review mechanism for the model's outputs. This will help minimize risks and ensure compliance and security in the application of LLMs in the legal field."}, {"title": "B. The definition of legal liability", "content": "The delineation of legal liability when utilizing LLMs for legal advice and decision-making remains unclear. Although developers typically emphasize the limitations and potential risks of their models upon release and strive to mitigate legal issues during the training process, unintended consequences can still arise. When a model provides advice or analysis that leads to undesirable outcomes, the question of liability arises: who should be held accountable? Is it the developer, the user, or the model itself? There is currently no consensus on whether users should be liable for decisions made based on model outputs, highlighting the need for further policy discussions and the establishment of a comprehensive legal framework. Such measures are urgently required to ensure the sustainability and security of LLMs in legal practice."}, {"title": "C. Ethical and moral issues", "content": "Due to the diverse sources of data, these models can introduce biases, which may result in unfair outputs. In the legal field, where fairness and impartiality are crucial, ensuring that models remain neutral during case analysis and preventing potential discrimination and injustice is an urgent concern. Moreover, the lack of transparency in model-generated results complicates users' ability to assess their reliability. This high- lights the need for a robust ethical review mechanism in the legal domain to ensure that model outputs adhere to relevant laws, regulations, and ethical standards. By implementing such a mechanism, we can help ensure that the use of LLMs aligns with the principles of justice and accountability in legal practice."}]}