{"title": "EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents", "authors": ["Yuhui Yun", "Huilong Ye", "Xinru Li", "Ruojia Li", "Jingfeng Deng", "Li Li", "Haoyi Xiong"], "abstract": "The paper introduces EICopilot, an novel agent-based solution enhancing search and exploration of enterprise registration data within extensive online knowledge graphs like those detailing legal entities, registered capital, and major shareholders. Traditional methods necessitate text-based queries and manual subgraph explorations, often resulting in time-consuming processes. EICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this landscape by utilizing Large Language Models (LLMs) to interpret natural language queries. This solution automatically generates and executes Gremlin scripts, providing efficient summaries of complex enterprise relationships. Distinct feature a data pre-processing pipeline that compiles and annotates representative queries into a vector database of examples for In-context learning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought with ICL to enhance Gremlin script generation for knowledge graph search and exploration, and a novel query masking strategy that improves intent recognition for heightened script accuracy. Empirical evaluations demonstrate the superior performance of EICopilot, including speed and accuracy, over baseline methods, with the Full Mask variant achieving a syntax error rate reduction to as low as 10.00% and an execution correctness of up to 82.14%. These components collectively contribute to superior querying capabilities and summarization of intricate datasets, positioning EICopilot as a groundbreaking tool in the exploration and exploitation of large-scale knowledge graphs for enterprise information search.", "sections": [{"title": "1 INTRODUCTION", "content": "Online knowledge graphs detailing vital enterprise registration data, such as legal persons, registered capital, and major shareholders, serve as a valuable resource for Internet users seeking enterprise information[9]. Despite their utility, exploring these graphs can be cumbersome due to the need for intricate text-based queries and manual exploration of subgraphs, presenting significant challenges in extracting pertinent information efficiently[13].\nConsider a scenario where a financial analyst is tasked with investigating whether the major shareholders of a company have made any investments in catering companies. The analyst must gather detailed information about these shareholders, including their investment patterns, related entities, and any associations with the catering industry. As shown in Figure 1, initially, the analyst would begin by querying the company's major shareholders, leading to an initial graph node that provides basic shareholder information. From there, the analyst needs to manually follow links to subgraphs that represent these shareholders' investment portfolios, affiliated business entities, and any connections to the catering sector. This manual exploration can be time-consuming and error-prone, as the analyst might overlook significant relationships or struggle to decipher intricate investment networks. This process may involve tracing back from the key shareholder node to various corporate or individual investment nodes, evaluating their stake percentages in catering companies, and interpreting the financial implications of each investment. The complexity increases when some investment nodes represent other corporations, requiring further layers of analysis."}, {"title": "2 FRAMEWORK DESIGN", "content": "As illustrated in Figure 2, EICopilot framework presents a sophisticated dual architecture for processing natural language queries directed towards enterprise information graph databases. During the offline phase, emphasis is placed on the preparation and enrichment of a robust data foundation to support subsequent online operations effectively. The construction of an enriched seed data repository, complemented by efficient data augmentation strategies, further enhances the system's capacity to generate precise query responses. Transitioning to the online phase, the intent understanding and decision-making modules of the EICopilot framework leverage the intricate capabilities of LLMs to interpret various user queries, accommodating non-standard query phrases. The system's capabilities in ICL and CoT further streamline the process, facilitating efficient and relevant information retrieval.\nThe integration of graph data query statement generation with contextual cues, coupled with the supervision provided by the reflection module, ensures the generation of accurate and logically consistent graph database information retrieval. These functionalities, along with the fundamental components utilized by the framework, attest to the precise, reliable, and secure operation of EICopilot. The resultant presentation constitutes the ultimate point of interaction between users and EICopilot, wherein complex structured data is transformed into textual responses, significantly enhancing the user experience. Subsequent sections will progressively delve into each phase to elucidate the detailed design principles."}, {"title": "2.1 Offline Phase", "content": "The offline phase is dedicated to preparing high-quality data that will be utilized during the online phase. This preparatory work involves four key activities: Schema Semantic Governance, Seed Data Construction, Data Augmentation, and Masked Question Similarity Selection. Once organized and refined, these data sets are embedded into an in-memory vector database, which in turn equips the online phase with the necessary contextual data to address specific user queries."}, {"title": "2.1.1 Schema Semantic Governance", "content": "Schema information is crucial for data analysis tasks, such as graph database query language writing, similar to the necessity for humans to comprehend complex graph databases. The EICopilot, by interpreting schema details, generates graph database query statements that align with human intent. For fields with enumerated values, it is essential to provide a comprehensive description of the values stored in the database and their interpretations. In cases involving complex data types like structures and maps, it is critical to elucidate key properties and their meanings. These detailed metadata facilitate an understanding of the intricate relationships between attributes, thereby enabling accurate response to queries for data retrieval. Additionally, annotations should be applied to graph database query languages to ensure the generation of syntax that meets the specific requirements of the target system."}, {"title": "2.1.2 Seed Data Construction", "content": "Current LLMs have limited autonomous capabilities in generating query languages for knowledge graphs. By leveraging the ICL capabilities, we aim to enhance the stability and accuracy of knowledge graph query generation by integrating dynamic query pairs relevant to the user's current problem. There are three strategies for constructing these seed data pairs. The first involves embedding query pairs commonly found in enterprise workflows, especially since some queries frequently involve business-specific metrics. Without the aid of few-shot learning or fine-tuning mechanisms, it is unrealistic to expect LLMs to autonomously generate user-specific knowledge graph queries. The second approach utilizes Graph2NL technology, which supports a cold start process without necessitating user-supplied knowledge graph query pairs. This is particularly advantageous given the extensive data available in corporate data warehouses. In this scenario, natural language queries are generated using knowledge graph and schema information, thereby establishing knowledge graph query pairs. The final method involves creating knowledge graph query pairs based on user feedback in cases where accurate results are not produced. In such instances, human intervention becomes essential for correcting inaccuracies."}, {"title": "2.1.3 Masked Question Similarity Selection", "content": "To address the shortcomings in autonomous knowledge graph query generation capabilities, we adopted the ICL method. By dynamically integrating query pairs relevant to the user's current query, we enhanced the model's ability to generate stable and precise query statements. Specifically, this method improves the model's query generation capability by dynamically generating contextually relevant query pairs.\nTo prevent key information differences in user queries from decreasing the relevance of information retrieval and intent recognition, we standardized the usage of query masking strategy. This standardization significantly increased the recall and accuracy of similar instances in the sample repository, thereby enhancing the overall effectiveness of the query generation mechanism.\nIn implementation, we focused on the following aspects:\n(1) Query Pair Construction: As shown in section 3.1.2, We built a sample repository, collecting diverse query pairs relevant to potential user queries. Each query pair contains a question and a corresponding query statement. By carefully"}, {"title": "2.1.4 Analysis System", "content": "The system aims to leverage a substantial amount of real-world user data to enhance the richness of the vector database. We have designed an offline analysis architecture that exports query execution records and categorize failed tasks and regenerate query statements. Subsequently, the regenerated queries are manually reviewed, and successful user query-statement pairs are imported into the vector database, thereby improving the quality and accuracy of the knowledge base.\nThe core functionality of the offline analysis architecture lies in utilizing exported query execution records to analyze and identify the reasons behind query failures. The analysis framework is capable of correcting issues by categorizing failed tasks and generating new query statements. Specifically, when a query execution fails, the system exports the relevant execution record, identifies the type of failure, and generates alternative query statements that better align with user needs based on task context and query intent, ultimately increasing the query success rate.\nAfter manual review, the regenerated query statements that successfully execute are paired with the user questions and imported into the vector database, thereby improving the quality of the knowledge base. This process ensures continuous database optimization and provides more accurate and comprehensive query results. By constantly refining the query execution records and regeneration strategies, the system gradually accumulates a large number of effective user query-statement pairs, providing richer references for future queries."}, {"title": "2.2 Online Phase", "content": "The system provides a refined user experience through an online architecture consisting of a series of modules driven by a Named Entity Recognition (NER) model, an Entity Retrieval model based"}, {"title": "2.2.1 Intent Understanding and Decision-Making", "content": "In the real-world application, user queries are diverse, encompassing content beyond specified parameters, topics outside the domain scope, incomplete queries, and questions that challenge continuity. To address these complexities, a decision-making mechanism supported by EICopilot has been designed. This mechanism integrates three main components: comprehensive intent absorption, relevant knowledge retrieval, and response generation-all aimed at enhancing the precision of service provided to users. The system utilizes user inquiries, similar example queries, and predefined decision metrics to craft detailed prompts, optimizing the LLM's responses. The comprehensive intent understanding component is designed to capture the essence of user needs, addressing gaps in multi-turn dialogues. Relevance assessment determines the pertinence of a query to the ongoing topic, thereby filtering out irrelevant or off-topic questions."}, {"title": "2.2.2 Disambiguation", "content": "The disambiguation process includes two steps: anaphora resolution and entity retrieval. For instance:\nIn the query, \"What is the registered address of Baidu?\" the term \"Baidu\" could refer to multiple corporate entities such as Baidu Netcom or Baidu Online. It is essential to determine the specific entity for the query before proceeding with data retrieval. In the statement, \"Who is their legal representative?\" the term \"their\" is a pronoun that, within the context of a multi-turn dialogue, requires semantic understanding to resolve its reference based on the preceding conversation. Initially, anaphora resolution is performed by considering the context of the historical dialogue to interpret the current user's query. The prompt for this process is as follows:\nIn the realm of LLMs, employing the aforementioned techniques can significantly reduce the occurrence of pronouns and incomplete sentences in queries. Following anaphora resolution, it is necessary to resolve ambiguities concerning corporate entities in the user's query. This process relies on NER, NLPC, and an ElasticSearch-based system for corporate entity retrieval. Initially, an NER model segments the user's query to extract corporate names. Then, a recall service that integrates NLPC and ElasticSearch is deployed for precise entity matching. If a match is found, the complete name and ID of the corporate entity are obtained, thus finalizing the disambiguation process. If the initial match attempt via NLPC and ElasticSearch fails, a fuzzy search is triggered. When multiple entities are detected, the user is prompted to confirm the specific entity. This ensures that the subject of the user's query is clearly identified and uniquely retrievable in the knowledge graph."}, {"title": "2.2.3 Schema Linking", "content": "In practical commercial environments, the challenge of managing large graph databases is often constrained by the context bandwidth of LLM prompts. This contextual limitation renders it impractical to integrate the comprehensive architectural details of all graph data tables into a single prompt. Moreover, incorporating excessive schema information could adversely affect the model's performance. As a solution, we introduce a Schema Linking Module, positioned prior to the construction of the graph database, to circumvent the complexity of excessive schema input.\nContemporary schema linking interventions typically revolve around the development of new models, which requires substantial resources and may face limitations in domain generality. To counteract this, our approach employs an initial multi-recurrence strategy to identify tables aligned with the user's query intent. Subsequently, the LLM is utilized to establish links between the user's question and the relevant graph database and fields.\nWe then derive the details of schema linking from the prescribed prompt, as illustrated in Figure 3. This two-stage method facilitates efficient graph database query language generation for large tables within specific domains and simplifies the schema linking process, thereby enhancing the model's effectiveness and generalization potential."}, {"title": "2.2.4 Query Language Generation", "content": "The module aims to accurately deconstruct user queries by obfuscating key information. The core process involves separating the user's query content from the intent and then leveraging a knowledge base in a vector database to match the intent. The specific workflow can be illustrated using the"}, {"title": "2.2.5 Reflection", "content": "This module aims to significantly enhance the accuracy of graph database query languages to rectify erroneous query language expressions. Through thorough evaluation and comprehensive review, we meticulously verify the authenticity of graph database query commands, delving into the root causes of errors, including the validation of edges, edge directions, attributes, and the syntactic integrity of queries. The reflection mechanism is activated only after anomalies in the graph database query commands have been clearly identified.\nThe prompt configuration of this module is meticulously designed to not only specify error types but also include graph database queries, detailed graph structure information, and in-depth diagnostic assessments of discrepancies. This framework enables EICopilot to focus on correcting potential errors in graph database query commands, ensuring an accurate and targeted rectification process."}, {"title": "2.2.6 Result Generation", "content": "After retrieving the execution results from the database engine, the result generation module comes into play, constructing the final output for the web-based application. EICopilot is capable of providing recommendations for scenarios such as complaints and information inquiries based on the retrieved context and content, effectively guiding users for further actions. Additionally, the module integrates functions like product recommendations, corporate directories, and supply-demand marketplaces to address users' multifaceted needs. To enhance system response speed, as outlined in section 3.2.1, if a user's intent is identified as related to procurement, franchising, etc., a template-based response will be returned directly. For other intents, our system will provide a summarized response."}, {"title": "3 EXPERIMENTAL EVALUATION", "content": "In this section, we present the experimental setups, followed by a comparisons of our overall performance results. We then delve into ablation tests and conclude with an analysis of various case studies."}, {"title": "3.1 Experimental Setup", "content": "We mainly introduce the experimental setups from the perspectives of LLM models and datasets used for evaluation."}, {"title": "3.1.1 Dataset Construction", "content": "Due to the lack of publicly available datasets, we obtained data from Baidu's internal data platform. Through rigorous processing, we constructed a test dataset consisting of 150 entries. Each entry comprises an input query paired with its corresponding graph database query statement. By decomposing the query into segments by splitting the string at each period, we determine the number of operational steps in the query traversal. The length of this list of steps provides an initial indication of complexity; typically, longer queries entail more intricate logic and higher resource consumption. To simplify the evaluation without losing generality, the complexity score based on traversal length is assigned as follows:\nLength Complexity Score = $\\begin{cases} 1 & \\text{if steps} < 5 \\\\ 2 & \\text{if } 5 \\leq \\text{steps} \\leq 7 \\\\ 3 & \\text{else} \\end{cases}$  (1)\nE.g., the query g.V().hasLabel('person').values('name') contains 3 steps, resulting in a score of 1. Conversely, a query with 8 steps would receive a score of 3. Each traversal step is further evaluated based on the operators used, categorized as shown in Table 1. Basic operations like has score 1 point, while more complex operations like repeat score 3 points due to their higher complexity. The final complexity score is the sum of the traversal length score and the points assigned to the operations. The final difficulty level is determined as follows:"}, {"title": "3.1.2 Evaluation metrics", "content": "To assess the performance of the proposed EICopilot method, we consider two key perspectives: the syntax errors of the Gremlin scripts generated within the EICopilot and their execution correctness. The detailed definitions for each metric are as follows:\n\u2022 Syntax Error Rate, defined as the percentage of predicted Gremlin scripts that are free of syntactic errors. It can be computed by $[1-\\frac{S}{N}]*100\\%$, where 1(\u00b7) is an indicator function, which can be represented as 1(R) = $\\begin{cases} 1, & \\text{execution success} \\\\ 0, & \\text{execution failed} \\end{cases}$\n\u2022 Execution Correctness, defined as the proportion of queries rated for their effectiveness in fulfilling user requirements, whether directly or indirectly. This metric is derived from expert evaluations of generated Gremlin scripts, assessing factors like alignment with user intent and overall script reliability. Scripts that fully satisfy user needs receive a score of 1, those offering partial or potential assistance are scored 0.5, and those deemed irrelevant to user requirements receive a score of 0."}, {"title": "3.1.3 LLM Models", "content": "In this experiment, we compared the performance of EICopilot on top of three models as follows:\n\u2022 ErnieBot is a close-source, full-size LLM developed by Baidu, designed for understanding and generating human-like text across various applications, eg., code generation.\n\u2022 ErnieBot-Speed is the lite and fast version of ErnieBot with fewer trainable parameters. This model supports SFT for application customization.\n\u2022 Llama3-8b is an open-source LLM with 8 billion parameters. It supports SFT for applications.\nTo fine-tune ErnieBot-Speed and Llama3-8b, we collect and annotate a dataset consisting of 418 manually selected Gremlin query pairs that cover a wide range of Gremlin syntax. The data is divided into training and validation sets in an 8:2 ratio. During the fine-tuning process, we use a full SFT approach based on training samples and perform the parameter tuning with the validation set.\nNotably, the ErnieBot and Llama series are utilized as foundational LLMs within our system, specifically for the prompt-tuning process of EICopilot. Although prompt-tuning is not our primary contribution, we emphasize system design and agentic workflows for chat-based enterprise information searches using knowledge graphs. Consequently, we limited evaluations to these models for consistency, without asserting their superiority in all Gremlin generation tasks. While other LLMs may achieve superior performance in these tasks through pre-training or fine-tuning, our contribution to system design can effectively complement such advancements."}, {"title": "3.1.4 Baselines and Configurations", "content": "When an evaluation query serves as the target for the generation of Gremlin scripts, representative queries are used as potential examples for ICL. The EICopilot framework masks both the evaluating and representative queries, constructs a vector database, and executes similarity-based matching utilizing the following four strategies:\n\u2022 Raw Matching (Raw Match): This strategy employs LLMs to extract vectors for both the evaluating and representative queries, performing similarity-based matching between the evaluating query and every representative query.\n\u2022 Representative Query Entity Masking (Rep. Mask): Here, the entities in each representative query are masked before performing vector-based matching.\n\u2022 Representative Query Entity Masking (Eval. Mask): Here, the entities in each representative query are masked before performing vector-based matching.\n\u2022 Full Entity Masking (Full Mask): This approach involves masking entities in both the evaluating and representative queries, followed by similarity-based matching of the vectors. This strategy is used in the production of EICopilot.\nThe top-3 and top-5 matched representative queries serve as few-shot examples for ICL in our experiments, respectively. Notably, the vectors of all representative query are pre-extracted offline to build the vector database."}, {"title": "3.2 Performance Comparisons", "content": "In this section, we compare the performance of EICopilot in various settings compared to the zero-shot approach. We collect a testing dataset with 150 queries from the real-world traffics of Aiqicha and annotate these queries with Gremlin scripts. Note that there is no overlap between the testing dataset for evaluation and the training/validation datasets for SFT.\nTable 2 reveals that EICopilot under various models improves syntax error rate, with the Full Mask variant achieving an impressive 10.00% and 2.00%, indicating superior query quality. Other variants, such as Raw Match and Rep. Mask, also show improvements over the zero-shot baseline, which averages 19.33%. In terms of execution correctness, shown in Table 3, EICopilot with Full Mask excels with top scores up to 83.93%, underscoring its practical"}, {"title": "3.3 Ablation Analysis", "content": "We here analyze the four masking and representative query matching strategies, assessing their impact on syntax error rate and execution correctness as shown in Tables 2 and 3.\nWithout masking any entities in both the evaluating and representative queries, Raw Match still offers moderate gains, reducing syntax errors to 17.33%-25.33% and improving execution correctness to 53.00%-58.00%. Later, we can observe that masking either the evaluating query or the representative queries could bring performance gain: Eval. Mask reduces syntax errors with results up to 40.67% and correctness of 41.33%-70.67%. In contrast, Rep. Mask also shows notable improvements, with syntax errors decreasing to 14.00% and correctness rising to 61.61%-81.25%.\nBy combining Eval. Mask and Rep. Mask strategies, Full Mask excels, minimizing syntax errors to 10.00%-2.00% and achieving the highest correctness rates of 82.14%-83.93%. This strategy emerges as the most effective, consistently reducing errors and enhancing correctness, making it the best EICopilot configuration."}, {"title": "3.4 Case Study", "content": "We compare the alike querues matching results of EICopilot in the previous three strategies with a real-world online query: \"Who are the executives of Binzhou Binxin Entertainment Network Technology Co., Ltd.?\" Here, \"Binzhou\" refers to a small town in China, and \"Binxin\" is a brand name. As stated in Section 2.2.1, EICopilot would first decompose the online query to extract an entity \u2013 \"Binzhou Kaixin Entertainment Network Technology Co., Ltd.\" and identify the search intent \u2013 \u201ccompany executives\u201d. Figures 6, 7, and 8 illustrate the top \"alike queries\" matched with the online query by the three strategies. The Raw Matching strategy, which extracts queries without masking, results in examples related to general details of the targeted entity, but does"}, {"title": "4 DISCUSSIONS ON RELATED WORKS", "content": "This section explores key areas of our methodology: Text2SQL, RAG [7], and Information Retrieval (IR) [16], which enhance querying and summarization of complex enterprise data from graph databases. Traditional IR systems, typically reliant on keyword matching, struggle with synonymy, polysemy, and contextual gaps, necessitating manual intervention [16]. Leveraging large pre-trained language models promises improvements across user modeling, indexing, matching/ranking, evaluation, and user interaction components [4]. ICL allows models to adapt during inference, while RAG augments LLMs with external databases to reduce hallucinations and improve accuracy [2, 6], integrating retrieval and generation by enhancing input with retrieved data [10, 12].\nOur method overcomes traditional IR limitations by using LLMs alongside ICL and advanced masking strategies, boosting semantic comprehension and reducing manual efforts [3, 6]. We also tackle"}, {"title": "5 CONCLUSION", "content": "This paper introduces EICopilot for enterprise information search that leverages LLMs to enhance querying and summarization in large graph databases. Key innovations include automated Gremlin script generation and a novel masking strategy for precise intent recognition in ICL example matching. Empirical analysis shows that EICopilot far exceeds baseline methods in data retrieval and interpretation speed and accuracy, potentially revolutionizing large-scale knowledge graph exploration. Specifically, EICopilot reduces syntax errors to as low as 10.00% and increases execution correctness to 83.93%. These results demonstrate the superior efficacy of its automated Gremlin script generation and innovative query masking strategies over traditional methods. This research offers valuable insights into agent-based methodologies and facilitates broader industrial applications in the exploration and utilization of large-scale graph databases."}, {"title": "A DEPLOYMENT", "content": "The deployment of our system, illustrated in Figure 9, employs a distributed architecture utilizing NebulaGraph and Docker. NebulaGraph is set up to function across multiple nodes to optimize data management. The HugeGraph system comprises hundreds of millions of nodes, with each node containing an average of 150 attribute fields. The architecture consists of several Docker containers, each containing components such as nebula-metad, nebula-graphd, and nebula-storaged, which enhances modularity and scalability. This setup facilitates the seamless management of graph data and supports efficient query processing. Furthermore, we use NebulaGraph Studio for data visualization and interaction. The system is meticulously configured to enhance the performance and reliability of graph operations. Particular attention is given to data distribution and replication across nodes to ensure robustness and improved access speeds."}, {"title": "B EXAMPLES OF PROMPTS AND OUTPUTS", "content": "B.1 Prompt: Gremlin Generation.\nThe Gremlin generation prompt, as shown in Figure 10, enhances accuracy and precision in script generation by integrating knowledge graph data and business logic. This comprehensive approach improves query reliability and expressiveness while maintaining data security and aligning with business needs. The content within [] remains undisclosed due to its confidential nature related to business operations. Subsequently, we present several illustrative examples to demonstrate user inputs and the corresponding scripts"}]}