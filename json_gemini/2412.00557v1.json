{"title": "Blind Inverse Problem Solving Made Easy by Text-to-Image Latent Diffusion", "authors": ["Michail Dontas", "Yutong He", "Naoki Murata", "Yuki Mitsufuji", "J. Zico Kolter", "Ruslan Salakhutdinov"], "abstract": "Blind inverse problems, where both the target data and forward operator are unknown, are crucial to many computer vision applications. Existing methods often depend on restrictive assumptions such as additional training, operator linearity, or narrow image distributions, thus limiting their generalizability. In this work, we present LADiBI, a training-free framework that uses large-scale text-to-image diffusion models to solve blind inverse problems with minimal assumptions. By leveraging natural language prompts, LADiBI jointly models priors for both the target image and operator, allowing for flexible adaptation across a variety of tasks. Additionally, we propose a novel posterior sampling approach that combines effective operator initialization with iterative refinement, enabling LADiBI to operate without predefined operator forms. Our experiments show that LADiBI is capable of solving a broad range of image restoration tasks, including both linear and nonlinear problems, on diverse target image distributions.", "sections": [{"title": "1. Introduction", "content": "Inverse problems are fundamental to many computer vision tasks, where the goal is to recover unknown data x from observed measurements y. Formally, these problems can be expressed as $y = A(x) + n$, where A is a operator representing the forward process parametrized by 4, and n is the measurement noise. These problems are critical in fields such as medical imaging, computational photography and signal processing, as they are inherently tied to real-world scenarios like image decompression, deblurring, and super-resolution [13, 17, 41, 43]. Recently, deep learning-based methods [7, 8, 10, 22, 30, 44] have emerged as powerful tools for solving inverse problems. In particular, diffusion models offer an elegant solution that incorporates pre-trained models in diverse conditional settings, providing flexible and scalable frameworks for reconstructing high-quality data by guiding the generation process through the measurement constraints [3, 14, 19, 36, 37, 42].\nHowever, most of these efforts focus on inverse problems where the operator Af is assumed to be known. In practice, the forward operator is often unknown, leading to what are termed blind inverse problems. Solving these blind inverse problems remains a significant challenge due to their ill-posed nature. Consequently, current methods address this problem by introducing various assumptions about the prior distributions of the target data and unknown operator. These assumptions are typically incorporated through a combination of the following strategies: (1) using explicit formulas or specific neural network architectures to hand-craft inductive biases, (2) simplifying the operator with linear assumptions, (3) restricting target distributions to narrow image classes, (4) collecting measurement, operator or image datasets to train models tailored to specific tasks. While effective in certain cases, these solutions often entail significant computational and manual overhead, limited flexibility, and substantial barriers to practical deployment due to complex model training, costly data curation, unrealistic assumptions, and laborious hyperparameter tuning. These limitations raise a critical question: can we design an algorithm that applies to diverse operators and target image distributions without additional training or data collection?\nTo tackle this challenge, we formulate this problem as a Bayesian inference problem, where the optimal solution is to sample from the posterior $p(x, A\u2084|y) \u03b1 p(y|x, A\u2084)p(x, A\u2084)$. State-of-the-art diffusion-based methods often simplify this problem by assuming independence between the target image and operator distributions [8, 23, 27, 34]. Although this independence assumption reduces the modeling difficulty, we challenge its validity by observing the correlation between the target image distribution and the operator distribution, and argue that this assumption heavily restricted the flexibility of the current diffusion-based approaches. To address this problem effectively, we first propose to estimate the joint distribution $p(x, A)$ instead. While this estimation seems intractable on the first glance, there actually exists a surprisingly simple solution \u2013 large-scale pre-trained text-to-image diffusion models already capture diverse target data and measurement distributions. Moreover, many inverse problems can be described using natural language, allowing tasks like deblurring or super-resolution to be expressed through prompts such as \u201chigh-definition, clear image\" for the target and \"blurry, low-quality\" for the measurement. By simply prompting with classifier-free guidance [15], we can approximate the score of this challenging joint prior distributions across a wide range of image and operator types using the same base model, significantly extending the flexibility of the current diffusion-based framework.\nIn addition to a strong prior, an effective posterior sampling technique is also crucial for meeting measurement constraints. Existing methods generally fall into two categories: Gibbs or EM-style alternating optimization [23, 27], which suits diffusion-based setups without additional training but is sensitive to operator initialization and tuning, and a two-step approach that first estimates the operator followed by solving the non-blind problem [34], which often requires training and strong assumptions. To obtain the best of both worlds, we propose a hybrid approach: first, we obtain a reasonable initial estimate of the operator parameters, and then apply the alternating optimization to iteratively refine both operator parameters and data estimates throughout the diffusion process. Obtaining a reliable initial operator estimate can be difficult for broad functional classes like neural networks. To address this, we introduce a novel initialization scheme that leverages the pseudo-supervision signals from multiple lower-quality data estimation generated by fast posterior diffusion sampling. This approach eliminates the assumption of a specific form of operators, allowing for nonlinear blind inverse problem solving and flexible operator parametrization.\nCombining the strong prior with the effective posterior sampling technique, we introduce Language-Assisted Diffusion for Blind Inverse problems (LADIBI), a training-free method that leverages large-scale text-to-image diffusion models to solve a broad range of blind inverse problems with minimal assumptions. LADiBI can be directly applied across diverse data distributions and allows for easy specification of task-specific modeling assumptions through simple prompt adjustments. Algorithm 1 provides an overview of LADiBI, which can be easily adapted from the standard inference algorithm used in popular text-to-image diffusion models. Unlike existing methods, LADIBI requires no model retraining or reselection for different target data distributions or operator functions; instead, all prior parameterization is encoded directly in the prompt, which users can adjust as needed. Notably, we do not assume linearity of the operator, making LADIBI, to the best of our knowledge, the most generalizable approach to blind inverse problem solving in image restoration.\nWe evaluate LADiBI against state-of-the-art baselines across several blind image restoration tasks, including two linear inverse problems (motion deblurring and Gaussian deblurring) and a nonlinear inverse problem (JPEG decompression), on various image distributions, as illustrated in Figure 1. In the linear cases, our method matches the performance of the state-of-the-art approaches, which require extensive assumptions and model specifications. Additionally, LADIBI is the only method tested that successfully performs JPEG decompression without any information about the task, such as the compression algorithm, the quantization table or factors, relying solely on observations of the compressed images."}, {"title": "2. Background & Related Works", "content": "Diffusion for Inverse Problem Solving Diffusion models, also known as score-based generative models [16, 38], generate clean data samples x by iteratively refining noisy samples xt using a time-dependent score function"}, {"title": "3. Method", "content": "In this paper, we aim to tackle the problem of blind inverse problem solving defined in Equation 4. Our solution (Algorithm 1) has the following desiderata: (1) No additional training: our method should not require data collection or model training, (2) Adaptability to diverse image priors: the same model should apply to various image distributions, (3) Flexible operators: no assumptions about the operator's functional form, such as linearity or task-specific update rules, should be necessary. To make this problem feasible, we assume access to open-sourced pre-trained models.\nTo tackle this problem, we first formulate it as a Bayesian inference problem where the optimal solution is to sample from the posterior\n$p(x, A\u2084|y) xp(y|x, A\u2084)p(x, A\u2084)$.\nThis formulation allows us to decompose this problem into two parts: first obtaining a reliable estimation of the prior $p(A)$ and then maximizing the measurement likelihood $p(y|x, A4)$. This makes diffusion-based framework the ideal approach as its posterior sampling process naturally separates these two stages (by Equation 2)."}, {"title": "3.1. Obtaining a better Prior", "content": "Most existing diffusion-based methods [1, 8, 23, 27, 34, 39] avoid modeling the joint prior and instead further decompose the goal distribution as $p(x, A|y) \u03b1 p(y|x, A\u2084)p(x)p(A4)$, under the assumption that the target data distribution p(x) independently from the operator distribution p(A$). In this way, they can separately model the image and operator distribution by pre-trained diffusion models or fixed distributions and thus bypass the combinatorial complexity. However, is this truly a fair assumption?\nConsider the task of deblurring and super-resolution. A low-resolution blurry measurement may correspond to a high-resolution blurry image (e.g. an out of focus DSLR photo) if the operator is a downsampler, or to a low-resolution clear image if the operator is a blur kernel. Similarly, different target image distribution can imply different operators: for example, the estimated blur kernel should differ if the target is a realistic photo versus an Impressionist painting, even when both share the same measurement.\nThese observations suggest that p(x) and p(A) should be correlated, and previous methods can make this independence assumption because they implicitly restrict the types of operations and target images they handle. In other words, while this independence assumption reduces modeling complexity, it also significantly limits the flexibility of the resulting algorithms. Consequently, most existing methods require additional training or parametrization of the operator prior and need to switch the image prior models when the target distribution changes.\nTherefore, to build a unified training-free algorithm, we should directly model $p(x, A\u2084)$, or in the case of diffusion models, $V\u00e6\u2081 log p(xt, A4)$. On the first glance, modeling $V\u00e6 log p(xt, A\u2084)$ appears intractable. However, with large-scale pre-trained text-to-image diffusion models now widely available, we have a surprisingly simple solution:\nIn practice, the target data distribution (e.g. \"a high-resolution photo\") and the forward operation (e.g. \u201cGaussian blur\u201d) can often be effectively described in natural language. We can specify the target distribution by using its description as a positive prompt. Specifying the operator distribution is less direct, as these pre-trained models are designed to represent image distributions rather than operators. However, by leveraging classifier-free guidance (CFG) [15], we can implicitly define the operator distribution through negative prompts. For example, if the operator is Gaussian blur, an effective negative prompt can be \"blurry image, low quality\". Formally, denote positive prompt as c+ and negative prompt as c, we can approximate x log p(xt, A\u2084) as\n$Vxt log p(xt, A\u2084) \u2248 \u2207x\u2081 log p(xt|c\\_)\n+(x+log p(xt|c+) - \u221ax+ log p(xt|c))$\nwhere y > 1 is a weighting hyperparameter. This is equivalent to approximating p(x, A\u2084) as a distribution that is proportional to $p(x|c\\_)^{1-y}p(x|c+)^\u03b3$.\nWhen using latent diffusion models parameterized by 0, this corresponds to having the empirical noise prediction\n$\u0109o (zt, t) = \u20ac (zt, t, c\u2212) + (eo (zt, t, C+) \u2013 eo (zt, t, c\\_))$.\nThis way, our method not only models this seemingly extremely intractable joint distribution in a remarkably simple way, it also enable wide range of applications with diverse target image and operator distributions by leveraging the knowledge in large-scale pre-trained text-to-image diffusion models like Stable Diffusion [31]."}, {"title": "3.2. Obtaining a better Posterior", "content": "In addition to a strong prior, our final output image should also satisfy the measurement constraint.Given the problem setup in Equation 4, the measurements are subject to additive Gaussian noise n, hence $log p(y|x, A\u2084) = \\frac{1}{2\u03c3^2}||Y - A_{\u03c6}(x)||^2$. When Af is known, we can use the MPGD update rule in Equation 3 to perform posterior sampling.\nHowever, since Af is not known, the true parameters is often approximated by another set of parameters $. This approximation is usually addressed by one of the two strategies: an alternating optimization scheme that jointly approximates \u00e6 and 4, or obtaining a reliable & first then solving a non-blind inverse problem. The first approach is well-suited for training-free settings as it can be well integrated with diffusion-based methods, but it is often highly sensitive to & initialization and tuning. The second approach can perform well if a strong 4 is obtained, though it usually requires training and additional assumptions or restrictions. We propose to combine the two strategies above: we first obtain a reliable initial 4, and then perform an alternating optimization to iteratively refine both the operator parameter and data estimations throughout the diffusion process.\nInitialization In some cases, initializing the operator parameters is straightforward - for example, for a slight blur, an identity function can be a reasonable stating point. Alternatively, reliable operator priors, such as the pre-trained prior in BlindDPS [8] or the Gaussian prior in GibbsDDRM [27] for linear operators, can also provide effective initializations for simple kernels. However, when the operator requires complex functions like neural networks, obtaining good initializations becomes more challenging.\nTo address this, we propose a new algorithm for general operator initialization by drawing further inspiration from alternating optimization algorithms. Note that since the goal here is only to initialize 6, the quality of intermediate x estimates is less critical as long as they provide a useful signal. Unlike other diffusion-based methods that alternate optimization targets at each diffusion step, we use SDEdit [26] and MPGD [14] with very few diffusion steps to quickly obtain a batch of a estimates. We then perform maximum likelihood estimation (MLE) on these estimates to update using Adam optimizer. As detailed in Algorithm 2, repeating this process can leverage the diffusion prior to quickly converge to a reliable starting point for $. Notice that we only assume that & can be approximated by differentiable functions, allowing Af to be parameterized by general model families such as neural networks. Moreover, as mentioned earlier, any well-performing operator priors can be seamlessly integrated into our framework.\nIterative Refinement After initializing 4, we then perform another alternating optimization scheme to refine both the operator and the data. In particular, we alternate between updating 20|t using MPGD guidance with Af fixed and updating the MLE estimation of f using Adam with Zolt fixed throughout the diffusion process.\nSince unlike GibbsDDRM, which uses Langevin dynamics to update the operator, we solve for a local optimum. Therefore, it's reasonable not to update the operator too frequently. Empirically, we find that periodic updates to the operator in combination of the time-traveling technique [25, 42] yield the best results\nIn addition, since MPGD supports any differentiable loss function, we can incorporate techniques like regularization to further improve the visual quality. In practice, we use\n$20|t = 20|t-CtVz0|t (||y-A\u2084(D(zo|t))||2+1zLPIPS(D(zo|t), y))$\nas the MPGD update rule and\n$L\u00f8(zo\t, $) = ||y - A\u2084(D(zo|t))||2 + 1$||$||1$\nas the Adam objective. Here LPIPS(\u00b7) denotes the LPIPS distance between two images and || \u00b7 ||1 denotes the L\u2081 regularization term. Az and X are adjustable hyperparameters.\nBy combining large-scale language-conditioned diffusion priors, effective operator initializations, and the iterative refinement process described above, we introduce LADIBI (Algorithm 1), a new training-free algorithm for blind inverse problem solving that supports diverse target image distributions and flexible operators."}, {"title": "4. Experiments", "content": "We empirically verify the performance of our method with two linear deblurring tasks, Gaussian deblurring and motion deblurring, and a non-linear restoration task, JPEG decompression. Here we provide the details of our experiments.\nDatasets We conduct quantitative comparisons on the datasets FFHQ 256 \u00d7 256 [18] and AFHQ-dog 256 \u00d7 256 [6]. We use a size of 1000 images for FFHQ and 500 for AFHQ, following the setting in Murata et al. [27].\nBaselines We compare our method against other state-of-the-art approaches as baselines. Specifically, we choose Pan-10 [28] and Pan-DCP [29] as the optimization-based method, SelfDeblur [30] as the self-supervised approach, PRNet [44] and DeblurGANv2 [22] as the supervised baselines, and BlindDPS [8] and GibbsDDRM [27] as the diffusion-based methods. All baselines are experiments using their open-sourced code and pre-trained models, whose details are provided in the appendix.\nImplementation Details We conduct all experiments an NVIDIA A6000 GPU. We use Stable Diffusion 1.4 [31], DDIM 200-step noise scheduling, and T = 150, M = 4 for all tasks. We set positive prompts as \u201ca clear headshot of a person\" and \"a clear headshot of an animal\" for FFHQ and AFHQ experiments respectively. We adjust negative prompts according to each individual task, and the details will be provided in the following sections.\nEvaluation Metrics We evaluate our method and the baselines with three quantitative metrics: LPIPS [46], PSNR and KID [4]. Each metric has its own significance and reveals a different set of characteristics about performance. In particular, PSNR directly measures the pixel-by-pixel accuracy of the reconstructed image compared to the original, while LPIPS measures how similar two images are in a way that reflects human perception. Finally, KID evaluates the image fidelity on a distribution level."}, {"title": "4.2. Blind Linear Deblurring", "content": "We first test our method against the baselines on linear de-blurring, which is the design space of most baselines. We evaluate all methods on two types of blur kernels: Gaussian blur and motion blur.\nSetup To generate measurements, we apply randomly generated motion blur kernels with intensity 0.5 and Gaussian blur kernels with standard deviation 3.0 respectively. The final measurements are derived by applying a pixel-wise Gaussian noise with \u03c3 = 0.02. We use a 61 x 61 convolutional matrix as 6 and we initialize it as a Gaussian kernel of intensity 6.0 following Murata et al. [27]. We adjust the negative prompts to the potential negative image artifacts induced by the degradation operation, such as \u201clowres, blurry, DSLR effect, poorly drawn face, deformed, bad proportions, ...\u201d for Gaussian blur, \u201cshaken image, morbid, mutilated, text in image, disfigured, ...\u201d for motion blur. Full prompts are included in the appendix.\nResults Table 2 and Figure 2 show results on blind linear deblurring. Our method matches the performance the state-of-the-art method GibbsDDRM, which is explicitly designed to solving linear problems using SVDs. In fact, GibbsDDRM's highly specialized design makes it so sensitive that even small discrepancies (e.g. kernel padding) between their modeling assumption and the ground truth operator can result in significant performance degradation. Moreover, although BlindDPS and GibbsDDRM use diffusion models that are trained on the exact data distributions tested, our method can still match or outperform them with the large-scale pre-trained model. In addition, even though supervised methods can obtain higher PSNR, our method produces the fewest artifacts, which is also validated by the LPIPS and KID scores. Overall, our method offers a consistently competitive performance on linear tasks, even though our method is designed for more general applications."}, {"title": "4.3. Blind JPEG Decompression", "content": "We further compare our method with baselines on JPEG decompression, a particularly challenging task due to the non-linear, non-differentiable nature of JPEG compression. Unlike traditional settings, our experiments provide no task-specific knowledge, such as the compression algorithm, quantization table, or factors \u2013 algorithms rely solely on the measurement images.\nSetup We generate measurements using JPEG compression with a quantization factor of 2. We use a neural network with a 3-layer U-net [32] to parametrize the operator. The operator is initialized using Algorithm 2 with M = 8 and N = 4. We use phrases including \u201cpixelated, low quality, jpeg artifacts, deformed, bad proportions, ...\u201d as negative prompt, whose full version is provided in the appendix.\nResults Table 3 and Figure 3 present the results on the JPEG decompression task. It is evident through both quantitative and qualitative results that our method is the only one capable of enhancing the fidelity of the images and maintaining consistency to measurements. Unlike the baselines, which struggle with this task due to their limited posterior formulations, our flexible framework adapts to approximate this challenging operator and produces high quality images."}, {"title": "4.4. Ablation Studies", "content": "To showcase the effectiveness of each part of our algorithm, we conduct ablation study on AFHQ dataset with JPEG decompression task. In particular, we test the importance of suitable ad-hoc prompts, the use of MPGD guidance, and the operator initialization for neural network A. in-between diffusion steps. We keep SDEdit in all settings to encode the measurement information for fair comparisons. As shown in Table 4, each of the aforementioned components plays a significant role in our scheme and is indispensable for producing high quality results."}, {"title": "4.5. Style Preserving Deblurring", "content": "In order to demonstrate our method's ability to solve blind inverse problems from a wider range of image distributions, we present indicative examples of Gaussian and motion deblurring on Monet paintings in Figure 4. We use the same negative prompts as in the previous experiments and \"a portrait of a person as a Monet style painting\" as positive prompts. We notice that, although the images portray human faces, the baseline method using models trained on realistic human face images cannot accurately solve the problem, while our method effectively generates images consistent with both the measurement image and the painting style present in the ground truth image."}, {"title": "5. Conclusion", "content": "In this work, we propose LADIBI, a new training-free algorithm to solving blind inverse problems in image restoration using a large-scale pre-trained text-to-image diffusion model. Our method leverages text prompts as well as posterior guidance on intermediate diffusion steps to guide the generation process towards clean reconstructions based on degraded measurements, in cases where the degradation operation is unknown. Experimental results demonstrate that LADIBI achieves competitive performance on tasks with diverse operator and is also capable of covering a wider range of image distributions compared to baselines."}, {"title": "A. Additional Implementation Details", "content": "We offer more detailed information regarding the implementation setup for Algorithms 1 and 2. All experiments are conducted using an NVIDIA A6000 GPU. In an effort to make our methodology generalizable and extensible to other inverse problems, we attempt to maintain the same hyper-parameter values across tasks wherever possible. Each hyper-parameter value has been chosen after conducting preliminary experiments for a specific range and opting for the value that offers the best performance. Indicative examples of such experiments are shown in C. In particular, we run Algorithm 1 for T = 150 timesteps while performing 4 repetitions as part of the time-traveling strategy. We encode the measurement as \u00e6\u0442 by applying the forward diffusion process up to timestep 800. In parallel with the reverse diffusion process, we update f every 5 timesteps, each time conducting K = 150 gradient steps. We adust the ct and the A parameters of Equations 8 and 9 to 30 and 2 respectively. In terms of the operator initialization process described by Algorithm 2, we make use of a batch of N = 4 samples and run M = 8 iterations, each comprising T\u2081 = 60 timesteps.\nAdditionally, schematic overviews of Algorithms 1 and 2 are presented in Figures 5 and 6.\nFurthermore, there are some parameters in our approach for which employing a task-aware setup strategy is essential for state-of-the-art performance. These are the prompt sentences as well as the architecture of $. Here we provide details with respect to these parameters according to each restoration task:"}, {"title": "Motion Deblurring", "content": "\u2022 Positive prompts: \"a clear headshot of a person/animal\u201d\n\u2022 Negative prompts: \"shaken image, motion blur, pixelated, lowres, text, error, cropped, worst quality, blurry ears, low quality, ugly, duplicate, morbid, mutilated, poorly drawn face, mutation, deformed, blurry, dehydrated, blurry hair, bad anatomy, bad proportions, disfigured, gross proportions\"\n\u2022 architecture: A single 61 \u00d7 61 convolutional block with 3 input and 3 output channels."}, {"title": "Gaussian Deblurring", "content": "\u2022 Positive prompts: \"a clear headshot of a person/animal\"\n\u2022 Negative prompts: \"blurry, gaussian blur, lowres, text, error, cropped, worst quality, blurry ears, low quality, ugly, duplicate, morbid, mutilated, text in image, DSLR effect, poorly drawn face, mutation, deformed, dehydrated, blurry hair, bad anatomy, bad proportions, disfigured, gross proportions\"\n\u2022 architecture: A single 61 \u00d7 61 convolutional block with 3 input and 3 output channels."}, {"title": "JPEG Decompression", "content": "\u2022 Positive prompts: \"a clear headshot of a person/animal\"\n\u2022 Negative prompts: \"pixelated, lowres, text, error, cropped, worst quality, blurry ears, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, text in image, DSLR effect, poorly drawn face, mutation, deformed, blurry, dehydrated, blurry hair, bad anatomy, bad proportions, disfigured, gross proportions\"\n\u2022 architecture: A neural network with a typical 3-layer U-net [32] architecture. Each layer consists of 2 convolutional blocks of size 3 \u00d7 3 with ReLU activations and number of input and output channels ranging from 32 to 128."}, {"title": "B. Additional Results", "content": "We present more detailed experimental results on all benchmark tasks. In specific, Table 5 shows quantitative results on the JPEG decompression task, including the optimization-based Pan-10 and Pan-DCP methods. Moreover, Figures 7, 8 and 9 offer more qualitative comparisons against baseline methods on motion deblurring, gaussian deblurring and JPEG decompression respectively. Finally, in Fig. 10 we include comparisons against selected baseline methods on the 3 benchmark tasks using a set of Monet and Van Gogh portrait paintings as ground truth images."}, {"title": "C. Additional Ablation Study", "content": "We carefully adjust each parameter of our methodology to the value that offers the best overall results by conducting comparative experiments and in this section we offer some indicative examples of such tests. All hyper-parameter tuning experiments have been performed on the motion deblurring task using the AFHQ dataset.\nFigure 11 presents both the LPIPS and KID score for the value of the timestep at which we encode the measurement using the forward diffusion process. Both metrics form a U-shape curve, which results from the following fact about encoding the measurement image; if we make the encoding timestep too large, most of the information about the measurement has been replaced by noise which does not allow the sampling process to leverage useful features of the degraded image. On the other hand, if the timestep is too small, the sampling process is not equipped with enough scheduled variance to reach the target prior distribution.\nIn addition, Figure 12 presents the effectiveness of taking advantage of the time-traveling strategy. More time-traveling boosts the overall performance up to a specific value, after which we begin to notice a trade-off between perceptual clarity of the image and fidelity to the target distribution."}, {"title": "D. Limitations and Future Works", "content": "In this section, we discuss the limitation of LADIBI and potential future works to address these problems.\nSimilar to many training-free diffusion posterior sampling algorithms [8, 9, 14, 27], our method is also sensitive to hyper-parameter tuning. We have provided details about our hyperparameter choices in the previous sections, and we will release our code in a public repository upon publication of this paper.\nAnother notable drawback of our method is that LADIBI requires significantly longer inference time in comparison to the best performing baseline (i.e. GibbsDDRM [27]) in order to obtain high quality restorations. With the general operator initialization, our algorithm can take around 5 minutes to complete on a single NVIDIA A6000 GPU while GibbsDDRM only takes around 30 seconds. Although this is justifiable by the larger optimization space that we operate on, investigating on how to reduce the inference time requirement is an interesting and critical next step for our work.\nLastly we would like to note that, while neural networks, as demonstrated in the previous sections, can serve as a general model family for various operator functional classes and achieve satisfactory results, obtaining state-of-the-art performance for linear tasks within a reasonable inference time still requires resorting to a linear kernel as the estimated operator. Exploring neural network architectures that can easily generalize across different operator functional classes while achieving state-of-the-art results efficiently remains an exciting direction for future work."}, {"title": "E. Broader Impact Statement", "content": "Lastly, since our algorithm leverages large pre-trained image generative models, we would like to address the ethical concerns, societal impact as well as the potential harm that can be caused by our method when being used inappropriately.\nAs a consequence of using large pre-trained text-to-image generative models, our method also inherits potential risks associated with these pre-trained models, including the propagation of biases, copyright infringement and the possibility of generating harmful content. We recognize the significance of these ethical challenges and are dedicated to responsible Al research practices that prevent reinforcing these ethical considerations. Upon the release our code, we are committed to implement and actively update safeguards in our public repository to ensure safer and more ethical content generation practices."}]}