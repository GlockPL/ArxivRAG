{"title": "An Unbiased Risk Estimator for Partial Label Learning with Augmented Classes", "authors": ["JIAYU HU", "SENLIN SHU", "BEIBEI LI", "TAO XIANG", "ZHONGSHI HE"], "abstract": "Partial Label Learning (PLL) is a typical weakly supervised learning task, which assumes each training instance is annotated with a set\nof candidate labels containing the ground-truth label. Recent PLL methods adopt identification-based disambiguation to alleviate\nthe influence of false positive labels and achieve promising performance. However, they require all classes in the test set to have\nappeared in the training set, ignoring the fact that new classes will keep emerging in real applications. To address this issue, in this\npaper, we focus on the problem of Partial Label Learning with Augmented Class (PLLAC), where one or more augmented classes are\nnot visible in the training stage but appear in the inference stage. Specifically, we propose an unbiased risk estimator with theoretical\nguarantees for PLLAC, which estimates the distribution of augmented classes by differentiating the distribution of known classes from\nunlabeled data and can be equipped with arbitrary PLL loss functions. Besides, we provide a theoretical analysis of the estimation error\nbound of the estimator, which guarantees the convergence of the empirical risk minimizer to the true risk minimizer as the number\nof training data tends to infinity. Furthermore, we add a risk-penalty regularization term in the optimization objective to alleviate\nthe influence of the over-fitting issue caused by negative empirical risk. Extensive experiments on benchmark, UCI and real-world\ndatasets demonstrate the effectiveness of the proposed approach.", "sections": [{"title": "1 INTRODUCTION", "content": "Supervised learning models have been vigorously developed over the past few years [34]. Although having achieved\npromising performance, they rely on a large number of accurately labeled instances to complete training, which is\nnot only costly but also suffers from difficulties in data acquisition caused by privacy and security issues. Weakly\nsupervised learning [61], which utilizes incomplete labels, inaccurate labels and inexact labels to train models, has\ndrawn extensive attention in recent years. Several representative tasks have been investigated, such as semi-supervised\nlearning [8, 64], noisy-label learning [19, 56], partial-label learning [49], multi-label learning [18, 37, 40, 55, 58], etc.\nThey have been widely employed in various real-world scenarios, including data annotation [36], disease diagnosis\n[43], object segmentation [23, 45], object detection [21] and text classification [30]."}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Partial Label Learning", "content": "Existing PLL methods adopt label disambiguation to mitigate the influence of label ambiguity on model training. They\ncan be roughly divided into average-based methods [27] and identification-based methods [11, 14] according to different\ndisambiguation strategies. Average-based methods treat each candidate label of training instances equally and make\nprediction by averaging the outputs on each candidate label. Though simple to implement, they make the ground-truth\nlabel overwhelmed by false positive labels easily. Identification-based methods try to identify the ground-truth label\nfrom the candidate label set, so as to reduce the influence of false positive labels. Some of them adopt two-phase strategy\n[59], i.e., first refine label confidence, then learn the classifier, while others progressively refine confidence during\nlearning the classifier [52]. Early PLL methods are usually linear or kernel-based models, which are hard to deal with\nlarge-scale datasets. With the powerful modeling capability and the rapid development of deep learning, deep PLL\nmethods, which can handle high-dimensional features, have drawn attentions in recent years. Most deep PLL models\nare identification-based methods, for example, RC [16], PRODEN [29] and LWS [46] estimate label confidence and\ntrain the model with it iteratively. Furthermore, PiCO [44] and DPLL [47] explore contrastive learning and manifold\nconsistency in deep PLL, respectively. However, existing PLL methods ignore the fact that new labels may emerge\nduring the inference process in practice and are not able to deal with the augmented classes in partial label learning."}, {"title": "2.2 Open-Set Recognition", "content": "Open-set recognition (OSR) considers a more realistic scenario, where incomplete knowledge of the world exists at\ntraining time and unknown classes at test time appear. [38]. Studies for OSR problem could divided into two categories:\ndiscriminative models and generative models [17]. Most methods based on discriminative model study the relationship\nbetween known classes and augmented classes, like using open space risk based on SVM [39] as the traditional ML-based\nmethods, a Nearest Non-Outlier (NNO) algorithm [3] is established for open-set recognition by using the Nearest\nClass Mean (NCM) classifier [31] as distance-based method. The way based on DNN is to exploit convolutional neural\nnetwork which applies a threshold on the output probability, that is OpenMax[4], using an alternative for the SoftMax\nfunction as the final layer of the network [5]. Learning with Augmented classes is similar to OSR problem in Pattern\nRecognition for they both deal with the problem that to classify the augmented classes which are unseen in training\nstage but emerge in test phase. Different from OSR problem, LAC studies on how to classify all the classes appeared in\ntest stage, while OSR focuses on whether observed instances are out of distribution."}, {"title": "2.3 Learning with Augmented Classes", "content": "Learning with augmented classes (LAC) is a problem where augmented classes unobserved in the training stage may\nemerge in the test phase. It is a main task of class-incremental learning [42, 63]. The main challenge of LAC is that no\ninstances from augmented classes appear in the training phase. Motivated by that unlabeled data can be easily collected\nin real-world application and unlabeled data help improve the classification performance when the number of training\ninstances is limited [7, 62, 64], Da et al. [13] present the LACU (Learning with Augmented Class with Unlabeled data)\nframework and the LACU-SVM approach to the learning with augmented class problem. Considering the distribution\ninformation of augmented classes may be contained in unlabeled data and estimated by differentiating the distribution\nof known classes from unlabeled data, a recent study proposes an unbiased risk estimator (URE) under class shift\ncondition [60], which exploits unlabeled data drawn from test distribution. However, this URE is only restricted to\nthe specific type of one-versus-rest loss functions for multi-class classification. Therefore, Shu et al. [41] propose\na Generalized Unbiased Risk Estimator (GURE) which can be equipped with arbitrary loss functions and provide a\ntheoretical analysis on the estimation error bound. Under the assumption that the distribution of known classes would\nnot change when augmented classes emerged in test phase, both URE and GURE introduce the class shift condition to\ndepict the relationship between known and augmented class, then the testing distribution $P_{te}$ can be obtained as:\n$P_{te} = \\theta P_{kc} + (1-\\theta) P_{ac}$                                                                             (1)\nwhere $\\theta \\in [0, 1]$ is a mixture proportion of the distribution of known classes $P_{kc}$ and augmented classes $P_{ac}$.\nHowever, these methods for the LAC problem are all towards supervised learning and not applicable to partially\nlabeled datasets."}, {"title": "3 THE PROPOSED METHOD", "content": "In this section, we first present the formulation of the PLLAC problem. Next, we propose an unbiased risk estimator for\nthe PLLAC problem and provide theoretical analysis for it. Then, we identify the potential over-fitting issue of unbiased\nrisk estimator and establish a risk-penalty regularization to alleviate the over-fitting problem."}, {"title": "3.1 Problem Formulation", "content": "We represent the feature space and label space of partial label data respectively as $\\mathcal{X}$, $\\mathcal{Y}$, where $\\mathcal{X} \\in \\mathbb{R}^d$ and $\\mathcal{Y} =$\n${1, ..., k}$, $d$ is feature dimension and $k$ is the number of classes. In conventional PLL, we are given a $k$-classes PLL\ndataset $\\mathcal{D}_{PL} = \\{x_i, S_i\\}_{i=1}^n$ independently and identically drawn from an underlying distribution with probability\ndensity $P_{PL}$ defined over $\\mathcal{X} \\times \\mathcal{Y}$, where each training sample $x_i$ is associated with a candidate label set $S_i$, $S_i \\in \\mathcal{C}$, and\n$\\mathcal{C} = \\{2^\\mathcal{Y} \\backslash \\emptyset \\backslash \\mathcal{Y}\\}$. The goal of PLL is to train a classifier $f : \\mathcal{X} \\rightarrow \\mathcal{Y}$ with considering the training set and test set\nare under the same data distribution. However, in the test phase of the PLLAC, augmented classes unobserved in the\ntraining phase may emerge. Due to uncertainty and inaccessibility of the number of augmented classes in test set,\nthese augmented classes would be labeled as one class named $a_c$ and the augmented label space could be denoted as\n$\\mathcal{Y}' = \\{1, ..., k, a_c\\}$.\nIn addition, we assume that in the training stage, except for the partially labeled data, a set of unlabeled data sampled\nfrom the test set, denoted as $\\mathcal{D}_u = \\{x_i\\}_{i=1}^{n_u} \\sim P_{te}(x, y)$, is available and could be used in training stage. Note that it is\nfeasible to use unlabeled data from test set when training the model, because in most situations, it is easy to obtain\ntest set or open-set data with the same distribution as the test set. The unlabeled data enrich the features of training"}, {"title": "3.2 Unbiased Risk Estimator", "content": "Similar to LAC, in PLLAC, the distribution of data from the augmented classes is also inaccessible. Therefore, we\nfollow the class shift condition [60] in Eq. 1 to describe the relationship between the distribution of known classes and\naugmented classes. Specifically, on accurately labeled datasets, the distribution of known classes can be calculated\nby $P_{kc} = \\sum_{j=1}^k P(x, y = j)$. However, in PLLAC, only partial labels are available and the distribution is calculated by\n$P_{PL} = \\sum_{S_v \\in C} p(x, S = S_v)$. Fortunately, we find that the two are equivalent by the following derivation,\n$\\begin{aligned} P_{kc} = \\sum_{j=1}^k p(x, y = j) &= \\sum_{j=1}^k \\sum_{v=1}^C p(y = j|x, S_v)p(x, S = S_v) \\\\ &= \\sum_{v=1}^C \\sum_{j=1}^k p(y = j|x, S_v)p(x, S = S_v) \\\\ &= \\sum_{v=1}^C p(x, S = S_v) = P_{PL}, \\end{aligned}$                                                                        (2)\nwhere $p(y = j|x, S_v)$ indicates the probability that $j$ is the true label with the given data $(x, S_v)$ and $\\sum_{j=1}^k p(y =\nj|x, S_v) = 1$. Therefore, we obtain the following distribution relationship in PLLAC by substituting $P_{kc}$ with $P_{PL}$:\n$P_{te} = \\theta P_{PL} + (1-\\theta) P_{ac}$.                                                                                                    (3)\nLet $f(x) \\in \\mathbb{R}^{k+1}$ denote the classification probability of instance $x$ in $k + 1$ classes, $l_{PLL}(\\cdot)$ represents a PLL loss\nfunction, $l(\\cdot)$ is multi-class classification loss function, e.g., the categorical cross-entropy loss. The loss of instance $x$ in\npartial label set $S$ and $a_c$ class can be represented respectively as $l_{PLL}(f(x), S)$ and $l (f(x), a_c)$. According to Eq. (3), the\nrisk estimator of the PLLAC problem over test set can be defined as:\n$\\mathcal{R}(f) = \\theta\\mathbb{E}_{(x,S)\\sim P_{PL}} [l_{PLL} (f(x), S)] + (1 - \\theta)\\mathbb{E}_{x\\sim P_{ac}} [l (f(x), a_c)].$                                                     (4)"}, {"title": "3.3 Theoretical Analysis", "content": "Here, we establish an estimation error bound for our proposed unbiased risk estimator and prove that the estimator is\nconsistent.\nDefinition 1 (Rademacher Complexity [2]) Let n be a positive integer, $x_1, ..., x_n$ be independent and identically distributed\nrandom variables drawn from a probability distribution with density $\\mu$, $\\mathcal{F} = \\{f : \\mathcal{X} \\rightarrow \\mathbb{R}\\}$ be a class of measurable\nfunctions. Then the expected Rademacher complexity of $\\mathcal{F}$ is defined as\n$\\mathfrak{R}_n(\\mathcal{F}) = \\mathbb{E}_{x_1,...,x_n\\sim \\mu} \\mathbb{E}_{\\sigma} \\sup_{f\\in \\mathcal{F}} \\frac{1}{n} |\\sum_{i=1}^n \\sigma_i f(x_i)|$                                                                     (9)\nwhere $\\sigma = (\\sigma_1, ..., \\sigma_n)$ are Rademacher variables taking the value from $\\{-1,+1\\}$ with even probabilities."}, {"title": "3.4 Overfitting of Unbiased Risk Estimator", "content": "Considering the classification loss on class $a_c$ we used in the experiment is cross-entropy loss, which is unbounded\nabove, the third term in the URE $\\mathcal{R}(f)$ could be unbounded below. Then, during training, the loss in the training stage\nwould steadily decrease and cause over-fitting issue. As shown in Figure 2, during the first 20 epochs, the training loss\ndecreases but does not fall below 0, and the accuracy on the training set increases accordingly. However, when the\nnumber of epochs increases, the training loss does not converge after it decreases below 0, resulting in the occurrence\nof overfitting issue, and the corresponding accuracy declines.\nPrevious work solves the overfitting problem by regularization [41], motivated by this, we add a regularization\nterm to alleviate the influence of the negative empirical risk. Notice that in $\\mathcal{R}_u$, the second and third term are both in\nthe right side of Eq. (6). Meanwhile, the left side is non-negative due to 1 \u2013 $\\theta$ and $l (f(x), a_c)$ would not be below 0.\nTherefore, we could choose these two terms as $\\mathcal{R}_{PAC}$, which should also be non-negative to be the regularization term.\nThat is:\n$\\mathcal{R}_{PAC} = \\frac{\\theta}{n_u} \\sum_{j=1}^{n_u} l(f(x_i), a_c) - \\frac{\\theta}{n} \\sum_{i=1}^{n} l(f(x_i), a_c).$                                                                                                  (11)"}, {"title": "4 EXPERIMENTS", "content": ""}, {"title": "4.1 Experimental Setup", "content": ""}, {"title": "4.2 Impact of Partial Label Learning Losses", "content": "As stated in Section 3.2, $l_{PLL}$ in the first term of the derived URE $\\mathcal{R}_u$ can be any partial label learning losses. In this\nsection, we choose three partial label learning losses including RC [16], CC [16], PRODEN [29] and LWPLL [46], to\ninstantiate $l_{PLL}$ and investigate the impact of partial label learning losses on three metrics: accuracy, Macro F1 and\nAUC. As shown in Table 6, PLLAC equipped with RC and PRODEN losses achieves more than 90% accuracy on MNIST\nand most UCI datasets, which shows the effectiveness of our PLLAC methods. Moreover, RC and PRODEN are overall"}, {"title": "4.3 Comparison Experiments", "content": "Table 7, 8 report the results of comparison experiments on benchmark datasets, Table 9 reports the results of that on\nreal-world dataset. We could conclude our observations as follows:\nFirst of all, whether on benchmark datasets or real-world datasets, our proposed method significantly outperforms\nthe other compared methods in three different metrics, which fully demonstrates the effectiveness of $PLLAC_{Reg}$ method\nin solving PLLAC problems. This may be because $PLLAC_{Reg}$ method makes full use of unlabeled data which includes\nclass in the training stage, and could implicitly learn the distribution of augmented class from unlabeled data and partial\nlabeled data, which helps to accurately identify augmented classes in the test set.\nMeanwhile, we found that though some comparison methods can solve the PLLAC problem to a certain degree\nthrough the heuristic classification threshold setting, their performance varies greatly in different datasets and is not\nstable enough. This may due to the feature discrimination of instances from different classes is different with datasets\nvarying. For example, if the features of instances in class $a_c$ is highly similar to those of instances in class $k_c$, it may be\nwrongly classified into the known class with a high probability, resulting in prediction failure. The heuristic threshold\nsetting method is difficult to flexibly adapt to different datasets, which further reflects the necessity of designing models\nfor PLLAC problems.\nIn addition, we find that the instance-dependent PLL model VALEN performs better on the real-world datasets\nthan on the benchmark datasets. This is because the benchmark PLL dataset adopts a uniform partial label generation\nprocess, which is different from the assumption of VALEN. In real-world datasets, the partial labels is more likely to be\ninstance-dependent, thus VALEN performs better.\nFinally, we find that MAE, a complementary learning method, is a strong competitor, even surpassing compared PLL\nmethods on some datasets. The advantage of transforming PLL into complementary learning over direct PLL is that it\ncan learn from a large number of accurate supervised signals, i.e., instances must not belong to their non-candidate\nlabels. Most PLL methods try to identify the ground-truth label from the candidate label set but may suffer from error"}, {"title": "4.4 Performance of increasing unlabeled instances", "content": "The Theorem 1 in Section 3.3 claims that the performance of our proposed methods should be improved when more\ntraining instances are available. In this section, we verify this finding empirically by performing experiments on the\nUCI datasets. It is natural for the classifier to get better as the number of partially labeled data increases, so we focus on\nthe effect of the increase in unlabeled data on the performance. We keep the number of partially labeled data constant\nand vary the number of unlabeled instances from 200 to 2000. The results in Figure 3 show that when the number of\nunlabeled instances is increasing, the accuracy would increase first and then would gradually converge to an optimal\nvalue, which supports the derived error estimation bound in Theorem 1."}, {"title": "4.5 Analysis of Regularization parameter", "content": "In this section, we first investigate the impact of risk-regularization by comparing the original PLLAC with a constructed\nmodel variant by removing the regularization term and optimizing the unbiased risk estimator $\\mathcal{R}_u (f)$ directly for model"}, {"title": "4.6 Influence of the mixture proportion", "content": "To show the influence of the mixture proportion $\\theta$, we conduct experiments on the Usps and Optdigits datasets by\nvarying the preseted mixture proportion $\\hat{\\theta}$ from 0.1 to 1 under different values of the true mixture proportion $\\theta$. As\nshown in Figure 5 (a)-(b), performance improves as the estimated $\\hat{\\theta}$ approaches the true mixture proportion $\\theta$, so it\nis important to estimate the true proportion accurately. Additionally, larger $\\hat{\\theta}$ could achieve better performance than\nsmaller one in the case of inaccurate estimates."}, {"title": "4.7 Handling Class Shift Condition", "content": "To show our proposed method ability of handling more complex situation, we conduct experiments on Optdigits and\nUsps with class prior shift. Specifically, we select eight known classes and the rest is augmented classes, varying the\npreseted the mixture proportion $\\theta$ in $\\{0.4, 0.5, 0.6, 0.7, 0.8\\}$, which means the distribution proportion of known classes\nand augmented classes is set by it. Then we use $\\alpha$, selected in $\\{0, 0.1, 0.3, 0.5, 0.7, 0.9\\}$ to control the shift intensity\nand reset the prior of eight known classes to $\\{1 - \\alpha, 1 - \\frac{\\alpha}{3}, 1, 1, 1, 1, 1 + \\frac{\\alpha}{3}, 1 + \\alpha\\}$ in test data and\nFigure 5 (c)-(d) reports the accuracy for different mixture proportion with different $\\alpha$. As shown in Figure 5 (c)-(d),\nperformance of our method would not fluctuate greatly when $\\alpha$ changes. This observation suggests that our proposed\nmethod effectively handles changing learning environments and is robust to class shift conditions, meaning that its\nperformance does not degrade when class prior shifts."}, {"title": "5 CONCLUSION", "content": "In this paper, we investigate the problem of partial label learning with augmented classes and propose an unbiased\nrisk estimator for it. We derive an estimation error bound for our methods, which ensures the optimal parametric\nconvergence rate. Besides, to alleviate the over-fitting issue caused by negative empirical risk, we add a risk-penalty\nregularization term. Extensive comparison experiments on datasets prove that our proposed method is superior to other\ncomparison methods, which verifies its effectiveness. Our method paves the way for the study of PLLAC. In the future,\nwe will study more complex settings, such as the LAC tasks in scenarios such as instance-dependent PLL and noisy\npartial label learning, and apply the proposed methods to real-world scenarios."}, {"title": "A PROOF FOR THEOREM 1.", "content": "Our proof of the estimation error bound is based on Rademacher complexity. Recall that the unbiased risk estimator we\nderived is represented as follows:\n$\\mathcal{R}_u (f) = \\theta [\\frac{1}{n} \\sum_{i=1}^n l_{PLL} (f(x_i), S_i) - \\frac{1}{n} \\sum_{i=1}^n l(f(x_i), a_c)] + \\frac{1}{m} \\sum_{i=1}^m [l(f(x_i), a_c)]$\nLet us further introduce\n$\\begin{aligned} \\mathcal{R}_{kac} (f) &= \\theta [\\frac{1}{n} \\sum_{i=1}^n l_{PLL} (f(x_i), Y_i) - l(f(x_i), a_c)]\\\\ &= \\theta \\frac{1}{n} \\sum_{i=1}^n [\\sum_{\\gamma_i \\in S_i} \\frac{p(y_i = \\gamma | x_i)}{\\sum_{\\theta \\in S_i} p(y_i = \\theta | x_i)} l(f(x_i), o) - l(f(x_i), a_c)] \\\\ \\mathcal{R}_{tac}(f) &= \\frac{1}{m} \\sum_{j=1}^m l(f(x_j), a_c) \\\\ \\mathcal{R}_{kac}(f) &= \\mathbb{E}_{(x,S)\\sim P_{kc}} [l_{PLL} (f(x), S) - l(f(x), a_c)] \\\\ \\mathcal{R}_{tac}(f) &= \\mathbb{E}_{x\\sim P_{te}} [l(f(x), a_c)] \\end{aligned}$\nLemma 1. Assume the loss function l(f(x), y) is p-Lipschitz with respect to f(x)(0 < p < \u221e) for all y \u2208 Y.Then, the\nfollowing inequality holds:\n$\\mathfrak{R}_n (G_1) \\le \\sqrt{2p} \\sum_{y=1}^k \\mathfrak{R}_n (F_y)$"}, {"title": "Proof", "content": "where\n$\\begin{aligned} G_1 = \\{(x, y) \\mapsto \\sum_{i=1}^k p(y=i|x) \\cdot l(f(x), i) | f \\in F \\} \\\\ F_y = \\{f : x \\mapsto f_y(x) | f \\in F \\} \\\\ \\mathfrak{R}_n (F_y) = \\mathbb{E}_{P(x)} \\mathbb{E}_{\\sigma} \\sup_{f \\in F_y} |\\frac{1}{n} \\sum_{i=1}^n \\sigma i f (x_i)| \\end{aligned}$\nWe introduce $p_i(x) = \\frac{p(y=i|x)}{\\sum_{j \\in Y}p(y=j|x)}$ for each instance (x, Y). And we have $0 \\le p_i(x) \\le 1, \\forall i \\in [k]$ and\n$\\sum_{i=1}^k p_i(x) = 1$ since $p_i(x) = 0$ if $i \\notin Y$. Then we can obtain $\\mathfrak{R}_n(G_1) \\le \\mathfrak{R}_n(L\\circ F)$ where $L\\circ F$ denotes $\\{L \\circ f | f \\in F\\}$.\nSince $F_y = \\{f : x \\leftrightarrow f_y(x) | f \\in F \\}$ and the loss function $L(f(x), y)$ is p-Lipschitz with respect to f(x)($0 < p < \\infty$)\nfor all $y \\in Y$, by the Rademacher vector contraction inequality, we have $\\mathfrak{R}_n(L\\circ F) \\le \\sqrt{2p} \\sum_{y=1}^{k+1} \\mathfrak{R}_n(F_y)$.\nLemma 2. Assume the multi-class loss function $L(f(x), y)$ is p-Lipschitz ($0 < p < \\infty$) with respect to f(x) for all\ny \u2208 Y and upper bounded by a constant $C_\\mathcal{L}$, i.e.,$C_\\mathcal{L} = \\sup_{x\\in X,y\\in Y,f\\in F}L(f(x, y))$. Then, for any $d > 0$,with probability\nat least $1 - \\delta$,we have\n$\\sup_{f\\in F} | \\hat{\\mathfrak{R}}_{kac}(f) - \\mathfrak{R}_{kac}(f) | \\le 4 \\sqrt{2p(k+1)} + 3 C_\\mathcal{L} \\sqrt{\\frac{log \\frac{2}{d}}{2n}}$\nProof. For any sample $S = (x_1, x_2, ..., x_n)$, we define $\\Phi(S)$ that for any sample S by\n$\\Phi(S) = \\sup_{f \\in F} (\\hat{\\mathfrak{R}}_{kac}(f) - \\mathfrak{R}_{kac}(f))$\nLet S and S' be two instances differing by exactly one point, say $x_i$ in S and $x_i'$ in S'. Then since the difference of\nsuprema does not exceed the supremum of the difference, we have\n$\\begin{aligned} \\Phi(S) - \\Phi(S') &\\le \\sup_{f\\in F} (\\hat{\\mathfrak{R}}_{kac}(f) - \\hat{\\mathfrak{R}}_{kac}(f)) \\\\ & = \\sup_{f \\in F} | \\frac{f(x_i) - f(x_i')}{n} | < \\frac{3 C_L}{n} \\end{aligned}$\ntherefore, when an instance $x_i$ in $\\hat{\\mathfrak{R}}_{kac}(f)$ is replaced by another arbitrary instance $x_i'$, and then the change of\n$\\sup_{f \\in F} (\\hat{\\mathfrak{R}}_{kac}(f) - \\hat{\\mathfrak{R}}_{kac}(f))$ is no greater than $\\frac{3 C_L}{n}$. Then, by applying the Diarmid's inequality (McDiarmid 1989 [32]),\nfor any $d > 0$, with probability at least $1 - \\frac{d}{2}$,\n$\\sup_{f \\in F} | \\hat{\\mathfrak{R}}_{kac}(f) - \\hat{\\mathfrak{R}}_{kac}(f) | \\le \\mathbb{E} [\\sup_{f \\in F} (\\hat{\\mathfrak{R}}_{kac}(f) - \\hat{\\mathfrak{R}}_{kac}(f))] + \\frac{3 C_L}{n} \\sqrt{\\frac{log \\frac{2}{d}}{2n}}$"}]}