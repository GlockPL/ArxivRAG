{"title": "MAO: A Framework for Process Model Generation with Multi-Agent Orchestration", "authors": ["Leilei Lin", "Yumeng Jin", "Yingming Zhou", "Wenlong Chen", "Chen Qian"], "abstract": "Process models are frequently used in software engineering to describe business requirements, guide software testing and control system improvement. However, traditional process modeling methods often require the participation of numerous experts, which is expensive and time-consuming. Therefore, the exploration of a more efficient and cost-effective automated modeling method has emerged as a focal point in current research. This article explores a framework for automatically generating process models with multi-agent orchestration (MAO), aiming to enhance the efficiency of process modeling and offer valuable insights for domain experts. Our framework MAO leverages large language models as the cornerstone for multi-agent, employing an innovative prompt strategy to ensure efficient collaboration among multi-agent. Specifically, 1) generation. The first phase of MAO is to generate a slightly rough process model from the text description; 2) refinement. The agents would continuously refine the initial process model through multiple rounds of dialogue; 3) reviewing. Large language models are prone to hallucination phenomena among multi-turn dialogues, so the agents need to review and repair semantic hallucinations in process models; 4) testing. The representation of process models is diverse. Consequently, the agents utilize external tools to test whether the generated process model contains format errors, namely format hallucinations, and then adjust the process model to conform to the output paradigm. The experiments demonstrate that the process models generated by our framework outperform existing methods and surpass manual modeling by 89%, 61%, 52%, and 75% on four different datasets, respectively.", "sections": [{"title": "1 INTRODUCTION", "content": "Software engineering is a field that employs a systematic and disciplined methodology for the design, implementation, and maintenance of software systems [2]. Process-driven approaches [48] are commonly utilized within software engineering, focusing on process modeling to aid software developers in gaining a comprehensive understanding of software systems, thereby enhancing development efficiency or optimizing running software systems [12]. For example, a process model acts as a guide or blueprint for developers throughout software development [9], it facilitates communication between stakeholders in the company and developers during the requirements analysis phase [18], and it is a valuable auxiliary tool for software testing [63]. However, over the past few decades, although traditional manual modeling approaches have yielded significant benefits, their inherent drawbacks such as time-consuming processes and high costs have become increasingly evident.\nThis motivated academics to devise methods and tools that enable business analysts or software developers to create process models as efficiently as possible. Process mining, as we all know, is an automated process modeling technique that uses event logs from information systems to reconstruct process models and improve ongoing business processes [22]. However, process mining belongs to a data-driven approach, relying on predefined mining rules by experts, resulting in significant disparities in process models generated by different rules [19, 32, 53]. With the rapid advancement of large language models (LLMs), LLMs are emerging with intelligence that was previously unique to human beings [65]. Specifically, the agents based on LLMs have attracted significant attention and exhibited a certain level of human-like intelligence, such as the ability to use tools [50], play games [6, 64], and develop software [44]. Therefore, a meaningful idea naturally arises: could LLM-based agents be employed for process modeling to promote future progress in the software engineering domain?\nSome researches about workflow automation generation based on large language models has shown initial progress in the field of Robotic Process Automation (RPA), like ProAgent [68] and FlowMind [69]. However, these researches mainly focus on generating activities to be executed and arranging them in a sequential order, without considering complex relationships such as concurrency or choice between activities. It is important to note that sorting through the complex relationships among activities is the most difficult part of process modeling. Kourani et al. [28] proposed the ProMoAI method, which involves converting process text into Partially Ordered Workflow Language (POWL) [29] before extracting the process model. This approach relies on the capabilities of POWL and does not fully leverage the capabilities of LLMs. Furthermore, ProMoAI requires user involvement in resolving hallucination phenomena during the process generation."}, {"title": "2 PRELIMINARY", "content": "A process model can be considered as a tool or language utilized for modeling software systems or service requirements. For instance, the Web Services Business Process Execution Language (WS-BPEL) serves as an XML-based implementation-oriented standard for delineating the interaction of executable processes with web services, without providing a graphical notation [23]. In contrast, the event-driven process chain (EPC) was introduced with the objective of semantically modeling business processes through the identification and graphical documentation of business management interconnections within an organization [1]. With the aim of graphical software specification, design, and documentation, the Object Management Group (OMG) introduced the unified modeling language (UML), primarily utilized for the initial specification of IT systems [54]. Furthermore, the Petri net is a mathematical modeling tool [20, 43, 59] commonly employed to model and analyze the behavior of systems like manufacturing processes, communication protocols, and computer networks. Petri nets are particularly adept at capturing issues of concurrency, synchronization, and resource allocation within intricate systems. However, one minor limitation of Petri nets is their propensity to generate overly complex models, rendering them challenging for modelers to comprehend. This inherent"}, {"title": "2.1 Process Model BPMN", "content": "A process model can be considered as a tool or language utilized for modeling software systems or service requirements. For instance, the Web Services Business Process Execution Language (WS-BPEL) serves as an XML-based implementation-oriented standard for delineating the interaction of executable processes with web services, without providing a graphical notation [23]. In contrast, the event-driven process chain (EPC) was introduced with the objective of semantically modeling business processes through the identification and graphical documentation of business management interconnections within an organization [1]. With the aim of graphical software specification, design, and documentation, the Object Management Group (OMG) introduced the unified modeling language (UML), primarily utilized for the initial specification of IT systems [54]. Furthermore, the Petri net is a mathematical modeling tool [20, 43, 59] commonly employed to model and analyze the behavior of systems like manufacturing processes, communication protocols, and computer networks. Petri nets are particularly adept at capturing issues of concurrency, synchronization, and resource allocation within intricate systems. However, one minor limitation of Petri nets is their propensity to generate overly complex models, rendering them challenging for modelers to comprehend. This inherent"}, {"title": "2.2 \u0392\u03a1\u039cN Text for LLMs", "content": "As we know, each BPMN diagram is represented by a .bpmn file in real-life, but this file contains abundant content. In order to enhance the understanding of BPMN diagrams by LLMs, we design a more concise BPMN text for the agent's operation. As shown in Figure 2, on the bottom side is a simple BPMN diagram, while on the top side is its equivalent BPMN text representation. In BPMN text, <process> signifies the beginning of a process model, while </process> indicates the end. The activity node <activity> includes four attributes: the executor \"role\", the activity name \"action\", the resources \"object\" required for the activity, and a unique identifier \"id\" for the activity, where the value of the \"object\" attribute can be null. The branch node <branch> must be enclosed within the gateways like exclusiveGateway, parallelGateway and inclusiveGateway, where the \"condition\" attribute in <branch> denotes the condition that needs to be met for the branch to be executed. In this paper, regardless of whether it is generating a process model or modifying a process model, multi-agent operate on the BPMN text."}, {"title": "3 PROCESS MODELING FRAMEWORK", "content": "In this section, a novel framework (i.e., MAO) will be presented, which enables the generation of process models through multi-agent orchestration. Figure 3 illustrates the specifics of MAO. Upon receiving modeling requirements from users, we first establish a process design team comprised of multi-agent with distinct roles who collaborate to complete the process modeling tasks. The team collaboration involves four main phases: the first phase involves the team leader and process design expert in generating the initial process model; the second phase entails further refinement based on the initial model; the third phase involves the process reviewer and process design expert adjusting semantic hallucinations within the process model; and in the final phase, external tools are employed to rectify any format errors in the process model.\nIt is worth noting that in the establishment of the process design team, we employ inception prompting [33], a method that has demonstrated effectiveness in enabling agents to fulfill their respective roles. As illustrated in Figure 4, we categorize the roles into two types: instructor and assistant, with the former responsible for thinking and issuing directives, and the latter for executing specific tasks based on the directives received. Within the MAO framework, the first two phases involve only the team leader and process design expert, while in the third and fourth phases, all three roles are involved."}, {"title": "3.1 Generation", "content": "The first phase of MAO involves generating an initial process model from user requirements. Initially, the team leader creates instruction content based on user needs, and then guides the process design expert in completing the process modeling through prompt engineering. In order to better stimulate the capabilities of LLMs, the following prompting strategies have been adopted:\n\u2022 Knowledge Injection. This strategy entails providing the LLMs with novel, specific information or context that may not have been part of its original training [37]. Although"}, {"title": "3.2 Refinement", "content": "After establishing the initial process model, the agent of the team leader proposes instructions for refining the activities in the model, then the process design expert autonomously decides on the specifics to be refined based on the instructions. The orchestration at this phase is primarily aimed at addressing two causes that can easily lead to low quality process models: (1) overly vague user requirements. The ideal user requirement involves providing a detailed description of the process, including the activities to be modeled and the dependencies between activities. However, in reality, many users only present a modeling goal without any description of the process content, such as designing a procurement process. This vague requirement can result in the process model generated by the agent being very rough, possibly with only a few common activities. We know that a very coarse process model of procurement process may lack sufficient value as a reference for users; (2) low information density in LLMs. Large language models are typically trained on vast amounts of unlabeled or weakly labeled text data [38, 52], which may encompass diverse styles and themes, resulting in low information density. As a result, when generating responses, LLMs may opt for a more neutral and generalized expression to cater to various users.\nThe refinement operation mainly consists of two actions: refining existing activities into multiple sub-activities and adding appropriate gateways. The team leader provides a prompt including the initial model generated by the first phase and user requirements to the process design expert, enabling the expert to autonomously decide on the content to be refined. The prompts also include a few examples of refinement operations to guide the expert's refinement actions."}, {"title": "3.3 Reviewing", "content": "In this section, we will discuss how multi-agent collaborate to address hallucination phenomena in process modeling. In natural language processing, \u201challucination\" denotes the situation where a machine learning model generates text or responses that are entirely disconnected from the context or not reliant on the input data [21]. This can manifest when the agents produce language that lacks logic in relation to the input or sounds plausible but lacks factual accuracy. This paper attributes illogical errors in process modeling to semantic hallucinations (SH), in other words, the focus of the Reviewing phase in MAO is on rectifying logical errors in process models. As depicted in Table 2, we present the categories"}, {"title": "3.4 Testing", "content": "After processing semantic hallucinations, we will make the final formatting adjustments to the BPMN text. Although in the first phase of MAO, we enhance the agents' understanding of the BPMN text format through knowledge injection, the agents still make a few errors when generating complex process models, such as"}, {"title": "4 EXPERIMENT", "content": "In this section, we conduct an evaluation of the performance of the MAO framework. All our experiments are conducted using GPT-4, and all the code is publicly available\u00b9."}, {"title": "4.1 Setup", "content": "Datasets: To evaluate the performance of MAO for generating process models, we choose two types of datasets for comparison, fine-grained and coarse-grained. The fine-grained dataset is sourced from Camunda, a business process management company, we name this dataset as FG-C2, while the coarse-grained dataset is from the Object Management Group (OMG), named CG-O\u00b3. A detailed description of the two datasets is given below:\n- FG-C. In this type dataset, user modeling requirements are described in text form in great detail, including the business objectives to be addressed, the activities involved, and the execution logic between activities. FG-C is collected by Camunda during their BPMN training sessions. Camunda first provides BPMN modeling training to participants, and at the end of the training chapters, participants complete four BPMN modeling exercises. Each exercise is presented as a text-based process scenario, and participants are required to create a BPMN model based on this textual process description. Additionally, for each process description, Camunda provides a reference BPMN model, which participants can study after completing their modeling. In the experiment, we regard this reference BPMN as the standard model. Therefore, the dataset includes four process description texts, each corresponding to multiple BPMN processes modeled by the training participants and one standard BPMN process. As shown in Table 3, the process description texts"}, {"title": "4.2 Comparison of experiments on the dataset FG-C", "content": "In this experiment, we compare the MAO with the ProMoAI and manual modeling method. We utilize the process description texts from the FG-C provided by Camunda as inputs. The MAO and ProMoAI methods are sequentially applied to generate process models, producing their respective outputs. For the manual modeling method, BPMN models created by multiple participants in Table 3 are considered as outputs. It should be noted that for manual modeling methods, we use the average value of each dataset, which we named Human-Mean.\nNext, we employ four algorithms from the BPMNDiffViz tool to compute the distance between the process models generated by the three methods and the standard models. A smaller distance value indicates a closer resemblance of the generated model to the standard answer, hence smaller distance reflects higher model"}, {"title": "4.3 Comparison of experiments on the dataset CG-O", "content": "In this section, we want to discuss the capability of large language models in generating processes on open-ended requirements. As stated in Section 4.1, CG-O is a coarse-grained dataset containing cases of three business processes: \"Ordering and delivering pizza\u201d, \"Shipment of a hardware retailer\", and \"Order Fulfillment\". Each case includes only a standard process model and its corresponding name, without any description of the process model. This type of dataset CG-O meets the open-ended requirements, because even with the same business process name, individuals will create different process models based on their own knowledge and experiences.\nAs depicted in Figure 9(a), in the case of \"Ordering and delivering pizza\", the OMG organization provides a standard model that they consider to represent the business process of ordering pizza in a reasonable manner. Figures 9(b) and 9(c) illustrate the process models generated by the MAO and ProMoAI based on the user requirement (i.e., \"please design a process model about ordering and delivering pizza\"). In the user requirements, there are no descriptions of activities related to ordering or delivering pizza, so both methods create process models based on their own knowledge autonomously. Since open-ended requirements do not have definitive answers, a comparative analysis according to the metric outlined in Section 4.2 is not feasible. Therefore, this paper subjectively evaluates the strengths and weaknesses of the two methods (MAO and ProMoAI). From Figure 9(b), it is apparent that the MAO"}, {"title": "4.4 Ablation study", "content": "To assess the contributions of each phase in our proposed framework MAO, this section will conduct ablation experiments: 1) Refinement-4, which represents discarding the second phase in MAO. 2) Reviewing-4, which removes the Reviewing phase in MAO, generating processes without examining semantic errors in the process text. 3)"}, {"title": "5 RELATED WORK", "content": "This study mainly explores process modeling and large language models, with particular emphasis on leveraging multi-agent to automatically produce process models and investigating approaches"}, {"title": "6 CONCLUSION", "content": "Process modeling is a valuable topic in software engineering. This paper explores a novel process modeling framework, named MAO. The MAO framework leverages the capabilities of large language models to create a process design team composed of multiple agents, and then finishes process modeling with multi-agent orchestration. Upon receiving user requirements, the MAO framework goes through four phases: Generation, Refinement, Reviewing, and Testing to produce a BPMN diagram. The first two phases involve designing a rough process model and refining the process model, while the latter two phases deal with semantic hallucinations and format hallucinations. Extensive experiments were conducted on two types of datasets, fine-grained dataset FG-C and coarse-grained dataset CG-O. The results indicate that for user requirements containing detailed process descriptions, the process model quality generated by the MAO surpasses the existing methods and far exceeds the average level of manual modeling. For open-ended requirements, i.e., those containing only modeling objectives, the MAO framework is capable of generating a reasonable process model with significant reference value.\nIn the future, we will expand the work content of this article to support more different elements of BPMN in process models, such as data flow and message flow."}]}