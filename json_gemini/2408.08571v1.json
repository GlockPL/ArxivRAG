{"title": "AgentSimulator: An Agent-based Approach for Data-driven Business Process Simulation", "authors": ["Lukas Kirchdorfer", "Robert Bl\u00fcmel", "Timotheus Kampik", "Han van der Aa", "Heiner Stuckenschmidt"], "abstract": "Business process simulation (BPS) is a versatile technique for estimating process performance across various scenarios. Traditionally, BPS approaches employ a control-flow-first perspective by enriching a process model with simulation parameters. Although such approaches can mimic the behavior of centrally orchestrated processes, such as those supported by workflow systems, current control-flow-first approaches cannot faithfully capture the dynamics of real-world processes that involve distinct resource behavior and decentralized decision-making. Recognizing this issue, this paper introduces AgentSimulator, a resource-first BPS approach that discovers a multi-agent system from an event log, modeling distinct resource behaviors and interaction patterns to simulate the underlying process. Our experiments show that AgentSimulator achieves state-of-the-art simulation accuracy with significantly lower computation times than existing approaches while providing high interpretability and adaptability to different types of process-execution scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Business process simulation (BPS) is a widely used technique to estimate the impact of changes to a process with respect to key performance indicators, such as cycle time, resource utilization, or waiting time for a given activity-a practice known as counterfactual reasoning or \"what-if\" analysis [1]. BPS has the potential to drastically reduce the risks of process change and facilitate process improvement with tangible outcomes, as decision makers can compare process designs without already having to implement the changes. Nevertheless, the effectiveness of BPS relies heavily on the availability of a simulation model that precisely mirrors the dynamics of a given process across dimensions such as control-flow, time, and resource behavior. Manually constructing these simulation models is time-consuming and error-prone due to several pitfalls [2]. Therefore, various approaches have been developed for the automated discovery of process simulation models based on historical execution data contained in event logs [3]\u2013[7]. Most commonly, such data-driven simulation approaches discover a process model\u2014capturing the control flow of an entire process\u2014and subsequently augment this model with simulation parameters, such as arrival rates, resources, and processing times.\nIn this paper, we argue that there are settings in which such control-flow-first simulation models cannot provide a faithful representation of the dynamics of real-world processes, leading to simulation inaccuracies. This particularly applies to processes involving distinct resource behavior or decentralized decision-making. Although certain processes are indeed centrally orchestrated, such as those supported by workflow systems [1], other processes provide higher operational flexibility to the actors involved. In such settings, each actor in a process performs their part from their own perspective and, to some extent, in their own manner, i.e., they receive a case from a co-worker, conduct one or more tasks they deem necessary, and pass on the case to the next individual or system. This can result in processes where specific traits or preferences of actors can influence a case's execution. Such characteristics are difficult for existing control-flow-first approaches to capture.\nTherefore, we use this paper to propose AgentSimulator, a resource-first approach for data-driven process simulation. By discovering a multi-agent system (MAS) from an event log, AgentSimulator can simulate the execution of a process through autonomous and interacting agents, corresponding to real-world actors and systems. This allows AgentSimulator to achieve various benefits in comparison to existing approaches for data-driven process simulation:\n\u2022 our approach provides full flexibility over the behavior of individual resources involved in a process, allowing to capture differences in terms of control-flow behavior, interaction preferences, and capabilities;\n\u2022 agent-based systems are highly interpretable and allow for a high degree of adaptability, which is crucial to performing what-if analyses, and thus provides a substantial advantage over black-box deep learning models;\n\u2022 our approach requires significantly lower run times than previous approaches, making it more feasible to run a large number of simulations, which is necessary to achieve stable and confident results given the stochastic nature of simulation models;\n\u2022 and finally, our approach yields state-of-the-art simulation accuracy across a variety of event logs.\nThe remainder starts with a motivating scenario (Section II), followed by the presentation of the AgentSimulator approach"}, {"title": "II. MOTIVATION", "content": "This section illustrates the benefits of shifting simulation models from a control-flow-first to a resource-first perspective.\nFor this illustration, we consider a simplified credit application process, for which a schematic visualization is shown in Figure 1. As depicted, the process starts when an application is received by the system, after which the applicant's credit history and income sources need to be checked by a clerk (in any order). Once both checks have been completed, the application is passed on to a credit officer, who assesses the application and notifies the applicant of the outcome. As shown, there are three clerks (Steve, Oliver, and Angela) and two credit officers (Maria and Patrick) involved in the process.\nEven for such a simple scenario, we may observe various ways in which the involvement of specific actors in a case can influence its execution:\n\u2022 Process performance. The execution time of an activity may depend on the employee who performs it. For example, Steve (a less experienced, Junior Clerk) might need 45 minutes to check the credit history and the income sources, respectively. For the same activities, the Senior Clerks Oliver and Angela only need 15 to 20 minutes. Considering these performance differences between resources is critical for accurate simulation, as has been recently demonstrated [8].\n\u2022 Resource availability. Employees involved in a process may have different availabilities, owing to factors such as part-time work and other duties. Such considerations are particularly relevant in decentralized processes, where cases may be handed over directly from employee to employee, rather than by a central workflow system that can assign a case to the next available person. For example, if Angela hands over an application specifically to Patrick, rather than to the next available credit officer, this can lead to considerable delays in the case's execution if Patrick is not available for the next working days. Such irregularities should be reflected in a simulation model, calling for individual resource calendars, as again was recently demonstrated to positively impact accuracy [8].\n\u2022 Control-flow behavior. Control-flow-first simulation models impose the assumption that the sequence of activities performed for a given case is independent of the actors involved in it. However, there can be various reasons why this is not the case. In our scenario, for example, we may observe that Angela always checks the credit history first, before checking the income sources, whereas other actors may alternate these orders. Furthermore, there may even be actor-specific rules that influence the possible sequences of a case. For example, it may be necessary that any application handled by a Junior Clerk"}, {"title": "III. OUR APPROACH: AGENTSIMULATOR", "content": "This section introduces AgentSimulator, our data-driven agent-based business process simulation approach, with a high-level overview in Figure 2. To adopt a resource-first perspective, AgentSimulator models agents in a MAS (see Section III-A), which is (along with general simulation parameters) discovered from an event log in the discovery phase (see Section III-B). Following the MAS discovery, we can simulate the process and generate a new event log (see Section III-C). We detail our approach for both discovery and simulation, also discussing alternative design choices for different process types, highlighting AgentSimulator's adaptability.\nA. Definitions\nIn this section, we define event logs, which provide the input of our approach (and its simulated output), before providing the definition of agents and a MAS that our approach employs."}, {"title": "A. Definitions", "content": "Input. AgentSimulator takes as input an event log L, which we define as a finite multi-set of traces. A trace $$\\sigma \\in L$$ is a finite sequence of events, $$(e_1, ..., e_n)$$, recording the execution of activities performed for a single case in an organizational process. Each event $$e_i$$ is a tuple $$(act, ts_{start}, ts_{end}, res)$$, with act as the activity to which it corresponds, $$ts_{start}$$ and $$ts_{end}$$, respectively, as the start and end timestamps of the activity's execution, and res as the resource that executed the activity. Note that we follow [8] by representing each event with a start and end timestamp, which is required in simulation settings to consider activity durations, and ordering the events in a trace based on their start timestamp.\nIn the remainder, we commonly use dot notation to refer to components of tuples, e.g., using $$e_i.act$$ as a shorthand to refer to the activity of an event $$e_i$$, whereas we use $$ACT_L$$ and $$RES_L$$ to, respectively, refer to the sets of activities and resources contained in the traces of event log L.\nMulti-agent system. The notion of an agent is a fundamental abstraction in Artificial Intelligence (AI) [9]. Agents perceive their environment (including other agents) to reason about the perceptions and decide on an action, which is then executed against the environment. In a multi-agent system (MAS), agents can collaborate to achieve joint goals. In our work, we define a MAS and an agent as follows:\nDefinition 1 (Multi-agent system). We define a MAS for our AgentSimulator as a tuple $$m = (A,p)$$. Here, A corresponds to the set of agents used to simulate a process, whereas p is a tuple of general simulation parameters, reflecting aspects of the process's environment. Here, p consists of a case inter-arrival distribution and a set of probability density functions (PDFs) over extraneous delays (more details in Section III-B).\nDefinition 2 (Agent). An agent in a business process environment is an autonomous entity representing a real-world actor or system. We define an agent $$a \\in A$$ that acts in the MAS m as a tuple, denoted $$a = (t, s, c, b)$$, where:\n1) t refers to the agent's type. Agent types are used to indicate agents with similar characteristics, e.g., in terms of the activities they can perform. We use T to refer to the set of types in A\n2) s refers to a schedule (a set of intervals) during which the agent is available to perform activities. The simulation needs to capture the distinct availabilities of agents (e.g., full-time vs. part-time) to faithfully reflect the temporal dimension of the process.\n3) c refers to capabilities of an agent, denoted as a tuple $$c = (ALLOC, PT)$$, where:\n\u2022 $$ALLOC \\subseteq ACT_L$$ is the set of activities that a can execute, i.e., that can be allocated to agent a.\n\u2022 PT refers to a set of PDFs, where each $$f_{pt}(act) \\in PT$$ captures a distribution over processing times $$pt \\in [0,\\infty)$$ for an activity act $$\\in$$ ALLOC. Defining PT per agent allows us to differentiate process performance across resources.\n4) b refers to the behavior of an agent, capturing how agent a hands a case over to continue its execution after finishing an activity. What b exactly entails depends on the kind of process being simulated. In a centrally orchestrated process, determining the next activity is handled centrally, whereas in a more autonomous process, agents directly hand over cases to others. Therefore, we provide further details and exact definitions in the following sections."}, {"title": "B. Phase 1: MAS Discovery", "content": "In this section, we describe how AgentSimulator discovers the agents A and general simulation parameters p from an event log L to define the MAS m. In the realm of business processes, our generic definition of an agent offers numerous implementation possibilities. Thus, besides describing our discovery approach, we also discuss alternatives. The flexibility of agent systems is a key advantage of our AgentSimulator, enabling adaptation to diverse collaborative work dynamics.\nAgent instantiation. In business process environments, resources are the active entities performing actions. Therefore, we instantiate one agent $$a \\in A$$ for each resource $$res \\in RES_L$$. For our motivating example, we thus instantiate six agents (five human actors and System). If certain events lack resource information, we additionally generate a dummy agent for each distinct activity that lacks such information. We noticed that events without resource information often refer to either instantaneous activities or system resources. First, explicitly modeling these as agents ensures that any activity"}, {"title": "C. Phase 2: Simulation", "content": "This section details how the AgentSimulator approach uses the discovered MAS m to simulate an event log $L'$, illustrated by the pseudo-code in Algorithm 1. The simulation proceeds in discrete steps, each representing a time tick. At each step, we check if new cases arrive and for each running case in the system, we verify if it is waiting to be processed (e.g., due to completion of the previous activity) to instantiate the next activity. The simulation step ends after all cases have been checked. In more detail, one simulation step looks as follows:\n1) Check for new cases. Based on the discovered inter-arrival distribution p.$$f_{iat}$$, we first check if a new case arrives (Line 3). If there are multiple cases in the system, their processing order is determined in a first-in-first-out manner. Note that when evaluating against a test log, we follow the convention of Simod [4] and only simulate as many case arrivals as there are cases to be simulated. However, for regular simulations, we keep on letting cases arrive until we finish the simulation to avoid a cool-down phase, which is more realistic.\n2) Handle all running cases. The cases are processed one-by-one (Line 4) until all cases have been addressed:\na) Determine next activity. First, we check if the given case $$\\sigma_{prefix}$$ is waiting to be processed (Line 5). If so, a new event e is created with its corresponding activity e.act being determined (Line 7) either globally, modeling orchestrated handovers based on the current activity prefix (i.e., a global entity orchestrates the control-flow execution), or locally, modeling autonomous handovers through the last active agent in the case. Note that a case's first activity is always determined globally as there is no prior agent.\nb) Determine the responsible agent. After a new activity was determined for the given case, it requires an agent for the execution. Based on the set of activities that an agent can execute a.c.$$_{ALLOC}$$, we identify possibly responsible agents p_a (Line 11). To determine the specific agent (Line 12), we again differentiate between the two architectures:\n\u2022 Orchestrated handovers. In a MAS with orchestrated handovers, there are no agent interaction patterns modeled. Thus, having determined the set of possibly responsible agents, we order this set based on the agent availabilities and iteratively ask these agents to perform the next activity until one agent is available to execute it (which we call iterative task allocation). Thus, the first agent to be asked is the one that offers (based on its schedule a.s and its current occupation) the earliest availability. An agent refuses to accept the activity if its estimated duration (based on $$f_{pt}(act) \\in a.c.PT$$) collides with occupied or non-working time slots. If none of the possible agents are available, the case cannot be processed for now and will be checked again in the next simulation step. Thus, the case receives waiting time due to contention (Line 14).\n\u2022 Autonomous handovers. In a MAS with autonomous handovers, we use the computed agent handover probabilities $$P(a_i | a_j)$$ to determine the next agent. There are two design choices for their usage: (i) iterative task allocation and (ii) direct task assignment.\n(i) Using iterative task allocation, we simulate (just as in the orchestrated handovers) that agent aj iteratively asks other agents to take the activity. However, the difference is that here the order of to-be-asked agents is determined by the agent handover probabilities that are transformed into a ranking, i.e., agent ai is asked first if it has the highest handover probability from aj.\n(ii) Using direct task assignment (not represented in Algorithm 1), current agent aj does not ask agents until one is available but assigns the task to an agent who then starts executing it as soon as it finds the time. This can be a common agent interaction pattern in real-life processes, for instance, if an employee forwards a case via e-mail to a colleague. For this direct assignment, we sample the agent based on the agent handover probabilities.\nNote that a case's first agent is always determined as described for orchestrated handovers.\nc) Start activity execution. If an agent could be identified, it begins executing the assigned activity, with the end timestamp being determined by sampling from the agent-specific activity duration distribution $$f_{pt}(act) \\in a.c.PT$$ and potentially adding extraneous delays using $$f_{d}(act) \\in p.D$$ (Line 16).\nAfter each case is processed, a simulation step is completed. A case exits the system once its final activity is executed"}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "This section presents the experiments used to evaluate the performance of AgentSimulator. Table I summarizes the characteristics of the 9 publicly available event logs used in our experiments, which are commonly used in BPS evaluations [5], [6], [15] as they contain both start and end timestamps. Our implementation, the event logs (with train-test splits), and additional results are available through our public repository\u00b9.\nA. Experimental Setup\nImplementation. We implemented our approach in Python using the agent-based modeling framework mesa [16].\nBenchmark approaches. We empirically compare our AgentSimulator (AgentSim) against three common data-driven BPS approaches. We adopt the state-of-the-art Data-driven Process Simulation (DDPS) approach from [8], which we refer to as Simod. It combines the original Simod [4] with the Prosimos simulator, which considers differentiated resource availability and performance and was shown to outperform the original Simod. DeepGenerator (DGEN) [12] is a pure Deep Learning (DL) approach, and DeepSimulator (DSIM) [6] is a hybrid of DDPS and DL (more details in Section V).\nData split. We follow evaluations of existing BPS approaches [5], [6], [12] and perform a temporal hold-out split, excluding all cases that span the separation time between the train set (first 80% of cases) and the test set (last 20% of cases).\nHyperparameters. AgentSim has two automatically determined hyperparameters: the architecture (orchestrated or autonomous handovers) and whether to consider extraneous delays, resulting in 4 possible configurations. We treat the latter as a hyperparameter because we noticed considerable differences regarding the benefit of considering extraneous delays between different event logs. We determine both hyperparameters by initially simulating the last 20% of the training set for each of the 4 possible configurations and checking which simulation most closely resembles the training subset in terms of cycle time. To ensure a fair comparison, we use the same option regarding extraneous delays for Simod.\nMetrics. To evaluate and compare the different simulation approaches, we use recently proposed metrics that are designed to evaluate simulation models across three dimensions: control-flow, time, and congestion, thus, providing a holistic perspective [15]. All metrics compute the distance between the simulated and test log, where a lower value indicates a better result. To measure the control-flow, we use the N-Gram Distance (NGD) that computes the difference in the frequencies of the n-grams observed in the event logs. To measure the temporal performance of the simulation, we use the Absolute Event Distribution (AED), the Circadian Event Distribution (CED), and the Relative Event Distribution (RED). To measure the capability of a model to represent congestion, we use the Cycle Time Distribution (CTD). We do not measure the Case Arrival Rate as we apply the same case arrival method as Simod, thus, we focus on metrics where AgentSim differs from other approaches."}, {"title": "B. Results", "content": "Overall results. Table II summarizes the results for the 9 event logs, showing the average metrics from 10 simulation runs for each log. The best value per log and metric is marked in bold, the second-best is underlined. Generally, no single approach consistently outperforms the others across all datasets and metrics as also observed in previous BPS works [5], [6]. However, AgentSim stands out by most frequently achieving the best performance within each metric across the 9 logs. When looking more closely at the 3 dimensions captured by the metrics, we can obtain the following main insights:\nControl-flow. Achieving the best NGD (N-gram distance) in 4 out of 9 logs and considerably outperforming Simod and DSIM, the results indicate that our resource-first AgentSim approach, which is independent of an underlying process model enhances the accuracy of the control-flow dimension compared to control-flow-first approaches such as Simod. This is particularly evident when analyzing the two real-life BPI\nlogs. Thus, putting the resource at the core of the simulation often allows to represent control-flow behavior more faithfully.\nTime. In terms of absolute (AED), circadian (CED), and relative (RED) event distributions over time, AgentSim is the leader across all 3 metrics, followed by DSIM. Simod and DGEN stay on average significantly behind AgentSim. These results indicate that AgentSim can capture the temporal patterns in the logcomparatively well.\nCongestion. Accurately capturing the cycle time of a process instance serves as a critical indicator of the accuracy of a simulation approach. The CTD metric is influenced by the processing times of individual activities and the corresponding waiting times, which in turn are dependent on resource availability. Consequently, the cycle time metric captures a comprehensive range of factors. AgentSim demonstrates superior accuracy in capturing cycle times compared to the benchmarks, achieving the best CTD in 5 out of 9 logs, again followed by DSIM leading in the remaining 4 logs. The advantage of AgentSim over Simod is particularly pronounced with the Confidential logs.\nHere, Simod's simulated logs exhibit significantly longer cycle times compared to reality, primarily due to resource contention and the consequent waiting times. AgentSim mitigates this issue by recognizing that some agents do not require waiting time, such as agents performing instantaneous activities.\nImpact of handover configuration. Simulating the same process using the two different handover configurations (centrally orchestrated versus autonomous) reveals considerable differences in results for some logs (full results for both options are in our repository). Overall, our automated method of selecting the handover configuration in AgentSim leads to 5 of 9 processes being simulated with orchestrated handovers, e.g., P2P and Production, for which AgentSim, despite being a resource-first approach, still yields strong results. Some logs strongly benefit from being simulated in an orchestrated instead of autonomous manner. For instance, the Production log shows an improvement in CTD from 45.65 to 25.79 and in NGD from 0.77 to 0.61, aligning with the standardized nature of production processes. By contrast, looking at the logs that are simulated with autonomous handovers, we also observe clear benefits of considering distinct agent behaviors for certain processes. For instance, for the real-life BPI17W log, we halve both the CTD and RED to 22.75 and 26.03, respectively, compared to the orchestrated configuration. Also, C. 1000 and Loan Appl. show slightly better results across all metrics using autonomous handovers. Overall, these insights demonstrate AgentSim's adaptability to diverse process types, leading to considerable improvements in terms of results.\nPost-hoc analysis on agent interactions. To exemplarily demonstrate AgentSim's ability to represent agent interactions, we compare its interaction patterns with Simod for the real-life BPI12W log. Figure 3 shows that AgentSim accurately reflects the training log's interaction dynamics, capturing the given activity chaining of resources (see diagonal). In contrast, Simod exhibits random interactions and fails to capture these patterns, thus showing the crucial nature of considering individual interaction patterns for certain processes.\nRuntime. Given the stochasticity of simulation, it is essential to simulate numerous logs to achieve reliable predictions. Therefore, runtime is a critical factor in the practical application of BPS. In this regard, it is important to note that AgentSim consistently operates much faster than the benchmarks. For instance, while AgentSim only requires around 30 seconds to discover and simulate the Production log (on a machine with 32GB of RAM and an Intel Core i7 2.3 GHz CPU), Simod runs 20 times and DSIM even 80 times longer."}, {"title": "V. RELATED WORK", "content": "This section briefly discusses related work on automated BPS and agent-based modeling and simulation.\nAutomated BPS. We can divide existing literature on automated BPS approaches into three categories: Data-Driven Process Simulation (DDPS), Deep Learning (DL), and hybrid approaches. DDPS approaches automate simulation model discovery from event logs by initially identifying a process model and then enhancing it with simulation parameters. A semi-automated approach using colored Petri nets is proposed in [3], while [7] introduces a data-driven approach without considering resources. A more recent approach is Simod [4], which incorporates hyperparameter tuning. DL approaches for BPS typically rely on recurrent neural networks. LSTM models are employed in [13] to predict events and timestamps, later improved upon by DGEN [12] incorporating n-grams and embeddings. Due to their black-box nature, DL models are not applicable for what-if analysis. Hybrid models combine DDPS and DL approaches. DSIM [6] combines a stochastic process model with DL for event timestamping, extended by RIMS that integrates predictions at runtime [5].\nAgent-based modeling and simulation. Over the past decades, the application of MAS to various domains has been studied extensively (cf. [17] for a review). Applying agents to Business Process Management (BPM) was initially proposed in the 1990's [18], where a business process is modeled as a system of negotiating agents. More recently, the concept of agent system mining has been introduced, recognizing that processes often emerge from interactions of autonomous agents [19], as demonstrated by an agent-based discovery algorithm in [20], and also shown for simulation in [21]. However, such agent-based simulation approaches in BPM rely on manual configurations to simulate a specific process, e.g., in a factory production domain [23]. To the best of our knowledge, our approach is the first to use event logs to automatically infer MAS models for process simulation."}, {"title": "VI. CONCLUSION", "content": "This paper introduced AgentSimulator an agent-based approach for data-driven business process simulation. Given an event log, our approach discovers a multi-agent system that represents real-world actors and systems, each modeled with unique behaviors and interaction patterns. The discovered multi-agent system is then used to simulate the execution of the process. Our resource-first approach provides more means to capture distinct resource behaviors and interactions than traditional control-flow-first approaches and achieves state-of-the-art results with significantly reduced computation times. The evaluation shows that centrally orchestrated and decentralized processes often need to be captured differently, with AgentSimulator being automatically adaptable to both. Modeling human behavior is a complex task. Although our approach successfully captures some agent-specific behaviors, it currently does not account for multitasking, batching, or fatigue effects, which we want to incorporate in future work. Furthermore, we will explore the use of additional architectures for our multi-agent system itself."}]}