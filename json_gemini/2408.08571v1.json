{"title": "AgentSimulator: An Agent-based Approach for\nData-driven Business Process Simulation", "authors": ["Lukas Kirchdorfer", "Robert Bl\u00fcmel", "Timotheus Kampik", "Han van der Aa", "Heiner Stuckenschmidt"], "abstract": "Business process simulation (BPS) is a versatile\ntechnique for estimating process performance across various\nscenarios. Traditionally, BPS approaches employ a control-flow-\nfirst perspective by enriching a process model with simulation\nparameters. Although such approaches can mimic the behavior\nof centrally orchestrated processes, such as those supported by\nworkflow systems, current control-flow-first approaches cannot\nfaithfully capture the dynamics of real-world processes that\ninvolve distinct resource behavior and decentralized decision-\nmaking. Recognizing this issue, this paper introduces AgentSimu-\nlator, a resource-first BPS approach that discovers a multi-agent\nsystem from an event log, modeling distinct resource behaviors\nand interaction patterns to simulate the underlying process. Our\nexperiments show that AgentSimulator achieves state-of-the-art\nsimulation accuracy with significantly lower computation times\nthan existing approaches while providing high interpretability\nand adaptability to different types of process-execution scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Business process simulation (BPS) is a widely used tech-\nnique to estimate the impact of changes to a process with\nrespect to key performance indicators, such as cycle time,\nresource utilization, or waiting time for a given activity-a\npractice known as counterfactual reasoning or \"what-if\" anal-\nysis [1]. BPS has the potential to drastically reduce the risks\nof process change and facilitate process improvement with\ntangible outcomes, as decision makers can compare process\ndesigns without already having to implement the changes.\nNevertheless, the effectiveness of BPS relies heavily on the\navailability of a simulation model that precisely mirrors the dy-\nnamics of a given process across dimensions such as control-\nflow, time, and resource behavior. Manually constructing these\nsimulation models is time-consuming and error-prone due to\nseveral pitfalls [2]. Therefore, various approaches have been\ndeveloped for the automated discovery of process simulation\nmodels based on historical execution data contained in event\nlogs [3]-[7]. Most commonly, such data-driven simulation ap-\nproaches discover a process model-capturing the control flow\nof an entire process and subsequently augment this model\nwith simulation parameters, such as arrival rates, resources,\nand processing times.\nIn this paper, we argue that there are settings in which\nsuch control-flow-first simulation models cannot provide a\nfaithful representation of the dynamics of real-world processes,\nleading to simulation inaccuracies. This particularly applies to\nprocesses involving distinct resource behavior or decentralized\ndecision-making. Although certain processes are indeed cen-\ntrally orchestrated, such as those supported by workflow sys-\ntems [1], other processes provide higher operational flexibility\nto the actors involved. In such settings, each actor in a process\nperforms their part from their own perspective and, to some\nextent, in their own manner, i.e., they receive a case from a\nco-worker, conduct one or more tasks they deem necessary,\nand pass on the case to the next individual or system. This\ncan result in processes where specific traits or preferences of\nactors can influence a case's execution. Such characteristics are\ndifficult for existing control-flow-first approaches to capture.\nTherefore, we use this paper to propose AgentSimulator,\na resource-first approach for data-driven process simulation.\nBy discovering a multi-agent system (MAS) from an event\nlog, AgentSimulator can simulate the execution of a process\nthrough autonomous and interacting agents, corresponding to\nreal-world actors and systems. This allows AgentSimulator to\nachieve various benefits in comparison to existing approaches\nfor data-driven process simulation:\n\u2022 our approach provides full flexibility over the behavior\nof individual resources involved in a process, allowing\nto capture differences in terms of control-flow behavior,\ninteraction preferences, and capabilities;\n\u2022 agent-based systems are highly interpretable and allow\nfor a high degree of adaptability, which is crucial to per-\nforming what-if analyses, and thus provides a substantial\nadvantage over black-box deep learning models;\n\u2022 our approach requires significantly lower run times than\nprevious approaches, making it more feasible to run\na large number of simulations, which is necessary to\nachieve stable and confident results given the stochastic\nnature of simulation models;\n\u2022 and finally, our approach yields state-of-the-art simulation\naccuracy across a variety of event logs.\nThe remainder starts with a motivating scenario (Section II),\nfollowed by the presentation of the AgentSimulator approach"}, {"title": "II. MOTIVATION", "content": "This section illustrates the benefits of shifting simulation\nmodels from a control-flow-first to a resource-first perspective.\nFor this illustration, we consider a simplified credit applica-\ntion process, for which a schematic visualization is shown in\nFigure 1. As depicted, the process starts when an application\nis received by the system, after which the applicant's credit\nhistory and income sources need to be checked by a clerk\n(in any order). Once both checks have been completed, the\napplication is passed on to a credit officer, who assesses\nthe application and notifies the applicant of the outcome. As\nshown, there are three clerks (Steve, Oliver, and Angela) and\ntwo credit officers (Maria and Patrick) involved in the process.\nEven for such a simple scenario, we may observe various\nways in which the involvement of specific actors in a case can\ninfluence its execution:\n\u2022 Process performance. The execution time of an activity\nmay depend on the employee who performs it. For\nexample, Steve (a less experienced, Junior Clerk) might\nneed 45 minutes to check the credit history and the\nincome sources, respectively. For the same activities,\nthe Senior Clerks Oliver and Angela only need 15 to\n20 minutes. Considering these performance differences\nbetween resources is critical for accurate simulation, as\nhas been recently demonstrated [8].\n\u2022 Resource availability. Employees involved in a process\nmay have different availabilities, owing to factors such\nas part-time work and other duties. Such considerations\nare particularly relevant in decentralized processes, where\ncases may be handed over directly from employee to em-\nployee, rather than by a central workflow system that can\nassign a case to the next available person. For example, if\nAngela hands over an application specifically to Patrick,\nrather than to the next available credit officer, this can\nlead to considerable delays in the case's execution if\nPatrick is not available for the next working days. Such\nirregularities should be reflected in a simulation model,\ncalling for individual resource calendars, as again was\nrecently demonstrated to positively impact accuracy [8].\n\u2022 Control-flow behavior. Control-flow-first simulation mod-\nels impose the assumption that the sequence of activities\nperformed for a given case is independent of the actors\ninvolved in it. However, there can be various reasons\nwhy this is not the case. In our scenario, for example,\nwe may observe that Angela always checks the credit\nhistory first, before checking the income sources, whereas\nother actors may alternate these orders. Furthermore,\nthere may even be actor-specific rules that influence the\npossible sequences of a case. For example, it may be\nnecessary that any application handled by a Junior Clerk\n\u2022 Interaction patterns. Finally, owing to a lack of central\norchestration, there may be specific interaction patterns\namong actors. For example, we may observe that Steve\nalways collaborates with Oliver, since they both work\nin Mannheim, while he has no contact with Angela in\nHamburg. Such specific patterns influence the workload\nof individual resources, e.g., leading to an imbalance\nbetween Oliver and Angela, which is missed by general\nsimulation models. Furthermore, as described above, spe-\ncific interaction patterns may lead to additional delays\nwhen the availability of individual resources differs.\nAll of the above factors influence the execution of cases\nin a process. Therefore, process simulation models should\nreflect these as faithfully as possible in order to appropriately\nmimic the dynamics of a real-world process. The former\ntwo aspects have already been recognized and captured by\ncontrol-flow-first models [8]. However, especially the latter\ntwo can be much more naturally incorporated by an agent-\nbased simulation model, where the behavior of each resource\nis explicitly captured. This is achieved by our AgentSimulator\napproach, described next."}, {"title": "III. OUR APPROACH: AGENTSIMULATOR", "content": "This section introduces AgentSimulator, our data-driven\nagent-based business process simulation approach. To adopt a resource-first\nperspective, AgentSimulator models agents in a MAS (see\nSection III-A), which is (along with general simulation param-\neters) discovered from an event log in the discovery phase (see\nSection III-B). Following the MAS discovery, we can simulate\nthe process and generate a new event log (see Section III-C).\nWe detail our approach for both discovery and simulation,\nalso discussing alternative design choices for different process\ntypes, highlighting AgentSimulator's adaptability.\nA. Definitions\nIn this section, we define event logs, which provide the input\nof our approach (and its simulated output), before providing\nthe definition of agents and a MAS that our approach employs."}, {"title": "Input.", "content": "AgentSimulator takes as input an event log L, which\nwe define as a finite multi-set of traces. A trace \u03c3\u2208 L is a\nfinit\u00e9 sequence of events, (e1, ..., en), recording the execution\nof activities performed for a single case in an organizational\nprocess. Each event e; is a tuple (act, tsstart,tsend, res), with\nact as the activity to which it corresponds, tsstart and tsend,\nrespectively, as the start and end timestamps of the activity's\nexecution, and res as the resource that executed the activity.\nNote that we follow [8] by representing each event with a start\nand end timestamp, which is required in simulation settings to\nconsider activity durations, and ordering the events in a trace\nbased on their start timestamp.\nIn the remainder, we commonly use dot notation to refer\nto components of tuples, e.g., using ei.act as a shorthand to\nrefer to the activity of an event e;, whereas we use ACTL\nand RESL to, respectively, refer to the sets of activities and\nresources contained in the traces of event log L."}, {"title": "Multi-agent system.", "content": "The notion of an agent is a fundamental\nabstraction in Artificial Intelligence (AI) [9]. Agents perceive\ntheir environment (including other agents) to reason about the\nperceptions and decide on an action, which is then executed\nagainst the environment. In a multi-agent system (MAS),\nagents can collaborate to achieve joint goals. In our work,\nwe define a MAS and an agent as follows:\nDefinition 1 (Multi-agent system). We define a MAS for our\nAgentSimulator as a tuple m = (A,p). Here, A corresponds\nto the set of agents used to simulate a process, whereas p is\na tuple of general simulation parameters, reflecting aspects of\nthe process's environment. Here, p consists of a case inter-\narrival distribution and a set of probability density functions\n(PDFs) over extraneous delays (more details in Section III-B).\nDefinition 2 (Agent). An agent in a business process environ-\nment is an autonomous entity representing a real-world actor\nor system. We define an agent a \u2208 A that acts in the MAS m\nas a tuple, denoted a = (t, s, c, b), where:\n1) t refers to the agent's type. Agent types are used to\nindicate agents with similar characteristics, e.g., in terms\nof the activities they can perform. We use T to refer to\nthe set of types in A\n2) s refers to a schedule (a set of intervals) during which\nthe agent is available to perform activities. The simulation\nneeds to capture the distinct availabilities of agents (e.g.,\nfull-time vs. part-time) to faithfully reflect the temporal\ndimension of the process.\n3) c refers to capabilities of an agent, denoted as a tuple\nc = (ALLOC, PT), where:\n\u2022 ALLOC C ACTL is the set of activities that a can\nexecute, i.e., that can be allocated to agent a.\n\u2022 PT refers to a set of PDFs, where each fpt(act) \u2208\nPT captures a distribution over processing times pt \u2208\n[0,\u221e) for an activity act \u2208 ALLOC. Defining PT per\nagent allows us to differentiate process performance\nacross resources.\n4) b refers to the behavior of an agent, capturing how agent\na hands a case over to continue its execution after finish-\ning an activity. What b exactly entails depends on the kind\nof process being simulated. In a centrally orchestrated\nprocess, determining the next activity is handled centrally,\nwhereas in a more autonomous process, agents directly\nhand over cases to others. Therefore, we provide further\ndetails and exact definitions in the following sections."}, {"title": "B. Phase 1: MAS Discovery", "content": "In this section, we describe how AgentSimulator discovers\nthe agents A and general simulation parameters p from an\nevent log L to define the MAS m. In the realm of business\nprocesses, our generic definition of an agent offers numerous\nimplementation possibilities. Thus, besides describing our dis-\ncovery approach, we also discuss alternatives. The flexibility\nof agent systems is a key advantage of our AgentSimulator,\nenabling adaptation to diverse collaborative work dynamics.\nAgent instantiation. In business process environments, re-\nsources are the active entities performing actions. Therefore,\nwe instantiate one agent a \u2208 A for each resource res \u2208\nRESL. For our motivating example, we thus instantiate six\nagents (five human actors and System). If certain events lack\nresource information, we additionally generate a dummy agent\nfor each distinct activity that lacks such information. We\nnoticed that events without resource information often refer\nto either instantaneous activities or system resources. First,\nexplicitly modeling these as agents ensures that any activity"}, {"title": "Agent type.", "content": "To assign a type to each agent, we use the\nalgorithm from [10] that clusters agents into types based on\nthe similarity of their executed activities. This algorithm is\nalso used in [4] to group simulated resources."}, {"title": "Schedule.", "content": "We discover a schedule for each agent a \u2208 A\nby using the same algorithm as proposed in [8]. Note that\ndiscovering the schedule per agent type is also a possible\ndesign choice that our approach allows for. Furthermore, the\nmore recent approach to discovering probabilistic instead of\ncrisp calendars [11] could also be integrated."}, {"title": "Capabilities.", "content": "The capabilities a.c of an agent a consist of a\nset of activities and a set of PDFs over processing times."}, {"title": "Set of activities.", "content": "We discover the set of activities a.c.ALLOC\nthat agent a can execute by checking which activities from\nACTL (the resource corresponding to) a has performed in L."}, {"title": "Processing times.", "content": "The set of PDFs over processing times\na.c.PT contains one distribution for each activity that re-\nflects how long agent a requires to execute each of these\nactivities. Following [4], we fit various distributions to the\nactivity durations. Subsequently, we select the distribution with\nthe lowest error measured by the Wasserstein distance. The\nset of distributions includes the following ones: Exponential,\nGamma, Normal, Uniform, Log-Normal, and a fixed value\nto capture activities with fixed durations. However, instead\nof discovering one PDF per activity, we discover one PDF\nfor each combination of agent and activity, denoted as a\nmapping ACTL \u00d7 A \u2192 PTT, where PTT = Uaca a.c.PT.\nThis ensures more realistic activity processing times, as, for\nexample, a junior employee typically requires more time to\nperform the same activity than a senior employee.\nThe properties type, schedule, and capabilities are aspects\ncommonly considered in non-agent-based simulation ap-\nproaches as well, which is why we largely follow existing\nworks for their discovery. However, the distinctive agent\nbehaviors serve as the main ingredient of our AgentSimulator."}, {"title": "Behavior.", "content": "The behavior of an agent a.b describes its activity\ntransition and agent handover patterns. Therefore, the behavior\nof an agent determines (i) which activity is the next in\nan ongoing case and (ii) who performs this activity. The\nbehavior can be learned in many different ways, leading to\nnumerous design options for the architecture of the MAS.\nBelow, we outline two distinct behavior discovery approaches:\none suitable for capturing processes involving orchestrated\nhandovers and one for processes with autonomous handovers."}, {"title": "Orchestrated handovers.", "content": "We use this first configuration to\nmimic processes that are centrally orchestrated, such as those\nsupported by a workflow or business process management\nsystem [1]. In such processes, the execution of a case is\ncentrally guided. Therefore, this kind of architecture only\nrequires discovering global execution patterns, which are inde-"}, {"title": "To compute transition probabilities from a given activity", "content": "dependent of specific agents. We achieve this by learning activity\ntransition probabilities at the log level.\nSpecifically, we compute the frequentist probability of tran-\nsitioning to an activity given the activity prefix of an ongoing\ncase, where a prefix oprefix = (e1, 2, ..., ek) is the sequence\nof events from the beginning of o up to event ek, with oth\nbeing the corresponding activity sequence. This transition\nprobability Pact prefix) is computed by determining how\no prefix\noften each possible activity prefix act prefix in log L is followed\nby each activity act \u2208 ACTL. This is achieved by dividing\nthe number of times the specific transition from ex to act\nhappens by the number of times the activity prefix occurs in\nthe log. Note that, in case an activity prefix act prefix has not been\nobserved in the log, we iteratively remove the first activity of\nthe prefix until we reach a subsequence that has been observed\nin L, e.g., if we have not seen (a, b, c, d), we next check for\noccurrences of (b, c, d). To transition to the end of a case, we\nintroduce a placeholder end event following the last activity in\neach case. Furthermore, without loss of generality, transition\nprobabilities may also be computed using other methods, such\nas through next-activity prediction techniques [12], [13]."}, {"title": "Autonomous handovers.", "content": "As argued in Section II, many pro-\ncesses provide higher flexibility and decision power to the\nagents involved. Therefore, our AgentSimulator can also be\nused to discover decentralized MASs in which agents them-\nselves determine the next activity for a process instance and\nwhich agent should perform it. In this case, activity transition\nprobabilities need to be learned locally instead of globally.\nThe locality can either be given by the individual agent or\nthe agent type, i.e., activity and agent transition probabilities\ncan either be unique for each agent or generalized across all\nagents of the same type t \u2208 T. The latter can make sense if\nonly limited data is available per agent."}, {"title": "P(a_i|a_j).", "content": "To compute transition probabilities from a given activity\nprefix act prefix to an activity act \u2208 ACTL individually for each\nagent a \u2208 A, we can extend the computation described for\norchestrated handovers and make it agent-depending. Thus,\nP(act opex, a) is computed by counting for each agent a \u2208 A\nhow often there happened to be a transition from act prefix to\nact with the last activity of the prefix being performed by a,\ndivided by the total number of occurrences of ract with its\n\u03c3 prefix\nlast activity being executed by a. Consider Angela in Figure 1\nwho, given the prefix application received, always first checks\nthe credit history before the income sources, whereas Steve\nand Oliver have no fixed order as they sometimes collaborate.\nIn addition to activity transitions, the autonomous handover\narchitecture also accounts for distinct interaction patterns\namong agents. Therefore, we compute the frequentist proba-\nbility of handing over a case from one agent to another agent.\nThe conditional probability P(a_i|a_j) of handing over a task\nfrom agent aj to a\u017c with i,j \u2208 {1, ...,|A|} is computed by\ncounting all occurrences where one activity is performed by\naj and the following activity is executed by ai, divided by\nthe total number of activities performed by aj. Following\nour example, this results in P(Maria|Angela) = 0.0 and\nP(Patrick|Angela) = 1.0."}, {"title": "The combination of", "content": "There exist several other approaches to compute the han-\ndover probabilities. For instance, including the dependence of\nthe specific activity in the conditional probability P(a_i|a_{j, act})\ncould make the interaction patterns even more precise. Com-\np\u00e1ring different approaches for determining the interaction\npatterns can be tackled in future work.\nThe combination of Pact ex, a) and P(ailaj) defines\nagent behavior in an autonomous handover architecture and\ncaptures agent-specifics that influence the progress of a case."}, {"title": "General simulation parameters.", "content": "After having instantiated\nthe set of agents A, we discover some general simulation\nparameters \u0442.\u0440 = (fiat, D), where fiat is a PDF of case\ninter-arrival times and D a set of PDFs over extraneous delays.\nThese parameters are not specific to an agent-based simulation\nmodel but are also used in other BPS approaches [4]."}, {"title": "Inter-arrival times.", "content": "Inter-arrival times denote the duration\nbetween the start of two consecutive cases. The PDF over\ninter-arrival times is used during simulation to sample new\ncases. For discovering the PDF over case inter-arrival times\nfiat, we follow [4] who fit different distributions to the inter-\narrival times and take the one with the smallest error."}, {"title": "Extraneous delays.", "content": "Because different instances of a process\ntypically compete for limited resources and because resources\ndo not always start an activity as soon as it can possibly be\nperformed, processes are affected by waiting times. Extraneous\ndelays are waiting times that are not caused by resource\ncontention or unavailability (e.g., a resource waits for the\ncustomer to return a phone call). They need to be modeled\nexplicitly. Following the algorithm in [14], we discover a PDF\nover extraneous delays for each activity, resulting in a set of\nextraneous delay distributions D."}, {"title": "C. Phase 2: Simulation", "content": "This section details how the AgentSimulator approach uses\nthe discovered MAS m to simulate an event log L', illustrated\nby the pseudo-code in Algorithm 1. The simulation proceeds\nin discrete steps, each representing a time tick. At each step,\nwe check if new cases arrive and for each running case in the\nsystem, we verify if it is waiting to be processed (e.g., due\nto completion of the previous activity) to instantiate the next\nactivity. The simulation step ends after all cases have been\nchecked. In more detail, one simulation step looks as follows:\n1) Check for new cases. Based on the discovered inter-arrival\ndistribution p. fiat, we first check if a new case arrives (Line 3).\nIf there are multiple cases in the system, their processing order\nis determined in a first-in-first-out manner. Note that when\nevaluating against a test log, we follow the convention of\nSimod [4] and only simulate as many case arrivals as there\nare cases to be simulated. However, for regular simulations,\nwe keep on letting cases arrive until we finish the simulation\nto avoid a cool-down phase, which is more realistic.\n2) Handle all running cases. The cases are processed one-\nby-one (Line 4) until all cases have been addressed:\na) Determine next activity. First, we check if the given case\nOprefix is waiting to be processed (Line 5). If so, a new event e is\ncreated with its corresponding activity e.act being determined\n(Line 7) either globally, modeling orchestrated handovers\nbased on the current activity prefix (i.e., a global entity\norchestrates the control-flow execution), or locally, modeling\nautonomous handovers through the last active agent in the\ncase. Note that a case's first activity is always determined\nglobally as there is no prior agent.\nb) Determine the responsible agent. After a new activity was\ndetermined for the given case, it requires an agent for the\nexecution. Based on the set of activities that an agent can\nexecute a.c.ALLOC, we identify possibly responsible agents\np_a (Line 11). To determine the specific agent (Line 12), we\nagain differentiate between the two architectures:\n\u2022 Orchestrated handovers. In a MAS with orchestrated han-\ndovers, there are no agent interaction patterns modeled.\nThus, having determined the set of possibly responsible\nagents, we order this set based on the agent availabilities\nand iteratively ask these agents to perform the next ac-\ntivity until one agent is available to execute it (which we\ncall iterative task allocation). Thus, the first agent to be\nasked is the one that offers (based on its schedule a.s and\nits current occupation) the earliest availability. An agent\nrefuses to accept the activity if its estimated duration\n(based on fpt (act) \u2208 a.c.PT) collides with occupied or\nnon-working time slots. If none of the possible agents are\navailable, the case cannot be processed for now and will\nbe checked again in the next simulation step. Thus, the\ncase receives waiting time due to contention (Line 14).\n\u2022 Autonomous handovers. In a MAS with autonomous han-\ndovers, we use the computed agent handover probabilities\nP(araj) to determine the next agent. There are two\ndesign choices for their usage: (i) iterative task allocation\nand (ii) direct task assignment.\n(i) Using iterative task allocation, we simulate (just as in\nthe orchestrated handovers) that agent aj iteratively asks\nother agents to take the activity. However, the difference\nis that here the order of to-be-asked agents is determined\nby the agent handover probabilities that are transformed\ninto a ranking, i.e., agent ai is asked first if it has the\nhighest handover probability from aj.\n(ii) Using direct task assignment (not represented in\nAlgorithm 1), current agent aj does not ask agents until\none is available but assigns the task to an agent who then\nstarts executing it as soon as it finds the time. This can\nbe a common agent interaction pattern in real-life processes,\nfor instance, if an employee forwards a case via e-mail\nto a colleague. For this direct assignment, we sample the\nagent based on the agent handover probabilities.\nNote that a case's first agent is always determined as described\nfor orchestrated handovers.\nc) Start activity execution. If an agent could be identified, it\nbegins executing the assigned activity, with the end timestamp\nbeing determined by sampling from the agent-specific activity\nduration distribution fpt(act) \u2208 a.c.PT and potentially adding\nextraneous delays using fa(act) \u2208 p.D (Line 16).\nAfter each case is processed, a simulation step is completed.\nA case exits the system once its final activity is executed"}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "This section presents the experiments used to evaluate\nthe performance of AgentSimulator. Table I summarizes the\ncharacteristics of the 9 publicly available event logs used in\nour experiments, which are commonly used in BPS evaluations\n[5], [6], [15] as they contain both start and end timestamps.\nA. Experimental Setup\nImplementation. We implemented our approach in Python\nusing the agent-based modeling framework mesa [16].\nBenchmark approaches. We empirically compare our\nAgentSimulator (AgentSim) against three common data-driven\nBPS approaches. We adopt the state-of-the-art Data-driven\nProcess Simulation (DDPS) approach from [8], which we refer\nto as Simod. It combines the original Simod [4] with the\nProsimos simulator, which considers differentiated resource\navailability and performance and was shown to outperform the\noriginal Simod. DeepGenerator (DGEN) [12] is a pure Deep\nLearning (DL) approach, and DeepSimulator (DSIM) [6] is a\nhybrid of DDPS and DL (more details in Section V).\nData split. We follow evaluations of existing BPS approaches\n[5], [6], [12] and perform a temporal hold-out split, excluding\nall cases that span the separation time between the train set\n(first 80% of cases) and the test set (last 20% of cases).\nHyperparameters. AgentSim has two automatically deter-\nmined hyperparameters: the architecture (orchestrated or au-\ntonomous handovers) and whether to consider extraneous\ndelays, resulting in 4 possible configurations. We treat the\nlatter as a hyperparameter because we noticed considerable\ndifferences regarding the benefit of considering extraneous\ndelays between different event logs. We determine both hyper-\nparameters by initially simulating the last 20% of the training\nset for each of the 4 possible configurations and checking\nwhich simulation most closely resembles the training subset\nin terms of cycle time. To ensure a fair comparison, we use\nthe same option regarding extraneous delays for Simod.\nMetrics. To evaluate and compare the different simulation\napproaches, we use recently proposed metrics that are de-\nsigned to evaluate simulation models across three dimensions:\ncontrol-flow, time, and congestion, thus, providing a holistic\nperspective [15]. All metrics compute the distance between\nthe simulated and test log, where a lower value indicates\na better result. To measure the control-flow, we use the N-\nGram Distance (NGD) that computes the difference in the\nfrequencies of the n-grams observed in the event logs. To\nmeasure the temporal performance of the simulation, we\nuse the Absolute Event Distribution (AED), the Circadian\nEvent Distribution (CED), and the Relative Event Distribution\n(RED). To measure the capability of a model to represent\ncongestion, we use the Cycle Time Distribution (CTD). We\ndo not measure the Case Arrival Rate as we apply the same\ncase arrival method as Simod, thus, we focus on metrics where\nAgentSim differs from other approaches."}, {"title": "B. Results", "content": "Overall results. Table II summarizes the results for the 9 event\nlogs, showing the average metrics from 10 simulation runs for\neach log. The best value per log and metric is marked in bold,\nthe second-best is underlined. Generally, no single approach\nconsistently outperforms the others across all datasets and\nmetrics as also observed in previous BPS works [5], [6].\nHowever, AgentSim stands out by most frequently achieving\nthe best performance within each metric across the 9 logs.\nWhen looking more closely at the 3 dimensions captured by\nthe metrics, we can obtain the following main insights:\nControl-flow. Achieving the best NGD (N-gram distance) in\n4 out of 9 logs and considerably outperforming Simod and\nDSIM, the results indicate that our resource-first AgentSim\napproach, which is independent of an underlying process\nmodel enhances the accuracy of the control-flow dimension\ncompared to control-flow-first approaches such as Simod. This\nis particularly evident when analyzing the two real-life BP\u0399\nlogs. Thus, putting the resource at the core of the simulation\noften allows to represent control-flow behavior more faithfully.\nTime. In terms of absolute (AED), circadian (CED), and\nrelative (RED) event distributions over time, AgentSim is\nthe leader across all 3 metrics, followed by DSIM. Simod\nand DGEN stay on average significantly behind AgentSim.\nThese results indicate that AgentSim can capture the temporal\npatterns in the logcomparatively well.\nCongestion. Accurately capturing the cycle time of a process\ninstance serves as a critical indicator of the accuracy of a simu-\nlation approach. The CTD metric is influenced by the process-\ning times of individual activities and the corresponding waiting\ntimes, which in turn are dependent on resource availability.\nConsequently, the cycle time metric captures a comprehensive\nrange of factors. AgentSim demonstrates superior accuracy in\ncapturing cycle times compared to the benchmarks, achieving\nthe best CTD in 5 out of 9 logs, again followed by DSIM lead-\ning in the remaining 4 logs. The advantage of AgentSim over\nSimod is particularly pronounced with the Confidential logs."}, {"title": "Here, Simod's simulated logs exhibit significantly longer cycle", "content": "Here, Simod's simulated logs exhibit significantly longer cycle\ntimes compared to reality, primarily due to resource contention\nand the consequent waiting times. AgentSim mitigates this\nissue by recognizing that some agents do not require waiting\ntime, such as agents performing instantaneous activities.\nImpact of handover configuration. Simulating the same\nprocess using the two different handover configurations (cen-\ntrally orchestrated versus autonomous) reveals considerable\ndifferences in results for some logs (full results for both\noptions are in our repository). Overall, our automated method\nof selecting the handover configuration in AgentSim leads to\n5 of 9 processes being simulated with orchestrated handovers,\ne.g., P2P and Production, for which AgentSim, despite being\na resource-first approach, still yields strong results. Some\nlogs strongly benefit from being simulated in an orchestrated\ninstead of autonomous manner. For instance, the Production\nlog shows an improvement in CTD from 45.65 to 25.79 and\nin NGD from 0.77 to 0.61, aligning with the standardized\nnature of production processes. By contrast, looking at the\nlogs that are simulated with autonomous handovers, we also\nobserve clear benefits of considering distinct agent behaviors\nfor certain processes. For instance, for the real-life BPI17W\nlog, we halve both the CTD and RED to 22.75 and 26.03,\nrespectively, compared to the orchestrated configuration. Also,\nC. 1000 and Loan Appl. show slightly better results across all\nmetrics using autonomous handovers. Overall, these insights\ndemonstrate AgentSim's adaptability to diverse process types,\nleading to considerable improvements in terms of results."}, {}]}