{"title": "KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation", "authors": ["Siyuan Fang", "Kaijing Ma", "Tianyu Zheng", "Xinrun Du", "Ningxuan Lu", "Ge Zhang", "Qingkun Tang"], "abstract": "Large language models (LLMs) demonstrate exceptional performance across a variety of tasks, yet they are often affected by hallucinations and the timeliness of knowledge. Leveraging knowledge graphs (KGs) as external knowledge sources has emerged as a viable solution, but existing methods for LLM-based knowledge graph question answering (KGQA) are often limited by step-by-step decision-making on KGs, restricting the global planning and reasoning capabilities of LLMs, or they require fine-tuning or pre-training on specific KGs. To address these challenges, we propose Knowledge graph Assisted Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global planning abilities of LLMs for efficient and accurate KG reasoning. KARPA operates in three steps: pre-planning relation paths using the LLM's global planning capabilities, matching semantically relevant paths via an embedding model, and reasoning over these paths to generate answers. Unlike existing KGQA methods, KARPA avoids stepwise traversal, requires no additional training, and is adaptable to various LLM architectures. Extensive experimental results show that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both high efficiency and accuracy.", "sections": [{"title": "1 Introduction", "content": "In recent years, large language models (LLMs) (Touvron et al., 2023a,b; Achiam et al., 2023; Bai et al., 2023) have revolutionized natural language processing, demonstrating impressive performance in areas such as information extraction (Xu et al., 2023), summarization (Jin et al., 2024), and question answering (Louis et al., 2024). However, despite these advancements, LLMs face notable challenges, particularly in maintaining up-to-date knowledge, domain-specific knowledge (Zhang et al., 2024), and dealing with hallucinations (Zhang et al., 2023; Huang et al., 2023) where LLMs produce incorrect or nonsensical outputs.\nKnowledge graphs (KGs) enhance the reasoning capabilities of LLMs by providing structured, reliable external knowledge (Zhu et al., 2024; Pan et al., 2024). Existing approaches to integrating LLMs with KGs fall into two categories: (1) Direct interaction between LLMs and KGs, where the LLM explores the KG step-by-step (Sun et al., 2023; Jiang et al., 2023), often relying on local search strategies like beam search. These methods can produce suboptimal answers by overlooking the LLM's global planning and reasoning potential. Additionally, they require numerous interactions between LLMs and KGs, as shown in Figure 1(b). (2) Training-based methods, such as reasoning on graphs (RoG) (Luo et al., 2023), generate retrieval information for KGQA. However, they often require fine-tuning or pre-training on specific KG data (Li et al., 2023b; Huang et al., 2024). These methods struggle with unseen KGs, necessitate retraining, and are prone to hallucinations during information generation.\nTo address these limitations, we propose Knowledge graph Assisted Reasoning Path Aggregation (KARPA), an innovative framework that leverages the global planning capabilities of LLMs alongside semantic embedding models for efficient and accurate KG reasoning. Our approach consists of three key steps: pre-planning, matching, and reasoning, as shown in Figure 2. In the pre-planning phase, KARPA enables the LLM to generate initial relation paths for the provided question using LLM's inherent reasoning and planning capabilities. With these inital relation paths, KARPA employs a semantic embedding model (Ruder et al., 2019) to identify candidate relations that are semantically similar to the relations within the initial paths. The LLM can then create coherent relation paths that logically connect the topic entity"}, {"title": "2 Related Work", "content": "Prompt-Based Reasoning with LLMs. LLMs such as LLAMA (Touvron et al., 2023a,b), Qwen (Bai et al., 2023), and GPT-4 (Achiam et al., 2023)have advanced reasoning by leveraging extensive internal knowledge. Various prompt-based"}, {"title": "3 Preliminary", "content": "Knowledge Graphs (KGs). KGs represent structured information as $G = (E, R)$, where $E$ is the set of entities and $R$ denotes the set of relations. Each relation $r\\in R$ connects two entities $(e_i, e_j)$, with $e_i, e_j \\in E$.\nRelation Paths and Reasoning Paths. A relation path $P$ connects a topic entity $e_t$ to an answer entity $e_a$ via a sequence of relations: $P = (r_1, r_2,...,r_n)$, where $r_i \\in R$. Reasoning paths further include intermediate entities along the path, represented as $P_r = \\{e_t \u2192 e_1 \u2192 ...\u2192 e_{n-1} \u2192 e_a\\}$.\nKnowledge Graph Question Answering (KGQA). KGQA aims to answer questions using information from KGs. Given a query $Q$, the goal of KGQA is to generate an answer $A$ using a function $f: A = f(Q, G)$, where $f$ extracts the answer from the KG $G$ based on $Q$.\nEmbedding Models and Semantic Similarity. Embedding models represent text in a continuous vector space, enabling semantic similarity measurements. A function $\\Phi : R \\rightarrow R^d$ maps a sentence $R$ to a d-dimensional vector. Similarity between embeddings is computed using cosine similarity:\n$\\operatorname{sim}(r_i, r_j) = \\frac{\\Phi(r_i) \\cdot \\Phi(r_j)}{||\\Phi(r_i)|| ||\\Phi(r_j)||}$   (1)\nwhere \u22c5 is the dot product and $||\u00b7||$ is the Euclidean norm. This metric aids in comparing semantic information for retrieval tasks."}, {"title": "4 Approach", "content": "In this section, we present KARPA, a framework that leverages the strengths of LLMs and embedding models to enhance KGQA. Our approach is composed of three key steps: pre-planning, matching, and reasoning, as illustrated in Figure 2."}, {"title": "4.1 Pre-Planning with LLM", "content": "The pre-planning phase leverages the global planning capabilities of LLMs to generate initial paths $P_{\\text{initial}}$ and candidate paths $P_{\\text{cand}}$. This phase initiates the reasoning process by allowing the LLM to analyze the input question $Q$ and the associated topic entity $e_t$. By leveraging the reasoning capability of LLM, KARPA is able to propose paths that are not only logically coherent but also have the potential to lead to the answer entities $E_a$.\nInitial Planning Using LLM KARPA starts by using the LLM to generate a set of initial relation paths based on the provided question $Q$, as shown in Figure 2. The LLM outputs a set of potential relation paths $P$ as follows:\n$P = \\{P_1, P_2, ..., P_m\\},$ where $p_i = (r_{i_1}, r_{i_2},..., r_{i_{n_i}}).$ (2)\nHere, each $p_i$ is a path of $n_i$ relations $r$ that could logically connect a topic entity $e_t$ to the potential answer entity $e_a$. The relations within these paths serve as candidates for relations extraction.\nRelation Extraction Strategy With the initial relation paths $P$, we decompose each path $p_i$ into its constituent relations $R_i = \\{r_{i_1}, r_{i_2},..., r_{i_{n_i}}\\}$. For each relation $r \\in R_i$, we utilize an embedding"}, {"title": "4.2 Relation Paths Matching", "content": "The matching step in KARPA extracts relevant relation paths from KGs based on the LLM-generated candidate paths $P_{\\text{cand}}$, as shown in Figure 2. This process systematically explores and scores potential relation paths for reasoning step.\nConventional Relation Paths Matching\nConventional LLM-based KG exploration methods, such as ToG(Sun et al., 2023), typically involve the LLM selecting top-K promising relations $R_t$ from the adjacent relations of the current entity $e$ at each step. This strategy resembles greedy algorithms, such as beam search. Formally, let $R(e)$ denote the set of relations available for the current entity $e$. The selection process can be defined as:\n$R_{\\text{selected}} = \\underset{r \\in R(e)}{\\operatorname{argmax}} f(r), r \\in KG.$ (5)\nIn Equation 5, $f(r)$ is a scoring function indicating the potential of relation $r$. Since embedding similarity represents the similarity between two relations, we use $1 - \\operatorname{sim}(r_i, r_j)$ as the cost function for beam search. However, this approach does not guarantee finding the optimal path, as it may overlook globally optimal solutions.\nTo enhance relation path matching, we employ traditional pathfinding algorithms like Dijkstra's,"}, {"title": "4.3 Reasoning with LLM", "content": "In the reasoning step, we combine the matched relation paths with their respective entities $e$ into a prompt for the LLM to reference during the final answer determination, as shown in Figure 2. The reasoning process can be expressed as:\n$\\text{Answer} = \\text{LLM}(Q, P_K, e),$ $P_K = \\{r_1, r_2,..., r_n\\}.$ (10)\nGiven the top-K candidate paths $P_K$ and their corresponding entities $e$, the LLM can effectively assess whether the provided connections lead to a valid answer to the question $Q$. The KARPA framework facilitates the LLM's ability to evaluate multiple reasoning paths in parallel, thereby enhancing the overall efficiency of LLM-based KGQA tasks."}, {"title": "5 Experiments", "content": "In this section, we detail the experimental setup, present our main results, and conduct further analysis to evaluate the performance of KARPA."}, {"title": "5.1 Experimental Settings", "content": "Datasets and Evaluation Metrics We evaluate KARPA on two widely used multi-hop KGQA"}, {"title": "5.2 Main Results", "content": "Comparison between Baselines\nWe compare KARPA with other approaches in Table 1.The results show that KARPA significantly outperforms existing baselines across most metrics, achieving state-of-the-art performance. When comparing to the direct answering methods, we demonstrate that leveraging KGs as external knowledge sources enables the LLM to yield superior answers. In contrast to training-based methods, KARPA is plug-and-play, requiring no additional training while maintaining effective KG-based reasoning. When comparing with inference-based method, which also utilizes LLMs for reasoning over KGs without additional training, KARPA achieves superior results by leveraging LLM's global planning"}, {"title": "5.2.2 Performance Across Different LLMs", "content": "We also evaluate ToG and KARPA across various LLMs. As shown in Table 3, KARPA consistently outperforms ToG and CoT, regardless of the LLM, by leveraging global planning to construct more logically sound and complete reasoning chains. In contrast, ToG's reliance on stepwise relation selection limits its effectiveness, as it neglects the"}, {"title": "6 Analysis and Discussion", "content": "Interaction Comparison\nWe compare the average number of interactions required by KARPA and ToG across multiple LLMs and datasets. As shown in Table 5, KARPA reduces interactions by more than half compared to ToG while maintaining higher answer accuracy."}, {"title": "6.2 Ablation Study", "content": "Impact of matching methods. Table 3 shows that KARPA-H achieves the best matching results, demonstrating the advantage of its flexible and robust performance for KGQA.\nInfluence of different LLMs. Figure 3 shows the impact of LLM capabilities on KARPA's performance. More powerful LLMs, such as GPT-4, generate better relation paths, leading to more accurate answers (Kaplan et al., 2020). With weaker LLMs like GPT-4o-mini, performance declines slightly"}, {"title": "6.3 Discussion", "content": "KARPA requires fewer interactions and token usage comparing to ToG, while still outperforming ToG even when using smaller LLMs. This efficiency stems from KARPA's ability to generate complete reasoning chains, reducing the need for stepwise interactions in other methods. Methods like ToG impose heavy computational burdens by evaluating hundreds or even thousands of adjacent relations at each step, whereas KARPA's global planning aligns better with human-like reasoning. Table 7 demonstrates that KARPA performs robustly across embedding models. Its pre-planned paths are distinctive and semantically aligned with correct reasoning paths, making even lightweight embedding models sufficient for path matching."}, {"title": "7 Conclusion", "content": "In this paper, we propose KARPA, a novel framework designed to enhance LLM-based KGQA by utilizing the global planning and reasoning capabilities of LLMs. KARPA addresses key limitations of existing methods, achieving superior accuracy and efficiency through its pre-planning, matching and reasoning processes. Our experiments show that KARPA consistently outperforms state-of-the-art methods across multiple datasets. Its training-free design allows seamless integration with various LLMs, making it broadly applicable to different KGQA tasks. By optimizing LLM-KG interactions, KARPA enhances reasoning efficiency and effectiveness, highlighting its potential as a robust approach for future RAG systems."}, {"title": "8 Limitations", "content": "Although KARPA effectively reduces the reliance on the capacity of LLMs, its performance is still influenced by the reasoning and planning capabilities of the LLMs themselves. In situations where weaker LLMs are used, KARPA's performance may degrade due to LLMs' limited ability to generate logically coherent paths or perform intricate reasoning tasks. In our future work, we aim to enhance KARPA's performance on weaker LLMs, ensuring that KARPA remains effective across a broader range of LLMs with varying levels of reasoning and planning capabilities."}, {"title": "A Algorithm for KARPA", "content": "In this section, we present the pseudo-code for the Knowledge graph Assisted Reasoning Path Aggregation (KARPA) framework, as shown in Algorithm 1. The pseudo-code outlines the key components of our approach, including the pre-planning, matching, and reasoning phases. It demonstrates the interaction between the large language model (LLM) and the embedding model in generating, matching, and refining relation paths, which are crucial for improving LLM-based KGQA tasks."}, {"title": "B Implementation Details", "content": "Model Invocation. KARPA is tested with LLMs such as GPT-4 (OpenAI, 2023), GPT-4o (OpenAI, 2024), GPT-4o-mini, Claude-3.5-Sonnet (Anthropic, 2024), Gemini-1.5-pro (Team et al., 2024), and other LLMs through API calls. These LLMs are queried dynamically throughout the experimental pipeline to perform pre-planning, matching, and reasoning steps.\nExperimental Setup. During the pre-planning stage, the initial paths generated by the LLM are decomposed and stored, along with the query, into a list. For each element in this list, we extract the top-k relations, where the total number of extracted relations does not exceed 30. These relations are semantically closest to the elements based on the LLM's initial output.\nIn the matching step, KARPA selects the top 16 relation paths with the highest similarity for each initial relation path. These paths serve as candidate paths for reasoning step. In the reasoning step, we limit the number of candidate paths input to the LLM at one time to a maximum of 8, ensuring that the reasoning process remains manageable and focused on the most relevant paths.\nAnswer Evaluation. To determine if the LLM correctly answers the question, KARPA enforces a specific output format. The final answer must be enclosed in curly brackets in the LLM's output. We consider an answer correct only when the tail entities of the reasoning paths match the text enclosed within the curly brackets in the LLM's output. For CoT, we consider an answer correct if the LLM's response contains the correct answer entities. This difference reflects the distinct reasoning and output expectations between KARPA and CoT."}, {"title": "C Additional Results", "content": "In this section, we present additional experimental results to further evaluate the performance of KARPA when using different matching methods: KARPA-B (beam search-based matching strategy), KARPA-P (pathfinding-based matching strategy), and KARPA-H (heuristic value-based matching strategy). We conduct these experiments across various LLMs, analyzing the effectiveness of each"}, {"title": "D Additional Experiments", "content": "In this section, we provide additional experiments to validate KARPA's performance from different perspectives.\nTo demonstrate that KARPA has better generalization capabilities than methods based on instruction-tuned LLMs, we conducted an experiment using GPT-4o-mini with a modified version of the WebQSP dataset. Specifically, we slightly alter the questions in WebQSP dataset while preserving their original meaning, using the prompt: \"Please revise the question to make it more clear, but the original meaning of the question and the corresponding answers remain unchanged.\" We test RoG using its instruction-tuned LLaMa2-Chat-7B from in the planning step and GPT-4o-mini for reasoning. In KARPA, we use GPT-4o-mini for both pre-planning and reasoning steps."}, {"title": "E Further Discussion", "content": "Effectiveness Beyond KGQA Tasks\nWhile KARPA is currently designed to address challenges in KGQA tasks, following the settings of prior works such as RoG and ToG, its methodology is generalizable to other knowledge-intensive tasks.\nKARPA's core idea lies in letting LLMs generate complete reasoning chains instead of disrupting reasoning continuity with step-by-step searching. This approach mimics human reasoning processes and enhances reasoning efficiency. For example, in knowledge-intensive task such as the retrieval of academic papers, KARPA could generate reasoning chains like \u201cresearch field \u2192 target journal/conference \u2192 specific keywords\u201d, and then retrieve the corresponding paper using semantic similarity. When extracting information from books, the reasoning chain like \u201cbook title \u2192 relevant chapter \u2192 relevant paragraphs\u201d could streamline the information extraction. This reasoning-chain generation aligns with human thought processes, making it both intuitive and adaptable to diverse knowledge-intensive tasks.\nIncorporating User Feedback Mechanisms\nKARPA's architecture is inherently well-suited to incorporating user feedback mechanisms due to its design of generating complete reasoning paths. We provide a potential extension here:\n\u2022 Initial Path Generation: KARPA generates an initial reasoning path based on the user query."}, {"title": "F Detailed Related Work", "content": "Prompt-Based Question Answering Using Internal Knowledge\nIn the field of large language models (LLMs), researchers explore how to combine internal knowledge with external information to enhance reasoning abilities. Existing models utilize a vast internal knowledge base and achieve significant progress in reasoning tasks. To further optimize these capabilities, researchers propose various prompt-based methods, such as Chain of Thought (CoT) (Li et al., 2023c) prompting. This method breaks down complex tasks into manageable steps, promoting structured reasoning and excelling in mathematical and logical reasoning. Building on CoT, researchers also develop variants like Auto-CoT (Zhang et al., 2022), Zero-Shot-CoT (Kojima et al., 2022), Complex-CoT (Fu et al., 2022), and new frameworks such as Tree of Thoughts (ToT) (Yao et al., 2024), which further expand the application range of LLMs.\nAdditionally, with regard to the \u201cdecoding\u201d problem of the reasoning process, Self-consistency CoT (Wang et al., 2022) serves as a representa-"}, {"title": "G Datasets", "content": "We adopt two widely-used multi-hop KGQA datasets in our work. Table 17 below gives detailed statistical information for both datasets.\n\u2022 WebQuestionsSP (WebQSP) (Yih et al.,"}, {"title": "H Baselines", "content": "We consider the following baseline methods for performance comparison:\n\u2022 IO Prompt: Directly query large language models (LLMs) for answers without relying on external sources of information or additional reasoning processes.\n\u2022 CoT Prompt: Utilizing Chain-of-Thought prompting with LLMs to facilitate reasoning involves guiding the LLM through a step-by-step process, where each step reflects the logical sequence of human reasoning.\n\u2022 LLM-Based KGQA Methods:\nKD-CoT (Wang et al., 2023) interacts with external knowledge to verify and amend the reasoning paths within the Chain-of-Thought (CoT), effectively overcoming issues of hallucinations and error propagation. It structures the CoT reasoning process of LLMs into a formatted multi-round QA approach. In each round, LLMs interact with a QA system that retrieves external knowledge, constructing more reliable reasoning paths based on the precise answers retrieved, thereby enhancing the accuracy and credibility of reasoning.\nUniKGQA (Jiang et al., 2022) unifies retrieval and reasoning in both model architecture and parameter learning by designing a shared pre-training task based on question-relation matching and applying fine-tuning strategies to optimize the retrieval and reasoning processes. It includes two main modules: a semantic matching module based on a pretrained language model (PLM) for question-relation semantic matching, and a matching information propagation module that spreads matching information along directed edges in the knowledge graph (KG).\nDECAF (Yu et al., 2022) arrives at the final answer by co-generating logical forms and direct answers and combining the best of both. Unlike approaches that rely on entity linking tools, DECAF simplifies the process of information retrieval by linearizing the knowledge base into text documents and locating relevant subgraphs using text-based retrieval methods.\nRoG (Luo et al., 2023) is an approach that combines LLMs with KG to achieve reliable and interpretable reasoning. The method first generates knowledge graph-based relational paths that serve as faithful reasoning plans, and then utilizes these plans to retrieve valid reasoning paths from the knowledge graph for accurate reasoning in LLMs. RoG enhances the reasoning capabilities of LLMs by training to distill knowledge from knowledge graphs and allows them to be seamlessly integrated with arbitrary LLMs for reasoning.\nToG (Sun et al., 2023) proposes a new LLM-KG integration paradigm \u201cLLM \u2194 KG\u201d that treats a LLM as an agent that performs a beam search over the knowledge graph iteratively to discover the most promising reasoning paths and return the most possible reasoning results. ToG leverages the reasoning power of LLMs and expert feedback to ensure trace-"}, {"title": "I Prompts", "content": "Our proposed KARPA framework consists of the following three main steps: (1) Pre-Planning; (2) Matching; (3) Reasoning. Among them, steps (1) and (3) use the Large Language Model (LLM), and Appendix I provides the related Prompts."}, {"title": "I.1 Pre-Planning", "content": "Initial-Planning Prompt\nIn the pre-planning stage, initial planning involves using an LLM to preliminarily generate several relation paths of different lengths. The prompt used for this process is given in Content I.1.1."}, {"title": "1.2 Reasoning", "content": "In the reasoning step, the top-K relation paths retrieved in the matching step, along with their connected topic entity, answer entities, the corresponding question, and all related information are input into the LLM. The prompt used is provided in content I.2 below."}, {"title": "J Case Study", "content": "In this section, we present a detailed case study to illustrate the effectiveness of KARPA in handling complex knowledge graph question answering (KGQA) tasks. KARPA leverages LLMs in both the pre-planning and reasoning steps. For the question \u201cWhat did James K. Polk do before he was president?\u201d, KARPA uses the LLM to generate initial reasoning paths and then further refines the answer by reasoning over the identified relation paths and corresponding entities. The following case study elaborates on the workflow of KARPA in this example, showcasing its ability to utilize external knowledge and LLM planning capabilities to accurately answer the question.\nIn the pre-planning step, KARPA first utilizes the LLM to generate initial relational paths based on the provided question, as shown in Figure 4. Given the question \u201cWhat did James K. Polk do before he was president?\u201d, the LLM generates paths of varying lengths. Initially, the LLM considers whether the answer entities can be reached within a single relational step. Since the LLM considers the answer entities for this question cannot be reached in one step, the LLM outputs an empty reasoning path of length 1.\nWhen considering a relational path with two associated relations, the LLM infers that the answer entity can be found by first identifying the political positions held by James K. Polk through"}]}