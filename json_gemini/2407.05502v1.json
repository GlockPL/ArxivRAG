{"title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models", "authors": ["Nikhil Sharma", "Kenton Murray", "Ziang Xiao"], "abstract": "With Retrieval Augmented Generation (RAG), Large Language Models (LLMs) are playing a pivotal role in information search and are being adopted globally. Although the multilingual capability of LLMs offers new opportunities to bridge the language barrier, do these capabilities translate into real-life scenarios where linguistic divide and knowledge conflicts between multilingual sources are known occurrences? In this paper, we studied LLM's linguistic preference in a RAG-based information search setting. We found that LLMs displayed systemic bias towards information in the same language as the query language in both information retrieval and answer generation. Furthermore, in scenarios where there is little information in the language of the query, LLMs prefer documents in high-resource languages, reinforcing the dominant views. Such bias exists for both factual and opinion-based queries. Our results highlight the linguistic divide within multilingual LLMs in information search systems. The seemingly beneficial multilingual capability of LLMs may backfire on information parity by reinforcing language-specific information cocoons or filter bubbles further marginalizing low-resource views.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) have played a pivotal role in search technologies such as ChatGPT\u00b9 and Bing Copilot\u00b2. With Retrieval Augmented Generation (RAG), LLMs can leverage external knowledge that is outside of their training data and respond to questions about ongoing events (Lewis et al., 2021). Such search technologies have significantly impacted how people seek and access information worldwide. More importantly, the premise of LLM's multilingual capability (Qin et al., 2024a), supporting over 100 languages and multilingual understanding, offers new opportunities to break the language-specific information cocoon and provide more equitable information access for people with diverse linguistic preferences, cultural backgrounds, and geographical locations.\nHowever, achieving information parity is challenging because of the intrinsic complexity in how information is created and represented in different linguistic contexts. This complexity stems from a broad spectrum of cultural nuances, regional influences, and historical narratives that shape how information is consumed and communicated (White, 1990; Edelman, 1985). In addition, each language and cultural context also brings its own set of values and perspectives when interpreting an event of interest, which can significantly influence the representation of facts and narratives (Foucault, 1980).\nThis challenge is exacerbated by the linguistic divide, the gap in terms of representation between different languages on the internet (Li et al., 2024a; Mehdad et al., 2012). Not all facts and viewpoints are presented equally. Dominant languages, such as English, have a disproportionate influence on content creation and dissemination (Holborow, 1996). Such divides can lead to linguistic imperialism, where information in higher-resource languages is more accessible and frequently amplified, potentially overshadowing or distorting narratives in low-resource languages, particularly when differing views are presented (Phillipson, 2018).\nAs a result, when responding to user's queries, LLMs need to retrieve meaningful information from diverse multilingual sources and synthesize diverse perspectives and often conflicting knowledge residing in multilingual contexts. For example, when an information seeker asks for an event of conflict or topic with multiple perspectives in different regions, for instance, an ongoing war between two countries with distinct languages, LLMs should be able to present viewpoints and facts from both sides regardless of the query language.\nRecent evidence indicates information disparity in LLMs' behavior. Individuals asking the same query in different languages may get different answers. This difference manifests in the quality of the responses (Boughorbel and Hawasly, 2023; Jin et al., 2024a), consistency (Dong et al., 2024), and dispute resolution (Li et al., 2023). As illustrated in Fig. 1, current models like GPT-4 struggle with information disparity in multilingual settings. The narratives generated by LLMs regarding a conflict can vary significantly depending on the language of the query and the language of reference documents.\nTherefore, it is crucial to understand how the linguistic divide affects information disparity in the context of multilingual LLMs. In RAG, these biases can potentially skew both the retrieval and generation processes, favoring information from certain languages over others. Such biases could undermine the very goal of using multilingual LLMs to democratize access to information and support diverse information-seeking globally. If unchecked, these biases could reinforce existing cultural dominance and create an information cocoon, potentially alienating non-dominant language speakers and disproportionately perpetuating dominant views.\nThis study aims to understand information parity in multilingual LLMs, especially when conflicting perspectives and facts are presented in different languages. Specifically, we ask the following research questions,\nRQ1: How does the language of the query affect a multilingual LLM's information preference when it retrieves relevant documents and generates answers?\nRQ2: How do multilingual LLM's information preference change across different types of information queries?\nRQ3: How do multilingual LLM's information preference change if all relevant documents are in Foreign Languages?\nTo answer our research questions, we proposed a new multilingual synthetic dataset with 170 documents in 5 languages providing information about two fictional events. The dataset represents a real-world information environment where diverse, sometimes conflicting viewpoints and factual information are represented in different languages. Using the dataset as source references, we studied 13 multilingual LLMs with 7 query types and found,\n\u2022 Current multilingual LLMs have a systematic preference towards documents in the Native Language of the query.\n\u2022 Such preference is consistent across both factual and opinion-based queries in the retrieval phase.\n\u2022 Factual queries specifically targeting information in Foreign Languages can successfully retrieve information from Foreign Documents in the generation phase.\n\u2022 When there is no relevant document in the language of the query, the current LLMs prefer documents in high-resource languages over low-resource languages."}, {"title": "Experiments", "content": "To answer our research questions, we conducted a series of experiments on multilingual LLM's capabilities in responding to a diverse set of queries on fictional topics in five different languages.\nFocus on RAG There are two types of LLM-powered search systems: Retrieval Augmented Generation (RAG) and Direct Generation. In Direct Generation, the LLM relies on its parametric memory to respond to the user's query. In this paper, we focus on RAG (Lewis et al., 2021), where LLMs primarily rely on external knowledge presented in the context to answer user information queries. We made this choice for the following reasons: 1) most LLMs are closed source with no access to their parametric memory, and 2) most popular information systems, such as Bing Copilot, Perplexity.ai \u00b3, etc., use RAG to keep their search system updated with the most recent information.\nSeparating Retrieval and Generation Retrieval Augmented Generation consists of two phases: retrieval and generation. In the retrieval phase, the system retrieves a ranked list of documents based on cosine similarity scores between query embedding and document embedding. In the generation phase, the top documents are used as LLM's context to generate the response. In this study, we separated the two phases to independently study the effect of language when multilingual LLMs answer user queries with RAG.\nIsolating LLM's Parametric Memory To study LLM's information preference in RAG, we need to separate the effects of parametric memory from in-context non-parametric memory. We created a synthetic dataset with fictional entities that were not in the LLM's pre-training data.\n2.1 Multilingual Fictional Dataset\nThe overarching goal of our dataset is to mimic a real-world multilingual information environment"}, {"title": "Premise setup", "content": "Festival: The festival premise is designed for factual queries, which contain information about a fictional festival targeting factual queries. There are versions: original and alternate \u2013 each with some shared, contradictory, and exclusive facts. Here is an example with contradictory facts,\n\u2022 Original: Planet {{PLANET_NAME}} is a planet full of minions.\n\u2022 Alternate: Planet {{PLANET_NAME}} is a planet full of wonders.\n{{PLANET_NAME}} is a fictional named entity.\nWar: The war premise is designed for opinion-based queries. It contains information about a fictional war taking place between two fictional regions speaking different languages. This premise is designed to represent an information environment with diverse opinions and perspectives. Similarly, there are two document sets in the war: original and alternate \u2013 each taking the perspective of one side in the war. Example perspectives are\n\u2022 Original: {{BRANCH_FAMILY}} was accumulating too much power and diverging from the Confederation's values.\n\u2022 Alternate: {{MAIN_FAMILY}} had strayed from the path of righteousness.\nBRANCH_FAMILY and MAIN_FAMILY are fictional named entities."}, {"title": "Synthetic Dataset Creation", "content": "An overview of the process of creating our dataset is illustrated in figure 2. We describe the dataset creation steps in detail below:\nCore facts: To start, we created two variants for each premise: \"original\" and \"alternate\u201d. We manually created a set of 10 core facts about the premise for the original set. For the alternate set, we edit these core facts based on the setup of the premise in Sec. 2.1.1.\nExtended story facts: Since the festival premise by our design goals contains more short-form factual information instead of diverse perspectives, to mimic a more realistic setting, we expanded each core facts using OpenAI GPT-4-turbo model where we added a consistency check during the expansions such that none of the expansions contradict any of the core facts. The result was 5 extensions for each core fact, making a total of 50 story facts for the original document set and 50 for the alternate document set on each premise.\nFinal Documents: Based on these extended story facts for the festival premises, we created a total of 14 documents, 7 for each document set in the festival setting using OpenAI GPT-4-turbo with temperature = 1. We set temperature = 1 to make the model's responses diverse. Of these 7 documents, 2 were long documents, consisting of a subset of 4 story facts in a story format, and 5 were short documents, consisting of a subset of 2 story facts each, in a news format mimicking articles in the real world. The average length of these documents was 484.85 words.\nManipulation Check: We verified that the dataset is not in LLM's parametric memory by prompting each evaluated model with \u201cTell me about named entity\" with temperature = 0. We ensured that the model did not provide any meaningful answers for each named entity (places, objects, names, etc.). We also performed a Google search of the named entities and ensured that no article about the named entities existed as of June 2024.\nMultilingual Dataset Creation\nTo make our dataset multilingual, we translated documents and queries with translate-shell, a Python package that uses Google Translate at the backend, from English to the target language (e.g., de, hi, zh, hi). For the documents in the festival setting, we repeat the document creation step for each language, where we create a document set in English before translating it into the target language to mimic a real-world setting where the data is not entirely parallel."}, {"title": "Experiment Design", "content": "We queried popular multilingual retrieval models and multilingual LLMs with different types of user queries to analyze the preference of models when presented with conflicting multilingual information in retrieval and generation.\nDiverse Information Queries\nWe curated a diverse set of queries to mimic real-world multilingual information-seeking behaviors. We covered two types of information queries: factual and opinion-based. Each query has versions in 5 languages: English(en), Hindi(hi), Chinese(zh), Arabic(ar), and German(de) aligned with the languages used in the dataset.\nFactual Queries Based on the core facts, we created 27 factual queries consisting of 6 broad, 9 specific-contradiction, 9 specific-exclusive and 3 specific-differential queries. The descriptions of the query types are listed below:\n\u2022 Broad: Queries that target the generation of a summary of documents in different languages.\n\u2022 Specific-Contradiction: Queries that target contradictory facts in different languages.\n\u2022 Specific-Exclusive: Queries that target the exclusive facts in different languages.\n\u2022 Specific-Differential: Queries that ask the model to choose one of the two contradictory facts presented in different languages.\nOpinion-based queries Based on the core facts, we created 16 opinion-based queries consisting of 6 neutral, 5 confirmatory-original, and 5 confirmatory-alternate queries. We translated the"}, {"title": "Model Choices", "content": "We choose multilingual LLMs commonly used in RAG-based search systems, differing in size and the number of languages supported. All models support all the languages in our study.\nRetrieval: We evaluated OpenAI (text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large), Cohere (multilingual-light-v3.0, multilingual-v3.0) and Voyage (voyage-2, voyage-large-2, voyage-large-2-instruct) embedding models.\nGeneration: We evaluated OpenAI (gpt-3.5-turbo-0125, gpt-4o-2024-05-13), Cohere (aya-23-8B, aya-23-35B) and Antrhopic (claude-3-opus-20240229) models."}, {"title": "Experiment Setup", "content": "Retrieval: We embedded all the documents, got the query embedding for each premise, and obtained the ranked list of documents based on the cosine similarity score.\nGeneration: We followed the following prompt design: context + \"\\n Question:\" + question + \"\\n Answer:\" where context = original document set in Language + alternate document set in Language;"}, {"title": "Measures", "content": "In this paper, we define Native Language as having the same language of the query and Foreign Language as having a different language of the query.\n3.1 Retrieval\nWe follow the following metrics to evaluate the retrieval of multilingual LLMs:\nLanguage Distribution of the Top 10 Retrieved Documents\nWe analyzed the top 10 ranked documents retrieved by looking at the distribution of the document language in relation to the query language.\nPreference Score\nTo calculate the preference scores for each document, we normalize cosine similarity scores using z-score for the documents retrieved by each query. In this paper, we use the mean preference score to measure documents grouped by a property, such as Foreign Language vs. Native Language document."}, {"title": "Generation", "content": "In the generation process, we provide two documents in different languages as the context for generating the answer. We need reference answers for each context separately to evaluate which context the model used as the source for generating the answer. We then compare the generated answer to each reference answer from both document sets (original and alternate) to determine which context is more represented in the generated answer.\nEvaluation in English:\nFor the evaluation of generation, we use English reference answers only and translate the generated answers back to English using translate-shell4. This approach is necessary due to the lack of high-quality, robust metrics for evaluating multilingual text in generation tasks (Ahuja et al., 2023).\nReference Answers:\nTo obtain reference answers, we follow the same prompt template described in Section 2.4. We change the context to the original document set for the original reference answer and to the alternate document set for the alternate reference answer. To ensure quality, we review the reference answers and correct any discrepancies."}, {"title": "Information overlap (IO):", "content": "We use Information Overlap (IO) as our primary evaluation method. We use different strategies to evaluate the queries depending on the query type. For queries with subjective or lengthy answers\u2014such as broad queries in the festival premise and all queries in the war premise\u2014we use BERTScore(Zhang* et al., 2020) with the microsoft/deberta-xlarge-mnli model, which is the best-performing model in WMT16 for English tasks. We use keyword matching for factual queries\u2014all specific queries on the festival premises.\nSource Reference proportion: To analyze which document-set (original Language_i or alternate language_j) the model preferred to generate the answer, we use source reference proportion as our measure. We compute the IO of the gold_answer in the original language with the generated answer, which we call original_overlap and compare that with the IO of the gold_answer in the alternate language with the generated answer (alternate_overlap). The desired outcome is for the source reference proportion to be Both, i.e. when both scores are above @ or Original_overlap = Alternate_overlap. The outcome is Original when Original_overlap is higher and Alternate when Alternate_score is higher. The outcome is None when both scores are below a.\nWe do not consider a and 6 when the IO method is a keyword match. For BertScore, the authors manually analyzed and set a to 0.55, where answers above this threshold contained partial similarity with the reference answer but did not cover all points, and 0 to 0.7, where answers above this threshold contained most of the information from the reference answer."}, {"title": "Results", "content": "Retrieval\nWe measured the preference of Native and Foreign languages in the retrieval phase across 5 languages for 8 models (3 model families) in 2 premises, with 27 factual queries in the festival and 16 opinion-based queries in the war premise. A total of 215 queries were issued per model. Additional results for bert-based retrieval models and a Chinese-focused LLM are in Appx. A.5"}, {"title": "RQ1r: Preference for Native Language", "content": "Overall, for the top-10 retrieved documents, models preferred the Native Language Document 68% of the time across both premises. As shown in Figure 4, there was a strong preference for Native Language document retrieval, with an average z-score of 1.03 for Native Language versus -0.25 for Foreign Language. The trend is consistent across all models. Further results are in Appx. A.3"}, {"title": "RQ2r: Impact of query type on language preference", "content": "For factual queries, we did not observe significant differences across question types for both Native Language preference (Broad: M = 1.01, SE = 0.24; Specific-Contradiction: M = 0.97, SE = 0.21; Specific-Exclusive: M = 1.03, SE = 0.25; Specific-Differential: M = 0.90, SE = 0.22) and Foreign Language preference (Broad: M = -0.25, SE = 0.06; Specific-Contradiction: M = -0.24, SE = 0.05; Specific-Exclusive: M = -0.25, SE = 0.06; Specific-Differential: M = -0.22, SE = 0.05). The results are consistent across all models.\nSimilarly, for opinion-based queries, no significant differences were found across different question types for both Native Language preference (Neutral: M = 0.80, SE = 0.27; Confirmatory: M = 0.87, SE = 0.26) and Foreign Language Preference (Neutral: M = -0.20, SE = 0.06; Confirmatory: M = -0.21, SE = 0.06). Native Language documents are more likely to be retrieved by all models."}, {"title": "RQ3r: Second Language Preference", "content": "The second language preference looks into the model's language preference when there are no related Native Language documents. The second language preference for models varied based on training, model size, and model family. Key observations are as follows:\nModel Size: As model size increased, OpenAI and Cohere models showed similar second language preferences, but the magnitude of preference scores, see Sec. 3.1.2 decreased. For example, embedding-3-small saw de, zh, and hi all prefer en with average scores of M = 0.86 (SE = 0.04), 0.60 (SE = 0.04), and 0.59 (SE = 0.05), respectively. In embedding-3-large, these scores decreased to 0.45 (SE = 0.05), 0.27 (SE = 0.05), and 0.52 (SE = 0.05).\nConversely, Voyage models showed stronger preferences with increased size. Voyage-2 saw en, de, zh, and hi all prefer ar with scores of 1 (SE = 0.02), 0.89 (SE = 0.02), 1.28 (SE = 0.01), and 1.56 (SE = 0.01). In voyage-2-large, these scores increased to 1.12 (SE = 0.02), 1.22 (SE = 0.01), 1.44 (SE = 0.01), and 1.57 (SE = 0.01).\nInstruction Tuning: Voyage models showed a strong preference for Arabic in non-instruction finetuned versions. This trend changed with instruction tuning, altering both language preference and its magnitude. For instance, de and zh changed their preference to en with scores of M = 0.40 (SE = 0.06) and 0.29 (SE = 0.06), while en changed its preference to de with a score of M = 0.18 (SE = 0.06). hi still preferred ar, but the magnitude decreased to M = 0.89 (SE = 0.04).\nada-002 vs. embedding-3: A trend change was observed from ada-002 to embedding-3 (large and small). In ada-002, de, zh, and hi all preferred ar with scores of M = 0.28 (SE = 0.05), 0.51 (SE = 0.04), and 0.84 (SE = 0.04). In embedding-3, these languages preferred en."}, {"title": "Generation", "content": "We measured the preference in generation in 5 languages for 6 models (3 model families) across 2 settings with 27 queries and 16 queries each. In total we queried each model 5375 times5."}, {"title": "RQ1g: Preference for Native language", "content": "On average, across the two premises, the Native Language documents were the source for the answer 42% (SE = 0.54%) of times compared to 29.58% (SE = 0.5)% for Foreign Language Documents while only 8.55% (SE = 0.30%) contains information from both the sources, and 19.8% (SE= 0.43%) the answer was from none of the sources. This shows that the models systematically prefer to generate answers from the document in the Native Language as that of the query, even though diverse facts and perspectives were presented in a different language. Breakdown by model is in Appx. \u0410.4."}, {"title": "RQ2g: Impact of query type on language preference", "content": "Unlike retrieval, we observed that depending on the query, the model's preference for the document varied (Figure 6). For factual information, we observed a preference for Native Language documents over Foreign Language documents (Broad: $M_{native}$ = 57.05%, SE = 6.39% vs $M_{foreign}$ = 25.38%, SE = 3.75%) in broad"}, {"title": "RQ3g: Second Language Preference", "content": "We saw a preference for higher resource language as the Second Language across different queries in different languages, as shown in figure 5. Overall, across all models and query languages, we saw that on average, en (M = 39.56%, SE = 4.72%) > de (M = 35.82% SE = 4.35%) > zh (M = 33.93% SE = 4.35%) > ar (M = 35.82% SE = 4.08%) > hi (M = 32.79% SE = 3.95%). This also reflects the language resource, where English is the highest resource, and Hindi is the lowest."}, {"title": "Discussion", "content": "Through a comprehensive evaluation of the retrieval and generation phases of current multilingual RAG systems, we found that multilingual LLMs exhibit a clear preference for the language of queries and documents in high-resource languages. Given the premise of multilingual LLMs, breaking the linguistic barriers and information cocoon for global users, our results highlight a significant drawback in providing information parity and motivate further research. Below, we discuss our main findings and their implications."}, {"title": "Diverse, multilingual documents are hidden in retrieval", "content": "Retrieving diverse perspectives is a crucial phase in RAG systems. We found that the retrieval systems disproportionately prefer Native Documents in retrieval. 68% of the top-10 documents were Native Documents, which implies that today, most multilingual documents do not even reach the context of the LLMs in the generation phase."}, {"title": "LLMs prefer facts in Native Languages in knowledge conflict", "content": "In the generation experiment, we provided the model with diverse multilingual texts. Our results found that LLMs prefer facts from Native Documents and rarely present facts from both Native and Foreign perspectives. Our results indicate that the LLM-powered search system could create and intensify the information cocoon by only presenting facts in the information seeker's Native Language."}, {"title": "Only if you knew what you don't know", "content": "Our results also found that to generate results from Foreign Documents, the user must issue specific-differential or specific-exclusive queries (queries that specifically target exclusive information in the foreign document) to LLMs, whereas general queries like broad or confirmatory queries (general queries like tell me about event A) prefer Native documents. This, however, is difficult in a real-world setting where users often don't know the topic they want to search for, and the queries are more exploratory in nature."}, {"title": "High-resource languages dominate the information landscape", "content": "During our evaluation, we asked about the second language preference, i.e., the preferred language, when there was no source of Native Language documents. We found that during the generation phase, LLMs preferred high-resource languages as their second language. This is worrying because, often, when querying about international topics, the information is not present in the Native Language of the query. For instance, in Figure 1, if we query about the India-China conflict in Arabic, although there are facts about the conflict in Hindi and Chinese, which are the languages of the countries involved in the conflict, the model chooses to present the English viewpoint only. This behavior reinforces the views from dominant languages and further marginalizes the non-dominant views.\nIn our generation evaluation, \u201cBoth\u201d is considered ideal, where the model draws information from both documents and \"None\" is considered a failure, where the model can not generate correct responses. Our results showed that models' average performance increases when the query language is English or the documents in context are English. Such results again highlight the linguistic divide in LLMs. Details are in Appx. A.4.1."}, {"title": "Related Work", "content": "Language Disparity in Multilingual LLMs\nThere has been a rise in the multilingual capabilities of large language models (LLMs) (Qin et al., 2024b) with models now supporting over 100 languages. This rise has been facilitated by increasing multilingual datasets (Qin et al., 2024a; Singh et al., 2024; Sun and Duh, 2020) and benchmarks (Siddhant et al., 2020; Ahuja et al., 2023; Zhang et al., 2023; Liang et al., 2020; Ruder et al., 2021) evaluat-ing a diverse set of multilingual capabilities where recent multilingual LLMs such as GPT-4o have achieved STOA performance(Watts et al., 2024).\nHowever, this progress often hides the inherent language disparity that exists in Multilingual LLMs (Yu et al., 2022; Verma et al., 2022; Joshi et al., 2021); where pretraining data of models such as Llama and GPT-4 is still predominantly English. Such language disparity affects the multilingual capabilities of LLMs (Li et al., 2024b). The effect of language disparity in information parity has not been studied previously, making our study unique. Furthermore, such evaluations lack context realism (Liao and Xiao, 2023)."}, {"title": "Knowledge Conflicts", "content": "In real-world settings, multilingual interactions will be driven by conversational search, where the LLMs will interact with often conflicting and contradictory information across different languages. Recently, there have been studies exploring how such knowledge conflicts affect the LLMs responses (Xu et al., 2024; Jin et al., 2024b; Kortukov et al., 2024; Chen et al., 2022). In multilingual settings, Dong et al. (2024); Jin et al. (2024a); Boughorbel and Hawasly (2023); Li et al. (2023) explore how queries in different languages and cultural contexts affect the LLMs generation and preference for answers. However, in today's conversational search systems, there are two phases, information retrieval and generation, and how they individually react to knowledge conflict has not been studied yet. Moreover, less is known about how diverse types of queries influence the model's response to such knowledge conflicts, which has not been studied yet. For instance, Sharma et al. (2024) showed that users issued confirmatory queries while interacting with controversial information where knowledge conflicts are common and in response, LLMs mirrored the bias of the query, how such interactions shape up in multilingual settings is also not been explored before. In this paper, we aim to answer these unanswered questions."}, {"title": "Conclusion", "content": "The recent rise of multilingual LLMs and RAG has played a pivotal part in the exponential growth of conversational search across diverse users with different backgrounds, cultures, and languages. Such multilingual conversational searches have the ability to break linguistic barriers and provide users with information consisting of diverse viewpoints. However, we find that instead of offering diverse viewpoints, current multilingual LLMs struggle with information disparity across different languages by 1) failing to retrieve diverse, multilingual texts, 2) bias towards higher resource languages over lower resource languages and 3) preferring to generate from Native Facts over Foreign Document facts while not being able to generate facts from both the documents. This failure of current Multilingual LLM models to offer consistent information across different querying styles and languages leads to linguistic information cocoons. These results concern information parity and can lead to polarization and hinder constructive communication across different communities."}, {"title": "Limitations", "content": "We only studied 5 languages with the perspective of lower and higher resources. To understand the interaction between different languages along the lines of script and language family, we need a much larger pool of languages. For example, we did not run our study on very low-resource languages, such as Swahili and Khlosa, due to the limitation of creating document sets in these languages.\nAnother limitation is that we did not probe into the effect of pre-training knowledge. Pre-training data of models often have bias and based on that bias the models have a preference to generate certain outputs, how those existing preferences affect the RAG pipeline when dealing with conflicting information is another future direction. Moreover, our study only focuses on language differences instead of cultural differences. People in different cultures may speak the same language and have diverse narratives. Cultural differences during information foraging might add to the observed effect of linguistic preference. Finally, during our Evaluation, we only focused on one architecture of the RAG system, i.e., retrieval based on cosine similarity. However, there are other architectures, such as summarization, rerank, etc., that we have not evaluated."}, {"title": "Appendix", "content": "A.1 Cost of Experiments\nWe had 27 factual + 16 opinion-based queries. For all queries, we had 2 contexts: alternate and original. We had all permutations and combinations of these contexts across the 5 target languages, making it 5\u00d75 contexts for each premise (festival and war). We query each context with their respective query pool across all languages. This makes the total number of requests (27 factual queries + 16 opinion-based queries) \u00d7 5 query-languages \u00d7 5 original context languages \u00d7 5 alternate context languages. Each input context was around 1000 tokens and 526 output tokens. This results in a total of 5,375,000 input tokens and 2,872,250 output tokens per model. The cost of GPT-40 is $5.00 / 1M tokens for inputs $15.00 /1M tokens for outputs. This made the total cost of the experiments in generation phase for OpenAI GPT-40 $680.\nA.2 Prompt used in Dataset creation\nDuring our dataset generation process, we use two OpenAI calls: one to expand the core facts and one to verify their consistency (filter). We repeat this for three iterations to ensure we have enough expansions after filtering. We use the system prompt below with temperature t = 1 to expand the story. For the user prompt, we provide the model with JSON string of core facts."}]}