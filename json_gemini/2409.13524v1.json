{"title": "Contextualized AI for Cyber Defense: An Automated Survey using LLMs", "authors": ["Christoforus Yoga Haryanto", "Yoshiano Hartanto", "Anne Maria Elvira", "Emily Lomempow", "Trung Duc Nguyen", "Arathi Arakala", "Minh Hieu Vu"], "abstract": "This paper surveys the potential of contextualized AI in enhancing cyber defense capabilities, revealing significant research growth from 2015 to 2024. We identify a focus on robustness, reliability, and integration methods, while noting gaps in organizational trust and governance frameworks. Our study employs two LLM-assisted literature survey methodologies: (A) ChatGPT 4 for exploration, and (B) Gemma 2:9b for filtering with Claude 3.5 Sonnet for full-text analysis. We discuss the effectiveness and challenges of using LLMs in academic research, providing insights for future researchers.", "sections": [{"title": "I. INTRODUCTION", "content": "Contextualized AI enhances traditional Artificial Intelligence (AI) and Large Language Model (LLM) capabilities by integrating private data, beyond typical public datasets [1]. This emerging field finds application in autonomous monitoring, threat detection, and response within secured network environments [2], [3], [4], [5]. Yet, the full efficacy of these systems is under ongoing evaluation with challenges such as Al dependency, data privacy, human oversight, and end-to-end governance [6], [8], [9], [10], [11], [12], [13].\nInitially, we hypothesized such systems were ready for widespread deployment in cyber security. However, we discovered a complex landscape with diverse terminology and approaches, leading us to do comprehensive literature review.\nGiven the vast amount of potentially relevant research and the challenges in identifying pertinent studies, we decided to experiment with LLM-assisted methods for our survey while also providing us an opportunity to explore innovative methodologies for academic research [14], [15], [16].\nThis paper aims to conduct a survey of the literature in contextualized AI for cyber defense to answer:\n1) RQ1: How can cyber security decision-makers strategically leverage contextualized AI to enhance defense capabilities while mitigating risks?\n2) RQ2: Protection Layer: How can we ensure comprehensive protection of the system, data, and processes when implementing contextualized Al in cyber security?\n3) RQ3: Security System Layer: How can we guarantee that the AI-enhanced protection system itself functions reliably and as expected?\n4) RQ4: Organizational Layer: How can we foster organizational trust in AI, ensuring that the organization can confidently rely on AI capabilities within appropriate scopes while maintaining necessary human oversight?"}, {"title": "A. Definition of Contextualized AI", "content": "For this study, we define contextualized AI to be supplied as part of the prompt to LLM as follows:\nContextualized AI refers to AI systems designed to access and utilize proprietary and domain-specific knowledge. While it is not strictly generative AI and LLM, most of the contextualized AI systems are built on top of generative AI and LLM so pay attention to the usage that involves further training using proprietary or domain-specific knowledge on top of pre-trained model. Some earlier papers may mention full AI training using private data, hence they should be considered as contextualized AI systems too."}, {"title": "B. Paper Structure", "content": "Section II describes our method, including the use of LLM tools, Section III discusses the findings from exploration using GPT-4, Section IV and V discusses the findings from literature screening using Gemma 2:9b and full-text analysis using Claude 3.5 Sonnet, and Section VI summarizes all the findings, including an analysis to the research methodology we use, and recommends for the future research directions.\nThis paper presents two distinct methodologies for LLM-assisted literature surveys: Method A using ChatGPT 4 for initial exploration and thematic analysis, and Method B combining Gemma 2:9b for literature screening with Claude 3.5 Sonnet for full-text analysis. We compare these approaches to demonstrate their effectiveness in processing large volumes of academic literature efficiently."}, {"title": "II. METHODOLOGIES", "content": "We employ two distinct LLM-assisted approaches: 1) Method A: GPT-4 for initial exploration and thematic analysis. 2) Method B: Gemma 2:9b for literature screening and Claude 3.5 Sonnet for full-text analysis. See Fig. 1 for the overview."}, {"title": "A. Method A: Exploration with GPT", "content": "Method A uses GPT-4 via ChatGPT to rapidly generate a broad overview and identify key themes using the following steps:\n1) Input research questions and definitions into GPT-4.\n2) Instructed GPT-4 to search for relevant literature.\n3) Used consistent prompt structure for each of RQ:\n{{Research Question}}\n{{Definitions}}\nSearch online for relevant conference papers and journal articles.\n4) Prompted twice more with Find more for each query.\n5) Collected and categorized provided sources.\nOur exploratory review with GPT-4 returned 34 unique sources without dead links, including 18 academic publications (52.9%), 12 industry reports (35.3%), 2 professional organization resources (5.9%), and 2 non-profit think tank publications (5.9%). All the returned sources were publicly accessible."}, {"title": "B. Method B: Systematic Review with Gemma and Claude", "content": "Method B employs a more systematic approach Gemma 2:9b and Claude 3.5 Sonnet for in-depth analysis [16], [21], [22]. We chose Gemma 2:9b for literature screening due to its efficiency in processing large volumes of text. Claude 3.5 Sonnet was selected for its ability to do full-text analysis of academic papers using prompt engineering."}, {"title": "Literature Screening with Gemma 2:9b", "content": "We used LLAssist, an LLM-based simplified screening tool with Gemma 2:9b backend (commit version 3bf51a6) [23]. LLAssist streamlines literature reviews through the following process:\n1) Data Input: Processes CSV files with article metadata and abstracts, along with research questions.\n2) Key Semantics Extraction: Extracts topics, entities, and keywords from titles and abstracts using Natural Language Processing (NLP).\n3) Relevance Estimation: Assesses each article's relevance to research questions, providing scores (0-1) for relevance and contribution, with 0.7 as the threshold between false (below 0.7) and true (0.7 and above).\n4) Must-Read Determination: Identifies \"must-read\" articles based on relevance and contribution scores.\n5) Output Generation: Produces JSON and CSV files with detailed information for each article.\nThe process involved:\n1) Querying the Scopus database with search string as \"artificial AND intelligence AND cyber AND security\" for 2015-2024. We use Scopus as its result already includes IEEE and ACM databases.\n2) To check if the abstract addresses one or more research question we developed screening questions (SQ) for the LLM prompt as below, followed by the definitions:\n\u2022 SQ1: Does it discuss strategic factors for implementing LLM-based or contextualized AI in cyber security defense? [Definitions]\n\u2022 SQ2: Does it mention methods for integrating such AI into cyber security defense systems? [Definitions]\n\u2022 SQ3: Does it address techniques for ensuring robustness and reliability of these AI systems? [Definitions]\n\u2022 SQ4: Does it discuss organizational measures or governance frameworks for building trust in these solutions? [Definitions]\n3) Analyze relevance and contribution of papers based on Gemma 2:9b's scores, using 0.7 as the threshold."}, {"title": "In-depth Analysis with Claude 3.5 Sonnet", "content": "We conducted a full-text review using Claude 3.5 Sonnet [22] with prompting techniques [24]. The following prompt engineering techniques are used: \"Prompt generator for the initial draft\", \"Be clear and direct\", \"Give Claude a role\", \"Prefill Claude's response\", and \"Long context prompting\" [25]. We use the following steps:\n1) Filtering contributing papers from 2020-2024 with DOIs, excluding non-Q1 journal articles.\n2) Analyzing full-text PDFs using Claude 3.5 Sonnet.\n3) Manual review for divergences between AI and human interpretations. We read the paper title, abstract, introduction, and conclusion then compare with the LLM output to check whether it is reasonably correct.\nWe used the following instruction prompt to guide Claude:\nYou are the research assistant. Given the research article, explain concisely how the paper addresses the following research questions:\n{{Research Questions}}\n{{Definition of Contextualized AI}}\nIn your explanation, first read the title and abstract, determine the type of the paper, e.g. survey paper, and then read the introduction and conclusion sections. Indicate if you need also to read the entire content of the paper. For each point you make, give the exact reference on where the original statement can be found, i.e. page/section number and paragraph. Strictly limit it to the actual content of the paper itself. Put a note in your explanation if the paper does not address one or more RQ.\nYour output will be:\n{{Output Format}}\nThis prompt engineering approach is effective in extracting relevant information and insights from full-text articles."}, {"title": "III. EXPLORATION WITH GPT-4", "content": "Our exploration with GPT-4 yielded valuable insights for each research question, drawing from both academic and non-academic sources:"}, {"title": "A. Key Findings", "content": "1) RQ1: Strategic Leverage of Contextualized AI: Academic research highlights enhanced threat detection and adaptive defense [26], [27], automation of routine tasks [26], and proactive threat prediction [27]. Industry perspectives emphasize domain-specific models for improved threat recognition [28], human-AI teaming for optimal decision-making [29], and the importance of ethical considerations [26], [27], [55].\n2) RQ2: Comprehensive Protection Strategies: Academic sources advocate for deep learning in behavioral analysis [33], [34] and integration of generative AI technologies [35]. Industry reports recommend persistent monitoring and real-time analysis [30], [57], contextualized security measures [31], AI-driven anomaly detection [30], and automation of security processes [31], [58].\n3) RQ3: Ensuring AI System Reliability: Academic research focuses on robust system structures and reliability assessment [36], recurrent events analysis for prediction [40], and Scientific Machine Learning (SciML) for safeguarding [40]. Industry and government initiatives emphasize enhanced protection strategies like GREP [37], AI Systems Engineering and Reliability Technologies (ASERT) [41], risk management [38], and human-in-the-loop approaches with continuous monitoring [39].\n4) RQ4: Fostering Organizational Trust: Academic sources stress transparency and explainability of AI systems [46], [50], ethical considerations in AI development [53], [54], and dynamic trust calibration mechanisms [44]. Industry perspectives highlight robust compliance and security implementation [42], cultivating a culture of ethical AI use [43], effective communication strategies [45], talent development [47], [51], and stakeholder engagement with policy advocacy [49], [55]."}, {"title": "B. Common Themes", "content": "While academic and non-academic sources address similar themes, the angles are different. Academic sources tend to focus on theoretical frameworks, in-depth technical aspects, and long-term implications while non-academic sources emphasize practical applications with market-orientation. Across both academic and industry sources, common themes emerged:\n\u2022 Importance of human-AI collaboration [29], [48], [52]\n\u2022 Continuous learning and adaptation [27], [39], [56]\n\u2022 Ethical considerations and transparency [26], [55], [46]\n\u2022 Balancing automation and oversight [31], [48] [59]\n\u2022 Significance of contextual understanding in AI [28], [33]"}, {"title": "IV. ANALYSIS OF GEMMA2:9B FILTERING RESULT", "content": "Our analysis, based on LLAssist's output applied to Scopus database results, uses a scoring system (0-1) for relevance and contribution, with 0.7 as the threshold for classification. Tables I and II summarize relevant and contributing papers from 2015-2024, respectively. Figure 2 visualizes the distribution of both categories. In the tables, we define: 1) SQ: Screening Question 2) R: Relevant papers, i.e. papers discussing topics related to the screening questions 3) C: Contributing papers, i.e. papers directly researching topics in the screening questions 4) Any SQ: Papers relevant to or contributing to at least one screening question 5) All SQs: Papers relevant to or contributing to all screening questions\nThe relevance criterion assesses whether a paper discusses topics related to our research questions, while the contribution criterion evaluates whether a paper directly researches these topics. We use a score threshold of 0.7 for both criteria to determine if a paper is considered relevant or contributing. The analysis reveals significant growth in research attention, with relevant papers increasing from 5 (2015) to 150 (2024), and contributing papers from 0 to 25 over the same period."}, {"title": "A. Focus of Research", "content": "Papers on robustness and reliability received the most attention (376 relevant, 48 contributing), followed by integration methods and strategic implementation factors. Organizational measures and governance frameworks for trust-building received the least attention (131 relevant, 4 contributing)."}, {"title": "B. Recent Developments", "content": "2023-2024 saw accelerated research activity across all screening questions. 2023 produced 193 relevant and 32 contributing papers, while 2024 already shows 150 relevant and 25 contributing papers, indicating rapidly growing interest."}, {"title": "C. Research Gaps", "content": "SQ4 in Tables I and II reveals a significant gap in research on organizational measures and governance frameworks, suggesting opportunities for future research on trust-building aspects of AI adoption in cyber security."}, {"title": "D. Field Maturity", "content": "The ratio of contributing papers to relevant papers (14.9%) gives insight into the field's maturity. While there is growing interest, as evidenced by the increase in relevant papers, the slower emergence of contributing papers suggests that it is still developing with considerable potential for in-depth studies."}, {"title": "E. Evolution of Research Focus", "content": "2015-2017 saw minimal relevant or contributing papers. 2018-2021 showed gradual increase, especially in strategic factors, integration methods, and robustness techniques. 2022-2024 demonstrated significant attention growth across all questions, particularly in robustness and reliability techniques."}, {"title": "F. Summary of the Analysis", "content": "This analysis highlights rapid growth and evolution in the research. While attention increases across all aspects, more focused research on organizational measures and governance frameworks for trust-building is needed. Recent surges suggest accelerated development with the potential for significant future advancements. For deeper insights into recent impactful research, we conducted a full-text review of selected papers, presented in the following chapter."}, {"title": "V. FULL-TEXT ANALYSIS USING CLAUDE 3.5 SONNET", "content": "Based on the selection criteria, we have short-listed and obtained the full text of 58 research papers between 2020 and 2024. From processing each of the research papers using Claude 3.5 Sonnet, we extracted their type, key themes, author stances, and concise summary of their research results to the RQs and definitions provided as part of the prompt. The key insights are summarized in table III and future research direction is outlined in table IV.\nNote that during our manual review of the 58 research papers, we encountered several things where our judgment was misaligned with AI, notably [60], [95], [96], [77], [86]:\n\u2022 There is one occurrence where we deemed the paper is insightful and can contribute towards the robustness [60] yet LLM determined the paper as not sufficiently contributing. After careful inspection, we noted that the paper was from 2020, before the advent of LLM-style deep learning. Hence, LLM's determination is correct.\n\u2022 There are two occasions where we failed to identify future research directions [95], [96]. LLM was correct to determine that fake cyber threat intelligence needs deeper research.\n\u2022 There is one occurrence where we misidentified the necessity of privacy-preserving methods in an explainable AI system [77], dismissing its importance while LLM was correctly identified it as important for future research.\n\u2022 There is one occurrence where we did not fully understand the key insight of using deep ensembles and temperature scaling [86]. Upon investigation, the team did not understand those specific terminologies and LLM was correctly identifying them."}, {"title": "VI. DISCUSSIONS AND RECOMMENDATIONS", "content": "Our review reveals a rapidly evolving landscape, with research attention significantly increasing from 2015 to 2024. Key areas requiring further attention:\n1) Research Focus Imbalance: Substantial research exists on technical aspects (robustness, integration), but a gap persists in studies on organizational measures and governance frameworks for building trust in AI-enhanced cyber security solutions."}, {"title": "A. Synthesis of Findings", "content": "Both methodologies complement traditional reviews. Future work should refine these techniques while maintaining rigor, potentially:\n\u2022 Developing sophisticated AI prompting strategies\n\u2022 Using multiple AI models for cross-validation\n\u2022 Establishing AI-human analysis integration protocols\n\u2022 Combining strengths of both methodologies"}, {"title": "C. Implications and Future Directions", "content": "Table IV outlines specific research gaps and future directions. Our analysis reveals rapid field evolution (2022-2024), the need for interdisciplinary approaches, and opportunities for meta-research on AI-assisted systematic reviews in cyber-security. Future work should prioritize addressing these gaps while balancing innovation and practical implementation."}, {"title": "VII. CONCLUSION AND FUTURE WORKS", "content": "This survey examined contextualized AI's potential in reshaping cyber defense strategies using a novel AI-assisted methodology. Key findings include significant research attention growth (2015-2024), focus on robustness, reliability, and integration methods, with gaps in organizational trust and governance studies. Our AI-assisted approach demonstrated efficiency in processing diverse sources, highlighting the potential of such methods in comprehensive literature reviews. Future research should prioritize empirical studies comparing traditional and AI-enhanced systems, exploring adaptive AI for evolving threats, and developing governance frameworks. While contextualized AI promises enhanced cyber defense capabilities, effective implementation requires balancing AI strengths with human oversight and risk mitigation. As this field rapidly evolves, interdisciplinary collaboration among cyber security experts, AI researchers, and policymakers will be crucial in addressing the multifaceted challenges of AI contextualization in cyber defense."}]}