{"title": "TIBYAN CORPUS: BALANCED AND COMPREHENSIVE ERROR COVERAGE CORPUS USING CHATGPT FOR ARABIC GRAMMATICAL ERROR CORRECTION", "authors": ["Ahlam Alrehili", "Areej Alhothali"], "abstract": "Natural language processing (NLP) utilizes text data augmentation to overcome sample size constraints. Scarce and low-quality data present particular challenges when learning from these domains. Increasing the sample size is a natural and widely used strategy for alleviating these challenges. Moreover, data-augmentation techniques are commonly used in languages with rich data resources to address problems such as exposure bias. In this study, we chose Arabic to increase the sample size and correct grammatical errors. Arabic is considered one of the languages with limited resources for grammatical error correction (GEC) despite being one of the most popular among Arabs and non-Arabs because of its close connection to Islam. Furthermore, QALB-14 and QALB-15 are the only datasets used in most Arabic grammatical error correction research, with approximately 20,500 parallel examples, which is considered low compared with other languages. In addition, most Arabic data augmentation techniques have not been adequately addressed. Therefore, this study aims to develop an Arabic corpus called \"Tibyan\" for grammatical error correction using ChatGPT. ChatGPT is used as a data augmenter tool based on a pair of Arabic sentences containing grammatical errors matched with a sentence free of errors extracted from Arabic books, called guide sentences. Multiple steps were involved in establishing our corpus, including the collection and pre-processing of a pair of Arabic texts from various sources, such as books and open-access corpora. We then used ChatGPT to generate a parallel corpus based on the text collected previously, as a guide for generating sentences with multiple types of errors. By engaging linguistic experts to review and validate the automatically generated sentences, we ensured that they were correct and error-free. The corpus was validated and refined iteratively based on feedback provided by linguistic experts to improve its accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to analyze the types of errors in the Tibyan corpus. Our corpus contained 49% of errors, including seven types: orthography, morphology, syntax, semantics, punctuation, merge, and split. The Tibyan corpus contains approximately 600 K tokens.", "sections": [{"title": "Introduction", "content": "The Arabic language has a great deal of influence worldwide. It is an ancient language with deep roots in the human history. The Holy Qur'an's language is Arabic, which has a special religious status among Muslims worldwide. Many of the most significant literary and philosophical works in human history have been written in Arabic, making it a sophisticated literary and poetic language [1]. In addition to being an important scientific and intellectual language,\nArabic has contributed greatly to the transfer of knowledge and culture to Europe and other countries as it was the language of scholars and philosophers during the Middle Ages [2].\nOne of the most important and famous features of Arabic is that it consists of three main versions: classical Arabic, modern standard Arabic (MSA), and regional dialects [3]. Classical Arabic was used in the Holy Quran and ancient literary texts between the 7th and 9th centuries [4]. Non-native Arabic speakers may find it difficult to learn classical Arabic or Quranic Arabic because of the special symbols (Tanween) that indicate proper pronunciation. Modern Standard Arabic (MSA) is the official language used primarily in newspapers, television broadcasts, and films. As it is not commonly spoken as a first language, it is a language without native speakers. There are currently 274 million speakers worldwide\u00b9. MSA is a formal language that is not used in daily life. Arabic is a vast language with a variety of dialects, and all Arabic speakers learn a local dialect, such as Mesopotamian Arabic and Egyptian Arabic. Meanwhile, dialectal Arabic is used by Arabs as a daily language of conversation. Although Arabic dialects are fundamentally related, they cannot be understood by one another because Arab countries speak different dialects [4].\nBecause MSA is rarely used in daily life, it is sometimes mixed with local dialects. Moreover, because of the rich and intricate nature of Arabic, ambiguity can lead to incomprehensible and inaccurate text. In addition, Arabic grammar presents several semantic, syntactic, and morphological challenges owing to its flexible word order, diacritic, and agglutination properties. Furthermore, considerable deficiencies at the Arabic morphological level have hampered extensive research in this area. At higher research levels, semantics and syntax did not significantly advance. Therefore, grammatical error correction (GEC) is becoming increasingly important for native and non-native speakers.\nGrammatical Error Correction (GEC) automatically detects and corrects grammatical errors in a text [5]. Recent approaches to grammatical error correction, such as the seq2seq model, require large, high-quality parallel datasets. However, many languages do not contain such data, making it difficult to train these models. Other languages contain only a limited number of examples, making it difficult to build models that can correct all types of linguistic errors. Moreover, the creation of such datasets can be time-consuming and expensive. Therefore, most researchers use data augmentation techniques to increase the size of Grammatical Error Correction (GEC) parallel data. Data augmentation techniques generate more diverse training examples, which enhances the model's ability to generalize to unknown errors. Various error types and contexts can be introduced using data augmentation to balance the dataset. Consequently, grammatical error correction systems have become more robust and accurate.\nThe Arabic language has limited resources. Only two parallel corpora are available for GEC research:QALB-14 [6] and QALB-15 [7]. The QALB-14 and QALB-15 are part of the Qatar Arabic Language Bank (QALB) project. QALB aims to create a large corpus of Arabic texts that have been manually corrected, such as user comments on news sites, essays written by native and non-native speakers, and machine translation text. A specialized annotation interface was developed for this project, along with comprehensive annotation guidelines [8] [9]. A total of 20,430 and 1,542 samples were available from the two training corpora, (QALB-14) and (QALB-15). Despite the researchers' complete reliance on these data, they have some shortcomings, including inadequate coverage of Arabic language defects, inconsistent punctuation correction, and small size compared with o datasets in other languages.\nThis study aims to contribute to the development of an Arabic corpus for Grammatical Error Correction by employing ChatGPT to generate paired sentences based on common errors found in Arabic books. First, we collected a diverse range of pair Arabic sentences; one containing common grammatical errors made by native speakers and other corrected versions of the sentence. The sentences collected from the three Arabic books were short, ranging from one to seven words. These sentences were extracted from three Arabic books namely \"A Dictionary of Common Grammatical, morphological, and Linguistic Errors\"2, \"Common linguistic errors in cultural circles\"\u00b3, \"Common linguistic errors\"4. Moreover, we used the A7'ta corpus [10] which is composed of 466 short sentence pairs taken from a book called Linguistic Error Detector (Saudi Press). Second, we instructed the ChatGPT model to generate full sentence pairs using our collected short sentence pairs, one containing the error and the other free from errors. Additionally, the corrected versions of the corpus were annotated and all grammatical errors were corrected by experts, creating a valuable resource for training and evaluating the performance of the Arabic GEC. Finally, we analyzed the types of errors generated in our corpus using the Arabic Error Type Annotation tool (ARETA) [11]. We make our corpus publicly available. The contributions of this study are as follows.\n\u2022 Collect and organize short Arabic sentences, including common grammatical errors, from various Arabic books as a guide."}, {"title": "Related work", "content": "This section discusses the Arabic corpus available for grammatical error correction (GEC) and recent research using ChatGPT as a data augmentation for GEC.\nArabic Corpus\nFive Arabic GEC datasets are publicly available for grammatical error correction. The first two are derived from the shared QALB-14 [6] and QALB-15 [7] tasks.In addition to these, there are the A7'ta corpus [10], the ZAEBUC dataset [12]) and Lang-8 corpus [13]. None of them were manually annotated for a specific type of error. An overview of the dataset statistics is presented in Table 1.\nThe QALB corpus is one of the components of the Qatar Arabic Language Bank (QALB) project and was created as part of it. In the QALB project, large manual correction corpora for a variety of Arabic texts were developed, including texts written by native and non-native authors and machine translation outputs.\nThe QALB-14 [6]is a compilation of Modern Standard Arabic comments written by native speakers on the Al Jazeera News website. Both native and non- native Arabic speakers were addressed in QALB-15. Learners of Arabic as a second language (L2) contributed texts to the QALB-15 [7], extracted from two learner corpora: the Arabic Learner Corpus (ALC) [14] and the Arabic Learners Written Corpus (ALWC) [15]. The annotation process was divided into three phases: automatic preprocessing, automatic spelling corrections, and manual annotation by humans (annotators). They used morphological analysis [16] and the disambiguation system MADA (version 3.2) [17] to automate spelling corrections. Annotators were required to correct spelling, punctuation, word choice, morphology, syntax, and dialect errors. There were 21,396 sentences in the QALB-14 Corpus and 1,533 sentences in the QALB-15 corpus, divided into training, development, and test sentences.\nThe QALB corpus contains valuable Arabic data but not all types of errors, such as lengthening short vowels, Nun dan Tanwin confusion, and shortening long vowels [11]. The datasets contained inconsistent manual annotations of punctuation corrections; for example, there was a space between the full stop and the word.\nA7'ta [10] is a parallel monolingual corpus that presents Arabic texts in parallel. A total of 470 erroneous sentences and 470 correct sentences were found. Sentences were collected manually from a book called the Linguistic Error Detector (Saudi Press), which was designed to guide writers and readers in correct Arabic grammar usage. In this corpus, there are only 3,532 tokens, the majority of which are incomplete sentences, which cannot be used alone for deep learning.\nZAEBUC [12]) is a bilingual corpus annotated in Arabic and English by first-year university students at Zayed University. Designed to represent bilingual writers, one writing in their native language and one writing in their second language, the corpus contained short essay bilingual corpora matched to writers. The corpus creation process involved four steps. The first step was to obtain approval from ZU's IRB board and then contact the faculty teaching the targeted courses. Written consent was obtained from all participating students. In parallel to the second step, manual text correction and CEFR annotation were performed independently. Morphological annotation followed text correction depending on the results. Finally, the semi-automatic annotations were manually corrected. There were 214 sentences in total, which was a relatively small corpus.\nThe Lang-8 corpus [13]) ranks as one of the largest corpora for training grammatical error correction systems based on machine translation. Furthermore, it contains nearly 80 languages of learner and corrected sentences based on Lang-8's revision logs. There are approximately 737 sentence pairs in Arabic, which is one of the top 20 languages."}, {"title": "ChatGPT for Data Augmentation", "content": "ChatGPT has recently demonstrated effective GEC performance using zero-shot and few-shot prompts [18] [19] [20]. ChatGPT is used in GEC in various ways. For Example, [21] evaluated the effectiveness of ChatGPT as a corrector for grammatical error correction (GEC) by using a prompt-based approach. In- structed ChatGPT to correct sentences for grammatical errors. In this study, perturbations unrelated to errors were introduced into ChatGPT to evaluate the context robustness.\nMoreover, ChatGPT used as a data augmenter, such as in fan et al. [22]), introduced GrammarGPT, an open-source Large Language Model (LLM) that is designed to correct native Chinese grammar errors. Fan et al. [22] studied ChatGPT-generated and human-annotated datasets in conjunction with an error-invariant augmentation method to achieve better accuracy when correcting native Chinese grammatical errors. They guided ChatGPT in generating ungrammatical sentences by providing clues and manually correcting sentences collected from websites without clues. The model was enhanced to correct native Chinese grammatical errors using an error-invariant augmentation method. A hybrid dataset of ChatGPT-generated and human-annotated data was used to fine-tune open-source LLMs with instruction tuning. Native Chinese grammatical error correction using open-source LLMs was demonstrated using this approach. In addition, it can be used to introduce natural language explanations for correction reasons. kaneko et al. [23]introduced a method called Controlled Generation with Prompt Insertion (PI) that allows Large Language Models (LLMs) to explain the reasons for corrections in natural language in the context of Grammatical Error Correction (GEC). The Grammatical Error Correction (GEC) explanations were improved using Chat-GPT. Large Language Models (LLMs) are used to explain the correction reasons in natural language using ChatGPT in a technique called controlled generation with prompt Insertion (PI). The LLMs produced better correction reasons by inserting edit prompts during generation and explicitly engaging them in providing explanations for all edits. According to the study, PI led to enhanced performance when describing the correction reasons for all correction points compared to using the original prompts for generation.\nThe only Arabic study that has used ChatGPT to augment data is that of Kwon et al. [24], who used ChatGPT to inject grammatical errors into Arabic text. They created a parallel dataset using ChatGPT by selecting and corrupting 10,000 correct sentences from an original training set. Therefore, note that our approach for increasing the amount of data using ChatGPT is unique.\nTo the best of our knowledge, this is the first study to augment data by extracting sentence fragments from books (guide sentences) and instructing ChatGPT to generate two sentences using guide sentences, one correct and one with errors. According to an extensive review, there is a lack of research utilizing similar techniques for data augmentation. A novel avenue for expanding datasets was created by leveraging ChatGPT, which holds considerable promise across several fields. In addition to enriching the available data, this innovative method illustrates the versatility and adaptability of ChatGPT. Exploring and validating this approach can significantly advance this field and open doors for new possibilities and insights."}, {"title": "Approach", "content": "Figure 1 shows the proposed approach. We began by collecting pairs of sentences from Arabic books, one of which was correct and the other contained grammatical errors. This is called a guide sentence. There is also an Arabic corpus called A7'ta that contains sentences extracted from Arabic books. Guide sentences are usually short with limited tokens and incomplete sentences. ChatGPT was then instructed to construct two useful sentences based on the guide sentences: one with correct guide sentences and the other with grammatical errors based on incorrect guide sentences. In addition, the data were reviewed by a human annotator to ensure that they were accurate and did not contain grammatical errors."}, {"title": "Data Collection", "content": "Owing to the lack of parallel Arabic corpora, we initially collected pairs of correct and incorrect sentences. Various sources including books and available corpus were used during this phase. The following are the descriptions of the three Arabic books used:\n\u2022 A Dictionary of Common Grammatical, morphological, and Linguistic Errors: Several common linguistic errors are highlighted in this dictionary book to alert Arabic language students. Four main types of errors are discussed in \"A Dictionary of Common Grammatical, morphological, and Linguistic Errors\": Syntactic errors, errors in transitive verbs with prepositions, errors in grammar, morphology, and sentence structure, and errors in correctness and semantics.\n\u2022 Common linguistic errors in cultural circles: It contains six types of errors, which include errors in syntax, nouns, verbs, linguistic structures, masculine and feminine, and phonetics.\n\u2022 Common linguistic errors: This dataset contains approximately 83 sentence pairs with the most common linguistic errors in Arabic."}, {"title": "Data Pre-processing", "content": "Preprocessing was performed once valuable linguistic sources were gathered. We manually extracted sentences from these sources from the hand sides of the books. As shown in Figure 2, the books contained correct and incorrect sentences along with explanations and clarifications. A separate file was created for each correct and incorrect sentence pair. One file contained the correct sentences, and the other contained incorrect sentences. Several obstacles were encountered, including the existence of correct sentences without incorrect sentences. In this case, we repeated the correct sentence in the files of correct sentences and incorrect sentences to increase the sample size and avoid ignoring any errors. In some cases, there was more than one correct sentence equivalent to one incorrect sentence; therefore, all correct sentences were placed in separate lines, and incorrect sentences were repeated for each correct sentence."}, {"title": "Data Augmentation", "content": "The data collected in the previous stage consisted of sentences of one to eighteen words, as shown in Figure 3. The average word length was four words. At least one word differed between the sentence pairs. Moreover, it can be expressed as part of a sentence or as an incomplete sentence. These data are not valuable for many modern approaches such as seq2seq [25]and seq2edit [26], which require large amounts of data. Therefore, we used ChatGPT to convert parts of the sentences into full sentences. ChatGPT is a machine-learning and artificial neural network-based artificial intelligence language model. ChatGPT supports advanced natural-language understanding and generation, making it useful for a wide range of applications. ChatGPT was used for creative text synthesis, writing assistance, content generation, translation, and natural interactions with users in chatbots. Several areas of artificial intelligence can benefit from the ChatGPT technology, which represents a qualitative leap in natural language understanding."}, {"title": "Human Annotation", "content": "We compared them with professional annotators to ensure that the sentences generated by ChatGPT were accurate and error-free. We only provide annotators with data generated by ChatGPT assumed to be correct and part of a corrected sentence (guide sentences) extracted from books, whereas incorrect data are obtained without an audit. To ensure the reliability of the human annotation, annotation was performed in two phases.\nIn the first phase, annotators were instructed to correct the morphology, punctuation, spelling, syntax, word choice, and dialectal usage within a given sentence without affecting the wording. Annotators are only required to specify the appropriate corrective action during annotation and not the type of error. Moreover, it instructs students to retain the correct parts of sentences extracted from books, without modifying their wording. We also instructed them to follow the same guidelines and rules developed by Zaghouani et al. (2014) [27] to ensure the uniformity of human annotation and compatibility with previous standards (QALB-14 and QALB-15). To ensure that all copies were corrected, we manually removed data from the annotator in both correct and incorrect parts to ensure compatibility between parallel data. After the first phase, the following comments were received:\n\u2022 Some words and phrases are repeated and they should be deleted from the sentences.\n\u2022 A few words were inserted into sentences that were irrelevant to the context. This should be replaced with a more appropriate word or deleted.\n\u2022 Some phrases contain religious transgressions or defects from legal, historical, or even realistic standpoints; therefore, they must be changed or deleted.\nWe then reviewed all the annotators' comments and made all necessary changes, including removing duplicate tokens and phrases containing religious transgressions. We then proceed to the second phase of annotation. We contract with the most qualified linguistic auditor to review the text to ensure the accuracy of sentences and freedom from errors. To ensure that a word fits the context, we instructed the annotator to delete or modify the word to fit the context without modifying sentence wording, remove duplicate words if separated by conjunctions, and remove repetitive phrases."}, {"title": "Experiment", "content": "Setting\nWe used gpt-3.5-turbo-instruct for the ChatGPT API. The maximum sequence length was 1400, the target length was 200, the temperature was 0.8, and the number of sentences generated was five. The prompt consisted of correctly guided sentences from books. The total number of guide sentences was 3627.\nImplementation Details\nImplementation was carried out in Python using the OpenAI library and langid for language identification. We first use the following promote \"Create a useful sentence consisting of target length words using the guide correct sentence without any changes in the letters or semantic of the phrase: correct_guide\" to generate full corrected sentence. The phrase in our previous promotion was a correct guide sentence, and we instructed the ChatGPT API not to change any letters or semantics so that the phrase's meaning would remain the same, because in Arabic, changing one letter could alter the meaning of the entire sentence. After executing the previous promote, we obtained five sentences that all included the correct guide sentence separated by a full stop in one line. The generated sentence may not be a complete and may end in an incomplete word. To ensure the generation of complete sentences, we identified the maximum sequence length as 1400; therefore, the generated sentences were not all of the same length but varied from 200 to 1400. We then applied post-processing to ensure proper formatting and punctuation of the resulting sentences. After that, To construct an incorrect sentence, we only search for correct guide in the correct sentence and replace it with the incorrect guide while maintaining the sentence's structure. Finally, we also promote ChatGPT to generate errors in an incorrect sentence pair only by using the following promote: \"In the following sentence, please add spelling, grammar, morphology, punctuation, semantic, and morphology errors, as well as merging and separating words\". We used the previous promotion to ensure that the erroneous sentences were diverse and contained a wide range of errors in addition to those derived from books.\nEvaluation Metric\nFor text generation models such as ChatGPT, BERTScore is used to calculate the precision, recall, and F1 scores by comparing the generated text to a target text. BERTScore [28] is a metric that measures the similarity between two pieces of text using contextual embeddings from BERT (Bidirectional Encoder Representations from Transformers). Precision measures the number of relevant (correct) words in the generated text. The recall value is the percentage of relevant words in the text generated by those in the reference text. In F1 Scoring, precision and recall were balanced, providing a balanced measure.\nResults\nThe corrected and uncorrected sentences generated by ChatGPT were compared with sentences corrected by a human after annotation. We demonstrated the effectiveness of ChatGPT in generating error-free human-like sentences. Compared to human-corrected sentences, ChatGPT-generated corrected sentences resembled those produced by humans after annotation, as listed in Table 3. The ChatGPT model constructs sentences that follow a natural flow and coherence, similar to human speech. By rigorously analyzing ChatGPT's output, we demonstrated its remarkable ability to produce sentences with accuracy and naturalness comparable to human corrections. A demonstration of ChatGPT's ability to seamlessly integrate linguistic nuances and grammatical rules, ultimately delivering outputs indistinguishable from those produced by humans, serves as an advancement in natural language processing."}, {"title": "Analysis", "content": "In this section, we highlight some of the statistics from our data. We then used the Arabic Error Type Annotation tool (ARETA) [11]to analyze the types of errors when receiving two data files, one with errors and the other without errors, and determine the type of error. The ARETA tool is based on Afifi's and Atwell [29] comprehensive error classification, which classified 29 Arabic language error tags. The ARETA tool includes two modifications to Afifi's comprehensive error classification system. First, merging (MG) and splitting (SP) errors were added to accommodate one-to-many corrections. Furthermore, they removed all other error tags such as OO, MO, XO, SO, and PO, representing orthographic, morphological, syntactic, semantic, and punctuation errors, respectively. Therefore, there were seven classes and 26 error tags in the ARETA taxonomy.\nGeneral Statistics and Observations\nTable 4 summarizes the general statistics of the Tibyan Corpus. The total number of words was 618598 for correct data and 604592 for incorrect data. The average sentence length indicated the number of words in each sentence. In the correct data, there are approximately 99.92 words, whereas in incorrect data, there are approximately 97.66 words. The \"Average Token Length\" shows the average number of characters in each token. In the correct data, there are approximately 4.85 characters per word, whereas in the incorrect data, there are approximately 4.88 characters per word. An \"unique token\" shows a number of unique token (or words). The error-free data contained 71,976 unique tokens, whereas the error-containing data contained 81,905 unique tokens.\nAnalysis of Error Type Before Data Augmentation\nIn this section, we analyze the existing error types before data augmentation for both the A7'ta corpus and our extracted data from the books described in Section 3.1, using the ARETA tool. The A7'ta corpus consists of 466 sentences and 2208 tokens. According to the ARETA tool, 22 error types exist in the a7'ta corpus, as listed in Table 5. The error rate is 33%. The corpus lacks four types of errors: lengthening short vowels (OG), shortening long vowels (OS), merged words (MG), and words that are split (SP). Owing to an insufficient number of words, a limited number of sentences, and the lack of focus on these types of errors in the a7'ta corpus. Moreover, we observed that lengthening short-vowels (OG) error types appeared in a combination with Additional Char (OD) error types. Despite its low frequency, it appears only three times. Figure 7 shows the types of combination errors and their frequencies.\nOur extracted data from the books described in Section 3.1 consists of 3166 sentences and 12407 tokens. According to the ARETA tool, 22 error types exist in our data, as listed in Table 5. The error rate is 31%. The corpus lacks four types of error: lengthening short vowels (OG), shortening long vowels (OS), confusion in Alif Fariqa (OW), and words that are split (SP). Moreover, a token may contain more than one type of error. Figure 8 shows the types of combination errors and their frequencies. We found that OD and OR error types usually existed together at 102 frequencies, followed by OH and OM at 65 frequencies. Another error combination exists at frequencies less than 20. Moreover, we observed that low-frequency error types appeared in combination with other types, such as OD and OG.\nWhen the data were combined, the total error rate was 32%. There were 23 types of errors and a lack of three types: lengthening short vowels (OG), shortening long vowels (OS), and words that are split (SP). This is due to the lack of a sufficient number of words and a limited number of sentences. As the tool did not accurately classify some semantic errors, 449 unknown errors were found, such as when we replaced a Modern Standard Arabic (MSA) token with a dialect or foreign word, using a word that differed from its meaning, or when more than one error was present in a phrase. Figure 9 shows the top ten types of combination errors and their frequencies. We observed that some error types usually exist together, such as OD with OR and OH and OM error types."}, {"title": "Analysis of Error Type After Data Augmentation", "content": "In this section, we analyze the error type after data augmentation, and before and after human annotation.\nAnalyze the Error Type Before Human annotation\nThe error rate increased by 7% for the a7'ta corpus (manual generation), 13% for our extracted data, and 11% for all the data, as listed in Table 6. Our corpus contained 23 types of errors. Three types of errors do not exist in the Tibyan corpus: OG, OS, and SP. There were only four instances of the ON error type in the Tibyan corpus. Although some errors exist at high frequencies such as OT, OH, PC, and OA, others exist at low frequencies such as ON, MT, and SF. Figure 10 shows the error combinations of the top five low-frequency classes. The types of errors that appear in small percentages appear in combination with other types in varying percentages, as shown in Figure 9. In conclusion, all types of errors appeared in varying proportions, either alone or in combination."}, {"title": "Analyze the Error Type After Human annotation", "content": "In comparison with analyzing the error type following data augmentation before human annotation, we notice that a7'ta corpus (manual generation) has an error rate of 8%, our extracted data has an error rate of 5%, and all our data has an error rate of 6%, as listed in Table 7. Our corpus contained 26 types of errors. Furthermore, it contains two types of errors: OG and OS. The ON error types in the corpus increased to 527 instances. Although some errors exist at high frequencies such as OT, OH, PC, and OA, others exist at low frequencies such as ON, MT, and SF. Figure 11 shows the error combinations of the top five low-frequency classes. The types of errors that appeared in small percentages were combined with other types of errors in varying percentages. In conclusion, all error types appeared in varying proportions, either alone or in combination.\nA strength of the Tibyan Corpus is that it includes common errors by native Arabic speakers. There are several types of errors, including Alif, Ya, and Alif-Maqsura (OA), Hamza errors (OH), Ha/Ta/Ta-Marbuta confusion (OT), and punctuation confusion (PC). Despite the complexities of the Arabic orthography and grammar, these errors are challenging for native speakers.\nNative speakers, however, are more likely to make errors, such as char order (OC), additional char (OD), missing char (OM), char replacement (OR), nun and tanwin confusion (ON), confusion in Alif Fariqa (OW), merge (MG), and split (PS). It is more common for these errors to arise from typing than from a lack of language understanding. Because these errors are usually straightforward and follow predictable patterns, modern applications and spell checkers are generally"}, {"title": "Limitation", "content": "Although the ARETA tool is effective for determining Arabic errors, its classification is not always accurate. These tools sometimes fail to classify words with more than two errors and mark them with X or UNKs, even though the tool"}, {"title": "Conclusion", "content": "In conclusion, this study aimed to create an Arabic corpus called Tibyan for Grammatical Error Correction. We use a diverse range of Arabic text extracted from books and the a7'ta corpus containing common grammatical errors. The ChatGPT model is then used to generate parallel sentences containing quoted sentences extracted from Arabic books, one with grammatical errors and the other with correct sentences. By engaging linguistic experts and iteratively refining the corpus based on their feedback, we ensured that it represented the real world and was reliable. Ultimately, the Tibyan corpus will enable the development of an accurate and powerful Grammatical Error Correction tool tailored specifically for the Arabic language. Two key aims are addressed by the corpus: error-type coverage and unbalanced error-type classification. The Tibyan corpus contains all types of errors in Arabic, as the sentences were extracted from books, representing a diverse and rich source of errors. Moreover, it achieves a balance between types of errors. All the types of errors appeared in proportion to each other. In the future, we will use our corpus to construct a robust Arabic\ngrammatical error correction model. In addition, the number of sentences and tokens can be increased using modern techniques."}]}