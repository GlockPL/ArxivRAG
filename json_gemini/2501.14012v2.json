{"title": "Transfer Learning of Surrogate Models via Domain Affine Transformation Across Synthetic and Real-World Benchmarks", "authors": ["Shuaiqun Pan", "Diederick Vermetten", "Manuel L\u00f3pez-Ib\u00e1\u00f1ez", "Thomas B\u00e4ck", "Hao Wang"], "abstract": "Surrogate models are frequently employed as efficient substitutes for the costly execution of real-world processes. However, constructing a high-quality surrogate model often demands extensive data acquisition. A solution to this issue is to transfer pre-trained surrogate models for new tasks, provided that certain invariances exist between tasks. This study focuses on transferring non-differentiable surrogate models (e.g., random forest) from a source function to a target function, where we assume their domains are related by an unknown affine transformation, using only a limited amount of transfer data points evaluated on the target. Previous research attempts to tackle this challenge for differentiable models, e.g., Gaussian process regression, which minimizes the empirical loss on the transfer data by tuning the affine transformations. In this paper, we extend the previous work to the random forest model and assess its effectiveness on a widely-used artificial problem set - Black-Box Optimization Benchmark (BBOB) testbed, and on four real-world transfer learning problems. The results highlight the significant practical advantages of the proposed method, particularly in reducing both the data requirements and computational costs of training surrogate models for complex real-world scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Surrogate modelling [1]\u2013[4] is commonly utilized across various fields of computer science and engineering, particularly for complex simulations or physical experiments where data acquisition is expensive. Common learning algorithms for building surrogate models include artificial neural networks [5], support vector machine [6], [7], random forest regression [8], [9] and Gaussian process regression [10]\u2013[12]. These learning algorithms often have a high sample complexity, especially when the dimension of the independent variable becomes large. As such, when surrogate-modeling a new regression task, one might wish to exploit surrogate models trained on previous tasks, given similarities and symmetries between tasks.\nDomain shift is a prominent type of task similarity, where the probability distribution of the input variable shifts from one task to the other while the predictive distribution remains the same. Under this assumption, one can transfer a model from the source task to the target task by learning the domain shift. In this work, we focus on a specific type of domain shift affine shift - the input distributions between tasks are related by an unknown affine transformation (rotation and translation). A prior study [13] proposed a transfer learning method for differential models, e.g., Gaussian process regression. In this work, we propose to extend this transfer learning method to non-differentiable models, for instance, random forests.\nOur contributions are:\n\u2022 We extend the transfer learning method in [13] to handle non-differentiable surrogates, e.g., random forest regression.\n\u2022 We verify the effectiveness of our extension on the Black-Box Optimization Benchmark suite and four real-world transfer learning problems.\n\u2022 We conduct an empirical analysis to investigate when the transferred model outperforms the model trained from scratch on the transfer dataset.\nThis paper is organized as follows. In Sec. II, we summarize some key related works. In Sec. III, we delineate our extension of the affine transformation method to non-differentiable functions. Experimental setup and both synthetic and real-world transfer learning tasks are explained in Sec. IV, followed by a detailed discussion of the results in Sec. V. Finally, we conclude the empirical findings and point out the future direction in Sec. VI."}, {"title": "II. RELATED WORKS", "content": "A. Transfer learning in RFR surrogate modeling\nSegev et al. [14] introduced two distinct algorithms for transferring RFR. The first method employs a greedy search strategy to iteratively refine the structure of each decision tree. This approach enables localized modifications, such as expanding or pruning individual nodes, to improve the model's adaptability. The second method, in contrast, preserves the original tree structure but focuses on recalibrating the parameters, specifically by adjusting the decision thresholds at the internal nodes.\nB. Transfer learning with affine model\nSaralajew et al. [15] proposed a manifold-based adaptation technique for classification models, such as generalized learning vector quantization classifiers (GLVQ) [16], [17], to address distribution shifts between datasets. The affine transformation was also considered to minimize discrepancies between source and target domains [18]. Mandl et al. [19] applied affine transformations within the framework of Physics-Informed Neural Networks (PINNs)."}, {"title": "III. AFFINE TRANSFER LEARNING FOR NON-DIFFERENTIABLE MODELS", "content": "Consider a source regression task to approximate function $f_S: \\mathbb{R}^d \\rightarrow \\mathbb{R}$ and a target task $f_T: \\mathbb{R}^d \\rightarrow \\mathbb{R}$. We assume an affine symmetry between them: there exist $W \\in SO (d)$ and $v \\in \\mathbb{R}^d$ such that $f_T(x) = f_S(Wx + v)$, where $SO (d)$ denotes the $d$-dimensional rotation group. In practice, the affine parameters $W$ and $v$ are unknown. Given a high-quality model $f_S$ trained on $f_S$, we wish to transfer it to $f_T$ by affine reparameterization $f_T(x) := f_S(Wx + v)$, where the unknown parameters are determined by minimizing the empirical loss of $f_T$ on a small transfer data set $T$ evaluated on $f_T$, namely $L(v, W) = \\frac{1}{n} \\Sigma_{x\\in T}(f_S (Wx + v) - f_T(x))^2$. If the surrogate model $f_S$ is differentiable, e.g., GPR, we can employ the Riemannian gradient algorithm to minimize the loss [13]. For non-differential models, e.g., RFR, we propose the following optimization procedure.\nWe propose to use the Covariance matrix adaptation evolution strategy (CMA-ES) [20]\u2013[22] to tune the affine parameters."}, {"title": "IV. EXPERIMENTAL SETTINGS", "content": "A. Synthetic tasks based on BBOB\nWe evaluate our transfer learning approach with RFR using the widely recognized BBOB problem set. While originally designed for benchmarking black-box optimization algorithms, BBOB is also widely utilized as a regression testbed [23]\u2013[26] due to its computational efficiency and the diverse properties of its functions. These include multi-modality, ill-conditioning, and irregularities that closely resemble the complexities of real-world regression tasks. Detailed information on BBOB is available in its documentation [27]. To construct target problems for each source problem in BBOB, we introduce diversity and complexity by randomly generating rotation matrices and translation vectors, creating a robust and challenging testbed for our method.\nWe train the original RFR model $f_S$ on a dataset generated by uniformly sampling $1000 \\times d$ points at random within the range [-5,5]$^d$ and evaluating them on $f_S$. To apply our proposed transfer learning approach, we generate a transfer dataset $T$ by uniformly sampling 50 \u00d7 d points within [-5, 5]$^d$ and evaluating them on the target function $f_T$. For comparison, we also train an RFR model from scratch on the same transfer dataset $T$ without leveraging any prior knowledge. Finally, to evaluate the accuracy of the various RFR models on $f_T$, we independently sample uniformly at random a test dataset of 1000 \u00d7 d points evaluated on $f_T$.\nB. Real-World benchmark\n1) Porkchop Plot Benchmarks in Interplanetary Trajectory Optimization: The energy required to travel between Earth and another planet in the solar system is a function of the relative positions and velocities of the planets, as well as the desired trip duration, i.e., of both the departure and arrival times. Calculating this energy for specific departure and arrival dates involves solving Lambert's problem, a differential equation that determines the orbital trajectory [28]. The periodic motion of planets generates recurring patterns in the contour lines of this function around local minima. These contours resemble the shape of a porkchop slice, inspiring the term \"porkchop plots\" [29], [30]. The analysis of porkchop plots is useful in the design of interplanetary trajectories. For benchmarking, we consider as the source function the energy required for an Earth-to-Mars mission within a specific launch window and within a maximum travel time of 14 years and the target function corresponds to a different launch window. In this way, we aim to transfer insights gained from the planning of an interplanetary mission during a specific launch window to plan similar missions for future windows. Besides the Earth-to-Mars mission, we also validate our transfer learning approach on Earth-to-Venus (a maximum travel time of 12 years) and Mercury-to-Earth (a maximum travel time of 6 years) missions. For validating our transfer learning method on this dataset, for example, the energy function of a specific Earth-to-Mars mission during a chosen launch window is treated as the source function $f_S$, while the corresponding energy functions for alternative launch windows serve as the target functions $f_T$. The surrogate model $f_S$ is trained using 40000 randomly selected points from $f_S$, while the full dataset is used as the test set for evaluating the SMAPE of the various RFR models on the target function. The transfer dataset $T$ is sampled uniformly at random from the full dataset of the target function. The same transfer dataset is used to train an RFR model from scratch without leveraging any prior knowledge. We study the effect of varying the size of the transfer dataset, ranging from 10 to 1000 points.\n2) Kinematics of a Robot Arm: This task involves predicting the feed-forward torques needed for the seven joints of the SARCOS robot arm [31] to execute a desired trajectory. The input data comprises 21 features, including joint positions, velocities, and accelerations. The target is to predict the torque value for a specific joint. 30000 randomly sampled points from the source function are used to train the surrogate model $f_S$. Similarly, up to 1000 points, also selected at random, are drawn from the target function $f_T$ to create the transfer dataset $T$.\n3) Real-World Optimization Benchmark in Vehicle Dynamics: This dataset benchmarks optimization algorithms in automotive applications, focusing on minimizing braking distance. It features five vehicle configurations, each defined by distinct tire performance and vehicle load combinations. The parameter space comprises two ABS control variables, $x_1$ and $x_2$, spanning 10101 discrete combinations [32]. The surrogate model $f_S$ for source functions is trained using the entire $f_S$ dataset, while up to 10101 points from target $f_T$ form the transfer dataset $T$.\n4) Single-Objective Game-Benchmark MarioGAN Suite: The RW-GAN-Mario suite [33] offers 28 single-objective fitness functions for evaluating and optimizing procedurally generated levels in the Mario AI environment. These functions cover various level types (e.g., underground) and ensure segment playability through concatenation mechanisms. Fitness metrics combine statistical properties (e.g., enemy distribution) with gameplay-based measures (e.g., air time) derived from simulations. In this work, we focus on three functions - F1, F5, and F6 - and apply transfer learning within instances of each function. For each source instance, the surrogate model $f_S$ is trained on 50000 randomly sampled points, while up to 1000 randomly selected points from the target instance $f_T$ form the transfer dataset $T$.\nC. Surrogate model\nIn our experiments, we evaluate the performance of RFR using the SMAPE [34], chosen for its scale-neutral properties that enable fair comparisons across datasets with different scales. Transfer learning experiments are repeated ten times, with randomly generated affine transformations applied to each BBOB function to validate our method. Similarly, real-world applications are also tested ten times to account for variability and ensure robust and consistent results."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "A. Transferring RFR on BBOB\nFig. 2 highlights the advantages of our approach by presenting the average SMAPE differences (percentage) between the RFR trained from scratch and the transferred RFR. For the majority of functions, the transferred model consistently provides a better fit, as indicated by positive differences. Notably, the performance gap narrows with increasing sample size, indicating that the benefits of transfer learning diminish as more data becomes available, allowing the model trained from scratch to catch up. Compared to the transferred GPR results reported in the prior study [13], the RFR exhibits more stable performance, with no extreme outliers observed in the 10-dimensional (10-D) case using 50 transfer samples. This demonstrates that the RFR can still deliver reasonable results even when data is sparse in high-dimensional scenarios. However, achieving effective transfer for certain functions remains challenging. For instance, across various dimensions and transfer data sizes, the transferred RFR consistently struggles within function F24, where the model trained from scratch consistently outperforms it. Similarly, functions F21-F23, especially in high-dimensional scenarios, present substantial challenges for the transferred model, limiting its ability to deliver optimal performance.\nFor a detailed analysis of the 5-D case, TABLE II (refer to the supplementary material [41]) reports the SMAPE values (mean and standard deviations across ten runs) for three models: the original RFR, the transferred model, and the one trained from scratch. Similar results for the 2-D and 10-D are included in the supplementary material [41]. The table reports outcomes for two different sizes of the transfer data: |T| \u2208 {50,50d}. Statistical comparisons between the models are conducted using the Kruskal-Wallis test, followed by Dunn's posthoc analysis, with a significance level of 5%. To indicate statistical significance, we highlight the following: if the transferred model demonstrates superior performance compared to the original model, it is underlined. Furthermore, when comparing the transferred model with the model trained from scratch, the better-performing model is highlighted in bold.\nIn 5-D functions, the transferred RFR generally outperforms the original model and the model trained from scratch at transfer data sizes of 50 and 250, with rare exceptions. An exception arises with F23, where the original model outperforms both the transferred models and the one trained from scratch. Specifically, when the transfer dataset is 50, the original RFR demonstrates significantly better performance than the transferred RFR. Further analysis reveals that the original RFR trained on the source function exhibits considerable underfitting a behavior also observed with the original GPR model [13]. In such cases, an affine transformation is unlikely to improve the model's performance on the target function effectively. These findings suggest that the proposed transfer learning approach is most effective when the original surrogate model already demonstrates a reasonably good fit to the source function.\nFigure 7 (see the supplementary material [41]) provides a detailed visualization of how model performance varies with the size of the transfer dataset for the 5-D case. The SMAPE trends indicate that, for most functions, the transferred model outperforms the model trained from scratch up to a transfer dataset size of 250 points. This trend supports the expected suitability of our transfer learning method for scenarios with relatively small sample sizes. However, there are notable exceptions. For function F24, the model trained from scratch surpasses the transferred model with as few as 40 samples. Similarly, for F21, the model trained from scratch consistently outperforms the transferred model regardless of dataset size. Additionally, in the cases of F16 and F23, the original RFR demonstrates superior performance, consistently exceeding both the transferred model and the model trained from scratch across all transfer dataset sizes, ranging from 10 to 250 samples.\nNext, we explore the impact of the function's domain dimensionality on the performance and efficacy of the proposed transfer learning approach. In 2-D functions (see Fig. 6 and Table I in the supplementary material [41]), the transferred model demonstrates superior performance over the model trained from scratch for most functions at smaller sample sizes (e.g., 50), with F23 and F24 being notable exceptions. This advantage largely persists as the number of transfer samples increases, although F19 and F24 emerge as additional exceptions. Furthermore, the transferred model consistently outperforms the original model across all tested sample sizes, except for function F23. In 10-D functions (refer to the supplementary material [41]), an intriguing trend emerges as the transfer dataset size increases. With smaller datasets (e.g., 40 samples), the transferred RFR significantly outperforms the model trained from scratch, highlighting a clear performance advantage. However, as the dataset size grows (e.g., 500 samples), this gap gradually diminishes, reflecting the scratch-trained model's ability to catch up with more data. Despite this, transfer learning proves less effective for certain highly multi-modal functions, such as F16 and F21 - F24, where the inherent complexity poses persistent challenges.\nB. Transferring RFR on Real-world applications\n1) Porkchop Plot Benchmarks in Interplanetary Trajectory Optimization: Fig. 3 illustrates the percentage difference in average SMAPE between RFR models trained from scratch and those adapted through transfer learning, evaluated across various transfer scenarios and transfer dataset sizes. The result reveals that, in most cases, the transferred model outperforms the model trained from scratch, particularly when the transfer dataset contains fewer than 100 samples. This indicates that transfer learning is especially advantageous in data-scarce settings. However, as the size of the transfer dataset increases, the performance gap diminishes, with the models trained from scratch showing greater improvements. A more detailed analysis of the relation between performance and transfer dataset size is provided in Fig. 9 (see the supplementary material [41]). In most scenarios, the transferred RFR consistently outperforms the original RFR, and the model is trained from scratch when only a small transfer dataset is available. However, as the dataset grows, the from-scratch model outperforms the transferred model.\nThe original RFR model rarely surpasses the transferred or scratch-trained models when the transfer dataset is extremely limited, such as with just 10 samples, though occasional exceptions are observed. In such exceptions, the transferred model may overfit the limited data during optimization, leading to poor generalization to the broader target domain. Overfitting can be identified when the transferred model performs better than the original RFR on the transfer samples, as it is explicitly optimized for them. These findings highlight that while the transfer learning approach is generally robust, its effectiveness can be challenged in scenarios with severely restricted data availability. Similar performance patterns are observed in other experimental scenarios, such as Earth-to-Venus and Mercury-to-Earth transfers, as shown in Fig. 10, 11, 12, and 13, which are included in the supplementary material [41].\n2) Kinematics of a Robot Arm: As shown in Fig. 4, the results highlight varying outcomes of the proposed transfer learning approach depending on the specific transfer scenario. For example, when transferring from torque1 to torque3, the transferred RFR consistently delivers strong performance regardless of the transfer dataset size. In contrast, scenarios such as transferring from torque7 to torque1 demonstrate a clear advantage for the model trained from scratch, which outperforms the transferred RFR across all dataset sizes. A more granular analysis of how performance correlates with the size of the transfer dataset is provided in Fig. 14 (see the supplementary material [41]). Beyond the general trends, there are rare instances where the original RFR outperforms both the transferred model and the from-scratch model. Such cases are primarily observed when the transfer dataset is extremely small. This behavior mirrors patterns seen in the Interplanetary Trajectory Optimization application, where an insufficient transfer dataset can lead to suboptimal adaptation and even misguide the optimization process.\n3) Real-World Optimization Benchmark in Vehicle Dynamics: Compared to other real-world applications, this problem poses significant challenges, as illustrated in Fig. 5. In most scenarios, the transferred RFR outperforms the model trained from scratch only when the transfer dataset is relatively small (fewer than 30 samples) and for specific transfer settings. However, there are instances, such as transferring from instance4 to instance3, where the transfer learning approach fails entirely. A more detailed analysis, provided in Fig. 15 (see the supplementary material [41]), shows the SMAPE trends for the original RFR, the model trained from scratch, and the transferred RFR across different transfer dataset sizes. The results underscore the unique difficulty of transferring from instacne3 to other instances. These findings, combined with the landscapes of different instances discussed in the original paper [32], suggest that the instance differs substantially from the others. This distinction likely explains why increasing the transfer dataset size-even to encompass the entire domain-fails to meaningfully reduce the SMAPE of the transferred RFR.\n4) Single-Objective Game-Benchmark MarioGAN Suite: As illustrated in Fig. 16 and Fig. 17 (see the supplementary material [41]), the transferred RFR consistently outperforms both the original RFR and the model trained from scratch across most transfer scenarios involving F5 of the MarioGAN Suite. Notably, the performance gap between the transferred RFR and the model trained from scratch becomes more pronounced as the size of the transfer dataset increases up to 30. However, this gap diminishes when the transfer dataset approaches a size of 1000 in the majority of transfer settings. A comparable trend is observed for F1 and F6 of the MarioGAN Suite, as shown in Fig. 18, 19, 20, and 21, included in the supplementary material [41]."}, {"title": "VI. CONCLUSION", "content": "We introduce a transfer learning method specifically designed for non-differentiable surrogate models like Random forest regression (RFR). This method addresses the challenge of domain shifts between source and target functions connected through an unknown affine transformation. By leveraging a small transfer dataset sampled from the target domain, the method optimizes the transformation to adapt a source-trained surrogate model for effective approximation of the target function. This method is particularly valuable in scenarios where data collection is costly, offering superior sample efficiency compared to training a new model from scratch.\nExperiments on synthetic scenarios using BBOB test functions demonstrate the effectiveness of the proposed method. With transfer datasets comprising 50-100 samples, the transferred RFR consistently outperformed models trained from scratch, particularly in high-dimensional settings. However, for highly complex functions such as F16 and F21-F24, the benefits of transfer learning are limited, as the original RFR struggles to approximate these functions accurately due to their inherent complexity.\nThe transfer learning method is further validated on four real-world applications, highlighting its strengths in low-data scenarios. However, challenges emerge when the transfer dataset is extremely small (e.g., 10 samples), leading to potential overfitting. Additionally, substantial differences between source and target domains constrained the model's adaptability, even with larger datasets. These results underscore the importance of well-aligned transfer datasets to ensure successful adaptation.\nFuture enhancements could include integrating active learning to prioritize informative data points for fine-tuning and refining both the surrogate model and the transformation simultaneously. While this study demonstrates the feasibility of leveraging pre-trained RFR models in affine transformation scenarios, future work will explore non-linear transformations, such as input-output warping [42], to extend the method's applicability to more complex and diverse problems."}]}