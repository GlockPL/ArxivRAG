{"title": "Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference", "authors": ["Jian Xu", "Delu Zeng", "John Paisley"], "abstract": "Deep Gaussian processes (DGPs) provide a robust paradigm for Bayesian deep learning. In DGPs, a set of sparse integration locations called inducing points are selected to approximate the posterior distribution of the model. This is done to reduce computational complexity and improve model efficiency. However, inferring the posterior distribution of inducing points is not straightforward. Traditional variational inference approaches to posterior approximation often lead to significant bias. To address this issue, we propose an alternative method called Denoising Diffusion Variational Inference (DDVI) that uses a denoising diffusion stochastic differential equation (SDE) to generate posterior samples of inducing variables. We rely on score matching methods for denoising diffusion model to approximate score functions with a neural network. Furthermore, by combining classical mathematical theory of SDEs with the minimization of KL divergence between the approximate and true processes, we propose a novel explicit variational lower bound for the marginal likelihood function of DGP. Through experiments on various datasets and comparisons with baseline methods, we empirically demonstrate the effectiveness of DDVI for posterior inference of inducing points for DGP models.", "sections": [{"title": "1. Introduction", "content": "Deep Gaussian Processes (DGPs) (Damianou & Lawrence, 2013) have emerged as a robust framework for Bayesian deep learning (Fortuin, 2022) that allows for flexible modeling of complex functions. DGPs extend the idea of Gaussian Processes (GPs) (Rasmussen, 2003) to multiple layers, enabling the modeling of hierarchical structures and capturing intricate dependencies within the data. A crucial aspect of DGPs is the selection of inducing variables (Titsias, 2009; Snelson & Gharahmani, 2005; Qui\u00f1onero-Candela & Rasmussen, 2005), which are sparse integration locations used to approximate the posterior distribution of the model. By leveraging these inducing points, DGPs can efficiently handle large datasets and reduce the computational burden.\nVariational inference methods (Blei et al., 2017; Zhang et al., 2018) aim to approximate the true posterior distribution with a parameterized variational distribution by minimizing their KL divergence. In the context of DGPs, traditional variational methods include mean-field Gaussian variational inference (DSVI) (Salimbeni & Deisenroth, 2017) and Implicit Posterior Variational Inference (IPVI) (Yu et al., 2019). However, both of these methods have their limitations and can introduce significant bias when learning the posterior distribution of inducing points.\nDSVI approximates the posterior distribution of inducing points with a simple Gaussian distribution. Although this approximation is analytically tractable, it often leads to substantial bias when dealing with nonlinear likelihood functions. The simplifying assumptions made in the mean-field approximation can fail to capture the complex dependencies and correlations between the inducing points, resulting in suboptimal results. On the other hand, IPVI uses a neural network to parameterize the posterior distribution of inducing points. Posterior inference is formulated as a Nash equilibrium (Awerbuch et al., 2008) similar to that of generative adversarial networks (GANs) (Goodfellow et al., 2014), requiring adversarial learning for the max-max problem. However, optimizing this objective function can be challenging, especially when dealing with non-convex neural networks, and lead to instability during training and contribute to significant bias in the posterior inference of inducing points (Jenni & Favaro, 2019).\nThese limitations of traditional variational methods for inference of DGPs inspires the exploration of alternative approaches. Motivated by the success of denoising diffusion models (Rombach et al., 2022) in deep learning, we propose a Denoising Diffusion Variational Inference (DDVI) method that utilizes the denoising diffusion SDE and incorporates principles similar to the score matching method (Song et al., 2020) in order to construct the objective function.\nBy employing the denoising diffusion SDE, we can accurately capture the complex dependencies and correlations among the inducing points. Additionally, similar to the score matching method, we can approximate the intricate score functions required for accurate posterior inference using a neural network. This combination finally allows us to explicitly derive a variational lower bound for the marginal likelihood function by KL divergence minimization, thereby addressing the bias introduced by traditional variational methods. Furthermore, DDVI incorporates numerous unique insights, including the well-developed mathematical theory of SDEs (Anderson, 1982; Haussmann & Pardoux, 1986), the bridge process trick, stochastic optimization techniques, reparameterization techniques, and gradient backpropagation. These collectively enable us to efficiently obtain posterior samples from the denoising diffusion network. As a result, our approach improves not only the computational efficiency but also ensures stable and reliable training in DGPs.\nIn summary, our contributions can be outlined as follows:\n\u2022 We propose a novel parameterization approach for the posterior distribution of inducing points in DGPs, utilizing a denoising diffusion process. This method not only guarantees model efficiency by accurately capturing the complex dependencies and correlations among the inducing points, but also facilitates optimization and training.\n\u2022 We exploit the minimization of KL divergence between the approximate and true processes to derive an explicit variational lower bound. To efficiently obtain posterior samples, we employ stochastic optimization and reparameterization techniques for gradient backpropagation within the denoising diffusion network.\n\u2022 Through extensive experiments on various datasets and comparisons with baseline methods, we empirically demonstrate the effectiveness of the DDVI method in posterior inference of inducing points for DGP models."}, {"title": "2. Method", "content": "2.1. Model Review\n2.1.1. GAUSSIAN PROCESS\nConsider a random function f : \\mathbb{R}^D \\rightarrow \\mathbb{R} that maps N training inputs X = \\{X_n\\}_{n=1}^N to a set of noisy observed outputs y=\\{y_n\\}_{n=1}^N. Often, a zero mean Gaussian Process (GP) prior is assumed for the function, f \\sim GP(0, k), where k denotes the covariance kernel function k : \\mathbb{R}^D \\times \\mathbb{R}^D \\rightarrow \\mathbb{R}. Let \\mathbf{f} \\doteq (f(x_1),..., f (x_N))^\\text{T} represent the latent function values at the inputs X. The GP prior assumption then induces a multivariate Gaussian prior over the function values, expressed as p(\\mathbf{f}) = \\mathcal{N}(\\mathbf{f}|0, K_{XX}), where the covariance matrix $K_{XX}$ is defined by $[K_{XX}]_{ij} = k (x_i, x_j)$. The observed outputs y are then assumed to be contaminated by i.i.d. noise, modeled as $p(y|\\mathbf{f}) = \\mathcal{N}(y|\\mathbf{f}, \\sigma^2I)$, where $\\sigma^2$ is the noise variance. The GP posterior distribution of the latent output $p (\\mathbf{f}|y)$ has a closed-form solution. However, the computational cost is $O(N^3)$ and the storage requirement is $O(N^2)$, making it challenging to scale to large datasets without introducing additional techniques.\nSparse methods have been developed that introduce inducing points $Z = \\{Z_m\\}_{m=1}^M$ from the input space, along with corresponding inducing variables: $u = \\{f(z_m)\\}_{m=1}^M$. These methods reduce the computational complexity to $O(NM^2)$. In the Sparse Gaussian Processes (SGPs) framework, the inducing variables $u$ and the function values $\\mathbf{f}$ share a joint multivariate Gaussian distribution, expressed as $p(\\mathbf{f}, u) = p(\\mathbf{f}|u)p(u)$, with the conditional distribution given by\np(\\mathbf{f}|u) = \\mathcal{N}(\\mathbf{f}|K_{XZ}K_{ZZ}^{-1}u, K_{XX}-K_{XZ}K_{ZZ}^{-1}K_{ZX}) \\tag{1}\nand $p (u) = \\mathcal{N} (u|0, K_{ZZ})$ is the prior over the outputs of the inducing points.\n2.1.2. DEEP GAUSSIAN PROCESSES\nA multi-layer Deep Gaussian Process (DGP) model is a hierarchical composition of Gaussian Process (GP) models constructed by stacking multiple-output Sparse GPs (SGPs) together, as described in (Damianou & Lawrence, 2013). Consider a DGP model with L layers, where each layer $l = 1,..., L$ consists of $D_l$ independent random functions. The output of the $(l - 1)$th layer, denoted as $F_{l-1}$, serves as the input to the $l$th layer. Formally, the outputs of the $l$th layer are defined as $F_l = \\{f_{l,1} (F_{l-1}),\\cdots, f_{l,D_l} (F_{l-1})\\}$, where $f_{l,d} \\sim GP(0, k_l)$ for $d = 1, ..., D_l$, and $F_0 \\equiv X$. The inducing points and their corresponding inducing variables for each layer are denoted by $Z \\equiv \\{Z_l\\}_{l=1}^L$ and $U \\equiv \\{U_l\\}_{l=1}^L$, respectively. Here, $U_l \\doteq \\{f_{l,1}(Z_l), \\ldots, f_{l, D_l}(Z_l)\\}$. Let $F\\doteq \\{F_l\\}_{l=1}^L$. The design of the DGP model leads to the following joint model density,\np(y, F, U) = p (y|F_L) \\prod_{l=1}^L p(F_l|F_{l-1}, U_l)p (U). \\tag{2}\nHere we place independent GP priors within and across layers on U,\np(U) = \\prod_{l=1}^L p(U_l) = \\prod_{l=1}^L\\prod_{d=1}^{D_l}\\mathcal{N} (U_{l,d}|0, K_{Z_lZ_l}). \\tag{3}"}, {"title": "", "content": "and the condition similar to Eq. (1) is defined as follows,\np (F_l | F_{l-1}, U_l) = \\prod_{d=1}^{D_l}\\mathcal{N} (F_{l,d} | \\mu_{l,d}, \\Sigma_{l,d}), \\tag{4}\nwhere we define\n\\mu_{l,d} = K_{F_{l-1}Z_l}K_{Z_lZ_l}^{-1}U_{l,d}\n\\Sigma_{l,d} = K_{F_{l-1}F_{l-1}} - K_{F_{l-1}Z_l} K_{Z_lZ_l}^{-1}K_{Z_lF_{l-1}}.\nIn the context of DGPs, traditional variational methods primarily include mean-field Gaussian variational inference (DSVI) (Salimbeni & Deisenroth, 2017) and Implicit Posterior Variational Inference (IPVI) (Yu et al., 2019). However, both of these methods have their limitations and can introduce significant bias in inferring the posterior distribution of inducing points.\nDSVI approximates the posterior by a mean-field Gaussian, $q (U_{l,1:D_l}) = \\mathcal{N} (U_{l,1:D_l} | m_{l,1:D_l}, S_{l,1:D_l})$, where $m_{l,1:D_l}$ and $S_{l,1:D_l}$ are variational parameters. However, this assumption is overly strict and may limit the effectiveness and expressiveness of the model. The likelihood $p(y | U)$ is difficult to compute because the latent functions $F_1, \\cdots, F_{L-1}$ are all non-linear kernel functions.\nOn the other hand, IPVI utilizes a neural network $\\psi$ to parameterize the posterior distribution of inducing points. Posterior inference is formulated as a Nash equilibrium (Awerbuch et al., 2008) similar to that of generative adversarial networks (GANs) (Goodfellow et al., 2014), requiring adversarial learning for the max-max problem,\nl_{IPVI}(\\xi) = \\mathbb{E}_{q_{\\xi} (U)}[\\log p(y|U) - D_{\\psi^*} (U)]\\\\\ns.t.\\ \\psi^* = \\underset{\\psi}{\\arg \\max} \\mathbb{E}_{p(U)} [\\log (1 - \\sigma (D_{\\psi}(U)))] + \\mathbb{E}_{q_{\\xi} (U)} [\\log \\sigma (D_{\\psi}(U))], \\tag{5}\nwhere $D_\\psi$ is another discriminator network. However, optimizing such an implict objective $l(g)$ can be challenging, especially when dealing with the non-convex neural network $D_\\psi$. This can lead to instability during training and contribute to significant bias in the posterior inference of inducing points (Jenni & Favaro, 2019).\nTo address this issue, we propose a novel parameterization approach for the posterior distribution of inducing variables U that uses a denoising diffusion process. This method not only ensures model efficiency by accurately capturing the complex dependencies and correlations among the inducing points, but also facilitates optimization and training.\n2.2. Denoising Diffusion Variational Inference\n2.2.1. PARAMETERIZING INDUCING POINT POSTERIORS\nLet H = D \u00d7 M \u00d7 L denote the dimension of the inducing points. We aim to sample from the true posterior distribution $q(U)$ in \\mathbb{R}^H, $q(U) = p(U|y)$. Following a similar setup to prior works (Tzen & Raginsky, 2019; Zhang & Chen, 2021; Vargas et al., 2023), we start by sampling from a fixed distribution $P_{fix}$ and then follow a Markov process in which we consider a sequential latent variable model with a joint distribution denoted as $Q (U_0, . . ., U_T)$, for step $t_s \\in \\{0, .., T - 1\\}$,\nU_{t_s+1}\\sim T (U_{t_s+1} | U_{t_s}), \\quad U_0\\sim P_{fix} \\tag{6}\nHere $T (U_{t_s+1} | U_{t_s})$ denotes a transition probability distribution. Through this sequence model, we use the marginal distribution $Q (U_T)$ at the terminal step T to approximate the true posterior distribution $q (U_T)$.\n2.2.2. TIME-REVERSAL REPRESENTATION OF DIFFUSION SDE\nIn this paper, we constrain the Markov process $Q(U_0,..., U_T)$ to be a time-reversal process of the following forward noising diffusion stochastic differential equation (SDE),\ndU_t = h(t, U_t)dt + g(t)dB_t, \\quad U_0 \\sim q, \\tag{7}\nwhere $h(t, \\cdot) : \\mathbb{R}^H \\rightarrow \\mathbb{R}^H$ is the drift coefficient, $g(t) \\in \\mathbb{R}$ is the diffusion coefficient, and $(B_t)_{t\\in[0,T]}$ is an H-dimensional Brownian motion. This diffusion induces the path measure P on the time interval [0, T] and the marginal density of $U_t$ is denoted $p_t$. Note that by definition we always have $p_0 = q$ when using an SDE to perturb this distribution. In DDPM (Ho et al., 2020; Song et al., 2020), $p_T$ is an unstructured prior distribution that contains no information of $p_0$, such as a Gaussian distribution with fixed mean and variance.\nFrom (Anderson, 1982; Haussmann & Pardoux, 1986), the time-reversal representation of Eq. (7), $\\overline{U}_t = U_{T-t}$, where equality is here in distribution, satisfies\nd\\overline{U}_t = (g(T-t))^2 \\nabla \\log (p_{T-t}(\\overline{U}_t)) dt - h(T-t, \\overline{U}_t) dt \\\\\n+g(T - t) dW_t, \\quad \\overline{U}_0 \\sim p_T, \\tag{8}\nwhere $(W_t)_{t\\in [0,1]}$ is another H-dimensional Brownian motion. By definition, this time-reversal starts from\n\\overline{U}_0 \\sim p_T \\approx P_{fix}\nand is such that $\\overline{U}_T \\sim q$. Since the distribution of $\\overline{U}_T$ is consistent with the true posterior $q$, we can parameterize the transition probability $T (U_{t_s+1} | U_{t_s})$ in the Euler discretized form of Eq. (8)."}, {"title": "2.2.3. SCORE MATCHING TECHNIQUE", "content": "This suggests that if we could approximately simulate the diffusion of Eq. (8), then we could obtain approximate samples from the target q. However, putting this idea in practice requires being able to approximate the intractable scores $\\nabla \\log (p_t(\\cdot))$ for $t \\in [0,T]$. To achieve this, DDPM (Ho et al., 2020; Song et al., 2020) rely on score matching techniques. Specially, to approximate P consider a path measure $\\mathbb{P}^{\\phi}$ whose time-reversal is induced by\nd\\overline{U}_t^{\\phi} = (g(T-t))^2s_\\phi(T - t, \\overline{U}_t)dt - h(T - t, \\overline{U}_t)dt \\\\\n+ g(T - t) dW_t, \\quad \\overline{U}_0^{\\phi} \\sim P_{fix}, \\tag{9}\nso that the backward process $\\overline{U} \\sim \\mathbb{Q}^{\\phi}$, where $P_{fix}$ represents a fixed distribution. To obtain $s_\\phi(t, \\cdot) \\approx \\nabla \\log (p_t(\\cdot))$, we parameterize $s_\\phi(t, \\cdot)$ by a neural network whose parameters are obtained by minimizing $KL(\\mathbb{P}||\\mathbb{P}^{\\phi})$. From the chain rule for the KL divergence (L\u00e9onard, 2013) we have,\nKL(\\mathbb{P}||\\mathbb{P}^{\\phi}) = KL(P_T||P_{fix}) + KL(\\mathbb{P}(\\cdot |\\overline{U}_T)||\\mathbb{P}^{\\phi}(\\cdot |\\overline{U}_T^{\\phi})), \\tag{10}\nwhere by the well-known Girsanov Theorem (Oksendal, 2013) and the martingale property of It\u00f4 integrals the second term on the RHS is\nKL(\\mathbb{P}(\\cdot |\\overline{U}_T)||\\mathbb{P}^{\\phi}(\\cdot |\\overline{U}_T^{\\phi})) = \\\\\n\\frac{1}{2} \\int_{0}^{T} \\mathbb{E}_{P} (g(t))^2 \\| \\nabla \\log (p_t(U_t)) - s_\\phi(U_t,t)\\|^2 dt \\tag{11}\nFrom the denoising score matching derivation (Vincent, 2011), this can also be written as\n\\frac{1}{2} \\int_{0}^{T} \\mathbb{E} (g(t))^2 \\| \\nabla \\log (p_t(U_t)) - s_\\phi(t, U_t)\\|^2 dt\nplus a constant term, where the expectation is over the joint distribution $p_0(U_0)p_t(U_t|U_0)$.\nAs the main loss function in DDPM, diffusion-based generative modeling approaches typically rely on Eq. (10), which involves sampling from $p_0$, the original data such as images, and then backpropagating to estimate the parameters of the neural network $s_\\phi$. However, unlike traditional score matching techniques, this loss function is not applicable to our model since our $p_0$ is the posterior probability q and we only have access to the joint likelihood, and cannot sample from it. To address this issue, we propose an alternative approach by minimizing $KL(\\mathbb{P}^{\\phi}||\\mathbb{P})$. Analogous to Eq. (10), considering that we can only obtain samples from $\\mathbb{Q}^{\\phi}$, we have,\nKL(\\mathbb{P}^{\\phi}||\\mathbb{P}) = KL(\\mathbb{Q}^{\\phi}||\\mathbb{Q})\\tag{12}\n= KL(P_{fix}||P_{T}) + KL(\\mathbb{Q}^{\\phi}(\\cdot |\\overline{U}_0)||\\mathbb{Q}(\\cdot |\\overline{U}_0)),"}, {"title": "", "content": "where\nKL(\\mathbb{Q}^{\\phi}(\\cdot |\\overline{U}_0)||\\mathbb{Q}(\\cdot |\\overline{U}_0)) = \\frac{1}{2} \\int_{0}^{T} \\mathbb{E}_{Q} (g(T-t))^2 \\| \\gamma(t) \\|^2 dt\\tag{13}\nwhere the expectation is over $\\mathbb{Q}^{\\phi}$ and we have defined\n\\gamma(t) \\doteq \\nabla \\log (p_{T-t}(\\overline{U})) - s_\\phi(T - t, \\overline{U})\nHowever, the current challenge we face is that, although we can obtain samples from $\\mathbb{Q}^{\\phi}$ by simulating the SDE (9), dealing with the nonlinear drift function of SDE (9) makes it difficult to obtain $\\nabla \\log (p_{T-t}(\\overline{U}))$ in Eq. (13).\n2.2.4. BRIDGE PROCESS TRICK\nTherefore, we propose an alternative approach by constructing a bridge process $\\mathbb{P}^{Bri}$ to assist in measuring $KL(\\mathbb{P}^{\\phi}||\\mathbb{P})$. First, we observe that\nKL(\\mathbb{P}^{\\phi}||\\mathbb{P}) = \\mathbb{E}_{P^{\\phi}} \\log \\frac{d\\mathbb{P}^{\\phi}}{d\\mathbb{P}} = \\mathbb{E}_{P^{\\phi}} \\log \\frac{d\\mathbb{P}^{\\phi}}{d\\mathbb{P}^{Bri}} + \\mathbb{E}_{P^{\\phi}} \\log \\frac{d\\mathbb{P}^{Bri}}{d\\mathbb{P}},\\tag{14}\nwhere we represent the stochastic process KL with the Radon-Nikodym derivative. Given the specific form in Eq. (14), we define the bridge process $\\mathbb{P}^{Bri}$ to follow the diffusion formula as in Eq. (7), but initialized at $p^{Bri} (U^{Bri}_0) = P_{fix}$ instead of q, which aligns with the distribution of $U_0$ in Eq. (9),\ndU^{Bri}_t = h(t, U^{Bri}_t)dt + g(t)dB_t, \\quad U^{Bri}_0 \\sim P_{fix}.\\tag{15}\nWe typically assume h(\\cdot, t) is affine, $h(x,t) = -\\lambda(t) x$ and $P_{fix} = \\mathcal{N}(0, \\sigma^2I)$. Then the transition kernel $p_t(U^{Bri}_t|U^{Bri}_0)$ is always a Gaussian distribution $\\mathcal{N}(\\mu_t, \\Sigma_t)$, where the mean $\\mu_t$ and variance $\\Sigma_t$ are often known in closed-forms (S\u00e4rkk\u00e4 & Solin, 2019) by\nd\\mu_t = -\\lambda(t)\\mu_t, \\quad \\mu_0 = 0 \\\\\n\\frac{d\\Sigma_t}{dt} = -2\\lambda(t)\\Sigma_t + g(t)^2I, \\quad \\Sigma_0 = \\sigma^2I \\tag{16}\nBy the calculations of ordinary differential equations (Hale & Lunel, 2013), we obtain the following general solution to Eq. (16),\n\\mu_t = \\mu_0e^{\\int_{0}^{t}\\lambda(s)ds},\n\\Sigma_t = (\\int_{0}^{t}g(r)^2e^{\\int_{0}^{r}\\lambda(s)ds}drI + \\Sigma_0) e^{-\\int_{0}^{t}\\lambda(s)ds}\\tag{17}\nAccording to Eq. (17) we can derive from the Gaussian linear transformation principle that for any t, the distribution"}, {"title": "", "content": "of $U^{Bri}_t$ is a zero-mean Gaussian distribution,\np^{Bri} of $U^{Bri}_t$ is\np_t^{Bri} (U_t^{Bri}) = \\int p_t(U_t^{Bri}|U_0^{Bri})p(U_0^{Bri})dU_0^{Bri}\n= \\mathcal{N}(0, \\kappa_tI)\nwhere we have defined the variance\n\\kappa_t = (\\int_0^tg(r)^2e^{\\int_0^r\\lambda(s)ds} dr + \\sigma^2) e^{-\\int_0^t\\lambda(s)ds}.\nWe can write the SDE equation for the reverse process $\\mathbb{Q}^{Bri}$ of $\\mathbb{P}^{Bri}$ as\nd\\overline{U}_t^{Bri} = (g(T-t))^2 \\nabla \\log (p_{T-t}^{Bri}(\\overline{U}^{Bri}_t)) dt \\\\\n- h(T - t, \\overline{U}^{Bri}_t)dt\n+ g(T-t) dW_t,\n\\overline{U}_0^{Bri} \\sim p^{Bri}_T \\tag{19}\nAccording to Eq. (18), we can obtain an analytical expression for the derivative of the log-likelihood function with respect to $U^{Bri}_t$,\n\\nabla \\log (p_t^{Bri}(U^{Bri}_t)) = -\\frac{U^{Bri}_t}{\\kappa_{T-t}} \\tag{20}\nNext we calculate the value of Eq. (14). For the first term, according to the chain rule for KL and Girsanov Theorem (Oksendal, 2013), incorporating Eqs. (9, 19, 20), we have\n\\mathbb{E}_{P^{\\phi}} \\log \\frac{d\\mathbb{P}^{\\phi}}{d\\mathbb{P}^{Bri}} = KL (\\mathbb{P}^{\\phi}||\\mathbb{P}^{Bri}) = KL (\\mathbb{Q}^{\\phi}||\\mathbb{Q}^{Bri})\nwhich can be broken down into the sum of two terms,\nKL (pix||pri) + KL(\\mathbb{Q}^{\\phi}(\\cdot |U)||\\mathbb{Q}(\\cdot |\\overline{U}^{Bri}_0))\\\\\nwhere\nKL(\\mathbb{Q}^{\\phi}(\\cdot |U)||\\mathbb{Q}(\\cdot |\\overline{U}^{Bri}_0)) =\n\\frac{1}{2} \\int_0^T \\mathbb{E}_{Q^{\\phi}} (g(T - t))^2\\|\\frac{U^{Bri}_0}{\\kappa_{T-t}} + s_\\phi(T-t, U)\\|^2 dt\nAt this point, we can simulate the SDE (9) to compute the first term in Eq. (14). The integral term can be computed using either ODE solvers (Chen et al., 2018) or by employing Riemann summation methods. For the second term, $\\mathbb{E}_{P^{\\phi}} \\log \\frac{d\\mathbb{P}^{Bri}}{d\\mathbb{P}}$, we can see from Eq. (7) and Eq. (15) that $\\mathbb{P}$ and $\\mathbb{P}^{Bri}$ have the same dynamic system $\\tau$, except for different initial values. Therefore, we have\n\\mathbb{E}_{P^{\\phi}} \\log \\frac{d\\mathbb{P}^{Bri}}{d\\mathbb{P}} = \\mathbb{E} \\log \\frac{p^{Bri} (\\tau|\\cdot) p^{Bri} (\\cdot)}{p (\\tau) p_0 (\\cdot)}\n= \\mathbb{E} \\log \\frac{p^{Bri} (\\cdot)}{p_0 (\\cdot)}\n= \\mathbb{E} \\log \\frac{P_{fix}}{q} = \\mathbb{E} \\log \\frac{P_{fix}}{p(y)p(U)}\n+ \\log p(y)"}, {"title": "2.2.5. A NEW EVIDENCE LOWER BOUND", "content": "Let $\\l_{1}(\\phi) = \\mathbb{E}_{P^{\\phi}} \\log \\frac{d\\mathbb{P}^{\\phi}}{d\\mathbb{P}^{Bri}}$. Combining Eqs. (2, 14, 21, 22), we obtain a new variational lower bound $l(\\phi)$ for the marginal likelihood $\\log p(y)$ of our method,\n\\log p(y) = KL(\\mathbb{P}||\\mathbb{P}^{\\phi}) - \\l_{1}(\\phi) - \\mathbb{E}_{Q^{\\phi}} \\log \\frac{P_{fix}}{p(y)p(U)}\n= KL(\\mathbb{P}||\\mathbb{P}^{\\phi}) - \\l_{1} - \\mathbb{E}_{Q^{\\phi}} \\log P_{fix}\n+ \\mathbb{E}_{Q^{\\phi}} \\log p(U) + \\mathbb{E}_{Q, F_1,...,F_L} \\log P(y|F_L)\n\\geq  \\mathbb{E}_{Q^{\\phi}} \\log p(U) + \\mathbb{E}_{Q, F_1,...,F_L} \\log P(y|F_L)\n- \\l_{1}(\\phi) - \\mathbb{E}_{Q^{\\phi}} \\log P_{fix}\n= l(\\phi) \\tag{23}\nIn our derivation, $p(\\cdot)$ represents the prior function of U. By introducing a new variational lower bound for $\\log p(y)$, our proposed model, compared to the initial mean-field variational inference model (DSVI) where q is approximated by a Gaussian distribution, approximates the posterior distribution through a denoising diffusion process. The flexibility of the denoising neural network $s_\\phi$ intuitively suggests that our model has an advantage in approximating the posterior distribution. On the other hand, compared to IPVI, DDVI provides an explicit evidence lower bound (ELBO), which means it is easier to train and allows for efficient backpropagation.\n2.3. Reparameterization Trick and SGD\nFor ease of sampling, we consider a reparameterization version of Eq. (23) based on the approaximate transition probability $T_{\\phi} (U_{t_s+1} | U_{t_s})$ given by\nU_{t_s+1} = T_{\\phi}(U_{t_s}) = U_{t_s} - h(U_{t_s},T - t_s) +\n(g(T - t_s))^2s_\\phi (T - t_s, U_{t_s}) + g(T - t)\\epsilon_{t_s} \\tag{24}\nwhere $\\epsilon_{t_s} \\sim \\mathcal{N}(0, I)$. Given that $U_{t_s+1} = T_{\\phi}(U_{t_s})$, we have a representation of $U_{t_s}$ by a stochastic flow,\nU_{t_s+1} = T_{\\phi}(U_{t_s}) = T_{\\phi} \\circ T_{\\phi} \\circ \\cdots T_{\\phi}(U_0).\\tag{25}\nMoreover, for DGP models, we also have a reparameterization version (Salimbeni & Deisenroth, 2017) of the conditional distribution in Eq. (4) of the form\nF_{l,d} = K_{F_{l-1}Z_l}K_{Z_lZ_l}^{-1} U_{l,d}\n+ \\sqrt{K_{F_{l-1}F_{l-1}} - K_{F_{l-1}Z_l}K_{Z_lZ_l}^{-1}K_{Z_lF_{l-1}}}\\epsilon_{l,d}\\tag{26}\nwhere $\\epsilon_{l,d} \\in \\mathbb{R}^N$ are standard Gaussian random variables. In order to accelerate training and sampling in our inference scheme, we propose a scalable variational bound that is tractable in the large data regime based on stochastic variational inference (Kingma & Welling, 2013; Hoffman & Blei, 2015; Salimbeni & Deisenroth, 2017; Naesseth et al., 2020) and stochastic gradient descent (Welling & Teh, 2011; Chen et al., 2014; Zou et al., 2019; Alexos et al., 2022). Specifically, instead of computing the full log likelihood, we use a stochastic variant to subsample datasets into a mini-batches $\\mathbb{D}_I$ with $|X_I | = B$, where I \\subset \\{1, 2, .., N\\} is the index of a mini-batch. We present the resulting stochastic inference for our Denoising Diffuison Variational Inference algorithm for DGP models in Algorithm 1."}, {"title": "2.4. Predictive Distribution", "content": "To obtain the final layer density for making predictions, we first sample from the optimized generator and transform the input locations x to the test locations $x^*$ using Eq. (2). We subsequently compute the function values at the test locations, which are represented as $F_L$. Finally, we use the equation below to estimate the density of the final layer, which enables us to make predictions for the test data\nq(F_L)=\\int \\prod_{d,l}p(F_{l,d}|F_{l-1}, U_{l,d}) \\mathbb{Q}^{\\phi} (U_{l,d}) dF_{l-1}dU_{l,d}\nwhere $\\mathbb{Q}^{\\phi}$ represents the output of the denoising diffusion process at time T and the first term of the integral $p(F_{l,d}|F_{l-1}, U_{l,d})$ is conditional Gaussian. We leverage this to draw samples from $q (F_L)$ and further perform the sampling according to the problem considered."}, {"title": "3. Experiments", "content": "3.1. Baseline Models and Hyperparameter Settings\nIn order to evaluate the performance of our proposed method, we conducted empirical evaluations on real-world datasets for both regression and classification tasks, with both small and large datasets. We compare against several other models, including Doubly Stochastic VI (DSVI) (Salimbeni & Deisenroth, 2017), Implicit Posterior VI (IPVI) (Yu et al., 2019), and the state-of-the-art SGHMC model (Havasi et al., 2018). All experiments were conducted with the same hyper-parameters and initializations whenever possible to obtain a fair comparison.\nWe constructed a random 0.9/0.1 train/test split and normalized the features of our datasets to the range [-1,1]. The depth L of DGP models varied from 2 to 5, with 128 inducing points per layer, which were initialized by sampling Gaussian random variables. The output dimension for each hidden layer is set to 1 for the final layer and the dimensionality of the data for all others. We use the RBF kernel for all tasks. For all datasets, we have optimized hyper-parameters and network parameters jointly and set learning rate to 0.01 using Adam optimizer (Kingma & Ba, 2014). We trained all models on all datasets until convergence was achieved. In each experiment, we repeated the process 10 times and reported the mean and standard deviation of the metrics. The selection of the denoising diffusion networks are done manually by the classical grid search approach for each experimental dataset. It is worth mentioning that this work also benefits from the contributions of the PyTorch platform, GPyTorch (Gardner et al., 2018), and related work on neural SDE solvers (Li et al., 2020; Kidger et al., 2021). All our experiments were conducted on an RTX 4090 GPU.\n3.2. Regression Task\nIn our experiments, we evaluated the performance of the DDVI model on ten UCI regression datasets, which varied in size from 308 to 2,055,733 data points. We used the mean RMSE and mean NLL (Gneiting & Raftery, 2007) of the test data as the performance metric, and the results are presented in Figure 1 and Figure 2.\nAs shown in these two figures, our DDVI method consistently achieves competitive results compared to three baselines on the majority of datasets. This is attributed to the key advantages of our approach, which overcomes limitations present in previous methods as discussed in the main text. Our findings also suggest that deeper DGP models tend to perform better. It is worth mentioning that the difference in performance may be attributed to the nature of the datasets, such as their size or the presence of outliers or singular values.\nUsing mini-batch algorithm and GPU acceleration, our method can also be extended to larger datasets. Our evaluation of the performance of DDVI in Figures 1 and 2 is also conducted on two real-world large-scale regression datasets: the YearMSD dataset and the Airline dataset. The YearMSD dataset has a large input dimension of D = 90 and a data size of approximately 500,000. The Airline dataset, on the other hand, has an input dimension of D = 8 and a large data size of approximately 2 million. For the YearMSD dataset, we split the data into training and test sets, using the first 463,810 examples as training data and the last 51,725 examples as test data. Similarly, for the Airline dataset, we take the first 700K points for training and next 100K for testing."}, {"title": "3.3. Image and Large-Scale Dataset Classification", "content": "We evaluate our method on multiclass classification tasks using the MNIST (LeCun et al., 1998), Fashion-MNIST (Xiao et al., 2017), and CIFAR-10 (Krizhevsky et al., 2009) datasets. The first two datasets consist of grayscale images of size 28 \u00d7 28 pixels, while CIFAR-10 comprises colored images of size 32 \u00d7 32 pixels. The results are presented in Table 1. We note that our method outperforms the other three methods on all three datasets, with significantly less training time. Specially, for CIFAR-10 dataset, we utilize the convolutional layers of ResNet-20 (He et al., 2016) as our feature extractor (Wilson et al., 2016) and achieve a remarkable accuracy of 95.56 on the test set. Additionally, we evaluate our approach using two large-scale classification datasets, the Higgs datase and the SUSY dataset, which are presented in Table 2."}, {"title": "3.4. Unsupervised Learning for Data Recovery Task", "content": "We conducted a reconstruction experiment on Frey Faces Data (Roweis & Saul, 2000), focusing on how models capture uncertainty when training with missing data in structured inputs. We used the entire dataset with a latent variable dimensionality of 20. The image data set contains 1965 images of a face taken from sequential frames of a short video. Each image is of size 20\u00d728 yielding a 560 dimensional data space. In both cases, we chose 5% of the training set as missing data samples and removed 75% of their pixels, seeking to recover their original appearance. Figure 3 summarize the samples generated from the learned latent distribution. This reconstruction experiment is performed using the Gaussian Process Latent Variable Model (GPLVM) (Titsias & Lawrence, 2010) and is similar to the related work by (Gal et al., 2014).\nTo demonstrate the effectiveness of our method in producing more accurate likelihoods on image datasets, we present in Table 3 negative log-likelihood, and RMSE for reconstructed images on the Frey Faces, comparing with baseline methods. The results show that our method converges to higher likelihoods and lower RMSE, indicating superior performance in high-dimensional and multi-modal image data. This suggests that adding DDVI method can also improve the convergence of the traditional GPLVM methods."}, {"title": "4. Conclusion", "content": "We have introduced Denoising Diffusion Variational Inference (DDVI) as an alternative approach for inferring the posterior distribution of inducing points in Deep Gaussian Processes (DGPs). By employing a denoising diffusion stochastic differential equation (SDE) and utilizing the score matching method, we are able to accurately approximate challenging score functions using a neural network. Through extensive experiments and comparisons with baseline methods on various datasets, we demonstrated the effectiveness of DDVI in posterior inference of inducing points for DGP models. The DDVI method addressed the limitations of traditional variational inference techniques, reducing biases and improving accuracy in the posterior approximation. Our proposed DDVI approach not only enhances computational efficiency, but also provides a more robust framework for Bayesian deep learning with DGPs."}, {"title": "A. Additional Related Works", "content": "A line of closely related work focusing on enhancing variational posteriors with decoupled/orthogonal inducing points has garnered significant attention in recent years (Cheng & Boots, 2017; Salimbeni et al., 2018; Shi et al., 2020; Sun et al., 2021). These methods present variational Gaussian process models that segregate the representation of mean and covariance functions within the reproducing kernel Hilbert space. This novel parametrization extends previous models and allows for solving the variational inference problem using stochastic gradient ascent with linear time and space complexity in the number of mean function parameters. In contrast to these approaches, our work diverges in its emphasis on precise posterior inference for Gaussian process models rather than complexity analysis concerning inducing points.\nAnother line of related work is on the idea of fully Bayesian Gaussian processes (Lalchand & Rasmussen, 2020; Rossi et al., 2021), particularly (Rossi et al., 2021) have applied MCMC-related methods and the ideas of fully Bayesian approaches to deep GPs, achieving significant improvements. Our work, on the other hand, focuses on improvements and advancements in the field of variational inference.\nAdditionally, another line of related work is on implict stochastic processes (Ma et al., 2019), that is not restricted to Gaussian predictive distributions, which is closely related to function-space models (Sun et al., 2019; Mescheder et al., 2017). Furthermore, (Ortega et al., 2022) further extends the idea of DGP models to implict stochastic processes, enhancing the flexibility of the models. We believe that this is a valuable complement to our approach, and future work may involve integrating our method with these advancements to explore more useful applications."}]}