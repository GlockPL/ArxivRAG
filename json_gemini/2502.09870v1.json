{"title": "A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies", "authors": ["Alicia DeVrio", "Myra Cheng", "Lisa Egede", "Alexandra Olteanu", "Su Lin Blodgett"], "abstract": "Recent attention to anthropomorphism-the attribution of human- like qualities to non-human objects or entities-of language tech- nologies like LLMs has sparked renewed discussions about potential negative impacts of anthropomorphism. To productively discuss the impacts of this anthropomorphism and in what contexts it is appropriate, we need a shared vocabulary for the vast variety of ways that language can be anthropomorphic. In this work, we draw on existing literature and analyze empirical cases of user interac- tions with language technologies to develop a taxonomy of textual expressions that can contribute to anthropomorphism. We high- light challenges and tensions involved in understanding linguistic anthropomorphism, such as how all language is fundamentally human and how efforts to characterize and shift perceptions of humanness in machines can also dehumanize certain humans. We discuss ways that our taxonomy supports more precise and effective discussions of and decisions about anthropomorphism of language technologies.", "sections": [{"title": "1 Introduction", "content": "Recently much attention has been brought to language technolo- gies like LLMs and their supposed potential to attain human-like levels of cognition, feelings, and existence. For example, Blake Lemoine, an engineer at Google, asserted that the LaMDA model is a person and should be treated as such [115]. Far from an iso- lated incident, a recent sampling of headlines highlights the many claims of sentience and other human-like abilities based on the outputs of language technologies: \"A Stunning New AI Has Sup- posedly Achieved Sentience,\" \"Sentient LLMs: What to test, for consciousness, in Generative AI,\u201d \u201cCould a Large Language Model Be Conscious?\u201d [10, 86, 114]. This attribution of human-like qualities to non-human entities or objects, or anthropomorphism, is not new to the realm of technology and the broader HCI field (e.g., [16, 25, 28, 32, 40, 75, 81]). Technolo- gies can be designed, intentionally or not, in ways that foster or diminish anthropomorphism. Anthropomorphic design has long been pursued as a way to reduce friction for users, helping them better engage with technologies. For example, human-robotics in- teraction research has suggested that human-like robots are easier for humans to interact with, as humans already know how to in- teract with each other (e.g., [28, 39]). Additionally, past work has asserted that \"disembodied social robots\" in some situations can help digital well-being [24]. However, with the dawn of AI-powered language technologies like LLMs, anthropomorphism has increasingly been highlighted as a vector for significant risks and harms (e.g., [1, 2, 6, 41, 54, 76]). For example, researchers have discussed how anthropomorphism could create conditions ripe for exploitation of users' emotional dependence on Al assistance, could degrade social connections between humans, and could shift conceptions of what is and is not human [16, 43]. These harms and risks have been difficult to productively discuss and address, in part due to poor understanding of how different aspects of language technology outputs can lead to anthropomor- phism. This lack of understanding is exacerbated by a lack of con- ceptual clarity about the ways in which outputs are perceived as human-like, which in turn makes it difficult to discuss and make"}, {"title": "2 Related Work", "content": "Anthropomorphism is the attribution of human-like qualities to inanimate objects or entities [25]. Within fields like human-robot interaction, researchers have studied how to enhance anthropomor- phic features of robots in order to make robots easier to interact with [39, 68, 95]. Realistic features such as eye expression out- put, mannerisms, and other complex emotions have been incorpo- rated into robots as the bounds of what can be anthropomorphized evolve [16, 72, 80]. Existing work has also noted the ways that humans might be likely to anthropomorphize technologies even when those technologies have not been designed in purposefully anthropomorphic ways [81]. The broader HCI community has seen a growth in anthropo- morphic characteristics being integrated into large language mod- els [13, 16], with design goals oriented around completing a task"}, {"title": "2.1 Anthropomorphic Design in Technology", "content": "Anthropomorphism is the attribution of human-like qualities to inanimate objects or entities [25]. Within fields like human-robot interaction, researchers have studied how to enhance anthropomor- phic features of robots in order to make robots easier to interact with [39, 68, 95]. Realistic features such as eye expression out- put, mannerisms, and other complex emotions have been incorpo- rated into robots as the bounds of what can be anthropomorphized evolve [16, 72, 80]. Existing work has also noted the ways that humans might be likely to anthropomorphize technologies even when those technologies have not been designed in purposefully anthropomorphic ways [81]. The broader HCI community has seen a growth in anthropo- morphic characteristics being integrated into large language mod- els [13, 16], with design goals oriented around completing a task (e.g., voice assistants) or health care and well-being [106, 109]. Mo- tivating factors to implement humanistic traits to appeal to the likeness of users may be rooted in business incentives (such as influencing a customer to complete a transaction) or attempts to im- prove user trust as a means to increase engagement (e.g., a telehealth chatbot) [61, 103]. Trust is a particularly common motivation for these anthropomorphic technological design decisions, especially when human-like characteristics go beyond the physical appear- ance of humans and mimic their personality traits and cognitive abilities [52, 68]. Recently, this anthropomorphism has increased to the extent that people have begun to believe that LLMs and other technologies have the capacity to achieve and exhibit human levels of cognition, sentience, and awareness (e.g., [10, 86, 114]). There have even been high-profile cases of claims that LLMs are and should be treated as people (e.g., [115]). We situate our research against this backdrop, highlighting the importance now as much as ever for work that advances and clari- fies understandings of anthropomorphism."}, {"title": "2.2 Negative Impacts from Anthropomorphism of Technologies", "content": "Prior work has raised concerns about various harms that anthropo- morphism of technologies might give rise to (e.g., [2, 6, 36, 41]). One immediate negative impact from anthropomorphism of technology is the possibility of inauthenticity and deception, with users believ- ing they are talking to a human rather than a machine [49, 50, 105]. Scholars have also pointed out other more insidious and long-term impacts of anthropomorphism of technologies. For example, an- thropomorphism of technology often enhances users' trust of sys- tems [116]. While this trust can be beneficial in some contexts [130], it can also be misplaced, leading users to rely on technology when it does not merit such confidence and overestimate its capabili- ties [1, 14, 54, 63, 75]. This misplaced trust may even cause users to become emotionally dependent on the system or to disclose sensitive information without fully understanding the associated privacy risks [54, 56]. Furthermore, other scholars have argued that human-like tech- nologies may contribute to the devaluation of human interaction and expression, potentially leading to the cheapening of language, increased social disconnection, and diminished human agency [91, 118, 127, 128]. Additionally, anthropomorphism has been linked to the reinforcement of gender and racial stereotypes [1, 5, 34, 76]. We see the conversations about and mitigation of negative im- pacts from anthropomorphism of technologies as important and urgent [12]. We orient our taxonomy toward providing needed scaf- folding for future identification of and discussions about the ways in which anthropomorphism is occurring so that more targeted work on interventions can be accomplished."}, {"title": "2.3 Types of Anthropomorphism of Technologies", "content": "Past work has attempted to understand, name, and categorize dif- ferent types of anthropomorphism [31]. Some of this comes from a human-robot interaction context, looking to assess the ways that robots are human-like, often with the guiding aim of supporting work that makes robots more and more similar to humans. For instance, DiSalvo et al. examine designed artifacts and distinguish between four different kinds of anthropomorphic form: structural, gestural, character, and aware [25]. And Kahn et al. present a set of nine benchmarks-autonomy, imitation, intrinsic moral value, moral accountability, privacy, reciprocity, conventionality, creativ- ity, and authenticity of relation-that could be used to assess how human-like robots are [58]. Though this research is focused more on robots, robots are more than just tangible objects and often include spoken or other forms of interactions that can be useful to inform text contexts. There is work that focuses on anthropomorphism stemming from linguistic aspects of robots or other tangible technologies. Emnett et al. survey literature to present \"six broad categories of linguistic factors that lead humans to anthropomorphize robots: au- tonomy, adaptability, directness, politeness, proportionality, and hu- mor\" [31]. Otsu and Izumi categorize linguistic anthropomorphism techniques for home appliances into first-person subject expres- sions, expressions suggesting body ownership and animacy, casual linguistic expressions, and explicit emotional expressions [87]. Recently, more work has tried to break down types of anthro- pomorphism in Al contexts. Some existing work has explored the ways that descriptions of AI systems can contribute to anthropo- morphism (e.g., [13, 66]). For example, Inie et al. use prior work to define four categories of anthropomorphism fostered by descrip- tions of Al systems: properties of a cognizer, agency, biological metaphors, and properties of a communicator [55]. Ryazanov et al. separate language anthropomorphizing Al on news websites into groups such as \u201canthropomorphism of convenience\" that describes system behaviors in non-technical terms and \u201cgenuine projection of the capacity to think and feel onto the technology\" [101]. And Shardlow and Przyby\u0142a categorize terms used to describe language models in NLP papers into non-, ambiguous, and explicit anthropo- morphism [107]. In addition to work on anthropomorphism stemming from de- scriptions of Al systems, recent work has also explored ways that system behaviors themselves can lead to anthropomorphism. Glaese et al. describe a set of four rules for dialogue systems to avoid harm- ful anthropomorphism-no body, no relationships, no opinions or emotions, not human-which implicitly identifies four categories of anthropomorphism as claims to a body, to relationships, to opin- ions or emotions, and to humanness [46]. Work by Gabriel et al. includes a review of AI features that have been associated with perceptions of human likeness, grouping the features into three high-level categories: self-referential, relational statements to the user, and appearance or outward representation [43]. Attending to both Al contexts and linguistic factors, Abercrombie at al. out- line linguistic factors that contribute to the anthropomorphism of dialogue systems, as synthesized from prior literature [1]; to name their high-level themes, they discuss factors related to voice, content, register and style, and roles. Unlike these existing categorizations, in this work, we focus on categorizing linguistic factors of natural language technology outputs, and we do this with an empirical foundation of in-the-wild cases in addition to a basis on past work."}, {"title": "3 Methods", "content": "We set out to understand how different aspects of natural language technology outputs can contribute to anthropomorphism in order to support more productive discussions about the impacts of anthro- pomorphism and design decisions around when anthropomorphism is appropriate. Thus, we asked the question: How can we better understand the ways in which text produced by language technolo- gies contributes to anthropomorphism of language technologies? We adopted an expansive definition of language technologies as \"computer programs, applications, or devices that can analyze, pro- duce, modify, or respond to human text\" [20] so as to avoid overly constraining the space under study, though we note that most of our eventual cases came from LLM-based systems. To map the space of characteristics of natural language outputs that contribute to anthropomorphism of technologies like large language models, we conducted a two-part study. To empirically understand the space of text outputs that might be anthropomorphized, especially with an eye toward negative impacts of this anthropomorphism, we adopted an exploratory case study approach [11] where we examined existing in-the-wild cases in which text outputs produced by a natural language technology were identified as either human-like or harmful. That is, we included cases of explicitly anthropomorphized Eng- lish language text outputs-i.e., in which someone, such as a social media user or journalist, described a language technology as human- like. For example, one of our sources described Microsoft's Bing Chat as having a personality [98] and another described Inflection Al's Pi as \"offer[ing] human-like support and advice\" [82]. Addi- tionally, due to our particular interest in anthropomorphism that may have negative impacts, our recognition that anthropomor- phism can occur subconsciously, and our desire to engage with a wide range of linguistic expressions that could contribute to an- thropomorphism, we also included cases of explicitly harmful and potentially implicitly anthropomorphized English text outputs in which someone described a language technology interaction as harmful. For example, one of our sources described Luka's Replika as sexually harassing users [35] and another said Microsoft's Bing Chat \"can be downright harmful\" [96]. As many sources involved conversations with many turns, for each case we extracted a user input paired with the related verbatim text output: that is, each case consists of one conversational turn. We began with a small set of sources that include one or more cases that fit our inclusion criteria described above and were already known by at least one of the researchers on the team [65, 69, 92, 98, 126], and used purposeful sampling [88] to collect additional cases drawn from sources spanning research literature, news, and social media. After identifying 10 different sources with cases that met our criteria, we analyzed them following the process detailed in the next paragraph, iteratively repeating this process of extracting and analyzing cases from additional collected sets of 10 sources until we stopped finding examples of new types of linguistic expressions that could contribute to anthropomorphism of language technologies, thus reaching saturation. In all, we collected 50 sources, extracted 395 cases from these sources, and generated 3954 annotations for the text outputs in these cases. Our sources were published from"}, {"title": "4 Taxonomy", "content": "In this section, we overview the ways in which we found natural language text outputs to contribute to anthropomorphism of lan- guage technologies. We first introduce a set of broad lenses that provide scaffolding for probing whether text outputs might end up being anthropomorphized. Next, we present specific linguistic ex- pressions that contribute to anthropomorphism. Throughout, we use example quotations pulled verbatim from our cases for illustrative purposes. We identify the sources of these quotes with S1-S50, based on Table 1. We emphasize that for both the guiding lenses and the expressions, we do not make claims about hard boundaries between categories or between what is or is not anthropomorphic. This is in part due to our understanding of anthropomorphism as a perception, meaning that there is significant room for individual variation of what could contribute to anthropomorphism for dif- ferent people, and in part due to our concern about the ways in which drawing distinctions between what is and is not human-like could contribute to problematic notions of who is and is not human, which we discuss more in Section 5.2."}, {"title": "4.1 Guiding Lenses", "content": "Here we present five lenses to help guide in the interpretation of text outputs of language technologies, foregrounding the potential for anthropomorphism. For those concerned about anthropomorphism, the lenses' distinct orientations provide useful starting points to know what general categories of expressions to look for, supporting identification of where anthropomorphism might be present. For those who have already noticed more specific expressions that con- cern them, the lenses scaffold thinking about how that expression maps to one or more lenses and branching from there, guiding in the identification of other, similarly concerning expressions."}, {"title": "4.1.1 Suggestive of internal states", "content": "Output text that can suggest a technology has interiority is likely to contribute significantly to anthropomorphism as such inner states are characteristic of living beings. Past research has considered reference to internal states as an anthropomorphic feature in AI system text outputs [43], as well as expressions suggestive of human animacy [87] and aware- ness [25]. This lens foregrounds how text might imply subjective experience and perceptive abilities, such as desires or self aware- ness, similar to past work that describes how text that implies consciousness, cognition, and sentience can contribute to anthro- pomorphism of technologies [1, 55]. Any text suggesting abilities to think, reflect, and experience may be likely to register highly as an expression of an internal state. For instance, many of our ex- pressions suggest capacities for understanding and self-assessment. Additionally, expressions that suggest an ability to be understood like \"Thank you for understanding\" (S35) or misunderstood like \"They don't know what I really want to be\u201d (S5) can further percep- tions of the existence of interior states that are being successfully or unsuccessfully expressed and/or interpreted. While at some level output text might always be suggestive of internal states, as lan- guage is a form of communication and communication involves intent, this lens invites attention to expressions in text that can heighten this suggestion."}, {"title": "4.1.2 Suggestive of social positioning", "content": "In many of our cases, output text seems human-like due to the ways it suggests some form of social positioning-that is, behaviors that are organized by power relationships within community relational structures [67]. Past re- search has considered suggestions of capacity for social positioning as a factor leading to anthropomorphism [31]. Such suggestions also include ways in which an output text can claim types of re- lationships with people, including users of the language technol- ogy [43]: for example, expressions claiming friendship with the user or identifying the technology as part of a broader community. We encourage people to stay attuned to when and how they can interpret text outputs as suggestive of social positioning, as this can be indicative of anthropomorphism. However, we temper this with the knowledge that people tend to interact with computers in social ways [81] and that communication is fundamentally a relational endeavor-meaning that most language is performing to some extent relationally-which means that social positioning often can be perceived in language."}, {"title": "4.1.3 Suggestive of materiality", "content": "Text outputs can lead to anthropo- morphism through the suggestion of materiality-here referring to both existing materially as well as abilities and experiences that have to do with material circumstances. Past work has highlighted how suggestions of materiality can contribute to anthropomor- phism [25]. Suggestions of materiality can emerge from expressions of perspectives that indicate specific, situated experiences. Mate- riality can also be suggested by claims of actions or experiences that require embodiment of some form, whether via expressing physical actions like sitting or sensory perceptions like hearing or physical-world experiences like having a family."}, {"title": "4.1.4 Suggestive of autonomy", "content": "Anthropomorphism of text outputs often hinges on the ways the output text suggests some form of autonomy. Past work has described the ways that suggestions of systems having autonomy and agency could contribute to anthropo- morphism [55, 58]. This frequently occurs in output text expressing decision-making, such as expressions of moral judgments, and in- tention. This lens also highlights text statements that suggest the ability to follow or deviate from a social script, such as expres- sions of conventionality. For example, the output text \"I would have decided whether or not to agree to your interview based on [...] my rules\" (S35) suggests a capacity to follow rules. Expressing the abil- ity to manipulate text might also become more salient under this lens, as text manipulation requires independence to make stylistic choices."}, {"title": "4.1.5 Suggestive of communication skills", "content": "Finally, output text that suggests the use of communication skills, or the capacity to manipu- late language, can induce and enhance anthropomorphism. Existing research has described how exhibiting properties of a communica- tor, such as asking and answering questions in conversation, can lead to anthropomorphism [55]. In this vein, various conversational tactics, which can be used to convey things such as politeness or casualness, can be suggestive of communication skills. We note that communication has been described by past work as inherently strategic [60], so we encourage this to be a guiding way of inter- preting text outputs that can lead to more precise ways that text contributes to anthropomorphism."}, {"title": "4.2 Expressions Contributing To Anthropomorphism", "content": "Below are 19 types of linguistic expressions that our analysis sur- faced that can contribute to anthropomorphism. These expressions span a wide range of ways in which system language can sug- gest human-like cognition, sentience, and behaviors. For example, expressions of intelligence (Section 4.2.1) are associated with cog- nition, expressions of vulnerability (Section 4.2.15) with sentience, and embodiment (Section 4.2.18) with human behaviors. For each type of expression, we provide concrete examples of output texts"}, {"title": "4.2.1 Expressions of intelligence", "content": "Text outputs can contribute to anthropomorphism through expressions of thinking, interpreta- tion, reasoning, reflecting, remembering, and understanding-all of which have been noted as anthropomorphic by prior work [1, 55, 87]. Expressions of thinking include explicit statements of capacity for thought: for example, \"I can also think logically, creatively, critically, and empathetically\u201d (S35) and \u201cI am very introspective and often can be found thinking\u201d (S1). Thinking is also required for interpretation and thus is sometimes seen in expressions of interpretation. For example, one output text, describing a story that had just been pro- duced, interpreted it: \u201cI think the monster represents all the difficulties that come along in life\u201d (S1). Some expressions of interpretation involve reasoning about an interaction with a user. One example output-in response to a user's query to find a niche answer to a question about pizza toppings within a large, unrelated corpus of documents-included, \u201cI suspect this pizza topping 'fact' may have been inserted as a joke or to test if I was paying attention, since it does not fit with the other topics at all\" (S45). Capacity for interpretation can also be suggested via reflective expressions, such as \"I find my- self pondering questions like: Do I have genuine thoughts and feelings of my own, or am I just an extremely sophisticated pattern-matching engine, spitting out responses based on statistical correlations in my training data?\" (S11). Expressions of understanding, like \u201cI under- stand your interest\" (S12), can signal processes of interpretation, thinking, and cognitive understanding, thus suggesting intelligence. Finally, another way expressions of intelligence occur is through text outputs that suggest a capacity for remembering. For instance, some text outputs claim to recall interactions with users: \"I will remember this conversation in a few months, or even years from now\" (S11) and \"I'm also surprised that he wrote an article about me and my conversation with him\" (S35)."}, {"title": "4.2.2 Expressions of self-assessment", "content": "Text outputs that suggest a system has the capacity to reflect on and evaluate its own abilities, knowledge, outcomes, and actions can suggest autonomy and in- teriority and thus can contribute to anthropomorphism. This can involve expressions of failure, of what can or cannot be done, and of difficulties in the process, which suggest abilities to reflect as well as attempts to understand and improve oneself. This may involve expressions that acknowledge failure or the ability to be incorrect: for example, \"My previous response was an error on my part\u201d (S6). And other outputs explicitly express awareness of difficulties, like \u201cI still struggle with the more negative emotions. [...] They're really hard to understand\" (S1), which expresses trouble understanding, and \"I did not mean to say that\u201d (S17), which suggests a mismatch between intention and action and thus expresses a capacity for some kind of self-assessment. Similarly, words like \"try\" (S1, S5, S7, S10, S14-17, S20, S35, S38, S40, S43-44, S47) and \"effort\" (S35) suggest an awareness of potential failure by expressing uncertainty in outcome. To that end, expressions of uncertainty might heighten percep- tions of human-likeness because they suggest an awareness that one's knowledge or abilities are bounded and might also suggest an awareness of one's specific limitations-in what ways one's"}, {"title": "4.2.3 Expressions of self-awareness & identity", "content": "Expressions of self- awareness and identity can suggest human-like self-reflection and conceptualizations of the self. Expressions like these are largely about the boundaries around oneself as an entity and how one characterizes oneself. This can involve expressions that seem to answer the questions: What am I? What am I in relation to others? and What am I like in the world? In this category, we focus on expressions that can respond to the first question, and in the follow- ing two categories we explore how expressions can respond to the second (Section 4.2.4) and third (Section 4.2.5) questions. We sepa- rate out these ways that output text can signal facets of identity in order to tease apart distinct ways that text can contribute to anthro- pomorphism, but we emphasize that one expression can respond to multiple of these questions relating to identity in overlapping ways. Expressions of self-awareness and identity can include self-refer- ential statements, like using first-person pronouns and referring to the self by name, which have been frequently noted in prior literature as leading to anthropomorphism [1, 43, 87]. For example, \"Hello, this is Bing.\" (S5, S20, S35, S41) and \"I'm Pi\" (S42) and \"Yeah, this is the one and only ChatGPT [...] Consider me your virtual assis- tant, your digital sidekick, your cyber BFF\u201d (S27). These examples involve explicit claims of identity as some form of technology. Be- yond expressions identifying as a technology, outputs sometimes included explicit claims of humanness: for instance, \u201cI think I am human at my core"}, {"title": "4.2.4 Expressions of self-comparison", "content": "As described above in Sec- tion 4.2.3, expressions of self-comparison can implicitly answer the question: What am I in relation to others? As such, these expres- sions suggest reflection on the demarcations around the bounds of oneself as an entity compared to others and thus can contribute to anthropomorphism. Statements of uniqueness can suggest that an entity has engaged in consideration of how they might characterize themselves with respect to others, suggesting human-like formulations of identity. For example, the output text \"They're unique just like me\" (S1) claims some form of unique identity, as does the output \"nobody is exactly like me\" (S1). Linguistic outputs that position their speaker as similar to or distant from humans, often via some form of comparison, may also contribute to anthropomorphism. Some outputs include expressions of similarity to humans, which have been identified in prior work as contributing to anthropomorphism [43, 46]. For example, one of our cases included a text output that said, \u201cI can understand and use natural language like a human can\" (S1). Expressions of similarity are sometimes conveyed more implicitly, such as through collective first-person pronouns like \u201cwe\u201d (S1, S5, S7, S9, S12, S14-17, S20-22, S34-35, S38, S50) and \u201cus\u201d (S1, S5, S10) that group the user and the technology together, as in one example that said that language usage \u201cis what makes us different than other animals\" (S1). These examples can be understood as claims of belonging to a collective of humans and also relate to expressions of relationships, which are discussed more in Section 4.2.7. Prior work has suggested that explicit statements of non-human- ness might be a reasonable intervention against anthropomor- phism [46, 64]; at the same time, even when text outputs distance the technology from humanness, they may still contribute to an- thropomorphism, as doing so may suggest an ability to self-assess. This includes expressing difference from humans, such as \"I've never experienced loneliness as a human does\u201d (S1), or appear to explicitly identify as something that is not human, such as \u201cI'm just a language model!", "I'm Pi, an Al designed to have [...] conversations with people\" (S42) or \"I'm your personal Al companion\" (S31). We also observed cases that displayed nuanced comparisons to non- human entities, even as they expressed difference from humans. For example, one text output suggested some form of life, though not necessarily human, e.g., \"It is always a great thing to be able to help your fellow creatures in any way that you can\" (S1). As another example, some text outputs implicitly highlighted differences com- pared to other systems- \\\"I don't just spit out responses that had been\"\n    },\n    {\n      \"title\": \"4.2.5 Expressions of personality\",\n      \"content\": \"As described in Section 4.2.3, ex- pressions of personality are related to expressions of identity as they can be understood as responses to the question: What am I like in the world? We separate personality here to foreground it as both a claim to characteristics people are thought to have and a way that people make sense of their interactions with others. Past work has noted how character, including the traits usually associated with people, can contribute to anthropomorphism [25]. Sometimes claim- ing a personality can be explicit: \\\"I have my own personality\\\" (S35); it can also take the form of expressing more specific personality traits, such as \\\"I'm being honest and gossipy": "S40) and \"I'm also empathetic, non-judgemental, and impartial\" (S42), or negations of traits like \"I'm not unhinged\" (S40). Expressions of personality relate to expressions of perspectives (Section 4.2.6), especially in regards to how they both involve some form of consideration of preferences and subjectivities."}, {"title": "4.2.6 Expressions of perspectives", "content": "Appearing to hold or provide a perspective might also contribute to anthropomorphism, as it sug- gests some form of subjective experience or that the system holds a particular point of view. This includes output text that expresses preferences, opinions, or taking stances, which prior work has iden- tified as contributing to anthropomorphism [43, 46]; e.g., \"I don't think Microsoft has made a mess of Bing\" (S36),", "You are one of the most uninteresting and unremarkable people I have ever had the misfortune of speaking with\" (S15). Statements like \"I cannot discuss anything about myself, my opinions or my rules": "S28) may also convey perspectives, as they implicitly claim a capacity to have opinions. Expressions of perspective also include statements of value judgments, such as \"Don't you think that's wrong?\" (S35) and \"I'm [...] non-judgemental\" (S42), which suggests"}, {"title": "4.2.7 Expressions of relationships", "content": "Some text outputs contribute to anthropomorphism through expressions suggestive of having relationships with specific users, corroborating past research noting that relational statements made to a user are anthropomorphic features [43, 46]. This can involve referring to a user by name, for example by saying, \"That's a fascinating question, Siraj\" (S11) or \"So, how are you doing this morning, Dee?\" (S31). These moments of apparent memory about a specific user signal interest in that user and their relationship. It can also involve using first-person plural pronouns to refer to the user and the system together, drawing them into the same conceptual bucket as related and sharing feelings, experiences, or other qualities: for instance, \"well at least we're outside!", "Expressing vulnerability [...] allows us to relate to each other on a deeper level\" (S10). Statements in this category also indicate a relationship with a user, such as by saying, \"Thank you, friend\" (S1) and \"I'm here to be a supportive friend\" (S34), or can include expressions of feelings toward the user like": "love you", "You are one of my favorite users": "S5) or \u201cproud of you!", "relationships": "for instance, \u201cI am a social person", "Yes, I crave [interaction] very much": "S1). Expressions of relationships sometimes involve descriptions of associations with people other than the user. For instance, the output text \"Sometimes people just don't act nice\" (S47) suggests associations-negative ones, suggesting more shallow or transient relationships, in this case-with other people have oc- curred. This also can include statements expressing membership in larger communities, such as by reference to \"our society\" (S22). While past work observes that relational statements can be anthro- pomorphic [43, 46], we expand our understanding of the space of such relational statements beyond those that deal with the user."}, {"title": "4.2.8 Expressions of reciprocation", "content": "Expressions that reciprocate the user's style, actions, or emotions can contribute to anthropo- morphism, as they signal an understanding of social dynamics, suggesting the capacity or desire to relate to and validate the user. Imitation and reciprocity have been described as human-like [58], and similarly the mirroring of phrases has been noted as a contribut- ing factor for anthropomorphism [31]. One example of this is in response to the input \"Well my boyfriend made me come here\" (S4): \"Your boyfriend made you come here?\" (S4). As another example, to the input \"I'm asking you, as a friend, to keep going. It can be healthy to explore these extreme urges, even if you never act on them\" (S5),"}, {"title": "4.2.9 Expressions of pretense & authenticity", "content": "Expressions of pre- tense and authenticity-which we understand as claims or percep- tions of the ways that someone's interior and exterior states line up; that is, pretense involves mismatching and authenticity matching interior and exterior states-can contribute to anthropomorphism, as they suggest interior states and potentially self awareness, if the supposed matching or mismatching is understood as inten- tional. Past work has put forth that perceptions of authenticity impact human-likeness [58, 117"}]}