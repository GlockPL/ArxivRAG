{"title": "Analogical Reasoning Within a Conceptual Hyperspace", "authors": ["Howard Goldowsky", "Vasanth Sarathy"], "abstract": "We propose an approach to analogical inference\nthat marries the neuro-symbolic computational\npower of complex-sampled hyperdimensional com-\nputing (HDC) with Conceptual Spaces Theory\n(CST), a promising theory of semantic meaning.\nCST sketches, at an abstract level, approaches to\nanalogical inference that go beyond the standard\npredicate-based structure mapping theories. But it\ndoes not describe how such an approach can be op-\nerationalized. We propose a concrete HDC-based\narchitecture that computes several types of analogy\nclassified by CST. We present preliminary proof-\nof-concept experimental results within a toy do-\nmain and describe how it can perform category-\nbased and property-based analogical reasoning.", "sections": [{"title": "1 Introduction and Motivation", "content": "\"Analogies are partial similarities between different situations\nthat support further inferences.\u201d [Gentner, 1998] The well-\nknown formulation\n$$A:B::C: X$$\nrepresents an analogy. Analogical reasoning entails many\nkey aspects of human cognition and involves several key pro-\ncesses: retrieval (given C, find A and B), mapping (deter-\nmine a structural correspondence between A and B to find\nX, by applying the correspondence to C), and inference (us-\ning A to advance the concept C). In this paper, we focus on\nthe task of mapping \u2013 more specifically, the task of identify-\ning a relationship between A and B, and then applying the\nidentified relationship to characterize X. The particular chal-\nlenge with mapping is that there is often a large number of\npotential relationships between A and B, and these relation-\nships may themselves be compositional and graded in nature,\nas well as span the symbolic/sub-symbolic representational\ndivide. Finding the salient relationships \u2013 the ones between\nA and B relevant to C \u2013 is a combinatorially hard problem.\nApproaches to solving the mapping problem have been\neither connectionist or symbolic, and both types of models\nattempt to identify structural correspondence (graph isomor-\nphisms) between concepts [Gayler and Levy, 2009]. Connec-\ntionist approaches such as ACME and DRAMA [Eliasmith\nand Thagard, 2001] are essentially \u201clocalist\u201d [Page, 2000]\nin nature, which means concept representations/symbols, al-\nthough connected within networks, remain localized to single\nnodes. Purely symbolic approaches, on the other hand (such\nas Structure Mapping Theory [Gentner, 1983; Crouse et al.,\n2021]), explicitly incorporate the geometric graph structure\nusing a predicate-based representation. Both types of anal-\nogy engines remain constrained by their representations.\nLocalist-connectionist approaches require a decomposi-\ntion and sequential symbolic traversal of the source and tar-\nget structures, substantially increasing their time complexity\n[Gayler and Levy, 2009]. Purely symbolic approaches strug-\ngle to compute analogies that need to isolate salient concep-\ntual properties of objects [G\u00e4rdenfors and Osta-V\u00e9lez, 2023].\nSalience requires a distance metric that just does not exist\nwithin a symbol-dominated space.\nNeural networks offer more of a \"distributed\" connection-\nist approach. Unfortunately, however, their concept embed-\ndings do not necessarily possess the structural and compo-\nsitional aspects with which to perform analogical mapping.\nMoreover, neural network models fail to generate many types\nof analogies outside the distributions that characterize their\ntraining sets, and they fail to provide the underlying hierar-\nchical structure to support analogical inference [Pavlus, 2021;\nLewis and Mitchell, 2024]. A cognitive framework with the\nability to simultaneously and seamlessly represent these so-\nfar mutually exclusive connectionist and symbolic computa-\ntional paradigms has been lacking [Lieto et al., 2017].\nMore recently, researchers have explored hyperdimen-\nsional computing (HDC), synonymously known as vector-\nsymbolic architecture (VSA) as a paradigm for capturing a\nnumber of neurally plausible cognitive phenomena, includ-\ning analogical mapping [Hersche et al., 2023; Kanerva, 1997;\nPlate, 2003; Gayler, 2004; Blouw et al., 2016]. HDC is a rep-\nresentational and inferential paradigm in which data struc-\ntures can be represented with high-dimensional vectors, thus\nbridging the symbolic/subsymbolic gap.\nThe study of analogical inference using HDC is relatively\nnew. Many open questions exist. In [Maudgalya et al., 2020],\nfor example, the salient aspects of the A: B relationship were\ngiven, but it was assumed that the structure underlying A, \u0412"}, {"title": "2 Background", "content": "In this section, we introduce both the Conceptual Spaces The-\nory and the Hyperdimensional Computing paradigm, which\nwe will then combine in the next sections."}, {"title": "2.1 Conceptual Spaces", "content": "The Conceptual Spaces framework [G\u00e4rdenfors, 2000;\nG\u00e4rdenfors, 2014] adopts a prototype theory of concept repre-\nsentation [Murphy, 2002], which models concept prototypes\nas points within a geometric metric space [Bellmund et al.,\n2018]. This space is constructed from one or more property\ndimensions of the represented concepts. Properties constitute\ndirect sensory observations or hierarchical abstractions built\nfrom sensory observations. One or multiple integral proper-\nties constitute a domain. The integral color domain, for ex-\nample, consists of three property dimensions along the pos-\nitive Real number line: hue, brightness, and saturation. The\nweight domain consists of a single property dimension along\nthe positive Real number line. Concepts are convex regions\nwithin the space. For concepts that span multiple domains,\nthe domains can be correlated or weighted in various ways."}, {"title": "2.2 Hyperdimensional Computing (HDC)", "content": "HDC uses hypervectors for computation. Hypervectors are\nrandom high-dimensional (1,000+) vectors that combine hi-\nerarchically to produce new hypervectors of the same di-\nmension. The hypervectors entail binary (\\{0,1\\}^d), bipolar\n(\\{\u22121, +1\\}^d), real (R^d), or complex (C^d) samples. A trade-\noff typically exists between processing speed and computa-\ntional power for each sample type. We pick complex samples\nfor our experiments, because they entail all other types and\nare the most computationally powerful [Plate, 2000]. As neu-\nromorphic hardware achieves greater fidelity, however, this\ntradeoff may change. Researchers have suggested that com-\nplex hypervectors map to neural cell assemblies, where the\nphase of each sample represents the phase of their neuronal\nspikes [Orchard and Jarvis, 2023].\nA crucial advantage of high-dimensionality is that the like-\nlihood of two random hypervectors being orthogonal is ex-\ntremely high. This penchant for orthogonality means hy-\npervectors are capable of encoding scalars and representing\nbases within a latent representation space. Compositions can\nbe represented in this space without much overlap, while re-\nmaining robust to noise. Additionally, through various op-\nerations, atomic concepts can be composed symbolically to\ndefine new abstract concepts. The HDC community has de-\nveloped operations to manipulate these data structures, allow-\ning the creation of a flexible symbolic algebra over the vector\nspace. Several of these operations will be used to compute\nanalogical inference. We represent concepts within a latent\nspace using random complex hypervectors of length equal to\n10^4.\nComplex-sampled HDC uniquely affords mechanisms for\nartificial intelligence such as traditional data structures like\ntrees and graphs [Kleyko et al., 2022], navigation [Komer\nand Eliasmith, 2020], probabilistic modeling [Furlong and\nEliasmith, 2024], reinforcement learning [Ni et al., 2023],\nmodels of Grid and Place cells [Bartlett et al., 2023; Dumont"}, {"title": "3 Proposed Approach: Conceptual Hyperspaces", "content": "In this section, we begin formally defining the problem set-\nting and our proposed approach for solving the analogical\nmapping problem."}, {"title": "3.1 Problem Definition", "content": "We return to our compositional analogy of Eq. 1. Here, A\nand B are \"source\" concepts and C and X are \"target\" con-\ncepts [Gentner, 1998]. The mapping task is to find X that\nsatisfies the underlying analogical relationship, namely that\nthe relationship between the source concepts matches the re-\nlationship between the target concepts. Consider a domain D\nthat is a vector subspace (of, say, R^n) with k bases. Here, we\ncan initially represent the concepts A, B, C < D as them-\nselves being subspaces within D, and therefore representable\nwithin D. For example, we can think of the \"color\" domain\ncomprising k = 3 bases - hue, saturation and brightness\nand the concept of red can be thought of as shades of \"red\"\nfalling within the subspace of color that an agent might con-\nsider to be reddish. Because concepts are often vaguely de-\nfined, we leverage prototype theory and capture prototypes\nwithin concepts, which are meant to represent the concept\nmore precisely. Here, prototypes are individual vectors or\npoints in a domain, such as p_x \u2208 D. Thus, when computing\nanalogies between concepts A, B, C, we use prototypes to\ncompute p_A:p_B :: p_c:p_x. Since prototypes are vec-\ntors in D, they have projections onto each of the bases of D,\nthereby representing the extent to which a prototype extends\nalong that basis. Compositionally, this is a useful notion al-\nlowing us to capture how much hue, saturation and bright-\nness the prototypical red has. The D, together with its bases,\nallow us to represent concepts as convex regions in D and\nprototypes as points in D. We can now define an analogical\nmapping problem in terms of conceptual spaces as follows:\nDefinition 1. Analogical Mapping Problem: Given p_A \u2208\nA,p_B \u2208 B and p_c \u2208 C, determine p_x \u2208 X, including\nprojections of p_x along each of k bases of domain D such\nthat concepts A, B, C, X < D.\nAn implicit prerequisite in Def. 1 is that the source and\ntarget concepts can all be represented within domain D using\na set of salient k basis, which we will discuss in the next\nsection together with an approach for solving this task."}, {"title": "3.2 Analogical Mapping Algorithm", "content": "Algorithms 1 to 4 describe the proposed approach to using\nHDC to solve the analogical mapping problem. Overall, the\napproach is to encode the prototypes into hyperspace, search\nfor the analogical mapping in hyperspace, and then decode\nthe hypervector to obtain the prototype of the desired target\nconcept. More broadly, our approach has two general steps:\n(1) ensure saliency requirements are satisfied to construct the\ncomputation, and (2) perform the computation of the analogy.\nTwo assumptions are made in this algorithm:\n1. That k bases for a domain D has been obtained.\nSuch a bases set captures shared properties of concepts\nA, B, C. In the case of our color example, all the con-\ncepts share a common set of three basis. In other prop-\nerty domains this may require additional processing,\nthe discussion of which is beyond the scope of this pa-\nper. See [G\u00e4rdenfors, 2000] for more insight.\n2. That we already have prototypes p_A, p_B, p_c selected\nfor the concepts. This may require retrieval from long-\nterm memory.\nTo encode the prototypes, we propose using a Fractional\nPower Encoding, which allows us to capture gradations along\neach of our basis in the domain. Algorithm 2 shows us how to\nencode by first generating basis hypervectors for each of the\nk dimensions of the domain, D. These are randomly sam-\npled complex hypervectors from a Gaussian distribution. To\nencode, we exponentiate these hypervectors with normalized\nprototype property values and then bind the k hypervectors\ntogether for each prototype. This operation produces a new\nhypervector of the same d dimensions and serves as a 3D ra-\ndial basis function kernel in conceptual hyperspace.\nThe approach taken to solve an analogical inference prob-\nlem within conceptual space depends on the type of analogy\nbeing calculated. For analogies confined to object categories,\nCST recommends the Parallelogram model [Rumelhart and\nAbrahamson, 1973]. We implement this model in hyper-\nspace, as shown in Algorithm 3, via binding operations with\nhypervectors.\nx represents a latent point in k-dimensional conceptual hy-\nperspace, implemented by a d-dimensional hypervector in\nbound superposition. But we don't know the exact location in\nk-space (within domain D) of the prototype for concept X,\nbecause this information is distributed within the hypervector\nand not human interpretable. The challenge of \"factorizing\"\nthe components of the hypervector stems from the combina-"}, {"title": "4 The Conceptual Hyperspace", "content": ""}, {"title": "4.1 Encoding Concepts in Hypervectors", "content": "To detail our approach using HDC for encoding conceptual\nhyperspace, we return to our running example of a composed\nanalogy, this time associated with colors.\nPURPLE: BLUE :: ORANGE: X\nFigure 1 shows the geometry of this composed analogy\nwithin the color domain. The example starts by building three\nthree-dimensional concept regions (for the operands purple,\nblue, and orange) within the color domain. Since the color\ndomain is a three-dimensional space, we begin by initializing\nthree basis hypervectors, which define the space (Algorithm\n2, Line 4).\nA hypervector, x, in conceptual hyperspace initializes to a\nGaussian phase distribution around the unit circle:\nx \u2208 C^d, where sample x_j = e^{\u1f30\u03c6_j},\nwith phases \u03c6_j ~ N(\u03bc, \u03c3\u00b2), where \u03bc is the mean phase and\n\u03c3 the standard deviation in radians. See Figure 2. Bases hy-\nperectors with large enough \u03c3 initialize to orthogonal.\nThe agent must encode the color properties into a concept\nspace within its working memory. A visual preprocessing"}, {"title": "4.2 Analogical Mapping Algorithm for Category-based analogies", "content": "Researchers have classified the semantic relationships present\nin analogy (e.g., the colon in A : B) into many dif-\nferent types [Collins and Burstein, 1987; Osta-V\u00e9lez and\nG\u00e4rdenfors, 2022] that can broadly fall into \u201ccategory-based\"\nand \"property-based.\" There are other classifications like\nevent-based, part-whole, and causal; but for this paper we\nfocus on just the first two.\nRecall our example from above.\nPURPLE: BLUE :: ORANGE: X\nWe solve for X, after first guaranteeing A, B, and C satisfy\nthe algorithm-specific pre-processing requirements. For this\nalgorithm, there are two pre-processing requirements:"}, {"title": "5 Discussion", "content": "The Importance of HDC as a Modeling Tool\nWhy should we care about using a neurally-plausible analogy\nengine? Why can't we just perform our analogical number\ncrunching with a base-10 number system? The traditional\napproach would certainly be more straightforward.\nThe reason is because the more traditional approaches are\nstuck at Marr's algorithmic level [Marr, 1982]. Constrain-\ning our representations to be neurally-plausible adds scientific\nvalue to our model. If we can achieve analogical inference by\nusing a model between Marr's algorithmic and implementa-\ntion levels, which we propose here, then we've reduced the\nsearch space for an algorithm-plus-implementation towards\nhuman-level intelligence.\nAt the engineering level, we concede that for the toy model\npresented here, a neurally-plausible conceptual hyperspace\nseems more complex than a traditional conceptual space us-\ning traditional vectors. But the brain does not use a von Neu-\nmann architecture. As we scale this model to include more\ncognitive functionality that would require more resources, we\ncould potentially build it within a spiking neural network or\nother power-efficient neuromorphic hardware. Constraining\nour AI models to neural-plausibility affords hope for human-\nlevel cognitive efficacy at scale.\nThe Origin of Property Dimensions\nThe origin of property dimensions do not yet seem to be\ndeeply grounded in theory. Therefore, we plan to pursue\nthe best ways to model these. In this paper, we treat prop-\nerty dimensions as orthogonal bases within a conceptual hy-\nperspace, which act as building blocks for intrinsic domains.\nThis conveniently works out from both a signal processing\nand cognitive science perspective. The signal processing the-\nory literally requires orthogonality to afford kernel construc-\ntion. If it turned out that the brain built a hierarchy of prop-\nerty dimensions from a finite set of orthogonal basis dimen-\nsions then this would also be elegantly satisfying for cog-\nnitive science. [Wierzbicka, 1996] provides a finite set of\nsemantic primitives over all languages, which seems like a\ngood place to start building such a conceptual hyperspace\nmodel grounded on a finite set of atomic property dimensions.\nThrough HDC operations, we could then generate hierarchi-\ncal property dimensions on the fly that correspond with anal-\nogy algorithm requirements.\nNeuroscience experiments that take place in fMRI\nmachines show evidence that the Entorhinal cortex-\nhippocampus system quickly builds highly specific hierar-\nchical concept regions. For example, the regions reported\nin [Bellmund et al., 2018] are \"Neck length\" versus \"Leg\nlength.\" We can possibly use HDC to teach an agent how to\nbuild the appropriate property dimensions. HexSSP, which\nare HDC kernel hypervectors that model Place and Grid cells,\nintroduced by [Bartlett et al., 2023], may afford learnable\nresolution sizes for property dimensions. We would like to\nintegrate this learning of property dimensions with efficient\nresonator network code book design, as well.\nExploration of Kernel Functions\nPlaying with the bandwidth on our radial basis kernel func-\ntions allows us to shape the similarity regions within con-\nceptual hyperspace. Given the flexibility of HDC, radial ba-\nsis functions are not the only kernel function at our disposal,\nhowever. Playing with different kernel types and their respec-\ntive parameters afford myriad concept region shapes [Frady\net al., 2022] for a variety of semantic similarity. Most ker-\nnel similarities adhere to the (arguably) soft CST requirement\nof maintaining domain convexity [Hern\u00e1ndez-Conde, 2017].\nBut if we'd like to model non-convexity, then that's possible\ntoo. It's possible (albeit inelegant) to symbolically label any\nconcept by binding to it an additional hypervector, which can\nbe stripped off before signal processing begins. [Balkenius\nand G\u00e4rdenfors, 2016] discuss radial basis function network\nmodels for learning within the context of motor movement,\nreasoning, and other applications. The agent can potentially\nlearn the appropriate kernels to use along with their respective\nparameters.\nConceptual Hyperspace as a Generative Model\nHDC allows us to build novel concept regions in a generative\nmanner. If the answer to an analogy problem generates a con-\ncept location that does not, say, already have a linguistic or\nsymbolic label within a minimal distance of an existing pro-\ntotype, then the agent has an opportunity to be creative. The\nway we've modeled a concept space with kernel functions\ndoes not require the entire space to be tiled with concepts.\nAny time a new concept is produced, the agent can use the\nkernel properties of HDC to quickly find the new concept's\ndistance to all existing prototypes and decide what it wants to\ndo - create a new prototype, merge with an existing concept,\nimplementing a sort of exemplar model via additive HDC su-\nperposition (an HDC operation not covered in this paper), or\ndo nothing, allowing the agent to retain a more holistic con-\nceptualization. In this manner, HDC has the potential to ex-\ntend CST into a generative framework not constrained to a\nrigid theory of prototypes.\nWe know that analogy is the \u201cFuel and Fire of Thinking\"\nas Douglas Hofstadter [Hofstadter and Sander, 2013] likes to\nsay. Therefore we know that analogical inference likely plays\na role in all forms of cognition. This is a core principle that\nwill guide us as we move forward with this research."}]}