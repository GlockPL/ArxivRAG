{"title": "OODFace: Benchmarking Robustness of Face Recognition under Common Corruptions and Appearance Variations", "authors": ["Caixin Kang", "Yubo Chen", "Shouwei Ruan", "Shiji Zhao", "Ruochen Zhang", "Jiayi Wang", "Shan Fu", "Xingxing Wei"], "abstract": "With the rise of deep learning, facial recognition technology has seen extensive research and rapid development. Although facial recognition is considered a mature technology, we find that existing open-source models and commercial algorithms lack robustness in certain real-world Out-of-Distribution (OOD) scenarios, raising concerns about the reliability of these systems. In this paper, we introduce OODFace, which explores the OOD challenges faced by facial recognition models from two perspectives: common corruptions and appearance variations. We systematically design 30 OOD scenarios across 9 major categories tailored for facial recognition. By simulating these challenges on public datasets, we establish three robustness benchmarks: LFW-C/V, CFP-FP-C/V, and YTF-C/V. We then conduct extensive experiments on 19 different facial recognition models and 3 commercial APIs, along with extended experiments on face masks, Vision-Language Models (VLMs), and defense strategies to assess their robustness. Based on the results, we draw several key insights, highlighting the vulnerability of facial recognition systems to OOD data and suggesting possible solutions. Additionally, we offer a unified toolkit that includes all corruption and variation types, easily extendable to other datasets. We hope that our benchmarks and findings can provide guidance for future improvements in facial recognition model robustness.", "sections": [{"title": "1. Introduction", "content": "In recent years, the rise of deep learning has significantly advanced facial recognition (FR) technology, leading to extensive research and rapid development worldwide. Innovations in loss functions such as SphereFace [30], CosFace [47] and ArcFace [10], have greatly enhanced the efficiency of FR models, achieving unprecedented accuracy under standard conditions. Additionally, the release\nIn real-life scenarios, users still encounter issues, such as failing to unlock apartment access during snowy weather or unsuccessful facial recognition for apps that have not been used for a while [2]. To explore the causes, we conduct a simple experiment by adding light Gaussian noise to facial images (potentially introduced during data processing or transmission), as shown in Fig. 1. Although humans can easily recognize the person in both images, we find that state-of-the-art open-source models [9] and the commer-"}, {"title": "2. Related Work", "content": "2.1. Face Recognition\nFacial recognition, a key task in computer vision, has made significant progress in recent years. Early models like DeepFace [44] and FaceNet [41] were the first to demonstrate the power of deep learning for FR tasks. Later, models such as SphereFace [30], CosFace [47], and ArcFace [10], which leverage angular margin-based loss functions, further enhanced feature discriminability. AdaFace [23] introduced an adaptive margin function to"}, {"title": "3. OOD in Face Recognition", "content": "We introduce the categories of common corruptions and appearance variations in Sec. 3.1 and Sec. 3.2, respectively, and provide implementation details in Appendix. A.\n3.1. Common Corruptions\nReal-world corruptions in FR arise from diverse application scenarios. Based on this, we classify corruptions into five categories: Lighting & Weather, Sensor, Movement, Data & Processing, and Occlusion. Considering the varied environments of FR applications, we identify 20 distinct types of corruptions across these categories, as illustrated in Fig. 2. We visualize examples of these corruptions in Fig. 3.\nLighting & Weather: Changes in lighting conditions and complex weather are common in FR scenarios, such as variations in daylight, indoor/outdoor lighting, or adverse weather like fog and snow [2]. These conditions can reduce image clarity, blur facial features, or introduce partial occlusions. We categorize these as brightness, contrast, saturation, fog, and snow. Image enhancement techniques [20] are used to simulate realistic weather and lighting effects.\nSensor: Sensors can suffer from internal or external disturbances (e.g., sensor vibrations, lighting conditions [20, 27], reflective surfaces), causing data degradation. Based on prior studies on sensor noise [12, 20], we design three realistic sensor-level corruptions: defocus blur, color shift, and pixelation. Defocus blur simulates the effect of an out-of-focus lens. Color shift alters the overall hue of the image, mimicking color bias due to sensor issues or ambient lighting. Pixelation reduces image detail by compressing it into larger pixel blocks, obscuring facial features."}, {"title": "4. OOD Benchmarks", "content": "To thoroughly evaluate the robustness of FR models, we establish multiple robustness benchmarks using widely adopted datasets: LFW [22], CFP-FP [42], and YTF [49]. For each dataset, we create two benchmark versions: one for common corruptions (denoted as LFW-C, CFP-C, YTF-C) and one for appearance variations (denoted as LFW-V, CFP-V, YTF-V). Additionally, we offer a unified toolkit that includes all corruptions and variations, easily extendable to other datasets. Below, we detail the datasets, evaluation metrics, and FR models used in our benchmarks.\n4.1. LFW-C/V\nWe first conduct experiments using the LFW [22] dataset, a widely used benchmark in FR. LFW consists of 5,749 identities and 13,233 images, forming 6,000 pairs of face images. We preprocess the entire LFW dataset using MTCNN [54], obtaining aligned images. We then apply 20 types of common corruptions and 10 types of appearance variations. Each includes five levels of severity [20].\nCommon Corruption Dataset LFW-C. We design LFW-C, a version of the LFW dataset that incorporates common corruptions, to comprehensively evaluate the robustness of FR models under various types and severities of corruption. For each model, we first obtain its performance on the original LFW dataset, denoted as $Acc_{clean}$. We then re-evaluate the model's performance under each corruption type c and severity level s in LFW-C, denoted as $Acc_{c,s}$.\nWe calculate the average corruption robustness among 5 severity levels of the model using the following formula:\n$ACC_{cor} = \\frac{1}{|C|} \\sum_{c \\in C} \\frac{1}{5} \\sum_{s=1}^{5} ACCC,$\nwhere c represents all corruption types. To further analyze the degradation of the model under each corruption, we introduce the Relative Corruption Error (RCE), which measures the percentage decrease in performance as follows:\n$RCE_{C,S} = \\frac{Acc_{clean} - Acc_{c,s}}{Acc_{clean}}; RCE = \\frac{Acc_{clean} - Acc_{cor}}{Acc_{clean}}$\nAppearance Variations Dataset LFW-V. We also design LFW-V, an appearance editing version of the LFW. Similarly, for the LFW-V, we first obtain the $Acc_{clean}$ and then evaluate the model's performance under each variation category v and severity level s, denoted as $Acc_{v,s}$.\nWe calculate the average robustness of appearance variations for the model using the following equation:\n$Acc_{var} = \\frac{1}{|V|} \\sum_{v \\in V} \\sum_{s=1}^{5} Acc_{v,s}$\nwhere v represents all appearance variations. To further analyze the performance variation of the model under each appearance variations condition, we introduce the Relative Variations Error (RVE), which measures the percentage decrease in performance as follows:\n$RVE_{v,s} = \\frac{Acc_{clean} - Acc_{v,s}}{Acc_{clean}}; RVE = \\frac{Acc_{clean} - Acc_{var}}{Acc_{clean}}$\n4.2. CFP-C/V\nThe CFP (Celebrities in Frontal-Profile) [42] dataset consists of frontal and profile images of celebrities. It includes clear frontal and side-view face images, with a total of 500 identities and 7,000 pairs. Following a similar procedure as LFW, we first align all images using MTCNN [54], then apply designed 20 types of common corruptions and 10 types of appearance variations."}, {"title": "5. Benchmarking Results and Insights", "content": "We present the evaluation results on LFW-C in Sec. 5.1, and LFW-V in Sec. 5.2, and leave the results on CFP-C/V and YTF-C/V in Appendix C and Appendix D. In Sec. 5.3, we discuss commercial API evaluation, followed by ex-5.1. Common Corruptions Evaluation Results\nTab. 2 shows the robustness evaluation of 19 FR models on LFW-C, categorized into Open-source Model Eval, Architecture Eval, and Loss Function Eval. We report the average performance across five levels for each category. It is evident that natural robustness does not strongly correlate with $Acc_{clean}$. For example, models with high $Acc_{clean}$ (e.g., TopoFR [9]) does not achieve the high $Acc_{cor}$. In Fig. 5, we further illustrate the Relative Corruption Error (RCE) for each model across different corruption categories. Based on these evaluations, we provide the following analysis:\nComparison of Corruption Types. As shown in Tab. 2 and Fig. 5, all corruption types lead to performance degradation in FR models. Among these, Data & Processing has the highest RCE exceeding 20%. Additionally, Occlusion causes substantial performance drops, likely due to the loss of key facial features. On the other hand, most models exhibit negligible degradation under Sensor Corruptions (e.g., color shift, defocus blur), possibly because these corruptions are partially present in natural face datasets.\n5.2. Appearance Variations Evaluation Results\nTab. 3 presents the variation robustness evaluation of 19 FR models on LFW-V. Overall, the impact of appearance variations is smaller than that of corruptions. Unlike corruptions, robustness against appearance variations is largely correlated with the model's clean accuracy, consistent with observations in [12, 20]. In Fig. 6, we further illustrate the5.3. Commercial API Evaluation Results\nWe evaluate the robustness of three commercial FR services (Aliyun, iFLYTEK, and Tencent) on LFW-C and LFW-V. The underlying mechanisms and training data of these APIs are entirely unknown to us. We follow their original threshold ranges and determine the optimal threshold for each dataset. The results are shown in Tab. 4 and Tab. 5.\n5.4. Extended Experiments on Face Masks\nIn the field of FR, face masks typically refer to physical disguises used to deceive or obscure the identity of the wearer, preventing the system from accurately recognizing the individual [55]. Masks can replicate the appearance of a real face, thereby bypassing the system's security measures. As an extension, we conduct physical experiments on masks, creating five different types made from various materials, as shown in Fig. 7. In the experiments, we first test whether the masks could be correctly identified, and then further explore the impact of corruptions and variations on recognition. Our findings indicate that masks are also affected by OOD scenarios, exhibiting a different category of performance degradation compared to real faces. We provide additional experimental data and further analysis in Appendix E, along with details of the mask fabrication process."}, {"title": "5.5. Extended Experiments on VLMs", "content": "To explore better solutions for OOD scenarios in FR, we investigate the use of Vision-Language Models (VLMs) for FR, a previously unexplored approach. As shown in Fig. 8, we find that GPT-4o-mini [1] demonstrates robust FR capabilities and can identify specific types of corruption present in the images, suggesting that VLMs could be a solution to the challenge of OOD data.\n5.6. Extended Experiments on Potential Defenses\nWe further explore potential defenses for improving robustness in Appendix F. Following [52], we test 10 robust models using input transformation such as R&P [50], Bit-Red [51], and adversarial training such as PGD-AT [32], TRADES [53]. However, the improvements are limited."}, {"title": "6. Conclusion", "content": "In this paper, we introduce OODFace, a comprehensive benchmark for OOD robustness in FR, systematically designed with 20 common corruptions across 5 categories and 10 appearance variations across 4 categories. By augmenting public datasets, we establish three robustness benchmarks: LFW-C/V, CFP-FP-C/V, and YTF-C/V. We conduct extensive evaluations on 19 FR models and 3 commercial APIs, along with additional experiments towards face"}, {"title": "A. More Details of OOD Scenarios", "content": "A.1. Implementation Details of Corruptions\nFirst, we describe the implementation details and hyperparameters of 20 common corruptions used in the LFW-C, CFP-C, and YTF-C benchmarks. Note that each corruption is evaluated at five severity levels, with specific hyperparameter configurations corresponding to each level.\nGaussian Noise. Gaussian noise simulates sensor noise by adding random values with a normal distribution to the image. The noise intensity is controlled by the standard deviation, with five levels of severity: {0.08, 0.12, 0.18, 0.26, 0.38}. Noise is added to each pixel, creating effects of varying intensities. We implement this using imagecorruptions [3] library, simulating different levels of Gaussian noise with predefined severities {1, 2, 3, 4, 5}.\nShot Noise. Shot noise simulates photon counting noise that occurs during image capture, particularly noticeable under low-light conditions. The intensity depends on the noise amplitude and the illumination level of the image. Severity levels are set as {60, 25, 12, 5, 3}, with higher levels introducing noticeable random brightness variations. We implement this using imagecorruptions [3] library, with severities {1, 2, 3, 4, 5}.\nImpulse Noise. Impulse noise replaces random pixel values with extremes (e.g., 0 or 255) to simulate transmission errors in images. The intensity of the noise is determined by its density, with levels {0.03, 0.06, 0.09, 0.17, 0.27}. Higher noise density results in more black-and-white speckles. We implement this using imagecorruptions [3] library, with severities {1, 2, 3, 4, 5}.\nSpeckle Noise. Speckle noise simulates multiplicative noise caused by scattering, adding random values to each pixel. Noise intensity is controlled by levels {0.15, 0.2, 0.35, 0.45, 0.6}. As the intensity increases, the image becomes blurrier and the speckles more pronounced. We implement this using imagecorruptions [3] library, with severities {1, 2, 3, 4, 5}.\nDefocus Blur. Defocus blur simulates the effect of misfocused cameras, with the degree of blur controlled by the focal radius. Severity levels {1, 2, 3, 4, 5} correspond to different blur radii: level 1 uses a radius of 3, level 2 uses 4, level 3 uses 6, level 4 uses 8, and level 5 uses 10. Alias blur parameters range from 0.1 to 0.5 for each level. We implement this using imagecorruptions [3] library to simulate defocus blur with predefined severity levels.\nMotion Blur. Motion blur simulates the relative move-A.2. Appearance Variations Implementation Details\nNext, we present the implementation details and hyperparameters for the 10 appearance variations across the three benchmarks: LFW-V, CFP-V, and YTF-V. Additionally, each corruption has five severity levels.\nAge-. Age reduction is an important factor in facial changes, as facial features undergo noticeable alterations with age, such as changes in skin texture, sagging, wrinkles, and overall facial structure. We simulate facial rejuvenation using a generative model, which reduces signs of aging, making the face appear younger. The age reduction levels consist of five stages, ranging from mild to significant rejuvenation. The higher the level, the more pronounced the reduction in aging signs. We implement this using the PTI [39] algorithm."}]}