{"title": "Neural Port-Hamiltonian Differential Algebraic Equations for Compositional Learning of Electrical Networks", "authors": ["Cyrus Neary", "Nathan Tsao", "Ufuk Topcu"], "abstract": "We develop compositional learning algorithms for coupled dynamical systems. While deep learning has proven effective at modeling complex relationships from data, compositional couplings between system components typically introduce algebraic constraints on state variables, posing challenges to many existing data-driven approaches to modeling dynamical systems. Towards developing deep learning models for constrained dynamical systems, we introduce neural port-Hamiltonian differential algebraic equations (N-PHDAEs), which use neural networks to parametrize unknown terms in both the differential and algebraic components of a port-Hamiltonian DAE. To train these models, we propose an algorithm that uses automatic differentiation to perform index reduction, automatically transforming the neural DAE into an equivalent system of neural ordinary differential equations (N-ODEs), for which established model inference and backpropagation methods exist. The proposed compositional modeling framework and learning algorithms may be applied broadly to learn control-oriented models of dynamical systems in a variety of application areas, however, in this work, we focus on their application to the modeling of electrical networks. Experiments simulating the dynamics of nonlinear circuits exemplify the benefits of our approach: the proposed N-PHDAE model achieves an order of magnitude improvement in prediction accuracy and constraint satisfaction when compared to a baseline N-ODE over long prediction time horizons. We also validate the compositional capabilities of our approach through experiments on a simulated D.C. microgrid: we train individual N-PHDAE models for separate grid components, before coupling them to accurately predict the behavior of larger-scale networks.", "sections": [{"title": "1. Introduction", "content": "Many physical systems, such as electrical networks, chemical reaction networks, and multi-body mechanical systems, comprise many interacting subsystems. Such systems not only exhibit complex dynamics, but are often subject to algebraic constraints that enforce compositional relationships between the subsystems (e.g., energy balance, conservation laws, or geometric couplings).\nDeep learning methods that use physics-inspired architectures and training losses have shown promise in learning data-efficient models of unconstrained dynamical systems (Raissi et al., 2019; Chen et al., 2018; Djeumou et al., 2022, 2023). However, such methods are currently unable to learn models that respect the aforementioned algebraic constraints. This limitation renders compositional"}, {"title": "2. Related Work", "content": "Methods that leverage physics knowledge in deep learning algorithms have been studied extensively in recent years. For example, Lu et al. (2021); Raissi et al. (2019); Raissi (2018); Karniadakis et al. (2021); Han et al. (2018); Sirignano and Spiliopoulos (2018); Long et al. (2018, 2019) use neural networks and deep learning training algorithms to solve partial differential equations. By contrast, our work focuses on the problem of system identification-learning unknown dynamics from time series data. More closely related to our work, Neural Ordinary Differential Equations (N-ODES) are a family of deep learning architectures that use neural networks to parametrize the right-hand side of ODEs. Originally proposed by Chen et al. (2018) in the context of generative modeling, N-ODEs provide a flexible framework for incorporating prior physics knowledge with data-driven models of dynamical systems, yielding models with improved data efficiency and generalization capabilities, especially when training data is limited (Djeumou et al., 2022, 2023; Rackauckas et al., 2020; Kidger, 2021; Neary, 2024; Zhong et al., 2021; Greydanus et al., 2019). However, N-ODES struggle to model constrained dynamical systems, often relying on penalty-based methods to enforce known algebraic equations.\nIn particular, without significant modification, N-ODEs are unable to model systems that include algebraic constraints on the state variables. Such DAEs\u2014systems of both differential and algebraic equations\u2014arise frequently in the modeling of physical systems, especially when accounting for couplings between distinct subsystems. Recently, several approaches to learning DAEs from data have been proposed (Xiao et al., 2022; Moya and Lin, 2023; Huang et al., 2024; Koch et al., 2024). These methods rely on learned predictors for the algebraic states or latent variables, which are then"}, {"title": "3. Background", "content": "Port-Hamiltonian Differential Algebraic Equations. The port-Hamiltonian (PH) framework enables compositional approaches to modeling complex, interconnected systems in a structured and modular way. Conceptually, the dynamics of individual PH systems are governed by the system's Hamiltonian function H, energy dissipation terms, and control inputs. Separate PH systems can be coupled via energy exchanges through so-called port variables to obtain new PH systems that represent the dynamics of larger composite systems. We refer to Van der Schaft and Maschke (2013); Van Der Schaft et al. (2014) for further details.\nIn this work, we consider port-Hamiltonian differential algebraic equations (PHDAEs)\u2014a broad class of PH systems that include both differential and algebraic equations, and can be written as\n$\\frac{d}{dt} Ex(t) = Jz(x(t))) - r(z(x(t))) + Bu(t).$\nHere $x \\in \\mathbb{R}^n$ is the system's state, $z : \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ is the effort (a vector-valued function that includes gradients of the system's Hamiltonian function $H(x)$), $E \\in \\mathbb{R}^{n \\times n}$ is the flow matrix, $J \\in \\mathbb{R}^{n \\times n}$ is the skew-symmetric interconnection matrix, $r : \\mathbb{R}^n \\rightarrow \\mathbb{R}^n$ is the dissipation term, $B \\in \\mathbb{R}^{n \\times m}$ is the port matrix, and $u \\in \\mathbb{R}^m$ is the control input (Mehrmann and Morandin, 2019).\nPort-Hamiltonian Differential Algebraic Equations for Electrical Networks. PHDAEs provide a general framework for energy-based modeling and control of complex dynamics. Electrical circuits may be modeled in PHDAE form as follows (G\u00fcnther et al., 2021).\n$\\begin{bmatrix} A_c & 0 & 0 & 0 \\\\ 0 & A_L & 0 & -A_V \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 \\end{bmatrix} \\frac{d}{dt} \\begin{bmatrix} q_C \\\\ Q_L \\\\ e \\\\ j_v \\end{bmatrix} = \\begin{bmatrix} 0 & -A_L^T & 0 & -A_I \\\\ A_L & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ A_I^T & 0 & 0 & 0 \\end{bmatrix} \\begin{bmatrix} \\nabla H(Q_L) \\\\ q(q_C) \\\\ 0 \\\\ j_v \\end{bmatrix} + \\begin{bmatrix} A_{Rg}(A_{RE})^T \\\\ 0 \\\\ A_e - q(q_C) \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} 0 & -A_I \\\\ 0 & 0 \\\\ 0 & 0 \\\\ 0 & -I \\end{bmatrix} \\begin{bmatrix} i(t) \\\\ v(t) \\end{bmatrix}$"}, {"title": "4. Neural Port-Hamiltonian Differential Algebraic Equations", "content": "We now present Neural Port-Hamiltonian Differential Algebraic Equations (N-PHDAEs): a physics-informed and compositional deep learning approach to modeling dynamical systems subject to algebraic constraints. As described in \u00a71, N-PHDAEs may be used to learn control-oriented models of dynamical systems in a variety of application areas, however, in this work, we focus on their application to modeling electrical networks.\n4.1. Constructing Neural Port-Hamiltonian Differential Algebraic Equations\nTo begin, we assume that the interconnection topology of the system's components is known a priori. However, models of the individual components are unknown and must be learned from data. Mathematically, we use the interconnection topology to derive the matrices E, J, and B in equation (1), and we parametrize the unknown effort $z(\\cdot)$ and dissipation $r(\\cdot)$ functions using neural networks, as illustrated in Figure 1."}, {"title": "4.2. Transforming Neural Port-Hamiltonian DAEs into Systems of Neural ODEs", "content": "Evaluating and training the constructed N-PHDAEs directly is difficult due to the challenge of solving DAEs in general. However, under appropriate conditions on the system's interconnection topology (G\u00fcnther et al., 2021), the N-PHDAEs that result from \u00a74.1 will always be index-1 equations that may be converted into semi-explicit form (as described in \u00a73).\nIn \u00a74.1, we construct N-PHDAEs in the form of (1). We proceed by automatically identifying the differential $v \\in \\mathbb{R}^d$ and the algebraic $w \\in \\mathbb{R}^a$ components of the state $x$, and by converting the N-PHDAE into semi-explicit form $\\dot{v} = f_0(v, w, u, t)$ and $0 = h_0(v, w, u, t)$, where $f_0(v, w, u, t)$ and $h_0(v, w, u, t)$ are functions of E, J, B, $z_e(\\cdot)$, $r_0(\\cdot)$, and $u(t)$. We include derivations for these terms in Appendix A, however, we omit them here due to space constraints.\nAfter converting the N-PHDAE to semi-explicit form, we use automatic differentiation to transform it into an equivalent system of N-ODEs via index reduction (Wanner and Hairer, 1996).\n$\\begin{bmatrix} \\dot{v} \\\\ \\dot{w} \\end{bmatrix} = \\begin{bmatrix} f_0(v, w, u, t) \\\\ -(\\nabla_w h_0(v, w, u, t))^{-1}(\\nabla_v h_0(v, w, u, t) f_0(v, w, u, t) + \\nabla_t h_0(v, w, u, t)) \\end{bmatrix}$"}, {"title": "4.3. Evaluating and Training Neural Port-Hamiltonian Differential Algebraic Equations", "content": "The N-PHDAE inputs are the state $x(t)$ and control input $u(t)$ at time $t$, and the prediction horizon T. The model output is the predicted state at time $t + T$, i.e. $\\hat{x}(t + T) = N-PHDAE(x, u, t, T)$, obtained by numerically integrating the right-hand side of (6) using any ODE solver.\nGiven a training dataset D, consisting of trajectories $\\tau$ of states and control inputs, we optimize the parameters $\\theta$ of the N-PHDAE by minimizing the objective (7) using gradient-based methods.\n$\\mathcal{L}(\\theta, \\mathcal{D}) = \\frac{1}{|\\mathcal{D}|} \\sum_{\\tau \\in \\mathcal{D}} \\sum_{(x,u,t,T,y) \\in \\tau} ||y - N-PHDAE(x, u, t, T)||^2 + \\alpha ||h_0(x, u, t)||^2$\nHere, the target y is defined by the true state at the prediction time $y = x(t+T)$. The first term of $\\mathcal{L}$ ensures the model predictions fit the trajectory data, and the second term of $\\mathcal{L}$ encourages $h_0(x, u, t)$ to be as close to zero as possible. We note that in order to evaluate (6) and to train the N-PHDAE, the Jacobian $\\nabla_w h_0(v, w, t)$ must be invertible. Experimentally, we found that incorporating the algebraic equation penalty into the loss function was both essential and empirically effective in ensuring that $\\nabla_w h_0(v, w, t)$ remained invertible, thereby maintaining training stability. A detailed investigation of methods to ensure this property holds in all cases is left for future work."}, {"title": "5. Composing Neural Port-Hamiltonian Differential Algebraic Equations", "content": "We now propose a method to compose previously learned subsystem N-PHDAEs to obtain an accurate dynamics model for larger composite systems, without requiring additional training.\nWe define an interconnection matrix $A_\\lambda$ to specify the couplings between an arbitrary number N of pre-defined subsystem N-PHDAEs. Intuitively, the entries of $A_\\lambda$ define couplings between the inputs and outputs of the various subsystems. In the context of electrical networks, the coupling relations are defined by introducing $n_\\lambda$ new edges between the nodes of distinct subsystems. Each new edge models a physical connection in the composite circuit, which may be modeled as a voltage source with a voltage drop of zero and a coupling current $\\lambda$ (G\u00fcnther et al., 2021). The coupling leads to an additional term in Kirchhoff's current law, modeled with an incidence matrix $A_\\lambda \\in \\{-1, 0, 1\\}^{n_{ue} \\times n_\\lambda}$ describing all the new edges of the composite system, where $n_{ue} = \\sum_{i=1}^N n_{ui}$ is the number of non-grounded nodes in all subsystems. Given the subsystem N-PHDAEs and the interconnection matrix $A_\\lambda$, the composite N-PHDAE is defined by\n$\\begin{bmatrix} A_c & 0 & 0 & 0 & 0 \\\\ 0 & A_L & 0 & -A_V & -A_\\lambda \\\\ 0 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\end{bmatrix} \\begin{bmatrix} q_C \\\\ Q_L \\\\ e \\\\ j_v \\\\ \\lambda \\end{bmatrix} = \\begin{bmatrix} 0 & -A_L^T & 0 & -A_I & 0 \\\\ A_L & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 \\\\ A_I^T & 0 & 0 & 0 & 0 \\\\ A_{Rg}(A_{RE})^T \\\\ 0 \\\\ A_e - q_0(q_C) \\\\ 0 \\end{bmatrix} + \\begin{bmatrix} -A_I & 0 \\\\ 0 & 0 \\\\ 0 & 0 \\\\ 0 & -I \\\\ 0 & 0 \\end{bmatrix} \\begin{bmatrix} i(t) \\\\ v(t) \\end{bmatrix}$"}, {"title": "6. Experimental Results", "content": "To demonstrate the strengths of the proposed N-PHDAE, we present two simulation-based case studies. We begin by training a N-PHDAE model of a well-studied circuit with nonlinear dynamics, before demonstrating the proposed approach to compositional modeling through experiments involving interconnected DC microgrids. In all experiments, we parameterize the unknown electrical component relations $g_e$, $q_e$ and Hamiltonian $H_e$ of the N-PHDAE (\u00a74.1) as multi-layer perceptrons. The training datasets D consist of only 30 state trajectories, highlighting the data efficiency of the N-PHDAE. We refer the reader to the Appendix B for additional experimental details. Project code is available at https://github.com/nathan-t4/NPHDAE.\n6.1. Learning the Nonlinear Dynamics of the FitzHugh-Nagumo Circuit\nAs an illustrative example, we begin by training a N-PHDAE model of the FitzHugh-Nagumo circuit (Izhikevich and FitzHugh, 2006), illustrated in Figure 4, which includes a nonlinear resistor R1. We compare the performance of the N-PHDAE to a black-box N-ODE, i.e., a neural ODE that does not leverage physics-based priors, as presented in \u00a73. The baseline N-ODE is parameterized using an MLP and trained on the same dataset to minimize the mean-squared error of the model's predictions.\nN-PHDAEs efficiently learn accurate models of complex dynamics. Figure (4) illustrates the predictions of the proposed N-PHDAE model over a 200-second horizon. For comparison, we also illustrate the predictions of a baseline N-ODE. The predictions from the N-PHDAE are more accurate than the N-ODE, especially for long horizons. This improvement is likely due to the N-PHDAE's ability to better satisfy the system's algebraic constraints, discussed below."}, {"title": "6.2. Learning Compositional Models of Coupled DC Microgrids", "content": "Next, we demonstrate the compositional approach to learning introduced in \u00a75 via experiments simulating a DC microgrid\u2014a low-voltage power grid operating independently from a main grid (Cucuzzella et al., 2018). The DC microgrids we consider are powered by distributed generation units (DGUs), such as renewal energy sources, and are interconnected by transmission lines to disperse and store energy. We first train a N-PHDAE to model the dynamics of a DGU. Figure (6), illustrates the N-PHDAE's state predictions, prediction error, and a measure of the extent to which the predictions violate constraints. As with the FitzHugh-Nagumo circuit, the N-PHDAEs modeling individual DGUs output accurate and constraint-satisfying state predictions.\nCompositions of pre-trained N-PHDAE submodels accurately simulate a larger DC microgrid without additional training. As illustrated in Figure 2 we then compose the learned DGU models by connecting them with transmission lines represented by known PHDAE models. To do so, we use the composition procedure detailed in \u00a75. We configure the DC microgrid as a complete graph with 10 nodes, with DGUs as the nodes and transmission lines as the edges. In Figure (7), we plot"}, {"title": "7. Conclusions", "content": "We introduce Neural Port-Hamiltonian Differential Algebraic Networks (N-PHDAEs), a class of physics-informed neural networks that enables compositional approaches to learning system dynamics. The proposed N-PHDAEs use neural networks to parameterize unknown terms in port-Hamiltonian dynamical systems, even when unknown terms are included in algebraic constraints between state variables. We propose algorithms for model inference and training that use automatic differentiation to transform the parametrized differential algebraic equations into equivalent systems of Neural Ordinary Differential Equations (N-ODEs), which may be evaluated more easily. Our experimental results demonstrate that N-PHDAEs learn data-efficient, accurate, and compositional models of electrical networks, enjoying an order of magnitude improvement to constraint satisfaction compared to a baseline N-ODE. Future work will apply the proposed compositional learning algorithms to a broader range of constrained and coupled dynamical systems."}, {"title": "Appendix A. Transforming the N-PHDAE into Semi-Explicit Form", "content": "We explain how to rewrite the N-PHDAE as an index-1 semi-explicit DAE, as described in \u00a74.3. First, let the algebraic indices of E be the indices of the rows of E that are all zero, and the differential indices of E as the indices of the rows of E with nonzero elements. Since E is generally not invertible, we solve a least squares problem to rewrite the N-PHDAE in semi-explicit form. For our experiments, we solve the least-square problem with reduced QR-decomposition (Trefethen and Bau, 1997).\nLet $\\bar{E}$ be the submatrix of E that contains the rows corresponding to differential equations (i.e. the rows with non-zero elements) and columns that multiply the differential states. Additionally, let $\\bar{Q}$ and $\\bar{R}$ denote the reduced QR-decomposition of $\\bar{E}$, and $R_d$ the submatrix of $\\bar{R}$ that contains the first d rows of R (where d is the number of differential state variables). The differential equations f of the PHDAE in semi-explicit form may then be expressed as\n$\\dot{v} = [\\frac{E}{0}]^{-1} [\\frac{f}{h_e}] = f_0(v, w, u, t) = R_d^{-1}\\bar{Q}^T (Jz_e(v, w, t) - r_0(v, w, t) + Bu(t)).$\nThe algebraic equations $h_e(\\cdot)$ correspond to the remaining rows of the right-hand side of the N-PHDAE, i.e., the entries of the vector output of $Jz_e(v, w, t) - r_0(v, w, t) + Bu(t)$ that share indices with the algebraic variables.\n$0 = h_0(v, w, u, t) = [Jz_e(v, w, t) - r_0(v, w, t) + Bu(t)]_{algIndices}.$"}, {"title": "Appendix B. Additional Experimental Details", "content": "B.1. Implementation Details\nThe code to reproduce all numerical experiments is implemented in Python using the Jax (Bradbury et al., 2018) and Haiku (Hennigan et al., 2020) libraries and available at https://github.com/nathan-t4/NPHDAE. All numerical experiments are trained for 100000 epochs with a batch size of 128, loss function hyper-parameter \u03b1 = 0.01 (\u00a74.3), and optimized using Adam. The learning rate is initially set to 0.0001 for the N-PHDAE and 0.001 for the baseline black-box NODE, and decays to zero with cosine annealing (Loshchilov and Hutter, 2016). The resistor and capacitor component relations $g_e$, $q_e$ and Hamiltonian $H_e$ of the N-PHDAE and the baseline black-box NODE are all parameterized with multi-layer perceptions, each with two hidden layers of 100 nodes and ReLU activation.\nThe training datasets are generated by rewriting the electrical network dynamics as a Port-Hamiltonian differential algebraic equation (2). Then, the Port-Hamiltonian differential algebraic equation is transformed to an equivalent ordinary differential equation using index reduction (\u00a74.2), and the state at the next time-step is obtained through numerical integration using the fourth-order Runge-Kutta method with a fixed time-step (\u00a74.3). For all numerical experiments, we generate 30 trajectories of 1000 time-steps for the training dataset and 10 trajectories of 10000 time-steps for the validation dataset.\nB.2. FitzHugh-Nagumo Circuit\nThe FitzHugh-Nagumo model is a well-studied nonlinear dynamics model of excitable biological systems first introduced by FitzHugh (1961), and with an equivalent circuit derived by Nagumo"}, {"title": "B.3. Microgrids", "content": "We use the direct current (DC) microgrid model introduced by Cucuzzella et al. (2018) for the compositional learning experiment. DC microgrids are small-scale power grids composed of distributed generation units, loads, and energy storage systems.\nB.3.1. DISTRIBUTED GENERATION UNIT MODEL\nDistributed generation units (DGU) are small-scale electricity generators that are an alternative to traditional power plants. For example, renewable energy sources can act as the power generation unit in the DGU model. The equivalent PHDAE of the distributed generation unit (2) has incidence matrices:\n$A_c = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, A_R = \\begin{bmatrix} -1 \\\\ 0 \\end{bmatrix}, A_L = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, A_V = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, A_I = \\begin{bmatrix} 0 \\\\ -1 \\end{bmatrix}.$\nand component relations:\nr: $V_R \\rightarrow V_R/R$\nq: $V_c \\rightarrow CV_c$\nH: $\\phi_L \\leftrightarrow \\phi_L^2/2L$\nThe training dataset for the distributed generation unit has \u2206t = 0.01 and parameter values $R_{dgu}$ = 1.2, $L_{dgu}$ = 1.8, and $C_{dgu}$ = 2.2.\nB.3.2. TRANSMISSION LINE MODEL\nThe transmission lines interconnect two distributed generation units and model the grid loads. The equivalent PHDAE of the transmission line model has incidence matrices:\n$A_C = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, A_R = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}, A_L = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}, A_V = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}, A_I = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}.$\nand component relations:\nr: $V_R \\rightarrow V_R / R_0$\nH: $\\phi_L \\leftrightarrow \\phi_L^2/2L_{tl}$\nThe transmission line models have parameter values $R_{tl}$ and $L_{tl}$ sampled from the uniform distribution U(0.1, 2.0).\n\u0412.3.3. \u041e\u0412TAINING THE MICROGRID WITH COMPOSITION\nTowards simulating microgrids via composition, we need an interconnection matrix $A_\\lambda$ which specifies how the various distributed generation units and transmission lines are interconnected. In the compositional learning experiments, the microgrid has a complete graph configuration with 10 nodes, with DGUs at the nodes and transmission lines at the edges. Due to space constraints, we do not include $A_\\lambda \\in \\{-1, 0, 1\\}^{165\\times 90}$ for the microgrid configuration as a complete graph with 10 nodes. Instead, for illustration purposes, we include $A_\\lambda$ when the microgrid is configured as a complete graph with 2 nodes:\n$A_\\lambda = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\\\ 1 & 1 \\\\ 0 & 0 \\\\ 0 & -1 \\\\ -1 & 0 \\\\ 0 & 0 \\\\ 0 & 1 \\end{bmatrix}$"}]}