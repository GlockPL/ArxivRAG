{"title": "TinyGraph: Joint Feature and Node Condensation for Graph Neural Networks", "authors": ["Yezi Liu", "Yanning Shen"], "abstract": "Training graph neural networks (GNNs) on large-scale graphs can be challenging due to the high computational expense caused by the massive number of nodes and high-dimensional nodal features. Existing graph condensation studies tackle this problem only by reducing the number of nodes in the graph. However, the resulting condensed graph data can still be cumbersome. Specifically, although the nodes of the Citeseer dataset are reduced to 0.9% (30 nodes) in training, the number of features is 3,703, severely exceeding the training sample magnitude. Faced with this challenge, we study the problem of joint condensation for both features and nodes in large-scale graphs. This task is challenging mainly due to 1) the intertwined nature of the node features and the graph structure calls for the feature condensation solver to be structure-aware; and 2) the difficulty of keeping useful information in the condensed graph. To address these challenges, we propose a novel framework TinyGraph, to condense features and nodes simultaneously in graphs. Specifically, we cast the problem as matching the gradients of GNN weights trained on the condensed graph and the gradients obtained from training over the original graph, where the feature condensation is achieved by a trainable function. The condensed graph obtained by minimizing the matching loss along the training trajectory can henceforth retain critical information in the original graph. Extensive experiments were carried out to demonstrate the effectiveness of the proposed TinyGraph. For example, a GNN trained with TinyGraph retains 98.5% and 97.5% of the original test accuracy on the Cora and Citeseer datasets, respectively, while significantly reducing the number of nodes by 97.4% and 98.2%, and the number of features by 90.0% on both datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Graphs have been extensively employed in modeling structured or relational real-world data [1, 2, 3], encompassing various domains such as social network analysis [4, 5], recommendation systems [6, 7], drug discovery [8, 9, 10], transportation forecasting [11], and epidemiology [12]. Despite the success of GNNs in capturing abounding information in graph data [13, 14], training GNNs on real-world graphs containing large numbers of nodes and edges can be costly in terms of computational resources and time due to the complex sparse multiplication operations involved in training [15, 16, 17]. This problem is further compounded by the high-dimensional features that are common in graph data. More remarkably, the storage and time demands are magnified under the setting of automated machine learning [18, 19], e.g., neural architecture search and hyperparameter optimization, where the GNN models need to be retrained for multiple times. One feasible idea to address these challenges is to condense the graph into a small graph so that it can save storage while facilitating the GNN training.\nRecent studies on graph condensation mainly focus on reducing the number of nodes in large-scale graphs [20, 21, 22]. An early work [23] proposes a data condensation algorithm to reduce the training samples of image datasets. A more recent work [20] generalizes the data condensation problem to the graph domain and designs a graph condensation framework that aims to compress the node size in a large graph. Furthermore, a one-step gradient matching strategy has been proposed to improve the efficiency of graph condensation [24]. However, existing graph condensation frameworks solely condense node size, which may be insufficient and still require large computation resources and storage when training over graphs where the nodal features are high-dimensional. For example, the number of features is 41 times that of the number of nodes in Cora, 123 times in Citeseer, 11.2 times in Flickr, and 7.8 times in Reddit. Such high dimensional features still lead to large weight matrices in GNN training. Hence only reducing the node size does not thoroughly resolve the issue of the high computational cost of GNN training. As such, there is a crucial demand to effectively address the challenges posed by high-dimensional features in large-scale graph datasets.\nIn essence, to develop a structure-aware joint condensation framework for graph data, we are faced with two main challenges: 1) how to learn a tiny graph with fewer nodes and features that are still informative, so that the GNN trained on the tiny graph can achieve comparable accuracy with that trained on the original graph, and 2) how to formulate the optimization problem and update rules for the joint"}, {"title": "condensation task that efficiently learns the condensed graph structure and features. The first challenge centers around what needs to be learned and preserved from the original graph data while learning the condensed graph. One simple idea would be conducting the node and feature condensation sequentially by applying a two-stage framework, where one can carry out graph-condensation algorithms after dimensionality reduction is done on the nodal features. However, such a framework will likely lose critical information as structure-agnostic dimensionality reduction does not use the structural information often useful for graph-based learning. In addition, such a two-stage algorithm may result in error propagation if too much information is lost in the first stage. The second challenge lies in how to circumvent the high computational complexity of multi-level optimization involved in joint condensation, as the learning procedure often requires updating the optimized parameters for GNN trained on the condensed graph as well as the trainable condensed graph in an iterative manner. To this end, we propose a novel joint graph condensation framework as illustrated in Figure 1. For the first challenge, we propose a unified framework TinyGraph, to simultaneously condense nodes and features. TinyGraph employs a gradient matching technique to enforce the gradients of the condensed graph to be as close as possible to the original graph along the training trajectory, and thus the learned condensed graph can be informative to train an accurate GNN. For the second challenge, TinyGraph does not rely on solving an optimization of the inner problem first and then an outer problem but only solves a gradient matching loss minimization problem for the learning task. The goal of TinyGraph is to simultaneously condense nodes and features in a large graph while retaining useful information in the condensed graph. It synchronizes the GNN training trajectories of the two graphs through an optimization of a matching loss. This approach ensures that the condensed graph is consistent with the original graph and preserves the relationships between nodes. This study makes the following major contributions:", "content": "\u2022 We address the challenge that arises when training GNNs on large-scale graphs with high-dimensional features, which persists even in existing graph condensation methods.\n\u2022 Instead of a two-stage technique, we propose a unified framework that condenses both nodes and features simultaneously. Specifically, a structure-aware feature condensation framework is designed that can efficiently take the graph structure into consideration.\n\u2022 TinyGraph is able to achieve remarkable test accuracy of 98.5%, 97.5%, 98.7%, 94.9%, and 86.5%, meanwhile significantly reducing the node size by more than 97.4% and the corresponding feature sizes by 90%, 90%, 80%, 70%, and 70%, on Cora, Citeseer, Flickr, Reddit, and Arxiv, respectively."}, {"title": "II. PROBLEM FORMULATION", "content": "Notations. Given a graph dataset T = {A, X, Y}, where A \u2208 \u211d^{N\u00d7N} is the adjacency matrix, N is the number of nodes, X \u2208 \u211d^{N\u00d7D} is the node feature matrix and Y \u2208 {0,...,C \u2013 1}^N denotes the node labels over C classes, GNN_{\u03b8} represents a GNN model parameterized by \u03b8, L denote the node classification loss (i.e., cross-entropy loss) that measures the discrepancy between predictions and the ground truth.\nGoal. We aim to learn a tiny, condensed graph S = {\u00c2, X, \u0176} with A \u2208 \u211d^{n\u00d7n}, X \u2208 \u211d^{n\u00d7d}, \u0176 \u2208 {0,...,C \u2013 1}^n, with n << N, and d << D, such that a GNN trained on S can achieve comparable performance to one trained on the original graph T. It is necessary for the larger graph to have the same feature dimension as S to match the input dimension of GNN.\nProblem Formulation. To achieve this goal, we introduce a trainable feature condensation function f(\u00b7) : \u211d^D \u2192 \u211d^d, parameterized on \u03a6. By projecting the original feature matrix X through this function, we obtain the feature-condensed graph \u0164 = (A, f_{\u03a6}(X), Y), which retains the key information from the full graph T. This allows our proposed framework to establish an association between the original graph T and the condensed graph S through this function f_{\u03a6}(\u00b7). To ensure comparable performance achieved by training on the condensed graph and the original graph, we draw inspiration from prior studies [25, 26, 27, 28], that models the parameters \u0398_S as a function of the synthetic data S. Henceforth, we approach the joint condensation problem by training a GNN on the trainable condensed graph S, based on which the feature condensation function parameterized by \u03a6* and condensed graph S* is obtained by minimizing the loss. The objective of the joint condensation problem can be formularized as follows:\nS* = arg min_{S} L(GNN_{\u0398_S}(\u00c2, f_{\u03a6*}(X)), \u0176), \ns.t. \u03a6* = arg min_{\u03a6} L(GNN_{\u0398_S}(A, f_{\u03a6}(X)), Y),\n\u0398_S = arg min_{\u0398_S} L(GNN_{\u0398_S}(\u00c2, X), \u0176). (1)\nNote that the optimization in Equation (1) necessitates solving a nested-loop optimization problem. Specifically, this involves iteratively updating \u0398_S while performing computationally expensive computations of the gradient of the trainable condensed graph S, i.e., L_S, which is obtained by calculating the discrepancies between the model predictions and the ground truth for S. For calculating L, We employ the cross-entropy loss. These computations are carried out over multiple updates within each iteration.\nHowever, this procedure encounters scalability issues when applied to large graphs with a substantial number of optimization steps in the inner loop. The computational burden imposed by these iterations becomes increasingly prohibitive as the graph size grows. To address this limitation, we propose an alternative algorithm in the subsequent section. Our approach follows the gradient matching strategy [29], which aims to overcome the scalability challenges in nested-loop optimization and offers an efficient solution to the joint condensation."}, {"title": "III. PROPOSED ALGORITHM", "content": "In this section, we introduce a novel algorithm TinyGraph to solve the problem in Equation (1).\n\nA. Structure-aware feature condensation\nGraph data presents unique challenges for traditional dimensionality reduction (DR) methods. Principal Component Analysis (PCA) [30], or Independent Component Analysis (ICA) [31] are two typical and widely used DR methods. Others include linear and nonlinear techniques, unsupervised and supervised methods, and matrix factorization and manifold learning approaches. They have been shown promising results in abstracting primary features in various research disciplines, such as on image data [32, 33], text data [34, 35], as well as biological or health data [36]. However, their applications are limited to Euclidean data where samples are independent and thus are not well-suited for graph data where nodes are interlaced with others based on graph structure. Therefore, grafting these methods for graph data is not feasible, and it is necessary to design a structure-aware algorithm for high-dimensional graph data. To better capture the graph structure in the condensation process, we adopt a graph attention function [37] as the feature condensation function, which contains multiple graph attention networks (GAT) layers. GAT is an attention-based GNN model that leverages attention mechanisms to assign precise weights during the aggregation of neighboring node information pertaining to a given target node. By incorporating the fine-grained weight assignment capability of GAT, the proposed approach aims to improve the accuracy and comprehensiveness of the graph condensation process.\nGraph Attention Networks as Feature Condensation Function. The graph attentive network in the condensation framework is denoted as GAT_{\u03a6}. It is parameterized by \u03a6 and maps the original features X to the trainable condensed features X_t = GAT_{\u03a6}(X). The graph that contains the trainable condensed features, is referred to as a trainable condensed graph denoted by \u0164 = (A, X_t, Y). During each training epoch t, the node representation of node v_i is obtained. For brevity, the epoch index t will be omitted in the subsequent notations pertaining to the calculation of the Graph Attentive Encoder [38]. Within each layer of the GAE, denoted by l, node v_i integrates the features of its neighboring nodes to acquire representations for the subsequent layer, l + 1, through the following process:\nh^{l+1}_i = \u03c3 (\u03a3_{j\u2208N_i\u222a{v_i}} \u03b1_{ij}W^lh^l_j)\nwhere h^{l+1}_i represents the representation of node v_i in layer l + 1, N_i denotes the set of neighboring nodes of v_i, W^l represents a weight matrix associated with layer l, and \u03c3 denotes a nonlinear activation function (e.g., ReLU), and \u03b1_{ij} is an attention coefficient that determines the importance of neighboring node v_j to node v_i in layer l, which can be computed as:\n\u03b1_{ij} = \\frac{exp (\u03c3 (a^T[W_lh^l_i \u2295 W_lh^l_j]))}{\u03a3_{k\u2208N_i\u222a{v_i}} exp (\u03c3 (a^T[W_lh^l_i \u2295 W_lh^l_k]))},\nwhere W and W^t represent weight matrices, and h^l_i and h^l_j denote the hidden states of nodes v_i and v_j in layer l, respectively. The symbol \u2295 denotes the concatenation operation. The term a represents a trainable parameter vector that allows the model to learn the importance of different node relationships. Furthermore, in order to enhance the expressive power of our model, we incorporate multiple GAT layers into GAE. The computation of the latent representation, denoted as x_i, for each node i is performed as follows:\nx_i = \u03c3 (\u03a3_{j\u2208N_i\u222a{v_i}} W^Lx_j^{(L-1)}),\nwhere x_i \u2208 \u211d^d (d << D) is the trainable condensed feature of node i, and h^{L\u22121}_j is the hidden representation of node j at layer L \u2212 1. We initialize the first layer by setting h^0_j = x_j, which is the nodal feature of node j. In each training epoch, we encode the original feature matrix X using the GAE. By employing GAE, the proposed condensation framework is capable of learning the condensed feature while considering the underlying graph structure. By incorporating"}, {"title": "multiple GAT layers, TinyGraph leverages the interplay between nodal attributes and the graph topology, our model captures the intricate non-linear relationships present in the graph. This enhanced representation learning capability is essential for addressing the complexities of real-world graph data and facilitating downstream tasks that rely on learning an accurate condensed graph. B. Gradient Matching Note that the objective of this study is to learn a condensed graph, denoted as S, that allows the trained model to converge to a solution similar to that of an optimized parameter space represented by \u0164. To this end, an intuitive optimization approach is to align the optimal GNN parameters trained from the trainable feature-condensed graph and the trainable condesed graph, denoted as \u0398_S^T and \u0398_T^T, respectively, In this way, the resulting optimized parameters converge to a comparable solution:", "content": "min_{S,\u03a6} M (\u0398_S^T, \u0398_T^T)\ns.t. \u0398_S^T = arg min_{\u0398_S^T} L (GNN_{\u0398_S^T}(\u00c2, X), \u0176),\nand \u0398_T^T = arg min_{\u0398_T^T} L (GNN_{\u0398_T^T}(A, X), Y), (2)\nwhere the objective is to minimize the matching loss M(\u00b7,\u00b7) with respect to the optimal parameters \u0398_S^T and \u0398_T^T, which are associated with the condensed graph and the model GNN_{\u0398}, respectively. The optimization of Equation (2) aims to obtain a trainable condensed graph S for the GNN model that is parameterized by \u0398. However, the effectiveness of \u0398_S^T is influenced by its initial value \u0398_S^0. Consequently, the objective function in Equation (2) optimizes over a single model initialized with the initial weights \u0398_S^0. Our objective is to ensure that \u0398_S^T not only closely approximates the final value of \u0398_T^T, but also follows a similar trajectory to the parameter values \u0398^t_S at time t throughout the optimization process.\nCurriculum Gradient Matching. In order to enhance the learning process and improve optimization outcomes, we adopt curriculum gradient matching [25]. This technique aims to align the training trajectories of T and S, throughout each epoch of the training process, achieved by quantifying the disparity between their respective gradients. By employing curriculum gradient matching, the problem in Equation (2) can be reformulated as:\nmin_{S,\u03a6} E_{\u0398_S^0\u223cP_{\u0398_S^0}} [\u03a3_{t=0}^{T-1} M (\u0398_S^t, \u0398_T^t)]\nwith \u0398_{S}^{t+1} = \u0398_{S}^{t} \u2212 \u03b7\u2207_{\u0398_{S}^{t}} L(GNN_{\u0398_{S}^{t}} (\u00c2, f_{\u03a6}(X)), \u0176),\nand \u0398_{T}^{t+1} = \u0398_{T}^{t} \u2212 \u03b7\u2207_{\u0398_{T}^{t}} L(GNN_{\u0398_{T}^{t}} (A, X), Y),\n(3)\nwhere GNN_{\u0398} denotes the GNN model parameterized with \u0398, \u03b7 is the learning rate for the gradient descent. This approximation method eliminates the need for computationally expensive unrolling of the recursive computation graph over the previous parameters, denoted as \u0398_S^0,..., \u0398_S^{t\u22121}. Consequently,"}, {"title": "the optimization technique demonstrates significantly enhanced speed, improved memory efficiency, and the ability to scale up to the joint condensation. By minimizing M to a near-zero value, we aim to obtain the optimal \u0398_S^T = \u0398_T^T, which is parameterized by S, by emulating the training of \u0398_{T}^{t+1}. Gradient Matching Loss. Based on the optimization approach described earlier, we propose the utilization of a gradient-matching loss to update the trainable parameters. In this context, we have two losses: L_T and L_S, which represent the discrepancies between the model predictions and the ground truth for the transformed original graph and the trainable condensed graph, respectively. For calculating L, We employ the cross-entropy loss. To update the weights of GNN, we calculate the gradients of the losses with respect to the GNN weights. Specifically, we denote these gradients as G_T and G_S, which are obtained through the respective expressions: G_T = \u2207_{\u0398}L(GNN(A, f_{\u03a6}(X)), Y) and G_S = \u2207_{\u0398}L (GNN (\u00c2, X), \u0176).\nThe gradient matching loss M quantifies the dissimilarity between the gradients of the source network and the target network training. To calculate the gradient matching loss M, we consider each individual class c separately. For a given class c, the gradient distance is determined by computing the Cosine Distance between the corresponding columns of the gradient matrices, i.e., G_T^c and G_S^c. These matrices represent the gradients of the sampled graphs T and S^c of a class c, derived from the original graph and condensed graph, respectively. This Cosine Distance captures the disparity in the way class-specific information is represented in the two graphs. By assessing the Cosine Distance between the gradient columns, we quantify the dissimilarity between the gradient directions associated with class c in the original and condensed graphs. By summing the gradient distances across all classes, the gradient matching loss M provides a comprehensive assessment of the overall dissimilarity between the networks. Mathematically, the gradient matching loss M can be formulated as follows:\n M(G_T, G_S) = \u03a3_{c=0}^{C-1} M^c\n with M^c= \\frac{1}{P}\\frac{1}{H} \u03a3_{p=1}^{P}\u03a3_{h=1}^{H} [1- \\frac{G_{T_{h,p}}^c G_{S_{h,p}}^c}{||G_{T_{h,p}}^c|| ||G_{S_{h,p}}^c||}]. (4)\nwhere G_{T_{h,p}}^c and G_{S_{h,p}}^c are the h-th column vectors of the gradient matrices for the class c, at layer p. In the subsequent subsection, we delve deeper into the practical implementation and utilization of the gradient-matching process, discussing how it is integrated into our framework to enhance the overall condensation procedure and optimize the trainable parameters. C. Model Optimization The standard large-batch optimization process poses chal- lenges for reconstruction tasks and necessitates substantial memory usage [39]. To address this, we adopt a strategy where a mini-batch of graph data is sampled at each layer of GNN. Subsequently, we compute the gradient-matching loss for each class independently. Specifically, to handle a specific class"}, {"title": "c, TinyGraph selects a batch of nodes and their corresponding neighbors from the transformed original graph T, denoted as \u0164^c ~ \u0164. Likewise, TinyGraph samples a batch of condensed nodes from the condensed graph S = \u00c2, X, \u0176 and incorporates all of their neighbors, denoted as S^c ~ S.\nDespite these measures, the training process remains challenging primarily due to the significant complexity introduced by learning graph structure. This complexity stems from factors such as intricate relationships between nodes, intricate connectivity patterns, and the need to capture graph-specific features. Hence, in the following, we will further navigate these challenges and improve the effectiveness of joint condensation. Parameterizing Graph Structure. Treating A and X as free parameters will lead to overfitting caused by learning a large number of parameters in the order of O(n^2). In order to alleviate the computational complexity associated with optimizing the quadratic model of A \u2208 \u211d^{n\u00d7n}, we model \u00c2 as a function \u03a8, denoted by g_\u03a8(\u00b7, \u00b7), which is parameterized by \u03a8 [20], i.e.:", "content": "\u00c2_{ij} = g_\u03a8(X_i, X_j) = \u03c3 (\\frac{k_\u03a8(z) + k_\u03a8(z')}{2})\nwhere both vectors z := [X_i;X_j] and z' := [X_j;X_i] are elements of \u211d^{1\u00d72d}. The function k_\u03a8(\u00b7) denotes a multi-layer neural network (MLP) parameterized by \u03a8, and \u03c3(\u00b7) represents a sigmoid activation function. This method offers the scalability to expand the condensed graph by incorporating additional synthetic nodes derived from the real graph. In this expansion process, the trained g_\u03a8(\u00b7, \u00b7) can be effectively utilized to infer the connections of the newly added synthetic nodes. As a result, we only need to focus on learning the distinctive features of these new nodes, while leveraging the existing graph structure and connections inferred by g(\u00b7).\nBuilding upon the aforementioned elucidation, we articulate the ultimate objective of the proposed framework. This objective is formulated based on an empirical observation: the proximity between \u0398_S^T and \u0398_T^T is typically small. Consequently, we couple them and replace them with \u0398^t, denoting the GNN weights trained on S at time t. In light of this, we can simplify the objective presented in Equation (3) by treating it as a gradient-matching process. This process can be represented in the following manner:\nmin_{X,\u03a6,\u03a8} E [ \u03a3_{t=0}^{T-1} M (\u2207_{\u0398_t}L (GNN_{\u0398_t} (g_\u03a8 (X), X), \u0176),\n\u2207_{\u0398_t}L (GNN_{\u0398_t} (A, f_\u03a6 (X)), Y))\n]. (6)\nThe loss function M combines the gradients of L with respect to the parameters \u0398 for both input cases. The minimization of this loss function drives the optimization process, influencing the updates made to the variables X, \u03a6, and \u03a8. Figure 2 provides an overview of our proposed framework and depicts the optimization process visually. Alternative Optimization Strategy. Optimizing X, \u03a8, and \u03a6 simultaneously can be a challenging task due to their interdependence. To overcome this challenge, we employ an alternative optimization strategy in our research. Our approach aims to iteratively update the parameters \u03a6, \u03a8, and X in distinct time periods. At each epoch, our method begins by updating the feature condensation function \u03a6. Following this, for the first t_1 training epochs, we focus on updating \u03a8. Then we proceed to update the condensed features X for the subsequent t_2 epochs.\nImportantly, the parameters are updated asynchronously at different epochs, reflecting their interdependence. This asynchronous updating scheme allows us to leverage the information and progress made in the previous phases, leading to more effective optimization. We iterate this process until a predefined stopping condition is met, such as reaching a convergence criterion or completing a fixed number of epochs:\n\u03a6_{t+1} = \u03a6_t - \u03b7_1\u2207 M (every epoch),\n\u03a8_{t+1} = \u03a8_t - \u03b7_2\u2207 M (t_1 epochs),\nX_{t+1} = X_t - \u03b7_3\u2207 M (t_2 epochs). (7)\nThis iterative optimization strategy ensures that each parameter is updated strategically, accounting for their mutual influence and optimizing the overall performance of the model. Model Initialization. For the initialization of trainable parameters in the joint condensation, we centralize original features by X' = X(I_D \u2212 \\frac{1}{1}1 1^T). To simplify the joint condensation, we fix the node labels \u0176 while keeping the class distribution as original labels Y. For the initialization of the trainable condensed graph, we use graph sampling. We first sample a subset of nodes from the trainable condensed graph T = (A, X, Y), where X = f_\u03a6(X) \u2208 \u211d^{N\u00d7d} is the trainable condensed feature. The number of sampled nodes from each class is set to preserve the distribution of the labels. Learning all four variables, namely X, Y, \u03a6, and \u03a8, poses significant challenges. To simplify the problem, we fix the node labels \u0176 after initialization, and the feature vectors corresponding to \u0176 are used to initialize X \u2208 \u211d^{n\u00d7d}.\nAlgorithm Implementation. In our algorithm, we follow a series of steps to implement the TinyGraph framework. We begin by initializing the GNN model parameter \u0398^0, which is sampled from a uniform distribution Q_\u0398 based on \u0398^0. Next, we proceed with the sampling of node batches from the labeled training graph T and the condensed graph S for each class. These batches serve as input for the subsequent computations. Within each class, we calculate the gradient matching loss. The losses obtained from each class are summed up and then used to update specific parameters such as \u03a6, X, and \u03a8. Once the condensed graph parameters have been updated, the GNN parameters are updated for a specified number of epochs t_\u0398. During this phase, the GNN model is fine-tuned to improve its performance. Finally, to obtain the final sparsified graph structure, we apply a filtering step. We discard edge weights that fall below a predetermined threshold \u03b3. This filtering process helps in simplifying the graph representation and reducing unnecessary edges. The detailed algorithm of TinyGraph is summarized in Algorithm 1.\nD. Discussion on the Differences from Related Studies In this subsection, we further discuss the novelty of the proposed TinyGraph compared with node condensation methods and two-stage condensation approaches."}, {"title": "Algorithm 1: TinyGraph for Graph Condensation", "content": "1 Input: Training data T=(A, X, Y), pre-defined labels \u0176.\n2 Initialize X of dimension d by randomly selecting node features from each class.\n3 for k = 0,..., K \u2212 1 do\n4 | Initialize \u0398^0 ~ Q_\u0398\n5 | for t = 0,..., T - 1 do\n6 | M = 0\n7 | Compute X_t = f_{\u03a6}(X) and to form \u0164\n8 | for c = 0, ..., C - 1 do\n9 | | Compute \u00c2 = g_\u03a8(X); then S = {\u00c2, X, \u0176}\n10 | | Sample (\u0164^c, X, Y) ~ \u0164 and (S^c, X, \u0176) ~S\n\u25b7 detailed in Section 3.1\n11 | | Compute \u2207_{\u0398_t} L_T, and \u2207_{\u0398_t} L_S\n12 | | Obtain M from Equation (4)\n13 | Update \u03a6_{t+1} = \u03a6_t - \u03b7_1 \u2207_{\u03a6_{t}} M\n14 | if t%(t_1+t_2) < t_1 then\n15 | | Update \u03a8_{t+1} = \u03a8_t - \u03b7_2 \u2207_{\u03a8_{t}} M\n16 | else\n17 | | Update X_{t+1} = X_t - \u03b7_3 \u2207_{X_{t}} M\n18 | for j = 0,..., J - 1 do\n19 | | Update \u0398^{t+1} = \u0398^t \u2013 \u03b7_\u0398 \u2207_{\u0398_{t}} L_S\n20 A = g_\u03a8(X)\n21 A_{ij} = \u00c2_{ij} if \u00c2_{ij} > \u03b3, otherwise 0\n22 Return: S = (\u00c2_{T\u22121}, X_{T\u22121}, \u0176_{T\u22121}), and \u03a6_{T\u22121}\nComparison with Node Condensation Methods. Various recent works have focused on reducing the size of data while preserving essential information, such as data condensation methods [20, 23, 24, 40] and graph compression methods [41, 42]. However, these methods overlook the high dimensionality of nodal features in real-world graphs. In contrast, our proposed method addresses both feature and node condensation, achieving significant storage reduction of 75.3%, 83.3%, 87.0%, 87.8%, and 51% on Cora, Citeseer, Flickr, Reddit, and Arxiv, respectively, when compared to the existing node condensation framework GCond.\nTwo-stage Condensation Approaches. Two-stage condensation approaches directly apply dimensionality reduction methods [30, 31, 43, 44, 45, 46, 47, 48] to node condensation frameworks, which are insufficient due to the structure-agnostic nature in their feature condensation process. Compared to these approaches, TinyGraph offers two key advantages in feature condensation: 1) the feature and node condensation are learned through unified optimization, enabling structure awareness in feature condensation, and 2) TinyGraph utilizes a learnable projection function for feature condensation, offering greater flexibility than fixed projection matrices used in DR methods."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we conduct experiments with five real-world graphs to evaluate TinyGraph. The main observations in experiments are highlighted as boldface.\nA. Experimental setup.\nDatasets. We evaluate the efficacy of our proposed method over three transductive datasets, i.e., Cora, Citeseer [49], and Arxiv [50], as well as two inductive datasets, i.e., Flickr [51] and Reddit [4]. For consistency and fair comparisons, we utilized all the datasets provided by PyTorch Geometric[52], following the publicly available data splits, as widely adopted by previous studies [4]. Note that the employed experimental setup is outlined in [4]. We also present the detailed statistics of the used in Table I.\nBaselines. We conducted a comprehensive comparative analysis between our proposed method, TinyGraph, and seven baseline approaches, which are: (1) a model that utilizes the original graph structure and node features without any condensation for training; (2) and (3) two unsupervised classical methods for density-based clustering, which employ condensed graph structures and complete node features, namely GCond [20] and GraphPCA [53]; (4) GCond-ICA, (5) GCond-PCA, and (6) GCond-LDA, which incorporate GCond with feature condensation by projecting the original features through a fixed feature condensation matrix based on Independent Component Analysis (ICA) [31], Principal Component Analysis (PCA) [30], and Linear Discriminant Analysis (LDA) [44], respectively. (7) Additionally, we consider a deep-learning approach, namely the Variational Graph Autoencoder (VGAE) [54], and utilizes its latent representation as a condensed feature along with the GCond, denoted as GCond-VGAE. To sum up, (1) does not involve any condensation process, while (2)-(3) implement node condensation through GCond and GraphPCA, and (4)-(7) implement node condensation through GCond and feature condensation by the corresponding algorithm. It is worth noting that for methods (4)-(7), where both feature size and node size condensation are involved, we perform feature condensation prior to node size condensation.\nEvaluation. To evaluate the effectiveness of condensed graphs, our approach involves several steps. Firstly, we obtain the condensed graph for the original training graph via each algorithm. Then we utilize the trained GNN model to infer labels for the test nodes on the entire graph. Note that the training graph corresponds to the complete graph in the transductive setting. The performance of the algorithm is then assessed by measuring the test accuracy. For the trainable condensed graph, we retain r_n \u00d7 N nodes for all algorithms, where r_n represents the node condensation ratio, satisfying the condition 0 < r_n < 1. Similarly, for baselines utilizing condensed features, the learned condensed graph has r_n \u00d7 N nodes and r_d \u00d7 D features. The parameter r_d (0 < r_d < 1) signifies the ratio of condensed features to the original features. For the transductive setting, we utilize the full graph in the condensation process since the full graph is available in training. For the inductive setting, when only the training graph is"}, {"title": "available in training, we only condense the training graph. Hyperparameter settings. To implement TinyGraph, we employ a 2-layer Simplified Graph Convolution (SGC) [55] with 256 hidden units as the GNN backbone. To capture the relationship between A and X, we utilize a multi-layer perceptron (MLP) function, g_\u03a8(\u00b7, \u00b7). Specifically, for smaller graphs such as Cora and Citeseer, g_\u03a8(\u00b7, \u00b7) is a 3-layer MLP with 128 hidden units in each hidden layer, while for larger graphs like Flickr and Reddit, we employ a 3-layer MLP with 256 hidden units. We experiment with different numbers of training epochs from {600, 800, 1000}, and learning rates chosen from {1e-2, 5e-2, 1e-4, 5e-4, 1e - 6, 1e - 8} for all the methods. Moreover, we set the value of \u03b3 as {0.05, 0.05, 0.01, 0.01} for Citeseer, Cora, Flickr, and Reddit, respectively. Additionally, we set t1, t2, and t_\u0398 as {20, 15, 10} for Cora and Citeseer, and {20, 10, 20} for Flickr and Reddit, respectively.", "content": "B. Can TinyGraph achieve comparable performance with baselines using the original features?\nIn this subsection, we present the experimental results to validate the performance of the condensed graph on node classification tasks, as shown in Table II. Table III lists the performance of different GNN frameworks trained on the original graph. From the results, it can be observed that \u25cf GNN trained with TinyGraph can achieve comparable performance to GCond that trained with full features, at the same node condensation rate r_n. Specifically, TinyGraph achieves test accuracies of up to 97.5% on Citeseer and 98.7% on Flickr, while reducing the graph size by 99.9% and feature size up to 90%. This demonstrates the effectiveness of our proposed approach in condensing graph features while preserving important information. Overall, these results provide strong evidence for the utility of TinyGraph in tackling the challenges of training GNNs on large-scale graphs.\nC. Can TinyGraph archive better performance compared"}]}