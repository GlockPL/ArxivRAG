{"title": "TinyGraph: Joint Feature and Node Condensation for Graph Neural Networks", "authors": ["Yezi Liu", "Yanning Shen"], "abstract": "Training graph neural networks (GNNs) on large- scale graphs can be challenging due to the high computational expense caused by the massive number of nodes and high- dimensional nodal features. Existing graph condensation studies tackle this problem only by reducing the number of nodes in the graph. However, the resulting condensed graph data can still be cumbersome. Specifically, although the nodes of the Citeseer dataset are reduced to 0.9% (30 nodes) in training, the number of features is 3,703, severely exceeding the training sample magnitude. Faced with this challenge, we study the problem of joint condensation for both features and nodes in large-scale graphs. This task is challenging mainly due to 1) the intertwined nature of the node features and the graph structure calls for the feature condensation solver to be structure-aware; and 2) the difficulty of keeping useful information in the condensed graph. To address these challenges, we propose a novel framework TinyGraph, to condense features and nodes simultaneously in graphs. Specifically, we cast the problem as matching the gradients of GNN weights trained on the condensed graph and the gradients obtained from training over the original graph, where the feature condensation is achieved by a trainable function. The condensed graph obtained by minimizing the matching loss along the training trajectory can henceforth retain critical information in the original graph. Extensive experiments were carried out to demonstrate the effectiveness of the proposed TinyGraph. For example, a GNN trained with TinyGraph retains 98.5% and 97.5% of the original test accuracy on the Cora and Citeseer datasets, respectively, while significantly reducing the number of nodes by 97.4% and 98.2%, and the number of features by 90.0% on both datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Graphs have been extensively employed in modeling structured or relational real-world data [1, 2, 3], encom- passing various domains such as social network analysis [4, 5], recommendation systems [6, 7], drug discovery [8, 9, 10], transportation forecasting [11], and epidemiology [12]. Despite the success of GNNs in capturing abounding information in graph data [13, 14], training GNNs on real-world graphs containing large numbers of nodes and edges can be costly in terms of computational resources and time due to the complex sparse multiplication operations involved in train- ing [15, 16, 17]. This problem is further compounded by the high-dimensional features that are common in graph data. More remarkably, the storage and time demands are magnified under the setting of automated machine learning [18, 19], e.g., neural architecture search and hyperparameter optimization, where the GNN models need to be retrained for multiple times. One feasible idea to address these challenges is to condense the graph into a small graph so that it can save storage while facilitating the GNN training.\nRecent studies on graph condensation mainly focus on reducing the number of nodes in large-scale graphs [20, 21, 22]. An early work [23] proposes a data condensation algorithm to reduce the training samples of image datasets. A more recent work [20] generalizes the data condensation problem to the graph domain and designs a graph condensation framework that aims to compress the node size in a large graph. Furthermore, a one-step gradient matching strategy has been proposed to improve the efficiency of graph condensation [24]. However, existing graph condensation frameworks solely condense node size, which may be insufficient and still require large computa- tion resources and storage when training over graphs where the nodal features are high-dimensional. For example, the number of features is 41 times that of the number of nodes in Cora, 123 times in Citeseer, 11.2 times in Flickr, and 7.8 times in Reddit. Such high dimensional features still lead to large weight matrices in GNN training. Hence only reducing the node size does not thoroughly resolve the issue of the high computational cost of GNN training. As such, there is a crucial demand to effectively address the challenges posed by high-dimensional features in large-scale graph datasets.\nIn essence, to develop a structure-aware joint condensation framework for graph data, we are faced with two main challenges: 1) how to learn a tiny graph with fewer nodes and features that are still informative, so that the GNN trained on the tiny graph can achieve comparable accuracy with that trained on the original graph, and 2) how to formulate the optimization problem and update rules for the joint"}, {"title": "condensation task that efficiently learns the condensed graph structure and features", "content": "The first challenge centers around what needs to be learned and preserved from the original graph data while learning the condensed graph. One simple idea would be conducting the node and feature condensation sequentially by applying a two-stage framework, where one can carry out graph- condensation algorithms after dimensionality reduction is done on the nodal features. However, such a framework will likely lose critical information as structure-agnostic dimensionality reduction does not use the structural information often useful for graph-based learning. In addition, such a two-stage algorithm may result in error propagation if too much information is lost in the first stage. The second challenge lies in how to circumvent the high computational complexity of multi-level optimization involved in joint condensation, as the learning procedure often requires updating the optimized parameters for GNN trained on the condensed graph as well as the trainable condensed graph in an iterative manner.\nTo this end, we propose a novel joint graph condensation framework as illustrated in Figure 1. For the first challenge, we propose a unified framework TinyGraph, to simultaneously condense nodes and features. TinyGraph employs a gradient matching technique to enforce the gradients of the condensed graph to be as close as possible to the original graph along the training trajectory, and thus the learned condensed graph can be informative to train an accurate GNN. For the second challenge, TinyGraph does not rely on solving an optimization of the inner problem first and then an outer problem but only solves a gradient matching loss minimization problem for the learning task. The goal of TinyGraph is to simultaneously condense nodes and features in a large graph while retaining useful information in the condensed graph. It synchronizes the GNN training trajectories of the two graphs through an optimization of a matching loss. This approach ensures that the condensed graph is consistent with the original graph and preserves the relationships between nodes. This study makes the following major contributions:\n\u2022 We address the challenge that arises when training GNNs on large-scale graphs with high-dimensional features, which persists even in existing graph condensation methods.\n\u2022 Instead of a two-stage technique, we propose a unified framework that condenses both nodes and features simulta- neously. Specifically, a structure-aware feature condensation framework is designed that can efficiently take the graph structure into consideration.\n\u2022 TinyGraph is able to achieve remarkable test accuracy of 98.5%, 97.5%, 98.7%, 94.9%, and 86.5%, meanwhile significantly reducing the node size by more than 97.4% and the corresponding feature sizes by 90%, 90%, 80%, 70%, and 70%, on Cora, Citeseer, Flickr, Reddit, and Arxiv, respectively."}, {"title": "II. PROBLEM FORMULATION", "content": "Notations. Given a graph dataset T = {A, X, Y}, where A \\in \\mathbb{R}^{N \\times N} is the adjacency matrix, N is the number of nodes, X \\in \\mathbb{R}^{N \\times D} is the node feature matrix and Y \\in {0,...,C-1}^N denotes the node labels over C classes, \\Theta represents a GNN model parameterized by \\theta, L denote the node classification loss (i.e., cross-entropy loss) that measures the discrepancy between predictions and the ground truth.\nGoal. We aim to learn a tiny, condensed graph S = {\\hat{A}, \\hat{X}, \\hat{Y}} with \\hat{A} \\in \\mathbb{R}^{n \\times n}, \\hat{X} \\in \\mathbb{R}^{n \\times d}, \\hat{Y} \\in {0,...,C - 1}^n, with n << N, and d << D, such that a GNN trained on S can achieve comparable performance to one trained on the original graph T. It is necessary for the larger graph to have the same feature dimension as S to match the input dimension of GNN.\nProblem Formulation. To achieve this goal, we introduce a trainable feature condensation function f(\\cdot) : \\mathbb{R}^{D} \\rightarrow \\mathbb{R}^{d}, parameterized on \\Phi. By projecting the original feature matrix X through this function, we obtain the feature-condensed graph \\tilde{T} = (A, f_{\\Phi}(X), Y), which retains the key information from the full graph T. This allows our proposed framework to establish an association between the original graph T and the condensed graph S through this function f_{\\Phi}(\\cdot). To ensure comparable performance achieved by training on the condensed graph and the original graph, we draw inspiration from prior studies [25, 26, 27, 28], that models the parameters \\theta_S as a function of the synthetic data S. Henceforth, we approach the joint condensation problem by training a GNN on the trainable condensed graph S, based on which the feature condensation function parameterized by \\Phi^* and condensed graph S^* is obtained by minimizing the loss. The objective of the joint condensation problem can be formularized as follows:\n\\begin{equation}\n\\begin{aligned}\nS^* &= \\underset{S}{\\text{arg min}} \\mathcal{L}(GNN_{\\theta_S} (\\hat{A}, f_{\\Phi^*}(X)), Y), \\\\\ns.t. \\Phi^* &= \\underset{\\Phi}{\\text{arg min}} \\mathcal{L}(GNN_{\\theta_S} (\\hat{A}, f_{\\Phi}(X)), Y), \\\\\n\\theta_S &= \\underset{\\theta_S}{\\text{arg min}} \\mathcal{L}(GNN_{\\theta_S} (\\hat{A}, \\hat{X}), \\hat{Y}).\n\\end{aligned}\n\\end{equation}\nNote that the optimization in Equation (1) necessitates solving a nested-loop optimization problem. Specifically, this involves iteratively updating \\theta_S while performing computa- tionally expensive computations of the gradient of the trainable condensed graph S, i.e., \\mathcal{L}_S, which is obtained by calculating the discrepancies between the model predictions and the ground truth for S. For calculating \\mathcal{L}, We employ the cross-entropy loss. These computations are carried out over multiple updates within each iteration.\nHowever, this procedure encounters scalability issues when applied to large graphs with a substantial number of opti- mization steps in the inner loop. The computational burden imposed by these iterations becomes increasingly prohibitive as the graph size grows. To address this limitation, we propose an alternative algorithm in the subsequent section. Our approach follows the gradient matching strategy [29], which aims to overcome the scalability challenges in nested-loop optimization and offers an efficient solution to the joint condensation."}, {"title": "III. PROPOSED ALGORITHM", "content": "In this section, we introduce a novel algorithm TinyGraph to solve the problem in Equation (1).\nA. Structure-aware feature condensation\nGraph data presents unique challenges for traditional di- mensionality reduction (DR) methods. Principal Component Analysis (PCA) [30], or Independent Component Analysis (ICA) [31] are two typical and widely used DR methods. Others include linear and nonlinear techniques, unsupervised and supervised methods, and matrix factorization and manifold learning approaches. They have been shown promising results in abstracting primary features in various research disciplines, such as on image data [32, 33], text data [34, 35], as well as biological or health data [36]. However, their applications are limited to Euclidean data where samples are independent and thus are not well-suited for graph data where nodes are interlaced with others based on graph structure. Therefore, grafting these methods for graph data is not feasible, and it is necessary to design a structure-aware algorithm for high- dimensional graph data. To better capture the graph structure in the condensation process, we adopt a graph attention function [37] as the feature condensation function, which contains multiple graph attention networks (GAT) layers. GAT is an attention-based GNN model that leverages attention mechanisms to assign precise weights during the aggregation of neighboring node information pertaining to a given target node. By incorporating the fine-grained weight assignment capability of GAT, the proposed approach aims to improve the accuracy and comprehensiveness of the graph condensation process.\nGraph Attention Networks as Feature Condensation Function. The graph attentive network in the condensation framework is denoted as GAT_{\\Phi_t}. It is parameterized by \\Phi_t and maps the original features X to the trainable condensed features \\hat{X}_t = GAT_{\\Phi_t}(X). The graph that contains the trainable condensed features, is referred to as a trainable condensed graph denoted by \\tilde{T} = (A, \\hat{X}_t, Y). During each training epoch t, the node representation of node v_i is obtained. For brevity, the epoch index t will be omitted in the subsequent notations pertaining to the calculation of the Graph Attentive Encoder [38]. Within each layer of the GAE, denoted by l, node v_i integrates the features of its neighboring nodes to acquire representations for the subsequent layer, h_i^{l + 1}, through the following process:\n\\begin{equation}\nh_i^{l+1} = \\sigma\\left(\\sum_{j \\in N_i \\cup \\{v_i\\}} \\alpha_{ij}^l W^l h_j^l\\right),\n\\end{equation}\nwhere h_i^{l+1} represents the representation of node v_i in layer l + 1, N_i denotes the set of neighboring nodes of v_i, W^l represents a weight matrix associated with layer l, and \\sigma denotes a nonlinear activation function (e.g., ReLU), and \\alpha_{ij}^l is an attention coefficient that determines the importance of neighboring node v_j to node v_i in layer l, which can be computed as:\n\\begin{equation}\n\\alpha_{ij}^l = \\frac{\\exp \\left( \\sigma \\left( a^T[W^l h_i^l \\oplus W^l h_j^l] \\right) \\right)}{\\sum_{k \\in N_i \\cup \\{v_i\\}} \\exp \\left( \\sigma \\left( a^T[W^l h_i^l \\oplus W^l h_k^l] \\right) \\right)},\n\\end{equation}\nwhere W and W_t represent weight matrices, and h_i^l and h_j^l denote the hidden states of nodes v_i and v_j in layer l, respectively. The symbol \\oplus denotes the concatenation operation. The term a represents a trainable parameter vector that allows the model to learn the importance of different node relationships. Furthermore, in order to enhance the expressive power of our model, we incorporate multiple GAT layers into GAE. The computation of the latent representation, denoted as z_i, for each node i is performed as follows:\n\\begin{equation}\n\\hat{x}_i = \\sigma\\left( \\sum_{j \\in N_i \\cup \\{v_i\\}} W^L h_j^{L-1} \\right),\n\\end{equation}\nwhere \\hat{x}_i \\in \\mathbb{R}^{d} (d << D) is the trainable condensed feature of node i, and h_j^{L-1} is the hidden representation of node j at layer L - 1. We initialize the first layer by setting h_j^0 = x_j, which is the nodal feature of node i. In each training epoch, we encode the original feature matrix X using the GAE. By employing GAE, the proposed condensation framework is capable of learning the condensed feature while considering the underlying graph structure. By incorporating"}, {"title": "multiple GAT layers, TinyGraph leverages the interplay between nodal attributes and the graph topology, our model captures the intricate non-linear relationships present in the graph", "content": "This enhanced representation learning capability is essential for addressing the complexities of real-world graph data and facilitating downstream tasks that rely on learning an accurate condensed graph.\nB. Gradient Matching\nNote that the objective of this study is to learn a condensed graph, denoted as S, that allows the trained model to converge to a solution similar to that of an optimized parameter space represented by \\tilde{T}. To this end, an intuitive optimization approach is to align the optimal GNN parameters trained from the trainable feature-condensed graph and the trainable condesed graph, denoted as \\theta_{\\tilde{T}}^t and \\theta_S^t, respectively, In this way, the resulting optimized parameters converge to a comparable solution:\n\\begin{equation}\n\\begin{aligned}\n\\underset{S,\\Phi}{\\text{min}} M(\\theta_S^t, \\theta_{\\tilde{T}}^t) \\\\\ns.t. \\theta_S = \\underset{\\theta_S}{\\text{arg min}} \\mathcal{L}(GNN_{\\theta_S} (\\hat{A}, \\hat{X}), \\hat{Y}), \\\\\nand \\theta_{\\tilde{T}} = \\underset{\\theta_{\\tilde{T}}}{\\text{arg min}} \\mathcal{L}(GNN_{\\theta_{\\tilde{T}}} (A, f_{\\Phi}(X)), Y),\n\\end{aligned}\n\\end{equation}\nwhere the objective is to minimize the matching loss M(\\cdot,\\cdot) with respect to the optimal parameters \\theta_{\\tilde{T}}^t and \\theta_S^t, which are associated with the condensed graph and the model GNN_{\\theta_{\\tilde{T}}}, respectively. The optimization of Equation (2) aims to obtain a trainable condensed graph S for the GNN model that is parameterized by \\theta_{\\tilde{T}}^t. However, the effectiveness of \\theta_{\\tilde{T}}^t is influenced by its initial value \\theta_{\\tilde{T}}^0. Consequently, the objective function in Equation (2) optimizes over a single model initialized with the initial weights \\theta_{\\tilde{T}}^0. Our objective is to ensure that \\theta_S^t not only closely approximates the final value of \\theta_{\\tilde{T}}^t, but also follows a similar trajectory to the parameter values \\theta_{\\tilde{T}}^t at time t throughout the optimization process.\nCurriculum Gradient Matching. In order to enhance the learning process and improve optimization outcomes, we adopt curriculum gradient matching [25]. This technique aims to align the training trajectories of T and S, throughout each epoch of the training process, achieved by quantifying the disparity between their respective gradients. By employing curriculum gradient matching, the problem in Equation (2) can be reformulated as:\n\\begin{equation}\n\\underset{S}{\\text{min}} E_{\\theta_{\\tilde{T}}^0 \\sim \\mathcal{U}(Q_{\\theta_{\\tilde{T}}^0})} \\left[\\sum_{t=0}^{T-1} M(\\theta_{\\tilde{T}}^{t+1}, \\theta_{S}^{t+1})\\right]\n\\end{equation}\nwith \\theta_{S}^{t+1} = \\theta_{S}^{t} - \\eta \\nabla_{\\theta} \\mathcal{L}(GNN_{\\theta} (\\hat{A}, \\hat{X}), \\hat{Y}),\nand \\theta_{\\tilde{T}}^{t+1} = \\theta_{\\tilde{T}}^{t} - \\eta \\nabla_{\\theta} \\mathcal{L}(GNN_{\\theta} (A, f_{\\Phi}(X)), Y),\nwhere GNN_{\\theta} denotes the GNN model parameterized with \\theta, \\eta is the learning rate for the gradient descent. This approximation method eliminates the need for computationally expensive unrolling of the recursive computation graph over the previous parameters, denoted as \\theta_{\\tilde{T}}^0,...,\\theta_{\\tilde{T}}^{t-1}. Consequently,"}, {"title": "the optimization technique demonstrates significantly enhanced speed, improved memory efficiency, and the ability to scale up to the joint condensation", "content": "By minimizing M to a near-zero value, we aim to obtain the optimal \\theta_S^{t+1} = \\theta_{\\tilde{T}}^{t+1}, which is parameterized by S, by emulating the training of \\theta_{\\tilde{T}}^{t+1}.\nGradient Matching Loss. Based on the optimization approach described earlier, we propose the utilization of a gradient- matching loss to update the trainable parameters. In this context, we have two losses: \\mathcal{L}_{\\tilde{T}} and \\mathcal{L}_S, which represent the discrepancies between the model predictions and the ground truth for the transformed original graph and the trainable condensed graph, respectively. For calculating \\mathcal{L}, We employ the cross-entropy loss. To update the weights of GNN, we calculate the gradients of the losses with respect to the GNN weights. Specifically, we denote these gradients as G_{\\tilde{T}} and G_S, which are obtained through the respective expressions: G_{\\tilde{T}} = \\nabla_{\\theta} \\mathcal{L}(GNN_{\\theta} (A, f_{\\Phi}(X)), Y) and G_S = \\nabla_{\\theta} \\mathcal{L}(GNN_{\\theta} (\\hat{A}, \\hat{X}), \\hat{Y}).\nThe gradient matching loss M quantifies the dissimilarity between the gradients of the source network and the target network training. To calculate the gradient matching loss M, we consider each individual class c separately. For a given class c, the gradient distance is determined by computing the Cosine Distance between the corresponding columns of the gradient matrices, i.e., G_{\\tilde{T}}^c and G_S^c. These matrices represent the gradients of the sampled graphs T and S^c of a class c, derived from the original graph and condensed graph, respectively. This Cosine Distance captures the disparity in the way class-specific information is represented in the two graphs. By assessing the Cosine Distance between the gradient columns, we quantify the dissimilarity between the gradient directions associated with class c in the original and condensed graphs. By summing the gradient distances across all classes, the gradient matching loss M provides a comprehensive assessment of the overall dissimilarity between the networks. Mathematically, the gradient matching loss M can be formulated as follows:\n\\begin{equation}\nM(G_{\\tilde{T}}^t, G_S^t) = \\sum_{c=0}^{C-1} M^c,\n\\end{equation}\nwith M^c = \\frac{1}{H} \\sum_{p=1}^{H} \\sum_{h=1}^{P}\\left(1 - \\frac{G_{\\tilde{T}h,p}^c \\cdot G_{Sh,p}^c}{\\left|\\left| G_{\\tilde{T}h,p}^c \\right|\\right| \\cdot \\left|\\left| G_{Sh,p}^c \\right|\\right|} \\right),\nwhere G_{\\tilde{T}h,p}^c and G_{Sh,p}^c are the h-th column vectors of the gradient matrices for the class c, at layer p. In the subsequent subsection, we delve deeper into the practical implementation and utilization of the gradient-matching process, discussing how it is integrated into our framework to enhance the overall condensation procedure and optimize the trainable parameters.\nC. Model Optimization\nThe standard large-batch optimization process poses chal- lenges for reconstruction tasks and necessitates substantial memory usage [39]. To address this, we adopt a strategy where a mini-batch of graph data is sampled at each layer of GNN. Subsequently, we compute the gradient-matching loss for each class independently. Specifically, to handle a specific class"}, {"title": "c, TinyGraph selects a batch of nodes and their corresponding neighbors from the transformed original graph T, denoted as \\tilde{T}^c \\sim \\tilde{T}", "content": "Likewise, TinyGraph samples a batch of condensed nodes from the condensed graph S = {\\hat{A}, \\hat{X}, Y} and incorporates all of their neighbors, denoted as S^c \\sim S.\nDespite these measures, the training process remains chal- lenging primarily due to the significant complexity introduced by learning graph structure. This complexity stems from factors such as intricate relationships between nodes, intricate connectivity patterns, and the need to capture graph-specific features. Hence, in the following, we will further navigate these challenges and improve the effectiveness of joint condensation.\nParameterizing Graph Structure. Treating A and X as free parameters will lead to overfitting caused by learning a large number of parameters in the order of O(n^2). In order to alleviate the computational complexity associated with optimizing the quadratic model of A \\in \\mathbb{R}^{n \\times n}, we model \\hat{A} as a function \\Psi, denoted by g_{\\Psi}(\\cdot), which is parameterized by \\Psi [20], i.e.:\n\\begin{equation}\n\\hat{A}_{ij} = g_{\\Psi}(X_{ij}) = \\sigma\\left(\\frac{k_{\\Psi}(z) + k_{\\Psi}(z')}{2}\\right)\n\\end{equation}\nwhere both vectors z := [\\hat{x}_i; \\hat{x}_j] and z' := [x_i; x_j] are elements of \\mathbb{R}^{1 \\times 2d}. The function k_{\\Psi}(\\cdot) denotes a multi-layer neural network (MLP) parameterized by \\Psi, and \\sigma(\\cdot) represents a sigmoid activation function. This method offers the scalability to expand the condensed graph by incorporating additional synthetic nodes derived from the real graph. In this expansion process, the trained g_{\\Psi}(\\cdot) can be effectively utilized to infer the connections of the newly added synthetic nodes. As a result, we only need to focus on learning the distinctive features of these new nodes, while leveraging the existing graph structure and connections inferred by g(\\Psi).\nBuilding upon the aforementioned elucidation, we articu- late the ultimate objective of the proposed framework. This objective is formulated based on an empirical observation: the proximity between \\theta_{\\tilde{T}}^t and \\theta_S^t is typically small. Consequently, we couple them and replace them with \\theta^t, denoting the GNN weights trained on S at time t. In light of this, we can simplify the objective presented in Equation (3) by treating it as a gradient-matching process. This process can be represented in the following manner:\n\\underset{\\mathcal{X},\\Phi,\\Psi}{\\text{min}} E \\left[\\sum_{t=0}^{T-1} M\\left(\\nabla_{\\theta^t} \\mathcal{L} (GNN_{\\theta^t} (g_{\\Psi} (X), \\hat{X}), \\hat{Y}),\\\\\n\\nabla_{\\theta^t} \\mathcal{L} (GNN_{\\theta^t} (A, f_{\\Phi} (X)), Y)\\right)\\right].\nThe loss function M combines the gradients of \\mathcal{L} with respect to the parameters \\theta for both input cases. The minimization of this loss function drives the optimization process, influencing the updates made to the variables \\hat{X}, \\Phi, and \\Psi. Figure 2 provides an overview of our proposed framework and depicts the optimization process visually.\nAlternative Optimization Strategy. Optimizing \\hat{X}, \\Psi, and \\Phi simultaneously can be a challenging task due to their interdependence. To overcome this challenge, we employ an alternative optimization strategy in our research. Our approach aims to iteratively update the parameters \\Phi, \\Psi, and \\hat{X} in distinct time periods. At each epoch, our method begins by updating the feature condensation function \\Phi. Following this, for the first t_1 training epochs, we focus on updating \\Psi. Then we proceed to update the condensed features \\hat{X} for the subsequent t_2 epochs.\nImportantly, the parameters are updated asynchronously at different epochs, reflecting their interdependence. This asynchronous updating scheme allows us to leverage the information and progress made in the previous phases, leading to more effective optimization. We iterate this process until a predefined stopping condition is met, such as reaching a convergence criterion or completing a fixed number of epochs:\n\\begin{equation}\n\\begin{aligned}\n\\Phi_{t+1} &= \\Phi_t - \\eta_1 \\nabla_{\\Phi^t} M (\\text{every epoch}), \\\\\n\\Psi_{t+1} &= \\Psi_t - \\eta_2 \\nabla_{\\Psi^t} M (t_1 \\text{epochs}), \\\\\n\\hat{X}_{t+1} &= \\hat{X}_t - \\eta_3 \\nabla_{\\hat{X}^t} M (t_2 \\text{epochs}).\n\\end{aligned}\n\\end{equation}\nThis iterative optimization strategy ensures that each pa- rameter is updated strategically, accounting for their mutual influence and optimizing the overall performance of the model.\nModel Initialization. For the initialization of trainable pa- rameters in the joint condensation, we centralize original features by X' = X(I_D - \\frac{1}{1_N 1_N^T}). To simplify the joint condensation, we fix the node labels \\hat{Y} while keeping the class distribution as original labels Y. For the initialization of the trainable condensed graph, we use graph sampling. We first sample a subset of nodes from the trainable condensed graph \\tilde{T} = (A, \\hat{X}, Y), where \\hat{X} = f_{\\Phi}(X) \\in \\mathbb{R}^{N \\times d} is the trainable condensed feature. The number of sampled nodes from each class is set to preserve the distribution of the labels. Learning all four variables, namely \\hat{X}, \\hat{Y}, \\Phi, and \\Psi, poses significant challenges. To simplify the problem, we fix the node labels Y after initialization, and the feature vectors corresponding to \\hat{Y} are used to initialize \\hat{X} \\in \\mathbb{R}^{n \\times d}.\nAlgorithm Implementation. In our algorithm, we follow a series of steps to implement the TinyGraph framework. We begin by initializing the GNN model parameter \\theta^0, which is sampled from a uniform distribution Q_{\\theta} based on \\theta^0. Next, we proceed with the sampling of node batches from the labeled training graph T and the condensed graph S for each class. These batches serve as input for the subsequent computations. Within each class, we calculate the gradient matching loss. The losses obtained from each class are summed up and then used to update specific parameters such as \\Phi, \\hat{X}, and \\Psi. Once the condensed graph parameters have been updated, the GNN parameters are updated for a specified number of epochs t_e. During this phase, the GNN model is fine-tuned to improve its performance. Finally, to obtain the final sparsified graph structure, we apply a filtering step. We discard edge weights that fall below a predetermined threshold \\gamma. This filtering process helps in simplifying the graph representation and reducing unnecessary edges. The detailed algorithm of TinyGraph is summarized in Algorithm 1.\nD. Discussion on the Differences from Related Studies\nIn this subsection, we further discuss the novelty of the proposed TinyGraph compared with node condensation methods and two-stage condensation approaches."}, {"title": "Comparison with Node Condensation Methods", "content": "Various recent works have focused on reducing the size of data while preserving essential information, such as data con- densation methods [20, 23, 24, 40] and graph compression methods [41, 42]. However, these methods overlook the high dimensionality of nodal features in real-world graphs. In contrast, our proposed method addresses both feature and node condensation, achieving significant storage reduction of 75.3%, 83.3%, 87.0%, 87.8%, and 51% on Cora, Citeseer, Flickr, Reddit, and Arxiv, respectively, when compared to the existing node condensation framework GCond.\nTwo-stage Condensation Approaches. Two-stage conden- sation approaches directly apply dimensionality reduction methods [30, 31, 43, 44, 45, 46, 47, 48] to node condensation frameworks, which are insufficient due to the structure-agnostic nature in their feature condensation process. Compared to these approaches, TinyGraph offers two key advantages in feature condensation: 1) the feature and node condensation are learned through unified optimization, enabling structure awareness in feature condensation, and 2) TinyGraph utilizes a learnable projection function for feature condensation, offering greater flexibility than fixed projection matrices used in DR methods."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we conduct experiments with five real- world graphs to evaluate TinyGraph. The main observations in experiments are highlighted as boldface.\nA. Experimental setup.\nDatasets. We evaluate the efficacy of our proposed method over three transductive datasets, i.e., Cora, Citeseer [49], and Arxiv [50], as well as two inductive datasets, i.e., Flickr [51] and Reddit [4]. For consistency and fair comparisons, we utilized all the datasets provided by PyTorch Geometric[52], following the publicly available data splits, as widely adopted by previous studies [4]. Note that the employed experimental setup is outlined in [4]. We also present the detailed statistics of the used in Table I.\nBaselines. We conducted a comprehensive comparative analysis between our proposed method, TinyGraph, and seven baseline approaches, which are: (1) a model that utilizes the original graph structure and node features without any condensation for training; (2) and (3) two unsupervised classical methods for density-based clustering, which employ condensed graph structures and complete node features, namely GCond [20] and GraphPCA [53]; (4) GCond-ICA, (5) GCond-PCA, and (6) GCond- LDA, which incorporate GCond with feature condensation by projecting the original features through a fixed feature con- densation matrix based on Independent Component Analysis (ICA) [31], Principal Component Analysis (PCA) [30], and Linear Discriminant Analysis (LDA) [44], respectively. (7) Additionally, we consider a deep-learning approach, namely the Variational Graph Autoencoder (VGAE) [54], and utilizes its latent representation as a condensed feature along with the GCond, denoted as GCond-VGAE. To sum up, (1) does not involve any condensation process, while (2)-(3) implement node condensation through GCond and GraphPCA, and (4)- (7) implement node condensation through GCond and feature condensation by the corresponding algorithm. It is worth noting that for methods (4)-(7), where both feature size and node size condensation are involved, we perform feature condensation prior to node size condensation.\nEvaluation. To evaluate the effectiveness of condensed graphs, our approach involves several steps. Firstly, we obtain the condensed graph for the original training graph via each algorithm. Then we utilize the trained GNN model to infer labels for the test nodes on the entire graph. Note that the training graph corresponds to the complete graph in the transductive setting. The performance of the algorithm is then assessed by measuring the test accuracy. For the trainable condensed graph, we retain r_n \\times N nodes for all algorithms, where r_n represents the node condensation ratio, satisfying the condition 0 < r_n < 1. Similarly, for baselines utilizing condensed features, the learned condensed graph has r_n \\times N nodes and r_d \\times D features. The parameter r_d (0 < r_d < 1) signifies the ratio of condensed features to the original features. For the transductive setting, we utilize the full graph in the condensation process since the full graph is available in training. For the inductive setting, when only the training graph is"}, {"title": "available in training, we only condense the training graph", "content": "Hyperparameter settings. To implement TinyGraph, we employ a 2-layer Simplified Graph Convolution (SGC) [55] with 256 hidden units as the GNN backbone. To capture the relationship between A and X, we utilize a multi-layer perceptron (MLP) function, g_{\\Psi}(\\cdot). Specifically, for smaller graphs such as Cora and Citeseer, g_{\\Psi}(\\cdot) is a 3-layer MLP with 128 hidden units in each hidden layer, while for larger graphs like Flickr and Reddit, we employ a 3-layer MLP with 256 hidden units. We experiment with different numbers of training epochs from {600, 800, 1000}, and learning rates chosen from {1e-2, 5e- 2, 1e-4, 5e-4, 1e - 6, 1e - 8} for all the methods. Moreover, we set the value of \\gamma as {0.05, 0.05, 0.01, 0.01} for Citeseer, Cora, Flickr, and Reddit, respectively. Additionally, we set t1, t2, and t0 as {20, 15, 10} for Cora and Citeseer, and {20, 10, 20} for Flickr and Reddit, respectively.\nB. Can TinyGraph achieve comparable performance with base- lines using the original features?\nIn this subsection, we present the experimental results to validate the performance of the condensed graph on node classification tasks, as shown in Table II. Table III lists the performance of different GNN frameworks trained on the original graph. From the results, it can be observed that\n\u25cf GNN trained with TinyGraph can achieve comparable performance to GCond that trained with full features, at the same node condensation rate r_n. Specifically, TinyGraph achieves test accuracies of up to 97.5% on Citeseer and 98.7% on Flickr, while reducing the graph size by 99.9% and feature size up to 90%. This demonstrates the effectiveness of our proposed approach in condensing graph features while preserving important information. Overall, these results provide strong evidence for the utility of TinyGraph in tackling the challenges of training GNNs on large-scale graphs.\nC. Can TinyGraph archive better performance compared to structure-agnostic feature condensation baselines?\nTo answer this question, we compare TinyGraph with other baselines that use feature preprocesses as dimensionality reduction methods and present the results in Table II. From the results, we notice that TinyGraph consistently obtains the best performance among all feature condensation baselines. This demonstrates the key role of structural information in feature condensation. At the same time, we notice that on Reddit, GCond-VGAE can achieve comparable performance with TinyGraph. This implies that the original training graph structure of Reddit might not be useful. To verify this assumption, we train a GCN on the original Reddit dataset without using graph structure (i.e., setting A_train = I), but only use the test graph structure for inference using the trained model. The obtained performance is 90.1%, which is indeed close to the original 93.9%, indicating that training without graph structure can still achieve comparable performance. In addition, on the other three datasets, TinyGraph outperforms baselines that directly apply dimensionality reduction as a preprocessing method on the original feature, i.e., GCond-ICA, GCond-PCA, GCond-LDA, and GCond-VGAE. The reason lies in the fact that these four methods condense the feature independently from the graph structure. However, the correlation between feature and graph information is well known in literature [56, 57], overlooking the impact will lead to bad performance. TinyGraph jointly condenses features and nodes so it retains this relevance between features and structure.\nD. How many features are needed for TinyGraph to achieve equal performance with full-feature baselines?\nTo answer this question, we conducted experiments to demon- strate the effectiveness of TinyGraph for feature condensation across a range of feature condensing ratios r_d from 10% to 90%. We report our observations in Figure 3, which shows that our proposed method outperforms the baseline methods across all feature condensing ratios tested. These results highlight the benefits of our proposed method for feature condensation, particularly in scenarios where the number of training nodes is limited, and feature dimensionality is high. We have the following two observations: TinyGraph achieves equivalent performance while only utilizing 50%, 30%, 70%, and 90% of the original feature size. And even when r_d is small enough, TinyGraph can still reach a high test accuracy compared to GCond that uses full features. Specifically, 10% in Cora, 10% in Citeseer, 20% in Flickr, 30% in Reddit, and 30% in Arxiv, the proposed TinyGraph is still able to perform the comparable performance (95% of the test accuracy) comparing to GCond using the full-feature graph. Larger feature size does not necessarily obtain better performance. The performance of TinyGraph varies with the number of training nodes in each dataset. When the number of training nodes is small, such as 35 and 30 in Cora and Citeseer, TinyGraph achieves the best performance with fewer features. However, for larger datasets like Flickr and Reddit, with 44, 625 and 153, 932 training nodes, respectively, TinyGraph performs best with a larger r_d. This behavior occurs because as the number of training nodes increases, a larger reduced dimensionality is needed to capture the complex relationships between the nodes. Therefore, for large datasets, it is necessary to use a larger r_d to ensure optimal performance.\nE. What is the effect of GAT compared to other feature condensation functions? An Ablation study.\nTo address this question, we explored multiple implementa- tions of TinyGraph, incorporating variations in the GAT function. These variants included: (1) a linear feature condensation function denoted as TinyGraph-Lin, (2) multi-layer perceptrons (MLPs) denoted as TinyGraph-MLP, and (3) graph convolutional networks (GCNs) denoted as TinyGraph-GCN. Additionally, we also consider another graph condensation framework based on one-step gradient matching [24]. Specifically, this method does not simulate the entire training trajectory of the original graph, which matches gradients at every epoch, but it only utilizes the gradient matching of the initial epoch. Based on this framework, we derive another variant of our method, (4) TinyGraph-One. Table IV presents a comprehensive analysis, revealing that TinyGraph consistently outperforms all other variants across five datasets, highlighting the efficacy of"}, {"title": "the chosen GAT function", "content": "Notably, on Cora and Citeseer, both characterized by a limited number of training nodes and abundant features, simple linear feature condensation functions and MLPs yield impressive performance. The potential reason behind this observation is that the smaller-scale graphs (i.e., Cora and Citeseer) with large feature sizes are easy to condense, which has less requirement on the choice of feature condensation functions. The rationale behind this observation lies in the relative ease of feature condensation due to the smaller scale of training nodes in Cora and Citeseer with ample features, i.e., (D >> n), rendering the feature condensation functions less stringent in their requirements. Conversely, Flickr and Reddit, with their substantial number of training nodes and fewer features, pose a significantly more challenging scenario for the process of condensing structural awareness. Consequently, the utilization of structure- aware feature condensation functions, such as GCN and GAT, becomes imperative.\nF. How does TinyGraph perform with various GNN models? A Generalizability Analysis.\nWe demonstrate the generalizability of the TinyGraph in this experiment. Specifically, we evaluate the test performance by employing one GNN model for feature condensation while performing the gradient matching on other GNN architectures, including the default architecture SGC used in Table II. The selected architectures for the gradient matching graph neural network, i.e., GNN(\\cdot), include APPNP [58], GCN, SGC [55], GraphSAGE [4], GAT [59], and MLP. The corresponding results are presented in Table V. Our analysis of the table reveals that the condensed graph yields good performance even outside the scope it was optimized for. This generaliz- ability can be attributed to the similarity in filtering behaviors among these GNN models, as extensively investigated in prior studies [60, 61]."}, {"title": "G", "content": "Will different feature condensation functions work with different GNN architectures for gradient matching?\nThe condensed graph obtained from different feature conden- sation functions (which are instantiated as different graph neural networks) demonstrates its potential applicability to various GNN models. To investigate this applicability of TinyGraph, we evaluate the performance of a condensed graph produced by one specific feature condensation function for the gradient matching utilizing alternative GNN architectures, (i.e., GCN, GraphSAGE, SGC, and APPNP). The results are illustrated in Figure 4, where the x-axis denotes GNN architecture for the feature condensation, and the y-axis represents the gradient matching performance measured by test accuracy of other GNN models. Our analysis reveals a noteworthy observation: the condensed graphs generated by different feature con- densation functions exhibit promising applicability across different gradient matching GNNs. This finding validates the versatility of the condensed graph and demonstrates the ability of TinyGraph to extract essential information from the original graph, resulting in a tiny condensed graph that retains practical utility for downstream tasks.\nH. What are the specific statistics of the condensed graph V.S. the original graph? \u2014 A Condensed Graph Analysis.\nIn Table VI, we present a comprehensive comparative anal- ysis that examines several attributes distinguishing condensed graphs from their original counterparts. Our research findings reveal significant insights in the following areas. Firstly, despite achieving comparable performance in downstream tasks, con- densed graphs exhibit notable reductions in node count and feature dimensionality, thereby demanding significantly less storage capacity. The feature size reduction is achieved while maintaining an accuracy level within acceptable tolerances. Secondly, the condensed graphs demonstrate a lower degree of sparsity compared to their larger counterparts. This observation arises due to the inherent challenge of maintaining the original level of sparsity in graphs that are significantly smaller in scale. Preserving the original sparsity in condensed graphs would result in minimal inter-node connections, which may hinder the effectiveness of the condensed graph.\nI. How is the quality of the learned feature by TinyGraph? \u2014 A Visualization of Condensed Features.\nTo address this question, we conducted a visual analysis of the t-SNE [43] embeddings derived from both the original features and the condensed features of the Cora and Citeseer datasets in Figure 5. The condensation ratios employed were set at 10% and 20%, denoted as r_d = 10% and r_d = 20%,"}, {"title": "respectively", "content": "Figure 5 shows that the condensed features learned by our proposed TinyGraph, exhibit distinct separable clusters while the original node feature is mixed together. This finding provides compelling evidence of TinyGraph\u2019s capability to learn highly discriminative features. Remarkably, upon closer examination of both datasets, the t-SNE plots reveal that the embeddings obtained with a condensation ratio of 10% demonstrate more discernible patterns compared to those obtained with a condensation ratio of 20%. This observation suggests that a smaller condensation ratio can yield even more discriminative features. The underlying reason lies in TinyGraph\u2019s ability to map nodes from different classes into distinct communities and thereby maximize the dissimilarity between the nodes within the same class.\nV. CONCLUSION\nIn this work, we introduce a new joint graph condensation framework, named TinyGraph. Unlike traditional approaches that only focus on condensing nodes, TinyGraph is designed to condense both nodes and features of a large-scale graph. Despite the condensation, it meticulously preserves the original graph information. To optimize the trainable condensed graph, we employ a gradient matching strategy, while a structure- aware dimensionality function is used to maintain the integrity of the graph structure. This dual condensation allows TinyGraph to achieve high test accuracies across various datasets, demon- strating its efficiency. TinyGraph has potential applications in training Graph Neural Networks on large-scale graphs. This is particularly relevant for graphs with massive nodes and high-dimensional features, where computational resources, such as memory and time, are limited.\nAPPENDIX\nA. Implementation Details\n1) Hyperparameter Setting: We present our hyperparameter configuration, encompassing three key stages: node conden-"}, {"title": "sation, feature condensation, and evaluation", "content": "Additionally, the hyperparameters are detailed in both Table V and Figure 4. Node Condensation: We compare our TinyGraph on two main methods, GraphPCA, and GCond.\nIn the context of TinyGraph, our approach involves the application of a 2-layer Simplified Graph Convolutional Net- work (SGC) with 256 hidden units, serving as the Graph Neural Network (GNN) for gradient matching. The function g_\\Psi, representing the relationship between A\u2019 and X\u2019, is implemented as a multi-layer perceptron (MLP). Specifically, we employ a 3-layer MLP with 128 hidden units for small graphs (Cora and Citeseer) and 256 hidden units for larger graphs (Flickr, Reddit, and Arxiv). We also explore various training epochs for TinyGraph, ranging from {400, 600, 1000}. For GraphPCA, we leverage the implementation available at 1, configuring 'add_supernode' as False and 'eigende- comp_strategy' as \u2018exact\u2019. In the case of GCond, we adopt a parameter setting similar to TinyGraph, as previously elucidated. We performed hyperparameter tuning for all methods by adjusting the learning rate, considering values within the range of {0.1, 0.01, 0.001, 0.0001}. Additionally, we assigned specific values to the parameter \u03b4 for different datasets: 0.05 for Citeseer, 0.05 for Cora, 0.01 for Arxiv, 0.01 for Flickr, and 0.01 for Reddit.\nAddressing the condensation ratio choices, our discussion is divided into two sections. The first section focuses on transductive datasets, posing challenges due to their low labeling rates. In the case of Cora and Citeseer, with labeling rates of only 5.2% and 3.6%, respectively, we expressed condensation ratios as percentages of the labeling rates. For Cora, we selected r values of {25%, 50%, 100%}, resulting in condensation ratios of {1.3%, 2.6%, 5.2%}. Similarly, for Citeseer, r values of {0.9%, 1.8%, 3.6%} yielded the desired condensation ratios. For Arxiv, with a labeling rate of 53%, we set r to {0.1%, 0.5%, 1%} of this rate, resulting in condensation ratios of {0.05%, 0.25%, 0.5%}. The second section contains inductive datasets, where all nodes in the training graphs are labeled. Here, we selected different r values to ensure the desired condensation ratios. Specifically, for Flickr, we chose {0.1%, 0.5%, 1%}, and for Reddit, {0.05%, 0.1%, 0.2%} were selected as our r values.\nFeature Condensation: In this analysis, we primarily assess the efficacy of the suggested joint condensation technique by juxtaposing it against conventional dimensionality reduction methods such as ICA, PCA, and LDA, along with the deep learning approach VGAE. Note that, unless otherwise specified, default parameters are employed for all functions. Specifically, for ICA, PCA, and LDA, the 'PCA' and 'FastICA' functions\nA. Efficiency"}, {"title": "We also evaluate the efficiency of the proposed method", "content": "Specifically, we first analyze the time complexity of TinyGraph and then compare the run time of our method with baselines.\n1) Run Time Analysis: We present the runtime analysis of our proposed method across various condensation rates. Specifically, we explore condensation rates within the range of {0.1%, 0.5%, 1%} for Arxiv and {1%, 5%, 10%} for Cora. The execution times for 30 epochs on a NVIDIA RTX A4000 GPU are detailed in Table VII.\n4sklearn.decomposition.FastICA"}, {"title": "Additional Experiments", "content": "We conducted additional experiments focusing on three key aspects. First, we investigated the sole learning of the feature matrix. Second, we explored the effects of reversing the order of node and feature condensation processes. Third, we delved into neural architecture search. It\u2019s worth noting that for the third aspect, we previously examined various GNN architectures in Section IV-G. In this context, our current discussion primarily centers on the parameter modifications applied to the default architecture, namely the two-layer SGC with 128 hidden units. We contemplated altering it by either introducing three layers or adjusting the hidden units to 128 or 512, referred to as TinyGraph-l3, TinyGraph-h512, or TinyGraph-h128 respectively. From Table VIII, we have the following observations:\n\u2022 Learning X and \u00c2 concurrently allows direct absorption of graph structure into learned features, reducing the need to consistently distill graph properties. This approach maintains good generalization performance from features.\n\u2022 Using a three-layer SGC or employing 512 hidden units, such as TinyGraph-l3 and TinyGraph-h512, results in inferior performance compared to the default two-layer 256 SGC. This aligns with the intuitive understanding that deeper and wider GNNs can lead to over-smoothing. Regarding TinyGraph-h128, reducing the hidden units to 128 yields slightly worse but closely comparable performance to the default TinyGraph, indicating that decreasing hidden units has minimal impact on performance.\n\u2022 Reversing the sequence of node and feature condensation, where the initial condensation of the original graph followed by condensing features on the reduced graph results in poor performance. The issue arises from the asynchronous learning of node and feature condensation,"}]}