{"title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data", "authors": ["Wenwen Min", "Zhen Wang", "Fangfang Zhu", "Taosheng Xu", "Shunfang Wang"], "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is pivotal for understanding cellular heterogeneity. However, the high sparsity and complex noise patterns inherent in scRNA-seq data present significant challenges for traditional clustering methods. To address these issues, we propose a deep clustering method, Attention-Enhanced Structural Deep Embedding Graph Clustering (scASDC), which integrates multiple advanced modules to improve clustering accuracy and robustness. Our approach employs a multi-layer graph convolutional network (GCN) to capture high-order structural relationships between cells, termed as the graph autoencoder module. To mitigate the oversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module that extracts content information from the data and learns latent representations of gene expression. These modules are further integrated through an attention fusion mechanism, ensuring effective combination of gene expression and structural information at each layer of the GCN. Additionally, a self-supervised learning module is incorporated to enhance the robustness of the learned embeddings. Extensive experiments demonstrate that scASDC outperforms existing state-of-the-art methods, providing a robust and effective solution for single-cell clustering tasks. Our method paves the way for more accurate and meaningful analysis of single-cell RNA sequencing data, contributing to better understanding of cellular heterogeneity and biological processes. All code and public datasets used in this paper are available at https://github.com/wenwenmin/scASDC_ and https://zenodo.org/records/12814320.", "sections": [{"title": "I. INTRODUCTION", "content": "Cell clustering is one of the most critical tasks in scRNA-seq data analysis [1, 2]. However, due to the limitations of sequencing technology, scRNA-seq data often exhibits high sparsity and complex noise patterns [3, 4]. Traditional clustering methods [5-7] such as k-means and hierarchical clustering, which rely on similarity measures, struggle to meet the demanding requirements of single-cell data clustering due to these inherent challenges.\nTo better capture the unique characteristics of scRNA-seq data, deep learning-based clustering algorithms have emerged and been widely applied [8]. Examples of these algorithms include DESC [9], scDCC [10], and scDeepCluster [11]. These methods typically utilize autoencoders to learn low-dimensional representations of the data, which helps in clustering and distribution analysis. However, these approaches mainly focus on gene expression information and often overlook the relationships between cells, i.e., the structural information within the data. Given the sparsity and noise in single-cell data, relying solely on gene expression information for clustering can lead to suboptimal results. It is crucial to incorporate both gene expression and structural information for more robust cell clustering.\nTo address these limitations, recent studies have explored the integration of graph-based methods to capture cell-cell relationships and enhance clustering performance [12-14]. Techniques such as scGNN [15], scGAE [16], scTAG [17] and scDSC [18] leverage graph convolutional networks (GCNS) to extract structural information, thereby improving clustering accuracy. However, these methods often suffer from over-smoothing when dealing with large-scale data, leading to the loss of critical features embedded in the gene expression matrix [19].\nThis paper proposes an innovative approach named Attention-Enhanced Structural Deep Embedding Graph Clustering (scASDC). Our method employs a multi-layer GCN to capture high-order structural relationships in single-cell data, termed as the graph autoencoder module. To mitigate the oversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module to extract content information from the data, learning the latent representations of gene expression data [20]. By integrating these two modules, our approach combines gene expression and structural information through an attention fusion mechanism, enhancing clustering performance significantly.\nThe core components of our method include four modules: the ZINB-based autoencoder module, the graph autoencoder module, the attention fusion module, and the self-supervised module. After preprocessing, the single-cell RNA sequencing data matrix is input into the ZINB-based autoencoder module. This module learns a mapping from the data space to a low-dimensional feature space, capturing the content information of the data and producing a low-dimensional latent representation. The ZINB decoder can then reconstruct the gene expression matrix and the data distribution.\nSimultaneously, we construct a cell-cell graph based on the single-cell RNA sequencing matrix and use it as the initial input for the graph autoencoder module. This module, composed of multiple layers of GCNs, effectively extracts high-"}, {"title": "II. MATERIALS AND METHODS", "content": "A. Dataset and pre-processing\nWe collect six scRNA-seq datasets across multiple platforms, encompassing various organs and cell types, including kidney, limb, and diaphragm cells from both humans and mice. These datasets include 'QS Limb Muscle', 'Adam', 'QS Di-aphragm', 'QS Trachea', 'Romanov', and \u2018QX Limb Muscle'. Detailed information on these datasets is provided in Table I. The original gene expression matrix obtained from the scRNA-seq data was preprocessed as follows: We use the scRNA-seq gene expression data matrix $X \\in \\mathbb{R}^{n \\times g}$ as input, where n represents the number of cells and g represents the number of genes. First, we filter out genes that are not expressed in any cells to reduce the impact of sparsity inherent in scRNA-seq data. Next, we use the Scanpy package [21] to normalize the data, converting discrete data into continuous data. Finally, the genes are ranked according to their normalized variance values, and the top d highly variable genes are selected to obtain the normalized data matrix $X \\in \\mathbb{R}^{n \\times d}$.\nTo capture the structural relationships between cells, we use the preprocessed gene expression matrix X to construct a K-nearest neighbor (KNN) graph $A \\in \\mathbb{R}^{n \\times n}$ [22]. In the KNN graph, each node represents a cell, and the edges between nodes represent the relationships between cells."}, {"title": "B. The proposed scASDC method", "content": "1) ZINB-based autoencoder: The autoencoder module consists of symmetrical encoder and decoder components. Specifically, assuming the encoder module of the autoencoder has $L$ layers, the input to the l-th layer is $H_{l-1}$, and its output can be represented as:\n$H_l = \\phi(W_lH_{l-1} + b_l)$ (1)\nwhere the activation function $\\phi$ can be flexibly chosen according to the specific application. We select the ReLU function as the activation function. $W_l$ represents the weights of the l-th layer, and $b_l$ represents the bias vector of the l-th layer. It is noteworthy that the input to the first layer is the preprocessed gene expression matrix $X$, and the output of the final layer is the reconstructed gene expression matrix, whose dimensions are the same as the original input matrix.\nTo capture the global probabilistic structure of the data, we integrate the ZINB model into the decoder structure of the autoencoder. Specifically, we connect three independent fully connected layers to the final layer of the autoencoder to estimate the three parameters of the ZINB distribution: the drop out parameter $\\pi$, the dispersion parameter $\\theta$, and the mean parameter $\\mu$:\n$\\Pi = sigmoid (W_\\pi H_L)$ (2)\n$\\mu = diag (S_i) \\times exp (W_\\mu H_L)$ (3)\n$\\theta = exp (W_\\theta H_L)$ (4)\nwhere the size factor $S_i$ is calculated in the data preprocessing stage by dividing the total expression of each cell by the total expression of a reference cell, $W_\\pi$, $W_\\mu$, $W_\\theta$ represent the weight parameters. The ZINB distribution uses the above three parameters to model the original scRNA-seq data and reconstruct its data distribution:\n$NB(X | \\mu, \\theta) = \\frac{\\Gamma(X + \\theta)}{X!\\Gamma(\\theta)} (\\frac{\\theta}{\\theta + \\mu})^{\\theta} (\\frac{\\mu}{\\theta + \\mu})^X$ (5)\n$ZINB(X | \\pi, \\mu, \\theta) = \\pi \\delta_0(X) + (1 - \\pi)NB(X)$ (6)\nTo guide the model in learning more effective representations, we hope that the reconstructed ZINB distribution is as close as possible to the original data distribution. Therefore, we define the final loss function of the ZINB-based autoencoder module as the negative log-likelihood of the ZINB distribution:\n$L_{ZINB} = -log(ZINB(X | \\pi, \\mu, \\theta))$ (7)"}, {"title": "2) Graph Autoencoder Module", "content": ": To capture the structural information between cells, we introduce a graph autoencoder module that uses a graph convolutional network (GCN) as its backbone, taking the KNN graph A as input to effectively extract structural information while fusing content and structural information in a heterogeneous structure.\nSpecifically, assuming that the graph autoencoder module has L layers, and the input of the 1-th layer is Z_{l-1}, its output can be expressed as:\n$Z_l = \\phi (\\hat{D}^{-\\frac{1}{2}} (A + I) \\hat{D}^{-\\frac{1}{2}} Z_{l-1} U_{l-1})$ (8)\nwhere I is the unit diagonal matrix, D is the degree matrix, $D_{ii} = \\sum_j (A_{ij} + I_{ij})$, $U_{l-1}$ represents the weight of the l-1th layer, and the normalized adjacency matrix $\\hat{D}^{-\\frac{1}{2}} (A + I) \\hat{D}^{-\\frac{1}{2}}$ propagates $Z_{l-1}$ to obtain the new representation $Z_l$. To obtain a richer representation, we embed the output of the ZINB-based autoencoder and the output of the graph autoencoder through an attention fusion module, performing layer-by-layer heterogeneous fusion embedding. This process results in a more robust representation $R_{l-1}$ that integrates both structural and content information:\n$R_{l-1} = F_{att} (\\alpha H_{l-1} + (1 - \\alpha) Z_{l-1})$ (9)\nwhere $\\alpha$ is an adjustable weight parameter. The specific implementation of the attention fusion operation $F_{att}$ will be introduced in detail in the attention fusion module below.\nTo enable the network to learn richer representations and reduce noise interference, we use the integrated representation $R_{l-1}$ as the input for the GCN to learn high-order discriminative information and generate new representations:\n$Z_l = \\phi (\\hat{D}^{-\\frac{1}{2}} (A + I) \\hat{D}^{-\\frac{1}{2}} R_{l-1} U_{l-1})$ (10)\nIt is worth noting that the input $R_0$ of the first layer of the graph autoencoder module is the preprocessed gene expression matrix X. In the representation learned by the GCN, the middle layer $Z_l$ is selected for subsequent clustering. A softmax operation is then performed on this middle layer to predict the probability distribution of the gene expression data:\n$Z_{pre} = softmax (\\hat{D}^{-\\frac{1}{2}} (A + I) \\hat{D}^{-\\frac{1}{2}} R_{l-1} U_{l-1})$ (11)\nThe representation $Z_{ij} \\in Z_{pre}$ can be regarded as the probability that the i-th sample belongs to the j-th cluster center, which is used for end-to-end model learning and training of the subsequent self-supervised module. To guide the model training direction and make the learned representation more credible, we use the following two reconstruction errors as the loss function of the graph autoencoder module:\n$L_{GAEX} = ||X - Z||_F$ (12)\n$L_{GAEA} = ||A - \\hat{A}||_F$ (13)"}, {"title": "3) Attention Fusion Module", "content": ": The attention mechanism maps a query and a set of key-value pairs to an output, where the query, key, value, and output are all vectors. Specifically, we calculate the dot product of the query and the key, apply the softmax function to obtain the relevant weight of the value, and multiply the value by this weight to get the final result. To simplify the calculation, a set of key-value pairs is computed simultaneously in practice, converting vector calculations into matrix operations. The specific calculation method of the attention mechanism is as follows:\n$Attention (Q, K, V) = softmax (\\frac{QK^T}{\\sqrt{d_k}}) V$ (14)\nwhere Q, K, V are the query matrix, key matrix, and value matrix, respectively. Building on this, we introduce a multi-head attention mechanism, which can simultaneously capture information from each subspace at different positions of the data. This ensures that the attention fusion representation contains richer and more robust information. Specifically, this approach performs different attention operations on Q, K, V M times, then executes the attention function in parallel, concatenates the results, and projects them again to obtain the final output. The i-th attention operation is expressed as follows:\n$head_i = Attention (W_i^Q Q, W_i^K K, W_i^V V)$ (15)\nwhere $W_i^Q$, $W_i^K$, $W_i^V$ are transformation matrices responsible for projecting the corresponding query, key, and value matrices, respectively. Assume that the attention module has a total of L layers, and the output of its l-th layer is:\n$R_l = F_{att} (Q, K, V)$\n$F_{att} (W^Q Y_{l-1}, W^K Y_{l-1}, W^V Y_{l-1})$ (16)\n$= W_O \\cdot Concat (head_1, ..., head_M)$\nHere, $Y_{l-1} = \\alpha H_{l-1} + (1-\\alpha) Z_{l-1}$, $W^Q, W^K, W^V$ are three transformation matrices, $W_O$ is a weight matrix, and Concat(.) represents the matrix concatenation operation."}, {"title": "4) Self-supervised module", "content": ": We first perform k-means clustering on the intermediate layer output $H_L$ of the ZINB-based autoencoder module to obtain a set of initial cluster centers {$\\mu_i$}$_{i=1}^k$, where k is the predefined number of clusters. Next, we calculate the soft assignment between the embedded representation $H_L$ and the cluster centers {$\\mu_i$}$_{i=1}^k$ using Student's t-distribution to measure similarity. For the i-th sample and the j-th cluster center, the soft assignment $q_{ij} \\in Q$ is calculated as follows:\n$q_{ij} = \\frac{(1 + ||h_i - \\mu_j||^2 /\\lambda)^{-\\frac{\\lambda+1}{2}}}{\\sum_{j'}(1 + ||h_i - \\mu_{j'}||^2 /\\lambda)^{-\\frac{\\lambda+1}{2}}}$ (17)\nwhere $h_i$ is the i-th sample of the embedded representation $H_L$, $\\lambda$ represents the degree of freedom of Student's t distribution.\nBased on the soft cluster distribution Q, an auxiliary target distribution is required to supervise the learning of the soft cluster distribution and improve clustering by learning the high-confidence distribution of the target distribution. We use the soft cluster frequencies to calculate a target distribution $p_{ij} \\in P$ with higher confidence. The calculation method is as follows:\n$p_{ij} = \\frac{q_{ij}^2 / \\sum_i q_{ij}}{\\sum_{j'} q_{ij'}^2 / \\sum_i q_{ij'}}$ (18)\nwhere $g_j = \\sum_i q_{ij}$ represents the soft clustering frequency. To align the distributions Q and P, we use the KL divergence loss between the two distributions as the optimization target for this part, aiming to achieve higher quality clustering:\n$L_{clu} = KL(P || Q) = \\sum_i \\sum_j p_{ij} log \\frac{p_{ij}}{q_{ij}}$ (19)\nSimilarly, we can adopt the same self-supervised strategy and use the target distribution P to supervise the learning of the graph autoencoder module:\n$L_{gae} = KL(P || Z_{pre}) = \\sum_i \\sum_j p_{ij} log \\frac{p_{ij}}{z_{ij}}$ (20)\nwhere $z_{ij} \\in Z_{pre}$. By optimizing the two loss functions from Eq.(19) and Eq.(20), we integrate the optimization objective into a distribution P, making the learned representation more suitable for clustering tasks.\nThe total loss function of the scASDC model is as follows:\n$L = \\lambda_1 L_{GAEX} + \\lambda_2 L_{GAEA} + \\lambda_3 L_{clu} + \\lambda_4 L_{gae} + \\lambda_5 L_{ZINB}$ (21)\nwhere $\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4, \\lambda_5$ are hyperparameters that measure the importance of each loss function."}, {"title": "C. Evaluation metrics", "content": "We adopt two widely used evaluation metrics Normalized Mutual Information (NMI) and Adjusted Rand Index (ARI) to evaluate the clustering performance of the methods. The larger the values of these metrics, the better the clustering performance of the method."}, {"title": "III. EXPERIMENTAL RESULTS", "content": "A. Implementation details\nFor all baselines, default parameters from the original papers were used, and all experiments were conducted on an NVIDIA GeForce RTX 3090. In our scASDC, the weight coefficients of the Loss function are set as follows: $\\lambda_1$ = 0.5, $\\lambda_2$ = 0.01, $\\lambda_3$ = 0.1, $\\lambda_4$ = 0.01, and $\\lambda_5$ = 0.5. We pre-train the ZINB-based autoencoder module before the formal training phase. During pre-training, we set the initial learning rate (lr) to 0.001, ran for 100 epochs, and used the Adam optimizer to adjust the learning rate. In the formal training phase, the initial learning rate (lr) was also set to 0.001, with the Adam optimizer used again, epoch = 200. The ZINB-based autoencoder module features a symmetrical structure for its encoding and decoding layers. Each layer of the encoder is configured with 1000, 1000, 4000, and 10 nodes, respectively.\nIn the attention fusion module, we set the number of attention heads to 8."}, {"title": "B. Comparison with baseline methods", "content": "We select the following seven single-cell clustering baseline methods for comparison:\nDESC [9]: It is an unsupervised deep embedding algorithm that clusters scRNA-seq data by iteratively optimizing the clustering target, which can effectively eliminate the batch effect.\nSDCN [26]: This method is a structural deep clustering network that utilizes graph convolutional networks to integrate structural information into deep clustering models.\nscDeepCluster [11]: scDeepCluster is a deep embedding denoising network that adds a ZINB model to the autoencoder that can simulate the distribution of scRNA-seq data, and then learns feature representation of the data to guide single-cell clustering.\nDCA [27]: DCA is a deep count autoencoder denoising network that takes into account the sparsity of scRNA-seq data as well as dropout events and uses a zero-inflated negative binomial noise model to restore its data distribution.\nscDSC [18]: scDSC integrates structural information into single-cell deep clustering, adds a ZINB model to the basic autoencoder, and introduces a GNN module to capture the structural information between cells.\nDEC [28]: It is a deep embedding clustering method that guides the learning of data representation by designing a clustering objective.\nAttentionAE-sc [29]: AttentionAE-sc introduces an attention mechanism to fuse structural embedding and denoising embedding together to obtain a more robust representation, thereby improving clustering performance.\nTable II presents the clustering performance results of our scASDC method and seven baseline methods across six scRNA-seq datasets. We repeat the experiments five times using 500, 1000, 1500, and 2000 highly variable genes, and calculated the average values. The best highly variable gene setting is selected as the final result. Bold values in the table indicate the average indices with the best clustering performance. As shown in the table, our method consistently outperforms the baseline methods, achieving the best average indices across all six datasets. Notably, the clustering indices on the QX Limb Muscle dataset reach 0.9665 and 0.9829, respectively. Additionally, we observed that deep graph embedding clustering methods such as SDCN and scDSC also demonstrate strong clustering performance, indicating that embedding the graph structure effectively captures important structural information in scRNA-seq data, positively impacting clustering results."}, {"title": "C. Parameter analysis", "content": "1) Influence of Balance Parameter $\\alpha$: We conduct experiments on six datasets and averaged the results. Fig. 2A shows the impact of the balance parameter $\\alpha$ in Eq.(9) on"}, {"title": "D. Ablation studies", "content": "To evaluate the effectiveness of different components within the scASDC framework, we conduct an ablation study. The study focuses on the impact of removing three key elements: ZINB loss, the attention mechanism, and graph loss.\nSpecifically, in the ZINB-based autoencoder module, we remove the ZINB loss $L_{ZINB}$, referred to as scASDC w/o ZINB Loss. In the layer-by-layer embedding of the encoder,"}, {"title": "E. Downstream analysis", "content": "We visualize the clustering results of the algorithms on the six datasets using UMAP for two-dimensional visualization, as shown in Fig. 3. The figure demonstrates that our scASDC method more effectively separates cells of different populations compared to other algorithms.\nTo verify whether the embedding representation obtained by the scASDC method can facilitate functional genomics interpretation, we perform a series of functional genomics analyses on the Qx Limb Muscle dataset. The results show that the embedding representation obtained by our method retains important expression patterns and structural information from the original gene expression data.\nSpecifically, we use the scanpy package to identify the most significantly differentially expressed genes in each cluster compared to other clusters and illustrate the detailed distribution of these genes across different clusters, as shown in Fig. 4A. The results indicate that our scASDC method identifies highly expressed genes in each cluster and retains this valuable information in the embedding representation. Furthermore, we plot the expression heat map of the top five differentially expressed genes in each cell cluster across all cells (Fig. 4B). From the heat map, we can clearly observe the expression differences of these genes in different cell clusters. Furthermore, we perform functional enrichment analysis on the two cell clusters (T Cell and B Cell) of the Qx Limb Muscle dataset. In Fig. 5A, the enrichment analysis reveals that the T cell-related cluster (Cluster1) is significantly enriched in immune-related biological processes, including T cell activation, T cell receptor signaling pathways, and antigen receptor-mediated signaling pathways. Conversely, Fig. 5B illustrates that the B cell-related cluster (Cluster3) is significantly enriched in processes such as B cell activation, B cell receptor signaling pathways, and lymphocyte differentiation. The violin plots on the right side of the figure depict the expression distribution of representative genes specifically expressed in the two clusters, further corroborating the functional distinctions between these clusters."}, {"title": "IV. CONCLUSIONS", "content": "In this study, we propose a deep learning method, scASDC, for the effective clustering of scRNA-seq data by integrating content and structural information. Our approach leverages a ZINB-based autoencoder and a graph autoencoder, fused through an attention mechanism, to create a robust representation of the data. This method effectively captures both gene expression patterns and the structural relationships between cells. Through extensive experiments on six scRNA-seq datasets, scASDC demonstrates superior performance compared to seven baseline methods, achieving the highest average clustering indices. Our ablation study highlights the significance of each component in scASDC, with the complete model outperforming variations lacking ZINB loss, the attention mechanism, or graph loss. Visualization of clustering results using UMAP further confirms the capability of scASDC to distinctly separate different cell populations. Moreover, pathway enrichment analysis reveals meaningful biological insights, with significant pathways identified for both T cells and B cells. This underscores the ability of scASDC to not only cluster cells accurately but also facilitate downstream biological interpretation."}]}