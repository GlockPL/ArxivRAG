{"title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data", "authors": ["Wenwen Min", "Zhen Wang", "Fangfang Zhu", "Taosheng Xu", "Shunfang Wang"], "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is pivotal for understanding cellular heterogeneity. However, the high sparsity and complex noise patterns inherent in scRNA-seq data present significant challenges for traditional clustering methods. To address these issues, we propose a deep clustering method, Attention-Enhanced Structural Deep Embedding Graph Clustering (scASDC), which integrates multiple advanced modules to improve clustering accuracy and robustness. Our approach employs a multi-layer graph convolutional network (GCN) to capture high-order structural relationships between cells, termed as the graph autoencoder module. To mitigate the oversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module that extracts content information from the data and learns latent representations of gene expression. These modules are further integrated through an attention fusion mechanism, ensuring effective combination of gene expression and structural information at each layer of the GCN. Additionally, a self-supervised learning module is incorporated to enhance the robustness of the learned embeddings. Extensive experiments demonstrate that scASDC outperforms existing state-of-the-art methods, providing a robust and effective solution for single-cell clustering tasks. Our method paves the way for more accurate and meaningful analysis of single-cell RNA sequencing data, contributing to better understanding of cellular heterogeneity and biological processes.", "sections": [{"title": "I. INTRODUCTION", "content": "Cell clustering is one of the most critical tasks in scRNA-seq data analysis [1, 2]. However, due to the limitations of sequencing technology, scRNA-seq data often exhibits high sparsity and complex noise patterns [3, 4]. Traditional clustering methods [5-7] such as k-means and hierarchical clustering, which rely on similarity measures, struggle to meet the demanding requirements of single-cell data clustering due to these inherent challenges.\nTo better capture the unique characteristics of scRNA-seq data, deep learning-based clustering algorithms have emerged and been widely applied [8]. Examples of these algorithms include DESC [9], scDCC [10], and scDeepCluster [11]. These methods typically utilize autoencoders to learn low-dimensional representations of the data, which helps in clustering and distribution analysis. However, these approaches mainly focus on gene expression information and often overlook the relationships between cells, i.e., the structural information within the data. Given the sparsity and noise in single-cell data, relying solely on gene expression information for clustering can lead to suboptimal results. It is crucial to incorporate both gene expression and structural information for more robust cell clustering.\nTo address these limitations, recent studies have explored the integration of graph-based methods to capture cell-cell relationships and enhance clustering performance [12-14]. Techniques such as scGNN [15], scGAE [16], scTAG [17] and scDSC [18] leverage graph convolutional networks (GCNS) to extract structural information, thereby improving clustering accuracy. However, these methods often suffer from over-smoothing when dealing with large-scale data, leading to the loss of critical features embedded in the gene expression matrix [19].\nThis paper proposes an innovative approach named Attention-Enhanced Structural Deep Embedding Graph Clustering (scASDC). Our method employs a multi-layer GCN to capture high-order structural relationships in single-cell data, termed as the graph autoencoder module. To mitigate the oversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module to extract content information from the data, learning the latent representations of gene expression data [20]. By integrating these two modules, our approach combines gene expression and structural information through an attention fusion mechanism, enhancing clustering performance significantly.\nThe core components of our method include four modules: the ZINB-based autoencoder module, the graph autoencoder module, the attention fusion module, and the self-supervised module. After preprocessing, the single-cell RNA sequencing data matrix is input into the ZINB-based autoencoder module. This module learns a mapping from the data space to a low-dimensional feature space, capturing the content information of the data and producing a low-dimensional latent representation. The ZINB decoder can then reconstruct the gene expression matrix and the data distribution.\nSimultaneously, we construct a cell-cell graph based on the single-cell RNA sequencing matrix and use it as the initial input for the graph autoencoder module. This module, composed of multiple layers of GCNs, effectively extracts high-"}, {"title": "II. MATERIALS AND METHODS", "content": "We collect six scRNA-seq datasets across multiple platforms, encompassing various organs and cell types, including kidney, limb, and diaphragm cells from both humans and mice.\nThe original gene expression matrix obtained from the scRNA-seq data was preprocessed as follows: We use the scRNA-seq gene expression data matrix \\(X \\in \\mathbb{R}^{n \\times g}\\) as input, where n represents the number of cells and g represents the number of genes. First, we filter out genes that are not expressed in any cells to reduce the impact of sparsity inherent in scRNA-seq data. Next, we use the Scanpy package [21] to normalize the data, converting discrete data into continuous data. Finally, the genes are ranked according to their normalized variance values, and the top d highly variable genes are selected to obtain the normalized data matrix \\(X \\in \\mathbb{R}^{n \\times d}\\).\nTo capture the structural relationships between cells, we use the preprocessed gene expression matrix X to construct a K-nearest neighbor (KNN) graph \\(A \\in \\mathbb{R}^{n \\times n}\\) [22]. In the KNN graph, each node represents a cell, and the edges between nodes represent the relationships between cells."}, {"title": "B. The proposed scASDC method", "content": "The autoencoder module consists of symmetrical encoder and decoder components. Specifically, assuming the encoder module of the autoencoder has L layers, the input to the l-th layer is \\(H_{l-1}\\), and its output can be represented as:\n\n\n\n\\begin{equation}\nH_l = \\phi(W_lH_{l-1} + b_l)\n\\end{equation}\n\n\n\nwhere the activation function \\(\\phi\\) can be flexibly chosen according to the specific application. We select the ReLU function as the activation function. \\(W_l\\) represents the weights of the l-th layer, and \\(b_l\\) represents the bias vector of the l-th layer. It is noteworthy that the input to the first layer is the preprocessed gene expression matrix X, and the output of the final layer is the reconstructed gene expression matrix, whose dimensions are the same as the original input matrix.\nTo capture the global probabilistic structure of the data, we integrate the ZINB model into the decoder structure of the autoencoder. Specifically, we connect three independent fully connected layers to the final layer of the autoencoder to estimate the three parameters of the ZINB distribution: the drop out parameter \\(\\pi\\), the dispersion parameter \\(\\theta\\), and the mean parameter \\(\\mu\\):\n\n\n\n\\begin{equation}\n\\Pi = sigmoid(W_{\\pi} H_L)\n\\end{equation}\n\n\n\n\\begin{equation}\n\\mu = diag(S_i) \\times exp(W_{\\mu} H_L)\n\\end{equation}\n\n\n\n\\begin{equation}\n\\Theta = exp(W_{\\Theta} H_L)\n\\end{equation}\n\n\nwhere the size factor \\(S_i\\) is calculated in the data preprocessing stage by dividing the total expression of each cell by the total expression of a reference cell, \\(W_{\\pi}\\), \\(W_{\\mu}\\), \\(W_{\\Theta}\\) represent the weight parameters. The ZINB distribution uses the above three parameters to model the original scRNA-seq data and reconstruct its data distribution:\n\n\n\n\\begin{equation}\nNB(X | \\mu, \\Theta) = \\frac{\\Gamma(X + \\Theta)}{X!\\Gamma(\\Theta)} (\\frac{\\Theta}{\\Theta + \\mu})^\\Theta (\\frac{\\mu}{\\Theta + \\mu})^X\n\\end{equation}\n\n\n\n\\begin{equation}\nZINB(X | \\pi, \\mu, \\Theta) = \\pi \\delta_0(X) + (1 - \\pi) NB(X)\n\\end{equation}\n\n\nTo guide the model in learning more effective representations, we hope that the reconstructed ZINB distribution is as close as possible to the original data distribution. Therefore, we define the final loss function of the ZINB-based autoencoder module as the negative log-likelihood of the ZINB distribution:\n\n\n\n\\begin{equation}\nL_{ZINB} = -log(ZINB(X | \\pi, \\mu, \\Theta))\n\\end{equation}\n\n\n\nTo capture the structural information between cells, we introduce a graph autoencoder module that uses a graph convolutional network (GCN) as its backbone, taking the KNN graph A as input to effectively extract structural information while fusing content and structural information in a heterogeneous structure.\nSpecifically, assuming that the graph autoencoder module has L layers, and the input of the 1-th layer is \\(Z_{l-1}\\), its output can be expressed as:\n\n\n\n\\begin{equation}\nZ_l = \\phi (\\hat{D}^{-\\frac{1}{2}}(A + I) \\hat{D}^{-\\frac{1}{2}}Z_{l-1}U_{l-1})\n\\end{equation}\n\n\nwhere I is the unit diagonal matrix, D is the degree matrix, \\(D_{ii} = \\sum_{j} (A_{ij} + I_{ij})\\), \\(U_{l-1}\\) represents the weight of the l \u2212 1th layer, and the normalized adjacency matrix \\(\\hat{D}^{-\\frac{1}{2}}(A + I) \\hat{D}^{-\\frac{1}{2}}\\) propagates \\(Z_{l-1}\\) to obtain the new representation \\(Z_l\\). To obtain a richer representation, we embed the output of the ZINB-based autoencoder and the output of the graph autoencoder through an attention fusion module, performing layer-by-layer heterogeneous fusion embedding. This process results in a more robust representation \\(R_{l-1}\\) that integrates both structural and content information:\n\n\n\n\\begin{equation}\nR_{l-1} = F_{att} (\\alpha H_{l-1} + (1 - \\alpha)Z_{l-1})\n\\end{equation}\n\n\nwhere \\(\\alpha\\) is an adjustable weight parameter. The specific implementation of the attention fusion operation \\(F_{att}\\) will be introduced in detail in the attention fusion module below.\nTo enable the network to learn richer representations and reduce noise interference, we use the integrated representation \\(R_{l-1}\\) as the input for the GCN to learn high-order discriminative information and generate new representations:\n\n\n\n\\begin{equation}\nZ_l = \\phi (\\hat{D}^{-\\frac{1}{2}}(A + I) \\hat{D}^{-\\frac{1}{2}}R_{l-1}U_{l-1})\n\\end{equation}\n\n\nIt is worth noting that the input \\(R_0\\) of the first layer of the graph autoencoder module is the preprocessed gene expression matrix X. In the representation learned by the GCN, the middle layer \\(Z\\) is selected for subsequent clustering. A softmax operation is then performed on this middle layer to predict the probability distribution of the gene expression data:\n\n\n\n\\begin{equation}\nZ_{pre} = softmax (\\hat{D}^{-\\frac{1}{2}}(A + I) \\hat{D}^{-\\frac{1}{2}}R_{l-1}U_{l-1})\n\\end{equation}\n\n\nThe representation \\(Z_{ij} \\in Z_{pre}\\) can be regarded as the probability that the ith sample belongs to the jth cluster center, which is used for end-to-end model learning and training of the subsequent self-supervised module. To guide the model training direction and make the learned representation more credible, we use the following two reconstruction errors as the loss function of the graph autoencoder module:\n\n\n\n\\begin{equation}\nL_{GAEX} =|| X - Z_l||^2\n\\end{equation}\n\n\n\n\\begin{equation}\nL_{GAEA} =|| A - \\hat{A}||^2\n\\end{equation}\n\n\nThe attention mechanism maps a query and a set of key-value pairs to an output, where the query, key, value, and output are all vectors. Specifically, we calculate the dot product of the query and the key, apply the softmax function to obtain the relevant weight of the value, and multiply the value by this weight to get the final result. To simplify the calculation, a set of key-value pairs is computed simultaneously in practice, converting vector calculations into matrix operations. The specific calculation method of the attention mechanism is as follows:\n\n\n\n\\begin{equation}\nAttention (Q, K, V) = softmax (\\frac{QK^T}{\\sqrt{d_k}}) V\n\\end{equation}\n\n\nwhere Q, K, V are the query matrix, key matrix, and value matrix, respectively. Building on this, we introduce a multi-head attention mechanism, which can simultaneously capture information from each subspace at different positions of the data. This ensures that the attention fusion representation contains richer and more robust information. Specifically, this approach performs different attention operations on Q, K, V M times, then executes the attention function in parallel, concatenates the results, and projects them again to obtain the final output. The i-th attention operation is expressed as follows:\n\n\n\n\\begin{equation}\nhead_i = Attention (W_i^Q Q, W_i^K K, W_i^V V)\n\\end{equation}\n\n\nwhere \\(W_i^Q\\), \\(W_i^K\\), \\(W_i^V\\) are transformation matrices responsible for projecting the corresponding query, key, and value matrices, respectively. Assume that the attention module has a total of L layers, and the output of its l-th layer is:\n\n\n\n\\begin{equation}\nR_l = F_{att} (Q, K, V)\\\\\n\\approx F_{att} (W^q Y_{l-1}, W^k Y_{l-1}, W^v Y_{l-1}) = W^O . Concat (head_1, ..., head_M)\n\\end{equation}\n\n\nHere, \\(Y_{l-1} = \\alpha H_{l-1} + (1 - \\alpha)Z_{l-1}\\), \\(W^q\\), \\(W^k\\), \\(W^v\\) are three transformation matrices, \\(W^O\\) is a weight matrix, and Concat(.) represents the matrix concatenation operation.\nWe first perform k-means clustering on the intermediate layer output \\(H_L\\) of the ZINB-based autoencoder module to obtain a set of initial cluster centers \\({\\mu_i\\}_{i=1}^k\\), where k is the predefined number of clusters. Next, we calculate the soft assignment between the embedded representation \\(H_L\\) and the cluster centers \\({\\mu_i\\}_{i=1}^k\\) using Student's t-distribution to measure similarity. For the i-th sample and the j-th cluster center, the soft assignment \\(q_{ij} \\in Q\\) is calculated as follows:\n\n\n\n\\begin{equation}\nq_{ij} = \\frac{(1 + ||h_i - \\mu_j||^2 / \\lambda)^{-\\frac{\\lambda + 1}{2}}}{\\sum_{j'} (1 + ||h_i - \\mu_{j'}||^2 / \\lambda)^{-\\frac{\\lambda + 1}{2}}}\n\\end{equation}\n\n\nwhere \\(h_i\\) is the i-th sample of the embedded representation \\(H_L\\), \\(\\lambda\\) represents the degree of freedom of Student's t distribution.\nBased on the soft cluster distribution Q, an auxiliary target distribution is required to supervise the learning of the soft cluster distribution and improve clustering by learning the high-confidence distribution of the target distribution. We use the soft cluster frequencies to calculate a target distribution \\(P_{ij} \\in P\\) with higher confidence. The calculation method is as follows:\n\n\n\n\\begin{equation}\nP_{ij} = \\frac{q_{ij}^2 / g_j}{\\sum_{j'} q_{ij'}^2 / g_{j'}}\n\\end{equation}\n\n\nwhere \\(g_j = \\sum_i q_{ij}\\) represents the soft clustering frequency. To align the distributions Q and P, we use the KL divergence loss between the two distributions as the optimization target for this part, aiming to achieve higher quality clustering:\n\n\n\n\\begin{equation}\nL_{clu} = KL(P || Q) = \\sum_i \\sum_j P_{ij} log \\frac{P_{ij}}{q_{ij}}\n\\end{equation}\n\n\nSimilarly, we can adopt the same self-supervised strategy and use the target distribution P to supervise the learning of the graph autoencoder module:\n\n\n\n\\begin{equation}\nL_{gae} = KL(P || Z_{pre}) = \\sum_i \\sum_j P_{ij} log \\frac{P_{ij}}{z_{ij}}\n\\end{equation}\n\n\nwhere \\(z_{ij} \\in Z_{pre}\\). By optimizing the two loss functions from Eq.(19) and Eq.(20), we integrate the optimization objective into a distribution P, making the learned representation more suitable for clustering tasks.\nThe total loss function of the scASDC model is as follows:\n\n\n\n\\begin{equation}\nL = \\lambda_1L_{GAEX} + \\lambda_2L_{GAEA} + \\lambda_3L_{clu} + \\lambda_4L_{gae} + \\lambda_5L_{ZINB}\n\\end{equation}\n\n\nwhere \\(\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4, \\lambda_5\\) are hyperparameters that measure the importance of each loss function."}, {"title": "C. Evaluation metrics", "content": "We adopt two widely used evaluation metrics Normalized Mutual Information (NMI) and Adjusted Rand Index (ARI) to evaluate the clustering performance of the methods. The larger the values of these metrics, the better the clustering performance of the method."}, {"title": "III. EXPERIMENTAL RESULTS", "content": "For all baselines, default parameters from the original papers were used, and all experiments were conducted on an NVIDIA GeForce RTX 3090. In our scASDC, the weight coefficients of the Loss function are set as follows: \\(\\lambda_1\\) = 0.5, \\(\\lambda_2\\) = 0.01, \\(\\lambda_3\\) = 0.1, \\(\\lambda_4\\) = 0.01, and \\(\\lambda_5\\) = 0.5. We pre-train the ZINB-based autoencoder module before the formal training phase. During pre-training, we set the initial learning rate (lr) to 0.001, ran for 100 epochs, and used the Adam optimizer to adjust the learning rate. In the formal training phase, the initial learning rate (lr) was also set to 0.001, with the Adam optimizer used again, epoch = 200. The ZINB-based autoencoder module features a symmetrical structure for its encoding and decoding layers. Each layer of the encoder is configured with 1000, 1000, 4000, and 10 nodes, respectively.\nIn the attention fusion module, we set the number of attention heads to 8.\nWe select the following seven single-cell clustering baseline methods for comparison:\nIt is an unsupervised deep embedding algorithm that clusters scRNA-seq data by iteratively optimizing the clustering target, which can effectively eliminate the batch effect.\nThis method is a structural deep clustering network that utilizes graph convolutional networks to integrate structural information into deep clustering models.\nscDeepCluster is a deep embedding denoising network that adds a ZINB model to the autoencoder that can simulate the distribution of scRNA-seq data, and then learns feature representation of the data to guide single-cell clustering.\nDCA is a deep count autoencoder denoising network that takes into account the sparsity of scRNA-seq data as well as dropout events and uses a zero-inflated negative binomial noise model to restore its data distribution.\nscDSC integrates structural information into single-cell deep clustering, adds a ZINB model to the basic autoencoder, and introduces a GNN module to capture the structural information between cells.\nIt is a deep embedding clustering method that guides the learning of data representation by designing a clustering objective.\nAttentionAE-sc introduces an attention mechanism to fuse structural embedding and denoising embedding together to obtain a more robust representation, thereby improving clustering performance.\nshows the impact of the balance parameter \\(\\alpha\\) in Eq.(9) on the clustering performance. In our method, \\(\\alpha\\) determines the fusion ratio between the graph autoencoding module and the ZINB-based autoencoding module. As shown in the figure, as \\(\\alpha\\) increases from 0.1 to 0.5, both NMI and ARI values remain relatively stable, reaching their highest at 0.5. This indicates that our method is robust to changes in \\(\\alpha\\) within this range. However, when \\(\\alpha\\) increases further, the performance drops significantly, demonstrating the effectiveness of our fused embedding strategy. Therefore, \\(\\alpha\\) is set to 0.5 in our experiments.\nThe number of highly variable genes is a critical parameter influencing the richness of data representation. illustrates the average clustering performance of scASDC across six datasets with varying numbers of highly variable genes (500, 1000, 1500, and 2000). The results indicate that both NMI and ARI values improve as the number of highly variable genes increases, with the best performance observed at 2000 genes. This suggests that using a larger number of highly variable genes offers a more comprehensive representation of the data, resulting in better clustering outcomes.\nshows the effect of varying the KNN parameter k on the clustering performance across six datasets. The NMI and ARI values are plotted against different k values ranging from 5 to 25. The results show that performance peaks at k = 10 and k = 20, with a noticeable dip observed at k = 15. Consequently, we set k to 10 in our experiments.\nTo evaluate the effectiveness of different components within the scASDC framework, we conduct an ablation study. The study focuses on the impact of removing three key elements: ZINB loss, the attention mechanism, and graph loss.\nSpecifically, in the ZINB-based autoencoder module, we remove the ZINB loss \\(L_{ZINB}\\), referred to as scASDC w/o ZINB Loss. In the layer-by-layer embedding of the encoder,"}, {"title": "IV. CONCLUSIONS", "content": "In this study, we propose a deep learning method, scASDC, for the effective clustering of scRNA-seq data by integrating content and structural information. Our approach leverages a ZINB-based autoencoder and a graph autoencoder, fused through an attention mechanism, to create a robust representation of the data. This method effectively captures both gene expression patterns and the structural relationships between cells. Through extensive experiments on six scRNA-seq datasets, scASDC demonstrates superior performance compared to seven baseline methods, achieving the highest average clustering indices. Our ablation study highlights the significance of each component in scASDC, with the complete model outperforming variations lacking ZINB loss, the attention mechanism, or graph loss. Visualization of clustering results using UMAP further confirms the capability of scASDC to distinctly separate different cell populations. Moreover, pathway enrichment analysis reveals meaningful biological insights, with significant pathways identified for both T cells and B cells. This underscores the ability of scASDC to not only cluster cells accurately but also facilitate downstream biological interpretation."}]}