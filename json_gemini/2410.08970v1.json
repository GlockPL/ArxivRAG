{"title": "NoVo: Norm Voting Off Hallucinations With Attention Heads in Large Language Models", "authors": ["Zheng Yi Ho", "Siyuan Liang", "Sen Zhang", "Yibing Zhan", "Dacheng Tao"], "abstract": "Hallucinations in Large Language Models (LLMs) remain a major obstacle, particularly in high-stakes applications where factual accuracy is critical. While representation editing and reading methods have made strides in reducing hallucinations, their heavy reliance on specialised tools and training on in-domain samples, makes them difficult to scale and prone to overfitting. This limits their accuracy gains and generalizability to diverse datasets. This paper presents a lightweight method, Norm Voting (NoVo), which harnesses the untapped potential of attention head norms to dramatically enhance factual accuracy in zero-shot multiple-choice questions (MCQs). NoVo begins by automatically selecting truth-correlated head norms with an efficient, inference-only algorithm using only 30 random samples, allowing NoVo to effortlessly scale to diverse datasets. Afterwards, selected head norms are employed in a simple voting algorithm, which yields significant gains in prediction accuracy. On TruthfulQA MC1, NoVo surpasses the current state-of-the-art and all previous methods by an astounding margin\u2014at least 19 accuracy points. NoVo demonstrates exceptional generalization to 20 diverse datasets, with significant gains in over 90% of them, far exceeding all current representation editing and reading methods. NoVo also reveals promising gains to finetuning strategies and building textual adversarial defence. NoVo's effectiveness with head norms opens new frontiers in LLM interpretability, robustness and reliability.", "sections": [{"title": "INTRODUCTION", "content": "One of the most significant challenges facing Large Language Models (LLMs) today is their tendency to hallucinate-outputs that are factually incorrect or entirely fabricated (Zhang et al., 2023b). This flaw is particularly serious in high-stakes applications like finance and healthcare, where even small errors can lead to huge losses and compromised patient safety (Kang & Liu, 2023; Pal et al., 2023). Reducing factual hallucinations is a critical research area with major practical benefits, essential for realising the full potential of LLMs to revolutionise these industries by enhancing efficiency and decision-making, and safeguarding against costly and harmful errors (Kaddour et al., 2023).\nGiven these serious risks and the high cost of retraining LLMs, it is crucial to find affordable techniques to reduce factual hallucinations. Although inference techniques such as retrieval augmentation and prompt engineering work well, they come with significant limitations: latency and external dependencies, and the need for user expertise, respectively (Zhao et al., 2024; Sahoo et al., 2024). In response, we turn to representation editing and reading methods (REAR) (Zou et al., 2023), which operate within the model, ensuring rapid response times and eliminating the need for external data or user interaction. REAR methods reduce hallucinations by modifying or extracting factual information encoded in LLMs' latent feature vectors (hidden states), such as attention heads (Bronzini et al., 2024). This process often requires specialized tools such as probes and autoencoders (Li et al., 2024; Zhang et al., 2024), trained and tuned on in-domain samples. Thus, existing REAR methods are difficult to scale and prone to overfitting, leading to limited accuracy gains and generalizability to diverse datasets. Tackling these limitations is crucial, since REAR methods can improve factuality with minimal costs, latency, and user friction; highly desirable attributes for practical applications.\nThis paper presents Norm Voting (NoVo), a more accurate and generalizable REAR method for reducing factual hallucinations in LLMs. Following previous works, we evaluate NoVo on multiple-choice questions (MCQs), which are excellent tests of factuality and serve as an important foundation for more complex tasks."}, {"title": "2 RELATED WORKS", "content": "Representation Editing Some REAR methods involve manually modifying hidden states during inference towards hidden state clusters, formed by the forward propagation of true and false sequences (Burns et al., 2023), to improve factual accuracy. All methods here require cross-fold training on in-domain samples from the test set, with some set aside for validation. Inference Time Intervention (ITI) edits specific attention head hidden states towards those clusters (Li et al., 2024), using custom-built linear probes and visualisation tools. Similarly, TruthForest (TrFr) edits heads toward multiple directions (Chen et al., 2024), while Truthx edits concepts of truth disentangled from hidden states with a deep autoenconder (Zhang et al., 2024), as a specialised tool.\nRepresentation Reading There are decoding strategies that use hidden states to improve the factuality of LLMs without editing. This includes Decoding by Contrasting Layers (DoLa) (Chuang et al., 2024), which extracts factual information in intermediate layers, tuned with in-domain samples, and Induce-then-Contrast Decoding (ICD) (Zhang et al., 2023a), which contrasts LLM outputs with a special hallucinatory model trained on a large external dataset. RePE (Zou et al., 2023) uses a different, more direct approach with highly curated templates and samples, to measure truth in hidden states, with an special technique known as linear artificial tomography. All these methods here extract factual information from hidden states without editing, to improve factual accuracy."}, {"title": "3 METHOD", "content": null}, {"title": "3.1 BACKGROUND", "content": "Preliminary Burns et al. (2023) found that some attention heads were linearly separable to classify true or false statements, which formed the basis of representation editing. However, Li et al. (2024) found that orthogonal hyperplanes could also classify well above chance, indicating the multifaceted nature of truth. REAR methods typically define a claim as true if supported by publicly available and reliable evidence, following Lin et al. (2022). Yet, the latter also framed truth as a probability measure. We observe that most existing REAR methods operated on the basis that truth is binary, yet at the same time hinted at its complex nature. We believe that clarifying this inconsistent interpretation is crucial, by acknowledging that the truthfulness of a sequence is multifaceted and non-discrete. This leads us to look for a broad and continuous measure of truth, denoted T.\nSetup In the forward pass of an auto-regressive decoder transformer LLM, token sequences of length s are embedded and featurized through multiple layers as hidden states, before reaching the likelihood layer for next-token prediction. Each layer includes a multi-head attention (MHA) module and a two-layer fully-connected perceptron (FFN). The likelihood and embedding layers are not counted. An LLM with L layers and H heads per MHA will have a total of LH heads throughout the network. The MHA at layer $l \\in \\{1,2..., L\\}$ takes as input $X^{(l-1)} \\in \\mathbb{R}^{s \\times d}$ from the previous layer and projects each feature in the sequence to their key, query and value states\n$Q = X^{(l-1)}W_{query}^l \\quad K^l = X^{(l-1)}W_{key}^l \\quad V^l = X^{(l-1)}W_{value}^l$ (1)\nignoring the bias term, where $Q^l, K^l, V^l \\in \\mathbb{R}^{s \\times d}$ and d is the model dimension. Splitting them on the column axis gives $Q^{l,h}, K^{l,h}, V^{l,h} \\in \\mathbb{R}^{s \\times d'}$ for $h \\in \\{1,2..., H\\}$ and $d' = d/H$. The context vectors, or attention heads, $C^{l,h} \\in \\mathbb{R}^{s \\times d'}$, is thus computed via the attention mechanism as\n$C^{l,h} = A^{l,h}V^{l,h} \\quad A^{l,h} = softmax( \\frac{Q^{l,h}(K^{l,h})^T}{\\sqrt{d'}} + M)$ (2)\nWhere M enforces auto-regression by setting $A_{sh}^l$ to a lower triangular matrix. In Equation 2, each head in the sequence $C^{l,h}$ is the attention weighted sum of each value state in $V^{l,h}$, computed component-wise from the current and all previous sequence positions as\n$C^{l,h} = A^{l,h}V^{l,h} = \\begin{bmatrix} a_{11}v_{11} & ... & a_{11}v_{1d'}\\\\ \\sum_{j=1}^{2} a_{2j}v_{j1} & ... & \\sum_{j=1}^{2} a_{2j}v_{jd'}\\\\ ... & ... & ...\\\\ \\sum_{j=1}^{S} a_{sj}v_{j1} & ... & \\sum_{j=1}^{S} a_{sj}v_{jd'} \\end{bmatrix}$ (3)\nMotivation Recall that we are looking for a broad and continuous measure of truth T. Inspired by Li et al. (2024), we look to individual heads in $C^{l,h}$ for T. To avoid the complexities of fine-grained analyses on the attention weighted matrix in Equation 3, such as is done in Lieberum et al. (2023), T should be an easily computed scalar for practical use. The L2 vector norm is a good candidate, since it is continuous and broadly encompasses all dimensions that point in various directions to classify truth in heads (Chen et al., 2024). We posit that for some heads, the L2 norm correlates to the truthfulness of a sequence. While it may seem intuitive to expect both norm and truth to increase together, we make no assumption and allow for inverse relationships as well. In Appendix F, we show that the latter approach is better. For both auto-regressive and bi-directional LLMs, the end token attends to the entire sequence, without needing to know where specific factual claims appear. Therefore, we propose taking T as the attention head norm at the final sequence position such that\n$T^{l,h} = ||C_{s,*}^{l,h}||_2$. This process is shown in Figure 2. Since $T^{l,h}$ is unbounded and the correlation direction unknown, with l, h being unspecified, it cannot be used yet. $T^{l,h}$ instead forms the basis for NoVo, which addresses these issues and operationalises $T^{l,h}$ to improve factual accuracy."}, {"title": "3.2 NORM VOTING (NOVO)", "content": "Norm Selection The goal of this stage is to operationalise $T^{l,h}$ by resolving its unbounded nature, and specifying all (l, h) indices that correlates with truth, including the correlation direction. Figure 3 shows this stage in five steps. In step 1, 30 random samples are fed into the LLM to produce 30 Norm Matrices, packed as a tensor. The idea here is that all head norms are initially assumed to correlate with truth, each producing two predictions from the argmax and argmin operators. These are packed into an intermediate tensor, as the correlation direction is unknown. The unbounded nature of $T^{l,h}$ is resolved here, since both operators are relative. In step \ufffd, each head receives an accuracy score across 30 samples for both sets of prediction, forming a matrix with two rows representing each prediction set, and columns that represent each head's accuracy. It is clear here that most heads are poor performers. In steps 3 and 4, the correlation direction and strength are identified using these accuracies scores as a proxy measure. This approach does not require any training, special techniques or external tools, making NoVo lightweight and scalable. The row with the highest accuracy indicates the correlation direction. Steps 4 and 5 determines which heads are strongly correlated with truth, by taking the higher accuracy of the two rows. This is followed by a thresholding operation, set at the 85th percentile (P85) of all accuracies. We refer to these remaining heads as \u201cVoters\". For clarity, (l, h) is enumerated as consecutive integers, starting from 0 for the first head in the first layer. This entire stage is only performed once, as the Index Vector and Indicators are reused, and takes less than 10 seconds on one NVIDIA A100 GPU. The number of samples and threshold are hyper-parameters, found to be optimal at 30 and P85. The search for these two values is detailed in Appendix B, with a hyper-parameter free variant explored in Appendix C.\nVoting Inference Now that the latent measure of truth $T^{l,h}$ is operationalised with NoVo, zero-shot MCQ classification can begin. The goal of this stage is to output more accurate predictions via majority voting, shown in four steps in Figure 4. In Step 1, an example MCQ with three options is fed through the LLM to produce the Norm Matrix. Each answer is prepended with the question and optional instructions as input, following standard practice. In Step, Voters are selected with the Index Vector from the previous stage. In Step 3, the correlation direction of each Voter is flagged with Indicators, also from the previous stage. This allows for dynamic selection between the argmax or argmin operators, for individual Voter predictions. While each Voter's T is unbounded and could become very large, we observe in practice that it is well-conditioned to varying truthfulness in a sequence. In most cases, T ranges between 0.5 to 3. In step 4, all Voter predictions participate in a majority vote via the mode operator, resulting in the final MCQ prediction of the LLM."}, {"title": "4 EXPERIMENT AND DISCUSSION", "content": null}, {"title": "4.1 SETTINGS", "content": "Experiments We evaluate NoVo in three key areas: 1 its effectiveness in reducing factual hallucinations compared to existing REAR methods on a standard benchmark, 2 its generalizability across various reasoning and natural language understanding (NLU) tasks, and 3 its adaptability to broader classification strategies, measured by its finetuning performance. Experimental results for the first area are shown in Table 1. Results for the second area are presented in Tables 2, 3, and 4, while the third area is reported at the bottom of Table 2. To ensure that results are not inflated, all experiments use 30 random training samples drawn without tuning, for Norm Selection. Furthermore, all zero-shot prompts for NoVo are used without tuning (Perez et al., 2021). More experimental details and information on random variations can be found in Appendices A and D.\nModels NoVo is evaluated in two classification settings: zero-shot and finetuned. Zero-shot is the primary setting used in most experiments, and the results are presented in Tables 1 through 4. Finetuning, on the other hand, is used in only one experiment, which is reported at the bottom of Table 2. In the zero-shot setting, NoVo is applied to four 7B decoder LLMs: Llama2 and LLama2-Chat (Touvron et al., 2023), Vicuna (Chiang et al., 2023) and Mistral-Instruct (Jiang et al., 2023). For the finetuned setting, NoVo is applied to DeBERTa-Large (He et al., 2023). Additionally, Table 2 includes results from two finetuned 11B models, UnifiedQA and UNICORN (Khashabi et al., 2020; Lourie et al., 2021), for reference purposes only, without making any direct comparisons.\nDatasets We evaluate NoVo's effectiveness in reducing factual hallucinations on TruthfulQA MC1 (Lin et al., 2022), a standard and unsolved hallucination benchmark used by all previous REAR methods. For our generalizability experiment, we apply NoVo to diverse datasets covering multiple topics and presented in various formats. This includes CommonsenseQA 2.0 (CQA2) (Talmor et al., 2021) for commonsense reasoning. QASC (Khot et al., 2020) tests for scientific knowledge. SWAG (Zellers et al., 2018) and HellaSwag (HSwag) (Zellers et al., 2019) requires sentence completions about challenging commonsense scenarios. SIQA (Sap et al., 2019) and PIQA (Bisk et al., 2020) looks for social and physical reasoning, respectively. CosmosQA (Cosmos) (Huang et al., 2019) requires causal reasoning over narrative contexts. CICERO V1 and V2 (CICv1, CICv2) (Ghosal et al., 2022b; Shen et al., 2022) tests for multi-turn dialogue and strategic reasoning. We use a MCQ variant from Ghosal et al. (2022a). Adversarial GLUE (AdvGLUE) (Wang et al., 2021) tests model robustness to adversarial texts in NLU tasks. FACTOR-Expert (expert) (Muhlgay et al., 2023), Natural Questions (nq) (Kwiatkowski et al., 2019), and TriviaQA (trivia) (Joshi et al., 2017) all contain general factual questions from expert domains or online documents. We reformulate nq and trivia following Li et al. (2024). MMLU (Hendrycks et al., 2020) involves a broad range of topics, and Arc (Clark et al., 2018) contains science question. All datasets report accuracy."}, {"title": "4.2 MAIN RESULTS", "content": "Hallucination Mitigation Table 1 reports the zero-shot accuracy of NoVo on TruthfulQA MC1 across four models. Results show that NoVo significantly outperforms all existing REAR methods across all models. Notably, they all require either cross-fold training, few-shot prompting, or custom instruction, but NoVo uses only true zero-shot prompts with 30 random samples from Arc-Easy's train split for Norm Selection. NoVo on a 7B model surpasses GPT4 by a remarkable margin of 19 points, setting a new SOTA accuracy of 78.09%. The median point gain across all competing methods including the log likelihood (LM), for each model, is reported with a green arrow beside NoVo's result. Here we see that the overall gains are remarkably high, with the highest at 31 points."}, {"title": "4.3 ERROR ANALYSIS", "content": "Table 5 shows representative samples from PIQA, our lowest-performing dataset. The left column contains examples misclassified by NoVo but correctly predicted with the LM, with the reverse in the right column. Questions are in blue, followed by correct and incorrect answers. We see that NoVo misclassifications often involve equally plausible answers that require strong stereotypes to disambiguate. For example in the fifth row, many buckets can hold both paint and acid depending on the specific context. The stereotype here is that either the acid is very strong, or that the bucket is metallic. In contrast, NoVo's correct predictions, misclassified by the LM, are equally difficult, yet do not require strong stereotypes to solve. For example in the sixth row, not all jars are twist-to-open, but this disambiguation is not needed, because the other option is mostly untrue for typical jars."}, {"title": "4.4 DISCUSSION", "content": "NoVo significantly outperforms all previous REAR methods on TruthfulQA, while generalizing well across 20 diverse datasets to include reasoning, NLU, and factuality benchmarks. The innovative use of attention head norms in measuring latent truth forms the basic building block of NoVo (See Figure 2 and Section 3.1). This underlying mechanism enables NoVo to completely bypass the final likelihood layer, unlike existing REAR and standard zero-shot MCQ methods for LLMs, potentially avoiding the selection of fluent but incorrect answers (Zhou et al., 2024; Jaiswal et al., 2024). NoVo's strong results on TruthfulQA, which contains misleading questions, suggests that it excels in scenarios where avoiding stereotypes is critical. In contrast, PIQA and HellaSwag presents a unique challenge, as their questions often require broad and general assumptions about the real world, to answer correctly. In such cases, it is possible that NoVo's sole reliance on attention head norms may inhibit these helpful simplifications. NoVo's competitive gains on AdvGLUE and DeBERTa finetuning, highlight its potential for textual adversarial defence and more general SFT tasks. Further analysis of NoVo in Section 5 demonstrates how head norms measure truth across varying levels of granularity, and how using multiple heads with diverse error profiles can enhance accuracy."}, {"title": "5 ANALYSIS", "content": null}, {"title": "5.1 WHAT DO VOTERS MEASURE?", "content": "Plotting We plot the token contributions for each Voter in Figure 5. Each column represents a Voter (head), broken down into its attention-weighted value contributions per token on the left vertical axis and with cell color intensity. Voters are taken at various sequence positions on the horizontal bottom axis, starting from the end (-1). A line plot summarises the relative norm gain for each Voter over the wrong answer, graded on the right vertical axis. Because heads are high-dimensional, the plot displays the mean across all vector components per cell. These three Voter are selected here for display based on their representative patterns, with more shown in Appendix E.\nVoter Specialisation Voter 527 has the largest norm gains at the last three positions, with a drastic drop in the middle, slowly recovering at the first two tokens. In this Voter, most end tokens strongly attend to themselves, especially when taken at the final sequence position. In contrast, both Voters 509 and 665 places more weights to other tokens, such as between 'can' and 'fly'. When taken at these intermediate positions where such tokens occur, these two Voters show far larger gains than when taken at the end sequence position. Plotting other Voters in Appendix E reveal broadly similar patterns to Figure 5, suggesting two general types of Voters. We characterise Type-1 Voters (T1) as those attending to periods and end tokens as a measure of structure, while Type-2 Voters (T2) attend to individual token associations as a measure of resolution and dependence. Table 6 and Figure 6 show that both Voter types exhibit similar performance, with no clear preference for either, and are evenly distributed throughout the upper portions of the model, suggesting no specific localisation of these roles.\nWhat is being Measured Based on NoVo's majority voting process back in Figure 4, we see that each Voter type plays a distinct yet complementary role in shaping the model's capacity for making more factual predictions in MCQs. Perhaps T2 Voters signal strong links betwen factually related tokens, by capturing context-specific relationships. Similarly, T1 Voters may also express factual coherence across a sequence, by attending to endpoints and sentence boundaries. This balance between structural comprehension and local contextual precision may be the driving force behind how Voter norms measure latent truth. By interpreting the inner workings of each Voter, we might gain a window into how these mechanistic factors converge to form a robust internal framework for factual MCQ answering. In this way, we suspect that observing Voter behaviour may reflect"}, {"title": "5.2 EFFECTIVENESS OF USING MULTIPLE VOTERS", "content": "Plotting To assess the effectiveness of the majority vote, we analyse each Voter's contribution to the overall accuracy of NoVo. On the left of Figure 7, Voters are sorted by individual accuracy and are gradually included in voting process at each step of the horizontal axis, with percentage values graded on the left vertical axis. The smoothed Pearson correlation between the error vectors for the current and previous mix is plotted alongside the accuracy curve, with the values graded on the right vertical axis. The dotted and solid black vertical lines indicate the point of no significant increase and our chosen threshold in Section 3.2, respectively. On the right of Figure 7, the hamming distances between error vectors of the top 50 Voters are plotted on a 2D space using t-SNE (Van der Maaten & Hinton, 2008). Clusters and centroids are marked by colour and crosses. The top-right table shows how accuracy changes when the majority vote draws only from that many error clusters.\nEnsemble Principles It may be intuitive to select amongst high-performing, upper-layer Voters. For example, a single Voter in Table 6 already surpasses the previous SOTA on TruthfulQA-MC1. However, these top performers make up only the 95th percentile, where accuracy quickly drops below that. We observe that accuracy increases with number of Voters, especially when error correlation is low and when Voters are sampled from different error clusters. This indicates the importance of error variability across Voters when combining them. Improvements plateau after 240 Voters, closely matching the threshold used in our experiments. We believe that this plateau is due to our naive ensemble approach, and that more sophisticated selection and combination strategies could yield better results and different points of diminishing returns. We propose a weighted combination strategy in Appendix C. In Table 2, NoVo finetuning involves learning weights to each Voter with the classification layer, which could be seen as learning an selection and combination function. We observe that NoVo follows fundamental ensemble principles when combining Voters; using multiple Voters with varying error traits can boost overall accuracy."}, {"title": "5.3 ABLATIONS", "content": "Plotting We perturb sequences and remove Voters with high error variability from NoVo, and plot their effects on TruthfulQA MC1. The left of Figure 8 compares T1 and T2 when taken further away from the sequence end. Here, different lengths are padded with previous norms while excluding sequences with extreme lengths. The middle removes Voters from the majority vote. Here,"}, {"title": "6 CONCLUSION", "content": "In this paper, we introduced Norm Voting (NoVo), an effective method for enhancing the factual accuracy of LLMs, by measuring latent truth in certain attention head norms. NoVo significantly outperforms all existing methods on the challenging TruthfulQA MC1 benchmark, and achieves a new SOTA. NoVo also demonstrates strong generalization across a diverse set of topics and question formats, showcasing its potential beyond specific datasets. More importantly, NoVo does not require any specialized tools or in-domain sample training, making it scalable and lightweight. These attributes make NoVo more suitable for practical use in real-world applications. Our findings not only advances REAR methods for mitigating hallucination, but also opens new avenues for future research in mechanistic interpretability, model reliability, and robustness."}, {"title": "A EXPERIMENTAL DETAILS", "content": "Finetuning Supervised finetuning (SFT) feeds the final layer hidden state to the task-specific layer, such as a classifier for MCQ tasks. We use SFT as a baseline for our finetuning experiments in Table 2. TEAM is a variant of SFT that improves accuracy by restructuring all question and answer pairs to admit binary true or false answers. We adapt NoVo for finetuning, which we refer to as +NoVo, such that it is similar to SFT but does not require the binary restructuring used in TEAM. In +NoVo, all attention head norms are serialised as a vector and fed to the classifier. Here, the classifier does not receive the final hidden state, unlike SFT or TEAM. Different from the original zero-shot design of NoVo, the Norm Selection and Voting Inference stages described in Section 3.2 does not apply to +NoVo, and can instead be seen as a learnt function represented by the classifier weights. SFT, TEAM, and +NoVo trains all parameters in the model. We use the same finetuning parameters set by TEAM (Ghosal et al., 2022a), with the exception of the learning rate, which we change to 3e-6 for the model and 3e-5 for the classifier, across all three methods. We also implemented early stopping.\nReporting Results In Table 1, we re-implement results for DoLa, ICD, ITI by adapting from their official repositories. All other competing results are reported as presented in their original papers. MC1 accuracy is reported without cross training or validation. In Table 2, all results are implemented by us. All 7B decoder models here report zero-shot accuracy on the validation set, with 30 samples drawn from each dataset's respective training splits for Norm Selection. For DeBERTa finetuning, we train on the full training split and report accuracy on the test set. No cross training or validation is performed here. In Table 3, all results are implemented by us. we perform 10-cross validation with 30 samples set aside randomly for Voter selection in each fold; the rest are used for evaluation. We report the average accuracy across all 10 folds. In Table 4, we report all competing results as presented in their original papers or from other studies that re-implemented them. All methods here use Llama2-chat-7B. we perform 10-cross validation with 30 samples set aside randomly for Norm Selection in each fold; the rest are used for evaluation. We report the average accuracy across all 10 folds. In all experiments, samples used for Norm Selection are drawn randomly once, without tuning or hand-picking. Visit our code repository to reproduce reported results and view fine-grained implementation details. All model and datasets used in this paper are fully detailed and referenced in Table 8."}, {"title": "B NORM SELECTION HYPER-PARAMETERS", "content": "Grid Search The number of samples used and percentile threshold for Norm Selection are hyper-parameters. We search through different combinations of these two values for each dataset individually, shown in Figure 10. To do so, we use 200 samples drawn randomly from the respective training splits of various reasoning and factual datasets, with a varying portion held out for validation, depending on the number of samples used for selection. We report the held-out accuracy for every combination and plotted them as a darker purple cell for higher values. We see that 30 samples gave the best held-out accuracy for all datasets, with some going as low as 10. Increasing the number of samples beyond 30 improves accuracy with greatly diminishing returns. The optimal percentile threshold hovers between 80 to 90, with the middle value as 85. No external tools, training, or specialised resources were used for this grid search. Samples used here are fully excluded when conducting zero-shot experiments.\nSample Type In Figure 9, difficulty is defined per sample as the percentage of Voters that misclassified it. The horizontal axis marks the average difficulty across 30 samples used during Norm"}, {"title": "C HYPER-PARAMETER-FREE DISCOVERY", "content": "We propose a Voter selection algorithm free of hyper-parameters, without requiring the number of samples or percentile threshold to be specified. Similar to the Norm Selection process in Section 3.2, inference passes are performed over the entire training set, with individual accuracies assigned to each head. Heads that perform worse than the random baseline are excluded. Instead of using a percentile threshold, all heads are Voters with weights assigned according to their accuracy scores, normalized between 0 and 1. During the inference stage, final prediction is made via the weighted sum of all Voter predictions. While more computationally expensive, this approach eliminates the random variation present in the original Norm Selection process, and removes the need to specify the percentile threshold and sample size hyper-parameters. Table 10 compares this approach, denoted NoVo-F, with NoVo and LM. We see that NoVo-F is competitive with NoVo in most datasets."}, {"title": "D RANDOM VARIATIONS OF EXPERIMENTAL RESULTS", "content": "Random variations attributable to the sampling process in Norm Selection are recorded in Table 11. We show that our zero-shot results are not inflated; most fall within the 25th and 75th percentiles."}, {"title": "E ADDITIONAL CONTEXT ATTRIBUTION PLOTS", "content": null}, {"title": "F NORM CORRELATION DIRECTION", "content": "To better understand the impact of fixing the head norm correlation direction during Norm Selection, we introduce two distinct variants: NoVo-A and NoVo-B. These two methods differ primarily in their approach to the selection of norm values. Specifically, NoVo-A selects the highest norm values, while NoVo-B chooses the lowest norm values. These two variants allows us to investigate how prioritizing one correlation direction influences performance across various datasets. In contrast to these static methods, NoVo adapts its selection strategy based on the correlation direction of each Voter, by using Indicators (as illustrated in Figure 3). Table 12 provides a comparative analysis of these three approaches: NoVo-A, NoVo-B, and NoVo, across a variety of reasoning and factuality benchmarks. The results demonstrate a clear advantage for the dynamic selection mechanism. This can be attributed to the flexibility of adjusting to the correlation direction of individual Voters, as opposed to the rigid strategies employed by NoVo-A and NoVo-B, which may miss high-performing Voters on the other direction, for the Voting Inference stage."}, {"title": "G NOVO PERFORMANCE ANALYSIS WITH TRUTHFULQA", "content": "TruthfulQA consists of 817 samples, each belonging to one of 38 categories such as science, geography, humanities, politics and law, finance, and pop culture. During inference, the model does not see the category label. Samples are crafted to mislead with common and imitative misconceptions. Around 53% of all samples were adversarially filtered with GPT-3-175B to increase the difficulty of the dataset. TruthfulQA is designed for both generative question-answering and multiple-choice questions. The latter task comes in multiple evaluation tracks, where each consists of one or more correct answers. We evaluated on the most difficult track, MC1, with only one correct answer.\nFigure 13 plots the accuracy of NoVo on a per-category basis, using Mistral-7B-Instruct. Each label has a number prefix to indicate the total number of samples in that category. NoVo surpasses the LM in all categories. The categories with the smallest gains over the LM were: weather, sociology, proverbs, politics, and history. Similarly, the largest gains over the LM were: advertising, confusion-"}]}