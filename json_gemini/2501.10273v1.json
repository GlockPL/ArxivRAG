{"title": "SEANN: A Domain-Informed Neural Network for Epidemiological Insights", "authors": ["Jean-Baptiste Guimbaud", "Marc Plantevit", "L\u00e9a Ma\u00eetre", "R\u00e9my Cazabet"], "abstract": "In epidemiology, traditional statistical methods such as logistic regression, linear regression, and other parametric models are commonly employed to investigate associations between predictors and health outcomes. However, non-parametric machine learning techniques, such as deep neural networks (DNNs), coupled with explainable AI (\u03a7\u0391\u0399) tools, offer new opportunities for this task. Despite their potential, these methods face challenges due to the limited availability of high-quality, high-quantity data in this field. To address these challenges, we introduce SEANN, a novel approach for informed DNNs that leverages a prevalent form of domain-specific knowledge: Pooled Effect Sizes (PES). PESs are commonly found in published Meta-Analysis studies, in different forms, and represent a quantitative form of a scientific consensus. By direct integration within the learning procedure using a custom loss, we experimentally demonstrate significant improvements in the generalizability of predictive performances and the scientific plausibility of extracted relationships compared to a domain-knowledge agnostic neural network in a scarce and noisy data setting.", "sections": [{"title": "Introduction", "content": "Historically in epidemiological studies, the impact of environmental health associations was largely studied using a 'one-exposure-one-health-effect' approach [1]. While such targeted approaches are informative, scaling them to the diversity of existing environmental factors is expensive and they can miss complex interactions and unaccounted confounders. The exposome paradigm emerged to address these limitations, proposing to consider the totality of individuals' environmental exposures. This holistic framework allows investigating the combined effects on health from diverse environmental factors, including urban, chemical, lifestyle, and social hazards. Analyzing such complex mixtures of exposures requires advanced modeling techniques capable of handling high-dimensional data from observational studies [2,3]. While traditional biostatistical methods remain important, recent advancements in machine learning, particularly Deep Neural Networks (DNNs), offer a powerful alternative for discovering complex patterns in high-dimensional data. Their use, however, poses specific challenges. Their need for large and high-quality datasets and their lack of interpretability are significant obstacles, especially in healthcare, where data can be scarce, noisy, and ethically sensitive.\nIn dealing with such data, purely data-driven approaches can lead to unsatisfactory results, such as capturing spurious associations. In addition, purely data-driven methods do not comply with known natural laws (e.g., biological pathways). Incorporating additional knowledge to complement the training data has proven its ability to address those issues in various domains [4].\nIn epidemiology and other cumulative empirical science, scientific knowledge emerges from a consensus among multiple studies, focusing on the same question but in slightly different settings. In the context of the exposome, in which we search for the relation between variables of interest and a target outcome, each study estimates these relations, and these estimations are aggregated across several studies in meta-analyses [5], to derive a more reliable and statistically robust indicator, namely a Pooled Effect Size (PES) [6]. PESs thus represent a quantitative formulation of a scientific consensus. Considered one of the most reliable forms of information in the field [7], PESs have been used to compute literature-only health risk scores (e.g. [8]) and informed risk scores (e.g., [9]) using traditional biostatistical methods (e.g., logistic and linear regression). However, the integration of PESs within machine learning models, particularly DNNs, has not been explored yet, despite their potential to improve the reliability of these models in scarce and noisy data settings.\nIn this work, we introduce SEANN (Summary Effects Adapted Neural Network), a novel approach designed to integrate prominent forms of PESs, namely Odd Rations(ORS), Relative Risks(RRs), and Standard Regression Coefficients (SRCs) [10,11] directly into DNNs learning process. By incorporating PESs as a form of scientific prior, SEANN aims to enhance the model's generalizability and ensure that extracted relationships are scientifically plausible. This is achieved through a custom loss function that penalizes deviations from integrated PESS measured through differences in prediction when perturbing the inputs.\nSEANN addresses challenges posed by Deep Neural Networks (DNNs) that limit their use in epidemiological contexts, compensating for the limited observational data typically available in exposome-wide studies and improving the generalizability and trustworthiness of computed risk indicators. Additionally, by incorporating knowledge from well-known relationships, SEANN can better characterize those that are less studied.\nThe paper is structured as follows: in Section 3, we introduce SEANN; In Section 4, we perform a series of experiments on synthetic scenarios illustrating the method's benefits in a controlled environment. More specifically, we refer to improved prediction accuracy in noisy contexts and improved reliability of interpretation using \u03a7\u0391\u0399. Finally, Section 5 discusses the significance of those results and concludes."}, {"title": "Related work", "content": "Machine Learning (ML) models and DNNs in particular often rely heavily on both the quantity and the quality of the available training data. In many fields, including healthcare, securing vast and representative datasets poses significant challenges due to ethical, logistical, and technical constraints that would consequently impact the reliability of obtained predictions [12]. Beyond predictive performances, most machine learning procedures do not consider the underlying mechanisms at play (e.g., biological pathways, physical rules, etc) when they learn patterns within the data. As such, they may learn and amplify potential biases, particularly when the data is noisy and incomplete [13].\nInformed Machine Learning (IML) addresses these challenges by combining data-driven learning with domain-specific knowledge, leveraging a hybrid approach that can enhance both predictive accuracy and model interpretability [4]. While it is still an emergent stream of research, the number of papers published per year in healthcare alone has approximately doubled every year, starting from 10 published studies in 2018 to 58 in 2021, [14].\nThe domain-specific knowledge incorporated with IML approaches refers to information not present in the input data. The three most prominent forms of knowledge incorporated using IML in medical applications [14], ranked by decreasing order of importance, are: 1) spatial invariances (e.g., [15]) widely used for image processing, 2) probabilistic relations (e.g., [16]) and 3) knowledge graphs (e.g., [17]). These representations can be integrated into ML models in various ways, such as by modifying the input data, altering the model structure, incorporating knowledge into the loss function, or comparing model outputs with known constraints [4]. Adding penalty terms to the loss function allows the model to balance between fitting the data and adhering to known domain-specific rules. This approach is particularly relevant in cases where learning purely from data may conflict with established domain knowledge. For instance, [18] introduced a Physics-Guided Neural Network (PGNN) incorporating physical rules between water temperature, depth, and density into DNNs training. Similarly, [19] proposed a Domain-Adapted Neural Network (DANN) to integrate domain knowledge for monotonicity and approximation constraints demonstrating superior overall performances over a standard agnostic DNN.\nOur approach is instead designed to incorporate PESs for the computation of exposome risk scores. In epidemiological studies, PESs are considered to be among the strongest levels of confidence for a factor's relationship with health at a population level [20]. Despite their significance, there has been limited research on incorporating them into informed machine learning procedures, particularly using deep neural networks (DNNs). To our knowledge, our approach is the first to achieve this. The most similar work, introduced by Neri et al. in 2022 [9], proposed to integrate PESS into a naive Bayes model for the computation of health risk scores, the Cardiovascular LIterature-Based Risk Algorithm (CALIBRA). While their approach can combine input data with literature estimates to learn health relationships, it is limited to naive Bayes models and cannot be directly applied to other types of machine learning procedures."}, {"title": "Method", "content": "This section introduces SEANN. We first define the general setting of integrating PESS as soft constraints via additional terms to the loss function and then detail the implementation of this approach for three types of PESs: standardized regression coefficients, odd ratios, and risk ratios.\nGiven a set of p observed variables P, and a subset Q \u2286 P, with |Q| = q of these variables for which we have an effect size estimate value to use as enforced external knowledge, we define X, an n\u00d7p input matrix of n observations, and V, a vector of q effect size estimates values. Similarly to previous works (e.g., [21,22]), the general principle of our method, described in Eq. 1, consists in adding a term to the loss function L for each meta-heuristic to incorporate.\n$L = \\lambda_0 L_{pred}(X, \\theta) + \\sum_{i=1}^{q} \\lambda_i L_{meta}(X, \\theta, V_i, h_i)$ (1)\nWhere $L_{pred}$ is the convex function used for the predictive task (e.g., mean squared error, cross-entropy, etc.) and \u03b8 the parameters of the model. $L_{meta}$ is the convex loss function used to enforce the desired soft constraints for the neural network, i.e., to enforce the neural network to respect the PESs vector V.  $\\lambda_0$ and $\\lambda_i$ are weights pondering the importance of each term, namely the predictive task and the ith constraint. They can be treated as hyperparameters and set to values that optimize the obtained predictive performances. However, for cases where learning plausible relationships, i.e., relationships aligned with known associations, is considered equally or more important than raw predictive power (e.g., imperfect input data, trustworthiness), a different approach should be used to settle the tradeoff between learning from the data (and optimizing performances) or learning associations observed in the literature. We propose choosing weight values proportional to the confidence in both the data and the external knowledge. Following a common principle in meta-analyze (e.g., [5]), we express this confidence using the sample size available in each study as well as the sample size available in the training data.\nThe proposed weighting is calculated as follows: first, we define a confidence score $c_i$ associated with $v_i$ corresponding to the sample size of the ith meta-analysis. Similarly, we define a confidence score $c_0$ for the input data X composed of n rows and p variables to be computed as n x p. Then, for $c_i > 1$, we estimate the final \u03bb weights using a log scale relative normalization:\n$\\lambda_i = \\frac{ln c_i}{\\sum_{j=0}^{q} ln c_j}$\nThis scheme ensures that terms associated with small confidence scores have a noticeable impact on the learning process compared to the others and are not entirely ignored.\nDepending on the type of PES considered, the loss function $L_{meta}$ will be implemented differently. As effect estimates in the meta-analysis are typically represented either as OR, RR, or SRC, we express $L_{meta}$ for those forms below. In all cases, the principle is to generate for each observation a slightly perturbated copy of it with an increment h-called the perturbation for each variable in Q, to measure the difference between the expected change in the target value according to our PESs and the observed change in our model, and to penalize this difference."}, {"title": "Case of a standardized regression coefficient", "content": "Let us first consider, for simplicity, a single SRC, called $B_i$, that we want to integrate into the training of a DNN. This $\u03b2_i$ would be either directly extracted in a domain-specific literature study from a uni/multi-variate linear regression model or would summarize several similar effects in a meta-analysis. Considering a multivariate linear regression model defined as:\n$f_\u03b2(Z) = \u03b2_0 + \\sum_{j=1}^{m_2}\u03b2_jz_j$\nWith Z \u2208 Rm1Xm2 an input matrix and \u1e9e, a vector of SRCs, \u03b2\u2081 \u2208 \u03b2, 1 \u2264 i \u2264 m2. Then the expected change in the target values according to Bi when modifying the corresponding input variable $z_i$ with a perturbation step h is:\n$f_\u03b2(Z^{z_i+h}) = f_\u03b2(Z) + \u03b2_i h$\nWhere $Z^{z_i+h}$ denotes the matrix obtained from the input matrix Z by perturbing its i-th column, denoted as zi, through the addition of a quantity h, where h\u2208R\\{0}.\nTo integrate $\u03b2_i$ within SEANN, we enforce a similar relationship between our model's predicted values $f_\u03b8(X)$ and predicted values with perturbed inputs $f_\u03b8(X^{x_i+h})$ as a soft constraint, i.e., $f_\u03b8(X) = f_\u03b8(X^{x_i+h}) \u2013 \u03b2_i h$, by penalizing the deviation from this equality.\nFor a vector V of SRCs derived from the literature, with vi \u2208 V, the ith element of V, the training loss term $L_{meta}$ is defined as:\n$L_{meta}(X, \\theta, v_i, h_i) = \\frac{1}{n} \\sum_{k=1}^{n} \\frac{1}{2} (f_\u03b8(X_k^{x_i+h}) - v_i h_i - f_\u03b8(X_k))^2$ (2)\nWhere Xk denotes the kth row vector of matrix X. fo is the output of the neural network with parameters 0, n the number of data points (i.e., batch size), and hi \u2208 R \\{0} a perturbation parameter. In this case, as SRCs (similar to other PESS) are constant regardless of input data Z, we can theoretically use any value other than 0. For simplicity, we use $h_i = 1$ for every SRCs to integrate. In a hypothetical, more general case of a constraint to integrate as a function of X, h would be taken as the smallest possible."}, {"title": "Case of an odd-ratio", "content": "The approach we proposed in this section, while mathematically correct, can suffer from numerical instability during the training (cf., Eq. 3). In paper 3, we addressed this issue by generalizing equation 2 instead.\nSimilar to section 3.1, let us consider a single OR, referred to as $(OR_i = e^{\u03b2_i})$, that we want to integrate into the training process of a DNN. This OR would be extracted from logistic regression models in a meta-analysis. Considering a multivariate logistic regression model defined as:\n$P_\u03b2(Z) = \\frac{1}{1 + e^{-(\u03b2_0+\\sum_{j=1} \u03b2_jz_j)}}$\nWith Z \u2208 Rm1Xm2 an input matrix and \u1e9e, a vector of m2 log-odds coefficients, \u03b2\u03b5 \u03b5\u03b2, 1 \u2264 i \u2264 m2. We can express the change in Logit(pp) when modifying the input variable zi associated with \u1e9ei with a perturbation step h. This difference is independent of other variables in Z.\n$log(\\frac{P_\u03b2(Z^{z_i-h})}{1 \u2212 p_\u03b2(Z^{z_i-h})}) - log (\\frac{P_\u03b2(Z)}{1 \u2212 p_\u03b2(Z)}) = -\u03b2_ih$\nThus, we can express the corresponding relationship between the predicted values on inputs Z with and without modifying the corresponding input variable zi with a perturbation step h:\n$p_\u03b2(Z) = \\frac{e^{\u03b2_ih}p_\u03b2(Z^{z_i-h})}{e^{\u03b2_ih}p_\u03b2(Z^{z_i-h}) \u2212 p_\u03b2(Z^{z_i-h}) + 1}$\nFor a vector V of log-odds coefficients derived from the literature, with vi \u2208 V, the ith element of V, the training loss term $L_{meta}$ to integrate vi is defined as in Eq. 3\n$L_{meta}(X, \\theta, v_i, h_i) = \\frac{1}{n} \\sum_{k=1}^{n} (\\frac{e^{v_ih}p_\u03b8(X_k^{x_i-h})}{e^{v_ih}p_\u03b8(X_k^{x_i-h}) \u2212 p_\u03b8(X_k^{x_i-h}) + 1} - p_\u03b8(X_k))^2$ (3)"}, {"title": "Case of a risk ratio", "content": "Following the same principle, let's define the integration of a single PES encoded as a risk ratio. Considering a negative binomial regression model defined as:\n$log (\u00b5_\u03b2(Z)) = \u03b2_0 + \\sum_{j=1}^{m_2}\u03b2_jz_j$\nWith Z\u2208 Rm1xm2 an input matrix and \u1e9e, a vector of log-estimates,\n\u03b2\u03b5 \u03b5\u03b2, 1 \u2264 i \u2264 m2. Then the expected change in the target values according to Bi when modifying the corresponding input variable zi with a perturbation step h is:\n$\u00b5_\u03b2(Z^{z_i+h}) = e^{\u03b2_ih}\u00b5_\u03b2(Z)$\nWhere $Z^{z_i+h}$ denotes the matrix obtained from the input matrix Z by perturbing its i-th column, denoted as zi, through the addition of a quantity h, where h\u2208R\\{0}.\nTo integrate \u03b2\u2081 within SEANN, we enforce a similar relationship between our model's predicted values fo (X) and predicted values with perturbed inputs fo(Xxi+h) as a soft constraint, i.e., fo(X) = fo(Xxi+h)e-Bih, by penalizing the deviation from this equality.\nFor a vector V of log-estimates derived from the literature, with vi \u2208 V, the ith element of V, the training loss term $L_{meta}$ is defined as:\n$L_{meta} (X, \u03b8, V_i, h_i) = \\frac{1}{n} \\sum_{k=1}^{n} (e^{-v_ih_i} f_\u03b8(X_k^{x_i+h}) \u2013 f_\u03b8(X_k))^2$ (4)\nWhere Xk denotes the kth row vector of matrix X. fe is the output of the neural network with parameters \u03b8, \u03b7 the number of data points (i.e., batch size), and hi \u2208 R \\{0} a perturbation parameter. Similar to Section 3.2, we recommend using:\n$h=\\begin{cases}\n1 & \\text{if } v_i = 0, \\\\\n\\frac{1}{v_i} & \\text{otherwise}.\n\\end{cases}$\nTo demonstrate the approach's potential, we rely on synthetic data that emulates different scenarios. In each experiment, we compare two DNNs, identical in all aspects but the inclusion of our modified loss and external knowledge. For the sake of simplicity, we use and compare basic multilayer perceptrons. The approach can be directly usable with more complex feed-forward neural architectures (e.g., convolutional networks, residual networks), and the benefits highlighted in this study should apply to other neural configurations. Below, we call SEANN the model that implements our approach, and agnostic DNN the reference one."}, {"title": "Experimental validation", "content": "To illustrate the relevance in real applications, we introduce an intuitive fictional example composed of 1) a target variable y representing the risk of developing a disease or the strength of symptoms and 2) several variables contributing to the outcome y according to a dose-response relationship. To make the experiment more intuitive, we take a well-known confounding factor in health studies: fish intake tends to decrease health risks, while mercury intake increase it. However, fish intake is an important driver of mercury intake. We thus define two correlated variables, mercury (x1) and fish intake (x2), having an opposite effect on the target variable. Correlation between 21 and 22 is designed to emulate a confounding effect [23]. We also define two additional variables, namely perceived stress (x3) and body mass index (i.\u0435., BMI, x4) uncorrelated to the variables x1 and 12 but affecting y. 23 is linear and positively correlated with the outcome, while x4 has a nonlinear effect.\nIn this simple scenario, we perform different experiments in which we test the benefits of incorporating PESs to eligible variables (i.e., X1, X2 and x3). We are interested not only in the networks' predictive performances but also in their ability to capture and restitute the input-output relationships that we encoded in the data. The experiments focus on SRCs and ORs, but we could use RRs in a similar manner."}, {"title": "Standardized regression coefficients", "content": "For the case where PESs are encoded as SRCs, we generate an input matrix X by sampling m = 1000 values from a multivariate Gaussian with mean 0 and covariance matrix $\\begin{pmatrix} 1 & 0.8 & 0 & 0 \\\\ 0.8 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{pmatrix}$. Target vector Y is generated from the additive function described in Eq. 5 with Bo = 1, \u03b2\u03b9 = 1, \u03b22 = -2, \u0432\u0437 = 5 and \u1e9e4 10.\nY(X) = \u03b2\u03bf + \u03b21 \u00d7 x1 + \u03b22 \u00d7 x2 + \u03b23 \u00d7 x3 + 34 \u00d7 cos(x4) (5)"}, {"title": "Odd-ratios", "content": "Similar to the linear case, we generate a data matrix X with three variables, namely X1, X2, and X3, corresponding to mercury, fish intake, and perceived stress, respectively, to predict an outcome (i.e., a risk to develop a disease). X was generated by sampling m = 1000 values from a multivariate Gaussian with mean 0 and covariance matrix $\\begin{pmatrix} 1 & 0.8 & 0 \\\\ 0.8 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$. Target vector Y was generated from the function described in Eq. 6 with Bo = 0, \u03b2\u2081 = 1, \u03b2\u2082 = \u22122, \u03b23 = 5.\nY(X) = $\\frac{1}{1+ e^{-\u03b2_0-\u03b2_1\u00d7x_1-\u03b2_2\u00d7x_2-\u03b2_3\u00d7x_3}}$ (6)"}, {"title": "Experimental design", "content": "We use a fully connected neural network (NN) with a single hidden layer for both SEANN and the agnostic model. Both NNs were implemented using Pytorch and trained with a batch size of 64 and a maximum number of epochs of 1000. Parameter optimization was achieved using Adam [24]. We standardize and split data into training (n=600), validation (n=200), and test (n=200) datasets. To reduce over-fitting, we use early stopping (with patience 10) on the validation set."}, {"title": "Evaluation", "content": "To evaluate the correctness of extracted relationships, we propose a score, called Shap, to compute the distance between two dose-response relationships represented with Shapley values [25]. \u2206Shap is defined by the mean absolute error (MAE) computed across Shapley values for a given marginal relationship that must be computed using the same background dataset. We can use it to compare the distance between a neural network-extracted relationship and a relationship admitted in the literature or, in this work, as we use synthetic data, to compare the distance between a neural network-extracted relationship and the true predictor-outcome relationship.\nThe smaller the distance, the more we would consider a relationship to be scientifically plausible or in line with the true effect. In this work, we use the generative functions (i.e., Eq. 5 and Eq. 6) to compute Shapley values representing the reference relationships for Shap. Shapley values are approximated using the SHAP library [26] and systematically computed on the test sets.\nTo evaluate the performance of models, we use the coefficient of determination (R2) score for regression tasks and the receiver operating characteristic curve's (ROC) area under the curve (AUC) for binary classification tasks (i.e., odd-ratios)."}, {"title": "Experiment 1", "content": "In this experiment, we illustrate that SEANN can leverage the information from external expert knowledge to mitigate the poor quality of the data. To simulate the data imperfection, we progressively increase the level of noise on all variables (i.e., X1,X2,X3, X4) and check that while the performance of the agnostic NN deteriorates quickly, our informed NN can retain most of it. Information was degraded differently for linear coefficient and odd ratios to illustrate two common scenarios. In the linear case, we added Gaussian noise to all input variables, with a mean of 0 and increasing standard deviation. For odd ratios, missing values were generated completely at random with increasing proportions and imputed using a simple mean imputation. External knowledge was integrated on top of training data for every eligible predictor (i.e., beta1,.., beta3 for x1, ..., x3 respectively).\nBetter performances were obtained with SEANN both for the predictive task and the explainability of constrained relationships measured with Shap. No significant gains were observed for the nonlinear unconstrained variable (BMI). Results are displayed in Fig. 1 for linear coefficients and summarized in Table 1 for odd-ratios. Results indicate that given PESs encoding correct relationships between input variables and target outcome, performances obtained while training on imperfect data can be more stable with SEANN."}, {"title": "Experiment 2", "content": "In this experiment, we focus on the quality of the relationships captured when external knowledge is integrated for a single predictor. The objective is to show that variables that do not benefit directly from external knowledge may nevertheless be better captured, thanks to corrections brought to the other variables. Similar to the previous experiment, Gaussian noise was added to a single variable (i.e., fish intake, 12) with mean 0 and standard deviation 0.75, and 1.5 for the SRCs and ORs respectively, in both training and validation sets.\nFig. 2 show results with PESs encoded as SRCs. The most significant gain was observed for fish intake, the variable with integrated external knowledge. Shap (see definition in Section 4.1.4) measured for this variable was 1.11 with the agnostic DNN and 0.04 with SEANN. A significant gain was also observed for mercury, the variable correlated with the informed one (1.02 for agnostic DNN to 0.53 for SEANN). Finally, no significant performance gains were observed for the remaining variables, i.e., those uncorrelated with the informed one (0.99 to 1.04 for perceived stress, 1.74 to 1.64 for BMI, with agnostic DNN and SEANN, respectively). Results show that not only SEANN better captures relationships for features with corresponding external knowledge but also for noninformed features that are correlated with those externally informed."}, {"title": "Experiment 3", "content": "In a last experiment, we simulate a setting where a confounding variable is missing from the data. A confounding variable is a predictor impacting both the outcome to predict and other predictor(s) of interest. In numerous contexts, including health science, it is challenging to collect all relevant variables to predict an outcome (and study their effects), and we can expect to have unseen confounders.\nWe train both NNs with a missing variable (fish intake) and compare both the predictive performance and the quality of extracted relationships on the test set. With SEANN, we integrate external knowledge for mercury alone (i.e., the variable correlated with the missing predictor), and we duplicate the mercury variable in both training and validation datasets, the copy being an unconstrained variable. The objective of this duplication is that 1) The constrained version captures what is known by external knowledge, and 2) The unconstrained version captures what comes from the unseen confounder.\nWe observe (Fig. 3) that without the constraint, mercury is incorrectly captured, with a Shap of 1.32. In this case, interpreting the Shapley values directly could lead to the misleading conclusion that mercury has a protective effect. On the contrary, with SEANN, the constraint allows the capture of the correct relation (\u2206Shap=0.013).\nAdditionally, SEANN was able to capture part of the association with the missing variable (fish intake) using duplicated input data of mercury (\u2206Shap: 0.43). Minor improvements were also observed for other variables. Results show that SEANN can be used to better disentangle individual effects while estimating the effect of unknown confounding factors."}, {"title": "Discussion", "content": "In this paper, we propose a method to integrate the wealth of knowledge available in the scientific literature encoded as PESS. While these representations are simple estimates unable to express complex relationships, they are easily understandable, can be aggregated across multiple studies, and are widely used in multiple domains of science, in particular in epidemiology. By integrating traditional statistical measures into the deep learning process, our approach offers a tool to capture complex nonlinear relationships from data while leveraging simpler but well-established knowledge.\nOur experimental protocol demonstrates that, compared with a standard DNNs, our approach offers two main benefits. First, a better generalization of the predictive performances on unseen data could be obtained under the condition that PESs contain relevant information for the task at hand that is lacking in the available data. This is a common use case, notably in epidemiology, where vast amounts of data are scarce and independent relationships are well studied across multiple studies on different populations. Second, significant improvements were observed in the alignment of extracted relationships with external knowledge when using SEANN, both for informed and uninformed variables. In particular, we demonstrated its potential to better disentangle individual input-output relationships in the presence of collinearity. In the continuity of our work on the early life exposome from the HELIX project [27,28], we plan to enhance the predictive power of our environmental clinical risk scores using this approach."}]}