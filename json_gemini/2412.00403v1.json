{"title": "FINE-TUNING PRE-TRAINED LARGE TIME SERIES MODELS FOR\nPREDICTION OF WIND TURBINE SCADA DATA", "authors": ["Yuwei Fan", "Tao Song", "Chenlong Feng", "Keyu Song", "Chao Liu", "Dongxiang Jiang"], "abstract": "The remarkable achievements of large models in the fields of natural language processing (NLP)\nand computer vision (CV) have sparked interest in their application to time series forecasting within\nindustrial contexts. This paper explores the application of a pre-trained large time series model,\nTimer, which was initially trained on a wide range of time series data from multiple domains, in the\nprediction of Supervisory Control and Data Acquisition (SCADA) data collected from wind turbines.\nThe model was fine-tuned on SCADA datasets sourced from two wind farms, which exhibited\ndiffering characteristics, and its accuracy was subsequently evaluated. Additionally, the impact of\ndata volume was studied to evaluate the few-shot ability of the Timer. Finally, an application study\non one-turbine fine-tuning for whole-plant prediction was implemented where both few-shot and\ncross-turbine generalization capacity is required. The results reveal that the pre-trained large model\ndoes not consistently outperform other baseline models in terms of prediction accuracy whenever the\ndata is abundant or not, but demonstrates superior performance in the application study. This result\nunderscores the distinctive advantages of the pre-trained large time series model in facilitating swift\ndeployment.", "sections": [{"title": "1 Introduction", "content": "The time series prediction of data collected by Supervisory Control and Data Acquisition (SCADA) system of wind\nturbines is a pivotal challenge as it serves as a foundational method of artificial intelligence (AI) in various aspects of\nwind turbine operations and maintenance (O&M), including data preprocessing[1, 2], fault diagnosis [3, 4, 5], and wind\npower forecasting[6, 7]. Within the sphere of data preprocessing, time series prediction is employed to fill in missing\nvalues by leveraging historical monitoring data. For fault diagnosis, the distribution of discrepancies between actual\nmonitored values and those generated by time series predictions is examined to identify anomalies. As for the domain\nof wind power forecasting, the outcomes of time series predictions are directly applied. Therefore, as the cornerstone of\nthese applications, the enhancement of time series prediction accuracy is crucial for improving their effectiveness and\nreliability, which in turn contributes to the efficiency and profitability of renewable energy generation.\nThe existing time series prediction methods are primarily based on deep learning, including recurrent neural network\n(RNN)[8], graph neural networks (GNN)[9], and the transformer[10]. Deep learning methods have made advancements\nin precision compared to classical forecast methods, but they have not yet demonstrated the advantages brought by the\nincrease in parameter scale of large models, which has been conducted in the fields of NLP and CV[11, 12, 13, 14].\nThe powerful problem-solving capabilities and the \"one for many\" generalization performance demonstrated by large\nmodels are impressive, and these abilities can play a significant role in the O&M of wind turbines. The wind turbine\nO&M is constantly challenged by the need for enhanced precision. Additionally, it necessitates a versatile approach\ncapable of generalizing across various turbine and facilities to accommodate the diversity in data patterns, thereby\nstreamlining the effort involved in developing and sustaining models.\nThere are two methods for applying large models to time series prediction: adjusting the large language models to\nfit the data patterns of time series, and training foundation models from scratch on time series data. The approaches\nto adapt large language models to time series include two types: text-visible LLM adaption and embedding-visible\nLLM adaption[15]. The former[16] converts numerical time series data into strings and integrates them into prompts\nalong with other contextual information. The prompts are then processed by LLM which generates outputs based on\nthe inference capabilities. The latter[17] embeds numerical time series data into vector sequences and fine-tunes the\nembedding layer on downstream time series datasets to align the vector representations of time series with those of text.\nThese two methods require fewer computational resources compared to training a large model from scratch and are\nmore easily integrated with text for multimodal analysis. However, the lack of evidence that time series data exhibit\npatterns similar to language raises doubts about the appropriateness of using large language models for time series\nforecasting, and existing literature has highlighted the limitations of these approaches, necessitating the development of\nlarge time series models specifically trained on time series data[18].\nTraining a foundation model for time series from scratch usually involves preprocessing time series data and designing\nmodel architecture. In the data preprocessing stage, data quality management is necessary, and due to the limited\namount of time series data in a single domain, alignment of the data formats across multiple domains is required. After\ndata preparation, large-scale pre-training is typically conducted based on the transformer architecture. As the training\ndata encompasses time series from diverse domains, the model acquires a broad-spectrum capability for analyzing time\nseries data across a variety of domains.\nTo ascertain the applicability of the large time series foundation model within specialized domains and to delineate its\ncomparative strengths and weaknesses against conventional models, this study employs a pre-trained large time series\nmodel named Timer[19] for the prediction of wind turbine SCADA data. Timer encompasses 67 million parameters\nand has been initialized with pre-training time series datasets spanning various sectors. The experiments organized\nand preprocessed the SCADA data from two real-world wind farms, which were subsequently used for fine-tuning\nand evaluation of the Timer. The variety in data volume and plant type (onshore or offshore) enables a comprehensive\nevaluation of the large time series model's performance across varying conditions. For the wind farm with adequate\ndata, the fraction of data employed in the fine-tuning was modified to further scrutinize the influence of data volume\non the model's predictive accuracy. This work also designed an application scenario of one-turbine fine-tuning for\nwhole-plant prediction, which necessitates both the few-shot and generalization capabilities of the model. Experimental\nresults across different wind farms and data volumes indicate that large time series model does not exhibit a dominant\naccuracy advantage in data-sufficient conditions. In scenarios with limited data, pre-trained large time series models\ndemonstrate few-shot learning advantages, although this capability does not significantly surpass that of LSTM in\nshort-term predictions. In the context of fine-tuning on a single turbine, the large model not only exhibits few-shot\nlearning ability but also generalization across turbines, yielding comprehensive accuracy advantages over other methods\nin this scenario. This demonstrates the strengths of pre-trained large time series models for rapid deployment in wind\nfarms.\nThe contributions of this paper include: (1) This paper applies the large time series foundation model to the time series\nprediction of real-world SCADA data; (2) A comparative study was conducted to evaluate the strengths and weaknesses\nof large time series model against conventional methods across varying data volumes and prediction horizons; (3)\nThe few-shot learning and generalization benefits of the large time series model was illustrated within the context of\nsingle-turbine fine-tuning for whole-plant prediction, offering valuable insight for future application of large time series\nmodels in wind turbine SCADA data."}, {"title": "2 Methodology", "content": ""}, {"title": "2.1 Timer", "content": "The Timer was proposed in reference[19], which is a 67-million-parameter transformer model that has undergone\nlarge-scale pre-training on time series datasets across multiple fields. It is pre-trained by performing autoregressive\nnext-token predictions on the time series, demonstrating promising performance in various downstream tasks across\nmultiple domains."}, {"title": "2.1.1 Data for pre-training", "content": "The Timer model was pre-trained on the Unified Time Series Dataset (UTSD), a high-quality collection of time series\ndata spanning various domains. The dataset integrates 29 distinct datasets, classified into ten different fields according to\ntheir origin, such as energy, environment, health, and others. This dataset incorporates time series with diverse sampling\nrates, extending from yearly to minute-by-minute intervals. UTSD implements a series of strategies to guarantee\nthe quality of the data. Initially, missing values in the data are addressed through linear interpolation; subsequently,\ncomprehensive statistical analyses are performed to evaluate stationarity and forecastability. These metrics facilitate the\nidentification of four superior subsets within UTSD, each escalating in complexity and variety of patterns in relation to\ntheir size. The most extensive subset, UTSD-12g, encompasses one billion data points. The vast scale of UTSD ensures\ncomprehensive model training and the acquisition of generalized time series patterns across a multitude of domains."}, {"title": "2.1.2 Single-Series Sequence", "content": "The Timer employs the single-series sequence (S3) format to standardize heterogeneous data from disparate sources,\naccommodating the formatting discrepancies that arise due to variations in the number of variables, sampling frequencies,\nand other attributes. S3 is an iteration of the channel-independent (CI) strategy. CI splits multivariate time series into\nunivariate series, with each variable analyzed independently, thereby disregarding the inter-variable correlations. In\ncontrast, conventional time series modeling often utilizes a channel-dependent (CD) strategy, which entails simultaneous\nmodeling of multiple variables, taking into account their inter-dependencies. Although the CI approach neglects the important correlations between variables, it offers a\nconvenient means of harmonizing such diverse data. Additionally, researches[20, 21] have shown that the CI, compared\nto CD strategy, offers better adaptability, lower training data requirements, and reduced risk of overfitting, leading to\nhigher precision in time series modeling.\nS3 extends the CI approach by not requiring temporal alignment within the same batch of time series samples, nor do\nthe samples need to originate from the same dataset. Additionally, S3 implements instance normalization, ensuring that\nthe training time points for each univariate sequence adhere to a normal distribution. This process helps to neutralize\ndisparities in amplitude across various datasets."}, {"title": "2.1.3 Tokenization", "content": "The Timer adopts a strategy of segmenting univariate time series into patches for the purpose of tokenization. Conven-\ntionally, each time point within a series is treated as an individual token. However, due to the quadratic relationship\nbetween the computational complexity of attention mechanisms and sequence length, tokenizing by individual points\nresults in a very high computational complexity for long sequences. Furthermore, the information of a single time point\noften pales in comparison to the importance of local trend characteristics. As a result, the practice of dividing time\nseries into patches of a defined size as tokens has emerged as a prevalent technique. The Timer utilizes non-overlapping\nwindows for segmentation and the tokenization formula is presented as follows:\n$S_i = {X_{(i-1)S+1},..., X_{iS}} \\in \\mathbb{R}^S, i = 1, ..., N$                                                                                                                                                 (1)\nwhere $X = {X_1, ..., X_{NS}} \\in \\mathbb{R}^{NS}$ is the original time series, and $s = s_1,..., s_N \\in \\mathbb{R}^{N\\times S}$ is the token sequence."}, {"title": "2.1.4 Decoder-Only Transformer", "content": "The Timer leverages a decoder-only transformer architecture for time series modeling. The distinction between\nencoder and decoder modules has been a fundamental aspect of transformer design since its inception, with the\nencoder facilitating global bidirectional attention for the extraction of features from time series data, and the decoder\nutilizing an attention mask to enforce unidirectional attention, thereby precluding tokens from attending to subsequent\npositions in the sequence. Inspired by generative pre-training (GPT), the decoder-only transformer configuration\nhas increasingly become the norm, as researches[22, 23] suggest that models based on this architecture demonstrate\nenhanced generalization capabilities. In alignment with this trend, the Timer model adopts the decoder-only transformer\nblock for its time series modeling. The model architecture of the Timer is depicted in Figure 2, and the equation of the\nmodel is presented as follows:\n$h_i = s_iW_e + TE_i, i = 1, ..., N$\n$H^l = TrmBlock(H^{l-1}), l = 1, ..., L$\n$\\widehat{s_{i+1}} = H[W_d, i = 1, ..., N$\n(2)\nwhere $W$ represents weights, $TE$ stands for the optional time stamp embedding, and $H = {h_i}$ is the latent\nrepresentation of the embedding and transformer blocks.\nSimilar to GPT, the Timer model also utilizes autoregression as its pre-training task, a self-supervised learning method\nthat equips the model with the capability to predict next token in a time series. This approach facilitates the model's\nability to learn from extensive, unlabeled time series datasets. The objective function for its pre-training task is presented\nas follows:\n$L_{MSE} = \\frac{1}{NS} \\sum_{i=2, ..., N} |s_i - \\widehat{s_i}|_2, i = 2, ..., N$\n(3)"}, {"title": "2.2 Fine-tune on SCADA dataset", "content": ""}, {"title": "2.2.1 Data Preprocessing", "content": "Prior to fine-tuning the pre-trained large time series model, it is essential to preprocess the SCADA data obtained\nfrom real-world wind farms to guarantee data quality. To exclude the influence of wind curtailment, sensor noise,\ntransient errors, and equipment failures, this work implements a data cleaning strategy designed to eliminate outliers by\nleveraging key variables within the wind turbine SCADA dataset.\nInitially, an examination of the distribution of each monitoring parameter within the SCADA data was conducted,\nremoving outliers likely resulting from sensor damage or data transmission issues. Subsequently, with consideration\nto the operational principles of wind turbines, additional data cleansing was performed by referencing the turbine's\nworking states across different wind speed ranges. Below the cut-in wind speed, the turbine is disconnected from\nthe grid, and the power output is nil. In the range between the cut-in wind speed and the rated wind speed, which is\nthe maximum power point tracking (MPPT) segment, the turbine maintains a blade pitch angle of zero degrees, thus\nachieving the highest wind energy utilization coefficient, where the relationship between power and wind speed is\napproximately cubic. From the rated wind speed to the cut-off wind speed, the turbine incrementally increases the\nblade pitch angle in response to rising wind speeds and ensure a constant rated power output. Consequently, leveraging\nthese principles, outliers primarily due to power limiting were identified and removed through the interrelation of wind\nspeed, power, and blade pitch angle: within the MPPT segment, an upper limit for the blade pitch angle was established,\nwith values exceeding this limit being flagged as outliers; in the range between the rated and cut-off wind speed, a\nlower limit for power was set, and data points falling below this threshold were excluded. Subsequently, density-based spatial clustering of applications with noise (DBSCAN) and\nlocal outlier factor (LOF) were applied for the final refinement of the SCADA data, with the objective of excluding\nmeasurement errors attributable to sensor malfunctions.\nAfter data cleaning, the distribution of normal data points on the time axis becomes discontinuous. In response to\nthis situation, this paper replaces individual existing outliers with linear interpolation and, according to the required\nsequence length of the time series, applies a sliding window to continuous normal time points to create time series\nsamples, ensuring that the patterns of the time series are not disrupted."}, {"title": "2.2.2 Fine-tune and Inference", "content": "The fine-tuning of the pre-trained Timer model on SCADA datasets for downstream tasks encompasses several key steps.\nInitially, the processed time series samples are transformed into the S3 format. Subsequently, given the simplicity of the\nautoregressive pre-training task for time series prediction, the finetuning also involves the prediction of the next token,\nutilizing the loss function detailed in Equation (3). Throughout the fine-tuning process, the Timer backbone parameters\nremain unfrozen, and no additional regression head is appended to the Timer model. Instead, a small learning rate is\napplied uniformly across the Timer model, with the Adam optimizer employed for optimization. Following fine-tuning,\nin a manner consistent with models that typically utilize autoregression, inference is carried out by iteratively forecasting\nthe next token. The number of iterations is determined by the required prediction horizon, and the requisite prediction\nlength is subsequently extracted."}, {"title": "3 Experiment", "content": ""}, {"title": "3.1 Dataset and Preprocessing", "content": "In the experiment, real-world SCADA datasets obtained from two wind farms located differently in China are utilized.\nPlant 1, an onshore plant equipped with 64 turbines each rated at 1.5 MW, provided data spanning three years. The\ninitial two years of data were allocated for constructing the training sets, while the final year was divided equally\nbetween validation and testing, each encompassing six months of data. Plant 2, an offshore wind farm with 121 turbines\neach rated at 4.0 MW, also provided a one-year dataset, where the training set comprised six months, and the validation\nand test sets each comprised three months. The SCADA data from all two wind farms were sampled at 10-minute\nintervals. The raw data underwent the cleaning process to eliminate outliers, and the efficacy of this method across the\nthree wind farms is illustrated in Figure 4.\nFour key variables were selected from the SCADA attributes to construct multivariate time series: wind speed, power,\ngenerator speed, and ambient temperature. A sliding window was employed to generate the time series dataset from\nthe continuous normal data points, with a window size of 768. For the training and validation sets, the window\nslid in increments of 100, whereas for the test set, the increment was 1. The numbers of samples used for training,\nvalidation, and testing are detailed in Table 1. Plant 1 offers a relatively large sample size, facilitating the assessment\nof the performance of large time series models in data-rich environments. Conversely, plant 2 present smaller sample\nsizes, which are suitable for evaluating whether large time series models demonstrate distinct properties compared to\ntraditional models in few-shot scenarios. The differences among these two wind farms in terms of wind farm type,\nturbine model, and data volume allow the experiment to cover a broad range of wind farm application scenarios."}, {"title": "3.2 Experiment Settings", "content": "This study encompasses three experiments. In the first experiment, the Timer was fine-tuned on the datasets obtained\nfrom the two wind farms and its time series prediction accuracy was assessed on the corresponding test sets. To\naccommodate various time series prediction scenarios, multiple prediction lengths were employed for the testing phase.\nFurthermore, the experiment includes a comparison between the Timer without pre-training or fine-tuning, and three\nadditional time series prediction models: long short-term memory networks (LSTM), two transformer models with\nvarying numbers of parameter. This comparative analysis across different scenarios serves to validate the applicability\nand benefits of the large time series model for predictions. The second experiment, carried out on plant 1, changed the\nquantity of samples used for training to delve deeper into the performance of the Timer under varying data volumes,\nparticularly in few-shot learning scenarios, and to ascertain its comparative advantages over traditional models. The\nthird experiment constitutes an application study, with the objective of utilizing the few-shot learning capabilities of\nlarge models and assessing their generalization ability. Data from a single wind turbine at Plant 1 was utilized for model\nfine-tuning or training, following which the model was applied to all turbines within the wind farm. The experiment\nis supposed to demonstrate the potential for rapid deployment inherent in large models, thereby circumventing the\nrequirement for extensive data collection procedures. The Mean Squared Error (MSE) was used to evaluate the accuracy\nof models.\nThe declaration of the hyperparameters for several models involved in the experiments is as follows. The Timer\narchitecture comprised 8 transformer decoder blocks, each with a model dimension of 1024, a feed-forward network\n(FFN) comprising 2048 hidden units, an 8-head multi-head self-attention mechanism, and a dropout rate of 0.1.\nIncluding both the input embedding layer and the output regression head, the Timer model encompassed a total of\n67.40 M parameters. In the process of tokenization, a sequence of 768 time points was segmented into 8 patches, each\nconsisting of 96 time points. The initial 7 tokens were employed as the historical context for predicting the 8th token,\nthereby deriving the temporal trend over a span of 96 time points. Actually, in the experimental setup, all parameters\nremained fixed, with the exception of the dropout rate and the number of tokens for the input, to ensure consistency\nwith the Timer architecture as pre-trained in the literature [19]. In the experimental setup, the Timer was examined\nacross three distinct training paradigms: training from scratch, utilizing pre-trained weights without further fine-tuning,\nand fine-tuning the pre-trained model. These configurations are designated as Timer-scratch, Timer-pretrained, and\nTimer-finetuned, respectively. Of particular interest is the performance of the Timer-finetuned model, whereas the other\ntwo configurations are primarily used to elucidate the effects of pre-training and fine-tuning on model efficacy through\ncomparative analysis.\nThe Transformer model adopted a channel-dependent and decoder-only architecture, utilizing a patch length of 96. For\nthe model with a larger scale of parameters, the configuration of the transformer blocks aligned with that of the Timer,\nyielding a total parameter count that closely mirrors the Timer, at approximately 68.00 million. For the Transformer\nwith fewer parameters, the architecture was streamlined by reducing the number of transformer blocks to 4, each with a\nmodel dimension of 256 and a FFN comprising 512 hidden units. This model is referred to as transformer-mini, and it\ncontains a total of 2.31 million parameters. The LSTM model, on the other hand, was structured as a unidirectional\nnetwork, featuring 128 hidden units, a depth of three layers, and a dropout rate of 0.1, processing the time series data\nsequentially step by step without patching.\nAll models were trained utilizing the Adam optimizer. For models trained from scratch, an initial learning rate of\n1 \u00d7 10-4 with a cosine decay scheduler was employed across a total of 2000 epochs. Fine-tuning was performed with a\nreduced learning rate of 5 \u00d7 10-6 for 100 epochs. The number of epochs was chosen to ensure convergence across\nvarying data volumes, and early stopping was implemented for both training and fine-tuning phases, based on the\naccuracy achieved on the validation set."}, {"title": "3.3 Results", "content": ""}, {"title": "3.3.1 Plant 1", "content": "The MSE of different methods across various prediction length on the initial wind farm dataset is detailed in Table 2,\nwith the optimal outcomes for each prediction length highlighted in bold. The results reveal that the LSTM model attains\nthe highest precision for short prediction length, whereas the Timer-finetuned outperforms others as the prediction\nlength extends. Moreover, when the prediction length equals 96, the Transformer-mini model demonstrates the greatest\naccuracy. The variation in accuracy with prediction length is depicted in Figure 5.\nThe results imply that the three models are suitable for distinct predictive scenarios, and that the pre-trained and\nfine-tuned large models do not universally outperform across all prediction tasks. The LSTM model, with its step-wise\nmodeling approach, provides superior accuracy for single-step predictions but is less effective for long-term forecasting"}, {"title": "3.3.2 Plant 2", "content": "On Plant 2, the MSE for different methods is presented in Table 3 and Figure 6. The results indicate that, on this dataset\nwith insufficient data, the Timer that has undergone pre-training and fine-tuning demonstrates a more pronounced\ncomparative advantage over other methods featuring a large parameter scale. The enlarged accuracy gap between\nthe pre-trained and scratch models indicates that pre-training confers enhanced few-shot capabilities to the model,\nallowing for better prediction performance with less data. However, this advantage is more effective in the short term.\nFor the transformer and transformer-mini models, which have a large scale of parameters, the impact of data quantity\non accuracy is significant, resulting in a loss of predictive capability for both short-term and long-term prediction.\nComparison between the two models reveals that an increase in the scale of parameters may lead to a decrease in\naccuracy, potentially due to overfitting when faced with limited data. This finding also underscores the importance of\npre-training for the application of large models. For LSTM, which has fewer parameters than the transformer-based\nmodels, the influence of data volume on predictive accuracy is relatively diminished. Short-term accuracy is comparable\nto that of the Timer-finetuned but continues to demonstrate suboptimal performance in long-term forecasting."}, {"title": "3.3.3 The influence of data volume", "content": "To examine the influence of data volume on model accuracy, the proportion of data allocated for training was adjusted\nto train or fine-tune models. The test results are depicted in Figure 7, where the accuracy of the pre-trained Timer in the\nzero-shot context is delineated by a purple horizontal line as a baseline. Pre-trained large time series models necessitate\nless data for short prediction horizons as compared to other transformer-based architectures, where accuracy remains\nlargely stable with diminishing data volumes. Nevertheless, the benefit of pre-training wanes as the prediction horizon\nextends. Notably, the Timer-scratch, which has the same scale of parameters as the Transformer but lacks pre-training,\ndoes not exhibit a significant decline in accuracy. This is possibly due to its channel-independent strategy that provides\nstronger generalization capabilities. The LSTM still exhibits a reduced dependency on data volume, with advanced\naccuracy lying in short-term forecasting. However, it tend to exhibit unstable performance when tasked with long-term\nprediction."}, {"title": "3.4 One-turbine Fine-tuning for Whole-Plant Prediction", "content": "Data from a single wind turbine at Plant 1 were employed to fine-tune the pre-trained large model and to train\nbenchmarks, which were then evaluated using data from all turbines in the wind farm. This application not only\ninvestigates the influence of data volume but also evaluates the models' generalization capabilities across various\nindividual turbines. To mitigate the effects of randomness, the test was conducted three times, each time utilizing data\nfrom a distinct turbine. The average MSE across these three trials is detailed in Table 4. The fine-tuned pre-trained large\nmodel demonstrated superior performance across all prediction lengths. While in the previous experiment, some models\nmay outperform the Timer-finetuned for specific prediction lengths when the data is limited, the pre-trained large"}, {"title": "4 Conclusion", "content": "This paper explores the application of large foundation models for time series in the prediction of wind turbine SCADA\ndata. Two wind farms, encompassing both onshore and offshore facilities, and turbines with capacities of 1.5 MW\nand 4 MW, were employed to assess the predictive efficacy of the large model, Timer, and to benchmark it against\nalternative methodologies. The experimental results across various wind farms and data volumes suggest that the large\ntime series model does not consistently yield a superior accuracy in data-abundant cases. In scenarios of limited data,\nit manifest few-shot learning advantage, although this does not notably outperform LSTM in short-term forecasting.\nWhen fine-tuned on data from an individual turbine, the large model not only demonstrates its few-shot learning capacity\nbut also its ability to generalize across different turbines, resulting in a comprehensive accuracy enhancement compared\nto other models within this specific context. These findings underscore the utility of pre-trained large time series models\nfor expedited deployment in wind farms.\nIn the experiments, the influences of various components within the pre-trained large model on its overall performance\nwere examined. It is evident that the impact of pre-training on model accuracy is predominantly observed in short-term\npredictions. Additionally, a comparative analysis of Transformers with varying parameter counts suggests that an\nincrease in parameters predominantly enhances short-term prediction accuracy. These observations may stem from\nthe inherent volatility and randomness of wind resources, which introduce higher unpredictability into wind turbine\nmonitoring data compared to other domains encountered during pre-training, with only short-term temporal patterns\nbeing effectively captured. However, in short-term prediction scenarios, such as one-step-ahead forecasting, the LSTM,\nwhich processes sequences step-by-step and has a small scale of parameters, surpasses large models that treat patches\nas tokens, regardless of whether data is abundant or limited, which diminishes the prominence of the advantages of\npre-trained large time series model. Consequently, for time series prediction of SCADA data, further refinement of\ncurrent large time series models is necessary, particularly in terms of model architecture and pre-training data selection,\nto broaden the applicability and enhance the performance."}]}