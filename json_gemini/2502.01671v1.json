{"title": "Life-Cycle Emissions of Al Hardware:\nA Cradle-To-Grave Approach and Generational Trends", "authors": ["Ian Schneider", "Hui Xu", "Stephan Benecke", "David Patterson", "Keguo Huang", "Parthasarathy Ranganathan", "Cooper Elsworth"], "abstract": "Specialized hardware accelerators aid the rapid advancement of artificial intelligence (AI), and their efficiency impacts Al's environmental sustainability. This study presents the first publication of a comprehensive AI accelerator life-cycle assessment (LCA) of greenhouse gas emissions, including the first publication of manufacturing emissions of an AI accelerator.\nOur analysis of five Tensor Processing Units (TPUs) encompasses all stages of the hardware lifespan-from raw material extraction, manufacturing, and disposal, to energy consumption during development, deployment, and serving of AI models. Using first-party data, it offers the most comprehensive evaluation to date of AI hardware's environmental impact. We include detailed descriptions of our LCA to act as a tutorial, road map, and inspiration for other computer engineers to perform similar LCAs to help us all understand the environmental impacts of our chips and of AI.\nA byproduct of this study is the new metric compute carbon intensity (CCI) that is helpful in evaluating AI hardware sustainability and in estimating the carbon footprint of training and inference.\nThis study shows that CCI improves 3x from TPU v4i to TPU v6e.\nMoreover, while this paper's focus is on hardware, software advancements leverage and amplify these gains.", "sections": [{"title": "1 Introduction", "content": "The energy consumption and environmental impacts of artificial intelligence (AI) have generated widespread interest, due to the growing compute requirements of AI models [39]. However, comprehensive assessments of Al's greenhouse gas (GHG) emissions remain limited, hindering the development of standardized quantification methods. This study quantifies the GHG emissions of five Google Al hardware accelerators, adapting the LCA methodology to establish a repeatable process and a consistent metric (Compute Carbon Intensity or CCI) for wider use.\nA comprehensive analysis of the GHG emissions associated with AI includes the entire lifespan of the hardware, from the extraction of raw materials to manufacturing, energy use, and eventual disposal."}, {"title": "2 Definition of concepts and assumptions", "content": "The functional unit for this study is one AI computer deployed in the data center, which includes one or more accelerator trays (containing TPUs) connected to one host tray (i.e., a computing server). This configuration is a standard practice across all Google TPU generations. Due to the definition of the functional unit, peripheral components beyond the tray (e.g., rack, shelf, network equipment) and auxiliary computing and storage resources are excluded from the calculation of embodied and operational emissions. We include data center cooling overheads in operational emissions.\nWe use a lifespan of six years for Al machines. While machine lifespans vary, this length is a reasonable assumption in line with those found previously [52]. Appendix A provides more details on the specific aspects of the AI computer's lifecycle that are in- cluded in the study, using the GHG Protocol [14]-the internation- ally accepted GHG accounting and reporting standard-to define the categories of the emission inventory boundary.\nFor all platforms covered in this study, GHG emissions are in grams or kilograms of carbon dioxide equivalent emissions (gCO2e or kgCO2e). We use emission factors from the IPCC Fifth Assess- ment Report (AR5) [32] to estimate GHG emissions associated with data center operations. While newer factors may be available, the AR5 provides a widely recognized and standardized methodology, ensuring comparability with other studies and facilitating a consis- tent assessment of AI hardware's climate impact.\nTo calculate electricity-related emissions (\"Scope 2\"), we multiply operational electricity consumption by the annual average electric- ity emission factor, which can be assessed in a number of ways. Two commonly accepted methods come from the GHG Protocol:\n\u2022 Location-based (LB) GHG emissions refer to the GHG emis- sions emitted within a specific geographic boundary, such as a country or grid region. LB emissions are calculated us- ing the annual average electricity emissions factor for the defined grid. They exclude the impact of carbon-free energy (CFE) procurement, so it's the most conservative standard we consider.\n\u2022 Market-based (MB) GHG emissions account for the GHG emissions emitted by generating sources from which a com- pany purchases electricity and associated environmental attributes. It thus credits companies for CFE purchases, al- lowing them to reduce their associated MB emissions. To- day's Scope 2 Standard allows companies to reduce their MB emissions by purchasing CFE to match their demand on an annual basis within broad geographic boundaries that may not reflect deliverability of that electricity."}, {"title": "3 CCI: A novel CO2e/performance metric", "content": "Vahdat et al. [53] opine that we need new metrics to guide us \"to find a path to grow AI and cloud computing efficiently and respon- sibly.\" To accurately compare the emissions across generations and relative to other architectures, we need to define a suitable mea- sure of carbon intensity. Vahdat et al. [53] suggest a performance measure of CO2e relative to \"Workload Goodput\": CO2e/Goodput.\nWe propose a new metric related to CO2e/Goodput based on first-party measurement data of workloads run in data centers that we call compute carbon intensity (CCI). It is the CO2e per utilized floating-point operation (FLOP), or CO2e/FLOP. The denominator of CCI is a fixed amount of computation, not a rate: its unit is number of FLOPs, not FLOPs/second.\nThis assessment aspires towards the CO2e/Goodput ideal by ac- counting for the varying throughput and energy use of accelerators based on evaluations in the fleet and on their embodied footprint."}, {"title": "4 Results and discussion", "content": "This result shows how the life-cycle carbon intensity of Google TPUs, normalized by performance, has improved with each succes- sive machine generation. It is essential to normalize by performance because newer machines are substantially faster than older ones."}, {"title": "4.1 Result 1: Generational trends of TPU carbon intensity", "content": "This result shows how the life-cycle carbon intensity of Google TPUs, normalized by performance, has improved with each succes- sive machine generation. It is essential to normalize by performance because newer machines are substantially faster than older ones."}, {"title": "4.2 Result 2: Emissions by life-cycle stage", "content": "The life-cycle GHG emissions methodology presented in the appen- dices allows us to completely characterize the life-cycle emissions of deployed Al hardware. The third segment of Table 1 above summa- rizes lifetime emissions for Google's several recent generations of TPUs, and Figure 3 shows the percentage break down of emissions by contributions from each life-cycle stage.\nThese results illustrate that over the six year accelerator lifetime:\n\u2022 Operational electricity emissions dominate embodied hard- ware emissions. Operational emissions are ~70% of emissions when including Google's CFE procurement (market-based electricity) and ~90% of emissions when not including CFE procurement (location-based).\n\u2022 Google's CFE purchases substantially mitigate operational emissions under the GHG-protocol aligned MB operational emissions metric, reducing them by more than half.\nConsider more accurate standards for operational emis- sions accounting. We can more accurately account for operational emissions and more effectively mitigate them through more selec- tive CFE purchases. The current market-based (MB) approach under the GHG Protocol allows for emissions mitigation strategies that differ widely in effectiveness. Most companies focus on procuring CFE to match their annual electricity demand, often from projects located far from where they consume power. A significant and growing body of academic research employing robust energy sys- tem modeling approaches has shown that corporate matching of electricity use on a locational and hourly basis, even at levels be- low 100%, can drive greater grid decarbonization and accelerated technology innovation compared to matching electricity demand at an annual level [1, 40, 56].\nIn 2020, Google set an ambitious goal to run on 24/7 CFE on every grid where we operate by 2030 [10]. This approach involves matching electricity consumption with CFE sources on an hourly basis, ensuring that operations are met with clean energy at all times. To better align with this goal, we can calculate electricity emissions factors using a 24/7 methodology that employs stricter geographical and temporal matching requirements for CFE; see Appendix C for more details. This methodology provides a more accurate and conservative picture of emissions reductions from CFE procurement compared to the predominant MB approach (i.e., the electricity emission factor will be higher)."}, {"title": "4.3 Result 3: Manufacturing emissions trends by TPU generation", "content": "Result 4.1 illustrates that CCI is decreasing with each successive generation of AI hardware. That trend is replicated when we specif- ically consider machine manufacturing emissions (blue parts of Figure 2). The embodied CCI decreases by 66% from v5e to v6e and by 29% from v4 to v5p. The deep reduction from v5e to v6e is be- cause peak performance improved by 4.7x whereas manufacturing emissions increased by only 1.8x. While new TPUs are more carbon intensive to manufacture and operate, the new machines provide much more useful workload throughput than older AI machines.\nFigure 4 on the next page shows the increase in absolute manufac- turing emissions of newer generations and highlights the primary component drivers of the increase in absolute emissions. The adop- tion of advanced manufacturing technologies and more resources added to the machine both increase absolute emissions.\nTaking the three versatile TPU platforms (i.e., v4i, v5e, v6e), kgCO2e per chip for manufacturing emissions increased 1.8x from the v4i to v6e. Based on the breakdown of manufacturing GHG emis- sions, a larger TPU ASIC die-along with larger High Bandwidth Memory (HBM) modules packaged alongside the TPU chip (see Figure 6 below)-and growing DRAM capacity in the host compute tray are the two most important emission drivers. Printed circuit board assembly (PCBA) and thermal are the two other important commodities, but increases in these two areas are smaller."}, {"title": "4.4 Result 4: TPU emissions trends for two specific training tasks", "content": "This section provides a granular analysis of the carbon emissions associated with running identical example workloads on two TPU generations: v6e and v5e. This micro-level comparison offers in- sights into the CO2e of jobs executed on different TPU platforms."}, {"title": "5 LCA versus Corporate Inventories", "content": "Our LCA found that the operational (electricity-related) emissions dominate the lifetime emissions of AI hardware (see Section 4.2). For the platforms we considered, approximately 25% of AI hardware life-cycle emissions come from manufacturing, using the market- based operational electricity emissions.\nIt would seem one could use a company's annual corporate emissions inventory to estimate the embodied versus operational emissions of Al hardware [16]. However, in Google's Environmen- tal Report [12], about 32% of Google's 2023 corporate emissions are attributable to hardware manufacturing of Tier 1 and beyond suppliers (Capital Goods and Other categories).\nSurprisingly, this gap is expected due to the differing calculations of this LCA and Google's corporate inventory. This gap comes from these key distinctions between the two approaches:\n(1) Accounting Methodology: The LCA approach follows ISO 14040 and 14044 standards that consider emissions associated with a well-defined functional unit. These standards allow for the amortization of emissions over its lifetime. However, Google's corporate inventory [12] follows the GHG Protocol: Corporate Standard that does not allow for amortization of Capital Good emissions across hardware lifetimes. Thus, emis- sions for a given hardware purchase will be disclosed fully in the first year of use, while only ~1/6th of the hardware lifetime and ~1/20th of the data center lifetime occurs in the first year. This accounting approach is the largest difference between emissions from the LCA and corporate inventories.\n(2) Other Emissions Sources: The LCA considers only the functional unit of the AI accelerator and host machine. The corporate inventory of Google includes a wider inventory boundary that includes emissions sources unrelated to AI, including emissions outside the data center and emissions associated with manufacture of consumer devices. Some of these emissions are unrelated to A\u0399.\nDue to the different methodologies and the continuous growth of Google's data centers, the annual reported hardware emissions in Google's corporate inventory are driven by first-year hardware purchases and the rate of data center growth, and therefore do not directly correspond to a lifecycle view of the machines deployed by Google."}, {"title": "6 Related work", "content": "The existing literature provides targeted assessment of the envi- ronmental impact of certain Al workloads, but often lacks a com- prehensive and consistent view of these impacts. Here we provide the context of many of these studies following the cradle-to-grave life-cycle that Figure 1 above defines.\nAI accelerator hardware manufacturing emissions and life- cycle assessment studies are relatively limited in the literature. Kuo et al. [27] show that improvements in semiconductor manufacturing processes and node size have led to reduced life-cycle manufactur- ing emissions of DRAM; DRAM is an important component of AI accelerators, as DRAM memory is one of key drivers of the overall Al hardware footprint in our results. Luccioni et al. [31] estimate emissions associated with server and GPU hardware of the open-access BLOOM language model. For the embodied emissions of AI,"}, {"title": "7 Conclusion", "content": "We believe this is the first published study of a cradle-to-grave analysis of the carbon footprint of AI hardware, including the first publication of manufacturing emissions of an AI accelerator. To complete our evaluations, we needed a new carbon intensity metric related to CO2e/goodput called compute carbon intensity (CCI), measured as gCO2e/ExaFLOP. We believe this metric will be useful for many in evaluating AI hardware emissions comprehensively, and helpful in estimating the carbon footprint of their workloads. Ideally, CCI would join performance/TCO [23] as a design target and the detailed appendices will act as a tutorial, road map, and inspiration that encourages more engineers to perform LCAs.\nThe CCI metric can help clarify the multiplicative impacts of hardware and software improvements. Hardware improvements reduce CCI: g CO2e/ExaFLOP. Software efficiency improvements reduce the number of computations (FLOPs) required relative to the model quality. Improving each by 3x would result in a 9x reduction in carbon emissions for the same model quality.\nOur evaluation led to the following observations:\n(1) More advanced TPU chips and increasing memory demand drive embodied emissions-representing more than half of all embodied emissions with memory alone more than a third- yet CCI from manufacturing still declines each generation, suggesting performance gains via more efficient hardware design outweigh increases in manufacturing emissions.\n(2) Operational emissions dominate AI hardware lifetime at 70% to 90% of total emissions, with manufacturing emissions under 25% and data center construction emissions under 5%.\n(3) When evaluating AI benchmark workloads, workload emis- sions decline per TPU generation. For example, gCO2e per training step dropped 27% to 39% over one TPU generation when training the same model.\n(4) CCI as measured across Google's fleet declines with each TPU generation, delivering a 3x improvement in CCI from TPU v4i to TPU v6e (Trillium)."}, {"title": "A Steps of a Life-Cycle Analysis (LCA)", "content": "To assess supply chain manufacturing GHG emissions, we per- formed machine-level cradle-to-gate (i.e., from start to delivery) Life-Cycle Assessments (LCA), consistent with international LCA standards (ISO 14040 and 14044), applying industry best practices. For readers unfamiliar with an LCA, we believe the appendices can be a tutorial, as they detail all the steps to perform an LCA. After defining the boundaries between the development and use stages, this appendix shows how to properly collect emissions data over the lifetime of computer equipment, including data centers. Appendix B then gives a concrete example of an LCA for TPU v5e. Appendix C introduces 24/7 emissions and Appendix D describes efforts to standardize carbon footprint assessments for electronics."}, {"title": "A.1 Inventory boundary and exclusions", "content": "For LCA modeling, the system boundary covers all stages along the supply chain and usage phases, including manufacturing, oper- ations in data centers, and end-of-life disposal. On the other hand, since corporate emissions are typically reported following the GHG Protocol [14], we define the emission inventory boundary of this study along the operational control consolidation approach and divided life-cycle emissions into three scopes. Operational control includes activities where the developer has control to implement op- erational changes. In order to provide a comprehensive view of AI"}, {"title": "A.2 Manufacturing emissions", "content": "At the core of our semiconductor assessments we use a combination of advanced life-cycle inventories for front-end and wafer-level pro- cesses based on IMEC's virtual fab. We customized these analyses to Google's chip designs incorporated into our platforms, and propri- etary life-cycle inventories to account for the remaining back-end chip and panel-level assembly. The virtual fab in IMEC.netzero [20] utilizes a detailed, bottom-up approach to assess environmental impacts. It starts by analyzing process flows, recipes, and tool data to create a virtual model of a high-volume semiconductor manu- facturing facility. This model incorporates a variety of logic and memory technologies, i.e., DRAM and NAND, across different pro- duction nodes (both current and upcoming). Moreover, advanced packaging life-cycle inventories allow for the configuration of HBM"}, {"title": "A.2.1 Life-cycle inventory data.", "content": "The Life-Cycle Inventory (LCI) data used for AI machine LCAs is a combination of primary and secondary (or industry average) datasets-see Table 3-collected through a combination of various methods and data sources, in- cluding bill of materials (BOMs), GCM engagement, and supplier- provided primary data. When necessary, detailed teardowns are conducted on platform trays to confirm completeness of compo- nents captured through above-mentioned methods and fill data gaps on part dimensions and materials.\nThe product system scope follows a bottom-up approach con- sidering all physical components that make up individual trays. Figure 5 shows that for a typical tray, major components include the processors (e.g., CPU or TPU), memory (e.g., DRAM, SSD), printed circuit boards assemblies (PCBAs), thermal management solutions (e.g., heatsink, cold plate), mechanical components (e.g., base tray enclosure), and electromechanical components. For the selected TPUs, the full list of hardware components is mapped to the internal LCA commodity-level data repository.\nWe build on comprehensive data repositories that are indepen- dently third-party reviewed, by deploying a combination of Sphera Professional Databases [45] and ecoinvent [9]. Both data sources are the most established among LCA practitioners in the Informa- tion and Communication Technology (ICT) sector and are frequently updated to remain accurate, relevant, and comprehensive. Our fore- ground models allow for the necessary configurability of the LCIs to ingest key primary data points relevant to technologies in scope and supplier-specific activity. While we customize chip production using IMEC's virtual fab, commodities such as PCBAs, mechani- cal enclosures, and thermal management, are configured through proprietary, parameterized models in LCA for Experts."}, {"title": "A.2.2 Life-cycle impact assessment.", "content": "Once an LCI completes, we assess the cradle-to-gate environmental impact of an Al machine by characterizing its LCI using life-cycle impact assessment (LCIA) [26]. This process quantifies energy and material flows included in the system boundary, and measures the environmental outcome using a common metric. Since our focus is carbon emissions, the metric for climate change impact is typically expressed as carbon inten- sity per functional unit, such as kg CO2e per kg of metal used for base tray, or kg CO2e per kWh of electricity used for chip produc- tion. GHG beyond CO2 (e.g., N2O, CH4, SF6, etc.) are converted to CO2e equivalents using global warming potential (GWP) [19] as the environmental impact indicator of choice in this study. Because GHG emissions include not only CO2, we need a metric to quan- tify the relative contributions of different substances. The GWP is commonly used to convert climate change impact of non-CO2 emissions to the CO2e equivalent. We use GWP for a one hundred year timeframe (GWP100) from the 5th assessment report (AR5) of the Intergovernmental Panel on Climate Change (IPCC) [32]."}, {"title": "A.2.3 Transportation emissions.", "content": "The hardware transportation GHG emissions for Al machines include transportation emissions asso- ciated with shipping AI trays from manufacturing sites to data centers. For the AI accelerator tray, transportation GHG emissions include three major segments: 1) ground shipping from the manu- facturing site in Asia to a nearby departing airport, 2) shipping to a Google hub in the US, and 3) ground transportation from the hub to individual data centers. For host trays, transportation emissions are modeled as a combination of sub-assemblies. For mechanical components, transoceanic travel is modeled as ocean shipping. For the rest (chips, PCBA), transoceanic travel is modeled as air travel. Once they arrive in the US, ground transportation emissions from hubs to individual data centers are added. Emissions reflect weight of both the tray itself and the packaging portion."}, {"title": "A.3 Operational (Development and Serving) electricity emissions", "content": "This section describes the methodology to estimate the energy consumption and electricity-related emissions of AI hardware in Google's fleet. In Section 2 we estimated the carbon intensity of electricity consumption in the data centers where Al hardware is deployed. To estimate the electricity-related emissions from a spe- cific machine (e.g., TPU v5p), we also need to collect power / energy measurements from all machines of that type deployed in Google data centers. We leverage existing hardware and software systems built by Google to allow for measurement and estimation [42].\nFor each Al hardware device in this study, we measured power consumption from each tray via its power supply unit (PSU), which includes an estimate of 4% overhead for rectifier losses. We use these measurements from the PSU of each machine tray to collect average Al machine power data. To get the total energy measured for a machine, which may include multiple trays, we sum the total power measured across all tray PSUs, plus estimated rectifier losses. Thus, the number of measurements is a function of the number of trays per machine: e.g., two for v5p (motherboard and one TPU tray) and three for v5e (motherboard and two TPU trays). In each case, the TPU tray itself includes a printed circuit board with four TPU chips; see Figure 5 above for an example.\nTray power data is collected from a central Google database, where measurements are collected every five minutes. For PSU power data, the reading is the average power consumption mea- sured at the PSU sensor for the past five minutes, so it represents average power. In some cases, a small portion of machines may have missing power readings for trays (e.g. due to sensor failures), and these observations are excluded from analysis.\nTo get the average energy consumption per day, we take the total energy consumption of all machines of a particular machine type over a representative month (e.g., October 2024), and then divide by the number of machine-days in that sample. To get the average lifetime operational energy consumption for a machine type, we then multiply this value by the assumed six year machine lifetime and the average Google data center power usage effectiveness (PUE). Google's 2024 average PUE is 1.10 [12]."}, {"title": "A.4 End-of-Life emissions", "content": "By applying Google's Zero Waste to Landfill strategy [12], cascaded use (through a combination of device lifetime extension and end- of-life material recovery) leads to net carbon credits if deployed in closed loops. We estimate through LCA, that the latter has the potential to offset embodied emissions by up to 4%, applying the avoided burden approach to value of scrap material. Bulk metal scrap is collected from uniform aluminum, steel and copper alloys"}, {"title": "A.5 Data center construction and Scope 1 emissions", "content": "Two additional contributors of Al life cycle emissions are the con- struction of data centers that house Al hardware and Scope 1 emis- sions from local backup generation for data center emergencies. Since these emissions are very small in the life-cycle of AI hardware (<5%), we reuse a simple existing approach from Google's Cloud Carbon Reporting [5] to roughly estimate their emissions."}, {"title": "A.5.1 Embodied emissions of data center facilities.", "content": "This emission source encompasses the embodied emissions of data center con- struction materials and the emissions associated with the construc- tion itself. This includes site infrastructure such as coolant systems and power systems. Using life-cycle analysis, Google has estab- lished a data center construction emissions footprint, accounting for the size of new data center additions. This scaled footprint is then amortized over 20-years."}, {"title": "A.5.2 Scope 1 - Fossil fuels combusted onsite & fugitive emissions", "content": "from onsite HVAC (heating, ventilation, air conditioning). These emis- sions include all data center onsite fuels use-e.g., for backup power, water and space heating, and transportation (fleet vehicles)-and fugitive emissions from HVAC leakage. Google calculates the re- sulting carbon footprint in its emission reports; we apply a fraction proportional to each TPU's share of overall energy consumption.\nFor both categories, total annual emissions are allocated across all data center machines and workloads relative to their fraction of total annual data center energy consumption."}, {"title": "B Example: Embodied Emissions of TPU v5e", "content": "Taking the TPU v5e machine as an example, the LCA process starts with compiling bills of materials for the accelerator tray and host tray. Based on the components on each tray, a detailed LCI database is constructed and used for LCA modeling. For large integrated cir- cuits like TPUs, we use the IMEC.netzero tool and technology-node specific data sets that were developed with the industry-joint IMEC SSTS program. This new tool is a big improvement in integrated circuit manufacturing modeling capabilities by allowing us to:"}, {"title": "B.1 Manufacturing and transportation emissions", "content": "Taking the TPU v5e machine as an example, the LCA process starts with compiling bills of materials for the accelerator tray and host tray. Based on the components on each tray, a detailed LCI database is constructed and used for LCA modeling. For large integrated cir- cuits like TPUs, we use the IMEC.netzero tool and technology-node specific data sets that were developed with the industry-joint IMEC SSTS program. This new tool is a big improvement in integrated circuit manufacturing modeling capabilities by allowing us to:"}, {"title": "B.2 Operational emissions", "content": "Following the methodology outlined in Appendix A, Table 1 above presents the measured power for TPUs. Measurements of actual measured power in the fleet illustrate the importance of using mea- sured data rather than machine thermal design power (TDP), which can be 2x to 3x higher. This result justifies the use of average hourly power in this study; the alternatives, TDP or a fixed fraction of TDP, are very coarse approximations. To account for data center over- heads, we multiply by Google's average data center PUE, 1.10 [12]."}, {"title": "C Introduction to 24/7 CFE", "content": "A number of leading academic studies find that annually matched CFE procurement has less impact than hourly matching [1, 40, 56]. One problem is the GHG Protocol Scope 2 Guidance [44] allows companies to reduce their electricity emissions by matching annual electricity use with CFE purchases including from unbundled EACs (Section 4.2) that may have little impact on reducing actual system emissions [3]. Companies that purchase solar or wind energy to match 100% of their annual electricity consumption may still rely on carbon-emitting grid electricity for over 50% of their demand [7]. This discrepancy has become even more significant as the rapid progress of Al has increased the electricity demand in a number of regions where fossil generation still provides a significant share of electricity and where new clean power solutions are needed [21].\nTo try to address these inaccuracies, in 2019 Google developed another electricity accounting system-what we call 24/7 Carbon-free Energy (CFE)-that goes beyond the traditional Scope 2 rules to restrict both the location and time period where CFE purchases can be applied to reduce Scope 2 emissions. Using this method, a MWh of purchased CFE must be matched to a MWh of consumed electricity that is delivered to the same local grid boundary and in"}, {"title": "D Initiatives and Process Flow of Manufacturing Emissions Methodology", "content": "Figure 7 gives an example of the process flow followed in this paper. To try to standardize product carbon footprint assessments for electronics, Google is actively collaborating with industry part- ners on unified methodologies for conducting LCAs for specific Information and Communication (ICT) devices. A key focus is the development of Product Category Rules (PCRs) that aim to streamline supplier data collection and ensure comparability across assessments, with the overarching goal of aligning with established standards like ISO 14040/44/67, the GHG Protocol, and EU PEF guidelines. We started with the impact category of climate change, planning to expand to additional impact categories in the midterm.\nWhile Google is already sponsoring the development of a PCR for computers and laptops [46], the initiation of a parallel industry- joint workstream specific to Data Center Equipment is underway via the Open Compute Project's Sustainability project. This col- laborative effort will involve documenting existing LCA practices and further developing configurable, parameterized model build- ing blocks relevant to data center equipment, ensuring alignment between data developers. Additionally, the initiative will define sufficient data accuracy and coverage to enable the identification of hotspots, drive supply chain action, and facilitate carbon-aware product design decisions. A key outcome will be the establishment of a standardized approach to primary data reporting throughout the supply chain, contributing to a more harmonized and transpar- ent approach to carbon footprint assessments in our industry."}, {"title": "E On-Duty Machine Power for Benchmark Workloads", "content": "Accurately determining on-duty machine power is crucial for com- puting the Scope 2 carbon emissions per step for Result 4 in Section 4.4. To achieve this accuracy, we collected machine power and duty cycle data for each machine at five-minute intervals throughout each workload run.\nFigure 8 displays this data for two representative runs. As il- lustrated, average machine power closely tracks duty cycle over time. However, interruptions can lead to periods of inactivity where machines are idle, creating gaps in job execution. To account for these idle periods, we employ a filtering strategy: only timestamps where all machines assigned to the run have a duty cycle of at least 80% are included in the analysis. This filter ensures we capture ma- chine power solely during active job execution, excluding periods of inactivity. For each run, the average on-duty machine power is calculated across all machines and all included timestamps.\nThis approach is applied to both complete and incomplete runs. Incomplete runs, which may be stopped for various reasons (e.g., sufficient steps processed for meaningful metrics), can still provide valuable data points, because the energy and Scope 2 carbon per step during completed steps are not affected by the eventual early termination of the workload. We manually validate the calculated power for incomplete runs to ensure we only include runs that fall within a reasonable range."}, {"title": "F Propensity Score Weighting", "content": "Directly comparing emissions across TPU generations (e.g., CO2e per machine-day) is challenging due to varying utilization patterns: older platforms generally exhibit lower utilization rates (both duty cycle and FLOPs/second) than newer platforms, potentially due to migration trends. Since each platform typically achieves higher performance-weighted energy efficiency at higher utilization, a naive comparison risks overstating the efficiency improvements of newer platforms. This liability comes from conflating two factors:\n(1) Inherent efficiency gains: Newer platforms are inherently more energy efficient.\n(2) Utilization differences: Newer platforms tend to operate at higher, more energy-efficient utilization rates.\nTo isolate the impact of inherent efficiency gains (factor 1), we employ propensity score weighting, a statistical technique [41] that:\n\u2022 Balances utilization levels. By weighting observations based on their probability of being assigned to a specific accelerator given their utilization, we create a \"pseudo-population\" with similar utilization distributions across generations, and\n\u2022 Reduces confounding. This balancing minimizes the con- founding effect of utilization, allowing us to focus on the true impact of hardware improvements on carbon intensity.\nWe employ propensity score weighting to create a balanced compar- ison of machines at similar duty-cycle utilization levels. Specifically, we apply this method to two cohorts separately: Powerful TPUs (v4 and v5p) and Cost-efficient TPUs (v4i, v5e, and v6e (Trillium)) for comparisons within each cohort. Table 4 shows how propensity score weighting balances duty cycle distributions across each class of TPUs. The propensity score weighting process involves:\n(1) Calculating propensity scores. For each machine at a given time, determine the probability of the machine belonging to a specific TPU generation based on its duty cycle. Instead of looking at raw duty cycle rates, we'll group observations into levels. Within each duty cycle level, we calculate what percentage of observations belong to each TPU generation, and that is the propensity score for this observation.\n(2) Inverse probability weighting. For each observation, calcu- late the weight as the inverse of its propensity score for the accelerator it was actually assigned to. This gives higher weight to observations that were less likely to be assigned to their particular accelerator given their duty cycle rate.\n(3) Applying weights. Utilize the calculated propensity scores to weight the data points, effectively balancing the duty cycle distribution across generations. This assignment ensures that the comparison is not skewed by differences in duty cycle patterns. The formula is given as:\nWeighted average for $M = \\frac{\\Sigma_i weight_i \\times M_i}{\\Sigma_i weight_i}$,\nwhere $M_i$ is a metric of interest (e.g., average machine power and utilized FLOPs/second) for observation i, and $weight_i$ is the weight for observation i."}]}