{"title": "Memory-Driven Metaheuristics: Improving Optimization Performance", "authors": ["Salar Farahmand-Tabar"], "abstract": "Metaheuristics are stochastic optimization algorithms that mimic natural processes to find optimal solutions to complex problems. The success of metaheuristics largely depends on the ability to effectively explore and exploit the search space. Memory mechanisms have been introduced in several popular metaheuristic algorithms to enhance their performance. This chapter explores the significance of memory in metaheuristic algorithms and provides insights from well-known algorithms. The chapter begins by introducing the concept of memory, and its role in metaheuristic algorithms. The key factors influencing the effectiveness of memory mechanisms are discussed, such as the size of the memory, the information stored in memory, and the rate of information decay. A comprehensive analysis of how memory mechanisms are incorporated into popular metaheuristic algorithms is presented, and concludes by highlighting the importance of memory in metaheuristic performance and providing future research directions for improving memory mechanisms. The key takeaways are that memory mechanisms can significantly enhance the performance of metaheuristics by enabling them to explore and exploit the search space effectively and efficiently, and that the choice of memory mechanism should be tailored to the problem domain and the characteristics of the search space.", "sections": [{"title": "1. Introduction", "content": "Optimization is a fundamental tool used in various fields to find the best solution to a problem given a set of constraints. An optimization problem involves minimizing or maximizing an objective function subject to constraints. For example, in a manufacturing process, optimization can be used to minimize the production cost or maximize the production output while satisfying the production constraints. Optimization problems can be complex and difficult to solve, especially when the search space is large or there are many constraints. In such cases, traditional optimization methods such as mathematical programming may not be able to find the optimal solution within a reasonable time. Metaheuristics are a class of algorithms that are designed to overcome these challenges.\nMetaheuristics are general problem-solving techniques that can be applied to a wide range of optimization problems. Unlike mathematical programming, which requires a specific model and constraints, metaheuristics do not rely on a specific problem structure. Instead, they use iterative search procedures to explore the solution space and find the best solution. The search process of metaheuristics involves generating a set of candidate solutions, evaluating the solutions based on the objective function, and then modifying the solutions to generate a new set of candidates. This process is repeated until the algorithm converges to the best solution or a stopping criterion is met.\nThere are several types of metaheuristics, each with its own unique approach and characteristics. For example, evolutionary metaheuristics are based on the principles of natural selection such as Genetic Algorithm [1]. Swarm Intelligence are inspired by the social behavior of swarming insects and animals such as Particle swarm optimization [2]. Physic-based metaheuristics are another type of metaheuristics, which are based on physical principles such as energy, forces, and vibrations such as Thermal Exchange [3]. Human-inspired metaheuristics are inspired by human behavior and problem-solving approaches such as Neural Network [4].\nMetaheuristics are powerful optimization algorithms that are used to solve complex problems, but they can sometimes get stuck in local optima or fail to converge to the global optima. To overcome these limitations, several techniques have been developed to enhance the performance of metaheuristics. One of the most commonly used techniques is parameter tuning, which involves optimizing the values of the metaheuristic's parameters to improve its performance. Another technique is hybridization, which involves combining two or more metaheuristics to create a more powerful algorithm. This technique can combine the strengths of different metaheuristics to overcome their weaknesses and improve their overall performance.\nThere are numerous improving features to enhance the performance of the optimization algorithms such as levy flight or chaotic maps [4]. Another feature used in enhanced metaheuristics is memory-based improvement. Memory-based improvement involves storing and reusing the information of previous solutions to improve the performance of the metaheuristic algorithm. This approach is commonly used in metaheuristics that rely on a population-based search, such as genetic algorithms and particle swarm optimization. By storing and reusing the information of previous solutions, memory-based improvement can help the algorithm avoid local optima and improve convergence speed. One example of memory-based improvement is the use of adaptive memory, which involves storing the best solutions found so far and adjusting the search process based on the historical information.\nAs evident from the literature review, many basic optimization algorithms have several limitations that hinder their ability to solve complex problems efficiently. Some of the common issues include slow convergence speed and the tendency to get trapped in local optima. To overcome these issues, researchers have proposed various mechanisms to enhance the performance of these algorithms. In this chapter, we propose the use of memory-assisted optimization algorithms as an improvement feature. The memory-assisted version of well-known optimization algorithms such as Multi-Verse Optimizer (MVO), Vibrating Particle Search (VPS), Thermal Exchange Optimization (TEO), and Ray optimization (RO) is implemented as an optimization method, with a separate memory component for storing and exchanging the best solutions found so far. The efficiency of utilizing memory in these algorithms is investigated through various benchmark engineering examples, and its effectiveness is compared with that of memory-less versions of the algorithms."}, {"title": "2. Background Studies on Memory-Enhanced Metaheuristics", "content": "Memory-enhanced metaheuristics have gained increasing attention in recent years due to their ability to improve the performance of optimization algorithms. These methods are designed to incorporate memory mechanisms into conventional metaheuristics, such as Differential Evolution (DE), Genetic Algorithms (GA), Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), Grey Wolf Optimizer (GWO), Ant Colony Optimization (ACO), and Whale Optimization Algorithm (WOA), etc. The use of memory mechanisms can enhance the search process by storing and utilizing information about previously visited solutions, enabling the algorithm to explore the search space more effectively and converge to better solutions faster. In this section, a comprehensive overview of the background studies on memory-enhanced metaheuristics is provided, covering"}, {"title": "3. Memory assignment (multi-elite strategy)", "content": "To enhance the performance of an algorithm without introducing additional computational costs, an approach called the multi-elite strategy can be employed, which involves utilizing a separate memory to store historical best solutions and their corresponding fitness values. This strategy differs from the elitist strategy typically utilized by standard algorithms like"}, {"title": "4. Memory-Enhanced Metaheuristics", "content": "In this section, the metaheuristics utilized in the study are introduced to demonstrate the effectiveness of memory-enhanced optimization. The chosen algorithms are well-known and widely used in the optimization literature, including the Biogeography-Based Optimization (BBO), Krill Herd Algorithm (KHA), and Thermal Exchange Optimization (TEO). These algorithms are categorized under swarm intelligence and physics-based metaheuristics and have been successfully applied in various optimization problems, including engineering, computer science, and other fields. In this study, it is aimed to enhance these algorithms by incorporating a memory mechanism that stores historical best solutions to improve their overall performance in terms of convergence speed, quality of solution, and reliability. These algorithms are applied to optimize the problems to be evaluated their performance with and without memory enhancement."}, {"title": "4.1. Biogeography-Based Optimization", "content": "BBO primarily employs species migration and mutation models in the field of biogeography to address optimization issues. In BBO [61], individual solutions are referred to as \"habitats\", and their quality is evaluated using a Habitat Suitability Index (HSI). The Suitability Index Variables (SIVs) represent the factors that define the habitability of a habitat. BBO primarily relies on migration and mutation processes to explore and discover the most optimal solution."}, {"title": "4.1.1. Migration Operator", "content": "In the BBO (Biogeography-Based Optimization) algorithm, a high HSI (Habitat Suitability Index) indicates a good solution, analogous to a habitat with abundant species. Such habitats exhibit high emigration rates (species leaving the habitat) and low immigration rates (species entering the habitat), and vice versa. The migration operator in the algorithm aims to facilitate the exchange of information among different solutions. In this context, good solutions tend to share their favorable characteristics with poor solutions, while poor solutions are more receptive to adopting beneficial features from good solutions. Each habitat within the algorithm has its specific emigration rate (u), and immigration rate (\u03bb) which are computed as follows:\n$\\lambda_i = I (1 - \\frac{N_i}{N})$,\n$\\mu_i = E \\frac{N_i}{N}$\nIn these equations, $I$ represents the maximum immigration rate, $E$ denotes the maximum emigration rate, $N_k$ corresponds the number of species of the habitat $H_k$, and $N$ represents the maximum number of species. It's worth noting that while the given equations present a simple linear model for migration, in practice, more complex and nonlinear models are often utilized in the BBO algorithm. The migration operator in the BBO algorithm modifies the SIVs of a habitat by incorporating features from other advantageous habitats. This process can be expressed as follows:\n$H_i(SIV) \\leftarrow H_k (SIV)$\nIn the given expression, $H_i$ represents the immigration habitat, while $H_k$ denotes the emigration habitat. The emigration habitat $H_k$ is chosen using the roulette wheel selection method."}, {"title": "4.1.2. Mutation Operator", "content": "In BBO, sudden events can lead to significant changes in the characteristics of a habitat, resulting in alterations to its HSI and the number of species present. The probability of species number in BBO is directly related to the mutation rate of a habitat. More specifically, the mutation rate ($m_i$) is determined by the probability ($p_i$) of the species number, and it can be mathematically expressed as follows:\n$m_i = m_{max}(1 - \\frac{p_i}{p_{max}})$\nIn the provided equation, $m_{max}$ represents the maximum mutation rate, which is a parameter defined by the user. The calculation of $p_i$ follows a specific computation method, and $p_{max}$ corresponds to the maximum value among all $p_i$ probabilities. The mutation process can be performed as follows:\n$H_i(SIV_j) \\leftarrow Ib_j + rand * (ub_j \u2013 Ib_j)$\nHere, $H_i$ represents the mutation habitat. For each SIV in $H_i$, denoted by j ranging from 1 to D (where D is the number of decision variables), the mutation operation is conducted. The lower and upper boundary values of the jth SIV in $H_i$ are represented by $Ib_j$ and $ub_j$, respectively. The mutation process involves modifying the SIV by adding a uniformly distributed random real number, rand, between 0 and 1.\nIn order to maintain the most optimal solutions throughout the search process, BBO utilizes the strategy of elitism. This approach involves several steps: during each iteration, after executing operations such as migration and mutation, the population is sorted. Following this, a number of the least favorable habitats are replaced with some of the top-performing solutions that were preserved from previous iterations. Once this replacement is completed, the population is sorted once more. To summarize, the BBO algorithm follows the following steps:\nStep 1: set the parameters and initialize the random population\nStep 2: compute each habitat and sort the population considering their HSIs in descending order\nStep 3: evaluate the immigration, emigration, and mutation rates and keep the elitists\nStep 4: perform the migration and mutation operator by Eq. (2 and 4)\nStep 5: restrict the boundary of each new solution\nStep 6: compute HSI of each habitat's and sort the population in descending order"}, {"title": "4.2. Krill Herd Algorithm", "content": "Krill swarms, a marine species studied by humans, exhibit a tendency to form clusters. When these krill swarms encounter natural predators or disturbances, some individuals may be lost or displaced, leading to a reduction in population density. To restore the original state, krill swarms exhibit two main behaviors: increasing population density and searching for food. Inspired by these behaviors, researchers have proposed a novel heuristic algorithm called the Krill Herd Algorithm (KHA). The KHA algorithm aims to solve global optimization problems by simulating the clustering and foraging behaviors observed in krill swarms.\nIn the Krill Herd Algorithm (KHA) [62], every individual krill represents a potential solution for the optimization problem at hand. The two goals of increasing population density and finding food are considered as the driving forces for the optimization problem. The process of re-aggregating individual krill represents the algorithm's search for the optimal solution. The location of each krill evolves over time, primarily influenced by the following three factors:\n\u2022 Movement induced by other krill individuals\n\u2022 Foraging motion\n\u2022 Random diffusion\nIn KHA, the Lagrangian model is applied to tackle decision problems that involve multiple dimensions:\n$\\frac{dX_i}{dt} = N_i + F_i + D_i$\nwhere $N_i$ represents the induced motion of other krill individuals; $F_i$ denotes the Foraging activity and $D_i$ corresponds the physical diffusion."}, {"title": "4.2.1. Movement Induced by Other Krill Individuals", "content": "To facilitate the collective migration of the population, every krill individual in the KHA algorithm interacts with one another, fostering a high population density. The direction of movement (denoted as $a_i$) for each krill is influenced by three factors: the influence of neighboring individuals (local effect), the impact of the optimal individual (target effect), and the repulsion effect from the population as a whole (repulsive effect). The movement induced by other krill individuals ($N_i$) for a given krill can be expressed as follows:\n$N_i = N_{max} a_i + w_n N_{old}$\n$a_i = a^{local} + a^{target}$\nIn the equation, $N_{max}$ represents the maximum induced speed, and $N_{old}$ denotes the previously induced motion for the krill individual. The inertia weight of the motion, $w_n$, takes a value between 0 and 1 and represents the influence of the krill's previous motion on the current movement. $a^{local}$ and $a^{target}$ represent the local effect and target effect, respectively. The local effect, induced by neighboring krill individuals, can be interpreted as an attractive or repulsive tendency. It is determined by the following expression:\n$a^{local} = \\sum_{j=1}^{NN} R_{i,j} \\chi_{i,j}$\n$\\chi_{i,j} = \\frac{X_j - X_i}{||X_j \u2013 X_i|| + \\varepsilon'}$\n$R_{i,j} = \\frac{K_i - K_j}{K_{worst} - K_{best}}$\nwhere $NN$ is the number of neighbors, $X$ represents the related position, and $K$ represents the fitness value of the krill individual. $K_{worst}$ and $K_{best}$ represent the worst and best fitness values observed among the krill herds thus far. Additionally, $\u03b5$ is a small positive value introduced to avoid singularities and ensure stability in the calculations. The calculation of the local effect in the KHA algorithm involves determining the neighbors of a krill individual based on their sensing distance. The sensing distance determines which other krill individuals are considered as neighbors. It is defined using the following formula:"}, {"title": "4.2.2. Foraging Motion", "content": "The population's search for food in the foraging process involves estimating the desired resource based on the fitness distribution of the krill individuals. The location of the resource is determined using the concept of the \"center of mass\" from physics:\n$\\chi^{food} = \\frac{\\sum_{i=1}^{NP} K_i X_i}{\\sum_{i=1}^{NP} K_i}$\nTwo primary factors influence the foraging behavior of krill: the current location of the food source and its previous location. This relationship can be expressed as follows:\n$F_i = V_f \\beta_i + w_f F_i^{old}$ , $\\beta_i = \\beta_i^{food} + \\beta_i^{i,best}$\nWhere the variables are the foraging speed ($V_f$), the inertia weight ($w_f \\in [0 1]$), previous foraging motion ($F^{old}$), the food attraction and the effect of the best fitness of the ith krill so far ($\\beta^{food}$, $\\beta^{i,best}$) which are defined as:\n$\\beta_i^{food} = C^{food} R_{i,food} \\chi_{i,food}$, $\\beta^{i,food} = C^{food} R_{i,i best} \\chi_{i,i best}$"}, {"title": "4.2.3. Random Diffusion", "content": "The dispersion of krill individuals in their physical environment can be explained by the maximum speed of diffusion, combined with a randomly determined directional vector.\n$D_i = D^{max} (1-\\frac{g}{g_{max}}) \\delta$\nwhere $D^{max}$ denotes the maximum diffusion speed and $\u03b4$ represents uniformly distributed random vector between -1 and 1."}, {"title": "4.2.4. Updating Position", "content": "The three factors mentioned earlier prompt each krill individual to modify its position in alignment with the optimal direction. The adjustment of an individual's position during the time interval t + \u0394t can be represented by the following expression:\n$X_i(t + \\Delta t) = X_i(t) \\Delta t \\frac{dX_i}{dt}$\nThe \u0394t is crucial and its value entirely relies on the characteristics of the search space. It can be represented as:\n$\\Delta t = C_t \\frac{1}{NV} (UB_i \u2013 LB_i)$\nThe equation is determined by the constant $C_t$, which is a number between 0 and 2. NV denotes the overall count of control variables, whereas UB\u012f and LB\u012f represent the upper and lower boundaries of the jth variable, respectively."}, {"title": "4.2.5. Genetic Operators", "content": "To enhance the performance of the KH algorithm, the crossover and mutation strategies of the Genetic Algorithm are integrated. The crossover operation is formulated as follows:\n$X_{i,j} = \\begin{cases} X_{r1,j} & \\text{if rand < $C_R$ } \\\\ X_{i,j} & \\text{else} \\end{cases}$, j = 1, ..., D I = 1, ..., NP\n$C_R = 0.05/R_{i,best}$\nwhere D represents the dimension of the optimal problem, $X_{r1}$ (r1 \u2260 i) is randomly selected from the current population, $C_R$ denotes the probability of crossover. For the global best solution, $C_R$ is set to zero. The mutation is applied as follows:\n$X_{i,j} = \\begin{cases} X_{best,j} + \\mu (X_{r2,j} - X_{r3,j}) & \\text{if rand < $M_u$ } \\\\ X_{i,j} & \\text{else} \\end{cases}$\nj = 1, ..., D i = 1, ..., NP\n$M_u = 0.05/R_{i,best}$\nIn this context, $X_{best}$ refers to the overall best position within the entire swarm, while \u03bc represents the mutant factor that spans a range of values from 0 to 1. Additionally, factor, $X_{r2}$, and $X_{r3}$ (where r2 \u2260 r3 \u2260 i) are selected randomly from the present population. The mutant probability, denoted as $M_u$, is set to zero for the global best solution as well."}, {"title": "4.2.6. The Procedure of KHA", "content": "The KHA (Krill Herd Algorithm) can generally be defined by the following steps:\nStep 1. Initialization: Set the randomly generated initial population of krill individuals, define the search space boundaries ($X_{min}$ and $X_{max}$), and initialize the algorithm's parameters. Random values are assigned to each D-dimensional individual according to:\n$X_{j,i\\vert g=0} = X_{j,min} + rand \u00d7 (X_{j,max} \u2013 X_{j,min})$, j = 1,.., D; i = 1,.., NP\nwhere NP represents the population size."}, {"title": "4.3. Thermal Exchange Optimizer", "content": "In the Thermodynamics-Inspired Optimization (TEO) algorithm [63], a subset of agents is designated as cooling objects, while the remaining agents represent the environment. Interestingly, in TEO, this assignment is done contrariwise compared to traditional approaches. The algorithm follows the steps outlined below:\nStep 1. Initialization: In an m-dimensional search space, the initial temperature of all the objects is established.\n$T_i^{i0} = T_{min} + rand(T_{max} \u2013 T_{min})$\n$T_i^{i0}$ represents the initial solution vector of the ith object. $T_{min}$ and $T_{max}$ are the lower and upper bounds of the design variables, respectively, and n denotes the total number of objects.\nStep 2. Evaluation: The objective function computes the cost value for each object.\nStep 3. Saving: In order to enhance the algorithm's performance without significantly increasing computational cost, a memory component is introduced to store historically best T vectors along with their corresponding objective function values. This memory, referred to as the Thermal Memory (TM), is utilized in this step. The saved solution vectors in TM are added to the population, while an equal number of the current worst objects are removed. Subsequently, the objects are sorted based on their objective function values in ascending order. This process helps incorporate valuable historical information into the population and maintain a diverse set of solutions.\nStep 4. Creating groups: The agents in the population are divided into two equal groups. The pairs of agents are defined [63]. For example, $T_1$ serves as an environment object for $T_{2n+1}$, which acts as a cooling object, and vice versa. This pairing scheme ensures the interaction and exchange of heat between the environment and cooling objects in a structured manner.\nStep 5. Defining \u03b2: In nature, when an object has a lower \u03b2 value, it tends to undergo only minor temperature exchanges. Drawing inspiration from this characteristic, a similar formulation is proposed in the algorithm. The value of \u03b2 for each object is evaluated using Eq. (25). In this equation, objects with lower cost values have lower \u03b2 values, indicating that they undergo smaller changes in position. This approach allows objects with better fitness (lower cost) to make gradual adjustments while exploring the search space.\n$\\beta = \\frac{Cost(object)}{Cost(worst object)}$\nStep 6. Defining t: The value of time, denoted as t, is associated with the iteration number in the formulation. The calculation of t for each agent is determined using Eq. (226), which is given as:\n$t = \\frac{iter.}{Max\\_iter}$\nStep 7. Escaping from local optima (i): Metaheuristic algorithms should possess the capability to escape from traps encountered when agents approach local optima. Step 7 and Step 9 are employed specifically for this purpose. In these steps, the environmental temperature is adjusted using Eq. (27):\n$T_{env.} = (1 \u2013 (c_1 + c_2 \u00d7 (1 \u2013 t)) \u00d7 rand) \u00d7 T'_{env.}$\nThe previous temperature of the object, denoted as $T_{env.}$, is adjusted to a new temperature, $T_{env.}$. The parameter (1 - t) is employed to reduce randomness as the iterations advance. As t increases towards the end of the process, randomness decreases linearly, promoting exploitation. $C_2$ controls the factor (1 \u2013 t). For example, when decreasing is not required,"}, {"title": "5. Results and Discussion on Case Studies: Truss Bridges", "content": "Truss bridges are a specific type of trusses that are suitable for shape and size optimization. These trusses are utilized in various bridge components, including the deck [64] and arch [65-68]. Topology or shape optimization plays a significant role in enhancing the structural form of truss bridges. By optimizing the shape, material usage can be significantly reduced while improving overall performance. Therefore, truss bridges are classified as the third category among the truss benchmark examples, which include the Michell arch, forth bridge model, and the 37-bar truss bridge. The design data pertaining to the optimization problems for these examples can be found in Table 2.\nThe Michell arch, as shown in Figure 1, is recognized as the initial instance of its kind. This optimization problem has an available analytical solution that takes into account equal allowable stresses in both tension and compression (Wang et al., 2002):"}, {"title": "4. Conclusions", "content": "In this chapter, the effectiveness of utilizing memory-based techniques in enhancing the performance of various metaheuristic algorithms has been investigated. By adding a memory component to the basic optimization algorithm, several best solutions from previous iterations are saved to be exchanged with several worst solutions in the next iterations. This strategy is called a multi-elite strategy and has been applied to a number of well-known optimization algorithms such as the Biogeography-Based Optimization (BBO), Krill Herd Algorithm (KHA), and Thermal Exchange Optimization (TEO). The proposed memory implementation allowed the algorithm to avoid the worst solutions by exchanging them (20% of the population size) with the global best ones from the memory. In this chapter, the proposed memory-assisted versions of these algorithms have been implemented to optimize benchmark engineering examples, such as size and shape optimization of truss bridges. The results show that the memory-assisted optimization algorithms outperform the memory-less ones in terms of convergence speed, solution quality, and reliability. The case study examples of truss bridges demonstrated that the proposed method can effectively optimize problems with both continuous and discrete variables. Therefore, utilizing memory-based techniques can be a promising approach to improve the performance of various optimization algorithms and to solve complex engineering problems."}]}