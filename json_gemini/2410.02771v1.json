{"title": "COMPLEX-VALUED CONVOLUTIONAL NEURAL NETWORK CLASSIFICATION OF HAND GESTURES FROM RADAR IMAGES", "authors": ["Shokooh Khandan"], "abstract": "Hand gesture recognition systems have yielded many exciting advancements in the last decade and become more popular in HCI (human-computer interaction) with several application areas, which spans from safety and security applications to automotive field [1].\nVarious deep neural network architectures have already been inspected for hand gesture recognition systems, including multi layer perceptron (MLP) [2], convolutional neural network (CNN) [3], recurrent neural network (RNN) [4] and a cascade of the last two architectures known as CNN-RNN [5].\nHowever a major problem still exists, which is most of the existing ML algorithms are designed and developed the building blocks and techniques for real-valued (RV). Researchers applied various RV techniques on the complex-valued (CV) radar images, such as converting a CV optimisation problem into a RV one, by splitting the complex numbers into their real and imaginary parts. However, the major disadvantage of this method is that, the resulting algorithm will double the network dimensions.\nRecent work on RNNs and other fundamental theoretical analysis suggest that, CV numbers have a richer representational capacity, but due to the absence of the building blocks required to design such models, the performance of CV networks are marginalised.\nIn this report, first we review the background of ML and artificial neural networks (ANNs) in chapter two, then in the third chapter, we explain the characteristics of our utilised two sets of CV datasets. In the forth chapter,we propose a fully CV-CNN, including all building blocks, forward and backward operations, and derivatives all in complex domain. Then we implement the designed model in Python from scratch and fully in complex domain. We explore the proposed classification model on two sets of CV hand gesture radar images in comparison with the equivalent RV model.", "sections": [{"title": "Introduction", "content": "Hand gesture recognition is a branch of human-computer interaction (HCI), hand gesture recognition systems have yielded many exciting advancements in the last decade and be come more popular in HCI in several application areas which spans from safety and security applications to automotive field [1], mobile phones, home automation and biomedical engineering [6]. Interaction with the infotainment system inside the car cockpit is realised more intuitively nowadays than in the past when a driver had to press various buttons or touch the surface of a screen to perform some fundamental tasks such as turning up and down the radio or activating the air-conditioning system. Virtual reality (VR) [7][1] and augmented reality (AR) [8] are emerging scientific areas that have utilised the hand gesture. Camera-based and radar-based techniques are two main categories of contactless hand gesture recognition methods [1]. While the performance of the former is affected by the ambient light, the latter is insensitive to varying illumination conditions. In addition, some people do not find it convenient when they are kept under constant surveillance by a camera [9], [10]. Furthermore, contactless hand gesture recognition, prevents from the risk of infection or contamination, which is an important issue especially in the clinical field[6].\nThe recent substantial progress in the semiconductor industry, introduced the millimeter-wave radars can beamed into small-sized and portable gadgets, making them more efficient than cameras in terms of power consumption[1]. Various deep neural network architectures have already been inspected for hand gesture recognition systems, including multi layer perceptron (MLP) [2], convolutional neural network (CNN) [3], recurrent neural network (RNN) [4] and a cascade of the last two architectures as CNN-RNN [5]. Previous scientific works have excessively used long-short-term memory (LSTM) networks as RNN. The gated recurrent unit (GRU) proposed in 2014 has demonstrated promising results comparable to its LSTM counterpart in video-based gesture identification [11]s[1].\nIn many scientific and engineering problems, the unknown variables are complex vectors and the main task is to find these variables that minimise complex-variable optimisation problems. Applications of the complex-variable optimisa-tion problem can be found in communications, adaptive filtering, medical imag-ing, remote sensing[12], Magnetic Reasoning Images (MRI), Synthetic Aperture Radar Data (SAR) and Very-Long-Baseline Interferometry (VLBI), Antenna Design (AD), Radar Imaging (RI), Acoustic Signal Processing (ASP) and Ultrasonic Imaging (UI), Communications Signal Processing (CSP), Traffic and Power Sys-tems (TPS)[13]. Traditional optimisation methods are used to solve real-valued optimisation problems and cannot be directly applied to CV optimisation prob-lems. To solve the optimisation problems over the complex field, it is required to convert a CV optimisation problem into a real-valued one by splitting the CV numbers into their real and imaginary parts. However, the major disadvantage of this method is that the resulting algorithm will double the dimension compared with the original problem and may break the special data structure. Moreover, they will suffer from high computational complexity and slow convergence when the problem size is large[12].\nIn this report we demonstrate and compare three CV network and explore their accuracy and the effect of some hyper parameters setting on the classi-fication accuracy, computation time and number of trainable parameters. A fully CV-CNN including all building blocks forward and backward operations and derivatives all in complex domain, then we implement the designed model in Python from scratch and without the use of any libraries fully in complex domain. We test the designed and implemented network on 2 sets of CV hand gesture radar images and the results of our binary gesture classification model is 100%. The second CV network is the complex-forward residual network which separates the imaginary and real parts of dataset, the convolutional block result as a CV con-volution (with separated imaginary and real part convolution output ), however the back propagation is RV and the network implemented by using Python RV libraries. The third network that we implement and explore is complex-forward CNN which is also implemented by using the Python RV libraries."}, {"title": "Aims", "content": "This report aims to design and implement bellow three binary classification mod-els:\n\u2022 a fully CV-CNN model for an accurate binary classification method of hand gestures, based on CV 2D radar images. We aim to have every block in the network and all mathematical operations to utilise both real and imag-inary parts of the data. The network blocks include convolutional layer, pooling layer, activation function, fully connected layer. The mathematical operations during the training, optimisation and BP the real and imaginary part are all applied on CV numbers and real and imaginary parts are not splitted during the mathematical operations at any stage.\n\u2022 a CV-forward CNN model for binary classification of two CV hand gesture datasets. This model, utilises the simulated CV operations, including con-volutional, pooling and activation function. However the BP derivatives are all in the RV domain and the real and imaginary parts of data are always splitted.\n\u2022 a CV-forward residual network, which include one residual block with two convolutional layers. Similar to CV-forward CNN model, the model, utilises the simulated CV operations, including convolutional, pooling and activa-tion function. However the BP derivatives are all in the RV domain and the real and imaginary parts of data are always splitted."}, {"title": "Objectives", "content": "\u2022 Prepare two CV 2D radar images datasets each consist of two hand gestures in order to prepare the binary classification CV-CNN's training and test dataset.\n\u2022 Design a mathematical 2-layer CV-CNN, CV-forward CNN and a CV-forward residual network, with details of every CV layer and their CV derivatives.\n\u2022 Implement the designed models in Python.\n\u2022 Explore and tune the hyper-parameters such as learning rate, convolution feature map size and number of filters.\n\u2022 Analyse the results of the implemented models in order to develop an ac-curate CV model to classify the hand gesture images."}, {"title": "Background", "content": "In this chapter we explain the background of machine learning (ML) and five main types of ML. Then we review the artificial neural networks biological origin and discuses their model training methods. In the direction of discussing different model training methods, first we introduce various loss functions and optimisation algorithms and explain their differences. Afterwards, we explain the detailed mathematical operations in back propagation and various activation functions in order to create an insight to the optimisation and evaluation process of a selected training model. Next, we overview the validation techniques and regularisation methods. Finally, we concentrate on the radar-based hand gesture classification literature review and challenges with focus on convolutional neural network methods."}, {"title": "Machine learning", "content": "The idea of ML has been around over the last six decades. In 1950, Alan Turing brought the idea of \"Can machine think?\". In 1959, Arthur Samuel defined ML as a \"field of study that gives computers the ability to learn without being explicitly programmed\". Samuel is credited with creating one of the first self-learning computer programs with his work at IBM [14]. Tom M. Mitchell is the chair of ML at Carnegie Mellon University and the author of the book \"Machine Learning\". He defines ML as \"a computer program which is said to learn from experience with respect to some class of tasks and performance measure, if its performance at tasks in, as measured by performance measure, improves with the experience\"."}, {"title": "Supervised learning", "content": "Supervised learning refers to working with a set of labeled training data. For every sample in the training data we have an input and an output object. The main goal in supervised learning is to learn a model from labeled training data that allows us to make predictions about unseen or future data. In unstructured environments, such as an agricultural field, conditions are variable, so robustness of unsupervised algorithms may be at risk [15]. Therefore supervised classification techniques are of special interest in this field, since a training set can be prepared by a priori establishing what features will correspond to the elements of a class, which, in turn, reduces uncertainty and leads to the possible solutions.\nExamples of supervised learning algorithms include linear regression, logistic regression, decision trees, support vector machines (SVM), and neural networks. A supervised learning task with discrete class labels is also called a classification task. Another subcategory of supervised learning is regression, where the output is a continues value [16]."}, {"title": "Classification", "content": "Classification is subcategory of supervised learning where the goal is to predict the categorical class labels of new instances based on past observations. Those class labels are discrete, un-ordered values that can be understood as the group memberships of the samples. The classification can be binary (two classes), multi-class classification or multi-label [16]. In summary, the main differences between the classification types are in the number of classes or labels assigned to each"}, {"title": "Regression", "content": "The term regression was devised by Francis Galton in his article \"Regression towards mediocrity in hereditary stature in 1886\". Another type of supervised learning is the prediction of continuous outcomes, which is also called \"regression analysis\". In regression learning, we are given a number of the predictor (explanatory) variables and a continuous variable (outcome) and we try to find a relationship between those variables that allows us to predict an outcome [16]. In statistics, the regression analysis is a basic type of predictive analysis which is used to quantify the relationship between a dependent variable known as the \"system output\" and one or more independent variables [17]."}, {"title": "Unsupervised learning", "content": "Unsupervised learning is where we let the algorithm find a hidden pattern in a set of data. With unsupervised learning there is no right or wrong answer, it's just a case of running the ML algorithm and seeing what patterns and outcomes occur [14]. When using unsupervised learning techniques, we are able to explore the structure of our data to extract meaningful information without the guidance of a known outcome variable or reward function [16]."}, {"title": "Semi-supervised learning", "content": "Semi-supervised learning lies between supervised and unsupervised learning. It combines a small amount of labeled data with a larger set of unlabeled data. The goal is to leverage the unlabeled data to improve the learning process and enhance the model's performance. Techniques such as self-training, co-training, and graph-based methods are commonly used in semi-supervised learning."}, {"title": "Transfer learning", "content": "Transfer learning involves using knowledge or representations learned from one task or domain to improve performance on a different but related task or domain. Instead of starting from scratch, the model leverages the pre-existing knowledge to bootstrap the learning process in the new task. This can be especially useful when the target task has limited labeled data, as the model can transfer knowledge from a source task with abundant labeled data. Transfer learning is often employed in deep learning models, where pre-trained models (e.g., ImageNet pre-trained models) are fine-tuned on new tasks."}, {"title": "Reinforcement learning", "content": "The aim of reinforcement learning is to develop a system (agent) that improves its performance based on interactions with the environment. Since the information about the current state of the environment typically also includes a reward signal, we can think of a reinforcement learning as a field related to supervised learning. However, in reinforcement learning, this feedback is not the correct ground truth label or value, but a measure of how well the action was measured by the reward function. Through the interaction with the environment, an agent can then use reinforcement learning to learn a series of actions that maximises this reward via an exploratory trial-and-error approach [16]."}, {"title": "Artificial neural network", "content": "The idea of building an artificial brain has existed for a long time. ANN is a possible method to help to better understand artificial intelligence [18]. ANN is a supervised learning algorithm inspired by biological operations consisting of a group of interconnected artificial neurons that work together to solve a specific problem (Figure 2.1). Although ANN has gained more popularity in recent years, the earliest studies of neural networks date back to the 1940s, when Warren McCulloch and Walter Pitt first described how neurons work. However, even after Rosenblatt's perceptron in the 1950's, which was the first implementation of McCulloch and Pitt's model, no one had a good solution for training a neural network with multiple layers. Eventually in 1983, Michalski proposed a machine that can learn from labeled samples [19].\nIn 1986, when Rumelhart, G.E. Hilton and R.J. Williams introduced a back-propagation (BP) algorithm to train ANN online automatically [20], [21], subse-quently, some studies showed that memristors could be used as electronic synapses in ANN [22], [23]. For example, ANN consisting of neurons and memristor-based synapses was used to mimic the associate function of human brain [22], [24]. ANN shows a powerful and robust performance in modelling a complex system. Since then, researchers have made many amazing achievements in the applica-tions of the ANN like pattern recognition [25], [26], [27], face recognition [28], [29], learning cat concept from cat videos on the internet [30], classifying [31], and playing 'Pokemon Go' game [32]. ANN is a hot topic not only in academic research, but also in big technology companies such as Facebook, Microsoft and Google who invest heavily in ANN and deep learning research."}, {"title": "Training an ANN", "content": "The multi-layer neural network is a typical example of a feed-forward ANN. The term feed-forward refers to the fact that each layer serves as the input to the next one without loops. The training procedure starts at the input layer, we forward propagate the patterns of the training data through the network to generate an output. The second step, based on the network's output, we calculate the error that we want to minimise by using a loss (cost) function. The third step is to back-propagate the loss, find its derivative with respect to each weight in the network and update the model[16]."}, {"title": "Loss function", "content": "Machines learn by means of a \"loss function\u201d. It's a method of evaluating how well a specific algorithm models the given data. If prediction deviates too much from actual results, the loss function would cough up a very large number. Gradually, with the help of some optimisation functions, the loss function learns to reduce the error in prediction. There are various factors involved in choosing a loss function for specific problems, such as type of ML algorithm chosen, ease of calculating the derivatives and to some degree the percentage of outliers in the data set. There are many loss functions which are commonly used for different purposes in ML, such as mean square error (MSE), mean absolute error (MAE) and mean bias error (MBE):\n\\text{MSE} = (y - \\hat{y})^2. (2.1)\nEquation (2.1) calculates the MSE, where $y$ is its label of a training sample and $\\hat{y}$ is the predicted output of the training sample. MSE is measured as the average of squared difference between predictions and actual observations It is only concerned with the average magnitude of error irrespective of their direction. However, due to squaring, predictions which are far away from actual values are penalised heavily in comparison to less deviated predictions. Moreover, it is computationally easy to calculate the gradients.\n\\text{MAE} = | y - \\hat{y} |. (2.2)\nMAE as in equation (2.2), is measured as the absolute differences between pre-dictions and actual observations. Like MSE, it measures the magnitude of error without considering their direction. Unlike MSE, MAE needs more complicated tools such as linear programming to compute the gradients. In addition, MAE is more robust to outliers since it does not make use of the square.\n\\text{MBE} = y - \\hat{y}. (2.3)\nMBE as in equation (2.3), is less popular in the ML domain. There is a need for caution as positive and negative errors could cancel each other out. Although less accurate in practice, it could determine if the model has positive or negative bias."}, {"title": "Gradient based optimisation algorithm", "content": "Gradient descent is an iterative algorithm for finding the local or global minimum of the \"loss function\u201d. It measures the closeness of a desired output for an input to the output of the network (predicted output). As the model iterates, it gradually converges towards a minimum where further tweaks to the parameters produce little or zero changes in the loss, which is also referred to as convergence. Let us start with a training set which is a set of samples, each sample consisting of a pair of an input and a desired output. The pairs are the samples of the function to be learned. There are several algorithms in ML, most of the successful algorithms can be categorised as gradient-based learning methods. The learning machine, as represented in Figure 2.2, computes a function $f(x^{(m)}, w)$ where $x^{(m)}$ is the vector of m-th input, and w represents the vector collection of adjustable parameters in the system.\n$L^{(m)} = L(f(x^{(m)}, w), y^{(m)}) (2.4)$\nA loss function $L^{(m)}$ (2.4) measures the discrepancy between $y^{(m)}$ the \"correct\" or desired output for the mth input $x^{(m)}$, and the predicted output by the system $\\hat{y}^{(m)} = (f(x^{(m)}, w))$. The average loss function L is the average loss function over a set of input and output pairs called the training set $(x^{(1)}, y^{(1)}), ....(x^{(m)}, y^{(m)})$. In the simplest setting, the learning algorithm consists in finding the value of w that minimises loss [34]. In practice, the performance of the system on a training set is of little interest. The more relevant measure is the loss rate of the system in the field, where it would be used in practice. This performance is estimated by measuring the accuracy on a set of samples disjoint from the training set, called the test set. The MSE loss function, which is used commonly in regression problems, measures the average squared difference between an desired actual and predicted values, as in (2.1).\n$\\mathcal{L} = \\frac{1}{M} \\sum_{m=1}^{M} (f(x^{(m)}, w) - y^{(m)})^2 (2.5)$\nThe output of equation (2.5) is a single scalar representing the average loss, associated with the current set of weights. Our goal is to minimize MSE to improve the accuracy of our model. The momentum method [35], which we refer to as classical momentum (CM), is a technique for accelerating gradient descent"}, {"title": "Back propagation", "content": "BP or \"backward propagation of errors\u201d, is a standard method of training ANN. This method helps to calculate the gradient of a loss function with respects to all weights in the network. The BP algorithm was originally introduced in the 1970s, but its importance wasn't fully appreciated until a famous 1986 paper by David Rumelhart, Geoffrey Hinton, and Ronald Williams [25]. BP is an expression for the partial derivative of the loss function L with respect to any weight win the network. BP provides detailed insights into how changing the weights changes the overall behaviour of the network [25].\nAlthough BP was rediscovered and popularised almost 30 years ago, it still remains one of the most widely used algorithms to train an ANN. BP is a very popular neural network learning algorithm because it is conceptually simple, com-putationally efficient and it often works accurately. Designing and training a network using BP requires making many seemingly arbitrary choices such as the number and types of nodes, layers, learning rates, training and test sets. Proper tuning of the weights allows you to reduce error rates and to make the model reliable by increasing its generalisation [34]. Lets assume we have a multi-layer feed-forward neural network which consist of N layers of neurons( Figure 2.5).\n$R_n = W_nZ_{n-1}$\n$Z_n = \\ln (R_n)  (2.8)$\nFor each layer of the multi-layer neural network, where in (2.8) $W_n$ is a weight parameter matrix of the nth layer whose number of columns is the dimension of $Z_{n-1}$, and number of rows is the dimension of $Z_n$. $ln$ is a vector function that applies an activation function to each component of its input. Each layer implement the functions as in (2.8), where $R_n$ is a vector representing the n-th layer's input to activation function and $Z_{n-1}$ is the output vector of the n 1th layer as well as the input vector of n-th layer. $Z_0$ is the input vector and $Z_N$ is the output. $L^{(m)}$ is the loss function for the mth sample. In the BP algorithm, we calculate the $\\frac{\u2202L}{\u2202W_n^{(m)}}$ for each training sample m, then calculate the $\\frac{\u2202L}{\u2202W_n}$ by averaging over the training samples.\n$\\frac{\u2202L}{\u2202R_n} = \\frac{\u2202L}{\u2202Z_n} \\frac{\u2202Z_n}{\u2202R_n}$\n$\\frac{\u2202L}{\u2202W_n} = \\frac{\u2202L}{\u2202Z_n} \\frac{\u2202Z_n}{\u2202W_n} =  \\frac{\u2202L}{\u2202Z_n} \\frac{\u2202\\ln(W_nZ_{n-1})}{\u2202Z_n} \\frac{\u2202Z_n}{\u2202W_n}$\n$\\frac{\u2202L}{\u2202Z_{n-1}} = \\frac{\u2202L}{\u2202Z_n} \\frac{\u2202Z_n}{\u2202Z_{n-1}} = \\frac{\u2202L}{\u2202Z_n} \\frac{\u2202\\ln(W_nZ_{n-1})}{\u2202Z_n} \\frac{\u2202Z_n}{\u2202Z_{n-1}} (2.9)$\nIf the partial derivative of L with respect to $Z_n$ is known then the partial deriva-tives of L with respect to $W_n$ and $Z_{n-1}$ can be computed using the backward recurrence as in (2.9).\n$\\frac{d\\ln_n (W_nZ_{n-1})}{\u2202R_n} =  \\ln'_n(R_n) (2.10)$\nLet $\\ln'(R_n)$ be the derivative of $\\ln$ with respect to $R_n$ as in (2.10) and (2.8). Applying the chain rule to BP equations, the classical BP equations in matrix form are obtained as:\n$\\frac{\u2202L}{\u2202R_n} = \\frac{\u2202L}{\u2202Z_n} \\ln'_n(R_n)$\n$\\frac{\u2202L}{\u2202W_n} = \\frac{\u2202L}{\u2202Z_n}  Z_{n-1}$\n$\\frac{\u2202L}{\u2202Z_{n-1}} = \\frac{\u2202L}{\u2202Z_n} W_n^T  (2.11)$\nWhen the BP equations are applied to the layers in reverse order, from layer N to layer 1, all the partial derivatives of the loss function with respect to all the weights parameters can be computed. The way of computing gradients is known as BP. Let $S_n$ be the sensitivity in layer n."}, {"title": "Activation function", "content": "Activation functions are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated (\u201cfired\") or not, based on whether each neuron's input is relevant for the model's prediction. One aspect of activation functions is that they must be computationally efficient because they are calcu-lated across thousands or even millions of neurons for each data sample. Modern neural networks use BP technique to train the model, which places an increased computational strain on the activation function, and its derivative function.\nIn a neural network, numeric data points, called inputs, are fed into the neurons in the input layer. Each neuron has a weight, and multiplying the input number with the weight gives the output of the neuron, which is transferred to the next layer. The activation function is a mathematical \u201cgate\u201d in between the input feeding the current neuron and its output going to the next layer( Figure 2.6). It can be as simple as a step function that turns the neuron output on and off or it can be a transformation that maps the input signals into output signals that are needed for the neural network to function [38].\nIncreasingly, neural networks use non-linear activation functions, which can help the network learn complex data, compute and learn almost any function representing a question, and provide accurate predictions. Non-linear functions address the problems of a linear activation function. They allow backpropagation because they have a derivative function which is related to the inputs. They allow \"stacking\" of multiple layers of neurons to create a deep neural network. Multiple hidden layers of neurons are needed to learn complex data sets with high levels of accuracy[38]."}, {"title": "Sigmoid", "content": "The Sigmoid activation function $\\text{Sigmoid}(\\theta) = \\frac{1}{1+\\exp^{-\\theta}}$ as shown in Figure 2.7, is one of most widely used non-linear activation. The smooth gradient of sigmoid activation function prevents \u201cjumps\u201d in the output values. Moreover, the output values bound between 0 and 1, normalising the output of each neuron makes this function very suitable for models that require probabilistic interpretations or binary classification tasks. It can also be used as an activation function in the output layer for multi-label classification.\nHowever for very high or very low values of activation function input there is almost no change to the prediction, causing a vanishing gradient problem. This can result in the network refusing to learn further, or being too slow to reach an accurate prediction. In addition, the outputs are not zero centered and sigmoid calculation is computationally expensive."}, {"title": "Tanh (Hyperbolic tangent)", "content": "The Tanh activation function $Tanh(\\theta) = \\frac{1-\\exp^{-2\\theta}}{1+\\exp^{-2\\theta}} - 1$ as shown in Figure 2.8 is a zero-centred function which makes it easier to model inputs that have strongly negative, neutral and strongly positive values. The characteristics of Tanh func-tion is similar to sigmoid function, however, the gradient is stronger for Tanh than sigmoid ( derivatives are steeper). Deciding between the sigmoid or Tanh will depend on the requirement of gradient strength. Like sigmoid, Tanh also has the vanishing gradient problem. Tanh is also a very popular and widely used activation function."}, {"title": "ReLU ( rectified linear unit)", "content": "ReLU function $ReLU(\\theta) = max(0,\\theta)$ as shown ins Figure 2.9. ReLU calculation is computationally efficient (only comparison, addition and multiplication) which allows the network to converge very quickly. ReLU activation function is non-linear, although it looks like a linear function, ReLU has a derivative function so it can be utilised for BP.\nIn addition, for larger Neural Networks, the speed of building models based on ReLU is very fast because of sparse activation, which means in a randomly initialised network, only about half of hidden units are activated (having a non-zero output). Moreover, ReLU has better gradient propagation characteristics, so fewer vanishing gradient problems compared to sigmoidal activation functions will accrue. However, when inputs approach zero or are negative, the gradient of the function becomes zero, the network cannot perform backpropagation and cannot learn. Another disadvantage of ReLU is the \"dying ReLU\u201d problem, where some neurons can become inactive and stop learning if they consistently receive negative inputs."}, {"title": "Validation methods", "content": "If all the data is used for training the model and the error rate is evaluated based on model's outcome compare to actual value from the same training data set, this error is called the resubstitution error. This technique is called the resubstitution validation technique. Cross validation is a model evaluation technique that is more accurate than resubstitution. The problem with resubstitution evaluations is that they do not give an indication of how well the model will do when it is asked to make new predictions for data it has not already seen. One way to overcome this problem is to not use the entire data set when training a model. Some of the data is removed before training begins. Then when training is done,"}, {"title": "The Holdout Method", "content": "The holdout method is the simplest kind of cross validation. The dataset is separated into two sets, called the training set and the testing set. The model is trained using the training set only. Then the model is asked to predict the output values for the data in the testing set (it has never seen these output values before). The errors it makes are accumulated as before to give the mean absolute test set error, which is used to evaluate the model. The advantage of this method is that it is usually preferable to the residual method and takes no longer to compute. However, its evaluation can have a high variance. The evaluation may depend heavily on which data points end up in the training set and which end up in the test set, and thus the evaluation may be significantly different depending on how the division is made."}, {"title": "K-fold Cross Validation", "content": "K-fold cross validation is one way to improve over the holdout method. As Figure 2.10illustrates, the data set is randomly divided into k subsets of approxi-mately equal size, and the holdout method is repeated k times. Each time, one of the k subsets is used as the test set and the other k-1 subsets are put together to form a training set. Then the average error across all k trials is computed. The advantage of this method is that it matters less how the data gets divided, therefore, it provides a more robust estimate of the model's performance com-pared to a single train-test split. Every data point gets to be in a test set exactly once, and gets to be in a training set k-1 times. The variance of the resulting estimate is reduced as k is increased. K-fold cross-validation allows the model to be trained on a larger portion of the dataset, as each sample gets an opportunity to be part of the training and validation sets. K-fold cross-validation can be used to compare the performance of different models or different hyperparameter set-tings. By evaluating each model or configuration on multiple validation sets, it provides a fair comparison and helps in selecting the best-performing model. The disadvantage of this method is that the training algorithm has to be rerun from scratch k times, which means it takes k times as much computation to make an evaluation. A variant of this method is to randomly divide the data into a test and training set k different times. The advantage of doing this is that you can independently choose how large each test set is and how many trials you average over."}, {"title": "Leave-one-out Cross Validation", "content": "Leave-one-out cross validation (LOOCV) is K-fold cross validation taken to its logical extreme, with K equal to the number of the instance in the set M. That means that M separate times, the model is trained on all the data except for one instance and a prediction is made for that instance. The average error is computed and used to evaluate the model. The evaluation given by LOOCV error is good, but it is expensive to compute. Fortunately, locally weighted learners can make LOO predictions just as easily as they make regular predictions. That means computing the LOOCV error takes no more time than computing the residual error and it is a much better way to evaluate models. Leave-one-out cross-validation is a special case of cross-validation where the number of folds equals the number of instances in the data set. Thus, the learning algorithm is applied once for each instance, using all other instances as a training set and using the selected instance as a single-item test set. Thus, LOOCV is far less bias as we have used the entire dataset for training compared to the validation set approach where we use only a subset (60% to 80%) of the data for training. In addition, there is no randomness in the training or test data as performing LOOCV multiple times will yield the same results. However, MSE will vary as test data uses a single observation."}, {"title": "Regularisation", "content": "There are three main ways to improve the performance of a model, to increase the training data, to increase the complexity of the network and to regularise the network [39]. All these three ways are related to each other and can improve the performance in combination to each other. Regularisation is a technique that is used to avoid over-fitting and improve the generalisation performance of a model [40]. There are different types of regularisation methods utilised in literature (dropout, batch normalisation kernel regularisation and early stopping). The dropout method is the most commonly used regularisation technique for deep neural network, it can be implemented easily in CNN and is computationally cheap [39]. Moreover, batch normalisation has been emerged as another effec-tive and strong regularisation method and has been utilised in many computer vision tasks. Kernel regularisation (L1 and L2) have been effectively applied in optimising the deep neural networks in the literature."}, {"title": "Dropout", "content": "Dropout handles the over-fitting issue by randomly dropping units from the neural network with their connections during training, which enables every neuron to work independently. The unit with all incoming and outgoing connections is removed temporarily from the network is called a dropout. The dropout technique is not applied during testing, it is only applied to input or hidden layer nodes and not output nodes [39] [41]."}, {"title": "Batch Normalisation", "content": "In deep neural networks, during training, the input of each layer changes due to parameters update of the previous layer, thus training slows down [39"}]}