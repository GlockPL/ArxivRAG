{"title": "AI-Driven Cyber Threat Intelligence Automation", "authors": ["Shrit Shah", "Fatemeh Khoda Parast"], "abstract": "This study introduces an innovative approach to automating Cyber Threat Intelligence (CTI) processes in industrial environments by leveraging Microsoft's AI-powered security technologies. Historically, CTI has heavily relied on manual methods for collecting, analyzing, and interpreting data from various sources such as threat feeds. This study introduces an innovative approach to automating CTI processes in industrial environments by leveraging Microsoft's AI-powered security technologies. Historically, CTI has heavily relied on manual methods for collecting, analyzing, and interpreting data from various sources such as threat feeds, security logs, and dark web forums-a process prone to inefficiencies, especially when rapid information dissemination is critical. By employing the capabilities of GPT-40 and advanced one-shot fine-tuning techniques for large language models, our research delivers a novel CTI automation solution. The outcome of the proposed architecture is a reduction in manual effort while maintaining precision in generating final CTI reports. This research highlights the transformative potential of AI-driven technologies to enhance both the speed and accuracy of CTI and reduce expert demands, offering a vital advantage in today's dynamic threat landscape.", "sections": [{"title": "1. Introduction", "content": "Cyber Threat Intelligence (CTI) collects, analyzes, and disseminates information about current and potential cyber threats. CTI involves data collection from various sources, such as security logs, threat feeds, and incident reports, to identify Indicators of Compromise (IoC) and understand the Tactics, Techniques, and Procedures (TTPs) used by threat actors [1]. CTI is crucial in cybersecurity as it enables organizations to proactively defend against cyber attacks by providing actionable insights that inform security measures, enhance incident response, and facilitate identifying and mitigating vulnerabilities [2]-[4].\nUnlike measurement data, which is automatically gathered, threat intelligence requires meticulous manual analysis by expert analysts [5], [6]. These professionals use their expertise and intuition to extract IoCs and attack patterns. An IoC could be any observable element linked to an attack, such as a file (identified by its name or hash), a URL, or an IP address. To decode the attack pattern of an attack group, analysts identify several IoCs related to a malicious campaign and ascertain the role of each one-for instance, determining if a URL is an exploitation site or a command-and-control server. This carefully curated threat intelligence is published in technical blogs and industry reports. Moreover, commercial or open-source IoC feeds share some of the identified indicators essential for detecting security threats, conducting forensic investigations after breaches, and attributing attacks to specific threat actors [2], [3], [7].\nIn today's rapidly evolving cybersecurity landscape, the promptness and accuracy of CTI reports are crucial for safeguarding digital infrastructures by enabling immediate responses to security risks. However, the current methodologies for generating these reports predominantly rely on manual human efforts, which introduces significant challenges affecting their efficiency and effectiveness. The manual approach to report generation is inherently time-consuming, labour-intensive, and susceptible to human error. Threat Intelligence Analysts must sift through vast amounts of data from multiple sources, synthesize the information, and compile comprehensive reports, all of which demand substantial expertise and meticulous attention to detail [8], [9].\nIn the cybersecurity community, several standard methods are used to automate CTI processes involving open-source tools, custom scripting, platform integration, and AI-based methods, which still demand CTI specialists [10]\u2013[12]. This study addresses CTI automation using AI-powered Microsoft security products, including Microsoft Copilot for Security (MCS), Logic Apps, and Azure AI, within an industrial-scale environment. The proposed method offers significant benefits, including faster threat detection, improved response times, and more accurate threat intelligence. Out method facilitates CTI processes and reduces manual efforts, ultimately strengthening cybersecurity defences. The experimental results, along with interviews with security experts, have revealed a significant impact of these technologies. We present a detailed architectural design for deploying this method within an industrial environment, highlighting how this approach can enhance security efficiency and effectiveness."}, {"title": "1.1. Problem Statement", "content": "Many organizations today rely on manual and semi-automated approaches to collect, analyze, and generate CTI reports. These methods often involve threat analysts gathering threat data from disparate sources, such as security logs, threat feeds, vulnerability databases, and social media platforms. Analysts must then filter through this data and manually correlate it to identify patterns and assess the potential impact on the organization's security posture. This process may involve using essential tools, but in many cases, it still requires a significant amount of manual work, including writing the final report [13]. The manual nature of these methods introduces several challenges. The gathering, analyzing, and reporting process can take days or weeks, delaying the response to emerging threats. Due to the complexity of modern threats, manual processing increases the likelihood of missing critical insights or introducing errors. Different analysts may interpret threat data differently, leading to inconsistencies in reporting. As the volume and complexity of threats increase, manual processes struggle to keep pace, leading to bottlenecks in threat detection and mitigation efforts [6], [13].\nIn response to these challenges, automation and using AI offers promising solutions. Organizations can significantly reduce the time and effort required to generate final CTI reports by automating the collection and analysis of threat data. AI-powered systems can ingest vast amounts of threat data in real-time, correlate patterns across multiple sources, and identify emerging threats with high accuracy. Machine learning models can learn continuously from new data, improving their detection capabilities and reassuring organizations of their adaptability to new threats as they evolve [8], [9]. Despite these advancements, many organizations are hesitant to adopt fully automated CTI processes due to concerns about the reliability of AI-driven systems, particularly in complex or high-stakes environments. They may worry about false positives, the inability of machines to interpret nuanced threat information, or the lack of transparency in how AI makes decisions [11].\nThis research aims to address the gap by exploring the limitations of current manual CTI report generation processes and investigating how automated solutions, including AI, can enhance these reports' overall quality, speed, and accuracy. By identifying which tasks within the manual process can be effectively automated-such as data collection, correlation, and preliminary analysis\u2014this study aims to lay the groundwork for developing more advanced automated CTI systems. These systems will not replace threat intelligence analysts. However, they will better support them by minimizing the manual effort required in report creation, thus enabling faster and more consistent dissemination of threat intelligence. Applying the proposed method, in turn, will allow organizations to respond more rapidly to emerging threats and implement defensive measures promptly. This research offers a practical solution to the critical shortage of highly skilled cyber threat analysts worldwide, particularly impacting medium-sized cybersecurity companies that provide CTI services."}, {"title": "2. Current Trends and Scholarly Perspe\u0441tives", "content": "Numerous studies have proposed automating the final extraction of CTI using AI-based methods, including Natural Language Processing (NLP), Information Retrieval (IR), and Machine Learning (ML) approaches such as Neural Networks (NN) [9], [11], [12], [16]. Husari et al. [9] proposed the pioneer model TTPDrill to automatically extract threat actions and map them to attack patterns, techniques, and phases of the cyber kill chain from unstructured CTI reports. The tool combines NLP and IR techniques, using an ontology derived from MITRE ATT&CK and CAPEC repositories-Common Attack Pattern Enumeration and Classification or CAPEC [17], is a comprehensive database maintained by MITRE Corporation-to map extracted TTPs to recognized cyber threat patterns. The repository aims to provide a structured and detailed understanding of how attacks are executed, which helps cybersecurity professionals anticipate threats, design effective defences, and communicate about security issues more effectively. TTPDrill aims to facilitate timely, cost-effective cyber defence by converting unstructured CTI into structured threat information, significantly improving the precision and recall of TTP extraction.\nZhao et al. [12] presents TIMiner, an automated framework designed to extract and categorize CTI from unstructured social media data. The framework uses a Convolutional Neural Network (CNN) to classify CTIs into specific domains such as finance, government, IoT, and Industrial Control Systems (ICS). The study employs a hierarchical IoC extraction method that leverages word embedding and syntactic dependency to identify known and unknown types of IoCs. TIMiner also introduces a novel metric, Threat-Index, which quantifies the severity of threats across different domains by analyzing attack frequency, exploited vulnerabilities, and risk levels.\nSatvat et al. [16] introduce an EXTRACTOR tool, which automates the extraction of concise attack behaviour from unstructured CTI reports. EXTRACTOR generates provenance graphs that capture the relationships between entities, actions, and system artifacts in a cyber attack. The tool leverages NLP techniques like Semantic Role Labeling (SRL) to process complex CTI texts and infer who did what to whom in an attack. The study addresses verbosity, syntactic complexity, and the need to capture causal and temporal dependencies between actions. EXTRACTOR generates actionable intelligence, simplifying threat-hunting tasks by focusing on attack behaviour that can be observed in system audit logs. The tool was evaluated against real-world CTI reports and DARPA adversarial engagements, showing high precision and utility in detecting cyber threats using automatically generated graphs.\nJo et al. [11] present a CTI system called Vulcan, which automates the extraction of diverse CTI data, including TTPs, from unstructured sources like security reports and blogs. Vulcan employs a fine-tuned language model to perform Named Entity Recognition (NER) and Relation Extraction (RE), accurately identifying CTI entities (e.g., attack vectors, tools) and their relationships. The extracted CTI data are stored in a graph database, accessible via APIs, enabling applications such as threat evolution tracking and profiling. Liu et al. [15] introduce a system to extract actionable CTI from unstructured cybersecurity reports automatically. TriCTI uses a trigger-enhanced neural network model that incorporates campaign triggers to classify IoCs based on the cyber kill chain stages. By leveraging NLP and data augmentation techniques, TriCTI improves classification accuracy and generates actionable intelligence that can be integrated into intrusion detection systems.\nYou et al. [14] introduce the TIM framework designed to mine and classify TTPs from unstructured threat data such as security analysis reports. The framework uses a TCENet (Threat Context Enhanced Network) model that leverages textual descriptions and specific TTP-related elements (e.g., IPs, CVEs, file hashes) to classify TTP. The lack of available sentence-level TTP datasets and the complexity of accurately classifying TTP descriptions is addressed in this study. In a recent study, Le et al. [8] introduced LADDER, a framework designed for knowledge extraction that identifies text-based attack patterns from CTI reports. LADDER automates the extraction of TTPs and other essential data related to malware and APTs from CTI sources. The framework organizes the extracted information using an ontology-a structured representation of knowledge domains in information science to aid in meaningful information organization. Combined with the TTPClassifier, this ontology integrates the information into a comprehensive knowledge graph (KG). The KG, formatted as triples (subject, predicate, object), includes domain-specific information, facilitating predictive analysis. In contrast to our research, the author proposed a method to automate only attack pattern extraction. Our work not only automates the whole CTI generation but also produces a comprehensive report, including strategic and operational CTI.\nLi et al. [10] introduce AttacKG, a novel system designed to automatically extract structured attack behaviour graphs from unstructured CTI reports and aggregate them to form a Technique Knowledge Graph (TKG). This approach addresses the challenge of manually recovering attack behaviours from CTI reports, often written in natural language. By parsing multiple CTI reports, AttacKG identifies and integrates diverse attack techniques, creating comprehensive knowledge graphs that summarize various aspects of attack patterns. The system outperforms existing tools in accuracy, providing valuable intelligence for security tasks like APT detection and cyber attack reconstruction.\nRecent advancements in AI-driven CTI extraction, such as LADDER and AttacKG, employ a combination of NLP techniques and open-source pre-trained LLMs, including BERT [18], ROBERTa [19], and XLM-ROBERTa [20], to identify relevant sentences, determine if they describe an attack, and map these attacks to the corresponding Tactics, Techniques, and Procedures (TTPs) in the MITRE ATT&CK framework [2], [3], [7], [11], [12]. Despite their effectiveness, these approaches still demand specialized expertise for model implementation, limiting their practicality in environments without such resources. In contrast, our study introduces the first fully automated CTI extraction methodology that eliminates the need for domain-specific expertise. Additionally, our approach autonomously generates comprehensive CTI reports, covering IoCs and TTPs, mapping attack behaviours to the MITRE framework, and recommending mitigation strategies. These reports are organized into two primary sections: strategic reports, offering high-level summaries for executives, and technical"}, {"title": "3. Methodology", "content": "This study introduces a fully automated, end-to-end process for generating CTI reports using AI built within the Microsoft enterprise ecosystem. Key technologies include PowerShell scripting, Azure Logic Apps, MCS, Azure AI Studio, and Azure DevOps. The automation begins with a PowerShell script, which gathers essential data from the user and manages the workflow. Azure Logic Apps then orchestrate the report generation by dividing it into multiple sections. Each section is produced through customized prompts directed to MCS or Azure AI. Once all sections are completed, the Logic Apps and PowerShell script merges them into a final, cohesive report that is automatically stored in the Azure DevOps repository. The proposed architecture is shown in Figure 1. The segmentation approach ensures precise control over the prompt creation, allowing for customization of each section. The generated final CTI report comprises the following seven sections:\n1) Metadata and Overview\n2) MITRE Summary Table\n3) Data Extraction\n4) Tools and Malware\n5) Defense Recommendations\n6) References\n7) Tags\nThe first and second sections include strategic CTI information for executive-level decision-making, while the remaining sections fall under the technical CTI report category. The Metadata and Overview section provides general information about the report, including the report title, creation date, attacker details, and a threat intelligence summary. The Overview briefly describes the scope of the threat, including the affected sectors, systems, or technologies, and the severity or priority level of the threat, offering a high-level snapshot to set the context for the rest of the report. The MITRE Summary Table section presents a structured summary of the identified TTPs used in the threat, mapped to the MITRE ATT&CK framework, including specific techniques leveraged by attackers and highlighting the associated adversarial tactics. The table serves as a quick reference for understanding the threat actors' behaviour and operational methodologies.\nThe Data Extraction section contains all relevant data points related to the observed threat. This section typically includes IoCs information, such as IP addresses, file hashes, domain names, and other artifacts that may assist in identifying or tracking a threat. This section focuses on the factual data collected from various sources during the investigation. The Tools and Malware section details any tools, exploits, or malware observed in the attack, including the descriptions of how these tools are used by threat actors and their potential impact on compromised systems. The analysis often highlights known or new malware variants, software used in the attack chain, and the relationships between the tools and broader campaigns.\nThe Defense Recommendations section provides actionable recommendations to mitigate or respond to threats. This section covers suggested defensive measures, including patches, configurations, detection rules, and long-term strategies to protect against similar future threats. It may also highlight gaps in current defences that organizations should address. The References section lists all the sources used to create the CTI report, including but not limited to academic papers, threat feeds, public and private security advisories, and other research material relevant to the threat. Finally, the Tags section contains keywords or phrases that categorize the threat for easier indexing and retrieval. Tags may include the malware family name, associated adversaries, affected industries, geographic regions, TTPs, or specific vulnerabilities exploited. These tags help in searching and cross-referencing the report with other similar threats."}, {"title": "3.1. PowerShell Script", "content": "The PowerShell script acts as the main user interface, orchestrating the initialization of all the underlying systems, including Azure Logic Apps and Azure DevOps. This component integrates various functionalities such as user input, file validation, HTTP requests, and monitoring mechanisms to ensure a smooth and automated workflow. As illustrated in Figure 2, the script's tasks are divided into four main functions:\n1) User Input and Validation\n2) File Existence Check\n3) Trigger Logic Apps\n4) Report Monitoring and Retrieval\nBased on artifact similarities, the threat types are categorized as follows: Campaign, Threat Actor, Vulnerability, or Malware/Tool. The user input and validation functions collect intelligence data and verify the threat type. The script then prompts the user to provide essential intelligence information and select a specific threat type, ensuring the chosen threat meets predefined criteria for validity. The file existence check ensures the uniqueness of the CTI report's file name. To start, the user is prompted to input a file name checked against the Azure DevOps repository to avoid duplicates. If a file with the same name already exists, the user is notified and asked to provide a new name. The Trigger Logic Apps function initiates the CTI report creation process by collecting all user-provided data and sending an HTTP request to the Logic Apps. This data is passed as a JSON request body, and the function ensures the request is successfully sent while handling potential errors. The report monitoring and retrieval components continuously monitor the Azure DevOps repository for the CTI report's creation. The script checks for recent commits every two minutes until the CTI report is located. Once the report is successfully generated, the user is notified that it is available in the repository."}, {"title": "3.2. Azure Logic Apps", "content": "Azure Logic Apps defines a cloud service that helps users automate workflows and integrate applications, data, and services across organizations. It allows the creation of automated workflows to connect different services and applications and offers numerous pre-built connectors for services. Users can create custom workflows using a visual designer or code and trigger workflows based on specific events or schedules. Azure Logic Apps automates business processes and tasks, integrates disparate systems and data sources, manages enterprise workflows and data flows, and builds complex integration scenarios with minimal coding.\nThe Azure Logic Apps workflow serves as the core engine of the process, orchestrating the generation of the CTI report by integrating MCS, Azure AI Studio, and Azure DevOps a Cloud-based platform from Microsoft that offers tools for managing the entire software development lifecycle, including version control, project tracking, and collaboration. This workflow is designed to manage various types of threat intelligence, including campaigns, threat actors, vulnerabilities, and malware/tools. Depending on the threat type, the workflow branches into sub-workflows, employing Azure AI and MCS where applicable. The process is initiated by an HTTP request from a PowerShell script, which sends JSON-formatted data containing key parameters such as intelligence information, threat type, and file name. A variable, Merge Sections, is created to store the context of the report sections. The Logic Apps workflow then assesses the threat type (Campaign, Threat Actor, Vulnerability, or Malware/Tool) and redirects the process accordingly, as illustrated in Figure 3.\nThe figure provides the Campaign threat type as an example for clarity without loss of generality.\nThe CTI report is organized into distinct sections based on the threat type (elaborated in Section 3.1). Logic Apps initiates Azure AI or MCS to generate each section accordingly, appending the results to the Merge Sections variable. Once all sections are compiled, Logic Apps retrieves the latest commit details from the Azure DevOps repository. The response is parsed to extract the most recent commit ID, which is required to initiate a new commit via the DevOps API. Finally, the fully compiled CTI report, stored within the Merge Sections variable, is uploaded to the Azure DevOps repository under the specified file name using the DevOps API."}, {"title": "3.3. Azure AI Studio", "content": "Azure AI Studio facilitates the development of prompt flows, empowering developers to design, debug, and deploy AI-driven applications using customizable prompts and Python scripts. In this architecture, these flows are integrated with Azure Logic Apps. Our design leverages OpenAI's GPT-40 model to extract, analyze, and generate specific sections of the CTI report. As depicted in Figure 4, the workflow is structured into two main prompt flow deployments: one dedicated to generating the MITRE summary table and performing data extraction, and the other focused on generating the Tags section. In the first prompt flow, a spreadsheet containing the complete MITRE ATT&CK enterprise matrix is uploaded into the Azure Al environment to facilitate prompt flow deployment. This file provides a comprehensive reference for ATT&CK techniques and sub-techniques. The process initiates when intelligence information (Intel Info), received through an HTTP request from Logic Apps, is sent to Azure AI Studio. A Python script is subsequently employed to extract relevant text from a specified URL or article, which is the basis for further analysis and data extraction.\nThe retrieved text is processed by prompting GPT-4o to generate a summary table of MITRE ATT&CK techniques. In this step, GPT-4o is tasked with creating a section explaining the techniques and sub-"}, {"title": "3.4. Microsoft Copilot for Security", "content": "MCS is an AI-powered assistant designed to enhance cybersecurity operations by providing real-time insights and recommendations. MCS, powered by machine learning, efficiently analyzes threat data and provides actionable insights, helping security teams respond to threats more effectively with guided steps and automation. MSC assists proactive threat hunting by analyzing vast amounts of security data to integrate the outcome with existing Microsoft security tools such as Microsoft Defender and Sentinel. In the proposed architecture, MCS is integrated with Azure Logic Apps, which provide a built-in action to facilitate direct interaction with MCS, enabling prompts to be sent and responses to be received within the workflow. Additionally, Azure Logic Apps allows the specification of skills, which are capabilities that enhance prompt processing. These skills enable extended functionality, such as accessing web URLs or retrieving threat intelligence from Microsoft Defender for threat intelligence. In this architecture, MCS generates four essential sections of the report: Metadata and Overview, Tools or Malware, Defense Recommendations, and References. From this point on, we use AI, LLM, and GPT-4.0 interchangeably to refer to systems that receive prompts and generate outputs. Specific distinctions will be made when necessary."}, {"title": "3.4.1. Metadata and Overview", "content": "At this stage, the prompt directs the AI to extract detailed information about a threat campaign from a URL. Then, it is tasked with populating a pre-defined CTI report template in markdown format, ensuring accuracy and thoroughness. The critical elements, such as the campaign name, threat type, associated threat groups, and targeted industries, are filled in based on the data retrieved from the source. Additionally, the AI generates a strategic campaign summary to enhance accessibility for a wider audience. This structured process ensures the creation of consistent, detailed CTI reports while minimizing the risk of human error."}, {"title": "3.4.2. Tools or Malware", "content": "To generate this section, the prompt concentrating on identifying malicious software, tools, or malware employed in a cyber threat campaign. The AI generates a detailed technical report using data from a provided URL and the Microsoft Defender CTI Platform. A structured markdown template captures specific sections for each identified tool or malware. For each entry, the AI delivers a description and an example of how the threat actors utilize the tool or malware. This approach ensures the report is technically comprehensive and accurate, leveraging authoritative sources for in-depth analysis."}, {"title": "3.4.3. Defense Recommendations", "content": "In this section, the prompt identifies malicious software, tools, or malware employed in a cyber threat campaign. The LLM generates a detailed technical report using data from a provided URL and the Microsoft Defender CTI Platform. A structured markdown template captures specific sections for each identified tool or malware. For each entry, the AI delivers a description and an example of how the threat actors utilize the tool or malware. This approach ensures the report is technically comprehensive and accurate, leveraging authoritative sources for in-depth analysis."}, {"title": "3.4.4. References", "content": "The LLM first compiles a list of references specific to a given threat campaign in this prompt. It gathers data from the provided URL and other publicly available sources. A structured markdown template populates these references as a list of URLs related to the threat campaign, ensuring the accurate collection and citation of relevant sources. This process provides comprehensive references to substantiate the report's findings."}, {"title": "4. Performance Assessment and Key Findings", "content": "We evaluated the proposed approach from two perspectives: performance and cost. Initially, we conducted experiments comparing the reports generated manually by CTI analysts with those produced by AI. This phase focused on a Campaign threat type, comparing eight attack campaigns created by both methods, which are extracted from hundreds of reports, news, blogs, and other open and closed CTI resources. Lastly, we assessed and presented the cost associated with AI-based report generation using the proposed method."}, {"title": "4.1. Performance Evaluation Manual vs. A\u0399-Based Methods", "content": "We selected Cosine Similarity and BERT (Bidirectional Encoder Representations from Transformers) to compare the AI-generated report with the manual counterpart. BERT can process up to 512 tokens at a time, allowing it to handle relatively long documents [21]\u2013[23]. BERT can be used to compare two documents by representing each document as a numerical vector (embedding) and then measuring the similarity between these vectors. The process involves encoding the documents' text into high-dimensional embeddings that capture the text's semantic meaning, allowing for a meaningful comparison. BERT starts by breaking down the text of each document into tokens (typically words) and converting words into a sequence of token IDs that BERT can process. Then, it adds unique tokens like [CLS] at the start of each document and [SEP] at the end to signify the boundaries of the input. Each token is then mapped to a pre-trained embedding vector using BERT's embedding layer. These embeddings are contextual, meaning that the representation of a word depends on the words around it. BERT uses multiple layers of bidirectional transformers to process the input sequence and generate contextualized embeddings for each token. The embeddings capture the meaning of the words considering the surrounding context rather than treating them as isolated entities.\nAfter processing the document through BERT, each document is represented as a high-dimensional vector (embedding). These vectors capture the meanings of individual words and their relationships in the document's context. Once both documents have been transformed into vectors, we compare them using a Cosin Similarity. We also use Cosine Similarity to capture the similarity between the vocabulary of the two documents. The formula for cosin similarity between two vectors A and B is:\ncosine similarity = $\\frac{A \\cdot B}{||A||||B||}$\nwhere $A \\cdot B$ is the dot product of the two vectors, and $||A||$ and $||B||$ are the magnitudes (or norms) of vectors A and B, respectively. The expanded formula then becomes:\ncosine similarity = $\\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}}$\nCosine similarity measures the cosine of the angle between two non-zero vectors. A result of 1 indicates"}, {"title": "4.2. Automated CTI Report Generation Efficiency and Trade-offs", "content": "While this research indicates the proof of concept, the system successfully automates the development of CTI reports, significantly speeding up the process and reducing the need for manual effort while maintaining the intelligence's accuracy. However, this efficiency comes with a cost each report's creation requires substantial computational resources. These resources are primarily consumed by the AI tools employed, such as MCS and Azure AI Studio, which contribute to the environment's overall complexity and resource demands.\nAzure AI Studio: The computational cost in Azure AI Studio is determined based on the Compute Instance (CI) specifications and the online endpoint where the prompt flow is deployed. The CI functions similarly to a Virtual Machine (VM) instance, with pricing in Azure based on the instance type and the number of hours it operates. All AI computations, such as prompt processing, are executed using the allocated computational resources, including the number of CPU cores, RAM, and storage space provided by the instance type. Each deployment functions like a web server, offering a URL endpoint that handles HTTP requests to trigger the prompt flow, returning the AI-generated output. Since the deployment endpoint is integrated into Logic Apps for automated HTTP requests, the compute instance must remain active 24/7. Azure AI Studio hosts two prompt flow deployments in this setup-one for processing Sections 2 and 3 of the report and another for Section 7. Each deployment is equipped with a 2-core CPU and 8GiB of RAM. The combined monthly cost for both deployments is approximately $290, which breaks down to $0.20 per hour per deployment (assuming a 30-day month with 720 hours).\nMicrosoft Copilot for Security: The usage cost for MCS is measured in Security Compute Units (SCUs), which are consumed during prompt processing and output generation. Two key factors influence the consumption of SCUs: the size of the prompt (the number of characters submitted to the model) and the utilization of specific skills within MCS. This implementation optimizes prompt sizes to reduce SCU usage by summarizing explanations and eliminating"}, {"title": "5. Discussion and Challenges", "content": "The cost and SCU usage are approximate due to the inherent variability in each output generated by the AI, which differs in terms of length and word choice. Both Azure AI and MCS utilize OpenAI's GPT-40 model for prompt processing [24]. This model is designed to introduce an element of randomness, ensuring that identical prompts, input values, and parameters do not result in the same output on different occasions [25]. Despite this variability, the overall quality and intent of the generated content remain consistent. Due to the minor inconsistencies and the continuous advancements in AI technology, the outputs generated by the system cannot be considered final without human oversight. Human analysts must review and refine the AI-generated reports to meet the quality standards of manually produced reports. The primary goal of this research project was to accelerate the report creation process and reduce manual effort rather than completely eliminate the need for human involvement.\nTo report the acceleration of the AI-based model, we interviewed the Threat Intelligence team at our industrial partner site. Based on the survey outcome, the manually produced CTI report from raw data typically required an average of 8 hours of effort, depending on the threat's complexity. With the introduction of AI automation, the manual effort needed"}, {"title": "6. Conclusion and Future Work", "content": "This study presents an architecture for automating Cyber Threat Intelligence (CTI) report generation using AI-powered tools within the Microsoft ecosystem. The primary objective was to accelerate the CTI generation process, enabling faster sharing of intelligence and enhancing attack detection and prevention for stakeholders. This objective was successfully achieved by integrating Microsoft Copilot for Security, Azure DevOps, and Azure AI Studio. Our evaluation of the proposed architecture, comparing manually generated and AI-generated reports, demonstrated high performance across both technical and executive-level reporting. Notably, while AI performed equally well in generating executive summaries, human intervention is still crucial in the more complex technical sections of the report. This necessity underscores the value of human expertise in maintaining the level of precision necessary for effective decision-making and implementation by security teams.\nFuture research will focus on evaluating the proposed method with larger datasets, incorporating both manually and AI-generated reports. Additionally, an in-depth analysis of other threat types beyond campaign threat intelligence will be conducted to assess performance and other factors, including cost. While GPT-40 was the primary language model used for prompt engineering, future work will explore the use of alternative models to compare their effectiveness. The experiments further indicated that combining AI-driven processes with human input yields the highest performance. As a next step, we propose developing a hybrid model that integrates other AI-based methods with proprietary security products. This model promises to further refine CTI report generation and enhance the overall quality of the final output, instilling optimism about the future of CTI report generation."}]}