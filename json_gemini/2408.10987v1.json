{"title": "Denoising Plane Wave Ultrasound Images Using Diffusion Probabilistic Models", "authors": ["Hojat Asgariandehkordi", "Sobhan Goudarzi", "Mostafa Sharifzadeh", "Adrian Basarab", "Hassan Rivaz"], "abstract": "Ultrasound plane wave imaging is a cutting-edge technique that enables high frame-rate imaging. However, one challenge associated with high frame-rate ultrasound imaging is the high noise associated with them, hindering their wider adoption. Therefore, the development of a denoising method becomes imperative to augment the quality of plane wave images. Drawing inspiration from Denoising Diffusion Probabilistic Models (DDPMs), our proposed solution aims to enhance plane wave image quality. Specifically, the method considers the distinction between low-angle and high-angle compounding plane waves as noise and effectively eliminates it by adapting a DDPM to beamformed radiofrequency (RF) data. The method underwent training using only 400 simulated images. In addition, our approach employs natural image segmentation masks as intensity maps for the generated images, resulting in accurate denoising for various anatomy shapes. The proposed method was assessed across simulation, phantom, and in vivo images. The results of the evaluations indicate that our approach not only enhances image quality on simulated data but also demonstrates effectiveness on phantom and in vivo data in terms of image quality. Comparative analysis with other methods underscores the superiority of our proposed method across various evaluation metrics. The source code and trained model will be released along with the dataset at: http://code.sonography.ai", "sections": [{"title": "I. INTRODUCTION", "content": "ULTRASOUND imaging, a non-invasive and cost-effective medical diagnostic tool, is crucial in modern healthcare by providing real-time visualization of internal structures and abnormalities. Nevertheless, despite its many advantages, the presence of noise can hinder broader use of ultrasound imaging because it can restrict the interpretability and diagnosis precision of the medical images [1]. The development of robust post-processing techniques [2] [3] for ultrasound images has, therefore, become imperative to enhance image quality and facilitate more accurate diagnoses. To address the mentioned challenges, classical techniques have delved into realms such as image filtering, speckle reduction algorithms, and contrast enhancement methods [4]. These endeavors, while being impactful, often encounter complexities inherent to ultrasound data, which necessitates the development of more robust methods which have adaptive approaches [5].\nRecently, deep learning has come to the world as a game changer in the domain of medical imaging, and ultrasound image analysis is not an exception. Deep learning has shown remarkable potential in dealing with the formidable challenges of ultrasound imaging. These models, harnessed by their ability to leverage large-scale datasets and discern intricate patterns within ultrasound data, have the power to significantly reduce noise, enhance image contrast, and amplify image fidelity. Recent studies underscore their prowess in tasks such as image denoising, image segmentation, and pathology detection [6]. For instance, U-Net [7] stands as a landmark in medical image segmentation and denoising, spanning several applications in ultrasound imaging [8]. Furthermore, the work by Kaur et al. [9] underlines the promising trajectory of deep learning techniques in denoising ultrasound images.\nRecently, Denoising Diffusion Probabilistic Models (DDPM) [10] have shown a remarkable performance in image denoising. DDPMs are based on diffusion models, which are a part of larger generative models. Among the pioneers of generative modeling, Generative Adversarial Networks (GANs) [11], Variational Autoencoders (VAE) [12], and diffusion models [10] stand out as versatile frameworks, each offering a unique perspective on the generation of complex data.\nGenerative models, when repurposed as denoisers, utilize their learned knowledge of data distributions to remove noise from input data while preserving essential features. This denoising capability makes them valuable tools for enhancing the quality of noisy images, audio, or data. DDPMs stand out among generative models for their ability to reduce noise progressively and iteratively [10].\nDiffusion denoising probabilistic model (DDPM) was the first version of the diffusion generative models, which triggered many other innovations that improved both sampling time and image quality. Those attempts resulted in improved diffusion models [14], [15], and \u201ccome closer diffuse faster\u201d [16], which decrease the sampling time. Fundamental diffusion models were used to transfer between the normal noise space and the objective training space. However, the most recent diffusion models like [17]\u2013[20] have shown the feasibility of moving directly between two arbitrary spaces which are not necessarily normal noise. Such ideas motivated us to use diffusion models to move from the low-quality ultrasound plane waves (PWs) toward the high-quality ones. Diffusion models, apart from their applications on natural images, can be leveraged for medical image applications. Medical image segmentation [21], [22], image inpainting [23], and super-resolution [24] are some examples. In ultrasound imaging, recent works have tackled super-resolution [25], ultrasound dehazing [1], and ultrasound image reconstruction [26].\nIn this study, we leverage the iterative denoising capabilities of diffusion models to improve the quality of ultrasound images. While we acknowledge in this section that DDPMs may not excel in rapid sampling, it is essential to emphasize that we utilize these models specifically for denoising, not sample generation. As a result, the number of iterations employed for denoising is significantly less than the time typically required when using DDPMs for sample generation. More specifically, the proposed method uses the differences between low-compounded PWs (representing low-quality images) and high-compounded PWs (representing high-quality images) as the perturbation factor instead of the noise (in DDPM) in the forward process. In the reverse process, our method is initialized by a low-quality image (instead of a Normal noise image). This conditioning helps us to reduce the required number of reverse steps, leading to less computations.\nA preliminary version of this paper was recently published [27]. This initial publication proposed a method for eliminating Normal noise in ultrasound images, where the input and output of the model were B-mode PW images. Herein, we present the methodology to denoise the RF beamformed PW data, wherein our input and output to the model are RF beamformed images. We also present the method in substantially more depth and extend the validation scope significantly, incorporating evaluations using both real phantom and in vivo data. The main contributions of this paper are as follows:\n\u2022 Tailored DDPM for ultrasound image denoising. The"}, {"title": "II. RELATED WORK", "content": "Considering the main idea of the proposed method and our emphasis on ultrasound image denoising, in this section, we specifically concentrate on denoising methods. Subsequently, we will delve into the examination of generative models and their application in the context of image denoising."}, {"title": "A. Ultrasound image denoising methods", "content": "Several elements contribute to the degradation of ultrasound image quality: Gaussian electronic noise present in the RF data, and a range of acoustic noise sources, including reverberation and multiple scattering phenomena. These factors collectively lead to large diffuse reverberations and clutter, adversely affecting image clarity. In this paper, we exploit advances in the field of denoising to improve the quality of ultrasound images. It is important to emphasize that our goal is not to despeckle the ultrasound image, as ultrasound speckle is not simply noise; it often holds essential information pertinent to diagnosis and image-guided interventions. While despeckling might aid tasks like image segmentation, it can adversely affect radiologists and certain subsequent tasks, such as quantitative ultrasound. Instead, our aim is to concentrate on denoising the images, ensuring the preservation of the speckle pattern.\nBefore deep learning, adaptive filtering methods utilized filters such as the Wiener filters, and adjusted their parameters based on local image characteristics, smoothing out noise while preserving essential anatomical structures [29]. Wavelet-based denoising, another prevalent classical method, decomposed ultrasound images into different frequency components, enabling selective noise reduction while retaining crucial image features [30]. The adaptability to target noise at specific scales has made wavelet-based denoising a valuable asset in ultrasound image processing. Anisotropic diffusion filters were also employed to enhance ultrasound images by selectively permitting diffusion along image edges while preserving the edges themselves [30]. This approach maintained structural details in the image while reducing noise. Furthermore, the non-local means denoising algorithm found its application in ultrasound image denoising [31]. Leveraging the redundancy in ultrasound images, the method averaged similar pixels, effectively reducing noise without compromising vital diagnostic information. While classical methods typically suffer from high computational complexity and produce blurry outputs, deep learning-based methods exhibit low computational complexity in the inference phase and generate denoised images of higher quality.\nRecently, a number of methods based on deep learning have been developed to improve the quality of ultrasound images. For instance, Perdios et al. [32] trained an adapted version of U-Net on simulated data and showed that their network also performs well on in vivo data. Gupta et al. [33] looked at image denoising as an inverse problem and solved it using a deep learning model. A network called Mimicknet [34] was proposed to improve the image quality in post-beamformed data. Zhang et al. [35] aimed to reconstruct high-quality ultrasound PWs from raw channel data by training a self-supervised trained network in an inverse problem approach. Van Sloun et al. [5] have explored deep learning methods that have been developed for adaptive beam-forming, spectral Doppler, clutter suppression, and super-resolution.\nSuper-resolution is another post-processing technique commonly employed to transform a low-quality image into a higher-quality one. This technique has recently garnered significant attention from researchers specializing in medical image analysis. Khakzad et al. [36] designed a network made of an encoder followed by a transformer-based decoder for probable localization. In another similar work [37], Deep-ULM was suggested for vascular ultrasound imaging using super-resolution.\nIn comparison to natural images, ultrasound data exhibit challenges arising from both high frequency and wide dynamic ranges [38]. These characteristics, irrespective of the specific application, pose significant obstacles to the effective utilization of Convolutional Neural Networks (CNNs) for ultrasound image enhancement. Various studies have attempted to address these challenges by proposing pre-processing techniques, architectures, and loss functions. For instance, it has been demonstrated that individually standardizing each RF ultrasound image in the dataset enhances the performance of CNNs by mitigating the detrimental effects of high dynamic range and utilizing the data more efficiently [39]. To address both the high dynamic range and the oscillating properties of RF ultrasound images, mean signed logarithmic absolute error (MSLAE) was introduced as the loss function for training a residual-based CNN with multi-scale and multi-channel filtering properties [40]. For efficient recovery of high-frequency contents, the wavelet transform was employed in a multi-resolution architecture [41]. To mitigate the risk of getting trapped in local minima during the initial stages of optimization on fluctuating RF ultrasound images, an adaptive mixed loss function was proposed that gradually transitions from B-mode loss to RF loss as the training progresses [28].\nOne of the major concerns when using CNNs for ultrasound image denoising pertains to the network's ability to retain informative features while removing noise. To address this concern, different attention mechanisms were utilized to guide feature extraction in different layers of CNNs. Dong et al. [42] employed a multi-stage CNN, introducing feature masking to identify the most beneficial features. Residual attention was another attention mechanism used for more efficient feature"}, {"title": "B. Generative models", "content": "Numerous valuable efforts have been made to develop generative models for the purpose of denoising and image enhancement. MedGAN [45] was designed for medical image-to-image translation, which brought two main contributions. First, a discriminator was trained to play the rule of feature extractor by measuring the distance between the output and the desired one. Second, the textures and fine structures of the desired target images are matched to the translated images using style-transfer losses. Chung et al. [46] have proposed a score-based diffusion model to reconstruct high-quality MRI images from a low-quality image. Their method process the real and imaginary data separately and finally adds them together. In contrast to our method, which is initialized by one PW in the reverse process, their method starts from pure noise and passes many steps to reach a high-quality image in the reverse process. Goudarzi et al. [47] proposed a generative adversarial network to recover a high-quality image from a single-focus image, which resembles a multi-focus ultrasound image in terms of quality. UltraGAN [48] also applied GANS to improve ultrasound echocardiography.\nApart from the GANs, there are some works that adapted diffusion models on ultrasound data. In [1] diffusion model was employed for ultrasound cardiography dehazing. Two diffusion models were trained to generate a patch-wise clean image and haze separately using a hazy image as a condition. Domingues et al. [49] introduced ultrasound physics to a diffusion model for ultrasound image generation. They modified the noise scheduler based on attenuation maps to include the attenuation in their synthetic data. In Zhang et al. [26], a reconstruction method was proposed based on the diffusion models to reconstruct B-mode images from raw channel data. Their main desire was to eliminate the effects of the normal noise that exists in the raw channel data, which appears as artifacts in the beamformed data. In Li et al. [50] and Lan et al. [51], the authors have proposed a score-based diffusion model which trained on B-mode 75 compounding PW images to enhance ultrasound image quality from one PW to 75 compoundings. In a recent work [52], the authors propose a new method to distinguish 13 anatomies in fetal ultrasound videos using a dual-conditioned diffusion model."}, {"title": "C. Background", "content": "Denoising diffusion models are composed of two procedures: the forward process and the reverse process. In the forward process, an image is perturbed by normal noise during several steps. In the next step, a network learns how to approximate the noise in each step. In the reverse process, starting from pure noise, the model (using an iterative process) reconstructs a sample using the training distribution based on the learned priors by the network. Here are more details about the procedures (from [10]):\n1) Forward process: Given an initial image $x_0$, the output of each step (a Markov chain) can be defined as follows:\n$x_t = \\sqrt{1 - \\beta_t}x_{t-1} + \\sqrt{\\beta_t}\\epsilon, \\epsilon \\sim N(0, I)$,\t\t\t(1)\nwhere $x_t$ is the data at time step $t$, $\\beta_t$ is a variance schedule, $\\epsilon$ is noise sampled from a normal distribution $N(0, I)$. In that case, $q(x_t | x_{t-1})$ has a normal distribution:\n$q(x_t|x_{t-1}) = N(x_{t-1}, \\mu(x_{t-1},t), \\sigma_t)$.\t\t\t(2)\nIt can be directly linked to $x_0$ by:\n$x_t = \\sqrt{1-\\bar{\\beta}_t}x_0 + \\sqrt{\\bar{\\beta}_t}\\epsilon, where, \\bar{\\beta}_t = \\sum_{s=1}^t\\beta_s$\t\t\t(3)\n2) Reverse process: In the reverse process, the objective is to transition from a noisy (low-quality) image at step $T$ and enhance the image quality step by step to approximate the original high-quality image $x_0$ closely. This entails maximizing the likelihood of the predicted image $P_{\\theta}$, where $\\theta$ denotes the prediction parameters, or minimizing the negative log-likelihood of the prediction as follows:\n$P_{\\theta}(x_0) = \\int P_{\\theta}(x_{0:T}) dx_{0:T}$,\t\t\t(4)\n$L_{\\theta}(x_0) = -log(P_{\\theta}(x_0))$,\t\t\t(5)\n$P_{\\theta}(x_{0:T}) = \\prod_{t=1}^T P_{\\theta}(x_{t-1}|x_t)$.\t\t\t(6)\nwhere\nNote that $p_{\\theta}$ is the predicted noise distribution at each step of the reverse process, and $P_{\\theta}$ indicates the PDF of the predicted $x_0$. Since the predicted $x_0$ is conditioned on several consecutive steps, to calculate $P_{\\theta}$ in integral form, we need to integrate over a very high dimensional (pixel) space for continuous values over $T$ time steps. As such, this integral is not tractable. To solve the problem stemming from variational lower bound [53], one can write:\n$\\begin{aligned} - \\log(P_{\\theta}(x_0)) &= -\\log(\\int \\frac{P_{\\theta}(x_{0:T})}{q(x_{0:T}|x_0)} q(x_{0:T}|x_0) dx_{0:T}) \\\\  &= -\\log( E_q[\\frac{P_{\\theta}(x_{0:T})}{q(x_{0:T}|x_0)}])\\\\ &\\leq E_q [ - \\log( \\frac{P_{\\theta}(x_{0:T})}{q(x_{0:T}|x_0)}  )]. \\end{aligned}$\t\t\t(7)"}, {"title": "III. METHODS", "content": "This paper presents an iterative model inspired by DDPMs to enhance a low-quality beamformed RF image to a high-quality beamformed RF image. Specifically, our primary objective is to enhance the quality of a PW image initially constructed with a restricted number of compounded angles to closely resemble the quality of an image constructed using a larger number of angles. In other words, we consider the low-compounded ultrasound images (low-quality) in $\\pi_1$ space and their corresponding high-compounded counterparts (high-quality) in $\\pi_0$. Therefore, our problem can be defined as a transition from $\\pi_1$ to $\\pi_0$.\nIn similar diffusion-based denoising methods [1], [16], a diffusion model is trained on high-quality image space to generate high-quality images (corresponding to $t=0$) starting from Normal noise (corresponding to $t=T$). Then, in the inference procedure, a low-quality image passes through a number of forward process steps to the extent that the resulting noisy image becomes close to the noise in the training phase (corresponding to $t=T$). Finally, in the reverse process, the trained network generates a high-quality image starting from the noisy image corresponding to $t=T$. This approach includes many steps in the reverse processes, which creates very high-quality results but requires additional guidance to ensure the reliability of the output. As an example, Li et al. [50] also adapted this approach and introduced data consistency to reduce the error that can be compounded in several diffusion steps. In this work, similar to [17]\u2013[20], the idea is to train a diffusion model to move directly from $x_1$ in space $\\pi_1$ toward $x_0$ in space $\\pi_0$. This approach dramatically reduces the number of required sampling steps because a single-PW image is not very different from a compounded image.\nBased on our particular objective, we examined the disparity between low-compounded ultrasound images (low-quality from $\\pi_1$) and their corresponding high-compounded counterparts (high-quality from $\\pi_0$). The analysis indicates that the distribution of this difference can be close to a Gaussian distribution.\nAlthough the vanilla diffusion models used normal Gaussian noise in their forward and reverse processes, here, stemming from [18]\u2013[20], we define a forward and a reverse process to directly transfer between $\\pi_0$ and $\\pi_1$ without requiring to go to Normal noise distribution in between. It means the forward and reverse processes are not merely dependent on Gaussian noise."}, {"title": "A. Forward process", "content": "Having observations like $X_0 \\sim \\pi_0$ and $X_1 \\sim \\pi_1$, we can construct a forward process based on ordinary differential equations to gradually move from $\\pi_0$ to $\\pi_1$ following an interpolation procedure:\n$x_t = (1-t)X_0 + tX_1$,\t\t\t(18)\nwhere $t \\in [0, 1]$. After a minor replacement:\n$x_t = X_0 +t(X_1 \u2013 X_0)$,\t\t\t(19)\n$\\Delta x_t = (X_1 - X_0) \\Delta t$,\t\t\t(20)\n$X_{t+\\Delta t} = x_t + \\Delta x_t = x_t + v(x,t)\\Delta t$.\t\t\t(21)\nHence, $(X_1 - X_0)$ can be considered as a flow velocity $v(x_t, t) = \\frac{X_1 - X_0}{\\Delta t}$, which determines the changes in each time step (in the forward process). "}, {"title": "B. Reverse process", "content": "In the reverse process, starting from an initial point like $x_1$ from $\\pi_1$, we want to move toward $x_0$ from $\\pi_0$ while following a trajectory that is as close as possible to the reverse of the forward process, which means maximizing $p_{\\theta}(x_1)$. Similar to 13 and 14:\n$q(x_{t-\\Delta t} | X_t, x_0) = q(x_{t - v(x_{t-\\Delta t}, t) \\Delta t})$.\n$P_{\\theta}(x_{t-\\Delta t}|x_t) = p(x_{t - V_{\\theta}(x_{t-\\Delta t}, t) \\Delta t})$.\nTo make sure that we have a true trajectory in the reverse process, a network should be trained to solve the following optimization problem:\n$\\theta = arg min_{\\theta} \\{ l_1 ( v(x_t, t), v_{\\theta} (x_t, t) ) \\}$,\nwhere $l_1$ denotes the loss function and $\\theta$ refers to the network\u2019s parameters. Finally, the reverse process is done as follows:\n$X_{t-\\Delta t} = X_t \u2013 v_{\\theta}(x_{t-\\Delta t}, t) \\Delta t$.\nIt is worth noting that because there is no stochastic factor in the reverse process, and also our network does not have any randomness factor, the reverse process is considered a deterministic process."}, {"title": "C. Architecture", "content": "The overarching structure of the employed CNN is illustrated in Fig. 4, which is comprised of two primary modules called convolutional blocks and time embedding modules. The time embedding module is devised to allocate a vector to each time step $t$ through Sine and Cosine transforms, serving as informative cues for the network\u2019s temporal understanding. These time vectors are subsequently input into the convolutional blocks to provide temporal context. Within the convolutional blocks, the data stream incorporates an input tensor alongside the associated time vectors. Initially, the input tensor undergoes a 3\u00d73 convolutional layer, succeeded by batch normalization and ReLU nonlinearity layers. Simultaneously, the input time vector is processed through a linear layer to"}, {"title": "IV. EXPERIMENTS", "content": "This section provides details regarding the evaluation procedure for the proposed method. We begin with an overview of the datasets, followed by an explanation of the data generation sequences and the inclusion of test images. Subsequently, we delve into the evaluation metrics and then elaborate on the training strategy and comparison results."}, {"title": "A. Dataset", "content": "In this study, the proposed network was trained using a simulated dataset. We leveraged both phantom and in vivo data for evaluation, supplementing the simulated test data.\n1) Simulated data: The simulated dataset, which consists of 400 images, was simulated using the publicly available Field II package [54] [55]. The designed phantom, situated at an axial depth of 10 mm from the transducer\u2019s face, measures 45 mm laterally and 40 mm axially and contains a uniform distribution of fully developed speckle patterns, with an average scatterer density of 60 per resolution cell. Two different types of contrast were introduced to the images, including anechoic regions and hyperechoic regions. To create the two echogenicity types and similar to [28], we utilized a public dataset called XPIE [56], which contained segmented natural images. We isolated only the segmentation masks and resized them to match the dimensions of the phantoms. Subsequently, we applied a weight to the amplitude of scatterers within the masks, determined by the echogenicity type of each image. For anechoic regions, the weight was set to zero. For hyperechoic"}, {"title": "B. Evaluation metrics", "content": "We use key metrics like Contrast to Noise Ratio (CNR) and Generalized Contrast to Noise Ratio (gCNR) [58] for quantitative evaluation. In addition, because our goal is enhancing the image quality using a high-quality image as the target, we should investigate how much our method can get the input image closer to the target image. To do so, we measure the similarity between the output images and their corresponding high-quality image utilizing Normalized Root Mean Squared Error (NRMSE).\n1) The CNR index is calculated as follows:\n$CNR = 20 log_{10} ( \\frac{|\\mu_{ROI} - \\mu_{B}|}{\\sqrt{(\\sigma^2_{ROI} + \\sigma^2_B)/2}} )$,   \t\t(26)\nwhere $\\mu$ and $\\sigma$ point to the mean and standard deviation of both background and region of interest, respectively.\n2) It has been proved that CNR depends on dynamic range alternation [59], and gCNR was introduced to mitigate this problem. The corresponding formula for gCNR calculation is:\n$gCNR = 1 - \\int_{-\\infty}^{+\\infty} min\\{P_{ROI}(x), P_B(x)\\}dx$,   \t\t(27)\nwhere $p_B$ and $P_{ROI}$ points to the histogram of the background and region of interest, respectively. The gCNR metric quantifies the extent of overlap between the pixel intensity distributions in two regions, considering dynamic range transformations. A higher gCNR value signifies reduced overlap between the distributions, reaching a maximum value of 1 when the two distributions exhibit no overlap.\n3) NRMSE: The Euclidean distance, renowned alongside the Mean Squared Error (MSE), stands as one of the most prevalent metrics employed for assessing the similarity between two vectors. However, when evaluating diverse methods across disparate datasets characterized by specific dynamic ranges, computing the general MSE may fail to provide a comprehensive understanding of the enhancement potential. Therefore, normalization is employed to scale distances within the range of [0, 1] across all test sets. For an image denoted as $I$ and a corresponding target $Y$, comprising $L$ elements, NRMSE can be calculated as follows:\n$RMSE = \\sqrt{ \\frac{1}{L} \\sum_{i=1}^L (I_i - Y_i)^2}$,\t\t(28)\n$NRMSE = \\frac{RMSE}{max(Y)}$,\t\t(29)\nNote that the denominator corresponds to the range of $Y$, as the minimum value of Y is zero.\n4) KS test: The Kolmogorov-Smirnov (KS) test in ultrasound, is a statistical method used to quantifies the differences between the cumulative distribution functions (CDFs) of pixel intensity values in the images, providing a measure of how well the processed image retains the characteristics of the original speckle pattern.\n5) SSIM: The Structural Similarity Index (SSIM) is a metric used to measure the similarity between two images. It takes into account three components of image quality: luminance, contrast, and structure. SSIM compares local patterns of pixel intensities in the images and computes a score between -1 and 1, where 1 indicates perfect similarity. Higher SSIM values suggest that the images are more similar in terms of quality."}, {"title": "C. Training", "content": "The architecture illustrated in Fig. 4 was employed to predict noise parameters at each time step. During the training phase, following the forward process, a high-quality beam-formed image undergoes degradation based on a randomly selected time step noise coefficient $\\beta_t$, where 1 < $t$ < T, as described in [10]. Subsequently, the network is exposed to the degraded image as input and its corresponding additive"}, {"title": "V. DISCUSSION", "content": "Our proposed method demonstrates superior performance when compared to existing supervised deep learning-based models in the context of PW ultrasound denoising. A key aspect contributing to this efficacy lies in our approach of breaking down the noise into smaller, more manageable segments. This strategic division aims to facilitate a more targeted and efficient learning process for the model by simplifying the distribution learning task. By breaking down the noise, our method can effectively capture and address specific characteristics, leading to enhanced denoising outcomes.\nWe conducted our training using extensive RF images, adhering to the constraints of the Nyquist rate, thereby preventing any downsampling. While this approach ensures a high-fidelity representation of the ultrasound data, it introduces a computational burden due to the large size of the data. However, in future investigations, there is potential to explore the utilization of in-phase and quadrature (IQ) images, which offer more flexibility in terms of downsampling without violating the Nyquist rate constraints. This avenue could potentially streamline computations while maintaining the essential information required for effective PW ultrasound denoising.\nThe versatility of our formulation can be extended beyond its application on PW ultrasound denoising because we only trained the model using simulation data, and the method performed well in real phantom and in-vivo data. In other words, since generating simulated data is generally less expensive than performing real experiments, the method can be trained for other types of ultrasound imaging. This includes, but is not limited to, focused and synthetic aperture imaging, broadening the scope of its applicability across different ultrasound modalities. Moreover, our method is not confined to a specific type of ultrasound transducer; it can seamlessly be employed with diverse transducer configurations, such as convex and phased array transducers (granted that new simulated data is generated and the network is fine-tuned on the new data). This adaptability underscores the robustness and generalizability of our approach, making it a promising candidate for enhancing image quality and denoising capabilities across a spectrum of ultrasound imaging modalities and transducer types.\nDeep learning models often show brittleness; although they provide good results for certain inputs, they can generate subpar results for others. Therefore, more experiments on simulated, real phantoms and in-vivo data are needed to ensure good performance in a large test database.\nIn future investigations, we plan to delve into the potential impact of the RF data denoised through our method on downstream tasks, with a specific focus on ultrasound elastography [61], [62]. This line of inquiry aims to explore whether the enhanced denoising capabilities of our method translate into improved performance and accuracy in subsequent higher-level applications, such as elastography. In addition, reducing the processing time can be one of the prospective studies. The running time can be further improved using knowledge distillation and pruning to achieve real-time performance.\nWhile our method exhibits notable superiority over other approaches in the in vivo test images, there remains a potential for further validation and improvement. Acknowledging this, our next research endeavor will focus on refining our network by incorporating additional in vivo data. The intention is to fine-tune the model, leveraging an expanded dataset to enhance its adaptability and performance, specifically in real-world scenarios. This proactive approach to data collection and model refinement reflects our commitment to continuous improvement, ensuring that our method evolves to deliver even more impressive results in the dynamic and complex conditions encountered in in vivo ultrasound imaging.\nSimilar to [18], [19] and [20], the output of our model is not stochastic and is deterministic for a given input. In contrast to conventional diffusion models like [1], [16], [50], which are trained using only high-quality images, our method is trained on pairs of low/high-quality images to learn the process of transforming a low-quality image into a high-quality one. Therefore, if we start from a determined point (in our case, one PW) and pass through a deterministic process, knowing that the network does not have any randomness in the inference phase, the network returns the same output.\nIn this work, we did not use any stochasticity in the diffusion model and, therefore, did not take advantage of good mode convergence of these models. One idea for future work can be incorporating stochasticity with the proposed method model so that multiple plausible 75-PW compounded images can be reconstructed from a single sonification. This can ultimately help the clinicians using the technology by allowing inspection of different possible reconstructions. In other words, if different high-quality reconstructions are very different and can change clinical decision-making, the input of the diffusion-based reconstruction can be augmented with additional steering angles to narrow down the diverse set of modes, or alternatively, the full 75 steering angles can be collected to eliminate ambiguity."}, {"title": "VI. CONCLUSION", "content": "This paper proposes a denoising method in ultrasound PW imaging based on DDPMs. Our method was solely trained on a small dataset comprising of 400 simulated images, and performs well on simulation, real phantom as well as in vivo data in the test phase. Diverging from traditional methodologies that simulate circular anatomies in data generation, our approach utilizes natural image segmentation masks as intensity maps for the simulated images. As a result, the proposed method showcases the ability to extend the denoising task to diverse anatomical shapes."}]}