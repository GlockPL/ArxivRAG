{"title": "Exploring Domain Shift on Radar-Based 3D Object Detection Amidst Diverse Environmental Conditions", "authors": ["Miao Zhang", "Sherif Abdulatif", "Benedikt Loesch", "Marco Altmann", "Marius Schwarz", "Bin Yang"], "abstract": "The rapid evolution of deep learning and its integration with autonomous driving systems have led to substantial advancements in 3D perception using multimodal sensors. Notably, radar sensors show greater robustness compared to cameras and lidar under adverse weather and varying illumination conditions. This study delves into the often-overlooked yet crucial issue of domain shift in 4D radar-based object detection, examining how varying environmental conditions, such as different weather patterns and road types, impact 3D object detection performance. Our findings highlight distinct domain shifts across various weather scenarios, revealing unique dataset sensitivities that underscore the critical role of radar point cloud generation. Additionally, we demonstrate that transitioning between different road types, especially from highways to urban settings, introduces notable domain shifts, emphasizing the necessity for diverse data collection across varied road environments. To the best of our knowledge, this is the first comprehensive analysis of domain shift effects on 4D radar-based object detection. We believe this empirical study contributes to understanding the complex nature of domain shifts in radar data and suggests paths forward for data collection strategy in the face of environmental variability.", "sections": [{"title": "I. INTRODUCTION", "content": "With the rapid development of deep learning technology, various sensors are utilized to optimize autonomous driving systems. Data inputs such as camera images and lidar-generated point clouds are commonly integral to modern advanced 3D perception systems. While using a deep learning-based model with the input of a camera and lidar point cloud can achieve significant perception results [1], [2], these systems still face challenges related to illumination, adverse weather conditions, and high cost [3]. In contrast, radar sensors offer a more robust signal at an acceptable cost under such conditions. Additionally, the latest 4D radar not only provides high-resolution range and velocity information but also includes azimuth and elevation angle data. Considering its advantages, radar sensors are increasingly recognized as a promising avenue in the 3D perception field.\nAlthough radar signals are relatively robust under adverse weather conditions compared to optical-based signals (lidar and camera), their features can still vary with different environmental conditions [4], [5]. Research has shown that most radar datasets are collected under normal weather conditions [6]. A model trained solely on these datasets may yield unreliable predictions under different weather conditions, as shown in Fig. 1. This phenomenon is known as \"domain shift\" in the machine learning field: it occurs when a model trained on one set of data (the source domain) encounters different data distributions (the target domain), potentially reducing its performance. For an open-world task such as autonomous driving, it is crucial to know if a considerable domain shift happens and utilize domain adaptation methods to solve that accordingly. Recent studies have begun to address the impact of domain shift on 3D object detection, primarily focusing on lidar sensors [7], [8]. However, the specific effects of domain shift on radar object detection remain less explored, especially given the unique characteristics of radar sensors.\nIn this paper, we conduct a comprehensive empirical study into the effects of domain shift on 4D radar-based object detection across various environmental conditions, including different weather scenarios and road types. Our research demonstrates that domain shifts occur consistently under various weather conditions, although their impacts vary significantly across different datasets. This emphasizes the crucial role of generating radar point clouds. Additionally, we found that neither different network architectures nor increasing the size of datasets substantially mitigates the impact of weather-related domain shifts, highlighting the importance of domain adaptation techniques. We also observed domain shift effects when transitioning between different road types, particularly from highways to urban settings. This underscores the importance of gathering a diverse range of data from various road environments to enhance the effectiveness of radar-based 3D object detection."}, {"title": "II. RELATED WORK", "content": "A. Weather Effect on Radar Signals\nThe radar sensor transmits electromagnetic waves and captures the reflected signal to determine the range, angle, and velocity information of the target. Compared to lidar, radar is more robust in adverse weather conditions, given the relatively long wavelength. Nevertheless, there are still some challenges like interference, attenuation, and backscattering, which can degrade the quality of the signal: Courova et al. [9] studied the impact of rain on the performance of automotive radar, showing that the attenuation and clutter during rain can reduce target detectability. The weather effect on radar signals was also mentioned in a recent work [4]: the precipitation condition (e.g., rain and snow) can have a significant impact on the signal, whereas conditions with airborne particles (e.g., dusty storm and smoke) have minimal effect on the radar signals. Most of this research focuses on the characteristics of radar signals, with less emphasis on the performance gap in deep learning-based perception. From a deep learning perspective, RADIATE [10] addresses domain shifts in adverse weather conditions, but it is constrained by an inconsistent and limited dataset size and only offers 2D evaluation. Unlike previous works, our study aims to conduct a comprehensive analysis of domain shifts for 4D radar-based object detection across various weather conditions.\nB. 4D Radar Datasets\nThe most recent 4D radar sensor provides additional elevation angle information, enriching the traditional 3D data (range, velocity, and azimuth angle) previously available from its predecessors. Given the improved angular resolution and range capabilities, 4D radar sensors are garnering increasing interest in autonomous driving. However, the availability of comprehensive open-source 4D radar datasets remains limited. Common datasets in 3D object detection, like Waymo [11] and KITTI [12], only provide lidar point clouds. Additionally, datasets like NuScenes [13], CRUW [14], and RADIATE [10] offer radar point clouds captured by 3D radar sensors. Astyx was the first to provide high-resolution 4D radar point clouds, but its dataset size is quite limited [15]. Since then, several 4D radar datasets have been released, but they are not very suitable for domain shift investigations due to a lack of abundant data from various weather conditions and diverse scenes, such as VOD [16], TJ4RAD [17], and aiMotive [18]. Recently, a 4D radar dataset named K-Radar, which includes data from different adverse weather conditions, was published [6]. It contains over 35k frames from 58 recordings, capturing data across seven types of weather conditions.\nC. Domain Shift on 3D Object Detection\nDomain shift has been extensively researched in various tasks, such as semantic segmentation [19], image classification [20], and 2D object detection [21]. Beyond camera sensors, pioneering works have also explored 3D object detection with lidar sensors. For instance, Vattem et al. [7] examined the domain shift effect in adverse weather conditions, demonstrating that a model trained in clear weather can achieve competitive results in adverse conditions. Wang et al. [22] highlighted geographic domain shift by training a model on data from Germany and testing it on data from the USA. A recent empirical study [8] provided a comprehensive analysis of lidar 3D object detection, considering factors such as model architectures, location domains, and weather domains, showing that training on clear weather samples yields more robust results than training on adverse weather samples. However, the impact of domain shift varies significantly across different sensors, suggesting that findings specific to lidar may not be directly applicable to radar sensors. To our knowledge, we are the first to study the domain shift impact on radar 3D object detection. In this paper, our research will focus exclusively on environmental conditions like weather and road type. Other aspects, such as model structure or sensor type domain gaps, are beyond the scope of this study."}, {"title": "III. METHODOLOGY", "content": "A. Dataset\nAs mentioned in Sec. II-B, most public 4D radar datasets are unsuitable for investigating environmental domain shifts. However, in this study, we will use one suitable public dataset along with a self-collected dataset to conduct a comprehensive analysis. Detailed information about the datasets is provided below, with specific data outlined in Table I:\n\u2022 K-Radar dataset [6]: This dataset was collected in South Korea using a single 4D radar sensor. It includes point clouds from seven different weather conditions: Normal, Rain, Heavy Snow, Light Snow, Overcast, Sleet, and Fog, with over 35k frames in total. The original K-Radar dataset has a default splitting configuration where the training and test sets contain frames from the same recordings, potentially leading to biased validation outcomes due to the short duration of the recordings and similarity of the frames. To address this, we re-split the dataset to ensure no recording overlap between the training and test sets. This approach prevents any bias and ensures a more reliable evaluation of domain shift. Additionally, we maintained the same dataset size for different settings to allow for fair comparison. The training set now consists of 27,024 frames, while the test set includes 7,970 frames, covering all adverse weather conditions.\n\u2022 Bosch-Radar dataset: In addition to evaluating a public dataset, we conducted experiments on a private dataset, referred to as the Bosch-Radar dataset. As shown in Table I, this dataset is significantly larger than the K-Radar dataset, containing over 180k frames collected from eight different cities in Germany over 27 days (19 days in the training set and 8 in the test set). Using five 4D radar sensors at the front view, we acquired high-quality radar point clouds. Our dataset includes three weather conditions (Normal, Overcast, and Rain) and three types of road environments (Urban, Rural, and Highway). To examine the domain shift effect\nB. Implementation Details\nTo conduct a comprehensive study, we validate the domain shift effect using two representative 3D object detectors, RTNH [6] and SECOND [23], on the aforementioned datasets. Our approach involves training the models with data from different domains and validating them on a fixed test set. To ensure a fair comparison for weather condition experiments, we maintain an identical number of training frames. Specifically, we use the bottleneck value of 8,764 frames from the normal samples as the training set size for each scenario in the K-Radar dataset (normal weather and all-weather data). For our Bosch-Radar dataset, we organize the data into three different scales, as previously mentioned. For road-type experiments, we maintain a consistent number of objects (200k) to account for variations in the average number of objects across different road types. For instance, there is an average of 8.12 sedans per frame in urban recordings, compared to only 4.10 per frame on highways in the Bosch-Radar dataset.\nThe models are implemented using the OpenPCDet framework [24] and PyTorch. In line with K-Radar [6], we utilize the AdamW optimizer and Cosine Annealing learning rate scheduler. Detection performance is measured using the $AP_{3D}$ and $AP_{BEV}$ metrics from the KITTI dataset [12]. We run each experiment three times on a NVIDIA A100 GPU, and the mean value along with the standard deviation is reported in the form of mean \u00b1std.\nBy observing the performance gap across different domains, we can determine whether a domain shift exists, as illustrated in Fig. 2. For example, if a model trained on the source domain s performs similarly in the target domain t as a model trained on the target domain, we can conclude that there is no significant domain shift from s to t, or that the two domains substantially overlap. It is important to focus primarily on comparing the performance gaps in the target domain between models trained on different domains, rather than on the absolute performance of each model.\nAssuming a model trained on domain s yields a validation score of $S_{s\u2192t}$ (e.g., Average Precision) when tested on domain t and a score of $S_{ss}$ when tested on domain s, the relationship between $S_{ss}$ and $S_{s\u2192t}$ alone does not necessarily indicate a domain shift from s to t. To confirm a domain shift, we need to compare the original performance on the target domain $S_{t\u2192t}$ with the shift performance $S_{s\u2192t}$. If $S_{t\u2192t}  S_{s\u2192t}$, then a domain shift occurs from s to t. Conversely, if $S_{t\u2192t} \u2248 S_{s\u2192t}$, then the two domains overlap significantly, or t is a subdomain of s."}, {"title": "IV. WEATHER DOMAIN SHIFT", "content": "A. Results on K-Radar\nOn the K-Radar dataset, we investigate the effect of weather domain shifts by comparing the results under two different settings: one model is trained exclusively on normal weather data, while the other is trained on a mixed dataset encompassing all seven weather conditions, with both datasets being of identical size. We follow a two-class object detection setting from the wide field of view (FOV) configuration of the original K-Radar, where one class is \"sedan\" and the other is \"bus or truck\". The evaluation results for two networks are concluded in Table II. Due to the non-overlapping split setting mentioned in Sec. III-A, the performance may be worse than reported in the original paper [6]. Our findings are detailed as follows:\n1. A significant domain gap is evident across five weather conditions: Rain, Heavy Snow, Light Snow, Sleet, and Fog. The snow scenario, in particular, exhibits the most severe performance degradation. Specifically, performance becomes invalid for the sedan class under heavy snow conditions according to the $AP_{3D}$ metric, and the performance drop in light snow exceeds 60%. An examination of the average power of the point cloud reveals that the average power in snow conditions is significantly lower than in normal weather conditions, as shown in Fig. 3. This reduction in power may be attributed to sensor blockages caused by ice or snow. For the bus or truck class, the two models fail under heavy snow and sleet conditions when trained only in normal weather. One possible reason is the difference in average power. Another reason could be that the bus or truck class is more challenging to detect than the sedan class due to the larger size of the objects and fewer samples. For other precipitation conditions, such as rain and sleet, the domain shift effect is still very noticeable for both models. This may be due to the cluttering and backscattering effects, which should be effectively addressed.\n2. Performance under overcast conditions is not severely affected by these weather domain variations. Notably, the two normal-trained models outperform the mixed-trained model on the overcast test data, especially the SECOND model for bus or truck class, indicating a considerable domain overlap between normal and overcast weather conditions. This phenomenon also aligns with our understanding, where the illumination conditions have a minimal impact on millimeter wave propagation.\n3. Comparing the effects on the two networks, we observe that although performance may vary, both experience the same domain shift effect. When a domain shift occurs in one network, it also occurs in the other. This demonstrates that the domain shift effect related to weather conditions is quite model-agnostic and should be addressed accordingly.\nB. Results on Bosch-Radar Dataset\nAs introduced in Sec. III-A, the Bosch-Radar dataset is considerably larger than the K-Radar dataset. We utilize this dataset to investigate the domain shift effect across three weather conditions: normal, overcast, and rain. Following the protocols established with K-Radar, we conduct a two-class object detection task using the same two networks. For clarity, the results on 60k scales are visualized in Fig. 4. The key findings are listed below:\n1. When examining the rain performance, we notice a significant domain shift effect from rain to normal and overcast conditions: For example, on RTNH model, there is a decrease of 7.4% in $AP_{3D}$ under normal conditions and a 7.1% decrease in $AP_{BEV}$ under overcast conditions for class sedan comparing the rain-trained model with the source domain-trained models. Conversely, models trained under normal or overcast conditions still adapt well to rain patterns: the results are slightly better than the rain-trained model in terms of $AP_{BEV}$ and better, by around 6%, in $AP_{3D}$. This aligns with observations from lidar domain research [8], which shows that normal weather-trained data can already give competitively strong results in adverse weather conditions.\n2. The model trained on a mixture of datasets does not exhibit any superiority compared to models trained with other data sets, despite the increased diversity of its training inputs. We can tell from the figure that all the results from mixed-trained models have competitive or worse results than the normal/overcast-trained models. This observation is consistent with findings from lidar-related research [7]. Based on the observation here, we claim that the superiority of multi-domain over single-domain [25] is not applicable to the weather domain shift problem.\n3. Solely increasing the dataset size may not effectively mitigate the effects of domain shift. This observation is based on comparisons among models trained with 60k, 20k, and 10k samples. The impact of weather domain shifts appears consistent (as shown in Fig. 5). Models trained on data from rainy conditions consistently performed worse than other models. Additionally, the domain gap remained uniform for both classes. This observation suggests that solely increasing the size of the dataset may not effectively mitigate the effects of domain shift from rain to normal. Though acquiring normal weather data is easier than rain data, investigating this issue for model behavior insights is still valuable.\nC. Comparison\nBy comparing the domain gaps in the two datasets, we find that weather domain shift effects vary between different datasets. As discussed in the previous two subsections, the impacts of domain shifts on the K-Radar and Bosch-Radar datasets differ significantly. Except for overcast conditions, all other adverse weather scenarios in the K-Radar data experience significant domain shift effects. In contrast, the Bosch-Radar data only exhibits adverse effects when transitioning from adverse to favorable weather conditions. Remarkably, models trained on favorable weather data often outperform those trained on adverse weather data.\nPotential reasons for these variations are as follows: First, the K-Radar dataset may not be sufficiently representative due to its mid-size. Second, and crucially, unlike lidar, which directly obtains point clouds from the sensor, the point clouds from the radar are derived through signal processing on spectrum data. The point cloud can significantly differ due to the sensor type and processing techniques. Here, the two datasets are using different methods to generate their point clouds: The method of K-Radar only selects the top k% highest power point from the 4D radar cube and then converts them into the Cartesian coordinates as 3D points with the power value. Our Bosch-Radar data uses a peak detection method, such as CFAR [26], to select relevant points. As a result, the point cloud distribution from the two datasets can be significantly different, which may cause a different domain shift effect. The disparity in our results indicates that the domain shift effect in radar data is highly specific to the datasets and is not universally applicable across all datasets."}, {"title": "V. ROAD DOMAIN SHIFT", "content": "In this section, we explore the impact of domain shift across various road types. Our experiment utilizes the Bosch-Radar dataset due to the large scale. Considering the varying numbers of objects in different road conditions mentioned in Sec. III-B, we use the same number of objects rather than frames across all subsets and focus exclusively on detecting a single class: \"sedan\". The results are shown in Table III. We trained the model on four different road conditions: only urban, only rural, only highway, and a mix of all three types. The test set is fixed-chosen, containing all three different road types. Based on the result, we discover that:\n1. A unidirectional domain shift from highway to urban/rural occurs. The performance of the model trained on highway data significantly decreased in urban areas (-8.65% $AP_{BEV}$/ - 8.33% $AP_{3D}$) and by approximately 5% $AP_{3D}$ in rural areas. Conversely, the model trained on urban/rural data performs competitively in highway scenarios. Generally, the urban/rural environment is more complex than highways due to differences in traffic density and environmental context (such as buildings and roadside facilities).\n2. The urban-trained model underperformed on rural data, showing a drop of -5.82% $AP_{3D}$ compared to the rural-trained model. We hypothesize that the robustness of the rural-trained model across all conditions is due to its intermediate nature, incorporating both built-up areas like townships and sparse scenes like rural roads. Rural driving behavior is also more varied than in urban or highway settings. For instance, in Germany, the speed limit in urban areas is typically 50 km/h, while in rural areas, it can range from 50 km/h to 100 km/h. This diverse training data likely enhances the model's generalization ability and robustness, aligning with our observations."}, {"title": "VI. LIMITATIONS", "content": "While the study is detailed and comprehensive, it is not without limitations. First, as an empirical study, our conclusions are based on analyzing experimental results. However, a theoretical analysis of domain shift under varying environmental conditions still needs further research. Second, although our dataset is large-scale, it lacks data on highly adverse weather conditions, such as snow, which are also scarce in K-Radar. These conditions warrant further investigation. Additionally, our study specifically focuses on environmental domain shifts involving radar point cloud data and does not cover behavior in radar spectrum data. Other critical factors, such as sensor type, also play an essential role in practical applications and should be explored."}, {"title": "VII. CONCLUSION", "content": "This paper presents an empirical study on the domain shift effect in radar-based object detection under diverse environmental conditions. We investigated this phenomenon using two datasets with various configurations, including weather conditions, road conditions, and dataset scales. Our findings reveal that domain shifts do occur across different weather conditions, with the effect varying between datasets. Additionally, we observed domain shifts between different road types, particularly from highways to urban areas.\nTo the best of our knowledge, our work is the first to investigate these effects within the context of 4D radar-based object detection. We hope our research will contribute to a deeper understanding of domain shifts in radar perception systems and provide valuable insights for optimizing data collection strategies. In future work, we will investigate domain adaptation techniques to address challenges posed by environmental variations."}]}