{"title": "Multi-Dimensional Reconfigurable, Physically Composable Hybrid Diffractive Optical Neural Network", "authors": ["Ziang Yin", "Yu Yao", "Jeff Zhang", "Jiaqi Gu"], "abstract": "Diffractive optical neural networks (DONNs), leveraging free-space light wave propagation for ultra-parallel, high-efficiency computing, have emerged as promising artificial intelligence (AI) accelerators. However, their inherent lack of reconfigurability due to fixed optical structures post-fabrication hinders practical deployment in the face of dynamic AI workloads and evolving applications. To overcome this challenge, we introduce, for the first time, a multi-dimensional reconfigurable hybrid diffractive ONN system (MDR-HDONN), a physically composable architecture that unlocks a new degree of freedom and unprecedented versatility in DONNs. By leveraging full-system learnability, MDR-HDONN repurposes fixed fabricated optical hardware, achieving exponentially expanded functionality and superior task adaptability through the differentiable learning of system variables. Furthermore, MDR-HDONN adopts a hybrid optical/photonic design, combining the reconfigurability of integrated photonics with the ultra-parallelism of free-space diffractive systems. Extensive evaluations demonstrate that MDR-HDONN has digital-comparable accuracy on various task adaptations with 74\u00d7 faster speed and 194\u00d7 lower energy. Compared to prior DONNS, MDR-HDONN shows exponentially larger functional space with 5\u00d7 faster training speed, paving the way for a new paradigm of versatile, composable, hybrid optical/photonic AI computing. We will open-source our codes.", "sections": [{"title": "I. INTRODUCTION", "content": "Emerging technologies promise efficiency and performance breakthroughs, and optical neural networks (ONNs) are at the forefront of this movement. They are poised to revolutionize next-generation AI computing by harnessing the inherent parallelism and speed of light. Diffractive ONNS (DONNs) [1], [2], [3], [4], [5] represent a compelling realization of optical AI hardware, employing free-space optical signal modulation, diffraction, and interference to achieve ultra-parallel intelligent information processing. Different from integrated photonic tensor cores (PTCs) [6], [7], [8], [9], [10], [11], [12] based on programmable photonic integrated circuits (PICs) designed for matrix-vector multiplication, free-space DONNs eliminate the dimension limitations of 2-D silicon chips and operate directly on light waves in 3-D free space, offering unprecedented parallelism through a global-view spatial linear operation.\nHowever, DONNs face a significant challenge in their lack of re-configurability after fabrication. The fixed manufactured phase masks limit their adaptability to new ML tasks, hindering their deployment in real-world rapidly changing AI workloads [13], [14]. While research into reconfigurable phase masks based on tunable metasurfaces shows promise, these approaches remain in the immature stages. They struggle with limitations such as low endurance and reliability, which make them unsuitable for adoption in the near term.\nTo circumvent this device-level restriction, we shift our focus to the system architecture level. Optical systems offer intrinsic adjustable variables-like light wavelength, phase mask spacing, and element size that impact system transmission but remain largely unexplored. These variables are often manually adjusted based on designer experience, raising the question: can these built-in hardware variables be automatically optimized for better expressivity? However, for true task adaptation, adjusting these scalar variables alone lacks sufficient degrees of freedom. A fundamental system redesign is needed to enable the necessary reconfigurability. In this work, we address this challenge: how to construct a versatile DONN system with exponentially many reconfigurable functionalities by re-purposing the same set of fabricated phase masks? Furthermore, considering the strengths and weaknesses of both diffractive ONNs and integrated PTCs, we explore how to hybridize free-space optics and integrated photonics organically to leverage both the ultra-parallel processing capability of DONNs and the superior reconfigurability of integrated PTCs for joint neural network acceleration.\nTo answer those questions, we investigate the intrinsic learnability of DONNs from the system level and propose a multi-dimensional reconfigurable hybrid DONN design, dubbed MDR-HDONN, with a physically composable architecture that can flexibly switch the orientation and placement order of phase masks for exponentially larger functional space. The main contributions are as follows,\n\u2022 We present the first in-depth analysis of multi-dimensional learn-ability in DONNs, introducing a physically composable hybrid optical system MDR-HDONN for extreme multi-functionality.\n\u2022 Auto-Learned Multi-Dimensional System Variables: we enable differentiable learning of DONNs across multiple dimensions (wavelength, spacing, orientation, permutation), unlocking an exponentially larger functional space with enhanced expressivity.\n\u2022 Hybrid Optical/Photonic System: Our design synergistically in-tegrates free-space diffractive optics and reconfigurable integrated photonics, leveraging the strengths of both technologies for joint NN acceleration.\n\u2022 Superior Task Adaptability: Extensive evaluations show that our system and differentiable learning algorithms enable digital-comparable task adaptation performance with 74 \u00d7 faster speed and 194\u00d7 lower energy, outperforming prior DONNs with expo-nentially higher functional space and 5\u00d7 higher training efficiency."}, {"title": "II. BACKGROUND", "content": "A. Diffractive Optical Neural Networks (DONN)\nAs shown in Fig. 1, the main trainable parameters are the modulation weights on the phase mask, i.e., $\\Phi \\in \\mathbb{R}^{K \\times K}$, where the phase shift of one unit cell is $\\phi_{i,j} \\in [0, 2\\pi)$. When incident light $X$ passes through the phase mask, it applies pixel-wise phase rotation, i.e., $e^{i \\Phi} \\odot X$, where $\\odot$ is element-wise multiplication. Typically, to increase the number of trainable parameters, a DONN will have multiple cascaded phase masks, e.g., $L$ layers [15]. Between two phase masks, the coherent light will propagate in the free space with diffraction. This can be described using the Rayleigh-Sommerfeld diffraction, a dense linear transformation where each light on the output plane is the superposition of all light from the input plane with a distance-related intensity/phase modulation coefficient $h$. The transmission, including a phase mask and diffraction, is denoted as $X_{l+1} = H(e^{i \\Phi_l} \\odot X_l)$, formulated as [16]:\n$X_{l+1}(k_{x}^{l+1}, k_{y}^{l+1}) = \\sum_{k_x} \\sum_{k_y} h(R, z, \\lambda) \\cdot e^{i \\Phi_l(k_x, k_y)} X_l(k_x, k_y)$,\n$h(R, z, \\lambda) = \\frac{-jk}{2\\pi} \\frac{e^{jkR}}{R}$,\n$R = \\sqrt{((k_{x}^{l+1} - k_x^l) \\cdot s)^2 + ((k_{y}^{l+1} - k_y^l) \\cdot s)^2 + z^2}$,\nIn the diffraction coefficient $h$, $k = \\frac{2\\pi}{\\lambda}$ is the wave vector in free space, and $\\lambda$ is the wavelength, and $z$ is the distance between two adjacent layers, $j = \\sqrt{-1}$. $R$ is the spatial distance from the unit cell located at $(k_x, k_y)$ in the $l$-th layer to the unit cell located at $(k_x^{l+1}, k_y^{l+1})$ in the $(l + 1)$-th layer. $s$ is the pixel size of the phase mask unit cell.\nAs nanofabrication technology advances, a promising approach to implement DONN is using a sub-wavelength metasurface. Metasur-faces offer a compact solution, where each unit cell is called a meta-atom and consists of sub-wavelength nanostructures [2], [17], [18]. A typical meta-atom is a rectangular nano-pillar with precisely defined width, length, and thickness to achieve a specific phase shift, in Fig. 1. This structure is polarization-dependent and thus can induce independent phase changes in orthogonal light polarizations, e.g., $\\phi_x$ for x-polarized and $\\phi_y$ for y-polarized light. This is the foundation of our polarization-differential computing technique introduced later.\nB. Integrated Photonic Tensor Cores\nA different approach to implementing ONNs is through photonic tensor cores (PTCs). Unlike DONNs, where key components are passive diffractive components, PTCs integrate photonic devices to actively modulate light to achieve high-speed matrix-vector multipli-cation (MVM) [6], [19], [20], [21], [11], [9], [10], [22]. DONNs are more natural for ultra-parallel low-energy spatial processing, while integrated PTCs are more suitable in generic reconfigurable MVMs. This indicates complementary capabilities between two hardware platforms for joint computing."}, {"title": "III. RELATED WORKS", "content": "Previous works have proposed solutions to build multi-functional DONNs. For instance, prior methods have introduced rotation into diffractive neural networks, enabling certain layers to be rotatable and thereby enhancing task adaptability [13], [14]. Prior work [18] also explored training different tasks on separate regions of the diffractive layer. This approach suffers from area limitations, constrained to a limited number of fixed functions (e.g., 2-3). Similarly, metasurface-based DONNs [17] leverage polarization-dependent phase responses"}, {"title": "IV. PROPOSED HYBRID DIFFRACTIVE OPTICAL NEURAL NETWORK MDR-HDONN", "content": "We introduce a hybrid DONN with multi-dimensional reconfig-urability and physical composability, dubbed MDR-HDONN, shown in Fig. 2. Delving into the learnability of system-level parameters, our MDR-HDONN brings new degrees of freedom to overcome the long-lasting reconfigurability limitations of traditional DONNs, enabling superior task adaptability and training efficiency.\nA. Overview of Learnable System Parameters\nFor a generic expressive DONN, our MDR-HDONN is assumed to have a multi-path architecture with $P$ parallel paths, each with $L$ cascaded phase masks, shown in Fig. 2. We summarize programming mechanisms and properties of all learnable variables in our MDR-HDONN architecture in Table I, including the conventional parameter phase masks $\\Phi$, and our 7 newly introduced dimension-alities: light source wavelength $\\lambda$, meta-atom pixel size $s$, diffraction distance between metasurfaces $z$, metasurface orientation $O$, metasurface placement ordering $P$, pre- and post-channel-mixing factor $\\alpha_{pre}$ and $\\alpha_{post}$, and differential polarization combining factor $\\beta$, visualized in Fig. 2.\n1) Phase Masks $\\Phi$: Phases are the most important learnable parameters in DONN. Adjusting the rectangular meta-atom width and length can independently change its polarization-dependent phase responses $\\phi_x, \\phi_y \\in [0, 2\\pi)$ for x-polarized and y-polarized light. Once a phase mask is trained and fabricated, it is fixed and cannot be reconfigured for task adaptation.\n2) Light Source Wavelength $\\lambda$: Tuning wavelengths can effectively change the optical system response. Given a broadband meta-atom, its phase response $\\delta$ is almost constant within a wide spectral range. Changing wavelength, instead, mainly impacts the diffraction function $H(\\cdot, \\lambda)$. A reasonable range for $\\lambda$ is from 400 nm visible spectrum to infra-red 1600 nm. Given a preferred $\\lambda$, e.g., 532 nm, we consider local fine-tuning with $\\pm20$nm linewidth given the tunability of the current laser with a 0.1 nm tuning resolution.\n3) Meta-Atom Pixel Size $s$: The diffraction operator $H(\\cdot)$ is a function of pixel size $s$, which is the period of the metasurface grid. Considering all metasurfaces have a shared scalar pixel size $s \\in \\mathbb{R}$, e.g., 300 nm, we are allowed to freely determine this variable during the initial design stage for better performance. The pixel size is lower-bounded by the meta-atom width required to realize $2\\pi$ phase response plus minimum manufacturable linewidth, e.g., $s > \\max(\\frac{\\delta_{2\\pi, \\lambda_0} \\cdot \\lambda / \\lambda_0 + \\Delta s, w_{min})$. For example, given a reference $\\lambda_0=532$ nm, the meta-atom width needs to be $\\delta_{2\\pi, \\lambda_0}=180$ nm to realize $2\\pi$ phase shift, then we assume a linear scaling w.r.t. $\\lambda$. With a $\\Delta s=20$ nm gap between pixels, the pixel period needs to honor the constraint $s > 200$ nm.\n4) Metasurface Spacing $z$: The spacing between two phase masks determines the diffraction behavior of the light, i.e., $H(z)$. Intuitively, a very close distance passes the light directly to the next metasurface with very weak diffraction and cross-pixel interference. Then, the system becomes almost a local linear operator with a nearly diagonal transfer matrix. An overly large spacing introduces all-to-all pixel interaction. However, most light spreads to spaces outside the next metasurface plane, which causes significant light energy and information loss, and the next metasurface ends up receiving a dim and blurred pattern. Hence, a carefully optimized diffraction spacing $z$ is critical to the receptive field and expressivity of the DONN. We explore a shared learnable spacing $z$ for all layers and independently adjustable spacings $(z_1, z_2, \\cdots, z_L)$ for different layers.\n5) Metasurface Orientation $O$: Before metasurface fabrication, the phase mask is freely optimized to realize arbitrary phase dis-tribution. After fabrication, the metasurface is fixed. Thanks to the physical composability of our MDR-HDONN design, the phase mask orientation becomes an additional degree of freedom to enrich the functionality while reusing the same piece of hardware, as shown in Fig. 3. The phase mask can be rotated in four angles, i.e., R0 (N), R90 (E), R180 (S), and R270 (W). Besides, as a bidirectional phase mask, a metasurface can also be horizontally flipped to introduce chirality, i.e., shine the light reversely through the metasurface. Then, we can augment to another 4 states: FN, FE, FS, and FW, shown in Fig. 3. Replacing the phase mask with an identity mask $\\Phi = 0$ is another allowable bypass state given the system flexibility, denoted as BP. Orientation reconfiguration can be implemented mechanically. Each metasurface can select its orientation out of 9 states, which gives exponentially many distinct hardware transmissions. For example, in a DONN with $P$ parallel paths, each with $L$ cascaded masks, there are $9^{PL}$ states.\nThough this approach might not be suitable for real-time frequent reprogramming, it is promising for less frequent task adaptation. It enables exponentially many new system responses for potential lifelong hardware reusing. Later, we will introduce how to learn the best state from discrete orientations in a differentiable way.\n6) Metasurface Placement Order $P$: To fully leverage the physical composability of our MDR-HDONN system, we further explore the location swapping of metasurfaces for extreme multi-functionality. Inspired by the concept of card shuffling, phase masks can be reordered and re-plugged to any valid slots. A permutation of all phase masks can be used to describe this placement ordering. In a $P \\times L$ multi-path DONN, the total permutation reaches $(PL)!$, enabling an even larger design space than orientation.\n7) Differential Polarization Combining Factor $\\beta$: Polarization-multiplexed DONN [17] is previously demonstrated to map two tasks onto orthogonal polarization channels. Differently, we use two independent polarization directions in a differential fashion to enhance the linear operation expressivity and realize full-range outputs. Each forward pass through our MDR-HDONN system generates two non-negative outputs $Y_x$ and $Y_y$ for x(y)-polarized channel, respectively. We use balanced photodetection to obtain a full-range feature map $Y = \\beta Y_x - (1 - \\beta)Y_y$ with a non-negative combining factor $\\beta \\in \\mathbb{R}^+$. $\\beta$ is electronically implemented with low overhead and thus can be dynamically reconfigured in real-time.\n8) Pre/Post Channel-Mixing Coefficients $\\alpha_{pre}$ and $\\alpha_{post}$: Simu-lating such systems in a multi-channel DONN layer is time-consuming and memory-hungry. With $C_{in}$ input feature map channels and $C_{out}$ output channels, it requires to simulate the $P$-path MDR-HDONN system by $\\frac{C_{in} C_{out}}{P}$ times, which is not scalable. To make DONN training more scalable and efficient, we borrow the concept of depth-wise convolution, which performs spatial-only channel-wise diffractive projection without aggregating the computing results from $C_{in}$ channels. To enable channel-wise feature extraction, we add a channel-mixing coefficient $\\alpha_{pre}$ and $\\alpha_{post}$ before and after the metasurface DONN layer, same as point-wise convolution. The pre-channel-mixing layer projects the features from $C_{in}$-channel to $C_{mid}$-channel. The DONN system forwards $C_{mid}$ channels of images through the metasurface system and obtains $C_{mid}$ output channels, which are further fed into $\\alpha_{post}$ layer and projects to $C_{out}$ channels. As the channel-mixing operation only involves parallel MVM, it can be efficiently mapped to integrated PTCs for ultra-fast processing with real-time reconfigurability. By leveraging the ultra-parallel global-view spatial processing capability of diffractive optical systems and ultra-fast reconfigurable MVM power of integrated photonic accelerators, our hybrid optical-photonic MDR-HDONN system can realize highly adaptable and efficient optical computing. Meanwhile, this depthwise separable operation, with comparable expressivity to traditional multi-channel convolution-like DONN layers, significantly lowers the training cost of simulating diffractive layers."}, {"title": "V. EVALUATION RESULTS", "content": "A. Settings\n1) Model and Dataset: As a case study, we assume our MDR-HDONN system has up to 4 paths and up to 4 cascaded meta-surface layers. The DONN model backbone based on this hardware contains two Hybrid DONNBlocks. In all DONNBlocks, the depth-wise DiffLayers are mapped to the same MDR-HDONN hardware. All structural and mechanical parameters that cannot be switched in"}, {"title": "VI. CONCLUSION", "content": "We present the first in-depth analysis of multi-dimensional learn-ability in DONNs, introducing a physically composable hybrid op-tical/photonic system design, MDR-HDONN. Our results demonstrate that MDR-HDONN with multi-dimensional learnable system variables provides digital-comparable accuracy on various task adaptations, especially challenging PDE-solving tasks, with 74\u00d7 faster inference speed and 194\u00d7 lower energy. Compared to prior DONNs, our hybrid MDR-HDONN shows exponentially larger functional space and extreme multi-functionality with 5\u00d7 faster training speed. MDR-HDONN shows the potential to enable versatile and high-efficiency optical AI systems with repurposed hardware, paving the way for practical deployment in dynamic AI applications."}]}