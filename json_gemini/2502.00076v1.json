{"title": "Influence of color correction on pathology detection in Capsule Endoscopy", "authors": ["Bidossessi Emmanuel Agossou", "Marius Pedersen", "Kiran Raja", "Anuja Vats", "P\u00e5l Anders Floor"], "abstract": "Pathology detection in Wireless Capsule Endoscopy (WCE) using deep learning has been explored in the recent past. However, deep learning models can be influenced by the color quality of the dataset used to train them, impacting detection, segmentation and classification tasks. In this work, we evaluate the impact of color correction on pathology detection using two prominent object detection models: Retinanet and YOLOv5. We first generate two color corrected versions of a popular WCE dataset (i.e., SEE-AI dataset) using two different color correction functions. We then evaluate the performance of the Retinanet and YOLOv5 on the original and color corrected versions of the dataset. The results reveal that color correction makes the models generate larger bounding boxes and larger intersection areas with the ground truth annotations. Furthermore, color correction leads to an increased number of false positives for certain pathologies. However, these effects do not translate into a consistent improvement in performance metrics such as Fl-scores, IoU, and AP50. The code is available at https://github.com/agossouema2011/WCE2024.", "sections": [{"title": "1 Introduction", "content": "Digestive system diseases are widespread around the world and cause considerable distress which can be fatal. In 2019, about 2276.27 million estimated prevalent cases and 2.56 million deaths were counted for digestive system diseases [1]. Endoscopy is the procedure commonly used to visualize the gastrointestinal tract and detect diseases [2]. However, traditional endoscopy is uncomfortable and painful for patients [3], discouraging it for wider preventive screening programs. A new type of gastrointestinal endoscopy, known as Wireless Capsule Endoscopy (WCE) [4], was introduced in 2000, which is an alternative and minimally invasive screening method. In WCE, the patient swallows a pillcam (pill-sized camera) which moves through the gastrointestinal tract and records videos [5]. The whole process can take on average eight to twelve hours, generating around 60,000 frames [6]. Considering the long procedure duration, the demand"}, {"title": "2 Related works", "content": "Object detection has gained huge attention [11] and consists of identifying objects or instances of objects in an image or a video using bounding boxes. There are two main groups of object detection methods: one-stage detectors and two-stage detectors[12][13]. One-stage objects detectors train models using a large amount of ground truth data. i.e., accurate human-annotated data. They require only a single pass through the neural network and predict all the bounding boxes in one go. One-stage methods include You Only Look Once (YOLO) [14], and Single Shot Detector (SSD) [15]. The two-stage detectors on the other hand generate a set of regions of interest with a region proposal network, and then perform classification and bounding box regression. Popular two-stage models include Faster-RCNN [16] and Mask R-CNN [17].\nDing et al. [18] used a Convolutional Neural Network (CNN) based model to first classify WCE images into normal and abnormal frames, and further catego-"}, {"title": "3 Methodology", "content": "Motivated by the limited attention to localizing and detecting the pathology when color correction is applied using CC and CCC, we present a series of analysis in this work. We make use of the publicly available WCE SEE-AI dataset [10] and create two color corrected versions using CC and CCC [8]. As a result, we get two color corrected datasets. We then benchmark Retinanet and YOLOv5 models [22] on all the three datasets: the original SEE-AI, and the two color corrected, to understand the impact on pathology detection. We briefly present the WCE SEE-AI dataset [10] and relevant details of color correction. Further, we present our experimental set up and discuss relevant metrics used for analysis."}, {"title": "3.1 Dataset", "content": "SEE-AI Dataset: The SEE-AI dataset [10] is an annotated dataset for WCE with bounding box coordinates that contains 12 classes of small bowel pathologies. The images were collected with WCE PillCam SB-3 [23]. The dataset"}, {"title": "3.2 Experimental Protocols", "content": "Challenges faced by object detection methods with images include class imbalance [24,22] and multiple aspect ratios [25]. Class imbalance is when the dataset has only few labeled images for some classes, or when the spatial area of object of interest is smaller compared to the background. Multiple aspect ratios (aspect ratio imbalance) are when objects vary in aspect ratio with a variety of sizes: small, medium, and large objects with varying orientations[26]. These challenges make it difficult for object detection methods to achieve good detection results. Considering the nature of the dataset used for this analysis, we make use of Retinanet model as it is reported to have better performance under class imbalance problems due to incorporated focal loss [22]. To verify the consistency of our results, we also benchmark YOLOv5 with focal loss on our datasets. We further study each of the two models in three different settings that focus on pathology detection:\n1. Retinanet and YOLOv5 on SEE-AI Dataset (R-OrigD)\n2. Retinanet and YOLOv5 on the CCD (R-CCD)\n3. Retinanet and YOLOv5 on the CCCD (R-CCCD)"}, {"title": "3.3 Training and performance measures", "content": "For each case, we train each model using 80% of data and test with the remaining 20%. In addition, we ensured that both the training and testing sets have images"}, {"title": "4 Results and Discussion", "content": "The results of the models performance metrics on the test set are summarized in Tables 1-3 and Fig. 3-9. Classes such as diverticulum and foreign-body have been exempted from our analysis due to very few and non-diverse samples of the pathologies, that could potentially bias the results."}, {"title": "5 Conclusion", "content": "This work evaluates the impact of color on the performance of a deep learning model in wireless capsule endoscopy. We use the SEE-AI dataset, create two color corrected sets and benchmark Retinanet and YOLOv5 models on the three datasets. Given the metrics F1 scores, AP and IoU, the impact of color scheme variations on the performance of the object detection model is heterogeneous across different pathologies and color schemes, resulting in no consistent enhancement or deterioration of performance metrics. We further investigated the influence of the color correction on the number of False Positives and the detected bounding boxes. As results, the color corrections generate more false positives and larger intersection areas with the ground truth. However, we observed that the color corrections degrade the contrast of the images in WCE, suggesting that color correction could be most beneficial along with contrast adjustment for diagnostic purposes. This leaves room for future research to investigate more on integrating a color correction scheme with contrast enhancement into deep learning models to evaluate their performance for pathology detection in WCE."}]}