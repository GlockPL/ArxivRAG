[{"title": "I. INTRODUCTION", "authors": ["Mehran Shoushtari Moghadam", "Sercan Aygun", "M. Hassan Najafi"], "abstract": "Data encoding is a fundamental step in emerging computing paradigms, particularly in stochastic computing (SC) and hyperdimensional computing (HDC), where it plays a crucial role in determining the overall system performance and hardware cost efficiency. This study presents an advanced encoding strategy that leverages a hardware-friendly class of low-discrepancy (LD) sequences, specifically powers-of-2 bases of Van der Corput (VDC) sequences (VDC-2", "implementations.": "sections", "content": "PROPER data encoding has always been a challenging task as the fundamental step in emerging computing models. Stochastic computing (SC) and hyperdimensional computing (HDC) have emerged as two promising paradigms for the efficient hardware design of machine learning systems. Both SC and HDC utilize long streams of 'O's and '1's, rather than conventional binary values (with positional encoding or bit-significance) as their basic computational elements. Bit-streams (BSs) and hypervectors (HVs) serve as the primitive components, acting as atomic data elements in SC and HDC, respectively. These atomic data elements are generated using a proper source of randomness. The state-of-the-art (SOTA) approaches typically employ pseudo-random number genera- tors as the source of randomness to generate BSs [1], [2] or HVs [3]\u2013[6].\nEnsuring high-quality randomness through an appropriate random number generator (RNG) is essential in achieving the desired accuracy and hardware efficiency for both SC and HDC systems. In number theory, pseudo-randomness and quasi-randomness are two well-established concepts. Pseudo- randomness refers to sequences or processes that appear statis- tically random but are generated by deterministic algorithms.\nPseudo-random sequences exhibit key randomness character- istics, such as uniform distribution and unpredictability over short intervals, yet they remain reproducible if the generator's initial conditions or seed are known [7]. These sequences are often referred to as high-discrepancy sequences, where the discrepancy denotes the deviation of the sequence points from the uniformity [8], [9]. Linear Feedback Shift Registers (LFSRs) are a well-known source for generating pseudo- random sequences.\nConversely, quasi-random sequences, such as Sobol and Halton sequences, offer a more even and uniform distribution. These sequences are generated by a special class of determin- istic algorithms designed to fill a space (such as a hypercube for multidimensional sequences) more uniformly than pseudo- randomness sequences. Quasi-random sequences possess a low-discrepancy (LD) property, where lower discrepancy leads to enhanced uniformity. Figs. 1(a) and (b) illustrate the point distribution for pseudo-random and quasi-random sequences,"}, {"title": null, "content": "respectively, highlighting the equal distribution of sequence points in quasi-random sequences. Figs. 1(c) and (d) compare the value spread of points in these sequences, with quasi- random sequences demonstrating a more uniform distribution.\nAnother important factor that signifies proper randomness is the degree of correlation between pairs of BS or \u0397\u03bd as illustrated in Figs. 1(e) and (f). The level of correlation plays a critical role in the quality of results. For instance, SC multiplication using bit-wise AND requires independent (or uncorrelated) BSs whereas SC minimum using the same bitwise operation demands highly correlated input BSs [10]. In HDC systems also, symbolic data (e.g., pixel positions, letter, signal time stamp, etc.) requires orthogonal (uncorrelated) HVs in the encoding stage of the learning model [11], [12].\nAdopting pseudo-randomness for encoding data into BSs or HVs can lead to model performance degradation and increased hardware costs. Achieving the desired level of ac- curacy often requires running the model iteratively, which re- sults in increased computational overhead, longer system run- time, energy inefficiency, and reduced performance. Previous studies have shown that pseudo-random sequences perform suboptimally in cascaded circuit architectures, where mid- level correlation among BSs is crucial [13]. To mitigate these challenges, we suggest a novel encoding method based on quasi-randomness, aimed at enhancing the overall performance of SC and HDC systems."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "In SC, any data value is represented by a sequence of random bits ('0's and '1's) [14], [15]. The probability of '1's appearing in the BS corresponds to the data value. A data value x with n-bit precision is represented by a BS, denoted as X, with the probability '1's occurring over the entire BS (Pr(X = 1)/2n). A common method to generate BSs involves comparing the given data with random values from an RNG source. While most SOTA works employ LFSRs (Fig. 1(g)) as RNGs, the authors in [16], [17] proposed using Sobol sequences as a deterministic approach for SC, significantly improving the model accuracy. Another deterministic approach in SC, known as Unary Computing (UC) [18], [19], utilizes unary BSs where all the '1's are aligned together. UC is free from the random fluctuations of the '0' and '1' bits, which is an important source of error in SC.\nSimilarly, in HDC, any atomic data unit, called a hypervec- tor (HV), is represented in high dimensionality and comprises elements of '-1's (or '0's) and '1's. In HDC, symbolic data- such as letters, numbers, sensor data, and temporal and spatial information- can be represented by distinct and orthogonal HVs. This structured information encoding is also known as holographic representation [20]. Orthogonality is achieved through randomness which generates independent HVs. Ideally, an HV consists of an equal number of '1's and 'O's, with each constituting 50% of the vector [21]\u2013[23]."}, {"title": "III. PROPOSED FRAMEWORK", "content": "Given the inefficiencies associated with using pseudo- randomness in SC and HDC, we propose an efficient, lightweight, and highly accurate deterministic bit-stream gen- erator by utilizing Van der Corput (VDC) sequences [13], [24]. VDC sequences are another example of low discrepancy (LD) sequences that exhibit deterministic yet quasi-random charac- teristics. In our approach, VDC sequences serve as the primary source of randomness and are ideal candidates for lightweight RNG hardware designs. Generally, VDC sequences are identi- fied by their bases, denoted as B. A VDC-B sequence number is generated by reversing the digits in the base-B numeral system, resulting in a value within the [0,1) interval. Our proposal employs Powers-of-2 bases for the VDC sequences (VDC-2\"). The advantage of using VDC-2n sequences lies in their simple hardware design and high accuracy in generating bit-streams. Any VDC-2n sequence can be implemented by hardwiring an n-bit counter (including T flip flops) (Fig. 1(h)). A distinguishing feature of our proposed design is its ability to produce multiple distinct sequences simultaneously through various hardwiring schemes. Another significant attribute that sets it apart from SOTA methods is that our design achieves high accuracy with a single run, whereas pseudo-random methods require multiple executions to attain optimal accuracy. This feature enhances the overall efficiency and throughput of the system, which is particularly beneficial for resource- constrained devices.\nFig. 2(a) demonstrates an SC implementation of a non- linear function, specifically, sin(x), comparing its conven- tional design (0) [1] with our modified design utilizing VDC-2nsequences (2) [25], [26]. Additionally, We present the implementation of the basic SC division operation (3) [27] and its enhanced design structure (4) [28], [29] using the proposed RNG. Incorporating VDC-2n sequences in the de- sign of SC operations [24] and trigonometric functions [25] significantly enhances accuracy while reducing the overall hardware costs.\nSimilarly, we demonstrate that equipping HDC models with such deterministic sequences enhances overall performance while reducing hardware costs. Fig. 2(b) exhibits the process of applying our method to the encoding stage of HDC. while the baseline methods (0) incorporate and bind (using element- wise multiplication) both Position and Level HVs for encoding images, employing quasi-random sequences to generate HVs eliminates the need for Position HVs and subsequent multi- plication operations (6) [30]\u2013[32].\nAs an extension of this approach, we introduce UnaryHD architecture (7), where Unary encoding is applied to HDC models by employing quantized LD sequences for HV genera- tion [33], [34]. This approach simplifies hardware implementa- tion, provides significant cost savings, and contributes to more efficient data encoding in HDC systems. To further improve the performance of HDC systems we propose an end-to-end unary structure. This streamlined design features a lightweight, single-source dynamic HV generator. The primary goal of this HV generator design is to achieve optimal randomness in a single iteration, while aligning with the recurrent nature of the random sequence. Unlike the baseline HDC (using LFSR), our proposed design does not employ multiple random sequences to generate m different D-sized vectors. Instead, we generate a single D-sized sequence and use it to create\""}, {"title": null, "content": "different HVs [35]. Another key contribution of this design is a lightweight hardware used to generate Level HVs. For the first time in the literature, we generate Level HVs not randomly but deterministically using our unary generator, eliminating the need for randomness. Our proposed design includes a left shifter module, an up-counter, and a comparator (0)."}, {"title": "IV. RESULTS AND CONTRIBUTIONS", "content": "To evaluate the effectiveness of our proposed approach, we first applied it to SC designs. Tables I and II assess the accu- racy and hardware costs for implementing the sin(x) function. This evaluation highlights the potential of our approach for designing SC trigonometric and non-linear functions, which are fundamental components in AI, computer vision, robotics, and communication models [25], [41]. As demonstrated, the proposed design significantly improves the accuracy and re- duces energy consumption by up to 77% and 92%, respec- tively, compared to the SOTA baseline architecture.\nEmploying deterministic sequences to generate high-quality HVs significantly improves the performance of HDC models. Tables III and IV compare the accuracy of the designs depicted in Fig. 2(b) (0) and (7) for image classification tasks. As shown, the HDC model encoded with deterministic HVs outperforms the baseline model. Fig. 3 showcases the perfor- mance of the end-to-end unary structure in the HDC model in Fig. 2(b) (0) when applied to the DermaMNIST dataset [42]. Additionally, we incorporated an epoch-based training option, given the increased complexity of this dataset compared to the traditional handwritten digit classification tasks. The results indicate that employing our deterministic solution in HDC encoding facilitates earlier learning progress compared to the"}, {"title": null, "content": "baseline model [43]. Beyond improved learning dynamics, the proposed architecture also offers superior hardware efficiency. The proposed HV generator reduces power consumption by 98% and improves the energy efficiency by 15% compared to the baseline method, making it a promising design for dynamic vector generation in resource-constrained edge devices."}, {"title": "V. CONCLUSION", "content": "This work presents a novel deterministic sequence generator and explores its significant applicants within the paradigms of Stochastic Computing (SC) and Hyperdimensional Computing (HDC). The key contributions are summarized in four re- search highlights: Utilizing hardware-friendly quasi-random sequences in SC and HDC systems to generate high-quality bit-streams. \u2461 Enhancing the model throughput, efficiency, and accuracy while simultaneously reducing hardware costs compared to SOTA solutions. Introducing a novel, stream- lined, and efficient RNG for both SC and HDC designs, of- fering a promising approach for resource-constrained devices. \u2463Pioneering the integration of Unary Computing and HDC, resulting in lightweight and energy-efficient HDC systems."}]