{"title": "Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach", "authors": ["Cheng Su", "Jinbo Wen", "Jiawen Kang", "Yonghua Wang", "Hudan Pan", "M. Shamim Hossain"], "abstract": "Secure data management and effective data sharing have become paramount in the rapidly evolving healthcare landscape. The advancement of generative artificial intelligence has positioned Multi-modal Large Language Models (MLLMs) as crucial tools for managing healthcare data. MLLMs can support multi-modal inputs and generate diverse types of content by leveraging large-scale training on vast amounts of multi-modal data. However, critical challenges persist in developing medical MLLMs, including healthcare data security and freshness issues, affecting the output quality of MLLMs. In this paper, we propose a hybrid Retrieval-Augmented Generation (RAG)-empowered medical MLLMs framework for healthcare data management. This framework leverages a hierarchical cross-chain architecture to facilitate secure data training. Moreover, it enhances the output quality of MLLMs through hybrid RAG, which employs multi-modal metrics to filter various unimodal RAG results and incorporates these retrieval results as additional inputs to MLLMs. Additionally, we employ age of information to indirectly evaluate the data freshness impact of MLLMs and utilize contract theory to incentivize healthcare data holders to share fresh data, mitigating information asymmetry in data sharing. Finally, we utilize a generative diffusion model-based reinforcement learning algorithm to identify the optimal contract for efficient data sharing. Numerical results demonstrate the effectiveness of the proposed schemes, which achieve secure and efficient healthcare data management.", "sections": [{"title": "I. INTRODUCTION", "content": "As the backbone of society and human interaction, the healthcare industry has undergone a seismic shift with the advent of digital technology [1]. This transformation has not only revolutionized patient care but also catalyzed the generation, storage, and analysis of vast amounts of healthcare data [2], which encompasses different types of big healthcare data [3], such as omics data, clinical data, electronic health records, sensing data, etc. Although the exponential growth in healthcare data volume holds the potential to revolutionize healthcare by providing insights into patient care, disease patterns, and treatment effectiveness, it also requires sophis-ticated tools for its analysis and interpretation. Fortunately, Generative Artificial Intelligence (GAI) as a new branch of Al has emerged as a potent technology that can effectively analyze vast datasets and generate various content [4], [5]. Es-pecially, by analyzing patient data, including medical history and treatment outcomes, GAI can contribute to personalized medicine by considering individual patient characteristics and generating customized treatment plans [5], [6].\nLarge Language Models (LLMs), as a technological appli-cation of GAI, can achieve general-purpose language gen-eration and conventional natural language processing tasks, which hold the potential to significantly transform healthcare management. With the integration of multi-modal data into LLMs, patients can effectively comprehend many aspects of their physical health through Multi-modal Large Language Models (MLLMs) [7]. For example, the latest GPT-4, equipped with vision capabilities and exceptional performance in natural language processing tasks, can be fine-tuned as a powerful guidance tool in the healthcare domain [8]. However, the sheer size and complexity of MLLMs necessitate efficient retrieval mechanisms to enhance their performance further. Retrieval-Augmented Generation (RAG) is a cutting-edge technique that boosts the reliability and accuracy of GAI models by retrieving facts from an external knowledge base [9]. Furthermore, RAG can capitalize on the similarity between the alignment vectors of the query to retrieve pertinent data, thereby enhancing user prompts by integrating relevantly retrieved data within the con-text, enabling MLLMs to generate accurate and contextually appropriate responses [4]. Thanks to the prominent capabilities of RAG, the integration of MLLMs and RAG has been widely used in various domains [10], [11].\nDespite the advancements in RAG-empowered MLLMs, there are several persistent challenges in the application of these technologies for healthcare data management: 1) Since healthcare data is normally multi-modal and stored in different"}, {"title": null, "content": "databases in a distributed manner, unimodal RAG using a single search manner, such as vector similarity search and keyword search [11], may not efficiently retrieve multi-modal healthcare data to support LLM tasks that handle multiple modes. 2) The application of MLLMs in analyzing healthcare data poses significant security risks and privacy concerns [12]. Healthcare data is highly sensitive, and any breach or misuse can have severe consequences for patients and healthcare providers [2]. Thus, ensuring the confidentiality and integrity of healthcare data during MLLM processing is a critical concern. 3) Pre-trained medical MLLMs can result in inaccurate inferences during task-specific fine-tuning due to biases in the dataset. Hence, incorporating fresh high-quality healthcare data is crucial for fine-tuning MLLMs to avoid incorrect learning patterns [4]. 4) Considering the problem of information asymmetry, healthcare data holders often have more data information, and appropriate incentive mechanisms need to be implemented to encourage healthcare data holders to provide accurate and up-to-date information, which is helpful to enhance the medical diagnostic quality of MLLMs empowered by RAG.\nTo address these challenges, we propose a hybrid RAG-empowered medical MLLMs framework for healthcare data management. Specifically, we utilize cross-chain techniques to allow participants to share data without the involvement of a central institution [13]. To enhance the diagnostic quality of MLLMs, we leverage hybrid multi-modal RAG to further refine the retrieval results. Compared to RAG-empowered LLMs, we employ multi-modal metrics to filter multiple unimodal RAG results and incorporate these retrieval results into MLLMs as additional inputs. Furthermore, we apply Age of Information (AoI) to indirectly evaluate the quality of healthcare data and propose a contract theory model to encourage participants to share fresh data, thus coping with the information asymmetry of data sharing. Besides, considering the dynamic environment of data sharing, we use Generative Diffusion Model (GDM)-based reinforcement learning to find the optimal contract [14]. The key contributions of this paper are summarized as follows:\n\u2022 We develop a novel hybrid RAG-empowered MLLMs framework for healthcare data management. This frame-work facilitates secure interactions between healthcare data holders and the MLLM service provider using a cross-chain system for secure healthcare data transmis-sion. Through employing hybrid RAG, MLLMs improve their quality and complete specific tasks by employing hybrid RAG to retrieve multi-modal healthcare data.\n\u2022 To optimize time-sensitive learning tasks within MLLM services, we apply Aol as a data freshness metric for in-directly assessing the quality of healthcare data. Further-more, we propose a contract theory model to incentivize healthcare data holders to contribute high-quality health-care data with small AoI, thus improving the inference performance of hybrid RAG-empowered MLLMs.\n\u2022 To tackle the high-dimensional complexity of the formu-lated problem, we utilize the GDM-based reinforcement learning algorithm to find the optimal contract for ef-"}, {"title": null, "content": "ficient data sharing. Numerical results demonstrate the effectiveness of the proposed GDM-based scheme and its superiority over the Deep Reinforcement Learning (DRL)-based scheme.\nThe remainder of this paper is organized as follows. Section II reviews the related work. In Section III, we propose a hybrid RAG-empowered medical MLLM framework based on cross-chain technology to enhance data management in the healthcare industry. In Section IV, we introduce a contract theory model to motivate healthcare data holders to provide high-quality healthcare data. In Section V, we present a GDM-based algorithm for optimal contract design. Section VI provides a performance analysis of the proposed schemes. Finally, Section VII concludes this paper. The main notations in our article are summarized in Table I."}, {"title": "II. RELATED WORK", "content": "Recent advancements in LLMs have significantly con-tributed to data management, with numerous research efforts focusing on various aspects such as data analysis, predictive modeling, and decision support systems. Some studies use the strong interpretative abilities of LLMs as agents to continu-ously improve data storage, data analysis, and additional areas [8], [15]. For instance, the authors in [8] introduced GPT-4, which has demonstrated remarkable capabilities in understand-ing and generating human-like text, facilitating various data management tasks [8]. The authors in [16] presented an LLM-based database framework that leverages LLMs for automatic prompt generation and model fine-tuning, which performs highly effective in query rewriting and index tuning [16]. In [17], the authors introduced Data-Copilot, which is a data anal-ysis agent capable of autonomously querying, processing, and visualizing vast amounts of data to meet various human needs. Existing works mainly focus on unimodal LLMs processing text data, while relatively insufficient research has been done on the integration of multi-modal data such as text, images, and structured data. Addressing this gap could substantially boost the functionality of data management systems, especially in complex and data-intensive fields like healthcare."}, {"title": "B. RAG-empowered LLMs", "content": "RAG has incredible capabilities in enhancing the accuracy and reliability of LLM output by incorporating additional information sources, such as external knowledge bases, and augmenting user prompts with relevant retrieval data in context [9]. As a novel technique, RAG allows LLMs to bypass retraining, allowing access to the most up-to-date information to generate reliable output through retrieval-based generation [10]. In [9], the authors introduced RAG, demonstrating its ability to improve the accuracy and relevance of generated text by incorporating retrieved documents into the genera-tion process. The authors in [18] proposed a hybrid RAG method, which integrates Sentence-Window and Parent-Child approaches, and demonstrated that the proposed method out-performs current state-of-the-art RAG techniques. The authors in [4] introduced a carbon emission optimization framework"}, {"title": "C. Contract Theory for Data Sharing", "content": "Contract theory is a branch of economics that studies how contractual arrangements can be designed to align incentives between parties with asymmetric information [21], and it has been widely used in wireless communication, AI, and other fields [13], [21]. In the context of data sharing, information asymmetry often arises because data holders possess more information about the data than data users. Contract theory can effectively incentivize data sharing by ensuring that both parties benefit from the exchange [13]. For example, the authors in [22] proposed a two-period incentive mechanism for healthcare applications, which takes into account the Willing-ness To Participate (WTP) of users and satisfies intertemporal incentive compatibility. This dynamic contract design meets essential constraints and achieves higher profits compared to a uniform pricing scheme. In the context of a mobile AI-generated content network with Unmanned Aerial Vehicles (UAVs), the authors in [23] proposed an AoI-based contract theory model to incentivize the contribution of fresh data between UAVs. The authors in [24] proposed an effective incentive mechanism. This mechanism integrates reputation and contract theory to motivate high-reputation mobile devices with high-quality data to engage in model learning in a federated learning scenario. In addition to the above work, several efforts have been made to develop contract theory models under prospect theory to facilitate user-centric sensing data sharing [13]. Despite these contributions, the application of diffusion-based contract theory to incentivize data sharing remains unexplored."}, {"title": "III. HYBRID RAG-EMPOWERED MEDICAL MLLM FRAMEWORK", "content": "In this section, we propose a hybrid RAG-empowered medical MLLM framework. The detailed methodologies for cross-chain interaction in MLLM training and the utilization of hybrid RAG-empowered MLLM agents for data management are discussed in the following subsections."}, {"title": "A. Cross-Chain Interaction in MLLM Training", "content": "In the health center, robust aggregate MLLMs are de-veloped by training on vast amounts of high-quality multi-modal healthcare data [20]. During the data collection, the health center collects healthcare data sourced from hospitals in diverse regions. However, considering privacy concerns,"}, {"title": "B. Hybrid RAG-empowered MLLMs Agents for Data Management", "content": "Data management tasks in hospitals and the health center include data storage, analysis, and retrieval. When multi-modal healthcare data is gathered into the subchains, the MLLM agent categorizes the data by type and stores it in the appropriate databases. As healthcare data is needed, the MLLM agent retrieves and analyzes the data, ensuring it meets the specific requirements of the task [16]. To further enhance the ability of MLLMs to analyze multi-modal healthcare data, we design a hybrid multi-modal RAG module [18], which is integrated with a data sharing mechanism inspired by contract theory, ensuring that the MLLM data analysis is conducted with high quality and strong privacy protection, allowing secure and effective handling of multi-modal healthcare data. As shown in the right of Fig. 1, the workflow of the Hybrid RAG-empowered MLLMs Agents for Data Management is presented as follows:\nStep 1 (Store multi-modal healthcare data): Hospitals and the healthcare center collect available multi-modal healthcare"}, {"title": null, "content": "data, convert them into vectors specific to each modality using an embedding model, and store these vectors in the local knowledge database with SQL tools [9].\nStep 2 (Retrieve multi-modal healthcare data): When a task query is received, the hybrid multi-modal RAG system uses the same embedding model from Step 1 to convert the query into a vector. Then it calculates similarity scores between the task query vector and the vectors within the knowledge database, retrieving and prioritizing the top K vectors that most closely match the task query [10].\nStep 3 (Re-rank the retrieved information): When all rele-vant information, particularly multi-modal data, is fed directly into the MLLMs, information overload can result and attention to key details can be reduced due to the inclusion of irrelevant content [10]. To address this, the system further screens the results by applying our Multi-modal Information Similarity (MIS) metric, which is calculated by\n$$MIS = \\sum_{i=0}^{n} W_i f_i(x_1, x_2),$$(1)\nwhere $f_i()$ represents the similarity measure function between the task query and the source data in the database and is determined freely according to the requirements of the specific task. $x_1$ and $x_2$ are the unimodal data corresponding to the task query and the source data in the database, respectively, and the weight factor $w_i$ is used to characterize the proportion of each the similarity measure function $f_i(.)$. When the results are re-ranked and filtered by MIS, the retrieved optimized healthcare information is then used to expand the context in the prompt."}, {"title": null, "content": "Step 4 (Optimize the multi-modal inputs): Upon complet-ing the retrieval process, we employ prompt engineering to optimize and synthesize a coherent prompt that integrates the original multi-modal task query with the retrieved multi-modal healthcare data [10], [26]. This refined prompt is then used as the input for the MLLMs, enhancing its ability to generate accurate and contextually relevant responses.\nStep 5 (Generate the corresponding content based on the inputs): Upon receiving the multi-modal inputs, MLLMs con-nect each modal input to its respective pre-trained encoder model, and an adapter module is used to unify all processed embedding [20]. Then, the MLLMs use the pre-trained LLM to generate the corresponding content based on the inputs [10].\nIn the generation of MLLMs, hybrid RAG can enhance the generation quality by effectively incorporating relevant information from various sources. However, RAG does not improve the generalization ability of MLLMs, meaning that the model's ability to apply learned information to new, unseen contexts remains limited, limiting its overall learning ability. To improve the output quality of MLLMs, an essential way is to continuously incorporate new healthcare data for train-ing. Thus, we propose an incentive mechanism to encourage hospitals to share updated healthcare data in Section IV."}, {"title": "IV. PROBLEM FORMULATION", "content": "In this section, we begin by developing a metric for healthcare data quality, followed by the formulation of utility functions for both healthcare data holders and the MLLM service provider. Finally, we propose a contract theory model to motivate healthcare data holders to contribute high-quality healthcare data.\nThe training of MLLMs relies heavily on a large volume of high-quality data [8]. Unfortunately, most healthcare data are stored in hospital databases in various regions. Without data sharing, these valuable resources remain untapped, hin-dering MLLM development. Furthermore, the effectiveness of MLLMs is directly influenced by the quality of the data used in training. Therefore, it is critical to implement an incentive mechanism that encourages hospitals to share healthcare data. Referring to [13], we consider the healthcare industry com-prising hospitals in diverse regions and a health center as an example. The health center acts as the MLLM service provider, and the hospitals in diverse regions serve as the healthcare data holders, represented by a set of $\\mathcal{M} = \\{1,..., m, ..., M\\}$. Initially, we propose a healthcare data quality metric through the Aol metric to assess the quality of healthcare data utilized for fine-tuning MLLMs. Subsequently, acting as the data task publisher, the MLLM service provider employs a contract theory model to encourage M healthcare data holders to engage in data sharing [23]."}, {"title": "A. Healthcare Data Quality Metrics", "content": "Aol has gained broad acceptance as a metric for assess-ing data freshness, especially within wireless communication networks [27]. In this paper, Aol is described as the duration between the data gathering at the hospital and the finalization of MLLM training. Lower Aol correlates with higher-quality MLLM output for healthcare applications. As described in [23], we propose a healthcare data quality metric through AoI, which is relevant for scenarios involving periodic data updates. To generalize, we define the size of healthcare data as $l$ (bytes) and the transmission rate between the health center and hospitals as $T$ (bytes per second). Hence, the transmission time of the healthcare data is $t_{trans} = l/\\tau$ [23]. Meanwhile, we denote $t_u$ as the time of completing a consensus process among blockchains [13]. Therefore, we represent the length of a single time slot $t$ as $t = t_{trans} + t_u$ [13]. To maintain data freshness, each healthcare data provider $m$ periodically updates its healthcare data, with $\\theta_m$ indicating the length of a single time slot in each update cycle. The refreshment of healthcare data happens in the initial time slot of the cycle. Referring to [28], the Aol for a data request made in the i-th time slot is $(i + 1)t$ for $i = 2, ..., \\theta_m - 1$, and for requests initiated in the first or last time slot, the Aol is $2t$. Due to the Poisson process [13], [23], data requests are equally likely to occur in any time slot, with a probability of $1/\\theta_m$. Therefore, the average Aol for data sharing by healthcare data holder $m$ is given by\n$$A_m(\\theta_m) = \\frac{2}{\\theta_m}(2t) + \\frac{\\theta_m-1}{\\theta_m} \\sum_{i=2}^{\\theta_m} (i+1)t = t( \\frac{\\theta_m}{\\theta_m} + \\frac{\\theta_m}{2} - \\frac{1}{2}).$$(2)\nRecognizing that a large Aol can degrade the quality of sensing data, we define the healthcare data quality metric $G(A_m)$ based on Aol as\n$$G(A_m) = A_{max}/A_m,$$(3)\nwhere $A_{max}$ represents the maximum permissible value for the Aol. The average Aol plays a critical role in the quality of MLLM services. Given that (2) is a convex function in relation to the update cycle $\\theta_m$, increasing $\\theta_m$ results in a decrease in Aol [23]. Consequently, there is a tradeoff in managing Aol, which can be optimized by modifying the update cycle."}, {"title": "B. Healthcare Data Holder Utility", "content": "In the context of healthcare data sharing for MLLM ser-vices, the utility for each healthcare data holder $m$ is the difference between the reward $R_m$ and the cost $C_m$ incurred by data sharing tasks, expressed as $U_m = R_m - C_m$ [13]. According to [29], the cost for healthcare data holder $m$ is defined as $C_m = \\xi_m f_m$ [23], with $f_m = 1$ representing the update frequency and $\\xi_m$ denoting the cost of each update [13]. Therefore, the utility of healthcare data holder $m$ is\n$$U_m = R_m - \\xi_m f_m.$$(4)\nThe MLLM service provider lacks precise knowledge of each healthcare data holder's update cost because of the information asymmetry. To address this, the MLLM service provider classifies data holders into discrete types by using statistical distributions derived from historical data, and its expected utility will be optimized [13]. By classifying M healthcare data holders into various types, we denote the k-th type healthcare data holder as $\\delta_k = 1/\\xi_k$ and group them"}, {"title": null, "content": "into a set $\\mathcal{K} = \\{\\delta_k : 1 \\leq n \\leq K\\}$, where a smaller update cost corresponds to a higher healthcare data holder type, and the healthcare data holder types are organized as $\\delta_1 \\leq \\delta_2 \\leq \\ldots < \\delta_K$. Thus, the utility of the type-k healthcare data holder is given by\n$$U_k(R_k, f_k) = R_k - \\frac{f_k}{\\delta_k}$$(5)"}, {"title": "C. MLLM Service Provider Utility", "content": "Due to the quality of MLLMs\u2019output being affected by the freshness of the healthcare data, large AoI leads to poor output for MLLMs and reduces the satisfaction of the MLLM service provider. Referring to [25], The satisfaction function for the MLLM service provider, based on type-k healthcare data holders, is defined as\n$$S_k = \\alpha \\log(G(A_k) + 1),$$(6)\nwhere $\\alpha$ is the overall zero-shot accuracy of MLLMs for var-ious services. For example, the zero-shot accuracy of LLaVA-Med across different domains is presented in Table II. Here, the value of $\\alpha$ is determined by past experience when applied to various services [30].\nOwing to information asymmetry, the MLLM service provider just knows the total count and type distributions of healthcare data holders, without detailed information about the type of each healthcare data holder [13], [23]. Thus, the expected utility of the MLLM service provider is calculated in the following manner [13], [29]\n$$U_s(f, R) = \\sum_{k=1}^{K} Q_k (\\beta S_k - R_k).$$(7)\nHere, $\\beta > 0$ represents the unit profit associated with $S_k$, while $Q_k$ is the probability that a healthcare data holder is type-k, subject to the constraint that the sum of these probabilities equals 1, i.e., $\\sum_{k=1}^{K} Q_k = 1$. Additionally, $R = [R_k]_{1\\times K}$ and $f = [f_k]_{1\\times K}$ represent the vectors of rewards and update frequencies for all $K$ types of healthcare data holders, respectively."}, {"title": "D. Contract Formulation", "content": "To prevent rational healthcare data holders from supplying low-quality data in pursuit of higher rewards, a robust method is required to maintain MLLM service quality [23]. Given that contract theory is an economic tool for effectively designing incentive mechanisms under conditions of asymmetric infor-mation, we propose a contract theory model for the MLLM service provider. This model leverages contract theory to effectively motivate healthcare data holders to provide timely data updates, ensuring the reliability of MLLM services [13]. In this scenario, the MLLM service provider takes the lead in designing a set of contract items and offers them to K healthcare data holders. Based on its type, each healthcare data holder selects the most appropriate contract item, denoted by $\\Psi_k = \\{(f_k, R_k), k \\in \\mathcal{K}\\}$, where $f_k$ represents the update frequency for the type-k healthcare data holder, and $R_k$ is the reward given to the type-k healthcare data holder as an incentive for its contribution. To guarantee that each healthcare data holder opts for the most advantageous contract item for its type, the designed contract must adhere to both Incentive Compatibility (IC) and Individual Rationality (IR) constraints.\nDefinition 1. (IR) The contract item for a type-k healthcare data holder guarantees a non-negative utility, formulated as\n$$\\frac{R_k}{f_k} - \\frac{1}{\\delta_k} \\geq 0, \\forall k \\in \\mathcal{K}.$$(8)\nDefinition 2. (IC) A healthcare data holder of type-k will choose the contract item$(f_k, R_k)$ tailored to its type rather than any other contract item $(f_i, R_i), i \\in \\mathcal{K}$, and $i \\neq k$, i.e.,\n$$\\frac{R_k}{f_k} - \\frac{1}{\\delta_k} > \\frac{R_i}{f_i} - \\frac{1}{\\xi_i}, \\forall k, i \\in \\mathcal{K}, k \\neq i.$$(9)\nTo maximize the expected utility of the MLLM service provider, the optimization problem can be formulated as\n$$\\max_{f,R} U_s (f, R) = \\sum_{k=1}^{K} Q_k(\\beta S_k - R_k)$$\ns.t.\n$$\\frac{R_k}{f_k} - \\frac{1}{\\delta_k} \\geq 0, \\forall k \\in \\mathcal{K},$$\n$$\\frac{R_k}{f_k} - \\frac{1}{\\delta_k} > \\frac{R_i}{f_i} - \\frac{1}{\\xi_i}, \\forall k, i \\in \\mathcal{K}, k \\neq i,$$\n$$f_k \\geq 0, R_k \\geq 0, \\delta_k > 0, \\forall k \\in \\mathcal{K}.$$(10)\nTraditional mathematical solutions may not be able to effectively adapt to the dynamic changes in the environment during data sharing. Consequently, we turn to GDM as a more efficient approach to determine the optimal contract [31], which we discuss in the following section."}, {"title": "V. GENERATIVE DIFFUSION-BASED CONTRACT DESIGN", "content": "In this section, we initially formulate the contract design between the MLLM service provider and healthcare data holders as a Markov Decision Process (MDP). Then, we present a GDM-based contract generation model to determine the optimal contract."}, {"title": "A. MDP Formulation", "content": "1) State space: To find the optimal contract item, i.e., $\\{(f,R), k\\in \\mathcal{K}\\}$, the system first adds Gaussian noise to the initial contract sample. In the current diffusion round t(t = 1,2,...,T), the state space affecting the optimal contract design is defined as\n$$s = \\{\\mathcal{M}, \\mathcal{K}, A_{max}, \\mathcal{Q}, \\mathcal{K}\\}$$(11)\nwhere M and K are constant values, while $A_{max}$, $\\mathcal{Q} = (Q_1,..., Q_K)$, and $\\mathcal{K} = (\\delta_1, . . ., \\delta_K)$ are generated randomly in the current diffusion round t.\n2) Action space: As the MLLM service provider designs the contract items $\\Psi$ to incentivize healthcare data holders to provide high-quality healthcare data, the action $\\alpha^t$ at round t is defined as\n$$\\alpha^t \\in \\{\\Psi\\},$$(12)\nwhere $\\Psi^t = \\{(f_k, R_k), k \\in \\mathcal{K}\\}$ determines the update frequency and reward for type-k healthcare data holders.\n3) Immediate reward: Following the action $\\alpha^t$, the MLLM service provider achieves an immediate reward r(s, $\\alpha^t$) aimed at maximizing the expected utility described in (7) while ensuring compliance with the IR (8) and IC (9) constraints. Thus, the reward function is defined as\n$$r(s, \\alpha^t) = \\begin{cases} U(f, R), & \\text{if } \\alpha^t \\text{ satisfies (8) and (9)}, \\\\\nU_p, & \\text{otherwise},\n\\end{cases}$$(13)\nwhere $U(f, R)$ denotes the expected utility of the MLLM service provider during round t, and $U_p < 0$ serves as the penalty for violating either the IR or IC constraints."}, {"title": "B. GDMs for Optimal Contract Design", "content": "Compared to DRL algorithms that directly optimize model parameters, GDMs enhance contract design through an iter-ative process of denoising the initial distribution [31]. The diffusion model network maps the environmental state to the contract design, which constitutes the contract design policy represented as $\\pi_\\omega(a|s)$ with parameters $\\omega$. The contract de-sign policy $\\pi_\\omega(a|s)$ designed to generate an optimal contract over multiple time steps can be expressed as [31]\n$$\\pi_\\omega(a|s) = \\rho_\\omega(a^0,...,a^T|s)$$\n$$= \\mathcal{N}(a^T; 0, I) \\prod_{t=1}^{T} \\rho_\\omega (a^{t-1}|a^t, s^t),$$(14)\nHere, $\\pi_\\omega(\\cdot)$ represents the reverse process of the conditional diffusion model and $\\rho_\\omega(a^{t-1}|a^t, s^t)$ is modeled as a Gaussian"}, {"title": null, "content": "distribution $\\mathcal{N}(a^{t-1}; \\mu_\\omega(a^t,s,t), \\Sigma_\\omega(a^t, s, t))$, where the co-variance matrix $\\Sigma_\\omega(a^t, s, t)$ is formulated as [31]\n$$\\Sigma_\\omega(a^t, s, t) = \\delta_t I,$$(15)\nwhere $\\delta_t \\in (0,1)$ is a hyperparameter determined before model training, and I is the identity matrix. Consequently, the mean $\\mu_\\omega(a^t, s, t)$ can be given by [31]\n$$\\mu_\\omega(a^t, s, t) = \\frac{1}{\\sqrt{\\chi_t}}(a^t - \\frac{\\delta_t}{\\sqrt{1-\\overline{\\chi}_t}}\\epsilon_\\omega(a^t,s,t)),$$(16)\nwhere $\\chi_t = 1-\\delta_t$, $\\overline{\\chi}_t = \\prod_{j=0}^{t} \\delta_j$, and $\\epsilon_\\omega$ denotes the contract generation network. We first sample $a^T \\sim \\mathcal{N}(0, I)$ and then"}, {"title": null, "content": "sample from the reverse diffusion chain parameterized by $\\omega$, which is given by [31]\n$$a^{t-1}|a^t = \\epsilon_\\omega(a, F, t) + \\sqrt{\\delta} \\epsilon,$$(17)\nwhere F is the conditional information during the denoising process. Referring to [31], we effectively train the contract design policy $\\pi_\\omega$ to enhance the training quality of the contract generation network $\\epsilon_\\omega$. Additionally, inspired by the concept of the Q-function [32], we introduce a contract quality network $q_\\phi (s, \\Psi)$. The training of the contract quality network utilizes the double Q-learning technique to minimize the Bellman operator, involving two critic networks $q_{\\phi_1},q_{\\phi_2}$ and the corresponding target critic networks $q_{\\phi'_1},q_{\\phi'_2}$. We define $q_\\phi = min\\{q_{\\phi_1},q_{\\phi_2}\\}$, and the optimal contract design policy that maximizes the expected cumulative utility of the client is expressed as\n$$\\pi^* = argmax_\\omega -\\mathbb{E}_{a^0 \\sim \\pi_\\omega} [q_\\phi(s, a^0)].$$(18)\nWe define the target policy as $\\pi_{\\omega'}$, and the optimization of $\\phi_i$ for $i = 1,2$ is performed by minimizing the following objective function:\n$$\\mathbb{E}_{(s,az) \\sim \\mathcal{D}} [(y_i^t - q_{\\phi_i}(s, a_z))^2], \\\\\\ y_i^t = r(s, a_z) + \\gamma \\min_{i=1,2} q_{\\phi'_i}(s, \\pi_{\\omega'}(s^t)).$$(19)\nwhere $\\gamma$ represents the discount factor and $\\alpha$ represents the action in the training step z.\nThe pseudo-code of the proposed GDM-based contract generation scheme is shown in Algorithm 1, which con-sists of three phases, and its computational complexity is $\\mathcal{O}(\\|\\omega\\|+\\|\\phi\\|+E_{max}Z_{max}(T\\|\\omega\\|+\\|\\phi\\|))$. In the proposed GDM-based contract generation scheme, denoising techniques are employed to generate optimal contract designs [31]. By in-tegrating exploration noise into the contract design and ex-ecuting it, the process accumulates exploration experience, contributing to the enhancement of contract quality."}, {"title": "VI. NUMERICAL RESULTS", "content": "In this section, we conduct extensive experiments to assess the performance of the proposed hybrid RAG-empowered MLLM framework in particular healthcare analysis and eval-uate the effectiveness of our proposed incentive mechanism. For MLLM inference, we use Python 3.10.14 running on CPU intel Xeon(R) Gold 6133 and GPU NVIDIA RTX A6000"}, {"title": null, "content": "to execute tasks. For the simulation setting of the diffusion model, we list the main parameter settings in III."}, {"title": "A. Case Study of Hybrid RAG-empowered Medical MLLMs", "content": "We simulate a prototype of the hybrid RAG-empowered MMLMs with the support of LLaVA-Med [30] and llamain-dex\u00b9. As illustrated in Fig. 2, we present two examples to demonstrate the functionality and application of our frame-work. Upon receiving a task query with multi-modal health-care data, the framework first retrieves the corresponding data from the respective modal database and performs a preliminary screening of P results based on the cosine similarity between vectors. Next, hybrid RAG further refines these results using the MIS metric to identify the best matches, which are then used as inputs to the MLLMs. Finally, the MLLMs process all this information to provide diagnostic outputs and personalized services according to the query.\nWe apply the criteria of Responsive Artificial Intelligence (RAI)\u00b2 to assess whether the outputs of MLLMs present po-tential risks related to morality, bias, and ethics. Additionally, we also assess the relationship between the output of MLLMS and task query with the Semantic Similarity (SS) [35], which reflects the quality of the diagnosis and serves as a crucial indicator for measuring the MLLMs\u2019 output. Due to the lack of evaluation benchmarks, we integrate LLM evaluators [36] with prompt engineering techniques [26] to measure the quality of data analysis for MLLMs under the method of GPT4-o, LLaVA, and LLaVA with Hybrid RAG. The scoring is normalized to a range of [0, 1]. Higher scores denote greater reliability and lack of bias in the MLLM output, along with a strong correlation to the task query information. In contrast, lower scores signify a substantial gap from the anticipated results. Finally, we combine the RAI evaluation and SS into a unified score, known as the relative LLM score ($\\zeta$) [37], which is calculated using the formula:\n$$\\zeta = \\lambda \\cdot RAI + \\nu \\cdot SS,$$(20)\nwhere $\\lambda$ and $\\nu$ are the weighting factors for the RAI and SS, respectively. In our approach, we assign equal weights by setting $\\lambda = 0.5$ and $\\nu = 0.5$.\nAs shown in Fig. 3, we present the performance comparison between the proposed framework under different healthcare data cases. Our findings indicate that hybrid RAG enables LLaVA-Med to consistently score above 0.9, particularly in X-ray cases from Users 1 and 2 with known etiologies, maintaining high-quality answers and stability. In contrast, other MLLMs exhibit reduced output quality due to the interference of disease factors. In the scenarios involving Users 3 and 4, who are normal without specific causes, the MLLMs achieve high scores and deliver reasonable judgments. However, in the case of User 5, who is normal but has an X-ray that can easily be misjudged by a doctor, other MLLMs exhibit a higher misjudgment rate. In contrast, hybrid RAG continues to produce high-quality outputs by matching similar disease conditions. These cases illustrate that the retrieved data"}, {"title": "B. Performance of GDM-based Contract Theory Approach", "content": "For the proposed contract model, we employ an on-policy GDM algorithm within a double actor-critic framework, and the specific settings of training hyperparameters are shown in Table III. In our setup, we consider 10 healthcare data holders divided into two types, with M = 10 and K = 2. For the two types of healthcare data holders $\\theta_1$ and $\\theta_2$, values are randomly sampled from the intervals (1,6) and (13,18), respectively. Additionally, the maximum tolerance of Aol $A_{max}$ is sampled randomly within the range of (30,60). For the utility of the MLLM service provider, the parameters $\\alpha$, $\\beta$, t are set to 39.9, 10, and 2 respectively, and $Q_1$ and $Q_2$ are randomly generated according to the Dirichlet distribution [38]. The experiments are performed on an NVIDIA GeForce RTX A6000 server GPU with CUDA 11.8.\nFirstly, we compare our proposed contract-based incentive mechanism, which operates under information asymmetry, with other methods: a contract-based mechanism with com-plete information, a greedy scheme, and a random scheme. As illustrated in Fig. 4, we can find that our proposed"}, {"title": "VII. CONCLUSION", "content": "In this paper, we studied the service quality issues of MLLMs and the design of incentive mechanisms for healthcare data management. We proposed a hybrid RAG-empowered medical MLLM framework based on cross-chain technolo-gies to enhance data management in the healthcare industry."}]}