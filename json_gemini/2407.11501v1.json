{"title": "Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era", "authors": ["Lei Ren", "Haiteng Wang", "Yuanjun Laili"], "abstract": "Industrial Multivariate Time Series (MTS) is a critical view of the industrial field for people to understand the state of machines. However, due to data collection difficulty and privacy concerns, available data for building industrial intelligence and industrial large models is far from sufficient. Therefore, industrial time series data generation is of great importance. Existing research usually applies Generative Adversarial Networks (GANs) to generate MTS. However, GANs suffer from unstable training process due to the joint training of the generator and discriminator. This paper proposes a temporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for MTS generation. It aims to better handle the complex temporal dependencies and dynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean Discrepancy (Ada-MMD) method has been proposed for the controlled generation of MTS, which does not require a classifier to control the generation. It improves the condition consistency of the diffusion model. Moreover, a Temporal Decomposition Reconstruction UNet (TDR-UNet) is established to capture complex temporal patterns and further improve the quality of the synthetic time series. Comprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that the proposed Diff-MTS performs substantially better in terms of diversity, fidelity, and utility compared with GAN-based methods. These results show that Diff-MTS facilitates the generation of industrial data, contributing to intelligent maintenance and the construction of industrial large models.", "sections": [{"title": "I. INTRODUCTION", "content": "Industrial Multivariate Time Series (MTS) plays a vital role in anomaly detection [1], remaining useful life prediction [2], [3] and fault diagnosis [4]. It is the basis for training deep learning models with high inference accuracy. However, multivariate time series data exhibit heterogeneity due to different time scales, noise levels, and different latent characteristics. Coupled with the data privacy concerns of different industrial companies, available industrial time series data for specific scenarios is rare. Data shortage has become a severe problem that hinders intelligent maintenance research and the construction of industrial large models.\nData generation techniques provide a means of alleviating data shortage and enhancing the test environment. The commonly applied AI-Generated Content (AIGC) methods for generating time series data include variational autoencoders (VAEs) [5]\u2013[7] and generative adversarial networks (GANs) [8]\u2013[10], etc. For example, Chen et al. [5] utilize VAE to generate trajectories to address the trajectory generation problem, which employs an LSTM network to learn the characteristics of trajectories. A modified Wasserstein auto-encoder (MWAE) is presented in the article [7] to generate highly similar fault data, which introduces the sliced Wasserstein distance for measuring distributional differences. However, the VAE usually fails to generate realistic samples due to its reconstruction loss function. Another recent promising method to generate samples is the GAN-based model, which employs a discriminator and generator through an adversarial process to create realistic data. CVAE-GAN [10] is a conditional variational generative adversarial network for bearing fault diagnosis, which adopts a classifier to distinguish different classes of fault data. CPI-GAN [11] integrates the physical information to the generative adversarial network to generate synthetic degradation trajectories, which improves the accuracy of downstream tasks. These methods reduce the time and effort required for manual data collection and improve the accuracy of the model. Although generative models have achieved success in some generation tasks, there are still some challenges in MTS data generation.\nFirstly, GANs-based models are prone to non-convergence and unstable training process [12]\u2013[14]. Specifically, MTS data is of low quality with high sampling frequency and strong noises, which makes it difficult for the generator in the GAN to learn the patterns in the time series data. Meanwhile, the discriminator can easily distinguish between real and synthetic samples. The adversarial nature between the generator and discriminator demands substantial effort to stabilize the training process.\nSecondly, MTS data have different conditions (e.g., fault classes, health indicators), and it's challenging for the generative model to generate data with specific conditions (consistency between input condition information and generated data). To guide the synthetic samples, some methods [9], [10], [15] leverage discriminator or classifier to achieve controlled generation of MTS data. However, these methods require joint training additional network structure, which reduces the condition consistency of controlled generation.\nThirdly, MTS data are usually non-smooth and involve complex temporal dependencies, leading to difficulties in gen-"}, {"title": "II. RELATED WORKS", "content": "Previous studies have investigated the application of generative networks for synthesizing multivariate time series data. One commonly used approach is the variational autoencoders (VAEs) [7], [20], [21], which is used to generate new samples that are similar to the original data For instance, Chen et al. [5] use a VAE to generate trajectories to tackle the trajectory generation problem, employing an LSTM network to learn the trajectory characteristics. The literature [7] presents a modified Wasserstein auto-encoder (MWAE) to generate highly similar fault data. This method introduces the sliced Wasserstein distance for measuring distributional differences. In contrast, GAN-based models [9], [10], [22], [23] employ a discriminator and generator through an adversarial process to create realistic data. Lu et al. [24] introduce a GAN architecture that combines the AE and LSTM network to monitor the RUL of bearings. CPI-GAN [11] integrates physical information into the GAN to generate synthetic degradation trajectories, which can enhance the accuracy of downstream tasks.\nUnlike GAN-based or VAE-based models requiring additional architecture for training (e.g., the discriminator in GAN or the encoder in VAE), we adopt the diffusion model for MTS generation task. This model use a forward diffusion process and doesn't require addition network in training, avoiding mode collapse and training instability issues from the joint training of two networks."}, {"title": "B. Diffusion Models", "content": "Diffusion models have recently been proposed to model data distributions using forward and reverse processes. The forward process gradually injects noise into real-world data, whereas the reverse process generates realistic data by removing noise. The fundamental research on diffusion models is proposed and theoretically supported by Sohl-Dickstein et al. [25]. Two significant advances in diffusion models, i.e., Denoising Diffusion Probabilistic Models (DDPM) [16] and conditional diffusion models on image synthesis [19], have demonstrated remarkable abilities in image generation [26]. These advances have catalyzed further developments and applications of diffusion models in various domains. Recently, diffusion models have been successfully extended to generate audio and ECG time series [27] [28]. DiffWave [27] involves a raw audio synthesis technique based on a diffusion probabilistic model, which has achieved significant results in audio quality.\nWhile diffusion models are commonly applied to image tasks, our research explores their potential in MTS data generation. Specifically, we expand the traditional diffusion model to a conditional adaptive generative model within the sensor time series and develop a temporal decomposition reconstruction module for MTS data."}, {"title": "III. TEMPORAL-AUGMENTED CONDITIONAL ADAPTIVE DIFFUSION MODEL FOR ITMS GENERATION", "content": "In this section, we present a temporal-augmented conditional adaptive diffusion model for MTS data generation. The model comprises the Denoised Diffusion Probabilistic Model, Conditional Ada-MMD Diffusion Method, and Temporal Decomposition Reconstruction UNet (TDR-UNet). Each of them will be introduced in detail as follows."}, {"title": "A. Denoised Diffusion Probabilistic Model", "content": "Compared to the VAE-based methods, diffusion models possess high-dimensional latent variables through a diffusion process, enabling them to generate high-quality samples. Additionally, diffusion models employ a fixed diffusion learning procedure that avoids the instability training problem of GAN-based methods. In essence, our approach extends the principles established by DDPM [16] to the domain of one-dimensional multivariate signal generation.\nThis diffusion model consists of two main stages, as shown in Fig. 1: a diffusion process and a reverse process. In the diffusion process, Gaussian noise is added to the original time series $x_0$. This noise is dependent on the time step $t$, which is sampled from a uniform distribution within the range of $[1,T]$. We refer to these noisy variables as $x_1, ..., x_t, .., x_T$. The process of diffusion can be defined by a Markov chain which remains fixed, starting from the data $x_0$ and ending with the latent variable $x_T$:\n$q(x_{0:T}|x_0) = \\prod_{t=1}^{T} q(x_t|x_{t-1})$\nwhere $q(x_t|x_{t-1}) := N(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_tI)$, $\\beta_t$ is the noise schedule. $T$ and $t$ are diffusion total timestep and current timestep, respectively. This entire process gradually transforms data $x_0$ into Gaussian distribution variables $x_T$ when $T\\rightarrow \\infty$.\nWe employ the reparameterization technique to modify the diffusion process in Eq. (1) to enhance its efficiency. The value of $x_t$ at any random timestep $t$ can be computed as follows:\n$x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon$\nwhere $\\epsilon \\sim N(0, I)$ is Gaussian noise; $\\bar{\\alpha}_t = \\prod_{i=1}^{t}\\alpha_i$; and $\\alpha_t = 1 - \\beta_t$.\nThe reverse process takes on the role of denoising $x_T$ to recover $x_0$ so that it can eventually recover data samples from the Gaussian noise. To achieve this, the noise added during the diffusion process is predicted through a trained denoising model. The reverse step is similarly defined by a Markov chain, as in the diffusion step.\n$p_\\theta(x_{0:T-1}|x_T) = \\prod_{t=1}^{T} p_\\theta(x_{t-1}|x_t)$\nwhere $\\theta$ are the parameters of the denoising model.\nIn the original DDPM work, a linear noise schedule was used. Nonetheless, in complex signal processing scenarios, this schedule failed to produce optimal results. The strong linear schedule led to rapid degradation of the noisy time series into pure noise, resulting in faster information loss during the noise introduction phase. To mitigate this problem, we implemented a cosine schedule as suggested in the paper [18].\n$f(t) = t/T$\n$f(t) = cos(\\frac{t/T + s}{1+s} \\cdot \\frac{\\pi}{2})$\nwhere Eq. (4) is the linear schedule function. Eq. (5) is the cosine schedule function. $s$ is an offset parameter set to $s = 0.008$. The cosine schedule is designed to preserve information within the noisy time series for a more extended period during the noising process steps."}, {"title": "B. Conditional Ada-MMD Diffusion Method", "content": "To achieve the synthesis of multivariate time series under specific conditions, it is necessary to incorporate condition information, such as equipment health indicators, into the diffusion model. Therefore, we develop a conditional diffusion model that does not require an explicit classifier and considers the health indicator of the equipment as the condition. Then, to ensure the condition consistency of the diffusion model, a Adaptive Maximum-Mean Discrepancy (Ada-MMD) regularization loss is introduced to adaptively capture mutual information. This facilitates the alignment of the generated samples under specific conditions with the original samples, promoting their similarity.\nFirst, we add the condition information $x_c$ to the reverse process. The conditional form of reverse process can be formulated as follows:\n$p_\\theta(x_{0:T}|x_c) = p(x_T) \\prod_{t=1}^{T} p_\\theta(x_{t-1}|x_t, x_c)$\n$p_\\theta(x_{t-1}|x_t, x_c) := N(x_{t-1}; \\mu_\\theta(x_t, t|x_c), \\sigma_\\theta(x_t, t|x_c) I)$\nThen, the parameterizations of $\\mu_\\theta$ and $\\sigma_\\theta$ can be defined by:\n$\\mu_\\theta(x_t, t|x_c) = \\frac{1}{\\sqrt{\\alpha_t}} ( \\frac{1 - \\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}})\\epsilon_\\theta(x_t, t|x_c)$\n$\\sigma_\\theta(x_t, t|x_c) = \\frac{\\beta_t}{1-\\bar{\\alpha}_{t-1}} \\cdot \\frac{1}{\\bar{\\alpha}_t}$\nwhere $\\epsilon_\\theta$ denotes the estimated noise. $\\beta_t$ is the noise schedule. $\\bar{\\alpha}_t$ has been defined in the Eq. (2). According to the Eqs. (6)-(7), the time series can be recovered by the estimated noise.\nSimilar to the standard reverse process, the original signal can be deduced from the noise distribution if it is predicted. Afterward, we input the noisy variable $x_t$, timestep $t$, and condition information $x_c$ into our denoising model UNet to estimate the noise distribution. To incorporate the condition into the denoising model, condition information is included in"}, {"title": "C. Temporal Decomposition Reconstruction UNet", "content": "A Temporal Decomposition Reconstruction UNet Model (TDR-UNet) is designed to tackle the task of generation. The model mainly includes two components, the input embedding module and the Temporal Decomposition Reconstruction UNet module. Specifically, the model embeds the inputs, including the latent variable $x_t$, the condition $x_c$, and the timestep $t$. The UNet encoders and decoders [16] are used for predicting the noise that is added to the original data during the diffusion process. To capture the temporal dependency of the MTS data, a decomposition reconstruction mechanism is executed between the encoder and decoder. The detailed architecture is shown in Fig. 2.\nTo preserve the temporal relationships within the data, we initiate the embedding transformation for each input sample. First, to facilitate the input to be better learned by the subsequent UNet, the latent variable $x_t$ is embedded using a 1D convolution layer.\n$x_{temb} = Conv1D(x_t)$\nwhere $Conv1D(.)$ represents 1D convolution layer. $x_{temb}$ denotes the embeded time series.\nNext, the discrete timestep $t$ is embedded sinusoidally with a two-layer fully connected (FC) network to a continuous feature $t_{emb}$, enabling the network to understand data over time.\n$t_{pos} = PosEmbed(t)$\n$t_{emb} = FC(GeLU(FC(t_{pos})))$\nwhere $PosEmbed(\u00b7)$ denotes sinusoidal position embedding methods [29]. $t_{pos}$ refers to the initial positional embedding of the timestep $t$. $GeLU$ is an activation function.\nIn order to enable the input signal to contain the target information, we transformed condition information into a vector via an FC network.\n$x_{cemb} = Maska (FC(x_c))$\nwhere $FC(.)$ denotes the fully-connected layer. In contrast to the one-hot processing for discrete features, we employ an FC network to embed continuous conditions in high-dimension space. $Mask_a()$ is a mask encoding function. Specifically, we set a parameter $a$ to adjust the degree of condition information. For the embedded condition vectors, $a$ of them will be set to random values. For example, the larger the value of $a$, the larger the random value in the embedded condition vector will be. This will result in less conditional information.\nIn the proposed UNet method, the network architecture is constructed based on the U-Net framework [15], consisting primarily of three encoders and three decoders. Each encoder features two sequential 1D convolution blocks, followed by a downsampling operation. Within each convolution block, two convolutional layers are employed: the first layer conducts a convolution operation on the input signal, which is then processed by a GroupNorm transformation and activated via a SiLU function. It is illustrated in Fig. 3.\nThe architecture integrates residual connections that add the input signal information directly to the output in the encoder and after convolution in the decoder. Additionally, condition and timestep information are fed into the first convolution block of each encoder. The decoder consists of two convolution blocks that progressively restore the signal to its original dimensions through convolution operations. These convolutional layers incorporate skip connections, which fuse\nfeatures from corresponding layers in the encoder with those in the decoder.\nThen, a temporal decomposition reconstruction layer is performed after the UNet encoder. To learn the complex temporal patterns in time series generation context, we apply the technique of time series decomposition on multivariate time series data. Given the input X, average-pooling and max-pooling are employed for the decomposition of X, yielding two distinct sets of features: $X_{Trend}$ and $X_{Peak}$. The trend part assists in capturing the inherent average trend within the data, while the utilization of peak parts serves to accentuate maximal variation. Each represents one of the underlying categories of patterns that are more predictable. Subsequently, these two features are concatenated and fed into a convolution block to integrate the time series information. This decomposition procedure can be described as:\n$X_{Trend} = AvgPool(Padding(X))$\n$X_{Peak} = MaxPool(Padding(X))$\n$F_{dec} = Convld(Concat(X_{Trend}, X_{Peak}))$\nAfter time series decomposition, a convolutional attention structure is performed to reconstruct the multivariate time series. The time series is first processed through three 1D convolutional layers to generate separated features. Then, an attention mechanism is executed as follows:\n$Q_{conv} = Conv(F_{dec}); K_{conv} = Conv(F_{dec});$\n$V_{conv} = Conv(F_{dec})$\n$Attention (Q, K, V) = softmax (\\frac{Q_{conv} K^T_{conv}}{\\sqrt{d_k}})) V_{conv}$\nwhere $Q_{conv}$, $K_{conv}$, $V_{conv}$ are parameter metrics. $\\sqrt{d_k}$ is the scaling factor. Since the attention layer is capable of highlighting the significant fields that are beneficial for feature representation, this layer facilitates learning the fine-grained information of the average part and max part. Therefore, the network is better to learn the underlying patterns. Subsequently, the model reconstructs the time series information through a one-dimensional convolutional layer. Finally, the reconstructed information is processed by the UNet decoder layer and a convolution layer to recover the original size."}, {"title": "D. Training and Sampling Procedure", "content": "The proposed methodology begins with constructing a neural network model for noise estimation of MTS data. The model parameters $\\theta$ are then trained by minimizing the loss function calculated by Eq. (11) through the Adam algorithm. This training procedure, outlined in Algorithm 1, enhances both training efficiency and convergence speed. The algorithm starts by initializing the model parameter and setting up the training environment. First, Gaussian noise is generated and a diffusion timestep is selected. Then, the corresponding target condition from the condition dataset guides the diffusion process. The latent variable is calculated, followed by an estimation of the added noise based on the model parameters.\nNext, the model's loss is calculated using a combination of standard noise estimation and Ada-MMD loss, weighted by a learnable factor. After processing all instances in the batch, the model parameters are updated using the Adam optimization algorithm, based on the gradients of the loss. This process is repeated through all epochs until the fully trained model parameters are output, ready for deployment or further validation.\nOnce the training process is completed, the method generates MTS data for specific operating conditions in an iterative manner. This procedure is presented in Algorithm 2. The first step is to determine the total number of diffusion steps and acquire the noise schedules. Next, a random noise sample $x_T$ is sampled from a Gaussian distribution. The typical HI of industrial equipment associated with the data synthesis is selected as the conditional input $x_c$. Along with the random noise and time step, this input is utilized in the model explained in Section III-C. The following steps include calculating the noisy data $x_t$ based on the model's output and repeating this procedure until $t = 0$. At this point, the denoised data $x_0$ serves as the generated time series."}, {"title": "IV. EXPERIMENT", "content": "Table II shows the experiment results of our method and other generative networks. Under the same length setting, Diff-MTS achieves consistent state-of-the-art performance in most datasets and length settings. For example, with the length setting of 96 in sub-dataset FD001, the Diff-MTS achieves a discriminative score of 0.611, which outperforms the DiffWave network by 32.4%. In the same length setting, Diff-MTS gives 33.4% (21.744\u219214.472) predictive score reduction in FD001, 13.2% (30.122\u219226.152) in FD002, 45.2% (28.433\u219215.554) in FD003, 28.7% (32.515\u219223.167) in FD004. This signifies that Diff-MTS is able to provide more accurate generation results. Note that the GAN-based methods generally obtain a discriminative score above 0.94, which means synthetic time series obtained by these methods have large distributional differences between the real time series. This situation of GAN-based methods may result from their limitation for generating complex MTS data and unstable training, while Diff-MTS proposes Ada-MMD to enhances the condition consistency of the diffusion model and TDR-UNet to improve diffusion model's ability to extract the temporal information, thus achieving superior results.\nFEMTO Dataset: We also perform an additional comparison experiment on the FEMTO dataset and vary the input length and the corresponding prediction lengths: 80, 160, 320. It can be observed that Diff-MTS consistently outperforms other methods at all length settings. The extensive experiment on different situations demonstrates the superior effectiveness of Diff-MTS in generating industrial multivariate time series."}, {"title": "C. Ablation Study of the Conditional Ada-MMD Mechanism", "content": "The ablation experiment of the conditional adaptive MMD mechanism assessed its effectiveness through modifications to Ada-MMD module on four sub-datasets. We adjusted the Diff-MTS model and reported predictive scores for the generated results: (1) Diff-MTS w/o Ada-MMD represents the model with the exclusion of the Ada-MMD mechanism, (2) Diff-MTS w/o Ada indicates the model a model using pure MMD, and (3) the original Diff-MTS architecture.\nAs shown in Table V, the removal of the Ada-MMD mechanism in Diff-MTS struggling to capture complex distributions in the data, consequently leading to relatively lower predictive and discriminative scores. Specifically, Diff-MTS w/o Ada-MMD achieves an average predictive score of 21.840, representing a decrease compared to the original Diff-MTS. Additionally, the exclusion of the adaptive kernel in Ada-MMD also demonstrates a declining trend. In conclusion, these experiments highlight the significance of the Ada-MMD mechanism and the effectiveness of the adaptive kernel in the Ada-MMD mechanism."}, {"title": "D. Ablation Study of the TDR-UNet", "content": "TDR-UNet is characterized by time series decomposition and convolutional attention mechanism. To analyze the effectiveness of key components, we modified Diff-MTS and reported the predictive and discriminative scores: (1) TR-UNet means the model without the time series decomposition, (2) TD-UNet means the model without the convolutional attention mechanism, and (3) the original 1-D UNet architecture.\nIn Table IV, one can observe that both the two elements significantly contribute to improving the quality of the generated time series data. The deployment of decomposition reconstruction UNet makes the network capture complex temporal patterns, thus improving the generation quality. Specifically, the TD-UNet achieves a discriminative score of 0.747 and a predictive score of 21.354 on average, which outperforms the original UNet by 4.8% (0.785\u21920.747) and 4.4% (22.333\u219221.354). It also can be observed that the TR-UNet outperforms the original UNet on average, which can benefit from focusing on the important regions in the reconstruction process. In addition, we find that the combination of the decomposition module and reconstruction module improves generative performance on average. Overall, the ablation experiment demonstrates that both elements of the temporal decomposition reconstruction contribute to the quality of the synthetic sensor time series."}, {"title": "E. Analysis on the Distance", "content": "To quantify the distance between synthetic data and real time series, we use two distance functions (similarity measures): Dynamic Time Warping (DTW) distance and Frechet Distance (FD) functions. Table VI shows the DTW and FD distance of our methods and some baselines (DiffWave [27], GAN-LSTM [24], TTS-GAN [32]). Each method generates the same number of time series with the same labels (health indicator) as the original dataset.\nFrom Table VI, it can be observed that the diffusion model-based methods (Diff-MTS, DiffWave) consistently outperform the GAN-based methods (TTS-GAN, GAN-LSTM). This is consistent with the results reported in Table II, indicating that the diffusion method produces high-quality time series. In some settings, DiffWave slightly outperforms Diff-MTS, such as FD001 with lengths of 96. This could be attributed to certain unique characteristics of the datasets or specific noise factors in some scenarios. However, it is essential to note that, on average, Diff-MTS still outperforms DiffWave on both similarity measures, indicating its ability to generate synthetic data that closely resembles real time series in a variety of scenarios."}, {"title": "F. Visualization Analysis", "content": "We utilize PCA and t-SNE techniques to reduce the synthetic and real data to two dimensions and plot their scatterplots in Fig. 4. In the scatterplots, synthetic data are denoted by brown dots while real data are represented by blue dots. A greater degree of overlap between these dots indicates higher similarity between the two data types. In the first column, the scatterplots of Diff-MTS demonstrate a notably improved overlap, especially when compared to other GAN-based benchmarks, suggesting that the synthetic datasets produced by diffusion model-based methods closely resemble the original data. For the PCA visualization of DiffWave, it can be observed that the blue and brown dots on the right side of the figure do not overlap well. It means that there are some distribution differences between the synthetic data of DiffWave and the real data.\nMoreover, we display some synthetic data and real data to show our classifier-free guidance in Fig. 5. The black curves are real time series, while t The gold, blue and green curves represent the synthesized time series of Diff-MTS, DiffWave and TimeGAN, respectively. It can be observed that Diff-MTS can generate high-fidelity time series in the given condition and can generate more similar time series than DiffWave and TimeGAN. For example, the synthetic signal of TimeGAN in sensor s13 is only in the upper half of the diagram. In contrast, the synthetic signal of the Diff-MTS in sensor S13 represents the trend of the real time series."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose Diff-MTS, a temporal-augmented conditional adaptive diffusion model for synthesizing industrial multivariate time series (MTS) data. Diff-MTS effectively mitigates the issues of non-convergence and unstable training encountered in Generative Adversarial Networks (GANs) and is capable of recovering high-fidelity signals from Gaussian noise. Comprehensive experiments demonstrate that Diff-MTS outperforms GAN-based methods, offering promising solutions for training industrial large models by generating high-quality industrial data.\nIn future work, we plan to investigate the integration of large language models (LLM) with industrial signal generation models. For example, by combining LLM with a time series prediction model, LLM can enhance its feature representation capabilities. In addition, given MTS data for industrial equipment, LLM can provide information about equipment failure states or health indicators and provide maintenance recommendations."}]}