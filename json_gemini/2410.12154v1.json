{"title": "Exploiting LLMs' Reasoning Capability to Infer Implicit Concepts in Legal Information Retrieval", "authors": ["Hai-Long Nguyen", "Tan-Minh Nguyen", "Duc-Minh Nguyen", "Thi-Hai-Yen Vuong", "Ha-Thanh Nguyen", "Xuan-Hieu Phan", "Ken Satoh"], "abstract": "Statutory law retrieval is a typical problem in legal language processing, that has various practical applications in law engineering. Modern deep learning-based retrieval methods have achieved significant results for this problem. However, retrieval systems relying on semantic and lexical correlations often exhibit limitations, particularly when handling queries that involve real-life scenarios, or use the vocabulary that is not specific to the legal domain. In this work, we focus on overcoming this weaknesses by utilizing the logical reasoning capabilities of large language models (LLMs) to identify relevant legal terms and facts related to the situation mentioned in the query. The proposed retrieval system integrates additional information from the term-based expansion and query reformulation to improve the retrieval accuracy. The experiments on COLIEE 2022 and COLIEE 2023 datasets show that extra knowledge from LLMs helps to improve the retrieval result of both lexical and semantic ranking models. The final ensemble retrieval system outperformed the highest results among all participating teams in the COLIEE 2022 and 2023 competitions.", "sections": [{"title": "Introduction", "content": "The statute law retrieval problem is a typical task in Legal NLP. The problem takes as input a natural language query, which could be a question, legal statement, or a specific scenario. The output of the problem is relevant legal articles or segments extracted from articles containing information that address the given query. In countries that follow the statute law system, this problem is the vital core of legal reference systems or legal search engines which could serve for many people, from legal experts to non-experts. These AI-based tools could help legal practitioners reduce the amount of time and resources on paperwork.\nPrevious studies have done well in using lexical features through statistical models combined with semantic features from Transformer-based models to address and improve retrieval results (Kim et al. 2022; Goebel et al. 2023; Louis and Spanakis 2022). Given the high number of candidates, the legal retrieval task is often split into two steps: lexical ranking and semantic re-ranking. However, a significant issue arises when queries containing content with no lexical overlap with the gold standard articles, which leads to the gold standard articles being eliminated from the first retrieval phase. Moreover, different query types exist, including legal statements and specific scenarios as shown in Table 1. Legal statements are typically concise and may not require logical reasoning for comprehension. Specific scenarios describe conflicts of rights between parties, involving more complex underlying logical reasoning.\nThe emergence of Large Language Models (LLMs) has opened up a new era of development in the field of AI, especially NLP (Zhao et al. 2023; Yang et al. 2023; Bommasani et al. 2021). To date, LLMs have effectively addressed various general NLP tasks, including text summarization and machine translation (Huang et al. 2023; Yao et al. 2023; Laban et al. 2023). For legal domains, these models have shown their abilities to improve the performance of downstream tasks (Yu, Quartey, and Schilder 2022; Trautmann, Petrova, and Schilder 2022; Zhou, Huang, and Wu 2023). However, previous work relied on prompting techniques or the in-context learning capability of LLMs to tackle these tasks straightforwardly. In contrast, this work leverages the strength of LLMs to explore hidden logical reasoning of queries as additional information to retrieval models.\nThe proposed method is inspired by how legal experts search legal documents. When searching for legal documents that relate to a real-life situation, legal experts typically begin by finding which behaviours the subjects perform, which legal issues are described in the situation, and which legal concepts they relate to. Then, they search for legal documents related to those legal issues or concepts. Identifying relevant legal issues and concepts related to real-life situations is equivalent to the process of query expansion in terms of computer science. However, this process is not merely semantic matching but requires inference based on the interaction between entities in the event. Recent studies have shown that large language models such as GPT-4 (Achiam et al. 2023) and Gemini have basic inference capabilities, although they have not reached human-level inference (Achiam et al. 2023; Rane, Choudhary, and Rane 2024; Wang et al. 2024). This has motivated this research to utilize LLMs to explore hidden logical semantics of queries for query expansion.\nThe main contributions of this research include identify-"}, {"title": "Related Work", "content": "Legal NLP has attracted much interest from researchers and companies because of its potential and wide range of applications (Chalkidis and Kampas 2019; Zhong et al. 2020). Statutory article retrieval is one of the core problems in this field, playing an essential role in search engines and reference systems. A traditional approach for query-article matching is the term-based model (Kim, Rabelo, and Goebel 2019; Tran, Nguyen, and Satoh 2019). However, the trend rapidly changes to deep learning models involving word embedding (Landthaler et al. 2016; Kayalvizhi, Thenmozhi, and Aravindan 2019), document vector embedding (Sugathadasa et al. 2019), and contextual understanding (Nguyen et al. 2024; Nguyen et al. 2023).\nRecently, a growing number of studies have focused on large language models (LLMs) in legal NLP (Sun 2023; Lai et al. 2023). These models can address downstream tasks such as question answering (Yu, Quartey, and Schilder 2022), legal judgment prediction (Trautmann, Petrova, and Schilder 2022), legal summarization (Pont et al. 2023; Gesnouin et al. 2024) based on fine-tuning and prompt engineering techniques. However, there is space for exploiting LLMs to address legal information retrieval. Zhou et al. (Zhou, Huang, and Wu 2023) utilized LLMs to extract significant content from legal cases and incorporate it into retrieval models. Unlike (Zhou, Huang, and Wu 2023), which involved a manual annotation process with the assistance of legal experts to collect salient content, this work does not rely on human-labeled data for LLMs. This distinction enhances the reproducibility and openness of the research.\nQuery expansion is one of the typical methods to shorten the gap between query and document, further improving retrieval performance. The expansion process mainly relies on external knowledge-based and pseudo-relevance feedback to enrich query information. Relevance documents can serve as additional knowledge in query expansion. However, this approach does not apply to our work as the relevant legal documents are not provided with the query. Therefore, we generate legal terms and a new query based on the original query to serve as additional knowledge for the retrieval system. Recently studies have leveraged generative models to rewrite the query via fine-tuning with labeled data (Imani et al. 2019; Zheng et al. 2020; Zheng et al. 2021). Large language models (LLMs) (Team et al. 2023; Touvron et al. 2023; Achiam et al. 2023) with billions of"}, {"title": "Query expansion for legal document retrieval", "content": "As mentioned in section 1, to address complex queries with multiple layers of implicit semantics, reasoning capabilities are required. This section will describe the prompting patterns on Large Language Models (LLMs) to leverage their basic reasoning abilities and extract key information. Additionally, the legal document retrieval system described in section 3.3 will integrate ranking results from multiple models and is designed to entirely leverage information obtained from the prompting process."}, {"title": "LLMs-based legal term extraction", "content": "Due to theirs generation capability and knowledge across various domains, LLMs are utilized to generate the key terms which represents the general topics of the query. Legal terms related to the query are extracted using zero-shot prompting techniques on LLMs. Since the experimented dataset is the COLIEE dataset with the original version written in Japanese, the prompting sentence will be written in Japanese to avoid information loss. Furthermore, to facilitate the processing of LLMs' output, the prompting sentence includes additional instructions for LLMs output in JSON format. The prompting pattern and instruction in English version are described in listing 1, the one with Japanese version is presented at the listing 3 in the Appendix."}, {"title": "LLMs-based query augmentation", "content": "Directly concatenating legal terms into the query does not ensure semantic coherence for the query, which may cause confusion for semantic-based ranking models. To preserve the semantic integrity, the legal-style oriented query reformulation is performed by zero-shot prompting technique on LMMs. The suggested prompting pattern written in English is detailed in listing 2, the Japanese one is showed at the listing 4."}, {"title": "Retrieval system utilizing expanded query", "content": "To combine the information from both prompting methods described in section 3.1 and 3.2, both lexical-based ranking and semantic-based ranking models will be utilized and ensembled.\nAssuming the input query is denoted as $q$ and the legal corpus, denoted as set $D$, including $m$ legal documents: $D = \\{d_1, d_2, ..., d_m\\}$. After the legal-term extraction, the obtained terms form the set $T_q = \\{t_1,t_2,...,t_n\\}$. These terms are concatenated with the query at the lexical level to create a new query:\n$q_{\\text{term-expand}} = \\text{concat}(q, t_1, t_2, ..., t_n)$"}, {"title": "Inference strategy", "content": "The legal document retrieval task is indeed about ranking the documents in the law corpus based on the relevancy"}, {"title": "Experiment and result", "content": "To evaluate the effectiveness of the proposed retrieval system, the COLIEE 2022 1 and COLIEE 2023 2 datasets for the Statute Law Retrieval task will be utilized. Both datasets employ a corpus derived from the Japanese statute law, containing 782 legal provisions. The labeled set of COLIEE"}, {"title": "Implementation detail", "content": "In this section, the implementation, training, inference, and ensemble of model results are discussed. Firstly, for the BM25 model, we utilize the rank-bm25 library\u00b3. Before being processed by the BM25 model, articles and queries written in Japanese are word-based tokenized using the Konoha library 4 and the MeCab tokenizer. The prompting process is performed on GPT-4 (Achiam et al. 2023) and Gemini (Team et al. 2023).\nThe training dataset provides sample which contains a query and a list of gold relevant articles. For training the BERT-based ranking model, the training samples are transformed into pairwise training samples. The transformed set contains a query and an article with two labels 0 or 1 representing not-relevant or relevant. The negative samples are chosen from top candidates according to the BM25's relevance score. To achieve the optimal ratio between negative and positive samples, the top-30 most relevant candidates according to the BM25 model are utilized for creating negative samples for the queries. The Huggingface library 5 is employed for creating and training the BERT-based model with the downstream task sequence classification. The pretrained Multilingual BERT 6 is being used for initializing the BERT-based retrieval model. The experimented mod-"}, {"title": "Experiment Result", "content": "The recall score of two term-expansion methods are presented in the table 4. According to that table, the recall scores when using the term-expanded queries instead of the original one are significantly higher at all top-k levels, with both Gemini and GPT\u20134 terms-expansion. This proves that adding legal terms will make the queries more lexically relevant to the gold standard articles, facilitating the BM25 model to rank more accurately. Additionally, the recall score of the Gemini-based term-expansion achieved a higher recall score than the GPT-4. Therefore, the BM25's relevance score with Gemini's expanded queries is used in the final retrieval system.\nAccording to the implementation detail, the retrieval system is experimented with the COLIEE 2022 and 2023 datasets. Because the BERT's training sample pair is generated by filtering from BM25's candidates, the relevance score derived from BERT-based ranking model need to be ensembled with the relevance score from BM25 model to"}, {"title": "Conclusion", "content": "In this study, two query expansion methods including legal-term extraction and query reformulation are used to exploiting the reasoning capability and general knowledge from LLMs. The information extracted from these two prompting method are injected into lexical-based and semantic-based ranking models. The experiments in COLIEE 2022 and 2023 dataset show that the generated legal information from LLMs significantly improves retrieval results and outperforms the results of the teams participating in the COL-IEE competition in 2022 and 2023."}, {"title": "Appendix", "content": "Due to the original data is written in Japanese, the prompting pattern used will be in Japanese. Listing 3 describes the prompting pattern of the legal term extraction process and listing 4 shows the prompting pattern for generating the re-described query."}]}