{"title": "Distributed Difference of Convex Optimization", "authors": ["Vivek Khatana", "Murti V. Salapaka"], "abstract": "In this article, we focus on solving a class of distributed optimization problems involving n agents with the local objective function at every agent i given by the difference of two convex functions $f_i$ and $g_i$ (difference-of-convex (DC) form), where $f_i$ and $g_i$ are potentially nonsmooth. The agents communicate via a directed graph containing n nodes. We create smooth approximations of the functions $f_i$ and $g_i$ and develop a distributed algorithm utilizing the gradients of the smooth surrogates and a finite-time approximate consensus protocol. We term this algorithm as DDC-Consensus. The de- veloped DDC-Consensus algorithm allows for non-symmetric directed graph topologies and can be synthesized distributively. We establish that the DDC-Consensus algorithm converges to a stationary point of the nonconvex distributed optimization problem. The performance of the DDC-Consensus algorithm is evaluated via a simulation study to solve a nonconvex DC- regularized distributed least squares problem. The numerical results corroborate the efficacy of the proposed algorithm.", "sections": [{"title": "I. INTRODUCTION", "content": "Due to the increase in size and complexity of modern sys- tems, solving problems involving many agents via distributed methods is highly desirable. An effective way towards a distributed solution is to cast the problems in the framework of distributed optimization [1], [2]. In this article, we focus on the following distributed optimization problem,\n\nminimize F(x) = \u2211=1(fi(x) \u2013 gi(x)),\nXERP\n\nwhere x \u2208 RP is a common decision, and $f_i : R^P \u2192 R \\cup {\\infty, \\infty}$ and $g_i : R^P \u2192 R$ are private objective functions of agent i. The agents are connected through a directed graph, $G(V, E)$, where V and E are the set of vertices and edges respectively. The terms in the aggregate objective function in (1) are of a difference-of-convex (DC) form. Due to the richness of the set of DC functions (see the properties mentioned in [3]), DC functions can be used to model most of all practical non-convex optimization problems. Many applications in statistical learning and estimation [4], power systems [5], computational biology [6], signal restoration [7], network optimization [8], combinatorial optimization [9] can be posed as DC programs.\nThe initial study of distributed optimization can be traced back to the seminal works [10], [11]. Since then the special case with $f_i$ being convex and $g_i = 0$ has received significant development (see [12]\u2013[14] and references therein). As a relaxation of the convex objective functions most works"}, {"title": "II. PROPOSED METHODOLOGY", "content": "The following assumption is satisfied throughout the article,\nAssumption 1. 1. Functions $f_i : R^P \u2192 R \\cup {\u2212\\infty, \u221e}$ are proper, lower semi-continuous, and $m_{f_i}$-weakly convex.\n2. Functions $g_i : R^n \u2192 R$ are convex and finite everywhere.\n3. The set of global minimizers of (1), arg $minimize_x F(x)$, is nonempty, and the global minimum value $F^*$ is finite.\nA vector $\u1ef9 \u2208 R^P$ is called a stationary point of F if:\n0\u2208(\u03a3=1 fi(\u1ef9)) \u2013 d (\u03a3=19i(\u1ef9)),\nor equivalently, \u03a3=1 fi(\u1ef9) \u03a0\u039f\u03a3=19i(\u1ef9) \u2260 0. Furthermore, given \u025b > 0, we say \u1ef9 \u2208 RP is an e-stationary point of F if there exists (\u00a7; y) \u2208 RP \u00d7 RP such that\n\u03be\u03b5\u03b8(\u03a3=1 fi(y)) \u2013 (\u03a3=19(y)), and\nmax {||||,||\u1ef9 \u2013 y||} \u2264 \u03b5.\nWe use df(x) to denote the general subdifferential of the function f at x ([33], Definition 8.3).\n\nA. Approach Roadmap and Supporting Results\nNote that the objective function has a DC structure. Under Assumption 1 we do not impose differentiability of the functions fi and gi. Thus, to develop an algorithm with desirable convergence properties, we first utilize a smooth function mapping to obtain a differentiable DC approxi- mation of the objective function fi gi. Then we utilize the differentiable DC approximation to develop first-order algorithms to solve problem (1). We take the approach in [31] and utilize separate Moreau envelopes of fi and gi to obtain a smooth approximation of the function fi-gi. To this end, we define the Moreau envelops: Given 0 < \u00b5i <1/mfi, the Moreau envelopes, $M_{\u00b5f_i} : R^P \u2192 R$, and $M_{\u00b5g_i} : R^P \u2192 R$ of functions fi and gi respectively are given by\n\nM\u00b5fi (Y) := minimize {fi(x)+2x-y||2},\nXERP\nMpigi (y) := minimize {g(x)+2x-y||2},\nXERP\nand form the smooth function $F_{i,\u00b5}$ := $M_{\u00b5f_i}$ - $M_{\u00b5g_i}$, for all i\u2208 {1,...,n}. The corresponding proximal mappings X\u00b5fi: RP \u2192 RP, and X\u00b5gi: RP \u2192 RP are defined as,\nXuifi (y) := arg minimize {fi(x) + 2 ||xy||2},\nXERP\nXuigi (y) := arg minimize {g(x) + 2x - y||2}.\nXERP\nDefine, $m_f := max_{1<i<n} M_{f_i}$. Given, 0 < \u03bc < 1/mf, let\n\nFi,\u00b5(x) := M\u00b5f; (x) \u2212 M\u00b5g; (x), and\nF\u03bc(x) := \u03a3\u0395\u03bc(x) = \u03a3(\u039c\u03bc\u03b6;(x) \u2013 M\u00b5g; (x)).\n\nNext, we summarize the properties of Fi,\u00b5, the Moreau envelops $M\u00b5f_i$, $M\u00b5g_i$; the mappings $X\u00b5f_i$, $X\u00b5g_i$.\nLemma 1. ([31], Properties of Moreau envelops and proxi- mal mappings) Let Assumption 1 holds. Let 0 < \u03bc < 1/mf and $M\u00b5f_i$, $M\u00b5g_i$, $X\u00b5f_i$, $X\u00b5g_i$ be given by definitions (4)-(7)"}, {"title": null, "content": "with parameter \u00b5. Then, the following claims hold:\n1. $X\u00b5f_i$, $X\u00b5g_i$ are Lipschitz continuous with modulus, $\\frac{1}{1-\u03bcm_f}$ and 1 respectively.\n2. $M\u00b5f_i$, $M\u00b5g_i$ are differentiable with gradient \u2207$M\u00b5f_i (y) = \u03bc\u00af\u00b9(y \u2212 X\u00b5f_i (y))$, \u2207$M\u00b5g_i (y) = \u03bc\u00af1(y \u2212 X\u00b5g_i (y))$.\n3. \u2207$M\u00b5f_i$, \u2207$M\u00b5g_i$ are Lipschitz continuous with modulus\n$\\frac{1}{\u03bc-\u03bc\u00b2m_f}$ and $\\frac{1}{\u03bc\u03c0}$ respectively.\n4. $F_{i,\u00b5}$ is differentiable, and \u2207$F_{i,\u00b5}(y)$ = \u2207$M\u00b5f_i(Y) -\n\u2207$M\u00b5g_i (y) = \u03bc^{\u22121}(X\u00b5g_i (Y) \u2212X\u00b5f_i (Y))$ is Lipschitz continuous\n$\\frac{2-\u03bcm_f}{\u03bc-\u03bc\u00b2m_f}$.\nwith the modulus $L\u00b5F := \\frac{2-\u03bcm_f}{\u03bc-\u03bc\u00b2m_f}$.\nNext, we introduce the following optimization problem,\n\nminimize F\u03bc(x) = \u03a3=1(\u039c\u03bcf;(x) \u2013 M\u00b5g; (x)).\n\nLemma 2. ([31], Relation between (1) and (9)) Let Assump- tion 1 holds and 0 < \u03bc < 1/mf. Then,\n1. The set of global minimizers of (9), arg $minimize_x, F\u00b5(x)$, is non-empty, and F* = $minimize_{x\u2208R^P} F\u00b5(x)$.\n2. \u1ef9 is a stationary point of $F\u00b5$, i.e. \u2207$F\u00b5(\u1ef9) = 0, if and only\nif x = \u03a3i=1 X\u00b5f_i (Y) = \u03a3i=1 X\u00b5g_i (\u1ef9) is a stationary\npoint of F in the sense of (2).\n3. $y^* \u2208 arg minimize_y F\u00b5(y)$ if and only if x* = = \u03a3i=1 X\u00b5g_i (Y^*) = x^* \u2208 arg $minimize_y F(y)$.\nThe minimization problem (1) is generally challenging due to the nonconvexity and nonsmoothness of the objective functions. In contrast, problem (9) with the approximation $F\u00b5$ provides an attractive surrogate: as F\u00b5 is Lipschitz continuous, which is a desirable property for a wide range of first-order methods. Moreover, from Lemmas 1 and 2, F\u00b5 also largely preserves the geometric structure of F. Obtaining a stationary solution of F\u00b5, we can recover its counterpart for F via the proximal mappings X\u00b5f_i and X\u00b5g_i. Thus, we focus on solving problem (9).\nB. Proposed DDC-Consensus Algorithm\nProblem (9) can be recast by creating local copies $y_i$ for all i\u2208 {1,2,...,n}, of the solution y to problem (9) and imposing the agreement of the solutions of all the agents via consensus constraint leading to the equivalent problem,\n\nminimize-1(M\u00b5fi (Yi) \u2013 M\u00b5g; (Yi)),\nsubject to yi = yj, for all i, j.\n\nWe develop a distributed gradient descent-based algorithm to solve problem (10) called the DDC-Consensus algorithm.\nThe algorithm proceeds in the following manner:\nAt any iteration k of the algorithm, each agent i maintains two estimates, an optimization variable $y_i(k) \u2208 R^P$, and a local update variable $z_i(k) \u2208 R^P$. Every iteration k involves two updates: first, each agent i updates $z_i(k)$ via local gradient descent based on the mapping $F_{i,\u00b5}$, with the gradient evaluated at $y_i(k-1)$; next, the optimization variable $y_i(k)$ is updated to an estimate which is $\u03b7_k$-close to the average value $\\frac{1}{n} \\sum_{i=1}^{n} z_i(k)$, i.e., $||y_i(k) - \\frac{1}{n} \\sum_{i=1}^{n} z_i(k)|| \u2264 \u03b7(k)$, using the distributed \u03b7-consensus protocol (described in detail in the next section), initialized with $z_i(k) := z_i$ as the initial condition for"}, {"title": null, "content": "the agent i and tolerance \u03b7\u03ba. The above algorithm updates at any agent i in are summarized in the next equations:\n\nZi2(k+1) = y(k) \u2013 \u03b1\u03bdFi,\u00b5(y(k))\n= y{k) - \u2207 (Muf\u2081 (y(k)) \u2013 Mufi (y(k)))\n= y{k) - \u03b1\u03bc (X\u00b5g (y(k))\nY\n\n(k+1) = wtk+1), where\n||wtk+1) - (k+1) || < \u03b7(k+1), (k+1) = \u03a3(k+1)\n\nwhere, wtk) is the output of the n-consensus protocol and is an approximate estimate of the average 2(k), tk denotes the number of communication steps utilized by the n-consensus protocol at iteration k of the DDC-Consensus algorithm. We summarize DDC-Consensus in Algorithm 1.\nAlgorithm 1: DDC-Consensus\nInput:\n0 < \u03bc < 1/mf; step-size: 0 < \u03b1 < 1/L\u00b5F;\nconsensus tolerances {n(k)}k\u22650\nInitialize:\nFor each agent i \u2208 V, y(0) = z(0) \u2208 RP;\nRepeat for k = 0, 1, 2, ...\nfor i = 1, 2, 3, ..., n, (In parallel) do\nend\n/* gradient descent iteration:\n(k+1) = Y - \u03b1\u03bc (\u03a7\u03bc\u03b1; (yk)) - Xufi (Y{k))) */\n(k) */\nZi\n/* consensus iterations:\n(k+1) \u03b7(k+1)-consensus(z{k+1), i \u2208V)\nYi\nuntil a stopping criterion is met\nThe finite-time n-consensus protocol is described next.\nC. Finite-time n-consensus Protocol\nThe finite-time n-consensus protocol and its variants are proposed in earlier articles [34]\u2013[38] by the authors under various practical scenarios. Here, we resort to consensus with vector-valued states [37], [38]. Consider, a set of n agents connected via a directed graph $G(V,E)$. The finite-time \u03b7- consensus protocol aims to design a distributed protocol so that the agents can compute an approximate estimate of the average, \u00fb := \u03a31 u), (0) of their initial states u10) (0) in finite-time. This approximate estimate is parameterized by a small tolerance \u03b7 chosen apriori to make the estimate precise. In the n-consensus protocol, the agents maintain state variables $u_i(k) \u2208 R^P$, $v_i(k) \u2208 R$ and update them as:\nU\n(k)\nVi\n=\n(k)\nwi\n=\nPiiv(k-1) + \u03a3EN Pijk-1)\n+\nEN Pijk-1)\n\nwhere, w) = u), \u0e02. (0) = 1 for all i \u2208 V and N\u00af denotes\nvi\nthe set of in-neighbors of agent i. The updates (15)-(17) are based on the push-sum (or ratio consensus) updates (see [39]). The following assumption on the graph G(V,E) and weight matrix P := [pij] is made:"}, {"title": null, "content": "Assumption 2. The directed graph G(V,E) is strongly connected and the weight matrix P is column-stochastic.\nNote that P being a column stochastic matrix allows for a distributed synthesis of the n-consensus protocol. The variable wk) \u2208 RP is an estimate of the average \u00fb with each agent i at any iteration k. The estimates w(k) converge to the average \u00fb asymptotically.\nTheorem 1. ([39],[40]) Let Assumption 2 hold. Let {wk)}k>o be generated by (17). Then wk) asymptotically converges to \u00fb = \u03a31U10) for all i \u2208 V, i.e.,\n\nlimk\u2192 wi wk) = \u03a3=1 (0), for all i \u2208 V.\n\nEvery agent i \u2208 V maintains an additional scalar value ri to determine when the state wk) are n-close to each other and hence from Theorem 1, \u03b7-close to \u00fb. The radius variable wi is designed to track the radius of the minimal ball that can enclose all the states wk) (more details can be found in [37], [38]). The radius w, for all i \u2208 V, is updated as:\n(k):=\n0,\nJEN\nif k = mD, m = 0, 1, 2, ...\nmaxlok) ||w(k) \u2013 w(k-1) || + r/(k-1)}, otherwise,\n\nwhere D is an upper bound on the diameter of the directed graph G. Denote, B(wk), r(k)) as the p-dimensional ball of (k) (k))\nradius ri centered at wi It is established in [37] that under Assumption 2, after D iterations of update (18), the ball B(w(k+D), r(k+D)) encloses the states w wk) of all the agents i \u2208 V. Further, it is also established that radius update sequences {r(k)}k>0 converge to zero as m \u2192 \u221e.\nTheorem 2. ([37], [38]) Let updates (15)-(17) hold. Let {rik)}k\u22650 be the sequences generated by (18). Under As- sumption 2,\n\nlimk\u221er (k)= 0, for all i \u2208 V.\n\nTheorem 2 gives a criterion for termination of the consen- sus iterations (15)-(17) by utilizing the radius updates at each agent i \u2208 V given by (18). Using the value of the rk), k = 0,1,2... each agent can ascertain the deviation from the consensus among the agents. As a method to detect n-consensus, at every iteration of the form mD, for m = 1,2,..., r(mD) is compared to the tolerance 7, if\nr(mD) < \u03b7 then all the agent states w(m-1)D) were \u03b7- close to \u00fb (from Theorem 1) and the iterations (15)-(17) are terminated. Proposition 1 establishes that the n-consensus protocol converges in a finite number of iterations.\nProposition 1. Under the Assumption 2, n-consensus is achieved in a finite number of iterations kn at each agent i \u2208 V. Moreover, kn satisfies\n\nk\u03b7 2 [u [u(0),..., u)] + || P || log(4)\n log(82)\nwhere, u(0)\n(1)\n, - and are constants related to the matrix P and graph G.\n\nProof. Note, r\u21920 ask \u2192 \u221e. Thus, given \u03b7 > 0, i \u2208 V there exists finite ki,n such that for k > ki,n, rk) < n, for all i \u2208 V. Choosing kn := max1<i<n ki,n establishes the claim. Further, (19) is proved rigorously in [14], Lemma 3.1.\nTo have a global detection, each agent generates a one-bit \"converged flag\" indicating its detection. The flag signal can be combined using distributed one-bit consensus updates (see [37]) allowing the agents to achieve global n-consensus."}, {"title": "III. CONVERGENCE ANALYSIS FOR DDC-CONSENSUS", "content": "Let the average of the optimization variables at iteration k be denoted as: \u0177(k) := \u03a3=1yk). Denote the gradient of the function \u03a3=1 Fi,\u00b5 evaluated at individual optimiza- tion variables of all the agents and the average \u0177(k) as:\n\nh(k) := 1 \u03a31 Fi,\u00b5(yk)), and\n\nh(k) := 1 Fi,\u00b5(\u1ef9(k))\n\nrespectively. A consequence of the n-consensus protocol is that the difference between h(k) and h(k) is bounded.\nLemma 3. Let y(k) denote the consensus tolerance in the DDC-Consensus algorithm at iteration k, then\n||h(k) \u2013 \u0125(k) || \u2264 2L\u00b5F\u03b7(k),\nwhere L\u00b5F is the constant as defined in Lemma 1.\nProof. Note that,\n\n||h(k) \u2013 \u0125(k) || = || [\u03bcg, (Y{k)) \u2013 X\u00b5f; (Y))] - [\u03bcg, () - X\u00b5f; (Y))] ||\n=|| [\u03a31 (g(y) - y(k)) - \u03a31 (\u03bcg, ((k)) \u2013 y(k)] ||\n=|| \u03a31 (\u03bcg, (y) - \u03bcg, (y) -\n1 (\u03bcf, (y) \u2013 F1(yk))) ||\n|\u03bc |(y)) - \u03a31 (2(k) - Y(k) ||| \u03a3\u03ba |+ \u03a3\u03ba||)1 ||\n<1\u03bcg (\u03bcg F)\n(F F \u03bc)||(\u03b7 \u03bc + \u03b7 = \u03a3\u03bd\n2 (L \u03b72 \u226a\nn\n1/k1.11\n= where, as defined in Lemma 1 and the last\n\u03bc"}, {"title": null, "content": "Recall 2(k+1) (2k), \u2013 \u03b1(E(y)). Therefore, 2(k+1) \u2013 (K+1) \u2013 (\u03b1 (E()))\n= (2K), ((k+1) -\n2(k)) \u2212 ah\n2k+ (02)2,\n1"}, {"title": "V. CONCLUSION", "content": "We focused on a distributed DC optimization problem with local objective functions given by the difference between a nonsmooth weakly convex function and a nonsmooth convex function. Based on the gradient of the smooth approxi- mations of the weakly convex and convex functions we developed the distributed DDC-Consensus algorithm. In the DDC-Consensus algorithm each agent performs a local gradient descent step and updates its estimates using a finite- time n-consensus protocol. The agent estimates are shared over a directed graph and updated via a column stochastic matrix; giving DDC-Consensus the desirable properties of allowing for non-symmetric communication and distributed synthesis. We established that the DDC-Consensus algo- rithm converges to a stationary point of the nonconvex dis- tributed optimization problem. The numerical performance of the DDC-Consensus algorithm is presented in a simu- lation study solving the DC-regularized least squares prob- lem. Results showing the behavior of DDC-Consensus and its relaxations DDC-Consensus-Inexact-q and DDC-Mixing concerning the residual metrics demonstrate the efficacy of the proposed DDC-Consensus algorithm."}]}