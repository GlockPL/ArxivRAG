{"title": "Distributed Difference of Convex Optimization", "authors": ["Vivek Khatana", "Murti V. Salapaka"], "abstract": "In this article, we focus on solving a class of distributed optimization problems involving n agents with the local objective function at every agent i given by the difference of two convex functions $f_i$ and $g_i$ (difference-of-convex (DC) form), where $f_i$ and $g_i$ are potentially nonsmooth. The agents communicate via a directed graph containing n nodes. We create smooth approximations of the functions $f_i$ and $g_i$ and develop a distributed algorithm utilizing the gradients of the smooth surrogates and a finite-time approximate consensus protocol. We term this algorithm as DDC-Consensus. The developed DDC-Consensus algorithm allows for non-symmetric directed graph topologies and can be synthesized distributively. We establish that the DDC-Consensus algorithm converges to a stationary point of the nonconvex distributed optimization problem. The performance of the DDC-Consensus algorithm is evaluated via a simulation study to solve a nonconvex DC-regularized distributed least squares problem. The numerical results corroborate the efficacy of the proposed algorithm.", "sections": [{"title": "I. INTRODUCTION", "content": "Due to the increase in size and complexity of modern systems, solving problems involving many agents via distributed methods is highly desirable. An effective way towards a distributed solution is to cast the problems in the framework of distributed optimization [1], [2]. In this article, we focus on the following distributed optimization problem,\n\nminimize $F(x) = \\sum_{i=1}^{n}(f_i(x) \u2013 g_i(x))$,\n\nwhere $x \\in \\mathbb{R}^P$ is a common decision, and $f_i: \\mathbb{R}^P \\rightarrow \\mathbb{R} \\cup {\\infty, \\infty}$ and $g_i : \\mathbb{R}^P \\rightarrow \\mathbb{R}$ are private objective functions of agent i. The agents are connected through a directed graph, $G(V, E)$, where V and E are the set of vertices and edges respectively. The terms in the aggregate objective function in (1) are of a difference-of-convex (DC) form. Due to the richness of the set of DC functions (see the properties mentioned in [3]), DC functions can be used to model most of all practical non-convex optimization problems. Many applications in statistical learning and estimation [4], power systems [5], computational biology [6], signal restoration [7], network optimization [8], combinatorial optimization [9] can be posed as DC programs.\nThe initial study of distributed optimization can be traced back to the seminal works [10], [11]. Since then the special case with $f_i$ being convex and $g_i = 0$ has received significant development (see [12]\u2013[14] and references therein). As a relaxation of the convex objective functions most works"}, {"title": "A. Definitions and Notations", "content": "Definition 1. (Directed Graph) A directed graph G is a pair (V,E) where V is a set of vertices and E is a set of edges, which are ordered subsets of two distinct elements of V. If an edge from j\u2208 V to i \u2208 V exists it is denoted as (i, j) \u2208 E.\nDefinition 2. (Strongly Connected Graph) A directed graph is strongly connected if for any pair (i, j), i \u2260 j, there is a directed path from node i to node j.\nDefinition 3. (Diameter of a Graph) The longest shortest directed path between any two nodes in the graph.\nDefinition 4. (In-Neighborhood) The set of in-neighbors of node i \u2208 V is called the in-neighborhood of node i and is denoted by $N_i$ = {$j | (i, j) \u2208 E$} not including the node i.\nDefinition 5. (Column-Stochastic Matrix) A matrix M = $[m_{ij}] \u2208 \\mathbb{R}^{n \\times n}$ is called a column-stochastic matrix if $0 < m_{ij} \\leq 1$ and $\\sum_{i=1}^{n} m_{ij} = 1$ for all $1 \\leq i, j \\leq n$.\nDefinition 6. (Lipschitz Continuity and Differentiability) A function $f: \\mathbb{R}^P \\rightarrow \\mathbb{R}$ is called Lipschitz continuous with constant L > 0 and Lipschitz, differentiable with constant $L_f > 0$ respectively, if the following inequalities hold:\n\n$|f(x) - f(y)| \\leq L||x \u2212 y||, \u2200 x, y \u2208 \\mathbb{R}^P$\n\n$||\\nabla f(x) \u2013 \\nabla f(y)|| \\leq L_f||x \u2212 y||, \u2200 x, y \u2208 \\mathbb{R}^P$.\n\nDefinition 7. (Strongly Convex Function) A differentiable function f is called strongly convex with parameter \u03c3, if there exists \u03c3 > 0 such that for all x, y in the domain of f:\n\n$\\langle \\nabla f(x) \u2013 \\nabla f(y), x \u2212 y \\rangle \\geq \u03c3||x \u2212 y||^2, \u2200 x, y \u2208 dom f$.\n\nDefinition 8. (Weakly Convex Function) For some $m_f \\geq 0$, we say that function $f : \\mathbb{R}^P \\rightarrow \\mathbb{R}$ is $m_f$-weakly convex if $f + \\frac{m_f}{2} ||x||^2$ is convex.\nDefinition 9. (Level-bounded Function) Function $f: \\mathbb{R}^P \\rightarrow \\mathbb{R}$ is called level-bounded if the \u03b2-level-set {x : f(x) \u2264 \u03b2} is bounded (possibly empty) for all \u03b2\u2208 \\mathbb{R}.\nDefinition 10. (Lower Semicontinuity) A function $f : \\mathbb{R}^P \\rightarrow \\mathbb{R} \\cup {-\\infty, \\infty}$ is called lower semi-continuous at a point $x_0$ if for every real y < f(x0) there exists a neighborhood U of $x_0$ such that y < f(x) for all x \u2208 U. The function f is lower semicontinuous at every point of its domain, dom(f).\nDefinition 11. (Proper Function) A function $f: \\mathbb{R}^P \\rightarrow \\mathbb{R} \\cup {-\\infty, \\infty}$ is called proper if f(x) > -\u221e for every x and and if there also exists some point $x_0$ such that f(x0) < \u221e.\n||x||1 and ||x|| denote the 1-norm and 2-norm of the vector x\u2208 \\mathbb{R}^P respectively. The notation $[x]$ denotes the least integer function or the ceiling function, defined as: given x \u2208 \\mathbb{R}, $[x]$ = min{$m \u2208 \\mathbb{Z} | m > x$}, where Z is the set of integers. dom(f) = {$x : f(x) < \\infty$}."}, {"title": "II. PROPOSED METHODOLOGY", "content": "The following assumption is satisfied throughout the article,\nAssumption 1. 1. Functions $f_i : \\mathbb{R}^P \\rightarrow \\mathbb{R} \\cup {-\\infty, \\infty}$ are proper, lower semi-continuous, and $m_{f_i}$-weakly convex.\n2. Functions $g_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ are convex and finite everywhere.\n3. The set of global minimizers of (1), arg minimizex\u2208RP F(x), is nonempty, and the global minimum value F* is finite.\nA vector $y^* \\in \\mathbb{R}^P$ is called a stationary point of F if:\n\n$0 \\in \\partial (\\sum_{i=1}^n f_i(y^*)) \u2013 \\partial (\\sum_{i=1}^n g_i(y^*))$,\n\nor equivalently,\n$\\partial (\\sum_{i=1}^n f_i(y^*)) \\cap \\partial (\\sum_{i=1}^n g_i(y^*)) \\neq \\emptyset$. Furthermore, given \u025b > 0, we say $y^* \\in \\mathbb{R}^P$ is an \u025b-stationary point of F if there exists $(\\xi; y) \\in \\mathbb{R}^P \\times \\mathbb{R}^P$ such that\n\\xi \\in \\partial (\\sum_{i=1}^n f_i(y)) \u2013 \\partial (\\sum_{i=1}^n g_i(y)), and\nmax {||\u03be||, ||y \u2212 y||} \u2264 \u025b.\n\nWe use \u2202f(x) to denote the general subdifferential of the function f at x ([33], Definition 8.3).\nA. Approach Roadmap and Supporting Results\nNote that the objective function has a DC structure. Under Assumption 1 we do not impose differentiability of the functions $f_i$ and $g_i$. Thus, to develop an algorithm with desirable convergence properties, we first utilize a smooth function mapping to obtain a differentiable DC approxi-mation of the objective function $f_i \u2013 g_i$. Then we utilize the differentiable DC approximation to develop first-order algorithms to solve problem (1). We take the approach in [31] and utilize separate Moreau envelopes of $f_i$ and $g_i$ to obtain a smooth approximation of the function $f_i \u2013 g_i$. To this end, we define the Moreau envelops: Given $0 < \u03bc_i < 1/m_{f_i}$, the Moreau envelopes, $M_{\u03bcf_i} : \\mathbb{R}^P \\rightarrow \\mathbb{R}$, and $M_{\u03bcg_i}: \\mathbb{R}^P \\rightarrow \\mathbb{R}$ of functions $f_i$ and $g_i$ respectively are given by\n\n$M_{\u03bcf_i} (y) := \\underset{x \\in \\mathbb{R}^P}{minimize} \\lbrace f_i(x) + \\frac{1}{2\u03bc_i} ||x - y||^2 \\rbrace ,$\n\n$M_{\u03bcg_i} (y) := \\underset{x \\in \\mathbb{R}^P}{minimize} \\lbrace g_i(x) + \\frac{1}{2\u03bc_i} ||x - y||^2 \\rbrace ,$\n\nand form the smooth function $F_{i,\u03bc} := M_{\u03bcf_i} - M_{\u03bcg_i}$, for all $i \u2208 \\lbrace 1,...,n \\rbrace$. The corresponding proximal mappings $X_{\u03bcf_i}: \\mathbb{R}^P \\rightarrow \\mathbb{R}^P$, and $X_{\u03bcg_i}: \\mathbb{R}^P \\rightarrow \\mathbb{R}^P$ are defined as,\n\n$X_{\u03bcf_i} (y) := \\underset{x \\in \\mathbb{R}^P}{arg \\ minimize} \\lbrace f_i(x) + \\frac{1}{2\u03bc_i} ||x - y||^2 \\rbrace ,$\n\n$X_{\u03bcg_i} (y) := \\underset{x \\in \\mathbb{R}^P}{arg \\ minimize} \\lbrace g_i(x) + \\frac{1}{2\u03bc_i} ||x - y||^2 \\rbrace$.\n\nDefine, $m_f := \\underset{1 \\leq i \\leq n}{max} m_{f_i}$. Given, $0 < \u03bc < 1/m_f$, let $F_{i,\u03bc}(x) := M_{\u03bcf_i} (x) \u2212 M_{\u03bcg_i} (x)$, and\n\n$F_\u03bc(x) := \\frac{1}{n} \\sum_{i=1}^n F_{i,\u03bc}(x) = \\frac{1}{n} \\sum_{i=1}^n (M_{\u03bcf_i}(x) \u2212 M_{\u03bcg_i}(x))$.\n\nNext, we summarize the properties of $F_{i,\u03bc}$, the Moreau envelops $M_{\u03bcf_i}, M_{\u03bcg_i}$ the mappings $X_{\u03bcf_i}, X_{\u03bcg_i}$.\nLemma 1. ([31], Properties of Moreau envelops and proxi-mal mappings) Let Assumption 1 holds. Let $0 < \u03bc < 1/m_f$ and $M_{\u03bcf_i}, M_{\u03bcg_i}, X_{\u03bcf_i}, X_{\u03bcg_i}$ be given by definitions (4)-(7)"}, {"title": "II. PROPOSED METHODOLOGY", "content": "at any agent $i$ in are summarized in the next equations:\n\n$z_i^{(k+1)} = y_i^{(k)} \u2013 \u03b1 \\nabla F_{i,\u03bc}(y_i^{(k)})$\n\n$= y_i^{(k)} - \u03b1 (\\nabla M_{\u03bcf_i} (y_i^{(k)}) - \\nabla M_{\u03bcg_i} (y_i^{(k)}))$\n\n$= y_i^{(k)} - \\frac{\u03b1}{\u03bc} (X_{\u03bcg_i} (y_i^{(k)}) - X_{\u03bcf_i} (y_i^{(k)}))$\n\n$y_i^{(k+1)} = w_i^{(k+1)}$, where\n\n$||w_i^{(k+1)} - \\hat{z}^{(k+1)}|| \\leq \u03b7^{(k+1)}, \\hat{z}^{(k+1)} = \\frac{1}{n} \\sum_{i=1}^n z_i^{(k+1)}$\n\nwhere, $w_i^{(k+1)}$ is the output of the n-consensus protocol and is an approximate estimate of the average $z_i^{(k+1)}$, tk denotes the number of communication steps utilized by the n-consensus protocol at iteration k of the DDC-Consensus algorithm. We summarize DDC-Consensus in Algorithm 1."}, {"title": "C. Finite-time n-consensus Protocol", "content": "The finite-time n-consensus protocol and its variants are proposed in earlier articles [34]\u2013[38] by the authors under various practical scenarios. Here, we resort to consensus with vector-valued states [37], [38]. Consider, a set of n agents connected via a directed graph $G(V,E)$. The finite-time \u03b7-consensus protocol aims to design a distributed protocol so that the agents can compute an approximate estimate of the average, $\\hat{u} := \\frac{1}{n} \\sum_{i=1}^n u_i^{(0)}$, of their initial states $u_i^{(0)}$ in finite-time. This approximate estimate is parameterized by a small tolerance \u03b7 chosen apriori to make the estimate precise. In the n-consensus protocol, the agents maintain state variables $u_i^{(k)} \u2208 \\mathbb{R}^P$, $v_i^{(k)} \u2208 \\mathbb{R}$ and update them as:\n\n$u_i^{(k)} = \\sum_{j \\in N_i^{-1}} P_{ij}u_j^{(k-1)}$\n\n$v_i^{(k)} = \\sum_{j \\in N_i^{-1}} P_{ij}v_j^{(k-1)}$\n\n$w_i^{(k)} = \\frac{u_i^{(k)}}{v_i^{(k)}}$,\n\nwhere, $w_i^{(k)} = u_i^{(k)}, v_i^{(0)} = 1$ for all $i \u2208 V and $N_i^-$ denotes the set of in-neighbors of agent i. The updates (15)-(17) are based on the push-sum (or ratio consensus) updates (see [39]). The following assumption on the graph G(V,E) and weight matrix P := $[p_{ij}]$ is made:"}, {"title": "III. CONVERGENCE ANALYSIS FOR DDC-CONSENSUS", "content": "Let the average of the optimization variables at iteration k be denoted as: $\\hat{y}^{(k)} := \\frac{1}{n} \\sum_{i=1}^n y_i^{(k)}$. Denote the gradient of the function $\\sum_{i=1}^n F_{i,\u03bc}$ evaluated at individual optimiza-tion variables of all the agents and the average $\\hat{y}^{(k)}$ as:\n\n$h^{(k)} := \\frac{1}{n} \\sum_{i=1}^n \\nabla F_{i,\u03bc}(y_i^{(k)}), and$\n\n$\\hat{h}^{(k)} := \\frac{1}{n} \\sum_{i=1}^n \\nabla F_{i,\u03bc}(\\hat{y}^{(k)})$\n\nrespectively. A consequence of the n-consensus protocol is that the difference between $h^{(k)}$ and $\\hat{h}^{(k)}$ is bounded.\nLemma 3. Let $y^{(k)}$ denote the consensus tolerance in the DDC-Consensus algorithm at iteration k, then\n||h(k) \u2013 \u0125(k) || \u2264 2L\u00b5F\u03b7(k),\nwhere $L_{\u03bcF}$ is the constant as defined in Lemma 1.\nProof. Note that,\n||h(k) (k) || = \\frac{1}{n}||\\sum_{i=1}^n \\nabla F_{i,\u03bc}(y_i^{(k)}) - \\sum_{i=1}^n \\nabla F_{i,\u03bc}(\\hat{y}^{(k)})||\\frac{1}{\u03bc}|| (\\sum_{i=1}^n (X_{\u03bcg_i} (y_i^{(k)}) - X_{\u03bcf_i} (y_i^{(k)})) - \\sum_{i=1}^n (X_{\u03bcg_i} (\\hat{y}^{(k)}) - X_{\u03bcf_i} (\\hat{y}^{(k)})) ||\n\n=(\\sum_{i=1}^n \\nabla M_{\u03bcf_i} (y_i^{(k)}) - \\sum_{i=1}^n \\nabla M_{\u03bcg_i} (\\hat{y}^{(k)}))||\\\n\\\\=\\frac{1}{\u03bc}|| (\\sum_{i=1}^n (\\hat{y}^{(k)} - X_{\u03bcf_i} (y_i^{(k)}) - \\sum_{i=1}^n (\\hat{y}^{(k)} - X_{\u03bcg_i} (\\hat{y}^{(k)})) ||\n< \\frac{2-\u03bcm_f}{\u03bc(\u03bc-\u03bc^2m_f)} \\frac{1}{n}\\sum_{i=1}^n ||y_i^{(k)} \u2013 \\hat{y}^{(k)}|| \\leq 2L_{\u03bcF}\u03b7^{(k)},\"\n\n\""}, {"title": "IV. NUMERICAL SIMULATIONS", "content": "This section presents a simulation study for the proposed DDC-Consensus algorithm. We consider a network of 10 agents with the underlying communication network gener-ated using the Erdos-Renyi model [41] with a connectivity probability of 0.2. We consider a $l_1\u20132$ regularized distributed least squares problem [28]:\n\n$\\underset{x \\in \\mathbb{R}^P}{minimize} \\frac{1}{10} \\sum_{i=1}^{10} || A_i x - b_i||^2 + \u03c1||x||_1 - \u03c1||x||_2$.\n\nThe problem data is generated as follows: first, we create the data matrices $A_i \u2208 \\mathbb{R}^{m\u00d7P}$, for all $i$, with entries generated from the standard Gaussian distribution. Then the columns of the matrices are normalized to the unit norm. We generate $x^* \u2208 \\mathbb{R}^P$ such that $x^*$ is a sparse vector with s non-zero entries. The non-zero entries of $x^*$ are drawn from the standard Gaussian distribution. Finally, the vectors $b_i \u2208 \\mathbb{R}^m$ are determined as $b_i = A_i x^* + 0.01\u03be_i$, where, $\u03be_i \u2208 \\mathbb{R}^m$ has standard Gaussian entries. $F^* :=\n$\\frac{1}{10} \\sum_{i=1}^{10} || A_i x^* - b_i||^2 + \u03c1||x^*||_1 - \u03c1||x^*||_2$. The parameters used during the simulations are: m = 720, p = 2560, \u03c1 = 0.1, \u03b1 = 0.01, \u03bc = 1/\u03bbmax($A_i^T A_i$), where \u03bbmax(M) is the maximum eigenvalue of matrix M. We choose $\u03b7(k) = 1/k^{1.1}$ as the tolerance sequence in Algorithm 1.\nWe compare the performance of the proposed algorithm DDC-Consensus with its following two relaxations: (i) DDC-Consensus-Inexact-q, where we solve the min-imization problems (4) and (5) inexactly via a gradient descent method for q iterations, (ii) DDC-Mixing, where the n-consensus is replaced with one step mixing (applying one iteration of the updates (15)-(17) to yi estimates of the optimization algorithms). To demonstrate the performance of the proposed algorithm we present utilize the following resid-ual metrics: Solution Residual(k): $ \\frac{1}{10} \\sum_{i=1}^{10} \\sum_{j=1}^{10} || y_i^{(k)} - \\hat{y}^{(k)}||^2$, Sta-tionarity Residual(k): $\\frac{1}{10} \\sum_{i=1}^{10} || X_{\u03bcg_i} (y_i^{(k)}) - X_{\u03bcf_i} (y_i^{(k)}) ||^2$, Objective Residual(k): $F(\\hat{y}^{(k)}) - F^*$, Consensus Resid-ual(k): $\\frac{1}{10} \\sum_{i=1}^{10} \\sum_{j=1}^{10} || y_i^{(k)} - y_j^{(k)}||^2$.\nA. Comparison with DDC-Consensus-Inexact-q\nFigs. 1-3 demonstrate the performance comparisons between the proposed DDC-Consensus algorithm and"}, {"title": "B. Comparison with DDC-Mixing", "content": "Figs. 4-7 present comparison plots showing the different metrics for both the DDC-Consensus and DDC-Mixing algorithms.\nThe simulation study in this section aims to study the effect of the agreement quality between the agent estimates in the DDC-Consensus algorithm on its performance. The DDC-Mixing algorithm uses only one information exchange step among the agents and is theoretically the lower bound on information aggregation. Note, that both DDC-Consensus and DDC-Mixing algorithms perform exact proximal minimization steps.\nFigs. 4-6 show that the n-consensus protocol allows for a higher degree of agreement between the agent estimates during the algorithm iterations lead to better convergence properties of the proposed DDC-Consensus algorithm compared to the DDC-Mixing algorithm. Furthermore, the \u03b7-consensus protocol adaptively controls the agent mismatch and leads to the consensus constraint satisfaction at every iterate of the proposed DDC-Consensus algorithm as seen in Fig. 7."}, {"title": "V. CONCLUSION", "content": "We focused on a distributed DC optimization problem with local objective functions given by the difference between a nonsmooth weakly convex function and a nonsmooth convex function. Based on the gradient of the smooth approxi-mations of the weakly convex and convex functions we developed the distributed DDC-Consensus algorithm. In the DDC-Consensus algorithm each agent performs a local gradient descent step and updates its estimates using a finite-time n-consensus protocol. The agent estimates are shared over a directed graph and updated via a column stochastic matrix; giving DDC-Consensus the desirable properties of allowing for non-symmetric communication and distributed synthesis. We established that the DDC-Consensus algo-rithm converges to a stationary point of the nonconvex dis-tributed optimization problem. The numerical performance of the DDC-Consensus algorithm is presented in a simu-lation study solving the DC-regularized least squares prob-lem. Results showing the behavior of DDC-Consensus and its relaxations DDC-Consensus-Inexact-q and DDC-Mixing concerning the residual metrics demonstrate the efficacy of the proposed DDC-Consensus algorithm."}]}