{"title": "DIALOGUE-BASED EXPLANATIONS FOR LOGICAL REASONING USING STRUCTURED ARGUMENTATION", "authors": ["LOAN HO", "STEFAN SCHLOBACH"], "abstract": "The problem of explaining inconsistency-tolerant reasoning in knowledge bases (KBs) is a prominent topic in Artificial Intelligence (AI). While there is some work on this problem, the explanations provided by existing approaches often lack critical information or fail to be expressive enough for non-binary conflicts. In this paper, we identify structural weaknesses of the state-of-the-art and propose a generic argumentation-based approach to address these problems. This approach is defined for logics involving reasoning with maximal consistent subsets and shows how any such logic can be translated to argumentation. Our work provides dialogue models as dialectic-proof procedures to compute and explain a query answer wrt inconsistency-tolerant semantics. This allows us to construct dialectical proof trees as explanations, which are more expressive and arguably more intuitive than existing explanation formalisms.", "sections": [{"title": "1. INTRODUCTION", "content": "This paper addresses the problem of explaining logical reasoning in (inconsistent) KBs. Several approaches have been proposed by [18, 17, 22, 24], which mostly include set-based explanations and proof-based explanations. Set-based explanations, which are responsible for the derived answer, are defined as minimal sets of facts in the existential rules [18, 17] or as causes in Description Logics (DLs) [22]. Additionally, the work in [22] provides the notion of conflicts that are minimal sets of assertions responsible for a KB to be inconsistent. Set-based explanations present the necessary premises of entailment and, as such, do not articulate the (often non-obvious) reasoning that connects those premises with the conclusion nor track conflicts. Proof-based explanations provide graphical representations to allow users to understand the reasoning progress better [24]. Unfortunately, the research in this area generally focuses on reasoning in consistent KBs.\nThe limit of the above approaches is that they lack the tracking of contradictions, whereas argumentation can address this issue. Clearly, argumentation offers a potential solution to address inconsistencies. Those are divided into three approaches:\n\u2022 Argumentation approach based on Deductive logic: Various works propose instantiations of abstract argumentation (AFs) for Datalog\u2260 [19, 35], Description Logic [14] or Classical Logic [51], focusing on the translation of KBs to argumentation without considering explanations. In [7], explanations can be viewed as dialectical trees defined abstractly, requiring a deep"}, {"title": "2", "content": "understanding of formal arguments and trees, making the work impractical for non-experts. In [35, 9], argumentation with collective attacks is proposed to capture non-binary conflicts in Datalog\u00b1, i.e., assuming that every conflict has more than two formulas.\n\u2022 Sequent-based argumentation [69] and its extension (Hypersequent-based ar- gumentation) [55], using Propositional Logic, provide non-monotonic ex- tensions for Gentzen-style proof systems in terms of argumen-tation-based. Moreover, the authors conclude by wishing future work to include \"the study of more expressive formalisms, like those that are based on first-order logics\" [69].\n\u2022 Rule-based argumentation: DeLP/DeLP with collective attacks are intro- duced for defeasible logic programming [45, 70]. However, in [35], the au- thors claim that they cannot instantiate DeLP for Datalog\u2260, since DeLP only considers ground rules. In [46, 62], ASPIC/ASPIC+ is introduced for defeasible logic. Following [61], the logical formalism in ASPIC+ is ill-defined, i.e., the contrariness relation is not general enough to consider n-ary constraints. This issue is stated in [35] for Datalog, namely, the ASPIC+ cannot be directly instantiated with Datalog. The reasons be- hind this are that Datalog does not have the negation and the contrariness function of ASPIC+ is not general for this language.\nNotable works include assumption-based argumentation (ABA) [44] and ABA with collective attack [53], which are applied for default logic and logic programming. However, ABAs ignore cases of the inferred assumptions conflicting, which is allowed in the existential rules, Description Logic and Logic Programming with Negation as Failure in the Head. We call the ABAS \"flat ABAs\". In [41], \"flat\" ABAs link to Answer Set Programming but only consider a single conflict for each assumption. In [67, 68], \" Non- flat\" ABAs overcome the limits of \"flat\" ABAs, which allow the inferred assumptions to conflict. However, like ASPIC+, the non-flat ABAs ignore the n-ary constraints case. Contrapositive ABAs [65] and its collective attack version [63], which use contrapositive propositional logic, propose extended forms for 'flat' and 'non-flat' ABAs. While [63] mainly focuses on representation (which can be simulated in our setting, see Section 3.2), we extend our study to proof procedures in AFs with collective attacks.\nArgumentation offers dialogue games to determine and explain the acceptance of propositions for classical logic [50], for Datalog\u2260 [33, 34, 20, 19], for logic program- ming/ default logic [48, 47], and for defeasible logic [42]. However, the models have limitations. In [33, 34], the dialogue models take place between a domain expert but are only applied to a specific domain (agronomy). In [20, 19, 42, 50], persuasion dialogues (dialectic proof procedures) generate the abstract dispute trees defined abstractly that include arguments and attacks and ignore the internal structure of the argument. These works lack exhaustive explanations, making them insufficient for understanding inference steps and argument structures. The works in [43, 13] provide dialectical proof procedures, while the works [47, 48] offer dialogue games (as a distributed mechanism) for \"flat\" ABAs to determine sentence acceptance under (grounded/ admissible/ ideal) semantics. Although the works in [47, 48] are similar to our idea of using dialogue and tree, these approaches do not generalize to n-ary conflicts."}, {"title": "3", "content": "The existing studies are mostly restricted to (1) specific logic or have limitations in representation aspects, (2) AFs with binary conflicts, and (3) lack exhaustive explanations. This paper addresses the limitations by introducing a general framework that provides dialogue models as dialectical proof procedures for acceptance in structured argumentation. The following is a simple illustration of how our approach works in a university example.\nExample 1.1. Consider inconsistent knowledge about a university domain, in which we know that: lecturers (Le) and researchers (Re) are employers (Em); full professors (FP) are researchers; everyone who is a teaching assistant (ta0f) of an undergraduate course (UC) is a teaching assistant (TA); everyone who teaches a course is a lecturer and everyone who teaches a graduate course (GC) is a full professor. However, teaching assistants can be neither researchers nor lecturers, which leads to inconsistency. We also know that an individual Victor apparently is or was a teaching assistant of the KD course (taOf(v, KD)), and the KD course is an undergraduate course (UC(KD)). Additionally, Victor teaches either the KD course (te(v, KD)) or the KR course (te(v, KR)), where the KR course is a graduate course (GC(KR)). The KB K\u2081 is modelled as follows:\nF\u2081 ={taOf(v, KD), te(v, KD), UC(KD), te(v, KR), GC(KR)}\nR1 ={r1: Le(x) \u2192 Em(x), r2: Re(x) \u2192 Em(x),\nr3: FP(x) \u2192 Re(x), r4: taof(x, y)^UC(y) \u2192 TA(x),\nr5: te(x,y) \u2192 Le(x), r6 : te(x, y) \u2227 GC(y) \u2192 FP(x)}\nC\u2081 ={C1: TA(x)^ Re(x) \u2192 \u22a5,C2: Le(x)\u2227TA(x) \u2192 \u22a5}\nWhen a user asks \"Is Victor a researcher?\", the answer will be \" Yes, but Victor is possibly a researcher\u201d. The current method [18, 17, 22] will provide a set-based ex- planation consisting of (1) the cause {te(v, KR), GC(KR)} entailing the answer (why the answer is accepted) and (2) the conflict {taOf(v, KD), UC(KD)} being inconsis- tent with every cause (why the answer cannot be accepted). The cause, though, does not show a series of reasoning steps to reach Re(v) from the justification {te(v, KR), GC(KR)}. The conflict still lacks all relevant information to explain this result. Indeed, in the KB, the fact te(v, KD) deducing Le(v) makes the conflict {taOf(v, KD), UC(KD)} deducing TA(v) uncertain, due to the constraint that lectur- ers cannot be teaching assistants. Thus, using the conflict in the explanation is insufficient to assert the non-acceptance of the answer. It remains unclear why the answer is possible. Instead, te(v, KD) deducing Le(v) should be included in the explanation. Without knowing the relevant information, it is impossible for the user - especially non-experts in logic to understand why this is the case.\nHowever, using the argumentation approach will provide a dialogical explanation that is more informative and intuitive. The idea involves a dialogue between a proponent and opponent, where they exchange logical formulas to a dispute agree. The proponent aims to prove that the argument in question is acceptable, while the opponent exhaustively challenges the proponent's moves. The dialogue where the proponent wins represents a proof that the argument in question is accepted. The dialogue whose graphical representation is shown in Figure 4 proceeds as follows:\n1. Suppose that the proponent wants to defend their claim Re(v). They can do so by putting forward an argument, say A1, supported by facts te (v, KR) and"}, {"title": "4", "content": "GC(KR):\nA1: Re(v) (by r3)\nFP(v)(by r6)\nte(v, KR), GC(KR)(by facts)\nProponent: I believe that v is a researcher because he is a full professor; and given the fact that he teaches the KR course and KR is a graduate course.\n2. The opponent challenges the proponent's argument by attacking the claim Re(v) with an argument TA(v), say A2, supported by facts taOf(v, KD) and UC(KD):\nA2: TA(v)(by r4)\ntaOf(v, KD), UC(KD)(by facts)\nOpponent: v is not possibly a researcher because v is a TA given the fact that he is a TA of the KD course and KD is an undergraduate course.\n3. To argue that the opponent's attack is not possible and to further defend the initial claim Re(v) - the proponent can counter the opponent's argument by providing additional evidence Le(v) supported by a fact te(v, KD):\nA3: Le(v) (by r5)\nte(v, KD) (by facts)\nProponent: v is not possibly a TA because v is certainly a lecturer given the fact that he teaches the KD course.\n4. The opponent concedes Re(v) since it has no argument to argue the proponent.\nOpponent: I concede that v is a researcher because I have no argument to argue that v is neither a lecturer nor researcher.\nThe proponent's belief Re(v) is defended successfully, namely, Re(v) that is justified by facts {te(v, KR), GC(KR)} that be extended to be the defending set {te(v, KR), GC(KR), te(v, KD)} that can counter-attack every attack.\nBy the same line of reasoning, the opponent can similarly defend their belief in the contrary statement TA(v) based on the defending set {taOf(v,KD), UC(KD)}. Because different agents can hold contrary claims, the acceptance semantics of the answer can be considered credulous rather than sceptical. In other words, the answer is deemed possible rather than plausible. Thus, the derived system can conclude that v is possibly a researcher.\nThe main contributions of this paper are the following:\n\u2022 We propose a proof-oriented (logical) argumentation framework with collective attacks (P-SAF), in which we consider abstract logic to generalize monotonic and non-monotonic logics involving reasoning with maximal consistent subsets, and we show how any such logic can be trans- lated to P-SAFs. We also conduct a detailed investigation of how existing argumentation frameworks in the literature can be instantiated as P-SAFs. Thus, we demonstrate that the P-SAF framework is sufficiently generic to encode n-ary conflicts and to enable logical reasoning with (inconsistent) KBs."}, {"title": "5", "content": "\u2022 We introduce a novel explanatory dialogue model viewed as a dialec- tical proof procedure to compute and explain the credulous, grounded and sceptical acceptances in P-SAFs. The dialogues, in this sense, can be re- garded as explanations for the acceptances. As our main theoretical result, we prove the soundness and completeness of the dialogue model wrt argu- mentation semantics.\n\u2022 This novel explanatory dialogue model provides dialogical explanations for the acceptance of a given query wrt inconsistency-tolerant semantics, and dialogue trees as graphical representations of the dialogical expla- nations. Based on these dialogical explanations, our framework assists in understanding the intermediate steps of a reasoning process and enhancing human communication on logical reasoning with inconsistencies.\n2. PRELIMINARIES\nTo motivate our work, we review argumentation approaches using Tarski ab- stract logic characterized by a consequence operator [71]. However, many logic in argumentation systems, like ABA or ASPIC systems, do not always impose certain axioms, such as the absurdity axiom. Defining the consequence operator by means of \"models\" cannot allow users to understand reasoning progresses better, as infer- ence rule steps are implicit. These motivate a slight generalization of consequence operators in a proof-theoretic manner, inspired by [72], with minimal properties.\nMost of our discussion applies to abstract logics (monotonic and non-monotonic) which slightly generalize Tarski abstract logic. Let L be a set of well-formed for- mulas, or simply formulas, and X be an arbitrary set of formulas in C. With the help of inference rules, new formulas are derived from X; these formulas are called logical consequences of X; a consequence operator (called closure operator) returns the logical consequences of a set of formulas.\nDefinition 2.1. We define a map CN : 2\u00a3 \u2192 2\u00a3 such that CN(X) = Un\u22650 CN (X) satisfies the axioms:\n\u2022 (A1) Expansion X \u2286 CN(X).\n\u2022 (A2) Idempotence CN(CN(X)) = CN(X).\nIn general, a map 2\u00a3 \u2192 2\u00a3 satisfying these axioms A1 - A2 is called a consequence operator. Other properties that consequence operators might have, but that we do not require in this paper, are\n\u2022 (A3) Finiteness CN(X) \u2286 \u222a{CN(Y) | Y Cf X} where the notation Y Cf X means that Y is a finite proper subset of X.\n\u2022 (A4) Coherence CN(\u00d8) \u2260 L.\n\u2022 (A5) Absurdity CN({x}) = L for some x in the language L.\nNote that finiteness is essential for practical reasoning and is satisfied by any logic that has a decent proof system.\nAn abstract logic includes a pair L and a consequence operator CN. Different logics have consequence operators with various properties that can satisfy certain axioms. For instance, the class of Tarskian logics, such as classical logic, is defined by a consequence operator satisfying A1 - A5 while the one of defeasible logic satisfies A1 - \u0410\u0437.\nExample 2.2. An inference ruler in first-order logic is of the form P1,...,Pn where its conclusion is c and the premises are p1,..., Pn. cis called a direct consequence"}, {"title": "6", "content": "of p1,..., Pn by virtue of r. If we define CN(X) as the set of direct consequences of XCL, then CN coincides with CN(X) = {a \u2208 L | X + a} and satisfies the axioms A1 - A5.\nFix a logic (L, CN) and a set of formulas XC L. We say that:\n\u2022 X is consistent wrt (L, CN) iff CN(X) \u2260 L. It is inconsistent otherwise;\n\u2022 X is a minimal conflict of K if X' C X implies X' is consistent.\n\u2022 A knowledge base (KB) is any subset K of L. Formulas in a KB are called facts. A knowledge base may be inconsistent.\nReasoning in inconsistent KBs KC Lamounts to:\n(1) Constructing maximal consistent subsets,\n(2) Applying classical entailment mechanism on a choice of the maximal con- sistent subsets.\nMotivated by this idea, we give the following definition.\nDefinition 2.3. Let K be a KB and X C K be a set of formulas. X is a maximal (for set-inclusion) consistent subsets of K iff\n\u2022 X is consistent,\n\u2022 there is no X' such that X CX' and X' is consistent.\nWe denote the set of all maximal consistent subsets by MCS(K).\nInconsistency-tolerant semantics allow us to determine different types of entail- ments.\nDefinition 2.4. Let K be a KB. A formula \u2208 Lis entailed in\n\u2022 some maximal consistent subset iff for some \u2206\u2208 MCS(K), \u0444\u2208 CN(\u2206);\n\u2022 the intersection of all maximal consistent subsets iff for \u03a8 = {\u0394 | \u0394 \u2208 MCS(K)}, \u2208 CN(\u03a8);\n\u2022 all maximal consistent subsets iff for all \u2206 \u2208 MCS(K), \u0444\u2208 CN(A).\nInformally, some maximal consistent subset semantics refers to possible an- swers, all maximal consistent subsets semantics to plausible answers, and the intersection of all maximal consistent subsets semantics to surest answers.\nIn the following subsections, we illustrate the generality of the above definition by providing instantiations for propositional logic, defeasible logic, Datalog\u00b1.\n2.1. Classical Logic. We assume familiarity with classical logic. A logical lan- guage for classical logic L is a set of well-formed formulas. Let us define CN: 2\u00a3c \u2192 2\u00a3c as follows: For X C Le, a formula x \u2208 Le satisfies x \u2208 CN(X) iff the"}, {"title": "7", "content": "inference rule is applied to X such that y \u2208 X. Define CNC(X) = Un\u22650 CN(X).\nIn particular, CN is a consequence operator satisfying A1 A5. Examples of classical logic are propositional logic and first-order logic. Next, we will consider propositional logic as being given by our abstract notions. Since first-order logic can be similarly simulated, we do not consider here in detail.\nWe next present propositional logic as a special case of classical logic. Let A be a set of propositional atoms. Any atoms a \u2208 A is a well-formed formula wrt. A. If and a are well-formed formulas wrt. A then \u00ac\u0444, \u0444\u2227\u03b1, \u03c6\u03bd\u03b1 are well-formulas wrt. A (we also assume that the usual abbreviations \u2283, \u2194 are defined accordingly). Then Lp is the set of well-formed formulas wrt. A.\nLet CNp: 2\u00a3p \u2192 2\u00a3p be defined as follows: for X \u2286 Lp, an element x \u2208 Lp satisfies x \u2208 CN(X) iff there are y1,..., Y; \u2208 X such that x can be obtained from y1,..., yj by the application of a single inference rule of propositional logic.\nExample 2.5. Consider the propositional atoms A\u2081 = {x,y} and the knowledge base K\u2081 = {x,y,x \u2283 \u00aby} \u2286 Lp. Consider a set {x,x \u2283 \u00aby} \u2286 K\u2081 . If the inference rule (modus ponens) A,ADB is applied to this set, then CN\u2081({x, x \u2283 \u00aby}) = {x,x \u00aby,y}.\nConsider CN\u2082(X) = Un>0 CN(X). For instance, CN\u2082(K1) = {x,y,x \u2283 \u00aby, \u00aby,x\u2227 y,...}. Since propositional logic is coherent and complete, then x \u2208 CN(X) = {x | X = x} where is the entailment relation, i.e., $ = a if all models of & are models of a in the propositional semantics. In particular, CNp is a consequence operator satisfying A1 - A5. The propositional logic can be defined as (Lp, CNp). It follows immediately\nLemma 2.6. (Lp, CNp) is an abstract logic.\nExample 2.7 (Continue Example 2.5). Recall K\u2081. The KB admits a MCS: {x,y,x\u2283\u00acy}.\n2.2. Defeasible Logic. Let (La, CNd) be a defeasible logic such as used in defea- sible logic programming [45], assumption-based argumentation (ABA) [44], AS- PIC/ASPIC+ systems [46, 62]. The language for defeasible logic La includes a set of (strict and defeasible) rules and a set of literals. The rules is the form of X1,...Xi \u2192s Xi+1 (X1,...Xi \u2192d Xi+1) where x1,...Xi,Xi+1 are literals and \u2192s (denote strict rules) and \u2192a (denotes defeasible rules) are implication symbols.\nDefinition 2.8. Define CN\u300f:2\u00a3d \u2192 2\u00a3d as follows: for X \u2286 La, a formula x \u2208 Ld satisfies x \u2208 CNa(X) iff at least of the following properties is true:\n(1) x is a literal in X,\n(2) there is (y1,\u2026\u2026\u2026,Yj) \u2192s x \u2208 X, or (y1,..., yj) \u2192d x \u2208 X st. {91,...,yj} \u2286 X.\nDefine C\u00d1a(X) = Un\u22650 CN (X).\nRemark 2.9. One can describe CN\u0105 explicitly. We have x \u2208 CN(X) iff there exists a finite sequence of literals x1,...,In such that\n(1) x is xn, and\n(2) for each xi \u2208 {X1,...,Xn},\n\u2022 there is y1,...,Yj \u2192s Xi \u2208 X, or Y1,...,Yj \u2192d_Xi \u2208 X, such that {Y1,...,Yj} {X1,..., Xi\u22121},"}, {"title": "8", "content": "\u2022 or x is a literal in X.\nNote that if x \u2208 CN(X), the above sequence x1,..., In might have length m \u2260 n: intuitively n is the depth of the proof tree while m is the number of nodes.\nExample 2.10. Consider the KB K2 = {x,x \u2192s y,t \u2192d z} \u2286 Ld. CNa(K2) = {x,y} where the sequence of literals in the derivation is x,y. The KB admits a MCS: {x, x \u2192sy,t\u2192d z}\nRemark 2.11. For ASPIC/ASPIC+ systems [46, 62], Prakken claimed that strict and defeasible rules can be considered in two ways: (1) they encode information of the knowledge base, in which case they are part of the logical language La, (2) they represent inference rules, in which case they are part of the consequence operator. These ways can encoded by consequence operators as in [61]. Our definition of CNd can align with the later interpretation as done in [61]. In particular, if we consider X being a set of literals of La instead of being a set of literals and rules as above, the definitions of CNd and CNd still hold for this case. Thus, the defeasible logic of ASPIC/ASPIC+ can be represented by the logic (La, CNa) in our settings.\nProposition 2.12 ([61]). CNd satisfies A1 \u0410\u0437.\nIt follows immediately\nLemma 2.13. (La, CNa) is an abstract logic.\nIn [64], proposals for argumentation using defeasible logic were criticized for violating the postulates that they proposed for acceptable argumentation. One solution is to introduce contraposition into the reasoning of the underlying logic. This solution can be seen as another representation of defeasible logic. We introduce contraposition by defining a consequence operator as follows:\nConsider Lco containing a set of literal and a set of (strict and defeasible) rules Rs (Rd). For this case represent inference rules, namely, they are part of a consequence operator. For A \u2286 Lco, Contrapositives(\u25b3) is the set of contrapositives formed from the rules in A. For instance, a strict rules is a contraposition of the rule \u03a61,..., \u03a6\u03b7 \u2192s a \u2208 Rs iff s = $1,\u00b7\u00b7\u00b7, \u03a6i\u22121, \u00ac\u03b1, \u03a6i+1,\u00b7\u00b7\u00b7, \u03a6\u03b7\u2192s\u00ac\u00a2i for 1 \u2264 i \u2264 n.\nDefinition 2.14. Define CNco: 2\u00a3co \u2192 2\u00a3co as follows: for a set of literals X \u2286 Lco, a formula x \u2208 Lco satisfies x \u2208 CN(X) iff at least of the following properties is true:\n(1) x is a literal in X,\n(2) there is (y1,\u06f0\u06f0\u06f0,Yj) \u2192s x \u2208 RU Contrapositives(Rs), or (Y1,...,Yj) \u2192d x \u2208 Rd U Contrapositives(Ra) such that (y1, . . ., Yj } \u2286 X.\nDefine CNC (X) = Un\u22650 CN(X).\nRemark 2.15. Similarly, one can represent CNco as follows: x \u2208 CNco(X) iff there exists a sequence of literals X1,..., In such that\n(1) x is xn, and\n(2) for each xi \u2208 {X1,...,Xn},\n\u2022 there is y1,...,Yj \u2192s Xi \u2208 R\u016aContrapositives(Rs), or y1,...,Yj \u2192d Xi \u2208 RaUContrapositives(Ra), such that {y1,...,Yj } \u2286 {x1,..., Xi\u22121},\n\u2022 or x is a literal in X.\nProposition 2.16. (Lco, CNco) is an abstract logic. CNco satisfies A1 \u0410\u0437."}, {"title": "9", "content": "Example 2.17. Consider K3 = {q, \u00abr,p^q \u2192ar, \u00abp \u2192s u}, Contrapositives(K3) = {\u00abr^q\u2192d\u00abp, \u00abr^p \u2192a \u00abq, \u00abu \u2192sp}. Then CNco(K3) = {q, \u00abr, \u00abp, u} where the sequence of literals in the derivation is q, \u00acr, \u00abp, u. The KB admits MCSs: {q, \u00abr, \u00abp \u2192su} and {q,p^q \u2192ar, \u00abp \u2192s u}.\n2.3. Datalog. We consider Datalog\u2260 [26], and shall use it to illustrate our demon- strations through the paper.\nWe assume a set Nt of terms which contain variables, constants and function terms. An atom is of the form P(t), with Pa predicate name and \u0165a vector of terms, which is ground if it contains no variables. A database is a finite set of ground atoms (called facts). A tuple-generating dependency (TGD) \u03c3is a first- order formula of the form V\u00e6\u2200\u1ef9\u00a2(x, y) \u2192 \u2203Z4(x, Z), where (x, y) and (Z, Z) are non-empty conjunctions of atoms. We leave out the universal quantification, and refer to $(x, y) and (Z, Z) as the body ad head of \u03c3. A negative constraint (NC) d is a rule of the form V\u0129 (x) \u2192 | where (3) is a conjunction of atoms. We may leave out the universal restriction. A language for Datalog\u2260Lda includes a set of facts and a set of TGDs and NCs. A knowledge base K of Lda is now a tuple (F, R, C) where a database F, a set R of TGDs and a set C of NCs.\nDefine CNda: 2\u00a3da \u2192 2\u00a3da as follows: Let X be a set of facts of Lda, an element x \u2208 Lda satisfies x \u2208 CNda(X) iff there are y1,...,Yj \u2208 X s.t. x can be obtained from y1,..., yj by the application of a single inference rule. Note that we treat such TGDs and NCs as inference rules.\nConsider CNda (X) = Un\u22650 CNa(X). Similar to proposition logic, x \u2208 CNda(X) = {x | X = x} where = is the entailment of first-order formulas, i.e., X = x holds iff every model of all elements in X is also a model of x. CNda satisfies the properties A1, A2. Note that the finiteness property (A3) still holds for some fragments of Datalog\u2260, such as guarded, weakly guarded Datalog\u2260.\nIt follows immediately\nLemma 2.18. (Lda, CNda) is an abstract logic.\nExample 2.19 (Continue Example 1.1). Recall K\u2081. The KB admits MSCs (called repairs in Datalog\u00b1):\nB\u2081 = {taOf(v, KD), UC(KD)} B3 = {taOf(v, KD), te(v, KR), te(v, KD), GC(KR)}\nB2 = {te(v, KR), GC(KR), te(v, KD)} B\u2081 = {taOf(v, KD), te(v, KR), te(v, KD), UC(KD)}\nB5 = {GC(KR), te(v, KR), te(v, KD), UC(KD)} B6 = {UC(KD), taOf(v, KD), GC(KR)}\nConsider q1 = Re(v). We have that v is a possible answer for q1 since q1 is entailed in some repairs, such as B2, B3, B5.\n3. PROOF-ORIENTED (LOGICAL) ARGUMENTATIONS\nIn this section, we present proof-oriented (logical) argumentations (P-SAFs) and their ingredients. We also provide insights into the connections between our frame- work and state-of-the-art argumentation frameworks. We then show the close rela- tions of reasoning with P-SAFs to reasoning with MCSS.\n3.1. Arguments, Collective Attacks and Proof-oriented Argumentations. Logical arguments (arguments for short) built from a KB may be defined in different ways. For instance, arguments are represented by the notion of sequents [69], proof [41, 44], a pair of (\u0393, \u03c8) where \u0393 is the support, or premises, or assumptions"}, {"title": "10", "content": "of the argument, and 4 is the claim, or conclusion, of the argument [7, 33]. \u03a4\u03bf improve explanations in terms of representation and understanding, we choose the form of proof to represent arguments. The proof is in the form of a tree.\nDefinition 3.1. A formula & \u2208 Lis tree-derivable from a set of fact-premises HCK if there is a tree such that\n\u2022 the root holds ;\n\u2022 H is the set of formulas held by leaves;\n\u2022 for every inner node N, if N holds the formula Bo, then its successors hold n formulas \u03b21,..., \u03b2n such that \u03b2\u03bf \u2208 CN({\u03b21,..., \u03b2\u03b7}).\nIf such a tree exists (it might not be unique), we call A: H \u21d2 \u00a2 an argument with the support set Sup(A) = H and the conclusion Con(A) = 6. We denote the set of arguments induced from K by Argk\nRemark 3.2. By Definition 3.1 it follows that H \u21d2 \u00a2 is an argument iff & \u2208 CN(H).\nNote that an individual argument can be represented by several different trees (with the same root and leaves). We assume these trees represent the same argu- ments; otherwise, we could have infinitely many arguments with the same support set and conclusion.\nIntuitively, a tree represents a possible derivation of the formula at its root and the fact-premise made at its leaves. The leaves of the tree, constituting the fact- premise, belong to H = CN\u00b0(H). If a node \u03b2 has children nodes \u03b2\u03b1\u2081 \u2208 CN21(H), \u03b2\u03b1\u03ba \u2208 CN\u00b2k (H), then \u03b2 \u2208 CN\u00b2+1(X) where i = max{i1,...,ik} because by the extension property CN\u00b2\u00b9(H),...,CN\u00b2k(H) \u2286 CN\u00b2(H). The root 4, constituting the conclusion, belongs to CN\" (H), where n is the longest path from leaf to root.\nNote that, by the extension property, if \u03b2\u2208 CN\u00b2(H), then also \u03b2\u2208 CN\u00b2+1(H), \u03b2\u2208 CN\u00b2+2(H), The idea is to have i in CN\u00b2 (H) as small as possible (we don't want to argue longer than necessary).\nSome proposals for logic-based argumentation stipulate additionally that the ar- gument's support is consistent and/or that none of its subsets entails the argument's conclusion (see [56]). However, such restrictions, i.e., minimality and consistency, are not substantial (although required for some specific logics). In some proposals, the requirement that the support of an argument is consistent may be irrelevant for some logics, especially when consistency is defined by satisfiability. For instance, in Priest's three-valued logic [57] or Belnap's four-valued logic [58], every set of formulas in the language of {\u00ac, V, ^} is satisfiable. In frameworks in which the supports of arguments are represented only by literals (atomic formulas or their negation), arguments like A = {a,b} \u21d2 a V b are excluded since their supports are not minimal, although one may consider{a,b} a stronger support for a Vb than, say, {a}, since the set {a,b} logically implies every minimal support of a Vb. To keep our framework as general as possible, we do not consider the extra restrictions for our definition of arguments (See [56, 69] for further justifications of this choice).\nWe present instantiations to show the generality of Definition 3.1 for generating arguments in argumentation systems in the literature.\n\u2022 We start with deductive argumentation that uses classical logic. In [59], arguments as pairs of premises and conclusions can be simulated in our set- tings, and for which H \u21d2 \u00a2 is an argument (in the form of tree-derivations), where HCL and \u00a2 \u2208 Le iff \u00a2 \u2208 C\u00d1\u00bf(H), H is minimal (i.e., there is no H' CH such that \u2208 CN(H')) and H is consistent. For example, we use\""}, {"title": "11", "content": "the propositional logic in Example 2.5", "A": {"14": ".", "45": "."}, "45": "H \u21d2 \u00a2 is an argument (in the form of tree-derivations) iff & \u2208 CNa(H) and there is no H' CH such that \u2208 CNa(H') and it is not the case that there is a such that \u03b1\u2208 CN(H) and \u00aca \u2208 C\u00d1\u2084(H) (i.e. H is a minimal consistent"}]}