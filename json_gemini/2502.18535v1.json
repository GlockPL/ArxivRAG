{"title": "A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning", "authors": ["Zhizhi Peng", "Taotao Wang", "Chonghe Zhao", "Guofu Liao", "Zibin Lin", "Yifeng Liu", "Bin Cao", "Long Shi", "Qing Yang", "Shengli Zhang"], "abstract": "As machine learning technologies advance rapidly across various domains, concerns over data privacy and model security have grown significantly. These challenges are particularly pronounced when models are trained and deployed on cloud platforms or third-party servers due to the computational resource limitations of users' end devices. In response, zero-knowledge proof (ZKP) technology has emerged as a promising solution, enabling effective validation of model performance and authenticity in both training and inference processes without disclosing sensitive data. Thus, ZKP ensures the verifiability and security of machine learning models, making it a valuable tool for privacy-preserving AI. Although some research has explored the verifiable machine learning solutions that exploit ZKP, a comprehensive survey and summary of these efforts remain absent. This survey paper aims to bridge this gap by reviewing and analyzing all the existing Zero-Knowledge Machine Learning (ZKML) research from June 2017 to December 2024. We begin by introducing the concept of ZKML and outlining its ZKP algorithmic setups under three key categories: verifiable training, verifiable inference, and verifiable testing. Next, we provide a comprehensive categorization of existing ZKML research within these categories and analyze the works in detail. Furthermore, we explore the implementation challenges faced in this field and discuss the improvement works to address these obstacles. Additionally, we highlight several commercial applications of ZKML technology. Finally, we propose promising directions for future advancements in this domain.", "sections": [{"title": "I. INTRODUCTION", "content": "THE rapid advancement of artificial intelligence (AI) technologies, epitomized by machine learning (ML), has brought significant transformations to various aspects of human life. Recently, the emergence of generative AI models based on large models has introduced new opportunities in fields such as design and art, software development, publishing, and even finance. However, as model capabilities increase, the demand for computational power in machine learning grows exponentially, necessitating larger datasets and more extensive computational clusters for parallel training.\nAI business products like ChatGPT [1] and Midjourney [2] present impressive performance, relying not only on sophisticated machine learning models and efficient algorithms but also on substantial investments in data and computational resources for model training.\nDue to limitations in computational and data resources, ordinary users such as individuals, small and medium-sized institutions often cannot train ML models locally or even perform inference using trained models. To address this, ML service providers (for example, large companies like Google, Amazon, Alibaba, etc.) offer rental services for ML models, computational resources, and storage space, enabling customers to easily execute ML tasks and integrate them into their applications. For example, ML clients, i.e., individuals, small and medium-sized institutions, utilize Machine Learning as a Service (MLaaS) [3] engines to outsource complex ML models (such as deep neural networks ) training and inference tasks, and performing inferences with trained ML models; the ML service provider receive data from ML clients to execute the ML tasks.\nHowever, the above paradigm raises significant concerns regarding trust and data privacy between ML clients and ML service providers. On one hand, clients are particularly vulnerable due to the sensitive nature of their data, as evidenced by frequent and severe data breaches. Notable examples include the 2022 data breach involving the digital booking and scheduling platform FlexBooker, which resulted in the compromise of personal information for approximately 3.2 million users. Similarly, the theft of a database hosted on Alibaba Cloud exposed the personal information of 1 billion Chinese citizens, along with billions of police records, highlighting the alarming scale and impact of such incidents. Additionally, other issues include ML service providers using underperforming models for inferences while fabricating seemingly flawless results to their clients. As a consequence, clients are often unwilling to provide data containing private information to ML service providers. On the other hand, ML service providers are concerned about their machine learning models being stolen or maliciously compromised. For instance, attackers disguise themselves as clients to implant \u201cbackdoors\" into the ML service providers' models, causing it to perform well on normal samples but make specific erroneous inferences on inputs with particular backdoor triggers [4]. Another scenario is that the ML service providers are using a model trained on the wrong data, or using a poorly performing model to make predictions and faking a seemingly perfect result to deceive the client. In summary, due to the trust and data privacy concerns between clients and machine learning service providers, there is a need for privacy-preserving solutions that allow the encrypted data of clients to be used in machine learning tasks while preventing attacks and fraudulent activities on the models of ML service providers, serving trust assurances [5].\nRecently, it has been demonstrated that the technique of zero-knowledge proofs (ZKP) can effectively address the aforementioned issues. Consequently, ZKP has been proposed as a solution to implement a verifiable machine learning framework, known as zero-knowledge machine learning (ZKML). ZKP is a type of cryptographic technique that allows one party to prove the truth of a statement to another party without revealing any information beyond the statement itself [6]. They have the potential to effectively solve the privacy protection and tissues of data and models in MLaaS, as well as the trustworthiness of model computation results. Within the framework of ZKML, the correctness of data and the correctness of model parameters or execution results can be considered as a \"statement\" that the ZKP is used to prove. For example, in a ZKP-based training task of verifiable machine learning, the client needs to prove to the ML service provider that the training data provided by the client is indeed correct; conversely, the ML service provider needs to prove to the client that the model parameters (or inference results) are indeed obtained by training (or performing inference) on the dataset received from the client. ZKP allows the two parties to trust the statements without learning the details of task executions.\nFig. 1 illustrates one of ZKML setups for executing inference tasks in ZKML. In this ZKML setup, the machine learning service provider acts as the prover in the ZKP algorithm, and the client acts as the verifier. The function \\(F(*)\\) represents the relationship the ZKP algorithm wants to prove. The input data for the ZKP algorithm is divided into public input (known to both the prover and verifier) and the private witness (known only to the prover). To execute this ZKML setup, a client first sends their data x to the ML service provider as the data input to the ML model; and then the ML service provider supplies the model parameters w together with the data x to completes the machine learning inference task by computing the model inference result \\(r = W(x,w)\\), where \\(W(*)\\) denotes the model inference computation; after that, the machine learning service provider runs the proving function of ZKP to generate a zero-knowledge proof \\(\\pi\\) for that the relationship \\(F(x,r,w) = W(x, w) - r = 0\\) is hold, where \\((x,r)\\) are set as the public input of the ZKP algorithm and w is set to as the private witness of the ZKP algorithm; finally, the client runs the verifying function of ZKP to verify the proof and accepts the inference result r if the proof \\(\\pi\\) is verified successfully. Through this ZKML setup, the client can trust that the inference result \\(r = W(x, w)\\) provided by the ML service provider is indeed obtained by executing the machine learning model on their provided data x, even though they do not learn the specific model parameters w and the exact inference computation process of \\(W(*)\\). In this way, a form of \u201ctrustworthy\u201d machine learning is achieved via the verifiability of ZKP.\nThanks to the growing interest in privacy-preserving and trust ML technologies and the advancements in zero-knowledge proof techniques, there are now numerous works on ZKML, and new proposals continue to emerge. ZKML is a novel verifiable ML framework at the intersection of machine learning and cryptography, characterized by a diverse and complex research landscape. Therefore, systematically reviewing its development trajectory and summarizing current progress is crucial for advancing future research. Currently, there are limited survey studies on ZKML research works and no comprehensive coverage about the latest research up to now, lacking depth understanding about the relationship between research works. The existing survey works about ZKML are [7]-[9], and we summarized them as follows. In [7], Modulus Lab conducted inductive and comparative studies on the verifiability of machine learning inference task based on ZKP, confirming the feasibility of ZKP in verifiable machine learning. Using multilayer perceptrons (MLP) as the benchmark machine learning model, they compared the performances of six different ZKP systems, including Groth16, Gemini, Winterfell, Halo2, Plonky2, and zkCNN [10], in terms of proof time and memory consumption during machine learning inferences. Additionally, through comprehensive experimental validation, this work explained the impact of different ZKP systems on the efficiency of machine learning verifiable inference works. However, their analysis of how ZKML works enhance efficiency is relatively limited (all the works mentioned in [7] are also included for investigations in this survey). Sathe et al. [8] introduced and analyzed ZKML works up to 2023, providing detailed descriptions of zkCNN [10], ezDPS [11], Xing [12], and Mystique [13]. However, this survey covers fewer works and does not provide a comparative investigation of the existing works; the authors of [8], individually described the specific contents of the four works mentioned, failing to comprehensively present the latest developments and directions in the field. Recently, Xing et al. [9] provided a comprehensive survey of ZKML, including definitions, properties, and challenges. This survey covered all relevant ZKML works up to June 2023. The existing works discussed in this survey were divided into two application categories and further classified based on technical characteristics, providing researchers with a more comprehensive reference.\nTo bridge the gap and enhance existing reviews and surveys on ZKML, we conducted a comprehensive investigation summarizing ZKML works from June 2017 to December 2024. The main contributions of this survey paper are as follows:\n\u2022 Systematic Investigation of ZKML Research: This paper offers a structured examination of ZKML works, organizing, classifying, and summarizing nearly all significant contributions from June 2017 to December 2024, encompassing a total of 27 notable studies.\n\u2022 Categorization and Discussion of Technical Improvements: We categorize the technical improvement works that aim to address the implementation challenges of ZKML research into two primary dimensions (i.e., improving the generality and efficiency of ZKML) and outline the evolutionary process of these advancements.\n\u2022 Introduction of Commercial Applications: Moving beyond academic contexts, this paper explores commercial applications of ZKML, demonstrating its relevance and potential impact in industry.\n\u2022 Future Directions and Technical Challenges: By analyzing the current state of ZKML research and identifying key technical challenges, this paper proposes potential avenues for future development, offering guidance and inspiration for subsequent researchers.\nThe remainder of the paper is organized as follows: Section II introduces the background of machine learning and zero-knowledge proofs, along with three categories of verifiable machine learning. Section III presents existing research works for verifiable machine learning based on zero-knowledge proofs and their development process. Section IV discusses commercial applications of ZKML. Section V not only summarizes the paper, but also proposes future directions for ZKML development. Table I lists the main abbreviations used in the paper and their definitions."}, {"title": "II. BACKGROUND", "content": "This section starts by providing the technical background of machine learning and zero-knowledge proofs. It then delves into the details of verifiable machine learning and concludes with a comparison of the strengths and limitations of zero-knowledge proofs relative to other security techniques in the context of verifiable machine learning.\nA. Machine Learning\nMachine Learning (ML) [14], a subfield of AI, enables the development of models from diverse types of data, such as numerical values, textual content, images, and user interactions. These ML models are applied to tasks like pattern recognition, problem-solving, and making predictions [15]. ML encompasses various approaches, including supervised learning, unsupervised learning, reinforcement learning, and more. In this survey, we primarily focus on supervised learning, as it is the most common form of ML and serves as the foundation for the most of existing zero-knowledge-based verifiable machine learning research.\nIn supervised learning, the goal is to train a model that can capture the mapping \\(g(.)\\) from inputs X (also referred to as data features) to outputs Y (also known as labels), expressed as \\(Y = g(X)\\). We denote a ML model by \\(f_{\\theta}(*)\\), where \\(\\theta\\) represents the parameters of the model. The model is trained using a training algorithm and a dataset \\(D_{train} = \\{(X_1,Y_1), (X_2,Y_2), ..., (X_n, Y_n)\\}\\), where each pair \\((X_i, Y_i)\\) represents an input and its corresponding output label. In the training process, the parameters of the model are optimized by minimizing the total loss over the training dataset, formalized as: \\(\\theta' = arg \\underset{\\theta'}{min} \\underset{(Y_i, X_i) \\in D_{train}}{min} \\sum l(Y_i, f_{\\theta'}(X_i))\\), where \\(l(\u00b7, \u00b7)\\) denotes the chosen loss function. Once the model \\(f_{\\theta}(*)\\) is trained, it can be used to infer the output label Y' for new input data X that were not part of the training dataset, expressed as \\(Y' = f_{\\theta}(X)\\). The goal is for the learned model \\(f_{\\theta}(*)\\) to approximate the true mapping \\(g(\u00b7)\\) as closely as possible, ensuring that the predicted output label Y' closely matches the true label Y.\nVarious models are used to represent the mapping between input data features and output labels, including linear regression, decision trees, support vector machines, and deep neural networks. Each model has distinct characteristics and is suited to specific scenarios. Given the popularity and effectiveness of deep neural networks in modern applications, as well as the fact that nearly all existing work on ZKML focuses on deep neural networks, we adopt them as the default ML model in this survey unless otherwise specified. Consequently, the model parameters refer to the weights of the connections between the neuron units across the layers of the deep neural network.\nB. Zero-Knowledge Proof\nZero-knowledge proof (ZKP) is a cryptographic technique that proves a statement's validity without revealing any private information about the statement. There are several types of zero-knowledge proof systems [16], for example, zero-knowledge succinct non-interactive argument of knowledge (zk-SNARK) [17], zero-knowledge scalable transparent argument of knowledge (zk-STARK) [18], and others.\nThe computation of a ZKP system is usually represented by an arithmetic circuit that consists of the basic arithmetic operations of addition, subtraction, multiplication, and division.\u00b9 An F-arithmetic circuit is a circuit in which all inputs and all outputs are elements in a field F. Consider an F-arithmetic circuit C that has an input \\(x \\in F^n\\), an auxiliary input \\(W \\in F^h\\) called a witness, and an output \\(C(x, W) \\in F^l\\), where n, h, l are the dimensions of the input, auxiliary input, and output, respectively. The arithmetic circuit satisfiability problem of the F-arithmetic circuit C is captured by the relation: \\(R_c = \\{(x, W) \\in F^n \\times F^h : C(x, W) = 0'\\}\\) and its expression is \\(L_c = \\{x \\in F^n : \\exists W \\in F^h s.t. C(x, W) = 0'\\}\\). A ZKP system consists of three algorithmic components [17]:\n\u2022 \\((PK,VK) \\leftarrow KEYGEN(1^{\\lambda}, C')\\) is the key generation algorithm that generates the proving key PK and the verification key VK by using a predefined security parameter \\(\\lambda\\) and an arithmetic circuit representation C.\n\u2022 \\(\\pi \\leftarrow PROVE(PK, x, W)\\) is the proof generation algorithm that generates a proof \\(\\pi\\) based on the proving key PK, the input x and the witness W.\n\u2022 \\(1/0 \\leftarrow VERIFY(VK,x,\\pi)\\) is the proof verification algorithm that outputs a decision to accept or reject \\(\\pi\\) using VK, x and as the input.\nThe proving key PK and the verification key VK generated by the KEYGEN algorithm are treated as the public parameters. The PROVE algorithm is executed by the prover, and the VERIFY algorithm is executed by the verifier. Witness W is the secret owned by the prover that they do not want to reveal to others and yet wants to prove that they know the secret.\nDifferent ZKP systems are computationally suited to different types of arithmetic circuits, each with distinct characteristics. As a result, various ZKP systems excel in different application domains. For instance, zk-SNARKs are particularly effective at handling arithmetic circuits represented in the Rank-1 Constraint System (R1CS) form; whereas ZKP systems based on sum-check [20] and GKR [21] protocols are more suitable for dealing with arithmetic circuits that exhibit a layered structure. This layered structure of arithmetic circuits is particularly relevant in the context of deep neural network models in machine learning, which typically possess a layered structure. Consequently, many ZKML works targeting deep neural networks leverage sum-check and GKR protocols for enhanced efficiency and performance.\nIn general, the following two technical advantages of ZKP systems are useful for verifiable machine learning and thus are exploited by ZKML. The VERIFY algorithm can be executed significantly faster than the PROVE algorithm. The VERIFY algorithm does not require access to the private witness. The first advantage enables machine learning clients to save computational resources compared to performing all computations themselves. The second advantage ensures that sensitive information remains protected throughout the entire machine learning process, preventing any disclosure.\nC. Verifiable machine learning\nAs machine learning continues to address increasingly complex problems, the size and complexity of the models employed have grown significantly. Larger neural networks require more parameters, which in turn leads to higher costs. These costs stem from the need for extensive datasets and substantial computational resources. As a result, high-cost machine learning computations are often accessible only to large institutions. Within the framework of MLaaS, these institutions, acting as ML service providers, perform ML tasks such as model training or inference and subsequently share the results with their clients.\nIn this context, it becomes crucial for ML service providers to prove that the shared results were derived from genuine computations rather than being fabricated. This necessity has given rise to the concept of verifiable machine learning. Verifiable machine learning encompasses three primary categories: Verifiable Training, Verifiable Testing, and Verifiable Inference, as outlined below:\n\u2022 Verifiable Training ensures the quality of data, the consistency of training algorithms, and the integrity of model parameters throughout the training process. In practice, many individuals and small companies lack the necessary infrastructure to train the machine learning models they require. To address this gap, ML service providers on MLaaS platforms offer model training services, allowing these individuals and small businesses-who act as their ML clients to outsource their training tasks to the providers on these platforms. In such a setup, the ML service provider undertakes the training process based on the client's specified configuration details, including accuracy thresholds, the number of epochs, and the network architecture. Once the training is complete, the ML service provider provides the company with the trained model in exchange for a fee. However, this arrangement introduces the need for the individuals and small companies to verify that the ML service provider performed the training task faithfully-strictly adhering to the predefined requirements-and that the returned model is genuinely the result of the stated training process.\n\u2022 Verifiable Testing involves proving the true performance of a model, ensuring that its claimed performance accurately reflects its generalization ability rather than being limited to its training data. For instance, in verifiable testing on an MLaaS platform, an ML client uploads the target machine learning model along with some test data and specifies the evaluation metrics to be used, such as accuracy or F1 score. The ML service provider then performs the testing as required and generates a detailed test report. To guarantee the authenticity of this process, some encryption techniques and third-party verification tools must be employed to ensure the following: the test data remains unaltered throughout the testing process; the testing adheres strictly to the predefined configuration; and the final testing results accurately reflect the model's true performance.\n\u2022 Verifiable Inference ensures that the claimed inference results are indeed the outputs generated by the specified machine learning model using the provided input data and following the predetermined inference process. For example, an ML client can upload the input data and the designated model to an ML service provider who performs the inference task while preserving the confidentiality of both the data and the model. To maintain authenticity and data privacy, cryptographic techniques like ZKP can be used. These techniques verify the correctness of the inference process and the integrity of the data without revealing sensitive details. The inference results returned by the ML service provider can then be verified to ensure they have not been tampered with and accurately reflect the model's capabilities. This approach allows ML clients to safely and reliably utilize external ML inference services.\nD. Comparison of Security Techniques in Verifiable Machine Learning\nSeveral security techniques, such as Differential Privacy (DP), Homomorphic Encryption (HE), Federated Learning (FL), Trusted Execution Environments (TEE), and Secure Multiparty Computation (SMC), can provide verifiable computation and privacy protection in machine learning to a certain degree. However, when these security techniques are applied to verifiable machine learning, they exhibit certain limitations compared to ZKP. The comparative analysis is presented in Table II and detailed as follows.\nDP is a highly regarded and rigorous security technique for privacy protection. Initially proposed by Dwork in 2006 [22], DP operates by adding random noise to query results, ensuring that the presence or absence of any individual in the dataset does not significantly alter the outcome. This approach safeguards individual data privacy. When applied to ML models, DP can protect training data against model inversion attacks. Consequently, numerous studies have explored integrating DP into ML models [27]. However, compared to ZKP, the introduction of random noise can compromise dataset accuracy, potentially affecting both model utility and precision.\nHE [23] is an encryption technique that enables computations to be performed directly on encrypted data (ciphertexts). The results remain encrypted, and once decrypted, they match the outcomes of the same computations performed on plaintexts. This capability is often referred to as \u201ccomputable yet invisible\u201d data. HE is categorized into Fully Homomorphic Encryption (FHE) and Partially Homomorphic Encryption (PHE). FHE supports arbitrary computations on ciphertexts, whereas PHE allows only specific operations, such as addition, multiplication, or a limited combination of both. While HE ensures data privacy while maintaining data computability, it faces significant performance challenges, including high computational and storage overhead, especially when compared to ZKP.\nFL is a distributed machine learning framework introduced by Google in 2016 [24], [28]. It enables collaborative model training while preserving data privacy and ensuring regulatory compliance, thereby enhancing AI model performance. FL addresses the limitations of single-feature data during the training phase and safeguards private data against leakage. Additionally, its distributed architecture reduces overall computational costs. However, FL has a significant vulnerability: it cannot prevent participants from submitting false or malicious data, which can irreparably compromise the final trained model.\nTEE [25] is a secure, independent processing environment with computation and storage capabilities, designed to provide robust security and integrity protection. It utilizes isolated memory to store private data and perform computations, ensuring that only authorized interfaces can access the data. Hardware-based TEE technology is highly efficient and capable of supporting multi-level, complex algorithm logic implementations. However, its reliance on underlying hardware architecture makes it less suitable for tasks requiring high network bandwidth or significant computational resources.\nSMC [26] is a cryptographic technique that enables multiple parties to collaboratively achieve computational goals while ensuring that private data remains confidential, except for the computed results and any information inferable from them. SMC offers high computational accuracy and supports programmable, general-purpose computations. Nevertheless, as the number of participants increases, it becomes increasingly difficult to design computational schemes that ensure computation latency scales linearly, posing challenges for large-scale applications."}, {"title": "III. RESEARCH OF ZKML", "content": "In this section", "participants": "the ML service provider", "components": "circuit input", "Training": "Fig. 3 presents the conceptual diagram of the arithmetic circuits used in ZKP-based verifiable training. Below", "Input": "The inputs to the circuit in ZKP-based verifiable training include both private witness and public input. The private witness encompasses the training data", "Logic": "The circuit executes several essential computational tasks to enable verifiable training. First", "Output": "The output includes the hash of the updated model parameters after training and the generated zero-knowledge proof.\nThis circuit design enables the verification of each step in the training process according to the defined algorithms and procedures", "Testing": "Fig. 4 presents the conceptual diagram of the arithmetic circuits used in ZKP-based verifiable testing. Below"}, {"Input": "Within the input to the circuit", "Logic": "The circuit performs several key computational tasks for verifiable testing. First", "Output": "The output includes the testing performance of the model and the generated zero-knowledge proof.\nThis circuit design of ZKP-based verifiable testing ensures that the model testing performance is within a certain range", "Inference": "Fig. 5 presents the conceptual diagram of the arithmetic circuits used in ZKP-based verifiable inference. Below"}, {"Input": "The inputs to the circuit in ZKP-based verifiable inference include both private witness and public input. The private witness comprises the model parameters. The public input includes the hash of the model parameters", "Logic": "The circuit performs several critical computational tasks for verifiable inference. It first computes the hash of the model parameters", "Output": "The output consists of the inference results for the input data and the generated zero-knowledge proof.\nThis circuit design ensures that the inference process adheres to the defined algorithms and procedures", "Training": "In 2021", "29": "whose core idea is to make the training process retrievable to achieve verifiability in machine learning training. VeriML pre-stores the inputs and outputs of several iterations during the training process and commits to them", "30": "a verifiable training protocol for neural networks built upon the GKR protocol. This system is specifically tailored for neural networks and builds upon the SafetyNets method-the first verifiable inference approach leveraging ZKP", "follows": "First", "31": "a framework that employs a two-round challenge-response protocol and random sampling of model weights to generate proofs. This approach reduces the time cost of proof generation while ensuring the verifiable integrity of the training process. Prior to executing the challenge-response protocol", "32": "is an efficient ZKML system designed for the verifiable training of deep neural networks. To address the non-arithmetic nature of ReLU activation functions in neural networks", "FAC4DNN": 1}]}