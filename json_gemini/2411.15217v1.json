{"title": "LPLgrad: Optimizing Active Learning Through Gradient Norm Sample Selection and Auxiliary Model Training", "authors": ["Shreen Gult", "Mohamed Elmahallawy", "Sanjay Madria", "Ardhendu Tripathy"], "abstract": "Machine learning models are increasingly being utilized across various fields and tasks due to their outstanding performance and strong generalization capabilities. Nonetheless, their success hinges on the availability of large volumes of annotated data, the creation of which is often labor-intensive, time-consuming, and expensive. Many active learning (AL) approaches have been proposed to address these challenges, but they often fail to fully leverage the information from the core phases of AL, such as training on the labeled set and querying new unlabeled samples. To bridge this gap, we propose a novel AL approach, Loss Prediction Loss with Gradient Norm (LPLgrad), designed to quantify model uncertainty effectively and improve the accuracy of image classification tasks. LPLgrad operates in two distinct phases: (i) Training Phase aims to predict the loss for input features by jointly training a main model and an auxiliary model. Both models are trained on the labeled data to maximize the efficiency of the learning process an aspect often overlooked in previous AL methods. This dual-model approach enhances the ability to extract complex input features and learn intrinsic patterns from the data effectively; (ii) Querying Phase that quantifies the uncertainty of the main model to guide sample selection. This is achieved by calculating the gradient norm of the entropy values for samples in the unlabeled dataset. Samples with the highest gradient norms are prioritized for labeling and subsequently added to the labeled set, improving the model's performance with minimal labeling effort. Extensive evaluations on real-world datasets demonstrate that the LPLgrad approach outperforms state-of-the-art methods by order of magnitude in terms of accuracy on a small number of labeled images, yet achieving comparable training and querying times in multiple image classification tasks. Our code is available at Github.", "sections": [{"title": "I. INTRODUCTION", "content": "Machine learning models are being adopted rapidly across various fields due to their exceptional performance and generalization capabilities. These models rely on both data and ground-truth labels to excel in their tasks. However, obtaining ground-truth labels is often challenging. For instance, in medical imaging, domain experts must be compensated to annotate data points, and in speech recognition, labeling audio data at the word level can take significantly more time than the actual speech duration [1]. The manual annotation process is both time-consuming and labor-intensive [2], [3].\nActive learning (AL) offers a solution to these challenges by intelligently selecting the most informative data points for"}, {"title": "II. RELATED WORK", "content": "In this section, we will review recent works in AL, which can be categorized into three main approaches: uncertainty sampling, diversity sampling and hybrid sampling."}, {"title": "A. Uncertainty based Methods", "content": "This category of AL methods evaluates the informativeness of unlabeled data points by assessing the uncertainty of the target deep network regarding these points. They prioritize selecting those unlabeled points fro annotation and adding to the labeled set where the model exhibits significant uncertainty. In this context, Wang et al. [5] introduce a metric for data selection based on model uncertainty, known as entropy sampling. This metric is one of the most widely used for uncertainty quantification and data selection. Some of the recent works that propose active learning approaches include [14]\u2013 [16]. For instance, the authors of [14] proposed a technique that incorporates both known and unknown data distributions to measure the model's uncertainty. Another work, [15] introduced a method that utilizes noise stability in the model's parameters as an uncertainty metric. A recent approach by [16] estimates the model's uncertainty by employing a Gaussian process (GP) model as a surrogate for the baseline neural network learner. Another recent work Verified Pseudo-label Selection for Deep Active Learning (VERIPS) proposed by [4] that uses a pseudo-label verification mechanism that consists of a second network only trained on data approved by the oracle and helps to discard questionable pseudo-labels.\nWhile the aforementioned methods effectively reduce labeling effort, they share a common drawback: they are susceptible to selecting outliers due to their high uncertainty. Additionally, focusing predominantly on sampling uncertain points can lead to unreliable model predictions and querying redundant data, ultimately decaying model's performance [2]."}, {"title": "B. Diversity based Methods", "content": "In this category of AL methods, the learner queries examples that are representative of the entire data distribution such as the work in [7], [8]. In [7], the authors proposed the Coreset approach, which is among the most prominent methods in diversity-based AL. It frames AL as a coreset problem; selecting unlabeled samples based on their geometric properties. Despite its effectiveness, this method is computationally intensive and has delayed sampling times because it requires storing an array of labeled samples for comparison with new samples. The authors of [8] proposed a variational adversarial AL (VAAL) approach that utilizes a variational autoencoder to learn the distribution of labeled data in latent space, coupled with an adversarial network that discriminates between labeled and unlabeled data. However, VAAL necessitates retraining the VAE multiple times rendering it computationally intensive.\nWhile diversity-based methods effectively capture the underlying data distribution, they may fail to fully leverage the information from unlabeled data necessary for training the task learner. Moreover, these techniques might be insensitive to data points near the decision boundary, even though such points could be crucial for the target model to query [2].\nIn this paper, we propose an uncertainty-based AL algorithm that addresses the limitations above by leveraging both the training and querying phases. Our algorithm effectively learns the features of input data through the joint training of models, thereby extracting inherent patterns in the input points and reducing the likelihood of selecting redundant data. During the selection phase, it chooses unlabeled points based on their gradient norm values, which provably reduces the test loss."}, {"title": "III. PROPOSED METHODOLOGY", "content": "In this section, we provide a comprehensive explanation of the components comprising our proposed AL approach, LPLgrad. We start with the problem formulation and an overview of the framework, followed by a detailed description of the two main building blocks of LPLgrad: the Training Phase and the Querying Phase."}, {"title": "A. Problem Formulation and Framework", "content": "Given a pool of unlabeled set of data samples denoted as $U = \\{x_i\\}_{i=1}^N$ with $N$ is the total number of samples, we aim to solve multi-class classification problem with $C$ categories. To do that, we first construct a labeled set of multi-class $L = \\{(x_i, Y_i)\\}_{i=1}^{B_1}$ ($Y_i$ represents the label of the data point $x_i$) by randomly selecting $B$ samples from the unlabeled pool $U_{N-B}$. Here, the superscript $t = 0, 1,...$ signifies the current round of AL, which increases by one as the training progresses. We then utilize a set of models $w = \\{W_{main}, w_{aux}\\}$ and train them on $L_t^B$. The training procedure involves an augmented approach where both the main model $w_{main}$ and the auxiliary model $w_{aux}$ are jointly learned.\nOnce the training on the selected set $L_t^B$ is completed, we compute the output entropy for all the samples in $U_{N-B}$ (which includes only the remaining unselected samples). These entropy values represent the loss incurred by $w_{main}$. Subsequently, we update the $w_{main}$ parameters and store the gradient norm for each sample in the set. These stored values will be then sorted, and a new $B'$ samples with the highest gradient norm will be selected for labeling in the next AL cycle $(t+1)$.\nIn the subsequent cycle, the updated labeled and unlabeled sets are denoted as $L_t^{B'}$ and $U_{N-B'}^{t+1}$, respectively. Then, the main and auxiliary models will be trained on $L_t^{B'}$ to update their model weights as $w_{main, t+1}, w_{aux, t+1}$, respectively. This process of training and querying new samples continues in subsequent AL cycles until a certain accuracy threshold is achieved, a predefined budget of iterations is exhausted, or any other termination criterion.\nBelow, we provide a detailed description of our proposed LPLgrad framework (see red numbered circles in Fig. 2):"}, {"title": "B. LPLgrad Training Phase", "content": "The training phase of LPLgrad involves two primary models: the main model $w_{main}$ and the auxiliary model $w_{aux}$. LPLgrad trains the model $w_{main}$ alongside $w_{aux}$, which is integrated into its architecture to effectively capture intricate patterns and characteristics within input data. Here's how it works:\nFor each data point $x_i$, we obtain two values: one is the prediction of the main model $Y_{main} = W_{main}(x_i)$, and the other is a feature map $F$, which is processed by auxiliary the model $w_{aux}$ to output the predicted loss $l_{aux} = w_{aux}(F)$. The loss of the main model $w_{main}$ is calculated using cross-entropy loss that takes the predicted value $Y_{main}$ and ground-truth label $Y_i$ of the sample $x_i$ as inputs, which can be expressed as\n$l_{main} = \\frac{1}{N} \\sum_{i=1}^N L_{CE} (Y_i, Y_{main})$\nThe loss for the auxiliary model $w_{aux}$ is computed based on the predicted loss $l_{aux}$ and its corresponding ground-truth loss value $l_{main}$, which can be presented as:\n$l_{aux} = \\frac{1}{P}\\sum_{i=1}^P max(0, M - d_i \\cdot (l_{aux,i} - l_{main,i}))$\nHere, $M$ is a parameter for margin which explains how much the predicted loss should differ from the ground-truth loss before a penalty is applied. $d$ in the equation is used to determine the direction of the margin penalty and is computed as\n$d_i = max(0, l_{main,i})$\nThis ensures that the margin is adjusted correctly, either penalizing or not penalizing the predicted loss, depending on the relative difference between the predicted and true losses. To make the auxiliary model $w_{aux}$ robust to overall scale variations in the loss, we construct a mini-batch of $P$ examples from $L^B$. We form $P/2$ data pairs, denoted as $\\{X^p = (x_m,x_n)\\}$, where $x^p$ represents a pair of examples m and n. The superscript p indicates the loss for a pair of data points, denoted as $l_{aux,i}$ and $l_{main,i}$ for the auxiliary model and the main model, respectively, as shown in equation (2).\nNote that $l_{aux,i}$ in equation (2) represents the predicted loss for a specific sample in the pair, which is obtained by processing the extracted features of input through the $w_{aux}$, while the overall loss for auxiliary model is denoted by $l_{aux}$. The auxiliary model $w_{aux}$ is learned by comparing the differences between the predicted losses $l_{main}$ and $l_{aux}$ for each data pair.\nThe total loss during the training phase is then calculated as follows:\n$L_{total} = l_{aux} + l_{main}$\nLPLgrad leverages the extraction of multi-level input features obtained from various layers of the main model $w_{main}$, which are subsequently fed into the auxiliary model $w_{aux}$. Specifically, the model $w_{aux}$ comprises a series of blocks corresponding to the layers within the model $w_{main}$. Each block consists of two distinct layers: a global average pooling layer and a fully-connected layer. These blocks process the feature"}, {"title": "C. LPLgrad Querying Phase", "content": "After training the main model $w_{main}$ alongside the auxiliary model $w_{aux}$, LPLgrad transitions to its second phase, which focuses on querying new samples for labeling. While the method proposed by Yoo et al. [10] utilizes the $w_{aux}$ model to identify the most informative points, our empirical results reveal a more effective strategy. Specifically, selecting samples based on their entropy values presents a robust alternative to the aforementioned approach. The hyperparameters in the loss prediction module can be highly sensitive in large-scale datasets like [11] and EMNIST [12] leading to performance degradation. Moreover, the model's uncertainty is better estimated using its entropy because it incorporates the model's confidence scores directly rather than with an attached loss prediction module. Specifically, selecting samples based on their gradient norm values presents a robust alternative to the aforementioned approach.\nTo implement this, we begin by extracting the embeddings of each sample in the unlabeled set $x_i \\in U_B$ such that $z_i = W_{main}(x_i)$. We then use a softmax classifier to obtain the posterior probabilities $P(y_i|x_i)$, which can be expressed as\n$P(Y_i = c|x_i) = \\frac{e^{z_c}}{\\sum_{c=1}^C e^{z_c}}$\nThese posterior probabilities are then used to calculate the output entropy of each sample, which can be given as\n$H(P(y_i|x_i)) = - \\sum_{c=1}^C P(Y_i = c|x_i) log P(Y_i = c|x_i)$\nwhere $P(y_i = c|x_i)$ is the predicted probability for class $c$ given the sample $x_i$, and $C$ is the total number of classes in the dataset.\nWe treat this entropy as a loss and perform a backward pass on the loss function to compute the gradient of the $w_{main}$ model parameters for each sample $x_i$:\n$w_{main} H_i = \\frac{\\partial H(P(y_i|x_i))}{\\partial w_{main}}|_{x_i}$\nThe Frobenius norm of these gradients is then calculated to assess the network's sensitivity to the input as\n$g_i =||w_{main} H_i ||_F$\nThese gradient norms of all the inputs are subsequently stored and sorted to identify the highest values, which can be represented as\n$\\{g_{i1},g_{i2},..., g_{iB}\\} s.t. g_{i1} \\ge g_{i2} \\ge... \\ge g_{iB}$\nIn our querying phase, we follow the theoretical insights presented in [13], which suggest that selecting samples with higher gradient norms from the unlabeled set can lead to a reduction in the upper bound of the total loss. Thus, we guide our selection process by prioritizing samples with the largest gradient norms for annotation. Subsequently, these selected samples are added to the labeled set L. Importantly, the parameters of the $w_{main}$ model will not be updated during the selection process of the new samples."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "In this paper, we proposed LPLgrad, a novel AL approach aimed at addressing a common gap in the literature: the underutilization of the core phases of AL, specifically the training and querying phases. To fully exploit the labeled data, we adopted an augmented approach wherein two models-a main model and an auxiliary model are trained together to optimally learn the features of the input data. Additionally, to effectively query the most informative samples, we compute the entropy values of the unlabeled set and backpropagate these values to obtain loss values. This loss is minimized, and its gradients with respect to the main model's parameters are calculated. The Frobenius norm of gradients is then computed, sorted, and used to identify the samples with the highest gradient norm values, which are selected for labeling and added to the labeled set. We extensively evaluate LPLgrad on diverse image classification datasets and a real-world dataset to validate its efficacy. Our findings demonstrate that LPLgrad surpasses state-of-the-art approaches by achieving higher accuracy with fewer labels and less computing time.\nAs future work, we plan to explore the application of LPLgrad to more complex and larger-scale datasets to further validate its robustness and scalability. We also aim to investigate the potential of LPLgrad in domains beyond image classification, such as natural language processing or time-series data, which will be a key focus. Finally, we will explore using LPLgrad in real-time systems where rapid decision-making with limited labeled data is critical."}]}