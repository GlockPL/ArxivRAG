{"title": "Formal Mathematical Reasoning: A New Frontier in AI", "authors": ["Kaiyu Yang", "Gabriel Poesia", "Jingxuan He", "Wenda Li", "Kristin Lauter", "Swarat Chaudhuri", "Dawn Song"], "abstract": "AI for Mathematics (AI4Math) is not only intriguing intellectually but also crucial\nfor AI-driven discovery in science, engineering, and beyond. Extensive efforts on\nAI4Math have mirrored techniques in NLP, in particular, training large language\nmodels on carefully curated math datasets in text form. As a complementary yet\nless explored avenue, formal mathematical reasoning is grounded in formal systems\nsuch as proof assistants, which can verify the correctness of reasoning and provide\nautomatic feedback. In this position paper, we advocate for formal mathematical\nreasoning and argue that it is indispensable for advancing AI4Math to the next\nlevel. In recent years, we have seen steady progress in using AI to perform formal\nreasoning, including core tasks such as theorem proving and autoformalization, as\nwell as emerging applications such as verifiable generation of code and hardware\ndesigns. However, significant challenges remain to be solved for AI to truly master\nmathematics and achieve broader impact. We summarize existing progress, discuss\nopen challenges, and envision critical milestones to measure future success. At\nthis inflection point for formal mathematical reasoning, we call on the research\ncommunity to come together to drive transformative advancements in this field.", "sections": [{"title": "Introduction", "content": "Since the early days of AI, researchers have dreamed of building AI systems that can automate\nmathematical reasoning. The first AI program in history was Newell and Simon's Logic Theorist [1],\na theorem proving system that could prove 38 theorems in Principia Mathematica [2]. In the decades\nsince then, the center of AI has shifted from symbolic methods to machine learning, and a new field\nof statistical AI for mathematics (AI4Math) has emerged. One appeal of the field is that mathematical\nproblems are a proxy for a broad array of reasoning and planning tasks. Another attraction is that math\nplays a foundational role in quantitative disciplines, so AI4Math has the potential to revolutionize\nAl for science, engineering, and beyond. For these reasons, designers of large language models\n(LLMs) [3, 4] have frequently highlighted LLMs' success in math problems, and there have also\nbeen efforts to build AI systems that outperform humans at math competitions [5-7].\nGiven the importance of AI4Math, substantial research has been dedicated to developing math LLMs,\nusing techniques borrowed from natural language processing (NLP). A common approach is to\ncontinue pretraining LLMs on math data, such as arXiv papers and web pages from MathOverflow,\nand then finetune the model on curated datasets of math problems with detailed, step-by-step solutions.\nWe call this the \u201cinformal\" approach to distinguish it from the formal approach that will be introduced\nlater (Sec. 2). Just like LLMs in general, math LLMs have a simple recipe, but the secret sauce is\noften data curation [8-11]. Carefully curated training data plus inference-time techniques, including\nchain-of-thought prompting [12], self-consistency [13], and tool use [14], have led to remarkable\nsuccess on widely used benchmarks such as GSM8K [15] and MATH [16], as well as in the AIMO\nProgress Prize [6]. However, at the time of writing, the success of the informal approach has been\nmostly limited to high school math not exceeding the AIME level.\u00b9 This raises a key question:\nHow far can we go by scaling up the informal approach? Will it enable math LLMs to solve\nmore challenging competition problems (e.g., IMO, International Mathematical Olympiad) or even\nproblems in mathematical research?\nMoving from high school to more advanced mathematics, the informal approach faces challenges that\nare hard to resolve by merely scaling up the training. First, training math LLMs requires high-quality\ndata, which is scarce in advanced mathematics. For novel research math problems, it is infeasible\nto find solutions to similar problems on the Internet or manually annotate the data on a large scale.\nWithout scaling up the data, we cannot fully benefit from the scaling laws for LLMs [18, 19]. Second,\nsolutions to many advanced problems are not numbers that can be evaluated by comparing them with\nthe ground truth. Instead, they carry out a chain of intricate reasoning steps, e.g., a proof. LLMs are\nnotorious for hallucinating seemingly valid reasoning steps, making it challenging to evaluate the\ncorrectness of model output or collect useful feedback for learning. These challenges are difficult to\naddress by scaling up the informal approach during training. If training-time scaling is not enough,\nwhat else do we need? One emerging direction, exemplified by OpenAI 01 [17], is to scale up the\ninformal approach during inference, potentially combining search with neural verifiers to mitigate\nhallucinated reasoning [15]. While this approach has gained traction, its effectiveness on advanced\nmathematical problems is an open question. In this position paper, we focus on a complementary\napproach that is less explored: formal mathematical reasoning.\nWe consider formal mathematical reasoning broadly as mathematical reasoning grounded in formal\nsystems, including but not limited to first/higher-order logic [20], dependent type theory [21], and\ncomputer programs annotated with formal specifications [22]. Such formal systems provide envi-\nronments that can verify the model's reasoning and provide automatic feedback. They stand apart\nfrom the \"tools\" used by modern LLMs [23] in their ability to model the provable truth or falsity of\na broad class of propositions. The feedback provided by such systems can mitigate data scarcity;\nalso, such systems enable rigorous test-time checks that resist hallucination. In contrast, informal\nmathematics refers to math text commonly found in textbooks, research papers, and online math\nforums. Informal math interleaves natural language with symbols (e.g., \\(\\LaTeX\\)), but these symbols do\nnot have a self-contained formal semantics, instead relying on informal text to convey significant\nparts of their meaning.\nAlphaProof [7] and AlphaGeometry [5] are two prominent examples of the success of this idea. Before\nthese systems, there were many failed attempts to use LLMs to solve olympiad-level math problems.\nThe key differentiator in the aforementioned systems is the principled use of symbolic representations\nand proof-checking frameworks. The symbolic components (Lean [24, 25] for AlphaProof; a domain-\nspecific geometry system for AlphaGeometry) are used to execute a neural network's reasoning steps\nand generate high-quality synthetic data, leading to unprecedented mathematical reasoning abilities.\nAlphaProof and AlphaGeometry follow in the footsteps of a broader literature on the synergistic\nuse of formal methods and machine learning in mathematical tasks [26\u201333]. This literature in-\ncludes research on neural theorem proving, i.e., generating formal proofs given formal theorem\nstatements [34\u201336], and autoformalization, i.e., automatically translating informal mathematics into\nformal mathematics [37]. The advent of LLMs has significantly accelerated research in this area.\nFor example, autoformalization was long hampered by the lack of aligned informal-formal pairs\nfor finetuning. LLMs can mitigate this problem by either synthesizing the data [38] or performing\nautoformalization without finetuning [37]. As a result, we are starting to realize autoformalization's\npotential in bootstrapping the capability of neural theorem provers [39]. LLMs are also powerful\ntools for theorem proving; in particular, recent approaches have exploited LLMs to predict proof\nsteps and fix buggy proofs without explicit training on formal proof data [36, 40].\nThe research infrastructure around LLMs and formal reasoning is rapidly maturing. Lean [24, 25]\u2014\na language for writing formal proofs\u2014has gained popularity among mathematicians, leading to\nformalized research mathematics [41] and general-purpose mathematical libraries [42]. There are now\nmultiple frameworks [35, 36] that support the interaction between LLMs and Lean. These frameworks\nallow the extraction of training data from human-written formal proofs, as well as theorem proving\nvia interaction with the formal environment. Multilingual infrastructures for proof languages like\nCoq [21] and Isabelle [20] in addition to Lean are also beginning to be built [36]. Finally, LLMs have"}, {"title": "AI for Mathematics (AI4Math) and the Formal Turn", "content": "Mathematical reasoning is a challenge at the frontier of AI research. In this section, we begin\nby examining the informal approach to AI4Math and its limitations. Then, we introduce formal\nmathematical reasoning as a promising path for advancing AI4Math."}, {"title": "State-of-the-art Math LLMs and Their Limitations", "content": "A Case Study of NuminaMath. NuminaMath [49] is a math LLM that won the first AIMO\nProgress Prize in July 2024, successfully solving 29 out of 50 test problems. The test problems were\nintermediate-level high school math problems newly created and kept private before the evaluation.\nTherefore, they have very little risk of data contamination compared to public benchmarks such as\nGSM8K [15] and MATH [16]. NuminaMath is an excellent example of state-of-the-art math LLMs,\nas it encompasses many key ingredients such as math pretraining [10, 50\u201352], finetuning [8, 9], and\ntool-integrated reasoning [14, 53] (Fig. 1). Next, we use NuminaMath as an example to elaborate on\neach ingredient, highlighting the critical role of data.\u00b2\n1. Math pretraining (Fig. 1 Left): Starting from a generic LLM (or a coding LLM such as\nCode Llama [54]), one can continue to pretrain the model on a large corpus of math-related\ndocuments from the web. The result is referred to as the base math LLM. NuminaMath and\nother top contestants in the AIMO Progress Prize unanimously adopted DeepSeekMath-Base\n7B [11] as the base math LLM. Critical to DeepSeekMath's success is data. To retrieve high-\nquality math documents from Common Crawl, the authors of DeepSeekMath engineered a\ndata selection pipeline that combined automatic filtering and manual annotation.\n2. Finetuning on step-by-step solutions (Fig. 1 Middle): The base math LLM has been exposed\nto a vast amount of mathematical content during pretraining, but it is not yet capable of\ngenerating well-structured solutions to math problems. To align the model with problem\nsolving, one can finetune it on a carefully curated dataset consisting of math problems with\ndetailed, step-by-step solutions, e.g., in the form of chain-of-thought [12]. This dataset can\nbe constructed by preprocessing and combining heterogeneous sources of problems, e.g.,\nonline forums, high school exams, math competitions, problem sets, and manual annotations.\nThe problems and solutions are then augmented and reformatted by LLMs like GPT-4 [3].\nNuminaMath, for example, has constructed a large dataset of 860K problems and solutions\ncovering high school and competition math [55].\n3. Tool-integrated reasoning (Fig. 1 Right): Finetuned math LLMs have acquired general\nproblem-solving skills, but they may still struggle with precise calculation (e.g., 162 \u00d7 731)\nand symbol manipulation (e.g., expanding \\((x + 2)^8\\) into powers of x). A simple solution is\nto outsource these operations to external tools such as SymPy [56]. NuminaMath performs\ntool-integrated reasoning that interleaves reasoning in natural language with tool invocation\nin Python. The key is, again, data. The model is finetuned on tool-integrated solutions\nconsisting of natural language combined with tool invocation trajectories. NuminaMath\nfollows the approaches in ToRA [14] and MuMath-Code [53] to collect this dataset of math\nproblems with tool-integrated solutions.\nData Scarcity. The NuminaMath team summarized: \u201cGood data is all you need\" [49]. Indeed,\ntraining data plays a pivotal role throughout all ingredients of the informal approach. As a result,\nthe success of this approach has been limited to domains where abundant high-quality data can be\nobtained at low costs. For pre-college math, it is relatively easy to collect problems and solutions on\nthe Internet or annotate them manually. However, it is difficult to extend the informal approach to\ndata-scarce domains such as advanced mathematics.\nAdvanced mathematics forms the foundation of numerous scientific disciplines. For example, climate\nmodeling depends on partial differential equations. To unlock Al's full potential in scientific discovery,\nit must be able to learn and apply advanced mathematics. Moreover, the long-term goal of developing\nhuman-level AI mathematicians requires AI to handle novel aspects of mathematics. Novelty, by\ndefinition, implies difficulty in collecting in-distribution training data. Therefore, moving forward,\nwe see data scarcity as a major roadblock to the informal approach to AI4Math.\nLack of Correctness Verifiability. Besides data scarcity, another challenge is in evaluation, which\nis essential for AI to make measurable progress. Existing math LLMs are evaluated on benchmarks\nsuch as GSM8K and MATH, which consist of math problems whose solution is a single number (or\nexpression). Therefore, evaluation can be done easily, by comparing the model-generated number\nagainst the ground truth. While this approach is suitable for pre-college mathematics, it is not directly\napplicable to more advanced mathematics. Recent work has attempted to adapt this evaluation\nframework for advanced problems by restricting to problems that have numeric solutions [57]."}, {"title": "AI for Formal Mathematical Reasoning", "content": "From Informal to Formal. Due to the challenges in data and evaluation, it is difficult to directly\nextend the informal approach to advanced mathematics. Formal mathematical reasoning helps address\nthese challenges. In this paper, it refers to mathematical reasoning grounded in formal systems,\nwhich have a syntax for well-formed formulas and can perform reasoning by manipulating formulas\nfollowing a set of well-defined inference rules. Examples of formal systems include axiomatic set\ntheory [67, 68], higher-order logic [69\u201371], and dependent type theory [72\u201374]. They are widely used\nin mathematics and computer programming. In math, they can express axioms, theorems, and proofs.\nIn programming, they are used to specify programs and reason about semantics. The connection\nbetween mathematical proofs and computer programs is deepened by theoretical results such as the\nCurry-Howard correspondence [75].\nMathematics expressed in formal systems is called formal mathematics. It is expressive: Almost all\nmathematics can be expressed by first-order logic with ZFC set theory [76]. At the same time, it\nenforces formal constraints: Formulas must conform to grammar rules, and their manipulation must\nconform to inference rules that capture valid reasoning. This is similar to how board games like chess\nand Go are played within predetermined rules and moves. The success of AI on board games [77, 78]\nsuggests that a similar approach could be applied to formal mathematics, even though mathematics,\nwith an infinite number of configurations and moves, can be much more challenging than Go.\nSpecifically, formal systems can be useful environments for AI to learn mathematics. A formal\nenvironment can guarantee the soundness of reasoning, provide automatic feedback, and check if\nthe goal has been achieved. This is crucial to addressing the two challenges faced by the informal\napproach: data scarcity and evaluation. Automatic feedback can serve as learning signals and alleviate\nthe need for human-annotated training data. Rigorous proof verification allows us to evaluate the\nmodel's reasoning without worrying about hallucination.\nProof Assistants and Lean. A concrete type of formal systems is called proof assistants, also known\nas interactive theorem provers. These are software tools that enable humans to write formal proofs\nabout mathematics or verified software. Common examples of proof assistants include Coq [21],\nIsabelle [20], and Lean [24, 25]. They have different logical foundations but share similarities from a\nuser's perspective, regardless of whether the \u201cuser\u201d is human or AI. For simplicity, we will frequently\nuse Lean as an example to explain key concepts in formal mathematical reasoning, though many\nideas can be applied to other proof assistants or formal systems in general.\nFig. 2 demonstrates how Lean is used to formalize mathematics. At its core, Lean is a functional\nprogramming language with dependent types [79], making it suitable for writing not only conventional\nprograms but also mathematical definitions, theorems, and proofs. Fig. 2 (Middle) is an example\nLean file. First, it defines natural numbers (Nat) as either zero or the successor of another natural\nnumber. Then, it defines addition between two natural numbers (add) as a recursive function. Finally,\nit states and proves the theorem add_zero (\\(\\forall n \\in N, 0 + n = n\\)). Lean can automatically check if\nthe proof is correct with respect to the theorem statement. Technically, due to the Curry-Howard"}, {"title": "Other Directions in AI for Mathematics", "content": "While we have highlighted the distinction between informal and formal approaches, AI4Math is a\nbroad and open-ended research field that does not fit neatly into this dichotomy. For example, in addi-\ntion to generating solutions or proofs, neural networks can also be used to approximate mathematical\nfunctions. This includes simple functions such as greatest common divisor [84], eigenvalues [85],\nand modular arithmetic [86]. These functions can be computed by well-known algorithms; however,\napproximating them through neural networks offers valuable insights into the model's capabilities and\nmechanistic interpretability. Furthermore, neural networks can approximate more complex functions\nfor which we do not have efficient algorithms, with applications in cryptography [87], theoretical\nphysics [88], control theory [89], and partial differential equations [90].\nCollaborative efforts between AI researchers and mathematicians have led to notable progress on\nopen problems in mathematics. For example, FunSearch [91] uncovered new solutions to the cap\nset problem, a long-standing open problem in additive combinatorics [92]. It represents solutions as\nprograms and leverages LLMs to generate new programs from existing ones, using an automated\nevaluator to assess the quality of solutions. Gukov et al. [93] use reinforcement learning (RL)\nto generate transformations for knot simplification in topology, while Wagner [94] uses RL to\nfind counterexamples to open conjectures in graph theory. PatternBoost [95] finds mathematical\nconstructions by combining Transformers with classical local search algorithms, demonstrating\neffectiveness on open problems in graph theory and combinatorics [96]. These works share similarities\nwith formal mathematical reasoning: They also represent mathematical objects as symbols and\nmanipulate them according to well-defined inference rules. However, they are tailored to specific\nsubdomains rather than relying on general-purpose mathematical languages like Lean. Incorporating\ndomain-specific mathematical insights can be valuable, as further discussed in Sec. 4.2."}, {"title": "Recent Progress in AI for Formal Mathematical Reasoning", "content": "AI has made substantial progress in formal mathematical reasoning. First, we discuss the progress in\ntwo key tasks: autoformalization and theorem proving. Then, we sample two adjacent areas natural\nlanguage and code generation\u2014that benefit from verifiable reasoning enabled by the formal approach."}, {"title": "Autoformalization", "content": "Pinpointing the origin of the phrase \"autoformalization\u201d is challenging, but the pioneers of automated\ntheorem proving in the 1950s and 60s clearly conceived the idea:\nNevertheless, it was not until the rise of interactive theorem proving (e.g., Automath [98]) that people\nbegan to seriously consider automating the labor-intensive formalization process [99].\nRule-Based Autoformalization. Mohan Ganesalingam [100] explored a linguistic foundation\nfor mathematical texts, introducing a theory of types to eliminate ambiguities in both words and\nsymbols. To address the flexibility and complexity of natural languages, many systems have adopted\ncontrolled natural language-a restricted subset of natural language governed by formal grammar-to\nallow users to express mathematical proofs in a way that is both natural and formal. Examples of\nsuch systems include Mizar [101], NaProChe [102], ForTheL [103], MathNat [104], and Verbose\nLean [105]. Strictly speaking, these systems may not qualify as autoformalization since they do not\ndirectly handle natural language in its entirety. Simultaneously, a high-level grammar-writing tool\ncalled the Grammatical Framework (GF) [106] has been gaining attention. This tool allows for the\nflexible development of customized grammars to parse mathematical texts directly. GF-based systems\ninclude GLIF [107], a framework for symbolic natural language understanding and processing, and\nGFLean [108], an autoformalization framework that translates natural language statements into\nLean's formal language.\nNeural and LLM-based Autoformalization. Kaliszyk et al. [109, 110] conducted early ex-\nperiments using machine learning to parse informal mathematical texts, followed by Wang et al.\n[111, 112], who applied neural machine translation techniques to convert informal mathematical\nstatements into the Mizar language. Unlike rule-based methods, machine learning approaches are\nmore flexible and can capture edge cases in natural language that experts might miss when creating\nrules. Although Wang et al. [112] explored unsupervised machine translation [113], most early\nmachine learning methods for autoformalization relied heavily on an aligned corpus of informal and\nformal statements, which is difficult to obtain on a large scale.\nLLMs like GPT-4 [3] represent a new paradigm of machine learning. These autoregressive models\nare pretrained on vast amounts of Internet data and can be quickly adapted to various downstream\ntasks through a few demonstrations, without requiring parameter updates\u2014a capability known as\nin-context learning. Wu et at. [37] showed that, with fewer than five expert-crafted examples, LLMs\ncan translate between formal and informal mathematical statements to some extent. This finding\nis promising, as it suggests that we may not need to collect a large aligned corpus of informal-\nformal statements\u2014an almost impossible task given the variety of formal systems-to achieve\nautoformalization. Another notable observation in Wu et al. [37] is that (auto-)informalization\nis generally easier than (auto-)formalization. With the same model, about 30% accuracy was\nachieved in formalizing competition-level math statements, while over 70% accuracy was achieved\nin informalizing even more challenging undergraduate-level math problems. This insight prompted\nfollow-up research utilizing LLMs-based back-translation, where synthetic aligned corpora were\ngenerated by auto-informalizing existing formal statements [38, 114]. Finetuning a smaller model\non this synthetic data led to notable improvements in autoformalization performance. Building on a\nsynthetic corpus, Lu et al. [115] further incorporated additional signals from the formal environment\nto develop a process-driven autoformalizer.\nLLMs have also significantly advanced the translation of natural languages into formal domain-\nspecific languages (DSLs) like SQL [116] and linear temporal logic [117, 118]. In this paper, we\nprimarily focus on the more expressive formal languages used in foundational proof assistants. These\nlanguages are capable of accommodating both statements and proofs of modern mathematics, but\ncome with the challenge of non-static vocabularies (definitions and proof tactics can evolve or expand\nover time). Nevertheless, autoformalization and NL-to-DSL translation are closely related, sharing\ntechniques such as self-consistency and self-correction.\nApplication of Autoformalization. Autoformalization serves as a bridge between informal and\nformal mathematical knowledge, resulting in three immediate applications: (1) data argumentation for\ntraining neural proving agents (via autoformalizing informal theorem statements) [37, 39], (2) guiding\nformal theorem proving via informal proofs [81, 82], and (3) validating informal reasoning [83, 119].\nThe first two applications are closely related to neural theorem proving, which will be discussed in\ndetail in the next section (Sec. 3.2). The third application will be examined in Sec. 3.3."}, {"title": "Neural Theorem Proving", "content": "Proving theorems in any sufficiently expressive formal system is undecidable [120]. Thus, theorem\nproving inevitably requires heuristics. Deep learning has been widely used for learning heuristics to\nfind proofs in formal systems. Holophrasm [121] was the first system to demonstrate the feasibility\nof training deep neural networks to guide proof search. Holophrasm used the Metamath formal\nlanguage [68] as its logical backbone, training gated recurrent unit (GRU) networks [122] on human-\nwritten formal proofs to serve as policy and value networks in Monte Carlo Tree Search (MCTS)\u2014the\nsame search algorithm used in AlphaGo [78]. This training paradigm was expanded in GPT-f [34],\nwhich trained a single Transformer model for predicting proof steps in Metamath. GPT-f enjoyed\nsubstantial gains from pretraining on informal math-related data (arXiv Math, Math StackExchange,\nGithub). Subsequent approaches have trained richer architectures such as retrieval-augmented\nTransformers [35] and also exploited zero-shot prompting of general-purpose LLMs [36, 40]. We\nnow highlight several prominent ideas in this literature.\nExpert Iteration. Since a formal theorem proving environment can guarantee the validity of proofs,\nwhenever a model finds a proof of a new theorem, that proof can be used as new training data. In the\ncontext of theorem proving, expert iteration consists of alternating between (a) attempting a set of\nunsolved problems, and (b) finetuning the model using new training data produced during the first\nphase. This has been shown to lead to improvements in formal theorem proving [123, 124], including\nin the recent work of AlphaProof [7]. However, gains tend to diminish after a few iterations. It is still\nan open problem to obtain continuous improvements, leveraging the potentially unlimited feedback\nthat a formal verifier can provide.\nLearning from Mistakes. A key benefit of formal proof environments is that they can provide error\nmessages when a proof step fails. COPRA [36], an approach that repeatedly asks a frontier LLM to\npredict proof steps from within a search loop, uses such error messages as part of the LLM's prompts.\nCOPRA is also equipped with a memory that stores a subset of the incorrect predictions that it made\nwhile proving a particular theorem, and this memory is included in the LLM's prompt. Because\nof frontier LLMs' ability to learn in context, these strategies reduce the odds of similar mistakes\nbeing repeated again and again. However, not all mistakes result in immediate failures; many lead\nto distractions or unproductive paths without making meaningful progress toward the proof goal.\nIdentifying and learning from such mistakes remains a challenge.\nInformal Proof Sketches. Neural theorem proving in formal languages has also benefited from\ninformal proofs, generated in natural language. Notably, Draft, Sketch and Prove (DSP) [81] proposed\nto first have the LLM generate a \u201cproof sketch\u201d, in natural language, to then attempt to formalize this\nsketch in Isabelle. Lean-STaR [125] proposed to interleave formal and informal reasoning steps in\ntheorem proving in Lean. COPRA, mentioned above, also takes in informal proofs as an optional\ninput and uses them as part of zero-shot proof-step-prediction queries to a general-purpose LLM.\nLibrary Learning. Human mathematicians can leverage a continuously growing library of mathe-\nmatical results to find new ones. Each new theorem potentially enters this library for reuse later in\nhigher-level work. Building towards this behavior, research in AI for formal mathematics has started\nto explore the idea of library learning, where not only the search heuristics (neural policy and value\nfunctions) improve with more data, but also the symbolic library that is available. Library learning\nfirst gained popularity in the context of program synthesis, with systems such as DreamCoder [126]\nthat are capable of discovering increasingly higher-level abstractions from its solutions to previous\ntasks. For theorem proving, LEGO-Prover [127] demonstrated this idea in Isabelle, by proposing po-\ntentially reusable lemmas to aid in the proof of a theorem at hand. Besides new theorems, researchers\nhave also explored learning tactics-procedural proof-generation strategies that shorten otherwise\nlengthy low-level proofs, often tailored to a particular mathematical domain. Tactic induction has\nbeen demonstrated to work in simpler formalisms [128, 129], but has not yet been developed for\nfull-fledged environments such as the tactic languages in Lean or Coq.\nPremise Selection and Retrieval. A large, changing library of theorems poses challenges for\ntraining neural theorem proving models, since the prover should not be limited solely by the lemmas\nand definitions it was given at training time. One architecture that can accommodate a changing\nlibrary is retrieval-augmented generation (RAG). In RAG, before attempting to generate (e.g., a proof\nfor a target theorem), we first retrieve potentially useful pieces of data from a database (e.g., lemmas\nfrom a mathematical library), putting these in the context that is given to the LLM. Retrieving lemmas\nthat are likely to be used to prove a target theorem is a problem known as premise selection [130],\nwhich has been extensively studied both in learning-guided [29, 131, 132] and symbolic [133-135]\ntheorem provers. Even before neural networks were directly applied to generating proofs, they had\nbeen shown to be effective as premise selection models in earlier works like DeepMath [29].\nReProver, the architecture introduced in LeanDojo [35], applied retrieval for neural theorem proving,\nwhere it first retrieves lemmas from a mathematical library. The COPRA [36] approach also uses\nretrieved lemmas as part of LLM queries. One desideratum in such retrieval-based approaches,\noriginally identified in LeanDojo, is success on a train/test split named \u201cnew premises\u201d, where\neach theorem seen at test time requires at least one premise that has not been seen during training.\nThis setup is closer to real use cases for a theorem prover, where human mathematicians might be\nformalizing a new domain, frequently building on recently proved lemmas that did not exist in the\noriginal training data."}, {"title": "Verified Reasoning in Natural Language", "content": "Many reasoning problems expressed in unstructured natural language are difficult to formalize\ncompletely. In such cases, it is desirable to still have some form of verification for natural language\nreasoning. Several works have proposed to \"verify\" natural language reasoning via trained, few-shot\nprompted, or symbolic verifiers. For example, the paper introduced the GSM8K dataset [15] of\ngrade-school mathematical word problems proposed finetuning GPT-3 to verify a partial solution.\nCombining GPT-3 as a solution generator with the finetuned verifier produced substantial accuracy\ngains. On this line of work, OpenAI later released PRM800K, a large-scale dataset of human-\nwritten feedback on step-by-step mathematical solutions, which has been used to explore training\nverifiers [136]. For logical reasoning in natural language, NLProofS [137] proposed a step-wise\nverifier, trained to evaluate whether a given conclusion is entailed by a set of premises, using it to\nguide a step-by-step prover. Step-by-step verifiers can also be obtained by prompting an LLM in a\ncontext dedicated to verification, as done in Natural Programs [61]. In all of these works, while the\nverifier cannot formally guarantee the validity of the reasoning, it nonetheless provided a boost in\noverall performance and faithfulness of the responses.\nAs opposed to verifying directly in natural language, another line of work has explored using LLMs to\nfirst formalize a problem given in natural language, then leverage a symbolic solver to find solutions.\nIn this thread, SatLM [138] and LINC [119] have both leveraged SAT/SMT solvers as a logical\nbackend for reasoning problems, with the LLM only being responsible for parsing the original\nproblem into an appropriate formal counterpart. In both methods, however, the system does not\nprovide a step-by-step solution, since all the reasoning happens inside the solver, in a form that is\nchallenging to translate back to natural language. LogicGuide [139] proposed to use a formal system\nto constrain the step-by-step deductions from the LLM, producing chain-of-thought reasoning that\nalternates between formal and natural language. In all of these systems, while the formal reasoning is\nguaranteed to be sound, it is still difficult to assess whether the natural language problem has been\nproperly formalized. This typically stems from the fact that natural language allows for ambiguity and\nreliance on common sense or general world knowledge, whereas the formal problem must be fully\nunambiguous and all of the assumptions must be fully written down, which is typically challenging."}, {"title": "Formal System Verification and Verified Generation", "content": "The formal verification of software [140-142", "144": "has long been among\nthe foremost applications of formal mathematics. In this area, one first specifies the correctness and\nsecurity requirements of a system as formal assertions. Next, theorem proving and model-checking\ntechniques are used to prove that the system satisfies its requirements or, alternatively, to find bugs.\nSpecifically, deductive theorem proving has been applied to a range of critical systems, including\nmicroprocessor designs [145", "147": "OS kernels [46, 148", "150": "compilers [47", "151": "and network infrastructure [152, 153", "154": ".", "156": "and the refinement of existing proofs [40, 157", "158\u2013161": "ngenerating helpful assertions [162", "163": ".", "164": ".", "166": "and\nsome recent research finds LLM-generated code to exhibit more vulnerabilities than human-written\ncode [167"}]}