{"title": "Knowledge Graph Enhanced Language Agents for Recommendation", "authors": ["Taicheng Guo", "Chaochun Liu", "Hai Wang", "Varun Mannam", "Fang Wang", "Xin Chen", "Xiangliang Zhang", "Chandan K. Reddy"], "abstract": "Language agents have recently been used to simulate human behavior and user-item interactions for recommendation systems. However, current language agent simulations do not understand the relationships between users and items, leading to inaccurate user profiles and ineffective recommendations. In this work, we explore the utility of Knowledge Graphs (KGs), which contain extensive and reliable relationships between users and items, for recommendation. Our key insight is that the paths in a KG can capture complex relationships between users and items, eliciting the underlying reasons for user preferences and enriching user profiles. Leveraging this insight, we propose Knowledge Graph Enhanced Language Agents (KGLA), a framework that unifies language agents and KG for recommendation systems. In the simulated recommendation scenario, we position the user and item within the KG and integrate KG paths as natural language descriptions into the simulation. This allows language agents to interact with each other and discover sufficient rationale behind their interactions, making the simulation more accurate and aligned with real-world cases, thus improving recommendation performance. Our experimental results show that KGLA significantly improves recommendation performance (with a 33%-95% boost in NDCG@1 among three widely used benchmarks) compared to the previous best baseline method.", "sections": [{"title": "Introduction", "content": "Large Language Model (LLM) agents have demonstrated strong capabilities in conversation and decision-making across various tasks (Xi et al. 2023; Guo et al. 2024, 2023a). By enabling multiple LLM agents to cooperate, each agent can have its profile, actions, and behaviors, simulating diverse human behaviors. Recent works have employed LLM Agents to simulate real-world recommendation scenarios (Zhang et al. 2024b). In these simulations, each agent represents a user or an item in the recommendation system, and each agent maintains a memory that records the user or item's profiles. The interactions between agents simulate user interactions with items, dynamically updating the agents' memories to reflect changes in user preferences or the recognition of unique item features.\nWhile LLM Agents can capture more explainable and explicit user profiles through text during the recommendation process, previous work has only considered adding short, basic descriptions of users and items as prompts during the interactions. As a result, the updated memory for user agents is nonspecific and general due to a lack of rational information about the user's choice (see Figure 1). With these insufficient memory profiles, LLMs struggle to identify precise user preferences and may recommend irrelevant items. In this work, we analyze the reason for insufficient user agent and item agent profiles, primarily due to the simulation relying solely on simple descriptions without rationalizing why users like or dislike certain items. Consequently, most user or item agent memories are generated by LLMs based on limited information. Such profiles heavily rely on the pre-trained knowledge of LLMs, making them susceptible to generating generic profiles. User profiling is a critical task for recommender systems. Hence, addressing the question of 'how to provide user agents with sufficient information during Agent simulation to obtain more rational and precise user profiles?' remains a crucial but unresolved problem.\nTo tackle this issue, we aim to leverage a Knowledge Graph (KG) containing entities with specific meanings to provide extensive rationales to enhance agent simulation for recommendation. For example, KG paths can provide rationales for why a user may like an item (User \\(\\leftarrow\\)features describe as CD), thus helping to build better user and item agent profiles. Most of the previous work on using KGs for recommendation represents the knowledge from a KG in the form of embeddings and trains a graph neural network to obtain graph embeddings, which are then concatenated with user embeddings to represent user profiles. In contrast, since we use LLM Agents to simulate users and items when the number of interactions is limited and the user or item profiles are represented by text, the KG information should also be represented by text to effectively influence the agent simulation process.\nBased on this motivation, we first identify the information from the KG required for recommendation. We formulate this as a 'path-to-text' problem, where the user and item can be regarded as nodes in a KG, and paths between the user and item indicate the rationales for why the user chooses that item, thus helping to build more precise user agent memory. There are a few previous works that focus on leveraging KGs for LLM agents (Jiang et al. 2024; Xu et al."}, {"title": "Related Work", "content": "LLM Agents\nLarge language model-based agents are widely researched for various scenarios. These agents can take actions, interact with the environment, and obtain feedback. The key capabilities of LLM agents are: 1) Take Action (Yao et al. 2022): Prompting the agent to perform an action or make a decision; 2) Reflection (Shinn, Labash, and Gopinath 2023): After taking an action, the agent receives feedback from the environment, which allows it to reflect on the task and improve decision making in subsequent trials; and 3) Memory (Zhang et al. 2024c): Agents store the lessons learned from reflection. In our work, during the simulation stage, the user agent first selects a preferred item from a list of items (Taking Action). Given the ground-truth item, the agent then reflects on its previous choice (Reflection). Subsequently, it"}, {"title": "LLM Agents for Recommendation", "content": "updates its profile to record its preference (Memory). In the ranking stage, the user agent provides a preferred rank list of items (Taking Action) based on the given list.\nLLM Agents for Recommendation\nDue to the strong capabilities of LLM agents, they have successfully been employed in recommendation tasks. (Wang et al. 2024) proposes two categories in agent-based recommendation: recommender-oriented and simulation-oriented. The recommender-oriented approach aims to develop a recommender agent equipped with enhanced planning, reasoning, memory, and tool-using capabilities to assist in recommending items to users. RecMind (Wang et al. 2023b) and InteRecAgent (Huang et al. 2023) both develop single agents with improved capabilities for recommendation. RAH (Shu et al. 2023) and MACRec (Wang et al. 2024) support collaboration among different types of agents to recommend items to users.\nIn contrast, the simulation-oriented approach focuses on using agents to simulate individual user behaviors and item characteristics. RecAgent (Wang et al. 2023a) and Agent4Rec (Zhang et al. 2024a) employ agents as user simulators to simulate interactions between users and recommender systems, investigating the plausibility of simulated user behaviors. AgentCF (Zhang et al. 2024b) explores simulating user-item interactions using user agents and item agents. The memories of user agents and item agents are dynamically updated during the simulation, and the final memory is used to recommend items to users.\nOur work falls under the category of simulation-oriented approaches. Previous simulation work only focused on using agent memory to simulate user profiles for the recommendation, neglecting the construction of high-quality user agent memories. Poor user agent memory can impair recommendation performance. Our work leverages KGs to incorporate comprehensive rationale information into the entire process of LLM Agents-based recommendation, thereby building well-grounded and precise user agent memories."}, {"title": "Knowledge Graph and LLM Agents", "content": "With the latest advances in LLMs, they are utilized in synergy with KGs to provide accurate information. Most previous works (Jiang et al. 2024; Xu et al. 2024; Luo et al. 2023) focus on synergizing LLM and KGs for question-answering tasks. The synergizing paradigm is deductive - Given a question, LLMs identify the starting entity node and then act as planners to generate relation paths, traversing the KG to reach potential entities that can answer the question. However, the synergizing paradigm between LLMs and KGs in recommendation systems is inductive and differs from previous methods. In this context, the starting entity node (user) and the target entity node (item) are already known within the KG. LLMs are responsible for analyzing all the paths between these two nodes and summarizing the key reasons why the user node can reach the target node. These rationales are then used to update the user agent's memory. In contrast to previous work, our approach is the first to leverage LLM agents to inductively analyze KG paths for reflection, thereby enhancing recommendation performance."}, {"title": "Methodology", "content": "Notation and Problem Definition\nWe will first introduce the required notations and define the problem.\nRecommender System. Let the user set be denoted by \\(U\\), and the item set be denoted by \\(I\\). Each user \\(u \\in U\\) has an interaction history \\([i_1, i_2, ..., i_n]\\). We have a ground-truth label \\(y\\) indicating whether the user likes an item (\\(y = 1\\)) or does not like it (\\(y = 0\\)).\nKnowledge Graph. A KG is a structured representation of knowledge that contains abundant facts in the form of triples \\(G = \\{(e_h,r,e_t) | e_h,e_t \\in E,r \\in R\\}\\), where \\(e_h\\) and \\(e_t\\) are head and tail entities, respectively, and \\(r\\) is the relation between them. \\(E\\) is the entities set in the KG and \\(R\\) is the relations set in the KG. A path in a KG is a sequence of triples: \\(p = e_0 \\longrightarrow e_1 \\longrightarrow ... \\longrightarrow e_l\\), connecting the entity \\(e_0\\) to the entity \\(e_l\\).\nLLM Agent and LLM Recommendation. For the LLM agent, we denote its memory as \\(M\\). During the simulation stage, the reflection process for the agent is represented by the function \\(Reflection\\). In the ranking stage, given a user and a list of items, the LLM used to generate the ranked list is represented by the function \\(LLM\\)."}, {"title": "Overall Framework", "content": "The architecture of our proposed framework (see Figure 2 and Algorithm 1) has three stages: Initialization, Simulation and Ranking. It is designed to combine LLM agents with KGs to enhance agent memory during simulation and improve recommendation performance during ranking. In the initialization stage, the memories of all users are set using the template \"I enjoy ...,\" while item memories are initialized with the titles and categories of the items.\nThe simulation stage consists of two phases: Autonomous Interaction and Reflection. Given a user \\(u\\) with a chronological sequence of behavioral interactions \\([i_1, i_2,..., i_n]\\), the simulation stage aims to optimize the memories representing the user and item profiles by simulating real-world user-item interactions. At the beginning of the simulation, we initialize the user and item agent memories \\(M_u\\) and \\(M_i\\), using basic properties. Then similar to most sequential recommendation settings (Wang et al. 2019; Guo et al. 2023b), for each user \\(u\\), we use items \\([i_1, i_2, ..., i_{n-1}]\\), except the last item \\(i_n\\) of the behavior sequences, as positive items for simulation. At each step of the interactions between \\(u\\) and \\(i_j \\in [i_1, i_2, ..., i_{n-1}]\\), we randomly sample a negative item \\(i^-\\) with high popularity among all items \\(I\\) to help the user agent refine their profiles better through comparison. We use the last item \\(i_n\\) as the ground-truth item in the ranking stage for testing.\nFor each user \\(u\\) and item \\(i\\), we first position these nodes in the KG. Then, we use our Path Extraction module to extract all 2-hop paths \\(P^{ui}_2 = u \\longrightarrow e_1 \\longrightarrow i\\) and 3-hop paths \\(P^{ui}_3 = u \\longrightarrow e_1 \\longrightarrow e_2 \\longrightarrow i\\) from the KG. Based on the extracted paths, we apply our Path Translator module to convert \\(P^{ui}_2\\) to text \\(T^{ui}_2\\) and \\(P^{ui}_3\\) to text \\(T^{ui}_3\\). Finally, we apply our Path"}, {"title": "Knowledge Graph Path Extraction", "content": "Incorporation module to incorporate \\(T^{ui}_2\\) and \\(T^{ui}_3\\) into the LLM Agents' simulation and ranking process.\nIn the Autonomous Interaction phase, we ask the user agent to choose an item from \\(i^+\\) and \\(i^-\\) based on the current user and item memories \\(M_u\\), \\(M_{i^+}\\), and \\(M_{i^-}\\), as well as the 2-hop relations between the user and items \\(T^{ui^+}_2\\) and \\(T^{ui^-}_2\\). After each interaction, the user agent selects an item \\(i_{select}\\) and we also ask the user agent to provide explanations \\(Y_{exp}\\) for this choice. To optimize the user agent and item agents, we derive the feedback signal by comparing the user agent's chosen item with the actual interacted item. In the Reflection phase, we inform the user agent whether the previous choice was correct or incorrect. Simultaneously, we incorporate the knowledge graph information \\(T^{ui^+}_2\\) and \\(T^{ui^-}_2\\) to enable the user agents to analyze the reasons behind their choices abductively and summarize key factors to update their memory. We also update the memory of item agents based on the information from KG paths.\nIn the ranking stage, we have user and item agents representing real-world user and item profiles. We focus on ranking the candidate items given a user \\(u\\) and a set of candidates \\(\\{C_1, ..., C_n\\}\\), the user agent's memory \\(M_u\\), the memories of all candidates \\(\\{M_{c_1}, ..., M_{c_n}\\}\\), and 2-hop KG information for each candidates. \\(R\\) is the final ranking list. In the following sections, we will describe our detailed design to incorporate KG information with LLM agents for recommendation.\nKnowledge Graph Path Extraction\nThis module aims to extract useful information from the knowledge graph \\(G\\) for building better user and item profiles. In recommendation systems, given a user \\(u\\) and his interaction history, the critical information needed is the ra-"}, {"title": "Path Translation: Expressing 2-hop Paths via Text", "content": "tionale behind why \\(u\\) chooses or ignores item \\(i\\). These rationales can provide detailed preference information that helps the user agent build a more accurate and comprehensive profile. In \\(G\\), paths between two nodes can explain why one node has a relation to another node, which can actually help explain why the user node \\(u\\) chooses or does not choose the item node \\(i\\) in \\(G\\). Hence, our first task is to extract paths as additional contexts for the following prompt. To achieve this, we propose the following path extraction procedure: for each user \\(u\\) and item \\(i\\), we first extract the 2-hop knowledge path set \\(P^{ui}_2\\) and 3-hop path set \\(P^{ui}_3\\), where \\(P_2\\) contains all 2-hop paths and \\(P_3\\) contains all 3-hop paths from \\(u\\) to \\(i\\).\nPath Translation: Expressing 2-hop Paths via Text\nAll 2-hop and 3-hop paths extracted from KG are represented as triples or quaternions. Since the input to LLM is in text format, our objective is to express these 2-hop and 3-hop paths in a textual form that LLM can understand. We identify two critical challenges in this translation process: Description Simplification and easily comprehensible to LLM. Description Simplification refers to the need to simplify the textual representation of the extracted paths, as the number of 2-hop and 3-hop paths can be large. If we do not shorten the text, its length may exceed the token limit of the LLM. Furthermore, LLMs may struggle to capture important factors from longer contexts (Liu et al. 2024). Easily comprehensible to LLM refers to the need for presenting the path information in a way that the LLM can easily comprehend. While directly adding all 2-hop path triples to the prompt is one approach (Shu et al. 2024), this method necessitates introducing the entire KG to LLM, which is feasible only for very small graphs. Additionally, LLMs often strug-"}, {"title": "Path Translation: Expressing 3-hop Paths via Text", "content": "gle to effectively process and analyze these direct triples. In recommendation scenarios, we require the LLM to act as an analyzer, examining the potential critical reasons behind user choices based on the relationships between users and items. Thus, we aim to translate the triples into more natural, human-like language to improve the LLM agent's understanding of their underlying meaning.\nAlgorithm 2 provides the details of the expression of 2-hops via text, and some examples of converting 2-hop and 3-hop to text are shown in Figure 2. We first group all paths for each user-item pair by the overall edge type of the paths. For each edge type (\\(r_1, r_2\\)), we have a subset of paths associated with it. Since the start entity (user) and the end entity (item) are the same within each subset, we merge all paths by concatenating the second entities as a list. This approach reduces the number of 2-hop paths while still representing the relevant information. To make the text better understandable for the LLM, we describe the merged formulas by emphasizing the relationships between the user and the item. For example, given a merged paths set \\(u \\longrightarrow (e_1, e_2, ..., e_n) \\longrightarrow i\\) with edge type \\(r_1 = mentions, r_2 = describe_as\\), we describe it as \"User mentions features \\(e_1, e_2, ..., e_n\\) which are described as this item\". This approach reduces the length of the 2-hop path information and explicitly prompts the LLM to perform better reasoning by highlighting the relationships.\nPath Translation: Expressing 3-hop Paths via Text\nAlgorithm 3: EXP-3HOP(G, u, i, \\(\\{(u, i^+, i^- ), ..., (u, i_n^+, i_n^- )\\}\\))\nRequire: Knowledge Graph G, user u and item i, training samples for u: \\(\\{(u, i^+, i^- ), ..., (u, i_n^+, i_n^- )\\}\\), where \\(i^+\\) is a positive item and \\(i^-\\) is a negative item sampled during autonomous interaction. Functions FIND-3HOP(G, u, i) which retrieves all 3-hop paths between u and i, and GET-DESC(P) which returns entities except u and i involved in path P\nEnsure: Text \\(T^{ui}_3\\) containing natural language descriptions of 3-hop paths between u and i\nInitialize: positive entity set \\(E^+ \\leftarrow \\emptyset\\), negative entity set \\(E^- \\leftarrow \\emptyset\\), non-informative entity set \\(S_u \\leftarrow \\emptyset\\)\nfor each \\((i^+, i^- )\\) in training samples do\n\\(E^+ \\leftarrow E^+ \\cup GET\\text{-}DESC(FIND\\text{-}3HOP(G, u, i^+ ))\\)\n\\(E^- \\leftarrow E^- \\cup GET\\text{-}DESC(FIND\\text{-}3HOP(G, u, i^- ))\\)\nend for\n\\(S_u \\leftarrow E^+ \\cap E^-\\) \u25b7 Identify non-informative common entities between positive and negative items.\n\\(T^{ui}_3 \\leftarrow GET\\text{-}DESC(FIND\\text{-}3HOP(G, u, i))\\)\nRemove non-informative entities: \\(T^{ui}_3 \\leftarrow T^{ui}_3 \\setminus S_u\\)\nreturn \\(T^{ui}_3\\)\nSimplifying the description and making it simpler for the LLM to understand becomes more challenging for 3-hop paths because the number and relations of 3-hop paths are much larger compared to 2-hop paths. Unlike emphasizing the relations of 2-hop paths, the objective of using 3-hop paths is to incorporate more descriptive information for updating agents' memories in the Reflection stage."}, {"title": "Path Incorporation: Incorporating Text", "content": "Algorithm 3 provides the details of expressing 3-hops through text. The number of 3-hop paths is too large, as shown in Table 2. In the Autonomous Interaction and Reflection phase for the simulation stage, where the user needs to select one item among the positive and negative items, the motivation for adding KG information is to incorporate discriminative factors between these two items for the user agent. Therefore, we only need the discriminative features between the user's positive item pair and the user's negative item pair. Hence, we first construct a non-informative entity set \\(S_u\\) for each user \\(u\\). Specifically, entities that appear in both positive items and negative items indicate that they do not provide useful information for distinguishing user preferences, and thus they will be added to this set. Then, for user u and item i, we extract the 3-hop paths from the KG, extract the descriptive entities, and filter based on \\(S_u\\). The descriptive entities are pre-defined. For example, if a KG contains four types of entities: user U, item I, category C, and words W, we only select category C and words W as descriptive entities. Finally, we obtain the filtered descriptive entities \\(T^{ui}_3\\) which may indicate the user's potential rationales for their choice.\nPath Incorporation: Incorporating Text\nAfter obtaining 2-hop and 3-hop text descriptions from the KG G, we need to incorporate these descriptions into the overall framework. As shown in Algorithm 1, we incorporate translated 2-hop KG text into the Autonomous Interaction stage (line 8), 2-hop and 3-hop KG text into the Reflection stage (lines 10 and 11), and 2-hop KG text into the Ranking stage (line 14)."}, {"title": "Experiments", "content": "Experiment Settings\nWe conducted extensive experiments to address the following research questions (RQs):\nRQ1: Does incorporating KG information enhance the recommendation performance?\nRQ2: How much do different types of KG information contribute to the overall performance?\nRQ3: How does KG information influence agent memory (user profiles) in simulation?\nRQ4: How does the enhanced agent's memory influence the ranking?\nRQ5: How much does our method reduce the input word count for the LLM?\nDatasets. Following previous works, we conducted our experiments on three datasets containing KG, including the CDs, Clothing, and Beauty which comprises product review data from existing recommendation benchmarking datasets (McAuley et al. 2015). Original data sets and Knowledge Graph (KG) information are sourced from (Xian et al. 2019). To reduce the impact of expensive API calls and facilitate effective simulations, consistent with previous"}, {"title": "RQ1: Does incorporating KG information enhance the recommendation performance?", "content": "settings (Zhang et al. 2024b), we sample dense recommendation subsets, where most users have rated a large portion of items. Specifically, we sample 100 users along with their corresponding items from each dataset for experiments. The dataset statistics are presented in Table 2. The Knowledge Graph comprises five types of entities:\nUser: User in recommender system\nItem: Product to be recommended to users\nFeature: A product feature word from reviews\nBrand: Brand or manufacturer of the product\nCategory: Category of the product\nand eight kinds of relations:\nEvaluation metrics. Similar to previous studies, we used NDCG@K as an evaluation metric for comparing different methods, where K is set to 1, 5, and 10. We considered the items excluding the last item of the user behavior sequences as the training data for the simulation stage in the recommendation, and the last item as the ground-truth item. To mitigate the randomness of the LLM, each experiment was repeated three times, and the mean and standard deviation were reported.\nBaselines\nWe compared the proposed model with the following categories of baseline methods available in the literature.\nConventional recommendation methods. We included BPR (Bayesian Personalized Ranking) (Rendle et al. 2012) which uses matrix factorization to learn the potential representations of users and items and performs recommending based on these representations; Pop (Popularity-based recommendation) (Ji et al. 2020) which ranks candidates based on their popularity; and BM25 (Best Matching 25) (Robertson and Zaragoza 2009) which ranks candidates based on their textual similarity to the user's past interactions.\nDeep-learning based recommendation methods. We used SASRec (Kang and McAuley 2018) which captures the sequential patterns of the users' historical interactions utilizing a transformer-encoder."}, {"title": "RQ2: How much do different types of KG information contribute to the overall performance?", "content": "The overall performance of the recommendation measured by NDCG@K is reported in Table 1. From the results, we have the following observations:\n1) Our method significantly outperforms all baselines in all datasets. Compared to the previous best baseline, our methods obtained 95.3%, 44.7%, and 40.8% improvements in NDCG@1 on the three datasets. This shows that incorporating the KG information through our methods can significantly enhance the model's ability to make accurate recommendations.\n2) The performance of all LLM-based recommendation methods surpasses that of conventional and deep learning methods. This indicates that LLMs can improve the recommendation performance, especially in settings with a small number of training datasets, due to their strong generalization capability.\nRQ2: How much do different types of KG information contribute to the overall performance?\nTo further investigate the effect of different types of KG information on recommendation performance, we conducted ablation studies on the CD dataset. The results are presented in Table 3, which show that incorporating 2-hop and 3-hop information from the KG can gradually improve the performance metrics. This demonstrates that each module contributes positively to the model and can complement each other, enabling the model to achieve better overall performance."}, {"title": "RQ3: How does KG information influence agent memory (user profiles) in simulation?", "content": "RQ3: How does KG information influence agent memory (user profiles) in simulation?\nOur proposed methods aim to ensure that the text is easily comprehensible for LLMs. In this experiment, to investigate whether the LLM understands the incorporated text, we conducted a case study to evaluate the impact of the KG information on the agent's memory during the Reflection stage.\nTo investigate further the main contribution of our method to the agent's memory, we will provide a case study of our method with KG. As shown in Figure 3, during simulation, with positive and negative items, the LLM can effectively conclude the potential preferred 2-hop features including \u201cgarden\u201d, \u201csultry\u201d, \u201cchick\u201d related to the user and help explore the expanded 3-hop features including \u201csensual\u201d to enrich the user profiles."}, {"title": "RQ4: How does the enhanced agent's memory influence the ranking?", "content": "RQ4: How does the enhanced agent's memory influence the ranking?\nTo investigate how the updated agent memory based on KG information influences the final recommendation, we show"}, {"title": "RQ5: How much does our method reduce the input word count for the LLM?", "content": "RQ5: How much does our method reduce the input word count for the LLM?\nA key objective of our proposed methods is to shorten the description of KG. In this experiment, we compare the word count of the original paths with the text generated by our methods for 2-hop and 3-hop paths. As shown in Table 4, our methods achieve a substantial reduction in word count, with around 60% for 2-hop paths and 98% for 3-hop paths, compared to the original descriptions of the path information across all datasets."}, {"title": "Conclusion", "content": "Conclusion\nUsing language agents for recommendation is a promising yet challenging task. Previous works on this topic have primarily focused on utilizing agents to simulate the recommendation process, often neglecting the rationale behind recommendations, thus have struggled to discover user preferences for recommendations. In this paper, we propose KGLA, the first framework that explores the syner-"}]}