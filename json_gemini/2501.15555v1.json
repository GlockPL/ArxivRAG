{"title": "Distributionally Robust Graph Out-of-Distribution Recommendation via Diffusion Model", "authors": ["Chu Zhao", "Enneng Yang", "Yuliang Liang", "Jianzhe Zhao", "Guibing Guo", "Xingwei Wang"], "abstract": "The distributionally robust optimization (DRO)-based graph neu- ral network methods improve recommendation systems' out-of- distribution (OOD) generalization by optimizing the model's worst- case performance. However, these studies fail to consider the impact of noisy samples in the training data, which results in diminished generalization capabilities and lower accuracy. Through experi- mental and theoretical analysis, this paper reveals that current DRO-based graph recommendation methods assign greater weight to noise distribution, leading to model parameter learning being dominated by it. When the model overly focuses on fitting noise samples in the training data, it may learn irrelevant or meaning- less features that cannot be generalized to OOD data. To address this challenge, we design a Distributionally Robust Graph model for OOD recommendation (DRGO). Specifically, our method first employs a simple and effective diffusion paradigm to alleviate the noisy effect in the latent space. Additionally, an entropy regular- ization term is introduced in the DRO objective function to avoid extreme sample weights in the worst-case distribution. Finally, we provide a theoretical proof of the generalization error bound of DRGO as well as a theoretical analysis of how our approach mit- igates noisy sample effects, which helps to better understand the proposed framework from a theoretical perspective. We conduct extensive experiments on four datasets to evaluate the effective- ness of our framework against three typical distribution shifts, and the results demonstrate its superiority in both independently and identically distributed distributions (IID) and OOD. Our code is available at https://github.com/user683/DRGO.", "sections": [{"title": "1 INTRODUCTION", "content": "Recently, Graph Neural Network (GNN)-based recommendation methods have gained extensive attention in various recommenda- tion tasks and scenarios [5, 11, 14, 43, 48]. Generally, GNN-based methods learn embeddings of users or items by capturing high- order collaborative signals from the user-item interaction graph. Although these GNN-based methods have achieved state-of-the-art performance in the collaborative recommendation, some assume that the training and test sets follow an independent and identical distribution (IID). Unfortunately, this assumption may not hold when faced with out-of-distribution (OOD) data (i.e., distribution shift) in real-world recommendation scenarios. Such data distribu- tion shifts may arise from various factors, such as changes in user consumption habits influenced by seasons, holidays, policies, etc. Additionally, various biases (e.g., popularity bias and exposure bias) in the recommendation system can lead to inconsistencies between training and test data distributions.\nExisting works have attempted to address the challenge of distri- bution shift using various techniques to enhance the generalization of recommendation models. For instance, some works [7, 26, 44] use causal learning and approximate inference methods to infer environment labels and further learn representations that are in- sensitive to the environment. Some works [32, 40] achieve OOD generalization by directly decoupling user-variant and invariant representations. In addition, other works employ data augmenta- tion or self-supervised learning [33, 39] methods to enhance the generalization performance of GNN-based methods on OOD data. However, the methods mentioned above also have some limitations in addressing distribution shifts: (1) The performance of these meth- ods, such as [7, 26, 44], relies on explicit environments as labels. If the environmental factors cannot be inferred, achieving satisfac- tory generalization will be difficult. And these methods [32, 40] to"}, {"title": "2 PRELIMINARY", "content": "In this section, we first define the notations used in this paper and then introduce the definition of DRO. Due to page limitations, we have provided an introduction to Diffusion model in Appendix E."}, {"title": "2.1 Problem Definition", "content": "Recommendation on Graphs. In GNN-based recommendation methods, we consider a given user-item interaction matrix $R \\in \\mathbb{R}^{|U| \\times |V|}$, where $U = \\{u_1,u_2, . . ., u_m\\}$ denotes the user set and $I = \\{1_1, 1_2, ..., i_n\\}$ represents the item set. GNN-based methods first convert the interaction matrix into graph-structured data $G = \\{U,I,\\&\\}$ and the $\\& = \\{(u, i)|r_{u,i} = 1\\}$ is the edge set. GNN- based methods use G as input to capture higher-order collaborative signals between users and items, thereby inferring user preferences towards items.\nDistribution shift on Recommendation. Due to environmen- tal factors, training and testing data distributions may differ in real-world scenarios. The environment is a key concept, as it is the"}, {"title": "2.2 Distributionally Robust Optimization", "content": "Distributionally Robust Optimization (DRO) differs from other OOD recommendation methods [7, 26, 44] that require environmental labels. Its core idea is to identify and optimize for the worst-case data distribution within a predefined range of distributions. This approach ensures that the model maintains good performance when facing distribution changes or shifts, thereby improving the model's generalization performance on OOD data. DRO is typically solved through a bi-level optimization problem: the outer optimization determines the model parameters that perform best under the worst distribution, while the inner optimization adjusts for all possible distributions. Its mathematical formulation is as follows:\n$\\min_ {\\theta \\in \\Theta} \\mathbb{E}_{(x,y) \\sim Q} [L(f_\\theta(x), y)]$\n$\\sup_ {Q \\in \\mathcal{P}(\\mathbb{P}_{train})} \\mathbb{E}_{(x,y) \\sim Q} [L(f_\\theta(x), y)]$\ns.t. $D(Q, \\mathbb{P}_{train}) \\le \\rho$,\nwhere $\\theta$ represents the optimal model parameters in DRO, and $L(\\cdot)$ denotes the loss function. sup is the supremum, which means finding the maximum value under the given conditions. The uncer- tainty set Q approximates potential test distributions. It is typically defined as a divergence ball with radius $\\rho$ centered around the nom- inal distribution $\\mathbb{P}_{train}$, expressed as $Q = \\{Q : D(Q, \\mathbb{P}_{train}) \\le \\rho\\}$, where D(,) represents a distance metric such as Wasserstein dis- tance or Kullback-Leibler (KL) divergence. Generally, constructing the uncertainty set and the nominal distribution is crucial to DRO."}, {"title": "3 METHODOLOGY", "content": "In this section, we first discuss the limitations of existing DRO- based methods, then propose a novel DRO approach and present the complete model structure, followed by a theoretical analysis. Figure 2 and Algorithm 1 (in Appendix) show the overall framework of the model and the algorithm pseudocode."}, {"title": "3.1 Limitations of DRO-based Recommendation Method", "content": "Drawback of KL divergence. Some recent works [25, 37] assume an overlap between the distributions of the training and testing sets and use KL divergence as a constraint for the uncertainty set. However, in practical scenarios, user behavior may exhibit high lev- els of uncertainty and significant randomness, leading to situations where the distribution of the testing set shares no standard support with that of the training set. KL divergence becomes extremely large in such cases, rendering the model optimization meaningless and preventing effective OOD generalization. We give a detailed theoretical derivation in the Appendix A.1.\nImpact of noise samples. Without loss of generality, we use the Bayesian Personalized Ranking (BPR) [23] loss, a commonly used ranking function, to analyze the impact of noise samples on recommendation performance. Specifically, DRO can be viewed as"}, {"title": "3.2 Sinkhorn DRO", "content": "To address the challenge of limited OOD performance in KL diver- gence based DRO methods, this paper introduces Sinkhorn Distribu- tionally Robust Optimization (i.e., Sinkhorn DRO). Sinkhorn DRO combines distributionally robust optimization with the Sinkhorn"}, {"title": "3.3 Model Instantiations", "content": "In this section, we detail how our proposed DRGO method leverages diffusion models and DRO to mitigate the limited model general- ization caused by noisy samples in training data."}, {"title": "3.3.1 Denoising Diffusion Module", "content": "We are motivated by the effectiveness of diffusion models in producing clean data across diverse areas, including images [49] and text [19]. Our proposed DRGO method incorporates diffusion models to generate denoised user-item embeddings. Considering the discrete nature of user-item interaction graphs, they are unsuitable for direct input into diffusion models. Therefore, we design a method that integrates Variational Graph AutoEncoders (VGAE) [10] with diffusion mod- els to efficiently denoise graph-structure data. In detail, consider a user-item interaction graph $G_0 = \\{U,V,E,X\\}$, and X denotes the features of the nodes, such as a user's gender and age or an item's category. Existing work [15] suggests that leveraging stable features related to the target distribution can effectively improve a model's generalization performance on OOD data. We use $G_0$ as the input to the VGAE model, mapping it to a low-dimensional latent vector $E_0 \\sim N(\\mu_0, \\sigma_0)$ to facilitate both forward and reverse diffusion processes in the latent space. The encoding process is given by:\n$q_\\varphi(E_0|A, X) = N(E_0|\\mu_0, \\sigma_0)$,\nwhere A represents the adjacency matrix of $G_0$, $\\mu_0 = GCN_\\mu(A,X)$ is the matrix of mean vectors, and $\\sigma_0 = GCN_\\sigma(A, X)$ denotes the matrix of standard deviations. Here, GCN(\u00b7) refers to the graph convolutional network in the graph variational autoencoder. Using the reparameterization trick, $E_0$ is calculated as:\n$E_0 = \\mu_0 + \\sigma_0 \\epsilon$,\nwhere $\\epsilon \\sim N(0, I)$ and denotes element-wise multiplication. $E_0$ will be used as the input to the diffusion model for denoising, and"}, {"title": "3.3.2 Nominal Distribution", "content": "Typically, when using DRO to op- timize on OOD data, the nominal distribution $\\mathbb{P}_{train}$ should ideally cover the testing distribution within a radius $\\rho$. However, in prac- tical recommendation scenarios, due to the unpredictability and randomness of user behavior, the distribution of the test set is often unknown, posing challenges for constructing the nominal distribu- tion. In reality, popular items or users in recommendation scenarios often influence the future behavior of other users. Considering the connectivity of graph-structured data, this study leverages be- tweenness centrality to construct the nominal distribution. The basic assumption is that groups with high centrality during training strongly influence unseen distribution groups [4, 20]. Betweenness centrality measures the frequency at which an entity appears on the shortest paths between other entities in a topology. Entities with higher betweenness centrality have greater control over the topology. Its mathematical definition is as follows:\n$c_{data} = \\sum_{s,t\\in E_{train}} \\frac{\\sigma(s, t|v)}{\\sigma(s, t)}$,\nwhere $\\sigma(s, t)$ is the number of shortest paths between groups s and t in the graph (i.e., (s, t)-paths), and $\\sigma(s, t | v)$ is the number of (s, t)-paths that pass through node v in graph $G_0$. After obtaining the betweenness centrality values for each node, we sort them in descending order and use the embeddings of the top-n% nodes to construct our nominal distribution. In the hyperparameter analysis experiments, we will discuss in detail the impact of the value of n on model performance."}, {"title": "3.3.3 Uncertainty Set", "content": "When using DRO-based methods, it is necessary to assign weights to different groups to optimize the worst-case scenario. However, an excessive number of groups can make DRO optimization challenging. Drawing on previous work [47], we can directly cluster the denoised user embeddings $\\hat{E}_u$, thereby reducing the number of samples. Additionally, clustering algorithms can more accurately group users with similar behaviors"}, {"title": "3.3.4 Joint Optimization", "content": "We propose the DRGO method, which uses LightGCN as the backbone and employs Bayesian Personalized Ranking as the optimization objective for the recommendation task:\n$L_{rec} = \\sum_{(u,i^+,i^-)} - \\log \\sigma (f_{u,i^+} \u2013 f_{u,i^-})$,\nwhere $(u, i^+, i^-)$ is a triplet sample for pairwise recommendation training. $i^+$ represents positive samples from which the user has interacted, and $i^-$ are the negative samples randomly drawn from the items with which the user has not interacted, respectively. $\\hat{u,i^+}$ represents the positive prediction score and $f_{u,i^-}$ is the negative prediction score. Therefore, the overall optimization objective of our DRGO is as follows:\n$\\min_ {\\theta} R(\\theta, w_{q_i}) := \\sup_{Q:W_{c, \\alpha}(\\mathbb{P}_{train}, Q) \\le \\rho}\\sum_{i=1}^{k} w_{q_i} L_{rec} (f(x), y)$\n$\\min_{\\theta} R(\\theta, w_{q_i}) : = \\sup_{Q:W_{c, \\alpha}(\\mathbb{P}_{train}, Q) \\le \\rho}\\sum_{i=1}^{k} w_{q_i} L_{rec} (f(x), y)$\n\u2212 $\\beta \\sum_{i=1}^{k} w_{q_i} \\log w_{q_i} + L_{denoising}(G_0)$,\nwhere $w_{q_i}$ represents the weights of different groups $q_i$, which need to be dynamically adjusted during training. The parameter $\\beta$ serves as the penalty factor coefficient. The term $\\sum_{i=1}^{k} w_{q_i} \\log w_{q_i}$ represents an entropy regularization component that encourages the distribution q to approach uniformity and k is the number of groups (i.e, the number of clusters k). This promotes balanced weighting of all samples during optimization and helps prevent the model from disproportionately focusing on outliers, such as noisy samples. The term $L_{denoising}$ represents the loss function of the denoising module, primarily comprising the loss from the VGAE, as defined in Eq. (8), and the diffusion model, as defined in Eq. (57), which is displayed as:\n$L_{denoising} = L_{VGAE} + L_{sample}$"}, {"title": "3.4 Theoretical Analysis", "content": "In this subsection, we primarily provide two theoretical analyses: (1) the generalization bound of DRGO on OOD data and (2) how DRGO mitigates the impact of random noise.\nTHEOREM 3.1. Assume the loss function $R(\\theta, W_{q_i})$ is bounded by a constant B. For $\u03b4 > 0$, with probability at least 1 \u2013 8, the following inequality holds for all f \u2208 F:\n$\\hat{R}(\\theta, w_{q_i}) \\le R(\\theta, w_{q_i}) + 2\\hat{R}_n(F) + BW(\\mathbb{P}_{train}: Q) + B \\frac{ln(1/\\delta)}{2n}$\nThe upper bound of the generalization risk on Q is primarily influenced by its distance to $\\mathbb{P}_{train}$, denoted as $W(\\mathbb{P}_{train}, Q)$. By incorporating the topological prior, the risk on Q can be tightly con- strained by minimizing $W (\\mathbb{P}_{train}, Q)$, provided that Q lies within"}, {"title": "4 EXPERIMENTS", "content": "We carry out numerous experiments to evaluate the performance of DRGO, aiming to solve the following critical research questions:\n\\u2022 RQ1: How does the performance of DRGO compare to state-of- the-art methods in OOD recommendation?\n\\u2022 RQ2: How does DRGO mitigate the effects of random noise?\n\\u2022 RQ3: How do the components proposed in DRGO contribute to improving the model's efficiency in OOD generalization?\n\\u2022 RQ4: How do different hyperparameter settings affect the model's performance?\nDatasets. We directly follow previous work [25] and conduct ex- periments under three common distribution shift scenarios (i.e., popularity shift, temporal shift, exposure shift.) to validate the performance of DRGO. The experiments are conducted on four"}, {"title": "4.1 Overall Performance (R1)", "content": "In this section, we evaluate the effectiveness of our method through comparative experiments under three scenarios: distribution shifts caused by different factors and comparisons under IID (Independent and Identically Distributed) conditions. Best results are displayed in bold, while second-best results are underlined."}, {"title": "4.2 Robustness Analysis (R2)", "content": "We investigated the robustness of DRGO and several baseline mod- els against noisy data in recommendation systems. To assess the impact of noise on model performance, we randomly replaced dif- ferent proportions of real edges with fake edges and retrained the models using the corrupted graphs as input. Specifically, we re- placed 5%, 10%, 15%, and 25% of the edges in the original graph with fake edges. The results are shown in Figure 3. DRGO experiences less performance degradation than the baseline models, even when the noise ratio reaches 25%, with DRGO still maintaining a signifi- cant performance advantage. We attribute this result to two main factors: DRGO utilizes a diffusion model to denoise the user-item interaction graph, producing denoised embeddings that effectively reduce the proportion of noise concentrated in the uncertainty set. Second, we introduced a regularization term in the objective func- tion to constrain outliers, thereby reducing the model's attention to these anomalous points. In the ablation study, we will analyze in detail the contribution of these two components to the performance of GRGO. Additionally, we found that DR-GNN experienced a more significant performance drop compared to the other two baselines. This is mainly due to the inherent sparsity of these datasets. DR- GNN, while using DRO to improve OOD generalization, did not consider the impact of noise, making the noisy data have a more significant effect on the model's performance. Overall, the experi- mental results demonstrate that DRGO enhances the generalization performance in OOD recommendations and maintains robustness and effectiveness in noisy data."}, {"title": "4.3 Ablation Studies (R3)", "content": "We conduct experiments by individually removing three applied techniques and methods from DRGO: the diffusion denoising mod- ule (DRGO w/o Diff.), the regularization term for outlier constraints (DRGO w/o Reg.), and the primary user/item features (DRGO w/o Feat.) to validate the effectiveness of the proposed method. Mean- while, we implement the DRGO method with LightGCL and SimGCL as backbones to verify the generality and portability of the pro- posed approach. These variants are retrained and tested on two datasets, and the results are shown in Table 5. From this, we draw the following significant conclusions: (1) After removing the diffu- sion module and the regularization term, the model's performance drops significantly, highlighting the importance of constraining noisy data and outlier values when using DRO to improve OOD generalization. Our proposed DRGO can prevent DRO from over- focusing on noisy data and outlier values during worst-case pa- rameter learning, further enhancing recommendation performance on OOD data. Additionally, although the performance of DRGO w/o Feat. also decreases, the drop is more minor than removing the other two modules, indicating that while user-item features contribute to performance improvement, they are not the primary factor driving the performance boost. (2) We implement DRGO with LightGCL and SimGCL as backbones, showing performance improvements. SimGCL w/ DRGO outperforms DRGO with Light- GCN as the backbone across all four metrics. We attribute this to SimGCL's unique method of enhancing embeddings, especially its approach of applying enhancement after denoising, which further boosts its performance. In conclusion, the ablation study highlights that each module in DR-GNN enhances the model's learning ability and validates the effectiveness and portability of DRGO."}, {"title": "4.4 Hyperparameter Analysis (R4)", "content": "Impact of the number of clusters K. We examine how varying the number of clusters, K, affects model performance in the context of constructing uncertainty sets. Results are presented in Figure 4 (a) and (b). On both datasets, model performance fluctuates as K changes. Initially, as K increases from 1 to 5, DRGO's performance improves, reaching an optimal level. However, further increases in K lead to performance degradation. This may be because a smaller K results in suboptimal worst-case selections, hindering general- ization, while a larger K introduces redundancy and overfitting.\nImpact of the robust radius $\\rho$. We explore how the robust radius $\\rho$ influences model performance. Figures 4(c) and (d) depict the effects on the Food and Yelp2018 datasets as $\\rho$ varies. It is evident that selecting an appropriate $\\rho$ value is crucial for optimal performance, with the best results achieved at $\\rho$ = 0.05 for both datasets. Furthermore, DRGO shows greater sensitivity to $\\rho$ on Yelp2018, likely due to more pronounced popularity shifts that complicate generalization.\nImpact of the nominal distribution top-n%. We calculate the betweenness centrality for each node and select the Top-n% of nodes to form the nominal distribution, studying its impact on DRGO's performance. Figures 4 (e) and (f) show that increasing the selection proportion enhances DRGO's performance, peaking at the top 10% of nodes. Beyond this, performance stabilizes. A higher proportion can lead to longer computation times and potential"}, {"title": "5 RELATED WORK", "content": "5.1 Graph-based Recommender Systems\nGraph Neural Networks (GNNs) play a vital role in recommenda- tion systems by effectively modeling high-order interaction sig- nals between users and items using graph-based domain infor- mation [2, 3, 5, 11]. NGCF [30] uses Graph Convolutional Net- works (GCNs) to learn high-order embeddings on bipartite graphs, while LightGCN [6] improves upon this by omitting feature trans- formations and non-linear activations, enhancing efficiency and recommendation performance. Approaches like KGAT [29] and CGAT [17] advance GNN-based models by incorporating knowl- edge graphs and attention mechanisms to better capture user prefer- ences. Contrastive learning and data augmentation techniques have also gained traction, as seen in SGL [33], which employs three data augmentation strategies on interaction graphs to bolster recommen- dations through contrastive learning. SimGCL [39], on the other hand, injects noise into embeddings to create positive and negative samples, improving accuracy without direct graph augmentation. Despite these successes, methods such as NGCF [30], LightGCN [6], and KGAT [29] often assume an IID (Independent and Identically Distributed) scenario for training and testing data, which limits their ability to generalize in OOD (Out-of-Distribution) contexts. Other strategies, like those employed in SGL [33] and SimGCL [39], target specific data shift types, which restricts their adaptability to more complex, real-world distributional challenges."}, {"title": "5.2 Diffusion for Recommendation", "content": "Recent advancements in diffusion methods have significantly broad- ened their application in recommendation systems, particularly in sample generation and representation learning. Notable works such as DiffRec [28] and Diff-POI [21] leverage diffusion for general and spatial recommendation tasks, respectively. The integration of dif- fusion models with graph neural networks (GNN) is explored in DiffKG [9] and DiffGT [38], which combine diffusion with data aug- mentation and transformer models to enhance knowledge graph learning and top-k recommendations. RecDiff [12] and DiffNet++ [34] utilize diffusion to refine user-user graphs, improving social recommendation accuracy, while MCDRec [18] optimizes multi- modal data processing. DiFashion [35] demonstrates diffusion's versatility by generating personalized user outfits. Despite these successes, diffusion-based approaches in recommendation systems still face challenges related to OOD data, which can limit their generalizability."}, {"title": "5.3 DRO based Recommendation", "content": "The application of Distributionally Robust Optimization (DRO) in recommendation systems has gained significant traction among researchers as they seek to address challenges of distribution shifts [13, 24, 25, 37, 45, 47]. The essence of DRO is to enhance model robustness by optimizing performance under the worst-case data distribution. For instance, PDRO [45] addresses popularity shifts, while DROS [37], RSR [47], and DRO [36] focus on improving the generalization of sequential recommendation models on OOD"}, {"title": "6 CONCLUSIONS", "content": "This paper employs theoretical analysis and experimentation to reveal the vulnerability of existing DRO-based recommendation methods to noisy data. Consequently, it proposes an innovative graph recommendation approach called DRGO, which incorporates a denoising diffusion process and an entropy regularization term to mitigate the impact of noisy data. Comparative experiments conducted across multiple datasets and settings demonstrate the model's effectiveness in addressing distribution shift issues and its robustness against noisy data."}, {"title": "A.1 The proof of KL divergence", "content": "PROOF. Given the mathematical definition of KL divergence:\n$D_{KL}(P||Q) = \\sum P(x)log(\\frac{P(x)}{Q(x)})$,\nwhere P and Q denote the different distributions, respectively. The training data distribution $\\mathbb{P}_{train}$ and the testing data distribution $\\mathbb{P}_{ts}$ do not overlap. For any test data point $X_{test} \\in \\mathbb{P}_{test}$, since $\\mathbb{P}_{train}(X_{test}) = 0$, we have:\n$\\lim_{x\\to0} log(\\frac{\\mathbb{P}_{ts}(x)}{\\mathbb{P}_{train}(x)}) \\to \\infty$,\nwe further analyze the following:\nInvisibility of the Test Distribution: During training, the model has no access to data points that resemble the distribution of the test set. Consequently, the optimized model cannot generalize to these unseen test data points.\nInability to Handle OOD Data: Since the training set lacks data points that match the distribution of the test data, the optimization process cannot leverage any information from these OOD data points, leading to severe degradation in the model's performance on the test data.\nTherefore, KL divergence will make it difficult for the optimiza- tion objective to converge effectively."}, {"title": "A.2 Example", "content": "Example. Assume the training dataset consists of clean samples and noisy samples, where the clean sample set is $\\{(u_i, i^+,i^-)\\}_{i\\in[c]}$ and the noisy sample set is $\\{(u_j, j^+, j^-)\\} _{j\\in [N_O]}$. Here, u represents the user, $i^+$ denotes a positive sample (an item liked by the user), $i^-$ denotes a negative sample (an item disliked by the user), and $N_C$ and $N_O$ are the numbers of clean samples and noisy samples, respec- tively. We assume that the labels for the noisy samples are more chaotic and may include incorrect positive and negative sample pairs. Given the standard BPR loss function as follows:\n$L_{BPR} = - \\sum_{u,i^+,i^-} \\ln(\\sigma(f_{u,i^+} \u2013 f_{u,i^-}))$,\nNow, introduce sample weights, where the weight of clean samples is defined as $w_c (i)$, and the weight of noisy samples is defined as $w_o (j)$, satisfying:\n$\\sum_{i=1}^{N_C}w_c(i) + \\sum_{j=1}^{N_O} W_O (j) = 1$"}, {"title": "A.3 The proof of Theorem 3.1", "content": "PROOF. Before formally beginning the proof, we introduce the following definitions :\nDefinition 1. (Lipschitz Continuity) A function $f : X \\to \\mathbb{R}^m$ is said to be G-Lipschitz continuous if for all $x, y \\in X$, it holds that $|f(x)f(y) | \\le G|x - y||$.\nDefinition 2. (Smoothness) A function $f: X \\to \\mathbb{R}$ is called L-smooth if it is differentiable on X and its gradient $\\nabla f$ is L-Lipschitz continuous, meaning $| \\nabla f(x) \u2013 \\nabla f(y) || \\le L||x \u2212 y|| for all $x, y \u2208 X$.\nNext, we provide the proof that the BPR loss function $L_{rec}$ in DRGO is G-Lipschitz continuous and L-smooth with respect to x. To facilitate the proof, we rewrite the BPR loss function. Assuming there is a user u and items i and j (where i is the positive sample and j is the negative sample), the BPR loss function is typically defined as:\n$L(f(u, i, j)) = \u2212 \\log (\u03c3(f (u, i) \u2013 f (u, j)))$,\nwhere f(u, i) represents the predicted rating of user u for item i, and generally f(.) is a dot product. \u03c3(x) is the sigmoid function.\nLipschitz Continuity. To prove that the BPR loss function is G- Lipschitz continuous, we need to show that there exists a constant"}, {"title": "Algorithm 1 Training Procedure of DRGO", "content": "1: Input: The user-item interaction graph $G(V, 8)$ and node feature matrix X; The number of cluster K, the number of layers L, and the learning rate $\\eta$.\n2: while not converged do\n3: for all $k \\in \\{1, 2, ..., K\\}$ do\n4: Get the denoising embeddings by Eq. (6) and Eq. (4);\n5: Calculate the nominal distribution Q by Eq. (9) and the uncertainty sets $\\mathbb{P}_{train}$ is calculated by Eq. (10)\n6: // Forward process\n7: Calculate the weights of different groups $w_{q_i}$ in Eq. (12)\n8: // Reverse process\n9: Calculate the gradients w.r.t. the loss in Eq. (12);\n10: end for\n11: Average the gradients over |U| users and K environments;\n12: Update the model \u03b8 via AdamW optimizer;\n13: end while\n14: Output:: Trained model parameter \u03b8*."}, {"title": "E INTRODUCTION TO DIFFUSION MODELS", "content": "Diffusion models [8], due to their high-quality generation, training stability, and solid theoretical foundation, have achieved notable advancements in computer vision. These models are a type of deep generative model that operates through two distinct phases: the forward process and the reverse process.\nForward process. Given a real data distribution p(x0), the goal of the forward phase is to progressively add Gaussian noise of varying scales to the data xo, ultimately obtaining a data point xt after T steps of noise addition. In detail, adding noise from xt-1 to xt is shown as:\nq(xt/xt-1) = N (xt; \u221a1 \u2013 \u03b2txt-1, \u03b2tI),\nwhere $\u03b2_t \u2208 (0, 1)$ controls the level of the added noise at step t. I denotes the identity matrix, and N represents the is the Gaussian distribution which means xt is sampled from this distribution. By applying the reparameterization trick, xt can be directly derived from xo, as demonstrated below:\nq(xt|xo) = N (xt; \u221a\u0101xo, (1 \u2013 \u0101)I)\nwhere \u0101t = \u220fi=1 tai, ai = 1 \u2212 \u1e9ei.\nReverse Process. It aims to reconstruct the original data by training a model pe to approximate the reverse diffusion from"}]}