{"title": "Enhancing Worldwide Image Geolocation by Ensembling Satellite-Based Ground-Level Attribute Predictors", "authors": ["Michael J. Bianco", "David Eigen", "Michael Gormish"], "abstract": "Geolocating an image of a ground-level scene entails estimating the location on Earth where the picture was taken, in absence of GPS or other location metadata. Typically, methods are evaluated by measuring the Great Circle Distance (GCD) between a predicted location and the ground truth. However, this measurement is limited because it only evaluates a single point, not estimates of regions or score heatmaps. This is especially important in applications to rural, wilderness and under-sampled areas, where finding the exact location may not be possible, and when used in aggregate systems that progressively narrow down locations.\n\nIn this paper, we introduce a novel metric, Recall vs Area (RvA), which measures the accuracy of estimated distributions of locations. RvA treats image geolocation results similarly to document retrieval, measuring recall as a function of area: For a ranked list of (possibly non-contiguous) predicted regions, we measure the accumulated area required for the region to contain the ground truth coordinate. This produces a curve similar to a precision-recall curve, where \u201cprecision\u201d is replaced by square kilometers area, allowing evaluation of performance for different downstream search area budgets.\n\nFollowing directly from this view of the problem, we then examine a simple ensembling approach to global-scale image geolocation, which incorporates information from multiple sources to help address domain shift, and can readily incorporate multiple models, attribute predictors, and data sources. We study its effectiveness by combining the geolocation models GeoEstimation [12] and the current SOTA GeoCLIP [2], with attribute predictors based on LandScan [17] and ESA-CCI Land Cover [1]. We find significant improvements in image geolocation for areas that are under-represented in the training set, particularly non-urban areas, on both Im2GPS3k and Street View images.", "sections": [{"title": "1. Introduction", "content": "Accurate localization of ground-level imagery is of great significance to a variety of tasks, including navigation, tourism, and security, and the subject of recent research activity [2,4,6,12,21]. However, even large publicly available geotagged image datasets, such as MP-16 [9] and Street View [11], sample only a small fraction of the Earth's surface and mostly concentrate on cities and other population centers. Moreover, much imagery that is available with labeled geographic coordinates is clustered around highly trafficked areas, such as famous landmarks, parks, restaurants and other sites of interest. These include most common benchmark datasets, e.g. Im2GPS3k [19] and YFCC26k [12,18]. Thus domain shift is a major problem as the imagery in many deployment applications do not reflect the training distribution, particularly when applied to rural areas or wilderness, or areas that are under-represented by the datasets' collection methods.\n\nWe introduce an novel image geolocation metric, Recall vs Area (RvA). This metric helps account for ground-level image similarity from different geographic regions, and naturally characterizes model performance when predicted regions are discontiguous. It is particularly apt for measuring systems that suggest areas for downstream tasks, for example, to be further refined using landmark-matching or other more expensive methods, or to flag images that may have come from certain regions of the globe for further study by human analysts. Further, the metric naturally enables ensembling geolocation models with additonal ground-level attribute models.\n\nTo help address the challenge of generalization to under-sampled areas, we propose a general ensembling approach to global-scale image geolocation, which incorporates ground-level attribute predictors based on satellite data products. While ground level training data are generally limited, satellite datasets have global coverage. These predictors bring additional information to bear on the geolocation problem, e.g. relating global land cover types to available ground-level imagery. The attributes are assumed"}, {"title": "1.1. Contributions", "content": "\u2022 We develop a novel metric, Recall vs Area, for evaluating geolocation systems, which can account for visual similarity of ground-level imagery across the Earth.\n\nWe use this method to assess image geolocation approaches.\n\n\u2022 We show that, in isolation, geolocation methods trained only on geotagged imagery can be vulnerable to image domain shift with respect to training data.\n\n\u2022 We develop an approach to combine ground-level attribute predictors, based on satellite data products, with geolocation models. The incorporation of ground-level information related to satellite data promises to improve generalization to areas of the Earth for which there are few ground-level picture samples.\n\n\u2022 We show ensembling ground-level attribute predictors improves image geolocation performance on both in- and out-of-domain datasets on SOTA image geolocation methods."}, {"title": "2. Related Work", "content": "M\u00fcller-Budack et al. [12] develop a hierarchical pixel-based approach to geolocation. They fine-tune their model on the large MP-16 dataset, and quantize the Earth using S2 cells (using the Google S2 geometry Library\u00b9), with 3 resolutions {'coarse', 'medium','fine'} depending on data density. The output of the model is image geolocations for each level. Subsequent papers have built on this work, proposing various ground-level gridding strategies, including CPlaNet [16] and Translocator [13].\n\nOther recent works have brought additional information to the geolocation problem, including relationships between scene and geographic scales and variations in environment [4] and segmentation models [13]. In Luo et"}, {"title": "3. Approach", "content": "3.1. Recall vs Area Metric\n\nThe most common metric currently used to measure geolocation performance calculates the distance between a single predicted location and the ground truth coordinates. Localization accuracy is calculated for different distance radius buckets, measured using great circle distance (GCD). For example [12] used GCD thresholds of [1, 25, 200, 750, 2500] km to evaluate model performance, even giving these distances names to represent how close the solution was, namely street, city, region, country, continent.\n\nWhile this measure works well to characterize performance of a single predicted location, it does not extend to measuring performance of a larger (possibly discontiguous) predicted area. This is important for many practical applications, where the image geolocation algorithm is used to propose a set of possible locations that are used in downstream tasks. Thus localization performance is measured in terms of an area budget.\n\nIn addition, many distant regions on Earth look similar from ground-level, as illustrated by the often scattered"}, {"title": "3.2. Algorithm", "content": "Given an image x, with corresponding geotag coordinates y, we ensemble geolocation and ground-level attribute predictors to find the a set of areas on Earth most likely to contain the image.\n\nBecause we combine the geolocation area predictions of multiple models, we map each of their outputs to a common image over the surface of the Earth, with \"pixel\" coordinates given by latitude and longitude (WGS-84 projection). Note that we index by (lat, lon), so each \"pixel\" has a different area on the Earth depending on its latitude coordinate. To account for this, we also create an array Apix that"}, {"title": "4. Datasets", "content": "4.1. Ground-level attribute datasets and processing\n\nHere, we describe the satellite data products used to develop our Earth surface attribute models, and the image datasets we used to train and evaluate our ensembling approach and related methods.\n\nIn our processing, we consider two satellite data products: LandScan Global [17] from Oak Ridge National Laboratory (ORNL) and Land Cover [1], from the European Space Agency (ESA) Climate Change Initiative (CCI). Each data product provides high resolution estimates of surface attributes: LandScan Global predicts 24-hour average population density and ESA-CCI Land Cover predicts 38 natural and anthropogenic land cover classes.\n\nWe used three image datasets. MP-16 [18] and Im2GPS3k [19] are common training evaluation benchmarks in image geolocation literature. MP-16 was used to train our attribute classifiers, and Im2GPS3k was used for testing. Additionally, we collected a set of images from Google Street View, using training-set panorama IDs from [11] to evaluate the generalization of the models to image location distributions and image capture pipelines that do not match those of MP-16 and Im2GPS3k."}, {"title": "4.1.1 LandScan Global", "content": "The ORNL LandScan Global dataset is a global map of population density at ~ 1 km\u00b2 resolution [17], see Fig. 1. The data is a large TIFF image, 21600 \u00d7 43200 pixels (lat x lon), with 24-hour average population densities.\n\nEach pixel indicates whether the corresponding region is land and if so, the population density. The coordinate system of the image is WGS-84, which is a standard lat-long. representation. The resolution is ~ 1km\u00b2."}, {"title": "4.1.2 ESA Landcover", "content": "ESA-CCI Land Cover is a global land cover and land use data product [1], see Fig. 1. It is generated using deep learning classifiers on Sentinel-2 satellite images. The product is a 64800 \u00d7 129600 pixel (lat x lon, WGS-84) GeoTIFF with 300 m resolution. Each pixel is labeled as the most likely land cover from 38 classes (22 super-classes), see Fig. 1. The classes include cropland, grassland, tree cover, and developed cover/use categories. Maps are available for the years 1992-2020. We used the ESA-CCA Land Cover 2015 dataset for development of region reduction classifiers."}, {"title": "4.2. Image datasets", "content": "Currently, the most comprehensive geotagged ground-level image dataset is MP-16 [9]. This dataset is a subset of the Yahoo Flickr Creative Commons 100 Million datasets (YFCC100M) [18], which have geotags. This dataset was used to train ground-level attribute predictors.\n\nThe size of the dataset is 4.7M images. We were able to obtain ~4.2 M of the total, as approximately 500 k were no longer available at the URLs provided by [12]. The MP-"}, {"title": "5. Experiments", "content": "5.1. Ground-level attribute predictors\n\nWe trained two ground-level attribute predictors, one for each satellite data product (LandScan and Land Cover), using MP-16 imagery relabeled with attributes from each source. In our experiments, we use the acronyms LS for LandScan and LC for Land Cover. For each image, the ground-level attribute labels were obtained by indexing the nearest pixel value in the attribute maps at the native TIFF resolution. As described in Section 3.2 the outputs of these models are projected on global masks and combined to find a global distribution of probable locations.\n\nSince the LS population densities are continuous, we mapped these to four density buckets for use in a softmax classifier, according to log10 population density using equal bin width over the range of population densities in LS. In Fig. 6 we show the LS population density range as sampled by MP-16 and the locations of the buckets. This results in four buckets of ['lowest', \u2018low', \u2018medium', 'high'] density, with corresponding percentage of land area being [93.9, 4.93, 1.10, 0.029]%, respectively. Thus the LS classifier predicts these 4 classes. In Fig. 3 the medium population density bucket is overlain with the S2 cells (fine) used for base(M, f*). The population density mask is more restrictive than the S2 cells alone.\n\nFor LC, we use the top 22 top-level land cover classes to relabel the MP-16 images. We then merge these into 7"}, {"title": "5.2. Ensembling", "content": "In our experiments, the common image size was H = 5400 (latitude) by W = 10800 (longitude). This size was chosen as the dimensions are common factors to the the LS and LC TIFF image sizes, and was small enough to yield reasonable time complexity and geolocalization performance. Thus average resolution of the common image is ~ 4 km, which corresponds to zero recall at ~ 16 km\u00b2 in Figs. 4 and 5, and Table 1.\n\nFor GeoEstimation, we used the hierarchical model (\"base(M, f*)\" from [12]). For GeoCLIP, we used the"}, {"title": "5.3. Results", "content": "We evaluate the geolocation methods with Algo. 3 for both Im2GPS3k and the Street View dataset, based on panoids from [11]. Im2GPS3k and Street View both predominantly consist of urban areas with higher population density. To reduce this bias and better measure the effects on the rural and undersampled areas we are interested in, we rebalance the data by randomly sampling equal number of images from each LandScan mask bucket. The results are summarized in terms of Recall vs Area in Figs. 4 and 5 both with and without balancing, and Table 1 gives results for balanced imagery. We present results for baseline rasterized algorithm for GeoEst. or GeoCLIP predictions Algo. 1; ensembling per Algo. 2, with GeoEst. or GeoCLIP and LS"}, {"title": "6. Conclusions and Future Work", "content": "We have introduced a new image geolocation metric, Recall vs Area, and an ensembling approach to global-scale image geolocation, which incorporates ground-level attribute predictors based on satellite data products. Our metric helps account for ground-level image similarity from different geographic regions, able to measure discontiguous predicted areas. Practical image geolocation systems are often concerned with search area, and Recall vs Area accounts for these needs naturally. By ensembling our ground-level attribute predictors, we have improved upon the SOTA method in image geolocation, GeoCLIP [2], in terms of RvA.\n\nOur ensembling approach combines ground-level attribute predictors with geolocation models, to obtain improvements in image geolocation recall as a function of search area. The attribute predictors bring additional information to bear on the solution using satellite-based attribute masks, and improve performance relative to strong baselines, particularly in areas that are under-sampled in the original dataset.\n\nInterestingly, the relative gain from ensembling predicted attribute masks was larger for GeoCLIP than GeoEst, even though it started at a higher performance level. The information in the embeddings could be complementary to our ground-level attributes. We will explore this in future work.\n\nSatellite data has global coverage, and is not as constrained by geotagged information. By associating satellite-recognizable attributes to ground level images, we can extend information about location to areas of the world not included in any geotagged image data, since they are included in the satellite coverage. We validate this approach using population density and land use, but we hope to extend it to more general attributes, including those found implicitly through large datasets of image captions. More generally, automatically associating ground-level image features with mask areas recognizable by satellite promises to extend the geographic reach of these image features to undersampled regions."}], "equations": ["recall(\u03b1) = \\frac{\\sum_{i=1}^{K} \\mathbb{1}[y_i \\in \\{a_{ik}: k=1 \\&  a_{ik'} \\leq \u03b1\\}\\}]}{|X|},\n\n(1)", "P_{ens.} = \\prod_k P_k(x)\n\n(2)"]}