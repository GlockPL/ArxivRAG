{"title": "MEC-IP: EFFICIENT DISCOVERY OF MARKOV EQUIVALENT CLASSES VIA INTEGER PROGRAMMING", "authors": ["Abdelmonem Elrefaey", "Rong Pan"], "abstract": "This paper presents a novel Integer Programming (IP) approach for discovering the Markov Equivalent Class (MEC) of Bayesian Networks (BNs) through observational data. The MEC-IP algorithm utilizes a unique clique-focusing strategy and Extended Maximal Spanning Graphs (EMSG) to streamline the search for MEC, thus overcoming the computational limitations inherent in other existing algorithms. Our numerical results show that not only a remarkable reduction in computational time is achieved by our algorithm but also an improvement in causal discovery accuracy is seen across diverse datasets. These findings underscore this new algorithm's potential as a powerful tool for researchers and practitioners in causal discovery and BNSL, offering a significant leap forward toward the efficient and accurate analysis of complex data structures.", "sections": [{"title": "Introduction", "content": "Most of the current machine learning and artificial intelligence tools are of a black-box nature and they primarily focus on prediction optimization, while falling short of model transparency and interpretability. Such properties, however, are often required by mission-critical applications such as in the areas of healthcare and governmental policy-making. In The Book of Why, the authors [1] repeatedly emphasize the importance of models being able to operate under causal frameworks to offer more than mere predictive insights. They propose a 'ladder of causation' with three tiers\n\u2022 Level 1: Models that can only make predictive associations, such as forecasting symptoms for a specific disease.\n\u2022 Level 2: Models that incorporate some level of causal understanding, allowing them to answer intervention-based questions.\n\u2022 Level 3: Models that provide comprehensive causal insights, even extending to counterfactual reasoning.\nThese levels are also referred to as 'seeing,' 'doing,' and 'imagining.' Bayesian Networks (BN), a concept Judea Pearl introduced decades earlier[2, 3], are equipped to tackle these questions at all levels, provided that they are used within a causal framework, i.e., causal BNs. These networks are probabilistic graphical models ideal for modeling complex, non-deterministic systems, and they have found applications across various fields from biology and healthcare to engineering and environmental science. A parametric BN is a graph that depicts direct (causal) dependencies between variables, where parameters in the BN define the form and strength of these relationships. It is known that specifying these parameters is generally simpler than accurately recovering the underlying graph, while learning the BN structure, also called 'causal discovery', often requires both an in-depth knowledge of the system under study and a tremendous amount of observations [4]. The problem of BN structure learning (BNSL) is considered the most challenging problem in parametric BN methods. This is because searching for the true graph is indeed an NP-Hard problem where some instances are much harder than others [5].\nThere exists a plethora of BN strucutre learning algorithms. These algorithms range from early yet still effective methods to the latest breakthroughs, and they typically operate by searching over a set of possible graphs in some manner. Classical BNSL algorithms can be generally categorized into two classes. Firstly, the score-based methods represent a traditional machine learning approach where graphs are explored and scored in terms of how well the fitting distributions agree with the empirical distributions. The graph that maximizes the scoring function is returned as the preferred graph [4]. On the other hand, the constraint-based learning approach is built upon a series of conditional independence tests that determine the addition, removal, or orientation of BN edges [6]. Additionally, there are hybrid algorithms being developed that adopt features from both score-based and constraint-based learning [4]. Automating the construction of causal structures possesses a huge benefit to every research field that is concerned with causal inference and causal intervention [7]. However, the automated causal discovery is hindered by many difficulties that go beyond the problem of NP-hardness which can be generally addressed by pruning the search space of possible graphs and effectively minimizing the loss in accuracy and maximizing the gain in speed.\nLearning the Directed Acyclic Graph (DAG) of a BN from data is only possible under certain assumptions [8]. The first assumption is the Faithfulness Assumption. This assumption states that all and only the conditional independencies that are present in data are implied by the true causal structure. In other words, if the data indicates that two variables are independent given a set of other variables, this independence should correspond to the true non-causal relationship, and vice versa. The second assumption, Causal Sufficiency, is the assumption that is commonly used for facilitating the data-driven learning of BN structure. This assumption holds that all common causes of every variable included in the model are also included in the model. In other words, there are no hidden or unmeasured confounding variables that influence the variables being studied. This assumption is crucial because unmeasured confounders can lead to spurious associations, making it difficult to correctly infer causal relationships. However, in real-world scenarios, especially in social sciences and biology, it is often challenging to ensure causal sufficiency due to the complexity of the systems and practical limitations in data collection [9]."}, {"title": "1.1 The Proposed MEC-IP Algorithm", "content": "From an observational data study, it is often impossible to identify a unique DAG; instead, a class of DAGs can be equally good at fitting the available data. Markov Equivalent Class (MEC) is defined as the causal structure that encodes the same conditional independence relationships among variables, which, as the result of data fitting, is a Completed Partially Directed Acyclic Graph (CPDAG). This concept is vital because, in many cases, the data alone cannot specify a unique DAG unless some other assumptions were made. Therefore, the goal of our algorithm in this paper is to identify the MEC.\nThe exact scoring-based methods for BNSL are often computationally intensive, particularly as the number of variables increases. This is because they examine a large combinatorial space of potential network structures to find the best fit of data. Therefore, this difficulty is conventionally countered by setting a limit on the in-degree of each node in the graph, which results in suboptimal BNs. The MEC-IP algorithm, in contrast, adopts a data-driven targeted-clique-focusing approach. It employs Extended Maximal Spanning Graphs (EMSG) and iteratively refines the network while avoiding the exhaustive search inherent in the exact scoring-based methods. This efficient learning process is especially beneficial for larger datasets where computational resources and time are significant considerations. Moreover, while constraint-based methods, such as the PC algorithm, are known for their relative efficiency, they typically require a large number of samples and a large number of statistical tests to determine the conditional independence between every variable pair. This can be problematic in cases of limited data, as the reliability of these statistical tests diminishes with smaller sample sizes [10]. Moreover, extensive statistical tests can be time-consuming too. The algorithm we proposed, however, strategically selects which statistical tests to perform, focusing primarily on those most likely to yield informative results. By doing that, it not only reduces the computational burden but also mitigates the issue of unreliable results due to limited data. This data-driven approach to testing is particularly advantageous in scenarios where data is scarce or when the dataset is large but has a limited number of observations per variable.\nThe MEC-IP algorithm is a hybrid algorithm, which possesses notable advantages over both exact scoring-based methods, such as GOBNILP, and traditional constraint-based methods, such as the PC algorithm. These advantages are primarily in terms of efficiency and accuracy, especially when dealing with datasets of limited size. In summary, the MEC-IP algorithm offers a balanced approach that enhances both computational efficiency and outcome reliability. This makes it a valuable tool for causal discovery and BNSL."}, {"title": "2 Literature Review", "content": "In the realm of BN structure learning, algorithms can categorized into either the constraint-based approach or the score-based approach, and finally the hybrid approach."}, {"title": "2.1 Constraint-based Approach", "content": "The constraint-based algorithms are the cornerstones of BNSL. They utilize conditional independence tests to discern the graph that underpins causal or associative interactions among variables. Among the seminal works in this area are the SGS (Spirtes-Glymour-Scheines) [11] algorithm and the PC (Peter-Clark) [12] family of algorithms. Each of them contributes unique methodologies, strengths, and limitations to the field. The SGS algorithm is initiated with a completely connected undirected graph, and then it iteratively removes edges that fail conditional independence tests. It has found applications in diverse domains such as bioinformatics, particularly in identifying gene regulatory [6], and in economics for analyzing market dynamics [13]. [14] also presents a conservative version of the SGS algorithm.\nOn the other hand, the PC family of algorithms are built upon the SGS algorithm by incorporating heuristics to decrease computational complexity. Starting much like SGS with a fully connected undirected graph, the PC algorithm employs some more efficient edge-pruning procedures. Various adaptations exist within the PC family, including the Conservative PC (CPC) [15], which adopts a more cautious approach in edge elimination, and the Fast Causal Inference (FCI) algorithm [16], which is equipped to handle latent variables and selection bias. However, despite these advancements, the PC family has its own set of challenges. Mainly, it is susceptible to the issues of false positives and false negatives, often stemming from data limitations or erroneous assumptions concerning conditional independence. There exists other algorithm that belong to the PC family such as PC-stable [17], and PC-MAX [18] that offer improvements related to consistency and accuracy of the results, respectively."}, {"title": "2.2 Score-based Approach", "content": "The score-based algorithms for BNSL offer a different approach from the constraint-based counterparts. Instead of relying on conditional independence tests to prune individual edges, the score-based algorithms evaluate the goodness-of-fit of an entire network to the data using scoring metrics such as the Bayesian Information Criterion (BIC) or the Akaike Information Criterion (AIC). This class of algorithms is often further classified into two major types: approximate methods, including Tabu Search and Hill Climbing (HC), as well as exact methods like Dynamic Programming (DP) [19] and Integer Programming (IP). HC [20] employs a greedy strategy, at each step choosing the neighboring solution that most improves the score, until no further improvement is possible. Tabu Search [21] extends basic local search by maintaining a \"tabu list\" of recently visited solutions to avoid cycling back, thus allowing for a more extensive search of the solution space. Tabu search and HC are often preferred for their computational efficiency, especially in high-dimensional scenarios. These methods, while fast and easy to implement, do not guarantee a global optimal solution and often settle in local optima. Their performance depends significantly on the choice of scoring function and network initiation. In contrast, exact methods like DP and GOBNILP (Globally Optimal Bayesian Network Learning with Integer Programming) aim to find the globally optimal structure. Dynamic programming [22, 23] techniques decompose the problem into overlapping sub-problems and recursively solve them, storing intermediate results for re-use. Although this approach guarantees finding the optimal solution, it is often too computationally expensive to be feasible for large networks. GOBNILP [24, 25, 26] reformulates the BNSL problem to be an Integer Linear Programming (ILP) problem. It uses mathematical optimization techniques to find the globally optimal solution, ensuring the quality of the learned network.\nWhen comparing approximate and exact methods, one notices a trade-off between computational efficiency and solution quality. Approximate methods like HC are quicker but may yield suboptimal solutions, whereas GOBNILP is computationally intensive but guarantee global optimality. Thus, the choice between the two largely depends on the specific requirements of the application at hand."}, {"title": "2.3 Hybrid Methods", "content": "Hybrid algorithms for BNSL present a compelling middle-ground between constraint-based and score-based methodologies, effectively incorporating the strengths of both approaches to overcome individual limitations. Typically, these hybrid algorithms use constraint-based techniques for initial structure learning and then refine the structure using score-based methods. In this literature review, we focus on some well-known hybrid methods such as the Max-Min Hill Climbing (MMHC) algorithm proposed by Tsamardinos et al. [27] and the RSMAX2 algorithm, among others.\nMax-Min Hill Climbing (MMHC) is a seminal hybrid method that first uses a constraint-based phase to learn an initial skeleton of the network. Then, it uses the max-min parents-and-children (MMPC) algorithm to perform skeleton tuning. After skeleton identification, the algorithm switches to a score-based phase, employing HC to optimize the network structure. This phased approach allows MMHC to benefit from the computational efficiency of constraint-based methods while also leveraging the optimization capabilities of score-based techniques. However, MMHC's performance can be affected by the quality of the initial skeleton and the scoring function used in the second phase. It has been widely applied in bioinformatics, particularly in learning gene networks [28]. Another noteworthy hybrid algorithm is RSMAX2, which combines restricted search space-based constraint techniques with Bayesian scoring mechanisms. It applies a score-based algorithm within restricted search spaces identified through constraint-based methods, effectively utilizing the advantages of both approaches. This algorithm often yields results comparable to exact methods while maintaining computational efficiency similar to approximate methods. Nevertheless, the performance of RSMAX2 depends on the accuracy of the restricted search spaces and may vary accordingly. Other emerging hybrid methods focus on the scheme of adaptively switching between constraint-based and score-based phases. These methods aim to dynamically capitalize on the strengths of each approach, although they often require intricate parameter tuning and a deep understanding of the problem domain."}, {"title": "3 The MEC-IP Algorithm", "content": "The MEC-IP algorithm employs a systematic approach to learning the BN through data, ensuring the learned structure accurately represents the underlying causal relationships. Initially, it performs a $\\chi^2$ test for independence on all variable pairs to assess their direct interactions. Based on the test statistics, these pairs are then ranked, leading to the formation of an EMSG by selectively removing weaker edges according to their comparative $\\chi^2$ values with shared neighbors. Subsequently, edges with a p-value above a significance threshold are eliminated, resulting in an Undirected Graph (UG).\nFrom this UG, a CPDAG is formulated through an IP by orienting the edges. This CPDAG is thus representing the initial MEC of DAGs. Our algorithm will then iteratively refine the CPDAG. First, it identifies candidate triangular cliques and tests for conditional independence using $\\chi^2$ tests, thereby determining whether additional connections are necessary to explain the dependency between node pairs. If so, new edges are added. This process is repeated, and the IP is resolved to refine the graph's structure. This iterative process continues until no further improvements can be made, culminating in a final CPDAG that best fits the data, representing the MEC of most suitable DAGs.\nThe MEC-IP algorithm consists of the following main steps:\n1. The $\\chi^2$ test statistic for (unconditional) independence is calculated for every pair of variables (edge).\n2. The edges are ordered in ascending order of the $\\chi^2$ statistic. The EMSG is produced by removing edges between two nodes A and B if and only if A and B share a neighbor C where\n$\\chi^2(A \\leftrightarrow B) < \\chi^2(A \\leftrightarrow C)$\nand\n$\\chi^2(A \\leftrightarrow B) < \\chi^2(B \\leftrightarrow C)$\n3. From the remaining edges, the edges with a p-value less than the required significance threshold are dropped. By now, an Undirected Graph (UG) is formed.\n4. Using the UG as input, the initial MEC of DAGs with the highest BIC score, represented by a CPDAG, is constructed by solving the BNSL IP.\n5. For every candidate triangular clique in the CPDAG, one of the minimum d-separating node sets is identified such that the pair of nodes in the triplet that are not currently joined are d-separated in the CPDAG.\n6. A $\\chi^2$ conditional independence test between the pair given the d-separating node set is performed.\n7. If the test is found to reject the null hypothesis, the current graph is deemed insufficient in explaining the dependence relationships between the pair of nodes, and an undirected edge is added between them. Otherwise, they remain unconnected.\n8. After going through all candidate triplets, the IP is solved again to orient the added edges as a result of the triangulation phase, and a new CPDAG is returned.\n9. Repeat Steps 5-8 until no further improvement can be achieved. The final CPDAG, representing the MEC of the best data-fitting DAGs, is returned as the final output."}, {"title": "3.1 EMSG", "content": "Notice that the initial EMSG is obtained from the unconditional test of independence between the variables. The ESMG generating algorithm is highly motivated by the work in [29, 30] and it is summarized in Algorithm 1. This algorithm returns a UG that will be used in subsequent steps of the MEC-IP algorithm."}, {"title": "3.2 Bayesian Network Structure Learning IP Model", "content": "The IP steps in the MEC-IP algorithm 2 specifically incorporate variables that adhere to the UG formed from the EMSG step. This focus ensures that only significant and relevant relationships between variables, as determined in EMSG, are considered in the BNSL process.\nTo illustrate how this works, consider a simple example of a 4-node network consisting of nodes A, B, C, and D. Assume that the EMSG step has resulted in a UG with the following edges:\n\u2022 A\u2194 B\n\u2022B\u2194 C\n\u2022 C\u2194 D\nIn this scenario, the EMSG has identified that nodes A and B, B and C, and C and D have significant correlations. However, there's no direct significant correlation between A and C, A and D, or B and D. In the IP model, the algorithm will consider parent sets for each node that are consistent with this UG structure. For instance, for node A, its potential parents could be B (since A \u2192 B exists in the UG). For node B, its potential parents could be A or C or both. For node C, its potential parents could be B or D or both. For node D, its potential parents could be C. In addition, each node could also have an empty parent set (i.e. this node is a root node in the graph). This targeted calculation is in contrast with a scenario where one would compute the BIC local scores for every possible variable-parent combination in the network, which, in the case of a 4-node network, would include additional pairs such as A-C, A-D, and B-D. By focusing only on the relationships established by the EMSG, the algorithm reduces the computational burden.\nThe IP model then works to optimize the network structure under these constraints, seeking the configuration that best fits the data while adhering to the relationships already specified by the EMSG. It does so by maximizing the objective function, which is the sum of the BIC scores reflecting how well each parent set explains the data. This approach ensures that the learned BN structure is not only data-driven but also respects the conditional independencies inferred during the EMSG stage. The aim is to select the best parent group for each variable. This selection is done in such a way as to maximize the overall explanatory power of the network, which is quantified by the sum of the scores of the chosen parent groups. Note, unlike other IP algorithms, our algorithm does not limit the number of parent nodes.\nThe detailed IP is as follows:"}, {"title": "3.3 Triangulation", "content": "The triangulation step plays a crucial role in enriching the network's complexity by methodically adding undirected edges. This phase addresses the initial network's potential under-specification problem as a result of employing the EMSG algorithm, ensuring that significant dependencies between nodes are not overlooked. During triangulation, the algorithm identifies potential undirected edges that could complete triangular cliques in the current network. The identification of these edges is based on a thorough examination of the network's existing structure, focusing on how adding an edge might reveal previously unrepresented relationships.\nDuring the triangulation step of the MEC-IP algorithm, the concept of d-separation [32] is essential to determining the conditional independence of nodes. The d-separation in BN refers to the criterion used to assess whether a set of nodes is independent of another set, given a third set (the conditioning set). This assessment will add an undirected edge to the network if two nodes are not d-separated. Specifically, for a potential edge between two nodes (say A and B), the algorithm examines all paths in the network between these nodes. Each path is assessed to see if it is blocked or unblocked based on the principle of d-separation:\n\u2022 A path is considered blocked if it contains a node where the incoming and outgoing arrows meet head-to-tail or tail-to-tail, and this node is included in the conditioning set.\n\u2022 Conversely, a path is also blocked if it contains a node where arrows meet head-to-head, and neither the node nor any of its descendants are in the conditioning set.\nIf the $\\chi^2$ conditional independence test finds that nodes A and B are independent given the d-separating set, it implies that the potential edge between them is unnecessary; otherwise, the edge should be added. After thickening the network with potential edges, the IP model is solved again to determine the optimal directions of these new edges, ensuring that the learned network accurately represents the directional dependencies implied by the data. This iterative process of edge addition followed by IP resolution ensures that the final network structure is both comprehensive and representative of the underlying causal relationships."}, {"title": "4 Numerical Experiments", "content": "We conducted experiments on multiple well-known BNs [33, 34]. The parameters of these BNs can be found in Table 1."}, {"title": "5 Conclusion", "content": "The MEC-IP algorithm is an improved IP approach to BNSL. It can efficiently identify MECs with reduced computation and fewer missing edge or extra edge errors. More importantly, it does not limit the number of parents of each node, thus suitable even for dense networks that have not been handled by previous IP approaches. Our numerical evaluation, comparing MEC-IP against several other established algorithms across multiple datasets, demonstrates its robustness and effectiveness, particularly in complex and large-scale networks.\nFuture work will explore further optimizations and the applications of MEC-IP in real-world scenarios, enhancing its utility for causal inference and decision-making processes in various fields. This research contributes to the ongoing development of more efficient and accurate methods for causal discovery, fostering deeper insights into the underlying mechanisms of complex systems."}]}