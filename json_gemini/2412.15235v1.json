{"title": "OG-RAG: ONTOLOGY-GROUNDED RETRIEVAL-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS", "authors": ["Kartik Sharma", "Peeyush Kumar", "Yunqing Li"], "abstract": "This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented Generation method designed to enhance LLM-generated responses by anchoring retrieval processes in domain-specific ontologies. While LLMs are widely used for tasks like question answering and search, they struggle to adapt to specialized knowledge, such as industrial workflows or knowledge work, without expensive fine-tuning or sub-optimal retrieval methods. Existing retrieval-augmented models, such as RAG, offer improvements but fail to account for structured domain knowledge, leading to suboptimal context generation. Ontologies, which conceptually organize domain knowledge by defining entities and their interrelationships, offer a structured representation to address this gap. OG-RAG constructs a hypergraph representation of domain documents, where each hyperedge encapsulates clusters of factual knowledge grounded using domain-specific ontology. An optimization algorithm then retrieves the minimal set of hyperedges that constructs a precise, conceptually grounded context for the LLM. This method enables efficient retrieval while preserving the complex relationships between entities. OG-RAG applies to domains where fact-based reasoning is essential, particularly in tasks that require workflows or decision-making steps to follow predefined rules and procedures. These include industrial workflows in healthcare, legal, and agricultural sectors, as well as knowledge-driven tasks such as news journalism, investigative research, consulting and more. Our evaluations demonstrate that OG-RAG increases the recall of accurate facts by 55% and improves response correctness by 40% across four different LLMs. Additionally, OG-RAG enables 30% faster attribution of responses to context and boosts fact-based reasoning accuracy by 27% compared to baseline methods.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) have advanced the capabilities of question-answering systems, search engines, and task- oriented chatbots [Perplexity, 2024, ChatGPT, 2024, Achiam et al., 2023]. However, they face significant challenges with fact-based adaptation, particularly in domains that rely on precise, domain-specific data [Cascella et al., 2023, Thirunavukarasu et al., 2023, Singhal et al., 2023, Guha et al., 2024, Wang et al., 2024, Balaguer et al., 2024]. Consider a precision agriculture system where real-time changes in soil moisture and weather data must influence irrigation decisions. A general-purpose LLM might suggest irrigation plans based on broad knowledge but fail to account for specific soil conditions or plant requirements in that region. This lack of adaptability means the LLM's recommendation could be inaccurate, potentially leading to overwatering or under-irrigation, which can harm crops. Such scenarios highlight a core limitation: the inability of LLMs to reliably adapt to domain-specific decision-making, where accuracy and specialized knowledge are paramount [Rudin, 2019, Sharma et al., 2020]. To overcome these limitations, off-the-shelf LLMs can be either fine-tuned for specific domains [Bommasani et al., 2021] or paired with external tools or documents [Lewis et al., 2020, Zhuang et al., 2023, Schick et al., 2024]."}, {"title": "2 Related Work", "content": "Fine-tuning. One approach to overcome the limitations of LLMs is fine-tuning on domain-specific data [Bommasani et al., 2021]. Fine-tuning allows models to adapt to the nuances of a specific domain by retraining the model on specialized datasets. However, this method is computationally expensive, requiring significant resources and extensive data curation, which makes it impractical for many real-world applications [Kumar et al., 2022]. OG-RAG addresses this shortcoming by eliminating the need for costly fine-tuning through retrieval-based solutions. Hallucination mitigation. LLMs are prone to generating hallucinations, i.e., outputs that are factually incorrect or irrelevant to the input [Ji et al., 2023a]. These hallucinations are especially problematic in domains that require precision, such as scientific research or industrial workflows [Thirunavukarasu et al., 2023]. Existing systems have attempted to mitigate hallucinations through post-generation correction methods and factuality checks, but these often require additional layers of computation and are not foolproof [Ji et al., 2023b, Madaan et al., 2024, Welleck et al., 2024]. OG-RAG reduces hallucinations by transforming data-mapped ontologies into hypergraphs and uses optimized retrieval of relevant fact clusters, ensuring LLM responses are grounded in domain-specific facts. Retrieval methods In addition to the traditional retrieval augmented generation (RAG) [Lewis et al., 2020], graph-based approaches have also been proposed. These include GraphRAG [Edge et al., 2024], RAPTOR [Sarthi et al., 2024], and other knowledge graph-based frameworks such as Langchain [lan] and Neo4J [neo]. They have advanced LLM performance by leveraging structured knowledge graphs to organize and retrieve contextually relevant information. GraphRAG excels in semantic clustering by organizing entities and relationships, allowing for more efficient handling of complex queries, while RAPTOR uses a hierarchical structure for multi-level abstraction, improving contextual understanding across large documents. However, these approaches rely on ad-hoc extraction of entities and domain- specific information, often without grounding in domain expertise. This results in overly complex workflows for generating the correct structured representation, while still leaving significant gaps in precision. It also leads to weaker context attribution, making it more difficult to trace conclusions back to relevant facts. Improving on these approaches, OG-RAG's hyperedge construction offers a compact fact representation that enhances transparency through better context attribution, while its hypergraph retrieval mechanism selects optimal fact clusters precisely tailored to the query. Attribution. To enhance the interpretability and reliability of the LLM responses, it is important to attribute their generation to trustworthy sources. One way is to generate text with citations but prior work has shown limitations of existing zero-shot approaches [Gao et al., 2023] and specially-trained models [Khalifa et al., 2024]. Furthermore, other forms of attribution are also explored since citations require users to search over a full page to verify the claims in the generated response, which is undesirable. Thus, locally-attributable methods [Slobodkin et al., 2024] and human-in-the-loop Kamalloo et al. [2023] strategies have also been proposed. While these approaches provide sentence-level attribution, complementary benefits can be achieved through interpretable RAG contexts. OG-RAG provides easy-to-attribute contexts that require only a little effort from the users to trace the generation of the response. Deductive reasoning. Traditional rule-based reasoning systems provide interpretable and easily controllable ways to deduce novel conclusions from a given input [Jackson, 1990, Saparov et al., 2023]. However, they lack the flexibility and generalization capabilities of neural models like LLMs. On the other hand, LLMs are prone to arbitrary hallucinations in deductive reasoning, which can be problematic in structured workflows [Wang et al., 2024, Saparov et al., 2023]. OG-RAG combines the structured precision of fact-based reasoning with neural flexibility by anchoring unstructured text to domain-specific vocabulary, enabling LLMs to more effectively apply domain-specific rules while maintaining scalability across multiple domains."}, {"title": "3 Summary of Key Contributions", "content": "This paper presents several key contributions that address the challenges of fact-based reasoning and hallucination reduction in large language models (LLMs): \u2022 Fact-based Context Retrieval Enabling Domain Adaptation: OG-RAG is a novel framework that integrates domain-specific ontologies into the LLM retrieval process, facilitating precise, fact-based adaptation across domains. OG-RAG achieves this through two core mechanisms: (a) formalization of facts by transforming data-mapped ontologies into a hypergraph, and (b) using an optimization-based hypergraph retrieval to extract compact clusters of facts that precisely align with domain-specific queries, resulting in more contextually accurate responses."}, {"title": "4 OG-RAG", "content": "Ontology Grounded Retrieval Augmented Generation (OG-RAG) is a novel framework which integrates ontolo- gies\u2014formal representations of domain-specific concepts and their relationships\u2014into the retrieval process. Unlike existing retrieval-augmented generation (RAG) systems or other ontology based approaches, which rely on general- purpose embeddings or ad-hoc context generation without grounding in domain expertise, OG-RAG leverages ontology- driven hypergraph retrieval to dynamically adapt LLMs to structured knowledge bases and complex domain-specific queries. Figure 2 shows the high-level pipeline of the proposed method while we describe each component in more detail below."}, {"title": "4.1 Hypergraph Construction", "content": "The first part includes mapping the general domain-specific documents D onto a given ontology O and converting the available information into a usable format for retrieval."}, {"title": "4.1.1 Ontology", "content": "Different domains organize decision-making by following specific rules and procedures tailored to their unique workflows. In agriculture, for instance, factual information is organized differently depending on the task. Crop cultivation relies on facts like soil quality, weather patterns, and pest management strategies, where decisions follow a series of steps based on phenotype and environmental data. On the other hand, agricultural budgeting uses the same foundational facts\u2014such as farm size or crop type\u2014but applies them through financial models and cost projections, which require a different decision-making framework. An ontology is a formal representation of key entities and their relationships within a domain. For example, in the agriculture domain, entities like crops, soil, and weather conditions are defined, along with relationships such as \"crop is grown in a region\" or \"soil has moisture level.\" By defining these entities and relationships, the ontology provides a consistent and clear framework for organizing domain knowledge [Guarino et al., 2009, Jackson, 1990]. It differs from taxonomy or classifications as it allows for richer relationships between entities that need not be hierarchical. More formally,"}, {"title": "Definition 1 (Ontology)", "content": "An ontology O \u2286 S \u00d7 A \u00d7 (S\u222a {$}) consists of a set of triples that relate a set of entities S using a set of attributes A, where (s, a, v) \u2208 O denotes that the subject entity s has an attribute a, and the value v := v(s, a) is either: \u2022 Another entity s' \u2208 S, or \u2022 An unspecified domain value, denoted by $. Here, v := v(s, a) represents the value of the attribute a for entity s, which is either another entity within the ontology or an undefined (unspecified) text or data. For example, consider a subject entity s = \"Crop\", that can have the attribute a1 \"is grown in\", which maps it to another object entity vo(s, a1) = s' = \"Crop Region\". Additionally, the same entity s can have another attribute a2 = \"has name\", which maps it to an arbitrary text, denoted as vo(s, a2) = $, indicating that this value is unspecified and can be any relevant text or name in the domain."}, {"title": "", "content": "Extracting factual information from domain-specific documents D is challenging due to their specialized language and often underspecified structure. Moreover, relevant facts are frequently scattered across various unrelated documents. An ontology O provides a structured way to organize key terms and their relationships within a domain. To address this, we propose leveraging the explicit relationships defined in the ontology to extract factual information from these documents. We claim that since domain-specific facts are often grounded in the underlying ontology, enforcing these relationships can help enrich and disambiguate the information contained in the documents. In particular, we use the documents to find values for attributes by extracting relevant domain-specific text or values from the documents themselves (i.e., when vo(s, a) = $). Since domain-specific documents may contain a variety of facts, this value assignment does not have to be unique across all documents. Instead, different parts of the documents may provide distinct yet valid text/data value related to the same ontology entity. Therefore, we model the extracted information I := D(O) using a set of self-contained factual-blocks F \u2208 D(O), where each factual-block F consists of relationships that map ontology entities to either a unspecfied domain text \u2208 V or another entity within the same factual-block F. More formally,"}, {"title": "Definition 2 (Ontology-mapped data)", "content": "Ontology-mapped data I := D(O) is information derived from the documents D using the ontology O. It consists of a set of factual-blocks, where each factual-block F represents a set of ontology relationships. For any relationship (s, a, v) \u2208 F, the value v is derived as follows: If value vo(s, a) = $ then v \u2208 V is extracted from the document text; otherwise v = v(s, a) is the value provided by the ontology. Thus, ontology-mapped data represents self-contained and ontology-grounded information extracted from domain- specific documents. For example, a factual-block F might represent that: a term s =\"Seed\" is a1 = \"of crop\" v(s, a1) =\"Soybean\" is a2 = \"is grown in\" v(s, a2) = (s' =\u201cCrop Region\", which a3 = \"has a name\" of v(s', a3) = \"Northwest Region\")."}, {"title": "", "content": "We can apply various pattern-matching heuristics, rule-based strategies, or embedding similarity to generate this ontology-mapped data [Otero-Cerdeira et al., 2015, Jackson, 1990]. However, with the powerful capabilities of LLMs, we leverage their natural language understanding capabilities to map these ontology entities to corresponding document text more effectively [Babaei Giglou et al., 2023]. We perform this task by prompting the LLM to generate the mapped information in JSON-LD format. The complete prompt is provided in Appendix B.1. One limitation of this method is that domain-specific ontologies may not always be available or sufficiently comprehen- sive. To address this, we are developing an ontology learning method that can automatically generate a robust baseline ontology. This provides domain experts with a starting point, making it easier for them to edit and refine an existing ontology rather than building one from scratch. Additionally, in many fields, rich pre-existing ontologies are already available due to decades of research in data modeling and ontology development, which can be directly leveraged by this method. The details of this work are beyond the scope of the current paper, so we omit them."}, {"title": "4.1.2 Hypergraph Transformation", "content": "Due to the nested structure of the definitions in the factual-block F \u2208 D(0), directly processing the information in these blocks is challenging. The combinatorial nature of the multi-layered relationships and dependencies make it difficult to efficiently extract or attribute information, which hampers our goal of providing compact and accurate context attribution. To address this, we flatten the structure so that each factual-block F in the ontology-mapped data I is converted into a set of flattened factual-blocks F, making the information easier to handle without significant loss of detail. Algorithm 1 outlines the flattening process, which is also illustrated in Figure 2."}, {"title": "Definition 3 (Hypergraph)", "content": "A hypergraph H := (N,E) consists of hypernodes N and hyperedges E, such that each hyperedge e \u2208 E is a set of nodes with arbitrary length. Defining P(X) as the power set of X and X as the set that is formed by concatenating the strings within each element of the set X, we have the hyperedges E \u2286 P(N) and the hypernodes N \u2286 [\u2295P(S \u00d7 A)] \u00d7 V, where \u00d7 is the cartesian product."}, {"title": "", "content": "Thus, the set of all flattened factual-blocks extracted from the ontology-mapped documents I thus can be seen as a hypergraph. We call this simply H(I). With this definition, a hypernode is essentially a key-value pair and we declare a hyperedge to be a true fact grounded in domain-specific data. Mathematically,"}, {"title": "Definition 4 (Fact)", "content": "A fact is a logical assertion between two entities - subject and object, through a functional attribute, which can be evidentially verified to be either true or false. Formally, it can be expressed as a logical assertion that can be verified to have a value of True or False. For example, consider the assertion: hasCropYield(Farm A) = 500 tons, where hasCropYield is the functional attribute mapping a farm (subject) to a crop yield (value), and which can be evidentially verified to be either True or False."}, {"title": "", "content": "Therefore, in OG-RAG a hyperedge can be viewed as a representation of a complex fact. Without loss of generality, consider two hypernodes, n1(81\u2295 a1, v1) =(Crop has name, Soybean) and n2(p2 \u2208 \u2295P(S \u00d7 A), v2) =(Crop has growing zone CropGrowingZone with name, Northwest) forming an hyperedge e =((Crop has name, Soybean), (Crop has growing zone CropGrowingZone with name, Northwest)) can be represented as a simplified fact: hasGrowingZone(Crop has name Soybean) = Northwest, which can be evidentially verified to be True or False. In this way, the OG-RAG hypergraph construction enables a compact and accurate representation of facts that are adapted to the specific domain. This structure facilitates fact verification by allowing users to inspect the hyperedges, which encapsulate the relationships and dependencies between entities."}, {"title": "4.2 Hypergraph-based retrieval", "content": "With the hypergraph constructed on domain-specific information, i.e., H(I(D, O)), OG-RAG is now ready to retrieve relevant context based on user query Q that can support the LLM in generating accurate, domain-specific responses."}, {"title": "4.2.1 Relevant Nodes", "content": "We first identify the set of hypernodes relevant to a given query. Using Definition 3, a hypernode n \u2208 N can be represented as a key-value pair that comes from the elements in the sets S, A, V. A hypernode can then be considered relevant to a query if: (1) the query pertains to an attribute a of the term s, or (2) the query focuses on an object with specific values v. In other words, a hypernode is relevant if either the similarity between the key (representing concatenated entities and attributes) and the query Q is high, or the similarity between v (the value) and the query Q is high. OG-RAG finds two sets of query-relevant hypernodes: Ns(Q) and Nv(Q) to represent the two sets respectively. In particular, Ns(Q) denotes the top k hypernodes with the highest similarity between their attributed term, 1.e., s \u2295 \u03b1 and the query Q in the vector space Z. Similarly, Nv(Q) represents the top k hypernodes with the highest similarity between their value v and the query Q. Thus, for each query, we extract 2 \u00b7 k relevant hypernodes."}, {"title": "4.2.2 Relevant Hyeredges as Context", "content": "We form the relevant context as the set of hyperedges CH(Q) \u2282 & that minimally cover the relevant hypernodes, N(Q) = Ns(Q) U Nv(Q). This is formulated as an optimization problem and solved in a greedy manner. Since the objective of minimizing the number of hyperedges is linear under a matroid constraint, the solution can be shown to be optimal [Korte et al., 2011]. Specifically, we maintain a dictionary that maps each hypernode n \u2208 N to the set of hyperedges that it is a part of, i.e., E(n), where e\u2208E(n) \u21d2 n \u2208e. In each iteration, we add the hyperedge that covers the largest number of uncovered nodes to the context and remove those nodes from further consideration. This process is repeated until either we have L hyperedges or all the relevant nodes are covered. In this way, the context is constructed as a collection of up to L hyperedges representing facts relevant to the given query. By organizing information into hyperedges, OG-RAG is able to group related facts together, ensuring that the retrieved context is both compact and comprehensive, capturing all necessary facts to support accurate LLM responses, while optimizing for efficiency."}, {"title": "4.2.3 Retrieval-Augmented Generation", "content": "Finally, given a user query Q and the relevant context as found above, we prompt the LLM M to use this context to answer the query as M(P(Q,CH(Q)), where P denotes the corresponding textual prompt:"}, {"title": "4.3 Complexity Analysis", "content": "Algorithm 2 outlines the full procedure of the proposed method which consists of two main components: (1) OG- PREPROCESS, applied to the set of documents once, and (2) OG-RETRIEVE, used to retrieve the relevant context for each query."}, {"title": "4.3.1 Query Complexity", "content": "Assume the context size for the LLM Mo is Nc. The ontology O, which can be written in a JSON-LD or textual format, has a length |0|, where the attributes are mapped to their corresponding ranges in the natural language vocabulary. OG-PREPROCESS phase may involves several LLM calls depending on the number of document chunks, specifically, (|D| + |O|)/Nc number of calls. We do not make any additional LLM calls during the querying time in the OG-RETRIEVE procedure."}, {"title": "4.3.2 Time Complexity", "content": "We ignore the time taken by LLM calls while calculating the time complexity, as this is accounted for under query complexity. Thus, the time complexity of the OG-PREPROCESS step only involves the hypergraph transformation by flattening the mapped data. Let us assume we have I factual-blocks derived from the documents, and each factual-block has a maximum length of |F|max = 0(0). We consider two cases: (1) Minimal or No Nesting: In this case, the time complexity is determined by step 4 in the algorithm, leading to a complexity of O(|O||I|), (2) Maximum Nesting: In this scenario, step 4 may result in an empty set. Thus, each factual-block F can be recursively flattened log |O| times while searching through the entire set, leading to a time complexity of O(|I||O|log |O|)."}, {"title": "4.3.3 Space Complexity", "content": "The only storage required is for the hypergraph structure H(I), which is directly proportional to the number of hyperedges |E| = |I|."}, {"title": "5 Experimental Setup", "content": "Datasets. We evaluate OG-RAG across two distinct domain categories that involve specialized workflows: (a) Industrial workflows, with a focus on the agriculture domain, where precise, data-driven decisions are critical for crop management and resource allocation, and (b) Knowledge work, where we evaluate it on research and analysis tasks in the news domain. We avoid general domains like Wikipedia to mitigate potential data contamination in LLM training. For the agriculture domain, we utilize two proprietary high-quality datasets comprising of 85 documents prepared by agriculture experts, focusing on the crop cultivation of Soybean and Wheat in India. For the news domain, we use the publicly available dataset from Multi-hop RAG [Tang and Yang, 2024], filtered for 149 long-form articles (each over 2,000 words) focused on multi-faceted, complex news stories requiring detailed, contextually rich analysis. Please refer to Appendix A for exemplary excerpts from the datasets. Ontology. We use a semi-automated approach to construct the ontology for both domains, which reflects the broader applicability of OG-RAG in specialized workflows. For the agriculture domain, the ontology was generated using a proprietary ontology learning module, which was then reviewed and verified by multiple experts specializing in crop cultivation. For the news domain, we modify the existing Simple News and Press (SNaP) ontology\u00b9. Specifically, we simplify its structure by excluding certain classes, such as those related to images, videos, and the \"stuff\" hierarchy. Instead, we allow an asset to be linked to multiple events, and each event can be associated with multiple organizations and persons. The complete ontologies for both domains are provided in Appendix B.2. Large Language Models. We consider 4 large language models for zero-shot query answering while adding the retrieved context from different methods: 2 closed-box models 2 (GPT-4o-mini and GPT-4o) and 2 open-source models 3 (Llama-3.1-8B and Llama-3.1-70B). These models have been chosen for their remarkable understanding and ability to reason in natural language. We consider 4096 completion tokens and a temperature of 0. Baselines. We compare OG-RAG against three leading retrieval-based methods, representing state-of-the-art approaches to context retrieval and generation, to demonstrate its effectiveness."}, {"title": "6 Experiments", "content": ""}, {"title": "6.1 Query answering", "content": ""}, {"title": "6.1.1 Question Generation", "content": "We generate a set of question/answer pairs using the RAGAS framework [RAGAS, 2024] to validate the factual accuracy of our proposed method. RAGAS prompts off-the-shelf LLM to generate questions of varying difficulty, each with the corresponding ground-truth answers and contexts. Specifically, we generate up to 100 unique questions from RAGAS focused on multi-hop reasoning abilities, which is commonly required in specialized domain tasks. Examples of these generated questions, along with their ground-truth answers, are provided in Appendix C."}, {"title": "6.1.2 Does OG-RAG help in retrieving useful contexts?", "content": "A context is deemed useful for a query if it provides sufficient information to derive the ground-truth response. We evaluate this using Context Recall and Context Entity Recall. Table 1 compares the performance of different retrieval"}, {"title": "6.1.3 Does OG-RAG help generate factually accurate responses?", "content": "A useful context should lead to more factual and precise response when incorporated into the query for various LLMs. We evaluate this by comparing how closely the generated responses/answers align with the ground-truth answer when added as context across different LLMs. Table 2 presents the results of response correctness, similarity, and relevance for the 3 datasets. OG-RAG consistently outperforms the baselines, significantly improving answer correctness by 40%, and answer relevance by 16%. The only notable exception where OG-RAG slightly underperforms is in the Answer Relevance for Wheat and Soybean datasets in GPT-4o and Llama-3-70B. This is likely due to the broad scope of the retrieved context, which can sometimes introduce extraneous information. This can be possibly mitigated through further fine-tuning of the hypergraph retrieval mechanism, adjusting the level of detail to suit the complexity of the queries expected. We leave domain-specific optimization for future work, as the current approach already delivers good responses across all datasets."}, {"title": "6.1.4 Is OG-RAG efficient?", "content": "Finally, we demonstrate that OG-RAG is computationally efficient by comparing its pre-processing and per-query retrieval times with other methods across different datasets. Table 3 shows that OG-RAG performs nearly as efficiently as a simple RAG method, with only a minimal increase of at most 2 seconds during querying time despite being at least 100% better in factual accuracy. OG-RAG is also shown to have significantly lower computational time than more competitive baselines such as RAPTOR and GraphRAG at both the pre-processing and query stages, particularly highlighted by a 50% drop in the pre-processing times. This efficiency is particularly critical for real-time applications, such as agricultural monitoring systems, legal research, and automated news fact-checking, where quick retrieval and processing of domain-specific knowledge is essential."}, {"title": "6.2 Context attribution", "content": ""}, {"title": "6.2.1 Survey design", "content": "To assess how effectively the proposed method aids humans in verifying facts within LLM-generated responses, we conduct a human study measuring the time taken to verify whether the given context supports the generated response. We randomly select 10 queries from the agriculture dataset and present the responses generated by GPT-4o using both RAG and OG-RAG, each paired with their respective contexts. We exclude RAPTOR due to its content similarity with RAG, and GraphRAG due to its prohibitive context length. Participants are asked to evaluate the level of factual support"}, {"title": "6.2.2 Results", "content": "A total of 16 participants, aged 18-34 and familiar with LLMs, took part in the survey. Table 4 presents the average time taken and the level of support participants attributed to the contexts. We observed that OG-RAG significantly reduced the time required by 28.8% and increased the human-attributed support by 29.6% on average. These results demonstrate that OG-RAG not only enables faster fact verification but also provides more robust and clear contexts, making the system more user-friendly and reliable for context fact attribution."}, {"title": "6.3 Factual Deduction", "content": ""}, {"title": "6.3.1 Deductive Facts", "content": "We assess OG-RAG's ability to enhance deductive reasoning in LLMs by evaluating how well it can generate new conclusions based on a set of predefined facts. These facts, grounded in domain-specific ontologies, provide the framework for reasoning tasks that require multi-step logic. Specifically, for this experiment we use six agricultural facts to deduce CO2 emissions, as this information is not directly available in the documents. These facts are partially derived from industry sources on the relationship between fossil fuels, pesticides, and greenhouse gases. 4:"}, {"title": "6.3.2 Question Generation", "content": "To create the evaluation test set, we prompt GPT-4o following the RAGAS guidelines RAGAS [2024] to generate questions that require the application of deductive facts and a randomly sampled chunk from the ontology-mapped data to generate the responses. Specifically, we use the following prompt:"}, {"title": "6.3.3 Results", "content": "Table 5 presents the results of factual deductions across two agriculture datasets, using GPT-4o and GPT-4o-mini as the underlying LLMs. In all cases, except two, the OG-RAG context substantially improves the correctness, similarity, and relevance of the generated answers compared to baseline methods. This demonstrates that OG-RAG is more effective at supporting deductive reasoning from a fixed set of facts. One exception is in the Soybean dataset for answer relevance which again points to a slightly less pertinent answer due to a broader retrieved context by OG-RAG. Overall, these results confirm that OG-RAG provides a more robust context for deducing new facts than alternative retrieval methods."}, {"title": "7 Conclusion", "content": "In this work, we study the problem of domain adaptation of LLMs using ontology-grounded retrieval-augmented generation. We introduce OG-RAG, a novel hypergraph-based retrieval method that retrieves query-relevant context from documents by structuring their facts as a hypergraph using a domain-specific ontology. OG-RAG has wide applicability in domains which include industrial workflows in healthcare, legal, and agricultural sectors, among others as well as knowledge-driven tasks like news journalism, investigative research, consulting and more. Through extensive experiments on two agriculture datasets and a news dataset, we demonstrate that OG-RAG significantly improves the factual accuracy of LLM-generated responses, while also enabling faster attribution of answers to their supporting context and more effectively deducing conclusions from domain facts. We recommend that LLMs have better ways to incorporate controlled vocabulary and structured evidence retrieval through fixed ontologies, as this not only enhances user comprehension of generated responses but also facilitates smoother integration of LLMs into industrial workflows and knowledge work. By offering greater flexibility and control over how context is retrieved and utilized, OG-RAG paves the way for more adaptable and reliable language systems. For future work we encourage to explore automated or"}, {"title": "A Dataset Examples", "content": ""}, {"title": "A.1 Soybean", "content": "title: SOYBEAN: AN INTRODUCTION Classification of States in six major Soybean growing zones: Soybean is majorly grown in the following areas # SOYBEAN: AN INTRODUCTION Classification of States in six major Soybean growing zones: Soybean is majorly grown in the following areas ## TILLAGE \u2022 Deep ploughing is essential during summer, after harvesting the Rabi crop. This facilitates exposing the hibernating insects to extreme heat and predatory birds as well as movement of nutrients and infiltration of soil water. Therefore, one deep ploughing once in 3-4 years, otherwise one normal ploughing in summer followed by 2 criss-cross harrowing or cultivation for breaking of soil clods will make ideal seed bed for a good crop of soybean cultivation is recommended. Also, sub-soiling operation once in 4-5 years at an interval of 10 meter, break the compactness of the sub-soil and also facilitate infiltration of rainwater which is useful for un-interrupted crop growth even during drought period also."}, {"title": "A.2 Wheat", "content": "## CLIMATE Wheat crop has wide adaptability. It is primarily a temperate crop but is widely cultivated in subtropical regions and is grown even in some tropical countries. \u2022 Ideal temperature for germination of wheat seeds is around 20-23 o C though these can germinate in temperature range of 3.5 to 35 o C. \u2022 During the heading and flowering stages, excessively high or low temperatures and drought are harmful to wheat. \u2022 The temperature conditions at the time of grain filling and development are very crucial for yield. \u2022 Temperatures above 25 o C during grain filling and development period tend to depress grain weight. When temperatures are high, too much energy is lost through the process of transpiration by the plants and the reduced residual energy results in poorer grain formation and lower yields"}, {"title": "A.3 News", "content": "#Raiders vs. Lions live score", "Monday Night Football": "ame **author**: Dan Treacy **source**: Sporting News **published_at**: 2023-10-30T22:20:03+00:00 **category**: sports **url**: https://www.sportingnews.com/us/nfl/news/ raiders-lions-live-score-highlights- monday-night-football/d022b1d62b18af8a70c516f4 The Lions just needed to get themselves back in the win column after a blowout loss in Balti- more, and they did just that in front of their home fans on Monday night. Detroit rolled to a 26-14 victory over the Raiders in a game that felt much more one-sided than the score indicates. The Lions thoroughly outplayed the Raiders, out-gaining Las Vegas by 329 yards, but critical mistakes by Detroit left points on the board. The offense struggled to turn red zone opportunities into touchdowns in the first half, and two turnovers deep in Raiders territory \u2013 including a pick-six by"}]}