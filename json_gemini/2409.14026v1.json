{"title": "UNCOVERING LATENT CHAIN OF THOUGHT VECTORS IN LARGE LANGUAGE MODELS", "authors": ["Jason Zhang", "Scott Viteri"], "abstract": "As language models grow more influential and trusted in our society, our ability to reliably steer them toward favorable behaviors becomes increasingly paramount. For this, we investigate the technique of steering vectors: biasing the forward pass of language models using a 'steering vector' derived from a specific task. We apply them to steer language models toward performing Chain of Thought (CoT) Reasoning without the need to prompt through natural language. We demonstrate this approach on Llama3 8b and Mistral 7b v0.2, and obtain competitive results compared to CoT-prompted performances on a series of reasoning benchmarks (GSM8k, MMLU, AGI Eval, ARC AI2) and qualitative examples. We find this approach yields consistent steering towards CoT responses and takes less compute than traditional methods of fine-tuning models towards CoT.", "sections": [{"title": "INTRODUCTION & RELATED WORKS", "content": "The integration of Language Models (LMs) into various aspects of society has accelerated rapidly in recent years (Zhao et al., 2023). However, these models still harbor significant limitations, par-ticularly in generating accurate information and solving complex reasoning problems (Huang et al., 2023; Mondorf & Plank, 2024). In response, considerable work has been done in making LMs more precise. One effective approach highlighted in the literature involves prompting or steering models toward Chain of Thought (CoT) Reasoning. This method enables LMs to decompose complex prob-lems into smaller, more manageable sub-problems and detect errors made in the problem-solving process (Wei et al., 2022; Nye et al., 2022).\nCurrent prominent approaches to steering models to CoT reasoning include supervised fine-tuning (Devlin et al., 2019), reinforcement learning from human feedback (Ziegler et al., 2020), and prompt engineering (Radford et al., 2019). However, these methods can be limited in effectiveness and re-quire substantial compute (Casper et al., 2023; Chen et al., 2024). Thus, in pursuit of a more efficient yet reliable approach, a new field of research called \"Activation Engineering\" has emerged. Operat-ing under the belief that the internal activations of LMs carry symbolic meaning (Azaria & Mitchell, 2023), researchers have successfully extracted \"steering vectors\" from the model's activation space to achieve control over sentiment, toxicity, and sentence-level steering in LM responses (Turner et al., 2023; Panickssery et al., 2024; Liu et al., 2024; Subramani et al., 2022).\nThis work builds upon existing methods of using steering vectors to manipulate the latent activation space of LMs by investigating whether we can apply this technique to reliably steer models towards CoT reasoning. We outline the process of creating steering vectors and evaluate the effectiveness of steering on a variety of reasoning benchmarks (GSM8k, MMLU, ARC-AGI Reasoning Challenge, AGI Eval) ((Cobbe et al., 2021; Hendrycks et al., 2021; Chollet, 2019; Zhong et al., 2023). Our experiments, conducted on two Language Models (Llama3 8b Instruct and Mistral 7b v0.2 Instruct) (Dubey et al., 2024; Jiang et al., 2023), demonstrate that this approach is not only effective, but also competitive when compared to models using traditional CoT prompting techniques."}, {"title": "METHODOLOGY & EXPERIMENT SET-UP", "content": "To extract steering vectors from our models, we use a similar approach as outlined by Panickssery et al. (2024). We utilize pairs of contrasting natural language prompts (e.g., \"Answer"}, {"title": "RESULTS & CONCLUSION", "content": "Our findings demonstrate that steering vector injected systems perform competitively against CoT-prompted systems for both models examined. This approach underscores the potential of steering vectors as an effective method for guiding language models toward Chain-of-Thought reasoning without compromising overall model performance. Further, the qualitative examples provided below illustrate the practical application of steering vector systems compared to baseline model responses for both Llama3 8b Instruct and Mistral 7b v0.2 Instruct (see Appendix C for more examples)."}]}