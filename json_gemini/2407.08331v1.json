{"title": "Towards Explainable Evolution Strategies with Large Language Models", "authors": ["Jill Baumann", "Oliver Kramer"], "abstract": "This paper introduces an approach that integrates self-adaptive Evolution Strategies (ES) with Large Language Models (LLMs) to enhance the explainability of complex optimization processes. By employing a self-adaptive ES equipped with a restart mechanism, we effectively navigate the challenging landscapes of benchmark functions, capturing detailed logs of the optimization journey, including fitness evolution, step-size adjustments, and restart events due to stagnation. An LLM is then utilized to process these logs, generating concise, user-friendly summaries that highlight key aspects such as convergence behavior, optimal fitness achievements, and encounters with local optima. Our case study on the Rastrigin function demonstrates how our approach makes the complexities of ES optimization transparent and accessible. Our findings highlight the potential of using LLMs to bridge the gap between advanced optimization algorithms and their interpretability.", "sections": [{"title": "1 Introduction", "content": "Nowadays, Large Language Models (LLMs) excel at solving diverse tasks by leveraging the attention mechanism, which enables them to recognize long-range dependencies in texts. Explainable AI (XAI) elucidate an AI model, its impact and potential biases helping to distinguish transparency and trustworthy in AI systems decisions. This approach aims to enhance AI systems' comprehensibility by utilizing an LLM to generate intuitive, user-friendly explanations of the Evolution Strategies (ES) [1] optimization process, which we refer to as Explainable ES (XES). XES can be used to draw conclusions from the LLM's explanations for potential hyperparameter tuning, such as adjusting the step size or other parameters in our evolutionary strategy use case. Through a detailed case study on the Rastrigin function, we demonstrate the efficacy of our approach in enhancing the transparency and understanding of ES, underscoring its potential implications for the field of XAI.\nIn Section 2, we explore the landscape of ES and XAI. In Section 3 we detail our developed framework XES. Following this, Section 4 presents an empirical analysis as a case study using the Rastrigin function. Finally, Section 5 consolidates our key discoveries and outlines unresolved inquiries, setting the stage for future exploration."}, {"title": "2 Related Work", "content": "XAI employs strategies to render AI systems' decisions transparent and interpretable. Intrinsically interpretable models like decision trees offer direct clarity, while complex models may be simplified for better understanding. Post-hoc algorithms, such as SHAP [5] and LIME [6], provide insights by highlighting influential features or input parts but require white box access and are computationally intensive. Example-based explanations, including counterfactuals, elucidate model decisions by presenting alternative scenarios. Interactive tools and comprehensive documentation further bridge the gap between AI complexity and user comprehension, enhancing transparency and trust.\nTools like FaAIr, HELM, and ANE elucidate how LLMs comes to responsible decisions. Zhao et al. [7] categorize various explainability techniques for LLMs. Liu et al. [4] introduce a ChatGPT-aided explainable framework for medical image diagnosis combining CLIP and ChatGPT that increases the zero-shot image classification accuracy on five medical datasets. Kroeger et al. [3] utilize the in-context learning capability of an LLM to explain the predictions of other models. Experiments conducted on real datasets demonstrate that this approach is competitive with state-of-the-art methods. Chuang et al. [2] explore the potential of LLMs as explainers by introducing a framework designed to provide faithful explanations, accurately capturing the prediction behaviors of LLMs."}, {"title": "3 XES: ES with LLM Explanations", "content": "XES is based on LLM-generated explanations summarizing and highlighting ES optimization runs. In our XES variant we employ a self-adaptive ES augmented with a restart mechanism to navigate complex optimization landscapes. The algorithm dynamically adjusts its mutation step sizes based on evolutionary history, enhancing exploration and exploitation capabilities. This self-adaptation mechanism fine-tunes the mutation parameters in response to the algorithm's performance, enabling a more efficient search process.\nTo counteract the potential for stagnation the algorithm incorporates a strategic restart mechanism. This mechanism is triggered when the algorithm detects a prolonged lack of significant improvements in fitness, indicative of entrapment in a local optimum. Upon activation, the algorithm reinitializes its state, including the population and mutation parameters, thereby diversifying the search space and increasing the likelihood of escaping suboptimal regions.\nCritical to our approach is the implementation of a detailed logging system that meticulously records the progression of the optimization process. The log file captures key metrics such as the development of fitness values across iterations, the evolution of mutation step sizes, stagnation events and subsequent restarts, offering a comprehensive view of the algorithm's dynamics.\nAn LLM is employed to distill the extensive and complex data recorded in the log-file into concise, user-friendly narratives, elucidating the optimization process. The LLM is prompted with prompts structured according to four dif-"}, {"title": "4 Case Study", "content": "In this section we present a case study, which is a practical application of our self-adaptive ES with LLM-generated explanations, utilizing the highly multimodal Rastrigin function to demonstrate the efficacy and transparency of our approach."}, {"title": "4.1 Setting", "content": "In our study, we deployed a o-self-adaptive (\u03bc + \u03bb)-ES to optimize a 10-dimensional Rastrigin function, a challenging benchmark known for its complex landscape with numerous local minima that requires the detection of stagnation in local optima and the triggering of restart mechanisms. The algorithm was set to run until either a maximum of 10,000 iterations were reached or a fitness threshold of 10-5 was achieved. To monitor and analyze the optimization process, logs were systematically generated every 30 iterations of the Rastrigin function, detailing the fitness values and step sizes. Additionally, instances of stagnation and subsequent restarts, particularly at the initial point (1,..., 1), were meticulously recorded to understand the algorithm's behavior in trapping and escaping local optima. Overall, XES was tested with three log files of varying lengths. Log file 1 (\"short\") documents 150 iterations, log file 2 (\"middle\") spans 420 iterations and log file 3 (\"long\") consists of 1260 iterations which encompass the highest number of restarts. Listing 1 presents log file 1. To translate these intricate logs into comprehensible narratives, we employed four different language models, setting the temperature to 0.0 for more deterministic text generation. The LLMs we use are Llama2:70b, Llama3:70b, Mistral 7b and Mixtral 8x7b. The prompts followed one of the four prompt strategies' structures. Each combination of LLM and prompt strategy was repeated ten times per log file. To evaluate the LLM's response, numerical information, such as the best and worst fitness, was automatically extracted and verified whether it was correct. Non-numerical information, such as convergence behavior and local optima, was assessed manually. The total score for a combination of LLM and prompt strategy was determined by assigning one point to each correct statement (best fitness, worst fitness, convergence behavior, local optima) and then normalizing the score to a value between 0 and 1."}, {"title": "4.2 Results", "content": "Table 2 shows the results of the experiments conducted w.r.t. the average score achieved across the ten repetitions.\nThe outcomes of the conducted experiments are largely similar. Notably, Llama2:70b shows lower scores, whereas Mixtral 8x7b, especially with Few-Shot Prompting, outperforms the others, achieving a peak performance value of 1.0. Among the different prompt strategies, Few-Shot Prompting achieves the best average results across all models. For instance Mixtral 8x7b with Few-Shot-Prompting for log file 2 outputs:\n\"The algorithm initially converged to a local optimum near 3.98, then re-started and converged to a lower optimum near 2, followed by another restart and convergence to the best observed value of 0.0106. Multiple local optima were encountered during the optimization process. The lowest fitness value observed was 0.0106. The highest fitness value observed was 3.9852.\"\nThe LLM's summary of the ES run is clear and coherent, detailing key aspects such as best and worst fitness values, and critical events like convergence and stagnation. The inclusion of specific numerical details enhances the summary's precision, providing a transparent view of the ES's performance on the Rastrigin function. However, the analysis could benefit from further context on the significance of step size adjustments and a more explicit evaluation of the strategy's overall success.\nXES tends to yield superior results with shorter log files, providing more detailed responses that mention specific iterations and values. In contrast, longer log file responses result in more general information, often referencing iterations and values from the log file's last iterations which is typical for the way an LLM works. A limitation is the parameter context length of an LLM, which may not be exceeded when formulating prompts based on the prompt strategy and the"}, {"title": "5 Conclusions", "content": "Our approach harnesses the advanced natural language generation capabilities of LLMs to transform technical optimization logs into accessible explanations, thereby demystifying the intricacies of the ES optimization process for a broader audience. Looking ahead, we see substantial potential in further enriching this framework. Firstly, by integrating an interactive analysis layer that prompts user inquiries, we can tailor explanations to individual needs, enhancing user engagement and comprehension. Secondly, the insights derived from LLM analyses could inform the development of intelligent, agent-based systems capable of automating optimization actions."}]}