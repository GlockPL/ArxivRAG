{"title": "Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting", "authors": ["Lifan Zhao", "Yanyan Shen"], "abstract": "Time series forecasting always faces the challenge of concept drift, where data distributions evolve over time, leading to a decline in forecast model performance. Existing solutions are based on online learning, which continually organize recent time series observations as new training samples and update model parameters according to the forecasting feedback on recent data. However, they overlook a critical issue: obtaining ground-truth future values of each sample should be delayed until after the forecast horizon. This delay creates a temporal gap between the training samples and the test sample. Our empirical analysis reveals that the gap can introduce concept drift, causing forecast models to adapt to outdated concepts. In this paper, we present PROCEED, a novel proactive model adaptation framework for online time series forecasting. PROCEED first operates by estimating the concept drift between the recently used training samples and the current test sample. It then employs an adaptation generator to efficiently translate the estimated drift into parameter adjustments, proactively adapting the model to the test sample. To enhance the generalization capability of the framework, PROCEED is trained on synthetic diverse concept drifts. We conduct extensive experiments on five real-world datasets across various forecast models. The empirical study demonstrates that our proposed PROCEED brings more performance improvements than the state-of-the-art online learning methods, significantly facilitating forecast models' resilience against concept drifts.", "sections": [{"title": "1 Introduction", "content": "Time series forecasting has been a prevalent task in numerous fields such as energy [5], retail [7], climate [4] and finance [29]. The past decade has witnessed a surge of deep learning-based forecast models [17, 21, 32] that take past time series observations to predict values in the next H steps, where H is called forecast horizon. Due to the dynamic nature of the environment, latent concepts that influence observation values (e.g., social interest [2], stock market sentiment [15]) often change over time. This ubiquitous phenomenon is known as concept drift [12]. In the presence of concept drift, future test time series may not follow a similar data distribution as the historical training data, causing degradation in forecasting performance [26, 29].\nOnline learning is commonly used to mitigate the effects of concept drift. The key consideration is to continually transform the newly observed time series into a set of training samples and adjust model parameters by minimizing the forecast errors on the new training samples. In addition to the standard fine-tuning technique, recent works [22, 28] proposed more advanced model adaptation techniques, which focus on how to effectively adapt to recent data by utilizing forecasting feedback (e.g., forecast errors or gradients) on the new training samples. Among them, FSNet [22] monitors the gradients in previous fine-tuning, transforms them into parameter adjustments, and tailors a new forecast model to the current training samples. OneNet [28] is an online ensembling network that generates ensemble weights to combine two forecast models and dynamically adjusts the ensemble weights and the models' parameter weights according to the forecast errors. However, existing online learning methods overlook the fact that the ground truth of each prediction is not available immediately but is delayed after the forecast horizon.\nAs illustrated in Fig. 1, an online learning task inherently has a H-step feedback delay in time series forecasting, resulting in a temporal gap (at least H steps) between available training samples and the test sample. Formally, at each online time t, the current horizon window Yt, which have not been observed yet, has overlap with $Y_{t-H+1},..., Y_{t-1}$. These samples cannot provide complete forecasting feedback and supervised signals for the performant, prevailing time series forecasting models which predict H-step values directly [17, 21, 27]. Hence, the available training samples for online learning at time t is $D_{t-} = \\{(X_{t'}, Y_{t'r}) | t' \\leq t - H\\}$, which has a temporal distance to the test sample ($X_t$, Yt). The temporal gap issue suggests that addressing concept drift by fitting the forecast model to the recent training samples may be insufficient, since concept drift may also occur over the H-step temporal gap between the recent training samples and the current test sample."}, {"title": "2 Definitions and Problem", "content": "Consider N distinct variates ($N \\in N^+$). Let $v_t \\in R^N$ denote the N-dimensional observation values at time t. A time series is a sequence of observation vectors in time order, i.e., $V_1$, $V_2$, ...."}, {"title": "DEFINITION 1 (TIME SERIES FORECASTING)", "content": "Let L be the lookback window size and H be the horizon window size, where L, H \u2208 N\u207a. At time t, a forecast model F parameterized by \u03b8 takes the past observations $X_t = [V_{t-L+1},\u2026,V_t] \u2208 R^{N\u00d7L}$ as input features to predict the future H-step values, denoted as $Y_t = [V_{t+1},\uff65\uff65\uff65,V_{t+H}] \\in R^{N\u00d7H}$. The training objective is to optimize the model parameters \u03b8 such that the loss function $||\u0176_t \u2013 Y_t||^2$ is minimized, where $\u0176_t \u2208 R^{NXH}$ denotes the predicted values in the horizon window.\nTypically, in multi-step forecasting where H > 1, there are two primary strategies to generate the predictions \u0176t at each time t. The first strategy performs iterative forecasting. That is, the model forecasts one step ahead and uses its prediction to forecast the next step, repeating this process for the entire horizon. Despite its simplicity, this strategy suffers from significant error accumulation over long horizons [27]. The second strategy adopts direct forecasting where the model makes all the predictions \u0176t simultaneously. Note that the two strategies require different output modules or layers in the forecast model. Recent works [21, 27] have shown that direct forecasting tends to outperform the iterative method, particularly for longer forecast horizons. Hence, this paper adopts the direct forecasting strategy where a sample Xt is considered valid for training if all the H-step values in Yt are known [9].\nIn online forecasting scenarios, time series data are observed sequentially. Due to the dynamic nature of real-world processes, underlying data distributions are subject to constant change. Consequently, a forecast model trained on historical data may encounter difficulties when confronted with new, evolving patterns. This issue is referred to as the concept drift challenge, which can substantially affect model performance over time [12]. To mitigate concept drifts, it is crucial to adapt the forecast model continuously to assimilate new concepts presented in the incoming time series. + Formally, the online model adaptation problem is defined as follows."}, {"title": "DEFINITION 2 (ONLINE MODEL ADAPTATION)", "content": "At time t, online model adaptation activates a model adapter A that produces adapted model parameters \u03b8t based on available observations {$v_1$, \u2026, $v_t$ }, where \u03b8t is expected to be close to the optimal parameters \u03b8. Then, we forecast Yt by F($X_t$;\u03b8t).\nAt a high level, existing model adaptation methods [9, 22, 28] select some observed data $D_{t-C}$  {((Xt', Yt') | t' \u2264 t - H} as training samples and utilize the forecasting feedback (e.g., forecasting errors and gradients w.r.t. $D_{t-}$) to update the model parameters. Their adapted parameters tend to align with the patterns or concepts present in $D_{t-}$. However, it is crucial to recognize that the concepts present in $D_{t-}$ may not necessarily reflect that of the test sample ($X_t$, Yt) due the horizon time span H. To this end, the model optimized on $D_{t-}$ might still be susceptible to concept drift, potentially resulting in suboptimal predictions at time t (see details in Section 3).\nIn what follows, we provide empirical analysis that illustrates the presence of concept drift between $D_{t-}$ and the test sample ($X_t$, Yt), revealing the limitations of existing model adaptation techniques."}, {"title": "3 Empirical Analysis and Motivation", "content": "In this section, we present an empirical study examining how concept drift between newly acquired training data and test data affects"}, {"title": "3.1 Datasets", "content": "Following prior works [22, 28], we use five real-world time series datasets, including ETTh2, ETTm1, Weather, ECL, and Traffic. We provide their detailed descriptions in Appendix C.1 and statistical information in Table 6. We also adhere to the evaluation settings of FSNet [22] and OneNet [28], where each dataset is chronologically divided into training/validation/test sets by the ratio of 20:5:75."}, {"title": "3.2 Baseline Variants", "content": "We consider the following there time series forecasting models.\n\u2022 FSNet [22]: FSNet is built upon a TCN [3] backbone and further develops an advanced updating structure that facilitates fast adaptation to concept drift.\n\u2022 OneNet [28]: OneNet is an ensemble model that dynamically combines two forecasters, one focused on temporal dependence and one focused on channel dependence. We follow its official implementation where the two forecasters are built upon FSNets.\n\u2022 PatchTST [21]: PatchTST is one of the state-of-the-art time series forecasters, which models cross-time dependence by Transformer blocks.\nWe pre-train the forecast models on the training set and then perform online learning across the validation set and test set. For each of the models, we compare two online learning techniques below.\n\u2022 Practical: At each time t, before forecasting Yt, we perform predictions on $X_{t-H}$ and use the Mean Square Error (MSE) between the ground truth $Y_{t-H}$ and the prediction $\u0176_{t-H}$ to update the model by one-step gradient descent.\n\u2022 Optimal: At each time t, before forecasting Yt, we assume the ground truth $Y_{t-1}$ is available without any delay. We calculate the previous forecast loss on the last sample $X_{t-1}$ (i.e., MSE between $Y_{t-1}$ and $\u0176_{t-1}$) to update the model by one-step gradient descent.\nIt is important to notice that the Optimal strategy uses the most relevant and recent information for the prediction on the test sample Xt. However, it is infeasible in practice as it requires knowledge of future data. The performance gap between this ideal strategy and the Practical strategy reveals the presence of concept drift that is not adequately addressed by existing online learning techniques. To maintain a fair comparison, both strategies fine-tune all the model parameters using one training sample each time."}, {"title": "3.3 Evaluation Metrics", "content": "Following previous works [22, 27, 31], we evaluate the forecasting performance by two commonly used metrics as defined below:\nMean Square Error (MSE) = $\\frac{1}{|T_{test}|} \\sum_{t \\in T_{test}} ||Y_{t} - \\hat{Y}_{t}||^2$,\nMean Absolute Error (MAE) = $\\frac{1}{|T_{test}|} \\sum_{t \\in T_{test}} |Y_{t} - \\hat{Y}_{t}|$,\nwhere $T_{test}$ represents all time steps of the test set and \u0176t \u2208 $R^{N\u00d7H}$ denotes the predicted result at time t. A lower error indicates higher forecasting performance. Each experiment is repeated 3 times with"}, {"title": "AMSE", "content": "$\\frac{MSE_{Practical} - MSE_{Optimal}}{MSE_{Optimal}} \\times 100\\%$."}, {"title": "3.4 Key Observations", "content": "Table 1 shows the MSE results of two strategies. We have the following major observations. First, the Practical strategy performs worse than Optimal by an average of 107% on different models. This significant difference suggests that the most recently observed pattern in ($X_{t-H}$, $Y_{t-H}$) substantially differs from ($X_{t-1}$, $Y_{t-1}$) and fails to reflect the concept of the test sample ($X_t$, Yt). In other words, the adapted forecast models are still vulnerable to the concept drift caused by the feedback delay issue. Second, we can observe the general tendency for the performance gap to become more significant as the forecast horizon increases. This could be attributed to the increasing temporal distance between $X_{t-H}$ and $X_t$. Third, OneNet demonstrates the best performance when utilizing the Optimal strategy. However, its effectiveness drastically diminishes in all the cases when employing the Practical strategy, even becoming the worst on the ETTm1 and Traffic datasets. The reason is that OneNet is an ensemble model with a large number of parameters, which increases the overfitting risk on the new training samples. Fourth, PatchTST, recognized as the leading time series forecasting model, reports much smaller AMSE than the other models. When using the Practical strategy, PatchTST outperforms all the other models. However, it still falls short of the performance achieved by OneNet under the Optimal strategy. To sum up, there is still considerable room for performance improvement if we can address the possible concept drift between each test sample and the latest available training data during online learning."}, {"title": "4 The Proposed Framework: PROCEED", "content": "In this section, we first discuss our idea and provide an overview of the proposed PROCEED solution. We then elaborate on two major steps, namely concept drift estimation and proactive model adaptation. Finally, we describe the end-to-end training scheme that improves the model's adaptation ability against concept drifts."}, {"title": "4.1 Solution Overview", "content": "The ultimate goal of PROCEED is to close the gap between the newly acquired training data and the test sample and boost performance against concept drift caused by the feedback delay issue. To achieve this, a simple solution is to extract the latent concepts from all historical samples and learn a mapping function between each concept and optimal model parameters w.r.t. the historical sample. As such, one can extract concept from each test sample and use the mapping function to directly generate possibly optimal parameters. However, the online phase may include new concepts that are out of the historical data distribution. The simple solution can fail in this case, since it has not learned the relationship between out-of-distribution (OOD) concepts and corresponding optimal parameters.\nTo address the problem, we propose to map concept drifts to parameter shifts. We assume that the direction and degree of the drift over the concept space can reflect a possible direction and magnitude of parameter shifts over the parameter space, informing how to make an adaptation. Specifically, given a model that fits new training samples, PROCEED exploits latent features from the training samples and the current test sample, estimates the undergoing concept drift, and accordingly predicts parameter shifts.\nFollowing existing online model adaptation methods [22, 28], we use one training sample for model updating at each time t, i.e., $D_t = (X_{t-H}, Y_{t-H})$. With the model updated on $D_{t-}$, we estimate the concept drift between $D_{t-}$ and $X_t$, predict potential shifts in the parameter space, and accordingly make parameter adjustments. Formally, our PROCEED solution consists of four key steps at each time t as listed below.\n(1) Feedback-based model adaptation. Given a forecast model F parameterized by $\u03b8_{t\u2212H\u22121}$, we redo forecasting by $\u0176_{t-H} = F(X_{t\u2212H};\u03b8_{t\u2212H\u22121})$. Next, we use the forecast error $||\u0176_{t-H} - Y_{t-H}||$ to update $\u03b8_{t\u2212H\u22121}$ into $\u03b8_{t\u2212H}$ by gradient descent. The subscript of indicates that the parameters have fit ($X_{t-H}$, $Y_{t-H}$).\n(2) Concept drift estimation. Given $D_{t-}$ and the test sample $X_t$, we feed them into two concept encoders \u03f5 and $\u03f5'$ that extract concept representations denoted as $c_{t-H} \\in R^{d_c}$ and $c_t \\in R^{d_c}$, respectively. Then, we estimate the hidden state of the concept drift between $X_{t-H}$ and $X_t$ by $s_{t-H\u2192t}$, where $s_{t-Ht} = c_t - C_{t-H}$."}, {"title": "(3) Proactive model adaptation", "content": "Given the estimated concept drift $s_{t-H\u2192t}$ and the parameters $\u03b8_{t-H}$, we employ an adaptation generator G to generate parameter shifts \u2206\u03b8, adjusting $\u03b8_{t-H}$ into $\u03b8_t$ as illustrated in Fig. 2.\n(4) Online forecasting. Finally, the adapted model yields predictions by $\u0176t = F(X_t; \u03b8\\hat{}_t)$. In the next time t + 1, the parameters will be reset to $\u03b8_{t-H}$.\nThe rationale of our solution is that we can synthesize diverse concept drifts based on historical data to train our model adapter. Fig. 3 shows an example of the historical training data including four samples with their concepts denoted by $c_1$,\u2026, $c_4$ respectively. Our idea is to shuffle the order of samples and train our model adapter on the synthetic concept drifts between each pair of samples. Though the concepts of the future test samples (i.e., $c_5$,\u2026, $c_7$) are out-of-distribution, the concept drift patterns $\u03b4_{4\u21926}$ and $\u03b4_{5\u21927}$ are similar to $\u03b4_{1\u21924}$, $\u03b4_{2\u21923}$ which have been learned in training data. Given such reoccuring concept drifts, we can generate appropriate parameter shifts by experience."}, {"title": "4.2 Concept Drift Estimation", "content": "In the literature, there are numerous concept drift detection methods [12] that estimate the degree of concept drift to decide when to adapt the model. The degree can be estimated by the changes in forecast error [8], distribution distance [10], prediction uncertainty [33], etc. Nevertheless, the degree as a scalar in R is not informative and cannot indicate how to adapt the model. Therefore, we propose to model a high-dimensional representation vector in $R^{d_c}$ that characterizes both the degree and the direction of the concept drift, where $d_c$ is the representation dimension.\nFirst, we devise a concept encoder \u03f5 that extracts concept representation $c_{t-H}$ from the latest training sample $D_t = (X_{t-H}, Y_{t-H})$. Let $X^{(i)}_{t-H} \u2208 R^L$ denote the time series of the i-th variate. Given all observations of N variates at time t, we encode $c_{t-H}$ by the following equation:\n$c_{t-H} = \u03f5(D_{t-}) = Average (MLP(X^{(i)}_{t-H} || Y^{(i)}_{t-H}))^N_{i=1} \u2208 R^{d_c}.  (1)$,\nwhere MLP extracts $d_c$ latent features (e.g., mean and standard deviation) from each univariate time series, and Average yields the average latent features as a global concept that affects all variates."}, {"title": "4.3 Proactive Model Adaptation", "content": "As illustrated in Fig. 2, we assume the concept representation space and the parameter space to have some learnable relationships, where the estimated concept drift $s_{t-H\u2192t}$ can indicate the direction that the parameters $\u03b8_{t-H}$ should shift to.\nTechnically, it is non-trivial to decode the concept drift representation into an appropriate parameter shift. As the parameter space is often of a huge dimension, it is tough to search for an optimal mapping function between the concept space and the parameter space. Also, a simple mapping function may require too many additional parameters, leading to costly memory overhead. For instance, when $d_c$ = 100 and the number of model parameters is 1 million, a trivial method is to learn a fully connected layer of 100 million parameters that maps $s_{t-H\u2192t}$ to parameter shifts"}, {"title": "4.4 Mini-batch Training", "content": "Given abundant historical data, we shuffle them to synthesize diverse concept drifts and train our model adapter on them. To improve the training efficiency, we randomly select multiple samples as a mini-batch, adapt the forecaster towards each sample concurrently, and compute the average forecast loss.\nLet $B_k$ = {$X_{k,j}$, $Y_{k,j}$} {$k =B+B$} represent the k-th mini-batch of B samples collected from different time. For the last mini-batch $B_{k-1}$, our concept encoder $\u03f5'$ extracts latent features of all samples and their average $c_{k-1}$ is considered as the concept representation of $B_{k-1}$. For each $X_{k,j}$ in $B_k$, we estimate the concept drift from $B_{k\u22121}$ to $X_{k,j}$ individually and generate the corresponding adaptation coefficients $\u03b1^{(l)}_{k,j}$,$\u03b2^{(l)}_{k,j}$ . Note that we do not iteratively make different versions of adapted models (i.e., {$\u03b8_{k,j}$} {$k = B+B+1$}) which consumes more GPU memory and more time cost. Instead, we only preserve one model obtained from the last mini-batch (denoted as $\u03b8_{k-1}$) and simultaneously handle multiple data batches.\nFor brevity, we omit the superscript (l) in the following equations. Let $h_{k,j} \u2208 R^{d_{in}}$ denote the intermediate inputs of the l-th layer. Given adaptation coefficients $\u03b1_{k,j}$, $\u03b2_{k,j}$, the linear transformation via adapted parameter $\u03b8\\hat{}_{k,j}$ is reformulated as\n $\u0398^{(l)}_{k,j} h_{k,j}$ = $(\u03b1_{k,j} \u03b2_{k,j} \\odot \u03b8_{k-1}) h_{k,j}$ = $\u03b2_{k.j} \\odot (\u03b8(\u03b1_{k,j} h_{k,j})). (5)$\nThis equation also stands for other parameters such as convolution filters and bias terms. As such, we can directly compute $\u0398^{(l)} H_{k,j}$ as usual, where $H_{k,j}$ = {$\u03b1_{k,j} h_{k,j}$  {$k =B+B$}. Correspondingly, we multiply the layer outputs with $\u03b2_{k,j}$ for each sample in parallel. As such, we obtain the predictions of all samples in $B_k$, denoted  {$\u0176_{k,j}$ }{$k = B+B+1$}. Next, we compute the average forecast loss on {$||\u0176_{k,j} - Y_{k,j}||^2$ }{$k = B+B+1$} and use the gradients to update $\u03b8_{k\u22121}$ into $\u03b8_k$ and train other additional parameters, including the concept encoders and the adaptation generator. The updated model and the updated adapters will be used in the next mini-batch. During the online phase, we only fine-tune the forecast model and keep the parameters of the model adapter frozen because the ground truth of the test sample is not available."}, {"title": "4.5 Discussion", "content": "4.5.1 Comparison with Existing Methods. Prior approaches to online time series forecasting make model adaptation passively based on forecasting feedback on previous samples, which mainly focus on effectively learning recent data patterns. In Table 2, we compare existing methods and PROCEED in terms of the training data and the model adaptation techniques at each online time t. Most methods use one newly acquired training sample, while SOLID [9] selects more recent samples that share similar lookback windows with the test sample and are assumed to share similar concept. SOLID and PROCEED simply fine-tune the forecast model by gradient descent, while FSNet and OneNet further generates additional parameter adjustments based on the forecasting feedback. Since the feedback is delayed by H steps and cannot reveal the test concept, we propose a novel step called proactive model adaptation which aims to mitigate the effects of concept drift between the training sample and the test sample. As this core step is orthogonal to existing methods, PROCEED can also incorporate the data augmentation technique of SOLID and the feedback-based model adaptation techniques of FSNet and OneNet.\n4.5.2 Time Complexity Analysis. Though the lookback window size L and the number of variates N could be large, our concept drift estimation has a linear complexity w.r.t. them, i.e., O(NLdc) with a relatively small hyperparameter dc. As for proactive model adaptation, the time complexity is O(r(dc + din + dout) + dindout), which is agnostic to the number of variates. Note we set a rather small bottleneck dimension r (e.g., 32). Hence, our framework is friendly to large-scale multivariate time series with a large N. Throughout the online phase, we first adapt the model parameters by Eq. (4), and online forecasting is performed with no additional cost."}, {"title": "5 Experiments", "content": "In this section, we present experiments on real-world datasets to evaluate the effectiveness and efficiency of PROCEED."}, {"title": "6 Conclusion", "content": "In this work, we highlight that online time series forecasting inherently has a temporal gap between each test sample and available training data, where concept drift may well occur. Through empirical study, we found that this gap hinders the effectiveness of existing model adaptation methods which passively rely on the forecasting feedback on recent data. To address this issue, we propose a novel online model adaptation framework named PROCEED, which proactively adapts the forecast model to the test concept before forecasting each test sample. Specifically, PROCEED first fine-tunes the model on the latest acquired training sample, then extracts latent features from time series data to estimate the undergoing concept drift, and efficiently maps the estimated drift into parameter adjustments that are tailored for the test sample. Furthermore, we synthesize diverse concept drift and optimize PROCEED with generalization capacity of mapping concept drift to beneficial parameter adjustments. Extensive experiments on five real-world time series datasets demonstrate that our proposed PROCEED remarkably reduces the forecast errors of various forecast models and surpasses the state-of-the-art online learning methods. Our proactive model"}, {"title": "A Theoretical Analysis", "content": "Inspired by a recent work [2], we can prove that it is feasible for the forecast model with proactive model adaptation to have lower forecasting error than one without proactive model adaptation.\nIn practice, we initialize the parameters $W_l^{(l)}$ as an all-zero matrix, and the adaptation coefficients stem from zeros. Thus, we have $A(\u03b8; \u03b8_0) = 0$, where A denotes the model adpater and $\u03b8_0$ denotes the initialized parameters of A. Given randomly shuffled historical data, we train the adapter parameters into $\u03c6 \\hat{*}$ that is close to an optimum $\u03c6^*$ and approximates the transition probability P(\u03b8t | \u03b8t), Xt', Xt. Let $\u03b8\\hat{}_t$ denote $A(\u03b8_{t\u2212H};), 0 denote the optimal model parameters for forecasting Xt, and $\u03b8_t^* = A(\u03b8_{t\u2212H}; *)$. The adapted model parameters $\u03b8\\hat{}_t$ generated by the well-learned model adapter are expected to get closer to the optimal model parameters $\u03b8_t^*$ than those generated by A(\u00b7; 0). Formally, we have\n$||A(\u03b8_{t\u2212\u043d}; \u03c6) \u2013 A(\u03b8_{t\u2212H};\u03c6^*)|| < ||A(\u03b8_{t\u2212H};\u03c6_0) \u2013 A(\u03b8_{t\u2212H};\u03c6^*)||,  (6)$\ni.e.,\n$||\u03b8\\hat{}_t - \u03b8_t^*|| < ||\u03b8_{t\u2212H} - \u03b8_t^*||. (7)$\nAs we synthesize various concept drifts to train the model adapter, we believe that most concept drifts on test data have been learned in past experience, thereby satisfying Eq. (7) during the online phase. Assuming that the forecast model F has Lipschitz constant with upper bound $L_{upper}$ and lower bound $L_{lower}$ w.r.t. its parameters \u03b8, we have\n$L_{lower}||0 \u2013 0' || < ||F(X; 0) \u2013 F (X; 0')|| < L_{upper}||0 \u2013 0\u2032 ||, \u2200X. (8)$\nThen, we can derive the following inequalities:\n$||F(Xt; \u03b8_{t-H}) - F(Xt;0^*)|| > L_{lower}||0_{t-H} - 0^*||,  (9)$\n$||F(X_t; \u03b8\\hat{}_t) \u2013 F (X_t;0^*)|| < L_{upper}||\u03b8\\hat{}_t \u2212 0^*||. (10)$\nNote that F is usually a neural network as a continuous function of \u03b8. We define S(0, \u2206) as a sphere centering at with a radius \u2206\u2208 $R^+$. When \u2206 approaches 0, due to the continuity of F, the upper bound and lower bound of Lipschitz constant within S(0, \u2206) will become closer and finally identical, i.e., lim\u25b3\u21920+ Lupper/Llower = 1. Moreover, we have known that $||\u03b8_{t\u2212H} \u2212 \u03b8^*|||||\u03b8_t \u2212 \u03b8^*|| > 1$ in Eq. (7). Therefore, there always exists a constant A > 0 such that $L_{upper}$/$L_{lower}$ < $||\u03b8_{t\u2212H} \u2212 \u03b8^*||||| \u03b8_t \u2212 \u03b8^*||, where $\u03b8_{t\u2212H}$, $\u03b8_t \u2208 S(0, 1)$. Thus it is always possible to satisfy the following inequality:\n$L_{upper}||\u03b8\\hat{}_t \u2212 0^*|| < L_{lower}||0_{t\u2212H} \u2212 0^*|| . (11)$\nCombining Eq. (11) and Eq. (9), we have:\n$||F(X_t; \u03b8\\hat{}_t) \u2013 F(Xt;0^*)|| < ||F(X_t; \u03b8_{t\u2212H}) \u2013 F(Xt;0^*)||, (12)$\nwhere $\u03b8_t^*$ is the optimal parameters for forecasting Xt. In other words, it is possible for the forecast model with proactive model adaptation that yields fewer forecast errors, i.e.,\n$||F(X_t; \u03b8\\hat{}_t) \u2013 Y_t|| < ||F(X_t; \u03b8_{t\u2212H}) \u2013 Y_t ||. (13)$"}, {"title": "B Related Works", "content": "B.1 Online Model Adaptation\nOnline model adaptation, or online learning [13], has been a popular learning paradigm that updates models on new data instantly or periodically. In the general field, most efforts focus on addressing the catastrophic forgetting issue [20] stemming from excessive updates, and numerous continual learning [24] methods have been developed to retain acquired knowledge of past data by rehearsal mechanisms [6] and regularization terms [23], which can be seamlessly incorporated into our framework. Most recently, SOLID [9] proposed to adapt the forecast model by several selected training samples which are assumed to have a similar context (i.e., concept in this paper) to each test sample. SOLID [9] relies on heuristic measures about context similarity and is not fully aware of unobserved contexts. The selected training samples may not share the exactly same concept with the test sample. Thus it is desirable to further adopt our proposed framework. We would like to leave the combination of training data sampling and proactive model adaptation as future work.\nAfter the submission of our manuscript, there are two concurrent researches [1, 16] that also noticed the information leakage in FSNet and OneNet. Since the ground-truth H-step values of the last prediction are not fully observed, both works propose to generate pseudo labels of the unobserved values, concatenate the pseudo labels with observed labels to simulate complete ground truth, and calculate the forecast errors to update the model. The potential drawback is that the pseudo label generator is still susceptible to concept drift and may produce low-quality pseudo labels, leaving the concept drift issue unresolved.\nOn top of online learning, rolling retraining [15] is another learning paradigm that periodically re-trains a new model from scratch on all historical data, while the cost of frequent retraining is unaffordable. In practice, we can perform rolling retraining once a month and adopt daily updates during the interval to learn new patterns timely. Our work is orthogonal to rolling retraining.\nB.2 Data Adaptation\nApart from model adaptation, data adaptation is also a mainstream approach to the concept drift in time series forecasting, which is orthogonal to model adaptation. The goal of data adaptation is to normalize historical training data and future test data into a common data distribution [11, 14, 19], reducing overfitting risks. Among them, RevIN [14] is the most popular method that applies instance normalization to each time series lookback window and restores the statistics to the corresponding predictions, making each sample follow a similar distribution. Such normalization-based data adaptation methods mainly focus on the statistical changes in the mean and deviation of time series, while they overlook the distribution shifts in more complex temporal dependencies between time steps and spatial dependencies between variates [30]. Meanwhile, the forecast model may underfit the normalized time series, as the removed statistics may also serve as informative signals for prediction [18]."}, {"title": "C Experimental Setup", "content": "C.1 Datasets\nWe list detailed descriptions of datasets used for experiments as follows.\n\u2022 ETT [31", "27": "records the hourly electricity consumption of 321 clients from 2012 to 2014.\n\u2022 Weather [31", "25": "records the hourly road occupancy rates recorded by the sensors of San Francisco freeways from 2015 to 2016.\nC.2 Evaluation Settings\nTo the best of our knowledge", "28": "noticed the feedback delay", "X_{t-L": "t"}, "to forecast $X_{t+1:t+H}$ and then use $X_{t-L+H:t+H}$ to forecast $X_{t+H+1:t+2H}$. In contrast, the common practice is to perform forecasting at each time step between t and t + H, continually updating the previous predictions of $X_{t-L+H:t+H}$. The reason is that short-term forecasting is typically easier than long-term forecasting. Therefore, in this work, we implement a more realistic evaluation framework for online learning where we perform forecasting at each time step, which remains consistent with the traditional evaluation setting.\nAs for the ETTm1 dataset, popular works (e.g., Informer [31"]}