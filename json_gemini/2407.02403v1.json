{"title": "Face Reconstruction Transfer Attack as Out-of-Distribution Generalization", "authors": ["Yoon Gyo Jung", "Jaewoo Park", "Xingbo Dong", "Hojin Park", "Andrew Beng Jin Teoh", "Octavia Camps"], "abstract": "Understanding the vulnerability of face recognition systems to malicious attacks is of critical importance. Previous works have focused on reconstructing face images that can penetrate a targeted verification system. Even in the white-box scenario, however, naively reconstructed images misrepresent the identity information, hence the attacks are easily neutralized once the face system is updated or changed. In this paper, we aim to reconstruct face images which are capable of transferring face attacks on unseen encoders. We term this problem as Face Reconstruction Transfer Attack (FRTA) and show that it can be formulated as an out-of-distribution (OOD) generalization problem. Inspired by its OOD nature, we propose to solve FRTA by Averaged Latent Search and Unsupervised Validation with pseudo target (ALSUV). To strengthen the reconstruction attack on OOD unseen encoders, ALSUV reconstructs the face by searching the latent of amortized generator StyleGAN2 through multiple latent optimization, latent optimization trajectory averaging, and unsupervised validation with a pseudo target. We demonstrate the efficacy and generalization of our method on widely used face datasets, accompanying it with extensive ablation studies and visually, qualitatively, and quantitatively analyses. The source code will be released.", "sections": [{"title": "1 Introduction", "content": "With the increasing deployment of face recognition systems in security-critical environments, threat actors are developing sophisticated attack strategies over various attack points, where one of the major threats is face reconstruction attacks [6-8,18,23,24]. The primary goal of face reconstruction attacks is to create fake biometric images that resemble genuine ones from the stored biometric templates which are then used to bypass the system. Previous works have mostly"}, {"title": "2.2 Out-of-Distribution Generalization", "content": "Generalization is one of the most important tasks in deep learning models especially when it comes to unseen OOD circumstances. Searching for flat minima is one of the main stems of research to achieve generalization where [21] establishes a strong connection between the flatness of the loss surface and generalization in deep neural networks. Weight averaging [3, 9, 13, 21, 22] ensembles the trajectories of non-linear function parameters during training to seek well generalized flat minima point. [9] gathers information from separately trained models, [13] stochastically averages a single model with cyclic learning rate, [3] aggregates from a dense trajectory, and [22] collects from several different training policies.\nOur task focuses on generalizing reconstructed face over unseen encoders, hence, we adopt the core principles from these works and adequately modify them for our work.\nPseudo label has been used for generalization tasks where label information is scarce such as domain adaptation [25, 28, 36]. They can be made by mixing both samples and labels [35], ensembling labels from augmented samples [1,"}, {"title": "3 Face Reconstruction Transfer Attack as OOD Generalization", "content": "We first clearly define the problem of FRTA, and we show that face reconstruction transfer attack is in fact an OOD generalization problem."}, {"title": "3.1 Problem Formalization", "content": "The FRTA can be formalized as an algorithm A that must return a solution vector A(@seen) = x* to the following optimization objective:\n$\\max_{x} \\min_{\\theta \\in \\Theta} sim(E_{\\theta}(x), v_{\\theta}),$ (1)\nwhere $v_{\\theta}$ indicates a true target $v_{\\theta} = E_{\\theta}(X_{real})$ corresponding to an encoder $E_{\\theta}$. The nature of FRTA poses a constraint that the attacker can access to the seen encoder $E_{\\theta_{seen}}$ only. The encoder parameter space $\\Theta$ includes both seen and unseen encoder networks exposed to attacks. Hence, the objective requires that the attack must be transferrable.\nOne approach to the attack is by using a face image generator G. By substituting x = G(z) in the above equation, one maximizes the objective in terms of z instead of x as:\n$\\max_{z} \\min_{\\theta \\in \\Theta} sim(E_{\\theta}(G(z)), v_{\\theta}).$"}, {"title": "3.2 FRTA As OOD Generalization", "content": "Given that both $E_{\\theta}$ and G are multi-layer perceptron instances, we show that the FRTA can be formulated as an OOD generalization problem. To this end, we first formalize the OOD generalization as follows:\nDefinition. OOD generalization on the domain D in the parameter space is to solve for an algorithm A that, given a seen dataset, returns a solution parameter A(Dseen) = 0* that minimizes\n$\\min_{\\Theta} \\max_{D} L(\\theta; D),$ (3)\nwhere L is a loss function defined as\n$L(\\theta; D) = \\frac{1}{|D|} \\sum_{(x, y) \\in D} l(f_{\\theta}(x), y).$"}, {"title": "3.3 Averaged Latent Search with Unsupervised Validation with Pseudo Target(ALSUV)", "content": "Inspired by the above interpretation, we tackle FRTA by means of OOD generalization techniques by defining the similarity as a loss function. Thereupon, we propose ALSUV with pseudo target, which is an integrated approach of OOD generalization on the latent.\nThe latent search mechanism of ALSUV are decomposed as follows: (1) multiple latent optimization, (2) latent averaging throughout optimization trajectories, and (3) unsupervised validation with the pseudo target.\nMultiple Latent Optimization In order to avoid the underminimization problem shown in Fig. 1b and to generate candidates for our following unsupervised validation method, we initialize multiple n latent vectors and optimize them in a parallel manner:\n$\\min_{{z_i}_{i=1}^n} L({z_i}; E_{seen}) = - \\sum_{i=1}^n sim(E_{seen}(G(z_i)), v_{seen})$ (6)\nwhere $E_{seen} = E_{\\theta_{seen}}, v_{seen} = v_{\\theta_{seen}}$. The given loss function is minimized by a gradient-based update using the standard optimizer such as Adam [15] or SGD. Fig. 3 validates that updating with multiple latents significantly improves the minimization of the loss. Moreover, we find that this simple multiple latent optimization can more effectively escape from poor local minima than iterating with complicated learning rate scheduler (Tab. 4).\nLatent Averaging Avoiding the poor underminimization issue alone is not sufficient for effective generalization of the attack under FRTA since the acquired solution may overfit to seen encoders as shown in Fig. 1c. To effectively improve the attack rate on the unseen encoders, we borrow the idea from OOD generalization [3,21,22] and apply averaging the solution latent vectors over the optimization trajectory:\n$z_i = \\frac{1}{T_o} \\sum_{t=T-T_o}^{T} z_i^{(t)}.$"}, {"title": "4 Experiments", "content": "The experiments section includes: 1) performance evaluation against existing methods; 2) comprehensive component ablation and hyperparameter variation to show effectiveness; 3) analysis of components by varying setups, comparing parallel latent optimization to serial optimization, visualizing loss surface effects with and without latent averaging, using different validation encoders for unsupervised validation, and assessing image quality visually and quantitatively."}, {"title": "4.1 Configuration", "content": "We use StyleGAN2 [14] trained with FFHQ-256 for the generative model, denoted as G(.), and latents are optimized in the W+ space. Both G(\u00b7) and target encoders $E_{seen} (\u00b7)$ are frozen while optimizing latents. We adopt Adam [15] optimizer with 100 steps where the learning rate starts from 0.1 and is divided by 10 at iteration 50. Our method involves three hyperparameters: n = 100, the number of latents; t = 70, length of trajectory for latent averaging; and $k_{top}$ = 10, the number of samples used for unsupervised validation. We use pytorch [20] for all experiments on a single Nvidia RTX 2080ti GPU."}, {"title": "4.2 Datasets and Networks", "content": "We use the LFW, CFP-FP, and AgeDB-30 datasets, three widely used verification datasets with distinct characteristics. For LFW and AgeDB-30, we compare"}, {"title": "4.3 Evaluation Metrics and Details", "content": "[18] introduces Type I and Type II SAR where Type I compares the generated face with the ground truth target, while Type II compares with different images from the same identity. SAR measures the ratio of generated samples passing the positive verification test where thresholds are specific to type of datasets and face encoders. Since Type I is relatively easy, we only report Type II performance"}, {"title": "4.4 Comparison with Previous Works", "content": "We compare our method with state-of-the-art feature-based face reconstruction methods including NBNet [18], LatentMap [6], Genetic [7], GaussBlob [23], Eigenface [24], FaceTI [27], and QEZOGE [19]. For FaceTI [27], we used Style-GAN2 and our face encoders for reproduction. As shown in Tab. 1 and Tab. 2, overall previous methods are effective on seen encoders, but the performance drastically drops on unseen encoders. EigenFace [24], FaceTI [27], and QE-ZOGE [19] show better performance compared with other works, however, tend to show lower performance compared with our method and the results highly fluctuates depending on the type of seen encoder. In contrast, our method outperforms for both seen and unseen cases. Our SAR and identification rate results are close to real face images on seen encoders while outperforming previous works with a large margin on unseen encoders for every dataset while depending less on the type of seen encoder. Additionally, results tested on unseen encoders shown in Tab. 1 and Tab. 2 present that our method achieves OOD generalization on unseen encoders successfully."}, {"title": "4.5 Analysis", "content": "Ablation of Components We analyze the effect of each component of our method on the overall performance. In Tab. 3, we present results for n ="}, {"title": "5 Conclusion", "content": "In this paper, we have presented a framework for face reconstruction transfer attacks. We devised our method inspired by out-of-distribution generalization to generalize our generated sample to unseen face encoders and propose ALSUV.\nALSUV is instantiated by combining multiple latent optimization, latent averaging, and unsupervised validation with the pseudo target. We demonstrate that our approach surpasses previous methods in FRTA by showing high SAR and identification rate across various unseen face encoders. Our thorough analysis shows the effectiveness of our method inspired by OOD generalization. Furthermore, we hope our work alerts the security risk posed by FRTA, and emphasizes the awareness to mitigate potential threats."}, {"title": "B Supplementary to Method", "content": null}, {"title": "B.1 Algorithm of the full method", "content": "The full algorithm of our method is given in Algorithm. 1. In this algorithm, [zi]=1 is the vector concatenation of the vectors zi, which is to parallelize the update of zi's.\nAlgorithm 1 The algorithm of our method\nRequire: {zi}i=1, Eoseen, G, Useen, \u03a4, \u03a4\u03bf, \u0395\u03b8\u03bd\u03b1\u03b9, Ktop\nEnsure: z*\n# Optimizing Multiple Latents\n1: Initialize zi0\n= zi for i = 1, ..., \u03b7\n2: for t = 1,..., T do\n3: \n [zi]=1 \u2190 [zi=1+\u2207\n# Latent Averaging\n5: zi \u03a3\u03a4-\u03a4\u03bf zt\n6: Order the index i of Zi such that sim (Eeen (G(+1)), Useen) < sim (Eeen (G()), Uesen)\n\u03a3 \u0395\u03b1(G())\nC Supplementary Results\nFig. 7 shows the result of reconstructed images from CFP-FP dataset of each baselines, our method and ground truth images.\nTab. 7 ablates pseudo target of unsupervised validation by using different types of target for searching the top 1 reconstructed sample. We compare SAR of 3 different cases: using the seen feature vector as target in the seen encoder space, using validation encoder and the pseudo target in the validation encoder space, and using the unseen encoder and the feature vector from real image in the unseen encoder space where the last works as a reference to upper bound performance."}]}