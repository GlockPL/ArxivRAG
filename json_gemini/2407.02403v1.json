{"title": "Face Reconstruction Transfer Attack as Out-of-Distribution Generalization", "authors": ["Yoon Gyo Jung", "Jaewoo Park", "Xingbo Dong", "Hojin Park", "Andrew Beng Jin Teoh", "Octavia Camps"], "abstract": "Understanding the vulnerability of face recognition systems to malicious attacks is of critical importance. Previous works have focused on reconstructing face images that can penetrate a targeted verification system. Even in the white-box scenario, however, naively reconstructed images misrepresent the identity information, hence the attacks are easily neutralized once the face system is updated or changed. In this paper, we aim to reconstruct face images which are capable of transferring face attacks on unseen encoders. We term this problem as Face Reconstruction Transfer Attack (FRTA) and show that it can be formulated as an out-of-distribution (OOD) generalization problem. Inspired by its OOD nature, we propose to solve FRTA by Averaged Latent Search and Unsupervised Validation with pseudo target (ALSUV). To strengthen the reconstruction attack on OOD unseen encoders, ALSUV reconstructs the face by searching the latent of amortized generator StyleGAN2 through multiple latent optimization, latent optimization trajectory averaging, and unsupervised validation with a pseudo target. We demonstrate the efficacy and generalization of our method on widely used face datasets, accompanying it with extensive ablation studies and visually, qualitatively, and quantitatively analyses. The source code will be released.", "sections": [{"title": "1 Introduction", "content": "With the increasing deployment of face recognition systems in security-critical environments, threat actors are developing sophisticated attack strategies over various attack points, where one of the major threats is face reconstruction attacks [6-8,18,23,24]. The primary goal of face reconstruction attacks is to create fake biometric images that resemble genuine ones from the stored biometric templates which are then used to bypass the system. Previous works have mostly"}, {"title": "2 Related Works", "content": "NBNet [18] first pioneered face reconstruction from the template by neighborly deconvolution, but the results are substandard for both quality and performance. [6] projects features into the latent space of a pre-trained StyleGAN2 [14]"}, {"title": "2.1 Face Reconstruction from Features", "content": "NBNet [18] first pioneered face reconstruction from the template by neighborly deconvolution, but the results are substandard for both quality and performance. [6] projects features into the latent space of a pre-trained StyleGAN2 [14] to generate fine-grained resembling images. The results are qualitatively decent, but often contain different identities as shown in Fig. 6. DiBiGAN [8] presents a generative framework based on bijective metric learning and pairs features with face images one-to-one. These methods offer fast sample generation after training but require extensive face datasets and time for training a new network. [23] samples varying random Gaussian blobs iteratively and combining the blobs as the shape of a face. It requires only a few queries and no prior knowledge such as dataset, but shows results with low quality. [24] reconstructs faces using similarity scores based on eigenface with soft symmetry constraints, generative regularization, and multi-start policy to avoid local minimas. However, the reconstructed images show severe noise as shown in Fig. 6. These works consume less time to generate few samples than training a new network but takes longer for large scale generations.\nMethods introduced above show promising results when tested with seen encoders, but performance drastically falls with unseen encoders. Recently, a couple of works [7, 19, 27] considered FRTA scenarios in their work. [7] suggests a genetic algorithm-based approach along with an attack pipeline to impersonate the target user. Reconstructed images are high quality, but evolutionary algorithms rely on random mutation and selection processes which might get trapped in local optima or fail to generalize well due to the limited exploration-exploitation trade-off inherent in their design. [19] suggests query efficient zeroth-order gradient estimation with top k initialization search followed by ensembling. This approach typically iteratively adjusts latent representations to minimize reconstruction errors but may suffer from overfitting to specific characteristics of the seen encoder. [27] trains a network which maps features to the W+ latent space of StyleGAN3 to learn the W+ distribution space based on a WGAN framework, however, the GAN frameworks are prone to mode collapse."}, {"title": "2.2 Out-of-Distribution Generalization", "content": "Generalization is one of the most important tasks in deep learning models especially when it comes to unseen OOD circumstances. Searching for flat minima is one of the main stems of research to achieve generalization where [21] establishes a strong connection between the flatness of the loss surface and generalization in deep neural networks. Weight averaging [3, 9, 13, 21, 22] ensembles the trajectories of non-linear function parameters during training to seek well generalized flat minima point. [9] gathers information from separately trained models, [13] stochastically averages a single model with cyclic learning rate, [3] aggregates from a dense trajectory, and [22] collects from several different training policies.\nOur task focuses on generalizing reconstructed face over unseen encoders, hence, we adopt the core principles from these works and adequately modify them for our work.\nPseudo label has been used for generalization tasks where label information is scarce such as domain adaptation [25, 28, 36]. They can be made by mixing both samples and labels [35], ensembling labels from augmented samples [1, 12], or confidence prediction with sliding window voting followed by confidence-based prediction [28]. The key components for pseudo labels are sufficiently high confidence [12,28] and adequate regularization to prevent over-confidence [36,37]. Our method requires selecting the best generalizing input(latent) in an unsupervised manner. Hence, we migrate the idea of previous works and discover how to find the proper pseudo target for our task."}, {"title": "3 Face Reconstruction Transfer Attack as OOD Generalization", "content": "We first clearly define the problem of FRTA, and we show that face reconstruction transfer attack is in fact an OOD generalization problem."}, {"title": "3.1 Problem Formalization", "content": "The FRTA can be formalized as an algorithm A that must return a solution vector $A(@_{seen}) = x^*$ to the following optimization objective:\n$\\max _{x} \\min _{\\theta \\in \\Theta} sim(E_{\\theta}(x), \\upsilon_{\\theta}),$                                                                              (1)\nwhere $\\upsilon_{\\theta}$ indicates a true target $\\upsilon_{\\theta} = E_{\\theta}(X_{real})$ corresponding to an encoder $E_{\\theta}$. The nature of FRTA poses a constraint that the attacker can access to the seen encoder $E_{\\theta seen}$ only. The encoder parameter space $\\Theta$ includes both seen and unseen encoder networks exposed to attacks. Hence, the objective requires that the attack must be transferrable.\nOne approach to the attack is by using a face image generator G. By substituting $x = G(z)$ in the above equation, one maximizes the objective in terms of z instead of x as:\n$\\max _{z} \\min _{\\theta \\in \\Theta} sim(E_{\\theta}(G(z)), \\upsilon_{\\theta}).$                                                                                 (2)"}, {"title": "3.2 FRTA As OOD Generalization", "content": "Given that both $E_{\\theta}$ and G are multi-layer perceptron instances, we show that the FRTA can be formulated as an OOD generalization problem. To this end, we first formalize the OOD generalization as follows:\nDefinition. OOD generalization on the domain D in the parameter space is to solve for an algorithm A that, given a seen dataset, returns a solution parameter $A(D_{seen}) = \\theta^*$ that minimizes\n$\\min _{A} \\max _{D \\in D} L(\\theta; D),$                                                                                                                                                                                 (3)\nwhere L is a loss function defined as\n$L(\\theta; D) = \\frac{1}{|D|} \\sum _{(x, y) \\in D} l(f_{\\theta}(x), y).$                                                                                                                                           (4)"}, {"title": "3.3 Averaged Latent Search with Unsupervised Validation with Pseudo Target(ALSUV)", "content": "Inspired by the above interpretation, we tackle FRTA by means of OOD generalization techniques by defining the similarity as a loss function. Thereupon, we propose ALSUV with pseudo target, which is an integrated approach of OOD generalization on the latent.\nThe latent search mechanism of ALSUV are decomposed as follows: (1) multiple latent optimization, (2) latent averaging throughout optimization trajectories, and (3) unsupervised validation with the pseudo target.\nMultiple Latent Optimization In order to avoid the underminimization problem shown in Fig. 1b and to generate candidates for our following unsupervised validation method, we initialize multiple n latent vectors and optimize them in a parallel manner:\n$\\min _{\\left[z_{i}\\right]_{i=1}^{n}} \\sum_{i=1}^{n} L(z_{i}; E_{seen}) = - \\sum_{i=1}^{n} sim(E_{seen} (G(z_{i})), U_{seen})$                                                        (6)\nwhere $E_{seen} = E_{\\theta seen}, U_{seen} = U_{\\theta seen}$. The given loss function is minimized by a gradient-based update using the standard optimizer such as Adam [15] or SGD. Fig. 3 validates that updating with multiple latents significantly improves the minimization of the loss. Moreover, we find that this simple multiple latent optimization can more effectively escape from poor local minima than iterating with complicated learning rate scheduler (Tab. 4).\nLatent Averaging Avoiding the poor underminimization issue alone is not sufficient for effective generalization of the attack under FRTA since the acquired solution may overfit to seen encoders as shown in Fig. 1c. To effectively improve the attack rate on the unseen encoders, we borrow the idea from OOD generalization [3,21,22] and apply averaging the solution latent vectors over the optimization trajectory:\n$\\overline{z_{i}} = \\frac{1}{T_{o}} \\sum_{t=T-T_{o}}^{T} z_{i}^{(t)}$                                                                                                                                                                                    (7)"}, {"title": "4 Experiments", "content": "The experiments section includes: 1) performance evaluation against existing methods; 2) comprehensive component ablation and hyperparameter variation to show effectiveness; 3) analysis of components by varying setups, comparing parallel latent optimization to serial optimization, visualizing loss surface effects with and without latent averaging, using different validation encoders for unsupervised validation, and assessing image quality visually and quantitatively."}, {"title": "4.1 Configuration", "content": "We use StyleGAN2 [14] trained with FFHQ-256 for the generative model, denoted as G(.), and latents are optimized in the W+ space. Both G(\u00b7) and target encoders $E_{seen} (\\cdot)$ are frozen while optimizing latents. We adopt Adam [15] optimizer with 100 steps where the learning rate starts from 0.1 and is divided by 10 at iteration 50. Our method involves three hyperparameters: n = 100, the number of latents; t = 70, length of trajectory for latent averaging; and $k_{top}$ = 10, the number of samples used for unsupervised validation. We use pytorch [20] for all experiments on a single Nvidia RTX 2080ti GPU."}, {"title": "4.2 Datasets and Networks", "content": "We use the LFW, CFP-FP, and AgeDB-30 datasets, three widely used verification datasets with distinct characteristics. For LFW and AgeDB-30, we compare"}, {"title": "4.3 Evaluation Metrics and Details", "content": "[18] introduces Type I and Type II SAR where Type I compares the generated face with the ground truth target, while Type II compares with different images from the same identity. SAR measures the ratio of generated samples passing the positive verification test where thresholds are specific to type of datasets and face encoders. Since Type I is relatively easy, we only report Type II performance"}, {"title": "4.4 Comparison with Previous Works", "content": "We compare our method with state-of-the-art feature-based face reconstruction methods including NBNet [18], LatentMap [6], Genetic [7], GaussBlob [23], Eigenface [24], FaceTI [27], and QEZOGE [19]. For FaceTI [27], we used Style-GAN2 and our face encoders for reproduction. As shown in Tab. 1 and Tab. 2, overall previous methods are effective on seen encoders, but the performance drastically drops on unseen encoders. EigenFace [24], FaceTI [27], and QEZOGE [19] show better performance compared with other works, however, tend to show lower performance compared with our method and the results highly fluctuates depending on the type of seen encoder. In contrast, our method outperforms for both seen and unseen cases. Our SAR and identification rate results are close to real face images on seen encoders while outperforming previous works with a large margin on unseen encoders for every dataset while depending less on the type of seen encoder. Additionally, results tested on unseen encoders shown in Tab. 1 and Tab. 2 present that our method achieves OOD generalization on unseen encoders successfully."}, {"title": "4.5 Analysis", "content": "Ablation of Components We analyze the effect of each component of our method on the overall performance. In Tab. 3, we present results for n ="}, {"title": "5 Conclusion", "content": "In this paper, we have presented a framework for face reconstruction transfer attacks. We devised our method inspired by out-of-distribution generalization to generalize our generated sample to unseen face encoders and propose ALSUV.\nALSUV is instantiated by combining multiple latent optimization, latent averaging, and unsupervised validation with the pseudo target. We demonstrate that our approach surpasses previous methods in FRTA by showing high SAR and identification rate across various unseen face encoders. Our thorough analysis shows the effectiveness of our method inspired by OOD generalization. Furthermore, we hope our work alerts the security risk posed by FRTA, and emphasizes the awareness to mitigate potential threats."}, {"title": "A Proof to Theorem", "content": "Theorem. Define fz by fz(\u03b8) = $E_{\u03b8}(G(z))$, and let $D_{seen}^* = \\{(\u03b8_{seen}, U_{\u03b8seen})\\}$, $D^* = \\{\\{(\u03b8,\u03c5_{\u03b8})\\} : \u03b8 \u2208 \u0398\\}$, and\n$l(f_{z}(\u03b8), \u03c5_{\u03b8}) = -sim(f_{z}(\u03b8), \u03c5_{\u03b8}).$ (10)\nThen, $f_{z}$ is an MLP, and the FRTA algorithm A on is an OOD generalization algorithm $A^*$ on the domain $D^*$ in the parameter space Z.\nProof. (MLP) Since MLP is a composition of MLPs, it suffices to prove that a layer of $f_{z}$ is MLP. To this end, we show that the MLP $\u03c3(Wx + b)$ with input x and parameters (W, b) is an MLP with input (W, b) and parameters x. Let $w_{i}$ and $b_{i}$ denote the i-th row of W and b, respectively, for $i = 1, ...,r$ where r is the row dimension of W. Observe,\n$\u03c3(Wx + b) = \u03c3 (diag(x)w_{i} + b_{i}1)$ (11)\nwhere diag(x) is the diagonal matrix whose diagonal elements are $x_{i}$, and 1 is a vector whose all entries are 1. Both\n$f_{1}((W, b); x) = diag(x)w_{i}$ (12)\nand\n$f_{2}((W, b); x) = b_{i}1$ (13)\nare MLPs with input (W, b) and parameters x, hence their sum and activattion are also MLPs with the same aspect, completing the proof.\n(Equivalence) We show the equivalence between FRTA and OOD generalization. To see this, first define\n$L(z; D^*) := \\frac{1}{|D^*|} \\sum_{(\u03b8,\u03c5_{\u03b8}) \u2208 D^*} l(f_{z}(\u03b8), \u03c5_{\u03b8})$ (14)\nThen, observe that\n$A^*(D_{seen}) := \\min _{z} \\max _{D^* \u2208 D^*} L(z; D^*)$\n$= \\min _{z} \\max _{\u03b8 \u2208 D^*} l(f_{z}(\u03b8), \u03c5_{\u03b8})$\n$= \\min _{z} \\max _{\u03b8 \u2208 D^*} -sim(f_{z}(\u03b8), \u03c5_{\u03b8})$\n$= \\max _{z} \\min _{\u03b8 \u2208 \u03b8} sim(f_{z}(\u03b8), \u03c5_{\u03b8})$\n=: $A(@_{seen})$\nwhere the second and fourth equations hold due to $D^* = \\{\\{(\u03b8, \u03c5_{\u03b8})\\}\\}$, completing the proof."}, {"title": "B Supplementary to Method", "content": "B.1\nAlgorithm of the full method\nThe full algorithm of our method is given in Algorithm. 1. In this algorithm, $[z_{i}]_{i=1}^{n}$ is the vector concatenation of the vectors $z_{i}$, which is to parallelize the update of $z_{i}$'s."}, {"title": "C Supplementary Results", "content": "Fig. 7 shows the result of reconstructed images from CFP-FP dataset of each baselines, our method and ground truth images.\nTab. 7 ablates pseudo target of unsupervised validation by using different types of target for searching the top 1 reconstructed sample. We compare SAR of 3 different cases: using the seen feature vector as target in the seen encoder space, using validation encoder and the pseudo target in the validation encoder space, and using the unseen encoder and the feature vector from real image in the unseen encoder space where the last works as a reference to upper bound performance."}]}