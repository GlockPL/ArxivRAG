{"title": "Heterophilic Graph Neural Networks Optimization with Causal Message-passing", "authors": ["Botao Wang", "Jia Li", "Heng Chang", "Keli Zhang", "Fugee Tsung"], "abstract": "In this work, we discover that causal inference provides a promis- ing approach to capture heterophilic message-passing in Graph Neural Network (GNN). By leveraging cause-effect analysis, we can discern heterophilic edges based on asymmetric node depen- dency. The learned causal structure offers more accurate relation- ships among nodes. To reduce the computational complexity, we introduce intervention-based causal inference in graph learning. We first simplify causal analysis on graphs by formulating it as a structural learning model and define the optimization problem within the Bayesian scheme. We then present an analysis of de- composing the optimization target into a consistency penalty and a structure modification based on cause-effect relations. We then estimate this target by conditional entropy and present insights into how conditional entropy quantifies the heterophily. Accord- ingly, we propose CausalMP, a causal message-passing discovery network for heterophilic graph learning, that iteratively learns the explicit causal structure of input graphs. We conduct extensive experiments in both heterophilic and homophilic graph settings. The result demonstrates that the our model achieves superior link prediction performance. Training on causal structure can also en- hance node representation in classification task across different base models.", "sections": [{"title": "1 INTRODUCTION", "content": "The message-passing mechanism of graph neural network (GNN) inherently assumes homophily, which degrades in the heterophilic graphs. Heterophily refers to the characteristic of graphs whose edges are more likely to connect the nodes from different classes. In such graphs, the representations of node pairs become less dis- tinguishable after being smoothed by their neighborhood features. This issue becomes particularly pronounced when there is lack in the node label information, such as link prediction task and few-shot node classification. The heterophilic edges can also act as the noise that hinder the optimization. Numerous studies have been proposed to improve message passing, aiming to learn more fair representations that are not affected by the heterophilic edges. They are usually dedicated to disentangling heterophilic informa- tion [1, 5, 36] or improving the information gathering process in the graph [12, 33, 40, 42]. However, these techniques are task- specific with low generalization ability. We also find most fail to demonstrate substantial performance improvements across both homophilic and heterophilic graphs.\nCausal inference emerges as a promising approach for capturing the cause-effect among variables according to the distribution of observed data. While self-training is a widely used and straight- forward strategy for relationship discovery [4, 32], it focuses on strengthening correlations, which is inadequate for complex and heterophilic graphs. Causal inference can detect dependencies at a higher level [6, 39]. It can be utilized to identify heterophilic edges, which exhibit asymmetric dependencies between connected node pairs. To illustrate the concept, we consider a camouflaged fraudster detection case, as depicted in Fig.1. The nodes consist of"}, {"title": "2 PRELIMINARIES", "content": "do-operator for causal inference. In causal inference, the do- operator is usually applied to evaluate the cause-effect relation. It represents interventions conducted on variables to assess their causal effects. By applying interventions, we can quantify the im- pact of intervened variables by observing the resulting variations in the distribution of other variables. We use P(X2|do(X1)) to describe the probability density of X1 \u2192 X2, which quantifies the effect on X2 resulting from X1. do-operator can be calculated by conditional probability in some scenarios. If there are three variables X1, X2, X3 and we wish to use the individual treatment effect (ITE) to quantify the effect of X1 on X2, we can apply the do-operator as:\n$\\displaystyle P(X_2|do(X_1)) = \\sum_{X_3} P(X_2|X_1, X_3)P(X_3).$ (1)\nIf X\u2081 is binary treatment, then the ITE is calculated by:\nITE(X1 \u2192 X2) = P(X2|do(X1 = 1)) - P(X2|do(X\u2081 = 0)). (2)\nIn the multivariable situations, Xi, i = 1, 2, ... can represent vari- able groups. Then the structural equation model (SEM) can be employed for causal analysis. In SEM, the relationships among variables are depicted using directed edges in a graphical model denoted as M(X, Ac), where X represents the variables and Ac represents the causal graph in the form of an adjacency matrix. The model M typically starts from either a fully connected graph or an initialization based on prior knowledge graph, whose adja- cency matrix denoted by A. Various algorithms, such as PC, FCI, etc., have been proposed to search for subgraphs that are faithful to the true causal graph Ac. Subsequently, conditional independence tests are conducted on the observed data to maximize the averaged treatment effect (ATE) after pruning.\n$\\displaystyle ATE = E_{(i,j)\\in A} [ITE(X_i \\rightarrow X_j)].$ (3)\nEstimation of causality. Intervention-based methods in structural equation modeling (SEM) exhibit superior performance in indepen- dence tests for uncovering causal relationships. However, these methods also demand greater computational resources. One such intervention-based analysis involves estimating the joint causal distribution of variables [22] and maximizing their likelihood [28]."}, {"title": "3 CAUSAL INFERENCE ON HETEROPHILY", "content": "The edges in the graph serve as indicators of association among the nodes. They can be treated as prior knowledge or skeletons for causal analysis. By optimizing the graph structure to align with the causal structure, we detect the heterophily and enhance the information-gathering of GNNs. This, in turn, aids GNNs in developing a better understanding of the node relationships during link prediction."}, {"title": "3.1 Information aggregation in GNN", "content": "In this Section, we start by forming the causal inference of the node dependency problem in GNNs. We present the assumptions regarding the properties of causality in the context of GNNs. Given a graph G(X, A) with N nodes, the features on each node Xi \u2208 RD, i \u2208 [N] are considered as a group of variables. The adjacency matrix A \u2208 RN\u00d7N is the initialization of causal structure. A graph convolution layer can be denoted by:\n$\\displaystyle X = AGG(A, X) = \\sigma(WAX + b) \\triangleq \\sigma (\\Gamma X + b),$ (6)\nwhere AGG() is the aggregation function, W, b are the weight matrix and bias vector of the GNN layer, \u03c3(\u00b7) is the activation function, and \u0393 is the connection coefficient matrix of the layer. \u0393 refers to a quantification of the cause-effect, where \u0393jk = 0 if Xk \u2209 PaAc (Xj), where PaAc (\u00b7) is the parents set of the given node in adjacency matrix Ac.\nLocal Markov property is a commonly applied assumption in the causal structure learning [23]. It enables the implied conditional independencies being read off from a given causal structure [10]. While, enumerate all the conditions in GNN is NP-hard problem. Thus, we focus on the most primary cause-effect relationships in"}, {"title": "3.2 Estimation of Intervention-based causality", "content": "In the Bayesian framework, the optimization involves maximizing the margin likelihood as Eq.(5). We aim to learn the parameter of the causal structure \u03b8. The posterior of the final causal structure Ac and its parameters are denoted by \u03b8c are P(Ac|X) \u221d P(Ac)P(X|Ac) and P(\u03b8c|X, Ac) \u221d P(\u03b8c|Ac)P(X|\u03b8c, Ac). They can be estimated by P(A|X), P(\u03b8c|X, A) respectively after initialization. To approximate the optimization, we conduct Bayesian experimental design (BED) [30] to model the node dependency in the form of entropy. Then utilize Monte Carlo estimator [30] for the do-intervention to quan- tify the point-wise causal relationship. The optimization problem is formalized as the following proposition.\nProposition 3.2. Given the intervention strategy I \u2208 I, if we have the condition distribution P(X\u22121, A|X), P(A|X), the causal structure Ac and corresponding optimal intervention target x1 can be obtained"}, {"title": "3.3 Insight into heterophily", "content": "We construct a criterion for heterophilic links based on dependency estimated by their conditional entropy. Additionally, we provide insight into how conditional entropy quantifies heterophily. As a first step, we assume that the connections between node pairs are label-dependent. The expectation of a node xi connecting to a heterophilic neighbor is given by the Rayleigh quotient of the label, where the expected value is denoted as E[P+] = 1 \u2212 Rh [13].\nIf we adopt a GNN as a node embedding model f, it learns the conditional probability distribution that relates each node to the context xNxi, where the neighbors can be divided into homophilic ones and heterophilic ones according to their labels Ni = N+, N\u2212.\nThen the conditional entropy is described as:\nH(N\u00a1\u00af |xi) + H(xi|N\u00a1\u00af ) = H(xi, Ni+, N\u00a1\u02dc\u00af) \u2013 H(N\u2021\u2020\u2021|xi) \u2013 I(xi, N\u00a1\u00af) (12)\nIn heterophilic graphs, the lower bound of mutual information be- tween heterophilic node pairs is negatively correlated with P+ [20]. This suggests that a heterophilic link refers to less mutual informa- tion, specifically a smaller I(xi, N\u00a1\u00af). Furthermore, the joint entropy H(xi, N, N\u2081) and the conditional entropy on the homophilic pair H(N+|xi) remain the same due to the static embedding model. Then, the conditional entropy on the left-hand side of the equation becomes larger."}, {"title": "4 PROPOSED MODEL", "content": "Based on the analysis in the previous section, we present the CausalMP to tackle the heterophily in graphs on the link prediction task. The main architecture is shown in Fig.3."}, {"title": "4.1 Main modules", "content": "1. Intervention on graph data. To learn the dependency among the nodes from the observational data, we employ a node feature intervention approach, where Gaussian noise rescales the node features X. rcN nodes are rescaled by Gaussian noise, where rc is ratio of intervened nodes. According to the [24], it is sufficient to identify the causal connections under the noise intervention. The graph after the intervention is denoted by G\u2081 (\u00dd, A), where X is the intervened feature matrix.\n2. Embedding learning. To identify node dependencies and cap- ture causal-effect relationships, we conduct an independence test on the distribution of observational data following the intervention. To mitigate sensitivity to downstream task correlations, we employ an unsupervised GNN denoted as f : G \u2192 B \u2208 RN\u00d7Demb, where Demb represents the dimension of the node embedding. Unsuper- vised learning enables the representations to capture the underlying causality among the nodes instead of correlation with the output.\n3. Node dependency estimation and causal structure mod- ification. We perform M intervention experiments on the original graph. The trained embedding network f maps the intervened graphs {G1 [m]}, m\u2208 [M] to the embedding space {B\u2081 [m]}. Uti- lizing these M discrete observations, we can quantify the depen- dency between the center nodes (i.e., intervened nodes) and their neighbors, which is calculated by Eq.(11). In the Monte Carlo ex- periment, we discretize the embeddings into bins and use kernel density estimation (KDE) to estimate the joint probability density function (PDF). By leveraging the KDE estimates, we compute the conditional entropy between the node pairs.\nFor each edge, we obtain a corresponding dependency score SH(i, j), where a larger value implies a more prominent causal- effect relationship. For a detected dependency Xi \u2192 Xj, we convert the original undirected edge (i, j) to directed by setting A(j, i) to 0. The threshold for pruning is \u03bcH+\u03bb\u2081\u03c3H. Here, \u03bb\u2081 is a coefficient, \u03bc\u0397 =\nEi\u2208I,j\u2208N(i) [SH(i, j)],\u1f29 = Vari\u2208I,j\u2208N(i) [8H(i, j)] are mean and variance of the dependency scores.\nSimilarly, we can examine the presence of triangular relation- ships within the graph. We calculate the mutual information (MI)"}, {"title": "4.2 CausalMP", "content": "In graph data, intervention I is applied to a subset of nodes. Addi- tionally, the pruning strategy during node dependency estimation is a greedy approach. To address these limitations, we introduce iterations in the intervention experiments. It ensures that the se- lected center nodes and their neighbors encompass a significant portion of the nodes in the graph, then more node dependencies can be detected. A detailed algorithm of the proposed CausalMP is shown in Algorithm 1."}, {"title": "4.3 Complexity analysis", "content": "Consider a graph with N = |V| nodes and |E| edges. During the in- tervention, the number of center nodes K is proportional to the node"}, {"title": "5 EXPERIMENT", "content": null}, {"title": "5.1 Experiment setup", "content": "To evaluate the improvement over GNNs on message-pathing, we conduct a comparative analysis on link prediction task. We adopt 85%/5%/10% split for training, validation, and testing. The negative link sampling capacity is the same as the positive ones. CausalMP is compared to popular baselines and SOTA models, including GAT [29], VGAE [11], Graph-InfoClust (GIC) [19] and Linkless Link Pre- diction (LLP) [9]. We also compare CausalMP with two additional models specifically designed for heterophilic graphs, namely LINKX [14] and DisenLink [41], as well as another causality-based model, Counterfactual Link Prediction (CFLP)[39].\nFor the obtained explicit causal structure, we compared it with original graph in node classification. To amplify the contribution of structural information, we adopt the limited label setting as [26]. Specifically, we used C-way 5-shot for small graphs and 100-shot for large graphs. We conduct the comparison on baselines models, i.e. GCN, GAT, and SOTA models for heterophilic graphs, i.e. LINKX, and GREET [17]. As graph prompt learning also shows superiority in few-shot heterophilic node classification setting, we also apply the causal structure to GPPT [25] and Gprompt [27].\nWe conduct experiments on 9 commonly used graph datasets, encompassing 4 homophilic graphs and 5 heterophilic graphs. For the implementation of CausalMP, we utilize CCA-SSG [38] with default setting as the unsupervised embedding learning network. The encoder of the CausalMP is the same size as the embedding"}, {"title": "5.2 Result", "content": "The results of link prediction are summarized in Table 1, where the bolded and underlined entries represent the best and second-best performance, respectively. The term \"OoM\" refers to out-of-memory issues of the device. Our observations are as follows: (a) The preva- lent models and SOTA link prediction models (GIC, LLP) generally exhibit satisfactory and stable performance on homophilic graphs. However, they are unable to perform well and stably on heterophilic graphs. (b) Models specifically designed for heterophily (LINKX, DisenLink) sacrifice their superiority on homophilic graphs, indi- cating a trade-off in performance depending on the graph type. (c) CFLP demonstrates the applicability of causal analysis in het- erophilic scenarios. However, it suffers from computational com- plexity. (d) The proposed CausalMP exhibits stable performance and outperforms the benchmarks on both homophilic and heterophilic graphs. Notably, it remains applicable even on large graphs (CS, Physics), showcasing its scalability.\nThe results of node classification with causal structure are pre- sented in Table 2. It demonstrates that the models perform better when trained with the causal structure, both for homophilic and heterophilic graphs. It indicates that the improved message-passing facilitated by the causal structure improves node representation learning by GNNs. To provide insight into the node classification experiment, we vary the number of shots and the performance of the GCN is shown in Fig.4, which demonstrate that the learned causal structure contributes more when there is less available node information."}, {"title": "5.2.1 Coefficients of the loss function.", "content": "In order to assess the impact of the coefficients a and \u03b2 in the optimization target, we conducted an ablation experiment, where we modified the loss function as:\n$\\displaystyle L = (1 - \\alpha) L_{recon} (A) + \\alpha L_{recon} (A_c) + \\beta L_{cons}$ (13)"}, {"title": "5.3 Ablation Experiment", "content": "Center node ratio. In CausalMP, the sampling ratio of center node rc \u2208 (0, 1] is an important parameter in the intervention strategy. We investigate its impact on two heterophilic graphs (Actor, Cor- nell) with rc \u2208 [0,0.5]. We report the results of the performance and corresponding time consumption in Table 3. Our findings in- dicate that when the iteration number is fixed, larger values of rc lead to increased time consumption, particularly on larger graphs. Excessively large values of re can result in a more dramatic modifi- cation of the structural information and performance degradation. Conversely, when re is too small, there are not sufficient node de- pendencies uncovered to improve the message-passing. To strike a balance, we experientially select rc from [0.02, 0.1].\nOptimization target weight. We first tune a through grid search in [0, 0.25, 0.5, 0.75, 1] with result shown in Fig.5. We discov- ered that assigning a too-large weight to either the original graph or the causal graph is not beneficial for training. Optimal performance is achieved when there is a balance between the two components. Similarly, the impact of \u03b2 is evaluated in Fig.6. We observe that as \u03b2 starts to increase from 0, the performance of CausalMP improves. This demonstrates the effectiveness of the consistency term. How- ever, if \u03b2 keeps increasing, the performance starts to degrade. This is because an excessively large weight on the consistency term can interfere with the optimization of the reconstruction loss. While, CausalMP can achieve a stable and satisfying performance as long as extreme values of a, \u03b2 are avoided. Thus, we set them as constant across different datasets.\nEdge modification strategy. We conducted a comparative anal-"}, {"title": "6 RELATED WORK", "content": "Heterophilic graph learning. Plenty of GNNs have been pro- posed to tackle the heterophilic graph. The prevalent models in- volved in improving the information gathering, such as MixHop [1] and GPR-GNN[5]. LINKX [14] learns node feature and adja- cency information separately, then concatenates them for final prediction, trained through simple minibatching. GOAT [12] adap- tive learns the relationship from virtually fully-connected nodes.\nAnother promising approach is to improve the message-passing [33, 40, 42]. GReTo [42] performs signed message passing by lo- cal context and target information. GOAL [40] enriches the struc- tural information by graph complementation to homophily- and heterophily-prone topology. ACMP [33] construct message passing by interacting particle dynamics with a neural ODE solver imple- mented.\nCausal inference. Traditional statistical causal inference can be categorized into score-based, constraint-based methods, and hybrid methods [22]. It has primarily been gaining interest in the context of graph classification tasks to guide GNN training [2, 8, 34], where they focus on identifying invariant substructures rather than dependency analysis. Causal inference is also applied to explanation tasks in GNN [15, 16]. [39] estimates a counterfactual adjacency matrix of the original graph to enrich the link information and improve the GNN learning. [3] defines the context information as the treatment and conducts augmentation on knowledge graph to improve representation learning and interpretability. [6] propose a different definition of causality, namely causal lifting, and conduct the graph learning on the knowledge graph."}, {"title": "7 CONCLUSION", "content": "In this study, we propose CausalMP, a novel scheme with causal in- ference embedded, devised to deal with heterophilic graph learning by GNNs. We conduct a theoretical analysis of intervention-based causality in GNN. We formulate an optimization problem by es- timating cause-effect relationships through conditional entropy and we propose an indicator to locate heterophily. CausalMP itera- tively transfers the detected dependencies into directed edges and add edges based on mutual information, optimizing GNNs under constrastive scheme. Through extensive experiments on both ho- mophilic and heterophilic graphs, we demonstrate that CausalMP achieves superior link prediction performance than other baselines. And the learned causal structure contributes to node classifications especially in limited label situation.\nIn the future, we plan to explore the inclusion of 2-hop condi- tions in causal analysis, striking a balance between computational complexity and accuracy. Furthermore, we intend to leverage the learned causal structure for explanation tasks."}, {"title": "A DETAILS ON EXPERIMENT", "content": "We conduct experiments on 9 commonly used graph datasets, en- compassing 4 homophilic graphs, i.e. Cora, CiteSeer, CS, Physics, and 5 heterophilic graphs, i.e. Actor, Cornell, Texas, Chameleon, and Squirrel. The dataset statistics are shown in Table 5."}]}