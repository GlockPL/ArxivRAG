{"title": "Uncertainty separation via ensemble quantile regression", "authors": ["Navid Ansari", "Hans-Peter Seidel", "Vahid Babaei"], "abstract": "This paper introduces a novel and scalable framework for uncertainty estimation and separation with applications in data driven modeling in science and engineering tasks where reliable uncertainty quantification is critical. Leveraging an ensemble of quantile regression (E-QR) models, our approach enhances aleatoric uncertainty estimation while preserving the quality of epistemic uncertainty, surpassing competing methods, such as Deep Ensembles (DE) and Monte Carlo (MC) dropout. To address challenges in separating uncertainty types, we propose an algorithm that iteratively improves separation through progressive sampling in regions of high uncertainty. Our framework is scalable to large datasets and demonstrates superior performance on synthetic benchmarks, offering a robust tool for uncertainty quantification in data-driven applications.", "sections": [{"title": "1 Introduction", "content": "In recent years, uncertainty estimation has become an essential aspect of machine learning, especially for applications that demand high reliability in decision-making, such as autonomous driving (Kendall and Gal 2017), and medical diagnosis (Lambrou, Papadopoulos, and Gammerman 2010; Yang et al. 2009). Accurate uncertainty estimation not only supports better model interpretability but also helps identify areas where models are likely to make errors, ensuring safety in high-stakes environments.\nUncertainty in machine learning is typically categorized into two types: aleatoric uncertainty, which originates from inherent noise or variability in the data, and epistemic uncertainty, which stems from limitations in the model's knowledge and can potentially be reduced with additional data (H\u00fcllermeier and Waegeman 2021). Separating these two types of uncertainty is essential in applications like Bayesian optimization (Frazier 2018; Hern\u00e1ndez-Lobato et al. 2017; Shahriari et al. 2015; Ansari et al. 2023), inverse design (Wijaya et al. 2024; Ansari et al. 2022), and active learning (Ren et al. 2021; Settles 2009; Kirsch, Van Amersfoort, and Gal 2019; Gal, Islam, and Ghahramani 2017), where understanding the nature of uncertainty influences strategic decisions.\nFor instance, in Bayesian optimization (BO) (Frazier 2018; Hern\u00e1ndez-Lobato et al. 2017; Shahriari et al. 2015;"}, {"title": "2 Related work and background", "content": "Uncertainty estimation in machine learning, particularly in deep learning models, has gained significant attention due to its importance in reliable decision-making. Separating epistemic and aleatoric uncertainty is critical in many applications. Deep Ensembles (DE), introduced by Lakshminarayanan, Pritzel, and Blundell (2017), provides uncertainty estimates by averaging predictions from independently trained neural networks. While DE can estimate both epistemic and aleatoric uncertainty, it sometimes fails to separate them effectively.\nMonte Carlo (MC) dropout approximates Bayesian neural networks by applying dropout during training and inference (Gal and Ghahramani 2016b).\nQuantile regression has emerged as a promising approach for uncertainty estimation, predicting the upper and lower quantiles of the target distribution instead of point estimates (Koenker and Bassett 1978). To ensemble such models, Fakoor et al. (2023) proposed a paradigm focused on aleatoric uncertainty capture but did not address epistemic uncertainty separation. Tagasovska and Lopez-Paz (2018) leveraged quantile regression ensembles to model epistemic uncertainty in high-dimensional spaces, while Hoel, Wolff, and Laine (2023) applied it to reinforcement learning in autonomous driving, demonstrating robustness in safety-critical scenarios. Additionally, Mallick, Balaprakash, and Macfarlane (2022) showcased its scalability and accuracy in separating uncertainties in spatiotemporal problems.\nDE and Ensemble Quantile Regression (E-QR) are superior to MC dropout for epistemic uncertainty estimation, as both train independent models with varying parameters, unlike MC dropout, which uses stochastic variations of a single model (Gal and Ghahramani 2016a; Lakshminarayanan, Pritzel, and Blundell 2016; Koenker and Hallock 2001).\nWhile DE uses sub-networks trained with Negative Log Likelihood (NLL) loss to model aleatoric uncertainty, E-QR leverages pinball loss to predict quantiles (Romano, Patterson, and Candes 2019).\nE-QR is simpler and more stable to train than DE. Pinball loss is less sensitive to initialization and learning rate compared to NLL loss, which is prone to gradient instabilities and overfitting on small datasets (Moustakides and Basioti 2019; Streit and Luginbuhl 1994). DE requires a two-step process-optimizing primary predictions (\u03bc) followed by training uncertainty (\u03c3) heads with NLL loss-doubling its computational effort compared to E-QR, which learns quantile predictions in a single step (Zhang 2020; Ansari"}, {"title": "3 Methodology", "content": "In Section 3.2, we discuss the shortcomings of scalable Bayesian Neural Networks (BNNs) in uncertainty separation and demonstrate how Algorithm 1 can be used to achieve robust uncertainty separation."}, {"title": "3.1 Challenges in uncertainty separation", "content": "Leakage of aleatoric uncertainty into epistemic uncertainty\nAlthough epistemic uncertainty is intended to capture only uncertainty due to limited knowledge, in practice, it may inadvertently include aleatoric uncertainty when data is insufficient. This occurs because each subnetwork in an ensemble model is trained on a subsample of the data. If these subsamples are too small, subnetworks may overfit to their specific data rather than generalizing between data points, as expected with an L2 loss function. As a result, aleatoric uncertainty can \"leak\" into the epistemic uncertainty estimates. This phenomenon is common in both Deep Ensembles and Ensemble Quantile Regression methods.\nLeakage of epistemic uncertainty in aleatoric uncertainty.\nAll models studied here rely on fitting mechanisms to model aleatoric uncertainty. DE uses the Negative Log Likelihood (NLL) loss, while E-QR employs the pinball loss to fit upper and lower quantiles. As a result, the accuracy of these predictions depends heavily on the availability of high-quality and sufficient data. In regions with high epistemic uncertainty, the fit of aleatoric uncertainty estimates can become arbitrarily. This issue is exacerbated by the use of bagging in sub-networks, where only a subsample of data is visible to models attempting to learn aleatoric uncertainty.\nKnowing that the root cause of both problems is the lack of data, we propose a progressive sampling strategy in the next section. This strategy focuses on regions where uncertainty is detected, but the type of uncertainty (aleatoric or"}, {"title": "3.2 Reliable separation of epistemic and aleatoric uncertainty", "content": "To reliably separate aleatoric and epistemic uncertainties, we first identify regions where uncertainty is suspected and create a comprehensive uncertainty map by normalizing and combining all available uncertainty maps. In cases with multiple outputs, we focus on the common regions across each output's uncertainty map, as these shared uncertainties are more likely to originate from the data rather than local misfitings specific to individual outputs.\nOnce this common uncertainty map is established, we gather additional data in the uncertain regions and retrain the models. Iteratively repeating this process diminishes regions of epistemic uncertainty while areas of aleatoric uncertainty remain unchanged. By performing a logical XOR operation between the final uncertainty map and the initial one, we can isolate the initial epistemic uncertainty present in our initial dataset. Algorithm 1 presents the complete procedure."}, {"title": "4 Evaluation", "content": null}, {"title": "4.1 Experiment setup", "content": "Toy In this experiment, we aim to fit the function\n$Y_1 = \\sin\\left(\\sqrt{x_1^2 + x_2^2}\\right), Y_2 = \\cos\\left(\\sqrt{x_1^2 + x_2^2}\\right) + \\cos(x_2)$\nWe introduce 4 specific regions in the input space two on the top lacking data, and two on the bottom polluted with irreducible random noise modeled as N(0,0.3) (Figure 3).\nMulti-joint robot In this problem, a robotic arm with four rotatable joints and an adjustable base position on the wall (x \u2208 R5) is considered. The goal is to predict the final 2D position of the arm's tip (y \u2208 R2) given its joint angles (Ardizzone et al. 2019). To evaluate uncertainty separation, we conduct an experiment where the behavior of one joint is excluded from the dataset to test whether our model can recover the missing information and determine the type of uncertainty."}, {"title": "4.2 Aleatoric uncertainty leak into epistemic uncertainty prediction", "content": "Figure 3 illustrates the aleatoric and epistemic uncertainty calculated by the E-QR model for both outputs for the toy"}, {"title": "4.3 Epistemic uncertainty leak into aleatoric uncertainty prediction", "content": "In Figure 4, the robotic arm is not augmented with aleatoric noise; however, the behavior of one joint is excluded from the dataset over a range of angles. This setup induces epistemic uncertainty, as the model lacks information about the excluded range. While we expect the model to predict only epistemic uncertainty, the figure shows a leakage of epistemic uncertainty into the aleatoric uncertainty predictions.\nAlgorithm 1 addresses this issue, identifying the uncertainty as epistemic after four iterations. By adding data to the uncertain regions, the uncertainty is completely resolved, confirming that it was indeed epistemic."}, {"title": "5 Conclusion", "content": "This work introduces a novel framework for uncertainty separation using Ensemble Quantile Regression (E-QR), addressing the challenges of uncertainty leakage that lead"}]}