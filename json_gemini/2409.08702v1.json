{"title": "DM: Dual-path Magnitude Network for General Speech Restoration", "authors": ["Da-Hee Yang", "Dail Kim", "Joon-Hyuk Chang", "Jeonghwan Choi", "Han-gil Moon"], "abstract": "In this paper, we introduce a novel general speech restoration model: the Dual-path Magnitude (DM) network, designed to address multiple distortions including noise, reverberation, and bandwidth degradation effectively. The DM network employs dual parallel magnitude decoders that share parameters: one uses a masking-based algorithm for distortion removal and the other employs a mapping-based approach for speech restoration. A novel aspect of the DM network is the integration of the magnitude spectrogram output from the masking decoder into the mapping decoder through a skip connection, enhancing the overall restoration capability. This integrated approach overcomes the inherent limitations observed in previous models, as detailed in a step-by-step analysis. The experimental results demonstrate that the DM network outperforms other baseline models in the comprehensive aspect of general speech restoration, achieving substantial restoration with fewer parameters.", "sections": [{"title": "I. INTRODUCTION", "content": "In real-life environments, speech signals are often affected by various distortions, thereby necessitating research aimed at mitigating these effects and enhancing speech quality and intelligibility. Considerable research has been conducted to address speech enhancement and generation, with a focus on removing background noise and reverberation and generating missing parts of speech signals. However, most studies have focused on scenarios involving a single type of distortion, such as denoising [1]\u2013[3], dereverberation [4]\u2013[6], and bandwidth extension (BWE) [7], [8]. Nevertheless, speech degradation factors often occur simultaneously in practical scenarios, which presents a challenging task that cannot be addressed by networks designed for single-distortion scenarios.\nGeneral speech restoration approaches have emerged to address multiple distortions in recent years [9]-[11]. However, although abundant research has been conducted on handling single distortion, systems that can address multiple distortions (common occurrences in real-world scenarios) remain scarce, highlighting a significant gap in the field. The challenge of addressing multiple distortions within a single network arises from differences in the desired learning methods and model architectures. Whereas noise and reverberation target a suppression approach, bandwidth degradation requires a synthesis-focused approach. Distinct treatment strategies for suppression and generation result in inherent limitations that prevent a single network from effectively performing both tasks concurrently. To bridge this gap, we conducted a thorough step-wise analysis to understand the inherent limitations that prevent a single network from performing enhancement and generation tasks simultaneously. This investigation led to the development of an integrated approach for addressing general speech restoration.\nIn this paper, we propose a novel general speech restoration model that enables the enhancement and generation processes. The novel dual-path magnitude (DM) network, based on the MP-SENet framework [12], is specifically designed to address multiple distortions by employing two parallel magnitude decoders for simultaneous removal and synthesis. One decoder focuses on distortion removal using a masking-based algorithm, whereas the other performs the restoration task using a mapping-based algorithm with parameter sharing. In addition, we incorporate the output magnitude spectrogram of the masking-based algorithm into the output of the mapping-based algorithm through a skip connection to capture the characteristics of the restoration module more effectively. The main contribution of this study lies in the introduction of a unified model that is informed by step-by-step procedures and findings, thereby enabling both speech enhancement and generation. Detailed insights into the development of this module are presented in Section II. Our experiments demonstrate significantly improved performance efficiency in general speech distortion environments, with the model achieving enhanced results using significantly fewer parameters."}, {"title": "II. MODELING DESCRIPTION", "content": "In this paper, we address three distortions: noise, reverberation, and bandwidth degradation. Denoising and dereverberation algorithms primarily focus on removal, which is more effective than generation [13], whereas BWE aims to estimate the missing high-frequency components from a generation perspective. In this section, we describe the unified model for enhancement and generation and explain the process that leads to the architecture of the proposed network."}, {"title": "A. General speech restoration: DM network", "content": "Generating missing high-frequency signals while removing background noise and reverberations for general speech restoration is difficult with a single-distortion network. We introduce the DM network with a modified architecture based on the MP-SENet framework [12]. Figure 1 (S1) presents a schematic of the MP-SENet architecture. This model includes an encoder, two-stage convolution-augmented Transformers (TS-Conformers), and decoder blocks. MP-SENet processes the magnitude and wrapped phase spectra of the input speech signal using the short-time Fourier transform (STFT) transform. Initially, the encoder encodes the magnitude and phase spectra into a compressed time-frequency domain representation. Subsequently, this representation is processed by four TS-Conformers, which sequentially enhance the time and frequency correlations. Thereafter, parallel decoders for the magnitude mask and phase predict the clean magnitude and phase spectra, respectively. These spectra are used to reconstruct the enhanced waveform through inverse STFT. Further details on the encoder, TS-conformer, masking-based magnitude decoder, phase decoder, and training method are described in [12], [14].\nWe employ two parallel magnitude decoders for general speech restoration. Specifically, the DM network comprises three decoders: a masking-based magnitude decoder, a mapping-based magnitude decoder, and a phase decoder, as shown in Figure 1. The magnitude decoders share the same structure and parameters but utilize different activation functions: learnable sigmoid and ReLU, respectively. Furthermore, we propose a novel approach in which the output of the masking-based decoder is used as a skip connection to enhance the output of the mapping-based decoder. The learnable parameter a is applied to determine the ratio of the skip connection. This strategy is designed to mitigate the limitation of not being able to use input features directly in the output through skip connections when the input signal is distorted. The outputs of the two parallel magnitude decoders are combined with a weight value w. Figure 1 depicts the step-by-step process through which the DM network architecture is constructed."}, {"title": "B. Development process", "content": "Generating missing high-frequency components while simultaneously removing background noise and reverberation poses a challenge for single-distortion networks in general speech restoration. Therefore, we first analyze the characteristics of single-distortion networks and design models that provide both enhancement and generation. Subsequently, we apply a new approach to the unified model to address its limitations. The networks outlined in the following are used for general speech restoration.\n1) Problem formulation: We address the problem of speech restoration in environments that are compromised by noise, reverberation, and bandwidth degradation. The simulated input speech is $y = h(x * r) + n$, where $x$ represents the original speech signal, $n$ denotes background noise, and $r$ is the room impulse response that simulates reverberation, which is convolved with $x$ through the convolution operation represented by $*$. The function $h$ introduces spectral distortions through low-pass filtering effects. Our objective is to develop a novel network that can effectively transform this complex noisy speech input into a restored output speech signal.\n2) Single networks (S1 and S2):\n\u2022 S1 (masking-based network)\nThe S1 model consists of a magnitude decoder that estimates noise masks for suppression, along with a phase decoder, as shown in Figure 1 (S1). This structure is directly adapted from the MP-SENet architecture introduced by [12] for general speech restoration. We find that this network is effective in noise and reverberation removal; however, it largely fails to reconstruct the bandwidth.\n\u2022 S2 (mapping-based network)\nThe S2 model was proposed in [14] for the BWE task. Similar to S1, it comprises magnitude and phase decoders. However, unlike S1 which estimates the mask,"}, {"title": "III. EXPERIMENTS", "content": "We considered noise, reverberation, and bandwidth degradation at a sampling rate of 16 kHz to generate distorted speech. For noise distortion, we mixed the VCTK corpus [16] consisting of 28 English speakers with the DEMAND noise dataset in a signal-to-noise ratio range of 0 - 20 dB. The reverberant signal was generated by convolving the speech signal with a simulated room impulse response using a Pyroomacoustics engine. The dimensions of the reverberant room ranged from 5 to 10 m in length and width and 2 to 6 m in height, with the reverberation times (RT60) ranging from 0.3 to 0.9 seconds. For non-echoic speech, the target dry room had a fixed absorption coefficient of 0.99. The bandwidth degradation signal was generated using various types of low-pass filters (e.g. Butterworth, Bessel, Chebyshev, and elliptic) with randomly selected cut-off frequencies between 2 and 4 kHz. We selected \"p258\" and \"p287\" speakers from the training set for the validation set.\nWe trained all the networks in Figure 1 for 1M steps. The outputs of two parallel magnitude decoders were combined with a $w = 0.5$ weight value. In addition, we adopted $w = 0$ for the DM2 model, in which the masking-based decoder output was used through a skip connection. All models in Figure 1 were trained using the AdamW optimizer [17] with a learning rate of 0.0005.\nB. Evaluation metrics\nWe evaluated the speech restoration performance using various assessment metrics. For comprehensive assessments of speech performance, we analyzed the speech signal distortion,"}, {"title": "D. Ablation Study", "content": "The single network S1 model exhibited excellent performance in terms of noise removal. Consequently, the PESQ and CBAK scores were high. However, as shown in Figure 2, bandwidth restoration was not achieved in S1. We observed that the mask estimation network excelled in background noise and reverberation removal, but failed in bandwidth generation. This suggests that the high PESQ and CBAK scores reflect the limitations of these metrics in accurately measuring overall speech quality, as they do not account for the failure in bandwidth restoration. S2 was designed for BWE tasks. However, as shown in Table 1, all scores, including the LSD representing the BWE performance, were subpar. This can be attributed to the skip connection architecture, which we found to be ineffective in general speech restoration. Based on the above results, we demonstrated the challenge of performing both enhancement and generation tasks using a single network. Therefore, we adopted a unified network by integrating a masking-based decoder that excels in noise and reverberation removal with a mapping-based decoder that can perform both tasks concurrently.\nThe unified model U1 achieved satisfactory performance in terms of the PESQ and CBAK scores, representing noise removal. However, bandwidth generation hardly occurred, leading to significantly worse LSD and CSIG scores, indicating the degree of speech distortion. Thus, we discovered that simply connecting two decoders in parallel did not effectively address general speech distortions. This issue arose because the two magnitude decoders were trained separately; therefore, we implemented a strategy in which the magnitude decoders shared parameters. We demonstrated that sharing parameters between two magnitude decoders significantly improved the noise and reverberation removal as well as bandwidth generation, thereby mitigating the aforementioned issues. Furthermore, we applied the learnable skip connection structure to DM1, resulting in DM2, which exhibited improved bandwidth restoration and enhanced performance in terms of speech quality and intelligibility. During inference, the learnable parameter value was set at 0.3827. From a general speech restoration perspective, the DM network demonstrated generally better performance compared to baseline models, capable of noise and reverberation removal as well as bandwidth generation."}, {"title": "IV. CONCLUSION", "content": "In this paper, we propose the DM network, a general speech restoration model that integrates two parallel magnitude decoders: distortion removal and speech restoration. Through a detailed analysis, we identified the limitations of existing models and guided the design of our integrated approach. Despite the simplicity of its concept, the DM network outperforms both the predictive model HD-DEMUCS and the generative model SGMSE+ in handling complex distortions, demonstrating its potential as a benchmark for general speech restoration tasks. The DM network addresses multiple speech distortions simultaneously, offering substantial enhancements over single-distortion networks and previous restoration methods, thereby providing robust solutions in challenging environments. This highlights the practical and experimental significance of our model, especially considering the limited development of models that effectively manage complex distortions in speech."}]}