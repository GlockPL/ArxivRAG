{"title": "A Lightweight Human Pose Estimation Approach for Edge\nComputing-Enabled Metaverse with Compressive Sensing", "authors": ["Nguyen Quang Hieu", "Dinh Thai Hoang", "Diep N. Nguyen"], "abstract": "The ability to estimate 3D movements of users over\nedge computing-enabled networks, such as 5G/6G networks, is\na key enabler for the new era of extended reality (XR) and\nMetaverse applications. Recent advancements in deep learn-\ning have shown advantages over optimization techniques for\nestimating 3D human poses given spare measurements from\nsensor signals, i.e., inertial measurement unit (IMU) sensors\nattached to the XR devices. However, the existing works lack\napplicability to wireless systems, where transmitting the IMU\nsignals over noisy wireless networks poses significant challenges.\nFurthermore, the potential redundancy of the IMU signals has\nnot been considered, resulting in highly redundant transmissions.\nIn this work, we propose a novel approach for redundancy\nremoval and lightweight transmission of IMU signals over noisy\nwireless environments. Our approach utilizes a random Gaussian\nmatrix to transform the original signal into a lower-dimensional\nspace. By leveraging the compressive sensing theory, we have\nproved that the designed Gaussian matrix can project the signal\ninto a lower-dimensional space and preserve the Set-Restricted\nEigenvalue condition, subject to a power transmission constraint.\nFurthermore, we develop a deep generative model at the receiver\nto recover the original IMU signals from noisy compressed data,\nthus enabling the creation of 3D human body movements at the\nreceiver for XR and Metaverse applications. Simulation results on\na real-world IMU dataset show that our framework can achieve\nhighly accurate 3D human poses of the user using only 82% of\nthe measurements from the original signals. This is comparable\nto an optimization-based approach, i.e., Lasso, but is an order\nof magnitude faster.\nIndex Terms-Compressive sensing, inertial measurement unit,\nedge computing, extended reality, metaverse, wireless networks.", "sections": [{"title": "I. INTRODUCTION", "content": "The past few years witnessed an ever-increasing demand\nfor virtual reality (VR) and augmented reality (AR) appli-\ncations over mobile networks (5G networks and upcoming\n6G networks). Following active academic research of VR/AR\ntechnologies [1], industrial leading organizations, such as\n3GPP groups, have shown early steps in incorporating VR/AR\ninto the next network generations, thus enhancing extended\nreality (XR) capabilities for Metaverse applications [2]. The\n3D nature of these XR and Metaverse applications brings\nnew challenges to network design in which conventional\napproaches are not sufficient. Such new challenges are field-\nof-view transmissions for 360-degree videos/images [3], the\ncapacity overhead of uplink transmission [4], and motion\nsickness of changing scene resolution [5], to name a few.\nIn these challenges, one of the most recognized patterns is\nchanging user body movements, e.g., changing head orienta-\ntion, acceleration, and height, which results in sudden updates\nin the virtual 3D environment. The service provider, e.g., an\nedge computing server, has to quickly adapt to, or predict\nthe changes of the user, and then update the user's QoE\naccordingly, e.g., updating the field-of-view's position [3],\nresolution [5], or allocating more physical resources to that\nframes within the new field-of-view [2].\nThe approaches in [2]-[5], and in the references therein,\nusually focus on the head orientation of the user, which is\nsimilar to conventional mobile phone user when changing the\nphone's direction/orientation can degrade the received signal\nstrength. However, in emerging Metaverse services over wire-\nless networks, such as real-time gaming and virtual interactive\nevents, having only head orientation is not enough. In such\nservices, having the full 3D movements of users is usually\nmuch more valuable [1]. However, estimating the 3D body\nmovements of users is a much more challenging task, given\nnoisy wireless environments and existing hardware VR/AR\ndevices' constraints. The literature works on estimating 3D\nhuman movements, or 3D human poses, suggest that lever-\naging calibrated camera systems gives the best performance,\ni.e., estimation accuracy. However, these camera systems\nare limited to indoor scenarios and are prone to lightning\nconditions. Furthermore, capturing user activities via camera\nusually reveals vulnerable privacy issues, especially when\nthese captured images/videos are transmitted via wireless\nnetworks. Thus, camera-based approaches are not sufficient for\nscalable solutions of 3D human pose estimation over wireless\nMetaverse systems.\nFortunately, recent approaches leverage another source of\ninformation from the built-in hardware devices within almost\nevery VR/AR user device, which is the inertial measure-\nment unit (IMU) sensor. The IMU sensors, which include\naccelerometers, gyroscopes, and magnetometers, are integrated\ninto devices such as VR/AR headsets and joystick controllers\nto measure their orientation, acceleration, altitude, and angular\nvelocity. More complex IMU systems may have a higher\nnumber of IMU sensors attached, for example, on a body\nsuite [6]. The literature works in [6]\u2013[9] suggest that the entire\n3D body movement can be accurately constructed with sparse\nmeasurements from IMU sensors, ranging from 3 to 17 sen-\nsors. These approaches can be divided into two categories that\nare (i) optimization-based approach [6], [7] and (ii) learning-\nbased approaches [8], [9]. Optimization approaches apply\nKalman Filter [6] or exponential mapping [7] to approximate\nthe 3D poses of a given human kinematic body model [10].\nUnlike optimization approaches, learning-based approaches\ncan achieve real-time estimation based on pre-trained deep"}, {"title": "A. Compressive Sensing", "content": "After having a fixed sequence of n (n > 0) data points\nabout the acceleration and orientation of all IMU sensors, we\nhave a finite original signal $x^* \\in \\mathbb{R}^n$ (illustrated as five multi-\ncolor squares within the transmitter in Fig. 1). The original\nvector is then down-sampled by a linear projection with the\nmeasurement matrix $A \\in \\mathbb{R}^{m\\times n}$, where $m$ is the number\nof measurements, or the length of the down-sampled vector,\n$y = Ax^*$. After that, the vector $y$ will be transmitted to the\nreceiver over a wireless channel. Assuming a Gaussian channel\nwith additive white noise, the received signal is $\\hat{y} = Ax^* +\\eta$,\nwhere $\\eta \\in \\mathbb{R}^m$ is the Gaussian noise vector with zero mean\nand $\\sigma_{\\eta}$ standard deviation, i.e., element $\\eta_i (i = 1, 2, ..., m)$\nof $\\eta$ follows a Normal distribution $\\eta_i \\sim \\mathcal{N}(0, \\sigma_{\\eta}^2)$. Despite the\nsimplicity of the channel model, the white Gaussian channel\nhas general properties that can be extended to other compli-\ncated channels, e.g., fading channels. In order to reconstruct\nthe original signal $x^*$ from the noisy measurement $\\hat{y}$, the\nreceiver needs to solve the following optimization problem:\n$P_0$: $\\min_x ||x||_1$,\n(1)\nsubject to $\\|Ax - \\hat{y}\\|_2 \\leq \\|\\eta\\|_2$,\nwhere the notation $\\|\\times\\|_p$ denotes the $l_p$ norm ($p = 0, 1, 2, ...$)\nof the vector $x$, i.e.,\n$\\left( \\sum_{j=1}^{n} |x_j|^p \\right)^{1/p}$.\n(2)\nThe objective of $P_0$ is to find the valid vector $x$ that\nminimizes the sum of the absolute value of the elements\n$x_j (j = 1,2,...,n)$, i.e., $\\|x\\|_1 = \\sum_{j=1}^{n} |x_j|$, subject to a\nreconstruction error constraint. Intuitively, minimizing the sum\n$\\|x\\|_1$ encourages the vector $x$ to be \"sparse\" to satisfy the\nreconstruction error constraint. In particular, the problem $P_0$"}, {"title": "B. Compressive sensing with Generative Models", "content": "Generative modeling is a class of machine learning that\ninvolves the process of modeling the underlying distribution\ngiven some input dataset. In particular, given some datasets\n$\\mathcal{D} = \\{x_i\\}_{i=1}^N$, where each data point $x_i \\in \\mathbb{R}^n$ is usually a $n$-dimensional vector. Generative modeling learns the generative\nprobability (or the forward probability) distribution $P(\\mathcal{D}|\\theta)$\nthat approximates the true data distribution $P(\\mathcal{D})$, given some\nmodel's parameters $\\theta$ (e.g., a vector, or a matrix, or a deep\nneural network). In this work, we are interested in a class\nof generative model that is the variational-autoencoder (VAE)\n[15] and use it as our model for approximating the underlying\ndistribution of the IMU signals taken from a real-world dataset\n[8]. Note that the selection of a generative model is flexible to\nour later algorithm, for example, GANs or generative diffusion\nmodels can also be used. The main reason for us to use the\nVAE is its simplicity in training, evaluating the variational\nlower bound (which will be discussed later), and generating\nmore dispersed samples over the training data. To train the\nVAE, we optimize a variational lower bound on the log-\nlikelihood, i.e.,\n$\\mathcal{L}(x|\\theta; \\phi) = \\sum Q(z|x; \\phi) \\log \\frac{P(x|z; \\theta)P(z)}{Q(z|x; \\phi)}$,\n(5)\nwhere $\\theta$ is the parameters of the VAE's decoder (i.e., the\ngenerative model), $\\phi$ is the parameters of the VAE's encoder\n(i.e., the inference model), $z$ is the latent vector, $Q(z|x; \\phi)$\nis the variational posterior, and $P(z)$ is the prior. The added\nparameters $z$ and $Q(z|x; \\phi)$ are for the variational modeling\nof the input data, where the prior $P(z)$ is usually assumed\nto follow a simple distribution, e.g., a multivariate Gaussian\ndistribution.\nAs sampling from the posterior is straightforward in VAE\ndue to the choice of latent prior (e.g., Gaussian), the VAE\nmodel can be trained with unbiased Monte Carlo estimate of\n$\\mathcal{L}$ in (5) using a gradient decent optimizer, e.g., SGD or Adam,\nresulting in the unbiased estimation of $\\mathcal{L}$ [15]:\n$\\widehat{\\mathcal{L}}(x | \\theta; \\phi) = \\log \\frac{P(x|z; \\theta)P(z)}{Q(z/x; \\phi)}$,\n(6)\nwhere $P(x|z; \\theta)$ can be calculated based on the output of\nthe VAE's decoder via an activation function, e.g., a Sigmoid\nfunction, and $Q(z|x; \\phi)$ can be effectively approximated via a\nreparameterization trick [15]. Once the variational lower bound\nis optimized, we can approximate the true probability density\nfunction $P(\\mathcal{D})$ of the dataset, i.e., $P(\\mathcal{D}|\\theta) \\approx P(\\mathcal{D})$.\nIn the context of compressing sensing, we do not have the\nfull observation of the data points $x_i$ [12]. In particular, in our\nconsidered setting, the receiver has access to the compressed\nand noisy observation $\\hat{y} = Ax^* +\\eta$, where the original vector\nis $x^* = x_i \\in \\mathcal{D}$. Replacing $x$ with $y = Ax$, the estimation of\nthe variational lower bound in (6) can be rewritten as:\n$\\widehat{\\mathcal{L}}(y|\\theta; \\phi) = \\log \\frac{P(Ax | z; \\theta) P(z)}{Q(z | Ax; \\phi)}$\n(7)\nAs we now approximate the probability distribution of the\nsignals via the generative model, we need to define the range\nof the output generator function, i.e., $\\mathcal{S}_G = \\{G(z) : z \\in \\mathbb{R}^k\\}$.\nThe reconstructed signals' range is now transformed into the\nlatent space $z \\in \\mathbb{R}^k (k < n)$. This means that the measurement\nmatrix $A$'s properties are no longer sufficient to guarantee the\naccuracy of the reconstructed signals. Thus, with generative\nmodel-based compressive sensing, we now require $A$ to satisfy\nthe Set-Restricted Eigenvalue Condition (S-REC), which is\na more comprehensive version of REC [11]. The S-REC\nproperty is defined as follows.\nDefinition 2 (Set-Restricted Eigenvalue Condition). Let $\\mathcal{S} \\subseteq \\mathbb{R}^n$, for some parameters $\\gamma > 0$ and $\\kappa \\geq 0$, a matrix $A \\in \\mathbb{R}^{m \\times n}$ is said to satisfy the S-REC($\\mathcal{S}, \\gamma, \\kappa$) if $\\forall x_1, x_2 \\in \\mathcal{S}$,\n$\\left\\|A(x_1 - x_2)\\right\\|_2 \\geq \\gamma \\left\\|x_1 - x_2\\right\\|_2 - \\kappa$.\nThe S-REC property enables training the VAE as the op-\ntimization solver for the compressive sensing problems while"}, {"title": "III. PROBLEM FORMULATION AND PROPOSED SOLUTION", "content": "With the introduced generative model-based compressive\nsensing method, which was first explored in [11], we aim to\ndevelop a practical framework for the reconstruction of 3D\nhuman pose over wireless channels. Recall that the presence\nof the wireless channel poses significant challenges to the\nconventional 3D human pose reconstruction methods, and\nthe conventional generative model-based compressive sensing\napproaches, e.g., [11] and [14], cannot be straightforwardly\napplied. In particular, the measurement matrices used in [11],\n[14] cannot guarantee the system constraints, i.e., transmission\npower constraint per channel use. Designing the measurement\nmatrix $A$ at the transmitter to ensure both S-REC property\nand power transmission is a challenging task that has not been\nconsidered in the literature. As we will discuss later, existing\nworks that overlook the presence of additive channel noise or\nutilize simple and intuitive power normalization schemes, such\nas $l_2$ normalization, may fail in reconstructing 3D human poses\nat the receiver. Before going into further analysis, let us define\nthe considered problem with the aforementioned constraints:\n$P_2$: $\\min_z \\| A G(z) - \\hat{y}\\|_2$,\nsubject to $\\frac{1}{m} \\|y\\|_2 \\leq P_T$,\n(8)\n$\\left\\|G(z) \\right\\|_1 \\leq \\nu$,\nwhere $G(z)$ is the generator function, i.e., the output of the\nVAE's decoder given the latent vector $z$, $P_T$ is the power\nconstraint of the transmitter per channel use, and $\\nu \\geq 0$ is\nthe $l_1$ constraint of the generator function (similar to in the\noriginal dimension of $x$ in equations (1) and (4)).\nAs seen in problem $P_2$ from (8), the power constraint (8b)\nsets an upper limit on the transmitted signal $y = Ax$, while\nalso requiring the lower bound of the S-REC property in\nDefinition 2. To the best of our knowledge, this is the first work\nthat investigates how to design a measurement matrix that\nsatisfies this duo constraint. To address this problem, we first\npropose a novel measurement matrix $A$ in Proposition 1 which\nensures that $y = Ax$ satisfies the power constraint (8b). Once\nthe power constraint is established, we use the Lagrangian of\n$P_2$ as a loss function to train the VAE model similar to the\napproach in [11], [14]. The proposed measurement matrix for\nproblem $P_2$ is as follows.\nProposition 1 (S-REC with power constraint). The recovered\nsignal obtained by the generative model-based compressive\nsensing method under the power constraint $P_T$ is guaranteed\nto be a unique solution if (i) $A$ satisfies S-REC property, and\n(ii) each element $A_{ij}$ (element $j$-th of the $i$-th row) of $A$ is\ndrawn i.i.d from a Gaussian distribution with zero mean and\nvariance $\\sigma^2 = \\frac{P_T}{n^2 m} (d \\sigma_x + \\mu_x)^2$, i.e.,\n$A_{ij} \\sim \\mathcal{N} \\left(0, \\frac{P_T}{n^2 m} (d \\sigma_x + \\mu_x)^2 \\right)$,\nwhere $\\sigma_x^2$ and $\\mu_x$ are the statistical variance and mean values\nof the source signals $x \\in \\mathbb{R}^n$, respectively, and $d > 0$ is a\nreal number derived from the Chebyshev's inequality."}, {"title": "IV. PERFORMANCE EVALUATION", "content": "1) Dataset and Simulation Settings: In this section, we\nvalidate our proposed CS-VAE framework on the real-world\ndataset of IMU signals, named DIP-IMU dataset [8]. The DIP-\nIMU dataset contains 330,178 IMU data frames from 17 IMU\nsensors placed on the human participants. The sampling rate\nof the IMU sensors is 60 frames per second. The participants\nin the experiments are asked to perform various actions,\ncategorized into different action classes, e.g., locomotion,\nfreestyle, upper body, and lower body movements. Detailed of\nthe action classes and corresponding number of data frames\ncan be found in [8]. After removing abnormal data points (i.e.,\ndata points with NaN values), we have the training set and test\nset containing 220,760 and 56,990 data frames, respectively.\nWe normalize the training set and test set within the range\n(-1, 1). Each data frame in the dataset, denoted by $x_t$ has 204\nfeatures of acceleration and orientation of the 17 IMU sensors,\ni.e., $x_t \\in \\mathbb{R}^{204}$. We train the VAE model for 50 epochs with\nbatch size 60. We use Adam optimizer with a learning rate of\n$10^{-4}$ to train the VAE model. The $l_1$ penalty in (9) is $10^{-5}$.\nWe evaluate the proposed CS-VAE framework and compare\nit with two baselines that are (i) Lasso (Lease absolute"}, {"title": "V. CONCLUSION", "content": "In this paper, we have developed a novel generative model-\nbased compressive sensing framework for the reconstruction\nof 3D human poses from sparse IMU measurements. The\nproposed measurement matrix design enabled the generative\nmodel, i.e., a variational auto-encoder, to recover the original\nIMU signals from compressed and noisy received signals.\nThe principle idea of this work is designing the measurement\nmatrix that ensures the power constraint of the transmitter over\nan additive white Gaussian noise channel and also guarantees\nthe S-REC property in compressive sensing. Simulation results\non the real-world dataset DIP-IMU have shown the best\nperformance of the proposed framework, compared with other\nbaselines. From the recovered signals at the receiver, we have\nshown that it is possible to recover the full 3D human body\nposes mimicking the movements of the user. This paves the\nway for a wide variety of Metaverse applications in which esti-\nmating the 3D body movements of the user plays an important\nrole. Potential approaches extending from this work could be\nextending our matrix design to more complicated channels,\nsuch as fading channels, or multiple-access scenarios."}]}