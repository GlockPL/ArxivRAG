{"title": "GraphFSA: A Finite State Automaton Framework for Algorithmic Learning on Graphs", "authors": ["Florian Gr\u00f6tschla\u00aa", "Jo\u00ebl Mathysa", "Christoffer Rauna", "Roger Wattenhofera"], "abstract": "Many graph algorithms can be viewed as sets of rules that are iteratively applied, with the number of iterations dependent on the size and complexity of the input graph. Existing machine learning architectures often struggle to represent these algorithmic framework: GraphFSA (Graph Finite State Automaton). GraphFSA\nis designed to learn a finite state automaton that runs on each node of a given graph. We test GraphFSA on cellular automata problems, showcasing its abilities in a straightforward algorithmic setting. For a comprehensive empirical evaluation of our framework, we create a diverse range of synthetic problems. As our main application, we then focus on learning more elaborate graph algorithms. Our findings suggest that GraphFSA exhibits strong generalization and extrapolation abilities, presenting an alternative approach to represent these algorithms.", "sections": [{"title": "1 Introduction", "content": "While machine learning has made tremendous progress, machines still have trouble generalizing concepts and extrapolating to unseen inputs. Large language models can write spectacular poems about traffic lights, but they still fail at multiplying two large numbers.\nThey do not quite understand the multiplication algorithm since they do not have a good representation of algorithms. We want to teach machines some level of \"algorithmic thinking.\" Given some unknown process, can the machine distill what is going on and then apply the same algorithm in another situation? This paper concentrates on one of the simplest processes: finite state automata (FSA). An FSA is a basic automaton that jumps from one state to\nanother according to a recipe. FSAs are the simplest, interesting version of an algorithm. However, if we assemble many FSAs in a network, the result is remarkably powerful regarding computation. Indeed, the simple Game of Life is already Turing-complete.\nBuilding on the work of Grattarola et al. [6] and Marr and H\u00fctt [17], this paper presents GraphFSA (Graph Finite State Automaton),\na novel framework designed to learn a finite state automata on graphs. GraphFSA extracts interpretable solutions and provides a framework\nto extrapolate to bigger graphs, effectively addressing the inherent challenges associated with conventional methods. To better under- stand the capabilities of GraphFSA, we evaluate the framework on\nvarious cellular automata problems. In this controllable setting, we can test the model's abilities to extrapolate and verify that GraphFSA"}, {"title": "2 Related work", "content": "Finite state automaton. A Finite State Automaton (FSA), also\nknown as a Finite State Machine (FSM), is a computational model used to describe the behavior of systems that operates on a finite\nnumber of states. It consists of a set of states, a set of transitions be- tween these states triggered by input symbols from a finite alphabet,\nand an initial state. FSAs are widely employed in various fields, in- cluding computer science, linguistics, and electrical engineering, for\ntasks such as pattern recognition [16], parsing, and protocol specifi- cation due to their simplicity and versatility in modeling sequential\nprocesses. Additionaly, there is a growing interest in combining FSA with neural networks to enhance performance and generalization, a\nnotion supported by studies by de Balle Pigem [1] on learning FSAs. Additional research by Mordvintsev [18] shows how a differentiable\nFSA can be learned.\nCellular automaton. Cellular Automata (CA) are discrete compu- tational models introduced by John von Neumann in 1967 von Neu-\nmann and Burks [29]. They consist of a grid of cells, where each cell is in a discrete state and evolves following transition rules based on\nthe states of neighboring cells. In our context, learning these tran- sition functions from data and modeling the appropriate domain is"}, {"title": "3 The GraphFSA framework", "content": "We present GraphFSA, a computational framework designed for exe- cuting Finite State Automata (FSA) on graph-structured data. Draw- ing inspiration from Graph Cellular Automata and Graph Neural Net-\nworks, GraphFSA defines an FSA at each node within the graph. This FSA remains the same across all nodes and encompasses a pre-\ndetermined set of states and transition values. While all nodes abide by the rules of the same automaton, the nodes are usually in dif-\nferent states. As is customary for FSAs, a transition value and the current state jointly determine the subsequent state transition. In our\napproach, transition values are computed through the aggregation of neighboring node states. As the FSA can only handle a finite num-\nber of possible aggregations, we impose according limitations on the aggregation function. For the execution of the framework, nodes are"}, {"title": "3.1 Formal definition", "content": "More formally, the GraphFSA F consists of a tuple (M, Z, A, T).\nF is applied to a graph G = (V, E) and consists of a set of states M,\nan aggregation A and a transition function T. At time t, each node\nv \u2208 V is in state sv,t \u2208 M. In its most general form, the aggregation\nA maps the multiset of neighboring states to an aggregated value\na \u2208 Z of a finite domain.\n\n$\\qquad a_{v,t} = A({{\\mathcal{S}_{u,t} | u \\in N(v)}})$\n\nHere {{}} denotes the multiset and N(v) the neighbors of v in G.\nAt each timestep t, the transition function T: M \u00d7 Z \u2192 M takes\nthe state of a node sv,t and its corresponding aggregated value av,t\nand computes the state for the next timestep.\n\n$\\qquad \\mathcal{S}_{v,t+1} =T(\\mathcal{S}_{v,t}, a_{v,t})$\n\nFor notational convenience, we also define the transition matrix\nT of size M \u00d7 |Z| where Tm,a stores T(m, a). Moreover, we\nintroduce the notion of a state vector s for each node v \u2208 V at time\nt, which is a one-hot encoding of size |M| of the node's current state.\nAggregation functions. The transition value a for node v at time\nt is directly determined by aggregating the multi-set of states from\nall neighboring nodes at time t. The aggregation A specifies how the\naggregated value is computed from this neighborhood information.\nNote that this formulation of the aggregation A allows for a general\nframework in which many different design choices can be made for\na concrete class of GraphFSAs. Throughout this work, we will focus\non the counting aggregation and briefly touch upon the positional\naggregation.\nCounting aggregation: The aggregation aims to count the occur- rence of each state in the immediate neighborhood. However, we want the domain Z to remain finite. Note that due to the general graph topology of G, the naive count could lead to Z growing with n the number of nodes. Instead, we take inspiration from the dis- tributed computing literature, specifically the Stone Age Computing\nModel by Emek and Wattenhofer [3]. Here, the aggregation is per- formed according to the one-two-many principle, where each neigh- bor can only distinguish if a certain state appears once, twice, or\nmore than twice in the immediate neighborhood. Formally, we can generalize this principle using a bounding parameter b, which de- fines up to what threshold we can exactly count the neighbor states.\nThe simplest mode would use b = 1, i.e., where we can distinguish if a state is part of the neighborhood or not. Note that this is equivalent to forcing the aggregation to use a set instead of a multi-set. For the\ngeneral bounding parameter b, we introduce the threshold function \u03c3, which counts the occurrences of a state in a multi-set.\n\n$\\qquad \\sigma(m, S) = \\min(b, |\\{\\{s | s = m, s \\in S\\}\\}|)$"}, {"title": "Starting and final states", "content": "We use starting states $S \\subseteq M$ of the\nFSA to encode the discrete set of inputs to the graph problem. These\ncould be the starting states of a cellular automaton or the input to an\nalgorithm (e.g., for BFS, the source node starts in a different state\nfrom the other nodes). Final states $F \\subseteq M$ are used to represent the\noutput of a problem. In node prediction tasks, we choose one final\nstate per class. Opposed to other states, it is not possible to transition\naway from a final state, meaning that once such a state is reached, it\nwill never change."}, {"title": "4 Empirical evaluation", "content": "The GraphFSA framework is designed to extract state automaton representations with discrete states and transitions to learn to\nsolve the task at hand through an algorithmic representation. Our evaluation consists of two key components to showcase this. In the\nfirst part, we focus on classic cellular automaton problems. These automatons serve as a foundational component of our study as they\nrepresent the simplest possible version of an algorithm. However, despite their simplicity, they can becomes increasingly powerful and\nexhibit complex behaviour when assembled together in a network.\nWe successfully learn the underlying automaton rules, demonstrating the ability and advantage of the GraphFSA framework to capture\nsimple algorithmic behaviour.\nIn the second part of our empirical study, we evaluate our models using our proposed graph automaton benchmark and a set of more\nchallenging graph algorithms. GRAB enables a comprehensive in- vestigation of GraphFSA's performance across a broad range of prob-\nlems. We are particularly interested in the generalisation ability of the GraphFSA Framework. Therefore, we perform extrapolation experi-\nments where we train on smaller graphs and subsequently test its per- formance on larger instances. Finally, we use the GraphFSA frame- work to learn a selection of elementary graph algorithms, demon- strating the framework's capability and potential for algorithm learn-\ning."}, {"title": "4.1 Training", "content": "We take inspiration from prior research on training differentiable\nfinite state machines [18] and propose an adaption to train Diff-FSA,\nwhich follows the GraphFSA framework, on general graphs. To\nmaintain differentiability, we relax the requirement for choos- ing a single next state for a transition in T during training and\ninstead model it as a probability distribution over possible next\nstates, resulting in a probabilistic automaton. We thus compute\nP(X = m | M \u00d7 Z) for m \u2208 M and parameterize Diff-FSA with\na matrix T' of size M \u00d7 Z \u00d7 M that holds the probabilities for\nall possible transitions and states. This means that the transition\nmatrix T' contains the probabilities of transitioning from a state m\u2081\nto a state m2 given a specific transition value. To train the model\nwith a given step number t, we execute Diff-FSA for t rounds\nand compute the loss based on the ground-truth output states of"}, {"title": "5 Limitations and future work", "content": "The main advantage of the GraphFSA framework is its use of discrete states. This allows us to interpret the learned mechanics through the\nlens of a state automaton. Moreover, it can perform well in scenarios where the underlying rules of a problem can be modeled with discrete\ntransitions while requiring that inputs and outputs can be represented as discrete states. This is the case for several algorithmic settings but\nlimits the model's applicability to arbitrary graph learning tasks. To broaden the applicability of the GraphFSA framework, future work\ncould investigate methods to map continuous input values to discrete states, potentially with a trainable module. Another aspect to inves- tigate is the study of more finite aggregations for GraphFSA. These\ncan heavily influence a model's expressivity or align its execution to a specific task. Moreover, Diff-FSA only represents one possible approach to train models within the GraphFSA framework. Training\nmodels that yield discrete transitions remains challenging and could further improve performance and effectiveness."}, {"title": "6 Conclusion", "content": "We present GraphFSA, an execution framework that extends finite state automata by leveraging discrete state spaces on graphs. Our re- search demonstrates the potential of GraphFSA for algorithm learn- ing on graphs due to its ability to simulate discrete decision-making\nprocesses. Additionally, we introduce GRAB, a benchmark designed to test and compare methods compatible with the GraphFSA frame- work across a variety of graph distributions and sizes. Our evaluation\nshows that Diff-FSAcan effectively learn rules for classical cellular automata problems, such as the Game of Life, producing structured\nand interpretable representations in the form of finite state automata. While this approach is intentionally restrictive, it simplifies complex- ity and aligns the model with the task at hand. We further validate\nour methodology on a range of synthetic state automaton problems and complex algorithmic datasets. Notably, the discrete state space\nwithin GraphFSA enables Diff-FSAto exhibit robust generalization capabilities."}]}