{"title": "CONTEXT CLUES: EVALUATING LONG CONTEXT MODELS FOR CLINICAL PREDICTION TASKS ON EHRS", "authors": ["Michael Wornow", "Suhana Bedi", "Miguel Angel Fuentes Hernandez", "Ethan Steinberg", "Jason Alan Fries", "Christopher R\u00e9", "Sanmi Koyejo", "Nigam H. Shah"], "abstract": "Foundation Models (FMs) trained on Electronic Health Records (EHRs) have achieved state-of-the-art results on numerous clinical prediction tasks. However, most existing EHR FMs have context windows of <1k tokens. This prevents them from modeling full patient EHRs which can exceed 10k's of events. Recent advancements in subquadratic long-context architectures (e.g., Mamba) offer a promising solution. However, their application to EHR data has not been well-studied. We address this gap by presenting the first systematic evaluation of the effect of context length on modeling EHR data. We find that longer context models improve predictive performance \u2013 our Mamba-based model surpasses the prior state-of-the-art on 9/14 tasks on the EHRSHOT prediction benchmark. For clinical applications, however, model performance alone is insufficient \u2013 robustness to the unique properties of EHR is crucial. Thus, we also evaluate models across three previously underexplored properties of EHR data: (1) the prevalence of \"copy-forwarded\" diagnoses which creates artificial repetition of tokens within EHR sequences; (2) the irregular time intervals between EHR events which can lead to a wide range of timespans within a context window; and (3) the natural increase in disease complexity over time which makes later tokens in the EHR harder to predict than earlier ones. Stratifying our EHRSHOT results, we find that higher levels of each property correlate negatively with model performance (e.g., a 14% higher Brier loss when making predictions for the most versus least irregular patients), but that longer context models are more robust to more extreme levels of these properties. Our work highlights the potential for using long-context architectures to model EHR data, and offers a case study for identifying new challenges in modeling sequential data motivated by domains outside of natural language. We release our model checkpoints and code at: https://github.com/som-shahlab/long_context_clues", "sections": [{"title": "INTRODUCTION", "content": "Foundation Models (FMs) (Bommasani et al., 2021) trained on Electronic Health Records (EHRs) have achieved state-of-the-art results on numerous clinical prediction tasks (Odgaard et al., 2024; Yang et al., 2023). Such models can improve patient outcomes via early detection of disease and risk stratification (Steinberg et al., 2023). As an EHR is simply a list of chronologically-ordered clinical events (see Figure 1a), it can be modeled as a sequence of tokens. Instead of subwords or image patches, however, tokens represent clinical events like diagnoses and procedures (McDermott et al., 2023). This approach has enabled the application of transformer architectures originally developed for natural language processing (NLP) such as BERT (Rasmy et al., 2021; Li et al., 2020; Odgaard et al., 2024) and GPT (Steinberg et al., 2021; Pang et al., 2024; Kraljevic et al., 2024) to EHR data.\nA critical choice in FM design is context length \u2013 i.e. how many tokens of input the model can ingest. Longer context lengths have shown a consistent positive impact on FM performance across various domains by enabling models to reference and reason over more information (Xiong et al., 2023). Given the typical hospital's limited compute resources, however, transformer-based EHR FMs have been limited to processing short context lengths (i.e., 512 tokens) due to the quadratic scaling of attention with input length (Vaswani et al., 2017). As a single patient's EHR can contain 10k's of tokens, this greatly limits the amount of data that EHR FMs can consider. This is especially\n1"}, {"title": "BACKGROUND", "content": "In this section, we motivate the application of long-context foundation models to electronic health record data and summarize related work."}, {"title": "FOUNDATION MODELS FOR EHRS", "content": "Foundation Models (FMs) are large-scale deep learning models trained on extensive amounts of unlabeled data via unsupervised learning (Bommasani et al., 2021). An electronic health record (EHR) provides comprehensive documentation of patient interactions with the healthcare system, including diagnoses, medications, procedures, lab results, etc. (Ambinder, 2005). In this work, we only consider structured EHR data \u2013 i.e. we ignore notes and images \u2013 as structured EHR data is simpler to deidentify and thus share with the community for open science (Negash et al., 2023).\nAs seen in Table 1, many architectures for sequence modeling have been re-applied to EHR data. Most utilize transformer-based architectures such as BERT (Devlin et al., 2019) or GPT (Brown et al., 2020) with a context length of 512. Pretrained on millions of EHRs using objectives such as\n3"}, {"title": "LONG CONTEXT FMS", "content": "Context length is the number of input tokens that a model can ingest. Longer contexts have shown to positively impact FM performance by enabling models to reason over more information (Xiong et al., 2023). Token-level perplexity typically decreases as context length increases, reflecting improved model comprehension of longer sequences (Press et al., 2022; Chen et al., 2023; Peng et al., 2023b).\nTheoretically, conditioning on more of a patient's medical history should also enable better clinical decisions. Unfortunately, transformers scale quadratically with context length (Vaswani et al., 2017), which makes processing long sequences computationally expensive. This is an especially important consideration for resource-constrained hospitals hoping to deploy such models. To remedy this, subquadratic architectures optimized for processing longer contexts have been proposed (Tay et al., 2020; Wang et al., 2024). They replace the $O(n^2)$ attention mechanism in transformers with linear or log-linear alternatives such as state space models (Gu & Dao, 2024; Goel et al., 2022), long convolutions (Poli et al., 2023a), linear attention (Peng et al., 2023a; Katharopoulos et al., 2020), or recurrent subunits (De et al., 2024). Despite strong results in NLP (Xu, 2024) and biology (Nguyen et al., 2023a), these architectures remain largely untested on EHR data."}, {"title": "RELATED WORK", "content": "The impact of context length on EHR FMs for clinical prediction tasks remains largely unexplored. Many papers have evaluated the trade-offs of BERT (Odgaard et al., 2024; Rasmy et al., 2021; Li et al., 2020) and GPT-based (Kraljevic et al., 2024; Pang et al., 2024) architectures on EHR data. However, they typically only consider one context length up to 512 tokens. In contrast, our work examines the impact of multiple context lengths up to 16,384 tokens.\nThese works also do not consider state-of-the-art subquadratic architectures. To our knowledge, only one work \u2013 EHRMamba (Fallahpour et al., 2024) \u2013 has done so. However, the authors only consider a single context length of 2048, and do not train or evaluate on longitudinal (i.e. full-length) EHRs, instead focusing on the more limited ICU setting. In contrast, our work evaluates Mamba (Gu & Dao, 2024) on 8x longer context lengths and longitudinal EHR tasks.\nSeveral studies have combined fixed context window transformers with a preliminary retrieval step that selects the most relevant events across a patient's entire timeline (Kim et al., 2023; Zhu et al., 2024). However, they only consider fixed context windows and benchmark against weaker long context models such as S4 (Gu et al., 2022) and Performer (Choromanski et al., 2022)."}, {"title": "METHODS", "content": "Our goal is to measure how non-transformer architectures, context length, and the unique properties of EHR data impact performance on clinical prediction tasks. We pretrain 16 models across four"}, {"title": "MODEL TRAINING", "content": "Here, we provide details on our training dataset, tokenization strategy, and model architectures."}, {"title": "PROBLEM SETUP", "content": "In this paper, we focus exclusively on the structured data within a longitudinal (i.e. full-length) EHR - i.e., diagnoses, medications, lab tests, procedures, visits, and other observational data. Our dataset consists of n patients $X = {X_1, ..., X_n}$. For each patient i we have their structured EHR data $X_i$, which is composed of a sequence of chronologically ordered clinical events $X_{ij}$:\n$X_i = {X_{i1}, X_{i2}, ..., X_{i|x_i|}}$\nWe refer to $X_i$ as a \u201cpatient timeline\u201c, where each clinical event is a tuple of the form $(t_{ij}, C_{ij}, V_{ij})$. Here, $t_{ij}$ is the timestamp, $C_{ij} \\in C$ is a medical code drawn from a fixed medical ontology $(C)$, and $V_{ij} \\in V_c \\cup V_n \\cup \\O$ is an optional value, either categorical $(V_c)$ or numeric $(V_n)$:\n$X_{ij} = (t_{ij}, C_{ij}, V_{ij})$\nEvents are sorted by time such that $t_{ij} < t_{i(j+1)}\\forall j$. This formulation of EHR data is also referred to as the \"event stream format\u201d (McDermott et al., 2023).\nFor our experiments, we use a dataset of deidentified longitudinal EHRs sourced from an academic medical center that have been formatted under the OMOP Common Data Model (Sciences & Informatics, 2021). We refer to this dataset as EHR-OMOP. We use 2.5M patients (covering 3.5B clinical events) for training, and hold out 0.5M patients as a validation set. The average patient has 1,364 total and 237 unique events. Additional information can be found in Appendix Section A."}, {"title": "TOKENIZATION", "content": "Given a patient timeline $X_i$, we must convert it into a sequence of tokens $T_i$ that our models can ingest. Thus, we must map each $X_{ij} = (t_{ij}, C_{ij}, V_{ij})$ to some set of token(s) $T_{ij} = {T_{ij1}, ..., T_{ijk}}$. We use the same vocabulary used by the prior SOTA model on the benchmark we use for evaluation, EHRSHOT (Wornow et al., 2023). Each clinical \u201cevent\u201d in a patient's timeline has a single \"code\" associated with it. Each \"code\" then gets converted into a single \"token\" within our vocabulary via the following process. First, all unique codes $c \\in C$ that occur at least once in our training dataset are assigned a unique token. Second, all codes that are associated with categorical values are assigned a unique token for each possible associated categorical value. Third, all codes associated with numerical values are assigned a unique token for each decile within the range of values attained in our training dataset. After sorting all tokens by their information content, the top 39811 tokens were kept as our vocabulary, and all models share this same vocabulary. Please see Appendix Section D for additional details on the token generation and selection process."}, {"title": "ARCHITECTURES", "content": "We evaluate four models - GPT (Brown et al., 2020), Llama (Team, 2024), Mamba (Gu & Dao, 2024), and Hyena (Poli et al., 2023a) at the 120 million parameter scale using their default HuggingFace implementations. (see Appendix Section C for details on each architecture and Appendix Table 6 for exact configurations). We evaluate each model across various context lengths $L\\in L$, with $L = {512,1k, 2k, 4k}$ for the transformer-based models (GPT and Llama) and $L = {1k, 4k, 8k, 16k}$ for the subquadratic models (Mamba and Hyena). The ranges are different given the poor computational scaling of transformers and our limited compute."}, {"title": "EVALUATION", "content": "We use the EHRSHOT clinical prediction benchmark for all of our downstream evaluations (Wornow et al., 2023). EHRSHOT consists of 15 clinical prediction tasks based on a dataset of 7k patients' longitudinal EHRs. The primary evaluation metric is AUROC, and Brier scores are also reported. We only consider binary classification tasks, thus we exclude the multilabel Chest X-Ray Findings task. We use the remaining 14 tasks from the EHRSHOT benchmark for our evaluations, which are broadly grouped into three categories: Operational Outcomes includes predicting ICU Transfer, 30-day Readmission, and Long Length-of-Stay; Anticipating Lab Test Results involves predicting if a thrombocytopenia, hyperkalemia, hypoglycemia, hyponatremia, or anemia lab will be abnormal; and Assignment of New Diagnoses requires predicting whether a patient will get a new diagnosis of hypertension, hyperlipidemia, pancreatic cancer, celiac disease, or lupus within the next year. For additional details on all 14 tasks, including precise definitions, label counts, statistics on the number of tokens per patient, and evaluation methodology, please see Appendix Section A.\nFor our evaluations, we use the same context length that was used during pretraining. We thus sample the last $min{L, |T_i|}$ tokens for each patient prior to the relevant prediction time for a task, then take the embedding of the last token in that sequence as our representation for that patient. We evaluate our models under the zero-shot, few-shot, and \"All\" data setting, with detailed results for zero- and few-shot evaluation provided in Appendix Sections G and H. All EHRSHOT scores reported in the main results use the \"All\" data setting. To be consistent with the original EHRSHOT benchmark, we do not finetune our base models \u2013 instead, we train a logistic regression head on top of the frozen representations created for each patient. Additional details are in Appendix Section A."}, {"title": "EHR-SPECIFIC PROPERTIES", "content": "In the following subsections, we define metrics to quantify three properties of EHR data that distinguish it from modalities such as natural language \u2013 repetitiveness due to copy-forwarding, irregular intervals of time between events, and a natural trend towards increased token complexity over time due to disease progression. Please see Figure 1c for an overview. We believe this analysis provides an interesting counterpoint to most ML research being conducted on natural language sequences.\nFor all three metrics, we first apply them to the EHR-OMOP validation dataset to measure the extent to which a large corpus of real-world EHR data exhibits these properties. Second, we apply two of the EHR-specific metrics \u2013 repetitiveness and irregularity \u2013 to the EHRSHOT dataset to stratify\n6"}, {"title": "COPY-FORWARDING LEADS TO NOISY TOKEN REPETITION", "content": "EHR v. NLP. Copy-forwarding refers to the practice of recording the same diagnosis across multiple visits, typically for chronic conditions or billing purposes (Thornton et al., 2013; Calder et al., 2024; Weis & Levy, 2014). This leads to higher levels of event repetition within the EHR. We hypothesize that repetition could worsen model performance by crowding information out of a limited context window. A long context model might be better equipped to handle this range of possibilities.\nMetrics. To quantify the prevalence of copy-forwarding in a sequence, we calculate its n-gram repetition rate (RR), i.e., the proportion of n-grams in the sequence that are repeated at least once. Please see Appendix Section F.1 for details. A higher RR implies a more repetitive sequence."}, {"title": "TIME INTERVALS BETWEEN EVENTS ARE HIGHLY IRREGULAR", "content": "EHR v. NLP. In natural language, consecutive tokens uniformly have the same \"distance\" of 1 position. In EHR data, however, a patient might wait days, weeks, or even years between visits to the hospital (McDermott et al., 2023). This means consecutive EHR events can have vastly different \"distances\" in time. We hypothesize that patients with more \u201cirregular\u201d sequences, i.e., a greater variety of inter-event time intervals, are more difficult to model as they present a more complex mix of timespans over which a model must reason. This could pose particular challenges to long context models given they observe an even broader range of events (and thus inter-event timespans).\nMetrics. We quantify irregularity as the standard deviation of time intervals between every pair of consecutive events. A higher standard deviation implies a more irregular sequence. Please see Appendix Section F.2 for more details."}, {"title": "DISEASE PROGRESSION CAUSES INCREASED TOKEN COMPLEXITY OVER TIME", "content": "EHR v. NLP. Disease progression refers to the evolving nature of a patient's health over time. As people age, they experience an increase in the variety, frequency, and complexity of diseases they experience due to declining immunity and the increased likelihood of developing comorbidities (Fabbri et al., 2015). In natural language, earlier tokens tend to help in predicting later tokens, and thus perplexity is inversely correlated with a token's position in a prompt (Kaplan et al., 2020). Since disease becomes more complex over time, however, it was unclear if this trend holds for EHR data.\nMetrics. To quantify disease complexity over time, we apply our trained EHR FMS to calculate the median perplexity at each token position across a sample of 20,000 patients from the EHR-OMOP validation set. Please see Appendix Section F.3 for additional experimental details."}, {"title": "RESULTS", "content": "First, we evaluate each of our models on the 14 EHRSHOT clinical prediction tasks. Overall results are shown in Figure 1b, and per-task results in Appendix Figure 9. Our best performing model is Mamba with a context length of 16k tokens. It achieves the highest average AUROC across all tasks, beating the prior state-of-the-art by 0.03 points. Second, we analyze how three EHR-specific properties \u2013 event repetition from copy-forwarding, irregularly spaced inter-event times, and disease progression \u2013 impact model performance. After stratifying EHRSHOT patients into quartiles by each property, we find that each property negatively correlates with model performance. However, longer context models exhibit more robustness as they perform better across all quartiles."}, {"title": "LONGER CONTEXTS IMPROVE PREDICTION MAKING FOR CERTAIN ARCHITECTURES", "content": "Our best performing model is Mamba at its maximum context length of 16k tokens, with a mean AUROC of 0.807 (+0.03 points over prior SOTA). This can be seen in Figure 1b. Each line represents a separate model architecture. The y-axis is mean AUROC across the 14 EHRSHOT tasks, and the x- axis is the context length. The dotted purple line is the AUROC (0.777) achieved by the best overall prior model, CLMBR-t-base, which had a context length of 512 tokens (Wornow et al., 2023).\nSeveral trends appear in Figure 1b. Both Mamba (green) and Llama (orange) show increased performance at longer context lengths, demonstrating the value of additional EHR data when making clinical predictions. In contrast, Hyena (red) exhibits a sharp decrease in performance after exceeding a context length of 4k. This shows that including more tokens into the context does not always improve performance across architectures. The impact of context length on GPT (blue) appears less clear, which could be due to its usage of absolute positional embeddings (see Section 4.4 for additional analysis). Results on individual tasks are in Appendix Figure 9.\nTo more explicitly model the passage of time, we also train a version of our models using the Artificial Time Tokens (ATT) technique proposed in CEHR-BERT (Pang et al., 2021). However, as shown in Appendix Figure 12, we see slightly worse performance with this tokenization strategy."}, {"title": "COPY-FORWARDING CREATES NOISY REPETITION HARMING MODEL PERFORMANCE", "content": "EHR-OMOP Analysis. We measure the n-gram repetition rate (RR) across all 0.5M EHR-OMOP validation patients and plot the frequency of each observed RR in Figure 3 in blue. We perform the same calculations on the WikiText-103 dataset and overlay them in orange as \u201cWikiText\u201d as a point of comparison (Merity et al., 2016). While a significant number of patients have no repeated n-grams in their records due to their short length (see Appendix Figure 8 for a recreation of this plot that excludes patients with less than 20 total events), we see that EHR data still exhibits a much higher degree of repetition than does natural language, especially when considering the repetition of 3-grams and 4-grams. For more details on n-gram RRs, see Appendix Section F.1.\nEHRSHOT Stratification. Next, we evaluated how the repetitiveness of a patient's timeline affects model performance on the EHRSHOT benchmark using Brier score. Using 1-gram repetition rate"}, {"title": "IRREGULAR INTER-TOKEN TIME INTERVALS ARE HARDER TO MODEL", "content": "EHR-OMOP Analysis. We first quantify the degree to which EHR data exhibits irregularity in the intervals of time between consecutive events. Figure 2 shows three different metrics for irregularity \u2013 the mean, standard deviation, and interquartile range of inter-event times for each individual patient \u2013 for the EHR-OMOP validation set in blue. The x-axis of each plot is on a log scale, illustrating the large range of inter-event times across patients. Most patients appear to have a standard deviation of inter-event times between $10^7$ and $10^8$ seconds (i.e. 115 days to 3.2 years).\nEHRSHOT Stratification. Next, we measured how patient timeline irregularity impacts model performance on the EHRSHOT benchmark using Brier score. Evaluating CLMBR-t-base across quartiles of patient irregularity (using the standard deviation of inter-event times as the metric), we found that performance generally degrades (higher Brier scores) as irregularity increases 1d (middle), indicating that irregular sequences are harder to model.\nTable 2 extends this analysis to the EHR FMs trained in this work. While model performance still degrades with increased irregularity, longer context versions of Mamba and Llama consistently outperform their shorter counterparts across all quartiles."}, {"title": "DISEASE PROGRESSION EFFECTS ARE BETTER MODELED WITH LONGER CONTEXTS", "content": "EHR-OMOP Analysis. Figure 4 shows that tokens later in a patient's timeline are more difficult to predict (higher perplexity), even when conditioning on all prior tokens. This contrasts with natural language, where later tokens tend to have lower perplexity (Kaplan et al., 2020; Peng et al., 2023b). We hypothesize this is because diseases naturally become more complex and varied with aging. This degrades the predictive utility of past medical history as primary diagnoses change over time.\nLonger context versions of Mamba and Llama consistently achieve lower perplexities across all token positions compared to shorter contexts, with the gap widening at later tokens. This suggests that a more complete view of the patient's timeline helps handle increasing token complexity due to aging. In contrast, Hyena's longer context models perform worse, replicating our original EHRSHOT results. For GPT, results are mixed: longer contexts (2k and 4k) achieve lower perplexities at later tokens but exhibit significant spikes. This appears to be caused by GPT's usage of absolute positional embeddings \u2013 replacing them with rotary positional embeddings (ROPE) (Su et al., 2024) mitigated these spikes as seen in Appendix Figure 11. Thus, despite its popularity in the EHR FM community (see Table 1), we recommend discontinuing the GPT architecture in favor of Llama or other more modern decoder-only architectures."}, {"title": "DISCUSSION", "content": "In this study, we evaluated the impact of context length on clinical prediction tasks across four models-Mamba, Llama, GPT, and Hyena-trained on longitudinal EHR data. We are the first to pretrain and release the full weights of these non-GPT architectures at the scale of millions of EHRs. With a context length of 16k tokens, Mamba achieved the highest average AUROC across 14 prediction tasks on the EHRSHOT benchmark, surpassing the prior state-of-the-art by +0.03 points. In addition to the best performance, Mamba also offers faster training, quicker inference, and the potential to support longer contexts (Gu & Dao, 2024). Notably, longer context versions of Mamba and Llama performed well in handling EHR-specific issues like token repetition due to copy-forwarding, irregular inter-token time intervals, and increased token complexity from disease progression. This improvement, however, wasn't universal, as Hyena's performance declined significantly beyond 4k tokens, underscoring the need to empirically validate each architecture for long context use.\nLimitations / Future Work: While our findings highlight the potential for long-context models to successfully model EHR data, several limitations should be considered. First, we did not evaluate transformer-based models at context lengths beyond 4k tokens due to limited computational resources. Running a vanilla 16k transformer takes roughly 16x more compute/memory than at a context length of 4k, which was a core motivator for the development of the subquadratic architectures evaluated in this work. Second, model sizes were kept consistent across architectures to isolate the impact of context length. Preliminary findings suggest smaller Mamba models with 16k tokens perform well, which may reduce the need for larger models unsuitable for resource-constrained settings. Future work should quantify the impact of model size on performance. Third, our evaluations focused on clinical risk prediction tasks, but broader clinical tasks (e.g., phenotyping, treatment selection) merit further consideration. Fourth, our pretraining dataset was sourced from a single institution due to data privacy concerns, which may limit generalizability. Fifth, we explored only three EHR-specific properties. Future research could extend this to more attributes of EHR data \u2013 e.g., partial observation due to underdiagnosis or miscoding (Pivovarov et al., 2014; Che et al., 2018), multimodal signals (Soenksen et al., 2022), and event-associated metadata (McDermott et al., 2023). Sixth, we focused on the impact of these EHR-specific properties on downstream evaluations, but they may also have effects on pretraining convergence and stability, which we leave to future work. Seventh, while the metrics we introduce offer a novel lens for examining EHR data, they are fairly simple and could be improved with additional context. For example, having our repetition metric distinguish between meaningful and non-meaningful repetition (e.g., a repeated lab test in an ICU stay is likely more informative than a repeated diagnosis code of a chronic condition like hypertension) could improve model performance in high-repetition settings. And for the irregularity metric, disease status may influence the regularity of time intervals between events (e.g. a cancer patient may exhibit more regular visits than a patient suffering from acute cardiovascular events), which future work could explore by stratifying results based on specific disease phenotypes. Eighth, other promising transformer alternatives, such as linear attention models (Arora et al., 2024), hybrid architectures (Poli et al., 2023b; Lieber et al., 2024), and recurrent models (Peng et al., 2023a), should be explored in future work that builds upon the framework introduced here."}, {"title": "CONCLUSION", "content": "Long context models have unlocked a broad range of natural language applications through their ability to ingest and reason over massive amounts of information. Translating these gains to EHR data could benefit patients by enabling the modeling of an entire lifetime. Thus, we present the first systematic evaluation of how context length impacts EHR modeling. We find that long context subquadratic models such as Mamba are capable of achieving state-of-the-art results on clinical prediction tasks. This represents a sharp break from prior work in EHR FMs, as shown in Table 1, which generally utilized BERT-based models limited to context windows of 512 tokens. We also find that longer context models are more robust to three distinct aspects of EHR data that had been underexplored in prior literature on sequence modeling. We hope our work inspires future efforts to identify interesting sequence modeling challenges from non-NLP domains and encourages further research towards applying non-transformer architectures to structured EHR data."}, {"title": "EVALUATION", "content": "For all of our model evaluations, we use 14 binary clinical prediction tasks sourced from the EHRSHOT benchmark (Wornow et al., 2023). The definitions of these tasks are detailed in Appendix Table 4. We also provide label and patient counts in Appendix Table 5 for each task."}, {"title": "TASKS", "content": "For all of our model evaluations, we use 14 binary clinical prediction tasks sourced from the EHRSHOT benchmark (Wornow et al., 2023). The definitions of these tasks are detailed in Appendix Table 4. We also provide label and patient counts in Appendix Table 5 for each task."}, {"title": "EXPERIMENTAL SETUP", "content": "We considered values of $k \\in {8, 16, 32, 64, 128}$ for all 14 EHRSHOT tasks, with one exception: for the Celiac prediction task, we limited k \u2264 64 due to the dataset's constraint of only 62 positive training examples. This approach ensures fairness in evaluating performance across tasks with varying dataset sizes and class imbalances."}, {"title": "RESULTS", "content": "As shown in Appendix Tables 13, 11, and 12 and Appendix Figure 10, our few-shot learning results indicate that model performance, as measured by AUROC, improves consistently as k increases. Longer-context models, particularly Mamba, demonstrated notable gains even at lower values of k, underscoring their robustness in data-limited scenarios. This trend was consistent across most benchmark tasks, underscoring the utility of long-context architectures in low-resource settings. Our key observations are as follows:\n\u2022 Performance Gains with Context Length: Longer context lengths generally led to better performance, with Mamba models achieving the highest AUROC scores across several k- shot settings, especially at 16,384 tokens.\n\u2022 Impact of Few-Shot Sample Size (k): All models showed improved performance with increasing k, but Mamba and Llama benefited more significantly at higher values of k (64 and 128), consistently outperforming other models across tasks."}, {"title": "ZERO-SHOT LEARNING ON EHRSHOT", "content": "We also evaluate a subset of our models under the zero-shot setting, i.e we simply run inference on each model without any finetuning. This offers the practical benefit of not having to train or store any fine-tuned task-specific model heads."}, {"title": "EXPERIMENTAL SETUP", "content": "We follow the procedure outlined in the ETHOS paper (Renc et al., 2024) for making our zero-shot predictions. In brief, we generate 20 synthetic timelines for each patient at the prediction time, measure the percentage of timelines in which the positive event for a task occurs, and then use that percentage as the probability that the patient experiences that positive event. For our zero-shot evaluations, we choose our two strongest models (Mamba and Llama) at their minimum and maximum context lengths, and evaluate them on three representative EHRSHOT tasks \u2013 new diagnosis of hypertension, 30-day readmission, and new diagnosis of acute MI."}, {"title": "RESULTS", "content": "As shown in Appendix Table 15, our zero-shot results significantly lag behind the performance of our few-shot and finetuned models. None of the zero-shot models beat the prior SOTA model (CLMBR-t-base) on any of the three tasks evaluated. Additionally, results across context lengths appear mixed. This underscores the importance of finetuning for clinical prediction making, and suggests that our training pipeline is not optimally designed for zero-shot evaluations."}, {"title": "REPETITIVENESS", "content": "Due to liability, documentation requirements, billing practices, and other administrative processes, EHR data tends to have a high prevalence of \"copy-forwarded\" information \u2013 i.e. data that is copied- and-pasted from one visit to the next (Thornton et al., 2013; Calder et al., 2024; Weis & Levy, 2014). To quantify the level of \"copy-forwarding\u201d within a sequence, we calculate the n-gram repetition rate (RR) for each EHR sequence in our dataset using n = 1, 2, 3, 4.\nWe define the n-gram repetition rate as the proportion of n-grams in a given sequence that are repeated at least once. A higher repetition rate means a sequence is more repetitive. Formally, we define the n-gram repetition rate as follows:\n$RR_n(x) = \\frac{\\sum_{u \\in U(x)} \\mathbb{I}[C(u,x) > 1]}{|U(x)|}$ where $U(x)$ is the set of unique n-grams in the sequence x and $C(u, x) \\in \\mathbb{R}$ is the count of occurrences of the n-gram u \u2208 U in the sequence x. We define $\\mathbb{I}[]$ as the indicator random variable that is 1 if the condition inside the brackets is true, and 0 otherwise.\nWe calculate n-gram repetition rates for n = 1, 2, 3, 4 across all 0.5M patients in our EHR-OMOP validation dataset. In Figure 8, we compare the observed repetition rate in our EHR dataset to the repetition rates observed in the WikiText-103 corpus to demonstrate the higher levels of repetition in EHR sequence data. We repeat our analysis in Appendix Figure 8, but first remove patients with less than 20 total clinical events in order to give a more accurate picture of the level of repetition seen in the timelines of patients with \"meaningful\" levels of engagement with the healthcare system."}, {"title": "IRREGULARITY", "content": "Irregularity in EHR data arises from uneven time intervals between clinical events for each patient (McDermott et al.", "times": "Let $X_i$ represent the sequence of clinical events for patient i. Let $"}]}