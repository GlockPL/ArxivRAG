{"title": "Hypergraph Learning based Recommender System for Anomaly Detection, Control and Optimization", "authors": ["Sakhinana Sagar Srinivas", "Rajat Kumar Sarkar", "Venkataramana Runkana"], "abstract": "Anomaly detection is fundamental yet, challenging problem with practical applica- tions in industry. The current approaches neglect the higher-order dependencies within the networks of interconnected sensors in the high-dimensional time se- ries(multisensor data) for anomaly detection. To this end, we present a self-adapting anomaly detection framework for joint learning of (a) discrete hypergraph structure and (b) modeling the temporal trends and spatial relations among the interdepen- dent sensors using the hierarchical encoder-decoder architecture to overcome the challenges. The hypergraph representation learning-based framework exploits the relational inductive biases in the hypergraph-structured data to learn the point- wise single-step-ahead forecasts through the self-supervised autoregressive task and predicts the anomalies based on the forecast error. Furthermore, our frame- work incentivizes learning the anomaly-diagnosis ontology through a differentiable approach. It derives the anomaly information propagation-based computational hypergraphs for root cause analysis and provides recommendations through an offline, optimal predictive control policy to remedy an anomaly. We conduct ex- tensive experiments to evaluate the proposed method on the benchmark datasets for fair and rigorous comparison with the popular baselines. The proposed method outperforms the baseline models and achieves SOTA performance. We report the ablation studies to support the efficacy of the framework.", "sections": [{"title": "1 Introduction", "content": "Anomaly detection is a long-standing task that has a wide range of applications in monitoring the behaviors of various dynamical real-world systems, including but not limited to financial markets, retail, and e-commerce. Of particular interest in this work is anomaly detection on industrial data for developing a framework that automates anomaly detection, identifies the root causes, and provides recommendations to resolve the underlying issues with ultra-low inference times. At a higher hierarchical level, large-scale industrial units are complex interaction systems of nonlinear dynamical subunits that operate within the margins of normal optimal conditions(NOCs), i.e., anomaly-free. The subunits with a copious amount of interdependent sensors generate high-dimensional time- ordered data capturing the collective behavior of subunits, mostly under NOCs. Anomalies are rare events. Detecting and identifying the anomalies in the large-scale system monitoring data is challenging. Under this scenario, the defacto approach is an unsupervised anomaly detection task on multidimensional data. The goal is to learn the temporal dependencies and the spatial correlations among the interdependent sensors for modeling normality. Any deviation from such learned relationships suggests the occurrence of abnormality, which is inherently different from the normality patterns. Of late, deep learning-based time series modeling techniques have attracted interest in learning the signatures of abnormality events in high-dimensional time series data. In this vein, traditional deep learning-enabled anomaly detection techniques are the reconstruction- based techniques[18, 35, 27, 36, 16]; the forecasting-based techniques[3, 13, 12, 28]; the density-"}, {"title": "2 Our approach", "content": "Our framework consists of the following modules. (a) The hypergraph structure learning(HgSL) module learns the underlying higher-order structural patterns of the multisensor data that captures the inherent dependency relationships within the network of interconnected sensors. (b) The encoder- decoder(HgED) module operates on the hypergraph topology to learn the hierarchical representations that implicitly encode both the temporal trends and spatial relations among the multiple IoT sensors while preserving the global topological properties of the hypergraph. The module learns the discrimi- native hypernode-level representations in the (low-dimensional) Euclidean space to distinguish the normal-abnormal instances. (c) The hypergraph forecasting(HgF) module utilizes the hypernode representations and predicts the one-step-ahead forecasts of the sensors. (d) The hypergraph devi- ation(HgD) module flags the probable anomalous events by comparing the expected and observed trends of the sensors. This module utilizes the forecasting error as the criterion for anomaly detection and serves as supervisory information for the HgSL module. Furthermore, the framework provides the root cause analysis by viewing the learned hypergraph topology as a computation hypergraph for anomaly information traversal across the interconnected network of sensors. The knowledge of the inherent structure plausibly explains the manifestation of the underlying cause when the predicted relationships deviate from the learned normality relationships in the hypergraph-structured data. The objective of unsupervised anomaly detection is to predict the output labels $y^{(t)} \\in {0,1}$, which is a two-label prediction task suggesting the anomaly occurrence at a time point, t. Note: label = 1 means \"anomaly\" and label = 0 means \u201cnormal\u201d."}, {"title": "2.1 Hypergraph Representation", "content": "Consider a multivariate contiguous time-series data from n variates(sensors) observed over T time steps denoted by $f = [f^{(1)}, ..., f^{(T)}]$. $f^{(t)} \\in R^{n}$ represents the n-variates observations at time step t, which form an n-dimensional vector. We generate fixed-length inputs by a sliding window of length w over historical data as input to our framework to learn from the multisensor data. The windowed data at time t, $F^{(t)} \\in R^{n\\times w}$ is given by $F^{(t)} = [f^{(t-w)}, f^{(t-w+1)}, . . ., f^{(t-1)}]$. The interconnected sensors do not have an explicit higher-order relational structure underlying the multisensor data. We utilize a hypergraph framework for a structured representation of the data. The hypergraph structured data offers a natural way to abstract the complex interdependencies among the sensors. We denote the sensors as the hypernodes of the dynamic bidirected hypergraph. The bidirectional hyperedges model the super-dyadic relations among the hypernodes. We obtain spatiotemporal hypergraph data with time-varying hypernode features. The hypernode, hyperedge set, and hypergraph structure remain unchanged."}, {"title": "2.2 Hypergraph Structure Learning(HgSL)", "content": "The traditional methods[8, 31] operate on the prior known explicit structure to learn from the hypergraph-structured data. In practice, however, the real-world applications present challenging scenarios where the higher-order structural dependencies in networks underlying the interdependent sensors is unknown, incomplete, or partially available due to limited prior knowledge. The HgSL module offers a structural modeling approach to dynamically optimize the sensor topology and implicitly learn the task-relevant relational structure from the hypernode(sensor) embeddings. The optimal sensor topology captures the complex hidden relations among the interdependent sensors. We perform inference on the hypergraph-structured multisensor data through the hypergraph representa- tion learning on the downstream anomaly detection task driven by the inductive-learning approach. The hypernodes of the hypergraph had characterized by learnable (low-dimensional) embeddings $z_{i}, 1 \\le i \\le n$. The hypernode embeddings $z_{i} \\in R^{d}$ are continuous vector representations in the d-dimensional embedding space. We will form a directed hyperedge from hypernode i by connecting with its k-nearest hypernodes. In essence, the hyperedge connects the hypernodes i and j; if j is among the k-closest local-hypergraph neighbors of i. We obtain n (in this setting, m = n) hyperedges that are incident with k + 1 non-repeating hypernodes of the hypergraph. We accomplish this by learning a sparse symmetric hypergraph incidence matrix H in which n \u00d7 (k + 1) elements are equal to 1 while the rest are zero. We achieve this by computing the pairwise Euclidean distance of the hypernodes using their embeddings to learn the similarity measure. It is described by,\n$d_{i,j} = (\\sum_{ind=1}^{d} |z_{i}^{ind} - z_{j}^{ind}|^{2})^{1/2}; i \\in {1, ..., n},i \\neq j$\n(1)"}, {"title": "2.3 Hypernode Positional Encoding(HPE)", "content": "There exists no canonical ordering of the hypernodes in the hypergraph. We encode hypernode positional information to enable position awareness[6]. The positional embeddings, $PE \\in R^{n \\times w}$, have been linearly added to the feature matrix $F^{(t)} \\in R^{n \\times w}$ to inform the model about the positional information of the hypernodes from the main hypergraph. The HPE module generates the positional embeddings based on the local and global neighbors of each hypernode."}, {"title": "2.4 Hypergraph Encoder-Decoder(HgED)", "content": "We will first discuss the Hypergraph Convolutional Neural Network(HgCNN), Hypergraph Local- Pooling(HgPool), and Hypergraph UnPooling(UnHgPool) operators. We then elaborate on the HgED module in great detail."}, {"title": "2.4.1 Hypergraph Convolutional Neural Network(HgCNN)", "content": "The HgCNN operator generalizes the convolution operation to the hypergraphs. It presents the neural network primitives that compute the hypernode representations $x_{v_{i}}, 1 \\le i \\le n$, where $x_{v_{i}} \\in R^{d}$. We obtain hypernode-level representations through propagating, aggregating, and transforming the hypernode-level feature information on the hypergraph topology to learn from the sensor-based information. It performs a spatial-hypergraph filtering operation in two phases. At first, given the incidence matrix $H \\in R^{n \\times n}$ and hypernode feature matrix $F^{(t)} \\in R^{n \\times w}$. We determine the hyperedge attribute matrix $X_{ep}^{(t)} \\in R^{n \\times d}$. The row-vectors in $X_{ep}^{(t)} $ denote the hyperedge representations $x_{ep}^{(t)} \\in R^{d}, 1 < p < n$ and are computed by aggregating the attention-weighted features of the incident hypernodes obtained as,\n$x_{ep}^{(t)} = \\sigma(\\sum_{i \\in N_{p}} \\alpha_{p,i} W_{1}F_{i}^{(t)})$\n(3)\nwhere $F_{i}^{(t)} \\in R^{w}$ denotes the feature vector of hypernode i and $W_{1} \\in R^{d \\times w}$ is the learnable weight matrix. $\\sigma$ is the sigmoid function to introduce non-linearity in the intra-neighborhood feature aggregation scheme. The hyperedge representations embeds the latent information of the intra-relations among the incident hypernodes. We utilize the hypernode embedding vectors($z_{i}$) to learn the attention score $e_{p,i}$ of hyperedge p incident with the hypernode i. The normalized attention score $\\alpha_{p,i}$ determined using the softmax function is computed by,\n$e_{p,i} = ReLU (W_{2}^{T} g_{i}^{(t)}); g_{i}^{(t)} = z_{i} \\oplus W_{1}F_{i}^{(t)}$\n$\\alpha_{p,i} = \\frac{exp (e_{p,i})}{\\sum_{i \\in N_{p}} exp (e_{p,i})}$\n(4)\nwhere $W_{2} \\in R^{2d}$ is the learnable vector. $\\oplus$ denotes the concatenation operation. The next phase captures the complex non-linear inter-relations between the hypernodes and hyperedges. We perform the hypergraph attention-based global neighborhood aggregation scheme for learning informative and expressive hypernode representations. In simple terms, the hyperedge attribute extractor fuses the hyperedge information with the incident hypernodes as described by,\n$x_{v_{i}}^{(t)} = ReLU (W_{3}F_{i}^{(t)} + \\sum_{p \\in N_{i}} \\beta_{i,p} W_{4}x_{ep}^{(t)})$\n(5)\nwhere $W_{3} \\in R^{d \\times w}$ and $W_{4} \\in R^{d \\times d}$ are learnable weight matrices. We utilize the ReLU activation function to introduce non-linearity to update hypernode-level representations. The unnormalized attention score of hypernode i incident with hyperedge p given by $\\phi(i, p)$, and the attention coefficients $\\beta_{i,p}$ computed as,\n$\\phi(i,p) = ReLU (W_{5}^{T} (g_{i}^{(t)} \\oplus W_{4}x_{ep}^{(t)}))$\n$\\beta_{i,p} = \\frac{exp(\\phi(i, p))}{\\sum_{p \\in N_{i}} exp(\\phi(i,p))}$\nwhere $W_{5} \\in R^{3d}$ is a trainable vector. In summary, the HgCNN operator performs the neighborhood aggregation schemes to learn the optimal hypernode-level representations, whilst maximally preserv- ing the high-order relations embedded in the structural characteristics of the hypergraph."}, {"title": "2.4.2 Hypergraph Local-Pooling(HgPool)", "content": "We present a two-fold approach-based differentiable local-hypergraph pooling operator to (1) induce subhypergraphs by reducing the order and size of the main hypergraph to obtain a pooled hypergraph and (2) learn the hierarchical representations of the hypernodes by encoding the dominant structural characteristics of the hypergraph. The prominent steps in a downsampling technique based local- hypergraph pooling mechanism are (a) computing the measure for performing down-sampling on the hypergraph to obtain the pooled hypergraph by dropping fewer hypernodes of lower importance"}, {"title": "2.4.3 Hypergraph UnPooling(UnHgPool)", "content": "In contrast, the hypergraph unpooling operator performs the inverse operation for the local- and global-neighborhood enlargement by upsampling the pooled hypergraph $\\mathcal{G}^{(t)}$ to the original hy- pergraph structure $G^{(t)}$. The UnHgPool operator utilizes the indices of the hypernodes selected by the HgPool operator to restore the high-resolution hypergraph topology. The forward propagation of the hypergraph unpooling mechanism given by,\n$X^{(t)} = addition(0^{(t)}, \\tilde{X}^{(t)}, idx^{(t)})$\n(12)\nThe vector $idx^{(t)}$ contains the indices of the important hypernodes selected from the hypernode- ranking operation of the Hgpool operator. $\\tilde{X}^{(t)} \\in R^{n_{p} \\times d}$ denotes the hypernode attribute matrix of the pooled hypergraph obtained from Equation (11). $0^{(t)} \\in R^{n \\times d}$ denotes the initial hypernode attribute matrix of the resultant upsampled hypergraph from the UnHgPool operator. The mathematical operation, $addition(0^{(t)}, \\tilde{X}^{(t)}, idx)$, distributes the hypernode representations from the $\\tilde{X}^{(t)}$ matrix into the $0^{(t)}$ matrix, according to the indices stored in idx. In simple terms, row vectors in $0^{(t)}$ are replaced with the corresponding row vectors in $\\tilde{X}^{(t)}$, acceding with indices in idx and the rest of the row vectors filled with zeros. Furthermore, we have skip connections to perform the feature- map summation between the hypernode representations obtained from the HgPool operator(refer to Equation 6) and the upsampled hypergraph(refer to Equation 12). In brief, we fill the zero vectors in the hypernode attribute matrix with the corresponding row vectors obtained by the HgPool operator. We then compute the hyperedge attribute matrix $\\hat{X}_{ep}^{(t)}$ of the upsampled hypergraph as given by,\n$\\hat{x_{ep}}^{(t)} = \\sigma (W_{9}\\sum_{i \\in N_{p}} x_{v_{i}}^{(t)})$\nwhere $W_{9} \\in R^{d \\times d}$. Further, we employ the self-attention mechanism to explicitly model the anomaly propagation delay or advancement from the global-neighborhood sooner or later through the hypergraph topology. The refined hypernode-level representations are obtained by,"}, {"title": "2.5 Hypergraph-Forecasting(HgF)", "content": "The hypergraph forecasting module predicts the multi-sensor values at time step t, i.e., $f^{(t)} \\in R^{n}$.\n$\\hat{f}^{(t)} = f_{\\Theta} ([z_{1}x_{v_{1}}^{(t)}... z_{n} x_{v_{n}}^{(t)}])$\n(17)\nwhere the hypernode representations($x_{v_{i}}^{(t)}$ obtained from HgED. Here, the goal is to minimize the mean squared error(MSE) between the model predictions $\\hat{f}^{(t)}$ and the observed data $f^{(t)}$ for lower- forecasting error. Under a scenario where labeled-anomaly data are available. An anomaly detection task is a supervised two-category classification, where the objective is to distinguish the normal and abnormal instances. The hypergraph prediction module in this scenario,\n$\\hat{y}^{(t)} = o_{f} ([z_{1}x_{v_{1}}^{(t)}... z_{n} x_{v_{n}}^{(t)}])$\n(18)\nwhere the goal is to minimize the binary cross-entropy loss between the model predictions($\\hat{y}^{(t)} \\in 0, 1$) and the ground-truth labels($y^{(t)} \\in 0, 1$). $f_{\\Theta}, f_{y}$ are fully-connected layers."}, {"title": "2.6 Hypergraph-Deviation(HgD)", "content": "The HgD module in the unsupervised anomaly detection task computes the robust normalized anomaly scores($A_{i}^{(t)}$). This information regarding the sensors help in accurately localizing the anomalies within the multisensor data in the temporal domain.\n$A_{i}^{(t)} = \\frac{dev_{i}^{(t)}}{\\tilde{\\sigma}_{i}}; dev_{i}^{(t)} = |f_{i}^{(t)} - \\hat{f}_{i}^{(t)}|$\n(19)\nwhere $\\hat{f}_{i}^{(t)}, f_{i}^{(t)}$ are prediction of HgF module and ground truth respectively. $\\tilde{\\mu}_{i}$ and $\\tilde{\\sigma}_{i}$ are the me- dian(second quartile) and inter-quartile range(difference of upper and lower quartiles) of $A_{i}^{(t)}$ across the time points. We compute the simple moving average of the maximum value of anomalousness score($A_{i}^{(t)}$) across the multi sensors at time point t over the validation set as given,\n$T_{h} = \\underset{t \\in T_{val}}{max} \\widehat{A^{(t)}}; \\widehat{A^{(t)}} = \\frac{1}{w_{a}}\\sum_{t-(w_{a}+1)}^{t} max (A_{i}^{(t)})$\nwhere $w_{a}$ (= 10) denotes the number of time points in the moving average calculation. $T_{val}$ denotes the time points in the validation set. We set the anomaly detection threshold(Th) as the max of $\\widehat{A^{(t)}}$ over the validation data. During inference, time points in the test set with an anomaly score higher than the threshold score were identified as abnormality events."}, {"title": "3 Experiments and results", "content": "We demonstrate and support the effectiveness of our proposed method in comparison to the baseline approaches by investigating the following research questions:\n\u2022 RQ1(Accuracy): How does our proposed method perform compared to the baseline methods on the anomaly-detection task?\n\u2022 RQ2(Ablation): How helpful are the modules of the proposed method in improving the model performance?\n\u2022 RQ3(Interpretability): How does our method provide the anomaly diagnosis and suggest recommendations in a prescriptive approach to avoid the anomalies?"}, {"title": "3.1 Benchmark Datasets", "content": "To probe the efficacy of our proposed method on anomaly detection, we evaluate our framework on a variety of publicly available datasets for competitive benchmarking with the baseline methods. Table 1 summarizes the characteristics of the varied datasets used in this study. The SWaT and WADI are real-world datasets on water treatment facilities and distribution networks. SMAP and MSL are expert-labeled open-sourced datasets of telemetry data from NASA[12]. The Tennessee Eastman process(TEP) is a simulated industrial benchmark dataset for process monitoring and control. It contains 20 different faults. The HAI is a time-series dataset of a realistic industrial testbed of steam-turbine power generation and pumped-storage hydropower generation. It contains 38 different attack scenarios."}, {"title": "3.2 Experimental setup", "content": "We perform min-max scaling on all the datasets to rescale variables into the range [0,1]. We train the model for 100 epochs with a batch size of 48 on multiple NVIDIA Tesla T4 GPUs in all the experiments. We optimize using Adam optimizer with initial learning rate(lr) set as 0.001 and (\u03b21, \u03b22) =(0.9,0.99). We implement the early-stopping technique and adopt the Ir adjusting strategy to decay the learning rate by half with the patience of 10 epochs on the validation set. We conduct five different experimental runs and report the mean values of the evaluation metrics obtained on the different experimental run outputs across all the datasets."}, {"title": "3.3 Model configurations", "content": "The hypernode embeddings($z_{i}$) and representations($x_{v_{i}}^{(t)}$) dimensions have a fixed size(d) of 128 for all the datasets. We report, in Table 1, the optimal sliding window size(w) and the number of nearest neighbors(k) used in this study across the datasets."}, {"title": "3.4 Evaluation Metrics", "content": "We evaluate and report the performance of our model on the test set across all the benchmark datasets. We report the model performance in terms of the standard evaluation metrics such as precision(P as %), recall(R as %), and F1-score(F1 as%) for a fair and rigorous comparison with the baseline models. We utilize the maximum anomaly score(refer to section 2.6) over the validation dataset to set the threshold to identify anomalies. For SWaT and WADI datasets, there exist contiguous anomaly segments. We had adopted the point adjustment strategy[24, 34] to flag the entire time segment as an anomaly if the model predictions within this subset window had detected an anomaly."}, {"title": "3.5 Results", "content": "We compare the HgAD model with state-of-the-art methods for multivariate time-series anomaly detection on all the datasets. Tables 2 and 3 present the performance of the baseline models in comparison with our proposed method. The results show that the HgAD model outperforms the baseline models and attains significant gains consistently across the evaluation metrics on all datasets. On SWaT and WADI datasets, the proposed method demonstrates relatively the best performance with a high precision score of 97.48% on SWaT and 98.75% on WADI. The HgAD model brings a moderate 2% and 1.3% improvement in the precision score compared to the GRELEN[33] and GDN[7] on SWaT and WADI datasets, respectively. In terms of recall and F1-measure, the HgAD model surpasses the previous state-of-the-art baselines and reports a percentage increase of 2.2% and 3.9% on SWaT; 1.7%, 10.65% on WADI over the successive-best baseline models GTA[6], GRELEN[33] and GTA[6], MTAD-GAT[34] respectively. On SMAP and MSL datasets, the HgAD model unsurprisingly outperforms the baseline models and reports the highest scores on all the evaluation metrics. In terms of precision score, the HgAD model shows a phenomenal increment of 3.7% on SMAP; 4% on MSL compared to the next-best baseline model GRELEN[33]. Similarly, our method attains the best performance and reports a high recall and F1 score of 99.07% and 99.23% on SMAP; 97.11% and 96.84% on MSL, respectively. Further, in the multi-fault anomaly detection task on the Tennessee Eastman simulated datasets, the HgAD model surpasses the baseline models on fault detection rate(FDR, [9]). In particular, the HgAD model outperforms the next-best baseline models by a large margin on the identification of faults 3, 5, 9, and 10 with a remarkable improvement of 31.2%, 23.81%, 29.07%, and 27.09%, respectively. Likewise, on faults 15, 16 and, 19, the HgAD model shows an increment of 19.6%, 23.5%, 21.89% over the succeeding-best baseline models, respectively. In addition, on the HAI dataset, the HgAD model reports relative improvements of 18.1% in the precision score, 14.4% in the recall, and 15.3% in the F1 score. In brief, our method showed impressive improvements and demonstrated its potential to detect anomalous events on unbalanced and high-dimensional datasets of great relevance to industry. We generated and verified the results of the baseline models from [30, 7, 6, 9]."}, {"title": "3.6 Ablation studies", "content": "We perform ablation studies to provide insights into the relative contribution of the different architec- tural modules of our proposed method for the improved overall performance of the HgAD model. We gradually exclude or substitute the modules to design several variants of our proposed method. We examine the variant's performance compared to the HgAD model on all the datasets. (a) We study the efficacy of the hypergraph structure learning module in modeling the complex relational dependencies among the multiple IoT sensors in the multisensor data. We utilize the HgSL module to construct the k-uniform nearest neighbor hypergraph (k-uniform NNHg) representation of the multisensor data. We refer to the HgAD model realized with the following limiting scenarios of structure modeling as follows,\n\u2022 w/ 2-graph: HgAD model with 2-uniform NNHG(the hyperedges have the same cardinality of size 2).\n\u2022 w/ irr-hypergraph: HgAD model with irregular hypergraph(hyperedges have different cardinality) computed through the Gumbel-softmax sampling technique[6].\nAs shown in , we notice a drop in the performance of the variants compared to our proposed method. The HgAD model significantly outperforms the variants(w/ 2-graph, w/ irr-hypergraph),"}, {"title": "3.7 Root-cause analysis", "content": "The traditional data-driven modeling approaches lack explicit contextual information to identify the cause of anomalies obtained from several interdependent systems. Here, we present our approach for uncovering the prominent substructures underlying the hypergraph-structured data for anomaly diagnosis underneath the model predictions. The hypernodes define computation hypergraphs based on their local network neighborhoods inferred from the learned hypergraph representation of the complex sensor networks. The computation hypergraphs obtained from the subhypergraphs explain the root-cause analysis. The abnormality events detected at the hypernodes will traverse along their respective computational hypergraphs via the top-bottom approach. The anomaly information propagates from the root hypernode(deviating sensor) through the intermediate hypernodes all the way to the leaf hypernodes(k-hop or k-order proximities). k is pre-determined by the user or fixed by the algorithm. In summary, the module presents a bifold approach. It identifies the hypernode deviating from the learned normality relationship with a high anomaly score. Highlights the salient regions of substructures through the computational hypergraphs to diagnose the anomalies underlying the abnormal system."}, {"title": "3.8 Prescriptive analytics", "content": "Anomalies have cascading effects on the overall performance of large-scale systems. We present an offline, hypergraph-based predictive control(HgPC) module to learn the optimal control policy through solving a single-objective optimization task to offset an anomaly. The module predicts the sequence of the manipulated variable, i.e., hypernode(deviating sensor) values so that the proposed framework predicts normal behavior of the system or falls-inline with the expected behavior. We leverage genetic algorithms(GAs) to recommend optimal actions."}, {"title": "3.9 Case study", "content": "We conduct a case study involving an anomaly with a known deviation behavior. A subunit of WADI consists of a flow-rate manipulator 1_MV_001_STATUS and a flow indicator trans- mitter 1_FIT_001_PV. Consider the first-anomaly scenario(refer to documentation) for the 1_MV_001_STATUS. The HgED module predicted an increase as 1_FIT_001_PV shoot-ups. The learned-normality relationship suggests that the variables are positively correlated. Due to the adver- sarial attack, no abrupt change was observed in 1_MV_001_STATUS and thus leading to a high forecast error. We predict based on the high anomalous score 1_MV_001_STATUS as the deviation-sensor. From the computation hypergraph, we infer that the 1_FIT_001_PV was under malicious attack. The process-plant operations advisor, the HgPC module, suggests reducing the 1_MV_001_STATUS to O to offset the anomaly."}, {"title": "4 Conclusion", "content": "We present a scalable, domain-agnostic hypergraph framework for anomaly detection on generic multisensor data. The framework incentivizes joint learning of the optimal hypergraph-structure representation, temporal trends, and spatial dependencies in the sensor networks for distinguishing the normal-abnormal instances. We also present the root cause analysis and suggest recommendations for better insights and decisions to remedy the anomalies. The experimental results support our framework efficacy to achieve better performance on the high-dimensional time-series anomaly- detection task."}]}