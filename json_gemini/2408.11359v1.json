{"title": "Hypergraph Learning based Recommender System for\nAnomaly Detection, Control and Optimization", "authors": ["Sakhinana Sagar Srinivas", "Rajat Kumar Sarkar", "Venkataramana Runkana"], "abstract": "Anomaly detection is fundamental yet, challenging problem with practical applica-\ntions in industry. The current approaches neglect the higher-order dependencies\nwithin the networks of interconnected sensors in the high-dimensional time se-\nries(multisensor data) for anomaly detection. To this end, we present a self-adapting\nanomaly detection framework for joint learning of (a) discrete hypergraph structure\nand (b) modeling the temporal trends and spatial relations among the interdepen-\ndent sensors using the hierarchical encoder-decoder architecture to overcome the\nchallenges. The hypergraph representation learning-based framework exploits the\nrelational inductive biases in the hypergraph-structured data to learn the point-\nwise single-step-ahead forecasts through the self-supervised autoregressive task\nand predicts the anomalies based on the forecast error. Furthermore, our frame-\nwork incentivizes learning the anomaly-diagnosis ontology through a differentiable\napproach. It derives the anomaly information propagation-based computational\nhypergraphs for root cause analysis and provides recommendations through an\noffline, optimal predictive control policy to remedy an anomaly. We conduct ex-\ntensive experiments to evaluate the proposed method on the benchmark datasets\nfor fair and rigorous comparison with the popular baselines. The proposed method\noutperforms the baseline models and achieves SOTA performance. We report the\nablation studies to support the efficacy of the framework.", "sections": [{"title": "1 Introduction", "content": "Anomaly detection is a long-standing task that has a wide range of applications in monitoring the\nbehaviors of various dynamical real-world systems, including but not limited to financial markets,\nretail, and e-commerce. Of particular interest in this work is anomaly detection on industrial data for\ndeveloping a framework that automates anomaly detection, identifies the root causes, and provides\nrecommendations to resolve the underlying issues with ultra-low inference times. At a higher\nhierarchical level, large-scale industrial units are complex interaction systems of nonlinear dynamical\nsubunits that operate within the margins of normal optimal conditions(NOCs), i.e., anomaly-free.\nThe subunits with a copious amount of interdependent sensors generate high-dimensional time-\nordered data capturing the collective behavior of subunits, mostly under NOCs. Anomalies are\nrare events. Detecting and identifying the anomalies in the large-scale system monitoring data\nis challenging. Under this scenario, the defacto approach is an unsupervised anomaly detection\ntask on multidimensional data. The goal is to learn the temporal dependencies and the spatial\ncorrelations among the interdependent sensors for modeling normality. Any deviation from such\nlearned relationships suggests the occurrence of abnormality, which is inherently different from\nthe normality patterns. Of late, deep learning-based time series modeling techniques have attracted\ninterest in learning the signatures of abnormality events in high-dimensional time series data. In\nthis vein, traditional deep learning-enabled anomaly detection techniques are the reconstruction-\nbased techniques[18, 35, 27, 36, 16]; the forecasting-based techniques[3, 13, 12, 28]; the density-"}, {"title": "2 Our approach", "content": "Our framework consists of the following modules. (a) The hypergraph structure learning(HgSL)\nmodule learns the underlying higher-order structural patterns of the multisensor data that captures the\ninherent dependency relationships within the network of interconnected sensors. (b) The encoder-\ndecoder(HgED) module operates on the hypergraph topology to learn the hierarchical representations\nthat implicitly encode both the temporal trends and spatial relations among the multiple IoT sensors\nwhile preserving the global topological properties of the hypergraph. The module learns the discrimi-\nnative hypernode-level representations in the (low-dimensional) Euclidean space to distinguish the\nnormal-abnormal instances. (c) The hypergraph forecasting(HgF) module utilizes the hypernode\nrepresentations and predicts the one-step-ahead forecasts of the sensors. (d) The hypergraph devi-\nation(HgD) module flags the probable anomalous events by comparing the expected and observed\ntrends of the sensors. This module utilizes the forecasting error as the criterion for anomaly detection\nand serves as supervisory information for the HgSL module. Figure 1 shows the HgAD framework.\nFurthermore, the framework provides the root cause analysis by viewing the learned hypergraph\ntopology as a computation hypergraph for anomaly information traversal across the interconnected\nnetwork of sensors. The knowledge of the inherent structure plausibly explains the manifestation of\nthe underlying cause when the predicted relationships deviate from the learned normality relationships\nin the hypergraph-structured data. The objective of unsupervised anomaly detection is to predict the\noutput labels $y^{(t)} \\in {0,1}$, which is a two-label prediction task suggesting the anomaly occurrence\nat a time point, t. Note: label = 1 means \"anomaly\" and label = 0 means \u201cnormal\u201d."}, {"title": "2.1 Hypergraph Representation", "content": "Consider a multivariate contiguous time-series data from n variates(sensors) observed over T time\nsteps denoted by $f = [f^{(1)}, ..., f^{(T)}]$. $f^{(t)} \\in R^{n}$ represents the n-variates observations at time step t,\nwhich form an n-dimensional vector. We generate fixed-length inputs by a sliding window of length\nw over historical data as input to our framework to learn from the multisensor data. The windowed\ndata at time t, $F^{(t)} \\in R^{n \\times w}$ is given by $F^{(t)} = [f^{(t-w)}, f^{(t-w+1)}, . . ., f^{(t-1)}]$. The interconnected\nsensors do not have an explicit higher-order relational structure underlying the multisensor data. We\nutilize a hypergraph framework for a structured representation of the data. The hypergraph structured\ndata offers a natural way to abstract the complex interdependencies among the sensors. We denote the\nsensors as the hypernodes of the dynamic bidirected hypergraph. The bidirectional hyperedges model\nthe super-dyadic relations among the hypernodes. We obtain spatiotemporal hypergraph data with\ntime-varying hypernode features. The hypernode, hyperedge set, and hypergraph structure remain\nunchanged. Figure 2 illustrates the hypergraph representation of the network of interconnected\nsensors."}, {"title": "2.2 Hypergraph Structure Learning(HgSL)", "content": "The traditional methods[8, 31] operate on the prior known explicit structure to learn from the\nhypergraph-structured data. In practice, however, the real-world applications present challenging\nscenarios where the higher-order structural dependencies in networks underlying the interdependent\nsensors is unknown, incomplete, or partially available due to limited prior knowledge. The HgSL\nmodule offers a structural modeling approach to dynamically optimize the sensor topology and\nimplicitly learn the task-relevant relational structure from the hypernode(sensor) embeddings. The\noptimal sensor topology captures the complex hidden relations among the interdependent sensors. We\nperform inference on the hypergraph-structured multisensor data through the hypergraph representa-\ntion learning on the downstream anomaly detection task driven by the inductive-learning approach.\nThe hypernodes of the hypergraph had characterized by learnable (low-dimensional) embeddings\n$z_{i}, 1 \\leq i \\leq n$. The hypernode embeddings $z_{i} \\in R^{d}$ are continuous vector representations in the\nd-dimensional embedding space. We will form a directed hyperedge from hypernode i by connecting\nwith its k-nearest hypernodes. In essence, the hyperedge connects the hypernodes i and j; if j is\namong the k-closest local-hypergraph neighbors of i. We obtain n (in this setting, m = n) hyperedges\nthat are incident with k + 1 non-repeating hypernodes of the hypergraph. We accomplish this by\nlearning a sparse symmetric hypergraph incidence matrix H in which n \u00d7 (k + 1) elements are equal\nto 1 while the rest are zero. We achieve this by computing the pairwise Euclidean distance of the\nhypernodes using their embeddings to learn the similarity measure. It is described by,\n$$d_{i,j} = (\\sum_{ind=1}^{d} |z_{ind} - z_{ind}|^{2})^{1/2}; i \\in {1, ..., n},i \\neq j$$"}, {"title": "2.3 Hypernode Positional Encoding(HPE)", "content": "There exists no canonical ordering of the hypernodes in the hypergraph. We encode hypernode\npositional information to enable position awareness[6]. The positional embeddings, $PE \\in R^{n \\times w}$,\nhave been linearly added to the feature matrix $F^{(t)} \\in R^{n \\times w}$ to inform the model about the positional\ninformation of the hypernodes from the main hypergraph. The HPE module generates the positional\nembeddings based on the local and global neighbors of each hypernode."}, {"title": "2.4 Hypergraph Encoder-Decoder(HgED)", "content": "We will first discuss the Hypergraph Convolutional Neural Network(HgCNN), Hypergraph Local-\nPooling(HgPool), and Hypergraph UnPooling(UnHgPool) operators. We then elaborate on the HgED\nmodule in great detail."}, {"title": "2.4.1 Hypergraph Convolutional Neural Network(HgCNN)", "content": "The HgCNN operator generalizes the convolution operation to the hypergraphs. It presents the neural\nnetwork primitives that compute the hypernode representations $X_{v_{i}}, 1 \\leq i \\leq n$, where $x_{v_{i}} \\in R^{d}$.\nWe obtain hypernode-level representations through propagating, aggregating, and transforming the\nhypernode-level feature information on the hypergraph topology to learn from the sensor-based\ninformation. It performs a spatial-hypergraph filtering operation in two phases. At first, given\nthe incidence matrix $H \\in R^{n \\times n}$ and hypernode feature matrix $F^{(t)} \\in R^{n \\times w}$. We determine\nthe hyperedge attribute matrix $X_{e_{p}}^{(t)} \\in R^{n \\times d}$. The row-vectors in $X_{e_{p}}^{(t)} X_{e_{p}}^{(t)}$ denote the hyperedge\nrepresentations $x_{e_{p}}^{(t)} \\in R^{d}, 1 < p < n$ and are computed by aggregating the attention-weighted\nfeatures of the incident hypernodes obtained as,\n$$x_{e_{p}}^{(t)} = \\sigma(\\sum_{i \\in N_{p}} \\alpha_{p, i}, W_{1}F_{i}^{(t)})$$"}, {"title": "2.4.2 Hypergraph Local-Pooling(HgPool)", "content": "We present a two-fold approach-based differentiable local-hypergraph pooling operator to (1) induce\nsubhypergraphs by reducing the order and size of the main hypergraph to obtain a pooled hypergraph\nand (2) learn the hierarchical representations of the hypernodes by encoding the dominant structural\ncharacteristics of the hypergraph. The prominent steps in a downsampling technique based local-\nhypergraph pooling mechanism are (a) computing the measure for performing down-sampling on\nthe hypergraph to obtain the pooled hypergraph by dropping fewer hypernodes of lower importance"}, {"title": "2.4.3 Hypergraph UnPooling(UnHgPool)", "content": "In contrast, the hypergraph unpooling operator performs the inverse operation for the local- and\nglobal-neighborhood enlargement by upsampling the pooled hypergraph $G^{(t)}$ to the original hy-\npergraph structure $G^{(t)}$. The UnHgPool operator utilizes the indices of the hypernodes selected\nby the HgPool operator to restore the high-resolution hypergraph topology. Figure 7 illustrates\nthe upsampling operation on the pooled hypergraph. The forward propagation of the hypergraph\nunpooling mechanism given by,\n$$\\widetilde{X}^{(t)} = addition(0^{(t)}, X^{(t)}, idx^{(t)})$$"}, {"title": "2.5 Hypergraph-Forecasting(HgF)", "content": "The hypergraph forecasting module predicts the multi-sensor values at time step t, i.e., $f^{(t)} \\in R^{n}$.\n$$f^{(t)} = f_{\\theta} ([Z_{1}x_{v_{1}}^{(t)}... Z_{n} x_{v_{n}}^{(t)}])$$"}, {"title": "2.6 Hypergraph-Deviation(HgD)", "content": "The HgD module in the unsupervised anomaly detection task computes the robust normalized anomaly\nscores($A_{i}^{(t)}$). This information regarding the sensors help in accurately localizing the anomalies\nwithin the multisensor data in the temporal domain.\n$$A_{i}^{(t)} = \\frac{dev_{i}^{(t)}}{\\widetilde{\\sigma_{i}}}; dev_{i}^{(t)} = |f^{(t)} - \\widehat{f}^{(t)}|$$"}, {"title": "3 Experiments and results", "content": "We demonstrate and support the effectiveness of our proposed method in comparison to the baseline\napproaches by investigating the following research questions:"}, {"title": "3.1 Benchmark Datasets", "content": "To probe the efficacy of our proposed method on anomaly detection, we evaluate our framework\non a variety of publicly available datasets for competitive benchmarking with the baseline methods.\nTable 1 summarizes the characteristics of the varied datasets used in this study. The SWaT and\nWADI\u00b3 are real-world datasets on water treatment facilities and distribution networks. SMAP and\nMSL are expert-labeled open-sourced datasets of telemetry data from NASA[12]. The Tennessee\nEastman process(TEP)4 is a simulated industrial benchmark dataset for process monitoring and\ncontrol. It contains 20 different faults. The HAI is a time-series dataset of a realistic industrial\ntestbed of steam-turbine power generation and pumped-storage hydropower generation. It contains\n38 different attack scenarios."}, {"title": "3.2 Experimental setup", "content": "We perform min-max scaling on all the datasets to rescale variables into the range [0,1]. We train\nthe model for 100 epochs with a batch size of 48 on multiple NVIDIA Tesla T4 GPUs in all the\nexperiments. We optimize using Adam optimizer with initial learning rate(lr) set as 0.001 and\n(\u03b21, \u03b22) =(0.9,0.99). We implement the early-stopping technique and adopt the Ir adjusting strategy\nto decay the learning rate by half with the patience of 10 epochs on the validation set. We conduct\nfive different experimental runs and report the mean values of the evaluation metrics obtained on the\ndifferent experimental run outputs across all the datasets."}, {"title": "3.3 Model configurations", "content": "The hypernode embeddings($z_{i}$) and representations($x_{v_{i}}^{(t)}$) dimensions have a fixed size(d) of 128 for\nall the datasets. We report, in Table 1, the optimal sliding window size(w) and the number of nearest\nneighbors(k) used in this study across the datasets."}, {"title": "3.4 Evaluation Metrics", "content": "We evaluate and report the performance of our model on the test set across all the benchmark datasets.\nWe report the model performance in terms of the standard evaluation metrics such as precision(P\nas %), recall(R as %), and F1-score(F1 as%) for a fair and rigorous comparison with the baseline\nmodels. We utilize the maximum anomaly score(refer to section 2.6) over the validation dataset to set\nthe threshold to identify anomalies. For SWaT and WADI datasets, there exist contiguous anomaly\nsegments. We had adopted the point adjustment strategy[24, 34] to flag the entire time segment as an\nanomaly if the model predictions within this subset window had detected an anomaly."}, {"title": "3.5 Results", "content": "We compare the HgAD model with state-of-the-art methods for multivariate time-series anomaly\ndetection on all the datasets. Tables 2 and 3 present the performance of the baseline models in\ncomparison with our proposed method. The results show that the HgAD model outperforms the\nbaseline models and attains significant gains consistently across the evaluation metrics on all datasets.\nOn SWaT and WADI datasets, the proposed method demonstrates relatively the best performance\nwith a high precision score of 97.48% on SWaT and 98.75% on WADI. The HgAD model brings\na moderate 2% and 1.3% improvement in the precision score compared to the GRELEN[33] and\nGDN[7] on SWaT and WADI datasets, respectively. In terms of recall and F1-measure, the HgAD\nmodel surpasses the previous state-of-the-art baselines and reports a percentage increase of 2.2%\nand 3.9% on SWaT; 1.7%, 10.65% on WADI over the successive-best baseline models GTA[6],\nGRELEN[33] and GTA[6], MTAD-GAT[34] respectively. On SMAP and MSL datasets, the HgAD\nmodel unsurprisingly outperforms the baseline models and reports the highest scores on all the\nevaluation metrics. In terms of precision score, the HgAD model shows a phenomenal increment of\n3.7% on SMAP; 4% on MSL compared to the next-best baseline model GRELEN[33]. Similarly, our\nmethod attains the best performance and reports a high recall and F1 score of 99.07% and 99.23%\non SMAP; 97.11% and 96.84% on MSL, respectively. Further, in the multi-fault anomaly detection\ntask on the Tennessee Eastman simulated datasets, the HgAD model surpasses the baseline models\non fault detection rate(FDR, [9]). In particular, the HgAD model outperforms the next-best baseline\nmodels by a large margin on the identification of faults 3, 5, 9, and 10 with a remarkable improvement\nof 31.2%, 23.81%, 29.07%, and 27.09%, respectively. Likewise, on faults 15, 16 and, 19, the HgAD\nmodel shows an increment of 19.6%, 23.5%, 21.89% over the succeeding-best baseline models,\nrespectively. In addition, on the HAI dataset, the HgAD model reports relative improvements of\n18.1% in the precision score, 14.4% in the recall, and 15.3% in the F1 score. In brief, our method\nshowed impressive improvements and demonstrated its potential to detect anomalous events on\nunbalanced and high-dimensional datasets of great relevance to industry. We generated and verified\nthe results of the baseline models from [30, 7, 6, 9]."}, {"title": "3.6 Ablation studies", "content": "We perform ablation studies to provide insights into the relative contribution of the different architec-\ntural modules of our proposed method for the improved overall performance of the HgAD model.\nWe gradually exclude or substitute the modules to design several variants of our proposed method.\nWe examine the variant's performance compared to the HgAD model on all the datasets. Table 4\nshows the performance comparison results of the HgAD model and its variants in the ablation studies.\n(a) We study the efficacy of the hypergraph structure learning module in modeling the complex\nrelational dependencies among the multiple IoT sensors in the multisensor data. We utilize the HgSL\nmodule to construct the k-uniform nearest neighbor hypergraph (k-uniform NNHg) representation of\nthe multisensor data. Please refer to subsection2.2. We refer to the HgAD model realized with the\nfollowing limiting scenarios of structure modeling as follows,\n\u2022 w/ 2-graph: HgAD model with 2-uniform NNHG(the hyperedges have the same cardinality\nof size 2).\n\u2022 w/ irr-hypergraph: HgAD model with irregular hypergraph(hyperedges have different\ncardinality) computed through the Gumbel-softmax sampling technique[6].\nAs shown in Table 4, we notice a drop in the performance of the variants compared to our proposed\nmethod. The HgAD model significantly outperforms the variants(w/ 2-graph, w/ irr-hypergraph),"}, {"title": "3.7 Root-cause analysis", "content": "The traditional data-driven modeling approaches lack explicit contextual information to identify the\ncause of anomalies obtained from several interdependent systems. Here, we present our approach\nfor uncovering the prominent substructures underlying the hypergraph-structured data for anomaly\ndiagnosis underneath the model predictions. The hypernodes define computation hypergraphs based\non their local network neighborhoods inferred from the learned hypergraph representation of the\ncomplex sensor networks. The computation hypergraphs obtained from the subhypergraphs explain\nthe root-cause analysis. The abnormality events detected at the hypernodes will traverse along\ntheir respective computational hypergraphs via the top-bottom approach. The anomaly information\npropagates from the root hypernode(deviating sensor) through the intermediate hypernodes all the\nway to the leaf hypernodes(k-hop or k-order proximities). k is pre-determined by the user or fixed\nby the algorithm. In summary, the module presents a bifold approach. It identifies the hypernode\ndeviating from the learned normality relationship with a high anomaly score. Highlights the salient\nregions of substructures through the computational hypergraphs to diagnose the anomalies underlying\nthe abnormal system."}, {"title": "3.8 Prescriptive analytics", "content": "Anomalies have cascading effects on the overall performance of large-scale systems. We present an\noffline, hypergraph-based predictive control(HgPC) module to learn the optimal control policy\nthrough solving a single-objective optimization task to offset an anomaly. The module predicts the\nsequence of the manipulated variable, i.e., hypernode(deviating sensor) values so that the proposed\nframework predicts normal behavior of the system or falls-inline with the expected behavior. We\nleverage genetic algorithms(GAs) to recommend optimal actions."}, {"title": "3.9 Case study", "content": "We conduct a case study involving an anomaly with a known deviation behavior. A subunit\nof WADI consists of a flow-rate manipulator 1_MV_001_STATUS and a flow indicator trans-\nmitter 1_FIT_001_PV. Consider the first-anomaly scenario(refer to documentation) for the\n1_MV_001_STATUS. The HgED module predicted an increase as 1_FIT_001_PV shoot-ups. The\nlearned-normality relationship suggests that the variables are positively correlated. Due to the adver-\nsarial attack, no abrupt change was observed in 1_MV_001_STATUS and thus leading to a high forecast\nerror. We predict based on the high anomalous score 1_MV_001_STATUS as the deviation-sensor.\nFrom the computation hypergraph, we infer that the 1_FIT_001_PV was under malicious attack.\nThe Figure9 shows the model sensor forecasts. The process-plant operations advisor, the HgPC\nmodule, suggests reducing the 1_MV_001_STATUS to O to offset the anomaly. Figure10 shows the\nsubhypergraph to explain the root-cause analysis."}, {"title": "4 Conclusion", "content": "We present a scalable, domain-agnostic hypergraph framework for anomaly detection on generic\nmultisensor data. The framework incentivizes joint learning of the optimal hypergraph-structure\nrepresentation, temporal trends, and spatial dependencies in the sensor networks for distinguishing\nthe normal-abnormal instances. We also present the root cause analysis and suggest recommendations\nfor better insights and decisions to remedy the anomalies. The experimental results support our\nframework efficacy to achieve better performance on the high-dimensional time-series anomaly-\ndetection task."}]}