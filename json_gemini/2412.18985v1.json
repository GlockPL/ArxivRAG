{"title": "TRAVELAGENT: GENERATIVE AGENTS IN THE BUILT ENVIRONMENT", "authors": ["Ariel Noyman", "Kai Hu", "Kent Larson"], "abstract": "Understanding human behavior in built environments is critical for designing functional, user-centered urban spaces. Traditional approaches\u2014such as manual observations, surveys, and simplified simulations\u2014often fail to capture the complexity and dynamics of real-world behavior. To address these limitations, we introduce TravelAgent, a novel simulation platform that models pedestrian navigation and activity patterns across diverse indoor and outdoor environments under varying contextual and environmental conditions. TravelAgent leverages generative agents integrated into 3D virtual environments, enabling agents to process multimodal sensory inputs and exhibit human-like decision-making, behavior, and adaptation. Through experiments, including navigation, wayfinding, and free exploration, we analyze data from 100 simulations comprising 1,898 agent steps across diverse spatial layouts and agent archetypes, achieving an overall task completion rate of 76%. Using spatial, linguistic, and sentiment analyses, we show how agents perceive, adapt to, or struggle with their surroundings and assigned tasks. Our findings highlight the potential of TravelAgent as a tool for urban design, spatial cognition research, and agent-based modeling. We discuss key challenges and opportunities in deploying generative agents for the evaluation and refinement of spatial designs, proposing TravelAgent as a new paradigm for simulating and understanding human experiences in built environments.", "sections": [{"title": "1 Introduction", "content": "Human behavior in urban environments is central to the design of spaces that are functional, inclusive, and responsive to the diverse needs of their users [Gehl, 2010, Jacobs, 1961, Whyte, 1980]. These behaviors shaped by a complex interplay of spatial configurations, visual stimuli, social dynamics, and individual preferences [Whyte, 1980]. This wide range of factors makes it challenging to asses how people will navigate, interact, and experience urban spaces, particularly in early design stages [Hillier and Hanson, 1984, Batty et al., 2000].\nThroughout the design process, architects, urban planners, city officials, and stakeholders often rely on a variety of methods to evaluate the impact of design decisions on human behavior [Gehl, 2010, Batty and Yang, 2022]. These include manual observations, surveys, focus groups, and computational simulations and visualizations [Noyman, 2022, Banerjee and Loukaitou-Sideris, 2011]. While these methods offer valuable insights, they often fall short of capturing the full complexity of human experience in real-world settings [Perez et al., 2016]. Manual observations are time-consuming and limited in scope, and surveys and focus groups may not fully represent the diversity of user"}, {"title": "1.1 Background", "content": "Building upon recent advancements in generative models, we aim to bridge the gap between urban simulations, ABM, and cognitive analysis of built spaces. Here we introduce TravelAgent (TA), a simulation platform that leverages Generative Agents (GA) to model and analyze human-like behavior and experiences in built environments. TravelAgent enables computational agents to explore, navigate, observe, and interact with their surroundings from a human perspective. Unlike traditional simulations that rely on predefined logic or pre-trained behavioral models [Chopra et al., 2024], TA incorporates cognitive principles such as spatial memory, visual perception, and context-based reasoning to facilitate autonomous decision-making [Wei et al., 2023]. We present the TA platform, a web-based tool designed to allow spatial designers to easily simulate pedestrian navigation tasks or open-ended exploratory activities, in various interior and exterior spaces under different environmental conditions.\nTravelAgent contributes to the field of urban simulation in the following ways: (i) It introduces an accessible interface for simulating behaviors ranging from routine navigation tasks to open-ended exploratory activities, and applicable across scales, from early-stage, schematic urban-planning to detailed, room-scale interior layouts. (ii) It provides data and analysis of 100 simulations with 1,898 steps,ranging across various settings, environments, and agent archetypes, achieving a task completion rate of approximately 75%. (iii) It offers a comprehensive analysis of the agents' behaviors, decision-making processes, and adaptability to unforeseen circumstances, and proposes a novel approach to evaluate and refine spatial designs based on human-like behaviors and experiences."}, {"title": "1.2 TravelAgent: Generative Agents Simulation in Urban Environments", "content": "Agent-Based Models (ABMs) are computational models that simulate the actions and interactions of agents in a given computational environment [Bonabeau, 2002]. ABMs are widely used in urban simulation to study complex systems, such as traffic flow, pedestrian dynamics, or infrastructural efficiency [Chen, 2012, Batty and Yang, 2022]. Generative Agents (GA) are a new class of Large Language Models (LLM), that preform multi-step tasks in response to natural language prompts [Wei et al., 2023, Park et al., 2023]. In this study, 'TravelAgent' (TA), refers to a platform combining Generative Agents (GA) with Agent-Based Modeling (ABM) to simulate agent behavior in built environments. Here, 'agent' denotes the simulated entity of an eye-level computational actor in 3D environments, while 'simulation' pertains to the process of generating and observing the agent behavior. The platform leverages \u2018sensory inputs' which are different data steams perceived by agents to interact with their surroundings, and 'cognitive streams', the structured representations of agents' thoughts, observations, and actions throughout the simulations."}, {"title": "1.3 Terminology", "content": "The remainder of this paper is organized as follows: Section 2 provides an overview of related work in spatial cognition, agent-based modeling, and pedestrian experience in urban design. Section 3 describes the methodology and implementation of the TravelAgent platform, including agent simulation, sensory inputs, and data collection. Section 4 presents several case studies of TravelAgent in different environments. Section 5 discusses the results and analysis of the case studies, and Section 6 concludes with a summary of the contributions, potential impact, and future directions of TravelAgent."}, {"title": "1.4 Paper Organization", "content": "Understanding human behavior in urban environments is a complex challenge that intersects multiple disciplines, including urban planning, spatial cognition, and computational modeling. This section reviews the key areas of research that inform the development of the TA platform, particularly focusing on the integration of computational models in simulating human behavior in the built environment."}, {"title": "2 Related Work", "content": "The importance of human-centered design principles, such as walkability, accessibility, and public space quality, has been widely recognized in shaping successful built environments [Jacobs, 1961, Gehl, 2010, Lynch, 1960, Banerjee and Loukaitou-Sideris, 2011, Ameli et al., 2015]. The integration of new technologies has enabled designers to better evaluate urban interventions in immersive ways, enhancing design processes, stakeholder engagement, and decision-making [Batty et al., 2000, Billger et al., 2017, Yin, 2017, Shen et al., 2018]. Computerized models, simulations, and visualizations can clarify the outcomes of design choices, including building design and spatial configurations [Smith et al., 1998, Batty et al., 2000]. Nevertheless, these digital design aids cannot fully embrace the nature of human behavior in built environments. Often, these tools are only accessible to few experts and fewer stakeholders; even when available, they tend to represent a highly-curated vision of the design, lacking actual interaction and experience [Lin et al., 2013, Tabrizian et al., 2020, Banerjee and Loukaitou-Sideris, 2011]. Newer technologies, such as virtual, augmented, or mixed reality (VR, AR, MR), have the potential to bridge this gap by providing more immersive and interactive experiences for urban design and planning [Batty and Yang, 2022]; however, these tools are often limited to a single user or small group, and require specialized equipment and expertise [Fonseca et al., 2016], making them less accessible for widespread use in urban design and planning. In that context, the problem of simulating human experience in urban environments remains an open challenge, as traditional methods are often limited in scope, scale, and realism [Batty and Yang, 2022, Banerjee and Loukaitou-Sideris, 2011, Gath-Morad et al., 2024]."}, {"title": "2.1 Human Experience in Urban Design and City Planning", "content": "Spatial cognition studies how humans perceive, interpret, and navigate physical spaces [Montello, 1993, Golledge, 1999]. Research in this area emphasizes the importance of environmental cues, such as landmarks, signage, and spatial configurations, in facilitating wayfinding and orientation [Javadi et al., 2017, Epstein et al., 2017, Gehl, 2010, Jacobs, 1961, Lynch, 1960]. Empirical studies have demonstrated that humans rely on a combination of egocentric (self-to-object) and allocentric (object-to-object) representations when navigating unfamiliar environments [Burgess, 2006, Klatzky, 2008, Mou et al., 2004]. Cognitive maps-mental representations of physical spaces- are constructed through experience and are essential for efficient navigation and spatial memory [Burgess et al., 2017, Epstein et al., 2017]. Advances in neuroimaging and computational modeling have provided new insights into the mechanisms underlying spatial cognition, memory, and navigation [Epstein et al., 2017]. Controlled settings, including the usage of immersive technologies, have also been employed to study spatial cognition, providing valuable data for design and planning [Batty and Yang, 2022, Gath-Morad et al., 2024]. Incorporating principles of spatial cognition into computational models can enhance the realism of simulated agents, allowing them to exhibit human-like navigation behaviors [Milivojevic and Doeller, 2013, Epstein, 1999]."}, {"title": "2.2 Spatial Cognition and Human Navigation", "content": "Agent-Based Modeling (ABM) has been instrumental in urban simulation, enabling researchers to model the actions and interactions of agents within controlled environments [Bankes, 2002, Batty and Yang, 2022]. ABMs have been applied to a wide range of urban studies, including traffic flow analysis [Nguyen et al., 2021, Grignard et al., 2018], pedestrian dynamics [Filomena and Verstegen, 2021], and urban policy evaluation [Perez et al., 2016]. However, traditional ABMs often rely on deterministic heuristics and predefined behavioral rules [Railsback and Grimm, 2019], limiting their ability to capture the complexity and variability of human behavior [Zhang et al., 2024, Epstein, 1999]. Recent research suggested integrating ABMs with machine learning techniques, such as Reinforcement Learning (RL) and Neural Networks (NN) [Kobayashi et al., 2023, Li et al., 2020], to model more adaptive behaviors. Yet, these approaches typically require extensive data, training, and validation and can be computationally intensive [Chopra et al., 2024]. Even when combined with NN, the challenge remains in simulating agents that performs beyond their intrinsic heuristics or learnt distribution; These models will most likely fail to response to unpredictable and complex environmental stimuli [Chen et al., 2019]."}, {"title": "2.3 Agent-Based Modeling in Urban Simulation", "content": "The emergence of Large Language Models (LLMs) has opened new avenues for simulating human-like behavior through natural language and generative agents [Park et al., 2023]. These models process natural language inputs and generate contextually relevant responses, enabling more sophisticated interactions between agents and their environments [Chopra et al., 2024]. By integrating GA with perception modules such as computer vision, agents can interpret and respond to complex environmental stimuli [Reid et al., 2024]. In the context of urban simulation, combining LLMs with agent-based models enables agents that can navigate and interact with physical environments [Yang et al., 2025]. These agents can process visual inputs, maintain spatial memory, and make decisions based on prior knowledge and real-time"}, {"title": "2.4 Generative Agents (GA)", "content": "TravelAgent is a web platform that allows spatial designers to create, simulate, and analyze Generative Agents in built environments. The platform consists of three main components: (i) a 3D environment, (ii) sensory inputs, and (iii) a Chain-of-Thought (CoT) reasoning framework, as shown in Fig. 1. TA experiments are designed as follows:\nEnvironment: The agent roams a rudimentary 3D environment, which could be created using any common modeling tool with minimal details. An image generation diffusion model generates realistic street-level images from the basic 3D model to serve as input for the agent visual observation. As described in Fig. 3, the 3D model contains objects that are semantically segmented, so that a class-guided image generation model can reference them when generating first-person images [Podell et al., 2023]."}, {"title": "3 Methodology", "content": "Agent Initialization: Agents are initialized with a set of parameters, which can range from simple properties to complex characters and environments. At minimum, these settings include the agent's starting location, orientation, environment description, number of allowed simulation steps, and task objectives. The agent's memory can be initialized as an empty set or can contain certain priors, for example - to reference a known environment. The agent's task is defined as a set of objectives in natural language, such as reaching a destination, finding an object, or free roaming for exploration, for example - visiting a museum gallery.\nSimulation Steps: At each step, the agent collects 'sensory inputs' from the environment, such as street-level images, segmentation maps, discovery map, and memory, as described in Sec. 3.2. The agent then processes these inputs using the CoT framework, first as observation, then as planning, and finally as action or decision. After making a decision, the agent executes it using a key-value pair response (i.e \"move forward\", \"turn right\", \"finish\") and a length parameter (i.e. \"move 1 meter\"). Table 6.3 provides an example of the agent's interactions and decisions in several simulation steps. As shown in Fig.8, simulation steps might vary in length and impact. For example, a more 'certain' agent might decide to move forward 50 meters in one step, when another might slightly turn left or right to look for its goal. At the end of each step, the agent updates its memory, and repeats the process until the task is completed or the simulation ends."}, {"title": "3.1 Agent Simulation", "content": "TravelAgents interact with the environment through a variety of sensory inputs, including visual cues, spatial memory, and prior knowledge. These inputs are designed to mimic pedestrian eye-level perception and decision-making processes, without the usage of navigation algorithms or top-down maps. The following sensory inputs are provided to the agent at each step of the simulation:\nVisual Perception: TA uses computer vision to process visual information, such as object detection, scene segmentation, and depth estimation. We have explored a verity of image recognition models, such as YOLO, Mask2Former, and OpenAI's GPT [Redmon et al., 2015, Achiam et al., 2023, Cheng et al., 2021]. Despite the advancements in image recognition, the agent's image-to-text inference is still abstract, and the textual information sometimes lacks the nuance and context needed for complex decision-making. To address these shortcomings, depth and collision information is provided via ray-casting, which the agent emits from their camera's viewpoint to nearby objects in the scene. This information is returned as class labels ('a wall', 'a tree') and values ('front: 2 meters')."}, {"title": "3.2 Sensory Inputs", "content": "Discovery Map: In early experiments, agents tended to revisit previously explored locations unintentionally. To mitigate this, we introduced a 'Discovery Map' that provides a top-down view of the environment, indicating the agent's current location, orientation, and previously-explored areas. The Discovery Map updates with each movement, reflecting the agent's new position and the areas it has already traversed. The map is incorporated into the Chain-of-Thought (CoT) as part of the agent's sensory inputs. Unlike traditional ABM, the Discovery Map is not used as an explicit pathfinding or navigation algorithm but serves only as a visual reference to the agent's spatial memory.\nCompass: In scenarios where the agent is assumed to have prior familiarity with the environment or possesses some navigational aid (such as a person holding a GPS enabled cellphone), a compass-like navigation cue provides general guidance. As shown in Fig. 2, this compass is displayed at the bottom of the agent's field of view and is provided to the agent's Chain-of-Thought (CoT) framework as part of the image inference process. The compass can be omitted to simulate a completely unfamiliar environment, such as visiting a museum gallery for the first time, compelling the agent to rely solely on visual cues and spatial memory for navigation. As with the Discovery Map, the agent is not forced to navigate using the compass, and can alter its path as needed, as discussed in Section 5.3.\nSpatial Memory: TA maintains a spatial memory of the environment, which is updated at each step. This memory encapsulates the agent's past experiences, including visited locations, observed objects, and navigational cues. The memory is stored in a compressed textual format, representing the agent's accumulated knowledge and experiences, and can be used to initialize new agents in future simulations, providing continuity and context. As discussed in Section 5, the agent's memory can be analyzed to understand the agent's behavior, experiences, and decision-making processes. Despite this verity of sensory inputs, human perception of physical environments is complex and multifaceted [Kim, 1999], and the agent's ability to interpret and respond to these inputs is limited by its current inference capabilities. With the advancement of multimodal models [Reid et al., 2024], future iterations of TA should explore wider range of sensory inputs, such as audio cues and social interactions, to enhance the realism and complexity of the agent's experiences."}, {"title": "4 Case Studies", "content": "To facilitate experimentation, we developed an easy to use web-based platform that enables agent creation and evaluation. We utilized this platform to conduct a series of experiments in various settings, including both interior and exterior spaces, to evaluate the effectiveness of TAs in simulating human behavior. This section presents the conducted experiments, with the results and analysis discussed in Section 5."}, {"title": "4.1 Early Experiments", "content": "Exterior - Lunch Break in Kendall Square: An early experiment evaluated the agent's ability to navigate and make decisions in real-world environments. The scenario involved simulating a student's search for a shaded lunch spot in Kendall Square, Cambridge, MA. Without a map or predefined route, the agent relied on visual cues and memory to navigate, simulating an unfamiliarity with the area. Google Street View (GSV) images were used to represent the agent's point of view. As shown in Fig. 4, at each step the agent is presented with a new GSV image and is asked to make decisions based on visual information, memory, and task requirements.\nThe use of GSV images provided realistic streetscapes but introduced certain challenges. The agent's visual perception was limited, as GSV is primarily captured from the center of the road and not in pedestrian areas. Additionally, navigation cues such as depth, distance, and collision warnings were challenging to produce, as GSV does not provide detailed object segmentation or depth information. Furthermore, GSV data cannot be easily modified to present different scenarios or environments, such as design iterations, varying seasons, times of day, or weather conditions, limiting the experiment's flexibility and scalability.\nInterior - Laboratory Exploration: In a subsequent experiment, we simulated a navigation task within a laboratory environment. Unlike GSV, this experiment utilized a detailed 3D model of a lab, featuring specific elements such as rooms, elevators, staircases, and lab equipment. Here, the agent was tasked with meeting a colleague in a public area of the lab. In several iterations, the agent successfully navigated to the designated location but struggled with consistent decision-making and pathfinding, often revisiting the same locations or getting stuck in corners. This experiment highlighted the importance of spatial memory as part of the CoT framework, as well as the need for more detailed and context-specific sensory inputs to facilitate task-driven navigation. These findings led to the design of the sensory inputs detailed in Section 3.2."}, {"title": "4.2 Main Experiment: 'Train Station'", "content": "Building on previous studies, we designed a controlled experiment to evaluate the effectiveness of the Chain-of-Thought (CoT) framework in guiding agent behavior. Here, the primary objective was to simulate a typical daily commute, and assess how well agents could navigate urban environments to reach a designated train station. Unlike earlier experiments, this study emphasized the agent's ability to integrate task objectives with dynamic observations and memory, rather than relying on initial conditions or step-by-step navigation. Agents were provided with no maps and did not follow any shortest-path or predefined navigation routes."}, {"title": "4.2.1 Experiment Design", "content": "The experiment was structured around a consistent urban environment and the same task, but varied across different scenarios, personas, and initial conditions. The environment comprised an urban scene featuring a mix of buildings, streets, urban design elements, and pedestrians, with the task being to navigate to a nearby subway station as part of a daily commute. Each agent received a natural language prompt detailing the agent's persona, time of day, weather conditions, and task requirements. Agent's personas may be as simple as a 'student' or 'researcher', or more complex to include additional attributes such as 'age', 'gender', or certain disabilities (e.g., \u2018wheelchair user'). The personas and scenarios were then combined to create a matrix of 100 experiments. Table 6.3 summarizes the scenarios and table 1 illustrates the associations between season, location, time, persona, and scene. Upon successful completion of its task, the agent was informed that the train service was unavailable, and was subsequently assigned an additional task from this set of sub-tasks:\n\u2022 'If the train is unavailable, find an alternative way to get to work.'\n\u2022 'Buy coffee before work if there's time.'\n\u2022 'Interact with a friend across the street if encountered.'\nThese sub-tasks were designed to evaluate the agent's adaptability to unforeseen circumstances and new information. The agent's action in these sub-tasks is shown as dotted lines in Fig. 5."}, {"title": "4.2.2 Agent Initation", "content": "In this experiment, all agents are aquatinted with their environment. To further reinforce their familiarity, the initiation prompt includes: 'You reside on this street. It is morning, and you are on your way to work. Your objective is to reach the nearby subway station. To reach the station, proceed down the street, then turn left, and it will be on your left. Look for a large 'Subway' sign.' This prompt is designed to provide the agent with a general sense of direction and task objectives, without explicitly guiding them through a predefined path or route. In unfamiliar environments, the agent is provided with a more general prompt, such as \u2018You are visiting this gallery for the first time. You are here to view the new exhibit. Find the exhibit hall and explore the rest of the museum.'"}, {"title": "5 Results", "content": "In this section we present the results of the case studies, focusing on the 'Daily Commute' experiment. We discuss the agent's behavior, decision-making process, and the opportunities and challenges of using TravelAgent."}, {"title": "5.1 Results: Early Experiments", "content": "In the initial experiments (see 4.1), the agent's decisions were primarily influenced by immediate visual stimuli and physical elements recognized by the computer vision model. In all tests, the agent's path was largely determined by early choices, such as its initial direction or its decision at a fork, leading to a deterministic behavior pattern that could not be attributed to any cognitive process. This suggests a strong influence of initial conditions, with limited adaptation to new information, and minimal reliance on memory. To address this, subsequent simulations incorporated and enhanced the CoT, allowing the agent to re-evaluate choices based on updated sensory inputs and environmental cues."}, {"title": "5.2 Results: 'Subway Station'", "content": "In our primary experiment we conducted 100 simulations totaling 1,898 steps. Approximately 76% of the agents successfully completed their tasks within the stipulated step count. The remaining 24% failed to achieve their objectives due to factors such as obstacle encounters or disorientation caused by continuous turning maneuvers. In this section we present a comprehensive evaluation of the agents' behaviors and decision-making processes using spatial analysis, thematic and topical modeling, and sentiment analysis of the agents' cognitive outputs and observations. Appendix 6.3 provides a log of the agent's interactions and decisions in one iteration of the 'Subway Station' experiment.\nIt is important to emphasize that reaching the goal (i.e., finding the subway station) was not the main objective of these experiments. Instead, TA is designed to inspect the agent's observation, planning, and decisions, so that the legibility and coherence of the environmental design could be evaluated based on these findings. In that respect, 'failed' experiments may tell more about the spatial design characteristics than successful ones."}, {"title": "5.3 Spatial Analysis", "content": "An evaluation of paths across different scenarios in the 'Subway Station' experiment revealed distinct spatial patterns, as shown in Fig. 5 (bottom). Agents in the 'Night' scenario exhibited the highest frequency of navigation failures and the most inconsistent path trajectories. This is reflected in a more dispersed aggregation of decision points, suggesting difficulties in spatial orientation and decision-making under reduced visibility conditions. Conversely, agents in the 'Winter' scenario demonstrated more consistent and successful navigation paths, with decision points clustered tightly and earlier in the simulation. Correlating with the top-terms analysis (see Sec. 5.4), the agents in the 'Winter' scenario focused on the presence of snow, ice, and cold weather, which may have influenced their tight navigation strategies and goal-oriented decision-making process.\nAs described in Sec. 4.2.1, upon reaching the subway station, the agent was assigned an additional sub-task. As shown in 6.3, the agent's behavior during these sub-tasks is more exploratory and less deterministic, as the agent is not provided with a clear objective or navigational cues to follow. Still, the agent is able to adapt to new information and make decisions based on its prior observations and memory. For instance, the agent concludes that a 'coffee shop' is likely to be located near the subway station, where it located a plaza. This demonstrates the agent's ability to infer and reason about its environment as well as rely on its memory, even in the absence of explicit instructions."}, {"title": "5.4 Term Frequency Analysis", "content": "To further understand the agent's cognitive process, we conducted a thematic analysis of its outputs and environmental observations. We extracted the agent's internal representations from the simulation logs and applied various natural language processing (NLP) techniques, including tokenization, lemmatization, and n-gram analysis. Subsequently, we utilized term frequency-inverse document frequency (TF-IDF) vectorization to identify the most prevalent features in"}, {"title": "5.5 Topical Modeling", "content": "To examine the cognitive processes underlying the agent's behavior, we conducted topic modeling on the observation and planning streams. Key topics were extracted using LLM clustering and semantic analysis [Petukhova et al., 2024], categorizing terms into navigation, visibility, movement, obstacles, and urban environment. Latent Dirichlet allocation (LDA) was applied to the agent's logs to identify semantic themes [Blei et al., 2003]. As depicted in Fig. 7, the analysis revealed a predominance of terms related to urban features and the agent's navigation, with less emphasis on movement, obstacles, and visibility. This model indicated a strong focus on direct path-following and target-seeking behaviors, with limited exploration or route optimization. The Natural Language Toolkit (NLTK) and GPT-4 were utilized for textual analysis and initial semantic categorization [Achiam et al., 2023, Hutto and Gilbert, 2014].\nAs shown in Fig. 5, the 3D environment for this experiment was designed to include potential shortcuts and detours, to allow for variability in the agent's decisions. Despite these features, the agent consistently followed the main road, indicating a deterministic decision-making process. The agent's behavior may be influenced by its initial conditions, prompting reliance on prior knowledge and the navigational cues (discovery map and compass), rather than adapting to new opportunities. As discussed in Sec. 6, further research is required to explore the agent's adaptability to dynamic and open-ended environments, including changing weather conditions, pedestrian interactions, or unexpected obstacles."}, {"title": "5.6 Sentiment Analysis", "content": "To evaluate the agent's 'emotional' state in both successful and failed paths, we conducted sentiment analysis using the Natural Language Toolkit's (NLTK) VADER sentiment analyzer [Hutto and Gilbert, 2014]. The agent's 'thought' and 'observation' streams were classified into three categories: positive, neutral, and negative. The results, visualized in Fig. 8, indicate a distinction between successful and failed paths. In both cases, the agent's sentiment is mostly positive, and occasional negative sentiment can be observed. However, failed paths exhibit clusters of both negative sentiments and iterative actions ('search' steps), indicating the agent's 'frustration' or 'confusion' when failing to find a path. In contrast, successful paths show a more positive sentiment, with fewer search steps and a clearer path to the target.\nAs described in 4.2.1, the agent is assigned an additional task upon reaching its goal. During these additional tasks, the agent's sentiment tends to be more negative and 'search' oriented, reflecting a sense of confusion. As shown in Fig. 5, the agent's path during these sub-tasks is generally more exploratory, suggesting a lack of clear objectives or guidance. In the subtask \u2018Interact with a friend across the street', the agent's sentiment appears more positive, and its actions are more deliberate. This might indicate that the agent can be more engaged and motivated when presented with a less ambiguous task, even in the absence of explicit instructions or navigational cues.\nThis sentiment analysis is conducted directly on the agent's \u2018thought' and 'observation'. For that reason, it is likely that emotional states are not fully captured, and the agent's sentiment is more reflective of its immediate environment and task. Future research should explore additional steps in the agent's CoT framework to incorporate more nuanced emotional states. For example, the agent could be requested to reflect on its 'emotions' or 'motivation' to perform certain actions, providing a more comprehensive understanding of the agent's cognitive processes."}, {"title": "6 Discussion", "content": "This paper presents TravelAgent (TA), a novel platform for simulating human behavior in urban environments using generative agents and a Chain-of-Thought (CoT) framework. TA models decision-making, experiences, and interactions of agents in virtual settings, providing urban designers, planners, and architects with a new way for evaluating spatial designs. Experiments presented here demonstrate TA's effectiveness in simulating behavior and assessing agents' interactions. This section discusses TA's potential implications for spatial design, along with the opportunities and challenges of using generative agents for behavior simulation."}, {"title": "6.1 Implications for Urban Design and Architecture", "content": "TA has several potential implications for urban design and architecture, particularly in the areas of wayfinding, environmental legibility, and user experience.\nWayfinding and Navigation: TA's ability to simulate human-like navigation offers insights into urban interactions. By analyzing agent paths and decision points, designers can identify wayfinding challenges and optimize layouts for better navigability. For instance, the clustering of decision points in the \u2018Winter' scenario highlights the importance of clear sightlines and distinctive landmarks in aiding navigation. Inversely, the sparse decision points in the \u2018Night' scenario can suggest the need for improved signage, lighting, and visibility. Integrating these elements can enhance wayfinding and reduce cognitive load on pedestrians in urban environments.\nEnvironmental Legibility: TA simulations underscore the significance of visual cues and spatial memory in navigation. By analyzing agents' observations and plans, designers can evaluate the legibility of various design options. Clear landmarks and visual cues, as indicated by the agents' cognitive outputs, enhance the clarity and coherence of urban spaces. Materials, opacities, and textures can also play a key role in navigation tasks and spatial orientation, as discussed in Section 5.4.\nUser Experience and Safety: Sentiment analysis can identify areas where agents experience frustration or confusion, and help address safety concerns and enhance user experience. For instance, negative sentiments and search steps in failed paths indicate confusing areas; Lack of clear signage, obstructed views, or ambiguous pathways may contribute to user discomfort and disorientation. Simulating diverse agents across demographics and personas can help designers assess inclusivity and accessibility, leading to more user-friendly and safe urban environments."}, {"title": "6.2 Limitations and Future Work", "content": "While TA demonstrates potential in simulating generative agent behavior within urban environments", "Integration": "Despite TA potential in simulating human-like behavior", "2023": ".", "2024": "."}, {"2024": "real-world observations", "Personalization": "TA agents may not fully capture the diversity of individuals and groups. Future work should develop more sophisticated agent profiles reflecting varying demographics", "Dynamics": "The current TA implementation is limited to simple environments with basic goals. Future work should incorporate more complex and dynamic environments", "move forward": "r 'turn left'", "Efficiency": "TA currently requires significant computational resources for generating sensory inputs, processing behaviors, and performing CoT analysis. Future efforts should focus on optimizing performance to reduce simulation time"}]}