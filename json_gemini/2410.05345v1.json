{"title": "Trained Models Tell Us How to Make Them Robust to Spurious Correlation without Group Annotation", "authors": ["Mahdi Ghaznavi", "Hesam Asadollahzadeh", "Fahimeh Hosseini Noohdani", "Soroush Vafaie Tabar", "Hosein Hasani", "Taha Akbari Alvanagh", "Mohammad Hossein Rohban", "Mahdieh Soleymani Baghshah"], "abstract": "Classifiers trained with Empirical Risk Minimization (ERM) tend to rely on at- attributes that have high spurious correlation with the target. This can degrade the performance on underrepresented (or minority) groups that lack these attributes, posing significant challenges for both out-of-distribution generalization and fair- ness objectives. Many studies aim to enhance robustness to spurious correlation, but they sometimes depend on group annotations for training. Additionally, a common limitation in previous research is the reliance on group-annotated valida- tion datasets for model selection. This constrains their applicability in situations where the nature of the spurious correlation is not known, or when group labels for certain spurious attributes are not available. To enhance model robustness with minimal group annotation assumptions, we propose Environment-based Validation and Loss-based Sampling (EVaLS). It uses the losses from an ERM-trained model to construct a balanced dataset of high-loss and low-loss samples, mitigating group imbalance in data. This significantly enhances robustness to group shifts when equipped with a simple post-training last layer retraining. By using environment inference methods to create diverse environments with correlation shifts, EVaLS can potentially eliminate the need for group annotation in validation data. In this context, the worst environment accuracy acts as a reliable surrogate throughout the retraining process for tuning hyperparameters and finding a model that performs well across diverse group shifts. EVaLS effectively achieves group robustness, showing that group annotation is not necessary even for validation. It is a fast, straightforward, and effective approach that reaches near-optimal worst group accu- racy without needing group annotations, marking a new chapter in the robustness of trained models against spurious correlation. You can access the implementation at https://github.com/sharif-ml-lab/EVaLS.", "sections": [{"title": "1 Introduction", "content": "Training deep learning models using Empirical Risk Minimization (ERM) on a dataset, poses the risk of relying on spurious correlation. These are correlations between certain patterns in the training dataset and the target (e.g., the class label in a classification task) despite lacking any causal relationship. Learning such correlations as shortcuts can negatively impact the models' accuracy on minority groups that do not contain the spurious patterns associated with the target [1, 2]. This problem leads to concerns regarding fairness [3], and can also cause a marked reduction in the performance. This occurs particularly when minority groups, which are underrepresented during training, become overrepresented at the inference time, as a result of shifts within the subpopulations [4]. Hence, ensuring robustness to group shifts and developing methods that improve worst group accuracy (WGA) is crucial for achieving both fairness and robustness in the realm of deep learning.\nMany studies have proposed solutions to address this challenge. A promising line of research focuses on increasing the contribution of minority groups in the model's training [5-7]. A strong assumption that is considered by some previous works is having access to group annotations for training or fully/partially fine-tuning a pretrained model [8, 7, 1]. The study by Kirichenko et al. [1] proposes that retraining the last layer of a model on a dataset that is balanced in terms of group annotation can effectively enhance the model's robustness against shifts in spurious correlation. While these works have shown tremendous robustness performance, their assumption for the availability of the group annotation restricts their usage.\nIn many real-world applications, the process of labeling samples according to their respective groups can be prohibitively expensive, and sometimes impractical, especially when all minority groups may not be identifiable beforehand. A widely adopted strategy in these situations involves the indirect inference of various groups, followed by the training of models using a loss function that is balanced across groups [5, 9, 10, 4]. The loss value of the model, or its alternatives, are popular signals for recognizing minority groups [5, 9\u201311]. While most of these techniques necessitate full training of a model, Qiu et al. [9] attempt to adapt the DFR method [1] with the aim of preserving computational efficiency while simultaneously improving robustness to the group shift. However, this method still requires group annotations of the validation set for the model selection and hyperparameter tuning. Consequently, this constitutes a restrictive assumption when adequate annotations for certain groups are not supplied. It also applies to situations where some shortcut attributes are completely unknown.\nIn this study, we present a novel strategy that effectively mitigates reliance on spurious correlation, completely eliminating the need for group annotations during both training and retraining. More interestingly, we provide empirical evidence indicating that group annotations are not necessary, even for model selection. We show that assembling a diverse collection of environments for model selection, which reflects group shifts can serve as an effective alternative approach. Our proposed scheme, Environment-based Validation and Loss-based Sampling (EVaLS), strengthens the robustness of trained models against spurious correlation, all without relying on group annotations. EVaLS is pioneering in its ability to eliminate the need for group annotations at every phase, including the model selection step. EVaLS posits that in the absence of group annotations, a set of environments showcasing group shifts is sufficient. Worst Environment Accuracy (WEA) could then be utilized for model selection. We observe that spurious correlations, as a form of subpopulation shifts, cause significant group shifts when using environment inference methods [12]. Consequently, the inferred environments\u2014which could be obtained even by simply dividing validation data based on predictions from a random linear layer atop a trained model's feature space-can effectively compare different sets of hyperparameters for tuning."}, {"title": "2 Preliminaries", "content": "2.1 Problem Setting\nWe assume a general setting of a supervised learning problem with distinct data partitions $D_{Tr}$ for training, $D_{Val}$ for validation, and $D_{Te}$ for final evaluation. Each dataset comprises a set of paired samples $(x, y)$, where $x \\in \\mathcal{X}$ represents the data and $y \\in \\mathcal{Y}$ denotes the corresponding labels. Conventionally, $D_{Tr}$, $D_{Val}$, and $D_{Te}$ are assumed to be uniformly sampled from the same distribution. However, this idealized assumption does not hold in many real-world problems where distribution shift is inevitable. In this context, we consider the sub-population shift problem [4]. In a general form of this setting, it is assumed that data samples consist of different groups $G_i$, where each group comprises samples that share a property. More specifically, the overall data distribution $p(x, y) = \\Sigma_i \\alpha_i p_i(x, y)$ is a composition of individual group distributions $p_i(x, y)$ weighted by their respective proportions $\\alpha_i$, where $\\Sigma_i \\alpha_i = 1$. In this work, we assume that $D_{Tr}$, $D_{val}$, and $D_{Te}$ are composed of identical groups but with a different set of mixing coefficients ${\\alpha_i}$. It is noteworthy that the validation set may have approximately identical coefficients to those of the training or testing sets, or it may have entirely different coefficients.\nSeveral kinds of subpopulation shifts are defined in the literature, including class imbalance, attribute imbalance, and spurious correlation [4]. Class imbalance refers to the cases where there is a difference between the proportion of samples from each class, while attribute imbalance occurs when instances with a certain attribute are underrepresented in the training data, even though this attribute may not necessarily be a reliable predictor of the label. On the other hand, spurious correlation occurs when various groups are differentiated by spurious attributes that are partially predictive and correlated with class labels but are causally irrelevant. More precisely, we can consider a set of spurious attributes $\\mathcal{S}$ that partition the data into $|\\mathcal{S}| \\times |\\mathcal{Y}|$ groups. When the concurrence of a spurious attribute with a label is significantly higher than its correlation with other labels, that spurious attribute could become predictive of the label, resulting in deep models relying on the spurious attributes as shortcuts instead of the core ones. This is followed by a decrease in the model's performance on groups that do not have this attribute."}, {"title": "2.2 Robustness of a Trained Model to Unknown Shortcuts", "content": "In scenarios where group annotations are absent, traditional methods that depend on these annotations for training or model selection become infeasible. Moreover, as previously discussed by Li et al. [14], when data contains multiple spurious attributes and annotations are only available for some of them, such methods would make the model robust only to the known spurious attributes. To further explore such complex scenarios, we introduce the Dominoes Colored-MNIST-FashionMNIST (Dominoes CMF) dataset (Figure 4(a)). Drawing inspiration from Pagliardini et al. [17] and Arjovsky et al. [18], Dominoes CMF merges an image from CIFAR10 [19] at the top with a colored (red or green) MNIST [20] or FashionMNIST [21] image at the bottom. The primary label is derived from the CIFAR10 image, while the bottom part introduces two independent spurious attributes: color (red or green) and style (MNIST or FashionMNIST). Although annotations for shape are provided for training and model selection, color remains an unknown variable until testing. For more details on the dataset refer to the Appendix.\nThe illustrations in Figure 3(a-c) depict the outlined scenario. A classifier trained using ERM is dependent on both spurious features (Figure 3(b)). Yet, achieving robustness against one spurious correlation (Figure 3(c)), does not ensure robustness against both (Figure 3(a)). In Section 4 we show that our approach, which does not rely on the group annotations of the identified group, achieves enhanced robustness to both spurious correlations, outperforming strategies that depend on the known group's information."}, {"title": "3 Environment-based Validation and Loss-based Sampling", "content": "EVaLS is designed to improve the robustness of ERM-trained deep learning models to group shifts without the need for group annotation. In line with the DFR [1] approach, we utilize a classifier defined as $f = h \\circ g_\\theta \\circ g_e$, where $g_e$ represents a deep neural network serving as a feature extractor, and $h_\\theta$ denotes a linear classifier. The classifier is initially trained with the ERM objective on the training dataset $D_{Tr}$. Subsequently, we freeze the feature extractor $g_e$ and focus solely on retraining the last linear layer $h_\\theta$ using the validation dataset $D_{val}$ as a held-out dataset. This scheme helps us make our method available in settings where $D_{Tr}$ is not available, or where repeating the training process is infeasible.\nWe randomly divide the validation set $D_{Val}$ into two subsets, $D_{LL}$ and $D_{MS}$ which are used for last layer training and model selection, respectively. In Section 3.1 we explain how to sample a subset of $D_{LL}$ that statistically handles the group shifts inherent in the dataset. In Section 3.2 we describe how $D_{MS}$ is divided into different environments that are later used for model selection. The optimal number of selected samples from $D_{LL}$ and other hyperparameters is determined based on the worst environment accuracies among environments that are obtained from $D_{MS}$. By combining our sampling and validation strategy, we aim to provide a robust linear classifier $h_{\\theta^*}$ that significantly improves the accuracy of underrepresented groups without requiring group annotations of training or validation sets. Finally in Section 3.3, we provide theoretical support for the loss-based sampling procedure and its effectiveness."}, {"title": "3.1 Loss-Based Instance Sampling", "content": "Following previous works [5, 10, 9], we use the loss value as an indicator for identifying minority groups. We first evaluate classifier $f$ on samples within $D_{LL}$ and choose $k$ samples with the highest and lowest loss values in each class for a given $k$. By combining these $2k$ samples from each class, we construct a balanced set $D_{Bal}$, consisting of high-loss and low-loss samples (see Figure 1(c))."}, {"title": "3.2 Partitioning Validation Set into Environments", "content": "Contrary to common assumptions and practices in the field, precise group labels for the validation set are not essential for training models robust to spurious correlations. Our empirical findings, detailed in Section 4, reveal that partitioning the validation set into environments that exhibit significant subpopulation shifts can be used for model selection. Under these conditions, the worst environment accuracy (WEA) emerges as a viable metric for selecting the most effective model and hyperparameters.\nThe concept of an environment, as frequently discussed in the invariant learning literature, denotes partitions of data that exhibit different distributions. A model that consistently excels across these varied environments, achieving impressive worst environment accuracy (WEA), is likely to perform equally well across different groups in the test set. Several methods for inferring environments with notable distribution shifts have been introduced [12, 22]. Environment Inference for Invariant Learning (EIIL) [12], leverages the predictions from an earlier trained ERM model to divide the data into two distinct environments that significantly deviate from the invariant learning principle proposed by Arjovsky et al. [18], thus creating environments with distribution shifts. Initially, EIIL is employed to split $D_{MS}$ into two environments. Subsequently, each environment is further divided based on sample labels, resulting in $2 \\times |\\mathcal{Y}|$ environments. To measure the difference between the distribution of environments, we define group shift of a class as the absolute difference in the proportion of a minority group between two environments of that class. A higher group shift suggests a more distinct separation between environments."}, {"title": "3.3 Theoretical Analysis", "content": "The environments obtained as described in Section 3.2 are utilized for hyperparameter tuning, specifically for tuning $k$, which is the number of selected samples from loss tails. It is known that minority samples are more prevalent among high-loss samples, while majority samples dominate the low-loss category. However, the question remains whether loss-based sampling can construct a balanced dataset without introducing spurious correlations. In this section, aligned with our practical approach, we provide theoretical insights into how loss-based sampling within a class can be used to create a group-balanced dataset.\nConsider a binary classification problem with a cross-entropy loss function. Let logits be denoted as $L$. We assume a general assumption that in feature space (output of $g_e$) samples from the minority and majority of a class are derived from Gaussian distributions. As a result, we can consider $\\mathcal{N}(\\mu_{min}, \\Sigma_{min})$ and $\\mathcal{N}(\\mu_{maj}, \\Sigma_{maj})$ as the distribution of minority and majority samples in logits space. Because the loss function is a monotonic function of logits, the tails of the distribution of loss across samples are equivalent to that of the logits in each class.\nProposition 3.1. [[Feasiblity Of Loss-based Group Balancing]] Suppose that $L$ is derived from the mixture of two distributions $\\mathcal{N}(\\mu_{min}, \\Sigma'_{min})$ and $\\mathcal{N}(\\mu_{maj}, \\Sigma'_{maj})$ with proportion of $\\epsilon$ and $1 - \\epsilon$, respectively, where $\\epsilon \\leq 1$. If $(i) \\sigma_{min} > \\sigma_{maj}$, or $(ii)$ under sufficient and necessary conditions on $\\mu_{min}, \\mu_{maj}, \\sigma_{min}$ and $\\sigma_{maj}$ including inequality 1, there exists $\\alpha$ and $\\beta$ such that restricting $L$ to the $\\alpha$-left and $\\beta$-right tails of its distribution results in a group-balanced distribution; in which both components are equally represented.\n$\\epsilon \\geq \\frac{2 \\cdot sigmoid\\left(\\frac{\\left(\\mu_{maj}-\\mu_{min}\\right)}{2\\left(\\sigma_{maj}^{2}-\\sigma_{min}^{2}\\right)}\\right)-\\log\\left(\\frac{\\sigma_{min}}{\\sigma_{maj}}\\right)}{2}$  (1)\nWe provide an outline for proof of Proposition 3.1 here and leave the complete and formal proof and also exact bounds to Appendix D. We also analyze the conditions and effects of spurious correlation in satisfying these conditions. Practical justifications for Proposition 3.1 can be found in Appendix D.2. To proceed with the outline, we first define a key concept.\nDefinition 3.1 (Proportional Density Difference). For any interval $I = (a, b]$ and a mixture distribution $\\epsilon P_1(x) + (1 - \\epsilon) P_2(x)$, the proportional density difference is defined as the difference of"}, {"title": "4 Experiments", "content": "In this section, we evaluate the effectiveness of the proposed scheme through comprehensive experiments on multiple datasets and compare it with various methods and baselines. We begin by briefly describing evaluation datasets and then introduce baselines and comparative methods. Finally, we report and fully explain the results.\nDatasets Our approach, along with other baselines, is evaluated on Waterbirds [7], CelebA [13], UrbanCars [14], CivilComments [16], and MultiNLI [15]. As per the study by Yang et al. [4], Waterbirds, CelebA, and UrbanCars among these datasets exhibit spurious correlation. Among the rest, CivilComments has class and attribute imbalance, whereas MultiNLI exhibits attribute imbalance. For additional details on the datasets, please refer to the Appendix E.3.\nBaselines We compare EVaLS with six baselines in addition to standard ERM. GroupDRO [7] trains a model on the data with the objective of minimizing its average loss on the minority samples. This method requires group labels of both the training and validation sets. DFR [1] argues that models trained with ERM are capable of extracting the core features of images. Thus, it first trains a model with ERM, and retrains only the last linear classifier layer on a group-balanced subset of the validation or the held-out training data. While DFR reduces the number of group-annotated samples, it still requires group labels in the training phase. GroupDRO + EIIL [12] infers environments of the training set and trains a model with GroupDRO on the inferred environments. JTT [5] first trains a model with ERM on the dataset, and then retrains it on the dataset by upweighting the samples that were misclassified by the initial ERM model. ES Disagreement SELF [2] selects samples with the highest difference in output when comparing an ERM-trained model to its early-stopped version. Then, they fine-tune the last layer of the ERM-trained model on the selected samples. AFR [9] trains a model with standard ERM, and retrains the classifier on a weighted held-out data. The weights assigned to retraining samples are determined by the probability that the ERM-pretrained model assigns to the ground-truth label, leading to an increased weighting of samples from minority groups.\nGroupDRO + EIIL, JTT, ES Disagreement SELF, and AFR eliminate the reliance on group annotations for their (re)training. However, unlike EVaLS, they all require group labels for model selection. JTT, GroupDRO, and GroupDRO + EIIL necessitate training the entire model to apply their methods. Additionally, ES Disagreement and SELF require early-stopped versions during training with ERM. In contrast, DFR, AFR, and EVaLS operate in a completely post-training manner without relying on"}, {"title": "4.1 Results", "content": "The results of our experiments along with the reported results on GroupDRO [7], DFR [1], JTT [5], ES Disagreement SELF [2], and AFR [9] on five datasets are shown in Table 1. The reported results for GroupDRO, DFR, JTT, and AFR except those for the UrbanCars are taken from Qiu et al. [9]. For EIIL+Group DRO, the results for Waterbirds, CelebA, and CivilComments are reported from Zhang et al. [24]. The results of SELF on CelebA and MultiNLI are reported from the original paper [2]. We report only the worst group accuracy of methods in Table 1. The average group accuracies are documented in the Appendix. The Group Info column shows whether group annotation is required for training or model selection entry for each method. Methods that do not require information regarding ERM training (such as training data or checkpoints) are identified with a star in the table.\nOverall, our approaches outperform methods that do not require group annotations for (re)training in 2 out of 3 datasets with spurious correlations. Moreover, EVaLS-GL surpasses other methods with a similar level of group supervision on MultiNLI [15] and achieves state-of-the-art performance among all methods on UrbanCars [14]. Furthermore, EVaLS and EVaLS-GL, similar to DFR [1] and AFR [9], can be applied to ERM-trained models without needing further information about their training."}, {"title": "5 Discussion", "content": "This study presents EVaLS, a novel approach to improve robustness to spurious correlations with zero group annotation. EVaLS uses loss-based sampling to create a balanced training dataset that effectively disrupts spurious correlations and employs EIIL to infer environments for model selection. We also explore situations with multiple spurious correlations, some of which are unknown. In this context, we introduce Dominoes-CMF, a dataset in which two factors are spuriously correlated with the label, but only one is identified. Our findings suggest that EVaLS attains near-optimal worst test group accuracy on spurious correlation datasets. We also present EVaLS-GL, which needs group labels only for model selection. Our empirical tests on various datasets demonstrate that EVaLS-GL outperforms state-of-the-art methods requiring group labels during evaluation or training.\nNote that this paper remains consistent with the findings of Lin et al. [30]. Our approach does not involve identifying spurious attributes without auxiliary information. Instead, the objective is to make a trained model robust against its reliance on shortcuts. Specifically, conditioning on what a trained model learns, we ascertain that both the loss value and the model's feature space are instrumental in mitigating shortcuts.\nEVaLS and EVaLS-GL may struggle with small datasets due to a low number of selected samples for the last layer training. Also, as environment inference from the last layer features is not effective for all types of subpopulation shifts, EVaLS is limited to datasets with spurious correlation. Similar to other methods in the field, EVaLS prioritizes the worst group accuracy at the cost of less average accuracy. Additionally, a notable variance has been observed in some of our experiments.\nEVaLS represents a significant advancement in the development of methods for enhancing model fairness and robustness without prior knowledge about group annotations. EVaLS could be simply applied as a plug-and-play solution on various ERM-pretrained models with unknown inherent biases to make them robust to possible spurious correlations. Future work could explore developing environment inference methods effective for other types of subpopulation shift, such as attribute and class imbalance."}, {"title": "A Related Work", "content": "Robustness to spurious correlation is a critical concern across various machine learning subfields. It is a form of out-of-distribution generalization [31] where the distribution shift arises from the disproportionate representation of minority groups\u2014those instances that are devoid of the correlated spurious patterns associated with their labels [4]. The issue of spurious correlation also intersects with the discourse on fairness in machine learning [32, 33].\nPast studies have proposed a range of strategies to mitigate the models' reliance on spurious correlation. Broadly speaking, these methods can be categorized according to the degree of supervision they require regarding group labels.\nInvariant learning (IL) methods [18, 34, 35] operate under the assumption of having access to a collection of environments that comprise group shift. By imposing invariant conditions on these environments, IL methods strive to create classifiers robust against group-sensitive features. IRM [18] is designed to learn a feature extractor, which, when utilized, guarantees the existence of a classifier that would be optimal in all training environments. VREx [34] aims to decrease the risk variance among different training environments. PGI [36] works by minimizing the distance between the expected softmax distribution of labels, conditioned on inputs across both majority and minority environments. Lastly, Fishr [35] focuses on bringing the variance of risk gradients closer together across different training environments. For scenarios that the environments are not available, environment inference methods [12, 22] are used to obtain a set of environments. Creager et al. [12] introduce environment inference for invariant learning (EIIL), which tries to partition samples into two groups such that the objective of IRM [18] is maximized. HRM [22] aims to optimize both an environment inference module and an invariant prediction module jointly, with the goal of achieving an invariant predictor.\nWhen group annotations are accessible, various methods leverage this information to equalize the impact of different groups on the model's loss. The Group Distributionally Robust Optimization (GDRO) approach [7], for instance, focuses on optimizing the loss for the worst-performing group during training. Kirichenko et al. [1] has shown that models can still learn and extract core data features even in the presence high spurious correlation. Consequently, They suggest that retraining just the last layer of a model initially trained with Empirical Risk Minimization (ERM) can effectively reduce reliance on spurious correlation for predicting class labels. This method, termed Deep Feature Re-weighting (DFR), has been validated as not only highly effective but also significantly more efficient than earlier techniques that necessitated retraining the full model [8, 7]. However, availability of group annotations is considered a serious restrictive assumption.\nSeveral recent studies have endeavored to enhance model robustness against spurious correlation, even in the absence of group annotations [5, 24, 9, 2, 6, 37]. Liu et al. [5] introduce a two-stage method that involves training a model using ERM for a number of epochs before retraining it to give more weight to misclassified samples. The study by Zhang et al. [24] employs the same two-stage training process, but with a twist for the second stage: they utilize contrastive methods. The goal is to bring samples from the same class but with divergent predictions closer in the feature space, while simultaneously increasing the separation between samples from different classes that have similar predictions. Another method, known as automatic feature reweighting (AFR) [9], reweights the last layer of an ERM-pretrained model to favor samples that the original model was less accurate on. LaBonte et al. [2] refine the last layer of an ERM-trained model through class-balanced finetuning, identifying challenging data points by comparing the classifier's predictions with those of an early-stopped version. While these methods have significantly reduced the reliance on group annotations, they still required for validation and model selection. This remains a constraint, particularly when the spurious correlation is completely unknown.\nTo make a trained model robust to subpopulation shifts with zero group annotations, LaBonte et al. [2] have recently demonstrated that class-balanced retraining of a model pretrained with ERM can effectively improve the worst-group accuracy (WGA) for certain datasets. While this method effectively reduces the impact of class imbalance, it fails in datasets with spurious correlations."}, {"title": "B Environment Inference for Invariant Learning", "content": "Consider the training dataset $D^{Tr} = \\{(x^{(i)}, y^{(i)}) | x^{(i)} \\in \\mathcal{X}, y^{(i)} \\in \\mathcal{Y}\\}$, where $\\mathcal{X}$ and $\\mathcal{Y}$ represent the input and output spaces, respectively. This dataset can be partitioned into different environments"}, {"title": "C Algorithm", "content": ""}, {"title": "D Theoretical Analysis", "content": "In this section, we establish a more formal description of loss-based sampling for balanced dataset creation and then prove it. We thoroughly analyze the close relationship between the availability of the balanced dataset and the gap between spurious features of minority and majority groups."}, {"title": "D.1 Feasibility Of Loss-based Group Balancing", "content": "Consider a binary classification problem with a cross-entropy loss function. Let logits be denoted as $L$. Because loss is a monotonic function of logits, the tails of the distribution of loss across samples are equivalent to that of the logits in each class. We assume that in feature space (output of $g_e$) samples from the minority and majority of a class are derived from Gaussian distributions $\\mathcal{N}(\\mu_{min}, \\Sigma_{min})$ and $\\mathcal{N}(\\mu_{maj}, \\Sigma_{maj})$, respectively. Before diving into the group balance problem we initially show that the distribution of minority and majority samples in the logit space (output of $h_\\theta$) are Gaussian too.\nLemma D.1. [[Gaussain Distribution of Logits]] Considering a Gaussian distribution $Z \\sim \\mathcal{N}(\\mathbf{h}, \\Sigma)$ in feature space and $\\mathbf{W} \\in \\mathbb{R}^d$, then the distribution of logits is as follows: $L = (\\mathbf{W}, Z) \\sim \\mathcal{N}(\\mathbf{W}\\mathbf{h}, ||\\mathbf{W}||_{\\Sigma}^2)$.\nProof. Let $Z \\sim \\mathcal{N}(\\mathbf{h}, \\Sigma)$.\nConsider $L = (\\mathbf{W}, Z) = \\mathbf{W}^T Z$, where $\\mathbf{W} \\in \\mathbb{R}^d$. $L$ is a linear combination of jointly gaussian random variables which makes it an univariate gaussian random variable.\nTo find the distribution of $L$, we need to determine its mean and variance.\n1. Mean of $L$\n$\\mathbb{E}[L] = \\mathbb{E}[(\\mathbf{W}, Z)] = \\mathbb{E}[\\mathbf{W}^T Z] = \\mathbf{W}^T \\mathbb{E}[Z] = \\mathbf{W}^T \\mathbf{h} = (\\mathbf{W}, \\mathbf{h})$.\nTherefore, the mean of $L$ is $\\mathbf{W}\\mathbf{h}$.\n2. Variance of $L$:\nThe variance of $L$ can be computed using the properties of covariance. Recall that if $Z \\sim \\mathcal{N}(\\mathbf{h}, \\Sigma)$, then the covariance matrix of $Z$ is $\\Sigma$."}, {"title": "D.2 Practical Justification", "content": "As shown in Table 3, the standard deviation (\u03c3) of the minority group is consistently greater than that of the majority group across all analyzed datasets. Consequently, condition (i) (Eq. 5) of Proposition D.1 is satisfied. Therefore, we theoretically expect the existence of properly balanced left and right tails."}, {"title": "E Experimental Details", "content": "E.1 Complete Results\nThe complete results on Waterbirds, CelebA, and UrbanCars, in addition to complete results on CivilComments and MultiNLI are reported in Tables 4 and 5 respectively. The results for all methods except Group DRO + EIIL on all datasets except UrbanCars are reported by Qiu et al. [9]. The results for Group DRO + EIIL are taken from Zhang et al. [24]. Also, the results of our method and DFR are shown in Table 6"}, {"title": "E.2 Dominoes-Colored-MNIST-FashionMNIST", "content": "Dominoes-Colored-MNIST-FashionMNIST (Dominoes-CMF) is a synthetic dataset. We adopt a similar approach to previous works [38, 39, 1] using a modified version of the Dominoes binary classification dataset. This dataset consists of images with the top half showing CIFAR-10 images [19], divided into two meaningful classes: vehicles (airplane, car, ship, truck) and animals (cat, dog, horse, deer). The bottom half displays either MNIST [20] images from classes {0 \u2013 3} or Fashion-MNIST [21] images from classes {T-shirt, Dress, Coat, Shirt}. The complex feature (top half) serves as the core feature and the simple feature (bottom half) is linearly separable and correlated with the class label at 75%. Furthermore, inspired by the approaches in Zhang et al. [24], Arjovsky et al. [18], we intentionally introduce an additional spurious attribute by artificially coloring a subset of images as follows: for three different datasets, 85%, 90%, and 95% of the images in the bottom half of class $c_1$ are randomly assigned a red color in each respective dataset, while 15%, 10%, and 5% of the images are assigned a green color, respectively. The same procedure is applied inversely for class $c_2$."}, {"title": "E.3 Datasets", "content": "Waterbirds [7] The dataset comprises images of diverse bird species, classified into two categories: waterbirds and landbirds. Each image features a bird set against a backdrop of either water or land. Interestingly, the background scene acts as a spurious feature in this classification task. Waterbirds are primarily shown against water backgrounds, and landbirds against land backgrounds. Consequently,"}, {"title": "E.5 Sensitivity to Hyperparameters", "content": "The parameters k (the number of selected samples from each loss tail) and \u03bb (the $l_1$ regularization factor) are automatically selected using the environment/group-based validation scheme proposed in our method. Sensitivity heatmaps demonstrate the impact of k and \u03bb on the worst-group validation accuracy (WGA) across various datasets. Importantly, our results demonstrate that for most datasets, multiple hyperparameter combinations yield optimal or near-optimal performance, reducing the need for exhaustive searches. This suggests that the hyperparameter tuning process is not prohibitively difficult, and even relatively shallow or targeted hyperparameter searches suffice to identify optimal hyperparameter configurations. The difference in WGA between the best and worst hyperparameter settings for the Waterbirds, CelebA, and UrbanCars datasets is approximately 10%, 16%, and 25%, respectively."}, {"title": "F Ablation Study", "content": "F.1 Use of EIIL with DFR and AFR\nWe conducted an ablation study to investigate the impact of using environments inferred from EIIL on model selection. Specifically, we benchmarked the performance of DFR and AFR with EIIL-inferred groups. The results, presented in Table 10, demonstrate the effectiveness of incorporating EIIL-inferred groups in model selection. The results show that while EIIL-inferred groups reduce the performance compared to ground-truth annotations for model selection, they still can be effective for robustness to an extent. Moreover, EVaLS outperforms these two methods when using EIIL inferred environments."}, {"title": "F.2 Comparison of High-Loss and Misclassified-Sample Selection", "content": "Several methods, such as JTT [5], rely on misclassified points to address group imbalances by treating these points as belonging to a minority group. To verify the effectiveness of loss-based sampling in comparison with misclassification-based sample selection, we conducted an experiment by replacing loss-based sampling in in EVaLS with selecting misclassified samples and an equal number of randomly chosen correctly classified samples from each class. This results in degraded performance compared to EVaLS on the Waterbirds and UrbanCars datasets, and only a marginal improvement (with higher variance) on CelebA."}, {"title": "F.3 Other Group Inference Methods", "content": "In addition to EIIL, other group inference methods could be utilized for partitioning the model selection set into environments.\nError Splitting JTT [5"}]}