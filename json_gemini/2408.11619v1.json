{"title": "Data-driven Modeling of Combined Sewer Systems\nfor Urban Sustainability: An Empirical Evaluation", "authors": ["Vipin Singh", "Tianheng Ling", "Teodor Chiaburu", "Felix Biessmann"], "abstract": "Climate change poses complex challenges, with extreme weather events becoming increasingly frequent\nand difficult to model. Examples include the dynamics of Combined Sewer Systems (CSS). Overburdened\nCSS during heavy rainfall will overflow untreated wastewater into surface water bodies. Classical\napproaches to modeling the impact of extreme rainfall events rely on physical simulations, which are\nparticularly challenging to create for large urban infrastructures. Deep Learning (DL) models offer a\ncost-effective alternative for modeling the complex dynamics of sewer systems. In this study, we present\na comprehensive empirical evaluation of several state-of-the-art DL time series models for predicting\nsewer system dynamics in a large urban infrastructure, utilizing three years of measurement data. We\nespecially investigate the potential of DL models to maintain predictive precision during network outages\nby comparing global models, which have access to all variables within the sewer system, and local models,\nwhich are limited to data from a restricted set of local sensors. Our findings demonstrate that DL models\ncan accurately predict the dynamics of sewer system load, even under network outage conditions. These\nresults suggest that DL models can effectively aid in balancing the load redistribution in CSS, thereby\nenhancing the sustainability and resilience of urban infrastructures.", "sections": [{"title": "1. Introduction and Related Work", "content": "Climate change has increased the frequency and intensity of extreme weather events [1],\nwhich pose significant challenges to urban infrastructure and environmental management [2].\nManaging Combined Sewer Systems (CSS) becomes particularly difficult [3]. Heavy rainfall can\noverwhelm the capacity of these systems, leading to overflows that release untreated sewage\ninto rivers and lakes [4]. This contamination compromises water quality and poses direct risks\nto human health [5].\nMany urban areas that utilize CSS have implemented overflow basins to mitigate this risk [4],\nas shown in Figure 1. However, there remains a significant gap in understanding the dynamics\nof water levels in these overflow basins. Traditional methods for modeling the dynamics of\nsewer systems rely on physical simulations [6]. These systems are challenging to apply to\nlarge urban infrastructures as they require domain expertise and detailed data on the system\ncomponents, which is often unavailable or imposes significant financial costs. Improving the\nforecasting of these water levels can significantly enhance real-time flow control and inform\nmaintenance and extension planning for sewage overflows.\nData-driven approaches, such as Deep Learning (DL) models, particularly time-series models,\noffer a promising alternative for modeling sewer system dynamics. Any target variable can\nbe modeled with a combination of variables of the sewer system and exogenous variables,\nsuch as rainfall, without an explicit model of the sewer system, as it would be required for\nclassical hydrological systems. These models enable accurate and flexible modeling of sewage\ntreatment facilities to proactively manage and redistribute the load, thus preventing overflows\nand mitigating their impacts [7]. Such predictive capabilities are crucial for timely interventions\nand informed decision-making in urban water management. Moreover, by supporting proactive\nmanagement of critical urban infrastructure, this approach aligns with the principles of public\ninterest AI, by addressing societal needs [8].\nIt is worth mentioning that there are approaches aiming at combining classical physics-based\nsimulations with the flexibility of DL methods [9]. The challenge with these combinations\nis that the model architectures require the same detailed knowledge about the sewer system\nas traditional methods. In addition, modeling the mixed viscosity of wastewater imposes\nsignificant complexity on the physical models. Here we focus on a data-driven approach that\nlearns the system dynamics from measurements and is thus readily applicable without building\ncost-intense digital twins reflecting the physical properties of the sewer system.\nIn this work, we evaluate the performance of various advanced time series models for\nforecasting the water levels in CSS overflow basins. We explore and compare two approaches to\ntime series forecasting: (1) a global model approach, which incorporates a number of exogenous\nvariables, such as rainfall data, and (2) a local model approach, which relies solely on historical"}, {"title": "2. Data and Preprocessing", "content": "In our study, we utilized data\u00b9 provided by Wirtschaftsbetriebe Duisburg\u00b2. The dataset com-\nprises time series sensory data, including water levels in rain basins and water tanks, energy\nconsumption of pumps, and rainfall amounts. The sensor data were collected from six locations\nin Duisburg's Vierlinden district, covering three years, from January 1, 2021, at 00:00 AM until\nJanuary 1, 2024, at 00:00 AM. The recording intervals are irregular as the sensors were read out\nevent-based, with sensor update intervals ranging from 1 second to 1 hour.\nTo standardize the data, we resampled it by calculating the mean values closest to each\nfull-hour mark. This resampling procedure resulted in a total of 26,280 data points, with each\ndata point comprising 35 features derived from the sensory data across the different locations.\nFor missing values in the rainfall measurements, we utilized data from the nearest weather\nstation of the Deutsche Wetterdienst\u00b3, specifically the station in Duisburg-Baerl, located 4.5\nkm from the sewage treatment plant that recorded the rainfall. For the other features, linear\ninterpolation was employed to fill the missing values. Additionally, an indicator column was\nadded for each feature with missing values to denote whether the corresponding value was\ninterpolated."}, {"title": "3. Methodology", "content": "This section details the time series models employed in this study, including the selection,\nimplementation, and comparisons of global and local model approaches."}, {"title": "3.1. Neural Network Architectures", "content": "For our empirical evaluation, we selected six state-of-the-art neural time series models. While\nclassical regression models, such as tree-based methods, can be effective for time series data,\nthe state of the art in water modeling increasingly relies on neural network models [13]. We\nthus focus on these models based on their effectiveness and versatility in forecasting tasks. The\nselected models are:\n\u2022 LSTM [11]: LSTM networks are well-suited for capturing long-term dependencies in\nsequential data, making them ideal for time series forecasting.\n\u2022 DeepAR [14]: This probabilistic forecasting model leverages autoregressive recurrent\nnetworks, providing robust predictions with uncertainty estimates.\n\u2022 Neural Hierarchical Interpolation for Time Series Forecasting (N-HiTS) [15]: As a neural\nhierarchical time series model, N-HiTS excels in capturing complex temporal patterns.\n\u2022 Transformer [16]: Originally designed for nature language processing [17], Transform-\ners use attention mechanism to effectively capture relationships across different time\nsteps [16].\n\u2022 Temporal Convolutional Network (TCN) [18]: TCNs can model long-range dependencies\nin time series data while being computationally efficient.\n\u2022 TFT [12]: TFT combines the strengths of LSTM and attention mechanisms to provide\ninterpretable and accurate forecasts.\nThese models were implemented using the Darts\u2074 Python library, which offers a user-friendly\ninterface for time-series forecasting. PyTorch was used as the supporting framework."}, {"title": "3.2. Global vs Local Model Approach", "content": "Our study considers two approaches to time series forecasting, each motivated by distinct\nreal-world scenarios.\n1. Global Model Approach: This approach corresponds to the scenario of normal CSS\noperation, where all sensors are fully operational, and all data can be transmitted reliably\nover the network. In this case, all available data, including exogenous variables such as\nrainfall data, are integrated into a single model for forecasting the relevant target variable.\nThis approach, referred to as the global model, allows the models to leverage additional\ncontextual information to improve forecasting precision.\n2. Local Model Approach: This approach is designed for scenarios where not all data is\navailable. Such circumstances can arise when sensors are damaged or network connections\nare unstable due to extreme weather events, or security incidents. To mimic these cases,"}, {"title": "4. Experiments", "content": "This section introduces the experimental settings, including data splits, model development,\nand error metrics."}, {"title": "4.1. Datasets", "content": "The dataset was divided into training, validation, and testing sets. The first two years of data\nwere used for training and validation, while the last year was reserved for testing. Within the\ninitial two years, 80% of the data was allocated for training and 20% for validation. Given the\nsequential nature of time series data, the data were not shuffled, and the split was performed in\nchronological order to maintain temporal dependencies. To ensure consistency across features,\nstandard scaling was applied using default parameters ($\\mu = 0, \\sigma^2 = 1$) prior to model training.\nAfter fine-tuning (see Appendix A), we determined that a 72-hour input sequence was optimal\nfor forecasting a 12-hour prediction sequence. This prediction sequence was determined together\nwith domain experts to meet operational requirements."}, {"title": "4.2. Model Development", "content": "To prevent overfitting, early stopping with patience of 10 epochs was adopted. All models\nwere optimized using the Adam optimizer [20] with 32-bit floating point precision. Training\nsessions were conducted on an NVIDIA A100 with 40GB VRAM, utilizing CUDA 12.2 and Python\n3.10. Hyperparameter optimization was performed using the Tree-structured Parzen Estimator\nalgorithm provided by the Optuna library. Each model had a training budget of 600 trials, with\neach trial consisting of 100 epochs. Further details on the hyperparameter optimization process\nare provided in Appendix A. The best hyperparameter configuration for each model was then\nevaluated using 100 different random weight initializations to ensure robust comparisons."}, {"title": "4.3. Error Metrics", "content": "We compared various error metrics well established in the field of time series forecasting [21],\nincluding MSE and Mean Absolute Percentage Error (MAPE). For model training, MSE was\nselected as the loss function, except for the probabilistic model DeepAR, which utilized the"}, {"title": "5. Results", "content": "Figure 2 shows the distribution of test MSE and MAPE across the 100 random weight initializa-\ntions for each model type and approach. It is evident in both figures that the LSTM and DeepAR\nmodels have a larger spread in the results compared to the other models.\nIn Table 1, we list the 0.25, 0.5, and 0.75 quantiles (q) of the MSE, along with the average\nmeasured wall clock runtime at single inference and the effective size of the trained model in\nMegabytes (MB). We observe that the inference times for global and local models are similar in\nmost cases. This is expected, as the experiments were conducted on high-capacity hardware. It\nshould be noted that these times were measured while executing the models in parallel on a\nsingle GPU."}, {"title": "6. Conclusion and Future Work", "content": "Our results demonstrate that DL models can accurately predict the complex dynamics of\nwastewater levels in real-world scenarios. Global models, with full access to all sensor readings\nunder normal operation without network outage, exhibit high forecast precision for wastewater\nlevels in the overflow basin. This enhanced precision can significantly aid sewage treatment\nfacilities in effectively redistributing the load of the CSS.\nIn contrast, local models perform worse in forecasting precision than global models. The\nreason could be the heavy concentration of target values around the mean. Due to sudden\nchanges after longer periods of stability, the local models struggle with longer forecasting\nperiods. However, local models can serve as a fallback in the event of a network interruption\nwhere exogenous variables become unavailable. Our results indicate that even when all network\nconnections are lost, and only historical sensor readings of an individual sensor are available,\nadequate forecasts can still be made. Additionally, due to their lower computational costs, it is\nworthwhile to explore the potential of deploying the local models on edge devices in the future."}, {"title": "A. Hyperparameter Optimization", "content": "Hyperparameter optimization was performed using the Tree-structured Parzen Estimator algo-\nrithm provided in the Optuna library. The optimization process was conducted in two iterations\nwith a total of 600 trials:\n1. Broad Search with 500 trials: An extensive hyperparameter search space will be\nexplored to identify potential optimal values.\n2. Refined Search with 100 trials: Based on the results of the broad search, a more focused\nand fine-grained search will be conducted around the best-performing hyperparameters."}]}