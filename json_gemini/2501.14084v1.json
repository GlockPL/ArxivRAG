{"title": "The Role of Generative AI in Software Student CollaborAltion", "authors": ["Natalie Kiesler", "Armando Fox", "Jacqueline Smith", "Stephen MacNeil", "Juho Leinonen", "Petri Ihantola"], "abstract": "Collaboration is a crucial part of computing education. The increase in Al capabilities over the last couple of years is bound to profoundly affect all aspects of systems and software engineering, including collaboration. In this position paper, we consider a scenario where Al agents would be able to take on any role in collaborative pro- cesses in computing education. We outline these roles, the activities and group dynamics that software development currently include, and discuss if and in what way AI could facilitate these roles and activities. The goal of our work is to envision and critically ex- amine potential futures. We present scenarios suggesting how AI can be integrated into existing collaborations. These are contrasted by design fictions that help demonstrate the new possibilities and challenges for computing education in the AI era.", "sections": [{"title": "1 Introduction", "content": "By 2030, we will see a generation of college students for whom generative AI (GenAI) has always existed as part of their educational experience. This, and the rapid development of technology, will change teaching and learning. The effects of GenAI on education are likely to be as large as, or even larger than, the effects that the Internet has had since the 1990s (see e.g. [19]). Khan [28] has proposed an inspiring vision of how AI could help realize personalized individual tutors for every learner. Com- plementing this, an expert panel from 2020 [49] draws a scenario where \"AI supports orchestration of the multiple types of activities, learning partners, and interaction patterns that can enrich a class- room\". We believe the possibilities are even broader, and to help think about them, we propose a thought experiment that not only accommodates emerging practices and visions but also suggests new use cases in education that (to the best of our knowledge) have not yet been explored. Specifically, we focus on the many roles of collaboration in Com- puter Science (CS) education, both because it has been identified as an important component of social constructivist learning the- ory [54], and because it is a crucial disposition in the practice of systems and software engineering [9, 39, 48, 56]. Taxonomies of collaboration define particular roles within a collaborative work scenario. We postulate that in the near future, Al Agents will be ca- pable of assuming any given role (e.g., facilitator, mentor, assistant, peer) in any given type of collaboration [41]. To keep our focus, we concentrate on systems and software engineering rather than theoretical computer science. In addition, we purposefully do not discuss some issues that current generative Al models have to keep the arguments in the paper focused on the"}, {"title": "2 Why Focus On Collaboration?", "content": "In computing education, collaboration is both an important ingre- dient in student learning and a desirable competency in itself. For example, collaboration is a central component of software develop- ment, where teams work together to overcome human limitations and achieve complex results while working at a high level of ab- straction [39, 56]. It is therefore not surprising that recent curricula recommendations such as the CC2020 [9] address students' abilities to successfully interact, communicate, and collaborate with others, e.g., in the form of the dispositions collaborative and responsive. Being a team player, and successfully working with others (e.g., team members, leaders, customers, etc.) is also an expectation in industry [29]. For this reason, students will likely play different software engineering roles throughout their studies - developer, tester, manager, scrum master, product owner, and so on. Even if AI agents were able to assume most of the roles on a software develop- ment team, humans would still need to be able to collaborate with the AI agent(s), for example, to convey what the human wants the AI agent to do. Hence we expect collaboration skills to be at least as important in the future as they are today, if not more important. In collaboration, actors generally work together towards a shared goal, and many taxonomies of collaboration exist [18, 22, 42, 43, 45]. In this paper, we take a broad view where collaborators are not always equal in standing such as when teachers and students or students and teaching assistants work together collaboratively. Based on social constructivism theory [54], collaboration tends to improve learning by providing social forms and processes [26, 31]. Thus, it would be desirable to maximize collaboration in favor of mere interaction (which does not require a shared goal). While in the past, some educational activities have been less collaborative due to technological limitations, we argue that with capable AI agents, some current teaching and learning activities can be transformed from interaction to collaboration. For example, it would be infeasible to have private one-to-one lectures between a human teacher and a human student due to resource constraints, but this is not the case for capable AI agents advising students. Such agents are available 24/7."}, {"title": "3 Roles and Group Dynamics in Collaboration", "content": "Many of the collaboration taxonomies mentioned above have (at least) two elements in common: (a) Each principal or agent in the collaboration takes on a particular role, (b) the collaboration can involve one or more media, and several modes. For example, a software project course might include several of the following configurations of collaboration: \u2022 Team meeting. Students working together on a project meet face-to-face or virtually. Each student takes on the role of a peer. The mode of collaboration is synchronous discussion. In virtual scenarios, respective software and hardware is required as a media. \u2022 Meeting with project manager/instructor. The student team meets with an instructor (\"project manager\") who gives them advice on their work. The instructor may take on the role of an evaluator, giving students feedback on the quality of the work; or they may be a facilitator, ensuring that the (less-experienced) students keep the meeting on track. \u2022 Meeting to resolve or de-escalate a conflict. An instruc- tor or TA calls a meeting to mediate conflict within the team, whether arising from a difference of technical opinion or a negative power dynamic (see below). The instructor or TA takes the role of a mediator. \u2022 Pair programming. Students may pair-program [24] lo- cally or remotely as peers. The medium is, for example, a collaboratively-authored file of code. \u2022 Peer instruction. Students may engage in collaborative quizzes, in-class discussions, or learn by teaching each other [11, 23, 34, 46]. We will not be surprised to see Al agents interpolated into all of the above roles, and indeed some are already being explored (e.g., using Al in pair programming and peer instruction scenarios). When Al agents become capable of taking on any of the above roles, how will we as educators decide which ones they should take on in an educational setting? One important consideration is the emergence of various kinds of group dynamics in collaborative work. For example, power imbalances may arise between a student and an instructor, or between a student and another student per- ceived to be more assertive, aggressive, competent, or more fluent in the language of the course. Negative dynamics may also arise from implicit or explicit gender bias [37, 52, 53] or racial/ethnic bias or stereotypes [8]. AI agents could be conditioned to detect, avoid, and/or steer away from such situations. Human participants can bring positive affect to a discussion, such as inspiration, encouragement in the face of difficulty, passion for a subject, and so on. They may also share cultural context with other participants that helps to lubricate discussions and avoid or clarify misunderstandings due to communication differences. These qualities can be particularly important in educational contexts. We currently do not know how well Al agents can generate such indi- vidual perspectives and styles - and even if so, whose perspectives and styles would they represent? While AI agents could be conditioned to \"say all the right things\" to mimic human-to-human interactions, we think it is unlikely that"}, {"title": "4 Current Uses of AI Agents in Computing", "content": "Even before the GenAI revolution, chatbots have been considered a promising technology to enhance learning. A 2018 systematic literature review (SLR) showed educational effects of chatbots on students regarding their technological skills, social skills, attitude and trust towards technology, self-regulation skills [57]. In 2021, an- other SLR analyzed how chatbots are applied in education, for which pedagogical roles (e.g., mentoring) they are used, and how they potentially personalize education [58]. The results reveal that chat- bots have been attributed a variety of roles, for example, to support learners by teaching content or skills via conversation tasks [16], as a voice assistant during leisure time, or as a pen-pal [32]. Another role is that of a mentor, i.e., for scaffolding [17], recommending [59], informing [27], but also to support self-regulation, life, and learning skills [58]. Chatbots were also found to be used as assistants to stu- dents, for example, to simplify processes, answer general questions, or make information available [58]. The development in the field of systems and software engineer- ing has been very similar, with Al agents rapidly gaining popularity since 2019. A SLR by Moguel et al. [40] from 2023 divides the ob- jectives of AI bots in software engineering (from least common to most common in the literature) into onboarding assistance, testing, design, requirements elicitation, project management, and coding (including code analysis, refactoring, and debugging). According to the same study, challenges typically associated with these tools re- late to the performance and capabilities of the tools, high coupling to third-party software, and some developers having a bias against AI agents [40]. Notwithstanding the challenges and obstacles in the above work, the UI/UX/HCI community has started to systematically explore the more general question of what new forms of human-computer interaction are enabled by GenAI [4], and has begun to develop general benchmarks to capture the subjective experience of human- LLM interaction in a variety of task types [36]. As one example, one recent project populates an entire small village of simulated residents powered by LLMs, embedding them in a larger architec- ture that reifies observation, planning, and reflection, as a potential way to simulate social phenomena [44]."}, {"title": "5 The Future: CollaborAltion with GenAI", "content": "This position paper aims to envision and explore the potential future of GenAI in computing education, identifying emerging op- portunities and challenges to guide future research. Our goal is thus not to prescribe ideal configurations, but to provide a framework that encourages broader thinking about the design space of possi- bilities and the key considerations that educators need to engage with to maximize benefits while avoiding harm. Accordingly, we introduce some examples of Al agents and how they may be utilized in introductory and advanced courses, as well as in the training of educators or teaching assistants."}, {"title": "5.1 Introductory Courses", "content": "Many teaching techniques common in introductory courses (e.g., Pair Programming, Think-Pair-Share, etc.) involve putting students in small groups to discuss solving a problem. While these techniques are shown to be effective, there are limitations, for example, when students do not engage with each other. We see a role here for AI agents as conversation facilitators, comparable to an instructor who is walking around the classroom. Al agents could also participate as mock-students, asking questions of their \"peers\" and allowing students to learn through teaching [10]. Pair programming is another widely used teaching approach in both introductory and advanced courses (as well as in industry), with both positive and negative outcomes [6, 24, 37]. The use of an Al agent as part of a pair could help address negative aspects, such as the presence of implicit gender bias in pair interactions [14], while retaining some of the benefits of this method of programming."}, {"title": "5.2 Advanced Courses", "content": "In more advanced courses such as software engineering projects, collaboration itself is often an important learning goal (even though it is not always explicit). Typically, an important component in such courses is team meetings, in which students working together on a project meet face-to-face or virtually. Each student takes on the role of a peer, and the medium of collaboration can be a synchronous discussion. A recent experience report showed that GenAI tools may help broaden students perspective in the critical thinking process [21]. There are several roles usually played by instructors or teaching assistants that Al agents could also assume, relieving the scaling challenges of finding and training staff, e.g., as facilitator, project manager/instructor, mediator, or simply providing personalized feedback and support. Another interesting role for an Al agent may be that of a sub- stitute team member. When a team member does not fulfill their role for whatever reason, Al agents could play the role of a stu- dent teammate, allowing teams to continue to run smoothly even if members drop out or underperform. However, it should be noted that such a substitution has further implications on the replaced student, the student team, and likely the entire class."}, {"title": "5.3 Teacher and Teaching Assistant Training", "content": "At present, many teachers and teaching assistants (TAs) receive little or no training and feedback on the way they interact with students in one on one or small group settings (e.g., in tutorials or in office hours). An Al agent could join these interactions and provide feedback to the teacher on their interactions with students to help improve their teaching and communication skills. We also see opportunities for Al agents in the training of teach- ers and TAs. A common technique in teacher and TA training is the use of exemplary classroom scenarios, either through case studies or role play. AI agents could be used to play some parts in these"}, {"title": "6 Grand Challenges and Future Research", "content": "Based on our position that Al agents can and will be integrated into many collaborative learning settings in the future, there are numerous challenges and future research directions to consider. For example, 1) should AI agents be identified as such to students, 2) how might Al agents affect power dynamics [55], 3) how might the identity of students and potential identity or lack of identity of Al agents affect group and classroom dynamics, 4) how much context should be maintained across activities, and 5) how would students who have always interacted with Al agents be different from our current students? In the following sections, we discuss some of the aspects involved in these questions, emphasizing the related challenges and need for future research."}, {"title": "6.1 Transparency", "content": "If AI agents can assume any role in classroom settings, it is impor- tant to better understand students' preferences for these roles and interactions. One area that requires clarity is around transparency. We might assume that students and instructors would be informed and aware that they are interacting with an Al agent. This assump- tion aligns with The European Union's Artificial Intelligence Act\u00b9 which requires that \"developers and deployers must ensure that end-users are aware that they are interacting with AI (chatbots and deepfakes).\" In 2020, Berendt et al. [3] already highlighted the implications of AI in education for fundamental human rights and freedoms of both teachers and learners. Those comprise, for ex- ample, privacy, the protection of personal data, expression and education (presumably a safe space). With capable AI agents, there is an expert pretrained entity in the classroom, which might also collect data. As a consequence, learners may wish to opt out of data collection, or from using Al agents. However, there is currently no global consensus on the issue and few other countries have similar legislation."}, {"title": "6.2 Power Dynamics and Identity", "content": "Prior work has demonstrated how power dynamics play out in computing classrooms, e.g., in pair programming and group discus- sions [37, 52, 53]. Rudimentary intelligent systems have also been developed to encourage more equitable group dynamics during col- laborative learning activities both in-person [38] and online [53]."}, {"title": "6.3 Impacts on Student Community", "content": "Mediation and facilitation can positively impact group dynamics. But more work is needed to understand the impacts of GenAI on student communities. By interacting more frequently with GenAI, students could be missing opportunities to work with, show interest in, and engage with their peers or learn how to interact in social situations. As a consequence, students may not be able to build as many weak and strong ties with their peers, which may lead to a limited support system during their studies. Some types of Al integration could negatively affect student communities - for example, if Al is used to replace all peers in group work. These types of effects might be mitigated by having multiple humans play a part in the collaboration when it is feasible. At the same time, it is crucial to ensure that all students have equal opportunities to engage with these human players, and not just Al agents. Hence, we also need to ensure and investigate students' access to all resources - human and AI, as this does not necessarily apply to all of our students. The same is true for students' prerequi- sites to successfully utilize AI agents, as mentioned in the previous section on power dynamics and identity (see Section 6.2). Future research may address the impact of AI agents on students' community building efforts and their ability to build long-lasting social networks with their peers."}, {"title": "6.4 Accounting for Context", "content": "While AI agents are becoming increasingly capable of leveraging context about students, classes, and generated artifacts, challenges"}, {"title": "6.5 (Lack of) AI Literacy", "content": "As Al agents become more ubiquitous and students become more familiar with the interactions, new challenges may emerge. For example, even if interactions with agents become more natural, we still need to remember to teach the underlying complexities. There is an analogy with the so-called \"digital natives\u201d, who were first assumed to have better digital skills simply because they had never known a world that was not digital - which later turned out not to be true [33]. For example, many students in CS1 courses today seem to struggle with basic things, e.g., following the file structure or understanding class paths, due to those things not being explicitly taught and modern systems such as smartphones hiding them from the user, and at the same time, their reliance on search and other mechanisms. Students in the future may be more competent as users applying GenAI tools, but they will not necessarily understand the tools, their architecture, etc. (e.g., how a Google search works, and how GenAI works). It is therefore crucial to inform them about the inherent limitations of Al agents, such as the bias of the training data, its knowledge cutoff date, etc., as we cannot assume Al agents will do so by themselves."}, {"title": "7 Limitations", "content": "This position paper has some limitations that need to be considered. For example, we assume Al agents to become extremely proficient in assisting learners with individual requests. However, this scenario might not happen. Moreover, we acknowledge and understand that we might see human resistance toward AI agents in learning and teaching contexts. Likewise, we refrained from taking a side in the discussion on the future direction of AI agents in collaboration. From our perspective, it is still too early for wild speculations about the distant future. Finally, it should be noted that the scenarios we discussed only focus on software engineering as part of computing education. It is not the goal of this position paper to make assumptions about education as a whole."}, {"title": "8 Conclusions", "content": "The main contribution of this position paper is to provide an outline of existing collaborative activities and roles in systems and software education, and to discuss how highly-capable Al agents might affect collaboration in this field. We believe that Al agents will soon be capable of assuming different roles in collaborative activities. It is crucial to carefully consider what effects AI might have on different aspects of collaboration, and how decisions made when integrating AI affect its impact. GenAI is a potentially transformative technology for our edu- cational system. We must be careful not to fall into the trap of simply substituting it into existing educational scenarios, but rather recognizing that it will enable entirely new modes of learning that were previously impossible or even unthinkable. Identifying the CS concepts that remain foundational, the intellectual vocabulary needed to identify and exploit those new learning modes, and the challenges and opportunities for introduced by doing so, should be on our agenda."}]}