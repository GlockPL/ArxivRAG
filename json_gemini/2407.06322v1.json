{"title": "MAGMAX: Leveraging Model Merging for Seamless Continual Learning", "authors": ["Daniel Marczak", "Bart\u0142omiej Twardowski", "Tomasz Trzci\u0144ski", "Sebastian Cygert"], "abstract": "This paper introduces a continual learning approach named MAGMAX, which utilizes model merging to enable large pre-trained models to continuously learn from new data without forgetting previously acquired knowledge. Distinct from traditional continual learning methods that aim to reduce forgetting during task training, MAGMAX combines sequential fine-tuning with a maximum magnitude weight selection for effective knowledge integration across tasks. Our initial contribution is an extensive examination of model merging techniques, revealing that simple approaches like weight averaging and random weight selection surprisingly hold up well in various continual learning contexts. More importantly, we present MAGMAX, a novel model-merging strategy that enables continual learning of large pre-trained models for successive tasks. Our thorough evaluation demonstrates the superiority of MAGMAX in various scenarios, including class- and domain-incremental learning settings.", "sections": [{"title": "Introduction", "content": "Large pre-trained models are considered cornerstones of complex machine learning systems, allowing unprecedented performance improvements across many challenging tasks [1,2,17,31,41,50]. Yet their remarkable ability to generalize to unseen conditions is intrinsically limited by the stationary character of their training data. To keep up with the ever-changing world, these models should adapt continuously and assimilate knowledge from the stream of new data, which is the objective of Continual Learning (CL) [21, 24, 39].\nTraditionally, CL approaches used regularization to retain the knowledge from previous tasks [18,23], grow the network while learning new tasks [32,48], or use a replay buffer to limit the catastrophic forgetting [12, 42, 52]. In this work, we argue that in the era of machine learning systems built on top of large"}, {"title": "Related Work", "content": "Continual learning (CL) is a setting where models learn a sequence of tasks with access to the data from the current task only. The goal is to achieve high performance on all the tasks from the sequence, with catastrophic forgetting of knowledge learned from the previous tasks being the main challenge [7,26]. One prominent example of CL approaches are the regularization-based methods. In EWC [18], the authors propose to use the Fisher information matrix to estimate model weight importance (for previous tasks) which is then used to penalize changes of important model weight. On the other hand, regularization can be applied on the data level, e.g. LwF [23] or DER [48] penalizes changes in model predictions or features. Other CL approaches include adding more parameters as the number of tasks increases [32,49], or using memory buffer [12, 42, 48, 52] for data from old tasks, which is often undesirable due to the privacy concerns. In general, it seems that the best results are obtained by CL methods that favor stability, that is the model does not change much between consecutive learning tasks [16,33]. As a result, a plethora of methods were developed for CL scenarios which assumed large first task [30,53], or Large Pre-trained Model (LPM).\nContinual Learning of LPMs became popular as capabilities (e.g., zero shot or out-of-distribution (OOD) performance) of foundation models became apparent [1,2, 17, 31, 41, 50]. A recent study questioned the utility of some CL methods, showing that by using a frozen model and nearest mean classifier can"}, {"title": "Background and motivation", "content": "We consider a problem of continual learning of large pre-trained models. We assume access to a pre-trained model parametrized by d weights \\( \\theta_0 \\in \\mathbb{R}^d \\). Our goal is to adapt the model to a sequence of disjoint tasks {\\( D_1, D_2, ..., D_n \\)} one task at a time. We investigate exemplar-free scenario which assumes no access to data from previous tasks.\nWe consider two fine-tuning scenarios:\nindependent (Ind FT) - starts from pre-trained weights \\( \\theta_0 \\),\nsequential (Seq FT) - starts from the weights of the model fine-tuned on the sequence of previous tasks, i.e. when fine-tuning on task \\( D_t \\), we start from \\( \\theta_{t-1} \\) which was trained on {\\( D_1, D_2, . . ., D_{t\u22121} \\)}.\nWe use a notion of task vector [13] that is an element-wise difference between the fine-tuned model and the pre-trained model, i.\u03b5. \\( \\tau_i = \\theta_i \u2013 \\theta_0 \\). Note that independently fine-tuned task vectors contain information about a single task and sequentially fine-tuned task vectors encompass some knowledge about all the tasks in the sequence."}, {"title": "Motivation", "content": "In this Section, we set and experimentally validate two hypotheses that serve as a motivation for developing a new method for continual learning via model merging."}, {"title": "MAXIMUM MAGNITUDE SELECTION", "content": "Based on the motivations introduced in the previous Section, we introduce MAXIMUM MAGNITUDE SELECTION (MAGMAX). It is a novel method for continual learning that utilizes sequential fine-tuning, following H2, and model merging based on selecting the parameters of the highest magnitude, following H1 (see Algorithm 1). Given a new task, Dt, our method consists of two steps:\n1. Sequential adaptation: We obtain the new weights of the model \\( \\theta_t \\) by fine-tuning it on Dt. Importantly, we start from the weights of the model fine-tuned on previous tasks \\( \\theta_{t-1} \\).\n2. Knowledge consolidation: We consolidate task-specific knowledge using model merging. Firstly, we create task vectors for all tasks seen so far: {\\( \\tau_i \\)}_{i=1}^{t}, where \\( \\tau_i = \\theta_i \u2013 \\theta_0 \\). Then, for each parameter p\u2208 {1,2,...,d}, we select the value \\( \\tau_{MAGMAX} \\) by the maximum magnitude out of all the task vectors. Lastly, we apply the resulting task vector \\( \\tau_{MAGMAX} \\) to the pre-trained model \\( \\theta_{MAGMAX} = \\theta_0 + \\lambda * \\tau_{MAGMAX} \\), where \u03bb is a scaling factor."}, {"title": "Experimental setup", "content": "For class-incremental learning (CIL) experiments we use CIFAR100 [20] and ImageNet-R [11] as generic image recognition benchmarks and CUB200 [40] and Cars [19] as fine-grained classification datasets. We split the datasets into N equal subsets of disjoint classes, where N \u2208 {5, 10, 20, 50} for generic benchmarks and N \u2208 {5, 10, 20} for fine-grained benchmarks (which contain less data).\nTo compare between class- and domain-incremental learning (DIL) we use ImageNet-R and DomainNet [29]. For domain-incremental learning experiments, we split DomainNet into 6 tasks by their domain (clipart, infographics, painting, quickdraw, real and sketch) and ImageNet-R into 15 tasks by their renditions"}, {"title": "Main results", "content": "Table 1 presents the comparison of MAGMAX with CL methods and merging-based baselines on various class-incremental learning benchmarks. MAGMAX consistently outperforms the competitors across the scenarios that vary in number of tasks and dataset granularity, achiev- ing on average 2.1% better results than the second best method. Interestingly, simple baselines that merge independent fine-tunings by averaging (Avg) or even randomly mixing (RandMix) the weights, are close competitors to CL meth- ods and other merging strategies."}, {"title": "Extended analysis", "content": "In this Section, we broaden the scope of our analysis. We investigate the impact of maximum magnitude selection merging on existing CL methods. We also study the impact of sequential fine-tuning on other model merging strategies in both CIL setting and on the popular eight datasets benchmark."}, {"title": "Conclusion", "content": "In this paper, we introduced MAGMAX, a novel approach to continual learning that leverages model merging via maximum magnitude selection alongside se- quential fine-tuning. Our findings underscore the potential of model merging as a viable solution to the challenges of continual learning. The synergy between sequential fine-tuning and maximum magnitude weight selection emerges as a pivotal factor in this success. It opens up possibilities for future research direc- tion focused on developing fine-tuning methods that facilitate model merging or finding new, more effective strategies for selecting important parameters in realms of continual learning."}]}