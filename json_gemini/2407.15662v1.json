{"title": "HOW TO SHRINK CONFIDENCE SETS FOR MANY EQUIVALENT DISCRETE DISTRIBUTIONS?", "authors": ["Odalric-Ambrym Maillard", "Mohammad Sadegh Talebi"], "abstract": "We consider the situation when a learner faces a set of unknown discrete distributions $(p_k)_{k \\in K}$ defined over a common alphabet X, and can build for each distribution $p_k$ an individual high-probability confidence set thanks to $n_k$ observations sampled from $p_k$. The set $(p_k)_{k\\in K}$ is structured: each distribution $p_k$ is obtained from the same common, but unknown, distribution $q$ via applying an unknown permutation to X. We call this permutation-equivalence. The goal is to build refined confidence sets exploiting this structural property. Like other popular notions of structure (Lipschitz smoothness, Linearity, etc.) permutation- equivalence naturally appears in machine learning problems, and to benefit from its potential gain calls for a specific approach. We present a strategy to effectively exploit permutation-equivalence, and provide a finite-time high-probability bound on the size of the refined confidence sets output by the strategy. Since a refinement is not possible for too few observations in general, under mild technical assumptions, our finite-time analysis establish when the number of observations $(n_k)_{k \\in K}$ are large enough so that the output confidence sets improve over initial individual sets. We carefully characterize this event and the corresponding improvement. Further, our result implies that the size of confidence sets shrink at asymptotic rates of $O(\\frac{1}{\\sqrt{\\Sigma_{k \\in K}n_k}})$ and $O(\\frac{1}{max_{k \\in K} n_k})$, respectively for elements inside and outside the support of $q$, when the size of each individual confidence set shrinks at respective rates of $O(\\frac{1}{\\sqrt{n_k}})$ and $O(\\frac{1}{n_k})$. We illustrate the practical benefit of exploiting permutation equivalence on a reinforcement learning task.", "sections": [{"title": "1 Introduction", "content": "Like Lipschitz smoothness, linearity or sub-modularity, leveraging a structural property of a set of unknown distributions, that can be known only by sampling, is generally the key to better statistical efficiency, hence improved learning guarantees. In this paper, we consider a learning task involving a set of unknown distributions $(p_k)_{k\\in K}$ over a discrete alphabet X CN that are known to satisfy a structural property called permutation-equivalence. Intuitively, this means all the distributions are actually the same up to a shuffling of the entries. Formally, permutation-equivalence means that there exists a common distribution $q$ over X such that each distribution $p_k$, $k \\in K$ is obtained from $q$ after applying some permutation $\\sigma_k$ of its entries (See Definition 1).\nPermutation-equivalence can be spotted in several situations. For instance in a decentralized learning task where K is a set of learners, different learners may number the observation space differently. Hence every process $q$ on the observation space will be seen as a different $p_k$ by learner k. Permutation-equivalence also naturally appears in reinforcement learning. Indeed in several environments such as RiverSwim and grid-world Markov Decision Processes (2-room, 4-room, frozen-lake, etc.)\u00b9, probability transitions from two different state-action pairs are usually not arbitrarily different: In grid-worlds, the set of next-state transitions $(p(\\cdot|s,a))_{s\\in S_o,a\\in A}$, where $S_o$ denotes all states with no neighboring wall, typically exhibits permutation-equivalence. This has been considered in [1, 2]. Likewise, a windy grid-world [3], sailboat [4], or RiverSail environment (see Appendix A) in which navigation is similar in each state or river channel except for the presence of a wind of unknown but constant direction also exhibit permutation-equivalence structure. Naturally, in practice a given task may present further structural properties beyond equivalence; we focus in this paper on the benefit that exploiting permutation-equivalence only can bring to the learner.\nExploiting permutation-equivalence, like any other structural assumption, is especially beneficial in when acquiring data from distributions is costly. In the context of statistical estimation where a learner has only access to $n_k$ samples from distribution $p_k$, for each $k \\in K$, by exploiting the structure we mean to build, using all samples, tighter confidence sets around each $p_k$ than the initial \u201cindividual\" confidence"}, {"title": "2 Setup and Notations: Tightening Estimation using Equivalence", "content": "For a finite alphabet X CN we denote by $P(X)$ the set of probability distributions over X and by Gx the group of permutations over X. Each permutation $\\sigma \\in G_x$ acts as perfect matching (one-to-one mapping of X). We consider a set $(p_k)_{k\\in K} \\subset P(X)$ of K = |K| many distributions on X. We assume they are all generated from the same common underlying distribution, after applying different permutation of X. More formally, we introduce the following definition:"}, {"title": "Definition 1 (Permutation-equivalent set).", "content": "Distributions $(p_k)_{k \\in \\kappa}$ are said to be equivalent under Gx (Gx-equivalent), if there exists a common distribution q such that each $p_k$ is obtained by applying one of the permutation from Gx to q, namely,\n$\\exists q \\in P(X), (\\sigma_k)_{k\\in K} \\subset G_X : \\forall k \\in K, p_k = q \\circ \\sigma_k$.\nWe call q the canonical distribution of $(p_k)_{k\\in K}$, and $(q, (\\sigma_k)_{k \\in K})$ its canonical representation.\nRemark 1. Definition 1 naturally extends beyond finite X and permutations, to any set X with correspond- ing set Gx of deformations (automorphisms). It also extends beyond P(X) to functions.\nEmpirical estimates and confidence sets. The learner does not know the distributions $(p_k)_{k \\in \\kappa}$. Instead, for each $k \\in K$, a sample $(X_{k,i})_{i<n_k}$ of $n_k$ many i.i.d. observations from $p_k$ is given, to form the empirical distribution $\\hat{p}_k$. More formally,\n$\\forall x \\in X, \\hat{p}_k(x) := \\hat{p}(S_{k,x}) := \\frac{1}{|S_{k,x}|} \\Sigma_y where S_{k,x} = (\\mathbb{I}{X_{k,i} = X})_{i<n_k}$ .\nFurther, the learner has access to a procedure Cl to build confidence sets. For each given $S_{k,x}$, and confidence level $\\delta\\in (0, 1)$, it builds $c\\hat{h}_{k,x} := CI(S_{k,x}, \\delta)$ such that $\\forall k \\in K, P(\\exists x\\in X, P(\\exists x\\in X, p_k (x) \\notin c\\hat{h}_{k,x}) \\le \\delta$. Such sets are obtained only based on the sample $S_{k,x}$, ignoring the G-equivalence structure. Noting that $S_{k,x}$ is a sample from a Bernoulli distribution with parameter $p_k(x)$, we consider confidence intervals written as follows:\n$CI(S, \\delta) = \\{x \\in [0, 1] : d(\\hat{p}(S), 1) \\le b(\\delta, |S|, \\delta)\\}$.\nwhere $d$ is some distance function, and $b$ is a decreasing function of the sample size |S|. For example, the confidence interval defined using Bernstein's concentration inequality for [0, 1]-bounded observations (see [21]) uses $d(x, y) = |x - y|$ and\n$b^{Berns}(\\delta, |S|, \\delta) = \\frac{1}{|S|} \\sqrt{2x(1-x) log (\\frac{2}{\\delta})} + \\frac{7 log (\\frac{2}{\\delta})}{3|S|}$.\nEquation (2) allows for greater flexibility, and examples are discussed in Appendix D.\nRefined estimates and confidence intervals. The goal of the learner is to output novel confidence sets $(C\\hat{I}_{k,x})_{k\\in K,x\\in x}$ for $(p_k)_{k\\in K}$ called the refined confidence sets, that exploit G-equivalence and make use of all samples $(S_{k,x})_{k\\in K,x\\in x}$. More precisely, these sets $(C\\hat{I}_{k,x})_{k\\in K,x\\in x}$ must satisfy:\n$\\nu\\delta \\in (0,1), k\\in K, P(x \\in X, p_k(x) \\notin C\\hat{I}_{k,x} (\\delta)) \\le \\delta$.\nFurther, they must (i) not depend on any unknown quantity, and (ii) be of as small size as possible.\nWarming-up: K = 2. To conclude this section, we provide some insights in the simplified case of K = 2 distributions, and discuss preliminary ideas to build refined confidence sets.\nFigure 1 provides an example of two distributions (shown in blue and red), defined on the same alphabet of size 6. Their true (unknown) values are depicted, together with the initial (not refined) confidence interval built from some samples. Let $c_i$ denote the confidence interval at point $x_i$ for the top (red) distribution, and $d_i$ for the down distribution. We observe that $d_1$ has non-empty intersection with $c_1, c_2, c_3$. More generally, one can consider all possible intersections compatible with Gx equivalence (see Figure 2). This can used to build a bipartite graph with class blue and red, and edges showing non-empty intersections. From Figure 2, $d_3$ can only match $c_1$, from which we deduce that $d_1, d_4$ can only match $c_2, c_3$. Hence, due to the one-to-one assignment, $d_2$ can only match $c_4, c_5$. The same holds for $d_6$, which implies that $d_5$ is only compatible with $c_6$. Hence, in this case, although the confidence intervals are not especially tight, it is possible to show that if $p_1 = q$ and $p_2 = q \\circ \\sigma_2$, then $\\sigma_2$ can only be one of out of four possible permutations (out of 720 candidates). Further, we can easily tighten the confidence bounds based on the pruned sets of compatible matchings. For instance, from Figure 2, the confidence interval on point $x_2$ becomes $d_2 \\cap C_4 \\cup C_5$. Proceeding similarly for each point leads to the refined bounds presented in Figure 1, right.\nEven in this simple example, an optimal pruning does not lead to a unique permutation, but four. As the sets $c_i$ and $d_i$ become larger (fewer observations), pruning becomes less effective, keeping more permutations thus yielding less and less refined confidence sets. Listing all possible permutations to"}, {"title": "3 Building Confidence Sets Exploiting Permutation Equivalence", "content": "In this section, we detail our simple strategy to output confidence sets exploiting Gx-equivalence from an unstructured set of individual confidence sets. It relies on Algorithm 1 then Algorithm 2.\nIdentification of Compatible Matchings. At a high level, the procedure consists in two steps: first building the graph of compatible matchings (non-empty intersections), which can be done in at most $|X|^2 K^2$ steps. Second, exploiting the property that permutations are one-to-one to prune the set of compatible matchings (starting from a set c with the smallest number J of matchings $(c)_{j\\le 1}$). This step is in general combinatorial: In the previous example, after removing the obvious assignment of $d_3$ to $c_1$, identifying that the pair $d_1, d_4$ should match the pair $C_2, C_3$ requires searching for a permutation over a subset of size 2 (done here using that $C_2, C_3$ also matches $d_1$). More generally, fully exploiting the structure requires searching for permutations over subsets of arbitrary any size, which is computationally demanding (see [20]). In order to keep a low computationally, we restrict the size of the permutations the algorithm is looking for to a predefined maximal value L (say 3), yielding Algorithm 1. This results in a pruning whose computational complexity can be controlled.\nRefined Concentration Sets. The last step is to build the refined confidence intervals from the set of compatible matchings out put by Algorithm 1. Indeed, for each point x and index k, it outputs sets $(I_{k,x,k'})_{k'}$, so that each k' \u2208 K\\{k} may contribute to refining the confidence sets.\nCase 1: $I_{k,x,k'}$ is a singleton. The situation when $I_{k,x,k'}$ is a singleton, say $I_{k,x,k'} = \\{x'\\}$ is simple to handle, since we then know that x can only be mapped to x'; we thus simply denote it $x_{k'}$ in the sequel. This means we can group together the sample $S_{k,x}$ (coming from (x, k)) and the sample $S_{k',x'}$ (coming from (x', k')) to form a novel confidence set. This suggests to introduce\n$K_{k,x} = \\{k' \\in K \\backslash \\{k\\} : |I_{k,x,k'}| = 1\\} \\cup \\{k\\}$,"}, {"title": "Case 2:", "content": "$I_{k,x,k'}$ is not a singleton. When $|I_{k,x,k'}| > 1$, there is an ambiguity to matching x from distribution k to another point related to distribution k'. In the worst case there are L possible matchings for each k' \u2260 k, hence resulting in $L^{K-1}$ possible combinations. With infinite computational power, one could form for each combination its corresponding sample, compute the corresponding confidence set combining all the observations in this sample, and then, to account for the ambiguity of the matchings, take the union of all these confidence sets. This would mean to compute\n$\\cup_{(x_{k'})_{k'}\\backslash K_{k'x} \\in I_{k,x,k'}} CI(\\cup_{k' \\in K} S_{k'x},\\delta)$,\nwhich is exponential in K. In order to avoid this computational blow-up, we proceed differently: For each $k' \\notin K_{k,x}$, we do not group observations but build the union of confidence sets $(c\\hat{h}_{k'}) x'\\in I_{kk}$, then simply intersect all the resulting sets. The cost of this computation is O(KL) and is no longer exponential in K. Combining the refinements obtained from case 1 and case 2 yields the sets $C\\hat{I}_{k,x}(\\delta)$ summarized in Algorithm 2."}, {"title": "Numerical illustration of Algorithm 2.", "content": "We examine the performance of Algorithm 2 on a small problem with K = 3 discrete distributions, defined on an alphabet of size 12, that are Gx-coherent. Our goal is to demonstrate the empirical reduction in the size of confidence intervals output by Algorithm"}, {"title": "4 The Statistical Benefit of Permutation Equivalence", "content": "The refinement strategy (Algorithms 1-2) is sound provided that each confidence interval $c\\hat{h}_{k} = CI(S_{k,x}, \\delta)$ is valid, which happens with probability higher than 1\u2013\u03b4, for all x and each k. Let $\\Omega := \\{\\forall x, \\forall k, p_k(x) \\in CI(S_{k,x}, \\delta)\\}$ be the event that all initial confidence sets are valid. A union bound over all k \u2208 K shows that P(\u03a9) \u2265 1 \u2013 \u039a\u03b4. The aim of this section is to assess the gain of using refined confidence sets exploiting permutation-equivalence. In order to simplify the presentation of the results, we consider Cl given in (2), and introduce the notion of surrogate confidence intervals:"}, {"title": "Definition 2 (Surrogate Confidence Intervals).", "content": "Let S be a sample set, \u03b4 \u2208 (0,1), and consider a confidence interval Cl of the form (2). For some deterministic function B, we define\n$SCI(S, \\delta) = \\{x \\in [0, 1] : [(\\hat{p}(S)-x|\\le B(\\delta, |S|, \\delta)\\}$.\nSCI is a surrogate confidence interval (for short, a surrogate) for Clif $\\forall S, \\delta, CI(S, \\delta) \\subseteq SCI(S, \\delta)$.\nFor example, Cl and SCI coincide when Cl is built from Hoeffding inequality. In Section C, we report surrogates of some other standard confidence intervals. The surrogates are only used to simplify the analysis; the algorithm still uses the original confidence sets.\nOur result involves some problem-dependent quantities. For p \u2208 P(X), let $X_p \\subseteq X$. Further, for a given set ACK, we define $n_A = \\sum_{k \\in A} n_k$ and $\\tilde{n}_A=max_{k \\in A}n_k$. We also make the following mild assumption (it is without loss of generality by density of the set of such distributions):\nAssumption 1. We assume that q is monotone on its support $X_q$.\nThe following theorems show precisely the interplay between the problem-dependent gaps and the finite number of observations. The first one concerns the elements inside the support:"}, {"title": "Theorem 1 (Concentration benefit for $x \\in X_{p_k}$).", "content": "Under Assumption 1 and the event \u03a9, it holds for all k, for all $x \\in X_{p_k}$ (points in the support of $p_k$),\n$C\\hat{I}_{k,x}(\\delta) \\subseteq SCI (\\frac{\\delta}{K}) \\subseteq SCI (\\frac{\\delta}{Kk,x})$, where\n$\\check{K}_{k,x} = \\{k\\} \\cup \\{k'\\in K\\backslash\\{k\\}: \\forall x'\\in X \\backslash \\{x\\}, \\frac{|p_k(x) - p_k(x')|}{2} > B(p_k(x), \\check{n}_k, \\delta) + B(p_k(x'), \\check{n}_{k'}, \\delta)\\}$.\nWe remark that $\\check{K}_{k,x}$ is a problem-dependent, explicit and deterministic set. We now focus on the remaining points."}, {"title": "Theorem 2 (Concentration benefit for $x \\notin X_{p_k}$).", "content": "Under Assumption 1 and the event \u03a9, it holds for all k and all $x \\notin X_{p_k}$,\n$C\\hat{I}_{k,x} (\\delta) \\subset \\{\\lambda: \\lambda \\le B(\\hat{p}_k(x), \\check{n}_k,\\delta)\\}, if |X \\backslash X_{p_k}| > 1\nC\\hat{I}_{k,x} (\\delta) \\subset \\{\\lambda: \\lambda \\le B(\\hat{p}_k(x), \\check{n}_k, \\delta)\\}, else,\nwith $\\check{K}_k = \\{k\\} \\cup \\{k' \\neq k : q_{min} > q_k(n_k)\\}$, where we introduced $q_{min} := min_{x\\in X_q, q(x)>0} q(x)$ and $q_k(n) = Sup_{x \\in X_{p}} \\{2(B(p_k(x), \\eta, \\delta) + B(0, \\eta_{k'}, \\delta))\\}$.\nFor a given k and x, $\\check{K}_{k}$ and $\\check{K}_k$, are explicit deterministic sets (unlike $\\check{K}_{k,x}$) that depend on the unknown distributions and number of observations. They capture the problem-dependent complexity of the problem. Hence Theorems 1 and 2 guarantee a control of the size of the refined confidence sets in terms of deterministic problem-dependent sets, that is for each instance of the distribution, and each value of each $n_k$. This contrasts with purely asymptotic results only showing a speed-up in the limit of a large enough number of observations, as it also enables to capture threshold effects. Also, it makes precise the intuition that the improvement increases with the number of observation, and becomes maximal when all initial confidence sets for each distribution are perfectly separated.\nRemark 2 (Asymptotic behavior). When Clis built based on Bernstein's concentration inequality, $b(p, \\eta, \\delta)$ scales as $O(\\sqrt{p/n})$ for positive p, and $O(1/n)$ for p = 0. Likewise, $q_k(n)$ scales as 1/n. Hence, we obtain as the corollary the following asymptotic control on the size of the confidence sets\n$|C\\hat{I}_{k,x}| = \\{\nO(\\frac{1}{\\sqrt{n\\bar{K}}} k}) for x \\in X_{p_k},\n\\frac{1}{\\check{n}}\\quad for x \\notin X_{p_k}.\n\\}$"}, {"title": "Impact of L.", "content": "The acute reader may notice that L does not appear in Theorems 1 and 2. The reason is that these are worst-case results, stated for Algorithm 2 with input plausible matchings not necessarily pruned by Algorithm 1. Indeed the primary role of L is to reduce the number of tests in the pruning process, hence computations and possibly reduce the set of plausible matchings. However, this does not imply reduction of confidence sets. Figure 5 actually shows that L little affects the size of the refined confidence sets in practice. Since L significantly affects computation time of Algorithm 1, we suggest the practitioner to scale L to keep it low.\nIn Figure 5, we plot the averaged ratio of the initial confidence set to the refined one over several experiments. We consider an alphabet X of size 10 and distributions q with support of size 6. For each q, we generate a problem with K = 5 equivalent distributions, and build the initial and refined confidence sets using empirical Bernstein confidence bounds. One distribution is estimated with $N_1$ observations while all others have $N_1/4$ observations. We then compute for each x \u2208 X the ratio between the size of these sets, and store the min, max and average of these values. Finally, we average all results over 100 randomly generated core distribution q. Figure 5 (left), shows that considering large values of L (which is computationally demanding), has negligible effect to sharpen the confidence sets. It uses $N_1 = 200$. Even for L = 1, they already divide the size of the initial ones by a factor close to 1.1 on average and up to 1.8. Figure 5 (right) shows the effect of $N_1$, for L = 5. When $n_k \u2192 \u221e$ and under Assumption 1, confidence sets become uniquely separated for any value of L > 1, hence producing maximal shrinkage. When $n_k$ are too small, no improvement is possible. The situation in between these situations makes appear a non-trivial behavior, as expected.\nThere is an intrinsic trade-off between statistical and computational efficiency. For instance here making \"optimal\" use of the structure involves solving an NP-hard problem, which definitely does not scale with K or X. Algorithm 2 aims at solving a relaxation of such NP-hard problem, enjoying a computational complexity of O(KL), as opposed to e.g. $L^K$ or worse complexity when targeting an exact but unnecessary solution. When O(KL) is still considered large, one may further split the set of distributions into smaller groups, with a size growing sublinear in K, and still benefit from local speed-up, gaining computational efficiency at the expense of sacrificing statistical efficiency."}, {"title": "Examples of surrogate sets.", "content": "For completeness and illustration, we present in the following table some confidence intervals constructed using some well-known concentration inequalities, and provide their corresponding surrogate intervals. We detail these derivations in Appendix C.\nConfidence set d b(\u03bb, S, \u03b4) in (2) B(p, S, \u03b4) in (3)\nKullback-Leibler KL \u03be\u03b7(\u03b4, |S|)||S| V\u03be\u03b7 (\u03b4, \u03b4)\n\nBernstein Berns(1, S, \u03b4) = 2\u03bb(1-\u03bb) log () 4.8 log (2\nS S S\nEmpirical Bernstein emp-Berns(\u03bb, S, d) = 2V(S) log (4x) V2p(1-p) log () V10 log (\nS S S"}, {"title": "An application to Reinforcement Learning.", "content": "We now briefly illustrate the benefit of the proposed algorithm on an undiscounted RL task. We consider the simple and popular RiverSwim environment (see Figure 8 in Appendix), and the average gain optimality criterion [22], when a learner interacts with an unknown MDP in a single stream of actions and observation until some unknown time horizon. RiverSwim exhibits a structure of permutation-equivalence of the next-state transition distributions, as observed already in [1], with 4 clearly identified classes (4 distinct sets of distributions). In [1], the authors propose a strategy called C-UCRL that adapts UCRL2 [23] to incorporate permutation-equivalence, assuming that the underlying permutations $(\\sigma_k)_{k \\in K}$ for each set K are known. However no specific mechanism is proposed to refine the confidence bounds when permutations are unknown. Algorithm 2 perfectly applies to this situation. Closely following [1], we easily derive the C-UCRL2B algorithm by adapting UCRL2B [24, 25] and making use of our refinement procedure on each of the four group of next-state distributions known to be equivalent, using the same confidence sets as chosen in UCRL2B. We compare this modified strategy against the state-of-the-art UCRL2B in Figure 6, showing the substantial reduction of the regret even in this arguably simple environment.\nNear-equivalence. We have discussed how to exploit the permutation-coherent structure. In practice, like any structural assumption (Lipschitz smoothness, Linearity, etc.) one may face situations of imperfect structure. We briefly discuss the case when the equivalence structure is either not exactly known or one can tolerate some error while mistakingly grouping samples from non-equivalent distributions. The goal is not to estimate the structure, but rather to provide insights into simple modifications that can help deal with such situations.\nLet us consider an \u025b-approximation of the deformation equivalence property, meaning that only $\\exists q, \\forall k, ||P_k - q\\circ \\sigma_k||_{TV} \\le \\varepsilon$ for some known $\\varepsilon$ is ensured. Note that if $p_k, p_{k'}$ are not exactly equivalent, one can separate the two distributions asymptotically, which means that for large number of observations, it happens that $\\exists x : I_{k,x,k'} = \\emptyset$. We modify Algorithm 1 to set $I_{k,x',k'} = \\emptyset$ for all others $x' \\in X\\backslash\\{x\\}$ in that case. When no separation happens, Algorithm 2 will produce refined confidence bounds guaranteed to be biased by at most \u025b. In case one can tolerate such a bias, the strategy can be kept unchanged. If one can only tolerate an error of $\\eta <\\varepsilon$, we modify Algorithm 2 to first compute $\\check{K}_{k,x}$, then\n$\\check{K},z= \\{k'\\in K\\backslash\\{k\\}: |I_{k,z,k'}|=1 and diam(CI(S_{k',2,1},\\delta)) \\le\\eta\\} \\cup \\{k\\}$,\nwhere diam denotes the diameter of the considered interval; we finally redefine the confidence set:\n$C\\hat{I}_{k,x} (\\delta) = CI(\\cup_{k'\\in \\check{K}} S_{k',x_k'},\\delta) \\cap \\cup_{(x')} CI(S_{k',x'})$"}, {"title": "5 Conclusion", "content": "In this paper, we have studied the benefit of using a permutation-equivalence property of a set of unknown distributions $(p_k)_{k\\in K}$ to produce a refinement of the confidence sets one may build for each $p_k$ based on observations from $p_k$ only. Leveraging this structure for estimation complements other popular setups involving permutations, such as matching of known distributions (optimal transport), or decision making with structured output. We brought a finite-time analysis using concentration inequalities to control the potential refinement for each given number of observations $(n_k)_{k\\in K}$ in a problem-dependent way, and provide an algorithm with low-computational complexity to build the underlying matchings. Applied to standard Bernstein confidence sets, this enables to get sizes of confidence intervals asymptotically scaling as $O((\\Sigma_k n_k)^{-1/2}))$ for points in the support of the distributions and $O((max_k n_k)^{-1/2})$ for points outside the support, plus to characterize the full finite-time behavior. A possible extension of this work is on the one hand to go beyond discrete space X and study other automorphisms structures (e.g. rotations for X = $R^d$, etc.), and on the other hand to apply similar ideas in various machine learning and RL setups."}, {"title": "A The RiverSail Environment", "content": "We depict in Figure 7 a discrete version of the RiverSail environment. It is similar to the windy grid-world [3] or sailboat [4] environment. In this grid-world MDP, an agent must sail on different rivers while collecting rewards (red states) on the way; exiting a channel (entering dashed states) randomly sends the agent to enter another channel. In each river channel, navigation is similar except for the presence of a constant wind, shown in the top-left corner of each channel, whose direction is unknown, as in a windy windy grid-world: When a boat in a pink position moves in the direction of the arrow, it ends up in the gray states, shaded according their probability level. All states with dark blue edges in the same region behave similarly. Here, the exact next-state probability masses are unknown by the sailor, yet she knows perfectly which transitions are equivalent; the permutations between next-state distributions are still unknown due to the unknown wind. Exploiting this structure may massively reduce learning time of the unknown dynamics.\nWe also provide below an illustration of the RiverSwim environment used in our application to reinforcement learning. It has been used in [1] as well. This is a standard MDP with L states and 2 actions (left, right). The RiverSwim environment has 4 classes of equivalent state-action pairs. One class for all\nstates and action left, one class for states 2 to L - 1 with action right, and one class for each of state 1 with action right, and state L with action right. That is, when going right, there is one class for each borders of the river and one for the river itself, and there is one further class for all states when going left."}, {"title": "B Benefits of Permutation Equivalence: Proofs", "content": "Proof of Theorem 1 and Theorem 2:\nWe first handle the points that belong to the support of the considered distributions, then turn to handling the points outside of the support. The reason for doing so is that, by the monotonicity assumption on q (that is, all masses are different), the permutation is uniquely defined on the support. However, it is not uniquely defined outside of the support, which calls for a modified proof.\nTo simplify the notation, throughout we omit the dependence of various quantities on \u03b4. Given k and x, denote $CI_{k,x} := CI(S_{k,x},, \\delta)$, and define $CI_{k,x}^+ = max\\{x \\in CI_{k,x}\\}$ and $CI_{k,x}^- = min\\{x \\in CI_{k,x}\\}$.\nStep 1: Points with positive mass. On the one hand, (k', x') is not compatible with (k, x) if\n$CI_{k,x}^+ < CI_{k',x'}^-$ or $CI_{k,x}^- > CI_{k',x'}^+$"}, {"title": "In view of the definition of SCI, this implies that", "content": "$p_k(x) + B(p_k(x)", "where\n$\\check{K}_{k,x}": {"K\\backslash\\{k\\}": "forall x_1\\in X\\backslash\\{x\\}, \\frac{|p_k(x)-p_k(x_1)|}{2} > B(p_k(x), n_k)+B(p_k(x_1), n_{k'})\\}$ .\nIn particular, since"}}]}