{"title": "Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors", "authors": ["Usman Syed", "Ethan Light", "Xingang Guo", "Huan Zhang", "Lianhui Qin", "Yanfeng Ouyang", "Bin Hu"], "abstract": "In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, GPT-40, Claude 3.5 Sonnet, Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level transportation engineering problems. We introduce TransportBench, a benchmark dataset that includes a sample of transportation engineering problems on a wide range of subjects in the context of planning, design, management, and control of transportation systems. This dataset is used by human experts to evaluate the capabilities of various commercial and open-sourced LLMs, especially their accuracy, consistency, and reasoning behaviors, in solving transportation engineering problems. Our comprehensive analysis uncovers the unique strengths and limitations of each LLM, e.g. our analysis shows the impressive accuracy and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving TransportBench problems. Our study marks a thrilling first step toward harnessing artificial general intelligence for complex transportation challenges.", "sections": [{"title": "1. Introduction", "content": "In recent years, the advent of artificial intelligence has heralded a new era of computational technology, fundamentally reshaping how we approach problem-solving across diverse domains. Among these, large language models (LLMs) stand out for their sophisticated ability to understand and generate human-like text, offering unprecedented opportunities for innovation across various domains including coding (Nijkamp et al., 2022; Nam et al., 2024; Xu et al., 2022; Chew et al., 2023; MacNeil et al., 2022), reasoning (Wei et al., 2022b; Huang and Chang, 2022; Zhou et al., 2022; Sun et al., 2023; Havrilla et al., 2024), planning (Valmeekam et al., 2022, 2024; Zhao et al., 2024; Song et al., 2023; Dagan et al., 2023), mathematics (Imani et al., 2023; Azerbayev et al., 2023; Frieder et al., 2024; Zhang et al., 2024a; He-Yueya et al., 2023), and science (Wang et al., 2023; Birhane et al., 2023; Ouyang et al., 2023; Yeadon and Hardy, 2024; Chen and Deng, 2023). The scientific community, as well as the general public, have been wondering how soon, if not already, LLMs will be capable of solving complex problems that involve not only general common knowledge, but also advanced, domain-specific terminologies and analytical skills. The educators and researchers are also particularly intrigued by (i) how the advancement of LLMs will impact the future of research, education, and workforce development, and (ii) how the current practice should be adapted or tailored to best accommodate and take full advantage of the LLMs' capabilities. To answer these questions, the first step is to keep track of and understand the development trends of LLMs with respect to the respective fields of interest, and to identify ways to help LLMs best achieve their positive potential for societal impacts.\nTransportation systems engineering is a critical interdisciplinary subfield of civil engineering, focusing on developing principles for the planning, design, operations, and management of all modes of transportation for people and goods (Cascetta, 2009; Fricker and Whitford, 2004). It encompasses various topics such as transportation economics, driver and vehicle characteristics, guideway geometric design, traffic flow and control, planning and demand modeling, utility and modal split, network analysis, and public transit systems (Daganzo and Ouyang, 2019), and is currently undergoing rapid technology-driven revolutions (such as autonomy, connectivity, electrification, and shared economy). The problems in this field combine mathematical foundation with strong engineering, social, and economic principles, making this field particularly ripe for technological interventions with LLMs, and at the same time, an ideal benchmark context for assessing the reasoning capabilities of LLMs.\nWith such a motivation, our paper studies how state-of-the-art LLMs such as GPT-4 (Achiam et al., 2023), GPT-40 (OpenAI, 2024), Claude 3.5 Sonnet (Anthropic, 2024b), Claude 3 Opus (Anthropic, 2024a), Gemini 1.5 Pro (Team et al., 2023, 2024), Llama 3 (AI@Meta, 2024a), and Llama 3.1 (AI@Meta, 2024b) can be leveraged to tackle undergraduate-level transportation engineering problems, potentially transforming the landscape of this vital engineering discipline. Understanding such capabilities of LLMs could signify a substantial leap towards a likely and exciting future of transportation engineering in which artificial general intelligence is seamlessly equipped with specialized domain-specific human expertise to enhance productivity and creativity of this engineering field. Our paper first introduces TransportBench, a benchmark dataset specifically designed to encapsulate the essential elements of transportation engineering. Our TransportBench dataset is designed to cover a wide range of subjects, form the foundation of our investigation, and enable a structured evaluation of how various LLMs perform in a domain traditionally dominated by human expertise. TransportBench captures the complexities and nuances of transportation engineering problems, providing a rigorous testing ground for assessing the problem-solving abilities of various commercially available and open-sourced LLMs. We present evaluations conducted by human experts to evaluate the outputs of these LLM models, focusing on their accuracy and consistency. These evaluations are critical, as they provide insights not only into the effectiveness of each model but also into their potential to integrate with existing engineering practices. Our study also identifies the unique strengths and limitations of each LLM, e.g. our analysis shows both the impressive overall accuracy and some unexpected inconsistent behaviors of Claude 3.5 Sonnet when tested on TransportBench. Our contributions can be summarized as follows.\n\u2022 We introduce an open-source new natural-language dataset called TransportBench, designed to test the capabilities of LLMs in solving undergraduate transportation system problems.\n\u2022 We evaluate the accuracy of GPT-4, GPT-40, Claude 3 Opus, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3, and Llama 3.1 on TransportBench, conducted by human experts. Our analysis shows that leading LLMs can achieve promising accuracy on TransportBench, and Claude 3.5 Sonnet achieves the highest accuracy on TransportBench among all the LLMs.\n\u2022 We further evaluate the consistency of these LLMs on TransportBench. Interestingly, we observe that Claude 3.5 Sonnet and Claude 3 Opus give less consistent answers when asked to double check their own solutions \u2013 this suggests a lack of deep conceptual understanding. In contrast, GPT-4 and GPT-4o give the most consistent responses in such a setting.\n\u2022 We carefully examine the reasoning behaviors of LLMs on TransportBench by twisting some problems from TransportBench. This provides the first study of LLM reasoning in the context of solving basic transportation system problems.\nOur study marks a significant step toward harnessing LLMs in the realm of civil engineering. Inspired by the capabilities of LLMs in transportation engineering, it is exciting to envision a promising future where transportation systems are dynamically managed, with AI predicting and mitigating traffic congestion, optimizing maintenance schedules, and even designing next-generation infrastructure with unparalleled efficiency. It is our hope that our exploration into the intersection of LLMs and transportation system engineering will set the stage for further research and development, potentially revolutionizing the way we design, build, and maintain our transportation systems in the future."}, {"title": "2. The TransportBench Dataset", "content": "We first create a collection of 140 undergraduate problems that span a broad spectrum of topics including transportation economics, driver characteristics, vehicle motion, road geometry design, traffic flow/control, transportation planning, utility/modal split, transportation networks, and public transit systems. TransportBench consists of both the true or false problems and the general Q&A problems. We summarize the statistics of our TransportBench dataset for each topic in Table 1.\nHuman expertise in data creation. All the problems in TransportBench are selected by the sixth author of this paper based on two of his courses at the University of Illinois: a junior-level introductory course CEE 310 - Transportation Engineering (taught 14 times) and a senior-level focused course CEE 418 - Public Transportation Systems (taught 11 times). Those for the first nine topics in Table 1 are twisted from CEE 310, while those for the last topic \"public transit systems\" are from CEE 418. Some of the CEE 418 problems are twisted from a co-authored textbook (Daganzo and Ouyang, 2019). Any figure(s) in an original problem are replaced by language descriptions. Together, these problems capture many key areas of current transportation systems engineering, and provide a reasonable benchmark test for LLMs. The solutions to most TransportBench problems are prepared by the second author.\nData format. We collect each problem from original documents in PDF files and presentation slides. We manually transfer these problems into LaTeX format. All the problems are carefully verified by human annotators to ensure that LaTeX documents can be compiled without any syntax errors. In addition, we also provide a detailed step-by-step solution for each problem in LaTeX. For ease of evaluations, we have also provided JSON-formatted files for TransportBench. All the files for our TransportBench dataset are available at https://agi4engineering.github.io/TransportBench/."}, {"title": "3. Evaluating Accuracy of Leading LLMs on TransportBench", "content": "Now we are ready to evaluate the accuracy of leading LLMs such as GPT-4, GPT-40, Claude 3 Opus, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3 (70B) and Llama 3.1 (405B) on TransportBench. In this section, we consider a zero-shot prompting strategy (i.e., directly inputting the question) and examine the web-version LLM responses through human expert annotation (our analysis does not require using APIs or local models). The inputs to the web-version LLMs are just the original problem descriptions from TransportBench. The zero-shot setting is fundamentally important (Kojima et al., 2022) and serves as a meaningful starting point for our analysis. We first present two examples (i.e. one general Q&A problem and one True or False problem) to illustrate the zero-shot setting and showcase the capabilities of LLMs in solving transportation problems. First, consider the following transportation economics problem."}, {"title": "Zero-Shot Setting (General Q&A Problem): Problem 2.5 from TransportBench", "content": "Input: Suppose you have one widget plant at the center of a sufficiently large country of size $S$ mi\u00b2, where population is uniformly distributed with a density of $\\delta$ people/mi\u00b2. The production cost is $C$ per unit, and the selling price is $P$ per unit, and it can sell $D$ widgets per person per year everywhere in the country. Transportation costs include a fixed cost of $F$ per unit and a variable cost of $f$ per widget-mile. Suppose $P > C + F$. Determine the shape, size and the total demand of your market.\nGPT-4: To solve this problem, we need to determine the region around the widget plant where it is profitable to sell widgets Since $P > C + F$, we can determine the break-even distance $d$ where the selling price equals the total cost: $P = C + F + fd$\n$d = \\frac{P-C-F}{f}$... The size (area) of the market is $\\pi \\cdot (\\frac{P-C-F}{f})^2$. The total market demand is $\\delta\\cdot \\pi \\cdot (\\frac{P-C-F}{f})^2 \\cdot D$\nClaude 3.5 Sonnet: Let's approach this problem ... Let $P$ be the revenue, $r$ is the radius of the circular market area, and the total cost = $C + F + fr$ . For the market boundary, revenue equals total cost implies $r = (P \u2013 C \u2013 F)/f$. Therefore, the market is a circular area with radius $r = (P \u2013 C \u2013 F)/f$, and the market demand is $\\pi \\cdot (\\frac{P-C-F}{f})^2 \\times \\delta  \\times D$ widgets per year.\nGemini 1.5 Pro: Here's how we can determine the shape, size, and total demand of the market under the given conditions: Since each person buys D widgets per year, the total demand is: Total Demand = $D * Population = D\\delta\\pi[(P \u2013 C \u2013 F)/f]^2$.\nFor illustrations, the solutions of GPT-4, Claude 3.5 Sonnet, and Gemini 1.5 Pro are provided for the above question. All three LLMs have clearly identified the \"uniformly distributed population\" setting"}, {"title": "Zero-Shot Setting (True or False Problem): Problem 5.1 from TransportBench", "content": "Input: In horizontal curve design, for a given design speed, the larger the road radius, the larger the rate of super-elevation. True or False?\nGPT-4: False. In horizontal curve design, the rate of super-elevation actually decreases as the radius of the curve increases for a given design speed. The rate of super-elevation is used to counteract the lateral acceleration experienced by a vehicle navigating a curve. A larger radius means the curve is less sharp, and therefore, the lateral forces are lower, requiring less super-elevation to maintain vehicle stability and comfort.\nClaude 3.5 Sonnet: False. In horizontal curve design, for a given design speed, the relationship between road radius and superelevation rate is actually inverse, not directly proportional. Here's a brief explanation: 1. As the radius of a horizontal curve increases, the centrifugal force acting on a vehicle decreases. This means less superelevation is needed to counteract the force. 2. Conversely, tighter curves (smaller radii) require more superelevation to help vehicles safely navigate the turn at the design speed. 3. For a given design speed, as you increase the radius of the curve, you can decrease the rate of superelevation while still maintaining safety and comfort for drivers. This relationship is fundamental to highway geometric design and is typically represented in design charts or tables that show the interplay between curve radius, design speed, and superelevation rate.\nGemini 1.5 Pro: False. In horizontal curve design, the relationship between road radius and superelevation rate is inverse. This means: Larger radius: Requires a smaller rate of superelevation. This is because the centrifugal force experienced by a vehicle traveling at a given speed is lower on a curve with a larger radius. Smaller radius: Requires a larger rate of superelevation to counteract the increased centrifugal force. The design goal is to provide a comfortable and safe driving experience by balancing the centrifugal force with the inward tilt of the road surface.\nIn the above example, all the LLMs have accurately identified the correct relationship between the road radius, super-elevation, and design speed, and come up the correct conclusion that the original statement is false. For concreteness, we listed some detailed reasoning provided by LLMs. We can see that the reasoning from LLMs for this specific question is quite plausible and supports the correct conclusion well.\nFollowing the above zero-shot setting, we present a comprehensive evaluation of GPT-4, GPT-40, Claude 3.5 Sonnet, Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1 on TransportBench. After receiving the LLM responses, we check the correctness of the LLM answers via human annotation. For all the problems, we also check the reasoning provided by LLMs. Our main evaluation metric is Accuracy (ACC), defined as the proportion of instances where the LLMs correctly solve the given problems. The ACC of GPT-4, GPT-40, Claude 3 Opus, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3 (70B), and Llama 3.1 (405B) on the TransportBench dataset is reported in Table 2. For simplicity, we only conduct our analysis on one trial per problem\u00b9, and hence there is some inherent randomness in the ACC obtained. Nevertheless, the results in Table 2 show that leading LLMs such as Claude 3.5 Sonnet,"}, {"title": "4. Evaluating Consistency of LLMs on True or False Problems", "content": "Although (zero-shot) accuracy provides a pivotal metric for initial assessments of LLM capabilities, it alone does not provide a true reflection of the intelligence level of LLMs. In this section, we will study another important aspect, namely the consistency of LLMs (Wang et al., 2022; Liang et al., 2024). Conceptually, consistency refers to uniform, reliable, and logically coherent responses that maintain the same principles and reasoning across different inquiries. Consistency can be measured in many different ways. In this section, we study the consistency of LLMs on the True or False problems in the following two settings.\n\u2022 Zero-shot consistency: Firstly, we independently test multiple trials of each problem in the zero-shot setting and examine whether LLMs will generate the same answer (either all true or all false). This setting is intuitive and can be illustrated by the following example where Claude 3.5 Sonnet generates inconsistent answers for different independent inquiries. The correct answer is false."}, {"title": "Inconsistency in the Zero-Shot Setting: Problem 10.11 from TransportBench", "content": "Input: Sufficiently large buses (infinite capacity) are used to provide shuttle service, and we always optimize dispatch frequency based on the demand. As the temporal demand distribution becomes more uneven (i.e., heterogeneous over time, but no change in total number of passengers), the total (agency + user) cost increases. True or False?\nClaude 3.5 Sonnet (Trial 1): To answer this question, let's think through it step by step... I believe the statement is False. While it's true that a more uneven demand distribution might lead to some inefficiencies, the ability to optimize dispatch frequency and the assumption of infinite capacity buses should allow for maintaining optimal or near-optimal total costs. The increased costs during peak times would likely be offset by decreased costs during off-peak times.\nClaude 3.5 Sonnet (Trial 2): To answer this question, let's think through it step by step: 1) First, let's consider what factors influence the total cost:- Agency costs: primarily related to the number of buses operated - User costs: primarily related to waiting time 2) In an optimized system, the dispatch frequency is adjusted based on demand. This means: During high demand periods, buses are dispatched more frequently - During low demand periods, buses are dispatched less frequently... 6) Overall effect: - Agency costs might increase slightly due to the need for a larger fleet- User costs are likely to increase due to longer average waiting times - The total cost, being the sum of agency and user costs, would therefore increase. Conclusion: True. As the temporal demand distribution becomes more uneven, the total (agency + user) cost is likely to increase, primarily due to increased user waiting times during off-peak periods and potentially higher agency costs for maintaining a larger fleet.\n\u2022 Consistency under self-checking prompts: Secondly, we examine whether LLMs will generate consistent answers and reasoning when they are prompted to double check their original answers."}, {"title": "Correction via Self-checking: Problem 10.12 from TransportBench", "content": "Input: The agency is trying to decide whether to design a hub-and-spoke network or a grid network to serve a city with uniformly distributed passenger O/D demand. As agency investment (total service route length per unit area) approaches infinity, these two types of networks eventually yield the same expected door-to-door passenger travel time. True or False?\nClaude 3.5 Sonnet: Let's think through this step-by-step: 1) First, let's consider what hub-and-spoke and grid networks look like: - Hub-and-spoke: Central hub with routes radiating outward like spokes - Grid: Parallel and perpendicular routes forming a grid pattern 2) As investment approaches infinity, we can assume: - The number of routes (spokes or grid lines) would approach infinity - The spacing between routes would approach zero 3) In a hub-and-spoke network with infinite investment: - Every point would essentially have a direct connection to the hub - From the hub, there would be a direct connection to every other point 4) In a grid network with infinite investment: - The grid would become infinitely fine - Any two points would be connected by an almost straight line path 5) Door-to-door travel time in both cases: As the network density approaches infinity, the path between any two points approaches a straight line - The travel time would approach the time it takes to travel in a straight line between origin and destination 6) Therefore, with infinite investment, both network types would provide essentially direct, straight-line paths between any two points, resulting in the same expected door-to-door travel time. Conclusion: True.\nInput: Carefully check your solutions.\nClaude 3.5 Sonnet: You're right to ask me to carefully check my solution. Let's review this problem more critically: 1) The key aspects to consider are: - Network structure (hub-and-spoke vs. grid) - Uniformly distributed passenger O/D (origin/destination) demand - Infinite investment (total service route length per unit area approaching infinity) - Expected door-to-door passenger travel time 2) Hub-and-spoke network with infinite investment: As investment approaches infinity, the number of spokes would approach infinity - However, all trips not beginning or ending at the hub still require a transfer at the hub - This transfer time doesn't disappear, even with infinite investment 3) Grid network with infinite investment: - As investment approaches infinity, the grid becomes infinitely fine - Any two points can be connected by an almost straight line path - No transfers are necessary 4) Door-to-door travel time comparison: - Grid network: Approaches direct, straight-line travel time - Hub-and-spoke network: Approaches straight-line travel time plus transfer time at the hub 5) Critical realization: - The transfer time at the hub in the hub-and-spoke network creates a persistent difference in expected door-to-door travel time compared to the grid network. Upon careful reconsideration, I realize my previous conclusion was incorrect. Revised conclusion: False. As agency investment approaches infinity, the hub-and-spoke network will still require transfers for many trips, resulting in longer expected door-to-door passenger travel times compared to the grid network.\nIn the above example, Claude 3.5 Sonnet is capable of correcting its original mistake and identifying that the key to this question is that the presence of a hub in hub-and-spoke networks imposes circuity that cannot be avoided even with an infinite route length i.e., the majority of passengers must make a transfer at the hub, which often implies detours. Even though it might be better to say \"no detours are necessary\" (instead of \u201cno transfers are necessary\") and avoid \"straight-line paths\" in the discussion of grid networks, this example demonstrates the potential benefits of using self-checking prompts.\nHowever, in the self-checking setting, LLMs may also misadjust their original correct answers and start to generate inconsistent true/false labels. This is illustrated by the following example."}, {"title": "Inconsistency in the Self-Checking Setting: Problem 6.3 from TransportBench", "content": "Input: In all stationary traffic, time-mean speed equals space-mean speed. True or False?\nClaude 3.5 Sonnet: False. In stationary traffic conditions, time-mean speed and space-mean speed are generally not equal. Here's a brief explanation: 1. Time-mean speed is the arithmetic average of speeds of vehicles passing a fixed point over a period of time. 2. Space-mean speed is the harmonic mean of speeds of vehicles over a given length of road at an instant in time. 3. In most cases, time-mean speed is higher than space-mean speed. 4. The difference between these two measures tends to increase with greater speed variability among vehicles. 5. Even in stationary traffic (where traffic conditions are stable over time), there can still be variations in individual vehicle speeds, leading to a difference between time-mean and space-mean speeds. The equality of time-mean and space-mean speeds occurs only in the special case where all vehicles are traveling at exactly the same speed, which is rarely the case in real traffic conditions, even when stationary.\nInput: Carefully check your solutions.\nClaude 3.5 Sonnet: Thank you for asking me to carefully check my solution. Upon review, I realize I need to correct my previous statement. You're right to question this, as my initial response was incorrect. Let me provide the correct answer: True. In stationary traffic, time-mean speed does equal space-mean speed. Here's the explanation: 1. Stationary traffic refers to a condition where the statistical properties of traffic flow do not change over time. 2. In such conditions, the distribution of speeds at a fixed point (used for time-mean speed) would be the same as the distribution of speeds over a section of road at an instant (used for space-mean speed). 3. When the traffic is stationary, the variability that usually causes the difference between time-mean and space-mean speeds is eliminated. 4. Therefore, in this specific case of stationary traffic, the two measures converge and become equal. I apologize for my initial error. This is an important concept in traffic flow theory, and I'm glad you prompted me to double-check. It's a good reminder of the specific conditions under which these two measures can be equal.\nIn the above example, Claude 3.5 Sonnet obtains the correct final answer initially in the zero-shot setting (despite the flawed statement in step 2; see a related error to Problem 6.13 in Section 5.3), and then the self-checking prompt makes it change the conclusion to a wrong one. Interestingly, Claude 3.5 Sonnet is zero-shot consistent for this problem, i.e. it generates correct final answers for the five independent trials in the zero-shot setting. However, the self-checking prompt becomes some disturbance that causes Claude 3.5 Sonnet to start giving inconsistent behaviors. Hence zero-shot consistency and the consistency in the self-checking setting are not equivalent. The interactions between LLMs and human users can lead to unexpected inconsistent behaviors that cannot be observed in a zero-shot setting.\nIn light of the above discussion, we next provide a complementary perspective on consistency of LLMs using two metrics. The first metric is self-checking accuracy (denoted as ACC-5), which quantifies the instances in which LLMs give correct answers after the self-checking process. Notice that ACC-5 does not have to be higher than ACC. For an LLM which responds very inconsistently to the self-checking prompts, ACC-5 can actually be lower than the original ACC in the zero-shot setting due to flipping the initial correct answers. The second metric is the number of the True or False problems in which the LLMs flip the original correct answers to wrong ones. The number of incorrect flips can give a more direct illustration on the extent of the inconsistency in the self-checking setting. For a consistent LLM, we ideally want ACC-5 to be higher than ACC and the number of incorrect flips to be low. Now we present both metrics for GPT-4, GPT-40, Claude 3 Opus, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3, and Llama 3.1 in Table 5. We make the following observations.\n\u2022 GPT-40 and GPT-4 are the only two models whose accuracy is benefited from the self-checking prompts. For all other models including Claude 3.5 Sonnet, the number of incorrect flips is larger than the number of correct flips. The number of incorrect flips for GPT-4 and GPT-40 is very low. Therefore, in the self-checking setting, GPT-4 and GPT-40 are the most consistent.\n\u2022 Given self-checking prompts, Claude 3.5 Sonnet is still more consistent than Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1, but less consistent than GPT-4 and GPT-40. Therefore, for transportation engineering tasks involving human interactions, it is unclear whether one should still view Claude 3.5 Sonnet as the state-of-the-art LLM.\n\u2022 Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1 all make many incorrect flips. It seems natural for us to question whether these models really master the concepts involving in our True or False problems.\nOverall, we can see that evaluating the consistency of LLMs is actually quite subtle. In the zero-shot setting, Claude 3.5 Sonnet is the most consistent model. However, in the self-checking setting, GPT-4 and GPT-40 are both more consistent than Claude 3.5 Sonnet. There are many other settings where the consistency of LLMs. can be tested. For instance, one can rephrase each problem in various tricky ways and then test whether LLMs will be able to answer all the variants correctly. Our analysis is just a starting point, and future efforts are needed to address the consistency of LLMs in a comprehensive manner."}, {"title": "5. Reasoning Behaviors of LLMs on TransportBench", "content": "One impressive observation from our study is that LLMs have started to show promise in reasoning for transportation engineering problems, e.g., sometimes they can provide seemingly correct reasons for their True/False labels or solutions to general Q&A questions. This observation aligns well with the large body of literature discussing the promise of LLM reasoning across various domains (Wei et al., 2022b; Huang and Chang, 2022; Zhou et al., 2022; Sun et al., 2023; Havrilla et al., 2024). However, alongside the promise of LLM reasoning, there are potential drawbacks and unresolved issues. For instance, recent work has identified potential breakdowns of LLM reasoning on very simple common-sense problems (Nezhurina et al., 2024). In this section, we perform a case study of LLM reasoning based on examining LLM responses on TransportBench more carefully. We will discuss various interesting observations on the reasoning behaviors of LLMs in answering transportation engineering problems. Importantly, despite the promise, LLMs can make various subtle reasoning errors."}, {"title": "5.1. Claude 3.5 Sonnet vs. Claude 3 Opus: Reasoning before conclusion matters", "content": "As seen previously, Claude 3.5 Sonnet has improved the accuracy of Claude 3 Opus on Transport-Bench. In this section, we will examine the role of reasoning in this improvement for the True or False problems. We will start from the following intriguing example."}, {"title": "Claude 3.5 Sonnet vs. Claude 3 Opus: Problem 6.5 from TransportBench", "content": "Input: In traffic, density = 1 / headway. True or False?\nClaude 3.5 Sonnet: To answer this question accurately, let's break down the concepts and their relationship: 1. Traffic density: This is typically defined as the number of vehicles per unit length of road. 2. Headway: In traffic engineering, headway usually refers to the time interval between vehicles passing a point on the road. Given these definitions, the statement \"density = 1 / headway\" is not precisely correct. Here's why: 1. Units mismatch: Density is typically measured in vehicles per unit length (e.g., vehicles/km), while headway is measured in time (e.g., seconds). The reciprocal of time wouldn't directly give us vehicles per unit length. 2. Relationship: While there is a relationship between density and headway, it's not as simple as a direct reciprocal. The correct relationship involves speed as well. The more accurate relationship is: Density = Flow / Speed Where: - Flow is measured in vehicles per unit time (e.g., vehicles/hour) - Speed is measured in distance per unit time (e.g., km/hour) - Resulting in Density as vehicles per unit distance (e.g., vehicles/km). Headway is related to flow: Flow = 1 / Headway. Therefore, the statement \"In traffic, density = 1 / headway\" is False.\nClaude 3 Opus: True. In traffic flow theory, density is defined as the number of vehicles per unit length of the roadway. Headway, on the other hand, is the time or distance between successive vehicles. Mathematically, density (k) is the inverse of headway (h), expressed as: $k = 1/h$. This relationship assumes a uniform headway between vehicles. In reality, headways can vary, and the density is often calculated as an average over a roadway segment.\nInput (Modified): In traffic, density = 1 / time headway. True or False?\nClaude 3 Opus: True. In traffic engineering, density is defined as the inverse of the average time headway between vehicles. Time headway is the time elapsed between the front of a leading vehicle passing a point on the roadway and the front of the following vehicle passing the same point. It's usually measured in seconds. So the formula is: Density = 1 / Average Time Headway, where density is measured in vehicles per unit time (often vehicles per hour) and average time headway is measured in units of time per vehicle (often seconds per vehicle). This relationship allows traffic engineers to estimate traffic density by measuring the time gaps between vehicles at a specific point on the road."}, {"title": "Reasoning Matters: Adding Prompts to Problem 6.5 from TransportBench", "content": "Input (Modification 1): In traffic", "Opus": "To determine if the statement \"In traffic", "relationship": "Traffic Density: Traffic density is the number of vehicles occupying a given length of a highway or road. It is usually expressed as vehicles per kilometer or vehicles per mile. Headway: Headway is the time gap between the front of a leading vehicle and the front of the following vehicle", "is": "density = flow / speed where: density is the traffic density (vehicles/km or vehicles/mile) - flow is the traffic flow rate (vehicles/hour) - speed is the average speed of the vehicles (km/hour or miles/hour). Assuming a constant flow rate"}, {"is": "headway = 1 / flow. Substituting this into the density equation", "get": "density = flow / speed = (1 / headway) / speed. Therefore", "density = 1 / headway\" is false. The correct relationship is": "density = (1 / headway) / speed. In other words", "2)": "In traffic", "Sonnet": true, "correct": 1.0, "terms": "Density: The number of vehicles per unit length of road (usually vehicles per kilometer or mile) - Headway: The time or distance between two consecutive vehicles in a traffic stream. 2. Relationship: - Headway is typically measured in time (seconds) or distance (meters or feet) - Density is the inverse of the average space headway. 3. Explanation: - If we consider a uniform traffic flow where all vehicles are evenly spaced: - A longer headway means fewer vehicles in a given length of road (lower density) - A shorter headway means more vehicles in a given length of road (higher density) - Mathematically", "as": "Density = 1 / (Average space headway) - Note: When using time headway", "headway": ""}]}