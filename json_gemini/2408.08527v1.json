{"title": "Focus on Focus: Focus-oriented Representation Learning and Multi-view Cross-modal Alignment for Glioma Grading", "authors": ["Li Pan", "Yupei Zhang", "Qiushi Yang", "Tan Li", "Xiaohan Xing", "Maximus C. F. Yeung", "Zhen Chen"], "abstract": "Recently, multimodal deep learning, which integrates histopathology slides and molecular biomarkers, has achieved a promising performance in glioma grading. Despite great progress, due to the intra-modality complexity and inter-modality heterogeneity, existing studies suffer from inadequate histopathology representation learning and inefficient molecular-pathology knowledge alignment. These two issues hinder existing methods to precisely interpret diagnostic molecular-pathology features, thereby limiting their grading performance. Moreover, the real-world applicability of existing multimodal approaches is significantly restricted as molecular biomarkers are not always available during clinical deployment. To address these problems, we introduce a novel Focus on Focus (FoF) framework with paired pathology-genomic training and applicable pathology-only inference, enhancing molecular-pathology representation effectively. Specifically, we propose a Focus-oriented Representation Learning (FRL) module to encourage the model to identify regions positively or negatively related to glioma grading and guide it to focus on the diagnostic areas with a consistency constraint. To effectively link the molecular biomarkers to morphological features, we propose a Multi-view Cross-modal Alignment (MCA) module that projects histopathology representations into molecular subspaces, aligning morphological features with corresponding molecular biomarker status by supervised contrastive learning. Experiments on the TCGA GBM-LGG dataset demonstrate that our FoF framework significantly improves the glioma grading. Remarkably, our FoF achieves superior performance using only histopathology slides compared to existing multimodal methods.", "sections": [{"title": "I. INTRODUCTION", "content": "As the most common type of brain tumors, gliomas are classified into Grade II to IV by the World Health Organization, correlating with varied prognoses and intervention approaches [1]. The gold standard for grading gliomas is the observation of representative histopathology features in biopsies [2]. However, histopathology slides present a complex milieu of cells, necrosis, and microenvironments, which complicates the localization of tumor foci, necessitating the expertise of senior pathologists [3]. The recent advances in computer-assisted cancer grading reveal promising performance in identifying glioma grades from histopathology slides [4], [5].\nRecent studies [6], [7] in cancer grade classification benefit from multimodal approaches that combine histopathology features with molecular biomarkers from tissue biopsies, offering a comprehensive and accurate tumor analysis. Existing multimodal methods [6], [8] heavily rely on paired pathology-genomic data for inference when deployed. However, obtaining molecular biomarkers requires staining and/or sequencing, which is not routinely available in clinical practice due to high costs and technical challenges, thereby limiting their practical applications [9]. To address this limitation, cutting-edge multimodal techniques [10], [11] propose achieving uni-modal inference by distilling knowledge from a pathology-genomic teacher, expanding the applicability of multimodal grading in clinical settings. Nevertheless, these methods are inherently constrained by the performance of multimodal teachers, highlighting an emergent need for a novel approach that can effectively learn from multimodal data while enabling unimodal inference.\nThe effectiveness of existing multimodal methods is limited by the difficulties in accurately identifying diagnostic molecular-pathology features, which can be attributed to two major issues. The first issue is the insufficient histopathology representation learning, attributed to a lack of focus on the most representative regions associated with gliomas. Existing methods [4] attempt to correlate the complex images with diagnostic grades by uniformly processing the whole histopathology slides. Nonetheless, without an explicit regularization, these approaches [5], [12] are prone to overfitting the minor textual details rather than high-level diagnostic patterns. Existing studies [6], [13] attempt to tackle this issue by augmenting the histopathology inputs with handcrafted morphological features but lack the generalization ability. To this end, there is an urgent need for a novel method to boost histopathology representation learning by directing the model focus toward areas most relevant to glioma grading.\nAnother challenge lies in the inefficient molecular-pathology knowledge alignment. Contemporary multimodal methods tend to fuse the pathology-genomic information in the feature space through simple combinations. However, due to the notable heterogeneity between the two modalities, these methods struggle to align the morphological features of tumor niches with molecular biomarkers, such as Intradialytic hypotension"}, {"title": "(IDH) mutation status and 1p/19q codeletion presence, which are crucial for precise glioma grading [1], [14]. Thus, there is a high demand for novel strategies that can effectively correlate genomic biomarkers with histopathology abnormalities to jointly identify the molecular-pathology features of gliomas toward precision grading.", "content": "To tackle these challenges, we propose the Focus on Focus (FoF) framework that enhances the identification of diagnostic molecular-pathology features by boosting the histopathology representations with Focus-oriented Representation Learning (FRL), and effectively integrating the molecular biomarkers with Multi-view Cross-modal Alignment (MCA). Specifically, to improve the representations of histopathology slides, we propose FRL to identify the regions positively and negatively correlated to cancer grading and encourage the model to focus on diagnostic regions with a consistency constraint. To correlate the genomic biomarkers with histopathology properties, we propose MCA to cluster the multi-view visual representations that share compatible molecular contexts while distancing those in discrepancies through supervised contrastive learning. By precisely locating the tumor niches and linking them with molecular biomarkers, FoF enriches the visual representations of histopathology slides and facilitates accurate glioma grading only using images. Experimental results prove that our FoF framework outperforms state-of-the-art histopathology and multimodal methods on the TCGA GBM-LGG dataset.\nThe contributions of this work are summarized as follows:\n\u2022 To achieve accurate grading of gliomas, we propose a novel FoF framework that directs the focus of models to diagnostic regions. To the best of our knowledge, this is the first work to adjust the model focus on areas of both histopathology and molecular-pathology significance.\n\u2022 We devise the FRL module to identify regions that positively or negatively contribute to grading, encouraging the model to focus on important diagnostic niches through a consistency constraint on histopathology features.\n\u2022 In response to the latest WHO classification of gliomas, we propose the MCA module to align the histopathology features directly with molecular biomarkers and balance the impact of each biomarker through a novel multi-view contrastive learning.\n\u2022 Extensive experiments on the TCGA GBM-LGG dataset prove the effectiveness, and our FoF outperforms multi-modal grading state-of-the-arts using only histopathology slides, demonstrating great clinical significance."}, {"title": "II. RELATED WORK", "content": "Histopathology grading Glioma is a significant type of malignant tumor that occurs in the glial cells of the brain or spinal cord and can be classified into Grades II to IV, each correlating with different prognoses [2]. Histologic properties observed under a microscope from biopsy samples are the gold standard for tumor assessments in clinical practice, e.g., the presence of necrosis and/or microvascular proliferation leads to the diagnosis of high-grade glioma (HGG) [15]. To reduce the workload of pathologists and promote consistent diagnosis, researchers have utilized traditional machine learning and deep learning models to classify morphological features [10]. For example, Ker et al. employed a pre-trained convolutional neural network to classify histopathology slides into normal, low-grade glioma (LGG), or HGG categories [16]. Rathore et al. extracted conventional features (e.g., intensity) and textural features (e.g., gray-level co-occurrence matrix) from specimens, and used a support vector machine for classification [17]. However, handcrafted features only capture detailed textural information, and deep learning models are prone to overfitting it due to the high complexity of histopathology slides. As a result, these approaches are inefficient at capturing the representative patterns of gliomas, lacking both generalization ability and interpretability.\nMultimodal grading According to the latest WHO classification of tumors of the central nerve system [1], integrating molecular biomarkers with histopathology slides provides a more comprehensive and precise analysis of gliomas. Inspired by this medical insight, researchers attempt to project the histopathology and molecular data into a uniform latent space, fusing the features of the two modalities through various combinations, such as concatenation [7], [18], Kronecker Product [6], [19], and cross attention [8]. Yet, molecular biomarkers, such as the status of IDH mutation and 1p/19q codeletion, contain precise information that directly correlates with the grading of gliomas [14]. As a result of this heterogeneity between the two modalities, existing methods that rely on uniform projection and late fusion are insufficient at aligning cross-modal information through simple combinations and overlook the correlations among different molecular biomarkers. In contrast, our FoF framework encourages the model to adaptively focus on representative regions and directly align these regions with biomarkers, resulting in more robust representation learning and improved interpretability.\nB. Multimodal Glioma Grading with Missing Modality\nAlthough molecular biomarkers are essential for the clinical assessment of cancers, their acquisition necessitates immunohistochemistry (IHC) staining and DNA/RNA sequencing. These processes are time-consuming and costly, thus resulting in limited accessibility, particularly in underrepresented areas [20]. Fusion-based multimodal methods [6] necessitate the presence of paired histopathology slides and molecular biomarkers, further restricting their practical application in real-world clinical settings. To alleviate this challenge, DDM-net [21] proposed to reconstruct the features of unavailable modality from the available one with the transformation function learned from paired data. Most recent studies have implemented distillation-based methods to enhance the image-based model by distilling knowledge from a pathology-genomic teacher [10]. For instance, Xing et al. [19] devised a novel distillation framework that effectively transfers knowledge from a multimodal teacher to a uni-modal student, achieving"}, {"title": "III. METHODOLOGY", "content": "As illustrated in Fig. 1, our FoF framework improves the glioma grading by highlighting the diagnostic molecular-pathology features. To enhance the representation learning on histopathology slides, we introduce FRL to identify the positive $x_{pos}$ and negative regions $x_{neg}$ from the input images $x_{glb}$ with the pixel-wise contribution score $A \u2208 R^{H\u00d7W}$, encouraging the model fg to focus on the most important areas. In MCA, we project the multi-view features {$v_{glb}$, $v_{pos}$, $v_{neg}$} into individual molecular subspaces with distinct projectors $h^{n}(\u00b7)$ and employ biomarkers as labels. During inference, the model predicts the glioma grades $f. g(x_{glb})$ with only histopathology slides.\nB. Focus-oriented Representation Learning\nExisting representation learning on histopathology slides is inadequate, which can be attributed to the lack of focus on the diagnostic morphological patterns [13]. To boost histopathology representation learning, we propose the Focus-oriented Representation Learning module to encourage the focus of the model on areas most relevant to gliomas and enhance these representations with a consistency constraint. Specifically, FRL quantifies the contribution score of each pixel towards accurate classification $A \u2208 R^{H\u00d7W}$ and identifies the areas that are positively and negatively related to grading using a threshold. This module separately feeds the positive $x_{pos}$ and negative $x_{neg}$ regions into the ViT encoder g and enhances the visual representations with a consistency constraint on the positive $v_{pos}$ and global features $v_{glb}$.\nTechnically, locating the focus of models has been formulated as identifying the input pixels that contribute most significantly to the output [22]. To identify the diagnostic regions within a specific slide $x$, FRL initially processes the whole image through the model to obtain the predictions $f.g(x)$. It then aggregates the gradient of the prediction for the ground-truth class s across each feature map layer $v_{k}$, thereby estimating the contribution score of each pixel towards accurate grading as follows:\n$A = Y(ReLU(\\sum_{k}{\\alpha_{k}v_{k}}), [H, W])$ (1)\nwhere i and j represent the location indices within the feature map $v_{k}$, $\u03b1_{k}$ is the weight associated with the k-th feature map $v_{k}$, and $Y(, [H, W])$ refers to the reshape and resample function that upscales the feature map to match the input image size. Consequently, the matrix A indicates the contribution of each pixel toward accurately classifying the input image to the target class. Following this step, we divide the pixel-wise contribution score into $P = \\frac{H\u00d7W}{p}$, patches, where p is the patch size. The FRL calculates the average patch-wise contribution score, filtering it by a threshold to generate the mask of patches $M\u2208 R^{P}$. We apply the patch-wise mask on the patchified image to select only the positive and negative"}, {"title": "patches as follows:", "content": "$M_{i,j} = \\frac{1}{p^{2}}\\sum_{m=0}^{p-1}\\sum_{n=0}^{p-1} A_{pi+m, pj+n} > \\theta$,\n$x_{pos} = x_{glb} \u2299 M$, $x_{neg} = x_{glb} \u2299 (1 - M)$,\nwhere @ is a pre-defined threshold for contribution scores set at 0.5 in this study, \u2299 denotes the element-wise multiplication operator and $x_{glb} \u2208 R^{P\u00d7C}$ corresponds to the patches of the input image. Consequently, $x_{pos}$ and $x_{neg}$ denote the positive and negative patches, respectively. To promote a consistent grading on global and positive regions as well as distinguish the negative ones, FRL applies the Cross-Entropy loss on all the regions {$x_{glb}, x_{pos}, x_{neg}$} as follows:\n$L_{CLS} = \\frac{1}{B}\\sum_{i=1}^{B}{\\sigma(x,y)}$ (3)\n$\\sigma(x,y) = L_{CE}(f. g(x), y))$,\nwhere B indicates the number of samples in a mini-batch, $L_{CE}$ denotes the Cross-Entropy loss, $y^{i}$ is the label of the i-th sample, and $e$ is a constant label for negative areas indicating background. To further boost the representations of histopathology slides, especially for the positive regions, we propose a consistency constraint that promotes a consistent mapping of positive and overall regions as well as a distinguishable mapping of negative regions. This approach pulls the positive and global features closer together as well as pushing the negative features far apart by the InfoNCE loss [23] defined on the features $v = g(x)$ as follows:\n$\\varphi(v) = \\frac{v}{||v||}, \\varphi(v_{i},v_{j}) = \\frac{cos(v_{i},v_{j})}{\u03c4},$\n$\\psi(v) = \\frac{\u03c6(v_{glb}, v_{pos})}{\u03c6(v_{glb}, v_{pos}) + \u03c6(v_{glb}, v_{neg}) + \u03c6(v_{pos}, v_{neg})}$, (4)\n$L_{FRL} = -\\frac{1}{B}\\sum_{i=1}^{B}{log(\\psi(v))}$,\nwhere $v_{glb}, v_{pos}, v_{neg}$ denote the features extracted from global, positive and negative regions, respectively. The cos(.,.) represents the cosine similarity function and $\u03c4\u2208 R+$ is a scalar temperature parameter. By locating the areas that contributed the most significantly to accurate grading and regularizing the representations of different regions with the consistency constraint, FRL encourages the model to focus on diagnostic areas, promoting representation learning on the histopathology slides, thus improving the performance of glioma grading.\nC. Multi-view Cross-modal Alignment\nCurrent multimodal glioma grading methods encode and fuse the histopathology slides with molecular biomarkers [6]. Notably, unlike histopathology representations, molecular biomarkers usually with integer values, e.g., IDH mutation status, provide direct insights related to glioma grading without necessitating neural network processing [1]. This heterogeneity between two modalities presents a challenge for existing fusion-based methods, which struggle to align molecular indicators with histologic features in the high-dimensional feature space [14]. To tackle this issue, we propose a Multi-view Cross-modal Alignment module that employs genomic biomarkers as unique labels and aligns the histological feature representations within each molecular subspace by supervised contrastive learning.\nSpecifically, MCA leverages the biomarkers with discrete values, including IDH mutation status, 1p/19q codeletion presence, and the Copy Number Variation (CNV), as labels. To accommodate the co-occurrence of biomarkers, this module projects multi-view histopathology representations $v\u2208 {v_{glb}, v_{pos}, v_{neg}}$ into individual molecular subspaces, employing distinct projection heads $h^{n}(\u00b7)$ for each. Within these subspaces, it aims to bring features that share the same molecular biomarker values closer together while distancing those that differ, thereby enhancing the concordance of histopathology features regarding each biomarker. The loss of Multi-view Cross-modal Alignment is formulated as follows:\n$L_{MCA} = \\sum_{n=1}^{N} L_{MCA}^{n}$ (5)\n$L_{MCA}^{n} = \\frac{1}{B}\\sum_{i=1}^{B}\\sum_{j=1}^{B}{l_{i\u2260j}^{n}1_{y=y} \u2022 log(\\omega(h^{n}(v), i, j))}$,\n$\u03c9(v,i,j) = \\frac{e^{\\frac{\u03c6(v_{i},v_{j})}{\u03c4}}}{ \\sum_{k=1}^{B}{l_{i\u2260k}^{n} \u2022 \u03c6(v_{i},v_{k})}}}$,\nwhere N denotes the number of gene biomarkers, n indicates the index of the biomarker, 1 is an indicator function that returns 1 if the condition is satisfied and 0 otherwise, and $y^{n}$ represents the status of the n-th biomarker. We set the gene labels of positive regions to the same as global regions and set the negative gene labels to the normal status (i.e., wildtype for IDH and 1p/19q, CNV equals 0 for other biomarkers). Following recent medical studies [1], [24], we include the IDH mutation status, 1p/19q codeletion presence, and CNV of PTEN, EGFR, CARD11, and FGFR2 as molecular biomarkers in this study. By enhancing the histological feature representations with FRL and aligning molecular biomarkers to them, FoF promotes a reliable and accurate grading of gliomas, reaching even better performance with sole images than existing multimodal counterparts.\nD. Training and Inference\nThe overall optimization objective of our FoF framework is summarized as follows:\n$\\mathcal{L}$ = $L_{CLS}$ + $\u03bb_{1}L_{FRL}$ + $\u03bb_{2}L_{MCA}$, (6)\nwhere $\u03bb_{1}$ and $\u03bb_{2}$ indicate the coefficients to control the trade-off of FRL and MCA, respectively. During training, FoF estimates the contribution score $A \u2208 R^{H\u00d7W}$ in the first back-propagation and calculates the losses of FRL and MCA modules in the second back-propagation. At the inference phase, the model fg directly outputs the predictions of the input images with no additional computational cost."}, {"title": "V. CONCLUSION", "content": "In this work, we propose the FoF framework that utilizes pathology-genomic knowledge toward accurate glioma grading with histopathology slides. To enhance the representation learning on histopathology slides, we propose the FRL module that encourages the model to focus on diagnostic regions and the MCA scheme which efficiently aligns the molecular biomarkers with visual representations. Experimental results indicate that FoF improves the glioma grading significantly. Particularly, with the sole histopathology slides, FoF achieves superior performance with existing multimodal approaches, which is of great clinical significance."}]}