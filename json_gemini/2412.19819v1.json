{"title": "ChipAlign: Instruction Alignment in Large Language Models\nfor Chip Design via Geodesic Interpolation", "authors": ["Chenhui Deng", "Yunsheng Bai", "Haoxing Ren"], "abstract": "Recent advancements in large language models (LLMs)\nhave expanded their application across various domains, including chip\ndesign, where domain-adapted chip models like ChipNeMo have emerged.\nHowever, these models often struggle with instruction alignment, a crucial\ncapability for LLMs that involves following explicit human directives.\nThis limitation impedes the practical application of chip LLMs, including\nserving as assistant chatbots for hardware design engineers. In this work,\nwe introduce ChipAlign, a novel approach that utilizes a training-free\nmodel merging strategy, combining the strengths of a general instruction-\naligned LLM with a chip-specific LLM. By considering the underlying\nmanifold in the weight space, ChipAlign employs geodesic interpolation\nto effectively fuse the weights of input LLMs, producing a merged\nmodel that inherits strong instruction alignment and chip expertise\nfrom the respective instruction and chip LLMs. Our results demonstrate\nthat ChipAlign significantly enhances instruction-following capabilities of\nexisting chip LLMs, achieving up to a 26.6% improvement on the IFEval\nbenchmark, while maintaining comparable expertise in the chip domain.\nThis improvement in instruction alignment also translates to notable gains\nin instruction-involved QA tasks, delivering performance enhancements of\n3.9% on the OpenROAD QA benchmark and 8.25% on production-level\nchip QA benchmarks, surpassing state-of-the-art baselines.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent years have seen remarkable breakthroughs in large language\nmodels (LLMs) across a wide range of applications, including text\nsummarization, machine translation, and conversational AI [30].\nModels like GPT [1], Gemini [19], Claude [4], and LLaMA [8]\nseries have transformed numerous industries by automating complex\ntasks, enhancing decision-making processes, and enabling creative\nproblem-solving that traditionally required human expertise. Alongside\nthis success, there is a growing trend of adapting LLMs to specific\ndomains to meet specialized needs. Domain-adapted LLMs have been\ndeveloped for fields such as healthcare [22], finance [24], law [5], and\nclimate [20], where nuanced understanding and specialized knowledge\nare essential for enhancing model performance within these domains.\nIn the realm of chip design, ChipNeMo stands out as a prominent\nexample of domain-adapted LLMs [14]. Built on the LLaMA2-70B\nfoundation model, ChipNeMo leverages domain-adaptive pretraining\n(DAPT) and finetuning (DAFT) to imbue the model with specialized\nknowledge in circuits, bugs, and electronic design automation (EDA)\nscripts. Following ChipNeMo, several customized LLMs have recently\nbeen developed for EDA tasks. He et al. introduced AutoMage, an\nLLM finetuned on LLaMA2 to specialize in EDA tool utilization [23].\nSubsequently, Sharma et al. [17] and Pu et al [16]. developed LLMs\ntailored for QA and script generation tasks from OpenROAD.\nHowever, these tailored LLMs typically exhibit diminished instruc-\ntion alignment, a fundamental capability of general-purpose chat\nLLMs to follow human instructions, as demonstrated in Figure 2.\nThis decline in instruction alignment limits the practical usability\nof chip LLMs, as they may struggle to respond effectively to user-\ndirected commands, making them less versatile and reliable in real-\nworld applications. For instance, when serving as single or multi-turn\nchatbots for hardware design engineers, it is critical that the chip"}, {"title": "II. BACKGROUND", "content": "In chip design, the need for domain-adapted LLMs has driven the\ndevelopment of several models tailored to hardware-related tasks. Liu\net al. developed ChipNeMo starting with DAPT on 24 billion tokens\ndrawn from chip design documents and code, using the LLaMA2-\n70B foundation model as a base. This pretraining phase employs\nthe standard autoregressive language modeling objective to tailor the\nmodel to domain-specific data. Subsequently, the model underwent\nDAFT on approximately 57,000 samples, incorporating both domain-\nspecific instructional data and open-source chat data from OASST [11].\nThrough DAPT and DAFT, ChipNeMo acquired specialized knowledge\nin the chip domain, leading to promising outcomes in various hardware\ndesign applications [14]. Later, He et al. developed AutoMage, an\nLLM finetuned on LLaMA2 for EDA tool usage [23], which led to\nthe creation of ChatEDA, an autonomous agent customized for EDA\ndesign flow. More recently, Sharma et al. [17] and Pu et al. [16]\nhave tailored LLMs for OpenROAD script generation and QA tasks,\ncovering a broad spectrum of queries related to command usage, VLSI\nflow, installation guides, and GUI usage.\nDAPT and DAFT often drastically change the weights of LLMs to\nemphasize domain knowledge, resulting in a loss of the instruction-\nfollowing capabilities originally present in general-purpose LLMs [9].\nHowever, instruction alignment is crucial for real-world applications,\nsuch as a chatbot assistant for chip designers. In such settings,\ndesigners may seek guidance on design methodologies, troubleshooting\nsteps, or explanations of specific design concepts, often phrased as\ndirect instructions. Additionally, they may instruct the chatbot to\nrespond solely based on a given context, which ensures the answer\nis grounded in relevant and context-specific information, as shown\nin Figures 5 and 6. Hence, the ability to understand and respond\nappropriately to these instructions is vital for the practical usability\nof a chip LLM, making instruction alignment an essential feature.\nA straightforward approach to enhance the instruction alignment of\nchip LLMs involves multi-task learning, which simultaneously trains\na model on chip domain-specific data and instruction-following data\nto effectively integrate both sets of capabilities. However, access to\nhigh-quality instruction data is limited, as datasets used by advanced\nmodels like GPT-4 and the LLaMA series remain proprietary. While\nopen-source instruction datasets are valuable [11], they often lack the\nscale and diversity needed to train models effectively for complex\ninstruction-following tasks. Besides, even when data is available, the\ncosts associated with finetuning on large-scale instruction datasets are\nprohibitively high, particularly for models with billions of parameters.\nIn contrast to multi-task learning, model merging is a training-\nfree technique that directly fuses the weights of specialized LLMs\nto incorporate multiple capabilities without requiring access to the\noriginal training data [27]. Recent work has demonstrated that with a\nproperly designed weight fusion scheme, model merging can achieve\nperformance comparable to multi-task learning, making it an efficient\nmethod to equip LLMs with multiple capabilities [28].\nIn literature, Model Soup represents a pioneering method in\nthis direction, averaging the weights of different LLMs to create\na single model that generalizes well across tasks [21]. Following\nthis idea, Ilharco et al. proposed task arithmetic that averages the\nweight differences (i.e., task vectors) between input LLMs and their\ncommon base model; the resulting average is then added back to\nthe base model to produce the merged model [10]. Building on task\narithmetic, TIES [26] enhances the approach by sparsifying the task\nvectors and incorporating a sign consensus algorithm prior to weight\nfusion. DELLA [6] further advances TIES via adaptively pruning less\nimportant weights with specific hyperparameters. However, all of these\nmethods neglect the underlying geometric properties of LLM weights,\nwhich can lead to merged models with suboptimal performance. In\ncontrast, ChipAlign aims to merge a chip LLM with a well-instructed\ngeneral LLM through geodesic interpolation. This geometric-aware\ntechnique allows us to smoothly blend the weights of the original\nLLMs along the shortest path on a Riemannian manifold. As a result,\nChipAlign produces a merged model that effectively combines chip\ndomain knowledge with instruction alignment, outperforming previous\nmodel merging techniques as detailed in Table 1. Notably, while\nChipAlign has potential applications in other domains, this work\nprimarily focuses on hardware-related QA tasks."}, {"title": "III. THE PROPOSED APPROACH", "content": "Problem formulation \u2013 Let $M_{chip}$ denote a chip LLM and $M_{instruct}$\ndenote a general-purpose instruction LLM. Let $\\{W^{(l)}|l = 1, ..., L\\}$\ndenote the complete set of weights for an L-layer LLM, encompassing\nweights from the embedding layer, normalization layers, self-attention\nlayers, and feed-forward layers. For each layer $l$,\nlet $W^{(l)}_{chip} \\in \\mathbb{R}^{p \\times q}$ and\n$W^{(l)}_{instruct} \\in \\mathbb{R}^{p \\times q}$ represent the weight matrices of $M_{chip}$ and $M_{instruct}$,\nrespectively. Our goal is to develop a merging function $f$ such that:\n$W^{(l)}_{merge} = f(W^{(l)}_{chip}, W^{(l)}_{instruct})$\nThe resulting $W^{(l)}_{merge} \\in \\mathbb{R}^{p \\times q}$ serves as the weights for the $l$-th layer\nin the merged model $M_{merge}$, which aims to combine the strengths\nof both $M_{chip}$ and $M_{instruct}$. For brevity, we omit the layer index $l\n$in the following sections unless explicitly mentioned. Notably, our\nproblem formulation implicitly assumes that the input models share the\nsame architecture, meaning their respective weight matrices $W_{chip}$ and\n$W_{instruct}$ are conformable for merging. This assumption generally holds\nin practice; for example, ChipNeMo is trained based on LLaMA2-\n70B-Base, which has the same architecture as the instruction model\nLLaMA2-70B-Chat that is publicly available.\nFigure 3 provides an overview of our proposed approach, ChipAlign.\nNext, we are going to first present the motivation for using geodesic\ninterpolation in our merging method in Section III-A. Then, Section\nIII-B introduces ChipAlign that computes geodesic interpolation along\na unit n-sphere. Finally, we analyze the complexity of ChipAlign in\nSection III-C. It is worth noting that ChipAlign operates under the\nassumption that both chip and instruction LLMs are already available.\nDetails on how to obtain these LLMs are provided in Section IV-A.\nNeural network weights can be viewed as points on a high-\ndimensional Riemannian manifold [2], [3]. This perspective opens\nthe door for leveraging powerful geometric tools, such as geodesic\ninterpolation, to transition smoothly between two sets of model\nweights. Geodesic interpolation follows the shortest path on the\nmanifold between two points, providing a structured way to transition\nthrough the weight space without compromising on important model\nproperties. Such interpolation techniques can be particularly useful\nfor merging LLMs that specialize in different tasks. Given two points\non the manifold corresponding to LLM weights optimized for distinct\nobjectives, geodesic interpolation enables us to find a new point on\nthe manifold that lies near both models, thereby inheriting strengths\nfrom each. This approach allows us to combine properties such as\nchip domain knowledge and instruction alignment into a single LLM.\nTo efficiently perform geodesic interpolation between the weights\nof these models, ChipAlign first projects the weight matrices $W_{chip}$\nand $W_{instruct}$ onto a unit n-sphere as follows:\n$Norm_{chip} = ||W_{chip} ||_F, Norm_{instruct} = || W_{instruct} ||_F$\n$W_{chip} = \\frac{W_{chip}}{Norm_{chip}}, W_{instruct} = \\frac{W_{instruct}}{Norm_{instruct}}$\nwhere $|| \\cdot ||_F$ denotes the Frobenius norm. According to Definition\nIII.1, $W_{chip} \\in \\mathbb{R}^{p \\times q}$ and $W_{instruct} \\in \\mathbb{R}^{p \\times q}$ now reside on a unit n-\nsphere (n = p x q - 1), the geodesic between them is represented by\nthe arc connecting the two points on the sphere. This allows us to\nperform geodesic interpolation by interpolating along this arc, which\ncan be efficiently achieved using the following lemma:\nLemma III.2. Given $W_{chip}$ and $W_{instruct}$ lie on a unit n-sphere, the\ngeodesic interpolation between them can be expressed as:\n$W_{merge} = \\frac{sin((1 - \\lambda)\\Theta)}{sin(\\Theta)}W_{chip} + \\frac{sin(\\lambda\\Theta)}{sin(\\Theta)}W_{instruct}$\nwhere $\\Theta = arccos(W_{chip}, W_{instruct})$ is the angle between $W_{chip}$ and\n$W_{instruct}$, and $\\lambda \\in [0,1]$ determines the interpolation point along\nthe geodesic, with $\\lambda = 0$ corresponding to $W_{instruct}$ and $\\lambda = 1$\ncorresponding to $W_{chip}$.\nFinally, to restore the magnitude of the original weight matrices,\nwe rescale the interpolated weights back to the manifold by applying\nthe Frobenius norms:\n$W_{merge} = Norm_{chip} \\cdot Norm_{instruct} \\cdot W_{merge}$\nThis process results in $W_{merge}$, the weight matrix for each layer in the\nmerged model $M_{merge}$, effectively combining instruction alignment\nand chip design expertise in a single model."}, {"title": "IV. EXPERIMENT", "content": "We have conducted a comprehensive evaluation of ChipAlign,\ncomparing its performance against state-of-the-art (SoTA) baselines\non the OpenROAD QA benchmark and industrial production-level\nchip QA benchmarks. To further evaluate ChipAlign's capabilities,\nwe assess its instruction alignment on the IFEval benchmark and its\ndomain knowledge on multiple-choice QA benchmarks covering EDA\nscript generation, bug summarization, and circuit design. Finally, we\nconduct a sensitivity analysis on the hyperparameter \u5165 in ChipAlign.\nOpenROAD QA \u2013 As shown in Figure 4(a), we consider two well-\naligned instruction LLMs that are publicly available: Qwen1.5-14B-\nChat and LLaMA3-8B-Instruct. Following the methodology of Pu et al.\n[16] and Sharma et al. [17] to generate strong domain-adapted LLMs,\nwe apply retrieval augmented DAFT to both models using around\n2K context-query-answer training triplets from OpenROAD QA [29].\nSpecifically, we perform DAFT on each training QA pair along with\nits golden context, and adopt low-rank adaptation (LoRA) with a rank\nof 8 and an alpha of 16. We train the models over 20 epochs with a\nlearning rate of 2\u00d710-4 and a batch size of 1. Both models are trained\non four nodes of a computing cluster, each node being equipped with\neight A100 GPUs, each with 80GB of memory. This process results\nin the creation of Qwen1.5-14B-EDA and LLaMA3-8B-EDA. Once\nboth the instruction and domain-adapted LLMs are available, we use\nChipAlign with X = 0.6 to fuse their weights, producing Qwen1.5-\n14B-ChipAlign and LLaMA3-8B-ChipAlign. Remarkably, the fusion\nprocess takes only 10 minutes on a CPU with 48 cores running at 2.5\nGHz. Additionally, we compare ChipAlign with various popular model\nmerging baselines such as task arithmetic (TA), TIES, DELLA, and\nModel Soup, adopting the recommended hyperparameters from their\nrespective publications. Besides, we further compare ChipAlign against\nthe general SoTA model GPT-4 Turbo and RAG-EDA, a Qwen1.5-\n14B-Chat based LLM highly customized for this benchmark [16].\nTo quantitatively assess model performance, we follow Pu et al. to\nadopt the ROUGE-L scoring method for comparing the generated\nLLM responses with the golden answers [13]. We have found that the\nROUGE-L score is a more representative metric on this benchmark\nthan either the BLEU [15] or UniEval [31] scores.\nIndustrial chip QA \u2013 As indicated by Figure 4(b), we select what\nis possibly the largest chip LLM, LLaMA2-70B-ChipNeMo, as our\nbaseline. This model is developed by first undergoing DAPT on 24\nbillion tokens derived from chip design documents and code, using\nthe LLaMA2-70B-Base model, followed by DAFT on 57K instruction\npairs. More training details are available in [14]. Additionally, we\nchoose LLaMA2-70B-Chat as the instruction model that is publicly\navailable and has the same architecture as LLaMA2-70B-ChipNeMo.\nWe set X = 0.6 in ChipAlign for merging LLaMA2-70B-ChipNeMo\nand LLaMA2-70B-Chat to produce LLaMA2-70B-ChipAlign. Owing\nto the linear complexity of ChipAlign, the weight fusion process takes\n43 minutes on a CPU equipped with 48 cores operating at 2.5 GHz.\nBesides, we utilize a GPT-4 based grader to assess the quality of each\nLLM response by comparing it with the golden answer. The grader\nassigns scores in {0, 25, 50, 75, 100}, where a higher score indicates\nbetter answer quality.\nWe evaluate all models using 90 high-quality context-query-answer\ntriplets from the OpenROAD QA benchmark, which all follow the\nsame instruction shown in Figure 5. For each triplet, the context is\nderived either from the golden context corresponding to the given\nquery or from the retrieved context via retrieval-augmented generation\n(RAG) using OpenROAD documentation. To establish a strong RAG\npipeline, we employ the bge-large-en-v1.5 for text embedding, BM25\nfor lexical retrieval, and bge-reranker-large for re-ranking [25]. For\nthe purpose of reproducibility, we set the temperature parameter to\n0.0 for all models during response generation.\nTable 1 showcases that ChipAlign surpasses all existing model merg-\ning methods in most cases, achieving a ROUGE-L score improvement\nof up to 6.4%. This empirical evidence confirms that our geometric-\naware method produces a superior merged model compared to other"}, {"title": "V. CONCLUSION", "content": "This work introduces ChipAlign, a geometric-aware model merging\napproach to enhance instruction alignment in chip LLMs. ChipAlign\ntreats the weights of a chip LLM and a general instruction LLM as two\npoints on a Riemannian manifold and employs geodesic interpolation\nto create the merged model. Our results demonstrate that this merged\nmodel significantly improves instruction alignment in chip LLMs,\nyielding superior performance across various chip QA benchmarks."}]}