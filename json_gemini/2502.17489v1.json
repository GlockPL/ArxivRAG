{"title": "Using Graph Convolutional Networks to Address fMRI Small Data Problems", "authors": ["Thomas Screven", "Andr\u00e1s Necz", "Jason Smucny", "Ian Davidson"], "abstract": "Although great advances in the analysis of neuroimaging data have been made, a major challenge is a lack of training data. This is less problematic in tasks such as diagnosis, where much data exists, but particularly prevalent in harder problems such as predicting treatment responses (prognosis), where data is focused and hence limited. Here, we address the learning from small data problems for medical imaging using graph neural networks. This is particularly challenging as the information about the patients is themselves graphs (regions of interest connectivity graphs). We show how a spectral representation of the connectivity data allows for efficient propagation that can yield approximately 12% improvement over traditional deep learning methods using the exact same data. We show that our method's superior performance is due to a data smoothing result that can be measured by closing the number of triangle inequalities and thereby satisfying transitivity.", "sections": [{"title": "1 INTRODUCTION", "content": "Analysis of functional magnetic resonance imaging (fMRI) data is most frequently performed for patients in \"resting state\" (absence of a task) during which the default mode network (DMN) [5] is the\nAX"}, {"title": "2 DATA SETTING", "content": "In this section, we use the following terminology: subject, scan, trial type, trial, event, and frame. The first two sub-sections are provided for completeness and can be skipped on the first reading. The last two sub-sections provide details required to better understand the representation and learning challenges.\nA subject is a participant performing the tasks while the brain activity is recorded. Each subject has a label (responds to treatment or not). A scan is the whole fMRI sequence of one subject. A trial is a snippet of a scan from the beginning of a cue to the last frame before the next cue. An event is either a \"Cue\", or a \"Probe\" with \"Rest\" frames (delay time) between any cues and probes. A frame is a 3-dimensional (3D) picture of the brain consisting of voxels. In our data, BOLD (blood-oxygen-level- dependent) measurements are taken at the voxel level."}, {"title": "2.1 Data Sample", "content": "The data sample consisted of 82 individuals with recent onset (<2 years) psychotic disorders. Treatment in the clinic follows a coordi- nated specialty care (CSC) for early psychosis model delivered by an interdisciplinary treatment team. Treatment includes detailed clini- cal assessments using gold-standard structured clinical interviews and medical evaluations, targeted pharmacological treatments, in- cluding low-dose atypical antipsychotic treatment, individual and family-based psychosocial education and support, cognitive behav- ioral therapy for psychosis, and support for education and employ- ment. The Structured Clinical Interview for DSM-IV-TR (SCID) (9) was used for diagnosis of psychopathology. Diagnoses were con- firmed by a group of trained clinicians during case conferences. All patients reported psychosis onset within two years of the date of informed consent. Patients were excluded for a diagnosis of ma- jor medical or neurological illness, head trauma, substance abuse in the previous three months (as well as a positive urinalysis on the day of scanning), Weschler Abbreviated Scale of Intelligence-2 score (WASI-2) (10) score < 70, and magnetic resonance imaging"}, {"title": "2.2 AX-CPT fMRI data", "content": "Whole brain, single subject fMRI connectivity data were extracted from the AX-CPT using an atlas of 5 mm radius ROIs centered at MNI coordinate locations provided by an fMRI meta-analysis by Power et al. (2011) (16) using the CONN v.21 toolbox (17). Frames with greater than 0.5 mm of movement between them were ex- cluded. Rigid-body movement parameters (x, y, z, roll, pitch, yaw) were used as nuisance regressors when calculating connectivity values. Counts of included frames for each trial-type were AX Tri- als: Mean = 328, S.D. = 96; AY Trials: Mean = 46, S.D. = 15; BX Trials: Mean = 61, S.D. = 17; BY Trials Mean = 41, S.D. = 9. Scanner field strength (1.5T or 3T) was included as a feature. Connectivity values were converted to absolute values before being used in models."}, {"title": "2.3 Task Description", "content": "The AX-CPT and associated task parameters have been described in detail elsewhere (3, 12-15). Briefly, participants are presented with a series of cues and probes and are instructed to make a target response (pressing a button with the index finger) to the probe letter \"X\" only if it is preceded by the cue letter \"A.\" All cues and nontarget probes require nontarget responses (pressing a button with the middle finger). Target sequence trials (i.e., \"AX\" trials) are frequent (60-70% occurrence) and set up a prepotent tendency to make a target response when the probe letter X occurs. As a result, a nontarget sequence trial in which any Non-A cue (collectively called \"B\" cues) is presented and followed by a probe letter X (i.e. \"BX\" trials) requires proactive cognitive control (e.g. maintenance of the inhibitory rule over the delay time) (13). Consistent with prior work (14), individual subject data was only included in analyses if results suggested the subject understood the AX-CPT (specifically, an accuracy greater than 44% on AX trials and 50% on BY trials at both baseline and follow-up). Participants were combined across two task protocols collected from two MRI scanners over a 14-year period. Parameters for each protocol (AX-CPT I and AX-CPT II) are provided in Supplementary Table 1a. The task was presented using EPrime2 software (Psychology Software Tools, Inc.)."}, {"title": "2.4 Small Data and Multi-View Nature", "content": "This paper is solving a small data problem because the dataset contains only 82 scans from different subjects. At the same time, it is also a multi-view problem. There are six different trial-types of the data: CueA, CueB, ProbeAX, ProbeAY, ProbeBX, and ProbeBY. Each trial type reveals different perspectives of brain activity, offering a unique perspective on the subject. Each trial type is treated as a unique view of the subject being scanned, and each view holds a collection of trials."}, {"title": "3 OUR APPROACH", "content": "We begin by overviewing the entire approach and then going into greater detail in each sub-section:\n\u2022 For each of the six views, we create a different model (see section 3.2). Each model is a graph convolutional neural network (GNN). The population structure is derived from the subject's phenotypic data, and the features for each pa- tient/node is their spectrally embedded region of interest (ROI) correlation matrices (see section 3.1).\n\u2022 We utilize a majority voting ensemble method to equally consider each trial-type model's predictions. This dynam- ically combines the multiple views in an instance-specific manner (see section 3.3)."}, {"title": "3.1 Subject Representation and Population Graph Construction", "content": "We first describe how we represent each subject and then how we construct the graph for the GNN.\nSubject Representation Using Spectral Embedding. Each sub- ject has a fully connected brain correlation matrix. The correlation matrix identifies co-activation between regions of interest (ROI) in the brain by computing the Pearson correlation between the temporal BOLD (Blood Oxygenation Level Dependent) signals for each ROI. Representing each subject with a full correlation matrix may be suitable for larger data problems but can yield overfitting in small data problems. Instead, to find the most active subnetworks in each subject's brain data, we use a spectral embedding approach. Spectral embedding is performed by converting a subject's cor- relation matrix into an unnormalized Laplacian matrix, as shown below in equation Equation 1. Then we find its eigenvectors, which are normalized by their maximum value, meaning all values are between [0,1]. The collection of the largest k (in out experiment k = 10) eigenvectors serve as the spectral embedding of the pa- tient's correlation matrix.\nLet C be a subject's correlation matrix, D be the degree vec- tor, L be the un-normalized Laplacian matrix, U be the matrix of eigenvectors, and \\lambda be the diagonal matrix of eigenvalues then we have:\n$D = \\sum_{j=1}^{n} C_j$\n$L=D-C$\n$LU = \\lambda U$ (1)\nIn the context of correlations between ROI's, less variance sig- nifies that those areas of the brain are highly synchronized with each other. Therefore, we use the eigenvectors with the lowest eigenvalues because these imply active sub-networks in the brain."}, {"title": "Population Representation Using Subject Similarity", "content": "We cre- ated a weighted adjacency matrix to represent the similarity be- tween subjects. The matrix details how similar the two subjects' phenotypic data are. Two similar subjects have a value closer to 1, while two dissimilar subjects have a value closer to zero.\nLet W be the weighted adjacency matrix where W[i][j] rep- resents the similarity between subject i and subject j. Let f be a function that returns the phenotypic data for a subject where $f_2$(age) returns the age of the second subject. Let N be a function that returns a normalizing constant for that phenotype so that different phenotypes can be aggregated over.\n$W[i][j] = \\prod_{p \\epsilon phenotypes} (1 - \\frac{|f_i(p) \u2013 f_j (p)|}{C(p)})$ (2)\nTo obtain the pairwise relationship between two subjects, we use Equation 2 where W[i][j] is initialized to 1 and then multiplied by the normalized dissimilarity between subject i and subject j for each phenotype.\nUsing the spectral embedding of the correlation matrices and the population level adjacency matrix, we construct a fully connected population graph where the edges represent population similarity. Each node represents an individual, with the node's features being the spectral embedding of the subject's connectivity matrix. The edge weights between nodes i and j are determined by the adjacency matrix entry at (i, j) (Y[i][j] = W[j] [i]) based on the similarity of the subjects' phenotypes. We use the phenotype features in Table 1."}, {"title": "3.2 Model Architecture", "content": "The deep learning architecture created for this problem setting is shown in Figure 2. We build six Graph Convolutional Neural Network (GNN) models with the same architecture for each view of the fMRI correlation data. Each model operates on a fully con- nected population graph incorporating the spectrally embedded ROI correlation data and pairwise phenotypic similarity between subjects.\nThe GNN models perform feature propagation on each node us- ing its neighbors. Because the graph is fully connected, information is shared between all subjects. The edge weights between subjects in the graph, encoded by their phenotypic similarity, determine how much weight each node has in propagation. The node feature matrix, H, encodes the internal feature matrices of each node in the graph. H at layer k + 1 is updated by multiplying the node feature matrix by the adjacency matrix (Equation 3).\n$H^{k+1} = WH^k$ (3)\nThe graph output of the propagation is fed into a fully connected feedforward neural network, producing binary classification labels. The final graph takes these labels. The nodes in the final graph retain the learned embeddings.\nTraining & Evaluation. For training, a cross-entropy loss func- tion and Adam optimizer are used. The model is evaluated using k-fold cross-validation."}, {"title": "3.3 Combining Models", "content": "Our method creates six graph convolutional neural networks, which have all been trained on correlation matrices from different tasks. The six different trial types can create different correlation matrices for the same subject. The subjects and phenotypic data are identical between models. We consider each model to be an expert and wish to leverage the knowledge that can be derived from the different tasks.\nWe accomplish this by implementing a majority vote ensemble method. This protocol combines the binary predictions from each GNN model for each subject. Each model's prediction is equally weighted. At least 4 models need to give a positive prediction for the ensemble to classify a subject as being a treatment improver. Subjects without a majority of models agreeing on a positive classi- fication, including a tie, are classified as treatment non-improvers."}, {"title": "4 EXPERIMENTS AND RESULTS", "content": "In this section, we discuss the experimental settings and results, addressing the following questions:\n\u2022 Can our GNN outperform a standard neural network (NN) model that uses the exact same data? (see section 4.2 and Table 2)\n\u2022 GNNs do not always work well. Are their properties on the underlying population graph that are more conducive to GNN's better performance? (see section 4.3 and Table 3)\n\u2022 Is the GNN model's better performance due to smoothing data by reducing the number of triangle inequality viola- tions? (see section 4.4 and Table 4)"}, {"title": "4.1 Data and Experimental Setup", "content": "Data Collection. Functional images were acquired with a gradient- echo T2* Blood Oxygenation Level Dependent (BOLD) contrast technique. AX-CPT I was performed in a 1.5T scanner (GE Health- care), and AX-CPT II in a 3.0T scanner (Siemens). fMRI data were preprocessed using SPM8 (Wellcome Dept. of Imaging Neuroscience, London) as described previously (6, 7). Briefly, images were slice- timing corrected, realigned, normalized to the Montreal Neurolog- ical Institute (MNI) template using a rigid-body transformation followed by non-linear warping, and smoothed with an 8 mm full- width-half-maximum Gaussian kernel. All individual fMRI runs had less than 4 mm of translational within-run movement, 3 degrees of rotational within-run movement, and .45 mm of average frame- wise displacement, calculated using the fsl_motion_outliers tool. (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLMotionOutliers). Mean dis- placement did not differ between Improvers and Non-Improvers (t = 1.42, p = .16). All participants had at least two fMRI runs surviving these criteria. Preprocessing pipelines were identical for AX-CPT I and II."}, {"title": "Experimental Setup", "content": "We studied the performance of our 2-layer GNN and compared it to a 1-layer and a 2-layer neural network (NN). These two other models were constructed using PyTorch neural network modules. For the 2-layer network, processed fMRI con- nectivity matrices and phenotypic data are the input. This means the NN has the exact same data as the GNN, but the two networks use it in different ways. The 1-layer network used just fMRI con- nectivity matrices. The results show that the GNN performed sig- nificantly better than the other two models, resulting in Table 2. All models use ten-fold cross-validation. For all models, we used a cross-entropy loss function and stochastic gradient descent for the training optimizer. The GNN has a learning rate of 0.1. Both the 1 and 2-layer NN have a learning rate of 1 \u00d7 10-3 and weight decay of 0.1 every 25 epochs. The dropout rate of the 1-layer network is 0.2 while the 2-layer network's dropout rate is 0.1."}, {"title": "4.2 Model Results", "content": "Performance metrics for all models are shown in Table 2. It is im- portant to note that the GNN had the effect of improving accuracy significantly for improvers whilst keeping the performance for non-improvers similar. This is a clinically important result as such subjects are the best use of clinical resources and also have a benefit for the subjects as treatments can be time-consuming. Interestingly, the 2-Layer NN uses the population level data (used by the GNN to construct the graph), and the fMRI data represented as a spectral embedding yet performed significantly worse. This shows the im- proved performance of the GNN is due to how it learns from the data, not due to additional data.\nStatistical Significance of Results. A significant effect of model type was observed on accuracy (ANOVA Wilks' Lambda F(2,23) = 283.4, p < .001). Post-hoc tests revealed significant differ- ences in accuracy between the 1 and 2-layer NNs, the 1-layer NN and GNN, and the 2-layer NN and GNN (all p < .001). Significant effects were also observed on accuracy for improvers F(2,23) = 824.8, p < .001, accuracy for non-improvers(F(2,23) = 509.8, p < .001), AUC (F(2,23) = 448.9, p < .001), and F1 score (F(2,23) = 42.7, p < .001). Post-hoc tests revealed significant differences between all pairwise"}, {"title": "4.3 GNN Propagation", "content": "In the previous section we demonstrated the better performance of our method. Here we try to understand when this will occur and in the next section why it occurred.\nTraditional deep learning models, such as the 1 and 2-layer NNs in Table 2, treat instances as independent entities. However, our GNN model propagates information between subjects using the population graph structure. This effectively rewrites each subject's connectivity data as a linear combination of its most similar neigh- bor/subjects (including itself, of course) and their most similar subjects and so on as described in section 3.2. This process lever- ages complex relationships between subjects and can mitigate the small data problem, but not always.\nFurthermore, the structure of the patient similarity graph allows effective communication within node communities (see Table 3). By sharing data between training instances, our model makes informed transformations to each subject node's embedding using phenotyp- ically similar subjects. This propagation process allows our GNN model to effectively identify patterns that traditional architectures may overlook."}, {"title": "4.4 Data Smoothing Via Reducing Triangle Inequalities Violations", "content": "The GNN method can be viewed as a pre-processing of the data, in our case, the subject connectivity data. Here, we investigate how our GNN model's feature propagation method favorably changed each subject's correlation matrices.\nOur subject representations scheme is a spectral embedding that takes the input correlation matrix between ROIs and attempts to map similarly behaving ROIs close together. Such a representation scheme makes strong assumptions in particular, that the triangle inequality is satisfied. This is so as if ROI R1 is highly correlated with R2 and R2 is highly correlated with R3 then it is assumed that R1 and R3 are correlated due to transitivity. If the data does not yield this result, and R1 and R3 are not highly correlated, then this creates challenges. In particular, how to embed R1 to be close to R2 and R2 to be closer to R3 yet making R1 far from R3. Triangle inequality violations are precisely what was occurring in our original data, and we empirically demonstrate that the GNN reduces the number of triangle inequality violations by nearly 30% (see Table 4).\nWe examined every possible triad of ROIs in each subject's cor- relation matrix for all six views. Every triad is classified as either satisfying the triangle inequality or not as follows. Let R1, R2, and R3 denote these three ROIs. The subject's correlation matrix contains the correlation value of each pair of ROI combinations. According to the triangle inequality, the absolute value of the correlation be- tween R1 and R3 must be greater than or equal to the sum of the absolute correlations between R1 and R2 and R2 and R3. If not, it sig- nals there is noise in the data in the sense that a triangle inequality is violated."}, {"title": "5 RELATED WORK", "content": "The Deep Learning Studies on fMRI Data. Medical imaging analysis has seen considerable development over the last several decades. Thanks to the rapid progress, particularly convolutional neural networks (CNNs) [8], towards medical imaging analysis [26]. Impressive performance comparable to human experts on im- age classification, object detection, segmentation, registration, and other tasks [11] has occurred. As one of the most popular modalities, most of the previous works are on resting-state fMRI (rs-fMRI) data. [17] used convolutional neural networks to classify Alzheimer's brain from the normal healthy brain. [1] proposed an unsupervised matrix tri-factorization to discover an underlying network that con- sists of cohesive spatial regions (nodes) and relationships between those regions (edges) for brain imaging data. Such works on rs- fMRI focus on exploring the intrinsically functionally segregation or specialization of brain regions/networks [12] but are limited on identifying spatiotemporal brain patterns that are functionally involved in specific task performance.\nThere exist some work on using GNN for fMRI data [14, 15] but it differs from our work in several important ways. Firstly, previous work is for diagnosis not prognosis, it is for resting state data not task fMRI data and does not use the spectral embedding representation as we do. Perhaps most importantly it is for larger data sets with the later work [14] using the ADNI data set [6] which contains thousands of instances not under one hundred like our work.\nThe t-fMRI Studies. Recently, the t-fMRI analysis is attracting more and more attention for its ability to connect human activities to brain functioning. In the work of [18], the subjects in the study are asked to read a chapter from a novel while the fMRI scans recording their brain activities are conducted. They fine-tuned a pre-trained BERT model to map the natural language to brain fMRIs. [16] used time-varying persistence diagrams to represent the human brain activities when the subjects are watching the movie. [19] studies deep image reconstruction by decoding fMRI into the hierarchical features of a pre-trained deep neural network (DNN) for the same input image. The studies in schizophrenia diagnosis utilizing cognitive control tasks suffered from either small sample size or modest classification performance [32]. All these t-fMRI settings are different from the AX-CPT setting, for they don't have multiple types of repeated independent clinical trials to result in one combined evaluation. Instead, their tasks are sequence-to-sequence, guided by the inputs such as series of images and natural languages.\nThe AX-CPT t-fMRI Studies. The AX-CPT task is a clinical test on reactive and proactive control processes to identify human"}, {"title": "6 CONCLUSION", "content": "The analysis of medical imaging has made great progress, par- ticularly in problems of diagnosis. These results are typically in domains where there are many training instances, as it is possible to aggregate results across different sites, producing data sets with thousands of instances.\nHowever, a growing important area is prognosis where we at- tempt to predict whether a subject will respond to at specific treat- ment based on brain imaging. For such prediction problems there is typically limited data, often numbering in the hundreds. In our experimental setting of predicting treatment response for children with Schizophrenia, we have just 82 instances.\nFor such small data problems, traditional deep learning methods (see Table 2) produce sub-standard results often because not all subject data is informative. We address the small data challenge with two innovations. Firstly, we showed a spectral embedding of the subject connectivity data produces a simpler representation that prevents over-fitting. Rather than representing each subject with n\u00b2 correlations, each subject is represented by kn values where k = 10 in our experiments. However, a spectral embedding requires well-behaved data in particular that the number of triangle inequality violations is limited. Our second innovation is we use a graph convolution using the subject similarity to smooth out data, and we empirically show that it greatly reduces the number of triangle inequality violations (see Table 4)."}]}