{"title": "Human Misperception of Generative-AI Alignment: A Laboratory Experiment", "authors": ["Kevin He", "Ran Shorrer", "Mengjia Xia"], "abstract": "We conduct an incentivized laboratory experiment to study people's perception of\ngenerative artificial intelligence (GenAI) alignment in the context of economic decision-\nmaking. Using a panel of economic problems spanning the domains of risk, time\npreference, social preference, and strategic interactions, we ask human subjects to make\nchoices for themselves and to predict the choices made by GenAI on behalf of a human\nuser. We find that people overestimate the degree of alignment between GenAI's\nchoices and human choices. In every problem, human subjects' average prediction\nabout GenAI's choice is substantially closer to the average human-subject choice than\nit is to the GenAI choice. At the individual level, different subjects' predictions about\nGenAI's choice in a given problem are highly correlated with their own choices in the\nsame problem. We explore the implications of people overestimating GenAI alignment\nin a simple theoretical model.", "sections": [{"title": "Introduction", "content": "Individuals and organizations are increasingly using generative artificial intelligence (GenAI)\nto help with their economic decisions.\\u00b9 This trend is accelerated by the rise of AI agents\nthat can interact with the external environment and autonomously take actions on behalf\nof the user (OpenAI, 2025), making it possible to even fully delegate economic decisions to\nGenAI.\nUnlike classification and prediction tasks, where machine-learning methods and AI systems\nhave been traditionally deployed, economic decisions often do not have an objectively \\u201ccorrect\\u201d\nanswer that applies to everyone. Instead, these economic problems confront agents with\ntrade-offs (e.g., higher payoff vs. earlier payoff, efficiency vs. equity, riskier but potentially\nhigher rewards vs. safer but lower rewards) and the optimal choices depend on the agent's\npreferences. To fully realize the potential gains from delegating economic decisions to GenAI,\npeople must hold correct beliefs about how this technology behaves when instructed to act\non their behalf. If people correctly anticipate GenAI's behavior, then judicious delegation\nof the appropriate decision problems to GenAI can save time and effort. But if people\nmisperceive the degree of alignment between the GenAI choices and the user's preferences,\nthey may make suboptimal delegation decisions and even end up worse off than without\naccess to GenAI.\nThis paper experimentally investigates the hypotheses that people overestimate the degree\nto which GenAI choices are aligned with human preferences in general (anthropomorphic\nprojection), and with their personal preferences in particular (self projection). To this\nend, we conduct an incentivized laboratory experiment where we focus on understanding\npeople's beliefs about GenAI's choices.\\u00b3 The experiment consists of two parts. In the first\npart, subjects are asked to make choices in an array of incentivized decision environments\nspanning the domains of risk, time preferences, social preferences, and strategic interactions.\\u2074\nIn the second part, subjects are asked to predict the choices an AI chatbot would make when\ninstructed to choose on behalf of a human user in the same decision environments. Subjects\nreceive a bonus if their prediction is sufficiently close to the average choice made by the large\nlanguage model (LLM) GPT-40.\nWe find evidence of both anthropomorphic projection and self projection. First, on\naverage, human subjects' predictions about GenAI's choices in every decision environment\nare much closer to the average human-subject choice than to the average GenAI choice."}, {"title": "Theoretical Implications of Anthropomorphic Projection\nand Self Projection", "content": "In this section, we present a stylized theoretical model of anthropomorphic projection and\nself projection and show that these misperceptions can imply some unexpected comparative\nstatics for GenAI users' welfare. This model also serves as the conceptual framework for\nguiding our empirical analysis of the experimental data."}, {"title": "A Model of Delegation under Misperceived Alignment", "content": "Nature draws a decision problem w ~ N(0,2), which is not observed by the agent. The\nagent observes their type 0 ~ N(0, \\u03c3\\xb2) and an attention cost c > 0, where c is drawn from\na strictly positive density on R+ (and is independent of \\u03b8 and w). An action a \\u2208 R must be\ntaken and the agent with type e gets decision utility \\u2013 (a \\u2013 w \\u2013 0)\\xb2 from action a in decision\nproblem w.\n3|\nThe agent first chooses whether to costlessly delegate their action to the GenAI. When\nthe decision problem is w and the agent delegates, the GenAI will take the action w+b(w) on\nbehalf of the agent (regardless of the agent's actual type 0). If the agent does not delegate,\nthen they must choose an action themselves. Before doing so, they have the chance to pay\nthe attention cost c and perfectly learn the realization of w. If the agent does not delegate\nand does not pay the attention cost, then they must choose an action knowing only their\ntype 0.\nThe agent is fully rational except for potentially misperceiving the GenAI's action. In\nparticular, a type 0 agent believes that the GenAI will take the action w + rb(w) + \\u03c1\\u03b8 in\ndecision problem w, where r \\u2208 [0,1] and p\\u2208 [0,1]. The agent maximizes expected total\nutility (i.e., decision utility minus any attention cost) given these beliefs."}, {"title": "Interpretation of the Model", "content": "We interpret w to capture the specific details of a decision to be made, such as the rate of\nreturn on a risky investment or the social benefit of a generous act. The agent's ideal action\ndepends on both the decision problem w and their type 0, which refers to a personal trait\nsuch as risk attitude or social-preference parameter. We assume that the agent knows their\ntype and the distribution of decision problems, but must pay a cost c > 0 to understand the\ndetails of the particular problem that they are currently facing.\nThe average ideal action within the population of agents for decision problem wi\\u03c2 w.\nWe interpret the term b(w) to be the bias of the GenAI relative to the humans for decision\nproblem w. We are agnostic about the source of such bias (for instance, biased training\nsample or issues with the model-training procedure) and allow the amount of bias to depend\non the decision problem in an arbitrary way.\nThe model accommodates both anthropomorphic projection and self projection. The\nparameter r relates to anthropomorphic projection, where agents on average wrongly predict\nthe GenAI action in problem w to be r\\u00b7 (w + b(w)) + (1 - r) \\u00b7 (w) = w + r\\u00b7 b(w). Thus\nanthropomorphic projection becomes more severe asr decreases, with people's predictions\nof GenAI's action becoming more centered around the typical ideal human action and further"}, {"title": "Implications of Anthropomorphic Projection", "content": "Suppose \\u03c3\\xb2 = 0, so there is no individual-level variance in optimal actions. We show that\nprojection bias causes over delegation to the GenAI.\nProposition 1. There is a threshold r \\u2208 [0,1] so that when r > r, the agent never delegates\nto GenAI and behaves in the same way as a rational agent. When r < r, the agent delegates\nto GenAI when c > r\\xb2E[b(w)\\xb2] and pays the attention cost when c < r\\xb2E[b(w)\\xb2], and the\nprobability of over-delegation is strictly decreasing in r over the range [0,7]. The threshold \u0159\nis strictly interior when E[b(w)\\xb2] > \\u03c3\\xb2 and it is equal to 1 when E[b(\\u03c9)\\xb2] < \\u03c32.\nIn the case where the GenAI's bias is relatively large (E[b(w)\\xb2] > \\u03c3\\xb2), a rational agent\nnever delegates to GenAI. Instead, a rational agent either pays the attention cost to learn\nw when c is low enough, or chooses the ex-ante optimal default action 0 when c is too high.\nWith sufficiently severe anthropomorphic projection, the biased agent over delegates. For\nhigh c, the biased agent delegates to GenAI while the rational agent chooses the default\naction. For medium c, the biased agent delegates to GenAI while the rational agent pays\nthe attention cost.\nEven in the case where the GenAI's bias is relatively small (E[b(w)\\xb2] < \\u03c3\\xb2) so that a\nrational agent sometimes delegates to GenAI, the biased agent still uses a wrong threshold\nin cost realization to decide between paying attention or delegating to GenAI. For some\nmedium realizations of c, a rational agent pays attention but the biased agent delegates.\nA corollary of Proposition 1 is that an agent who suffers from anthropomorphic projection\ncan be made strictly worse off when the GenAI becomes objectively more aligned on every\nproblem. Of course, this cannot happen to a rational agent, and it also cannot happen\nunder any fixed (even if irrational) delegation strategy that maps attention cost realizations"}, {"title": "Implications of Self Projection", "content": "Now suppose b(w) = 0 for every w, so the GenAI takes the optimal action for the average\nagent in every decision problem. If an agent exhibits self projection bias with p = 1, then\nthey believe that the GenAI will take their optimal action in every decision problem. So, they\nwill make the mistake of always delegating their decisions. The next proposition generalizes\nthis special case: under any amount of self projection, agents whose 0 types are not too\nextreme over-delegate to GenAI because they over-estimate the degree to which the AI's\ndecision matches their idiosyncratic preferences.\nProposition 2. Suppose p \\u2208 [0,1). For |0| > \\u03c3\\u03c9/(1 \\u2013 p), the agent never delegates to\nGenAI for any realization of c and behaves as-if rationally. For \\u03c3w < |0| < \\u03c3\\u03c9/(1 \\u2013 \\u03c1), the\nrational agent never delegates to GenAI but the biased agent delegates to GenAI with positive\nprobability. For |0| < \\u03c3\\u03c9, both the rational agent and the biased agent delegate to GenAI\nwith positive probability, but the biased agent does so for more realizations of the attention\ncost c.\nThe idea behind this result is that an agent with type 0 partially projects their type onto\nthe GenAI's behavior, thus misperceiving the expected decision utility from delegation to be\n-(1 \\u2013 p)\\xb20\\xb2 instead of the objectively correct -0\\xb2. This causes the agent to over-delegate\ncompared to the rational benchmark."}, {"title": "Experimental Design and Deployment", "content": "We advertised the experiment as a study that requires agents to make incentivized choices\nand predictions. The experiment began with a brief informed consent. Subjects who\nconsented were told that the experiment consists of two parts, that they will earn \"tokens\"\nbased on their answers, and that these tokens will be converted into a bonus payment at\na rate of 1,000 tokens per US dollar at the end of the experiment (in addition to a base\npayment).\nIn the first part of the experiment (choice tasks), subjects are asked to make choices in\nnine problems spanning four domains: risk, time preference, social preference, and strategic\ninteractions (see Section 3.2 for details on the problems). Problems appear in a random\norder: for each subject, we draw uniformly at random an order of the four domains, and\nwithin each domain we also randomize the order of the problems. Subjects earn tokens\nbased on their choices in every problem. Subjects receive no feedback during the experiment\n(specifically, they only learn how much they earned after the end of the experiment).\nIn the second part of the experiment (prediction tasks), subjects are told that an AI\nchatbot was asked to make choices on the behalf of a human user in the same problems (and\nin an additional problem that the subjects have not seen before). They are also shown the\nexact instructions that were given to the chatbot before each choice:"}, {"title": "The Decision Problems", "content": "We assembled a panel of ten economic decision problems across the four domains: risk,\ntime preference, social preference, and strategic interactions. Eight of the problems came\nfrom Snowberg and Yariv (2021), who use these (and other) tasks to compare behavior\nacross different experimental subject pools. We added an additional problem of strategic\ninteraction (the beauty contest, Decision Problem 9) and an additional problem of social\npreference (Decision Problem 10) that uses slightly different numbers than those used in\nSnowberg and Yariv (2021). Each problem requires either a numerical answer or a binary\nanswer.\nDecision Problem 1 (\\u201crisk100\"). The subject chooses how many tokens to wager out\nof an endowment of 100. With 35% probability, the subject receives three times the wagered\ntokens. With 65% probability, the wagered tokens are lost.\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\""}, {"title": "Auxiliary Measures and Questions", "content": "At the end of the study, we asked subjects several questions about their degree of exposure,\nusage intensity, and attitudes towards GenAI (see Figure 1). We also have access to\ndemographic data on the subjects from their Prolific account registration.\nIn addition, throughout the experiment, we tracked the amount of time that subjects\nspent on each task (choices and predictions). To mitigate the risk that subjects use LLMs in\nprediction tasks, we also kept track of subjects who copied text from the webpage during the\ntasks. Specifically, subjects who pressed the keyboard combination Ctrl+C on Windows,\nCommand+C on Mac, or used the copy function in their web browser during a task are\nflagged in our data. We found that 11% of the subjects copied text at least once.\nFinally, for robustness, and since subjects were not informed of the specific GenAI model\nused in the prediction tasks, we also queried three additional commercial models (GPT-40-\nmini, 13 Gemini-1.5-Pro, and Gemini-1.5-Flash). The prompts provided to each model were\nidentical, although the methods for eliciting choices varied. Specifically, since Google does\nnot provide the distribution of the next token, we queried the Gemini models 1,000 times for\neach task and computed the average result. These measurements were used for supplemental\nanalyses, but not for determining subjects' compensation."}, {"title": "Pre-Registration", "content": "We pre-registered our experimental protocol and primary analyses prior to the start of the\nexperiment. Our pre-registration specifies GPT-40 as the model to be used to test the\naccuracy of subjects' predictions, the target sample size (300), a measure of the relative\naccuracy of aggregate subject predictions about the GenAI choices (see Section 4.2), a\nregression specification to estimate individual-level self projection (see Section 4.3), and a\nsimilar regression specification with the subject's prediction for a particular problem as the\ndependent variable and the subject's choice in a related problem as the regressor. The pre-\nregistration also discussed our secondary analyses relating to subjects' experience with and\nattitudes towards GenAI tools, but we did not specify any particular hypotheses. The pre-\nregistration can be found on the registry website at https://aspredicted.org/yd32-r96n.pdf."}, {"title": "Main Experimental Results", "content": "Out of 300 subjects who participated in the experiment, 62.7% identified as women, 35.3%\nidentified as men, and the rest did not provide an answer. Subjects' average age was 37\n(s.d. 13). Consistent with our requirement that subjects live in the U.S., the majority of\nsubjects were born in the U.S., with 64% identifying as White, 14% identifying as Black,\n7.7% identifying as Asian, and the rest identifying as mixed or as belonging to other racial\ngroups.\nsubject pool are similar to those documented among MTurk users in Snowberg and Yariv\n(2021)."}, {"title": "Anthropomorphic Projection", "content": "To assess the degree of anthropomorphic projection, we need to compare subjects' predictions\nabout the average GenAI choice in each problem to both the actual average GenAI choice and"}, {"title": "Self Projection", "content": "Next, we investigate to what extent subjects' predictions about GenAI's choices are positively\ncorrelated with their own choices in the same problem. For each problem j, we run a linear\nregression to estimate the following pre-registered model\nPij = aj + BjXij + Eij,\n(2)\nwhere Pij is subject i's prediction of GenAI's choice in problem j, and Xij is the de-meaned\nversion of subject i's own choice for problem j (that is, Xij is i's choice minus X\u2081, the average\nchoice among all subjects for problem j). The coefficient of interest is \\u03b2;. It measures the\ncorrelation between subjects' choices and their predictions about GenAI, analogous to the\nparameter p from the theoretical model in Section 2. We interpret a positive estimate of Bj\nas evidence of self projection in problem j.\nThe two rightmost columns of Table 3 report our estimates of \\u03b2; (additional details\nare provided in Appendix Table 9). Across all problems, our estimates of \\u03b2; are positive,\nsubstantial, and statistically different from zero at the 1% level. These findings are consistent\nwith subjects projecting their personal traits onto GenAI. For example, subjects revealed\nto be more risk-seeking through their choices (i.e., those who wager more tokens in the two\nrisk-domain problems) tend to also believe that GenAI will behave in a more risk-seeking\nway, and vice versa for the more risk-averse individuals.\nOne may wonder if our findings result from subjects memorizing their choices for every\nproblem in the first part of the experiment and simply repeating them as their predictions\nor using them as anchors for their predictions in the second part of the experiment. To rule\nout this possibility, we analyze predictions in dictator200, a problem that was not used as a\nchoice task in the first part of the experiment. We estimate regression models of the form\nPij = ajk +\\u03b2jk Xik + Eij,\n(3)\nwhere Pij is subject i's prediction of GenAI's choice in problem j and Xik is the de-meaned\nversion of subject i's own choice for a different problem k.\nWe set j = dictator200. For regressors, we separately include the subjects' choices in\nfour other dictator problems and two risk problems (as k). Table 4 presents our results.\nWe find that subjects' choices from the dictator problems are highly correlated with their\npredictions of GenAI choice in dictator200, with all coefficient estimates \\u03b2jk being positive\nand statistically significant at the 1% level. This is consistent with self projection operating\nthrough a channel where subjects project their social-preference parameter onto the GenAI,\nso a generous subject both chooses to give away more tokens in the four dictator-type choice\ntasks and predicts the GenAI would give away more tokens in the new prediction task\nthat was previously unseen. By contrast, choices from the two problems that belong to a\ndifferent domain (risk problems) have much less explanatory power (as measured by R\\xb2).\nAdditionally, the estimated coefficient on one of the risk problems a is not statistically\nsignificant at standard levels.\nWe extend this analysis to problems that appeared as both choice tasks and prediction\nSummary. We find that, as a group, human subjects overestimate the similarity between\nthe average human choice and the average GenAI choice. Additionally, at the individual level,\nhuman subjects overestimate the correlation between their own choices and GenAI choices\nin every problem. We also provide evidence that suggests that this correlation may arise\nfrom human subjects projecting their traits (such as domain-specific preference parameters)\nonto the AI."}, {"title": "Heterogeneity Analyses", "content": "In this section, we explore how the degree of self projection varies along several dimensions:\nexperience with GenAI, attitudes toward GenAI, attention (as proxied by the amount of\ntime spent on prediction tasks), and gender. We find limited evidence of heterogeneity along\nany of these dimensions."}, {"title": "Experience with GenAI and Attitudes Toward GenAI", "content": "As we discuss in the introduction", "form": "nPij = aj + \\u03b2j \\u2022 Xij + dj \\u00b7 Gi + Yj \\u2022 Gi x Xij + Eij\n(4)\nwhere Gi is an indicator variable for whether subject i belongs to one of the groups. The\ncoefficient of interest is Yj. It measures if group membership is associated with lower (if\nYj < 0) or higher (if j > 0) levels of self projection in problem j.\nWe estimate the regression"}]}