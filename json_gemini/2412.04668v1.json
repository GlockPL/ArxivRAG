{"title": "Diffusion-Augmented Coreset Expansion for Scalable Dataset Distillation", "authors": ["Ali Abbasi", "Shima Imani", "Chenyang An", "Gayathri Mahalingam", "Harsh Shrivastava", "Maurice Diesendruck", "Hamed Pirsiavash", "Pramod Sharma", "Soheil Kolouri"], "abstract": "With the rapid scaling of neural networks, data storage and communication demands have intensified. Dataset distillation has emerged as a promising solution, condensing information from extensive datasets into a compact set of synthetic samples by solving a bilevel optimization problem. However, current methods face challenges in computational efficiency, particularly with high-resolution data and complex architectures. Recently, knowledge-distillation-based dataset condensation approaches have made this process more computationally feasible. Yet, with the recent developments of generative foundation models, there is now an opportunity to achieve even greater compression, enhance the quality of distilled data, and introduce valuable diversity into the data representation. In this work, we propose a two-stage solution. First, we compress the dataset by selecting only the most informative patches to form a coreset. Next, we leverage a generative foundation model to dynamically expand this compressed set in real-time-enhancing the resolution of these patches and introducing controlled variability to the coreset. Our extensive experiments demonstrate the robustness and efficiency of our approach across a range of dataset distillation benchmarks. We demonstrate a significant improvement of over 10% compared to the state-of-the-art on several large-scale dataset distillation benchmarks. The code will be released soon.", "sections": [{"title": "1. Introduction", "content": "With the rapid advancement of deep learning, the scale of neural networks and the datasets required to train them have expanded dramatically, introducing significant computational challenges. One promising approach to mitigate these demands is to explore the potential of \"small data,\" a research direction introduced by Wang et al. [34] and known as dataset distillation. Dataset distillation focuses on synthesizing a compact yet highly informative dataset from the original large-scale data, allowing models trained on this smaller set to achieve performance comparable to those trained on the full dataset [37]. By reducing training overhead, storage, and communication requirements while preserving the essential knowledge of the larger dataset, dataset distillation offers transformative potential across multiple areas of machine learning research. Its impact is particularly significant in applications that 1) require repeated training over large datasets, as seen in neural architecture search [27], 2) depend on constrained memory storage, such as memory replay in continual learning [21], and 3) involve knowledge sharing and communication across distributed machine learning agents, such as in federated learning [35].\nDataset distillation is classically formulated as a bilevel optimization problem, where the inner loop trains a model on a synthesized dataset, and the outer loop adjusts this synthetic dataset to maximize the model's performance on the original large-scale dataset. However, this approach presents two significant challenges: 1) it is computationally and memory intensive, as the outer optimization requires backpropagation through the entire unrolled computation graph of the model's training process in the inner loop; and 2) it often leads to synthetic images with spurious, non-realistic features due to overfitting to the specific architecture used during optimization, which limits generalization across architectures [2]. To address the former challenge and scale up computation, researchers have proposed methods such as gradient matching [41], which aligns the gradients of synthetic and original data to improve scalability, and training trajectory matching [1], which matches training trajectories between models trained on synthetic and original datasets to enhance distillation efficiency. To address the latter problem, recent studies emphasize the importance of realism in distilled data for achieving cross-architecture generalizability [2, 24, 28, 36], showing that incorporating generative priors and enhancing the diversity and realism of synthetic datasets can significantly improve the generalization capabilities of models trained on distilled data.\nRecently, Sun et al. [28] introduced the Realistic, Diverse, and Efficient Dataset Distillation (RDED) method, an optimization-free approach that achieves high-resolution and large-scale image dataset distillation by emphasizing the realism and diversity of the distilled images. RDED selects a diverse set of informative patches directly cropped from the original data and combines these patches into new images to form the synthetic dataset. To guide this selection, RDED uses a \"teacher\" model trained on the large-scale dataset to identify informative patches and assigns a soft label for each patch. A \"student\" model is then trained on these informative patches along with their corresponding soft labels, effectively employing knowledge distillation for dataset distillation.\nIn RDED, we observe a trade-off between patch diversity and realism for a fixed compression budget, i.e., images per class (IPC). Increasing diversity requires reducing the size of patches to fit more patches within the limited pixel space. However, decreasing patch sizes also reduces their realism, as downsampling acts as a low-pass filter, causing a loss of fine-grained details. In this context, we pose two questions: 1) Is it possible to pack more patches into a finite pixel space without sacrificing realism? and 2) Can we enhance diversity within a fixed number of patches? Following the RDED framework [28], to increase the number of patches without sacrificing realism, super-resolution techniques can be used to enhance low-resolution patches back to high-resolution quality. Additionally, diversity within a fixed number of patches can be achieved through realistic augmentations that preserve the natural image manifold. We show that modern Latent Diffusion Models (LDMs) provide both these capabilities, enabling high-quality super-resolution and naturalistic diversity enhancements. We demonstrate that enhancing the realism and diversity of the distilled dataset using LDMs results in a significant performance boost across various dataset distillation benchmarks.\nAs LDMs become faster and more accessible [20], the latency and computational costs of using them in dataset distillation are decreasing, enabling on-the-fly image augmentation. This trend lowers the barrier to incorporating LDMs, making their use more practical. Moreover, as LDMs become increasingly common in machine learning workflows, it's reasonable to expect that the student model could also leverage a diffusion model, ensuring consistent processing in teacher-student setups. This alignment makes LDM-enhanced distillation methods more feasible and appealing as LDMs continue to improve in efficiency and accessibility.\nOur experiments across multiple datasets and model architectures demonstrate that distilling a dataset into a small set of images such as one image per category-and training a student model on this distilled set results in higher accuracy than state-of-the-art dataset distillation methods. For example, on the ImageNette [13] dataset using a ResNet-18 architecture, our approach achieves 51.4% accuracy, while RDED [28], a recent comparable baseline, reaches only 35.8% accuracy.\nOur specific contributions in this paper are as follows:\n1. Using fast latent diffusion models (LDM) for on the fly coreset expansion in dataset distillation.\n2. Employing knowledge distillation with generative models for dataset distillation.\n3. Significantly advancing state-of-the-art performance in large-scale dataset distillation."}, {"title": "2. Related Works", "content": "Since its introduction by Wang et al. [34], numerous variations of dataset distillation have been developed. Below, we review some of these methods as well as other related works to our proposed framework.\nBi-level optimization provides a natural framework for formalizing dataset distillation [34]. However, as previously mentioned, this approach is generally intractable due to the significant computational and memory demands required to backpropagate through the unrolled computational graph of the inner model optimization. Various methods have been proposed to ameliorate this issue by introducing surrogate objective functions for the outer optimization. These include methods that match gradients [15, 41], extracted features [33] and their distributions [40], and training trajectories [1, 7].\nCore-set selection offers a natural approach to dataset distillation by selecting the most \"valuable\u201d subset of the training data rather than synthesizing a condensed version. Core-set-based methods vary primarily in the difficulty-based metrics they use to evaluate sample importance. For example, sample scores such as Gradient Normed (GraNd) and Error L2 Norm (EL2N) were introduced in [19] to guide core-set selection. Meanwhile, the forgetting score, initially proposed in [29], has recently been employed to perform dataset distillation progressively [3]. Recent works extend the concept of core-set selection by selecting a subset of pixels, tokens, or patches within chosen images, achieving further dataset compression [28, 43]. For instance, Sun et al. [28] select important image patches identified by a teacher model, while [43] use a subset of image tokens or patches and apply Masked Auto-Encoders [11] to reconstruct the missing patches, resulting in dataset distillation conditioned on a generative model. In our work, we use important patches similar to [28] but leverage generative modeling, and more precisely LDMs, to increase diversity and maximize compression, similar to [43].\nRealism priors have been explored in several studies to enhance the realism of distilled data. For example, Cazenavette et al. [1] show that overfitting to a specific architecture often stems from optimizing in the pixel space, which reduces realism. They address this by using generative models-specifically, Generative Adversarial Networks (GANs), to perform optimization in the latent space, producing a more realistic distilled dataset leading to better cross-architecture generalization. Other approaches use a trained teacher model and align the feature statistics of synthetic distilled data with those of a larger dataset [24, 36], which implicitly improves image realism. In our work, we leverage generative priors to enhance both the realism and diversity of the distilled dataset.\nDiffusion models have recently gained prominence as powerful tools for data augmentation and generation across various learning tasks [14, 22, 25, 31, 39]. For example, Zhang et al. [39] combine diffusion models with MAEs to expand small-scale datasets by generating new, informative, and diverse images, effectively creating realism-aware augmentations of limited datasets. DiffuseMix [14] utilizes diffusion models and introduces a unique approach that blends real and generated images, producing hybrid augmentations. However, due to the slow generation speed of diffusion models, these augmentations are often pre-generated and cached, leading to high memory demands. With growing interest in diffusion models and advances in fast sampling techniques, such as SDXL-Turbo [23], it is now feasible to generate on-the-fly augmentations during model training. In our work, we leverage SDXL-Turbo to super-resolve and augment our mined, important patches."}, {"title": "3. Method", "content": "Our proposed method for dataset distillation comprises three main steps. In Step 1, a teacher model is trained on the full training dataset. In Step 2, a compact coreset of important image patches is selected. In Step 3, the selected image patches are first upsampled and then noise-corrupted using different fixed random seeds. Each seed generates a distinct high-quality variation of the low-resolution patch using a Latent Diffusion Model (LDM). Multiple such variations are generated for each patch using different seeds. The high-quality images are then processed by the teacher model to obtain the softmax outputs of its classifier. Finally, the low-quality important patches, random seeds, and their corresponding soft labels are transferred to the student model. Figure 1 demonstrates these steps.\nUpon receiving the distilled data from the teacher, the student replicates the upsampling, noise corruption, and LDM denoising steps using the provided low-quality patches and random seeds to generate the same high-quality variations as produced by the teacher. The student then trains on the teacher's soft labels for the generated images."}, {"title": "3.1. Coreset Selection", "content": "We follow the methodology of [28] for forming the coreset of important patches. Given \\(D = \\{(x_i, y_i)\\}_{i=1}^N\\), where \\(x_i \\in \\mathbb{R}^{H \\times W \\times 3}\\) are the images and \\(y_i \\in \\mathbb{R}^{K}\\) are the corresponding class labels, we first train a teacher model \\(f_\\theta : \\mathbb{R}^{H \\times W \\times 3} \\rightarrow \\mathbb{R}^{K}\\) parameterized by \\(\\theta\\) on \\(D\\). Then, for a given image \\(x_i\\) from the dataset, we generate \\(P\\) random crops and resize them to be \\( \\lfloor\\frac{H}{r}\\rfloor \\times \\lfloor\\frac{W}{r}\\rfloor\\), where \\(r > 1\\) is a scalar indicating the patch-to-image compression ratio. Denoting \\(x_i^j\\) as the \\(j\\)-th random patch from \\(x_i\\), we deliberately use a smaller patch size compared to the full dimensions of \\(x_i\\) to compress the information, i.e., \\(x_i^j \\in \\mathbb{R}^{\\lfloor H/r \\rfloor \\times \\lfloor W/r \\rfloor \\times 3}\\). To construct our coreset, we first select the most informative patch from each image. This is achieved by choosing the patch \\(x_i^{j*}\\) that minimizes the cross-entropy loss:\n\\[x_i^{j*} = \\arg \\min_j CE(f_\\theta(x_i^j), y_i),\\qquad(1)\\]\nwhere \\(j = 1, 2, . . ., P\\), and \\(CE(\\cdot, \\cdot)\\) denotes the cross entropy loss. Next, to create the coreset under a fixed Images Per Class (IPC) memory budget, we form the coreset by choosing \\(P\\) patches with the lowest cross entropy loss. At the end of this step, for each class \\(c\\), we will have a total of \\(IPC \\times r^2\\) patches, satisfying the memory constraint. Figure 2 shows the selected coreset for the ImageNette dataset [13] for IPC=1. We note that increasing \\(r\\) allows us to store a greater number of important patches for a fixed IPC budget, thereby enhancing diversity. However, this comes at the cost of reduced realism due to the loss in resolution. Finally, we acknowledge that selecting patches based on minimum cross-entropy does not inherently ensure diversity. However, our results demonstrate that the diffusion model effectively compensates for any potential lack of diversity among the selected important patches. In the next step, we will describe our method for increasing realism despite increasing \\(r\\)."}, {"title": "3.2. Coreset Augmentation and Super Resolution", "content": "Data augmentation has long been a cornerstone for introducing variations into training data. In vision applications, simple and efficient geometric transformations such as rotations, flips, and noise additions are commonly used to artificially increase the dataset size. These augmentations are computationally inexpensive and can be performed on the fly. With recent advancements in Latent Diffusion Models (LDMs)"}, {"title": "3.2.1. Diffusion Preliminary", "content": "Latent Diffusion Models (LDMs) consist of an autoencoder and a UNet denoiser. The autoencoder is an encoder-decoder architecture that is initially trained separately to map the image from pixel space to a lower-dimensional latent space and then reconstruct it back to the original image space with minimal reconstruction error. Once the autoencoder is trained, all noise corruptions and denoising are performed in the latent space. Let \\(z_0 = Encode(x)\\) be the latent representation of image \\(x\\), and let \\(t \\in \\{0, 1, 2, . . ., T\\}\\) represent an arbitrary noising step. For training an LDM, \\(t\\) is uniformly sampled from the set of steps, and Gaussian noise is added to \\(z_0\\) in proportion to \\(t\\). The noisy latent representation is given by:\n\\[z_t = \\sqrt{\\bar{\\alpha}_t}z_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon,\\]\nwhere \\(\\sqrt{\\bar{\\alpha}_t}\\) is the data-noise interpolation coefficient and \\(\\epsilon \\sim \\mathcal{N}(0, I)\\). The denoiser, denoted by \\(\\epsilon_\\theta\\), is then trained by minimizing the following loss function:\n\\[\\mathcal{L}_{ldm} = ||\\epsilon_\\theta(z_t, t, c) - \\epsilon||^2\\]\nHere, \\(c\\) is the conditioning vector. In the case of a text-to-image diffusion model, \\(c\\) is the output of a text encoder that predicts the textual embedding of the image caption."}, {"title": "3.2.2. Using real Data as Anchors", "content": "Several works in the literature have investigated the potential of synthetic images for training downstream classifiers [8, 12, 30]. A consistent finding across these studies is that synthetic images can improve classifier performance when augmented with real data. However, even state-of-the-art synthetic images exhibit a slight distribution shift when not anchored to real images [8, 22]. Consequently, real data and synthetic samples augmented from real data tend to outperform purely synthetic samples.\nIn this work, we propose to use the low-resolution patches stored during the coreset selection step as anchors on the manifold of training distribution. Let \\(x^* \\in \\mathbb{R}^{\\lfloor H/r \\rfloor \\times \\lfloor W/r \\rfloor \\times 3}\\) be the \\(i\\)-th low-resolution patch subsampled in the previous step. We propose to first upsample the patch using 2D interpolation to the original image dimensions:\n\\[\\tilde{x}^* = INTERP(x^*),\\qquad\\]\nwhere \\(\\tilde{x}^* \\in \\mathbb{R}^{H \\times W \\times 3}\\). The upsampled patch matches the original image dimensions in \\(D\\) but still retains low quality. We propose using this low-quality image as an anchor for the LDM. Let \\(\\tilde{z^*}\\) be the latent code of the upsampled patch. We first add a small amount of noise to \\(\\tilde{z^*}\\):\n\\[\\tilde{z}_{t'} = \\sqrt{\\bar{\\alpha}_{t'}}\\tilde{z^*} + \\sqrt{1 - \\bar{\\alpha}_{t'}}\\epsilon,\\qquad(2)\\]\nwhere \\(t' \\in \\{1, 2, ..., T\\}\\). We define \\(\\rho_{as} \\in [0, 1]\\) and use it as a hyperparameter that controls the amount of noise. This small noise addition perturbs the data slightly off the training data distribution manifold. We then iteratively denoise the low-quality latent back to the manifold using \\(\\epsilon_\\theta\\), following the backward diffusion process:\n\\[z_{i,t'-1} = \\frac{1}{\\sqrt{\\alpha_{t'}}}(z_{i,t'} - \\frac{1 - \\alpha_{t'}}{\\sqrt{1 - \\bar{\\alpha}_{t'}}}\\epsilon_\\theta(z_{i,t'}, t', c))\\]\nwhere \\(\\epsilon' \\sim \\mathcal{N}(0,I)\\), and \\(\\bar{\\alpha}_{t'} = \\prod_{t=1}^{t'}\\alpha_t\\). The denoised sample is denoted as \\(\\hat{x^*}\\) = \\(z_{i,0}\\).\nThe denoised image \\(\\hat{x^*} = Decode(z_{i,0})\\) possesses two key properties: 1) since the denoiser is trained on high-resolution images, the denoised image will also be high-resolution, making \\(\\hat{x^*}\\) high quality; and 2) as a projection onto the manifold of the training distribution, \\(\\hat{x^*}\\) does not necessarily recover the same anchor patch, with the contents of \\(\\hat{x^*}\\) varying slightly based on \\(c\\) and \\(\\rho\\). Therefore, the final transformation results in a combination of super-resolution and semantic augmentation."}, {"title": "3.3. Mixup in Latent Space", "content": "Mixup [38] has become a widely adopted data augmentation method for training vision models. It encourages local linearity in the model by enforcing that the linear mixture of input images corresponds to the linear mixture of their outputs. This concept was later extended to manifold mixup [32], which better aligns with the underlying data manifold. In our approach, we assume that both the student and teacher models have access to an expressive LDM. This allows us to leverage the LDM to perform mixup operations in the latent space, effectively implementing manifold mixup, to further augment the student's limited set of samples. Let \\(\\tilde{z^k}\\) represent the latent code of an upsampled patch in the training data belonging to class \\(k\\). To augment this patch, we randomly sample another data point \\(z^k_j\\) from the same class and perform linear interpolation in the latent space with a mixing parameter \\(\\gamma\\), defined as \\(\\hat{z}_{interp}^k = \\gamma\\tilde{z^k} + (1 - \\gamma)z^k_j\\). The interpolated latent code is then used for augmentation via the LDM. Figure 3 presents qualitative results of the augmented samples generated using mixup. In our ablation study, we highlight the performance improvements achieved by mixing latent codes."}, {"title": "3.4. Putting it all together", "content": "For each IPC, we extract \\(r^2\\) low-resolution patches from our coreset selection. For each patch, we generate \\(m\\) high-quality augmentations using the diffusion model and pass them through the teacher model to obtain soft labels, resulting in a total of \\(m \\times r^2\\) soft labels. In all our experiments, we set \\(m\\) equal to the number of training epochs for the student. Notably, regenerating the high-quality augmentations requires only a single random seed. Lastly, we emphasize that the storage overhead for soft labels is present in many of the recent methods that combine knowledge distillation and dataset distillation, such as RDED [28], SRe2L [36], and G-VBSM [24]."}, {"title": "4. Experiments", "content": "We evaluated our method against both knowledge-distillation-based and bilevel-optimization-based approaches across several high-resolution benchmarks:\n1. Tiny-ImageNet [18]: This dataset includes 200 classes of 64 \u00d7 64 images derived from the original ImageNet-1k dataset. For our experiments, we selected patches at a resolution of 32 x 32.\n2. ImageWoof and ImageNette [13]: These datasets are 10-class subsets of ImageNet-1k, with an original resolution of 224 \u00d7 224. ImageWoof focuses on different dog breeds, while Imagenette covers a broad array of categories spanning animals and objects. To ensure comparability with RDED, we used a patch size of 112 \u00d7 112.\n3. ImageNet-1k [5]: A comprehensive dataset containing 1000 classes of 224 \u00d7 224 images representing a diverse set of categories. Consistent with [28], we employed patches of 112 \u00d7 112.\nWhile our method demonstrates its core strength on high-resolution benchmarks that benefit from super-resolution capabilities, we also benchmarked on CIFAR-10 and CIFAR-100 [16] to address the challenges bilevel methods face with high-resolution images and widely used ResNet architectures. For these datasets, we used 16 \u00d7 16 patches.\nThe following baseline methods, including both bilevel-optimization-based and knowledge-distillation-based approaches, were used for evaluation:\n1. RDED [28]: The first method that synthesizes collages of important patches, selected based on the teacher model's cross-entropy loss.\n2. SRe2L [36]: Leverages batch norm statistics of the teacher model to perform model inversion, facilitating the synthesis of diverse samples.\n3. G-VBSM [24]: Extending [36], this approach leverages rich statistical information from batch norm layers of multiple pretrained teachers to synthesize data.\n4. MTT [1]: The first approach to define the objective of outer-level optimization by matching the training trajectory of the student model to the expert's.\n5. IDM [42]: Proposes efficient data distillation through distribution matching between synthetic and real data.\n6. Tesla [4]: Simplifies gradient calculations for trajectory-matching-based methods, enhancing the computational efficiency of [1].\n7. DATM [9]: This work improves the trajectory matching methods and aligns the complexity of generated patterns to the dataset's size.\nImplementation Details: We conducted all experiments using the float16 variant of the SDXL-Turbo diffusion model, while setting num_inference_steps=5. For most experiments, we employed the AdamW optimizer with a learning rate of 0.001 and a weight decay of 0.01, training for 300 epochs. Detailed descriptions of each experimental setup and the corresponding hyperparameters are provided in the supplementary material."}, {"title": "4.1. Effect of Patch Size", "content": "RDED [28] proposes compressing visual information by utilizing patches smaller than the original image dimensions. To explore the performance dynamics associated with varying patch sizes under a fixed memory budget, we conducted a study where, limited to storing one 224 \u00d7 224 image per class, we evaluated performance as patch sizes decreased"}, {"title": "4.2. Effect of Super-resolution and Augmentation", "content": "By denoising the latent code of a patch after adding partial noise, both content variation and super-resolution are achieved in the recovered image. In this study, we aim to disentangle these two operations to analyze their individual impact on accuracy. To simulate super-resolution with minimal augmentation, we set the ratio \\(\\rho = \\rho_{as} = 0.4\\), which we qualitatively observe to achieve super-resolution while"}, {"title": "4.3. Cross-architectural Analysis", "content": "Bilevel-optimization-based methods often struggle with poor cross-architectural transferability, meaning the performance of a student model significantly degrades when its architecture differs from that of the expert model used for dataset distillation. To address this, GLaD [2] leverages the prior of a generative model to synthesize more realistic samples."}, {"title": "5. Conclusion", "content": "Recent advancements in dataset distillation have underscored the significance of realistic and diverse data representations. Some approaches emphasize the value of realism for generalizability, while others explore the capabilities of generative models to enhance the diversity and quality of distilled datasets. Building on these insights, our proposed method leverages modern Latent Diffusion Models (LDMs) to address both realism and diversity. By combining coreset selection with generative augmentations, we achieve significant improvements in dataset distillation benchmarks, demonstrating state-of-the-art performance across various datasets."}]}