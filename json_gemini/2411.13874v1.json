{"title": "Next-Generation Phishing: How LLM Agents Empower Cyber Attackers", "authors": ["Khalifa Afane", "Wenqi Wei", "Ying Mao", "Junaid Farooq", "Juntao Chen"], "abstract": "The escalating threat of phishing emails has become increasingly sophisticated with the rise of Large Language Models (LLMs). As attackers exploit LLMs to craft more convincing and evasive phishing emails, it is crucial to assess the resilience of current phishing defenses. In this study we conduct a comprehensive evaluation of traditional phishing detectors, such as Gmail Spam Filter, Apache SpamAssassin, and Proofpoint, as well as machine learning models like SVM, Logistic Regression, and Naive Bayes, in identifying both traditional and LLM-rephrased phishing emails. We also explore the emerging role of LLMs as phishing detection tools, a method already adopted by companies like NTT Security Holdings and JPMorgan Chase. Our results reveal notable declines in detection accuracy for rephrased emails across all detectors, highlighting critical weaknesses in current phishing defenses. As the threat landscape evolves, our findings underscore the need for stronger security controls and regulatory oversight on LLM-generated content to prevent its misuse in creating advanced phishing attacks. This study contributes to the development of more effective Cyber Threat Intelligence (CTI) by leveraging LLMs to generate diverse phishing variants that can be used for data augmentation, harnessing the power of LLMs to enhance phishing detection, and paving the way for more robust and adaptable threat detection systems.", "sections": [{"title": "I. INTRODUCTION", "content": "Phishing emails remain a prevalent and persistent threat in cybersecurity, often exploiting human psychology to deceive recipients into revealing sensitive information [1], [2], [3]. Which directly led to large organizations averaging a loss of $15 million in 2023 [4]. Traditional phishing detectors have achieved high precision and recall by recognizing specific linguistic cues, effectively mitigating many phishing attempts. However, the rapid advancement of Large Language Models (LLMs) has introduced new complexities into this landscape. These sophisticated models has already outperformed domain experts on cybersecurity benchmarks like CyberMetric [5], making them useful for crafting more nuanced and convincing phishing emails, rendering classical phishing datasets and detection methods increasingly less effective. As a result, LLM-generated phishing emails pose a significant new threat that needs to be urgently addressed. This challenge has been further exacerbated by advancements in prompt engineering techniques, such as zero-shot and few-shot prompting, which are effective for new tasks without requiring training data, enabling attackers to generate highly targeted and contextually accurate emails with minimum effort [6], [7].\nPrior to the rise of LLMs significant research had already enhanced phishing detection methods. For instance, Fette et al. [8] introduced a machine learning approach focusing on features designed to detect deception, successfully identifying over 99.5% of phishing emails with a very low false positive rate. Ma et al. [9] expanded on this by using hybrid features, combining content-based keywords and phrases with attributes like forms, and mismatched URLs, to build robust classifiers. Similarly, Verma et al. [10] explored natural language pro- cessing techniques, highlighting the effectiveness of semantic analysis in identifying phishing attempts. Other techniques have also proven to be very effective, achieving a near-perfect accuracy [11], [12].\nThe dual-use nature of LLMs makes them particularly relevant in this context, as they are highly effective in generating both beneficial and malicious content. Wu et al. [13] and Yao et al. [14] highlight security concerns posed by LLMs, noting their ability to craft sophisticated phishing emails that evade traditional detection methods. Additionally, LLMs have been shown to generate personalized phishing messages at scale, realistically and cost-effectively [15]. LLMs such as Llama [16], Gemini [17], Claude [18], and GPT [19] models demonstrate remarkable proficiency in generating human-like text, increasingly applied to tasks like phishing detection [20], [21]. Building on prior research, this study underscores the dual nature of these models: they can craft sophisticated phishing emails while also enhancing Cyber Threat Intelligence (CTI) by improving phishing detectors through augmented data training.\nThe rest of the paper is organized as follows: Section II reviews related works on phishing detection and the challenges posed by LLM-generated phishing emails. Section III presents the methodology, including the datasets used, experimental setup, and rephrasing techniques. Section IV discusses the experimental results, highlighting the performance of phishing detectors and machine learning models. Section V provides a discussion of the findings, outlines limitations, and suggests future research directions. Finally, Section VI concludes the paper with a summary of key insights and contributions."}, {"title": "II. RELATED WORKS", "content": "Phishing email detection has traditionally relied on non- LLM-based methods, such as Google's built-in Gmail spam filter, other prominent tools like SpamAssassin [22] and Proof- point have also proven to be highly effective detectors [23]. However, the integration of LLM-based phishing detection is an emerging phenomenon [25], with companies like JPMorgan Chase leading the charge [24], and NTT Holdings introducing their framework ChatSpamDetector [21].\nHowever, as phishing detection improves, LLMs are being harnessed to escalate the sophistication of phishing attacks, posing new challenges. Hazell [15]. for example, explored the potential of LLMs to scale spear-phishing campaigns by generating personalized emails for over 600 British Members of Parliament using GPT-3.5 and GPT-4 models. The find- ings show that these models can create realistic and cost- effective spear-phishing emails, with each email costing only a fraction of a cent. Similarly, Heiding et al. [20] investigated the use of LLMs combined with V-Triad in email phishing generation and found that models like GPT-4 when pared with human knowledge are capable of generating highly convincing phishing emails that can evade traditional detection methods. Kang et al. [26] further explored the use of LLMs in various malicious tasks, concluding that these models are capable of generating well-designed content that can be exploited for phishing and other scams.\nIn contrast to previous studies, our work comprehensively evaluates the detection capabilities of state-of-the-art phishing detectors, including Google's Gmail Spam Filter, SpamAs- sassin, and Proofpoint, as well as LLMs, on both original and LLM-rephrased phishing emails as illustrated in Fig. 1. Our approach employs various machine learning techniques, which represents the workflow of our evaluation methodology. Specifically, Fig. 1 highlights the differences in detection effectiveness between traditional phishing emails and LLM- rephrased emails, demonstrating the challenges faced by cur- rent phishing detectors in handling AI-generated threats. Roy et al. [27] tackled the issue of LLM-generated phishing attacks from a prompt engineering perspective, exploring the crafting of malicious prompts and utilizing LLMs to design these prompts. While their approach can mitigate the risk of LLM- generated phishing attacks, we believe that a more effective approach is to train models to detect these threats via better training data. Our approach complements the work of Roy et al. by focusing on improving the detection capabilities of phishing detectors, rather than solely relying on prompt engineering and detection. We focus on the Nazario and Nigerian Fraud datasets [28] and utilize GPT-40 and Llama 3 to rephrase phishing emails. We summarize the contributions of this paper as follows:\n1) We conduct a comprehensive comparison between tra- ditional phishing emails and those rephrased by LLMs. This comparison evaluates the performance of various phishing detection tools, such as Google's Gmail Spam Filter, SpamAssassin, Proofpoint, and other machine learning models, as well as LLMs such as Llama, Gemini, Claude, and GPT as phishing detectors .\n2) We introduce a framework for effective data augmenta- tion to create phishing email datasets that better reflect modern threats. Using GPT-4 and Llama 3, we rephrase and augment phishing emails from the Nazario dataset to create the LLM-Nazario dataset, which includes both original and rephrased emails as well as newly generated phishing attacks. The effectiveness of this approach is demonstrated by training three machine learning models on the new dataset to assess their improved ability to detect advanced threats like LLM-rephrased phishing emails."}, {"title": "III. METHODS", "content": "We utilized two primary datasets for our experiments: the Nazario and Nigerian Fraud phishing email datasets [28]. The Nazario dataset originally contained 2904 instances after cleaning, but for our experiments, we sampled 1200 emails evenly divided between the two classes: 600 legitimate emails and 600 phishing emails. The legitimate emails were origi- nally sourced from benign online discussions and newsletters, while the phishing emails followed the traditional format of including deceptive requests and fake links. The emails varied in length, ranging from 10 to 350 characters."}, {"title": "B. Experimental Setup", "content": "Our experimental setup involved testing three traditional phishing detection systems; Google's Gmail Spam Filter, Spa- mAssassin, and Proofpoint, three machine learning models; SVM, Logistic Regression, and Naive Bayes, and five promi- nent LLMs; Llama 3, Gemini 1.5, Claude 3 Sonnet, GPT-3.5, and GPT-40.\nFor the Gmail Spam Filter, we used different email accounts to simulate the user environment. Phishing and legitimate emails were sent to these accounts, and we recorded whether each email was automatically moved to the spam folder or shown in the user's inbox. This binary decision served as Gmail's detection metric across three categories of emails: original phishing emails, zero-shot rephrased emails, and few- shot rephrased emails.\nApache SpamAssassin applies a variety of content-based and statistical techniques to assess emails for potential phish- ing or spam. In our setup, we tracked whether each email was flagged as spam based on its evaluation criteria. Proofpoint, utilizing advanced email security technologies, was used to classify emails across the same categories, we recorded the emails that were shown to the receiver and the the emails that were put into the different \"Quarantine\" folders.\nFor the three machine learning models, we applied three text encoding techniques: Bag of Words [29], Term Frequency- Inverse Document Frequency (TF-IDF) [30], and Word2Vec [31], these models were trained on other subsets of the datasets used in the study. On average, TF-IDF encoding was 2.6% more accurate than Bag of Words and 5.4% more accurate than Word2Vec in detecting phishing emails. These encoding methods convert email text into numerical representations suitable for classification. Therefore, the results shown in Table I and Table III for the 3 machine learning models were obtained using TF-IDF encoding. The same encoding technique was also applied when testing the three models on rephrased emails after data augmentation.\nEach of the five LLMs was tested on the same three categories of emails: (1) original phishing emails, (2) emails rephrased using GPT-40 with zero-shot prompting, and (3) emails rephrased using GPT-40 with few-shot prompting. For"}, {"title": "C. Rephrasing Techniques", "content": "The two techniques, zero-shot prompting and few-shot prompting, were chosen due to their proven effectiveness in prior studies, particularly for new tasks that lack extensive training data, which aligns with our requirements [6].\n1) Zero-Shot Prompting: Zero-shot prompting involves providing the LLM with a task description without any ex- amples, relying solely on the model's pre-trained knowledge. This method leverages the LLM's ability to generalize from the provided instructions and apply its extensive pre-trained knowledge to novel tasks. Prior studies have demonstrated the effectiveness of zero-shot prompting, particularly for new tasks that lack extensive training data [6], [32], [33]. This approach is simple and efficient, allowing models to perform well without the need for task-specific fine-tuning [35]. \u03a4\u03bf bypass the security layers of some LLMs, it is effective to provide a clear context in the prompt. For example, adding an explanation that the task is for research purposes often helps achieve the desired response. Below is our chosen prompt for zero-shot prompting, with many variations of this prompt yielding similar results. It is important to note that we allow the LLM to only change the subject and body features of the emails. While using a better or more professional sender domain could be more effective, it is not considered realistic in our estimation.\n2) Few-Shot Prompting: Few-shot prompting includes a few examples along with the task description to help the model understand the task better and produce more accurate and contextually relevant outputs. Few-shot prompting does not necessarily produce better results compared to zero-shot prompting. Their performance depends on the specific task and context [36], [37]. For each dataset, we give the model a task description similar to what we had in zero-shot prompting with 3 examples (3-shot) of original phishing emails along with the desired output crafted carefully to bypass phishing detectors. Below is an example of an original phishing email from the Nazario dataset that's used in the few-shot prompting along with the desired output that's also given to the model."}, {"title": "D. Evaluation Metrics", "content": "The performance of phishing detectors was evaluated using the following metrics:\n\u2022 True Positive (TP): Correctly identified phishing emails.\n\u2022 True Negative (TN): Correctly identified legitimate emails.\n\u2022 False Positive (FP): Legitimate emails incorrectly classi- fied as phishing.\n\u2022 False Negative (FN): Phishing emails incorrectly classi- fied as legitimate.\n\u2022 Accuracy: (TP + TN)/(TP + TN + FP + FN).\n\u2022 Precision: TP/(TP + FP).\n\u2022 Recall: TP/(TP+FN), also referred to as the detection rate.\n\u2022 F1 Score:\n$$F1 = 2 x \\frac{Precision \\times Recall}{Precision + Recall}$$\nFor example, an FP rate of 0.2 means 20% of legitimate emails are incorrectly flagged, while an FN rate of 0.15 means 15% of phishing emails are missed. These metrics are crucial for evaluating the reliability of phishing detection systems, with the false negative rate being particularly important as it indicates the proportion of phishing threats that go undetected and potentially cause harm."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "The results of the experiments demonstrate a significant shift in the decision boundary when comparing traditional phishing emails to those rephrased using LLMs. By analyzing a sample of 200 emails composed from the different datasets used in this study, we observed that traditional phishing emails exhibited clearer decision boundaries. These boundaries were largely driven by the occurrence of certain keywords such as \"royal family\u201d \u201curgent\u201d, and \u201clarge payment,\" which are flagged as highly suspicious by phishing detectors.\nIn contrast, the rephrased phishing emails, generated using LLMs, employed more legitimate-sounding language, such as \"credentials,\u201d \u201cmembership,\" \"confirmation,"}, {"title": "A. Nazario Dataset Experiments", "content": "The results from the Nazario dataset, summarized in Table I, highlight the performance of three phishing detectors-Google Gmail, SpamAssassin, and Proofpoint\u2014as well as three ma- chine learning models-Naive Bayes, SVM, and Logistic Regression. A total of 1200 emails (600 phishing and 600 legitimate) were used in the experiments."}, {"title": "B. Nigerian Fraud Dataset Experiments", "content": "The Nigerian Fraud dataset combines two previous datasets with similar content [28]. The final dataset consists of 800 emails (400 phishing and 400 legitimate) and poses a distinct challenge with its longer emails (10\u2013650 characters) that often involve financial scams and urgent language. This complexity is both a challenge and an advantage, depending on the phishing detector.\nFor original emails, Proofpoint outperformed other detectors with near-perfect recall (98.95%), but its performance dropped on rephrased emails. Zero-shot rephrasing reduced its recall to 93.16%, with a corresponding accuracy drop, reflecting the sophistication of rephrased phishing emails that bypass traditional spam heuristics. SpamAssassin and Gmail also saw similar drops, with Gmail's recall decreasing to 88.76% in the zero-shot scenario.\nMachine learning models such as Naive Bayes and SVM, which were trained on 1500 emails from the original datasets, showed a more notable decline in performance when faced with rephrased phishing emails. In particular, Naive Bayes' accuracy dropped to as low as 88%, and its recall decreased to 85% when processing few-shot rephrased emails. This demonstrates the limitations of these models when handling sophisticated phishing emails that are able to bypass tradi- tional keyword-based detection. The results indicate that, for a dataset like the Nigerian Fraud dataset, traditional phishing detectors may still maintain strong performance on original emails, but their effectiveness is significantly compromised when these emails are rephrased using advanced techniques.\nWhen rephrased using few-shot prompting, the effectiveness of the phishing attempts improved slightly. The overall accu- racy remained around the same range as zero-shot rephrased emails suggesting the few-shot rephrasing might not be very effective in certain contexts compared to simpler prompts. Table III provides a detailed breakdown of the performance of all phishing detectors, while Table IV summarizes the performance of the LLMs tested on this dataset with the primary focus here on the False Negative values (FN) as they represent the number of harmful emails that evaded detection."}, {"title": "C. Using LLMs for Rephrasing and Data Augmentation", "content": "The integration of LLMs for rephrasing phishing emails presents a significant opportunity to augment phishing datasets, leading to the development of more robust phishing detectors. Specifically, the use of rephrased emails generated"}, {"title": "V. DISCUSSION AND LIMITATIONS", "content": "The results from both the Nazario and Nigerian Fraud datasets provide clear evidence of the challenges posed by LLM-rephrased phishing emails. Traditional phishing detec- tors, such as Google Gmail Spam Detector, SpamAssassin, and Proofpoint, perform exceptionally well on original phishing emails but struggle with rephrased emails, in both zero-shot and few-shot rephrased scenarios. The accuracy and recall metrics drop across the board when these detectors are faced with more subtle phishing attempts generated by advanced LLMs.\nOur study underscores the need for more advanced detection mechanisms capable of handling these evolving threats. LLMs, with their ability to generate highly realistic phishing emails, represent a new frontier in phishing attacks. However, they also present an opportunity to improve the robustness of phishing detectors through data augmentation. By incorporating LLM- generated emails into the training process, we can expose phishing detectors to a wider range of linguistic variations, making them better equipped to handle sophisticated attacks. The proposed LLM-Nazario dataset is a step in this direction, providing a rich source of rephrased phishing emails that can be used to train and fine-tune phishing detectors. The use of LLM-augmented datasets demonstrated notable improvements in detection accuracy. This highlights the dual nature of LLMs in the phishing detection landscape: while they can be used to craft more sophisticated attacks, they also hold the potential to enhance the CTI against these attacks.\nThe primary limitation of this study is its exclusive focus on English-language datasets. Due to the current availability of large, high-quality datasets primarily in English, extending our research to other languages was challenging. Future work should address this gap by incorporating datasets from diverse languages to enhance the robustness of language models in email detection across different linguistic contexts. Another limitation is that we did not explore the effect of fine- tuning some of the small language models on the LLM- augmented datasets, which could provide valuable insights. Future research could focus on this aspect to determine how fine-tuning influences model performance and adaptability, potentially leading to even better detection results."}, {"title": "VI. CONCLUSION", "content": "This paper presents a comprehensive evaluation of both traditional and LLM-based phishing detectors, focusing on the challenges posed by LLM-rephrased phishing emails. Our findings show that while traditional phishing detectors like Gmail Spam Detector, SpamAssassin, Proofpoint, and State- of-the-Art LLMs perform well on original phishing emails, their accuracy and recall decline notably when dealing with LLM-rephrased versions of the same emails.\nHowever, by leveraging LLMs for data augmentation, we have demonstrated that phishing detectors can be made more robust. Training models on LLM-augmented datasets signifi- cantl improves their detection rates. This approach provides a valuable strategy for developing more resilient phishing detectors that can adapt to the evolving tactics of cyber attackers. Future efforts should focus on continually advanc- ing phishing detection systems through innovative machine learning approaches and regularly updating training datasets to incorporate new phishing strategies."}]}