{"title": "FMDNN: A Fuzzy-guided Multi-granular Deep Neural Network for Histopathological Image Classification", "authors": ["Weiping Ding", "Tianyi Zhou", "Jiashuang Huang", "Shu Jiang", "Tao Hou", "Chin-Teng Lin"], "abstract": "Histopathological image classification constitutes a pivotal task in computer-aided diagnostics. The precise identification and categorization of histopathological images are of paramount significance for early disease detection and treatment. In the diagnostic process of pathologists, a multi-tiered approach is typically employed to assess abnormalities in cell regions at different magnifications. However, feature extraction is often performed at a single granularity, overlooking the multi-granular characteristics of cells. To address this issue, we propose the Fuzzy-guided Multi-granularity Deep Neural Network (FMDNN). Inspired by the multi-granular diagnostic approach of pathologists, we perform feature extraction on cell structures at coarse, medium, and fine granularity, enabling the model to fully harness the information in histopathological images. We incorporate the theory of fuzzy logic to address the challenge of redundant key information arising during multi-granular feature extraction. Cell features are described from different perspectives using multiple fuzzy membership functions, which are fused to create universal fuzzy features. A fuzzy-guided cross-attention module guides universal fuzzy features toward multi-granular features. We propagate these features through an encoder to all patch tokens, aiming to achieve enhanced classification accuracy and robustness. In experiments on multiple public datasets, our model exhibits a significant improvement in accuracy over commonly used classification methods for histopathological image classification and shows commendable interpretability.", "sections": [{"title": "I. INTRODUCTION", "content": "Histopathological images are of crucial significance in medical diagnosis and are essential for disease staging and treatment strategizing. The use of deep learning models for histopathological image classification tasks is a growing trend. Yang et al. [1] realized a threshold-based tumor prioritization aggregation method for label inference within whole slide images and introduced a deep learning-based classifier tailored for lung lesion categorization, substantially advancing the identification of distinct lung cancer subtypes. Wang et al. [2] used a fully convolutional neural network architecture in the extraction of pertinent deep features, to enable accurate predictions in lung cancer tissue histopathological image classification. Hence, deep neural networks have substantially improved the precision and efficiency of pathological diagnosis, thereby facilitating early intervention and treatment.\nHistopathological images commonly encompass a variety of morphological features, including cell size, shape, and color, as well as the size and shape of cell nuclei and the distribution of chromatin. These features exhibit alterations indicative of pathological changes in cells or tissues, underscoring the significance of accurate feature extraction. Widely used approaches for feature extraction include Convolutional Neural Networks (CNNs) and Attention Mechanisms [3]. The CNN operates by sliding convolutional kernels over an image, performing nonlinear transformations on the covered regions and extracting features at various hierarchical levels. Wahab et al. [4] devised a Hybrid-CNN model by integrating two-stage CNNs through weight transfer and custom layers, which accomplished the accurate classification of mitotic and non-mitotic cells. Attention mechanisms have been extensively utilized in histopathological image classification tasks. Differing from CNNs, attention mechanisms capture global dependencies by focusing on all elements of the input sequence, employing weighted aggregations of these features to construct higher-level representations. Sadafi et al. [5] applied an attention mechanism to the classification of hereditary blood disorders, showcasing its efficacy in enhancing a model's focus on pathological cell samples and increasing classification accuracy. Valanarasu et al. [6] introduced a gated axial-attention model, incorporating additional control mechanisms within the self-attention module. The model's global branch captures long-range dependencies to learn contextual features across the entire image, while the local branch refines finer features through patch-level operations, yielding notable results in medical image analysis.\nThe above methods neglect the features of histopathological images at diverse granularity levels, limiting feature extraction to a singular scale, which leads to the incomplete capture of intrinsic feature information among cells. To address this, Li et al. [7] demonstrated the efficacy of embedding features of varying granularities during the extraction process, effectively mitigating the challenges of limited inter-class variance and substantial intra-class variance in pathological image analysis and leading to reduced sensitivity to image magnification. Similarly, Hashimoto et al. [8] found through experiments that distinct class-specific features exist across various scales, achieving superior accuracy in tumor subtype classification, surpassing the performance of expert pathologists. We can conclude from the above findings that to employ multi-granularity theory in histopathological image classification tasks can enable the extraction of medical pathological features at diverse granularity levels, leading to significant improvement in classification accuracy.\nThe fusion of multi-granular features may encounter information redundancy. Sinha et al. [9] employed a multi-scale guided attention network in medical image analysis, leveraging additional losses between modules to disregard irrelevant information and accentuate relevant feature correlations, focusing on more discriminative regions. Xue et al. [10] proposed a deep neural network with a global guidance block. Utilizing multi-level integrated feature maps as guiding information, they employed spatial and channel domain distant non-local dependencies. Their approach outperformed other medical image techniques, particularly in breast ultrasound lesion detection.\nWe incorporate the theory of fuzzy sets to guide the operation, where membership functions characterize the degree of membership of elements, which allows for the expression of the uncertainty and ambiguity of pixels in medical images [11]. To capture the overlapping regions and indistinct boundaries in images and to mitigate potential disturbances caused by noise, artifacts, and lighting variations, membership functions allow each pixel to flexibly express its membership degree to different tissues and structures. Ding et al. [12] used Interval Type-2 Fuzzy Clustering and metaheuristics to enhance the objective function of conventional fuzzy c-means clustering, incorporating spatial information based on neighboring local windows of superpixels, achieving effective segmentation of radiographic images. Ahmed et al. [13] combined the Mamdani fuzzy model with adaptive neuro-fuzzy inference systems in a chronic kidney disease diagnostic system. It can be seen that the adoption of fuzzy set theory in medical imaging offers substantial support for clinical diagnosis and treatment [14].\nWe propose FMDNN, which is depicted in Fig. 1. When conducting feature extraction on histopathological images, we consider the medical structural properties of cells and individually extract tissue features at coarse, medium, and fine granularities. A fuzzy-guided cross-attention module incorporates universal fuzzy features into patch tokens, thus guiding features from different granularity. The main contributions of this paper are as follows:\n1) We introduce a multi-granular feature extraction method and employ feature visualization to investigate the semantic scales of features at different granularities, which contributes to a more comprehensive interpretation of information embedded in histopathological images;\n2) We use fuzzy logic to amalgamate key features from images through the computation of universal fuzzy features using three membership functions, which are utilized to globally guide the learning of multi-granular features. Experiments demonstrate the effectiveness of this approach in enhancing classification accuracy during model-guided training while minimizing interference from unrelated features;\n3) To address information redundancy in multi-granular feature extraction, we employ a fuzzy-guided approach to enhance the importance of key features. Continuously guiding features at three granularities with universal fuzzy features reduces interference from irrelevant information, significantly improving classification performance.\nThe remainder of this article is structured as follows. Section II presents an overview of relevant methods and the utilization of fuzzy logic in classification. Section III introduces the three modules of our model. Sections IV and V describe comparative experiments and ablation studies that validate the effectiveness of the proposed model. In section VI, we summarize our work and propose future research directions."}, {"title": "II. RELATED WORK", "content": "CNNs and attention mechanisms have shown notable success in image classification. Current methods can be broadly classified as based on (1) multiple feature inputs; (2) attention mechanisms; or (3) other functional modules.\nAmong methods based on multiple input features [15], Wang et al. [16] proposed a pyramid vision Transformer model that can generate feature pyramids akin to CNNs, thus achieving multiscale feature integration. Gradually reducing image spatial resolution, Zheng et al. [17] employed a Transformer framework to serially process images, thereby realizing a pure self-attention feature representation encoder. Tang et al. [18] introduced adaptive convolution with a globally complementary context for multiscale design, allowing for the comprehensive acquisition of multimodal information from various scales.\nAmong methods using diverse attention mechanisms, Yuan et al. [19] used an attention mechanism, Vision Outlooker, effectively encoding fine-grained features into Vision Transformer (ViT) token representations, thereby enhancing classification performance. Chu et al. [20] introduced the Twins model, featuring spatially separable self-attention, which optimizes and accelerates the computational process of deep learning models primarily through matrix multiplication.\nAmong methods reliant on other functional modules, Touvron et al. [21] introduced a teacher-student distillation training strategy tailored for ViT, which incorporated token-based distillation, enabling state-of-the-art (SOTA) results using ImageNet without external data. Chen et al. [22] used memory-driven Transformers to generate medical reports, with memory-driven modules to capture essential generated information.\nProposed by Zadeh in 1965, Fuzzy Set Theory addresses problems involving uncertainty and fuzziness [23] and can model and represent image features. Unlike traditional Boolean logic, an element can belong to multiple sets, with an assigned membership degree between 0 and 1. The membership degree of element x in fuzzy set A can be expressed as \\( \\mu_A(x) \\in [0, 1] \\). The flexibility of fuzzy logic is well suited to problems with fuzziness and uncertainty.\nThe combination of fuzzy sets with images is typically achieved through either: (1) fuzzy algorithms primarily based on machine learning; or (2) fuzzy feature processing predominantly based on deep neural networks. Wan et al. [24] introduced the sparse fuzzy two-dimensional discriminant local preserving projection algorithm to mitigate the impact of variations, overlaps, and sparse points in images. Bhalla et al. [25] proposed a hybrid fuzzy CNN approach, using fuzzy sets to eliminate uncertainty in images.\nThe complexity of configuring fuzzy membership functions requires task-specific adjustments, which significantly impacts model performance. The application of fuzzy set theory in the medical image domain is the subject of ongoing research [26].\nFuzzy logic is more adaptable in processing medical images [27], which often contain structures and pathological changes with fuzzy boundaries. Ding et al. [28] introduced FTransCNN, a composite model with a fuzzy fusion module that amalgamates features extracted from CNN and Transformer architectures. Hu et al. [29] addressed challenges in brain imaging, such as varying noise levels, indistinct boundaries, and artifacts, by combining improved fuzzy clustering with the HPU-Net model for brain image processing and disease diagnosis prediction.\nFuzzy set methods have also been used in the fusion of multimodal medical images [30]. By defining multiple membership functions and fuzzy rules, they integrate information from various modalities, thereby enhancing the accuracy of classification and diagnosis. Wang et al. [31] fused multiple CNNs and fuzzy neural network Gabor representation, filtering CT and MR image sets to realize distinct feature representations. Fuzzy set methods have been applied to medical image classification and diagnosis tasks. Das et al. [32] introduced a feature-driven linguistic fuzzy neural model for disease classification analysis in medical data, leveraging linguistic fuzzification to generate membership values to handle uncertainty and integrating feature extraction algorithms within the fuzzy neural architecture to extract crucial features in medical data analysis.\nDespite successes in medical image classification, several issues in histopathological images have been overlooked. Specifically, there is a lack of effective utilization of multi-granularity, as well as a lack of appropriate methods for guiding the learning of multi-granular features. A multi-granular feature extraction module is introduced that facilitates the extraction of key features across diverse granularity levels. We use fuzzy logic to compute and integrate universal features from the image. Fuzzy-guided cross-attention is introduced for feature fusion. Throughout the training process, universal fuzzy features continuously guide multi-granular features, overcoming information redundancy in multi-granularity learning. The model can acquire more effective classification features."}, {"title": "III. PROPOSED METHOD", "content": "As shown in Fig. 1, FMDNN conducts feature extraction on the input image at three distinct granularities, whose features are concatenated with the universal fuzzy feature and fed into the corresponding encoder, yielding classification tokens for each granularity. The final classification results are derived through linear transformation for feature fusion and dimension alignment."}, {"title": "A. Multi-granular Feature Extraction Module", "content": "Relying solely on singular features has proven inadequate in feature extraction from medical images [33]\u2013[35]. Given the unique characteristics of histopathological images, pathologists typically employ multi-granularity when classifying them. This involves observing the overall tissue morphology at low magnification to identify obvious abnormal regions. At medium magnification, attention shifts to cell arrangement, nucleus morphology, and cell relationships. High magnification is then used to examine features such as nuclear characteristics, intracellular organelles, and clarity of cell boundaries. Integrating observations across multiple microscopic levels provides a more comprehensive understanding of lesion nature and severity [36].\nInspired by the multiscale diagnostic approach employed in histopathological image classification, we incorporate CNN-based multi-granular feature extraction to extract features separately on fine-grained \\(X_{\\text{Fine}} \\in \\mathbb{R}^{H \\times W \\times C_{\\text{Fine}}}\\), medium-grained \\(X_{\\text{Medium}} \\in \\mathbb{R}^{H \\times W \\times C_{\\text{Medium}}}\\), and coarse-grained \\(X_{\\text{Coarse}} \\in \\mathbb{R}^{H \\times W \\times C_{\\text{Coarse}}}\\) levels. As illustrated in Fig. 2, an encoder-decoder structure is employed, and multiple layers of convolution and pooling are used to extract image features and reduce granularity. In the decoder, deconvolution and upsampling are used while extracting the desired granularity of features. The design ensures that the dimensions of the three granularity blocks remain the same during block embedding, reducing fusion costs and accelerating computation. As demonstrated by Kaul et al. [37], skip connections within a network facilitate the smooth propagation of gradients across the entire network, effectively preserving feature maps, particularly in capturing intricate details within fine-grained levels. The final representation of the features is \\(X = (X_{\\text{Fine}}, X_{\\text{Medium}}, X_{\\text{Coarse}})\\), where \\(X_{\\text{Fine}}\\), \\(X_{\\text{Medium}}\\), and \\(X_{\\text{Coarse}}\\), respectively, represent fine-, medium-, and coarse-grained features.\nMulti-granular features \\(X_{\\text{Fine}}\\), \\(X_{\\text{Medium}}\\), and \\(X_{\\text{Coarse}}\\) are reshaped into flattened 2D feature blocks \\(X_{\\text{Fine}}^P \\in \\mathbb{R}^{N \\times ((\\frac{P}{2r})^2 \\cdot C_{\\text{Fine}})}\\), \\(X_{\\text{Medium}}^P \\in \\mathbb{R}^{N \\times ((\\frac{P}{r})^2 \\cdot C'_{\\text{Medium}})}\\), and \\(X_{\\text{Coarse}}^P \\in \\mathbb{R}^{N \\times ((\\frac{P}{2})^2 \\cdot C_{\\text{Coarse}})}\\), respectively. Here, \\((H, W)\\) represents the original resolution of the features, \\(C\\) is the number of channels, \\((P, P)\\) is the resolution of each feature block, and \\(N\\) is the number of generated feature blocks, which is also the effective input sequence length for fusion with fuzzy features. Our design ensures that the dimension of \\(N\\) matches across granularities, significantly reducing computational complexity during fusion with fuzzy features. Similar to the [class] token in ViT, we add learnable embeddings to each embedded feature block sequence, and the final output can be represented as:\n\\begin{align} z_F^0 &= [x_{\\text{class}}^F; x_1^F E^F; x_2^F E^F; \\dots; x_N^F E^F] + E_{\\text{pos}}, \\label{eq:1} \\\\ z_M^0 &= [x_{\\text{class}}^M; x_1^M E^M; x_2^M E^M; \\dots; x_N^M E^M] + E_{\\text{pos}}, \\label{eq:2} \\\\ z_C^0 &= [x_{\\text{class}}^C; x_1^C E^C; x_2^C E^C; \\dots; x_N^C E^C] + E_{\\text{pos}}, \\label{eq:3} \\end{align}\nwhere variables \\(E_{\\text{pos}} \\in \\mathbb{R}^{(N+1)\\times D}\\), \\(E_{\\text{pos}} \\in \\mathbb{R}^{(N+1)\\times D}\\), and \\(E_{\\text{pos}} \\in \\mathbb{R}^{(N+1)\\times D}\\) are introduced, and \\(E^F \\in \\mathbb{R}^{((\\frac{P}{2r})^2 \\cdot C_F)\\times D}\\), \\(E^M \\in \\mathbb{R}^{((\\frac{P}{r})^2 \\cdot C_M)\\times D}\\), and \\(E^C \\in \\mathbb{R}^{((\\frac{P}{2})^2 \\cdot C_C)\\times D}\\). Similar to ViT, our model adopts the position embedding strategy when dealing with image data, embedding position information in each feature block to retain the accurate position of each pixel."}, {"title": "B. Universal Fuzzy Feature Module", "content": "We adopt fuzzy set theory to address information redundancy in multi-granular feature extraction, treating image pixels as elements and describing their membership to fuzzy concepts by membership functions. This approach can capture uncertainty and fuzziness in images. By setting different membership functions and thresholds, it is possible to accurately extract common features of malignant cells, thus providing more precise information for image classification.\nIn the Universal Fuzzy Feature Algorithm, an image \\(I\\) is converted to grayscale and normalized to the range [0,1]. When extracting the fuzzy features of the image, each pixel \\(I_x\\) is considered a fuzzy set, and different membership functions are applied to each image. We extract three fuzzy features. The obtained fuzzy universal feature set is \\({\\text{I}\\_{\\mu}, \\text{I}\\_{\\sigma}, \\text{I}\\_T}\\), whose definition depends on the membership functions, which describe the degree to which each pixel belongs to a certain fuzzy concept.\nThe universal fuzzy feature \\(z_{\\text{Fuzzy}}\\) is obtained through fuzzy operations. During the model learning process, the membership functions can help it to better understand the meaning of each pixel, including its potential membership categories and degrees.\nTo extract multiple features from the image, we select multiple membership functions, each corresponding to a specific feature representation method. We choose Gaussian, Sigmoid, and Trapezoidal functions, enabling more effective guidance of the model in learning key features through the universal fuzzy features, which are used to construct fuzzy sets. Through fuzzy set intersection operations, we extract the universal features of the image. The first membership function is defined using the Gaussian function, calculating the membership degree of each pixel by applying the Gaussian function to its grayscale value,\n\\begin{equation} \\mu_G = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp \\left( - \\frac{(x - \\mu)^2}{2\\sigma^2} \\right), \\label{eq:4} \\end{equation}\nwhere \\(\\mu\\) is the mean, \\(\\sigma\\) is the standard deviation, \\(x\\) is the grayscale value of the pixel, and \\(\\mu_G\\) is its membership degree. Next, we define the Sigmoid membership function:\n\\begin{equation} \\sigma_\\alpha = \\frac{1}{1 + \\exp(-a(I\\_x - \\beta))}, \\label{eq:5} \\end{equation}\nwhere \\(I_x\\) is the brightness value of pixel \\(x_i\\), and \\(a\\) and \\(\\beta\\) are parameters of the Sigmoid function, used to adjust its shape and position, respectively.\nFinally, we define the Trapezoidal membership function\n\\begin{equation} T(x; a, b, c, d) = \\begin{cases} 0, & x < a \\\\ \\frac{x - a}{b - a}, & a < x < b \\\\ 1, & b < x < c \\\\ \\frac{d - x}{d - c}, & c < x < d \\\\ 0, & x \\geq d, \\end{cases} \\label{eq:6} \\end{equation}\nwhere \\(a\\) and \\(b\\) are the respective left and right endpoints; and \\(c\\) and \\(d\\) are the ascending and descending inflection points, respectively. The function is controlled by ascending and descending slopes at its respective left and right ends, while the middle part has a membership degree of 1.\nWe use fuzzy set theory to effectively fuse features extracted from various membership functions, forming a more comprehensive and accurate universal feature for the image. We introduce a fuzzy weighting strategy to fuse uncertain data, aiming to integrate the three features for a more comprehensive feature description. We assign weights \\(\\omega\\_\\mu\\), \\(\\omega\\_\\sigma\\), and \\(\\omega\\_T\\) to fuzzy features \\(I\\_\\mu\\), \\(I\\_\\sigma\\), and \\(I\\_T\\), respectively, representing their importance in the overall description, and satisfying the condition \\(\\omega\\_\\mu + \\omega\\_\\sigma + \\omega\\_T = 1\\). We introduce a bias term \\(b\\) to adjust the baseline level of fuzzy feature fusion and enhance the model's flexibility.\nThe fused feature, i.e., the universal fuzzy feature obtained from the above variables and parameters, can be calculated as\n\\begin{equation} z_{\\text{Fuzzy}} = \\omega\\_\\mu \\times I\\_\\mu + \\omega\\_\\sigma \\times I\\_\\sigma + \\omega\\_T \\times I\\_T + b. \\label{eq:7} \\end{equation}\nIn the process of fuzzy fusion, the membership degree of each data point determines its contribution to the mean value. Through this method, we can extract rich fuzzy features that can be used in subsequent deep learning models."}, {"title": "C. Fuzzy-guided Cross-attention Module", "content": "Weighted averaging is commonly used in fusion approaches, where the fuzzy feature matrix \\(x_{\\text{Fuzzy}}\\) is normalized and directly added to a Transformer encoder or another fusion module [38]. However, this method assigns the same weight to all models. Using the fused output as input can enhance model expressiveness and generalization. However, in multi-granularity models, this approach may lead to information redundancy, or even the loss of critical features in certain granularities. Zhang et al. [39] introduced an Edge-Guided module for medical image datasets, which learns edge-aware representations and preserves local edge features at early encoding layers, with good results.\nWe propose fuzzy-guided cross-attention (FCA) for fusion, where universal fuzzy features, serving as the driving information, are deeply integrated with features of different granularities through cross-attention, rather than being fused using addition. As shown in Fig. 3(a), the key characteristic of this process is the ability to continuously drive pixel-level information using the universal fuzzy feature, preventing overfitting when continuously learning on three individual granularities. After interacting with the fuzzy patch tokens, the guiding information from the classifier is spread to the patch tokens through the Transformer encoder, continuously guiding the learning of multi-granular features. This is expressed as (8), where \\(l = 1, 2, ..., L\\).\n\\begin{equation} z^{\\prime l} = \\text{FCA} (LN(z\\_{\\text{Fuzzy}}), LN(z\\_{\\text{patch}}^{l-1})) + z\\_{\\text{patch}}^{l-1}, \\label{eq:8} \\end{equation}\nSpecifically, for different granularity branches \\(z_G\\), we have \\(z^{\\text{G}}\\_q = [f_l (z^{\\text{cls}}\\_G )||z\\_{\\text{Fuzzy}}]\\), where \\(G \\in (C, M, F)\\) represents the three granularities, \\(f_l(\\cdot)\\) is the projection function used for dimension alignment, and \\(LN(\\cdot)\\) is the layer normalization function. After using the guiding information for fusion, it will re-enter the next Transformer encoder and interact with its corresponding patch tokens:\n\\begin{align} z^{\\prime\\prime l} &= \\text{MLP} (LN(z^{\\prime l}) + z^{\\prime l}), l = 1, 2, ..., L, \\label{eq:9} \\\\ z^l &= \\text{Encoder}(z^{\\prime\\prime l}), l = 1, 2, . . ., L, \\label{eq:10} \\end{align}\nwhich promotes the propagation of guiding information and enriches the representation of each image patch, leading to improved overall model accuracy and robustness. Finally, by aggregating the representations processed through multiple Transformer encoders, we obtain the final classification results:\n\\begin{equation} y = LN(([z^F]\\_{\\text{cls}}, [z^M]\\_{\\text{cls}}, [z^C]\\_{\\text{cls}}) \\cdot W\\_d). \\label{eq:11} \\end{equation}\nIt is worth noting that we do not use traditional cross-attention, i.e., we do not simply change the sources of \\(Q\\), \\(K\\), and \\(V\\), which, as shown through experiments in Section IV, does not lead to significant improvements. Fig. 3(b) shows the algorithm, where fusion involves classification and patch tokens from multiple granularity branches, as well as fuzzy patch tokens. Similar to CrossViT [40], we use fuzzy patch tokens from the fuzzy features as guiding information to interact with multi-granularity patch tokens, enabling deep guidance.\nFCA is implemented as\n\\begin{align} Q = z\\_{\\text{Fuzzy}}W\\_q, K = z\\_G W\\_k, V = z\\_G W\\_v \\label{eq:12} \\\\ \\text{FCA}(Q, K, V) = \\text{softmax}\\left( \\frac{QK^T}{\\sqrt{C/h}} \\right) V, \\label{eq:13} \\end{align}\nwhere \\(W\\_q\\), \\(W\\_k\\), \\(W\\_v \\in \\mathbb{R}^{C\\times (\\frac{C}{h})}\\) are learnable parameters; and \\(C\\) and \\(h\\) are the embedding dimension and number of attention heads, respectively.\nIt has been demonstrated that the multi-granularity branches primarily serve the role of feature extraction, with the fuzzy feature branch contributing supplementary information [40]. Consequently, a lightweight fuzzy feature branch alone is sufficient to effectively guide the multi-granularity branches. We apply cross-attention to fuse multi-granular features, as the main information sources, with universal fuzzy features, which are treated as supplementary information. FMDNN achieves higher accuracy than other fusion methods."}, {"title": "D. Model framework", "content": "Algorithm 1 shows the implementation of the model. An initial step employs a multi-granularity convolution technique to extract features from the original image at various granular levels. Through the fusion of membership functions tailored to distinct feature points, universal fuzzy features of the original image are extracted. Extracted multi-granular features and universal fuzzy features are separately embedded with patches at different granularities, harmonizing dimensions and reducing subsequent algorithmic complexity.\nNext is the fuzzy-guided cross-attention module, which utilizes the universal fuzzy features to guide training at distinct granularities. By employing a multi-granularity classifier as an intermediary, features from different granularities and universal fuzzy features are integrated through fusion learning of feature information and are subsequently back-projected into their respective branches. Each training instance comprises a granularity-specific feature and a fuzzy feature. During each training iteration, the multi-granularity classification token interacts with a fuzzy patch token that serves as guiding information. Post-fusion, with this guiding information, the multi-granularity classification token engages once again with its corresponding patch token within the subsequent Transformer encoder, enabling the transfer of acquired guiding information to the associated patch token, enriching the representation of each image block."}, {"title": "IV. EXPERIMENTS", "content": "We evaluated the performance of FMDNN in medical image classification on five publicly available pathological image datasets. These include diverse tissue types, varying numbers of categories, and various granularity attributes. These are as follows:\n1) Lung and Colon Cancer Histopathological Images (LC)\n2) NCT-CRC-HE-100K (NCT)\n3) APTOS 2019 Blindness Detection (BI)\n4) HAM10000 (HAM)\n5) Kvasir (Kv)\nWithin the model, we configured different granularity blocks as 224 x 224 x 3, 112 x 112 x 12, and 56 x 56 x 48. We divided the dataset into training, validation, and testing sets in a 70:15:15 ratio. Data augmentation techniques such as random cropping, horizontal flipping, and rotation were employed to enhance the model's generalization capabilities. We utilized cross-entropy as the loss function and trained the model using stochastic gradient descent with a batch size of 64. The initial learning rate was set to 0.001, with a decay factor of 0.01.\nWe compared FMDNN against several classification models on different datasets:\n1) Resnet50 leverages residual connections to facilitate optimization and mitigates gradient vanishing. We utilized pretrained weights on the ImageNet dataset.\n2) We used the ViT-base model with pretrained weights from the ImageNet-21k dataset.\n3) With medical images, HiFuse adopts a three-branch hierarchical multi-scale feature fusion network structure, with the advantages of Transformer and CNN across multiple scale levels.\n4) MLP-Mixer uses an architecture based solely on multi-layer perceptrons.\n5) RSP+CR uses a semi-supervised learning framework incorporating knowledge distillation. It extracts context information at various resolutions within the multi-layer pyramid structure present in histopathological images."}, {"title": "V. DISCUSSION", "content": "We compared FMDNN with SOTA methods on various datasets, as shown in Table III.\nFMDNN surpasses all SOTA models on LC and outperforms the majority of models on NCT, with an ACC only 0.5% less than that of Srinidhi et al. It achieves a high F1-score of 98.1%. Both of these datasets exhibit significant multi-granularity attributes, and FMDNN shows favorable results on other datasets as well. FMDNN outperforms all SOTA models on Bl, with an ACC of 88.2%, which is significantly better than that of Kassani et al.'s model at 83.1%. It also performs close to SOTA models on HAM and Kv.\nFMDNN outperforms other classification algorithms on various datasets. However, its classification accuracy falls below expectations on HAM and Kv, mainly due to their unique characteristics, as they exhibit imbalanced numbers of samples across different categories, in which diseases share a high degree of visual similarity, posing a significant challenge to classification. In addition, the subtle nature of multi-granularity attributes in these datasets impacts the model's performance. However, FMDNN still achieves noteworthy results.\nWe conducted ablation experiments on FMDNN, using the LC and NCT datasets. We introduced specific modifications to the model, with experimental outcomes presented in Table IV and Fig. 5.\nTo verify the Multi-granularity Feature Extraction Module, we used a CNN without (w/o) multi-granularity, denoted as w/o MG, and eliminated coarse-, medium-, and fine-grained features, denoted as w/o C, w/o M, and w/o F, respectively.\nTo validate the Universal Fuzzy Feature Module, with all other conditions held constant, we replaced universal fuzzy features used as guiding information with features extracted by a standard CNN for model training, to compare the effectiveness of different guiding features.\nTo verify the fuzzy-guided cross-attention module, while keeping all other conditions constant, we replaced fuzzy-guided cross-attention with regular additive fusion and standard cross-attention, respectively.\nAs shown in Table IV, the ACC of FMDNN shows that it significantly outperforms w/o MG by 5.0% and 5.7% on LC and NCT, respectively, and its F1-score is improved by 6.0% and 5.9%, respectively. These results demonstrate that multi-granular feature extraction enables the model to capture a broader range of feature information, thus enhancing its performance.\nIn w/o Fuzzy, there was a notable decrease in ACC by 6% and 6%, a reduction in TPR by 4.6% and 6.2%, and a decline in PPV by 6.4% and 6.3% on LC and NCT, respectively. Hence, we conclude that universal fuzzy features play a more pivotal role than multi-granular features. Histopathological images commonly suffer from interference from a substantial number of normal cells and influences from other tissues. Universal fuzzy features excel at filtering essential feature information from intricate histopathological images and demonstrate superior resilience to interference.\nWhen training with features from two granularities, the evaluation metrics were consistently better than those with single-granularity features. On LC and NCT, fine- and medium-grained features exhibited F1-scores of 95.8% and 93.4%, respectively, and fine- and coarse-grained features showed F1-scores of 94.8% and 93.1%, respectively. Upon analysis, it is observed that fine-grained features capture more localized information, enabling the model to better capture subtle variations in the data, thereby improving model performance. However, when compared with F1-scores achieved by simultaneously extracting features from all three granularities, a notable performance gap still exists.\nWe compared three fusion algorithms. M-ADD, with ACC values of and F1-scores of on LC and NCT, respectively, did not exhibit significantly improved results after adding universal fuzzy features into multi-granular features. However, M-CA yielded slightly better results simply through the use of cross-attention. These findings highlight suboptimal performance due to the direct employment of additive fusion.\nFeature visualization methods are employed to enhance the interpretability of multi-granular feature extraction. Heatmaps and Class Activation Maps (CAMs) are utilized to visualize the critical feature information learned by the model.\nHeatmaps and CAM allow for a direct visual assessment of a model's attention across different spatial locations. We generated heatmaps for the three multi-granular features and compared them with other feature extraction methods.\nFigs. 6 and 7 show pathological images with respective \"colonca\" and \"lungaca\" classification labels as the subjects of analysis. Fig. 6(a) and 7(a) show the original image. In Fig. 6(b) and 7(b), from left to right, the sequence includes heatmaps and CAM maps for fine-, medium-, and coarse-grained features. From left to right, Fig. 6(c) and 7(c) show heatmaps and CAM maps derived from feature extraction by EfficientNet. In Fig. 6(d) and 7(d), from left to right, the sequence comprises heatmaps and CAM maps derived from feature extraction by AlexNet.\nObserving the heatmaps in Figs. 6(c) and 7(c), the extracted features exhibit an indistinct separation between cells. This can be attributed to the complex network design, which limits interpretability in tasks involving fine granularity, similar categories, or subtle differences. The CAM maps indicate that the method focuses on patchy regions, with less emphasis on features in edge areas.\nExamining the heatmaps in Figs. 6(d) and 7(d), the boundaries between cells are indistinct, and the separability is weak. This is attributed to the use of larger convolutional kernels in AlexNet, rendering it less sensitive in detecting smaller-granularity targets. In addition, the multifaceted nature of cells limits feature extraction to a single granularity, resulting in less accuracy and interpretability. The CAM maps further reveal that the model's focus extends over larger areas of the feature maps, making it susceptible to interference from non-critical features.\nIn Figs. 6(b) and 7(b), multi-granular feature heatmaps extracted by our model can better explain the multi-granularity attributes of cells. The proposed approach directs its attention at different granularities. At a coarse-grained level, it focuses on the overall cell layout, including spatial arrangement and aggregation; at a medium-grained level, it pays attention to the size and arrangement of cell populations; and at a fine-grained level, it hones in on details such as the size, shape, and chromatin distribution within cell nuclei. In addition, the CAM maps provide a visual representation of the network's activation regions in the images. FMDNN effectively and accurately captures features in pathological images, significantly enhancing classification accuracy.\nFig. 8 shows the F1-scores of FMDNN on datasets with different categories and sample sizes. The model achieves the expected results for datasets with a large number of samples, such as LC and NCT. The model performed commendably on datasets with less prominent multi-granular attributes, such as Bl, Kv, and especially HAM. However, there are still some limitations.\nIn reality, FMDNN is limited in the following ways: 1) The multi-granular feature extraction module exhibits suboptimal performance on datasets lacking discernible multi-granularity attributes as revealed by heat map analysis. 2) Our model demonstrates limited generalization in images with indistinct multi-granularity attributes. Employing NCT's weights on BL, HAM, and Kv yields ACCs of 71.2%, 50.6%, and 68.4%, respectively. The model has not yet acquired sufficient semantic information to optimize its performance effectively for these specific images.\nWe consider the following potential solutions to these limitations: 1) A dynamic gate-controlled multi-granular FMDNN could be designed that optimizes various granular features through a gate mechanism. 2) In the future, CLIP [57] could be integrated into the algorithm to enhance its semantic learning capabilities by maximizing the similarity of relevant sample pairs and learning model parameters."}, {"title": "VI. CONCLUSION", "content": "We introduced a Fuzzy-guided Multi-granularity Deep Neural Network (FMDNN), leveraging the unique multi-granularity attributes of cells to extract multi-granular features from histopathological images for improved information representation. Classical fuzzy set theory was introduced to address the challenge of information redundancy in multi-input scenarios. Fuzzy membership functions were used to extract general features from pathological tissue images. Fuzzy-guided cross-attention was employed to fuse critical feature information. Guided by the universal fuzzy features, the model showed enhanced generalization and robustness on datasets where multi-granularity attributes are obvious. Experimental evaluations on five publicly available datasets and comparative analyses with other models demonstrated the superior classification accuracy of FMDNN, particularly in tasks involving cellular interference and subtle features.\nIn our future work, we plan to adjust the resolution of feature extraction to enable better adaption to different types of datasets, especially to those with less pronounced multi-granularity attributes, to enhance the algorithm's generalizability and adaptability to a broad range of applications. Given the relatively small size of histopathological image datasets, we will explore adversarial learning and transfer learning, improve the application of large models in medical datasets, and potentially include multimodal data to construct models with stronger generalization capabilities."}]}