{"title": "Pensieve Discuss: Scalable Small-Group CS Tutoring System with AI", "authors": ["Yoonseok Yang", "Jack Liu", "J.D. Zamfirescu-Pereira", "John DeNero"], "abstract": "Small-group tutoring in Computer Science (CS) is effective, but presents the challenge of providing a dedicated tutor for each group and encouraging collaboration among group members at scale. We present Pensieve Discuss, a software platform that integrates synchronous editing for scaffolded programming problems with online human and AI tutors, designed to improve student collaboration and experience during group tutoring sessions. Our semester-long deployment to 800 students in a CS1 course demonstrated consistently high collaboration rates, positive feedback about the AI tutor's helpfulness and correctness, increased satisfaction with the group tutoring experience, and a substantial increase in question volume. The use of our system was preferred over an interface lacking AI tutors and synchronous editing capabilities. Our experiences suggest that small-group tutoring sessions are an important avenue for future research in educational AI.", "sections": [{"title": "1 Introduction", "content": "Small-group tutoring sessions involve a single human tutor or teaching assistant working with a small group of students to review course material and solve example problems. Research has demonstrated that this mode of instruction is effective for collaborative learning, resistance to forgetting, and instructional efficiency [5, 11, 17, 18]. Collaborative systems have been shown to significantly enhance learning gains compared to non-collaborative systems in CS education [5].\nHowever, resource constraints can make it impractical to assign a dedicated tutor for each small-group tutoring session in a large course. When a single TA must oversee multiple small groups simultaneously, it can be challenging to monitor each student's progress and provide sufficient support and feedback. The increasing interest in CS courses has exacerbated this issue, making it difficult for educators to maintain high-quality instruction and support during scheduled group tutoring sessions.\nMoreover, encouraging collaboration among group members poses another challenge. When each student in a small group is using a computer to write and test code using their own individual editors or writing code on individual worksheets, they may work at different paces and focus their attention on their own individual answers rather than group discussion. Individually distributed web pages or worksheets inhibit students from easily seeing each other's approaches, making collaboration more difficult.\nWe present Pensieve Discuss, a software platform designed to facilitate small-group CS problem solving sessions at scale by combining synchronous editing of scaffolded fill-in-the-blank problems with AI and online human feedback. Students can form small groups in Pensieve Discuss and work on problems together using a code editor with shared content. When they are stuck, they can get responsive expert help from an AI Tutor or human TAs. Human TAs can monitor student progress and AI tutor responses in real-time through the platform and assist students as needed.\nWe deployed Pensieve Discuss in a CS1 course that had weekly 80 minute in-person discussion sections. These discussion sections were conducted in the format of small-group tutoring sessions, with groups of up to seven students supervised by a TA who supported multiple groups simultaneously. Prior to introducing Pensieve Discuss, students in these groups used individual code editors to write down their answers to questions and check their work, and there was only human TA feedback available rather than both human and AI feedback. Pensieve Discuss was deployed to 800 students for the entire Spring 2024 semester. Students had the option of using Pensieve Discuss or the individual code editor used previously.\nTo our knowledge, Pensieve Discuss is the first LLM-based system designed to be used in real-time CS small-group discussions alongside teaching assistants. Our main contributions are as follows:\n\u2022 We present the Pensieve Discuss system, which provides collaborative and scalable small-group tutoring for CS1 courses.\n\u2022 We share our findings from student surveys, analysis of usage data, and teaching assistant interviews, which show"}, {"title": "2 Related Work", "content": "2.1 Small-group tutoring\nSmall-group tutoring in CS education is a resource-efficient alternative to one-on-one tutoring. One-on-one tutoring from a human expert is one of the most effective ways for novices to develop robust mental models of programming [2, 4]. Expert tutors can provide timely, targeted, and proactive help based on a close examination of the student's code, addressing individual learning needs promptly and accurately. However, assigning a TA to each student is impractical in higher education due to the limited availability of TAs. Small-group tutoring presents a promising alternative in terms of scalability.\nSmall-group tutoring can also increase student engagement through collaboration. Research has shown that collaborative learning environments facilitated by small-group tutoring can increase student engagement and make the learning experience more enjoyable [11, 17]. Some researchers argue that it is even more effective than one-on-one tutoring due to its instructional efficiency, resistance to forgetting, and promotion of cooperative learning [18].\nHowever, tools specifically designed for small-group tutoring have been rarely developed. Researchers have developed tools like Codeopticon [4] and VizProg [22] to provide real-time, one-to-many tutoring interfaces, enabling instructors to support multiple students more efficiently. However, these tools do not explicitly foster student collaboration, as each student is expected to work independently in a non-synced editor. Moreover, without Al assistants, these tools cannot fully eliminate delays in assisting students, as a single human tutor has limited capacity.\n2.2 LLM-Based Tools in CS Education\nLarge introductory CS courses in higher education have increasingly adopted Large Language Models (LLMs) to provide responsive support to students and alleviate instructors' workloads. One prominent application is assisting students in debugging their programming assignments [6, 7, 9, 10, 13, 16, 21]. LLMs can guide students towards correct solutions with high accuracy, and students find these tools helpful [7, 9, 16]. Additional uses of LLMs in CS education include answering students' questions in online course forums [10, 12, 19] and generating course materials [3, 14, 15, 20].\nLLM-based assistants are new, and so far as we are aware, no LLM tools have been developed specifically to support small-group tutoring sessions that are supported simultaneously by AI and human tutors or teaching assistants. Compared to the individual use of AI assistants, AI tools for small-group tutoring sessions need to consider collaborative features and human(TA)-in-the-loop components to maximize the learning benefit of each tutoring session."}, {"title": "3 System Description", "content": "Our system, Pensieve Discuss, was developed to provide an enhanced learning experience to students during real-time in-person small group tutoring sessions that are part of a regular CS1 course offering and are overseen by a TA. Unlike most LLM assistants in CS education intended only for student use, our system serves both students and TAs. In this section, we describe Pensieve Discuss in detail for each user group.\n3.1 Student Features\nFigure 1 shows the student interface to the system. Students can join a group and solve questions collaboratively.\nSynced Editor: Students use a synced editor to write their solutions to coding questions. Similar to Google Docs for programming,"}, {"title": "3.2 TA Features", "content": "Content Management System (CMS): TAs can use our CMS to upload questions. The CMS supports markdown, making it easy to import existing content into our platform. TAs can select the programming language and write test cases for the autograder.\nTA View: During development, TAs reported that it was very difficult for them to track student progress in any problem-solving session that involved them supervising a large number (such as 30) of students, whether they were in-person or online. To solve this problem, we developed a TA view (Figure 2) where TAs can monitor student progress in real-time. They can click each room to observe students' progress, seeing changes in real-time, enabling remote support. When students send a chat to the TA or the AI Tutor, TAs are notified to review new messages. Rooms with unreviewed activity are surfaced to the top of the room list, allowing TAs to prioritize those rooms.\nTA Feedback: TAs wanted an easy way to give feedback on Al chat messages. For instance, endorsing an Al message could help students trust the Al's advice. To support this, we developed a TA feedback feature. For each AI message, TAs can provide one of three feedback types: read, endorse, or edit. If a TA endorses a message, students can see that it was endorsed by a TA. TAs can edit a message if it contains incorrect information or gives away the answer to a problem. If TAs don't want to endorse or edit, they can mark the message as \"read\" to remove the unread message notification.\n3.3 Implementation & Deployment Details\nWhen students interact with our AI Tutor, we send a request to GPT-4 containing the question the group is solving, their current solution, and the autograder result if they ran the grader. Each request includes a system prompt that guides GPT-4 on how to assist the group. To prevent GPT-4 from providing solutions, we direct the model to guide them towards the solution by asking questions and offering hints.\nPensive Discuss was first deployed to 150 students for the final week of the Fall 2023 semester, then to 800 students for the entire Spring 2024 semester. For both semesters, Pensive Discuss was used during 80 minute in-person discussion sections with groups of up to 7 students. Discussion sections were conducted as small-group tutoring sessions, where TAs supervised multiple groups simultaneously.\nFor the Spring 2024 semester, six TAs used our system to assist students. Student groups were formed based on scheduling"}, {"title": "4 Results", "content": "We analyze the data collected during this deployment by focusing on the following Research Questions (RQs):\nRQ1: Did our system facilitate student collaboration?\nRQ2: Was the AI Tutor helpful and correct?\nRQ3: Did our system increase student satisfaction?\nRQ4: How much did the students and TAs use the chat interface?\n4.1 Data\nThe data presented in this section comes from three sources: 1) student surveys, 2) system usage data, and 3) TA interviews. Students completed short surveys each week directly after completing the discussion section of our CS1 course, in order to receive attendance credit. For the TA interviews, we reached out via email to six TAs who taught discussion sections during the Spring 2024 semester. Two TAs were available for interviews, so we conducted 20-minute virtual interviews with each of them. Both TAs had over two years of experience teaching this CS1 course and used Pensieve Discuss to run their remote discussion sections.\n4.2 RQ1: Did our system facilitate student collaboration?\nTo assess whether our system facilitated student collaboration, we compared student survey data from the Spring 2024 semester with data from the Fall 2023 semester. Pensieve Discuss was not used in the Fall 2023 semester, except for the last one (Discussion 12), but the small-group format overseen by a TA was used in both semesters. We added the survey question about collaboration starting from Discussion 6 in Fall 2023, so we compared data from Discussion 6 to 11 of both semesters; the problems and instructions used in these sessions had largely similar content.\nAs shown in Figure 3, student collaboration reported in surveys was consistently higher during the semester when Pensieve Discuss was used.\n4.3 RQ2: Was the AI Tutor helpful & correct?\nTo determine whether the AI Tutor was helpful and correct, we collected student feedback through surveys after each discussion session. As shown in Table 1, a significant majority of students found the AI Tutor to be helpful, with 41.8% rating it as Very Helpful and 35.3% as Helpful. Only 1.5% of the responses indicated that the AI Tutor was Not Helpful.\nMoreover, the AI Tutor's helpfulness was consistently rated high throughout the semester, showing no noticeable trend of decline. This indicates that the AI Tutor maintained a high level of usefulness and accuracy in assisting students with their queries.\nWe also analyzed the per-chat feedback labels provided by students for each chat message. Since the functionality to give per-chat feedback was deployed after Discussion 2, 7084 out of 7516 AI messages were able to be labeled. Out of these 7084 messages, only 336 (4.7%) were labeled by students.\nAs shown from Figure 2, while Helpful was the most popular label, the proportion of negative labels (Unhelpful, Too much help, Incorrect) was more substantial compared to the aggregate helpfulness ratings shown in Table 1. We hypothesize that students are more likely to label negative interactions since helpful chats are considered the default expectation, as reflected in the survey feedback.\nTAs corroborated the high accuracy of the AI Tutor during the interview, stating that it was rarely wrong. However, they noted that"}, {"title": "4.4 RQ3: Did our system increase student satisfaction?", "content": "After piloting our system with 150 students during the last discussion section of the Fall 2023 semester, we asked students to compare the previous discussion interface with the new discussion interface using Pensieve Discuss. Students rated their preference on a scale of 1 (strongly prefer previous system) to 7 (strongly prefer our system). As shown in Figure 4, 77.8% of the students preferred our system, with 32% strongly preferring it over the non-synced individual code editor without Al assistance used previously in Fall 2023.\nWe also asked the same students specifically about their experience with the synced editor. They rated their preference on a scale of 1 (strongly prefer non-synced editor) to 7 (strongly prefer synced editor). As shown in Figure 5, the majority of students preferred the synced editor over the non-synced editor, with 35% strongly preferring the synced editor.\nNext, we compare the survey results of Discussions without Pensieve Discuss (Discussion 1 - 11 in Fall 2023 semester) with the survey results of Discussions with Pensieve Discuss (Discussion 1-11 in Spring 2024 semester). As shown from Figure 6, student satisfaction is consistently higher for the semester (Spring 2024) that used our system. We acknowledge that there is a difference\nWe examined the correlation between student satisfaction, collaboration, and AI Tutor helpfulness. As shown in Table 3, student collaboration (r = 0.51) and AI Tutor helpfulness (r = 0.3) were both positively correlated with student satisfaction. This suggests that these factors are important contributors to the student experience during discussion sections.\n4.5 RQ4: How much did students & TAs use the system?\nIn this section, we analyze the interactions between students, TAs, and our platform.\n4.5.1 Student to Al Tutor interaction. Figure 7 shows the student-sent message distribution per group. It is worth noting that the average of 5.87 questions per group per section (~0.84 question per student) only accounts for questions asked through the Pensieve Discuss platform. Students were also able to ask questions via the voice channel in Discord during the session, which was not captured from our usage data."}, {"title": "4.5.2 TA to Al Tutor interaction.", "content": "Table 4 shows that approximately 8% of AI Tutor messages were reviewed by TAs. About 30% of the reviewed messages were endorsed.\nDuring the interviews, both TAs mentioned that they tried their best to review every message the AI Tutor sent to students, and estimated that they reviewed between 70% and 90% of the messages. However, they also acknowledged that they often forgot to mark messages as read, which explains the discrepancy between the review rate in the data and their testimonials.\n4.5.3 TA to Student interaction. TAs testified that having the TA view in our system helped them understand each group's progress better than in semesters without our system, as they could see the students' code in real-time.\nHowever, TAs rarely used our system to send chat messages to the students. Out of 1314 sessions, only 61 sessions (4.6%) included instances where TAs sent messages to the student groups. Until Discussion 9, TAs shared the same chat window with the AI Tutor. This caused confusion, as TAs were unclear whether students were directing their questions to the AI Tutor or to the TA. Additionally, since the AI Tutor responded to every question, even to the follow-up questions intended for the TA, the AI Tutor continued to send messages in the same window as the TA.\nTo address this issue, we released a separate TA chat window starting from Discussion 9. While TAs preferred the separate chat window, most students continued to use the AI Tutor chat window and rarely asked questions in the TA chat view.\nTAs were also able to communicate with students verbally by visiting the group in-person or using Discord. These additional communication methods may have contributed to the low usage of the chat interface for TA-student interactions within our system."}, {"title": "5 Limitations", "content": "Our study primarily examined the impact of Pensieve Discuss on student collaboration by comparing student survey results from different semesters. While the mode of instruction and the small-group tutoring format of discussion sections remained the same, aside from the introduction of our system, there are minor differences in problem descriptions that may have influenced the survey results.\nWe also acknowledge that our Al Tutor might be less beneficial to students who are behind in the course content. During TA interviews, one TA mentioned that the system wasn't as helpful for students who were significantly behind in the lecture material, as these students tended to over-rely on the AI Tutor."}, {"title": "6 Future Work", "content": "Pensieve Discuss has the capability to support multiple programming languages. Our CS1 course is taught primarily in Python with other languages, all of which are supported in Pensieve Discuss. Instructors can easily select the desired language for each question in our system's Content Management System and upload their content accordingly.\nAdditionally, our system is not limited to CS courses. In the future, we aim to leverage the scalability of Pensieve Discuss to expand its use to other courses within Computer Science and potentially to other disciplines."}, {"title": "7 Conclusion", "content": "We present Pensieve Discuss, a software platform designed for scalable small-group CS tutoring. We deployed our platform in a large CS1 course with 800 students at a public university for an entire semester. Through student surveys, usage data analysis, and teaching assistant interviews, we found that Pensieve Discuss helps increase student collaboration, student satisfaction, and question volume during small-group tutoring sessions.\nPensive Discuss is a first attempt to integrate LLM to scale and improve small-group tutoring section. We hope that the approach taken by our system serves as a stepping stone for future research in the application of AI in small-group tutoring."}]}