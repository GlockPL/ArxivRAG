{"title": "Rateless Joint Source-Channel Coding, and a Blueprint for 6G Semantic Communications System Design", "authors": ["Saeed R. Khosravirad"], "abstract": "This paper introduces rateless joint source-channel coding (rateless JSCC). The code is rateless\nin that it is designed and optimized for a continuum of coding rates such that it achieves a desired\ndistortion for any rate in that continuum. We further introduce rate-adaptive and stable communication\nlink operation to accommodate rateless JSCCs. The link operation resembles a \"bit pipe\" that is identified\nby its rate in bits per frame, and, by the rate of bits that are flipped in each frame. Thus, the link operation\nis rate-adaptive such that it punctures the rateless JSCC codeword to adapt its length (and coding rate)\nto the underlying channel capacity, and is stable in maintaining the bit flipping ratio across time frames.\nNext, a new family of autoencoder rateless JSCC codes are introduced. The code family is dubbed\nRLACS code (read as relax code, standing for ratelss and lossy autoencoder channel and source code).\nThe code is tested for reconstruction loss of image signals and demonstrates powerful performance that\nis resilient to variation of channel quality. RLACS code is readily applicable to the case of semantic\ndistortion suited to variety of semantic and effectiveness communications use cases.\nIn the second part of the paper, we dive into the practical concerns around semantic communication\nand provide a blueprint for semantic networking system design relying on updating the existing network\nsystems with some essential modifications. We further outline a comprehensive list of open research\nproblems and development challenges towards a practical 6G communications system design that enables\nsemantic networking.", "sections": [{"title": "I. INTRODUCTION", "content": "The concepts of semantic and effectiveness communication were raised by W. Weaver in\na preface to Shannon's mathematical theory of communication\u2014while referring to Shannon's\nwork as a solution to technical communication problem\u2014as what should come next beyond the\ntechnical communication [1]. Several attempts are made to formalize those concepts (see for"}, {"title": "A. The Issue with Current Communication Networking Paradigm", "content": "Semantic communication problem therefore mostly appears to have to do with source coding\nand less with communication networking, however, essential modifications to the way network\ntreats the messages can improve the semantic extraction and reconstruction efficiency. The\nrequired changes stem from the intense focus of the current communication networking paradigm\non error-free and packet-ized communication. Within the network, packets go through a sophis-\nticated and well-optimized process of routing, error correction coding, channel symbol mapping,\nretransmissions, etc. By the end of their finite latency budget, the packets are only passed to\nthe destination if successfully reconstructed\u2014i.e., error-free. Otherwise, there will be a packet\nerasure. The cliff effect and leveling-off effect associated to separate source and channel coding"}, {"title": "B. Joint vs Separate Source-Channel Coding", "content": "Optimality of separate source and channel coding solutions [20] hold only in the limit of\ninfinite blocklength. The assumptions that are needed for optimality frequently don't hold in\npractice where there exist constraints on end-to-end latency and implementation complexity [12].\nIn lossy communication and finite blocklength regeime, [21] proves sub-optimality of separation.\nJoint solutions outperforming separate desgins have presistantly reported in the literature, e.g.,\nsee examples in [19], [22]. On the other hand, separation-based solutions have become indispens-\nable to telecommunication systems, offering ease of interoperability, modular and independent\ndevelopment of devices and network systems, and simplicity of design. But another important\nbenefit of separate design is channel agnosticism offered to the source compression, allowing\nthe channel code to adapt to the channel state when needed."}, {"title": "C. Motivation", "content": "The proposed rateless JSCC coding framework in this work aims to resolve this very issue by\nhosting the JSCC functionality at the application while allowing the network to adjust the coding\nrate based on the knowledge of CSI. Particularly, the responsibility of the network is simplified\nto stabilizing the reliability of the end-to-end link (measured in ratio of flipped bits in each\nframe) and then adapting the coding rate to CSI by puncturing the binary codeword received\nfrom the application. This relaxes the need for continuous coordination between the application\nand the network, and forms a cooperative game-theoretic venture between the network and the\napplication. For this to function properly, the JSCC code at the application must perform well\nfor a range of coding rates that are among network's possible choices and maintain optimality\nin the rate-distortion tradeoff over that range.\nConventional source codes recognize rate-distortion tradeoff most commonly through quan-\ntization control. Rate control is therefore possible for those codes if performed by the source.\nHowever, commissioning the network with rate control using the conventional source codes\nresults in sub-optimal JSCC performance.\nThe proposal in this work thus has two main elements: a rateless JSCC coding framework\nfor the application, and a rate-adaptive and stable end-to-end link operation framework for the\nnetwork. In the following (as illustrated in Fig. 1), application refers to the user (a human and/or\na machine running an application), and, network refers to the service provider that establishes an\nend-to-end link for the application (possibly consisting of multitude of wireless and wired hops,\nswitching and processing nodes). We also use the term frame to refer to a segment of data bits\nthat is communicated at a time by the application\u2014the term is to be differentiated with packet\nin technical communication which implies integrity requirement (see further discussion on this\nin Sec. V)."}, {"title": "D. Prior Work", "content": "The literature on semantic communication and lossy JSCC is rich, especially the research\non leveraging the power of deep neural networks (DNNs) in realizing semantic communication.\nThe overview papers on the topic that raise interesting open research problems are outlined later\nin Sec. V-C. Here, we study the literature around a few points that are the most relevant to our\nrateless JSCC proposal."}, {"title": "1) Hierarchical Compression and Variable-Length Coding", "content": "The proposed rateless JSCC codes\nshouldn't be mistaken by the so-called variable-length JSCC schemes, such as in [23], [24], where\nthe code length is varied according to network-provided rate or source word length. In contrast,\na rateless JSCC code generates a codeword that can cover a continuum of compression rates\nwithout knowing which rate will be used by the network. Thus, the aim of the code design is\nto maintain a rate-distortion tradeoff for all the supported rates.\nUse of rateless codes such as Raptor codes together with hierarchical source compression was\nproposed in [25], [26] to provide a continuum of coding rate that can be adapted to the channel\ncapacity. The medium is first quantized into multiple bitplanes where each bitplane is then\nchannel coded using Raptor codes, allowing for the coding rate to be adapted to the transmission\nchannel capacity. In effect, the hierarchical source quantization and the channel coding remain\nseparate while each quantization hierarchy requires a separate coding rate matching. In contrast,\nin this work we target codes that achieve true joint source-channel coding effect with single\ncoding rate matching, and propose an example of those codes using deep neural networks that\ncan be flexibly made rateless according to the desired range of coding rates."}, {"title": "2) Unequal Importance of JSCC Coded Bits", "content": "In practical source coding it can be observed\nthat the individual coded bits incur different levels of relative importance or sensitivity. As a\nresult, channel errors in different bit positions can affect the reconstructed signal differently.\nSuch effect is apparent specially in variable-length source coding [27], such as entropy coding\nschemes-known to be otherwise optimal over noiseless channel.\nSeveral approaches have acknowledged this effect in developing JSCC techniques under noisy\nchannel conditions. Some of those solutions focus on designing the source and channel code\nto limit propagation of channel errors, e.g., by improving synchronization for variable-length\nsource codes [28], or, through packetization during channel coding [29]. Other solutions focus\non specifically weighted channel coding protection for different coded bit positions [30], [31].\nA more recent work capitalizes on further accented unequal importance of the coded bits and\nproposes to design autoencoder (AE) type channel codes to unequally protect the source encoded\nbits with non-uniform importance [32]."}, {"title": "3) Use of Deep Neural Networks for JSCC", "content": "This is a developing and rich part of the literature.\n[33], [34] and [35] are examples of studying deep learning-based JSCC. The latter targets wireless\nimage transmission and demonstrates improved performance over traditional separate source and"}, {"title": "4) Rateless Compression", "content": "AEs have proven powerful in compression tasks, thanks to nonlinear\nactivation functions such as rectified linear unit (ReLU). Compared to majorly linear techniques\nsuch as principle component analysis (PCA), AEs can more efficiently extract features (a.k.a.,\nlatent representations) of the data. This shortcoming of PCA-based techniques was addressed in\n[38], where non-linear PCA and hierarchical AEs were discussed. In essence, sorted principle\ncomponents of a liner (or, non-linear) PCA can be dropped out (i.e., punctured), starting from the\nleast significant order, to create a rateless behavior in the compression process. However, this is\nnot generally true for AEs since the latent variables are learned to be uniformly important. Similar\nshortcoming is persistent in sparse AEs too [39], where the AE learns latent representations that\ncan be randomly dropped out, thus providing rate-control mechanism for compression. This was\ninvestigated by [40] in developing a special case of AEs, referred to as rateless AE.\nThe rateless AE in [40] is based on TailDrop regularization which is stochastic in nature,\nbut unlike sparse AEs, imposes a non-uniform dropout rate to the latent space. Specifically,\nthe dropout rate in TailDrop monotonically increases from head neurons to tail neurons. The\nresult is an autoencoder with a stochastic bottleneck and rateless behavior that is adaptable to a\ncontinuum of compression rates. The rateless AE structure was utilized later by [41] to construct\na rateless deep JSCC solution for Point Cloud signals. The rateless JSCC in [41] allows the\ncode rate to be adapted, however, it doesn't assume a quantized (binary) interfacing between\nnetwork and application entities and appears to unify the function of those entities. In practice,\ntraining AE with binary latent space while applying a stochastic dropout, as was proposed in\n[40], proves highly complex\u2014the training must converge while experiencing randomness of the\ndropout regularization, randomness of bit flipping due to channel errors, and the quantization\nof the latent space into binary. Therefore, in the proposed solution in this paper we avoid the\nrandom dropout of the latent space to improve convergence of AE training, and instead, propose"}, {"title": "E. Contributions", "content": "The main contributions of this paper can be summarized as follows:\n1) We introduce the new framework of rateless JSCC. Rateless JSCC is unaware of the state\nof the network (including channel state and load variation) but anticipates time-variation\nin the state, hence optimizes the code to be rate-compatible and covers a continuum of\nsuch variations2. Further, we introduce a new rate-adaptive and stable communication link\napproach. The proposed link operation turns the underlying channel into a bit pipe that\nis identified by the number of bits it transfers in a single time frame and the rate of bits\nthat are flipped during the transfer. The link accommodates rateless JSCC by being rate-\nadaptive, such that it punctures the codeword to adapt its length (and coding rate) to the\nunderlying channel capacity, and is stable in maintaining the bit flipping ratio across time\nframes. The puncturing follows an order of bits that is known by both the network and the\napplication, e.g., from the end of the codeword, such that the more important information\nis encoded into bits that are less likely to be punctured. Due to the puncturing, the link\nintroduces a new paradigm of communication networking where the network is allowed\nto throw away part of the data based on pre-agreed terms with the application.\n2) We propose an AE solution to rateless JSCC. The proposed code is dubbed rateless and\nlossy autoencoder channel and source (RLACS) code (read as relax code!) and is built using\nresidual attention network architecture [43] with binary latent space. The code is trained\nand tested on image signals considering reconstruction loss as the objective distortion and\ndemonstrates powerful performance against channel state variation thanks to the rateless\nJSCC structure.\n3) A deep dive into practical implications of a semantic communication system is presented\nand a blueprint of a future end-to-end communication system design is provided. The\nproposed system design is aimed at enabling semantic and effectiveness communication"}, {"title": "F. Organization of the Paper", "content": "Sec. II describes the problem of semantic communication over noisy and faded channel; Sec. III\nintroduces rateless JSCC for application operation and rate-adaptive and stable link for network\noperation; Sec. IV presents an AE solution to rateless JSCC based on sequential training of a\nmulti-DNN attention residual network architecture, and provides numerical experiment results\nfor the proposes RLACS code; Sec. V provides a blueprint for next generation communication\nnetworks with semantic communication capabilities and outlines a comprehensive list of open\nresearch problems towards 6G semantic communication system design; and, finally, Sec. VI\nconcludes the paper."}, {"title": "II. PRELIMINARIES AND PROBLEM STATEMENT", "content": "We study the problem of semantic communication over a channel with time-varying gain $\\sqrt{\\gamma_t}$ and additive white Gaussian noise (AWGN) n. The channel is assumed to be block fading, that\nis, it stays constant over a blocklength W (in Hz-s), after which, it changes to a new independent\nchannel, where t is the block index3.\nA network operator (or, network, for simplicity) operates over the channel to create a semantic\ncommunication link between application source and application destination nodes (see Fig. 1).\nThe network has knowledge of the CSI $\\tilde{\\gamma}_t$, which is an estimate of the channel gain $\\gamma_t$ (i.e., it\nis either delayed or noisy, or both). Hereafter, the term block refers to a coherence block of the\nunderlying channel, while frame refers to a segment of data communicated by the application\nover a block.\nThe application uses a JSCC code with encoder f and decoder g (defined in the following\nsection). During block t, the source encodes an input medium $s_t$ (e.g., an image signal) into\na binary sequence $u_t = f(s_t)$ of length K and delivers it to the network. Network's job is to"}, {"title": "Remark 1.", "content": "The network and the application do not exchange the uncoded source information\nu, nor the state of the network. Therefore, the encoder f (and the decoder g) are unaware of the\nstate of the channel and the network is unaware of the distribution and instance of the source\nsignal."}, {"title": "Remark 2.", "content": "The goal laid out above is distinct from that of the classical JSCC excess distortion\ncriterion, i.e., $\\Pr[d(s,\\hat{s}) > d] < \\delta$. The intention, from the application perspective, is to minimize\nthe expected distortion given the randomness in the state of the network, $(\\tilde{\\gamma}_t, P_t, W_t)$. It is\nconceivable to further assume that the application is not aware of the distribution of those\nrandom variables either. Additionally, average distortion over several blocks is not a suitable\ngoal for still media forms such as images."}, {"title": "Remark 3.", "content": "The joint venture of the network and the application in this problem can be seen\nas a cooperative interaction in game theory. The players, network and application, exchange\nsome ground rules\u2014known as service level agreement or link configuration in telecommunication\nterminology-and cooperate towards achieving the goal. This also implies network's cooperative\neffort to maximize $P_t$ and $W_t$ within its practical limits."}, {"title": "A. Network's Operation: Rate-Adaptive and Stable Link for Semantic Communications", "content": "Let us focus on the single-user setting, where total transmit power P and total channel use\nW is allocated to the user. The block fading channel provides a SNR of $\\frac{P \\gamma_t}{(\\sigma_n W)}$, where $\\sigma_n$\nis the AWGN noise spectral density. The network uses modulated communication, e.g., from\nquadrature amplitude modulation (QAM) constellation, to transmit the bits over faded and noisy\nchannel. Using the knowledge of $\\tilde{\\gamma}$, the conditional cummulative distribution of $\\gamma$ is denoted by\n$F_{\\gamma|\\tilde{\\gamma}}$. The network can choose a modulation constellation to guarantee a target bit-flipping ratio\nbetween x and y.\nLet us assume the modulation constellation order M is chosen from a finite ordered set {$M_1 <$\n$M_2 < ... < M_c$}. Furthermore, let us use Q(snr,M) = ber to denote the deterministic mapping\nbetween SNR, M and the expected value of BER denoted by ber. The inverse of this mapping\nfor given M is available and provides $Q^{-1}(q_0, M) = snr_{M,th}$, where $snr_{M,th}$ is the threshold of\nSNR for $q_0$ BER cross-over for modulation order M. Similarly, we have $\\gamma_{M,th} = \\frac{nwsnr_{M,th}}{P}$.\nBoth Q(.) and $Q^{-1}(.)$ can be empirically derived through sufficient Monte Carlo sampling of\nthe underlying channel distribution. The network chooses the M that yields the highest spectral\nefficiency, i.e., $\\log_2M$, while stabilizing a target BER around $q_0$ for every block, by\n$M = \\arg \\max_{m \\in {M_1,..., M_c}} \\log_2 m \\qquad \\qquad s.t. F_{\\gamma|\\tilde{\\gamma}}(\\gamma_{M,th}) \\leq \\epsilon.$"}, {"title": "Definition 1.", "content": "A stabilized vector binary symmetric channel SVBSC($q_0,\\epsilon$) is a set of parallel\nbinary symmetric channels (BSCs) of BSC(q) where q is stabilized \u201caround\u201d $q_0$, that is, $\\Pr[q >$\n$q_0] \\leq \\epsilon$. Similarly, SVBSC($q_0,\\epsilon,K,\\bar{L}$) is a stabilized vector binary symmetric channel of length\n$K-\\bar{L}$, where the discrete random variable L $\\in$ {0,...,$\\bar{L}$}."}, {"title": "Remark 4.", "content": "It's worth stressing that such rate-control mechanism is a new paradigm in commu-\nnication where a portion of the data bits can be intentionally removed by the network. In the\nconventional communication systems, the network doesn't discard information bits intentionally\u2014\nit may deliver them correctly to the receiver as a packet, or drop them altogether, due to packet\ntransmission failure."}, {"title": "Remark 5.", "content": "The uncoded QAM version of SVBSC($q_0,\\epsilon,K,\\bar{L}$), presented above, is only appro-\npriate for the simple case where a channel coherence block and the communication frame\nalign. More commonly, a communication frame may tolerate a latency that spans over multiple\ncoherence blocks in time. Then, use of retransmission techniques, such as hybrid automatic repeat\nrequest (HARQ) together with error correction coding can complement the modulation order se-\nlection proposed above and improve throughput. Nevertheless, the definition of SVBSC($q_0,\\epsilon,K,\\bar{L}$)\nremains the same. For simplicity, here we focused on the uncoded modulation case."}, {"title": "B. Application's Operation: Rateless JSCC", "content": "The code is designed to minimize the distortion over a binary channel where BER is bounded\n\u201caround\" $q_0$, and for all the rates in the range [R1o, Rhi], where Rio and Rhi correspond to $\\bar{L}=\\bar{L}$\nand $\\bar{L} = 0$ puncturing lengths, respectively."}, {"title": "Definition 2.", "content": "A (K,N,$\\bar{L}$,$\\vec{d}$) binary rateless and lossy joint source-channel code is a tuple of\nmappings, consisting of an encoder f, a rate control bit-puncturing function r, and a decoder\ng,\nf:$R^N \\rightarrow {0,1}^K$, r:$ {0,1}^K \\rightarrow {0,1}^{K-L},g:{0,1,\\emptyset}^K \\rightarrow R^N \nthat satisfies\n$\\forall L \\in {0,...,\\bar{L}}\\qquad \\mathbb{E}(d(s,\\hat{s})|L) \\leq \\vec{d}[L]$,\nwhere the expectation is over the source distribution and channel randomness, $d : R^N \\times R^N \\rightarrow$\n[0,$\\infty$) is the distortion function, $\\vec{d}$ is a vector of distortion values, u = f(s), x = r(u) = $u_{1:K-L}$,\ny ~ $P_{y|x}$(x) is a vector binary channel, $\\hat{u}$ = y$\\|\\emptyset_L$, and $\\hat{s}$ = g($\\hat{u}$) (see Fig. 1).\nIn Definition 2, $\\emptyset_L$ denotes a vector of L null values and $\\||$ denotes concatenation of two\nvectors. The channel y ~ $P_{y|x}$(x) is assumed to be a vector binary channel, as also illustrated\nin Fig. 1. Thus, the channel may in practice include a channel mapping function that maps x\nto M complex symbols, passes them through an underlying complex valued channel, and then\nde-maps the received M complex symbols to binary vector y. Thus, the channel denoted by\n$P(y|x)$ comprises the underlying channel and the signal processing functions of the network."}, {"title": "Definition 3.", "content": "A rate-distortion mapping vector of $[(\\bar{L},\\vec{d}[1])]$ is said to be achievable if there\nexists a (K,N,$\\bar{L}$,$q_0$) rateless joint source-channel code as defined in Definition 2.\nThe encoder f operates at the coding rate of R = K/N, while the mapping r reduces the rate by\n(K-L)/K. The effective coding rate of f and r mappings is thus $R = \\frac{(K-L)}{M}$, representing\nthe inverse of the compression rate of the lossy and rateless JSCC.\nThe adopted model relaxes the need for a probabilistic model of an adaptive quantizer function\nfor the encoder output, commonly used in variable-rate compression techniques. In fact, the goal\nof the proposed rateless encoding is to commission the network with the rate-control function\u2014a\ncommon realization of such function is rate adaptation according to CSI that is commonly used\nin wireless communication technologies."}, {"title": "Remark 6.", "content": "Effectively, the null bits at the receiver can be seen as bit erasures. From the point\nof view of decoder g, one difference between the flipped bits (ratio q out of K \u2013L) and the L\nnull bits is that that the position of the former is unknown while the latter is in a known position\n(e.g., end of the vector)."}, {"title": "A. Training", "content": "We first sequentially train an autoencoder ladder structure with F iterations of training. In\nthe ith iteration, the previously trained i \u2212 1 encoders and decoders parameters are \u201cfrozen\u201d,\nthat is, they are only used for evaluation and not for training. The ith encoder and decoder are\ntrained, while decoder i effectively takes input from encoder i and all the frozen encoders before\ni. Therefore, the training iteration i optimizes the DNN parameters as follows.\n($\\theta^*_i, \\phi^*_i$) = arg min$\\limits_{\\theta_i, \\phi_i} \\mathbb{E} (\\mathcal{L}(s,\\hat{s})|\\theta^*_{i-1},...,\\theta^*_1)$"}, {"title": "B. Distortion Minimization", "content": "The loss function utilized for the training process is mean-squared error (MSE) reconstruction\nloss, where\n$\\mathcal{L}(s,\\hat{s}) = \\frac{1}{N} \\sum\\limits_{i=1}^N (s_i - \\hat{s}_i)^2$,\nand N is the image size representing the total number of pixels in all color channels of the image.\nThe inference loss is demonstrated in the following using the more popular peak signal-to-noise ratio (PSNR),\ncomputed as\n$\\text{PSNR} = 10 \\times \\log_{10} (\\frac{1}{\\mathcal{L}(s,\\hat{s})})$"}, {"title": "C. Evaluation and Inference", "content": "During evaluation, the encoder output is quantized to binary by simple thresholding of the\nSigmoid layer output around 0.5. The trained RLACS code is tested over SVBSC(qo,$\\epsilon$,K,$\\bar{L}$).\nThe application source encodes using f = {$f_1$,...,$f_F$} at maximum rate of K/N (see Alg. 1),\nwhile the application destination, being aware of the puncturing length, picks the corresponding\ndecoder from the set {$g_1$,...,$g_F$} and performs decoding over the received bits from the network\n(see Alg. 2)."}, {"title": "Remark 7.", "content": "In practice, the proposed solution can be designed for a set of $q_i$ and $\\epsilon_i$ values\nrelated to i \u2208 {1,...,F}. Such setting will introduce more degrees of flexibility for optimizing\nthe joint venture between the network and the application. In the following we foucs on $q_i = q_0$\nand $\\epsilon_i = \\epsilon$ for all i."}, {"title": "D. An Example RLACS Code", "content": "In the following we present one example of a RLACS code. We use DNNs, more specifically\nresidual attention network architecture [43] with binary latent space to embody the encoders\nand decoders. To convert the real-valued output of the encoder DNNs into a binary latent space\nduring trainig, we use the variational inference for Monte Carlo objectives (VIMCO) estimator"}, {"title": "E. Evaluation Results", "content": "Two testing channels are explored to test the example RLACS code proposed in Sec. IV-D.\nIn both cases, we assume a block fading channel model that follows Rician distribution with\nline-of-sight ratio of 20 dB.\nPerfect CSI: The test channel is block fading with perfect CSI at the transmitter and the receiver\nends of the network. In effect, this resembles an AWGN channel with varying but known SNR.\nImperfect CSI: To study the effect of imperfect CSI (and $\\epsilon$) on the performance, we assume a\nblock fading channel with imperfect CSI, where the Gaussian channel estimation noise variance\n$\\sigma_{\\epsilon}$ is proportional to SNR, according to [47], [48], as $\\sigma_{\\epsilon} = \\frac{1}{1 + n_p \\cdot snr}$, with $n_p$ denoting the number\nof pilot symbols used per coherence block for channel estimation and snr is the wireless channel\nSNR. We set $n_p$ = 10.\nFor these two test channels, Fig. 4 shows the average BER against channel SNR. The case of\nperfect CSI follows the BER of the uncoded QAM modulation. For the imperfect CSI case, the\naverage BER naturally depends on the configured $\\epsilon$. Notably, a tighter constraint on $\\epsilon$ results\non a lower average BER. However, as shown in Fig. 5, this in turn results in lowering the\nespectral efficiency of the link (i.e., increased chance of using a lower modulation order). This\ndemonstrates the tradeoff between stability and efficiency in a SVBSC link. We test our RLACS\ncode over this tradeoff to see the effect of instability parameter & on image reconstruction quality\ntoo.\nThree main JSCC codes are tested over the test channels, where all three are based on the\nDNN architectures in Fig. 3.\n\u2022 Code 1, F = 1 and $C_1$ = 1280: corresponds to a benchmark where the code is trained for\nmaximum spectral efficiency of 10 bpcu, but the code is not rateless, i.e., it is not specifically\noptimized with puncturing effect from the network in mind.\n\u2022 Code 2, F = 2, and $C_i$-$C_{i-1}$ = 640 for all i: is the proposed RLACS code, thus, is rateless,\nand is optimized for code lengths of i$\\times$ 640 for $i \\in$ {1,2}.\n\u2022 Code 3, F = 10, and $C_i$-$C_{i-1}$ = 128 for all i: is also the proposed RLACS code, but with Cis\nadjusted such that the puncturing lengths (resulted from choice of modulation order) aligns\nperfectly as $C_i \\leftrightarrow W \\cdot \\log_2(M_i)$, thus providing finer granularity of rateless-ness compared\nto the above two codes."}, {"title": "F. Discussion of the Results and Take-Away Points", "content": "Let us now delve into the details of the presented results and discuss the important points."}, {"title": "RLACS performs strongly against channel SNR variation", "content": "RLACS code can be compared\nwith the solutions in [35] and [32]. We refer to [32, Figure 10], where those two solutions are\ntested for a similar compression ratio of 1/24 over AWGN channel (comparable to our testing\nchannel with perfect CSI). Most notably, code 3 performs on par with Split-JSCC of [32], while\nin contrast, RLACS relaxes the need for code optimization over several training SNRs, and, only\nrequires JSCC operation in the application, significantly reducing the optimization complexity.\nThere is however a gap in performance of RLACS compared to DeepJSCC [35] which is rooted\nin the assumption of a binary interface between the application and the network in our proposal.\nPerformance of RLACS, thanks to the rateless operation, gracefully degrades as SNR decreases,\nand avoids the cliff effect and leveling-off effect associated to separate source and channel coding\nreported in [17], while maintaining separation of design and optimization of the network and\napplication, intact. In fact, looking at code 1 performance in Fig. 6, one can postulate that those\neffects are mainly the result of packet-ized and error-free approach to communication of bits in\nconventional separate source-channel coding (see further discussion in Sec. V)."}, {"title": "Modulation order granularity is critical for smooth rate-adaptation in SVBSC link", "content": "As\nshown in Fig. 4, the available QAM modulation orders in 5th generation (5G) system (i.e., 2\u2013\n1024) provide a limited range of SNR for a given target BER $q_0$. At SNR values lower and\nhigher than that range, the experience BER will be higher and lower than the target, respectively.\nExtending that range is easily possible by adding higher modulation orders to cover beyond\nM = 1024, and by adding channel codes with < 1 code rate to M = 2 modulation to cover\nbelow M = 2. The RLACS code granularity (i.e., $C_i$ values) can then be accordingly adjusted.\nAlternatively, as noted earlier in Remark 7, different q and $\\epsilon$ values can be used for the first\nand the last encoder and decoder pair, compared to the rest, to match the actual BER in Fig. 4."}, {"title": "JSCC can be fully performed by the application, without the knowledge of the network's\nstate", "content": "Exchanging network's state with the application can become a hurdle in practice, prevent-\ning the code to perform at its optimal rate. With rateless JSCC this issue is efficiently resolved\nby commissioning the network with the rate-control responsibility according to network's state,\nwhile ensuring optimal code design for potential puncturing of the codeword bits by the network.\nUnlike the works in [35] and [32], where training (optimizing) a code for different SNR values\nis exercised to match the training and testing channels, our proposed rateless JSCC approach\nrelaxes the need for the application to worry about the channel."}, {"title": "Progressive performance improvement as rate increases", "content": "As shown in Fig. 8, the proposed\nrateless JSCC framework, and the DNN-based realization of it in RLACS, can be seen as\nprogressive JSCC coding solutions. Conventional progressive coding is used for compression\npurposes without dealing with errors, or in combination with channel coding to recover from\nerrors too [49]. Rateless JSCC is thus, to our knowledge, the first true progressive JSCC solution,\nand is able to deal with channel errors while being unaware of the channel state."}, {"title": "A systematic and practical framework for code design and semantic communication", "content": "Importantly, RLACS code is built on a systematic approach with practical considerations taken\ninto account. RLACS code doesn't require to be designed separately for each SNR operation point\nand can be optimized agnostic to the undelying channel. This is a major advantage of general\nseparate source-channel coding solutions which was missing in joint source-channel codings."}, {"title": "Additional points to consider towards future work", "content": "While autoencoders show good potential for error correction coding, optimization and\ntraining convergance for them proves complex, especially, when the error rates are too high.\nThat suggests targetting a low qo in designing RLACS codes. A lower BER requires a"}]}