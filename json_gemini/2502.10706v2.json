{"title": "Raising the Bar in Graph OOD Generalization: Invariant Learning Beyond Explicit Environment Modeling", "authors": ["Xu Shen", "Yixin Liu", "Yili Wang", "Rui Miao", "Yiwei Dai", "Shirui Pan", "Xin Wang"], "abstract": "Out-of-distribution (OOD) generalization has emerged as a critical challenge in graph learning, as real-world graph data often exhibit diverse and shifting environments that traditional models fail to generalize across. A promising solution to address this issue is graph invariant learning (GIL), which aims to learn invariant representations by disentangling label-correlated invariant sub-graphs from environment-specific subgraphs. However, existing GIL methods face two major challenges: (1) the difficulty of capturing and modeling diverse environments in graph data, and (2) the semantic cliff, where invariant subgraphs from different classes are difficult to distinguish, leading to poor class separability and increased misclassifications. To tackle these challenges, we propose a novel method termed Multi-Prototype Hyperspherical Invariant Learning (MPHIL), which introduces two key innovations: (1) hyperspherical invariant representation extraction, enabling robust and highly discriminative hyperspherical invariant feature extraction, and (2) multi-prototype hyperspherical classification, which employs class prototypes as intermediate variables to eliminate the need for explicit environment modeling in GIL and mitigate the semantic cliff issue. Derived from the theoretical framework of GIL, we introduce two novel objective functions: the invariant prototype matching loss to ensure samples are matched to the correct class prototypes, and the prototype separation loss to increase the distinction between prototypes of different classes in the hyperspherical space. Extensive experiments on 11 OOD generalization benchmark datasets demonstrate that MPHIL achieves state-of-the-art performance, significantly outperforming existing methods across graph data from various domains and with different distribution shifts. The source code of MPHIL is available at https://anonymous.4open.science/r/MPHIL-23C0/.", "sections": [{"title": "1 Introduction", "content": "Graph Neural Networks (GNNs) have made remarkable advancements in modeling and learning from graph-structured data across various scenarios, including, encompassing social networks [4, 11, 23], molecules [26, 40], and knowledge graphs [15, 58]. Despite the powerful representational capabilities of GNNs, their success often relies on the assumption that the training and testing data follow the same distribution. Unfortunately, such an assumption rarely holds in most real-world applications, where out-of-distribution (OOD) data from different distributions often occurs [27, 48]. Empirical evidence has shown that GNNs often struggle to maintain performance when tested on OOD data that differ significantly from"}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 OOD Generalization and Invariant Learning", "content": "Due to the sensitivity of deep neural networks to distributional shifts, their performance can vary dramatically, making out-of-distribution (OOD) generalization an important research topic [2, 19, 21]. The predominant approach for OOD generalization is invariant learning, which explores stable relationships between features and labels across environments, aiming to learn representations that remain effective in OOD scenarios [1, 8]. Its interpretability is ensured by a causal data generation process [45]. [56] proved the theoretical error lower bound for OOD generalization based on invariant learning. Notably, the definition of environmental information is critical to invariant learning, yet it also restricts its further development, as it often requires the training set to encompass a diverse and comprehensive range of environments [24, 34, 38]."}, {"title": "2.2 OOD Generalization on Graphs", "content": "Inspired by the sucess of invariant learning in image data, many OOD generalization methods in the graph domain have been proposed, adopting this core idea, and several representative works have emerged. [10, 17, 22, 25, 31, 42, 54]. Their core idea is to design an effective model or learning strategy that can identify meaningful invariant subgraphs from the input while ignoring the influence of environmental noise [5, 50]. However, the difficulty of modeling environment information in the graph domain has recently garnered attention, with researchers generally agreeing that directly applying invariant learning to graph OOD generalization presents challenges [6, 59]."}, {"title": "2.3 Hyperspherical Learning", "content": "Hyperspherical learning has gained attention due to its advantages over traditional Euclidean methods in high-dimensional [9, 18]. The core idea lies in using a projector to project representations onto a unit sphere space for prototype-based classification [30]. Recently, hyperspherical learning has been extended to applications like contrastive learning and OOD detection, allowing for better disentanglement of features [3, 32]. Despite these advancements, the effective integration of hyperspherical representations with invariant learning to tackle graph OOD generalization has yet to be explored, with the primary challenge being the difficulty of accurately defining environmental information in these tasks."}, {"title": "3 Preliminaries and Background", "content": "In this section, we introduce the preliminaries and background of this work, including the formulation of the graph OOD generalization problem, graph invariant learning, and hyperspherical embeddings."}, {"title": "3.1 Problem Formulation", "content": "In this paper, we focus on the OOD generalization problem on graph classification tasks [10, 17, 21, 50]. We denote a graph data sample as $(G, y)$, where $G \\in \\mathcal{G}$ represents a graph instance and $y \\in \\mathcal{Y}$ represents its label. The dataset collected from a set of environments $\\mathcal{E}$ is denoted as $\\mathcal{D} = {\\mathcal{D}_e}_{e\\in\\mathcal{E}}$, where $\\mathcal{D}_e = {(G_i, y_i)}_{i=1}^{n_e}$ represents the data from environment $e$, and $n_e$ is the number of instances in environment $e$. Each pair $(G_i, y_i)$ is sampled independently from the joint distribution $P_e(G, Y) = P(G, Y|e)$. In the context of graph OOD generalization, the difficulty arises from the discrepancy between the training data distribution $P_{tr}(G, Y)$ from environments $e_{tr} \\in \\mathcal{E}_{tr}$, and the testing data distribution $P_{te}(G, Y)$ from unseen environments $e_{te} \\in \\mathcal{E}_{test}$, where $\\mathcal{E}_{te} \\neq \\mathcal{E}_{tr}$. The goal of OOD generalization is to learn an optimal predictor $f : \\mathcal{G} \\rightarrow \\mathcal{Y}$ that performs well across both training and unseen environments, $\\mathcal{E}_{all} = \\mathcal{E}_{tr} \\cup \\mathcal{E}_{te}$, i.e.,\n$\\min_{f \\in \\mathcal{F}} \\max_{e \\in \\mathcal{E}_{all}} \\mathbb{E}_{(G_e, y_e)\\sim P_e} [l(f(G_e), y_e)],$ (1)\nwhere $\\mathcal{F}$ denotes the hypothesis space, and $l(\\cdot, \\cdot)$ represents the empirical risk function."}, {"title": "3.2 Graph Invariant Learning (GIL)", "content": "Invariant learning focuses on capturing representations that preserve consistency across different environments, ensuring that the learned invariant representation $z_{inv}$ maintains consistency with the label $y$ [5, 33, 50]. Specifically, for graph OOD generalization, the objective of GIL is to learn an invariant GNN $f := f_c \\circ g$, where $g: \\mathcal{G} \\rightarrow \\mathcal{Z}_{inv}$ is an encoder that extracts the invariant representation from the input graph $G$, and $f_c: \\mathcal{Z}_{inv} \\rightarrow \\mathcal{Y}$ is a classifier that predicts the label $y$ based on $z_{inv}$. From this perspective, the optimization objective of OOD generalization, as stated in Eq. (1), can be reformulated as:\n$\\max_{f_c,g} I(z_{inv}; y), \\quad \\text{s.t.} \\quad z_{inv} \\perp e, \\forall e \\in \\mathcal{E}_{tr}, \\quad z_{inv} = g(G),$ (2)\nwhere $I(z_{inv}; y)$ denotes the mutual information between the invariant representation $z_{inv}$ and the label $y$. This objective ensures that $z_{inv}$ is independent of the environment $e$, focusing solely on the most relevant information for predicting $y$."}, {"title": "3.3 Hyperspherical Embedding", "content": "Hyperspherical learning enhances the discriminative ability and generalization of deep learning models by mapping feature vectors onto a unit sphere [28]. To learn a hyperspherical embedding for the input sample, its representation vector $z$ is mapped into hyperspherical space with arbitrary linear or non-linear projection functions, followed by normalization to ensure that the projected vector $\\hat{z}$ lies on the unit hypersphere $(\\|\\hat{z}\\|_2 = 1)$. To make classification prediction, the hyperspherical embeddings $\\hat{z}$ are modeled using the von Mises-Fisher (vMF) distribution [32], with the probability density for a unit vector in class $c$ is given by:\n$p(\\hat{z}; \\mu^{(c)}, \\kappa) = \\frac{\\kappa}{\\mathcal{Z}(\\kappa)} \\exp(\\kappa \\mu^{(c)^T} \\hat{z}),$ (3)\nwhere $\\mu^{(c)}$ denotes the prototype vector of class $c$ with the unit norm, serving as the mean direction for class $c$, while $\\kappa$ controls the concentration of samples around $\\mu_c$. The term $\\mathcal{Z}(\\kappa)$ serves as the normalization factor for the distribution. Given the probability model in Eq.(3), the hyperspherical embedding $\\hat{z}$ is assigned to class $c$ with the following probability:\n$P(y = c \\mid \\hat{z}; {\\kappa, \\mu^{(i)}}_{i=1}^C) = \\frac{\\mathcal{Z}(\\kappa) \\exp(\\kappa \\mu^{(c)^T} \\hat{z})}{\\sum_{i=1}^C \\mathcal{Z}(\\kappa) \\exp (\\kappa \\mu^{(i)^T} \\hat{z})} = \\frac{\\exp (\\mu^{(c)^T} \\hat{z} / \\tau)}{\\sum_{i=1}^C \\exp (\\mu^{(i)^T} \\hat{z} / \\tau)},$ (4)\nwhere $\\tau = 1/\\kappa$ is a temperature parameter. In this way, the classification problem is transferred to the distance measurement between the graph embedding and the prototype of each class in hyperspherical space, where the class prototype is usually defined as the embedding centroid of each class."}, {"title": "4 Methodology", "content": "In this section, we present the proposed method, Multi-Prototype Hyperspherical Invariant Learning (MPHIL). In Sec. 4.1, we first derive our general framework based on the learning objective graph invariant learning (GIL). Then, we describe the specific designs of the components in MPHIL, including hyperspherical invariant representation learning (Sec. 4.2), multi-prototype classifier (Sec. 4.3), and learning objectives (Sec. 4.4). The overall learning pipeline of MPHIL is shown in Fig. 2."}, {"title": "4.1 Hyperspherical Graph Invariant Learning Framework", "content": "The objective of GIL (i.e., Eq. (2)) aims to maximize the mutual information between the invariant representation $z_{inv}$ and the label $y$, while ensuring that $z_{inv}$ remains independent of the environment $e$. However, directly optimizing this objective with such strict constraints is challenging due to the difficulty of modeling environments in graph data. To make the optimization more tractable, we relax the independence constraint and introduce a soft-constrained formulation:\n$\\min_{f_c,g} -I(y; z_{inv}) + \\beta I(z_{inv}; e),$ (5)\nwhere $e$ represents the environment to which the current graph belongs, but it cannot be directly observed or accessed. The parameter $\\beta$ controls the trade-off between the predictive power of $z_{inv}$ and its independence from the environment $e$.\nAlthough the relaxed objective Eq. (5) is more feasible, the intractable properties of real-world graph data (i.e., complex environment information and inter-class semantic cliff as discussed in Sec. 1) still hinder us from learning reliable invariant representations and making accurate predictions with this objective. Specifically, the diversity and complexity of environments make it challenging to explicitly model $e$, leading to the difficulties of minimizing $I(z_{inv}; e)$."}, {"title": "4.2 Hyperspherical Invariant Representation Extraction", "content": "Encoder. In GIL, the goal of the encoder $f$ is to extract invariant representations that are highly correlated with the invariant subgraph of each sample. Nevertheless, explicitly identifying the subgraphs via modeling the selecting probabilities of each node and edge may lead to increased overhead and require more complex network architectures [59]. To mitigate these costs, we adopt a lightweight GNN-based model for efficient invariant representation learning. To be specific, our model includes two GNNS: $\\text{GNN}_E$ to encode the input graph $G$ into the latent space, producing the node representation $H$, and $\\text{GNN}_S$ to compute the separation score $S$ for the invariant features:\n$H = \\text{GNN}_E(G) \\in \\mathbb{R}^{|V| \\times d}, S = \\sigma(\\text{GNN}_S(G)) \\in \\mathbb{R}^{|V| \\times d},$ (7)\nwhere $|V|$ is the number of nodes in the graph $G$, $d$ is the latent dimension, and $\\sigma(\\cdot)$ is the Sigmoid function to constrain $S$ falls into the range of (0, 1). Then, the invariant representation $z_{inv}$ is obtained through the following operation:\n$z_{inv} = \\text{READOUT}(H \\odot S) \\in \\mathbb{R}^d,$ (8)"}, {"title": "4.3 Multi-Prototype Hyperspherical Classifier", "content": "Following hyperspherical projection, the next step is to construct a prototype-based classifier within the hyperspherical space. In conventional hyperspherical learning approaches [18], each class is typically assigned a single prototype. Although this is a straightforward solution, its modeling capabilities regarding decision boundaries are limited, as it may not adequately capture the complexity of the data distribution. More specifically, a single prototype often overfits easy-to-classify samples while failing to consider the harder samples. To address this limitation, we propose a multi-prototype hyperspherical classifier in which each class is represented by multiple prototypes. This multi-prototype approach ensures that the classification decision space is more flexible and comprehensive, enabling better modeling of intra-class invariance and inter-class separation. In the following paragraphs, we will explain how to initialize, update, and use the prototypes for prediction.\nPrototype Initialization. For each class $c \\in {1,..., C}$, we assign $K$ prototypes for it, and they can be denoted by $M^{(c)} \\in \\mathbb{R}^{K\\times d} = {\\mu_k^{(c)}}_{k=1}^K$. At the beginning of model training, we initialize each of them by $\\mu_k^{(c)} \\sim \\mathcal{N}(0, I)$, where $\\mathcal{N}(0, I)$ represents a standard multivariate Gaussian distribution. Random initialization can help prevent the issue of mode collapse.\nPrototype Updating. To ensure that the prototypes can represent the majority of samples in their corresponding classes while preserving cross-distribution stability, we adopt the exponential moving average (EMA) technique to update the prototypes asynchronously according to invariant representation $\\hat{z}_{inv}$. Specifically, the update rule for a batch of $B$ samples is given by:\n$\\mu_k^{(c)} := \\text{Norm} \\left(\\alpha \\mu_k^{(c)} + (1 - \\alpha) \\frac{1}{B} \\sum_{i=1}^B \\mathbb{1}(y_i = c) W_{i,k}^{(c)} \\hat{z}_{inv,i}\\right),$ (10)\nwhere $\\alpha$ is the EMA update rate, $W_{i,k}^{(c)}$ is the weight of the $i$-th sample for prototype $k$ in class $c$, $\\hat{z}_{inv,i}$ is the representations of the $i$-th sample, and $\\mathbb{1}(y_i = c)$ is an indicator function that ensures the update applies only to samples of class $c$. After each update, the prototype is normalized to maintain its unit norm, ensuring it remains on the hypersphere and the distance calculations take place in the same unit space as $\\hat{z}_{inv,i}$. Each representation $\\hat{z}_{inv, i}$ is associated with multiple prototypes, weighted by the assignment weight vector $W_i^{(c)} \\in \\mathbb{R}^K$.\nAssignment Weight Calculation. To ensure that each sample is matched with the most relevant prototype, we introduce an"}, {"title": "4.4 MPHIL Learning Objectives", "content": "In this subsection, we formulate the learning objective terms of MPHIL in Eq. (6), including the invariant prototype matching loss $\\mathcal{L}_{IPM}$, prototype separation loss $\\mathcal{L}_{PS}$, and the classification loss $\\mathcal{L}_{C}$. For $\\mathcal{L}_{IPM}$ and $\\mathcal{L}_{PS}$, we formulate them with contrastive learning loss, which is proved to be an effective mutual information estimator [41, 44, 53]. For the term of $-I(y; \\hat{z}_{inv}, \\mu^{(y)})$, we show in the Appendix A.2 that it can be implemented with classification loss.\nInvariant Prototype Matching Loss $\\mathcal{L}_{IPM}$. The challenge of disentangling invariant features from environmental variations lies at the heart of OOD generalization. In our formulation, the misalignment of a sample with an incorrect prototype can be seen as a signal of environmental interference. In contrast, successful alignment with the correct prototype reflects the capture of stable and invariant features. Motivated by this, we design $\\mathcal{L}_{IPM}$ that operates by reinforcing the proximity of samples to their invariant representations and penalizing the influence of environmental factors, implicitly captured through incorrect prototype associations. The loss function is expressed as follows:\n$\\mathcal{L}_{IPM} = - \\frac{1}{B} \\sum_{i=1}^B \\log \\frac{\\exp(\\hat{z}_i^T \\mu^{(c)} / \\tau)}{\\exp(\\hat{z}_i^T \\mu^{(c)} / \\tau) + \\sum_{\\hat{c}\\neq y} \\exp(\\hat{z}_i^T \\mu^{(\\hat{c})} / \\tau)},$ (13)\nwhere $B$ represents the batch size, with $i$ indexing each sample in the batch. $\\hat{z}_i$ represents the hyperspherical invariant representation, $\\mu^{(c)}$ is the correct class prototype, $\\mu^{(\\hat{c})}$ denotes the prototypes of the incorrect classes $\\hat{c} \\neq y_i$, and $\\tau$ is a temperature factor. This formulation reflects the dual objective of pulling samples towards their class-invariant prototypes while ensuring that the influence of prototypes associated with environmental shifts is minimized. The numerator reinforces the similarity between the sample's invariant representation and its correct prototype, while the denominator introduces competition between correct and incorrect prototypes, implicitly modeling the influence of environmental noise.\nPrototype Separation Loss $\\mathcal{L}_{PS}$. In hyperspherical space, all invariant $\\hat{z}$ representations are compactly clustered around their respective class prototypes. To ensure inter-class separability, prototypes of different classes must be distinguishable. The prototype separation loss $\\mathcal{L}_{PS}$ is designed to enforce this by maximizing the separation between prototypes of different classes while encouraging the similarity of prototypes within the same class. The loss function is defined as:\n$\\mathcal{L}_{PS} = -\\frac{1}{C K^2} \\sum_{c=1}^C \\sum_{k=1}^K \\sum_{c'=1}^C \\sum_{k'=1}^K \\log \\frac{\\sum_{\\mathbb{1}(c' == c)} \\exp((\\mu_k^{(c)})^T \\mu_{k'}^{(c)} / \\tau)}{\\sum_{\\mathbb{1}(c' \\neq c)} \\exp((\\mu_k^{(c)})^T \\mu_{k'}^{(c')} / \\tau)},$ (14)\nwhere $C$ represents the total number of classes, $K$ denotes the number of prototypes assigned to each class, $\\mu_k^{(c)}$ and $\\mu_{k'}^{(c)}$ correspond to different prototypes within the same class $\\mu_k^{(c)}$ and $\\mu_{k'}^{(c')}$ represent prototypes from different classes, and $\\mathbb{1}(c' \\neq c)$ represents prototypes from different classes. Such an indicator function ensures that the comparisons are made between distinct prototypes, enhancing intra-class similarity and inter-class separation.\nClassification Loss $\\mathcal{L}_{C}$. To calculate the classification loss with the multi-prototype classifier, we update the classification probability in Eq. (12) to be closed to truth labels with a classification loss. Take multi-class classification as example, we use the cross-entropy loss:\n$\\mathcal{L}_{C} = - \\frac{1}{BC} \\sum_{i=1}^B \\sum_{c=1}^C y_{ic} \\log(p(y = c \\mid \\hat{z}_i; {w_c, \\mu^{(c)}}_{c=1}^C)).$ (15)\nWith the above loss terms, the final objective of MPHIL can be written as $\\mathcal{L} = \\mathcal{L}_{C} + \\mathcal{L}_{PS} + \\beta \\mathcal{L}_{IPM}$. The pseudo-code algorithm and complexity analysis of MPHIL is provided in Appendix B."}, {"title": "5 Experiments", "content": "In this section, we present our experimental setup (Sec. 5.1) and showcase the results in (Sec. 5.2). For each experiment, we first highlight the research question being addressed, followed by a detailed discussion of the findings."}, {"title": "5.1 Experimental Setup", "content": "Datasets. We evaluate the performance of MPHIL on two real-world benchmarks, GOOD [13] and DrugOOD [16], with various distribution shifts to evaluate our method. Specifically, GOOD is a comprehensive graph OOD benchmark, and we selected three datasets: (1) GOOD-HIV [51], a molecular graph dataset predicting HIV inhibition; (2) GOOD-CMNIST [2], containing graphs transformed from MNIST using superpixel techniques; and (3) GOOD-Motif [50], a synthetic dataset where graph motifs determine the label. DrugOOD is designed for AI-driven drug discovery with three types of distribution shifts: scaffold, size, and assay, and applies"}, {"title": "5.2 Performance Comparison", "content": "In this experiment, we aim to answer Q1: Whether MPHIL achieves the best performance on OOD generalization benchmarks? The answer is YES, since MPHIL Shows the best results on the majority of datasets. Specifically, we have the following observations.\n\u25b7 State-of-the-art results. According to Table 1, MPHIL achieves state-of-the-art performance on 9 out of 11 datasets, and secures the second place on the remaining dataset. The average improvements against the previous SOTA are 2.17% on GOOD and 1.68% on DrugOOD. Notably, MPHIL achieves competitive performance across various types of datasets with different data shifts, demonstrating its generalization ability on different data. Moreover, our model achieves the best results in both binary and multi-class tasks, highlighting the effectiveness of the multi-prototype classifier in handling different classification tasks.\n\u25ba Sub-optimal performance of environment-based methods. Among all baselines, environment-based methods only achieve the best performance on 3 datasets, while architecture-based OOD generalization methods achieve the best results on most datasets. These observations suggest that environment-based methods are limited by the challenge of accurately capturing environmental information in graph data, leading to a discrepancy between theoretical expectations and empirical results. In contrast, the remarkable performance of MPHIL also proves that graph OOD generalization can still be achieved without specific environmental information."}, {"title": "5.3 Ablation Study", "content": "We aim to discover Q2: Does each module in MPHIL contribute to effective OOD generalization? The answer is YES, as removing any key component leads to performance degradation, as demonstrated by the results in Table 2. We have the following discussions.\n\u25b7 Ablation on $\\mathcal{L}_{IPM}$ and $\\mathcal{L}_{PS}$. We remove $\\mathcal{L}_{IPM}$ and $\\mathcal{L}_{PS}$ in the Eq. (6) respectively to explore their impacts on the performance of"}, {"title": "5.4 Visualized Validation", "content": "In this subsection, we aim to investigate Q3: Can these key designs (i.e., hyperspherical space and multi-prototype mechanism) tackle two unique challenges in graph OOD generalization tasks? The answer is YES, we conduct the following visualization experiments to verify this conclusion.\n\u25ba Hyperspherical representation space. To validate the advantage of hyperspherical space in enhancing class separability, we compare the 1-order Wasserstein distance [46] between same-class and different-class samples, as shown in Fig. 4(a). It is evident that MPHIL produces more separable invariant representations (higher inter-class distance), while also exhibiting tighter clustering for samples of the same class (lower intra-class distance). In contrast, although traditional latent spaces-based SOTA achieves a certain level of intra-class compactness, its lower separability hinders its overall performance. Additionally, we visualized the sample representations learned by our MPHIL and SOTA using t-SNE in Fig. 4(b), where corresponding phenomenon can be witnessed.\n\u25b7 Prototypes visualization. We also reveal the characteristics of prototypes by visualizing samples that exhibit the highest similarity to each prototype. Fig. 5 shows that prototypes from different classes capture distinct invariant subgraphs, ensuring a strong correlation with their respective labels. Furthermore, within the same category, different prototypes encapsulate samples with varying environmental subgraphs. This validates that multi-prototype learning can effectively capture label-correlated invariant features without explicit environment definitions, which solve the challenges of out-of-distribution generalization in real-world graph data."}, {"title": "5.5 In-Depth Analysis", "content": "In this experiment, we will investigate Q4: How do the details (hyperparameter settings and variable designs) in MPHIL impact performance? The following experiments are conducted to answer this question and the experimental results are in Fig. 3."}, {"title": "6 Conclusion", "content": "In this work, we introduce a novel graph invariant learning framework integrated with hyperspherical space and prototypical learning, ensuring that the learned representations are both environment-invariant and class-separable without relying on environmental information. Building upon this framework, we present a new graph out-of-distribution generalization method named MPHIL. MPHIL achieves inter-class invariance and intra-class separability by optimizing two effective loss functions and leverages class prototypes, defined as the mean feature vectors of each category, to eliminate dependency on individual prototypes. Experimental evaluations on benchmarks demonstrate the effectiveness of MPHIL."}, {"title": "A MPHIL Objective Deductions", "content": ""}, {"title": "A.1 Proof of the overall objective", "content": "In this section, we explain how we derived our goal in Eq. (6) from Eq. (5). Let's recall that Eq. (5) is formulated as:\n$\\min_{f_c,g} -I(y; z_{inv}) + \\beta I(z_{inv}; e),$ (16)\nFor the first term $-I(y; z_{inv})$, since we are mapping invariant features to hyperspherical space, we replace $z_{inv}$ with $\\hat{z}_{inv}$. Then according to the definition of mutual information:\n$-I(y; z_{inv}) = - \\mathbb{E}_{y, \\hat{z}_{inv}} \\log \\frac{p(y, \\hat{z}_{inv})}{p(y)p(\\hat{z}_{inv})},$ (17)\nWe introduce intermediate variables $\\mu_y$ to rewrite Eq. (17) as:\n$-I(y; z_{inv}) = - \\mathbb{E}_{y, \\hat{z}_{inv}, \\mu_y} \\log \\frac{p(y, \\hat{z}_{inv}, \\mu_y)}{p(y)p(\\hat{z}_{inv} | \\mu_y) p(\\mu_y)},$ (18)\nBy the definition of Conditional mutual information, we have the following equation:\n$-I(y; z_{inv}) = -I(y; \\hat{z}_{inv}, \\mu_y) + I(y; \\mu_y | \\hat{z}_{inv}),$ (19)\n$-I(y; \\mu_y) = -I(y; \\hat{z}_{inv}, \\mu_y) + I(y; \\hat{z}_{inv}|\\mu_y)$.\nBy merging the same terms, we have:\n$-I(y; z_{inv}) = -I(y; \\mu_y) + [I(y; \\mu_y | \\hat{z}_{inv}) - I(y; \\hat{z}_{inv} | \\mu_y)].$ (20)\nSince our classification is based on the distance between $\\mu_y$ and $\\hat{z}_{inv}$, we add $-I(y; \\hat{z}_{inv}, \\mu_y)$ back into the above equation and obtain a lower bound:\n$-I(y; z_{inv}) \\geq -I(y; \\mu_y) + [I(y; \\mu_y | \\hat{z}_{inv}) - I(y; \\hat{z}_{inv}| \\mu_y)] - I(y; \\hat{z}_{inv}, \\mu_y).$ (21)\nSince the $\\mu_y$ are updated by $\\hat{z}_{inv}$ from the same class, we can approximate $I (y; \\mu_y | \\hat{z}_{inv})$ equal to $I(y; \\hat{z}_{inv} | \\mu_y)$ and obtain the new lower bound:\n$-I(y; z_{inv}) \\geq -I(y; \\mu_y) - I(y; \\hat{z}_{inv}, \\mu_y).$ (22)\nFor the second term $I(z_{inv}; e)$, we can also rewrite it as:\n$I(z_{inv}; e) = I(\\hat{z}_{inv}; e, \\mu_y) - I(\\hat{z}_{inv}; \\mu_y | e).$ (23)\nGiven that the environmental labels $e$ are unknown, we drop the term $I(\\hat{z}_{inv}; e, \\mu_y)$ as it cannot be directly computed. This leads to the following lower bound:\n$I(z_{inv}; e) \\geq -I(\\hat{z}_{inv}; \\mu_y | e).$ (24)\nWe can obtain a achievable target by Eq. (22) and Eq. (24) as follow:\n$-I(y; z_{inv}) + \\beta I(z_{inv}; e) \\geq -I(y; \\mu_y) - I(y; \\hat{z}_{inv}, \\mu_y) - \\beta I(\\hat{z}_{inv}; \\mu_y | e).$ (25)\nIn fact, $p(\\hat{z}_{inv}, \\mu_y | e) \\geq p(\\hat{z}_{inv}; \\mu_y)$, Eq. (25) can be achieved by:\n$-I(y; z_{inv}) + \\beta I(z_{inv}; e) \\geq -I(y; \\mu_y) - I(y; \\hat{z}_{inv}, \\mu_y) - \\beta I(\\hat{z}_{inv}; \\mu_y).$ (26)\nFinally, optimizing Eq. (5) can be equivalent to optimizing its lower bound and we can obtain the objective without environment $e$ as shown in Eq. (6):\n$\\min_{f_c,g} -I(y; \\hat{z}_{inv}, \\mu^{(y)}) -I(y; \\mu^{(y)}) -\\beta I(\\hat{z}_{inv}; \\mu^{(y)}).$ (27)\n$\\mathcal{L}_C$   $\\mathcal{L}_{PS}$   $\\mathcal{L}_{IPM}$"}, {"title": "A.2 Proof of $\\mathcal{L}_C$", "content": "For the term $I(y; \\hat{z}_{inv}, \\mu^{(y)})$, it can be written as:\n$I(y; \\hat{z}_{inv}, \\mu^{(y)}) = \\mathbb{E}_{y, \\hat{z}_{inv}, \\mu_y} \\log \\frac{p(y|\\hat{z}_{inv}, \\mu^{(y)})}{p(y)},$ (28)\naccording to [39], we have:\n$I(y; \\hat{z}_{inv}, \\mu^{(y)}) \\geq \\mathbb{E}_{y, \\hat{z}_{inv}, \\mu_y} \\log \\frac{q_\\theta(y|\\gamma(\\hat{z}_{inv}, \\mu^{(y)}))}{p(y)},$ (29)\nwhere $\\gamma(\\cdot, \\cdot)$ is the function to calculate the similarity between $\\hat{z}_{inv}$ and $\\mu_y$. $q_\\theta(y|\\gamma(\\hat{z}_{inv}, \\mu^{(y)}))$ is the variational approximation of the $p(y|\\gamma(\\hat{z}_{inv}, \\mu^{(y)}))$. Then we can have:\n$\\begin{aligned} I(y; \\hat{z}_{inv}, \\mu^{(y)}) &\\geq \\mathbb{E}_{y, \\hat{z}_{inv}, \\mu_y} [\\log q_\\theta(y|\\gamma(\\hat{z}_{inv}, \\mu^{(y)}))] - \\mathbb{E}_y [\\log p(y)] \\\\ &\\geq \\mathbb{E}_{y, \\hat{z}_{inv}, \\mu_y} [\\log q_\\theta(y|\\gamma(\\hat{z}_{inv}, \\mu^{(y)}))] \\\\ &:= -\\mathcal{L}_{C}. \\end{aligned}$ (30)\nFinally, we prove that $\\min I(y; \\hat{z}_{inv}, \\mu^{(y)})$ is equivalent to minimizing the classification loss $\\mathcal{L}_{C}$."}, {"title": "B Methodology Details", "content": ""}, {"title": "B.1 Overall Algorithm of MPHIL", "content": "The training algorithm of MPHIL is shown in Algorithm. 1. After that, we use the well-trained $\\text{GNNS}, \\text{GNNE}, \\text{Proj}$ and all prototypes $M"}]}