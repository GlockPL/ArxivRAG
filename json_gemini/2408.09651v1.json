{"title": "Data-driven Conditional Instrumental Variables for Debiasing Recommender Systems", "authors": ["Zhirong Huang", "Shichao Zhang", "Debo Cheng", "Jiuyong Li", "Lin Liu", "Guangquan Lu"], "abstract": "In recommender systems, latent variables can cause user-item interaction data to deviate from true user preferences. This biased data is then used to train recommendation models, further amplifying the bias and ultimately compromising both recommendation accuracy and user satisfaction. Instrumental Variable (IV) methods are effective tools for addressing the confounding bias introduced by latent variables; however, identifying a valid IV is often challenging. To overcome this issue, we propose a novel data-driven conditional IV (CIV) debiasing method for recommender systems, called CIV4Rec. CIV4Rec automatically generates valid CIVs and their corresponding conditioning sets directly from interaction data, significantly reducing the complexity of IV selection while effectively mitigating the confounding bias caused by latent variables in recommender systems. Specifically, CIV4Rec leverages a variational autoencoder (VAE) to generate the representations of the CIV and its conditional set from interaction data, followed by the application of least squares to derive causal representations for click prediction. Extensive experiments on two real-world datasets, Movielens-10M and Douban-Movie, demonstrate that our CIV4Rec successfully identifies valid CIVs, effectively reduces bias, and consequently improves recommendation accuracy.", "sections": [{"title": "Introduction", "content": "With the rapid development of the Internet, the amount of information has exploded, making it increasingly difficult for users to sift through vast amounts of data to find content that aligns with their preferences (Gao et al. 2021). Recommender systems have emerged as a critical solution to this problem by analysing user behaviour data to deliver personalised recommendations, thereby enhancing user engagement and satisfaction (Wang et al. 2020). These systems have become an integral part of many digital platforms, finding extensive applications across various domains, including e-commerce (Shoja and Tabrizi 2019), streaming media (Gomez-Uribe and Hunt 2015), and social networks (Liao et al. 2022), significantly improving information retrieval efficiency and user experience.\nUser behaviour data is crucial for recommender systems in predicting user preferences. Existing models often assume this data is unbiased and accurately reflects user preferences, meaning the data accurately reflects user preferences. Based on this assumption, many methods have been proposed, such as Matrix Factorisation (MF) (Koren, Bell, and Volinsky 2009) and Neural Network-based Collaborative Filtering (NCF) (He et al. 2017). These methods achieve the goal of predicting user preferences by fitting user behaviour data, as depicted in the causal directed acyclic graph (DAG) (Pearl 2009) shown in Figure 1 (a), which illustrates the causal relationships between user preferences (U) and user feedback (Y), as well as between displayed items (I) and Y. However, in the real-world, user behaviour is inevitably influenced by various unobservable confounding factors, such as item popularity (e.g., frequent recommendation of an item limits users' choices) and user psychology (e.g., choosing to watch a movie for socialising) (Chen et al. 2023). These factors introduce biases like popularity and conformity bias, leading models to learn false correlations and reducing their ability to accurately predict preferences.\nCausal inference techniques have been utilised to mitigate bias in recommender systems (Wang et al. 2020; Gao et al. 2024). These methods leverage domain knowledge to design causal DAGs that t represent the data generation process, identify specific biases, and develop models to address them. For example, Zhang et al. (Zhang et al. 2021) proposed a novel causal graph (Figure 1 (b)) that analyses how item popularity affects recommendations. Based on this graph, they introduced the Popularity-bias Deconfounding and Adjusting (PDA) training paradigm to mitigate popularity bias. Similarly, Zheng et al. (Zheng et al. 2021) examined the impact of users' conformity mentality and proposed the Disentangling Interest and Conformity with Causal Embedding (DICE) method to address conformity bias. While these causal graph-based approaches have shown some success, they rely on the assumption that the data generation process strictly follows the proposed causal graph. If real-world conditions deviate significantly from these assumptions, their effectiveness may be limited (Cai et al. 2024). Moreover, the presence of numerous confounding factors in real-world scenarios makes it challenging to satisfy these assumptions.\nLatent confounding factors pose a significant challenge in debiasing recommender systems. These latent factors (a.k.a. unobserved or unmeasured variables) influence both the treatment (e.g., the recommendation process) and the outcome, leading to biased recommendations. Instrumental Variables (IVs) are often used to eliminate bias caused by latent variables (Caner and Hansen 2004; Pearl 2009), i.e., Z is an IV as shown in Figure 1 (c). A standard IV must meet three conditions (Pearl 2009): (i) relevance to the treatment variable; (ii) an exclusive impact on the outcome through the treatment; and (iii) no shared confounders with the outcome. Several debiasing methods for recommender systems based on standard IVs have been developed to address latent confounding factors without relying on strict causal graph assumptions (Si et al. 2022, 2023a,b). For instance, IV4Rec (Si et al. 2022) uses self-collected search data as an IV to effectively mitigate latent confounding. However, verifying the last two conditions of a standard IV using data alone is infeasible (Brito and Pearl 2012; Cheng et al. 2023), making it challenging to identify valid IVs.\nIn causal inference, researchers have used conditional IVs (CIVs) (definitions provided in the Appendix) to tackle the limitations of standard IVs (Pearl 2009; Brito and Pearl 2012). CIVs offer more relaxed application conditions than standard IVs. Recently, Cheng et al. (Cheng et al. 2023) developed a CIV method (CIV.VAE) based on the variational autoencoder (VAE) (Kingma and Welling 2013; Sch\u00f6lkopf et al. 2021; Sch\u00f6lkopf 2022) model, which generates CIVs and their conditional sets from data, significantly relaxing the constraints of standard IVs. However, this method is designed for tabular data, and no attempt has been made to adapt it to interactive data in recommender systems.\nTo address the challenge of using CIV in interactive data, we first propose a causal DAG, as shown in Figure 2, to represent the causal relationships between observed and latent variables in interaction data within recommender systems. Building on this causal DAG, we develop a novel data-driven CIV debiasing method for recommender systems, termed CIV4Rec. Specifically, CIV4Rec uses the embeddings of user-item pairs (including users with the selected items, i.e., positive samples, and users with their pre-selected items, i.e., negative samples) as the treatment variable W, the user feedback as the outcome Y, and the user interaction data (only positive samples) as the pretreatment variable X. We assume that at least one CIV exists within X, capturing latent information such as user search behaviours that lead to interactions. CIV4Rec employs a VAE to generate the representations of the CIV and its conditional set from X, denoted as Zt and Ze, as shown in Figure 2. The contribution of our work is summarised below:\n\u2022 We propose a novel causal DAG to represent the causal relationships between observed and latent variables in interaction data within recommender systems.\n\u2022 We develop a novel data-driven CIV method (CIV4Rec), for learning representations of CIVs and its conditional sets under the proposed causal DAG. To the best of our knowledge, this is the first work to generate representations of CIVs and their conditional sets from interaction data for mitigating bias in recommender systems.\n\u2022 Extensive experiments on two real-world datasets demonstrate that CIV4Rec achieves optimal debiasing results and recommendation performance compared to state-of-the-art causal debiasing methods."}, {"title": "Related Work", "content": "In this section, we review the recommender methods most closely related to our CIV4Rec, including traditional recommender methods and causal recommender methods."}, {"title": "Traditional Recommender Methods", "content": "Traditional recommender methods, primarily based on Collaborative Filtering (CF), typically assume that user behaviour data is unbiased (Koren, Rendle, and Bell 2021). The mainstream approach is model-based CF, which trains a model on user behaviour data to recommend items that align with user preferences. A classic method is MF (Koren, Bell, and Volinsky 2009), which decomposes the user-item rating matrix to predict preferences. However, MF assumes that unselected items are incompatible with user preferences, ignoring cases where users may not have encountered those items. To address this, Rendle et al. (Rendle et al. 2012) proposed Bayesian Personalized Ranking (BPR), which as-"}, {"title": "Causal Recommender Methods", "content": "To mitigate biases in recommender systems, researchers have increasingly adopted causal inference techniques. Early approaches used the Inverse Propensity Score (IPS) (Wang et al. 2021; Schnabel et al. 2016; Bottou et al. 2013) to reduce bias by assigning an inverse propensity score (e.g., the inverse of item popularity) to user-item interactions during training, balancing the influence of popular and less popular items. However, IPS methods often suffer from high variance and instability. Building on IPS success, researchers have explored causal graph-based methods (Zheng et al. 2021; He et al. 2023; Zhang et al. 2021) that model the generation mechanisms of user behaviour. These methods design specific models to address biases like popularity and conformity bias. Yet, the presence of unobserved confounders in real-world data limits the effectiveness of these causal graph assumptions (Cai et al. 2024).\nIVs are commonly used in causal inference to address confounding. Recently, methods leveraging user search data as IVs have emerged, with the IV4Rec framework by Si et al. (Si et al. 2022) being a notable example. IV4Rec uses user search data to decompose user-item representations into causal and non-causal components, addressing some limitations of causal graph-based methods and reducing bias. However, identifying valid user search data as IVs remains challenging. Unlike these approaches, our work focuses on learning the representations of CIVs and their conditional sets, which are less restrictive than standard IVs."}, {"title": "The Proposed CIV4Rec Method", "content": "In this section, we first introduce the problem definition, then explain the feasibility and rationality of our method by the causal graph, and then introduce the four main steps of our method. The overall workflow of our proposed CIV4Rec is visualised in Figure 3."}, {"title": "Problem Definition", "content": "In the recommender system, user behaviour data D usually consists of a user set U and an item set I. D contains two parts, namely: user u and selected items p to form positive sample pairs, and user u and pre-selected items n to form negative sample pairs. The user interaction data X consists of positive sample pairs derived from D. X implicitly contains a wealth of information, including user interactions stemming from search behaviours.\nIn recommendation models, users and items are usually represented as low-dimensional embedding representations W, and the corresponding user-item pairs can be represented as W = {(Wu, Wi) |u \u2208 U, i \u2208 I}. However, in addition to reflecting user preferences, user behaviour data D contains spurious correlations caused by various latent confounding factors Uc (e.g., item exposure, conformity influence). Although existing methods have mitigated the impact of these confounding factors to some extent through causal inference techniques, they often come with strong assumptions. We aim to address this challenging problem in our work, and our problem definition is described as follows.\nDefinition 1. In a recommender system, the latent variables Uc affect the choice made and introduce bias. We assume that at least one CIV exists within X, capturing latent information that leads to interactions. The causal relationships between measured and latent variables are shown in Figure 2. Our goal is to learn the representations of the CIV Zt and its conditional set Ze from the user interaction data X to address the confounding biases introduced by Uc."}, {"title": "The Proposed Causal DAG", "content": "In this work, we proposed a causal DAG G as shown in Figure 2 to represent the causal relationships between measured and latent variables. Let Gw be the manipulated graph, obtained by deleting all arrows emerging from nodes in W within G. In Gw, Zt and W are d-connected when conditioned on Ze because of the existence of the edge Zt \u2192 W. However, Zt and Y are d-separated by Ze since Zt, Ze and Uc form a collider at W, and Ze blocks the path Zt \u2190 Zc\u2192 Y. Furthermore, the effect of Zt on Y is mediated solely by W through the causal path Zt \u2192 W \u2192 Y. Therefore, Zt is a CIV, and Ze is its corresponding conditional set. Note that Ze may contain information about latent factors Uc due to the complex relationships in interactive data, as indicated by the dashed line between Uc and Zc (Wu et al. 2022; Cheng et al. 2024). Many existing works have shown that confounding factors can affect recommendation outcomes, specifically Ze \u2192 Y (Si et al. 2022, 2023a,b). Additionally, since Zt and Ze are derived from the user interaction data X, they will affect W, i.e., Zt \u2192 W and Zc\u2192 W in G.\nBased on the proposed causal DAG, we introduce a data-driven CIV method for debiasing recommender systems called CIV4Rec. The advantages of CIV4Rec over existing debiasing methods are twofold: it does not require the specification of IVs through domain knowledge, and it uses CIV, which is more general than IV-based methods for addressing confounding bias caused by latent factors."}, {"title": "The Concepts of Treatment Variable, CIV and Its Conditional Set", "content": "We define the concepts for the treatment variable, the CIV, and its conditional set based on user behaviour data. The treatment variable Wu,i using user-item pairs is defined as:\n\\(W_{u,i} = \\{(W_u, W_i) |u \\in U, i \\in I\\},\n                                                                        (1)\\)\nwhere wu and wi represent the embeddings of user u and item i, respectively. The concepts for the representations of CIV Zt and its conditional set Ze from the user interaction data X are as follows:\n\\(Z_t = \\{(z_{tu}, z_{tp}) | u, p \\in X\\},\\)\n\\(Z_c = \\{(z_{cu}, z_{cp}) | u, p \\in X\\},\\)\nwhere ztu and zc\u2081 indicate the representations of the CIV of the user u and its conditional set, respectively, ztp and zcp denote the representations of CIV of the corresponding item p and its conditional set, respectively."}, {"title": "Learning the Representations of CIV and Its Condition Set", "content": "In our CIV4Rec, we employ a VAE structure as our generative model for generating the representations of the CIV Zt and its conditional set Ze (Kingma and Welling 2013; Sohn, Lee, and Yan 2015) from the user interaction data X, referred to as the CIV and conditional Set Extraction Module (CSEM). We use the inference and generation networks of VAE to approximate the posterior distributions p (Zt|X) and p (Zc|X) for the two representations Zt and Zc.\nIn the inference network, we use two independent encoders to learn the posterior distributions q (Zt|X) and q (Zc|X). The variational approximations of their posterior distributions are as follows:\n\\(q(Z_t|X) = \\prod_{m=1}^{D_{Z_t}} N(\\mu = \\mu_{Z_{tm}}, \\sigma^2 = \\sigma^2_{Z_{tm}}),\\)\n\\(q(Z_c|X) = \\prod_{m=1}^{D_{Z_c}} N(\\mu = \\mu_{Z_{cm}}, \\sigma^2 = \\sigma^2_{Z_{cm}}),\\)\nwhere \u03bcand \u03c3 are the mean and variance of the Gaussian distribution captured by neural networks. It is worth noting that Zt and Ze are composed of pairs of user and item samples, so each q (Zt|X) and q (Zc|X) has two components: item and user. In the generative network, the prior distribution p (Zt) follows a Gaussian distribution:\n\\(p(Z_t) = \\prod_{m=1}^{D_{Z_t}} N(Z_{tm}|0, I).\\)\nThe prior distribution p (Zc) is obtained based on the conditional VAE (CVAE) (Sohn, Lee, and Yan 2015) model. We use Monte Carlo (MC) sampling to condition p(Zc) on X:\n\\(Z_c \\sim p(Z_c|X).\\)\nThen, the decoder for X is described as follows:\n\\(p(X|Z_t, Z_c) = \\prod_{m=1}^{D_X} p (X_m|Z_t, Z_c).\\)\nFor inference, we optimise the parameters by maximising the evidence lower bound (ELBO):\n\\(L_{civ} = E_q [log p (X|Z_t, Z_c)] - D_{KL}[q (Z_t|X) ||p (Z_t)] - D_{KL}[q (Z_c|X) ||p (Z_c|X)].\\)\nNote that using CVAE to condition p(Zc) on X is a critical step for learning the representations of Ze and Zt because Ze and Zt are independent given X, which ensures that Zt captures the CIV information, while Ze capture the confounding information given X in the interactive data."}, {"title": "Decomposition of Treatment Variable", "content": "After obtaining the representations of CIV (Zt) and its conditional set (Zc) from X, we use the CIV (Zt) to reconstruct the treatment variable (W) and decompose W to derive the causal relationship, specifically, user preference. We apply the least squares (LS) method based on IV4Rec (Si et al. 2022) to decompose W and obtain the representation Wu,i that is not affected by Uc:\n\\(W_{u,i}^{\\perp}= f_{pro} (Z_t, W_{u,i}),\\)\nwhere fpro is the projection function that maps Zt and Wu,i into the same space, allowing the unbiased Wu,i. The function fpro() is defined as:\n\\(f_{pro} (Z_t, W_{u,i}) = Z_t^+ \u00b7 W_{u,i},\\)\nwhere Wu,i is the closed-form solution of the LS method, and its calculation formula is as follows:\n\\(W_{u,i} = arg \\min_{W_{u, i}} || Z_t \u00b7 W_{u, i} - W_{u,i}||^2 = Z_t^+ \u00b7 W_{u,i},\\)\nwhere \\(Z_t^+\\) is the Moore-Penrose pseudo-inverse of Zt. Thus, the decomposed Wu,i captures the causal relationship from Zt while separating the latent confounding bias introduced by Uc, which reflects user preferences. Additionally, we need to incorporate Ze to obtain the reconstructed Wre, as Ze blocks the confounding bias between Zt and Y. Therefore, our final reconstructed Wre is obtained by:\n\\(W_{u,i}^{re} = W_{u,i}^{\\perp}+ (1 \u2212 \u03b1)Z_c,\\)\nwhere \u03b1 is a hyperparameter used to balance Wu,i and Zc."}, {"title": "Click Prediction", "content": "Click prediction is the core task of a recommender system, with the goal of predicting user preferences. BPR loss is a commonly used optimization method for click prediction. We use BPR loss to optimize the reconstructed treatment variables to enhance click prediction:\n\\(L_{click} = \\sum_{(u,p,n) \\in D} In \u03c3((w_{u,p}^{re}, w_{u,i}^{\\perp}) - (w_{u,n}^{re}, w_{u,i}^{\\perp})),\\)\nwhere (\u00b7) is the inner product operation. By combining the ELBO and BPR, the final loss function of our CIV4Rec is:\n\\(L_{total} = L_{civ} + L_{click}.\\)\nTherefore, our CIV4Rec obtain Wre for click prediction by learning the representations of CIV Zt and its condition set Ze from X and by decomposing W."}, {"title": "Experiments", "content": "In this section, we conduct experiments on two real-world datasets to validate the recommendation performance and debiasing effectiveness of CIV4Rec."}, {"title": "Experimental Settings", "content": "We introduce the datasets, baselines, and experimental parameters used in the experiments. Detailed parameter settings are provided in the Appendix due to the page limit."}, {"title": "Datasets", "content": "We use two publicly available real-world datasets: the Movielens-10M dataset (Harper and Konstan 2015) and the Douban-Movie dataset\u00b9. Both datasets include user IDs, movie IDs, and user ratings (1-5) for movies and are widely used in recommender system debiasing research. We binarized the datasets based on movie ratings, assigning a value of 1 to five-star ratings and 0 to the rest, and applied ten-core filtering to the data.\nWe follow the preprocessing steps used in DICE (Zheng et al. 2021) for the dataset. First, we randomly select 40% of the movie review data with the same probability (these data can be considered as unbiased and represent recommendation results under a completely random strategy). Then, we use 10% and 20% of the random data as the validation set and test set, respectively, to evaluate the model's debiasing performance on unbiased data. Finally, the remaining 10% of the random data and the other 60% of unselected samples form the training set. In other words, the training, validation, and test data are split in a 70:10:20 ratio. We include 10% unbiased data in the training set due to the requirements of CausE (Bonner and Vasile 2018). Table 1 shows the statistics of the processed datasets."}, {"title": "Baselines", "content": "Causal debiasing methods are typically used as adjunct techniques alongside a backbone recommendation model. In our experiments, we use the mainstream recommendation models, MF and LightGCN, as the backbone. We compare our approach with the following five debiased recommendation methods based on causality:\n\u2022 IPS (Schnabel et al. 2016): This method assigns weights that are the inverse of an item's popularity, thereby enhancing the impact of less popular items while reducing the influence of more popular ones.\n\u2022 IPS-C (Bottou et al. 2013): This approach caps the maximum value of IPS weights to reduce variance across the entire weight distribution.\n\u2022 CausE (Bonner and Vasile 2018): This method generates two sets of embeddings from the data, which are then aligned using regularization techniques to ensure their similarity.\n\u2022 DICE (Zheng et al. 2021): This method uses Structural Causal Modeling (SCM) (Pearl 2009) to define user-item interactions. This approach leverages the collision effect of causal reasoning to enhance training effectiveness.\n\u2022 DCCL (Zhao et al. 2023): This method uses contrastive learning to address data sparsity and the separation of these components."}, {"title": "Metrics", "content": "We evaluate Top-K recommendation performance on implicit feedback, a common setting in recommender systems. Top-K refers to the K items that the recommender system considers most relevant or attractive to the user, where K represents the number of items in the recommendation list. We use three frequently applied evaluation metrics: Recall, Hit Rate (HR), and NDCG, to evaluate all methods. The reported experimental results represent the optimal performance achieved by each method under its respective parameter settings.\nIt's important to note that we did not compare our CIV4Rec method with IV-based debiasing methods like IV4Rec (Si et al. 2022) since these methods require specifying a specific in IV based on domain knowledge or expert nomination, such as self-collected user search data. In contrast, our CIV4Rec model is designed to learn the representations of CIV and its conditional set directly from user interaction data. The datasets used in our experiments are not suitable for IV-based debiasing methods."}, {"title": "Comparison of Experimental Results", "content": "Tables 2 and 3 present the results of CIV4Rec and all baseline approaches on two real-world datasets. CIV4Rec-Causal is a variant of CIV4Rec that denotes click prediction using only the unbiased embeddings Wu,i, which capture the causal relationship. \u201cImp.\u201d represents the percentage improvement in Recall for each method compared to the original model. The best results are highlighted in bold, and the second-best results are underlined.\nThe analysis of Tables 2 and 3 shows that CIV4Rec and CIV4Rec-Causal significantly improve performance metrics compared to the original backbone, with the highest improvement reaching 39.71%, demonstrating statistical significance and the superiority of our approach. Notably, CIV4Rec consistently outperforms CIV4Rec-Causal, aligning with the understanding that incorporating appropriate confounders enhances recommendation performance. This confirms that Ze in CIV4Rec effectively captures relevant confounders in user interaction data.\nTables 2 and 3 reveal several key insights: (1) IPS-based debiasing methods perform poorly because they rely heavily on the inverse propensity score, which is closely tied to the data distribution. In our experiments, training was conducted on a biased dataset, while testing was performed on an unbiased dataset, leading to inconsistent data distributions between the training and validation sets. (2) Similarly, CausE showed suboptimal performance because it requires an unbiased dataset during training to align the user-item embedding representations. (3) Although DICE and DCCL, two debiasing methods based on causal graph assumptions, improve recommendation performance, they do not achieve optimal results. This is because these methods target specific biases based on assumed causal graphs, while real-world datasets often contain diverse biases due to latent confounding factors, limiting their effectiveness.\nNote that on the Movielens-10M dataset, while CIV4Rec's improvement with LightGCN appears marginal compared to DICE, it is statistically significant, with a p-value of less than 0.05. This can be attributed to CIV4Rec's ability to learn the CIV and its conditional set from interactive data, which reduces the typical constraints of such methods and effectively mitigates bias, leading to improved recommendation performance."}, {"title": "Evaluation on Debiasing Experiments Ability", "content": "We use the Intersection Over Union (IOU) (Zheng et al. 2021) metric to evaluate the debiasing ability of all methods. A higher IOU reflects more popular items in the recommendations, indicating weaker debiasing performance.\nFigure 4 shows the IOU curves for all methods on the Douban-movie dataset. CIV4Rec and CIV4Rec-Causal exhibit the lowest IOU, indicating superior debiasing ability. Notably, the IOU for all baseline methods increases significantly as the number of recommended items grows, suggesting that their debiasing ability diminishes with more recommendations. In contrast, the debiasing ability of our CIV4Rec and CIV4Rec-Causal remains relatively stable, demonstrating greater robustness.\nFigure 4 also illustrates that the IOU of CIV4Rec is higher than that of CIV4Rec-Causal, due to CIV4Rec incorporating confounding factor information. This suggests that Ze effectively captures confounding factors in user interaction data, validating our method."}, {"title": "Ablation Studies", "content": "We perform ablation studies to evaluate the effectiveness of each component in CIV4Rec. To verify the effectiveness of CIV and its condition set, we propose CIV4Rec-Con, which uses only Ze for click prediction. Figure 5 presents the IOU and Recall of CIV4Rec and its variants. The results show that CIV4Rec-Con has the highest IOU and lowest Recall, highlighting the effectiveness of Ze in capturing confounding factor information. In contrast, CIV4Rec-Causal exhibits higher Recall but lower IOU than CIV4Rec-Con, indicating its effectiveness in capturing user preference information and mitigating confounding factors through Zt. CIV4Rec, by integrating both user preference and confounding factor information, achieves higher Recall and IOU than CIV4Rec-Causal, demonstrating the combined effectiveness of Zt and Zc."}, {"title": "Conclusion", "content": "In this paper, we propose a data-driven CIV debiasing method called CIV4Rec. We learn the representations of CIV and its conditional set from user interaction data. The CIV is used to decompose the treatment variable and uncover the causal relationships between variables, while the conditional set captures confounding factors in the user interaction data. Unlike existing IV-based debiasing methods, CIV4Rec imposes fewer constraints and does not require the selection of specific IVs based on domain knowledge. By integrating confounding factors and the causal relationships of the treatment variable, CIV4Rec achieves high-quality recommendations and effective debiasing. We conducted extensive experiments on two real-world datasets to validate the effectiveness and superiority of CIV4Rec in both recommendation and debiasing performance."}, {"title": "Preliminaries", "content": "In this section, we will introduce the fundamental concepts of causal inference related to our main manuscript."}, {"title": "Directed Acyclic Graph", "content": "Causal graphs use Directed Acyclic Graphs (DAGs) to represent causal relationships between variables. In these graphs, nodes represent variables, and edges represent their relationships. Specifically, there are three classical DAGs used to describe causal relationships: the chain A \u2192 B \u2192 C, the fork A \u2190 B \u2192 C, and the collider A \u2192 B \u2190 C.\nIn the chain DAG A \u2192 B \u2192 C, A influences C through the intermediary B. In the fork DAG A \u2190 B \u2192 C, B is the confounder or common cause of A and C, meaning B influences both A and C, resulting in a correlation between A and C. However, this correlation does not imply a direct causal relationship between A and C. The collider structure A\u2192B C describes a situation where A and Care independent of each other but jointly influence the collision node B. In this case, A and C correlate when conditioned on B."}, {"title": "D-Separation", "content": "D-separation is a key concept in graphical models (Pearl 2009). It helps determine if a set of variables is conditionally independent given another set of variables within a DAG. It's an essential graph criterion for understanding conditional dependence or independence in a DAG.\nDefinition 2 (d-Separated (Pearl 2009)). A path is said to be d-separated (or blocked) by conditioning on a set of nodes Z if and only if one of the two conditions is satisfied:\n1. The path contains a chain structure or a fork structure, and the middle node B belongs to Z.\n2. The path contains a collision structures and the collision node B and its descendant nodes are not in Z.\nwhere a path represents a sequence of consecutive edges (directionless) in a DAG. For example, in causal DAGs A \u2192 B\u2192C and A \u2190 B \u2192 C, A and Care d-separated by conditioning on B, whereas in A \u2192 B \u2190 C, A and C are d-separated when B is not conditioned upon."}, {"title": "Conditional Instrumental Variable", "content": "The Instrumental Variable (IV) approach is powerful for addressing confounding factors in causal inference. As the Introduction mentions, the last two conditions of a standard IV (i.e., IV must be independent of confounders and outcome variables) are often too strict for real-world applications. In contrast, a conditional IV (CIV) has more relaxed conditions than a standard IV (Brito and Pearl 2012; Pearl 2009).\nDefinition 3 (Conditional IV (Brito and Pearl 2012; Pearl 2009)). Given a DAG G = (V, E), where nodes V = XUUc U {W,Y} and E are directed edges. W and Y are the treatment and outcome variables, respectively. X is the set of measured pretreatment variables, and Uc is the unmeasured confounders. Zc \u2286 X\\{Zt} and Zc \u2260 \u00d8. A variable Zt is a CIV if it satisfies the following three conditions:\n1. Ze contains only non-descendants of Y;\n2. When conditioning on Zc, Zt and W are d-connection;\n3. When conditioning on Zc, Zt and Y are d-separation in the manipulated graph Gw, which is obtained by deleting all arrows emerging from nodes in W from G."}, {"title": "The CIV and Its Condition Set Extraction Module", "content": "Figure 7 shows the architecture of our latent representation of CIV Zt and its conditional set Ze from user interaction data X. We use the inference and generation networks of VAE (Kingma and Welling 2013) to approximate the posterior distributions p (Zt|X) and p (Zc|X) of Zt and Zc."}, {"title": "Parameter Settings", "content": "To ensure fair comparisons, we standardised the parameter counts across all methods. We set the embedding size for models utilising DICE (Zheng et al. 2021) and DCCL (Zhao et al. 2023) to 64 since they comprise two concatenated sets of embeddings. For the other models, we maintained a consistent embedding size of 128. In the CIV4Rec method, the hyperparameter \u03b1 was set to 0.85. We employed the Adam Optimiser to update model weights, with an initial learning rate of 0.001 and a batch size 128. Except for DICE and DCCL, the loss functions for the other baseline models were based on the BPR (Rendle et al. 2012) function. All models were executed on an NVIDIA A100 (40GB RAM) GPU. To assess the model performance of our approach, we utilised three widely recognised metrics in the recommender systems field: Recall, Hit Ratio (HR), and NDCG."}]}