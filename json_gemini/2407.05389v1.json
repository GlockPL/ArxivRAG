{"title": "Image-Conditional Diffusion Transformer for Underwater Image Enhancement", "authors": ["Xingyang Nie", "Su Pan", "Xiaoyu Zhai", "Shifei Tao", "Fengzhong Qu", "Biao Wang", "Huilin Ge", "Guojie Xiao"], "abstract": "Underwater image enhancement (UIE) has attracted much attention owing to its importance for underwater operation and marine engineering. Motivated by the recent advance in generative models, we propose a novel UIE method based on image-conditional diffusion transformer (ICDT). Our method takes the degraded underwater image as the conditional input and converts it into latent space where ICDT is applied. ICDT replaces the conventional U-Net backbone in a denoising diffusion probabilistic model (DDPM) with a transformer, and thus inherits favorable properties such as scalability from transformers. Furthermore, we train ICDT with a hybrid loss function involving variances to achieve better log-likelihoods, which meanwhile significantly accelerates the sampling process. We experimentally assess the scalability of ICDTs and compare with prior works in UIE on the Underwater ImageNet dataset. Besides good scaling properties, our largest model, ICDT-XL/2, outperforms all comparison methods, achieving state-of-the-art (SOTA) quality of image enhancement.", "sections": [{"title": "I. INTRODUCTION", "content": "UNDERWATER imaging has been widely used in underwater archaeology, underwater robotics, marine detection, and other fields [1]\u2013[3]. However, wavelength- and distance-dependent light attenuation and scattering cause the problem of low contrast and color deviation in underwater images. These degraded images not only lead to unsatisfactory visual experience for humans but also affect the performance in computer vision tasks like object detection, image classification, and semantic segmentation.\nTo enhance the quality of underwater images, scholars have proposed a series of effective measures, promoting the development of underwater image enhancement (UIE). Conventional UIE methods [4]\u2013[9] (e.g., white balance [4], [5] and histogram equalization [6]) depend on assumptions or a priori knowledge, models, or design guidelines to enhance underwater images. Although conventional methods are easy to execute, they are not adaptable to different water environment and lighting conditions.\nThe rapid development of deep learning brings new insights and tools for UIE. By leveraging large-scale underwater image datasets to learn the patterns and features, deep-learning-based UIE methods can achieve intelligent, automated, and end-to-end underwater image enhancement. Deep-learning-based UIE methods are typically divided into two primary categories: 1) convolutional neural network (CNN)-based [10]\u2013[15] and 2) generative adversarial network (GAN)-based [16]\u2013[21]. The CNN-based UIE methods train deep CNNs to learn the mapping relationship from the degraded image to the high-quality reference image [10], which is robust to different underwater scenes. The GAN-based UIE can also accomplish the conversion from the degraded underwater image to the corresponding ground truth image and achieve good performance [16]. However, GANs often suffer from unstable training process and mode collapse. Therefore, it is necessary to develop more stable and diversified methods to further improve the effect and quality of UIE.\nDenoising diffusion probabilistic models (DDPM) have begun to attract extensive attention for its good convergence properties and relatively stable training process. DDPMs have emerged as a new state-of-the-art (SOTA) baseline in the field of image generation [22], [23]. As scholars continue to explore diffusion models, their potential for image-to-image generation is continually developed [24]. In image restoration, image coloring, and image super-resolution tasks, diffusion model-based approaches have produced superior results than GAN models [22]\u2013[24]. Although DDPMs can yield excellent results, an acknowledged challenge of DDPMs is the long inference time, which leads to poor real-time performance.\nIn this article, a generative approach for UIE based on conditional DDPM is proposed, which uses the degraded image as the conditional input. As for the model architecture, the conventional U-Net [25] backbone in a diffusion model is replaced with a transformer, which we call image-conditional diffusion transformer (ICDT). Diffusion transformer adheres to many good practices of vision transformers (ViT) [26], perhaps one of the most important factors is the excellent scalability properties compared to traditional convolutional networks."}, {"title": "II. RELATED WORK", "content": "Conventional UIE methods depend on assumptions or a priori knowledge, models, or design rules to enhance underwater images. These methods are based on physical models and utilize image degradation priors to inversely solve degradation models. Drews et al. [7] introduced a UIE method using underwater dark channel prior (DCP), which utilizes the statistical prior of images obtained in outdoor natural scenes and applies it only in the blue and green channels to improve enhancement quality. Li et al. [6] minimized the information loss of the enhanced underwater images to obtain the transmission map and improved the brightness and contrast of underwater images based on natural image histogram distribution prior. Wang et al. [8] proposed the maximum attenuation identification method for UIE based on a simplified underwater light propagation model. Ancuti et al. [4] combined the Laplacian pyramid and white balance to produce two enhanced results, which were then fused via weight mapping. Peng et al. [9] generalized the common DCP method to image restoration. They estimated scene transmission through calculating the difference between the ambient light and the observed intensity. In addition, they incorporated adaptive color correction into the image formation model to remove color casts and restore contrast.\nAlthough these methods have specific theoretical support, they may still suffer from under-enhancement or over-enhancement under challenging water environment and lighting condition. One reason is that the underwater environment is complex and changeable, and physical parameters are difficult to get; the other reason is that the underwater image degradation model is different from that on land and difficult to establish."}, {"title": "III. IMAGE-CONDITIONAL DIFFUSION TRANSFORMER", "content": "Conditional diffusion models take supplemental information as input. For UIE task, we use degraded image as the extra conditional input. Additionally, a few simple modifications are done following [27] to make DDPMs achieve better log-likelihoods and sample much faster without sacrificing sample quality.\nDDPMs [31] are a kind of generative models which progressively transforms a Gaussian noise distribution into the distribution of data on which the model is trained. The forward noising process is a Markov process which gradually corrupts"}]}