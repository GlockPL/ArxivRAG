{"title": "AI Governance InternationaL Evaluation Index (AGILE Index)", "authors": ["Yi Zeng", "Enmeng Lu", "Xin Guan", "Cunqing Huangfu", "Zizhe Ruan", "Ammar Younas", "Kang Sun", "Xuan Tang", "Yuwei Wang", "Hongjie Suo", "Dongqi Liang", "Zhengqiang Han", "Aorigele Bao", "Xiaoyang Guo", "Jin Wang", "Jiawei Xie", "Yao Liang"], "abstract": "The rapid advancement of Artificial Intelligence (AI) technology is profoundly transforming human society and concurrently presenting a series of ethical, legal, and social issues. The effective governance of AI has become a crucial global concern. During the past year, the extensive deployment of generative AI, particularly large language models, marked a new phase in AI governance. Continuous efforts are being made by the international community in actively addressing the novel challenges posed by these AI developments. As consensus on international governance continues to be established and put into action, the practical importance of conducting a global assessment of the state of Al governance is progressively coming to light.\nIn this context, the Center for Long-term Artificial Intelligence (CLAI), in collaboration with the International Research Center for AI Ethics and Governance hosted at the Institute of Automation, Chinese Academy of Sciences, jointly initiated the development of the AI Governance InternationaL Evaluation Index (AGILE Index). The index is utilized to delve into the status of AI governance to date in 14 countries for the first batch of evaluation. The aim is to depict the current state of AI governance in these countries through data scoring, assist them in identifying their governance stage and uncovering governance issues, and ultimately offer insights for the enhancement of their Al governance systems.\nAdhering to the design principle, \"the level of governance should match the level of development,\" the inaugural evaluation of the AGILE Index commences with an exploration of four foundational pillars: the development level of AI, the AI governance environment, the AI governance instruments, and the Al governance effectiveness. It covers 39 indicators across 18 dimensions to comprehensively assess the AI governance level of 14 representative countries globally. The countries evaluated include the Group of Seven (G7, namely the United States, United Kingdom, France, Germany, Japan, Canada, Italy), the BRICS countries (Brazil, Russia, India, China, South Africa), and representative countries from specific regions (Singapore, the United Arab Emirates), totalling 14 countries.", "sections": [{"title": "1.1. Evaluation Framework", "content": "The design philosophy of the Al Governance InternationaL Evaluation Index (AGILE Index) aligns with the principle that \"the level of governance should match the level of development.\" Specifically, a country should align its Al governance level with its overall AI development level to ensure the healthy and sustainable growth of Artificial Intelligence. The principle's essence is to avoid both uncontrolled development due to insufficient governance, which can harm society, and the stifling of technological innovation from excessive governance. The goal of governance is to achieve a beneficial healthy interaction between technological innovation and social welfare, so as to maximize the benefits of AI and minimize its potential risks. Based on this, the AGILE Index has four pillars for Al governance evaluation: development level, governance environment, governance instruments, and governance effectiveness. Through a thorough assessment of these aspects, the AGILE Index aims to provide each country with a comprehensive and clear analysis of the status of AI governance, thereby offering robust support for future development and governance."}, {"title": "1.2. Indicator system", "content": "The AGILE Index, built on four pillars, comprises 18 dimensions and 39 indicators, offering a comprehensive framework for evaluating the Al governance status in various countries. The table below outlines these dimensions and indicators. For an in-depth understanding of each indicator, including their data sources and the methodology used for the index score calculation, please see Appendices 1 and 2."}, {"title": "2.1. Score Composition", "content": null}, {"title": "2.2. Overall Observations", "content": "Key observation 1: Four Tiers of AGILE Index Scores\nThe index categorizes 14 countries into four tiers based on scores above 60, 50, and 40 points. The United States, which scoring slightly above 70, heads the first tier, followed by China, Singapore, Canada, Germany, and the United Kingdom, all scoring above 60. Japan and France, with 56.5 and 55.3 points, are in the second tier. The Italy, United Arab Emirates, India, and Russia, scoring between 40 to 50, fall in the third tier. Brazil and South Africa, scoring below 40, are in the fourth tier.\nKey observation 2: There is a strong positive correlation between AGILE Index score and the per capita GDP.\nThe AGILE Index score demonstrates a strong positive correlation with the per capita GDP of various countries. For analytical purposes, we categorize the 14 nations into two groups based on per capita GDP: a high-income group, including nine countries such as the G7 nations, Singapore, and the UAE, and a BRICS group of five middle-income countries pre-2023 expansion. Notably, the UAE is treated as high-income in this report, despite its BRICS membership. The data clearly shows that higher-income countries typically score above BRICS nations in the AGILE Index. However, China and India's AGILE Index scores (68.5;48.1) are significantly higher than their per capita GDP levels, while the United Arab Emirates' AGILE Index score (49) is observably lower than its per capita GDP level."}, {"title": "3.1 Pillar 1: AI Development Level", "content": "Pillar 1 overview: The AGILE Index assesses each country's level of Al development across three dimensions: Al research and development (R&D), AI infrastructure construction, and AI industry scale.\nIn total, the evaluation of 14 countries reveals more than two million AI professionals, over one million research papers, nearly one hundred thousand patents, and the publication of nearly 500 significant machine learning systems. Collectively, these countries possess a combined supercomputer computing power exceeding 9,000 pFLOP/s, and houses over 3,000 colocation data centers, facilitating diverse AI R&D activities.\nObservation 1.1: The United States holds a clear lead over other countries in AI development level.\nFigure 6 visually summarizes key indicators of AI activity across 14 countries. This analysis excludes per capita ratios to provide a high-level comparison of total numbers in various metrics, including research papers, researchers, patents granted, machine learning systems, supercomputing power, data centers, and AI company funding and startups. Notably, the United States holds a clear lead, contributing over one-third of the combined research papers and professionals and exceeding half the total in many other areas.\nObservation 1.2: China demonstrates notable strengths in AI development, while facing challenges in Al infrastructure building.\nChina demonstrates notable strengths in AI, ranking second overall in a pool of 14 countries. Notably, it leads the BRICS countries by a significant margin. Across five out of eight key indicators, China secures the second spot, with contributions ranging from 10% to 33%. When it comes to developed Al systems, China stands neck-and-neck with the United Kingdom, occupying the third position with nearly 10% of the total. Supercomputing power sees China close behind second-placed Japan, contributing 9% of operations. However, a concerning gap emerges in data center infrastructure. With only 2.5% of the total across the 14 countries, China falls to ninth place, highlighting a potential area for future development.\nObservation 1.3: Beyond the United States and China, a global mosaic of strengths emerges.\nBeyond the US, several countries contribute significantly to the global AI landscape. The UK, Germany, and Canada consistently rank within the top five for six out of eight indicators. Germany leads in research papers (around 10%), researchers (around 9%), and supercomputing power (around 4.4%). The UK shines in machine learning systems (around 10%), data centers (around 8%), AI funding (around 4%), and startups (around 9%). Meanwhile, Japan secures third place in patents (around 5%) and supercomputer operations (around 10%), showcasing its unique strengths."}, {"title": "3.2. Pillar 2: AI Governance Environment", "content": "Observation 2.1: There was a sharp 12-fold increase in documented Al risk incidents in 2023, underscoring the pressing need for Al governance to keep pace with rapid technological advancements.\nSince generative AI technology like ChatGPT entered the scene in late 2022, its rapid development has been accompanied by growing concerns about potential risks. Data from the OECD AI Incidents Monitor reveals a significant surge in publicly reported AI risk incidents. By January 1, 2024, the database contained 7,198 such reports. The number of recorded incidents involving AI technology jumped significantly in 2023. Compared to 2022, there were 12.8 times more incidents, with 4,409 cases documented \u2013 representing a staggering 61% of all recorded incidents since the beginning. This trend held true across all 14 countries, with annual growth ranging from 4 to over 70 times. The sharp rise in AI incidents during 2023 highlights the urgent need for strong AI governance systems to catch up with the fast development of this technology.\nObservation 2.2: Among the 14 evaluated countries, especially the USA, face a significant proportion of documented AI risk incidents globally, highlighting the collective pressure on AI governance worldwide.\nWith 1,681 Al risk incidents (83% of identified origin) reported in 2023 originating from 14 countries, the assessed 14 countries hold significant responsibility in shaping effective global AI governance. Further analysis using data from other global AI risk incidents databases revealed that the United States accounted for 67% of all AI risk events involving the 14 assessed countries, far exceeding the contributions of the second-place China (9.3%) and the third-place United Kingdom (6.5%). The substantial gap in AI risk incidents between the US and other nations necessitates further investigation into the contributing factors, particularly considering its leading role in AI development.\nObservation 2.3: Although high-income countries often demonstrate a higher level of preparedness for Al governance, it's important to recognize the opportunity for all countries to excel in Al governance, regardless of their overall governance readiness.\nTo assess government general preparedness for the growing number of AI incidents, our evaluation examines each country's overall readiness to govern Al effectively. We combine indicators from two key aspects: 1) overall evaluation of the governance capability of a country, using the World Bank's Worldwide Governance Indicators (WGI) and the GovTech Maturity Index (GTMI), and 2) evaluation of a country's commitment to achieving Sustainable Development Goals (SDGs), using the SDG Development Index (SDGDI). While our analysis using WGI, GTMI, and SDGDI indices reveals that high-income countries generally exhibit better AI governance readiness compared to others, it's important to recognize the opportunity for all countries to excel in Al governance, regardless of their overall governance readiness. For example, although the US's performance in overall governance readiness is relatively low in high-income countries, it achieves the highest score in AGILE Index."}, {"title": "3.3. Pillar 3: AI Governance Instruments", "content": "Pillar 3 overview: AGILE Index evaluates seven types of Al governance instruments.\nAl governance encompasses a variety of instruments, each with a distinct function to ensure the responsible development and use of AI.\nObservation 3.1: The 14 evaluated countries showed relatively strong performance in AI strategy, AI governance bodies, and participation in international AI governance.\nThe 14 evaluated countries showed relatively strong performance in AI strategy, AI governance bodies, and participation in international AI governance. However, there is room for improvement in areas such as Al standard certification, impact assessments, and legislation. Among these countries, most have published AI strategies. Ten countries have established AI principles and norms, six have introduced Al ethics assessment tools, five have implemented AI governance ethics standards, and four have enacted national laws pertaining AI.\nObservation 3.2: Between 2020 and 2023, the governance instruments of AI has evolved from setting broad principles in the preceding five years to the development of tangible measures, including AI legislation, AI standards, and AI impact assessment tools.\nGenerally, the majority of the 14 countries released their AI strategies, governance bodies, and principles between 2017 and 2020. However, from 2020 to 2023, there was a shift in focus towards AI legislation, AI standards, and Al impact assessment mechanisms.\nIn terms of publication timelines, we can categorize the development into three periods: before 2015, from 2015 to 2020, and from 2020 onwards. Most national governance bodies, strategies, and principles were established between 2015 and 2020, with some countries following suit in the subsequent three years. In contrast, the development of many standards and impact assessment tools began primarily after 2020, with numerous countries still in the process of formulating them. Regarding legislation on data protection and consumer protection, many were initially introduced before 2015 and have since been updated to address the challenges brought about by newer generations of AI technology.\nAnother notable point is the establishment of Italy's Data Protection Authority in 1996, known as Garante per la protezione dei dati personali. The Garante has proven to be a significant body in AI governance. For instance, on March 30, 2023, the Garante issued a temporary emergency order directing OpenAI LLC to cease using ChatGPT for processing personal data of individuals in Italy. This order was subsequently lifted at the end of April 2023.\nObservation 3.3: In the context of international participation in Al governance among the 14 evaluated countries, the United Kingdom, France, and Japan have demonstrated significant involvement.\nRegarding international governance of artificial intelligence, the United Nations stands as the most inclusive governance mechanism worldwide. UNESCO's Recommendations on the Ethics of Artificial Intelligence, the first globally reached agreement on AI ethics, is the most broadly supported AI governance document. Among the 14 evaluated countries, all except the United States, which had already withdrawn from UNESCO at the time, signed the recommendation at the end of 2021. During its drafting, representatives from 10 of these countries, with the exception of Germany, Canada, Italy, and Singapore, were involved in the process. Additionally, in October 2023, the UN Secretary-General formed a High-Level Advisory Body on Artificial Intelligence consisting of 38 experts. In this group, experts from all the evaluated countries, except Canada, were selected.\nRegarding international AI principles, the Organization for Economic Cooperation and Development (OECD) introduced the OECD AI Principles in 2019. Similarly, in June 2019, the Group of Twenty (G20) ratified the G20 Artificial Intelligence Principles, which promote a human-centered and responsible approach to development of AI. Of the 14 countries assessed, all except the United Arab\nObservation 3.4: AI legislation varies globally, with some countries adopting comprehensive state-level laws, while others integrate AI-specific amendments into existing frameworks or follow a more fragmented approach with state-specific initiatives and federal guidelines.\nThe top-down approach involves government-led initiatives to create broad, overarching regulations that directly address the nuances of AI technology. Contrastingly, other countries are adapting their existing legal frameworks to meet the evolving demands of AI. This approach, more evolutionary in nature, updates and extends current legislation to encompass the unique challenges and considerations posed by AI technologies. These varying strategies highlight the diverse responses to Al governance across the global landscape.\nIn the European Union, there's a move towards comprehensive, unified AI law, while the US shows a fragmented landscape with numerous state initiatives and federal guidelines. The UK's approach fa-"}, {"title": "3.4 Pillar 4: AI Governance Effectiveness", "content": "Observation 4.1: The public in BRICS countries generally express higher levels of trust in AI compared to their counterparts in high-income countries.\nThere is a strong positive correlation between public awareness and trust in AI, with a correlation coefficient of 0.84. This suggests that the more the public in a country is aware of AI applications in key scenarios, the more they trust AI. Among them, in China, India, Brazil, and South Africa, more than 60% of surveyed public expect AI to ultimately improve life rather than negatively impact it, which is significantly higher than other countries. In China, over three-quarters of respondents express trust in AI, the highest among the 14 countries. The KPMG survey\u00b9 shows the percentage of scenarios in which people in various countries are aware of existing or upcoming AI applications and averages these percentages across countries. In this statistic, respondents from China, India, Brazil, South Africa, and Singapore are aware of Al in over 60% of scenarios on average. Singaporean respondents have the highest awareness ratio, exceeding 70%.\nObservation 4.2: A stark gender imbalance permeates AI researchers across all 14 evaluated countries, with only about one in five researchers being female.\nAGILE Index sees that China and Singapore have the lowest identified gender author ratios, at 1.2 and 2.0 respectively, ranking first and second. Italy follows closely with a ratio of 2.9. This indicates the most balanced male-to-female participation in AI literature in these three countries. In most other countries, the gender ratio is between 3 and 5. However, Germany and Japan have significantly high-er gender ratios than other countries, at 7.1 and 9.7, indicating a need for increased female Al re-search participation in these countries.\nObservation 4.3: Further analysis on gender gap underscores a critical challenge: almost no countries excel at both AI gender inclusivity and broader societal gender equality, which calls for further research attention.\nIn comparison with the WEF Gender Gap report rating, which aims to score a country's general societal gender equality, we note countries like Germany, which have a small societal gender gap but a large gender ratio difference in literature, and countries like Japan with relatively large societal gender gaps and large gender ratios in literature, or countries like China with an observable societal gender gap and a more balanced gender ratio in literature. However, there are few countries that perform well in both aspects, indicating room for improvement in gender-ratio.\nFurther analysis reveals a weak negative correlation between the gender author ratio and the WEF Global Gender Gap score. Furthermore, we also observe a weak negative correlation between AI graduate ratio and the WEF Global Gender Gap score. The negative correlations between the gender ratio in AI and the overall societal gender gap suggests that if a country has a high performance in bridging the general gender gap, it tends to have a low score of the gender ratio in the field of AI. This counterintuitive phenomenon worths reflection and further research. It would be especially interesting to see if the same negative correlation occurs in more countries. If this phenomenon is indeed occurring, then it means that all countries still have work to do in terms of gender equality.\nObservation 4.4: While all 14 countries actively engage in global developer communities, the United States, China, and India stand out for their substantial contributions and impact.\nGitHub is an open-source code hosting platform with a multitude of open-source AI-related projects, including in fields like machine learning, natural language processing, and computer vision. We can see that India, despite having a very high number of total Al submissions on GitHub (about 49,000), has a low number of popular AI packages, accounting for only about 1.2%. The United States has the highest number of submissions to popular AI packages among the 14 countries, about 3,600, accounting for a significant percentage. Although China has fewer submissions to popular AI packages than the U.S., it has the highest percentage of popular packages, with the two ratios reaching about 39%.\nAGILE Index also compiled contributions from different countries to the AI community Hugging Face, which is an open-source community dedicated to advancing natural language processing (NLP) technology and tools, such as pre-trained models, datasets, and tutorials. Overall, China and the United States belong to the first tier in terms of contributions, contributing over 300 models and datasets each to the Top 1000 influential ones. Meanwhile, Canada, France, India, the United Kingdom, Singapore, Brazil, and Japan belong to the second tier, contributing two-digit numbers of models and datasets.\nObservation 4.5: The proportion of publications related to Al governance is around 3%-4% of all AI-related publications in the 14 countries.\nAccording to our statistics from the DBLP literature database, the 14 countries have a total of over 140,000 AI-governance-related publications. The proportion of publications related to AI governance is around 3%-4% of all AI-related publications. The total number of AI governance publications from the 14 countries was predominantly contributed by the US, China, and the UK, accounting for 22%, 18%, and 13%, respectively. Germany, the UK, India, and Italy also made significant contributions, with respective proportions of 10%, 9%, and 8%.\nObservation 4.6: The total volume of literature on AI governance has shown an exponential acceleration in recent years, with a growth rate reaching 45% in 2022.\nOver 2014-2022, the total number of AI governance-related publications from these 14 countries has steadily increased, rising from 472 in 2014 to 2,707 in 2022. We have observed the largest increase in volume in 2022 with a 45% of growth rate.\nNotably, the growth rate of AI governance publications from China was higher than other countries. In 2014, China's proportion of Al governance publications among the 14 countries was 14.2%, ranking second. In the same year, the US had a proportion of 25.2%, ranking first. However, by 2021, China reached 23.1%, becoming the leader in governance publications among the 14 countries and maintained the first place in 2022 with a contribution rate of 21.2%.\nObservation 4.7: Among the 14 countries, security, safety, and collaboration are consistently the most researched topics related to Al governance in AI literature, with long-term Al and accountability receiving significantly less research focus.\nWe analysed the themes of AI literature in the 14 countries based on the key topics mentioned in AI principles\u00b2. Among 14 countries, security, safety, and collaboration were consistently the most researched topics related to AI governance, with long-term AI and accountability receiving significantly less research focus, both with less than 1% of literature on it.\nObservation 4.8: There are visible collaborations on Al governance among all countries, indicating that Al governance is globally connected and indivisible.\nBased on analysis of collaborations in AI governance-related papers, visible collaborations can be found among all countries. Most collaborations occur between the US, the UK, and other countries, contributing about 21% and 16% of cooperation respectively, while regional cooperation within European, North American, and Eastern Asian countries are also strong. Noticeably, China-UK-US and UK-US-EU (France, Italy, Germany) collaboration network stands out from the rest, as they are also the most active hubs of governance research. The collaborations on Al governance among different countries indicates that Al governance is globally connected and indivisible.\nObservation 4.9: China and the United States together contribute more than half of the papers in nearly all AI for SDGs research directions.\nThe number of papers published by a country using AI technology to help achieve sustainable development goals indicates the effort made by that country in using Al for Good. Overall, the United States and China are in the first tier in terms of the number of AI for SDGs papers published, accounting for 34.7% and 23.2% of the AI for SDGs literature from all 14 countries, respectively. They in total also contribute more than half of the papers in all AI for SDGs research directions, except on SDG2 (Zero Hunger) and SDG11 (Sustainable Cities and Communities) where India and Italy also play an important role.\nObservation 4.10: SDG3 (Good health and well-being), SDG9 (Industry, innovation, and infrastructure) and SDG4 (Quality Education) are the three most popular AI for SDGs research topics for all 14 countries.\nAll countries' focus on AI for SDGs literature is consistent, with SDG3 (Good health and well-being), SDG9 (Industry, innovation and infrastructure) and SDG4 (Quality Education) be three of the most popular topics for all 14 countries. For all countries, papers on these three SDGs account for more than half of all AI for SDGs relevant papers. Japan and Italy have relatively researched a lot on SDG7 (Affordable and clean Energy), which alongside with SDG14 (Life below water) and SDG14 (Life on Land), have also attracted observable amount of attention for almost all countries.\nObservation 4.11: In AI for SDGs application, while SDG3, SDG9, and SDG4 remain popular, there are also notable number of projects for SDG11 (Sustainable Cities and Communities), SDG12 (responsible consumption and production) and SDG13 (Climate actions).\nThe AGILE Index also assesses the disparity between AI for SDGs literature and applications across the 14 countries. The United States continues to lead, contributing 43% of the total documented AI for SDGs use cases and significantly influencing all SDGs. In contrast, China exhibits a noticeably smaller share in AI for SDGs applications compared to literature. Conversely, India stands out with a higher proportion of SDGs application cases, particularly in the realms of SDG1 (No Poverty), SDG5 (Gender Equality), and SDG6 (Clean Water and Sanitation), in comparison to its literature contributions."}, {"title": "4. Links to Illustrations", "content": null}, {"title": "1. Dimension Details and Data Sources", "content": null}, {"title": "2. Scoring Methodology", "content": "a) Scoring Methodology for AI Legislation\nIf a country does not have a dedicated national-level AI law, it scores 0 in the national-level AI law indicator. This indicates the lack of a formal AI legislative framework at the national level. Laws from different provinces or regions within a country and regional legislations are excluded from this evaluation. A country with a comprehensive and detailed national-level AI law scores 100. The law should cover all aspects of AI, including generative AI, algorithms, ethical considerations, national digital infrastructure, and social impacts of AI.\nCountries without specific data protection provisions for AI score 0 in the data protection law indicator; those with partial provisions score 50; and those with comprehensive data protection legislation for AI score 100. The scoring method for consumer rights laws containing AI clauses is similar, based on whether the country's consumer rights law specifically targets AI and its extent of coverage.\nIf a country has enacted partial legislation involving AI, it scores 100 in the partially enacted AI legislation indicator. This might mean the law covers some aspects of AI but is not comprehensive in scope or depth. This also includes documents that are about to become law or are in the later stages of the legislative process.\nb) Literature Analysis\nWhen analysing nationality and gender information in various databases, we used multiple methods. First, we judged the nationality of the authors. If the author provided an address in the paper, we used this information to determine nationality. Otherwise, we inferred it through the author's collaboration network. We used the global_gender_predictor package to determine the gender of authors, based on the World Gender Name Dictionary Second Edition. When necessary, titles, abstracts, authors, publication dates, author addresses, article categories, and links information are collected.\nTo determine if a scientific literature is related to AI, we combined information on publishers and keywords. First, we identified literature published in AI journals or conferences as AI-related. Names and abbreviations of AI-related journals or conferences were extracted from the AMiner literature database's Al journal rankings. Literature published by these publishers was identified as AI-related. Additionally, we compiled a list of keywords for various Al sub-fields (e.g., machine learning, neural networks, reinforcement learning, Bayesian, Markov learning, etc.). If these keywords appeared in the title, the literature was identified as AI-related. To determine if a scientific literature was related to Al governance, we look for keywords like \u2018governance', \u2018policy', or \u2018ethics' in scientific literatures. If these keywords existed in the abstract or title, the literature was identified as governance related. To further confirm whether the literature is related to artificial intelligence governance, we use large language models to generate vector representations of the literature and perform clustering to eliminate irrelevant literature.\nc) Score Calculation at Each Level\nIn processing raw scores, we incorporated data entries and statistics from multiple sources for triangulation, enhancing reliability. This is especially useful when small fluctuations in scarce data can significantly impact scores; multiple data sources can reduce bias. Strong correlations between different data elements allow for mutual supplementation in cases of missing data. Where appropriate, ratio scores were considered to ensure fair comparisons between countries with different baseline statistics (such as population and GDP). Finally, percentile-fit normalization (see below) was used to standardize and average various data. In identifying genders, we combined average level inference, allocating 22.9% of unidentified genders as female, and the identified proportion was then percentile-fit normalized and averaged.\nWhere appropriate, ratio scores were aggregated to ensure fair comparisons between countries at different baseline factor (such as population and GDP). To compute the indicator score, we will use the average normalization score of the total and the ratio. For example, if a country obtains a normalized score of 5 in total number and 3 in per capita number, then the country's score in this indicator will be 4.\nAfter obtaining indicator scores, we averaged the scores within each dimension and then standardized them to obtain dimension scores. Simple standardization was used to readjust the mean to 50; due to the dispersion of scores based on survey indicators and tools, averages were used without further standardization. We then averaged the dimension scores to obtain pillar scores and averaged the pillar scores to obtain the index score. Here, D4. AI Risk Exposure is a negative factor in P2 aspect, so [100 - dimension score] was used for averaging.\nd) Score Normalization and Data Imputation\nFor simple normalization, we use:\n$25 * \\frac{Xn - \\mu}{\\sigma} + 50$\nwhere $\\mu$ is the statistical mean of all countries, $\\sigma$ is the statistical variance, and xn is the raw data of the country. After standardization, scores exceeding 0 and 100 were truncated to ensure they remained within the 0-100 range. For percentile-fit normalization, after each simple standardization, we extracted and removed one percentile of scores, then repeated the standardization and extraction on the remaining data until four score quartiles were obtained. This was necessary due to significant clustering in the original data and large magnitude differences, requiring adjustment of the standard deviation for better comparison of data at lower scales.\nIn the case of missing data within an indicator, we imputed the average of other available data sources within the indicator, given their strong correlation. For missing data in indicator scores, we used rank-adjusted mean imputation. We temporarily imputed 50, calculated the belonging dimension score, estimated the ranking, and then calculated the average score of countries with a close estimated ranking for the final imputation. This imputed value was only used for calculating the dimension score. Experiments showed this method effectively prevents excessively lowering or raising the scores of countries being imputed."}, {"title": "3. Other Related Indexes", "content": "In our survey of existing AI indexes, we compiled six evaluation systems or indices that related to the field of Al governance to some extent, which provide useful information on countries' AI capabilities and governance themes. These include UNESCO's Readiness Assessment Methodology for AI Governance (RAM), Tortoise Media's Global AI Index (GAII), Oxford Insights' Government Readiness Index (GRI), OECD's Going Digital Toolkit (GDT), AI Vibrancy Toolkit (AIVT) from Stanford Institute for Human-Centered Artificial Intelligence (HAI), and the European council's Center for AI and Digital Policy Centre's AI and Democratic Values Index (CAIDP AIDVI). The following table, based on the AGILE Index framework, organizes, and compares the content of each assessment system."}]}