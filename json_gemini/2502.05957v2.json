{"title": "AutoAgent: A Fully-Automated and Zero-Code Framework for LLM Agents", "authors": ["Jiabin Tang", "Tianyu Fan", "Chao Huang"], "abstract": "Large Language Model (LLM) Agents have demonstrated remarkable capabilities in task automation and intelligent decision-making, driving the widespread adoption of agent development frameworks such as LangChain and AutoGen. However, these frameworks predominantly serve developers with extensive technical expertise-a significant limitation considering that only 0.03% of the global population possesses the necessary programming skills. This stark accessibility gap raises a fundamental question: Can we enable everyone, regardless of technical background, to build their own LLM agents using natural language alone? To address this challenge, we introduce AutoAgent - a Fully-Automated and highly Self-Developing framework that enables users to create and deploy LLM agents through Natural Language Alone. Operating as an autonomous Agent Operating System, AutoAgent comprises four key components: i) Agentic System Utilities, ii) LLM-powered Actionable Engine, iii) Self-Managing File System, and iv) Self-Play Agent Customization module. This lightweight yet powerful system enables efficient and dynamic creation and modification of tools, agents, and workflows without coding requirements or manual intervention. Beyond its code-free agent development capabilities, AutoAgent also serves as a versatile multi-agent system for General AI Assistants. Comprehensive evaluations on the GAIA benchmark demonstrate AutoAgent's effectiveness in generalist multi-agent tasks, surpassing existing state-of-the-art methods. Furthermore, AutoAgent's Retrieval-Augmented Generation (RAG)-related capabilities have shown consistently superior performance compared to many alternative LLM-based solutions.", "sections": [{"title": "1 Introduction", "content": "The emergence of Large Language Models (LLMs) has revolutionized AI agent development, enabling unprecedented breakthroughs in autonomous task execution and intelligent problem-solving. LLM-powered agents excel at understanding context, making informed decisions, and seamlessly integrating with various tools and APIs. Leading frameworks like LangChain [1], AutoGPT [2], AutoGen [3], CAMEL [4], and MetaGPT [5] have demonstrated remarkable success in automating increasingly complex workflows - from sophisticated web navigation to advanced data analysis and innovative creative content production. By leveraging advanced mechanisms such as role-playing, structured operating procedures, and dynamic agent coordination, these frameworks deliver exceptional problem-solving capabilities while significantly reducing human intervention.\nDespite remarkable advancements in AI agent development, a significant barrier persists: the creation and optimization of LLM agent systems remains dependent on traditional programming expertise. Current frameworks primarily cater to technically proficient developers who can navigate complex codebases, understand API integrations, and implement sophisticated prompt engineering patterns. This reliance on coding skills creates a substantial accessibility gap, as only 0.03% of the global population possesses the necessary programming expertise to effectively build and customize these agents. Even with well-documented frameworks and development tools, the entry barrier remains dauntingly high for non-technical users. This limitation becomes particularly problematic given the universal need for personalized AI assistants in digital age. Everyone, from business professionals seeking workflow automation to educators designing interactive learning tools, requires customized LLM agents tailored to their specific needs. For instance, a researcher might need an agent specialized in literature review and data analysis, while a content creator might require an agent focused on creative writing and media management. The current paradigm of coding-dependent agent development not only severely restricts the user base but also creates a bottleneck in meeting the diverse and evolving demands for personalized AI assistance. This misalignment between universal needs and limited accessibility calls for a fundamental rethinking of how LLM agents are created and customized.\nThis stark contrast between universal needs and limited accessibility leads us to a fundamental research question: Is it possible to democratize LLM agent development by enabling Natural Language-based Creation and Customization? In this work, we aim to realize this vision by introducing AutoAgent, a novel framework that fundamentally reimagines agent development as a fully automated, language-driven process requiring zero programming expertise. To realize this vision, AutoAgentoperates as an autonomous Agent Operating System with three key capabilities: 1) Natural Language-Driven Multi-Agent Building - automatically constructing and orchestrating collaborative agent systems purely through natural dialogue, eliminating the need for manual coding or technical configuration; 2) Self-Managing Workflow Generation - dynamically creating, optimizing and adapting agent workflows based on high-level task descriptions, even when users cannot fully specify implementation details; and 3) Intelligent Resource Orchestration - providing unified access to tools, APIs, and computational resources via natural language while automatically managing resource allocation and optimization. Through this innovative architecture, AutoAgentdemocratizes LLM agent development while maintaining enterprise-grade sophistication, transforming a traditionally complex engineering task into an intuitive conversation accessible to all users.\nTo enable fully-automated and zero-code LLM agent development, AutoAgent introduces several synergistic technical innovations that form a complete framework: First, the Agentic System Utilities provides a foundational multi-agent architecture, where specialized web, code, and file agents collaborate seamlessly to handle diverse real-world tasks. At its core, the LLM-powered Actionable Engine serves as the system's brain, supporting flexible integration of any LLM provider through both direct and transformed tool-use paradigms for robust action generation. To address the critical challenge of information management, the Self-Managing File System enhances overall system capability by automatically converting diverse data formats into queryable vector databases, enabling"}, {"title": "2 Related Work and Preliminaries", "content": "LLM-empowered agents have revolutionized AI systems by leveraging powerful language understanding and reasoning capabilities to interact with external environments through tool invocation. A rich ecosystem of agent frameworks has emerged, with prominent examples including LangChain [1], AutoGPT [2], CAMEL [4], MetaGPT [5], and OpenAgent [6]. These frameworks have demonstrated impressive capabilities across diverse domains: CAMEL pioneered role-playing-based communication for cooperative behaviors, AutoGen [3] developed customizable LLM combinations for complex problem-solving, MetaGPT [5] integrated Standardized Operating Procedures for software engineering tasks, and OpenAgent [6] provided a comprehensive platform for specialized web agents including data processing, plugin integration, and web interaction. However, leveraging these LLM Agent frameworks requires substantial coding skills and domain expertise to build effective agents, which significantly limits their accessibility to non-technical users and hinders the widespread adoption of agent technology across different domains. To address this challenge, we aim to propose a new paradigm of LLM Agent framework that democratizes agent development by enabling automatic generation, customization, and orchestration of agents through natural language interactions, making powerful agent technology accessible to users regardless of their technical background.\nLLM-Empowered Agent. The task-solving process of Large Language Model (LLM) agents can be formalized as a Markov Decision Process (MDP), providing a comprehensive framework for modeling their interaction with the environment. Defined as $M = (S, A, O, P(\u00b7), E)$, the MDP captures the agent's state space $S$, action space $A$, observation space $O$, state transition function $P(\u00b7)$, and the set of environments $\\& it$ can interact with. At each time step, the LLM agent observes the current state, selects an action based on its policy, interacts with the environment, and updates its state, often referred to as the agent's \"context\". The mapping from state to action can follow two primary paradigms: Tool-Use [7], where the agent utilizes external capabilities, and ReAct [8] (Non-tool-use), where the agent generates the next action solely based on its internal language model. This MDP formulation provides a powerful framework for understanding, analyzing, and designing LLM-empowered agents capable of tackling a wide range of complex, multi-step tasks.\nGeneralist Multi-Agent System. The motivation behind multi-agent systems (MAS) is to overcome the limitations of a single agent in handling the full scope and nuances of complex problems. By leveraging the diverse capabilities and specialized knowledge of multiple agents, the MAS enables more effective problem-solving for multi-faceted tasks. To enhance the generalization power of MAS, researchers have designed Generalist Multi-Agent Systems that employ a team or ensemble of specialized agents. These agents work together under the coordination of a central Orchestrator agent to solve a wide variety of complex tasks through collaborative intelligence and synergistic efforts.\nIn a Generalist MAS, there are multiple agents, denoted as $\\pi_0 : S_0 \\rightarrow A_0, \\pi_1 : S_1 \\rightarrow A_1,..., \\pi_n: S_n \\rightarrow A_n$. Within each agent's action set, there exists a special transfer action $\\hat{A_i} \\in A_i$, which enables the delegation of tasks to other agents. The key challenge in a MAS lies in designing an effective Task Transfer Mechanism, which organizes different agents through appropriate transfer actions. We define such an agent organization mechanism as the \"MAS Design Pattern\". A common design is the Orchestrator-Workers paradigm [9, 10], where the Orchestrator comprehends the task and distributes subtasks to Workers via transfer actions. The Workers, acting as sub-agents, execute the subtasks and return the results to the Orchestrator through transfer actions."}, {"title": "3 The AutoAgent Framework", "content": "AutoAgent is designed to be the automated operating system for LLM agents and general AI assistant. Inspired by modern computer operating systems, AutoAgent consists of key components that enable seamless natural language-driven agent development and task execution, as illustrated in Fig 2. Its Agentic System Utilities provide foundational building blocks for complex agent-driven tasks, while the LLM-powered Actionable Engine forms the central brain, understanding inputs and orchestrating multi-agent coordination. The Self-Managing File System manages structured storage and retrieval of user multi-modal data, and the Self-Play Agent Customization empowers users to generate specialized, tailored agents and workflows through natural language, without any coding requirements. Collectively, these robust capabilities make AutoAgent a versatile and powerful platform, powering a variety of autonomous agent-based solutions for diverse applications."}, {"title": "3.1 Agentic System Utilities", "content": "The AutoAgent framework employs a modular, multi-agent architecture to address the key challenge of developing intelligent personal assistant agents capable of seamlessly integrating and coordinating diverse capabilities, from web browsing and information retrieval to data analysis and code execution. This design choice, which comprises specialized agents for web, coding, and file management tasks, as well as an orchestrator agent to decompose and delegate user requests, enables the agentic system utilities to serve as a versatile and extensible foundation that can adapt to a wide range of user requirements, facilitating the rapid development of tailored, agent-driven solutions. Detailed system prompts and tool definitions for Agentic System Utilities can be found in Appendix Sec 6."}, {"title": "3.1.1 Orchestrator Agent", "content": "The Orchestrator Agent is the primary interface for interacting with the user. It receives tasks from the user, comprehends the tasks, decomposes them into sub-tasks, and delegates these sub-tasks to appropriate sub-agents using the handoff tools [21]. Once a sub-agent completes a sub-task, it returns the result to the Orchestrator also using the handoff tool. Based on the task completion status, the Orchestrator continues to assign the next sub-task to a suitable agent. This iterative process continues until the entire task is completed. The Orchestrator, designed with the handoff mechanism, is a simple yet effective solution, eliminating the need for complex prompts to handle task planning."}, {"title": "3.1.2 Web Agent", "content": "The Web Agent provides a versatile and extensible set of tools that enable the agent to perform a wide range of web-based tasks, from general web searches to file downloads.\nFunctionality. The Web Agent performs web searches, navigate to pages, browse content, and download files. We abstract web browsing behaviors into 10 high-level tools (actions), such as: click, web_search, visit_url, etc., which the agent can use to complete web-based tasks.\nEnvironment. In this work, we implement the browser environment based on BrowserGym [18]. This environment defines low-level, code-driven browser behaviors, such as the execution code for clicking a specific browser element. The high-level tools used by the agent are implemented by combining these low-level actions, significantly enhancing the extensibility of the tool definitions."}, {"title": "3.1.3 Coding Agent", "content": "The Coding Agent is the agent's comprehensive and versatile solution for tackling a wide range of code-driven tasks. It empowers the agent to effortlessly handle complex challenges, from data analysis and calculations to machine learning, automation, and system administration. This seamlessly integrated, feature-rich agent serves as the primary interface for all code-related activities, abstracting complexities to enable focused problem-solving. In essence, the coding agent provides a secure environment to explore, execute, and interact with code to achieve diverse objectives.\nFunctionality. The Coding Agent is designed to handle a wide range of code-related operations. We have abstracted these capabilities into 11 distinct tools (actions), including the creation of code scripts and directories, execution of Python code, implementation of specific commands, and navigation of directory structures. This versatile toolset enables the Coding Agent to address a diverse array of everyday tasks that require programmatic solutions.\nEnvironment. The Coding Agent operates within an interactive terminal environment, where the results of all code-related tools are returned to the agent as observations through the terminal output. When the output exceeds the display capacity, the terminal presents it in a paginated form, allowing the agent to navigate through the content using commands such as terminal_page_up, terminal_page_down, and terminal_page_to. This ensures that the agent can access and review the full output without encountering issues related to the LLM's context length limitations.\nTo ensure safety, all code-related operations run in a secure Docker sandbox. We support third-party sandboxing integration, like the E2B system [22], further enhancing the safety and reliability of the agent's code-driven activities. This provides robust protection for local data during execution."}, {"title": "3.1.4 Local File Agent", "content": "The key objective of the Local File Agent is to provide a unified set of tools to convert and analyze various local multi-modal data types. This includes text, video, audio, spreadsheets, and other formats to assist users with everyday tasks in an efficient manner.\nFunctionality. Users need to handle a wide variety of file types, including text documents (e.g., .doc, .pdf, .txt, .ppt), videos (e.g., .mp4, .mov), audio files (e.g., .wav, .mp3), spreadsheets (e.g., .csv, .xlsx), and other multi-modal and multi-format files. Therefore, a dedicated Local File Agent for managing and analyzing local files is crucial. This Local File Agent can use a unified set of tools to convert files into Markdown and perform effective analysis to assist with everyday tasks.\nEnvironment. The interaction environment for the Local File Agent is similar to the Coding Agent, utilizing an interactive Markdown Browser. Files converted into Markdown format can be displayed in paginated form within the Markdown Browser, enabling the agent to analyze long texts and complex files that exceed the context length limitations."}, {"title": "3.2 LLM-powered Actionable Engine", "content": "As the CPU executes instructions, manages resources, and coordinates processes in an OS, the LLM-powered actionable engine can understand natural language, generate plans, and coordinate tasks across agents. This enables seamless human-agent collaboration and task completion.\nWe utilize LiteLLM [23] to standardize LLM requests through an OpenAI-like interface, supporting 100+ models from various providers. For agent collaboration, the LLM receives all action-observation pairs up to time t as state $s_t$ to determine the next action. These pairs serve as system RAM, facilitating efficient retrieval and enabling language-driven system coordination."}, {"title": "3.2.1 Generating Actionable Reflections", "content": "We generate reflections (i.e., actions) based on LLM context, which can be broadly categorized into two distinct approaches that leverage the language model's capabilities.\nDirect Tool-Use Paradigm. This approach is suitable for commercial LLMs or LLM serving platforms that support tool-use. These LLMs can directly generate a parsed next-step tool to execute based on the provided tool set and the current state, reducing errors during the tool parsing phase. However, this method heavily relies on the optimization of the third-party platform's capabilities.\nTransformed Tool-Use Paradigm. This approach does not rely on the LLM's inherent tool-use capabilities. Leveraging the superior code-generation abilities of modern LLMs, we transform the tool-use paradigm into a structured XML code generation task, e.g., <function=function_name> <parameter=parameter_1>value_1</parameter> </function>. This structured output is then parsed to extract critical information like tool arguments and others. It improves the performance of commercial models with suboptimal tool-use capabilities and enables the integration of open-source LLMs into the system, providing greater flexibility and customization."}, {"title": "3.3 Self-Managing File System", "content": "The file system in AutoAgent is a vector database that LLM agents can retrieve and understand. In our design framework, users can upload text files in any format (e.g., .pdf, .doc, .txt) or compressed archives and folders containing any text files. The system tools in the file system automatically convert these files into a consistent text format and store them in a user-defined collection within the vector database (using the save_raw_docs_to_vector_db tool). This enables agents to self-manage their database memory and perform efficient and accurate retrieval and generation using tools like query_db and answer_query. The detailed definitions of the tools are presented in Tab 4."}, {"title": "3.4 Self-Play Agent Customization", "content": "To allow users to customize tools and agents for specific scenarios or build their own multi-agent systems and workflows, it is designed as a code-driven, controllable self-programming agent framework. By implementing constraints, error-handling mechanisms, and customized workflows, it enables controlled code generation, facilitating the creation of tools, agents, and workflows. The AutoAgent supports two distinct modes: agent creation without workflow and agent creation with workflow."}, {"title": "3.4.1 Agent Creation without Workflow", "content": "Building effective multi-agent systems often requires domain-specific expertise, such as in-depth knowledge of financial regulations or healthcare protocols. However, this level of specialized know-how may not always be available to users. For example, in the financial services, constructing a multi-agent system to automate complex investment portfolio management would necessitate expertise in areas like asset allocation, risk modeling, and regulatory compliance."}, {"title": "3.4.2 Agent Creation with Workflow", "content": "When users have specific requirements for a MAS's workflow and domain knowledge, AutoAgent allows a tailored approach. In this mode, users provide descriptions of the desired agent(s) and specify the tasks they want the created agent(s) or workflows to accomplish. AutoAgent then uses this information about the target tasks to generate not just the individual agent(s), but also the necessary workflow(s) to coordinate their collaborative efforts in achieving the specified objectives.\nTraditional graph-based methods often require strict adherence to graph theory principles [25-28], a task challenging for LLMs when generating workflows. To overcome these challenges, AutoAgent adopts an event-driven approach where we model each agent's task-solving as an event. By leveraging event listening and triggering mechanisms, AutoAgent enables seamless collaboration between agents, offering greater flexibility and adaptability compared to rigid graph structures.\nConstructing New Workflows. The process of creating a new workflow is itself a multi-agent workflow. The Workflow Form Agent analyzes the requirements and existing tools/agents to determine if new agents need to be created, which agents should form the workflow, and what the listening and triggering logic between events should be. It then generates structured XML code."}, {"title": "4 Evaluation", "content": ""}, {"title": "4.1 Evaluation for a Generalist Agent System", "content": "Benchmark Dataset and Evaluation Protocols. The GAIA benchmark [29] is a comprehensive evaluation framework to assess General AI Assistants. It tests fundamental abilities like Reasoning, Multi-Modality Handing, Web Browsing, and Tool-Use Proficiency through a rigorous set of 466 test and 165 validation questions, divided into 3 distinct difficulty levels.\nGAIA emphasizes the importance of developing AI systems that can match human performance on everyday tasks, serving as a milestone for assessing progress toward AGI. Specifically, we evaluated our AutoAgent on the GAIA validation set, using success rate as the primary evaluation metric. This metric measures the percentage of tasks successfully completed, providing a clear indicator of its performance in handling real-world, human-like challenges.\nBaseline Methods. The baselines we selected are divided into two categories: Open-Source: FRIDAY [30], Magentic-1 [9], Multi-Agent Experiment v0.1 (powered by AutoGen) [31], HuggingFace Agents[32], Langfun Agent [33]; Closed-Source: TapeAgent, AgentIM, Trase Agent [34], Omne, Barcelona2, and the h2oGPTe Agent [35]. These diverse baselines represent the current state-of-the-art in open-source and proprietary multi-agent systems, providing a comprehensive landscape for evaluating the performance and capabilities of our proposed AutoAgent framework.\nImplementation Details. To address tasks in the GAIA benchmark, we utilize a combination of the System Utilities of the Model and the Tool Editor Agent from the Agentic-SDK. The basic agents first attempt to complete the task while collecting relevant information and reflections. If successful, the result is directly returned. If not, the Tool Editor Agent creates new tools to continue the task. During validation, Claude-Sonnet-3.5 is used by default."}, {"title": "Evaluation Results and Analysis", "content": "The results in Table 1 reveal the following key observations:\n\u2022 Obs.1. Overall Superiority of AutoAgent: Our method significantly outperforms all open-source agent systems and achieves performance close to the latest agent system, h2oGPTe Agent v1.6.8 (submitted on December 16, 2024), securing a stable position in the top 2 rankings. Notably, our approach demonstrates superior performance on Level 1 tasks compared to all state-of-the-art baselines, becoming the first method to achieve over 70% accuracy rate. This success is attributed to the well-designed System Utilities and the stable interaction of basic agents with the environment, enabling efficient solutions to everyday simple tasks.\n\u2022 Obs.2. Effectiveness of Key Components: Specifically, our framework demonstrates significantly superior performance compared to Magentic-1 [9], a recent representative open-source MAS, and FRIDAY, a classic self-improved framework. While Magentic-1 leverages the powerful reasoning capabilities of o1-preview to design complex Orchestrator Agent (also the Coder Agent), our framework emphasizes the stability of interactions between sub-agents and their respective environments, as well as the precision of tool definitions. Under these conditions, the Orchestrator Agent achieves better results with simple prompts and handoff tools.\n\u2022 Obs.3. Error Analysis: The analysis revealed two key limitations in the current evaluation protocol of the GAIA benchmark system: strict string matching that ignores semantic equivalence (e.g., \"840 citations\" vs. \"Citations\") and challenges posed by dynamic, anti-automation mechanisms during web searches. These issues underscore the need for a more semantically-aware evaluation approach to improve the system's effectiveness."}, {"title": "4.2 Evaluation of AutoAgent on the Retrieval-Augmented Generation (RAG) Task", "content": "Benchmark Dataset and Evaluation Protocols. To test the basic functionalities of the AutoAgent, we use the RAG task as the testing benchmark. MultiHop-RAG [36] is a dataset designed to evaluate RAG capabilities, requiring the RAG methods to gather information from multiple sources and generate responses, which aligns with the file functionality logic of AutoAgent. We evaluate using two metrics: Accuracy (Acc) measures response consistency with expected answers (e.g., \u201cChatGPT\u201d or \"OpenAI's ChatGPT\" are both correct for \"Which AI tool reached 100M daily users in March?\"). Error (Err) counts confident but incorrect responses (e.g., answering \u201cBard\u201d to the above query).\nBaseline Methods. The baselines represent a diverse range of LLM-based RAG techniques. The chunk methods, such as NaiveRAG [37] and HyDE [38], utilize the original text segmentation. The graph methods, including MiniRAG [39] and LightRAG [40], manage files as sophisticated graphs. In contrast, Langchain's Agentic RAG [1] innovatively accesses files through intelligent software agents. These baselines cover a wide array of strategies for leveraging large language models to retrieve and generate robust responses.\nImplementation Details. We used gpt-40-mini [41] as the LLM and text-embedding-3-small for embeddings. We followed MultiHopRAG [36] for text chunking, with 256-token chunks and top-6 retrieval. This leverages the gpt-40-mini's language abilities while text-embedding-3-small provides retrieval, with MultiHopRAG's chunking managing information effectively."}, {"title": "Evaluation Results and Analysis", "content": "The key observations from the results:\n\u2022 Superior Performance of AutoAgent. The results clearly demonstrate the superior performance of our proposed AutoAgent model compared to other baselines on the Multihop-RAG task. By leveraging a more flexible and adaptive agent-based framework, AutoAgent is able to dynamically orchestrate the retrieval and reasoning process, outperforming even other agentic approaches.\n\u2022 AutoAgent vs. LangChain. Our method significantly outperforms LangChain, which is also an agentic RAG. This is due to AutoAgent's more flexible framework, where agents do not need to rely on predefined workflows and tools to execute file search tasks. The proposed model can orchestrate workflows on the fly during the search process, leading to more efficient and accurate results."}, {"title": "4.3 AutoAgent's Performance on Open-Ended Tasks", "content": "This section thoroughly explores the capabilities of the AutoAgent framework in generating agents and workflows based on even vague, natural language inputs across various scenarios. To illustrate the breadth of AutoAgent's abilities, we will examine its performance on tasks of varying difficulty - from the creation of a single agent to the orchestration of multiple, coordinated agents."}, {"title": "5 Conclusion", "content": "The AutoAgent framework marks a significant advancement in democratizing LLM-powered agent technology, making it accessible to the non-programming majority. By bridging high-level natural language requirements with the practical implementation of multi-agent systems and workflows, MetaChain empowers users to create, customize, and deploy agents, tools, and workflows without requiring substantial technical expertise. Its modular architecture, versatile Agentic System Utilities, and LLM-powered Actionable Engine work together to enable seamless automation of agent development and task execution. Unique features such as the Self-Organizing File System and Self-Play Agent Customization further enhance AutoAgent's capabilities, allowing for dynamic agent evolution and task-specific optimization. Extensive evaluations demonstrate AutoAgent's superior performance, highlighting its transformative potential in making LLM capabilities accessible to a broad user base."}, {"title": "6 Appendix", "content": "In the supplementary materials, we provide a detailed technical description of the 'Agentic System Utilities' implementation within our AutoAgentframework."}, {"title": "6.1 System-level Tools", "content": "To empower our diverse array of system-level agents, we have carefully curated and predefined seven distinct categories of powerful tools. These tools span a wide range of functionalities, including coding, web browsing, file management, creating new tools, agents, and workflows, as well as natural language question answering for documents. The detailed names and comprehensive descriptions of these versatile tools are presented in Table 4."}, {"title": "6.2 Web Agent", "content": "The specific tools and system prompt for implementing the Web Agent are as follows:"}, {"title": "6.3 Local File Agent", "content": "The Local File Agent is equipped with a tailored set of tools and system prompts to enable it to efficiently manage and interact with files and directories. This specialized toolkit includes:"}, {"title": "6.4 Coding Agent", "content": "The specific tools and system prompts for implementing the Coding Agent are as follows:"}, {"title": "6.5 Orchestrator Agent", "content": "The specific tools and system prompt for implementing the Orchestrator Agent are as follows:"}, {"title": "6.6 Detailed Implementation of \u201cSelf-Play Agent Customization\u201d in AutoAgent", "content": ""}, {"title": "6.6.1 Agent Creation without Workflow", "content": "The following details demonstrate the specific process of Agent Creation without Workflow (Alg 1), as well as the tools and system prompts used in the implementation of Agent Profiling Agent, Tool Editor Agent, and Agent Editor Agent."}, {"title": "6.6.2 Agent Creation with Workflow", "content": "The following details demonstrate the specific process of Agent Creation with Workflow (Alg 2), as well as the tools and system prompts used in the implementation of Workflow Profiling Agent and Workflow Editor Agent."}, {"title": "6.7 Supplementary Experimental Findings", "content": ""}, {"title": "6.7.1 Case of 'DaVinci Agent'", "content": "The XML Form of DaVinci Agent generated by the Agent Profiling Agent is shown in List 17. The logos of our AutoAgent generated by the created DaVinci Agent are displayed in Fig 3."}, {"title": "6.7.2 Case of 'Financial Agent'", "content": "The XML Form of Financial Agent generated by the Agent Profiling Agent is shown in List 18. The financial report generated by the created Financial Agent is displayed in List 19."}, {"title": "6.7.3 Case of 'Majority Voting' workflow", "content": "The XML Form of 'Majority Voting' Workflow generated by the Workflow Profiling Agent is shown in List 20. A comparison between the math reasoning results of the created \u2018Majority Voting' Workflow and the math reasoning results of a single DeepSeek-V3 model is presented in Tab 5."}]}