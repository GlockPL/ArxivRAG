{"title": "HyperGCL: Multi-Modal Graph Contrastive Learning via Learnable Hypergraph Views", "authors": ["Khaled Mohammed Saifuddin", "Jonathan Shihao Ji", "Esra Akbas"], "abstract": "Recent advancements in Graph Contrastive Learning (GCL) have demonstrated remarkable effectiveness in improving graph representations. However, relying on predefined augmentations (e.g., node dropping, edge perturbation, attribute masking) may result in the loss of task-relevant information and a lack of adaptability to diverse input data. Furthermore, the selection of negative samples remains rarely explored. In this paper, we introduce HyperGCL, a novel multimodal GCL framework from a hypergraph perspective. HyperGCL constructs three distinct hypergraph views by jointly utilizing the input graph's structure and attributes, enabling a comprehensive integration of multiple modalities in contrastive learning. A learnable adaptive topology augmentation technique enhances these views by preserving important relations and filtering out noise. View-specific encoders capture essential characteristics from each view, while a network-aware contrastive loss leverages the underlying topology to define positive and negative samples effectively. Extensive experiments on benchmark datasets demonstrate that HyperGCL achieves state-of-the-art node classification performance.", "sections": [{"title": "I. INTRODUCTION", "content": "Building on the success of contrastive learning (CL) in computer vision and natural language processing [1], [2], CL approaches have been extended to graph data-known as Graph Contrastive Learning (GCL)\u2014where Graph Neural Networks (GNNs) learn robust representations by maximizing agreement between augmented graph views [3]\u2013[6]. Nonetheless, current GCL methods still exhibit several limitations.\nFirst, they often depend on handcrafted augmentations such as node dropping, edge perturbation, and attribute masking. While these techniques can be effective, they risk discarding crucial task-relevant information and force models to rely on specific hyperparameter settings [7]-[9]. Second, most methods primarily treat the graph structure and node attributes as a single, unified source of information [3], [4], overlooking the distinct yet complementary roles that topology and attribute can play in uncovering complex patterns. Third, they generally focus on local pairwise (dyadic) relationships, limiting their ability to capture higher-order global patterns [4], [10], [11]. Fourth, many GCL strategies employ contrastive losses originally designed for image data, often overlooking the distinct characteristics of graph-structured data, such as the homophily principle [12]. These approaches typically treat all non-positive nodes as negative examples, resulting in a large number of negative samples and leading to high computational and memory overhead [7], [10].\nTo address these issues, we propose HyperGCL, a multimodal attribute and structure-aware GCL framework from a hypergraph perspective. Hypergraphs naturally model complex systems and can capture hidden higher-order information present in networks even in standard graphs. Unlike prior GCL models that often treat graph structure and its attributes as a unified source of information and mainly focus on dyadic relations, our approach considers them as two distinct modalities and generates different hypergraph views for CL. Specifically, we design three distinct hypergraph views from graph structure and its attributes to capture different granularities of higher-order information for CL. These views include an attribute-driven hypergraph that leverages existing attributes of nodes representing semantic information and two structure-driven hypergraphs (local and global) that leverage varying graph structural information. This multimodal design allows HyperGCL to effectively capture various perspectives from the input graph, providing a richer and more robust framework for representation learning. Moreover, instead of using predefined augmentation techniques, we utilize an adaptive model for each hypergraph view using a learnable Gumbel-Softmax function [13]. This introduces controlled stochasticity, enhancing the diversity and quality of training samples for CL. The dynamic adjustment of the augmentation process improves the discriminative power of the views by selectively highlighting key relationships within the hypergraph.\nWe employ view-specific encoders for each augmented view. For attribute-driven hypergraph view, we use the Hypergraph Attention Network (HyGAN) [14], [15] that learns node embeddings by identifying semantically important nodes and hyperedges. However, since HyGAN focuses on semantic features, directly applying it to structure-driven hypergraphs may result in the loss of structural information. To address this, we introduce Structure-aware HyGAN (SHYGAN), a specialized variant that incorporates node structure information in the input layer and structural biases in the attention layers, ensuring the capture of both semantic and structural information.\nUnlike traditional GCL methods that adopt contrastive losses tailored for computer vision, such as InfoNCE [16] or NT-Xent [17], we introduce a novel network-aware contrastive loss, NetCL. This loss builds upon NT-Xent by leveraging the network topology to define positive and negative samples more effectively. To further optimize the selection of negative samples, we propose two selective negative sampling strategies: (1) distance-based, and (2) similarity-based. These strategies reduce the size of the negative sample while maintaining its effectiveness in the contrastive framework.\nThe contributions of this work are summarized as follows:\n\u2022 Multimodal Hypergraph View Generation and Adaptive Augmentation: In HyperGCL, we introduce a novel multimodal framework that generates three hypergraph views to capture diverse granularities of structural and attribute-driven information. To ensure robustness, we propose a learnable augmentation mechanism using a Gumbel-Softmax function, eliminating the need for predefined augmentations.\n\u2022 View-Specific Encoder: HyperGCL employs view-specific encoders to learn view embeddings. We apply HYGAN for attribute-driven hypergraphs and introduce SHYGAN for structure-driven hypergraphs to capture both semantic and structural information effectively.\n\u2022 Network-Aware Contrastive Loss (NetCL): We propose NetCL, a topology-guided contrastive loss that leverages network structure to define positive and negative samples, aligning multimodal hypergraph representations while optimizing computational efficiency."}, {"title": "II. RELATED WORK", "content": "Contrastive Learning (CL) has become a powerful paradigm for graph representation learning by maximizing agreement across augmented views [18]. Early work such as DGI [19], inspired by Deep InfoMax [20], maximizes mutual information between local patches and a global summary. Later approaches generate multiple views using various augmentations, e.g., feature/edge masking [8], node dropping, subgraph extraction [7], node/edge insertion/deletion [9], or graph diffusion [5], [21]. However, most GCL methods still employ contrastive loss functions from computer vision, typically treating the same node in different views as a positive sample and all other nodes as negatives, thereby overlooking inherent graph topology [7], [10].\nHypergraph Neural Networks (HyperGNNs) extend GNNs to model complex relationships through hyperedges connecting multiple nodes. HGNNs [22] and HyperGCN [23] were pioneers, applying spectral convolution to hypergraphs using clique expansion and hypergraph Laplacians. Moreover, attention-based models like HAN [24] and HyperGAT [14] adaptively learn node and hyperedge importance. HyperSAGE [25] and UniGNN [26] avoid information loss by directly performing message passing on hypergraphs. The AllSetTransformer [27] combines Deep Sets [28] and Set Transformers [29] for enhanced flexibility and expressive power."}, {"title": "III. METHODOLOGY", "content": "This section outlines the components of HyperGCL: Hypergraph View generation and adaptive augmentation, View-Specific Hypergraph Encoder, and Network-Aware Contrastive Loss (NetCL). Figure 1 presents the system architecture."}, {"title": "A. Multimodal Hypergraph View Generation and Adaptive Augmentation", "content": "Graphs are effective for modeling pairwise relationships between nodes but often fail to capture complex higher-order interactions. Moreover, most graph learning methods treat the graph structure and the node attributes as a unified source of information. This blending can obscure the distinct yet complementary roles that topology and attributes play in uncovering intricate patterns. To address this, we treat the graph structure G = (V, E)\u2014where V_denotes the set of nodes and E represents the edges and node attributes X \u2208 R|V|\u00d7d, where d is the feature dimension as distinct modalities. By leveraging these two modalities, we generate multiple hypergraph views for contrastive learning: attribute-driven, local structure-driven, and global structure-driven hypergraphs. Each view captures unique granularities, uncovering higher-order interactions while preserving and integrating the multimodal information inherent in topology and attributes for richer representations.\n1) Attribute-driven Hypergraph View (Ha): To incorporate attribute information, we construct an attribute-driven hypergraph by grouping semantically similar nodes into hyperedges. Specifically, we apply both k-nearest neighbors (k-NN) and k-means clustering to the node attributes X. Using k-NN, each node vi \u2208 V and its k closest neighbors form an initial hyperedge. Formally, for each node vi, a hyperedge \u0113j is formed as:\n\u0113j = {Vi} \u222a {Vk \u2208 V | vk is a k nearest neighbor of vi}.\nAdditionally, the clusters derived from k-means are also used to create hyperedges. Let C = {C1, C2,..., Ck} be the set of clusters obtained from k-means. Each cluster Ce is treated as a hyperedge \u0113c, where \u0113c = Cc. Each node vi is then assigned to its s nearest clusters, chosen based on the smallest Euclidean distances from vi to the respective cluster centers. Formally, for each node vi, the set of hyperedges it belongs to is given by:\nej = {\u0113j | vi \u2208 ej} \u222a {\u0113j | vi \u2208 Cj and\nCj is one of the s closest clusters to vi}.\nCombining all hyperedges produced by k-NN and k-means yields the attribute-driven hypergraph Ha = (V, Ea), where Ea is the set of all constructed hyperedges. This framework effectively captures higher-order relationships among nodes based on their semantic similarities.\n2) Structure-driven Hypergraph Views: While attribute-driven hypergraphs effectively preserve node semantic similarity, they often overlook the original graph's structural properties. To address this gap, we construct two additional hypergraph views-local and global that capture different levels of structural information.\ni. Local Structure-driven Hypergraph View (Hl). To capture local structural context, we represent each node's 1-hop ego network as a hyperedge. Specifically, for each node vi \u2208 V, we form the hyperedge e' by including vi and all of its 1-hop neighbors. Formally,"}, {"title": "ii. Global Structure-driven Hypergraph View (H9).", "content": "To capture higher-order structural relationships on a global scale, we form hyperedges from subgraphs that extend beyond local neighborhoods. Although there are multiple ways to define such higher-order structures (e.g., cliques, motifs), we focus on communities\u2014densely interconnected subgraphs that capture group-level interactions. Concretely, let CM = {CM1,CM2,...,CMk} denote a set of communities. Each community CMC is then represented as a hyperedge by its constituent nodes as: \u0113 = CMC. By collecting all such hyperedges, we obtain the global structure-driven hypergraph Hg = (V, Eg), where Eg is the set of hyperedges derived from the identified communities. This construction encapsulates broad structural patterns in the graph, complementing the local perspective captured by Hl.\nWhen representing each community as a hyperedge, it is crucial to ensure overlaps between communities to maintain the connectivity of the hypergraph. Therefore, we explore various overlapping community detection methods and ultimately adopt the algorithm described in [30], as it demonstrated superior performance in our experiments. This algorithm uses edge attributes as weights. In cases where the input graph lacks these attributes, we assign a uniform weight of 1 to each edge. By gathering all identified communities as hyperedges, we form the hypergraph H\u00ba = (V,E9), where E9 represents the set of all hyperedges derived from communities.\nIt is important to note that even after applying the overlapping community detection algorithm, some communities may remain isolated, resulting in hyperedges that are not interconnected. This isolation can stop the flow of information within the hypergraph. To address this and enhance connectivity, we incorporate global nodes selected based on their high closeness centrality scores from the input graph. Closeness centrality, which measures the average shortest distance of a node to all other nodes, helps identify nodes that can efficiently disseminate information across the network. By linking these centrally located global nodes to hyperedges, we significantly improve the interconnectivity and information exchange across the hypergraph, ensuring a more cohesive and efficient network structure."}, {"title": "3) Adaptive View Augmentation", "content": "In each hypergraph view, we introduce a learnable Gumbel-Softmax function to adaptively augment the hyperedges. We begin by initializing learnable logits that represent the probability of each node's association with a particular hyperedge. For each node vi, we perturb its logits \u03c6\u03c5\u2081 with Gumbel noise \u20ac and apply the Softmax function as follows: pvi = softmax( ${\u03c6_{v_i} + \u03b5}/\u03c4$), where\nTis the temperature parameter. The binary mask for node vi is obtained by applying a threshold 0 to pvi as mvi =(pv\u2081 > 0). To ensure gradients propagate through the Softmax probabilities pv, instead of the binary mask mv, we employ the straight-through estimator as mvi = (mv; - pvz) + pvi.\nThe final augmented hypergraph view is produced by element-wise multiplying the binary mask matrix M, composed of all mv, with the original hypergraph incidence matrix A as A = M\u2299A. This adaptive augmentation technique also works as a method for refining the hypergraph views. By leveraging this learnable Gumbel-Softmax-based augmentation strategy, our approach ensures the generation of diverse samples, enhancing the effectiveness of CL in hypergraph settings."}, {"title": "B. View-Specific Hypergraph Encoder", "content": "To generate node embeddings from each view, we utilize view-specific encoders capturing different granularities of information. We apply HyGAN to the attribute-driven hypergraph view generating node embedding matrix Za. Similarly, we define SHYGAN to apply on the local structure-driven hypergraph view and the global structure-driven hypergraph view, generating the node embedding matrices Zl and Zg, respectively. These embeddings are then utilized in contrastive loss functions to preserve different granularities of information.\nHyGAN: Motivated by [14], [15], we employ the Hypergraph Attention Network (HyGAN) on the attribute-driven hypergraph view focusing on capturing attribute-based semantic information. HyGAN accomplish this by employing a two-level attention mechanism: node-to-hyperedge level attention and hyperedge-to-node level attention.\nWhile the node-to-hyperedge level attention mechanism aggregates node information into hyperedge representations, it also pinpoints which nodes carry higher semantic importance within each hyperedge and assigns them greater weight during aggregation. Concretely, the representation of hyperedge ej at the l-th layer, denoted by q, is formulated as:\n$q^{l}_{e_j}= \\sum\\limits_{v_i \\in e_j} [\\Gamma_{ji}^{l}W_{1}^{l}p_{v_i}^{l-1}]$,\nwhere, $\\Gamma_{ji}^{l} = \\frac{exp(r_{ji}^{l})}{\\sum_{v_k \\in e_j} exp(r_{jk}^{l})}$,\n$r_{ji}^{l} = \\frac{1}{\\sqrt{d_{hid}}} \\beta (W_{2}^{l} p_{v_i}^{l-1} \\odot W_{3}^{l} q_{e_j}^{l-1})$.\nHere, rji is the attention coefficient of node vi in hyperedge ej at the l-th layer. The function \u03b2 is a non-linear activation, each W represents a trainable weight matrix, pvi and qej are the representations of node vi and hyperedge ej, dhid is their hidden dimension, and is the Hadamard product.\nSimilarly, the hyperedge-to-node level attention mechanism aggregates hyperedges to generate node representations. It employs an attention mechanism to identify hyperedges that are semantically important for each node and assign them more weights during aggregation. Formally, the representation of node vi at the l-th layer, denoted p, is defined as:\n$p_{v_i}^{l} = \\sum\\limits_{e_j \\in \\varepsilon_i} [\\Lambda_{ij}^{l} W_{4}^{l} q_{e_j}^{l-1}]$,\nwhere, $\\Lambda_{ij} = \\frac{exp(\\gamma_{ij}^{l})}{\\sum_{e_k \\in \\varepsilon_i} exp(\\gamma_{ik}^{l})}$,\nand, $\\gamma_{ij}^{l} = \\frac{1}{\\sqrt{d_{hid}}} \\beta (W_{5}^{l} q_{e_j}^{l-1} \\odot W_{6}^{l} p_{v_i}^{l-1})$.\nHere, y denotes the attention coefficient of hyperedge ej on node vi at the l-th layer.\nStructure-aware HyGAN (SHYGAN): While HyGAN focuses on attribute-based semantic features to identify important nodes and hyperedges, this approach can lead to a loss of structural information when applied directly to the structure-driven hypergraph. To address this limitation, we introduce a specialized variant of HyGAN called Structure-aware HyGAN (SHYGAN) by introducing a two-level topology-guided attention network. SHYGAN leverages structural inductive biases in the attention layers to identify significant nodes and hyperedges from both semantic and structural perspectives. Additionally, SHYGAN incorporates learnable nodes' structural feature encoding to enhance the initial node features.\n1) Node's Structural Feature Encoding: A node's significance in graph data is defined by its connectivity and role within the graph's structure, not just its individual attributes, where regular models often miss these distinctions. To capture these structural details, we introduce three structure encoding techniques: (1) Local Connectivity Encoding (lce), (2) Centrality Encoding (ce), and (3) Distinctiveness Encoding (de). These are combined with the initial node features xv of each node vi to enrich the overall representation as follows:\n$x_{v_i} = Sum(x_{v_i}, lce_{v_i}, ce_{v_i}, de_{v_i})$.\ni. Local Connectivity Encoding: When we represent each community as a hyperedge, we risk losing important local connectivity information between the nodes, which may be vital for accurate hyperedge representation. To address this issue, we apply a Graph Convolutional Network (GCN) to the input graph, capturing crucial local connectivity patterns. Specifically, the local connectivity encoding for each node vi is computed as: lcev\u2081 = Gconn (vi, N(vi); \u03a6), where lcev; represents the local connectivity encoding for node vi, derived using Geonn, a GCN function, which processes the neighborhood N(vi) with trainable parameters \u03a6.\nii. Centrality Encoding: To capture the role and influence of each node, we incorporate closeness centrality into the node features. Nodes with higher closeness centrality are closer to all other nodes in the graph, indicating that they can disseminate information more efficiently. We map these centrality scores into embedding vectors via a learnable function Gcentral, defined as: cevi = Gcentral(c; 4), where c is the vector of nodes' centrality scores, and 4 is a learnable parameter.\niii. Distinctiveness Encoding: Nodes appearing in multiple hyperedges may lose distinctiveness, reducing their significance. We define a distinctiveness score d for each node vi as:\n$d_{v_i} = 1 - \\frac{|E_{v_i}|}{|E|}$,\nwhere Evi is the number of hyperedges node vi belongs to, and |E| is the total number of hyperedges. Higher counts result in lower Distinctiveness scores. We generate an distinctiveness encoding de for each node, via a learnable function GDistinct defined as devi = GDistinct (d; 5), where d is the vector of nodes' Distinctiveness scores, and ( is a learnable parameter.\n2) Topology-Guided Attention: We design topology-guided attention that employs structural inductive biases in the attention layers, enabling the model to identify key nodes and hyperedges from both semantic and structural perspectives. We define two structural inductive biases."}, {"title": "i. Node Importance via Local Clustering Coefficient.", "content": "As a measure of node importance, the local clustering coefficient (lc) for a given node vi within a community ej quantifies the density of connections among its neighbors. It is defined as the ratio of the actual number of connections among the neighbors, Iji, to the maximum possible connections within the community. Mathematically, it is expressed as:\n$lc_{e_ji} = \\frac{2I_{ji}}{g_{ji}(g_{ji} - 1)}$,\nwhere gji represents the degree of node vi in the subgraph associated with hyperedge ej. This metric captures the extent of tightly-knit clusters around a node, reflecting its role in facilitating enhanced information flow within the network. We incorporate lc as a structural inductive bias into Equation 3 as follows:\n$\\Gamma_{ji}^{l} = \\frac{1}{\\sqrt{d_{hid}}} \\beta (W_{2}^{l} p_{v_i}^{l-1} \\odot W_{3}^{l} q_{e_j}^{l-1})+lc_{e_ji}$.\nii. Hyperedge Importance via Density Score The structural significance of hyperedges can be quantified by evaluating their connectivity and cohesion within a hypergraph. Hyperedges containing more nodes are generally regarded as more influential for a given node compared to those with fewer nodes to which it belongs. We formalize this by defining hyperedge density, hd, which measures the fraction of the number of nodes me; within a hyperedge ej relative to the total number of nodes m in the hypergraph. Formally represented as hd = $\\frac{m_{e_j}}{m}$. A higher hd value signifies greater interconnectivity among the nodes within the hyperedge, indicating a more cohesive and significant group. We integrate hd as a structural inductive bias into Equation 6 as follows:\n$\\gamma_{ij}^{l} = \\frac{1}{\\sqrt{d_{hid}}} \\beta (W_{5}^{l} q_{e_j}^{l-1} \\odot W_{6}^{l} p_{v_i}^{l-1})+hd_{ij}$."}, {"title": "C. Network-Aware Contrastive Loss (NetCL)", "content": "We propose a novel network-aware contrastive loss, termed NetCL, via incorporating network topology as supervised signals to define positive and negative samples in HyperGCL. Specifically, instead of forming only a single positive pair per anchor as in regular CL models, NetCL allows for multiple positives per anchor. These multiple positives are defined as follows:\nPositive Samples (PosS) for a node vi include the same node vi in two different views, nodes that are neighbors of vi within the input graph, and nodes that belong to the same hyperedges as vi in at least one of the views. Formally, they can be defined as:\nPosSv\u2081 ={same node in two different views}\n\u222a {vj | vj is a neighbor of vi in the input graph}\nU {Uk | Uk belongs to the same hyperedges as vi\nin one of the views}}.\nConversely, Negative Samples (NegS) for a node vi include all other nodes that do not meet these criteria, defined as NegSv. Considering all these Negs instances is computationally expensive. To address this, we propose Distance-based and Similarity-based negative sampling strategies. In the Distance-based negative sampling strategy, for an anchor node vi, we select the top t nodes from NegSv, that are the farthest node from the anchor in the input graph. The set of distance-based negative samples for anchor node vi is denoted as Ndis (vi). In the Similarity-based negative sampling strategy, the top t nodes from NegSv, are selected based on having the lowest cosine similarity to the anchor node Vi, ensuring they are the least semantically similar. The set of similarity-based negative samples for the anchor node vi is denoted as Nsim(vi). The contrastive loss can then be applied using negative samples selected via either of these strategies. This approach provides a computationally efficient and comprehensive framework.\nIn this paper, to capture and preserve various granularities of information within the node embeddings produced by the encoders, we employ three distinct contrastive learning modules, which are i) Contrast between the attribute-driven view and the local structure-driven view, ii) Contrast between the global structure-driven view and the attribute-driven view, iii) Contrast between the local structure-driven view and the global structure-driven view.\nAfter obtaining the node embeddings Za and Zl from attribute-driven and local structure-driven hypergraphs, respectively, we adopt InfoNCE [31] to estimate the lower bound of the mutual information between them. By defining positive and negative samples, the contrastive loss function can be expressed as follows:\n$L_{a-l} = -\\frac{1}{m} \\sum\\limits_{v_i \\in V} log \\frac{\\sum_{v_j \\in Poss_{v_i}} e^{sim(z_{v_i}, z_{v_j})/\\eta}}{\\sum_{v_j \\in (Poss_{v_i} \\cup Negs)} e^{sim(z_{v_i}, z_{v_j})/\\eta}}$,\nwhere \u03b7 is a temperature parameter. Similarly, loss for contrasting the node representation from the global structure-driven view Z9 with the local structure-driven view Zl can be expressed as:\n$L_{g-l} = -\\frac{1}{m} \\sum\\limits_{v_i \\in V} log \\frac{\\sum_{v_j \\in Poss_{v_i}} e^{sim(z_{v_i}, z_{v_j})/\\eta}}{\\sum_{v_j \\in (Poss_{v_i} \\cup Negs)} e^{sim(z_{v_i}, z_{v_j})/\\eta}}$.\nFinally, loss for contrasting the attribute-driven view Za and the global structure-driven view Zg, is defined as below:"}, {"title": "A. Experimental Setup", "content": "We evaluate HyperGCL on five diverse datasets, with statistics and hypergraphs detailed in Table I. The datasets include Cora, Citeseer (CS), Wiki, Twitch-PT (PT), and LastFMAsia (LFMA), all sourced from PyTorch Geometric [32]. After an exhaustive search, global node counts are set at 3, 1, 4, 5, and 4. An overlapping community detection algorithm [30] is used with default parameters. The data is split into: 10% for training, 10% for validation, and 80% for testing.\nHyperGCL is compared against sixteen baseline models, including graph-based models (GCN [33], GAT [34], GraphSage [35], DGI [19], GMI [4], MVGRL [5], GraphCL [7], GraphMAE [36]) and hypergraph-based models (HGNN [22], HCHA [37], HyperGCN [23], DHGNN [38], HNHN [39], UniGCNII [26], AllSetTransformer [27], DHKH [40]). Baseline hypergraphs are constructed following the original methodologies. The baselines are considered if their experimental results or codes are available.\nLocal connectivity information (lce) is integrated using a two-layer GCN implemented in DGL [41]. For computing ce and de, we use learnable encoding functions based on PyTorch's Embedding layer [42]. A single-layer HyperGCL model is trained using Adam, with hyperparameters tuned via grid search on the validation set. Experiments are conducted with ten random splits, using one-hot encoded node and hyperedge initial features. Key hyperparameters include a learning rate of 0.001, dropout rate of 0.1, k = 50 (for k-NN) and k = 60 (for k-means), s = 2, t = 0.2, 0 = 0.8, t = 25, and \u03b7 = 0.5. LeakyReLU activation, two attention heads, and early stopping after 100 epochs are applied. Both HYGAN and SHYGAN use a hidden dimension of 64. All experiments are implemented in DGL with PyTorch and executed on an NVIDIA L40S-46GB GPU."}, {"title": "B. Performance Comparison", "content": "The results of our model, along with those of selected baselines, are presented in Table II. These results demonstrate the consistent superiority of our model across all datasets. Specifically, our model HyperGCLdis with distance-based negative samples, excels on the Cora dataset, achieving an impressive accuracy of 85.88%. This significantly surpasses the accuracy of the best-performing graph-based baseline model, GraphMAE, at 83.80% and exceeds the top-reported accuracy of the hypergraph-based baseline, DHGNN, which stands at 72.22%. In the case of the Citeseer dataset, our model attains an accuracy of 73.12%, outperforming the graph-based leading baseline GMI with an accuracy of 73.0%, and the hypergraph-based top-performing baseline, AllSetTransformer, at 66.60%. The trend continues with the Wiki, Twitch-PT, and LastFMAsia datasets, where our model substantially outperforms the baselines. The results underscore our model's substantial enhancements in classifying the datasets, setting a new standard compared to existing state-of-the-art methods. Moreover, this table shows that HyperGCL with distance-based negative samples HyperGCLdis performs better than similarity-based negative samples HyperGCLsim. Distance-based negative sampling chooses negative samples for a node based on network connectivity information, whereas similarity-based negative sampling uses node feature information to choose negative samples. Thus, based on the performance, we can infer that information on network connectivity is more important.\nA closer look at Table II reveals that hypergraph-based models generally lag behind the top-performing graph-based models. Traditional HyperGNNs are effective at capturing higher-order global structural information from the data. However, they might miss some important local structural information as they do not consider local connection details. Additionally, the baseline models typically create hypergraphs based on a single aspect of the underlying data. In contrast, our approach generates different types of hypergraphs by leveraging multiple aspects of the input data. Nonetheless, hypergraph-based models like DHGNN, AllSetTransformer, and DHKH show better performance compared to other hypergraph-based models. Specifically, DHGNN and DHKH simultaneously learn the hypergraph structure and hypergraph neural network, enabling them to prune noisy and task-irrelevant connections, thus improving performance. The AllSetTransformer framework, which blends Deep Sets and Set Transformers with hypergraph neural networks, offers substantial modeling flexibility and expressive power, enhancing performance in various tasks."}, {"title": "C. Ablation Study", "content": "To evaluate the contribution of different components in HyperGCL, we perform an ablation study as follows:\ni. Impact of Hypergraph Views HyperGCL incorporates three distinct hypergraph views, each capturing unique aspects of the underlying graph. To assess the impact of each view, we remove each view in turn from HyperGCLdis and compare performance. Table III shows that discarding the global structure-driven hypergraph view H\u00ba leads to the most significant performance drop, underscoring the importance of capturing global structural patterns for contrastive learning.\nii. Impact of Adaptive View Augmentation. HyperGCL employs a learnable Gumbel-Softmax function to adaptively augment each hypergraph view, generating robust samples and selectively emphasizing critical relationships for contrastive learning. To quantify its effect, we remove it and compare the results against our main model across all datasets. As presented in Table III, the absence of adaptive augmentation results in a noticeable drop in performance, highlighting its importance in producing diverse and informative training examples.\niii. Impact of NetCL Many existing GCL methods adopt a vision-inspired contrastive loss, treating an anchor node and its multiple views as positive samples, and all other nodes as negatives. This approach disregards the underlying network structure. In contrast, our proposed NetCL integrates connectivity information to more accurately define positive and negative samples. To assess its effectiveness, we remove NetCL and revert to the vision-inspired approach where each node's alternative views are positive samples and all others are negatives. As shown in Table III, excluding NetCL degrades the model's performance, underscoring the importance of incorporating structural cues into contrastive objectives.\niv. Impact of SHYGAN and its components We employ view-specific encoders for each hypergraph view: HyGAN for Ha, and a specialized variant, SHYGAN, for Hand H9. SHYGAN enhances node representations by incorporating learnable structure encodings and employs a topology-guided attention mechanism to identify important nodes and hyperedges from both semantic and structural perspectives. First, we evaluate the effect of SHYGAN by replacing it with HyGAN the results in Table III show a significant performance degradation. Additionally, to understand how each component of SHYGAN contributes, we remove them one at a time and test them on Cora and LastFMAsia. Table IV indicates that excluding local structure encoding (lse) leads to the largest performance drop, underscoring its vital role in preserving local connectivity lost when forming community-based hyperedges. This result demonstrates that capturing fine-grained local structure via a GCN is crucial for maintaining overall performance.\nv. Impact of global nodes We investigate how the number of global nodes (ng) in H\u00ba influences model performance, as illustrated in Figure 2. For the Cora dataset, accuracy rises with ng, peaking at 85.88% when ng = 3 before declining. A similar pattern is observed for LastFMAsia, achieving its highest accuracy of 85.15% at ng = 4. For Citeseer, Wiki, and Twitch-PT, the optimal values of ng are 1, 4, and 5, respectively. These results suggest that selecting an optimal number of global nodes is crucial for effectively incorporating global context without introducing excessive parameters that can degrade generalization."}, {"title": "V. CONCLUSION", "content": "This paper introduces HyperGCL a novel Graph Contrastive Learning (GCL) framework that leverages three distinct hypergraph views to capture comprehensive attribute and structural information. By using a learnable Gumbel-Softmax function for adaptive augmentation and integrating a network-aware contrastive loss (NetCL), HyperGCL addresses critical limitations in existing GCL methods. Extensive experiments on benchmark datasets demonstrate that HyperGCL achieves state-of-the-art performance in node classification tasks, significantly outperforming both traditional graph-based and hypergraph-based models. The ablation studies confirm the critical role of each component in our framework, highlighting its robustness and adaptability across diverse datasets."}]}