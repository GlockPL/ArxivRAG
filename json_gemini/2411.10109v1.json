{"title": "Generative Agent Simulations of 1,000 People", "authors": ["Joon Sung Park", "Carolyn Q. Zou", "Aaron Shaw", "Benjamin Mako Hill", "Carrie Cai", "Meredith Ringel Morris", "Robb Willer", "Percy Liang", "Michael S. Bernstein"], "abstract": "The promise of human behavioral simulation\u2014general-purpose computational agents that replicate human behavior across domains could enable broad applications in policymaking and social science. We present a novel agent architecture that simulates the attitudes and behaviors of 1,052 real individuals\u2014applying large language models to qualitative interviews about their lives, then measuring how well these agents replicate the attitudes and behaviors of the individuals that they represent. The generative agents replicate participants' responses on the General Social Survey 85% as accurately as participants replicate their own answers two weeks later, and perform comparably in predicting personality traits and outcomes in experimental replications. Our architecture reduces accuracy biases across racial and ideological groups compared to agents given demographic descriptions. This work provides a foundation for new tools that can help investigate individual and collective behavior.", "sections": [{"title": "Main Text", "content": "General-purpose simulation of human attitudes and behavior\u2014where each simulated person can engage across a range of social, political, or informational contexts\u2014could enable a laboratory for researchers to test a broad set of interventions and theories (1-3). How might, for instance, a diverse set of individuals respond to new public health policies and messages, react to product launches, or respond to major shocks? When simulated individuals are combined into collectives, these simulations could help pilot interventions, develop complex theories capturing nuanced causal and contextual interactions, and expand our understanding of structures like institutions and networks across domains such as economics (4), sociology (2), organizations (5), and political science (6).\nSimulations define models of individuals that are referred to as agents (7). Traditional agent architectures typically rely on manually specified behaviors, as seen in agent-based models (1, 8, 9), game theory (10), and discrete choice models (11), prioritizing interpretability at the cost of restricting agents to narrow contexts and oversimplifying the contingencies of real human behavior (3, 4). Generative artificial intelligence (AI) models, particularly large language models (LLMs) that encapsulate broad knowledge of human behavior (12-15), offer a different opportunity: constructing an architecture that can accurately simulate behavior across many contexts. However, such an approach needs to avoid flattening agents into demographic stereotypes, and measurement needs to advance beyond replication success or failure on average treatment effects (16-19).\nWe present a generative agent architecture that simulates more than 1,000 real individuals using two-hour qualitative interviews. The architecture combines these interviews with a large language model to replicate individuals' attitudes and behaviors. By anchoring on individuals, we can measure accuracy by comparing simulated attitudes and behaviors to the actual attitudes and behaviors. We benchmark these agents using canonical social science measures such as the General Social Survey (GSS; 20), the Big Five Personality Inventory (21), five well-known behavioral economic games (e.g., the dictator game, a public goods game) (22-25), and five social science experiments with control and treatment conditions that we sampled from a recent large-scale replication effort (26-31). To support further research while protecting participant privacy, we provide a two-pronged access system to the resulting agent bank: open access to aggregated responses on fixed tasks for general research use, and restricted access to individual responses on open tasks for researchers following a review process, ensuring the agents are accessible while minimizing risks associated with the source interviews.\nTo create simulations that better reflect the myriad, often idiosyncratic, factors that influence individuals' attitudes, beliefs, and behaviors, we turn to in-depth interviews\u2014a method that previous work on predicting human life outcomes has employed to capture insights beyond what can be obtained through traditional surveys and demographic instruments (32). In-depth interviews, which combine pre-specified questions with adaptive follow-up questions based on respondents' answers, are a foundational social science method with several advantages over more structured data collection techniques (33, 34). While surveys with closed-ended questions and predefined response categories are valuable for well-powered quantitative analysis and hypothesis testing, semi-structured interviews offer distinct benefits for gaining idiographic knowledge about individuals. Most notably, they give interviewees more freedom to highlight what they find important, ultimately shaping what is measured."}, {"title": "Predicting Individuals' Attitudes and Behaviors", "content": "To assess the contribution of interviews to the generative agents' predictive accuracy, we compared the performance of interview-based generative agents with two baselines that replace interview transcripts with alternative forms of description. These baselines are grounded in how language models have been used to proxy human behaviors in prior studies: one using demographic attributes (13, 38), and the other using a paragraph summarizing the target person's profile (14). For the demographic-based generative agents, we used participants' responses to GSS questions to capture individuals' age, gender, race, and political ideology-demographic attributes commonly used in previous studies (38). For the persona-based generative agents, we asked participants to write a brief paragraph about themselves after the interview, including their personal background, personality, and demographic details, similar to the material used to generate persona agents in prior work (14).\nThe first component of our evaluation, the GSS, is widely used across sociology, political science, social psychology, and other social sciences to assess respondents' demographic backgrounds, behaviors, attitudes, and beliefs on a broad range of topics, including public policy, race relations, gender roles, and religion (20). Our evaluation focused on 177 core GSS"}, {"title": "Predicting Experimental Replications", "content": "Participants took part in five social science experiments to assess whether generative agents can predict treatment effects in experimental settings commonly used by social scientists. These were drawn from a collection of published studies included in a large-scale replication effort (26-31;"}, {"title": "Interviews Reduce Bias in Generative Agent Accuracy", "content": "There is concern about AI systems underperforming or misrepresenting underrepresented populations (19). To address this concern, we conducted a subgroup analysis focusing on political ideology, race, and gender\u2014dimensions of particular interest in relevant literature (13, 38, 16-18). We aimed to assess whether the in-depth descriptions provided by interviews could mitigate biases compared to methods using demographic prompts, which exhibited stereotyping in prior research (16-19). We quantified bias using the Demographic Parity Difference (DPD), which measures the difference in performance between the best performing and worst-performing groups (39, 40). For the GSS, we report DPD in percentages; for Big Five and"}, {"title": "Research Access for the Agent Bank", "content": "Access to an agent bank can help lay the foundations for replicable science using AI-based tools. Our agent bank of 1,000 generative agents offers a resource toward these goals. To balance scientific potential with privacy concerns, the authors at Stanford University provide a two-pronged access system for research: open access to aggregated responses on fixed tasks (e.g., GSS) and restricted access to individualized responses on open tasks. Safeguards include usage audits, participant withdrawal options, and non-commercial use agreements, modeled after genome banks and AI model deployments, supporting ethical research and reducing risk to human subjects while enabling AI applications in the social sciences."}, {"title": "Materials and Methods Summary", "content": "We contracted with the recruitment firm Bovitz (41) to obtain a U.S. sample of 1,000 individuals, stratified by age, census division, education, ethnicity, gender, income, neighborhood, political ideology, and sexual orientation. Participants completed interviews with the AI interviewer, along with Qualtrics versions of the General Social Survey (GSS), Big Five personality inventory, economic games, and selected experimental studies. For the GSS, we focused on 177 questions for the \u201ccore\u201d module, excluding non-categorical questions, questions with more than 25 response options, and conditional questions. For the experimental studies, we selected five studies from a recent large-scale replication effort (26-31). These were chosen based on two inclusion criteria: first, the study had to be describable to a language model using text or images, and second, the power analysis from the replication effort indicated that the effects would be observable with 1,000 or fewer participants. This ensured that our human participants could replicate the effects if present. The selected studies (27-31) covered the evaluation of harm based on perceived intent, the role of fairness in emotional reactions, the perceived benefits of conflict intervention, dehumanization in willingness to harm others, and how power influences trust."}]}