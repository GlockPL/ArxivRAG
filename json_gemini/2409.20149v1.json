{"title": "1 Trillion Token (1TT) Platform: A Novel Framework for Efficient Data Sharing and Compensation in Large Language Models", "authors": ["Chanjun Park", "Hyunsoo Ha", "Jihoo Kim", "Yungi Kim", "Dahyun Kim", "Sukyung Lee", "Seonghoon Yang"], "abstract": "In this paper, we propose the 1 Trillion Token Platform (1TT Platform), a novel framework designed to facilitate efficient data sharing with a transparent and equitable profit-sharing mechanism. The platform fosters collaboration between data contributors, who provide otherwise non-disclosed datasets, and a data consumer, who utilizes these datasets to enhance their own services. Data contributors are compensated in monetary terms, receiving a share of the revenue generated by the services of the data consumer. The data consumer is committed to sharing a portion of the revenue with contributors, according to predefined profit-sharing arrangements. By incorporating a transparent profit-sharing paradigm to incentivize large-scale data sharing, the 1TT Platform creates a collaborative environment to drive the advancement of NLP and LLM technologies.", "sections": [{"title": "Introduction", "content": "The availability of high-quality text data is critical for performant Natural Language Processing (NLP) services (Mishra et al. 2020; Bhadauria, Sierra-M\u00fanera, and Krestel 2024). With the rapid rise of services leveraging Large Language Models (LLMs), large-scale and high-quality text data have become ever more important (Zhao et al. 2023; Minaee et al. 2024).\nFor acquiring such data, traditional methods include web crawling (Huang et al. 2024), synthetic data generation (Lu et al. 2023), and digitizing documents via Optical Character Recognition (OCR) (Islam, Islam, and Noor 2017). However, these methods have the following limitations: (i) web crawling may inadvertently collect copyrighted materials, leading to legal complications (Krotov, Johnson, and Silva 2020); (ii) synthetic data generation and digitizing documents via OCR, while efficient, are constrained by the inherent capabilities of the models (Liu et al. 2023) used for synthetic generation and OCR, where the most performant models are often restricted for commercial use (Achiam et al. 2023).\nTo overcome the limitations of traditional methods for data acquisition, data sharing could be a promising solution for data consumer seeking to enhance their NLP or LLM-based services. However, it is not a straightforward issue due to the proprietary nature of large-scale, high-quality data. To encourage data contributors to provide such data, transparent and fair compensation must be guaranteed (Berke et al. 2024). To this end, we propose the 1 Trillion Token Platform (1TT Platform), a novel framework designed to facilitate seamless data sharing while ensuring transparent and fair profit-sharing mechanisms.\nThe platform facilitates collaboration between data contributors and a data consumer. In exchange for their contributions, data contributors are compensated with a share of the revenue generated by the services of the data consumer. The data consumer agrees to allocate a portion of their revenue directly to the contributors based on predefined profit-sharing arrangements. This platform ensures that contributors are fairly compensated in monetary terms, proportionate to the success of the services utilizing their data. Such profit sharing paradigms give incentive to share high-quality, non-disclosed data that would otherwise be hard to acquire. By integrating secure data sharing with a transparent profit distribution system and defining clear roles for both contributors and consumer, the 1TT Platform fosters a collaborative ecosystem for advancing NLP and LLM development."}, {"title": "1 Trillion Token (1TT) Platform", "content": "Platform Design\nAs shown in Figure 1, the 1TT Platform operates on a profit-sharing model that aligns the interests of data contributors and data consumer. Their roles are defined as follows:\n\u2022 Data Contributors: Individuals or entities that provide datasets to the platform.\n\u2022 Data Consumer: Company or organization that utilizes the contributed data to enhance their own services, gen-erating revenue.\nWhen data contributors submit datasets to the platform, the contributed data undergoes an automated preprocessing phase using the open-source Dataverse library (Park et al. 2024), which filters these datasets based on heuristic rules and removes duplicate samples. This preprocessing stage is essential for excluding low-quality or irrelevant data, as well as data that the consumer already possesses or that is publicly available on the web, ensuring that only meaningful contributions are compensated (Zhang et al. 2023b,a). Then, each data contributor is compensated based on the amount of data they ultimately contribute relative to the total pool on the platform. The monetary reward $R_i$ for each contributor $i$ is calculated as follows:\n$R_i = \\frac{T_i}{\\sum{T_i}} \\times R_{API} \\times a,$\nwhere $T_i$ is the number of tokens after filtering the data contributed by contributor $i$, $R_{API}$ is the total revenue generated by the services of data consumer, and $a$ is the portion of the total revenue $R_{API}$ that will be allocated to data contributors, which should be determined with consideration of the costs associated with service operations. This reward model ensures that contributors receive financial remuneration proportional to their contribution and the success of the services utilizing their data."}, {"title": "Implementation", "content": "The 1TT platform interface 1, implemented using Gradio (Abid et al. 2019), enables data contributors to seamlessly upload datasets and provides data consumer with the tools to manage and verify data contributions through an automated workflow.\nAs illustrated in Figure 2, key metrics, including Data Contribution Ratio, Contribution Token Count, Current Monetary Revenue, and Expected Payout, are readily available to data contributors and consumer. Expected payout is calculated based on revenue trends from the previous payout date to the present, offering interested parties an estimate of the amount they will receive on the next payment date.\nIn addition to these metrics, the platform offers detailed information on the following critical aspects:\n\u2022 Data Preprocessing Results: Offers a transparent account of how token allocation is adjusted throughout the various stages of data preprocessing. Not only does this ensure contributors are fully informed about the handling of their submitted datasets, it also gives insights about the quality of the submitted data for the contributors, allowing for better datasets to be shared in the future.\n\u2022 Detailed Information about Reward: Provides the details about the API usage patterns of data consumer and the corresponding revenue generated, allowing contributors to monitor real-time changes in their monetary rewards based on how well the services of the data consumer are faring.\nBy emphasizing transparency in both data processing and revenue distribution, the 1TT Platform ensures equitable compensation for contributors and fosters a sustainable ecosystem for data-driven NLP and LLM advancements."}, {"title": "Future Work", "content": "To enhance the 1TT Platform, future developments may include a targeted data-sharing mechanism where data consumers submit detailed requests specifying data characteristics like domain, format, and language. This would allow data contributors to align submissions accordingly. Additionally, a contributor reputation system could promote higher-quality contributions by helping consumers prioritize reliable sources (Bouchiha et al. 2024)."}, {"title": "Conclusion", "content": "The 1TT Platform introduces a novel data-sharing framework with a transparent profit-sharing model for the NLP and LLM communities. By addressing key issues of fair compensation, it ensures equitable rewards for data contributors. As a result, the platform fosters greater collaboration and long-term sustainability in advancing NLP and LLM technologies."}]}