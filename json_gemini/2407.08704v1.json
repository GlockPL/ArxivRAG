{"title": "Towards Efficient Deployment of Hybrid SNNs on\nNeuromorphic and Edge AI Hardware", "authors": ["James Seekings", "Peyton Chandarana", "Mahsa Ardakani", "MohammadReza Mohammadi", "Ramtin Zand"], "abstract": "This paper explores the synergistic potential of\nneuromorphic and edge computing to create a versatile machine\nlearning (ML) system tailored for processing data captured by\ndynamic vision sensors. We construct and train hybrid models,\nblending spiking neural networks (SNNs) and artificial neural\nnetworks (ANNs) using PyTorch and Lava frameworks. Our\nhybrid architecture integrates an SNN for temporal feature\nextraction and an ANN for classification. We delve into the\nchallenges of deploying such hybrid structures on hardware.\nSpecifically, we deploy individual components on Intel's Neu-\nromorphic Processor Loihi (for SNN) and Jetson Nano (for\nANN). We also propose an accumulator circuit to transfer data\nfrom the spiking to the non-spiking domain. Furthermore, we\nconduct comprehensive performance analyses of hybrid SNN-\nANN models on a heterogeneous system of neuromorphic and\nedge AI hardware, evaluating accuracy, latency, power, and\nenergy consumption. Our findings demonstrate that the hybrid\nspiking networks surpass the baseline ANN model across all\nmetrics and outperform the baseline SNN model in accuracy\nand latency.", "sections": [{"title": "I. INTRODUCTION", "content": "Spiking Neural Networks (SNNs) [1], [2] are an emerg-\ning technology aimed at creating biologically-inspired neural\nnetworks for low-power and high-performance computation.\nThey utilize neurons modeled after the brain, enabling them\nto learn over time and excel at extracting temporal infor-\nmation from event-based data [3]\u2013[5]. In contrast, artificial\nneural networks (ANNs) like convolutional neural networks\n(CNNs) are proficient at extracting spatial information but do\nnot handle temporal information well [6]. Recurrent neural\nnetworks (RNNs) have gained popularity for their ability to\nhandle temporal information, but they do not offer significant\nimprovements in terms of power or latency [7].\nSNNs are being explored as a promising alternative for\nconventional ANNs due to their low-power computing capabil-\nities, yet when deployed on existing neuromorphic hardware,\nthey often underperform in terms of classification accuracy\n[8]\u2013[10]. One solution to benefit from the advantage of both\nSNN and ANN models is to fuse them to create more robust\nand versatile neural network models capable of addressing\ncomplex tasks, including pattern recognition in time-series\ndata and understanding dynamic systems in real-time appli-\ncations. However, integrating SNNs and ANNs in a single\nsystem presents challenges such as developing efficient train-\ning algorithms to train across the two domains and optimizing\nthe use of computational resources. Despite these challenges,\nexploring the viability of combining ANNs and SNNs into\none system could yield promising results to advance neural\nnetworks capabilities.\nIn 2021, Kugele et al. [11] proposed a hybrid SNN-ANN\narchitecture with a custom simulator to compile and train\na hybrid neural network. Their proposed model consists of\nan SNN backbone for extracting temporal information and\nan ANN head for classification. Inspired by [11], Wu et al.\n[12] investigates appending dense layers to SNN networks to\nimprove accuracy on CIFAR-10 [13]. In [14], a hybrid SNN-\nANN model is utilized to process the data captured by dynamic\nvision sensor (DVS) [15], [16]. Instead of using the SNN for\nthe backbone, other works such as Muramatsu et. al. [17]\nexplore using the ANN as a backbone with an SNN head for\nclassification on the MNIST [18] and CIFAR-10 datasets. Ad-\nditionally, Muramatsu et. al. performed multiple experiments\nby modifying the ratios of ANN to SNN layers concluding\nthat models with more ANN layers typically achieve better\naccuracy. Beyond the domain of image classification, a few\npapers [19], [20] have also explored the use of hybrid networks\nin object detection tasks. This is done by combining an\nSNN backbone with a single-shot detector head and using a\nsurrogate gradient to train the networks.\nHerein, our work provides a deeper investigation of hybrid\nSNN-ANN models by offering a unified training mechanism\nthat operates across the SNN and ANN domains. Additionally,\nwe undertake a more extensive performance analysis for differ-\nent architectures of the hybrid network. The main contributions\nof our paper compared to the previous works are:\n\u2022 Developing a unified backpropagation-based training\nmechanism for hybrid spiking and non-spiking architec-\ntures using PyTorch and SLAYER [21] as part of the\nLAVA neuromorphic computing library [22].\n\u2022 Investigating the hardware deployment challenges of hy-\nbrid architectures. This paper is one of the pioneers in\nattempting the real hardware implementation of hybrid\nSNN-ANN models.\n\u2022 Providing comprehensive performance analyses of hybrid\nSNN-ANN models deployed on a heterogenous system of\nneuromorphic and edge AI hardware.\nThe remainder of the paper is organized as follows. Section\nII introduces the proposed hybrid SNN-ANN architectures and"}, {"title": "II. PROPOSED HYBRID SNN-ANN ARCHITECTURE", "content": "A hybrid network is generated by replacing the Conv layers\nfrom the ANN with SpkConv layers from the SNN. Layers\nare replaced in order starting from the beginning of the model\nand moving deeper. The accumulate operation is then placed\nbetween the spiking and non-spiking layers to remove the\ntemporal dimension as the data is passed to ANN, and the\ndense layers are always implemented via non-spiking blocks.\nTable I provides further details of the model architectures\ninvestigated in this paper."}, {"title": "A. Hybrid Architecture", "content": "Here, we develop a representative CNN architecture with\nfive convolution layers and three dense layers to test the\neffectiveness of integrating spiking and non-spiking compo-\nnents. Figure 1a shows the baseline ANN architecture using\nnon-spiking convolution and dense blocks that employ ReLU\nactivations and max pooling operations. Additionally, an ac-\ncumulate operation is included at the front of the network,\nrepresented by the green layer, which collapses the temporal\ndimension from the input data so that the ANN can process it.\nFigure 1b shows the baseline SNN architecture consisting of\nSpike Convolutions (SpkConv) and Spike Dense (SpkDense)\nblocks. These blocks use Current-Based Leaky Integrate and\nFire (CUBA-LIF) neurons as activations and spike pooling\noperations."}, {"title": "B. Accumulator", "content": "Before event-based data can be passed to ANN, the temporal\ndimension must be collapsed. To accomplish this, methods\nsuch as those used in [11] involve implementing an accumu-\nlator that sums spikes over small time intervals to generate\nmultiple outputs to the ANN. Each output is run through the\nfirst layer of the ANN and then concatenated together at the\nsecond layer. Our accumulator differs in that, after summation,\nthe outputs are concatenated together before being sent to\nANN. The concatenation occurs across the channel dimension,\ncausing it to expand with the size of the temporal dimension.\nHerein, the period over which the accumulator sums spikes\nis referred to as the accumulate interval. A large interval\nsums up many spikes at once, reducing output size at the cost\nof temporal resolution. On the other hand, smaller intervals\nbetter retain temporal resolution but lead to increased model\nsize. In our experiments, we treat the accumulate interval as a\nhyperparameter to investigate its effect on model performance,\nwhich we discuss in Section IV. A model's accumulate interval\nis denoted by $I = (5/10/25)$, as shown in Table I.\nFigure 2 shows the accumulate operation performed on\n2-dimensional data although it can be generalized for 4-\ndimensional input. First, the input data is separated into groups\nof size I along the temporal dimension, represented by dif-\nferent colors. The groups are then summed together resulting\nin channel-wide vectors. After summation, these vectors are"}, {"title": null, "content": "concatenated together with the earlier elements appearing first,\npreserving temporal order. The output of the accumulator is\nthen sent to ANN for further processing.\nA mathematical representation of the accumulate operation\ncan be seen in Eq. 1, where S is a $C \\times T$ matrix representing\nspiking input. $C$ is the number of channels and $T$ is the number\nof time steps. The output is a vector A with length $CT/I$,\nwhere I is the accumulate interval.\n\n$A_j = \\sum_{k=0}^{I-1} S_{(j \\mod C), (I[\\frac{j}{C}]+k)}$\n\nEach output $A_j$ is defined as the summation of $S$ at channel\n$j \\mod C$ over $I$ timesteps. Once $j$ exceeds $C$, the summation\nresets to the first channel through the modulus operation.\nAt this point, $[\\frac{j}{C}]$ equals 1 which shifts the columns for\nsummation over by $I$. This repeats for every $C$ indices until\nthe final index.\nOne challenge of this method is that the channel dimension\nexpands at a rate of $T/I$ to accommodate the shrinking\ntemporal dimension. Reducing the channel count back down to\nwhat it was before the accumulate operation can be done with\na simple convolutional layer. However, this is not possible in\nmodels such as $S_5A_0$ which does not have a convolution layer\nfollowing the accumulate operation. As such, those models\nexperience a substantial increase in parameter count at smaller\naccumulate intervals, as seen in Table I."}, {"title": "C. Training", "content": "Our hybrid model was built in PyTorch using the LAVA\nframework [22] for spiking components. The LAVA library\ncontains a SLAYER-based training algorithm for SNNs which\nsaves the network's previous states to be used during the cal-\nculation of gradients via a temporal credit assignment policy\n[21] and Back Propagation Through Time (BPTT) [23]. The\ntraining algorithms for ANN and SNN build computational\ngraphs for calculating gradients and the graphs are combined\nautomatically, allowing the hybrid model to train as a single\nunified network instead of being trained separately. However,\nthe accumulate operation is non-differentiable, requiring a\ncustom backward pass to be implemented.\nIn the backward pass of the accumulator, we are faced\nwith an inverse of the forward pass challenge encountered\npreviously. Here, 3-dimensional gradients are received from\nthe ANN while the SNN expects 4-dimensional gradients,"}, {"title": null, "content": "thus the temporal dimension needs to be reintroduced or\nexpanded from the ANN domain. This is done by repeating the\ngradients in-place I times and then reshaping the data to four\ndimensions. Through this process, spikes that were initially\nsummed together share the same gradient. A mathematical\nrepresentation following the logic of the forward pass can be\nseen in Eq. 2.\n\n$S_{i,j} = A_{C[\\frac{j}{I}]+i}$"}, {"title": "III. DEPLOYMENT METHODOLOGY", "content": "Figure 3 shows the end-to-end system in software and\nhardware starting from the training phase using our uni-\nfied training pipeline to deploying the networks on their\nrespective hardware. As shown, the spiking and non-spiking\ncomponents of our proposed hybrid network have differing\nhardware constraints that limit deployment options. Due to\ntheir asynchronous event-based nature, SNNs cannot be run\non GPUs or CPUs without simulation which increases latency\nand consumes more power. Neuromorphic hardware such as\nIntel's Loihi chip [24] is specially designed for running spiking\nmodels by emulating biologically inspired neuron dynamics\nin hardware. However, these chips do not support all of the\noperations in the ANN models making them unfit to run\nANNs. In recent years, there has been various research on the\ndeployment of ANN models on edge AI accelerators [25]\u2013\nAs shown in Fig. 3, we chose to deploy our hybrid\nspiking model through a distributed system combining a Loihi\nchip and a Jetson Nano [28]. These devices were profiled\nseparately to isolate their specific impact on the overall system."}, {"title": "1) Deployment of Non-Spiking Components on Edge AI\nAccelerator", "content": "The NVIDIA Jetson Nano is a development\nboard tailored for ML applications. It utilizes the Tegra X1\nSystem on Chip (SoC), which includes a quad-core ARM\nCortex A57 CPU clocked at 1.43 GHz. Additionally, the\nboard features four discrete processing clusters, each with 32\nCUDA cores, totaling 128 CUDA cores based on the Maxwell\narchitecture. Equipped with 4 GB of RAM, the Jetson Nano\nprovides a robust computational platform for ML acceleration\nat the edge.\nThe Jetson Nano operates in two distinct power configu-\nrations: a low-power 5 W mode and a higher-performance\nMax-N mode, both selectable via a software interface. In the\n5 W mode, the device restricts itself to utilizing only two\nARM A57 cores at a reduced frequency of 0.9 GHz, and\nthe GPU operates at a reduced clock speed of 0.64 GHz.\nConversely, the Max-N mode enables all four ARM A57 cores,\nrunning them at an increased frequency of 1.5 GHz, while\nthe GPU operates at a speed of 0.92 GHz. This dual-mode\nfunctionality allows developers to balance between power\nefficiency and computational performance based on the needs\nof their applications.\nAlthough Jetson Nano is equipped with CUDA capabilities,\nit primarily utilizes NVIDIA TensorRT [29] to optimize and\naccelerate deep learning models through quantization and\nother optimization techniques, thereby enhancing performance.\nModels can be exported to TensorRT through the Open Neural\nNetwork Exchange (ONNX) [30] library.\nThe proposed hybrid networks were recreated in Tensor-\nFlow [31] with the spiking components removed and the input\nlayers adjusted. These partial models were then converted to\nONNX and exported to TensorRT for deployment on the Jetson\nNano. For inference latency, we calculate the time required\nfor 100 inferences and then determine the average inference\ntime for a single input sample. Input, CPU, and GPU power\ndissipation were recorded through the Jetson Nano's built-\nin sensors while running each model for three minutes. The\ntegrastats utility is used to read the sensors automatically [28]."}, {"title": "2) Deployment of Spiking Components on Neuromorphic\nHardware", "content": "SNN simulators such as INIsim [32] or Brian 2\n[33] can be used to run SNNs on the CPU through a software\nabstraction of neural dynamics consuming considerable power\nand increasing execution latency. Devices that instead emulate\nneural dynamics, allowing for efficient execution of spiking\nnetworks, are referred to as neuromorphic hardware platforms.\nIn our paper, we utilize Intel's Loihi [24], to deploy the spiking\ncomponents of our hybrid network.\nThe Loihi chip departs from the typical von Neumann\narchitecture to more closely replicate the neural dynamics of\nthe brain. It contains a network of neurons and synapses that\ncommunicate asynchronously through discrete spike events\nfor more efficient computation. Loihi is organized into 128\nprogrammable cores, each containing 1024 neurons connected\nby a total of 128 million synapses. While not yet commercially\navailable, access to the Loihi chip is provided to us by Intel\nLabs through membership in the Intel Neuromorphic Research\nCommunity (INRC).\nWhile the LAVA framework is utilized in this paper to train\nthe hybrid and spiking networks, we could not measure the\npower reliably using the power measurement tools available\nin LAVA at the time of conducting this research. Consequently,\nwe opted for deploying the models on Loihi 1 and employed\nthe NengoLoihi toolchain [34] for deployment and power mea-\nsurements. NengoLoihi facilitates the conversion of CNNs into\nSNN architectures through a mapping algorithm, which maps\nthe weights and activations of the CNN onto an equivalent\nSNN in Intel's NxSDK framework.\nThese initial CNNs were first developed in PyTorch and\nthen mapped to the spiking domain of each hybrid network.\nOnce converted into SNNs through NengoLoihi, each network\nis partitioned layer-by-layer across Loihi's neuro-cores. After\nwhich, neurons and synapses are mapped together between the\nchip and network. Once partitioned and mapped, the SNN is\nrun directly on the chip. The power dissipation was recorded\nthrough a profiling toolkit in NengoLoihi which also reports\nthe number of Loihi cores allocated to the network. The last\ncolumn of Table I provides the number of Loihi cores for all\nthe hybrid and SNN architectures studied herein. As listed, one\nLoihi chip is sufficient to support the implementation of our\nhybrid SNN-ANN and SNN models. The latency is measured\nvia the spike propagation delay defined as the time between an\nimage being exposed to the network and the output of spikes\nfrom the final layer."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "Throughout our experiments, we use the DvsGesture dataset\nwhich includes 11 hand gestures recorded from 29 subjects\nunder 3 illumination conditions [35]. DVS events are defined\nby their type (on/off), pixel location (x,y), and a timestamp.\nTo transform the raw DVS data into usable training data, all of\nthe events that occurred in a 10ms time frame were compiled\ninto a 128\u00d7128 image. We then took 50 consecutive images to\nform a single sample of shape (2, 128, 128, 50), representing\n500ms of activity. The raw data includes the times when\ncertain gestures are made, which is then used to automatically\nlabel the samples. This generates 14,672 training samples and\n3,793 testing samples."}, {"title": "A. Dataset", "content": "Figure 4 provides a comparison of the accuracies between\nbaseline ANN and SNN, as well as the hybrid networks.\nTo determine the impact on model performance, the models\nare evaluated with three distinct accumulation intervals: I=5,\nB. Accuracy"}, {"title": "C. Latency", "content": "Figure 5 shows the latency of each model, separated for\nspiking and non-spiking components. The ANN baseline\nshows 3.28x, 5.47\u00d7, and 8.33\u00d7 less latency compared to the\nSNN baseline for I=5, I=10, and I=15, respectively. As shown\nin the figure, the accumulate interval has a considerable effect\non latency, ranging from 6.5 ms to 2.64 ms as it increases.\nSimilar to the accuracy results, it can be observed that the\ncontinued addition of SpkConv layers in hybrid networks\nincreases latency to eventually match the SNN's performance.\nHowever, a small decrease in latency can be seen when only a\nfew SpkConv layers are present with intervals I=5, and I=10."}, {"title": "D. Power Dissipation", "content": "Figure 6 shows a comparison of power consumption among\nthe SNN, ANN, and various hybrid SNN-ANN architectures.\nThe graph illustrates that the ANN baseline, run on CPU\nand GPU, exhibits significantly higher dynamic power con-\nsumption compared to the SNN baseline deployed on Loihi.\nAdding SpkConv layers reduces power dissipation across the\nboard, although even a very small ANN still consumes vastly\nmore power than a large SNN. A substantial increase in power\nconsumption is observed in configuration $S_5A_0$ across all\nintervals, but this is an outlier caused due to the model's\nincreased parameter count as shown in Table I. This occurred\nbecause the accumulator expands the channel dimension of the\ndata, which is normally reduced back down by consecutive\nConv layers. However, the accumulator in configuration $S_5 A_0$\nis followed by a fully connected layer which does not reduce"}, {"title": "E. Energy Consumption", "content": "Figure 7 provides a comparison between the ANN and\nSNN baselines and the hybrid SNN-ANN models. The results\ndemonstrate that SNNs exhibit significantly lower energy con-\nsumption for computational tasks compared to conventional\nANNs, highlighting the potential benefits of incorporating\nspiking layers to reduce energy consumption. It shows that the\nincremental addition of SpkConv layers significantly decreases\nenergy consumption compared to ANN models. However,\nthere is a similar increase in energy consumption for model\n$S_5 A_0$ due to the model's aforementioned parameter increase.\nIn our experiments, we found that larger accumulate intervals\nlead to decreased energy consumption across the board. As\nshown in Table II, the accumulator only consumes a marginal\namount of energy compared to the entire system."}, {"title": "F. Accumulator Overheads", "content": "To accurately estimate the overheads of the accumulator\nwhen used in a heterogeneous SoC comprising neuromorphic\nand ANN accelerator cores, we implemented the accumulator\nin the Verilog Hardware Description Language (HDL).\nThe accumulator circuit includes k-bit counters with three\ninput ports corresponding to the input clock, reset, and spike\nsignals. The clock signal is dependent on the hardware sys-\ntem's global clock and the reset signal is driven by the\naccumulator module. The spike signal corresponds to whether\na spike was emitted by the SNN during the current clock. Thus,\nif the last layer of the SNN, connected to the accumulator,\nspikes, the spikes are transmitted to the accumulator's counters\nwhich then increments the k-bit counter.\nThe high-level accumulator module combines multiple\ncopies of the k-bit counters into a single hardware accumulator\nblock. The accumulator also has three inputs including the\nclock signal along with a sync signal for synchronizing all of\nthe counters and N input wires to propagate the spike signals\nto their respective counters. The accumulator also contains\nan internal k-bit register for controlling when the N k-bit\ncounters should be reset after a predefined number of clock\ncycles have passed. The output of the accumulator module\nconsists of N \u00d7 k bits which can then be connected to an\nANN accelerator core for the ANN inference phase of the\nhybrid model.\nHere, we fix the number of inputs into the accumulator to\nN128 bits which are then fed into the 128 k-bit counters\ninside of the accumulator. The number of neurons connected\nto the accumulator from the SNN part of the model often\nexceeds the limit of the N = 128. To accommodate these\nlarger layer sizes, we divide the total number of output neurons\nfrom the last layer into partitions with 128 neurons and send\neach partition to the accumulator per timestep. Depending on\nthe value of k, the accumulator's output bus would then be\n128 \u00d7 k bits wide. The value of k depends on the accumulate\ninterval (I) value. For example, within the I = 5 interval, there\nwill be a maximum of 5 spikes. Thus, a 3-bit counter would\nadequately store the accumulator's output. Similarly, 4-bit and\n5-bit counters can support accumulate intervals of I = 10 and\nI = 25, respectively.\nUsing the Synopsys Design Compiler, we assessed the\nperformance of our accumulator operation on hardware. The\nfindings, detailed in Table II, indicate that the latency, power,\nand energy overheads attributed to the accumulator circuit are\nsignificantly lower, by several orders of magnitude, compared\nto those of the ANN and SNN models running on the ANN\naccelerator and neuromorphic cores. This implies that the\naccumulator overheads are negligible."}, {"title": "V. CONCLUSION", "content": "In this work, we presented a methodology for the effi-\ncient deployment of hybrid spiking models on a distributed\nsystem of neuromorphic hardware and edge AI accelerators.\nOur experiments involved testing numerous hybrid models\nto explore the effect that introducing spiking layers would\nhave on performance. We trained our models on the event-"}]}