{"title": "Addressing the Pitfalls of Image-Based Structural Health Monitoring: A Focus on False Positives, False Negatives, and Base Rate Bias", "authors": ["Vagelis Plevris"], "abstract": "This study explores the limitations of image-based structural health monitoring (SHM) techniques in detecting structural damage. Leveraging machine learning and computer vision, image-based SHM offers a scalable and efficient alternative to manual inspections. However, its reliability is impacted by challenges such as false positives, false negatives, and environmental variability, particularly in low base rate damage scenarios. The Base Rate Bias plays a significant role, as low probabilities of actual damage often lead to misinterpretation of positive results. This study uses both Bayesian analysis and a frequentist approach to evaluate the precision of damage detection systems, revealing that even highly accurate models can yield misleading results when the occurrence of damage is rare. Strategies for mitigating these limitations are discussed, including hybrid systems that combine multiple data sources, human-in-the-loop approaches for critical assessments, and improving the quality of training data. These findings provide essential insights into the practical applicability of image-based SHM techniques, highlighting both their potential and their limitations for real-world infrastructure monitoring.", "sections": [{"title": "Background and Motivation", "content": "Structural health monitoring (SHM) of civil infrastructure plays a crucial role in sustainable development. SHM involves the in situ, non-destructive measurement of the operating and loading conditions, as well as the critical responses of a structure. Damage-sensitive features are extracted from this data and statistically analyzed to detect the presence, location, and severity of structural damage. SHM also helps determine the current health condition of a structure, estimate its remaining useful life, and guide engineers and inspectors in making informed decisions regarding maintenance, rehabilitation, or replacement of infrastructure [1].\nTraditionally, structural inspections relied heavily on manual evaluations performed by engineers or technicians who would visually assess the state of a structure. While these inspections remain a crucial part of infrastructure maintenance, they are limited by subjective judgment, accessibility issues, and the vast number of structures that require regular monitoring. In recent years, the use of image-based classification methods has seen a significant rise in SHM and infrastructure management [2]. These methods, powered by advancements in artificial intelligence (AI) [3, 4], machine learning (ML) [5] and computer vision techniques [6], offer a way to supplement or even replace manual inspections by analyzing large volumes of image data captured by drones, cameras, or sensors [7] and they are increasingly being applied to detect damage in critical structures such as bridges [8], buildings, and tunnels [9]. By automating the process of damage detection, these technologies have the potential to revolutionize traditional inspection methods, which are time-consuming, labor-intensive, and prone to human error.\nAt the heart of these image-based techniques are algorithms designed to classify or segment images to detect potential signs of damage, such as cracks [10], corrosion, deformation, spalling [11], and others [12]. Convolutional neural networks (CNNs), deep learning (DL) models, and other artificial intelligence (AI) approaches are commonly used for this purpose. These models can be trained on large datasets of labeled images to recognize patterns that are indicative of structural damage, thus automating the detection process with high speed and accuracy.\nOne of the key motivations for adopting image-based techniques in SHM is their scalability and efficiency. Drones equipped with high-resolution cameras can survey large structures in a fraction of the time it would take for manual inspections [13]. Furthermore, AI models can analyze these images in real time, providing almost immediate feedback on the condition of the structure [2]. This rapid detection capability is especially critical in emergency situations, such as after an earthquake or a severe storm, where quick assessments are necessary to ensure public safety.\nAdditionally, image-based methods can capture minute details that might be missed by the human eye, especially in hard-to-reach areas or over extended periods where damage progression is subtle. The use of such techniques enables continuous monitoring and early detection of problems, potentially preventing costly and dangerous structural failures. Payawal et al. [14] conducted a systematic review of image-based SHM techniques. Their study highlights that image-based SHM represents a technological breakthrough aimed at addressing existing uncertainties in civil engineering and construction. However, several challenges still need to be overcome. Another state-of-the-art review on AI-assisted visual inspection systems has been carried out by Mishra and Louren\u00e7o, this time focusing on cultural heritage structures [15].\nHowever, despite these promising developments, the reliability of image-based classification methods in terms of damage detection in real-world applications is not without challenges. Issues such as false positives (where damage is incorrectly identified, when it does not exist) and false negatives (where the system fails to identify existing damage) remain a concern. Furthermore, while these technologies excel in controlled environments or with high-quality data, their effectiveness in diverse and complex real-world settings, where lighting, angles, and environmental factors vary, is less clear.\nGiven the potential inaccuracies and the low occurrence rate of actual damage in most structures, the significance of a positive result from these models must be carefully scrutinized. This becomes particularly crucial when considering the safety risks associated with undetected damage, as well as the financial burden of false positives, which can lead to unnecessary repairs and wasted resources. In response to these challenges, this paper aims to examine the limitations of image-based damage detection techniques, focusing on the effects of false positives, false negatives, and the Base Rate Fallacy [16]. By critically evaluating the practical effectiveness of these methods, the study seeks to determine whether they can reliably support the maintenance of structural integrity or if their limitations undermine their utility in certain contexts. Additionally, this study proposes several strategies to mitigate these limitations and enhance the reliability of image-based SHM systems."}, {"title": "Overview of Image-Based Techniques for Damage Detection", "content": "Image-based techniques have gained significant traction in the field of SHM, driven by advances in ML, DL, and computer vision technologies. Automated inspection systems equipped with drones or stationary cameras are commonly employed to capture high-resolution images of hard-to-reach areas in structures like bridges, dams, and high-rise buildings [8]. These images are then processed through ML models, which analyze the data for signs of damage without the need for manual intervention. The combination of drones, high-resolution imagery, and DL algorithms is transforming traditional inspection processes by automating tasks that previously required significant labor and time.\nAt the forefront of these techniques are Convolutional Neural Networks (CNNs), a specialized type of DL model that excels at recognizing patterns and features in images [17]. CNNs are particularly useful for detecting surface-level damage such as cracks, corrosion, or spalling in structural components [18]. By training CNNs on large datasets of labeled images, these models can learn to identify damage patterns with impressive accuracy [19].\nOther DL methods, including Recurrent Neural Networks (RNNs) and hybrid architectures, are also being explored to account for more complex structural behaviors and damage patterns over time [20]. Computer vision techniques, which involve the use of algorithms to analyze and interpret visual data from cameras or sensors, have been widely adopted for detecting surface-level deformations or anomalies in structures [21]. These technologies often rely on advanced algorithms for image segmentation, edge detection, and pattern recognition to identify potential damage."}, {"title": "Advantages of Image-Based Methods", "content": "The primary advantage of image-based techniques in damage detection is their ability to automate and scale the inspection process [18]. Traditional manual inspections are labor-intensive, time-consuming, and prone to human error, especially when dealing with large or complex structures. Image-based methods, on the other hand, can quickly analyze vast amounts of visual data, reducing the need for on-site personnel and providing faster assessments.\nAdditionally, these techniques allow for continuous monitoring. By using cameras integrated with real-time data analysis, structures can be continuously inspected without the need for scheduled manual assessments. This real-time capability is particularly valuable in the early detection of damage, enabling preventative maintenance before small issues escalate into larger structural problems [22]. Image-based techniques can also be complemented by additional data, such as information from sensors and other instruments, to enhance accuracy and reliability.\nAnother key benefit is the ability to access difficult-to-reach areas. Drones equipped with high-resolution cameras can inspect areas that are dangerous or otherwise inaccessible for human inspectors, such as the underside of bridges or tall skyscrapers [8]. The use of drones also enables more frequent inspections at a fraction of the cost, contributing to the overall efficiency of the monitoring process.\nFurthermore, the scalability of these techniques makes them ideal for monitoring large infrastructure networks. From a city's network of bridges to a country's roadways, image-based methods can be deployed on a large scale, providing comprehensive coverage and reducing the time required to detect potential issues."}, {"title": "Challenges in Image-Based Damage Detection", "content": "While image-based classification techniques have shown great potential for automating damage detection in structures, they face several key challenges, primarily related to the accuracy and reliability of the results. A known limitation of these methods has to do with their dependence on high-quality data. The performance of DL models, including CNNs, is highly reliant on the quality of the images used for training and analysis. Images with poor resolution, or those affected by noise or environmental factors, can significantly degrade the model's ability to correctly classify damage [23]. Furthermore, these methods are often tailored to surface-level damage, making it difficult to detect internal structural problems such as subsurface cracks or material fatigue, which might not be visible through imagery alone.\nAdditionally, the variability in environmental conditions such as lighting, weather, and perspective-can introduce noise or distortions in the images, reducing the effectiveness of damage detection algorithms [24]. For example, a crack detected in a sunny, clear image may go undetected in an image taken under cloudy or shadowy conditions. This variability presents challenges in maintaining consistent accuracy across different inspection scenarios.\nIn addition, training DL models requires large and diverse datasets of labeled images [25]. In many cases, collecting and labeling enough high-quality images of damaged and undamaged structures can be a time-consuming and resource-intensive process. Furthermore, the rarity of actual structural damage in many datasets (low base rate) complicates the training process, making it difficult for models to learn to differentiate between true damage and benign anomalies.\nAnother major concern arises from the presence of false positives and false negatives-two types of classification errors that can significantly impact the decision-making process in SHM. False positives occur when the image-based system incorrectly identifies damage in a structure where none exists. This type of error (Type I error) can lead to unnecessary inspections, repairs, and resource allocation. Conversely, false negatives represent an even greater challenge in structural damage detection, as they occur when the system fails to detect actual damage. This type of error (Type II error) can have severe safety implications, as undetected damage may worsen over time, leading to structural failures or even catastrophic incidents."}, {"title": "Understanding False Positives and False Negatives in Damage Detection", "content": "Both false positives and false negatives highlight the trade-offs inherent in using image-based classification techniques. While these systems offer scalability and efficiency, the risks associated with classification errors cannot be ignored. Even small error rates can have outsized impacts when dealing with safety-critical infrastructure. As such, engineers and decision-makers must consider not only the accuracy of these models but also the significance and consequences of the errors they may produce.\nA confusion matrix is a performance evaluation tool used in classification problems to summarize how well a ML model or classification algorithm has performed [26]. It is a table that displays the number of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions, providing insights into the types of errors the model makes. The matrix helps assess the model's accuracy, precision, recall, and other performance metrics. Each cell in the confusion matrix corresponds to the actual versus predicted outcomes, making it a valuable tool for evaluating classification algorithms where multiple types of predictions are involved.\nIn practice, increasing the precision of a model often results in a decrease in recall, and vice versa. The Fl-score captures the balance between these two metrics in a single value, which can be expressed as:\n$F1=\\frac{2}{\\frac{1}{Recall}+\\frac{1}{Precision}}=\\frac{2 \\cdot Recall \\cdot Precision}{Recall + Precision}$\n(1)\nThe F1-score is the harmonic mean of precision and recall, providing a comprehensive measure that reflects the balance between these metrics. It reaches its maximum value when precision is equal to recall. Both false positives (corresponding to Type I Errors) and false negatives (corresponding to Type II Errors) present unique challenges in the context of SHM, and understanding their implications is critical for engineers and decision-makers relying on image-based methods. The presence of such errors can significantly undermine trust in these methods, particularly when used for safety-critical infrastructure. In large-scale SHM programs, where hundreds or thousands of structures are routinely inspected, even a small percentage of these errors can have considerable consequences.\nWhile false positives may seem less critical than false negatives, they can lead to a significant misallocation of resources. When a system incorrectly identifies damage, maintenance teams may be dispatched to inspect or repair undamaged structures, resulting in unnecessary costs and labor. In a worst-case scenario, if the frequency of false positives becomes too high, decision-makers might lose confidence in the system, leading to underuse or disregard of the technology altogether. This lack of trust can stall the adoption of automated methods, pushing engineers back to manual inspections, which are slower and more costly.\nFalse negatives are arguably more problematic because they represent a failure to detect actual damage. This type of error is particularly dangerous in safety-critical structures such as bridges, tunnels, or large buildings, where undetected damage could compromise structural integrity over time. If damage goes unnoticed, it may progress to a point where repairs are no longer possible, increasing the risk of catastrophic failure. In public infrastructure, the consequences of false negatives can be dire, leading to accidents, loss of life, and significant legal and financial liabilities for asset managers and government bodies.\nThese inaccuracies complicate decision-making for engineers. They must continuously balance the need for fast, efficient damage detection with the inherent risks of relying on automated systems prone to classification errors. Engineers may find themselves second-guessing the results of the system, needing to introduce additional layers of manual verification, which defeats the purpose of automation in the first place."}, {"title": "Base Rate Fallacy and its role in SHM", "content": "The Base Rate Fallacy [16], also known as base rate bias and base rate neglect [28], is a cognitive bias where people tend to ignore or underweight the base rate (i.e., the general probability of an event occurring) in favor of specific information or evidence presented, leading to erroneous conclusions. This fallacy occurs in situations where the base rate of an event-such as a disease, accident, or failure is relatively low, but the likelihood of a positive result (such as a medical test or detection method) is mistakenly interpreted without adequately considering the initial low probability of the event [29].\nThe Base Rate Fallacy can often arise in various fields, such as medical diagnostics [30, 31], criminal justice [32], and financial risk analysis. In the medical field, for example, even a highly accurate test for a rare disease might yield a disproportionately high number of false positives because the disease itself occurs so infrequently [33]. Despite the high accuracy of the test, the low occurrence of the disease means that the majority of positive results may not correspond to actual cases of the disease. The fallacy occurs when individuals focus too heavily on the test result and neglect to consider the overall rarity of the condition .\nThe fallacy can also manifest in public health scenarios, particularly during outbreaks like the COVID-19 pandemic. A common misconception involves the effectiveness of vaccines in highly vaccinated populations [34]. Some people may conclude that vaccines are ineffective simply because the majority of infections occur among vaccinated individuals. However, this reasoning neglects the base rate of vaccination in the population, leading to misleading interpretations. In highly vaccinated populations, it is expected that vaccinated individuals will represent a significant portion of infection cases simply because they constitute the vast majority of the population [34]. However, this observation alone does not imply that the vaccine is ineffective-it highlights the importance of evaluating outcomes in relation to the base rates of the population rather than focusing narrowly on case counts.\nIn general, this fallacy is particularly prevalent when evaluating ML models or any detection system that operates in environments where the events being detected occur at a very low rate. The problem is exacerbated when people intuitively expect that a positive result from a seemingly accurate system must indicate a high probability of the event occurring, without accounting for the low base rate. This will be highlighted in section 4 of this study through the use of a practical example."}, {"title": "Conditional Probabilities and Bayes' Theorem", "content": "Conditional probability refers to the probability of an event A occurring given that another event B has already taken place. It is expressed as P(AIB), meaning the probability of A happening, assuming B has occurred. This concept is often described as \u201cA given B\u201d. The probability of A depends on the prior occurrence of B and is calculated using Bayes' theorem [35], which helps estimate the likelihood of an outcome based on new information.\nBayes' rule provides a framework for updating the probability of a hypothesis (A) when relevant evidence (B) becomes available [36]. It states that the conditional probability of event A, given event B, is equal to the likelihood of event B occurring given A, multiplied by the prior probability of A, and then divided by the probability of B. The formula is as follows:\n$P(A|B) = \\frac{P(B|A)\\cdot P(A)}{P(B)}$\n(2)\nWhere:\n\u2022\n$P(A)$ is the prior probability of A, which represents the likelihood of A before considering any new evidence.\n\u2022\n$P(B)$ is the marginal probability of B, representing the overall likelihood of observing event B.\n\u2022\n$P(AIB)$ is the posterior probability, or the probability of A occurring given that B has happened.\n\u2022\n$P(B|A)$ is the likelihood, or the probability of observing event B if A is true.\nIn cases where events A and B are independent, it is P(A|B) = P(A) and P(B|A) = P(B), meaning the occurrence of one event does not influence the probability of the other.\nBayes' Theorem plays a critical role in a wide range of fields, offering a powerful tool for reasoning about probabilities and updating beliefs in the presence of new information. Its significance lies in its ability to combine prior knowledge (or assumptions) with fresh evidence to refine the probability of an event. This approach is particularly valuable when dealing with uncertain or dynamic environments where data evolves over time.\nOne of the major strengths of Bayes' Theorem is its flexibility in handling complex problems involving uncertainty. It allows us to incorporate existing knowledge (prior probabilities) and adjust our understanding based on new observations, enabling more informed decision-making. This process of updating beliefs is iterative\u2014each new piece of evidence refines our prior knowledge, resulting in a more accurate posterior probability.\nIn the broader context, Bayes' Theorem finds applications across many disciplines, such as Medical Diagnostics, ML and AI [36], Risk Analysis and Decision-Making, Forensics and Legal Reasoning [37], Search and Rescue Operations [38, 39], Marketing and Consumer Behavior [40], and others. In all these applications, the ability of Bayes' Theorem to update probabilities based on real-time data is invaluable. It provides a structured and quantitative approach to dealing with uncertainty, making it essential in scenarios where decision-making relies on balancing probabilities with new, often incomplete, information. This process of continuously refining predictions or hypotheses is one of the key reasons why Bayes' Theorem remains a cornerstone in fields that require precise, data-driven insights."}, {"title": "Numerical Example in SHM", "content": "In this section, we will examine the efficiency of an image-based SHM system with high accuracy, while also considering the base rate of damage in a city. We will demonstrate that, even if the system exhibits theoretically high performance in detecting damage\u2014characterized by a high true positive rate-it is still extremely likely to trigger false alarms in most examined cases if the base rate of damage is relatively low. To understand this phenomenon, we apply Bayes' theorem to calculate the probability that a positive diagnosis by the system is indeed correct. We also investigate the relationship between key performance parameters of the system and the base rate of damage, and propose strategies to mitigate the challenges associated with low base rate environments.\nWe consider a city with thousands of buildings of varying sizes and ages. In this scenario, only a small fraction of these buildings-approximately 1 in every 1,000\u2014has a structural defect. For simplicity, each building is classified as either \u201cintact\u201d or \u201cdamaged\u201d in a binary classification, without any intermediate states. To ensure the safety and integrity of its infrastructure, the city has implemented an advanced, autonomous SHM system. This system uses drones equipped with high-resolution cameras that continuously scan and capture thousands of images of each building, providing a comprehensive visual record of the structures.\nThe SHM system is fully automated: after collecting images, it uploads the data to the cloud, where digital imaging procedures analyze the photos. Using advanced DL and AI algorithms, the system classifies whether damage is present or not. The system is highly efficient. According to its documented specifications:\n\u2022\nIt has a 98% success rate in detecting damage when it actually exists, meaning that in 98 out of 100 cases with real damage, the system successfully identifies that damage exists. In other words, the system misses damage in only 2% of the cases with actual damage present.\n\u2022\nIn addition, like all systems, it occasionally produces false positives, identifying damage where none exists, at a rate of 5%. In other words, in 95% of cases with no damage the system will also find no damage.\nNow, we will examine what happens when the system detects damage in one of the city's buildings. Based on its high success rate according to its manufacturer, many people and even experts might instinctively believe that a \u201cpositive\" result from such an advanced and theoretically accurate system would lead to a high probability that the building is actually damaged. However, when we factor in the base rate of damage, the reality becomes far less intuitive.\nTo understand this, we break down the problem using the following information:\n\u2022\nBase rate of damage (b): Only 1 in 1,000 buildings (b=0.1%) has actual structural damage.\n\u2022\nTrue positive rate (TPR): If there is damage, the system detects it 98% of the time and fails to detect it 2% of the time (TPR=98%). This means that the False Negative Rate is FNR=2%.\n\u2022\nFalse positive rate (FPR): The system mistakenly detects damage in 5% of undamaged buildings and it identifies correctly that there is no damage in 95% of the cases of undamaged buildings (FPR=5% and True Negative Rate TNR=95%)\nNow, we would like to determine the probability that a building is actually damaged, given that the system has flagged it as damaged (i.e., the system gives a positive result) and taking into account the base rate of damage in the city. Since 1 in 1,000 buildings (0.1%) has actual structural damage, then for the general population of buildings:\n\u2022\nP(damaged) = 0.001\n\u2022\nP(intact) = 1 - P(damaged) = 0.999\nOur system appears to be quite efficient, with a 98% accuracy (Recall value) in detecting damage when it actually exists. Let T denote a positive test result of the system (the system predicts structural damage). Thus, we have that:\n$P(T | damaged) = 0.98 = TPR$\n(3)\nThe system occasionally produces false positives, identifying damage where none exists, with a false positive rate of 5%.\n$P(T | intact) = 0.05 = FPR$\n(4)\nIn the above, P(T| damaged) represents the conditional probability that the test is positive, given that the building is damaged, while P(T| intact) represents the conditional probability that the test is positive, given that the building is intact (not damaged). The test mistakenly indicates damage in 5% of cases when the building is intact, so this probability is 0.05.\nIn this problem, we try to calculate the conditional probability P(damaged | T), i.e. the probability that a building is actually damaged, given a positive test result from the system. According to Bayes' theorem, it is:\n$P(damaged | T) = \\frac{P(T | damaged)\\cdot P(damaged)}{P(T)}$\n(5)\nTo do the above calculation, we also need to find the probability, i.e. the probability of a positive test result P(T). This is given by:\n$P(T) = P(T | damaged)\\cdotP(damaged)+ P(T|intact)\\cdot P(intact)$\n(6)\nWhich gives us\n$P(T) = 0.98\\cdot0.001+0.05\\cdot0.999 = 0.05093 = 5.093\\%$\n(7)\nAs a result,\n$P(damaged |T) = \\frac{0.98\\cdot0.001}{0.05093} = \\frac{98}{5093} \\approx 0.01924=1.924\\%$\n(8)\nThis surprising result means that the probability of the building being actually damaged, given a positive test result by the system, is less than 2%, which is counterintuitive considering the system's theoretical high accuracy. Given the high success rate that the manufacturer of the system reports (98%), one would expect that the probability of a building being damaged based on a positive test result would be very high. On the contrary, this probability for the particular example is less than 2%, which is a very low probability and practically gives no value to any decision maker.\nWe can reach the same conclusion using a frequentist approach without directly relyingon the Bayes' Theorem, by reasoning as follows:\n\u2022\nSuppose we inspect 100,000 buildings in the city.\n\u2022\nOut of these, 100 buildings have damage (1 per thousand), while the remaining 99,900 buildings are intact (undamaged).\n\u2022\nSince the system falsely indicates damage in 5% of cases where there is no actual damage, 5% of the 99,900 intact buildings, or 4,995 buildings, are incorrectly flagged as damaged.\n\u2022\nAdditionally, the system correctly identifies 98% of the 100 damaged buildings, meaning 98 buildings are accurately flagged as damaged, while 2 damaged buildings are missed.\n\u2022\nTherefore, the total number of buildings reported as damaged by the system is 4,995 + 98 = 5,093 buildings.\n\u2022\nThus, the probability that a building flagged as \u201cdamaged\u201d by the system is actually damaged is 98/5,093 \u2248 0.01924, or approximately 1.924%."}, {"title": "Parametric investigation", "content": "We consider the following basic quantities in a parametric investigation:\n\u2022\nTPR: The true positive rate (98% in the previous example)\n\u2022\nFPR: The false positive rate (5% in the previous example)\n\u2022\nb: The base rate of damage (0.1% in the previous example)\n\u2022\nN: The number of examined cases (100,000 in the previous example)\nThe first two of the above parameters, TPR and FPR, are characteristics of the SHM system, while the third one, b, is a characteristic of the city being examined, while N is the number of buildings examined (sample size). In this case, the formulas giving the TP, TN, FP, and FN values (cases) depend on the sample size N and they are given by:\n$TP = N\\cdotb\\cdotTPR$\n(9)\n$FN = N\\cdotb\\cdot(1\u2013TPR)$\n(10)\n$FP = N \\cdot FPR\\cdot(1\u2212b)$\n(11)\n$TN = N \\cdot (1\u2212b)\\cdot(1-FPR)$\n(12)\nOn the other hand, the performance metrics of the system do not depend on the sample size N, and they are given by the formulas:\n$Accuracy =1-FPR\\cdot(1\u2212b)-b\\cdot(1\u2212TPR)$\n(13)\n$Precision = \\frac{b\\cdotTPR}{FPR\\cdot(1\u2212b)+b\\cdotTPR}$\n(14)\n$Recall = TPR$\n(15)\n$F1= \\frac{2b\\cdotTPR}{FPR\\cdot(1\u2212b)+b\\cdot(1+TPR)}$\n(16)\nThe above proposed formulas for the Accuracy, Precision, Recall and Fl-score should be used in cases where the TPR, FPR rates are known, and also the base rate of damage is either known or it can be efficiently approximated using known information. By observing Eqs. (13)-(16) we see that all performance metrics (with the only exception of the Recall value) depend strongly on the base rate of damage, b. The base rate of damage in the city must be taken into account in order to access the significance of a positive test result."}, {"title": "The special case of TPR=100%", "content": "In the special case where the True Positive Rate (TPR) is 100% (i.e., the False Negative Rate FNR is 0), the system achieves perfect detection of damage-meaning that whenever there is damage, the system identifies it every single time. However, false positives can still occur, as the False Positive Rate (FPR) is not necessarily zero, indicating that the system may incorrectly identify damage where none exists. This is a simpler, special case of the general case examined in the previous section, and it can be used to extract useful results.\nWith_TPR = 100%, the performance metrics of the system can be simplified using the following formulas:\n$Accuracy =1-FPR\\cdot(1\u2212b)$\n(17)\n$Precision = \\frac{b}{FPR\\cdot(1\u2212b)+b}$\n(18)\n$Recall =1$\n(19)\n$F1= \\frac{2b}{FPR\\cdot(1\u2212b)+2b}$\n(20)\nIf we consider the previous example, keeping the False Positive Rate (FPR) at 5% (i.e., True Negative Rate (TNR) = 95%) but increasing the TPR to 100% (from the previous 98%), the performance metrics can be recalculated as follows:\n\u2022\nAccuracy = 0.95005 = 95.01% (previously 95.00%)\n\u2022\nPrecision = 0.0196271 = 1.96% (previously 1.92%)\n\u2022\nRecall = 1 = 100% (previously 98.00%)\n\u2022\nF1 = 0.038498556 (previously 0.037743116)\nEven with TPR = 100%, we notice that the Precision of the system only slightly increases, from 1.92% to 1.96%. This means that a positive test result still implies only a 1.96% probability that actual damage is present. Figure 2 graphically depicts Eq. (18), i.e. the values of Precision as a function of b and FPR (for the case TPR = 100%)."}, {"title": "Evaluation of Significance: Do Image-Based Techniques Hold Value?", "content": "As image-based damage detection techniques become more prevalent in SHM, it is crucial to evaluate whether these methods truly hold practical value, particularly in light of the challenges posed by false positives and false negatives. While these systems offer scalability, automation, and the ability to monitor structures continuously, engineers must carefully assess when to trust a positive result and how to improve the reliability of these methods. The trade-offs between economic costs and safety risks are critical considerations that will determine the overall utility of image-based techniques in real-world applications.\nOne of the key challenges in evaluating image-based classification systems is determining when a positive result\u2014indicating potential damage\u2014can be trusted. Engineers must account for the fact that even highly accurate systems can produce false positives, especially when the base rate of actual damage is low. Blindly acting on every positive result can lead to unnecessary inspections, repairs, and operational disruptions.\nTo assess the value of a positive result, engineers can implement several strategies:\n\u2022\nThresholds and Confidence Scores: Many ML systems provide not only a binary classification (damaged or undamaged) but also a confidence score that indicates the model's certainty about its prediction. Engineers can establish a threshold for confidence scores, acting on positive results only when the confidence level exceeds a certain value. For instance, if the model predicts damage with 95% confidence, this could warrant further investigation, while lower-confidence predictions might trigger additional verification steps.\n\u2022\nRisk-Based Decision Making: Engineers can prioritize responses to positive results based on the risk associated with the specific structure. For critical infrastructure\u2014such as bridges or tunnels with high safety risks\u2014a conservative approach may be taken, acting on positive results even at lower confidence thresholds. Conversely, for less critical structures, engineers may require stronger evidence before initiating costly maintenance procedures.\n\u2022\nSecondary Validation Steps: Before acting on a positive result, additional validation steps can be implemented. This might include a follow-up inspection using another detection method, such as ultrasonic testing, vibration analysis, or manual inspection, to confirm or rule out the presence of damage. By combining multiple sources of evidence, engineers can reduce the likelihood of acting on false positives, ensuring that resources are allocated efficiently.\nTo enhance the reliability of image-based damage detection systems and reduce the rates of false positives and false negatives, several approaches can be employed:\n\u2022\nHybrid Approaches: One of the most effective ways to improve the reliability of damage detection is by integrating image-based techniques with other SHM methods. For example, combining visual data with sensor-based monitoring, such as vibration or acoustic sensors, can provide a more comprehensive view of a structure's health. While image-based methods excel at detecting surface-level damage, sensors can detect internal issues like material fatigue or subsurface cracks, complementing the visual data.\n\u2022\nHuman-in-the-Loop Systems: Incorporating human oversight into the damage detection process can help reduce classification errors. In a human-in-the-loop system, initial damage detections from the ML model are reviewed by an expert engineer before any actions are taken. This approach leverages the strengths of automation while retaining the accuracy of human judgment in ambiguous or high-risk cases. Engineers can validate or override the system's predictions, ensuring that only the most reliable results are acted upon.\n\u2022\nImproving Data Quality and Model Training: The performance of image-based systems is highly dependent on the quality of the data used to train the models. Improving the dataset by incorporating more diverse and higher-quality images, including a wide range of damage types and environmental conditions, can significantly enhance the model's ability to differentiate between damaged and undamaged structures. Additionally, using data augmentation techniques such as generating synthetic images of damaged structures\u2014can help the model generalize better to real-world scenarios.\n\u2022\nAdaptive Algorithms: Another promising approach is the development of adaptive algorithms that can adjust their detection thresholds based on real-time data. These algorithms could, for instance, adjust their sensitivity based on the structural history, environmental conditions, or feedback from other SHM systems, reducing the likelihood of both false positives and false negatives.\nIn addition, in evaluating the value of image-based damage detection systems, engineers must weigh the economic costs associated with false positives against the safety risks posed by false negatives. In many cases, the trade-offs between economic costs and safety risks will depend on the specific application and the criticality of the structure being monitored. For safety-critical infrastructure, it may be prudent to adopt conservative detection thresholds and hybrid validation systems to minimize the risk of false negatives. For less critical applications, a more lenient approach may be taken, optimizing for cost-effectiveness by tolerating a certain level of false positives."}, {"title": "Conclusions", "content": "In this paper, we explored the limitations of image-based techniques for damage detection in SHM and examined how these limitations affect their practical significance. While advancements in ML and AI have brought significant potential for automating the inspection of structures, several challenges still pose barriers to the effective deployment of these methods in real-world applications. Chief among these challenges are the issues of false positives, false negatives, and the Base Rate Fallacy, all of which"}]}