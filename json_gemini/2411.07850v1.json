{"title": "IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems", "authors": ["XIAOYIN YI", "JIACHENG HUANG"], "abstract": "Adversarial examples, which are inputs deliberately perturbed with imperceptible changes to induce model errors, have raised serious concerns for the reliability and security of deep neural networks (DNNs). While adversarial attacks have been extensively studied in continuous data domains such as images, the discrete nature of text presents unique challenges. In this paper, we propose Irony-based Adversarial Examples (IAE), a method that transforms straightforward sentences into ironic ones to create adversarial text. This approach exploits the rhetorical device of irony, where the intended meaning is opposite to the literal interpretation, requiring a deeper understanding of context to detect. The IAE method is particularly challenging due to the need to accurately locate evaluation words, substitute them with appropriate collocations, and expand the text with suitable ironic elements while maintaining semantic coherence. Our research makes the following key contributions: (1) We introduce IAE, a strategy for generating textual adversarial examples using irony. This method does not rely on pre-existing irony corpora, making it a versatile tool for creating adversarial text in various NLP tasks. (2) We demonstrate that the performance of several state-of-the-art deep learning models on sentiment analysis tasks significantly deteriorates when subjected to IAE attacks. This finding underscores the susceptibility of current NLP systems to adversarial manipulation through irony. (3) We compare the impact of IAE on human judgment versus NLP systems, revealing that humans are less susceptible to the effects of irony in text.", "sections": [{"title": "I. INTRODUCTION", "content": "Adversarial examples [1], crafted by adding imperceptible tiny perturbations to origin inputs maliciously, cause deep neural networks (DNNs) to fail blatantly. The secure issue, namely adversarial attack, is being widely concerned among researchers as soon as it was proposed. Extensive research has revealed that adversarial examples widely exist in many fields, e.g., computer vision (CV) [2], natural language processing (NLP) [3] and automatic speech recognition (ASR) [4].\nTextual data is not as continuous as images which are capable of being perturbed imperceptibly with pixel noise. Instead, it is impossible to craft a factual imperceptible perturbation on a text due to its discrete nature. Furthermore, the grammar and semantics may be broken easily by changing even a character. The textual adversarial attack is confronted with greater challenges compared with images.\nA variety of textual adversarial attack models has been proposed in many NLP tasks, incorporating machine translation [5], question-answering system [3], sentiment analysis [6], et al. Spelling mistake [7], visually similar characters substitution [8], synonyms substitution [9] and sentence paraphrasing [10] are typical textual adversarial attack methods ranging from word-level to sentence-level while categorized by attacking granularity. However, there are still a few issues while assuming those methods in practical situations: 1) Subtle spelling mistakes can be recovered easily with spelling error correction [11]. 2) Words out of vocabulary may arise attention and alertness while exceeding averages in a text. 3) Word substitution and sentence paraphrasing may cause grammar to be broken or semantics deviated. Therefore, we consider a textual adversarial attacking method more practically.\nThe irony is a kind of rhetorical device expressing a strong emotion referring to the opposite of literal meaning and needs to understand the actual meaning from context. Detecting"}, {"title": "II. LITERATURE REVIEW", "content": "Our work connects to two strands of literature: textual adversarial examples and irony generation.\nTextual Adversarial Examples Existing textual adversarial attack models can be categorized into character-level, word-level, and sentence-level according to the perturbation levels of their adversarial examples.\nCharacter-level attacks disrupt the process of converting natural language text into numerical representations that computers can process, thereby causing model decision shifts. The manifestation of character-level attacks varies across different linguistic environments. In English, character-level attacks often exploit visual perturbations, such as inserting [12], deleting, swapping, and modifying [8] letters within words to create artificially constructed spelling errors. In the Chinese context, handwriting errors on paper do not occur in electronic input based on input methods. Therefore, character-level attacks in the Chinese environment often manifest as the use of homophones for substitution [13], [14] or visual decomposition of characters [15].\nWord-level adversarial attacks achieve a shift in the semantic vector of the sample by perturbing the input sample at the word level, causing it to cross the decision boundary and thus leading to incorrect model outputs. Word substitution, as the core method of this strategy, includes various word replacement means such as word vector similarity [16], synonyms [17], and language model scoring [18]. Word-level adversarial attacks do not break the grammatical rules of the text and retain the original semantics to the greatest extent, thus performing better in terms of adversarial text quality and attack success rate. Coupled with the use of language models for control, it also ensures the fluency and smoothness of adversarial texts. Among them, text attacks based on synonym substitution have strong semantic retention and grammatical coherence, belonging to the most threatening category of text adversarial attacks, which have attracted widespread attention from researchers.\nSentence-level adversarial attacks treat the entire original input sentence as the object of perturbation, carefully reconstructing the text content, that is, generating adversarial text that has the same semantics as the original input but causes the victim model to make decision errors. Common sentence-level adversarial attack methods include encoding"}, {"title": "III. PROBLEM STATEMENT", "content": "We assume access to a corpus of labeled sentences $D = \\{(s_1,p_1), ..., (s_n,p_n)\\}$, where $s_i$ is a sentence and $p_i \\in L$, the set of possible emotional polarity, i.e., $L = \\{positive, negative\\}$. We define $s^o = (c, e, d)$, a sentence with emotional polarity $p$, where $c$ is the central word of the sentence, $e$ is the evaluation word that evaluating the central word $c$, and $d$ is the detailed description of the evaluation. On this basis, we define emotional sentence $s^o$ as a straightforward sentence or an ironic sentence while the evaluation $e$ have emotional polarity $p'$, while collocating with $c$, and $p = p'$, or $p \\neq p'$. Generally, the irony is a negative sentence exhibiting positive evaluation. Thus, our goal is to build a model that takes as input sentence $s$, a negative emotional sentence exhibiting negative evaluation $e^{neg}$, and outputs a sentence $s'$ that retains the negative emotional polarity while exhibiting positive evaluation $e^{pos}$. Note that the concept of evaluation word we use is not equivalent to the sentiment word while sentiment word is an adjective with a clear emotional polarity. The emotional polarity of an evaluation word should be determined by the central word with which the evaluation word collocates."}, {"title": "IV. APPROACH", "content": "In this section, we detail our irony-based textual adversarial attacking method, incorporating three parts: 1) an extractor of collocations between nouns and adjectives, 2) a strategy for evaluation word substitution, and 3) a strategy for ironic evaluation sentence generation. An overview of our IAE generator is shown in Fig. 1. Generally, it takes straightforward text as inputs and outputs ironic text. First, the central word and relevant evaluation word will be located, and then the evaluation word will be substituted with an opposite evaluation word among all possible alternatives, Finally, an appropriate ironic evaluation sentence, determined by local model, will be appended to the text for strengthening the effect of irony. Next, we describe the details of each component of IAE generator.\nWe design a collocations extractor to establish noun-adjective collocations tables, which also reveals probable emotional polarity between a noun with all collocated adjectives, as a library of alternatives for evaluation word substitution (see section IV-B).\nA host of observations were made on Chinese corpus with part-of-speech tagging and dependency parsing, and we found the noun-adjective collocations in a Chinese sentence are supposed to form the following two kinds of dependencies: 1) a subject-verb structure, or 2) an attributive structure (see examples in Table 2). Note that the results of dependency parsing in Chinese may be different from English due to the differences in the two kinds of syntax rules. e.g., the words \"weather\u201d and \u201cgood\u201d are supposed to form a subject-predicative in English instead of a subject-verb.\nThen we can extract plenty of collocations from a large corpus through the observations above, but the next key question is how to determine the emotional polarity of each noun-adjective collocation. Although we can use advanced sentiment analysis models to determine the overall emotional polarity of the sentence from which a noun-adjective collocation extracted, it is no guarantee the emotional polarity of a noun-adjective collocation will be consistent with the whole sentence. But, intuitively, the emotional polarity of a collocation should probably be positive if it mostly appears in sentences with a positive overall emotional polarity rather than negative. Hence, the polarity of collocation can be inferred by the following formulas:\n$F(x) = \\frac{Freq_{pos}}{Freq_{neg}}$\n$x = \\begin{cases}positive, x > 1\\\\negative, x < 1\\\\manually, x = 1\\end{cases}$\nWhere $Freq_{pos}$ and $Freq_{neg}$ are the frequencies of a collocation appearing in sentences with an emotional polarity of positive or negative respectively. The emotional polarity of a collocation is supposed to be positive when $x > 1$, or"}, {"title": "B. EVALUATION WORD SUBSTITUTION", "content": "The strategy for evaluation word substitution is the most important procedure to convert a straightforward sentence $s$ to an ironic sentence $s'$ while $s'$ has the evaluation word $e$ with emotional polarity $p'$, which is opposite to the emotional polarity $p$ of the whole sentence. Next, we describe our evaluation word substitution step by step.\nLocating. At the very beginning, the pairs of central word and relevant evaluation word are located by using part-of-speech tagging and dependency parsing together, which is similar to the strategy of extracting noun-adjective collocation (see secttion IV-A).\nRetrieving. The alternatives are retrieved among the table $T$ by using central word $c$ as an index. The whole procedure will terminate and return a general evaluation word (e.g., \u201c\u4e0d\u9519\u201d, which is analog to \"fine\u201d in English) as the result while the central word does not exist or none of the positive evaluation words are retrieved.\nDetermining. To determine what alternative evaluation word to substitute original, our strategy is to evaluate the quality (i.e., probability of sentence) of all alternative sentences $S'$ by N-gram language model while combining any possible collocation of central word and alternative evaluation word. Formally, for any $s' \\in S'$, the probability is calculated by the following formula:\n$P(s) = \\prod_{i=1}^{|s|} \\frac{count(w_{i-1}w_i, D) + \\delta}{count(w_i, D) + \\delta}$\nwhere $w_i$ is the i-th word in $s'$, $w_{i-1}w_i$ is the sequence composed of $w_{i-1}$ and $w_i$ sequentially, $count(., D)$ denotes the numbers of times a word or a sequence appears in D, and $\\delta$ is an additive smoothing parameter for the situation that some words are just not appearing in D. In practice, the smoothing parameter $\\delta$ can be set to 1 empirically. The alternative sentence $s'$ with the highest probability among $S'$ will be determined as the result of evaluation word substitution."}, {"title": "C. IRONIC EVALUATION APPENDING", "content": "Reversing the result of sentiment analysis by substituting the evaluation alone is often difficult while the context still exhibits original emotional polarity. But this problem can be solved by appending an evaluation, which is opposite to the polarity of real emotion for strengthening the ironic effect.\nIt is easy to construct positive evaluations by composing positive adjectives and other grammatical constituents according to sentence patterns. However, the problems are how"}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "In this section, we conduct comprehensive experiments to evaluate our IAE on the tasks of sentiment analysis.\nWe evaluate our IAE on the public reviews of Meituan\u00b9 and Amazon. The five-star and one-star reviews are taken as positive and negative text respectively. Because our IAE is only applicable to the examples with negative emotional polarity, we randomly select 500 examples with negative emotional polarity from each dataset as the test set, and then we divide the remaining examples into two balanced parts for training local and victim models. Details of the datasets are shown in Table 3, where \"Class #\" refers to the number of labels, \"Max. #W\" means maximum length of sentences (number of words), \"Min. #W\" means minimum length of sentences (number of words), and \"Avg. #W\" means average length of sentences (number of words), \u201cP. #\u201d and \u201cN. #\u201d signify the number of text exhibiting positive and negative emotional polarity respectively.\nBesides, for comprehensive noun-adjective collocations extracting (see section IV-A), we collected 30111 nouns and 114383 related collocations from serveral Chinese corpus,"}, {"title": "B. BASELINE METHODS", "content": "We implement two baseline methods based on important word substitution and compared them with ours for proving the contribution of this work. The two baseline methods are 1) visual-based substitution [8], which means substitute important words with visual similar chart, and 2) homonym-based substitution [13], which means substitute important words with others pronounced the same way but have different meanings. The important words refer to the words in the input text that make the most contribution to the model decision and the calculation algorithm of important words adopts [30]."}, {"title": "C. ATTACK PERFORMANCE", "content": "The attack performance results of our IAE and two baseline methods are shown in Table 4. Note that only examples labeled with negative are used for test as the adversarial attack based on irony is only applicable to the examples with negative emotional polarity. We observe the adversarial examples generated by our irony-based attack cause the victim models to fail more seriously than the baseline methods in"}, {"title": "D. HUMAN EVALUATION", "content": "We ask 4 students with native Chinese language skill to evaluate the emotional correctness and semantic smoothness of successful IAE generated from Meituan and Amazon reviews. Specifically, we randomly select 100 IAE and 100 clean examples, and every student needs to evaluate the mixture of them.\nFor evaluating emotional correctness, each student evaluates the true emotional polarity of each example and it is annotated as positive (negative) if two or more students evaluate a example as positive (negative). An extra human evaluator would participate in the evaluation if there are equal numbers of different evaluation on emotional polarity.\nFor evaluating semantic smoothness, each student scores"}, {"title": "VI. DISCUSSION", "content": "We studied how to regard irony as a textual adversarial perturbation in Chinese and it proved effective in sentiment analysis. There are differences between Chinese and other languages in grammar and habits, however, irony, as a rhetorical device in almost all languages, could be utilized as a general way of textual adversarial perturbation.\nThe experiment of training the local model for generating effective adversarial examples also reveals some properties of transferability. First, the transfers between two models are non-symmetric. As we can see, the accuracy of victim model BERT is 54.2% when generated IAE from local model BidLSTM, however, the accuracy of victim model BidLSTM is 87.6% when generated IAE from local model BERT while testing on Meituan reviews dataset. It is similar to the findings in the study of the transferability of image adversarial examples [32], even though we focus on the text field. Second, the adversarial examples generated from the high-accuracy"}, {"title": "VII. CONCLUSION AND FUTURE WORK", "content": "In this paper, we have introduced Irony-based Adversarial Examples (IAE), a novel method for generating adversarial text by transforming straightforward sentences into ironic ones. Our research has made several significant contributions to the field of adversarial attack. Firstly, we have introduced IAE as a strategy for generating textual adversarial examples that leverages irony. This method is innovative in that it does not depend on pre-existing irony corpora, thereby offering a flexible instrument for creating adversarial text across a spectrum of NLP tasks. Secondly, we have demonstrated empirically that the performance of several deep learning models on sentiment analysis tasks is markedly compromised when confronted with IAE attacks. This result highlights the vulnerability of current NLP systems to adversarial manipulations facilitated through irony. Thirdly, we have compared the effects of IAE on human judgment versus NLP systems, revealing a notable difference in susceptibility. Our findings indicate that humans are relatively more resilient to the influence of irony in text, contrasting with the performance of NLP models.\nOur future work will focus on enhancing the performance of IAE in longer texts and improving its generalization capabilities across different languages. This will involve addressing the complexities associated with maintaining ironic integrity over extended passages and adapting to the nuances of various linguistic contexts. Additionally, we are intrigued by the prospect of integrating more rhetorical devices into textual adversarial perturbations, beyond irony. For instance, exploring the use of metaphors to disrupt machine reading comprehension presents an exciting avenue for further research. By expanding the repertoire of rhetorical strategies employed in adversarial text generation, we aim to deepen our understanding of the interplay between language, context, and machine learning models, ultimately contributing to the development of more robust and nuanced NLP systems."}]}