{"title": "Likelihood-Ratio Regularized Quantile Regression: Adapting Conformal Prediction to High-Dimensional Covariate Shifts", "authors": ["Sunay Joshi", "Shayan Kiyani", "George Pappas", "Edgar Dobriban", "Hamed Hassani"], "abstract": "We consider the problem of conformal prediction under covariate shift. Given labeled data from a source domain and unlabeled data from a covariate shifted target domain, we seek to construct prediction sets with valid marginal coverage in the target domain. Most existing methods require estimating the unknown likelihood ratio function, which can be prohibitive for high-dimensional data such as images. To address this challenge, we introduce the likelihood ratio regularized quantile regression (LR-QR) algorithm, which combines the pinball loss with a novel choice of regularization in order to construct a threshold function without directly estimating the unknown likelihood ratio. We show that the LR-QR method has coverage at the desired level in the target domain, up to a small error term that we can control. Our proofs draw on a novel analysis of coverage via stability bounds from learning theory. Our experiments demonstrate that the LR-QR algorithm outperforms existing methods on high-dimensional prediction tasks, including a regression task for the Communities and Crime dataset, and an image classification task from the WILDS repository.", "sections": [{"title": "1 Introduction", "content": "Conformal prediction is a framework to construct distribution-free prediction sets for black-box predictive models (e.g., Saunders et al., 1999; Vovk et al., 1999, 2022, etc). Formally, given a pretrained prediction model f : X \u2192 Y that maps features x \u2208 X to labels y \u2208 Y, as well as n\u2081 calibration datapoints (Xi, Yi) : i \u2208 [n1] sampled i.i.d. from a calibration distribution P1, we seek to construct a prediction set C(Xtest) y for test features Xtest sampled from a test distribution P2. We aim to cover the true label Ytest with probability at least 1 - a for some a \u2208 (0,1): that is, P(Ytest \u2208 C(Xtest)) \u2265 1-a. The left-hand side of this inequality is the marginal coverage of the prediction set C, averaged over the randomness of both the calibration datapoints and the test datapoint. In the case that the calibration and test distributions coincide (P\u2081 = P2), there are numerous conformal prediction algorithms that construct distribution-free prediction sets with valid marginal coverage; for instance, split and full conformal prediction (e.g., Papadopoulos et al., 2002; Lei et al., 2013). However, in practice, it is often the case that test data is sampled from a different distribution than calibration data. This general phenomenon is known as distribution shift (e.g., Qui\u00f1onero-Candela et al., 2009; Sugiyama and Kawanabe, 2012). One particularly common type of distribution shift is covariate shift (Shimodaira, 2000), where the conditional distribution of Y|X stays fixed, but the marginal distribution of features changes from calibration to test time. For instance, in the setting of image classification for autonomous vehicles, the calibration and test data might have been collected under different weather conditions Yu et al. (2020); Koh et al. (2021). Under covariate shift, ordinary conformal prediction algorithms may lose coverage.\nRecently, a number of methods have been proposed to adapt conformal prediction to covariate shift, e.g., in Tibshirani et al. (2019); Park et al. (2022b,a); Gibbs et al. (2023); Qiu et al. (2023); Yang et al. (2024); Gui et al. (2024). Most existing approaches attempt to estimate the likelihood ratio function r : X \u2192 R, defined as r(x) = (dP2,x/dP1,x)(x), for all x \u2208 X. One can construct an estimate of the likelihood ratio if one has access to additional unlabeled datapoints sampled i.i.d from the test distribution P2. Methods for"}, {"title": "1.1 Related work", "content": "Here we only list prior work most closely related to our method; we provide more references in Appendix C. The early ideas of conformal prediction were developed in Saunders et al. (1999); Vovk et al. (1999). With the rise of machine learning, conformal prediction has emerged as a widely used framework for constructing prediction sets (e.g., Papadopoulos et al., 2002; Vovk et al., 2005; Vovk, 2013). Classical conformal prediction guarantees validity when the calibration and test data are drawn from the same distribution. In contrast, when there is distribution shift between the calibration and test data (e.g., Qui\u00f1onero-Candela et al., 2009; Shimodaira, 2000; Sugiyama and Kawanabe, 2012; Ben-David et al., 2010; Taori et al., 2020), coverage may not hold. Covariate shift is a type of dataset shift that arises in many settings, e.g., when predicting disease risk for individuals whose features may evolve over time, while the outcome distribution conditioned on the features remains stable (Qui\u00f1onero-Candela et al., 2009).\nNumerous works have addressed conformal prediction under various types of distribution shift (Tibshirani et al., 2019; Park et al., 2022b,a; Qiu et al., 2023; Si et al., 2024). For example, Tibshirani et al. (2019) investigated conformal prediction under covariate shift, assuming the likelihood ratio between source and target covariates is known. Lei and Cand\u00e8s (2021) allowed the likelihood ratio to be estimated, rather"}, {"title": "2 Problem formulation", "content": "In this section we fix notation and state our problem."}, {"title": "2.1 Preliminaries and notations", "content": "For a \u2208 (0,1), recall that the quantile (pinball) loss la is defined for all c, s \u2208 R as\n\nla(c, s) := {(1-a)(sc) if s \u2265 c,\na(c-s) if s < C.\n\nFor any distribution P, the minimizers of c\u2192 Es~p[la(c, S)] are the (1 - a)th quantiles of P.\nLet the source or calibration distribution be denoted P1 = P1,x \u00d7 Py\\x, and let the target or test distribution be denoted P2 = P2,x \u00d7 Py|x, a covariate shifted version of the calibration distribution. Let Ei denote the expectation over Pi, i = 1,2. Let x \u2192 r(x) = (\\frac{dP_{2,x}}{dP_{1,x}})(x) denote the unknown likelihood ratio function.\nRecall that a prediction set C : X \u2192 2V has marginal (1-a)-coverage in the test domain if P2 [Y \u2208 C'(X)] > 1 - a. Observe that P2 [Y\u2208 C(X)] can be rewritten as E2 [1[Y\u2208 C(X)]], where 1[.] denotes an indicator function. Let S : (x, y) \u2192 S(x, y) denote the nonconformity score associated to a pair (x, y) \u2208 X \u00d7 Y. Given a threshold function q: X \u2192 R, we consider the corresponding conformal predictor C : X \u2192 2 given by\n\nC(x) = {y \u2208 Y : S(x, y) \u2264 q(x)}\n        (1)\n\nfor all x \u2208 X. Thus a threshold function q yields a conformal predictor with marginal (1 \u2013 a)-coverage in the test domain if P2[S(X, Y) \u2264 q(X)] \u2265 1 - a. We assume that a \u2264 0.5. For our theory, we consider [0, 1]-valued scores.\nIn this paper, a linear function class refers to a linear subspace of functions from X \u2192 R that are square-integrable with respect to P1,x. An example is the space of functions representable by a pretrained model with a scalar read-out layer. If I : X \u2192 Rd denotes the last hidden-layer feature map of the pretrained model, where \u0424 = ($1,..., \u0444\u0430) for i : X \u2192 R for all i \u2208 [d], then the linear class of functions representable by the network is given by {\u3008\u03b3, \u03a6) : \u03b3 \u2208 Rd}, where (\u00b7,\u00b7) is the l\u00b2 inner product on Rd."}, {"title": "2.2 Problem statement", "content": "We observe n\u2081 labeled calibration (or, source) datapoints {(Xi, Yi) : i \u2208 [n\u2081]} drawn i.i.d. from the source distribution P1, and an additional n3 unlabeled calibration datapoints S3. We also have n2 unlabeled (target) datapoints S2 drawn i.i.d. from the target distribution P2. Given a \u2208 (0,1), our goal is to construct a threshold function q : X \u2192 R that achieves marginal (1 \u2013 a)-coverage in the test domain: P2[S(X,Y) < q(X)] \u2265 1 \u2013 \u03b1."}, {"title": "3 Algorithmic principles", "content": "Here we present some intuition behind our approach."}, {"title": "3.1 Change of measure", "content": "A key fact for us is the change-of-measure identity E\u2081[r(X)h(X)] = E2[h(X)] for all measurable functions h : X \u2192 R. To see this, we simply write E\u2081[r(X)h(X)] = E1[dP2,x/dP1,x(X)\u00b7h(X)] = E2[h(X)]. Therefore, for a threshold function q,\nE\u2081[r(X)1[S(X, Y) \u2264 q(X)]] = E1[r(X)Py\\x[S(X, Y) \u2264 q(X)]]\n= E2 [PY|x [S(X, Y) \u2264 q(X)]] = P2[S(X, Y) \u2264 q(X)].\nThus a threshold function q yields a conformal predictor with marginal (1 \u2013 a)-coverage in the test domain if and only if\n\nE1 [r(X)1[S(X, Y) \u2264 q(X)]] \u2265 1 - \u03b1."}, {"title": "3.2 Warm-up: stationary conditions of pinball loss", "content": "As a warm-up, we begin with a simpler objective function, the pinball loss. Suppose that we knew the true likelihood ratio r. Then in order to obtain our threshold function, we could solve the optimization problem K* = arg mink\u2208R E1[la(kr(X), S)], and set our threshold function to equal (* = k*r. We now argue that the marginal (1-a)-coverage of (* in the test domain can be deduced from the first order condition with respect to k. Assuming that the distribution of S|X = x has a density for all x \u2208 X, and using the fact that dela(c, s) = 1[s < c] \u2013 (1 \u2212 a) for all c\u2260 s, the derivative of the objective with respect to kis\n\\frac{\\partial}{\\partial \\kappa} E_1[l_\\alpha (\\kappa r(X), S)] = E_1[\\frac{\\partial l_\\alpha (\\kappa r(X), S)}{\\partial \\kappa}]\n= E\u2081[r(X)(1[S < \u03bar(X)] \u2013 (1 \u2212 a))].\nSetting this equal to zero, we deduce that the minimizer * satisfies E\u2081 [r(X)(1[S < \u03ba*r(X)] \u2013 (1 \u2212 a))] = 0. By the change-of-measure identity above, this implies the desired marginal coverage guarantee for (*.\nThe above problem can be recast as optimizing over the one-dimensional function class \u0124 = {\u03bar : \u03ba\u2208R} spanned by r. So, if we knew r, we could ensure coverage by optimizing over a single scalar parameter, which would be convenient and also have good finite sample coverage. However, we do not know r. Therefore, we consider a general class H large enough to approximater in a suitable way, and solve an analogous optimization problem. Intriguingly, the first order conditions will ensure coverage.\nSpecifically, given a convex function class H, we consider the optimization problem\n\n(h*, **) = arg min E\u2081[la(kh, S)],\nh\\in H, \\kappa \\in R\n\nand set our threshold function equal to \u03ba*h*. To derive the first order condition with respect to h, assume for simplicity that the minimizer h* lies in the interior of H. Given a valid perturbation direction\u00b9 g, the function h* + eg is in H for sufficiently small \u025b. Since for \u03ba = k*, h* minimizes the objective in h, the function & E1 [la(\u03ba*(h*(X) + \u025bg(X)), S)] has a minimum at \u025b = 0. Setting the derivative of this function with respect to a equal to zero as in Gibbs et al. (2023), we obtain the first order condition\n\n\\frac{\\partial}{\\partial \\varepsilon} \\vert_{\\varepsilon =0} E_1 [l_\\alpha (\\kappa^* (h^*(X) + \\varepsilon g(X)), S)] = E_1 [\\kappa^* g(X) (1[S < \\kappa^* h^*(X)] - (1 - \\alpha))]\n= 0.\n\nIf * \u2260 0 and E\u2081[g(X)] \u2260 0, then by rearranging and dividing by K*E\u2081[g(X)], this is equivalent to\nE_1[\\frac{g(X)}{E_1 [g(X)]} 1[S < \\kappa^* h^*(X)]] = 1-a. If the likelihood ratio r is a valid perturbation at h*, we can plug in\ng = r to find that the threshold function *h* attains valid coverage in the test domain. Thus, we search\nfor classes H such that ris a valid perturbation at all interior points of H."}, {"title": "3.3 Constrained quantile regression", "content": "We now design a suitable function class H. Given \u03b5 > 0, consider in this section H = B(r), the ball of radius de centered at r, consisting of all square-integrable functions h satisfying E\u2081 [(h(X) \u2013 r(X))\u00b2] \u2264 \u03b5. Since the interior is an open set, all perturbations are valid. Thus, by our remarks above, if we minimize \u03951 [la (\u03ba\u03b7(\u03a7), S)] for scalar \u03ba and \u0125 restricted to this ball, we obtain a threshold function with valid coverage under the covariate shift defined by r."}, {"title": "3.4 Removing explicit dependence on the likelihood ratio", "content": "Next, notice that we can expand E\u2081[(\u0125(X) \u2013 r(X))\u00b2] into\n\nE1[h(X)\u00b2] + E1[-2r(X)h(X)] + E\u2081[r(X)\u00b2] = E1[\u0125(X)\u00b2] + E2[\u22122h(X)] + E1 [r(X)\u00b2],\n\nwhere we used the change-of-measure identity E\u2081[r(X)h(X)] = E2[h(X)]. Only the first two terms depend on the optimization variable h, so it is enough to consider these two terms. This is where we make our second key observation. The insight is that neither of the terms E\u2081[h(X)2] or E2[\u22122h(X)] explicitly involve r, and thus they can be estimated by sample averages over the source and target data, respectively. Thus, we can minimize E\u2081[la(kh(X), S)] over \u03ba\u2208 R while keeping E\u2081[h(X)2] + E2[\u22122h(X)] bounded. The threshold \u03ba*h* will have valid coverage under the covariate shift r."}, {"title": "3.5 Algorithm: likelihood ratio regularized quantile regression", "content": "Further, we can equivalently replace the constraint with a regularization term. Given a regularization strength x \u2265 0, we can minimize the objective E1 [la(kh(X), S)]+1(E1[\u0125(X)\u00b2]+E2[\u22122h(X)]) over \u03ba\u2208 R and h square integrable with respect to P1,x. By reparametrizing this optimization problem (\u0127 \u2194 \u03b2\u04bb, \u03ba \u2194 1/\u03b2), we may move the scalar parameter from the first term to the second and third terms. This yields the population-level likelihood ratio regularized quantile regression (LR-QR) objective\n\nL(h, \u03b2) = E1 [la(h, S)] + AE1[\u03b2\u00b2h\u00b2] + \u03bbE2[\u22122\u1e9eh],\n        (2)\n\nfor some regularization strength x \u2265 0. Finally, since in practice, we cannot optimize over all square-integrable functions, we restrict to functions h in some function class H, leading to the scaled LR-QR problem\n\n(h*, \u03b2*) \u2208 arg min L(h, \u03b2).\n        (LR-QR)\nh\\in H, \\beta\\in R\n\nWe set our threshold function q in (1) to equal h*, so that our conformal prediction sets equal C*(x) = {y \u2208 Y : S(x, y) \u2264 h*(x)} for all x \u2208 X.\nWe solve an empirical version of this objective. We will use our labeled source data {(Xi, Yi) : i \u2208 [n1]} to estimate E1[la(h, S)], our additional unlabeled source data S3 to estimate E3 [\u1e9e2h2], and our unlabeled target data S2 to estimate \u5165\u00ca2[\u22122\u1e9eh]. Letting \u00ca\u2081, \u00ca2, and \u00ca3 denote empirical expectations over {(Xi, Y\u2081) : i \u2208 [n1]}, S2, and S3, respectively, we thus define the empirical risk \u00ce(h, \u03b2) as\n\n\u00ca\u2081 [la(h, S)] + X\u00ca3[\u03b2\u00b2h\u00b2] + \u5165\u00ca2[\u22122\u1e9eh],\n        (3)\n\nfor \u2265 0. We then solve the following empirical scaled likelihood ratio regularized quantile regression problem:\n\n(h, \u03b2) \u2208 arg min (h, \u03b2).\n        (Empirical-LR-QR)\nh\\in H, \\beta\\in R\n\nOur proposed threshold is q = h. See Algorithm 1."}, {"title": "4 Theoretical results", "content": ""}, {"title": "4.1 Infinite sample setting", "content": "We first consider the infinite sample or \"population\" setting, characterizing the solutions of the LR-QR problem from (2) in an idealized scenario where the exact values of the expectations E1, E2 can be calculated. In this case, we will show that if the function class H is linear and contains the true likelihood ratio r, then the optimizer achieves valid coverage in the test domain. Let ru be the projection of r onto H in the Hilbert space induced by the inner product\u3008f, g) = E1[fg]. The key step is the result below, which characterizes coverage weighted by ra.\nProposition 4.1. Let H be a linear function class consisting of square-integrable functions with respect to P1,x. Then under regularity conditions specified in Appendix E (the conditions of Lemma L.3), if (h*,\u03b2*) is a minimizer of the objective in Equation (LR-QR), then we have\n\nE1[rn(X)1[S \u2264 h*(X)]] \u2265 1 \u2212 \u03b1.\n\nThe proof is given in Appendix I. As a consequence of Proposition 4.1, if H contains the true likelihood ratio r, so that r\u2081 = r, then in the infinite sample setting, the LR-QR threshold function h* attains valid coverage at test-time:\n\nE1 [r(X)1[Sh*(X)]] = P2[S \u2264 h*(X)] \u2265 1 \u2212 \u03b1.\n\nHowever, in practice, we can only optimize over finite-dimensional function classes, and as a result we must control the effect of mis-specifying H. If r is not in H, we can derive a lower bound on the coverage as follows. First, write\n\nE1 [r(X)1[S(X,Y) \u2264 h*(X)]]\n= E1[rn(X)1[S(X,Y) \u2264 h*(X)]] + E1[(r(X) \u2013 rn(X))1[S(X,Y) \u2264 h*(X)]].\n\nBy Proposition 4.1, the first term on the right-hand side is at least 1 \u03b1. Since the random variable 1[S(X,Y) \u2264 h*(X)] is {0,1}-valued, the Cauchy-Schwarz inequality implies that the second term on the right-hand side is at least -E1[(r \u2013 rn)2]1/2. Thus we have the lower bound\n\nP2[Y \u2208 C*(X)] = E\u2081[r(X)1[S(X, Y) \u2264 h*(X)]]\n> (1 \u2212 a) \u2013 E1 [(r \u2013 rn)2]1/2.\n\nGeometrically, this coverage gap is the result of restricting to H; in fact, E\u2081[(r \u2013 r\u04a3)2]1/2 is the distance from r to H. This error decreases if H is made larger, but in the finite sample setting, this comes at the risk of overfitting."}, {"title": "4.2 Finite sample setting", "content": "From the analysis of the infinite sample regime, it is clear that if the function class H is larger, the test-time coverage of the population level LR-QR threshold function h* moves closer to the nominal value. However, in the finite sample setting, optimizing over a larger function class also presents the risk of overfitting. In a finite sample setting, by tuning the regularization parameter A, we are trading off the estimation error incurred for the first term of Equation (2), namely (\u00ca\u2081 \u2013 E1)[la(h(X), S)], and the error incurred for the second and"}, {"title": "5 Experiments", "content": "In this section, we compare our method, the LR-QR algorithm, with the following baselines: (1) Split or inductive conformal prediction Papadopoulos et al. (2002); Lei et al. (2018); (2) Weighted conformal prediction Tibshirani et al. (2019), referred to as Weighted-CP; (3) The doubly robust method proposed in Yang et al. (2024), referred to here as 2R-CP; (4) The distributionally robust optimization approach from Cauchois et al. (2024), referred to as DRO-\u0421\u0420."}, {"title": "5.1 Choosing the regularization parameter \u5165", "content": "Equation (6) suggests an optimal choice of the regularization parameter A in LR-QR. Guided by this theory, we form a grid of ten equally spaced candidate values, ranging from the theoretical X* down too. We then perform three-fold cross-validation over the combined calibration and unlabeled sets (without using any labeled test data) as follows: for each candidate \u5165, we train LR-QR with that A, and compute a validation measure, namely the l\u00b2-norm of the gradient of the LR-QR objective on the held-out fold. We pick A with the smallest average validation measure across all folds."}, {"title": "5.2 Communities and Crime", "content": "We evaluate our methods on the Communities and Crime dataset Redmond (2002), which contains 1994 datapoints corresponding to communities in the United States, along with socio-economic and demographic statistics. The task is to predict the per-capita violent crime rate (a real-valued response) from a 127-dimensional input.\nSetup. We first randomly select half of the data as a training set, and use it to fit a ridge regression model f(\u00b7) as our predictor. We tune the ridge regularizer with five-fold cross-validation. We use the remaining half to design four covariate shift scenarios, determined by the frequency of a specific racial subgroup (Black, White, Hispanic, and Asian). For each of these features, we find the median value m over the remaining dataset. Datapoints with feature value at most m form our source set, while the rest form our target set. This creates a covariate shift between calibration and test, as the split procedure only observes the covariates, and is independent of labels. We then further split the target set into roughly equal unlabeled and labeled subsets. The unlabeled subset and the calibration data (only their covariates, not the labels) is used for estimating r, whereas the labeled subset of test is held out only for final evaluation. The same procedure is applied to each of the four racial subgroups, creating four distinct partitions.\nConformity score and likelihood ratio estimation. The conformity score is the absolute residual (x, y) \u2192 s(x,y) = |y - f(x)|. Several baselines require an estimate of the likelihood ratio r, which we obtain by training a logistic regression model to distinguish datapoints in the unlabeled target data from those in the source data. We then user = p/ (1 \u2212 p), where x \u2192 p(x) is the predicted probability that x belongs to the target distribution."}, {"title": "5.3 RxRx1 data - WILDS", "content": "Our next experiment uses the RxRx1 dataset Sypetkowski et al. (2023) from the WILDS repository Koh et al. (2021), which is designed to evaluate model robustness under distribution shifts. The RxRx1 task involves classifying cell images based on 1,339 laboratory genetic treatments. These images, captured using fluorescent microscopy, originate from 51 independent experiments. Variations in execution and environmental conditions lead to systematic differences across experiments, affecting the distribution of input features (e.g., lighting, cell morphology) while the relationship between inputs and labels remains unchanged. This situation creates covariate shift where the marginal distribution of inputs shifts across domains, but the conditional distribution Pyx remains the same.\nFor this task, we use a ResNet50 model He et al. (2016) trained by the WILDS authors on 37 of the 51 experiments. Using data from the other 14 experiments, we construct 14 distinct evaluations. In each evaluation, one experiment is selected as the target dataset, and its data is evenly split into an unlabeled target set and a labeled test set. The labeled data from the other 13 experiments serves as the source dataset. We evaluate all baselines across these 14 settings.\nConformity score and likelihood ratio estimation. The nonconformity score S(x, y) is the negative log-likelihood (x, y) \u2192 log fx (y), where fx (y) is the probability the pretrained model assigns to the image-label pair (x, y). Several baselines require an estimate of r, which we obtain by training a logistic regression model on top of the representation layer of the pretrained model to distinguish datapoints in the unlabeled target data from those in the source data. We then user = p/(1 \u2212 p), where x \u2192 p(x) is the predicted probability that x came from the target distribution.\nExperimental details. For our proposed method, we set the function class H to be a linear head on top of the representation layer of the pretrained model. The A is tuned using the cross-validation explained in Section 5.1. Also, all experimental results are averaged over 50 random splits."}, {"title": "6 Discussion and future work", "content": "Distribution shifts are inevitable in machine learning applications. Consequently, precise uncertainty quantification under distribution shifts is essential to ensuring the safety and reliability of predictive models in practice. This challenge becomes even more pronounced when dealing with high-dimensional data, where classical statistical procedures often fail to generalize effectively. In this work, we develop a new conformal prediction method, which we call LR-QR, designed to provide valid test-time coverage under covariate shifts between calibration and test data. In contrast to existing approaches in the literature, LR-QR avoids directly estimating the likelihood ratio function between calibration and test time. Instead, it leverages certain one-dimensional projections of the likelihood ratio function, which effectively enhance LR-QR's performance in high-dimensional tasks compared to other baselines.\nWhile this paper primarily focuses on marginal test-time coverage guarantees, we acknowledge that in many practical scenarios, marginal guarantees alone may not suffice. An interesting direction for future work is to explore whether the techniques and intuitions developed here can be extended to provide stronger conditional guarantees at test time in the presence of covariate shifts. In particular, is it possible to achieve group-conditional coverage at test time (e.g., see Bastani et al. (2022); Jung et al. (2023); Gibbs et al. (2023)) without directly estimating the likelihood ratio function?\nAdditionally, several open questions remain regarding the regularization technique in LR-QR. Specifically, what alternative forms of regularization, beyond the mean squared error used in this work, could be employed to further improve test-time coverage? Which type of regularization is optimal in the sense that it yields the most precise test-time coverage? Furthermore, what is the most effective strategy for tuning the regularization strength? In particular, can these ideas be extended to design a hyperparameter-free algorithm? Finally, the data-adaptive regularization introduced in this work may have applications beyond conformal prediction, serving as a general technique to improve robustness to covariate shifts in other machine learning problems."}, {"title": "A Additional figures", "content": ""}, {"title": "B Ablation studies", "content": "Here we provide an ablation study for A, the regularization strength that appears in the LR-QR objective. In the same regression setup as Section 5.2, instead of selecting A via cross-validation, here we sweep the value of A from 0 to 2, and we plot the coverage of the LR-QR algorithm on the test data. Here, note that the split ratios between train, calibration, and test (both labeled and unlabeled data) are fixed and similar to the setup in Section 5.2. We report the averaged plots over 100 independent splits.\nFigure 4a displays the effect of different regimes of A. At one extreme, when A is close to zero, the LR-QR algorithm reduces to ordinary quantile regression. In this regime, the LR-QR algorithm behaves similarly to the algorithm from Gibbs et al. (2023), without the test covariate imputation. In other words, when we set X = 0, we try to provide coverage with respect to all the covariate shifts in the linear function class that we optimize over. As we can see in Figure 4a, this can lead to overfitting and undercoverage of the test labels. As we increase A, as a direct effect of the regularization, the coverage gap decreases. This is primarily due to the fact that larger A restricts the space of quantile regression optimization in such a way that it does not hurt the test time coverage, since the regularization is designed to shrink the optimization space towards the true likelihood-ratio. Thus, the regularization improves the generalization of the selected threshold, as the effective complexity of the function class is getting smaller. That being said, this phenomenon is only applicable if A lies within a certain range; once A grows too large, due to the data-dependent nature of our regularization, the generalization error of the regularization term itself becomes non-negligible and hinders the precise test-time coverage of the LR-QR threshold. As is highlighted in Figure 4a, our theoretical results suggest an optimal regime for A which can best exploit the geometric properties of the LR-QR threshold.\nAdditionally, Figure 4b demonstrates the effectiveness of the cross-validation technique described in Section 5.1. We sweep the value of A from 0 to 2 and plot the average norm of the gradient on the holdout sets for the cross-validation procedure explained in Section 5.1. As our theory suggests, it is now evident that the stationary conditions of LR-QR are closely tied to the valid test-time coverage of our method. For all values of A, during training, we fit the LR-QR objective to the data, ensuring that the average norm of the gradients is zero. However, when evaluating the LR-QR objective on the holdout set, the average norm of the gradients is no longer zero due to generalization errors. Selecting A correctly minimizes this generalization error, thereby providing more precise test-time coverage."}, {"title": "C Further related work", "content": "The basic concept of prediction sets dates back to foundational works such as Wilks (1941), Wald (1943), Scheffe and Tukey (1945), and Tukey (1947, 1948). The early ideas of conformal prediction were developed in Saunders et al. (1999); Vovk et al. (1999). With the rise of machine learning, conformal prediction has emerged as a widely used framework for constructing prediction sets (e.g., Papadopoulos et al., 2002; Vovk et al., 2005; Lei et al., 2018; Angelopoulos and Bates, 2021). Since then, efforts have been emerged to improve prediction set size efficiency (e.g., Sadinle et al., 2019; Stutz et al., 2022; Bai et al., 2022; Kiyani et al., 2024b; Noorani et al., 2024) and conditional coverage guarantees (e.g., Foygel Barber et al., 2021; Sesia and Romano, 2021; Gibbs et al., 2023; Romano et al., 2019; Kiyani et al., 2024a; Jung et al., 2023).\nNumerous works have addressed conformal prediction under various types of distribution shift (Tibshirani et al., 2019; Park et al., 2022b,a; Qiu et al., 2023; Si et al., 2024). For example, Tibshirani et al. (2019) and Lei and Cand\u00e8s (2021), investigated conformal prediction under covariate shift, assuming the likelihood ratio between source and target covariates is known or can be precisely estimated from data. Park et al. (2022b) developed prediction sets with a calibration-set conditional (PAC) property under covariate shift. Qiu et al. (2023); Yang et al. (2024) developed prediction sets with asymptotic coverage that are doubly robust in the sense that their coverage error is bounded by the product of the estimation errors of the quantile function of"}, {"title": "D Notation and conventions", "content": "Constants are allowed to depend on dimension only through properties of the population and sample covariance matrices of the features", "1[A": "the indicator of an event A. Recall that H denotes the linear function class H = {\u3008\u03b3", "\u03a6)": "\u03b3\u2208 Rd}. This defines a one-to-one correspondence between Rd and H. This enables us to view functions defined on Rd equivalently as defined on H. In our analysis, we will use such"}]}