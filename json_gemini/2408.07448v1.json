{"title": "LiveFC: A System for Live Fact-Checking of Audio Streams", "authors": ["Venktesh V", "Vinay Setty"], "abstract": "The advances in the digital era have led to rapid dissemination of information. This has also aggravated the spread of misinformation and disinformation. This has potentially serious consequences, such as civil unrest. While fact-checking aims to combat this, manual fact-checking is cumbersome and not scalable. While automated fact-checking approaches exist, they do not operate in real-time and do not always account for spread of misinformation through different modalities. This is particularly important as proactive fact-checking on live streams in real-time can help people be informed of false narratives and prevent catastrophic consequences that may cause civil unrest. This is particularly relevant with the rapid dissemination of information through video on social media platforms or other streams like political rallies and debates. Hence, in this work we develop a platform named LIVEFC, that can aid in fact-checking live audio streams in real-time. LIVEFC has a user-friendly interface that displays the claims detected along with their veracity and evidence for live streams with associated speakers for claims from respective segments. The app can be accessed at http://livefc.factiverse.ai and a screen recording of the demo can be found at https://bit.ly/3WVAolw.", "sections": [{"title": "1 Introduction", "content": "The rapid proliferation of misinformation and disinformation in the digital era has lasting impacts on society, politics, and the shaping of public opinion. While several efforts have been undertaken to combat misinformation with the support of manual fact-checkers in platforms such as Politifact, it is not scalable at the current rate of growth in misinformation. Hence, automated fact-checking approaches have been proposed (Guo et al., 2022; Opdahl et al., 2023) which has made tremendous advances in recent times with advent of deep learning based approaches. Majority of the existing automated fact-checking approaches are primarily focused on textual modality (Nakov et al., 2021; Guo et al., 2022; Hassan et al., 2015). However, real-world misinformation and disinformation can be spread through multiple possible modalities, such as audio, video, and images (Yao et al., 2023; Akhtar et al., 2023). It has also been observed that multi-modal content has higher engagement and spreads faster than text only content (Li and Xie, 2020). Hence, it is crucial to fact-check multi-modal content.\nMisinformation spread through multi-modal content, such as political debates, interviews, and election campaigns, is time-critical due to its potential to sway public opinion and its perceived reliability (Newman et al., 2012). Manual fact-checking is cumbersome and time-consuming, and existing automated tools focus on post-hoc verification, which is ineffective against rapidly spreading misinformation. To address this, we developed LIVEFC, a tool that transcribes, diarizes speakers, and fact-checks spoken content in live audio streams in real-time (within seconds), targeting misinformation at its source. While focused on live events like election debates and campaign rallies, LIVEFC also works with long-form offline content such as parliament discussions, interviews, and podcasts. Fact-checkers and news reporters find LIVEFC particularly useful for detecting and verifying claims in real-time. This was validated in a pilot study with Danish fact-checkers Tjekdet\u00b9 during the European Parliament election in June 2024, where the tool helped catch important claims that would otherwise have been missed.\u00b2 Additionally, we conducted a case study of the first US presidential debate of 2024, comparing manual fact-checks from the Politifact with those done by LIVEFC.\nRecent advances in automatic speech recognition (ASR) models, like Whisper by OpenAI (Radford et al., 2023), have significantly improved audio"}, {"title": "2 System Design", "content": "An overview of our live fact-checking pipeline LIVEFC is shown in Figure 1. The live audio stream is provided as input to a speaker diarization module and transcription module in parallel. This is followed by a mapping phase where the transcribed segments are mapped to respective speakers based on timestamps and other meta-data. The resulting transcribed segments are then sent to a claim identification module followed by claim decomposition, evidence retrieval and claim verification stages. The pipeline is hosted using a Python FastAPI backend. The frontend is implemented using the Streamlit framework.\u00b3 Then the claims are verified using evidence retrieval and claim verification components which employ state-of-the-art fine-tuned models. There are several ML models used in the backend dedicated for (a) check-worthy claim detection, (b) topic categorization, (c) evidence ranking, (d) transcription, (e) speaker diarization and (g) veracity prediction. In addition, we use a self-hosted open large language model (Mistral-7b) with chain of though (CoT) prompting for claim normalization and claim decomposition. These models are also quantized yet effective, enabling real-time processing with low computational requirements."}, {"title": "2.1 Transcription of Live Audio Stream", "content": "We adapt the Whisper Live\u2074 implementation for our fact-checking pipeline. We use the whisper-large-v3 model, a sequence-to-sequence model pre-trained on a large amount of weakly supervised (audio, transcript) pairs, which directly produces raw transcripts. We process the audio stream in segments to support HLS (HTTP Live Streaming), which is then buffered and transmitted to the transcription client via the FFmpeg encoder.\u2075 Unlike traditional systems, Whisper Live employs Voice Activity Detection (VAD) to send data to Whisper only when speech is detected, making the process more efficient and producing high-quality transcripts."}, {"title": "2.2 Online Diarization Module", "content": "For attribution and offline analysis, linking claims to the corresponding speaker is essential. Our diarization module performs real-time speaker identification, known as online speaker diarization with limited context. LIVEFC employs an overlap-aware online diarization approach (Bredin and Laurent, 2021), involving speaker segmentation and clustering. We adapt the diart module (Coria et al., 2021) for our use, utilizing websockets to stream audio content.\nThe audio stream is sent via websocket to the diarization server, where it undergoes speaker segmentation using a neural network. Every 500ms, the server processes a 5-second rolling audio buffer and outputs speaker active probabilities $A = s_{1...sn}$, where n is the number of frames. Speakers with an active probability above a tunable threshold $T_{active}$ are identified, while inactive speakers are discarded. This approach effectively handles overlapping speakers, making it ideal for live fact-checking of debates. We set $T_{active} = 0.65$ to reduce false positives.\nThe segmentation model's permutation invariance means a speaker may not be consistently assigned the same speaker ID over time. To address this, we use incremental clustering to track speakers throughout the audio stream. Initially, speaker embeddings are created after segmentation for the first buffer, forming a centroid matrix C. As the rolling buffer updates, local speaker embeddings ($se_{1}..se_{r}$) are compared to the centroids to assign them using an optimal mapping ($m^{*}$):\n$m^{*} = arg min_{M} \\sum_{i=1}^{r} d(m(i), se_{i})$\nWhere M is the set of mapping functions between local speakers and centroids, with the constraint that two local speakers cannot be assigned to the same centroid. If the distance between a local speaker embedding and all centroids exceeds a threshold $A_{new}$, a new centroid is created. We set $A_{new}$ = 0.75 to balance sensitivity, avoiding the misclassification of slight tone changes as new speakers, while ensuring new speakers are accurately identified.\nSpeaker IDs are mapped to transcript segments using timestamps from the diarization and transcription components, which are run in parallel for efficiency. We use pyannote/embedding computing embeddings and the pyannote/segmentation-3.0 model for segmentation."}, {"title": "2.3 Check-Worthy Claim Detection Module", "content": "The function of this component is to identify claims from transcribed segments that warrant verification."}, {"title": "2.4 Claim Decomposition and Evidence Retrieval", "content": "The main goal is this component is to retrieve high quality evidence for verifying the check-worthy claims from the previous step. Fact-checking is not a linear process and involves multi-step reasoning, where fact-checkers synthesize diverse queries and search the web and other knowledge sources to gather multiple perspectives and evidence to verify a claim. To emulate the process of fact-checkers, we employ a claim decomposition module where we prompt a LLM (Mistral-7b) with few-shot examples to decompose a claim. The prompt is as shown in Figure 3.\nFollowing the decomposition step, we retrieve evidence from diverse sources such as Google, Bing, Wikipedia, You.com, Semantic Scholar (contains 212M scholarly articles). Since some claims might be duplicates or similar to existing fact-checked claims, we also search our ElasticSearch index, which houses Factiverse's fact-checking collection named FactiSearch, which comprises 280K fact-checks updated in real-time to retrieve related evidence. We filter out evidence from fact-checking sites and deduplicate evidence using meta-data like url, titles and approximate matching of content. We then employ a multilingual cross-encoder model (Reimers and Gurevych, 2019) (nreimers/mmarco-mMiniLMv2-L12-H384-v1) from huggingface to rank the retrieved evidences."}, {"title": "2.5 Claim Verification", "content": "Using the ranked evidences, we perform claim verification by formulating the task as a Natural language Inference (NLI) problem. The NLI task involves categorizing whether a claim is supported, refuted by a given piece of evidence or evidence is"}, {"title": "3 Performance Evaluation", "content": "In this section, we perform offline evaluation of critical components of LIVEFC using our benchmark for claim detection and verification. We also perform qualitative evaluation of a sample of fact-checks from 2024 presidential debate."}, {"title": "3.1 Offline Evaluation of Claim Detection and Verification Components", "content": "For offline evaluation of individual components of LIVEFC pipeline, we employ the dataset collected from production environment of Factiverse. The statistics of the dataset are shown in Table 1. The prompt employed for the LLM baselines can be found in the Appendix A. We observe that our fine-tuned XLM-Roberta model outperforms LLM based approaches for tasks of claim detection and verification. We primarily observe that in claim verification, LLMs underperform when compared to smaller fine-tuned models due to their inability to reason and extract required information from evidence and due to hallucination. Hence, we employ our fine-tuned model as part of the pipeline in the LIVEFC tool."}, {"title": "3.2 End to End Evaluation on Live Stream", "content": "We also evaluate LIVEFC on the first presidential debate of 2024. A screenshot of the tool is shown in Figure 4.\nDebate Statistics: We report the statistics obtained from live fact-checking of the debate through our tool LIVEFC. The number of supported and disputed claims made by each speaker is shown in Table 3 and topicwise distribution of claims are shown in Figure 5. We observe that topic related to War and Defense was the most discussed during the debate. The plot shows the distribution of claims across 7 key topics, and the rest of claims that do not fall into any of these topics are categorized as \"Other\" and are not shown in the graph. We also observe that there are a significant number of disputed claims made by the speakers, which highlights the significance of live fact-checking. We also display the evidence and summarize the justification for the veracity label, rendering the process more transparent to the end user.\nComparison based evaluation of claims identified and veracity prediction to Politifact: We compare the claims identified and corresponding predicted labels from manual fact-checker Politifact to those identified and verified by our tool LIVEFC for the 2024 presidential debate. We observed that we were able to identify all the 30 claims identified by Politifact. We were further able to identify more claims not covered by Politifact which highlights the advantages of automated fact-checking. However, we also acknowledge that some of the claims we identify are false positives and may not be significant enough, which is removed by us in post-processing phase. When comparing the veracity labels with Politifact for the 30 claims, we observe a macro averaged Precision, Recall and F1 scores of 82.59, 85.78 and 83.92 respectively and weighted F1 of 87.26. This highlights that LIVEFC can assist fact-checkers in verifying live-streams at scale.\nQualitative evaluation of evidence utility and topic assignments: We perform a qualitative evaluation of fact-checks performed on 2024 US presidential debate live-stream by sampling 20 claims with retrieved evidence, topic assigned and veracity predictions using our tool LIVEFC. We requested three annotators with background in automated fact-checking to rate the samples on three factors such as evidence usefulness, evidence completeness and topic relevance using the Likert scale (1-5). The average ratings across annotators with inter-annotator agreement are shown in Table 4."}, {"title": "4 User Interface", "content": "A screenshot of LIVEFC is shown in Figure 4. The left pane streams the video/audio, with the lower pane showing the transcribed segments in real-time. On the right pane at the top, we show a summary statistics of time segment of each active speaker along with number of claims made by each person as detected by our check-worthy claim detection module along with the veracity of the claims. We also display a plot demonstrating distribution of claims across different topics. on the lower right panel we display a running list of detected claims along with retrieved evidence and predicted verdict. This ensures the fact-checking process is transparent, as the users can trace the verdict to relevant evidence."}, {"title": "5 Related Work", "content": "Automated fact-checking approaches have made significant strides in identifying misinformation and assisting fact-checkers and journalists to obviate the time-consuming aspects of manual fact-checking (Nakov et al., 2021; Opdahl et al., 2023). The existing automated fact-checking approaches primarily focus on text modality (Nakov et al., 2021; Guo et al., 2022). However, in the real-world misinformation proliferates through multiple modalities such as audio, images, or video (Akhtar et al., 2023; Yao et al., 2023; Singhal et al., 2019). It has also been observed that multi-modal misinformation has a propensity to spread faster, which can have disastrous consequences such as civil unrest or health hazards in context of medical misinformation (Li and Xie, 2020). For instance, recent studies on misinformation spread through instant audio messages (Pasquetto et al., 2022; El-Masri and Woolley, 2022; Maros et al., 2021) on Whatsapp observed that audio messages are considered to be more reliable. Hence, fact-checking multimodal information is of crucial importance. While the majority of the existing fact-checking systems primarily focus on text (Schlichtkrull et al., 2023; Hassan et al., 2015; Guo et al., 2022), more recently focus on multi-modal fact-checking has increased, leading to development of new benchmarks and approaches (Singhal et al., 2020, 2019; Yao et al., 2023; Akhtar et al., 2023; Rangapur et al., 2024).\nThere are fact-checking demos in the literature (Setty, 2024; Botnevik et al., 2020; Popat et al., 2018; Chern et al., 2023), but none of them are designed to fact-checking live content. In this work, we build a tool for live fact-checking of political debates, as political claims play a major role in democracy and sometimes may sway public opinion or cause civil unrest. This has been evidenced by prior study that has demonstrated that fact-checking can help the public make an informed evaluation of political events(Wintersieck, 2017). Our tool, considers multiple modalities performing fact-checks in real-time, unlike existing works on political debates which primarily focus on post hoc fact-checking and are limited to textual modality relying on clean transcripts (Hassan et al., 2015; Gencheva et al., 2017; Shaar et al., 2022)."}, {"title": "6 Conclusion", "content": "This paper presents the LIVEFC system, an end to end approach for real-time fact-checking which employs efficient, effective and smaller models. We applied it to the live stream of 2024 political debate and observed that it was able to detect and verify facts in real-time. We conducted offline evaluation of different core components of the system using fact-checking benchmarks. We also conducted manual and qualitative evaluation of fact-checks generated from debate and observed that the system was able to detect all claims detected by manual fact-checkers and also retrieve useful evidence for accurate verification of claims. In the future, we plan to further extend LIVEFC to handle multimodal evidence sources. While our current pipeline provides support for multiple languages, we plan to further extend the number of languages covered."}, {"title": "Limitations", "content": "While our tool LIVEFC works well on live-streams, our tool requires the m3u8 format and audios in other formats need to be converted to m3u8 format. Identifying and converting from different formats requires engineering of adaptors, which we reserve for future work. However, currently, other formats can be converted to m3u8 format using existing tools. We plan to build adaptors and provide native support in LIVEFC in the future. Additionally, our claim verification component currently supports categorizing a claim as \u201csupported\" or \u201crefuted\u201d. In future, we also plan to support other fine-grained categories such as conflicting where a claim is partly true/false."}, {"title": "Ethics and Impact Statement", "content": "Our live fact-checking tool LIVEFC aims to assist fact-checkers and journalists to combat misinformation at the source. Since we employ deep learning based methods there is possibility of errors in claim veracity prediction. Hence, we try to render the process as transparent as possible by providing evidence sources, snippets and justification summary used for verification of a claim. This helps the users to look at the sources, evidence snippets and make their own judgement of the veracity. We also do not claim that LIVEFC would replace manual fact-checkers but would reduce their load and augment their abilities, making fact-checking at scale possible."}, {"title": "A.1 Checkworthy Claim Detection", "content": "The check worthy claim detection prompt used for LLM baselines in Table 2 are shown in Figure 6. For fair evaluation, we set temperature to 0.2 to reduce hallucination for all the LLMs."}, {"title": "A.2 Claim verification", "content": "The claim verification prompts used for LLM baselines in Table 2 are shown in Figure 7. For fair evaluation, we set temperature to 0.2 to reduce hallucination for all the LLMs."}, {"title": "A.3 Topic Assignment Prompt", "content": "To assign topics to claims, we use the Mistral (7b) model by providing examples in the prompt. The prompt employed is as shown in Figure 8"}]}