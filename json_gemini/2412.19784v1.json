{"title": "Can AI Help with Your Personal Finances?", "authors": ["Oudom Hean", "Utsha Saha", "Binita Saha"], "abstract": "In recent years, Large Language Models (LLMs) have emerged as a transformative\ndevelopment in artificial intelligence (AI), drawing significant attention from\nindustry and academia. Trained on vast datasets, these sophisticated AI systems\nexhibit impressive natural language processing and content generation capabilities.\nThis paper explores the potential of LLMs to address key challenges in personal\nfinance, focusing on the United States. We evaluate several leading LLMs,\nincluding OpenAI's ChatGPT, Google's Gemini, Anthropic's Claude, and Meta's\nLlama, to assess their effectiveness in providing accurate financial advice on topics\nsuch as mortgages, taxes, loans, and investments. Our findings show that while\nthese models achieve an average accuracy rate of approximately 70%, they also\ndisplay notable limitations in certain areas. Specifically, LLMs struggle to provide\naccurate responses for complex financial queries, with performance varying\nsignificantly across different topics. Despite these limitations, the analysis reveals\nnotable improvements in newer versions of these models, highlighting their\ngrowing utility for individuals and financial advisors. As these Al systems continue\nto evolve, their potential for advancing AI-driven applications in personal finance\nbecomes increasingly promising.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs), a significant development in artificial intelligence (AI),\nhave emerged as a transformative technology, attracting substantial interest from both\nindustry and academia. These advanced AI systems, trained on extensive datasets, have\nexhibited impressive capabilities across diverse domains, such as natural language\nprocessing, question answering, and content generation (Brown et al., 2020; Devlin et al.,\n2018). As LLMs continue to evolve and advance, their potential applications, particularly\nin personal finance, are becoming increasingly relevant and practical, extending well\nbeyond academic research.\nIn this paper, we thoroughly investigate the potential of AI, specifically LLMs, in\naddressing a spectrum of personal finance issues. We systematically evaluate the\nresponses of LLMs to a range of personal finance topics\u2014such as mortgages, taxes, loans,\nand investments\u2014within the United States context. We examine several prominent\nLLMs, including OpenAI's ChatGPT, Google's Gemini, Anthropic's Claude, and\nMeta/Facebook's Llama, to discern their comparative efficacy in delivering accurate and\nconsistent financial advice.\nOur findings indicate that AI models, on average, correctly answer approximately\n70 percent of posed questions. Notably, Al performance has shown consistent\nimprovement over time. Older versions of these models answered only about 50-60\npercent of questions correctly, while the latest models achieve accuracy rates up to 80\npercent. ChatGPT and Claude emerged as the top performers among the various models\ntested, with Llama being the least accurate. Specifically, the latest versions of ChatGPT,\nsuch as ChatGPT 40, and Claude 3.5 Sonnet, achieved accuracy rates exceeding 74\npercent, whereas Llama3 70b maintained a lower accuracy rate of about 65 percent.\nFurthermore, our results demonstrate that these LLMs provide consistent answers\nwhen prompted with the same questions multiple times, alleviating concerns about\ninconsistent responses. These advancements in Al model performance have significant\nimplications for future applications, particularly in the fields of natural language\nprocessing and question-answering systems within the finance industry and education\nsector."}, {"title": null, "content": "In this study, we use the terms AI and LLMs interchangeably. Technically, LLMs are a subset of AI, focusing on processing and\ngenerating human language."}, {"title": null, "content": "Personal finance is a critical aspect of everyone's life, yet it is often overlooked\ndue to its complexity and the lack of accessible, personalized guidance (Lusardi &\nMitchell, 2014). Many people struggle with budgeting, investing, taxes, and financial\nplanning, leading to suboptimal financial decisions and outcomes (Jappelli & Padula,\n2013). Traditionally, individuals have turned to financial advisors for help, but this can\nbe expensive and only within reach for a few. Financial advisors usually charge fees, with\nrobo-advisors at the more affordable end of this range and traditional in-person advisors\nat the higher end (Fisch, Labour\u00e9, & Turner, 2019). These fees can mount up swiftly,\nmaking professional financial guidance a costly and out-of-reach service for many.\nOur study reveals that while Al currently faces limitations in assisting with\npersonal finance, particularly with complex questions and variability in performance\nacross topics, its potential for future applications is promising as technology advances.\nAs AI models become more sophisticated, they could play an essential role in helping\nindividuals manage their finances more effectively. One could use AI to provide tailored\nadvice on various personal finance topics, such as budgeting, investments, loans, and tax\nplanning. Moreover, AI has the potential to become an invaluable tool for financial\nadvisors by improving their capability to analyze complex economic data, generate\ninsights, and offer personalized recommendations to clients. The continued advancement\nof Al in this domain could lead to greater financial literacy and improved financial\ndecision-making for both individuals and professionals.\nOur paper contributes to the growing body of literature analyzing the application\nof Al in finance and economics. While most studies focus on a limited set of AI models,\nthey offer valuable insights into specific capabilities and limitations. For instance,\nNiszczota and Abbas (2023) examine GPT-3.5 and GPT-4 models, evaluating their\nfinancial literacy to determine their potential as financial advisors for the public. Using a\nstandardized financial literacy test on core topics like compound interest, tax-advantaged\nassets, and risk diversification, they find that GPT-4 achieves a near-perfect score of 99%,\na marked improvement over GPT-3.5's 65-66%. This advancement in GPT-4 indicates\nsignificant progress in understanding fundamental financial concepts and its potential\naccuracy in financial advisement.\nFurther extending the capabilities of LLMs, Kim et al. (2024) demonstrate that\nGPT-4 can outperform human analysts in predicting company earnings from financial\nstatements, particularly in challenging scenarios. This study underscores the model's"}, {"title": null, "content": "capacity for analyzing complex financial information and positioning LLMs as\ncompetitive with, and in some cases superior to, human expertise in financial prediction\ntasks. Similarly, Dowling and Lucey (2023) and Korinek (2023) explore the broader\npotential of ChatGPT in financial and economic research, emphasizing LLMs' expanding\nutility in these domains.\nDespite these advancements, other studies caution against over-reliance on LLMs\nfor financial advisory roles. Lakkaraju et al. (2023) investigate the reliability and fairness\nof LLMs in financial advisement by comparing ChatGPT and Bard with SafeFinance, a\nrule-based chatbot. While LLMs provide plausible responses, they often make substantial\nerrors in retrieving financial information and show inconsistent accuracy across user\ndemographics. In contrast, the more limited SafeFinance offers safer, traceable advice,\nsuggesting that current LLMs may fall short in consistently reliable advisement,\nespecially in high-stakes financial contexts.\nOther research has focused on Al's role in dynamic financial markets. Yu et al.\n(2023) introduce FINMEM, an LLM-based autonomous trading agent designed to\nenhance decision-making under volatile conditions. FINMEM integrates a profiling\nmodule that adjusts risk preferences, a layered memory system that processes time-\nsensitive financial data, and a decision-making module that synthesizes insights for\ntrading actions. Their findings show that FINMEM can adapt to fluctuating market\nenvironments, demonstrating resilience and superior trading performance in complex\nscenarios. Similarly, Ding et al. (2023) develop a Local-Global model for predicting\noutcomes in the Chinese A-share market by combining LLM-processed financial news\nwith stock-specific features. This integration allows for more accurate market predictions,\nhighlighting the potential of combining LLMs with market data for enhanced financial\nforecasting.\nOur study also draws on broader research that links technology, education, and\neconomic outcomes (e.g., Goldin & Katz, 2009; Hean et al., 2023; Hean & Partridge,\n2022). These studies underscore the transformative role of technology in shaping\neconomic behavior and decision-making, offering a comprehensive backdrop for our\nwork within the broader narrative of Al's impact on economies.\nThe rest of the paper is organized as follows: Section 2 discusses the data sets\nused in this study, and Section 3 outlines the methodology. Section 4 presents the"}, {"title": null, "content": "findings, followed by a sensitivity analysis in Section 5. Finally, Section 6 presents the\nconclusion, discussing ethical considerations and offering suggestions for future research."}, {"title": "Data", "content": "In this study, we utilize two distinct datasets: MoneyCounts and the National Financial\nEducators Council's (NFEC) comprehensive suite of financial literacy tests. These\ndatasets provide a broad range of topics and varying levels of expertise in personal finance\nunderstanding.\nMoneyCounts is a specialized financial literacy series developed by Penn State\nUniversity's Sokolov-Miller Family Financial and Life Skills Center. It stands out for\nits extensive collection of practice quizzes designed to assess and improve financial\nliteracy across diverse subjects. Key areas covered include the principles of financial\nliteracy, financial planning after graduation, banking basics, budgeting essentials, car\nshopping tips, understanding credit cards, debt management strategies, environmental\nstewardship and finance, FICO credit scores, organizing financial clutter, financial\nknowledge specific to women, financial literacy for high school students, identity theft\nprotection, insurance planning, money and nutrition, money and relationships, mortgage\nfundamentals, retirement planning, salary negotiation, saving and investing, smart\nfinancial goals, managing student loans, financial planning for study abroad, U.S. tax\ninformation for international and U.S. individuals, and understanding the time value of\nmoney.\nThe NFEC dataset offers a detailed assessment of financial literacy through tests\nat beginner, intermediate, and advanced levels. These tests cover various topics,\nincluding financial psychology tests; savings, expenses, and budgeting tests; account\nmanagement tests; loans and debt tests; credit profile tests; income tests; economic and\ngovernment influences tests; risk management and insurance tests; investing and personal\nfinancial planning tests; and education and skill development tests."}, {"title": null, "content": "MoneyCounts' data were retrieved on July 18, 2024, from https://financialliteracy.psu.edu/explore-a-financial-topic.\nNFEC's data were retrieved on July 10, 2024 https://www.financialeducatorscouncil.org/financial-literacy-test/."}, {"title": "Methodology", "content": "We assess the financial literacy performance of LLMs using the specified test sets and\nconduct an accuracy assessment to evaluate their effectiveness in delivering accurate and\nuseful financial advice. Specifically, we employ zero-shot prompting, in which the LLMs\nare tested without prior exposure to specific examples. Our evaluation considers various\naspects of personal finance, such as budgeting, investments, loans, and tax planning, to\ncomprehensively analyze each model's capabilities. This evaluation includes a diverse\nrange of LLMs from several leading providers. Specifically, we test the following models:\nOpenAI (i.e., ChatGPT 3.5, ChatGPT 4, and ChatGPT 4o); Google (i.e., Gemini and\nGemini Advanced); Antropic (i.e., Claude 3 Haiku, Claude 3.5 Sonnet, and Claude 3\nOpus); and Meta/Facebook (i.e., Llama 3 8B and Llama 3 70B). Table 1 shows the\ndifferent Al models tested in the paper.\nWe initially assess the financial literacy of the models by asking each question\nonce and evaluating the generated answer. However, it is well-known that generative AI\ncan produce inconsistent answers even when asked the same questions multiple times. To\naddress this, we conduct a sensitivity analysis by repeating these tests ten times. This\napproach allows us to evaluate the consistency and reliability of the AI models' responses\nto financial literacy questions more thoroughly."}, {"title": null, "content": "Llama models in this study are accessible through Groq - https://groq.com/."}, {"title": "Results", "content": "Table 2 shows the overall performance of all Al models in addressing financial questions.\nOn average, the models correctly answer approximately 68 percent of the questions,\nhighlighting existing limitations in Al's personal financial literacy capabilities. However,\nthe high standard deviation (i.e., 46 percent) suggests significant variability in\nperformance; while some models perform well, others struggle with the same questions.\nThese findings underscore that there is still room for improvement in Al's role in personal\nfinance."}, {"title": "Overall Performance of LLMs", "content": "Table 2 shows the overall performance of all Al models in addressing financial questions.\nOn average, the models correctly answer approximately 68 percent of the questions,\nhighlighting existing limitations in Al's personal financial literacy capabilities. However,\nthe high standard deviation (i.e., 46 percent) suggests significant variability in\nperformance; while some models perform well, others struggle with the same questions.\nThese findings underscore that there is still room for improvement in Al's role in personal\nfinance."}, {"title": "Performance of LLMs by Topic", "content": "Our data enables us to analyze the performance of different models across various topics.\nTable 3 presents the results of this analysis. We focus on a few topics that have attracted\npublic attention. By examining these specific areas, we can highlight how different\nmodels perform and identify any notable trends or insights. This targeted discussion helps\nillustrate each model's strengths and weaknesses in real-world applications that matter to\nthe public."}, {"title": null, "content": "First, understanding credit card concepts is crucial for individuals to make\ninformed decisions about their financial well-being and to avoid potential pitfalls\nassociated with credit card usage (Akinwande et al., 2024; Limbu & Sato, 2019). The\nperformance of large language models (LLMs) on credit card-related questions varies\nsignificantly. ChatGPT 4 is one of the top performers, correctly answering 80 percent of\nthe questions. In contrast, Gemini, Claude 3 Haiku, and Llama 3 8B struggle, with only\n40 percent of their answers being correct. The results suggest that while some models\nhave a solid grasp of credit card concepts, others still face significant challenges.\nSecond, women have made remarkable strides, becoming influential consumers\nand gaining social and professional positions. However, they still face numerous demands\non their time and money, juggling home, work, and social priorities. Many women may\nface challenges in addressing financial goals throughout their lives and into retirement\n(Malhotra & Witt, 2010). Therefore, it is crucial to provide tailored financial advice to\nwomen. Most AI models score in the 80-90 percent range, demonstrating their ability to\nprovide relevant financial advice while navigating gender-specific considerations. This\nstrong performance indicates that the models have been trained on a diverse dataset that\nincludes information specific to women's financial needs. This is crucial given women's\nunique challenges in managing their finances and planning for the future.\nThird, money is a deeply personal and emotional topic, often more stressful to\ndiscuss than other aspects of life. In relationships, financial decisions can significantly\nimpact various areas, from joint accounts to retirement planning (Olson & Rick, 2022).\nAl models perform relatively well in addressing questions on \u2018money and relationships,'\nwith most large language models achieving scores in the 70\u2013100 percent range.\nFourth, buying a house is arguably one of the most significant financial decisions,\nespecially for Generation Z (Abdullah et al., 2024). This decision involves numerous\nconsiderations, including affordability, location, and long-term financial commitments.\nLLMs perform moderately well when navigating the mortgage process, with accuracy\nrates ranging from 60 to 90 percent. AI could provide valuable guidance on mortgage\noptions, interest rates, and repayment plans, helping prospective homeowners make\ninformed decisions.\nFifth, student loans, including federal and private options, are designed to help\nstudents cover post-secondary education costs (Gillen & Gutter, 2015). Navigating the\ncomplexities of borrowing and repayment strategies can be challenging for many"}, {"title": null, "content": "students. Al models offer valuable assistance by helping students make informed\ndecisions about borrowing strategies and repayment plans. Performance on student loan-\nrelated questions is generally good, with most models scoring in the 70-80 percent range.\nTherefore, LLMs could offer critical insights into interest rates, repayment options, and\nloan consolidation, aiding students in managing their financial responsibilities effectively\nand planning for a financially secure future.\nSixth, taxes are a critical topic that everyone must understand to fulfill their legal\nand fiscal obligations, avoid penalties, and save money. Many individuals in the U.S. and\ninternationally struggle with filing tax returns and paying taxes. Most AI models perform\nreasonably well on topics related to taxes for both domestic and international individuals,\nwith accuracy rates ranging from 70 to 90 percent. These results indicate that AI has a\nfair capability to handle the intricacies of tax law, providing valuable support in managing\ntax-related responsibilities.\nOverall, the performance of LLMs across various financial topics showcases their\npotential as valuable tools for enhancing financial literacy and decision-making.\nAlthough some models still face challenges in some areas, the overall high accuracy rates\nindicate significant progress and reliability in handling complex financial topics. These\nfindings highlight the importance of continued advancements in Al training\nmethodologies to ensure diverse and inclusive datasets, ultimately making LLMs more\neffective in providing accurate, personalized financial guidance to a broad audience."}, {"title": "Performance of LLMs by Level of Complexity", "content": "The NFEC data categorizes each question into three difficulty levels: beginner,\nintermediate, and advanced. We use this dataset to evaluate the performance of various\nLLMs. By examining the results of this analysis, we can gain insights into the strengths\nand weaknesses of each model in handling questions of varying complexity. This detailed\nevaluation helps us understand which models are more effective in providing accurate\nresponses based on the difficulty level of the questions."}, {"title": "Sensitivity Analysis", "content": "Generative AlI may produce varying answers when the same questions are asked\nrepeatedly. We perform a sensitivity analysis by conducting the tests ten times to mitigate\nthis issue. This strategy allows us to assess the consistency and reliability of the AI\nmodels' responses to financial literacy questions more thoroughly.\nTable 5 presents the findings from the sensitivity analysis, while Figure 2\ncompares the original results and those obtained from the sensitivity analysis.\nSurprisingly, the results demonstrate a high level of robustness, indicating that the AI\nmodels' performance remains consistent and reliable despite repeated testing. This"}, {"title": "Conclusions", "content": "In recent years, large language models have emerged as a transformative technology in\nartificial intelligence, garnering significant attention from both industry and academia.\nAs LLMs evolve, their potential applications, particularly in personal finance, become\nincreasingly relevant and practical, extending well beyond academic research."}, {"title": null, "content": "We investigate the potential of AI, specifically LLMs, in addressing a spectrum\nof personal finance issues. By examining a diverse array of personal finance topics such\nas mortgages, taxes, loans, and investments\u2014we systematically evaluate the responses\nprovided by various Al models. We analyze several prominent LLMs, including\nOpenAI's ChatGPT, Google's Gemini, Anthropic's Claude, and Meta/Facebook's Llama,\nto assess their comparative efficacy in delivering accurate and actionable financial advice.\nOur findings indicate that AI models still have limitations in answering personal\nfinance questions but have shown substantial improvement. Interestingly, all models\nprovide strongly consistent results when the same questions are asked multiple times. As\nAl models become more sophisticated, they could play an essential role in helping\nindividuals manage their finances more effectively.\nIndividuals could use AI to offer tailored advice on various personal finance\ntopics. Additionally, AI has the potential to become an invaluable tool for financial\nadvisors by enhancing their ability to analyze complex economic data, generate insights,\nand offer personalized recommendations to clients. The continued advancement of AI in\nthis domain could lead to greater financial literacy and improved financial decision-\nmaking for both individuals and professionals.\nAs LLMs become increasingly influential in personal finance, addressing key\nethical concerns such as data privacy, algorithmic bias, and potential misuse is crucial.\nThese models often require substantial personal information, underscoring the need for\nstrong data protection measures and regulatory compliance. Algorithmic bias, often\nstemming from historical training data, can result in skewed financial advice, highlighting\nthe importance of regular audits to ensure fairness. Additionally, preventing misuse\u2014\nsuch as the spread of misleading or high-risk financial guidance\u2014is vital to protect\nconsumers.\nRapid advancements in LLM capabilities reveal several promising areas for future\nresearch. Improving model interpretability is a key focus, as understanding the rationale\nbehind AI-generated advice is essential for building user trust. Integrating real-time data\nis another priority. Because LLMs primarily rely on historical datasets, their advice can\nbe outdated. Research incorporating live market trends and financial news can enhance\nthe accuracy and timeliness of recommendations. Furthermore, exploring LLMs in\nbehavioral finance can yield tailored insights, helping to address psychological biases like"}, {"title": null, "content": "overconfidence or loss aversion. Enhancing these capabilities will enable more\npersonalized, effective AI-driven financial advisory services."}]}