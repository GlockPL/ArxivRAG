{"title": "Chain of Stance: Stance Detection with Large Language Models", "authors": ["Junxia Ma", "Changjiang Wang", "Hanwen Xing", "Dongming Zhao", "Yazhou Zhang"], "abstract": "Stance detection is an active task in natural language processing (NLP) that aims to identify the author's stance towards a particular target within a text. Given the remarkable language understanding capabilities and encyclopedic prior knowledge of large language models (LLMs), how to explore the potential of LLMs in stance detection has received significant attention. Unlike existing LLM-based approaches that focus solely on fine-tuning with large-scale datasets, we propose a new prompting method, called Chain of Stance (CoS). In particular, it positions LLMs as expert stance detectors by decomposing the stance detection process into a series of intermediate, stance-related assertions that culminate in the final judgment. This approach leads to significant improvements in classification performance. We conducted extensive experiments using four SOTA LLMs on the SemEval 2016 dataset, covering the zero-shot and few-shot learning setups. The results indicate that the proposed method achieves state-of-the-art results with an F1 score of 79.84 in the few-shot setting.", "sections": [{"title": "Introduction", "content": "Recently, the rapid development of social media platforms such as X, WeChat, and TikTok has led to an explosive growth in user-generated content. The increasing availability of massive amounts of textual data has created a need to automatically analyze the opinions, emotions, and stances expressed. This is because understanding the stance tendencies of the public offers significant benefits for political analysis, public opinion polling, and rumor detection. Hence, stance detection has been an active topic in NLP. Stance detection aims to identify the author's attitude or stance towards a specific target (such as an entity, concept, or event)(?), typically classified into categories such as support, opposition, or neutrality."}, {"title": "Related Work", "content": null}, {"title": "Stance Detection", "content": "Stance detection has long been an active research area in the field of Natural Language Processing (NLP). Early studies employed various machine learning and deep learning techniques to tackle this task(Hardalov et al., 2021).In recent years, the advent of large language models (LLMs) has marked a significant advancement in artificial intelligence, pushing the state-of-the-art performance on many stance detection datasets(?). Models like GPT-3.5, which have demonstrated powerful capabilities in numerous areas of NLP, have garnered considerable attention. Trained on extensive datasets, these models have significantly improved their ability to understand and mimic human language patterns(Wei et al., 2022). Researchers are actively utilizing the potenial of LLMs for stance detection. For instance, Mets et al. (Mets et al., 2024) examined the applicability of LLMs in automated stance detection within challenging contexts. Wang et al.(Wang et al., 2024) leveraged the generation capability of LLMs to simulate specific experts (i.e.,multi-agents) to detect the stance. Ilker et al.(\u0130lker G\u00fcl et al., 2024) argue that large language models (LLMs) possess exceptional capabilities in stance detection and call for more extensive research in this area."}, {"title": "Prompt Tuning", "content": "Prompt learning transforms downstream learning tasks into text generation tasks by incorporating prompt information into the text input (Yao et al., 2024). Prompt tuning has proven to effectively enhance the capabilities of large language models (LLMs) in many NLP tasks, such as sentiment analysis and text classification, and is therefore widely adopted. Hardalov et al. (Hardalov et al., 2022) designed a prompt-based framework for cross-language stance detection. Ding et al. (Ding et al., 2024) utilizes a chain-of-thought approach to elicit knowledge and fuses knowledge through a multi-prompt learning network. Zhu et al. (Zhu et al., 2024) introduced soft knowledge during cue fine-tuning, a strategy that effectively enhances the model's understanding of the context of short texts and significantly improves text categorization. Hu et al. (Huang et al., 2023) expands the verbalizer in prompt-tuning using external semantic knowledge and infusing background knowledge. Wei et al. (Wei et al., 2022) made a formal definition of CoT prompting in LLMs and proved its effectiveness by presenting empirical evaluations on arithmetic reasoning benchmarks. This work pioneered the use of CoT prompting in NLP.\nHowever, most existing stance detection methods do not explicitly model the reasoning process, making the model's predictions difficult to interpret. Additionally, these methods typically treat stance detection as a binary or multi-class classification task(Wang et al., 2024), ignoring the inherent complexity of the problem."}, {"title": "Methodology", "content": null}, {"title": "Task Definition", "content": "The task of stance detection is defined as follows: Given a text S and a target t, the model needs to determine the stance polarity y towards t, such as favor, against, and none. We now use a chain of stance prompt-based approach to solve the stance"}, {"title": "The Proposed Approach: CoS", "content": "We propose a method called chain of stance(CoS), a CoT-style paradigm that allows LLMs to decompose the problem of stance detection into intermediate steps and solve each before making decision (Fig.1). Each step will be sampled sequentially, then the output is summarized based on the above steps.\nUnlike traditional stance detection input/output prompts, we do not require the LLM to directly provide the stance detection result. Instead, we ask the LLM to consider various aspects and fully account for potential information before giving the final result to enhance detection accuracy. Specifically, CoS involves the following steps:\nStep 1. We first use the following template to help the LLM understand the contextual information I of the text.\nGiven text S, understand the contextual information i of the text, which includes the topic of the text, the identity of the author, the target audience, and the relevant socio-cultural background.\nThis step can be formulated as $I = \\underset{i}{\\text{argmax}} p(i | S, t)$, where I is the contextual information contained in the text S.\nStep 2. Next, based on S, t, and i, we ask the LLM to interpret the main idea V of the text S.\nWhat are the core viewpoints and main intentions to be expressed in the text?\nThis step can be formulated as $V = \\underset{v}{\\text{argmax}} p(v | S, t, i)$, where V are the main ideas in the text S.\nStep 3. In this step, we instruct the LLM to analyze the language expression and emotional attitude E of the text.\nAnalyze the language expression and emotional inclination of the text. Identify the emotional words and rhetorical devices used within the text, and analyze the tone adopted by the author (e.g., affirmative, negative, interrogative, exclamatory, etc.). Based on this analysis, describe the author's emotional attitude E.\nThis step can be formulated as $E = \\underset{e}{\\text{argmax}} p(e | S, t, i, v)$, where E is the emotional attitude expressed in the text S.\nStep 4. In this step, we let the LLM compare the text S with three possible stances (e.g., favor, against, none), and obtain the similarities and contrasts between the text and each potential stance. For each stance, calculate its probability given S, t, i, v, e.\nCompare similarities and contrasts between text S and various possible stances (favor, against, none), based on the abovementioned information.\nThe calculated probabilities for each stance are combined to form a set A: $A = \\{\\text{favor:P(favor|S, t, i, v, e), against:P(against|S, t, i, v, e), none:P(none|S, t, i, v, e)}\\}$.\nStep 5. We ask the LLM to confirm the consistency and rationality of the stance.\nConduct logical inference based on the context and other relevant information to confirm the consistency and rationality of the stance.\nThis step can be formulated as $L = \\underset{l}{\\text{argmax}}p(l | S, t, i, v, e, a)$, where L is the result of logical reasoning performed by the LLM.\nStep 6. With the complete stance skeleton (S, t, i, v, e, a, l) as context, we ask the LLM to make the final decision.\nBased on the above information, determine the stance polarity towards t.\nWe note this step as $\\hat{y} = \\underset{y}{\\text{argmax}} p(y | S,t,i, v, e, a, l)$.\nBy following these steps, the model acts like an experienced \"stance expert\", thoroughly extracting valuable information from the text while breaking down the stance detection process into a series"}, {"title": "Experiment Settings", "content": null}, {"title": "Dataset and Evaluation Metrics", "content": "Dataset. SemEval-2016 Task 6 (?), named \"Stance Detection in Tweets\", is a benchmarking dataset widely used to explore and analyze users' stances on certain targets based solely on the content of their tweets. This dataset contains a total of 4,163 tweets, featuring five targets from different domains: Hillary Clinton (HC), Feminist Movement (FM), Legalization of Abortion (LA), Atheism (A), and Climate Change is a Real Concern (CC). The dataset includes three different stance labels: favor, against, and none.\nWe use the evaluation metric recommended by"}, {"title": "Implementation Details", "content": "We conducted experiments using four models: LLaMa2-7b-Chat, LLaMa3-8b-Instruct, Mistral-7b-Instruct-v0.2, and Qwen1.5-7b-Chat. For each model, we used the same instructions. To detail the fine-tuning parameters, the selected hyperparameters for LORA included a rank of 8, an alpha of 16, and a dropout rate of 0.1. We trained each model with a batch size of 2 for a maximum of 10 epochs. The learning rate was set to 5e-5, and the compute"}, {"title": "Baseline Models", "content": "To fully demonstrate the effectiveness of CoS, we selected 7 SOTA stance detection models as baselines for our experiments. They are:\n(1) JointCL (Liang et al., 2022). This model designs a new joint contrastive learning framework that enhances the model's ability to detect stances on unknown targets by constructing positive and negative samples for contrastive learning.\n(2) KEprompt (Huang et al., 2023). This framework designs a knowledge-enhanced prompt tuning method for stance detection. KEprompt includes an automatic vocabulary (AutoV) and background knowledge injection (BKI).\n(3) TATA (Hanley and Durumeric, 2023). This model achieves stance detection by combining topic-aware (TAW) and topic-agnostic (TAG) embedding layers.\n(4) KASD (Li et al., 2023). This model proposes combining Wikipedia knowledge for retrieval-enhanced generation.\n(5) MB-Cal (Li et al., 2024). This model designs a new gated calibration network to mitigate the bias of LLMs in stance detection results.\n(6) CoSD (Cheng et al., 2024). This framework utilizes contrastive heterogeneous topic graph learning to learn the topic-aware semantics and collaborative signals between texts, topics, and stance labels to enhance stance detection.\n(7) COLA (Lan et al., 2023). This model designs a collaborative role-injection framework involving multiple LLMs, where LLMs are designated different roles, including multi-dimensional text analysis phase, reasoning-enhanced debate phase, and stance conclusion phase. This framework does not require additional labeled data and only needs interaction with pre-trained LLMs, making it highly usable."}, {"title": "Experimental Results", "content": null}, {"title": "Main Results", "content": "We conducted both zero-shot and few-shot experiments on the SemEval-2016 dataset. The experimental results are shown in Table2 and Table3. For the few-shot experiments, we set the number of shots to 4. Based on the experimental results, we can draw the following conclusions: (1):After applying CoS, our models achieved state-of-the-art results in both zero-shot and few-shot settings. Not only did we surpass baseline models, but our results also outperformed the latest models and methods. This demonstrates that CoS can effectively and significantly enhance the stance detection capabilities of LLMs. (2):Except for the LLaMA3-8b model, all other models we used were 7b models. Notably, even though LLaMA2-MB-Cal uses a much larger 70b model, our LLaMA2-7b model still achieved leading results. This highlights the efficiency and effectiveness of CoS, proving that significant improvements can be made without requiring an excessively large model. (3):All four models we tested showed significant improvement after applying CoS. This indicates that CoS is broadly"}, {"title": "Error Analysis", "content": "When using the chain of stance (CoS), we conducted an error analysis on the four models. The results are illustrated in Fig.3 We categorized the errors into four types:\n(1)Contextual Misinterpretation: The model may fail to accurately capture key background information or contextual cues within the text, leading to a misinterpretation of the overall meaning. This includes, but is not limited to, misunderstandings of cultural or historical context, misuse of specific terms or slang, and so forth. (2)Sentiment Analysis Errors: Even with a correct understanding of the text content, the model might misinterpret the sentiment or tone expressed by the author, thereby affecting stance determination. This is particularly relevant for handling complex emotions like sarcasm or irony. (3)Insufficient Logical Reasoning: When the task requires logical reasoning to ensure stance consistency and validity, the model might make incorrect judgments due to a lack of deep understanding or reasoning capabilities. (4)Domain-Specific Knowledge Limitations: For specialized domains or specific topics, the model might struggle to accurately determine stances due to insufficient domain knowledge.\nBy analyzing these error categories, we can identify areas where the chain of stance method can be further improved to enhance the overall accuracy and robustness of stance detection in large language models."}, {"title": "Ablation Study", "content": "We conducted ablation experiments to demonstrate the effectiveness of our method: \"w/o CoS\" indicates the model without using chain of stance. The"}, {"title": "Conclusion and Future Work", "content": "To explore the potential of Large Language Models (LLMs) in human stance detection, we propose"}, {"title": "Limitations", "content": "The important limitation of this work is that the length of the prompts leads to a decrease in the model's computational efficiency. Although computational efficiency is not within the scope of this paper, improving computational efficiency while enhancing the model's detection accuracy will be our goal in future work."}]}