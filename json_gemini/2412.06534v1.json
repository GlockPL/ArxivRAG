{"title": "Inverting Visual Representations with Detection Transformers", "authors": ["Jan Rathjens", "Shirin Reyhanian", "David Kappel", "Laurenz Wiskott"], "abstract": "Understanding the mechanisms underlying deep neural networks in computer vision remains a fundamental challenge. While many prior approaches have focused on visualizing intermediate representations within deep neural networks, particularly convolutional neural networks, these techniques have yet to be thoroughly explored in transformer-based vision models. In this study, we apply the approach of training inverse models to reconstruct input images from intermediate layers within a Detection Transformer, showing that this approach is efficient and feasible for transformer-based vision models. Through qualitative and quantitative evaluations of reconstructed images across model stages, we demonstrate critical properties of Detection Transformers, including contextual shape preservation, inter-layer correlation, and robustness to color perturbations, illustrating how these characteristics emerge within the model's architecture. Our findings contribute to a deeper understanding of transformer-based vision models. The code for reproducing our experiments will be made available at github.com/wiskott-lab/inverse-detection-transformer.", "sections": [{"title": "1. Introduction", "content": "Recent advancements in deep neural networks (DNNs), particularly transformer-based architectures, have achieved remarkable results on vision tasks such as object detection, semantic segmentation, and image classification [1, 4, 15, 29, 31]. Despite their compelling performance, the internal mechanisms of these networks remain largely opaque, hindering a clear understanding of how predictions are made [6, 14, 30]. Enhancing network interpretability, i.e., understanding the mechanisms underlying the network's functionality, is crucial for ensuring safety, optimizing performance, and identifying potential weaknesses.\nFeature inversion, introduced by Dosovitskiy and Brox [3], is one of the first techniques developed to interpret the processing capabilities of DNNs for vision. Building on a substantial body of work on generating images from intermediate representations [5, 18, 26, 28], their method involved training an inverse network for each layer of a convolutional neural network (CNN) to reconstruct input images from intermediate representations. By analyzing these reconstructed images and their distinct characteristics from various layers, they uncovered important insights into the underlying mechanisms of CNNs.\nWhile feature inversion provided valuable understanding of the CNN explored in their study, the approach has not seen widespread application to more advanced iterations of CNNs or transformer-based vision models. This is mainly due to the computational challenges inherent to feature inversion, as training a separate inverse model for each intermediate layer of interest becomes impractical for the large and complex DNNs of today.\nIn this work, we revisit feature inversion and extend it to a modern transformer-based vision DNN: the Detection Transformer (DETR). To address the significant computational challenges, we propose a modular approach to feature inversion. We invert distinct components or modules of DETR independently. This modular strategy significantly reduces the size of inverse networks required while maintaining the interpretability of reconstructed images. Notably, we observe that these inverse modules can be effectively applied across all intermediate layers, including those for which they were not explicitly optimized.\nLeveraging these inverse modules, we qualitatively analyze reconstructed images from different stages of DETR. Hypotheses drawn from this qualitative evaluation are further validated through quantitative analyses, demonstrating key properties of DETR, such as contextual shape preservation, inter-layer correlation, and robustness to color perturbations."}, {"title": "2. Related work", "content": "In the context of DNNs for computer vision, synthesizing images from intermediate representations is a valuable technique for network interpretability. A central branch within synthesizing images for network interpretability is activation maximization [5, 20, 21, 26, 28]. Activation maximization generates images that activate specific network components, such as neurons, channels, or entire layers. While approaches vary in utilized techniques, the general goal is to synthesize images highlighting what specific parts of the network are responsive to. For example, synthesized images usually show simple features, such as edges, in lower layers, and more complex patterns in higher layers.\nA related approach of synthesizing images concerns the feature inversion of intermediate representations within DNNs [3, 18]. Unlike activation maximization, which targets individual network components, feature inversion reconstructs input images from intermediate representations, enabling researchers to assess the information retained at each layer. This approach aids in interpreting network behavior by examining specific features in these reconstructions. For example, Dosovitskiy and Brox [3] argued that color information remains accessible to the top layer of AlexNet [13].\nThese techniques for image synthesis have primarily been applied to convolutional neural networks (CNNs). In recent years, transformer-based vision models have been introduced. The analysis of vision models based on transformer networks [1, 4, 12] has so far focused on various other techniques such as analyzing the robustness against various image perturbations (e.g., occlusions or natural adversarial examples) representational similarity, and loss landscape analysis [2, 16, 19, 22-24]. Only recently has activation maximization been applied to vision transformers [9]. To the best of our knowledge, our work is the first to synthesize images from intermediate representations using feature inversion within a transformer-based vision model."}, {"title": "3. Methods", "content": "To efficiently apply feature inversion to DETR, we trained separate inverse models for distinct modules of the architecture. Specifically, for each of DETR's modules (backbone, encoder, decoder, and prediction head), we trained corresponding inverse models (backbone\u00af\u00b9, encoder-1, decoder\u00af\u00b9, prediction head\u00af\u00b9, and detection\u00af\u00b9) to reverse the path of information flow, as illustrated in Figure 2.\nFor a technical description of our method, we first outline the default forward path of information flow in the DETR architecture. In the forward path, an input image $X \\in \\mathbb{R}^{H_0\\times W_0\\times 3}$ is processed through the ResNet-50 [10] backbone, extracting feature maps and reducing the spatial dimensions by a factor of 32. Assuming $H, W = \\frac{H_0}{32},\\frac{W_0}{32}$, the backbone feature map is then flattened and linearly projected to produce the backbone forward embedding $B \\in \\mathbb{R}^{H\\times W\\times 256}$. Next, the DETR encoder processes B using six transformer blocks, generating contextualized encoder forward embeddings $E \\in \\mathbb{R}^{H\\times W\\times 256}$. The DETR decoder module takes E along with 100 learnable object queries $Q \\in \\mathbb{R}^{100\\times 256}$, and through a series of self-attention and cross-attention layers, refines these object queries to produce decoder forward embeddings $D \\in \\mathbb{R}^{100\\times 256}$. Finally, the prediction head utilizes D to generate object classification scores $Y_{cls} \\in \\mathbb{R}^{100\\times C}$, where C is number of object classes, and bounding box coordinates $Y_{bbox} \\in \\mathbb{R}^{100\\times 4}$\nFor the inverse path, all inverse modules were trained using the MSE loss between their outputs and the corresponding forward path embeddings independent of each other. Target forward path embeddings were generated for the COCO 2017 dataset [8]. The pre-trained forward weights of DETR were kept fixed during the training process, and the inverse modules were trained in isolation.\nThe backbone\u00b9 takes the embedding B and uses a 6-layer CNN to reconstruct the original input image as $X \\in \\mathbb{R}^{H_0\\times W_0\\times 3}$. The encoder\u00af\u00b9 takes E, and using the same architecture as the DETR encoder reconstructs the backbone inverse embedding $B\\in \\mathbb{R}^{H\\times W\\times 256}$. The decoder-1 receives zero-initialized image queries $I \\in \\mathbb{R}^{H\\times W\\times 256}$ along with D, and refines these image queries gradually by employing a structure similar to the forward decoder but operating on image queries instead of object queries. It outputs the encoder inverse embeddings $\\bar{E}\\in \\mathbb{R}^{H\\times W\\times 256}$. Finally, the prediction head\u00af\u00b9 takes [Ycls, Ybbox], and reconstructs the decoder inverse embeddings $D\\in \\mathbb{R}^{100\\times 256}$ using a multi-layer perceptron network.\nWith this final inverse module, we took an additional step by applying one-hot encoding suppression on the class scores, preserving only the predicted classes with the highest probabilities in $Y_{cls}$, while retaining their bounding boxes. These were fed to the final detection\u00af\u00b9, which reconstructs \u010e. DETR can use a \"no object\u201d class to handle images where the number of objects is fewer than 100 object queries. During training, if a query does not match any ground-truth object, it is classified as \"no object\" (i.e., background). Since not all possible object categories are included in COCO's ground-truth annotations, this background class may also encompass objects that are unknown to DETR. The detection-1 was designed to analyze the model's behavior when only the highest-confidence classes, including \"no object,\" are provided for inversion. In this way, reconstructions can partially preserve the scene's complexity by assuming that something should occupy the corresponding predicted locations."}, {"title": "4. Results", "content": "After training a set of inverse modules, we conducted a qualitative evaluation of the reconstructed images from various stages of DETR, as shown in Figure 2. We observed that structural and spatial information are generally well preserved in the reconstructions from backbone embeddings. Moreover, color shifts emerged as early as the encoder stage, which becomes more pronounced in the decoder. These color shifts resulted in reconstructed objects appearing closer to prototypical colors associated with their classes. For example, red was often assigned to buses, stop signs, and apples, green to potted plants, and orange to oranges. Beyond just color, the decoder stage also exhibited contextual shifts, where objects were reconstructed with prototypical semantic features even if they were not present in the original image. For instance, the presence of a tie often resulted in the model reconstructing the person wearing a suit, despite the original image not containing that. This indicates that DETR's deeper layers incorporate semantic features and contextual cues that align with learned object associations. Our analysis shows that most irrelevant information for object detection from the background scene is effectively removed after the decoder stage, allowing DETR to focus on features crucial for detection while discarding less useful details.\nThis selective filtering can also explain some detection errors. By comparing reconstructions before and after the decoder stage, we observed that false negatives can occur when certain objects, deemed irrelevant by the model, are entirely removed, leaving no trace in the reconstructions. Conversely, for false positive detections, the reconstructions showed cases where irrelevant features associated with an incorrect class are amplified, leading to misclassifications. For additional reconstruction results on such examples, please refer to Section 7 in the supplementary material.\nWhen analyzing reconstructions from grayscale images, we observed that removing color information did not significantly impair DETR's ability to detect objects. The reconstructions still displayed colors typical of the detected classes, emerging after the encoder.\nFurther analysis of reconstructions from decoder and prediction head stages showed that along this forward and inversion path it has been learned to encode not only classes but also prototypical shapes and spatial relationships. For example, human body parts and their spatial relations were contextually well reconstructed. Even if the figures are not anatomically perfect, the reconstructions captured recognizable human forms and varied poses differing from the original image. Similarly, objects like buses were reconstructed with distinctive features, sometimes from angles that differ from the input, demonstrating the model's ability to leverage class and bounding box information to generate plausible representations.\nIn the last experiment of this section, we applied one-hot encoding suppression on the class scores by preserving only the class with the highest confidence for each object query while retaining all bounding box predictions. This allowed us to investigate how the removal of lower-confidence class information affects the reconstruction. By limiting the class information to only the most confident predictions, we could observe the impact of class uncertainty on the reconstructed output and the resulting information loss. In some cases, this led to hallucinations of semantically relevant objects, such as generating additional chairs around a potted plant that were not present in the original image Figure 2.\nThe diagram presented in Figure 3 shows the MSE loss of reconstructions across different stages of the DETR model, suggesting that the most significant information loss occurs within the decoder. This aligns with the model's architecture, as the decoder has the role of transforming object queries into high-level abstract representations tailored for object classification and localization."}, {"title": "4.1. Reconstructing modules' embeddings", "content": null}, {"title": "4.2. Contextualizing reconstructions", "content": "Similar to Dosovitskiy and Brox [3], we contextualized our method for network interpretability by comparing reconstructions obtained from our default model with reconstructions obtained from a fine-tuned DETR fine-tuned for reconstruction. For this purpose, we started with a pre-trained DETR, an inverse backbone, an inverse encoder, and an inverse decoder and retrained all the parameters of both DETR and the inverse modules end-to-end. Specifically, we used a weighted combination of the detection performance loss $L_{Hungarian}$ with default hyperparameters as defined by Carion et al. [1], and a reconstruction loss $L_{MSE}$ defined as the MSE between an input image and its reconstruction from the decoder embedding, comparable to the method proposed by Rathjens and Wiskott [25]. The total loss is expressed as:\n$L = \\lambda L_{MSE} + (1 - \\lambda)L_{Hungarian}, \\lambda\\in [0,1]$ (1)\nThe hyperparameter A allows for a trade-off between the two losses. For example, when X = 0, the model is optimized solely for detection performance, while setting A = 1 optimizes the model exclusively for reconstruction performance.\nNotably, this procedure differed from our default training approach in two key ways. First, it involves updating DETR's parameters alongside the inverse modules. Second, images are reconstructed directly from the decoder embedding, rather than optimizing the inverse modules independently as described in Section 3.\nFigure 4 illustrates reconstructions for various images with fine-tuned models as well as our default model. The left column displays the original images, while the subsequent columns show reconstructions generated with progressively smaller A values. Across all examples, a consistent pattern emerges: for high \u5165 values, the reconstructions exhibit high quality, faithfully capturing details and colors. As A decreases, reconstruction quality deteriorates, increasing blurriness, loss of detail, and noticeable color shifts. This degradation is particularly pronounced in the last two columns. Interestingly, there are apparent differences in the last two columns, as the x = 0 column introduces a gray tone to reconstructions. While both DETRS corresponding to these columns were optimized purely for object detection, the inverse models were optimized differently. One represents our default approach of training inverse modules independently, whereas the other was trained using the method described in Equation (1). These differences highlight the significant impact of the two optimization techniques.\nWe quantitatively analyzed this pattern in Figure 5, which shows the MSE alongside the average precision (AP) for our default and fine-tuned models. The results align with the qualitative assessment of the reconstructed images: as \u5165 decreases, the reconstruction error increases. Notably, as A decreases, object detection performance improves, highlighting a trade-off between reconstruction quality and object detection performance in DETR."}, {"title": "4.3. Case study: coloring objects", "content": "Having contextualized our method, we investigated the role of color information in DETR in greater detail. To this end, we recolored specific objects in input images. We evaluated the influence of these modifications on reconstructions from intermediate embeddings at different stages within the network and the influence on object detection performance.\nFor recoloring, we used the segmentation annotations from the COCO dataset to apply five different color filters in the HSV color space to various object categories. For each filter, we adjusted the hue of specified objects to red, green, or blue or shifted the hue values by 120 or 240 degrees. We then evaluated the reconstructions and the object detection performance with AP. Since segmentation annotations in COCO are most accurate for large objects, all evaluations were conducted on objects with segmentation masks of at least 962 pixels.\nFigure 6 illustrates recolored images and the influence on DETR with several examples (additional examples are provided in Section 7 of the supplementary material). Each row presents an example from a different object category (from top to bottom, stop sign, bear, apple, and bus) with a different color filter. For each example, images are shown at different processing stages of DETR, displaying reconstructions from different embeddings. We observed that color changes were preserved in the backbone embedding for all objects and filters but faded or disappeared almost entirely in the encoder embedding. There was almost no color information from the input in the decoder embedding. Instead, colors shifted towards prototypical representations (e.g., red for the stop sign and bus, brown for the bear, or red and yellow for the apples). This finding contrasts sharply with previous results of inversion of feature analysis in CNNs, where color information was largely preserved throughout all layers [3].\nWhile it is unclear whether DETR adjusts or removes colors entirely, resulting in prototypical fills, these transformations suggest that the model exhibits robustness to color changes. This robustness is further supported quantitatively in the last column, with the exception of the apple category, where we show AP performance for unchanged objects compared to all color filters across rows for the respective objects. The graphs confirm this observation, as AP values remain relatively consistent regardless of color changes or object category.\nBuilding on our observations of the color robustness of DETR, we analyzed the individual influence of different color perturbations. To do this, we applied the previously described color perturbations to images and reconstructed them from various stages of DETR. Figure 7 provides an example of reconstructions for one image under different color perturbations. Consistent with earlier observations, color perturbations are noticeable in reconstructions from the backbone embedding but gradually diminish in reconstructions from later stages of DETR. Interestingly, reconstructions from the encoder and decoder embeddings converge to the same color and not to individual prototypical colors, becoming increasingly similar. Additionally, while reconstructions from the backbone and encoder embeddings are broadly similar in shape, objects in the decoder reconstructions show shape distortions that vary depending on the applied filter.\nWe quantified this effect by calculating the average pairwise MSE between reconstructions for perturbed and unperturbed images at each embedding stage. Figure 8 presents these results. We observed that the average pairwise MSE decreases progressively from the input to reconstructions derived from the backbone and encoder embeddings, reflecting increasing similarity. However, the MSE returns to input levels in reconstructions from decoder embeddings. This observation aligns with our qualitative analysis, confirming that reconstructions converge to the same or similar colors the farther they progress through the DETR architecture. The increase in average pairwise MSE at the decoder stage is likely not due to color divergence but caused by distortions in object shapes."}, {"title": "4.4. Reconstructing intermediate representations", "content": "In contrast to the design philosophy of CNNs \u2013 where intermediate layers often vary in dimensionality (with exceptions, e.g., intermediate layers within ResNet building blocks [10]) transformer-based DNNs use a consistent dimensionality across intermediate layers within their encoders and decoders. This consistency enables using all intermediate representations as inputs to inverse modules, even if the inverse module is optimized for a different representation. For instance, all intermediate encoder representations can be fed into encoder\u00af\u00b9 even though encoder-1 is optimized for the encoder embedding.\nUsing our inverse modules, we leveraged this feature to evaluate DETR's intermediate encoder and decoder representations. Figure 9 shows an illustrative example (additional examples are provided in Section 8 of the supplementary material). Specifically, the first column depicts reconstructions obtained by feeding the encoder's intermediate representations into backbone\u00af\u00b9. In the second column, the same intermediate representations were passed through encoder \u00b9 and then through backbone\u00af\u00b9. The last column displays results for intermediate decoder representations passed through decoder\u00af\u00b9, followed by encoder-1 and backbone-1.\nAs expected, we obtained the best reconstruction performance for the layer that each inverse module was trained on: encoder input (backbone embedding) for backbone-1, encoder layer six (encoder embedding) for encoder\u00af\u00b9, and decoder layer six (decoder embedding) for decoder\u00af\u00b9. The quality of reconstructions gradually decreased as we moved farther away from the layers the inverse modules were optimized for, a pattern particularly evident with the input to decoder \u00b9 since object queries initially hold values independent of the input image.\nDespite this degradation in quality, we generally observed strong shape preservation between intermediate layers, particularly when feeding intermediate encoder representations to encoder 1. Most variations in backbone-1 and encoder\u00af\u00b9 manifest as color shifts, while reconstructions from decoder\u00af\u00b9 show greater stability in color than shape. The overall stability in reconstructions across layers is noteworthy, as inverse modules might be expected to produce only noisy outputs when applied to intermediate embeddings."}, {"title": "5. Discussion", "content": "In this work, we took a closer look at DETR by inverting the three main modules of the network architecture - its backbone, encoder, and decoder. We used these inverse modules to study DETR's, by reconstructing input images from different stages. Following the premise that reconstruction quality reveals the information present in each layer, we evaluated the reconstructed images for distinctive features. We inferred that DETR is preserving object representations within its encoder and decoder, is robust to color changes, and that features evolve gradually across the architecture.\nOur findings align with previous analyses of vision transformers (ViT), which have been studied in the literature using different tools. For instance, the gradual change of representations was reported for ViT by Raghu et al. [24]. Additionally, the robustness of ViT to various image perturbations [19, 23] is comparable to our findings of DETR's robustness to color perturbations. This suggests that the properties we observed for DETR and those reported for ViT are not specific to these architectures but may reflect general patterns in transformer-based DNNs for vision.\nOur approach draws inspiration from Dosovitskiy and Brox's work [3], where they inverted intermediate representations in AlexNet. Compared to their study, we find that DETR is more shape- but less color-preserving than AlexNet. These differences align with recognized distinctions between CNNs and transformer-based vision models in the literature [12, 24, 27]. An important difference between our work and Dosovitskiy and Brox's is that we did not train separate inverse models for each intermediate layer. Instead, we inverted DETR's main components, allowing us to perform similar analyses with fewer inverse models, thanks to the consistent dimensionality across transformer layers and the gradual evolution of features within the architecture. This efficiency suggests that our method is well-suited for studying transformer-based DNNS in vision tasks and opens pathways for future interpretability studies, such as exploring newer versions of DETR or ViT.\nWhile our approach is efficient, a primary limitation of feature inversion, in general, is that properties observed across reconstructed images must be carefully interpreted. This caution arises from the uncertainty of whether a specific property originates from a transformer module itself or from its inverse counterpart. For instance, whether the prototypical colors observed in reconstructions are introduced during the forward pass through the transformer model or added by the inverse module to minimize the reconstruction error is unclear.\nThe success of our modular inversion method in DETR could have implications beyond computer vision. For instance, in computational neuroscience, generative models of episodic memory require the integration of both discriminative and generative processes [7]. Future iterations of such models might unify a transformer-based DNN and its inverse within a single architecture. Similarly, transformer-based DNNs could be promising candidates for biologically plausible learning architectures, as they can leverage local reconstruction losses [11]."}]}