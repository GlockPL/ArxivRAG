{"title": "Programming with Al: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers", "authors": ["Md Kamrul Siam", "Huanying Gu", "Jerry Q. Cheng"], "abstract": "Our everyday lives now heavily rely on artificial intelligence (AI) powered large language models (LLMs). Like regular users, programmers are also benefiting from the newest large language models. In response to the critical role that AI models play in modern software development, this study presents a thorough evaluation of leading programming assistants, including ChatGPT, Gemini (Bard AI), AlphaCode, and GitHub Copilot. The evaluation is based on tasks like natural language processing and code generation accuracy in different programming languages like Java, Python and C++. Based on the results, it has emphasized their strengths and weaknesses and the importance of further modifications to increase the reliability and accuracy of the latest popular models. Although these Al assistants illustrate a high level of progress in language understanding and code generation, along with ethical considerations and responsible usage, they provoke a necessity for discussion. With time, developing more refined AI technology is essential for achieving advanced solutions in various fields, especially with the knowledge of the feature intricacies of these models and their implications. This study offers a comparison of different LLMs and provides essential feedback on the rapidly changing area of AI models. It also emphasizes the need for ethical developmental practices to actualize Al models' full potential.", "sections": [{"title": "1 INTRODUCTION", "content": "The advent of the AI concept presents a new revolutionary age of innovation with an AI model and LLM-powered chatbots changing how our software is being developed and problems solved [36]. With the launch of ChatGPT and the newest LLM tools, such as GitHub Copilot, Bard AI (which is now a part of the Gemini framework), and DeepMind's AlphaCode, which have been developed by major players in the industry like Google, GitHub, and OpenAI, these AI systems have captured the attention of the tech community with their capacity to understand languages and generate programming languages. The reality of AI assistants is that they are revolutionary and keep widening the limits of AI models at work. Therefore, the discussion about their accuracy, architecture, capabilities, and implications for the future of AI technologies is crucial. One of the first and most effective LLMs, ChatGPT, attracted 100 million users in just two months after the launch, making it the fastest-growing platform out of all those based on technology and a testament to how much the consumers needed such platforms [53]. With the help of LLMs, notable progress in code generation and Natural language Processing (NLP) has been made recently [19]. One example is the generative pre-trained transformer (GPT) model series[61]. These models, which have received extensive training on textual data show that they can produce codes on the same level as human written codes and execute language-based tasks with remarkable accuracy. This paper thoroughly studies the most recent large language models, highlighting their strengths and weaknesses and crucially contributing to responsible development practices in the benefits of AI models in various fields. Thus, to understand and capture the behaviour of popular LLMs, we pose three research questions:\n\u2022 RQ1: Which model provides the most accurate code for programmers?\n\u2022 RQ2: What are the metrics are frequently used to evaluate LLM generated codes?\n\u2022 RQ3: What are the benchmarks are being used to evaluate LLM generated codes?"}, {"title": "2 RELATED WORK", "content": "The period of language models started in the late 19th century with the development of mathematical models known as Statistical Language Models (SLMs), which provide a probabilistic statistical framework for handling contextually important aspects of natural language [41]. SLM was among the pioneer techniques. After SLMs were developed, neural network-based machine learning (NLM) entered the revolution and predicted the likelihood of words in a sequence [24, 45]. PLM (Pre-trained Language Model) was the most recent language model prior to the development of more recent LLMs like chatGPT, Genimi, GitHub Copilot and AlphaCode. PLMs have a significant impact on the LLM industry, which came about after the introduction of NLM [13, 30]. Pre-training is the first phase of training that PLMs go through with a large amount of unlabeled text to help them understand basic language structures including vocabulary, syntax, semantics, and logic. Research on generative models-which are trained by gathering a large amount of data in a particular area, such sounds, phrases, or images-was published by OpenAI on June 16, 2016. The model is then taught to produce comparable data and research on optimizing the GPT-2 language model with human preferences and input was published by OpenAI on September 19, 2019 [38]. As part of a free research preview, OpenAI released ChatGPT utilizing GPT-3.5 on November 30, 2022. GitHub Copilot, a tool for code completion from GitHub and OpenAI, was announced on June 29, 2021, as being in the technical preview in the Visual Studio Code development environment [32, 37]. It was released eventually as a plugin to the JetBrains marketplace on October 29, 2021, and became available to all developers worldwide on June 21, 2022 [10]. As part of a free research preview, OpenAI released ChatGPT, a chatbot utilizing GPT-3.5 on November 30, 2022. This chatbot is built on top of large language models (LLMs). It lets users adjust and tailor a conversation to their preference regarding length, format, style, level of detail, and language. By January 2023, it had registered over 100 million users [53]. Google unveiled BARD AI, a generative artificial intelligence chatbot, to the globe on February 6, 2023 [29]. It commenced limited operations in March 2023, and the product was available in more regions by May. In February 2024, Bard merged under the banner of Gemini [28]. In contrast, in 2022, Goolgle's DeepMind introduced AlphaCode. This new Al-powered code writing program can create computer programs at the level of a professional programmer, using the system to compete in Codeforces, coding challenges popular with the programming community, and managing to rank 54% in the median Codeforces score after being trained on GitHub data and Codeforces problems and solutions [6]. The task was set to make up a particular answer that was unique and different."}, {"title": "3 TRANSFORMER ARCHITECTURE", "content": "The Transformer architecture seems indispensable for programming and central to the Large Language Models (LLMs) [11, 18]. This way, it is tuned for tasks such as machine translation or inducing general-purpose text generation. In a nutshell, the Transformer utilizes the mechanism of self-attention to process input data. Unlike the sequence data models (RNNs and LSTM) employed for natural language processing in previous deep learning models, Transformers aim to process parallel input data. Apart from this, the model's efficiency is also heightened, and there is an improved capability to understand the context within language [59].\nTransformer architecture is the main idea behind a few Al models, such as AlphaCode, GitHub Copilot, ChatGPT, and BardAI (laying a foundation for the upcoming Genie model). Every model innovates by using the transformer architecture differently to suit its purpose and the training dataset on which it is trained. Transformers' attention technique, which enables them to process and grasp intricate language patterns efficiently, is the primary advantage of this model. Via a process in which only the significant pieces are acknowledged, the models generate responses with more conciseness and pertinence. The model uses an extensive training corpus to grasp language subtleties and give discrete outputs. The transformer algorithm, considered a landmark in NLP, has shown a new way to develop chatting AI to participate in human-like conversations. Through this, the applications of transformer architectures in machine learning are proven.\nDeepMind's AlphaCode exemplifies the significance of transformers as a force multiplier. Within this framework, a code generator model, designed to generate competitive programming problems related to codes, utilizes an encoder-decoder transformer model. It employs an additional reduced competitive programming dataset and uses large-scale model sampling to explore the space [49]. This model is performance-sensitive; it can be reduced to some selected submissions, demonstrating the effectiveness of the transformer-based architectures [31]. Codex is the system used to build GitHub Copilot; an application based on transformer architectures. This model has been implemented on large numbers of code repositories. Similarly to language models such as GPT-3 and LaMDA, the architecture of transformers works well with sequential data, be it text, lines of software code, or amino acid sequences [17, 27]. A transformer architecture can be applied to many tasks, including identifying the following words in a sentence or prior computer instructions, proving transformer models' effectiveness.\nChatGPT, a GPT model variant with the exact underlying mechanism, is another example of a transformer-based neural network [64]. It consists of the encoder and the decoder, similar to the traditional transformer. The encoder, composed of several layers of self-attention and feed-forward neural networks, processes and interprets the input text [70]. The decoder, also made of self-attention-based and feed-forward neural network layers, generates the output text, demonstrating the greatness of transformer architecture in text generation [11, 60, 70].\nBard AI, now known as Gemini, is another model resembling the Transformer architecture [46]. It is trained on the linguistic statistics between the words and phrases as a vast corpus of text [47]. With the tools to understand an extensive repertoire of text and code, Bard can create human-like text, translate languages, write various types of creative work, and provide meaningful responses [5]."}, {"title": "3.1 ChatGPT", "content": "ChatGPT is a huge language model-based chatterbot that was developed by the OpenAI organization in November 2022. It also could be applied to the list of tasks, such as writing, analysis, and solving problems. The new player on the street, ChatGPT, is the talk of the town due to its unique aptitude of writing things in a similar way like a human being does. On the other hand, while some individuals might misuse this technology and it may not give correct outputs to us [54]. With ChatGPT and other similar Al virtual assistants becoming more mature and common, the ethical aspect of the matter as well as the necessity for duty-bound development and the deployment of the technology has received wide attention in the current discussion."}, {"title": "3.2 Gemini", "content": "Gemini is a multimodal AI meaning it has the ability to comprehend and write content using various data modalities, such as text, images, audio, video, and code. Perhaps the most spectacular thing is that it suits almost any feature. It is worth talking about the work of Gemini on the MMLU task. MMLU is a short test that seeks to determine an Al system's language processing competence and sentence construction skills for various tasks. The effectiveness of Gemini, therefore, can be boiled down to the superb language use and problem-solving faculties it is endowed with [7]. Thanks to the Gemini's API, developers can design their apps of around Gemini functionality. It is a multi-lingual software with support for languages like Python, Go, Node.js, and Swift. As a result, it has boosted the chances of getting popular among other developers as well. Finally, Gemini offers three model sizes: 1.0 Ultra, 1.0 Pro, and 1.0 Nano. These opportunities allow developers to select the best model for their needs [2]."}, {"title": "3.3 AlphaCode", "content": "The new approach of code creation that has been developed is known as AlphaCodium, and it was created by Tal Ridnik [62]. This is a multistage, process-based, code-oriented iterative approach that guarantees improved code problem performance for LLMs. Consideration has been given to the types of AI and their characteristics for code analysis in software design and development tasks, including code and document generation3. Three areas of skills are required for machine learning models to handle structured expression (SE) tasks involving code analysis: syntax, static behavior comprehension, and dynamic behavior comprehension.\nWe already have some existing research those were designed to make it easier for LLMs to understand and interpret abstract code structures like AST, CFG, and CG. Four cutting-edge foundational models were used: CodeLlama-13b-instruct, GPT4, GPT 3.5, and StarCoder [52]. One of the topics explored in the research was the ability of LLMs to analyze code syntax; nevertheless, they are unable to comprehend code semantics, including dynamic semantics. AlphaCode would be helpful in order to support those study findings and needs for programmers and software developers in their daily tasks.\nAlthough LLMs are capable of creating facts and making sense out of code structures, they are not real. These results imply that more research is necessary to create a system for guaranteeing the validity of LLM results. Because AlphaCodium is a multi-stage, iterative, test-driven process that focuses on code, code problems, in particular, improve LLM performance [63]. The CodeContests dataset, which consists of competitive programming issues from online platforms like Codeforces, was used to highlight this approach. Better results are being produced in a noticeable and prominent manner by the projected flow. As a result, GPT-4's accuracy(pass@5) improved dramatically from 19% to 44% due to the introduction of an AlphaCodium flow, as compared to employing a simple, lengthy prompt [63]. The majority of methods used in this undertaking and the overall abstraction of the peace plan are applicable to a variety of coding tasks."}, {"title": "3.4 GitHub Copilot", "content": "GitHub Copilot is an AI-based code recommendation tool designed by GitHub. It acts as an Al code pair partner, helping you complete your code by giving suggestions as you type. It gives you the context of your code by auto-completing lines and functions. By doing so, you will recognize alternate ways of solving problems, write tests, and discover new APIs [35]. It can be installed as a plugin into your favored platform. It can be done using an individual subscription to GitHub Copilot or an organization subscription to GitHub Copilot Business [1, 15]. Filters are present in GitHub Copilot that eliminate offensive words in the prompts and generate phrases that are not sensitive. As a rule, GitHub Copilot is a tool that utilizes AI to enhance the coding experience by providing helpful hints and advice directly to an editor."}, {"title": "4 METHODS", "content": "In order to support the research questions, we analyzed 10 latest research papers that were published between 2022 and 2024 [21, 22, 48, 51, 55, 57, 58, 65, 66, 73]. We further attempted to determine which model performed based on two major metrics: pass@k and Test Case Pass Rate, which are described in Table 1. Furthermore, we conducted a comparison analysis using those evaluation metrics.\nPass@k: This metric assesses the likelihood that at least one of the k produced code samples passes all test cases for a particular problem. For example, the measure pass@1 is widely used across several models, including ChatGPT, Gemini, GitHub Copilot and AlphaCode to indicate the accuracy rate when only one generated sample is examined. Higher k values, such as pass@100, are used in some evaluations (e.g., Gemini-Ultra), allowing the model more attempts and offering a more comprehensive assessment of the model's capabilities when given more opportunities to create accurate solutions.\nTest Case Pass Rate: This metric measures the percentage of test cases that the generated code successfully passes. It is mostly used to evaluate AlphaCode and GitHub Copilot on platforms such as Codeforces and LeetCode. This statistic provides a detailed evaluation of the model's capacity to generate functionally valid code across a wide range of test situations, reflecting its accuracy and resilience."}, {"title": "5 EMPIRICAL RESULT", "content": "5.1 RQ1: Which model provides the most accurate code for programmers?\nChatGPT (GPT-4-Turbo-0125) emerges as the model providing the most accurate code for programmers. It achieved a pass@1 accuracy of 87.2% on the HumanEval benchmark. On the other hand, ChatGPT (GPT-4-Turbo-1106) has scored an accuracy of 81.7% on the HumanEval benchmark, which are among the highest scores reported. These results indicate that ChatGPT (GPT-4-Turbo-0125) is highly effective in generating correct code on the first attempt, making it a top choice for developers who need reliable and precise code outputs."}, {"title": "5.2 RQ2: What are the metrics are frequently used to evaluate LLM generated codes?", "content": "The most frequently used metrics to evaluate LLM-generated codes in the provided table are:\nPass@k: This is the most common metric used, indicating the success rate when only k number of code samples are generated and evaluated. It's used extensively across various models, including ChatGPT, Gemini, and others. We also discovered that 7 out of 10 the research papers used Pass@k metric.\nTest Case: This metric is used mostly for models like AlphaCode and GitHub Copilot. It evaluates the percentage of test cases that the generated code passes, offering a detailed assessment of the model's performance in real-world coding scenarios. Our research supports that 3 out of 10 papers had the use of Test Case Metric. These metrics help in comparing the effectiveness and reliability of different models in generating correct and functional code."}, {"title": "5.3 RQ3: What are the benchmarks are being used to evaluate LLM generated codes?", "content": "Table 2 demonstrates that 6 out of 10 research was conducted using HumanEval benchmark which is one of the widely used benchmark used to evaluate code generated by LLMs. Also, Test Case Pass Rate and Natural Code Bench are also becoming popular since HumanEval is a benchmark that has been using for a long time [51]."}, {"title": "6 CONTEXT", "content": "ChatGPT impresses with its ability to preserve discourse continuity by retrieving all the conversation material discussed. It relies on a bi-directional context window that is somewhat like real-time memory, enabling it to keep relevant tokens from the discourse [12]. This, in effect, makes Communications with ChatGPT seem natural and yields human-like responses. On the other hand, the downside of the technique is the use of a context window that sometimes generates answers that sound plausible but might be incorrect. Gemini's comparable success to ChatGPT is mainly attributed to its ability to demonstrate contextual understanding aided by Google's resources and workforce and its flexible context window. Gemini then uses its data center with the potential to utilize diverse datasets and accurately carry out the computations, which contributes to the rising performance level.\nDifferences can be drawn between AlphaCode and GitHub Copilot in that they are primarily involved in programming-oriented operations. AlphaCode, created by DeepMind, is a system for code production with no boundaries that shows the capacity to find solutions to complex problems that involve learning from algorithms and natural language [3]. It has demonstrated the ability to generate a code that can beat other programs in simulated competitions. It is already doing the middle work but that of complex solutions. By contrast, GitHub Copilot is an AI-backed tool for code completion that advises developers to make them guess the algorithm, finish the functions, and give context-based tips. Copilot applies a mixture of transformer-based classifiers and the contextual data diverted from the code editor to improve the developers' overall productivity and eliminate boilerplate code. However, these language models are developed with different spearheads, yet significant advances in Al-driven tools still occur in other spheres. Search and Interactions ChatGPT from OpenAI is a language model that uses Artificial Intelligence to create text similar to human language when considering context and past dialogues [26]. It employs transformer-based language models, which allow it to generate the code at a scale never seen before [20]. Gemini, from Google, is a soulmate for your creativity and productivity, and it aims to do so [7]. Google AI technology supports writing, planning, learning, and many other activities. GitHub Copilot is a code suggestion tool developed to improve code writing [9]. An AI double agent gives you a hint code as you are coding. You can use the power of GitHub Copilot by typing the code you need or by writing a natural language comment about what the code should perform [1]\nAlphaCode, the product from DeepMind, can write code in all programming languages for different tasks [49]. It transforms problem statements into code and accesses vast amounts of code to analyze and extract solutions from its patterns and learn new patterns [4]. Such technologies are compatible with many hosting environments and productive tools to maximize productivity and efficiency [23]. They use AI and machine learning to comprehend the context fully, create text that reads like human speech, give out code, and solve complicated problems. They are the known technological advancements in AI applications in chatting, coding, and problem-solving. Remember that these technologies might be powerful, but they are tools that should be applied cautiously to address a balanced approach [8]."}, {"title": "7 RESPONSE ACCURACY", "content": "One of the central metrics for LLMs is their response accuracy. This is the level of correctness, relevance, and coherence of their outputs [40]. The Google AI model Gemini has a built-in fact-checker feature that reached a median accuracy level of 3 when interpreting biochemical laboratory data [42]."}, {"title": "8 ETHICAL ISSUES", "content": "The ethical complications arising from using pre-trained models featured in the language learning models (LLM) like ChatGPT and the GitHub Copilot are undoubtedly prominent [71]. The biases in the training data can be inherited by the models with a large dataset due to the algorithm's unconscious bias of replication [23]. It is necessary to have safeguards to detect and defeat bias. However, these models without person-specificity cannot leak personal data unless this information has already been collected during training data. However, they may generate answers that sound half-done with sensitive information [16]. It, therefore, indicates a random set of generated text with actual information that exists rather than an actual unveiling.\nEven though these models are created to give more factual and beneficial information, they can produce convincingly wrong but credible information [43]. Procedures are still refined in this zone, and a sound test is crucial. Content ownership and copyright may be involved in massive disputes [46]. Thus, the best example could be written where GitHub copilot creates a core snippet, which might infringe on the original code authors' intellectual property rights [47]. They (Gemini, Alphacode, and Chat GPT) can produce a variety of text forms that are often indistinguishable from original content. Such models need mechanisms to address intellectual property rights and not violate associated forums [7].\nThe reality is that such models automate some tasks, which, in turn, might lead people to worry about its effects on the jobs available. In this regard, it should be admitted that the models themselves do not possess the limitless problem-solving capacity of the human brain and can only emulate specific skills. Again, suppose in mental well-being, employing chatbots can give rise to distinct ethical issues. Ethical frameworks should be developed to ensure accountability for these innovations."}, {"title": "9 FAIRNESS", "content": "All individual models, such as ChatGPT, Gemini, AlphaCode, and GitHub Copilot, share the critical issue of fairness in Al models [44]. These approaches offered by business enterprises such as OpenAI and Google offer ideas to increase fairness. However, inconsistencies and errors related to bias detection and generation are still around [34]. ChatGPT and Gemini have developed a code of conduct to promote impartiality in their answers. However, in some cases, these guidelines may not be followed. The equality of the parties is vital to both AlphaCode and GitHub Copilot since they interact with a vast body of users, and these parties emphasize working to ensure their outputs do not discriminate against any particular group [33].\nThe framework evaluates the fairness of LLM and found biased data and social and power structures within the chatbot ChatGPT [50]. Compared with the earlier GPT-3, there are observed changes through the newer version GPT-4 to a certain extent. However, bias detection in specific contexts remains a problem. An elementary issue when comparing the fairness of Gemini, AlphaCode, and GitHub Copilot metrics is that their fairness standards are less investigatory, which makes a direct comparison hard to do [44]. There are concerns regarding the ethical objectives of AI model development. This aspect might be misidentified due to programmers' biases. There is a perception that, regardless of how serious the problem, the writers do not adequately address these concerns of principle, particularly when developing these models, in contrast to the notion that the staff investments in developing the AI Principles are overly substantial. According to the research findings, fairness concerns have emerged in algorithmic applications such as ChatGPT and Gemini in a variety of fields. The question of whether AlphaCode and human code are of equivalent quality has also been aggressively sought, but no standard benchmark tool is currently available. However, there has been some research that may be useful in reducing gender prejudice induced by LLMs [72]. We can aspire for future research in this field to eliminate the various sorts of biases created by algorithms, data, selection, labeling, and so on."}, {"title": "10 LIMITATIONS", "content": "ChatGPT is a language model born due to OpenAI's efforts, which can handle a broad range of tasks, including translation of texts between languages, language generation via models, and dialogue development among humans. It can create human-like texts and is applicable for completing tasks such as stocking emails, coding, producing content, and others [26]. It does not, however, eliminate some drawbacks, such as providing erroneous information, responding inappropriately or incomprehensibly, and having trouble understanding some things. Gemini is a sophisticated artificial intelligence (AI) system developed by Google that is capable of reasoning over a variety of data formats, including words, code used audio, images, and videos [71]. It is fast, and every day, packages with the right answers are tapped more closely. However, a number of variables influence the algorithm's performance, which is solely dependent on the caliber and variety of the code it was trained on. The quality and dependability of the resulting code may be impacted if the data used to train it contains bias or gaps [67].GitHub Copilot, a joint creation by GitHub and OpenAI, provides the latter two as an interactive coding assistant in real time [14]. There are different opinions among the users, but it somehow deeply hooks the code environment and performs the task of code completion and suggestion quite professionally [49]. On the one hand, it can help to save time with code writing, but on the other, it can present code suggestions that contain some degree of errors, and improvement by the developer is still needed [17]. Alpha code, designed by DeepMind and named after the first letter of a DNA strand, is a fundamental AI programming model that helps programmers write code that is much more accessible [23]. It has an OpenAI Codex model for the semantic completion of code by replacing functions, entire functions, or giving algorithms in real-time [28]. On the other hand, it sometimes fails to perform correctly; for example, it would create a variable and its purpose [63]. Corporations' use of AlphaCode demands substantial computing resources, which the biggest tech companies use."}, {"title": "11 FUTURE WORK", "content": "At the doorway of a new age in AI, AI models should be at the forefront of the discussion to determine the direction that they will be heading. As Gemini has proven the increase in its implementation, it has been observed to have improved its performance. By comparison, the next-generation model, Gemini 1.5, shows significant cutting-edge changes in all aspects without exception [68]. It has delivered a breakthrough in processing tokens of extended contexts, which are as many as one million. This development will provide unforeseen capabilities and enable developers to bring more valuable models and applications to it. While the future of Google Gemini AI technology remains speculative, the more Google Gemini evolves, the more likely it will be to improve on existing services, providing customers with a more advanced, intuitive, and efficient user. At the same time, GitHub Copilot, focuses on adding support for chat and voice interfaces, handling pull requests, answering questions on docs, and anticipating GPT-4 down the line as the better and more personalized version [35]. Future software development powered by Al is demonstrated by GitHub Copilot X, the improved version, as the greatest aim of the AI computer. It is meant to revolutionize productivity by eliminating boilerplates and monotonous work, hence simplifying these intricate processes across the developer life cycle. One of the prominent AI tool, ChatGPT has already left its imprint in the computing field, as millions of people use ChatGPT without warning to use it ethically. It is highly likely that as ChatGPT and other language models get more complex and advanced, they will substitute for human workers for multiple tasks. However, they may not necessarily produce 100% accurate outputs. The code-generating AlphaCode system of DeepMind is capable of creating qualitatively new solutions to complex issues, and past versions, such as AlphaCode 2, have even achieved beating 85% levels of opponents on average in programming competitions [69].\nIn the future, AlphaCode is anticipated to be a tool competitive programming for programmers [25].\nThe recent achievements in models such as Gemini, ChatGPT, GitHub Copilot, and AlphaCode, which show quick gains and increased application at the dawn of a new era in AI, pave the way for important future developments. On benchmarks like HumanEval and Natural2Code, the Gemini Al models-especially Gemini 1.5 Pro and Gemini-Ultra-have demonstrated remarkable pass@100 rates, demonstrating their increasing capacity to manage challenging tasks with more precision. Similar results have been obtained by ChatGPT's many iterations, such as the GPT-4-Turbo models, which indicate that future iterations will probably continue to improve the system's dependability and efficacy. With its 2024 versions obtaining high test case success rates, GitHub Copilot has also shown efficacy in coding activities, solidifying its place as an increasingly important tool for developers. Even while AlphaCode could still use some refinement in competitive programming, it clearly has the potential to provide creative solutions, and next iterations should build on these strengths. These AI models have the ability to completely change sectors and increase productivity as long as they keep developing. Given these developments, we want to evaluate and further contribute to the continuous development of these state-of-the-art technologies by conducting our own code generation accuracy tests in the future."}, {"title": "12 CONCLUSION", "content": "Throughout this comprehensive review, we have investigated the architecture, capabilities, and performance of various artificial intelligence models and chatbots, including ChatGPT, Gemini, GitHub Copilot, and AlphaCode, emphasizing their profound impact on language understanding, code generation, and problem solving across a wide range of applications. With ChatGPT producing outstanding results in language processing benchmarks and Gemini demonstrating surprising prowess in tasks like Java code generation, these AI models have completely changed the software development landscape by offering tools that aid engineers in real-time. The fact that GitHub Copilot can offer code recommendations and real-time feedback emphasizes the technologies' revolutionary potential even more. But the review also identifies a number of serious difficulties, such as problems with accuracy, reliability, and morality. Even with these developments, AI systems are not perfect; frequently, they provide results that need human review and revision. The conversation on ethical AI technology use needs to continue, especially as these tools are incorporated more and more into everyday tasks. This study's empirical analysis highlights the present advantages and disadvantages of these AI helpers, emphasizing the need for ongoing development to increase their efficacy and dependability. Metrics such as pass@k and test case pass rates have been used to compare models and provide important insights into how well they perform. ChatGPT and Gemini have shown themselves to be formidable competitors in code generation jobs. The market for AI-powered tools is expected to continue expanding and innovating in the future. In order to ensure that these technologies are refined and suit the changing needs of both sectors and users, it will be essential that we carry out independent testing of code generation accuracy. Al has a bright future in software development and other fields, as long as the problems of ethics, justice, and accuracy are given the attention and concern they require. These technologies will surely become more and more important in determining the direction of programming and other fields as they develop."}]}