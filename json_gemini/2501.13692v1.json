{"title": "Training-Free Consistency Pipeline for Fashion Repose", "authors": ["Potito Aghilar", "Vito Walter Anelli", "Michelantonio Trizio", "Tommaso Di Noia"], "abstract": "Recent advancements in diffusion models have significantly broadened the possibilities for editing images of real-world objects. However, performing non-rigid transformations, such as changing the pose of objects or image-based conditioning, remains challenging. Maintaining object identity during these edits is difficult, and current methods often fall short of the precision needed for industrial applications, where consistency is critical. Additionally, fine-tuning diffusion models requires custom training data, which is not always accessible in real-world scenarios. This work introduces FASHIONREPOSE, a training-free pipeline for non-rigid pose editing specifically designed for the fashion industry. The approach integrates off-the-shelf models to adjust poses of long-sleeve garments, maintaining identity and branding attributes. FASHIONREPOSE uses a zero-shot approach to perform these edits in near real-time, eliminating the need for specialized training. The solution holds potential for applications in the fashion industry and other fields demanding identity preservation in image editing.", "sections": [{"title": "1. Introduction", "content": "Fashion image editing plays an essential role in today's digital and online fashion industry, with applications spanning e-commerce, marketing, and design. The ability to flexibly adjust images \u2013 altering garment poses, colors, or styles to suit various audiences and preferences stream- lines workflows and enhances customer experience [29]. Yet, non-rigid transformations, such as pose adjustments,"}, {"title": "2. Related Work", "content": "Image Generation for Fashion and Non-Rigid Editing. Generative Adversarial Networks (GANs) have long been central to image generation tasks, enabling realistic ma- nipulations for applications such as facial attribute editing and complex scene generation [14]. GANs utilize a dual- network setup, with a generator and a discriminator that it- eratively improve image quality, producing results that can appear photorealistic. However, GAN-based approaches face challenges in tasks requiring non-rigid transformations, such as altering garment poses, as they often struggle to maintain subject identity and visual consistency.\nProbabilistic diffusion models (DMs) represent a promising alternative approach to image generation, gen- erating images through an iterative denoising process that produces high-quality outputs with fine-grained detail [19]. A key advancement in diffusion models for controlled im- age generation is the development of conditioning tech- niques. These methods allow for flexible control over gen- erated images, accommodating inputs like text, sketches, or poses [10, 32, 37, 50]. For instance, Stable Diffu- sion enables text-conditioned image generation, which has inspired adaptations for fashion applications [37]. Re- cent work has further expanded these capabilities with image-conditioned models such as ControlNet, which en- ables pose-controlled generation by conditioning on spe- cific poses or sketches [52]. Such conditioning approaches are crucial for fashion image editing.\nTask-Specific Consistent Edits. Modern GANs and diffu- sion models generate high-quality images. However, main- taining image consistency in task-specific edits, particularly when non-rigid transformations are needed, presents a sig- nificant challenge. Preserving subject identity across mod- ifications is crucial in these situations. GANs can excel at modifying specific attributes while keeping others in- tact [31], but they often require extensive fine-tuning to han- dle task-specific edits. Diffusion models (DMs) have in- troduced flexibility with fine-grained controls, yet adapting them for task-specific image edits frequently involves spe- cialized fine-tuning, such as Low-Rank Adaptation (LoRA), which improves efficiency [22] but still requires retraining"}, {"title": "3. Methodology", "content": "We address the need for zero-shot garment pose normaliza- tion in fashion, introducing FASHIONREPOSE, a training- free pipeline that preserves garment identity and consis- tency across complex, non-rigid transformations."}, {"title": "3.1. Task Definition and Motivation", "content": "Task Definition. We aim to modify long-sleeve garments from an initial relaxed arm position (\"source pose\" or \"still- life\") to a standardized 45-degree arm-torso angle (\"target pose\"or \"normalized-pose\u201d) without altering other image elements (see Fig. 1):\n\u2022 Source (or still-life) Pose: Initial position with arms re- laxed close to the body, pointing towards the ground.\n\u2022 Target (or normalized) Pose: Desired configuration with arms raised at a 45-degree angle from the torso.\nMotivation. Traditional pose editing models require exten- sive retraining and large annotated datasets, making them inefficient for real-time, task-specific applications. This"}, {"title": "3.2. Pipeline Architecture", "content": "The proposed pose normalization pipeline (see Fig. 2) pro- cesses a single input image of a long-sleeve garment, trans- forming it into a normalized pose while preserving garment details such as color, texture, and branding. This training- free, zero-shot pipeline achieves near real-time results (un- der one minute) and consists of the following stages:\n1. Long Sleeves Detection: Identifies and filters out all im- ages that contain non-long-sleeve garments.\n2. Image Preprocessing: Preprocesses the input images and integrates the logo detection and suppression stages.\n3. Coarse Generation: Generates an initial, approximate normalized-pose garment using pretrained models.\n4. Conditioned Unsampling: Applies conditioned noise to shift garment features in the latent space.\n5. Source-Target Shape Matching: Aligns the generated garment shape with the original one using masks.\n6. Garment Parts-Composition: Combines the torso from the original image with the edited sleeves.\n7. Upsampling: Increases image resolution for enhanced quality using the 4\u00d7 Ultrasharp model.\n8. Logo Detection, Suppression, and Injection: Restores the logo to preserve brand identity across edits.\nEach stage contributes to the pipeline ability to achieve accurate, visually consistent edits with minimal process- ing time, essential for fashion applications where real-time, zero-shot consistency is paramount."}, {"title": "3.3. Long Sleeves Detection", "content": "The long-sleeve garment detection stage is a crucial prepro- cessing step designed to filter out images that do not feature long-sleeve upper-body garments. This filtering process en- sures that only relevant images are passed to the subsequent pipeline stages, optimizing efficiency. The detection is per- formed using a two-step approach:\n\u2022\n\u2022 a VGG16[41] CNN trained on a subset of DressCode [17];\na combination of Florence2[49] and LLaMa3-8b[9].\nThis filtering step, although not mandatory, excludes long- sleeve garments, ensuring smooth integration into real- world workflows. The subsequent stages, which perform the actual editing operation, are training-free, aligning with"}, {"title": "3.4. Image Preprocessing", "content": "In the preprocessing stage, the input image is resized to 512x512 and to 1024 \u00d7 1024 pixels. The former resolution is required to fit dataset specification of the Realistic Vision model a Stable Diffusion checkpoint trained on realistic images of people, objects and scenes\u00b3. The latter preserves more garment details during different stages of the pipeline. Each input image must adhere to the following specifica- tions in order to be properly processed:\n\u2022 the resolution must be at least of 1024 \u00d7 1024 pixels, to avoid poor quality images during the upscaling operation;\n\u2022 the aspect ratio should be 1:1 to avoid image cropping during the preprocessing step;\n\u2022 the background behind the garment have to be a clear solid white color.\nAdditionally, at this stage, the logo detection and suppres- sion logic is also implemented (see Sec. 3.10)."}, {"title": "3.5. Coarse Generation", "content": "This phase is responsible for producing an initial coarse normalized-pose garment that approximates the details con- tained in the source image (see Figure 3), leveraging differ- ent pretrained models, such as RealisticVision [37], Con- trolNet OpenPose [52], and IP-Adapter Plus [50]. Due to the presence of the occluded portions of the sleeves behind"}, {"title": "3.6. Conditioned Unsampling", "content": "In this stage (see Fig. 4), we adopt the unsampling tech- nique conditioned by both positive and negative embed- dings. The unsampling process consists of injecting con- ditioned noise up to a specific timestep and consequently removing it during the conditioned sampling process. This enables us to move into the latent space following the di- rection provided by the positive and negative embeddings. In our scenario, we are moving from a point in which the sleeves are closed to a point in which the sleeves are opened (see Fig. 4). To enforce the target pose and preserve the shape of the initial garment, we leverage both the Control- Net OpenPose and ControlNet Canny models [52]. The ini- tial latent code is obtained through a gradient-mask blend- ing operation of the still-life and pose-normalized latents."}, {"title": "3.7. Source-Target Shape Matching", "content": "Since the generated normalized-pose image did not align properly with the still-life version, a shape-matching algo- rithm is employed to adjust the scaling factor to ensure ac- curate alignment (see Fig. 6). The algorithm uses the source and target silhouette masks of the garment as input. The scaling factor is calculated based on a section of the torso with $b \\times h$ pixels, where $b$ is the band width (30 pixels) and $h$ is the full height of the image (512 pixels). A bounding- box is used to measure the height of the white-filled parts in the masks, computing the scaling factor and the offset. Afterwards, the images are resized and combined together."}, {"title": "3.8. Garment Parts-Composition", "content": "The garment parts-composition stage is crucial to assem- bling the final image through the image composition tech- nique. Although most of the characteristics of the garment are preserved during the previous step, some alterations may occur during the process. Consequently, in this stage we improve the identity of the garment by a composition in the pixel space of the torso from the still-life image and the opened sleeves from the edited one. The algorithm de- termines the portions of the image in which the torso and"}, {"title": "3.9. Upsampling", "content": "To enhance the overall quality of the image, a final upsam- pling stage is integrated into the pipeline. This component upscale the resolution from 512x512 to 1024 \u00d7 1024 pixels via 4xUltrasharp model [45]."}, {"title": "3.10. Logo Detection, Suppression, and Injection", "content": "To better preserve the identity of the garment, a logo restoration phase is introduced. It detects the logo in the initial still-life image, suppresses it for the subsequent dif- fusion tasks and re-injects it at the end of the pipeline (see Fig. 7).\nLogo Detection. Detecting the logo in the original still-life images is essential to preserve brand identity across edits. To accomplish such a task, an approach based on Florence2 and SAM2 is proposed. Florence2 detects the logo in the"}, {"title": "4. Experiments", "content": "In this section, after an overview of the experimental setup, we validate the effectiveness of our pipeline from both a quantitative and a qualitative perspective. Additionally, we conducted an extensive ablation study of the pipeline stages."}, {"title": "4.1. Experimental Setup", "content": "All the experiments are conducted on a workstation equipped with a NVIDIA RTX 4090 GPU with CUDA 12.56 and driver version 555.52.047. We are using the IP- Adapter Plus [50] with CLIP ViT-H/14 LAION-2B [5, 24, 34, 39] to enforce strong reference image conditioning. To guide the unsampler and sampler diffusion processes, we leverage a ControlNet OpenPose and a ControlNet Canny [52] v1.1 production models, both for positive and nega- tive conditionings. For the cloth segmentation mask, we integrated Florence2 [49] and SAM2 [36]. For the logo de- tection task, we utilize Florence2 and LLaMa3 Instruct 8b [9]. We utilized Realistic Vision v5.1 [37] as stable diffusion"}, {"title": "4.2. Quantitative Evaluation", "content": "A comprehensive quantitative analysis was performed to test the effectiveness of the proposed solution (see Table 1).\nDatasets. The pipeline was evaluated on two different fash- ion datasets: DressCode [17] and VITON-HD [6], consid- ering only images of upper body garments. We conducted an additional study on a subset of VITON-HD containing only upper body clothing with brand logos, to demonstrate the effectiveness of the last stage of the pipeline.\nBaselines. We considered as baselines MasaCtrl [3], Null- text Inversion [30], Tuning-free Inversion-enhanced Control (TIC) [8], Free-Prompt-Editing (FPE) [27], and ControlNet [52]. TIC and FPE architectures were re-implemented from scratch starting from the information in the original papers.\nEvaluation Metrics. To support our study, the baselines are evaluated against different quantitative metrics [21], such as Learned Perceptual Image Patch Similarity (LPIPS) [53], Peak Signal-to-Noise Ratio (PSNR), and Structural Simi- larity Index Measure (SSIM) [46]. Despite the better quan-"}, {"title": "4.3. Qualitative Evaluation", "content": "A qualitative comparison is presented in Figure 8. Our method is the only one capable of solving the pose- normalization task, giving a still-life image of the garment.\nDetails about the prompts and more examples are available in the supplementary material."}, {"title": "4.4. Ablation Study", "content": "A comprehensive ablation study was conducted on different stages of the pipeline. In Table 2, we summarize the results obtained for each metric. As additional stages are incremen- tally incorporated into the pipeline, an increase in metrics can be observed up to the part composition stage. Between the part composition stage and the logo restoration stage, a deterioration in performance is observable in both datasets. This is related to the additional noise introduced by the last operation. The DressCode and VITON-HD datasets lack a substantial number of garments with brand logos, nega- tively impacting the metrics of this stage. Thus, the anal- ysis was performed on a subset of VITON-HD, containing"}, {"title": "5. Conclusion and Limitations", "content": "Conclusion. In this work, we presented FASHIONREPOSE, a novel training-free pipeline for pose normalization in the fashion domain. Our approach enables non-rigid edits on images of long-sleeve upper body garments, enabling near- real-time editing without model retraining or fine-tuning. Leveraging pretrained models and a multistage architec- ture, we achieve precise control over the editing process while maintaining consistency in shape, color tones, and lo- gos. Experimental results on diverse datasets demonstrate the effectiveness of the method in preserving garment iden-"}, {"title": "6. Overview", "content": "This supplementary material provides additional informa- tion on the proposed FASHIONREPOSE pipeline. Specifi- cally, we include further implementation details and more examples to validate our work.\nThe supplementary material is structured as follows:\n\u2022 Additional Implementation Details: Contains details regarding the text prompts utilized in both the baselines and in our pipeline.\n\u2022 Additional Qualitative Examples: Compares our methodology with other state-of-the-art baselines, show- casing more qualitative examples.\n\u2022 Additional Qualitative Ablation Study: Demonstrates the effectiveness of each stage of the pipeline in main- taining garment identity, showcasing more qualitative ex- amples."}, {"title": "7. Additional Implementation Details", "content": "This section presents a detailed description of the prompts employed in our study, allowing for precise control over the generated output. The text prompts are utilized both in the baselines and in different stages of our pipeline."}, {"title": "7.1. Baselines", "content": "To evaluate the performance of FASHIONREPOSE, we benchmarked against different text-to-image and pose-to- image baselines commonly used in image editing tasks, such as MasaCtrl [3], Null-Text Inversion [30], Tuning-Free Inversion-enhanced Control (TIC) [8], Free-Prompt Edit- ing (FPE) [27], and ControlNet [52]. Figure 11 illustrates the task-specific structured text prompt to perform pose edit for text-to-image models. The experiments show that, with the exception of ControlNet, all the aforementioned meth- ods failed to achieve meaningful pose transformations (see Fig. 8). Furthermore, all of them introduce visual artifacts and unintended alterations, which ultimately compromise the consistency of the garment (see Sec. 4.3 and Sec. 8)."}, {"title": "7.2. Long Sleeve Detection", "content": "The long-sleeve detection stage comprises two steps of the FASHIONREPOSE pipeline, introduced in Section 3.3.\nFirst step. In the first step of long-sleeve detection pro- cess, we utilize a VGG16-based Convolutional Neural Net- work (CNN), which has been fine-tuned to identify long- sleeve garments. The VGG16 model was selected due to its proven ability to effectively capture visual character- istics in images, which is crucial for distinguishing long- sleeve clothing from other types of garments. During train- ing, the model optimized with RMSprop, achieved an accu- racy of 97%, outperforming alternative architectures such as ResNet50 (95% accuracy) and InceptionV3 (94% accu- racy). This detection step filters out non-long-sleeve gar- ments, i.e., short and no sleeve clothing, ensuring that only relevant images are processed in the subsequent stages of the pipeline. Importantly, this step is designed to facilitate seamless integration into pre-existing industry workflows, as discussed in Section 3.1. This alignment with opera- tional processes ensures that the pipeline not only maintains technical efficiency but also meets practical requirements for scalability and deployment in real-world scenarios.\nSecond step. In this step, text prompts are employed to re- fine the identification process of long-sleeve clothing. This additional filtering phase guarantees that only relevant gar- ments are advanced to the subsequent stages of the pipeline, enhancing the reliability of detection and reducing false positives rate. This stage leverages Florence2 [49] and LLaMa3-8b [9] pretrained models. Florence2 generates a detailed caption that describes the still-life garment (see Sec. 3.1 for still-life definition), including attributes such as sleeve type, texture, and overall garment structure. The re- sulting caption is subsequently processed by LLaMa3 an open source Large Language Model (LLM) by Meta \u2013 to de- tect and accurately discriminate long and non-long sleeves imagery. To allow the LLM to determine whether the gar- ment in the image contains long sleeves or not, we lever- aged a string concatenation of a preamble followed by the detailed description generated by Florence2 (see Fig. 12)."}, {"title": "7.3. Logo Detection and Suppression", "content": "The logo detection phase and the logo suppression phase are introduced and described in Section 3.10 of the pipeline.\nLogo Detection. This stage integrates the capabilities of Florence2 and SAM2 [36] to respectively localize and gen- erate a precise segmentation mask of the logo. Specifically, Florence2 utilizes a targeted caption to guide the localiza- tion process withing the garment image, through a struc-"}, {"title": "7.4. Conditional Unsampling", "content": "The conditional unsampling phase is an essential step in re- fining garment pose transformations to ensure that garment identity and visual fidelity are consistently maintained (see Sec. 3.6). In this stage, we apply conditioned noise to mod- ulate the garment features within the latent space, enabling a precise alignment with the target pose while preserving garment-specific attributes.\nTo achieve these results, we leverage a combination of positive and negative prompts to guide the model's unsam- pling process effectively (see Fig. 15). The positive prompt used in this stage consists in a detailed caption generated by Florence2. This description is beneficial for informing the model about what characteristics must be retained through- out the editing process. In addition, a negative prompt is employed to prevent the generation of undesirable features during the unsampling phase. The negative prompt is struc- tured according to Realistic Vision author's guidelines 8, explicitly excluding undesirable features such as deformed body parts, low-quality renderings, and unrealistic effects. This targeted approach ensures that the unsampling process focuses on refining the pose transformation while preserv- ing the garment's realistic appearance."}, {"title": "8. Additional Qualitative Examples", "content": "In this section, we present additional qualitative examples that illustrate the efficacy of the FASHIONREPOSE pipeline in achieving consistent garment pose normalization. The examples demonstrate that our approach preserves garment identity, texture fidelity, and branding attributes while tran- sitioning the garment from its initial pose to a normalized"}, {"title": "9. Additional Qualitative Ablation Study", "content": "This section provides additional qualitative examples to il- lustrate the contribution of each stage of the pipeline. The following figures highlight the impact of each stage on the quality of the final output.\nFigure 19 presents an ablation study on garments from the DressCode [17] dataset, illustrating the contributions of each stage of the FASHIONREPOSE pipeline. Beginning with coarse generation, each subsequent stage includ- ing conditional unsampling, parts composition, and logo restoration demonstrates its role in enhancing garment identity and visual consistency. As new stages are intro- duced, significant improvements are observed in preserv- ing garment features and reducing artifacts, underscoring the importance of each stage in delivering high-quality pose normalization. The addition of conditional unsampling (c) refines garment identity details and reduces artifacts po- tentially present in the coarse generation (b). The parts composition stage (d) improves the garment's structural in- tegrity, while logo restoration (e) successfully reintegrates the brand logo without introducing noticeable inconsisten- cies. Figure 20 illustrates an ablation study conducted on the VITON-HD [6] dataset further confirming the previous observations. Finally, Figure 21 provides an ablation study specifically focused on garments with logos, using a subset of the VITON-HD dataset. The progression from coarse generation to logo restoration demonstrates the essential role of the logo workflow in achieving coherent, identity- preserving edits."}]}