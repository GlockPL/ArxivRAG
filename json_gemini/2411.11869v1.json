{"title": "A MULTI-MODAL UNSUPERVISED MACHINE LEARNING\nAPPROACH FOR BIOMEDICAL SIGNAL PROCESSING IN CPR", "authors": ["Saidul Islam", "Jamal Bentahar", "Robin Cohen", "Gaith Rjoub"], "abstract": "Cardiopulmonary resuscitation (CPR) is a critical, life-saving intervention aimed at restoring blood\ncirculation and breathing in individuals experiencing cardiac arrest or respiratory failure. Accurate\nand real-time analysis of biomedical signals during CPR is essential for monitoring and decision-\nmaking, from the pre-hospital stage to the intensive care unit (ICU). However, CPR signals are often\ncorrupted by noise and artifacts, making precise interpretation challenging. Traditional denoising\nmethods, such as filters, struggle to adapt to the varying and complex noise patterns present in CPR\nsignals. Given the high-stakes nature of CPR, where rapid and accurate responses can determine\nsurvival, there is a pressing need for more robust and adaptive denoising techniques. In this context,\nan unsupervised machine learning (ML) methodology is particularly valuable, as it removes the\ndependence on labeled data, which can be scarce or impractical in emergency scenarios. This paper\nintroduces a novel unsupervised ML approach for denoising CPR signals using a multi-modality\nframework, which leverages multiple signal sources to enhance the denoising process. The proposed\napproach not only improves noise reduction and signal fidelity but also preserves critical inter-signal\ncorrelations (0.9993) which is crucial for downstream tasks. Furthermore, it outperforms existing\nmethods in an unsupervised context in terms of signal-to-noise ratio (SNR) and peak signal-to-noise\nratio (PSNR), making it highly effective for real-time applications. The integration of multi-modality\nfurther enhances the system's adaptability to various biomedical signals beyond CPR, improving\nboth automated CPR systems and clinical decision-making.", "sections": [{"title": "1 INTRODUCTION", "content": ""}, {"title": "1.1 PROBLEM STATEMENT", "content": "Cardiopulmonary resuscitation (CPR) is a vital, life-saving technique that can make a significant difference in medical\nemergencies by restoring blood flow and breathing in individuals experiencing cardiac arrest or respiratory failure.\nThe primary objective of CPR is to keep the heart pumping and ensure continuous oxygenated blood flow to vital\norgans, particularly the brain (Raza et al., 2021). The American Heart Association, alongside other global health\norganizations, underscores the significance of CPR training, not just among healthcare professionals but also among\nthe general public (Hinkelbein et al., 2020), as the majority of cardiac arrests occur outside of hospital settings,\nwhere immediate medical intervention may not readily available. In such scenarios, manual, human-driven CPR\nis predominantly practiced despite several difficulties and challenges that hinder successful CPR. For instance,\nperforming CPR is physically demanding for individuals, even for health care providers for an extended period."}, {"title": null, "content": "Moreover, it is difficult to maintain the correct compression depth, rate, and consistency. Additionally, obtaining\nreal-time feedback is significantly challenging, which is very crucial during the initial treatment in ambulances or\nhospital environments. To address these limitations, there has been a growing need for automated CPR systems\nover the last two decades, driven by advancements in mechanical devices within the healthcare system (Swor et al.,\n2006). Automated CPR systems offer the potential to enhance the effectiveness of life-saving interventions by\nensuring optimal compression and decompression at precise intervals for long periods. However, automating CPR\nfaces several challenges related to decision-making and accuracy in compression and decompression. In this regard,\nArtificial intelligence(AI), particularly machine learning (ML), offers a promising way to address these limitations in\nmedical operations. ML is capable of identifying complex patterns in biomedical data, improving the quality of CPR\nin medical systems, enhancing diagnostic accuracy, and enabling real-time monitoring of CPR in diverse medical\nconditions (Hallstrom et al., 2006). Furthermore, various biomedical signals associated with CPR-such as blood\npressure, velocity, force, and respiratory waveforms-play a critical role in guiding treatment decisions, particularly\nin intensive care units (ICUs). Accurate monitoring and processing of these signals during CPR is essential for\nassessing patient response, informing medical interventions, and ultimately improving patient outcomes (Hurt, 2005)."}, {"title": null, "content": "CPR signals are inherently dynamic and time-sensitive, requiring specialized approaches for effective processing and\ndecision-making. Moreover, these signals are often corrupted by various types of noise sources, including baseline\nwander, electrode artifacts, motion artifacts, and electromagnetic interference, which significantly degrade signal\nquality and complicate interpretation (Fitzgibbon et al., 2002). Ensuring the integrity and quality of signal data is\ncrucial for effective ML approaches in accurate decision-making for CPR automation and monitoring systems. While\ntraditional signal processing techniques such as filtering, offer some improvements, they often struggle to remove\nnoise effectively without compromising essential physiological features (Luong et al., 2013). Since CPR is a process\nof emergency healthcare, where decision-making can directly impact survival, it is unacceptable to compromise the\nquality of the signal. Therefore, achieving effective denoising while preserving key signal characteristics is essential.\nMoreover, one limitation of conventional filters lies in their dependence on predefined parameters such as cutoff\nfrequencies or filter orders and assumptions regarding noise characteristics, which may not correspond to the\ncomplex and dynamic nature of real-world CPR signals. Traditional filters often struggle to effectively remove noise\nwithout inadvertently distorting or attenuating important signal components, leading to the potential loss of valuable\ninformation. Additionally, filters are generally tailored to specific noise types or signal modalities, limiting their\nadaptability to diverse noise profiles and environments (Seron et al., 2012). These inherent constraints underscore\nthe need for more flexible and adaptive denoising techniques capable of preserving critical signal features. Given\nthe high-stakes nature of CPR, where accurate signal interpretation is a matter of life and death, overcoming these\nlimitations is essential for advancing automated CPR systems and improving patient outcomes."}, {"title": null, "content": "The application of machine learning (ML) has emerged as a promising approach to tackling critical tasks in medical\nsystems. ML excels at identifying complex patterns and relationships within biomedical data, offering solutions\nthat can enhance diagnostic accuracy, improve healthcare systems, and enable real-time monitoring across a variety\nof medical conditions (Blum & Langley, 1997). Within the domain of CPR, integrating ML presents unique\nopportunities, as CPR signals are both dynamic and time-sensitive, requiring specialized approaches for effective\nprocessing and decision-making. ML-based approaches, particularly for tasks such as denoising and signal enhance-\nment, demonstrate the ability to learn from diverse, heterogeneous, and noisy data, thus showing great potential in\ndeciphering the intricate nuances inherent in CPR signals. Moreover, recent advancements in computational power,\nparticularly with the advent of high-performance GPUs and cloud computing platforms, have significantly improved\nthe feasibility of deploying ML algorithms in real-time applications, thus facilitating timely insights in critical\nmedical scenarios such as CPR (Azghadi et al., 2020). Such advancements can substantially improve the accuracy\nand reliability of real-time monitoring during life-saving interventions. However, despite these promising prospects,\napplying ML algorithms to CPR signal denoising presents several notable challenges. These include the development\nof robust feature extraction methodologies that are tailored to the unique characteristics of CPR signals, selecting\nappropriate ML frameworks and models capable of processing temporal data and noise, and acquisition of labeled\ndatasets for supervised learning tasks (Schelter et al., 2015). Existing ML approaches for CPR signal denoising are\npredominantly supervised, relying on clean labeled data that corresponds to noisy signals. In real-world scenarios,\nobtaining such labeled data is extremely difficult, if not impractical, thereby limiting the applicability of supervised\nML methods. Consequently, there is a clear need for an unsupervised ML approach dedicated to CPR signals that\ncan effectively denoise CPR signals without reliance on labeled data. Currently, no unsupervised ML methodology\nspecifically designed for CPR signal denoising has been developed, leaving a gap in the existing research landscape."}, {"title": "1.2 NOVELTY AND CONTRIBUTIONS", "content": "In this paper, we address the challenges by introducing an advanced method for CPR signal denoising and artifact\nremoval, aimed at enhancing patient outcomes and healthcare delivery. A novel unsupervised ML methodology\nhas been proposed, specifically designed for denoising biomedical signals during CPR. The framework introduces\na multi-modality approach, enabling the concurrent processing of multiple signals while addressing the noise\ncharacteristics of each signal individually. This individualized signal processing facilitates the extraction of unique\nfeatures, thereby improving the overall denoising process and enhancing the accuracy of signal interpretation. A\nkey feature of the proposed framework is its use of unsupervised ML, which demonstrates the method's capability\nto effectively remove noise and enhance signal fidelity without the need for labeled data. By identifying underlying\nstructures and patterns in noisy CPR signal data, this approach is particularly well-suited for real-world applications,\nwhere labeled ground truth is often scarce or unavailable. The key contributions of this paper are as follows: (i)\na comprehensive exploration of existing denoising approaches for CPR signals, (ii) the introduction of a novel\nmulti-modal ML methodology that processes multiple signals simultaneously, (iii) the use of an unsupervised ML\napproach, eliminating the dependency on labeled data, (iv) the generation of synthetic biomedical CPR signals for\nresearch purposes, and (v) the conceptualization of a multi-modal ML framework for enhanced decision-making in\nmedical emergencies."}, {"title": null, "content": "Moreover, a comprehensive comparison of the proposed method has been conducted with existing ML and filter meth-\nods in an unsupervised context to justify the performance of the proposed methodology. The effectiveness of the\nmethodology is demonstrated through visualizations, as well as signal-to-noise ratio(SNR) and peak signal-to-noise\nratio(PSNR) scores. Notably, the method successfully preserves the signal data correlations at a significant level,\neven while processing each signal through dedicated models and subsequently combining them. To illustrate this, the\ncorrelations matrix before and after the denoising process have been calculated and quantified the differences by deter-\nmining the correlation coefficients, which are crucial for downstream tasks. The results highlight the potential of this\napproach to enhance biomedical signal processing not only in CPR scenarios but also in border medical contexts. The\npaper is organized into six sections, the current section discusses the context and motivation behind this paper, while\nSection 2 presents a review of related literature, highlighting the limitations of existing methods and differentiating\nour contributions. Section 3 outlines the preliminary concepts essential for the proposed methodology. The details of\nthe methodology and proposed solution are presented and depicted in Section 4. Importantly, Section 5 showcases the\noutput results compares the findings with the existing methods, and extends the discussion to data correlation preser-\nvation. Section 6 presents a discussion addressing the scope of explainability, and exploring the application of the\nmulti-modality concept in decision-making processes that integrate multiple sources of information during medical\nemergencies. Finally, Section 7 summarizes the key findings and contributions of this paper."}, {"title": "2 RELATED WORK", "content": "This section explores the landscape of denoising techniques for biomedical signals, specifically focusing on CPR sig-\nnals. While several ML-based methods for denoising electrocardiogram (ECG) signals have been widely researched,\nthe consideration of ECG signal denoising techniques has been intentionally set aside due to the significant differences\nbetween ECG and CPR signals. Unlike ECG signals, which are electrical recordings of the heart's activity, CPR\nsignals are mechanical signals generated during chest compressions. Additionally, ECG signals exhibit characteristic\nwaveforms representing different phases of the heart's electrical activity, while CPR signals exhibit even more\ncomplex patterns and instead represent the rhythmic application of pressure to the chest. Furthermore, ECG signals\nare typically measured using electrodes placed on the skin surface and analyzed for cardiac rhythm abnormalities\n(Gacek, 2011). On the contrary, CPR signals are measured using external sensors during CPR maneuvers to monitor\nchest compression effectiveness. Importantly, CPR signals involve multiple signals from different body parts,\nincluding the abdomen, necessitating dedicated fashion denoising methods due to their unique characteristics (Baubin\net al., 1995). Consequently, there is an urgent need for robust and automated denoising techniques using a dedicated\nmethodology that can enhance the quality of CPR signals by removing artifacts and facilitating accurate clinical\ndecision-making."}, {"title": "3 PRELIMINARIES", "content": "The proposed approach uses advanced ML concepts and techniques that are carefully selected to address the dynamic\nand urgent nature of CPR signals. The framework considers various types of noise and interference that can\ncompromise the integrity of these signals, such as baseline wander, motion artifacts, and electromagnetic interference,\nand aims to enhance the overall signal quality during processing. The core of this method integrates a multi-modality\nconcept alongside several ML techniques, including autoencoders, convolutional neural networks (CNNs), and\nresidual connections. Each component plays a crucial role in forming an unsupervised CPR signal processing\nframework."}, {"title": "3.1 MULTI-MODALITY APPROACH", "content": "There are several motivating factors for choosing a multi-modality approach for effective CPR signal processing.\nFirst, it holds substantial promise for improving healthcare effectiveness by integrating various types of medical\ndata, leading to more comprehensive, accurate, and personalized patient assessments Muhammad et al. (2021).\nIn addition, multi-modality can enhance model transparency and the overall explainability of AI applications in\nhealthcare, opening doors to a broader range of clinical applications and making outcomes more interpretable for\npractitioners Yang et al. (2022), Wang et al. (2020). In general, multi-modal deep learning is an approach that\nintegrates information from various types of data, like text, images, and audio, to enhance model performance and\naccuracy. In this method, each data modality is initially processed independently using specialized neural networks\ntailored to the specific characteristics of that modality, as illustrated in Figure 1. These networks extract high-level\nfeatures from the data and encode them into lower-dimensional representations, capturing essential patterns while\nreducing noise and redundancy. Once features from each modality are extracted, they are fused into a single, unified\nrepresentation. This can happen early on when the raw data is combined before processing to learn cross-modal\nrelationships, or later when the processed features are combined using different methods (Su et al., 2021)."}, {"title": "3.2\nAUTOENCODER", "content": "An autoencoder is a type of artificial neural network designed to efficiently represent data by making its output\n(reconstructed data) as close as possible to the clean input data. It can be used in two main ways: supervised\nand unsupervised. In the supervised method, pairs of noisy input data and their corresponding clean versions are\ngiven to the autoencoder for training. However, in the unsupervised approach, only noisy input data is used for\ntraining, without any clean data. During training, the autoencoder learns to encode the noisy input data into a hidden\nrepresentation, capturing the important patterns and structure of the data (Feng et al., 2024)."}, {"title": "3.3 CONVOLUTION NEURAL NETWORK", "content": "One-dimensional Convolutional Neural Networks (1D CNNs) are essential components in deep learning architectures,\nknown for their ability to capture intricate complex patterns and spatial relationships within sequential data. A typical\n1D CNN consists of three primary components: convolutional layers, pooling layers, and fully connected layers, each\nserving a distinct function. In the convolutional layer, learnable filters are applied to input data using convolution\noperations, generating feature maps that encode local patterns (Kiranyaz et al., 2019). These filters learn to detect\nspecific features by scanning across the input data's spatial dimensions. Pooling layers are responsible for reducing\nthe size of feature maps while preserving important information. Techniques like max pooling or average pooling\naggregate feature map values within localized regions, help to summarize feature presence across different areas and\nimprove computational efficiency. Finally, fully connected layers combine extracted features from previous layers,\nallowing the network to perform specific tasks. These layers establish connections between all neurons in adjacent\nlayers, facilitating the representation of high-level features and making predictions tailored to the task at hand (Li et al.,\n2021). Mathematically, the 1D CNN can be represented as follows: Given an input sequence $X_{input}$ with dimensions\n(N, L, 1), where N is the number of samples, L is the sequence length (number of time steps), and 1 represents the\nsingle feature dimension, the output $X_{cnn}$ of the 1D CNN component can be obtained as follows:\n$Xcnn = Conv1D(Xinput, filters = n, kernel_size = n, activation = ReLU)$                                                                                                                     (1)"}, {"title": null, "content": "where Conv1D denotes the 1D convolution operation with n number of filters and a kernel size of n. activation\nfunction is applied to introduce non-linearity, here for instance ReLU (Rectified Linear Unit).\nNext, a MaxPooling1D layer with a pool size of n is applied to downsample the data and reduce the com-\nputational complexity:\n$Xcnn = \u041c\u0430\u0445Pooling1D(Xcnn, pool_size = n)$                                                                                                                                         (2)\nTo capture more intricate patterns, more 1D CNN layers can be added, comprising n filters with a kernel size of n and\nactivation function. Furthermore, more Max Pooling1D layers also can be applied to further downsampling the data\n(Zhang et al., 2023)."}, {"title": "4 METHODOLOGY AND PROPOSED SOLUTION", "content": ""}, {"title": "4.1 OVERVIEW AND FRAMEWORK", "content": "CPR signals are highly correlated, presenting challenges in automating their processing. Traditional ML methods\ntreat signals collectively, but denoising while preserving their interrelationships is difficult due to each signal's unique\ncharacteristics (Assegie et al., 2021). To address this, we propose an ML-based methodology that denoises each\nsignal individually while maintaining their correlations, improving accuracy and reliability for downstream tasks\nlike real-time monitoring. In the proposed framework, the concept of multi-modality is leveraged to simultaneously\nprocess multiple signals while individually denoising each signal before amalgamating them into a unified input data\nshape, as depicted in Figure 3. Each signal is treated as a distinct modality, and accordingly, processed with a separate\nmodel tailored to its unique characteristics and requirements. This approach ensures that each signal is effectively\ndenoised while preserving its individual attributes. After the separate processing of each signal with dedicated models,\nthe outputs are fed through a feed-forward network, where they are combined into a unified input. The feed-forward\nnetwork facilitates the integration of the denoised signals into a coherent and cohesive format, resembling the original\nnoisy input data but in a denoised form. Subsequently, the denoised output from the feedforward network is prepared\nfor downstream tasks or feature utilization in machine learning applications aimed at CPR automation."}, {"title": null, "content": "The selection of an appropriate model for each modality or signal is a critical aspect in achieving effective denoising\nof CPR signals. Given the primary objective of this framework-denoising\u2014the autoencoder model is employed\ndue to its flexibility for use in both supervised and unsupervised learning settings. While the supervised approach\ninvolves training the autoencoder with pairs of noisy input data and corresponding clean data, the unsupervised\nmethod is chosen for considering our real-life scenario. In this unsupervised setting, the autoencoder learns to encode\nnoisy input data into a latent representation, capturing underlying structures and patterns without relying on labeled\nclean data and then generating new data from the latent space using the decoder. Several architectural variations of\nautoencoders exist, such as RNNs, LSTMs, CNNs, and attention-based models (Ling et al., 2024). Given the need\nto capture local features and complex patterns in the CPR signals, CNN-based denoising autoencoders have been\nadopted across all modalities. CNNs are particularly well-suited for this task due to their capacity for effective feature\nextraction and their robustness in handling noise variations, making them ideal for processing biomedical signals. The\nstandardized use of CNN-based autoencoders ensures consistent performance across different signals. By leveraging\nCNNs' strengths in capturing spatial dependencies and hierarchical patterns, the approach is capable of demonstrating\npromising efficacy in mitigating noise artifacts and enhancing the fidelity of biomedical signals for improved analysis\nand interpretation (Thuwajit et al., 2022)."}, {"title": null, "content": "The CNN-based autoencoder model in the proposed framework enables the network to automatically discern relevant\nfeatures across various spatial scales, enhancing its ability to capture intricate patterns within the data. In our\nautoencoder, two(2)layers of 1-dimensional CNN are deployed in both the encoder and decoder. After each of the\n1D-Convolution layers, a max-pooling-1D layer has been placed in the encoder to compress the signals into latent\nspace, as in Figure 4. However, upsampling 1D layers have been used in the case of the decoder to generate signals\nfrom the latent space. One notable enhancement in our autoencoder is the incorporation of a residual connection.\nThis connection involves introducing an additional convolutional layer after the last max-pooling-1D layer in the\nencoder, which captures supplementary features or representations from the encoder's output (Qassim et al., 2018).\nSubsequently, the output of this residual layer is combined with the output of the last convolutional layer of the\nencoder. This combined output is then passed through upsampling layers to prepare it for concatenation with the\ninput of the decoder. By incorporating the residual connection in this manner, the autoencoder is enabled to leverage\nthe information captured by the residual layer, enhancing its denoising capabilities. This process facilitates the\npropagation of relevant features while minimizing the impact of noise, thereby enabling the autoencoder to learn more"}, {"title": "4.2 METHODOLOGY IMPLEMENTATION", "content": "Accessing real-world medical data, particularly CPR data poses significant challenges due to privacy concerns and\nregulatory constraints. These limitations make it difficult to utilize actual patient data for machine learning (ML)\nresearch in the CPR context. Despite an extensive search for publicly available CPR datasets, all identified datasets\nare private and restricted, creating a significant barrier to progress in this field. As a result, alternative data sources\nare necessary to advance research and development. To overcome this obstacle, the generation of synthesized data\nhas emerged as a viable solution. Simulated data allows for experimentation, algorithm development, and validation\nwhile avoiding privacy issues and regulatory hurdles. The Babbs model, a well-established mathematical model for\nsimulating CPR processes, was identified as the most suitable framework for this task (Shin & Lee, 2021, Jalali\net al., 2015). This model is renowned for its ability to accurately replicate the complex dynamics of CPR, including\nvariations in signal morphology and the introduction of realistic noise. By leveraging the Babbs model, realistic\nCPR scenarios are simulated, enabling robust research into CPR signal processing, monitoring systems, and decision-\nmaking algorithms without compromising patient confidentiality (Fitzgerald et al., 1981)."}, {"title": "4.2.1 DATA GENERATION", "content": "The Babbs model is a comprehensive mathematical framework that describes the physiological changes occurring\nduring CPR. It allows for real-time calculations of coronary perfusion pressure (CPP) based on chest compression\nparameters. The model can mimic the dynamic changes in the elastance and resistance of the arterial system during\nCPR, influenced by factors such as chest compression depth, rate, and duty cycle (Babbs et al., 1984). This provides\na quantitative method to optimize these parameters to achieve the desired CPP, which provides improved perfusion\nduring CPR. Specifically, the Babbs model incorporates variables like chest compression depth (D), compression rate\n(R), and duty cycle (Duty), and analyzes their effects on CPP and other physiological parameters. It has been proven\nin extensive research and validated through experimental and clinical studies. All of these factors make the Babbs\nmodel a reliable tool for simulating CPR scenarios and optimizing resuscitation techniques (Babbs & Thelander,\n1995).\nThe Babbs model equations can be summarized as follows:\n$CPP= \\frac{DBP \\times Duty}{Duty + \\frac{1}{R}}$                                                                                                                                                                                                                                                                                                                                                         (3)\n$DBP = E \\times D - F \\times D^2$                                                                                                                                                                                                                                                                                                                                                                 (4)\n$E=Emin + \\frac{E max-E min}{1 + exp(PE \\times (Dtarget \u2013 D))}$                                                                                                                                                                                                                                                                                                                                                     (5)\n$F=F min + \\frac{Fmax-F min}{1 + exp(PF \\times (Dtarget \u2013 D))}$                                                                                                                                                                                                                                                                                                                                                     (6)\nwhere the variables are as follows: CPP: Coronary perfusion pressure during CPR; DBP: Diastolic blood pressure\nduring CPR; D: Chest compression depth; R: Chest compression rate; Duty: Chest compression duty cycle; E:\nElastance of the arterial system; F: Resistance of the arterial system; Emin, Emax: Minimum and maximum\nelastance values; F min, F max: Minimum and maximum resistance values; PE, PF: Model parameters; Dtarget:"}, {"title": null, "content": "Target chest compression depth.\nThe Babbs model optimizes chest compression parameters during CPR by providing real-time feedback to guide\nrescuers in achieving optimal chest compressions. The algorithm implementation involves measuring compression\ndepth, duty cycle, and rate during CPR and using these values to calculate CPP based on the Babbs model equations.\nThe calculated CPP is then compared to the optimal CPP target range, and the algorithm provides feedback to the\nrescuers to adjust compression parameters accordingly. A total of 100 cycles of chest compressions is simulated with\na compression rate of 100 compressions per minute. The compression depth was set to 50 mm, and the decompression\ndepth was set to 10 mm. The time of compression and time of decompression were set to 50% and 50% of the total\ncycle time, respectively. The target diastolic blood pressure was set to 40 mmHg. To generate the synthetic data for\nvarious patients, the external force is varied and applied during chest compressions, chest compliance, and airway\nresistance to simulate different patient conditions. The external force was varied from 500 N to 1000 N in steps\nof 100 N, however, Chest compliance was varied from 0.01 L/kPa to 0.05 L/kPa in steps of 0.01 L/kPa. Moreover,\nAirway resistance was varied from 1 cmH2O/(L/s) to 5 cmH2O/(L/s) in steps of 1 cmH2O/(L/s). The potential clinical\nimplications of this approach are significant, as optimizing chest compression parameters during CPR can improve the\nchances of successful resuscitation and reduce the risk of complications. The five key signals that are critical for\neffective CPR operations have been selected for experimentation: Compression, Blood Pressure, Velocity, Force, and\nPmouth (Jung et al., 2006). These signals provide essential insights into the physiological response during chest\ncompressions and the overall effectiveness of CPR. Compression tracks the depth and rate of compressions, while\nBlood Pressure monitors circulatory efficacy. Velocity measures the speed of the chest recoil, ensuring optimal blood\nflow, and Force indicates the pressure applied during compressions to maintain perfusion. Pmouth reflects airway\npressure, which is vital for ensuring proper ventilation. Together, these signals offer a comprehensive understanding\nof CPR performance, and a sample of these signals for a single patient is depicted in Figure 5."}, {"title": "4.2.2 ADD NOISE AND ARTIFACTS TO SIMULATED DATA", "content": "To enhance the realism of the simulated CPR data generated by the Babbs model, several noise artifacts are incorpo-\nrated. These additional noise components are strategically introduced to mimic the diverse sources of interference\ncommonly encountered in real-world CPR signals. By augmenting the simulated data with realistic noise, a more\nfaithful representation of the complexities and challenges inherent in CPR monitoring scenarios is aimed to be\ncreated. This approach ensures that the research experiments and algorithm developments are robustly tested against a\nspectrum of noise patterns, thus increasing the validity and applicability of the findings to real-world clinical settings.\nThrough this meticulous process of noise augmentation, the gap between simulated and actual CPR data strives to\nbe bridged, ultimately advancing the field of CPR monitoring and signal processing with greater fidelity and relevance."}, {"title": null, "content": "Gaussian Noise:\nIn the context of CPR signal data, adding Gaussian noise is a crucial step in enhancing the realism and authenticity\nof simulated data for research purposes. Gaussian noise, also known as white noise, follows a normal distribution\ncharacterized by its mean \u00b5 and variance 02:\n$Noise = \u03bc + \u03c3\u00d7 \u039d (0,1)$                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (7)\nFor this study, we tested specific parameter values: a mean of 0 and a standard deviation (or variance) of 1. These\nvalues were selected to simulate typical noise conditions encountered during CPR. To reflect more extreme conditions,\nsuch as a noisy ambulance environment, we increased the standard deviation to introduce greater variability and\nmimic higher levels of interference. Additionally, by setting a noise factor of 1.2 and a noise probability of 0.1,\nwe controlled the intensity and likelihood of noise affecting the clean CPR signals. This controlled introduction of\nvariability captures the stochastic nature of real-world noise during CPR monitoring, ensuring that the data more\naccurately reflects conditions encountered in clinical settings. (Goceri, 2023)."}, {"title": null, "content": "Additionally, the noise probability parameter controls the likelihood of noise being added to each element of\nthe signal, further enhancing the realism of the simulated data. This approach replicates various sources of inter-\nference, such as electrical noise, sensor inaccuracies, or environmental disturbances. For example, real-world CPR\nmonitoring scenarios often involve noise from moving equipment, patient movement during compressions, or chaotic\nsettings like ambulances where vibrations and varying patient profiles can introduce significant interference. By\nincorporating Gaussian noise into the clean CPR data, the algorithms and methodologies can be rigorously evaluated\nunder more practical conditions that closely mimic the unpredictable nature of clinical environments (Kassam, 2012).\nThis noise augmentation process facilitates the development of more robust CPR monitoring and decision-making"}, {"title": null, "content": "Salt & Paper Noise:\nIn investigating CPR signal data, salt-and-pepper noise is introduced to simulate impulsive disturbances often encoun-\ntered in real-world monitoring environments. This noise type mimics issues like sensor anomalies or transmission\nirregularities, which can affect the precision of CPR signal assessments. The chosen parameters for this noise, include\nsalt probability = 0.0001, pepper probability = 0.0001, and salt and pepper values = 0.00001. These values reflect\ntypical error margins in sensor readings and momentary transmission glitches observed during CPR monitoring. For\ninstance, low probabilities such as 0.0001 were selected to represent rare but impactful occurrences, such as sudden\nmalfunctions in medical equipment or brief disruptions in signal transmission, which are infrequent but can lead to\nsignificant distortions in the data. The salt and pepper values (0.00001) represent extremely low and high-intensity\nvalues, simulating hardware malfunctions that inject sharp spikes or drops into the data (Azzeh et al., 2018). This\nmethodology ensures the simulated data realistically mimics real-life noise scenarios, where occasional, sudden,\nand extreme disturbances can impair signal integrity during CPR operations. By simulating these conditions, our\napproach enables the robust evaluation of algorithms, ensuring they are equipped to handle the unpredictability of\nactual clinical environments (Erkan et al., 2018)."}, {"title": null, "content": "Simulate Baseline Wander:\nThe Baseline Wander, modeled as a sinusoidal waveform, introduces subtle variations that capture the complexities\ninherent in CPR signal analysis, where T represents the period of the sine wave (time for one complete cycle) and t\ninstantaneous time at which the function is evaluated. It is simulated using a function with an amplitude parameter\nset at 0.02 to replicate the low-frequency variations often caused by physiological factors such as body movement or\nelectrode displacement. These variations can distort the primary CPR signal, and the chosen amplitude reflects realistic\nlevels of baseline wander observed in clinical settings. The 0.02 amplitude ensures that the simulation introduces\nsufficient variability without overwhelming the core signal, effectively emulating real-world noise sources like patient\nmovement or sensor shifts during chest compressions in emergencies. This approach allows for a more accurate\nrepresentation of the noise challenges encountered during CPR monitoring (Li et al., 2020).\n$Baseline Wander = amplitude \\times sin (\\frac{2\u03c0\u03c4}{T})$                                                                                                                                                                                                                                                                                                                                                               (8)\nThis added realism enhances the robustness of our dataset, allowing for more comprehensive testing and refinement\nof algorithms. By incorporating these nuanced fluctuations, the dataset becomes better suited for exploring diverse\nresearch directions and improving algorithmic performance, ultimately advancing the reliability of CPR monitoring\nand analysis techniques."}, {"title": null, "content": "Muscle Interference:\nIn our data augmentation process for CPR signal data, Muscle Interference has resembled using a function with\na specified amplitude parameter of 0.05. Muscle interference represents the unpredictable noise that arises from\ninvoluntary muscle contractions, movement artifacts, or electrical noise from surrounding muscles and it masks the\nfeatures of the underlying signal. By adding muscle interference with this parameter, realistic variations in the CPR\nsignals are simulated, mimicking the effects of muscle-related artifacts that are observed in real-world monitoring\nscenarios. The simulated interference is generated as Gaussian noise with a mean of 0 and a standard deviation\ncorresponding to the specified amplitude, which enriches the CPR signals by introducing nuanced noise patterns that\nrepresent the complexities of CPR signal (Murach & Bagley, 2016).\n$Muscle Interference = amplitude \\times N(0, 1)$                                                                                                                                                                                                                                                                                                                                                                                                                                  (9)\nThis augmentation will enhance the resilience of CPR signals and facilitate more comprehensive research exploration\nand algorithm development, which will help to improve the accuracy and reliability of CPR signal processing\nalgorithms."}, {"title": null, "content": "Simulate Sudden Amplitude Changes:\nMoreover, a unique approach is implemented by applying the simulated sudden amplitude changes function. This\nfunction is executed with several parameters such as num changes = 500, max change duration = 10, and change factor\n= 0.005. At the same time, a sudden variation in signal intensity is injected which resembles the abrupt fluctuations\noften encountered in real-world scenarios. These changes reflect the artifacts that arise from equipment glitches,"}, {"title": null, "content": "physiological shifts, or external disruptions, introducing an element of unpredictability into the signals. By employing\nthis function with carefully chosen parameters, numerous instances of sudden amplitude changes are simulated, each\nlimited to a maximum duration of 10 data points. These parameters were meticulously selected to mimic the dynamic\nnature"}]}