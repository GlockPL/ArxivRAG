{"title": "OSAD: Open-Set Aircraft Detection in SAR Images", "authors": ["Xiayang Xiao", "Zhuoxuan Li", "Haipeng Wang"], "abstract": "Current mainstream SAR image object detection methods still lack robustness when dealing with unknown objects in open environments. Open-set detection aims to enable detectors trained on a closed set to detect all known objects and identify unknown objects in open-set environments. The key challenges are how to improve the generalization to potential unknown objects and reduce the empirical classification risk of known categories under strong supervision. To address these challenges, a novel open-set aircraft detector for SAR images is proposed, named Open-Set Aircraft Detection (OSAD), which is equipped with three dedicated components: global context modeling (GCM), location quality-driven pseudo labeling generation (LPG), and prototype contrastive learning (PCL). GCM effectively enhances the network's representation of objects by attention maps which is formed through the capture of long sequential positional relationships. LPG leverages clues about object positions and shapes to optimize localization quality, avoiding overfitting to known category information and enhancing generalization to potential unknown objects. PCL employs prototype-based contrastive encoding loss to promote instance-level intra-class compactness and inter-class variance, aiming to minimize the overlap between known and unknown distributions and reduce the empirical classification risk of known categories. Extensive experiments have demonstrated that the proposed method can effectively detect unknown objects and exhibit competitive performance without compromising closed-set performance. The highest absolute gain which ranges from 0 to 18.36% can be achieved on the average precision of unknown objects.", "sections": [{"title": "I. INTRODUCTION", "content": "Due to the continuous progress in deep learning and convolutional neural network (CNN), visual object detection has witnessed significant advancements in recent years [1]-[3]. Concurrently, deep learning techniques have been introduced into the remote sensing domain, especially in tasks like synthetic aperture radar (SAR) object detection and recognition, where they play a pivotal role [4]-[8]. However, most contemporary methods are built on a strong assumption, referred to as closed-set modeling, which necessitates knowledge of all categories to be detected during the training phase. This modeling approach implies that the system can only be modeled based on observed categories. Under this assumption, object detectors might exhibit inaccuracies when dealing with objects from unknown categories, either misclassifying them as background objects or incorrectly classifying them into established categories.\nAs per the findings in [9], when conducting tests using samples from sources distinct from the training set, the performance of the optimal system for object classification and recognition is significantly compromised. More specifically, owing to constraints in the training dataset, only a limited subset of categories can be included. This leads to a lack of resilience in the majority of detection and recognition methods when confronted with unknown objects. In typical CNN, as depicted in Equation (1), the confidence score of the classification layer is conventionally employed for identifying unknown categories [10]. In essence, the determination of classifying an object as an unknown category relies on the confidence score generated by the network's output.\n\\(\\operatorname{conf}(x) = \\max_{y} p(y | x) = \\max_{y} \\frac{e^{z_y}}{\\sum_{i=1}^{C_k} e^{z_i}}\\)\nWhere \\(z_i\\) represents the logit value for the i-th class, if the confidence score conf(x) for a sample x surpasses the threshold T, it is classified as a known category; otherwise, it is labeled as unknown. During the training process, the posterior probabilities of the \\(C_k\\) known categories are normalized to yield a sum of 1, which frequently results in unknown objects being incorrectly assigned to existing categories with high confidence. These errors can be broadly classified into two cases, as shown in Fig.1: 1) false negatives, where targets are erroneously classified as other categories or as background; and 2) false positives, where background or unknown objects are mistakenly recognized as existing targets.\nThis issue can be attributed to several reasons:1) Algorithmic design: In closed-set training, it is common practice to normalize the probabilities of known categories to 1 through the SoftMax layer, leaving no probability space for unknown categories; 2) Feature level: The essence of CNN lies in partitioning the feature space and allocating corresponding regions for known categories, without considering the presence of unknown categories; 3) Loss function design: The common cross-entropy loss functions neglect intra-class compactness in the feature space, resulting in cases where distances within the intra-class feature space are greater than inter-class distances.\nThis paper is dedicated to tackling the challenge of detector response when confronted with unseen category, namely open-set detection. Our aim is to train a detector using a closed set while endowing it with the ability to detect all known categories and identify unknown objects within an open set. In open-set detection, recognizing unknown object categories presents the following challenges for conventional detectors: 1) The detector needs to provide accurate detection proposals simultaneously for known categories and potential unknown categories; 2) It is necessary to effectively leverage the model's learning of known categories to distinctly separate unknown categories from the background; 3) Modeling for objects of different sizes and simultaneous detection are required.\nIn order to better model unknown objects in SAR images and capture their spatial semantics, inspired by previous works [11]-[14], this work proposes OSAD, which is designed to facilitate the detection and recognition of unknown targets in SAR images under open environmental conditions. It is noteworthy that, while preserving the closed-set performance, the proposed approach has led to improvements in all open-set metrics. Specifically, an absolute gain of 18.36% in the average precision (APu) for unknown targets are acchieved in the OS-SAR-Aircraft dataset. This research holds significant implications for the application of intelligent algorithms in dynamically changing real-world environments.\nIn particular, this approach is equipped with dedicated components addressing the challenges posed by the open-set environment in SAR image analysis. These components encompass Global Context Modeling (GCM), Quality-Driven Pseudo Label Generation (LPG), and Prototype Contrastive Learning (PCL), aimed at effectively detecting unknown entities within SAR images. Inspired by the human recognition mechanism, this framework mimics human robustness when encountering unfamiliar data, often relying on templates or prototypes for unfamiliar entities. The GCM and PCL components aim to enhance the performance of the CNN extractor, analogous to simulating human sensory organs, transforming specific objects into abstract feature representations. The entire process of feature extraction emulates the human perceptual process. On the other hand, the PCL module learns prototypes for each known class, similar to abstract memories in the human brain corresponding to respective categories. Analogous to human cognition, the classification decisions within the PCL module are achieved by matching abstract features with prototypes of each known category. If the CNN features of a test sample do not align well with the prototypes of known categories, it is considered as unknown, mirroring the human cognitive process.\nRecently, the field of computer vision has witnessed a surge in research aimed at addressing the challenge of detecting unknown objects. Among these endeavors, one of the most notable studies are conducted by Joseph et al.[11], introducing the towards open world object detection (ORE). This method leverages class-agnostic proposals generated by the region proposal network (RPN) to automatically acquire pseudo-unknown objects. Subsequently, it clusters these automatically labeled unknown objects with known categories, ultimately distinguishing between unknown and known categories through an energy distribution approach. While the research marks a significant milestone in open-set detection research, it still presents some problems: 1) The classical design of Faster R-CNN falls short in encoding long sequential dependencies. 2) However, capturing contextual information in images is paramount for perceiving unknown objects. 2) Conventional RPN fundamentally operate as binary classifiers, and under strong supervision based on known categories, the generated proposals tend to favor known categories. This may lead to overfitting issues with the training data. In addtion, Han et al. [12] also propose an unknown object detector. Their approach employs a single potential region to represent unknown objects, which may result in inaccurate classification and suboptimal separation between known and unknown categories.\nOur primary contributions can be summarized as follows:\n(1) To the best of our knowledge, our study stands as the pioneering endeavor to apply an open-set setting to aircraft detection in SAR images, achieving an absolute gain in average precision for unknown targets from 0 to 18.36, allowing it to better adapt to real-world scenarios.\n(2) This paper introduces a novel open-set SAR detector, featuring meticulously designed learners LPG and PCL, trainable end-to-end, and directly applicable in open-set environments.\n(3) To enhance the detector's capability in identifying unknown entities, this study have improved traditional RPN networks, introducing a proposal network based on quality positioning clues, achieving generalization beyond categories and datasets, effectively enhancing perception of unknown entities."}, {"title": "II. RELATED WORK", "content": "A. Open-set Recognition\nIn closed-set learning, it is typically assumed that only previously known classes exist during testing, while open-set learning assumes the possibility of known and unknown classes during the testing phase. Scheirer et al. [15] are the first to treat open-set recognition (OSR) as a minimization-constrained task. They develop open-set classifiers based on Support Vector Machines (SVMs), which is capable of rejecting unknown objects during testing. Subsequently, researchers extended the open-set framework using SVM-based methods for multi-class classifiers, as well as probabilistic models and extreme value theory classifiers to address the problem of disappearing confidence in unknown classes[16]-[18]. Bendale et al. achieve the first deep learning-based open-set recognition method, known as OpenMax. They model distances on activation vectors using Weibull distribution and re-calibrated the Softmax layer's probabilities to recognize unknown objects in deep network feature space[19]. Additionally, Ge et al. [20] propose a method building upon OpenMax that utilizes generative models to synthesize unknown samples for effective separation of known and unknown samples. OpenGAN [21] employs generative adversarial training to discriminate unknown objects, where generated latent open images assist in identification. Furthermore, some methods employ encoders [22][23] or reconstruction-based approaches [24], using reconstruction errors as indicators for unknown recognition. On the other hand, distance-based prototype discrimination methods [25] measure the distance between image features and learned prototypes for open-set image recognition. Our approach shares some similarities with [25], but differs in that this work encode contrastive features in prototype-based discrimination and employ momentum sequence updates for known class prototypes.\nB. Open-set object Detection\nIn the field of object detection, open-set detection can be seen as an extension of open-set recognition. It is worth noting that, despite extensive research in the domain of optical images, such research has not yet been conducted in the SAR image domain. Dhamija [26] is the first to analyze the impact of an open-set setting on classical detectors in his research. He finds that most detectors exhibited excessive confidence when misidentifying unknown class targets as known class targets. To enhance detection performance under open conditions, researchers like Miller [27][28] utilizes dropout techniques based on Bayesian inference [29] approximations of neural network parameters, aiming to assess label uncertainty. Additionally, Joseph [11] and his colleagues observe that under open-set conditions, the Helmholtz free energy for unknown classes is higher. Therefore, they propose to utilize energy measurements to determine whether a sample belongs to an unknown class. OW-DETR[30] introduces attention feature maps for scoring candidate proposals objectively and selecting the top K candidate boxes to generate pseudo-labels, which are then distinguished between known and unknown categories using a novelty classifier. However, it is important to note that the methods proposed by [11] require labeling of unknown classes, which contradicts the open-set detection setup. Past methods mainly relied on feature outputs (logits) from pre-trained models in the latent space to represent unknown classes. However, as pointed out by UC-OWOD[30], unknown objects may span multiple categories, making this representation method less accurate. To better distinguish between known and unknown objects, this paper attempts to use prototype contrastive learning to achieve compactness within the latent space and separation between different categories through distance discrimination.\nC. Prototype Models\nThe initial prototype model is known as Learning Vector Quantization (LVQ) [31], originating from the concept of k-Nearest Neighbors (KNN). LVQ preserves one or multiple prototypes for each category, which are refined through learning from the data to better represent it, thus effectively distinguishing between different categories. Additionally, various methods for prototype learning have been proposed, with some focusing on improving prototype update rules during training, such as [32]-[35]. Meanwhile, other approaches model the problem as a challenging parameter optimization task, guided by more intricate loss functions, to learn how to present prototypes[36]-[39]. However, these methods are often based on manually designed features. Subsequently, prototype learning is introduced into the field of CNN. For prototype networks, it is assumed that there exists an embedding space where data points gather around independent prototypes for each category. Snell et al. [40] propose incorporating the concept of prototypes into CNN for few-shot learning, achieving satisfactory results. Considering that unknown class objects typically involve few-shot scenarios, in this paper, this work suggests jointly learning prototypes and contrastive learning from the data. This work constructs a standard end-to-end deep framework to explore prototype distance-based methods for classifying unknown objects."}, {"title": "III. MATHDOLOGY", "content": "A. Problem Definition\nIn accordance with prior research[11][12], the concept of open-set detection within the OSAD task is defined as follows: The dataset D is divided into the training data \\(D_{tr}\\) and the testing data \\(D_{te}\\). \\(D_{tr} = \\{(x, y), x \\in X_{tr}, y \\in Y_{tr}\\}\\), \\(D_{te} = \\{(x', y'), x' \\in X_{te}, y \\in Y_{te}\\}\\), where x and x' signify the input images, while y and y' denote their respective annotations including class labels and bounding box coordinates. The training data \\(D_{tr}\\) contains K known classes, \\(C = \\{C_1...C_k\\}\\), whereas the testing data \\(D_{te}\\) comprises both known and unknown instance \\(c_u \\notin C\\). An open-set detector is trained on \\(D_{tr}\\)aiming to accurately detect all known class objects within \\(D_{te}\\), while also effectively identifying unknown class objects to prevent misclassification as known classes.\nB. Overall Architecture\nAs depicted in Fig. 2, the proposed OSAD is a two-stage detector with three key modules: GCM, LPG, and PCL, designed to enhance open-set detection. GCM (Section III-C) enriches contextual information and improves feature encoding. It's helpful to mitigate inductive bias and potentially enhance detection accuracy by capturing long-range dependencies with multiscale receptive fields. LPG (Section III-D) addresses the challenge of identifying unknown classes within the background by using a quality-guided proposal network to filter candidate regions, as manually annotating infinite unknown classes is impractical. PCL (Section III-E) aids the detector in distinguishing between categories within the latent space through prototype contrastive learning, achieving clear differentiation between known and unknown objects by encoding the distance between proposals and known class prototypes. In the ensuing sections, we will delve into a meticulous explication of each of these integral components.\nC. Global Context Modelling\nThe capacity of the feature representation network to extract discriminative features is of paramount importance, particularly in downstream tasks involving robust target identification[41]. When considering the necessity for open-set detection, the scenario can grow in complexity due to the potential presence of diverse unknown objects within the images. Hence, it becomes imperative to ensure that the feature representation network possesses enhanced capabilities in encoding global contextual information effectively. This enhancement is essential to enable the network to accurately perceive objects that have not been encountered during training. In particular, when dealing with the prediction of objects at multiple scales, feature maps at distinct hierarchical levels exhibit remarkable sensitivity in capturing various fine-grained details and scale-related information of targets. Consequently, during the encoding of global contextual information, the incorporation of large receptive field information across multiple scales in the images becomes indispensable. This facilitates superior adaptability to targets of varying sizes. Furthermore, this refined detection framework serves to mitigate inductive biases and minimizes presumptions regarding unknown objects during the testing phase. As a result, it significantly contributes to the enhancement of detection performance.\nTo construct a global contextual framework, this work introduces the GCM [42] for SAR aircraft detection. The incorporation of the GCM empowers us to acquire contextual information from the images and establish long-range dependencies, resulting in the creation of a more robust multi-scale feature representation. As illustrated in Fig. 3, this work integrates the feature maps Pi (i=3,4,5) obtained from the neck with the GCM module. The GCM module comprises the following key components: (a) Global attention pooling: This component obtains attention weights through1 \u00d7 1convolution and a Softmax function. Subsequently, these weights are employed for attention aggregation, enabling the extraction of global contextual features. This step helps mitigate potential information loss that may occur due to dimensionality reduction. (b) Bottleneck transformation: Designed to capture dependencies between channels, this aspect utilizes 1 \u00d71 convolution for feature transformation. (c) Element-wise addition: This process is utilized to seamlessly integrate global contextual features into the features at each position. Furthermore, this work introduces layer normalization to alleviate optimization challenges that arise as a result of the bottleneck transformation. Through this methodology, the proposed model can effectively capture global information present in SAR images, thereby enhancing the performance of aircraft detection. The entire process is thoughtfully modeled to facilitate these improvements.\n\\(Z_i = \\Theta_2 \\operatorname{ReLU} \\left( \\operatorname{LN} \\left( \\Theta_1 \\left( \\sum_{j=1}^{N_p} \\alpha_j e^{\\Theta K_j} \\right) + X_i \\right) \\right)\\)\n\\(\\alpha_i = \\frac{e^{\\Theta K_i}}{\\sum_{i=1}^{N_p} e^{\\Theta K_i}}\\)       \n\nX and Z symbolize the input and output feature vectors, respectively. The \\(X_i\\) denotes information pertaining to the presently attended position, while \\(X_j\\) signifies global information, with j iterating over all conceivable positions. \\(N_p\\) is indicative of the number of positions within the feature map, which, in the case of an image, stands as \\(N_p = H \\times W\\). The symbols \\(\\Theta_K\\), \\(\\Theta_1\\) and \\(\\Theta_2\\) represent linear transformation matrices, conventionally achieved via 1\u00d7 1 convolutional operations. \\(\\alpha_j\\) stands as the weight associated with global attention pooling.\nD. Localization Quality-Driven Pseudo label Generation\nIn order for the detector to be able to detect unlabeled unknown objects in the training set, the open detection framework needs to rely on the presence of potentially unknown instances in the training images, which involves labeling these unknown objects using true unknown classes. However, it is impractical to re-annotate all instances of every image in an annotated dataset. ORE utilizes an automatic labeling step to obtain pseudo-unknown objects for training. Automatically labeled pseudo-labels refer to the proposal boxes associated with the RPN output with potentially unknown objects.\nHowever, standard RPN is trained under strong supervision of known categories, and the proposal boxes it generates may be biased towards known categories. Inspired by [14], without category label supervision, this study proposes LPG, which learns to use cues from object location and shape (called localization quality) to enhance generalization to unknown object proposals. LPG is designed to enable RPN networks to generalize better to new and unseen categories. As shown in Fig. 4, the pseudo-labels in LPG refer to proposal boxes with high objective scores that do not overlap with ground truth (GT) known instances.\nSpecifically, in standard RPN, the input is the output features of each level of the feature pyramid. Each feature map is processed through a separate convolutional layer, and finally two independent sub-layers are formed, one for performing bounding box regression and the other for classification tasks. Different from the standard RPN design, in the first stage, this work chooses to replace the classification branch with the centrality regression branch [44]. Because in the anchor frame proposal stage, the learning of target positioning is more critical than classification. This design helps avoid the problem of overfitting to foreground categories, thereby promoting generalization to unknown categories. For box regression, this work applies the distance (left, right, top, bottom, lrtb) from the position to the four sides of the real box to calculate the regression loss. In the second stage, the high-scoring proposal boxes filtered out in the RPN are used to perform RoIAlign, and then enter the refinement regression of the bounding box and the IoU regression head [45]. When evaluating the quality of the target proposal box, this work adopts the dual measurement of centrality score and IoU score. The IoU score not only helps the model refine the proposal score, but also helps avoid the model's overfitting of the foreground category. The objective score of a proposal region is calculated as the geometric mean of centrality c and IoU score b, \\(s = \\sqrt{c.b}\\). Finally, the proposed boxes with high objectivity scores that do not overlap with ground-truth objects are marked as potential unknown instances.\nDuring the training process, if the IoU between a proposal and the corresponding ground truth box is greater than the threshold 0.7, it is judged as a positive sample; if the IoU is less than 0.3, it is judged as a negative sample. Subsequently, 256 selected anchor frames are randomly sampled for loss calculation. The loss formula of LPG can be expressed as follows:\n\\(L_{LPG} = \\lambda_1 L_{box1} + \\lambda_2 L_{ctr} + \\lambda_3 L_{box2} + \\lambda_4 L_{IoU}\\)\nHere, \\(L_{box1}\\), \\(L_{ctr}\\), \\(L_{IoU}\\) and \\(L_{box2}\\) represent Irtb bounding box regression, centrality regression, xywh bounding box regression ((x, y), weight, height, xywh) and IoU regression, respectively. Meanwhile, \\(\\lambda_1\\), \\(\\lambda_2\\), \\(\\lambda_3\\) and \\(\\lambda_4\\) denote the corresponding weight coefficients. The first two loss functions are utilized during the initial proposal generation, whereas the latter two loss functions play a role in the proposal refinement process.\nE. Prototype Contrastive Learning\nThe classic Faster R-CNN [3] approach involves the integration of proposals into fixed-sized layers, subsequently encoding them as RoI features. Nevertheless, in certain scenarios, training reliable representations for unknown classes using known samples becomes a formidable challenge. Consequently, there is a need for a classification methodology capable of distinguishing features among different categories to elevate classification accuracy. This section delves into strategies for enhancing recognition performance by mitigating the overlap between features extracted from known-class samples and those from unknown samples.\nSpecifically, this work utilizes 1024-dimensional feature vectors obtained from the RoI head. These feature vectors \\(f(x_i)\\) are projected into a lower-dimensional embedding vector \\(z_i\\) via a projection head. The projection head is composed of a non-linear fully connected layer connected to the RoI. It includes fully connected (FC) layers, ReLU activation layers, and additional FC layers. It's important to note that the encoder, which includes this projection head, is used exclusively for the classification branch during training and is not employed during inference. Throughout the training process, the prototype contrastive loss is applied to the classification branch. During downstream tasks, this work adopts the feature vectors from \\(f(x_i)\\) instead of those obtained by the projection head.\nThe prototypes which calculate by encoder \\(f_{\\Theta}\\) are represented by M-dimensional vectors and denoted as \\(p_k \\in R^M\\), and possess learnable parameters \\(\\Phi\\). Each prototype serves as the average vector of embedded support points belonging to its respective category. The prototypes for each class can be likened to abstract memories of that class in the human brain.\n\\(p_k = \\frac{1}{|C_k|} \\sum_{(x_i, y_i) \\in C_k} f_{\\Theta}(x_i)\\)\n\nPrototype contrastive loss measures the similarity between pairs of samples in a representation space. This study defines the prototype contrastive loss as follows:\n\\(L_{pcl} = \\sum_{i=0}^K l(z_j p_k)\\)\n\\(l(z_j p_k) =\\begin{cases}\\Delta(z_j, p_k), j = k\\\\max\\{0, T - \\Delta(z_j, p_k)\\}, j \\neq k\\end{cases}\\)\n\nIn the formula (7), \\(\\Delta\\) represents the cosine distance between the embedding \\(z_j\\) and the prototype \\(p_k \\in P\\), while T is a hyperparameter used to denote the minimum distance between input feature vectors and prototypes of different classes in the latent space. By minimizing this loss, it ensures a good separation between different classes in the latent space. In addition, the performance of closed sets in the potential space is not as good as the traditional softmax classifier, so the softmax classifier is still used for known objects. The cross entropy loss \\(L_{cls}\\) is employed to optimize the embedding vector, the same as Faster-rcnn."}, {"title": "IV. EXPERIMENTAL RESULTS AND ANALYSIS", "content": "A. Datasets\nThis work has created a dataset specifically tailored for open-set aircraft detection in SAR imagery", "WR)[28": "comprising 40 test images with only known categories and {44", "26": "and Absolute Open Set Error (AOSE) [28", "framework[48": ".", "49": "and integrate it with a feature pyramid network. For optimization", "FR-CNN)[3": "Dropout Sampling (DS)[27", "OW-DETR[30": "PROSER[48", "OpenDet[12": ".", "dataset[7": ".", "https": "github.com/xiayang-xiao/Dataset-zkxt. This work maintains consistent experimental settings with seven distinct tasks, where four tasks are associated with known categories (A320/321, Boeing787, A220, other), while keeping the rest of the experimental conditions consistent.\n presents the quantitative analysis results on the ZKXT dataset. The results indicate that the proposed method achieves detection of unknown categories while maintaining closed-set accuracy. Specifically, in task T-7, the proposed method achieves an average precision of 7.93% for detecting unknown categories. However, compared to the GF3 dataset, we observe a slightly lower average precision in detecting unknown categories. That could be speculated due to issues with the imaging quality of the images in the ZKXT dataset. The target features on the images in this dataset may not be distinct, leading to blurry imaging.\nG. Sensitivity Analysis on Hyperparameters\n(1) The impact of stage in GCM\nIn Section III-C, this work describes the utilization of GCM with a bottleneck ratio of r = 4 applied to the feature layers P3, P4, P5. In this section, this work examines the impact of incorporating GCM at various stages. We observe these effects by incrementally introducing GC modules at different stages.\n  displays the performance results of the model following the integration of GCM at different stages. Notably, all stages exhibit improvements in performance attributed to the global context information modeling within GCM, underscoring the pivotal role of global context information in enhancing model performance. When GCM is introduced into c4 and c5, the model demonstrates superior performance compared to its insertion into c3, implying that higher-level semantic feature layers can more comprehensively leverage global context modeling. This phenomenon likely arises from the increment in model parameters as GCM is applied to multiple layers, thereby offering enhanced modeling capabilities"}]}