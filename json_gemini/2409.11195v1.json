{"title": "SDP: Spiking Diffusion Policy for Robotic Manipulation with\nLearnable Channel-Wise Membrane Thresholds", "authors": ["Zhixing Hou", "Maoxu Gao", "Hang Yu", "Mengyu Yang", "Chio-In IEONG"], "abstract": "This paper introduces a Spiking Diffusion Policy\n(SDP) learning method for robotic manipulation by integrat-\ning Spiking Neurons and Learnable Channel-wise Membrane\nThresholds (LCMT) into the diffusion policy model, thereby\nenhancing computational efficiency and achieving high per-\nformance in evaluated tasks. Specifically, the proposed SDP\nmodel employs the U-Net architecture as the backbone for\ndiffusion learning within the Spiking Neural Network (SNN).\nIt strategically places residual connections between the spike\nconvolution operations and the Leaky Integrate-and-Fire (LIF)\nnodes, thereby preventing disruptions to the spiking states.\nAdditionally, we introduce a temporal encoding block and a\ntemporal decoding block to transform static and dynamic data\nwith timestep Ts into each other, enabling the transmission\nof data within the SNN in spike format. Furthermore, we\npropose LCMT to enable the adaptive acquisition of membrane\npotential thresholds, thereby matching the conditions of varying\nmembrane potentials and firing rates across channels and\navoiding the cumbersome process of manually setting and\ntuning hyperparameters. Evaluating the SDP model on seven\ndistinct tasks with SNN timestep Ts = 4, we achieve results\ncomparable to those of the ANN counterparts, along with\nfaster convergence speeds than the baseline SNN method. This\nimprovement is accompanied by a reduction of 94.3% in\ndynamic energy consumption estimated on 45nm hardware.", "sections": [{"title": "I. INTRODUCTION", "content": "The swift progress in embodied AI not only has sparked\nthe revolutionary transformation in autonomous driving but\nalso unveiled grand opportunities for applying such tech-\nnologies in other forms of robotic systems, such as the\nnext-generation intelligent robotic arms designed for versa-\ntile open-world manipulations. These intelligent arms will\nbecome increasingly integral in a wide array of sectors, such\nas industrial automation and healthcare, and are expected\nto expand the application scope e.g. into everyday life.\nThe growing scope and complexity of applications have\nelevated the expectations and demands placed upon robotic\narms. There is an increasing demand for capabilities such as\nrobust open-world perception, common-sense reasoning and\ndecision-making, swift adaptation to dynamic environments,\nefficient and precise trajectory planning, and last-but-not-\nleast efficient computation in edge devices.\nTo address these challenges, large efforts have been paid\nto incorporating large language model and vision-language\nmodel [1] into the system loop, developing efficient robotic\nmanipulation models [2] and conducting various model\ncompression methods, such as pruning [3], [4], knowledge\ndistillation [5], and model quantization [6]\u2013[8]. Despite these\nadvancements, a significant challenge remains in achieving\nefficient computation that maintains high accuracy and en-\nables rapid response and low energy consumption, which is\nessential for the practical deployment of robotic arms in real-\nworld scenarios.\nDrawing inspiration from the extraordinary ability of bio-\nlogical brains to process large volumes of information effi-\nciently, the field of neuromorphic computing [9], [10] using\nSpiking Neural Networks (SNNs) [11] becomes an exciting,\ninnovative, less-explored path to explore towards improving\nefficiency of neural network models. Designed to closely\nmimic the neural mechanisms found in nature, SNNs provide\nbenefits like lower power consumption due to its binary\nspike representation and event-driven operation mechanism.\nSNN has been successfully applied in a variety of domains,\nencompassing tasks such as digit recognition [12], real-time\nsound source localization [13], image classification [14],\nobject detection [15], enhancement of large language models\n(LLMs) [16], image generation [17], and robotics [18].\nIn this paper, we introduce a Spiking Neural Network\nmethodology for robotic manipulation, achieved by incor-\nporating neuromorphic spiking neurons into the diffusion\npolicy algorithm [19]. This novel approach, designated as\nSpiking Diffusion Policy (SDP), significantly enhances com-\nputational efficiency while attaining performance on par\nwith traditional Artificial Neural Networks. Specifically, the\nSDP utilizes a U-Net architecture as its backbone for noise\nprediction in the reverse diffusion process and incorporates\nLeaky Integrate-and-Fire (LIF) nodes as activation functions\nthroughout the U-Net structure. Notably, we strategically\nplace residual connections between the spike convolution"}, {"title": "II. RELATED WORKS", "content": "Spiking neural network in robotics: In robotics, the\nproposed multi-task autonomous learning paradigm [18] for\nmobile robots employs an SNN controller with a reward-\nmodulated Spiking-time-dependent Plasticity learning rule\nand a task switch mechanism to enable the robot to au-\ntonomously learn, switch, and complete obstacle avoidance\nand target tracking tasks. [20] presents the successful appli-\ncation of a novel Spiking Neural Network (SNN) to control\nlegged robots, which achieves outstanding results across\nsimulated terrains while offering advantages in inference\nspeed, energy consumption, and biological interpretability\nover traditional artificial neural networks. In robotic arm\nmanipulation, [21] presents the design and analysis of a new\nPID controller based on the spiking neural network (SNN)\nfor a 3-DoF robotic arm, which demonstrates improved\naccuracy and efficiency in trajectory tracking compared to\nconventional neural network and fuzzy controllers.\nLearnable membrane parameters in SNNs: Some pa-\npers focus on developing bioinspired and adaptive membrane\nparameters for SNNs to improve their performance and\nefficiency. Ding et al. [22] proposes a bioinspired dynamic\nenergy-temporal threshold (BDETT) scheme that mirrors\nthe biological observation of a dynamic threshold positively\ncorrelated with average membrane potential and negatively\ncorrelated with the preceding rate of depolarization. Wei et\nal. [23] examines the limitations of applying existing time-to-\nfirst-spike (TTFS) learning algorithms and introduces a dy-\nnamic firing threshold (DFT) mechanism and a novel direct\ntraining algorithm for TTFS-based deep SNNs called DTA-\nTTFS. Fang et al. [24] proposes a training algorithm that\ncan learn the synaptic weights and membrane time constants\nof SNNs simultaneously, inspired by the observation that\nmembrane-related parameters differ across brain regions. The\nproposed methods in this work share similarities with the\nlearnable thresholding mechanism introduced by Wang et\nal. [25]. However, the study in this paper employs a channel-\nwise adaptive membrane potential threshold, which differs\nfrom the prior approach."}, {"title": "B. Diffusion Policy", "content": "Currently, diffusion models [26] and DDPMs [27] have\nbeen widely used in many related fields, especially in the\nfield of computer vision, such as high-resolution image\ngeneration [28], [29], image restoration [30], super-resolution\ntasks [31], [32], text-to-image generation [33]-[35], and\nother scenarios [36], [37]. The diffusion algorithm most\nrelevant to this work is the Diffusion Policy algorithm de-\nsigned for robotic manipulation proposed by Chi et al. [19].\nThey built a robot's visuomotor policy as a conditional\ndenoising diffusion process. This approach evaluates the\nDiffusion Policy across 12 different tasks from 4 different\nrobot manipulation benchmarks."}, {"title": "III. BACKGROUND", "content": "While elaborate conductance-based neuron models can\naccurately replicate electrophysiological measurements, their\ncomplexity makes them challenging to analyze in depth.\nTherefore, in the context of Spiking Neural Networks re-\nsearch, the most commonly employed neural model is the\nsimplified Leaky Integrate-and-Fire (LIF) model.\nThe LIF model is established as an RC-circuit composed\nof a resistor R and a capacitor C in parallel. Its dynamics\nare defined by two essential components: the evolution of\nthe membrane potential u(t) and a mechanism to generate\nspikes. According to elementary laws from the theory of elec-\ntricity, the evolution of the membrane potential is described\nby the following equation:Eq. 1:\n$\\tau_m \\frac{du}{dt} = -[u(t) - U_{rest}] + RI(t),$ (1)\nwhere the input current I(t) can be a continuous current or a\nshort current pulse. We refer to u as the membrane potential\nand to $\\tau_m = RC$ as the membrane time constant of the neu-\nron. Spikes are generated to transmit to postsynapse targets\nwhenever the membrane potential u crosses a threshold $\\theta$\nfrom below, as described by Eq. 2:\n$S(t) = H(u(t) - \\theta),$ (2)\nwhere H is the Heaviside step function."}, {"title": "B. Diffusion Model", "content": "The training process of DDPMs is designed to minimize\nthe difference between the forward diffusion process and the\nreverse denoising process. Specifically, the training goal is\nto minimize reconstruction errors by maximizing logarithmic\nlikelihood. This is usually done by the Variational inference\nmethod, which defines a Variational Lower Bound (VLB):\n$L = \\mathbb{E}_q \\sum_{t=1}^T D_{KL}(q(x_{t-1}|x_t, x_0) || p_\\omega(x_{t-1}|x_t))$, (3)"}, {"title": "IV. METHOD", "content": "The overall architecture of the model, as shown in the\nupper part of Figure 2, is a Spiking U-Net. The input,\nsampled from random Gaussian noise, is encoded into a\nspike sequence of fixed time length Ts through an encoding\nlayer. This spike sequence consists of binary values, 0 and\n1, representing the refractory and excited states, respec-\ntively. The encoded input is fed through consecutive levels\nof Spiking Blocks and downsampling modules, and then\nupsampled through multiple layers to restore to the input\ndata dimensions. To evaluate the error between prediction\nnoise and sampling noise, the dynamic spike signals formed\nby the temporal sequence need to undergo a decoding layer\nto be transformed back into static noise output. Each spiking\nblock comprises two spiking neurons that form a residual\nconnection block, with each spiking neuron composed of a\nconvolutional layer and Leaky Integrated and Fire neurons.\nThe neuron performs convolution operations (i.e., summation\noperations) on the spike state sequence received from the\nupper neurons within the time Ts at time ts, accumulating\nthe operation results into the current neuron's membrane\npotential. Once the accumulated membrane potential exceeds\nthe set threshold at time ts, the neuron emits a spike to the\nnext layer neuron at time ts, as described in Sec. III-A.\nCommon residual connections are typically established af-\nter a non-linear activation function as illustrated in Fig. 3(a),\nconnecting the current activation with the previous activation,\nand performing summation operations. In this study, the LIF\nnode serves as a non-linear unit emitting spike signals. If\nfollowing the conventional approach and placing the residual\nconnection after the LIF node, the 0-1 state emitted by the\ncurrent LIF node would be summed with the 0-1 state of\nthe previous spike data. The 0-1 values in spike data do\nnot represent actual numerical values but rather two relative\nstates. Summing these two states at the position of the\nresidual connection in spike data would result in ternary\nstates, disrupting the neural morphology of the network, as\nillustrated in Fig. 3(b). In this paper, we position the residual\nconnections of neurons after the conv layer. The data after\nspiking conv operations itself consists of floating-point data,\nenabling summation without any cost. The resulting sum is\nthen passed into the LIF node, generating spike data that\ncan propagate normally to subsequent neurons as shown in\nFig. 3(c)."}, {"title": "B. Temporal Spiking Encoding And Decoding", "content": "Research on spiking neural networks is in its early stages,\nwith many designs drawing inspiration from traditional artifi-\ncial neural networks (ANNs), thus retaining aspects of ANN\narchitecture. Traditional ANNs operate as parallel processing\nnetworks, where static data generated at a single moment\nis synchronously fed into the network. In contrast, SNNS\nrepresent a dynamic temporal network structure, requiring\ninput data that is sequential in the time dimension. When\nattempting to apply SNN network structures to address\nproblems traditionally solved by ANN networks, a challenge\narises in the conversion and migration between static and\ndynamic data formats. To integrate datasets born from the\nfoundation of traditional ANN architectures into SNNs,\ntemporal spike encoding of the data is necessary, along with\nthe conversion of temporal spike sequences output by SNN\nnetworks back into static data to achieve the desired task.\nIn this study, we introduce a temporal spike encoding\nblock to transform the network's static input data into pulse\nsignals, as well as a Temporal compression decoding block\nto convert the temporal spikes output by the network back\ninto static noise estimates, as shown in Fig. 4."}, {"title": "C. Learnable Channel-wise Membrane Threshold", "content": "The spiking neuron, as the most fundamental and crucial\ncomponent of Spiking Neural Networks (SNNs), processes\nspike signals received from presynaptic neurons. The result\nof this information processing is reflected in the neuron's\nmembrane potential. The evolution process of the spiking\nneuron's membrane potential is described by Eq. 4. In this\nequation, $u_i^n[t]$ represents the membrane potential of the i-\nth neuron in the n-th layer at time t. The term $s_i^{n-1}[t-1]$\nindicates the spike state emitted by the i-th neuron in the\nn-th layer at time t \u2013 1. Here, \u03c4 denotes the time decay\nconstant, \u03b4(i, j) represents the connectivity between neurons\ni and j in different layers, and $W_{ij}$ signifies the weight of\nthe connection between the neuron i and the neuron j.\n$u_i^n[t] = \\tau u_i^n[t-1](1 - s_i^{n-1}[t-1]) + \\sum_{j\\in\\delta(i,j)} W_{ijs_j^{n-1}[t]}\\hspace{0.2cm} (4)$\nOnce the accumulated membrane potential surpasses a\npredetermined threshold, a spike signal is emitted to post-\nsynaptic neurons. The state equation for spike emission in a\nspiking neuron is given by Eq. 5:\n$s_i^n[t] = H[u_i^n[t] - \\theta_i^n]$ (5)\nwhere H represents the Heaviside step function and $\\theta_i^n$\ndenotes the membrane potential threshold for the i-th neuron\nin the n-th layer.\nThe membrane threshold in a spiking neuron is a crucial\nhyperparameter to determine both the firing rates and the\nmomentary amplitude of the membrane potential at the firing\ntime. However, as a hyperparameter, a manually set threshold\nmay not always align well with network parameters. For\ninstance, a high threshold can make it difficult for the\nmembrane potential to accumulate to a sufficient level to\nfire a spike, while a low threshold can cause neurons to\nfire spikes too easily, leading to reduced information content\nand increased power consumption. Furthermore, repeatedly\ntrying different thresholds during training would significantly\nincrease the model's training costs. Consequently, this issue\nmotivates the introduction of a learnable membrane potential\nthreshold, which allows neurons to autonomously adjust and\nself-shape.\nIntroducing a learnable membrane potential threshold in-\nvolves treating the threshold of each spiking neuron as a\ntrainable parameter. As depicted in Eq. 6, this approach\nenables the computation of threshold gradients during back-\npropagation, thereby allowing the optimization of threshold\nvalues through parameter updates.\n$\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{t=1}^{T_s} \\frac{\\partial \\mathcal{L}}{\\partial s_i} \\frac{\\partial s_i}{\\partial u_i} \\frac{\\partial u_i}{\\partial \\theta}$ (6)\nUnfortunately, the Heaviside step function is discontinuous\nand has a derivative of zero everywhere except at the\npoint of discontinuity. Therefore, when using the chain rule\nto compute the gradient of the Heaviside function during\nbackpropagation, a surrogate gradient must be employed, as\ndescribed in Eq. 7.\n$S'[H[x]] = \\begin{cases} 1 \\hspace{0.2cm} \\text{for} \\hspace{0.2cm} 0 \\leq x \\leq 0.5 \\\\ 0 \\hspace{0.2cm} \\text{for} \\hspace{0.2cm} \\text{otherwise} \\end{cases}$ (7)\nIndividually learning a large number of neuronal mem-\nbrane potential thresholds undoubtedly increases computa-\ntional complexity and the number of model parameters. Upon\nfurther investigation, we observed that there are noticeable\ndifferences in spike firing rates and the momentary mem-\nbrane potential at firing time between neurons in the same\nlayer but across different channels. However, these variables\nremain relatively consistent within the same channel, as\nshown in Fig. 5. Building upon the foundation of learnable\nmembrane potential thresholds, we introduced the concept\nof Learnable Channel-wise Membrane Threshold (LCMT)\nto adapt to the varying membrane potential accumulation\nstates and spike firing rates across different channels. LCMT\nrelaxes the constraints on membrane potential thresholds,\nsuch that spiking neurons within the same channel utilize\na consistent membrane potential threshold $\\theta^c$, as illustrated\nin Eq. 8. For brevity, we have omitted the superscript n.\n$\\frac{\\partial \\mathcal{L}}{\\partial \\theta^c} = \\sum_{i=1}^{C} \\sum_{t=1}^{T_s} \\frac{\\partial \\mathcal{L}}{\\partial s_i} \\frac{\\partial s_i}{\\partial u_i} \\frac{\\partial u_i}{\\partial \\theta^c}$ (8)\nIn the absence of constraints, the range for the membrane\npotential threshold $\\theta^c$ is (-\u221e, +\u221e). However, excessively\nlarge or small values for this threshold are undesirable.\nConsequently, it is preferable to confine the threshold to\na specific narrow range without introducing additional con-\nstraints. Inspired by [25], we introduce a new parameter m\nwith a range of (-\u221e, +\u221e) to limit the range of \u03b8 to a range"}, {"title": "V. EXPERIMENTS", "content": "The SDP model proposed in this study is evaluated in\nseven robotic manipulation tasks, following the experimen-\ntal setup and evaluation metrics used by Chi et al. [19].\nThese tasks include Push-T [39], BlockPush [40], Lift,\nCan, Square, ToolHang, and Transport. They encompass\na diverse range of actions, such as pushing, grasping, and\nlifting, as well as interactions between robotic arms and\ntheir environment, as illustrated in Fig. 7. To elaborate, the\nPush-T task requires using a circular end-effector to push\na T-shaped object into a fixed target box. The objective of\nBlockPush is to push two blocks into two different squares\nin any order. Both of these tasks are performed in a 2D\ntabletop environment. The remaining five tasks are sourced\nfrom RoboMimic [38] and are conducted in a 3D spatial\nsetting, utilizing datasets collected from proficient human\nteleoperated demonstrations. Specifically:\n\u2022 Lift: Involves picking up a block.\n\u2022 Can: Focuses on grasping and moving a soda can.\n\u2022 Square: Requires lifting an object with a square hole\nand fitting it onto a square pillar.\n\u2022 ToolHang: Involves grabbing a tool and suspending it.\n\u2022 Transport: Involves two robotic arms that pass an object\nbetween them.\nThis diverse set of tasks provides a comprehensive evaluation\nof the capabilities of the proposed SDP model. In terms\nof additional experimental settings, the timestep Ts for the\nspiking neural network is set to 4, while the timestep TD\nfor the diffusion process is set to 100. The proposed model\nis evaluated on a single NVIDIA RTX 4090 GPU to ensure\nsufficient computational performance and reliability.\nDuring the training process, checkpoints are saved every\n50 epochs. The reported results are based on the aver-\nage evaluation metrics of the best-performing checkpoint.\nFor most tasks, we use the success rate as the evaluation\nmetric; however, for the push-T task, we use target area\ncoverage. We compare two categories of methods: one\nusing artificial neural networks (ANNs), including LSTM-\nGMM [38], IBC [39], BET [40], and Diffusion Policy [19];\nand another using spiking neural networks (SNNs). We used\nSDDPM [17] as the baseline SNN in our diffusion policy.\nFor each baseline method, we selected their best performance\nacross various benchmarks. Specifically, for the SDDPM\nbaseline, we detailed the results obtained by adjusting all\nmembrane thresholds. For the BlockPush task, $p_x$ represents\nthe frequency of pushing x blocks into the target area. The\nresults from all these baseline methods and our proposed\nSDP model are summarized in Tab. I and Tab. II."}, {"title": "C. Ablation Studies", "content": "For the ablation study on\nthe SNN timestep Ts, we set Ts to 1, 2, 4, and 8 and report\nthe SDP model's performance on each benchmark, as shown\nof (-1, 1) effectively, as illustrated in Fig. 6. By setting\n$\\theta = \\frac{m}{\\sqrt{1+ m^2}}$ (9)\nThe derivative of Eq. 9 is expressed as:\n$\\frac{\\partial \\theta}{\\partial mc} = \\frac{1}{(1 + (mc)^2)(\\sqrt{1 + (mc)^2})} $(10)\nGiven these derivations, substituting Eq. 7, 9, and 10 into\nEq. 8 yields the gradient formula for the learnable channel-\nwise membrane threshold as expressed Eq. 11.\n$\\frac{\\partial \\mathcal{L}}{\\partial m^c} = \\sum_{i=1}^{C} \\sum_{t=1}^{T_s} \\frac{\\partial \\mathcal{L}}{\\partial s_i} \\frac{\\partial s_i}{\\partial u_i} \\frac{\\partial u_i}{\\partial \\theta^c} \\frac{\\partial \\theta^c}{\\partial mc} = \\sum_{i=1}^{C} \\sum_{t=1}^{T_s}  S'[H[u[t] - \\frac{mc}{\\sqrt{1+ (mc)^2}}}]] \\frac{1}{(1 + (mc)^2) (\\sqrt{1+ (mc)^2}) }$(11)\nDuring backpropagation, this gradient is utilized to update\nthe thresholds."}, {"title": "D. Energy Consumption Analysis", "content": "The theoretical energy consumption for both SNNs and\nANNs, as referenced by [41], can be calculated as follows:\n$E_{SNN} = E_{AC} \\times SOPS$ (12)\nand\n$E_{ANN} = E_{MAC} \\times AOPS,$ (13)\nwhere SOPs represents the number of spike-based accumu-\nlate operations (AC) and AOPs represents the number of\nmultiply-and-accumulate operations (MAC). Assuming that\nboth AC and MAC operations are implemented on 45nm\nhardware, the energy consumption is $E_{AC} = 0.9\\mu J$ and\n$E_{MAC} = 4.6\\mu J$. The number of AC operations in an SNN\nis estimated as:\n$SOPS = T_S \\times \\psi \\times AOPs,$ (14)\nBased on the calculations above, the U-Net network that\nuses spiking neurons reduces 94.3% of the dynamic energy\nconsumption compared to its ANN counterpart, as shown in\nFig. 9. This demonstrates the significant potential of the SDP\nmodel proposed in this paper for applications in low-power\nembodied intelligence."}, {"title": "VI. CONCLUSION", "content": "This study introduces the Spiking Diffusion Policy (SDP)\nmethod for robotic manipulation, seamlessly integrating\nspiking neurons into a diffusion policy framework. This\nintegration enhances computational efficiency while achiev-\ning high accuracy in evaluated robotic tasks. We propose\nthe Learning-based Channel Membrane Threshold (LCMT)\nmechanism to enable the adaptive acquisition of membrane\npotential thresholds, thereby aligning with the varying mem-\nbrane potentials and firing rates across channels and elim-\ninating the cumbersome process of manual hyperparameter\ntuning. Extensive experiments demonstrate the potential of\nthe SDP model for applications in the field of low-power\nembodied AI."}]}