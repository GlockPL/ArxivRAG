{"title": "Towards Efficient IMC Accelerator Design Through Joint Hardware-Workload Co-optimization", "authors": ["Olga Krestinskaya", "Mohammed E. Fouda", "Ahmed Eltawil", "Khaled N. Salama"], "abstract": "Designing generalized in-memory computing (IMC) hardware that efficiently supports a variety of workloads requires extensive design space exploration, which is infeasible to perform manually. Optimizing hardware individually for each workload or solely for the largest workload often fails to yield the most efficient generalized solutions. To address this, we propose a joint hardware-workload optimization framework that identifies optimised IMC chip architecture parameters, enabling more efficient, workload-flexible hardware. We show that joint optimization achieves 36%, 36%, 20%, and 69% better energy-latency-area scores for VGG16, ResNet18, AlexNet, and MobileNetV3, respectively, compared to the separate architecture parameters search optimizing for a single largest workload. Additionally, we quantify the performance trade-offs and losses of the resulting generalized IMC hardware compared to workload-specific IMC designs.", "sections": [{"title": "I. INTRODUCTION", "content": "In-memory computing (IMC) is one of the promising solutions to implement energy- and area-efficient neural network accelerators, essential for advancing artificial intelligence (AI) applications [1]-[6]. To optimize IMC system design and implement truly efficient IMC chips, a comprehensive design approach across multiple architecture hierarchy levels is essential. This includes addressing device-level design parameters and non-idealities, optimizing circuit-level components and IMC macros, consideration of architecture-level design with attention to data transmission across chip components, and enhancing software-level and workload performance [1]. As Al models and the number of IMC hardware parameters grow in complexity, manual optimization of software and hardware parameters becomes infeasible. Consequently, software-hardware co-design methodologies, such as hardware-aware neural architecture search (HW-NAS) and hardware space exploration, are essential for developing efficient and optimized IMC hardware [7]-[9].\nCurrent state-of-the-art methods and frameworks for design space exploration in IMC systems are primarily focused on optimizing of IMC hardware designs for specific workloads and applications [10]-[15]. However, IMC chips often need to be more generalized to support a variety of workloads effectively. In addition, this field faces several open challenges, including the lack of unified framework to accommodate diverse Al models and different types of IMC hardware, runtime efficiency limitations and slow optimization speed, and insufficient architecture- and system-level considerations [7]. In this work, we address these challenges and propose high-speed joint hardware-workload design space exploration for IMC architectures, which aims to search for optimized generalized IMC system design parameters capable of supporting a range of different workloads effectively.\nWe demonstrate that hardware-workload co-optimization across multiple workloads is crucial for achieving optimal energy efficiency, on-chip area, and processing speed in a generalized IMC hardware system. Optimizing the design individually for each workload can result in 66\u2013100% of selected designs being incompatible with other workloads. Similarly, optimizing solely for the largest workload often yields suboptimal solutions. For instance, optimizing the IMC system for the VGG16 [16] workload and then deploying it for ResNet18 [17] results in lower performance compared to a joint optimization approach that considers all workloads. Specifically, joint optimization achieves a 36% higher energy-area-latency score, 22% lower latency, and 25% lower energy consumption (see Fig. 2 in Section IV).\nOverall, the main contributions of this work include implementing a joint hardware-workload framework to optimize generalized IMC hardware that supports multiple workloads, along with a comparative analysis against separate single-workload optimization. Additionally, our approach provides insights into the energy and latency trade-offs and performance loss involved when transitioning to a generalized design capable of supporting diverse workloads."}, {"title": "II. STATE-OF-THE-ART DESIGN SPACE EXPLORATION FOR IMC HARDWARE", "content": "State-of-the-art methods for design space exploration in IMC hardware can be classified into three types: model parameters search for a fixed architecture, co-optimization of architecture and model, and hardware parameters optimization for a fixed model [7]. Model parameters search for a fixed IMC architecture focuses on optimizing neural network models to meet specific IMC hardware constraints, as demonstrated in [18]\u2013[22]. This approach targets model optimization to align with IMC hardware limitations and constraints, maintaining high model accuracy while mitigating the effects of IMC device non-idealities on performance accuracy [23]. Co-optimization of model and architecture aims to identify an optimized pairs model and hardware parameters for specific applications, as seen in [10], [12], [13]. While hardware parameters optimization for a fixed model targets design space exploration to identify optimal hardware parameters that most effectively support a specific model [11], [15]. A primary limitation of these frameworks is their focus on optimizing IMC hardware for specific neural network models, which restricts hardware generalizability. The output designs obtained from these frameworks lack the flexibility to accommodate diverse workloads. To address this gap, we propose a joint hardware-workload optimization framework aimed to search for optimized IMC hardware parameters that can effectively support multiple workloads.\nMoreover, most hardware design exploration frameworks focus on device-level parameters, e.g. optimal bits per cell, as well as circuit parameters related to the IMC crossbar macro and peripheral circuits, including crossbar size, ADC precision, and number of ADCs per macro [10]\u2013[12], [14]. However, to achieve a realistic assessment of IMC chip performance, it is essential to consider higher-level architectural hierarchies. These often contribute significantly to energy consumption and area overhead, so effective energy efficiency of IMC system can be 100 times lower than the performance measured at the macro level [24]. A recent framework focusing on larger space of hardware parameters is CoMN [15], which considers optimization architecture-related parameters, e.g. tile sizes and buffer sizes, for a specific workload. In this work, we also consider optimization of architecture hierarchy parameters, but optimizing for a more generalized case, accommodating diverse workloads."}, {"title": "III. JOINT HARDWARE-WORKLOAD OPTIMIZATION", "content": "We propose a joint hardware-workload optimization approach and develop the framework searching for optimized IMC-based chip architecture parameters that support different workloads, resulting in a more generalized hardware solution, as shown in Fig. 1. The framework takes as inputs a set of workloads and a defined search space, and outputs hardware-workload-optimized designs that achieve the highest score in the specified objective function, including optimized hardware parameters and corresponding performance metrics. Experiments are conducted with different objective functions (see Section IV). The framework performs IMC hardware optimization by jointly considering all workloads, using the highest metrics across workloads to calculate the objective function. Compared to sequential optimization or optimizing solely for the largest workload, this approach yields a more generalized hardware solution, effectively optimized to support and perform well across all specified workloads."}, {"title": "A. Framework overview", "content": "We propose a joint hardware-workload optimization approach and develop the framework searching for optimized IMC-based chip architecture parameters that support different workloads, resulting in a more generalized hardware solution, as shown in Fig. 1. The framework takes as inputs a set of workloads and a defined search space, and outputs hardware-workload-optimized designs that achieve the highest score in the specified objective function, including optimized hardware parameters and corresponding performance metrics. Experiments are conducted with different objective functions (see Section IV). The framework performs IMC hardware optimization by jointly considering all workloads, using the highest metrics across workloads to calculate the objective function. Compared to sequential optimization or optimizing solely for the largest workload, this approach yields a more"}, {"title": "B. Selected IMC hardware, search space and hardware per-formance evaluation", "content": "In this work, we conduct the experiments considering several levels of IMC hardware hierarchy shown in Fig. 1. We simulate a tiled, crossbar-based architecture with resistive random access memory (RRAM) devices (from [25]) and 32nm CMOS technology. Each tile consists of $C_{per \\ tile}$ cross-bars along with peripheral circuits, ADCs, column and row drivers, and input/output buffers. Data transmission between tiles occurs through shared routers, following the architecture in [26], where each router connects to $T_{per \\ router}$ tiles. The overall chip structure includes $G_{per \\ chip}$ tile groups and a global buffer.\nFor hardware estimations, we use CIMLoop [27], which integrates Timeloop [28] for mapping and employs Accelergy [29] for energy estimations. The crossbar-related estimations in CIMLoop are equivalent to those in NeuroSim [30], but with reduced simulation time, which significantly decreases the search duration for optimized hardware configurations.\nThe search space, shown in Fig. 1, includes crossbar sizes (both rows $Xbar_{rows}$ and columns $Xbar_{cols}$), number of cross-bars per tile $C_{per \\ tile}$, number of tiles per router $T_{per \\ router}$, number of tile groups within the chip $G_{per \\ chip}$. Additionally, we include operating voltage $V_{op}$, impacting both energy efficiency and throughput [27]. Moreover, we consider the number of bits in RRAM cell $Bitscell$ (which affects hardware configuration rather than performance accuracy), cycle time $T_{cycle}$ (representing operating frequency), and the size of the global buffer $GLB$ storing input and output data. Overall, this search space contains approximately 1.9 \u00d7 107 configurations."}, {"title": "C. Algorithm selection", "content": "The most commonly used optimization algorithms for model and hardware design space exploration (Table I) include evolutionary algorithms (EA), differential search (DS), reinforcement learning (RL), and Bayesian optimization (BO) [7]. DS is particularly well-suited for differentiable search spaces in HW-NAS with constrained optimization, where only software model parameters are optimized under hardware constraints or co-optimization of software and hardware parameters, as demonstrated in [14]. In this work, we use an evolutionary algorithm, specifically a genetic algorithm, as it performs faster than RL and BO for a discrete search space of moderate size [7]. The objective function (score s) is calculated as\n$s = f(E_w, L_w, A)$\n$s.t. A \u2264 A_{constr}$  (1)\nwhere $E_w$ is the energy required to process a specific workload on the sampled IMC hardware, $L_w$ is the latency of this workload, A represents the on-chip area of this hardware. For example, score s can be calculated as $s = f = max(E_w) X max(L_w) \u00d7 A$, where each generation, we consider highest latency $max(L_w)$ and energy $max(E_w)$ across all workloads in the objective function aiming to minimize these scores. In Section IV, we also demonstrate the experiments with the other constraint objective functions."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "The workloads evaluated in these experiments cover the entire spectrum of CNN model types, including ResNet18 [17], VGG16 [16], AlexNet [31] and MobileNetV3 [32]. Each joint optimization search (with P = 40 and G = 10) takes approximately 4 hours on an AMD processor with 64 cores. Across experiments with both constrained and unconstrained objective functions, we observed that unconstrained searches often led to designs with excessively large on-chip area (Fig. 1). Thus, adding area constraints is crucial, and we present the results for constrained searches accordingly. In this section, we refer to the proposed optimization as 'joint search' and to optimization over individual workloads separately as 'separate search'.\nFigure 2 demonstrates the performance of the joint search (top-10 best selected designs) across 5 random iterations with different initial populations, compared to separate searches over individual workloads. The final scores of separate searches are recalculated for fair comparison with joint optimization for the performance across all workloads. The graph indicates that, in separate optimization for specific workloads, most of the best-selected designs fail to support all workloads ('failed designs' in Fig. 2), except for the largest workload, VGG16. While hardware optimized solely for the largest workload performs worse than joint optimization, as evidenced by implementing ResNet18 on VGG16-optimized hardware versus a jointly optimized hardware (Fig. 2, on the right). Overall, the example in Fig. 2 demonstrates that joint optimization achieves 36%, 36%, 20%, and 69% better energy-latency-area scores for VGG16, ResNet18, AlexNet, and MobileNetV3, respectively, compared to the separate search optimizing for the single largest workload (VGG16).\nWhen implementing a generalized architecture supporting multiple workloads, some performance metrics, such as energy or latency, are inevitably sacrificed compared to a design optimized for a single workload. Fig. 3 illustrates the performance loss in the generalized IMC architecture obtained via joint optimization, comparing it to workload-specific architectures and showing the percentage loss in score as the architecture becomes more generalized. Each graph presents the top-10 designs from a joint hardware-workload search alongside results from separate searches optimized individually for four different workloads under a specific objective function. The performance loss in a generalized design varies depending on the objective function. For instance, in energy optimization, both the joint and separate search approaches converge to designs with similar metrics. Scores in each graph are normalized to the best architecture from the joint search, and convergence curves over 10 generations of the evolutionary algorithm are provided for each joint case. To ensure a fair comparison, each search begins with the same set of initial architectures (using a specified random seed). Overall, the generalized models can lose from 17% to 85% (Fig. 3) of the score comparing to workload-specific designs. Additionally, we highlight the top designs selected in each joint search scenario."}, {"title": "V. CONCLUSION", "content": "We proposed the joint hardware-workload optimization framework for IMC design space exploration, aimed at identifying an optimized, generalized IMC hardware solution capable of supporting a variety of workloads. Our results demonstrate that this joint optimization approach leads to optimized designs with better performance compared to optimizing hardware for each workload individually or solely for the largest workload. Additionally, we analyzed the performance trade-offs and losses involved in transitioning from IMC solutions optimized for specific applications to more generalized solutions capable of supporting diverse workloads."}]}