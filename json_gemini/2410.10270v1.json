{"title": "QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis", "authors": ["Abhijit Manatkar", "Ashlesha Akella", "Parthivi Gupta", "Krishnasuri Narayanam"], "abstract": "Discovering meaningful insights from a large dataset, known as Exploratory Data Analysis (EDA), is a challenging task that requires thorough exploration and analysis of the data. Automated Data Exploration (ADE) systems use goal-oriented methods with Large Language Models and Reinforcement Learning towards full automation. However, these methods require human involvement to anticipate goals that may limit insight extraction, while fully automated systems demand significant computational resources and retraining for new datasets. We introduce QUIS, a fully automated EDA system that operates in two stages: insight generation (ISGEN) driven by question generation (QUGEN). The QUGEN module generates questions in iterations, refining them from previous iterations to enhance coverage without human intervention or manually curated examples. The ISGEN module analyzes data to produce multiple relevant insights in response to each question, requiring no prior training and enabling QUIS to adapt to new datasets.", "sections": [{"title": "1 Introduction", "content": "Exploratory Data Analysis (EDA) is the process of discovering meaningful insights from vast amounts of data, and it is a complex task requiring careful data exploration. There are various EDA techniques to uncover insights by analyzing patterns in the data. Automated Data Exploration (ADE) systems accelerate the EDA process through automation.\nADE literature includes statistics-based (Sellam et al., 2015; Ding et al., 2019; Wang et al., 2020; Ma et al., 2021, 2023) and interactive methods (Milo and Somech, 2016, 2018b; Agarwal et al., 2023; He et al., 2024), where users explore data through natural language queries or receive suggestions for subsequent actions. Visualization-based techniques (Vartak et al., 2015; Demiralp et al., 2017; Srinivasan et al., 2018; Wu et al., 2024) offer visual insights and allow further queries. However, these methods can become resource-intensive due to extensive user interactions. Goal-oriented ADE approaches, generate insights based on predefined objectives (Tang et al., 2017; Seleznova et al., 2020; Omidvar-Tehrani et al., 2022; Laradji et al., 2023). This approach directs the exploration using predefined objectives, such as natural language goals or statistical measures of interestingness. While this reduces user interactions, it may constrain the insights to only those aligned with the predetermined goals.\nADE using reinforcement learning is studied (Milo and Somech, 2018a; Bar El et al., 2019, 2020; Personnaz et al., 2021; Garg et al., 2023) to achieve full automation. While these systems minimize user involvement, they often demand dataset-specific training and substantial computational resources, particularly as the number of features, categorical values, or patterns increases, making the process increasingly challenging."}, {"title": "1.1 Motivation", "content": "An effective EDA system exercises statistical examination with attention to data semantics, such as analyzing trends in date and sales price or examining the impact of weather on flight delay. Systems like (Demiralp et al., 2017; Deutch et al., 2022; Ma et al., 2023; Guo et al., 2024) leverage Large Language Models (LLMs) to drive the analysis based on natural language goals. Systems which use LLMs to generate relevant questions based on natural language goals (Laradji et al., 2023), drive insight discovery based on user queries (Wang et al., 2022), and interpret analysis objectives from the user's natural language input to specify desired outcomes (Lipman et al., 2024) have also been proposed. Guiding EDA through insightful questions enables purposeful exploration, clarifying analysis goals, and deriving actionable insights. In contrast, such a goal-oriented approach (Laradji et al., 2023)"}, {"title": "1.2 Our Contributions", "content": "We propose a two-stage ADE system, QUIS, that fully automates the EDA process. In the first stage, QUIS generates questions based solely on the data semantics (dataset information like name, description, column names, and column descriptions) without requiring predefined objectives. In the second stage, QUIS uses statistical analysis to produce insights corresponding to the questions from the first stage. This research contributes to the following advancements\n\u2022 Question Generation (QUGEN) module generates questions in iterations, where questions generated in previous iterations, along with their reasoning and relevant information, serve as examples for subsequent iterations. This approach helps generate unique questions with broader coverage by providing additional context and guidance to the LLM in each iteration. Our approach eliminates the dependency on manually curated examples and predefined analysis goals.\n\u2022 Insight Generation (ISGEN) module analyzes the data using statistical patterns and classical search techniques to generate insights in response to the questions from the QUGEN module without requiring prior training. For a given question, this module provides multiple relevant insights.\nQUIS offers notable benefits, including reduced dependency on expert knowledge, enhanced efficiency in the exploration process, the ability to uncover a broader range of insights from the data, and ease of use across various datasets."}, {"title": "2 Preliminaries", "content": "Although it is challenging to precisely define the notion of an insight due to variations in users' objectives, for this work, we adopt the definition of an insight consistent with previous studies (Ding et al., 2019; Ma et al., 2023). Consider a tabular dataset $D = {X_1,X_2,... X_n}$ where each $X_i$ is an attribute (column) of the dataset. An insight, denoted by $Insight(B, M, S, P)$, consists of the following:\n1. Perspective - A perspective consists of a tuple (B, M). B represents the breakdown attribute, and M is the measure, referring to a quantity of interest from the table. Typically, M is of the form $agg(C)$ where agg (measure function) is an aggregation function, like count(), mean(), sum(), etc., and C (measure column) is a numerical attribute of the dataset. B is the breakdown dimension, a column of interest from the table, for which we want to compare different values of M. For each perspective (B, M), we can compute a view $view(D, B, M)$ of the dataset D by grouping on B and calculating the measure M for each group. For example, computing $view(D, Year, mean(Performance))$ is equivalent to applying the SQL query: SELECT Year, AVG(Performance) FROM D GROUP BY Year.\n2. Subspace - A subspace $S = \\bigcup_{i}\\{(X_i, Y_{ik})\\}$ is a set of filters that determine a subset $(D_S)$ of the dataset D. Each $X_i$ is an attribute, and each $Y_{ik}$ is a corresponding value of the column $X_i$ of D. A tuple $(X_i, Y_{ik})$ denotes that the dataset is to be filtered for rows where $D[X_i] = Y_{ik}$.\n3. Pattern - The pattern P represents the type of insight observed. It belongs to a predefined set of known patterns, such as trends or outliers.\nThe QUIS system incorporates the following insight types as candidates for our patterns: (1) Trend - An increasing or decreasing trend is seen in a set of values. (2) Outstanding Value - The largest (or smallest) value in a set of values is significantly larger (or smaller) than all other values in the set. (3) Attribution - The highest value accounts for a large proportion (\u2265 50%) of the total of all values in the set. (4) Distribution Difference The distribution of values in a set changes notably from one subspace to another.\nAs an example, consider the insight given by\n\u2022 B = Year, M = mean(Performance)\n\u2022 S = {(Department, \"Sales\")}\n\u2022 P = Trend\nThis insight suggests that for the \"Sales\" department, there has been a trend in the average employee performance over the years.\nBy combining a breakdown B, a measure M, and a subspace S, we can compute a unique view of the dataset D by first applying the filters in S on D to arrive at $D_S$, then computing the $view(D_S, B, M)$ as described. Let V(D) be the set of all possible views of dataset D that can be computed in this manner. A search for insights involves finding views belonging to V(D) for which"}, {"title": "3 Methods", "content": "The EDA process is often guided by the questions that arise from the semantic context and the statistical properties of the dataset. Hence, we propose an approach, QUIS (QUestion-guided InSight generation), that employs a two-stage process (refer to Figure 1). The first stage, QUGEN, leverages LLMs to formulate questions based on the dataset schema, basic statistics, and iteratively updated in-context examples. The second stage, question-driven insight generation (ISGEN), systematically analyzes the tabular data statistics based on the questions to uncover meaningful insights."}, {"title": "3.1 Question Generation (QUGEN)", "content": "Our QUIS framework begins with QUGEN producing a set of Insight Cards. Each Insight Card encapsulates relevant information aligning with recent advances in automated EDA (Ding et al., 2019; Ma et al., 2021). In particular, an Insight Card (example in Figure 2) includes four components: Question, which is the generated natural language question aimed at guiding data analysis; Reason, which explains the rationale behind the generated question to help further analysis; Breakdown B, and Measure M. The Reason is used by QUGEN to enhance the coverage, and other components are used by both QUGEN and ISGEN."}, {"title": "3.1.1 Input Prompt", "content": "The prompt for QUGEN consists of several key components (for details refer to Figure 6 in Appendix), starting with a high-level description of the data analysis task objective. It then provides detailed instructions for generating an Insight Card by examining the table schema and basic statistics along with a few-shot example table schemas"}, {"title": "3.1.2 QUGEN pipeline", "content": "The QUGEN LLM is prompted to generate multiple Insight Cards, as shown in Figure 1. The LLM's response is sampled s times with a temperature t, with each sample containing n Insight Cards. However, the exact number of Insight Cards per sample may vary slightly due to the fixed output token length.\nEach Insight Card undergoes a filtering process: first, cards with questions not semantically relevant to the table schema are removed using semantic similarity computed using the all-MiniLM-L6-v2 Sentence Transformers model (Reimers and Gurevych, 2019). Next, duplicate Insight Cards are eliminated based on semantic similarity between pairs of questions. Simple or rudimentary questions are filtered out by converting them to SQL queries and applying them on the dataset; if a query returns only one row, the question is discarded. This ensures that only in-depth questions are retained for comprehensive data analysis.\nQUGEN is iterative in nature (refer Figure 1). It uses subset of Insight Cards generated until the current iteration as in-context examples in the prompt for the next iteration, offering supplementary context and guidance to ensure generation of unique Insight Cards distinct from that of previous iterations. A key advantage of this comprehensive approach by QUGEN module is that it eliminates the need for manually providing dataset specific"}, {"title": "3.2 Insight Generation (ISGEN)", "content": "This module uses classical search techniques and insight scores based on different statistical measures to identify interesting insights from the data.\nTo determine whether a combination of B, M, and S reveals a particular pattern P, the module uses scoring functions based on data statistics and applies appropriate thresholds. For each insight pattern P, a corresponding scoring function $SCOREFUNC_P: V(D) \\rightarrow R$ is defined, along with a threshold value $T_P$. Further details about the scoring function and thresholds for each pattern are provided in Appendix A. If a combination of B, M, and S results in a view v = view($D_S$, B, M) such that $SCOREFUNC_P(v) > T_P$, the insight pattern P is considered to have been observed in v.\nAn Insight Card produced by QUGEN module is processed in two stages; first via identifying a basic insight followed by a subspace search for deeper insights as described below."}, {"title": "3.2.1 Basic Insight", "content": "Extraction of a basic insight helps to depict any meaningful patterns in the relationship between B and M considering the entire dataset without applying any filters. The basic insight is derived from an Insight Card by computing the view $v_0$ = view(D, B, M). The applicable insight patterns are determined based on the data type of the breakdown B and the measure M. For instance, if B is an ordinal column like Year or Revenue, then the Trend pattern becomes relevant. Then, scores corresponding to these insight patterns are evaluated. For an insight pattern P, if $SCOREFUNC_P(v_0) > T_P$, then Insight(B, \u041c, \u0444, P) is returned as a basic insight (here \u0444 is an empty set)."}, {"title": "3.2.2 Subspace Search for Deeper Insights", "content": "Further insights can be generated from an Insight Card by searching for subspaces where the insight patterns are observed. To do so, we carry out a beam search procedure (Russell and Norvig, 2010) as described in Algorithm 1. The search takes an initial subspace $S_0$, a perspective (B, M) and a score function $SCOREFUNC_P$ corresponding to"}, {"title": "3.2.3 Post Processing", "content": "The post-processing stage of an insight formulates the final insight response, which consists of a natural language description and a corresponding data visualization, as shown in Figure 1 (ISGEN). These components are based on the identified pattern P. For each pattern P, the natural language response uses a predefined template to clearly communicate the key findings. For details in the plotting conditions for each pattern refer to Appendix B."}, {"title": "4 Experimental Evaluation", "content": "In our study, we evaluated the QUIS pipeline's effectiveness using human assessment and insight scores on three datasets: Sales (Verma, 2024), Adidas Sale (Chaudhari, 2022) and Employee Attrition (Subhash, 2017). Human evaluation focused on the individual insights assessing Relevance, Comprehensibility, and Informativeness (details in Appendix C). We tested two conditions: 1. ONLYSTATS, replacing the QUGEN module with a purely statistics based card generation module, to assess the autonomous performance of ISGEN, 2. QUIS, where both QUGEN and ISGEN were involved. For further information about the parameters of the experimental conditions, please refer to Appendix D. The insights were evaluated by six participants who are well-versed in data analysis,"}, {"title": "4.1 Human Evaluation", "content": "The results of the human evaluation in Figure 3 shows that for the Sales and Employee Attrition datasets, QUIS outperformed the ONLYSTATS baseline in terms of relevance, comprehensibility, and informativeness, suggesting QUIS's overall effectiveness. However, in the Adidas Sales dataset, ONLYSTATS performed slightly better, likely due to specific characteristics of this dataset which favour a simpler analytical approach."}, {"title": "4.2 Insight Score", "content": "We compare the average normalized outputs (in the range [0, 1]) of SCOREFUNC for all insights returned by the two experimental conditions. The comparison of scores across datasets shows that QUIS consistently outperformed the ONLYSTATS condition, with higher scores across all datasets as shown in Figure 4."}, {"title": "4.3 Diverse Insight Cards", "content": "To assess the effect of the iterative process of QUIS on Insight Card diversity, we analyzed the number of unique cards generated by QUIS over multiple generations (with varied number of total iterations). We started with 1 iteration and a sampling rate of 20, then progressed to 11 iterations with a sampling rate of 2, keeping the total number of outputs generated by the LLM constant at 20. In the first condition, no few-shot examples were used, while in the last condition, QUGEN iterated 10 times, appending the prompt with new few-shot examples sampled from all previous iterations (refer Figure 5).\nThe iterative process produced more diverse Insight Cards, as shown by the rise in the number of unique cards across successive iterations."}, {"title": "5 Conclusion & Future Work", "content": "EDA systems often rely on user-generated, goal-oriented questions, which means the quality of the generated insights depends solely on these input questions, introducing potential overhead. To address this limitation, we propose a fully automated EDA system that generates dataset-specific questions automatically and performs insight discovery. This system operates in a data-agnostic manner, requiring no prior training, thereby minimizing the dependency on user input and streamlining the overall insight discovery process.\nAs a future work, we propose to enhance QUGEN to generate questions in chunks where ISGEN processes each chunk of questions before QUGEN generates the next chunk. This would enable QUGEN to use insights and their scores from previous chunks to inform the generation of subsequent chunks. Additionally, we will explore incorporating other types of insights as future work. For example, we aim to include outlier in time-series, anomaly detection, predictive insights and trend reversal to further enhance the variety and depth of insights generated by the QUIS system."}, {"title": "Algorithm 1 Insightful Subspace Search", "content": "Require: Dataset D, Initial subspace $S_0$, perspective (B, M), language model LLM, SCOREFUNC, beam_width, max_depth, exp_factor\nEnsure: Top-K subspaces by score {$S_1, ... S_k$}\n1: function EXPAND(S)\n2: $avlbl_cols \\leftarrow D.cols \\setminus S.used_cols$\n\u25b7 S.used_cols are the columns used in the filters so far in S\n3: $w \\leftarrow get_weights(avlbl_cols, LLM)$\n4: $X \\leftarrow sample(avlbl_cols, w)$\n5: $y \\leftarrow sample(D[X])$\n6: return S + (X, y)\n7: end function\n8: $beam \\leftarrow [(S_0, SCOREFUNC(S_0))]$\n9: for $depth \\in \\{1,...,max_depth\\}$ do\n10: for (S, score) $\\in$ beam do\n11: for $i \\in \\{1, ..., exp_factor\\}$ do\n12: $S_{new} \\leftarrow EXPAND(S)$\n13: $score \\leftarrow SCOREFUNC(S_{new})$\n14: $beam.add((S_{new}, score))$\n15: end for\n16: end for\n17: $beam \\leftarrow top-k(beam,k=beam_width)$\n18: end for\n19: return beam\ninsight pattern P as input. A beam of the current best subspaces is maintained. At each step, each subspace S in the beam is expanded to exp_factor number of subspaces. Each expanded subspace $S_{new}$ is obtained by adding a filter (X, y) to S. The selection of (X, y) happens in two steps; selecting the filter column X followed by y, the value to filter.\nFirst, an LLM is prompted with (B, M) and an instruction to return candidate filter columns $X^{LLM} = \\{X_1^{LLM} ... X_k^{LLM}\\}$ that can lead to semantically meaningful insights. X is obtained by sampling from a distribution of available columns (columns of D that have not been used in filters in S) with the candidate filter columns $X^{LLM}$ having a probability mass of $W_{LLM} \\in [0,1]$ distributed evenly over available columns with the rest of the mass (1 - $W_{LLM}$) distributed over the remaining columns (D $\\setminus$ $X^{LLM}$). $W_{LLM}$ is decided in such a way to ensure that semantically relevant columns are picked with a high likelihood for filtering while ensuring that other columns also have a chance of being picked."}, {"title": "4. Distribution Difference", "content": "- This insight pattern can only be observed when the aggregation in the measure is COUNT(). Let $v^I$ and $v^F$ be the initial and final views. We use the Jensen-Shannon divergence (Lin, 1991) to compare the difference between the two distributions:\n$SCOREFUNCDD(v^I, v^F) = JSD(\\frac{v^I}{\\Sigma v^I}, \\frac{v^F}{\\Sigma v^F})$\nThe threshold is set to $T_{DD}$ = 0.2."}, {"title": "B Plotting per Pattern", "content": "\u2022 Trend: Scatter plots with trend lines are used to describe the increasing or decreasing nature of the data.\n\u2022 Outstanding Value: Bar charts are used for depicting the difference in the factors.\n\u2022 Attribution: Bar charts are used to show the percentage contribution of different factors\n\u2022 Distribution Difference: Pie charts are used to compare the distributions before and after a condition."}, {"title": "C Human Evaluation Criteria", "content": "The participants in our user study were asked to rate each generated insight on the following criteria on a scale of 1-5.\n\u2022 Relevance: To what extent the insight is applicable and useful in a given context?\n\u2022 Comprehensibility: To what extent is this insight understandable and easy to follow?\n\u2022 Informativeness: Does the insight provide substantial information for understanding the data?"}, {"title": "D Experimental Conditions", "content": "The ONLYSTATS experimental condition replaces QUGEN with a purely statistical method for generating (B, M) pairs as follows. First, a random B is sampled from the list of all eligible columns of the table. This is followed by computing the Kruskal-Wallis test (Kruskal and Wallis, 1952) of association between breakdown B and all possible measures M in the table. The Kruskal-Wallis test is a non-parametric variance analysis test, used to determine if two sets of samples come from different distributions. The top 20 pairs of (B, M), ranked according to the strength of association measured by the Kruskal-Wallis test are selected as input to ISGEN."}, {"title": "D.2 QUIS", "content": "For QUIS, the following parameter values were used:\nQUGEN\n\u2022 LLM: Llama-3-70b-instruct (AI@Meta, 2024)\n\u2022 Sampling temperature t 1.1\n\u2022 Number of samples at each iteration s = 3\n\u2022 Number of iterations n = 10\n\u2022 Number of in-context examples = 6\nISGEN\n\u2022 beam_width = 100\n\u2022 exp_factor = 100\n\u2022 max_depth = 1\n\u2022 $W_{LLM}$ = 0.5"}]}