{"title": "A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf\nDisease Detection", "authors": ["Pandiyaraju V", "Shravan Venkatraman", "Abeshek A", "Pavan Kumar S", "Aravintakshan S A", "Senthil Kumar A\nM", "Kannan A"], "abstract": "Farmers face various challenges when it comes to identifying diseases in rice leaves during their early stages of\ngrowth, which is a major reason for poor produce. Therefore, early and accurate disease identification is important\nin agriculture to avoid crop loss and improve cultivation. In this research, we propose a novel hybrid deep learning\n(DL) classifier designed by extending the Squeeze-and-Excitation network architecture with a channel attention\nmechanism and the Swish ReLU activation function. The channel attention mechanism in our proposed model\nidentifies the most important feature channels required for classification during feature extraction and selection.\nThe dying ReLU problem is mitigated by utilizing the Swish ReLU activation function, and the Squeeze-and-\nExcitation blocks improve information propagation and cross-channel interaction. Upon evaluation, our model\nachieved a high F1-score of 99.76% and an accuracy of 99.74%, surpassing the performance of existing models.\nThese outcomes demonstrate the potential of state-of-the-art DL techniques in agriculture, contributing to the\nadvancement of more efficient and reliable disease detection systems.", "sections": [{"title": "1. Introduction", "content": "Rice is one of the most essential foods in the world,\nconsumed by about 36% of the world's population.\nIndia, contributing 20% to global rice production, is\none of the leading producers of rice. Due to its high\ndemand, farmers often use excessive amounts of\nsynthetic fertilizers and pesticides, which has led to\na decline in soil quality [1]. For efficient rice\nproduction, a balanced fertilizer with adequate\nquantities of various nutrients is necessary [2].\nHowever, factors such as diseases, nutrient\ndeficiencies, and pests can easily affect the quality\nand quantity of paddy yield [3]. Farmers' inability to\ndetect leaf diseases and deficiencies early on often\nresults in reduced rice yields. Factors like\ntemperature, soil fertility, climatic conditions, and\nthe presence of microorganisms such as bacteria and\nviruses play a crucial role in the growth of paddy\nplants. Diseases can affect various parts of the\nplants, such as leaves, tillers, and florets,\nmanifesting as discoloration, lesions, or dryness [4].\nTherefore, it is essential to detect these signs during\nthe plant's growth. Identifying these diseases with\nthe naked eye is challenging, necessitating the\ndevelopment of intelligent models to facilitate this\nprocess. Various automated models have been used\nto identify such leaf diseases [5].\nPaddy leaf identification has become an important\nissue in recent years, as rice production is a\nsignificant economic and social challenge in many\nparts of the world. In South India, a majority of\ndishes are made from rice, making paddy production\na critical requirement. The quantity of rice produced\nin the Tanjore District of Tamil Nadu, Andhra"}, {"title": null, "content": "Pradesh, and Punjab are major contribution to the\nfood supply for the people of South and East India.\nHowever, diseases frequently attack paddy leaves,\nleading to a reduction in rice production. Therefore,\nplant health plays an important role in both Indian\nand global food production. In this context, the\neffective and efficient management of plant diseases\nis a significant research issue. Paddy leaf diseases\nmust be identified at an early stage and prevented to\nensure that the quantity of paddy and rice production\nis not affected. Leaf diseases can be analyzed\neffectively by collecting leaf images periodically\nand continuously monitoring them based on the\nresults of the analysis. Most existing analytics on\npaddy leaf diseases use Machine Learning (ML)\nalgorithms for effective image segmentation and\nclassification. However, these methods require\nseparate approaches for feature selection and\nclassification and often provide a minimum level of\nrequired accuracy. In contrast, DL algorithms can\nmore accurately extract and select contributing\nfeatures. Therefore, DL classifiers provide the most\naccurate predictions regarding the development of\npaddy leaf diseases.\nDL models are applied to identify many plant leaf\ndiseases efficiently [6]. Various automated methods,\nsuch as using edges, clustering, borders,\nsegmentation, thresholds, and active contours, are\nused to detect leaf diseases [7]. DL-based\napplications have been used for several plant disease\nidentification and classification tasks [8, 9].\nConvolutional Neural Networks (CNNs) are widely\nused in many real-time applications across various\ndomains [10]. Many Artificial Intelligence (AI)\ntechniques have been introduced and efficiently\napplied in agriculture, reducing the human effort\nrequired for tedious cultivation\nprocesses.\nAutomated models using Al are applied to detect\nplant leaf diseases precisely [11].\nThis research proposes a novel hybrid CNN\narchitecture for classifying paddy leaf diseases. Our\nmodel extends the SENet architecture with Squeeze\nand Excitation blocks using a channel attention\nmechanism and a Swish ReLU activation to\nfacilitate efficient decision-making. Existing models\ndiscussed in the literature show drawbacks when it\ncomes to handling vanishing gradients, and efficient\ncolor-based feature extraction. They also do not\nemploy optimal image preprocessing techniques to\nprepare data for better model training. In our work,\nwe create an image preprocessing pipeline"}, {"title": null, "content": "consisting of a sequence of operations, specifically\ndesigned to enhance the quality of paddy leaf images\nand normalize variations in lighting and scale,\nthereby facilitating better training by our model. The\nSqueeze and Excitation block adjusts the weights of\neach feature map by considering the\ninterdependencies between different feature\nchannels in CNNs, thereby improving information\npropagation and cross-channel interaction. During\nfeature extraction and selection, the channel\nattention mechanism is essential in determining\nwhich features are most significant for\nclassification. Swish ReLU addresses the dying\nReLU problem by introducing a smooth activation\nfunction that automatically adjusts its slope based on\nthe input, preventing neurons from getting stuck at\nzero.\nThe remaining contents of the paper are organized\nas follows: The relevant literature is covered in\nSection 2, the proposed classifier model is explained\nin Section 3, the experimentation is described in\nSection 4, and the conclusion and the research's\nfuture directions are discussed in Section 5."}, {"title": "2. Related Works", "content": "Stephen et al. [12] proposed an approach to address\nthe problem of rice leaf disease detection, which is\ntraditionally performed manually by farmers and is\nprone to errors. Their research introduced a novel\nmethod utilizing an IBS-optimized DGAN and a 2D\n3D CNN for feature extraction and for classification.\nThe combination of 3D fast-learning blocks with\n2DCNNs enhanced the detection of disease features,\nwhile the IBS algorithm improved the GAN's\nstability and prevented overfitting. The proposed\nmethod demonstrated superior performance with an\naccuracy of 98.7%, surpassing existing techniques\nlike XGBoost and SVM. Overall, the research\npresented a robust solution for early and accurate\nrice disease detection, though it acknowledged the\nneed for future studies to encompass a wider variety\nof plant diseases and features.\nChug et al. [13] proposed a framework to mitigate\nthe significant economic losses caused by plant\ndiseases through early detection. The authors\ndeveloped an optimized hybrid DL model that\ncombines pre-trained EfficientNet variants with ML\nclassifiers using the Optuna framework. They\ncollected a real-time image dataset of tomato early"}, {"title": null, "content": "blight disease and achieved an accuracy, ranging\nfrom 87.55% to 100%, validated on additional\ndatasets. The study highlighted the efficacy of their\napproach in reducing farmers' workloads and\nenabling timely disease treatment, though\nchallenges like dataset biases and limited\ncomputational resources were noted. This work\nunderscores the importance of integrating ML and\nDL for effective plant disease prediction.\nKumar et al. [14] came up with a solution for the\ninefficiency of traditional rice leaf disease\nidentification methods, which rely on visual\ninspection and are prone to errors. They designed a\nmulti-scale feature fusion-based RDTNet, which\nextracts features using local binary patterns,\ngrayscale, and histograms of oriented gradients,\ncombined with global and local features from\ntransformers and convolutional blocks. This dual-\nmodule approach significantly improved\nclassification accuracy, achieving 99.55% precision,\n99.54% F1-score, and 99.53% accuracy. The study\nvalidated the model on various datasets, confirming\nits applicability for real-time rice disease diagnosis\nand potential use in monitoring other crops. The\nresearch presents a promising method for enhancing\nagricultural disease detection accuracy.\nBhagat et al. [15] employed a method for classifying\nleaf diseases by focusing on handcrafted features\nand ML classifiers, aiming to match the accuracy of\nDL models. They utilized a 3-level decomposition-\nbased 2D-DWT for image feature extraction and\nPCA for dimensionality reduction. Stratified K-Fold\nvalidation ensured the maintenance of class ratios\ndue to the small dataset size. The classification was\nperformed using Random Forest and XGBoost,\nachieving accuracies between 97.73% and 100%\nacross multiple datasets. The study demonstrated\nthat handcrafted features and shallow classifiers\ncould yield competitive results compared to DL\nmodels, providing an efficient alternative for leaf\ndisease detection and classification in tomato, bell\npepper, and potato species.\nSahu et al. [16] proposed a DD (Deep Dream) based\ndisease detection architecture for crop leaves\n(CLDD) to address the problem of detecting crop\nleaves, which is crucial for preventing crop losses.\nThe research introduces 24 Hybrid Deep Neural\n(HDN) models that integrate eight variants of\nEfficientNet (EffiNet B0-B7) for feature extraction\nwith three ML algorithms: Stochastic Gradient\nBoosting, AdaBoost, and Random Forest. The DD"}, {"title": null, "content": "technique is employed to segment and preprocess\nthe lesions present in the leaves, enhancing\ninterpretability and classification accuracy. The\nproposed models were evaluated on the PlantVillage\ntomato crop dataset, with the DD-EffiNet-B4-ADB\nmodel achieving the highest 96% accuracy. The\nstudy concludes that the proposed HDN models,\nespecially when combined with DD segmentation,\nsignificantly improve the prediction accuracy of\ncrop diseases, thus aiding farmers in early detection\nof diseases with a field performance of 100%.\nPandiyaraju et al. [17] developed a novel ensemble\nDL model to accurately classify tomato leaf\ndiseases, addressing the limitations of existing ML-\nbased classifiers in detecting new disease types.\nThey present a weighted ensemble model that\ncombines an enhanced weighted gradient optimizer\n(EWGO) with temporal constraints and an\nexponential moving average function into improved\nNASNet mobile and VGG-16 training techniques.\nTen thousand photos of tomato leaves divided into\nnine disease groups make up the dataset that was\nused. The proposed model demonstrated superior\nperformance with an accuracy of 98.7%, precision\nof 97.9%, and F1-score of 98.7%, outperforming\nexisting models. The study concludes that the\nintegration of DL CNN frameworks with EMA\nfunctions and gradient optimization significantly\nenhances the classification accuracy and provides an\nextensive approach for detecting tomato leaf\ndiseases, with implications for improving crop yield\nand supporting sustainable agriculture.\nPatil et al. [18] demonstrated an automated system\nfor the classification of paddy leaf diseases in their\nearly stage to support farmers in protecting their\ncrops. The system employs ML algorithms such as\nAdaBoost and Bagging Classifier, along with a\ngenetic algorithm (GA) and nearest neighbour\nalgorithm (NNA) for disease identification. The\nimages of paddy leaves undergo pre-processing\nsteps including resizing, brightness correction,\nfiltering, and geometric transformations to enhance\nimage features. Feature extraction algorithms are\nthen applied to create a relevant feature dataset,\nwhich is used by cascaded classifiers to improve\naccuracy. The proposed system, implemented using\nMATLAB, can be deployed on Android and\nWindows platforms, demonstrating the potential to\nassist farmers to detect diseases early, and crop\nprotection with a high classification accuracy."}, {"title": null, "content": "Jiang et al. [19] employed a method combining DL\nand support vector machine (SVM) technology to\nincrease the accuracy of recognizing diseases in rice\nleaves. The research utilizes convolution neural\nnetworks (CNNs) to extract features from images of\nrice leaves, after which they are classified using\nsupport vector machines. The optimal SVM\nparameters were determined through 10-fold cross-\nvalidation, resulting in a recognition accuracy of\n96.8%, which is higher than traditional\nbackpropagation neural networks. The study\nconcludes that the combination of SVM and DL\nprovides an effective approach for crop disease\ndiagnosis, offering higher accuracy and presenting a\nvaluable method for future research in agricultural\ndisease identification.\nAl-Gaashani et al. [20] demonstrated a classification\nmethod to identify tomato leaf diseases leveraging\ntransfer learning and feature concatenation to\nimprove accuracy with limited training data. The\nresearch extracts features using NASNetMobile and\nMobileNetV2, which are then concatenated and\nreduced in dimension using principal component\nanalysis. These are then fed into traditional ML\nclassifiers, concluding that a multinomial logistic\nregression achieved the best performance with a\n97% accuracy. The study concludes that the\nconcatenation of features from different pre-trained\nmodels boosts classifier performance, making the\nmethod suitable for real-world applications where\ndata is limited. The proposed approach offers a\nrobust solution for accurate and early tomato disease\ndiagnosis, with the potential for further development\nto identify new disease types and operate in diverse\nconditions.\nPantazi et al. [21] proposed an automated method for\ncrop disease identification using Local One Class\nClassification and Binary Patterns (LBPs). Their\napproach involves dedicated One Class Classifiers\n(OCC) for each plant health condition, and the\nmodel was trained on vine leaves and tested on\nvarious crops, demonstrating high generalization\ncapability. An original algorithm for conflict\nresolution between OCC was introduced, achieving\na success rate of 95% across 46 plant-condition\ncombinations. The study concludes that the\nproposed method offers a novel and effective\napproach to plant disease identification, with high\ngeneralization potential across different crop\nspecies, providing valuable support for farmers in\nearly disease detection and crop protection."}, {"title": null, "content": "Ramesh et al. [22] proposed a method for\nrecognizing and classifying diseases in paddy leaves\nusing the Jaya Algorithm on an Optimized Deep\nNeural Network (DNN_JOA). Preprocessing\nincludes segmenting diseased areas using a\nclustering technique and transforming RGB images\nto HSV images for background removal. The\nDNN_JOA method classifies diseases by selecting\nthe best weights with the JOA. Experimental results\nshow high accuracy rates - Blast: 98.9%, Bacterial\nBlight: 95.78%, Sheath Rot: 92%, Brown Spot:\n94%, and Normal Leaves: 90.57%. Compared with\nother classifiers like ANN, DAE, and DNN,\nDNN_JOA demonstrates superior accuracy and\nstability, achieving a testing accuracy of 97%. The\nstudy concludes that future improvements in\nrecognition and classification methods can further\nenhance performance and reduce false\nclassifications.\nHaridasan et al. [23] presented an approach for\nclassifying rice crop diseases to improve treatment\nefficiency and reduce yield losses. The system uses\nimage processing, computer vision techniques, ML,\nand DL to identify diseases such as False smut, Rice\nblast, Sheath rot, Bacterial leaf blight, Brown leaf\nspot. After image pre-processing and segmentation,\nthe diseases are classified using a combination of\nsupport vector machine classifiers and convolutional\nneural networks. The proposed DL-based strategy,\nutilizing ReLU and softmax functions, achieves a\nhigh validation accuracy of 0.9145. The system also\nrecommends predictive remedies to assist in\ncombating these diseases. This approach enhances\nthe traditional methods of protecting paddy crops by\nproviding accurate and efficient disease detection.\nYakkundimath et al. [24] explored the diagnosis of\npaddy blast disease utilizing three multi-layer CNN\nmodels for transfer learning: CapsNet, EfficientNet-\nB7, and ResNet-50. Based on the severity of the\ndisease, field photos of blast disease that impact\nfifteen different types of paddy crops are\ncategorized. With a dataset of 20,000 labeled photos,\nthe study demonstrates that the CapsNet model\ndelivers significant results with a validation\nefficiency of 93.29% and a testing efficiency of\n90.79%. The average testing efficiencies of the\nResNet-50 and EfficientNet-B7 models are 85.10%\nand 88.72%, respectively. The CapsNet model\noutperforms the other models in terms of\nclassification and computational efficiency,"}, {"title": null, "content": "demonstrating its effectiveness in diagnosing blast\ndisease in paddy crops.\nSankareshwaran et al. [25] addressed the issue of\ndetecting leaf diseases in rice plants using a novel\napproach CAHA-AXRNet (crossover boosted\nartificial hummingbird algorithm-based AX-\nRetinaNet). This method aims to improve the\naccuracy and efficiency of detecting rice plant\ndiseases, which are crucial for yield production and\nquality. The CAHA optimization model is used to\ntune the hyperparameters of the AX-RetinaNet\nmodel. To categorize rice plants as healthy or\ndiseased, the study uses three datasets: rice plant,\nrice leaf, and rice disease datasets. The effectiveness\nof the technique is validated by performance\nindicators like accuracy, specificity, recall,\nprecision, and F1-score. The CAHA-AXRNet\napproach outperforms other techniques for the\ndetection of rice plant diseases, with an accuracy\nrate of 98.1%.\nBhimavarapu et al. [26] focus on detecting leaf\ndiseases in rice leaves using DL to ensure sufficient\nfood supply for a growing population. The study\nemploys Convolutional Neural Networks (CNN) to\nanalyze images of affected plant areas, extracting\nfeatures to diagnose diseases efficiently. In order to\nreduce loss and improve prediction performance and\nclassification accuracy, the suggested method adds\nan Optimizer Function and Improved Activation\n(IAOF) to the CNN model. This approach addresses\nthe limitations of conventional manual identification\nmethods, providing a faster, more effective, and\ncost-efficient solution. The IAOF-CNN model\nsurpasses existing methods in output performance,\ndemonstrating its effectiveness in rice disease\nprediction and classification."}, {"title": "3. Proposed Methodology:", "content": "We procured a dataset containing 5932 images of\nrice leaves to classify four different types of paddy\nleaf diseases. Our preprocessing pipeline included\ntechniques such as resizing, histogram equalization,\nGaussian smoothing, and normalization. We applied\nhistogram equalization to enhance the image\ncontrast, resized the images to the necessary\nresolution, used Gaussian smoothing to reduce\nimage noise, and normalized the pixel intensities for\nefficient computation.\nAfter preprocessing, we fed the images into our\nclassification model. We employed the proposed\nSwiSENet classifier, which utilizes channel\nattention for classification. Based on the features of\nthe leaf images, we classified them into four leaf\ndisease categories: Bacterial Blight, Blast,\nBrownspot, and Tungro. We evaluated the\nclassification model using various performance\nmetrics, including precision, F1-Score, recall, and\naccuracy. Figure 1 outlines the overall workflow of\nour research."}, {"title": "3.1 Dataset Exploration", "content": "We used a dataset developed by Sethy et al. [27],\nsourced from Rice Leaf Disease Image Samples\navailable on Mendeley Data. This dataset comprises\n5932 images, with sample images shown in Figure\n2, depicting rice leaves affected by four different"}, {"title": null, "content": "diseases: blast, bacterial blight, brown spot, and\ntungro. We implemented a 75-25 split to make use\nof this image dataset for our suggested approach,\nemploying 75% of the images for model training and\nthe remaining 25% for validation. As a result, we\nused 4449 of the 5932 photos for the training phase\nand the remaining 1483 images for validation.\nThe distribution of rice leaf data is illustrated in\nFigure 3. Among the 5932 images in the dataset,\n27% represent brown spot disease, 24.3% depict"}, {"title": "3.2 Preprocessing", "content": "Before utilizing the dataset for classification, we\npreprocess the images to improve the proposed\nmethod's performance. Therefore, we carry out the\nfollowing preprocessing techniques:\n\u2022 Resizing\n\u2022 Histogram Equalization\n\u2022 Gaussian Smoothing\n\u2022 Image Normalization\nInitially, we apply image resizing to ensure uniform\nimage sizes for the model. This is achieved by\ndetermining height and width scaling factors based\non a target size and the original image dimensions.\nThese scaling factors are then used to adjust the pixel\ncoordinates x and y, resulting in the same image with\ndifferent dimensions.\nAfter resizing, we compute histograms representing\nthe image intensities of each pixel. We then obtain\nthe cumulative distribution function (CDF) based on\nthe computed histogram using Equation 1.\n\\(CDF_{i} = \\sum_{j=0}^{i} P(j)\\)\nWhere Pr(j) is the probability of occurrence of\nintensity level j.\nWith the cumulative distribution function (CDF)\ncomputed, we obtain the existing pixel intensities\nin the image and transform them using Equation 2.\n\\(I_{equalised} (x, y) = round((\\frac{CDF(I(x,y)-CDF_{min}}{L-1}) (CDF_{max}-CDF_{min} + \\frac{CDF_{max}-CDF_{min}}{L-1}))\\)\nWhere, I(x,y) and \\(I_{equalised}(x,y)\\) are pixel intensities\nbefore and after histogram equalization respectively."}, {"title": null, "content": "After equalizing the pixel intensities, we filter the\nGaussian noise in the image using Gaussian\nsmoothing, which we apply to all the pixels of the\nimage. This smoothing operation involves a\nconvolution operation between the image and the\nGaussian kernel, which is generated for every pixel\nin the image based on Equation 3.\n\\(G(x, y) = \\frac{1}{2\u03c0\u03c3^{2}} e^{\\frac{-x^{2}+y^{2}}{2\u03c3^{2}}}\\)\nWhere G(x,y) is Gaussian kernel for the pixel (x,y)\nand o is the standard deviation of pixel intensities.\nWe normalize the Gaussian kernel before\nperforming the smoothing operation. Once\nnormalized, we carry out the smoothing operation\nusing Equation 4.\n\\(I_{filtered} = \\sum_{m} \\sum_{n} I(x + m, y + n) \u00b7 G(m,n)\\)\nFinally, we normalize the pixel intensities of the\nsmoothed image to enhance performance and\nfacilitate efficient computation, ensuring that the\nvalues fall within the range of 0 to 1. This is done\nusing Equation 5.\n\\(I_{normalised} (x, y) = \\frac{I(x,y)-minimumimagevalue}{maximumimagevalue-minimumimagevalue}\\)\nThe steps involved in the preprocessing are\noutlined in Algorithm 1. The results obtained after\neach step of preprocessing are shown in Figure 4."}, {"title": "3.3 Paddy Leaf Disease Classification", "content": "Figure 5 illustrates the layer architecture designed\nfor constructing the proposed channel attention\nenabled hybrid CNN framework, named SwiSENet\n(Swish ReLU activated, SENet-inspired CNN).\nPreprocessed images are taken and sent to the\nclassification model. These images move to the\nconvolution block where various features are\nextracted. The max-pooling operation downsamples\nthe input image by reducing the number of\nparameters. The feature map obtained after this\npooling operation is used by the Convolution SE\nblocks (Conv_SE), which determine the number of\nfeatures extracted from the feature map during each\nconvolution operation."}, {"title": "3.3.1 Conv_SE and SE blocks", "content": "The Convolution Squeeze and Excitation\n(Conv_SE) block extends the basic convolution\nblock by incorporating additional components that\nenhance feature extraction. This block is pivotal in\nthe network's architecture as it extracts the majority\nof features from the preprocessed paddy leaf images.\nThe Conv_SE block consists of a convolution block,\na Squeeze and Excitation (SE) block, a Channel\nattention layer, and the Swish ReLU activation\nfunction. The SE block within this architecture\nincludes a global average pooling layer, two fully\nconnected layers, and a reshape layer. The global\naverage pooling layer performs a squeeze operation,\nreducing the spatial dimensions to a single value per\nchannel. The two fully connected layers and the\nreshape layer execute the excitation operation,\nproducing channel-wise weights that emphasize\nsignificant features, thereby improving the model's\nability to focus on relevant information while\nreducing redundancy in the feature maps. This"}, {"title": "3.3.2 Convolution Block", "content": "The Convolution block in our architecture is a\nfundamental unit designed to extract features from\npreprocessed paddy leaf images. It includes a\nconvolution layer associated with the Swish ReLU\nactivation function. The convolution layer employs\nkernels that slide across the input feature map with a\nspecified stride value, performing convolution\noperations to extract features, which\nmathematically expressed as:\n\\(0(a,b) = \\sum_{m=-\u221e} \\sum_{n=-\u221e} 1(a \u2013 m, b \u2013 n) * K(m, n)\\)\nHere, O(x,y) represents a value in the output feature\nmap at position (x, y), I(x-i,y-j) represents the pixel\nvalue in the input at position (x-i,y-i), and K(i,j)\nrepresents a value of the kernel at position (i,j).\nThe Swish ReLU function enhances the non-\nlinearity of the network, aiding in the effective\ncapture of complex patterns within the input data.\nBy integrating the convolution operation with the\nSwish ReLU function, the block efficiently learns\nessential features from the input images, which are\ncrucial for subsequent processing stages."}, {"title": "3.3.3 Channel Attention", "content": "The Channel Attention module, another key\ncomponent of the Conv_SE block, aims to exploit\nthe inter-channel relationships of the features to\nfurther refine the feature maps. This module\n\\(M_{c}(F) = 0 (W_{1} (W_{0}(F_{avg})) + W_{1} (W_{0}(F_{max})))\\)\nWhere, o represents the sigmoid function, and\nWo and W\u2081 represent the MLP weights which are\nshared for both inputs [28]."}, {"title": "3.3.4 SwisH-ReLU Activation Function", "content": "The Swish-ReLU activation function used in the\nConv_SE block combines the benefits of the Swish\nactivation function and the ReLU (Rectified Linear\nUnit) activation function. This composite function\nincludes a tunable hyperparameter, a, which\ncontrols the relative contributions of the outputs\nfrom Swish and ReLU. Through extensive\nexperimentation, an optimal value of a = 0.5 was\ndetermined, meaning that the activation function\nconsiders an equal contribution from both Swish and\nReLU. This balanced approach effectively mitigates\nthe Dying ReLU problem, where neurons become\ninactive, thereby maintaining a dynamic range of\nactivations that enhance the learning process. ReLU\nactivation function is expressed mathematically as\n\\(ReLU(k) = max (0, k)\\)"}, {"title": null, "content": "Swish activation function can be defined as the\nproduct of the feature map with the sigmoid function\nalong with a trainable parameter and is expressed as:\n\\(Swish(x) = x \u00b7 sigmoid(\u03b2x) = \\frac{x}{1+e^{-\u03b2}}\\)\nWhere x is the feature map which is obtained from\nthe convolution operation before activation and \u03b2 is\na trainable parameter.\nSwisH-ReLU is a combination of these two\nactivation functions and is mathematically\nexpressed as,\nSwisH - ReLU(x) = a * Swish(x) + (1 \u2013 \u03b1) * ReLU(x)"}, {"title": "Workflow:", "content": "In our SwiSENet model for classifying leaf diseases\nfrom paddy leaf images, the preprocessed images\nflow through various specialized blocks, each\ndesigned to extract and emphasize specific features\ncrucial for accurate classification. This section\noutlines how the input preprocessed paddy leaf\nimages are processed through the network, detailing\nthe role and scientific rationale behind each block.\nConvBlock_1 initiates the feature extraction\nprocess, transforming the input into an output of\nshape (None, 150, 150, 64) using 64 filters. This\ninitial convolution operation captures basic features\nlike edges, textures, and simple patterns from the\nleaf images. The Swish ReLU activation function\nenhances this process by providing smooth non-\nlinearity, aiding in better gradient flow and allowing\nthe model to learn intricate patterns more effectively.\nFollowing the ConvBlock 1, we employ\nMaxPooling_1 to reduce the spatial dimensions of\nthe feature maps while retaining the most prominent\nfeatures. This step is crucial for managing\ncomputational efficiency without sacrificing critical\ninformation. It simulates the process of focusing on\nareas of interest on the leaf surface, ignoring less\nrelevant details, thereby streamlining our attention\ntowards potential disease indicators like\ndiscoloration or lesions.\nThe model then processes the features through a\nseries of Conv_SE blocks. In ConvSEBlock_1 with\nan output shape of (None, 74, 74, 64), a convolution\nblock, an SE block, a Channel attention layer, and\nthe Swish ReLU activation function work together.\nThe convolution block here further refines the\nfeature extraction, emphasizing specific details such\nas disease spots and texture anomalies on the leaf\nsurface. The SE block, comprising a global average\npooling layer, two fully connected layers, and a\nreshape layer, performs a squeeze operation to\ncondense spatial dimensions into a single value per\nchannel. This operation reduces redundancy and\nemphasizes channel-wise significant features. The\nexcitation operation then scales these features to"}, {"title": null, "content": "highlight the most crucial aspects, ensuring that\ndisease-specific features are more pronounced.\nThe transition to a higher filter count in\nConvSEBlock_3 (None, 74, 74, 128) allows the\nmodel to capture more detailed patterns, such as\nsubtle color variations and complex textures\nassociated with different disease stages. Each\nConv_SE block leverages the SE mechanism to\nprioritize important features dynamically, thereby\nimproving the model's ability to discern between\nhealthy and diseased regions. ConvSEBlock_4 and\nConvSEBlock_5 (output shape: None, 74, 74, 128)\nenhances the model's capacity to extract intricate\ndetails, ensuring that the discriminative attributes of\ndiseases such as nutrient deficiencies are more\npronounced. The repeated application of SE and\nchannel attention mechanisms ensures that each\nlayer emphasizes the most relevant features,\nreducing redundancy and focusing on crucial\npatterns.\nWith ConvSEBlock_6 and ConvSEBlock_7 (output\nshape: None, 74, 74, 256), the model's depth and\ncomplexity increase, allowing it to capture high-\nlevel abstract features. These layers are critical for\nunderstanding the overall structure and distribution\nof disease patterns across the leaf surface. The\nincrease in filter count to 256 enables the model to\nrepresent these complex patterns effectively.\nGlobalAveragePooling then reduces the spatial\ndimensions, resulting in an output shape of (None,\n256). This layer of global average pooling reduces\nthe feature map to a single vector of 256 dimensions,\nsummarizing the learned features across the spatial\ndimensions. This condensation is crucial for feeding\ninto the dense layer, ensuring that the model retains\nonly the most significant information for\nclassification. Finally, the Dense layer with an\noutput shape of (None, 4) uses 1,028 parameters to\nperform the classification. This fully connected\nlayer takes the condensed features and maps them to\nfour classes, corresponding to the different types of\nleaf diseases being classified. Algorithm 2 maps out\nthe workflow of our SwiSENet model, designed to\nclassify various diseases in paddy leaves."}, {"title": "4. Results and Discussion", "content": "Our proposed model was trained and validated on a\nmachine that features an Intel Xeon CPU running at\n2.00GHz with support for KVM virtualization and\nan NVIDIA Tesla P100-PCIE-16GB GPU. Table 3\nprovides specifics on the parameters and\ncorresponding coefficients that were utilized to train\nthe model."}, {"title": null, "content": "Figure 6. Accuracy score obtained for each epoch\nduring training and validation phases for the\nproposed SwiSENet classifier\nFigure 7. Precision score obtained for each epoch\nduring training and validation phases for the\nproposed SwiSENet classifier\nFigure 8. Recall score obtained for each epoch\nduring training and validation phases for the\nproposed SwiSENet classifier\nFigure 9. F1 Score obtained for each epoch during\ntraining and validation phases for the proposed\nSwiSENet classifier"}, {"title": null, "content": "Figure 10. Confusion Matrix obtained from the"}]}