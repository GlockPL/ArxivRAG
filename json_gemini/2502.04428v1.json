{"title": "Confident or Seek Stronger: Exploring Uncertainty-Based On-device LLM Routing From Benchmarking to Generalization", "authors": ["Yu-Neng Chuang", "Leisheng Yu", "Guanchu Wang", "Lizhe Zhang", "Zirui Liu", "Xuanting Cai", "Yang Sui", "Vladimir Braverman", "Xia Hu"], "abstract": "Large language models (LLMs) are increasingly deployed and democratized on edge devices. To improve the efficiency of on-device deployment, small language models (SLMs) are often adopted due to their efficient decoding latency and reduced energy consumption. However, these SLMs often generate inaccurate responses when handling complex queries. One promising solution is uncertainty-based SLM routing, offloading high-stakes queries to stronger LLMs when resulting in low-confidence responses on SLM. This follows the principle of If you lack confidence, seek stronger support to enhance reliability. Relying on more powerful LLMs is yet effective but increases invocation costs. Therefore, striking a routing balance between efficiency and efficacy remains a critical challenge. Additionally, efficiently generalizing the routing strategy to new datasets remains under-explored. In this paper, we conduct a comprehensive investigation into benchmarking and generalization of uncertainty-driven routing strategies from SLMs to LLMs over 1500+ settings. Our findings highlight: First, uncertainty-correctness alignment in different uncertainty quantification (UQ) methods significantly impacts routing performance. Second, uncertainty distributions depend more on both the specific SLM and the chosen UQ method, rather than downstream data. Building on the insight, we propose a calibration data conp sstruction pipeline and open-source a constructed hold-out set to enhance routing generalization on new downstream scenarios. The experimental results indicate calibration data effectively bootstraps routing performance without any new data.", "sections": [{"title": "1. Introduction", "content": "Large language models (LLMs) deployment on edge devices have gained increasing attention in recent years, primarily due to their potential for low-latency, privacy-preserving inference. Given the computational and memory constraints of edge devices, small language models (SLMs) (e.g., Phi2-mini (Javaheripi & Bubeck, 2023) or Llama3.2-3B (Touvron et al., 2023) are designed for resource-efficient deployment, particularly on devices such as smartphones and wearable devices. Their overarching goal is to democratize the deployment of LMs, making it accessible and affordable to users across diverse settings and at any time (Lu et al., 2024; Zhou et al., 2023; Zhao et al., 2023). However, these SLMS often lack the robustness and scalability of LLMs (Chen & Varoquaux, 2024) (e.g., GPT-40 (Achiam et al., 2023) and Llama-3.1-405B), especially when faced with diverse and complex input queries under the deployment on edge devices, which eventually degrade the overall performance. This limitation raises a critical need for exploring the solutions to increase the response reliability of SLMs.\nTo mitigate this unreliability, a line of work proposes to partially offload challenging and complex queries from SLMs to LLMs (Chuang et al., 2024; Ong et al., 2024; Hu et al., 2024; Stripelis et al., 2024). A hybrid system is then established to wisely route the queries from SLMs and seek more reliable and deterministic responses from stronger LLMs. Although LLMs can exhibit superior performance, they incur high maintenance and inference costs given the large scale of model size and their infrastructure (i.e., a single NVIDIA A100 GPU can cost approximately $2,000 per month for deployment). Inaccurate routing by SLMs increases the volume of queries forwarded to LLMs, necessitating greater bandwidth allocation for maintaining the service of LLMs. As a result, operational costs and budgetary requirements rise accordingly, especially when continuous deployment is required. Hence, developing an effective routing strategy is crucial for fully deploying SLMs (Ong et al., 2024; Stripelis et al., 2024; Chuang et al., 2024), as it both enhances response reliability and reduces the costs associated with services and data transmission.\nLeveraging SLMs' self-uncertainty estimation emerges as a"}, {"title": "2. Reviewing Different Schools of Uncertainty Quantification and LLM Routing", "content": "robust strategy for enhancing routing effectiveness (Chuang et al., 2024; Ding et al., 2024). By relying on the self-assessed uncertainty, the system can better decide whether to handle a query locally or delegate it to a larger model without the aid of extra routers, ensuring that only queries deemed unreliable by the SLMs are routed to LLMs. As a result, the uncertainty-based routing approach not only generalizes well to new datasets, as only self-assessed information from SLM is needed, but it also reduces the high operational costs associated with accurately running LLMs. To this end, we aim to explore two open and nontrivial research questions for uncertainty-based SLM routing:\n1) What is the best practice of uncertainty estimation for query routing from SLMs to LLMs? In this research question, we benchmark the uncertainty-correctness alignment of each uncertainty quantification (UQ) method under their impact to SLM routing. A good alignment is a key factor for successful routing decisions, as any misalignment can cause unnecessary offloading with extra cost. However, SLMs may struggle to provide reliable uncertainty estimates (Huang et al., 2023; Detommaso et al., 2024; Wightman et al., 2023), making them less effective as indicators for query routing. Thus, we benchmark the alignment between uncertainty and correctness, paving the insights for establishing more effective routing strategies\u00b9.\n2) What is the best practice to initially establish an effective routing strategy when generalizing to new datasets? In this research question, we explore how to generalize routing strategies to new datasets. Existing approaches (Ong et al., 2024; Hu et al., 2024) rely on sufficient new downstream data to make routing decisions for optimal performance-cost trade-offs, but this process is time-consuming and labor-intensive. Broadly speaking, collecting and analyzing full downstream datasets under varying SLM configurations can be prohibitively costly, delaying implementation, which is not practical in real-world scenarios. This delay is particularly problematic in high-stakes scenarios, such as medical wearable devices, where reliability is critical, and inaccuracies are unacceptable even in early deployment stages. Based on our findings, we provide a data construction pipeline to enhance the generalization of establishing routing in new downstream scenarios. A generated calibration dataset as a data-agnostic hold-out set enables the estimation of effective routing decisions without requiring extensive new data. We further benchmark the benefits of this calibration dataset, demonstrating the one's generalization ability to new datasets.\nThis work offers an accessible and reproducible pipeline for uncertainty-based routing from benchmarking to generalization. Our main contributions are summarized as follows:"}, {"title": "2.1. Uncertainty Quantification for LMs", "content": "Uncertainty quantification methods estimate a model's confidence in its predictions (Hou et al., 2024). For traditional classification and regression, uncertainty estimation is well-established (Gal et al., 2016). However, for LLMs generating free-form responses to complex queries, estimating uncertainty is more challenging because the output space can grow exponentially with vocabulary size, and each sequence spans multiple tokens (Fadeeva et al., 2023). Existing uncertainty quantification approaches for LLMs can be grouped into the following four categories.\nVia Verbalizing Uncertainty. This line of work prompts language models to report linguistic confidence (Mahaut et al., 2024; Mielke et al., 2022). To enable LMs to verbalize confidence, researchers have proposed fine-tuning them to express uncertainty (Lin et al., 2022) or teaching them to verbalize confidence through in-context learning (Dong et al., 2024). Verbalized confidence can take the form of linguistic expressions of uncertainty or numerical scores (Geng et al., 2024). Multiple studies find that LLMs tend to be overconfident when reporting confidence (Xiong et al., 2024; Tian et al., 2023). To mitigate this overconfidence, prompting strategies such as multi-step elicitation, top-k, and Chain-of-Thought (Wei et al., 2022) have been explored (Tian et al., 2023). Sampling multiple response-confidence pairs and designing more effective aggregation strategies can also help mitigate overconfidence (Xiong et al., 2024). Moreover, Tian et al. report that verbalized confidence is typically better calibrated than the model's conditional probabilities.\nVia Analyzing Token/Sequence Probabilities. This line of research derives confidence scores from model logits for output tokens (Geng et al., 2024; Huang et al., 2023; Jiang et al., 2021). The confidence of a generated sequence is"}, {"title": "2.2. LLM Routing", "content": "In query-routing scenarios, recent approaches train additional classifiers to direct queries to different SLMs or LLMs based on historical performance metrics and user feedback data (Ding et al., 2024; Ong et al., 2024; Stripelis et al., 2024; Jiang et al., 2024; Zhao et al., 2024). For instance, RouterBench (Hu et al., 2024) collects inference outputs from selected LLMs to aid in the development of routing classifiers. However, these methods face significant challenges when encountering new downstream tasks, as such data falls outside the distribution of the existing training data. This limitation makes them less practical for real-world scenarios, such as on personal edge device deployment, where adaptability to unseen conditions is crucial. Our work focuses on how to establish routing systems between SLMs and LLMs and generalize to new downstream tasks. In this manner, uncertainty-based routing is an appropriate solution to overcome these challenges, as uncertainty is directly extracted from SLMs themselves. Furthermore, we propose a calibration data construction pipeline to initialize a routing system that generalizes to unseen datasets."}, {"title": "3. Benchmarking Uncertainty-based SLM Routing", "content": "In this section, we systematically evaluate 8 SLMs and 2 LLMs on 14 datasets using 8 UQ methods (see Table 1) for uncertainty-based SLM routing. This section details the datasets, models, and UQ methods, followed by several key findings and practical considerations. All experiments are conducted on four 80GB NVIDIA A100 GPUs."}, {"title": "3.1. Benchmark Coverage and Setup", "content": "Language Models. We select 8 open-source SLMs spanning 1-8B parameters from multiple affiliations: Llama-3.2-1B-Instruct (Meta, 2024), Llama-3.2-3B-Instruct (Meta, 2024), Phi-3.5-mini-instruct (Abdin et al., 2024), danube3.1-4b-chat (Pfeiffer et al., 2024), Mistral-7B-Instruct-v0.3 (Jiang et al., 2023), Qwen2.5-7B-Instruct (Yang et al., 2024), Llama-3.1-8B-Instruct (Dubey et al., 2024), and granite-3.1-8b-instruct (Granite Team, 2024). Three are from Meta, and the rest are contributed by Microsoft, H2O.ai, Mistral AI, Alibaba, and IBM. All adopt a decoder-only Transformer architecture and are available through Hugging Face. We include one open-source LLM (Llama-3.1-70B-Instruct (Dubey et al., 2024)) and one proprietary API-based counterpart (GPT-40 mini (Hurst et al., 2024)).\nDatasets. Experiments span 14 datasets from four domains: (1) Mathematical Reasoning (AQUA (Ling et al., 2017), GSM8K (Cobbe et al., 2021), MultiArith (Roy &\nRoth, 2016), SVAMP (Patel et al., 2021)), (2) Commonsense\nReasoning (CommonsenseQA (Talmor et al., 2019), HellaSwag (Zellers et al., 2019), OpenBookQA (Mihaylov et al., 2018), PIQA (Bisk et al., 2020), TruthfulQA (Lin et al., 2021), WinoGrande (Sakaguchi et al., 2021), BoolQ (Clark et al., 2019), Social IQa (Sap et al., 2019)), (3) Conversational and Contextual Understanding (CoQA (Reddy et al., 2019)), and (4) Problem Solving (MMLU (Hendrycks et al., 2021)). These cover free-form, multiple-choice, and True/False question answering and are available via Hugging Face. Table 2 in Appendix A provides further details.\nUQ Methods and Hyperparameters. We evaluate 8 approaches from the four categories in Section 2.1. (1) Average token probability uses the probability of the chosen option token (e.g., \u201cA\u201d) for multiple-choice tasks or the mean probability of all generated tokens for free-form tasks. (2) Perplexity is computed for a sequence of N output tokens $\\{y_i\\}^N_{i=1}$ with probabilities $\\{p(y_i)\\}^N_{i=1}$ as $\\exp(\\frac{1}{N} \\sum^N_{i=1} \\ln p(y_i))$, and its reciprocal serves as the con-"}, {"title": "3.2. Report Observations", "content": "fidence score. (3) p(True) is a method where the LM first outputs an answer, then evaluates the generated response using only \"True\u201d or \u201cFalse.\u201d The probabilities for these two tokens are normalized to sum to 1, and the probability of \"True\" is used as confidence. (4) Verbalized confidence in a single response (denoted as verbalization-1s) prompts the model to output both the answer and numeric confidence in one step. (5) Verbalized confidence in the second round (denoted as verbalization-2s) obtains the confidence in a separate, follow-up query after the model has provided an answer. (6) The degree matrix (denoted as jaccard-degree) generates $m = 5$ samples (temperature 1.0) for one query, computes pairwise Jaccard similarities, and sets confidence to $\\text{trace}((mI \u2013 D)/m^2)$, where $D$ is the degree matrix. (7) Trained probe is a four-layer MLP with LeakyReLU activations, trained on a fixed subsample of the in-domain training set for each dataset, taking as input the hidden states from the eighth-to-last transformer layer. We train for 20 epochs (learning rate $5 \\times 10^{-4}$). (8) Trained probe on out-of-distribution data (denoted as ood-probe) is identical in architecture but trained on all other datasets. For instance, if AQuA is evaluated, the ood-probe is trained on the remaining 13 datasets (20 epochs, learning rate $1 \\times 10^{-4}$).\nFor verbalization-based methods, we discard queries when the model does not follow instructions to produce a confidence score. For free-form question answering, we use GPT-40 mini to evaluate whether a response is essentially equivalent to the ground truth answer (Zheng et al., 2023).\nIn this section, we present our benchmarking results analyzing the impact of uncertainty-correctness alignment on routing tasks. More observations and experimental results on calibration and routing can be found in Appendix C.1.\nObservation 0: Uncertainty estimation in SLMs may exhibit misalignment with prediction correctness. From the theoretical perspective, well-calibrated uncertainty scores"}, {"title": "4. Generalizable SLM Routing for New Downstream Scenarios", "content": "In this section, we first describe the pipeline for constructing calibration data with experimental details. We then investigate how well the calibration data can enhance routing generalization to new downstream scenarios without accessing the new datasets. Finally, we discuss our benchmark results and offer several insights into the calibration data for establishing routing in early-stage deployments."}, {"title": "4.1. Calibration Data Construction Pipeline", "content": "We aim to evaluate how calibration data improves routing strategies when generalizing to new downstream scenarios without requiring additional downstream data. Specifically, the calibration data serves as a data-agnostic hold-out set tailored to a particular SLM, which can generalize its routing standards across various new downstream datasets. By leveraging this calibration data, we establish a generalizable routing framework for new scenario deployments. This"}, {"title": "Algorithm 1 Calibration Data Construction Pipeline", "content": "Algorithm 1 Calibration Data Construction Pipeline\ninput A collection of datasets $D = \\{D_i\\}^N_{i=1}$ with $N$ domains\noutput A set of calibration data $X$\n1: Collect diverse domain of dataset $D_i$ to form $D = \\{D_i\\}^N_{i=1}$\n2: Generate uncertainty distributions $\\{F^M_{D_i}\\}_{i=1}$ of $D$ with selected\nUQ methods\n3: Sample $X = \\{x_j | x_j \\in X_i \\sim \\{F^M_{D_i}\\}_{i=1} \\forall i, j\\}$ from i-th\nbin in $\\{F^M_{D_i}\\}_{i=1}$\napproach not only simplifies the deployment process by removing the need for comprehensive dataset-specific analytics for routing but also demonstrates the potential of calibration data as a proxy for diverse data types, ultimately enhancing the generalization to new scenarios.\nThe overall construction pipeline is detailed as follows. Let $D = \\{D_i\\}^N_{i=1}$ be a diverse collection of datasets, where $N$ denotes the number of distinct domain types included in the collection. We select a diverse collection of datasets $D$ with various domains, such as commonsense reasoning, mathematics, and more, where we follow the settings in (Liu et al., 2024c). And then, we process every data instance in ID through selected UQ methods to capture their corresponding uncertainty distributions $\\{F^M_{D_i}\\}_{i=1}$ with $M$ bins, where $M \\in \\mathbb{Z}^+$ is an arbitrary number. These distributions serve as the sampling foundation of each data instance in forming calibration data. Finally, data instances obtained in the set of calibration data X are weighted-sampled from each bin of $\\{F^M_{D_i}\\}_{i=1}$ such that $X \\{x_j | x_j \\in X_i \\sim \\{F^M_{D_i}\\}_{i=1} \\forall i, j\\}$.\nThis ensures similar distribution in calibration data across various uncertainty levels presented in $\\{F^M_{D_i}\\}_{i=1}$. The resulting collection of these sampled data instances forms the final calibration dataset. The detailed pipeline of constructing the calibration dataset is outlined in Algorithm 1."}, {"title": "4.2. Calibration Data Setups", "content": "Benchmark Settings. We evaluate the constructed calibration data on 8 SLMs and 2 LLMs across 14 datasets. Based"}, {"title": "4.3. Generalization of Calibration Data", "content": "We provide several key insights into the generalization ability of calibration data as follows.\nInsights 0: The extracted confidence distribution is predominantly determined by the chosen SLM and uncertainty quantification (UQ) method, with minimal dependence on the downstream dataset. As illustrated in Figure 4, confidence scores aggregated from 14 different tasks exhibit a nearly identical shape regardless of the specific dataset. Instead, they vary notably with different SLMs and UQ methods. This finding suggests that the confidence"}, {"title": "5. Challenges and Opportunities", "content": "distribution is largely data-agnostic, enabling the construction of calibration data that generalizes to new tasks without needing prior knowledge of new datasets.\nInsights 9: Calibration data helps SLM routing to achieve strong generalization, allowing routing strategies to be initialized on SLMs without accessing new datasets. Building on our findings about uncertainty distributions, we sampled a data subset to create a final calibration dataset using the pipeline described in Section 4.1. We then utilized this calibration dataset to determine thresholds for different routing ratios in new downstream scenarios. The experimental results (see Figure 5) show that the routing curves from the calibration data closely match those from the entire new downstream dataset, indicating that the calibration data provides strong generalization for establishing routing strategies on unseen downstream datasets. An identical phenomenon is observed across multiple UQ methods and different SLMs, highlighting the potential of calibration data to initiate the routing process for any new dataset independent of the UQ method or SLM used. Additional experimental results can be found in Appendix C.3.\n\u2022 How to cash-in routing efficiency on new edge devices? Based on the benchmark results, calibration data provides a robust foundation for establishing routing policies on new edge devices without accessing prior knowledge at the early stage of deployment. This enables the routing policies with strong generalization to new dataset scenarios and enhances the efficiency across diverse deployment for personal edge devices. While calibration data holds a good performance in the early deployment stage, an important direction to explore is how to effectively leverage additional private on-device data to further strengthen the quality of calibration data, aiming to continuously enhance the deployment of personalized routing strategies. With the aid of calibration data, less private data is required, but striking a balance between privacy and performance remains an open challenge.\n\u2022 How to effectively strike a balance between LLM routing efficiency and utility? We empirically observe that by leveraging UQ methods with strong uncertainty-utility alignment (e.g., Perplexity and OOD Probe methods), routing thresholds can effectively be determined with the sweet points of efficiency and utility. However, achieving such sweet spots can be challenging due to the variability in downstream datasets and the sensitivity of UQ methods to LLM-specific characteristics. Additionally, discrepancies across different device types, such as variations between iOS and Android systems\u00b2, further complicating the process,"}, {"title": "6. Conclusion", "content": "This paper investigates the routing accuracy of SLMs in estimating their uncertainty and establishing best practices for initiating effective routing strategies. Through comprehensive benchmarking of 8 SLMs, 2 LLMs, 8 UQ methods, and 14 datasets across 1500+ settings, we found that the alignment between uncertainty and correctness significantly impacts routing performance. Additionally, our experiments show that uncertainty distributions depend primarily on the specific SLM and UQ method rather than the downstream data. Building on the insights, we introduced a calibration data construction pipeline and a hold-out dataset to generalize routing strategies without prior knowledge of new downstream data. The results confirm that the calibration data effectively bootstraps routing, indicating its strong potential for benefiting in resource-efficient SLM deployment."}, {"title": "B. Related Work", "content": "B.1. Small Language Models\nSmall Language Models (SLMs) are designed for deployment on resource-constrained devices like desktops, smartphones, and wearables. Specifically, we consider the Transformer-based SLMs in this work due to their state-of-the-art performance, like Phi-3-mini (Abdin et al., 2024), TinyLlama (Zhang et al., 2024), MobileLLM (Liu et al., 2024d), and Qwen-1.5B (Bai et al., 2023), LiteLLaMa-460M, OPT-125M (Zhang et al., 2022), BLOOMZ (560M, 1.1B, 1.7B, 3B) (Le Scao et al., 2023), SmolLM (135M, 360M, 1.7B) (Allal et al., 2024), OLMo (1B) (Groeneveld et al., 2024), OLMoE (1B) (Muennighoff et al., 2024), MobiLlama (0.5B, 1B) (Thawakar et al., 2024), MobileLLaMA (1.4B, 2.7B) (Chu et al., 2024), OpenL-LaMA (3B) (Geng & Liu, 2023). These models are designed with lightweight architectures to operate effectively within the computational and storage limitations of mobile devices and edge hardware.\nRecurrent Neural Networks (RNNs), like RWKV (1B, 3B, 7B) (Peng et al., 2023), Mamba (1.4B, 6.9B) (Dao & Gu, 2024), and RecurrentGemma-2B (Griffin & Teams, 2024), can provide promising solutions for on-device inference in resource-constrained environments. These models leverage the recurrent nature of RNNs to process sequential data efficiently without requiring a KV cache, which is suitable for resource-constrained on edge devices. Specifically, RWKV introduces a hybrid RNN-Transformer backbone to capture long-term dependencies while maintaining computational efficiency. Similarly, Mamba and RecurrentGemma design recurrent layers for low-power consumption and high throughput inference, which can significantly reduce memory and computational requirements, fostering low-latency applications directly on devices."}, {"title": "C. Additional Experimental Results from Benchmarking to Generalization", "content": "In this section, we present additional experimental results on (1) evaluating the impact of uncertainty-correctness alignment on small language model (SLM) routing and (2) investigating the generalization capability of calibration data on novel datasets. For the first experiment (Section C.1 and Section C.2), we provide the complete set of results, including the AUC measurements for uncertainty-correctness alignment and the performance of uncertainty-based routing. For the second experiment (Section C.3), we present a comprehensive analysis of the generalization ability of calibration data to unseen downstream datasets. Each dataset referenced in the experiment is treated as a novel dataset for evaluation. We adopt a cross-validation setup, ensuring that the calibration data does not include any instances from the target dataset."}, {"title": "C.1. Evaluation on Uncertainty-correctness Alignment", "content": "RESULTS OF ALIGNMENT BETWEEN UNCERTAINTY AND CORRECTNESS.\nAll the experiments shown on this page are conducted under AQUA, BoolQ, and CoQA datasets with all 8 UQ methods."}, {"title": "C.3. Generalization Ability of Calibration Data on New Downstream Scenario", "content": "GENERALIZATION RESULTS ON ROUTING TO GPT-40-MINI\nAll the experiments shown on this page are conducted under GSM8K, MMLU, CommonsenseQA, TruthfulQA, CoQA, BoolQ, and OpenBookQA datasets with all 8 SLMs."}]}