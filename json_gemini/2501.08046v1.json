{"title": "Building Symbiotic Al: Reviewing the Al Act for a Human-Centred, Principle-Based Framework", "authors": ["Miriana Calvano", "Antonio Curci", "Giuseppe Desolda", "Andrea Esposito", "Rosa Lanzilotti", "Antonio Piccinno"], "abstract": "Artificial Intelligence (AI) spreads quickly as new technologies and services take over modern society. The need to regulate Al design, development, and use is strictly necessary to avoid unethical and potentially dangerous consequences to humans. The European Union (EU) has released a new legal framework, the Al Act, to regulate Al by undertaking a risk-based approach to safeguard humans during interaction. At the same time, researchers offer a new perspective on Al systems, commonly known as Human-Centred AI (HCAI), highlighting the need for a human-centred approach to their design. In this context, Symbiotic Al (a subtype of HCAI) promises to enhance human capabilities through a deeper and continuous collaboration between human intelligence and Al. This article presents the results of a Systematic Literature Review (SLR) that aims to identify principles that characterise the design and development of Symbiotic Al systems while considering humans as the core of the process. Through content analysis, four principles emerged from the review that must be applied to create Human-Centred Al systems that can establish a symbiotic relationship with humans. In addition, current trends and challenges were defined to indicate open questions that may guide future research for the development of SAI systems that comply with the Al Act.", "sections": [{"title": "Introduction", "content": "In recent years, society has witnessed a significant surge in interest and investment in Artificial Intelligence (AI), primarily driven by advancements in Machine Learning (ML) and Deep Learning (DL). These technologies have become transformative forces, enabling groundbreaking innovations and offering new services across a wide spectrum of domains, from healthcare and finance to transportation and entertainment. Such progress underscores the growing role of AI in shaping modern society and highlights the urgency of understanding its applications, implications, and potential. Despite its advancements, in fact, AI raises significant ethical, legal, and human rights concerns, ranging from fear of discrimination\u00b9 to deskilling2.\nThe burgeoning pervasiveness of AI in daily-use systems has highlighted several major flaws in current AI techniques. Among these, biases and lack of explainability greatly endanger the users of AI models\u00b3, who may be treated unfairly or exposed to life-threatening risks4.\nThese concerns have prompted academics and global legislative bodies to take action to ensure the responsible development of AI. In the academic sphere, a new perspective known as Human-Centred Artificial Intelligence (HCAI)5,6 is reshaping the research landscape. Located at the intersection between Human-Computer Interaction (HCI) and AI, HCAI promises to provide a direction to design AI systems that are safe, reliable, and trustworthy7. More precisely, HCAI aims to design, develop, and evaluate AI systems involving end-users in the process to increase their performances and satisfaction in performing specified tasks. Therefore, HCAI systems aim to be usable and useful for specified users to reach their specified goals in their context of use, while being reliable, safe to use, and trustworthy. By adopting a human-centred design approach, HCAI may foster a symbiotic relationship between humans and AI. Therefore, Symbiotic Artificial Intelligence (SAI) systems are a specific type of HCAI systems that allow for continuing and deeper collaborations between human intelligence and AI, aiming at their mutual augmentations without hampering human autonomy or AI's performance8,9. However, this may not suffice to ease ethical concerns.\nSimultaneously, governments are beginning to draft and implement new legislative measures. A notable example is the European Union (EU)'s AI Act, which represents a pioneering effort in regulating AI10. The AI Act is a legal framework concerning AI systems' design, development, deployment, and use, aiming at ensuring their proper employment while"}, {"title": "Results: A Principled Human-Centred AI Framework", "content": "Through content analysis performed on 58 articles, four principles were identified as requirements for designing AI Act-compliant HCAI systems: Transparency, Fairness, Automation Level, and Protection. These are described in the following sections and are represented in Figure 1. Through further analysis, three additional properties were identified: Trustworthiness, Robustness, and Sustainability.\nThe four principles and their relationship with the additional three properties are detailed in the following sections, discussing how they can support the creation of AI systems, fostering a symbiotic relationship with humans8."}, {"title": "Principles for Human-Al Symbiosis", "content": "Defining principles to guide the design and development of AI systems through a human-centred approach is crucial to establish a symbiotic relationship between the two parties. It is important to guarantee that AI systems adhere to the highest standards of ethical conduct. Thus, designers and developers must ensure that the implemented solutions comply with laws and regulations safeguarding human rights and European values, making these systems safer for end-users12,13. To this end, providers must register high-risk AI models in an EU database managed by the European Commission to enhance public transparency and enable oversight by authorities14.\nThis section explores the four principles identified through the SLR, describing their dimensions and characteristics."}, {"title": "Principle 1: Transparency", "content": "Transparency can guarantee that AI systems are effectively overseen by humans and allow intervention when potential harm occurs 14. Transparency ensures that critical information about how the AI model was trained and structured is available to humans14, since stakeholders must understand how AI models function and the reasoning behind their decisions to be able to intervene14. Being a multi-faceted property that concerns AI models, their components, and algorithms, Transparency serves as"}, {"title": "Explainability", "content": "Explainability aims to provide explanations concerning AI systems' operations, ensuring that even when humans cannot understand how an AI system provides an output, they can at least receive information about why it was produced18. In other words, this aspect contributes to the degree to which an AI system is open and observable to humans14,16. When interacting with AI systems, humans should have the right to explanations to make informed decisions, supported by AI and not replaced by it,19,20, while being able to oversee its processes21."}, {"title": "Interpretability", "content": "An Al system can be considered interpretable if it can be correctly understood by an individual who can assign meanings to outputs17. This means that the person interacting with AI can understand its functionality, purpose, or impact on the context of use. Therefore, the process of interpretation involves mapping an abstract concept, such as a predicted class or category, into a domain that is within the grasp of human understanding 14."}, {"title": "Principle 2: Fairness", "content": "In Al systems, Fairness reflects the concepts of equality and inclusiveness to avoid biases and discriminatory behaviors, safeguarding fundamental human rights and values17. An approach that considers humans as a whole is essential for ensuring that AI can contribute positively to society and protect them against potential harms22. Fairness is characterized by two dimensions: Rightful Information and Non-Discrimination."}, {"title": "Rightful Information", "content": "AI systems must disseminate accurate and reliable information to minimise the risk of incorrect or incomplete knowledge and to mitigate the risk of manipulation and persuasion of humans23,24. Providing accurate and complete information is essential to explain AI decisions to safeguard individual rights and freedom, foster a sense of trust and understanding among humans, and enhance the ethical use of AI systems13."}, {"title": "Non-Discrimination", "content": "Although AI is commonly used to boost productivity through automation, it is important to ensure that models are trained in accordance with ethical and societal norms that minimize discriminatory behaviors, avoiding that individuals are treated differently or unequally without any justifiable reason25. Thus, the whole pipeline of creating AI-based systems must be monitored and checked since biases can rise unintentionally during the early training phases of models14,26."}, {"title": "Principle 3: Automation Level", "content": "As AI becomes increasingly integrated into countless aspects of human life, studying the appropriate balance between automation and human control in human-AI interactions is necessary27. Although there are contexts of use in which humans need or wish for fully automated systems in which their control is not necessary, it is important to address the ethical and legal consequences of undesired events caused by AI systems' outputs. This implies that automation can be considered as a spectrum and not as a binary feature28. Automation Level is characterized by two dimensions: Human-on-the-loop and Human-in-the-loop."}, {"title": "Human-on-the-loop", "content": "Providing humans with appropriate oversight when interacting with AI systems is necessary to enable them to check, monitor, and supervise the system's behaviour. Oversight is a precondition to allow human intervention, which guarantees AI-assisted decisions rather than AI-driven decisions. This can avoid irreversible consequences and minimise risk and biased outputs while safeguarding human rights29. Human oversight is strictly related to Transparency, as AI models must provide effective explanations to users, ensuring that users can effectively interpret outputs in order to properly modify their behaviour, if necessary30."}, {"title": "Human-in-the-loop", "content": "Designing AI systems emphasising human control is useful in situations where humans need to actively participate in the decision-making process. In this context, the concept of Controllable Al is introduced, which reinforces the importance of human control to detect malfunctions and recover from dangerous situations; controlling the behavior of AI means influencing its output and processes in accordance with the context of use and human expertise for a more safe and reliable interaction31. Some of the conditions must be in place for humans to take control of the interaction properly: appropriate algorithmic transparency of AI models and high levels of feedback and affordance in User Interfaces (UIs) are needed since communication is key in any kind of relationship18."}, {"title": "Principle 4: Protection", "content": "The human-centric approach undertaken by the AI Act aims at ensuring that users are safeguarded against harm, threats, or intrusion. This principle is strongly intertwined with the legal requirements set by governmental norms and rules that designers, developers, and deployers must comply with to protect users from unsafe behavior. There is a need to create secure and resilient AI systems that can preserve users' privacy. In this regard, the AI Act recalls the General Data Protection Regulation (GDPR), which emphasized the integration of privacy and data protection into the design and development of systems32. Protection"}, {"title": "Privacy", "content": "An AI system that fosters users' privacy can safeguard individuals' sensitive data from improper access, theft, or loss33. This principle transcends from the specific case of AI systems, as applying the proper techniques to preserve data and protect individuals' identities impacts multiple system components and requires developers to inform end-users about how their data is being handled\u00b94. The correct application of data preservation techniques and protective measures can have far-reaching impacts on multiple system components."}, {"title": "Safety", "content": "A safe system is designed to fulfill its intended function without causing harm to living beings or the environment33. This concept is linked to the well-being and welfare of humans affected by AI and is also connected to the system's level of automation. The objective is to mitigate risk and prevent accidents by removing barriers to error reporting and fostering a collaborative and communicative environment. This ensures that end-users are always informed about potentially harmful practices that could threaten their rights34."}, {"title": "Security", "content": "To protect individuals, systems must be secure by design, implying that they must incorporate solutions that allow management, monitoring, and recovery from external threats26. This dimension is relevant to all types of systems, regardless of AI features, since security implies the preservation of the CIA triad (Confidentiality, Integrity, and Availability), meaning that strong prevention and recovery measures must be implemented. AI systems, especially those categorized as high-risk by the AI Act, should be designed to be resilient against attacks and consistently perform securely throughout their lifecycle since they deal with extremely private and sensitive information about their users18."}, {"title": "Properties of Human-Centred Al", "content": "Three properties emerged from the SLR, which underlie the principles that were identified and that must characterise AI-based systems that are designed and developed compliantly with the AI Act. The analysis was performed using hierarchical clustering, and after the initial step of identifying the first set of clusters, a hierarchical grouping was brought to the identification of the principles described in the previous section. A further grouping step allowed us to identify the overall properties of a truly human-AI symbiotic relationship: Trustworthiness, Robustness, and Sustainability. This section details these properties, highlighting their relationship with the four principles described in Section 'Results: A Principled Human-Centred AI Framework'. It is highlighted that these properties are not a sufficient condition for AI systems to be symbiotic, but they emerged as crucial components of the design phase from this SLR, influenced by its goals."}, {"title": "Trustworthiness", "content": "Trustworthiness is a critical, frequently-discussed topic in the context of the human-centric approach of the AI Act. It is essential for high-risk systems because it is necessary for reliable, safe, and positive interactions35. It can be fostered by implementing appropriate transparency techniques in AI models in order to make users aware of the motivations that lie behind outputs and responses36. This property is still a subject of debate within the research community and the legal landscape. For example, in the context of HCAI, a trustworthy system is one that deserves human trust, implying that it must align with users' needs, preferences, and cognitive models to achieve successful interactions. On the other hand, the AI High Level Expert Group (HLEG) identifies trustworthiness as the umbrella property to ensure a human-centric approach to AI37. Nevertheless, our analysis showed that trustworthiness is an important property, which covers the four principles, but it is not a sufficient condition for the establishment of a symbiotic relationship. It emerges that an AI system is trustworthy if it enables humans to properly oversee and/or control its performance with an appropriate automation level while exhibiting fair behavior and respecting humans in all their dimensions."}, {"title": "Robustness", "content": "Referring to the AI Act, the Robustness of AI has been defined as their ability to perform reliably and effectively under various conditions, including unexpected or challenging ones. Robustness is mentioned in Article 15 of the law, which is titled \"Accuracy, Robustness and Cybersecurity\" in the context of ensuring that high-risk systems feature fail-safe plans and technical redundancy solutions10. The motivations behind this lie in the fact that a robust AI system exhibits a safe, resilient, and reliable behaviour, which fosters trust in humans, thus being one of the factors that contribute to a symbiotic human-centred relationship 36, 38."}, {"title": "Sustainability", "content": "Sustainability is a factor that deployers should consider when creating systems to align with the EU's goals for the near future. As environmental concerns are substantially increasing worldwide and given the EU's efforts in trying to reduce emissions and energy consumption, a sustainable approach is necessary to minimize the environmental impact of AI and to create long-lasting"}, {"title": "Discussion", "content": "This section discusses the analysis of the literature concerning the challenges, trends and limitations faced while conducting the SLR. The release of the AI Act has shifted the focus towards a more human-centric approach even in the literature belonging to the more technical side of Computer Science. Individuals are not considered as mere users, but as human beings in all their dimensions, which must be included in the process of creating ethical AI systems13. Nevertheless, little indication is provided regarding the design patterns that can be employed to implement human control and oversight mechanisms in AI systems."}, {"title": "Grounding the Framework in the Literature", "content": "To better ground the framework introduced in Section 'Properties of Human-Centred AI', this section compares it with existing similar frameworks available in the literature. More precisely, three sets of principles, are taken as reference for the comparison6,33,42."}, {"title": "Uncovering Current Trends and Challenges", "content": "Throughout the literature review, some interesting trends and relevant challenges emerged that are worth reporting. This section briefly discusses them, highlighting open questions that may guide future research for the development of SAI systems that comply with the AI Act."}, {"title": "Research Trends", "content": "The research trends that emerged from this SLR are represented in Figure 4, which highlight the extent to which principles are considered in the literature and how they are related to each other. It is important to underline that researchers seem to be interested in investigating aspects of the identified principles from a legal perspective considering their impact on legal implications regarding the AI Act, the new set of soft laws that promises to bring breaking changes in the way AI is designed and developed."}, {"title": "Trend 1 - Increasing focus on Transparency", "content": "Analysing the review results, there appears to be a lack of emphasis on AI algorithms' transparency among researchers in articles published before 2024. This concern is overcome in subsequent works, which can be attributed to the recent adoption of the AI Act, which prioritizes legal considerations over technical ones in the way humans can understand the AI behaviors. Furthermore, while the AI Act offers guidelines for developing compliant AI systems, it does not provide specific technical instructions. Consequently, researchers are working on understanding how to implement it algorithmically."}, {"title": "Trend 2 - Significant Connection among Fairness with Protection and Automation Level", "content": "Researchers seem to be focused on investigating not only the legal considerations but also on crafting methods to safeguard users while ensuring non-discriminatory and ethical AI practices. Fairness exhibits equal connection with Protection and Automation Level, as following practices that preserve human rights translates in AI systems that handle sensitive personal data in the proper way while ensuring that individuals can exercise control over their behaviour."}, {"title": "Trend 3 - Weak connection among Transparency and Fairness", "content": "In the current scenario, algorithmic transparency and fairness are not always investigated together. In fact, from the review emerged that Transparency and Fairness are weakly correlated; while both are crucial for developing an ethical AI, they often require different approaches and considerations."}, {"title": "Trend 4 - Strong connection among Automation Level, Transparency and Protection", "content": "The level of automation within a system is closely tied to its transparency and the associated protective measures to enhance human oversight and system protection. Transparent systems allow humans to understand their behavior, enabling better supervision, effective intervention, and the identification of vulnerabilities. This can reduce the occurrence of unexpected events potentially harming humans, and transparency improves safety by balancing automation and augmentation."}, {"title": "Research Challenges", "content": "This SLR revealed some of the challenges of the current landscape of AI research, ranging from the lack of technical solutions for the new legal constraints and requirements to a missing shared standpoint among researchers. Another key issue remains Trustworthiness, which impacts human-AI relationship but has the potential of damaging the decision-making process."}, {"title": "Challenge 1 - Lack of technical design solutions", "content": "Most of the research does not conduct studies or experiments aiming at proposing new technical solutions, thus favouring a more general discussion. These results should not be surprising. In fact, the AI Act discusses the need for safe, ethical, fair, and trustworthy AI systems. However, no practical indications on how to design and develop such AI systems are provided. This implies that scholars and practitioners lack technical guidance to ensure the compliance of new AI solutions."}, {"title": "Challenge 2 - Lack of standardized evaluation methods", "content": "The AI Act remains a legal framework, providing theoretical and conceptual indications concerning the creation of AI systems. Although the EU also proposes a tool for compliance checking with the regulation, there is still the need for a standardized approach in the evaluation and assessment of the properties that characterize AI systems. This can translate to quantitative or qualitative methods that can objectively identify the strengths and weaknesses of the system."}, {"title": "Challenge 3 - Lack of a common view", "content": "Most of the analyzed papers do not suggest a common view of the proposed solutions (e.g., basic definitions, guidelines, frameworks, etc.) It emerged that a standardized approach is still lacking, and there are no methodological common approaches that can be employed to design and develop AI Act-compliant systems. The research community seems fragmented, focusing on different aspects of the matter, even exhibiting opposite standpoints."}, {"title": "Challenge 4 - Is there anything beyond trust?", "content": "Given the previous legal documents that contributed to laying its groundwork, the AI Act heavily relies on Trustworthy AI, which can potentially influence the perspective of the articles related to the regulation. As a result, many research works frequently highlight trustworthiness as the umbrella property of AI, which inevitably impacts the generalization of the concepts that emerged from this literature review. Although trustworthiness is an important component of the interaction between humans and AI, it must be carefully evaluated and balanced with other factors."}, {"title": "Challenge 5 - Inconsistencies in terminology", "content": "Al impacts countless aspects of modern society, implying that governmental bodies, researchers, and end users must be aligned in the use of terms and concepts that revolve around the design, development, deployment, and use of AI systems. From this SLR, it emerged that there are words that possess different meanings depending on the expertise of those who use them. For example, the term Transparency can refer either to the transparent use and storage of data in case of the GDPR, or to the extent to which an AI model is transparent to humans in the case of the AI Act. There is also a lack of clarity concerning the differences between the human-centred and the human-centric approaches, which are mistakenly often used interchangeably. This issue highlights the need for more uniformity in digital literacy for an aligned and aware society."}, {"title": "Challenge 6 - Underexplored impact of human factors", "content": "The increasing adoption of the human-centred approach to creating AI systems highlights the need for a more in-depth study of the human factors that can influence its relationship with humans. This SLR revealed the current research concerning the AI Act mainly revolves around Law and Computer Science, leaving out some relevant aspects concerning the psychological and behavioural factors that can impact the establishment of a symbiotic relationship between humans and AI. This aspect needs to be further investigated to ensure the seamless integration of these systems in our daily lives and guarantee the augmentation of humans instead of their replacement."}, {"title": "Limitations", "content": "In general, several threats to validity can affect the results of a SLR. In the following, we report how we mitigated the most critical ones."}, {"title": "Selection bias", "content": "This happens when the research papers selected for the review do not represent all the studies conducted on the topic. In fact, the personal biases of the reviewers can influence the selection and interpretation of papers. This was mitigated by deeply analyzing the selected papers to check their compliance with the objectives of the SLR and by involving multiple reviewers who independently assessed them."}, {"title": "Publication bias", "content": "This occurs when studies that show statistically significant results are more likely to be published than studies that do not. This aspect did not occur while performing this literature review since most of the selected papers concern the legal field."}, {"title": "Time lag bias", "content": "This arises when not all the relevant works are included in the SLR due to their publication after the review was conducted. In this case, the work was performed one month before its submission."}, {"title": "Publication quality", "content": "This emerges when poor quality works are considered in the SLR. To mitigate this aspect, inclusion and exclusion criteria considering the quality of the publication venue were defined leading to a manual evaluation of publications that appeared in venues of lower quality."}, {"title": "Methods", "content": "The systematic literature review was carried out following Kitchenham's procedure44. The procedure reinforces the key steps of the review to ensure transparency, minimise bias, and contribute to the advancement of knowledge by defining clear research questions and protocol compliant with the objective.\nThe keywords of the SLR were defined as follows. Being the core of our research, the keyword artificial intelligence act was necessary to identify the context of the investigation, while human-centric artificial intelligence was identified as the AI Act takes on a human-centric approach; we decided not to include \u201chuman-centred\" because the AI Act views it as a different approach and not as a synonym10. The keyword intelligent systems was used to encompass all the systems that exhibit an intelligent behaviour and was used as a synonym of AI. Finally, symbiotic artificial intelligence was a crucial keyword to explore the field of AI-based systems that establish a symbiotic relationship with humans. Starting from these keywords and based on the research objectives, the following queries were built:\n(Q1) european AND (\u201cartificial intelligence\" OR ai) AND act\n(Q2) european AND (\u201cartificial intelligence\" OR ai) AND act AND (human OR human-centric OR human-centric OR human-centric)\n(Q3) (\"human centric artificial intelligence\" OR \"human centric AI\") AND (\u201cartificial intelligence act\" OR \"ai act\")\n(Q4) (\u201csymbiotic artificial intelligence\u201d OR \u201cSymbiotic AI\u201d) AND (\u201cartificial intelligence act\" OR \"ai act\")\n(Q5) \"Intelligent Systems\u201d AND (\u201cartificial intelligence act\u201d OR \u201cai act\")\nThe latter was used to build the queries to run on Scopus because it is comprehensive and includes the most relevant and accredited digital libraries, including journal and conference manuscripts."}, {"title": "Inclusion and Exclusion Criteria", "content": "The inclusion and exclusion criteria were defined based on the research objectives. They are listed and described below.\n\u2022 Year: the period from 2022 to 2024 was considered because the AI Act was still an early draft before 2022 and underwent substantial changes throughout small periods.\n\u2022 Topic: we included papers that revolve around the AI Act and its implications in different areas of science and society, but documents in which the legal framework was merely mentioned or slightly addressed were excluded.\n\u2022 Peer reviewed: for articles appearing in journals, we included those ranked Q1, Q2, and Q3 in Scimago; for conference articles, we included A, B, and C conferences on the Core Conference Ranking. Conference articles ranked as regional can be considered if they can significantly impact the review results.\n\u2022 Document type: the review focused on single manuscripts and papers, excluding from the queries' outputs the entire proceedings of conferences or books.\n\u2022 Language: each paper not written in English was excluded."}, {"title": "Coding and Classification", "content": "The papers were classified using a mixed approach of data coding: i.e., a-priori and in-vivo. A-priori coding consists of the categorisation of papers with dimensions that are established before the classification process. In contrast, in-vivo coding involves the definition of the dimensions as the papers are read and analysed45. The name of each principle was collectively chosen by the researchers who took part in the SLR, reflecting terms that are recurrent in the set of papers and those used in the regulation."}, {"title": "Conducting the SLR", "content": "The first step of the execution was searching for academic articles about the topic by running the five queries on the Scopus digital library. Each query provided the following results: Q1: 530, Q2: 223, Q3: 4, Q4: 1, and Q5: 4. It emerged that Q1 and Q2 returned a higher number of papers obtained since they are broader and more exploratory than the others.\nThe resulting set of papers from the queries underwent a selection process respecting both inclusion and exclusion criteria. From a total of 762 papers, after a check for duplicates (i.e., 158 files), 604 publications were obtained. A more in-depth step was taken, which resulted in the removal of 365 papers since they did not match the inclusion criteria. In the end, each publication was further analysed by reviewing the abstract, the introduction, and the conclusions, obtaining the final set of papers. The final set used for the literature review contains 58 papers."}]}