{"title": "Efficient Human-in-the-Loop Active Learning: A Novel Framework for Data Labeling in AI Systems", "authors": ["Yiran Huang", "Jian-Feng Yang", "Haoda Fu"], "abstract": "Modern AI algorithms require labeled data. In real world, majority of data are unlabeled. Labeling the data are costly. this is particularly true for some areas requiring special skills, such as reading radiology images by physicians. To most efficiently use expert's time for the data labeling, one promising approach is human-in-the-loop active learning algorithm. In this work, we propose a novel active learning framework with significant potential for application in modern AI systems. Unlike the traditional active learning methods, which only focus on determining which data point should be labeled, our framework also introduces an innovative perspective on incorporating different query scheme. We propose a model to integrate the information from different types of queries. Based on this model, our active learning frame can automatically determine how the next question is queried. We further developed a data driven exploration and exploitation framework into our active learning method. This method can be embedded in numerous active learning algorithms. Through simulations on five real-world datasets, including a highly complex real image task, our proposed active learning framework exhibits higher accuracy and lower loss compared to other methods.", "sections": [{"title": "1 Introduction", "content": "A diverse range of AI systems have emerged for practical applications. Large language models, such as Generative Pre-trained Transformers (GPT) (Vaswani et al., 2017; Radford et al., 2018), demonstrated exceptional capabilities in natural language processing tasks, including understanding, generating and interpreting human language. Similarly, reinforcement learning models have also been successfully applied in real-world scenarios, such as autonomous driving (Kiran et al., 2021). These models are data-hungry, requiring significant amount labeled data for effective training. For a thorough overview of the data requirements across different models, see Zhao et al. (2023). This poses challenges in data collection, large-scale data labeling and data quality enhancement. Across various scientific domains like language processing, reinforcement learning, medical image field and speech recognition, there are a substantial volume of unlabeled data and a relatively small amount of annotated data (Budd et al., 2021; Zhu and Goldberg, 2022). It is prohibitive for traditional supervised model training, especially for deep learning models, because labeling a significant portion of data can be impractical. For instance, there is a large pool of unannotated pathological images, but only a small number of them have been diagnosed. Increasing the labeled images to a high level is unrealistic because clinical diagnosis for images can be expensive. One of the solutions to this dilemma is human-in-the-loop active learning algorithms. Active learning is a process in which humans interact with computers to enhance the efficiency of machine learning. It aims to identify the most informative unlabeled data and entrust them to oracle experts for labeling. The high quality of the newly labeled data enhances the efficiency of machine learning. Consequently, the demand for sample size sharply declines to an affordable level. Criteria from different perspectives are used to recognize informative data, including uncertainty-based method (Settles and"}, {"title": "2 Background and Notation", "content": "The size of full data in the pool is assumed to be N, where each data point $x_i \\in R^p$ has a label $y_i \\in \\{1,2,..., L\\}$, or say each $x_i$ is from class $y_i$, for $i \\in 1,2,..., N$. The full data is denoted by $D_{full} = \\{(x_i, y_i)\\}_{i=1}^{N}$. While most labels in $D_{full}$ are unknown, we adopt this notation for convenience. By the basic assumption of active learning, let $D_0$, with a size $n_0$, represent a small fraction of $D_{full}$ as annotated data. We further denote by $D_{full}^x = \\{x_i\\}_{i=1}^{N}$ all points without their labels from $D_{full}$, and $D_0^x$ is similarly defined. Though most labels in $D_{full}^x$ are unknown, $D_{full}$ is fully observed. Predicting the label y for a point x requires building some metrics or models. Metric learning aims to find an adequate positive semi-definite matrix $A \\in R^{p\\times p}$ to define a quadratic form distance such that points from the same class are close to each other and points from different classes are far away, see, for example, Xing et al. (2002), Yang et al. (2012) and Deng et al. (2023). The metric learning utilizes the pairwise constraints between any two points from $D_0$ to learn the optimal metric. The label of $x \\in D_{full}^x$ can be predicted according to the learned distance between x and each point in $D_0^x$. However, when the dimension p is high, the"}, {"title": "3 Method", "content": "As shown in Table 1, probability is the best bridge to connect different questions to the true labels. When the probabilities of classes are known, or at least can be predicted, the probabilities of answers to any question can be calculated or predicted. Consider a loss function $l_k(\\cdot,\\cdot)$ for each question $Q_k$ and then apply them to all information in $D = \\{D_0, D_1, ..., D_k\\}$ by\n\n$l(D,\\theta) = \\frac{1}{K} \\sum_{k=0}^{K} \\frac{1}{n_k}\\sum_{i=1}^{n_k} l_k(Pr(ans|q_{ki},\\theta), a_{ki}),$ (2)\n\nwhere $Pr(ans|q_{ki}, \\theta)$ is an $|A_k|$ length vector of estimated probabilities of answers under the model $p(\\cdot;\\theta)$ and $|A_k|$ is the size of the answer set $A_k$. For instance, for the question \u201care all of $x_{i_1},...,x_{i_m}$ from class $c$?\", the first and second entries of $Pr(ans|q_{ki}, \\theta)$ are $1 \u2013 \\prod_{j=1}^{m} p_c(x_{i_j};\\theta)$ and $\\prod_{j=1}^{m} p_c(x_{i_j};\\theta)$, respectively. The estimated parameter $\\hat{\\theta}$ can be obtained by minimizing the loss $l(D, \\theta)$. The selection of the loss function is not arbitrary. A wise choice would be cross-entropy loss, expressed as\n\n$l_k(Pr(ans|q_{ki}, \\theta), a_{ki}) = - \\sum_{\\alpha \\in A_k} 1(a_{ki} = \\alpha) log[Pr(ans = \\alpha|q_{ki}, \\theta)].$ (3)\""}, {"title": "3.1 Active learning method", "content": "The main concept behind active learning is to identify the most uncertain data, i.e., to find the question $q_k$ with a high expected loss, as determined by\n\n$E(l_k(Pr(ans|q_k, \\theta), \\alpha_k)) = - \\sum_{\\alpha \\in A_k} Pr(ans = \\alpha|q_k) log[Pr(ans = \\alpha|q_k, \\theta)].$ (4)\n\nThis is estimated by substituting the predicted probability, resulting in the entropy:\n\n$En(Pr(ans|q_k, \\theta)) = - \\sum_{\\alpha \\in A_k} Pr(ans = \\alpha|q_k, \\theta) log[Pr(ans = \\alpha|q_k, \\theta)].$ (5)\n\nAs discussed in Section 2, entropy is one of the criteria used to measure the information of a point. We use it as an active learning criterion. In our frame, active learning is divided into two parts. The first part determines what is the best $q_k$ to be queried for question $Q_k$ with fixed k, and the second part decides which question $Q_k$ should be queried. To solve"}, {"title": "3.2 Exploration and exploitation method", "content": "When the model is not accurate enough, the discrepancies between the predicted probabilities and the true probabilities can be large, resulting in a big gap between estimated loss and true loss. At this time, it may waste the budget to focus on exploiting the uncertain area. To mitigate the risks, the machine should expand its knowledge to unexplored areas. To achieve this, we introduce the distance function d, whose specific form will be introduced at the end of the subsection. Recall the definition of $D_{full}^x$ and $D = \\{D_0, D_1, . . .,D_k\\}$. Similarly, we define $D^x = \\cup_{k=0}^{K} D_k^x$. For any $x \\in D_{full}^x$, define its distance to $D^x$ as\n\n$d(x, D^x) = min_{x' \\in D^x} d(x, x').$\n\nA small $d(x, D^x)$ implies that some information has been gained in the neighbor of x. Therefore, to explore the sample space, we should consider the x with a large $d(x, D^x)$."}, {"title": "3.3 Some remarks", "content": "The entire procedure, including active learning as well as exploration and exploitation, is organized in Algorithm 2. The exploration and exploitation frame is flexible and can be"}, {"title": "4 Theory", "content": "Some theoretical supports for both the proposed entropy-based active learning frame and the exploration and exploitation frame are provided in this section. Let $X \\subseteq R^p$ be the input space. Assume the joint distribution of the input point X with its label Y to be F(X, Y). We also assume that the form of the model follows the \u201csoftmax\u201d structure. Let $H_0$ be the set of measurable functions mapping X into $R^L$. For any $h \\in H_0$, the predicted probability of label c for x is\n\n$p_h^c(x) = \\frac{exp\\{h_c(x)\\}}{\\sum_{l=1}^{L} exp\\{h_l(x)\\}}$.\n\nWe refer to $h \\in H_0$ as a model or a score. Working under the entire $H_0$ is impractical. We assume a subset $H \\subset H_0$ which contains functions with a given uniform bound \u0394. Furthermore, we define a subset of H by H', representing the set of functions under con-sideration. For example, by restricting a specific structure, the newly defined subset is"}, {"title": "5 Simulation", "content": "The section presents simulations of the proposed active learning method along with the ex-ploration and exploitation frame using several distinct models and five real-world datasets. Our frame with multiple questions available is compared with two typical traditional meth-ods. The first method repeatedly queries \"what is the class of x?\" with x obtained by"}, {"title": "5.1 Logistic model", "content": "We will start by illustrating the logistic model using two real-world datasets. The first dataset, MEU-Mobile, consists of 71 features of phone users. The aim is to identify users based on these features. The dataset involves 56 users who each repeated typing 51 times. We randomly sample 12 users in each simulation, resulting in 12 classes with 612 samples. The second is a pre-processed handwriting digits dataset from the UC Irvine machine learning repository\u00b9 with 5620 images depicting digits 0 to 9. The images are originally of"}, {"title": "5.2 Neural network model", "content": "When facing a high-dimensional, non-linear dataset, the logistic model fails to capture the features of the data. In such cases, the neural network model is a better alternative. The model is constructed by a great deal of hidden layers and nodes. As the hidden layers go deeper, this model captures increasingly abstract features. The number of nodes in the final layer equals the number of classes. A \u201csoftmax\u201d operator is used in the last layer, as described in Equation (7), to ensure that the model's outputs are probabilities. The third dataset is the urban land cover dataset containing 675 multi-scale remote sensing images. The dataset has been preprocessed into 147 features. The dataset includes nine objects: trees, grass, soil, concrete, asphalt, buildings, cars, pools and shadows. The fourth dataset is the frequently used MNIST handwriting digits dataset. It contains 70000 28 \u00d7 28 images of numbers 0 to 9. To ease the computational burden, we randomly sample"}, {"title": "5.3 Transfer learning", "content": "The fifth dataset utilized is an animal image set sourced from Kaggle\u00b2, which contains a total of 26179 images categorized into ten classes: dog, cat, horse, spyder, butterfly, chicken, sheep, cow, squirrel and elephant. During preprocessing, we excluded 51 images with fewer than three color channels and resized the remaining images to dimensions of (3, 224, 224) using bilinear interpolation. The data was then randomly split into two sets. The first set, $D_{full}$, has 60% of data and is designated for active learning. The remaining"}, {"title": "6 Concluding Remarks", "content": "In this paper, we address the classification active learning problems from a novel perspective on how the data are labeled. Three main contributions are as follows. First, we propose a method to effectively integrate full and partial information for model building by utilizing probabilities as a key bridge to connect the partial information. The method is applicable to all probabilistic models trained by minimizing the loss function. Secondly, we propose an innovative active learning method tailored for classification tasks. The proposed active learning method considers multiple questions and selects questions based on an index re-lated to both entropy and cost. Thirdly, we propose an exploration and exploitation frame that can be embedded in any active learning criterion by screening points with redun-dant information using a data-driven approach and automatically selecting the distance"}]}