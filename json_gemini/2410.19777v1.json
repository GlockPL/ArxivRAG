{"title": "Deep Learning-driven Mobile Traffic Measurement Collection and Analysis", "authors": ["Yini Fang"], "abstract": "The global mobile traffic consumption has been growing sharply, driven by the surge\nof smart IoT devices and the adoption of 5G technology. Further, the COVID-19 pan-\ndemic has accelerated the digital transformation of work and study, leading to tremen-\ndous traffic demands. Due to these reasons, mobile operators are facing pressing re-\nsource management problems related to storage and overhead of transferring large\namounts of metadata that serve for analysing user demands and planning the infras-\ntructure needed to accommodate these. In this context, intelligent measurement col-\nlection, precise geo-spatial traffic analysis, and forecasting are becoming essential to\nassuring high performance and cost-efficiency of cellular network deployments.\n\nModelling dynamic traffic patterns and especially the continuously changing de-\npendencies between different base stations, which previous studies overlook, is chal-\nlenging. Traditional algorithms struggle to process large volumes of data and to extract\ndeep insights that help elucidate mobile traffic demands with fine granularity, as well\nas how these demands will evolve in the future. Therefore, in this thesis we harness the\npowerful hierarchical feature learning abilities of Deep Learning (DL) techniques in\nboth spatial and temporal domains and develop solutions for precise city-scale mobile\ntraffic analysis and forecasting. Firstly, we design Spider, a mobile traffic measurement\ncollection and reconstruction framework with a view to reducing the cost of measure-\nment collection and inferring traffic consumption with high accuracy, despite working\nwith sparse information. In particular, we train a reinforcement learning agent to se-\nlectively sample subsets of target mobile coverage areas and tackle the large action\nspace problem specific to this setting. We then introduce a lightweight neural network\nmodel to reconstruct the traffic consumption based on historical sparse measurements.\nOur proposed framework outperforms existing solutions on a real-world mobile traffic\ndataset. Secondly, we design SDGNet, a handover-aware graph neural network model\nfor long-term mobile traffic forecasting. We model the cellular network as a graph, and\nleverage handover frequency to capture the dependencies between base stations across\ntime. Handover information reflects user mobility such as daily commute, which helps\nin increasing the accuracy of the forecasts made. We proposed dynamic graph con-\nvolution to extract features from both traffic consumption and handover data, showing\nthat our model outperforms other benchmark graph models on a mobile traffic dataset\ncollected by a major network operator.", "sections": [{"title": "Lay Summary", "content": "The COVID pandemic has accelerated digitalization as various events, lectures and\nmeetings moved online. The total mobile traffic consumption continues to grow, and\nthe cost resulting from computational overhead leads to expensive real-time traffic\nmonitoring. It thus becomes urgent for mobile operators to apply intelligent solutions\nfor precise traffic analysis with cost and latency reduction in mind.\n\nDeep learning techniques have gained increasing attention due to their excellent\nability to make sense of complex patterns hidden in data, and due to recent advance\nin parallel computing that facilitates experimenting with such tools in an affordable\nmanner. On the other hand, public mobile traffic high quality datasets are increasingly\navailable, thanks to contributions by mobile operators. All of these combined opened\nup new opportunities for advancing research in the mobile networking area.\n\nIn this thesis, we provide solutions to two of key challenges in this area, which\nbuild on deep learning. Firstly, we propose a measurement collection and reconstruc-\ntion framework, which enables mobile operators to only collect measurements from\nsmall sunsets of base stations and use these to 'paint' a complete picture of the traf-\nfic consumption across the entire network. We apply deep reinforcement learning, a\nspecial branch of machine learning, and propose an algorithm to address the difficulty\nof developing a strategy for where to take such measurements, among the numerous\nchoices available. Subsequently, we propose a lightweight model for reconstruction\nwhich accurately captures spatiotemporal relationships that are characteristic to mo-\nbile traffic. Our framework can significantly reduce the cost of data collection, transfer\nand storage, while offering high reconstruction quality.\n\nSecondly, we propose a deep learning solution for forecasting future mobile traf-\nfic consumption, given historical traffic snapshots. Previous studies either assume\nstatic dependencies between base stations or model such dependencies through loca-\ntion proximity, which overlooks essential dynamics. In contrast, we leverage handover\nfrequency information to model such dependencies. Our model provably effective in\ncapturing the dynamic characteristics of mobile traffic.\n\nWe conclude the thesis by pinpointing future research directions that are worth\npursuing based on the work presented."}, {"title": "Introduction", "content": "The total global monthly mobile data traffic consumption exceeded 66 exabytes (EB)\nin Q1/2021 and is expected to surpass 300 EB across different mobile technologies\ncombined by 2026 [1]. Additionally, the COVID-19 pandemic has forced people and\norganization to adjust to a new working paradigm: working-from-home. This leads\nto an acceleration in digitization and increased traffic demands. This continual rise\nin demand poses evermore pressing challenges on mobile networks and highlights the\nneed for precise networking analysis and demand-aware management as a driver for\nassuring high performance of the modern 5G networking infrastructures.\n\nNetwork visibility plays an important role in the network monitoring and manage-\nment. Data-driven network management hinges on accurate traffic measurements [2]\ncollected by dedicated probes that are deployed, e.g., at packet gateways (PGWs) or\nRadio Network Controllers (RNCs) [3]. Yet processing vast amounts of data in a\nscalable and timely fashion is ever more challenging, as it requires substantial local\nstorage capabilities, it requires a heavy overhead in transferring detailed logs to cen-\ntral locations for analysis, it involves data filtering by scope (e.g., cell ID, session\nstart/end times, traffic volume/type, etc.) to serve specific use cases [4], and it relies\non high-performance computing platforms to extract essential insights. On the other\nhand, modelling the complex cellular network precisely remains challenging, as previ-\nous studies overlook the dynamic dependencies between base stations and thus fail to\ncapture the dynamic spatiotemporal correlations. In this context, developing an intel-\nligent policy of measurement collection and performing accurate traffic reconstruction\nand forecasting become vital to establishing cost-efficient cellular networks with high\nperformance and high user experience.\n\nRecently, with the success of deep learning techniques, Convolutional Neural Net-"}, {"title": "1.1 Research Challenges", "content": "Monitoring large-scale mobile traffic across cities is a costly process that relies on ded-\nicated measurement equipment, and it becomes urgent to develop elegant solutions to\ndeal with the increasing cost driven by big data. Some of these probes have limited pre-\ncision or coverage, others gather tens of gigabytes of logs daily, which independently\noffer limited insights. Extracting fine-grained patterns involves expensive spatial ag-\ngregation of measurements, storage, and post-processing. Processing such huge data\nrelies on high-performance computing platforms to extract essential insights. There-\nfore, mobile operators urgently need more cost-effective alternative solutions for traffic\nmonitoring. Though recent progress in this domain appears promising, there still re-\nmain several research challenges to be addressed. Specifically:\n\n\u2022 One cost-effective alternative to extensive traffic measurement collection is to\ngather data only from a subset of probes and reconstruct the traffic consumption\nfrom those unsampled cells. Recent work on adaptive sampling [7] [8] [9] [10]\n[11] can only underpin suboptimal allocation of network resources and implicitly\nmodest end-user quality of experience, because such methods randomly select\nthe sampling locations without considering spatiotemporal correlations that are\nspecific to mobile traffic. In practice, mobile operators need intelligent strategies\nto instrument dynamic measurement collection campaigns using virtual probe\nmodules that can be instantiated as needed. However, developing an intelligent"}, {"title": "1.2 Thesis Contributions", "content": "policy for measurement collection is challenging: the cellular deployments usu-\nally comprise a large number of cells, so the number of possible sampling point\nselection options grows dramatically. How to quickly and accurately select a\nminimum number of optimal cells and reduce the collection cost needs to be\nfurther investigated.\n\n\u2022 Mobile traffic forecasting is another important driver for network resource allo-\ncation. Making highly-accurate mobile traffic predictions at city-scale is how-\never challenging, as services continues to diversify and exhibit highly dynamic\npatterns, while spatiotemporal correlations across different parts of a deploy-\nment are not straightforward to elucidate given unpredictable user mobility or\nterrain/coverage irregularities. A question to be answered is how can we mean-\ningfully represent complex cellular network to be able to make high-quality fore-\ncasts? Prior work builds on distance-based Euclidean (grids) or invariant graph\nrepresentations, which cannot capture dynamic spatiotemporal correlations with\nhigh fidelity. Especially, location proximity of base stations may not reflect\nstrong dependency due to terrain constraints, while distant base stations may\nexhibit strong dependencies because of user daily commute patterns (e.g. along\na motorway).\n\nIn this thesis we utilize the power feature learning ability of deep learning techniques\n(e.g., reinforcement learning, graph neural networks) to capture spatiotemporal corre-\nlations in the non-linear and dynamic mobile traffic patterns, and develop state-of-the-\nart solutions for city-scale mobile traffic measurement collection and analysis."}, {"title": "1.2.1 Deep Learning-driven Sparse Mobile Traffic Measurement Collection and Reconstruction", "content": "Firstly, we design Spider, a mobile traffic measurement collection and reconstruction\nframework which significantly reduces the cost of measurement collection and infers\ncomplete traffic consumption with high accuracy from sparse information. The frame-\nwork outputs cell selection matrices indicating at which locations to activate mea-\nsurement collection given sparse historical traffic snapshot, to reduce the collection"}, {"title": "1.2.2 A Handover-aware Spatiotemporal Graph Neural Network for Mobile Traffic Forecasting", "content": "Secondly, we design SDGNet (Spatiotemporal Dynamic Graph Network), a handover-\naware graph neural network model for mobile traffic forecasting. The cellular network\nis modelled as a directed and weighted dynamic graph. As location proximity fails to\nreflect the dependencies between base stations, we leverage the handover frequency\n(i.e., the number of handovers), which reflects user mobility such as the daily com-\nmute, to represent the weights of the graph. SDGNet uses gated linear units to extract\ntemporal features and we propose a DGCN (Dynamic Graph Convolution Network)\nthat combines dynamic graph spectral convolution and diffusion graph convolution\nfor spatial features extraction in both short- and long-term. Validated on a real-world\nmobile traffic dataset, our SDGNet excels at short-/mid-/long-term mobile traffic fore-"}, {"title": "1.3 Thesis Organization", "content": "We organize the rest of the thesis as follows:\n\n\u2022 Chapter 2 presents an up-to-date background in regard to Machine Learning\nalgorithms and related work on mobile traffic measurement collection and anal-\nysis utilizing these ML algorithms and other traditional algorithms. Specifically,\nwe first review work on mobile traffic sampling and reconstruction. Then, we\ngive a primer on Reinforcement Learning and its applications to sparse mobile\ncrowdsensing. Finally, we summarize relevant work on Graph Neural Networks,\nthe main types of graph convolution, and their applications on forecasting in\nspatiotemporal tasks.\n\n\u2022 Chapter 3 proposes Spider, a deep-learning mobile traffic measurement collec-\ntion and reconstruction framework. We provide an in-depth explanation of the\nalgorithm with visualization and pseudocode. We then perform experiments on\na real-world mobile traffic dataset and evaluate the outcomes.\n\n\u2022 Chapter 4 introduces SDGNet, a graph neural network model for long-term\nmobile traffic forecasting. We explain the algorithm in details and perform ex-\nperiments on a mobile traffic dataset collected by a major operator. We compare\nthe performance with that of other graph models.\n\n\u2022 Chapter 5 concludes our thesis and provide several open research issues and\nfuture directions following from our projects, including (i) end-to-end mobile\ntraffic measurement collection and reconstruction, (ii) hybrid dynamic graphs\nfor mobile traffic forecasting, and (iii) incorporating uncertainty in mobile traffic\nforecasting with Bayesian Graph Convolutional Networks."}, {"title": "Background & Related Work", "content": "This chapter reviews relevant related work in Machine Learning and traditional algo-\nrithms that have applications to mobile traffic analysis. Specifically,\n\n\u2022 Mobile Traffic Sampling and Reconstruction focuses on the traditional algo-\nrithms (e.g., Adaptive sampling, Compressive Sensing) used in sampling and\ndata reconstruction.\n\n\u2022 Reinforcement Learning and Its Applications elaborates on Reinforcement\nLearning algorithms and their applications to sparse mobile crowdsensing.\n\n\u2022 Graph Neural Networks and Their Applications introduces the concept of\nGraph Neural Network and reviews recent work on forecasting in spatiotemporal\ntasks, including mobile traffic prediction."}, {"title": "2.1 Mobile Traffic Sampling and Reconstruction", "content": "Sampling and reconstruction is an effective way to process vast amounts of data in a\nscalable and timely fashion, where only a subset of data collection points are activated\nand complete network traffic snapshots are subsequently reconstructed via interpola-\ntion."}, {"title": "2.1.1 Sampling", "content": "Sampling methods can be divided into uniform sampling and adaptive sampling. Adap-\ntive sampling determines the sampling amount based on predefined criteria, and thus it\nis more effective and further reduce the sampling cost compared to random sampling."}, {"title": "2.1.2 Data reconstruction", "content": "Traditionally, K-Nearest Neighbors (KNN) and Compressive Sensing (CS) are widely\napplied to data reconstruction problems. KNN interpolates missing values by using a\nweighted average of the values of the k nearest neighbours. Wang et al. [17] propose\nspatial KNN (KNN-S) and temporal KNN (KNN-T) for mobile traffic data reconstruc-\ntion, which perform KNN on columns or rows. However, the KNN algorithm has\nsignificant drawbacks. Firstly, because the inferred values are based on their neigh-\nbours, the algorithm cannot work if the matrix is too sparse. Secondly, the inferred"}, {"title": "2.1.3 Reconstruction Quality Estimation", "content": "One challenge in data reconstruction is reconstruction quality estimation. In practice,\nwe cannot get access to the complete data for evaluating the reconstructed data, there-\nfore the reconstruction quality can only be estimated. In the following, we discuss\nseveral ways of estimating the reconstruction quality.\n\nLeave-One-Out Statistical-Analysis Wang et al. [17] leverage Leave-One-Out Sta-\ntistical Analysis (LOO-SA) for quality estimation. Instead of directly predicting the\ninference error $e$, LOO-SA use statistical analysis to estimate the probability of the\ninference error being no larger than the predefined error threshold $\u03b5$ (i.e., $P(e \\leq \u03b5)$). If\nthe estimated probability is larger than $\u03b2$ ($\u03b2$ being the predefined probability threshold),\nthen the quality of reconstruction is considered to be satisfied. There are two steps in"}, {"title": "2.2 Reinforcement Learning and Its Applications", "content": "they will not affect the behaviour of the regression functions and, hence, the distance\nmeasure $d$ is not sensitive to them.\n\nIn summary, LOO-SA algorithm has a large time complexity, and requires con-\nfiguring two hyperparameters (error threshold $e$ and probability threshold $P(e \u2264 \u03b5)$).\nConcept drift can only be used for the generalization error of the model. In order to\nhave a fast and simple solution, one can leverage the power of deep learning to approx-\nimate the function of reconstruction quality."}, {"title": "2.2.1 Reinforcement Learning", "content": "Reinforcement Learning (RL) is a commonly-used algorithm in Machine Learning\nwhere an agent learns by interacting with the environment. It has been widely used\nin various fields, such as chemistry, manufacturing, robotics, etc. Instead of explicitly\nbeing taught the behaviour, the agent learns its behaviour from the consequences of the\ntaken actions in the past. We use a Markov Decision Process (MDP) [28] to define an\nenvironment. There are five components in an MDP:\n\n\u2022 A set of states $S = \\{s_t | t = 0,1,..., T\\}$.\n\n\u2022 A set of actions $A = \\{a_t | t = 0,1,...,T\\}$.\n\n\u2022 $P = \\{p_t | t = 0,1,...,T\\}$, the probability that action $a$ in state $s$ will lead to the\nnext state $s'$ at time $t$.\n\n\u2022 $R = \\{r_t | t = 0,1,..., T\\}$, the immediate reward received after the transition $(s,a)$\nto $s'$ at time $t$.\n\n\u2022 Discount factor $\u03b3$ that is used to compute the return (i.e., the accumulative re-\nward) $R = \\sum_{t=0}^T \u03b3^t r_t$.\n\nFigure 2.2 illustrates how the agent interacts with the environment. For every\ntimestamp in an episode (i.e., from an initial state to a terminal state), the agent re-\nceives the current state $s_t$ and chooses an action $a_t$ from the set of available actions\naccording to its policy. The environment receives the action, which returns a reward $r_t$.\nThen the environment transitions to a new state $s_{t+1}$. The agent continuously adjusts\nits behaviour based on the feedback from the environment. The goal of the agent is"}, {"title": "2.2.2 Sparse Mobile Crowdsensing", "content": "With the unprecedented growth of smartphones, urban sensing applications have been\nboosted by mobile crowdsensing (MCS). MCS is a paradigm that leverages the sensors\nin users' smartphones for data collection, especially for areas that are not covered by\nsensing infrastructure. In order to obtain high-quality sensed data, numerous users\ncovering the whole area should be recruited, which sometimes is impossible. Early\nstudies focus on minimizing the redundant number of allocated data collection tasks"}, {"title": "2.3 Graph Neural Networks and Its Applications", "content": "In most machine learning tasks such as image classification and natural language\nprocessing, data is usually represented in Euclidean space (e.g., text, images, and\nvideo). In recent years, research on deep learning techniques for non-Euclidean data\n(e.g., citations, friendships, and interactions) has been gaining more and more atten-\ntion [40]. These data are represented as graphs with complex relationships and interde-\npendency between objects [40] which are overlooked in the Euclidean domains. Coates\net al. [41] utilized graph structure in network tomography, where a node represents a\ncomputer/cluster of computers/router and an edge represents a direct link between two\nnodes. The weight of an edge is the bandwidth of the corresponding connection. They\nuse these to deal with large-scale network inference problems (e.g., link-level param-\neter estimation and sender-receiver path-level traffic intensity estimation). Assume a\ngraph consists of $n$ nodes (i.e. vertices), it can be formulated as $G = (v,e,w)$, where\n$v \u2208 R^n$ represents the graph signal, $e \u2208 R^{n\u00d7n}$ is a set of edges indicating the connect-\nedness between vertices, and $w \u2208 R^{n\u00d7n}$ denotes the weighted adjacency matrix of $G$.\nFigure 2.4 shows the benefits of modelling the cellular network as a graph. Base sta-\ntions are represented as vertices, and the weight in the adjacency matrix indicates the\ndependency between two base stations. Such dependency is dynamic and non-linear.\nThe graph signal can be modelled as the traffic consumption and the timestamp infor-\nmation. Compared to matrices, the merits of graph representation are obvious."}, {"title": "2.3.1 Graph Neural Networks", "content": "In most machine learning tasks such as image classification and natural language\nprocessing, data is usually represented in Euclidean space (e.g., text, images, and\nvideo). In recent years, research on deep learning techniques for non-Euclidean data\n(e.g., citations, friendships, and interactions) has been gaining more and more atten-\ntion [40]. These data are represented as graphs with complex relationships and interde-\npendency between objects [40] which are overlooked in the Euclidean domains. Coates\net al. [41] utilized graph structure in network tomography, where a node represents a\ncomputer/cluster of computers/router and an edge represents a direct link between two\nnodes. The weight of an edge is the bandwidth of the corresponding connection. They\nuse these to deal with large-scale network inference problems (e.g., link-level param-\neter estimation and sender-receiver path-level traffic intensity estimation). Assume a\ngraph consists of n nodes (i.e. vertices), it can be formulated as G = (v,e,w), where\nv\u2208 R\" represents the graph signal, e \u2208 R\"\u00d7n is a set of edges indicating the connect-\nedness between vertices, and w \u2208 R\"\u00d7n denotes the weighted adjacency matrix of G.\nFigure 2.4 shows the benefits of modelling the cellular network as a graph. Base sta-\ntions are represented as vertices, and the weight in the adjacency matrix indicates the\ndependency between two base stations. Such dependency is dynamic and non-linear.\nThe graph signal can be modelled as the traffic consumption and the timestamp infor-\nmation. Compared to matrices, the merits of graph representation are obvious."}, {"title": "2.3.2 Graph Convolution Primer", "content": "As spectral graph convolution and DCRNN are fundamental to Graph Neural Networks\n(GNNs) and is vital to our project, in this subsection, we explain these two types of\ngraph convolution in details.\n\nFirst, we define the spectral graph convolution operator $*_G$ as the multiplication of\na graph signal $v \u2208 R^n$ and static adjacency matrix $A \u2208 R^{n\u00d7n}$ with a kernel $g\u2208 R^n$, i.e.,\n\n$v *_G g = g(L)v = g(U\u039bU^T)v=Ug(\u039b)U^Tv$,\n\nwhere $L \u2208 R^{n\u00d7n}$ is the normalized graph Laplacian, $\u039b$ is the diagonal matrix of eigen-\nvalues of $L$, and the graph Fourier basis $U \u2208 R^{n\u00f6n}$ is the matrix of eigenvectors of $L$.\nThe transition is based on the equation $L = I_n \u2212 D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} = U\u039bU^T$, where $I_n$ is an\nidentity matrix and $D \u2208 R^{n\u00d7n}$ is the diagonal degree matrix with $D_{ii} = \\sum_jA_{ij}$.\n\nChebyshev Polynomials Approximation In order to localize the filter and reduce\nthe algorithm complexity, the kernel $g$ can be restricted to a polynomial of $L$: $g(L) =$\n$\\sum_{k=0}^{K-1} \u03b8_kL^k$, where $\u03b8 \u2208 R^K$ is a vector of polynomial coefficients. $K$ is the kernel\nsize and indicates the area of the convolution in the neighbourhood. The Chebyshev"}, {"title": "2.3.3 Forecasting in Spatiotemporal Tasks", "content": "Applying a Graph Neural Network (GNN) in spatiotemporal tasks is gaining wide in-\nterest. Y. Seo et al. [51] introduce a Graph Convolutional Recurrent Network (GCRN)\nto predict structured sequences of data. The proposed model combines graph convo-\nlution operations to identify spatial structures and RNN to capture dynamic patterns.\nThe authors found that simultaneously exploiting graph spatial and dynamic infor-\nmation about the data can improve both prediction accuracy and training speed [51]."}, {"title": "2.4 Summary", "content": "This chapter discussed related work. We first introduced sampling and reconstruc-\ntion approaches applied in the mobile traffic analysis, as well as how to estimate the\nreconstruction error. Then we explained basic concepts in Reinforcement Learning,\nincluding Q learning, deep reinforcement learning, and Monte Carlo Tree Search, and\ntheir applications to mobile traffic analysis, e.g., Spare Mobile Crowdsensing. Lastly,\nwe took a look at Graph Neural Networks and popular graph convolution operations,\nfollowed by their applications in spatiotemporal forecasting tasks. Additionally, we\nsummarize several limitations of the state-of-the-art and the opportunities that arise\nin the area of mobile traffic analysis. In the next chapter we will first focus on the\nsampling and reconstruction framework, where we propose a deep learning-based ap-\nproach and show it outperforms a set of benchmarks."}, {"title": "Deep Learning-driven Sparse Mobile Traffic Measurement Collection and Reconstruction", "content": "Precise traffic monitoring is costly due to dedicated equipment, substantial storage\ncapability and transfer overhead. As discussed before, traditional sampling and re-\nconstruction approaches are based on the assumption that the measurement collection\npoints are fixed and randomly selected, which overlooks spatiotemporal correlations\ntailored to mobile traffic. Therefore, it is vital to developing a solution to an intelli-\ngent selection policy and precise mobile traffic reconstruction, so that the cost of data\ncollection is reduced while high reconstruction accuracy is retained.\n\nThis chapter describes our first contribution. We propose Spider, a deep learning-\ndriven mobile traffic measurement collection and reconstruction framework for in-\nfrastructure level data. Spider relies on a dedicated neural network that we train to\nselectively sample small subsets of target mobile coverage areas. It then employs a\npurpose-built mobile traffic reconstruction neural model, which exploits spatiotempo-\nral correlations in historical data, to infer mobile traffic consumption across the entire\ndeployment. Our framework reduces dramatically the cost of data collection while\nretaining high traffic consumption inference accuracy. In summary, we:\n\n(1) We introduce a policy network that takes as input sparse historical traffic snap-\nshots and outputs cell selection matrices indicating at which locations to activate\nmeasurement collection, so as to minimize overhead while acquiring enough data\nto ensure high-quality traffic consumption interpolations at all non-sampled cells.\nWe take a Deep Reinforcement Learning (DRL) approach to produce examples for"}, {"title": "3.1 Problem Formulation", "content": "Consider a mobile network coverage area that is geographically partitioned into a grid\nwith $X \u00d7 Y$ squares (cells), where a square denotes an atomic region for mobile traffic\ncollection. We denote by $F_t$ the traffic consumption snapshot across all cells, observed\nover an interval $[t \u2013 \u2206,t]$, i.e.,\n\n$F_t = \\begin{bmatrix}\n d'_{1,1} & d'_{1,2} & ... & d'_{1,Y} \\\\\n d'_{2,1} & d'_{2,2} & ... & d'_{2,Y} \\\\\n : & : & ... & : \\\\\n d'_{X,1} & d'_{Y,2} & ... & d'_{X,Y}\n\\end{bmatrix}$,\n\nwhere $d'_{i,j}$ is the volume of traffic at cell $(i, j)$, and $\u2206$ is the time granularity config-\nurable by a network administrator, with which traffic measurement equipment (probes)\ncompute summaries of the volume of traffic observed at different locations. A mobile\nnetwork operator will need a sampling strategy that gives a binary selection matrix\n$B_t$ indicating which cells are to be selected for measurement collection at time $t$, i.e.,\n$b_{i,j} = 1$, if cell $(i, j)$ is selected; $b_{i,j} = 0$, otherwise; and subsequently use the mea-\nsurements collected to infer the traffic consumption across the entire deployment. A\nselection matrix produces a sparse measurement matrix $M_t$ of a network traffic snap-"}, {"title": "3.2 Our Framework: Spider", "content": "To solve the problem defined by (3.1)\u2013(3.3), we propose Spider, an original mobile\nnetwork traffic measurement collection and reconstruction framework that (i) predicts"}, {"title": "3.2.1 RL for Cell Selection with Large Action Spaces", "content": "To collect measurements with minimum sampling overhead, we first leverage Rein-\nforcement Learning (RL) and train an agent that learns the likelihood of selecting a\ncell where to sample traffic, based on past experience. We subsequently use this agent\nto train a policy network that directly outputs optimal cell selection matrices, given\nprior observations, and thus is suitable for real-time decision-making.\n\nWe start by regarding cell selection as an episodic task, which can be modelled as\na Markov Decision Process (MDP), $M := (S,A, P, r, \u03b3)$, where\n\n\u2022 $S$ is the set of states $s_i$, in our case a state representing a collection of sparse\nmeasurement matrices of the past T network traffic snapshots, i.e., $s_i = M =$\n$[M_{t-T+1},...,M_{t-1}]$, with $M_{t-1}$ denoting the sparse measurement matrix at itera-\ntion i - 1 of an episode t;\n\n\u2022 A is the set of possible actions, where an action $a_i$ corresponds to sampling one\nof all the previously unselected cells at timestamp t, from which the agent can\nchoose;\n\n\u2022 $P(s, a, s')$ is the probability that action a in state s will lead to next state s';\n\n\u2022 $r(s,a,s')$ is the reward the agent receives as a consequence of choosing action\na when in state s; we work with $r(s,a,s') = \u2212MAE(f(s'), F_t)$ to incentivize\nthe agent to take actions that reduce the reconstruction error; while a range of\nmethods $f(\u00b7)$ can be employed for reconstruction, including compressive sensing\nor K-Nearest Neighbour-based interpolation, our Spider framework evaluates\nhow good an action is using a pre-trained Mobile Traffic Reconstruction neural\nNetwork (MTRNet), which we detail in Sec. 3.2.2.\n\n\u2022 $\u03b3\u2208 [0, 1]$ is the discount rate an agent's objective is to maximize a cumulative\nreward it receives (expected return), i.e. the sum of discounted rewards $\u03b3^{k-1}r$\nover k iterations; we work with $\u03b3 = 0$, meaning that at each iteration we seek to"}, {"title": "3.2.2 Traffic Reconstruction from Sparse Measurements", "content": "We perform traffic measurement reconstruction using a supervised learning approach.\nThe proposed Mobile Traffic Reconstruction neural Network (MTRNet) takes as input\nthe sparse measurement matrices for the current (t-th) and previous T timestamps, i.e.,\n$[M_{t\u2212T},\u2026\u2026,M_t]$, and outputs the traffic consumption of the full map $F_t$ at the current\ntimestamp.\n\nThe model architecture is shown in Figure 3.4. We draw inspiration from Zip-\nNet [25], a mobile traffic super-resolution technique that infers fine-grained traffic\nconsumption from coarse measurements. The original ZipNet was modified in or-\nder to reduce the size of the model and improve its inference speed. Specifically, since\nin our setting the size of the sparse measurement matrices is the same as the size of\nthe output, we discard upscaling blocks. Further ablation study allows us to reduce the\nnumber of layers of the model (depth) while retaining high accuracy. The resulting\nMTRNet comprises three key components:\n\n\u2022 Correlation capture. A 3D convolutional layer is used to capture spatiotempo-\nral correlations between recent snapshots. The activation layer is a Leaky-ReLU\n(LReLU) that improves the model's non-linearity and its robustness to network ini-\ntialization. LReLU is defined by:\n\n$LReLU(x) = \\begin{cases}\n x, & x \u2265 0 \\\\\n \u03b1x, & x<0\n\\end{cases}$,\n\nwhere $\u03b1$ is a configurable slope value. A SumPooling layer is applied after LReLU\nto reduce the size of the feature maps and speed up the training.\n\n\u2022 Feature extraction. Several 2D Convolutional layers followed by a LReLU extract\nhigh level abstract features from the geographical configuration of the measured traf-"}, {"title": "3.2.3 Policy Network", "content": "Since RL agents typically evaluate one action at a time, they are often impractical to\ndeploy in settings where decisions have to be made within short deadlines. Therefore,\nwe design a policy network that predicts all optimal cell locations to be sampled,\n$B_t = g(M_t)$, at once. This policy network (g) takes historical sparse measurement\nsnapshots and timestamp information as input and learns to predict binary selection\nmatrices generated by the agent introduced in Sec. 3.2.1 at the end of each episode.\n\nThis neural network effectively solves a multi-label classification task where pos-\nitive labels represent cells to be selected, and negative labels indicate non-selected\nsquares. The model architecture is similar to that of MTRNet (shown in Figure 3.5),\nthough here a final Sigmoid layer transforms the outputs into probability scores, and\nwe assign positive labels to those selection matrix elements where the probability is\nabove 0.5, and negative to all others. As the cell selection frequencies are likely to\nbe skewed, the probabilities are normalized to the range [0,1] before the binarization\nprocess.\n\nWe use a Binary Cross-entropy (BCE) loss function to train this neural model,"}, {"title": "3.3 Performance Evaluation", "content": "For evaluation, we adopt a real-world mobile traffic dataset collected by Telecom Italia\nin the city of Milan [67]. The city is divided into 100\u00d7100 squares of 0.055 km\u00b2.\nMobile data traffic measurements were collected on aggregate at these locations every\n10 minutes between 01/10/2013 and 01/01/2014 (3 months). We use 40 days worth\nof data to train the models, and 20 days for testing. Figure 3.6 shows the heatmaps\nof average traffic consumption of one snapshot in weekend, weekdays, off-peak, and\npeak (9am-6pm), respectively, from left to right.\n\nThe distribution of traffic consumption is skewed, as shown in Figure 3.7 (a). We\nnormalize the traffic consunmption by $x = log(1+x)/x$, where x is the traffic consump-"}, {"title": "3.3.1 Dataset", "content": "For evaluation, we adopt a real-world mobile traffic dataset collected by Telecom Italia\nin the city of Milan [67"}]}