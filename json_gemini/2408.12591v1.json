{"title": "Differentiable Logic Programming for Distant Supervision", "authors": ["Akihiro Takemura", "Katsumi Inoue"], "abstract": "We introduce a new method for integrating neural networks with logic programming in Neural-Symbolic AI (NeSy), aimed at learning with distant supervision, in which direct labels are unavailable. Unlike prior methods, our approach does not depend on symbolic solvers for reasoning about missing labels. Instead, it evaluates logical implications and constraints in a differentiable manner by embedding both neural network outputs and logic programs into matrices. This method facilitates more efficient learning under distant supervision. We evaluated our approach against existing methods while maintaining a constant volume of training data. The findings indicate that our method not only matches or exceeds the accuracy of other methods across various tasks but also speeds up the learning process. These results highlight the potential of our approach to enhance both accuracy and learning efficiency in NeSy applications.", "sections": [{"title": "1 Introduction", "content": "Neural-Symbolic AI (NeSy) [15, 16] is a field of research aimed at combining neural networks with symbolic reasoning. While deep learning is capable of learning complex representations from input-output pairs, it requires a large amount of training data and struggles with tasks that require logical reasoning. On the other hand, learning with symbolic reasoning can be done with small amounts of data, but it is sensitive to noise and unable to handle non-symbolic data. In NeSy, it is crucial to combine the roles of neural networks and symbolic reasoning in a way that leverages their respective strengths.\nThere are various methods for implementing NeSy, including associating the continuous-valued parameters of neural networks (NN) with logical language and using the results of logical reasoning as the value of the loss function (e.g., semantic loss [32]). Also known are methods that combine symbolic solvers with neural networks, e.g., DeepProbLog [19] uses Problog for probabilistic logic programming, and NeurASP [33] uses clingo for answer set programming (ASP). These methods that internally call solvers often encapsulate computationally expensive problems such as weighted model counting or enumerating stable models in each iteration during learning.\nAlternative methods have been proposed that embed inference traditionally done by symbolic reasoning solvers into vector spaces and perform symbolic reasoning using linear algebra [24]. One such method embeds logic programs into vector spaces and designs appropriate loss functions based on the semantics of non-monotonic reasoning to compute the results of reasoning in a differentiable manner [2, 28]. However, these methods have issues such as not being able to directly handle logical constraints and not being applicable to neural network learning as is. Thus, in this paper, we propose a method that enables learning in neural networks for NeSy tasks using logical programs that include constraints.\nDistant supervision is a method of generating labeled data for learning using rules, external data, or knowledge bases and was proposed by Mintz et al. [21] as a method to train classifiers for relation extraction based on information from knowledge bases. In NeSy, tasks where label information is provided through symbolic reasoning are commonly used, with MNIST Addition [19] being a representative task. In this task, pairs of handwritten digits are input, and the goal is to learn the classification of handwritten digits with the sum of the digits provided as the label (e.g., 2+3= 5). Unlike the usual MNIST classification, in MNIST Addition, the labels are not given for each image individually. In this case, the relationship between the sum given as the label and the digits corresponding to the images is expected to be provided through symbolic reasoning.\nIn this paper, we propose a novel architecture for NeSy systems [19, 33] that integrates differentiable logic programming [2, 28] and neural networks. This paper makes the following contributions:\n1. We propose a novel architecture that integrates neural networks with logic programming through a differentiable approach. This method facilitates the direct evaluation of logical implications and constraints using differentiable operations, thus enabling effective learning under distant supervision without relying on symbolic solvers for reasoning about missing labels.\n2. We demonstrate through experiments with a constant volume of training data that our proposed method not only matches but, in some cases, exceeds the accuracy of existing approaches that utilize symbolic solvers. Moreover, we achieved a significant reduction in the training time for neural networks, highlighting substantial gains in computational efficiency.\nThe structure of this paper is as follows. After the preliminaries in Section 2, Section 3 introduces the logic programming semantics in vector spaces. Section 4 presents our proposed method for using differentiable logic programming for distant supervision. Section 5 presents the results of experiments and comparison to the state of the art NeSy methods. Section 6 covers the related works in the literature. Finally, Section 7 presents the conclusion."}, {"title": "2 Preliminaries", "content": "A normal logic program P is a set of rules of the form:\n$A \\leftarrow A_1 \\land \\dots A_m \\land \\neg A_{m+1} \\land \\dots \\land \\neg A_n$\nwhere A and $A_i (n \\geq m > 0)$ are atoms. In this paper, the terms 'normal logic program', 'logic program', and 'program' are used interchangeably. An atom is a predicate with some arity, e.g., p(X, Y), where variables are represented by upper case characters, and predicates and constants are represented by lower case characters. A literal is either an atom p, or its negation \u00acp. The atom A in (1) is the head and ${A_1,..., A_n}$ is the body of a rule. For each rule $R_i$ of the form (1), define $head(R_i) = A, body^+(R_i) = {A_1,..., A_m}$ and $body^-(R_i) = {A_{m+1},..., A_n}$.\nThe Herbrand universe of a logic program P is the set of all ground terms in the language of P, i.e., terms composed of function symbols and constants that appear in P. The Herbrand base $B_P$ is the set of atoms that can be formed from the relations of the program and terms in the Herbrand universe. We assume that the Herbrand base $B_P$ of a program to be lexicographically ordered.\nA rule with an empty body is a fact. A program P is definite if no rule in P contains negation as failure. A program, a rule, or an atom is ground if it is variable free. A program P is semantically identified with its ground instantiation, ground(P), by substituting variables in P by elements of its Herbrand universe in every possible way.\nAn interpretation $I \\subseteq B_P$ satisfies a rule $R_i$ of the form (1) if $body^+(R_i) \\subseteq I$ and $body^-(R_i) \\cap I = \\emptyset$ imply $A \\in I$. An interpretation that satisfies every rule in a program P is a model of the program. A model of a program is supported if for each atom $p \\in I$, there exists a ground rule such that I satisfies its body [1]. A model M is minimal if there is no model J of P such that $J \\subset M$. A definite program has a unique minimal model, which is the least model.\nGiven a normal logic program P and an interpretation I, the reduct $P^I$, which is a ground definite program, is constructed as follows: a ground rule $A \\leftarrow L_1,..., L_m$ is in $P^I$ iff there is a ground rule of the form (1) such that $body^-(R_i) \\cap I = \\emptyset$. If the least model of $P^I$ is identical to I, then I is a stable model of P [14]. For a definite program, the stable model coincides with the least model. A stable model is always supported, but the converse does not hold in general. Supported models can be computed as the models of Clark's completion [5]. Let heads(P, a) be the set of rules in P whose head is a. The completion of P, denoted comp(P), is the set of clauses\n$a \\leftrightarrow \\bigvee\\limits_{R_i \\in heads(P,a)} body(R_i)$\nfor all $a \\in B_P$. A model of comp(P) is a supported model of P [1]. Let $I \\subseteq B_P$ be an interpretation of P. The relation |= is defined as follows: for a rule $R_i$ of the form (1), I satisfies $R_i$ if $head(R_i) \\cap I \\neq \\emptyset$ whenever $body(R_i) \\subseteq I$, and denoted as $I |= R_i$; for a program P, I satisfies P if $I |= R_i$ for all $R_i \\in P$; for a formula $F = F_1 \\lor \\dots \\lor F_k (k \\geq 0)$, $I |= F$ iff there is a $F_i (k \\geq i \\geq 1)$ such that $I |= F_i$, i.e., the empty disjunction is false. Let comp($R_P$) denote the completed rule ($p \\rightarrow body(R_{p1}) \\lor \\dots \\lor body(R_{pj})$) for the atom p, then $p \\in I$ iff $I |= comp(R_p$)."}, {"title": "3 Semantics", "content": "In this section, we consider the semantics of ground normal logic programs in vector spaces. First, we introduce the necessary notations. Matrices are denoted using bold uppercase letters (M), and vectors are denoted using bold lowercase letters (v). The element in the i-th row and j-th column of a matrix is denoted by $M_{ij}$, and the i-th element of a vector is denoted by $v_i$. The slice of the i-th row of a matrix is denoted by $M_{i:}$, and the slice of the j-th column is denoted by $M_{:j}$. Variables are denoted by upper case letters, and constants and predicates are denoted by lower case letters; e.g., in sum(L), L is a variable and sum/1 is a predicate with arity 1.\n3.1 Embedding Normal Logic Programs\nGiven a ground normal logic program P, we introduce two matrices that jointly represent the program. The program matrix represents the bodies of the rules in the program, and the head matrix represents their disjunctions. This is an alternative formulation to the embedding approach described by Sakama et al. [24].\nDefinition 1 (Program Matrix). Let P be a ground normal logic program with R rules and the size of its Herbrand base be $|B_P| = N$. Then P is represented by a binary matrix $Q \\in {0,1}^{R \\times 2N}$ such that i-th row corresponds to the body of the i-th rule $R_i$: $Q_{ij} = 1$ if $a_j \\in body^+(R_i), Q_{i(N+j)} = 1$ if $a_j \\in body^-(R_i)$, and $Q_{ij} = 0$ otherwise.\nDefinition 2 (Head Matrix). Let $D \\in {0,1}^{(N \\times R)}$ be the head matrix associated with P. Then the element $D_{ji} = 1$ if the head of rule $R_i(1 \\leq i \\leq R)$ is $a_j(1 \\leq j \\leq N)$, and 0 otherwise.\nExample 1. Consider the following program $P_1$ with 3 rules:\n$(R_1) a \\leftarrow c \\land \\neg b$\n$(R_2) a \\leftarrow a$\n$(R_3) b \\leftarrow a$\n$P_1$ is encoded into a pair of matrices (Q, D):\nQ=\\begin{array}{c|cccccc} & a & b & c & \\neg a & \\neg b & \\neg c \\\n\\hline\nR_1 & 0 & 0 & 1 & 0 & 1 & 0 \\\nR_2 & 1 & 0 & 0 & 0 & 0 & 0 \\\nR_3 & 0 & 0 & 0 & 1 & 0 & 0\\end{array}\nD=\\begin{array}{c|ccc} & R_1 & R_2 & R_3 \\\n\\hline\na & 1 & 1 & 0 \\\nb & 0 & 0 & 1 \\\nc & 0 & 0 & 0\\end{array}\nQ represents the bodies of the rules, which are the conjunctions of the literals appearing in the bodies. For example, $Q_{1:}$ represents the body of $R_1$, ($c \\land \\neg b$). D represents the disjunctions of the bodies of the rules sharing the same head. For example, $D_{1:}$ represents the disjunction $body(R_1) \\lor body(R_2) = (c \\land \\neg b) \\lor a$. Together, Q and D represent the logic program P.\n3.2 Evaluating Embedded Normal Logic Programs\nWe consider the conjunction appearing in the bodies of the rules as the negation of disjunctions of negated literals using De Morgan's law, i.e., $L_1 \\land \\dots \\land L_n = \\neg(\\neg L_1 \\lor \\dots \\lor \\neg L_n)$. This means that when evaluating the body of a rule, instead of checking whether all literals hold (as in [28]), we can count the number of false literals and check whether the count exceeds 1. To this end, we introduce a piecewise linear function $min_1(x) = min(x, 1) = ReLU(1 - x)$, which gives 1 for $x > 1$. This function is almost everywhere differentiable (except at x = 1), which allows gradient-based optimization to be applied effectively.\nTo evaluate normal logic programs in vector spaces, we introduce the vectorized counterparts of interpretation and model.\nDefinition 3 (Interpretation Vector). Let P be a ground normal logic program. An interpretation $I \\subseteq B_P$ is represented by a binary vector $v = (v_1,..., v_N) \\in Z$ where each element $v_i (1 \\leq i \\leq N)$"}, {"title": "3 Semantics", "content": "represents the truth value of the proposition $a_i$ such that $v_i = 1$ if $a \\in I$, otherwise $v_i = 0$. We assume propositional variables share the common index such that $v_i$ corresponds to $a_i$, and we write $idx(v_i) = a_i$.\nDefinition 4 (Complementary Interpretation Vector). The complementary interpretation vector $w \\in Z^{2N}$ is a binary vector, which is a concatenation of the interpretation vector v and its complement:\n$w = [v; 1_v - v]$.\nProposition 1. (Embedding Models of Normal Logic Programs) Let P = (Q, D) be an embedding of a ground normal logic program P, dist(\u00b7,\u00b7) be a distance function in a metric space, v be an interpretation vector representing $I \\subseteq B_P$, and w be its complementary interpretation vector. Then, for an interpretation vector v,\n$I |= comp(P) \\text{ iff } dist \\left(v, min_1(D(1-min_1(Q(1-w))))\\right)=0$\nProof. (Sketch; full proof in the Appendix.) A row slice of the program matrix $Q_{i:}$ corresponds to the body of a rule $R_i$, so the matrix-vector products $Q_{i:} \\cdot w$ and $Q_{i:} \\cdot (1 - w)$ computes the number of true and false literals in I, respectively. The conjunctions can be computed as the negation of disjunctions of negated literals using De Morgan's law, i.e., $1 - min_1(Q_{i:} \\cdot (1 - w))$.\nLet ${R_{a_i}} = {a_i \\leftarrow B_j,..., a_i \\leftarrow B_t}$ be the set of rules that share the same head atom $a_i$, where $B_j$ denote the rule bodies, and $B_j \\lor \\dots \\lor B_t$ be the disjunction of the rule bodies. By construction of the head matrix D, $D_{i:}(1 - min_1(Q(1 - w)))$ computes the number of true rule bodies that share the same head. Thus, $h_i =$ $min_1(D_{i:}(1 - min_1(Q(1 - w)))) = 1$ if there is at least one rule body that is true in I and in the disjunction $B_j \\lor \\dots \\lor B_t$, and 0 otherwise. Then computing $h_i$ corresponds to the evaluation of $I |= comp(R_{a_i})$. This can be generalized to the entire matrix.\nLet $h^1 = min_1(D(1 - min_1(Q(1 - w))))$, then the second part of the iff relation is simplified to dist(v, $h^1$)) = 0.\n*   If $I |= comp(P)$, then dist(v, $h^1$) = 0.\nSuppose $I |= comp(R_{a_i})$, then there is at least one rule body that is true in I, so $h_i = 1$. Otherwise, when we have $I \\not |= comp(R_{a_i})$, $h_i = 0$. Therefore, it holds that $h = v_i$, and since the index i is arbitrary, we have v = h, i.e., dist(v, $h^1$) = 0.\n*   If dist(v, $h^1$) = 0, then $I |= comp(P)$.\nConsider dist(v, $h^1$) = 0. For $h_i = 1$, there is at least one rule body that is true in I, and for $h_i = 0$, there is no rule body that is true in I. Since we have $v_i = h_i$, for $v_i = h_i = 1$, $a_i \\leftrightarrow \\forall R_j \\in heads(P,a_i) body(R_j)$ is satisfied and denote $I |= comp(R_{a_i})$, and for $v_i = h_i = 0$ denote $I \\not |= comp(R_{a_i})$. Since the index i is arbitrary, we conclude $I |= comp(P)$.\nThe vector $h^1 = min_1(D(1-min_1(Q(1-w))))$ serves as the head vector, which is an indicator vector representing true atoms following the evaluation of rule bodies in the logic program. This will be used later to define the loss function in Section 4.1.4. We note that while this paper computes supported models as the models of the completion formula, this can be viewed as an alternative formulation of the methods based on the immediate consequence operator $T_P$ in vector spaces [24, 2, 28]. Consider the equation in Proposition 1: given dist(v, $h^1$) = 0, we have v = $h^1$, which corresponds to the condition $T_P(I) = I$ [20].\n3.3 Embedding and Evaluating Constraints\nA constraint is a rule with an empty head, e.g., $\\leftarrow a \\land b$ represents a constraint where a and b must not both be true simultaneously. Since constraints are rules in a program, we embed them into a constraint matrix C in the same manner as the program matrix P. Note that we do not require the head matrix because constraints have empty heads.\nDefinition 5 (Constraint Matrix). Let $C = {C_1,...,C_k} = {\\leftarrow B_1,...,\\leftarrow B_k}$ be the set of constraints in a program P with $|B_P| = N$. Then the matrix corresponding to the constraints is $C \\in {0,1}^{(k \\times 2N)}$ such that i-th row corresponds to the body of the i-th constraint $C_i$: $C_{ij} = 1$ if $a_j \\in body^+(C_i), C_{i(N+j)} = 1$ if $a_j \\in body^-(C_i)$ and $C_{ij} = 0$ otherwise.\nTo evaluate the constraints, we check whether the bodies of the constraint rules are in I: given a constraint $R_i$, if $body(R_i) \\subseteq I$ then the constraint is violated; otherwise it is satisfied.\nProposition 2. (Evaluating Constraints) Let C be an embedding of constraints C, dist(,) be a distance function in a metric space, v be an interpretation vector representing $I \\subseteq B_P$, and w be its complementary interpretation vector. Then, for an interpretation vector v, it holds that $I \\not |= C \\text{ iff } dist(1, min_1(C(1 - w))) = 0$.\nProof. Proved similarly to Proposition 1. Let $c^1 = min_1(C(1 - w))$. Consider the i-th constraint $C_i$ and the corresponding row slice $C_{i:}$. The existence of at least one false literal in the body is computed by $c_i = min_1(C_{i:}(1 - w))$, where $c_i = 1$ if there is a false literal and $c_i = 0$ otherwise, i.e., when $c_i = 0$, the body is satisfied and the constraint is violated.\nSuppose $I \\not |= C_i$, then there is at least one false literal in the body of $C_i$, so $min_1(C_{i:}(1 - w))) = 1$. Repeat this for all $C_i \\in C$, we obtain a 1-vector, which means there is at least one false literal in the bodies of all constraints. By definition, dist(1, 1) = 0. The converse can be proved similarly.\nExample 3. Consider the constraint $\\leftarrow a \\land b$. Then we have:\nQ=\\begin{array}{c|cccccc} & a & b & c & \\neg a & \\neg b & \\neg c \\\n\\hline\nC_1 & 1 & 1 & 0 & 0 & 0 & 0\n\\end{array}\nWe examine two scenarios: in the first, the constraint is violated, and in the second, it is not. Let $c^1 = min_1(C(1 - w))$ and dist(,) denote the Euclidean distance, then, for the following cases,\n*   $v_{a,b} = (1 1 0)$: we obtain $c_{a,b} = (0)$, and dist(1, $c_{a,b}$) = 1, so we conclude that the constraint is violated.\n*   $v_{a} = (1 0 0)$: we obtain $c_{a} = (1)$, and dist(1, $c_{a}$) = 0, so we conclude $I |= C$."}, {"title": "4 Learning with Differentiable Logic Program", "content": "In this section, we show how the aforementioned differentiable logic program semantics can be used to train neural networks. Although our method supports both implication and constraint rules, it is not always necessary to use both of them for learning, as we shall show later in the experimental section. Specifically, for the NeSy tasks we studied, using exclusively either one of implication or constraint rules is enough to achieve competitive accuracy. On the other hand, in NeurASP [33] for example, the observation atoms are typically given as integrity constraints in ASP rules to compute stable models, and implication rules are defined similarly to ours. Consequently, we included a combination of both implication rules and constrains in our experiments to provide a thorough evaluation.\n4.1 Example: MNIST Addition\nThe MNIST digit addition problem [19] is a simple distant supervision task that is commonly used in neural-symbolic literature. The input consists of two images, and the output is their sum (e.g., 8 + 7 = 9). The goal is to learn digit classification from the sum of digits, rather than from images with individually labeled digits, as in the usual MNIST digit classification. For brevity, we shall focus on the single digit additions in this section.\nWe first introduce neural predicates [19], which act as an interface between the neural and logic programming parts. More concretely, a neural predicate is a predicate which can take references to tensorized objects as arguments. For example, in MNSIT Addition, we define two neural predicates, obs/4 and label/3. obs(i1, D1, i2, D2) represents a situation where images i1 and i2 were classified as digits D1 and D2 ranging from 0 to 9, respectively. label(i1, i2, S) represents the two images and their sum S ranging from 0 to 18. Thus, we obtain 100 obs and 19 label neural atoms.\n4.1.1 Implication rules\nIn general, we expect the label atoms to appear in the heads of the implication rules so that we can compare the output of the logic programming component with the label using a loss function such as binary cross entropy. For a single digit MNIST Addition, the label is the integer values between 0 and 18 represented by the label/3 predicate. As for the individual rules, we enumerate the possible combinations of digits that sum to the given label, e.g.,\nlabel(i1, i2,0) \u2190 obs(i1, 0, i2, 0).\nlabel(i1, i2, 1) \u2190 obs(i1, 0, i2, 1).\nlabel (i1, i2, 1) \u2190 obs(i1, 1, i2, 0).\nlabel (i1, i2, 18) \u2190 obs(i1, 9, i2, 9).\nIn this way, 100 rules with label/3 in the heads can be instantiated, which results in the embedded program $P_{impl.} = (Q_{impl.}, D_{impl.})$ where $Q_{impl.} \\in {0,1}^{(100\\times 200)}$ and $D_{impl.} \\in {0,1}^{(19\\times 100)}$"}, {"title": "4 Learning with Differentiable Logic Program", "content": "4.1.2 Constraints\nIn the case of MNIST Addition, constraints can be represented with smaller number of rules compared to the implication rules, e.g.,\n\u2190 label(i1, i2,0) ^ \u00acobs(i1, 0, i2, 0).\n\u2190 label(i1, i2, 1) ^ \u00acobs(i1, 0, i2, 1) ^ \u00acobs(i1, 1, i2, 0).\n\u2190 label(i1, i2, 18) ^ \u00acobs(i1, 9, i2, 9).\nIntuitively, one can read the first rule as \"when the label is 0, both of the digits must be 0\". This essentially amounts to enumerating all possible combinations of digits that sum to the label and adding them as negative literals to the rule bodies. Preparing constraints for each label results in a constraint matrix $C \\in {0,1}^{(19\\times 238)}$.\n4.1.3 Handling Neural Network Outputs\nHere, the outputs of the neural network combined with facts evident from the problem and labels are treated as a continuous interpretation. Facts evident from the problem refer to, for example, the three digits $(d_1, d_2, d_3)$ in the Apply2x2 task or the given digit number in the Member task. The details of the Apply2x2 and Member tasks will be explained later in the experiment section. The label information is also incorporated into this continuous-valued interpretation vector.\nDefinition 6 (Continuous-valued Interpretation Vector). Let $x \\in [0, 1]^N$ be the output passed through the last layer of the neural network. Let $f \\in {0,1}$ represent facts from the problem that are not dependent on NN's output, and $lb \\in {0,1}$ represent the label information available from the instance. If the number of elements in x, f or lb is less than N, pad appropriately with zeros. The continuous-valued interpretation vector z is computed as follows: $z = x + f + lb$.\nIn MNIST Addition, facts are not available from the problem settings, so we only focus on the neural network outputs and labels. In this task, the inputs to the (convolutional) neural network are two images (i1, i2). After passing through the Softmax activation, we obtain two output vectors $X_1, X_2 \\in [0,1]^{10}$ as (probabilistic) outputs. To map these vectors to 100 obs neural atoms, we compute their Cartesian product and obtain $x \\in [0, 1]^{100}: x = x_1 \\times x_2$. Depending on the problem, the dimension of the continuous-valued interpretation vector may be different for implication and constraints. In MNIST Addition, for implication rules it is not necessary to have label in the interpretation vector, as they are the heads of the rules. On the other hand, it is necessary to include label in the interpretation vector for evaluating constraints, as they are present in the rule bodies. It is imperative that the indexing remain consistent across all vectors and matrices; otherwise we risk neural network outputs being mapped to incorrect neural atoms.\nThe learning pipeline is shown in Figure 1. Firstly, the input images are classified using the CNN, and we associate its probabilistic output with neural atoms obs/4. Then, using the neural atoms and label information, we obtain the logical loss which can be used to train the CNN with gradient backpropagation."}, {"title": "4 Learning with Differentiable Logic Program", "content": "4.1.4 Loss Function\nUsing the embedded program, continuous-valued interpretation vector and label information, the loss function is defined as follows:\n$h = min_1 \\left(D(1 - min_1(Q(1 - w_z)))\\right)$\n$c' = 1 - min_1(C(1 - w_z))$\n$L = L_{impl.} + L_{cons.} = BCE(h, lb) + BCE(c', 0)$\nwhere BCE stands for binary cross-entropy, lb corresponds to the label vector, and 0 is a zero vector with the same dimension as c'. Note that $w_z$ here is the complementary interpretation vector based on the continuous-valued interpretation vector z which contains neural atoms, facts and labels: $w_z = [z; 1 - z]$. When the continuous valued interpretation vector is a binary one, h corresponds to the interpretation I. If all atoms that are supposed to be true in I are true, then the BCE loss will be 0. c' corresponds to an indicator vector for the violated constraints. Thus, c' should be all 0 when all constraints are satisfied. Combining the aforementioned BCE's, the loss function will be 0 iff all implied neural atoms are true, and all constraints are satisfied.\nThe difference between programs (6) and (7) lies in their structure: implication rules may contain label neural atoms in the head, whereas constraints always contain label neural atoms in the body. Implication rules present a more straightforward approach for representing partial information in the form of logical rules, especially in scenarios where employing intermediate predicates is necessary or enumerating constraints is time-consuming. In the context of the NeSy tasks examined in this study, we observed a consistent pattern where implication rules are typically comprised of straightforward forward inference rules, and constraints are formed from a fewer number of rules. Each of these constraints contains a label neural atom alongside a series of negated observation atoms in their body.\nBased on the definition of the combined loss function, it is clear that only one is necessary for accomplishing the MNIST Addition task. The first BCE is essentially the same as the one for a 19-label multiclass classification task (labels spanning from 0 to 18), while the second BCE corresponds to a multiclass classification with an all-0 label.\nThe evaluation of implication rules ensures that if the correct label's corresponding atom is derived as the head, $L_{impl.}$ becomes 0. Similarly, if all constraints are satisfied, then $L_{cons.}$ becomes 0. Since both the evaluation of implication rules and constraints are defined in a (almost-everywhere) differentiable manner, it is possible to train the neural network using this loss function through backpropagation."}, {"title": "5 Experiments", "content": "5.1 Task Description\nWe studied the learning performance on the following NeSy tasks.\nMNIST Addition [19]\nThe input consists of two MNIST images of digits (i1, i2), and the output is their sum (e.g., 8 + 7 = 9). The goal is to learn image classification from the sum of digits, rather than from images with individually labeled digits, as in the usual MNIST classification. This paper deals with two types: single-digit additions (two images), and two-digit additions (four images).\nADD2x2 [13]\nThe input is four MNIST images of digits (i11, i12, i21, i22) arranged in a 2x2 grid, and the output is four sums ($S_1, S_2, S_3, S_4$) calculated from each row and column of the grid (e.g., $\\begin{bmatrix} 0 & 1\\\\ 3 & 5 \\end{bmatrix}$, 0+1=1, 3+5=8). The goal is to learn the classification problem of MNIST images from the four sums provided as labels.\nAPPLY2x2 [13]\nThe input consists of three numbers $(d_1, d_2, d_3)$ and four handwritten operator images $(o_1, o_2, o_3, o_4)$ arranged in a 2x2 grid, with the output being the results $(r_1, r_2, r_3, r_4)$ of operations performed along each row and column of the grid. The operators are one of {+,-, \u00d7}. For example, the result for the first row is calculated as $r_1 = (d_1 o_{p11} d_2) o_{p12} d_3$ (e.g., 1, 2, 4, X, +, \u4e00,X, 6, -4, -2, 12). The goal is to learn the classification of handwritten operators from the four results and three numbers given as labels.\nMEMBER(n) [30]\nFor n=3, the input consists of three images (i1, i2, i3) and one number (d1), with the output being a boolean indicating whether d1 is included in the three images (e.g., 1, 9, 5, 4,0). For n=5, the input includes five images (i1, ..., i5). The goal is to learn the classification problem of MNIST images from the numbers provided as labels. This paper deals with two types: n=3 and n=5.\n5.2 Implementation and Experimental Setup\nThe methods introduced in the previous section were implemented in PyTorch. The convolutional neural network (CNN) used in the experiments is the same as those in [19] and [33]. The experimental environment is an AMD Ryzen 7950X (16c/32t), 128GB RAM, and an NVIDIA A4000 (16GB), with settings to utilize the GPU as much as possible. The number of training data was 30,000 and 15,000 for Addition 1 and 2, respectively, and 10,000 for other tasks. Unless otherwise noted, the number of epochs and batch size for all tasks were set to 1, and Adam was used with a learning rate of 0.001. Each experiment consisted of 5 repeated trials, and the average is reported. The timeout was set to 30 minutes per trial."}, {"title": "5 Experiments", "content": "5.3 Results\nTable 1 shows the dimensions of the program matrix P, head matrix"}]}