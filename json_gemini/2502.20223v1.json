{"title": "Deep Convolutional Neural Networks for Palm Fruit Maturity Classification*", "authors": ["Mingqiang Han", "Chunlin Yi"], "abstract": "To maximize palm oil yield and quality, it is essential to harvest palm fruit at the optimal maturity stage. This project aims to develop an automated computer vision system capable of accurately classifying palm fruit images into five ripeness levels. We employ deep Convolutional Neural Networks (CNNs) to classify palm fruit images based on their maturity stage. A shallow CNN serves as the baseline model, while transfer learning and fine-tuning are applied to pre-trained ResNet50 and InceptionV3 architectures. The study utilizes a publicly available dataset of over 8,000 images with significant variations, which is split into 80% for training and 20% for testing. The proposed deep CNN models achieve test accuracies exceeding 85% in classifying palm fruit maturity stages. This research highlights the potential of deep learning for automating palm fruit ripeness assessment, which can contribute to optimizing harvesting decisions and improving palm oil production efficiency.", "sections": [{"title": "1 Introduction", "content": "Palm fruit is a high economic value plantation crop and one of the most widely used vegetable oils. Its cultivation is an important strategic agricultural industry in some tropical countries, such as Egypt, Iran, and Indonesia. Crude palm oil accounts for 34.2% of the world's largest vegetable oil consumption due to its modifiable chemical composition and suitability in various food applications (Silalahi et al. 2016). There is a constant demand for the production of high-quality palm oil with lower production costs (Abdullah, Guan, and Azemi 2001). The quality of palm oil produced and the overall marketability depend heavily on the ripeness level of the palm fruit. One of the biggest challenges in the processing of fruits during oil production is the classification of fresh oil palm fruits for their maturity. Hence, to maximize the yield and quality of palm oil, it is crucial to harvest oil palms at their correct ripeness stage.\nThe conventional method for grading palm fruit maturity relies on manual detection, requiring experts to visually sort the fruit based on texture, shape, and color. However, this manual process is labor-intensive and inefficient, often leading to bias and human error. To enhance productivity, an automated harvesting system should be developed. Recently, some fruit harvesting robots have been introduced to improve yield and quality while reducing production costs and delays (Al-Janobi and Abdulwahed 2012). The key capability of these robots is their ability to interpret and analyze collected data. To achieve optimal performance, they must be equipped with an accurate sorting system that classifies and assesses fruit maturity in real time.\nThe practical success of designing such maturity sorting systems still requires further research due to the challenges posed by unstructured and unconstrained agricultural environments (Kapach et al. 2012). The most practical approach for an automatic system is to use an Artificial Intelligence system that can classify the ripeness of palm fruit from an image. In this study, we aim to develop a computer vision system to detect ripeness stages. This system, installed on a harvesting robot, can accurately analyze and classify fruits based on different types and ripeness levels in real time, providing references for decision-making.\nThe remainder of this paper is organized as follows. Section 2 reviews related work. Section 3 provides a detailed description of the proposed method. Section 4 presents the experimental results. Finally, Section 5 concludes the paper."}, {"title": "2 Related Work", "content": "Methods for Classifying Palm Fruit Ripeness\nTo ensure that the maximum amount of palm oil is extracted from the fruit, it is important to harvest it at the correct stage of ripeness. As the fruit enters the under-ripe stage, its oil content begins to increase. Ripe fruit has a reddish-orange color and, at the same time, the highest oil content. However, once the fruit becomes overripe, its fatty acid content starts to increase, reducing the oil quality. In recent years, various automated fruit grading systems have been proposed and tested. These methods can be classified into two categories. One approach relies on image processing techniques, which extract color features by preprocessing palm fruit images. The other employs CNNs, which automatically learn features from data.\nIn the traditional method, features from RGB and HSI color models are extracted from images and used as predictors for classification. Color histogram, color moment, and color correlogram (Sabri, Ibrahim, and Isa 2018) are derived from the original images as predictive features. RGB values"}, {"title": "Dataset", "content": "Although weaknesses exist in the previous work (Altaheri, Alsulaiman, and Muhammad 2019), the dataset used (Altaheri et al. 2019) is valuable and meaningful for palm research. To the best of our knowledge, this is the only publicly available dataset for palm fruit pre-harvesting and har-"}, {"title": "3 Proposed Method", "content": "This study explores three classification models for determining palm fruit maturity. The input consists of a stream of images captured by an RGB video camera in an orchard, as described in (Altaheri et al. 2019). The output is the predicted maturity stage of the palm fruit in each image. For"}, {"title": "CNN Deep Learning", "content": "Image classification is one of the core challenges in computer vision, with a wide range of practical applications. Significant attention has been given to neural networks, particularly CNNs. CNNs utilize deep convolutional layers and non-linearity to automatically learn local and spatial features directly from images, eliminating the need for manual feature extraction. However, CNNs typically require a large amount of labeled training data for learning weight parameters. Additionally, their high computational cost necessitates the use of powerful GPUs to accelerate the training process.\nA deep CNN architecture (Krizhevsky, Sutskever, and Hinton 2012) typically consists of five convolutional layers and three fully connected layers, followed by a softmax classifier, and contains more than 60 million parameters. Even deeper networks, which achieve better performance, contain even more parameters. Training such large models on small datasets can lead to severe overfitting, even when overfitting prevention techniques are applied.\nA common solution for training deep CNNs on small datasets is transfer learning, where the classifier layer of a pre-trained CNN is removed and fine-tuned on the target dataset. Transfer learning, which enables knowledge transfer from related tasks, has gained increasing attention in recent years. Several pre-trained CNN architectures have been proposed, including VGG, ResNet, Inception, and EfficientNet. In this study, we employ ResNet50 and InceptionV3, fine-tuning them on the palm fruit dataset for fruit maturity classification."}, {"title": "ResNet50", "content": "Instead of constructing a CNN from scratch, this study utilizes a pre-trained ResNet50 model. ResNet50 is a residual learning-based convolutional neural network with 50 layers. Residual learning has proven effective in addressing the vanishing gradient issue in very deep networks (those exceeding twenty layers) (Sha, Zandavi, and Chung 2019). Compared to other architectures, ResNet models offer an additional advantage: their performance does not degrade as the network depth increases. The architecture of ResNet is illustrated in Figure 2. The key innovation introduced by ResNet is the use of skip connections (shortcuts) to facilitate information flow across layers. ResNet begins with a single convolutional layer followed by max pooling. It then consists of four sequential layers, each with varying filter sizes, all utilizing 3 \u00d7 3 convolution operations. Additionally, after every two convolutional layers, a skip connection bypasses the intermediate layer, allowing the model to learn residual mappings instead of direct feature transformations. This concept defines the essence of ResNet models. These skipped connections, known as identity shortcut connections, are implemented using residual blocks. The residual block in ResNet is expressed as \\(H(x) = F(x) + x\\), where x is input layer, H(x) is output layer, and F(x) represents the residual mapping function. Residual blocks are effective when the input and output dimensions are identical, ensuring smooth information propagation. Each ResNet50 block consists of three layers. The initial layers of the ResNet architecture resemble those of GoogleNet, incorporating a 7 \u00d7 7 convolution operation followed by max pooling."}, {"title": "Inception V3", "content": "The GoogLeNet network introduced a novel approach by integrating multiple Inception modules to form a Network-in-Network topology, as illustrated in Figure 3. The resulting network consists of 22 layers and achieved a winning top-5 error rate of 6.66%. The significance of this architecture becomes evident when considering that it achieved such high accuracy with an order of magnitude fewer parameters compared to other models. The Inception module performs convolutions with multiple filter sizes on the input, applies max pooling, and concatenates the results before passing them to the next Inception module. A key innovation in this architecture is the introduction of 1 \u00d7 1 convolution operations, which significantly reduce the number of parameters, improving computational efficiency without sacrificing performance."}, {"title": "4 Experiments", "content": "We trained three models, a shallow CNN, ResNet50, and Inception V3, for the palm fruit ripeness classification task. We utilized pre-trained parameters of ResNet50 and InceptionV3 for transfer learning. All experiments were conducted on Google Colab using Python 3, as Google Colab provides free GPUs for training. The dataset was downloaded from IEEE DataPort, and all images were reorganized according to their ripeness levels. The dataset was then processed and prepared for CNN architectures using the following steps:\n\u2022 Zip the dataset and upload it to Google Drive.\n\u2022 Unzip the dataset on Google Colab for use in training."}, {"title": "Evaluation Metrics", "content": "The performance of the classification models was evaluated using accuracy (ACC), F1 score, confusion matrix, and the Area Under the Curve (AUC) of the Receiver Operating Characteristic (ROC) curve. Accuracy is defined in Equation (1):\n\\(ACC = TP/N\\) (1)\nwhere TP represents the number of correctly classified images, and N is the total number of images in the test dataset. The F1 score combines precision and recall into a single metric using the harmonic mean, where the best score is 1 and the worst is 0. F1 score is defined in equation (2). Precision measures the accuracy of positive predictions and is defined as TP/(TP + FP), where TP refers to a case that belongs to class x and is correctly predicted as x, while FP refers to a case that does not belong to class x but is incorrectly predicted as x. Recall measures the fraction of actual positive cases that are correctly identified and is defined as TP/(TP + FN), where FN refers to a case belonging to class x that is incorrectly predicted as another class. A confusion matrix provides insight into how well models distinguish between different classes, helping to identify which classes are most easily confused. For each model, we used sklearn.metrics to generate the confusion matrix and a classification report that includes precision, recall, and F1 score.\n\\(F1 score = \\frac{2 \\times (Recall \\times Precision)}{(Recall + Precision)}\\) (2)\nAn ROC curve (Altaheri et al. 2019) is a graphical representation of a classification model's performance across all classification thresholds. It visually illustrates model performance, while AUC (Area Under the Curve) quantifies the overall classification ability. AUC values range from 0 to 1, where AUC = 1 indicates a perfect model with 100% correct predictions, and AUC = 0 represents a completely incorrect model with 100% misclassifications. AUC is desirable because it is scale-invariant and classification-threshold-invariant. The ROC curve is generated using the true positive rate (TPR) and false positive rate (FPR). Both micro-average and macro-average methods were used to compute AUC values in our evaluation."}, {"title": "Baseline Model", "content": "A classifier based on a simple CNN architecture was trained as our baseline model. This model consists of two convolutional layers, each followed by MaxPooling2D and Dropout"}, {"title": "ResNet50 Model", "content": "The ResNet50 model was selected as one of the deep CNN architectures for our classification task. We imported the pre-trained ResNet50 model from Keras applications and applied the following fine-tuning settings:\n\u2022 weights='imagenet' The model utilized the weights learned from training on the ImageNet dataset.\n\u2022 include_top=False \u2013 This allowed us to customize the input and output layers according to our dataset."}, {"title": "Inception V3 Model", "content": "The InceptionV3 architecture was another model fine-tuned for the palm bunch maturity classification task. The pre-trained model was imported from Keras applications, utilizing pretrained parameters from the ImageNet dataset. We followed a process similar to the ResNet50 model, modifying only the input and output layers to fit our dataset. After flattening the pre-trained Inception V3 layers, we added a dense output layer with five units and a softmax activation function to compute the multinomial probability distribution for the five maturity classes.\nThe model was trained using the same dataset split settings. It was optimized using Adam, with a learning rate of 0.0001, and categorical cross-entropy as the loss function. After 40 epochs, it achieved an accuracy of 100% on the training set and 85.24% on the test set. The performance of this model was fairly strong for the classification task. As shown in Figure 5(c) the F1 scores for all classes were above 0.8, except for the medium-ripe class. The confusion matrix exhibited a pattern similar to the ResNet50 model, where a large number of under-ripe palm bunches were misclassified as medium-ripe. Similar to the ROC curve of the ResNet50 model, shown in Figure 6(c), the AUC values for this model were also very close to 1, further indicating its effectiveness in palm bunch maturity classification."}, {"title": "Comparisons of Models", "content": "The summary of accuracy, AUC, and F1 score using different methods for the baseline model, ResNet50, and InceptionV3 is presented in Table 1. The highest values among the three models for different methods or classes are highlighted in grey. ResNet50 outperformed the other models in most evaluation metrics. Although Inception V3 achieved the highest AUC for the unripe class and the highest F1 scores for the ripe and unripe classes, its overall performance was not significantly better than that of ResNet50.\nFigure 7 illustrates the training and validation loss and accuracy trends for the baseline model, ResNet50, and InceptionV3 during training. The baseline model exhibited a slow decrease in loss, with validation accuracy peaking at approximately 70% after 15 epochs and stabilizing thereafter. For the InceptionV3 model, the loss decreased the fastest, but validation accuracy stabilized after just 10 epochs. The training accuracy reached 100% within a few epochs, yet the test accuracy remained around 80%, indicating a clear overfitting problem. The ResNet50 model also showed a rapid decrease in loss, with validation accuracy stabilizing after six epochs. Throughout training, the accuracy difference"}, {"title": "5 Discussion and Conclusion", "content": "A machine vision framework for palm fruit maturity classification was proposed based on deep learning. A shallow CNN was used as the baseline model, while transfer learning with fine-tuning was applied to the classification task. Two pre-trained CNN models, ResNet50 and InceptionV3, were investigated. The study utilized a published dataset designed with a high degree of variation to reflect the challenges present in natural environments and fruit orchards. The best accuracy was achieved by the fine-tuned ResNet50 model, which attained 86.41% for maturity classification.\nThis study demonstrated that a pre-trained CNN could achieve robust fruit classification without the need for image preprocessing to remove background noise or enhance illumination. By leveraging pre-trained models, high classification accuracy can be obtained within a few training epochs, as the feature extraction process is already well-optimized by the original architecture. However, further research is necessary. EfficientNet, another pre-trained model, was originally included in our study. Despite extensive parameter tuning and multiple training attempts, we observed that while training accuracy was very high, test accuracy remained below 50%. Future work should investigate the reasons behind this poor generalization and explore ways to enhance its performance. Additionally, the maturity stages of palm fruit are influenced by fruit type. To improve classification performance, a type classification task will be incorporated to mitigate errors caused by different palm fruit varieties."}]}