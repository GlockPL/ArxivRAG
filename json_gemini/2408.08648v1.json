{"title": "Understanding Enthymemes in Argument Maps:\nBridging Argument Mining and Logic-based Argumentation", "authors": ["Jonathan Ben-Naim", "Victor David", "Anthony Hunter"], "abstract": "Argument mining is natural language processing technology aimed at identifying arguments in text.\nFurthermore, the approach is being developed to identify the premises and claims of those arguments,\nand to identify the relationships between arguments including support and attack relationships. In this\npaper, we assume that an argument map contains the premises and claims of arguments, and support and\nattack relationships between them, that have been identified by argument mining. So from a piece of\ntext, we assume an argument map is obtained automatically by natural language processing. However,\nto understand and to automatically analyse that argument map, it would be desirable to instantiate that\nargument map with logical arguments. Once we have the logical representation of the arguments in an\nargument map, we can use automated reasoning to analyze the argumentation (e.g. check consistency\nof premises, check validity of claims, and check the labelling on each arc corresponds with the logical\narguments). We address this need by using classical logic for representing the explicit information in the\ntext, and using default logic for representing the implicit information in the text. In order to investigate\nour proposal, we consider some specific options for instantiation.", "sections": [{"title": "1 Introduction", "content": "Argument mining aims to identify the parts of text that represent arguments (premises and/or claims), and\nthe support or attack relationships between those arguments [LR19]. Using a range of natural language\nprocessing (NLP) technology, with increasing emphasis on large language models, they can be trained to\nidentify arguments and relationships between them with increasing accuracy. The resulting information can\nthen be represented by an argument graph or argument map, where each node contains the text representing\nthe premises and claim of the argument, and each arc denotes a relationship (such as positive/support,\nor negative/attack) between arguments, as illustrated in Figures 1 and 2. In this paper, we assume the\ndifference between an argument graph and argument map is the latter distinguishes between the premises\nand the claim of each argument.\nWhilst argument graphs and maps provide a useful visualizable summary of argumentation in text, there\nis then a lack of automated methods for analysing or reasoning with the information in the argument map.\nTo address this shortcoming, it would be desirable to translate the text into logical arguments, and then\nuse automated reasoning to analyze the arguments (e.g. check consistency of premises, check validity of\nclaims, and check the labelling on each arc corresponds with the logical arguments assigned to the abstract\narguments in the map). Unfortunately, there is a lack of a formal representational framework for bridging\nargument maps and the underlying logical arguments. So this gives us the first problem that we tackle in\nthis paper:\n(Problem 1) How can we represent the explicit information in an argument map, and then\nrepresent that explicit information in a logical rendition of the arguments?\nTo address these two questions in this paper, we start from the assumption that each premise, and\neach claim, is a string of text, such as a phrase, a sentence, or a paragraph. If the premise or claim is\nimplicit, then we use the Null value. We then assume a function that can translate each piece of text into a\nformula of classical logic, where the formula is an atom, a propositional formula, or a first-order formula,\ndepending on the nature and granularity of translation. We use classical logic because it has a clear syntax\nand semantics for representing and reasoning with information. Then, for each argument we use default\nlogic (which we introduce in the next paragraph) for connecting each claim with its premise, and each\nargument with the arguments it supports or attacks.\nDefault logic was developed as a formalism for commonsense reasoning. It extends classical logic with\ndefault rules [Rei80]. Default rules are a generalization of natural deduction rules. They provide a clear"}, {"title": "2 Translation of explicit premise and claim into logic", "content": "We assume the usual propositional and predicate (first-order) languages for classical logic. Let A be the set\nof ground atoms (i.e. propositional atoms and positive ground literals). Let P be the set of propositional\nformulae composed from atoms A and the logical connectives ^, V, \u00ac. Let F be the set of first-order\nformulae composed from a set of function symbols, predicate symbols, the logical connectives A, V, \u00ac,\nand the quantifiers \u2200 and \u2203. Since we are often indifferent as to whether we use the propositional or first-\norder language, we use L to denote a language that can be either a propositional or first-order language. In\nthe examples, we will use teletype font for the logical formulae."}, {"title": "2.1 Argument maps", "content": "We assume an argument map is obtained as output from argument mining of a text (e.g. a discussion doc-\nument). Each node denotes an argument (often with some/all of the premises and/or claim being implicit).\nOften the text in a node appear as a statement rather than a complete argument since either the premises or\nclaim are implicit. We represent an argument map as a tuple as follows.\nDefinition 1. Let T be a set of text strings. An argument map is a tuple (N, P, C, L) where N is a set\nof nodes; P: N \u2192 T\u222a {Null} is a text labelling function for premises; C: N \u2192 T\u222a {Null} is a\ntext labelling function for claims; And L : N \u00d7 N \u2192 {+,-,\u25a1} is an arc labelling function, where +"}, {"title": "2.2 Logical translation", "content": "Given an argument map, we want to represent each of the premise and the claim by a set of formulae\nof classical logic. The following definition of translation function is a key step in bridging the output of\nargument mining (i.e. the text-based annotation of argument maps) and a logic-based representation of the\nargument map.\nDefinition 2. Let T be a set of text strings. A logical translation is a function T : T\u222a {Null} \u2192 \u2119(L)\ns.t.\u00b2 T(Null) = \u00d8.\nIf there is no text string (i.e. Null), then the translation is \u00d8 (i.e. tautology) which represents no useful\ninformation.\nExample 1. Containing Example 2, the following logical translation T is listed for the text string for each\npremise and claim. In this example, each text string is assigned an atom in the logical language.\n\nThe following are some types of translation, where the first is the most abstract and the simplest to\nimplement, and the third is the least abstract of the three, and it is the most difficult to implement.\nAtomic translation. The logical translation is a set of propositional atoms. So each text string is assigned\nan atom (as illustrated in Example 1). This allows for different ways that a claim is expressed in\ntext being assigned to the same atom (as illustrated in Example 2). This can be implemented by\na text string classifier where each string is assigned an atom that denotes its class. Assignments\ncan group similar text items to the same atom as in intent classification [GTF+23] or key point\nanalysis [BEK+21]. Also, in an argumentative chatbot system, sentence embeddings have been used\nto classify a user input as to being one of around 1500 arguments in an argument graph in order to\nidentify a counterargument to be given by the chatbot [CH20]."}, {"title": "3 Review of default logic", "content": "We use \u03b1, \u03b2, \u03b3, \u03b4, \u03c6, \u03c8, ... for arbitrary formulae and \u0394, \u0393,... for arbitrary sets of classical formulae.\nWe let \u22a2 denote the classical consequence relation, and write \u0394 \u22a2 \u03c6 to denote that \u0394 is inconsistent.\nAtoms(\u0394) gives the atoms appearing in the formulae in \u0394. Let Cn be the consequence closure function\n(i.e. Cn(\u0394) = {$ | \u0394 \u22a2 $}). For \u03c6, \u03c8 \u2208 L, \u03c6 = \u03c8 denotes that \u03c6 and \u03c8 are equivalent (i.e. {\u03c6} \u22a2 \u03c8 and\n{\u03c8} \u22a2 \u03c6). For \u0394, \u0393 \u2286 L, \u0394 \u22a8 \u0393 denotes that \u0394 and \u0393 are equivalent (i.e. Cn(\u0394) = Cn(\u0393)).\nAs a basis of representing and reasoning with default knowledge, default logic, proposed by Reiter\n[Rei80], is one of the best known and most widely studied formalisations of default reasoning. Furthermore,\nit offers a very expressive and lucid language."}, {"title": "3.1 Types of default theory", "content": "There are various special cases of default rules that will be useful for our purposes. These include the\nfollowing.\n\u2022 Precondition-free default rule. This is a default rule of the form \u22a4: \u03b2/\u03b3 and so the consequent is\nobtained as long as the justification is satisfiable. For example, we might use the following default\nrule to capture the reasoning that anything that is unbroken is usable.\n\u22a4:\u00acbroken(X)/useable(X)\n\u2022 Justification-free default rule. This is a default rule of the form \u03b1 : \u22a4/\u03b3 and so the consequent is\nobtained as long as the precondition holds, and so there is no block by the justification. This would\nmean that we assume that there are no exceptions. For example, we might use the following default\nrule to capture the reasoning that anything that is divisible by two is even.\ndivisablebytwo(X):\u22a4/even(X)\n\u2022 Normal default rule. This is a default rule of the form \u03b1 : \u03b2/\u03b2 and so the consequent is obtained\nwhen the precondition holds, and the consequent is satisfiable. For example, we might use the\nfollowing default rule to capture the reasoning that if it is consistent to believe that someone has no\nbrother, then we infer they have no brother.\nperson(X):\u00achasBrother(X)/\u00achasBrother(X)\n\u2022 Semi-normal default rule. This a default rule of the form \u03b1: \u03b2\u2227 \u03b3/\u03b3and so the consequent is ob-\ntained when the precondition holds, and the justification which includes the consequent is satisfiable.\nFor example, we might use the following default rule to capture that a bird flies if it is consistent to\nbelieve that it flies and that it is not a penguin (as we used in Example 5).\nbird(X):penguin(X) \u2227 fly(X)/fly(X)\nFor more coverage of default logic, see [Bes89, Bre91, BDK97]. There are algorithms for automated\nreasoning with default logic [BQQ83, RS94], and scalable implementations of default logic [TDJ22]. Also,\na default theory can be translated into an answer set program (ASP) and an ASP solver used to automate\nthe reasoning [CWZZ10]."}, {"title": "3.2 Singular default theories", "content": "In the next section, we use default logic in our definition for default arguments. For this, the only restriction\nis that the default rules in the premises give a unique extension, and for this we introduce the following\nsubsidiary definition."}, {"title": "4 Default arguments", "content": "We use the singular criteria (Definition 4) in the following definition of a default argument to ensure that\nthe implicit premises (respectively implicit claim) give a single perspective on the explicit premises (re-\nspectively explicit claim). The definition is very general, and we will consider constraints on this definition\nin order to give us appropriate notions of logical argument.\nDefinition 5. A default argument is a tuple (WP, DP, WC, DC) where WP, WC \u2286 L, and DP, DC \u2286 D\ns.t. (DP, WP) is singular and (DC, WC) is singular.\nFor a default argument A = (WP, DP, WC, DC), we refer to WP as the explicit premises, DP as the\nimplicit premises, WC as the explicit claims, and DC as the implicit claims. To extract these components\nof a default argument A, we use the following functions: Ep(A) = WP; Ip(A) = DP; Ec(A) = WC; and\nIc(A) = DC.\n\nAs we will explore in the rest of this paper, a default argument provides a richer representation of\nan argument than available with other approaches to structured argumentation. This includes the follow-\ning features which go beyond other formalisms for logic-based argumentation: Delineatation of implicit\ninformation connecting premises and claims: The set DP is a set of defaults that represents the im-\nplicit information in the premises; Logical mechanism for disabling connection between premises and\nclaims: The justification of each default rule can be negated by the claim of another argument, thereby\nattacking the connection between the premise and claim; Delineatation of implicit information connect-\ning one argument with another: The set DC is a set of defaults that represents the implicit information\nin the claim; Logical mechanism for disabling connection between one argument and another: The\njustification of each default rule can be negated by the claim of another argument, thereby attacking the\nconnection between that argument and other arguments.\n\nLet R be the set of all possible default rules. The set of default arguments from a set of default rules\n\u03a0 \u2286 R is Arguments(II) = {(WP, DP, WC, DC) | WP, WC \u2286 L and DC, DC \u2286 \u03a0}. Using default logic"}, {"title": "5 Relationships between arguments", "content": "We now consider how one default argument supports or attacks another default argument. For this, we will\nrequire some subsidiary definitions. The first is to identify the justifications that arise in the default rules in\nthe premises of an argument using the following definition for the premise justification function, where\nA is an argument.\nJp(A) = {\u03b2 | \u03b1 : \u03b2/\u03b3 \u2208 Ip(A)}\n\nWe also require the following variants of the S and C functions. For any default argument A, C\u2217(A) =\nC(A) \\ Cn({\u22a4}) and S\u2217(A) = S(A) \\ Cn({\u22a4}). We use C\u2217(A) and S\u2217(A) instead of C(A) and S(A) as\nwe want to avoid trivial support involving tautologies.\nWe define the following notions of support relation that hold between a pair of default arguments.\nWhilst there are further kinds of support that we could define, we start with these intuitive options. Es-\nsentially, we restrict the definitions to comparing the explicit claim or consequence (i.e. extension of the\nimplicit and explicit claims) of a supporting argument A (i.e. Ec(A) or C(A)), and the explicit premises,\nor support (i.e. extension of the implicit and explicit premises), or justification, of the supported argument\nB (i.e. Ep(B), or S(B), or Jp(B)), and we restrict the comparison between the supporting and supported\narguments to an intersection between the respective sets of formulae.\nDefinition 8. For default arguments A and B, the following are types of support.\n\u2022 A inferentially supports B iff S\u2217(B) \u2229 C\u2217(A) \u2260 \u2205.\n\u2022 A directly supports B iff Ep(B) \u2229 C\u2217(A) \u2260 \u2205.\n\u2022 A explicitly supports B iff Ep(B) \u2229 Cn(Ec(A)) \u2260 \u2205.\n\u2022 A justification supports B iff Jp(B) \u2229 C\u2217(A) \u2260 \u2205.\nWe explain the above definitions as follows and provide an example below: Inferential support ensures\nthat there is a consequence of A that is a support in B; Direct support ensures that there is a consequence of\nA that is an explicit premise in B; Explicit support ensures that the explicit claim in A implies an explicit\npremise in B; And justification support ensures that there is a consequence of A that is a justification in the\nimplicit premises in B.\nDefinition 9. For default arguments A and B, the following are types of support.\n\u2022 A strongly inferentially supports B iff A inferentially supports B and S(B) \u2286 C(A).\n\u2022 A strongly directly supports B iff A directly supports B and Ep(B) \u2286 C(A).\n\u2022 A strongly explicitly supports B iff A explicitly supports B and Ep(B) \u2286 Cn(Ec(A)).\n\u2022 A strongly justification supports B iff A justification supports B and Jp(B) \u2286 C(A).\nNow we turn to notions of attack from one argument on another. We use the following definition of\nattacks for a default argument A on default argument B which essentially specifies attack as being an\ninconsistency between the claim of the attacker and either the support or claim of the attackee. Another\nkind of attack involves inconsistency between the support of an argument and the justification of the the\nother argument. In this attacker, the attacker negates the justification of the attackee, and thereby presents\na reason to block the use of the default rule.\nDefinition 10. For default arguments A and B, the following are types of attack.\n\u2022 A support attacks B iff C(A) \u222a S(B) \u22a2 \u22a5.\n\u2022 A consequence attacks B iff C(A) \u222a C(B) \u22a2 \u22a5.\n\u2022 A justification attacks B iff C(A) \u222a Jp(B)) \u22a2 \u22a5."}, {"title": "6 Bridging framework", "content": "Now we can address the need to bridge argument maps and logic-based argumentation by producing instan-\ntiated argument maps. The first part of this bridging is the logical translation of premises and claims into\nlogical formulae using a translation function (as discussed in Section 2). The second part of the briding is\nthe instantiation by the logical argument assignment function defined below. This simply assigns a default\nargument to each node in the argument map.\nDefinition 14. Let M = (N,P,C, L) be an argument map and let A be a set of default arguments. A\nlogical argument assignment for M is a function I : N \u2192 A.\nWe give examples of logical argument assignments in Examples 29 to 32. We give further examples in\nFigure 14 and Figure 15."}, {"title": "7 Literature review", "content": "In this section, we consider our proposal for instantiated argument maps with developments in abstract\nbipolar argumentation, structured argumentation including approaches using default logic, and formalisms\nfor handling of enthymemes."}, {"title": "7.1 Bipolar argumentation", "content": "Bipolar argumentation is a generalization of abstract argumentation that incorporates a support relation in\naddition to the attack relation [CL05a, CL05b, ACLL08, CL13]. A bipolar argument graph is a directed"}, {"title": "7.2 Structured argumentation", "content": "Our proposal goes beyond existing proposals for structured argumentation. In Section 4, we have shown\nhow we can capture classical logic deductive arguments as default logic. It is then straightforward to"}, {"title": "7.3 Handling enthymemes", "content": "Most proposals for handling enthymemes in the compuptational argumentation literature either focus on\nthe coding/decoding of enthymemes via abduction [Hun07, BH12, HMR14], and how this can be under-\ntaken within a dialogue [BH08b, dS11b, dS11a, XHMB20, PMB22, LGG23]. For instance, dialogues can\nbe shown to shorter when using enthymemes [PMB22]. However, these proposals do not provide a sys-\ntematic framework for translating argument maps into logic, and concomitantly, addressing the problem of\nidentifying the missing premises and/or claim, and discerning the relationships between them.\nAnother important aspect of dealing with enthymemes is the uncertainty that arises from decoding.\nWhen an audience is listening to participants in a discussion or debate, the participants present arguments\nincluding enthymemes. The way these are presented gives some idea to the audience of which are meant\nto attack which. However, if an argument being attacked is an enthymeme, and the attacking and attacked\narguments are from different participants, then there is uncertainty about whether it is indeed a valid attack.\nEach enthymeme is a representative for an intended argument, but for the audience it may be uncertain\nwhich decoding is the intended argument. The audience may have zero or more choices. This means that\nthe audience takes an argument graph as input, and tries to determine the intended argument graph (i.e. the\ngraph obtained by instantiating each node with its intended argument and deleting the arcs that are not valid\nattacks). This intended argument graph has a structure that would be isomorphic to a spanning subgraph\nof the original argument graph. One way to model this uncertainty is to use the constellations approach\nto probabilistic argumentation, where a probability distribution over these graphs is used to reflect the\nuncertainty [Hun13]. However, this assumes that the graph contains abstract arguments. Another approach"}, {"title": "7.4 Translating text into logic", "content": "Within the NLP community, there has always been interest in technology for translating free text into\nformal logic. In the past, use of approaches such as phrase-structure grammars, allows for translation of\nfragments of natural language into logic, but it is only with the advent of deep leanring and large language\nmodels that it appears more general, robust, and scalable, methods can be developed for translating natural\nlanguage into logic. Preliminary investigations using deep learning include [SAK20, LL21] and using\nLLMs include [LLG+22, PAWW23, OGL+23, LCH+24].\nAnother approach is to use abstract meaning representation (AMR) as a semantic representation of a\nsentence as a directed graph. The aim of AMR is that the graph reflects the content of a sentence in terms of\nthe actors, and their roles, in the sentence, rather than a complete coverage of the grammar of the sentence\n[LK98]. So it is intended that sentences that are grammatically different but the same or similar semantics\nare represented by the same AMR graph. By drawing on LLMs, some AMR parsers offer a general, robust,\nand scalable approach to generating AMR graphs from a wide variety of text (e.g. [LAF+23]). Once, an\nAMR graph has been obtained from free text, a logical formula can be obtained which can be reasoned\nwith using neurosymbolic approach [CH23, FH24].\nFinally, a recent proposal for analysing enthymemes draws on the semi-formal approach of argument\nschema [RTLR24]. First, a dataset has been synthetically generated using large language models (GPT3.5\nand GPT 4) where the model is prompted to fill out an argument scheme from a selection of 20 schema.\nThen, fine-tuned Roberta models were developed for classification of free text arguments according the type\nof argument scheme. Whilst, this proposal does not produce logical arguments, it could be harnessed as part\nof process of producing logical arguments. This dataset has also been used in developing a reinforcement\nlearning approach for classifying free text arguments according the type of argument scheme using Mistral\n[TEB+24]."}, {"title": "8 Discussion", "content": "In the real-world, arguments are often enthymemes (i.e. arguments with some premises being implicit).\nThe missing premises have to be abduced by the recipient. These may be obtained from contextual and\nbackground knowledge, and more challengingly, common-sense knowledge. We need to understand en-\nthymemes if we want to make sense of them or respond to them. If we don't understand an enthymeme\nproperly, we can have misunderstandings, and we can talk at cross-purposes.\nArgument mining find sentences representing premises and claims. But there is a lack of a framework\nto then identify the underlying logical arguments. We have addressed this shortcoming by providing the"}]}