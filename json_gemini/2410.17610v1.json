{"title": "IMDY: HUMAN INVERSE DYNAMICS FROM IMITATED OBSERVATIONS", "authors": ["Xinpeng Liu", "Junxuan Liang", "Zili Lin", "Haowen Hou", "Yong-Lu Li", "Cewu Lu"], "abstract": "Inverse dynamics (ID), which aims at reproducing the driven torques from human kinematic observations, has been a critical tool for human motion analysis. However, it is hindered from wider application to general motion due to its limited scalability. Conventional optimization-based ID requires expensive laboratory setups, restricting its availability. To alleviate this problem, we propose to exploit the recently progressive human motion imitation algorithms to learn human inverse dynamics in a data-driven manner. The key insight is that the human ID knowledge is implicitly possessed by motion imitators, though not directly applicable. In light of this, we devise an efficient data collection pipeline with state-of-the-art motion imitation algorithms and physics simulators, resulting in a large-scale human inverse dynamics benchmark as Imitated Dynamics (ImDy). ImDy contains over 150 hours of motion with joint torque and full-body ground reaction force data. With ImDy, we train a data-driven human inverse dynamics solver ImDyS(olver) in a fully supervised manner, which conducts ID and ground reaction force estimation simultaneously. Experiments on ImDy and real-world data demonstrate the impressive competency of ImDyS in human inverse dynamics and ground reaction force estimation. Moreover, the potential of ImDy(-S) as a fundamental motion analysis tool is exhibited with downstream applications.", "sections": [{"title": "INTRODUCTION", "content": "The rapid progress in human motion capture based on computer vision has made an enormous amount of human motion data available to the research community. The accumulation of human motion manages to push motion understanding forward in various tasks, including behavior understanding and character animation . However, given the vision-based nature, most current efforts focus only on visible kinematics information. The invisible factors, especially the dynamic factors, which could carry deeper insights into the underlying production mechanism of human motion, are typically overlooked, such as driven torques and ground reaction forces. This limits the current motion understanding algorithms from wider applications to domains where physical constraints must be seriously considered, such as robotics, healthcare, and sports training. To alleviate this, we focus on identifying the driven torques and ground reaction forces for human motion from pure kinematics MoCap data, known as human inverse dynamics (ID).\nHuman inverse dynamics, as a basic step toward physical motion modeling, has been extensively discussed by the biomechanics community for applications like gait analysis. A fundamental obstacle is that it could not be measured non-intrusively. Therefore, computationally expensive optimization-based methods are widely adopted and mature software is developed. However, accurately measured ground reaction forces are required to ensure a determinate solution, which could be expensive and applicable only in restricted laboratory settings. Also, the optimization process could be sensitive to small disturbances in either motion capture noises or subject variances."}, {"title": "BACKGROUND", "content": "Conventional Inverse Dynamics. Inverse dynamics, known as inferring forces/moments from kinematic observations, have been discussed for long in the biomechanics community. In this literature, it is formulated as an optimization problem: given a representative model of a subject, the joint kinematics over time w.r.t. the subject model, and the external forces imposed on the subject, find the driving torques that produce the observed motion . The Newtonian dynamic equations are involved as\n$M(q)\\ddot{q}+C(q, \\dot{q}) + G(q) = J\\lambda + \\tau$,\nwhere $M(q)$ is the generalized human inertia matrix w.r.t. generalized coordinate q, $C(q, \\dot{q})$ is the Coriolis and centrifugal forces, $G(q)$ represents gravity, $J$ is the Jacobian matrix mapping external forces $\\lambda$ to the generalized coordinates. Thus, the driven torques $\\tau$ could be obtained by minimizing the difference between the left and right terms of Eq. 1. Mature software based on this has been developed like OpenSim , AnyBody , and Nimble . In addition, many efforts are made for clinical motion analysis . However, these efforts are not as extensively recognized by the computer vision and computer graphics community as expected due to the scalability issue. Despite the elegant formulation, the efficacy of optimization-based heavily relies on the quality of external force  (like GRF) measurement, whose cost could be non-trivial. Therefore, most of them focused on limited motion in laboratory settings. Some resort to wearable devices to partially mitigate the limitation. In addition, fitting the raw captured kinematic observations to a specific human model for joint kinematics could be time-consuming and unstable, even with recent progress on it.\nLearning-based Inverse Dynamics. With the progress in deep learning, there have been efforts to adopt neural networks to address the human ID problem. Many efforts focus on lower-body-only  or upper-body-only inverse dynamics. More recently, collected over 1 hour of motion with an optical MoCap system, four force plates, and a pair of pressure insoles. The ground truth was obtained through optimization and a Gaussian mixture framework was devised. introduced a predictive dynamics-based human modeling for the acquisition of ground truth. Hundreds of motions were collected and different data-driven techniques were adopted for joint torque regression. proposed a weakly supervised method based only on motion for gait analysis. These efforts were constrained by costly data acquisition in real-world scenarios, resulting in limited data scale. Very recently, aggregated multiple existing biomechanics datasets, considerably boosting the data scale. However, most of the collected sequences contained only regular exercise motion with limited diversity. Some efforts focused on ground reaction forces. Some recent works incorporated inverse dynamics into vision-based markerless MoCap systems. simultaneously captured motion and joint torques with customized fully differentiated pipelines. A series of works imitated the captured motion in physical simulators with PD controllers and obtained the torques. However, an inherent problem is the amplification effect from kinematic errors to dynamic errors. As measured by , only a 2-cm uncertainty of marker placement in a marker-based MoCap system could result in a peak ankle plantarflexion moment of 26.6 N m. Considering the precision of current markerless MoCap algorithms, the accuracy of the accompanied inverse dynamics could be questionable. Also, among all these efforts for learning-based inverse dynamics, only a few  were quantitatively evaluated with limited locomotion data. A scalable benchmark for learning-based inverse dynamics is still not available.\nMotion Imitation. IL for human motion replicates recorded human motion sequences with physically controlled simulated characters, which could be inherently close to ID. Most early efforts focus on specified usages with limited generalizability. With residual force control , which imposed supernatural forces at the root joint of the humanoid, generalized to 97% sequences in AMASS . eliminated the supernatural root force and achieved a 98.9% success rate on AMASS with fall-state recovery. The progress in human motion IL makes it possible to collect human-like motions with full dynamics, shedding new light on the scalable human ID data collection."}, {"title": "CONSTRUCTING IMITATED DYNAMICS", "content": "ImDy aims to exploit the inherent closeness of inverse dynamics and imitation learning. Generally, the inverse dynamics (ID) and imitation algorithms (IL) could be abstracted as\n$\\tau = ID(s_t, s_{t+1}), \\qquad \\tau = IL(s_t, s^i_{t+1}),$\nwith driven torque $\\tau$, timestamp t, observed kinematic states $s_t$, and the state to imitate $s^i_t$. Both ID and IL learn the dynamic production mechanism of human motion. However, IL algorithms are not directly applicable to ID due to the non-equivalence between $s_{t+1}$ and $s^i_{t+1}$. The errors in kinematics could be magnified in dynamics . This also makes ID algorithms that are deeply coupled with markerless MoCap less reliable. However, it is possible to extract knowledge from IL for ID. In this section, we introduce a simple but effective ID data collection pipeline with IL algorithms. First, the adopted IL algorithm is briefly covered in Sec. 3.1. Then, the data collection pipeline is introduced in Sec. 3.2.\n3.1 IMITATION LEARNING BASICS\nA motion imitator $\\pi(a_t|s_t, s^i_t)$ is trained following to solve the Markov Decision Process $M = (T, S, A, R, \\gamma)$. The transition dynamics T and states S are governed by the physics simulator. For each timestamp t, the policy $\\pi$ produces action $a_t \\in A$ and the reward R, based on state s \u2208 S. The training goal is maximizing the reward expectation $E(\\sum_{t=1}^T \\gamma^{t-1}R_t)$.\nTransition. IsaacGym is adopted for simulation. A 24-joint humanoid with SMPL kinematics and physical properties following  is adopted with variable shape parameter $\\beta \\in \\mathbb{R}^{10}$. Thus, a human pose at timestamp t could be defined as $q_t = {\\Theta_t, p_t}$, where $\\Theta_t \\in \\mathbb{R}^{J \\times 6}$ is the joint rotation in the 6d representation and $p_t \\in \\mathbb{R}^{J \\times 3}$ is the 3D joint position.\nState. At timestamp t, $s_t$ contains the observed $s_t^o$ and $s^i_{t+1}$ to imitate. $s_t^o$ is defined in simulator as $s_t = (q_t, \\dot{q_t}, \\beta)$ with 3D body pose $q_t$, velocity $\\dot{q_t}$, and body shape $\\beta$. $s^i_{t+1}$ is defined similarly except that it is the reference motion with finite-differentiated velocities.\nAction. All joints but the pelvis are actuated with proportional derivative (PD) controllers, with $a_t$ as the PD target. The torque applied could be calculated as\n$\\tau^t = k_p \\circ (a^t - q^t) - k_d \\circ \\dot{q}^t$.\nReward. The reward is composed of four terms: motion imitation reward for minimizing the difference between the imitated states and the expected states, fail-state recovery reward , AMP reward , and energy reward to reduce jittering.\nTraining. Following PHC, three primitive policies are progressively trained with hard negative mining, two for pure motion imitation, and one for fail-state recovery. Then, a composer learns to combine the primitives dynamically. PPO  is adopted to train the policies.\n3.2 IMITATED DATA ACQUISITION\nWith the imitator $\\pi$, we pursue to extract its inherent ID knowledge. As in Eq. 2, though the imitator-produced $\\tau$ is not accurate for $s_t \\rightarrow s^i_{t+1}$ since $s^i_{t+1}$ is not guaranteed to reach, $\\tau$ is accurate for $s_t \\rightarrow s_{t+1}$."}, {"title": "LEARNING IMDYS", "content": "With the collected ImDy, we could address the human inverse dynamics in a full-supervised manner with a data-driven solver ImDyS. In Sec. 4.1, we first introduce the formulation of data-driven inverse dynamics. Then, the proposed data-driven solver is introduced in Sec. 4.2.\n4.1 FORMULATION\nRecall the abstraction of ID in Eq. 2, which we rewrite as\n$(\\tau_t, \\lambda_{t:t+1}) = ImDyS(s_{t-w:t+w+1}).$\nGiven the kinematics states from timestamp t - w to t + w + 1, ImDyS is required to estimate the internal dynamics $\\tau_t$ for the transition from $s_t$ to $s_{t+1}$ and the ground reaction forces $\\lambda$ that the subject bears in timestamp t and t + 1.\nMotion States s could be represented by either SMPL parameters, joint angles, joint coordinates, or marker coordinates. However, due to the topology divergence, the conversion among SMPL parameters, joint angles, and joint coordinates is non-trivial with limited performances. To guarantee that ImDyS could be seamlessly adopted to both ImDy and real-world biomechanics data, we adopt marker coordinates as motion state representation for ImDyS. The state $s_t = (m_t, \\dot{m}_t)$ is composed of marker coordinates $m_t$ and finite-differentiated velocities $\\dot{m}_t$ at timestamp t, which are easy to obtain for both ImDy and AddBiomechanics . Two temporal windows before and after the transition with a length of w are included for contextual information. Notice that human physical properties like height and weight could also be implicitly represented by the markers. The states are canonicalized w.r.t. the heading direction of $s_t$.\nInternal Dynamics $\\tau$. For ImDy, the imposed angular momentum $\\tau_{am}$ is adopted for dynamics representation. Notice that in Sec. 3.2, the original sequences are in 30FPS, while the simulation runs at 60FPS. This means for each motion transition (st, st+1), two torques were applied sequentially, each for $\\frac{1}{60}s$. Predicting both torques is a plausible design choice. However, the second torque is based on the un-recorded mid-state between st, st+1. Predicting it involves the forward dynamics from st to the mid-state, with increased complexity. To this end, instead of predicting instantaneous torques, we switch to predicting the imposed angular momentum $\\tau_{am} \\in \\mathbb{R}^{(J-1)\\times 3}$, the time-accumulation effect of torque, for each motion transition. Thus, the modeling could stay consistent with proper complexity, only needing to sum the two torques up for st, st+1 and then multiply it with the delta time. For AddBiomechanics, joint torque $T_{jt}$ is adopted for dynamics representation.\nGround Reaction Forces $\\lambda$. Different from previous efforts with foot GRFs only, we predict full-body GRF $\\lambda \\in \\mathbb{R}^{J \\times 3}$ as in Fig. 1.\n4.2 DATA-DRIVEN IMDYS\nModel architecture. With the enormous data scale of ImDy, we would like to keep ImDyS simple. An encoder-head structure is adopted. $s_{t-w:t+w+1} \\in \\mathbb{R}^{M \\times (2w+2) \\times 6}$ is first flattened as $s_{t-w:t+w+1} \\in \\mathbb{R}^{M \\times (12w+12)}$ with window size w and M markers. Then, a transformer encoder converts $s$ into ID feature $f_{ID} \\in \\mathbb{R}^d$, where d is the feature dimension. For prediction, we decompose $\\tau_{am}$ and $\\lambda$ into magnitudes $|\\tau_{am}|,|\\lambda_{t:t+1}|$ and direction vectors $\\hat{\\tau_{am}}, \\hat{\\lambda_{t:t+1}}$ and predict each of them with a linear head. $T_{jt}$ is predicted with another linear head. The final predictions are $\\tau_{am} = |\\tau_{am}|\\hat{\\tau_{am}}, \\lambda_{t:t+1} = |\\lambda_{t:t+1}|\\hat{\\lambda_{t:t+1}}$ and $T_{jt}$\nLoss terms. $L_1$ loss, cosine loss, and $L_2$ loss are adopted to optimized the predicted magnitudes $|\\tau_{am}|,|\\lambda_{t:t+1}|$, direction vectors $\\hat{\\tau_{am}}, \\hat{\\lambda_{t:t+1}}$, and joint torques $T_{jt}$ as $L_{mag}, L_{cos}, L_{L2}$ respectively. Besides, a forward dynamics (FD) loss $L_{fd}$ is proposed with an auxiliary FD model to inform the learning with the ID-FD cycle. The FD model takes $s_{t-w:t}, T = (\\tau_{am}, T_{jt}), \\lambda_t$ as input, predicts the next-frame joint angles. The FD loss is thus computed with cycle consistency as\n$L_{FD} = |s_{t+1} - FD(s_{t-w:t}, \\theta^*)|$.\nFinally, we devise a loss term similar to , which encourages the ImDy feature $f_{ID}$ to model physically plausible motion transitions. A linear discriminator takes $f_{ID}$ and outputs a logit indicating whether the motion transition is plausible. To train the discriminator, besides the positive samples from ImDy and AMASS , we propose two negative sample generation strategies. First, $s_{t-w:t+w+1}$ is randomly permuted along the temporal axis. Second, random Gaussian noises are added on $s_{t-w:t+w+1}$. Binary cross-entropy loss is adopted as $L_{cls}$.\nSim2Real training curriculum is devised in a simple two-stage manner. In the first stage, ImDyS is trained on ImDy, with the overall loss as $L_{s1} = \\alpha_1L_{mag}+\\alpha_2L_{cos}+\\alpha_3L_{FD}+\\alpha_4L_{cls}$. In the second stage, we freeze the encoder and train the linear head for joint torques $T_{jt}$. The loss is calculated as\n$L_{s2} = \\alpha_3L_{FD} + \\alpha_4L_{cls} + \\alpha_5 L_{L2}$. Results show that ImDy pre-trained encoder converges fast on AddBiomechanics, indicating that it holds useful knowledge on real-world human dynamics."}, {"title": "EXPERIMENTS", "content": "5.1 IMPLEMENTATION DETAILS\nPHC adopted the position-control mode implemented by IsaacGym , where the imposed torque is calculated differently from the naive PD controller and inaccessible. Therefore, we re-trained the PHC on AMASS with the effort-control mode, and a naive PD controller was adopted. Training the PHC took approximately 10 days, with a success rate on AMASS of 91.3%. The window size w is set as 2 to keep a short-term motion modeling, which is proven helpful in Sec. 5.3. The encoder of ImDyS is a three-layer transformer with a dimension of 64, ReLU activation, and LayerNorm. The loss weights are set as $\\alpha_1 = \\alpha_3 = 0.01, \\alpha_2 = \\alpha_4 = \\alpha_5 = 1$ to maintain all terms at similar numerical scales for training stability. ImDyS, the prior discriminator, and the FD model are all trained using the AdamW optimizer with a batch size of 2,400 for 140 epochs on ImDy for the first stage. For the second stage, ImDyS is further tuned on AddBiomechanics for only 10 epochs with the same hyperparameters. When generating negative samples for the prior discriminator, the two strategies are randomly adopted with a positive-negative ratio of 1:1. We split ImDy into a training set of 27,501 sequences and a test set of 3,055 sequences. All the data collection processes and experiments are conducted on a single NVIDIA RTX3090 GPU.\n5.2 EVALUATION ON IMDY\nMetric. We calculate the mPJE (mean Per Joint Error) for $\\tau$ and $\\lambda$ as\n$mPJE_T = \\frac{1}{J} \\sum_{j=1}^J | \\tau_j - \\hat{\\tau_j} |_2, \\quad mPJE_{\\lambda} = \\frac{1}{J} \\sum_{j=1}^J | \\lambda_j - \\hat{\\lambda_j} |_2,$\nwhere J is the number of joints. The result is further normalized by body weight to align different subjects, with units of N\u00b7m\u00b7s/kg and N/kg. Specifically, the mPJE for the GRF on both feet $mPJE_{\\lambda_{lf}}, mPJE_{\\lambda_{rf}}$ is also reported.\nBaseline. Few efforts except IL algorithms are feasible as baselines. To this end, we introduce PHC as a baseline, where the sequences in ImDy are re-imitated by the re-trained PHC. The imposed angular momentums and the GRF obtained via the re-imitation process are adopted as the baseline predictions. With this baseline, we demonstrate the amplification effect from the kinematics error to the dynamics error, thus validating the performance of directly adopting IL for ID.\nResults. Quantitative results are shown in Tab. 2. PHC produces an mPJPE of 56.13 mm, which is admirable for kinematics but results in high dynamics errors. ImDyS demonstrates considerably better performance. We further visualize two qualitative samples in Fig. 4. Since the raw data could be jittering, we also filter the predictions with a low-pass filter at 14Hz, denoted as $\\bar{\\tau}, \\bar{\\lambda}$, which helps reveal the general trend of the predictions. For the gait sample at the left, the imposed angular momentum at the left hip and the left knee are plotted, along with the GRF $\\lambda$ at the left toe. We also plot the error between the predicted values and GT values. ImDyS manages to faithfully reconstruct $\\tau$ for the left knee and hip with minor errors. Meanwhile, PHC typically produces higher errors due to phase mismatch. As shown, it tends to lag behind the input motion. For GRF, ImDyS also produces reasonable predictions. Besides a typical gait analysis sample, we also demonstrate the performance of ImDyS with an arm-waving motion. The $\\tau_{am}$ at directly related body segments including the left thorax and shoulder is visualized. ImDyS reproduces the dynamic status with better alignment to GT compared to PHC. Generally, ImDyS produces reasonable ID predictions. A potential issue is the jittering prediction, which is a consequence of the jittering observations in ImDy. However, we show that ImDyS could handle real-world smooth observations well even when trained only on jittering ImDyS.\n5.3 EVALUATION ON GROUNDLINK\nMetrics. GroundLink  provides 1.5-hour motion from 7 subjects with GRF. We adopt subject 7 for evaluation. mPJE_$\\lambda$ at both feet normalized by body weight is reported.\nBaselines. PHC is evaluated similarly to Sec. 5.2. We also report the performance of GroundLinkNet . PHC and ImDyS are not exposed to GroundLink during training, resulting in a zero-shot evaluation for ImDyS and the PHC baseline. Also, GroundLinkNet operates on 250FPS motion, while ImDyS and the PHC re-imitation baseline only operate on 30FPS motion. Finally, GroundLinkNet predicts GRF for both feet, while ImDyS and PHC could decouple feet into ankles and toes, and predict GRF separately for each part. We add up the ankle GRF and the toe GRF as the foot GRF. All predictions are re-sampled to 30FPS.\nResults. Quantitative results are illustrated in Tab. 3. Surprisingly, both ImDyS and PHC manage to outperform the specifically trained GroundLinkNet. We attribute this to the enormous scale of AMASS and ImDy, which is much larger than GroundLink. Moreover, even though ImDyS is trained on simulated ImDy only, it generalizes to real-world data with competitive performance.\n5.4 EVALUATION ON ADDBIOMECHANICS\nMetrics. AddBiomechanics  is recently proposed with over 50 hours of human dynamics data from 273 subjects. We adopt the armless part of this dataset. We follow the train/test split in Addbiomechanics and report mPJE for the joint torque normalized by body weight.\nResults. A baseline model trained only on AddBiomechanics for 150 epochs with the same architecture as ImDyS is reported to showcase the generalization from ImDy to real-world dynamics. All data are re-sampled to 30 FPS. Quantitative results are illustrated in Tab. 4. ImDyS outperforms the baseline with faster convergence, indicating the efficacy of Imdys in pre-training and mitigating the sim2real gap.\n5.5 ABLATION STUDIES\nDifferent Motion Representations are evaluated on ImDy in Tab. 5. Though SMPL and joint-based representations perform better, we adopt marker-based representation for its generality.\nDifferent Loss Terms are evaluated in Tab. 5. $L_{FD}$ is proven to contribute more than $L_{cls}$.\nDifferent Window Sizes w are evaluated on AddBiomechanics in Tab. 6. ImDyS achieves the best balance between rich contexts and conciseness with w = 2."}, {"title": "DISCUSSION", "content": "Given the fully simulated nature of ImDy, a reasonable question is the sim2real problem. ImDy could be unnaturally jittering. Also, the physical properties of the simulated humanoid differ from those of real humans. Empirically, experiments show that ImDyS generalizes well to real-world data, partially mitigating this gap. The reason could be threefold. First, the jitters are unnatural but still physically plausible given that ImDy faithfully preserves consistent information for the simulated physics phenomena. Second, the small window size of ImDyS prevents it from relying on long-term contexts, where jitters are more salient. Finally, the enormous scale of ImDy is helpful for generalization. To further mitigate the sim2real gap with ImDy is a meaningful goal to pursue. Besides, ImDyS is designed as a first-step baseline to demonstrate the efficacy of ImDy. Introducing more sophisticated designs to regulate the behavior of ImDyS would be preferable."}, {"title": "CONCLUSION", "content": "Leveraging the inherent resemblance between inverse dynamics and imitation learning, we proposed a novel human dynamics dataset ImDy, which contained over 150 hours of human motion paired with full-body driven torques and GRFs from well-developed simulator and imitation algorithms. Based on ImDy, a data-driven human inverse dynamics solver ImDyS is devised to reconstruct the driven angular momentum and contact forces from kinematic observations. ImDyS demonstrated impressive performance on both simulated and real-world data. As a first step toward scalable and easily accessible human inverse dynamics, we hope ImDy can shed new light on the data-driven physical analysis of human motion."}, {"title": "APPENDIX", "content": "A APPLICATIONS OF IMDYS\nIn this section, we demonstrate some downstream applications of ImDyS.\nHuman Work Analysis. With the predicted $\\tau$, we could calculate the work conducted at each joint.\nMotion Assessment. Another interesting application of ImDyS is based on the discriminator in-troduced in Sec. 4.2. Besides facilitating ImDyS learning, it could also assess whether a motion"}, {"title": "BADDBIOMECHANICS RESULTS ANALYSIS", "content": "We visualize a failure case on the AddBiomechanics dataset in Fig. 11. As shown, neither the baseline nor ImDyS manages to faithfully predict the joint torques for the jumping motion. In the following, we discuss the reasons for the failure."}]}