{"title": "Data-Driven Self-Supervised Graph Representation Learning", "authors": ["Ahmed E. Samy", "Zekarias T. Kefato", "\u0160ar\u016bnas Girdzijauskas"], "abstract": "Self-supervised graph representation learning (SSGRL) is a representation learning paradigm used to reduce or avoid manual labeling. An essential part of SSGRL is graph data augmentation. Existing methods usually rely on heuristics commonly identified through trial and error and are effective only within some application domains. Also, it is not clear why one heuristic is better than another. Moreover, recent studies have argued against some techniques (e.g., dropout: that can change the properties of molecular graphs or destroy relevant signals for graph-based document classification tasks). In this study, we propose a novel data-driven SSGRL approach that automatically learns a suitable graph augmentation from the signal encoded in the graph (i.e., the nodes' predictive feature and topological information). We propose two complementary approaches that produce learnable feature and topological augmentations. The former learns multi-view augmentation of node features, and the latter learns a high-order view of the topology. Moreover, the augmentations are jointly learned with the representation. Our approach is general that it can be applied to homogeneous and heterogeneous graphs. We perform extensive experiments on node classification (using nine homogeneous and heterogeneous datasets) and graph property prediction (using another eight datasets). The results show that the proposed method matches or outperforms the SOTA SSGRL baselines and performs similarly to semi-supervised methods. The anonymised source code is available at https://github.com/AhmedESamy/dsgrl/", "sections": [{"title": "1 Introduction", "content": "Self-supervised graph representation learning (SSGRL) has been successfully used for graph representation learning (GRL) [12, 17,26,29,37] in various domains where labeled data is scarce and manual label is expensive. It has recently attracted interest across domains by achieving a competitive performance when compared to semi-supervised approaches. Considering the scarcity of labeled data, SSGRL has emerged as a new paradigm that narrows down the performance gap between the unsupervised and semi-supervised learning methods. Self-supervised learning (SSL) is commonly formulated as a predictive or contrastive learning [46]. For predictive models [7], one first defines a related task on which an SSL model is pre-trained to extract meaningful patterns. The pre-trained model is subsequently refined (fine-tuned) on a relevant but specific task of interest. Typically, an SSL model is pre-trained over large data as a starting point. The quintessential models, particularly from NLP, are the ones that are pre-trained on masked word prediction tasks and are fine-tuned on other relevant tasks, such as text classification or translation. On the other hand, contrastive models learn based on augmented views of a data point (e.g., image, graph) that are generated by applying a meaningful perturbation on the original data point. The representation of a data point is then learned by maximizing the mutual information between latent representations obtained from its augmented views. The main challenge here is to produce augmented views of the data points. The key to learning high-quality representations based on augmentation is that the perturbations should preserve semantics [1,6,38,49]. For instance, a perturbation applied to an image of a dog should preserve \"dogness\". Effective augmentation techniques for images (e.g., rotation, flipping, resizing) allow learning high-quality visual representations because they preserve the semantics of the original image. This is also true for SSL techniques in NLP [7,21,23], (e.g. synonym augmentation and word masking), such techniques do not alter the meaning of the original sentence. Due to the complex nature of graph data, it is much more challenging to find appropriate techniques for augmenting graphs. While some techniques are proposed, there is no standard technique that works well for graphs in different domains [14,18,35,38\u201340, 48, 53]. Consequently, most efforts rely on finding a heuristic by trial and error to identify a suitable augmentation for the graph at hand. Generally, there are two classes of perturbations, which either corrupt the topology of the graph or node features. The topology can be corrupted by dropping nodes and edges or adding new edges either randomly or through a diffusion process [14, 35, 40, 53]. Similarly, dropout, masking, and permutation techniques have been used for corrupting node features [18,35]. Nonetheless, it is unclear why a particular augmentation technique works better. A study [39] has shown that these strategies are susceptible to destroying task-relevant information. Furthermore, in some cases, e.g., for molecular graphs, dropout techniques alter the semantics of the graph [46]. The effectiveness of such techniques usually comes not from the graph augmentations but from the strong inductive bias of the underlying learning algorithm, particularly Graph Neural Networks (GNNs) [39]. In this paper, we follow a data-driven approach, where the augmentation process is guided by the inherent signal encoded in the graph. Such an approach establishes obvious benefits, first as one can avoid trial and error in identifying a suitable augmentation mechanism. Second, it provides a flexible framework that can be adapted to different domains. Thus, we propose a novel Data-driven Self-supervised Graph Representation Learning (DSGRL) method. DSGRL is data-driven because it jointly learns the augmentation with the representation. Similar to existing methods, we aim to augment either the topology or node features; however, unlike them DSGRL learns both augmentations from the data. DSGRLIS a general approach that can be applied to both homogeneous and heterogeneous graphs (i.e., graphs containing multiple node/edge types). Generally, for a given graph G, and a family of augmentation heuristics A, existing methods apply either a topological, $A_t \\sim A$, or feature, $A_f \\sim A$, augmentation sampled from A. However, DSGRL does not rely on A,"}, {"title": "2 The Proposed Method", "content": "We consider a graph G = (A,X) with a set of N nodes V and M edges E. $A \\in \\{0,1\\}^{N \\times N}$ denotes the adjacency matrix of G and $X \\in R^{N \\times F}$ is a feature matrix, where F is the number of features. For a given row index i, A[i] = $a_i$ and X[i] = $x_i$ represent the topological structure and feature signals of node i. For any index i, A[:,i] = $a_{:i}$ and X[:,i] = $x_{:i}$ refers to the indexing of the ith column of the adjacency and feature matrices, respectively. Finally, $z_{ij}$ corresponds to the ijth entry of any matrix Z. We consider a message passing GNN, $h_{\\Theta}$, is given, and\n$h_{\\Theta}(G) = h_{\\Theta}(A, X) = \\sigma(...\\sigma(\\hat{A}X^{(l)}W^{(l)})...)$\nwhere, $W^{(l)} \\in R$ is the weight matrix of the lth layer, $\u03c3$ is an activation function, e.g., ReLU, and $\\hat{A}$ is a transformed adjacency matrix. Depending on the type of GNN, one can apply different transformations on A, e.g., the symmetric normalization used in [19]."}, {"title": "2.2 The Case for DSGRL", "content": "Several techniques for self-supervised graph representation learning (SS-GRL) rely on perturbations by randomly dropping nodes, edges, or sub-graphs. This perturbation is acceptable for social graphs. However, they are susceptible to losing semantics. For instance, dropping a node (an"}, {"title": "2.3 Learnable Augmentation", "content": "The key hypothesis behind learning augmentations is that because it is a data-driven approach, it enables us to effectively capture augmentation signals without the human intervention needed for heuristics based on trial and error. Therefore, we propose two alternative approaches, which are learnable feature and topology augmentation."}, {"title": "2.3.1 Learnable Feature Augmentation", "content": "This technique allows us to learn node feature augmentations. Given a graph G=(A,X), we apply a learnable feature augmentation $A_{f_{\\Theta}}$ on G as:\n$A_{f_{\\Theta}}(G) = (A, f_{\\Theta}(X))$\nand we model f as a feed-forward neural network (FFN). Two separate learnable functions $f_{\\Theta_1}$ and $f_{\\Theta_2}$, parameterized by $\\Theta_1$ and $\\Theta_2$ compute two augmented views of X as:\n$X_1 = f_{\\Theta_1}(X) \\in R^{B \\times D_1}$\n$X_2 = f_{\\Theta_2}(X) \\in R^{B \\times D_1}$\nwhere\n$\\Theta_1 = \\{W_1^{(l)}: l=1,...,L\\}$, $\\Theta_2 = \\{W_2^{(l)}: l=1,...,L\\}$\nare set of weights, and $W_1^{(l)}$ or $W_1^{(l)}$ are the weight matrices of the l\u2013th layer of the FFNs, B is batch-size, $D_1$ is the augmentation dimension, and L is the number of layers of the FFNs. Figure 1 (a) shows DSGRL'S architecture based on learnable feature augmentation."}, {"title": "2.3.2 Learnable Topology Augmentation", "content": "Studies have shown that using diffusion-based high-order networks improves the performance of GNNs [20]. Consequently, high-order networks have been used for augmentation in SSGRL. This study proposes a complementary approach that learns the K-order relation between nodes. That is, we apply $A_{t_{\\Phi}}$ on G as:\n$A_{t_{\\Phi}}(G) = (t_{\\Phi}(A), X)$\nto obtain a high-order network\n$A' = t_{\\Phi}(A)$\nFirst, we learn a latent representation, $H \\in R^{B \\times D_1}$, which encodes high-order (K-hop) signal. To this end, we employ a GNN, as GNNs enable us to receive a signal from K-hop neighbors similar to static diffusion algorithms, such as personalized PageRank and heat kernel. Hence, for each node i, a GNN $h_{\\Phi}$, parameterized by $\\Phi$ is used to learn high-order feature vector H[i]=$h_i$ and H is computed as:\n$H = h_{\\Phi}(A, X)$\nwhere $\\Phi$ = $\\{W^{(l)}: l=1,...,K\\}$, $W^{(l)}$ is the weight matrix of the l-th layer of the GNN, and K is the number of layers."}, {"title": "2.4 Encoding", "content": "After generating two views of the graph, either using the feature or topology augmentor, we feed each view independently to a shared GNN encoder, $h_{\\Theta}$, to learn a latent graph representation. For brevity, regardless of the augmentor, we refer to the views in the augmentation space as $G_1 = (A_1, X_1)$ and $G_2 = (A', X_2)$. The next task is to learn two latent representations $Z_1 \\in R^{B \\times D}$ and $Z_2 \\in R^{B \\times D}$ that encode the two views, where D is the number of latent dimensions. We achieve this by using a shared GNN, $h_{\\Theta}$, as:\n$Z_1 = h_{\\Theta}(A, X_1)$\n$Z_2 = h_{\\Theta}(A', X_2)$\nFor full-batch training, the batch axis becomes N instead of B. Henceforth though, we assume a mini-batch training."}, {"title": "2.5 Training", "content": "Generally, in SSGRL, we want the latent representations $Z_1$ and $Z_2$ of nodes to be invariant to the perturbations. For this reason, we want to maximize the agreement (similarity) between $Z_1$ and $Z_2$. Minimizing the L-2 distance is commonly used for this purpose; thus, we use the same strategy. We closely follow a similar formulation as [1] and define a term called invariance based on the L-2 distance as:\n$inv = ||Z_1 - Z_2||_F$\nNonetheless, this has a trivial solution that collapses the representations. Several strategies, mostly engineering tricks, have been used to prevent this collapse [11,18,38]. Instead, we use a principled approach inspired by a recent method [1] proposed for visual representation. That is, we add two regularization terms called variance and covariance regularizations. The variance regularization is defined as\n$\\Nu(Z) = \\sum_{j=1}^D max(0, 1-Var(z_{:j}) + \\epsilon)$\nand it constrains each dimension of the latent representation to have a variance of 1; as a result prevents data points from collapsing into a subspace. The covariance term is defined as\n$\\Nu(Z) =  \\frac{1}{B-1} \\sum_{i \\neq j} \\frac{Z^T Z}{(B-1) \\times D}$"}, {"title": "3 Empirical Evaluation", "content": "We validate the proposed method on node classification (NC) and graph property prediction (GPP) tasks. In the former case, the prediction is at a node level, and for the latter, it is at a graph level. Additional thorough analysis of the experiments and the running times of the methods and are included in the appendix."}, {"title": "3.1 Datasets", "content": "The datasets are 8 for NC and 8 for GPP, and a summary is provided in Tables 1 and 2."}, {"title": "3.1.1 NC Datasets", "content": "\u2022 Citation Networks (PubMed): Paper-to-paper citation networks, and we classify papers into different subjects [13].\n\u2022 Co-Author Networks (MAG-CS): Author collaboration network from Microsoft Academic Graph, and the task is to predict the active field of authors [31].\n\u2022 Co-Purchased Products Network (AmazonPhoto): Co-purchased products from Amazon Photo Category, and the task is to predict the refined categories [31].\n\u2022 Wikipedia (WikiCS): Wikipedia hyperlinks between Computer Science articles, and we classify articles into branches of CS [31].\n\u2022 Social (Facebook, GitHub, Reddit, and Yelp): Facebook contains a page-to-page graph of verified Facebook sites, and we want to classify pages into their categories [28]. GitHub contains the social network of developers, and we want to classify developers as web or machine learning developers [28]. Yelp is also the social network of Yelp users, and we predict the business categories each user has reviewed. For Reddit, we predict the subreddits (communities) of user posts [13,50]."}, {"title": "3.1.2 GPP Datasets", "content": "\u2022 Chemical Datasets (DD, NCI1, PROTEINS, ENZYMES) [24] that represent protein interaction or molecular graphs. The task is to predict different properties of molecules or macromolecules.\n\u2022 Social Datasets (IMDB-BINARY, IMDB-MULTI, REDDIT-BINARY, COLLAB) [24] that represent the collaboration between users in different ego-networks. The task is to predict the class of the ego-networks."}, {"title": "3.2 Baselines", "content": "We compare our method against strong self-supervised baselines. As a result of a plethora of related methods, baselines are selected either based on their popularity or if they are current SOTA methods that outperform existing methods. Hence, for the NC task, we select DGI [40], a method that uses corruption based on permutation of node features and topology, MVGRL [14], which augments the topology using high-order networks obtained through a diffusion process, and GCA [53] is a method based on adaptive edge removal and feature masking augmentations. All of these use a contrastive architecture using mutual information maximization with negative sampling. Furthermore, we include a contrastive architecture based on asymmetry called BGRL [11] for completeness. Although it was initially proposed for visual representations, recent studies [18,38] have extended it for GRL. We use the best augmentations reported in these papers. As there are several studies for the GPP task, we select strong representative baselines, which are GRAPHCL [47, 48], ADGCL [35], and INFOGRAPH [33]. For example, SimGrace [45] is shown to give sub-optimal performance compared to GraphCL [47] as reported in [22, 36], therefore, we only include the results for GraphCL in our experiments. GRAPHCL learns augmentations from a set of augmentations whereas ADGCL learns to drop edges using adversarial training. INFOGRAPH learns by maximizing the mutual information between graph and patch (subgraphs, node, edges) level representations. Furthermore, we include untrained variants of DSGRL as suggested in [39]. We refer to them as Random-F and Random-T to denote the feature and topology augmentation-based architectures, respectively. All the above baselines are self-supervised and unsupervised methods. We also include semi-supervised methods; however, they are included just for reference and not comparison."}, {"title": "3.3 Node Classification on Homogeneous Graphs", "content": "Following the recommended evaluation protocol for node classification [31], we create ten splits for each dataset where there is no public split. We use the linear evaluation protocol to quantify the quality of the representations obtained from the SSGRL methods, where we first train each SSGRL method on each split with no labels. Then, for each split, we set 5% and 15% as training and validation splits used for model selection and 80% for testing using a Linear (Logistic) classifier. Model selection is carried out using only 1 of the ten splits, and for a fair comparison, it is done for all the baselines. We tune all the hyper-parameters using Bayesian optimization \u00b2. In addition, for the baselines, the size of the representation dimension, D, is 128; for our model, it is 64, since we concatenate Z1 and Z2. The reported results for the small datasets are the accuracy on the test set averaged over the ten splits. For two large datasets, Yelp and Reddit, we only report the ROC-AUC and accuracy using the publicly available single set of train, validation, and test sets. The configuration of the hyper-parameters of DSGRL and additional details for this experiment are presented in the appendix. The results are reported in Table 3. DSGRL based on feature and topology augmentations is better than the baselines in almost all datasets. In addition, it is also comparable with the semi-supervised methods. To highlight the scalability of DSGRL, we evaluate it on large-scale datasets and report the results in Table 4. The self-supervised baselines throw an out-of-GPU memory error for the large datasets. So we include semi-supervised methods for reference, and not comparison."}, {"title": "3.4 Node Classification on Heterogeneous Graphs", "content": "Although DSGRL is primarily optimized for homogeneous graphs, it can easily be applied to heterogeneous graphs. Recent studies [16, 22, 25, 27, 41, 44, 51] have generalized graph contrastive learning (GCL) to heterogeneous graphs. In these approaches, composite sequences of edge types (i.e., meta-paths) are hand-crafted for an underlying graph to express different possible semantics. For example, a meta-path \"author-paper-author\" refers to collaboration in a citation graph. Next, meta-path-based graph augmentations are designed for GCL. In doing so, the qualities of the learned representations and augmentation rely heavily on the chosen meta-paths that are typically domain-specific. DSGRL differs from this line of research, as no pre-defined data augmentation or domain knowledge are assumed. As a demonstration, we choose a popular dataset commonly used to benchmark methods for heterogeneous GRL. This dataset, IMDB [10], has three node types, which are movie, director, and actor, and there are two undirected edge types, which are movie-to-director and movie-to-actor. There are 11,616 (4,278-movie, 2081-director, 5,257-actor) nodes and 17,106 (4, 278-movie-to-director and 12,828-movie-to-actor) edges. The task is to classify the movie nodes as one of the three classes (Action, Comedy, and Drama). The only modification we need is, instead of a single parameter \u0398, we use $ = \\{\\Theta_R\\}$, where $\\Theta_R$ denote the model parameter specific to an edge type R. We use the same experimental setting and splits provided in [10]. That is, the movie nodes are split into training (400-9.35%), validation(400-9.35%), and testing (3,478\u201381.30%) nodes. For the linear evaluation, we only use the test set just as in [10] with different training rates, which are 20%, 40%, 60%, and 80%. For example, when using 20% for training, we will use 20% of the test set for training the linear classifier and the remainder (80%) for evaluating and reporting the performance of the learned representations. In Table 5, we report the F1-Score of our model and previous methods. We take the figures for the baselines from [10], and we see that DSGRL achieves better performance than unsupervised methods and is sometimes comparable to the semi-supervised ones. Although the paper's primary focus is not on heterogeneous graphs, this experiment highlights the potential of successfully applying a similar approach to this kind of graph. In future work, we shall address this with more experiments, including more baselines and datasets, and introduce a self-supervised learning technique that generalizes not only to homogeneous but also heterogeneous graphs, including knowledge graphs."}, {"title": "3.5 Graph Property Prediction", "content": "In this experiment, we closely follow the experimental protocol suggested for a fair comparison of GNNs in GPP [9]. Since they provide public splits \u00b3, we use their split in our experiment. For each dataset, they provide ten splits, and each split contains a model selection and test splits. The model selection has training and validation splits. Similar to the NC experiment, we use the linear evaluation protocol and a similar model selection procedure. As the number of features for the datasets in this experiment is usually tiny, we also tune D for the baselines between 32 and 128 and for our method between 32 and 64. Since the social dataset does not have features, we use the degree profile as features. The configuration of the hyper-parameters of DSGRL and additional details for this experiment are also in the appendix. The results are reported in Table 6, and we use the published results for semi-supervised methods. As shown in the table, DSGRL with feature augmentation is better than the baselines in almost all cases. Although the topology augmentation is comparable with the feature one for the social datasets, it could perform better for chemical datasets. We have similar observations for the baselines, which also alter the topology. Note that even"}, {"title": "4 Related Work", "content": "In general, there have been many frameworks for contrastive learning. Mostly, they differ in their data augmentation techniques and the architectures they choose to prevent collapse. Data Augmentation Although there are well-established data augmentation techniques in the computer vision domain, this is not the case for the graph domain [14, 47]. Different heuristics, based on high-order networks, perturbation of topology and attributes have been proposed [3, 14, 18, 40, 48]. It is unclear what the relative benefit of these augmentation strategies is, and little is known regarding the relevance of each strategy concerning different downstream tasks. Recently, studies [35,39,47] have proposed learnable and contextual augmentation techniques [35, 39, 53]. However, these methods are restrictive because they either specify a set of graph data augmentation techniques so that the learning is choosing the correct technique, or they only learn to dropout edges through adversarial training. A more relevant study, i.e., Sim-"}, {"title": "5 Conclusion and Discussion", "content": "This paper presents a novel data-driven self-supervised graph representation learning method called DSGRL. Unlike existing methods, DSGRL learns augmentation governed by the graph's inherent signal. We propose two complementary approaches, one based on learning high-order topology and another on learning feature augmentations. In both cases, augmentation is jointly learned with the graph representation. We perform an extensive empirical evaluation using eight graph property predictions and another nine node classification datasets, including heterogeneous and homogeneous graphs, which are publicly available. We compare DSGRL against seven popular and SOTA baselines, three for graph property prediction and four for node classification experiments. Furthermore, in both experiments, we closely follow recommended protocols for a fair comparison and tuned the hyper-parameters of all the baselines. The overall results confirm that DSGRL surpasses the baseline SOTA approaches. Among the graph property prediction datasets, 4 of them are chemical, and 4 are social datasets. For the social graphs, the empirical results show that both augmentation techniques produce comparable results. Whereas for the chemical graphs, the topological augmentation does not perform well. The latter is also the case for the baselines, which rely on perturbing the topology. This aligns with existing studies that argue against topological perturbation for such datasets [39]. We believe topological augmentations for chemical datasets require further careful investigation. Last, we report on the untrained variants of the DSGRL. Our results show that even the untrained model is significantly better for the chemical datasets than some of the baselines. The latter is consistent with recent findings [39], which show that the strong inductive bias of GNNs tends to compensate for what is lost in the augmentation."}]}