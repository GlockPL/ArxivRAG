{"title": "Exploring the Use of Abusive Generative AI Models on Civitai*", "authors": ["Yiluo Wei", "Yiming Zhu", "Pan Hui", "Gareth Tyson"], "abstract": "The rise of generative AI is transforming the landscape of digital imagery, and exerting a significant influence on online creative communities. This has led to the emergence of AI-Generated Content (AIGC) social platforms, such as Civitai. These distinctive social platforms allow users to build and share their own generative AI models, thereby enhancing the potential for more diverse artistic expression. Designed in the vein of social networks, they also provide artists with the means to showcase their creations (generated from the models), engage in discussions, and obtain feedback, thus nurturing a sense of community. Yet, this openness also raises concerns about the abuse of such platforms, e.g., using models to disseminate deceptive deepfakes or infringe upon copyrights. To explore this, we conduct the first comprehensive empirical study of an AIGC social platform, focusing on its use for generating abusive content. As an exemplar, we construct a comprehensive dataset covering Civitai, the largest available AIGC social platform. Based on this dataset of 87K models and 2M images, we explore the characteristics of content and discuss strategies for moderation to better govern these platforms.", "sections": [{"title": "1 INTRODUCTION", "content": "The commodification of AI Generated Content (AIGC) has had a significant impact on online creative communities [4, 12]. For example, the Generative Diffusion Model (GDM) [35] has achieved state-of-the-art outcomes in the realm of image generation, with open-source implementations like Stable Diffusion [33] easily accessible. Their open-source nature further enables fine-tuning and extension of the models.\nThis has driven the emergence of AIGC social platforms such as Civitai, PixAI, and Tensor.art. These are online platforms for sharing models, images and discussing open-source generative AI. They are designed akin to social media services, allowing users to showcase their creations, participate in discussions, and receive feedback, thereby creating a sense of community. Uniquely, they also allow users to develop and share their own generative Al models. For instance, bespoke models can be developed for generating particular types of images (e.g., containing particular people or artistic styles) and, subsequently, other users can then share the outputs (images) from these models for further social discussion. These unique features have attracted a significant number of creators sharing numerous novel models and artworks, catalyzing new trends in AI content creation [3, 23].\nHowever, the unrestricted proliferation of diverse models represents a double-edged sword: while they can help unleash creativity, they also pose challenges and risks that require careful consideration. Numerous issues concerning the abuse of generative AI have already been reported, including flooding online communities with not-safe-for-work (NSFW) images [38], disseminating deceptive deepfakes [44], and infringing upon copyright [14]. Anecdotally these platforms have often been the origin of the generative AI models that produce the aforementioned abusive content, and also where the abusive content is initially shared [17, 22]. Thus, the proliferation of abusive content from these platforms can exert a broader influence, permeating other social media communities.\nAs a result, there is an arguable need to somehow moderate the use of these models on such platforms. However, to date, there have been no prior studies that could inform the debate. With this in-mind, we conduct the first large-scale empirical study of an emerging AIGC social platform, focusing on the Civitai - the largest social platform for image models [34]. As of November, 2023, it has attracted 10 million unique visitors each month. We compile a dataset comprising all metadata (for both images and"}, {"title": "2 PRIMER ON CIVITAI", "content": "As a social platform, Civitai enables users to share their Al models and generated images, as well as receive feedback, comments and even tips from other users. In this section, we introduce the necessary pre-knowledge about Civitai.\nModels and images. Civiati hosts diffusion models and AI-generated images, uploaded by creators. Every model/image is associated with a unique ID and a preview web page public to any users. Various social metadata is visible as well, involving tags (assigned by users or Amazon Rekognition [9, 10]), statistics (e.g., number of downloads/views, likes, and rating scores), and text comments by other registered users. Creators can also attach descriptive information to their models and images, i.e. textual descriptions of models' usage and images' configurations, resources, and prompts used for generation.\nUsers. Similar to common social platforms, Civitai users have profile pages displaying their self-reported information and all their models/images. Users can also attach external links to their profile page, as promotion for their accounts on other social platforms (e.g., Instagram and X) or profitable platforms (e.g., Ko-fi and Patreon). Furthermore, users can follow each other and leave rating scores to the profile pages."}, {"title": "3 DATA COLLECTION METHODOLOGY", "content": "We compile a dataset containing the metadata of all models, images, and creators on Civitai. To accomplish this, we utilize the Civitai REST API\u00b9 and python Selenium WebDriver.\nModel data. We collect 87,042 models' metadata. The metadata contains the number of downloads, likes, comments, and rating score (range from 0 to 5), amount of tips, tags, a textual model description, and flags for whether the model is a real-human deepfake or NSFW. Of these models, 8.0% are checkpoint models (base models), 84.4% are LoRA [11, 19] (or LyCORIS [46]) models (fine-tune models), 5.8% are embeddings and 1.8% are other models.\nImage and prompt data. We collect 2,740,149 images' metadata. These are images generated from the shared models. The metadata contains the number of consumers' five reactions (cry, laugh, like, dislike, and heart), number of comments, views, amount of tips, tags, flags for whether the image is NSFW, and the model used to generate the image. Note, as Civitai API does not identify deepfake images, we annotate an image as real-human deepfake if it is generated by any one model explicitly reported as real-human deepfake. Importantly, the metadata also includes the text prompts used for 1,534,922 images.\nCreator data. We extract 56,779 creators, with 11,632 model creators and 52,546 image creators (7,399 are both model and image creators). We also gather their lists of followers and followees."}, {"title": "3.2 Data Augmentation", "content": "We augment our data with two types of annotations: (i) labeling models and images with their content themes (\u00a74); and (ii) identifying person names as well as occupations, using the models'"}, {"title": "4 EXPLORING MODEL AND IMAGE THEMES (RQ1)", "content": "In this section, we investigate RQ1, inspecting the themes of models and images. Our ultimate goal is to explore the potential prevalence of abusive content on Civitai."}, {"title": "4.1 Overview of Themes", "content": "Recall, we use ChatGPT to identify the theme of each model and image, based on their tags. Thus, we begin by examining the distribution of the six identified themes. Overall, while \"Human attributes\" is the most common themes across both models and images, we observe that the focus on themes varies between the creation of models vs. images. Model development predominantly revolves around three themes: \"Virtual character, fictional content, entertainment media\" (65.03% models), \"Human attributes\" (53.85% models), and \"Style of art and culture\" (34.58% models). In contrast, image creation focuses on \"Scenery"}, {"title": "4.2 Overview of Creators' Themes", "content": "We next examine the specific themes that each creator (primarily) focuses on. To do this"}, {"title": "4.3 Relationships between Themes", "content": "The prior subsection has revealed clear preferences for certain themes of models and images within the Civitai community. Abusive themes (NSFW & deepfakes) seem particularly prevalent for images. That said, deepfakes themselves are not inherently abusive; rather, they only become abusive when intertwined with other themes. For instance, a satirical deepfake portraying a politician may be innocuous, whereas one depicting a celebrity naked is problematic. Thus, we next examine the co-occurrence of themes, measured using the phi coefficient ($\\phi$)."}, {"title": "5 EXPLORING THE CREATION OF ABUSIVE IMAGES (RQ2)", "content": "The previous section has exposed the presence of models specifically designed to generate abusive content, alongside a wealth of images generated using those models. Next, we focus on the popularity of these models, and who they target.\nPopularity of deepfake and NSFW models. We first inspect the \"popularity\" of real-human deepfake and NSFW models, as this can offer moderators a useful lens into the productivity of abusive models. We measure popularity based on the number of images that have been created using those models. Recall, that the Civitai API returns whether a model is dedicated to deepfakes or NSFW. Rather than using the tags, we therefore next use these labels to classify each model. Overall, 13,516 models (15.53%) are classified as real-human deepfakes, and 7,614 models (8.75%) are classified as generating NSFW content."}, {"title": "6 EXPLORING USER ENGAGEMENT WITH ABUSIVE MODELS AND IMAGES (RQ3)", "content": "Prior literature has underscored the importance social engagement in encouraging users to share more abusive media [26, 29]. Civitai allows users to interact and, for example, post comments and likes on models or the images that they generate. Inspired by this, we inspect the level of social engagement received by models and images labeled as abusive."}, {"title": "7 EXPLORING THE NETWORK POSITIONS OF ABUSIVE CREATORS (RQ4)", "content": "One potential explanation for the above prevalence of abusive models and images is that help creators to gain a greater social status. To explore this, we next investigate whether the sharing of abusive models and images is correlated with a creator's social network position (e.g., centrality)."}, {"title": "7.1 Social Network Definition", "content": "We induce a follower network based on users' following connections. If a user (followee) is followed by another user (follower), we assign a directed link from the follower to the followee. The resulting social network is a directed graph consisting of 214,218 nodes and 1,731,805 edges. Among these users, we focus on active creators who have shared at least 3 models or images. We further categorize these creators as NSFW/deepfake if they have contributed at least 3 NSFW/deepfake models or images. In all, there are 26,180 (12.22%) active creators who generate 1,699,606 (98.14%) connections on the follower network. 19,160 (73.18%) are NSFW creators and 2,591 (9.89%) are deepfake creators. This means that the follower network is predominately led by a small group of active creators, who commonly share models and images. This unsurprisingly seems to play a key role in forming the connections."}, {"title": "7.2 Centrality Analysis", "content": "Graph centrality is a metric to assess users' positions on a social network [5]. We calculate three centrality metrics to quantify the creators' network positions [30, 47]: (i) Betweenness: Creators with higher betweenness centrality hold a brokerage position, connecting different communities within the social network; (ii) Indegree: Creators with higher indegree are more popular, with more followers; (iii) PageRank: Creators with higher PageRank are followed by other users, who have high influence."}, {"title": "8 RELATED WORK", "content": "Platforms for Al models. Previous studies have looked at online platforms for AI models, with a particular emphasis on traditional platforms like GitHub and Huggingface. These investigations cover a wide range of perspectives, including machine learning [27, 37], software engineering [20, 37], and social computing [1, 41]. Additionally, there are also studies that put forward innovative designs for these platforms [18, 21]. In contrast, Civitai and other AIGC social platforms also serve as a hub to showcase AIGC, and an online community for Al creators, attracting a diverse user base that extends beyond programmers and computer scientists. To the best of our knowledge, this is the first large-scale empirical study of an emerging AIGC social platform.\nAbuse of generative AI. Several studies have examined the abuse of generative AI. There are two perspectives closely related to our work. The first issue concerns the spread of misinformation through deepfakes [43]. Multiple studies have looked into the prevalence of deepfakes on social media and their potential impact on security and safety [7, 15, 24, 28, 32, 45]. The second issue involves the creation of NSFW content more generally. Numerous studies have highlighted the significant increase in Al-generated NSFW content on the Internet, particularly on social media platforms. Concerns have been raised about the lack of regulation and moderation of this content, and the potential impact it may have on the online environment and community building [6, 13, 17, 38, 41]. In contrast, Civitai and other AIGC social platforms offer more than just AI-generated images - they include generative AI models that produce the abusive images. Overall, our research complements prior studies by providing insights not only from the image angle, but also from the model and creator perspective. We argue this can help in better regulating and moderating potentially abusive models and images."}, {"title": "9 CONCLUSION AND DISCUSSION", "content": "Summary and implications. This paper performed a large-scale study of the creative ecosystem of Civitai. Our analysis reveals abusive use of generative models, mainly revolving around NSFW content and deepfakes. Moreover, we flag several crucial points related to the use of NSFW prompts, emerging deepfake attacks on social media celebrities, and users' active engagement with abusive models and images. This motivates the need to better develop moderation tools by analysing creators' network positions."}, {"title": "Limitations and future work", "content": "Our research is based solely on Civitai. Moving forward, we hope to include additional AIGC platforms such as PixAI and Tensor.art. This expansion will allow us to gain a wider perspective on the patterns of AI-generated abuse across various platforms. Furthermore, so far, our focus is limited to the exploration of NSFW content and deepfake abuses through generative models. We wish to explore other forms of misuse, such as copyright infringement, the creation of offensive memes, and the production of false information."}, {"title": "Ethics consideration", "content": "Our study is based on public data from the Civitai RESTful API. We do not attempt to de-anonymise users. We only use the data to understand users' behaviors associated with abusive AIGC and discuss moderation strategies for Civitai. Our analyses follow Civitai's data policies."}]}