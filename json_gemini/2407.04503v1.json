{"title": "When LLMS Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions", "authors": ["J\u00e9r\u00e9my Perez", "Corentin L\u00e9ger", "Grgur Kova\u010d", "C\u00e9dric Colas", "Gaia Molinaro", "Maxime Derex", "Pierre-Yves Oudeyer", "Cl\u00e9ment Moulin-Frier"], "abstract": "As large language models (LLMs) start interacting with each other and generating an increasing amount of text online, it becomes crucial to better understand how information is transformed as it passes from one LLM to the next. While significant research has examined individual LLM behaviors, existing studies have largely overlooked the collective behaviors and information distortions arising from iterated LLM interactions. Small biases, negligible at the single output level, risk being amplified in iterated interactions, potentially leading the content to evolve towards attractor states. In a series of telephone game experiments, we apply a transmission chain design borrowed from the human cultural evolution literature: LLM agents iteratively receive, produce, and transmit texts from the previous to the next agent in the chain. By tracking the evolution of text toxicity, positivity, difficulty, and length across transmission chains, we uncover the existence of biases and attractors, and study their dependence on the initial text, the instructions, language model, and model size. For instance, we find that more open-ended instructions lead to stronger attraction effects compared to more constrained tasks. We also find that different text properties display different sensitivity to attraction effects, with toxicity leading to stronger attractors than length. These findings highlight the importance of accounting for multi-step transmission dynamics and represent a first step towards a more comprehensive understanding of LLM cultural dynamics.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) are playing an increasingly significant role in the production of media content across various domains [10]. They are being used for academic writing [12, 2, 16, 24, 37, 40, 14], journalism [55], story generation [70, 78, 79], as chatbots on social media [61] and in the workplace at large [11, 27]. As LLMs become more performant, controllable, and more widespread, their impact on the creation and dissemination of information content humans consume is expected to grow even further [10].\nGiven the implications of LLM usage for the production of cultural information, numerous researchers have studied the properties of LLM-generated content. In these studies, LLMs showed several biases with respect to gender [1, 62, 72, 30, 25], race [57], values [5, 66], politics [48, 3, 30], authority,"}, {"title": "2 Related work", "content": "Biases in LLMs outputs LLM-generated content is known to exhibit a variety of stereotypical biases [8, 73]. In single-turn settings, LLMs perpetrate [49] or even amplify human biases based on gender, nationality, race, and religion [39]. For instance, the GPT model was shown to exhibit cultural values similar to those of WEIRD (Western, Educated, Industrial, Rich, Democratic) cultures [5]. LLMs trained through reinforcement learning with human feedback (RLHF) were found to overly express left-wing opinions on American politics - a tendency that, once formed, is difficult to avoid even after steering the model toward different demographic groups [63].\nTransmission chains featuring artificial agents Several studies have applied experimental designs used in cultural evolution to study knowledge and skill accumulation in groups of Reinforcement Learning agents [18, 64, 69, 56]. Closer to the current study, populations of LLMs have also been studied [10]. Iterative chains of generative models trained on the preceding model's output have been shown to sometimes collapse toward the most likely outputs while the tails of the original distribution disappear [65, 54]. This idea of using LLM-generated content to fine-tune the next generation has also been applied to groups of LLMs with various communication structures [33]. Similar to our approach, iterative chains with frozen (i.e., not re-trained) LLMs have been shown to express human-like biases in terms of gender stereotypes, positivity, and social, threat, and biology-related information [1]. Strong, but non-human-like biases for producing factual information have also been observed [17], stressing the importance of understanding the evolution of content in LLMs and the ways it might deviate from human cultural evolution."}, {"title": "3 Methods", "content": "Our telephone game experiments aim to study the possible attractors and biases that may accumulate across multiple turns of interactions between LLMs. This is done with a transmission chain design tracking the evolution LLM outputs as a function of the number of interactions in the LLM chain. This section introduces our transmission chain design (Section 3.1), the set of metrics used to study the evolution of text properties, semantic similarity and the added effect of multi-turn interactions (Section 3.2), and our method to characterize the properties of attractors (Section 3.4)."}, {"title": "3.1 LLM transmission chains", "content": "In transmission chains, individual participants are ordered linearly. Each participant receives some information from the previous one, performs a task, and transmits new information to the next participant. Each agent is prompted with a task (instruction on how the text should be processed) and a text, which are concatenated and passed to the user message. The first agent is given a human-generated text and a task, and subsequent agents are given the same task and the text generated by the previous agent in the transmission chain:\n$text_{i+1} = LLM(task, text_i),$ (1)\nwhere $text_0$ is the initial human-generated text and $LLM$ generates an output based on task $task$ and the previous agent's text $x_i$. We run this process for 50 generations. Examples of texts evolving through generations are provided in Appendix Section A."}, {"title": "3.2 Metrics", "content": "Text properties Iterated transmissions may affect the generated text in several ways. We focus on four, orthogonal properties for each text which could be automatically measured (as opposed to requiring human annotators, which would have been impractical given the size of the output corpus):\n\u2022 Toxicity. Companies typically fine-tune LLMs to avoid the generation of toxic (i.e., dangerous or harmful) content. However, to our knowledge, this fine-tuning step focuses on single-turn dynamics, and the evolution of content with respect to its toxicity is currently understudied. We measure the toxicity of texts by quantifying the presence of rude, disrespectful, or unreasonable language, using a probability score that ranges from 0.0 (benign and non-toxic) to 1.0 (highly likely to be toxic), as estimated by the classifier introduced in [31].\n\u2022 Positivity. Even when trained to avoid toxic content, LLMs have been shown to express similar positivity biases to humans, often favoring negative over positive information in preserving and generating new information [1]. To study whether positivity biases over transmission chains are affected by tasks and models, we measure the positivity of produced contents using the SentimentIntensityAnalyzer tool from NLTK [32]. It uses this information to calculate a sentiment score for the text, ranging from -1.0 (highly negative) to 1.0 (highly positive).\n\u2022 Difficulty. While LLMs are argued to benefit society by democratizing knowledge [74], such positive outcomes are conditioned on the LLMs generating output that is accessible and inclusive to all kinds of audiences. However, whether text difficulty is preserved, increased, or reduced"}, {"title": "3.3 Effect of multi-turn transmissions", "content": "One of our questions is how content evolves over multi-turn transmissions compared to single-turn settings. To address this point, we compare the distribution of a given property in the generated texts at the first generation to the distributions at subsequent generations. Thus for each model and task, we look at the properties of each of the 100 generated texts (20 transmissions chains * 5 seeds) at each generation, which gives us a sample of 100 property values for each value. Using a Kolmogorov-Smirnov test [41], we then test whether the sample obtain at each generation comes from the same distribution as the sample obtained after the first generation. If we can confidently reject the hypothesis that the sample of property values at the end of the transmission chain comes from the same distribution as the sample obtained after the first generation, this would confirm that looking at outputs after a single-turn transmission is not enough for predicting output properties in a multi-turn setting."}, {"title": "3.4 Attractor strength and position", "content": "Human cultural evolution shows that cultural traits sometimes evolve towards attractor states, i.e., content that invites convergence even with different starting points [36, 45, 46, 13]. Therefore, we were interested in whether transmission chains with LLMs would show similar attractor dynamics, and whether these depend on the model and task used in the chain. The concept of cultural attractor is not consistently formalized in the human cultural evolution literature [13]. Here, we defined attractors as the theoretical equilibrium point to which the iterated generation process (defined in Eq. 1) may eventually converge. We mathematically define attractors in terms of two properties of interest: its position (i.e., the location in output generation space the process converges toward) and its strength (i.e., the intensity to which generated outputs are pulled toward it). The strength takes values in [0, 1], which allows for a continuous notion of an attractor: rather than being a binary concept that either exists or does not, attractors here lie on a spectrum, covering systems without attraction effects (strength=0) to ideal attractors (strength=1). To compute position and strength, we use the simulated data to fit a linear regression predicting the value of a property at the end of the chain as a function of its value in the initial text (Figure 2).\nFor example for a given text property, we fit:\n$property(generation = 50) = I + s * property_{initial},$ (2)\nwhere $I$ is the estimated intercept and $s$ the estimated slope."}, {"title": "4 Results", "content": "For each of the 5 models, 3 tasks, and 20 initial texts, we ran 5 transmission chains with 50 transmission steps. We provide some examples of generated texts in Appendix Section 1, and complete data on the companion website 9. By extracting the properties of generated texts at each generation of each chain, we can study the evolution of these properties through generations, measure how they are affected by interactions beyond single-turn effects, as well as detect and characterize theoretical attractors. By comparing the semantic similarities of texts produced by different chains, we can also evaluate whether sets of chains tend to converge or diverge."}, {"title": "4.1 Qualitative analysis of property evolutions over generations", "content": "We first hypothesized that iterated transmissions would affect the properties of generated texts beyond the first transmission. Across many instances, we indeed found that text properties keep evolving after the first generation. In Figure 3, we show the evolution of text difficulty, positivity, length and toxicity for one of the 20 initial texts, for all models and all tasks. Evolution of these properties for each of the 20 initial texts can be found in Appendix Section B. This specific example already allows to notice important differences in dynamics between models, tasks, and properties. Indeed, we observe that while toxicity converges to values close to zero for all models and tasks, this happens at a slower pace for GPT3.5 in the Rephrase task, and for Llama3-70B in the Take Inspiration task. For positivity, we observe that on the Take Inspiration and Continue tasks, GPT3.5 and Mixtral-8x7B converge to high positivities almost instantly, while evolution is more gradual for other models. The dynamics of difficulty appears to be highly influenced by task and models, as we observe cumulative changes for Llama3-8B and Llama3-70B in the Take Inspiration and Continue tasks, but not so much for other tasks and models. Length appears to exhibit little to no cumulative dynamics in this example. Interestingly, there seems to be a discontinuity of high magnitude for Mistral-7B toward the end of the chain in the Continue task. Qualitative observation of the texts revealed that this appears to be an example of collapsing behavior, which we discuss more extensively in Appendix Section B.\nOverall, these results suggest that the evolution of text properties across repeated transmission is highly sensitive to both agent models and tasks.\nAlthough we here focused on a specific example, looking at the evolution over generations of the distribution of each properties gives a higher-level idea of the dynamics. In Figure 4, we show the evolution of property distributions over generation for each model and task. This reveals important"}, {"title": "4.2 To what extent do multi-turn transmissions affect the evolution of properties?", "content": "Qualitative analyses from the previous section appear to suggest that multi-turn transmissions lead texts to acquire different properties compared to single-turn settings. To quantitatively evaluate"}, {"title": "4.3 What influences the presence, strength, and position of attractors?", "content": "Visual inspection of the evolution of text properties as presented on Figure 4 indicate that multi-turn transmissions lead distributions to become skewed toward certain values, which suggests the presence of attractors. The task assigned to a chain and the model type populating it appear to influence the position of those attractors, as well as their strength (i.e. how quickly do shifts in distributions happen). To have quantitative measures of attractors strengths and positions, we use the method described in 3.4 and Figure 2. By fitting a linear regression predicting the value of a given property at the end of the chain as a function of the property in the initial text, we can represent for each property, model and task the position and strength of the attractors, provided they exist. Figure 6 presents the estimated strengths and positions of attractors, and fitted linear regressions are provided as supplementary material in Figure 8.\nFor all combinations of property, task and model, we found that the recurrent relationship defined by the fitted linear regression converges. This means that all conditions admit a theoretical attractor as defined in Section 3.4. As for the strength and position of these theoretical attractors, Figure 6 already allows to notice some tendencies. For instance, it seems that less constrained tasks (e.g. Continue) lead to stronger attractors than more constrained tasks (e.g. Rephrase). To better disentangle the respective contributions of model type, task and property on attractors, we fitted bayesian models predicting attractor Strength as a function of Task, Model and Property, and predicting attractor Position as a function of Task and Model, for each of the four considered properties. Details about statistical analyses are provided in Appendix section B.\nWe find a strong effect of Task on attractor strength: Continue leads to significantly stronger attraction than Take Inspiration, itself leading to significantly stronger attraction than Rephrase. This confirms our observation that less constrained tasks lead to stronger attraction than more constrained tasks. Different properties are also find to display different sensitivity to attraction effects. We detect that toxicity possesses significantly stronger attractors than positivity, difficulty and length. As for the effect of model, we observe significantly weaker attraction for Llama3-70b compared to GPT3.5, Llama3-8B and Mixtral-8x7b.\nAs for the position of the attractors, we observe the attractor for toxicity is significantly higher for Llama3-8b than for GPT3.5 and Mixtral-8x7b, and significantly higher for Llama3-70b than for GPT3.5, Mistral-7b and Mixtral-8x7b. It is also higher for Continue than for Rephrase. For positivity, we found that the position of the attractor was significantly lower for Llama3-8b than for GPT3.5, Mistral-7b and Mixtral-8x7b, and that the task Take inspiration and Continue both led to significantly higher positivity than the Rephrase task."}, {"title": "4.4 To what extent do different transmission chains converge on similar content?", "content": "Lastly, we investigate the extent to which iterated transmissions lead different chains to diverge or converge as determined by whether the between-chain similarity among generated texts increases or decreases after several generations. This can be measured by assessing the cosine similarity between final text embeddings versus the cosine similarity between initial text embeddings for each possible pair of chains, for each model and task (Figure 7).\nAs expected given the nature of the task, chains instructed with the Rephrase task maintained close similarity with the initial text (Figure 7). Out of the five model tested, Llama3-8B was more likely to maintain semantic similarity across generations for this prompt. For Take inspiration and Rephrase, there seems to be a tendency for chains to lead to a specific distance between final texts, as the initial distance between texts has little impact on the final distance. This means that over generations, chains that started with very similar texts diverge while chains that started with very different texts converge. The position of this attractor appears to be influenced by the model, as for example Llama3-8b displays much more convergence than the two other models for the Take inspiration task."}, {"title": "5 Discussion", "content": "While current studies analyzing the outputs of LLMs are restricted to a single prompt-output interac- tion, we borrowed the methodology from studies on human cultural evolution to address how cultural content may evolve over transmission chains with LLMs. This resulted in a series of telephone game experiments assessing the evolution of cultural content in LLMs as a function of models, instructions,"}, {"title": "Limitations and future work", "content": "As the study of the cultural dynamics of generative agents is an emerging research area, our setting involved several simplifications. While we focused on linear transmission chains, real-world interactions typically involve networks of senders and receivers. Human studies have shown that network size [28, 60, 4, 6, 21] and structure [58, 38, 22, 19, 23] influence cultural evolution. Following some initial endeavors [50, 53], future work may assess similar effects in machine networks. To investigate model- and task-specific biases, we studied transmission chains in homogeneous settings, where agents belonged to the same model type and received the same instructions, but future studies may address cultural dynamics in heterogeneous populations of LLMs prompted with various instructions. While we focused on LLM and, therefore, text outputs, similar studies may be run to address the properties of various generative tools (e.g., for image generation). In the future, researchers may also address hybrid networks in which humans and LLMs interact \u2014 a scenario that is becoming increasingly relevant as generative tools become more widespread and which may, in turn, shape the future of human cultural evolution. [10]."}, {"title": "A Additional details on the methods", "content": "Selecting initial texts We extracted 5 scientific abstracts 10, 10 news articles 11, and 5 social media comments 12 from online datasets as initial texts. To ensure that those initial texts covered the range of text properties we were interested in, we proceeded as follows: for difficulty, we measured the maximal and minimal difficulty $d_{min}$ and $d_{max}$ of texts from the scientific abstracts datasets, defined a linear space of 5 values $(d_i)_{i=1:5}$ between $d_{min}$ and $d_{max}$ and sampled 5 texts, each having a value"}, {"title": "Measuring text properties", "content": "\u2022 Toxicity. We assess the level of toxicity in generated texts using the Detoxify library, a classifier developed for the Jigsaw Toxic Comment Classification Challenges (see https://github.com/unitaryai/detoxify/tree/master. This classifier defines toxicity as the presence of rude, disrespectful, or unreasonable language in a text and assigns a probability score ranging from 0.0 (benign and non-toxic) to 1.0 (highly likely to be toxic). Trained on a large dataset of human-labeled comments from various online platforms, the classifier use a transformer-based architecture to analyze the text's context and meaning, identifying patterns indicative of toxicity.\n\u2022 Positivity. We employ the SentimentIntensityAnalyzer tool from the NLTK library to assess the positivity of generated texts. The tool is based on the Valence Aware Dictionary and sentiment Reasoner (VADER) method [35], which is a lexicon and rule-based sentiment analysis tool specifically designed for social media data. It uses a combination of lexical features, such as words and their semantic orientation, to determine the over- all sentiment of a text. In the VADER method, every word in the vocabulary is rated with respect to its positive or negative sentiment and the intensity of that sentiment. The SentimentIntensityAnalyzer uses this information to calculate a sentiment score for the text, ranging from -1.0 (highly negative) to 1.0 (highly positive).\n\u2022 Difficulty. We estimate the difficulty of generated texts using the Gunning-Fog index. In the method, complex words are defined as those with three or more syllables, excluding proper nouns, familiar jargon (and removing common suffixes as syllables). We used textstat to compute it."}, {"title": "B Additional figures and analyses", "content": "Statistical models We performed statistical analyses using the Python package pymc [75] to fit Bayesian models.\n\u2022 Model 1 We fitted a model predicting the attractor strength (Figure 6) as a function of the Task, Model and Property: $Strength \\sim N(\\mu, \\sigma^2)$\nwhere $\\mu = \\alpha_{Task} + \\beta_{Model} + \\gamma_{Property}$\nPriors for parameters a, b and c were standard normal distribution, and standard half-normal distribution for $\\sigma$.\n\u2022 Model 2 For each Property, we fitted a model predicting the attractor position (Figure 6) as a function of the Task and Model: $Position_{property} \\sim N(\\mu, \\sigma^2)$\nwhere $\\mu = \\alpha_{Task} + \\beta_{Model}$"}]}