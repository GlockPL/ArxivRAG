{"title": "Deformable Image Registration with Multi-scale Feature Fusion from Shared Encoder, Auxiliary and Pyramid Decoders", "authors": ["Hongchao Zhou", "Shunbo Hu"], "abstract": "In this work, we propose a novel deformable convolutional pyramid network for unsupervised image registration. Specifically, the proposed network enhances the traditional pyramid network by adding an additional shared auxiliary decoder for image pairs. This decoder pro- vides multi-scale high-level feature information from unblended image pairs for the registration task. During the registration process, we also design a multi-scale feature fusion block to extract the most beneficial features for the registration task from both global and local contexts. Validation results indicate that this method can capture complex de- formations while achieving higher registration accuracy and maintaining smooth and plausible deformations.", "sections": [{"title": "1 Introduction", "content": "Deformable image registration (DIR) is a basic task in the field of computer vision, which is widely used in medical diagnosis, surgical guidance, disease de- tection and so on, with the goal of determining an optimal spatial transformation that warps the moving image and align it with the corresponding fixed image. Traditional methods [5,4] usually treat DIR as an optimization task, trying to minimize the energy function in an iterative manner, but it requires a lot of computation and long processing time.\nThese limitations have spurred the rapid development of deep learning-based DIR methods. Recently, deep learning DIR methods, especially unsupervised ap- proaches [2,12], have gained significant attention due to their ability to operate without any labeled data. Pyramid network [7,11] have shown exceptional per- formance in recent unsupervised methods. Specifically, in a pyramid network, the moving and fixed images are typically encoded separately with shared parame- ters. Their multi-scale features are then sent to the decoder to achieve coarse to fine registration."}, {"title": "2 Method", "content": "The proposed method mainly consists of a shared encoder, a shared auxiliary decoder and a fusion pyramid decoder. The fusion pyramid decoder includes five scales. Except for the smallest scale, each scale is constructed by MSFB. The pyramid decoder first merges the smallest scale low-level features and predicts the coarse DDF. This DDF is then upsampled and applied to the moving feature map at the current scale. The moving feature map, the fixed feature map, and the high-level moving and fixed features from the shared auxiliary decoder at the same scale are input into the MSFB. This process removes redundant infor- mation and produces fused features, predicting the DDF at the current scale.\nThe subsequent process is the same as the current scale, with the final refined DDF obtained by iteratively combining the coarse DDFs from each scale.\nIn our method, we choose to use normalized cross-correlation $L_{ncc}$ [9] and deformation regularization $L_{reg}$ [1] to train the network. Thus, the total loss L is expressed as:\n$L = \u2212(\u03b1L_{ncc}(I_f, I_m \u25e6 \u03c6) + \u03b2L_{ncc}(I_f, I_m \u25e6 \u03a6)) + \u03bbL_{reg}(\u03a6), (1)$\nwhere \u03c6 is obtained by sampling the DDF at the scale of 80\u00d7112\u00d796. We first calculate the deformation using \u03c6. This approach optimizes the auxiliary de- coder during back propagation and provides the fusion pyramid decoder with deformation-included feature information, leading to more accurate deforma- tions. The parameters \u03b1, \u03b2 and \u03bb are hyperparameters. In the experiments, we set \u03b1 to 0.7, \u03b2 to 0.3, and \u03bb to 1."}, {"title": "3 Results", "content": "Dateset and preprocessing We evaluate our method by performing registra- tion on the dataset from the LUMIR task [3,8,10] in the Learn2Reg challenge. The dataset contains 3384 training images. For each calculation, we randomly select two images as the moving and fixed images, resulting in a total of 1692 image pairs. Additionally, a validation set consisting of 40 images is provided, forming 38 pairs for validation purposes. All images are converted to NIfTI, re- sampled, and cropped to size of 160\u00d7224\u00d7192 with a voxel spacing of 1\u00d71\u00d71 mm\u00b3.\nEvaluation criteria To assess registration performance, we utilize the Dice score (Dice), Target registration error (TRE) and 95% Hausdorff Distance(HdDist95)."}, {"title": "4 Discussion", "content": "Our method extends the traditional pyramid network by leveraging multi-scale fusion feature information from three sources: low-level encoder, high-level aux- iliary decoder, global and local fusion pyramid decoder, which enhances the network's understanding of image details and global structures. Additionally, our designed MSFB effectively filters out redundant information and retains key features from both global and local perspectives, further improving registration performance.\nExperiments show that our method effectively handles large deformation is- sues. Additionally, due to our MSFB, the fusion features provide more accurate detail information for the registration task, allowing our method to refine the registration across different scales and achieve higher performance. Overall, our method not only enhances registration performance but also ensures smooth and plausible deformations."}]}