{"title": "Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning", "authors": ["Muzhi Li", "Cehao Yang", "Chengjin Xu", "Zixing Song", "Xuhui Jiang", "Jian Guo", "Ho-fung Leung", "Irwin King"], "abstract": "Inductive knowledge graph completion (KGC) aims to predict missing triples with unseen entities. Recent works focus on modeling reasoning paths between the head and tail entity as direct supporting evidence. However, these methods depend heavily on the existence and quality of reasoning paths, which limits their general applicability in different scenarios. In addition, we observe that latent type constraints and neighboring facts inherent in KGs are also vital in inferring missing triples. To effectively utilize all useful information in KGs, we introduce CATS, a novel context-aware inductive KGC solution. With sufficient guidance from proper prompts and supervised fine-tuning, CATS activates the strong semantic understanding and reasoning capabilities of large language models to assess the existence of query triples, which consist of two modules. First, the type-aware reasoning module evaluates whether the candidate entity matches the latent entity type as required by the query relation. Then, the subgraph reasoning module selects relevant reasoning paths and neighboring facts, and evaluates their correlation to the query triple. Experiment results on three widely used datasets demonstrate that CATS significantly outperforms state-of-the-art methods in 16 out of 18 transductive, inductive, and few-shot settings with an average absolute MRR improvement of 7.2%.", "sections": [{"title": "Introduction", "content": "Knowledge Graphs (KGs) are graph-structured knowledge bases that represent facts with triples in the form of (head entity, relation, tail entity). KGs become essential in various downstream applications such as question answering (Sun et al. 2024), fact checking (Kim et al. 2023), and recommendation systems (Wang et al. 2019). In practice, most real-world KGs are incomplete, which highlights the significance of the knowledge graph completion (KGC) (or relation prediction) task, which aims to predict the missing head or tail entity from the query triples.\nExisting approaches to the KGC task usually perform well under an \u201ctransductive setting", "inductive\\\" KGC task requires the model to handle newly emerged entities, which is more reflective of real-world scenarios, as KGs are continuously evolving. The inductive setting highlights the importance of three key contexts inherent in KGs, namely entity types, reasoning paths, and neighboring facts. First, relations within KGs impose latent type constraints to head and tail entities being connected, which are crucial in inferring potential missing triples. For instance, the relation works in typically connects a person (head) and a location (tail). Although we have not encountered newly emerged entities during training, a triple can still be considered plausible if the head and tail entities conform to the implicit types as required by the relation.\nSecond, reasoning paths provide direct clues for the existence of missing triple (Zha, Chen, and Yan 2022). However, these paths can be unreliable in certain contexts. For example, in Figure 1, if the training set contains numerous triples such as (Joe Biden, works in, Washington, D.C.), (Washington, D.C., city of, U.S.), and (Joe Biden, has nationality, U.S.), the model may come up with some rules like (works in + city of = has nationality). It should be noted that such implicit rules do not invariably apply. A notable counterexample is Ant\u00f3nio Guterres, who works in New York City as the Secretary-General of the United Nations.\nFinally, neighboring facts of the head and tail entities also provide valuable clues for triple completion. For instance, in Figure 1, it is difficult to predict entity \u201cAnt\u00f3nio Guterres\" has a Portuguese nationality solely based on the available reasoning path. Fortunately, the presence of specific neighboring facts such as (Ant\u00f3nio Guterres, born in, Lisbon) can help disambiguate the proper answer from the distracter.\nDespite great efforts, existing methods cannot fully utilize these contexts. Specifically, embedding-based methods (Bordes et al. 2013; Sun et al. 2019) need expensive re-training to embed unseen entities; GNN-based methods (Schlichtkrull et al. 2018; Teru, Denis, and Hamilton 2020) are less robust when few connections between existing and new entities are available; path-based methods (Das et al. 2018; Zha, Chen, and Yan 2022) rely strongly on the existence and reliability of reasoning paths between certain entities; text-enhanced methods disregard entity type properties in KGs.\nA direct and promising approach to effectively utilize the three types of contexts is the integration of large language models (LLMs). On the one hand, LLMs, trained on extensive corpora, possess a fundamental understanding of the type of KG entities. On the other hand, the strong semantic understanding and reasoning capabilities enable LLMs to capture crucial information from triples and paths (Liao et al. 2024). Nevertheless, existing LLM-based KGC methods (Wei et al. 2023; Liu et al. 2024) can only re-rank candidate answers provided by previous KGC approaches. Consequently, they are inevitably constrained by the limitations of preceding models. Moreover, these approaches rely on additional triples from the validation set for in-context demonstration (Wei et al. 2023) or supervised fine-tuning (Liu et al. 2024), which can lead to severe information leakage when being applied to inductive scenarios.\nThis paper proposes \u201cCATS": "a novel Context-Aware approach for the inductive KGC task based on latent Type constraints and Subgraph reasoning. Considering the semantic gap between natural language sentences and structural KG triples, CATS fine-tunes and guides LLMs to assess the existence of potential missing triples from two perspectives. First, the Type-Aware Reasoning (TAR) module evaluates whether the candidate entity conforms to the implicit type constrained by the relation. Since explicit type annotations are not prevalent for entities in non-encyclopedic KGs (e.g. Wordnet), we instead assess whether the candidate head/tail entity and other head/tail entities connected by the same relation belong to the same entity type. Then, the Subgraph Reasoning (SR) module proposes a degree-based filtering mechanism to select meaningful paths, and takes relevant neighboring facts of the head and tail entity into consideration. The superior long-context understanding capabilities of LLMs allow the SR module to comprehensively evaluate whether different paths and neighboring facts support the existence of the specific triple. Finally, we ensemble the inference results based on the scorings obtained from the two modules mentioned above.\nWe conduct extensive experiments on three widely used datasets: WN18RR, FB15k237, and NELL-995. The best variant of CATS significantly outperforms state-of-the-art approaches in 16 out of 18 transductive, inductive, and few-shot settings with an average absolute improvement of 7.2% in MRR and 10.1% in Hits@1. These results highlight the importance of incorporating the three types of contexts in KGs. Furthermore, ablation studies on various LLMs and configurations show that the effectiveness of the proposed method does not rely on internal knowledge and the scale of LLMs. Our contributions are summarized as follows:\n\u2022 We propose CATS, the first LLM-based inductive KGC solution capable of handling unseen entities without any external knowledge or prior inference results.\n\u2022 We devise two novel triple evaluation mechanisms based on latent type constraints, as well as the reasoning paths and neighboring facts within the local subgraph.\n\u2022 We conduct extensive experiments to evaluate the effectiveness of CATS in different settings, and discuss the contribution of each component and the LLM in detail."}, {"title": "Related Works", "content": "Embedding-based Methods. The majority of KGC methods rely on KG embeddings, such as TransE (Bordes et al. 2013), RotatE (Sun et al. 2019), and GIE (Cao et al. 2022). These methods learn a set of low-dimensional embeddings for each entity and relation within the KG with certain geometric assumptions, which are inherently transductive. However, they require costly retraining to handle unseen entities (Zha, Chen, and Yan 2022), limiting their adaptability to inductive scenarios.\nGraph Neural Network (GNN)-based Methods. Graph Neural Networks (GNNs) (Song, Zhang, and King 2023b,a) are popular in natural language processing for modeling relationships between entities (Ma et al. 2023). GNN-based methods such as CompGCN (Vashishth et al. 2020), RGCN (Schlichtkrull et al. 2018), and WGCN (Zhao et al. 2021) embed entities in a KG by iteratively aggregating features from the local neighborhood. Nevertheless, these approaches struggle to produce meaningful embeddings for newly emerged entities with few links to existing ones, and are not applicable to entirely new graphs (Zha, Chen, and Yan 2022). To conform to the inductive setting, GraIL (Teru, Denis, and Hamilton 2020), and TACT (Chen et al. 2021) embed entities in the local subgraph with their distances to the head and tail entities of the query triple. However, such an embedding approach fails to distinguish different entities that share the same relative position. Consequently, it cannot perform well when the subgraph of query triple is large.\nPath-based Methods. Path-based methods aim to mine rules from the co-existences of certain reasoning paths connecting the head and tail entities in a triple and the relation between them (Meilicke et al. 2018). In particular, DeepPath (Xiong, Hoang, and Wang 2017) and MINERVA (Das et al. 2018) exploit random-walk with reinforcement learning to generate reasoning paths, while BERTRL (Zha, Chen, and Yan 2022) and KRST (Su et al. 2023) leverage breadth-first search. However, the existence and quality of reasoning paths between unseen entities is not ensured (Su et al. 2024), which inevitably limits their generality.\nText-enhanced Methods. In addition to the graph structure, the textual information provided in the KG also entails valuable semantic knowledge (Li et al. 2024). Recently, several KGC methods such as KG-BERT (Yao, Mao, and Luo 2019), BERTRL (Zha, Chen, and Yan 2022), and KRST (Su et al. 2023) employ PLMs to embed entities, relations, and reasoning paths with textual labels and descriptions. APST (Su et al. 2024) further introduces incomplete anchor paths for unseen entities that are not connected with any reasoning paths, achieving state-of-the-art performance. As the authors stated in (Zha, Chen, and Yan 2022), combining multiple reasoning paths encourages knowledge interactions. Nevertheless, their BERT-based backbone PLMs (Devlin et al. 2019) can only each reasoning path independently, leaving significant room for improvements."}, {"title": "Preliminaries", "content": "Problem Specification. A knowledge graph (or \"KG\" denoted as G = {E,R,T} consists of a set of triples T = {(h,r,t)} where head and tail entities h,t \u2208 E, relation r\u2208 R. E and R denote the set of entities and relations, respectively. Following the convention of (Teru, Denis, and Hamilton 2020; Su et al. 2023, 2024), the task of inductive knowledge graph completion is defined as follows:\nDefinition 1 (Inductive KGC): Given a training graph Gtrain = {Etrain, Rtrain, Ttrain} and a test graph Gtest = {Etest, Rtest, Ttest, the inductive KGC task aims to complete the missing head or tail entity from a set of query triples Q =\nQ\n{hq, rq, tq}q=1 such that Etrain \u2229 Etest = \u00d8, Rtest \u2286 Rtrain,\nq, hq, tq \u2208 Etest, rq \u2208 Rtest\u00b7\nThe settings of the inductive KGC task ensure that entities in the training and test KGs form two disjoint sets. Only the triples in the training graph can be used in model training, while triples in the test graph are provided as evidence for query triple completion. Handling unseen entities requires the model to have inductive reasoning capabilities.\nType properties of entities. Apart from triples, entities within a KG are often annotated with entity types (or categories) in an ontological taxonomy (Hao et al. 2019). For instance, in Freebase (Bollacker et al. 2008), entity \u201cAlbert Einstein\" belongs to the \u201c/scientist/physicist\" type. In general, entity types provide a high-level summary of the salient properties of their instance entities, which play a crucial role in judging whether a specific entity is a plausible head or tail of a specific query relation. Nonetheless, explicit type annotations are typically scarce for entities in non-encyclopedic KGs like Wordnet.\nReasoning paths. Since entities in the test graph are not encountered during training, recent state-of-the-art methods (Su et al. 2023, 2024) leverage reasoning paths to make predictions.\nDefinition 2 (Reasoning Path): Given a query triple (hq, rq, tq), a reasoning path is a sequence of triples that connects head entity hq and tail entity tq. Formally, we have:\n$p(h_q,t_q) = h_q \\rightarrow e_1, \\rightarrow e_2, ..., \\rightarrow e_n \\rightarrow t_q,$\nwhich satisfies Vi, (ei, ri, ei+1) \u2208 T and \u2200j,rj \u2260 rq. Tx denotes Ttrain during training and Ttest for model evaluation. However, the existence and quality of reasoning paths are not guaranteed, especially in few-shot scenarios. For instance, our statistics in Figure 2 show that reasoning paths are unavailable for 61 of the 205 query triples in the test split of the FB15k-237 (inductive) dataset."}, {"title": "Methodology", "content": "Figure 3 shows the end-to-end architecture of the proposed CATS framework. To get rid of the reliance on explicit type annotations, we devise a more generalized approach to exploit latent type constraints w.r.t. relations in the Type-Aware Reasoning (TAR) module. In addition, we incorporate relevant neighboring facts and reasoning paths to support triple assessment in the Subgraph Reasoning (SR) module. Furthermore, we discuss our LLM supervised fine-tuning (SFT) strategy, and aggregate our final predictions for query triples.\nType-aware Reasoning (TAR)\nIn KGs, entities connected by the same relation often possess similar attributes and characteristics, thereby belonging to the same entity type. Therefore, when determining whether an unknown entity is the head or tail entity of a triple, we need to confirm that the entity conforms to the type dictated by the relation. In practice, type properties are not explicitly available for all entities in the KG. A direct solution is to employ LLMs to annotate type information for each candidate entity, and to summarize common type for entities connected by the particular relation. However, an entity may belong to multiple types with different granularities in different domains. For instance, in Freebase, entity Nick Mason corresponds to type person, film actor, and book author. Without clear guidance from explicit type annotations, the type output from the LLM will be unstable.\nInstead of explicitly conducting entity typing, we guide the LLM to evaluate the plausibility of a triple by implicitly considering the type relevance between the candidate head/tail entity and other head/tail entities connected by the same relation. Figure 3 (top-right) shows the detailed prompts. For each query triple (hq, rq, tq), we first sample a set of k triples Sr with the same relation rq as demonstrations. Formally, we have S\u2081 = {(h,rq,t)|h,t \u2208 E \\ {hq,tc}}. Then, we linearize these structural triples with the textual labels of entities and relations, which allows the LLM to summarize a latent type triple e.g. (art work, nominated for, award) between the set of head and tail entities. Finally, we provide the linearized query triple to the LLM, and ask the LLM to output \"Y\" if the query triple is consistent with the same pattern in terms of entity types and \u201cN\u201d otherwise.\nWe fine-tune the LLM with a contrastive learning strategy. For each triple (h,r,t) \u2208 Ttrain, we construct negative samples by replacing the head or tail entity with a random entity from the training graph Gtrain. Then, we utilize the following loss function for supervised fine-tuning:\n$L_{TAR} = \\sum_{(h,r,t) \\in T_{train}} log p(y = 'Y'|S_r; \\Theta) - \\sum_{(h,r,t) \\in T_{train}} log p(y = 'N'|S_r; \\Theta)),$ (2)\nwhere y denotes the first output token generated by the LLM, \u0398 denotes the model parameters, p(\u0177 = \u2018Y') is the estimated probability that triple (h, r, t) holds.\nSubgraph Reasoning (SR)\nWithin KGs, the knowledge about an entity is manifested in its local subgraph (Li et al. 2024). Simply considering the type of an entity is insufficient to assert that the candidate entity should be connected to certain entities with a specific relation. Recent studies (Zha, Chen, and Yan 2022; Su et al. 2023) have shown that reasoning paths provide direct evidence for the existence of a particular relation between two entities. Nevertheless, limited by the power of BERT-like pre-trained language models, each reasoning path has to be independently encoded and considered, which may lead to unreliable relation prediction results. Inspired by the powerful reasoning capabilities of LLMs, we can model the interactions between multiple reasoning paths and neighboring facts of the two entities in a query triple.\nPath extraction and filtering. Following the convention of (Su et al. 2023, 2024), we leverage breadth-first search (BFS) to extract reasoning paths connecting the two entities of the query triple. We only retain reasoning paths with a length less than or equal to n, as extraordinarily long paths contribute less to relation prediction. Moreover, we find that some high-frequency relations, such as \u201chas gender\u201d and \u201chas color\u201d, are meaningless for assessing the existence of other relations (Su et al. 2023). On the contrary, infrequent fine-grained relations such as \u201cappear in film\" usually offer more precise evidence. Hence, we devise a degree-based filtering mechanism to find out meaningful paths. Specifically, given a reasoning path p(hq, tq), we count the occurrences or for each relation r \u2208 p(hq,tq) in the training triple set Train. Then, we compute the degree of the reasoning path dp(hq,tq) by summing up the occurrences of all relations within the path. Formally, we have:\n$d_{p(h_q,t_q)} = \\sum_{r \\in p(h_q,t_q)} o_r = \\sum_{r \\in p(h_q,t_q)} \\sum_{(h,r',t) \\in T_{train}} 1(r = r'),$ (3)\nwhere 1(.) denotes the identifier function. Finally, for each query triple (hq, rq, tq), we select \u03b2 reasoning paths P(hq,tq) with the lowest degrees dp(hq,tq) for assessment, while the others are filtered out.\nNeighboring facts selection. Since the existence of reasoning paths is not guaranteed, we further adopt neighboring facts of the head and tail entities of the query triple as supplementary contexts. Specifically, for each query triple (hq, rq, tq), we first collect supporting triples containing the head entity hq or the tail entity tq from the training graph. Then, we embed the query triple and each supporting triple with \"bge-small-en v1.5\" (Chen et al. 2024) sentence transformer. To safeguard the accuracy of our assessment against irrelevant neighboring information, we select top o supporting triples which the embeddings have the highest cosine similarities to the query triple. Formally, we have\n$T_{h_q} = arg \\underset{(h_q,r,t) \\in T_{train}}{max} cos(f_{bge}(h_q, r, t), f_{bge} (h_q, r_q,t_q)),$ (4)\n$T_{t_q} = arg \\underset{(h,r,t_q) \\in T_{train}}{max} cos(f_{bge}(h, r, t_q), f_{bge} (h_q, r_q,t_q)),$ (5)\nwhere $cos(a, b) = \\frac{a*b}{\\left \\| a \\right \\| \\left \\| b \\right \\|}$, Tha and Tt, are selected supporting triples for hq and tq. Similarly, we design appropriate prompts to instruct the LLM to output \"Y\" if the given query triple can be supported by the aforementioned reasoning paths and neighboring triples and \"N\" otherwise (Figure 3 bottom). Then, we use the following loss function to fine-tune the LLM:\n$L_{SR} = \\sum_{(h,r,t) \\in T_{train}} log p(y = 'Y' |P(h_q,t_q), T_{h_q}, T_{t_q}; \\Theta) - \\sum_{(h,r,t) \\in T_{train}} log p(y = 'N' |P(h_q,t_q), T_{h_q}, T_{t_q}; \\Theta).$ (6)\nTriple Scoring\nDuring the inference stage, the commonly adopted evaluation metrics require the KGC model to rank (or score) each masked triple in the form of (h, r, ?) or (?, r,t) with a set of candidate entities. Motivated by the complementary relationship between type properties and structural context, we compose the final scoring of a triple s(h, r, t) by ensembling the probabilities that the LLM outputs \"Y\" based on the two kinds of prompts. Formally, we have\n$s(h,r,t) = \\frac{1}{2}(p(\\hat{y} = 'Y'|S_r; \\Theta)\n+ p(\\hat{y} = 'Y'|P(h,t), T_h, T_t; \\Theta)) .$ (7)\""}, {"title": "Experiments", "content": "Datasets and Evaluation Metrics\nWe evaluate our proposed method on three widely adopted benchmark KGS WN18RR, FB15k-237, and NELL-995 with their transductive and inductive subsets. Following the convention of (Zha, Chen, and Yan 2022; Su et al. 2023, 2024), we evaluate each query triple with 1 ground truth entity and 49 negative candidate entities. For a fair comparison, we use the same dataset splits and negative triples provided by (Zha, Chen, and Yan 2022). The detailed statistics of datasets are available in the technical appendix. We score the plausibility of the query triple with each candidate entity and rank them in descending order. The performance of our model is evaluated based on two metrics: Mean Reciprocal Rank (MRR) and Hits@1.\nBaselines and Experiment Settings\nWe compare the proposed framework with embedding-based methods RuleN and TuckER, GNN-based method GraIL, text-based methods KG-BERT, and path-based methods MINERVA, BERTRL, KRST and the state-of-the-art method APST. We select Qwen2-7B-Instruct (Yang et al. 2024) as our backbone LLM. The experimental results on Llama-3-8B (AI@Meta 2024) and Qwen2-1.5B are also included in our ablation studies. We employ LoRA (Hu et al. 2021) for parameter-efficient fine-tuning, setting the rank to 16 and \u03b1-value to 32. We use the AdamW optimizer (Loshchilov and Hutter 2017) to fine-tune the LLM with a learning rate of 1e-4, a per-device batch size of 2, and a gradient accumulation step of 4 iterations for 1 epoch only. For each query triple, we sample k = 3 supporting triples with the same relation, \u03b4 = 6 reasoning paths and \u03c3 = 6 neighboring facts. We construct the instruction set by generating 12 negative samples for each positive triple in Ttrain. All of our experiments are conducted on a server with 2 Intel Xeon Platinum 8358 processors and 8 NVIDIA A100 40G GPUs. On average, CATS takes 2.4 hours for SFT and 1.43s to evaluate and rank a single test sample.\nMain Results\nWe evaluate the proposed CATS framework on the three datasets in transductive and inductive settings. The \"TAR\u201d and \"SR\" variants of CATS severally utilize the probabilities generated by corresponding modules to score and rank each candidate entity. Experimental Results in Table 7 demonstrate that the CATS (full) significantly and consistently outperforms all baseline methods. Most notably, CATS (full) achieves double-digit absolute Hits@1 improvements of 12.8%, 16.2%, and 12.0% on the WN18RR, FB15k-237, and NELL-995 datasets under an inductive setting. Correspondingly, the improvements in transductive scenarios, namely 12.3%, 8.2%, and 12.2%, are also remarkable.\nAmong all CATS' variants, the majority of best results (4 out of 6 cases) are achieved by the \u201cfull\u201d variant, which exhibits the importance of considering latent type constraints and subgraph contexts. In comparison, the improvements observed with the TAR variant are less pronounced, indicating that while matching entity types may help filter out irrelevant entities, it is insufficient for delivering accurate relation predictions. Moreover, the TAR variant demonstrates improved effectiveness in transductive settings. The better performance can be credited to SFT, which enhances the LLM's understanding of the type properties of known entities. However, the training graph does not contain any contexts for unseen entities. Therefore, the LLM may not be able to precisely infer types for some of them, thereby compromising the performance of TAR in inductive scenarios. Conversely, the SR variant benefits from neighboring facts and reasoning paths sampled from the test graph, providing relevant contextual information for unseen entities and allowing it to achieve state-of-the-art performance on WN18RR and NELL-995 datasets in inductive settings.\nAblation Studies\nWe examine the effectiveness of each component of the proposed CATS framework in different settings by answering the following research questions (RQs)."}, {"title": "RQ1: Can CATS generate plausible inference results in few-shot scenarios?", "content": "Table 8 shows the experiment results on the three datasets with 1000 and 2000 triples in the training graph. In general, CATS achieves significant improvements for 10 out of 12 cases in terms of MRR compared to state-of-the-art methods. \u00a7 For the remaining cases, the performance gap to the best baseline method is marginal. Considering the three variants of CATS, TAR outperforms SR in transductive settings, while SR performs better in inductive scenarios. The disparity in performance can be attributed to the following reasons: Reducing the number of triples in the training graph significantly decreases the average degree of each entity. Consequently, it becomes challenging to sample a sufficient number of neighboring facts and reasoning paths for entities in the query triple, which diminishes the effectiveness of the SR variant. However, in most KGs, the number of relations is considerably smaller than the number of entities (|R| << |E|). Hence, we are still able to retrieve sufficient triples with the same relation from the training graph, which sustains the desirable performance of the TAR variant, and ensures the robustness of the the proposed framework. In inductive scenarios, neighboring facts and reasoning paths are sampled from the supplementary test graph. Hence, reducing training triples has subtle negative impacts on the effectiveness of the SR variant.\nOne may notice that CATS does not achieve stat-of-the-art performance on the NELL-995 dataset in transductive settings. This is attributed to the higher number of triples in the NELL-995 training graph. Selecting the subset of 1000 or 2000 triples results in an extremely sparse graph structure. Without external knowledge, the training graph may fail to provide sufficient support for the inference of certain triples, thereby lowering the performance ceiling. Moreover,"}, {"title": "RQ2: Do reasoning paths and neighboring facts improve the inference performance?", "content": "From the experimental results in Table 9, we observe that both reasoning paths and neighboring facts play a crucial role in enhancing inference performance. However, the contribution of neighboring triples is more pronounced. This reconfirms the key shortcoming of path-based methods, which struggle to assess query triples without suitable paths. In comparison, neighboring triples guarantee CATS's robustness and generality. Moreover, the performance decline resulting from the removal of the path filtering step emphasizes the effectiveness of the proposed degree-based filtering mechanism, further reaffirming that irrelevant reasoning paths may misdirect the evaluation of query triples."}, {"title": "RQ3: Can we simply attribute the performance improvement to extra knowledge inherent in the LLM?", "content": "We conduct additional experiments by presenting the query triple and corresponding entities to the LLM, prompting the model to make judgments with its internal knowledge. However, experimental results in Table 10 indicate that the LLM fails to make reliable assessments on KG triples in such a zero-shot setting (see Qwen2-7B w/o. all), showing that CATS does not benefit from the LLM's internal knowledge. Furthermore, the pre-trained LLM cannot adequately comprehend the contextual information (e.g., paths and triples) outlined in our prompts without proper guidance (see Qwen2-7B w/o SFT). The unsatisfactory performance underscores the substantial semantic gap between natural language sentences and KG triples, emphasizing the importance of SFT."}, {"title": "RQ4: Can we simply attribute the performance improvements to the power of LLMs?", "content": "We conduct an extra experiment by directly fine-tuning the LLM to evaluate the plausibility of query triples based solely on the triple itself (see Table 10 w/o. TAR & SR). The significant performance decline indicates the following: despite possessing enhanced semantic understanding capabilities, the LLM does not inherently know the appropriate method to evaluate a triple. On the one hand, the backbone LLM in this variant cannot recognize the importance of type relevance between the target entity and entities connected by the same relation. On the other hand, the process of SFT is insufficient to inject knowledge stored in KGs into the LLM. This reaffirms the significance of providing relevant guidance and structural contexts in the KGC task. Furthermore, we investigate whether combining prompts from the two reasoning modules improves the model performance (see Table 10 (comb.)). Our experiments show that the current adopted separated setting achieves better results in most of the (4 out of 6) cases."}, {"title": "RQ5: How does the selection of backbone LLM affect the experimental results?", "content": "In Table 10, we evaluate the performance of the proposed CATS framework on three LLMs, namely Llama3-8B, Qwen2-1.5B, and Qwen2-7B. The experimental results show that CATS significantly and consistently surpasses the state-of-the-art method with all these LLMs, demonstrating its broad effectiveness across different model scales and architectures. Most notably, CATS can still achieve desirable results with an 1.5B model, which significantly reduces the average inference time from 1.43s to 0.51s, showcasing a perfect balance between performance and efficiency. Furthermore, the performance improvements observed with the Qwen2-7B model indicate that increasing the model size is likely to yield better results. Since comparison among different LLMs is not the primary focus, this paper does not explore the performance of CATS with larger LLMs due to time and resource constraints."}, {"title": "Conclusion", "content": "In this paper, we propose CATS, a novel context-aware approach for knowledge graph completion. CATS is designed to guide the LLM to assess the plausibility of query triples based on latent type constraints, selected reasoning paths, and relevant neighboring facts. With sufficient guidance from proper prompts and SFT, CATS achieves state-of-the-art performance in transductive, inductive, and few-shot scenarios, showing its robustness and generality. Overall, CATS demonstrates the potential of leveraging LLMs in conducting knowledge-intensive reasoning tasks on structural data. In the future, we aim to incorporate LLMs in more complicated KG-related tasks such as complex query answering."}]}