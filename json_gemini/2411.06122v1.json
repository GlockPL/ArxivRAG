{"title": "Characteristics of Political Misinformation Over the Past Decade", "authors": ["Erik J. Schlicht"], "abstract": "Although misinformation tends to spread online, it can have serious real-world consequences. In order to develop automated tools to detect and mitigate the impact of misinformation, researchers must leverage algorithms that can adapt to the modality (text, images and video), the source, and the content of the false information. However, these characteristics tend to change dynamically across time, making it challenging to develop robust algorithms to fight misinformation spread. Therefore, this paper uses natural language processing to find common characteristics of political misinformation over a twelve year period. The results show that misinformation has increased dramatically in recent years and that it has increasingly started to be shared from sources with primary information modalities of text and images (e.g., Facebook and Instagram), although video sharing sources containing misinformation are starting to increase (e.g., TikTok). Moreover, it was discovered that statements expressing misinformation contain more negative sentiment than accurate information. However, the sentiment associated with both accurate and inaccurate information has trended downward, indicating a generally more negative tone in political statements across time. Finally, recurring misinformation categories were uncovered that occur over multiple years, which may imply that people tend to share inaccurate statements around information they fear or don't understand (Science and Medicine, Crime, Religion), impacts them directly (Policy, Election Integrity, Economic) or Public Figures who are salient in their daily lives. Together, it is hoped that these insights will assist researchers in developing algorithms that are temporally invariant and capable of detecting and mitigating misinformation across time.", "sections": [{"title": "1 Introduction", "content": "Misinformation is a statement that contains false or misleading information, and can result in serious consequences, including the erosion of civil discourse, political paralysis, uncertainty, in addition to alienation and disengagement (Kavanagh & Rich, 2018; Hook & Verdeja, 2022). Despite its serious impact on individuals and society, misinformation is known to be shared more than valid information (Vosoughi, et al, 2018), and the reasons that misinformation is propagated are diverse and include cognitive factors (Del Vicario, et al, 2016; Ecker, et al, 2022), socio-affective factors (Ecker, et al, 2022), incentives (Ceylan, et al, 2023) and changes in the information system (Kavanagh & Rich, 2018, Chen et al, 2023).\nAs a result, finding scalable solutions to detect and mitigate the impact of misinformation has proven challenging, although many efforts have demonstrated some promise (Conroy, et al., 2015; ,Aldwairi & Aldwairi, 2018, RAND, 2018). Part of the challenge facing researchers is that misinformation can be propagated through many modalities (e.g., text, image and video), thereby increasing the"}, {"title": "2 PolitiFact Data", "content": "In order to investigate trends in political misinformation across time, twelve years of fact-checked PolitiFact data was obtained, ranging between 2011 through 2023. PolitiFact is owned by the nonprofit Poyneter Institute for Media with the objective of improving the relevance, ethical practice and value of journalism. As part of that objective, PolitiFact verifies the accuracy of claims made throughout various online and media sources. By using this fact-checked information, it offers a source of ground-truth for information accuracy with relatively high confidence.\nApproximately sixteen thousand statements were collected across twelve years, and further classified into three categories:\n\u2022 Accurate: this information class was given to fact-checked ratings with TRUTH-O-METER scores of TRUE or MOSTLY-TRUE.\n\u2022 Misinformation: this information class was given to fact-checked ratings with TRUTH-O-METER scores of PANTS-ON-FIRE or FALSE.\n\u2022 Mixed-Accuracy: this information class was given to fact-checked ratings with all other TRUTH-O-METER ratings not contained in the classes above.\nThis statement classification resulted in the following distribution of information accuracy in the sample:"}, {"title": "3 Trends in Information Accuracy", "content": "Figure 1 shows how political information accuracy has changed across time. It is apparent that political misinformation has increased over time, starting around 2017 (red dashed line), when it first became more frequent than accurate or mixed-accuracy information. It is interesting to note that this is eleven years after the public launch of Facebook and Twitter (2006), and according to Oberlo.com, this was a time when Facebook had approximately two billion users.\nThe approximately ten year window that it took for misinformation to surface on PolitFact following the launch of major social media sites can be due to a number of reasons including the time it takes"}, {"title": "4 Misinformation Source Modality Trends", "content": "Since the modality in which misinformation is conveyed (text, images or video) impacts the algo-rithmic complexity and computational resources necessary to deploy solutions, it is important to understand trends across time. Figure 2 shows the primary information modality associated with misinformation sources that were responsible for at least five PollitiFact statements for a given year. For example, Facebook and Twitter (now Meta and X) both have a primary modality of text, since most of the posts shared on these sites are written in text, whereas Instagram and TikTok would be examples of sources with a primary modality of image and video, respectively. Finally, misinformation statements associated with sources that are entities are labeled with a source modality of individual.\nIt is apparent that misinformation from sources that are primarily in text form increased around 2017, eleven years after the launch of Facebook and Twitter, whereas misinformation from sources associated with images started to increase around 2019, only nine years after the public launch of Instagram. Moreover, misinformation from sources with a primary modality of video started to appear in 2020. If misinformation associated with videos follow similar trends as text and images, it would predict an uptick in this modality in the next few years, as TikTok was launched internationally in 2017.\nAs a result of the multimodal nature of contemporary misinformation, researchers should no longer rely exclusively on algorithms associated with text (natural language processing) or images/video (computer vision) alone, and transition to multimodality versions available models. Alternatively, they may choose to deploy independent models to detect and mitigate for each modality, but this may require additional complexity.\nRegardless of the solution, these results demonstrate that political misinformation now spans the modality spectrum (Figure 2) and that misinformation has been trending upward in recent years (Figure 1). Next, tools from natural language processing will be used to explore the sentiment associated with both accurate and inaccurate information across time."}, {"title": "5 Information Sentiment Trends", "content": "Previous research found that misinformation relies on emotional content, such as appealing to morality and statements with negative sentiment (Carrasco-Farre, 2022). Therefore, this section explores the sentiment associated with political statements sampled in this study by leveraging the compound score produced by VADER (Hutto & Gilbert, 2014). This score ranges between -1 and +1, with scores less than 0 corresponding to a statement with negative sentiment, scores greater than 0 corresponding to statements with positive sentiment, and scores around 0 corresponding to neutral statements.\nBy averaging the compound sentiment scores across years (Figure 3), similar trends were realized where misinformation was associated with more negative sentiment (Mean = -.08, SEM = .004) than accurate statements (Mean = -.03, SEM = .007). A Mann-Whitney U-test found these differences to be significant (p<.001). This supports the notion that misinformation relies on emotional content to propagate at higher rates than valid information (e.g., clickbait)."}, {"title": "6 Misinformation Topics Across Years", "content": "Another line of investigation explored in this effort was to use a new technique in natural language processing (BERTopic) to discover topics associated with PolitiFact statements (Grootendorst, 2022). The model uses document embeddings to cluster into coherent topics in order to uncover themes in text. Misinformation statements from each year were input into the algorithm, allowing it to converge on the best number and type of clusters for each year independently (Table 3).\nSubjective descriptions were provided for each cluster/topic to better understand common topics across years. Table 3 shows each of these topic descriptions with the number of misinformation statements that are associated with each topic. The number of topics BERTopic converged on increased across time, suggesting that not only is there more misinformation in recent years (Figure 1), but that it spans a greater number of topics (Table 3). Note that the topic description corresponds to the primary theme or entity associated with each cluster. In the case of entities, it does not discriminate between those where the entity was the target of misinformation or if they were responsible for stating the misinformation."}, {"title": "7 Recurring Misinformation Topics", "content": "In order to facilitate insights into topics that occur across multiple years, Figure 5 depicts recurring topics and the number of statements that correspond to each recurring topic. The number of years topics recur ranges between two and seven years, with Mass Shootings and Barack Obama occurring most frequently across years. However, when focusing on the total number of statements that correspond to each recurring topic, Joe Biden and COVID are the topics that correspond to the greatest number of misinformation statements."}, {"title": "8 Conclusions", "content": "Overall, these results suggest that the advent of social media has allowed misinformation to propagate more rapidly, spanning a greater number of topics and modalities (Figures 1 & 2, Table 3). Moreover, the sentiment results (Figure 3) support the idea that misinformation appeals to people's emotions through negative claims (Grootendorst, 2022) that are often shared at higher rates than accurate information (Vosoughi, et al, 2018). What's more, the sentiment trends across time show that accurate information has also adopted a slightly more negative tone, which may imply that valid information is starting to be portrayed in an emotional context to complete for the attention of readers (Figure 4).\nThis paper also uncovered several recurring topics of misinformation (Figure 5) spanning seven categories (Table 4), which provides insight into temporally invariant themes of misinformation. Taken in the context that misinformation is emotionally charged, these categories could suggest that people tend to share inaccurate statements around information they fear or don't understand (Science and Medicine, Crime, Religion), impacts them directly (Policy, Election Integrity, Economic) or Public Figures who are salient in their daily lives.\nThe impact of misinformation on our democracy has been well studied and includes the erosion of civil discourse, political paralysis, uncertainty, in addition to alienation and disengagement (Kavanagh & Rich, 2018; Hook & Verdeja, 2022). A necessary first condition to mitigating these outcomes is to reduce the availability of misinformation. Since social media provides the opportunity for misinformation to be spread rapidly, automated methods for detecting and removing inaccurate misinformation is one approach to accomplish this objective.\nAs a result, it is hoped that these insights will help researchers and engineers to develop robust algorithms to detect and mitigate misinformation. Whatever the solution, these algorithms will need"}]}