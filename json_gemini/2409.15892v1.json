{"title": "Symmetries and Expressive Requirements for Learning General Policies", "authors": ["Dominik Drexler", "Simon St\u00e5hlberg", "Blai Bonet", "Hector Geffner"], "abstract": "State symmetries play an important role in planning and generalized planning. In the first case, state symmetries can be used to reduce the size of the search; in the second, to reduce the size of the training set. In the case of general planning, however, it is also critical to distinguish non-symmetric states, i.e., states that represent non-isomorphic relational structures. However, while the language of first-order logic distinguishes non-symmetric states, the languages and architectures used to represent and learn general policies do not. In particular, recent approaches for learning general policies use state features derived from description logics or learned via graph neural networks (GNNs) that are known to be limited by the expressive power of C2, first-order logic with two variables and counting. In this work, we address the problem of detecting symmetries in planning and generalized planning and use the results to assess the expressive requirements for learning general policies over various planning domains. For this, we map planning states to plain graphs, run off-the-shelf algorithms to determine whether two states are isomorphic with respect to the goal, and run coloring algorithms to determine if C2 features computed logically or via GNNs distinguish non-isomorphic states. Symmetry detection results in more effective learning, while the failure to detect non-symmetries prevents general policies from being learned at all in certain domains.", "sections": [{"title": "1 Introduction", "content": "Generalized planning is concerned with the problem of obtaining general action strategies for solving classes of instances drawn from a common domain. A classical planning domain ensures that all instances share a structure given by a set of action schemas and predicates. These general strategies, called also general plans or policies, are learned by considering a small set of training instances from the target class Q (Srivastava, Immerman, and Zilberstein 2011; Jim\u00e9nez, Segovia-Aguas, and Jonsson 2019; Illanes and McIlraith 2019; Toyer et al. 2020; Yang et al. 2022; Srivastava 2022). General policies that solve the training instances are then expected to generalize to Q. In the symbolic setting, where the learning problem is formulated as a combinatorial optimization problem, this generalization can often be established formally (Bonet, Franc\u00e8s, and Geffner 2019; Franc\u00e8s, Bonet, and Geffner 2021). In the deep learning setting, the algorithms scale up better but do not result in policies that can be understood and proved to be correct (St\u00e5hlberg, Bonet, and Geffner 2022b; St\u00e5hlberg, Bonet, and Geffner 2023).\nThe computational bottleneck of the symbolic approach is that it considers the complete state space of the training instances, which becomes very large quickly. For example, in the Gripper domain, where the task is to move balls from one room to another, the state space contains more than 2n reachable states when the number of balls is n. It turns out, however, that many pairs of states in the training set are symmetric, meaning that a solution for one state implies a solution for the other. This suggests that the number of states for the training set can be significantly reduced by considering just one representative of each equivalent class of states.\nInterestingly, state symmetries play a second important role in generalized planning. Languages and neural architectures that lack the expressive power to distinguish pairs of states that are not symmetric may fail to represent general policies at all for certain domains. In particular, recent approaches for learning general policies that use state features derived from description logics or learned via graph neural networks (GNNs) (Franc\u00e8s, Bonet, and Geffner 2021; St\u00e5hlberg, Bonet, and Geffner 2024) are known to be limited by the expressive power of C2, first-order logic with two variables and counting (Barcel\u00f3 et al. 2020; Grohe 2021).\nIn this work, we address the problem of detecting symmetries in planning and generalized planning and use the results for two different purposes: to assess the expressive requirements for learning general policies over planning domains, which requires distinguishing non-symmetric states, and to speed up learning, which involves grouping symmetric states together. For detecting symmetries, we map planning states to plain graphs, run off-the-shelf graph algorithms to determine whether two states are isomorphic with respect to the goal, and run coloring algorithms to determine if C2 features computed logically or via GNNs distinguish non-isomorphic states. The expressive requirements and the performance gains are then evaluated experimentally.\nThe paper is organized as follows. After discussing related work, we review planning, generalized planning, and relational structures and graphs. Then, we introduce faithful and uniform abstractions, look at the notion of isomorphic relational structures (states) and the computation of such abstractions, carry out experiments, and draw conclusions."}, {"title": "2 Related Work", "content": "We discuss briefly three related research threads.\nSymmetries. The detection of symmetries in planning has been used to prune the search space (Shleyfman et al. 2015), to define heuristic functions (Edelkamp 2001; Haslum et al. 2007; Helmert et al. 2014; Nissim, Hoffmann, and Helmert 2011), and to transform the problem representation (Riddle et al. 2016). A common thread in these approaches, which contrasts with our approach, is that actions are explicitly considered in the detection of symmetries (Pochter, Zohar, and Rosenschein 2011; Sievers et al. 2019; Sievers et al. 2017).\nGeneral policies. The problem of learning general policies has a long history (Khardon 1999; Mart\u00edn and Geffner 2004; Fern, Yoon, and Givan 2006; Jim\u00e9nez, Segovia-Aguas, and Jonsson 2019). General, symbolic policies have been formulated in terms of logic (Srivastava, Immerman, and Zilberstein 2011; Illanes and McIlraith 2019), regression (Boutilier, Reiter, and Price 2001; Wang, Joshi, and Khardon 2008; Sanner and Boutilier 2009), and policy rules (Franc\u00e8s, Bonet, and Geffner 2021; Drexler, Seipp, and Geffner 2022; Yang et al. 2022; Srivastava 2023; Silver et al. 2024). General policies have also been learned using deep learning methods (Toyer et al. 2020; Bajpai, Garg, and others 2018; Rivlin, Hazan, and Karpas 2020; St\u00e5hlberg, Bonet, and Geffner 2022a), in many cases using graph neural networks or GNNs (Scarselli et al. 2009; Gilmer et al. 2017; Hamilton 2020).\nExpressivity. Interestingly, the expressive limitations of symbolic methods relying on features derived from the domain predicates via description logic grammars (Bonet, Franc\u00e8s, and Geffner 2019; Franc\u00e8s, Bonet, and Geffner 2021) and methods relying on GNNs (St\u00e5hlberg, Bonet, and Geffner 2022b; St\u00e5hlberg, Bonet, and Geffner 2023) are similar. Such methods cannot distinguish states (i.e., relational structures) that cannot be distinguished by C2, first-order logic with two variables and counting (Barcel\u00f3 et al. 2020; Grohe 2021), or equivalently, by the Weisfeiler-Leman (1-WL) coloring procedure (Cai, F\u00fcrer, and Immerman 1992; Morris et al. 2019; Xu et al. 2019). The consequences of this limitation have been analyzed by St\u00e5hlberg, Bonet, and Geffner (2022a), and more recently by Horc\u00edk and S\u00edr (2024). We will come back to this work in the discussion section."}, {"title": "3 Background", "content": "We review basic notions of planning, generalized planning, relational structures, and graphs."}, {"title": "3.1 Classical Planning", "content": "A planning problem is a pair $P = \\langle D, I\\rangle$ where $D$ is a general first-order domain containing a set of predicates (or relations) $R$, each with given arity, and a set of action schemas of the form (pre, eff) where pre is an arbitrary first-order formula and eff is an arbitrary effect, and $I$ is specific instance information that contains the set of objects $O$, and two sets of ground atoms, $Init$ and $Goal$, that describe the initial and goal situations, respectively. The problem P defines the state model $Sp = (S, s_1, G, Act, A, f)$ where the states in S are the truth valuations over the ground atoms, where each such valuation is represented by the set of atoms true in the valuation, $s_1 = Init$ is the initial state, and $G = \\{s \\in S \\mid Goal \\subseteq s\\}$ is the set of goal states. The function $A$ maps states s into the set $A(s)$ of ground actions from Act that are applicable in s, and the state transition function f maps states s and actions $a \\in A(s)$ into the resulting state $s' = f(s, a)$.\nThe unlabeled state model for the problem P is the tuple $Sp = (S, s_1, G, Succ)$ where the actions are compiled away, and states have a set of possible successor states instead. In this unlabeled model, the first three components are those for Sp, while $Succ = \\{(s, f(s, a)) \\mid a \\in A(s)\\}$ is the (unlabeled) successor relation.\nA trajectory seeded at state $s_0$ in $P$ is a state sequence $s_0, s_1,..., s_n$ such that $(s_i, s_{i+1})$ is in $Succ$, $0 \\leq i < n$. A state s is reachable in P if there is a trajectory seeded at the initial state $s_1$ that ends in s. For a reachable state s, a plan (resp. optimal plan) for s is a trajectory (resp. trajectory of minimum length) seeded at s that ends in a goal state. The length of an optimal plan for state s is denoted by $V*(s)$, and referred as the optimal cost of state s."}, {"title": "3.2 Generalized Planning", "content": "A generalized planning problem is a class $Q$ of planning problems $P$ for a common domain $D$ (Bonet and Geffner 2018). A general policy $\\pi$ for a class Q is a binary relation on states. A state trajectory $S_0, S_1,..., S_n$ is a $\\pi$-trajectory seeded at state $s_0$ if $(s_i, s_{i+1})$ is a transition that is in both P and $\\pi$, for $0 < i < n$. We say that: (1) $\\pi$ solves state s if each maximal $\\pi$-trajectory seeded at s reaches a goal state, (2) $\\pi$ solves problem $P$ if it solves the initial state of $P$, and (3) $\\pi$ solves class $Q$ if it solves each problem $P$ in $Q$.\nIn generalized planning, goals are encoded as part of the state as follows. For each atom $p(\\overline{o})$ that appears in the goal condition $G$, a new relational symbol $p_g$ of the same arity of $p$ is created. Then, the initial situation $I$ is extended with the atoms $\\{p_g(\\overline{o}) \\mid p(\\overline{o}) \\in G\\}$ which are static and thus remain in every reachable state (Mart\u00edn and Geffner 2004). Adding these \"goal atoms\" in the state allows general policies/sketches to take the specific goal of the instance into account, so they may generalize not just to instances with different numbers of objects and initial states, but also to instances with different goals.\nGeneral policies are often represented in terms of state features. A state feature for class $Q$ is a function that maps the reachable states s for the problems in $Q$ into values $\\phi(s)$. The feature $\\phi$ is Boolean if its values are Boolean values, and numerical if its values are non-negative integers. If $\\Phi$ is a set of features, $\\Phi(s)$ denotes the vector $(\\phi(s))_{\\phi \\in \\Phi}$."}, {"title": "3.3 States, Relational Structures, and Graphs", "content": "A (planning) state defines a relational structure $A_s$ with universe $U_S = O$ for the set of objects $O$ in s, and interpretations $R_A \\subseteq (U_s)^k$ for each predicate $R$ of arity $k$ in the planning domain $D$, where$\\langle o_1, o_2,..., o_k\\rangle \\in R$ iff $R(o_1, o_2,..., o_k)$ is true in s. The signature of a relational structure $A$ is the set of relational symbols in A. We assume fully relational structures that contain no functions nor constants (nullary functions). This type of structures are adequate for planning problems described in PDDL.\nWhile a planning state defines a relational structure, relational structures can be encoded by graphs, a mapping that we will use to test state equivalence. Recall that a directed graph, or graph, is a pair $G = (V, E)$ where $V$ is the set of vertices and $E \\subseteq V^2$ is the set of edges. An undirected graph is a directed graph $G$ where E is symmetric; i.e., $(v,w) \\in E$ iff $(w,v) \\in E$. Two graphs $G = (V, E)$ and $G' = (V', E')$ are isomorphic, denoted by $G \\approx_g G'$, if there is a bijection $f : V \\rightarrow V'$ such that $(u, v) \\in E$ iff $(f(u), f(v)) \\in E'$.\nA vertex-colored graph is a tuple $G = (V, E, \\lambda)$ where $(V, E)$ is a graph, and $X : V \\rightarrow C$ maps vertices to the colors in C. Two vertex-colored graphs $G = (V, E, \\lambda)$ and $G' = (V', E', \\lambda')$ are isomorphic, denoted as $G \\approx_g G'$, iff there is a color preserving isomorphism f from G to G', i.e., $\\lambda(v) = \\lambda' (f(v))$ for $v \\in V$. If the graphs G and G' are isomorphic via the bijection f, we write f: G \\rightarrow G'."}, {"title": "4 Abstractions", "content": "We formalize first the abstraction induced by an equivalence relation ~:\nDefinition 1 (Abstraction). Let Q be a class of problems, let ~ be an equivalence relation on the reachable states of the problems in Q, and let P be a problem in Q with unlabeled state model $Sp = (S,s_1,G,Succ)$. The abstraction of P induced by ~, denoted by $P/\\sim$, is the unlabeled state model $Sp = (\\widetilde{S}, [s_1], \\widetilde{G}, \\widetilde{Succ})$ where\n1. $\\widetilde{S} = \\{[s] \\mid s \\in S\\}$ is the set of equivalence classes for P,\n2. $[s_1]$ is the equivalence class for initial state $s_1$ of P,\n3. $\\widetilde{G} = \\{[s] \\mid s \\in G\\}$ is the set of goal classes, and\n4. $\\widetilde{Succ}\\{\\left([s], [s']\\right) \\mid (s, s') \\in Succ\\}$.\nThe abstraction $Q/\\sim$ is the class of abstractions $\\widetilde{S}_p$ for the problems $P$ in $Q$.\nThe successor relation in $\\widetilde{S}_p$ is the existential quantification of the successor relation in $S_p$ where $([s], [s']) \\in \\widetilde{Succ}$ iff there is a transition $(t, t')$ in Succ such that $s\\sim t$ and $s'\\sim t'$. In particular, the transition $(s, s')$ may not exist in P. Hence, generalized plans that solve the abstraction $\\widetilde{S}_p$ do not necessarily solve P. In the following, we write $(s, s') \\sim (t, t')$ to denote $s \\sim t$ and $s' \\sim t'$.\nDefinition 2 (Faithful Abstractions). Let $Q$ be a class of problems, and let ~ be an equivalence relation on the reachable states in $Q$. The abstraction $Q/\\sim$ is faithful iff\n1. for any $P$ in $Q$, any reachable transition $(s, s')$ in $P$, and any reachable state $t$ in $P$ with $t \\sim s$, there is a transition $(t, t')$ in $P$ such that $(s, s') \\sim (t, t')$, and\n2. if $s \\sim t$ for reachable states $s$ and $t$ in $P$, then s is a goal state iff t is a goal state."}, {"title": null, "content": "If the abstraction $Q/\\sim$ is faithful, the binary relation that associates states $s$ in $Q$ with their equivalence classes $[s]$ in $Q/\\sim$ is a bisimulation between the corresponding unlabeled transition systems (Sangiorgi 2012). Indeed,\nTheorem 3 (Bisimulation). Let $Q/\\sim$ be a faithful abstraction, and let $P$ be a problem in $Q$. Then, 1) if $s_0, s_1, ..., s_n$ is a trajectory in $S_p$, then $[s_0], [s_1], ..., [s_n]$ is a trajectory in $\\widetilde{S}_p$, and 2) if $[s_0], [s_1], ..., [s_n]$ is a trajectory in $\\widetilde{S}_p$, for each $s_0$ in $[s_0]$, there is trajectory $s'_0, s'_1, ..., s'_n$ in $S_p$ with $s'_i \\sim s_i$ for $0 \\leq i \\leq n$.\nProof. The first claim is direct by the definition of $\\widetilde{S}_p$. For the second, notice that $\\left([s_i], [s_{i+1}]\\right)$ in $\\widetilde{Succ}$ implies there is a transition $(s', s_{i+1})$ with $(s_i, s_{i+1}) \\sim (s', s_{i+1})$, for $0 \\leq i < n$. We construct the required trajectory in $S_p$ inductively. By faithfulness, there is $s'_1$ such that $(s_0, s'_1)$ is in Succ and $s'_1 \\sim s''_1$. Hence, $s'_1 \\sim s_1$. After constructing $s'_0, s'_1,..., s'_k$, we have $s'_k \\sim s_k$. By faithfulness, there is transition $(s'_k, s'_{k+1})$ with $s'_{k+1} \\sim s_{k+1} s'_{k+1}$. Thus, $s'_{k+1} \\sim s_{k+1}$, and the trajectory can be extended with $s'_{k+1}$.$\\Box$\nCorollary 4. Let $Q/\\sim$ be a faithful abstraction, and let $P$ be a problem in $Q$. If $s$ and $t$ are reachable states in $P$ with $s \\sim t$, then $V*(s) = V*(t)$.\nFaithfulness allows us to work with the abstraction, but it does not take into account the form of the policy $\\pi$. Namely, it can be the case that a transition $(s, s')$ in $P$ belongs to $\\pi$ but not a transition $(t, t')$ with $(t, t') \\sim (s, s')$. This will not happen, however, for the large class of uniform policies:\nDefinition 5 (Uniform Policies). Let $Q/\\sim$ be an abstraction, and let $\\Pi$ be a class of policies for $Q$. A policy $\\pi$ in $\\Pi$ is uniform over $Q/\\sim$ iff for any problem $P$ in $Q$, and any pair $(s, s')$ of reachable states in $P$, if $(t, t')$ is a pair of reachable states in $P$ such that $(s, s') \\sim (t, t')$, then $(s, s')$ is in $\\pi$ iff $(t,t')$ is in $\\pi$. The class $\\Pi$ of policies is uniform over $Q/\\sim$ if each policy $\\pi$ in $\\Pi$ is so.\nA uniform policy $\\pi$ over a faithful abstraction $Q/\\sim$ generates well-defined trajectories $[\\,[s_0], [s_1], [s_2], ...$ on the abstraction. Let us say that the transition $\\left([s], [s']\\right)$ belongs to $\\pi$ if $(s, s')$ belongs to $\\pi$. By uniformity, if t and t' are reachable states such that $(s, s') \\sim (t, t')$, then $(t, t') \\in \\pi$. Hence, we can lift the notions of solvability to define when a policy $\\pi$ solves the abstraction $Q/\\sim$. We have\nTheorem 6 (Solvability). Let $Q/\\sim$ be a faithful abstraction, and let $\\Pi$ be a uniform class of policies for $Q/\\sim$. Then, for any policy $\\pi$ in $\\Pi$: $\\pi$ solves $Q$ iff $\\pi$ solves $Q/\\sim$.\nProof. Let us assume that $\\pi$ solves $Q$, and suppose it does not solve $Q/\\sim$. That is, there is a $P$ in $Q$ with initial state $s_0$, and maximal trajectory $[s_0], [s_1], ..., [s_n]$ seeded at the initial class $[s_0]$ of $S_p$ that is not goal reaching. By Theorem 3, there is a trajectory $s'_0, s'_1, ..., s'_n$ in $P$ such that $s'_i \\sim s_i$, for $0 \\leq i \\leq n$. By faithfulness and uniformity, such a trajectory is a maximal $\\pi$-trajectory. On the other hand, the state $s'_n$ cannot be a goal state since $[s_n]$ is not a goal state. Hence, $\\pi$ cannot solve $Q$, which contradicts the assumption. The other direction is shown similarly.$\\Box$"}, {"title": "5 Isomorphic Relational Structures (States)", "content": "As planning states are relational structures, it is natural to deem two states as equivalent when their relational structures are isomorphic, defined as follows:\nDefinition 7 (Isomorphic Structures). Two relational structures $A$ and $B$, over a common universe $U$ and common signature (without constants), are isomorphic, written as $A\\sim B$, iff there is a permutation $\\sigma$ on $U$ such that for each relation $R$ of arity k, $R_B = \\{\\sigma(\\overline{u})|\\overline{u}\\in R_A\\}$, where $\\sigma(\\overline{u})$ for tuple $\\overline{u}=(u_1, u_2,..., u_k)$ is the tuple $(\\sigma(u_1), \\sigma(u_2), ...,\\sigma(u_k))$. We say that $\\sigma$ maps $A$ into $B$, and write $\\sigma: A \\rightarrow B$.\nIsomorphic structures satisfy the same set of sentences and the same set of formulas under suitable permutations. The following is a standard result.\nLemma 8. Let $A$ and $B$ be two relational structures, and let $\\varphi(\\overline{x})$ be a first-order formula whose free variables are among the ones in $\\overline{x}$. If $\\sigma : A \\rightarrow B$, then for any tuple u of objects of the same length as x, $A \\models \\varphi(\\overline{u})$ iff $B \\models \\varphi(\\sigma(\\overline{u}))$. In particular, if $\\varphi$ is a sentence (i.e., it has no free variables), $A \\models \\varphi$ iff $B \\models \\varphi$.\nIn the STRIPS setting where classes $Q$ consist of problems over a common domain, isomorphism-based equivalence of states yields faithful abstractions:\nTheorem 9 (Isomorphism-Based Equivalence). Let $Q$ be a class of STRIPS problems over domain $D$. If $\\sim_{iso}$ is the equivalence relation on the reachable states in $Q$ such that $s \\sim_{iso} t$ iff $A^s \\sim A^t$, then $Q/\\sim_{iso}$ is a faithful abstraction.\nProof (sketch). Let $P$ be a problem in $Q$, let $(s, s')$ be a reachable transition in $P$, and let t be a reachable state in P with $t \\sim_{iso} s$. We need to show that there is a transition $(t, t')$ in P with $t' \\sim_{iso} s'$. By assumption, $\\sigma : A^s \\rightarrow A^t$ for some permutation $\\sigma$, and there is a ground action a(o) with $s' = f(s, a(\\overline{o}))$. In particular, $A^s \\models pre(\\overline{o})$ and thus, by Lemma 8, $A^t \\models pre(\\sigma(\\overline{o}))$ (i.e. the ground action $a(\\sigma(\\overline{o}))$ is applicable in t). It is not hard to show that $t' \\sim_{iso} s'$ for $t' = f(t, a(\\sigma(\\overline{o})))$.\nFinally, to show the second condition in Definition 2, let P be a problem in Q. As the states in P are assumed to contain the goal atoms for the problem, the sentence $\\varphi_g = \\bigwedge_p \\forall \\overline{x} [p_g(\\overline{x}) \\rightarrow p(\\overline{x})]$, where the conjunction is over all predicates p in D, $p_g$ is the goal predicate for p, and the size of $\\overline{x}$ is the arity of p, determines whether a state s in P is a goal state; i.e., s is a goal state iff $A^s \\models \\varphi_g$. Hence, if s and t are reachable states in P such that $s \\sim_{iso} t$, then $A^s \\models \\varphi_g$ iff $A^t \\models \\varphi_g$; i.e., s is a goal state iff t is a goal state.$\\Box$\nExample. Let us consider the Gripper domain, where the goal is to move all balls from room A to room B with a robot. The robot has two grippers, it can move between the rooms, and it can pick and drop balls with any of the grippers. As"}, {"title": "6 Computing The Abstraction", "content": "Checking $\\sim_{iso}$ on two reachable states can be reduced to a graph-isomorphism test on vertex-colored graphs. These graphs, that we call object graphs, encode relational structures as vertex-colored undirected graphs. On the theoretical side, the exact complexity of graph isomorphism is still unknown, but it can be tested in quasi-polynomial time (Babai 2016). However, in practice, the test can be performed efficiently (McKay and Piperno 2014); see discussion in Babai (2016, page 83). Indeed, we use nauty (McKay and Piperno 2014) to compute canonical representations (i.e. isomorphism-invariant representations) of graphs, that we apply to the object graphs associated with states. nauty is a state-of-the-art tool that applies Color Refinement, recursively, using a technique called vertex individualization.\nDefinition 11 (Object Graphs). Let $A$ be a relational structure with universe $U$, and relational symbols $R_i$, each of arity $k_i$, $0 \\leq i < n$. The object graph for $A$ is the vertex-colored undirected graph $G(A) = (V, E, \\lambda)$ where the set V of vertices consists of\n1. vertices $v = \\langle u\\rangle$ with color $\\lambda(v) = 1$ for $u \\in U$, and\n2. vertices $v = \\langle R_i, j,\\overline{u}\\rangle$ with color $\\lambda(v) = \\langle R_i, j\\rangle$ for each relation $R_i$, $1 \\leq j \\leq k_i$, and tuple $\\overline{u} \\in (R_i)_A$.\nThe set of edges E consists of\n1. edges connecting the vertices $\\langle u_j\\rangle$ and $\\langle R_i,j,\\overline{u}\\rangle$ if $\\overline{u} = (u_1, u_2,..., u_{k_i})$, and\n2. edges connecting the vertices $\\langle R_i, j,\\overline{u}\\rangle$ and $\\langle R_i, j +1,\\overline{u}\\rangle$ for $1 < j < k_i$.\nThe object graph G(s) for a planning state s is the object graph $G(A_s)$ of its relational structure.\nThe vertices of the form $\\langle u\\rangle$ are called object vertices, and vertices of the form $\\langle R, j, \\overline{u}\\rangle$ are called positional-argument vertices. The first type of edge connects object vertices to corresponding positional-argument vertices, while the second connects successive positional-argument vertices.\nTheorem 12 (Reductions). Let $A$ and $B$ be two relational structures over a common universe $U$ and signature (with no constant symbols). Then, $A \\sim B$ iff $G(A) \\sim_g G(B)$."}, {"title": null, "content": "Proof (sketch). First assume $A \\sim B$ with $\\sigma: A \\rightarrow B$. We construct a color-preserving isomorphism f from G(A) to G(B): for object vertices, $f(\\langle u\\rangle) = \\langle \\sigma(u)\\rangle$, while for positional-argument vertices, $f(\\langle R, j,\\overline{u}\\rangle) = \\langle R, j, \\sigma(\\overline{u})\\rangle$. It can be seen that f is an edge-preserving bijection between the vertices of both graphs. Additionally, $\\lambda(\\langle u\\rangle) = 1 = \\lambda(\\langle \\sigma(u)\\rangle)$, and $\\lambda(\\langle R,j,\\overline{u}\\rangle) = \\langle R, j\\rangle = \\lambda(\\langle R, j, \\sigma(\\overline{u})\\rangle)$. Hence, f is a color-preserving isomorphism.\nFor the converse, let us assume that f is a color-preserving isomorphism from G(A) to G(B). Consider the function $\\sigma: U \\rightarrow U$ defined by $\\sigma(u) = u'$ iff $f(\\langle u\\rangle) = \\langle u'\\rangle$. As no object vertex has the color of a positional-argument vertex, $\\sigma$ is a U-permutation. We need to show $\\sigma : A \\rightarrow B$; i.e., for each relation R,\n$R_B = \\{\\sigma(\\overline{u}) \\mid \\overline{u} \\in R_A \\}.\n(1)\nThe set of vertices related to the tuple $\\overline{u}$ in $R_A$ is $V(A, \\overline{u}) = \\{\\langle u_i\\rangle \\mid u_i \\in \\overline{u}\\} \\cup \\{\\langle R, j, \\overline{u}\\rangle \\mid 1 \\leq j \\leq k\\}$. This set induces the subgraph G(A, \\overline{u}) of G(A). It is not hard to see that (1) holds iff the subgraphs G(A, \\overline{u}) and $G(B,\\sigma(\\overline{u}))$, for all tuples $\\overline{u} \\in R$, are isomorphic through the (restriction of) f. As this is the case, (1) holds, and $A \\sim B$. $\\Box$\nBy Theorem 12, we can use nauty to identify equivalent states. Other state encodings have been proposed that are not aimed at testing structural equivalence but at using standard GNN libraries (St\u00e5hlberg, Bonet, and Geffner 2022a; Chen, Trevizan, and Thi\u00e9baux 2023). While the theoretical relationship between GNNs and first-order logics with counting quantifiers $C_k$ is known (Grohe 2021), the relation between logical entailment of such logics over relational structures (i.e., states) and their different encodings (e.g., object graphs) is not clear."}, {"title": "7 Abstractions and Domain Expressivity", "content": "Function-based policies", "aspects": "whether a pair of non-isomorphic states (s, s') can be distinguished with GNNs, and whether a pair of states (s, s') with different $V*$-value can be distinguished with GNNs. Such pairs that cannot be distinguished by any GNN are called conflict pairs. If a training set contains conflict pairs of the first type and s is a goal state and s' is not, then no GNN will be able to distinguish goal states from non-goal states. If the conflict is of the second type, no GNN will learn a representation of $V*$, even in the training set.\nWe use the known relations between the counting logics $C_k$ and Weisfeiler-Leman coloring algorithms (Cai, F\u00fcrer, and Immerman 1992), and the latter and GNNs (Morris et al. 2019; Xu et al. 2019; Barcel\u00f3 et al. 2020; Grohe 2021), to establish whether a domain contains conflict pairs. More precisely, we use the 1-WL and 2-FWL coloring algorithms over to the object graph G(s) associated with relational structures (states) s.\nIt is known that if s and s' are two states whose object graphs cannot be distinguished by 1-WL, they will not be distinguished either by formulas in the logic $C_2$ (first-order logic with counting quantifiers and two variables), or by the embeddings produced by a GNN. And if the graphs for s and s' cannot be distinguished by 2-FWL, they cannot be distinguished by formulas in the logic $C_3$ or by the embeddings produced by 3-GNNs.\nGraphs are compared in terms of their histograms of colors, denoted by $Hist^k(\\cdot)$ with k = 1 for 1-WL, and k >"}]}