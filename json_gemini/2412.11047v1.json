{"title": "Deployment Pipeline from Rockpool to Xylo for Edge Computing", "authors": ["Peng Zhou", "Dylan R. Muir"], "abstract": "Deploying Spiking Neural Networks (SNNs) on the Xylo neuromorphic chip via the Rockpool framework represents a significant advancement in achieving ultra-low-power consumption and high computational efficiency for edge applications. This paper details a novel deployment pipeline, emphasizing the integration of Rockpool's capabilities with Xylo's architecture, and evaluates the system's performance in terms of energy efficiency and accuracy. The unique advantages of the Xylo chip, including its digital spiking architecture and event-driven processing model, are highlighted to demonstrate its suitability for real-time, power-sensitive applications.", "sections": [{"title": "1 Introduction", "content": "Deploying neural networks onto custom Application-Specific Integrated Circuit (ASIC) hardware involves comprehensive integration across all levels of the technology stack, including application design, algorithm development, compilation techniques, and chip architecture. This multi-layered process is fraught with challenges due to the need for precise alignment between high-level network functionality and low-level hardware operations. Here, we present an extensible deployment pipeline utilizing the Rockpool framework and the Xylo neuromorphic chip."}, {"title": "2 Rockpool", "content": "Rockpool [1] is a open-source Python package designed specifically for working with dynamical neural network architectures, particularly adept at designing event-driven networks for neuromorphic computing hardware. It offers a robust interface for designing, training, and evaluating recurrent networks that can operate with both continuous-time dynamics and event-driven dynamics. It provides a high-level API compatible with various backends like PyTorch, Jax, and Numpy. Rockpool supports hardware-aware training which is critical for optimizing models for specific neuromorphic hardware such as the Xylo chip."}, {"title": "3 Xylo", "content": "The Xylo chip [2, 3] is an ultra-low-power neuromorphic ASIC optimized for the efficient simulation of spiking leaky integrate-and-fire neurons with exponential input synapses. It is highly configurable, supporting individual synaptic and membrane time-constants, thresholds, and biases for each neuron, and can support arbitrary network architectures, including recurrent networks, for up to 1000 neurons. The integration of Rockpool's model design and training capabilities with Xylo's configurable, efficient hardware platform exemplifies a leading-edge approach to deploying energy-efficient neuromorphic computing at the edge.\nThe following table details the most important hardware specifications of the Xylo chip that should be considered when designing networks for deployment:"}, {"title": "4 Deployment Pipeline", "content": "The deployment pipeline for Rockpool networks onto the Xylo Hardware Development Kit (HDK) involves a series of structured steps to ensure that the neural network model is optimized for neuromorphic hardware implementation. The flow-chart below summarizes these steps, beginning with network construction in Rockpool and culminating in network simulation on the Xylo HDK."}, {"title": "4.1 Building a Network in Rockpool", "content": "Utilizing rockpool.nn.modules such as layers LIF and Linear, we can construct neural network architecture. These modules serve as the building blocks for creating diverse and complex neural network configurations tailored to specific tasks and functionalities. Additionally, we use rockpool.nn.combinators like Sequential and Residual to add neural network connections, enhancing the flexibility and capability of the network architecture.\nAn example of utilizing these tools is shown in Figure 2, where the network employs both a Residual architecture as well as feedforward and recurrent blocks, demonstrating how complex architectures can be easily composed."}, {"title": "4.2 Extracting a computational Graph", "content": "The graph extraction process in Rockpool is a critical step for preparing a neural network model for deployment onto neuromorphic hardware such as the Xylo chip. This process transforms the complex, dynamic structures of a neural network into a static graph format that can be efficiently mapped and deployed onto Neuromorphic hardware."}, {"title": "4.2.1 GraphModule and GraphNode", "content": "The core of Rockpool's graph extraction process involves the use of GraphModule and GraphNode classes. A GraphModule acts as a unit of computation and encapsulates the functional aspects of parts of the network, such as layers or neuron groups, as shown in Fig. 3. Each GraphModule is linked to input and output through GraphNode objects, which manage the flow of data through the network. The GraphNode essentially serves"}, {"title": "4.2.2 Constructing a Graph", "content": "To construct a graph, you begin by defining GraphModules that represent the different computational components of your network, ranging from simple sets of weights to complex configurations of spiking neurons. Each GraphModule includes the parameters necessary for defining the functionality of the unit, such as time constants and biases in the case of LIF neuron layers, or sets of weights in the case of linear layers."}, {"title": "4.2.3 Connecting Modules", "content": "Connecting these modules requires careful management of graph.GraphNode. The graph.utils.connect_modules() function in Rockpool is typically used to link output nodes from one module to input nodes of another, establishing a direct pathway for data flow. This function is vital for maintaining the integrity of data transformations across the network. An illustration of how modules are connected using the connect_modules() function is shown in Fig. 5."}, {"title": "4.2.4 Finalizing the Graph", "content": "Once all modules are interconnected, the final graph represents a comprehensive map of the network, detailing how data should move and be processed across different computational units. This graph is then ready to be translated into a format suitable for deployment on hardware like the Xylo chip.\nWhen you have built up a graph, you can conveniently encapsulate complex graphs and subgraphs using the graph.GraphHolder class. This class only requires the input_nodes and output_nodes arguments and conceptually holds an entire subgraph linked from those nodes. You can also use the as_GraphHolder() function to easily encapsulate a GraphModule as a GraphHolder. Graphs can be traversed by iterating over GraphModule.input_nodes, GraphNode.sink_modules, etc."}, {"title": "4.3 Map to Hardware Specification", "content": "Mapping the network graph to the Xylo hardware specifications is a crucial step that ensures the network's architecture can be effectively supported by the hardware. This process involves assigning hardware resources to various components of the network. For instance, each neuron within the network must be matched with a hardware neuron on the Xylo chip, and each non-input weight must be associated with a global hidden weight matrix specific to Xylo's architecture. Additionally, neurons in the final layer of the network need to be assigned to output channels to facilitate the correct delivery of output signals.\nThe Xylo family includes several devices, each with different hardware blocks and capabilities, which are catered to by specific subpackages within rockpool.devices.xylo, named according to the chip ID recognized by your Hardware Development Kit (HDK). Rockpool automates the process of detecting a connected HDK and loading the appropriate support package. This functionality is particularly helpful when setting up the environment for network deployment, as it ensures that the correct device-specific configurations are applied.\nIf a Xylo HDK is connected, Rockpool identifies it and imports the necessary package for interfacing with the hardware. For users without a Xylo HDK, there is support available for Xylo-Audio 2 through the rockpool.devices.xylo.syns61201 package.\nOnce the appropriate device package is loaded, the x.mapper() function is used to convert the computational graph into a Xylo-compatible specification. This function"}, {"title": "4.4 Network Quantization", "content": "The network is quantized using rockpool.transform.quantize methods to match the precision requirements of the Xylo chip. The quantization process can be approached using either global or channel-specific methods, each catering to different needs and resulting in various levels of precision and performance efficiency."}, {"title": "4.4.1 Global Quantization", "content": "Under the global quantization approach, all weights in the network are considered together when scaling and quantizing weights and thresholds. This method treats input and recurrent weights as one group, while output weights are processed separately. The advantage of this method is that it maintains a uniform scale across all parameters, simplifying the quantization process but possibly at the cost of losing some precision where finer control over individual weights might be beneficial."}, {"title": "4.4.2 Channel Quantization", "content": "In contrast, the channel quantization approach scales and quantizes parameters on a per-channel basis. This means that all input weights leading to a single target neuron are quantized together, allowing for more precise control over the weight scaling based on the specific needs of each neuron. This method is particularly useful when different neurons in the network have varying sensitivity to weight adjustments."}, {"title": "4.5 Hardware Configuration and Deployment", "content": "Once the network graph has been mapped to the Xylo hardware specifications using the mapper() function, the next crucial steps involve converting this specification into"}, {"title": "4.6 Network Evolution on the Xylo HDK", "content": "After deploying the network configuration to the Xylo processor, inference can be performed in the integer-logic SNN processor core, and compared with the floating-point LIF simulation provided by Rockpool.\nA Poisson input can be used, and transmitted to the Xylo processor to evolve the state of the SNN. During this evolution, all internal states such as membrane potentials, synaptic currents, and spiking events are recorded. It's important to note that while recording these internal states assists with debugging the network's functionality, it can reduce the speed of evolution, potentially below real-time operation. This trade-off is essential for detailed analysis but can be adjusted based on specific experimental needs.\nFollowing the evolution process, the recorded data are visualized to analyze the network's performance. This visualization helps in identifying patterns, understanding the network's behavior, and making necessary adjustments to optimize performance."}, {"title": "5 Results", "content": "The final step in validating the performance of the deployed neural network on the Xylo HDK involves comparing the outputs generated by the hardware with those produced by XyloSim, a bit-precise simulator of the Xylo architecture. This comparison is crucial to demonstrate that the simulator can accurately reflect the hardware's behavior, providing a reliable platform for pre-deployment testing and verification.\nThe network was evolved using XyloSim with inputs identical to those used in the hardware deployment. Both platforms recorded various internal states such as membrane potentials, synaptic currents, and spiking events. The analysis of these recordings indicates a perfect match between the simulated data and the hardware output, showing that XyloSim accurately mirrors the real-time dynamics observed in the Xylo HDK.\nComparative visualizations of the outputs from both the simulator and the hardware provide a clear indication of their alignment. The following figures illustrate the results from the simulator, highlighting the close match in the spiking activity and synaptic behaviors recorded during the network evolution."}, {"title": "6 Conclusion", "content": "The Rockpool to Xylo Hardware Development Kit (HDK) deployment pipeline marks a significant advancement in neuromorphic computing. It demonstrates a streamlined transition from conceptual neural network design to physical implementation, highlighting the efficacy of Rockpool in conjunction with the Xylo platform.\nThis pipeline methodically transforms theoretical models into deployable hardware configurations, encompassing network building, hardware specification mapping, and deployment. These steps ensure consistent and efficient final implementations, enhancing computational resource optimization and network performance.\nMoreover, the pipeline's structured approach supports extensibility, replicability and scalability, making it adaptable for various applications in neuromorphic computing. It significantly advances the field, making sophisticated neural network"}]}