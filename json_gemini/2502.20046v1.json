{"title": "Polish-ASTE: Aspect-Sentiment Triplet Extraction Datasets\nfor Polish", "authors": ["Marta Lango", "Borys Naglik", "Mateusz Lango", "Iwo Naglik"], "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is one of the most challenging and complex tasks in sentiment analysis.\nIt concerns the construction of triplets that contain an aspect, its associated sentiment polarity, and an opinion\nphrase that serves as a rationale for the assigned polarity. Despite the growing popularity of the task and the\nmany machine learning methods being proposed to address it, the number of datasets for ASTE is very limited. In\nparticular, no dataset is available for any of the Slavic languages. In this paper, we present two new datasets for\nASTE containing customer opinions about hotels and purchased products expressed in Polish. We also perform\nexperiments with two ASTE techniques combined with two large language models for Polish to investigate their\nperformance and the difficulty of the assembled datasets. The new datasets are available under a permissive\nlicence and have the same file format as the English datasets, facilitating their use in future research.", "sections": [{"title": "1. Introduction", "content": "Aspect Sentiment Triplet Extraction (ASTE) is\na recently proposed sentiment analysis (SA)\ntask (Peng et al., 2020) that involves the extraction\nof triplets comprising:\n\u2022 aspect phrase - a text span that represents a\nparticular feature or attribute of the item, for\nwhich an opinion is being expressed\n\u2022 sentiment polarity - often categorised as pos-\nitive, negative or neutral and refers to the\nemotional tone being expressed regarding the\ngiven aspect.\n\u2022 opinion phrase - a text span that explicitly con-\nveys the sentiment towards the aspect.\nTwo examples of sentences with extracted ASTE\ntriplets are given below and in Figure 1.\nCena jest rozs\u0105dna, ale obs\u0142uga s\u0142aba.\nThe price is reasonable, but the service\nis poor.\nTriplets: (Cenaprice, rozs\u0105dnareasonable,\nPositive), (obs\u0142ugaservice, s\u0142abapoor, Neg-\native)\nPok\u00f3j by\u0142 czysty i bardzo przytulny.\nThe room was clean and very cosy.\nTriplets: (Pok\u00f3jroom, czystyclean, Positive),\n(Pok\u00f3jroom, bardzo przytulny very cosy, Posi-\ntive)\nNote that multi-word phrases and one-to-many\nlinks are possible.\nSince the ASTE triples provide the comprehen-\nsive \"What, How and Why\" information regarding\nthe sentiment (Peng et al., 2020), the task quickly\ngained significant research attention. Many ma-\nchine learning techniques have been proposed,\nincluding GTS (Wu et al., 2020), JET (Xu et al.,\n2020), Span-based approach (Xu et al., 2021),\nPBF (Li et al., 2021), GAS (Zhang et al., 2021),\na two-stage approach (Huang et al., 2021),\nBMRC (Liu et al., 2022), SBC (Chen et al., 2022)\nand EPISA (Naglik and Lango, 2023). However,\nthe experimental evaluation of these models is\nlimited to English only, since datasets for other\nlanguages are not available.\nIn this paper, we introduce two novel datasets\nfor ASTE that contain customer opinions on hotels\nand purchased products, all expressed in Polish.\nFurthermore, we conduct experiments using two\nASTE techniques in conjunction with two state-of-\nthe-art large language models designed for Polish\nto assess the difficulty posed by the newly curated\ndatasets to already existing ASTE methods."}, {"title": "2. Related works", "content": "There are several datasets constructed for senti-\nment analysis in Polish. PolEmo 2.0 (Koco\u0144 et al.,\n2019a) contains over 57k sentences with anno-\ntated sentiment polarity, later extended to As-\npectEmo (Koco\u0144 et al., 2021) with sentiment as-\nsigned to each token of the sentence. Even more\nfine-grained annotation can be found in the Polish\nSentiment Treebank\u00b9, used in the PolEval-2017\nchallenge (Wawer and Ogrodniczuk, 2017), which\nis a dependency treebank with sentiment annota-\ntions for each subphrase of the sentence."}, {"title": "3. New ASTE Datasets for Polish", "content": "The customer reviews for the new datasets\nwere taken from the training part of Wroclaw"}, {"title": "3.1. Construction of datasets", "content": "Corpus of Consumer Reviews Sentiment (WC-\nCRS) (Koco\u0144 et al., 2019), which contains online\ncustomer reviews from four domains: medicine,\nhotels, products and students' opinions about lec-\ntures. The sentiment polarity in WCCRS is pro-\nvided at the sentence and document level, but not\nat the aspect level. Therefore, the sentiment anno-\ntation from WCCRS was not used during the con-\nstruction of our ASTE datasets.\nWe selected two WCCRS domains: hotels (re-\nviews of hotels, originally taken from TripAdvisor)\nand products (buyers' opinions on products from\nCeneo.pl). Following previous work for English\n(Fan et al., 2019; Peng et al., 2020), we annotated\n(aspect phrase, opinion phrase, sentiment polar-\nity) triples in each sentence, where aspect/opinion\nphrases are text spans and the considered senti-\nment polarities are: positive, negative and neutral.\nThe datasets were annotated by Polish na-\ntive speakers using Doccano annotation plat-\nform (Nakayama et al., 2018). Every annotator\nstudied the annotation guidelines prepared by an\nNLP expert with experience in sentiment analy-\nsis. All doubts and questions of the annotators\nwere discussed during the Q&A sessions. Quality\ncontrol was done by reviewing the annotators' out-\nput by NLP experts who were allowed to correct\nthem if needed (less than 5% of examples). To\nmeasure the inter-annotator agreement, we asked\none of our annotators to re-annotate 50 examples\nfrom the hotel datasets that had previously been\nannotated by another annotator. The annotator\nprovided the same annotation for 78% of the sen-\ntences.\nA basic summary of the annotation guidelines is\nprovided below.\n\u2022 Aspects should be properties of the whole\nitem/service being described in a review. For\ninstance, in a hotel review the aspects might\nbe \"room\" or \"parking lot\u201d but not \u201ckettle\u201d.\n\u2022 Opinion phrases are the shortest possible\nphrases that provide a sentiment polarity for\nan aspect, without changing the intensity of\nthe sentiment polarity. For example, in the text"}, {"title": "3.2. Characteristics of new datasets", "content": "The qualitative analysis of the constructed\ndatasets can be found in Table 1. For comparison,\nthe same statistics were computed for four English\ndatasets from SemEval competitions. Further-\nmore, to facilitate comparisons, we computed a\nweighted average of each statistic value over all\ndatasets for each language, using the size of the\ncorpora (measured by the number of sentences)\nas the average weight.\nThe average number of triples in a sentence is\nslightly higher in the Polish datasets, mostly due\nto more frequent opinion phrases forming triples\nwith the same aspect. An important feature of\nthe proposed datasets that makes them more chal-\nlenging are multi-word opinion phrases, which are\nalmost six times more frequent than in the En-\nglish datasets. The average length of an opinion\nphrase is 2.97 words in the hotels dataset and 2.22\nwords in the products' dataset, while this value\ndoes not exceed 1.25 in any of the English cor-\npora. Similarly, the number of triples containing\nsolely single word spans in both aspect and opin-\nion phrases is about 1.75 times lower in the Pol-\nish datasets. Such triples are much easier to con-\nstruct by machine learning methods, making the\nPolish datasets more challenging for them.\nThe distribution of sentiment polarity in the Pol-\nish datasets is significantly more balanced be-\ntween positive and negative classes than in the En-\nglish counterparts. However, in datasets for both\nlanguages, the triplets with Neutral sentiment are\nquite rare. Note, that the issue of class imbal-\nance is common in sentiment classification (Lango,\n2019)."}, {"title": "4. Experimental evaluation", "content": "The aim of experimental evaluation is to assess the\ndifficulty of the newly constructed datasets for Pol-\nish. We selected two deep learning approaches\nfor the comparison:\n\u2022 Grid Tagging Scheme (GTS, Wu et al., 2020)\nis a classical approach for ASTE which builds\na classifier predicting a particular word-by-\nword matrix. Due to the special coding\nscheme used, the matrix can be converted to\naspect-sentiment triplets by a dedicated de-\ncoding algorithm.\n\u2022 Exploiting Phrase Interrelations Span-level\nApproach (EPISA, Naglik and Lango, 2023) is\na recent technique that first generates all suit-\nable phrases from a given text, and then con-\nstructs final triples with a 2-dimensional CRF\nmodel that exploits interrelations between the\nphrases. To the best of our knowledge, this\nis the state-of-the-art approach for ASTE for\nEnglish."}, {"title": "4.1. Experimental setup", "content": "To construct text representation, the aforemen-\ntioned models leverage masked language mod-\nels (MLM) like BERT (Devlin et al., 2019) or De-"}, {"title": "4.2. Results", "content": "The results are presented in Table 2. As expected,\nthe more recent EPISA method produced better\nresults in terms of F1 score for all datasets, with\nan average improvement of 7.5 percentage points\nover GTS. For both Polish datasets, the combina-\ntion of GTS with TrelBERT yielded better results\nthan its HerBERT counterpart. Similarly, the Trel-\nBERT variant achieved the highest F1-score value\nfor EPISA on products corpora. On the other hand,\nHerBERT performed slightly better on hotels cor-\npora when paired with EPISA.\nThe proposed Polish datasets proved to be\nmuch more challenging for existing methods than\nthe existing English datasets. The F1 score aver-\naged over all English datasets is 63.5% for GTS\nand 68.7% for EPISA, while the average perfor-\nmance of the generally better performing Trel-\nBERT variants is 40.5% and 45.4% for GTS and\nEPISA respectively. The difference in triplet ex-\ntraction performance between Polish and English\nis approx. 23 percentage points for both methods,\nwhich calls for future research in ASTE for under-\nresourced languages."}, {"title": "5. Summary", "content": "In this paper we have presented two datasets for\nthe Aspect Sentiment Triplet Extraction task for the\nPolish language. The new datasets have the same\nformat as commonly used English datasets, which\nfacilitates the comparison and development of ma-\nchine learning ASTE models for both languages.\nThe ASTE datasets for Polish are characterised by\na higher average number of triplets and a higher\nfrequency of one-to-many relations than their En-\nglish counterparts. Multi-word opinion phrases are\nalso significantly more common.\nThe conducted experiments with two ASTE\ndeep learning approaches adopted to Polish by\ncoupling them with two different Polish language\nmodels showed that the constructed datasets are\nchallenging for modern machine learning tech-\nniques."}, {"title": "6. Frequently Asked Questions", "content": "1. The data used for annotation is a subset of an\nexisting data set - why is it being presented as\ntwo datasets?\nThe research on ASTE is almost exclusively\ncarried out on the English datasets dis-\ncussed in our paper. These datasets con-\ntain texts from only one domain, e.g. opin-\nions about restaurants or laptops. The perfor-\nmance achieved by the current SOTA meth-\nods on English is still not fully satisfactory and\nproduction-ready to move to a more challeng-\ning scenario of multi-domain datasets. As we\nexpected that training ASTE for Polish may be\neven more challenging, we considered it nec-\nessary to produce single-domain datasets as\nwell. However, just as all four English datasets\ncan be merged into one larger dataset, the\nsame is true for the Polish datasets. One can\nalso merge all the datasets in our work to test\nthe multilingual multi-domain scenario.\n2. The lower metric values obtained on Polish\ndatasets are interpreted as the datasets being\nmore challenging. Is it possible that the model\nreplication/implementation for Polish has is-\nsues?\nBoth the GTS and EPISA algorithms have\nbeen run by us for Polish and English using\noriginal implementation provided by the au-\nthors. For EPISA we were able to reproduce\nthe exact results of the original work on En-\nglish, as the original implementation of EPISA\nwas available with fixed random seed. GTS re-\nsults differed slightly from the original work on\nEnglish, but none of the differences were sta-\ntistically significant. The Polish datasets have\nthe same input format as the English datasets,\nand the only change with respect to the origi-\nnal methods is to replace an English MLM with\na Polish MLM, so it is unlikely that there are\nany implementation issues for Polish.\n3. Is it possible that the methods used were just\noptimized for English data, and this causes\nthe lower performance on the Polish data?\nAlthough current SOTA methods based on\ndeep learning do not appear to explic-\nitly model language-dependent features that\nwould favour English over Polish, it is possible\nthat they are inadvertently optimised for En-\nglish data. For example, published methods\ntend to perform better on English benchmarks,\nleading to the promotion of such methods dur-\ning development, despite the fact that other\ndesign choices might work better for other lan-\nguages. Developing datasets for languages\nother than English is the first step in investi-\ngating this issue."}, {"title": "7. Acknowledgements", "content": "The research has been partially supported by\n0311/SBAD/0743 PUT University grants. \u039c.\nLango was supported by National Science Centre,\nPoland (Grant No. 2022/47/D/ST6/01770). This\nwork used resources of the LINDAT/CLARIAH-CZ\nResearch Infrastructure (Czech Ministry of Educa-\ntion, Youth, and Sports project No. LM2018101).\nFor the purpose of Open Access, the author has\napplied a CC-BY public copyright licence to any\nAuthor Accepted Manuscript (AAM) version arising\nfrom this submission."}]}