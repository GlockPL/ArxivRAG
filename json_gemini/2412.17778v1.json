{"title": "An Investigation on the Potential of KAN in Speech Enhancement", "authors": ["Haoyang Li", "Yuchen Hu", "Chen Chen", "Eng Siong Chng"], "abstract": "High-fidelity speech enhancement often requires sophisticated\nmodeling to capture intricate, multiscale patterns. Standard ac-\ntivation functions, while introducing nonlinearity, lack the flex-\nibility to fully address this complexity. Kolmogorov-Arnold\nNetworks (KAN), an emerging methodology that employs\nlearnable activation functions on graph edges, present a promis-\ning alternative. This work investigates two novel KAN vari-\nants based on rational and radial basis functions for speech\nenhancement. We integrate the rational variant into the 1D\nCNN blocks of Demucs and the GRU-Transformer blocks of\nMP-SENet, while the radial variant is adapted to the 2D CNN-\nbased decoders of MP-SENet. Experiments on the VoiceBank-\nDEMAND dataset show that replacing standard activations with\nKAN-based activations improves speech quality across both the\ntime-domain and time-frequency domain methods with minimal\nimpact on model size and FLOP, underscoring KAN's potential\nto improve speech enhancement models.", "sections": [{"title": "1. Introduction", "content": "Speech enhancement reduces noise and distortion to improve\nspeech clarity, aiding applications like hearing aids, telecom-\nmunications and voice recognition systems. Deep learning-\nbased speech enhancement (SE) methods can be generally clas-\nsified under time domain methods [1] [2] [3] [4] [5] and time-\nfrequency (TF) domain methods [6] [7] [8] [9] [10]. Time-\ndomain methods aim to predict clean waveform directly from\nnoisy counterparts. SEGAN [1] is trained in an adversarial man-\nner with a CNN-based auto-encoder as the enhancement mod-\nule. DEMUCS [2] combined a convolutional encoder-decoder\nwith LSTM layers for effective sequential modeling. On the\nother hand, TF-domain methods predict clean TF-domain rep-\nresentation and recover time domain waveform from it. Some\nearly TF-domain SE focused solely on enhancing the magnitude\nspectrum, followed by reconstructing clean speech using the In-\nverse Short-Time Fourier Transform (ISTFT) [6] [11]. Later ap-\nproaches, such as CMGAN [7] and MP-SENet [12], implicitly\nor explicitly predict clean phase information in addition to the\nmagnitude spectrum, yielding better enhancement results. Ad-\nvancements have also been made in designing better objective\nfunctions for SE. Early works [13] [14] typically minimize the\nL1/L2 distance of time-domain waveform or TF-domain rep-\nresentations, which does not precisely reflect human auditory\nperception. Metricgan [6] addresses the problem through opti-\nmizing the model on PESQ [15] or STOI [16] directly through\nGAN training with the discriminator serving as a PESQ/STOI\nscore estimator.\nDespite advancements in SE methods, current approaches\ntypically rely on standard activation functions like GELU [17],"}, {"title": "2. Preliminaries", "content": "2.1. KAN: Kolmogorov-Arnold Network\nKAN is developed based on the Kolmogorov-Arnold theorem\n[27], which asserts that any continuous function can be repre-\nsented as a composition of univariate continuous functions of\na finite number of variables. In theory, each KAN layer L is\na composition of learnable univariate functions $\\Phi$ as illustrated\nin equation 1, where I and O are the input and output dimen-\nsions. These univariate functions can be used to model contin-"}, {"title": "3. KAN in Speech Enhancement", "content": "3.1. KAN in Time-domain SE\nWe first investigate the impact of KAN activation on time-\ndomain SE. Figure 1 illustrates the GR-KAN adapted causal\nDemucs, where we replace the ReLU activations in the original"}, {"title": "4.1. Dataset", "content": "We investigate our solutions using VoiceBank-DEMAND [30],\na widely recognized benchmark dataset for SE. The training set\ncomprises 11,572 clean utterances from 28 speakers, while the\ntest set consists of 824 clean utterances from 2 unseen speakers,\nall originating from the Voice Bank corpus [31]. Each clean"}, {"title": "4.2. Experimental Setup", "content": "For Demucs, we used the causal version with 5 encoder blocks,\n5 decoder blocks and a 2 layer unidirectional LSTM. We set the\ninitial hidden dimension to 48, kernel size to 8, stride size and\nresample factor to 4. All models are trained to 500 epochs using\nthe adam optimizer at a learning rate of 0.0003 and batch size\nof 16. The model is optimized using L1 loss on the waveform\nand a multi-resolution STFT loss on the magnitude spectrum.\nFor MP-SENet, we used a hop size, Hanning window size\nand FFT point number of 100, 400 and 400, respectively. We\ntrained all models to 200 epochs with a batch size of 4 using\nthe AdamW optimizer [33] with $\\beta_1$ = 0.8 and $\\beta_2$ = 0.99. We\nset the learning rate to 0.0005, which decays with a factor of\n0.99 every epoch. Our training objective follows MP-SENet,\nwhere the generator is optimized using a weighted sum of the\nmagnitude spectrum loss, phase spectrum loss, complex spec-\ntrum loss, STFT consistency loss and metricgan loss, while the\ndiscriminator is trained to predict the PESQ of the predicted\nmagnitude spectrum."}, {"title": "4.3. Evaluation Metrics", "content": "Following [6] [11] [7] [20], we evaluate our models with PESQ\n[15], CSIG, CBAK, COVL [34] and STOI [16], which are mea-\nsurements for perceptual speech quality, signal distortion, noise"}, {"title": "4.4. Experimental Results", "content": "Table 1 reports Demucs's performance when the ReLU activa-\ntions in the Encoder and/or Decoder are replaced with GR-KAN\nactivations. In all runs, GR-KAN activations consistently out-\nperform ReLU activations in all speech quality metrics, with ap-\nproximately the same FLOPs and model size. The result shows\nthe superiority of GR-KAN over ReLU activation in the time-\ndomain Demucs.\nTable 2 compares different GRU-Transformer variants in\nMP-SENet. The GR-KAN variant (Figure 2b) outperforms the\nLeaky ReLU and GELU variants at similar model size and\nFLOPS, suggesting GR-KAN activation's stronger modeling\ncapacity in the T-F domain MP-SENet. The original GRU-\nTransformer block in MP-SENet (LeakyReLU*) achieves the\nlowest performance, likely because it uses only one linear layer\nafter the Bi-GRU module, compared to two layers in other runs.\nTable 3 compares different decoder variants in MP-SENet,\nwhile the GRU-Transformer variant is fixed to the GR-KAN\nvariant in Table 2. We observe that the decoders using K\u0391\u039d-\nConv2D with both RBF-KAN and Swish activation (Figure\n2c) have the best performance. When RBF-KAN activation in\nKAN-Conv2D is replaced with another Swish activation, there\nis a significant drop in PESQ from 3.609 to 3.537, indicating\nthat the information captured by the RBF-KAN activation effec-\ntively complements the Swish activation. When KAN-Conv2D\nis replaced with Conv2D preceded by PReLU (the original im-\nplementation in MP-SENet), there is a drop in PESQ from 3.609\nto 3.572, suggesting the stronger modeling capability of the\nKAN-Conv2D module.\nTable 4 compares our KAN adapted MP-SENet against\nseveral well-known SE solutions on the VoiceBank-DEMAND\ndataset. Our method achieves the highest PESQ of 3.61, show-\ning its superiority as a state-of-the-art SE method."}, {"title": "5. Conclusion", "content": "This work investigates KAN, a competitive alternative to MLP\non the SE domain, by adapting 2 novel KAN variants based\non rational function and radial basis function to existing SE\nsolutions. Comprehensive experiments on the VoiceBank-\nDEMAND dataset demonstrate that these KAN variants sur-\npass traditional MLPs with standard activation functions in both\nthe time-domain Demucs and the T-F domain MP-SENet, with\nminimal or negligible increases in model size and computa-\ntional cost. The encouraging results suggest that future SE ap-\nproaches could benefit from incorporating KAN to achieve en-\nhanced performance."}]}