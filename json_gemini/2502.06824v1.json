{"title": "NEURAL NETWORK-BASED VEHICULAR CHANNEL ESTIMATION\nPERFORMANCE: EFFECT OF NOISE IN THE TRAINING SET", "authors": ["S. A. Ngorima", "A. S. J. Helberg", "M. H. Davel"], "abstract": "Vehicular communication systems face significant challenges due to high mobility and rapidly\nchanging environments, which affect the channel over which the signals travel. To address these\nchallenges, neural network (NN)-based channel estimation methods have been suggested. These\nmethods are primarily trained on high signal-to-noise ratio (SNR) with the assumption that training a\nNN in less noisy conditions can result in good generalisation. This study examines the effectiveness\nof training NN-based channel estimators on mixed SNR datasets compared to training solely on\nhigh SNR datasets, as seen in several related works. Estimators evaluated in this work include an\narchitecture that uses convolutional layers and self-attention mechanisms; a method that employs\ntemporal convolutional networks and data pilot-aided estimation; two methods that combine classical\nmethods with multilayer perceptrons; and the current state-of-the-art model that combines Long-Short-\nTerm Memory networks with data pilot-aided and temporal averaging methods as post processing.\nOur results indicate that using only high SNR data for training is not always optimal, and the SNR\nrange in the training dataset should be treated as a hyperparameter that can be adjusted for better\nperformance. This is illustrated by the better performance of some models in low SNR conditions\nwhen trained on the mixed SNR dataset, as opposed to when trained exclusively on high SNR data.", "sections": [{"title": "1 Introduction", "content": "The integration of network infrastructure with artificial intelligence (AI) is becoming more prevalent due to the\nincreasing demands of data-intensive applications and the need for more efficient and reliable communication systems.\nIncorporating AI into these systems promises to improve network management, resource allocation, and overall system\nperformance.\nThis convergence is notably evident in vehicular communication, which is an important component of intelligent\ntransportation systems. Vehicular communication systems face unique problems due to their high mobility, rapidly\nvarying environments, and significant latency requirements. One of the challenges in this domain is obtaining accurate\nchannel estimates, which is critical to ensuring reliable communication between vehicles and infrastructure. Channel\nestimation involves determining the characteristics of a communication channel and monitoring its changes to adjust to\nvarying conditions [9]."}, {"title": "2 Background", "content": "We describe the system model, well-known channel estimation schemes in vehicular communications, and some of\nthe NN-based channel estimation techniques currently used. We also provide a brief description of the IEEE 802.11p\nphysical layer structure that is used in all simulations, along with a description of its specifications."}, {"title": "2.1 System Model", "content": "In this paper, we adopt the IEEE 802.11p physical layer structure, which is specifically designed for vehicular\ncommunication systems. This section follows a detailed discussion of the IEEE 802.11p specifications as outlined in\nNgorima et al. [10]. The IEEE 802.11p standard uses Orthogonal Frequency Division Multiplexing (OFDM) to transfer\ndata by dividing the available bandwidth into several subcarrier frequencies for simultaneous transmission of multiple\nsignals. 52 of the 64 available subcarriers are used for data transmission and pilot symbols. The remaining subcarriers"}, {"title": "2.2 Well-known Vehicular Channel Estimation Schemes", "content": "This section describes some of the main vehicular channel estimation schemes that have been widely used and studied in\nthe literature. These methods were selected based on their effectiveness in dynamic environments and their foundational\nrole in the development of more advanced NN-based estimators."}, {"title": "2.2.1 DPA Estimation:", "content": "The first step of the DPA process, as described by Pan et al. [13], is to calculate the initial estimate of the frame. This is\ndone by applying the least squares (LS) estimation to the preamble as shown below:\n$h_{0}[k] = \\frac{y_{1}^{(P)}[k] + y_{2}^{(P)}[k]}{2p[k]}$,\nwhere $y_{1}^{(P)}[k]$ and $y_{2}^{(P)}[k]$ are the known orthogonal preambles received on the [k] subcarrier and p[k] is the OFDM\ndata symbol transmitted over the k-th subcarrier. The next OFDM symbols in the frame are equalised using the initial\nestimate as the starting point as follows:\n$h_{i}^{DPA}[k] = \\frac{y_{i}[k]}{h_{i-1}^{DPA}[k]}$"}, {"title": "2.2.2 STA Estimation Scheme:", "content": "STA uses both spectral (frequency) and temporal correlations within data symbols to estimate the channel [4]. STA can\nalso be viewed as a recursive filtering process that combines multiple channel estimates into a more accurate estimate.\nThe first step is to calculate a channel estimate in the frequency domain $h_{i}^{FD}[k]$ as follows:\n$h_{i}^{FD}[k] = \\sum_{\\lambda = -\\beta}^{\\beta} \\omega_{\\lambda} \\hat{h}_{i}^{DPA}[k + \\lambda]$, where $\\omega_{\\lambda} = \\frac{1}{2\\beta + 1}$,\nwhere 2$\\beta$ + 1 represents the number of subcarriers that are considered. Subsequently, a temporal average is computed\nto arrive at the final STA channel estimate, $h_{i}^{STA}[k]$:\n$h_{i}^{STA}[k] = \\frac{1}{\\alpha}(\\alpha - 1) h_{i-1}^{STA}[k] + \\frac{1}{\\alpha}\\hat{h}_{i}^{DPA}[k]$,\nwhere $\\alpha$ is a smoothing parameter that controls the weight given to current and previous estimates."}, {"title": "2.2.3 TRFI Estimation Scheme:", "content": "TRFI leverages the high correlation within OFDM symbols to improve the accuracy of the channel estimation [5]. The\nprocess starts by creating multiple channel estimates for each symbol using the DPA method. The received symbol is\nequalised using the estimates of the current and previous symbols ($h_{i}^{DPA}[k]$) and ($h_{i-1}^{DPA}[k]$) respectively.\n$y_{i}^{eq[k]} = \\frac{y_{i}[k]}{h_{i}^{DPA}[k]}$,\n$y_{i-1}^{eq}[k] = \\frac{y_{i}[k]}{h_{i-1}^{DPA}[k]}$\nSubsequently, the equalised symbols are remapped to their corresponding constellation points, $d_{i-1}'[k]$ and $d_{i-1}''[k]$.\nTRFI then categorises subcarriers into reliable and unreliable sets based on a reliability test between the remapped\nsymbols. Subcarriers with consistent remapped symbols, that is, $d_{i-1}''[k] = d_{i-1}'[k]$, are considered reliable, while\nthose with discrepancies are classified as unreliable. TRFI then interpolates channel estimates for unreliable subcarriers\nby using the reliable subcarriers as anchor points. This interpolation process effectively fills in the gaps in channel\nknowledge, resulting in a more accurate overall channel estimate. A detailed discussion on the interpolation procedure\nis given in [4]."}, {"title": "2.3 MLP-based Estimators", "content": "To enhance the performance of conventional STA and TRFI estimators, Gizzini et al. [4] introduced MLP-based channel\nestimation methods. In these methods, MLP layers are added to the STA and TRFI processes, allowing the model\nto learn complex patterns in vehicular channels and thereby improve the accuracy of the estimation. The methods\nSTA-MLP and TRFI-MLP initially conduct DPA estimation, proceed with STA or TRFI estimation and subsequently\nfeed the results into the MLP layers."}, {"title": "2.4 TCN-DPA Estimator", "content": "As proposed in [10], the TCN-DPA estimator integrates a Temporal Convolutional Network (TCN) with DPA estimation\nto enhance channel estimation in dynamic environments. The TCN processes the received OFDM symbols in the\nfrequency domain, treating subcarriers as time steps. The extracted features are then passed to the DPA process, where\nthe previous TCN output, $h_{i-1}^{TCN}[k]$, is used to equalise the current received symbol. After equalisation, the symbol is\ndemapped and remapped to the nearest constellation point to obtain the final channel estimate, $h_{i}^{TCN}[k]$. This estimate\nis updated iteratively using the DPA process. This approach leverages the ability of the TCN to model long-range\ndependencies across subcarriers, making it effective for complex channel conditions."}, {"title": "2.5 LSTM-DPA-TA Estimator", "content": "The LSTM-DPA-TA estimator [3] integrates an LSTM network with DPA and Temporal Averaging (TA) techniques\nto enhance channel estimation in vehicular environments. In this approach, the LSTM processes the received OFDM\nsymbols to extract key features, which are then passed into the DPA module. The resulting channel estimates are\nfurther refined using the TA technique. In the LSTM-DPA-TA method, OFDM symbols are treated as time steps, with\nsubcarriers considered as features within each time-step sequence. This design enables the model to effectively capture\nfrequency dependencies and improve the accuracy of channel estimation under dynamic conditions."}, {"title": "2.6 CNN-Transformer", "content": "The CNN-Transformer is a recently proposed hybrid architecture for vehicular channel estimation in [11]. This\napproach combines the strengths of CNNs and Transformer networks to analyse vehicular channel data comprehensively.\nThe channel data can be represented in both the time and frequency domains. The frequency domain represents the\nsubcarriers of the OFDM symbols, while the time domain represents the sequence of OFDM symbols transmitted\nover time. Each OFDM symbol is transmitted across multiple subcarriers. The frequency domain captures the spatial\ncharacteristics of the channel across OFDM subcarriers, while the time domain reflects the temporal dynamics as\nOFDM symbols are transmitted sequentially.\nIn this CNN-Transformer architecture, subcarriers are treated as the 'time steps'. The architecture leverages CNNs to\nextract local features from subcarriers and uses Transformer layers to capture global dependencies across the frequency\ndomain. The CNN component applies 1D convolutions to capture local patterns, while the Transformer component uses\nself-attention mechanisms to analyse patterns between subcarriers globally."}, {"title": "3 Methodology", "content": "This section outlines the methodological framework used in this study. We start with a detailed description of the\ndatasets used for training and evaluation, specifically focussing on two approaches: the mixed SNR dataset and the high\nSNR dataset. Following this, we discuss the data preprocessing steps applied to transform complex received symbols\ninto a format suitable for input into NNs."}, {"title": "3.1 Data Preparation", "content": "We simulate vehicle-to-vehicle communication following the 'Vehicle-To-Vehicle Expressway Same Direction with\nWall' (VTV-SDWW) channel model [7]. Our simulation specifically modelled vehicles moving at 100 km/h, with a\nDoppler shift of 550 Hz. We used 16QAM (16-Quadrature Amplitude Modulation) modulation for data transmission in\nthis urban environment scenario. This modulation scheme encodes the data by varying the amplitude and phase of the\ncarrier signal."}, {"title": "3.1.1 Mixed SNR Dataset", "content": "The mixed SNR dataset represents a wide range of noise introduced on the VTV-SDWW channel. For this dataset, we\nsimulate 18,000 time-specific frames with SNR values ranging from 0 to 40 dB in increments of 5 dB. Each SNR level\nincludes 2,000 frames, with 50 OFDM symbols spread across 52 active subcarriers (48 data and 4 pilot subcarriers).\nDuring training, each model is exposed to the entire range of SNR levels. The validation set is created by reserving\n25% of this training data to monitor the performance of the model during training. An independent test set consisting\nof 2,000 frames is generated separately from the training sets. This test set includes frames at SNR levels of 0, 5, 10,\n15, 20, 25, 30, 35, and 40 dB, ensuring that the evaluation correctly reflects the performance across different SNR\nconditions. The same test set is used to test all the models regardless of how they are trained."}, {"title": "3.1.2 High SNR Dataset", "content": "The high SNR dataset focusses on a fixed SNR level, representing less noisy or nearly ideal channel conditions, as\nopposed to the mixed SNR dataset. This dataset is used to train models with the assumption that training NNs in an\nenvironment with a clearly defined channel can lead to better generalisation even in noisy environments [3, 4, 5, 13]. In\nthis work, the high SNR dataset consists of 18,000 time-specific frames, all generated at a 40 dB SNR level, with the\nsame frame structure as the mixed SNR data. As before, 25% of the training data is set aside for validation."}, {"title": "3.1.3 Data preprocessing", "content": "To preprocess the data for NN models, we transform the complex 16QAM symbols received across subcarriers and time\nslots into a real-valued format. Each received symbol consists of both real and imaginary components. The following\nsteps are performed to prepare the data:\n1. Separate Real and Imaginary Components: Decompose each complex 16QAM symbol into its real and\nimaginary parts. Handle the data as two separate real-valued matrices instead of a single complex-valued\nmatrix. For a given OFDM symbol, where y[k] = r[k] + j \u00b7 i[k] represents the received complex value at\nsubcarrier k, extract r[k] as the real part and i[k] as the imaginary part.\n2. Interleave Components: After separation, interleave the real and imaginary components. This means\narranging the real and imaginary parts in an alternating sequence across the time slots. By interleaving, a\nunified structure that preserves the relationship between the real and imaginary parts within the input data is\ncreated.\n3. Form the Input Matrix: Structure the interleaved data into a matrix with dimensions 52 \u00d7 100, where\n52 represents the number of subcarriers and 100 represents the sequence of interleaved real and imaginary\ncomponents across the time slots. This transformation enables the NN to process the complex-valued input as\na series of real-valued inputs.\n4. Prepare Input Data for NN models: The resulting matrix is now a real-valued representation of the original\ncomplex data, ready for input into NN models."}, {"title": "3.2 Hyperparameter Optimisation", "content": "We reimplement most of the NN-based estimators discussed in the previous sections to ensure compatibility with\nour experimental setup and to be able to optimise each individually for the specific datasets used. Specifically, the\nCNN-Transformer, TCN-DPA, STA-MLP, and TRFI-MLP models were reimplemented from scratch. The LSTM-\nDPA-TA model is implemented using existing code available online. To verify the accuracy of our reimplementations,\nwe compare the performance of our implementations against the benchmark results reported in the original studies,\nensuring that they perform as expected.\nThe final architecture of each model is determined through a hyperparameter tuning process, to identify the optimal\nconfigurations for each model. We optimise the hyperparameters of all models in both datasets using Optuna, a\nBayesian optimisation framework that efficiently searches the hyperparameter space using a tree-structured Parzen\nestimator (TPE) [1]. This method systematically explores different hyperparameter configurations while conserving\ncomputational resources by early termination of underperforming trials."}, {"title": "4 Results", "content": "This section evaluates the performance of channel estimators using BER as the primary metric. We compare the\neffectiveness of two training approaches: one using a mixed SNR dataset and the other using a high SNR dataset. The\nevaluated architectures are CNN-Transformer, TCN-DPA, STA-MLP, TRFI-MLP, and LSTM-DPA-TA."}, {"title": "4.1 BER", "content": "BER is a crucial performance measure in digital communication. It compares transmitted and received bit sequences to\nassess system reliability. In channel estimation, a lower BER means more accurate signal reconstruction and fewer\nerrors in decoded data. The following analysis details the BER performance of each model at different levels of SNR,\nproviding a direct comparison between the two training approaches.\nFigure 3 presents the BER performance of the channel estimators trained using a high SNR dataset (40 dB) and a mixed\nSNR dataset, respectively. The ideal curve, represented by the dotted black line in these figures, represents the best\npossible performance in channel estimation, where the received signal is assumed to be perfectly equalised without any\nchannel estimation errors. This curve serves as a theoretical lower bound for the BER, showing the performance in a\nscenario where only additive white Gaussian noise (AWGN) is present and the channel effects are perfectly compensated\nfor. The closer the BER of a model is to the ideal curve, the better its performance in accurately estimating the channel\nand mitigating the effects of noise. LS serves as the lower performance baseline.\nIn Figure 3a, we observe several key trends across models trained on an high SNR dataset: In the low SNR range\n(0-10 dB), the STA-MLP and the LSTM-DPA-TA models perform relatively well, maintaining a lower BER compared\nto other models. As we move into the mid SNR range (15-25 dB), the CNN-Transformer and DPA-TCN models\nshow an improvement, particularly from 15 dB onwards, with performance becoming more pronounced from 20 dB.\nThis improvement at high SNR highlights that these models have effectively adapted to high SNR conditions. The\nTRFI-MLP model also improves in this range, although it lags behind the CNN-Transformer and DPA-TCN models,\nindicating some limitations in its ability to adapt to low SNR conditions. In the high SNR range (30-40 dB), the\nCNN-Transformer and DPA-TCN models continue to show further significant reductions in BER. The LSTM-DPA-TA\nmodel continues to outperform other models across all SNR levels, showing its effectiveness in less noisy conditions. In\ncontrast, STA-MLP shows limited improvement beyond 20 dB, indicating that it struggles to capitalise on the reduced\nnoise at higher SNR levels.\nIn the mixed SNR training scenario depicted in Figure 3b, we observe that CNN-Transformer and DPA-TCN models\nexhibit excellent performance across the entire SNR range with CNN-Transformer outperforming all models. The\nLSTM-DPA-TA and STA-MLP models perform well at lower SNR levels (0 to 15 dB) but show reduced performance\nas the SNR increases, indicating diminished capabilities in high SNR conditions when trained on mixed SNR data. We\ncan also observe the improved performance of the TRFI-MLP estimator across the entire SNR range tested compared\nto its performance when trained on the high SNR dataset. The unsatisfactory performance by LSTM-DPA-TA and\nSTA-MLP indicates that while these models can handle varying noise conditions, they may not leverage mixed SNR\ntraining as effectively as TRFI-MLP, CNN-Transformer and DPA-TCN.\nModels trained on mixed SNR data exhibit lower BER even in low-SNR scenarios, compared to those trained on\nhigh SNR data. Mixed SNR training appears to be beneficial for models such as TRFI-MLP, TCN-DPA, and CNN-\nTransformer, which show a significant improvement in low SNR conditions than when trained on high SNR. In contrast,\nthe LSTM-DPA-TA and STA-MLP models demonstrate better performance when trained on a high SNR dataset,\nsuggesting that these models make use of the better channel statistics available at high SNR. This is analysed in more\ndetail below."}, {"title": "4.2 Difference in BER Between Models Trained on Mixed SNR and High SNR Datasets", "content": "Figure 4 illustrates the difference in BER between models trained on high SNR datasets and those trained on a mixed\nSNR dataset. The graph clearly shows how the training dataset influences the performance of various models across\ndifferent SNR ranges. In the low SNR range (0-10 dB), the CNN-Transformer and TCN-DPA models exhibit the highest\npositive delta, peaking around 10 dB. This indicates a substantial improvement in performance when these models are\ntrained on a mixed SNR dataset compared to a high SNR dataset. A positive delta suggests that mixed SNR training\nbetter equips these models to generalise in low SNR conditions. TRFI-MLP also shows a noticeable positive delta,\nalthough less pronounced, indicating that mixed SNR training offers some advantages in low SNR environments. In\ncontrast, the LSTM-DPA-TA and STA-MLP models display a slightly negative delta across this range, implying that\ntraining on high SNR datasets offers a marginal performance advantage in these specific models.\nAs the SNR increases (15-25 dB), the positive delta values for the CNN-Transformer and TCN-DPA models start to\ndecrease but remain positive, particularly around 15 dB. This indicates that while the benefits of mixed SNR training\ndiminish slightly, these models still gain performance advantages in this SNR range. TRFI-MLP continues to maintain\npositive delta values, demonstrating that mixed SNR training consistently improves its performance at varying SNR\nlevels. Meanwhile, the LSTM-DPA-TA model continues to show a negative delta, particularly at the higher end of the\nmid-SNR range, around 20-25 dB. Similarly, the STA-MLP model exhibits a slight negative delta in this range.\nIn the high SNR range (30-40 dB), the delta values for most models, including the CNN-Transformer, TCN-DPA, and\nTRFI-MLP, approach zero. This suggests that as the SNR increases and the impact of noise decreases, the performance\ndifference between models trained on high SNR and mixed SNR datasets becomes negligible."}, {"title": "5 Conclusion", "content": "This study investigated the effectiveness of training NN-based channel estimators using mixed SNR datasets compared to\nhigh SNR datasets. Our results demonstrate that training with mixed SNR data significantly improves the generalisation\nof various estimators, especially in low SNR conditions. In particular, models such as the CNN-Transformer, DPA-TCN\nand TRFI-MLP exhibited substantial improvements in BER across the entire SNR range when trained on mixed SNR\ndata compared to when trained on high SNR. Among the models tested, the CNN-Transformer, when trained on\nmixed SNR data, outperformed other estimators, including the current state-of-the-art LSTM-DPA-TA. However, it is\nimportant to note that some models, such as LSTM-DPA-TA and STA-MLP, showed reduced performance when trained\non mixed SNR data. Mixed SNR training improves performance and generalisation across SNR levels for some models.\nThe exact reason why only certain models benefit remains unclear and requires further investigation.\nThese results indicate the importance of considering the SNR range as an important hyperparameter during training,\nrather than following the current practice of using only high SNR training data. The channel model used in this study is\nan example where the impact of mobility on the channel is more significant compared to other channels with lower\nmobility. As a result, the tested models should be able to generalise well to those channels. This will be verified in\nfuture research that will investigate the impact of mixed SNR training on other vehicular channel models."}]}