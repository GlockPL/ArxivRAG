{"title": "Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Model", "authors": ["Yuxing Tian", "Yiyan Qi", "Aiwen Jiang", "Qi Huang", "Jian Guo"], "abstract": "Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world relationships, drawing heightened interest in dynamic graph learning across academia and industry. However, existing CTDG models encounter challenges stemming from noise and limited historical data. Graph Data Augmentation (GDA) emerges as a critical solution, yet current approaches primarily focus on static graphs and struggle to effectively address the dynamics inherent in CTDGs. Moreover, these methods often demand substantial domain expertise for parameter tuning and lack theoretical guarantees for augmentation efficacy. To address these issues, we propose Conda, a novel latent diffusion-based GDA method tailored for CTDGs. Conda features a sandwich-like architecture, incorporating a Variational Auto-Encoder (VAE) and a conditional diffusion model, aimed at generating enhanced historical neighbor embeddings for target nodes. Unlike conventional diffusion models trained on entire graphs via pre-training, Conda requires historical neighbor sequence embeddings of target nodes for training, thus facilitating more targeted augmentation. We integrate Conda into the CTDG model and adopt an alternating training strategy to optimize performance. Extensive experimentation across six widely used real-world datasets showcases the consistent performance improvement of our approach, particularly in scenarios with limited historical data.", "sections": [{"title": "1 INTRODUCTION", "content": "Continuous-Time Dynamic Graphs (CTDGs), with every edge (event) having a timestamp to denote its occurrence time, are prevalent in real-world applications such as social networks [1, 11], physical systems [18] and e-commerce [46]. Recently, CTDG models [2, 16, 17, 23, 24, 26, 31, 37, 48] have gained increasing attention due to their significant representation capacity by directly learning the representation of the continuously occurring events in CTDGs. Despite the rapid advancements in CTDG models, they encounter two primary challenges. Firstly, the \"observed\" CTDG often falls short of accurately representing the true underlying process it intends to model, mainly due to various factors such as measurement inaccuracies, thresholding errors, or human mistakes [22]. Secondly, most CTDG methods typically rely on extensive historical data for effective training [26]. However, in many applications, obtaining such data is impractical, particularly in scenarios with a cold start. For instance, a nascent trading platform may only possess a few days' worth of user-asset interactions, rendering existing CTDG models trained on such limited data inadequate and resulting in sub-optimal performance.\nGraph Data Augmentation (GDA) has emerged as a promising solution, with existing methods falling into two main categories [7]: structure-oriented and feature-oriented methods. Structure-oriented methods, such as [15, 28, 42], typically involve adjusting graph connectivity by adding or removing edges or nodes. On the other hand, feature-oriented methods, exemplified by works from [12, 14, 15, 21, 32], directly modify or create raw features of nodes or edges in graphs."}, {"title": "2 PRELIMINARIES", "content": ""}, {"title": "2.1 Continuous-Time Dynamic Graph", "content": "A CTDG G can be represented as a chronological sequence of interactions between specific node pairs: G = {(uo, vo, to), ..., (un, vn, tn)}, where \\(t_i\\) denotes the timestamp and the timestamps are ordered as \\((0 \\leq t_0 \\leq t_1 \\leq ... \\leq t_n)\\). \\(u_i, v_i \\in V\\) denote the node IDs of the i - th interaction at timestamp \\(t_i\\), V is the entire node set. Each node \\(v \\in V\\) is associated with node feature \\(v_u\\), and each interaction \\((u,v,t)\\) has edge feature \\(e_u \\in \\mathbb{R}^{d_e}\\), where \\(d_n\\) and \\(d_e\\) denote the dimensions of the node and link feature respectively."}, {"title": "2.2 Diffusion Model", "content": "The diffusion model encompasses both forward and reverse processes.\nForward process. In general, given an input data point \\(x_0\\) drawn from the distribution \\(q(x_0)\\), the forward process involves gradually introducing Gaussian noise to \\(x_0\\), generating a sequence of increasingly noisy variables \\(x_1, x_2,...,x_N\\) in a Markov chain. The final noisy output, \\(x_N\\), follows a Gaussian distribution \\(\\mathcal{N}(0, I)\\) and carries no discernible information about the original data point. Specifically, the transition from one point to the next is determined by a conditional probability \\(q(x_n|x_{n-1}) = \\mathcal{N}(x_n; \\sqrt{1 - \\beta_n}x_{n-1}, \\beta_n I)\\), where \\(\\beta_n \\in (0, 1)\\) controls the scale of noise added at step n.\nReverse process. The reverse process reverses the effects of the forward process by learning to eliminate the added noise and tries to gradually reconstruct the original data \\(x_0\\) via sampling from \\(x_N\\) by learning a neural network \\(f_\\theta\\).\nInference. Once trained, the diffusion model can produce new data by sampling a point from the final distribution \\(x_N \\sim \\mathcal{N}(0, I)\\) and then iteratively denoising it using the aforementioned model \\(x_N \\rightarrow x_{N-1} \\rightarrow ... \\rightarrow x_0\\) to obtain a sample from the data distribution."}, {"title": "3 METHODOLOGY", "content": "Existing structure-oriented GDA methods like MeTA augment the CTDGs by modifying the initial interactions through edge addition/deletion and time perturbation. However, these methods introduce coarse-grained augmentations and substantially alter the original transition patterns within CTDGs. Conversely, simply introducing noise to either the raw or hidden feature space often lacks theoretical bound. In this section, we introduce a novel fine-grained GDA model based on a conditional diffusion model and establish robust theoretical guarantees."}, {"title": "3.1 CTDG model", "content": "As mentioned above, the paradigm of the CTDG model \\(\\xi\\) can be divided into two parts: the encoder module and the backbone module. Mathematically, given an interaction (u, v, t) and historical interactions before timestamp t, the computation flow unfolds as follows:\n\\[s_u = enc(\\lbrace v_w || e_{u,w} || t_l \\rbrace_{l=1}^L ), w_l \\in N_{<t}(u)  \\qquad (1)\\]\nwhere \\(s_u \\in \\mathbb{R}^{L \\times D}\\) denotes the historical neighbor embedding sequence, D represents the embedding dimension. \\(N_{<t}(u)\\) denotes the sampled set of neighbors that interacted with node u before timestamps t, \\(w_l \\in N_{<t}(u)\\) is the l-th neighbor, and \\(||\\) denotes the concatenation operation. enc() represents the general encoder module of CTDG model.\n\\[h_t = backbone(s_u) \\qquad (2)\\]\n\\(h_t \\in \\mathbb{R}^{D}\\) denotes the representation of node u at timestamp t. backbone() represents the backbone of CTDG model."}, {"title": "3.2 Conda", "content": "Due to the extensive resource requirement of the diffusion process, to reduce the costs, we first utilize a VAE encoder to conduct dimension compression and then conduct diffusion processes in the latent space."}, {"title": "VAE Encoder", "content": "Given the historical neighbor embedding sequence \\(s\\) of any node \u00b9, computed by the CTDG encoder module, we use a variational encoder parameterized by \\(\\phi\\) to compress \\(s\\) to a low-dimensional vector \\(z \\in \\mathbb{R}^{L \\times d}\\), where d << D, the VAE encoder \\(\\phi\\) predicts \\(\\mu_\\phi\\) and \\(\\sigma^2_\\phi I\\) as the mean and covariance of the variational distribution \\(q_\\phi(z|s) = \\mathcal{N}(z; \\mu_\\phi(s), \\sigma^2_\\phi(s)I)\\)."}, {"title": "Forward Process with Partial Noising", "content": "It is worth noting that, different from the conventional diffusion model that corrupts the whole variable without distinction, we conduct partial noising in order to control the magnitude of data augmentation and prepare for the reverse process with conditional denoising. Specifically, given the low-dimensional vector \\(z = [z_{w_1}, z_{w_2}, ..., z_{w_L}]\\), we can set \\(x_0 = z\\) as the initial state. Then we divide \\(x_0\\) into two part: diffused part and conditional part, \\(x_0^{diff} \\in \\mathbb{R}^{d_{diff} \\times d}\\) and \\(x_0^{cond} \\in \\mathbb{R}^{d_{cond} \\times d}\\) where \\(d_{diff} + d_{cond} = L\\) and \\(x_0 = x_0^{diff} || x_0^{cond}\\). In the forward process, we only add noise on \\(x_0^{diff}\\). Then the forward process is parameterized by\n\\[q(x_n^{diff}|x_{n-1}^{diff}) = \\mathcal{N}(x_n^{diff}; \\sqrt{1 - \\beta_n}x_{n-1}^{diff}, \\beta_n I), \\qquad (3)\\]\nwhere \\(\\beta_n \\in (0, 1)\\) controls the Gaussian noise scales added at each step n. Since the transition kernel is Gaussian, the value at any step n can be sampled directly from \\(x_0\\) in practice. Let \\(\\alpha_n = 1 - \\beta_n\\) and \\(\\bar{\\alpha}_n = \\prod_{n'=1}^{n} \\alpha_{n'}\\), then we can write:\n\\[q(x_n^{diff}|x_0^{diff}) = \\mathcal{N}(x_n^{diff}; \\sqrt{\\bar{\\alpha}_n}x_0^{diff}, (1-\\bar{\\alpha}_n) I). \\qquad (4)\\]\nwhere we can reparameterize \\(x_n = \\sqrt{\\bar{\\alpha}_n}x_0 + \\sqrt{1 - \\bar{\\alpha}_n}\\epsilon\\) with \\(\\epsilon \\sim \\mathcal{N}(0, I)\\). To regulate the added noises in \\(x_{1:N}\\), follow [35], we ultilize the linear noise schedule for \\(1 - \\bar{\\alpha}_n\\):\n\\[1 - \\bar{\\alpha}_n = k \\cdot [\\alpha_{min} + \\frac{n-1}{N-1} (\\alpha_{max} - \\alpha_{min})], \\quad n \\in \\lbrace 1,..., N \\rbrace  \\qquad (5)\\]\n\u00b9For brevity, we omit the subscript node u and superscript timestamp t in s for \\(s_u\\) unless necessary to avoid ambiguity."}, {"title": "Reverse Process with Conditional Denoising", "content": "The reverse process is used to reconstruct the original \\(x_0\\) by denoising \\(x_N\\). With the partial nosing strategy adopted in the forward process, we can naturally employ the part without noise as the conditional input when denoising.\nStarting from \\(x_N\\), the reverse process is parameterized by the denoising transition step:\n\\[p_\\theta(x_{n-1}|x_n) = \\mathcal{N}(x_{n-1}; \\mu_\\theta (x_n, n), \\sigma_\\theta (x_n, n)) \\qquad (6)\\]\nwhere \\(\\mu_\\theta (x_n, n)\\) and \\(\\sigma_\\theta(x_n, n)\\) are parameterization of the pre-dicted mean and standard deviation outputted by any neural networks \\(f_\\theta\\). Then the whole reverse process can be written as follows:\n\\[p_\\theta(x_{N:0}) = p(x_N) \\prod_{n=1}^{N} p_\\theta(x_{n-1}|x_n) \\qquad (7)\\]\nThe reconstructed output is denoted as \\(\\hat{x}_0\\)."}, {"title": "VAE Decoder", "content": "To keep the notations consistent, we set \\(\\hat{z} = \\hat{x}_0\\), \\(\\hat{z}\\) is then fed into the VAE decoder parameterized by \\(\\psi\\) to predict s via \\(p_\\psi(s|\\hat{x}_0)\\)."}, {"title": "3.3 Optimization and Alternating Training", "content": "In this section, we first present the optimization objective for the Conda and the CTDG model, respectively. Then we introduce the training and inference process of CTDG model with conda.\nAlthough our ultimate goal is to learn a CTDG model \\(\\xi\\), but we also have to learn the parameters of the VAE encoder \\(q_\\phi(z|s)\\), the conditional diffusion model \\(log\\,p_\\theta (x_0)\\) and the VAE decoder \\(p_\\psi(s|\\hat{x}_0)\\) for providing positive augmentation to the CTDG model.\nCTDG model. For training the CTDG model \\(\\xi\\), the Loss function \\(\\mathcal{L}_{ctdg}\\) depends on the downstream task. For example, if the downstream task is link prediction, then the loss function is binary cross-entropy."}, {"title": "Variational Auto Encoder", "content": "The \\(q_\\phi (z|s)\\) and \\(p_\\psi (s|\\hat{x}_0)\\) jointly constitute a VAE that bridges the embedding space and the latent space. We optimize the VAE by directly maximizing the ELBO:\n\\[\\mathcal{L}_{vae} (s; \\phi, \\psi) = \\mathbb{E}_{q_{\\phi}(z/s)} log\\,p(s,z)\\]\n\\[= \\mathbb{E}_{q_{\\phi}(z/s)} log \\frac{p(s,z)}{q_{\\phi}(z/s)}\\]\n\\[= \\mathbb{E}_{q_{\\phi}(z|s)} [log\\,p_\\psi(s|z)] +\\mathbb{E}_{q_{\\phi}(z|s)} log \\frac{p(z)}{q_{\\phi}(z/s)}\\]\n\\[= \\mathbb{E}_{q_{\\phi}(z|s)} [log\\,p_\\psi(s|z)] - D_{KL}(q_{\\phi}(z|s)||p(z))\\]\n\\[\\geq \\mathbb{E}_{q_{\\phi}(z|s)} [log\\,p_\\psi(s|z)] \\qquad (8)\\]\nwhere the first term measures the reconstruction likelihood of the decoder from variational distribution, the second term measures how similar the learned variational distribution is to a prior belief held over latent variables. Maximizing the ELBO is thus equivalent to maximizing its first term and minimizing its second term. Since the KL divergence term of the ELBO can be computed analytically, and the reconstruction term can be approximated using a Monte Carlo estimate:\n\\[arg\\,max_{\\Phi,\\psi} \\mathbb{E}_{q_{\\phi} (z/s)} [log\\,p_\\psi(s|z)] - D_{KL}(q_{\\phi}(z|s)||p(z))\\]\n\\[\\approx arg\\,max_{\\Phi,\\psi} \\frac{1}{M} \\sum_{m=1}^{M} log\\,p_\\psi (s|z^{(m)}) - D_{KL}(q_{\\phi}(z|s)||p(z)) \\qquad (9)\\]\nwhere latents \\(\\{z^{(m)}\\}_{m=1}^{M}\\) are sampled from \\(q_\\phi(z|s)\\), for every observation s in the traning sample."}, {"title": "Conditional diffusion model", "content": "To optimize the conditional diffusion model \\(\\theta\\), the training objective is to use the Variational Lower Bound (VLB) to optimize the log-likelihood of \\(x_0\\):\n\\[\\mathcal{L}_{VLB}(x_0; \\theta) = log\\,\\mathbb{E}[p_\\theta (x_0)]\\]\n\\[= log\\,\\mathbb{E}[\\int p_\\theta (x_{0:N})dx_{1:N}]\\]\n\\[\\leq log\\,\\mathbb{E}_{q(x_{1:N}|x_0)} [\\frac{p_\\theta (x_N)}{q(x_N|x_0)} + \\sum_{n=2}^{N}log \\frac{q(x_{n-1}|x_{0}, x_n)}{p_\\theta (x_{n-1}|x_n)}\\]\n\\[\\overset{\\Delta}{=} \\mathbb{L}_N + \\sum_{n=2}^{N} \\mathbb{L}_{n-1} \\qquad (10)\\]\nNext we will provide detailed to show how we estimate VLB. The term \\(\\mathbb{L}_{n-1}\\) makes \\(p_\\theta(x_{n-1}|x_n)\\) to approximate the tractable distribution \\(q(x_{n-1}|x_0,x_n)\\). Through Bayes rules, we can derive the probability of any intermediate value \\(x_{n-1}\\) given its successor \\(x_n\\) and initial \\(x_0\\) as:\n\\[q(x_{n-1}| x_n, x_0) = \\frac{q(x_n| x_{n-1}, x_0)q(x_{n-1}|x_0)}{q(x_n|x_0)} \\qquad (11)\\]\n\\[q(x_{n-1}| x_n, x_0) = \\mathcal{N}(x_{n-1}; \\tilde{\\mu}_n, \\tilde{\\beta}_n I) \\qquad (12)\\]\nwhere \\(\\tilde{\\mu}_n (x_n, x_0) = \\frac{\\sqrt{\\alpha_n}(1 - \\bar{\\alpha}_{n-1})}{1 - \\bar{\\alpha}_n}x_n + \\frac{\\sqrt{\\bar{\\alpha}_{n-1}}\\beta_n}{1 - \\bar{\\alpha}_n} x_0,  \\tilde{\\beta}_n = \\frac{1 - \\bar{\\alpha}_{n-1}}{1 - \\bar{\\alpha}_n} \\beta_n.\\)\nFurthermore, the parameterization of mean of \\(q(x_{n-1}|x_0, x_n)\\) is:\n\\[\\tilde{\\mu}_n (x_n, x_0) = \\frac{\\sqrt{\\alpha_n}(1 - \\bar{\\alpha}_{n-1})}{1 - \\bar{\\alpha}_n}x_n + \\frac{\\sqrt{\\bar{\\alpha}_{n-1}}\\beta_n}{1 - \\bar{\\alpha}_n} x_0, \\qquad (13)\\]\nthere n can be calculated by pushing \\(\\mu_\\theta (x_n, n)\\) to be close to \\(\\tilde{\\mu}_n (x_n, x_0)\\). Then, we can similarly factorize \\(\\mu_\\theta (x_n, n)\\) via\n\\[\\mu_\\theta(x_n, n) = \\frac{\\sqrt{\\alpha_n}(1 - \\bar{\\alpha}_{n-1})}{1 - \\bar{\\alpha}_n}x_n + \\frac{\\sqrt{\\bar{\\alpha}_{n-1}}\\beta_n}{1 - \\bar{\\alpha}_n} f_\\theta (x_n, n) \\qquad (14)\\]\nwhere \\(f_\\theta (x_n, n)\\) is the predicted \\(x_0\\) based on \\(x_n\\) and diffusion step n. And the \\(\\mathcal{L}_{VLB}\\) at step n can formula as :\n\\[\\mathcal{L}_{VLB_n} = \\mathbb{E}_{x_0} log \\frac{q(x_n| x_0, x_{n+1})}{p_\\theta (x_n| x_{n+1})}\\]\n\\[= \\mathbb{E}_{x_0} [ log \\frac{\\frac{1}{\\sqrt{(2\\pi)^D|\\tilde{\\beta}|}} \\exp \\{-\\frac{1}{2\\|\\tilde{\\sigma}\\|^2} ||x_{n-1} - \\tilde{\\mu}_n(x_n,x_0)||^2\\}}{\\frac{1}{\\sqrt{(2\\pi)^D|\\sigma_\\theta|^2}}\\exp {-\\frac{1}{2\\|\\sigma_\\theta\\|^2}||x_{n-1} - {\\mu}_\\theta(x_n,n)||^2\\}}} ]\\qquad (15)\\]\n\\[= \\mathbb{E}_{x_0} [\\frac{1}{2\\|\\sigma_\\theta\\|^2} (||x_0 - f_\\theta(x_n, n)||^2)]\\]\nIn practice, to keep training stability and simplify the calculation, we following the previous work [35], ignore the learning of \\(\\sigma_\\theta (x_n, n)\\) in \\(p_\\theta(x_{n-1}|x_n)\\) of Eq. (6) and directly set \\(\\sigma_\\theta (x_n, n) = \\beta_n\\). Then the optimization of training loss can be further simplified as:\n\\[min \\mathcal{L}_{VLB} (x_0; \\theta) = min \\sum_{n=2}^{N} [\\mathbb{E}_{x_0} [||x_0 - f_\\theta (x_n, n)||^2]\\]\n\\[\\to min  \\sum_{n=2}^{N}  \\mathbb{E}_{x_0} [||x_0 - f_\\theta (x_n, n)||^2] \\qquad (16)\\]"}, {"title": "Optimization of Conda", "content": "In conclusion, we combine and minimize the loss of the conditional diffusion model and VAE via \\(\\mathcal{L}_{VLB}(x_0; \\theta) + \\lambda \\cdot \\mathcal{L}_{vae} (s; \\phi, \\psi)\\) to optimize Conda, where the hyper-parameter \\(\\lambda\\) ensures the two terms in the same magnitude.\nAlternating training. Unlike the common diffusion models that are trained for the direct generation of raw graph data through pre-training, Conda requires the historical neighbor sequence embeddings of nodes obtained through the CTDG encoder before performing the diffusion process. Therefore, we utilize alternative training method to alternatively train the CTDG model and Conda.\nHere we briefly describe the training process. Initially, the CTDG model \\(\\xi\\) is trained by minimizing the \\(\\mathcal{L}_{ctdg}\\) for \\(R_{etdg}\\) rounds. Then we insert Conda into the intermediate layer of the CTDG model and train the \\(\\theta, \\phi, \\psi\\) according to \\(\\mathcal{L}_{VLB}(x_0; \\theta) + \\lambda \\cdot \\mathcal{L}_{vae} (s; \\phi, \\psi)\\) with the \\(\\xi\\) frozen for \\(R_{conda}\\) rounds. Next, we train the CTDG model \\(\\xi\\) again for \\(R_{etdg}\\) rounds with the \\(\\theta, \\phi, \\psi\\) frozen. At this point, Conda is in the inference phase, used to generate augmented historical neighbor embeddings via the reverse process. The above process will be repeated several times."}, {"title": "4 EXPERIMENTS", "content": "In this section, we evaluate the performance of our method on link prediction task across various CTDG models. All the experiments are conducted on open CTDG datasets."}, {"title": "4.1 Experiment settings", "content": "4.1.1 Datasets. We utilize six open CTDG datasets: Wiki, REDDIT, MOOC, LastFM, Social Evo, and UCI in the experiments. The detailed description and the statistics of the datasets are shown in Table 7 in Appendix A.1. The sparsity of the graphs is quantified using the density score, calculated as \\(\\frac{2|E|}{|V|(|V| - 1)}\\), where \\(|E|\\) and \\(|V|\\) represent the number of links and nodes in the training set, respectively. These datasets are split into three chronological segments for training, validation, and testing with ratios of 10%-10%-80% and 30%-20%-50%. To differentiate the datasets with different splitting ratios, the dataset names are written with suffix 0.1 and 0.3.\n4.1.2 Baselines. Since Conda is agnostic to model structure, to evaluate the performance of our GDA method, we conduct experiments on several state-of-the-art CTDG models, including JODIE [23], DyRep [31], TGAT [6], TGN [29], TCL [34], GraphMixer [5], DyG-Former [44]. We also combine our method with other data augmentation methods: DropEdge [28], DropNode [8], and MeTA [36]. Detailed descriptions of these baselines and GDA methods can be found in Appendix A.2 and Appendix A.3, respectively.\n4.1.3 Evaluation and hyper-parameter settings. We evaluate Conda on the task of link prediction. As for the evaluation metrics, we follow the previous works [36, 44], employing Average Precision (AP) and Area Under the Receiver Operating Characteristic Curve (A-R) as the evaluation metrics. We perform the grad search to find the best settings of some critical hyper-parameters. We vary the learning rates of all baselines in \\({1e-4, 1e-3}\\), the dropout rate of dropout layer in \\({0.0, 0.1, 0.2, 0.3, 0.4, 0.5}\\), the number L of sampled neighbors and the diffusion length \\(d_{iff}\\) in"}, {"title": "4.2 Performance Comparison and Discussion", "content": "In this section, in order to verify the effectiveness of Conda, we integrate it into each baseline across six datasets with different ratios of the train set for the link prediction task. As shown in Table 1 and Table 2, mean and standard deviations of five runs are reported, and the best results are highlighted in bold font. The experiment results clearly demonstrate that Conda improves the performance of all the baselines with respect to all datasets with different ratios of train sets.\nFrom the results, we can observe that with the ratio of train set decreasing, the performance of each baseline also decreases. Specifically, when the training data is relatively sufficient, all baselines achieve great performance. However, when training data is more limited, the performance of most baselines drops significantly (e.g. JODIE on Wiki_0.1, all baselines on Reddit_0.1, MOOC_0.1 and SocialEvo_0.1). The possible reason is that the paradigm of CTDG models is to use historical data to obtain target node embeddings. When historical data is limited, the quality of the obtained embeddings cannot be guaranteed. In addition, the data distribution of the testing set could be diverse from the training set. This would lead to the model overfitting the historical data and cannot be generalized to future data. By using Conda, the model's performance improves. It is achieved by utilizing the conditional diffusion model to generate augmented historical neighbor embeddings of the target node during the training of the CTDG model. In Conda, the mechanism of partial noise addition and conditional inputs ensures that the newly generated embeddings are not random. Instead, they closely resemble the embeddings of recently interacted neighbors. Consequently, this guarantees high-quality embeddings of the node's historical neighbors following augmentation.\nIn addition, we also compare Conda with three GDA methods to show the superiority of our GDA method. Overall, we find that Conda can consistently outperform competing GDA methods. Furthermore, the variance in the results indicates that Conda provides stable improvements in model performance, unlike other GDA methods that rely on random augmentations and thus yield erratic results. This stability is particularly evident in the setting with more sparse training data (e.g. 0.1 train set ratio). By analyzing the experiments on datasets with a 0.3 train set ratio, it's obvious that all GDA methods can improve baselines' performance on most datasets to some extent, but the improvement on UCI_0.3 is relatively minor compared to SocialEvo_0.3. The reason may be that SocialEvo has a smaller sparsity and longer interaction sequences than UCI. This phenomenon suggests that training the CTDG model indeed requires sufficient historical interaction data. Moreover, we notice that MeTA improves baselines' performance than DropEdge and DropNode. This might be because MeTA considers the time perturbation, which is crucial for dynamic graph learning. Additionally, unlike Dropedge and DropNode, which essentially remove edges, MeTA maintains or even increases the number of interaction data samples before and after augmentation by simultaneously adding and removing edges. However, due to the combination of multiple augmentation strategies, the results of MeTA also introduce a larger variance, indicating that it is hard to control.\nNext, we analyze the results of the experiment on datasets with a 0.1 train set ratio. Table 4 clearly shows that, apart from our method, which still achieves stable performance improvements, the other three methods frequently resulted in outcomes even worse than the original baseline. The main reason is that at such a low ratio of train sets, the datasets become extremely sparse. At this level, employing random perturbations like edge deletion further reduces the already insufficient data samples and risks removing essential interaction. However, our method maintains stable performance gains by controlling the diffused sequence length. Even though the dataset becomes sparser and the historical neighbors of nodes decrease, by simultaneously reducing the length of the diffused"}, {"title": "4.3 Ablation analysis", "content": "We conduct an ablation study to assess the contributions of the VAE and diffusion components within the Conda module. The results, summarized in Table 5, compare the baseline GraphMixer, add Conda without VAE (+Conda w/o VAE), add Conda without diffusion (+Conda w/o diffusion), and add the full Conda module (+Conda).\nIt is obvious that the full Conda module achieves the highest AP scores on all datasets, and consistently outperforms all variants, indicating the importance of both VAE and diffusion components. Removing the diffusion component results in a performance drop, particularly on WIKI_0.1 (from 94.61 to 93.87), highlighting the diffusion's role in generating effective latent representation. Similarly, removing the VAE component also decreases AP scores, especially on MOOC_0.1 (from 75.24 to 74.77). In conclusion, the combination of the VAE and diffusion model results in superior performance, as shown by consistently higher AP scores compared to the ablated variants. This synergy is crucial for optimal model performance.\nIn addition to the ablation study of the Conda module, we also explore different training approaches to further understand their impact on model performance. As shown in Table 6, we conduct experiments on GraphMixer+Conda with two different training approaches: end-to-end training (E2E) and alternative training (AT). The results indicate that the E2E training approach results in a significant performance decline across all datasets. For example, on the MOOC_0.1 and MOOC_0.3, the AP drops from 75.24.61 (AT) to 73.62 (E2E) and from 80.01 (AT) to 78.53 E2E), respectively. This decline can be attributed to conflicting objectives between the Conda module and the CTDG model. The Conda module aims to generate embeddings similar to the original data, while the CTDG model seeks to learn from diverse augmented data close to reality to enhance performance. When integrated into end-to-end training, these conflicting goals prevent the model from optimally achieving both objectives, leading to suboptimal or even diminishing performance."}, {"title": "4.4 Sensitivity of Hyper-Parameters", "content": "In this section, we conduct experiments to investigate the Sensitivity of two important hyper-parameters in our proposed method: diffused sequence length \\(d_{iff}\\) and noise scale k.\nWe conducted experiments with DyGFormer on Reddit, MOOC, and SocialEvo datasets, as DyGFormer tends to yield better results from longer historical neighbor sequences on these datasets, which can effectively show the effect on the model performance of using varying diffused lengths across the historical neighbor sequence. We also provide the optimal configurations of the number L of sampled neighbors and diffused sequence length \\(d_{iff}\\) of different baselines on different datasets in Appendix A.4. Specifically, we first set L, the number of sampled historical neighbors by DyGFormer on each dataset, to the optimal settings which can be found in the Appendix A.4. Note that in practice, if the target node's historical neighbors are fewer than L, we use zero-padding to fill the gap. Then, we vary \\(d_{iff}\\) in the set \\(\\lbrace 1, \\frac{L}{16}, \\frac{L}{8}, \\frac{L}{4}, \\frac{L}{3} \\rbrace\\) with results as shown in the Figure 2. From the Figure, we can observe that the model performance is best when \\(d_{iff} = \\frac{L}{8}\\). However, as \\(d_{iff}\\) increases, such as when \\(d_{iff} = \\frac{L}{3}\\), the model performance significantly decreases, even falling below the baseline. This phenomenon is particularly pronounced when the training set ratio of the dataset is 0.1. The underlying reason is likely due to the fact that there are few actual neighbors in the sampled historical neighbor sequence of the node,"}, {"title": "5 RELATED WORK", "content": ""}, {"title": "5.1 Graph Data Augmentation", "content": "There is a growing interest among researchers in graph data augmentation (GDA) methods since they offer an attractive solution in denoising and generally augmenting graph data. GDA methods can be categorized into structure-oriented and feature-oriented methods by the data modality that they aim to manipulate. Structure-oriented GDA methods often modify the graph structure via adding or removing edges and nodes. Zhao et al. [47", "9": "modify the graph structure and used the modified graph for training/inference, Feng et al. [8", "28": "randomly drop edges/nodes from the observed training graph. Wang et al. [38"}]}