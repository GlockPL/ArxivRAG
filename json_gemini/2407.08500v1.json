{"title": "Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Model", "authors": ["Yuxing Tian", "Yiyan Qi", "Aiwen Jiang", "Qi Huang", "Jian Guo"], "abstract": "Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world relationships, drawing heightened interest in dynamic graph learning across academia and industry. However, existing CTDG models encounter challenges stemming from noise and limited historical data. Graph Data Augmentation (GDA) emerges as a critical solution, yet current approaches primarily focus on static graphs and struggle to effectively address the dynamics inherent in CTDGs. Moreover, these methods often demand substantial domain expertise for parameter tuning and lack theoretical guarantees for augmentation efficacy. To address these issues, we propose Conda, a novel latent diffusion-based GDA method tailored for CTDGs. Conda features a sandwich-like architecture, incorporating a Variational Auto-Encoder (VAE) and a conditional diffusion model, aimed at generating enhanced historical neighbor embeddings for target nodes. Unlike conventional diffusion models trained on entire graphs via pre-training, Conda requires historical neighbor sequence embeddings of target nodes for training, thus facilitating more targeted augmentation. We integrate Conda into the CTDG model and adopt an alternating training strategy to optimize performance. Extensive experimentation across six widely used real-world datasets showcases the consistent performance improvement of our approach, particularly in scenarios with limited historical data.", "sections": [{"title": "1 INTRODUCTION", "content": "Continuous-Time Dynamic Graphs (CTDGs), with every edge (event) having a timestamp to denote its occurrence time, are prevalent in real-world applications such as social networks [1, 11], physical systems [18] and e-commerce [46]. Recently, CTDG models [2, 16, 17, 23, 24, 26, 31, 37, 48] have gained increasing attention due to their significant representation capacity by directly learning the representation of the continuously occurring events in CTDGs. Despite the rapid advancements in CTDG models, they encounter two primary challenges. Firstly, the \"observed\" CTDG often falls short of accurately representing the true underlying process it intends to model, mainly due to various factors such as measurement inaccuracies, thresholding errors, or human mistakes [22]. Secondly, most CTDG methods typically rely on extensive historical data for effective training [26]. However, in many applications, obtaining such data is impractical, particularly in scenarios with a cold start. For instance, a nascent trading platform may only possess a few days' worth of user-asset interactions, rendering existing CTDG models trained on such limited data inadequate and resulting in sub-optimal performance.\nGraph Data Augmentation (GDA) has emerged as a promising solution, with existing methods falling into two main categories [7]: structure-oriented and feature-oriented methods. Structure-oriented methods, such as [15, 28, 42], typically involve adjusting graph connectivity by adding or removing edges or nodes. On the other hand, feature-oriented methods, exemplified by works from [12, 14, 15, 21, 32], directly modify or create raw features of nodes or edges in graphs."}, {"title": "2 PRELIMINARIES", "content": ""}, {"title": "2.1 Continuous-Time Dynamic Graph", "content": "A CTDG G can be represented as a chronological sequence of interactions between specific node pairs: G = {(uo, vo, to), ..., (un, vn, tn)}, where ti denotes the timestamp and the timestamps are ordered as (0 \u2264 to \u2264 t\u2081 \u2264 ... \u2264 tn). Ui, vi \u2208 V denote the node IDs of the i - th interaction at timestamp ti, V is the entire node set. Each node v \u2208 V is associated with node feature vu, and each interaction (u, j, t) has edge feature eu \u2208 Rde, where d\u2081 and de denote the dimensions of the node and link feature respectively."}, {"title": "2.2 Diffusion Model", "content": "The diffusion model encompasses both forward and reverse processes.\nForward process. In general, given an input data point x0 drawn from the distribution q(x0), the forward process involves gradually introducing Gaussian noise to x0, generating a sequence of increasingly noisy variables x1, x2,...,x in a Markov chain. The final noisy output, X, follows a Gaussian distribution N(0, I) and carries no discernible information about the original data point. Specifically, the transition from one point to the next is determined by a conditional probability q(xn|xn\u22121) = N(xn; \u221a1 \u2013 \u03b2nxn\u22121, \u03b2\u03b7\u0399), where \u03b2\u03b7 \u2208 (0, 1) controls the scale of noise added at step n.\nReverse process. The reverse process reverses the effects of the forward process by learning to eliminate the added noise and tries to gradually reconstruct the original data xo via sampling from XN by learning a neural network fo.\nInference. Once trained, the diffusion model can produce new data by sampling a point from the final distribution x ~ N(0, I) and then iteratively denoising it using the aforementioned model x \u2192 \u2192xo to obtain a sample from the data distribution."}, {"title": "3 METHODOLOGY", "content": "Existing structure-oriented GDA methods like MeTA augment the CTDGs by modifying the initial interactions through edge addition/deletion and time perturbation. However, these methods introduce coarse-grained augmentations and substantially alter the original transition patterns within CTDGs. Conversely, simply introducing noise to either the raw or hidden feature space often lacks theoretical bound. In this section, we introduce a novel fine-grained GDA model based on a conditional diffusion model and establish robust theoretical guarantees."}, {"title": "3.1 CTDG model", "content": "As mentioned above, the paradigm of the CTDG model \u00a7 can be divided into two parts: the encoder module and the backbone module. Mathematically, given an interaction (u, v, t) and historical interactions before timestamp t, the computation flow unfolds as follows:\nsu = enc({vwr||eu, w\u2081) ||t1}), w\u2081 \u2208 N<t(u)   (1)\nwhere s\u2208 RL\u00d7D denotes the historical neighbor embedding sequence, D represents the embedding dimension. N<t(u) denotes the sampled set of neighbors that interacted with node u before timestamps t, w\u2081 \u2208 N<t(u) is the l-th neighbor, and || denotes the concatenation operation. enc() represents the general encoder module of CTDG model.\nh = backbone(s)   (2)\nh\u2208 RD denotes the representation of node u at timestamp t. backbone() represents the backbone of CTDG model."}, {"title": "3.2 Conda", "content": "Due to the extensive resource requirement of the diffusion process, to reduce the costs, we first utilize a VAE encoder to conduct dimension compression and then conduct diffusion processes in the latent space."}, {"title": "VAE Encoder", "content": "Given the historical neighbor embedding sequence s of any node \u00b9, computed by the CTDG encoder module, we use a variational encoder parameterized by $ to compress s to a low-dimensional vector z \u2208 RL\u00d7d, where d << D, the VAE encoder $ predicts \u03bc\u03c6 and ofI as the mean and covariance of the variational distribution q\u00a2(z|s) = N(z; \u03bc\u03c6(s), of(s)I)."}, {"title": "Forward Process with Partial Noising", "content": "It is worth noting that, different from the conventional diffusion model that corrupts the whole variable without distinction, we conduct partial noising in order to control the magnitude of data augmentation and prepare for the reverse process with conditional denoising. Specifically, given the low-dimensional vector z = [Zw\u2081, Zw2, ..., Zw\u2081], we can set x0 = z as the initial state. Then we divide xo into two part: diffused part and conditional part, x = xdiff ||xconda, where diff + cond = L and xo = xdiff ||xconda. In the forward xdiff. Then the forward process is process, we only add noise on xo parameterized by\nq(xdiff|xdiff) = N(xdiff; \u221a1 \u2013 Bnxdiff, BnI),  (3)\nn-1\nwhere \u03b2\u03b7 \u2208 (0, 1) controls the Gaussian noise scales added at each step n. Since the transition kernel is Gaussian, the value at any step n can be sampled directly from xo in practice. Let an = 1 \u2013 \u03b2n and \u0101n = [an, then we can write:\nq(xdiff|xdiff) = N(xdiff; Vanxdiff, (1-0 an) I). (4)\nn'=1\nwhere we can reparameterize xn = \u221a\u0101nxo + \u221a1 \u2013 \u1fb6ne with \u20ac~ N(0, I). To regulate the added noises in x1:N, follow [35], we ultilize the linear noise schedule for 1 \u2013 \u0101n:\n1 - \u1fb6n = k . [amin + (amax - amin)], \u03b7\u2208 {1,..., \u039d}  (5)\nN-1n-1\nFor brevity, we omit the subscript node u and superscript timestamp t in s for s unless necessary to avoid ambiguity."}, {"title": "Reverse Process with Conditional Denoising", "content": "The reverse process is used to reconstruct the original xo by denoising xy. With the partial nosing strategy adopted in the forward process, we can naturally employ the part without noise as the conditional input when denoising.\nStarting from xy, the reverse process is parameterized by the denoising transition step:\nPo(xn-1/xn) = N(xn\u22121; \u03bc\u03b8 (\u03a7\u03b7, \u03b7), \u03c3\u03b8 (\u03c7\u03b7, \u03b7)) (6)\nwhere \u03bc\u03b8 (\u03c7\u03b7, n) and \u03c3\u03b8(\u03c7\u03b7, n) are parameterization of the predicted mean and standard deviation outputted by any neural networks fo. Then the whole reverse process can be written as follows:\nPo(XN:0) = p(xN) [Po(Xn-1|Xn)  (7)\nn=1\nThe reconstructed output is denoted as xo.\nVAE Decoder. To keep the notations consistent, we set 2 = xo, 2 is then fed into the VAE decoder parameterized by y to predict s via py(sxo)."}, {"title": "3.3 Optimization and Alternating Training", "content": "In this section, we first present the optimization objective for the Conda and the CTDG model, respectively. Then we introduce the training and inference process of CTDG model with conda.\nAlthough our ultimate goal is to learn a CTDG model \u00a7, but we also have to learn the parameters of the VAE encoder qp(z|s), the conditional diffusion model log po (x0) and the VAE decoder py(sxo) for providing positive augmentation to the CTDG model.\nCTDG model. For training the CTDG model \u00a7, the Loss function Letdg depends on the downstream task. For example, if the downstream task is link prediction, then the loss function is binary cross-entropy."}, {"title": "Variational Auto Encoder", "content": "The q4 (z|s) and py (s|xo) jointly constitute a VAE that bridges the embedding space and the latent space. We optimize the VAE by directly maximizing the ELBO:\nLoae (s; 4, 4) =Bq4(z/s) log p(s,z)\n= Eq4(z/s) log\n94(z/s)\np(z)\n= Eqq(z|s) [logpy(s|z)] +Bqq(zs) log qp(s)\n= Eqp(z|s) [log py(s|z)] \u2013 DKLqp(z|s)p(z)\n\u2265 Eqp(z|s) [log py(s|z)] (8)\nwhere the first term measures the reconstruction likelihood of the decoder from variational distribution, the second term measures how similar the learned variational distribution is to a prior belief held over latent variables. Maximizing the ELBO is thus equivalent to maximizing its first term and minimizing its second term. Since the KL divergence term of the ELBO can be computed analytically, and the reconstruction term can be approximated using a Monte Carlo estimate:\narg max Eq4 (z/s) [logpy(s|z)] \u2013 DKL(qp(z|s)p(z))\n\u03a6\u03b9\u03c8\nM\n\u2248 arg max log py (s|z(m)) \u2013 DKL(qq(z|s)p(z)) (9)\n\u03a6\u03b9\u03c8\nm=1\nwhere latents {z(m)}M=1 are sampled from qp(z|s), for every observation s in the traning sample."}, {"title": "Conditional diffusion model", "content": "To optimize the conditional diffusion model 0, the training objective is to use the Variational Lower Bound (VLB) to optimize the log-likelihood of x0:\nLVLB(x0; 0) = log E[pe (xo)]\n\u222b\n= log E[po (xo:N)dx1:N]\nN\n\u2264log Eq(x1:Nx0) [log\n9(N/x0) + Slog\nPo (XN)\nLN\nn=2\nq(xn-1X0, Xn)\n-] (10)\nPo (Xn-1/Xn)\nLn-1\nNext we will provide detailed to show how we estimate VLB. The term Ln-1 makes po(xn-1|xn) to approximate the tractable distribution q(xn-1|x0,xn). Through Bayes rules, we can derive the probability of any intermediate value xn-1 given its successor xn and initial xo as:\nq(xn-1 xn, x0) = q(xn Xn-1, X0)\nq(xn-1/x0)\nq(xn|xo)\n(11)\nq(xn\u22121|xn, x0) = N(xn\u22121; \u03bc\u03b7, \u03b2\u03b7\u0399) (12)\nwhere \u00b5n (xn, X0) =\n1-\u0103n-1\n1 - \u0103n\n\u221aan (1-an-1)\n1 - \u0103n\nXn+\n\u03b2\u03b7 =\n\u03b2\u03b7. \u00b5\u03b8(\u03c7\u03b7, \u03b7) =\n\u221a\u0101n-1(1-an)\n\u03b2\u03b7.\nX0,\n(13)\nn can be calculated by pushing \u03bc\u03b8 (xn, n) to be close to \u00b5n (xn,\n\u221aan (1 - an-1)\n1 - \u0103n\nXn+\nfo(xn, n) (14)\n\u221a\u0101n-1(1-an)\n1 - \u0103n\nwhere fo (xn, n) is the predicted xo based on xn and diffusion step n. And the LVLB at step n can formula as :\n=log q(xn X0, Xn+1)\nLVLBn Exo log\n1\n= 2||\u03c3\u03b8||2\nPo (xn Xn+1)\n= Exo [||\u00b5n (Xn, X0) \u2013 \u00b5\u03b8 (Xn, n) ||2] -X0- \u03bc\u03b8(\u03c7\u03b7,\n1\n= 2||\u03c3\u03b8||2\n-Exo \n,\nn)\\2]\n\u221aan (1-an-1)\n1 - \u0103n\nVan-1\u00dfn\n1 - \u0103n\nXn +\n\u221aan (1-an-1)\n1 - \u0103n\nVan-1\u00dfn\n1 - \u0103n\n11(X0\n||Xo - fo (xn, n) ||\u00b2] (15)\n= -Exo\n2||\u03c3\u03b8||2\nIn practice, to keep training stability and simplify the calculation, we following the previous work [35], ignore the learning of \u03c3\u03b8 (xn, n) in po(xn-1|xn) of Eq. (6) and directly set \u03c3\u03c1 (xn, n) = \u03b2n. Then the optimization of training loss can be further simplified as:\nN\nmin LVLB (x0; 0) = min |||(XN)||\u00b2 + ||xo-fo (xn, n) ||2 (16)\nn=2\n\u03a3\u03c7\u03bf\n\u2192 min - fo (xn, n) ||2\nN\nn=2"}, {"title": "Optimization of Conda", "content": "In conclusion, we combine and minimize the loss of the conditional diffusion model and VAE via LVLB(x0; 0) + \u03bb\u00b7 Lvae (s; \u03c6, \u03c8) to optimize Conda, where the hyper-parameter A ensures the two terms in the same magnitude.\nAlternating training. Unlike the common diffusion models that are trained for the direct generation of raw graph data through pre-training, Conda requires the historical neighbor sequence embeddings of nodes obtained through the CTDG encoder before performing the diffusion process. Therefore, we utilize alternative training method to alternatively train the CTDG model and Conda.\nHere we briefly describe the training process. Initially, the CTDG model \u011f is trained by minimizing the Lctdg for Retdg rounds. Then we insert Conda into the intermediate layer of the CTDG model and train the \u03b8, \u03c6, \u03c8 according to LVLB(x0; 0) + \u03bb\u00b7 Lvae (s; \u03c6, \u03c8) with the frozen for Rconda rounds. Next, we train the CTDG model \u03be again for Retdg rounds with the \u03b8, \u03c6, \u03c8 frozen. At this point, Conda is in the inference phase, used to generate augmented historical neighbor embeddings via the reverse process. The above process will be repeated several times."}, {"title": "4 EXPERIMENTS", "content": "In this section, we evaluate the performance of our method on link prediction task across various CTDG models. All the experiments are conducted on open CTDG datasets."}, {"title": "4.1 Experiment settings", "content": ""}, {"title": "4.1.1 Datasets", "content": "We utilize six open CTDG datasets: Wiki, REDDIT, MOOC, LastFM, Social Evo, and UCI in the experiments. The detailed description and the statistics of the datasets are shown in\n2|E|\nTable 7 in Appendix A.1. The sparsity of the graphs is quantified using the density score, calculated as\n, where |E| and |V| |V|(|V| \u2013 1)\nrepresent the number of links and nodes in the training set, respectively. These datasets are split into three chronological segments for training, validation, and testing with ratios of 10%-10%-80% and 30%-20%-50%. To differentiate the datasets with different splitting ratios, the dataset names are written with suffix 0.1 and 0.3."}, {"title": "4.1.2 Baselines", "content": "Since Conda is agnostic to model structure, to evaluate the performance of our GDA method, we conduct experiments on several state-of-the-art CTDG models, including JODIE [23], DyRep [31], TGAT [6], TGN [29], TCL [34], GraphMixer [5], DyG-Former [44]. We also combine our method with other data augmentation methods: DropEdge [28], DropNode [8], and MeTA [36]. Detailed descriptions of these baselines and GDA methods can be found in Appendix A.2 and Appendix A.3, respectively."}, {"title": "4.1.3 Evaluation and hyper-parameter settings", "content": "We evaluate Conda on the task of link prediction. As for the evaluation metrics, we follow the previous works [36, 44], employing Average Precision (AP) and Area Under the Receiver Operating Characteristic Curve (A-R) as the evaluation metrics. We perform the grad search to find the best settings of some critical hyper-parameters. We vary the learning rates of all baselines in {1e-4, 1e-3}, the dropout rate of dropout layer in {0.0, 0.1, 0.2, 0.3, 0.4, 0.5}, the number L of sampled neighbors and the diffusion length diffusion"}, {"title": "4.2 Performance Comparison and Discussion", "content": "In this section, in order to verify the effectiveness of Conda, we integrate it into each baseline across six datasets with different ratios of the train set for the link prediction task. As shown in Table 1 and Table 2, mean and standard deviations of five runs are reported, and the best results are highlighted in bold font. The experiment results clearly demonstrate that Conda improves the performance of all the baselines with respect to all datasets with different ratios of train sets."}, {"title": "4.3 Ablation analysis", "content": "We conduct an ablation study to assess the contributions of the VAE and diffusion components within the Conda module. The results, summarized in Table 5, compare the baseline GraphMixer, add Conda without VAE (+Conda w/o VAE), add Conda without diffusion (+Conda w/o diffusion), and add the full Conda module (+Conda).\nIt is obvious that the full Conda module achieves the highest AP scores on all datasets, and consistently outperforms all variants, indicating the importance of both VAE and diffusion components. Removing the diffusion component results in a performance drop, particularly on WIKI_0.1 (from 94.61 to 93.87), highlighting the diffusion's role in generating effective latent representation. Similarly, removing the VAE component also decreases AP scores, especially on MOOC_0.1 (from 75.24 to 74.77). In conclusion, the combination of the VAE and diffusion model results in superior performance, as shown by consistently higher AP scores compared to the ablated variants. This synergy is crucial for optimal model performance.\nIn addition to the ablation study of the Conda module, we also explore different training approaches to further understand their impact on model performance. As shown in Table 6, we conduct experiments on GraphMixer+Conda with two different training approaches: end-to-end training (E2E) and alternative training (AT). The results indicate that the E2E training approach results in a significant performance decline across all datasets. For example, on the MOOC_0.1 and MOOC_0.3, the AP drops from 75.24.61 (AT) to 73.62 (E2E) and from 80.01 (AT) to 78.53 E2E), respectively. This decline can be attributed to conflicting objectives between the Conda module and the CTDG model. The Conda module aims to generate embeddings similar to the original data, while the CTDG model seeks to learn from diverse augmented data close to reality to enhance performance. When integrated into end-to-end training, these conflicting goals prevent the model from optimally achieving both objectives, leading to suboptimal or even diminishing performance."}, {"title": "4.4 Sensitivity of Hyper-Parameters", "content": "In this section, we conduct experiments to investigate the Sensitivity of two important hyper-parameters in our proposed method: diffused sequence length diff and noise scale k.\nWe conducted experiments with DyGFormer on Reddit, MOOC, and SocialEvo datasets, as DyGFormer tends to yield better results from longer historical neighbor sequences on these datasets, which can effectively show the effect on the model performance of using varying diffused lengths across the historical neighbor sequence. We also provide the optimal configurations of the number L of sampled neighbors and diffused sequence length diff of different baselines on different datasets in Appendix A.4. Specifically, we first set L, the number of sampled historical neighbors by DyGFormer\nLLLL\non each dataset, to the optimal settings which can be found in the 16' 8' 4' 3'Appendix A.4. Note that in practice, if the target node's historical neighbors are fewer than L, we use zero-padding to fill the gap.\nLLLL\nThen, we vary diff in the set 1,\nwith results as shown 16' 8' 4' 3'in the Figure 2. From the Figure, we can observe that the model per-L\nformance is best when diff = . However, as diff increases, such 8\nLL\nas when diff = , the model performance significantly decreases, 3\neven falling below the baseline. This phenomenon is particularly pronounced when the training set ratio of the dataset is 0.1. The underlying reason is likely due to the fact that there are few actual neighbors in the sampled historical neighbor sequence of the node,"}, {"title": "5 RELATED WORK", "content": ""}, {"title": "5.1 Graph Data Augmentation", "content": "There is a growing interest among researchers in graph data augmentation (GDA) methods since they offer an attractive solution in denoising and generally augmenting graph data. GDA methods can be categorized into structure-oriented and feature-oriented methods by the data modality that they aim to manipulate. Structure-oriented GDA methods often modify the graph structure via adding or removing edges and nodes. Zhao et al. [47] and Gasteiger et al. [9] modify the graph structure and used the modified graph for training/inference, Feng et al. [8], Rong et al. [28] randomly drop edges/nodes from the observed training graph. Wang et al. [38] utilizes a node-centric strategy to crop a subgraph from the original graph while maintaining its connectivity. However, these GDA methods are usually used in static graphs or DTDG and can not be directly applied to CTDG due to the lack of consideration of time, Although Wang et al. [36] introduces MeTA for CTDG model, which augments CTDG combining three structure-oriented GDA methods including perturbing time, removing edges, and adding edges with perturbed time. However, it is limited to apply on CTDG models with memory modules [29, 31] because it needs to incorporate a multi-level memory module to process augmented graphs of varying magnitudes at different levels. Furthermore, It is widely noticed that the effectiveness structure-oriented GDA methods requires a great of specific domain knowledge, necessitating the selection of diverse augmentation strategy combinations tailored to different graph datasets.\nFeature-oriented methods directly modify or create raw features. Hou et al. [15] uses Attribute Masking that randomly mask node features, Kong et al. [21] augments node features with gradient-based adversarial perturbations. It's worth noting that structure-oriented and feature-oriented augmentation are also sometimes combined in some GDA methods. For example, You et al. [43] summarizes four types of graph augmentations to learn the invariant representation across different augmented view. Wang et al. [39] changes both the node feature and the graph structure for different"}, {"title": "5.2 Generative Models", "content": "Generative models [10, 19] are powerful tools for learning data distribution. Recently, researchers have proposed several interesting generative models for graph data generation. Variational graph auto-encoder (VGAE) [20] exploits the latent variables to learn interpretable representations for undirected graphs. Salha et al. [30] make use of a simple linear model to replace the GCN encoder in VGAE and reduce the complexity of encoding schemes. Xu et al. [40] propose a generative GCN model to learn node representations for growing graphs. ConDgen [41] exploits the GCN encoder to handle the invariant permutation for conditional structure generation. Besides, diffusion-based generative models are shown to be powerful in generating high-quality graphs [4, 13, 27, 33]. DiGress [33], one of the most advanced graph generative models, employs a discrete diffusion process to progressively add discrete noise to graphs by either adding or removing edges and altering node categories. However, these diffusion models rely on continuous Gaussian noise and do not align well with graph structure. In addition, they are limited to generating small graphs and can not scale up to large graphs. Contrary to these approaches mainly focusing on structure generation, [25] pretrains a VAE for node feature generation, which can serve as a DA method for the downstream backbone models. However, VAE often uses over-simplified prior and decoder, which suffers from the trade-off between tractability and representation ability."}, {"title": "6 CONCLUSION", "content": "In this paper, we propose Conda, a novel GDA method designed to integrate seamlessly into any CTDG model. Conda utilizes a latent conditional diffusion model to enhance the embeddings of nodes' historical neighbor sequences during the training phase of CTDG models. Unlike structure-oriented and feature-oriented GDA methods, Conda operates within the latent space rather than the input space, thereby enabling more subtle modeling of transition in dynamic graphs. More importantly, Conda employs a conditional diffusion model to generate high-quality historical neighbor embeddings with solid theoretical foundations. Extensive experiments conducted on various baseline models using real-world datasets demonstrate the efficacy of our method Conda. In the future, we aim to extend our method to CTDG with edge deletions."}, {"title": "7 ACKNOWLEDGMENTS", "content": "The research presented in this paper is supported in part by the National Natural Science Foundation of China (Grant No. 62372362) and the National Natural Science Foundation of China (Grant No. 62366021)."}, {"title": "A APPENDIX", "content": ""}, {"title": "A.1 Detail Descriptions of Datasets", "content": "\u2022 Wiki: is a bipartite interaction graph that contains the edits on Wikipedia pages over a month. Nodes represent users and wiki pages, and links denote the editing behaviors with timestamps. Each link is associated with a 172-dimensional Linguistic Inquiry and Word Count (LIWC) feature.\n\u2022 Reddit: consists of one month of posts made by users on sub-reddits. Users and subreddits are the nodes, and links are the timestamped posting requests. Each link has a 172-dimensional LIWC feature.\n\u2022 MOOC: is a bipartite interaction network of online sources, where nodes are students and course content units (e.g., videos and problem sets). Each link denotes a student's access behavior to a specific content unit and is assigned a 4-dimensional feature.\n\u2022 UCI: is a Facebook-like, unattributed online communication network among students of the University of California at Irvine, along with timestamps with the temporal granularity of seconds.\n\u2022 LastFM: is an interaction network where users and songs are nodes and each edge represents a user-listens-to-song relation. The dataset consists of the relations of 1000 users listening to the 1000 most listened songs over a period of one month. The dataset contains no attributes.\n\u2022 SocialEvo: is a mobile phone proximity network that tracks the everyday life of a whole undergraduate dormitory from October 2008 to May 2009. Each edge has 2 features."}, {"title": "A.2 Detail Descriptions of baselines", "content": "\u2022 JODIE is a RNN-based method. Denote hu(t) as the embedding of node u at timestamp t, ev as the link feature between u, v at timestamp t, and mu as the timestamp that node u latest interact with other nodes. When an interaction between node u, v happens at timestamp t, JODIE updates the node embedding using RNN by hu(t) = RNN(hu(mu), ho(mv), eu,v, t \u2212 mu). Then, the embedding of node u at timestamp to is computed as hu (to) =\n(1+(tomu)w) hu(mu).\n\u2022 TGAT is a self-attention-based method that could capture spatial and temporal information simultaneously. TGAT first concatenates the raw feature xu with a trainable time encoding z(t), i.e., xu(t) = [xu||z(t)] and z(t) = cos(tw + b). Then, self-attention is applied to produce node representation hu(to) =\nSAM(xu (to), x(mv)|v\u2208 Nto (u)), where Nto (u) denotes the neighbors of node u at time to and mu denotes the timestamp of the"}]}