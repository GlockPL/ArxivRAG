{"title": "Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents", "authors": ["Wouter M. Kouw"], "abstract": "In nature, active inference agents must learn how observations of the world represent the state of the agent. In engineering, the physics behind sensors is often known reasonably accurately and measurement functions can be incorporated into generative models. When a measurement function is non-linear, the transformed variable is typically approximated with a Gaussian distribution to ensure tractable inference. We show that Gaussian approximations that are sensitive to the curvature of the measurement function, such as a second-order Taylor approximation, produce a state-dependent ambiguity term. This induces a preference over states, based on how accurately the state can be inferred from the observation. We demonstrate this preference with a robot navigation experiment where agents plan trajectories.", "sections": [{"title": "1 Introduction", "content": "In nature, intelligent agents build a model to infer the causes of their sensations [2]. In engineering, we are able to utilize knowledge of the relevant physics to structure such a model. In particular, we often know how sensors measure states of the world. For example, we know how radar measures relative velocity and distance [19]. Measurement functions that are non-linear transformations of state variables pose challenges to state estimation, which are often dealt with using Gaussian approximations of the transformed variables [8,14]. We show that for certain Gaussian approximations, an active inference agent will prefer to avoid states because it already knows that state estimation will be difficult.\nActive inference agents are based on free energy functionals that rank policies on explorative and goal-directed behaviour [5,7,6,16]. The expected free energy functional can be understood through its decomposition into a cross-entropy term between states and observations given action (\"ambiguity\"), and a Kullback-Leibler divergence between the posterior predictive and a goal prior distribution (\"risk\") [7,18,4]. We show that Gaussian approximations of a non-linear observation function that are itself linear in the covariance matrix, e.g.,"}, {"title": "2 Problem statement", "content": "We want to plan a trajectory for a robot across a plane. The robot's state at time k is its planar position and time derivatives, $x_k \\in \\mathbb{R}^D$. The robot does not sense position directly, but has to infer it from noisy measurements $y_k \\in \\mathbb{R}^{D_y}$, produced by a sensor through a non-linear mapping $g : \\mathbb{R}^{D_x} \\rightarrow \\mathbb{R}^{D_y}$ and measurement noise $v_k \\in \\mathbb{R}^{D_y}$. It accepts control inputs $u_k \\in \\mathbb{R}^{D_u}$ and moves according to linear dynamics with a transition matrix $A \\in \\mathbb{R}^{D_x \\times D_x}$, control matrix $B \\in \\mathbb{R}^{D_x \\times D_u}$ and process noise $e_k \\in \\mathbb{R}^{D_x}$. Overall, we consider robot systems described with discrete-time state-space models of the form:\n$x_k = Ax_{k-1}+ Bu_k + e_k, \\qquad e_k \\sim \\mathcal{N}(0, Q),$\\n$y_k = g(x_k) + v_k, \\qquad v_k \\sim \\mathcal{N}(0, R),$\\nwhere $Q \\in \\mathbb{R}^{D_x \\times D_x}$, $R \\in \\mathbb{R}^{D_y \\times D_y}$ are noise covariance matrices.\nThe goal is to find a sequence of $T$ controls $\\bar{u}_k = {u_{k+1},... u_{k+T}}$ that produces future states close to a desired state $x^*$. Agents must plan every time-step. The challenge is that errors in state estimation may cause drastic changes in the planned trajectory, which can lead an agent astray.\nConsider a robot with position and velocity states that must move from position $x_0 = (0, -1)$ to $x^* = (0, 1)$. Its state transition, control and process noise covariance matrices are given by:\n$A=\\begin{bmatrix}1 & 0 & \\Delta t & 0\\\\0 & 1 & 0 & \\Delta t\\\\0 & 0 & 1 & 0\\\\0 & 0 & 0 & 1\\end{bmatrix}$, $B=\\begin{bmatrix}0 & 0\\\\0 & 0\\\\\\Delta t & 0\\\\0 & \\Delta t\\end{bmatrix}$, $Q=\\begin{bmatrix}0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0\\\\0 & 0 & \\sigma_1^2\\frac{\\Delta t^3}{3} & \\sigma_1^2\\frac{\\Delta t^2}{2}\\\\0 & 0 & \\sigma_1^2\\frac{\\Delta t^2}{2} & \\sigma_1^2\\Delta t\\end{bmatrix}$,\nfor $\\Delta t = 0.5$, $\\sigma_1 = \\sigma_2 = 0.1$. Measurements are produced by a sensor station at (0,0) that reports relative angle $\\varphi_k \\in [-\\pi, \\pi]$ and relative distance $d_k \\in [0, \\infty)$. The mapping and measurement noise covariance matrix are:\n$\\begin{bmatrix}\\varphi_k\\\\d_k\\end{bmatrix} = \\begin{bmatrix}arctan(x_{1k}, x_{2k})\\\\\\sqrt{x_{1k}^2 + x_{2k}^2}\\end{bmatrix}$, $R = \\begin{bmatrix}\\rho & 0\\\\0 & \\rho\\end{bmatrix}$,"}, {"title": "3 Agent specification", "content": "The agent's model will have Gaussian prior distributions over states and controls,\n$p(x_0) = \\mathcal{N}(x_0 \\; | \\; m_0, S_0), \\qquad \\mathcal{N}(u_k \\; | \\; 0, \\eta^{-1}I),$\nwith mean $m_0$, covariance matrix $S_0$, precision $\\eta$ and identity matrix $I$. The agent's state transition will also be expressed as a Gaussian distribution:\n$p(x_k \\; | \\; x_{k-1}, u_k) = \\mathcal{N}(x_k \\; | \\; Ax_{k-1} + Bu_k, Q).$"}, {"title": "3.2 Inferring states", "content": "We assume that, when inferring states, the agent has observed the system output $y_k = \\hat{y}_k$ and input $u_k = \\hat{u}_k$. Let $D_k \\doteq {\\hat{y}_i, \\hat{u}_i}_{i=1}^k$ refer to data observed thus far. Given the known executed control, state estimation follows the general Bayesian filtering equations [14]. Firstly, the prior predictive distribution is given by:\n$p(x_k \\; | \\; \\hat{u}_k, D_{k-1}) = \\int p(x_k \\; | \\; x_{k-1}, \\hat{u}_k) \\; p(x_{k-1} \\; | \\; D_{k-1})dx_{k-1} = \\mathcal{N}(x_k \\; | \\; m_k, \\mathcal{S}_k).$\nwith $m_k \\doteq Am_{k-1} + B\\hat{u}_k$ and $\\mathcal{S}_k \\doteq A S_{k-1} A^T + Q$. This prediction is corrected by the observation through Bayes' rule [14],\n$p(x_k \\; | \\; D_k) = \\frac{p(y_k \\; | \\; x_k)}{p(\\hat{y}_k \\; | \\; D_{k-1})} p(x_k \\; | \\; \\hat{u}_k, D_{k-1}) = \\mathcal{N}(x_k \\; | \\; m_k, S_k),$\nwith $m_k \\doteq m_k + \\Gamma_k \\Sigma_k^{-1}(\\hat{y}_k - \\mu_k)$ and $S_k = \\mathcal{S}_k - \\Gamma_k \\Sigma_k^{-1}\\Gamma_k^T$."}, {"title": "3.3 Inferring controls", "content": "We will discuss the inference procedure first for a single step into the future, and then generalize to a finite horizon of length $T$. Predictions for the future state and observation are made by unrolling the generative model to $t = k + 1$:\n$p(y_t, x_t, u_t \\; | \\; D_k) = p(y_t \\; | \\; x_t) p(x_t \\; | \\; u_t; D_k) p(u_t).$\nWe will use an expected free energy functional to infer a posterior distribution over the control $u_t$ [13]:\n$F_k[q] = \\int q(y_t, x_t, u_t) \\; \\text{In} \\; \\frac{q(x_t, u_t)}{p(y_t, x_t, u_t \\; | \\; D_k)}d(u_t, x_t)dy_t.$"}, {"title": "4 Gaussian approximations", "content": "We discuss the three most popular Gaussian approximations to non-linear transformations of Gaussian random variables: the first and second-order Taylor series approximations (used in extended Kalman filters) and the unscented transform (used in the unscented Kalman filter) [9,8][14, Ch. 5].\nThe first-order Taylor series approximation effectively linearizes the non-linear observation function $g(x_t)$. Since ambiguity is known to be constant over states under a linear observation function [10], it is no surprise that the first-order Taylor also leads to an ambiguity term that is constant over states.\nLet $G_x(m_t)$ be the Jacobian of $g$ with respect to $x_t$, evaluated at $m_t$. Under a first-order Taylor approximation, the parameters $\\Sigma_t, \\Gamma_t$ are:\n$\\Sigma_t = G_x(m_t)S_tG_x(m_t)^T + R, \\qquad \\Gamma_t = S_tG_x(m_t)^T.$\nWith these parameters, the ambiguity term does not depend on the state $x_t$:\n$\\mathbb{E}_{p(y_t, x_t \\; | \\; u_t;D_k)} [-\\text{In} \\frac{p(x_t \\; | \\; u_t; D_k)}{p(y_t, x_t \\; | \\; u_t; D_k)}] = -\\frac{1}{2}\\text{In}|R|.$\nPerhaps surprisingly, under the second-order Taylor approximation, the ambiguity term varies as a function of the state $x_t$.\nLet $G_{ij}^o(m_t)$ be the Hessian of the $i$-th element of the non-linear observation function evaluated at $m_t$, and let $e_i$ be a canonical basis vector. The parameters $\\Sigma_t, \\Gamma_t$ computed through a second-order Taylor approximation are:\n$\\Sigma_t = G_x(m_t)S_tG_x(m_t)^T + \\frac{1}{2} \\sum_{i=1}^{D_y} \\sum_{j=1}^{D_y} e_i e_j^T \\text{tr}(G_{ij}^o(m_t)S_tG_{ij}^o(m_t)S_t) + R$\n$\\Gamma_t = S_tG_x(m_t)^T.$\nWith these parameters, the ambiguity term depends on $x_t$ through:\n$\\mathbb{E}_{p(y_t, x_t \\; | \\; u_t;D_k)} [-\\text{In} \\frac{p(x_t \\; | \\; u_t; D_k)}{p(y_t, x_t \\; | \\; u_t; D_k)}] = \\text{In} |\\frac{1}{2} \\sum_{i=1}^{D_y} \\sum_{j=1}^{D_y} e_i e_j^T \\text{tr}(G_{ij}^o(m_t)S_tG_{ij}^o(m_t)S_t) + R|.$"}, {"title": "5 Experiments", "content": "Our experiment is as described in Section 2, with the nonlinear observation function g(.) measuring relative angle and distance to a base station. Examples of sensors include Hall effect and ultrasound sensors. The robot starts at xo = [0 -1 0 0] and must reach x* = [0 1 0 0]. The agent's state prior distribution's parameters were mo = [0 -1 0 0] and So = 0.5I. Its control prior precision was set to a tiny value, \\eta = 1.0\\cdot10^{-8}, so as to best study the effects of ambiguity and risk. It was given a goal prior of m* = g(x*) and S* = 0.5I.\nWe will compare three agents: firstly, an agent that uses the first-order Taylor approximation, referred to as EFE1. Secondly, an agent with a second-order Taylor approximation, referred to as EFE2. Thirdly, an agent with a second-order Taylor approximation but with only the risk term included, referred to as EFER. The difference between EFER and EFE2 reflects the effect of the ambiguity term, while the difference between EFE1 and EFE2 reflects the effect of"}, {"title": "6 Discussion", "content": "One could argue that our analysis is more about model selection than inference, as each Gaussian approximation essentially constitutes a different generative model. In that sense, the experiments only indicate that richer approximations of nonlinear functions lead to better performance, which is not surprising. However, the result is more subtle than that since the unscented transform is richer than the first-order Taylor (produces a more accurate mean estimate [8]) but apparently still leads to constant ambiguity. No, the approximation must be sensitive to how the covariance between states and observations changes as a function of g's curvature. It would be interesting to extend this work with parameter estimation, such as inferring the process noise covariance matrix using a Wishart distribution [15], or the state transition matrix with a Matrix-Normal distribution [1,12]."}, {"title": "7 Conclusion", "content": "We examined active inference agents with linear Gaussian distributed dynamics and a non-linear measurement function. We found that the first-order Taylor series and unscented transform approximations to the non-linearly transformed states lead to expected free energy functions with ambiguity terms that are constant over states. A second-order Taylor approximation leads to a state-dependent ambiguity term, inducing a preference over states."}, {"title": "A Appendix: proof of Lemma 1", "content": "$\\mathbb{E}_{p(y_t, x_t \\; | \\; u_t;D_k)} [-\\text{In} \\frac{p(x_t \\; | \\; u_t; D_k)}{p(y_t, x_t \\; | \\; u_t; D_k)}]$\n$= - \\int \\mathcal{N}\\begin{pmatrix} x_t\\\\y_t\\end{pmatrix} \\begin{pmatrix}m_t\\\\\\mu_t\\end{pmatrix}, \\begin{pmatrix}S_t & \\Gamma_t\\\\\\Gamma_t^T & \\Sigma_t\\end{pmatrix} \\text{In} \\mathcal{N}(y_t \\; | \\; y_t, \\Sigma_t) \\; dy_t,dx_t$\n$= - \\int \\mathcal{N}(x_t \\; | \\; m_t, S_t) \\text{In} \\mathcal{N}(y_t \\; | \\; \\mu_t, \\Sigma_t)$\n$= \\frac{D_x + D_y}{2} \\text{In}(2\\pi e) + \\frac{1}{2} |S_t^{-1}\\Gamma_t\\Sigma_t^{-1}| - \\frac{D_x}{2} \\text{In}(2\\pi e) + \\frac{1}{2} |S_t|$\n$= \\frac{D_y}{2} \\text{In}(2\\pi e) + \\frac{1}{2} \\text{In} |\\Sigma_t - \\Gamma_t S_t^{-1} \\Gamma_t^T| - \\frac{1}{2} |S_t|$\n$= \\frac{D_y}{2} \\text{In}(2\\pi e) - \\frac{1}{2} \\text{In} |\\Gamma_t S_t^{-1} \\Gamma_t^T S_t|.$"}, {"title": "B Appendix: proof of Theorem 1", "content": "- \\frac{1}{2} |\\Sigma_t - \\Gamma_t S_t^{-1} \\Gamma_t^T|$\n$= -\\frac{1}{2} \\text{In}|G_x(m_t)S_tG_x(m_t)^T + R - G_x(m_t)S_tS_t^{-1}S_tG_x(m_t)^T|$\nSince the covariance matrix $S_t$ is symmetric, $S_t S_t^{-1} = S_t S_t^{-1} = I$. Thus:\n$- \\frac{1}{2} \\text{In}|G_x(m_t)S_tG_x(m_t)^T + R - G_x(m_t)S_tG_x(m_t)^T| = -\\frac{1}{2} \\text{In} |R|.$"}, {"title": "C Appendix: proof of Theorem 2", "content": "- \\frac{1}{2} \\text{In} |\\Sigma_t - \\Gamma_t S_t^{-1} \\Gamma_t^T| = -\\frac{1}{2} \\text{In} | G_x(m_t) S_t G_x(m_t)^T +$\n$\\frac{1}{2} \\sum_{i=1}^{D_y} \\sum_{j=1}^{D_y} e_i e_j^T \\text{tr}(G_{ij}^o(m_t) S_t G_{ij}^o(m_t) S_t) + R - G_x(m_t) S_t G_x(m_t)^T|.$\nThe covariance matrix $S_t$ is symmetric. Thus, $S_t S_t^{-1} = S_t S_t^{-1} = I$. Note that the Hessian $G_{ij}^o(m_t)$ depends on the inferred mean of the predicted state $m_t$."}, {"title": "D Appendix: proof of Theorem 3", "content": "- \\frac{1}{2} \\text{In} |\\Sigma_t - \\Gamma_t S_t^{-1} \\Gamma_t^T| = \\frac{1}{2} \\text{In}| \\sum_{i'=0}^{2D_x} w_i (g(x_i) - \\mu_t) (g(x_i) - \\mu_t)^T + R| -$\n$(\\sum_{i=0}^{2D_x} w_i (x_i - m_t) (g(x_i) - \\mu_t)^T ) S_t^{-1} (\\sum_{j=0}^{2D_x} w_j (x_j - m_t) (g(x_j) - \\mu_t)^T ).$\nThe second term can be re-arranged to:\n$\\sum_{i'=0}^{2D_x} (w_i (x_i - m_t) (g(x_i) - \\mu_t)^T ) S_t^{-1} (\\sum_{j=0}^{2D_x} w_j (x_j - m_t) (g(x_j) - \\mu_t)^T )$\n$= \\sum_{i=0}^{2D_x} \\sum_{j=0}^{2D_x} w_i (g(x_i) - \\mu_t) (x_i - m_t)^T S_t^{-1} w_j (x_j - m_t) (g(x_j) - \\mu_t)^T.$"}]}