{"title": "Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities", "authors": ["Adam Goodge", "Wee Siong Ng", "Bryan Hooi", "See Kiong Ng"], "abstract": "Foundation models have revolutionized artificial intelligence, setting new benchmarks in performance and enabling transformative capabilities across a wide range of vision and language tasks. However, despite the prevalence of spatio-temporal data in critical domains such as transportation, public health, and environmental monitoring, spatio-temporal foundation models (STFMs) have not yet achieved comparable success. In this paper, we articulate a vision for the future of STFMs, outlining their essential characteristics and the generalization capabilities necessary for broad applicability. We critically assess the current state of research, identifying gaps relative to these ideal traits, and highlight key challenges that impede their progress. Finally, we explore potential opportunities and directions to advance research towards the aim of effective and broadly applicable STFMs.", "sections": [{"title": "I. INTRODUCTION", "content": "The emergence of deep learning has significantly advanced state-of-the-art performance in an astonishingly diverse range of applications. In recent years, foundation models (FMs) [8], large neural networks pre-trained on large-scale and broad data, have enabled transformative success particularly in language and vision tasks due to their remarkable abilities to \"generalize\" to a wide range of downstream tasks through the notion of transfer learning. However, FMs have yet to achieve a similar impact on state-of-the-art performance in tasks involving spatio-temporal data. Encompassing all kinds of data with both spatial and temporal dimensions, spatio-temporal (ST) data is pervasive across an extremely diverse range of fields, including urban analysis [37], [45], [50], [53], [58], weather forecasting [9], [30], [38], climate science [16], [18], [31], [54], environmental monitoring [1], [4], [26], [51], agriculture [10], [14], [34], [55], and public health [36], [42], [49], [60], [64]. As the collection and distribution of spatio-temporal data continues to grow from diverse sources, so does the feasibility and potential of spatio-temporal foundation models (STFMs) to learn shared patterns across different domains, improving efficiency and enhancing generalization, particularly for data-deficient applications. However, progress remains slow due to a number of characteristics of ST data which significantly complicates the learning of STFMs. Moreover, current research is highly fragmented by application, which hinders progress towards a truly universal STFM comparable to those developed for language and vision.\nIn this paper, we present a vision for the future of STFMs and their potential to advance state-of-the-art performance across diverse spatio-temporal applications. We outline the key generalization capabilities that are essential for broadly applicable STFMs and examine the primary challenges and obstacles to their development. We critically evaluate the current state of research in this direction, identifying gaps relative to these ideal traits. We also explore opportunities for further advancement through targeted research and innovation. In summary, the key contributions of this work are as follows:\n\u2022\nWe propose a vision for the direction of spatio-temporal foundation models by identifying their key desirable capabilities.\n\u2022\nWe examine existing efforts in STFM research and assess current capabilities with respect to these ideals.\n\u2022\nWe consider the main avenues and opportunities for further research to further boost performance and applicability."}, {"title": "II. PRELIMINARIES", "content": "Spatio-temporal data is any kind of data that involves both spatial and temporal dimensions. Most abstractly, it can be understood as a set of time-series sequences, each of which is associated with a specific spatial location. We denote a ST sequence as $X \\in R^{V \\times N \\times T}$, where V represents the number of variables or features, N is the number of spatial locations (typically but not necessarily determined by the number of sensors or measuring devices), and T is the number of time-steps. In practice, ST data comes in several different formats or structures, and different formats are suited to different applications. Figure 1 categorizes the four types of ST data, along with illustrative examples of their applications. We now describe each type of ST data in detail.\nRaster data is structured on a regular and fixed spatial grid with height H and width W. In this format, N is equal to the total number of cells in the grid, i.e. $N = H \\times W$. Note that the features in each cell may not correspond to a unique data recording or sensor within the physical system, which depends on physical and logistical constraints. Instead, raw measurements can be converted into raster data of a desired resolution through various interpolation techniques. Raster data is widely used in ST applications, ranging from transportation, weather & climate analysis, medical imaging, remote sensing, and many more. Video data can also be considered a special form of raster data, in which each cell represents a pixel and contains its own set of RGB values at each time-step.\nPoint reference data is similar to raster data except the spatial locations of data measurements are subject to change from one time step to another. For example, climate data collected by weather balloons which move over time due to air currents, or sea surface temperatures recorded by sensors attached to drifting buoys. In this case, the evolving spatial position becomes an additional variable that must be tracked and recorded at each time step, adding complexity to the data structure.\nTrajectories represent the paths traced by moving objects through space over time, consisting of paired sets of geographical co-ordinates and time-stamps: {$l_i$, $t_i$}. They are commonly found in applications related to mobility, such as pedestrian or vehicular movement tracking. When dealing with multiple moving objects, it is typical to group trajectories into discrete buckets, where the features represent the number of trajectories within a specific spatial boundary over a specific time-period, closely resembling raster data.\nEvent Data is characterized by a set of tuples {$e_i$,$l_i$,$t_i$}, where each tuple corresponds to a discrete event of type $e_i$, recorded at location $l_i$ and time $t_i$. Events are typically rare, such as crimes or traffic accidents. As a result, event data is typically much sparser than other forms of ST data, with a large proportion of zero entries. This sparsity presents unique challenges and requires specialized techniques to model and analyze the data effectively.\nAs outlined in [20], spatio-temporal data exhibits two key properties. The first property is heterogeneity, which means that ST patterns can vary across spatial (from one location to another) and temporal (from one time period to another) ranges and scales. Heterogeneity is a particularly challenging property, as it violates the assumption that all data samples are independent and identically distributed, i.e. drawn from the same probability distribution. The second property is auto-correlation, which reflects that measurements taken closer together tend to follow more similar distributions, where closeness can be understood in both the spatial and the temporal sense. This is neatly summarized in Tobler's First Law of Geography, which states that \u201ceverything is related to everything else, but near things are more related than distant things\u201d."}, {"title": "B. Spatio-Temporal Data Mining", "content": "Spatio-temporal data mining involves learning to model both the spatial and temporal patterns within a set of ST data. In recent years, neural networks that integrate convolutional and recurrent modules have proven particularly successful at capturing both spatial and temporal dependencies. CNN-LSTMs firstly use a convolutional neural network (CNN) to extract spatial features from input data, followed by a long short-term memory (LSTM) network to learn sequential patterns from the extracted spatial features [7], [11], [57]. Alternatively, ConvLSTMs [5], [15], [22], [27], [41], [47] replace the matrix multiplications in the LSTM gates with convolution operations to capture spatial dependencies within the sequential model.\nSpatio-temporal graph neural networks (ST-GNNs) [3], [21], [30], [33], [39], [40], [44], [58], [65] have recently gained prominence due to their ability to flexibly handle ST data that does not conform to a regular grid structure. Instead, they operate over spatio-temporal graphs, which represent the spatial locations as nodes or vertices in a graph, with connecting edges representing spatial relationships between adjacent nodes, such as proximity or connectivity. More details about ST-GNNs can be found in [20].\nFollowing success in other modalities, transformers [46] have also gained significant attention for spatio-temporal data [2], [17], [23], [29], [56], [59] due to their ability to capture long-range dependencies across space and time through the self-attention mechanism. Unlike convolutional models, which operate over local receptive fields, or recurrent models, which depend on sequential processing, transformers can learn global relationships by attending to all parts of an input sequence simultaneously. This is particularly useful in domains where complex, non-linear interactions evolve over large spatial areas and extended time periods. Transformer models are also heavily relied upon in foundation models in other modalities, However, the vast majority of ST research continues to adopt a one-model-per-task paradigm, in which separate models are trained for single tasks with specific training data."}, {"title": "III. SPATIO-TEMPORAL FOUNDATION MODELS", "content": "The key distinction between the one-model-per-task-paradigm and the foundation model paradigm is their notion of generalization.\nDefinition 3.1: Generalization is the ability of a model to learn patterns which effectively transfer from one set of data to another.\nIn the one-model-per-task paradigm, models are trained to perform a single task with data from a single domain and only expected to generalize to unseen samples from the same underlying distribution. On the other hand, foundation models are trained with much broader data and expected to generalise to new and unseen data drawn from other distributions. With this context, we define a spatio-temporal foundation model as follows:\nDefinition 3.2: A Spatio-Temporal Foundation Model (STFM) is a large-scale neural network pre-trained on diverse spatio-temporal data sources, designed to generalize across multiple tasks by learning universal patterns of spatial and temporal dependencies.\nThis description is intentionally broad to reflect the significant diversity within existing STFM research. We observe that the \"foundation-ness\" of foundation models is not a binary description, rather it exists on a spectrum with varying levels of demonstrated generalization capabilities. To begin to decipher this diversity, we pose the fundamental question: what should a spatio-temporal foundation model be able to do? We address this question by identifying four main ways in which tasks can vary in the spatio-temporal context, leading to four forms of generalization by which to evaluate the capabilities of STFMs. In summary, these are as follows:\n1) Domain generalization: across different sources of data representing different physical systems and categories of applications.\n2) Spatial generalization: across different locations or re-gions in space.\n3) Temporal generalization: across different periods and intervals of time.\n4) Scale generalization: across different resolutions, fre-quencies or granularities of data.\nThese generalization capabilities can be evaluated in two distinct ways:\n\u2022\nIn-distribution generalization: We can assess the model's ability to learn generalizable patterns across multiple domains and distributions during pre-training by evaluating its performance on tasks encountered during that phase.\n\u2022\nOut-of-distribution generalization: Alternatively, we can evaluate the model's ability to transfer to new tasks that were not observed during pre-training, even without prior exposure to their data distribution."}, {"title": "A. Generalization Capabilities of STFMs", "content": "In the remainder of this section, we comprehensively detail the four types of generalization, and identify the key challenges in achieving them with current data and technological constraints.\n1) Domain Generalization: As discussed, ST data is prevalent in a highly diverse range of applications. Figure 3 illustrates a small selection of example applications, organized by top-level categories or domains: transportation, weather &\nclimate and urban activity. Each of these categories encompasses a plethora of individual applications. For example, the transportation domain includes traffic flow measured by road network sensors, the time and location of traffic incidents, or the volume of passengers entering and exiting a public transport network at different stops. Within weather & climate, there is a wide variety of different atmospheric variables, such as air temperature, precipitation, or the concentration of different pollutants. Given these diverse applications, the first type of generalization is across different domains of data.\na) Challenge: Foundation models rely on the existence of shared patterns across different data sources or domains. For example, in language, the semantic meaning of words are generally consistent across various contexts, and sentences adhere to a common set of grammatical rules. In contrast, the rules that determine the distribution of ST data are highly application-dependent. For example, in a transportation net-work, applications like traffic flow and traffic incidents are likely to exhibit strong correlations because they both pertain to the same underlying physical system. Similarly, within weather & climate studies, the concentration of pollutants in the air is often closely correlated with rainfall occurrence and intensity. In these cases, training a spatio-temporal foundation model (STFM) with data from both applications could offer mutual benefits by leveraging these shared patterns. However, the existence of shared patterns becomes much less clear between more disparate applications, such as traffic incidents and disease outbreaks. In such cases, it is uncertain whether training an STFM to simultaneously model both applications would enhance or degrade performance for either, a phenomenon known as negative transfer in the deep learning community. This highlights the challenges of developing an STFM that can generalize effectively across diverse applications. As discussed in Section IV, current research typically focuses on more narrowly defined STFMs, often limited to a few applications within a single domain, rather than addressing cross-domain generalization.\n2) Spatial Generalization: The second type of generalization is across different locations in space. An STFM should not only be limited to applications from a limited selection of geographic spaces; it should learn from diverse environments and conditions simultaneously, and also be able to transfer to unseen places during inference.\na) Challenge: ST data can exhibit significant spatial heterogeneity. In other words, data patterns can vary significantly from one location to another, even within a single application. For example, in traffic flow, a model trained on traffic data from one city may struggle to generalize to another city with different road networks or traffic regulations. In pollutant concentration, a model trained on data from heavily urbanized areas may struggle to generalize to suburban or rural areas. This challenge is particularly acute in applications where existing dataset available for use in pre-training are heavily biased towards certain regions. For example, a disproportionate amount of the traffic datasets commonly used in existing studies are collected in a small number of major urban centers like Beijing, New York City, and London. This limitation increases the risk that an STFM is biased towards the patterns found in these cities and others like them, while failing to generalize to the vast majority of other regions with a smaller or no presence at all in the training data.\n3) Temporal Generalization: STFMs should also be able to generalize across different periods of time. For example, it should perform well both during both day and night, on weekdays as well as weekends, and from one year to the next.\na) Challenge: Spatio-temporal patterns are inherently dynamic, continuously evolving in complex ways. As a result, the patterns learned by models may lose relevance over time. These changes can occur gradually, as the characteristics of a given space evolve. For instance, general population growth in a city leads to a steady increase in traffic and public transport usage. Such gradual changes are typically easier to manage, as the slow pace of the data distribution shift provides an opportunity to adapt the model by re-training it with more recent data. In contrast, some changes are abrupt and drastic. These often result from interventions, such as the opening of a new attraction that drives a sudden surge in traffic, or from unforeseen events like natural disasters. Such shifts are far more challenging to accommodate, as their effects are complex and the distribution shift is akin to a step-change, creating a significant gap between the most recent historical data and the new reality. This limits the ability to retrain the model effectively in response to these sudden changes.\n4) Scale Generalization: Spatio-temporal data spans a broad range of scales. Spatially, this can range from small-scale measurements, such as those at the meter level, to large-scale observations covering distances of hundreds of kilometers or more. Similarly, temporal scales vary from high-frequency observations, with timestamps in seconds or minutes, to low-frequency data collected over days or weeks. An STFM must be capable of generalizing across these diverse spatial and temporal scales.\na) Challenge: Spatio-temporal patterns can be highly scale-dependent, i.e, patterns can differ significantly depending on the scale at which the data is observed. This is particularly evident in weather applications, where a model trained on global weather patterns may not perform well on a fine-grained, region-level scale as individual regions have unique features and micro-climates which are less prominent in broader, global-level data. To overcome this, existing research in spatio-temporal data mining has explored hierarchical architectures, which are designed to capture patterns at multiple levels and across different scales."}, {"title": "IV. CURRENT RESEARCH IN STFMS", "content": "In this section, we examine the current landscape of STFM research, focusing on a selection of particularly recent and impactful models. We begin by briefly describing each model. UniST [61] adopts a transformer-based encoder-decoder architecture, trained via masked-patch modeling where the objective is to reconstruct the original data from masked tokens in the model output. It uses various types of mask in pre-training to simulate several different problems in the reconstruction phase. It also constructs pools of learned prompts to encode different forms of spatio-temporal knowledge, e.g. spatial proximity and daily or weekly periodicity, which are added to the masked token embeddings to guide the model towards a better prediction. OpenCity [25] combines the transformer architecture with graph neural networks to learn spatio-temporal dependencies from large-scale, heterogenous traffic datasets. Alternatively, UrbanGPT [24] learns to encode ST sequences into new representations which can be incorporated into natural language prompts that can be understood and processed by a large language model. ClimaX [35] employs a vision transformer for various weather and climate-related tasks. It tokenizes and embeds each variable independently in order to flexibly handling varying numbers of input variables, and then aggregates across variables for a given region to reduce memory complexity. Pangu-Weather designs a 3D Earth Specific Transformer (3DEST) that processes weather information into cubic data and performs supervised training for various weather forecasting tasks."}, {"title": "A. Current STFM Generalization Capabilities", "content": "Table I shows our qualitative assessment of the generalization capabilities of the current state-of-the-art STFMs, based on their demonstrated performance in the original art. We now explain our assessment."}, {"title": "B. Domain Generalization", "content": "An immediate observation is that, unlike FMs for other modalities, STFMs are highly fragmented by application. UniST, UrbanGPT and OpenCity are almost exclusively focused on traffic data Both UniST and OpenCity are trained and evaluated on 21 datasets in total, however the majority of these relate to traffic speed or flow in both cases, and a few other datasets for bike usage, taxi trajectories and cellular usage. Both models are evaluated in adapting to previously unseen applications by leaving certain datasets out of the training distribution entirely. On the other hand, UrbanGPT uses only four datasets from taxi, bike, and crime applications, three of which are used in pre-training.\nPangu-Weather and ClimaX are focused on a variety of atmospheric variables. ClimaX takes 48 input variables in total, but is only evaluated in forecasting 4 of them. Pangu-Weather, on the other hand, is only evaluated in predicting"}, {"title": "C. Spatial Generalization", "content": "The spatial coverage of publicly available traffic datasets are limited to only a few major urban centers. The datasets used in both pre-training and evaluation of UniST and OpenCity come from various cities in the United States and China, and they are evaluated in their generalization to unseen regions of these cities. UrbanGPT is exclusively trained on data from New York City, and evaluated in its generalization to unseen regions with the city, as well as to a new city (Chicago). As these geographic locations are very limited, it is difficult to assess their generalization capabilities to locations which are highly dissimilar to the training set.\nCommonly used weather datasets use real observations from satellites with global coverage combined with numerical weather prediction models, which means they offer much broader spatial coverage compared with transportation datasets. In particular, ClimaX is trained on CMIP6 [32] and tested on ERA5 [19], [43], while Pangu-Weather is trained and evaluated on different years of data within ERA5. The primary experiments in both works test performance across the entire globe all at once, though ClimaX does also perform regional forecasting for North America only. However, as training and inference is performed over the entire globe at once, it does not demonstrate generalization from one seen regions to unseen regions. They also lack analysis of the distribution of errors in the spatial dimension."}, {"title": "D. Temporal Generalization", "content": "Most of the traffic datasets from China are recorded within the same one month period in March-April 2022, at intervals at 5 minutes. The other datasets are slightly more varied in time period and total length over the past decade. UrbanGPT is evaluated in its long-term forecasting capabilities by training the model on 2017 data and testing it on 2021 data.\nWeather datasets generally contain much greater timespans, enabling training and evaluation over greater temporal ranges. Pangu-Weather is trained on 38 years of data from ERA5 (1979-2017), validated in 2019 and tested in 2018 and 2020-2021 data, while ClimaX is trained on CMIP6 which extends from 1850-2014, and tested on ERA5. Furthermore, it's climate projection task extends until 2100, although it is important to note that this is not a temporal modelling task as it does not use historical observations to predict future states."}, {"title": "E. Scale Generalization", "content": "Most of the traffic datasets are recorded over 5 to 30 minute intervals. UniST performs short-scale experiments with 6 time steps and long-scale experiments with 64 time steps in both input and target output size. UrbanGPT only considers one temporal scale of 12 time-steps.\nGeneralization across spatial scales is most relevant to the weather-related applications. Spatially, Pangu-Weather considers only one spatial resolution; 0.25\u00b0 \u00d7 0.25\u00b0, which corresponds to approximately 28km \u00d7 28km cells. Comparatively, Climax evaluates performance with 5.625\u00b0 x 5.625\u00b0 cells and 1.40625\u00b0 x 1.40625\u00b0 cells. It also evaluates the model's ability to perform climate down-scaling from 5.625\u00b0 to 1.40625\u00b0, as well as regional forecasting over North America only. However, these are all relatively large-scale and coarse-grained resolutions, which fails to capture the local patterns which are most useful for local-scale prediction.\nTemporally, Pangu-Weather trains four separate models with different lead times (1, 3, 6 and 24 hours), and aggregates these models for any-time forecasting. This is in order to reduce the impact of error propagation in forecasting, especially at longer lead times, however it is also fundamentally at odds with the intended purpose of a foundation model. On the other hand, ClimaX randomizes lead times between 6 hours and 168 hours (1 week) in pre-training, and various other lead times for evaluation. Furthermore, they consider various forecasting tasks, including sub-seasonal prediction and climate projection with much greater timeframes."}, {"title": "V. OPPORTUNITIES", "content": "Section III-A1 explored the complex relationships between ST sequences from different applications or sources. These relationships are severely under-utilized in existing ST models. For instance, based on our understanding of how infectious diseases spread through close contacts, we can infer that patterns of human mobility and traffic flow may significantly influence disease transmission. Therefore, a model that captures human mobility patterns could also provide valuable insights for modeling the spread of disease. By training STFMs to understand these patterns from data across multiple domains, we can enhance performance in specific applications by identifying and leveraging cross-domain correlations.\nAn important consideration is that, in many cases, relationships between applications are directional. For example, weather conditions likely impacts travel patterns, therefore accurate weather forecasting can aid in predicting traffic flow, but the reverse is not true. For this reason, a promising approach could be to design mechanisms to incorporate prior knowledge about spatio-temporal dynamics, such as physical laws and constraints, into the model. We can also look to recent advances in causal learning to uncover the nature of relationships between different features if their relationship is not already known. There is an established line of research dedicated to the discovery and inference of causal relationships in a spatio-temporal context [13], [28], [67] and this has continued in the era of spatio-temporal neural networks [12], [48], [52], [66]."}, {"title": "B. Unified Architectures", "content": "As discussed in Section II, ST data appears in a variety of different types and formats. An effective STFM should be able to handle all of these data types, however existing models are primarily or exclusively focused on only a single data type (namely, grid-based raster data). There have been some initial steps towards incorporating more flexible ST graph-based data very recently [62], [63], however this is mostly approached as a simple pre-processing step which may fail to account for the distinct properties of different data types. Furthermore, there is overwhelming focus on the transformer architecture, which suffers from quadratic complexity due in the self-attention mechanism. As the size of ST datasets and the number of variables and features to be modelled continues to grow, this complexity becomes a hindrance in the learning of ST patterns. Addressing these challenges requires innovative approaches, such as sparse attention mechanisms, efficient graph-based representations, and hybrid models that combine the strengths of transformers with other architectures like convolutional neural networks."}, {"title": "C. Diverse Objectives", "content": "Existing ST research is primarily focused on predicting the spatial distribution of variables or forecasting their future states based on historical observations. Though these objectives have singificant practical importance, there are numerous other tasks that foundation models are capable of performing. Anomaly detection, for example, can be naturally derived from the prediction task by measuring the discrepancy between predicted and ground-truth sequences. In such cases, the quality of the underlying representation learning plays a crucial role in success, and a model that excels at one task is often also effective for others due to its robust feature learning. However, instilling STFMs with an ability to perform other tasks, such as classification, clustering, or recommendation, would greatly broaden their utility across various applications without compromising their accuracy in others. One effective approach is to add a lightweight module on top of the base foundation model, enabling it to leverage pre-trained features while adapting to new tasks in a flexible and efficient manner."}, {"title": "D. Adaptation to Distribution Shift", "content": "Foundation models are trained with large-scale data, across diverse sources and domains, which exposes them to a wide range of scenarios. Nevertheless, during inference, they remain heavily reliant on the statistical properties of their training data. If the test data deviates from the training distribution (e.g., due to temporal changes like urban development or spatial differences like regional policies), the model's performance can drop sharply. Moreover, the particularly high complexity and dimensionality of spatio-temporal data increases the likelihood of encountering unseen patterns or out-of-distribution (OOD) scenarios in practice. This challenge is identified in Sections III-A2 and III-A3. Foundation modal adaptation offers a promising approach to address this challenge. There has been a great amount of research interest in the adaptation of foundation models for computer vision to boost their performance in specific tasks involving data outside their original training distribution. Recent research focuses on techniques like domain-adversarial training, which encourages the model to learn domain-invariant features, and meta-learning to rapidly adapt to new distributions with limited data from new distributions."}, {"title": "VI. CONCLUSION", "content": "Spatio-temporal foundation models offer an exciting development with great potential to improve performance in existing tasks, as well as unlock capabilities in new tasks related to spatio-temporal data. While STFMs have shown significant promise in capturing the intricate relationships between space and time, their ability to generalize to unseen spatial regions, time periods, and novel downstream tasks remains a critical challenge. We highlighted key issues such as spatial variability, temporal dynamics, data distribution shifts, and scale-dependent patterns that hinder effective generalization. As spatio-temporal models continue to evolve, future research should focus on developing methods to enhance their adapt-ability to unseen data distributions and dynamic environments. By integrating more robust mechanisms for handling cross-domain correlations and incorporating fine-grained adaptation techniques, we can unlock the full potential of STFMs for a wide range of real-world applications. Through continued innovation and refinement, spatio-temporal models have the potential to advance our understanding of complex systems and enable more accurate predictions, better decision-making, and improved outcomes across a variety of domains."}]}