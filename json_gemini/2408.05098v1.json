{"title": "Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks", "authors": ["Roel Koopman", "Amirreza Yousefzadeh", "Mahyar Shahsavari", "Guangzhi Tang", "Manolis Sifalakis"], "abstract": "Currently, neural-network processing in machine learning applications relies on layer synchronization, whereby neurons in a layer aggregate incoming currents from all neurons in the preceding layer, before evaluating their activation function. This is practiced even in artificial Spiking Neural Networks (SNNs), which are touted as consistent with neurobiology, in spite of processing in the brain being, in fact asynchronous. A truly asynchronous system however would allow all neurons to evaluate concurrently their threshold and emit spikes upon receiving any presynaptic current.\nOmitting layer synchronization is potentially beneficial, for latency and energy efficiency, but asynchronous execution of models previously trained with layer synchronization may entail a mismatch in network dynamics and performance.\nWe present a study that documents and quantifies this problem in three datasets on our simulation environment that implements network asynchrony, and we show that models trained with layer synchronization either perform sub-optimally in absence of the synchronization, or they will fail to benefit from any energy and latency reduction, when such a mechanism is in place.\nWe then \"make ends meet\" and address the problem with unlayered backprop, a novel backpropagation-based training method, for learning models suitable for asynchronous processing. We train with it models that use different neuron execution scheduling strategies, and we show that although their neurons are more reactive, these models consistently exhibit lower overall spike density (up to 50%), reach a correct decision faster (up to 2x) without integrating all spikes, and achieve superior accuracy (up to ~10% higher). Our findings suggest that asynchronous event-based (neuromorphic) AI computing is indeed more efficient, but we need to seriously rethink how we train our SNN models, to benefit from it.", "sections": [{"title": "1 Introduction", "content": "Artificial Neural Networks (ANNs) are the foundation behind many of the recently successful developments in AI, such as in computer vision [54, 58] and natural language processing [57, 5]. To match the complexity of the ever more demanding tasks, networks have grown in size, with advanced large language models having billions of parameters [65]. With this the power consumption exploded [28], limiting the deployment to large data centers. In an effort to learn from our brain's superior power efficiency, and motivated in neuroscience research, SNNs [30] bolster as an alternative. They use discrete binary or graded spikes (events) for communication, are suited for processing sparse features [18], and when combined with asynchronous event-based processing are assumed to enhance latency and energy efficiency (and scalability).\nConventional highly parallel ANN compute accelerators, such as Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs), which are primarily optimized for dense vectorized matrix operations, face inherent challenges in exploiting sparsity for improving their energy efficiency. Targeting the commonplace practiced way of executing ANNs layer-after-layer has left them with poor support for asynchronous processing too (for improving latency). At best, they parallelize processing within a layer and/or pipeline processing across layers. This leaves an exploration space for neuromorphic processors that try to excel in handling the event-driven nature of SNNs and leverage asynchronous concurrent processing, offering efficiency advantages in various tasks [19, 21, 36]."}, {"title": "2 Related work", "content": "The term \"asynchronous processing\u201d is often used whenever neurons can be active in parallel and communicate asynchronously, even if some synchronization protocol is enforced to control the order of spikes and synaptic current processing [44, 22, 51, 61]. Another kind of asynchrony is related to input coding[15]. In this context, synchronizing means grouping spikes (events) into frames, a topic that has extensively been researched [18, 33, 43, 45, 56]. Neither of the two, however, is the focus of this work.\nHere, asynchrony refers solely to activity within the network not being artificially bound by any order restriction. This has been researched for simulating biologically accurate neural networks [29, 32, 31], but remains under-explored in the context of executing SNNs for machine learning. In this context, grouping and processing in layers is just one convenient way [34].\nFew event-driven neuromorphic processors, such as \u00b5Brain [53] and Speck [6], are fully event-driven and lack any layer synchronization mechanism. This makes them notorious for training out-of-the-box with mainstream model training tools that rely on per-layer synchronization (e.g., PyTorch). Speck developers propose to train their models with hardware in-the-loop [27] to reduce the mismatch between the training algorithms and the inference hardware. However this method does not provide a general solution for training asynchronous neural networks. Others, like SpiNNaker [14] and TrueNorth [1], use timer-based synchronization, or Loihi [10] and Seneca [55] use barrier synchronization between layers, in order to warrant that the asynchronous processing dynamics on hardware are aligned at layer boundaries with models trained in software (with layer synchronization). This, however, entails an efficiency penalty, as we will show.\nFunctionally, the most suitable type of model for end-to-end asynchronous processing is probably rate-coded SNN models, whereby neurons can integrate state and communicate independently from any"}, {"title": "3 Methods for simulating and training of asynchronous SNNs", "content": "In this section, we provide an overview of our methodology. We first introduce our simulator for SNN processing with network asynchrony and then show how this is used for training."}, {"title": "3.1 Simulating asynchronous SNNs", "content": "The SNNs used in this work consist of L layers of Leaky Integrate and Fire (LIF) neurons [18], with each layer l for 1 < l < L having N(l) neurons and being fully-connected to the next layer l + 1, except for the output layer. Each input feature is connected to all neurons in the first layer. Every connection has a synaptic weight. Using these weights, we can compute the incoming current x per neuron resulting from spikes, as per equation 3.\nEach LIF neuron has a membrane potential exponentially decaying over time based on some membrane time constant Tm. We use the analytical solution (see equation 4) to compute the decay. By keeping track of the membrane potential u[t] and the elapsed time \u2206t since time t, it is possible to precisely calculate the membrane potential for t + \u2206t. Therefore, computations are required only when x[t + \u2206t] > 0.\nTo determine if a neuron spikes, a threshold function checks if the membrane potential exceeds a threshold Uthr, following equation 5. If \u0398(u) = 1, the membrane potential is immediately hard reset to 0. Soft reset is another option in the simulator often defended in the literature [16] as well as refractoriness [48]. However for simplicity here we only experiment with hard reset."}, {"title": "3.1.1 Event-driven state updates", "content": "We can vectorize the computations introduced in the previous section to perform them on a per-layer basis. This is the \"layered\" inference approach, which implies layer synchronization, since all neurons of one layer evaluate their state at the same instant. An alternative to this is an event-driven approach, where the computations for state updates are applied in response to new spike arrivals. Spikes can be emitted at any time by any neuron, affecting the states of postsynaptic neurons independently of others. Such an approach can achieve a true representation of network asynchrony.\nWhen using event-driven updates, the network dynamics evolve with each spike. A single spike can generate multiple currents, each linked to a specific time t, determined by the initiating input activity. Let Kt represent the atomic computational unit that is executed for an input current received at time t and that will update the state of a single neuron and evaluate its threshold function (activation). The exact computations for a LIF neuron can be found in section A.2. The order in which Kt is executed across neurons inside the entire network (and not just in one layer) affects the output of the network due"}, {"title": "Vectorized network asynchrony", "content": "The event-driven (neuron state) update rules for network asynchrony as introduced in the previous section can be vectorized by selecting multiple spikes for processing at the same time. This allows us to consider the entire spectrum of possibilities between full layer synchronization at one extreme, and \"complete\" asynchrony at the other extreme, where each spike event is processed entirely independently of all others. Additionally, vectorization makes acceleration possible by exploiting the parallelization features and vector pipelines of accelerators, where these models execute, leading to pragmatic simulation of network asynchrony.\nDuring the simulation, the states of all the $N = \\Sigma_{l=1}^{L} N(l)$ neurons in the network are stored in vectors. The vector $x \\in \\mathbb{R}^{N}$ tracks the computed input currents for the neurons, $u \\in \\mathbb{R}^{N}$ the membrane potential of the neurons, $s \\in \\mathbb{N}^{N}$ the emitted spikes queue, and $c \\in \\mathbb{N}^{N}$ which neurons have spiked in the current forward pass. For any of those vectors, the indices from $1 + \\Sigma_{j=0}^{k-1} N(j)$ to $\\Sigma_{j=0}^{k} N(j)$ represent the values for the neurons in layer l, for $1 \\lt l \\lt L$ where $N(0) = 0$.\nAlgorithm 1 outlines the processing during a forward pass (propagation of the spikes of an input frame through the network). Before starting, the input spikes from time $t_{0}$ to $t_{1}$ are grouped, resulting in an input vector $S_{in} \\in \\mathbb{N}^{N_{in}}$ where $N_{in}$ is the number of input features. Then, the input spikes are passed as one single batch, triggering a forward pass. Each forward pass consists of forward steps (the code within"}, {"title": "3.2 Training asynchronous SNNs", "content": "We use backpropagation to estimate the gradients of a loss function with respect to the weights. If multiple forward passes are needed, such as for sequential or temporal data, then Backpropagation Through Time (BPTT) can be used for training. Given that spike trains are temporal data as well, BPTT also applies to SNNs, and by extension, to the research presented here.\nTo address the issue of the non-differentiability of the threshold function, the surrogate gradient method is used [64]. An arctan function [13], (see section A.3 for details) provides a continuous and smooth approximation of the threshold function."}, {"title": "3.2.1 Unlayered backpropagation", "content": "Training of SNNs with per-layer synchronization is by now straightforward using backpropagation [9] so long as the forward processing is differentiable. We refer to this as \"layered backpropagation\".\nThe vectorized network asynchronous processing approach is differentiable as well, and can be used with backpropagation. We refer to this as \"unlayered backpropagation\". Combined with BPTT unrolling, this method implies a two level unrolling. In the outer level, unrolling is based on discretization of time in timesteps (when new inputs are provided); within the inner level, unrolling is based on the F-grouping of spikes, given a scheduling policy, and the activity of neurons up-until the output is read. For a single backward pass, which can be used in BPTT in a similar way as the layered backpropagation equivalent, it is given that:\n$$\n\\frac{\\partial L_t}{\\partial W} = \\sum_{i=1}^{N_t} \\frac{\\partial L_t}{\\partial C_t} \\frac{\\partial C_t}{\\partial s_i} \\frac{\\partial s_i}{\\partial W}\n$$\nwhere t is the time(step) of the forward pass, W can be a weight on any of the synapses, Lt is the loss, Ct is the spike count at the end of the forward pass, and si are the spikes in the queue at the end of the forward step i, with Nt forward steps in total within the forward pass (referring to concept of (micro)-time in 3.1.1). The number of steps scales linearly with the number of spikes processed in the forward pass. It is important to understand that due to asynchronous processing the number of spikes processed until the evaluation of the loss function may be (well) less than the total number of spikes emitted. Since for every forward step, the computations are repeated, the time complexity scales linearly with the number of forward steps: O(Nt). The same applies to the space complexity.\nDuring the backward pass, the spikes which are not selected can skip the computation f for that step:\n$$\n\\frac{\\partial s_i}{\\partial W} = \\frac{\\partial f(S_{i-1;selected}, U_{i-1}, x_t, W)}{\\partial W} + \\frac{\\partial s_{i-1; not\\ selected}}{\\partial W}\n$$\nSkip connections have been researched in deep ANNs and identified as a major contributor to the stability of the training process [38]. This may apply to the skip in unlayered backpropagation as well. To what extent this is the case is not explored in this work."}, {"title": "3.2.2 Regularization techniques", "content": "During training, we use regularization to prevent overfitting and/or enhance model generalization. These techniques are not used during inference.\nInput spike dropout. Randomly omits input spikes with a given probability. The decision to drop each spike is independent according to a Bernoulli distribution.\nWeight regularization. Adds weight decay to the loss function: $\\mathcal{L}_{w}(W)=\\mathcal{L}(W)+\\lambda_{w}||W||$ where $\\lambda_{w}$ is the regularization coefficient, $\\mathcal{L}$ is the loss given the weights, and W are all the weights.\nRefractory dropout. With some probability, do not apply the refractory effect, allowing a neuron to fire again within the same forward pass.\nMomentum noise. When using momentum scheduling, noise sampled from U(0,1) and multiplied by some constant $\\lambda_{MS}$ is added to the recorded membrane potential while selecting spikes."}, {"title": "4 Results", "content": ""}, {"title": "4.1 Experimental setup", "content": "We experimented with trained SNN models for asynchronous execution in three common benchmarking datasets: N-MNIST [37], SHD [8], and DVS gesture [2]. Each of them has different structure. N-MNIST has purely spatial structure, SHD purely temporal, and DVS gesture combines both spatial and temporal (i.e. input framing in DVS gesture is done such that an entire gesture motion and contour is not revealed within a single frame). More details on the datasets, can be found in section A.6.1. The network architecture and hyperparameters are given in table 5. State-of-the art performance for these tasks can be achieved with reasonably shallow and wide models. We chose however to train narrow, but deeper network"}, {"title": "4.2 Network asynchrony increases neuron reactivity", "content": "As observed in figure 2 (top row) during asynchronous inference, neurons are more reactive, i.e. a neuron can spike after integrating only a small number of incoming currents. With layer synchronization, this effect is averaged out as neurons are always required to consider all presynaptic currents (which are more likely to cancel each other out). For inference with F = 8, artifacts in the number of currents to spike can be observed, because each forward step propagates currents resulting from 8 spikes, causing neurons to integrate more currents than necessary for firing. Similar artifacts might also occur in neuromorphic chips equipped with fixed-width vector processing pipelines; making these observations insightful into the behavior of such hardware."}, {"title": "4.3 Unlayered backpropagation increases accuracy and sparsity", "content": "Network asynchrony negatively affects the performance of the models trained with layered backpropagation in all three datasets (table 2). This is likely in general the \"Achilles' heel\" of neuromorphic AI today. However, we observe that the accuracy loss is remediated when using unlayered backpropagation, which also significantly increases sparsity (by about 2x). In fact, the accuracy of models trained and executed asynchronously is consistently superior under both scheduling policies (with momentum scheduling having consistently an edge). This result alone suffices to attest that neuromorphic AI is competitive and more energy efficient.\nFigure 3 reveals another interesting result. It depicts how accuracy evolves as we allow more forward steps in the forward pass after the initial output during asynchronous inference. We see that because of the free flow of key information depth-first, models trained with unlayered backpropagation obtain the correct predictions as soon as the output layer gets stimulated. Activity that is likely triggered by \"noise\" in the input is integrated later on. Momentum scheduling is particularly good at exploiting this to boost accuracy."}, {"title": "4.4 Unlayered backpropagation decreases latency", "content": "The final and equally important result that we report is that under asynchronous network processing, models trained with unlayered backpropagation have significantly lower latency than those trained with layer synchronization. Assuming that, without parallel processing (worst case), latency is a function of the number of spikes processed until a decision is made, figure 4 shows a distribution of the inference latencies across the entire test-set. It should be clear by now that this is because \"the important spikes\" in these models quickly reach the output layer, uninhibited by layer synchronization."}, {"title": "4.5 Unlayered backpropagation is resource-intensive", "content": "The current implementation of unlayered backpropagation is costly when training with a smaller F and a larger dataset. When F is halved, the time and memory requirements approximately double, consistent with the linear time and space complexity discussed in section 3.2.1. The detailed results can be found in section A.8."}, {"title": "5 Discussion", "content": "We have introduced a variation of backpropagation training that does not assume per layer synchronization, and we use it to train models. Under asynchronous processing, these models exceed the performance of conventionally trained models and deliver the anticipated energy and latency efficiency from event-driven execution. Our findings show that unless we revise our training methods (taking into account asynchronous processing dynamics), and designs choices of neuromorphic accelerators (layer synchronization primitives considered harmful), SNNs and brain-inspired computing will likely fail to deliver either in performance or efficiency.\nThis study has merely scratched the surface. A key realization (that confirms neurobiology) is that trainable dynamics related to network asynchrony allow neurons (and models overall) to use partial input for decision making. The extent and generality of this effect on network architecture/structure, neuron models, and data types deserves further exploration. Our results also encourage a dynamics driven design space exploration for neuromorphic processors with regard to event processing scheduling and granularity of synchronization primitives (or lack thereof), which is almost absent today. The third exploration dimension is undoubtedly the resource efficiency and scalability of unlayered backpropagation (or analogous training framework) to facilitate very big models and datasets."}, {"title": "A Appendix / supplemental material", "content": ""}, {"title": "A.1 Spiking neural networks", "content": ""}, {"title": "Incoming current", "content": "For every neuron layer, all the synaptic weights on its inbound connections are kept in a weight matrix $W^{(l)} \\in \\mathbb{R}^{N(l) \\times N(l-1)}$, where N(0) = number of input features Nin. Using these weight matrices, the total incoming current x for a neuron i in the next layer can be computed using:\n$$ x_i^{(l+1)}[t] = \\sum_{j=1}^{N(l)} W_{ij}^{(l+1)} s_j^{(l)}[t] $$\nwhere $s_j^{(l)}[t]$ is 1 if neuron j in layer l has emitted a spike at time t, otherwise 0."}, {"title": "Membrane potential decay", "content": "The decay of the membrane potential is governed by a linear Ordinary Differential Equation (ODE). The analytical solution can be used to compute the decay:\n$$ u[t] = u[t - \\Delta t] e^{-\\frac{\\Delta t}{T_m}} + x[t] $$\nwhere Tm is the membrane time constant and \u2206t the elapsed time."}, {"title": "Threshold function", "content": "$$\\n\\Theta(u) = \\begin{cases}\n1 & \\text{if } u > U_{thr} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nwhere Uthr is the membrane potential threshold required for spiking."}, {"title": "A.2 Event-driven state update rule for LIF neuron", "content": "When an input current is received at time t by a neuron with a previous state u[to] at some time to \u2264 t, an atomic set of computations is executed. Start with computing the decayed membrane potential $u[t_-] = u[t_0] e^{-\\frac{t-t_0}{T_m}}$, then update the membrane potential u[t+] = u[t_] + x[t] with the input current x[t], and finally set u[t] = 0 and emit a spike if \u0398(u[t+]) = 1; otherwise u[t] = u[t+] without emitting a spike."}, {"title": "A.3 Arctan surrogate gradient", "content": "$$\\n\\Theta(u) = \\frac{1}{\\pi} arctan(\\frac{\\pi u}{2})\n$$\nwhere a is a hyperparameter modifying the steepness of the function."}, {"title": "A.4 Class prediction", "content": "Class prediction involves first calculating the output rates as follows:\n$$ c_i = \\sum_{t \\in T} s[i, t] $$\nwhere ci is the spike count for class i, T are all the timesteps for which a forward pass occurred, and s[i, t] is the output of the neuron representing class i in the output layer at the end of the forward pass at time t. These values are subsequently used as logits within a softmax function:\n$$ p_i = \\frac{e^{c_i}}{\\sum_{j=1}^{N_c} e^{c_j}} $$\nwhere Nc is the total number of classes. The resulting probabilities are then used to compute the cross-entropy loss:\n$$ \\mathcal{L} = - \\sum_{i=1}^{N_c} y_i \\log(p_i) $$\nwhere $y \\in \\{0, 1\\}^{N_c}$ is the target class in a one-hot encoded format."}, {"title": "A.5 Parameters for the simulator", "content": ""}, {"title": "A.6 Details on the experimental setup", "content": ""}, {"title": "Datasets and network architectures", "content": "The Neuromorphic MNIST (N-MNIST) dataset captures the MNIST digits using a Dynamic Vision Sensor (DVS) camera. It presents minimal temporal structure [20]. It consists of 60000 training samples and 10000 test samples. Each sample spans approximately 300 ms, divided into three 100 ms camera sweeps over the same digit. Only the initial 100 ms segment of each sample is used in this study.\nThe Spiking Heidelberg Digits (SHD) dataset [8] is composed of auditory recordings with significant temporal structure. It consists of 8156 training samples and 2264 test samples. Each sample includes recordings of 20 spoken digits transformed into spike sequences using a cochlear model, capturing the rich dynamics of auditory processing. The 700 cochlear model output channels are downsampled to 350 channels.\nThe DVS gesture dataset [2] focuses on different hand and arm gestures recorded by a DVS camera. Like the SHD dataset, it has significant temporal structure. It focuses on 11 different hand and arm gestures recorded by a DVS camera. It consists of 1176 training samples and 288 test samples. The 128 x 128 input frame is downsampled to a 32 \u00d7 32 frame.\nFor all three datasets, input events are assigned a timestamp and an index. In the case of N-MNIST, the index corresponds to a position within a 34 \u00d7 34 pixel frame, with each pixel having a binary polarity value (either 1 or 0), leading to a total of 34 \u00d7 34 \u00d7 2 = 2312 distinct input indices. For SHD, the index denotes one of the 350 output channels. For DVS gesture, the 128 \u00d7 128 input frame is downsampled to a 32 \u00d7 32 frame. Like N-MNIST, each pixel has a binary polarity value, so in total this gives 32 \u00d7 32 \u00d7 2 = 2048 input indices."}, {"title": "Performance metrics", "content": "To evaluate accuracy, output rates ci for each class i are first calculated as outlined in equation 7. The predicted class corresponds to the one with the highest output rate. Accuracy is then quantified as the ratio of correctly predicted outputs to the total number of samples."}, {"title": "A.7 Results on hyperparameters", "content": "Choosing a smaller F (i.e., with a more asynchronous system), may improve accuracy, particularly benefiting models with mechanisms that rely on network asynchrony such as momentum scheduling. However, reducing F also has its drawbacks. It significantly raises resource demands (discussed in section A.8), and there is a risk of reducing the effectiveness or even stalling the training process, as observed for SHD and DVS gesture.\nRefractory dropout, can positively affect training outcomes. An explanation for this is that it increases the gradient flow by allowing more spiking activity. However, using full refractory dropout can also reduce performance, likely due to the inability to generalize to inference with refractoriness.\nThe momentum noise helps by introducing a slight stochastic element into the spike selection process, helping to avoid potential local minima that a purely deterministic selection method is prone to get stuck in. This seems to do little for N-MNIST, but for more complex datasets like SHD and DVS gesture it has a significant effect."}, {"title": "A.8 Results on resource usage", "content": "The increase in processing time is less pronounced for the N-MNIST and DVS gesture datasets compared to the SHD dataset. This discrepancy could be due to computational optimizations that apply specifically to the N-MNIST and DVS gesture datasets (both being vision-based datasets)."}]}