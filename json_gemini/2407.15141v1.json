{"title": "TEXT-AUGMENTED MULTIMODAL LLMS FOR CHEMICAL\nREACTION CONDITION RECOMMENDATION", "authors": ["Yu Zhang", "Ruijie Yu", "Kaipeng Zeng", "Ding Li", "Feng Zhu", "Xiaokang Yang", "Yaohui Jin", "Yanyan Xu"], "abstract": "High-throughput reaction condition (RC) screening is fundamental to chemical synthesis. How-\never, current RC screening suffers from laborious and costly trial-and-error workflows. Traditional\ncomputer-aided synthesis planning (CASP) tools fail to find suitable RCs due to data sparsity and\ninadequate reaction representations. Nowadays, large language models (LLMs) are capable of tack-\nling chemistry-related problems, such as molecule design, and chemical logic Q&A tasks. However,\nLLMs have not yet achieved accurate predictions of chemical reaction conditions. Here, we present\nMM-RCR, a text-augmented multimodal LLM that learns a unified reaction representation from\nSMILES, reaction graphs, and textual corpus for chemical reaction recommendation (RCR). To train\nMM-RCR, we construct 1.2 million pair-wised Q&A instruction datasets. Our experimental results\ndemonstrate that MM-RCR achieves state-of-the-art performance on two open benchmark datasets\nand exhibits strong generalization capabilities on out-of-domain (OOD) and High-Throughput Ex-\nperimentation (HTE) datasets. MM-RCR has the potential to accelerate high-throughput condition\nscreening in chemical synthesis.", "sections": [{"title": "1 Introduction", "content": "Chemical synthesis is a crucial step for the discovery of transformative molecules in multiple fields, including drug\ndesign, materials, renewable energy, etc. In chemical synthesis, reaction conditions are usually optimized to maximize\nthe yield of each target molecule or minimize the cost of the corresponding process [1, 2]. Despite significant\nadvancements in chemical synthesis over the past few decades, discovering suitable reaction conditions from the\nextensive substrates combined with high-dimensional conditions renders exhaustive experimental impractical. [3].\nChemists have focused on building reliable and convenient computer-aided synthesis planning (CASP) tools to facilitate\nchemical synthesis [4, 5, 6]. However, few efforts have been made to solve the problem of reaction condition screening\ndue to the low sparsity of chemical data, and the lack of effective reaction representation [7, 8]. In summary, to realize\nefficient synthesis in chemistry, there is an urgent need to realize high-efficiency reaction condition recommendations.\nNowadays, the emergency of generative pre-trained transformer-based large language models (LLMs), typified by\nGPT-4, has sparked significant interest in the field of AI for chemistry [9, 10, 11, 12]. Prtrained with massive\nchemical reaction data including molecular simplified molecular-input line-entry system (SMILES) [13] and chemistry\nliterature in natural language, LLMs are endowed with fundamental chemical knowledge through text-to-text generation.\nHowever, for tasks that demand a precise understanding of molecular SMILES representations, such as retrosynthesis\nand chemical condition recommendation, LLMs have exhibited less competitive performance compared to traditional\nmethods [14, 15]. Further, these text-to-text models cannot fully exploit the advantages of molecular structure data\nand fall short in understanding reaction mechanisms [16]. To address these challenges, chemical reaction condition\nrecommendation necessitates LLMs to possess additional chemical comprehension representation beyond textual data\nto understand effectively and reason over chemical processes.\nMultimodal large language models (MM-LLMs) have been proven to achieve higher accuracy and perform more\neffectively in a wide range of applications [17, 18, 19]. Considering that, in addition to SMILES strings, there are\nvarious types of data in the field of chemistry, such as molecular graphs and external textual corpus of reaction [20]. By\nsynergizing the strengths of multiple modalities of chemical data, we enhance the capabilities of LLMs to understand\ncomplex chemical processes [21]. However, there is currently no widely adopted multimodal prediction model\nspecifically tailored for chemical reaction condition recommendation. Hence, it is imperative to develop an effective\nprediction model that can incorporate different chemical data into LLMs to achieve a more comprehensive understanding\nof reaction processes, facilitating the task of chemical reaction condition recommendation.\nIn view that molecules can be expressed as sequences, and reactions are described as natural language, e.g. text corpus,\nMM-LLMs can be a potential solution due to the following advantages: (i) pre-trained with extensive reaction data,\nfoundational LLMs can learn relationships between molecules in reactions, thereby acquiring chemical knowledge akin\nto the learning process of chemists [10]; (ii) via learning the joint representation of chemical reactions from different\nmodalities, including graphs, SMILES, and corpus, LLMs might be empowered the capability of understanding the\nmechanism of reactions, which facilitates the task of RCR. To this end, we fine-tune general-purpose LLMs with\ndomain-specific reaction data for RCR. Specifically, we present MM-RCR, a multimodal LLM that jointly learns from\nthe SMILES, graphs, and textual corpus of reactions. The contributions of this work can be summarized as follows:\n1.  We propose a multimodal LLM, a.k.a. MM-RCR, designed to learn a unified reaction representation from\nSMILES, graphs, and textual corpus of reactions for condition recommendation tasks. We further develop\ntwo distinct types of prediction modules, a classification module, and a generation module for MM-RCR to\nenhance its compatibility with different chemical reaction condition predictions.\n2.  We design text-augmented instruction prompts to construct a 1.2 million pair-wised Q&A dataset for training.\nWe propose the Perceiver module for modality alignment, which utilizes latent queries to align graphs and\nSMILES tokens with text-related tokens.\n3.  Through experimental validation on benchmark datasets, MM-RCR achieves competitive results comparable to\nstate-of-the-art models. Furthermore, MM-RCR exhibits strong generalization capabilities on out-of-domain\n(OOD) and high-throughput experimentation (HTE) datasets."}, {"title": "2 Related Work", "content": "In chemical synthesis, reaction conditions are usually developed and optimized to maximize the yield of each target\nmolecule or minimize the cost of the corresponding process [1, 2]. High-throughput reaction condition (RC) screening,\nas an important tool in synthesizing molecules, exerts an important influence on chemical synthesis. However,\ndiscovering suitable reaction conditions from the extensive matrix of substrates combined with the high-dimensional\nreaction conditions renders exhaustive experimental impractical. [3]. For decades, chemists have focused on building"}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Problem Setup", "content": "For a task of reaction condition recommendation, we define the X as the input for the chemical reaction R, T as the\nreaction corpus, G as the graph representations of reactions, and the output Y as a list of reaction conditions including\nthe catalyst, solvent, and reagent. Thus, we define prediction model F, i.e., $Y = F(X, G, T)$.\nIn this paper, we incorporate three types of data for the training of model F:\n1.  SMILES of a reaction X: each example in the training set is presented by chemical SMILES, i.e.,\n\u201cCC(C)O.O=C(n1ccnc1)nccnc1 >> CC(C)OC(=O)n1ccnc1\".\n2.  Graphs of reaction G: each SMILES representation of the reactants and the product is encoded using a graph\nneural network (GNN). All compounds are integrated to generate a comprehensive reaction representation.\n3.  An unlabeled reaction corpus: a paragraph describing a chemical reaction, e.g., \u201cTo a solution of CDI (2 g,\n12.33 mmol), in DCM (25 mL) was added isopropyl alcohol (0.95 mL, 12.33 mmol) at 0\u00b0 \u0421.\u201d."}, {"title": "3.2 Model Structure", "content": "Here we first describe the MM-RCR, a multimodal LLM designed for reaction condition recommendation (RCR). An\noverview of MM-RCR is provided in Figure. 2. MM-RCR responds to task-specific questions constructed by instruction\nprompts such as \u201cplease recommend a catalyst of this reaction: Reactant1.Reactant2>Product\u201d, and generates answers\nabout reaction conditions. MM-RCR takes three modalities of data as inputs, including text (a textural corpus of\nreaction and question prompts), molecular SMILES, and graphs of reactions. We employ both transformer-based\nreaction encoder and GCN models to jointly learn reaction representations from SMILES. Subsequently, the modality\nprojection transforms the graph and SMILES embeddings into language tokens compatible with LLM space. These\nlearnable tokens, defined as reaction tokens, along with tokens of question prompts, are then input into the LLM to\npredict chemical reaction conditions. Note that, we develop two distinct types of prediction modules, a classification\nand a generation prediction module to enhance its compatibility with different chemical reaction conditions."}, {"title": "3.2.1 Construction of Text-Augmented Instruction Prompts", "content": "Instruction prompt datasets refer to format structured or unstructured data as natural language instructions so that LLMs\ncan respond properly [36, 37]. Compared to creating language instruction datasets for fine-tuning LLMs, constructing\nmultimodal instruction datasets requires a thorough understanding of domain-specific tasks. Recent advancements\nindicate that the other data modalities, such as images, and graphs, can be transformed as the prefix of prompts thereby\nfacilitating effective reasoning based on inputs [38, 18, 19].\nToward reaction condition recommendation task in chemical synthesis, we design a tailored instruction prompts system\nfor better cross-modality alignment and instruction tuning (Figure. 3). Compared to instruction prompts for natural\nlanguage instruction tunning (Figure. 3(a)), we introduce augmented text tokens and multimodal tokens into instruction\nprompts (Figure. 3(b)). In particular, given a reaction, we collect corpus (<Corpus>), a paragraph that is similar to this\nreaction, and its SMILES (<Reaction SMILES>) to construct high-quality Q&A datasets. Question templates such\nas 'please predict the optimal conditions' are generated by GPT-4 autonomously using prompt engineering; reaction\nembeddings (<SMILES> and <Graph>) are inserted into instruction prompts. The expected answer for each question\nis the combination of chemical conditions, such as \u2018Cl.CICCl'. It is important to note that, to maintain the diversity of\ninstruction datasets, we randomly generate 2,000 question templates using GPT-4 for each pair-wised Q&A. In a word,\nwe encode all representations from different modalities into a unified language space, which facilitates the generation of\nresponses by LLMs."}, {"title": "3.2.2 Encoder and Decoder", "content": "Given a reaction R, we adapt a pioneering transformer-based encoder, Parrot [32] to produce the reaction embeddings\n$X_R \u2208 R^{N\u00d7C}$. Here, N and C indicate the length of text tokens and embedding channels, respectively. During training\nthe encoder computes a contextual vector representation of the reactions by performing self-attention on the masked\ncanonicalized SMILES string of molecules. We denote reaction embeddings as SMILES embedding in the following\nsection.\nIn the meantime, we leverage a GNN [20] to model the relationship between atoms in molecules. We denote directed\nand labeled multi-graphs as $G = (V,E,R)$ with nodes (atom entities), $v_i \u2208 V$ and labeled edges (atom relations)\n$(v_i, r, v_j) \u2208 E$, where $r \u2208 R$ is a relation type. GNN can be understood as special cases of a simple differentiable"}, {"title": "3.2.3 Modality Projection", "content": "For the reaction condition recommendation task, the representation of the reaction is extracted by encoders (see in\nsection 3.2.2), and the text representation is tokenized by LLMs. However, fusing two types of representation introduces\ninductive biases issues [39, 40]. To effectively fuse representations from multiple modalities, we propose projection\nmodules, the Perceiver [40], for modality alignment (Figure 2). This module employs latent tokens to align graphs and\nSMILES embeddings with text-related tokens extracted from question prompts and a text-augmented corpus. During\ntraining, we employ two Transformer-based Perceivers as projectors. Although these modules share an identical model"}, {"title": "4 Experiments and Results", "content": ""}, {"title": "4.1 Data", "content": "We curate two large datasets, named USPTO-Condition and USPTO_500MT_Condition for evaluation. Data vol-\numes are presented in Table. 7. The visualization of data distribution is depicted in Figure. 5. As depicted in\nTable. 1, for the USPTO-Condition dataset, five conditions categories are separated by commas in order. For the\nUSPTO_500MT_Condition dataset, all conditions are combined by dot as strings. The detailed data description can be\nseen in Appendix. B."}, {"title": "4.2 Experiment Setup", "content": "In our work, the reaction encoder is implemented based on Wang et al. [32]. A pre-trained graph model proposed\nby [20] encodes the molecules in the reaction. We utilize LLaMA-2 [41] as a text decoder. Each reaction has the\ncorresponding corpus, a paragraph describing a chemical reaction with an average length of 190 tokens. During the\ntraining process, we fix the weight parameters of GCN, reaction encoder, and LLaMA-2. The modality projection and\ncondition prediction layer is trainable. The detailed training setting can be seen in Appendix. A."}, {"title": "4.3 Performance Comparison", "content": "We assess the performance of our proposed MM-RCR for reaction condition recommendation. The top-N accuracy\nof condition recommendation on the combined test datasets of USPTO-Condition and USPTO_500MT_Condition\nare presented in Table. 2 and Table. 3, respectively. Compared methods include RCR [30], Reaction GCNN [31],\nTextReact [33], and Reagent Transformer [28], and the details of the baselines are present in Appendix. D."}, {"title": "4.4 Ablation Study", "content": ""}, {"title": "4.4.1 Model Structure", "content": "In MM-RCR, SMILES strings provide a textual representation of molecular structures, concisely encoding vital\nconnectivity and stereochemistry details. Structural graphs of molecules offer a topological view of molecules in\ntwo-dimensional space, where atoms are nodes and bonds are edges. The textual corpus introduces a natural language\ncontext into the model to enhance the chemical interpretation capability of LLMs."}, {"title": "4.4.2 Modality Projection", "content": "By leveraging the strengths of multiple modalities, multimodal LLMs can achieve higher accuracy in a wide range\nof applications. However, aligning representations among different modalities remains a challenging task. In our\nproposed MM-RCR, we employ the Perceiver module [40] to integrate molecular SMILES tokens and graphs tokens"}, {"title": "4.5 Geralization Performance", "content": "In order to validate the out-of-domain performance of MM-RCR, we employ MM-RCR trained on the\nUSPTO_500MT_Condition to test on the USPTO-Condition. The evaluation strategy includes three specific\ntraining conditions: reagents, catalysts, and solvents. We adopt a metric of partial matched accuracy to il-\nlustrate the generalization capability of MM-RCR. The idea is that if the predicted results match the substi-\ntutable part of the ground truth. The evaluation strategy includes three specific training conditions: reagents,\ncatalysts, and solvents."}, {"title": "4.6 Zero-Shot Prediction on High-Throughput Experimentation Reaction", "content": "Discovering effective reaction conditions precisely for high-throughput reaction condition screening is very important,\nas it has the potential to release chemists from laborious and costly trial-and-error workflows. Thus, we evaluate\nour proposed MM-RCR on the high-throughput reaction datasets, aiming to recommend conditions that yield high-\nproduct outputs. Recently, Pd-catalysed C-H direct functionalization has earned increasing interest in pharmaceutical\ndevelopment for its ability to generate molecule complexity without the need for pre-functionalized starting material [43].\nThus, We select imidazole C\u2013H arylation reaction for evaluation. Imidazole C\u2013H arylation dataset is extracted from\nthe work proposed by Shields et al. in 2021 [1], where the substrate scope contains 8 imidazoles and 8 aryl bromides\nassociated with conditions including ligands, bases, and solvents.\nCatalysts are vital compounds in chemical reactions, as they play a crucial role in determining both reactivity and\nyield. The catalyst used in imidazole C-H arylation comprises a metal (Pd) and ligands. Thus, we evaluate the"}, {"title": "5 Conclusion and Limitations", "content": "Conclusions In this paper, we present a multimodal LLM, a.k.a. MM-RCR for chemical reaction condition recom-\nmendation. Trained with 1.2 million pair-wised Q&A instruction datasets that integrate with multimodal reaction\nrepresentations and corpus in natural language, MM-RCR effectively answers questions regarding reaction conditions\nthrough either a classification head or sequence generation. MM-RCR achieves competitive results with state-of-the-art\nmodels via experimental validation. Additionally, MM-RCR exhibits strong generalization abilities on OOD and HTE\ndatasets.\nLimitations Further, we will focus on optimizing data representation with full fine-tuning training strategies to improve\nits performance across various chemical reaction tasks in future work."}, {"title": "Appendix", "content": ""}, {"title": "A Training settings", "content": "To realize peak efficiency within our MM-RCR model, we carefully design the training phases. This section offers a\ncomprehensive summary of the training settings and the hyperparameter values. Through the detailed orchestration of\nthese parameters, we ensure that MM-RCR is capable of fully leveraging its capabilities in the application contexts.\n\u2022 Optional Settings: There are alternatives for modification in the MM-RCR framework, such as the replacement\nof the Perceiver-based modality projection layer with other architectures like Reprogramming and MLP.\n\u2022 Reaction Condition Recommendation task: Within the framework, the model takes the 32-layer LLaMA-\n2-7b as the LLM backbone. Besides, we utilize a pre-trained SMILES-to-text retriever proposed by Qian et\nal. [33] and extract the most similar unpaired corpus as the reaction text. Meanwhile, we introduce Parrot, a\nBert-like model to encode the reaction SMILES. We leverage R-GCN [20] to encode the molecules in the\nreaction, and the combination of reactant and product embeddings is considered as the reaction representation.\nIn the training process, the encoders in all modalities are frozen. After the alignment of the representation\nspace, the SMILES- and the graph-based tokens have a length of 128 and 3, respectively. Additionally, the\nmodel employs the OneCycleLR as the learning rate schedular, initializing the learning rate as 3e-5. The batch\nsize is set to 16, with less than 6 epochs 48 hours in training. The GPU configuration is 8 \u00d7 80G A800."}, {"title": "B Data Description", "content": "We curate two large datasets, named as USPTO-Condition and USPTO_500MT_Condition, with the data volumes\npresented in Table. 7. Both datasets are split with the ratio of train:validation:test=8:1:1 in our work. For USPTO-\nCondition dataset, all molecules including reactants, products, and conditions are collected in canonical SMILES. Each\nreaction entry contains five condition labels, including one catalyst, two solvents, two reagents, and an additional\n\"none\" category is introduced to illustrate that the reaction does not require this type of reaction condition [30]. The\nvisualization of data distribution is depicted in Figure. 5 (left). From Figure. 5 we can see that this dataset covers a vast\nvariety of reaction types, characterized by a substantial proportion of heteroatom alkylation, arylation, and acylation\nreactions, while C-C formation reactions are less included. We also introduce the corpus of reaction descriptions\nproposed by Qian et al. [33] into the USPTO-Condition dataset. Each reaction is associated with a corpus of reaction\ndescriptions. It should be noted that the corpus will not be utilized directly for training. Instead, we employ the\ncorpus as an input for the pre-trained retrieval module proposed by [33]. This approach allows us to obtain similar\nembeddings necessary for the multimodal representation learning of our MM-RCR, and avoid data leaking issues.\nFor USPTO_500MT_Condition datasets, it collects Top-500 types of reactions from the USPTO-MIT datasets [22],"}, {"title": "CDetails of Modality Alignment", "content": "For the reaction condition recommendation task, the representation of the reaction is extracted by encoders (see in\nsection 3.2.2), and the text representation is tokenized by LLMs. However, fusing two types of representation introduces\ninductive biases issues [39, 40]. To effectively fuse representations from multiple modalities, we propose the use of a\nprojection module, the Perceiver [40], for modality alignment (Figure 2). This module employs latent queries to align\ngraph and SMILES tokens with text-related tokens, such as question prompts and a text-augmented corpus. We show\nthe pseudo-code for modality projection in Algorithm. 1."}, {"title": "D Model performance", "content": "A chemical reaction can be represented as the transformation of a sequence of characters (reactants, conditions) into\nanother sequence (products), with compounds connected by special characters, such as '\u00bb'. This structure makes\nsequence-to-sequence models, such as the Transformer, well-suited for predictive modeling of reaction representation\n[26, 44]. However, existing SMILES-based Transformer models for reaction representation encounter limitations\nin various aspects, particularly with respect to atom permutations and the interpretability of reaction mechanisms.\nConsequently, our proposed MM-RCR fuses data from diverse sources including corpus, SMILES and graphs of\nmolecules to present a comprehensive view of the reaction. We assess the performance of our proposed MM-RCR\nand the aforementioned baseline methods for reaction condition recommendation. The top-N accuracy of condition\nrecommendation on the combined test datasets of USPTO-Condition and USPTO_500MT_Condition are presented\nin Table. 2 and Table. 3, respectively. We introduce several comparative methods to illustrate the performance of\nMM-RCR.\n1.  RCR [30]. This method proposes a reaction fingerprint to represent the difference between the product and\nreactant fingerprints.\n2.  Reaction GCNN [31]. This method proposes a machine-learned ranking model to predict the set of conditions\nused in a reaction as a binary vector."}, {"title": "D.1 Ablation study on modality", "content": "Besides, we visualize the results of ablation study on modality on the USPTO-Condition dataset, which can be seen in\nTable. 4. Specifically, we categorize the conditions of the USPTO-Condition into two types: more complex and less\ncomplex. According to the data sparsity, reagent 1 and solvent 1 are considered more complex, while catalyst, reagent\n2, and solvent 2 are considered less complex. Then, the investigation on the effectiveness of modalities comprising\nsimilar corpus, SMILES, graph is depicted in Figure. 8. From the results, we can see that compared with the model\nwith multiple modalities, the model with single one modality degrades dramatically. Moreover, MM-RCR with three\nmodalities combined achieves the best performance, which demonstrates the vital importance of capturing the reaction\nrepresentations from different dimensions."}, {"title": "D.2 Case Study", "content": "In this section, we select four cross-coupling reactions from USPO-Condition datasets for performance validation. We\nvisualize the predicted results in Figure. 10. As depicted in Figure 10, the reaction centers and leaving groups are"}]}