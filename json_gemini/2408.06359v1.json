{"title": "An Adaptive CSI Feedback Model Based on BiLSTM for Massive MIMO-OFDM Systems", "authors": ["Hongrui Shen", "Long Zhao", "Kan Zheng", "Yuhua Cao", "Pingzhi Fan"], "abstract": "Deep learning (DL)-based channel state information (CSI) feedback has the potential to improve the recovery accuracy and reduce the feedback overhead in massive multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. However, the length of input CSI and the number of feedback bits should be adjustable in different scenarios, which can not be efficiently achieved by the existing CSI feedback models. Therefore, an adaptive bidirectional long short-term memory network (ABLNet) for CSI feedback is first designed to process various input CSI lengths, where the number of feedback bits is in proportion to the CSI length. Then, to realize a more flexible feedback bit number, a feedback bit control unit (FBCU) module is proposed to control the output length of feedback bits. Based on which, a target feedback performance can be adaptively achieved by a designed bit number adjusting (BNA) algorithm. Furthermore, a novel separate training approach is devised to solve the model protection problem that the UE and gNB are from different manufacturers. Experiments demonstrate that the proposed ABLNet with FBCU can fit for different input CSI lengths and feedback bit numbers; the CSI feedback performance can be stabilized by the BNA algorithm; and the proposed separate training approach can maintain the feedback performance and reduce the complexity of feedback model.", "sections": [{"title": "I. INTRODUCTION", "content": "Massive multiple-input multiple-output (MIMO) technology has become the key technology of 5G mobile communication due to its high spectrum efficiency [1], [2]. To generate beamforming for downlink signal transmission, it is necessary to obtain timely and accurate downlink channel state information (CSI) at the next generation nodeB (gNB). In time division duplex (TDD) mode, the downlink CSI can be directly estimated from uplink pilot by using channel reciprocity [3]. While in frequency division duplex (FDD) mode, different frequency bands are employed for uplink and downlink, making it challenging to estimate the downlink CSI from uplink pilot. Consequently, the CSI feedback scheme for massive MIMO in FDD systems has become one of hot topics in recent years.\n\nThe traditional CSI feedback methods, such as compressive sensing (CS) algorithms [4], [5], utilize the channel sparsity and orthogonal basis matrix to compress CSI and then feedback the low-dimension CSI to the gNB for reconstruction. However, the actual channel is not completely sparse on any orthogonal basis. Moreover, both the number of algorithm iterations and the feedback overhead increase dramatically with the increasing number of antennas in massive MIMO systems. Therefore, feasible CSI feedback methods for massive MIMO systems need to be further studied.\n\nRecently, artificial intelligence (AI) has been developed rapidly, including deep learning (DL) [6]\u2013[8] and reinforcement learning (RL) technology [9]-[11]. In particular, wireless communication systems based on DL frameworks have attracted a lot of attention, which can efficiently achieve channel estimation [12], [13], feedback [14]-[22], channel encoding[23], and signal detection [24]. Specifically, the DL-based CSI feedback, including full channel CSI feedback and eigenvector-based CSI feedback, has been widely studied since it can provide higher recovery accuracy and lower feedback overhead simultaneously.\n\nFor the full channel CSI feedback, a kind of CSI feedback architecture based on the autoencoder structure [25], termed as CsiNet, was first introduced in [14]. Based on which, a series of feedback models were proposed to improve the feedback accuracy by optimizing the model structure or quantizing method of the compressed vector with continuous values [15]\u2013[19]. On the other hand, for the eigenvector-based CSI feedback discussed by 3rd generation partnership project (3GPP) [26], fully connected layers and convolutional neural network (CNN) are adopted to design EVCsiNet [20]. Moreover, the encoder of Transformer was used for both the encoder and decoder of CSI feedback model to compress and recover the eigenvectors [21]. And in [22], authors proposed a lighter model, named MixerNet, based on MLP-Mixer structure [27].\n\nThese studies in [14]-[22] primarily focus on the design of DL-based models or quantization methods to improve the CSI feedback performance, they needs to train and store a large number of feedback models to handle different input CSI lengths and feedback bit numbers. Therefore, for the full channel CSI feedback, the model with adaptive inputs or compression ratios (CRs) are studied. On the one hand, a DL-based feedback schemes only relying on fully convolutional are proposed for CSI with different numbers of subcarriers and antennas, however realizing multiple CRs needs a list of model parameters [28]\u2013[30]. On the other hand, a framework consisting of an encoder with multiple fully connected layers and multiple decoders is proposed to realize various CRs by leveraging optional output layer and corresponding decoder in [31], furthermore its variant simplifies multiple decoders into a multi-branches decoder [32]. However, both of them need more fully connected layers of encoder and decoders (or branches) to accommodate various CRs; meanwhile, the adaptive input model in [28]-[30] could not compatible with the multi-CRs model in [31], [32]. Additionally, the padding operation is taken to change the lengths of compressed vectors [33]; a classification model is designed to select the suitable CR for the CSI data with same size in the training stage, but can not be flexibly adjusted in the inference stage [34]; a quantization method with adjusted quantization bit number of each neuron output value is proposed for variable CRs without considering the quantization loss in the test stage [35]. In conclusion, the proposed adaptive schemes may not be sufficient for alterable input CSI lengths and feedback bit numbers simultaneously with one set of model parameters.\n\nBesides, most researchers do not consider the model protection problem [36], [37], where the user equipment (UE) and gNB can not share the trained encoder and decoder model, including the model structure and parameters, when they belong to different manufactures in actual communication. Consequently, they need to unify their interface and train a pair of matched encoder and decoder separately. As a result, we are inspired to further investigate the CSI feedback model based on DL for these practical factors.\n\nTherefore, this paper proposes an adaptive eigenvector-base CSI feedback model and designs a plug-in control unit for adapting to various input CSI lengths and feedback bit numbers simultaneously. Then, an adaptive bit number adjusting (BNA) algorithm is developed for satisfying the target feedback performance. Moreover, a novel separate training approach is designed for CSI feedback when the UE and gNB are from different manufacturers. In summary, the main contributions of this paper are given as follows.\n\n\u2022 To deal with different lengths of input CSI, an input-adaptive CSI feedback model based on autoencoder structure is designed by leveraging bidirectional long short-term memory (BiLSTM), referred to as ABLNet. By fully exploiting the property of LSTM for processing different lengths of input sequences, the proposed ABLNet is capable of compressing and recovering input CSI with different lengths and the number of feedback bits is in proportion to the corresponding length of input CSI.\n\n\u2022 Then, a feedback bit control unit (FBCU) is proposed to further realize the adjustable number of feedback bits through discarding the ending part of codeword output by the encoder. Based on the adjustable characteristic of the proposed ABLNet with FBCU, a bit number adjusting (BNA) algorithm is designed to achieve a unified, instead of an average, target feedback performance for every input CSI with lower feedback bit number on average than before the adjustment.\n\n\u2022 In order to achieve the model protection between different manufacturers of encoder and decoder, the UE-first separate training method is adopted to decouple the training of the encoder and decoder. Moreover, a general decoder is utilized at the gNB to reconstruct CSI from different UEs rather than storing multiple decoders corresponding to multiple UE encoders. In this way, the UEs can adapt to different input CSI lengths and feedback bit numbers by utilizing the ABLNet with FBCU; and the general decoder can reduce the feedback model complexity."}, {"title": "II. SYSTEM MODEL", "content": "This section firstly introduces massive MIMO-OFDM system model and then discusses the DL-based CSI feedback model in detail.\n\n**A. Massive MIMO-OFDM System Model**\n\nIn a massive MIMO-OFDM system, $N_T$ transmit antennas are deployed at the gNB and $N_R$ receive antennas are deployed at each UE. As illustrated in Fig. 1, by leveraging channel estimation at the UE [38], the downlink channels in frequency domain can be obtained based on the pilot sequences transmitted by the gNB. Then, the downlink channels are divided into $K$ subbands, where each subband consists of $N_{sc}$ subcarriers and the subcarriers in the same subband employ the same beamformer at the gNB in order to reduce the system complexity. The common beamformer in each subband can be obtained by the following method in order to maintain the performance of each subcarrier.\n\nAssume that the downlink channel of the $n$th subcarrier in the $k$th subband is denoted as $H_{kn} \\in C^{N_R \\times N_T}$ ($1 \\le k \\le K, 1 \\le n \\le N_{sc}$). Then, the correlation matrix of the channel of each subcarrier in the $k$th subband can be calculated as $H_{kn}H_{kn}^H$, and the average correlation matrix of the $k$th subband can be written as\n\n$R_k = \\frac{1}{N_{sc}} \\sum_{n=1}^{N_{sc}} H_{kn}H_{kn}^H$  (1)\n\nBased on eigenvalue decomposition (EVD), the feedback eigenvector of the $k$th subband can be calculated by\n\n$R_k w_k = \\lambda_k w_k$, (2)\n\nwhere $\\lambda_k$ and $w_k = [w_{k1}, w_{k2},\u2026, w_{kN_T}]^T\\in C^{N_T\\times 1}$ represent the maximum eigenvalue and corresponding eigenvector of matrix $R_k$ in the $k$th subband. From (2), $w_k$ is a complex vector; to fit for the processing of universal neural network, the corresponding real-valued eigenvector is given by\n\n$\\widetilde{w_k} = [Re \\{w_{k1}\\}, Im \\{w_{k1}\\},\u2026,Re\\{w_{kN_T}\\},Im\\{w_{kN_T}\\}]^T$, (3)"}, {"title": "B. DL-Based CSI Feedback Model", "content": "Since the CSI feedback scheme is comparable to the overall workflow of the autoencoder, the autoencoder architecture can be employed to design the DL-based CSI feedback framework. As shown in Fig. 1, an adaptive CSI feedback model is proposed to adapt to the input CSI eigenvector with different lengths and various numbers of feedback bits.\n\nAmong the feedback model, the UE first obtains the CSI eigenvector $w$ and compresses it to codeword vector $c$ by the encoder, which is denoted as\n\n$c = f_{\\theta_E}(w, K)$, (5)\n\nwhere $f_{\\theta_E}()$ is the encoder function with parameter set $\\theta_E$. And the length $m$ of codeword vector $c$ changes proportionally with $K$.\n\nThen, a FBCU module is applied to make the codeword vector $c$ changeable based on the capacity requirements of feedback channel. If the number $q$ of quantization bit is fixed, the length of feedback bits obtained after quantization is also changeable according to the length $n$ ($ \\le m$) of $c$. Therefore, if the FBCU module is applied, (5) becomes\n\n$c = f_{\\theta_E}(w, K, \\eta)$. (6)\n\nAfter passing through the quantization and dequantization module, the obtained feedback bit stream $s$ and recovered codeword vector $\\hat{c}$ can be respectively expressed as\n\n$s = f_{quan} (c), \\hat{c} = f_{dequan} (s)$, (7)\n\nwhere $f_{quan} (\\cdot)$ and $f_{dequan} (\\cdot)$ are the quantization and de-quantization functions, respectively.\n\nFinally, the gNB reconstructs the CSI eigenvector $\\hat{w}$ with the decoder module, which is denoted as\n\n$\\hat{w} = f_{\\theta_D}(\\hat{c}, K)$, (8)\n\nwhere $f_{\\theta_D} (\\cdot)$ is the decoder function with parameter set $\\theta_D$. Usually, the square of generalized cosine similarity (SGCS) is taken to evaluate the recovery performance of eigenvector-based CSI feedback. The average SGCS $\\rho$ between the original joint eigenvector $w$ and the recovered joint eigenvector $\\hat{w}$ with $K$ subbands can be written as\n\n$\\rho = \\frac{1}{K} \\sum_{k=1}^{K} (\\frac{|w_k^H \\hat{w_k}|}{||w_k|| \\cdot ||\\hat{w_k}||})^2$, (9)\n\nThen, one objective of the paper is to optimize the model weight parameter set $\\Theta_1 = \\{\\theta_E, \\theta_D\\}$ to make the feedback performance $\\rho$ as high as possible, as most existing studies [14]-[22] have done. On the other hand, for the proposed separate training with multiple UEs and a single gNB, the objective is to optimize the weight parameter set $\\Theta_2 = \\{\\theta_{E1}, \\theta_{E2},\u2026\u2026,\\theta_{EN},\\theta_D\\}$ to make the feedback performance $\\rho$ of all $N$ UEs as high as possible, i.e.,\n\n$\\Theta_2 = arg \\underset{\\Theta_2}{max} \\frac{1}{N} \\sum_{n=1}^{N} \\rho_n (\\theta_{En}, \\theta_D)$, (10)\n\nwhere $\\theta_{En}$ and $\\rho_n$ ($1 \\le n \\le N$) represent the encoder parameters set and the SGCS of the $n$th UE, respectively."}, {"title": "III. ADAPTIVE CSI FEEDBACK MODEL", "content": "The adaptive CSI feedback model based on BiLSTM structure, named ABLNet, is first introduced in this section. The role of ABLNet includes adapting to different input lengths of CSI eigenvectors and ensuring the recovery accuracy. Then, the FBCU module is designed to make the feedback bit number of ABLNet model more adjustable. Based on which, the BNA algorithm is introduced to achieve the target SGCS for every input CSI by adjusting the number of feedback bits."}, {"title": "A. Architecture of ABLNet", "content": "By fully considering the characteristics of input CSI eigenvector and the aim of dealing with different subband numbers, the designed framework of ABLNet is illustrated in Fig. 2, which contains encoder and decoder and both are described as follows.\n\nEncoder. The input CSI eigenvector sequentially passes through four types of blocks and the specific design of each block is described as follows.\n\n1) Feature extraction block: The block consists of two BiLSTM layers, which is responsible for extracting the feature of input CSI eigenvector. Each subband eigenvector  is input to a LSTM cell and is extracted feature vector by using features of preceding and following subband eigenvectors. Then, the $K$ output feature vectors $y_1, y_2,\u2026, y_K$  are merged to be transmitted to the next BiLSTM layer. After passing through this block, the output feature vector can be expressed as $x_1$ = BiLSTM (BiLSTM ($w$)).\n\n2) Residual block: The residual block has a fully connected layer, i.e., Dense1, and transforms the output of feature extraction block into Dense1 ($x_1$) for further processing. Moreover, the residual structure [39] is introduced to accelerate model convergence and improve the model performance. The original input eigenvector $w$ is maintained via the shortcut branch and so the final output feature vector of the residual block can be written as $x_2$ = Dense1 ($x_1$) + $w$.\n\n3) Compression block: Data compression is achieved in this block. Firstly, layer normalization (LN) operation is carried out to unify the variation range of the extracted feature vector $x_2$ and help network training. Then, a fully connected layer, Dense2, is employed to compress the output LN ($x_2$) and therefore the output of whole compression block can be expressed as $x_3$ = Dense2 (LN ($x_2$)).\n\n4) Non-linearity block: In order to utilize the non-linearity to improve the expressiveness of the model, the Sigmoid function is first adopted in the block. And then, the flatten operation is employed to transform its output Sigmoid ($x_3$) into the codeword vector $c$, which can be expressed as Flatten (Sigmoid ($x_3$)).\n\nFinally, the obtained codeword vector $c$ is sent to the quantization layer and is quantized into the feedback bit stream $s$. In this paper, the uniform quantization method is adopted to quantize the compressed codeword. Moreover, some other quantization methods introduced in [22] and [40], such as non-uniform quantization and vector quantization, can also be used to improve the CSI feedback performance.\n\nDecoder. At the gNB, the dequantization layer is firstly used to transform the received bit stream $s$ into the float codeword vector $\\hat{c}$, which is the inverse operation of the quantization"}, {"title": "B. ABLNet for Adjustable Subband Number", "content": "1) Deal with different subband numbers: Generally, DL-based models have the fixed-length input interface. As a result, in order to satisfy the fixed input length of the proposed ABLNet, the input CSI eigenvectors with different number of subbands need to be unified to the maximum number of subbands through the approach of padding 0. Meanwhile, the BiLSTM layer only processes the non-zero input part during the feature extraction and the zero-padding part is automatically ignored. Therefore, on the one hand, every subband eigenvector of each kind of subband number can be further compressed and quantified through the ABLNet after padding operation; on the other hand, the length $Q$ of feedback bit streams is in proportion to the number $K$ of CSI eigenvector subbands.\n\nIn this way, when the ABLNet model receives CSI eigenvectors with different subband numbers in different scenarios, the feedback overhead can also change with the subband number. As shown in Fig. 4, CSI eigenvectors with subband number $K_1$, $K_2$,\u2026\u2026, $K_M$ are input to the model, and after compression and quantization, the lengths $Q_1$, $Q_2$, \u2026, $Q_M$ of feedback bits $s_1$, $s_2$,\u2026, $s_M$ are proportional with the corresponding subband number of CSI eigenvectors, i.e.,\n\n$\\frac{Q_1}{K_1} = \\frac{Q_2}{K_2} = \u2026 = \\frac{Q_M}{K_M}$  (11)\n\n2) Loss function: As mentioned in Section II, SGCS is used as the loss function of the proposed ABLNet model, which can be formulated as\n\n$L_1 = \\frac{1}{M} \\sum_{i=1}^{M} \\sum_{k=1}^{K_i} (\\frac{|w_{ik}^H \\hat{w_{ik}}|}{||w_{ik}|| \\cdot ||\\hat{w_{ik}}||})^2$, (12)\n\nwhere $K_i \\in \\{K_1,K_2,\u2026\u2026, K_M\\}$ is the number of CSI eigenvector subbands and $\\mu_i$ is the weight coefficient of SGCS of CSI eigenvector with subband number $K_i$. In this paper, when CSI eigenvectors with multiple subband numbers are trained at the same time, equal weight coefficient $\\mu_i = 1/M$ is assumed for simplification. However, when the ABLNet is trained for a fixed subband number $K_j$, the loss function can be set as $\\mu_i = 1 (i = j)$ and $\\mu_i = 0 (i \\ne j)$."}, {"title": "C. FBCU for Adjustable Feedback Bit Number", "content": "Since the encoder output length $m$ of the codeword vector $c$ and the number $q$ of quantization bit for each float number in the output codeword vector $c$ are predetermined, the CSI feedback bit stream $s$ obtained by the UE has a constant length $Q$, which can be calculated as\n\n$Q (m) = m \\times q$.  (13)\n\nWhile in the actual communication systems, different scenarios or applications may require changeable feedback overhead, even for the same length of input eigenvector. And every subband CSI eigenvector can report different length of feedback information. Therefore, as shown in Fig. 5, a CSI feedback scheme with FBCU that adapts to different numbers of feedback bits is proposed to improve the generalization and practicability of the CSI feedback model.\n\n1) FBCU principle: The FBCU is applied for CSI feedback model to change the length of the compressed vector output by the encoder and further change the number of feedback bits. Assuming the output codeword vector of the encoder is $c = [c_1, c_2,..., c_m]$ the FBCU can maintain the codeword vector with length $n$, i.e., $\\overline{c} = [c_1, c_2, \u2026\u2026\u2026, c_n]$, according to the feedback overhead requirements and directly discard the rest part of the codeword vector, i.e., $[c_{n+1},c_{n+2},\u2026\u2026\u2026, c_m]$. Then, the remaining codeword vector $\\overline{c}$ is quantized and fed back to the gNB through the feedback link. Due to the fact that"}, {"title": "D. BNA Algorithm for Target SGCS", "content": "1) Purpose of BNA algorithm: Generally, when the CSI feedback performance approaches one target SGCS $\\rho_t$, further improving the SGCS will increase little communication performance and meanwhile consume a lot of feedback overhead. On the other hand, for the varying input CSI eigenvectors, the SGCS performance is different with a fixed number of feedback bits. Therefore, by utilizing the adjustable characteristic of feedback bit numbers of ABLNet with FBCU, a BNA algorithm is developed to increase or decrease the number $Q$ of feedback bits to make the SGCS performance $\\rho$ stabilize at a reasonable target SGCS $\\rho_t$ for every feedback eigenvector.\n\n2) Description of BNA algorithm: Assume that the minimum and maximum number of feedback bits supported by ABLNet with FBCU are $Q_{min}$ and $Q_{max}$, respectively; given the initial feedback bit number $Q_i$, the corresponding SGCS performance $\\rho_i$, the target SGCS $\\rho_t$ and the tolerance error $\\varepsilon = 0.01$, the BNA algorithm is"}, {"title": "E. UE-First Separate Training for Different Manufacturers", "content": "1) Training process: When the UE and gNB come from different manufacturers, the trained encoder that matched to the adopted decoder at the gNB may not be transmitted to the UE due to the model protection. On the other hand, most"}, {"title": "V. CONCLUSIONS", "content": "This paper proposes an adaptive CSI feedback model ABLNet and designs a FBCU to process different lengths of input CSI eigenvectors and numbers of feedback bits. Then, a BNA algorithm is developed to achieve a target SGCS for every input CSI by adjusting feedback bit number flexibly. Moreover, a UE-first separate training approach is realized for decoupled training of encoders and decoder among the UEs and gNB from different manufacturers. Experiments reveal that the proposed ABLNet has better feedback performance with adapting different lengths of input CSI. Meanwhile, ABLNet with FBCU can improve the model robustness and maintains the SGCS performance. The designed BNA algorithm can effectively stabilize the SGCS performance for every input CSI with fewer number of feedback bits. Finally, separate training delivers comparable feedback performance to joint training model, and can reduce the complexity of feedback model."}]}