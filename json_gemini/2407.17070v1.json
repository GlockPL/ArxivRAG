{"title": "Curriculum Negative Mining For Temporal Networks", "authors": ["Ziyue Chen", "Tongya Zheng", "Mingli Song"], "abstract": "Temporal networks are effective in capturing the evolving interactions of networks over time, such as social networks and e-commerce networks. In recent years, researchers have primarily concentrated on developing specific model architectures for Temporal Graph Neural Networks (TGNNs) in order to improve the representation quality of temporal nodes and edges. However, limited attention has been given to the quality of negative samples during the training of TGNNs. When compared with static networks, temporal networks present two specific challenges for negative sampling: positive sparsity and positive shift. Positive sparsity refers to the presence of a single positive sample amidst numerous negative samples at each timestamp, while positive shift relates to the variations in positive samples across different timestamps. To robustly address these challenges in training TGNNs, we introduce Curriculum Negative Mining (CurNM), a model-aware curriculum learning framework that adaptively adjusts the difficulty of negative samples. Within this framework, we first establish a dynamically updated negative pool that balances random, historical, and hard negatives to address the challenges posed by positive sparsity. Secondly, we implement a temporal-aware negative selection module that focuses on learning from", "sections": [{"title": "1. Introduction", "content": "Temporal networks have gained popularity in recent years due to their capacity to capture the evolving nature inherent in diverse domains, such as social networks [18, 21, 28], recommendation systems [1, 16], financial transactions [22], transport [26], and political networks [6, 11, 19]. Unlike their static counterparts, these networks support additions, deletions, and changes in the features of nodes and edges over time by modeling a sequence of time-stamped events. To best leverage this temporal information, Temporal Graph Neural Networks (TGNNs) [8, 16, 24, 25, 27, 30, 33] have been developed.\nSimilar to static graph models, TGNNs [24, 33] employ negative sampling techniques to prevent the models from being overwhelmed by a disproportion-ally high number of negative over positive samples and enhance the models' efficiency. The most straightforward approaches often adopted are random sampling and recent sampling [24, 33]. However, temporal networks intro-duce two unique challenges that particularly undermine these approaches: positive sparsity and positive shift. Positive sparsity emerges as the inclusion of a temporal dimension significantly increases the negative-to-positive ratio by the number of timestamps, compared to static graphs. Consequently, ran-dom sampling in this context tends to produce a multitude of irrelevant and easily distinguishable negative samples, offering little to no value. Positive shift, on the other hand, occurs as the relationships between nodes change over time; for instance, in recommendation systems, users' preferences are likely to evolve [16]. Ignoring this factor may result in training models on outdated information, particularly in datasets spanning long periods.\nNonetheless, the negative sampling problem in temporal network learning has been seldom explored. While such efforts are limited for TGNNs, there"}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Temporal Graph Learning", "content": "Motivated by the significant progress of deep learning in Computer Vi-sion [15] and Natural Language Processing [20], learning dense embeddings for nodes has become a de facto standard paradigm in graph learning [9, 23], unifying different graph tasks into a graph representation learning task. Sub-sequently, Graph Neural Networks [10, 14, 31], which take both graph struc-ture and node features into account, replaced skip-gram models [9, 23] for graph representations. Influenced by the advances of static graph represen-tation learning, TGNNs have been proposed to handle the evolving dynamics of temporal networks [29], updating node embeddings as time elapses.\nExisting TGNNs can be classified into discrete-time and continuous-time TGNNs based on their temporal natures [13]. On the one hand, discrete-time TGNNs [8, 22, 25, 27] focus on the sequential dynamics of a series of graph snapshots, where the timespan of a snapshot depends largely on the graph domain. The consequent discrete-time TGNNs include a combination of Recurrent Neural Networks and Graph Neural Networks. DySAT [25], a typical discrete-time TGNN, first learns the structural representations of nodes within each graph snapshot and then aggregates across multiple snap-shots using a temporal self-attention layer.\nOn the other hand, continuous-time TGNNs focus on the sequential in-teractions of nodes, thereby offering more fine-grained temporal information. Various design paradigms exist for continuous-time TGNNs since temporal networks can be seen as sequential dynamics of either nodes or a graph. JODIE [16] utilizes two mutually updated RNNs to update user and item embeddings, alongside a temporal attention layer that projects user embed-dings after a certain time since their last interaction. Conversely, TGN [24] presents a generic framework on continuous temporal networks, simulating"}, {"title": "2.2. Hard Negative Sampling", "content": "Negative sampling strategies [4, 5, 12, 17, 32, 36, 38, 39] have been abun-dant in graph representation learning such as collaborative filtering and knowledge graphs. These strategies are traditionally categorized into two types: static and model-aware negative sampling.\nStatic negative sampling strategies [20] select negative samples based on a pre-defined probability distribution. The simplest and most common strategy is random sampling, which uniformly selects negative samples from uninter-acted nodes. However, random sampling falls short in ensuring the quality of the samples. In response, alternative distributions have been proposed. For instance, NNCF [4] and NCEPLRec [32] adopt item-popularity-based sampling distributions to preferentially select popular items as negative sam-ples, thereby mitigating the widespread popularity bias in recommender sys-tems [3]. Despite these advancements, all these methods fail to adequately account for distribution variations across different networks, thus leading to unsatisfactory performance.\nTo tackle this challenge, model-aware negative sampling strategies lever-age models' specific information to oversample negatives that closely resem-ble positive samples, thereby tightening models' decision boundaries and en-hancing accuracy. DNS [36] pioneers this approach by dynamically choosing negative samples with the highest prediction scores. NSCaching [38] builds on this by keeping a cache of hard negatives, whereas SRNS [5] introduces a variance-based criterion to reduce the risk of false negatives. Moreover, MixGCF [12] synthesizes hard negatives by infusing positive information into negative samples. DENS [17] splits embeddings into relevant and irrelevant factors and selects negatives that only differ in relevant factors from the pos-itives. ANS [39] combines factor-aware and augmentation techniques from these strategies; it separates the hard and easy factors of negative items and synthesizes new negatives by augmenting the easy factors. While these afore-mentioned strategies have shown encouraging outcomes, their direct applica-tion to TGNNs is disappointing due to their oversight of temporal networks' unique characteristics, particularly positive shift and positive sparsity.\nTo the best of our knowledge, ENS [7] is the only negative sampling method specifically designed for temporal networks. ENS selects negative samples by aiming to meet a difficulty target composed of the proportion of historical neighbors and average temporal proximity. While ENS tries to tackle positive sparsity by increasing the difficulty target by a predefined amount each epoch, its heuristic approach fails to adapt to the varying needs of different models and datasets. Moreover, although it addresses positive shift by considering temporal proximity, this method requires evaluating all historical edges to ensure accuracy, thereby consuming substantial resources. Finally, ENS does not account for individual node preferences; it indiscrim-inately prioritizes all nodes that have historically appeared, without distin-"}, {"title": "3. Problem Statement", "content": "Temporal Network. This section formulates the problem of negative sam-pling in temporal networks. Let G(V, E,T, X) be a temporal network where V and E denote the set of nodes and edges, T denotes the timestamps of interactions, and X denotes the node features. We denote the set of inter-actions by O+ = {(u, v+, t)|u, v+ \u2208 V and t \u2208 T} where each tuple (u, v\u207a, t) records an interaction between two nodes u,v\u207a that occurs at time t. By convention, we call u source node and v+ destination node. These pairs form positive training samples. Conversely, we define the complement of O+ as O\u00af = {(u,v\u00af,t)|u,v\u00af \u2208 V, t \u2208 T and (u, v\u00af, t) \u00a2 O+}. This set contains all node pairs u, v\u00af that are not connected by an edge at time t and is used to generate negative samples. Our goal is to define a negative sampling strategy f that selects negative samples (u, v\u00af, t) from O\u00af to enhance the performance of existing TGNNs.\nHistorical Neighbor. u, v' are called neighbors at t if (u, v', t) \u2208 O+. If there exists (u, v\", t') \u2208 O+ such that t' < t, v\" is called a historical neighbor of u at t. In our context, we further restrict historical neighbors to nodes that are not neighbors of u at the current time, i.e., (u, v\",t) \u00a2 O+. For each (u,t) \u2208 (V,T), we maintain a set H_{u,t} = {(v1, t1), (V2, t2), ..., (Vn, tn)} that records all unique historical neighbors of u at t and their respective interaction timestamps. In cases where vi interacts with u multiple times before t, we use the latest timestamp for ti. Historical neighbors in our method are then drawn from this set H_{u,t}"}, {"title": "4. Methodology", "content": "Overall, CurNM is a curriculum learning strategy that progressively in-creases the difficulty of selected negatives based on performance on the val-idation set, effectively addressing the steep difficulty curves found in ex-isting methods. Within this framework, we further develop two compo-nents. Firstly, to tackle positive sparsity, we establish a negative pool con-sisting of historical neighbors and random negatives, with hard negatives included when the model exhibits sustained improvements. Secondly, we use\na temporal-aware disentangling technique to score the information of can-didate negatives in the negative pool, emphasizing those that differ from positives only in the most critical dimensions, thus capturing positive shifts and individual preferences. These informative negative samples are then fetched for training TGNNs to ensure their performance and robustness.\nThis framework is illustrated in Figure 1, and the detailed workflow is presented in Algorithm 1."}, {"title": "4.1. Curriculum Learning", "content": "To address the learning difficulty caused by positive sparsity, the cur-riculum learning strategy adaptively increases the difficulty level of selected negatives based on the learning performance of TGNNs. Additionally, these"}, {"title": "Adaptive Selected Negatives.", "content": "Firstly, we introduce a sampling proportion \u03c0\u03b5 that self-adjusts based on the model's performance at e-th epoch \u2013 shrinking when performance improves and expanding otherwise - thus dynamically controlling the difficulty level of selected negatives. By starting with a large \u03c0\u03b5 to include both easy and hard negatives and tightening it only if the model consistently demonstrates improvements, this approach prevents the model from being overwhelmed by overly challenging negatives. Furthermore, we utilize a shrinkage rate \u03b3shrink to control the adjustment steps of \u03c0e. A high \u03b3shrink establishes a steep difficulty curve for model learning, while a low \u03b3shrink sets a flatter curve. This strategy is written as\n\u03c0_{e+1} = \\begin{cases}\n\u03c0_e - \u03b3_{shrink}, & \\text{If performance improves,} \\\\\n\u03c0_e + \u03b3_{shrink}, & \\text{Otherwise}\n\\end{cases} \n(1)\nIn addition, instead of the traditional method of selecting a set of nega-tive samples for each positive sample, we merge and evaluate all candidate negatives at the minibatch level. As the learning difficulties vary across source nodes, this approach allows us to focus on more informative nodes that present greater difficulty while automatically eliminating nodes that are easier to learn as we shrinks. Technically, we select the top-scored n\u044c = \u03c0e \u00d7 |b| \u00d7 M samples for each minibatch b at e-th epoch, where |b| denotes the number of source nodes in minibatch b, and M represents the size of each source's negative pool V.\nO_{sel} = arg \\text{top}_{n_b} {S_{uv^-} |\u2200u \u2208 b, v^- \u2208 V_u} \n(2)\nwhere Osel denotes the set of selected negatives, and \u015duv\u2013 is a scoring function between node pairs for negative selection, as defined by Eq. 13."}, {"title": "Annealing Random Negatives.", "content": "To provide the model with additional space for exploration and adaptation, especially in early epochs, each minibatch also includes de random negatives Orand in addition to Osel. A weight de is applied to balance these two types. Initially, we assign a higher weight to ran-dom negatives to enable the model to understand the basic patterns. As the model gains experience, the emphasis gradually shifts toward the selected, presumably more challenging negatives, enhancing the learning depth. Fol-lowing this intuition, we define \u03b4\u03b5 = max{\u03c0\u03b5, \u03b4min}. dmin is a hyper-parameter"}, {"title": "4.2. Negative Pool", "content": "The negative pool, which is an essential component of the curriculum learning strategy, is also constructed dynamically.\nTo ensure efficiency, we start the entire process by sampling a negative pool Vu of fixed size M for each positive sample (u, v\u207a,t). During the ini-tial epochs, we sample Vu as a mixture of historical neighbors and random negatives, a simple approach to prevent overcrowding with easy negatives. Random samples here serve a different purpose than before and are included to capture newly emerging preferences not disclosed by users' historical in-teractions. This process can be written as\nVu = V^{hist}_u \u222a V^{rand}_u\n(4)\nwhere |V\u2212| = M, and a proportion hyper-parameter \u03b3hist is used to balance between |V^{hist}_u| = \u03b3hist \u2217 M and |V^{rand}_u| = (1 \u2212 \u03b3hist) \u2217 M.\nOnce the model learns the fundamentals, we raise the difficulty level. We introduce this advanced stage when sampling proportion \u03c0e falls below a preset threshold \u03c4 for the first time. Since \u03c0e decreases only if the model is learning well, this condition ensures that the model only encounters more challenging negatives after it has adequately learned the basics. The indicator C\u03c0\u03b5 is determined as follows:\nC_{\u03c0_e} = \\mathbb{1}(\u03c0_e \u2264 \u03c4)\n(5)\nIn this advanced stage, we implement a hard negative cache V^{hard} of size M/2 to store a subset of Vu from the current epoch, focusing on likely false positives and those showing less learning in previous epochs. The cached negatives"}, {"title": "4.3. Negative Selection", "content": "The second critical component of our framework is the selection function used to choose negative samples from the negative pool Vu. This process consists of two steps: disentangle irrelevant factors of negative nodes and score negative samples with time embeddings."}, {"title": "Irrelevant Factor Disentanglement.", "content": "To facilitate TGNNs to differentiate pos-itive from negative samples, we disentangle nodes' relevant and irrelevant factors, which is in line with DENS [17].\nFor each positive sample (u, v\u207a, t), we construct a positive gate. This gate leverages the embeddings of the source node hu and the destination node hv+ to isolate the relevant factor h^{r}_{v^+} of the destination node v\u207a, illustrated as\nh^{r}_{v^+} = h_{v^+} \u2299 \u03c3(W_{src}h_u + W_{dst}h_{v^+} + b_p),\n(8)\nwhere Wsrc, Wdst and bp are trainable parameters shared by all positive sam-ples, \u2299 is the sigmoid function, and \u22c5 is the element-wise product. This factor"}, {"title": "Temporal Scoring Function.", "content": "As our goal is for the model to predict neighbors based on relevant factors, the most useful negatives for training are those that differ from the positives only in their relevant factors. In practice, this involves selecting negative samples from the negative pool Vu by maximizing the differences in relevant factors and minimizing the differences in irrelevant factors. This approach is written as\nS_{uv^-} = \u03b2_e \u2217 S^{+,-}_{r,ir} + (1 - \u03b2_e) \u00d7 S^{ir,ir}_{-,-}, \n(12)\nwhere suv- denotes the scoring function and Be is a hyper-parameter that balances the contributions of relevant and irrelevant factors at epoch e. In-tuitively, we want the model to first learn which factors are important and then understand how these factors drive interactions. This entails initially"}, {"title": "5. Experiment", "content": ""}, {"title": "5.1. Datasets and Evaluation", "content": "Dataset. We evaluate the performance of our CurNM method on 12 stan-dardized datasets obtained from DyGLib [35] and TGL [40]. These datasets encompass a broad spectrum of domains, sizes, durations, and network fea-tures, and are intended to represent a diverse array of datasets. According to Table 1, which summarizes the statistics, social and interaction networks are typically sparse, while social and economic networks often exhibit high recency and repetition. These characteristics are expected due to the limited number of relationships individuals can realistically maintain and the sig-nificant impact of recent events and cyclic patterns on public attention and market dynamics. Other features, such as average time proximity, present a more diverse result across different domains. We divide these datasets into training, validation, and test sets using a chronological split with ratios of 70: 15 : 15 to prevent temporal data leakage during model training."}, {"title": "5.2. Experiment Setting", "content": "Baselines. We compare our method against two commonly adopted negative sampling strategies \u2013 random sampling and recent sampling [24, 33] \u2013 along with ENS [7], the only existing method known to us tailored for temporal networks. Random sampling selects negative samples based on a uniform dis-tribution. Recent sampling selects the latest historical neighbors as negatives, offering a straightforward approach to addressing issues of positive sparsity"}, {"title": "5.4. Complexity Analysis", "content": "Theoretically, CurNM adds a negative mining process with a time com-plexity of O(|E| \u00d7 n \u00d7 d) to TGNNs, which originally have a complexity of O(L \u00d7 |E|\u00d7 n \u00d7 d). Here, L denotes the number of layers, |E| is the number of edges, and n represents the number of positive and negative samples per node, with nonlinear operations simplified to O(d).\nEmpirically, CurNM maintains high efficiency by limiting n with a rela-tively small negative pool, sized at M = 8. Table 3 presents a runtime com-parison between CurNM and baseline methods on the TGN model, which demonstrates the best overall performance among the three TGNNs eval-uated. According to Table 3, CurNM adds minimal computational load compared to basic random and recent sampling, consistently requiring about twice the time regardless of dataset size. Moreover, it is significantly more efficient than the state-of-the-art ENS on large datasets, requiring approxi-mately one-seventh of the time on Flights, the largest dataset tested."}, {"title": "5.5. Ablation Study", "content": "The ablation study detailed in Figure 2 examines the effects of adaptive \u03c0\u03b5, annealing random negatives, hard negative cache, factor disentanglement, and temporal-aware embeddings in our method on the TGN model. Due to space constraints, we present our study using six datasets here. In both transductive and inductive settings, the complete CurNM model delivers the"}, {"title": "5.6. Hyper-Parameter Sensitivity", "content": "Impact of Strategies for ae, \u00dfe, and de. We investigate our assumptions about the structures of ae, \u00dfe, and de by testing an increasing strategy (e.g., ae = min(E\u2032/E, 1)), a decreasing strategy (e.g., ae = max(0,1 \u2212E\u2032/E)), and a constant strategy (e.g., ae = 0.5). Our findings in Figure 3 confirm that, as expected, our current approach yields the most robust results. This underscores the ef-fectiveness of our dynamic strategies, which progressively guide the model to focus on relevant factors of informative nodes, thereby achieving a smoother and more advantageous learning curve.\nImpact of Strategies for \u03c0e and \u03b3shrink. Under the framework where \u03c0e should shrink as learning progresses, we explore two approaches: a linear strategy"}, {"title": "6. Conclusion", "content": "In this paper, we identify two unique challenges of negative sampling in temporal networks positive sparsity and positive shift. Our proposed CurNM method employs a dynamically updated negative pool and a cur-riculum learning strategy to adaptively adjust the difficulty level of negative samples during training, thus addressing the common challenge of positive sparsity. Furthermore, we implement a temporal-aware negative selection function to effectively capture positive shift. Our method's efficacy is demon-strated through extensive experiments against 3 algorithms and 12 datasets. Although CurNM demonstrates superior performance, it requires tuning sev-eral hyper-parameters to optimize its performance. In the future, we aim to"}]}