{"title": "rLLM: Relational Table Learning with LLMs", "authors": ["Weichen Li", "Xiaotong Huang", "Jianwu Zheng", "Zheng Wang", "Chaokun Wang", "Li Pan", "Jianhua Li"], "abstract": "We introduce rLLM (relationLLM), a PyTorch library designed for Relational Table Learning (RTL) with Large Language Models (LLMs). The core idea is to decompose state-of-the-art Graph Neural Networks, LLMs, and Table Neural Networks into standardized modules, to enable the fast construction of novel RTL-type models in a simple \"combine, align, and co-train\" manner. To illustrate the usage of rLLM, we introduce a simple RTL method named BRIDGE. Additionally, we present three novel relational tabular datasets (TML1M, TLF2K, and TACM12K) by enhancing classic datasets. We hope rLLM can serve as a useful and easy-to-use development framework for RTL-related tasks. Our code is available at: https://github.com/rllm-project/rllm.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs), like ChatGPT [1], are driving a new wave of artificial intelligence advancements, garnering widespread attention. These models are great at at understanding and generating text by leveraging technologies such as web-scale unsupervised pretraining [2], instruction fine-tuning [3], and value alignment [4]. Their strong performance across various tasks suggests they could be key to achieving Artificial General Intelligence [5].\nHowever, applying LLMs to real-world big data is extremely costly. Figure 1 illustrates the growth trends of various types of data alongside the corresponding expenses\u00b9. The costs associated with LLMs are unsustainable. For example, by 2025, the total cost of LLMs is anticipated to reach nearly $5,000 trillion, which is 214 times the 2023 GDP of the United States ($27.37 trillion). Another notable observation is that processing text and structured data will incur most of these expenses, despite these two types of data being smaller in volume compared to multimedia data.\nAs relational databases host around 73% of the world data [6], recent years have seen a significant shift towards Relational Table Learning (RTL) [7] [8] [9] 2. In this paper, we introduce the rLLM (relationLLM) project, which aims to provide a platform for rapidly developing RTL-typle methods with LLMs. As shown in Figure 2, it performs two key functions: 1) decomposing state-of-the-art Graph Neural Networks (GNNs), LLMs, and Table Neural Networks (TNNs) into standardized modules, and 2) enabling the construction of novel models in a \"combine, align, and co-train\" manner using these decomposed modules.\nTo illustrate the application of rLLM, we present a simple RTL method named BRIDGE. Specifically, this method utilizes TNNs to process table data and leverages the \"foreign keys\" in relational tables to construct relationships between table samples, which are then analyzed using GNNs. This approach takes into account multiple tables and the relationships between them.\nFurthermore, as RTL is an emerging field with a notable lack of datasets, we further introduce a novel data collection (named"}, {"title": "2 System Overview", "content": "As shown in Figure 2, rLLM consists of three main layers: Data Engine Layer, Module Layer, and Model Layer."}, {"title": "2.1 Data Engine Layer", "content": "This layer designs the fundamental data structures for graph and table data and defining the processing workflows for relational table data. As shown in Figure 3, the overall architecture decouples data loading and storage, which are handled by the Dataset subclass and BaseGraph/BaseTable subclasses, respectively. This design philosophy is driven by the pursuit of flexibility and scalability, enabling efficient and flexible handling and storage of different graph and table data.\nSpecifically, within the Dataset subclasses, we can implement various data loading classes tailored to the characteristics of different datasets. These subclasses focus on efficiently data loading and preprocessing, ultimately storing the processed data in data structures inherited from BaseGraph and BaseTable. Additionally, they are both optimized for the storage and processing of graph data (such as homogeneous and heterogeneous graphs) and table data, respectively. Overall, this design meets the familiar storage and processing requirements of relational table data consist of table data and foreign key relationships."}, {"title": "2.2 Module Layer", "content": "This layer decomposes the operations of GNNs, LLMs, and TNNS into standard submodules."}, {"title": "2.2.1 GNN Modules.", "content": "This part mainly includes the GraphTransform and GraphConv modules. The GraphTransform module provides preprocessing methods for graph data, such as normalization and self-loop operations. Additionally, this module supports combining various graph preprocessing methods, allowing users to perform complex graph preprocessing operations to meet the requirements of subsequent algorithms.\nThe GraphConv module implements popular graph convolution layers, including homogeneous and heterogeneous graph convolutions. The core functionality of this module involves different message-passing functions between nodes for various graph convolution operations, addressing the requirements of diverse graph types and algorithms. In practical applications, stacking and interacting multiple graph convolution layers allows for the modeling of complex graph data information."}, {"title": "2.2.2 LLM Modules.", "content": "This part mainly includes the Predictor and Enhancer modules. The Predictor module allows users to leverage LLMs for data annotation. It is crucial because much real-world data lacks labels, and manual annotation is expensive and prone to errors. Users can use existing prompts or design their own to enable LLMs to perform preliminary annotations. These annotations can serve as final label predictions or as labeled data for further training of other machine learning models.\nThe Enhancer module allows users to employ LLMs for data augmentation. In many real-world scenarios, data may be insufficient or of low quality. For example, understanding the full context of a research paper based solely on its title can be challenging. Users can use various prompts to generate detailed textual explanations for data samples with the LLM. These explanations can be used directly to enhance the data or be transformed into other feature formats to improve performance in downstream tasks."}, {"title": "2.2.3 TNN Modules.", "content": "This part mainly includes the TableTransform and TableConv modules. The TableTransform module maps sample features to higher-dimensional vector spaces. It is necessary because table data samples (i.e., rows) consist of multiple feature columns, which can vary greatly in nature. Due to the diverse types of features and the often limited information provided by tables with fewer columns, it is crucial to map or transform some columns into higher-dimensional feature spaces to enhance the sample information. The TableConv module facilitates multi-layer interactive learning among feature columns to extract latent information. Since the contribution of each column to downstream tasks varies (e.g., blood sugar levels in a diabetes dataset significantly impact diabetes prediction), this module usually employs various attention mechanisms to automatically learn and extract complex relationships from features. In reality, stacking and interacting multiple layers of this module generally provide sufficient capacity for comprehensive learning from table data."}, {"title": "2.3 Model Layer", "content": "By combining modules from the second layer, this layer provides three main strategies for rapidly developing RTL-type models: Combine, Align, and Co-Train.\n\u2022\tCombine refers to jointly using modules from different parts. For example, [10] and [11] use LLMs for preliminary label annotation, and then the annotated results are fed into a GCN [12] model for graph node classification. Within the rLLM framework, we can utilize the Predictor module from the LLM part to complete the annotation task and then use the GCN module from the GNN part for the following classification task.\n\u2022\tAlign involves aligning the input and output feature spaces for different modules. For instance, ConGraT [13] generates node embeddings using a language model and a GNN separately, followed by aligning these embeddings within the final embedding space. Within the rLLM framework, we can first use the Enhancer module from the LLM part to generate embeddings (and potentially perform enhancement simultaneously), then generate node embeddings with the GNN module, and finally align the two types of embeddings.\n\u2022\tCo-Train denotes the collaborative training of different modules. For example, BRIDGE (Section 3) integrates TNNs and GNNs to leverage internal and inter-table information. Within the rLLM, we can invoke modules from both GNNs and TNNs, combine them as needed, and perform co-training to enhance the performance of multi-table joint learning tasks.\nMoreover, these three strategies can be employed independently or in combination, allowing for the rapid development of various RTL-type models."}, {"title": "3 An Illustration Method - BRIDGE", "content": "In this section, we introduce a straightforward method named the Basic Relational table-Data LearninG Framework (BRIDGE) to illustrate how to quickly construct RTL-type methods using rLLM.\nIn real-world applications of relational databases, data is usually stored in multiple (two-dimensional) tables connected by foreign keys. This means relational table data includes table features (i.e., each sample is a row in a table with many columns) and non-table features (such as the graph structure formed by foreign key relationships). Therefore, we need to handle both the table data and their interrelationships.\nFirstly, for table data, we need to use table neural networks to model and learn from the data. This is due to the heterogeneity of table data, where each column's feature type and meaning can vary significantly. As shown in Figure 4, we use a Table Encoder to model the table features. As mentioned in Section 2.2.3, we can construct different Table Encoders using the TableTransform and TableConv modules from the TNN part in rLLM, to obtain the table embeddings.\nSecondly, for non-table data, particularly referring to the \"foreign keys\" between tables, we can leverage these foreign pivotal relationships to construct associations among multiple samples, and then use a Graph Encoder to model these connections. As mentioned in Section 2.2.1, we can use the GraphTransform and GraphConv modules from the GNN part in rLLM, to construct various Graph Encoders, ultimately producing graph embeddings. Additionally, we input the results from the TNN (i.e., table embeddings) along with other forms of non-table data into the Graph Encoder for joint processing.\nFinally, we integrate the outcomes from the table encoder and the graph encoder, allowing the Bridge framework to concurrently model multi-table data and their interconnections. The training objective of the entire model can be either supervised (e.g., using a cross-entropy loss function based on labeled data) or unsupervised (e.g., designing an unsupervised loss function based on data reconstruction principles from table data or foreign key relationships)."}, {"title": "4 Methods and Datasets", "content": "We have already included some common methods, which can be categorized into two types.\n(1) GNN-type Methods:\n\u2022\tHomogeneous Methods: GCN [12], GAT [14], RECT [15], TAPE [16], and OGC [17].\n\u2022\tHeterogeneousMethods: HAN [18] and HGT [19].\n(2) TNN-type Methods:\n\u2022\tSingle-Table Learning: TabTransformer [20], TabNet [21], and FT-Transformer [22].\n\u2022\tRelational Table Learning: BRIDGE."}, {"title": "4.2 Included Datasets", "content": "In addition to the common graph data and single-table data, we further introduce a novel data collection (named SJTUTables) which includes three novel relational table datasets by enhancing existing classical ones. As summarized in Table 1, each dataset has a default classification task with a balanced and fixed train/val/test split setting. Specifically, we provide 20 labeled samples for each class in these datasets, with two additional sets of 500 validation samples and 1000 test samples. The complete details are as follows.\n\u2022\tTable-MovieLens 1M (TML1M) is a relational table dataset enhanced from the classical MovieLens1M dataset\u00b3, comprising three tables: users, movies and ratings. We have enriched the movie table with more comprehensive features and defined a new task for classifying user age ranges.\n\u2022\tTable-LastFm2K (TLF2K) is a relational table dataset enhanced from the classical LastFm2k dataset\u2074, containing three tables: artists, user_artists and user_friends. We have enriched the artists table with more detailed features and streamlined the tags for each artist, defining a new task for music genre classification of artists.\n\u2022\tTable-ACM12K (TACM12K) is a relational table dataset enhanced from the ACM heterogeneous graph dataset5. It includes four tables: papers, authors, citations and writings. The paper features include year, title, and abstract, while author features include name and affiliation. In addition, we also make some completion when some features of papers are lost. The task is to predict the conference of papers.\nCompared to other datasets. The RelBench dataset [9], recently scraped from websites like Amazon and Stack Overflow, includes commercially practical applications such as user lifetime value prediction and user forum activity prediction. However, this practicality also introduces some additional challenges such as imbalance, high noise levels, complex tasks, and large data volumes. In contrast, SJTUTables are enhancements of classic datasets, offering simplicity and reliable data quality. In addition, its datasets focus on the most classic classification tasks in the machine learning field, providing fixed, balanced splits to facilitate standardized evaluation. Therefore, we strongly recommend designing standard RTL methods based on SJTUTables before conducting further commercial application evaluations on the RelBench dataset."}, {"title": "5 Evaluation", "content": "To demonstrate our system and the proposed BRIDGE algorithm, we conducted comparative experiments on the TML1M dataset. In the BRIDGE algorithm, we used TabTransformer as the table encoder and GCN as the graph encoder. To ensure fairness, we standardized training batches, dropout rates, and other parameters for each method and conducted multiple experiments to get the average results."}, {"title": "5.3 Results and Analysis", "content": "The experimental results indicate that traditional single-tabular TNNs can only learn knowledge from the single target table, failing to effectively utilize the information provided by multiple tables and the relationships between them. Consequently, their performance is relatively poor. In contrast, the BRIDGE algorithm effectively extracts valuable information from both the various tables and the relationships between them by combining a table encoder and a graph encoder, leading to a notable improvement in performance."}, {"title": "6 Conclusion", "content": "We presented rLLM framework for relational table learning with LLMs. We are actively working to further integrate more advanced methods and also plan to optimize relevant data structures to improve system efficiency. All researchers and software engineers are welcomed to collaborate with us in extending its scope."}, {"title": "A.1 Details of Figure 1", "content": "Global Data Trend Estimation. We calculated the total data distribution based on statistics and projections from Statista [23], which estimate that the global data volume will reach a staggering 181ZB by 2025. Additionally, using reports from Chopra [24] and IBM [25], we roughly estimated the proportion of each modality and calculated their corresponding data volumes based on the projected global data total.\nLLM Cost Trend Estimation. To calculate the LLM cost, we first determined the number of tokens that different modalities of data could be converted into. First, for pure text data, we assumed the text to be in UTF-8 encoded plain English, where each character occupies one byte. According to relevant studies [26], English words are approximately 6-11 characters. Using this ratio, we calculated the number of words corresponding to the text data and then used OpenAI's empirical formula [27] to estimate the number of tokens. Second, for multimodal data, such as images and videos, we applied different methodologies. For images, we used 256px by 256px RGB images and employed tokenization techniques similar to those used in Vision Transformer [28], in conjunction with OpenAI's pricing strategy for estimation [29]. For videos, we referred to Google's Gemini 1.5 technical report [30], analyzing token calculation strategies demonstrated in the AlphaGo documentary. This approach involved randomly sampling one frame per second from the video and calculating the number of tokens in the same way as for images. Last, after determining the number of tokens for each modality, we calculated the associated costs. We assume that these data are uniformly given to GPT-3.5 Turbo[4] for analysis, the overhead required to output the token is ignored, and finally, the approximate analysis cost is obtained."}, {"title": "A.2 Datasets", "content": "We introduce a novel data collection (named SJTUTables) which includes three novel relational table datasets by enhancing existing classical ones. Each dataset has a default single-label classification task with a balanced and fixed train/val/test split setting. Specifically, we provide 20 labeled samples for each class in these datasets, with two additional sets of 500 validation samples and 1000 test samples. The complete details are as follows."}, {"title": "A.2.1 TML1M.", "content": "Derived from the classical MovieLens 1M dataset7, the TML1M dataset consists of three relational tables.\n\u2022\tusers table: Inherited from the MovieLens 1M dataset, it includes UserID, Gender, Age, Occupation and Zip-code information of users. In sum, the row number is 6,040 and the column number is 5.\n\u2022\tmovies table: Enhanced by scraping the MovieLens website to gather additional metadata for each movie, including MovieID, Title, Year, Genre, Director, Cast, Runtime, Languages, Certificate, Plot and Url. This enhancement provides more comprehensive and detailed textual information of movies. In sum, the row number is 3,883 and the column number is 11.\n\u2022\tratings table: Contains UserID, MovieID, Rating, and Timestamp of ratings. In sum, the row number is 1,000,209 and the column number is 4.\nThe default task for this dataset is to predict the user's age range in the User table."}, {"title": "A.2.2 TLF2K.", "content": "Derived from the classical LastFM 2K datasets8, the TLF2K dataset consists of three relational tables.\n\u2022\tartists table: Enhanced by scraping Last.FM, its column includes artistID, type, name, born, yearsActive, location, genre, tag_list, biography and url. Every artist is classified into one of 11 genres. Specifically, ChatGPT was used to assign a single label to each artist based on their tag list, including confidence scores, with manual intervention for low-confidence labels. As such, original tags, by default, should not be used for this classification task. In sum, the row number is 9,047 and the column number is 10.\n\u2022\tuser_friends table: Contains 12,717 bi-directional edge relationships, representing friendships among 1,892 users. In sum, the row number is 12,717 and the column number is 2. The columns are userID an friendID.\n\u2022\tuser_artists table: Represents listening relationships between users and artists. In sum, the row number is 80,009 and the column number is 3. The columns are userID, artistID and weight, where weight represents listening count.\nThe default task for this dataset is to predict the music genre of artists."}, {"title": "A.2.3 TACM12K.", "content": "Derived from the classical ACM heterogeneous graph dataset, TACM12K contains four tables:\n\u2022\tpapers table: Manually labeled the year information for venues and added year attributes via the 'PvsV' matrix. Corrected errors in the original 'PvsC' markings, reclassified STOC as COLT in 'VvsC', and recalculated the 'PvsV * VvsC' matrix to add conference attributes to papers. In addition, we also provide the title and abstract information as two columns. In sum, the row number is 12,499 and the column number is 5, and the columns are paper_id, year, conference, title and abstract.\n\u2022\tauthors table: Extracted from the file, it includes original author IDs and names, with firm information added based on 'AvsF'. In sum, the row number is 17,431 and the column number is 3, and the columns are author_id, name and firm.\n\u2022\tcitations table: Derived from the original 'PvsP' matrix. In sum, the row number is 30,789 and the column number is 2, and the columns are paper_id and paper_id_cited, where the former column cites the latter.\n\u2022\twritings table: Derived from the original 'PvsA' matrix. In sum, the row number is 37,055 and the column number is 2, and the columns are paper_id and author_id.\nThe default task for this dataset is to predict the conference of papers."}]}