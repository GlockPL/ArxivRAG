{"title": "Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding", "authors": ["Rania Hossam", "Ahmed Heakl", "Walid Gomaa"], "abstract": "Traditional fish farming practices often lead to inefficient feeding, resulting in environmental issues and reduced productivity. We developed an innovative system combining computer vision and IoT technologies for precise Tilapia feeding. Our solution uses real-time IoT sensors to monitor water quality parameters and computer vision algorithms to analyze fish size and count, determining optimal feed amounts. A mobile app enables remote monitoring and control. We utilized YOLOv8 for keypoint detection to measure Tilapia weight from length, achieving 94% precision on 3,500 annotated images. Pixel-based measurements were converted to centimeters using depth estimation for accurate feeding calculations. Our method, with data collection mirroring inference conditions, significantly improved results. Preliminary estimates suggest this approach could increase production up to 58 times compared to traditional farms. Our models, code, and dataset are open-source a.", "sections": [{"title": "INTRODUCTION", "content": "Optimizing the fish feeding process is critical, as it accounts for up to 40% of total production costs (Atoum et al., 2014; Arditya et al., 2021; Oostlander et al., 2020). Effective nutrient control enhances profitability in aquaculture by preventing waste and maintaining high fish quality. Nutrient wastage not only escalates costs but also contributes to water pollution, adversely affecting fish survival and fertility rates. Therefore, precise nutrient management is essential for both economic efficiency and sustainable aquaculture development, ensuring optimal water quality and operational success.\nRecent research has proposed various techniques for controlling the amount of nutrients given to fish. Some researchers have utilized Convolutional Neural Networks (CNNs) for predicting morphological characteristics such as overall length and body size by detecting keypoints on the fish body (Su and Khoshgoftaar, 2009; Tseng et al., 2020). For instance, (Tseng et al., 2020) proposed a CNN classifier to detect only two keypoints, the fish head, and tail fork regions, to measure the fish body length. Alternatively, (Su and Khoshgoftaar, 2009) used a combination of a faster R-CNN (Ren et al., 2015) for initial fish detection and a stacked hourglass (Newell et al., 2016) for keypoint detection, resulting in a complex and computationally expensive method. Another study (Li et al., 2021) proposed a CNN for marine animal segmentation, which performed well but involved 207.5 million trainable parameters, making it unsuitable for resource-constrained environments like embedded systems or mobile devices.\nAutomatic control of fish feeding in real environments remains challenging due to variable data appearance and weather conditions, which can affect the accuracy of detection and tracking results (Soetedjo and Somawirata, 2019; Vaquero et al., 2021; Babaee et al., 2019). Object tracking, an active research area in computer vision applications, faces increased complexity in multiple-object tracking due to the need for accurate association of objects across frames (Vaquero et al., 2021; Tang et al., 2017; Zhang et al., 2020b). Recent advancements like the SiamRPN tracker (Zhu et al., 2018; Li et al., 2019) and multiaspect-ratio anchors have significantly improved the performance of Siamese-network-based trackers by addressing the bounding box estimation problem.\nTo address these challenges, our approach involves the following contributions:\n\u2022 We develop a method to estimate the weight of Tilapia fish using a length-weight relationship\n\u2022 We curate an open-source dataset of Tilapia fish images, annotated with keypoints such as the mouth, peduncle, belly, and back.\n\u2022 We train a YOLOv8 model on this dataset, achieving high precision and recall in keypoint detection and fish counting.\n\u2022 We design an end-to-end system, powered by two cameras installed in the fish tank, to monitor feeding amounts, pH levels, and dissolved oxygen. The collected data is relayed to a mobile application for easy access and real-time monitoring.\nThis approach provides a holistic solution for efficient and effective aquaculture management.\nThe remainder of the paper is organized as follows. Section 2 reviews existing fish mass estimation techniques and feeding methods. Section 3 details our approach, including data collection, model training, and fish weight estimation. Section 4 describes our IoT system architecture for real-time monitoring and control. Results and comparative analysis are presented in Section 5, followed by a discussion of limitations and future work in Section 6. Finally, Section 7 summarizes our findings and their implications for aquaculture productivity."}, {"title": "RELATED WORK", "content": "This section provides an overview of existing research relevant to our study on precise fish feeding in aquaculture. We focus on two key areas: fish mass and length estimation techniques, and automated fish feeding methods. By examining current approaches, we aim to contextualize our work within the field and highlight the advancements offered by our proposed system."}, {"title": "Fish Mass and Length Estimation Techniques", "content": "The authors in (Zhang et al., 2020a) developed a fish mass estimation approach by constructing an experimental data collection platform to capture fish images. They used the GrabCut algorithm (Rother et al., 2004) for image segmentation, followed by image enhancement and binarization to extract fish body contours. Shape features were extracted and redundant features were removed using Principal Component Analysis (PCA) (Ma\u0107kiewicz and Ratajczak, 1993), with feature values calculated through a CF-based (Collaborative Filtering) method (Su and Khoshgoftaar, 2009). A BPNN algorithm was then employed to construct the fish mass estimation model. In contrast, our study uses the YOLOv8 model for keypoint detection to identify critical points such as the fish's head and tail. Our dataset is collected using dual-synchronous orthogonal network cameras, with frames analyzed by our backend server. Instead of traditional feature extraction and PCA, we integrate depth estimation using the GLPN (Kim et al., 2022) model to create depth maps, enhancing length measurement accuracy by converting pixel coordinates to real-world dimensions.\nThe authors in (Jisr et al., 2018; Mathiassen et al., 2011; Islamadina et al., 2018) have used computer vision like saliency map, edge detection and thresholding and traditional image processing techniques like noise reduction and contrast enhancement to segment (Jisr et al., 2018; Islamadina et al., 2018), or make a 3D model (Mathiassen et al., 2011) of the fish body; then use classical machine learning methods, e.g. regression (Sanchez-Torres et al., 2018; Mathiassen et al., 2011) for weight and length extraction. Although these studies have achieved significant results, they have involved complex image processing and feature engineering processes to suit their experimental conditions.\nThe authors in (Saleh et al., 2023) applied a novel end-to-end keypoint estimation model called MFLD-net. It builds upon CNNs (Sandler et al., 2019), vision transformers (Dosovitskiy et al., 2020), and multi-layer perceptrons (MLP-Mixer) (Tolstikhin et al., 2021). Additionally, it leverages patch embedding (Dosovitskiy et al., 2020), and spatial/channel locations mixing (Tolstikhin et al., 2021). It differs significantly from our approach as the images were taken outside the pool environment. Additionally, their method involved annotating more than four keypoints on each fish, which may increase the complexity of the annotation process. Furthermore, their study used fish of a fixed size, which limits the model's ability to generalize to different fish sizes."}, {"title": "Fish Feeding Techniques", "content": "The authors in (Riyandani et al., 2023) focus on developing an automatic feeder employing the YOLOv5x detection model (Vasanthi and Mohan, 2024) for fish feed detection. Their model achieved notable metrics, including an accuracy of 82% and mAP of 81.9%. The automatic feeder dispenses a"}, {"title": "METHODS", "content": "This section details our approach to developing a precise fish-feeding system. We describe the process of estimating Tilapia fish weight, our data collection and annotation methods, the implementation of YOLOv8 for keypoint detection and fish counting, and our technique for calculating fish length and feed amounts. These methods form the foundation of our integrated computer vision and IoT-based solution for optimizing aquaculture management."}, {"title": "Tilapia Fish Weight Estimation", "content": "To determine the appropriate amount of Tilapia fish feed, (Jisr et al., 2018; Lupatsch, 2022) have shown that the amount of feed required for fish can be estimated based on their weight. (M Osman et al., 2020) provided an equation 1 to estimate the fish weight from its length, where the length is defined as the distance from the mouth to the peduncle (Jerry and Cairns, 1998) as shown in figure 1 (Maximum Standard Length):\n$W = aL^b$ (1)\nwhere W is the fish's weight in grams (g), L is the length (cm), and a and b are species-specific coefficients (a = 0.014 and b = 3.02 for Tilapia) (M Osman et al., 2020). This method simplifies data collection, bypassing direct weight measurements, and allows weight distribution analysis and other parameters within the fish population."}, {"title": "Keypoint Annotation and Data Collection", "content": "To determine the appropriate feed amount for Tilapia fish, we first needed to specify keypoints to measure their length accurately, defined as the distance from the mouth to the peduncle (Author and Author, Year). For this purpose, we collected 3,500 images of Tilapia fish in a small bowl of three fish. These images were manually annotated using Roboflow (Roboflow, 2022), a widely used tool for creating and managing annotated datasets. Although we only needed"}, {"title": "Calculating Fish Length", "content": "To estimate fish length, we calculate the Euclidean distance between the head and tail keypoints in pixel units. This measurement is converted to centimeters by integrating depth estimation and focal length, considering the camera distance. Initially, each fish image is resized to a standard (416 \u00d7 416) for consistency.\nThe GLPN (Global-Local Path Networks) model (Kim et al., 2022) is employed for depth estimation, predicting a depth value for each pixel and creating a depth map essential for spatial information. The YOLOv8 model detects keypoints on the fish (head and tail). These coordinates are then adjusted by their respective depth values to approximate real-world distances. In this depth-adjusted coordinate space, the Euclidean distance between the head and tail keypoints represents the fish's length in pixel units. For the conversion of pixel coordinates to real-world coordinates, given a point in the image with coordinates ($x_p$,$y_p$) and depth d, the real-world coordinates (X,Y,Z) can be computed as follows: Let f be the focal length of the camera (in pixels). Then, we can calculate the 3D coordinates (X,Y,Z) from the 2D image coordinates ($x_p$,$y_p$) and depth d as follows:\n$X = \\frac{x_p.d}{f} , Y = \\frac{y_p.d}{f}, Z=d$ (2)\nWe can retrieve the length by getting the Euclidean distance between $(X, Y, Z)_{head}$ and $(X,Y,Z)_{tail}$ which we call distance. Finally, the fish length is calculated using the formula:\nfish length = $\\frac{f}{distance}$ (3)"}, {"title": "Calculating Fish Count", "content": "After estimating the fish feed amount based on weight, our next goal is to determine the total feed required for the fish in the bowl. To achieve this, we trained another YOLOv8 model (Reis et al., 2023) on our dataset to count the fish accurately as shown in figure 2b."}, {"title": "Feed Estimation", "content": "Once the optimal fish feeding allowances are determined from table 1, we estimate the final feed requirements. By leveraging the robustness of the fish counting models in table 2, the final feed estimation is calculated by multiplying the number of fish, as determined by the fish counting model, with the average feeding amount."}, {"title": "IOT SYSTEM", "content": "Our IoT system integrates a diverse set of sensors including pH, dissolved oxygen (DO), and temperature sensors, along with two cameras, an STM32F103C8 MicroController Unit (MCU) (STMicroelectronics, 2024), and dual pumps-one for feeding fish and another for pH control, as depicted in figure 3. These sensors are connected to the MCU and continuously collect crucial data from the aquatic environment. A prototype is shown in figure 4.\nThe sensor readings are initially processed by the MCU. Once processed, the MCU transmits the data to gateways within the system architecture. From the gateways, the data is then forwarded via the MQTT communication protocol (Router, 2024) to our backend server. The backend server then acts as the central hub where the data is stored and processed.\nThe backend server interacts with a dedicated mobile application, shown in figure 6, serving as the user interface. Through this application, users can view real-time graphs, detailed analytics, statistical summaries, and logs reflecting the system's operations and environmental conditions. Simultaneously with sensor data collection, our dual-synchronous orthogonal network cameras actively capture frames from the pool. These frames undergo processing via the MCU, followed by transmission to the gateway, and onward to the MQTT broker before reaching the backend server. At the backend, AI models analyze these frames from two cameras to extract keypoints and fish counts. The results from each camera data and averaged for more accurate predictions.\nThe AI model's predictions are then relayed back to the backend server, which communicates them via the MQTT broker to the MCU. Based on these insights, the MCU precisely transmits the feeding amount to the feeding pump mechanism. The feeding mechanism operates through a vertical inventory above the pool, regulated by gates, and monitored by a load cell sensor for precise food dispensation. This setup includes a 10KG load cell, an HX-711 amplifier, and two servo motors for meticulous gate control as shown in figure 5."}, {"title": "RESULTS & DISCUSSION", "content": "This section presents the outcomes of our experiments using the YOLOv8 model for keypoint detection and fish counting in Tilapia aquaculture. Our evaluation demonstrates that YOLOv8 outperforms existing approaches in both accuracy and speed, making it exceptionally well-suited for deployment on edge devices in resource-constrained environments."}, {"title": "YOLOv8 Performance on Tilapia Dataset", "content": "Our experiments demonstrate the superior performance of our YOLOv8 model in both keypoint detection and fish counting tasks. Table 2 summarizes the evaluation metrics for the YOLOv8 model trained on our custom Tilapia fish dataset.\nFor the fish counting task, we employed the same YOLOv8 architecture, which yielded an even higher precision of 96.21%. This precision metric, derived from the model's training report, represents the ra-"}, {"title": "Comparative Analysis with Existing Models", "content": "To contextualize our results, we compared YOLOv8's performance with other state-of-the-art deep learning models, as reported in (Tengtrairat et al., 2022). Table 3 presents the comparison of various metrics across different models (Faster R-CNN(Ren et al., 2015), Mask R-CNNN (He et al., 2017), RetinaNet (Lin et al., 2017), and our YOLOv8 models (Vasanthi and Mohan, 2024)) on the tilapia dataset.\nAs evident from table 3, our YOLOv8 model outperforms other models in most metrics, particularly in AP@50 and AP@75. The superior performance in AP@75 is especially noteworthy, as it indicates YOLOv8's ability to maintain high accuracy even with stricter overlap requirements. This is crucial for precise keypoint detection in densely populated fish farms.\nWhile Mask R-CNN shows a higher overall AP score, which averages performance across all IoU thresholds, YOLOv8 demonstrates more consistent performance at the critical AP@50 and AP@75 levels. This suggests that YOLOv8 may be more reliable for practical applications where moderate to high precision is required."}, {"title": "YOLOv8 & Edge Computing", "content": "YOLOv8's architecture is optimized for edge computing, making it ideal for real-time aquaculture monitoring. Its lightweight design allows efficient processing on limited-resource devices, with the nano version achieving sub-200ms inference times on our MCU. This efficiency reduces energy consumption and operational costs. YOLOv8's scalability ensures consistent performance across various hardware configurations, from IoT devices to edge servers. Local data processing minimizes latency and enables rapid decision-making without constant server communication. These features address on-site aquaculture management challenges, potentially revolutionizing Tilapia monitoring. YOLOv8's reliable performance under hardware constraints makes it a superior choice for transforming aquaculture practices."}, {"title": "Implications for Aquaculture Productivity", "content": "The high accuracy of our YOLOv8-based system translates to significant potential improvements in aquaculture productivity. Based on preliminary assessments and comparisons with traditional methods, we estimate that our approach can contribute to a 58-fold increase in production compared to conventional fish farms, inspired by (SEAFDEC/AQD, 2022). This dramatic improvement is attributed to:\n1. More accurate fish counting, enabling optimal stocking densities.\n2. Precise monitoring of fish growth and health through keypoint detection.\n3. Reduced water pollution and fish mortality due to timely interventions.\nIt is important to note that these productivity gains are theoretical maximums based on optimal conditions and full implementation of our system. Real-world results may vary depending on specific farm conditions and management practices."}, {"title": "LIMITATIONS AND FUTURE WORK", "content": "The limitations of this study include the use of datasets from a single fish size in a controlled environment. Future work should include a diverse range of fish sizes and environments to improve model generalizability, especially for smaller fish where keypoint detection is more challenging. Additionally, the current system does not account for varying environmental factors such as water quality, which can influence fish growth and feeding behavior. Integrating environmental monitoring could further optimize feeding practices. While the YOLOv8 model performed well on the Tilapia dataset, its applicability to other fish species remains untested. Lastly, expanding training datasets to include multiple species could enhance its utility across different aquaculture contexts."}, {"title": "CONCLUSION", "content": "This paper used computer vision and IoT technologies to present a novel system for precise Tilapia fish feeding. The system utilizes real-time water quality monitoring and vision-based fish weight estimation to determine optimal feeding amounts. Our models demonstrated superior performance with precision of 94% for keypoint detection, and 96% for fish counting, respectively, outperforming Faster R-CNN, Mask R-CNN, and RetinaNet in key metrics. This study provides a precise, scalable solution for sustainable and efficient aquaculture, with recommendations for further real-world testing and refinement. Lastly, this approach has the potential to significantly enhance fish farm productivity (up to 58x) while mitigating environmental concerns by minimizing pollution and fish mortality."}]}