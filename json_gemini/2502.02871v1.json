{"title": "Position: Multimodal Large Language Models Can Significantly Advance Scientific Reasoning", "authors": ["Yibo Yan", "Shen Wang", "Jiahao Huo", "Jingheng Ye", "Zhendong Chu", "Xuming Hu", "Philip S. Yu", "Carla Gomes", "Bart Selman", "Qingsong Wen"], "abstract": "Scientific reasoning, the process through which humans apply logic, evidence, and critical thinking to explore and interpret scientific phenomena, is essential in advancing knowledge reasoning across diverse fields. However, despite significant progress, current scientific reasoning models still struggle with generalization across domains and often fall short of multimodal perception. Multimodal Large Language Models (MLLMs), which integrate text, images, and other modalities, present an exciting opportunity to overcome these limitations and enhance scientific reasoning. Therefore, this position paper argues that MLLMs can significantly advance scientific reasoning across disciplines such as mathematics, physics, chemistry, and biology. First, we propose a four-stage research roadmap of scientific reasoning capabilities, and highlight the current state of MLLM applications in scientific reasoning, noting their ability to integrate and reason over diverse data types. Second, we summarize the key challenges that remain obstacles to achieving MLLM's full potential. To address these challenges, we propose actionable insights and suggestions for the future. Overall, our work offers a novel perspective on MLLM integration with scientific reasoning, providing the LLM community with valuable vision for achieving Artificial General Intelligence (AGI).", "sections": [{"title": "1. Introduction", "content": "Scientific reasoning, at its core, is the process through which humans apply logic, evidence, and critical thinking to explore and interpret phenomena in various scientific domains (Bao et al., 2009; Lawson, 2004). This cognitive ability is essential not only for advancing knowledge but also for fostering a deeper understanding of the natural world, particularly in fields such as mathematics, physics, chemistry, and biology. In education, AI for Science, and other domains, scientific reasoning serves as a cornerstone for cultivating problem-solving skills, analytical thinking, and innovation (Huang & Chang, 2022; Willemsen et al., 2023). However, despite shared objectives, each domain has unique characteristics in terms of data representation, knowledge construction, and reasoning methods (Wang et al., 2023c).\nIn response to these challenges, the scientific community has explored a range of approaches, from traditional statistical methods to the more recent advancements in deep learning, with the goal of improving knowledge reasoning across disciplines (Goodman, 2016; Lu et al., 2022b). While significant progress has been made in enhancing scientific reasoning within specific domains, a gap remains in the broader context of scientific research. Current scientific reasoning models, and even those targeted toward domain-specific applications, are still far from achieving the generalization capabilities necessary for Artificial General Intelligence (AGI), which aims to exhibit unified reasoning across all fields (Birhane et al., 2023).\nThe rapid rise of Large Language Models (LLMs) in recent years has brought transformative changes across various domains, pushing the boundaries of what is possible in natural language processing and understanding (Min et al., 2023; Zhao et al., 2023a). Despite their remarkable zero-shot reasoning abilities, many areas, particularly in scientific fields, require multimodal inputs to build a comprehensive understanding of knowledge. This has led to the emergence and growth of Multimodal Large Language Models (MLLMs), which are capable of integrating and reasoning over multiple types of data, such as text, images, and other modalities (Bai et al., 2024a; Liang et al., 2024b). MLLMs are not only revolutionizing language understanding but also paving the"}, {"title": "2. Background", "content": "Scientific reasoning is the intellectual process of forming hypotheses, interpreting evidence, and applying logical frameworks to solve problems or explain phenomena (Bao et al., 2009; Lawson, 2004). Its importance spans diverse scientific domains, such as mathematics, physics, chemistry, and biology, where it drives discovery, fosters understanding, and enables practical innovation. With the rise of multimodal data, scientific reasoning increasingly requires integrating and synthesizing information from multiple sources, including textual, visual, and other modalities. We elaborate on the formal formulation of the task in Appendix A.\nThe significance of scientific reasoning in the MLLM context is profound. By enabling models to connect disparate data points and infer relationships across modalities, MLLMs hold the potential to transform how researchers approach interdisciplinary problems. This capability is critical for addressing grand challenges such as climate modeling, drug discovery, and sustainable engineering (Zhang et al., 2024d). Moreover, enhancing MLLM-based scientific reasoning aligns with the broader goal of advancing AGI, as it exemplifies the synthesis of learning, abstraction, and decision-making across various domains."}, {"title": "2.2. Multimodal Large Language Models", "content": "Most existing MLLMs consist of three primary modules: a modality encoder, an LLM module, and a projector between them (Fu et al., 2024). Typically, the modality encoder ex-"}, {"title": "3. How MLLMs Benefit Scientific Reasoning", "content": "The development of (M)LLMs for scientific reasoning can be categorized into four progressive stages: Broad Knowledge and Recognition, Analogical Reasoning and Generalization, Insightful Inference, and Creative Hypothesis Generation. Each stage is defined by its unique characteristics across four dimensions: data and knowledge requirements, reasoning mechanisms, model generalization, and applications and impact (See the detailed comparison in Appendix C). Figure 1(c) provides an overview of four stages, highlighting their evolution progress."}, {"title": "3.1. Research Roadmap", "content": "The initial stage focuses on building a strong foundational understanding across domains. MLLMs in this stage rely on highly diverse and multimodal datasets to capture a broad range of knowledge. Reasoning mechanisms are primarily retrieval-based, with emphasis on pattern recognition, data alignment, and summarization. Model generalization remains limited, operating primarily within predefined domains (Chen et al., 2023c; Pei et al., 2024; White, 2023)."}, {"title": "Stage 2: Analogical Reasoning and Generalization", "content": "This stage emphasizes the ability to draw connections and analogies across domains. Data requirements shift towards moderately diverse datasets that emphasize relationships and cross-domain patterns. Reasoning mechanisms incorporate relational reasoning and analogical thinking, enabling MLLMs to generalize effectively across domains. Applications include interdisciplinary problem-solving, transfer learning, and identifying cross-domain insight, reflecting a moderate increase in complexity and impact (Lewis & Mitchell, 2024; Webb et al., 2023)."}, {"title": "Stage 3: Insightful Inference", "content": "The third stage focuses on inferring deep insights from minimal and high-context data. Data requirements narrow to low-diversity, domain-specific datasets, allowing MLLMs to develop nuanced understanding. Reasoning mechanisms involve predictive reasoning and contextual interpretation, enabling the model to deduce complex outcomes. Generalization becomes highly context-specific, and applications include optimization and predictive modeling, making this stage highly impactful (Barman et al., 2025; Melko & Carrasquilla, 2024)."}, {"title": "Stage 4: Creative Hypothesis Generation", "content": "In the final stage, MLLMs achieve the ability to generate innovative hypotheses and explore uncharted territories. Data requirements include highly diverse and synthetic datasets or simulation environments, fostering creativity. Reasoning mechanisms reach their highest complexity, involving generative reasoning and hypothesis exploration. Generalization becomes innovation-driven, synthesizing knowledge across fields. Applications at this stage have the highest impact, including proposing new theories, designing experiments, and driving scientific discovery (Orwig et al., 2024; Pelletier et al., 2024; Qi et al., 2024; Xiong et al., 2024a)."}, {"title": "3.2. Data Heterogeneity Across Four Scientific Domains", "content": "MLLMs are designed to process and integrate information from both textual and visual modalities, offering a versatile framework for handling complex scientific reasoning. However, the distinct nature of data across disciplines introduces unique challenges in model training and application. Appendix C summarizes the key differences in visual features for four scientific subjects within our scope.\nEach subject presents unique challenges in data representation, with mathematical tasks primarily focusing on abstract symbols and formulas, while other subjects, particularly biology, require a mix of detailed real-world imagery"}, {"title": "3.3. MLLM-based Scientific Reasoning", "content": "As shown in Figure 2, current MLLM-based scientific reasoning can generally be divided into the following five paradigms, which progressively enhance the reasoning capabilities of MLLMs, ultimately moving towards AGI."}, {"title": "Data Integration.", "content": "One of the primary strengths of MLLMs is their ability to integrate multimodal data from various scientific domains. For example, in physics, models can combine textual descriptions of a problem, such as Newton's second law, with visual representations like force diagrams. The model can then reason about how different forces interact and predict motion (Barman et al., 2025; Sato, 2024). Similarly, in chemistry, MLLMs can combine chemical equations with 3D molecular structures, offering deeper insights into reaction mechanisms (Guo et al., 2023; Zhang et al., 2024a). This integrated approach allows MLLMs to handle intricate, often disjointed, data sources to generate coherent scientific explanations.\nThe ability to integrate and synthesize multimodal information enables the MLLM to solve complex problems more effectively. However, challenges arise when the visual data does not perfectly align with the textual explanation, potentially leading to misinterpretations (Lu et al., 2023; Zhang et al., 2025; Zhuang et al., 2024)."}, {"title": "Knowledge Retrieval.", "content": "A significant aspect of scientific reasoning is knowledge retrieval. In fields like physics and chemistry, the vast amount of scientific knowledge available - such as established theories, laws, or empirical data - can be overwhelming. Knowledge retrieval helps MLLMs access external knowledge bases, databases, and scientific literature to supplement their reasoning. For instance, when solving a chemistry problem, an MLLM could retrieve data"}, {"title": "Contextual Understanding.", "content": "Contextual understanding in scientific reasoning involves understanding not only the literal data presented but also the broader context in which it is used. MLLMs are capable of this by combining visual data, such as molecular structures in chemistry, with textual descriptions of chemical properties. This allows them to reason about potential interactions between molecules in a way that goes beyond simple matching (Horawalavithana et al., 2023; Liu et al., 2025a). Wang et al. (2024b) leverage Chain-of-Thought rationale as teaching signals to train small models to perform reasoning in complicated scenarios.\nThis contextual capability is crucial in fields like biology, where visual images of biological processes must be linked with underlying theories to make accurate predictions. However, this capability can be limited when the model fails to integrate textual and visual information effectively, leading to errors in its reasoning (Li & Tang, 2024)."}, {"title": "Pattern Recognition.", "content": "In scientific reasoning, pattern recognition is a crucial skill that MLLMs excel at. MLLMs can detect patterns across different modalities, whether they are geometric in mathematics or experimental in chemistry. For instance, in biology, MLLMs can recognize cellular structures in images and relate them to known biological processes described in text, such as identifying mitochondria and correlating their function with energy production (Kraus et al., 2024; Luu & Buehler, 2023). Additionally, an example of pattern recognition in mathematics could involve an MLLM matching visual representations of geometric figures with algebraic equations to find solutions to geometry problems (Mouselinos et al., 2024). This capability enhances the model's ability to understand complex systems across disciplines, including identifying patterns in large datasets that might be too intricate for manual analysis.\nThis skill allows MLLMs to be highly effective in analyzing multistep reasoning problems, which are often required in scientific disciplines (Qiao et al., 2024; Yan et al., 2024b)."}, {"title": "Simulation and Hypothesis Testing.", "content": "MLLMs also possess the ability to perform simulation and hypothesis testing, a fundamental part of scientific reasoning (Qi et al., 2023). For example, in physics, MLLMs can simulate the effect of various forces on an object, predict outcomes, and validate those predictions against real-world data or experiments (Gao et al., 2024a; Melko & Carrasquilla, 2024; Yu et al., 2024a). This capacity allows MLLMs to conduct scientific inquiries in a manner akin to human researchers, testing hypotheses and refining conclusions. In biology, given a diagram of an ecological system, an MLLM can hypothesize how a change in one species' population might impact the entire ecosystem, testing these hypotheses by comparing them to real-world ecological data (Morera, 2024).\nDespite these strengths, hypothesis testing is constrained by the quality and quantity of available data, which in some scientific domains remains insufficient or incomplete. This limits the generalizability and reliability of MLLMs in tasks requiring deep, multistep reasoning (Xiong et al., 2024a)."}, {"title": "4. Challenges", "content": "Even though MLLMs show substantial promise in solving scientific reasoning tasks, significant challenges remain. Based on the inherent characteristics of scientific reasoning - the need for multi-step inference and precise speculation, while ensuring transparency and ethicality - we further propose the following five key challenges (Figure 3)."}, {"title": "Data Diversity.", "content": "Another challenge is the diversity of data across different scientific domains (summary of multi-domain scientific datasets can be seen in Appendix D). While mathematics is rich in textual data, such as equations and proofs, the availability of high-quality visual data is more limited (He et al., 2024a; Liu et al., 2024c; Qiao et al., 2024; Sun et al., 2024a). In contrast, fields like chemistry and biology benefit from abundant visual data, such as molecular structures and microscopic images, but the corresponding textual descriptions may not always provide the depth required for comprehensive reasoning (Alampara et al., 2024; Hocky, 2024). Without sufficient high-quality data for all modalities, the model's ability to generalize across domains is compromised."}, {"title": "Reasoning Depth.", "content": "MLLMs frequently struggle with tasks that require deep, multi-step reasoning, especially when abstract concepts are involved. In mathematics, for example, solving a theorem involves a series of logical steps that must be followed precisely (Chen et al., 2023b). In physics, simulating complex systems, such as thermodynamics or"}, {"title": "Error Propagation.", "content": "Error propagation is another significant challenge in multimodal reasoning. Errors in one modality, such as a misinterpreted graph or an unclear image, can propagate throughout the reasoning process, leading to incorrect conclusions (Li et al., 2024b;1; Yan et al., 2024b). For example, in a physics problem involving force vectors, an error in interpreting the vector diagram could lead to an incorrect calculation of the net force, which would then affect subsequent steps in the solution process (Jaiswal et al., 2024). The risk of error propagation is particularly high when models are tasked with handling complex, multi-step problems across multiple modalities. In particular, the impact of error propagation is especially acute in fields like physics and chemistry, where the accuracy of one step can influence the entire solution process. Small errors in initial data interpretation can lead to significant discrepancies in the final outcome (Li et al., 2024c; Xu et al., 2024a)."}, {"title": "Role of Hallucinations.", "content": "One of the most complex challenges in leveraging MLLMs for scientific reasoning is determining whether hallucinations, the generation of information not grounded in the input data or knowledge base, are inherently harmful or potentially beneficial (Bai et al., 2024b; Liu et al., 2024b). While hallucinations are widely regarded as detrimental in factual tasks, their role in scientific reasoning is nuanced, particularly when considering"}, {"title": "Ethical and Interpretability Issues.", "content": "Ethical concerns and model interpretability are major challenges when deploying MLLMs in high-stakes scientific domains, such as medical research or chemical engineering. MLLMs often lack transparency, making it difficult for users to understand how the model arrived at a particular conclusion (AlSaad et al., 2024). Furthermore, ethical concerns arise when MLLMs are used to make decisions that could have significant consequences, such as in medical diagnoses or environmental impact assessments (Rahman et al., 2024). In biology and medicine, the potential for biased reasoning in MLLMs, especially when trained on unbalanced datasets, could lead to harmful or misleading conclusions (Stureborg et al., 2024; Wang et al., 2024e). An MLLM trained on biased medical data could fail to recognize critical symptoms in under-represented populations, leading to erroneous diagnoses or treatment recommendations (Flores et al., 2024; Jones et al., 2024; Norori et al., 2021)."}, {"title": "5. Discussion: What Next?", "content": "Eight prospects for the future of MLLMs in the field of multimodal scientific reasoning. We base our core expectation on developing unified scientific MLLMs, and further elaborate our prospects from four high-level aspects: input side, output side, environments interact with itself, and internal reasoning schemes.\nBuilding on the challenges outlined in Section 4, it is evident that while MLLMs hold great promise in advancing scientific reasoning, targeted solutions must be developed to address the limitations. In this section, we explore eight key"}, {"title": "The Necessity of Unified Scientific MLLMs.", "content": "Although many domain-specific models have achieved remarkable performance in specialized scientific fields, exploring unified scientific MLLMs remains a critical pursuit (Taylor et al., 2022). Domain-specific models are optimized for particular areas (summary of scientific MLLMs can be seen in Appendix E), but they often lack the ability to integrate knowledge across disciplines (Shi et al., 2024a; Wang et al., 2023b). In contrast, a unified MLLM could facilitate interdisciplinary reasoning, leveraging connections between fields to tackle complex problems that require holistic understanding, such as climate change modeling (Nguyen et al., 2023) or biomedical research (Wang et al., 2023a).\nFor example, a unified scientific MLLM could simultaneously analyze chemical reaction pathways and their biological implications, enabling breakthroughs in drug discovery (Guan & Wang, 2024; Oniani et al., 2024). Similarly, it could integrate physics-based simulations with mathematical optimization to design more efficient renewable energy systems (Gao et al., 2024b; Xu et al., 2024d)."}, {"title": "Improving Multimodal Datasets.", "content": "A critical step in advancing MLLMs' capabilities is the improvement of multimodal datasets (Bayoudh et al., 2022; Gadre et al., 2024; Rahate et al., 2022). Current datasets often lack the richness and variety required to train models effectively across disciplines. For instance, in chemistry, existing datasets may focus heavily on molecular structures without providing sufficient textual descriptions of reaction mechanisms (Cao et al., 2023b). Similarly, in biology, while there are abundant images of anatomical structures, these are often not paired with detailed descriptions of biological processes (Tang et al., 2023; Zhang et al., 2024g). By creating multimodal datasets that include both high-quality images and comprehensive textual descriptions across all domains, the model can better learn to correlate visual features with their corresponding scientific explanations (Albalak et al., 2024; Muennighoff et al., 2023; Yu et al., 2024b).\nFor example, in physics, datasets that combine experimental setups with corresponding theoretical explanations could help improve a model's understanding of underlying principles, such as energy conservation or force interactions. This integration would facilitate a more robust training process, ensuring that models can handle a wider range of scientific reasoning tasks. As a concrete suggestion, developing domain-specific multimodal datasets that cover not only the subject but also different teaching contexts (e.g., beginner vs. advanced materials) would help MLLMs generalize across varying levels of complexity (Shi et al., 2023)."}, {"title": "Integrating Expert Knowledge and Explainability.", "content": "In-"}, {"title": "Interactive Feedback Systems.", "content": "Another powerful strategy involves the development of interactive feedback systems, which would allow MLLMs to engage with users dynamically, iterating on their answers based on user input or feedback (Abramson et al., 2022; Shtarbanov et al., 2023). This interactive feature would not only enable models to adjust their reasoning during the problem-solving process but also allow them to ask clarifying questions, improving the overall user experience and enhancing the model's output.\nFor example, in biology, a researcher could input a biological query related to an ecological model and receive initial results from the model. If the results are unclear or ambiguous, the researcher could provide feedback to guide the model toward more accurate predictions or interpretations. This back-and-forth interaction would provide a mechanism for error correction and refinement, ensuring that the model's outputs align more closely with expert understanding (Pan et al., 2023; Wu et al., 2023b)."}, {"title": "Agent-based Collaboration.", "content": "A promising avenue for future development is agent-based collaboration, which involves the integration of multiple specialized agents working together to solve complex scientific problems (Guo et al., 2024b; Wang et al., 2024c; Xi et al., 2023). Each agent could be tailored to handle specific scientific tasks, such as mathematical reasoning, chemical reaction prediction, or biological system analysis. These agents could communicate and collaborate with each other to cross-check information, validate hypotheses, and combine knowledge from their respective domains (Chen et al., 2023a; Hao et al., 2023).\nFor instance, in a physics problem involving both mechanics and electromagnetism, an agent focused on classical mechanics could collaborate with an agent specialized in electromagnetism to deliver a comprehensive solution that accounts for the interactions between mechanical forces and electromagnetic fields. The agents would share insights, identify potential errors, and improve each other's reasoning in a cooperative manner. By building a system where"}, {"title": "Evolving Reasoning Schemes.", "content": "Current reasoning architectures in MLLMs remain constrained by opaque, monolithic designs that limit adaptability to diverse scientific domains (Besta et al., 2025). Existing paradigms of Reasoning Large Models (RLMs) bifurcate into implicit RLMs (e.g., QwQ (Qwen, 2024b)), where reasoning is embedded in model weights as a black box, and explicit RLMs (e.g., LLaMA-Berry (Zhang et al., 2024b) & o1 (Jaech et al., 2024)), which deploy structured reasoning strategies like Monte Carlo Tree Search (MCTS) or Beam Search with modular components. While explicit methods enable stepwise evaluation and refinement, their reliance on fixed templates and proprietary training schemes hinders reproducibility and domain-specific customization.\nTo advance scientific reasoning, future MLLMs should integrate three innovations: (i) dynamic reasoning structures (e.g., nested graphs) that adapt to multimodal inputs; (ii) process-based supervision with stepwise uncertainty metrics (e.g., token-level entropy) to refine domain-specific reasoning paths; and (iii) open-source, composable toolkits for hybrid training (i.e., Supervised Fine-Tuning + Reinforcement Learning phases) that decouple policy/value models, enabling collaborative, cost-efficient optimization across scientific disciplines (Besta et al., 2025)."}, {"title": "6. Alternative Views", "content": "While this paper advocates for leveraging MLLMs to advance scientific reasoning, it is important to acknowledge and address alternative perspectives that question the feasibility, necessity, or effectiveness of this paradigm."}, {"title": "6.1. Domain-Specific Models as a Superior Alternative", "content": "One argument suggests that highly specialized, domain-specific models tailored to individual scientific disciplines may outperform general-purpose MLLMs in reasoning tasks, as indicated in Figure 5(a). Proponents of this view highlight that scientific reasoning often requires deep domain expertise, nuanced understanding, and customized data processing pipelines that are difficult to replicate in generalized multimodal architectures (Barman et al., 2025; Zhang et al., 2024d). For example, domain-specific models like AlphaFold for protein structure prediction (Jumper et al., 2021) or symbolic computation tools for solving mathematical problems (Lu et al., 2021a; Mirzadeh et al., 2024) excel precisely because of their narrow focus.\nCounterargument. While domain-specific models have demonstrated remarkable success in narrow applications,"}, {"title": "6.2. Risks of Over-reliance on MLLMS", "content": "Another valid concern is the potential over-reliance on MLLMs, which could exacerbate issues such as hallucination and lack of explainability, as shown in Figure 5(b). Critics argue that MLLMs, while powerful, are prone to generating plausible-sounding but incorrect or unsubstantiated outputs. This risk is particularly concerning in scientific reasoning, where accuracy and rigor are paramount (Bai et al., 2024b). Additionally, the black-box nature of these models makes it difficult for researchers to validate their reasoning processes or trust their conclusions, which could hinder their adoption in critical scientific applications (Cambria et al., 2024; Dang et al., 2024b; Rodis et al., 2024).\nCounterargument. These concerns are valid and underscore the need for a cautious and measured approach to MLLM adoption. However, rather than dismissing MLLMs outright, these issues highlight areas for improvement. For example, integrating explainability mechanisms, such as visual attention maps (Chefer et al., 2021; Dehimi & Tolba, 2024) or rationale generation (Hu & Yu, 2024; Wu et al., 2024a), can enhance transparency. Additionally, hybrid models that combine MLLMs with symbolic reasoning (Li et al., 2024a; Zhou et al., 2024a) or expert systems (Guan et al., 2024; Niu et al., 2024) can mitigate risks of hallucination while maintaining the strengths of multimodal reasoning. Finally, iterative feedback loops and human-in-the-loop"}, {"title": "7. Conclusion", "content": "This paper aims to emphasize the transformative potential of MLLMs in advancing scientific reasoning across diverse domains, including mathematics, physics, chemistry, and biology. Our key position is that MLLMs represent a significant step forward in enabling more comprehensive and accurate reasoning about scientific phenomena, bridging gaps between different types of data and reasoning methods. To support this stance, we reviewed the current state of MLLM applications in scientific reasoning, outlined key challenges, and proposed actionable insights for future progress.\nOur objective is to raise awareness of the potential for MLLMs to reshape scientific reasoning and provide a foundation for future research in this space. By proposing a structured research roadmap and highlighting areas for innovation, we aim to guide the development of MLLMs in ways that can enhance generalization and multimodal integration across scientific fields, moving toward achieving AGI."}, {"title": "Impact Statement", "content": "This position paper seeks to redefine the role of MLLMs in advancing scientific reasoning, advocating for their transformative potential across domains such as mathematics, physics, chemistry, and biology. By integrating diverse modalities, MLLMs present a unique opportunity to overcome limitations in current reasoning frameworks, enabling richer, more comprehensive analytical capabilities. Our vision outlines a future where scientific discovery is accelerated through the synergistic application of MLLMs, offering enhanced precision, adaptability, and scalability.\nWhile our primary focus is on advancing academic research and methodological innovation, we also anticipate meaningful societal impacts, such as improved problem-solving approaches in education, healthcare, and other knowledge-intensive sectors. Importantly, we emphasize the ethical imperatives of leveraging MLLMs responsibly, ensuring transparency, fairness, and interpretability in their applications to scientific reasoning. Although no immediate risks are evident, we recognize the need for continuous monitoring of societal implications as MLLMs become increasingly integrated into critical decision-making processes. This paper aims to inspire both researchers and practitioners to embrace this interdisciplinary frontier, fostering collaboration and innovation toward achieving AGI."}, {"title": "A. Formulation of Scientific Reasoning Task", "content": "Mathematically, the scientific reasoning process can be modeled as an optimization task over a multimodal knowledge graph $G = (V, E)$, where $V$ denotes nodes (concepts, entities, or data points) and $E$ represents edges (relationships or interactions). Let $X_m$ represent the modality-specific input data, including mandatory modalities such as textual descriptions $X_t$ and visual representations $X_v$, as well as optional modalities like numerical data $X_n$ or other specialized inputs $X_o$. The goal is to predict or infer target outputs $Y$ based on a reasoning function $f_\\theta$, parameterized by $\\theta$, over $G$:\n$Y = f_\\theta(G, X_m) = f_\\theta(V, E, X_t, X_v, X_n, X_o)$.\nMathematics: Consider solving a geometry problem where $X_t$ provides the problem description, $X_v$ includes the geometric diagram, and $X_n$ optionally contains measurements or coordinates. The reasoning function $f_\\theta$ integrates these inputs to infer the solution, such as identifying the area of a triangle.\nPhysics: In a physics experiment, $X_t$ describes the theoretical background, $X_v$ presents the experimental setup image, and $X_n$ includes sensor data such as velocity or temperature measurements. The function $f_\\theta$ predicts the outcome or validates a hypothesis.\nChemistry: A multimodal analysis of a chemical reaction could include $X_t$ for the reaction mechanism, $X_v$ for molecular structure visualizations, and $X_o$ for spectroscopic data. The model predicts reaction yield or product properties.\nBiology: When studying gene expression, $X_t$ describes the biological context, $X_v$ contains microscope images, and $X_n$ optionally includes numerical gene expression levels. The reasoning function predicts gene interactions or cellular behavior.\nThese examples illustrate how MLLMs can handle diverse inputs, integrating mandatory and optional modalities to perform complex scientific reasoning tasks."}, {"title": "B. Four Phases of Research Roadmap", "content": "MLLMs have seen significant advancements in recent years, positioning their reasoning capabilities as a pivotal element on the pathway to achieving Artificial General Intelligence (AGI) (Jin et al., 2024a; Sun et al., 2023; Wang et al., 2024h;\nWei et al., 2024; Yan et al., 2024a;c). However, realizing AGI requires navigating a structured roadmap characterized by progressively complex reasoning tasks. This section outlines the Four Phases of Research Roadmap, each delineated by unique data requirements, reasoning mechanisms, generalization abilities, and impact. Table 1 provides a comparative overview of these phases."}, {"title": "B.1. Phase 1: Broad Knowledge and Recognition", "content": "In this phase, MLLMs prioritize high diversity and low specificity in data and knowledge. Tasks involve integrating vast and diverse datasets, emphasizing retrieval and alignment mechanisms. For example, MLLMs excel in synthesizing encyclopedic knowledge, aligning visual inputs (e.g., diagrams) with textual descriptions, and providing domain-specific insights. The generalization is limited to specific domains, resulting in low-impact applications like data retrieval and integration."}, {"title": "B.2. Phase 2: Analogical Reasoning and Generalization", "content": "This stage emphasizes medium diversity and specificity in data, leveraging contextual understanding to enable relational and analogical reasoning. For instance, MLLMs may draw analogies between chemical reaction pathways and electrical circuits, enhancing interdisciplinary insights. The models exhibit medium-level generalization across domains, allowing for moderate complexity tasks like explaining scientific phenomena using cross-domain analogies."}, {"title": "B.3. Phase 3: Insightful Inference", "content": "As reasoning tasks grow in complexity, MLLMs in this phase focus on low diversity but high specificity datasets. Predictive reasoning mechanisms are central, enabling context-specific inferences. For example, a model might predict the behavior of a physical system under certain constraints or optimize complex processes like material design. These capabilities lead to high-impact applications, including scientific optimization and inferential problem-solving."}, {"title": "B.4. Phase 4: Creative Hypothesis Generation", "content": "The final phase demands both high diversity and high creativity in data. Generative reasoning mechanisms empower MLLMs to propose innovative solutions and simulate hypotheses. For instance, models might design novel molecules for drug discovery or hypothesize ecological models for sustainable ecosystems. This phase represents very high-impact applications, bridging the gap between scientific discovery and innovation."}, {"title": "B.5. Summary", "content": "In summary, the Four Phases of Research Roadmap reflect the increasing complexity and potential of MLLMs in scientific reasoning. While current MLLMs have demonstrated impressive capabilities, they remain far from achieving AGI (Fei et al., 2022; Feng et al., 2024; Mumuni & Mumuni, 2025; Wang, 2024). The community must continue to explore advanced reasoning abilities, fostering collaboration and innovation along this roadmap to address the challenges of AGI-driven scientific reasoning."}, {"title": "C. Data Differences among Four Domains", "content": "The reasoning capabilities of MLLMs make them particularly well-suited for processing heterogeneous multimodal data (Li et al., 2024f;h; Pattnayak et al., 2024). By integrating and analyzing diverse data formats such as text, images, and structured information, MLLMs enable more comprehensive insights across various scientific disciplines. This section highlights the unique data characteristics of four domains: mathematics, physics, chemistry, and biology, as summarized in Table 2."}, {"title": "C.1. Mathematics: Structured Abstraction", "content": "Mathematical data is characterized by its symbolic equations, graphs, and geometric figures. These data types are highly structured and abstract, requiring precise interpretation and manipulation. Visual features such as coordinate axes and geometric shapes often complement formal textual elements like equations and proofs. The integration of these modalities enables MLLMs to solve complex mathematical problems and support theorem proving."}, {"title": "C.2. Physics: Real-world Dynamics", "content": "Physics data encompasses diagrams (e.g., vector and circuit diagrams), graphs, and descriptions of real-world phenomena. Its data structure reflects system dynamics and real-world applications, combining descriptive text with visual representations like force vectors or particle motion. MLLMs leverage these multimodal inputs to model physical systems and predict outcomes under varying conditions."}, {"title": "C.3. Chemistry: Molecular and Symbolic", "content": "Chemistry relies heavily on molecular structures, reaction pathways, and the periodic table"}]}