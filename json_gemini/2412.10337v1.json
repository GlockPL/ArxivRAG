{"title": "Generative AI in Medicine", "authors": ["Divya Shanmugam", "Monica Agrawal", "Rajiv Movva", "Irene Y. Chen", "Marzyeh Ghassemi", "Maia Jacobs", "Emma Pierson"], "abstract": "The increased capabilities of generative AI have dramatically expanded its possible use cases in medicine. We provide a comprehensive overview of generative AI use cases for clinicians, patients, clinical trial organizers, researchers, and trainees. We then discuss the many challenges including maintaining privacy and security, improving transparency and interpretability, upholding equity, and rigorously evaluating models which must be overcome to realize this potential, and the open research directions they give rise to.", "sections": [{"title": "1. Introduction", "content": "Excitement about the promise of generative AI in medicine has inspired an explosion of new applications. Generative models have the potential to change how care is delivered (1-5), the roles and responsibilities of care providers (6, 7), and the communication pathways between patients and providers (8, 9). Further upstream, generative models have shown promise in improving scientific discovery in medicine (through both clinical trials (10, 11) and observational research (12, 13)) and facilitating medical education (8, 14). These developments are a direct result of technical advances in generative AI, which have drastically increased the ability to generate realistic language and images, and raise important questions about how to integrate generative models into medicine.\nGenerative AI is the latest in a series of technical advances that have driven major shifts in medicine. Past significant advances include the adoption of electronic health records (EHRs); the integration of robotics into telesurgeries (15); and the incorporation of predictive models and continuous monitoring as foundational infrastructure for new diagnostic tools (16, 17). But the introduction of new technologies into health settings inevitably introduces new challenges to overcome. For instance, the introduction of EHRs led to increases in data privacy concerns and data security breaches (18, 19). And while the introduction of EHRs has led to significant reductions in medical errors and improvements in medical guideline adherence overall (20), they have also introduced other types of errors (21). Similarly, continuous monitoring devices in healthcare settings have resulted in pervasive alert fatigue (22). Overall, the integration of technologies into medicine requires an iterative design process which addresses pitfalls and amplifies benefits (23).\nSo, too, with generative AI. As generative models become a leading area of research and deployment in medicine, we provide a comprehensive review of the new applications they enable and the new challenges they create, with a particular focus on how users could interact with generative models. We first provide a brief overview of generative AI, detailing salient types of generative AI and how they fit into the broader landscape of machine learning in medicine. We next discuss the myriad use cases for generative AI in medicine, organized by potential users: clinicians (\u00a72.1), patients (\u00a72.2), trial organizers (\u00a72.3), researchers (\u00a72.4), and trainees (\u00a72.5). We then highlight the challenges (\u00a73) that must be addressed to realize this potential and safely deploy generative models (including ensuring informed consent, protecting privacy, and improving transparency, among many other considerations) and discuss future directions for research throughout."}, {"title": "1.1. Background on Generative Al", "content": "Generative modeling is a fundamental AI paradigm which stands in contrast to predictive modeling (also called discriminative modeling): predictive models are given an input and seek to predict its label but do not attempt to model the input, whereas generative models do seek to model the input. For example, while a predictive model might be given a clinical note (the input) and try to predict whether the note indicates the presence of cancer (the label), a generative model would aim to model the distribution of clinical note text itself. The fact that generative models are trained to model the entire data distribution affords them the powerful ability to generate new data: for example, to write new clinical notes.\nThe basic generative modeling paradigm far predates the current surge of interest in generative AI. For example, classical generative modeling methods such as Markov chains have been used to model sequences of words for decades (24), and in theory could be used"}, {"title": "2. Use cases for generative Al in medicine", "content": "The use cases for generative AI in medicine are numerous . We organize our discussion around key constituents in patient care: clinicians, patients, clinical trial organizers, researchers, and trainees. Within each role, we highlight core responsibilities that can be transformed by the introduction of generative AI."}, {"title": "2.1. Clinicians", "content": "Generative models have the potential to improve clinicians' ability to provide care in multiple ways: by assisting with writing and documentation (reducing administrative burden and physician burnout, which are major concerns (54)); assisting with diagnosis; retrieving patient data; and supporting evidence-based medicine. Each use case suggests that generative models can act as a useful tool for delivering care personalized to patient needs.\nAssistance in writing The amount of documentation in the electronic health record is a leading cause of physician burnout (55). Outside of their shifts, clinicians frequently spend"}, {"title": "Increasing Patient Engagement", "content": "Increased patient engagement can enable patients to better understand their own health conditions and care plan. This engagement can also lead to an increase in patient-reported outcomes (e.g., self-tracking and sharing of symptom burden); this in turn can enable clinicians to better understand their patients' conditions in between visits (88). One approach to increased patient engagement is the use of patient portals; however, utilization of patient portals remains low (89). Given their potential, there have been several long-running suggestions for how to increase utility of patient portals that are now more feasible with generative AI (90-92). As an example, clinical notes contain valuable information for patients but were not written with patients as the intended audience: they are filled with jargon, and patients cite the difficulty of medical jargon as a major barrier to comprehension (93). Recent work has explored using generative models to translate clinical notes into patient-friendly language and visualizations, with the opportunity to personalize to information needs of patients and how they want that information presented (4, 5, 94). The opportunity of patient-friendly text simplification extends past clinical notes alone to other facets of health literacy, e.g., medical literature and patient consent forms (95, 96)."}, {"title": "2.3. Trial Organizers", "content": "Clinical trials provide critical evidence to update and improve clinical practice. Conducting these trials, however, remains challenging: only 20% of clinical trials in the United States complete within the planned timeframe (97), and of those that do, only a small fraction are published (98, 99). The difficulty of clinical trial design is in part due to the complexity of interaction and documentation involved; trials can fail due to incorrectly designed protocols, insufficient participant registration, or high patient dropout (100, 101). Generative interfaces present the potential to rework key components of this pipeline.\nProtocol Design Clinical trial design begins with the creation of a protocol, which collates existing research, study aims, and regulatory requirements into concrete steps detailing how the trial will proceed. Protocol creation requires significant manual effort (102), and existing work has illustrated the value in using generative models (specifically, large language models) to expedite the process (10, 11, 102-105). Several works center on the generation and evaluation of exclusion and inclusion criteria (106, 103, 10, 105), while others propose the use of large language models to retrieve relevant past clinical trials to inform the construction of a new protocol (11, 102). (104) employs large language models to evaluate protocols for bias automatically, while (10) uses large language models to generate trial inclusion and exclusion criteria based on details of the setup expressed in natural language. Together, the literature thus far highlights the potential for generative interfaces to reduce the time required to construct a successful protocol.\nParticipant Recruitment & Retention Equipped with a protocol, clinical trial designers must recruit a sufficient number of participants to conduct the trial. Generative interfaces can be used to identify suitable trial participants by parsing both the criteria and patient history (107-110). Early results suggest that large language models can reduce the number of eligibility criteria a clinician must manually check to assess eligibility by 90% (107) and reduce the time it takes to assess eligibility by 42% (109).\nAs the trial progresses, patient dropout can threaten its validity and success. Patients drop out of clinical trials for a multitude of reasons, one of which is poor communication"}, {"title": "2.4. Researchers", "content": "Designing a useful medical study is a time-consuming process. Researchers comb through large bodies of literature, across multiple disciplines, to identify open questions and understand the status quo in different application areas. Later stages of research, including dataset construction, hypothesis generation, and code generation are no easier. Here, we highlight how generative models can help alleviate significant manual effort at each step.\nLiterature review Efforts to collate existing literature into a coherent research question precede any effort to execute the study. Large language models have been shown to be a promising tool for problem generation through automated systematic literature reviews (12, 116). Here, a generative interface can allow a researcher to automatically assemble a clinical review by querying thousands of clinical abstracts, substantially reducing the effort required to perform a systematic review. (12) demonstrate how a popular large language model (GPT-4) can identify relevant papers at 91% accuracy compared to human evaluation, with the ability to justify the inclusion and exclusion of particular papers.\nDataset construction Generative AI can improve the quality, quantity, and diversity of datasets in medicine (117, 13, 118). To produce such datasets, generative models can be used in two ways: to generate completely synthetic data, or to extract structured information from existing unstructured data.\nUsing generative models to create synthetic data has shown promise in compensating for gaps in existing datasets (13, 119, 120). (119) show that synthetically generated images can be used to improve a machine learning model's ability to detect COVID-19. Beyond improvements to accuracy, (13) illustrated how augmenting training data using generative models can improve the fairness of the resulting diagnostic classifier. These findings hold in the context of natural language; (120) demonstrate how diagnostic classifiers trained on generated text perform comparably to those trained on real datasets of the same size, suggesting that synthetic data is a promising approach to addressing data limitations.\nGenerative AI can also be used to extract structured information from semi-structured data or to label existing data, across both natural language and imaging. Research on health equity, for example, relies on structured fields describing patient demographics to assess the severity of health disparities. Large language models can be used to extract demographic data from unstructured text (e.g. clinical notes) (121), thus enabling comparisons of health outcomes between demographic groups. Similarly, several generative AI tools have also been developed to measure morphological features from large cohorts of histopathology images using natural language prompts (122-124). Generative models can also be used to alleviate the burden of data annotations by providing synthetic labels (i.e. predictions of"}, {"title": "Hypothesis generation", "content": "Given a dataset, generative models can be used to surface hypotheses (127-130). (127) examine the use of generative models to produce natural language hypotheses (i.e. \"customers tend to buy shoes that match the color of their shirt\"). They find that the resulting hypotheses confirm expected relationships, provide new insights, and outperforms supervised baselines. (128) frame the discovery of drug-specific side effects as a task for a generative model; given patient feedback for different drugs, the generative model is tasked with describing differences between drug-specific patient feedback in natural language.\nCode generation Generative interfaces can also be used to write code based on natural language prompts, which could lower the barrier for researchers to perform quantitative analysis of large-scale datasets (131). (131) demonstrate that GPT-4 is capable of autonomously producing code to train models for disease screening and diagnosis. Collaboration with a code assistant has been shown to improve programming productivity (132), and could help facilitate quantitative analysis of increasingly large observational health datasets."}, {"title": "2.5. Trainees", "content": "Generative interfaces are already in widespread use by medical trainees (133). The rapid uptake of these tools among trainees suggests the potential for generative interfaces to significantly transform medical education. Two promising applications are the use of generative interfaces to create practice clinical scenarios and provide feedback that targets student-specific areas for improvement.\nCase creation Designing realistic clinical scenarios to test understanding is a critical yet difficult task. Those in charge of clinical curriculum design could use large language models to generate compelling multiple choice questions, as (134) have demonstrated in the context of surgical education. Doing so could also address the lack of diversity in clinical vignettes (135), and allow the generation of problems that better reflect patient populations trainees are likely to interact with (14, 136, 137). (14), for example, develop a tool to use large language models to produce 30 distinct cases in under an hour (including manual human review). Simulated patients could also be used to simulate real-world interaction. For example, the process of collecting patient history could be taught through a generative interface, in which a large language model responds to a medical student's requests for information based on a synthetic patient profile. (138) have shown that such a set-up is well-received by medical students, and that more than 97% of the generated answers were deemed clinically plausible. Each of these uses cases presents an opportunity to reduce the resources required to train medical students to deliver care.\nProviding personalized feedback Generative interfaces can also provide tailored feedback to students (139). (139) show that large language models can provide students with more coherent, process-oriented feedback compared to human instructors, while retaining high agreement with human-generated feedback. There is significant opportunity to apply these findings in medicine; for example, one could use large language models to provide feedback"}, {"title": "3. Challenges and directions for future work", "content": "Fully realizing the opportunities to apply generative AI in healthcare requires significant progress on a number of challenges we describe below. Generative AI interfaces are far from perfect, and we are only beginning to understand the impacts of such interfaces on clinical decision-making. We have already seen examples of the potential harms such interfaces have caused that warrant attention. For example, (70) demonstrate how large language models fail to follow diagnostic guidelines up to 36% of the time in an evaluation across realistic patient cases. Below, we enumerate challenges we foresee as critical to address as the intersection between generative interfaces and healthcare evolves, and discuss future directions for research throughout."}, {"title": "3.1. Ensuring informed consent", "content": "Informed consent is a foundational principle of medical ethics which states that a patient must have access to sufficient information about a medical procedure (including risks, benefits, and alternatives) (142-145). Achieving informed consent when using AI models raises new challenges which are a topic of active discussion (146): for example, how do we provide patients with comprehensive, accurate, and understandable information about complex models whose behavior is not fully understood even by their own creators (let alone the clinicians using them)? How do we ensure patients are consenting to the use of their data if it is used in model training? These issues similarly apply to generative models, which also raise new challenges (147, 148). For example, when asked for their concerns about the use of generative AI models to transcribe and summarize patient-clinician conversations, providers expressed concerns about whether patients could meaningfully consent to the collection of this data (147). Similarly, the use of generative models in chatbots that interact with patients raises new concerns about informed consent (148). When chatbots and other generative AI tools are implemented in care practices, patients need to be given the option to decline the use of the models in their care and the use of their data. Patients must be provided with clear information that they are interacting with a chatbot, who the chatbot's creators are, and the uses and limitations of the technology.\nContrasting with these concerns, generative models also show promise for improving the informed consent process (149) by making consent forms easier to understand. A study comparing LLM-generated consent forms to those created by five surgeons for six common medical procedures found that the LLM-created forms were more readable and accurate than those created by surgeons. In this way, LLMs can help advance equity in"}, {"title": "3.2. Maintaining privacy and security", "content": "The use of generative models in medicine raises substantial privacy and security challenges (153), given the sensitivity and legal protections of medical data. One challenge is that generative models perform best (and are more likely to generalize) when trained on large, multi-institutional datasets, raising the question of how to share data across multiple institutions in a privacy-preserving way. Technical approaches like federated learning (154-156) offer one approach to this, although recent work has indicated that privacy violations are still possible in this setting (157-159). The creation of large de-identified datasets which can be securely shared with researchers (160, 161) is also an important catalyst for generative model research which institutions and policymakers should facilitate.\nAfter training generative models, a second challenge is deploying models trained on sensitive data in a secure and private way. Past work has demonstrated that generative models can leak sensitive data by memorizing their training datasets and revealing private data in response to adversarially crafted prompts (162-166). Past work also suggests that these problems may grow worse as models continue to scale because larger models possess greater capacity to memorize the training data (164). Mitigating these challenges remains an active area of research which is essential for safely deploying models trained on sensitive health data.\nFinally, and more optimistically, generative AI also holds potential for sharing data in a more privacy-preserving way, via generation of synthetic datasets which mimic properties of a real dataset while preserving patient privacy (167-169) (see \u00a72.4 for further discussion of synthetic datasets). For example, (167) demonstrate how synthetic patient records produced by a generative model can be substituted for real data at no loss of performance, with significant improvements to patient privacy."}, {"title": "3.3. Improving transparency and interpretability", "content": "Modern AI models are opaque for a number of reasons, and generative models are no exception. A first major challenge is a lack of transparency: basic details of generative models are often not disclosed, including training data, training methods, model architecture, capabilities, limitations, and risks (170). Lack of transparency causes several harms (170): it makes it more challenging for policymakers to regulate models; for users to assess when they will perform reliably; and for researchers to innovate on them. Consolidation around a small number of closed models risks heightening the lack of transparency (26). The sensitivity of health datasets, which often cannot be publicly released, also makes achieving transparency more challenging. A 2023 review of widely used generative models scored them on 100 granular transparency indicators and found they averaged only 37 out of 100 (170), though the average score had improved to 58 out of 100 when the review was conducted in May 2024 (171), suggesting that transparency can be improved and that systematic reviews"}, {"title": "3.4. Mitigating hallucinations", "content": "Recent work has shown that generative models sometimes output medical information that is incorrect (184) or hallucinated (185, 186). Hallucinated outputs in high-stakes medical settings can be dangerous: for example, they can harm patients without clinician access who rely on LLM-generated outputs for medical advice. Other work shows that LLM outputs can be hard to understand or non-actionable (187), which, while not directly harmful, may undermine widespread usability, especially for underserved patients.\nOne promising approach to reducing generative models' propensity to hallucinate is retrieval-augmented generation (RAG). As discussed above (\u00a72.1), RAG integrates traditional approaches towards search and information retrieval into generative models: specifically, by retrieving information from a verified knowledge base to guide the text a language"}, {"title": "3.5. Designing usable interfaces", "content": "Pioneers in human-computer interaction have called generative AI \"the first new interaction model in more than 60 years\" (193). When interacting with generative AI, users are now able to tell the computer their desired intent (e.g. create a summary of melanoma for patients that includes symptoms, treatment options, and management strategies), rather than the exact actions they want the computer to take (194). Thus, generative AI interactions can be efficient and low-burden (195), and offer a new way to design and develop novel health interventions (196). However, this new interaction paradigm brings usability challenges that have yet to be addressed. Numerous studies have shown that creating accurate and useful prompts for a generative AI platform is difficult for end users (197-201). Once a prompt is provided, end users then face the additional challenge of interpreting and evaluating the output (200, 202). As we have seen with previous AI technologies, when end-users are unable to accurately evaluate the output of a model, they can become overreliant or make erroneous decisions (203-206). To address these usability challenges, (207) recommend adopting user experience principles to guide the design of these systems. More work is needed to establish best practices for both the design and end-user evaluations of generative AI systems.\nAI tools often face many obstacles to widespread adoption (208-211) leading to limited health impact (212, 213). Given similarities of generative interfaces with prior AI tools, we expect similar challenges to arise. First, healthcare professionals may be hesitant or skeptical about new generative AI interfaces, making them resistant to change. In studies which simulated clinical settings with patients, research has found that provider experience levels (214, 215), interface style (216), and time pressure (216) may all affect adoption likelihood. Second, training and education are crucial to ensuring that healthcare professionals can best leverage these new technologies, which can be costly and time-consuming. Exposure through formal education or prior experience with similar AI interfaces can make healthcare professionals more comfortable with AI tools, leading to a higher rate in adoption (217). Educating users on the strengths and weaknesses of commonly used generative interfaces has been shown to improve qualities of human-AI collaboration including accuracy (218) and reliability (219), and we expect these findings to hold true in medicine. Lastly, deployment of generative interfaces may require an initial investment in cost and resource allocation. While preliminary studies have shown that generative interfaces can save time e.g., initial estimates show that it may save nurses around 30 seconds per generated message (220) - the potentially large upfront cost remains a key concern to active adoption."}, {"title": "3.6. Centering equity", "content": "Abundant previous work has demonstrated how biases in medical datasets can propagate into AI models (221-242). It is thus unsurprising that the use of generative models in medicine creates several equity-related challenges (243). Research indicates that larger models do not, on their own, necessarily resolve equity concerns; indeed, larger models have been shown to exhibit more covert forms of bias (i.e. prejudice against certain dialects) compared to smaller counterparts (244). (243) perform the largest-scale health equity evaluation of large language models to date, highlighting the complexity of equity challenges and the necessity of careful, multi-dimensional evaluations to identify and mitigate them.\nA first challenge is mitigating stereotypes and bias in generated text. Like human clinicians (245), LLM-generated text has been shown to display medical stereotypes (246, 247). For example, (246) finds that when GPT-4 is asked to provide clinical vignettes about sarcoidosis, it generates vignettes about Black patients 97% of the time, exaggerating the true population skew. Due to these embedded biases, if patients specify their demographics when asking questions to LLM chatbots, there is a risk that the LLM will overestimate the impact of race, gender, etc. in its response. Similarly, when generating new clinical vignettes (e.g., for use in medical education), LLMs may over-index on demographic correlations (246), which would skew the knowledge of medical trainees if generated vignettes are widely used (248). It is likely that these issues can be mitigated through improved prompting and careful auditing of generated text. However, LLM stereotypes remain a key risk, both because they can be hard to detect, and because even small effect sizes can cause significant harm if the models are used at scale. Further work is necessary to better document such patterns, to properly inform users about them, and to develop mitigating strategies.\nA second equity-related challenge is disparities in patient awareness of, and willingness to use, generative interfaces. Recent surveys show that awareness of LLMs positively correlates with formal education level and household income (249). Moreover, LLMs are more accessible to \"tech-savvy\" users (250), since using them requires a fast internet connection, intuition around how to best phrase prompts, etc. These factors raise the possibility that generative interfaces may create larger benefits for already-privileged patients who have fewer barriers to health access. (251, 252). To mitigate this risk, we need to study the factors underlying generative interface literacy (253) and ensure they become broadly accessible.\nHowever, generative models also open important new health-equity-related opportunities (121, 254). (121) describes several such use cases for generative models: detecting human biases (e.g., from clinical notes); creating structured equity-relevant databases from unstructured text; and improving equity of access to health information. To identify such equity-related opportunities, it is imperative to focus on equity from the very beginning of a project, at the problem selection stage (226, 255)."}, {"title": "3.7. Performing real-world evaluation", "content": "In order to reason about the real-world efficacy of generative models, we need fine-grained, real-world evaluations. Recent work has highlighted how evaluating clinical generative models on the basis of diagnosis alone overestimates their efficacy (70). Specifically, (70) highlight the importance of quantifying the extent to which generative models fail to adhere to treatment guidelines, or are sensitive to the order in which information is presented to them; measures of these types of behavior are important towards reasoning about the impact"}, {"title": "3.8. Clarifying accountability", "content": "The introduction of generative AI in healthcare raises important questions about who should be responsible for potential harms and regulation. Errors from generative models are inevitable, as they are with humans, but it remains unclear whether responsibility lies with the healthcare provider, the AI system developer, or the institution implementing the technology. Uncertainty surrounding liability is a key concern for healthcare providers who interact with generative interfaces (267), and regulation should be designed to reduce this uncertainty. Possible paths forward range from holding the \"manufacturer\" (i.e. the model developer) completely accountable for model errors to distributing responsibility across providers, hospitals, and model developers (268).\nThe question of accountability is further complicated by concerns about over-reliance. If healthcare professionals rely too heavily on generative AI tools to make accurate decisions, while model developers simultaneously rely on healthcare professionals to carefully vet those decisions, accountability may be lost. Healthcare professionals who rely too heavily on generative AI tools may not only find it difficult to make accurate decisions without them, but also be unable to detect errors when the generative AI tools are incorrect. Behavioral changes in response to the integration of AI tools are well-established (269, 270) and relate to the autonomy of decision-making, a key factor in determining liability (271). In the education space, researchers have found that students who have access to generative AI tools outperform a control group, but once the generative AI tools are removed, they perform worse (269). Similar studies have found that humans can also inherit biases from Al even when access to tools has been removed (270). These findings have important implications for the deployment of generative models in medicine, and suggest the importance of research"}, {"title": "4. Conclusion", "content": "Those witnessing the explosion of interest in generative models in healthcare might justly feel both excitement and trepidation. On the one hand, increased model capabilities enable many use cases benefiting clinicians, patients, trial organizers, researchers, and trainees, with the potential to transform healthcare. But realizing this potential in high-stakes healthcare settings will require addressing numerous challenges from centering equity, to protecting consent, to rigorously evaluating models to bridge the gap between medical generative models in theory and in practice. The history of technical advances in medicine suggests that we will not be able to anticipate all the impacts of generative models hospitals today are still adapting to the transition to EHRS, 15 years after their widespread introduction and that humility is warranted. But, in the face of this uncertainty, the research directions we outline offer a roadmap for addressing generative AI's shortcomings, and realizing its potential, in order to provide better healthcare for all."}]}