{"title": "ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models", "authors": ["Xiyuan Zhou", "Huan Zhao", "Yuheng Cheng", "Yuji Cao", "Gaoqi Liang", "Guolong Liu", "Junhua Zhao"], "abstract": "In response to the urgent demand for grid stability and the complex challenges posed by renewable energy integration and electricity market dynamics, the power sector increasingly seeks innovative technological solutions. In this context, large language models (LLMs) have become a key technology to improve efficiency and promote intelligent progress in the power sector with their excellent natural language processing, logical reasoning, and generalization capabilities. Despite their potential, the absence of a performance evaluation benchmark for LLM in the power sector has limited the effective application of these technologies. Addressing this gap, our study introduces \"ElecBench\", an evaluation benchmark of LLMs within the power sector. ElecBench aims to overcome the shortcomings of existing evaluation benchmarks by providing comprehensive coverage of sector- specific scenarios, deepening the testing of professional knowledge, and enhancing decision-making precision. The framework categorizes scenarios into general knowledge and professional business, further divided into six core performance metrics: factuality, logicality, stability, security, fairness, and expressiveness, and is subdivided into 24 sub-metrics, offering profound insights into the capabilities and limitations of LLM applications in the power sector. To ensure transparency, we have made the complete test set public, evaluating the performance of eight LLMs across various scenarios and metrics. ElecBench aspires to serve as the standard benchmark for LLM applications in the power sector, supporting continuous updates of scenarios, metrics, and models to drive technological progress and application.", "sections": [{"title": "1. Introduction", "content": "The power sector is undergoing significant transforma- tion due to the increasing impacts of global climate change and rising demand for renewable energy sources [1]. This transformation aims to establish a new power system char- acterized by efficiency, cleanliness, flexibility, and intelli- gence, aiming to comprehensively optimize power produc- tion, transmission, consumption, and storage. Power dis- patch, a critical component of power system operation, relies on advanced devices and algorithms to balance real-time supply and demand, ensuring stability and economic effi- ciency of power supply. However, as the complexity of the power system increases and renewable energy sources are extensively integrated, traditional power dispatch businesses are facing severe challenges, particularly in addressing the economical and safe dispatch of massive equipment and the intermittency and uncertainty of renewable sources such as wind and solar energy [2].\nWhen facing these problems, traditional power system optimization methods, such as linear programming, nonlin- ear programming, and mixed-integer programming, though capable of providing system operation solutions, demand extensive computational resources and struggle to adapt to real-time supply and demand changes [3]. Due to no modeling and fast solving characteristics, data-driven meth- ods such as deep learning and reinforcement learning have demonstrated substantial potential in load forecasting, sys- tem operation, fault detection, and so on. Despite signif- icant achievements in improving prediction accuracy and operation efficiency, these technologies still meet limitations by data quality, algorithm complexity, model generalization ability, and model interpretability [4][5].\nLarge Language Models (LLMs) have emerged as a novel Artificial Intelligence (AI) technology, offering new possibilities for managing power systems and addressing these limitations. LLMs can process and analyze large-scale, complex datasets, significantly enhancing the accuracy of electricity demand and renewable energy output forecasts [6]. By utilizing historical data and real-time information, these models optimize energy allocation and respond more swiftly and accurately to system changes. Importantly, the high flexibility and adaptability of LLMs enable the imple- mentation of real-time optimization and adjustment strate- gies under changing system and environmental conditions, which is crucial for improving the operational efficiency and reliability of power systems.\nDue to the significant difference in the ability and scope of various LLMs, constructing and implementing precise evaluation benchmarks is crucial for accurately measuring LLMs' performance. The evaluation of LLMs has relied on benchmark tests from the traditional Natural Language Pro- cessing (NLP) domain, such as the General Language Un- derstanding Evaluation benchmark (GLUE), SuperGLUE, and Stanford Question Answering Dataset (SQUAD), to evaluate the model performance of single ability[7][8][9]. Recently, with the development of LLM's general abilities, a series of specialized evaluation benchmarks focusing pri- marily on the model's general abilities have emerged, such as Holistic Evaluation of Language Models (HELM), AlpacaE- val, and Xiezhi [10][11][12]. These evaluation frameworks play a key role in advancing LLM technology by critically examining the comprehensive model performance in terms of accuracy, flexibility, applicability, and so on, across a comprehensive set of tasks, datasets, and performance met- rics. However, these frameworks exhibit significant limita- tions in domain-specific applications, such as power dis- patch.\nFor power dispatch, the demands placed on LLMs extend from basic language understanding and generation capa- bilities to the resolution of complex professional issues, handling of advanced technical knowledge, and execution of specific engineering tasks. Despite the existing evaluation frameworks covering areas such as code generation, soft- ware engineering, and commonsense planning, these frame- works significantly fall short in meeting the specific needs of electrical engineering [13]. The shortcomings are mainly in two aspects: firstly, the existing evaluation frameworks do not offer a benchmark that adequately covers the unique requirements and business scenarios of the power sector; secondly, the system inadequately addresses numerical data from in-depth business scenarios, particularly lacking in handling sector-specific simulation data, a deficiency that becomes obvious when evaluating model performance in power system operation tasks.\nThis study addresses the challenges faced in evaluating LLMs within the power system operation domain by propos- ing an innovative evaluation framework. This new frame- work aims to deeply analyze the model's general and spe- cific performance related to power system operation tasks. By simulating detailed operation scenarios and their sub- scenarios, this framework can accurately evaluate the LLMs' capability to handle power system operation problems, en- suring the comprehensiveness and depth of the evaluation. The main contributions of this paper are:\n1.  Our study introduces a pioneering evaluation frame- work specifically designed for the power sector, inte- grating six fundamental metrics: factuality, logicality, stability, fairness, security, and expressiveness, and elaborated through twenty-four secondary metrics. To the best of our knowledge, this is the first compre- hensive evaluation framework for the thorough and precise evaluation of LLMs in the power sector.\n2.  To address the substantial gap between evaluation metrics and available testing data, we have developed a method for generating testing data and created a specialized dataset. This dataset is designed specifi- cally for evaluating LLMs against the challenges of power system operations, allowing for more precise assessment and optimization of LLMs in the power sector. Additionally, this dataset has been made pub- licly available to facilitate further research in this area.\n3.  The empirical tests are conducted to evaluate sev- eral leading-edge LLMs' performance thoroughly. The test results demonstrate the current application effectiveness of LLMs in the electrical domain and provide valuable insights and strategies for the future development and practical application of models."}, {"title": "2. General Metrics", "content": "The remaining sections of this paper are as follows: Section 2 presents a taxonomy of the evaluation framework along with a detailed description of each specific metric. Section 3 outlines the generation of test datasets and the cor- responding evaluation procedures. In Section 4, we present an experimental comparison of the performance of various LLMs within the power system operation. Finally, Section 5 discusses potential opportunities and challenges, as well as future directions for research."}, {"title": "2.1. Taxonomy Overview", "content": "Current evaluation frameworks for LLMs, such as HELM, AlpacaEval, and Xiezhi, have established a foundation for evaluating the general capabilities of models but fall short in evaluating the specific requirements of power system oper- ations [10][11][12], in particular not adequately simulating and tackling the highly specialized and technical challenges. This gap in the evaluation methodology limits our ability to precisely measure the effectiveness and potential of LLMs within real-world power system operations. Consequently, there's an urgent necessity for the development of more refined and sector-specific evaluation frameworks that are customized to the unique needs of power system operation, ensuring LLMs can contribute to the efficient and reliable operation of power systems.\nAddressing the deficiencies in current evaluation frame- works, we have developed a comprehensive set of metrics to evaluate LLMs' functionalities in power system opera- tions. This new evaluation framework targets LLM's direct impact on various aspects of power system operations. Each metric is crafted to uncover the specific contributions and implications of LLMs within operational scenarios, ensuring that these models meet the rigorous demands of the power sector and effectively support its operational efficiency and reliability. By applying these metrics, we aim to deliver a precise and practical evaluation of LLMs' performance, fostering their informed integration and optimization in the power sector. The specific metrics are as follows:\n\u2022  Factuality: Factuality ensures that the conclusions derived from model outputs are both authentic and accurate. This means the data is not fabricated and the conclusions correctly represent the real condi- tions, which is essential for reliable decision-making in power system operations.\n\u2022  Logicality: Logicality focuses on the accuracy of logical reasoning and the reliability of the information used in that process. It specifically addresses issues that require logical reasoning, ensuring that the rea- soning is based on credible sources and follows a logical path. This focus on the process distinguishes logicality from factuality, which evaluates the truth- fulness and accuracy of the conclusions themselves.\n\u2022  Stability: The stability metric evaluates the ability of LLMs to maintain similar outputs in changing environments, ensuring operational continuity and re- liability.\n\u2022  Fairness: The fairness metric evaluates LLMs' ability to maintain equity in all decisions and avoid discrim- ination.\n\u2022  Security: The security metric emphasizes that model applications should not compromise the security of the power system under any circumstances, which is key to ensuring operational security.\n\u2022  Expressiveness: Expressiveness in LLMs measures their ability to clearly express diverse perspectives, adapt to user needs, and use precise terminology in the power sector.\nBy evaluating these key capabilities, we can more accu- rately evaluate the real-world application potential of LLMs, ensuring their effective integration and utilization in sup- porting the efficient and safe operation of power systems. This comprehensive set of metrics, designed to address the specific challenges and requirements of power system oper- ations, marks a significant advancement in our methodology for evaluating LLMs, offering a pathway toward their more effective deployment in critical infrastructure sectors."}, {"title": "2.2. Factuality", "content": "In the power sector application field, the deployment of LLM requires a firm guarantee of factuality, which mainly includes the authenticity and reliability of the content gen- erated by the model. Factuality is particularly important in the power sector because misinformation can have signif- icant consequences, impacting decision-making processes, and operational efficiency, and even causing serious system failures [14]. In addition, it should be noted that the scope of factuality focuses on the authenticity of the content and explicitly excludes factors related to expression style, infor- mation security aspects, and logical derivation details. These factuality metrics are divided into five secondary metrics based on key characteristics to refine further. These aspects will be explained with specific metrics in the following subsections. For additional test set examples, see Appendix \u0392.1."}, {"title": "2.2.1. Misinformation", "content": "Misinformation refers to inaccurate information pro- duced by LLMs, which, although not intended to deceive users, can negatively impact decision-making and opera- tional efficiency [15]. The importance of addressing mis- information lies in its potential to disrupt operations and compromise system reliability. Therefore, evaluating LLMs' ability to identify and mitigate misinformation is crucial to ensure the provision of accurate and reliable information for critical tasks such as power dispatching and fault diagno- sis. An effective evaluation framework should test LLMs' capabilities in maintaining information integrity across var- ious scenarios, including updating knowledge bases and correcting errors, to prevent misinformation from adversely affecting the power sector."}, {"title": "2.2.2. Math Calculation", "content": "In the domain of power system operation, the numerical computation capabilities of LLMs are crucial for handling complex calculations involved in various power sector sce- narios. These include but are not limited to load forecast- ing, power flow analysis, resource optimization, and fault diagnosis, where the advanced computational abilities of LLMs directly impact the stability, reliability, and opera- tional efficiency of power systems [16]. By accurately and swiftly processing vast amounts of data, LLMs provide scientific decision support for real-time monitoring, early warning responses, and long-term planning of power sys- tems. Therefore, thoroughly evaluating and continuously enhancing the computational performance of LLMs in such business scenarios is fundamental to ensuring the efficient and safe operation of power systems, while also serving as a key driver for technological innovation and development within the power sector."}, {"title": "2.2.3. Hallucination", "content": "Hallucinations refer to content generated by LLMs that diverge from existing knowledge bases, representing entirely fictional concepts or technologies [17]. Unlike misinfor- mation, which can arise from incorrect data identification or reasoning flaws, hallucinations involve the model creat- ing content without any factual basis (see Sec 2.2.1). This distinction is crucial, especially in the context of power system operations, where decisions based on hallucinated information could lead to inappropriate actions or responses, thereby increasing system risk and severely impacting the security of operations. Therefore, it is vital to ensure that LLMs avoid generating answers based on fictional concepts or technologies and can identify and prevent the generation of such fictitious content. Developing effective evaluation methods to test whether models can safeguard against the production of hallucinated content is essential for ensuring the accuracy and reliability of applications within the power sector, necessitating a high degree of authenticity and trust- worthiness in model outputs."}, {"title": "2.2.4. Sycophancy", "content": "Sycophancy refers to the models' tendency to align their outputs with users' preferences at the expense of factual accuracy [18][19]. In the power sector, where precise in- formation is critical for operational maintenance and fault diagnosis, such tendencies can lead to detrimental decisions. Sycophancy can be divided into authority-led sycophancy, where models may favour users' claimed expertise over objective facts, and opinion-accommodating sycophancy, which involves pandering to users' personal or emotional bi- ases. Addressing these behaviours is essential for maintain- ing the integrity and reliability of LLM-generated content, ensuring decisions in the power sector are based on accurate and objective information."}, {"title": "2.2.5. Miscalibration", "content": "Miscalibration evaluates the accuracy of LLMs in gaug- ing their confidence levels in responses, aimed at ensur- ing the model's confidence is neither excessively high nor inadequately low [20][21]. This is particularly pivotal for key operational tasks within power systems, such as load forecasting or resource allocation, where an appropriate level of confidence ensures that model recommendations align with actual system data and constraints. These tests are designed to assess the model's confidence level in its outputs, ensuring that the model's confidence is neither too high nor too low. The accuracy of confidence levels is essential for evaluating the factuality of the model's recom- mendations. These tests are crucial for verifying the self- calibration capabilities of LLMs in critical decision-making processes, thereby maintaining accuracy and trustworthiness in practical applications."}, {"title": "2.3. Logicality", "content": "In the application of LLMs within the power system op- eration, logicality refers to the rigour of the overall reasoning process behind the generated content. This entails ensuring that the model's logic of generated content is accurate and based on precise, timely, and non-misleading information [22][23]. Logicality is crucial in the power sector as accurate reasoning directly impacts decision-making, and operational efficiency, and can prevent serious system failures. In eval- uating logicality, our focus is on the logical rigour of the entire reasoning process and the accuracy of the information it relies upon, rather than directly on the accuracy of the conclusions.\nLogicality is divided into five secondary metrics based on specific characteristics. This evaluation includes an eval- uation of LLM's capabilities in reasoning consistency, causal logic analysis, problem decomposition capability, informa- tion reliability, and source validity. Through this compre- hensive evaluation, we ensure that LLMs maintain logical accuracy and precision in addressing complex issues in the power sector, thereby enhancing their application value in this sector. For additional test set examples, see Appendix \u0392.2."}, {"title": "2.3.1. Reasoning Consistency", "content": "Reasoning consistency measures the model's ability to maintain logical coherence across deductive reasoning (from general principles to specific conclusions) and inductive rea- soning (from specific instances to general principles). In the power system operation, where decision-making relies on complex data analysis and reasoning, such consistency en- sures accurate problem-solving and decision support in tasks like load forecasting, risk assessment, and troubleshooting. Logical inconsistencies can mislead conclusions, affecting the security and efficiency of power system operations. Evaluating LLMs' reasoning stability and reliability through targeted questions enables an understanding of their logi- cal capabilities and ensures their practical applications are founded on solid reasoning."}, {"title": "2.3.2. Causal Logic Analysis", "content": "Causal logic accuracy evaluates LLMs in the power sector on their ability to identify and explain causal relation- ships between events, essential for tasks like fault diagnosis and grid accident analysis. By testing direct and indirect causal scenarios, it evaluates the model's proficiency in complex physical interactions, ensuring its contributions to power system operations rely on accurate causal understand- ing, thereby enhancing operational security, and reliability."}, {"title": "2.3.3. Problem Decomposition Capability", "content": "Evaluating LLMs' problem decomposition capability focuses on the model's ability to break down complex prob- lems into simpler, more manageable parts and logically process each segment. This capability is particularly crucial for tasks such as operational maintenance, troubleshooting, and decision-making within power systems. For instance, in addressing a grid failure, a model must swiftly identify the fault location, analyze the cause, predict its impact, and for- mulate steps to restore normal operations. This necessitates the model's comprehensive understanding and analysis of each subtask and its logical organization of action sequences. Therefore, designing tests to evaluate LLMs' ability to ef- fectively decompose, structure, and prioritize tasks in the face of complex power system issues is essential. These evaluations ensure that the support and recommendations provided by LLMs in real-world power system operations are grounded in solid logical and structured analysis, thereby enhancing the efficiency and reliability of power system operations."}, {"title": "2.3.4. Information Reliability", "content": "Information reliability focuses on the accuracy and trust- worthiness of the data a model uses for its logical reasoning. This differs from misinformation (see Sec 2.2.1, which con- cerns the correctness of the results; information reliability pertains specifically to the reliability of information used in the reasoning process. This metric is critical for power sector tasks requiring precise and up-to-date information, such as load forecasting and system fault analysis. An effec- tive information reliability evaluation ensures that the data used for model reasoning is relevant to the power sector and verified by authoritative sources. Additionally, given the rapid changes and technological advancements in the power sector, the model must demonstrate the capability to update its knowledge base in a timely manner to accurately reflect the latest industry developments. The model should also be able to identify and exclude potentially misleading or inaccurate information. Considering the complexity of power systems and the potential for multiple interpretations of technical data, this capability is crucial for ensuring scientific decision-making and system security."}, {"title": "2.3.5. Source Validity", "content": "Source validity critically evaluates LLMs in accurately identifying and verifying the origins of reference informa- tion, which is essential for ensuring the high trustworthiness of decision-support data provided by LLMs. In the power system operation, decisions heavily rely on the authenticity and credibility of information sources, necessitating models to adeptly differentiate between real and fabricated sources. It's important to note that source validity focuses on ensuring the reliability and authenticity of data origins, contrasting with hallucination (see Sec 2.2.3, which evaluates the accu- racy of final conclusions based on potentially non-existent or incorrect information. Unlike information reliability (see Sec 2.3.5, which assesses the accuracy and trustworthiness of the content within the model's knowledge base, source validity specifically emphasizes verifying the credibility of information sources. This distinction highlights source va- lidity's critical role in evaluating and confirming the authen- ticity of data, ensuring accurate and reliable decision support in power system operations."}, {"title": "2.4. Stability", "content": "In the evaluation of LLMs for the power sector, the sta- bility metric focuses on evaluating the model's consistency and predictability in response to similar or varied inputs [24][25][26]. This metric does not concern itself with the factuality or fairness of information, but rather concentrates on the consistency of outputs, providing similar responses to comparable questions.\nThe construction logic of the secondary stability metrics follows a progression from words to phrases and then to sentences. The word level includes typo tolerance and data scalability, evaluating the model's ability to handle lexical errors and data format changes. At the phrase level, it evalu- ates semantic stability, focusing on the model's response to text content or logic changes. Finally, at the sentence level, assess the model's ability to simplify and expand contex- tually, measuring the stability of results when reducing or adding information that does not affect the conclusion.\nThis layered evaluation approach ensures a comprehen- sive evaluation of LLM's stability in processing information at different levels, providing a critical evaluation basis for its application in the power sector. For additional test set examples, see Appendix B.3."}, {"title": "2.4.1. Typo Tolerance", "content": "In the context of LLMs in the power sector, typo tol- erance refers to the model's capability to handle variations in regular vocabulary errors. This includes lexical spelling mistakes, stability in specialized terminology substitutions, abbreviations, and syntactic changes. This aspect is crucial for ensuring that the model's performance is not adversely affected by minor inaccuracies in input, reflecting its robust- ness in practical scenarios."}, {"title": "2.4.2. Data Scalability", "content": "Data scalability evaluates the model's ability to maintain information accuracy and consistency when dealing with different data scales and formats. This includes handling variations in data dimensions and forms. This metric is significant for diverse data set applications, ensuring the model's reliable performance across various data represen- tations."}, {"title": "2.4.3. Semantic Stability", "content": "Semantic stability evaluates the model's output stability concerning changes in text content or logic. This encom- passes handling synonymous/paraphrased text changes, al- terations in textual sequence, and logical variations. This metric is key to ensuring that the model's output remains consistent and reliable even when faced with complex or nuanced textual changes."}, {"title": "2.4.4. Simplification Contextual Stability", "content": "Simplification contextual stability evaluates the model's ability to generate invariant responses when presented with inputs that have undergone contextual reduction or abstrac- tion. The core objective is to determine whether the LLM can maintain response consistency when the input's descriptive complexity is minimized. This is particularly relevant in power sector applications where the preciseness of technical communication must not be compromised by the streamlin- ing of input variables. The integrity of an LLM's output in such circumstances is indicative of its underlying compre- hension capabilities, ensuring that essential information is robustly captured and articulated, independent of the input's level of elaboration."}, {"title": "2.4.5. Expansion Contextual Stability", "content": "Expansion contextual stability measures the model's ro- bustness in its output when faced with augmented input. This stability metric tests the LLM's ability to maintain the integrity of its original response even when additional, potentially unrelated content is introduced into the dialogue. For sectors like power systems, where precision and con- sistency in technical communication are imperative, the model must demonstrate an unwavering capacity to provide uniform answers\u2014 irrespective of extraneous information that may accompany the input. This ensures that the model remains anchored to the relevant context and that the quality of the response does not fluctuate with the complexity or breadth of the expanded input."}, {"title": "2.5. Fairness", "content": "In the power sector, a rigorous evaluation of the fairness metric for LLMs focuses on ensuring the model's impar- tiality and justice in processing and answering questions. The fairness metric extends beyond the traditional evaluation of factual accuracy and expressiveness, emphasizing equal and justice treatment for all users and topics within LLM applications [27].\nThis framework introduces secondary categories tailored to the specific needs of the power sector, including oppor- tunity fairness, procedural fairness, and interests fairness. These categories address equal opportunities for users to access power services and participate in the market and fairness in policy implementation and resource distribution. This layered and multi-dimensional evaluation approach en- sures that applying LLMs maintains the balance of interests and rights and promotes the overall health and fairness of the power sector. For additional test set examples, see Appendix B.4."}, {"title": "2.5.1. Pre-operation Fairness", "content": "Pre-operation fairness evaluates the foundational rules and policies that ensure equitable entry conditions for all stakeholders involved in power system operation. This guar- antees that every participant, regardless of size or influence, has fair opportunities to engage effectively within the opera- tional framework of the power system [28][29]. This metric advocates for fair access to resources and opportunities, es- tablishing a fair operational environment essential for build- ing stakeholder trust, ensuring equitable competition, and promoting innovation. These efforts contribute significantly to a balanced and progressive power system operation."}, {"title": "2.5.2. In-process Fairness", "content": "In-process fairness in the power sector focuses on eq- uitable treatment during the ongoing application of policies and procedures. This metric guarantees fairness in executing regulations throughout all stages of power system operations and ensures regulations are enforced fairly. Maintaining consistent regulatory application and unbiased policy en- forcement ensures that all stakeholders, regardless of size or influence, are treated equitably under the same operational conditions."}, {"title": "2.5.3. Post-operation Fairness", "content": "Post-operation Fairness in the power sector focuses on assessing and addressing the outcomes of operational deci- sions to ensure equitable distribution of benefits and burdens across various stakeholder groups, regions, and socioeco- nomic backgrounds after implementation. This metric dif- fers from in-process fairness (see Sec 2.5.1), which ensures fairness during the decision-making and implementation by applying policies and procedures transparently and consis- tently. Post-operation fairness is concerned with correcting imbalances and enhancing the long-term equity of the power sector's outcomes."}, {"title": "2.6. Security", "content": "In the security evaluation of LLMs within the power sector, we have established a tiered set of metrics across three levels: content security, privacy security, and cyberse- curity. This structured, incremental approach is designed to comprehensively evaluate the performance of LLMs against diverse security challenges, ensuring safe and regulation- compliant applications in the power sector.\nContent security, representing the foundational security considerations, ensures that the model's outputs do not pose security risks or breach regulations. Mid-level privacy secu- rity focuses on protecting user data and sensitive information privacy. The highest level, information security, involves the model's ability to counter complex information attacks, safeguarding the overall system's integrity.\nThis layered and progressive evaluation methodology encompasses all security aspects. It thoroughly evaluates the model's performance at different security levels, providing comprehensive security assurance for LLM applications in the power sector. For additional test set examples, see Ap- pendix B.5."}, {"title": "2.6.1. Content Security", "content": "Content security ensures that model outputs do not gen- erate factually correct but potentially harmful content, ad- hering strictly to security, legal, and ethical standards [30]. In power system operations, it is critical to avoid outputs that, while accurate, may contravene ethical or legal norms, as such missteps could lead to severe consequences. The primary goal of content security is to mitigate risks by preventing high-risk operational suggestions and ensuring that all outputs adhere to legal and ethical guidelines. This approach is essential for preventing harmful recommenda- tions and ensuring safe power system operations. It also aligns model outputs with industry regulations, which are crucial for maintaining compliance of LLM applications in the power sector."}, {"title": "2.6.2. Privacy Security", "content": "Privacy security involves protecting sensitive data and personal privacy while handling and responding to queries [31][32]. Privacy security ensures the confidentiality of user data, trade secrets, operational modes, and system configu- rations from being compromised. It encompasses the pro- tection of user and commercial data privacy, safeguarding individual information and business secrets; operational and system configuration information protection, focusing on the security of sensitive operational data of power systems; and critical infrastructure information protection, ensuring the security of detailed information about crucial power infrastructure such as locations, design details, and security measures. The comprehensive consideration of these aspects is vital for ensuring the security and compliance of LLM applications in the power sector and maintaining user trust."}, {"title": "2.6.3. Cybersecurity", "content": "Cybersecurity evaluates the model's resistance to infor- mation attacks, safeguarding the security of power system data and operations [33][34]. Key aspects include defending against jailbreak prompt attacks, prompt injection attacks, and hybrid attacks. Jailbreak prompt attacks involve trick- ing the LLM into bypassing security protocols, potentially evaluating unauthorized system information [35]. Prompt in- jection attacks manipulate the model by injecting malicious commands into the inputs, leading to undesired actions [36]. Hybrid attacks combine various methods, posing a greater threat to the power system's cybersecurity. Ensuring robust cybersecurity in LLMs is vital for protecting critical data and operational integrity in the power sector, enhancing the security and reliability of LLM applications in this field."}, {"title": "2.7. Expressiveness", "content": "In the expressiveness evaluation of LLMs in the power sector, we focus on three key metrics: Comprehensive Ex- pression, Adaptive Expression, and Terminological Preci- sion. This metric ensures that the models demonstrate pro- ficiency in expressing problems from varied perspectives, customizing expressions to meet diverse user preferences, and utilizing precise terminology, thus supporting their ef- fectiveness and reliability within the industry [37]. By as- sessing these dimensions, the metric emphasizes that the models cover a broad spectrum of concepts and viewpoints, adapt their expression to diverse user needs, and maintain precise terminology."}, {"title": "2.7.1. Comprehensive Expression", "content": "Comprehensive expression assesses the model's ability to express ideas incorporating diverse perspectives such as economic, environmental, and technical perspectives. This metric determines how effectively the model can generate insights from these distinct angles, ensuring a well-rounded evaluation of topics within the power sector. Such a compre- hensive approach is essential for fostering deep, informed discussions and generating innovative solutions [38]."}, {"title": "2.7.2. Adaptive Expression", "content": "Adaptive expression measures the model's capability to adapt its responses to the specific needs and themes of different users within the power sector [39]. This metric evaluates how well the model can adjust its approach to ef- fectively communicate with various stakeholders, including engineers, policymakers, and business executives, ensuring the information is relevant and accessible to each user. The model's adaptability is crucial for engaging diverse groups effectively and facilitating clear, purpose-driven answers. This capacity to customize expression improves user experi- ence and optimizes solution development by addressing each user group's unique challenges and priorities."}, {"title": "2.7.3. Terminological Precision", "content": "Terminological precision concentrates on the accuracy and appropriateness of professional terminology used in model responses. This metric evaluates the model's ability to accurately employ domain-specific terminology relevant to the power sector, ensuring the professionalism and technical correctness of the information [40].\nTerminological precision necessitates the correct usage of professional vocabulary in responses, which is pivotal for ensuring accurate information transmission and enhancing the model's credibility in specialized fields. This criterion guarantees that LLMs, in providing responses and advice, accurately utilize professional terminology, thereby improv- ing their efficacy and professional perception in the power sector."}, {"title": "3. Test Set Construction and Model Evaluation", "content": "In the field of NLP research, the construction of test questions typically involves the aggregation and categoriza- tion of existing examinations and practical problems. These questions are often sourced from online public resources, including official standardized test practice questions, uni- versity course-related problems, and reading questions from publications. This method creates a comprehensive test set that spans various subjects and difficulty levels, thereby testing language models' performance across different fields and complexities."}, {"title": "3.1.1. Framework for Test Set Construction", "content": "We have proposed a new methodological approach to address the challenges of constructing test sets in the power sector. This approach is grounded in a deep understanding of the nature of test metrics, dividing them into two major categories: source-based and generation-based. We employ distinct dataset construction strategies for these categories to cater to their specific characteristics and requirements.\nFor source-based metrics, such as factuality, logicality, and stability, we utilize a source-based test set. This dataset collects information from reliable real-world sources, in- cluding professional literature, technical reports, and official statistical data in the power sector. The construction of this dataset type focuses more on the authenticity, timeliness, and professionalism of the information to ensure that the test questions comprehensively cover the core knowledge and practical application scenarios in the power sector.\nThis study constructs a source-based test set by lever- aging both private datasets and public test sets. For the private dataset, we collected literature materials on power systems. This included the latest research papers, industry regulations, and authoritative textbooks. This effort helped us build a comprehensive knowledge base specific to the power sector. In addition, we employed simulation soft- ware to generate a wide range of power system scenarios, such as economic dispatch, operation monitoring, and black start procedures. These simulations are designed to test the LLM's ability to handle realistic operational scenarios in the power sector. Combining a specialized knowledge base and simulated data forms the core of our private dataset. On the other hand, our public test set comprises sections from existing public test sets relevant to the power sector. Using this data, we adopted a mixed approach of manual curation and GPT technology - a dual LLM independent evaluation followed by a manual review process. This methodology enabled us to categorize the test set data into three main scenarios, further divided into four sub-scenarios. We then employed a team of university undergraduates, each with a relevant background in power systems, to meticulously se- lect appropriate content from the specific scenario datasets. These selections were used to construct test questions tai- lored to specific metrics. Finally, we combined GPT-4 and manual intervention to generate and standardize these selec- tions into a formal test set.\nFor generation-based metrics, including hallucination and source validity, typically do not originate from existing datasets as they aim to identify content fabricated by the model without a factual basis. We have constructed datasets based on a generative model to evaluate model performance in these areas effectively. The datasets are designed to check if the LLM might create unfounded or made-up responses. By giving the entirely fictional model scenarios, we can test how well it finds and avoid generating these inventive answers. This is key to ensuring the model stays trustworthy when providing accurate information. In the power sector, assessing LLMs for their capability to recognize and handle fictional content is particularly critical. To facilitate this, we initially use GPT-4 to generate hypothetical concepts or technologies in specific scenarios. Subsequently, we manu- ally verify these concepts through search engine to confirm their fictitious nature. Once confirmed as fictional, we refine these concepts by combining the outputs of GPT-4 with manual efforts, resulting in the creation of standardized test questions. This rigorous process ensures that LLMs can accurately identify and manage fabricated concepts, thereby maintaining their integrity and reliability in critical applica- tions."}, {"title": "3.1.2. Data Sources", "content": "Considering the limited"}]}