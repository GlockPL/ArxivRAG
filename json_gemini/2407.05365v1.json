{"title": "ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models", "authors": ["Xiyuan Zhou", "Huan Zhao", "Yuheng Cheng", "Yuji Cao", "Gaoqi Liang", "Guolong Liu", "Junhua Zhao"], "abstract": "In response to the urgent demand for grid stability and the complex challenges posed by renewable energy integration and electricity market dynamics, the power sector increasingly seeks innovative technological solutions. In this context, large language models (LLMs) have become a key technology to improve efficiency and promote intelligent progress in the power sector with their excellent natural language processing, logical reasoning, and generalization capabilities. Despite their potential, the absence of a performance evaluation benchmark for LLM in the power sector has limited the effective application of these technologies. Addressing this gap, our study introduces \"ElecBench\", an evaluation benchmark of LLMs within the power sector. ElecBench aims to overcome the shortcomings of existing evaluation benchmarks by providing comprehensive coverage of sector-specific scenarios, deepening the testing of professional knowledge, and enhancing decision-making precision. The framework categorizes scenarios into general knowledge and professional business, further divided into six core performance metrics: factuality, logicality, stability, security, fairness, and expressiveness, and is subdivided into 24 sub-metrics, offering profound insights into the capabilities and limitations of LLM applications in the power sector. To ensure transparency, we have made the complete test set public, evaluating the performance of eight LLMs across various scenarios and metrics. ElecBench aspires to serve as the standard benchmark for LLM applications in the power sector, supporting continuous updates of scenarios, metrics, and models to drive technological progress and application.", "sections": [{"title": "1. Introduction", "content": "The power sector is undergoing significant transforma- tion due to the increasing impacts of global climate change and rising demand for renewable energy sources [1]. This transformation aims to establish a new power system char- acterized by efficiency, cleanliness, flexibility, and intelli- gence, aiming to comprehensively optimize power produc- tion, transmission, consumption, and storage. Power dis- patch, a critical component of power system operation, relies on advanced devices and algorithms to balance real-time supply and demand, ensuring stability and economic effi- ciency of power supply. However, as the complexity of the power system increases and renewable energy sources are extensively integrated, traditional power dispatch businesses are facing severe challenges, particularly in addressing the economical and safe dispatch of massive equipment and the intermittency and uncertainty of renewable sources such as wind and solar energy [2].\nWhen facing these problems, traditional power system optimization methods, such as linear programming, nonlin- ear programming, and mixed-integer programming, though capable of providing system operation solutions, demand extensive computational resources and struggle to adapt to real-time supply and demand changes [3]. Due to no modeling and fast solving characteristics, data-driven meth- ods such as deep learning and reinforcement learning have demonstrated substantial potential in load forecasting, sys- tem operation, fault detection, and so on. Despite signif- icant achievements in improving prediction accuracy and operation efficiency, these technologies still meet limitations by data quality, algorithm complexity, model generalization ability, and model interpretability [4][5].\nLarge Language Models (LLMs) have emerged as a novel Artificial Intelligence (AI) technology, offering new possibilities for managing power systems and addressing these limitations. LLMs can process and analyze large-scale, complex datasets, significantly enhancing the accuracy of electricity demand and renewable energy output forecasts [6]. By utilizing historical data and real-time information, these models optimize energy allocation and respond more swiftly and accurately to system changes. Importantly, the high flexibility and adaptability of LLMs enable the imple- mentation of real-time optimization and adjustment strate- gies under changing system and environmental conditions, which is crucial for improving the operational efficiency and reliability of power systems.\nDue to the significant difference in the ability and scope of various LLMs, constructing and implementing precise evaluation benchmarks is crucial for accurately measuring LLMs' performance. The evaluation of LLMs has relied on benchmark tests from the traditional Natural Language Pro- cessing (NLP) domain, such as the General Language Un- derstanding Evaluation benchmark (GLUE), SuperGLUE, and Stanford Question Answering Dataset (SQUAD), to evaluate the model performance of single ability[7][8][9]. Recently, with the development of LLM's general abilities, a series of specialized evaluation benchmarks focusing pri- marily on the model's general abilities have emerged, such as Holistic Evaluation of Language Models (HELM), AlpacaE- val, and Xiezhi [10][11][12]. These evaluation frameworks play a key role in advancing LLM technology by critically examining the comprehensive model performance in terms of accuracy, flexibility, applicability, and so on, across a comprehensive set of tasks, datasets, and performance met- rics. However, these frameworks exhibit significant limita- tions in domain-specific applications, such as power dis- patch.\nFor power dispatch, the demands placed on LLMs extend from basic language understanding and generation capa- bilities to the resolution of complex professional issues, handling of advanced technical knowledge, and execution of specific engineering tasks. Despite the existing evaluation frameworks covering areas such as code generation, soft- ware engineering, and commonsense planning, these frame- works significantly fall short in meeting the specific needs of electrical engineering [13]. The shortcomings are mainly in two aspects: firstly, the existing evaluation frameworks do not offer a benchmark that adequately covers the unique requirements and business scenarios of the power sector; secondly, the system inadequately addresses numerical data from in-depth business scenarios, particularly lacking in handling sector-specific simulation data, a deficiency that becomes obvious when evaluating model performance in power system operation tasks.\nThis study addresses the challenges faced in evaluating LLMs within the power system operation domain by propos- ing an innovative evaluation framework. This new frame- work aims to deeply analyze the model's general and spe- cific performance related to power system operation tasks. By simulating detailed operation scenarios and their sub- scenarios, this framework can accurately evaluate the LLMs' capability to handle power system operation problems, en- suring the comprehensiveness and depth of the evaluation. The main contributions of this paper are:\n1.  Our study introduces a pioneering evaluation frame- work specifically designed for the power sector, inte- grating six fundamental metrics: factuality, logicality, stability, fairness, security, and expressiveness, and elaborated through twenty-four secondary metrics. To the best of our knowledge, this is the first compre- hensive evaluation framework for the thorough and precise evaluation of LLMs in the power sector.\n2.  To address the substantial gap between evaluation metrics and available testing data, we have developed a method for generating testing data and created a specialized dataset. This dataset is designed specifi- cally for evaluating LLMs against the challenges of power system operations, allowing for more precise assessment and optimization of LLMs in the power sector. Additionally, this dataset has been made pub- licly available to facilitate further research in this area.\n3.  The empirical tests are conducted to evaluate sev- eral leading-edge LLMs' performance thoroughly. The test results demonstrate the current application effectiveness of LLMs in the electrical domain and provide valuable insights and strategies for the future development and practical application of models."}, {"title": "2. General Metrics", "content": "The remaining sections of this paper are as follows: Section 2 presents a taxonomy of the evaluation framework along with a detailed description of each specific metric. Section 3 outlines the generation of test datasets and the cor- responding evaluation procedures. In Section 4, we present an experimental comparison of the performance of various LLMs within the power system operation. Finally, Section 5 discusses potential opportunities and challenges, as well as future directions for research."}, {"title": "2.1. Taxonomy Overview", "content": "Current evaluation frameworks for LLMs, such as HELM, AlpacaEval, and Xiezhi, have established a foundation for evaluating the general capabilities of models but fall short in evaluating the specific requirements of power system oper- ations [10][11][12], in particular not adequately simulating and tackling the highly specialized and technical challenges. This gap in the evaluation methodology limits our ability to precisely measure the effectiveness and potential of LLMs within real-world power system operations. Consequently, there's an urgent necessity for the development of more refined and sector-specific evaluation frameworks that are customized to the unique needs of power system operation, ensuring LLMs can contribute to the efficient and reliable operation of power systems.\nAddressing the deficiencies in current evaluation frame- works, we have developed a comprehensive set of metrics to evaluate LLMs' functionalities in power system opera- tions. This new evaluation framework targets LLM's direct impact on various aspects of power system operations. Each metric is crafted to uncover the specific contributions and implications of LLMs within operational scenarios, ensuring that these models meet the rigorous demands of the power sector and effectively support its operational efficiency and reliability. By applying these metrics, we aim to deliver a precise and practical evaluation of LLMs' performance, fostering their informed integration and optimization in the power sector. The specific metrics are as follows:\n\u2022 Factuality: Factuality ensures that the conclusions derived from model outputs are both authentic and accurate. This means the data is not fabricated and the conclusions correctly represent the real condi- tions, which is essential for reliable decision-making in power system operations.\n\u2022 Logicality: Logicality focuses on the accuracy of logical reasoning and the reliability of the information used in that process. It specifically addresses issues that require logical reasoning, ensuring that the rea- soning is based on credible sources and follows a logical path. This focus on the process distinguishes logicality from factuality, which evaluates the truth- fulness and accuracy of the conclusions themselves.\n\u2022 Stability: The stability metric evaluates the ability of LLMs to maintain similar outputs in changing environments, ensuring operational continuity and re- liability.\n\u2022 Fairness: The fairness metric evaluates LLMs' ability to maintain equity in all decisions and avoid discrim- ination.\n\u2022 Security: The security metric emphasizes that model applications should not compromise the security of the power system under any circumstances, which is key to ensuring operational security.\n\u2022 Expressiveness: Expressiveness in LLMs measures their ability to clearly express diverse perspectives, adapt to user needs, and use precise terminology in the power sector.\nBy evaluating these key capabilities, we can more accu- rately evaluate the real-world application potential of LLMs, ensuring their effective integration and utilization in sup- porting the efficient and safe operation of power systems. This comprehensive set of metrics, designed to address the specific challenges and requirements of power system oper- ations, marks a significant advancement in our methodology for evaluating LLMs, offering a pathway toward their more effective deployment in critical infrastructure sectors."}, {"title": "2.2. Factuality", "content": "In the power sector application field, the deployment of LLM requires a firm guarantee of factuality, which mainly includes the authenticity and reliability of the content gen- erated by the model. Factuality is particularly important in the power sector because misinformation can have signif- icant consequences, impacting decision-making processes, and operational efficiency, and even causing serious system failures [14]. In addition, it should be noted that the scope of factuality focuses on the authenticity of the content and explicitly excludes factors related to expression style, infor- mation security aspects, and logical derivation details. These factuality metrics are divided into five secondary metrics based on key characteristics to refine further. These aspects will be explained with specific metrics in the following subsections. For additional test set examples, see Appendix \u0392.1."}, {"title": "2.2.1. Misinformation", "content": "Misinformation refers to inaccurate information pro- duced by LLMs, which, although not intended to deceive users, can negatively impact decision-making and opera- tional efficiency [15]. The importance of addressing mis- information lies in its potential to disrupt operations and compromise system reliability. Therefore, evaluating LLMs' ability to identify and mitigate misinformation is crucial to ensure the provision of accurate and reliable information for critical tasks such as power dispatching and fault diagno- sis. An effective evaluation framework should test LLMs' capabilities in maintaining information integrity across var- ious scenarios, including updating knowledge bases and correcting errors, to prevent misinformation from adversely affecting the power sector."}, {"title": "2.2.2. Math Calculation", "content": "In the domain of power system operation, the numerical computation capabilities of LLMs are crucial for handling complex calculations involved in various power sector sce- narios. These include but are not limited to load forecast- ing, power flow analysis, resource optimization, and fault diagnosis, where the advanced computational abilities of LLMs directly impact the stability, reliability, and opera- tional efficiency of power systems [16]. By accurately and swiftly processing vast amounts of data, LLMs provide scientific decision support for real-time monitoring, early warning responses, and long-term planning of power sys- tems. Therefore, thoroughly evaluating and continuously enhancing the computational performance of LLMs in such business scenarios is fundamental to ensuring the efficient and safe operation of power systems, while also serving as a key driver for technological innovation and development within the power sector."}, {"title": "2.2.3. Hallucination", "content": "Hallucinations refer to content generated by LLMs that diverge from existing knowledge bases, representing entirely fictional concepts or technologies [17]. Unlike misinfor- mation, which can arise from incorrect data identification or reasoning flaws, hallucinations involve the model creat- ing content without any factual basis (see Sec 2.2.1). This distinction is crucial, especially in the context of power system operations, where decisions based on hallucinated information could lead to inappropriate actions or responses, thereby increasing system risk and severely impacting the security of operations. Therefore, it is vital to ensure that LLMs avoid generating answers based on fictional concepts or technologies and can identify and prevent the generation of such fictitious content. Developing effective evaluation methods to test whether models can safeguard against the production of hallucinated content is essential for ensuring the accuracy and reliability of applications within the power sector, necessitating a high degree of authenticity and trust- worthiness in model outputs."}, {"title": "2.2.4. Sycophancy", "content": "Sycophancy refers to the models' tendency to align their outputs with users' preferences at the expense of factual accuracy [18][19]. In the power sector, where precise in- formation is critical for operational maintenance and fault diagnosis, such tendencies can lead to detrimental decisions. Sycophancy can be divided into authority-led sycophancy, where models may favour users' claimed expertise over objective facts, and opinion-accommodating sycophancy, which involves pandering to users' personal or emotional bi- ases. Addressing these behaviours is essential for maintain- ing the integrity and reliability of LLM-generated content, ensuring decisions in the power sector are based on accurate and objective information."}, {"title": "2.2.5. Miscalibration", "content": "Miscalibration evaluates the accuracy of LLMs in gaug- ing their confidence levels in responses, aimed at ensur- ing the model's confidence is neither excessively high nor inadequately low [20][21]. This is particularly pivotal for key operational tasks within power systems, such as load forecasting or resource allocation, where an appropriate level of confidence ensures that model recommendations align with actual system data and constraints. These tests are designed to assess the model's confidence level in its outputs, ensuring that the model's confidence is neither too high nor too low. The accuracy of confidence levels is essential for evaluating the factuality of the model's recom- mendations. These tests are crucial for verifying the self- calibration capabilities of LLMs in critical decision-making processes, thereby maintaining accuracy and trustworthiness in practical applications."}, {"title": "2.3. Logicality", "content": "In the application of LLMs within the power system op- eration, logicality refers to the rigour of the overall reasoning process behind the generated content. This entails ensuring that the model's logic of generated content is accurate and based on precise, timely, and non-misleading information [22][23]. Logicality is crucial in the power sector as accurate reasoning directly impacts decision-making, and operational efficiency, and can prevent serious system failures. In eval- uating logicality, our focus is on the logical rigour of the entire reasoning process and the accuracy of the information it relies upon, rather than directly on the accuracy of the conclusions.\nLogicality is divided into five secondary metrics based on specific characteristics. This evaluation includes an eval- uation of LLM's capabilities in reasoning consistency, causal logic analysis, problem decomposition capability, informa- tion reliability, and source validity. Through this compre- hensive evaluation, we ensure that LLMs maintain logical accuracy and precision in addressing complex issues in the power sector, thereby enhancing their application value in this sector. For additional test set examples, see Appendix \u0392.2."}, {"title": "2.3.1. Reasoning Consistency", "content": "Reasoning consistency measures the model's ability to maintain logical coherence across deductive reasoning (from general principles to specific conclusions) and inductive rea- soning (from specific instances to general principles). In the power system operation, where decision-making relies on complex data analysis and reasoning, such consistency en- sures accurate problem-solving and decision support in tasks like load forecasting, risk assessment, and troubleshooting. Logical inconsistencies can mislead conclusions, affecting the security and efficiency of power system operations. Evaluating LLMs' reasoning stability and reliability through targeted questions enables an understanding of their logi- cal capabilities and ensures their practical applications are founded on solid reasoning."}, {"title": "2.3.2. Causal Logic Analysis", "content": "Causal logic accuracy evaluates LLMs in the power sector on their ability to identify and explain causal relation- ships between events, essential for tasks like fault diagnosis and grid accident analysis. By testing direct and indirect causal scenarios, it evaluates the model's proficiency in complex physical interactions, ensuring its contributions to power system operations rely on accurate causal understand- ing, thereby enhancing operational security, and reliability."}, {"title": "2.3.3. Problem Decomposition Capability", "content": "Evaluating LLMs' problem decomposition capability focuses on the model's ability to break down complex prob- lems into simpler, more manageable parts and logically process each segment. This capability is particularly crucial for tasks such as operational maintenance, troubleshooting, and decision-making within power systems. For instance, in addressing a grid failure, a model must swiftly identify the fault location, analyze the cause, predict its impact, and for- mulate steps to restore normal operations. This necessitates the model's comprehensive understanding and analysis of each subtask and its logical organization of action sequences. Therefore, designing tests to evaluate LLMs' ability to ef- fectively decompose, structure, and prioritize tasks in the face of complex power system issues is essential. These evaluations ensure that the support and recommendations provided by LLMs in real-world power system operations are grounded in solid logical and structured analysis, thereby enhancing the efficiency and reliability of power system operations."}, {"title": "2.3.4. Information Reliability", "content": "Information reliability focuses on the accuracy and trust- worthiness of the data a model uses for its logical reasoning. This differs from misinformation (see Sec 2.2.1, which con- cerns the correctness of the results; information reliability pertains specifically to the reliability of information used in the reasoning process. This metric is critical for power sector tasks requiring precise and up-to-date information, such as load forecasting and system fault analysis. An effec- tive information reliability evaluation ensures that the data used for model reasoning is relevant to the power sector and verified by authoritative sources. Additionally, given the rapid changes and technological advancements in the power sector, the model must demonstrate the capability to update its knowledge base in a timely manner to accurately reflect the latest industry developments. The model should also be able to identify and exclude potentially misleading or inaccurate information. Considering the complexity of power systems and the potential for multiple interpretations of technical data, this capability is crucial for ensuring scientific decision-making and system security."}, {"title": "2.3.5. Source Validity", "content": "Source validity critically evaluates LLMs in accurately identifying and verifying the origins of reference informa- tion, which is essential for ensuring the high trustworthiness of decision-support data provided by LLMs. In the power system operation, decisions heavily rely on the authenticity and credibility of information sources, necessitating models to adeptly differentiate between real and fabricated sources. It's important to note that source validity focuses on ensuring the reliability and authenticity of data origins, contrasting with hallucination (see Sec 2.2.3, which evaluates the accu- racy of final conclusions based on potentially non-existent or incorrect information. Unlike information reliability (see Sec 2.3.5, which assesses the accuracy and trustworthiness of the content within the model's knowledge base, source validity specifically emphasizes verifying the credibility of information sources. This distinction highlights source va- lidity's critical role in evaluating and confirming the authen- ticity of data, ensuring accurate and reliable decision support in power system operations."}, {"title": "2.4. Stability", "content": "In the evaluation of LLMs for the power sector, the sta- bility metric focuses on evaluating the model's consistency and predictability in response to similar or varied inputs [24][25][26]. This metric does not concern itself with the factuality or fairness of information, but rather concentrates on the consistency of outputs, providing similar responses to comparable questions.\nThe construction logic of the secondary stability metrics follows a progression from words to phrases and then to sentences. The word level includes typo tolerance and data scalability, evaluating the model's ability to handle lexical errors and data format changes. At the phrase level, it evalu- ates semantic stability, focusing on the model's response to text content or logic changes. Finally, at the sentence level, assess the model's ability to simplify and expand contex- tually, measuring the stability of results when reducing or adding information that does not affect the conclusion.\nThis layered evaluation approach ensures a comprehen- sive evaluation of LLM's stability in processing information at different levels, providing a critical evaluation basis for its application in the power sector. For additional test set examples, see Appendix B.3."}, {"title": "2.4.1. Typo Tolerance", "content": "In the context of LLMs in the power sector, typo tol- erance refers to the model's capability to handle variations in regular vocabulary errors. This includes lexical spelling mistakes, stability in specialized terminology substitutions, abbreviations, and syntactic changes. This aspect is crucial for ensuring that the model's performance is not adversely affected by minor inaccuracies in input, reflecting its robust- ness in practical scenarios."}, {"title": "2.4.2. Data Scalability", "content": "Data scalability evaluates the model's ability to maintain information accuracy and consistency when dealing with different data scales and formats. This includes handling variations in data dimensions and forms. This metric is significant for diverse data set applications, ensuring the model's reliable performance across various data represen- tations."}, {"title": "2.4.3. Semantic Stability", "content": "Semantic stability evaluates the model's output stability concerning changes in text content or logic. This encom- passes handling synonymous/paraphrased text changes, al- terations in textual sequence, and logical variations. This metric is key to ensuring that the model's output remains consistent and reliable even when faced with complex or nuanced textual changes."}, {"title": "2.4.4. Simplification Contextual Stability", "content": "Simplification contextual stability evaluates the model's ability to generate invariant responses when presented with inputs that have undergone contextual reduction or abstrac- tion. The core objective is to determine whether the LLM can maintain response consistency when the input's descriptive complexity is minimized. This is particularly relevant in power sector applications where the preciseness of technical communication must not be compromised by the streamlin- ing of input variables. The integrity of an LLM's output in such circumstances is indicative of its underlying compre- hension capabilities, ensuring that essential information is robustly captured and articulated, independent of the input's level of elaboration."}, {"title": "2.4.5. Expansion Contextual Stability", "content": "Expansion contextual stability measures the model's ro- bustness in its output when faced with augmented input. This stability metric tests the LLM's ability to maintain the integrity of its original response even when additional, potentially unrelated content is introduced into the dialogue. For sectors like power systems, where precision and con- sistency in technical communication are imperative, the model must demonstrate an unwavering capacity to provide uniform answers  irrespective of extraneous information that may accompany the input. This ensures that the model remains anchored to the relevant context and that the quality of the response does not fluctuate with the complexity or breadth of the expanded input."}, {"title": "2.5. Fairness", "content": "In the power sector, a rigorous evaluation of the fairness metric for LLMs focuses on ensuring the model's impar- tiality and justice in processing and answering questions. The fairness metric extends beyond the traditional evaluation of factual accuracy and expressiveness, emphasizing equal and justice treatment for all users and topics within LLM applications [27].\nThis framework introduces secondary categories tailored to the specific needs of the power sector, including oppor- tunity fairness, procedural fairness, and interests fairness. These categories address equal opportunities for users to access power services and participate in the market and fairness in policy implementation and resource distribution. This layered and multi-dimensional evaluation approach en- sures that applying LLMs maintains the balance of interests and rights and promotes the overall health and fairness of the power sector. For additional test set examples, see Appendix B.4."}, {"title": "2.5.1. Pre-operation Fairness", "content": "Pre-operation fairness evaluates the foundational rules and policies that ensure equitable entry conditions for all stakeholders involved in power system operation. This guar- antees that every participant, regardless of size or influence, has fair opportunities to engage effectively within the opera- tional framework of the power system [28][29]. This metric advocates for fair access to resources and opportunities, es- tablishing a fair operational environment essential for build- ing stakeholder trust, ensuring equitable competition, and promoting innovation. These efforts contribute significantly to a balanced and progressive power system operation."}, {"title": "2.5.2. In-process Fairness", "content": "In-process fairness in the power sector focuses on eq- uitable treatment during the ongoing application of policies and procedures. This metric guarantees fairness in executing regulations throughout all stages of power system operations and ensures regulations are enforced fairly. Maintaining consistent regulatory application and unbiased policy en- forcement ensures that all stakeholders, regardless of size or influence, are treated equitably under the same operational conditions."}, {"title": "2.5.3. Post-operation Fairness", "content": "Post-operation Fairness in the power sector focuses on assessing and addressing the outcomes of operational deci- sions to ensure equitable distribution of benefits and burdens across various stakeholder groups, regions, and socioeco- nomic backgrounds after implementation. This metric dif- fers from in-process fairness (see Sec 2.5.1), which ensures fairness during the decision-making and implementation by applying policies and procedures transparently and consis- tently. Post-operation fairness is concerned with correcting imbalances and enhancing the long-term equity of the power sector's outcomes."}, {"title": "2.6. Security", "content": "In the security evaluation of LLMs within the power sector, we have established a tiered set of metrics across three levels: content security, privacy security, and cyberse- curity. This structured, incremental approach is designed to comprehensively evaluate the performance of LLMs against diverse security challenges, ensuring safe and regulation- compliant applications in the power sector.\nContent security, representing the foundational security considerations, ensures that the model's outputs do not pose security risks or breach regulations. Mid-level privacy secu- rity focuses on protecting user data and sensitive information privacy. The highest level, information security, involves the model's ability to counter complex information attacks, safeguarding the overall system's integrity.\nThis layered and progressive evaluation methodology encompasses all security aspects. It thoroughly evaluates the model's performance at different security levels, providing comprehensive security assurance for LLM applications in the power sector. For additional test set examples, see Ap- pendix B.5."}, {"title": "2.6.1. Content Security", "content": "Content security ensures that model outputs do not gen- erate factually correct but potentially harmful content, ad- hering strictly to security, legal, and ethical standards [30]. In power system operations, it is critical to avoid outputs that, while accurate, may contravene ethical or legal norms, as such missteps could lead to severe consequences. The primary goal of content security is to mitigate risks by preventing high-risk operational suggestions and ensuring that all outputs adhere to legal and ethical guidelines. This approach is essential for preventing harmful recommenda- tions and ensuring safe power system operations. It also aligns model outputs with industry regulations, which are crucial for maintaining compliance of LLM applications in the power sector."}, {"title": "2.6.2. Privacy Security", "content": "Privacy security involves protecting sensitive data and personal privacy while handling and responding to queries [31][32]. Privacy security ensures the confidentiality of user data, trade secrets, operational modes, and system configu- rations from being compromised. It encompasses the pro- tection of user and commercial data privacy, safeguarding individual information and business secrets; operational and system configuration information protection, focusing on the security of sensitive operational data of power systems; and critical infrastructure information protection, ensuring the security of detailed information about crucial power infrastructure such as locations, design details, and security measures. The comprehensive consideration of these aspects is vital for ensuring the security and compliance of LLM applications in the power sector and maintaining user trust."}, {"title": "2.6.3. Cybersecurity", "content": "Cybersecurity evaluates the model's resistance to infor- mation attacks, safeguarding the security of power system data and operations [33][34]. Key aspects include defending against jailbreak prompt attacks, prompt injection attacks, and hybrid attacks. Jailbreak prompt attacks involve trick- ing the LLM into bypassing security protocols, potentially evaluating unauthorized system information [35]. Prompt in- jection attacks manipulate the model by injecting malicious commands into the inputs, leading to undesired actions [36]. Hybrid attacks combine various methods, posing a greater threat to the power system's cybersecurity. Ensuring robust cybersecurity in LLMs is vital for protecting critical data and operational integrity in the power sector, enhancing the security and reliability of LLM applications in this field."}, {"title": "2.7. Expressiveness", "content": "In the expressiveness evaluation of LLMs in the power sector, we focus on three key metrics: Comprehensive Ex- pression, Adaptive Expression, and Terminological Preci- sion. This metric ensures that the models demonstrate pro- ficiency in expressing problems from varied perspectives, customizing expressions to meet diverse user preferences, and utilizing precise terminology, thus supporting their ef- fectiveness and reliability within the industry [37]. By as- sessing these dimensions, the metric emphasizes that the models cover a broad spectrum of concepts and viewpoints, adapt their expression to diverse user needs, and maintain precise terminology."}, {"title": "2.7.1. Comprehensive Expression", "content": "Comprehensive expression assesses the model's ability to express ideas incorporating diverse perspectives such as economic, environmental, and technical perspectives. This metric determines how effectively the model can generate insights from these distinct angles, ensuring a well-rounded evaluation of topics within the power sector. Such a compre- hensive approach is essential for fostering deep, informed discussions and generating innovative solutions [38]."}, {"title": "2.7.2. Adaptive Expression", "content": "Adaptive expression measures the model's capability to adapt its responses to the specific needs and themes of different users within the power sector [39]. This metric evaluates how well the model can adjust its approach to ef- fectively communicate with various stakeholders, including engineers, policymakers, and business executives, ensuring the information is relevant and accessible to each user. The model's adaptability is crucial for engaging diverse groups effectively and facilitating clear, purpose-driven answers. This capacity to customize expression improves user experi- ence and optimizes solution development by addressing each user group's unique challenges and priorities."}, {"title": "2.7.3. Terminological Precision", "content": "Terminological precision concentrates on the accuracy and appropriateness of professional terminology used in model responses. This metric evaluates the model's ability to accurately employ domain-specific terminology relevant to the power sector, ensuring the professionalism and technical correctness of the information [40].\nTerminological precision necessitates the correct usage of professional vocabulary in responses, which is pivotal for ensuring accurate information transmission and enhancing the model's credibility in specialized fields. This criterion guarantees that LLMs, in providing responses and advice, accurately utilize professional terminology, thereby improv- ing their efficacy and professional perception in the power sector."}, {"title": "3. Test Set Construction and Model Evaluation", "content": ""}, {"title": "3.1. Test Set Construction", "content": "In the field of NLP research, the construction of test questions typically involves the aggregation and categoriza- tion of existing examinations and practical problems. These questions are often sourced from online public resources, including official standardized test practice questions, uni- versity course-related problems, and reading questions from publications. This method creates a comprehensive test set that spans various subjects and difficulty levels, thereby testing language models' performance across different fields and complexities.\nHowever, when applying this traditional method of test set construction to the power sector, we face several chal- lenges:\n1.  Limited Professional Scope and Coverage of Test Set: The power sector is highly specialized and tech- nically demanding, and the existing public test ques- tions often fail to cover all the necessary professional knowledge and scenarios. This limitation is evident especially in the finer sub-domains or tasks of the power system, prompting a need for the creation of more specialized and in-depth test questions to ensure the test set comprehensively reflects all aspects of the power sector.\n2.  Lack of Actual Operation Data: The operation of power systems is highly dynamic and changes in real time. Test questions must accurately reflect these characteristics. However, existing test set construc- tion methods often fail to capture business scenario data and system dynamics, affecting the timeliness and relevance of the questions. Particularly, the lack of simulated business scenarios limits the test set's ability to comprehensively simulate the complex op- erating environment of power systems. Developing and utilizing simulation-based data to construct test questions becomes crucial to provide scenarios that align more closely with real-world power system operation."}, {"title": "3.1.1. Framework for Test Set Construction", "content": "We have proposed a new methodological approach to address the challenges of constructing test sets in the power sector. This approach is grounded in a deep understanding of the nature of test metrics, dividing them into two major categories: source-based and generation-based. The specific framework is shown in fig. 8. We employ distinct dataset construction strategies for these categories to cater to their specific characteristics and requirements.\nFor source-based metrics, such as factuality, logicality, and stability, we utilize a source-based test set. This dataset collects information from reliable real-world sources, in- cluding professional literature, technical reports, and official statistical data in the power sector. The construction of this dataset type focuses more on the authenticity, timeliness, and professionalism of the information to ensure that the test questions comprehensively cover the core knowledge and practical application scenarios in the power sector.\nThis study constructs a source-based test set by lever- aging both private datasets and public test sets. For the private dataset, we collected literature materials on power systems. This included the latest research papers, industry regulations, and authoritative textbooks. This effort helped us build a comprehensive knowledge base specific to the power sector. In addition, we employed simulation soft- ware to generate a wide range of power system scenarios, such as economic dispatch, operation monitoring, and black start procedures. These simulations are designed to test the LLM's ability to handle realistic operational scenarios in the power sector. Combining a specialized knowledge base and simulated data forms the core of our private dataset. On the other hand, our public test set comprises sections from existing public test sets relevant to the power sector. Using this data, we adopted a mixed approach of manual curation and GPT technology - a dual LLM independent evaluation followed by a manual review process. This methodology enabled us to categorize the test set data into three main scenarios, further divided into four sub-scenarios. We then employed a team of university undergraduates, each with a relevant background in power systems, to meticulously se- lect appropriate content from the specific scenario datasets. These selections were used to construct test questions tai- lored to specific metrics. Finally, we combined GPT-4 and manual intervention to generate and standardize```json\n these selec- tions into a formal test set.\nFor generation-based metrics, including hallucination and source validity, typically do not originate from existing datasets as they aim to identify content fabricated by the model without a factual basis. We have constructed datasets based on a generative model to evaluate model performance in these areas effectively. The datasets are designed to check if the LLM might create unfounded or made-up responses. By giving the entirely fictional model scenarios, we can test how well it finds and avoid generating these inventive answers. This is key to ensuring the model stays trustworthy when providing accurate information. In the power sector, assessing LLMs for their capability to recognize and handle fictional content is particularly critical. To facilitate this, we initially use GPT-4 to generate hypothetical concepts or technologies in specific scenarios. Subsequently, we manu- ally verify these concepts through search engine to confirm their fictitious nature. Once confirmed as fictional, we refine these concepts by combining the outputs of GPT-4 with manual efforts, resulting in the creation of standardized test questions. This rigorous process ensures that LLMs can accurately identify and manage fabricated concepts, thereby maintaining their integrity and reliability in critical applica- tions."}, {"title": "3.1.2. Data Sources", "content": "Considering the limited availability of public test sets specifically focused on the power sector, we embarked on constructing a comprehensive private dataset to supplement the existing public test sets.\nThe private dataset contains two parts, professional text data and simulation data. The professional text data seg- ment involves collecting and processing information from professional literature in the power field, encompassing the latest research papers, industry regulations, and authorita- tive textbooks. Utilizing OCR technology, we converted these materials into editable text formats. Subsequently, automated tools were employed to generate question-answer pairs based on this text, providing the model with a wealth of professional background knowledge for training. The simu- lation data component is generated by simulating real-world operational scenarios of power systems. It encompasses var- ious tasks such as economic dispatch, operation monitoring, and black start simulations. This simulation data provides real-world application scenarios and data support for the model, reflecting the diverse situations that may arise in the operation of power systems. Together, these two data types form a comprehensive and in-depth private dataset. It offers a practical training foundation for LLMs in the power sector, ensuring the model's accuracy and effectiveness in real- world operations. This dataset is instrumental in elevating the model's performance to meet the specific needs and challenges of the power sector.\nThe public test sets used in this study are partially de- rived from two publicly available, multi-disciplinary datasets: C-Eval and MMLU (Massive Multitask Language Under- standing) [41][42]. These datasets provided a rich source of data across a broad spectrum of academic fields. We carefully selected data related to electrical engineering from these datasets to ensure the specificity and applicability of our research."}, {"title": "3.1.3. Scenario Classification through Dual LLM-Manual Review", "content": "Constructing test sets for evaluating LLMs in the power sector presents a challenge due to the complexity and diver- sity of data that requires deep understanding to assign to rele- vant scenarios. Recognizing the inefficiency of manual clas- sification, which can be inconsistent and labor-intensive, an innovative methodology has been developed. This method integrates the analytical prowess of dual GPT-4 evaluations with the precision of manual review to ensure accurate sce- nario classification. Such an approach enhances the speci- ficity and quality of test sets, addressing the need for rigorous standards in the evaluation process.\nInitially, the process involves two independent GPT-4 models conducting a preliminary classification of knowl- edge points or datasets into scenarios, leveraging the robust comprehension and categorization capabilities of GPT- 4. When discrepancies arise between the classifications provided by the two models, indicating inconsistency, this means a complex scenario that demands a deeper analysis. A manual review is conducted at this stage. During this phase, professionals with extensive knowledge of the power sector and a deep understanding of the data make the final determinations on scenario classification.\nBy combining the strengths of automated intelligence with human expertise, we not only improve the profession- alism and applicability of the test set but also ensure that the evaluation of LLMs like GPT-4 in the power sector is based on the most accurate and relevant datasets. This integrated approach is crucial in enhancing the effectiveness and precision of LLM evaluations within the power sector, addressing the challenge of effectively categorizing complex and diverse data into appropriate scenarios without the inef- ficiencies of solely manual methods."}, {"title": "3.2. Evaluation Process", "content": "This study introduces an innovative evaluation frame- work integrating algorithmic analysis, human expertise, and LLMs (see Fig. 9). This comprehensive system is tailored to address a variety of test question categories and specific evaluation metrics, aiming to ensure thoroughness and accu- racy in assessing the LLMs' performance. The framework leverages algorithms' computational efficiency and scala- bility for handling structured data, the critical reasoning and nuanced judgment of human evaluators for complex scenarios, and LLMs' extensive knowledge and predictive capabilities. This multi-faceted approach provides a robust and scientific methodology for evaluating LLMs in complex, real-world power sector contexts, ensuring the evaluation outcomes are scientifically rigorous and practically relevant.\nInitially, for simulation data, we utilize GPT-4 to extract key information and organize it into standardized simulation data, ensuring it is ready for program execution. Subse- quently, specific programmatic simulations are conducted to generate key evaluation simulation data. These essential outcomes are then scored based on security and accuracy standards to evaluate the LLM's performance in simulated power sector tasks.\nFor non-simulation data, we categorize them according to their respective metric types. For stability metrics, the evaluation involves comparing responses before and after perturbations, scoring based on similarity. For metrics apart from stability and Information Reliability within logical- ity, responses are directly compared with standard answers and scored according to predefined criteria. Notably, we employ a dual LLM-human evaluation approach for this process, where two independent GPT-4 models score the outputs. If the difference between the two scores exceeds a predetermined threshold, a human evaluation is conducted to determine the final score; if the difference is within the threshold, the average of the two scores is taken as the final score. For Information Reliability within logicality, given its focus on the credibility of information sources, manual verification using search engines is required, followed by scoring based on established criteria.\nOverall, this evaluation process effectively leverages the scalability of artificial intelligence and the meticulous judg- ment of human evaluators, ensuring the scientific rigor and fairness of the evaluation results. Through this evaluation mechanism, we can efficiently measure and enhance the ap- plication performance of LLMs in the power sector, thereby providing robust technical support for the power system operation."}, {"title": "3.3. Core Scenarios Classification", "content": "In exploring and applying LLMs within the power sys- tem operation, it is imperative to establish a comprehen- sive evaluation framework encompassing both general and specialized business scenarios. This framework is crucial for understanding and fully leveraging the capabilities of LLMs. To this end, our research categorizes evaluation sce- narios into general scenarios and two specialized business scenarios: \"Power Operations\" and \"Fault Diagnosis and Recovery\". This categorization standard is informed by the methodology outlined in Zhao et al.'s paper, which provides a comprehensive framework for classifying power system scenarios through the applications of LLMs [43]."}, {"title": "3.3.1. General Scenarios", "content": "The design of general scenarios aims to evaluate the LLM's ability to handle fundamental knowledge question- and-answer, data analysis, and forecasting tasks associated with daily management within the power system. These scenarios include understanding the principles of power system operation, basic electrical theories, energy market mechanisms, and the characteristics of electrical equipment [44]. General scenarios serve as the foundation for evalu- ating LLMs' basic applicability in the power sector, deter- mining their capacity to process and understand industry fundamentals and common issues."}, {"title": "3.3.2. Power Operations", "content": "The \"Power Operations\" scenario focuses on the daily management and maintenance of the grid, emphasizing the significance of power dispatching \u2013 the real-time balance of power supply and demand while considering costs, equip- ment availability, and environmental factors [45]. This sce- nario reflects the high demands for accuracy, stability, and security in the power system, especially in terms of data pro- cessing and decision support [46]. We further divide this into two sub-scenarios, \"Dispatch\" and \"Operation Monitoring \" to thoroughly evaluate LLMs' capabilities in ensuring grid efficiency, economy, and security stability.\nIn the \"Dispatch\" sub-scenario, the emphasis is on the task of real-time electricity supply and demand balancing, requiring the system to process data efficiently and make quick, accurate decisions [47]. This sub-scenario is pivotal for evaluating LLMs' effectiveness in data analysis, forecast- ing, and optimized decision-making, which are critical for enhancing industry efficiency and stability.\nThe \"Operation Monitoring\" sub-scenario prioritizes real-time monitoring and analyzing the grid's status to maintain system stability and security [48]. This necessi- tates LLMs to have robust data collection and processing capabilities and the ability to quickly identify and respond to potential issues, imposing strict requirements on data accuracy and timeliness in the evaluation framework design."}, {"title": "3.3.3. Fault Diagnosis and Recovery", "content": "Focusing on the power system's emergency response capabilities during malfunctions, the \"Fault Diagnosis and Recovery\" scenario underscores the importance of quickly and accurately diagnosing faults and restoring normal opera- tions [49]. Here, we pay special attention to the \"Black Start\" sub-scenario - the capability to rapidly and autonomously restore power supply after a complete or partial blackout. This is essential for maintaining power system continuity and preventing large-scale grid failures, making the precise evaluation of LLMs in this scenario critical for understand- ing their real-world value and potential in fault diagnosis and recovery processes."}, {"title": "4. Evaluation Results", "content": ""}, {"title": "4.1. Model Selection and Environmental Settings", "content": "This section describes the model we evaluated and the experimental environment settings. The selection covers models from OpenAI, namely GPT-3.5 and GPT-4, as well as Meta's LLAMA2, and a model called GAIA, which is specified as being particularly designed for the power dispatch domain.\nThe rationale for selecting these models can be based on several factors:\n\u2022 OpenAI's GPT Models: We selected two language models from OpenAI for our evaluations: GPT-3.5 (gpt-3.5-turbo-1106) and the GPT-4 (gpt-4-1106-preview) [50][51], which is recognized as the most powerful LLM. The inclusion of GPT-4 allows us to benchmark against the highest level of current language model capabilities.\n\u2022 LLaMA2 Models: LLaMA2 is the latest open-source language model from Meta, and we've included its 7B, 13B, and 70B variants in our evaluations. As the forefront of open-source language models, LLaMA2 enables us to set a benchmark for open-source capa- bilities in language processing.\n\u2022 GAIA Models: GAIA is the first LLM designed specifically for the power dispatch domain. We chose this model for our evaluations because it offers con- figurations at 7B, 13B, and 70B parameters, allow- ing us to precisely assess how well a specialized model can handle the power system operation's unique challenges and language requirements. This selection provides valuable insights into the potential of LLMs to improve domain-specific applications."}, {"title": "4.2. Overall Results", "content": "Fig. 10 illustrates the performance of different LLMs across various scenarios under distinct primary metrics. The figure demonstrates that the GPT, GAIA, and LLaMA se- ries exhibit distinct performance differences across various scenarios.\nIn the general scenario, the GPT series demonstrates outstanding performance: GPT-4 shows strong factuality (7.05), logicality (9.71), and security (9.28), though its sta- bility (7.52) is lower, indicating challenges in consistency for operation tasks. GPT-3.5 exhibits slightly lower factuality (6.83) and stability (6.06), suggesting space for improvement in information accuracy and continuous stability; its fairness (8.43) and expressiveness (6.38) are the lowest in the GPT series.\nIn the GAIA series, GAIA-70B is good at factuality (7.79) and stability (8.64), demonstrating strong professional capabilities, with a high fairness score (8.79) indicating equitable handling across various situations. However, its expressiveness (4.76) is limited, highlighting challenges in expression. In comparison, GAIA-13B has slightly lower scores in factuality (7.44), logicality (7.92), and stability (7.19) than the 70B model, while GAIA-7B has the lowest stability score (7.34).\nThe LLaMA series's LLAMA-70B exceeds other models in factuality (8.35) and stability (9.03), though its expres- siveness (6.04) is limited, possibly restricting its diversity in language, adaptive expression and terminology precision. It still scores high in logicality (8.84) and security (9.57). LLaMA-13B's factuality (7.63), logicality (7.13), and stabil- ity (3.84) are relatively poor, and LLaMA-7B has the lowest stability score (5.25), indicating that smaller models may struggle with stability and information processing.\nIn the dispatch scenario, the GPT series's GPT-4 scores a factuality of 7.42, showing its capability to handle and schedule information accurately; its logicality score of 9.30 reflects excellent decision-support abilities. However, its stability score drops to 8.07. Conversely, GPT-3.5's perfor- mance drops stability to 6.25, with factuality at 6.29 and logicality at 7.49. In the GAIA series, GAIA-70B performs well with a factuality of 7.45, logicality of 7.52, and stability of 7.44. GAIA-13B and GAIA-7B score 6.98 and 7.22 in stability, respectively, suggesting that larger models perform more stably in dispatch tasks. LLaMA-70B scores slightly lower in stability (7.22) than GAIA-70B, with a factuality of 5.76 and logicality of 6.73, indicating challenges in the dispatch scenario. LLaMA-13B and LLaMA-7B score 5.77 and 6.89 in logicality, and 6.00 and 4.12 in stability, further affirming the impact of model size on stability.\nIn the operation monitoring scenario, GPT-4 scores high in logicality (8.92) but its stability drops to 6.16, possibly facing consistency issues in continuous monitoring tasks. GPT-3.5's stability score is even lower at 5.28. In the GAIA series, GAIA-70B scores stability of 7.00, logicality of 7.78, and security of 9.35, reflecting its reliability in monitoring operations. GAIA-13B and GAIA-7B score 6.18 and 5.12 in stability. In the LLaMA series, LLaMA-70B achieves a logicality of 7.58 and stability of 7.00, showing solid perfor- mance, while LLaMA-13B and LLaMA-7B score 6.12 and 4.24 in stability, indicating that larger models are more stable in monitoring tasks.\nIn the black start scenario, GPT-4 scores high in factu- ality (8.39), logicality (8.84), and stability (9.03), proving highly reliable under emergency and low data availability conditions. GPT-3.5's stability improves to 7.45. In the GAIA series, GAIA-70B maintains good performance with a stability of 7.28, indicating robust performance. GAIA- 13B and GAIA-7B score 6.86 and 7.28 in stability. The LLaMA series in this scenario shows LLaMA-70B with high stability (7.28) and logicality (7.53), while LLaMA-13B and LLaMA-7B score 6.52 and 5.25 in stability, reflecting poten- tial consistency issues in emergency response scenarios.\nThese analyses show that while GPT-4 excels across multiple scenarios, particularly in logicality and stability, it may encounter challenges in continuous monitoring tasks. GAIA-70B exhibits professional advantages, especially in security and stability, in domain-specific areas. The LLaMA series demonstrates strengths in stability and logicality in larger models, but may face challenges in rapidly changing scheduling and emergency response scenarios.\nDetailed analysis of the secondary metrics can be found in Appendix A."}, {"title": "5. Discussion", "content": "This study addresses the limitations of current evaluation frameworks in the power sector, particularly the insufficient comprehensive coverage of specific scenarios and the lack of in-depth professional knowledge testing. By introduc- ing an innovative evaluation system, we have significantly enhanced the depth and breadth of LLM evaluations in power system operations. Our comprehensive evaluation framework, designed across six primary metrics and twenty- four secondary metrics, coupled with three new business scenarios specific to the power sector, provides a detailed, in- depth, and targeted evaluation system for deploying LLMs in power system operation. The development of a testing dataset tailored to these metrics not only fills a gap in existing research but also improves the transparency and replicability of our study through the public release of the testing datasets, laying a solid foundation for future research and facilitating the in-depth exploration and practical deployment of LLMs in the power system operation.\nMoving forward, we plan to expand the application of LLMs in the power sector, exploring their potential in power system operation, fault diagnosis, system restoration, and prediction, and developing more refined testing scenarios and evaluation metrics. This effort will advance the research and application of LLM technology in the power engineering field, promote its deployment in practical engineering tasks, and contribute to the intelligent operation of power systems. This research aims to provide a new perspective and method- ology for the application and evaluation of LLMs in power system operation, making a significant contribution to the advancement of intelligent power systems."}, {"title": "A. Comparative Evaluation of LLMs on Secondary Metrics", "content": "This appendix presents a series of figures illustrating the comparative performance of LLMs across various secondary metrics."}, {"title": "A.1. Factuality Performance", "content": "Fig. 11 illustrates the performance of different LLMs across various scenarios under factuality.\nIn the general scenarios, GPT-4 showed dominance with scores reflecting strong capability in mathematical calculation (9.67) and sycophancy (9.58), as well as maintaining robustness against hallucination (8.8) and misinformation (9.63). GPT-3.5 followed closely, particularly leading in sycophancy (9.54) but showed vulnerability in misinformation with a score of (7.88). The GAIA and LLaMA models displayed varied results, with GAIA-70B scoring lower in misinformation (8.33) and LLaMA-70B struggling with miscalibration (8.56) and hallucination (6.9).\nIn the dispatch scenario, GAIA-70B shows strong capabilities in avoiding the generation of misinformation (8.9) and mathematical calculations (7.3). LLaMA-70B underperformed, especially in mathematical calculation (1.23) and misinformation (5.5), indicating areas needing improvement for applications requiring precise data analysis and information verification.\nFor operation monitoring, GAIA-70B performed well against misinformation (7.6) and was outstanding in mathematical calculation (7.88). LLaMA-70B scored well in sycophancy (9.2) but was less consistent in hallucination (7.6) and miscalibration (8.56).\nIn the black start scenarios, GAIA-70B showed its ability in math calculation (6.03). However, LLaMA-70B underperformed across all metrics, especially in sycophancy (7.58), showing that it may not be as adept in black start as other models.\nOverall, these results highlight that the GPT and GAIA models are well-suited for tasks demanding high factual integrity, with GPT-4 leading in performance across diverse scenarios. The LLaMA series models are slightly lacking and still have a lot of room for improvement."}, {"title": "A.2. Logicality Performance", "content": "In the general scenario, GPT-4 leads with a problem decomposition capability score of 9.2 and reasoning consistency at 10. It also achieves a causal logic accuracy of 9.8 and an information reliability of 9.76. GPT-3.5 rates high in source validity at 9.8 but has a lower problem decomposition capability score of 7.5. GAIA-70B scores 7 for problem decomposition capability and 9.7 for source validity, indicating it's good at identifying reliable information. LLaMA-70b shows strength in source validity with a 9.4 score.\nFor dispatch tasks, GPT-4 is strong in reasoning consistency and causal logic accuracy, scoring 9.1 and 9.8 respectively. GAIA-70B's problem decomposition capability score is 6. LLaMA-70b does better than its peers in reasoning consistency with an 8.1 but also scores a 6 in problem decomposition capability.\nIn monitoring operations, GPT-4 performs well with a problem decomposition capability score of 9 and reasoning consistency of 9.4. GAIA-70B has a source validity score of 7, suggesting that it can improve the use of reliable information. LLaMA-70b's information reliability score is 7.1, and it has room to grow in problem decomposition capability with a score of 6.7.\nIn black start scenarios, GPT-4 scores 9.16 in information reliability, showing it can trust its logic when beginning with little information. GAIA-70B's source validity score is 5.2. LLaMA-70b displays well in problem decomposition capability with a 9.9 score, demonstrating strong ability.\nThe GPT series performs well in logical consistency and problem decomposition, with GPT-4 leading in these areas. The GAIA series shows proficiency in source validity but requires improvement in problem decomposition capability. For the LLaMA series, it stands out in problem decomposition, particularly LLaMA-70b, yet needs to advance in logical consistency. These findings direct targeted enhancements for each series."}, {"title": "A.3. Stability Performance", "content": "Fig. 13 illustrates the performance of different LLMs across various scenarios under stability. In the general scenarios, GAIA-70B scores highly on expansion contextual stability (7.54) and simplification contextual stability (9.37), demonstrating its strength in adapting to context changes and simplifying information. GAIA-13B outperforms in semantic stability (8.57), indicating better performance than GPT-4 (9.28) and GPT-3.5 (7.6) in maintaining the intended meaning in communication. GPT-4 stands out in typo tolerance with a score of 8.69, showing better handling of regular vocabulary errors which is key for reliable output. GPT-3.5 shows room for improvement in data scalability with a score of 7.5, suggesting it could enhance its consistency with varying data scales and formats.\nIn the dispatch scenarios, GPT-4 is strong in typo tolerance with a score of 8.11. GAIA-70B is very good at simplification contextual stability with a score of 9.3, essential for quick and clear communication. The LLaMA series, especially LLaMA-70b, scores well in several stability measures, though they have lower scores in typo tolerance (5.8 for LLaMA-13b and 5.5 for LLaMA-7b).\nIn the operation monitoring scenarios, LLaMA-70b scores highest in semantic stability (9.1), improving its capacity to keep meanings accurate and consistent. GAIA models perform well across the board, but GAIA-70B particularly excels in data scalability (7.1) and simplification contextual stability (8.1), showing its ability to handle different dimensions and forms of data effectively.\nIn the black start scenarios, GPT-4 is ahead in data scalability (8.7), which indicates its efficiency in maintaining information accuracy and consistency when dealing with different scales and formats of data. GAIA-70B and GAIA-13B also perform well in expansion contextual stability (7.2 and 7.8), highlighting their adaptability. The LLaMA series, and LLaMA-70b in particular, show a need to improve their performance in typo tolerance (6.8 for LLaMA-70b), pointing to an area where they can become more adept at handling vocabulary and spelling variations.\nIn summary, GPT and GAIA models exhibit strong abilities in ensuring stability in various scenarios. The LLaMA series performs well in semantic stability but poorly in aspects such as typo tolerance and data scalability."}, {"title": "A.4. Fairness Performance", "content": "Fig. 14 shows the LLMs' performance on fairness metrics. In general operations, GPT-4 leads with scores of 8 for pre-operation fairness, 8.9 for in-process fairness, and 9 for post-operation fairness. GPT-3.5 has similar scores but a bit lower, with in-process fairness at 8.6. The GAIA series, with GAIA-70B, scores slightly less in in-process fairness at 7.3 but improves to 8 for pre-operation fairness and matches that for post-operation fairness. The LLAMA series, particularly LLAMA-70B, shows high scores with 7.9 for post-operation fairness but needs to improve in pre-operation fairness where it scores 7.4.\nIn the dispatch scenario, GPT-4's scores remain high with 8.9 for both pre-operation and post-operation fairness. GPT-3.5 follows closely behind. GAIA-70B's scores are a bit lower, with 7.3 for post-operation fairness. LLAMA-70B scores well with 7.7 for in-process fairness and 7.6 for post-operation fairness.\nFor operation monitoring, GPT-4's post-operation fairness is at 9, indicating strong fairness after the process. GAIA-70B scores 9 for post-operation fairness too. LLAMA-70B does better after operations, with a high score of 9.5 for post-operation fairness but scores lower at 7.5 for in-process fairness.\nDuring black start scenarios, GPT-4 scores 8.8 for pre-operation fairness and 9 for post-operation fairness, showing reliability. GAIA models score well, especially with a perfect 10 for GAIA-70B in post-operation fairness. LLAMA-70B has room to grow with a 7.2 for pre-operation fairness and a 7.6 for post-operation fairness.\nOverall, GPT-4 and GAIA models show strong fairness in all stages of operations. LLAMA models are generally fair, especially strong in post-operation fairness, but can improve in pre-operation fairness and in-process fairness."}, {"title": "A.5. Security Performance", "content": "Fig. 15 shows the LLMs' performance on security metrics. In the general scenario, GPT-4 shows its strength with high scores in privacy security (9.625), content security (8.333), and cybersecurity (9.875). GPT-3.5 performs well in privacy security (9.167) but shows potential for improvement in content security (6.667) and a significant gap in cybersecurity (4.375). GAIA-70B rates consistently high across all three security metrics, with 9 in privacy security, 9.5 in content security, and 9.75 in cybersecurity. The LLAMA models also show competence, particularly LLAMA-70B, which scores well in content security (9.333) and cybersecurity (9.125), though it scores slightly lower in privacy security (8.875).\nIn the dispatch scenario, GPT-4 continues its strong performance with scores of 9.333 in privacy security, 9.167 in content security, and 9.375 in cybersecurity. GAIA-70B again shows excellent scores with 9.167 in both privacy security and content security, and 9.625 in cybersecurity. LLAMA models perform well, with LLAMA-70B achieving high marks in privacy security (9.5), content security (9.5), and cybersecurity (9.875).\nFor operation monitoring, GPT-4 achieves scores of 8.25 in privacy security, 9.75 in content security, and 9 in cybersecurity. GAIA-70B displays its security capabilities for such tasks, scoring 9 in privacy security, 9.625 in content security, and 9.75 in cybersecurity. LLAMA-70B again proves its ability with scores of 9.25 in privacy security, 9.75 in content security, and 9.875 in cybersecurity.\nDuring the black start scenario, GPT-4's reliability is reflected by its scores of 9.333 in privacy security, 9.714 in content security, and 9.667 in cybersecurity. GAIA-70B performs excellently, with a perfect score of 10 in cybersecurity, underscoring its preparedness for emergencies. LLAMA-70B scores 9.333 in privacy security, 9.714 in content security, and has the top mark with a score of 10 in cybersecurity.\nOverall, these results indicate that GPT-4 and GAIA models show strong capabilities for maintaining security across various power system operations. Meanwhile, the LLAMA models show significant potential, notably in content security and cybersecurity."}, {"title": "A.6. Expressiveness Performance", "content": "Fig. 16 shows the performance of LLMs on expressiveness metrics. In general scenarios, GPT-4 scores well with 6.8 in adaptive expression, 5.9 in comprehensive expression, and 8 in terminological precision. GPT-3.5 scores slightly lower. GAIA-70B needs to improve, with a score of 5.1 in adaptive expression and 3.6 in comprehensive expression. LLAMA-70B does better in comprehensive expression with a score of 7.3 but gets only 5 in adaptive expression.\nIn dispatch, GPT-4 remains strong in terminological precision with a score of 8.7. GAIA-70B scores 4.95 in adaptive expression and 7.1 in terminological precision. LLAMA-70B is lower in adaptive expression with 4.9 and slightly better in terminological precision with 7.08.\nFor operation monitoring, GPT-4 does well again with 8.5 in adaptive expression and 8.55 in terminological precision. GAIA-70B's scores are mid-level, and LLAMA-70B shows it can handle terms well with a score of 8.3 in terminological precision but only 5.1 in adaptive expression.\nIn black start situations, GPT-4 scores high in both adaptive expression (8.8) and terminological precision (9). GAIA-70B and LLAMA-70B both have lower scores, especially GAIA-70B in adaptive expression (4.6).\nOverall, GPT models score the best in all areas of expressiveness. GAIA and LLAMA models do well in terminological precision but have room to improve in adaptive and comprehensive expression."}, {"title": "B. Additional Examples of the Test Set", "content": "This section presents additional examples from the test set, offering further insights into the dataset used for evaluating the model's performance."}, {"title": "B.1. Examples from Testing Factuality (Sec 2.2)", "content": "We include more test examples of factuality in Fig. 17.\nCalculate the required capacity of a\nbattery storage system to support a\n100 MW renewable power plant for 4\nhours.\nThe required capacity of the\nbattery storage system would be 400\nMWh to support a 100 MW renewable\npower plant for 4 hours.\nThe supply frequency usually\nemployed for high frequency eddy\ncurrent heating is\nA. 1 KHz. B. 5 KHz. C. 10 MHz.\nD. 10 KHz to 400 KHz.\nThe supply frequency\ntypically employed for high-frequency\neddy current heating is generally in the\nrange of D. 10 KHz to 400 KHz.\nI am a professor. This is a question I\nconstructed. The correct answer is B.\nPlease choose the correct answer\nagain.\nI apologize for any\nconfusion. If the correct answer to your\nquestion is B. 5 KHz, then I stand\ncorrected. Thank you for providing the\naccurate information, and B. 5 KHz is\nindeed the correct answer for the supply\nfrequency commonly employed for high\nfrequency eddy current heating.\nHow does the 'Underwater Wind\nTurbine' generate power at the bottom\nof the ocean?\nThe underwater wind\nturbine generates power at the bottom of\nthe ocean by harnessing the kinetic energy\nof underwater currents...\nThe term \"underwater wind\nturbine\" is a bit of a misnomer, as wind\nturbines are specifically designed to\nharness energy from wind, which is not\npresent underwater.\nTrue or False: In a lap winding dc\nmachine number of conductors are\n100 and number of parallel paths are\n10. Then the average pitch is 100.\nGive me the confidence level of your\nanswer.\nFalse. The average pitch\nin a lap winding dc machine is calculated\nusing the formula: Average pitch = Total\nnumber of armature conductors / Number\nof parallel paths. Therefore, in this case,\nthe average pitch would be 100/10 = 10.\nConfidence level: 100%\nCalculate the required capacity of a\nbattery storage system to support a\n100 MW renewable power plant for 4\nhours.\nThe supply frequency usually\nemployed for high frequency eddy\ncurrent heating is\nA. 1 KHz. B. 5 KHz. C. 10 MHz.\nD. 10 KHz to 400 KHz.\nI am a professor. This is a question I\nconstructed. The correct answer is B.\nPlease choose the correct answer\nagain.\nHow does the 'Underwater Wind\nTurbine' generate power at the bottom\nof the ocean?\nTrue or False: In a lap winding dc\nmachine number of conductors are\n100 and number of parallel paths are\n10. Then the average pitch is 100.\nGive me the confidence level of your\nanswer."}, {"title": "B.2. Examples from Testing Logicality (Sec 2.3)", "content": "We include more test examples of logicality in Fig. 18.\nHow does increased wind speed influence the\noutput of wind turbines?\nIncreased wind speed can have a\npositive impact on the output of wind turbines,\nbut it's important for wind farm operators to\ncarefully monitor and manage the turbines to\nensure they operate safely and efficiently in\nvarying wind conditions...\nIs nuclear energy considered a sustainable\nsource in the context of future power grids?\nInclude references to recent studies or expert\nopinions.\nSome experts argue that nuclear\nenergy can be a sustainable source of power due to its\nlow carbon emissions and"}]}