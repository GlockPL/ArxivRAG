{"title": "Mobility-Aware Federated Learning: Multi-Armed Bandit Based Selection in Vehicular Network", "authors": ["Haoyu Tu", "Lin Chen", "Zuguang Li", "Xiaopei Chen", "Wen Wu"], "abstract": "In this paper, we study a vehicle selection problem for federated learning (FL) over vehicular networks. Specifically, we design a mobility-aware vehicular federated learning (MAVFL) scheme in which vehicles drive through a road segment to perform FL. Some vehicles may drive out of the segment which leads to unsuccessful training. In the proposed scheme, the real-time successful training participation ratio is utilized to implement vehicle selection. We conduct the convergence analysis to indicate the influence of vehicle mobility on training loss. Furthermore, we propose a multi-armed bandit-based vehicle selection algorithm to minimize the utility function considering training loss and delay. The simulation results show that compared with baselines, the proposed algorithm can achieve better training performance with approximately 28% faster convergence.", "sections": [{"title": "I. INTRODUCTION", "content": "Data-driven machine learning (ML) tasks in vehicular networks such as trajectory prediction, object detection and traffic sign classification enhance road safety and alleviate urban congestion to facilitate autonomous driving [1]. The distributed data of each vehicle is collected by various sensors such as GPS (Global Positioning System), LiDAR (Light Detection and Ranging) and cameras, and increased data privacy and communication overhead is brought in when local data is offloaded to the server. Federated learning (FL) enables vehicles to collaboratively train models from the server aggregated from all vehicles without sharing local data directly and reduces the communication overhead caused by large amounts of data transmission between vehicles to the server and cloud [2], [3]. Nevertheless, vehicle mobility brings issues for FL in vehicular networks with dynamic communication channels and time-varying available vehicle set [4].\nIn the literature, the research to speed up FL convergence in vehicular networks can be roughly divided into two categories: model aggregation design [5], [6] and resource allocation [7], [8]. In terms of model aggregation, the successful probability of vehicle training is optimized by designing a weighted parameter with the duration time and size of the dataset for each vehicle [5]. The inner-cluster and inter-cluster training scheme is proposed for vehicles with multi-hop clusters [6]. An incentive mechanism based on contract theory is proposed to select vehicles with better quality wireless channels and the dataset size [7]. Xie et al. in [8] optimized the round duration and local iteration number to measure the performance of FL in vehicular networks considering mobility. Different from existing papers, we study the impact of moving vehicles and develop an online algorithm to select vehicles based on their locations.\nDesigning an efficient FL scheme in vehicular networks faces the following challenges. Firstly, the designed model aggregation algorithms require prior knowledge of the vehicle's mobility which may not be easy to get such as the historical trace information in the current area. Secondly, the modeling of mobility involves viewing movement as a given probability, but the probability is statistical in long-time period and difficult to provide real-time information to guide vehicle selection and resource allocation choices.\nIn this paper, we design a Mobility-Aware Vehicular Federated Learning (MAVFL) scheme, where vehicles drive through the road segment to participate in FL with a collaborative base station (BS). We propose the real-time ratio that vehicles successfully upload models. We conduct the theoretical analysis of convergence and demonstrate that the ratio significantly influences convergence. Based on analytical results, we formulate the optimization problem to maximize the utility function while minimizing training loss and training delay. We design an MAB-based vehicle selection algorithm to solve the optimization problem. Extensive simulation results show the effectiveness of the proposed scheme in terms of convergence speed and training delay.\nThe main contributions of our paper are summarized as follows:\n\u2022 We propose an MAVFL scheme and conduct the convergence proof of the proposed scheme.\n\u2022 We formulate an optimization problem to speed up the convergence. We propose an MAB-based vehicle selection algorithm to solve the problem."}, {"title": "II. CONSIDERED SCENARIO AND SYSTEM MODEL", "content": "As shown in Fig. 1, we consider a segment of road covered by a BS with a collaborative server and Ko vehicles that arrive at this stretch of road over a period of time. These vehicles will communicate with the BS in the segment of"}, {"title": "B. Vehicular Federated Learning Scheme", "content": "In the proposed scheme, the training process contains R rounds before the deadline Ta. The server is able to get the location and velocity of vehicle k within the segment during training as $x_k$ and $v_k$ at $t_0 < Ta$.\nDuring the training process of the MAVFL scheme, the loss function for vehicle k is expressed as\n$f(w_k, D_k) = \\frac{1}{|D_k|} \\sum_{i \\in D_k} l(w_k; z_i)$,\nwhere $D_k$ means the indices of samples in $D_k$, $z_i$ is the data sample representation for sample $i \\in \\{1, 2, ..., |D_k|\\}$ and $l$ is the local loss function. Vehicle k will train model $w$ to find the optimal model as $w_k = \\arg \\min_{w_k} \\frac{1}{|D_k|} \\sum_{i \\in D_k} l(w_k; z_i)$, and the global loss function is $F(w) = \\sum_{k=1}^K q_k f(w_k, D_k)$, where $q_k$ is the aggregation weight of vehicle k.\n1) Vehicle Selection and Model Distribution: At the beginning of round $r \\in \\{1, 2, ..., R\\}$, the server owns the newest global model $w^{(r)}$, then it will make the vehicle selection decision to generate the set of vehicles $S^r$ and distribute the model to vehicles within its covering segment as\n$w_k^{r,0} = w^{(r)}, x_k \\in X_s, k \\in S^r$,\nwhere $w_k^{r,0}$ means the local model for vehicle k in round r and epoch 0, $X_s$ is the location range of covering segment, and $x_k$ is the location of vehicle k at the beginning of round r.\n2) Local Updating: After receiving model $w_k^{r,0}$, vehicle k will perform local stochastic gradient descent (SGD) for E epochs. For local training epoch $e \\in \\{0, ..., E - 1\\}$, the gradient descent is expressed as $g_k^{r,e}(w_k^e; z_i) = \\frac{1}{|D_k|} \\sum_{i \\in D_k} \\nabla l(w_k^e; z_i)$ and vehicle k performs local SGD as\n$w_k^{r,e+1} \\leftarrow w_k^{r,e} - \\eta g_k^{r,e}$, for $e \\in [0, E - 1]$.   (2)\n3) Model Uploading: After local updating, vehicle k will try to upload model updates $w_k^r = \\sum_{e=0}^{E-1} w_k^{r,e}$ to the server. Due to the movement of vehicles, it may drive out of the covering segment of the BS, which causes model missing. We define the dropout indicator $\\mathbb{1}_k \\in \\{0,1\\}$ as\n$\\mathbb{1}_k = \\begin{cases}\n1, & x_k^{r,E} \\in X_s, \\\\\n0, & x_k^{r,E} \\notin X_s\n\\end{cases}$\nto represent the state of whether vehicle k stays in the covering segment after local updating with E epochs in round r.\n4) Model Aggregation: The server will wait for a period of time to receive model updates from vehicles within the covering segment. If the server receives any model updates within $T_{max}$, it will aggregate these models as\n$w^{r+1} = \\frac{\\sum_{k=1}^K \\mathbb{1}_k w_k^r}{\\sum_{k=1}^K \\mathbb{1}_k}$, $w_k^r \\neq 0$  (3)\nto get new global model $w^{r+1}$. For each global model $w^{r+1}$, we define the set of vehicles as $N^r$ which denotes the set of vehicles uploading models included in the global model as\n$N^r = \\cup_{\\mathbb{1}_k=1} \\{k\\}$.  (4)\nthen the successful training ratio $p_r$ is denoted as\n$p_r = \\frac{|N^r|}{|S^r|}$,  (5)\nwhere $|N^r|$ is the number of receiving uploading models from vehicles and $|S^r|$ is the number of vehicles receiving downloading models. The value of $p_r$ is related to both vehicle selection and vehicle mobility. Especially, when all vehicles are stationary, the ratio $p_r$ is 1, and the ratio is 0 considering all selected vehicles driving out of the covering segment during local computing. When $p_r$ is 0, the server will distribute the global model as $w^{r+1} = w^r$."}, {"title": "C. Training Delay model", "content": "We give the analysis of the delay of the MAVFL scheme in this part. Considering the movement of vehicle k, the distance of vehicle k and BS as $L_k$ is related to the topology structure of the road and the movement of vehicles. We define the location coordinate of vehicle k as $x_k$, then the distance between vehicle k and BS can be expressed as\n$L_k = \\sqrt{(L_z)^2 + H^2}, x_k \\in z$,\nwhere H is the height of BS, $L_z$ is the normalized distance between vehicle and BS in zone z, and $Z_z$ is the range of location for zone z.\nThe uplink transmission for selected vehicles is considered as an orthogonal frequency-division multiple access"}, {"title": "IV. PROBLEM FORMULATION", "content": "To minimize the training loss and training delay, we design the utility function which combines the proportion of receiving models and normalized training delay as\n$\\Phi^r(\\alpha) = [\\alpha p^r(\\alpha) - (1 - \\alpha) \\frac{T_r(\\alpha) - T_{min}}{T_{max} - T_{min}}]$\nwhere $\\alpha = [a_1, a_2, ..., a_K]$ is the vehicle selection strategy for all vehicles, $\\alpha$ is the parameter between 0 and 1 to balance the impact of training loss and delay, and $T_{min}$, $T_{max}$ are minimum and maximum of round duration time, respectively. Then we formulate the optimization problem to maximize the sum of utility functions as\nP1: $\\max_\\alpha \\sum_k \\Phi^r(\\alpha_k)$\ns.t.$\\frac{B}{\\sum_k a_k} \\geq B_{min}, \\forall r \\in R, k \\in K$ (7a)\n$a_k \\in \\{0, 1\\}, \\forall r \\in R, k \\in K$ (7b)\n$\\sum a_k = K_0, \\forall r \\in R$ (7c)\nThe inequality in (7a) means the lower bound of bandwidth for each vehicle should be guaranteed. The expression in (7b) indicates the feasibility condition of vehicle selection, and the equality in (7c) gives the number of initially selected vehicles.\nThe problem P1 is difficult to solve directly because the expression of probability $p_r(\\alpha_r)$ needs future location and velocity information of selected vehicles, which are challenging to get before vehicle selection and training. We design the MAB-based vehicle selection algorithm to solve the optimization problem."}, {"title": "V. PROPOSED ALGORITHM", "content": "In this section, we provide the solution to the problem P1. The proposed vehicle selection problem in P1 can be formulated as an MAB problem [11]\u2013[13]. The vehicles with the larger estimated accumulated utility function are selected with the upper confidence bound (UCB) policy.\nIn the proposed MAB vehicle selection algorithm, the exploitation-exploration trade-off is considered with a larger utility function as exploitation and the diversity of participated vehicles as exploration. The details of exploitation and exploration are shown below.\n1) Exploitation: We record the times of vehicle k been selected before round r as\n$M_k^r(\\lambda, \\alpha) = \\sum_{\\tau=1}^r \\lambda^{r-\\tau} \\mathbb{1}(a_k^{\\tau} = 1)$,\nwhere $\\lambda$ denotes as discount factor between 0 and 1 to measure the importance of recent choices. Then we can get the discounted empirical average as\n$\\hat{\\Phi}_k^r(\\lambda, \\alpha) = \\frac{\\sum_{\\tau=1}^r \\lambda^{r-\\tau} \\mathbb{1}(a_k^{\\tau} = 1)\\Phi^{\\tau}(a_k)}{M_k^r(\\lambda, \\alpha)}$ (8)\nwhich gives more weight to recent objective functions."}, {"title": "Algorithm 1 MAB-based vehicle selection algorithm.", "content": "Input: Location of vehicles ${x_k^r}$, number of vehicles se- lected $M_r$.\nOutput: The set of selected vehicles $S^r$.\n1: for $r < R$ do\n2: if $r = 0$ then\n3: Select $K_0$ vehicles randomly as $S^0$ in K.\n4: else\n5: BS calculates the UCB score in (10) and updates score list $U[k] = U_k(\\alpha)$ based on $S^{r-1}$.\n6: BS generates vehicle set\n7: $S^r = \\{K_0$ vehicles with largest values of $U_k$ in $U\\}$.\n8: end if\n9: BS distributes global model to vehicles in $S^r$.\n10: end for\n2) Exploration: We give the function of the UCB index of the proposed scheme as\n$c_k(\\lambda, \\alpha_k) = \\sqrt{\\frac{2 \\log n(r, \\lambda)}{M_k^r(\\lambda, \\alpha_k)}}$, (9)\nwhere $n(r, \\lambda)$ records the total number of all the vehicles selected before round r. This UCB index function facilitates the selection and exploration of alternative vehicles in other zones.\nAt the beginning of the selection, if vehicle k is not chosen for a while, then $n(r, \\lambda)$ will increase with the training and $M_k^r(\\lambda, \\alpha_k)$ remains the same. In subsequent training rounds, vehicle k will be chosen frequently with a larger UCB index. When the vehicle k is selected for many rounds, the parameter $M_k^r(\\lambda, \\alpha_k)$ will increase bringing in a decreasing UCB index. Based on the above formulations, the upper UCB index in MAVFL scheme is denoted as\n$U_k(\\alpha) = \\hat{\\Phi}_k^r(\\lambda, \\alpha_k) + c_k(\\lambda, \\alpha_k)$.  (10)\nDuring the training process for the largest $K_0$ values of $U_k$, the vehicle selection choices $a_k^r$ will be set as 1. All the selection choices are learned from past rounds of UCB scores. The details of the vehicle selection process are described in Algorithm. 1."}, {"title": "VI. SIMULATION RESULTS", "content": "In the simulation, we consider a flow of vehicles driving through a straight road with a length of 1,000 m. The mobility pattern of the vehicle is the intelligent driver model, and the base station is situated in the middle of the road with a height of 25 m. For vehicle ML tasks, we consider image classification tasks with the CIFAR-10 dataset and GTSRB dataset, respectively. For the CIFAR-10 dataset, we utilize the ResNet-18 model, and for the GTSRB dataset, we utilize the LeNet model. Each vehicle contains 600 samples with independent identically distributed. Other relevant parameters used in this simulation are listed in Table I.\nThe baselines are as follows:\n\u2022 Communication-based selection (CBS): The vehicles are selected with the nearest distance from the BS with better communication conditions in each round.\n\u2022 Remain-time based selection (RBS): The vehicles are selected with the longest remaining time in the covering segment in each round.\n\u2022 Random: The vehicles are selected randomly through the covering segment."}, {"title": "B. Simulation Results", "content": "In Fig. 2, we compare the training accuracy for the above vehicle selection algorithms with different velocities as 60 km/h and 80 km/h with the CIFAR-10 dataset. From Fig. 2a and 2b, we observe that the convergence speed of the proposed vehicles selection algorithm with MAB is faster, and the overall time of the proposed scheme can be substantially reduced compared to two heuristic and one random algorithms. Moreover, the reduction of the overall time is decreased on average with higher velocity because the number of vehicles is less with larger distance between vehicles.\nFigure 3 shows the performance of different algorithms on the GTSRB dataset. We can observe that the convergence speed of the proposed vehicle selection algorithm with MAB is faster than the three baseline algorithms. We note that the improved accuracy in the GTSRB dataset is smaller than in the CIFAR dataset. It is also worth noting that the convergence time required for GTSRB is shorter than CIFAR-10. The reason for these two situations is that the GTSRB dataset is easier to train with fewer training samples compared with CIFAR-10.\nTable II shows the results of the delay in target accuracy performance of the proposed scheme with two datasets. Especially, for the CIFAR-10 dataset, we compare the delay of all vehicle selection methods reaching 75% accuracy, and the 90% accuracy is considered for the GTSRB dataset. For the CIFAR-10 dataset, compared with CBS and RBS selection algorithms, the MAB algorithm is nearly 23% faster for 60 km/h, and approximately 50% faster for 80 km/h. In particular, the Random algorithm can not reach 80% accuracy within the given deadline. Meanwhile, the proposed scheme is approximately 32% faster than CBS and RBS methods for the GTSRB dataset."}, {"title": "VII. CONCLUSION", "content": "In this paper, we have designed an MAVFL scheme and proposed a real-time ratio to reflect the successful training participation rate. We also analyzed the impact of the proposed ratio on convergence results. We have formulated an optimization problem to decrease training delay by selecting suitable vehicles through the MAB-based vehicle selection algorithm. The proposed MAB-based algorithm provides a new feasible solution for real-time vehicle selection. In future work, we will explore the proposed scheme for vehicles with computing and data heterogeneity."}]}