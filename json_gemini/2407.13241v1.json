{"title": "NODER: Image Sequence Regression Based on Neural Ordinary Differential Equations", "authors": ["Hao Bai", "Yi Hong"], "abstract": "Regression on medical image sequences can capture temporal image pattern changes and predict images at missing or future time points. However, existing geodesic regression methods limit their regression performance by a strong underlying assumption of linear dynamics, while diffusion-based methods have high computational costs and lack constraints to preserve image topology. In this paper, we propose an optimization-based new framework called NODER, which leverages neural ordinary differential equations to capture complex underlying dynamics and reduces its high computational cost of handling high-dimensional image volumes by introducing the latent space. We compare our NODER with two recent regression methods, and the experimental results on ADNI and ACDC datasets demonstrate that our method achieves the state-of-the-art performance in 3D image regression. Our model needs only a couple of images in a sequence for prediction, which is practical, especially for clinical situations where extremely limited image time series are available for analysis.", "sections": [{"title": "Introduction", "content": "In medical image analysis, image sequences like longitudinal image scans or image time series provide rich spatio-temporal information for studying the mechanisms of human aging and the patterns of disease development. Regression on temporal image sequences [15,12,9,10] is a commonly-used technique to explore the relationship between images and their associated time attribute. However, in practice, regression on medical image sequences, especially longitudinal 3D image volumes, is facing the following three challenges: (i) Missing data. Collecting regular follow-up scans of a subject is a challenging task. Often, we have missing scans at one or more time points for each subject. (ii) High-dimension low-sample size data. In this paper, we tackle 3D medical image sequences, and each volume is high-resolution three-dimensional images with millions of voxels, while each sequence has only tens of image scans for regression. (iii) Semantic richness but with subtle temporal changes. Each volume has detailed spatial information about tissue structures, which is non-trivial to generate; at the same time, the temporal changes of these tissues are often subtle, which is difficult to capture without a special design or treatment to model the temporal dynamics.\nTo address the above challenges, there are two categories of regression approaches, i.e., the optimization-based methods like geodesic regression [15,9,11] and the learning-based methods like regression based on diffusion models [21,16]. Geodesic regression extends linear regression to Riemannian manifolds, which is developed in the framework of Large Deformation Diffeomorphic Metric Mapping (LDDMM)[2]. By generalizing diffeomorphic image registration to temporal image data, the regression can compactly model the spatial deformations over time [2,15]. However, solving the underlying optimization problem is computationally expensive. Therefore, a simplified approximation method, i.e., Simple Geodesic Regression (SGR) [11], has been proposed, which decouples the iterative optimization of regressing geodesics into pairwise image registrations. To further reduce the computational time with the help of deep learning techniques, the Fast Predictive Simple Geodesic Regression (FPSGR) [9] is proposed by utilizing a fast predictive registration method. Although this method is computationally efficient, its regression accuracy is limited by its assumption of linear temporal changes.\nThe diffusion-based model is a recent popular alternative to generate high-quality images. One recent image regression method is the Sequentially Aware Diffusion Model (SADM) [21], which augments diffusion models with a sequence-aware transformer as a conditional module. Like geodesic regression, diffusion-based methods can also handle the missing data issue and allow for autoregressive image sequence generation during inference. However, diffusion-based methods likely introduce unwanted structures into the generated images since they are learning-based techniques and have no constraints like diffeomorphic deformations in geodesic regression to ensure the topological preservation and differential homeomorphism properties of the generated images. Other limitations are the requirements of massive data, a long training process, extensive memory usage, and high time consumption during inference.\nIn addition to the previously mentioned regression methods, several time series modeling approaches utilize spatio-temporal transformers combined with attention mechanisms [1,13]. However, these methods are associated with substantial computational overhead and lack the ability to directly constrain diffeomorphism, making them more suitable for simpler tasks like human action recognition rather than for reconstructing high-resolution 3D medical images. Alternatively, Generative Adversarial Network (GAN) based methods with attribute embedding [20] convert the generation of medical image time series into a multivariable autoregressive problem. Despite this, GAN methods often face convergence challenges during training, and the constraints imposed by reconstruction loss terms to maintain subject identity are limited.\nTherefore, we stick to the optimization-based methods like geodesic regression by using diffeomorphic deformations to drive the image generation over time, but relax its linear dynamic assumption to model more complex dynamics. Fortunately, the neural ordinary differential equations (Neural ODEs) [6] provide a neural network based solution for addressing numerous dynamic fitting problems, which is successfully adopted to model deformable image registration, such as NODEO proposed in [19]. Inspired by NODEO, we generalize the Neural ODEs to the image space and handle image regression on a couple of images in a sequence via neural network based optimization. In particular, we propose a model called NODER, which converts the velocity field op-"}, {"title": "Method", "content": "We consider an unparameterized 3D image as a discrete solid, where the position of its i-th voxel can be represented as: $x_i \\in \\Omega \\subseteq \\mathbb{R}^3$, where $\\Omega$ represents the 3D image domain. The positions of all voxels in the image can be represented by an ordered set: $q = \\{x_i\\}_{i=1}^{N}$. Here, $N = D \\times H \\times W$ represents the total number of voxels in the image, and $D, H, W$ denote the depth, height, and width of the image, respectively. We denote the domain where the voxel cloud resides as $\\Pi$, then we have $q \\in \\Pi$.\nNow we denote an image sequence as: $\\{(I_k, t_k)\\}_{k=0}^{L-1}$, where $L$ represents the length of the image sequence, $I_k$ represents the k-th, and $t_k$ is its associate time like age. The\ndeformation occurring within an image over time is essentially a mapping from the original spatial positions at a starting point to the new spatial positions at the next time point, which can be represented as: $\\psi : \\Omega \\rightarrow \\Omega$. On this basis, the identity mapping $Id = \\psi_0$ can be defined as: $\\psi_0(x) = x$, for all $x \\in q$. In many applications, we desire the deformation field $\\psi$ to possess the properties of smoothness and diffeomorphism.\nThe objective function of the deformable image registration is defined as:\n$J(\\psi; I_m, I_f) = S(I_m(\\psi(q_0)), I_f) + R(\\psi),$   (1)\nwhere $q_0$ represents the initial voxel cloud without any deformation. The term $S(\\cdot, \\cdot)$ denotes a similarity metric, used to measure the similarity between the moving image $I_m$ deformed by $\\psi$ and the fixed image $I_f$. The term $R(\\cdot, \\cdot)$ represents the regularization constraint applied to the deformation field. By generalizing image registration to the temporal regression, the objective function is updated as:\n$J(\\psi; \\{(I_k, t_k)\\}_{k=1}^{L-1}) = \\sum_{k=1}^{L-1}(S(I_0(\\psi_k(q_0)), I_k) + R(\\psi_k)).$  (2)\nIn this way, we regress the image sequence and generate an image trajectory, where the generated images are as close as possible to the corresponding images in the original sequence, while imposing the smoothness constraints on the deformation fields."}, {"title": "Formulation of Image Regression in Neural ODEs", "content": "From a system perspective, neural ODEs represent vector fields as a continuous-time model of neural networks. It has been widely used as a general framework for modeling high-dimensional spatio-temporal chaotic systems using convolutional layers, demonstrating its ability to capture highly complex behaviors in space and time. Therefore, we consider the trajectory of the entire voxel cloud as the solution of the following first-order ordinary differential equation (ODE):\n$\\frac{dq}{dt} = v_\\theta(q(t), t), \\ \\text{s.t.} \\ q(0) = q_0 = Id,$  (3)\nwhere $v_\\theta(\\cdot)$ is a parameterized network that describes the dynamics of voxel cloud deformation, $q_0$ represents the initial state of the voxel cloud at $t = 0$, which corresponds to an identity map. The varying velocity field over time indicates non-stationary dynamics, which is fundamentally different from SGR with stationary dynamics.\nThe trajectory of $q$ is generated by integrating the above ODE under the initial condition $q_0$. Assuming the voxel cloud evolves from $t = 0 \\text{ to } t = t_k (k = 1, 2, ..., L-1)$, the voxel cloud obtained at $t = t_k$ is given by the following equation:\n$\\psi_k(q_0) = q(t_k) = q_0 + \\int_{0}^{t_k} v_\\theta(q(t), t) dt.$  (4)\nIn particular, the computation of this flow field map is performed using numerical integration methods such as the Euler method [4]. The time $t$ can be parameterized by the\ntotal number of steps and the corresponding step size adopted by the solver. Therefore, the task of finding the transformation $\\psi$ becomes the search for the optimal parameter set $\\theta$ that describes $v_\\theta$. The optimization problem becomes:\n$\\underset{\\theta \\in \\Theta}{\\text{arg min}} \\sum_{k=1}^{L-1} \\Big(S \\Big(I_0 \\Big(q_0 + \\int_{0}^{t_k} v_\\theta(q(t), t) dt\\Big), I_k\\Big) + R(\\psi_k, V_\\theta) \\Big)$  (5)\nwhere $\\Theta$ represents the entire parameter space. Since Neural ODEs typically require numerical solvers and take many steps to approximate flows, they will incur significant memory overhead if all gradients along the integration steps need to be stored during backpropagation. Hence, the Adjoint Sensitivity Method (ASM) [6,17] has been implemented for optimizing Neural ODEs with constant memory gradient propagation, allowing our framework to interpolate any number of time steps between $t = 0$ and $t = s$ with a constant memory overhead.\nDue to the complexity of high-dimensional data, solving Neural ODEs directly in the original space incurs significant computational costs. Therefore, we bring the above image regression formulation into a latent space, using a pair of pre-trained encoder-decoder networks to reduce the dimension of deformations, as shown in Fig. 1. We apply diffeomorphic VoxelMorph [7,8] on a large 3D MRI dataset to estimate the deformations between image pairs and use these estimated deformations to guide the pre-training of the auto-decoder. At the training stage of our regression model, we fine-tune the decoder. Overall, the final framework of our NODER can be represented as:\n$\\frac{dy}{dt} = u_\\theta(y(t), t), \\ \\text{s.t.} \\ y(0) = Encoder(q_0), \\ y(t_k) = y_0 + \\int_{0}^{t_k} u_\\theta(y(t), t) dt.,$\n$q(t_k) = K(Decoder(y(t_k))),$   (6)\nwhere $Encoder(\\cdot)$ and $Decoder(\\cdot)$ represent the encoder and decoder, respectively, following the design in [18]. $K$ denotes a smoothing kernel used to smooth the deformation fields obtained after decoding. $u_\\theta$ is a parameterized network like $v_\\theta$ but in the latent space, which is used to estimate dynamics. In the dynamic network $u_\\theta$, we extract features from the latent space through continuous convolutional downsampling. These features are then flattened into one-dimensional vectors and added to the input time embedding, achieving fusion between the latent space features and time. Finally, we reconstruct the output of the fully connected layers, restoring the one-dimensional vector to the shape of the compressed three-dimensional deformation field. The overview of our model is presented in Fig. 1.\nWe choose the normalized cross-correlation (NCC) as the loss function for the similarity term S. The regularization term R consists of two parts:\n$R(\\psi) = \\lambda_1 L_{smt} + \\lambda_2 L_{bdr} = \\lambda_1 \\frac{1}{N} \\sum_{x \\in q} (||\\nabla \\psi(x)||^2) + \\lambda_2 \\frac{1}{N} \\sum_{d \\in D} \\sum_{b \\in B} |\\psi_{d,b}(x)||^2,$\t(7)\nwhere the first term $L_{smt}$ constrains the smoothness of the spatial gradients within the deformed voxel cloud, and the second term $L_{bdr}$ represents the $L_2$-norm constraint on the boundary of the deformation field. Here, $N, N_{bdr}, D = \\{d_1, d_2, d_3\\}$, and B ="}, {"title": "Experiments", "content": "We conducted experiments on two medical datasets, including a 3D MRI brain image dataset ADNI (Alzheimer's Disease Neuroimaging Initiative) [14] and the cardiac dataset ACDC [3]. We compare our method with two advanced medical image regression baselines, FPSGR [9] and SADM [21]. Finally, we perform ablation experiments to demonstrate the effects of a series of smoothness constraints within the network.\n(1) ADNI [14]. The ADNI dataset consists of 3D brain MRI images collected from 2,334 subjects. Each subject has an image sequence of 1 to 16 time points, resulting in 10,387 MRI images. All images went through preprocessing steps including denoising, bias field correction, skull stripping, and affine registration to the SRI24 atlas. All brain images are standardized to a size of 144 \u00d7 176 \u00d7 144 with a spacing of 1mm \u00d7 1mm \u00d7 1mm and applied histogram equalization. The intensity of each image volume is normalized within [0, 1]. We select 1,568 subjects that have more than two image scans as our dataset for experiments. For each subject, we randomly select 20% time points for the test and the remaining images are used for training and validation.\n(2) ACDC [3]. The ACDC (Automatic Cardiac Diagnosis Challenge) dataset consists of cardiac MRI images from 100 training subjects and 50 testing subjects. We follow SADM [21] and borrow its pre-processed and partitioned ACDC dataset. We take the\nimage sequence from the ED (the End-Diastole of the cardiac cycle) to the ES (End-Systole) and resize it to 12 image frames and each frame has a size of 128 \u00d7 128 \u00d7 32.\nTo evaluate the quality of the generated images, we use three metrics, including the Normalized Root Mean Square Error (NRMSE), the Structural Similarity (SSIM), and the Peak Signal-to-Noise Ratio (PSNR). Also, we quantify the smoothness of a deformation field by calculating the percentage of its voxels with negative Jacobian determinants. Regarding the inference time, we implement our models and FPSGR on a single RTX 3090 GPU and report their memory cost and the average time of 5 forward inferences. Since SADM needs more GPU memory, we implement it on A100-PCIE-40GB GPU and then report its computational cost. For other inference costs, we load the model on a single RTX 3090 GPU and record the time and storage required for one forward inference, averaging multiple forward inferences to obtain the average costs.\nFor the ACDC dataset, we compare our method with both FPSGR and SADM, while on the ADNI dataset, we have only FPSGR as the baseline, since SADM cannot handle it even with an A100 GPU. Due to the lack of ground truth and other technique issues, we replace the registration networks of FPSGR with the diffeomorphic VoxelMorph [8], which is pre-trained on the ADNI dataset.\nIn the specific implementation of NODER, we choose the average smoothing kernel with a window size of 15 and a sliding stride of 1. The optimizer is Adam, with a learning rate set to 0.005. The construction of Neural ODE relies on the torchdiffeq toolkit [5], where the solving method is set to RK4 (fourth-order Runge-Kutta method with a fixed step size). The relative error tolerance (rtol) is set to 1e-3, and the absolute error tolerance (atol) is set to 1e-5. The coefficients \u03bb\u2081 and \u03bb\u2082 for the loss functions Lsmt and Lbdr are set to 0.05 and 0.0001, respectively. For image sequences from a single subject, we train our model for a total of 300 epochs."}, {"title": "Conclusion and Discussion", "content": "In this work, we propose the NODER method, leveraging the powerful representation capability of neural networks to simulate the underlying dynamics of brain or cardiac deformation trajectories. Through solving ordinary differential equations, we achieve fitting regression on existing medical image time series, thus enabling the generation of desired images at any time point. Our method is based on the theoretical basis of deformable registration and resamples the first image of each subject through the deformation field to generate a new image. The loss terms we use in this paper explicitly impose diffeomorphic constraints, thus maintaining accurate anatomical information to some extent. Experimental results on large-scale 3D MRI datasets demonstrate that our method outperforms existing state-of-the-art methods, FPSGR and SADM, by predicting more accurate image volumes. In future work, we consider incorporating the learning-based methods to further reduce the inference time cost and make it more practical. Also, exploring ways to improve the smoothness of the deformation fields is another direction for our future work."}]}