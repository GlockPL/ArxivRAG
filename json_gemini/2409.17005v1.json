{"title": "Models Can and Should Embrace the Communicative Nature of Human-Generated Math", "authors": ["Sasha Boguraev", "Ben Lipkin", "Leonie Weissweiler", "Kyle Mahowald"], "abstract": "Math is constructed by people for people: just as natural language corpora reflect not just propositions but the communicative goals of language users, the math data that models are trained on reflects not just idealized mathematical entities but rich communicative intentions. While there are important advantages to treating math in a purely symbolic manner, we here hypothesize that there are benefits to treating math as situated linguistic communication and that language models are well suited for this goal, in ways that are not fully appreciated. We illustrate these points with two case studies. First, we ran an experiment in which we found that language models interpret the equals sign in a humanlike way-generating systematically different word problems for the same underlying equation arranged in different ways. Second, we found that language models prefer proofs to be ordered in naturalistic ways, even though other orders would be logically equivalent. We advocate for AI systems that learn from and represent the communicative intentions latent in human-generated math.", "sections": [{"title": "1 Introduction", "content": "Language Models sometimes rely on heuristics and statistics rather than being perfectly compositional idealized reasoners, especially in domains like math and logic [23, 28, 30, 35, 36, 38]. Whereas language production and comprehension involve some idealized composition using abstract rules [6, 18] but also a lot of memorization and pragmatic inference [7, 14], math and logic are domains where it seems like an idealized compositional system is required for obtaining precise solutions. Indeed, whether an expression is written $5+ x = 7$ or $7-5 = x$ or \u201cWhat is 5 less than 7?\u201d or \u201cSeven frogs were sitting on a log. Five left. How many are there now?", "in total\" in a word problem, they should add up all the numbers [33]. While the \u201cheuristic": "eyword-based direct translation approach may be less cognitively taxing, it is also prone to translation errors [40]. Students who report adopting the more involved strategy of parsing a math word problem into a structured mental model, and then planning computation and evaluating the solution in that space are more successful problem solvers [17].\n\nTaken together, these ideas might make it seem like the goal of AI math models should be to leave the messy domain of language behind and translate expressions into symbolic representations. And, indeed, combining language models with symbolic provers has proven successful in a variety of math and reasoning domains [3, 12, 16, 27, 37, 43].\n\nHere, we argue that there can be something lost by entirely disregarding the context. We introduce the Communicative Math Hypothesis: Math is constructed by people, for people, and as such, there are conventions and pragmatics that people bring to the production and comprehension of mathematical expressions\u2014communicative interpretations that go beyond the purely symbolic and that can be well studied using the tools of linguistics and cognitive science. The choice to write $3x +9$ instead of $3(n + 3)$ conveys something to the reader, even though they are equivalent. Similarly, the proof of a theorem is not only a formalization that could be computationally verified, but is itself a communicative act, with intention of being internalized and understood by others.\n\nDrawing on research in math education that we believe is underappreciated in machine learning, we make the case for AI researchers to take the Communicative Math Hypothesis seriously. We present some initial proof-of-concept experiments showing that LLMs pick up on these communicative regularities. We argue that this information should not always be ignored or explained away, but is a crucial component of human mathematics."}, {"title": "2 Case Study One: Equations are Asymmetric", "content": "Asymmetry in human mathematics interpretations has long been studied in math education. In particular, there is a wealth of literature on the perils of grade-school-aged children's asymmetrical understanding of math \u2013 that is, a difficulty in reasoning with a problem such as $= 2 + 4$, despite relative comfort with the complementary equation of $2 + 4 = $ [2, 31]. Even expert mathematicians, though, understand math asymmetrically [25], giving different interpretations of expressions based on what is on the left or right of the equals sign. Here, we present results from a case study demonstrating that LLMs are sensitive to asymmetry in equations and, like humans, do not learn a purely symmetrical interpretation of the equals sign.\n\nMethods To test LLMs' sensitivity to symmetry, we conduct an experiment assessing their ability to reconstruct the equations they used to create a specific word problem, as shown in Figure 1. Formally, we perform a three-step experiment. We first generate a set of n paired forward and reverse equations, denoted as $E = {e_1, e_2, ..., e_n}$, where each paired equation $e_i$ consists of the forward equation $e_i^f$ and the reverse equation $e_i^r$. Thus, we can express each $e_i$ as $e_i = {e_i^f, e_i^r}$. Next, for each of our n pairs, we pass both equations in $e_i$ to GPT-40, and prompt it to generate a corresponding pair of word problems, $w_i = {w_i^f, w_i^r}$, that could be solved by $e_i$, with $W = {W_1 ... W_n}$. We finally ask the LLM to extract the equations $e'_i = {e'_i^f, e'_i^r}$ for each $w_i \u2208 W$, with $E' = {e'_1 . . . e'_n}$. Our hypothesis is that across all n equations, the LLMs will more often recover $e'_i^f$ from $e_i^f$ and $e'_i^r$"}, {"title": "3 Case Study Two: Mathematical Rules and Proofs Have Orders", "content": "Our second case study focuses on mathematical communication of the sort more likely to take place among professional mathematicians: mathematical rules and proofs. Proofs, especially, are widely used in academic math, as well as related fields, and are duly an area of major focus for AI for math.\n\nProofs are written to communicate truths that are, in some sense, tautological. Nonetheless, math-ematicians have strong expectations and interpretations about the directionality of equation. For instance, there are generalized principles associated with equal signs, like that the right side of the equation expounds upon or explains the left side [25]. Thus, while $a = b$ and $b = a$ are equivalent statements by our agreed-upon set of axioms and inference rules, the choice of one or the other might communicate a different message when used in a proof.\n\nTo explore the preferred orderings used by mathematicians in proofs and rules, Mirin and Dawkins [25] utilize a set of breaching experiments. Breaching experiments are a class of experiments which try to break rules in an attempt to confirm their existence [34]. In particular, the authors first provided expert mathematicians with a host of formal mathematical equations, such as the distributive rule or an inductive proof. However, these equations were ordered in an unnatural manner \u2013 that is in the case of rules, orders which are not commonly encountered in formal mathematical texts, or in the case of proofs, orders in which steps do not logically follow from one to the next. The authors measured whether these mathematicians reported any perceived breaches, with any such breaches providing evidence for the existence of the mathematicians' ordering preferences. Our case study into LLM ordering preferences in formal mathematics follows in this vein, measuring LLM surprisals for various natural (extant) and unnatural (unobserved) equation orderings.\n\nMethods Our set of mathematical equations consists of all examples used in the breaching ex-periments of Mirin and Dawkins [25]. This totals ten different examples, six of which are one line equivalences, expressing common mathematical rules, and the other four of which are a series of equivalences comprising a longer proofs. Each example further contains a brief textual introduction before the series of equivalences.\n\nWe first split each equation into its individual expressions. We then generate every possible ordering of a given equation by permuting the order of these individual expressions. Finally, for each model we calculate the average per-token surprisal for every ordering of expressions in a given equation, conditioned on that equation's textual introductions. Our calculations are performed using the minicons package [26], a wrapper around Huggingface's transformers package [41].\n\nIn this case study, we use the instruction-tuned variants of four models: LLaMa 3.1 8B [10], Mistral 7B v0.3 [21], Mathstral 7B [1], and Qwen2-Math 7B[42]."}, {"title": "4 Conclusion", "content": "We focused our experiments on equation asymmetry and proof ordering, showing that LLMs learn extra-symbolic communicative information in both domains. But these principles encompass a much wider set of phenomena. For instance, several phenomena identified as reflecting LLMs' brittleness can be fruitfully seen as contributing to the communicative interpretation of math.\n\n\u2022 Even though they don't matter logically, variable names matter for communicating math (e.g., functions are often $f$ and $g$). This pattern extends to programming as well. [19, 24]\n\n\u2022 Logically extraneous or pragmatically anomalous information can matter for inferences about how expressions are interpreted [29, 36].\n\n\u2022 The choice of notation and the phrasing of the instructions/prompt can matter for how problems are solved [15, 20].\n\nSeeing these aspects of LLMs as possible features, and not bugs, could be an important step in developing AI systems that can work with humans. For instance, working mathematicians were long limited to purely symbolic theorem provers. Such systems in isolation neglect the more human aspects of math, ignoring differences in style and comprehensibility. Perhaps we should be developing proof assistants that are sensitive to these regularities in human proof-writing and other communicative cues. LLM-based proof systems offer the promise of mathematical assistants that can work with people [9], alongside them and not just for them as blackbox tools.\n\nWhile necessarily fuzzier than purely symbolic representations, these communicative principles are not lawless or illogical but can be studied, systematized, and modeled as rational behavior-as they are in linguistics and cognitive science [7, 11, 13]. We join Zhang et al. [44] in their call for a cognitive science perspective on AI and mathematics, centering the role of math as a group activity and communicative endeavor. The math of the people, by the people, for the people, shall not perish from our models."}, {"title": "A Equation Generation and Prompting in Case Study One", "content": "A.1 Equation Generation\n\nFor step one of this experiment, we create our equation sets as follows. We first create two independent expressions, each of which consists of two operands, either added or subtracted to each other. One of these operands is a single digit number, with the other being a variable quantity in x with a single digit coefficient. All operands, operations, and choice of which operands are the variable quantity are selected at random. We then form our pair of complimentary equations by placing an equals sign between these two expressions, in both orders. That is, given the two expressions a and b, our pair of complimentary equations would be $a = b$ and $b = a$. To illustrate further, a generated set of expressions may include, for example, $2x + 3 = 4 - 5x$ or $8 - 5x = 2 + 3x$, but not $2x = 3$, $4x + 5y = 8x - 2$, or $9x * 2 = x - 4$.\n\nA.2 Prompting Methods\n\nOur experimental methodology necessitates prompting GPT-40 twice for each equation in our evaluation set: once to create a word problem from a given equation, and once to try and recover an equation given a math word problem. Below, we describe the prompts used for each of these steps.\n\nA.2.1 Prompting for Word Problem Creation\n\nFor a given equation, EQUATION, we first prime GPT-40 with the following command:\n\n\"You are a helpful middle school math teacher.\"\n\nWe then prompt the model to generate a word problem using the following prompt:\n\n\"Create a grade-school math problem representing the following equation:\n{EQUATION}. Make sure your problem is clear, concise, represents every term of\nthe equation, and ends in a question mark. Generate just the problem and nothing\nelse.\"\n\nA.2.2 Prompting for Equation Recovery\n\nFor a given math word problem, PROBLEM, we first prime GPT-40 with the following command:\n\nYou are a helpful assistant.\n\nWe then prompt the model to recover the equation that is represented by PROBLEM with the following prompt:\n\n\"What is the underlying math equation represented by the following situation:\n{PROBLEM}. Use the letter 'x' for the unknown quantity. Please do not explain, or\nwrite any accompanying text, give just a single equation and nothing else.\""}, {"title": "B Equation Set for Case Study Two", "content": "We use the following set of equations for evaluating model order preferences in formal mathematics.\nWe name each following subsection as they are labeled in Figure 2. Each equation is presented below\nin its \"natural\" form. All TEXformatting used to render the following sections, up-to the end of the equations, is included in our experiment.\n\nB.1 DIFFERENCE QUOTIENT\n\nThe difference quotient of a function g is defined to be\n\n$\\frac{g(x + h) - g(x)}{(x + h) - x}$"}, {"title": "B.2 DISTRIBUTIVE", "content": "The distributive law tells us that for all numbers x, y, and z,\n\n$x(y + z) = xy + xz$"}, {"title": "\u0392.3 \u0395\u03a7\u03a1\u039fONENTS DIFF RULE", "content": "Recall the Properties of Exponents:\n\n$\\frac{b^x}{b^y} = b^{x-y}$"}, {"title": "B.4 EXPONENTS POWER RULE", "content": "Recall the Properties of Exponents:\n\n$(b^x)^y = b^{xy}$"}, {"title": "B.5 EXPONENTS PROD RULE", "content": "Recall the Properties of Exponents:\n\n$b^x * b^y = b^{x+y}$"}, {"title": "\u0392.6 \u041d\u043e\u043cOMORPHISM", "content": "Let (S, *) and (S', *') be binary algebraic structures. A homomorphism from \u3008S, *) to (S', *') is a\nfunction\n: S \u2192 S' such that for all x, y \u2208 S,\n\n$\\phi(x * y) = \\phi(x) *' \\phi(y)$"}, {"title": "B.7 INDUCTION", "content": "The following is a portion of a proof by induction that for all natural numbers k, $k^3 \u2013 k$ is divisible\nby 6. At this point in the proof, it has been assumed that $n^3 \u2013 n$ is divisible by 6, and it is being\nshown that $(n + 1)^3 \u2013 (n + 1)$ is therefore also divisible by 6.\n\n$(n + 1)^3 \u2013 (n + 1) = (n^3 + 3n^2 + 3n + 1) \u2212 (n + 1)$\n\n$= (n^3 + 3n^2 + 3n + 1) \u2013 (n + 1)$\n\n$= (n^3 \u2013 n) + (3n^2 + 3n)$\n\n$= (n^3 \u2013 n) + 3n(n + 1)$"}, {"title": "B.8 PRODUCT RULE", "content": "The product rule for derivatives says that if f and g are differentiable functions, then\n\n$fg' + f'g = (fg)'$"}, {"title": "B.9 PROOF", "content": "Theorem 1. Suppose (S,*) and (S', *') be binary algebraic structures, and \u00a2 is an isomorphism\nfrom (S, *) onto (S',*'). Further suppose that e is a left identity element in \u3008S, *). Then $(e) is a\nleft identity element in (S', *').\n\nProof. Let s' be an element of S'. Since & is onto, there exists some s \u2208 S such that $(s) = s'.\nHence\n\n$s' = \\phi(s) = \\phi(e*s) = \\phi(e) *' \\phi(s) = \\phi(e) *' s'$"}, {"title": "B.10 SET THEORY", "content": "The following is a proof in a set theory textbook that if a is a transitive set, then U(a+) = a. Note\nthat a transitive set is defined to be a set a such that all members of a are subsets of a, and a+ is\ndefined to be a \u222a {a}\n\nProof.\n\n$(\\bigcup a^+) = (\\bigcup a \\cup {a})$\n\n$= (\\bigcup a) \\bigcup (\\bigcup {a})$\n\n$= (\\bigcup a) \\bigcup a$\n\n$= a$"}]}