{"title": "Exposing Assumptions in AI Benchmarks through\nCognitive Modelling", "authors": ["Jonathan H. Rystr\u00f8m", "Kenneth C. Enevoldsen"], "abstract": "Cultural AI benchmarks often rely on implicit assumptions about measured con-\nstructs, leading to vague formulations with poor validity and unclear interrelations.\nWe propose exposing these assumptions using explicit cognitive models formulated\nas Structural Equation Models. Using cross-lingual alignment transfer as an exam-\nple, we show how this approach can answer key research questions and identify\nmissing datasets. This framework grounds benchmark construction theoretically\nand guides dataset development to improve construct measurement. By embracing\ntransparency, we move towards more rigorous, cumulative AI evaluation science,\nchallenging researchers to critically examine their assessment foundations.", "sections": [{"title": "Introduction", "content": "Following the rapid advancements in Generative AI, marked by the release of Chat-\nGPT, benchmarks for such models have proliferated, encompassing a range of concepts including\n'reasoning' [Sprague et al., 2024] and 'cultural alignment' [Wang et al., 2023]. However, combining\ninsights from these diverse benchmarks remains challenging due to unclear measurement targets and\nmethodologies [Jacobs and Wallach, 2021, Raji et al., 2021].\n\nPsychometrics, experienced in measuring complex constructs, offers valuable approaches for ad-\ndressing these challenges [Jacobs and Wallach, 2021, Hughes, 2018]. Previous work has applied\npsychometric methods to LLM benchmarking, defining intelligence as skill acquisition efficiency\n[Chollet, 2019] and reducing sample sizes for LLM evaluation [Polo et al., 2024]. However, most\nexplicit psychometric modelling has focused on applying human-oriented psychometric batteries to\ngenerative models [Hagendorff et al., 2024, Jiang et al., 2024, Serapio-Garc\u00eda et al., 2023].\n\nWe propose extending psychometrics-inspired approaches to elucidate Large Language Model (LLM)\n'traits', encompassing capabilities and attributes with no clear \u2018better' or 'worse' [e.g., political\nstances; R\u00f6ttger et al., 2024]. Our contribution lies in explicitly using cognitive models [Wilson and\nCollins, 2019], operationalized through Structural Equation Modeling [SEM; Suhr, 2006], to expose\nassumptions in how test batteries relate to theoretical constructs. This approach enables rigorous\naggregation of multiple datasets, identifies gaps in existing benchmarks, and develops a sounder\ntheoretical foundation for understanding LLM traits [Shanahan, 2022].\n\nTo illustrate, we (re)construct the concept of 'cultural alignment' using SEM, focusing on cross-\nlingual alignment transfer. This example demonstrates how our framework improves construct\nvalidity, highlights missing datasets, and provides clear testable hypotheses. By offering a meta-\nevaluation perspective, our approach contributes to the workshop's goal of evaluating AI evaluations,\nproviding a robust framework for assessing traits and their relationships across model evaluations."}, {"title": "(Re)constructing Crosslingual Alignment Transfer", "content": "Building on the need for improved evaluation\nmethodologies outlined in the introduction, we now turn to a specific case study in cross-lingual\nalignment transfer. The concept of 'alignment' in LLMs is predominantly studied using English\ndata [Kirk et al., 2024], implicitly assuming cross-lingual transferability. However, recent empirical"}, {"title": "Limitations", "content": "As mentioned in the previous section, a key challenge with our approach is avoiding\nthe 'Formalism Trap' [Selbst et al., 2019]. In machine learning, it's common to transform structural"}]}