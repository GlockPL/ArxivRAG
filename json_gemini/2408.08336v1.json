{"title": "Graph representations of 3D data for machine learning", "authors": ["Tomasz Prytu\u0142a"], "abstract": "We give an overview of combinatorial methods to represent 3D data, such as graphs\nand meshes, from the viewpoint of their amenability to analysis using machine learning\nalgorithms. We highlight pros and cons of various representations and we discuss some\nmethods of generating/switching between the representations. We finally present two concrete\napplications in life science and industry. Despite its theoretical nature, our discussion is in\ngeneral motivated by, and biased towards real-world challenges.", "sections": [{"title": "Introduction", "content": "3D data appears naturally in science and\nindustry, and covers a wide range of do-\nmaing, from bioimaging (microscopy images,\nCT scans), through molecular chemistry, to\n3D modeling and design plans [GZW+20]. A\n3D representation is often advantageous as\nit describes a real world (hence 3D) object\nmore accurately, compared to e.g., 2D pro-\njections or slices. However, a drawback of\nthe 3-dimensional representation is the com-\nputational cost of the analysis, as the extra\ndimension, together with scarcity typical for\n3D data, makes it very challenging to apply\nlearning algorithms that scale effectively - to\nthe extreme where already analysis of a sin-\ngle sample can be on a verge of capability of\na single machine.\nIn our work we have investigated whether\nthis challenge can be overcome, or at least\npartially alleviated by employing lighter rep-\nresentations of 3D data graphs, meshes,\npoint clouds, and simplicial complexes, and\nthe corresponding deep learning algorithms\nthat operate on those representations. Our\nfindings suggest that in many real-world sit-\nuations it is the case, and we hope that prac-\ntitioners of machine learning can adapt some\nof our learnings to their work with 3D data.\nOur approach is backed by recent develop-\nments in the field Geometric Machine Learn-\ning, both theoretical [BBC+21] and software-\noriented [FL19].\nIn the specific domain of preclinical re-\nsearch and biomedical imaging, we are plan-\nnig to release a set of guidelines for analyz-\ning 3D data using a variety of combinatorial\nmethods, in cases where classical 3D deep\nlearning is not feasible.\nAnother benefit of using combinatorial rep-\nresentations is their potential for explain-\nability. Since such representations usually\ncome at a higher level of abstraction (e.g.,\na graph modeling a human pose), their el-\nements (edges, vertices) naturally carry se-\nmantic meaning, and thus it may be easier to"}, {"title": "3D data", "content": "In this section we present an overview of some\nrepresentations of 3D data, and we compare\nthem from a viewpoint of analysis using deep\nlearning methods. The overview is biased by\nthe specific problems we encountered, and by\nthe overarching theme of studying combina-\ntorial representations.\nVolumetric\nThe main challenge with 3D data compared\nwith 2D data is the computational complex-\nity of algorithms to analyze this data. This\nstems from the fact the most common rep-\nresentation of 3D data is by voxels (3D ana-\nlogue of pixels), which means that a volume is\nrepresented by a dense grid of 3-dimensional\ncubes, each of the cubes storing information\nabout e.g., RGB color or intensity. This is a\nstandard format used in many imaging tech-\nniques, and thus can be considered as a 'fun-\ndamental' or 'raw' format for 3D data. It is a\ntrivial observation that the number of voxels\ngrows exponentially with the dimension, and\nthus already a jump from 2D to 3D has severe\nconsequences for compute requirements.\nAnother issue, which is somehow more a\ncharacteristic of 3D data in general, is its\nsparsity. Whether it is a microscopy image\nof a neuron cell, or a 3D design for manu-\nfacturing, a lot of voxels are unoccupied, and\nthe actual object of interest fills only a small\nportion of the volume, see Figure 2. How-\never, one does not know it in advance, and\ntherefore the standard 3D algorithms (like\ne.g., Convolutional Neural Networks) process\nthe entire volume voxel by voxel.\nFinally, 3D data is typically more scarce\nthan 2D data: in many cases one uses an\nexpensive and time consuming procedure to\nproduce a single 3D image (e.g. 3D mi-\ncroscopy) and thus by default one deals with\nmuch smaller datasets than in other contexts.\nAn important feature of volumetric rep-\nresentations it that it is a so-called Eu-\nclidean representation, meaning that there is\na global coordinate system of XYZ coordi-\nnates. Thus, after agreeing on a given size of\nthe volume, all the examples have the exact\nsame size, and thus the algorithm for analy-\nsis does not have to accommodate size differ-\nences between samples.\nThere are a plenty of other ways to rep-\nresent the 3D data (and switch between the\nrepresentations) that can have some advan-\ntages. All the following representations are\nthe examples of non-Euclidean representa-\ntions.\nMesh\nMesh is a tessellation of a surface of a 3D ob-\nject by triangles (or other polygons). It de-\nscribes geometry well and removes the spar-\nsity problem. This is because to represent\na mesh, one only needs to store the position\nof vertices and encode which vertices form\ntriangles/polygons. As such, the mesh for-\nmat does not offer an intrinsic global coordi-\nnate system, but it has a resemblance of the\ncoordinate system locally, as the neighbor-\nhoods of vertices are all disks. This means\nthat around every vertex, mesh looks like a\nplanar region, and thus one can use tech-\nniques for processing 2D images, appropri-\nately adjusted. From the deep learning view-\npoint there are a few architectures to han-\ndle meshes (mostly variants of MeshCNN\n[HHF+19]), which cleverly exploit geomet-\nric features of the mesh without referring to\nits embedding into R\u00b3 (like angles and edge\nlengths). There are also some novel pooling\nand unpooling operations which are specific"}, {"title": "Point cloud", "content": "A point cloud is a collection of points in\na 3D space, described by their coordinates\ntogether with some additional features, like\nRGB color or the intensity value. They\n'occur naturally', e.g., from Lidar scanning.\nPoint cloud offers a lot of flexibility of non-\nEuclidean data, together with some struc-\nture of Euclidean data. However, often point\ncloud format is too loose to capture geomet-\nric information as there is no apparent re-\nlation between the points, besides what one\ncan infer from their attributes. For example,\ngiven only points and no other information\nlike edges or triangles, it may be impossible\nto tell two objects apart. Another challenge\nis the size point clouds often contain mil-\nlions or even billions of points. This, how-\never, can be remedied, as it is relatively easy\nto subsample points. This in fact offers some\nextra flexibility, as one can choose different\ngranularity for different parts of the object,\nbased on the level of detail one wishes to cap-\nture.\nGraphs\nMany tasks in 3D analysis require under-\nstanding the geometry of the object (e.g.,"}, {"title": "The \u20182-step process' in graph\nanalysis", "content": "Given a 3D data representation, to bene-\nfit from Graph Neural Networks and other\ngraph related tools, one first must turn the\ndata into a graph format. This is the first\nstep of the 2-step process, the second step be-\ning the analysis of the graph itself. This task\ncan already be nontrivial, where one may\nneed to use domain specific knowledge and\nvarious tricks. There are a couple of stan-\ndard methods, but they usually do not lead\nto optimal graphs:\n\u2022 Mesh \u2192 graph: take the 1-skeleton, i.e.,\nonly vertices and edges, forget about tri-\nangles/polygons. (Loses face informa-\ntion. One can subdivide mesh before-\nhand to retain some info about poly-\ngons.)\n\u2022 Voxel \u2192 graph: let voxels be nodes and\nconnect every voxel to 6 of its neighbors.\n(Results in a graph as large as the vol-\nume itself.)\n\u2022 Point cloud \u2192 graph: add edges based\non the proximity of vertices (may re-\nsult in a very large number of edges, if\nthe distance threshold is too low). Note\nthat 'proximity' here does not necessar-\nily mean spacial proximity, but can be\nan arbitrary user-chosen metric.\nIt is worth mentioning that some architec-\ntures, e.g., PointNet++ [QYS+17] create the\ngraph dynamically while training for a down-\nstream task, thus effectively merging steps 1\nand 2 into one pipeline."}, {"title": "Graph generation methods", "content": "We investigated mostly the so-called 'skele-\ntonization methods', whose aim is to pro-\nduce a 1-dimensional skeleton of a 3D ge-"}, {"title": "Applications in concrete\ncases", "content": "In this section we present findings from two\nprojects in collaboration with life scientists\nand a software company, respectively.\n3.1 Mitochondrial\nmuscle cells\nnetworks in\nThe area of bioimaging and preclinical re-\nsearch and development is a particularly good\ntestbed for our programme, as one almost al-\nways deals with the major challenges of 3D"}, {"title": "AI for 3D design generation\nand analysis", "content": "We\npilot\nproject under the AI:Denmark initiative\n(https://aidenmark.dk/) with\nsoftware company called RD8 Technology\n(https://rd8.tech). RD8 Technology investi-\ngates 3D design drawings for manufacturing,\nand offer improvements to those designs,\nfrom the point of view of functionality,\nmaterial use, durability, robustness to manu-\nfacturing imperfections, etc. They work with\n3D CAD models (see Figure 7) and process\nthem using, among other measures, para-\nmetric and analytic geometry. They plan to\nintroduce AI and a data-driven approach to\nimprove their model application and func-\ntionality. There are multiple possibilities\nfor doing so, to name a few: an AI-aided\nautomatic generation of designs, automatic\nsuggestions for improvements to existing\ndesigns, or detection of bottlenecks or errors.\nBehind many of these improvements there\nis a need for an ML-architecture capable\nof learning geometry, topology, and all the\nphysical constraints (like e.g., movement or\nbending of parts). In our pilot project, we\nisolate a fairly simple task to see how one\ncan begin creating such an architecture.\nwe"}]}