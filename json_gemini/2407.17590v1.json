{"title": "Is computational creativity flourishing on the dead internet?", "authors": ["Terence Broad"], "abstract": "The dead internet theory is a conspiracy theory that\nstates that all interactions and posts on social media\nare no longer being made by real people, but rather\nby autonomous bots. While the theory is obviously\nnot true, an increasing amount of posts on social media\nhave been made by bots optimised to gain followers and\ndrive engagement on social media platforms. This paper\nlooks at the recent phenomenon of these bots, analysing\ntheir behaviour through the lens of computational cre-\nativity to investigate the question: is computational cre-\nativity flourishing on the dead internet?", "sections": [{"title": "Introduction", "content": "The dead internet theory is a conspiracy theory that emerged\nin the late 2010's or early 2020's that states that large parts of\nthe internet, in particular on social media are no longer oc-\ncupied by humans and human generated content, but rather\nposts by AI-driven bots that are designed to control or influ-\nence human behaviour (IlluminatiPirate 2021).\nWhist the theory emerges from the fringes of the inter-\nnet, stemming in conspiratorial thinking as a way of ex-\nplaining broad-based changes to society from nefarious ac-\ntors, many commentators have observed that there is a grain\nof truth to the theory (Tiffany 2021). With the emergence\nand widespread adoption of generative deep learning, which\nis able to generate media in many domains to a plausible\nhuman level of fidelity, the possibility of bots acting au-\ntonomously or semi-autonomously on social media in order\nto garner influence is no longer a speculative possibility, but\na real phenomenon on many social media platforms.\nEngagement driven social media bots, or AI influencers\n(Walter 2024), that are optimised to maximise common so-\ncial media metrics now exist on many social media platforms\nsuch as X (formerly Twitter), Facebook, Instagram, Reddit\nand TikTok. A recent report investigating web bots and in-\nternet traffic estimates that nearly 50% of web traffic is now\ndriven by bots (Imperva 2024).\nBots on social media for the purposes of generating art,\npoetry or other kinds of content that are designed explicitly\nas computationally creative agents or artistic experiments in\nthemselves are not new (Veale and Cook 2018). What is new\nabout the phenomenon of these Al influencers is that they are\nnot explicitly listed as bots, but instead posing as real peo-\nple on social media or accounts that aggregate and share the\ncreative work of real people. It is likely these bots are being\ndeveloped by spammers and scammers to create accounts\nthat have a large amount of engagement so that they traf-\nfic off the platforms to content-farm sites where advertising\nrevenue can be generated (Koebler 2024a).\nThis paper will investigate the recent emergence of bots\non various social media platforms, that appear to be explic-\nitly optimised to drive engagement, and are acting in an at\nleast somewhat autonomous fashion. This paper will analyse\nthe output and behaviour of these models through the lens of\ncomputational creativity to determine if these bots are act-\ning as autonomously computationally creative systems in the\nwild."}, {"title": "Social Media and Content Farms", "content": "Social media platforms, such as Facebook, Instagram, Red-\ndit and TikTok rely on content generated by users as the\nmeans of engagement on their platforms and to leverage\nnetwork effects through an 'architecture of participation'\n(O'Reilly 2005). The business model of these platforms is\nprimarily to serve advertisements alongside user generated\ncontent.\nSince the invention of the Facebook 'News Feed' in 2006,\ncontent is usually presented to users on these sites on a\nhomepage, showing them the content from accounts that\nthey follow (Arrington 2006). For many years the presen-\ntation of the feed has not been given in a chronological man-\nner, but recommendation algorithms are used to to person-\nalise the experience for users and will prioritise some con-\ntent over other content in an algorithmic fashion. Since\n2022, Facebook's Feed algorithm has been pushing content\nonto feeds from accounts that users do not follow to compete\nwith TikTok's popular 'For You Page' (Heath 2022) which\nemploys collaborative filtering to personalise the feeds of\nusers to show them content from creators they primarily do\nnot follow (Boeker and Urman 2022).\nContent farms are websites or media creation organisa-\ntions that make low effort and low quality content that makes\nmoney from advertisements, traditional online content farms\nwould have paid freelancers to write articles that would get\ntraffic from organic search, news aggregators and social me-\ndia traffic (Bakker 2012). With the decline in revenues from"}, {"title": "AI-Powered Content Farming", "content": "Algorithmic content farms have existed long before the re-\ncent wave of generative AI tools. Content farms that make\nanimated musical videos on the platform YouTube that take\nadvantage of the young children's passive engagement with\nYouTube and it's auto-play featured that is powered rec-\nommendation algorithms, have been widely observed and\ncriticised (Bridle 2017). The new wave of content farm-\ning is making use of generative AI to produce spam con-\ntent and is being actively promoted by the platforms them-\nselves into unsuspecting users feeds (DiResta and Goldstein\n2024). These bots accounts appear to be making use pri-\nmarily of modern text-to-image generation using techniques\nsuch as latent diffusion (Rombach et al. 2022) and large\nlanguage models for text generation such as the Generative\nPre-Training (GPT) class of models (Radford et al. 2018) to\nautomate text generation on the click-farm websites.\nAn example of an AI-powered content farm is the so-\ncial media account Inspiring Designs and associated website\n(inspiringdesigns.net), active on the Facebook, In-\nstagram and TikTok platforms (with hundreds of thousands\nof followers on each platform). The posts and articles doc-\nment new fictional product categories, such as 'power-tool\ntoilets' 'cowboy-hat showers' and 'pickup-\ntruck strollers'. The articles are very likely written by large\nlanguage models and are written in a highly consistent style\nand structure. The goal of this site appears to be in order\nto host ads and generate revenue from affiliate links to the\ne-commerce website Amazon for products that bear little re-\nsemblance to the ones described in the articles.\nAnother example of a content farm that makes use of gen-\nerative AI is the TikTok account Globetrots. Globetrots does\nnot fully use generative AI, but rather amalgamates content\nfrom satellite imagery, publicly available information based\non national and international statistical rankings (i.e. 'top 5\nmost dangerous motorways in the UK', or 'top 10 Biggest\nIKEA stores in the USA'). This account make use of text-\nto-speech voiceovers which are available to all users in Tik-\nTok and widely used by AI spam content producers (Koebler\n2024b). These videos are sometimes set to musical melodies\nand'sung' by AI in various different genres."}, {"title": "'Shrimp Jesus' and Combinatorial Creativity", "content": "One of the images that quickly rose to prominence and the\nattention of this phenomenon on Facebook was the now in-\nfamous 'Shrimp Jesus' This became a widely"}, {"title": "Religious Pareidolia", "content": "Fascination with religious pareidolia (the perception of reli-\ngious iconography in otherwise random of ambiguous pat-\nterns) has long existed (Obadia 2018). Tabloid newspapers\nare regularly writing articles about people seeing images of\nJesus in toast (Willis 2014) and various other objects.\nMany bot driven accounts make use of the phenomenon of\npareidolia of religious iconography to make posts that drive\nengagement. shows examples of two posts of pho-\ntorealistic imagery that have the pareidolia effect of images"}, {"title": "Engagement Hacking as Extrinsic Motivation", "content": "The intention behind the development of these bot accounts\nis likely not for them to be explicitly creative agents, but\nto maximise engagement on social media platforms in the\nmost efficient and inexpensive way possible. The speed with\nwith generative deep learning can produce realistic media in\na mass produced fashion (Smith and Cook 2023) means that\nthis technology has now become the cheapest and fastest\nway to generate content and drive engagement. Templates\nfor posts and combinations of different concepts can be iter-\nated on extremely quickly, with near instantaneous feedback\nwith likes, comments and shares from other social media\nusers.\nSocial media engagement metrics are clearly acting as a\nmeans of extrinsic motivation for the agents posting on these\naccounts in some way. depicts images depicting\nfictitious people in distressing situations who are celebrat-\ning their 'birthday'. These images are posted with captions\nlike 'Happy Birthday To Me, but I haven't received any\nblessings yet' and are clearly designed in order to deceive\nusers on the platform into liking the posts and commenting"}, {"title": "Framing of Authorship", "content": "Many of these accounts on Facebook and other social media\nplatforms frame themselves as aggregators of content, which\nare sharing (or reposting) the work of individuals, in the vein\nof a 'meme page' or 'meme aggregator' (\u0162\u0103ran 2014). The\npages themselves are not framing themselves as the creators\nof the works, but simply the aggregators of content.\nOften times on these pages the work is framed as having a\nhuman creator that is present in the generated image. shows several examples of these images which with the\nimages and associated captions are clear examples of decep-\ntive framing (Cook et al. 2019) being utilised to drive en-\ngagement. These images are not of real people but deepfake\nhuman avatars that are generated as part of the image, pre-\nsumably included in the prompt of a text to image generator.\nBy including images of the supposed human creators in\nthe images, these bot accounts are seeking to enhance the"}, {"title": "Computational Creativity in the Wild", "content": "With the expense and difficulty in moderating social media\nplatforms, and the difficult in detecting AI generated con-\ntent, this phenomena is unlikely to disappear anytime soon.\nBots are already generating content on social media in at\nleast a semi-autonomous fashion. The computational cre-\nativity research community will need to start taking this phe-\nnomena seriously. By examining these examples in a criti-\ncal fashion, this will further our understanding how mod-\nels of computational creativity are being utilised by nefari-\nous actors to generate spam and and scam content. These\nbots are utilising creative processes for ulterior motives with\nlittle consideration for the suitability of the content being\nproduced. This could be considered a form of dark creativ-\nity (Cropley et al. 2010) or malevolent creativity (Cropley,\nKaufman, and Cropley 2013).\nIf we are to understand these systems we will need to start\nanalysing them from an external perspective to try to infer\nhow they operate, as the likelihood is that many of the cre-\nators of these bot accounts will not be forthcoming about\nthis. Platform restrictions permitting, the behaviour of these\nbot accounts could be analysed in a systematic way to try\nand reverse engineer their behaviour, such as prompts used\nand evolution over time. Leakage of text from prompts into\nwriting on the images may also be a means to investigate\nthe instructions given to these models. In addition, qualita-\ntive approaches could also be taken to better understand the\nbehaviour of these bot accounts."}, {"title": "Conclusion", "content": "This paper suggests that models of computational creativ-\nity, whether intentionally or not, are being employed by ne-\nfarious actors to maximise engagement on social media in\norder to generate spam, to underpin content farming opera-\ntions, and to generate engagement on accounts that can later\nbe used for promoting scams. This is a clear delineation\nfrom, and emergence of computational creativity from the\ntraditional worlds of academic research and creative prac-\ntice, where computationally creative systems have previ-\nously been developed and disseminated. The goal of these\nbots are likely not necessarily to be creative agents per se,\nbut simply a means to an end for some ulterior profit mak-\ning motive.\nHow much of the behaviour of these bots is fully au-\ntomated, and how much creativity autonomy in turn they\nhave (Berns et al. 2021) is not currently possible to deter-\nmine. Evaluating the extent of autonomy in these systems\nrequires further investigation. However, the nature of the\ngenerations, both in their highly abnormal combinations of\nconcepts, their seemingly regular and mechanical behaviour,\nand the perceived lack of content moderation of items being\nposted seem to suggest that these bots are acting in at the\nvery least a semi-autonomous fashion.\nAs more and more of the internet is being populated\nby content generated by generative AI and automated bots,\nmoving us closer towards a 'dead internet', then the prospect\nof these agents acting in creative ways, whether intentionally\nor not should be taken seriously. Studying the behaviour of\nthese bots through the lens of computational creativity will\nhelp us understand the impact that these bots are having on\nboth cultural production and the broader media ecology."}]}