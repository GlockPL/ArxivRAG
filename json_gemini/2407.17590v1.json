{"title": "Is computational creativity flourishing on the dead internet?", "authors": ["Terence Broad"], "abstract": "The dead internet theory is a conspiracy theory that states that all interactions and posts on social media are no longer being made by real people, but rather by autonomous bots. While the theory is obviously not true, an increasing amount of posts on social media have been made by bots optimised to gain followers and drive engagement on social media platforms. This paper looks at the recent phenomenon of these bots, analysing their behaviour through the lens of computational creativity to investigate the question: is computational creativity flourishing on the dead internet?", "sections": [{"title": "Introduction", "content": "The dead internet theory is a conspiracy theory that emerged in the late 2010's or early 2020's that states that large parts of the internet, in particular on social media are no longer occupied by humans and human generated content, but rather posts by AI-driven bots that are designed to control or influence human behaviour (IlluminatiPirate 2021).\nWhist the theory emerges from the fringes of the internet, stemming in conspiratorial thinking as a way of explaining broad-based changes to society from nefarious actors, many commentators have observed that there is a grain of truth to the theory (Tiffany 2021). With the emergence and widespread adoption of generative deep learning, which is able to generate media in many domains to a plausible human level of fidelity, the possibility of bots acting autonomously or semi-autonomously on social media in order to garner influence is no longer a speculative possibility, but a real phenomenon on many social media platforms.\nEngagement driven social media bots, or AI influencers (Walter 2024), that are optimised to maximise common social media metrics now exist on many social media platforms such as X (formerly Twitter), Facebook, Instagram, Reddit and TikTok. A recent report investigating web bots and internet traffic estimates that nearly 50% of web traffic is now driven by bots (Imperva 2024).\nBots on social media for the purposes of generating art, poetry or other kinds of content that are designed explicitly as computationally creative agents or artistic experiments in themselves are not new (Veale and Cook 2018). What is new about the phenomenon of these Al influencers is that they are not explicitly listed as bots, but instead posing as real people on social media or accounts that aggregate and share the creative work of real people. It is likely these bots are being developed by spammers and scammers to create accounts that have a large amount of engagement so that they traffic off the platforms to content-farm sites where advertising revenue can be generated (Koebler 2024a).\nThis paper will investigate the recent emergence of bots on various social media platforms, that appear to be explicitly optimised to drive engagement, and are acting in an at least somewhat autonomous fashion. This paper will analyse the output and behaviour of these models through the lens of computational creativity to determine if these bots are acting as autonomously computationally creative systems in the wild."}, {"title": "Social Media and Content Farms", "content": "Social media platforms, such as Facebook, Instagram, Reddit and TikTok rely on content generated by users as the means of engagement on their platforms and to leverage network effects through an 'architecture of participation' (O'Reilly 2005). The business model of these platforms is primarily to serve advertisements alongside user generated content.\nSince the invention of the Facebook 'News Feed' in 2006, content is usually presented to users on these sites on a homepage, showing them the content from accounts that they follow (Arrington 2006). For many years the presentation of the feed has not been given in a chronological manner, but recommendation algorithms are used to to personalise the experience for users and will prioritise some content over other content in an algorithmic fashion. Since 2022, Facebook's Feed algorithm has been pushing content onto feeds from accounts that users do not follow to compete with TikTok's popular 'For You Page' (Heath 2022) which employs collaborative filtering to personalise the feeds of users to show them content from creators they primarily do not follow (Boeker and Urman 2022).\nContent farms are websites or media creation organisations that make low effort and low quality content that makes money from advertisements, traditional online content farms would have paid freelancers to write articles that would get traffic from organic search, news aggregators and social media traffic (Bakker 2012). With the decline in revenues from"}, {"title": "AI-Powered Content Farming", "content": "Algorithmic content farms have existed long before the recent wave of generative AI tools. Content farms that make animated musical videos on the platform YouTube that take advantage of the young children's passive engagement with YouTube and it's auto-play featured that is powered recommendation algorithms, have been widely observed and criticised (Bridle 2017). The new wave of content farming is making use of generative AI to produce spam content and is being actively promoted by the platforms themselves into unsuspecting users feeds (DiResta and Goldstein 2024). These bots accounts appear to be making use primarily of modern text-to-image generation using techniques such as latent diffusion (Rombach et al. 2022) and large language models for text generation such as the Generative Pre-Training (GPT) class of models (Radford et al. 2018) to automate text generation on the click-farm websites.\nAn example of an AI-powered content farm is the social media account Inspiring Designs and associated website (inspiringdesigns.net), active on the Facebook, Instagram and TikTok platforms (with hundreds of thousands of followers on each platform). The posts and articles document new fictional product categories, such as 'power-tool toilets' 'cowboy-hat showers' and 'pickup-truck strollers'. The articles are very likely written by large language models and are written in a highly consistent style and structure. The goal of this site appears to be in order to host ads and generate revenue from affiliate links to the e-commerce website Amazon for products that bear little resemblance to the ones described in the articles.\nAnother example of a content farm that makes use of generative AI is the TikTok account Globetrots. Globetrots does not fully use generative AI, but rather amalgamates content from satellite imagery, publicly available information based on national and international statistical rankings (i.e. 'top 5 most dangerous motorways in the UK', or 'top 10 Biggest IKEA stores in the USA'). This account make use of text-to-speech voiceovers which are available to all users in TikTok and widely used by AI spam content producers (Koebler 2024b). These videos are sometimes set to musical melodies and'sung' by AI in various different genres."}, {"title": "'Shrimp Jesus' and Combinatorial Creativity", "content": "One of the images that quickly rose to prominence and the attention of this phenomenon on Facebook was the now infamous 'Shrimp Jesus' (Figure 2). This became a widely shared and discussed example of how many accounts on social media were using automated methods to combine concepts to make images and drive engagement on posts. The nonsensical combinations of concepts combined with the mechanical regularity with which images are posted by theses accounts are the main explanatory factors that have convinced many people that pages were being run in a partly or wholly autonomous fashion (Koebler 2024a).\nMany people assume that these images were not just generated by a person entering text prompts into a text-to-image generator, but that some form of automated process was instrumental in creating the text prompts used to generate these images. This is evidenced by the mechanical regularity with which these accounts are posting new images and continuously trying new combinations of visual concepts, regardless of how nonsensical they may be. If these accounts are in fact driven by automated algorithms then, whatever underlying process that is generating these images is clearly an example of combinatorial creativity (Boden 2004) or bisociation (Koestler 1964), where more than one concept is brought together to make a new concept."}, {"title": "Religious Pareidolia", "content": "Fascination with religious pareidolia (the perception of religious iconography in otherwise random of ambiguous patterns) has long existed (Obadia 2018). Tabloid newspapers are regularly writing articles about people seeing images of Jesus in toast (Willis 2014) and various other objects.\nMany bot driven accounts make use of the phenomenon of pareidolia of religious iconography to make posts that drive engagement. Figure 3 shows examples of two posts of photorealistic imagery that have the pareidolia effect of images"}, {"title": "Engagement Hacking as Extrinsic Motivation", "content": "The intention behind the development of these bot accounts is likely not for them to be explicitly creative agents, but to maximise engagement on social media platforms in the most efficient and inexpensive way possible. The speed with with generative deep learning can produce realistic media in a mass produced fashion (Smith and Cook 2023) means that this technology has now become the cheapest and fastest way to generate content and drive engagement. Templates for posts and combinations of different concepts can be iterated on extremely quickly, with near instantaneous feedback with likes, comments and shares from other social media users.\nSocial media engagement metrics are clearly acting as a means of extrinsic motivation for the agents posting on these accounts in some way. Figure 4 depicts images depicting fictitious people in distressing situations who are celebrating their 'birthday'. These images are posted with captions like 'Happy Birthday To Me, but I haven't received any blessings yet' and are clearly designed in order to deceive users on the platform into liking the posts and commenting"}, {"title": "Framing of Authorship", "content": "Many of these accounts on Facebook and other social media platforms frame themselves as aggregators of content, which are sharing (or reposting) the work of individuals, in the vein of a 'meme page' or 'meme aggregator' (\u0162\u0103ran 2014). The pages themselves are not framing themselves as the creators of the works, but simply the aggregators of content.\nOften times on these pages the work is framed as having a human creator that is present in the generated image. Figure 5 shows several examples of these images which with the images and associated captions are clear examples of deceptive framing (Cook et al. 2019) being utilised to drive engagement. These images are not of real people but deepfake human avatars that are generated as part of the image, presumably included in the prompt of a text to image generator. By including images of the supposed human creators in the images, these bot accounts are seeking to enhance the"}, {"title": "Computational Creativity in the Wild", "content": "With the expense and difficulty in moderating social media platforms, and the difficult in detecting AI generated content, this phenomena is unlikely to disappear anytime soon. Bots are already generating content on social media in at least a semi-autonomous fashion. The computational creativity research community will need to start taking this phenomena seriously. By examining these examples in a critical fashion, this will further our understanding how models of computational creativity are being utilised by nefarious actors to generate spam and and scam content. These bots are utilising creative processes for ulterior motives with little consideration for the suitability of the content being produced. This could be considered a form of dark creativity (Cropley et al. 2010) or malevolent creativity (Cropley, Kaufman, and Cropley 2013).\nIf we are to understand these systems we will need to start analysing them from an external perspective to try to infer how they operate, as the likelihood is that many of the creators of these bot accounts will not be forthcoming about this. Platform restrictions permitting, the behaviour of these bot accounts could be analysed in a systematic way to try and reverse engineer their behaviour, such as prompts used and evolution over time. Leakage of text from prompts into writing on the images may also be a means to investigate the instructions given to these models. In addition, qualitative approaches could also be taken to better understand the behaviour of these bot accounts."}, {"title": "Conclusion", "content": "This paper suggests that models of computational creativity, whether intentionally or not, are being employed by nefarious actors to maximise engagement on social media in order to generate spam, to underpin content farming operations, and to generate engagement on accounts that can later be used for promoting scams. This is a clear delineation from, and emergence of computational creativity from the traditional worlds of academic research and creative practice, where computationally creative systems have previously been developed and disseminated. The goal of these bots are likely not necessarily to be creative agents per se, but simply a means to an end for some ulterior profit making motive.\nHow much of the behaviour of these bots is fully automated, and how much creativity autonomy in turn they have (Berns et al. 2021) is not currently possible to determine. Evaluating the extent of autonomy in these systems requires further investigation. However, the nature of the generations, both in their highly abnormal combinations of concepts, their seemingly regular and mechanical behaviour, and the perceived lack of content moderation of items being posted seem to suggest that these bots are acting in at the very least a semi-autonomous fashion.\nAs more and more of the internet is being populated by content generated by generative AI and automated bots, moving us closer towards a 'dead internet', then the prospect of these agents acting in creative ways, whether intentionally or not should be taken seriously. Studying the behaviour of these bots through the lens of computational creativity will help us understand the impact that these bots are having on both cultural production and the broader media ecology."}]}