{"title": "PRISMe \u2013 A Novel LLM-Powered Tool for Interactive Privacy Policy Assessment", "authors": ["VINCENT FREIBERGER", "ARTHUR FLEIG", "ERIK BUCHMANN"], "abstract": "Protecting online privacy requires users to engage with and comprehend website privacy policies, but many policies are difficult and tedious to read. We present PRISMe (Privacy Risk Information Scanner for Me), a novel Large Language Model (LLM)-driven privacy policy assessment tool, which helps users to understand the essence of a lengthy, complex privacy policy while browsing. The tool, a browser extension, integrates a dashboard and an LLM chat. One major contribution is the first rigorous evaluation of such a tool. In a mixed-methods user study (N=22), we evaluate PRISMe's efficiency, usability, understandability of the provided information, and impacts on awareness. While our tool improves privacy awareness by providing a comprehensible quick overview and a quality chat for in-depth discussion, users note issues with consistency and building trust in the tool. From our insights we derive important design implications to guide future policy analysis tools.", "sections": [{"title": "1 Introduction", "content": "Today, almost every interaction with companies, online services, smart devices, etc. leaves trails of personal data. Companies leverage cutting-edge techniques like hyper-personalization, powered by Artificial Intelligence (AI) and Machine Learning (ML) with real-time data sources [43], to create detailed user profiles and enable real-time micro-targeting [16]. This results in significant privacy risks, such as automated influence [7], manipulation [54], and potential security breaches. Yet, while companies invest heavily in acquiring and analyzing their users' personal data, users without extensive research or background knowledge lack awareness of the associated privacy risks [29] or have distorted perceptions of risks [31], which results in irrational decisions [1].\nRegulations such as the GDPR [25] force companies to communicate data management practices and users' rights regarding their data in privacy policies, to enhance users' decision-making. However, evidence shows that companies focus on compliance, effectively targeting lawyers instead of users [78], so users rarely read privacy policies [61].\nUsing LLMs to automatically assess privacy policies is a promising approach to solve this issue [37, 72, 91]. Yet, no prior work evaluates their impact on understandability and risk awareness from a user's perspective through a user study. Additionally, to the best of our knowledge, no existing tool combines LLM-based automatic privacy policy assessment with: (i) dynamic evaluation criteria not focused on compliance but tailored to type of platform (e.g., e-commerce or health services); (ii) an interactive dashboard; and (iii) a chat for open conversations with the LLM with (iv) customizable explanations and responses that adapt to the user's preferences for detail and complexity.\nTo address these gaps, we introduce PRISMe (Privacy Risk Information Scanner for Me), a Chrome extenstion with the above features designed to empower users in making informed privacy decisions. To evaluate PRISMe, we conducted a scenario-based, mixed-methods user study with a qualitative focus. It involved 22 participants from diverse backgrounds, acquired via different channels, to answer the following research questions:\nRQ.1 How understandable is the information provided by PRISMe to users with varying privacy knowledge levels?\nRQ.2 How efficiently does PRISMe help users quickly grasp key information about data protection?\nRQ.3 To what extent does PRISMe enhance users' awareness and understanding of data protection issues?\nRQ.4 How suitable and usable is PRISMe for everyday use across different user contexts and tasks?\nWe make the following contributions:\n\u2022 We provide an assessment of the current landscape of transparency-enhancing tools for privacy policies.\n\u2022 Drawing from existing tools, we introduce our LLM-based interactive privacy policy assessment tool, PRISMe, a Chrome extension that we will make publicly available.\n\u2022 We evaluate PRISMe, targeting a wide variety of users and providing the first qualitative evaluation of an LLM-based privacy policy assessment tool through our user study (N=22).\nOur findings suggest that PRISMe can tremendously help users who lack awareness and comprehension regarding privacy-related risks when surfing online [31]. While users find PRISMe intuitive and report it provides valuable insights into privacy issues by communicating relevant privacy protection information, there are areas for improvement, such as formatting, easier comparability between websites, and occasional inaccuracies due to LLM hallucinations. These findings mark an important step towards designing user-friendly, interactive tools for enhancing privacy awareness and enabling users to make more informed decisions.\nPaper structure: After reviewing related work in Section 2, we detail our research concept in Section 3 and introduce PRISMe in Section 4. Section 5 outlines our research method and provides details about our main user study. We present our results in Section 6 and discuss them in Section 7. Section 8 concludes."}, {"title": "2 Related Work", "content": "2.1 Challenges with Privacy Policies\nPrivacy policies are intended to bridge the knowledge asymmetry between service providers and users, empowering individuals to make informed decisions about their data [53, 93]. However, their design appears far from user-centered, prioritizing legal compliance over understandability, as if written by lawyers for lawyers rather than for the individuals the policies aim to empower [78]. These documents are thus often lengthy and complex, and vague phrasing and poor contextualization hinder users to find answers to their specific questions [56, 90]. Legal compliance under frameworks like the General Data Protection Regulation (GDPR) in Europe [25] and similar laws elsewhere [13] does not guarantee comprehensibility, as persuasive language can obscure unethical practices and create an illusion of trustworthiness [6, 65]. Consent mechanisms, often tied to these policies, tend to use manipulative \"dark patterns\" [47, 60]. Practical accessibility issues further hinder user engagement, with policies inconsistently placed or hidden altogether [66]. Thus, users reading privacy policies is rare and users understanding them is even rarer [70, 80]. Instead, users face symptoms of overwhelm like consent fatigue [15, 78], risking being exposed to unethical privacy practices without knowing the implications, which results in informational unfairness [27]. These long-standing issues are magnified by the rise of generative AI, with its privacy risks [50], and Augmented Reality, which tracks vast multimodal data, further complicating data management practices and exacerbating transparency issues [4-6].\nAddressing these challenges requires innovative tools that not only simplify policies but also enable users to meaningfully interact with them and receive easy-to-understand answers to their questions.\n2.2 The Landscape of Transparency-Enhancing Technologies\nTo counter the informational unfairness, several transparency-enhancing technologies (TETs) have been proposed. Although semi-automated approaches exist to assess privacy policies [28, 86, 88], our tool also targets users without any expertise in privacy. Hence, we focus on automatic analysis of privacy policies.\n2.2.1 Approaches reliant on a privacy language representation of the policy. Early efforts relied on the now-obsolete P3P privacy language [22]. Privacy Bird [23], the first tool for automatic assessments, allowed users to preconfigure privacy sensitivity levels, ran in the background while browsing, and relied on static, rule-based risk evaluations to display warnings using a traffic-light system. However, its fixed criteria limit adaptability to the fast-changing digital landscape. More importantly, the tool lacks a mechanism for users to query specific details about the policy and the tool's warnings, which limits its capacity to educate users or address their individual concerns. For PRISMe, we draw inspiration from evaluating privacy policies in the background with minimal user intervention and presenting the results through a traffic-light system.\nThe first privacy nutrition label [44] visualized key policy aspects in a tabular format, highlighting data collection types, purposes, and consent procedures. Similar to Privacy Bird, its main limitations are static, predefined criteria and no mechanisms for users to ask questions or explore policy details interactively. For PRISMe, we borrow from the idea of a concise, visual summary of key privacy policy aspects to enable users to quickly grasp the most critical privacy-related practices without needing to read the entire policy.\nMore recently, Gr\u00fcnewald et al. [34] developed a layered privacy dashboard with icons and a separate RASA X-based chatbot based on their previously introduced TILT policy language [35]. While the chatbot facilitates interactive exploration of privacy policies, its reliance on predefined conversation flows restricts its capacity for natural, dynamic"}, {"title": "2.2.2 Reliance on processed data.", "content": "Many tools rely on already processed data [36] or crowd-sourced privacy policy annotations [74, 89]. For example, Poli-see [36] uses icons on a circular dashboard to visualize data transmission within the provider's organization (second ring) or to third parties (third ring). Hovering over icons reveals data usage and consent requirements. ToS;DR [74] grades common web services and provides color-coded (green, yellow, and red) lists of potential issues. While these approaches reduce the computational complexity of real-time processing and leverage collective knowledge to identify common privacy concerns, such reliance introduces scalability and adaptability limitations."}, {"title": "2.2.3 Automated assessment with Natural Language Processing (NLP).", "content": "With the discontinuation of P3P and advances in NLP, automated privacy policy assessments shifted to plain-text policies. In 2013, the Usable Privacy Project began automating assessments using NLP and creating corpora to support this [75]. Of their work, the most relevant for our tool are PriBot [39] and the underlying Polisis [38], which uses privacy-specific word embeddings and ML classifiers trained on the OPP-115 dataset [87]. Polisis predicts privacy icons, while PriBot was the first notable approach to inform users in a chat-based interaction about policy content. It decides whether the user input is a statement or a structured query before ranking which segment of the policy is the most suitable answer. Since the returned segments are direct policy quotes, users may still struggle with comprehension. In contrast, our LLM-based chat can deliver clearer explanations, cite policy evidence upon request, and handle a broader range of questions beyond the policy text.\nSimilarly, based on Polisis, Windl et al. [90] developed PrivacyInjector, which overlays icons on website elements to show context-relevant privacy policy details, such as cookie information near banners, with additional details in a sidebar. A user study showed the tool enhances users' decisions-making, albeit without significant influence on privacy concerns. While promising, users suggested reducing text length and interpreting the severity of privacy threats. Drawing from these suggestions, our tool interprets these and offers various levels of text lengths.\nDashboard-based approaches have also advanced with NLP improvements. PrivacyInsight [8] does not offer a comprehensive policy overview of potential issues but focuses more narrowly on visualizing data transmission and their purpose, highlighting to what degree personalized data may be linked. While this can raise privacy awareness, interpretations are left to the user.\nPrivacyCheck [59] evaluates a privacy policy through 10 static questions on user control and GDPR, respectively (17 of them yes/no questions). The respective scores are calculated by ML models. While it determines the \"market sector\" of a website and displays three competitors in the same sector with better scores, users not satisfied with the responses to mostly binary questions cannot query specific information or ask for further or simpler explanations."}, {"title": "2.2.4 LLM-based privacy policy assessment.", "content": "More recently, the capabilities of LLMs to extract key details from privacy policies, such as contact information and third parties have been investigated. Rodriguez et al. [72] find that \"ChatGPT has proven to be as effective as traditional NLP techniques\". Hamid et al. [37] assessed the capabilities of Bard, BingAI, and ChatGPT-4 in answering questions related to a privacy policy, finding that \"ChatGPT-4 distinguishes itself with consistent performance and adaptability\". While both works are benchmarks rather than user-facing tools, their results encourage us to use OpenAI's GPT-40 [62]. Woodring et al. [91] present Privacify, an LLM-based approach closest to"}, {"title": "2.2.5 ML classifiers.", "content": "Another body of literature focuses on ML classification of legal compliance of privacy policies targeted at legal experts. Claudette [17] uses a Support Vector Machine (SVM) to check GDPR compliance across criteria like information comprehensiveness, substantive compliance, and clarity. Their study indicated that \"none of the analyzed privacy policies meets the requirements of the GDPR\" [17]. Another SVM-driven approach [77] automatically assigns \"positive\" or \"negative\" tags to each statement in the policy (trained on manually tagged sentences from 4 privacy policies) and calculates scores from the (relative) amount of positive and negative tags. Similarly, GDPR-completeness is classified by several methods [3, 84, 92]. PrivacyGuide [83] uses 11 criteria, primarily based on the GDPR, with ratings (green, yellow, red) that reflect compliance (good, neutral, bad). It uses classifiers to identify relevant sentences from the privacy policy, which are then fed into a risk prediction engine to identify the rating, and displayed when hovering over each criterion. PrivacyGuide provides direct policy quotes as evidence for its scoring, but does not provide ways to simplify and explain the given quote. The criteria are fixed and users cannot query specific information.\nThe above approaches target GDPR compliance assessment (mostly) from a legal perspective. These can help identify violations of GDPR requirements, such as inadequate information comprehensiveness or lack of user consent mechanisms. While valuable for legal experts and organizations, these tools have significant limitations in communicating or explain resulting scores and potential risks to users without legal expertise. For instance, a score indicating a 75% compliance may leave users uncertain about the implications for their data. Moreover, the fixed criteria used by these tools may overlook non-compliance issues that users deem important but are orthogonal to compliance, such as (allowed) data sharing practices with specific third parties users do not approve of. Hence, our focus is less on automatic assessment of (GDPR) compliance, but more on providing insights into privacy policies beyond jurisdictional constraints, allowing users to dig deeper regarding what they deem important."}, {"title": "2.2.6 Shorter and tailored privacy policies.", "content": "Efforts to condense privacy policies yielded mixed results. While highlighting critical practices can boost awareness [24], removing well-known facts to highlight more critical issues can reduce overall user awareness [32]. Goram et al. [33] explored tailoring privacy information to user preferences and concluded \"a long road lies ahead\". Presenting all relevant information concisely and tailored to user interests remains the most promising approach, which we thus pursue."}, {"title": "2.2.7 TETs beyond privacy policy analysis and tools for service providers.", "content": "While PRISMe focuses on analyzing raw policy text, TETs extend beyond privacy policy analysis. For instance, Van Kleek et al. [85] visualize smartphone app data flows based on traffic logs, and Gerber et al. [30] explore nudging techniques to enhance consent awareness. Some tools focus on service providers, aiding compliance through user control dashboards [68] or privacy icons for service providers to easier convey privacy-related information [40, 57, 73]. However, without regulatory pressure, privacy icons remain underutilized. We chose not to use them in our dashboard, as they would merely replace single words and require user familiarization."}, {"title": "2.3 Identified Gaps and PRISMe's Position in the TET Landscape", "content": "Since machine-readable privacy policy representations are not yet widespread, pioneering tools that rely on them, e.g., Privacy Bird, can provide inspirations but have limited real-world applicability. Similarly, tools based on processed (crowd-sourced) data face scalability and adaptability issues. Approaches focused on (GDPR) compliance can be valuable to some (e.g., legal experts), but are of limited use to non-expert users when it comes to communicating risks and addressing users' individual preferences or concerns. Static rules and predefined criteria impose a one-size-fits-all solution that limits adaptation to users and evolving privacy practices. Furthermore, the lack of interaction in many tools leaves users without the ability to query specific details or understand the rationale behind evaluations, diminishing their awareness potential and engagement. LLM-based TETs remain in their early stages, with a comprehensive user study of such approaches yet to be conducted.\nPRISMe bridges the identified gaps by integrating automated privacy policy analysis with a user-centered, interactive approach. Leveraging advancements in LLMs, PRISMe bypasses the need for machine-readable representations or pre-annotated and crowd-sourced datasets, and directly analyzes raw, plain-text privacy policies. This capability allows PRISMe to identify and evaluate criteria dynamically (as opposed to static), offering adaptable explanations (as opposed to no or static explanations) and allows user queries on and beyond the policy text. PRISMe's primary focus lies in providing broader insights beyond legal frameworks rather than compliance assessment. By offering layered, personalized explanations and fostering exploratory engagement, PRISMe aims to empower users in making informed privacy decisions regardless of their background knowledge. We evaluate PRISMe through our user study, providing the first comprehensive qualitative evaluation of an LLM-based privacy policy assessment tool."}, {"title": "3 Design Process - Our Road to PRISME", "content": "To develop PRISMe, we compiled a set of design considerations from (i) a review of the concepts and shortcomings of existing tools as detailed in Section 2, (ii) personal experiences of our research group with a history in studying privacy issues, and (iii) an initial interview study serving as a reality check. For the study, we asked five participants (different from the main user study participants, 4 female, 1 male) about their privacy preferences across various online contexts (e.g., social media, online banking, adult media). Participants were sampled from different professional and educational backgrounds. Interview data was analyzed following [55] resulting in codes on attitudes, behavior, motivation, and situations. Analyzing literature and the interviews revealed a general sense of helplessness, a preference for a smooth browsing experience, and low involvement with privacy-related decisions. Based on this, we established the following design considerations to guide development of PRISMe:\nDC.1 Communication should be clear, adaptable, and comprehensible for a wide range of users.\nDC.2 The tool should not disrupt the browsing experience too much and should offer immediate feedback.\nDC.3 There should be an exploratory, ideally easy and engaging aspect to understanding privacy policies.\nDC.4 The tool should adapt to different privacy requirements and across various types of websites.\nFrom these considerations, we initially designed three independent LLM-based facets of the tool focusing on different aspects, each inspired by different elements of related work. These designs were tested within our research group and then refined based on iterative feedback cycles and a pilot study.\nFacet 1: Scrollbar Feedback and Policy Visibility. This facet aimed to make problematic aspects of a privacy policy visible to users without requiring them to open the tool. Inspired by Privacy Bird [23], we used colored scrollbars (green, yellow, or red) to reflect the overall rating of a policy based on the assessed data protection practices. We wanted to raise awareness with minimal intrusion and provide immediate feedback, as suggested by Patil et al. [64]. Users could then view a condensed display of the most critical privacy issues by clicking on the scrollbar, ensuring they received only the most necessary information."}, {"title": "Facet 2: Chat-Based Interactive Exploration.", "content": "This facet centered around an interactive, chat-based interface where users could ask specific questions about the privacy policy and get answers tailored to their level of involvement. It allowed for deeper exploration, encouraging users to engage more actively with privacy issues. We drew inspiration from other privacy chatbots [39] but utilized the flexibility of LLMs to dynamically adapt to user queries. This version required a higher level of user engagement, as users had to think of their own questions."}, {"title": "Facet 3: Dynamic Dashboard Evaluation.", "content": "We designed this facet with inspiration from existing dashboard-based approaches [8, 59, 83], which offer structured privacy evaluations. However, instead of using fixed criteria, we implemented a dynamic assessment approach, where the evaluation criteria were tailored to the specific context of the website (e.g., processing health data vs. an email address). Evaluations were displayed using smileys to communicate the severity of issues, and users could click on these smileys to get more detailed explanations."}, {"title": "Integration into a Comprehensive Solution, PRISMe.", "content": "Following discussions within our research group and with other HCI researchers, we combined these three facets into PRISMe to offer a layered complexity interface similar to Gr\u00fcnewald et al. [34]. PRISMe allows users to interact with privacy policies in a manner that matches their level of interest and expertise, providing more in-depth information the more they explore, see Section 4."}, {"title": "Pilot Study.", "content": "To refine the design of PRISMe, we ran a pilot study with an early prototype and participants (4 male, 2 female) different from the initial interview study and the main study. Based on their feedback, we improved performance by caching LLM assessments and user input, and improved the scraping of policies. We re-arranged frontend interface elements and added a plain-text display of the website's scraped policy. We ensured that individual user preferences on length and complexity are considered in the policy assessment right from the start. Finally, we added speech-to-text as an alternative to typing questions."}, {"title": "4 PRISMe - Privacy Risk Information Scanner for Me", "content": "We explain PRISMe's user interface (Section 4.1), policy assessment (Section 4.2), and backend (Section 4.3) as used in the main user study, after the refinements from the pilot study."}, {"title": "4.1 Frontend - An Interface of Layered Complexity", "content": "Our interface has Point-of-Entry Signaling and Overview, Dashboard, Chat, Settings and Policy Text panels."}, {"title": "4.1.1 Point-of-Entry Signaling.", "content": "When users visit a website, they are automatically alerted to privacy concerns through colored scrollbars and intuitive smiley icons (Figure 2 top left). The smiley icon (green, yellow, or red) reflects the overall privacy policy rating (see Section 4.2) and is the first point of interaction.1 The color-coded smileys provide immediate feedback (DC.2) and do not require technical expertise, ensuring clear communication comprehensible for a wide range of users (DC.1). We positioned the smiley icons on the right-hand side in the middle of the screen height, as this space is rarely covered by website UI elements. However, users can drag it anywhere on the screen, giving users control of how and when they interact with the tool without being forced into unnecessary disruptions (DC.2). In addition, to capture cases where the smiley does get covered, we color the scrollbar accordingly. This feature was inspired by our goal of minimizing the cognitive burden on users, allowing them to engage with privacy issues without feeling overwhelmed.\n\u00b9In case PRISMe fails to find or scrape the website's privacy policy, we display a gray question mark instead of the smiley."}, {"title": "4.1.2 Overview Panel.", "content": "Clicking on the smiley brings users to a Overview Panel (Figure 2 top right) that provides a quick summary of the most critical issues. From here, users can navigate to the dashboard and chat interface. The Overview Panel offers users an immediate view of the most problematic aspects of the website's privacy policy (DC.2). Red highlighting of the most urgent issues (see Section 4.2) makes them immediately apparent without overwhelming users with too much detail at once (DC.1). Links to the chat and the Dashboard Panel give users the option to explore deeper without forcing them into it, supporting adaptability to different information needs from users based on their personal privacy concerns and the current website (DC.4)."}, {"title": "4.1.3 Dashboard Panel.", "content": "The dashboard (Figure 2 bottom right) offers a comprehensive overview of dynamically identified criteria used to evaluate the policy, with the ability to drill down into specific aspects and engage in chat"}, {"title": "4.1.4 Chat.", "content": "We implemented two different chat windows to provide flexible, user-driven exploration (DC.3): one for general questions accessible through the Overview Panel (General Chat), and one for specific criteria accessible through the Dashboard Panel (Criteria Chat, Figure 2 bottom left). They differ in their system prompt (see Appendix A.1). In both, in addition to entering their own questions (by keyboard or voice), users are given three dynamically generated suggestions for questions. Providing suggestions was inspired by Ravichander et al. [69]. Suggestions for follow-up questions are generated again after each answer (which is not streamed but shown once finished) to the previous question. This allows user exploration in a structured way without requiring extensive effort or technical knowledge (DC.1). At the same time, we respect users who wish for a deep-dive using their own custom questions and provide voice and keyboard input options for that.\nSince chats are (inherently) website-specific, an important feature in this context is that when users visit a new website, we include the last asked question for each respective criterion (and the General Chat) from the interactions on the previous website as one of the three suggestions. This facilitates website comparison, e.g., asking the same question on different websites.\nThe chat history for each Criteria Chat and the General Chat is cached for each visited domain and can be deleted by clicking the respective button at the bottom of the Overview Panel. This makes it easier for users to come back to a website assessment and continue the conversation where they left off (DC.2), further facilitating website comparisons."}, {"title": "4.1.5 Other Panels.", "content": "The Settings Panel is accessible through the cogwheel icon in the top right corner of each window. It affects all chats and all future assessments of websites. Users can adjust both the length and complexity of PRISMe's responses with sliders. We offer three levels of length (short, medium, long), and three levels of complexity depending on the user's technical background (no prior knowledge, basic knowledge, expert knowledge) to cater to diverse user groups, ranging from those who need simplified, short explanations to privacy experts seeking more detailed insights (DC.1). In the top bar is another icon that displays a panel with the scraped policy in plaintext. It helps to detect flaws in scrape results and provides users with a sense of transparency, enhancing trust calibration. The top bar also includes a help icon where users can find the most relevant information for using PRISMe outside of lab study conditions."}, {"title": "4.2 Policy Analysis and Rating", "content": "When users change tabs or visit a new website, PRISMe fetches (see Section 4.3) and assesses its privacy policy. The underlying LLM dynamically identifies relevant evaluation criteria and evaluates each of them on a 5-point Likert-scale. On the dashboard, we translate the score into smileys (red: rating 2 or below; yellow: rating 3, green: rating 4 or above). Criteria with a red rating are listed on the Overview Panel as the most pressing issues. For coloring the initial assessment smiley and the scrollbar, we average the individual scores (red: average below 2.5, yellow: average between 2.5 and 3, green: average above 3). Thresholds were hand-calibrated using results from the tool applied to 10 websites known for strong data protection practices like Startpage.com and 10 known for poor practices like TikTok.com, as"}, {"title": "4.3 Backend", "content": "The backend has four components: a privacy policy scraper, a script connecting the LLM API, a script managing the database for policy assessments that can be queried by domain, and an activity logger. All scripts run on Node.js [18].\nThe backend receives the link to the privacy policy from the frontend. The privacy policy scraper scrapes the content with Puppeteer [19] to capture dynamic JavaScript content, and removes irrelevant HTML divs. As web pages display privacy policies in very different ways, the scraping might fail. If the size of the scraped content is less than a threshold, it returns empty text, resulting in a question mark icon in the frontend. Valid policy text is sent to the frontend for further processing. Out of the 100 pages with the most web traffic in the authors' country according to [2] the scraper retrieved 67 correctly. For 12 policies the scraper could not find any links, 7 requests were blocked, 6 were incompletely scraped, 6 of the wrong page (e.g. overview page), and 2 pages had multiple privacy policies for different target groups.\nThe LLM API script handles GPT40-based assessments and GPT40-mini requests for context-aware suggestions of chat questions. The database script stores policy assessments in SQLite to avoid redundant evaluations. The activity logger tracks user activity during our study, such as screen time, feature use, and chat histories. All components except the activity logger run on a Raspberry Pi 4."}, {"title": "5 Study Methodology", "content": "To answer our research questions, we conduct an exploratory lab-based mixed-methods user study (N=22) using three custom scenarios. We detail the full scenario descriptions in the supplementary material.\nScenario 1: Privacy Exploration on a News Media Platform and Payment Provider for its Digital Subscription. The first scenario is designed to assess how users use the tool on their own and to evaluate the depth of their engagement with privacy information. By selecting a news media platform and a payment provider for its digital subscription, we expose participants to common yet complex online services that involve significant data collection. Our motivation is to evaluate whether PRISMe helps users break down and make sense of privacy policies in real-world contexts, targeting RQ.1 (understanding) and RQ.3 (awareness).\nScenario 2: Comparing Privacy Practices of Online Bookstores. The second scenario addresses RQ.2 (efficiency) by measuring how quickly and effectively users compare the privacy policies of four online bookstores (with same prices including delivery) before selecting one for a hypothetical purchase. The chosen online shops have varying degrees of data protection practices. Additionally, it allows us to observe how the tool influences participants' decisions when faced with different levels of privacy protection.\nScenario 3: Free Exploration of Websites. The third scenario explores how PRISMe supports users' natural curiosity and diverse privacy concerns across various web environments. The scenario allows participants to freely explore any website of their choosing, i.e., it provides an opportunity to gauge the tool's engagement potential in their daily lives."}, {"title": "5.1 Collected Data", "content": "Our study is exploratory in nature. We employ a mixed-methods approach and focus on rich qualitative insights complemented by quantitative metrics. Qualitative data includes data from semi-structured interviews and comments participants made during use. The interview guide for our semi-structured interview is in Appendix A.2. Quantitative data includes telemetry data, the System Usability Scale (SUS) [12], and custom 5-point Likert-scale questions, as we did not find suitable, validated questionnaires to measure the contribution to our research questions apart from usability.\nTo gather qualitative insights, we employed an open coding approach based on grounded theory [20, 21], analyzing interview transcripts and participant comments. Telemetry data such as time spent on the different screens of the tool, question and answer lengths, number of used suggestions, and mouse movements were tracked to identify navigation patterns and user behavior. In addition, we recorded the frequency of each feature used and utilized screen-recording for post-hoc analysis. With this, we identified usage patterns, i.e., how decisive participants navigate our application and how features were used. Triangulating this data with the qualitative findings helped provide a comprehensive view of user interactions and responses.\nFor preparing and conducting the interviews we follow the suggestions of Myers [58]. We transcribed the semi-structured interviews using faster-whisper (large-v3) [63, 81], which we ran locally. We manually checked the resulting text output for accuracy and consistent formatting, and analyzed the data using open coding, facilitated by Taguette [71]. The interview transcripts, help requests, questions, and comments made during use were coded by two researchers independently after familiarization with the text and writing initial memos. After initial coding, both authors discussed, aggregated, and cleaned their codes. In total, we created 61 codes and grouped them into six categories. We report our full code book in the supplementary material."}, {"title": "5.2 Participants", "content": "We recruited 22 participants (14 male, 8 female) from various professional backgrounds, including research \u2013 in the field of IT (3), industrial production (3), chemistry (2), law (1) -, university students (4), IT (3), education (2), real estate (1), entertainment (1), handcraft (1), healthcare (1). Recruitment channels included mailing lists, online message boards, public events on AI, adult education centers, and convenience sampling. Participants from two cities were recruited.\nFigure 3 illustrates the age distribution (left), education background (middle), and the confidence participants have in their understanding of privacy policies (right). The latter reflects the differing exposure to privacy-related topics our participants had in their professional backgrounds. Our participants range from those who have little to no knowledge about the topic to experts like one participant being a data protection officer. However, all of our participants rarely or never read privacy policies.\nParticipants were compensated with a 15 Euro gift card. The anticipated duration for the study was around one hour. We allowed more and longer exploration if participants wished to do so, in particular at the end of the study for websites they chose. This led to actual times between 60 and 90 minutes, depending on participant engagement."}, {"title": "5.3 User Study Procedure", "content": "The procedure for each participant is visualized in Figure 4. Upon arrival, participants signed a consent form outlining the study's goals, procedures, data collection, and their rights. They then completed an initial questionnaire covering"}, {"title": "6 Results", "content": "6.1 Interview & Comments Data\nWe analyzed all 22 interview transcripts, comments of participants during use, and notes taken during the scenarios, which resulted in 896 coded passages. In total, we created 61 codes structured into six code groups: (i) User Attitudes, Motivations, and Behavior, (ii) Information Quality and Clarity, (iii) User Experience and Interface Interaction, (iv) Tool Reliability and Trustworthiness, (v) Recommendations for Features and Functional Improvements, and (vi) Impact on Users.\nWe focus on the most interesting findings and report the full list of 61 codes in the supplementary material."}, {"title": "6.1.1 User Attitudes, Motivations, and Behavior (RQ.3, RQ.4).", "content": "Many participants are somewhat indifferent to privacy risks (P1", "a sad face like that does something to me emotionally\\\" and \\\"I would use it because it interested me. [...] Looking at privacy policies has never been relevant in my life before, even though that's actually a bit stupid. And I think I first need to become more aware that data protection is actually important and that websites have different levels of privacy policies\\\". PRISMe motivated exploration: \\\"It was interesting, so I always wanted to try more\\\" (P15). Participants also expressed a strong interest in using the extension in their daily lives: \\\"If it was available, I think I would directly install it": "P21), \u201cI think it would be great progress if this became standard practice\u201d (P20).\nWhile participants admitted they were rather unwilling to change behavior due to existing habitualized behavior and inconvenience of a change (P1, P4, P5, P6, P10, P18) and note that decision-making also depends on other (to them more important) factors depending on the context (P3, P8, P11, P12"}]}