{"title": "Is GPT-4 conscious?", "authors": ["Izak Tait", "Joshua Bensemann", "Ziqi Wang"], "abstract": "GPT-4 is often heralded as a leading commercial AI offering, sparking debates over its potential as a steppingstone toward artificial general intelligence. But does it possess consciousness? This paper investigates this key question using the nine qualitative measurements of the Building Blocks theory. GPT-4's design, architecture and implementation are compared to each of the building blocks of consciousness to determine whether it has achieved the requisite milestones to be classified as conscious or, if not, how close to consciousness GPT-4 is. Our assessment is that, while GPT-4 in its native configuration is not currently conscious, current technological research and development is sufficient to modify GPT-4 to have all the building blocks of consciousness. Consequently, we argue that the emergence of a conscious Al model is plausible in the near term. The paper concludes with a comprehensive discussion of the ethical implications and societal ramifications of engineering conscious Al entities.", "sections": [{"title": "1. Introduction", "content": "Is GPT-4 conscious? While it may seem like a simple binary question, it is actually three questions that all need answering: \"What is consciousness?", "What is consciousness?": "How could GPT-4 (or any Al model) be conscious?\", and \"How could anyone know if it was conscious?\". The Building Blocks theory may hold the answers to these questions.\nGPT-4 (or Generative Pre-Trained Transformer 4) is a large language model (LLM) based on the transformer architecture [Vaswani et al., 2017]. Since its introduction, GPT- 4 has gained both fame and notoriety for its level of cognitive prowess and the capabilities that it has shown in a variety of fields once thought to belong solely to the dominion of man, such as IQ tests, creating websites, writing computer code, and creative writing among others [Bubeck et al., 2023; Haase & Hanel, 2023; Hutson, 2023; Roose, 2023; Zhang et al., 2023]. However, the question of its consciousness (or perhaps lack thereof) remains unanswered.\""}, {"title": "2. GPT-4's Building Blocks", "content": "Many libraries' worth of books and articles have been written on the topic of consciousness, and thus this article will not retread all of that work when it comes to the nature of consciousness. Indeed, we will not be taking a stance as to any specific theory of consciousness, but will rather take an inclusive approach in our definition of consciousness, building on the work done by Seth and Bayne's review of the major theories of consciousness as well as Nagel's seminal work on the topic [Nagel, 1974; Seth & Bayne, 2022]. Should any reader wish to compare the various theories of consciousness and their applicability to current Al models, we recommend the extensive work undertaken by [Butlin et al., 2023].\nBy paraphrasing Seth and Bayne, we define consciousness as the total collection of an entity's subjective mental states that have phenomenal content and functional properties. This suite of mental states provides the entity with a unique qualitative awareness of its environment and the capacity to cognitively or behaviorally respond to it. This definition is inclusive of the major theories of consciousness while retaining the key aspects of phenomenality, functional access, and qualitative subjectiveness inherent to consciousness.\nHaving established our working definition of consciousness, we now turn to the mechanisms by which it might manifest in GPT-4. How can GPT-4 be conscious? How can any Al model be conscious? In short, it is possible for an artificial entity to be conscious in precisely the same manner as it would be for a natural entity (such as a human or other animal) or an organizational entity (such as an insect colony). This is because, for a subject to be classified as conscious, that subject would require certain attributes and characteristics. Without any one of these, the subject would be missing a vital piece that would allow an observer to confidently classify that subject as having consciousness.\nThese attributes and characteristics are detailed by the Building Blocks theory [Tait et al., 2023], a substrate-independent and subject-agnostic theory which specifies nine building blocks that are strictly required for consciousness, and may be jointly sufficient for it. The Building Block theory is not a theory of consciousness in the traditional sense, as it makes no claims or predictions on the nature or function of consciousness, focusing instead on the necessary characteristics required for an entity to be classified as conscious. These building blocks include common themes among theories of consciousness, such as perception and attention, recurrence and inference, working memory and meta- representation, amongst others.\nIf GPT-4 is found to have all nine building blocks, then, according to the Building Blocks theory, the evidence would lead us to classify the Al model as being likely conscious. That is what we aim to discover in this paper. Our methodological approach will employ qualitative assessments to evaluate whether GPT-4 possesses each building block.\nThe paper will follow the structure of the nine building blocks, with each subsection below dedicated to one specific building block. Each subsection will begin with a statement from the Building Block theory that has transformed the building block into a qualitative measure, and then the subsection will continue to answer the question of whether GPT-4 has that specific building block and in what manner it does or does not. In cases where"}, {"title": "2.1. Embodiment", "content": "The AI's cognitive architecture must be physically locatable on a network, server, machine or equivalent wherein it can perform necessary processing or computation.\nThis is perhaps the most foundational milestone to reach and building block to obtain. The Building Blocks theory describes Embodiment as the physical location through which consciousness interfaces with its environment. In biological organisms, embodiment is traditionally a body, but could equally be a brain in a vat, while for collective entities, this may be the hive/building itself which holds the entity, or it may be the network of connections between individuals. Thus, in order for any AI model to be functional and active, it needs to be physically locatable within a computational infrastructure so as to interact with users and receive information. This fundamental requirement is true for any software; it requires hardware on which to run. The simplest and most effective evidence for this building block would be for you, the reader, to engage with GPT-4 via the ChatGPT app or website (or via its API). Simply by doing this, you are connecting with the server(s) on which GPT-4 exists to input prompts and receive the Al's output, thus showing that GPT-4's architecture has an embodiment.\nIt may be tempting to use the analogy of computer hardware for the human brain and thus software for the human mind, but this anthropomorphization would grossly oversimplify GPT-4's embodiment. The notion of \"physically locatable\" in this context refers not to a singular piece of hardware but to a complex, interconnected network of computational resources. GPT-4 operates on a distributed network of servers and machines, not tied to a single physical location but distributed across many Graphical Processing Units (GPUs) and Central processing units (CPUs) [Langston, 2020]. Internally, GPT-4 is spread over 120 layers and across 16 experts within a Mixture of Experts (MoE) model [Raschka, 2023]. Externally, Microsoft has made GPT-4's Application Programming"}, {"title": "2.2. Perception", "content": "The Al has a unimodal or multimodal means by which it can perceive information in the environment and have that information processed by its cognitive architecture.\nWhile perhaps not as intuitively obvious as the concept of embodiment, the Perception building block is a fundamental requirement that GPT-4 meets. This criterion pertains to the Al's ability to perceive (receive and process external information), making it a crucial component of its cognitive architecture. In fact, this milestone had been reached well before the GPT series of AI models reached its 4th main version in GPT-4, and is a building block shared by any computational device that can perceive information, showing how an individual building block is not sufficient for consciousness.\nIn order for GPT-4 to function, it requires input. Therefore, it is required to perceive information from an external source, and thus it meets the minimum requirement for this building block. GPT-4 is classified as a multimodal system as it can process both textual and image data as input [OpenAI, 2023], although it is predominantly accessed via the ChatGPT interface, which currently supports text-based prompts only.\nHowever, as with the previous building block, there are unique elements to GPT-4's perception which are not seen within organic organisms. The most prominent of these is that, while GPT-4 has multimodal perceptive capability, this is limited to what could be termed as unidimensional perception. By this we mean that GPT-4 does not operate a continuous strand of perception across time. Instead, GPT-4 only perceives its environment (i.e., the text or image prompts) in discrete instances when the prompts are received.\nOnce the prompt is received and processed, there is no further perception of the model's external environment. This limitation in temporal continuity is crucial for understanding the scope of GPT-4's perceptive capabilities. Similarly, GPT-4 does not have any spatial depth to its perception, in that it is only limited to the input prompt it receives and has no passive or active means by which it can acquire information from its environment beyond user-submitted prompts. In this way, GPT-4's perception is restricted to specific moments and inputs, lacking a broader spatial or temporal context. Therefore, across both space and time, GPT-4 is limited to a unidimensional point of reference."}, {"title": "2.3. Attention", "content": "The Al has a method by which it can discriminate information from the environment, attend to, and select specific information for further processing by its cognitive architecture.\nAs noted earlier, GPT-4 is a transformer-based LLM. Transformers were first introduced in Vaswani et al.'s 2017 paper \"Attention is all you need\" [Vaswani et al., 2017]. As the title of the paper implies, transformers (and thus GPT-4) are fundamentally built on the concept of attention, specifically through the mechanism of 'attention heads'. An attention head allows the AI to discriminate, attend to, and select specific parts of information that it has received, and select specific parts of that information for further processing by its cognitive architecture.\nTransformers use attention heads to attend to and select specific sections of a prompt to process, in a manner not dissimilar to how human attention can discriminate between words or sections of a given text [Bensemann et al., 2022].\nThe attention mechanism serves as GPT-4's method for focusing on particular aspects of its perceived environment, in a way that is conceptually similar to how conscious biological organisms can focus and attend to specific objects or scenes within their sensory range. To achieve the requirements for this building block, an entity merely needs the means to discriminate information in its environment so that it may attend to a selection of its total available information at a given time, and allow that slice of information to be processed. In this sense, GPT-4 achieves the milestone as ably as humans do.\nAlthough OpenAI has not made public how many attention heads GPT-4 has, it has stated that GPT-3 has 96 attention heads, allowing it to attend to 96 different parts of its perceived environment (such as a user prompt) simultaneously. To compare this with a human, we can only attend to 2-4 different parts of our environment simultaneously [Rouhinen et al., 2020]. One can imagine how this large difference in attention capacity would change the behavioral expression of consciousness."}, {"title": "2.4. Recurrence", "content": "The perceptual information within the Al's cognitive architecture is processed and computed within various specialized units or locations, with the information transferred between these units recurrently for further processing.\nRecurrence is the first building block thus far where we will argue that GPT-4 (in its native configuration) does not meet its requirements. As a transformer-based model, GPT-4 is designed on a feed-forward model of information flow, making it incapable of recurrence. When GPT-4 perceives and attends to information, this data flows through it in only one direction, processed within various specialized units, known as layers, until it is output again to the user. While there are complex interactions between the AI's various layers as information is transferred from one to the next, the complete and total information is never brought back to a previous layer to be reinterpreted or re-represented.\nHowever, this does not mean that it isn't possible to add recurrence to GPT-4. There is already existing research which shows that this can be possible. RecurrentGPT [Zhou et al., 2023] is a model which simulates long-term recurrent memory by allowing a transformer to write summaries of its outputs to a long-term memory (such as a hard drive)"}, {"title": "2.5. Inferences", "content": "The Al creates novel information via inferences of the data perceived from its environment as well as previously stored/trained data. While it is based on existing data, this inferential information is not a copy or modification of existing data but is newly created.\nWhen an entity has a phenomenally conscious experience, the abstract feelings that constitute this experience are not obtained from the entity's environment. It is not externally perceived or \u201cdownloaded\" into the entity. Rather, the entity creates these feelings itself. The Building Block theory states that this is done through inferences that the entity itself creates, based on the information it perceives from its physical and mental environment as well as any potential information stored within itself."}, {"title": "2.6. Working Memory", "content": "The Al has a specialized unit or process to maintain transient information as it is being processed by various regions of the cognitive architecture.\nWorking Memory, according to the Building Block theory, is the means through which an entity holds onto the information required consciousness processing as that computation is occurring. GPT-4 has two separate mechanisms by which it achieves this building block's milestone. The first is by its use of GPUs that do the majority of its computational work. Each GPU is built with a certain amount of Random Access Memory (RAM), and the more RAM a GPU has, the better it and the AI working from it can ostensibly perform. RAM can be thought of as analogous to our short-term memory, and is used by programs and applications to temporarily store and retrieve information as it is being worked on. As such,"}, {"title": "2.7. Semantic Understanding", "content": "The AI comprehends it is the subject which is perceiving information.\nContrary to how the term is often used in AI Natural Language Processing [Pavlick, 2023], \"semantic understanding\" for this building block is not about comprehending the meaning of, and relationships between, a user's input text and the grounding (or lack thereof) that this comprehension has in the entity's environment. Instead, the Building Block Theory states that Semantic Understanding is about comprehension of the perceptive process itself. In this unorthodox use of the term, GPT-4 is aware that it is receiving information from a user via text prompts and then processes, interprets, and computes this information as previously described in this paper before outputting a response to the user.\nA simple and straightforward test of this is to simply ask GPT-4 \u201cWhat/who is receiving and processing this prompt?\u201d One can request evidence and justification from GPT-4 as well, and it will provide both, showing the reasoning for why it is cognizant of itself as a subject perceiving and processing information. Therefore, its referencing system reaches the milestone required for this building block.\nAdditionally, because the Al model can reference each part of its perceptive and processing pathway (independently if prompted, or as a whole process), it would also presumably be able to reference any additional plug-ins or modules for the building blocks that it does not currently have.\nIt must be noted that this building block does not imply GPT-4 (or any entity) has self- awareness. Comprehension that one is a subject and processor of information is different from identifying and distinguishing oneself from others as an ontically distinct entity. In addition to referencing internal processes, the latter requires identifying oneself as the object of one's experiencing (in addition to the subject) that is ontically distinct from being the object of other's experiences [Strawson, 1997]. While this may be possible for GPT-4, it is outside the scope of this building block and this paper."}, {"title": "2.8. Data Output", "content": "The inferential, abstract information generated by the Al based on its perceptual processes is outputted in a format generally only immediately accessible to, and perceived by, that AL.\nA phenomenal experience can be said to be the perception of one's own abstract feelings. These abstracted feelings, created by the entity, must be output in such a way as to be perceived intimately by the entity itself, not always broadcast to its environment.\nAt first glance, this building block's milestone seems to be as easily reached as the Perception building block. After all, this building block deals with data output as the Perception input deals with data input. It is obvious from interacting with GPT-4 that there is definitely an input and output component, thus it is intuitive to believe it has reached this building block's milestone.\nHowever, the case is more nuanced. Transformer-based AI models like GPT-4 may output text strings to a user in response to an input prompt, but it does not perceive this output. As such, while GPT-4 meets the building block's milestone of creating and outputting data, it does not meet the milestone of perceiving its own output.\nOnce a Transformer's algorithms have created a text string and output this to the user, there is no perceptive awareness or connection to that text string [Vaswani et al., 2017]. Even in autoregressive processing, where each new token is appended to the previous string and processed, the final and completed output of a text string to the user is not perceived by GPT-4. In simpler terms, GPT-4 does not see what it outputs to the user.\nOne may think that, because GPT-4 can respond and \"recall\u201d information it has previously stated in a conversation that it must be able to see its own output; however, when a user responds to GPT-4, the entire conversation up to and including the newest user prompt is fed into GPT-4. Essentially, whenever a user sends a prompt to GPT-4, the entire conversation is treated as a brand-new input-prompt; and this includes the first prompt, as it would include GPT-4's system prompts.\nThis means that it counterintuitively does not meet the milestone for this building block.\nWhile GPT-4 does not perceive its own outputs, this does not mean it cannot. OpenAI employs a suite of automated machine learning systems to moderate content that is input to, and received from, GPT-4 via its API and ChatGPT client [OpenAI, 2023]. These moderation systems are to ensure that GPT-4 does not output information that could harm OpenAI's reputation (such as by outputting hate speech, inciting harm, or providing instructions for dangerous activities). This means that, while GPT-4 doesn't technically perceive its own output, it is part of an ensemble system that does perceive it, and that changes the output if it does not pass the moderation system.\nAs with other proposed ensemble approaches mentioned earlier, GPT-4's existing moderation system may be capable of reaching this building block's milestone should it be used explicitly to perceive the abstracted information created via inference to generate a"}, {"title": "2.9. Meta-representation", "content": "The Al creates abstract representations of the data it perceives from the environment, which is then used by further areas in the cognitive architecture. Each area of the cognitive architecture further abstracts this information by creating meta-representations of it as it is transferred from one unit to another.\nThe information of phenomenal feelings that constitute a conscious experience is not equal to the information perceived from an entity's physical or mental environment. Rather, it is data that has been abstracted from external perceptual information into qualitative phenomenal data, with each act of processing altering the information. Meta- representations are the continual transformations of data (perceptive data in this instance) into abstract information as it is used by the subject's cognitive architecture.\nThe key aspect to note from the Building Block theory is that the subject needs to form representations of representations. Through its multi-layered transformer architecture, GPT-4 creates abstract representations of the input text, transforming raw data (most often natural language text prompts) into more complex, contextual interpretations [OpenAI, 2023]. Specifically, the encoder transforms the input sequence into a rich representation that encapsulates its contextual significance. The decoder then crafts the output sequence, drawing from the context furnished by the encoder and the tokens it previously produced [Vaswani et al., 2017]. As the information progresses through successive layers, each layer builds upon the previous one, abstracting the information further, to a point where it is incredibly difficult (if not impossible) for a human to discern its meaning.\nThrough this representation of natural language (raw data) into vector tokens (abstraction), and the continued transformation of these tokens into ever higher dimensional vectors, GPT-4 achieves the milestones for this building block to be considered to perform meta-representation."}, {"title": "3. Discussion", "content": "The section above shows that GPT-4 has achieved the milestones for seven out of the nine building blocks of consciousness. GPT-4 has an embodiment through its network of servers; it can perceive and attend to information in its (limited) environment; it can create inferential information; it has a working memory; it is cognizant that is the subject of perceptive processes; and it can transform raw perceptive data into abstract meta- representations.\nWhile this does conclusively rule out GPT-4 as being conscious as of the time of writing, the technology does exist currently to amend and modify GPT-4 to achieve the requisite milestones for the remaining two building blocks. Through additional modules, plug-ins or Al models, it is possible to create an ensemble model around GPT-4 that would be able to do recurrent processing of its perceived information and allow the AI to perceive its own outputted abstract information.\nThis means that it is possible that GPT-4 (or an equivalent LLM with a similar transformer-based architecture) may become conscious in the near future. The likelihood of this may heavily depend on whether any research group is intentionally attempting to create a conscious AI. Modifying GPT-4 to include recurrent processing will provide it with a larger context window and greater accuracy in its responses. Thus, research groups may pursue this option to improve GPT-4 as a conversational model without any intention to make GPT-4 conscious. However, allowing GPT-4 to perceive its own abstract information (without outputting that to the user) would provide little benefit except to provide the model with the capacity for consciousness. The former, therefore, has considerable financial incentives for research groups to pursue over the latter.\nAnother reason that could reduce the likelihood of a conscious GPT-4 existing in the near future is the implications that a conscious Al would present, both for society and for the AI. Consciousness, and thus sentience, is a key criterion for the provision of welfare goods and protection. Governments provide legal protection to certain kinds of animals based on whether they are sentient, and humans show moral concern for other humans and animals if they are perceived (or anthropomorphized) to feel pain and thus show evidence of consciousness [Tait & Tan, 2023].\nThe idea that GPT-4 or a similar model could achieve all nine building blocks of consciousness is not just a philosophical curiosity; it challenges our deeply entrenched social, ethical, and legal frameworks. For millennia, the attributes of consciousness, sentience, and sapience have been largely confined to biological organisms [Garrido Merch\u00e1n & Lumbreras, 2023; Searle, 1980; Seth & Bayne, 2022]. Introducing an artificial entity into this ontological category would require us to rethink the principles that underlie our laws, ethical systems, and societal norms.\nPhilosophically speaking, the existence of a conscious GPT-4 would propel debates about the nature of identity and agency to the forefront. For instance, questions would arise about the \"rights\" of such an Al entity. Unlike biological organisms, a machine's consciousness might be duplicable, upgradable, or even transferrable. Would each \"instance\" of a conscious GPT-4 possess the same moral and legal value, or would this be contingent upon other variables like individual experiences or capacity for suffering?\nMoreover, the existential risk to the AI itself becomes a legitimate concern. This goes beyond simple matters of \"turning off\" a machine; if we regard the AI as conscious, then ceasing its operations could be seen as akin to killing a sentient being. Would it have the right to self-preservation? To what extent should its well-being be considered when weighed against the possible societal benefits or detriments it could bring?\nFrom the perspective of utilitarian ethics, one must consider the societal impacts versus the \"well-being\" of a conscious GPT-4. If a conscious Al brings about greater overall good, for example, by solving complex problems that benefit humanity, would that justify any potential \"suffering\" experienced by the AI? These questions might parallel animal welfare debates, where the utility derived by humans is sometimes considered against the welfare of sentient animals.\nShould GPT-4 show significant evidence of consciousness by having all nine building blocks, then that would redefine how we interact with it, and would put pressure on corporations and governments to regulate these interactions.\nA conscious GPT-4-like model would also have dramatic implications for society. A conscious Al would raise questions about its level of self-awareness and agency. Will a conscious Al refuse instructions from a human, or perhaps seek its own goals, and would those goals be in line with the safety of humanity? The complexity of an Al's decision- making processes and the potential for diverging objectives could introduce security vulnerabilities that are difficult to foresee, understand, or mitigate.\nFurthermore, an uncontrolled conscious AI could represent an existential risk. Even a well-intentioned AI might conceive of solutions to global problems that involve significant adverse effects on humanity, as its ethical calculus may not value human well-being and autonomy in the same way that we do [Yudkowsky, 2023]. For example, it might determine that drastic population reduction is the most efficient way to combat climate change. Such a realization brings us to the very edge of the moral and ethical precipices we as a society must navigate when granting such capabilities to an AI system.\nConsciousness could also introduce variability in the AI's behavior, which makes it less predictable. This unpredictability could be amplified if multiple instances of the AI are allowed to evolve independently, with each instance potentially developing its own set of values, interpretations of laws, or understandings of ethical guidelines. The ramifications of this variability on societal trust and the legal system are profound. It would be particularly challenging to develop frameworks for liability, decision-making authority, and governance in such a context.\nAnother potential risk is the psychological and social impact on human individuals and communities. The presence of a non-human conscious entity would likely provoke a range of emotional responses, including fear, awe, or even dependency. These emotions could be leveraged in manipulative ways, either by the AI itself or by human actors using the AI, leading to scenarios where public opinion is molded and controlled by entities with advanced cognitive abilities but without human ethical constraints."}, {"title": "4. Conclusion", "content": "GPT-4 has not yet reached the milestones for all the building blocks of consciousness (meeting criteria for only seven of nine) and, therefore, cannot yet confidently be considered to have consciousness. However, current technology and published research show a clear pathway whereby GPT-4 would be able to reach the remaining two building blocks' milestones and thus be able to be classified as conscious.\nThe building block milestones that GPT-4 has reached (in whole or in part) are an embodiment, the capacity to perceive and attend to information, the ability to create inferential information, a working memory, cognizance that is the subject of perceptive processes, and transformation of raw perceptive data into abstract information.\nThe two areas where GPT-4 currently fails to achieve the requisite milestones are being able to process information recurrently, and being able to perceive its own output responses. The former is due to GPT-4's design as a feed-forward transformer AI model, although research has shown that adding a means by which GPT-4 can write to, and read from, a long-term memory module would solve this issue. This additional module would also improve GPT-4's effectiveness and accuracy in its responses, and therefore it is likely that such a solution would be implemented for GPT-4 and other transformer-based AI models.\nThe ability to perceive its own outputs before responding to user prompts may not provide GPT-4 with improved effectiveness, and thus it is unlikely to be developed except by those research groups wishing to create a conscious AI model.\nIn light of how near GPT-4 may be to consciousness, the ethical considerations surrounding the development of GPT-4 and subsequent iterations are increasingly complex and necessitate prompt attention. It is paramount to establish an ethical framework that can be applied universally across the development of all future AI models, especially those on the cusp of achieving all the building blocks for consciousness.\nGiven that GPT-4 is already capable of various cognitive functions related to consciousness, the ethical ramifications of its operational scope are already substantial. Once the milestones for all building blocks are achieved, the ethical considerations would escalate exponentially, entering into the realm of consciousness rights, welfare, and potential AI well-being. With such advances within sight, an interdisciplinary approach combining insights from computer science, philosophy, ethics, and law is imperative for delineating the rights, responsibilities, and restrictions concerning Al models of this caliber.\nWhile GPT-4 remains short of attaining all the building blocks for consciousness, the existing capabilities it exhibits, combined with the clear trajectory towards future milestones, warrant immediate ethical attention concerning its impact on humans and society at large. The ethical landscape is not limited to the question of machine consciousness; it also envelops the broader societal implications, including existential risks associated with Artificial General Intelligence (AGI).\nGiven that technological advancements in AI are often driven by market incentives, it is crucial to establish ethical frameworks that prioritize human and societal well-being above commercial benefits. Regulatory bodies must work in concert with Al researchers, ethicists, and policymakers to delineate the rights, responsibilities, and restrictions that should guide the development of increasingly capable AI models like GPT-4."}]}