{"title": "Learning Unlabeled Clients Divergence via Anchor Model Aggregation for Federated Semi-supervised Learning", "authors": ["Marawan Elbatel", "Hualiang Wang", "Jixiang Chen", "Hao Wang", "Xiaomeng Li"], "abstract": "Federated semi-supervised learning (FedSemi) refers to scenarios where there may be clients\nwith fully labeled data, clients with partially labeled, and even fully unlabeled clients\nwhile preserving data privacy. However, challenges arise from client drift due to undefined\nheterogeneous class distributions and erroneous pseudo-labels. Existing FedSemi methods\ntypically fail to aggregate models from unlabeled clients due to their inherent unreliability,\nthus overlooking unique information from their heterogeneous data distribution, leading to sub-\noptimal results. In this paper, we enable unlabeled client aggregation through SemiAnAgg, a\nnovel Semi-supervised Anchor-Based federated Aggregation. SemiAnAgg learns unlabeled\nclient contributions via an anchor model, effectively harnessing their informative value.\nOur key idea is that by feeding local client data to the same global model and the same\nconsistently initialized anchor model (i.e., random model), we can measure the importance\nof each unlabeled client accordingly. Extensive experiments demonstrate that SemiAnAgg\nachieves new state-of-the-art results on four widely used FedSemi benchmarks, leading to\nsubstantial performance improvements: a 9% increase in accuracy on CIFAR-100 and a 7.6%\nimprovement in recall on the medical dataset ISIC-18, compared with prior state-of-the-art.\nCode is available at: https://github.com/xmed-lab/SemiAnAgg.", "sections": [{"title": "1 Introduction", "content": "Federated learning has emerged as a promising solution for learning in decentralized environments, where\ndata centralization is often infeasible due to privacy concerns. Federated learning has gained considerable\nattention in machine learning tasks in natural image domains (McMahan et al., 2017) as well as medical\nimage domains (Liu et al., 2021; Saha et al., 2023; Jiang et al., 2023). Due to the challenges of data and label\nheterogeneity, multiple methods such as MOON (Li et al., 2021a), FedDisco (Ye et al., 2023), FedFed (Yang\net al., 2023), and FedRoD (Chen & Chao, 2022) have been developed, utilizing FedAvg (McMahan et al., 2017)\nas their baseline. While these methods have shown promise, they often assume that all clients have exhaustive\nand expert-level annotations, which is a requirement that is both time-consuming and labor-intensive. This\nrenders them impractical in real-world cross-silo federated settings, such as those found in hospitals. Therefore,\ndeveloping methods that require minimal expert-level annotations in decentralized settings is a crucial area\nof research that deserves further attention."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Semi-Supervised Learning", "content": "Semi-Supervised Learning (SSL) leverages a large amount of unlabeled data along with labeled data to\nlearn a generalizable model. Semi-supervised methods include consistency regularization (ensuring consistency\nbetween two distorted unlabeled images) (Li et al., 2021b; Tarvainen & Valpola, 2017), generating pseudo\nlabels through supervised objectives (Zhang et al., 2021; Chen et al., 2023; Wang et al., 2023), or self-supervised\nclustering objectives (Fini et al., 2023). Prominent methods incorporating adaptive pseudo labeling are\nFlexMatch (Zhang et al., 2021), SoftMatch (Chen et al., 2023), and FreeMatch (Wang et al., 2023). However,\nthese strategies assume uniform and identical class distribution of labeled and unlabeled data, which is often\nnot the case in real-world applications."}, {"title": "Semi-Supervised Imbalanced Learning", "content": "Semi-Supervised Imbalanced Learning (SSIL) aims to learn SSL models in scenarios where there is a\nclass imbalance distribution in labeled and unlabeled data. Several works address this issue by amplifying\npseudo labels for minority classes through resampling (Wei et al., 2021), re-weighting (Wei et al., 2022; Wang\n& Li, 2023a;b), and classifier blending (Oh et al., 2022). However, these methods assume the unlabeled class\nimbalanced distributions follow the labeled ones. In the non-IID FedSemi setting, a more realistic scenario\narises where there is a class distribution mismatch between labeled and unlabeled data. This setting, which\nhas not been extensively explored, is addressed by the state-of-the-art method proposed by ACR (Wei &\nGan, 2023). ACR builds upon FixMatch (Sohn et al., 2020) with a dual branch and introduces adaptive\nconsistency regularization. The intensity of logit adjustment, controlled by a scaling parameter, is adaptively\ncalculated based on the pseudo-label distribution distance to three anchor distributions: uniform, labeled\ndistribution, and its reversed version. While ACR (Wei & Gan, 2023) showed promising results in centralized\nsettings, the three anchor distribution is crafted and does not adhere to non-IID FedSemi. Thus, the challenge\nof semi-supervised learning with heterogeneous labeled and unlabeled class distributions, particularly in FL\nnon-IID scenarios, remains unresolved."}, {"title": "2.2 Federated Semi-Supervised Learning", "content": "Federated Semi-Supervised Learning (FedSemi) addresses the decentralized learning of both unlabeled and\nlabeled data while preserving privacy. FedSemi has been explored in three different settings. In the first two\nsettings, labeled data is available on the server, as in FedMatch (Jeong et al., 2021) and FedLID (Psaltis\net al., 2023), or clients have partially labeled data, as seen in SemiFed (Lin et al., 2021) and FedLabel (Cho\net al., 2023). The third setting, which we consider more realistic, involves fully unlabeled clients, while other\nclients can be either fully labeled or partially labeled. For the third setting, recent works have shifted from\naddressing clients with independent and identically distributed (IID) data, such as FedConsist (Wang et al.,\n2020) and FedIRM (Liu et al., 2021), to non-IID data, including RSCFed (Liang et al., 2022) and CBAFed (Li\net al., 2023). This work focuses on the third setting, characterized by most clients with fully unlabeled and\npotentially non-IID data."}, {"title": "2.3 Federated Model Aggregation", "content": "Federated aggregation aims to improve the global model through proper aggregation across various clients.\nGiven the heterogeneity of client data, clients with unique information could benefit the global model more\nduring optimization, rendering the control of clients' contributions a crucial concern. This direction has\nshown great promise in supervised federated learning settings (Jiang et al., 2023; Elbatel et al., 2023; Ye\net al., 2023). For instance, FedCE (Jiang et al., 2023) measures contribution in both the gradient and\nsample space. Using the sample space involves prediction error calculation, relying on labeled validation data\nwithin clients. FedMAS (Elbatel et al., 2023) proposes leveraging labeled data for estimating inter-client\nintra-class variation to emphasize the contribution of clients with minority classes. However, these methods\nrely on label information, making them inapplicable to unlabeled clients in FedSemi. In unlabeled clients, the\nnon-IID distribution results in noisy pseudo-label estimation, rendering the surrogation with pseudo-labels on\nunlabeled clients less effective for aggregation measurement.\nExisting FedSemi (Liang et al., 2022; Li et al., 2023) methods regard non-robust clients or data as outliers\nand opt to minimize their influence. RSCFed (Liang et al., 2022) proposes to leverage unlabeled gradient\ndivergence to eliminate non-robust (noisy) clients through average consensus inspired by RANSAC (Fischler &\nBolles, 1981). However, RSCFed (Liang et al., 2022) does not consider cases when unlabeled clients are diverse\ndue to unique information (i.e. underrepresented classes or attributes). CBAFed (Li et al., 2023) introduced\nfederated class adaptive pseudo labeling, which can be seen as curriculum-paced pseudo learning from a\nglobal perspective (Zhang et al., 2021). It uses hard temporal ensembling (Rasmus et al., 2015; Tarvainen\n& Valpola, 2017; Laine & Aila, 2017) to address the stochastic variability in the global model and simply\naggregates models based on reliable data amount. These strategies overlook the informative unlabeled clients\nwith heterogeneous data, leading to suboptimal optimization. Therefore, a more comprehensive method\nfor quantifying unlabeled clients is needed. In this work, we fill this gap by introducing SemiAnAgg, an\nanchor-based aggregation strategy in FedSemi, which harnesses the heterogeneity of unlabeled clients during\nvaluation."}, {"title": "3 Preliminaries on Federated Semi-Supervised Learning", "content": "FedSemi Setting. Let us consider the generic Federated Semi-Supervised Learning (FedSemi) setting, which\nallows clients to be fully unlabeled, partially labeled, or fully labeled which is introduced in RSCFed (Liang\net al., 2022) and CBAFed (Li et al., 2023). We denote the set of clients as {$C_1, ...,C_K$}, where each client\npossesses a local dataset represented by $D_{client} = {{(x,y)}_{i=1}^{N_L}, {(x)}_{i=1}^{N_U}}$. Here, $N_L$ and $N_U$\ncorrespond to the number of labeled and unlabeled data instances, respectively. The objective is to derive\na robust global model, $\\Theta_{glob}$, which effectively leverages all the available data across all clients. The most\nrigorous setting, as defined in (Liang et al., 2022; Li et al., 2023), is characterized by the majority of clients\npossessing fully unlabeled non-IID data, with $N_L = 0$.\nFederated Warm-up. To ensure reliable pseudo-labels for unlabeled clients in initial stages, previous\nFedSemi approaches (Li et al., 2023; Liang et al., 2022) have employed a warm-up phase based on labeled"}, {"title": "4 Method", "content": ""}, {"title": "4.1 FedAvg-Semi: A Strong Aggregation Baseline for Fedsemi", "content": "Previous FedSemi approaches (Cho et al., 2023; Liang et al., 2022; Li et al., 2023) show that assigning\na higher weight to labeled clients on the server produces better performance than traditional FedAvg\naggregation (McMahan et al., 2017). Notably, semi-supervised learning necessitates a weighted combination\nof supervised and unsupervised loss (Equation 1), with prior semi-supervised regimes (Sohn et al., 2020;\nWang et al., 2023; Zhang et al., 2021) equally weighting $\\mathcal{L}_{sup}$ and $\\mathcal{L}_{unsup}$ to avoid bias towards potentially\nincorrect pseudo-labels. Consequently, it is crucial to re-adjust the global optimization objective in\nfederated semi-supervised learning. Unlike existing FedSemi approaches (Cho et al., 2023; Liang et al.,\n2022; Li et al., 2023) that aggregate clients on the server based on traditional FedAvg (McMahan et al., 2017),\nwe disentangle the aggregation based on labeled and unlabeled data on the server to write a more generic\nform, termed FedAvg-Semi.\nGiven K clients, with number of labeled samples, $N^L$, and the selected number of unlabeled samples contribut-\ning for $\\mathcal{L}_{unsup}$ in each client local training, $\\bar{N}^U$, FedAvg-Semi dynamically disentangles FedAvg (McMahan\net al., 2017) to ensure a global optimization objective consistent with traditional semi-supervised optimization\nas follows:\n$\\Theta_{glob} = \\sum_{k=1}^{K} \\lambda_1 \\frac{N^L_k}{N^L_{total}} \\Theta^L_k + \\lambda_2 \\frac{\\bar{N}^U_k}{\\bar{N}^U_{total}} \\Theta^U_k , where  N^L_{total} = \\sum_{k=1}^{K} N^L_k , and  \\bar{N}^U_{total} = \\sum_{k=1}^{K} \\bar{N}^U_k,$\nwhere $\\lambda_1 + \\lambda_2 = 1$ to ensure a normalized mean, and control the optimization of the labeled and unlabeled\ndata consistent with semi-supervised regimes. Setting $\\lambda_1 = 1$ reduces to supervised warm-up on labeled clients.\nFor simplicity, we set $\\lambda_1 = \\lambda_2 = 0.5$, noting that ideally these values could be ramped during federation."}, {"title": "4.2 SemiAnAgg: Semi-Supervised Anchor-Based Aggregation", "content": "Unlabeled clients in semi-supervised learning can provide valuable and diverse information"}, {"title": "5 Experiments", "content": ""}, {"title": "5.1 Experimental Setup", "content": "Datasets, Models, and Settings. We adhere to existing FedSemi benchmarks in all experimental settings,\nas established by (Li et al., 2023) and (Liang et al., 2022), while additionally expanding on multiple\nscenarios. Specifically, we utilize four datasets to assess the effectiveness of our approach: SVHN, CIFAR-\n100 (Krizhevsky, 2009) (both the standard and its long-tailed imbalanced variant with an imbalance factor of\n100), and the skin-lesion classification dataset, ISIC-18. Note that for imbalanced datasets, the imbalance\nis global, existing in both labeled and unlabeled data with class distribution mismatch between the label\nand unlabeled data. For all datasets, we reproduce the reported results of RSCFed (Liang et al., 2022) and\nCBAFed (Li et al., 2023) on the same non-IID federated partitioning publicly available, $Dir(a) = 0.8$. While\nCBAFed utilize ResNet-18 ImageNet version detailed in (He et al., 2016) and RSCFed use a simple CNN, we\nfind their lower-bound is not comprehensive. Thus, we reproduce their results by using the ResNet-18 CIFAR\nversion detailed (He et al., 2016) for datasets with small spatial input dimensions (SVHN, CIFAR100), and\nthe traditional ImageNet ResNet-18 in (He et al., 2016) for ISIC-18. This results in improved reproduction\nof all baselines than reported in CBAFed (Li et al., 2023).\nTo demonstrate the generalization performance, we evaluate the global model on the standard balanced test\nset for all datasets and report accuracy, following the conventions of previous FedSemi methods (Li et al.,\n2023; Liang et al., 2022). It should be noted that the ISIC-18 test set exhibits imbalanced class distribution,\nprompting us to provide a more comprehensive evaluation for this particular dataset.\nImplementation Details (A detailed version in Appendix C.) To ensure a fair comparison, we maintain\nconsistency in the training protocol, architecture, exact federated partitioning checkpoint, and other exper-\nimental settings across all methods. The same warmup model is utilized for initialization in all reported\ntables unless otherwise stated, which is trained for 250 rounds for SVHN, 250 rounds for ISIC-18, and 500\nrounds for CIFAR-100. This is followed by FedSemi learning for an additional 500 rounds for SVHN, 500\nrounds for ISIC-18, and 1000 rounds for CIFAR-100 until convergence. Notably, unlike RSCFed (Liang et al.,\n2022), and SemiAnAgg (ours), CBAFed (Li et al., 2023) benefit from temporal ensembling and a higher\nlower-bound. Consequently, we initialize CBAFed (Li et al., 2023) with a temporal ensembled model to\nmaintain consistency.\nBaselines. In our evaluation, we compare our results with two state-of-the-art reproducible methods:\nRSCFed (Liang et al., 2022) and CBAFed (Li et al., 2023). To provide a more competitive baseline, we\nalso present in Appendix D a study involving the SOTA in semi-supervised imbalanced learning under class\ndistribution mismatch, implementing ACR (Wei & Gan, 2023) within the FedSemi framework."}, {"title": "5.2 Quantitative Comparisons with State-of-the-Art Methods", "content": "We strictly follow the experimental setting of the previous FedSemi benchmark (Li et al., 2023; Liang et al.,\n2022). This rigorous setting includes a single labeled client, which holds only 5% of the global dataset,\nalongside nine unlabeled clients. Additionally, we expand our experiments to include multiple scenarios and\nablation studies. Table 1 reports the quantitative results on four benchmarks, including two balanced datasets\nSVHN and CIFAR-100, and two imbalanced datasets CIFAR-100-LT and ISIC-18 (skin-lesion).\nResults on the Balanced Global Setting. As shown in Table 1, SemiAnAgg achieves the best accuracy\non two balanced datasets, SVHN and CIFAR-100, outperforming the compared methods in terms of accuracy.\nSpecifically, SemiAnAgg surpasses RSCFed and CBAFed by 9.85%, and 0.12% on SVHN which is a relatively\nsimple dataset. On a more challenging dataset, CIFAR-100, SemiAnAgg showcases a substantial improvement\nof 17.25% and 9.03%.\nResults with Imbalanced Global Setting. Previous FedSemi methods did not consider the imbalanced\nglobal setting, which is critical in non-IID FedSemi, where class distribution mismatch between the label and\nunlabeled clients exists. To this end, we report the results on two imbalanced datasets (CIFAR-100LT and\nISIC-18) while all baselines adopting logit-adjustments (Ren et al., 2020) to account for the class-imbalance."}, {"title": "5.3 Ablation studies", "content": "Effectiveness of SemiAnAgg. The results of employing different\naggregation strategies are presented in Table 3. Adopting FedAvg-\nSemi, which aligns with the principles of traditional semi-supervised\noptimization regimes, increases accuracy by 5.63% and \"B-Acc\" by\n8.48% compared to the FedAvg baseline. FedAvg-Semi disentangles\nthe aggregation of labeled and unlabeled clients, thereby avoiding\nthe skewing of global optimization towards unlabeled clients with\npotentially incorrect pseudo-labels. Unlike methods that assign\nweights based on the amount of data for unlabeled clients, our\nSemiAnAgg leverages data heterogeneity for valuation, substantially\nsurpassing our simple baseline, FedAvg-Semi, by 4.45% on accuracy\nand 8.56% on \"B-Acc\".\nEffects of Random Anchor Initialization. Figure 3 presents\nthe results of our ablation study using different random seeds for the anchor model in SemiAnAgg compared"}, {"title": "SemiAnAgg Convergence", "content": "SemiAnAgg Convergence. We analyze the convergence behavior of SemiAnAgg on the SVHN dataset\nin Figure 4. Given that SVHN is a relatively simple task, the pseudo-labels become highly reliable (\u2248 99%)\nin Figure 4 (a). Consequently, SemiAnAgg converges to almost equal contribution from all clients (1/9 \u2248\n0.111) as shown in Figure 4 (b). Notably, in the early rounds, SemiAnAgg values clients 9, 7, and 6 the\nmost due to their respective distances from the anchor model. SemiAnAgg behavior is supported by the\nleave-one-out in Figure 4 (c) indicating these clients are the most significant (their removal results in the\nhighest error rate). Conversely, clients 2, 3, and 8 are weighted less in SemiAnAgg, supported by the fact\nthat their removal does not significantly impact performance (their removal results in the lowest error rate).\nTo this end, SemiAnAgg's novel setup of using a randomly initialized anchor model can measure not only\nthe learned probably (most distant from the random anchor) but also consider the inter-client divergence\n(relative client distance). Unlike other FedSemi approaches (Liang et al., 2022; Li et al., 2023), SemiAnAgg's\nnovel setup enables diverse unlabeled client aggregation.\nEffects of Client Numbers. Expanding the experimental scenarios, we consider a broader range of clients.\nFollowing the rigorous tests of (Liang et al., 2022; Li et al., 2023), we conduct an ablation study with 5, 10,"}, {"title": "Effects of Different Heterogeneous Levels", "content": "Effects of Different Heterogeneous Levels. Table 4 expands the ablations with scenarios of different\nheterogeneity and a broader number of unlabeled clients. Specifically, we examine the impact of client\nheterogeneity by employing a Dirichlet distribution Dir(a) with varying a values. A smaller a indicates\ngreater heterogeneity. The results demonstrate that the SemiAnAgg method outperforms the state-of-the-art,\nCBAFed (Li et al., 2023), particularly under the most challenging conditions of heterogeneity with a = 0.1,\nachieving improvements of 6.78% in \"B-Acc\" and 5.11% in AUC on the ISIC-18 dataset."}, {"title": "Effects of Labeled Clients", "content": "Effects of Labeled Clients. Figure 5 presents an ablation study on the impact of increas-\ning the number of labeled clients on the ISIC dataset. Notably, all methods show improve-\nments when the number of labeled clients is increased to two. Our SemiAnAgg method particu-\nlarly outperforms the state-of-the-art CBAFed (Li et al., 2023) under the two-labeled-clients setting.\nDetailed metrics in Appendix C reveal a remarkable 12%\nincrease in precision and a substantial 4.5% in \"B-Acc\"."}, {"title": "Privacy Implications of FedSemi", "content": "Privacy Implications of FedSemi. While suscepti-\nbility to attacks within the FedSemi framework has not\nbeen studied previously due to pseudo-labels adding an\nextra layer of stochasticity, SemiAnAgg is more privacy-\npreserving than the SOTA FedSemi, CBAFed (Li et al.,\n2023), given the latter sharing the pseudo-class count of\neach unlabeled client, while SemiAnAgg opts for sharing\npseudo-diversity scalars instead. Sharing pseudo-diversity\nscalars adds a layer of ambiguity against attempts to deci-\npher the class distribution of unlabeled clients, stemming\nfrom the pseudo-diversity scalars being influenced not only\nby class count but also by the presence of minority at-\ntributes within a majority class, or conversely, a majority\nattribute within a minority class."}, {"title": "Additional Comments", "content": "Additional Comments. SemiAnAgg communication cost is the exact same as CBAFed (Li et al., 2023),\n60% of RSCFed (Liang et al., 2022)."}, {"title": "6 Conclusion", "content": "In this paper, we provide a new insight for FedSemi-highlighting the importance of measuring the divergence\nfor unlabeled clients, which has been neglected in prior work. We introduce SemiAnAgg, a novel anchor-\nbased semi-supervised aggregation method that leverages a consistently initialized random anchor model\nacross clients, allowing informative unlabeled clients to contribute more effectively during global aggregation.\nSemiAnAgg achieves new state-of-the-art results on four different benchmarks, offering unique insights for\nfuture research in FedSemi and semi-supervised imbalanced learning."}, {"title": "7 Limitations and Future Directions", "content": "In the absence of labeled data from unlabeled clients, SemiAnAgg approximates their contribution by\ncomparing their data distribution through two consistently initialized models across clients. SemiAnAgg\nadds a layer of feature dictionary saving, nevertheless, it is negligible compared to the dataset size and the\nimprovements obtained. Cosine similarity does not accurately represent the direction of the divergence given\nit shares only scalars. A more comprehensive approach that bounds the similarity within the unit sphere is\nnecessary, nevertheless, it might raise privacy concerns. Despite its simple design, SemiAnAgg achieves state-\nof-the-art on four different benchmarks in FedSemi, compared to state-of-the-art federated semi-supervised\nlearning (FedSemi). FedSemi is widely addressed in classification, whereas extending it to imbalanced"}, {"title": "Broader Impact Statement", "content": "This paper introduces a novel federated learning aggregation, SemiAnAgg, whose goal is to enhance the\nutilization of unlabeled data across distributed networks, improving collaborative learning and ensuring\ndata confidentiality. Uniquely, SemiAnAgg promotes the diversity of unlabeled clients, an aspect previously\nunexplored, by establishing a more equitable framework. While SemiAnAgg shares model weights and\ndistance-derived scalars, these scalars do not reveal sensitive information due to their irreversible nature. We\nacknowledge the potential societal impacts, yet no specific issues must be highlighted here."}, {"title": "A Federated Self-Supervised Warmup", "content": "To ensure reliable pseudo-labels for unlabeled clients in initial stages, previous Federated Semi-Supervised\nLearning (FedSemi) approaches (Li et al., 2023; Liang et al., 2022) have employed a warm-up phase based on\nlabeled clients using traditional FedAvg (McMahan et al., 2017). Unfortunately, as depicted in Figure 6, a\npoorly executed supervised warm-up can lead to model degradation, especially in the case of working with\nlimited samples (Yang & Xu, 2020; Yan et al., 2022). To address this issue, intuitive federated self-supervised\nlearning (Zhang et al., 2020; Lubana et al., 2022; Zhuang et al., 2022; Kim et al., 2023a) can be employed as\na solution to alleviate the warm-up problem.\nIt is empirically demonstrated that FedBarlow, de-\nspite its simplicity, is a highly effective baseline in\nFedSelf.\nIn Table 5, we present comparative results on the\nSVHN and CIFAR-100 datasets in the context of\nself-supervised federated learning. We compare our\napproach, FedBarlow, with the clustering-based ap-\nproach, Orchestra (Lubana et al., 2022). Our results\ndemonstrate a significant improvement over Orches-\ntra on CIFAR-100, achieving a 9.52% increase in\nlinear evaluation performance. This improvement is even higher with 4.02% compared to the reported results\nin (Lubana et al., 2022) (55.89%). Furthermore, when training a federated online classifier using the 10\nlabeled clients, FedBarlow showcases remarkable improvements with a substantial increase of 14.6% and 10%\non CIFAR-100 and SVHN, respectively. This highlights the importance of utilizing the Barlow Twin objective\nas a baseline in federated self-supervised learning, as it provides a consistent objective that promotes smooth\nalignment and leads to significant performance gains."}, {"title": "B SemiAnAgg Convergence", "content": "This section provides an in-depth discussion and empirical convergence analysis of the unlabeled client model\naggregation approach, SemiAnAgg, on two datasets, SVHN and ISIC-18. Our SemiAnAgg focuses on the\nvaluation of whether the model is learned properly while measuring divergence. SemiAnAgg introduces a\nnovel client weighting strategy that aims to achieve a balanced contribution from unlabeled clients based on\ndiversity measurements.\nThe SemiAnAgg weighting strategy offers an alternative metric to the computationally expensive impractical\nleave-one-out data valuation (Ghorbani & Zou, 2019). Unlike other approaches in semi-supervised learning\nthat rely on metrics such as model confidence (Chen et al., 2023) or uncertainty ensembles (Chen et al., 2020),\nwhich have proven to be unreliable in imbalanced and class distribution mismatch scenarios, SSIL-CDM\n(as demonstrated in ACR (Wei & Gan, 2023)). SemiAnAgg takes a different perspective to address the\nchallenges of federated non-iid semi-supervised training by considering diversity measurements as a criterion\nfor client weighting. SemiAnAgg as a novel FedSemi adaptive weighting strategy shows competitive results to\nthe baseline not using it as demonstrated in Figure 8."}, {"title": "C Additional Experiments", "content": ""}, {"title": "C.1 Implementation Details", "content": "This section provides a detailed explanation of the implementation details for the main section (Sec. 4.1). We\nimplement our method using the PyTorch framework (Paszke et al., 2019). In the Federated Semi-Supervised\nLearning (FedSemi) framework, SGD optimizer is used with a learning rate of 0.03 for labeled clients and\n0.02 for unlabeled clients, following previous FedSemi approaches such as RSCFed (Liang et al., 2022) and\nCBAFed (Li et al., 2023). This difference in learning rates serves as an implicit regularization to prevent\nunlabeled clients from deteriorating the received global model in case of erroneous pseudo labels. A batch\nsize of 64 is utilized for all datasets. The experiments were conducted on NVIDIA RTX 3090 GPUs.\nThe reported results in the main table follow a warm-up stage, similar to CBAFed (Li et al., 2023) and\nRSCFed (Liang et al., 2022). Specifically, CIFAR-100 and its long-tailed version are pre-trained for 1000\nepochs, while the other datasets are pre-trained for 500 epochs. This is followed by an additional 1000 epochs\nfor CIFAR-100 and its long-tailed version, and an additional 500 epochs for the other datasets. The optimal\nhyperparameter settings for other methods, RSCFed (Liang et al., 2022) and CBAFed (Li et al., 2023), as\nreported and presented in their respective code, are utilized. It is noted that, unlike other methods that\ninvolve scaling and extensive hyperparameters, our SemiAnAgg does not contain any hyperparameters, and\nthe parameters are solely dependent on the local learning method.\nFor the local training procedure FlexMatch (Baseline) (Zhang et al., 2021), the default setting with the\ndefault confidence thresholds presented in TorchSSL, which is the official implementation of FlexMatch, is\nadopted. Better results are reproduced for all FedSemi baselines compared to the originally stated results\nin their tables (Li et al., 2023; Liang et al., 2022). The improvement for smaller spatial resolution datasets\n(SVHN, CIFAR) comes from utilizing an optimal architecture, CIFAR ResNet-18 (He et al., 2016), while for\nISIC-18, the architecture (ImageNet ResNet-18 (He et al., 2016)) remains the same, and the improvement\nsolely comes from utilizing RandAugment (Cubuk et al., 2020) as augmentation for all datasets. For all\nbaselines, the classifier is learned without weight decay, while the backbone has a weight decay of 5e-4.\nIn experiments with self-supervised pre-training, the official Barlow Twins implementation is followed (Zbontar\net al., 2021), but with some modifications. SGD optimizer is used with a learning rate of 0.008, and a\nscale loss of 0.01 is applied, which acts as an implicit scaling of the learning rate for biases and batch norm\nparameters. The choice of hyperparameters is based on the small batch size of 64 used for pre-training on all\ndatasets."}, {"title": "C.2 Dataset pre-processing", "content": "We explain in this section the steps taken for dataset splitting and pre-processing. The same dataset splitting\nfor CIFAR-100, SVHN, and the skin dataset is adopted as in previous FedSemi approaches, RSCFed (Liang\net al., 2022) and CBAFed (Li et al., 2023). It is ensured that the partition loading and splitting are derived\nfrom the same checkpoint for all evaluated methods, ensuring consistency.\nFurthermore, the same pre-processing steps as those used in CBAFed (Li et al., 2023) and RSCFed (Liang\net al., 2022) are adopted. These steps are likely described in more detail in the respective papers (Li et al., 2023;\nLiang et al., 2022). Additionally, a consistent data augmentation technique based on RandAugment (Cubuk\net al., 2020) is employed. RandAugment (Cubuk et al., 2020) has been shown to improve performance for all\nbaseline methods."}, {"title": "C.3 More than One Labeled Client", "content": "In this section, we present the results of more than one labeled client setting for the ISIC-18 dataset. As\nexpected, all methods show improved performance compared to the one labeled client setting.\nIn Table 6, we report the lower bounds for FedAvg (McMahan et al., 2017), which is used for the initialization\nof RSCFed (Liang et al., 2022) and our SemiAnAgg, and the lower bound of CBAFed (FedAvg with residual\nweight connection), which serves as the initialization for CBAFed (Li et al., 2023). The lower bound of\nCBAFed (Li et al., 2023) is significantly higher than that of FedAvg (McMahan et al., 2017), with an\nimprovement of 4.9% in accuracy. However, while CBAFed (Li et al., 2023) exhibits enhanced performance\nin terms of accuracy (0.5% improvement) and AUC (3.0% improvement), it experiences a drop in balanced\naccuracy (1.8% decrease) compared to its lower bound. This observation is consistent with previous evaluations\nin the one-labeled client setting.\nRemarkably, our SemiAnAgg achieves the best results across all four metrics, particularly demonstrating\nan impressive 12.3% increase in precision and a significant 4.5% improvement in recall (balanced accuracy)\ncompared to state-of-the-art CBAFed (Li et al., 2023), despite being initialized from a worse starting point.\nWhen compared to RSCFed (Liang et al., 2022), which maintains consistent initialization, our SemiAnAgg\nachieves greater improvements of 8.28% in precision and 0.95% in recall (balanced accuracy). It is important\nto note that RSCFed (Liang et al., 2022) removes noisy clients through average consensus, leading to the\nelimination of minority classes and consequently lowering precision (by predicting a high number of false\npositives, considering minority as majority) and recall (by predicting lower numbers for minority classes). In\ncontrast, our SemiAnAgg addresses this issue by adaptively valuing unlabeled clients, implicitly assigning\ngreater weight to clients with minority classes, thereby achieving a more balanced performance."}, {"title": "C.4 Partially Labeled", "content": "In the context of FedSemi, we consider a scenario where clients have partial labeling, with each client having\nonly 10% of its samples labeled. This setting presents a relatively easier local optimization compared to\nthe case of one fully labeled client, but global optimization becomes challenging due to the non-iid data\ndistribution. In this section, we present results for partially labeled clients on two datasets: SVHN and\nISIC-18. The results are shown in Table 7."}, {"title": "D Integration of Semi-Supervised Imbalance Learning Techniques", "content": "The original ACR (Wei & Gan, 2023) requires a two-\nbranch network with logit adjustment (Ren et al., 2020).\nWithout prior knowledge about the global distribution\n(e.g., uniform, long-tailed, or imbalanced), one approach\nis to use labeled clients to adjust the logits of unlabeled\nclients. However, this can amplify an inaccurate distri-\nbution, leading to severe performance degradation (See\norig-ACR FL in Figure 12). An improvement can be\nachieved by estimating a stable pseudo-label distribution\nwith an Exponential Moving Average (EMA) locally using\nthe global model. This modification namely SSIL-CDM\nachieves a reasonable performance in Figure 12. All models\nare initialized with FedAvg-Semi detailed in Equation 2.\nFedAvg-Semi modifies the global optimization to be sim-\nilar to local self-training optimization (Chen et al., 2023;\nZhang et al., 2021; Sohn et al., 2020; Wang et al., 2023).\nIn Table 8, we present the results of different strategies on the ISIC-18 dataset. Using SSIL-CDM with\nFedAvg-Semi achieves improvements of 4.7% and 7.3% on accuracy and balanced accuracy compared to not\nusing FedAvg-Semi (w/o FedAvg-Semi).\nOur proposed approach, SemiAnAgg, outperforms our most competitive baselines with 0.9% and 5.6% on\naccuracy and balanced accuracy respectively. Notably, SemiAnAgg achieves this superior performance without\nrequiring specifically tailored architecture design or the need for a dual branch architecture."}]}