{"title": "Pedestrian motion prediction evaluation for urban autonomous driving", "authors": ["Dmytro Zabolotnii", "Yar Muhammad", "Naveed Muhammad"], "abstract": "Pedestrian motion prediction is a key part of the modular-based autonomous driving pipeline, ensuring safe, accurate, and timely awareness of human agents' possible future trajectories. The autonomous vehicle can use this information to prevent any possible accidents and create a comfortable and pleasant driving experience for the passengers and pedestrians. A wealth of research was done on the topic from the authors of robotics, computer vision, intelligent transportation systems, and other fields. However, a relatively unexplored angle is the integration of the state-of-art solutions into existing autonomous driving stacks and evaluating them in real-life conditions rather than sanitized datasets. We analyze selected publications with provided open-source solutions and provide a perspective obtained by integrating them into existing Autonomous Driving framework - Autoware Mini and performing experiments in natural urban conditions in Tartu, Estonia to determine valuability of traditional motion prediction metrics. This perspective should be valuable to any potential autonomous driving or robotics engineer looking for the real-world performance of the existing state-of-art pedestrian motion prediction problem. The code with instructions on accessing the dataset is available at https://github.com/dmytrozabolotnii/autoware_mini.", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous driving research is an exciting topic nowadays, with an aggrandizing promise to improve the driving process for everyone and eventually replace human drivers, starting from future long-distance truck operators [1] to already running autonomous taxi services [2]. However, even if the human drivers can be replaced, the human factor will never disappear from autonomous driving. One of the most significant human factors is not even connected to the car itself - rather to the agency of other human actors on the road - other drivers in non-self-driving cars and pedestrians [3]. A self-driving vehicle should be aware of their possible future actions and apply necessary corrections to its course of action to avoid collisions, follow legal directives, and ensure a safe and comfortable environment for all actors. This function is essential for ensuring pedestrian safety. Poor interactions of the vehicle and pedestrians lead to many traffic accidents, with over 80% possibility of the fatal outcome when the car moves over 60 km/h [4]. This issue is even more exorbitant among youth and elderly groups, especially in developing countries, with road-caused accidents being the lead cause of youth disabilities globally [5].\nAccordingly, to solve these problems in the future autonomous driving applications, pedestrian motion prediction remains an active research topic, with numerous new solutions published every year. Starting from the classic physics-based models [6], the trends shifted to Machine-Learning-based solutions over the last decade [3]. In the last few years of the published articles, there is a wide representation of underlying architectures used for prediction [7]: CVAE methods [8]\u2013[11], GAN methods [12]\u2013[14], Transformer methods [15]\u2013[17], Diffusion methods [18], [19], and even as novel application of LLM-based methods [20], [21]. However, while the variety of underlying methods is excellent, the evaluation of these methods is not as outstanding. The majority of newly published (that often claim to be state-of-the-art), use ADE/FDE (or minADE/minFDE variants) metrics for validation, despite emerging research about deficiencies of these metrics [22]\u2013[24] and the existance of appropriate alternative metrics that have been proposed in literature, such as negative log-likelihood (NLL) or Average Mahalanobis Distance (AMD) [25]. Additionally, model training and experimental evaluation are often done only on small and somewhat outdated datasets such as ETH/UCY [26], [27] and SDD [28] instead of larger and much more diverse datasets such as Argoverse [29] or Waymo Open Motion [30].\nEven more fundamentally, there remains an inconsistency between evaluating any prediction method on the offline dataset and evaluating the prediction method as the module in the modular Autonomous Driving framework, as illustrated by Fig. 1. During the application of the prediction algorithm as part of the modular framework, not only is it affected by the potential errors in the upstream detection and sensor modules, but it also influences the planning and control modules that lead to the movement of the ego-vehicle, and correspondingly all the exo-agents whose motion is predicted can change their future actions because of our movements. This compounding error effect leads to what is called dynamics gap in [23]. Combining all these factors demonstrates the need for a change in the approach to pedestrian motion prediction evaluation.\nIn this letter, we aim to expand upon the evaluation of existing state-of-the-art methods using a more realistic experimental setup - an open-source autonomous driving framework with real-life sensor data. The necessity of processing raw sensor data and running all the other parts of the autonomous driving framework simultaneously as the prediction algorithms on the limited consumer-grade hardware that is expected to be in the autonomous vehicle requires stringent evaluation of the computational efficiency. At the same time, we want to challenge the standard Best-of-N approach that uses ADE/FDE metrics for evaluating the prediction algorithm in the existing pedestrian motion prediction datasets benchmarks. As such, our contributions are three-fold:\n1) Selection and engineering adaptation of a number of state-of-the-art pedestrian motion prediction meth-ods to enable their online performance inside an au-tonomous driving framework.\n2) Creation of an experimental dataset from raw data recorded during past trips of the autonomous vehicle in Tartu, Estonia.\n3) Evaluation of the selected methods and baseline inside the Autoware-mini framework under different output modalities, creating unique perspective of state-of-the-art prediction methods performance."}, {"title": "II. RESEARCH METHODS", "content": "We approach the pedestrian motion prediction problem primarily as the problem of future trajectory prediction based on historical observations, or, as they are sometimes referred, stimuli [3]. There are several commonly used stimuli, however the most prominent is the previous locations of the pedestrian agents represented in 2D from a Birds-Eye-View (BEV) perspective [7]. As such, we can formalize the problem of prediction in the following way: given the historical trajections of N pedestrians over H previous states $X_i = {x_i^1, x_i^2, ..., x_i^H}$, find the future trajectories of the pedestrians over F future states $Y_i = {y_i^{H+1}, y_i^{H+2}, ..., y_i^{H+F}}$ or in another form, find function f that satisfies $Y_i = f(X_i)$ [31].\nThis simple problem formulation is used when introducing physics-based solutions, such as Constant Velocity Model (CVM) [6]. However, it is insufficient for the more recent data-driven approaches. To extend it, we can represent $x_i$ as not only the physical location of the pedestrian $p$, but as a collection of location and other auxiliary inputs $x_i = (p, a, b, ...)$ such as environment representation (HD-map), inner characteristics of the pedestrians (gestures, emotions) or raw sensor data. Then, data-driven approaches need to estimate model M that represents output trajectory $Y_i$ given input features of all N pedestrians to represent cross-actor interactions: $Y_i = M(X_i, {X_j})$. Often, instead of direct deterministic output, the model represents probability distribution $p(Y_i | X_i, {X_j})$ from which multiple candidate trajectories can be sampled, with the intent that at least one of them will be close to future ground-truth."}, {"title": "B. Motion prediction Algorithms", "content": "The main step in the selection of state-of-the-art pedestrian motion prediction methods is finding them. The original search was performed in three distinct steps: first, the relevant keywords search was performed on academic journals to find corresponding survey articles [3] [31] [7] covering latest advancements in the field; second - filtering out articles of interest from all reviewed by reading the original publication and finding if they fulfill necessary criteria; third - analyzing the open source solution of algorithms and cross-referencing the published results with benchmarks of the used datasets. The criteria for filtering out the articles are as follows:\n1) The model is based on a supervised learning algorithm\n2) Pre-trained model allows real-time inference on the limited hardware constraints.\n3) The model's main input should be the historical tra-jectories of the pedestrians. While many models rely on other input data such as HD-map, in practice, it is hard to transfer learned features from the HD-map used for the training to the HD-map used in different autonomous stacks.\n4) Open source implementation of the model's architec-ture, preferably with access to pre-trained weights that reproduce results published in the article. While open-source implementation distributions are common, they are often incomplete, with details missing both from the training code and the description of the training process in the original publication.\nFollowing these criteria, four methods from the last four years were chosen: a) PECNet [32] b) SGNet [10] c) GATraj [17] d) MUSEVae [8]. Furthermore, we establish CVM as"}, {"title": "C. Experimental Setup", "content": "1) Data collection: Our goal is the evaluation of the existing prediction models in the environment as close as possible to a real autonomous vehicle. As such, we base our setup on Autoware Mini framework [34], a lightweight fork written in pure Python of the original Autoware [35], one of the first modular autonomous driving frameworks, which itself is based on Robot Operating System (ROS) [36]. This framework exists both as a scientific and a pedagogical tool, but it has been tested on Lexus RX450h vehicle on the streets of Tartu, Estonia. The vehicle is equipped with Ouster OS1-128 and Velodyne VLP-32C lidars as the primary sensors for object detection. All data these and other sensors recorded during regular autonomous and manual trips for the last three years are stored inside .bag file format. This raw sensor data collection provides a primary dataset for our evaluation purposes. However, the full data collection is 3400+ different .bag files, totaling over 43 Tb, so some filtering was necessary to produce a compact and interesting dataset. The main filter was the rich presence of the pedestrians, requiring over five detected pedestrians to be present at the same time in every selected file and restricting the car route to the center of Tartu. The final result was a dataset with 18 .bag files, where every .bag file represents continuous scene, with a total runtime of 4 hours and 15 minutes of raw sensor footage.\n2) Implementation Details: Using .bag files inside Autoware Mini framework allows to \"replay\" them, simulating the stream of data that the real autonomous vehicle received during the trip and allowing to run a full framework processing the data through full autonomous driving architecture described in Figure 1. This flow of data is represented in the Figure 2. Bag files output raw lidar point cloud data to the detector module. For detection, our framework uses SFA detector based on [37] to process raw point cloud data and output labelled vector representation of the objects. Next, the simplistic exponential moving averages based tracker [38] keeps the objects permanence that allows to construct historic pedestrian trajectories in real-time. Finally, prediction module receives historical trajectories and other auxiliary data, and outputs candidate trajectories.\nHowever, because of the errors introduced by these upstream algorithms, the raw dataset is unsuitable for chosen prediction models training, which necessitates usage of the pre-trained models. For our evaluation, we use PECNet and MUSE-VAE pre-trained on SDD [28], while SGNet and GATraj are pre-trained on ETH/UCY [26], [27]. Both datasets follow the same input format of 8-point historical trajectories to predict 12-point candidate trajectory, where points are 0.4 seconds apart. As a result, all models consider 3.2 seconds of past data, to predict next 4.8 seconds of motion. Consequently, all models were adapted to run with a constant stream of incoming data, where every 0.4 seconds, they receive updated trajectories of all visible pedestrians. As such, the key requirement for performance was that the inference with a variable batch size finishes in 0.4 seconds before the next set of trajectories is obtained.\nTo simulate the limited resources of an embedded system of the real car, the full evaluation framework was performed on a consumer-grade laptop equipped with one NVIDIA GeForce 3080 and AMD Ryzen 5900HX. This severely limits performance compared to how these prediction models are usually evaluated - using either NVIDIA V100/A100, or"}, {"title": "D. Evaluation Metrics", "content": "The most commonly used metrics for evaluating trajectory prediction are Average Displacement Error (ADE) and Final Displacement Error (FDE) [3]. ADE metric is commonly defined as the average L2 distance between all points of predicted trajectory and ground truth future trajectory:\n$ADE = \\frac{1}{NF} \\sum_{i=1}^N \\sum_{j=1}^F ||y_i^{H+j} - \\hat{y}_i^{H+j}||_2$,\nwhere $\\hat{Y_i} = {\\hat{y_i^{H+1}}, \\hat{y_i^{H+2}}, ..., \\hat{y_i^{H+F}}}$ is the ground truth future trajectory. FDE is similar, but considers only L2 distance between final points of predicted and ground-truth trajectories.\n$FDE = \\frac{1}{N} \\sum_{i=1}^N ||y_i^{H+F} - \\hat{y}_i^{H+F}||_2$\nHowever, many data-driven approaches output multiple candidate trajectories. To solve this, the variations of ADE/FDE were introduced called minADE/minFDE, which calculates metrics for every candidate trajectory but considers only the best (lowest) metric score. This variant is commonly used for benchmarking on most pedestrian motion prediction datasets, such as SDD, ETH-UCY, Nuscenes, and Argoverse, with the only difference being that dataset evaluation restricts the amount of candidate trajectories methods that can be submitted. Early datasets such as SDD and ETH-UCY allow up to k = 20 candidate trajectories, while Nuscenes has two different benchmarks for k = 5 and k = 10 and Argoverse v1/2 settling down for k = 6.\nThe methodology of using only best score (Best-of-N approach) has been recently called into question [22], [23], [25], [39], [40]. The central point of the critique, is that if the future ground truth trajectories are parametric distribution (Gaussian or mixed-Gaussian in the simplest case), and our model tries to estimate this distribution by means of minADE/minFDE, it instead estimates square root of PDF [39], which means that it will always perform worse than Bayes-optimal predictor. The theoretical way to recover from this is significantly increase amount of k trajectories we sample. However, this approach is unpractical in autonomous driving, where there are performance constraints to obtaining more sample trajectories if our inference time is long, and a large amount of predicted trajectories can cause a problem for downstream planning and control modules (when for example pedestrian is moving on the sidewalk, and low probability candidate trajectory falsely predicts they will cross a road, forcing vehicle to react, when with lower amount of candidate trajectories this prediction wouldn't exist). Another point of the criticism is that existing metrics poorly represent the so-called \"dynamics gap\" [23] - the idea is that as much as our autonomous vehicle planner considers predicted trajectories and reacts to them, the agents whose motion we predict also consider and predict our ego-vehicle movements, creating dependency on each others' predictions. To resolve this, we follow [23], and implement Dynamic Average Displacement Error (DynADE) and Dynamic Final Displacement Error (DynFDE) metrics. The critical difference is the interactivity factor - in normal ADE/FDE calculation, we calculate metric once per given trajectory in the dataset, while in our setup as we receive updated trajectory of each agent in online stream of data, we calculate new metric value with every new added trajectory point, averaging these L2 distance values for every agent, and then averaging over all agents in the end of each scene. Formally:\n$DynADE = \\frac{1}{N} \\sum_{i=1}^N \\frac{1}{L_i} \\sum_{j=1}^{L_i} \\sum_{k=1}^{j} ||y_i^{j+k} - \\hat{y}_i^{j+k}||_2$\n$DynFDE = \\frac{1}{N} \\sum_{i=1}^N \\frac{1}{L_i} \\sum_{j=1}^{L_i} ||y_i^{j+F} - \\hat{y}_i^{j+F}||_2$\nwhere $L_i$ is the total length of agent $i$ trajectory in the observed scene. For our dataset we average results from each .bag file scene to obtain the final result. The new metric is similar to standard ADE/FDE but shows a more significant correlation with driving performance when integrated into the autonomous driving framework [23]. Correspondingly, for models that output multiple candidate trajectories, Best-of-N approach is still used by choosing the candidate trajectory with the lowest metric score to allow comparison between performance on our dataset and standard datasets such as Nuscenes, denoted as minDynADE/minDynFDE."}, {"title": "III. FINDINGS", "content": "We first present a quantitative evaluation of the chosen algorithms and baseline over a created dataset in Table II. To demonstrate the effect of the Best-of-N approach, we test selected methods under variable candidate trajectories amount k = 1,5, 10. If the model provides more trajectories than k during the single inference run, then k trajectories were selected randomly unless the specified method also outputs the probability of every candidate trajectory, in which case k most likely trajectories were selected. As previously stated, all methods except baseline CVM rely on trajectories over the past 3.2 seconds while outputting candidate trajectories for 4.8 seconds, in line with pre-trained model original datasets ETH/UCY and SDD. Several insights can be derived from the results:\n\u2022 Inline with theory, Best-of-N metric of every data-driven model increases with increase of k. However, increasing k beyond 10 is impractical in the framework due to performance limitations and potential issues in downstream modules such as planning.\n\u2022 Given k = 1, none of the models outperform the Constant Velocity Model despite considering more than a final state of the pedestrian trajectory. This confirms previous findings [33] and demonstrates that pedestrian motion prediction remains an unsolved problem under certain conditions, opening avenues for future research that need to consider other input modalities instead of relying on trajectory only.\n\u2022 MUSE-VAE model, despite being the only model that relies on additional auxiliary map input data, performs the weakest in our framework. The result shows that transferring learned features from one dataset to another is non-trivial, even for the simple semantic map representation. Additionally, MUSE-VAE implementation wasn't able to output k = 10 candidate trajectories under the required time constraint of 0.4 seconds, leading to no results available for Table II."}, {"title": "B. Ablation testing", "content": "The critical issue for pedestrian motion prediction in the context of autonomous driving is the limited availability of historical information. During testing on our dataset, it is common that some pedestrians are only detected very close to the ego-vehicle, giving no time to construct a full 3.2-second trajectory history before the critical prediction needs to be made. As such, we perform ablation testing where we limit the amount of historical trajectory points models consider H to lower value, simulating the lower length of historical trajectory, and compare with the results on default behavior H = 8 in table III (for all methods except CVM k = 5). From this testing, it can be seen that while PEC-Net gradually improves its predictions while incorporating more historical trajectory steps, GATraj and SGNet plateau performance on H = 4, and Muse-VAE seems to rely almost entirely on auxiliary map information and last H = 2 trajectory points, as no meaningful improvements observed with increase in H. The testing shows that while models claim that they consider entire past trajectories, they do not always encode useful information from the oldest trajectory steps."}, {"title": "C. A note on reproducibility of experiments", "content": "Due to the internal workings of ROS adding delays during data transfer between different framework modules, it is impossible to guarantee deterministic metrics calculation on a specific bag scene. As such, we execute one scene evaluation 20 times using every predictor (at k = 5 and H = 8) and calculate the standard deviation and mean of the obtained metric values to showcase possible deviation ranges from the published results in this section."}, {"title": "IV. CONCLUSION", "content": "In this work, we have performed a comprehensive evaluation of selected state-of-the-art pedestrian motion prediction methods on the dataset obtained from a real autonomous vehicle trips in the software environment of the autonomous driving framework under similar hardware restraints. Our evaluation focused on testing limits of the Best-of-N approach of the standard ADE/FDE metrics using modified implementation, created to resolve issues arising from implementing standard solutions into full modular autonomous driving stack. We found out that none of the evaluated models perform better than the standard Constant Velocity Model when outputing only a single candidate trajectory. Otherwise, GATraj model performs the best, both when increasing amount of candidate trajectories beyond one, and when decreasing the length of the observation window of historical trajectory input.\nThe study confirms that pedestrian motion prediction remains an open problem under certain condition, and that researchers should more strictly evaluate potential practical application of their research. Many better or more promising machine-learning models were not evaluated in this study due to hardware or implementation constraints. As such, future research direction should be focused towards more light-weight practical solutions to the problem, while also developing methods of incorporating input data other than historical trajectories. We are hopeful that our research is helpful both to scientists working on new pedestrian motion prediction models and engineers working on real autonomous driving vehicles."}]}