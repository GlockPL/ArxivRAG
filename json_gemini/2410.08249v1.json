{"title": "Federated Graph Learning for Cross-Domain Recommendation", "authors": ["Ziqi Yang", "Zhaopeng Peng", "Zihui Wang", "Jianzhong Qi", "Chaochao Chen", "Weike Pan", "Chenglu Wen", "Cheng Wang", "Xiaoliang Fan"], "abstract": "Cross-domain recommendation (CDR) offers a promising solution to the data\nsparsity problem by enabling knowledge transfer across source and target domains.\nHowever, many recent CDR models overlook crucial issues such as privacy as\nwell as the risk of negative transfer (which negatively impact model performance),\nespecially in multi-domain settings. To address these challenges, we propose\nFedGCDR, a novel federated graph learning framework that securely and effec-\ntively leverages positive knowledge from multiple source domains. First, we design\na positive knowledge transfer module that ensures privacy during inter-domain\nknowledge transmission. This module employs differential privacy-based knowl-\nedge extraction combined with a feature mapping mechanism, transforming source\ndomain embeddings from federated graph attention networks into reliable domain\nknowledge. Second, we design a knowledge activation module to filter out potential\nharmful or conflicting knowledge from source domains, addressing the issues of\nnegative transfer. This module enhances target domain training by expanding the\ngraph of the target domain to generate reliable domain attentions and fine-tunes the\ntarget model for improved negative knowledge filtering and more accurate predic-\ntions. We conduct extensive experiments on 16 popular domains of the Amazon\ndataset, demonstrating that FedGCDR significantly outperforms state-of-the-art\nmethods.", "sections": [{"title": "1 Introduction", "content": "Cross-domain recommendation (CDR) has emerged as an effective solution for mitigating data\nsparsity in recommender systems [1; 2; 3; 4; 5]. CDR operates by integrating auxiliary information\nfrom source domains, thereby enhancing recommendation relevance in the target domain. Recently,\nto address data privacy constrains, many privacy-preserving CDR frameworks have been proposed\n[6; 7; 8; 9], which achieve strong performance under the assumptions of data sparsity and a\ndual-domain model (i.e., typically involving a single source domain and a single target domain.)."}, {"title": "2 Related work", "content": ""}, {"title": "2.1 Cross-domain recommendation", "content": "CDR utilizes auxiliary information from external domains to alleviate the data sparsity problem\nand effectively improve recommendation quality. Li et al. [21] enrich domain knowledge by\ntransferring user-item rating patterns from source domains to target domains. Man et al. [15] and\nElkahky et al. [22] augment entities' embeddings in the target domain by employing a linear or\nmulti layer perceptron (MLP)-based nonlinear mapping function across domains. Liu et al. [23]\naddress the review-based non-overlapped recommendation problem by attribution alignment. Zhao et\nal.[24] improve the recommendation quality of multi-sparse-domains by mining domain-invariant\npreferences. Liu et al. [25] achieve knowledge transfer without overlapping users by mining joint\npreferences. Chen et al. [17] and Liu et al. [26] avoid intermediate result privacy leakage during\ncross-domain knowledge transfer by employing DP. In these works, the NT problem is often ignored\nbecause most of them assume a carefully selected dual-domain scenarios or limited multi-domain\nscenarios where NT is not evident. We aim to solve the NT problem in complex BS-CDR scenarios."}, {"title": "2.2 Federated recommendation", "content": "Recently, FL [27; 28; 29; 30; 31] has been widely adopted to tackle the privacy issue in recommender\nsystem. Chai et al. [32] adopts FL to classic matrix factorization algorithm and utilize homomorphic\nencryption to avoid the potential threat of privacy disclosure. Later, Wu et al. [33] explores the\napplication of federated graph neural networks (GNN) models to improve the recommendation quality\nand ensure user privacy. To utilize sensitive social information, Liu et al. [8] adopts local differential\nprivacy (LDP) and negative sampling. More recent studies use VFL to protect company's privacy\nin recommender system. Mai et al. [34] utilizes random projection and ternary quantization to\nensure privacy preservation in VFL. In CDR, Chen et al. [9] designs a dual-target VFL CDR model\nwith orthogonal mapping matrix and LDP for organizations' privacy preservation. Liu et al. [35]\ndesigns a graph convolutional networks (GCN)-based federated framework to learn user preference\ndistributions for more accurate recommendations. To ensure user privacy in CDR, Liu et al. [6]\nutilizes a VAE-based federated model to mine user preference with data stored locally. Wu et al. [7]\ndesigns a personal module and a transfer module to provide personalised recommendation while\npreserving user privacy. These existing works, especially federated CDR frameworks, only protect the\nprivacy of either individual users (intra-domain privacy) or the organizations (inter-domain privacy)\nbut not both at the same time. We aim to provide both intra-domain and inter-domain privacy."}, {"title": "3 Methodology", "content": ""}, {"title": "3.1 Problem definition", "content": "We consider M (M>3) domains participating in the CDR process. The domains are divided into\nM-1 source domains DS1, DS2, ..., DSM-1 and one target domain DT. Each domain is assigned\na domain server to conduct intra-domain model training. U is the user set across all the domains,\n$U = U_1 \\cup U_2 \\cup ... \\cup U_M$, where Ui denotes the user set of domain i. We assume that users partially\noverlap between domains. Each user is treated as an individual client. User space refers to the virtual\nspace in the user's device containing domain models distributed from each domain server. Meanwhile,\nVi is the item set of domain i. Let Ri \u2208 R|Ui|\u00d7|Vi| be the observed rating matrix of the i-th domain.\nWe consider top-K recommendation, i.e., we learn a function to estimate the scores of unobserved\nentries in the rating matrix, which are later used for item ranking and recommendations. Our goal is\nto achieve highly accurate recommendations in the target domain."}, {"title": "3.2 Framework of FedGCDR", "content": ""}, {"title": "3.2.1 Overview", "content": "The overall framework of FedGCDR is shown in Figure 2. FedGCDR follows a Horizontal-Vertical-\nHorizontal (HVH) pipeline and its two horizontal stages ensure the intra-domain privacy (i.\u0435.,\nindividual user level) privacy. Our two key modules focus on the vertical stage and the second\nhorizontal stage: (1) The positive knowledge transfer module preserves the inter-domain privacy by\nDP and alleviates NT by feature mapping. (2) The positive knowledge activation module filters out\npotential harmful or conflicting knowledge from the source domains. Specifically, we expand the\nlocal graph of the target domain by virtual social links, such that the target domain GAT model could\ngenerate reliable domain attention based on the expanded graph. After target domain GAT model\ntraining, we further mitigate NT by adopting a fine-tuning stage.\nHorizontal-Vertical-Horizontal pipeline The HVH pipeline contains three stages with switching\nfederated settings. The first horizontal stage refers to the source domain training in which source\ndomain servers individually interacts with its domain users (clients). The private rating matrices are\nstored within each client, while the clients exchange model and gradients to train a domain-specific\nglobal model. The next two stages correspond to our two key modules (vertical positive knowledge\ntransfer module and horizontal positive knowledge activation module), which we will cover in detail"}, {"title": "3.2.2 Positive knowledge transfer module", "content": "After the source domain training, we obtain a series of source models in individual client's user space.\nOur positive knowledge transfer module then prepares positive knowledge to be transferred from\neach source domains Ds to the target domain D\u00b9, while protecting inter-domain privacy (CH1).\nSpecifically, suppose a individual user (client) u and a source domain DSi, we transfer the user u's\nembedding matrix $X_{S_i}$ in $R^{L \\times d}$. Take the row l of the matrix (i.e., $x_{S_i}^l$) as an example, it is the user\nu's embedding output by the l-th message propagation layer. In an ideal scenario (i.e., we transfer\ntotally positive knowledge without taking inter-domain privacy into account) [6], embedding matrices\nfrom different source domains can be directly used to enhance target domain local training in client u.\nBy utilizing the source domain embeddings, u's final target domain embedding $e_T^l$ of layer l is:\n$e_T^l = f_T(x_{S_1}^l, x_{S_2}^l, ..., x_{S_{M-1}}^l), l \\in [1, L]$\\nwhere $f_T(\\cdot)$ is the function that the target domain aggregates the knowledge of the source domains\nand we will give its expression in Subsection 3.2.3. In this process, the transfer of knowledge between\ndomains takes place entirely in the user u's local space. Such a fully localized mode of knowledge\ntransfer avoiding the additional communication overhead and potential privacy issues [6]. However,\nthis direct emebddings transfer does not meet the privacy and NT constrains in BS-CDR scenarios."}, {"title": "Privacy-preserving knowledge extraction", "content": "In existing CDR frameworks, the user or item embed-\nding was shared as knowledge [9; 15; 6], which neglects inter-domain privacy. In a GNN-based\napproach, such direct transfers are subject to privacy attacks. Each message propagation layer can be\nviewed as a function with user and item embeddings as input. An attacker can easily obtain the user's\nprivate rating matrix based on these embeddings. We apply DP to the souce domain embeddings $X_{S_i}$\n[20; 44] to safeguard inter-domain privacy.\nTHEOREM 1. By perturbing the source domain embeddings with Gaussian noise, the reconstructed\ndata of the ideal attack deviates from the real data and prevents a perfect reconstruction.\nIn FedGCDR, we adopt the Gaussian mechanism to the source domain embedding $X_{S_i}$, to obtain $\\tilde{X}_{S_i}$\nfor knowledge transfer. Detailed privacy analysis is included in Appendix A."}, {"title": "Feature mapping", "content": "User features (i.e., user embeddings) could represent personal preferences and\nare influenced by domain features (e.g., items). The discrepancy of domains leads to the heterogeneity\nof feature space between domains which means that source domain embeddings cannot be utilized\ndirectly by the target domain. Man et al. [15] show that there exists an underlying mapping\nrelationship between the latent user matrix of different domains, which can be captured by a mapping\nfunction. In order to alleviate NT, we adopt a series of MLP to explore mapping functions for each\nsource domain. Adding Gaussian noise and feature mapping, Equation (5) becomes:\n$e_T^l = f_T(\\tilde{x}_T^l, MLP_1(x_{S_1}^l), ..., MLP_{M-1}(x_{S_{M-1}}^l))$.\nTo learn more effective mapping function, we adopt a mapping loss term:\n$l_m = \\sum_{i=1}^{M-1} \\sum_{l=1}^{L} ||\\tilde{x}_{S_i}^l - MLP_i(x_{S_i}^l)||_2^2,$"}, {"title": "3.2.3 Positive knowledge activation module", "content": "After the aforementioned operations, the target domain obtains a list of source domain matrices\n$\\tilde{X}_{S_1}, \\tilde{X}_{S_2}, ..., \\tilde{X}_{S_{M-1}}$. The row of the matrices represent $MLP(x_{S_i}^l)$. It is worth noting that for\nsource domains where a user has no rating, $\\tilde{X}_{S_i}$ is a Gaussian noise matrix. Our consideration for\ndoing this is: (1) no rating may also suggest a preference; (2) this is beneficial for enhancing the\nmodel's capability to filter noise and identify NT. With the knowledge from the source domains,\nthe positive knowledge activation module is to alleviate NT after the knowledge transfer (CH2).\nAlthough we have aligned the feature space in the previous module, the Gaussian noise that has been\nfed to the target domain with source domain embedding matrices leads to potential NT. How to utilize\nthe transferred knowledge remains a great challenge."}, {"title": "Graph expansion and target domain training", "content": "To alleviate NT, common approaches are to\ngenerate domain attention by predefined domain features [13] or to control the transfer ratio of source\ndomains by hyper-parameters [7]. These methods are only applicable to a limited number of domains\nand have excessive human intervention. In FedGCDR, we take an attention-based approach. First,\nwe expand the u's (Mary's) local graph of the target domain as shown in Figure 3. For the source"}, {"title": "Target model fine-tuning", "content": "After target domain training with the expanded graph, the target domain\nGAT model assimilated knowledge from the source domains. However, NT may still be inevitable,\nand negative knowledge may have accumulated in the target domain. An example is that the Gaussian\nnoise matrices from the source domains where the user has no rating data. On the basis of this\nconsideration, we adopt an additional fine-tuning stage: First, we freeze the message propagation\nlayer of GAT to isolate the influence of source domains. This is because the Gaussian noise still floods\nthrough the transfer process. Second, we directly train the well-informed embeddings generated by\nthe target domain GAT. These steps adapt the learned external knowledge for predicting the target\ndomain ratings. In this process, we use the loss of prediction in Equation (11) as the object function:\n$L_{ft} = BCELoss(R_u^v, \\hat{R}_u^v).$"}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental setup", "content": "Datasets We study the effectiveness of FedGCDR with 16 popular domains on a real-world dataset\nAmazon [49]. To study the impact of the number of domains on model performance, we divide\nthese domains into three subsets containing 4, 8, and 16 domains respectively and denote them as\nAmazon-4, Amazon-8, and Amazon-16 respectively. We filter the original data in different ways,\nand more details are given in Appendix C.1. In our experiments, Books and CDs are selected as the\ntarget domains. For the ratings in each domain, we first convert them to implicit data, where entries\ncorresponding to existing user-item interactions are marked as 1 and others are marked as 0."}, {"title": "Baselines", "content": "We compare FedGCDR with the following state-of-the-art models: (1) FedGNN [33] is\nan attempt to adopt FL graph learning to recommender systems. Its recommendation performance\ncould represent the data quality of the target domain and reflect negative transfer. In Tables 1 and\n2, in order to distinguish FedGNN from the CDR baselines, we denote it by Single Domain. (2)\nEMCDR [15] is a conventional embedding-mapping CDR framework. We adjust it to the HFL\nframework following [6]. (3) PriCDR [17] is a privacy-preserving CDR framework, which adopted\nDP on the rating matrices rating matrix to ensure privacy. (4) FedCT [6] is a VAE-based federated\nframework that is the first attempt to protect intra-domain privacy in cross-domain recommendations.\n(5) FedCDR [7] is a dual-target federated CDR framework, where the user embeddings are transferred\nas knowledge to enhance the other domain's model training. To adapt to the BS-CDR scenarios, we\nmodify FedCDR by applying embedding averaging when receiving source domain embeddings."}, {"title": "4.2 Recommendation performance", "content": "We report the model performance results in Tables 1 and 2. Single domain shows that the Book\ndomain has better single-domain recommendation accuracy than the Music domain, which represents\nhigher data quality and quantity. Under BS-CDR settings, FedGCDR outperforms all CDR baselines\non all three sub-datasets, which confirms the effectiveness of the proposed model on real-world data.\nTo further study our model capacity in alleviating negative transfer, we first define two types of\nnegative transfer: (1) Soft Negative Transfer (SNT), where recommendation models' performance\nunder the multi-domain setting is worse than that under the single-domain setting. This means that\nthe knowledge from source domains poisoning the target domain's model training. (2) Hard Negative\nTransfer (HNT), where recommended performance of a large number of source domains is lower\nthan that of a small number of source domains. This means that the newly added domains are not\nconducive to the training of the target domain or conflict with the already added source domain.\nTaking the Books domain as the target domain, EMCDR, PriCDR, FedCT and FedCDR both have\nserious negative transfer problems and lower performance on the three data subsets. From the SNT\nperspective, their performances is much worse than that of Single Domain as shown in Figure 4.\nFrom the HNT perspective, their performances under 16-domain settings is worse than that under the\n8-domain and 4-domain settings, which suggests it is not appropriate to recklessly transfer knowledge"}, {"title": "4.3 Ablation study", "content": "To study the contribution of each module of FedGCDR, we implement two model variants,\nFedGCDR-M and FedGCDR-T. FedGCDR-T transfers the source domain embeddings with-\nout mapping. FedGCDR-M replaces the attention graph expansion with the average sum of source\ndomain embeddings and removes the fine-tuning. We experiment with Books and CDs as target\ndomains on the Amazon-16 dataset. The experimental results are shown in Figure 5. We make\nthe following observations: (1) The two variants perform differently on different target domains.\nOn the Books domain, FedGCDR-T performs better than FedGCDR-M, which indicates that for\ndomains with higher data quality, preventing the transfer of negative knowledge from other domains is\nmore important than mapping this knowledge better, and the Positive Knowledge Activation module\nmeets the requirements of such domains. On the CDs domain, FedGCDR-M performs better than\nFedGCDR-T, which indicates that for domains that are deficient in information, mapping knowledge\ncorrectly is more important than preventing inter-domain negative knowledge, and the Positive\nKnowledge Transfer module meets these requirements. (2) Compared to FedGCDR, the absence\nof either module can cause a significant drop in performance. This indicates that in cross-domain\nrecommendation, we should not only focus on transferring positive knowledge, but also control the\nspread of negative knowledge to the target domain, especially when a large number of domains."}, {"title": "5 Limitations", "content": "Our experiments were conducted on 16 domains of the Amazon dataset. While this extensive dataset\ncovers broader source domains, relying on a single dataset may limit the generalizability of our\nmodel to data from other sources. Our approach uses overlapping users as a cross-domain bridge."}, {"title": "6 Conclusion", "content": "We proposed FedGCDR, a federated graph learning framework designed for BS-CDR. FedGCDR\naddresses the critical challenge of privacy preservation and negative transfer by employing a positive\nknowledge transfer module and a positive knowledge activation module. Our privacy-preserving\nmethod achieves best recommendation quality results on 16 domains of the Amazon dataset. In the\nfuture, we aim to extend FedGCDR to improve the recommendaiton performance of both the target\nand the source domains."}, {"title": "A Privacy analysis", "content": "Due to the algorithmic nature of GNN, the source domain embeddings we pass are a function result\non the user embeddings and item embeddings. This means that in the event of a successful inference\nattack, our user item interaction matrix is exposed to the threat of privacy disclosure. So we use DP\nto further protect privacy.\nThreat model In this paper, we assume the threat model to be semi-honest (honest-but-curious).\nUnder this threat model, the participants adhere strictly to the FL protocol for collaborative model\ntraining. However, they are interested in the sensitive rating data and may attempt to extract as much\ninformation as possible from the transferred embeddings. Specifically, these semi-honest parties,\ni.e. the target domain, may employ inference attacks [50] on the embeddings to reconstruct or infer\nsensitive user-item interaction matrix of other domains.\nDEFINITION 1 (THE GAUSSIAN MECHANISM). Given a function $f : \\mathcal{D} \\rightarrow \\mathbb{R}^d$ over a dataset $\\mathcal{D}$, the\nGaussian mechanism is defined as:\n$F_G(x, f(\\cdot), \\epsilon) = f(x) + (r_1, ...r_k),$\nwhere $r_i$ is the random noise drawn from $\\mathcal{N} \\sim (0, \\sigma^2 \\Delta_f^2)$ and $\\sigma = \\sqrt{\\frac{2ln(1.25/\\delta)}{\\epsilon}}$. In FedGCDR,\nthe intra-domain GAT-based federated model is considered as the function f().\nTHEOREM 2. The Gaussian mechanism defined in Definition 1 preserves $(\\epsilon, \\delta)$-DP for each publica-\ntion step [20].\nFirst, we give the definition of the inverse function:\nDEFINITION 2 (INVERSE FUNCTION). Given a function $f : \\mathcal{D} \\rightarrow \\mathbb{R}^d$ over a dataset $\\mathcal{D}$, the inverse\nfunction $f^{-1}$ is defined as:\n$f^{-1} = \\underset{g}{argmin} \\sum_{i \\in U} \\sum_{v \\in V} || e_i - g(f(e_u, e_v)) ||_2,$\nwhere\n$e_u, e_v = Embedding(x), x \\in \\mathcal{D}.$\nFor the target domain, the embeddings received form source domains can be regarded as the functional\nresult of their models. Let the function be $f(\\cdot, \\cdot)$ and the input $e_u, e_v$ is the user embedding and item\nembedding respectively. The embeddings is the output $f (e_u, e_v)$. The target domain attempts to find\na inference attack function $I(\\cdot)$ which is as close to the inverse function as possible.\nDEFINITION 3 (PRIVACY LEAKAGE). Given a function $f : \\mathbb{E} \\rightarrow \\mathbb{R}^d$ over a Embedding set $\\mathbb{E}$ and an\ninference function I, the privacy leakage $\\Lambda$ is defined as:\n$\\Lambda = \\frac{1}{\\mathcal{U}} + \\frac{1}{\\mathcal{V}} \\sum_U Leak_u + \\sum_V Leak_v$\nwhere\n$Leak_u =|| e_i - I_u(f(e_u, e_v)) ||_2, i \\in \\mathcal{U},$\n$Leak_v =|| e_j - I_v (f(e_u, e_v)) ||_2, j\\in \\mathcal{V}.$\n|| e - $I(f(e_u, e_v))$ ||2 reflects the closeness of the reconstructed input to the true input. Therefore,\nprivacy leakage (PLeak) $\\Lambda$ is able to reflect privacy leakage of FedGCDR with the inference function\n$I(\\cdot)$. PLeak equal to 1 means a perfect reconstruction, and being close to zero means a bad recon-\nstruction. DP on the embeddings further ensures that attackers cannot perfectly reconstruct the raw\ndata.\nTHEOREM 2. If PLeak equals to 1 with the inference function $I(\\cdot)$, the function $f(\\cdot, \\cdot)$ is bijection.\nProof. If the function $f(\\cdot, \\cdot)$ is not bijection, there are $i, j \\in \\mathcal{D}$ and $i \\neq j$, but $f (e_i^u, e_i^v) = f(e_j^u, e_j^v)$\nand $I (f(e_i^u, e_i^v))$ and $I(f(e_j^u, e_j^v))$. This is a contradiction as the perfect reconstruction requires both\n$e_i^u, e_i^v = I(f(e_i^u, e_i^v))$ and $e_j^u, e_j^v = I(f(e_j^u, e_j^v))$ to achieve $\\Lambda = 1$. Therefore, the function $f(\\cdot, \\cdot)$\nmust be is bijection."}, {"title": "THEOREM 3.", "content": "Given the lipschiz constant L of the function f at x \u2208 D with the noise generated by\nGaussian mechanism N on embeddings. If f(eu, ev) + N \u2208 f, the distance between x to the\nreconstructed data of the attack $I(\\cdot)$ which achieves $\\Lambda$ = 1 is bounded by $\\frac{|N|}{L}$.\nProof. By Theorem 2, we have for x \u2208 D and v \u2208 f, $I(f(e_u, e_v)) = (e_u, e_v)$ and f(I(v)) = v,\nFrom the Lipschitz continuous,\n$|e - I(f(e_u, e_v) + N)| \\geq \\frac{|f(e_u, e_v) - (f (e_u, e_v) + N)|}{L} = \\frac{|N|}{L}.$\nTherefore, by perturbing the source domain embedding with Gaussian mechanism, the reconstructed\ndata of the ideal attack deviates from the real data and prevents a perfect reconstruction (i.e., $\\Lambda$ = 1)."}, {"title": "B Cost analysis", "content": "Due to the complexity of the FedGCDR pipeline, we perform a theoretical analysis of the computa-\ntional and communication cost of FedGCDR accordance with the HVH pipeline including horizontal\nsource domain training, vertical positive knowledge tranfer module and horizontal positive knowledge\nactivation module."}, {"title": "B.1 Computational cost", "content": "Given a GAT model, let V be the node set, E be the edge set, and F the embedding size. The\ncomputational cost of one propagation layer of classic GAT framework is $O(|V|FF' + |E|F')$ [37].\nIn the horizontal source domain training, our model is a simplified GAT variants which discard\nfeature transformation and non-linear activation. For a NK layer model, the simplified computational\ncost is O(NK|E|F). In the vertical positive knowledge tranfer module, space mapping is carried\nby a $N_m$ layers' MLP with computational cost $O(N_mF^2)$. In the horizontal positive knowledge\nactivation module, the first part is the simplified GAT model and the second part is the fine-tuning\nmodel with computational cost $O(F^2)$. In conclusion, for the FedGCDR framework with $N_D$ domains,\n$T_G$ GAT-based federated model traing epochs, and $T_F$ fine-tuning epochs, the total computational\ncost is $O(T_G (N_D N_K|E|F + N_mF^2) + T_F F^2))$. Cause $N_m F^2 \\ll N_D N_K|E|F$, we get the final\ncomputational cost $O(T_G N_D N_K|E|F +T_F F^2)).$"}, {"title": "B.2 Communication cost", "content": "In FedGCDR, the global model and item embeddings are held by the domain server. Let I be the\nitem set and F be the embedding size. The space complexity of global model and item embeddings\nare O(F) and $O(|I|F)$ respectively. In the horizontal source domain training, the domain server\ndistributes the global model and item embeddings and get the gradient with the same size. The\ncommunication cost is O(F + |I|F). In the vertical positive knowledge tranfer module, the $N_m$\nlayers' MLP and its gradients are transmitted with the commnication cost $O(N_mF^2)$. In the\nhorizontal positive knowledge activation module, the target domain additionally perform a fine-\ntuning stage with comunication cost O(|I|F). In conclusion, for the FedGCDR framework with\n$N_u$ users, $T_G$ GAT-based federated model traing epochs, and $T_F$ fine-tuning epochs, the total\ncommunication cost is $O(T_G N_u (N_mF^2+F+|I|F)+T_FN_m|I|F)$. Cause $N_m F^2+F < |I|F$, we\nget $O(N_u|I|F(T_G + T_F))$. According to the expression, the communication cost of our FedGCDR\nis basically equivalent to the cost of two HFL progress. The cost is reduced because knowledge\ntransfer takes place in user space, thus avoiding large-scale information exchange."}, {"title": "C Experimental details", "content": ""}, {"title": "C.1 Dataset details", "content": "The Amazon dataset we used is the 2018 version and can be easily accessd in https://cseweb.\nucsd.edu/~jmcauley/datasets/amazon_v2/. The basis of our domain selection strategy is the\namount of data before performing data filtering. Thus, we sorted the domains contained in the\nAmazon dataset based on the amount of data in descending order and selected the top 16 domains.\nSimilarly, Amazon-4 and Amazon-8 were selected accordingly. The only exception is that we"}, {"title": "C.2 Implement details", "content": "We provide the implemented details of our proposed model and baselines. We set batch size = 256\nand latent dim = 8 for all domains. The number of propagation layer of GAT-base federated model\nis set to 2. The MLP has two hidden layers with size={16, 4}.Considering the trade-off between\nrecommendation performance and privacy preservation, we set $\\epsilon$ to 8 and $\\delta$ to $10^{-5}$. We set a=0.01\nand $\\beta$=0.01 which are the two hyper-parameters of the objective function $L_{GAT}(\\cdot)$. When training\nour models, we choose Adam as the optimizer, and set the learning rate to 0.01 both in GAT-based\nfederated model training and the fine-tuning stage. To evaluate the recommendation performance, we\nuse the leave-one-out method which is widely used in recommender systems [48]. Specifically, we\nheld out the latest interaction as the test set and utilized the remaining data for training. Then, we\nfollow the common strategy which randomly samples 99 negative items that are not interacted with\nby the user for the rank list generation of the test set. We consider the top-k recommendation task as\nthe main experiment so we choose metrics including Hit Ratio (HR)@K score and the Normalized\nDiscounted Cumulative Gain (NDCG)@K [51] of the top-K ranked items with K=5, 10. We conduct\nthe experiments on three groups of random seeds and report the average results. We conduct all the\nexperiments on NVIDIA 3090 GPUs."}, {"title": "D Additional experimental results", "content": ""}, {"title": "D.1 Neagtive transfer on HR@10 and NDCG@10.", "content": "For HR@10 and NDCG@10 in Figure 6, our method and baselines show similar trends to the\nprevious HR@5 and NDCG@5. Compared to Figure 6, the slight difference is that FedCT's HR@10"}, {"title": "D.2 Dual-domain scenario", "content": ""}, {"title": "D.3 Privacy budget", "content": "To study the effects of privacy budget $\\epsilon$ on the model performance, we vary the privacy budget\n$\\epsilon$ = {4, 8, 16, 32, 64} to affect the $\\sigma$. We experimented on Amazon-16 with CDs as the target domain\nand fix $\\delta$ = $10^{-5}$. We report the results Figure 7. From that we can observe that the model's\nperformance decreases as $\\epsilon$ decreases, but the model performance is not completely destroyed by\nGaussian noise. Thus, there is a trade-off between accuracy and privacy, where a smaller $\\epsilon$ value\nadds more noise to embeddings for stronger privacy preservation but leads to more prediction error.\nTherefore, to balance the data privacy preservation capacity and the model performance, we set it as\n$\\epsilon$ = 8."}, {"title": "E Broader impacts", "content": "Our proposed FedGCDR is tailored for BS-CDR, focusing on the privacy and negative transfer\nproblems. CDR is widely uesd, while BS-CDR is generic and close to the reality. Our approach can\nbetter mine user preferences and effectively protect privacy. On the one hand, users will benefit from\nmore accurate recommendations and thus have a better experience in shopping, watching movies, etc.\nOn the other hand, various economic entities can gain more profits."}, {"title": "NeurIPS Paper Checklist", "content": ""}, {"title": "1. Claims", "content": "Question: Do the main claims made in the abstract and introduction accurately reflect the\npaper's contributions and scope?\nAnswer: [Yes", "nJustification": "We have claimed the contributions and scope in lines 5-7 and 69-75.\nGuidelines:\n\u2022 The answer NA means that the abstract and introduction do not include the claims\nmade in the paper.\n\u2022 The abstract and/or introduction should clearly state the claims made, including the\ncontributions made in the paper"}]}