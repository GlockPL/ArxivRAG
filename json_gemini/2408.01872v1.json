{"title": "Safe Semi-Supervised Contrastive Learning Using In-Distribution Data as Positive Examples", "authors": ["Min Gu Kwak", "Hyungu Kahng", "Seoung Bum Kim"], "abstract": "Semi-supervised learning methods have shown promising results in solving many practical problems when only a few labels are available. The existing methods assume that the class distributions of labeled and unlabeled data are equal; however, their performances are significantly degraded in class distribution mismatch scenarios where out-of-distribution (OOD) data exist in the unlabeled data. Previous safe semi-supervised learning studies have addressed this problem by making OOD data less likely to affect training based on labeled data. However, even if the studies effectively filter out the unnecessary OOD data, they can lose the basic information that all data share regardless of class. To this end, we propose to apply a self-supervised contrastive learning approach to fully exploit a large amount of unlabeled data. We also propose a contrastive loss function with coefficient schedule to aggregate as an anchor the labeled negative examples of the same class into positive examples. To evaluate the performance of the proposed method, we conduct experiments on image classification datasets\u2014CIFAR-10, CIFAR-100, Tiny ImageNet, and CIFAR-100+Tiny ImageNet-under various mismatch ratios. The results show that self-supervised contrastive learning significantly improves classification accuracy. Moreover, aggregating the in-distribution examples produces better representation and consequently further improves classification accuracy.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep neural networks have shown promising results in various supervised learning problems, including image classification [1], object detection [2], natural language processing [3], and signal data analysis [4]. It is well known that a large-scale training dataset with well-annotated labels is required for dependable performance in supervised learning tasks [5]. However, creating such extensive collections of labeled data is typically time-consuming and incurs high costs for many real-world problems. Consequently, it limits the broad adoption of deep neural networks for many practical issues and applications.\nSemi-supervised learning (SSL) algorithms have been proposed to reduce the labeling overload and improve model performance by leveraging unlabeled data when only a limited number of data samples have corresponding labels [6], [7]."}, {"title": "II. RELATED WORKS", "content": "Traditional deep SSL methods have raised the model capability to the point where it can achieve similar performance to supervised learning. They tackle the scenario when the class categories of labeled data and unlabeled data are identical. Pseudo-label was proposed as a method to use predicted class probabilities as targets for a standard supervised loss function [33]. Making the network produce confident predictions by minimizing the entropy for all unlabeled data has also been proposed [13]. The \u041f-Model introduced a simple framework to apply consistency regularization in SSL [14]. Consistency regularization means that even when subtle perturbations such as data augmentation are given to an input, a model should produce an output similar to that of the original input. Temporal ensembling was proposed as the second version of \u041f-Model, which aggregates past predictions to derive current predictions for improving classification accuracy and training speed [15]. An additional momentum-updated teacher network was introduced by mean teacher to enable the SSL model to produce stable predictions [16]. Virtual adversarial training (VAT) was proposed to enhance the model's robustness against local perturbations, which are approximated to those that most significantly affect the predictions during training [17]. Another study found that stochastic weight averaging (SWA) improved generalization performance by averaging network parameters along the trajectory of stochastic gradient descent [34]. Because the experiments to test these methods were conducted in different experimental settings, a unified evaluation protocol for SSL was provided [22]. Most recently, holistic approaches of UDA [35], MixMatch [18], and FixMatch [20] have yielded performance improvements inspired by strong data augmentations. However, the existing SSL methods are built on a strict assumption that there is no OOD data in the unlabeled data. This assumption is readily violated in many realistic circumstances, resulting in significant performance degradation.\nSeveral safe SSL methods have been proposed to tackle the class distribution mismatch problem by focusing on utilizing ID data to eliminate or reduce the negative impact of OOD data. The uncertainty-aware self-distillation (UASD) proposed a self-distillation method to dynamically filter out OOD data based on confidence scores calculated during training [23]. It stabilized the filtering process by averaging the confidence scores of past predictions on the validation dataset. DS3L adopted a bi-level meta learning optimization framework to impose the proper weight on the unlabeled data to improve generalization performance [24]. It used a single-layer network updated by only labeled ID data to decrease the influence of unlabeled OOD data. Multi-task curriculum framework (MTCF) was a proposed end-to-end trainable framework that detects OOD data and classifies ID data simultaneously [36]. OpenMatch combined the learning process of FixMatch and novelty detection to learn ID data representations while rejecting OOD data [37]. Semi-supervised open set classification (S2OSC) proposed a framework of simultaneously filtering the distinct OOD data and assigning new super-class labels to them. S2OSC also adopted knowledge distillation to effectively separate the remaining uncertain unlabeled data [38]. The performances of the abovementioned methods might lose the basic representations that OOD data possess, regardless of class. Contrary to the studies that consider OOD data to be totally harmful, transferable OOD data recycling (TOOR) proposed to reuse some OOD data having informative information by employing adversarial domain adaptation method [39]. The performances of the existing methods necessarily depend on the OOD data's detectability. We demonstrate that our method can improve classification performance by adopting SSCL approach without filtering the unlabeled OOD data.\nRecently, contrastive learning has gained great attention in self-supervised learning because of its ability to learn generalized representations without labels [40]. The main idea of SSCL is to make the representations from different data augmentations on an instance similar to but distinct from those of other instances. Noise contrastive estimation was successfully applied to compare instances rather than classifying them into pre-defined classes [31]. For high-dimensional time series data, an autoregressive model with a contrastive loss that predicts the future latent space was proposed [41]. Pretext-invariant representation learning (PIRL) uses a memory bank to store representations of all instances that are used for efficient negative sampling during training [42]. To address the memory inefficiency caused by large batch sizes or a memory bank with a memory queue, momentum contrast (MoCo) was proposed [43], [44]. This method also applies a momentum or exponential moving average update for the network to achieve consistency in the representation during training. SimCLR uses a simple end-to-end architecture that performs well through simultaneous negative sampling from large batch sizes [45], [46]. Several most recent studies successfully leveraged strong data augmentations. For example, SwAV used a multi-crop strategy to produce more views of an instance to increase the number of data augmentations along with a novel cluster-based contrastive loss function [27]. DINO also used the multi-crop strategy in synergy with vision transformer (ViT) [47]. Although the existing methods achieved much success, they have not yet been applied to the class distribution mismatch problem in SSL."}, {"title": "III. PROPOSED METHOD", "content": "We propose a safe semi-supervised contrastive learning method to mitigate the performance degradation caused by class distribution mismatch. The core principle of our method is the specific reassignment of labeled negative examples that share the same class label as the anchor, treating them as additional positive examples. The reassigned examples are indeed ID. Our method enhances the model's ability to identify and aggregate similar patterns within a class, thereby increasing the precision and distinctiveness of class representations. Additionally, by not discarding OOD data and instead utilizing it in our training process, we can more effectively learn the information commonly shared across the dataset.\nThe proposed method is based on MoCo, an SSCL approach renowned for its enhanced representation learning capability and computational efficiency. It is worth noting that the selection of MoCo as our foundation is attributed to its dynamic dictionary mechanism of a memory queue. MoCo maintains a memory queue of encoded representations, which are employed as negative examples. In the context of SSL, where labeled data is scarce, methods like SimCLR that do not utilize a memory queue require significantly larger batch sizes. This is because, in smaller batches, the number of negative examples with labels can be extremely low or even non-existent. However, large batch sizes often lead to memory shortage issues. To effectively implement our method, we designed our model based on the MoCo framework, which reduces the need for large batch sizes while ensuring a sufficient supply of labeled negative examples for contrastive learning in class distribution mismatch scenarios."}, {"title": "A. Problem Statement", "content": "Let \\(D = D_L \\cup D_U\\) be a training dataset, where \\(D_L = \\{(x_i, y_i)\\}_{i=1}^n\\) is the labeled data of n instances and \\(D_U = \\{x_j\\}_{j=1}^m\\) is the unlabeled data of m instances. In a typical SSL classification problem, \\(x \\in \\mathcal{X} \\in \\mathbb{R}^d\\), \\(y \\in \\{1, 2, \\ldots, C\\}\\), and \\(m \\gg n\\) where d is the number of input dimension and C is the number of classes. The goal of deep SSL is to train a parameterized network h that minimizes the following loss function:\n\\[\\mathcal{L}_{SSL} = \\sum_{(x_i, y_i) \\in D_L} \\ell_1(h(x_i, y_i)) + \\sum_{x_j \\in D_U} \\ell_2(h(x_j)),\\]\nwhere \\(\\ell_1\\) and \\(\\ell_2\\) are loss functions. In general, cross-entropy is used for \\(\\ell_1\\), and a regularization function is used for \\(\\ell_2\\). The network h converges to capture the data representations from D and classifies new instances with a clue from the limited number of \\(D_L\\). However, if the class distribution of \\(D_L\\) and \\(D_U\\) is different, the data representations are poorly learned, resulting in the classification performance degradation [22]."}, {"title": "B. SSCL: Instance Discrimination", "content": "SSCL methods conduct instance discrimination, enabling a model to utilize all information in unlabeled data without being adversely influenced by the distribution discrepancies between labeled and unlabeled data. The instance discrimination aims to learn the representations by making similar instances pull each other together and dissimilar instances push each other apart. To achieve this goal, stochastic data augmentation strategies are applied. Given an instance \\(x_i \\in D\\), two different views are generated by applying data augmentation twice: \\(x_i\\) and \\(x_i^+\\) denote the anchor example and positive example, respectively. Then, data augmentation is applied to K instances sampled from \\(D - \\{x_i\\}\\) to achieve negative examples \\(\\{x_{i,k}\\}_{k=1}^K\\). The representations of a positive pair \\((x_i, x_i^+)\\) must be close because they originate from an identical instance. On the contrary, the representations of any negative pair \\((x_i, x_{ik})\\) must be far away. Through a neural network f that embeds an input x to a representation vector \\(z = f(x) \\in \\mathbb{R}^{d'}\\), representations of positive and negative pairs can be achieved, denoted by \\((z_i, z_i^+)\\) and \\((z_i, z_{ik})\\), respectively. The output vector z is normalized by its L2-norm [31]. Consequently, the contrastive loss function of instance discrimination is formulated as follows:\n\\[\\mathcal{L}_{MoCo} = -\\log \\frac{\\exp(z_i \\cdot z_i^+ / \tau)}{\\exp(z_i \\cdot z_i^+ / \tau) + \\sum_{k=1}^K \\exp(z_i \\cdot z_{ik} / \tau)} ,\\]\nwhere \\(\tau\\) is a temperature hyperparameter for scaling. Because the representation vector z is L2-normalized, the inner dot product can easily measure the similarity of a pair's corresponding components. From the instance discrimination point of view, minimizing \\(\\mathcal{L}_{MoCo}\\) is equivalent to maximizing the probability of assigning an anchor example to a positive example among K + 1 instances consisting of one positive example and K negative examples.\nTo compare the anchor with other examples, following the MoCo framework, we utilized two networks: key network \\(f_{\theta_k}\\) and query network \\(f_{\theta_q}\\), where \\(\theta_k\\) and \\(\theta_q\\) denote the corresponding weight parameters. The networks are trained to find the similar representation of query (anchor) from keys (positive and negative examples); namely, \\(z_i^q = f_{\theta_q}(x_i)\\), \\(z_i^+ = f_{\theta_k}(x_i^+)\\), and \\(z_{ik} = f_{\theta_k}(x_{ik})\\) can be obtained. Specifically, \\(\theta_k\\) is not backpropagated after every iteration. Instead, it is updated by an exponential moving average or momentum update of \\(\theta_q\\). The update rule is formulated as follows:\n\\[\theta_k \\leftarrow m \\cdot \theta_k + (1-m) \\cdot \theta_q,\\]\nwhere \\(m \\in [0, 1)\\) is the momentum coefficient. m is usually set by a large value, such as 0.950 or 0.999. The slightly changing key network preserves the consistency of key representations. It makes the instance discrimination task difficult enough, and consequently, the model converges to generate proper representations [43]."}, {"title": "C. Proposed Contrastive Loss and Schedule Method", "content": "It is known that the classes are linearly separable on an L2-normalized unit hypersphere if the instances are successfully discriminated and semantically well-clustered (Figure 4a). Therefore, if desired, we can simply use MoCo to provide initial parameters for SSL. However, we expect the model to have an additional characteristic to separate ID data from OOD data because we consider the SSL under the class distribution mismatch (Figure 4b). The model should provide representations suitable for performing the downstream classification problem, and the OOD data are not of interest for classifying. To address this consideration, we propose a loss function that uses the labeled negative examples of the same class as the anchor and thus as additional positive examples. Incorporating additional information as positive examples should proceed carefully.\nIn particular, in a class distribution mismatch scenario, the overall semantic data structure might be easily broken when an OOD instance is selected as the positive example of the corresponding ID anchor and vice versa. To this end, we aggregate the labeled data, which are indeed ID, into positive examples.\nThe loss function is formulated as follows:\n\\[\\mathcal{L}_{ID} = -\\frac{I(i)}{\\sum_{p \\in \\mathcal{P}(i;t)} \\exp(z_i \\cdot z_p^+ / \tau)} ,\\]\nwhere \\(I(i)\\) is an indicator function that \\(I(i) = 1\\) if an anchor \\(x_i \\in D_L\\), otherwise \\(I(i) = 0\\). The proposed loss function is only applicable when the anchor has class information. \\(\\mathcal{P}(i; t)\\) denotes an index set of labeled keys of the memory queue at iteration t having the same class as the anchor. As the keys in a memory queue dynamically change along training iteration, \\(\\mathcal{P}(i; t)\\) also changes accordingly.\n\\(\\mathcal{L}_{ID}\\) helps the model learn data representations that are more beneficial for downstream classification tasks. On the other hand, \\(\\mathcal{L}_{MoCo}\\), which is applied to all data, performs instance discrimination, enabling the learning of more nuanced features within each class. We train the proposed model using a weighted sum of the two losses, balancing the need for detailed intra-class feature learning and effective data representation for classification.\nThe memory queue is a key feature of MoCo, allowing for the storage of past representations generated by the key network. At the end of every training iteration, the current representations \\(\\{z_i^+\\}_{i=1}^B\\) are enqueued to the memory queue, and the most outdated and the least consistent B representations in the queue are dequeued, where B refers to the mini-batch size. With this operation, MoCo maintains the keys on-the-fly during training with manageable extra computations. We modified the memory queue to be appropriate for addressing the safe SSL problem. Our modification allows the memory queue to store not only the representations but also their corresponding class information. It equips the memory queue with the capability to pair each stored representation with its class label, offering a more organized and informative approach to managing representations.\nIn our method, we recognized the potential for overfitting due to the reuse of the same labeled data in both the pre-training and fine-tuning phases. This risk can be particularly pronounced in SSL because of the limited amount of labeled data available. To address this, we applied a coefficient schedule \\(\\omega(t)\\) to gradually reduce the influence of the proposed loss function, \\(\\mathcal{L}_{ID}\\), on the model training as the training progresses. Instance discrimination, which is the focus of \\(\\mathcal{L}_{MoCo}\\), represents a more challenging task than class discrimination, which is the focus of \\(\\mathcal{L}_{ID}\\). If the influence of \\(\\mathcal{L}_{ID}\\) remains strong throughout the training process, it may hinder the model's ability to adequately learn from \\(\\mathcal{L}_{MoCo}\\). In the initial stages of training, \\(\\mathcal{L}_{ID}\\) plays a critical role in ensuring that class representations are effectively clustered. However, as training progresses, reducing its influence becomes reasonable to prevent the model from being overly tuned to \\(\\mathcal{L}_{ID}\\) at the expense of \\(\\mathcal{L}_{MoCo}\\).\nTherefore, a schedule of the balance coefficient is essential. For simplicity, we adopted a function that starts at one and decreases linearly to zero at epoch \\(t_{end}\\) for \\(\\omega(t)\\), which constantly remains zero after \\(t_{end}\\). The coefficient schedule is designed to adjust the balance between the two types of learning as training progresses, thereby facilitating robust generalization and reducing the risk of overfitting. The final loss function is formulated as follows:\n\\[\\mathcal{L}_i = \\mathcal{L}_{MoCo} + \\alpha \\omega(t) \\mathcal{L}_{ID},\\]\nwhere \\(\\alpha\\) is a balancing hyperparameter. After pre-training, the final SSL classifier is trained on \\(D_L\\) through the fine-tuning phase. Details of the fine-tuning are illustrated in Section IV."}, {"title": "IV. EXPERIMENTS", "content": "For a thorough and fair comparison, we followed the experimental settings and evaluation protocol for SSL with class distribution mismatch proposed by [22] and [23]. We used three benckmark datasets for our experiments: CIFAR-10, CIFAR-100, and Tiny ImageNet. Both CIFAR-10 and CIFAR-100 consists of 60,000 color images of size 32 \u00d7 32, from which 50,000 and 10,000 images were used for training and testing, respectively. The images were equally divided according to the number of classes, 10 or 100. Tiny ImageNet consists of 200 classes, with 500 traiing images and 50 testing images for each class. Because the size of all Tiny ImageNet color images is 64 \u00d7 64, all Tiny ImageNet samples were resized to 32\u00d732, the same size as CIFAR-10 and CIFAR-100.\nFirst, we modified CIFAR-10 to examine the performance of the proposed method within various mismatch ratios. We designed a 6-class classification task to classify animals. Among the classes of CIFAR-10, bird, cat, deer, dog, frog, and horse were considered ID classes. On the other hand, airplane, car, ship, and truck were considered OOD classes. For each class, 400 images were used as training labeled data (\\(D_L\\)), 400 images were used as validation data, and the rest were used as training unlabeled data (\\(D_U\\)). We set the mismatch ratio from 0% to 100% by changing the classes constituting the unlabeled data, as shown in Table I. For instance, for a mismatch ratio of 50%, the classes of the unlabeled data consisted of frog, horse, airplane, and car. Second, we modified CIFAR-100 and Tiny ImageNet to evaluate the performances under class distribution mismatch in larger class spaces. From 100 of CIFAR-100 classes, the 1~50 classes were used as labeled classes, and 26~75 classes were used as unlabeled classes. From 200 Tiny ImageNet classes, the 1~100 classes were used as labeled classes, and the 51~150 classes were used as unlabeled classes. Therefore, the mismatch ratio of the modified datasets is 50%. For each class, 100 images per class were used as \\(D_L\\), 100 images were used as validation data, and the rest were used as \\(D_U\\).\nTo more extensively evaluate our method, we created a cross-dataset scenario by combining CIFAR-100 and Tiny ImageNet. Following the data construction method proposed by UASD [23], CIFAR-100 was used as labeled data and Tiny ImageNet was used as unlabeled data. Because Tiny ImageNet contains the same or similar classes as CIFAR-100, we can create a class distribution mismatch scenario. We denoted the dataset as CIFAR-100+Tiny ImageNet and the mismatch ratio is 86.5%.\nFor both SSL and SSCL, model performances can change quite a bit depending on which data augmentation strategy is applied to which method. Therefore, it is important to carefully select the appropriate data augmentation. To directly demonstrate the effectiveness of using an SSCL approach for safe SSL, we used similar data augmentation strategies for SSL and the proposed method. For SSL methods, we used a standard strategy consisting of random resizing, random cropping, random horizontal flipping, and adding Gaussian noise [22]. For the proposed method, random color jittering and grayscale conversion are substituted for the Gaussian noise [44]. In SSCL, applying the color-related data augmentations is important. Because the cropped images from an identical image share the nearly same color histogram, the model focuses on merely memorizing the histogram, resulting in poor representations [45]. The aforementioned strategies are suitable and are generally used for the methods described in Section IV-B."}, {"title": "B. Model Configuration and Training Parameters", "content": "We compared the proposed method with a supervised model trained on only labeled data, six representative deep SSL methods, and four state-of-the-art safe SSL methods. The SSL methods are pseudo-label [33], VAT [17], \u041f-Model [14], temporal ensembling [15], mean teacher [16], and SWA [34]. Although these methods have achieved great results, they operate under the conventional SSL assumption that the class distribution mismatch does not exist. MTCF [36], DS3L [24], UASD [23], and TOOR [39] are recently proposed safe SSL methods that consider the challenging scenario in which the identical distribution assumption is violated. MTCF considers that the ID and OOD data are originated from two different domains and distinguishes them with curriculum learning. DS3L uses an extra weight network to control the amount of influence on a training classifier per unlabeled data observation while UASD adopts a self-distillation framework to robustly calculate confidence scores, which are consequently used to dynamically filter out the OOD data during training. TOOR reuses the OOD samples that have similar representations to labeled data by positioning them on similar feature space with adversarial domain adaptation. We conducted experiments to directly demonstrate that learning general data representations based on SSCL can enhance the model performance without unlabeled OOD data detection."}, {"title": "C. Evaluation Protocol", "content": "After pre-training, we evaluated the quality of representations by two commonly used protocols: simple weighted k-nearest neighbor classification (k-NN) and linear classification [27], [31], [47]. First, we froze the pre-trained model to compute the representation vectors of the training data for k-NN classification. Then, the k-NN classifier matches the label of a validation or test image to the label voted by k-nearest training images. This evaluation can be conducted without any other hyperparameter tuning or additional model training. Therefore, we can continuously monitor the k-NN accuracy not only after the pre-training has ended, but also during the pre-training. We used k of 5 and 200. The accuracy obtained with small k values indicates how well semantically similar ID instances are clustered, while the accuracy with large k values indicates how linearly separable each class is.\nSecond, for the linear classification, we froze the weights of the pre-trained network. The multilayer perceptron was replaced with a single-layer softmax classifier with a dimension of C. We trained the classifier on \\(D_L\\) for 100 epochs. An SGD optimizer with a learning rate of 30 was used, and the learning rate gradually decreases to zero using a half-period cosine schedule. We only applied horizontal flipping and random cropping for training the linear classifier. No data augmentation was applied to the testing dataset.\nFinally, we conducted a supervised fine-tuning to evaluate the classification performance of the proposed method. The fine-tuning resembles the approach used in the linear classification, where we substituted the multilayer perception with a single-layer softmax classifier. It is important to note that during the fine-tuning phase, we did not freeze the pre-trained network; instead, we allowed further training and adjustments on weights to occur. This approach was employed to ensure that the model adpats more effectively to the specific characteristics of \\(D_L\\), resulting in high classification accuracy. We fine-tuned the network on \\(D_L\\) for 100 epochs. Except for the learning rate of 0.03, optimizer, learning rate schedule, and data augmentations used the same settings as those used for the linear classification. Consequently, we can achieve a trained safe SSL classifier that plays the same role as h(x) in Equation 1. We reported the average performances with standard deviations in parentheses over five runs for all experiments."}, {"title": "D. Results", "content": "First of all, we investigated the effect of hyperparameters of \\(\\alpha\\) and \\(t_{end}\\) for pre-training. In general, the balancing hyperparamters used for adding a new loss term strongly affects model performance. We conducted experiments on CIFAR-10 with a mismatch ratio of 50% varying the values of \\(\\alpha\\) and \\(t_{end}\\). The scenario was chosen as an intermediate level of difficulty among various mismatch scenarios. Tables II, III, and IV show the k-NN and linear classification accuracy over different values of \\(\\alpha\\) and \\(t_{end}\\). \\(t_{end}\\) = none means that no schedule is applied and the value of \\(\\omega(t)\\) is always one during pre-training. Additionally, we report the performances of MoCo that uses only \\(\\mathcal{L}_{MoCo}\\) as a baseline.\nTables II, III, and IV present the representation qualities evaluated through 5-NN, 200-NN, and linear classification, respectively. Notably, our method consistently outperforms the baseline MoCo across various settings of \\(\\alpha\\) and \\(t_{end}\\). The NN-based classification accuracy, assessed during the model's pre-training phase, demonstrates that our approach that utilizes additional class information can more effectively bring representations of the same class closer together compared to MoCo, which solely relies on instance discrimination.\nThe proposed model achieved its highest performance with \\(\\alpha\\) = 2 and \\(t_{end}\\) = 200, marking a significant improvement of approximately 9% over MoCo. This highlights the effectiveness of our coefficient schedule, enabling the pre-training phase to yield representations that are more beneficial to downstream classification tasks. Additionally, Table IV shows that without the coefficient schedule, i.e., \\(t_{end}\\) = none, there is a decline in the linear evaluation performance of the proposed model, contrasting with the NN-based results. This performance reduction is attributed to overfitting, which occurs due to the use of a limited amount of labeled data in both the pre-training and linear classification phases. This outcome emphasizes the necessity of the coefficient schedule for maintaining the model's generalizability, as it prevents over-adaption to the small labeled data. Based on these results, we fixed \\(\\alpha\\) to 2 and \\(t_{end}\\) to 200 in all remaining experiments.\nWith the fixed hyperparameters \\(\\alpha\\) = 2 and \\(t_{end}\\) = 200, we compared the performance of MoCo and the proposed method in various datasets. We evaluated the yielded representation quality by linear classification; the results are shown in Table V. The results confirmed that the proposed method yielded better representations than MoCo in all cases, showing performance improvements of about 5% on average. In the experiments that changed the mismatch ratio in CIFAR-10, the model's overall performance is degraded because the larger the mismatch ratio, the more difficult the scenario is. Recall that there is no ID data in the unlabeled data when the mismatch ratio is 0%. Nevertheless, the proposed method performed well with substantial performance gaps. The proposed method also yielded better results in CIFAR-100 and Tiny ImageNet.\nTo further assess the representation quality, we visualized the data representations to analyze how the proposed loss function and coefficient schedule affected model training. The representations were obtained from CIFAR-10 with a mismatch ratio of 50%. A vanilla MoCo, a model in which the proposed loss function is added to MoCo without a schedule, and the proposed model using a schedule were compared. The 128-dimensional representations obtained from each model were reduced to two-dimension vectors by t-SNE for visualization [51]."}, {"title": "V. CONCLUSIONS", "content": "In this study, we proposed a safe semi-supervised contrastive learning method built upon MoCo. It is the first study to apply a SSCL approach to SSL with OOD data. The proposed method contributes to considerable gains in classification performance in various SSL scenarios involving class distribution mismatches. Because the MoCo learns data representations in terms of instance discrimination, it has the advantage that there is no need to consider the mismatch problem. A new contrastive loss function that utilizes the labeled examples of the same class for additional positive examples was introduced. It helps ID data to be well clustered compared to simple MoCo. We also proposed the use of a coefficient schedule to prevent the model from being overfitted to the small amount of labeled data. To verify the proposed method, we conducted experiments on image classification datasets, CIFAR-10, CIFAR-100, Tiny ImageNet, and CIFAR-100+Tiny ImageNet. We confirmed that applying the proposed loss function with its coefficient schedule greatly enhanced the model performance in terms of both representation quality and classification accuracy.\nAlthough the proposed method showed favorable results, it can be extended in several interesting directions. First, an adaptive scheduling strategy is required. For simplicity, we used a linearly decaying schedule. However, this is also a limitation of our method. The learning curve of the model differs depending on the type of data, and it needs a lot of time and effort to find the appropriate hyperparameter for each dataset. In some cases, labeled information may be needed again in the middle of training. It is thus necessary to design a metric that can quantify the characteristics and develop a method for adaptively adjusting the coefficient of the proposed loss function. Second, we could consider selecting candidates for positive examples from the unlabeled negative examples. The proposed method considers only labeled data as additional positive examples in a safe manner. However, it is evident that a better representation can be obtained if the unlabeled negative examples can also be utilized. Especially in scenarios where label information is extremely rare, it is more necessary to search for useful information in the unlabeled data. Third, it would be interesting to develop a model adept at OOD detection while improving classification performance. From a data collection point of view, there is no need to continuously collect and store unnecessary data. Although the proposed method aimed to achieve high classification performance using the given training data, it will also be necessary to develop an OOD detection model to reduce the data collection cost.\nLastly, we can apply the recent algorithms using strong data augmentations in the pre-training phase. To see the effect that can be obtained when applying SSCL, we restricted the study to using a few basic strategies. However, we expect a further performance gain can be achieved by searching for the proper pair of algorithm and data augmentations."}]}