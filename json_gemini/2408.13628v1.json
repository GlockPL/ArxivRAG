{"title": "Enhancing Uplift Modeling in Multi-Treatment Marketing Campaigns: Leveraging Score Ranking and Calibration Techniques", "authors": ["Yoon Tae Park", "Ting Xu", "Mohamed Anany"], "abstract": "Uplift modeling is essential for optimizing marketing strategies by selecting individuals likely to respond positively to specific marketing campaigns. This importance escalates in multi-treatment marketing campaigns, where diverse treatment is available and we may want to assign the customers to treatment that can make the most impact. While there are existing approaches with convenient frameworks like Causalml, there are potential spaces to enhance the effect of uplift modeling in multi treatment cases. This paper introduces a novel approach to uplift modeling in multi-treatment campaigns, leveraging score ranking and calibration techniques to improve overall performance of the marketing campaign. We review existing uplift models, including Meta Learner frameworks (S, T, X), and their application in real-world scenarios. Additionally, we delve into insights from multi-treatment studies to highlight the complexities and potential advancements in the field. Our methodology incorporates Meta-Learner calibration and a scoring rank-based offer selection strategy. Extensive experiment results with real-world datasets demonstrate the practical benefits and superior performance of our approach. The findings underscore the critical role of integrating score ranking and calibration techniques in refining the performance and reliability of uplift predictions, thereby advancing predictive modeling in marketing analytics and providing actionable insights for practitioners seeking to optimize their campaign strategies.", "sections": [{"title": "1 INTRODUCTION", "content": "Marketing campaigns are continuously seeking optimization to identify the right customers who will be most impacted by specific interventions. Uplift modeling [4, 5, 13] has emerged as a powerful tool to address this need by identifying the causal effect of a campaign on individual outcomes. Specifically, uplift modeling quantifies this causal effect using the Conditional Average Treatment Effect (CATE), which has proven effective in various scenarios. However, real-world marketing campaigns can be complex, often involving multiple treatment methods within a single campaign. In these multi-treatment marketing campaign scenarios, more detailed and sophisticated approaches are required.\nSeveral libraries, such as CausalML [2] or EconML[1], offer convenient ways to apply uplift modeling in multi-treatment cases. However, a question arises: 'Why not use multiple single-treatment models, applying single treatment modeling for each treatment and then selecting the highest effect treatment for each individual?' This approach can be particularly useful when there are many features to consider, allowing for feature selection tailored to each treatment. While this method can serve as an alternative to existing multi-treatment solutions, it necessitates additional steps, such as score ranking and calibration techniques, to enhance the reliability of uplift predictions.\nIn this paper, we introduce a novel approach to optimizing multi-treatment marketing campaigns based on CausalML. Instead of directly applying the multi-treatment logic provided by existing framework, we propose using multiple single-treatment models, augmented by score ranking to directly compare treatment effects on individuals, and calibration techniques to improve the reliability of uplift predictions.\nOur main contributions are as follows:\n\u2022 Applying multiple single-treatment models and selecting the best treatment for each individual, rather than relying on a single multi-treatment model\n\u2022 Implementing a score ranking method to ensure that treatment effects are on the same scale for accurate comparison\n\u2022 Utilizing calibration techniques to enhance the robustness of uplift models\nThese contributions aim to advance the precision and reliability of uplift predictions, thereby providing more actionable insights for optimizing marketing campaign strategies. Through extensive"}, {"title": "2 RELATED WORK", "content": "Uplift modeling in multi-treatment contexts has been approached in various ways."}, {"title": "2.1 Decision tree-based approach", "content": "Decision tree-based approaches provide logics in terms of splitting criteria to effectively handle multi-treatment cases. One such approach defines the split criteria based on arbitrary divergence between two distributions: (1) all treatments and the control group, and (2) the differences between treatments themselves [8]. Another decision tree-based approach, the Contextual Treatment Selection (CTS) algorithm, directly maximizes the expected response from the decision tree by optimizing the splitting criteria [12]."}, {"title": "2.2 Meta-learner based approach", "content": "Extending meta-learners[5] to support multiple treatments has been proposed by expanding the propensity score model to calculate the Conditional Average Treatment Effect (CATE) for each treatment group [13]. This approach also introduces a net value optimization framework by modifying treatment effect. The lift is measured using the observed value, the estimated response, and considering the cost function for each treatment."}, {"title": "2.3 Multi-armed bandit approach", "content": "Another interesting work utilizes a multi-armed bandit approach to define customer-level treatment effects by measuring the difference between receiving treatment t and not receiving treatment t, where t refers to one of the multiple treatments [9]. This method follows a logic similar to one-vs-all multi-treatment classification."}, {"title": "2.4 Optimization framework", "content": "An optimization framework has also been proposed as a direction for improvement. While it primarily relies on single-treatment cases, a dynamic calibration technique [3] has been introduced. This technique adjusts the model threshold dynamically and optimizes the incremental treatment outcome, ensuring compliance with the required Return on Investment (ROI) constraints."}, {"title": "3 METHODOLOGY", "content": null}, {"title": "3.1 Problem Definition", "content": "Our problem focuses on recommending a group of customers who would benefit most from the marketing campaign. Given a limited budget, the marketing team aims to maximize the campaign's impact.\nOur uplift modeling framework is based on Rubin's approach [7]. We denote Y as the response flag (or revenue) for customer i at treatment t (t = 0 for the control group, t = 1 for the treatment group), X as a vector of features, and $x_i$ as the feature value per customer [13]. Here, we rank customers by the highest lift, defined as having the highest Conditional Average Treatment Effect (CATE), where:\n$\\tau(x_i) = E[Y_i(1) \u2013 Y_i(0) | X = x_i]$\nFor the multi-treatment case, we expand this formula as follows:\n$\\tau_t(x_i) = E[Y_i(t) - Y_i(0) | X = x_i]$\nwhere t = n (n > 0) denotes a treatment condition n, and t = 0 denotes the control condition, assuming we have n treatments in the given marketing campaign.\nWe then compare each treatment effect and select the most effective treatment for each customer as:\nassign treatment = $max_t \\tau_{t_i}(x_i)$\nFinally, we establish a cutoff point (or threshold) to assign customers to treatment groups based on the top percentile, where we can achieve the highest lift."}, {"title": "3.2 Meta-Learner as a baseline", "content": "Our baseline approach is mainly focusing meta-learner, as it has been constantly developed and now is one of the robust approach. This ranges from simple approach such as S/T learners to more complex approach such as X learner. Note that we used those learners from CausalML [2] package for convenience."}, {"title": "3.2.1 S-learner", "content": "\"Single\" estimator learner [2, 5] would be considered as one of the simplest approach in meta-learner. S-learner estimates the treatment effect using a single machine learning model by estimating the average outcome $\\mu(x)$ with covariates X and an indicator variable for treatment T:\n$\\mu(x, t) = E[Y | X = x, T = t]$\nand define the CATE estimate as:\n$\\tau(x) = \\mu(x, 1) \u2013 \\mu(x, 0)$"}, {"title": "3.2.2 T-learner", "content": "\"Two\" estimator learner [2, 5] is probably one of the well-known approaches in meta-learner. This \"Two Model Approach\" takes two steps. First, it estimates the control response function by a base learner as:\n$\\mu_0(x) = E[Y(0) | X = x]$\nSecond, it estimates the treatment response function as:\n$\\mu_1(x) = E[Y(1) | X = x]$\nwith a potentially different base learner.\nFinally, it estimates the treatment effect by the differences between treatment and control response functions as:\n$\\tau(x) = \\mu_1(x) \u2013 \\mu_0(x)$"}, {"title": "3.2.3 X-learner", "content": "The X-learner builds on the T-learner but differs in that it uses the ground truth observations in the training set in an \"X\"-like shape [5]. This approach is well-known for using \"pseudo-effects\". First, it uses the same treatment and control response functions as:\n$\\mu_0(x) = E[Y(0) | X = x]$\n$\\mu_1(x) = E[Y(1) | X = x]$"}, {"title": "3.2.4 Meta-learners in Multi-Treatment Cases", "content": "As a baseline approach, we follow methodologies for multi-treatment cases proposed and embedded in CausalML [2, 13]. This approach utilizes propensity scores to estimate the CATE, and handle cost differences across treatments by updating the cost function in the treatment effect formula accordingly."}, {"title": "3.3 Calibration with Meta-Learner", "content": "A classifer is well-calibrated if the class probabilities accurately represent the true probabilities. For uplift modeling, we extend it to calling the model well calibrated if given different priors, treatments or control, the predicted outcome is close to the real outcome on individual level. In the context of uplift modeling, calibration ensures that the probability estimates produced by our models are accurate and reliable, thereby improving decision-making processes in marketing campaigns. The methodologies behind calibration involve adjusting the model outputs to correct any biases or inaccuracies, making the predicted probabilities more reflective of true likelihoods."}, {"title": "3.3.1 Calibration Techniques", "content": "Isotonic regression is a non-parametric method that fits a non-decreasing function to the predicted probabilities. This approach is beneficial when the predicted probabilities do not exhibit a monotonic relationship with the true probabilities, as it ensures a more accurate alignment."}, {"title": "3.3.2 Implementation", "content": "Utilizing the CalibratedClassifierCV module from sklearn [6], we applied isotonic regression to ensure that our uplift models produce well-calibrated probability estimates. The implementation process involves:\n\u2022 Training uplift models using Meta-Learner frameworks (S-learner, T-learner, X-learner)[5]\n\u2022 Applying isotonic regression [10, 11] to the model outputs.\n\u2022 Evaluating the calibrated models using Area Under the Uplift Curve(AUUC) [4, 8], uplift score plotting, and accuracy on the validation dataset.\nCalibration enhances the robustness and reliability of our predictions, ensuring that the uplift scores reflect true probabilities of treatment effects. This improves the accuracy of targeting and decision-making in marketing campaigns."}, {"title": "3.3.3 Measuring Calibration", "content": "To assess the effectiveness of calibration, we compared uplift modeling with and without calibration using the AUUC score. The process involved:\n\u2022 AUUC Score Comparison: The metric is calculated by sorting the individual on their predicted uplift score from highest to lowest, divided the sorted group into 100 groups, and computing the difference between treatment and control across these segments. We measured the AUUC for models before and after applying calibration techniques.\n\u2022 Uplift Score Distribution: Plot the uplift curve by placing the cumulative uplift on the y-axis and the proportion of the population on the x-axis. By observing the distribution of uplift scores, we compared models before and after applying calibration techniques.\n\u2022 Uplift at Different Quantiles: Sorting individual based on their uplift score from highest to lowest. We compared the conversion rates among the top 10%, 20%, and other quantiles between the calibrated and uncalibrated models."}, {"title": "3.4 Scoring Rank: Offer Selection Strategy", "content": "In multi-treatment marketing campaigns, selecting the most effective treatment for each individual is a complex task. To address this, we propose a scoring methodology which involves standardizing uplift scores to identify the best offer. Furthermore, we conduct a comparative analysis between this standardization approach and the direct ranking of uplift scores to evaluate the effectiveness in selecting the most suitable treatment."}, {"title": "3.4.1 Ranking the Uplift Score and Comparing Ranks", "content": "Calculate uplift scores for each treatment using Meta-Learner models. Rank individuals based on their uplift scores for each treatment and compare these ranks to identify the treatment with the highest uplift for each individual. Ranking individuals based on their uplift scores helps in identifying the most responsive candidates for each treatment, thereby optimizing the allocation of marketing resources."}, {"title": "3.4.2 Z-score Standardization of Uplift Scores", "content": "Compute the mean and standard deviation of the uplift scores for each treatment. Transform the uplift scores into Z-scores and compare the Z-scores across treatments for each individual. Based on the comparison, select the optimal treatment. Standardizing uplift scores using Z-scores allows for comparisons on a common scale, it can highlight the most impact treatments.\nAfter applying either the direct ranking method or Z-score standardization, integrate the results to select the optimal treatment for each individual. We validated the outcomes using cross-validation and out-of-sample testing. This approach ensured the robustness of the methods and allowed us to determine which technique performed better."}, {"title": "4 EXPERIMENT SETUP", "content": "The experimental setup involved utilizing vehicle A, and the campaign was designed as a follow-up to a prior marketing campaign conducted in recent year. This section outlines the details of the campaign, and A/B test experiment setup."}, {"title": "4.1 Campaign Overview", "content": null}, {"title": "4.1.1 Initial Marketing Campaign", "content": null}, {"title": "4.1.2 Follow-Up Campaign", "content": "\u2022 Timeframe: The follow-up campaign was conducted within a brief period following the evaluation of the initial marketing campaign's results.\n\u2022 Total Circulation: A large group of customers were targeted in this campaign, divided into two creative versions: Version A: Treatment A was applied, targeting a subset of the overall targeted customers. This group was equally divided between those who had and had not received prior treatment in the initial campaign.\nVersion B: Treatment B was a more generic version, targeting a subset the overall targeted customers. This group included a mix of those who had and had not received prior treatment.\nNote that both versions contained a sufficient number of customers, and balancing criteria were applied to ensure that both groups are unbiased."}, {"title": "4.2 Uplift Modeling", "content": "To effectively target customers for the follow-up campaign, we leveraged these uplift modeling techniques to identify those most likely to respond to specific actions. The modeling process is detailed as follows:\n\u2022 Data Source: The dataset for model training was derived from one historical Marketing campaign, which had an identical setup to the new campaign and its follow-up campaign.\n\u2022 Feature Selection and Model Training: Features such as customer demographics, past purchase behavior, and marketing communication history were selected for training the uplift models. These features were chosen based on their predictive relevance to customer responses."}, {"title": "4.3 Evaluation Metrics", "content": "To measure the performance of our uplift models and the campaign outcomes, we used several key metrics: Uplift at Different Quantiles, AUUC, and Accuracy.\n\u2022 Uplift at Different Quantiles: Measure the effectiveness of targeting different segments of the customer base.\n\u2022 Area Under the Uplift Curve (AUUC): Evaluate the overall performance of the uplift model.\n\u2022 Accuracy: Determine the correctness of the predictions."}, {"title": "4.4 Experimental Procedure", "content": "\u2022 Data Preprocessing: The historical campaign data were cleaned and preprocessed, including handling missing values, outliers, and encoding categorical variables. Additionally, select relevant features using statistical analysis and predictive relevance.\n\u2022 Model Training: Uplift models were trained using Meta-Learner frameworks (S-learner, T-learner, X-learner). Calibration techniques, isotonic regression was applied to refine the model outputs.\n\u2022 Score Ranking and Standardization: Uplift scores for each treatment were calculated, followed by directly ranking or standardization using Z-scores for each treatment.\n\u2022 Treatment Selection: Optimal treatments for each individual were selected based on either the direct ranking method or Z-score standardization. Cross-validation and out-of-sample testing were used to ensure robustness.\n\u2022 Performance Evaluation: The models' performances were evaluated using the specified metrics (AUUC, Uplift At Quantiles), comparing our approach against baseline models in sample."}, {"title": "5 RESULTS", "content": "The results of our experimental setup demonstrate the effectiveness of the proposed uplift modeling approach, particularly in the context of multi-treatment marketing campaigns. Our methodology, which integrates score ranking and calibration techniques, showed significant improvements in prediction accuracy and overall campaign performance."}, {"title": "5.1 Calibration Effectiveness", "content": "Calibration techniques, particularly isotonic regression, significantly enhanced the reliability of the predicted probabilities. Figure shows the calibration tables for the Meta-Learner models before and after calibration. The calibrated model's probabilities align more closely with the true probabilities, demonstrating the effectiveness of the calibration process."}, {"title": "5.1.1 AUUC Score Comparison", "content": "The Area Under the Uplift Curve (AUUC) was utilized to evaluate the performance of the uplift models. We observed that our proposed approach, which included score ranking and calibration, achieved higher AUUC scores compared to the baseline models. Table 1 summarizes the AUUC scores for different models:"}, {"title": "5.1.2 Uplift at Different Quantiles", "content": "We also assessed the effectiveness of targeting different customer segments based on uplift scores. Table 2 illustrates the lift at different quantiles for both calibrated and uncalibrated models. The calibrated models consistently outperformed the uncalibrated models across all quantiles, with the most significant improvements observed in the top 10% and 20% segments. Also, note that X Learners underperformed aligning the performance on AUUC scores. The conversion rate of the random target group was used as the baseline for comparison."}, {"title": "5.2 Scoring Rank and Offer Selection Strategy", "content": "Our score ranking strategy, involving both direct ranking and Z-score standardization, was pivotal in selecting the optimal treatment for each individual. Tables 3 and 4 show the distribution of selected treatments for a subset of the population, demonstrating the diversity and precision of our approach."}, {"title": "5.2.1 Direct Ranking", "content": "Table 3 presents the baseline approach, where we rank customers from each treatment by it's uplift score and assign customers how has higher ranking between both treatments. This method shows a 7.5% lift for treatment A. However, for treatment B, there is a -0.8% lift, raising questions about the validity of comparing treatments directly by uplift score ranking. It is possible that the assignment strategy favored treatment A for customers who showed positive uplift scores for both treatments A and B. We used the conversion rate of random target group and received no treatment as baseline."}, {"title": "5.2.2 Z-Score normalization", "content": "Table 4 illustrates the results after applying the Z-score normalization. Here, both treatments show a positive lift, with treatment A achieving an 8.2% lift and treatment B achieving a 3.2% lift. This approach outperforms the baseline method, indicating that Z-score normalization allows for a more balanced and effective comparison between treatments."}, {"title": "6 CONCLUSION", "content": "In this paper, we have presented a novel approach to uplift modeling in multi-treatment marketing campaigns, discussed the integration of score ranking and calibration techniques to enhance prediction accuracy. By using Meta-Learner frameworks with calibration and implementing a scoring rank-based offer selection strategy, we aimed to address the complexities and improve the incremental effect and reliability of uplift predictions.\nOur extensive experiments with real-world datasets showed that the proposed methodology had a robust model performance. The findings underscore the effectiveness of score ranking and calibration in refining reliability of uplift predictions. This advancement provides more actionable insights for practitioners seeking to optimize their campaign strategies.\nThe key contributions and findings of our work include:\n\u2022 The implementation of multiple single-treatment models and the selection of the best treatment for each individual, enhancing the granularity and effectiveness of targeting."}]}