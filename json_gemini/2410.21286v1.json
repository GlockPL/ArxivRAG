{"title": "OPENCITY: A SCALABLE PLATFORM TO SIMULATE URBAN ACTIVITIES WITH MASSIVE LLM AGENTS", "authors": ["Yuwei Yan", "Qingbin Zeng", "Zhiheng Zheng", "Jingzhe Yuan", "Jie Feng", "Jun Zhang", "Fengli Xu", "Yong Li"], "abstract": "Agent-based models (ABMs) have long been employed to explore how individual behaviors aggregate into complex societal phenomena in urban space. Unlike black-box predictive models, ABMs excel at explaining the micro-macro linkages that drive such emergent behaviors. The recent rise of Large Language Models (LLMs) has led to the development of LLM agents capable of simulating urban activities with unprecedented realism. However, the extreme high computational cost of LLMs presents significant challenges for scaling up the simulations of LLM agents. To address this problem, we propose OpenCity, a scalable simulation platform optimized for both system and prompt efficiencies. Specifically, we propose a LLM request scheduler to reduce communication overhead by parallelizing requests through IO multiplexing. Besides, we deisgn a \u201cgroup-and-distill\" prompt optimization strategy minimizes redundancy by clustering agents with similar static attributes. Through experiments on six global cities, OpenCity achieves a 600-fold acceleration in simulation time per agent, a 70% reduction in LLM requests, and a 50% reduction in token usage. These improvements enable the simulation of 10,000 agents' daily activities in 1 hour on commodity hardware. Besides, the substantial speedup of OpenCity allows us to establish a urban simulation benchmark for LLM agents for the first time, comparing simulated urban activities with real-world data in 6 major cities around the globe. We believe our OpenCity platform provides a critical infrastructure to harness the power of LLMs for interdisciplinary studies in urban space, fostering the collective efforts of broader research communities. Code repo is available at https://anonymous.4open.science/r/Anonymous-OpenCity-42BD.", "sections": [{"title": "1 Introduction", "content": "Agent-based models (ABMs) were first introduced to urban studies in the seminal work of Thomas Schelling about 50 years ago [1], which ingeniously explained how segregation can emerge as the aggregation of individual choices. Compared to black-box predictive models, ABMs offer the unique advantage of explaining the underlying mechanisms behind aggregated phenomena [2], i.e., revealing the connections between \u201cmicro-motives\u201d and \u201cmacro-behaviours.\" As a result, ABMs play an important role in many research areas [3], including computational social sciences, urban planning and public health. The recent advance of Large Language Models (LLMs) have driven the rise of LLM agents [4, 5], which leverage LLM's remarkable capabilities of commonsense reasoning and role-playing to simulate human behaviours. Unlike previous rule-based agents, these emerging LLM agents generate far more realistic human behaviours [4, 6], and can also explain their inner motives via prompting techniques like chain-of-thoughts [7]. Therefore, LLM agents hold great potential to harness the power of language models in transforming urban studies."}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 LLM Agents", "content": "With the widespread use of large language models (LLMs) in various applications, the limitations of LLMs, e.g., unstable reasoning abilities, limited memory capacity, and lack of specialized expertise, have been exposed to the public. As one of the potential solution, LLM agents are proposed to overcome these limitations and promote the practical application of LLMs. AutoGPT [18] as one of the most popular LLM autonomous agent explore the potential of applying LLM to enable the autonomous planning and task-solving. After that, LLM agents [19, 20] have made significant progress in two directions: task-oriented agents and simulation agents. Following the first direction, researchers aim to improve LLM agent's ability to solve complex tasks. For example, lots of programming agents, such as ChatDev [21], SWEAgent [22], and MetaGPT [23], are designed to solve the complex programming tasks. As for the second direction, generative agents [4] have demonstrated the potential of large models in simulating human behavior, which has been further validated in subsequent research. S3 [24] explores the potential of using LLM agents to simulate the social network. CoPB [6] defines a agentic workflow to simulate the mobility behaviors. RecAgent [25] simulate the user behavior in the recommendation system. While these works demonstrate the potential of LLM agents, the large scale efficient simulation of generative agents becomes the critical bottleneck of further applications."}, {"title": "2.2 LLM Deployment Optimization", "content": "To support the efficient inference of LLMs and LLM agents, enormous works and systems [26] are designed to optimize the inference efficiency of LLMs and further accelerate their practical applications. For example, Flash-attention [27] is an IO-aware exact attention algorithm which uses tiling to reduce the number of memory reads/writes within GPU. AWQ [28] is an activation-aware weight quantization to compress and accelerate the LLM inference. vLLM [29] proposes pagedAttention mechanism to enable highly efficient KV cache scheduler during the inference and becomes the most population open source LLM inference engine. SGLang [30] provides a flexible frontend language to enable the efficient autonomous optimization of LLM inference. Synergy-of-thought [31] proposes to exploit the synergy between larger and smaller language models for efficient reasoning. While these systems are designed to process the general LLM inference, specific characteristics of generative agents especially urban generative agents are ignored which can be employed to further accelerate the inference and simulation. In this paper, we explore the potential of this direction and design the OpenCity platform."}, {"title": "3 Preliminaries", "content": ""}, {"title": "3.1 LLM Agents for Urban Activities", "content": "We focus on using LLM agents to reproduce urban dynamics characterized primarily by physical mobility. Consider an urban environment E containing N LLM agents. The state of agent i at simulation time t, denoted as $S_i(t) = {s_i, m_i(t)}$, consists of both static properties $s_i$ and dynamic properties $m_i(t)$. Static properties, like the agent's demographics, remain constant throughout the simulation, while dynamic properties, such as memory and perceived environment information, change frequently and are hard to predict. We can represent the state update of agent i using a function f:\n$m_i(t+1) = f(s_i, E, m_i(t); S_i(t + 1) = {s_i, m_i(t+1)}$\nHere, $m_i(t + 1)$ is the updated memory of agent i at time t + 1, and the function f models how the agent updates its state by perceiving the urban environment E, reflecting on its memory $m_i(t)$, and interacting with the LLM. The individual trajectory of agent i, denoted as $T_i$, describes the trajectory of the agent over time in the urban environment E. If the location of agent i at time t is represented by $L_i(t)$, which depends on state $S_i(t)$, then the individual trace can be expressed as $T_i = {L_i(0), L_i(1), L_i(2), ..., L_i(t_s)}$, where $t_s$ is the the total simulation time. Along with individual mobility, we also examine the aggregated mobility features $A = \\Phi(\\Sigma_i \\Phi(\\Sigma_t S_i(t)))$, such as Original-Destination (OD) matrix and income segregation index, which reflects the urban dynamics involving states of all agents.\nTo simulate LLM agents in the urban space, we set the initial state for the agents and environment ${S_i(0)|i \\in N}$ and then apply the Equation 1 for each agent at every simulation step. When the number of agents increases, challenges arise mainly because of the LLM request process. LLMs are inherently slow due to their parameter size, and when using commercial LLMs accessed via APIs, response times can be further delayed, especially with poor network conditions. Some have proposed reusing the LLM response for agents can improve the efficiency [9], but it requires that the agents have the completely same state or have limit kinds of state that can be easily predicted. What's more, simply reusing the response would eliminate the independence of agents and reduce the faithfulness of the simulation results. Urban"}, {"title": "3.2 Time Cost Analysis", "content": "In light of the prevailing dominance of remote LLM service invocations in the current operational landscape of LLM agents simulation, a decomposition of the time required for a single LLM request can be undertaken, as illustrated in Fig.1(b). The first phase is the initialization and reception time for the LLM request, the second is the TCP/IP connection and destruction time between the simulation system and the LLM service provider, and the third is the data transmission and waiting time. For a single LLM request, the overhead of the first and second phases is relatively low in comparison to the third, and the core time consumption is derived from the data transmission and waiting.\nThe simulation of large-scale agents necessitates the issuance of a considerable number of LLM requests, which, given the presence of waiting periods, impairs the overall efficiency of the simulator. Furthermore, the system resources are not fully utilized. Consequently, the effective scheduling of LLM requests is essential for enhancing the overall utilization of system resources, which in turn improves the overall efficiency of the simulation. Furthermore, as the time required for LLM inference is directly proportional to the number of tokens contained in an LLM request, it is also important to reduce the number of tokens consumed per agent while compressing the number of requests.\nFrom this vantage point, the present work puts forth an efficacious LLM request scheduler and a prompt distillation method, which can markedly enhance the efficiency of large-scale LLM agents simulation."}, {"title": "4 OpenCity Platform", "content": "We devise a scalable platform OpenCity to accelerate the simulation of urban LLM agents from both system- and prompt-level. The OpenCity platform aims to substantially reduce the simulation time per LLM agent while maintaining high simulation fidelity. Besides, OpenCity also provides a user-friendly web interface to facilitate the easy access of researchers from diverse background. The key designs are introduced as follows."}, {"title": "4.1 LLM Request Scheduler", "content": "As shown in Fig.1(a), for a LLM agent, the dependency between its LLM requests that is, the necessity for the next LLM request to be initiated after the previous one is completed results in a constant waiting time under the condition of a fixed network environment and request content. In contrast, for a system comprising multiple agents, there is no dependency between their LLM requests. In order to achieve asynchronous processing of multiple LLM requests, we have implemented an IO multiplexing scheme (based on epoll in Linux) which eliminates waiting time in the simulation system. This allows the operating system to manage IO waiting, thereby achieving the desired \"zero-awareness\" of data transmission in the simulation system. Consequently, the average time for a LLM request is reduced to the time required for the first and second phases (Time saving#1 in Fig.1(c)).\nFurthermore, the considerable number of LLM calls necessitates the frequent establishment of connections with the service provider, resulting in a considerable overhead in the establishment and destruction of each connection. However, given that the content of LLM requests is inherently linked to the corresponding agent, it is possible to leverage the same connection for multiple agents, thereby reducing the overall performance overhead. To address this issue, a pool of reusable connections is maintained within the system. Upon initiation of an LLM request by an agent, the request content is populated into an available connection, thus avoiding the establishment of a new connection. This approach additionally reduces the mean time consumption of LLM requests (Time saving#2 in Fig.1(c)).\nFor those agents with CPU tasks during the computation process, it is important to note that the continued occupation of CPU resources by the computation load will inevitably result in a delay in the sending of LLM requests from subsequent agents. To mitigate the adverse effects of this issue on the system's overall performance, we categorize the CPU task as \"local IO\", offload it to available cores for computation through a multi-core parallel scheme, and then return the result to the designated agent upon completion of the computation. This approach further ensures the stable operation of asynchronous LLM requests (Time saving#3 in Fig.1(c)).\nThe proposed LLM request scheduler is designed to reduce the waiting time for a significant number of LLM requests during the simulation runtime. Based on the supporting auxiliary scheme, it has the potential to significantly enhance the efficiency of large-scale LLM agents."}, {"title": "4.2 Group-and-Distill Meta-Prompt Optimizer", "content": "A further crucial method for enhancing the efficiency of the simulation is to reduce the number of LLM requests issued by agents and the quantity of tokens consumed by said agents. A conventional approach is to reuse the generated result of a single LLM request across multiple agents. However, this approach presents two significant drawbacks: 1. In fine-grained urban LLM agent simulations, each agent possesses its own dynamic properties. Consequently, the reuse scheme compromises the independence of agents, which is antithetical to the objective of conducting urban simulations through large-scale LLM agents. Furthermore, for agents with dynamic properties, it is inherently impossible to share the result of a single LLM request, as shown in Fig.2(a).\nTo address this issue, we propose the Group-and-Distill Meta-Prompt Optimizer (depicted in Fig.2), which employs group information in lieu of the static attributes of the agent. This approach aggregates requests from multiple agents at runtime and realizes prompt by sharing group information and context information while preserving the agent's dynamic properties. The optimizer is comprised of two distinct components. In-context prototype learning (IPL) and distill meta-prompt.\nThe inputs and outputs of IPL are defined as follow:\n$IPL({s_i}, M,T) \\rightarrow G, D$\nin which, ${s_i}$ is the collection of agent's static properties; M controls the number of agents in initial prototype learning; T is the threshold for decision making; G is the collection of agent groups; D is the descriptions for each group of agents.\nInput the static properties of a set of agents, IPL first groups the first M agents, providing both group results and the corresponding description information. Subsequently, IPL classifies the remaining agents by transmitting the static properties of the agent to LLM, which analyzes the likelihood of the agent belonging to each group based on the group description and provides the quantization result. By comparing the quantization result with T, when the result is greater than T, IPL assigns the agent to the specified group. Otherwise, it constructs a new group and describes the characteristics of the group. In comparison to conventional prototype learning methods that operate within a fixed parameter space, IPL exhibits enhanced generalization capabilities and a particular aptitude for leveraging semantic-level knowledge in the prototyping process. The prototype information obtained by IPL is employed to efficiently summarize the static attribute characteristics of the set of agents within the specified group.\nThe distill meta-prompts obtained through a systematic examination of the original prompts and the CoT approach is employed to generate the prompts (details can be found in Fig.A1). To facilitate the generation procedure, we have proposed a raw prompt design diagram, which divides the prompt into three sections: the function section, the variable section, and the input section. The generation process, which is initiated with a given raw prompt, comprises four steps: summarization, context extraction, information sharing, and rewriting of the raw prompt into the distill meta-prompt. In"}, {"title": "4.3 Web Portal", "content": "A web portal has been designed for the utilisation of OpenCity, encompassing the frontend, backend, and simulation system. This enables users to rapidly configure simulation conditions and visualise simulation results, as well as facilitating the storage of simulation data and urban infrastructure information within a database. The fundamental concept underlying the design of this portal is user-friendliness, particularly given the inherently interdisciplinary nature of urban research. We have developed a rapid, code-free configuration approach tailored to the needs of researchers, thereby facilitating the seamless engagement of experts from diverse fields with our simulation platform.\nUser-friendliness: In order to enhance the usability of the OpenCity platform, the Web Portal has been augmented with the incorporation of the LLM agent blueprint construction function. Users are able to drag and drop each basic function module in order to construct complex logic for LLM agents. In order to meet a variety of needs, the blueprint function is based on the established LLM agent development frameworks, such as Langchain [32] and AutoGPT [33], and incorporates several fundamental modules oriented towards urban simulation, including environmental and traffic sensing. The blueprint offers an efficient and agile development solution for interdisciplinary researchers, facilitating the rapid iteration of simulation methods and theories.\nBasic workflow: The primary process of urban LLM agent simulation on this web portal is comprised of three distinct phases: citizen profile configuration, deployment and simulation, and results presentation. The configuration of the citizen profile is facilitated by the provision of a console hub, which enables users to efficiently and transparently administer the simulation tasks they have created on the platform, along with the agents within those simulations. The user is able to bind the execution logic designed in the blueprint to different agents and to configure their profiles with"}, {"title": "5 Benchmark", "content": ""}, {"title": "5.1 Dataset and Setup", "content": "Dataset We collect urban mobility data in 6 major cities around world: Beijing, New York, San Francisco, London, Paris, and Sydney. The data sources vary. Beijing's data comes from a related work [6], which collected from social network platform. New York and San Francisco source from Safegraph for aggregated population flow data. And the other three cities are from Foursquare which consist of thousands of check-ins data. To make better use of these data, we have done some preprocess method, such as trajectory filter, home extraction and profile sampling. More details can be seen in Appendix A.\nArchitecture of LLM Agent The main agent used in OpenCity platform to simulate the urban dynamic is the generative agent [4]. Generative agents use a framework that involves perception, planning, and reflection. A generative agent first creates a daily plan to ensure the trajectory is reasonable. When the agent arrives at a POI, it makes decisions based on current perceptions and memory. After taking action, the agent records the action and the POI into its memory stream. Once the memory stream reaches a threshold, the agent reflects. The results show that the generative agent to function well in the OpenCity platform.\nWe also have rule-based agent for comparison, such as the famous Explore and Preferential-Return (EPR) model [16]. This work make agent choose to explore a new location or return to the visited location. Decisions are related to some parameters to compute the probability. In this paper, we set the parameters as follows: exploration rate $p = 0.6$, exploration-return trade-off parameter $y = 0.21$, waiting time distribution parameters $7 = 17, \\beta = 0.8$."}, {"title": "5.2 Acceleration Performance", "content": "This section presents an evaluation of the performance of the OpenCity platform in conjunction with the Generative Agent (Tested on Huawei ECS Cloud Server - Intel(R) Xeon(R) Platinum 8378C CPU @ 2.80GHz with 64 cores and 256 GB RAM). The performance of the platform was evaluated in six major cities with 10,000 agents. The results are presented in Table.1, where the following variables are defined: Speedup denotes the improvements in simulation time, Rr denotes the LLM request number reduction rate, and Tr denotes the token number reduction rate.\nThe results demonstrate that OpenCity exhibits substantial acceleration in all test cities, with an average runtime of 0.058s per LLM agent and an average speedup of 635.3x in simulation time. Furthermore, the proposed acceleration scheme is capable of markedly reducing the number of LLM requests and token consumption, with an average reduction of 73.7% and 45.5%, respectively.\nTo assess the scalability of OpenCity, we conducted a series of simulations to evaluate its acceleration performance under varying orders of magnitude of agents. The results of this analysis are presented in Fig.3, in which the baseline represents the simulation time without optimization. The results demonstrate that OpenCity's acceleration capability is scalable, with a notable enhancement in acceleration effect when the number of agents is increased from 10 to 10,000. This is due to the fact that as the number of agents increases, the number of groups obtained based on IPL also gradually increases. This, in turn, allows the advantages of the LLM request scheduler to be fully realised, thereby ensuring a better utilisation of system resources.\nFurthermore, faithfulness experiments are conducted to demonstrate that the Group-and-Distill optimizer can effectively preserve the distinctive personality traits of the agents. The testbed for this evaluation is location choice generation, which requires the combination of agent properties to select the next location to visit. A comparison was conducted between the performance of four distinct methods, including raw prompting (without any modification), batch prompting [12], archetype prompting [9], and the proposed method. One hundred agents were randomly selected and location selection was performed 100 times for each agent with the same context. The effectiveness of the method was evaluated by counting the distribution of selections (JSD) as well as the top-1 hit rate (T1). The results are shown in Table.2, where Inherent denotes the bias present in LLM itself (raw prompt method)."}, {"title": "5.3 Reproducing Urban Dynamics", "content": "The significant increase in simulation efficiency enables us to benchmark LLM agent's ability to reproduce large-scale urban dynamics for the first time. We use comprehensive metrics in three-levels to evaluate the simulation performance, from individual- to group level, and also from physical domain to social domain. At the individual level, we calculate the radius of gyration [13] for each user. At the group level, we use the original-destination matrix [14]. As for the social domain, we focus on the income segregation index [15]. To evaluation the simulation performance, we compute the MSE for these three metrics, which are denoted as $RMSE_r, ODMSE$ and $SMSE$. More details can be referred to Appendix B.\nIn this section, we analyze the performance of the Generative Agent and EPR Agent in reproducing urban dynamics. We test both agents in 6 major cities using 1,000 agents. The results are shown in Table 3. The results indicate that both the Generative Agent and EPR Agent successfully reproduce urban dynamics with low MSE values. Additionally, the LLM Agent performs as well as or better than the classical rule-based EPR Agent, highlighting the advantage of LLM's semantic understanding ability in urban simulations."}, {"title": "6 Case Study: Experienced Urban Segregation", "content": "With the ability to simulate large-scale urban LLM agents, we can conduct counterfactual experiments to explore outcomes under different policies and design optimal strategies for the future. Conventional rule-based models do not support this capability, as they are designed to simulate real-world scenarios. Experienced urban segregation is a widely discussed issue with significant impacts on social dynamics and the economy. It arises from both demographic differences in residential neighborhoods and the mobility patterns of urban residents [15].\nThis section provides a case study: a counterfactual simulation is conducted in New York and San Francisco, to observe how the simulation results change in different configurations, and try to summarize the results with the LLM agents themselves.\nSpecifically, we construct the counterfactual scenario by evenly distributing LLM agents with different income levels across the city, that means we almost eliminate the residential segregation. The results of the income segregation statistics with CBGs as the statistical granularity are shown in Fig.4, where 'Original' samples the segregation results from the real census data, and 'Even' is the result after uniform distribution of agents with different incomes."}, {"title": "7 Conclusion", "content": "In this work, we introduced OpenCity, a scalable platform designed to address the computational and communication challenges inherent to the deployment of large-scale LLM-based urban agents in city simulations. By incorporating an LLM request scheduler and a novel \"group-and-distill\" prompt optimization strategy, we achieved a notable 600-fold increase in the efficiency of agent simulations, with a substantial reduction in both LLM requests and token usage. The OpenCity platform was evaluated through experiments conducted on six global cities. The results demonstrated the platform's capability to simulate the daily activities of 10,000 agents at an hourly level, while also establishing a benchmark for generative agent performance in urban contexts. The platform's ability to compare simulated behaviors with real-world data highlights its potential for real-world urban-scale applications, offering a robust tool for urban planners and researchers to explore and understand complex societal phenomena."}, {"title": "A Urban Mobility Dataset", "content": "As shown in Table A1, we collect urban mobility data of 6 major cities around the world. The data sources vary. In Beijing, the data is from a related work [6], which gathered through a social network platform and tracking users' mobility trajectories. Additionally, users' profiles, such as income level, gender, occupation, education level and age, are collected through digital surveys. In New York and San Francisco, the data comes from Safegraph, which provides aggregated population flow among Points of Interest(POIs) and Census Block Groups(CBGs). The other three cities-London, Paris and Sydney-use data are from Foursquare. Foursquare data consist of thousands of check-ins data of users and the corresponding venue position.\nTo make better use of the datasets, we apply several preprocessing methods. We firstly arrange the trajectory points in time sequence, and divide the trajectory into units of one day. Then we filter out trajectories with fewer than 4 points in a day, as they do not fully capture users' mobility patterns. For home extraction, we identify the most frequently visited location of the useres the home. Since only the Tencent dataset includes user profiles, we make profile sampling for users of each city based on local census data for the other two datasets. In the end, our dataset is optimized for easy use in urban mobility simulations."}, {"title": "B Urban dynamic metrics", "content": "We use comprehensive metrics in three-levels to evaluate the simulation performance, from individual-level to group level, and also from physical domain to social domain. These metrics allows us to gain a full understanding of mobility patterns and their implications, and can also help us evaluate the performance of the simulation by analysing the generated trajectory.\nAt the individual level, we calculate radius of gyration $r_g$ [13] for each user, which is a measure of the spatial extent of their movements. The radius of gyration is defined as follows:\n$r_g = \\sqrt{\\dfrac{1}{N^a} \\sum_{i=1}^{N}(r_i^a - r_m^a)^2 }$\nwhere $r_i^a$ represents the i = 1, 2, ..., N positions recorded by user a, and $r_m^a = 1/N^a \\sum_{i=1}(r_i^a)$ is the center of mass of the trajectory. The radius of gyration provides an indication of the size of a user's activity range. To assess the accuracy of our simulation data against real-world data for a specific user, we calculate $RMSE_r$, the Mean Squared Error(MSE) of the radius of gyration.\nTo analyze movement patterns and other aggregated features, we define block areas as spatial units within the city. For cities with Safegraph data, we use existing Census Block Group (CBG) areas. For other cities, we divide the map area into evenly spaced grids, with each grid cell representing a block area.\nAt the group level, we count the inflow and outflow of agents between block areas, calculate the Origin-Destination (OD) matrix [14], and normalize it. To compare real data with simulation data, we calculate the MSE of the normalized OD matrix, denoted as $ODMSE$. A smaller $ODMSE$ value indicates greater similarity between the OD matrices, meaning the movement characteristics of the simulated data closely match the real data.\nAt the social domain, we calculate the income segregation index [15] for each block area. The income segregation of a place a is defined as $S_a = \\sum_q |q_a - \\tau|$, where $q_a$ is is the proportion of visitors in each income quintile for place a. The $S_a$ ranges from 0 to 1. A high $S_a$ indicates that the place a is predominantly visited by a single income group, suggesting a high level of income segregation. We denote $SMSE$ as the MSE between the real data and simulation data."}, {"title": "C Image supplements", "content": ""}]}