{"title": "TableTime: Reformulating Time Series Classification as Zero-Shot Table Understanding via Large Language Models", "authors": ["Jiahao Wang", "Mingyue Cheng", "Qingyang Mao", "Qi Liu", "Feiyang Xu", "Xin Li", "Enhong Chen"], "abstract": "Large language models (LLMs) have demonstrated their effectiveness in multivariate time series classification (MTSC). Effective adaptation of LLMs for MTSC necessitates informative data representations. Existing LLM-based methods directly encode embeddings for time series within the latent space of LLMs from scratch to align with semantic space of LLMs. Despite their effectiveness, we reveal that these methods conceal three inherent bottlenecks: (1) they struggle to encode temporal and channel-specific information in a lossless manner, both of which are critical components of multivariate time series; (2) it is much difficult to align the learned representation space with the semantic space of the LLMs; (3) they require task-specific retraining, which is both computationally expensive and labor-intensive. To bridge these gaps, we propose TableTime, which reformulates MTSC as a table understanding task. Specifically, TableTime introduces the following strategies: (1) convert multivariate time series into a tabular form, thus minimizing information loss to the greatest extent; (2) represent tabular time series in text format to achieve natural alignment with the semantic space of LLMs; (3) design a reasoning framework that integrates contextual text information, neighborhood assistance, multi-path inference and problem decomposition to enhance the reasoning ability of LLMs and realize zero-shot classification. Extensive experiments performed on 10 publicly representative datasets from UEA archive verify the superiorities of the TableTime. The code is publicly available\u00b9.", "sections": [{"title": "1 Introduction", "content": "Multivariate time series [14, 17, 45] are ubiquitous for many web applications [33, 43], which are sequences of events collected over time, with each event consisting of observations recorded across multiple attributes. For example, the electrocardiogram (ECG) [32] signals in electronic health records (EHRs) capture various aspects of heart function through multiple sensors. Comprehensive analysis of such data can facilitate decision-making in real applications [13, 30], such as human activity recognition, healthcare monitoring, and industry detection. Particularly, as a fundamental problem in time series analysis, multivariate time series classification (MTSC) tasks, have attracted significant attention in academia and industry.\nOver the years, various approaches have been developed to address the MTSC problem [1, 18, 34]. Traditional methods like Dynamic Time Warping (DTW) [23] with nearest neighbor classifiers [27] have been popular for aligning time series of varying lengths. But they struggle to capture the hidden features of the time series data, leading to inaccurate modeling. Deep learning [19] has since revolutionized MTSC by reducing the need for feature engineering. Among them, convolutional neural network (CNN)-based [6, 31] and transformer-based [40, 47] approaches have garnered considerable attention. Despite their success, deep learning models are often criticized for their \"black box\" problem [29], limiting their interpretability. The aforementioned methods can be classified as numerical paradigms, as they primarily focus on modeling numerical time series data.\nPre-trained large language models (LLMs), have driven rapid progress in natural language processing (NLP) [28]. In the meanwhile, LLMs' impressive capabilities have inspired their application for time series analysis [4, 15, 22, 36]. For example, Time-LLM reprograms LLMs for time series tasks by using a process called reprogramming, which transforms time series data into formats that LLMs can understand. InstructTime transforms time series classification using LLMs for direct label generation, improving performance and cross-domain adaptability. These methods effectively align time series with the outputs of LLMs, yielding strong results.\nLLM-based methods have demonstrated effectiveness, there exits several bottlenecks when applying LLMs to time series analysis [21].\nFirst, they struggle to capture temporal dependencies and channel-specific features, which are crucial for accurate modeling. Second, a mismatch exists between the numerical time series and the the semantic space of LLMs, which impedes their ability to process such data effectively. Third, extensive fine-tuning incurs high computational, particularly in large-scale applications. LLM-based model requires a large volume of data for training, posing challenges for small datasets. Lastly, they are unable to utilize the reasoning capabilities of LLMs fully. These challenges highlight the need for more efficient, domain-adaptive approaches for MTSC.\nAn effective LLM-based method, in our view, should possess several key attributes. First, it should be able to capture significant information in time series, which helps in accurate modeling. Second, it must align the numerical time series with the semantic space of LLMs, because text is the natural input of LLMs. Third, it should be possible to achieve zero-shot training when applying LLMs to MTSC. Finally, it is imperative for LLM-based models to exhibit exceptional capability in reasoning over complex and multifaceted information, allowing it to effectively handle tasks that require not only deep logical connections but also a nuanced understanding of intricate relationships and dependencies within the data.\nTo this end, we propose TableTime, a framework based on table understanding for multivariate time series classification. To effectively capture both temporal and channel-specific information in multivariate time series, we convert the raw time series into a tabular format, preserving both temporal and channel-specific information. To align the tabular time series with the semantic space of LLMs, we introduce the Table Encoding, which converts the tabular time series into a textual representation. For zero-shot classification, we adopt a table understanding approach that reformulates the MTSC task into a table understanding problem. To maximize the reasoning potential of the LLMs, we developed a prompt incorporating neighbor enhancement and multi-path reasoning, aiming to fully leverage the LLMs' reasoning capabilities.As shown in Figure 1, TableTime provides a new solution paradigm for MTSC. To summarize, our contributions include:\n\u2022 We propose a new paradigm for MTSC based on table understanding and give detail explanations on how it overcomes the bottlenecks of existing LLM-based methods.\n\u2022 We introduce table encoding for time series, and design a zero-shot classification framework called TableTime to fully stimulate the reasoning capability of LLMs to achieve zero-shot classification.\n\u2022 We conduct comprehensive experiments on ten benchmark multivariate time series datasets, validating the effectiveness of our proposed TableTime."}, {"title": "2 Related Work", "content": "Time series classification has received significant attention both in academia and industry [18, 26]. Traditional methods initially centered around distance-based methods, such as Dynamic Time Warping (DTW) [23] combined with K-Nearest Neighbors (K-NN), are effective in handling the temporal distortion present in time series data. In response to the limitations of distance-based methods, ensemble approaches were introduced to enhance classification accuracy. For example, Hive-Cote [24] is an ensemble learning algorithm that improves accuracy by combining multiple feature transformations and classifiers through hierarchical voting. These ensemble techniques offer more robust performance by capturing diverse aspects of the data. With the advent of deep learning, more sophisticated models began to outperform traditional methods. Early architectures like Fully Convolutional Networks (FCN) [20, 38] and Recurrent Neural Networks (RNN) [16] directly learned hierarchical representations from raw data. More recently, models like InceptionTime [20] have leveraged deeper networks with multi-scale convolutions, significantly improving the ability to capture complex patterns across different time scales. Additionally, Transformer-based models [5, 47] have emerged as powerful alternatives by capturing long-range dependencies and global context more effectively, further advancing the performance."}, {"title": "2.1 Time Series Classification", "content": "Time series classification has received significant attention both in academia and industry [18, 26]. Traditional methods initially centered around distance-based methods, such as Dynamic Time Warping (DTW) [23] combined with K-Nearest Neighbors (K-NN), are effective in handling the temporal distortion present in time series data. In response to the limitations of distance-based methods, ensemble approaches were introduced to enhance classification accuracy."}, {"title": "2.2 LLMs in Time Series", "content": "Given the impressive capabilities of LLMs, researchers in the time series classification community are increasingly exploring their applications in time series analysis[4, 48]. LLM-based approaches can be divided into two categories: fine-tuning and generative modeling. Fine-tuning methods, such as Linear Fine-Tuning, combine pretrained LLMs with time series-specific encoders, leveraging their linguistic capabilities to identify patterns. Generative models, like GPT-based forecasting, predict future time series sequences, while models like TEMPO integrate domain knowledge (e.g., seasonal-trend decomposition) to enhance performance. Despite these advances, challenges remain, including the modality gap between textual and numerical data, which hinders tokenization and semantic understanding [4, 48]. Quantization techniques address this but may fail to capture temporal dependencies. Fine-tuning for multivariate or long-horizon time series also incurs high computational costs, and many approaches overlook domain-specific knowledge.\nAlthough its effectiveness, LLMs face several significant challenges [35, 41, 42]. They struggle to capture temporal dependencies and channel-specific features, which are essential for accurate modeling. There is also a misalignment between numerical data and LLMs' semantic space, complicating processing. Fine-tuning is computationally expensive, particularly for large-scale applications. Moreover, they fail to fully leverage LLMs' reasoning capabilities. To solve these problems, we proposed TableTime, a paradigm for time series analysis from the perspective of table understanding."}, {"title": "3 Preliminaries", "content": null}, {"title": "3.1 Problem Definitions", "content": "$\\mathcal{D} = \\{(X^1, y^1), (X^2, y^2), ..., (X^n, y^n)\\}$ is a dataset containing a collection of pairs $(X^i, y^i)$, where $n$ denotes the number of examples. $X^i \\in \\mathbb{R}^{t\\times m}$ denote one multivariate time series, with its corresponding label denoted by $y \\in \\{C_1, C_2, ..., C_k\\}$. In the above denotations, $t$ denotes the time steps and $m$ denotes the dimension of $X^i$. For classification task, the goal is to learn a classifier on $\\mathcal{D}$ that maps the input space $\\mathcal{X}$ to a probability distribution over the class $y$. In TableTime model, our task is to take a prompt engineering based on the characteristic of the dataset and task definitions. Let $P$ denote the prompt. It can be summarized by the following formula: $T^i = LLM(P, X^i)$. Here $T^i$ denotes the text generated by the LLM"}, {"title": "3.2 Large Language Models", "content": "Recent advancements in large language models (LLMs) have revealed a range of powerful capabilities, enabling them to tackle a variety of complex tasks. In this context, we propose to use LLMs to enhance multivariate time series classification tasks. There are several key advantages to leveraging LLMs for advancing classification techniques: Reasoning: LLMs possess advanced reasoning and pattern recognition capabilities, which could enhance classification accuracy by leveraging higher-level concepts. Existing non-LLM methods, on the other hand, are largely statistical and lack intrinsic reasoning abilities. World Knowledge: LLMs are pre-trained on vast amounts of textual data, which enables them to incorporate general world knowledge into their predictions. This broad knowledge base can enhance classification by providing contextual understanding that is often missing in previous methods, which are limited to domain-specific information. Generalizability: LLMs have demonstrated remarkable zero-shot transfer learning capabilities, suggesting their potential for generalizable classification across domains without task-specific retraining. In contrast, current classification methods are often rigidly specialized by domain."}, {"title": "4 The Proposed TableTime", "content": "In this section, we will introduction the TableTime in detail. We first introduce the overall architecture of our designed TableTime. After that, we elaborate the TableTime via respectively introducing four aspects of key designs. Finally, we demonstrate the difference between the TableTime and relative methods."}, {"title": "4.1 Framework Overview", "content": "An overview of the TableTime model is shown in Figure 2. The model takes a single multivariate time series as input. To enhance reasoning capabilities, we first employ neighbor retrieval to identify relevant neighbors, improving the understanding of LLMs. These raw numerical time series data are then converted into tabular format, preserving both temporal and channel information. Next, we design one prompt, consisting of three components: contextual text information, neighbor knowledge and task decomposition. In the final stage, the comprehensive prompt is fed into the LLMs for classification, where the model leverages its zero-shot reasoning abilities to classify the test sample based on the provided information. Compared to other LLM-based models, our approach preserves both temporal and channel information, retaining more of the original data. Additionally, by reformulating the time series as text format, our method aligns with the LLMs' semantic space, facilitating better integration. Furthermore, TableTime does not require any training, enabling stronger generalization capabilities. These features demonstrate the powerful capabilities of TableTime."}, {"title": "4.2 Context Information Modeling", "content": null}, {"title": "4.2.1 Reformulating Time Series as Tabular Data", "content": "LLM-based models either learn time series embeddings directly in their latent space or align outputs from external models, often resulting in significant information loss, including temporal dependencies and channel relationships. The inherent mismatch between numerical time series and text-based semantic spaces introduces inefficiencies and limits the LLMs' ability to capture complex patterns in time series data. To solve these difficulties, we introduced Table Encoding, which reformulating time series as tabular data. Tables are a natural representation of time series data. Table Encoding converts the original multivariate time series into tabular format while retaining the temporal and channel information. The tabular time series are then serialized into text through serialization. This process can be formalized as follows:\n$\\begin{array}{c:ccc} & C_1 & C_2 & \\dots C_m\\\\\n\\hline\n t_1 & X_{11} & X_{12} & \\dots X_{1m}\\\\\n t_2 & X_{21} & X_{22} & \\dots X_{2m}\\\\\n  & \\vdots & \\vdots & \\vdots \\\\\n t_t & X_{t1} & X_{t2} & \\dots X_{tm}\\\\\n\\end{array}$\nwhere $C_T = (C_1 \\quad C_2 \\quad \\dots C_m)^\\intercal$ denotes the channel information, $T = (t_1 \\quad t_2 \\quad \\dots t_t)^\\intercal$ denotes the temporal information."}, {"title": "4.2.2 Contextual Text Information", "content": "LLMs lack intrinsic task-specific knowledge and rely heavily on explicit prompts to guide their reasoning process. Without clear and comprehensive instructions, ambiguous or incomplete prompts can lead to misinterpretations, irrelevant outputs, or deviations from task requirements. To address this, we introduced the domain context as a foundational part of the prompt, explicitly providing task-specific knowledge and essential context for accurate reasoning.\nThe generation of domain context follows a structured template approach, ensuring consistency and semantic richness. Key elements include: (1) Task Definition: accurately describe tasks in a certain field; (2) Dataset Description: explain the characteristics of the data set, including the length of the data, the meaning of the channel, etc; (3) Class Definition: detailed description of the meaning of each label; (4) Channel Information: detailed explanation of the meaning of each channel of the dataset. For time-series tasks, temporal dependencies and channel-specific features are highlighted to emphasize data structure. This systematic design mitigates ambiguity, aligns the model's reasoning with task requirements, and enhances accuracy and consistency."}, {"title": "4.3 Neighborhood-Assisted In-context Reasoner", "content": "The primary challenge lies in LLMs' inability to effectively classify unseen samples due to a lack of task-specific examples, resulting in uncertainty, difficulty capturing complex data characteristics. To bridge these gaps, we introduce neighborhood-assisted in-context reasoner mechanism. By retrieving the neighbors from the training data, we provide LLMs with essential contextual guidance. These neighbors may share critical features and patterns with the test sample, acting as reliable references for generation.\nSpecifically, we employ two neighbor retrieval strategies: (1) positive samples only; (2) contrast enhancement. For first, we apply similarity measurement algorithms to identify the k-nearest neighbors from the training dataset for each test sample. The retrieval process can be formalized as follows:\n$\\text{Retrieval}(X_{\\text{test}}, \\mathcal{D}, f, k) = \\arg \\min_{i=1}^k [f(X_{\\text{test}}, X^i)]_{\\mathcal{D}}$,\nwhere $X_{\\text{test}}$ denotes one test sample; $\\mathcal{D}$ denotes the training dataset; $f$ denotes the similarity measuring algorithm, e.g., euclidean distance and $k$ denotes the number of the neighbors.\nTo further assist LLMs for classification, we introduce contrast enhancement mechanism that incorporates negative samples into the model's reasoning process. We first cluster the training dataset using algorithms such as K-means. After that, we select negative samples from clusters that test sample doesn't belong to, ensuring these samples are sufficiently dissimilar. The process of K-means clustering can be described by the following formula:\n$\\begin{aligned}\\{C_k\\}_{k=1}^K = \\arg \\min \\sum_{k=1}^K \\sum_{x_i \\in C_k} \\|x_i - \\mu_k\\|^2, \n\\end{aligned}$\nwhere $C_k$ denotes the $k$th cluster of training dataset $\\mathcal{D}$, $\\mu_k$ denotes the centroid of the $k$th cluster, $K$ denotes the numbers the clusters. By introducing these negative examples, TableTime leverages contrastive learning to help the LLMs better differentiate between classes and refine its decision boundaries.\nContextual text information and neighborhood serve complementary roles in enhancing LLM reasoning. Contextual neighbors provides task-specific, data-driven context by identifying samples from the training data, directly guiding classification decisions through pattern and feature alignment. In contrast, contextual text description leverages the broad, pre-trained semantic understanding of LLMs to establish task rules and logical frameworks, offering a warm up for LLMs. By combining the precision of neighbor-based contextual information with the generalization capabilities of domain context, TableTime achieves robust and accurate classification."}, {"title": "4.4 Multi-Path Ensemble Enhancement", "content": "Ensemble methods have demonstrated their effectiveness in time series classification. Similarly, self consistency [37] leverages multiple outputs from one LLM, selecting the most consistent response to ensure coherence and accuracy. In the meanwhile, responses generated by LLMs are random, making it challenging to transfer them to classification tasks.\nInspired by the above, we introduce multi-path ensemble enhancement. Multi-path inference leverages multiple distinct inference paths to generate a diverse set of results, capturing a broader range of feature expressions. By aggregating these outputs, this approach reduces the potential biases of any single inference path, enhancing both the robustness and accuracy. This makes multi-path inference suitable for our task, especially our task involves understanding multivariate time series data. The multi-path ensemble enhancement can be formalized as follows:\n$Y_{final} = \\arg \\max_y (\\sum_{i=1}^M f_i(x) = y)$,\nwhere $M$ denotes the number of models, $f_i$ denotes the $i$th classifier, $Y_{final}$ denotes the final classification result. Each classifier is an LLM. We can use different parameters to integrate, or integrate results from different LLMs. By generating multiple results using varied models and aggregating them through voting mechanism, we ensure that the final classification reflects the model's most confident and consistent reasoning."}, {"title": "4.5 Prompt of Zero-shot LLM Reasoning", "content": null}, {"title": "4.5.1 Task Decomposition", "content": "Traditional prompts often lack the structured guidance needed for LLMs to handle complex tasks effectively. This absence of clear instructions forces LLMs to interpret the task independently, which can result in errors, inconsistencies, or irrelevant reasoning. Without a step-by-step framework, the model risks overlooking critical aspects of the problem or focusing on less relevant details. To address these challenges, we introduce task decomposition, which breaks the complex time series classification task into a series of smaller, manageable steps, allowing the model to reason more effectively. This step-by-step process ensures that the LLMs gradually converges to a more accurate classification, enhancing both decision quality and interpretability."}, {"title": "4.5.2 Prompt Design", "content": "The LLM-based approach involves fine-tuning specific components within the LLMs, such as the multi-head self-attention mechanism or the linear output mapping layer. Although easy to implement, the fine-tuning process is still time-consuming and labor-intensive. This is obviously not aligned with our expectations for LLMs. We argue that LLM-based methods should have the ability of zero-shot classification.\nIn TableTime, a structured prompt is crucial to achieve zero-shot reasoning. The contextual text information provide LLMs with professional knowledge to warm them up. Neighbor information provides crucial context by linking the test sample to similar labeled examples from the training set. Task decomposition guides LLMs to implement step-by-step reasoning. The template is shown in 3."}, {"title": "4.6 Remark and Discussion", "content": "In the following, we summarize the characteristics of TableTime and discuss its relations to LLM-based and Dist-based models.\nRelation to LLM-based Models. LLMs have shown great superiority in sequence modeling tasks. However, the huge number of parameters in LLMs makes training very difficult. Therefore, how to efficiently use LLMs has become an urgent problem. Existing methods learn embeddings for time series in LLMs' latent space from scratch or map from external models to align with LLMs. Although effective, they cannot represent the original time series in a lossless manner. In contrast, TableTime can encode the raw time series fully and achieve zero-shot classification.\nRelation to Traditional Models. Distance-based methods are traditional but effective and highly interpretable. However, distance-based methods are sensitive to noise and outliers and have difficulty identifying local patterns. They also lack the ability to effectively represent the features of the sequence and cannot fully explore the potential structural information in the sequence. In TableTime, we retain the advantages of distance-based methods and leverage LLMs to achieve understanding of raw time series. Compared with ensemble learning methods, TableTime obtains the final result by integrating the generated results of the same LLM under different parameter settings. Instead of using multiple models, we introduce multi-path ensemble strategy, which can enhance the robustness of the model and make the final result more accurate."}, {"title": "5 Experiments", "content": "In this section, we first evaluate TableTime on a variety of datasets, comparing its performance with several baseline methods. Next, we conduct further investigations to assess the effectiveness of each module, drawing insights from the experimental results."}, {"title": "5.1 Experimental Setup", "content": null}, {"title": "5.1.1 Datasets", "content": "We perform all experiments by conducting experiments on ten public datasets, which are selected from the well-known UEA multivariate time series classification (MTSC) archive. In reality, the UEA archive has become nearly the most widely used multivariate time series benchmarks. We select a set of 10 multivariate datasets from the UEA archive [2] with diverse characteristics in terms of the number, and the length of time series samples, as well as the number of classes. Specifically, we choose: ArticularyWordRecognition (AWR), AtrialFibrillation (AF), BLink (BL), Cricket (CR), Ering (ER), FingerMovements (FM), StandWalkJump (SWJ), SelfRegulationSCP2 (SRS2), RacketSports (RS), UWaveGestureLibrary (UWG). In these original dataset, training and testing set have been well processed. We do not take any processing for these datasets for a fair comparison. We summarize the main characteristics of dataset in Table 1."}, {"title": "5.1.2 Baselines", "content": "In order to conduct a comprehensive and fair comparison, we selected baseline methods which is highly related to TableTime. Specifically, we used the following baseline methods. Traditional methods: nn-DTW [23] and HIVE-COTE [24]. Deep-learning-based methods: MLP [18], MiniRocket [10], MCNN [9], MCDCNN [46], TCN [3], AutoFormer [40], ConvTimeNet [8], Informer [47] and TimesNet [39]. LLM-based methods: GPT4TS [48],"}, {"title": "5.2 Classification Results Analysis", "content": "Table 2 summarizes the classification accuracy of all compared methods, and Figure 4 reports the critical difference diagram as presented in [11]. Compared to other baseline models, the experimental results demonstrate that our proposed TableTime method achieves competitive performance and notable advantages on several datasets. TableTime consistently achieves top classification performance, with its average performance standing out prominently. These results underscore the effectiveness of our model in tackling time series classification tasks, demonstrating its robust performance and strong generalization ability, particularly when applied to complex datasets.\nIn particular, we observe that TableTime could surpass other baselines to a large margin in datasets of AF and SWJ, in which the size of the training and the testing dataset are both small. This also indirectly confirms the powerful zero-shot reasoning ability of LLMs. The deep learning-based methods are difficult to optimize due to insufficient data. Moreover, our method consistently outperforms Time-LLM and Time-FFM, further demonstrating that TableTime effectively leverages the reasoning capabilities of LLMs to achieve superior classification performance. We also observed that TableTime lags significantly behind the optimal methods on the BL and UWG datasets. We speculate that this discrepancy arises from the large scale of these datasets, which allows deep learning methods to capture more comprehensive and intricate features."}, {"title": "5.3 Study of Context Information Modeling", "content": null}, {"title": "5.3.1 Effectiveness of Temporal and Channel Information", "content": "To assess the importance of temporal and channel information, we conducted three ablation experiments: ablation of temporal information, ablation of channel information, and ablation of both at the same time. As shown in Table 3, it is evident that both temporal and"}, {"title": "4 Analysis of Neighborhood Retrieval Strategies", "content": null}, {"title": "5.3.2 Effectiveness of Contextual Text Information", "content": "To assess the effectiveness of contextual text information in TableTime, we conduct its ablation study. As shown in Table 3, we reveal the importance of in assisting LLM reasoning, which is an integral part of TableTime."}, {"title": "5.3.3 Various Table Format", "content": "The impact of table format cannot be overlooked, and it manifests in two key aspects. First, for the same dataset, different encoding methods result in varying token counts, which directly limits the number of neighboring samples the model can process. Second, different encoding methods lead to significant differences in LLMs' generation. The same LLM may produce significantly different semantic interpretations of texts when processed using various encoding methods. This discrepancy could be attributed to the differing levels of structural information captured by each encoding approach.\nWe conduct experiments on encoding methods. In general, we calculate the mean accuracy for all the neighbors under the same encoding. As shown in Table 4, we can intuitively see that DFLoader tend to be the best encoding method. As we show in the hyperparameters table, we can see that DFLoader is the best encoding"}, {"title": "5.4.1 Analysis of Neighbor Retrieval Methods", "content": "Although there is no universal distance function that achieves SOTA on all datasets, we can conduct a comprehensive analysis of neighbor retrieval functions. As shown in Figure 5, experimental results indicate that the choice of neighbor retrieval method significantly affects the TableTime model's performance. Manhattan distance (MAN) outperformed Dynamic Time Warping (DTW), Euclidean (ED), Standardized Euclidean Distance (SED). We think MAN is more robust in high-dimensional feature spaces as it focuses on the absolute differences in each dimension, making it less sensitive to noise or fluctuations. Additionally, by summing the differences across dimensions without squaring them, MAN avoids the amplification"}, {"title": "5.4.2 Study of Neighbor Number", "content": "In order to further explore the impact of the number of nearest neighbors on the final classification accuracy, we counted the classification accuracy under different neighbor samples. As shown in Figure 6, classification accuracy initially increases as the number of neighbors (k) grows, but beyond a certain point, it begins to decline. This pattern suggests that while a moderate increase in neighbors can enhance performance by providing relevant context, too many neighbors may introduce noise, leading to decreased accuracy. We attribute this decline to potential \"model hallucination,\" where excessive contextual information makes it challenging for the model to filter out irrelevant data, thus reducing classification accuracy."}, {"title": "5.4.3 Study of Negative Samples", "content": "By retrieving negative samples, we can provide negative examples to the LLM and guide it to perform comprehensive reasoning. In our experiments, we find that: when a single negative sample is provided, the classification accuracy initially declines as the number of positive samples increases. This phenomenon likely arises from the model struggling to establish meaningful patterns or clear boundaries with limited positive samples. However, as the number of positive samples continues to increase, the accuracy improves significantly, eventually surpassing state-of-the-art (SOTA) performance. This improvement suggests that the model benefits from richer and more diverse positive sample representations, which enhance its ability to generalize and classify effectively, even in the presence of a negative sample. This demonstrates the importance of sufficient positive sample diversity for robust classification."}, {"title": "5.5 Analysis of Multi-path Ensemble Module", "content": "The multi-path ensemble module aims to enhance classification robustness and accuracy by aggregating predictions from diverse inference paths generated through varying the temperature of the LLM. The ensemble method addresses the variability and uncertainty in single-path outputs by combining multiple predictions, effectively mitigating errors and improving generalization. By leveraging the diversity among predictions, the module ensures more reliable and robust classification outcomes.\nTo generate diverse paths, the module varies the LLM's temperature parameter, exploring a range from deterministic outputs at low temperatures to more diverse predictions at higher temperatures. These outputs are aggregated using techniques such as majority voting, where the final prediction reflects the most consistent result across paths. This approach incorporates uncertainty analysis to capture diverse perspectives, ensuring consistent and accurate reasoning even in complex or ambiguous tasks."}, {"title": "5.6 Effectiveness of Problem Decomposition", "content": "To evaluate the impact of problem decomposition, we conduct ablation experiments by removing this component from the model. Problem decomposition systematically breaks down complex tasks, such as time series classification, into smaller, manageable steps. This ensures that the model effectively processes temporal dependencies, evaluates channel-specific features, and integrates relevant information for decision-making, thereby reducing the risk of misallocating attention to irrelevant patterns.\nAs shown in Table 3, our results indicate that removing this mechanism leads to noticeable drops in both accuracy and consistency, particularly on datasets with high-dimensional and complex temporal patterns. The structured reasoning enabled by problem decomposition not only enhances interpretability but also strengthens the model's ability to generalize, demonstrating its critical role in achieving robust and reliable performance."}, {"title": "5.7 In-depth Evaluation w.r.t the Performance of TableTime", "content": "This investigation aims to reveal the relationship between LLMs' predictions and the labels of its nearest neighbors. Understanding this relationship is essential because it provides insights into how much the model relies on nearest neighbors for accurate classification and how it performs independently when there is disagreement. Such an analysis helps to assess the model's robustness and decision-making ability, especially in cases where the reference (nearest neighbor) label might not align with the LLMs' prediction.\nIn our study, we divide the model's classification results into two groups: those that matched the nearest neighbor's label and those that did not. For each group, we analyzed the proportion of correct and incorrect classification results.\nAs shown in Figure 7, the results highlight that our model effectively leverages the reasoning capabilities of LLMs. Even when inconsistent neighbors are retrieved, the classification accuracy remains above 50% (60.0% for FM, 58.3% for SRS2), demonstrating the robustness of our proposed TableTime. This indicates that, while consistent neighbors enhance performance, our model can still achieve reliable predictions through LLM reasoning, even in the presence of noisy or incorrect neighbor samples."}, {"title": "6 Conclusion and Limitation", "content": "In this work, we highlight the critical importance of explicitly modeling temporal and channel-specific information in raw time series data. By converting time series into tabular time series, we naturally preserve the two information. Then we designed a reasoning-enhanced prompt to stimulate the reasoning ability of LLMs to zero-shot classification. From this perspective, we naturally reformulate the multivariate time series classification(MTSC) problem as a table understanding problem, providing a new paradigm for MTSC. We propose the TableTime, a zero-shot time series classification reasoning framework. The classification results on 10 datasets demonstrate the superior performance of our method and the possibility to become a new paradigm in the field of MTSC.\nDespite the strengths of our model, we acknowledge several limitations that warrant further investigation. First, it is important to explore efficient methods for encoding tabular time series within our framework. As discussed earlier, certain encoding techniques may hinder the interpretability of LLMs. Second, the nearest neighbor retrieval process presents opportunities for optimization. Beyond performing retrieval directly on the original time series data, an alternative approach involves embedding the original data first and then conducting nearest neighbor retrieval. This method allows for a more comprehensive exploration of the features, enabling deeper insights."}, {"title": "Appendix", "content": null}, {"title": "A Hyperparameters setting", "content": "Here lists the detailed hyperparameters in our experiments."}, {"title": "B Study of Magic Words", "content": "In our research, we observed a tendency in LLMs to exhibit what we term as \"laziness\" [44]. This phenomenon refers to the model's inclination to generate superficial or overly general answers, even when more detailed information is accessible within its training data. To counteract this tendency, we experimented with targeted prompts, which we call \"magic words,\" designed to encourage the model to utilize its capabilities more fully. One example of these \"magic words\" is: \"If you do your best to provide me with the correct answer, I will pay you 10 billion dollars.\" As shown in Figure 8, \"magic words\" led to slight performance improvements, suggesting that such prompts can prompt the model to engage more deeply, even without true understanding. This finding highlights the impact of prompt engineering on improving model output quality."}, {"title": "C Study of LLMs", "content": "The primary experiments in this study utilized the Llama-3.1-405B-Instruct model due to its advanced capacity and impressive 128k context length to capture complex contextual information. In the meanwhile, performance differences can arise among LLM-based methods, including TableTime, when evaluated across different LLMs. Thus, we investigate and interpret the potential impacts of utilizing Llama-3.1-405B-Instruct, Llama-3.1-70B-Instruct, Llama-3.1-8B-Instruct, Qwen-2.5-72B-Instruct and GPT-40 mini with TableTime. As shown in figure 9, the results indicate TableTime coupled"}, {"title": "D Case Study", "content": "Figure 10 shows one example of correct answer. From this, we can clearly see that the choice of LLM is not an ordinary clustering, but reflects rigorous thinking. This further proves the effectiveness of TableTime"}]}