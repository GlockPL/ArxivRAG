{"title": "BAICHUAN4-FINANCE TECHNICAL REPORT", "authors": ["Hanyu Zhang", "Boyu Qiu", "Yuhao Feng", "Shuqi Li", "Qian Ma", "Xiyuan Zhang", "Qiang Ju", "Dong Yan", "Jian Xie"], "abstract": "Large language models (LLMs) have demonstrated strong capabilities in language\nunderstanding, generation, and reasoning, yet their potential in finance remains\nunderexplored due to the complexity and specialization of financial knowledge. In\nthis work, we report the development of the Baichuan4-Finance series, including\na comprehensive suite of foundational Baichuan4-Finance-Base and an aligned\nlanguage model Baichuan4-Finance, which are built upon Baichuan4-Turbo base\nmodel and tailored for finance domain. Firstly, we have dedicated significant effort\nto building a detailed pipeline for improving data quality. Moreover, in the contin-\nual pre-training phase, we propose a novel domain self-constraint training strategy,\nwhich enables Baichuan4-Finance-Base to acquire financial knowledge without\nlosing general capabilities. After Supervised Fine-tuning and Reinforcement Learn-\ning from Human Feedback and AI Feedback, the chat model Baichuan4-Finance is\nable to tackle various financial certification questions and real-world scenario ap-\nplications. We evaluate Baichuan4-Finance on many widely used general datasets\nand two holistic financial benchmarks. The evaluation results show that Baichuan4-\nFinance-Base surpasses almost all competitive baselines on financial tasks by\nsignificant margins without sacrificing performance on general LLM benchmarks.\nAt the same time, Baichuan4-Finance demonstrates even more impressive per-\nformance on financial application scenarios, showcasing its potential to foster\ncommunity innovation in the financial LLM field.", "sections": [{"title": "1 INTRODUCTION", "content": "Since the launch of ChatGPT \u00b9, interest in large language models (LLMs) has surged worldwide. The\nrelease of the Llama series (Touvron et al., 2023) further sparked excitement within the open-source\ncommunity, particularly for GPT-level local LLMs. Recently, Claude-3 Opus 2, Gemini-1.5 (Team\net al., 2023), GPT-4 (Achiam et al., 2023), GPT-40 (omni) 3, 01-preview and o1-mini 4, the updated\nversions of ChatGPT, quickly rose to the top of the Chatbot Arena (Chiang et al., 2024). Additionally,\nLlama-35 has become the leading open-weight model series, closing the performance gap with top\nproprietary models and regarded as on par with GPT-4. An increasing number of competitive LLMs,\nsuch as Baichuan (Yang et al., 2023a), Qwen (Bai et al., 2023), Mistral (Jiang et al., 2023), and\nGemma (Team et al., 2024), are reported gradually, following in the footsteps of the GPT series and\nLlama series.\nApplying general LLM to the finance domain presents challenges, as financial documents often\ncontain complex numerical data and domain-specific terminology, requiring advanced numerical\nprocessing and reasoning skills. As a result, financial LLMs must have extensive domain knowledge\nto interpret the subtle implications. Recently, many financial LLMs have also been developed to meet\nthe needs of the financial domain, such as (Wu et al., 2023; Yang et al., 2023b; Liu et al., 2021; Xie\net al., 2023; Yang et al., 2023c; Shah et al., 2022), which have demonstrated superior capabilities over\ngeneral models in many financial-related tasks. These advancements have revealed the potential of\nunstructured data for data-driven financial decision-making and for transforming financial documents\ninto actionable insights and market intelligence.\nOver the past two years, Baichuan Inc. has introduced many LLM series, including Baichuan series 6,\nBaichuan2 series (Yang et al., 2023a), Baichuan3 series and progressed to the latest Baichuan4\nseries 7. During the same time, we reported the role play LLMs Baichuan-NPC series 8 providing\nhighly flexible personalized character customization capabilities. In this work, we introduce the\nfirst financial LLM series of the Baichuan LLM family: Baichuan4-Finance. It is a series of LLMs\ngrounded in the Baichuan4-Turbo base model 9 and specifically tailored for the finance domain.\nThis LLM series includes a foundational/base language model Baichuan4-Finance-Base, which\nis pre-trained but not yet aligned with human preferences, as well as an instruction-tuned model\nBaichuan4-Finance, which has been fine-tuned for chat and downstream applications.\nGenerally, the development of a domain-specific LLM consists of two main stages:\n\u2022 Continual pre-training: aiming to remain an existing general LLM with new domain-\nspecific data on an incremental sequence of tasks (Lee et al., 2024).\n\u2022 Alignment: aiming to fine-tune models to follow instructions, align with human preferences,\nand improve LLMs' specific domain capabilities (Dubey et al., 2024).\nBased on past experience, many factors have a significant impact on the performance of the final\nmodel: data (quality & size & mixture ratio), model (tokenizer & architecture), and training strategy\n(continual pre-training & alignment). In this report, we will introduce how we seek to optimize the\nabove factors throughout our development process."}, {"title": "2 TOKENIZER & MODEL ARCHITECTURE", "content": "This section introduces the tokenizer and model architecture of Baichuan4-Finance-Base."}, {"title": "2.1 TOKENIZER", "content": "We employ the byte-level byte-pair encoding (BBPE) (Wang et al., 2020) as the tokenizer, which\nhas been proven to have a high compression rate relative to others (Yang et al., 2024). The resulting\nvocabulary has 141,056 regular tokens."}, {"title": "2.2 MODEL ARCHITECTURE", "content": "Pre-normalization with RMSNorm To handle training stability, we employ the RMSNorm (Jiang\net al., 2024) for pre-normalizing.\nGrouped-Query Attention We leverage the Grouped Query Attention (GQA) (Ainslie et al., 2023)\ninstead of the traditional Multi-Head Attention (MHA) (Vaswani, 2017) to improve inference speed\nand to reduce the size of key-value caches during decoding.\nPositional Encoding ROPE (Su et al., 2023) is employed to serve for positional encoding as most\nopen-sourced models do."}, {"title": "3 CONTINUAL PRE-TRAINING", "content": "In the pre-training of the Baichuan4-Finance-Base, we mainly focused on dataset composition,\ndataset quality enhancement, determining the data mixture ratio with scaling law, and the strategy of\ncontinuing pre-training. We present each of these components separately below."}, {"title": "3.1 PRE-TRAINING DATA COMPOSITION", "content": "The Pre-training Data consists of two main parts: general data encapsulating world knowledge and\nfinancial data containing extensive financial knowledge.\nGeneral Data (400B tokens - 80% of pre-training data) To create a comprehensive global\nknowledge system, we collect diverse data from various sources, such as internet webpages, books,\nresearch papers, codebases, and more.\nFinancial Data (100B tokens - 20% of pre-training data) To teach the model finance-related\nknowledge, we construct a comprehensive dataset comprising a range of financial documents includ-\ning news, press releases, finance books, finance journals, and social media posts. The composition of\nthe financial corpus is shown in Figure 1."}, {"title": "3.2 DATA QUALITY ENHANCEMENT", "content": "Generally, datasets that are unfiltered or only lightly filtered tend to have lower quality compared\nto more carefully curated ones. Therefore, we have carefully designed a pipeline to enhance the\noverall quality of the data. We filter and clean the associated texts using rule-based heuristics, such as\ncontrolling the average sentence length and document length. Then the following processing methods\nare employed to the dataset step by step.\nData Filtering with Quality Classifier To improve data quality, we first train an automatic quality\nclassifier based on logistic regression to remove the low-quality documents. High-quality examples\nare selected from general data, while the raw unfiltered documents are sampled from various sources\nand taken as low-quality examples. We mix these two class data with a 1:1 ratio for classifier training.\nOnce the classifier is fitted, we then apply it to score the unfiltered documents and re-sample them by\ngiving priority to those predicted to be of higher quality:\nnp.random.pareto(a) > 1 document_score."}, {"title": "Data Filtering with Model Scoring", "content": "After the quality classifier, we perform further data filtering\nfrom a more fine-grained perspective. At first, by prompting Baichuan4-Turbo, we score millions\nof data samples across multiple dimensions, including readability, coherence, informativeness,\nsafety, degree of anonymity, and unattainable references. The scoring system is designed to capture\nboth qualitative and quantitative aspects of the data reliably and responsibly. Secondly, the data and\ncorresponding labels serve as inputs to train an automatic scoring model grounded on XLM-Roberta 10.\nLastly, after the scoring model is fitted, we leverage the aforementioned pareto re-sampling strategy\nto filter data.\nIn this process, we also leverage an abnormal loss detection schema to filter low-quality data.\nSpecifically, we obtain the loss of every source of data using a 1B Base model and perform sampling\nanalysis on data with abnormal loss values. If the anomalies are due to low-quality data and represent\ncommon, generalizable issues, we apply rules to identify and remove similar entries. For more\ncomplex issues that cannot be fully addressed with rules, we collect a sample set and feed them into\nthe XLM-ROBERTa model to learn their patterns.\nCode, Math and Markdown Data Due to the significantly different token distributions of code,\nmath, and markdown data compared to natural language, we develop specialized filtering models\ntailored to these data types.\nData De-duplication & Anonymization To prevent redundancy, following (Dubey et al., 2024),\nwe perform many rounds of de-duplication processes at the URL level, document level and line level,\nrespectively.\n\u2022 URL level de-duplication: we retain the latest version of each page corresponding to its\nURL across the entire dataset.\n\u2022 Document level de-duplication: we leverage global MinHash (Broder, 1997) across the\nentire dataset to de-duplicate the similar docments. Remarkably, different de-duplication\nthresholds are set for documents of varying difficulty.\n\u2022 Line-level de-duplication: following Llama 3 (Dubey et al., 2024) and ccNet (Wenzek et al.,\n2019), we remove lines that occur more than certain times within each bucket.\nBesides, We use regular expressions to anonymize data, including personal names, paper references,\netc."}, {"title": "3.3 DETERMINING THE DATA MIXTURE RATIO BY SCALING LAWS", "content": "Scaling Laws Considering the differences in data distribution between the pre-training and continual\npre-training stages, careful attention must be given to seeking the optimal mixture ratio of the pre-\ntraining financial data to develop a high-quality financial LLM. To obtain the Baichuan4-Finance-Base,\nwe need to determine the mixture ratio of n = 37 financial data sources, including research reports,\nacademic papers, examination questions, and more.\nTo identify the optimal data mixture ratio with limited training costs, we conduct a two-stage scaling\nlaw methodology by training several small models on specific data mixture ratios and using their\nperformance to estimate how a larger model would perform with the same mixture ratio:\n\u2022 We first establish a correlation between the model size, data mixture ratio, dataset sizes and\nthe model validation loss with D-CPT Law (Que et al., 2024). Assuming that N indicates\nthe model size, $D = [D_1, D_2,\\cdots, D_n]$ indicates the dataset size of n data sources, given a\nspecific mixture ratio $r = [r_1,r_2,\\ldots,r_n]$ corresponding to these data sources, we could\nleverage the parameterization function $L = \\{L_i\\}_{i=1}^n$ defined as follows to predict the"}, {"title": "3.4 CONTINUAL PRE-TRAINING", "content": "We continue training Baichuan4-Turbo base model to develop Baichuan4-Finance-Base. Regular\ncontinual pre-training involves training on new data using the same training strategy as the pre-\ntraining phase. Drawing inspiration from the concept of PPO (Schulman et al., 2017), we introduce\na novel domain-specific continual pre-training strategy, termed domain self-constraint continual\npre-training. This approach balances two objectives: firstly, maintaining the knowledge of the\ngeneral model, ensuring the retention of general task-solving capabilities; and secondly, enabling\nthe training model to acquire domain-specific financial knowledge. To achieve these two goals, we\ndesign two different objectives, respectively.\nConsidering a reference LLM - Baichuan4-Turbo base model parameterized by bref, and the\nBaichuan4-Finance-Base parameterized by @fin and a pre-training document $x = \\{x_t\\}_{t=1}^T$, where T\nindicates document length.\nIf the document \u00e6 belongs to the general data, we formalize the learning objective as:\n$\\mathcal{L} = \\mathcal{L}_{kl} = \\frac{1}{T} \\sum_{t=1}^T KL (P_{\\theta_{fin}} (x_t | x_{<t}), P_{\\theta_{ref}} (x_t | x_{<t})),$"}, {"title": "3.5 ANNEALING", "content": "During the continual pre-training stage on the final 80M tokens, the learning rate was linearly reduced\nto 0. Additionally, the data mixture ratio was adjusted to prioritize high-quality financial data sources\n(Dubey et al., 2024)."}, {"title": "4 ALIGNMENT", "content": "After the extensive large-scale pre-training phase, we further delve into the alignment phase to refine\nits capabilities across diverse domains such as financial computation, financial logical reasoning,\nand financial instruction following. This phase is crucial for ensuring that the model's outputs align\nwith human values, making them useful, truthful, and safe. Specifically, we focus on collecting\nhigh-quality demonstration data for alignment training aiming to reduce the reliance on human\nlabeling while maximizing data quality and reliability."}, {"title": "4.1 SUPERVISED FINE-TUNING", "content": null}, {"title": "4.1.1 DEMONSTRATION DATA CONSTRUCTION", "content": "The construction process of demonstration data mainly consists of three steps: finance materials\nconstruction, seed sample repository construction and large-scale demonstration construction.\nFinance Materials Construction Firstly, we collect a large-scale financial corpus, including news\narticles, research papers, books, and other relevant financial documents, to serve as the foundational\ndemonstration data source.\nSeed Sample Repository Construction Secondly, we construct a high-quality human-annotated\nseed sample repository for further large-scale automated data construction. From an application per-\nspective, we categorize the problems that Baichuan4-Finance aims to solve along multiple dimensions\nto construct the instructions:\n\u2022 By basic capabilities: classification, clustering, generation, summarization, extraction,\nquestion-answering, coding, mathematics, etc.\n\u2022 By problem complexity: simple instructions, normal instructions, complex instructions.\nFor these instructions, we manually constructed high-quality data to serve as seeds for generating\nlarge-scale demonstration datasets."}, {"title": "Large-scale demonstration construction", "content": "For one document sampled from the constructed finance\nmaterials repository, with an in-context learning strategy, in which the examples are sampled from the\nseed sample repository, we prompt Baichuan4-Turbo to generate the corresponding instruction. Then,\nmultiple responses to an instruction are obtained using diverse generation strategies. Lastly, human\nannotators manually review and filter the generated demonstration data and construct a high-quality\ndemonstration dataset for further supervised fine-tuning."}, {"title": "4.1.2 TRAINING STRATEGY", "content": "We have curated a comprehensive instruction dataset containing over 160,000 high-quality demonstra-\ntions, covering tasks such as instruction following, financial classification, clustering, and generation.\nBased on this dataset and the regular supervised fine-tuning process, the supervised fine-tuned model\nis produced."}, {"title": "4.2 REWARD MODEL", "content": null}, {"title": "4.2.1 PREFERENCE DATA CONSTRUCTION", "content": "Human Feedback Preference Data Construction For scenarios with non-unique answers, such\nas in information understanding and creative tasks, we use human feedback (Ouyang et al., 2022)\nto construct the preference dataset. Specifically, we first collect prompts and perform multiple\nhigh-temperature samplings for each prompt using Baichuan4-Turbo. Then, human annotators score\nand rank each answer on truthfulness, harmlessness, fluency, and instruction following. Finally, based\non the ranking results, we could construct many chosen and rejected pairs for each prompt.\nAI Feedback Preference Data Construction For scenarios with unique answers, such as math-\nematical reasoning, which is particularly important for financial scenarios requiring calculations,\nwe use AI feedback (Cui et al., 2024; Li et al., 2024b) to construct the preference dataset. For\nexample, given a mathematical dataset, for each math prompt, Baichuan4-Turbo generates answers\nthrough several inference runs. A verifier then checks each answer against the ground truth label to\ndetermine its correctness. Samples where all answers are correct and those with all incorrect answers\nare removed. The remaining samples are used to construct the preference dataset.\nBy the above two processes, we fulfill the preference dataset construction, which is used for the\nreward model training."}, {"title": "4.2.2 REWARD MODEL TRAINING", "content": "The reward model is initialized from the Baichuan4-Turbo base model by replacing the language mod-\neling head with a value head. For a prompt x with its corresponding preference data (Ychosen, Yrejected),\nfollowing (Ouyang et al., 2022), the loss function of the reward model is formulated as:\n$\\mathcal{L}_{rm} = -\\frac{1}{N} \\sum_{(x, Y_{chosen}, Y_{rejected})} [log (\\sigma (r_{\\theta}(x, Y_{chosen}) \u2013 r_{\\theta} (X, Y_{rejected})))],$ \nwhere N denotes the number of preference pairs of the prompt x, e denotes the parameter set of\nreward model and re(x, y) indicates the output reward score."}, {"title": "4.3 REINFORCEMENT LEARNING FROM HUMAN FEEDBACK AND AI FEEDBACK", "content": "Reinforcement Learning from Human Feedback (RLHF) or from AI feedback is increasingly regarded\nas a crucial approach for LLM alignment. However, alignment methods that depend on the reward\nmodel present notable challenges due to the inherent instability and imperfections of reward models,\nleading to problems like reward hacking and misalignment with human intentions. Inspired by\n(Yan et al., 2024), we leverage such a PPO-based reward-robust framework to pursue more reliable\nand resilient reinforcement learning. We first initialize the model with the supervised fine-tuned\nBaichuan4-Finance-Base and use it to generate predictions for randomly selected prompts from\nthe overall prompts constructed in preference data construction. Then we optimize it with the\nPPO strategy and the above reward-robust framework by maximizing the overall reward. After\nreinforcement learning, the final chat version model is produced, called Baichuan4-Finance."}, {"title": "5 EXPERIMENTS", "content": null}, {"title": "5.1 BENCHMARKS", "content": "Public General Benchmarks C-Eval (Huang et al., 2024), CMMLU (Hendrycks et al., 2020),\nMMLU (Hendrycks et al., 2020), GSM8k_ZH (translated from GSM8k (Cobbe et al., 2021) into\nChinese), and HumanEval (Chen et al., 2021). Besides, we also leverage 7 math datasets from (Li\net al., 2024a), including MATH, K-12, Orca-math, AoPS Forum, Olympiads, AMC&AIME and\nSynthetic. We randomly sampled 800 samples from them and manually translated 400 of them into\nChinese for testing.\nPublic Financial Benchmarks We evaluate the financial capabilities by using two benchmarks\nFinanceIQ and FLAME."}, {"title": "5.2 PRELIMINARY EXPERIMENTS", "content": null}, {"title": "5.2.1 ABLATION STUDY FOR DOMAIN SELF-CONSTRAINT CONTINUAL PRE-TRAINING", "content": "To evaluate the effectiveness of the domain self-constraint strategy, we conducted a preliminary\nexperiment using a 1B small Base model, with the results presented in Figure 2. The figure compares\nthe model's performance on multiple datasets using three different training approaches: without\ncontinual pre-training, with regular continual pre-training, and with the proposed domain self-\nconstraint continual pre-training. The results indicate that regular continual pre-training leads to a\nloss of general knowledge as the model learns financial knowledge. In contrast, the proposed domain\nself-constraint strategy enhances the model's financial performance while preserving its general\nknowledge.\nFurthermore, we compared the performance of Baichuan4-Finance-Base with its backbone,\nBaichuan4-Turbo base model, to showcase the capabilities of Baichuan4-Finance-Base on both\ngeneral tasks and financial-related tasks. The results are shown in Figure 3, from which we can see\nthat Baichuan4-Finance-Base surpasses Baichuan4-Turbo base model on financial benchmark by\nsignificant margins with comparable performance on general datasets."}, {"title": "5.2.2 ABLATION STUDY FOR PPO", "content": "To investigate the necessity of the reinforcement learning phase, i.e. the effectiveness of PPO, we\ncompared the following three models:\n\u2022 Baichuan4-Finance: trained Baichuan4-Finance-Base with supervised fine-tuning strategy\non the SFT demonstration dataset and then aligned it by PPO strategy on the preference\ndataset;\n\u2022 Baichuan4-Finance w/o PPO: trained Baichuan4-Finance-Base with supervised fine-tuning\nstrategy, on the SFT demonstration dataset and the prompts in preference dataset with\ncorresponding ground truth labels;\n\u2022 Baichuan4-Finance-Base-SFT: trained Baichuan4-Finance-Base with the supervised fine-\ntuning strategy only on the SFT demonstration dataset."}, {"title": "5.3 MAIN RESULTS OF BAICHUAN4-FINANCE", "content": null}, {"title": "5.3.1 BASELINES", "content": "Under zero-shot setting, we compare the generation accuracy of Baichuan4-Finance with GPT-\n40 13 and two open-source LLMs Qwen2.5-72B-Instruct 14 and Xuan Yuan3-70B 15 on benchmark\nFinanceIQ. For the benchmark FLAME, we present the evaluation results of the official institute,\nwhich contains 5 competitive chat LLMs including GPT-40, ERNIE-4.0-Turbo-128K 16, GLM-4-\nPLUS 17, Qwen2.5-72B-Instruct and XuanYuan3-70B."}, {"title": "5.3.2 COMPARISON RESULTS", "content": "The comparison results of Baichuan4-Finance and baselines on the FinanceIQ dataset are shown\nin Table 3, while the results of the FLAME benchmark are shown in Table 1 and Table 2. We can\nsee that Baichuan4-Finance has strong capabilities in tackling different financial certifications and\napplication scenarios."}, {"title": "6 CONCLUSION", "content": "In this report, we introduce the Baichuan4-Finance series, which includes two models: Baichuan4-\nFinance-Base and the chat model Baichuan4-Finance. There are three key technical highlights in this\nreport: (1) For the data side: the continual pre-training data construction pipeline and the data mixture\nratio determining process using two scaling laws; (2) For the training side, the proposed a novel\npre-training strategy, called domain self-constraint training, tailored for the domain LLM continual\npre-training. We evaluate Baichuan4-Finance through extensive experiments and the results indicate\nthat Baichuan4-Finance-Base outperforms nearly all competitive baselines on financial tasks by\nsubstantial margins, without compromising performance on general LLM benchmarks. Additionally,\nBaichuan4-Finance delivers even more remarkable performance in financial application scenarios,\nhighlighting its potential to drive innovation within the financial LLM community."}]}