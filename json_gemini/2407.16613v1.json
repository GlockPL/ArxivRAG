{"title": "No-brainer: Morphological Computation driven Adaptive Behavior in Soft Robots", "authors": ["Alican Mertan", "Nick Cheney"], "abstract": "It is prevalent in contemporary AI and robotics to separately postulate a brain modeled by neural networks and employ it to learn intelligent and adaptive behavior. While this method has worked very well for many types of tasks, it isn't the only type of intelligence that exists in nature. In this work, we study the ways in which intelligent behavior can be created without a separate and explicit brain for robot control, but rather solely as a result of the computation occurring within the physical body of a robot. Specifically, we show that adaptive and complex behavior can be created in voxel-based virtual soft robots by using simple reactive materials that actively change the shape of the robot, and thus its behavior, under different environmental cues. We demonstrate a proof of concept for the idea of closed-loop morphological computation, and show that in our implementation, it enables behavior mimicking logic gates, enabling us to demonstrate how such behaviors may be combined to build up more complex collective behaviors.", "sections": [{"title": "1 Introduction and Background", "content": "Recent advances in artificial intelligence and machine learning have benefited greatly from the rise of modern deep learning systems, ultimately aimed at artificial general intelligence [22]. The coming-of-age of these artificial neural network systems includes a long history of bio-inspiration, dating back to Mcculloch and Pitts [26]. Yet the processes behind biological intelligence reach far beyond systems and processes confined to the brain of living organisms.\nOur bias toward attributing intelligent behavior to the mind is far from new. Descartes' mind-body-dualism dates back to the 1600s [13]. However, Bongard warns that \"thinking about thinking is misleading\" [4]. Moravec's paradox, the observation that reasoning takes less computational resources than sensory-motor skills (contrary to the expectations of experts), is an example of how intuition could fail in introspection on thinking [30]. Examples of complex, perhaps intelligent-seeming, behavior stemming from non-neural processes are abound in both engineered and natural systems. Perhaps the most notable example of a system built to mimic a complex behavior in simple and purely mechanical form is the passive walking robot, which gracefully walks down an incline plane"}, {"title": "2 Methodology", "content": "Simulation: We run our experiments on the EvoGym simulator [3]. It is a 2D soft robot simulator where robots are represented by voxels that can actuate by changing their areas (a \u2208 [0.6 \u00d7 r, 1.6 \u00d7 r] where r is the resting area). Designing robots' bodies means placing voxels with varying materials in a grid layout and specifying connections with their neighbors. In our experiments, we assume all neighboring voxels are connected to simplify the design space.\nEnvironment: We use EvoGym's Python API to define a custom environment with two stimuli. These stimuli work in a binary fashion - they are either present or absent in the environment. For our robots to sense these stimuli and adapt their behavior, we hand-design \"sensory voxels\". We consider two environmental stimuli, each with one voxel type that expands in response to that stimuli and one that contracts in the presence of that stimuli for a total of 4 sensory voxel types (Fig. 1; green, red, magenta, blue). We also hand-designed two active voxels (orange and teal) that horizontally expand and contract to provide energy for locomotion following a sinusoidal signal with a 180\u00b0 phase offset, similar to the designs in [11], but do not provide any neural or informational connectivity between them to organize a coordinated controller by means other than physical forces traveling through the robot's body. Lastly, we provide evolution with two passive voxels, soft (gray) and rigid (black)."}, {"title": "3 Responding to Binary Stimuli", "content": "Firstly we investigate whether purely morphological changes can result in behavior that adapts to environmental stimuli. Over the 4 stimuli patterns presented to the robot, our MAP-Elites archive collects different combinations of behavioral patterns that different morphologies produce (labeled for whether a robot moves (L)eft or (R)ight for each of the 4 stimuli). Fig. 2 visualizes the behavior of a robot exhibiting LRRL behavior as a spacetime diagram to investigate how the morphology gives rise to adaptive behavior. The solid line tracks the position of the robot's center of mass during simulation. The two lines accompanying the solid line display the stimuli pattern at each time step. The dotted horizontal line shows the moments when the stimuli pattern changes. The robot's morphology and its gait under different stimuli can be seen on the right. The robot moves to the right only if one of the two stimuli is present (the middle two settings). In the case where both stimuli are present or absent (the first and last setting), the robot moves to the left. This behavior is achieved with the help of sensory voxels the change in the sensory voxels alters the robot's shape and thus changes its gait. The robot exhibits an adaptive behavior without the help of a dedicated brain. Reactive materials are enough to unlock morphological computation.\nFig. 3 displays spacetime diagrams of all run champions successfully exhibiting different adaptive behaviors. Each run champion is drawn in a different color and the average normalized space traversed by run champions in each plot can be seen in the bottom right corner. We see that given adequate environmentally-sensitive building blocks to work with, evolution can find morphologies that exhibit various adaptive behaviors \u2013 responding to stimuli in different ways via shape change alone (without a learned and/or stimuli-aware controller)."}, {"title": "4 Making a Swarm for More Complex Behavior", "content": "The above section demonstrated the evolution of robots exhibiting adaptive behavior in response to the two stimuli. To the best of our knowledge, this is the first example of a closed-loop fully-morphological behavior in evolved robots. The simplicity of the chosen behavior (more right or left) allows us to clearly see how shape change due to the stimuli-sensing materials affects the robots' behavior. But this also invites a thought experiment: how could this proof of concept scale to create complex \"intelligent\" behaviors from this simple framework?\nIn this section, we study how these robots can be grouped to create a swarm exhibiting more complex behavior. As a proof of concept, we use a subset of previously evolved robots and hand-design the swarm to show a certain behavior. We start with an observation. Given the binary nature of the stimuli and the possible behaviors of the robot (moving in a positive or negative direction on the x-axis), the robots could be considered implementing logic gates from the perspective of an outside observer. Above, we evolved robots implementing all possible boolean functions by evolving an archive of robots exhibiting all possible behaviors (Fig. 3). For instance, if we assume that a robot moving in the positive x direction on the x-axis is outputting a 1, robots exhibiting the RRRL behavior can be considered as implementing the NOT-AND boolean function.\nWe can organize robots, by assuming that the behavior of one robot could determine the stimulus of another robot. While this is arbitrary given our manually and abstractly designed stimuli, it's not a great stretch of the imagination to envision some analogous physical or chemical sensory apparatus that would allow voxels to sense the relative change in distance of a neighboring robot similar to how animals do (e.g. it became \u201clouder\u201d or its \u201csmell\u201d became stronger).\nTo demonstrate a more complex function derived from these morphological logic gates, we manually design a swarm implementing a D-type latch\u00b9. Fig. 5 top left, shows the schematic of the swarm from an outside observer's perspective. The swarm consists of a single robot with behavior RRLL (leftmost robot, implements AND gate), and four robots with behavior RRRL (implement NAND gate). The swarm has two swarm stimuli, observed by three of the robots. The rest of the stimuli that robots observe are determined by others' behavior. The inner wiring of the swarm can be seen in Fig. 5 top right, where wires on the left side of the robots represent stimuli and the wires on the right side of the robots represent the output of the robot (which determines the stimulus of another robot). If a robot's center of mass has moved in the positive x direction in the last actuation cycle it is considered to be outputting 1 and turns the stimulus on for another robot and vice versa.\nWe plot the behavior of the swarm as a spacetime diagram in Fig. 5 bottom row. The behavior of each individual and their immediate stimuli can be seen on the left. As expected, robots successfully perform the behaviors that are evolved for, seamlessly responding to changing stimuli patterns. However, if we observe the behavior of the starred robot (top-right robot) with respect to swarm stimuli (as opposed to the robot's immediate stimuli) in Fig. 5 bottom right, we see that the robot is moving following the swarm stimulus 1, only when the swarm stimulus 2 is present, otherwise the robot keeps moving in the direction of last observed swarm stimulus 1. Given the right frame of reference (observing the robot's behavior with respect to the swarm stimuli) and certain assumptions (behavior of one robot determining the stimulus of another), we show that robots exhibit complex adaptive behavior, without any separately postulated brain, that would typically require memory to achieve. This achievement is, certainly, not a surprise, given the equivalence of robots' behavior with boolean functions. Once we have robots that can implement the NOT-AND function, we could build a swarm that would perform any computable behavior. We leave the design of such swarms as an exercise for the reader."}, {"title": "5 Discussion", "content": "The above results demonstrate \"intelligent\" morphological computation that adapts the robot's behavior via stimuli-educed shape change rather than by a dedicated control or brain-like mechanism. While we feel that this proof of concept is an important, and hopefully entertaining, demonstration, we fully acknowledge that the most complex and adaptive behaviors in natural systems are not fully morphological, but are an interplay of embodied cognition connecting the body and the brain.\nRecent literature had demonstrated the challenges of brain-body co optimiza-tion and noted fragile co-adaptation to be a major challenge of evolving these systems [8,29], further suggesting that increasing the adaptability and robust-ness of the brain and body to modification in the other could result in less fragile and thus more effective brain-body systems [10,28]. We hope that by creating more intelligent and adaptive bodies, this work helps to open doors to transfer additional computation to the morphology and enable less fragile co-adaptation.\nLastly, we want to connect this research to recent ideas in artificial and natural evolution. Specifically, it has been argued that a key feature of natural evolution is that it works with material that is active. Cells that already have an array of functionalities come together to create multi-cellular structures, tissues, organs, and systems, creating a \"multiscale competence architecture\" where each scale exploits and regulates the already-existing functionalities of the scale below to achieve its goals [24]. This is considered to be an important feature of natural evolution and understanding/exploiting this in artificial evolution could have substantial effects [6,15]. Inspired by these ideas, here we show a first pass at demonstrating that simple materials each with straightforward behaviors can be optimized in their emergent design to result in a complex and adaptive system. In future work, we hope to examine how we can consider such a system as a substrate for further evolution (potentially in combination with separately postulated brain models)."}, {"title": "6 Conclusion", "content": "We investigate ways in which complex, adaptive behavior can be created in virtual voxel-based soft robots without the use of a separately postulated brain. We hand-design simple muscle (that continuously expands and contracts) and sensory (that expands/shrinks in the presence or absence of a binary stimulus) voxel materials and show that evolution can create designs that exhibit closed-loop adaptive behavior, responding to two binary stimuli. Moreover, a swarm of such robots can exhibit even more complex behavior. In future work, we hope to study more ways of creating adaptive and complex behavior."}]}