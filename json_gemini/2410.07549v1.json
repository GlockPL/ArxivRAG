{"title": "OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting", "authors": ["Xukai Liu", "Ye Liu", "Kai Zhang", "Kehang Wang", "Qi Liu", "Enhong Chen"], "abstract": "Entity Linking (EL) is the process of associating ambiguous textual mentions to specific entities in a knowledge base. Traditional EL methods heavily rely on large datasets to enhance their performance, a dependency that becomes problematic in the context of few-shot entity linking, where only a limited number of examples are available for training. To address this challenge, we present OneNet, an innovative framework that utilizes the few-shot learning capabilities of Large Language Models (LLMs) without the need for fine-tuning. To the best of our knowledge, this marks a pioneering approach to applying LLMs to few-shot entity linking tasks. OneNet is structured around three key components prompted by LLMs: (1) an entity reduction processor that simplifies inputs by summarizing and filtering out irrelevant entities, (2) a dual-perspective entity linker that combines contextual cues and prior knowledge for precise entity linking, and (3) an entity consensus judger that employs a unique consistency algorithm to alleviate the hallucination in the entity linking reasoning. Comprehensive evaluations across seven benchmark datasets reveal that OneNet outperforms current state-of-the-art entity linking methods.", "sections": [{"title": "1 Introduction", "content": "Entity Linking (EL), also known as Named Entity Disambiguation (NED), entails the process of linking ambiguous textual mentions to specific entities in a knowledge base, as shown in Figure 1 (a). This process is a critical element of both Natural Language Processing (NLP) and Information Retrieval (IR) (Sevgili et al., 2022; Liu et al., 2023e).\nTo enhance the accuracy of EL, researchers employ two primary methods: discriminative models and generative models. Discriminative models represent mentions and entities through embeddings and link entities by calculating the similarity. To"}, {"title": "2 Related Works", "content": "2.1 Entity Linking\nRecently, knowledge graphs (KGs) have received widespread attention (Liu et al., 2023e,c). Entity linking (EL), which is the core step in constructing KG, has been applied to various fields (Xu et al., 2023a; Shi et al., 2024). As a crucial tool for information extraction and natural language processing (Zhang et al., 2021a; Liu et al., 2023d), early EL studies utilized discriminative models, incorporating external datasets to enhance entity representation. Techniques included hyperlink counts in Deep-ed (Ganea and Hofmann, 2017) and Mulrel-nel (Le and Titov, 2018), NER classifiers in NER4EL (Tedeschi et al., 2021), and hierarchical constraints in CDHCN (Wang et al., 2023a). Other methods leveraged large-scale datasets (e.g., Wikipedia) to boost performance. Blink (Wu et al., 2020) trained bi-encoders on 5.9 million entities, incorporating titles and descriptions. EntQA (Zhang et al., 2021b) improved this with question-answering techniques, while ReFinED (Ayoola et al., 2022) fused priors, types, and descriptions using over 6 million entities. However, these methods depend on extensive data, limiting their ability to novel or domain-specific entities.\nGenerative models for EL have also emerged recently (Wang et al., 2023b). Genre (De Cao et al., 2021) generates predicted entities after the mention using a constrained decoder. Extend (Barba et al., 2022) extracts linking entities from context using candidates, while InsGen (Xiao et al., 2023) applies instruction-tuning on large language models (LLMs). Despite these advances, reliance on fine-tuning still restricts flexibility for few-shot adaptation across diverse scenarios.\nNotably, previous studies (Zhou et al., 2024; Xu et al., 2023b) claimed the suitability of their methods for few-shot and zero-shot learning, yet primar-"}, {"title": "3 Preliminary", "content": "3.1 Few-shot Entity Linking\nIn this paper, we formally define m as a mention in a text S, and e as an entity in a knowledge base (KB) associated with its description. For each mention m, we have a pre-processing step called entity candidate generation that chooses potential candidate entities 0 = {e1, C2, ..., en} from a specific KB. Each mention m also has a labeled link entity y. Following the few-shot setting (Xu et al., 2023c), the training set Dtrain = {(S,m, 0, y)} contains only a few examples and satisfies |Dtrain| < |Dtest|. Our goal is to learn the input (S,m, 0) to output y mapping with as little training data as possible.\n3.2 Entity Linking with LLMs\nAs illustrated in Figure 3, we form a query for LLMs as q = [m; S; 0], and the prompt P of entity linking can be composed as a task-specific instruction I, n CoT exemplars and the test query itself:\nP = [I; 91; Y1, ..., In; Yn; qtest], (1)\nwhere y = (e,r) is the output of LLMs, which contains a predicted entity e and the reasoning r. It is important to acknowledge that the difficulties outlined in Section 1 present substantial impediments to the entity linking process when a single Large Language Model (LLM) is employed. Therefore, we form a pipeline to complete the entity linking by adjusting instruction I and exemplars to"}, {"title": "4 Method", "content": "4.1 An Overview of One-Net\nAs shown in Figure 2, the proposed methodology comprises three distinct modules: (a) Entity Reduction Processor (ERP), (b) Dual-perspective Entity Linker (DEL), and (c) Entity Consensus Judger (ECJ). Initially, ERP conducts a two-step process that involves the summarizing of entity descriptions and the point-wise exclusion of irrelevant candidate entities. Subsequently, DEL is devised to establish fine-grained entity linking within the filtered candidates, utilizing both contextual analysis and prior knowledge. Finally, ECJ combines the contextual result and prior result to generate the predicted entity. Notably, each module is derived from a large language model, leveraging distinct prompts without fine-tuning.\n4.2 Entity Reduction Processor\nTo address the issue of token length limitations in Section 1, we employed the following optimization strategy. As illustrated in Figure 2, firstly, the Entity Representation Aggregator is utilized to condense the descriptions of entities, thereby providing a more succinct representation. Secondly, the Candidate Entity Filter is implemented to execute an initial, point-wise filtration of potential entities to reduce the number of candidates."}, {"title": "4.2.1 Entity Representation Summarizer", "content": "From previous research (Cheng et al., 2015), entity summarization can significantly enhance the efficiency of entity linking by distilling the essential characteristics of entity descriptions. In this context, we function as a summarizer by engaging a large language model through a simple prompt. The prompt Psum consists solely of a summary instruction prompt and an entity, which are structured as follows:\nPsum = [Isum; e], (2)\nwhere Isum is the summary instruction prompt, e is an entity with its description."}, {"title": "4.2.2 Candidate Entity Filter", "content": "In light of the suboptimal performance exhibited by directly list-wise EL, the Candidate Entity Filter transfers the list-wise EL into a sequence of pointwise EL, which only has one candidate in the query. This strategic conversion facilitates the effective filtration of irrelevant entities, which prompt Pfil is as follows:\nPfil = [Iel; m; S; ei], (3)\nwhere Iel is the instruction of entity linking, ei is one entity in the candidates. To improve efficiency, we don't use the Chain-of-Thought methods. Inspired by the insights of prior research (Honovich et al., 2022), we utilize LLMs to formulate instructions, which details are shown in Appendix C."}, {"title": "4.3 Dual-perspective Entity Linker", "content": "Building upon the established understanding from prior research (Ganea and Hofmann, 2017; Le and Titov, 2018), it is recognized that entity linking can be decomposed into two distinct components: a prior probability p(e) and a contextual probability p(cle). Accordingly, to maintain an equilibrium in the analytical process mentioned in Section 1, the Dual-perspective Entity Linker is composed of two components in Figure 2: the Contextual Entity Linker, which leverages the inference capabilities of LLMs to generate context-aware predictions, and the Prior Entity Linker, which employs the inherent knowledge embedded within LLMs to produce predictions based on prior information."}, {"title": "4.3.1 Contextual Entity Linker", "content": "To effectively harness the inferential capabilities of LLMs for list-wise entity linking, the Contextual Entity Linker employs a structured prompt as"}, {"title": "Algorithm 1 The Consistency Algorithm", "content": "Input: contextual prediction econtext, prior prediction eprior, mention m, context S\nOutput: link entity eresult\n1: if econtext = eprior then\n2: Cresult econtext\n3: else\n4: Cresult \u2190 LLM(econtext, eprior, m, S)\n5: end if\n6: return eresult\ndepicted in Figure 3. This prompt is composed of three distinct segments: the instruction prompt, the CoT prompts, and the question prompt, which is formed as:\nPcontext = [Iel; 91; Y1, ..., qn; Yn; qtest], (4)\nwhere Iel is the entity linking instruction mentioned in Section 4.2.2, [qi, Yi] is the CoT exemplar.\nCoT Exemplar Pool. Inspired by previous work (Liu et al., 2023b), in order to distill the reasoning power of the advanced models, we sample a subset of questions from the training dataset and present them to advanced models for response. To mitigate the issue of hallucination(Ji et al., 2023), we implement a stringent selection criterion, retaining only those responses that accurately predict the correct entity.\nAdaptive CoT Selector. To effectively determine the optimal CoT reasoning approach, our selection process is informed by two critical dimensions: context similarity and entity category. Firstly, we postulate that similar contexts likely share analogous reasoning patterns. To implement this, we quantify the resemblance by computing the cosine similarity between the input context and the exemplar contexts in our CoT pool. Secondly, we recognize that mentions belonging to the same category often exhibit common features that are pertinent to the reasoning process. To leverage this, we employ an LLM as a classifier, which incorporates a specific classifier instruction prompt along with the mention and its provided context. Ultimately, our composite CoT score is derived by integrating these considerations:\nS = a\u00b7cos(Si, Stest)+(1-a)\u00b7I(mi, Mtest),(5)\nwhere II(,) indicates whether the category is the same in both mentions and a is a hyperparameter."}, {"title": "4.3.2 Prior Entity Linker", "content": "To utilize the inherent prior knowledge in the LLMs, we employ an LLM as the Prior Entity Linker. As shown in figure 2, the prior prompt is comprised of three distinct components: the prior instruction prompt, the mention, and the filtered candidates, which can be represented as follows:\nPprior = [Iprior; m; 0 fil]. (6)\nIt is worth noting that the context is hidden to prevent the influence of noise in the context on the prior (Conover et al., 2018). Due to the lack of context, many of the hints about the context in the entity linking instructions are no longer appropriate, so we use instructions that are not the same as the contextual linker. Additionally, the imperative for preserving prior knowledge necessitates the exclusion of CoT methods to preclude the potential overwriting of LLM intrinsic knowledge (Wei et al., 2023)."}, {"title": "4.4 Entity Consensus Judger", "content": "To ensure accurate entity prediction from the two predicted entities in Section 4.3, the Entity Consensus Judger utilizes a consistency algorithm to mitigate potential hallucination in DEL, as illustrated in Figure 2. The algorithm functions as follows: when both prediction modules concur on the same entity, that entity is confirmed as the result. Conversely, in instances of prediction discordance, the ECJ invokes an auxiliary LLM to ascertain the correct entity for linking. The details of this algorithm are shown in Algorithm 1.\nThe propensity for inaccuracies within the Contextual Linker predominantly stems from misleading of CoT. Conversely, errors within the Prior Linker are principally attributed to the lack of context. To mitigate the occurrence of both error types, the auxiliary LLM has been designed to incorporate instruction prompt, context, and the entities ascertained by the dual linkers, which is formed as:\nPmerge = [Iel; m; S; econtext; eprior], (7)\nwhere Iel is the entity linking prompts as Section 4.2.2. Candidate entities are limited to the entities predicted by the previous linkers."}, {"title": "5 Experiments", "content": "5.1 Datasets\nFor the reliability and authority of experimental results, we have conducted evaluations across"}, {"title": "5.2 Implementation Details", "content": "For Wiki-based datasets, we implement our method on Zephyr-7b-beta (Tunstall et al., 2023) and GLM (Du et al., 2022). The exemplar pool, comprising 65 data instances, is derived from the training set of AIDA. We place n = 1 exemplar in the prompt P for the contextual entity linker. The adaptive CoT selector's hyper-parameter is set to a = 0.5. When running Zephyr, we fix the parameters to the default values provided by the official, and the max new token is set to 1024. For classifier, we use Wikipedia's 12 categories. To mitigate the potential bias arising from sequence dependency within the model, we randomize the order of candidate entities for each time. We take the first occurrence of the entity as the prediction. Following the previous work (Sevgili et al., 2022), we report the micro F1 to assess entity linking performance. For ZeShEL, we use the same setting as Wiki-based datasets, which is described in appendix B."}, {"title": "5.3 Benchmark Methods", "content": "To evaluate the effectiveness of One-Net, we compare it with traditional state-of-the-art supervised methods and popular large language models:\n\u2022 Traditional Supervised Methods. These models necessitate supervised learning. Specifically, Mulrel-nel (Le and Titov, 2018), NER4EL (Tedeschi et al., 2021), and CDHCN (Wang et al., 2023a) utilize leverage external data to train discriminative models. Conversely, Extend (Barba et al., 2022) employs a generative approach to extract the corresponding entity from the candidate entities. Our exemplar pool provides the foundational data required for the training.\n\u2022 Large Language Models. Since entity linking is a text-only task, LLMs can also be directly applied to it. For GLM (Du et al., 2022), We tested both 4K and 32K versions to confirm the effectiveness of long text training. For Zephyr (Tunstall et al., 2023), we use the same version to validate the effectiveness of our framework. For ChatGPT (Brown et al., 2020), we utilize the model gpt-3.5-turbo-1106 to test. During the generation of outputs, we adhered to the default settings provided by the official documentation. The same exemplars are provided to all LLMs to facilitate their chain-of-thought ability.\nAs we focus on the few-shot scenario, we disregard additional models which are trained on massive additional data, such as Blink (Wu et al., 2020), EntQA (Zhang et al., 2021b), and ReFinED (Ayoola et al., 2022), to ensure an equitable comparison. Additionally, we have omitted results from other popular language models like Llama2 (Touvron et al., 2023), as their performance is found to be suboptimal, which falls below 5%."}, {"title": "5.4 Experimental Results", "content": "The results of all methods on the datasets are shown in Table 2 and Table 7. For Wiki-based datasets, We report three OneNet results based on different base models. In general, OneNet with Zephyr has achieved the best performance compared with SOTA baselines. For ZeShEL, OneNet also achieves optimal results on most domains. Specifically, our method outperforms the best-performing baseline (i.e., Extend, ChatGPT) by 4%-11%. Additionally, we discover some interesting phenomena:\nFirst, traditional generative models, such as Extend, demonstrate superior performance over tra-"}, {"title": "5.5 Ablation Study", "content": "5.5.1 Accuracy and Efficiency of ERP\nTo validate the effectiveness of the ERP in Section 4.2, we show the recall, filtering rate, and average number of remaining candidate entities on all datasets, where filter rating shows the percentage of filtered-out candidates. In fact, as the first module of OneNet, ERP determines the performance ceiling of the entire pipeline. As shown in Table 3, recall reaches 0.8 for most datasets except ACE2004, and for filtering rate and Avg, the filtering rate reaches more than 0.8 on the unprocessed dataset, and the Avg is around 4. For the prepro-"}, {"title": "5.5.2 Context and Prior are Both Necessary", "content": "As we mentioned in Section 4.3, to substantiate the indispensability of both context and prior perspectives, a comparative analysis of the individual modules and their merged results is conducted. Figure 4 illustrates that merge results yield superior performance across all datasets, thereby affirming ECJ's efficacy. Nonetheless, it is noteworthy that the context and prior components each exhibit distinct advantages across varying datasets. For example, context outperforms 2% on AIDA, while prior is 2% higher on AQUAINT. This observation validates the rationale behind incorporating dual perspectives within the DEL module."}, {"title": "5.5.3 Detailed Instructions and Reasonable Exemplars make LLMs Aligned", "content": "Figure 3 elucidates that our prompt contains both detailed instructions and reasonable exemplars to"}, {"title": "5.6 Case Study of OneNet", "content": "For a more intuitive comparison of how our frameworks work, we provide two case studies, one utilizing contextual linking in Figure 5 while the other utilizing prior linking in Figure 8 in Appendix A.3.\nThe first mention is Sago, found in an article on mining safety. Initially, the Entity Reduction Processor screened out 6 irrelevant entities. For instance, Sago as a foodstuff and Mount Soga for its geographical inaccuracy. Subsequently, three pertinent entities remained: Sago Mine disaster, Sago, West Virginia, and California. Following the classification history and events, the contextual linker identified Sago Mine disaster as the likely reference, deducing that Sago Mine was implied within the text. Conversely, the prior linker suggested Sago, West Virginia, which considers Sago Mine disaster to be overly specific. Ultimately, the Entity Consensus Judger favored the contextual prediction Sago Mine disaster, corroborated by the text's detailed description of the event. This resolved an error in the prior linker by taking into account the context provided.\nfacilitate LLM's understanding of entity linking. The comparative results, as summarized in Figure 6, demonstrate that our adaptive CoT approach surpasses other CoT selection methods across all evaluated datasets, which underscores the efficacy of our method in identifying more suitable exemplars. Meanwhile, our findings indicate that the absence of detailed instructions hampers the LLM's ability to understand the EL task (e.g., No-Prompt, W/o Ins). Furthermore, our analysis reveals that prompts with CoT demonstrate superior performance in ACE2004 and AIDA. Conversely, prompts without CoT exhibit enhanced efficacy in AQUAINT. This result is consistent with Figure 4, as AIDA is more context-aware, AQUAINT is more prior-dependent and ACE2004 considers both. This further suggests that both reasoning ability and prior knowledge are important for EL.\nTo test the robustness of our module, we generate various instruction prompts for testing. The results, illustrated in Figure 7 in Appendix A, demonstrate that the module's performance remained stable despite variations in the prompts. Additionally,\nThe second entity mentioned is Orange County in an airport blog. The procedure mirrors that of the initial case. However, the term \"airport\" in the context notably causes the contextual linker's error. In contrast, the prior linker predominantly depends on the model's intrinsic knowledge to render an accurate prediction. Details are provided in Figure 8 in Appendix A.3."}, {"title": "6 Conclusion", "content": "In this study, we introduced OneNet, a novel framework for few-shot entity linking by leveraging large language model prompts without fine-tuning. Specifically, OneNet was comprised of three key LLM-prompted components: the Entity Reduction Processor, which was designed for efficient text condensation by summarizing entity descriptions and irrelevant entity filtering; the Dual-perspective Entity Linker, which considered both contextual information and prior knowledge to provide a balanced analysis; and the Entity Consensus Judger, which was instrumental in reducing hallucinations through a consistency merger algorithm. Our framework demonstrated superior performance on seven datasets. Our future research will aim to merge mention detection within our model."}, {"title": "7 Limitations", "content": "Although we have demonstrated the superiority of our OneNet compared to previous work on seven real-world datasets, there are still two limitations that should be addressed in the future:\n(1) Our framework relies on prompting LLMs, thus its efficiency is constrained by LLM inference speed. As shown in Table 4 in Appendix A, the runtime is heavily influenced by the base model. Table 5 Appendix A reports the average input tokens per module, showing that our framework does not substantially increase token requests compared to direct LLM use. Additionally, some modules (e.g., ERS) can run offline, which will enhance efficiency. Nonetheless, the field has witnessed significant advancements aimed at expediting the inference process for LLMs. These enhancements encompass strategies like I/O optimization (Dao et al., 2022), model pruning (Liu et al., 2023f), and quantization techniques (Dettmers et al., 2022),. It is our assertion that these ongoing research efforts will eventually surmount the current limitations imposed by the inference speed of large language models, thereby mitigating this bottleneck in the foreseeable future.\n(2) Currently, our framework is dedicated exclusively to the task of entity disambiguation. It is important to note that the broader domain of entity linking encompasses both entity disambiguation and mention detection. Actually, mention detection has been effectively approached using large language models (Jin et al., 2023) and prompting techniques (Shen et al., 2023), its integration is not"}, {"title": "A Experimental Supplement", "content": "A.1 Different Instruction Prompts\nDue to space constraints, Figure 7 mentioned in the main text have been moved to the appendix, which shows the performance of the contextual linker with different instruction prompts in Section 5.5.3\nA.2 Repeated Answers\nTo provide a more intuitive illustration of the robustness of our framework, we provide a case study of repeated responses. As shown in Table 6, although the expressions of the model outputs are different, none of the semantics of the results change, which demonstrates the stability of our framework."}, {"title": "A.3 Case Study for Prior", "content": "As we mention in Section 5.6, we also provide another case for prior linking in Figure 8. The entity mentioned is Orange County, which appears in an airport blog. Initially, the Entity Reduction"}, {"title": "A.4 Framework Efficiency", "content": "As mentioned in Limitation, we acknowledge that the execution efficiency of the framework is indeed influenced by the inference speed of the base model. In order to address this, we have conducted performance evaluations and execution time measurements of our framework on various base models including Zephyr and GLM. The EL results are shown in Table 2, while the running time analysis is illustrated in Table 4. The execution time is obtained by randomly sampling 100 tests on each dataset without any parallelization acceleration. Overall, while the GLM model shows slightly lower performance than Zephyr, its inference speed"}]}