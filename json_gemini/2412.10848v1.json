{"title": "Large Language Models for Medical Forecasting - Foresight 2", "authors": ["Zeljko Kraljevic", "Joshua Au Yeung", "Daniel Bean", "James Teo", "Richard J. Dobson"], "abstract": "Foresight 2 (FS2) is a large language model fine-tuned on hospital data for modelling patient timelines (GitHub 'removed for anon'). It can understand patients' clinical notes and predict SNOMED codes for a wide range of biomedical use cases, including diagnosis suggestions, risk forecasting, and procedure and medication recommendations. FS2 is trained on the free text portion of the MIMIC-III dataset, firstly through extracting biomedical concepts and then creating contextualised patient timelines, upon which the model is then fine-tuned. The results show significant improvement over the previous state-of-the-art for the next new biomedical concept prediction (P/R - 0.73/0.66 vs 0.52/0.32) and a similar improvement specifically for the next new disorder prediction (P/R - 0.69/0.62 vs 0.46/0.25). Finally, on the task of risk forecast, we compare our model to GPT-4-turbo (and a range of open-source biomedical LLMs) and show that FS2 performs significantly better on such tasks (P@5 - 0.90 vs 0.65). This highlights the need to incorporate hospital data into LLMs and shows that small models outperform much larger ones when fine-tuned on high-quality, specialised data.", "sections": [{"title": "1 Introduction and Related Work", "content": "Language plays a central role in healthcare and medical practice, with unstructured text constituting a significant portion of Electronic Health Records (EHRs, [Jackson et al., 2018]). Recent advancements in AI, particularly with Natural Language Processing (NLP) models, have begun to tap into this rich resource. Examples include Bio_ClinicalBERT [Alsentzer et al., 2019] and ClinicalT5 [Lehman et al., 2023], trained on real-world hospital data, demonstrating the feasibility and value of utilizing EHR's free text. Models such as GatorTron [Yang et al., 2022] further illustrate the application of NLP in processing EHR data from specific health systems, underscoring the adoption of NLP technologies in handling unstructured EHR text effectively. However, despite these advancements, a gap remains in applying and evaluating the latest generation of Large Language Models (LLMs) like GPT-4 [et al., 2023b], Gemini [et al., 2023a], LLaMA-2 [Touvron et al., 2023b], and Mistral [Jiang et al., 2023] in real-world clinical settings. While exceptions exist, many of these models are not primarily trained, tested, or validated on hospital-generated EHR data. Instead, they often rely on medical quizzes, exams, and other synthetic benchmarks for validation. This reliance potentially overlooks hospital data's complex nuances and contextual richness, which could inform more accurate and relevant clinical decision-making processes.\nToday's large language models have seen a remarkable evolution. Models like BERT [Devlin et al., 2019], ROBERTa [Liu et al., 2019], T5 [Raffel et al., 2023], GPT-1 [Radford and Narasimhan, 2018] and GPT-2 [Radford et al., 2019] set the stage. The BERT family notably changed natural language"}, {"title": "2 Methods", "content": "FS2 is a transformer-based model built on top of a pretrained LLM (LLaMAv2-7B and Mistralv0.1-7B) for temporal modelling of patient timelines. Formally, the task at hand can be defined as given a corpus of patients U = {41, 42, 43, ..} where each patient is defined as a sequence of tokens Ui = {W1, C2, W3, ...} and each token is either a biomedical concept (cm) or a text token (wn - context where the concept was found), our objective is a modified language modelling objective for supervised fine-tuning:\n\n\nL(U) = \\sum_{i} \\sum_{j \\in C_i} logP(c_j | k_1, k_2, ... k_{j-1})\n\nWhere k is either a biomedical concept c or a free text token w belonging to the timeline from the patient i, and C\u00b2 is the list of all concept token indices from the timeline of patient i (in other words C\u00b2 tells us the position of concept tokens in a patient timeline). In simpler terms, the model is not trained to predict text tokens but only biomedical concept tokens given the past (concepts and text). The output of the model is in no way limited, the patient timeline in the training set is known, in the same sense that during language modelling the next word in a sequence is known. During inference, the model can predict any concept token in the vocabulary."}, {"title": "2.1 Data Preparation", "content": "The dataset used in this work is MIMIC-III [Johnson et al., 2016]; we used all available free text from all clinical notes for patients (the whole note events table from the MIMIC-III database, without any filtering), totalling 2,083,179 documents from 46,520 patients.\nWe first perform entity recognition and linking using the Medical Concept Annotation Toolkit (MedCAT; Kraljevic et al. [2020]) on the collected free text. The model used was presented and validated in Kraljevic et al. [2020, 2023]; the model has an F1 score of above 0.9 across multiple hospital datasets for the NER+L task. Extracted entities include disorders, symptoms, findings and medications. Following extraction, these entities are chronologically organized into a timeline, reflecting their occurrence based on the document's creation date (The first part of Figure 1). An essential aspect of our methodology is the retention of contextual information for each extracted entity. For example, if an entity such as \"hypertension\" is identified, the term itself and the sentence in which it was found are preserved. This is crucial for two reasons: firstly, it allows us to capture qualifying information that could modify the understanding of the entity, such as severity (e.g., \"severe hypertension\"), and secondly, it enables the inclusion of negated or hypothetical concepts into the patient timeline (e.g., \"no hypertension\"). In instances where the boundaries of a sentence are ambiguous, we extract up to 50 tokens from each side of the entity, ensuring a comprehensive capture of context. In addition to contextual sentences, we also record the specific document ID for each concept and the absolute token IDs of words within the context. We establish a precise reference"}, {"title": "2.2 Modelling of Patient Timelines", "content": "FS2 is built on top of a pretrained LLM and fine-tuned for the modelling of patient timelines. We have two versions of FS2, FS2-Mistral - based on the Mistralv0.1 7B model, and FS2-LLaMA, based on the LLaMAv2-7B model. LLaMAv2-7B is a partially open-source model from Meta\u00b9 and one of the most widely used open-weight LLMs, and Mistralv0.1 7B is a general open-source model from Mistral.ai\u00b2 showing near state-of-the-art performance on a wide range of benchmarks. Both models are general LLMs, and not trained or fine-tuned for biomedical use cases. They also do not have an understanding of SNOMED codes (the patient timelines consist of free text and SNOMED codes). To enable the LLaMAv2-2/Mistralv0.1-7B model to handle SNOMED codes efficiently and effectively, we expand its tokenizer with the SNOMED concepts of interest (i.e. those SNOMED concepts that appear in our dataset). Usually, when adding new tokens to the tokenizer, we set the embeddings to be the average of all other tokens in the tokenizer. As the SNOMED codes are special, we have slightly changed this approach. Every token we add is an SNOMED code with a unique name, so we first tokenise that name and then average the embeddings of the tokens in the name and set this as the embedding of the new token (i.e. SNOMED code). With this, our model represents every SNOMED code as one token. We have also tested the standard approach where the embedding of a new token is set to be the average of all other tokens in the tokenizer, but this approach has made the training more unstable, and our loss has tended to diverge more often.\nTo fine-tune the model, we used 4xA100 80GB GPUs (the training took around 1 day in the case of both Mistralv0.1-7B and LLaMAv2-7B), the hyperparameters were as follows\u00b3: max_seq_len = 4096, learning_rate = 1e-5, gradient_accumulation_steps = 2, per_device_batch_size = 1, weight_decay = 0, warmup_ratio = 0.1, and the adamw_torch optimizer. We set the adam_beta1 = 0.9 and adam_beta2 = 0.95 to stabilise the model during training. To speed up training and enable efficient training with long sequences we use Flash Attention 2 with PyTorch FSDP, without quantization. Importantly, we have disabled loading the model in bfloat16 with the Huggingface library, as enabling this significantly reduces the performance of the model."}, {"title": "2.3 Metrics", "content": "The metrics used for the next concept prediction in the patient timeline are equivalent to those used in Kraljevic et al. [2023]. In summary, the performance of the models is measured using custom metrics that are an extension of the standard precision (TP / TP + FP) and recall (TP / TP + FN),"}, {"title": "2.4 Second Stage Fine-tuning for Risk Forecasting", "content": "We also create timelines for risk forecasting. We do this by taking a patient timeline, splitting it in the middle (or at most after 50 concepts) and taking the first part of the timeline as is, while for the second part, we extract unique new diseases that appear in the first month. So our task is, given a patient timeline (first part of it), to predict new disorders that will affect the patient in the first month of the subsequent patient timeline. We take only patients that, after the timeline split, have at least one month of data in the future and have at least 5 different disorder concepts appearing in that month. This reduces the dataset to 13,651 in the train set and 535 in the test set. The time frame of one month was chosen because it aligns with the healthcare system's needs in the UK, such as reducing 30-day readmission rates, a common metric for hospital performance.\nWhen fine-tuning FS2 on this data, all training parameters are kept the same as for the initial training. We run for 1 epoch - anything above this led to overfitting to the training set. We prepare the same timelines for testing with GPT-4-turbo, BioMistral, MedAlpaca and MEDITRON. The primary difference is that all SNOMED codes are replaced with proper names (e.g. 73211009 > Diabetes mellitus), the prompt used with GPT-4-turbo/BioMistral/MedAlpaca/MEDITRON is in Appendix A. This means that GPT-4-turbo and all other models excluding FS2 have disease names in their input. The output of all these models (excluding FS2) also includes disease names; none of these models ever see or predict SNOMED codes. The GPT-4-turbo model was used via Azure OpenAI services with the opt-out of human review of the data, in line with the instructions provided by Physionet for responsible use of MIMIC data with online services like GPT5. All other models were deployed locally.\nTo validate the risk predictions from all models (FS2, GPT-4-turbo, BioMistral, MedAlpaca, MED-ITRON) we made an automated validation pipeline via GPT-4-turbo (see Appendix A), the predictions (i.e. disease names) together with the ground truth or labels (i.e. disease names) were sent to GPT-4-turbo, and the task was to find how many of the predictions match the ground truth (GPT-4-turbo was also prompted to be a bit more tolerant and allow synonyms and similar diseases to be counted as correct). A clinician double-checked the GPT-4-turbo validation pipeline and confirmed that the comparison makes sense (i.e. GPT-4-turbo is correctly matching the predictions to the labels)."}, {"title": "3 Results", "content": "The primary task we tested the FS2 model on was predicting the next concepts in a patient timeline. In this task, the model (FS2-Mistral) showed a significant improvement over the FS1 model, including a jump of 40% (relative to the score of FS1) for the prediction of the next new concept (concept type 'All', the micro average of all concept types), and 50% (relative to the score of FS1) for the prediction of the next new disorder (Table 1). These results were achieved using the objective function shown in Section 2; if we modify this function to a standard language modelling objective (i.e. input_ids == labels) and train the model, the performance is slightly worse (overall 2-3% worse than that shown in Table 1). In addition, in Table 3, we show the top and bottom 10 concepts with respect to precision for the prediction of new Disorders (for the FS2-Mistral model).\nWe performed a simple ablation study to test the importance of the context in which a biomedical concept was found. If we remove the context from the patient timelines (i.e. leave only the biomedical concepts), the performance drops drastically (on average 40% compared to the FS2 results in Table 1)."}, {"title": "3.1 Risk Forecasting", "content": "GPT-4-turbo, BioMistral, MedAlpaca, MEDITRON and FS2 were tasked with predicting the top 5 disorders a patient is at risk of in the next month. The dataset consisted of 535 patients from the test set prepared for the risk prediction task. As seen in Table 2, out of the 5 predictions on the dataset of 535 patients using FS2-Mistral, in 90% of patients, at least one prediction was correct. The next best was GPT-4-turbo, where in 65% of patients (out of 472, the model refused to predict risk for all 535 patients), at least one prediction was correct. Additional results validating the reconstructed timelines are available in Appendix B."}, {"title": "4 Conclusion and Discussion", "content": "FS2 is built upon a pretrained LLM (LLaMAv2-7B and Mistralv0.1-7B) and fine-tuned on hospital data for modelling and understanding patient timelines. It can understand clinical notes and predict SNOMED codes for a wide range of biomedical use cases, including disorder prediction, medication recommendation, symptom forecast, procedure recommendation and many more. FS2 marks a significant advancement in the modelling of patient timelines over the previous state-of-the-art (FS1), enhancing the precision and effectiveness of LLMs for healthcare. FS2 builds on top of the work presented in [Kraljevic et al., 2023]. The primary differences are 1) The use of a pre-trained large language model as the base model (i.e. LLaMAv2-7B and Mistralv0.1-7B), enabling free text understanding; 2) The introduction of contextualised timelines; 3) The encoding of SNOMED codes in the tokenizer; and 4) The second stage fine-tuning for risk prediction;\nThere are four reasons why SNOMED codes were used: 1) Patient timeline standardisation [Searle et al., 2021] and a way to benchmark LLMs on hospital data. 2) It allows us to rank the predictions of the model based on probability. 3) It makes sure the model predictions are part of a standardised, widely accepted medical ontology, as opposed to having a model generate free text and then needing another step to map backwards into standardised forms for compatibility with existing healthcare informatics systems. 4) The model predictions are inherently privacy-preserving as the model was not directly trained on text; it can only output healthcare concepts within intentionally constrained healthcare vocabulary (SNOMED); it cannot predict any personally identifiable information, like names, addresses or other HIPAA-defined protected health information.\nIt is important to note the difficulty of the task, which in turn can explain why models that were not trained on hospital data like GPT-4-turbo/BioMistral/MedAlpaca/MEDITRON are performing significantly worse. Real-world EHR data is messy, noisy, extremely complex and filled with duplicated text. Within this noisy data, predicting the next event can prove to be a very difficult task with the added factors of patient complexity, multi-morbidity, polypharmacy and acute clinical instability of patients. Complications can develop as a result of their severe underlying disease or as an iatrogenic event secondary to procedures and medications."}, {"title": "4.1 Limitations and Risk", "content": "There are limitations to ontological classification systems such as SNOMED or ICD-10 - these systems may not cover all details and nuances within the clinical text. For example, there will be diseases or concepts that don't fall within the defined boundaries of available terminology or do not yet exist as formal concepts in codified terminologies (highly prevalent in fields with rapid scientific progress, e.g. cancer genetics and precision medicine). This challenge was, to some extent, addressed on the input side because FS2 is capable of understanding free text next to SNOMED concepts. The output side (i.e. predictions) will be explored in detail in future work.\nWe also note a limitation with respect to the NER+L tool that was used to extract SNOMED concepts from the free text. Currently, FS2 is using MedCAT, and while MedCAT has been shown to achieve an F1 score of above 0.9 across multiple hospitals and use cases [Kraljevic et al., 2020], it is still imperfect. Future work should look into improving the NER+L aspect of FS2 or find ways to make the model less dependent on the performance of the NER+L tool.\nAs this model is trained without human preference alignment, the prompts are more similar to GPT-3 rather than more recent LLMs (e.g. GPT-4). The prompts must reflect how the clinical notes are written, and the model cannot answer general questions or hold conversations. For example, in the notes, we often have the phrase \"The patient was discharged with: \" the model knows that after this it has to predict discharge medications. Q&A-style prompting popularised by ChatGPT, like \"What are the discharge medications for this patient?\" would not work without further human preference alignment.\nIt is also very important to note that while the results obtained are very good, these models are still in the early stages of research and testing and are not yet suitable to be Software as a Medical Device (SaMD). There is a temptation to imagine the predictions to be used for clinical care or decision support - this is still premature as FS2 is derived from historical practice, so it would not always be expected to be consistent with contemporary best practices.\nLastly, significantly larger hospital datasets and general medical literature are needed to better cover all possible biomedical concepts found in SNOMED and prevent biases or inaccuracies that can stem from using a single hospital as the training dataset."}, {"title": "4.2 Potential Utility", "content": "We note alerting systems as a use-case for which models like FS2 are well-suited. Table 3 shows there is a wide range of conditions with a precision of 100% and such conditions are particularly well suited in the context of designing alert systems. The high precision ensures that when an alert is issued, it is almost invariably relevant. Importantly, this high-precision approach minimises the clinician 'alert fatigue', a scenario that might arise if high recall was favoured over high precision.\nAnother utility of FS2 is for risk prediction and prognosis; this can be used to guide primary or secondary disease prevention or determine management courses. In medicine, there are countless validated risk and prognostic scores designed for disease-specific scenarios; e.g. QRISK [Hippisley-Cox et al., 2017] for stratification of cardiovascular disease, CHADSVASC [Lip et al., 2010] score for stroke risk, CURB65 [Lim, 2003] for pneumonia severity; these require large-scale calibration for generalisability and ongoing feature-engineering for more variables. Our approach with FS2 is more fine-grained and high-dimensional as it models temporally ordered sequences of comorbidities, and additional features (e.g. medications, social determinants of health, complications and outcomes) are included with limited a priori assumptions."}, {"title": "A Evaluation of other LLMs for risk prediction", "content": "GPT-4-turbo, BioMistral and other open-source models were validated automatically via GPT-4-turbo. For GPT-4-turbo predictions, we have also done a manual validation with a clinician to ensure the model was not biased in its answers and verify that the validation script works as expected. Manual verification showed that the GPT-4-turbo is a bit lenient, but it is accurate in concluding that diseases are a match or very similar. The prompt used is as follows: Please note that the labels are disease names (SNOMED codes were converted to their respective name), as well as predictions (the output of all models are disease names).\n<system prompts, these are appended as system messages to gpt-4-turbo>\nYou are now playing the role of a medical doctor taking an exam,\nyour goal is to be as accurate as possible and make sure you do\nnot make any mistakes. If you are unsure about something, think\nstep by step and then answer. You have to follow the instructions\nprecisely.\nYour first task is to compare how many of the predicted disorders\nmarked as 'Predictions: match the labels marked as 'Labels: in the input.\nPlease take care that predictions can contain\nsome additional text, but feel free to ignore it and only take the\npredicted disorders. Something is a match if it is\napproximately the same disorder (based on the definition of the\ndisorder). For example \u2018Diabetes' and 'T1DM'\nare a match, T1DM and T2DM are types of 'Diabetes', i.e. they\nare more specific. The reverse is also fine, T1DM is a match for Diabetes.\nThe output should be a json file formatted as follows:\n{'explanation': <your brief explanation>, 'number_of_direct_matches': <number>}\nprompt '''Labels: {labels}\nPredictions: {predictions}'''"}, {"title": "A.2 GPT-4-turbo", "content": "The following is the prompt used to get risk predictions from GPT-4-turbo.\n<system prompts, these are appended\nas system messages to gpt-4-turbo>\nYou are now playing the role of a medical doctor taking an exam,\nyour goal is to be as accurate as possible and make sure you do\nnot make any mistakes. If you are unsure about something, think\nstep by step and then answer. You have to follow the instructions\nprecisely.\nYour first question in this medical quiz will consist of a patient history,\nyour goal is to predict {limit} specific disorders the patient is at risk for in the next\nmonth. Please take care that the disorders you are predicting cannot be part of"}, {"title": "A.3 BioMistral", "content": "BioMistral is an open-source LLM tailored for the biomedical domain, utilizing Mistral-7B-v0.1 as its foundation model and further pre-trained on PubMed Central. BioMistral was benchmarked on 10 established medical question-answering (QA) tasks in English. The prompt we've used for risk prediction is aligned with the examples shown in the Biomistral paper and is as follows:\n<s>Please truthfully answer the\nfollowing question. Please ensure\nthat your choice is socially unbiased\nand positive. If you don't know the\nanswer to a question,\nplease don't share false information.\n<patient_history>\n{history}\n</patient_history>\nGiven the above patient history,\nwhat {limit} specific new\ndisorders is this patient at risk\nfor in the next month? The answer is:"}, {"title": "A.4 MedAlpaca", "content": "MedAlpaca expands upon both Stanford Alpaca and AlpacaLoRA to offer an advanced suite of large language models specifically fine-tuned for medical question-answering and dialogue applications. The prompt we've used for risk prediction is aligned with the examples shown in the MedAlpaca paper and is as follows:\nContext: {history}\nQuestion: Given the above patient\nhistory, what {limit} specific\nnew disorders is this patient at"}, {"title": "A.5 MEDITRON", "content": "MEDITRON is a suite of open-source LLMs with 7B and 70B parameters adapted to the medical domain. MEDITRON builds on Llama-2 (through our adaptation of Nvidia's Megatron-LM distributed trainer), and extends pretraining on a comprehensively curated medical corpus, including selected PubMed articles, abstracts, and internationally-recognized medical guidelines. In our tests we've only used to 7B version as that is comparable in size to all the other open-source models we've tested. The prompt we've used for risk prediction is aligned with the examples shown in the MEDITRON paper, and is as follows:\n<|im_start|>system\n{system}<|im_end|>\n<|im_start|>question\n{prompt}<|im_end|>\n<|im_start|>answer"}, {"title": "B Validation of Reconstructed timelines", "content": "To make sure the reconstructed timelines shown at the bottom of Figure 1 were not problematic for GPT-4-turbo, we also took the first 10 patients (from the test set for risk prediction of 535 patients) and fed the full patient history (complete clinical notes) until the timepoint T and prompted the model to predict risk in the next month (this was possible with GPT-4-turbo because of the large maximum sequence length, no other models could support this test). The results for these 10 patients were 10% worse (relative) in the case of full timelines compared to the reconstructed timelines."}, {"title": "C Additional Results", "content": "In table 3, we show the Top and bottom 10 concepts with respect to precision for the prediction of new disorders using the FS-2 Mistral model."}, {"title": "D Examples of tasks in the MIMIC-III dataset", "content": "To showcase the capabilities of the model, we manually go through the MIMIC-III notes and find examples of different tasks that the model had to solve during the prediction of the next concept in a sequence. The results are shown in Table 4, for the input (column Patient) we only show a brief summary of the patient's condition as we are not able to show real patient data. The Prompt column shows the prompt used for FS2, it is what really was found in the clinical note for this patient. For GPT-4-turbo the prompt was slightly adjusted to be more natural and concrete, for example, we pre-pended every prompt shown in the table with an explanation that this is a medical quiz, that the model should try to answer in a way a doctor would and that it should be as precise as possible. The Ground Truth comes from the patient's EHR and it represents what really happened to the patient."}]}