{"title": "Monitoring snow avalanches from SAR data\nwith deep learning", "authors": ["Filippo Maria Bianchi", "Jakob Grahn"], "abstract": "Snow avalanches present significant risks to human life and infrastructure, partic-\nularly in mountainous regions, making effective monitoring crucial. Traditional\nmonitoring methods, such as field observations, are limited by accessibility, weather\nconditions, and cost. Satellite-borne Synthetic Aperture Radar (SAR) data has\nbecome an important tool for large-scale avalanche detection, as it can capture\ndata in all weather conditions and across remote areas. However, traditional pro-\ncessing methods struggle with the complexity and variability of avalanches. This\nchapter reviews the application of deep learning for detecting and segmenting\nsnow avalanches from SAR data. Early efforts focused on the binary classification\nof SAR images, while recent advances have enabled pixel-level segmentation,\nproviding greater accuracy and spatial resolution. A case study using Sentinel-1\nSAR data demonstrates the effectiveness of deep learning models for avalanche\nsegmentation, achieving superior results over traditional methods. We also present\nan extension of this work, testing recent state-of-the-art segmentation architectures\non an expanded dataset of over 4,500 annotated SAR images. The best-performing\nmodel among those tested was applied for large-scale avalanche detection across\nthe whole of Norway, revealing important spatial and temporal patterns over several\nwinter seasons.", "sections": [{"title": "1 Introduction", "content": "Each year, snow avalanches claim more than 250 lives worldwide and cause significant damage\nto infrastructures, like roads, buildings, and ski areas [10, 32]. To mitigate this hazard, strategies\nsuch as constructing deflection barriers or triggering controlled avalanches with explosives are\ncommonly used. Although effective, these approaches are costly and can have negative impacts on\nthe environment [19]. Because of these drawbacks, reliable avalanche forecasting is considered one\nof the most practical and cost-effective ways to reduce both human and economic losses [11].\nPredicting avalanche danger involves assessing snowpack stability. Traditionally, this has been\ndone by digging snow pits and examining the snow structure directly in the field. While this gives\nvaluable insights, it is labor-intensive, time-consuming, and potentially dangerous - especially when\navalanche danger is high. Consequently, avalanche forecasters often rely on observations of recent\navalanche activity and weather patterns to understand snowpack conditions.\nHistorically, observations of avalanche activity were limited to manual field reports, leaving many\nregions unmonitored. However, advancements in satellite remote sensing have made large-scale\nmonitoring of avalanche activity feasible. In particular, space-borne synthetic aperture radar (SAR)\noffer detailed insights into avalanche debris over vast and remote regions, being agnostic to weather\nconditions or daylight. Despite some limitations, SAR provided a broader and more consistent\ntracking of avalanche activity, greatly improving our understanding of snowpack dynamics across\nentire mountain ranges [7]."}, {"title": "1.1 SAR - an (almost) ideal sensor for avalanche mapping", "content": "SAR is an active remote sensing technology that transmits coherent microwave pulses toward the\nEarth's surface and measures the backscattered signal. Since these pulses are coherent, their relative\nphase information can be used to achieve high spatial resolution typically down to just a few\nmeters. This enables SAR to detect detailed features such as avalanche debris. Additionally, because\nSAR generates its own signal, it can operate independently of daylight, making it particularly\nvaluable for monitoring avalanches, which often occur during poor visibility or limited daylight\nconditions. Most SARs operate at frequencies that are unaffected by atmospheric conditions,\nensuring consistent and reliable data even during challenging weather.\nFigure 1 shows several avalanches captured using two different satellites: Radarsat-2 and Sentinel-\n1. The bright areas represent high backscatter values, where avalanche debris clearly stands out\ncompared to the surrounding snow. The increased backscatter is primarily attributed to the higher\nsurface roughness and the compaction of snow within the debris.\nDespite having properties that are ideal for avalanche monitoring, there are some limitations to\nusing SAR for this purpose. Firstly, unless the frequency is relatively high (e.g. X-band or higher),\nmicrowaves are largely insensitive to dry, low-density snow. Under these conditions, avalanche\ndebris may appear almost transparent, making detection challenging [9]. This limitation means that\nSAR-based detections might be biased towards compact or wet snow avalanches, while some loose\nand dry snow avalanches could go unnoticed. The specific conditions under which this occurs are not\nyet well understood.\nSecondly, although SAR provides high spatial resolution, it can suffer from a relatively low temporal\nresolution, due to the time interval between image acquisitions. The interval depends on the satellite's\norbit and the number of satellites in the constellation. For instance, the Sentinel-1 constellation\nhas a 6-day repeat-pass cycle. If an avalanche occurs early in this interval, changing weather\nconditions such as precipitation, wind, or temperature fluctuations\u2014may alter the snowpack enough\nto make the debris difficult to detect by the next pass. However, in areas where multiple orbits overlap,\nthis time interval is significantly reduced. This overlap is more pronounced at higher latitudes, like"}, {"title": "1.2 The advent of Deep Learning in Remote Sensing for disaster management", "content": "The advent of deep learning, particularly Convolutional Neural Networks (CNNs), has transformed\nthe field of remote sensing by offering innovative approaches to analyzing complex and high-\ndimensional data. CNNs and other deep learning models have proven highly effective across various\nremote sensing tasks, such as land cover classification [1], change detection [28], and vegetation\nmonitoring [13]. These models excel at automatically extracting and learning relevant features from\nvast datasets, thanks to their capacity to handle large volumes of data and capture hierarchical spatial\nfeatures an essential capability for interpreting intricate patterns found in satellite imagery [14].\nA significant advantage of deep learning in remote sensing is its ability to generalize across different\ndatasets and sensor types. CNNs have been effectively adapted to handle diverse inputs, from\nhigh-resolution optical images to radar data, demonstrating remarkable flexibility in addressing\nvarious challenges across multiple domains [28]. This ability to simultaneously process both spectral\nand spatial information enables a more nuanced analysis of remote sensing data, far surpassing\nthe capabilities of conventional techniques. The adaptability of deep learning has paved the way\nfor integrating data from multiple sources, resulting in more robust and comprehensive disaster\nmonitoring systems [23].\nIn the context of disaster management and environmental monitoring, deep learning models have\ndemonstrated significant advancements over traditional methods, offering improved accuracy, speed,\nand automation in critical tasks such as flood detection [38], wildfire monitoring [34], and oil spill\ndetection [2]. These capabilities are particularly crucial for a near-real-time analysis of extensive\nsatellite data, enabling effective monitoring and timely responses to hazardous events such as snow\navalanches."}, {"title": "2 History of regional avalanche monitoring with SAR", "content": "Satellite-borne SAR has introduced a new way to monitor avalanches on a large scale, providing\ncoverage that ground-based methods could never achieve. However, this technology generates a vast\namount of data. In Norway, for example, avalanche-prone terrain extends over 1,750 km from south\nto north, and Sentinel-1 captures imagery at a 10-meter resolution, resulting in enormous datasets\nthat are impractical to analyze manually.\nMoreover, human interpretation can introduce inconsistencies and biases, as results often vary\ndepending on the analyst's experience and judgment. Automatic methods offer a more consistent and\nobjective approach, reducing biases and ensuring reliable results across large regions. Early methods\nfaced challenges in processing these datasets effectively, but advancements in machine learning and\ndeep learning greatly advanced the accuracy and efficiency in the analysis of SAR data."}, {"title": "2.1 Early methods", "content": "Early efforts to detect avalanches in SAR data relied on standard signal processing techniques,\nsuch as segmentation based on thresholding. Especially in dynamic and complex terrains, these\nmethods frequently failed to distinguish avalanche debris from other snow-covered surfaces with\nsimilar radar signatures due to the highly variable nature of snow, leading to numerous false alarms.\nThese methods were also sensitive to noise and the choice of thresholds, which rely on simplistic\nstatistical assumptions that cannot fully capture the complexity of avalanche events. Consequently,"}, {"title": "2.2 Binary Classification of Avalanches with Deep Learning", "content": "One of the earliest applications of deep learning for snow avalanche monitoring focused on binary\nclassification of SAR images, where CNNs were used to classify fixed-size patches of Sentinel-\n1 radar data into two categories: those containing at least one avalanche and those without any\navalanche [21, 16].\nIn particular, the study in [21] trained CNNs to detect avalanche features within patches of SAR\nimages. While the model achieved reasonable accuracy, the performance was highly dependent on\nthe size of the image patches used. Larger patches covered more area, making it easier to detect\nthe presence of at least one avalanche but often at the expense of spatial precision, as this approach\ntended to overestimate the affected areas. In contrast, smaller patches provided finer spatial resolution\nbut were more prone to missing avalanches, leading to higher false negative rates (see Figure 2).\nAlthough this patch-wise classification represented a step forward in leveraging deep learning\nfor avalanche detection, it had several notable limitations. The patch size heavily affected the\nmodel behavior: larger patches increased the likelihood of detecting avalanches but compromised\nspatial accuracy, while smaller patches improved resolution but introduced misclassification issues.\nAdditionally, the model was only capable of providing a binary outcome for each patch, which limited\nits ability to capture the presence of multiple avalanches within a single area. This lack of detailed\ninformation reduced the effectiveness of the model, particularly in complex terrains where multiple\navalanches could occur simultaneously."}, {"title": "2.3 Recent Advances: segmentation of SAR images with deep learning", "content": "Recent advancements in deep learning have led to significant improvements in the detection and\nmapping of avalanches from remote sensing data, particularly in the context of segmentation. Unlike\nearlier methods performing binary classification of image patches, modern approaches focus on\npixel-wise segmentation, which aims to classify each pixel in an image, thereby providing a more\nprecise delineation of avalanche boundaries and improving the spatial resolution of detection.\nDeep learning architectures such as U-Net [31] and its variants have emerged as powerful tools for\nsegmenting snow avalanches in remote sensing images, including SAR. These models are designed\nto perform dense prediction, enabling them to label each pixel in an image based on learned features\nthat represent avalanche characteristics such as texture, shape, and context [27]. Recent studies\nhave demonstrated that these models can effectively capture the complex patterns associated with\navalanche debris, even in challenging mountainous terrains [9].\nAdvanced deep learning models can incorporate contextual information, such as topographical\ndata and multi-temporal images, to improve the accuracy and reliability of segmentation outcomes.\nTechniques like multi-scale feature extraction, attention mechanisms, and data augmentation have\nfurther enhanced the robustness of these models against diverse snow and terrain conditions [26].\nOne notable development in this area is the application of hybrid models that combine SAR data\nwith other remote sensing modalities, such as optical images or LiDAR, to improve segmentation\nperformance [20]. These approaches leverage the complementary information within different data\ntypes to enhance the overall accuracy of avalanche detection and mapping.\nDespite these advances, several challenges remain in deploying deep learning models for SAR image\nsegmentation in operational avalanche monitoring. These include the scarcity of labeled data, the\nneed for models to generalize across different geographical regions and SAR sensor types, and the\ncomputational complexity associated with training and deploying deep learning models on large\ndatasets.\nThe seminal work presented in the paper \"Snow avalanche segmentation in SAR images with fully\nconvolutional neural networks\" by [3] represents a pivotal contribution to this evolving field. The\nstudy will be discussed in detail in the next section, highlighting the methodologies employed, the\nresults obtained, and the potential implications in avalanche monitoring. Then, to conclude the\nchapter, recent extensions of this work and future directions will be discussed."}, {"title": "3 Segmentation of snow avalanches with fully convolutional neural networks", "content": "We will now discuss the case study presented in [3], which explores the application of deep learning\nfor pixel-level segmentation of snow avalanches using Sentinel-1 SAR imagery. This has been one\nof the first works introducing a Fully Convolutional Network (FCN) for detecting avalanches at a\nfiner granularity compared to earlier methods that relied on patch-based classification. The proposed\nFCN incorporates novel input features, including the potential angle of reach (PAR), to improve\ndetection accuracy by integrating contextual and topographical information. The model was trained\non a large dataset of manually labeled SAR images and achieved an F1 score of 66%, significantly\noutperforming the existing state-of-the-art algorithm, which had an F1 score of 38%. The study\ndemonstrated that the proposed deep learning approach is effective in detecting most avalanches,\nincluding some that were overlooked during manual annotation, while only missing a few smaller\nevents.\nIn the next sections, we present the study in detail, covering the dataset construction, the deep learning\narchitecture, the experimental setup, and the obtained results."}, {"title": "3.1 Dataset construction", "content": "The dataset used in the study consists of 118 SAR images acquired from the Sentinel-1 satellites over\ntwo mountainous regions in Northern Norway during the period from October 2014 to April 2017.\nThe SAR data were captured in the interferometric wideswath (IW) mode and processed to create\nground range detected products. Each image was radiometrically calibrated to radar backscatter\n(sigma nought) values, downsampled from a resolution of 10 meters to 20 meters, and geocoded onto\na 20-meter resolution UTM grid using a digital elevation model (DEM) with 10-meter resolution. The\nresulting images were transformed to decibel (dB) values and clipped to a range between -25 and\n-5 dB to remove noise and clamp the backscatter values to intervals where avalanches are visible.\nThree primary SAR features were generated for use in the deep learning model: (1) the difference in\nhorizontal polarization (VV) between a reference and activity image, (2) the difference in vertical\npolarization (VH) between these images, and (3) the point-wise product of the squared differences of\nVV and VH (VVVH). These features were rescaled to the range [0, 1] to enhance the model's ability\nto detect avalanches (Fig. 3a-c).\nFor the labeling process, a human expert manually annotated each image to create a binary segmenta-\ntion mask, distinguishing avalanche from non-avalanche pixels. To identify changes indicative of\navalanche activity, the expert utilized a difference of two images acquired at different time steps.\nThe images were created from three channels (R [VV reference], G [VV activity], and B [VV refer-\nence]). In total, the dataset contained 6, 345 avalanches with approximately 712, 945 pixels labeled\nas \"avalanche\" and over 3.6 billion pixels labeled as \"non-avalanche\".\nTo further enhance the dataset, two topographical features derived from the DEM were included: the\nslope angle and the PAR (Fig. 3d,e). The slope angle, computed from the gradient of the DEM, is\na critical factor in avalanche detection as avalanches typically initiate on slopes between 35 - 45\ndegrees and deposit on gentler slopes. Figure 4 illustrates the distribution of the slope angle for"}, {"title": "Figure 5: Computation of the potential angle of reach (PAR) \u1fb6. \u03b8(x) denotes the angle between\nthe horizontal and the line drawn from a point in a release zone, denoted x, to the point of interest.\nSource: [3].", "content": "avalanche and non-avalanche pixels, showing that avalanche pixels are mainly concentrated around\nslopes of 20 - 35 degrees.\nThe PAR is a novel introduced feature that estimates the likelihood of an avalanche reaching a specific\nlocation, defined as the elevation angle between the furthest avalanche runout point and the highest\nrelease point. Figure 5 shows the computation of the PAR \u1fb6. Unlike traditional runout masks, which\nfilter areas where avalanches are unlikely, the PAR is used as an additional input feature to guide the\ndeep learning model's attention toward areas more likely to contain avalanches. Figure 6 illustrates\nthe distribution of the PAR for avalanche and non-avalanche pixels, hinting that this feature could\nhelp to separate the two classes."}, {"title": "3.2 Deep learning model: architecture and training", "content": "The deep learning model is based on a Fully Convolutional Network (FCN) architecture inspired\nby the U-Net model. The architecture consists of an encoder-decoder structure designed to perform\npixel-level segmentation in Sentinel-1 SAR imagery. The encoder extracts hierarchical features from"}, {"title": "3.3 Results and discussion", "content": "The trained FCN was evaluated on a test set consisting of a single SAR scene containing 99 avalanches,\nand its performance was benchmarked against the state-of-the-art algorithm at the time, based on\ntraditional signal processing techniques. The FCN achieved an F1 score of 66.6%, substantially\noutperforming the baseline algorithm, which obtained an F1 score of 38.1%. Additionally, the\nintersection over union score for the FCN was 54.3%, compared to 33.1% for the baseline. The FCN\ncorrectly detected 72 avalanches while missing 17. The missed avalanches were primarily small\nin size, which are typically more challenging to detect. Furthermore, the FCN produced 32 false\npositives, some of which were actual avalanches that had been overlooked during manual annotation\nby experts.\nFigure 9 presents examples of predictions made by the FCN on patches from the validation set. The\nfigure shows the input SAR channels (VVVH), slope feature, and PAR feature fed into the network,\nalong with the ground truth labels, the raw FCN output, and the thresholded binary output. The\npredictions demonstrate that the FCN effectively identifies avalanche regions with high accuracy\nwhile maintaining sharp boundaries around the detected areas, even for challenging cases with\noverlapping or clustered avalanches.\nFigure 10 provides a visual comparison between the manual annotations and the output of the FCN\noverlaid onto a change detection image. From left to right, the figure highlights: (i) areas where\nthe FCN detections match the manual annotations, (ii) avalanches missed by the FCN, (iii) false\ndetections produced by the FCN, and (iv) avalanches correctly detected by the FCN but not marked\nin the manual annotation. This visual analysis underscores the FCN's potential to detect avalanches\nthat were missed during manual annotation, suggesting that the model can capture subtle patterns in\nthe SAR data that may be overlooked by human experts.\nAn ablation study was conducted to assess the impact of different input features on the segmentation\nperformance. The study revealed that the inclusion of both VV and VH polarization differences,\nas well as the derived topographical features (slope and PAR), significantly contributed to the\nmodel's accuracy. Moreover, the attention mechanism based on the PAR feature provided further\nimprovements by helping the model focus on the most relevant areas.\nIn summary, the results showed that the proposed deep learning approach offers a substantial\nadvancement in snow avalanche detection from SAR images, reducing false positives and capturing\navalanches that are smaller and more challenging to detect. The integration of topographical features\nand an attention mechanism into the FCN framework enhanced its detection performance, highlighting\nthe potential for further improvements in operational avalanche monitoring systems."}, {"title": "4 Improvements and large-scale application", "content": "Recently, we extended the work presented in [3] by expanding the original dataset and training a\nwider range of state-of-the-art segmentation architectures and backbones. Furthermore, we used\none of the newly trained models to generate a large-scale segmentation of snow avalanches across\nthe entirety of Norway, covering the winter seasons from 2016 to 2021. The details of this work\nextension are discussed in the following."}, {"title": "4.1 Dataset extension", "content": "A high-quality, comprehensive dataset is crucial to train effective deep learning models. Therefore, to\nenhance the segmentation model's performance, we significantly expanded the original dataset. This\nextension allows for training models with higher capacity and improves the performance of previous\narchitectures.\nThe updated dataset consists of 4, 507 annotated SAR images, each covering approximately 3.6 \u00d7\n3.6km, collected over the winter seasons from 2016 to 2020, when both Sentinel-1 A and B satellites\nwere operational. The input data includes co-polarized backscatter images (VV and VH channels)\nfrom Sentinel-1, captured at two consecutive times from the same orbit, and detailed topographical\ninformation, such as slope angles derived from a high-resolution DEM. This expanded dataset\nprovides a broader and more diverse set of avalanches across different regions, encompassing a wider\nrange of snow conditions, terrain types, and temporal variations, which can enhance the model's\nability to generalize across different environments."}, {"title": "4.2 Evaluation of State-of-the-art segmentation models", "content": "In recent years, there have been significant advances in deep learning for computer vision, particularly\nwith the development of novel architectures such as Vision Transformers (ViT) [6]. These models\nhave shown considerable promise in many tasks across various domains. Given this progress, we\naimed to evaluate these new approaches in the context of avalanche segmentation, alongside more\nestablished convolutional models.\nThe newly extended dataset was used to train a wide range of state-of-the-art segmentation models\nin addition to the FCN presented in [3]. The goal was twofold: first, to identify if there was a more\nefficient and lightweight segmentation model that could achieve similar or superior performance.\nSecond, to explore the potential of new segmentation models based on ViT, which are more data-\nhungry.\nWe tested several well-known architectures, including the U-Net [31], Feature Pyramid Network\n(FPN) [22], Pyramid Scene Parsing Network [41], and DeepLabV3+ [4]. We equipped these architec-\ntures with various backbones, including ResNet [17], ResNeSt [40], Res2Ne(X)t [12], Xception [5],\nand DenseNet [18]. The backbones were initialized with pre-trained weights from ImageNet to\nleverage transfer learning. The models were implemented with Segmentation Models PyTorch, a\nframework for testing and benchmarking different architectures. In addition, we tested a modern U-\nNet variant adapted from those used in diffusion models [33]. For Transformer-based architectures, we\nexperimented with UnetFormer [36], SegFormer [39], and Dense Prediction Transformer (DPT) [30].\nFinally, we tested the DPT architecture, with various backbones, including Swin Transformer [24],\nConvNeXt [25], and ConvNeXtV2 [37].\nPerhaps surprisingly, the best-performing architecture in terms of detection performance and compu-\ntational complexity was the FPN with an Xception backbone. This result aligns with recent findings\nby [15], which suggest that, despite the recent popularity of ViT, traditional CNNs continue to achieve\nstate-of-the-art performance in many computer vision tasks, including image segmentation."}, {"title": "4.3 Large-scale detection of avalanches in Norway", "content": "The best-performing model, an FPN with Xception backbone, was used to detect avalanche debris\nacross the whole of Norway from Sentinel-1 SAR data from 2016 to 2020. The input data had a\nspatial resolution of 10 meters and a 6-day revisit time. To refine the results, filtering criteria were\nused based on segment area, elevation, and overlap with specific land use types and runout zones."}, {"title": "5 Conclusion and future work", "content": "Snow avalanches pose significant risks in mountainous regions, and effective monitoring is crucial for\npublic safety and disaster management. This chapter has provided an overview of the advancements\nin using deep learning for the detection and segmentation of snow avalanches from SAR data.\nTraditional methods for detecting avalanches, such as manual observations and threshold-based\nsignal processing techniques, have proven to be limited in their ability to handle the variability and\ncomplexity of SAR data. The application of deep learning has opened new possibilities for improving\navalanche monitoring. The case study by [3] demonstrated the potential of FCNs for pixel-wise\nsegmentation of avalanches in SAR images, significantly enhancing the detection performance over\ntraditional methods.\nFurthermore, by extending the original dataset and evaluating a wide range of state-of-the-art\nsegmentation models, including ViT, we identified that an FPN with an Xception backbone provides\na good tradeoff between performance and computational complexity. Our extended dataset, which\nincludes over 4,500 manually annotated SAR images and nearly half a million automated avalanche\ndetections across Norway from 2016 to 2020, serves as a valuable resource for training and testing\nadvanced deep-learning models.\nWe plan to leverage this extensive dataset, alongside historical meteorological data and weather\nforecasts, to predict avalanche activities using spatio-temporal deep learning models. This ongoing\neffort aims to integrate avalanche detection data with meteorological conditions to enhance forecast-\ning accuracy over large regions where traditional in-situ measurements are sparse or unavailable.\nOur ultimate goal is to improve real-time avalanche forecasting and provide better tools for risk\nmanagement in avalanche-prone areas."}]}