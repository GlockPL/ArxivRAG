{"title": "Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies", "authors": ["Mingkun Xu", "Huifeng Yin", "Yujie Wu", "Guoqi Li", "Faqiang Liu", "Jing Pei", "Shuai Zhong", "Lei Deng"], "abstract": "In recent years, spiking neural networks (SNNs) have attracted substantial interest due to their potential to replicate the energy-efficient and event-driven processing of biological neurons. Despite this, the application of SNNs in graph representation learning, particularly for non-Euclidean data, remains underexplored, and the influence of spiking dynamics on graph learning is not yet fully understood. This work seeks to address these gaps by examining the unique properties and benefits of spiking dynamics in enhancing graph representation learning. We propose a spike-based graph neural network model that incorporates spiking dynamics, enhanced by a novel spatial-temporal feature normalization (STFN) technique, to improve training efficiency and model stability. Our detailed analysis explores the impact of rate coding and temporal coding on SNN performance, offering new insights into their advantages for deep graph networks and addressing challenges such as the oversmoothing problem. Experimental results demonstrate that our SNN models can achieve competitive performance with state-of-the-art graph neural networks (GNNs) while considerably reducing computational costs, highlighting the potential of SNNs for efficient neuromorphic computing", "sections": [{"title": "1. Introduction", "content": "Spiking neural networks (SNNs) are brain-inspired computational models that replicate the spatio-temporal dynamics and rich coding schemes inherent in biological neural systems. These features make SNNs particularly adept at mimicking neuroscience-inspired models and performing efficient computations on neuromorphic hardware. SNNs have been successfully applied to a variety of tasks, including image classification, voice recognition, object tracking, and neuromorphic perception [1, 2, 3, 4, 5, 6]. However, most existing studies have focused on processing unstructured data in Euclidean space, such as images and language [7]. Meanwhile, biological spiking neurons, characterized by their complex coding schemes and dynamic properties, are foundational in creating cognitive maps in the hippocampal-entorhinal system. These maps are crucial for organizing and integrating spatial relationships and relational memory, facilitating advanced cognitive functions [8]. Thus, there is a strong motivation to explore effective algorithms for training SNNs that can integrate topological relationships and structural knowledge from graph-based data.\nIn recent years, there have been attempts to combine SNNs with graph-based scenarios, but these have primarily focused on applying graph theory to analyze spiking neuron characteristics and network topologies [9, 10, 11], or utilizing spiking neuron features to tackle simple graph-related problems such as shortest path, clustering, and minimal spanning tree problems [12, 13]. A recent study [14] introduced graph convolution to preprocess tactile data for SNN classification, achieving high performance in sensor data classification. However, this approach faces challenges in accommodating general graph operations and adapting to other scenarios. In addition, although some works have investigated the modelling of SNN and graph learning [15, 16, 17], they overlooked a more in-depth and systematic exploration of how spiking dynamics could impact and enhance graph representation learning. On the other hand, numerous graph"}, {"title": "2. Related Work", "content": null}, {"title": "2.1. Spiking Neural Networks", "content": "Over the past few years, Spiking Neural Networks (SNNs) have gained significant attention in the field of neuromorphic computing, which seeks to emulate the biological plausibility of the human brain. Unlike traditional Artificial Neural Networks (ANNs), SNNs are adept at processing sequential data. These networks mimic the behavior of biological neurons by incorporating synaptic and neuronal dynamics, utilizing binary spikes that are either 0 or 1. Among the various SNN models, the Leaky Integrate-and-Fire (LIF)[23] and Hodgkin-Huxley (HH)[24] models are notably prominent. Due to the high computational demand of the HH model, the LIF model is more commonly adopted, as it offers a practical compromise between accuracy and computational efficiency. The LIF model can be mathematically described as follows:\n$\\tau \\frac{du(t)}{dt} = -u(t) + I(t)$ \nIn this context, u(t) denotes the membrane potential of the neuron at a given time t, I(t) signifies the external input current, and $\\tau$ represents the membrane time constant, which influences the rate of potential decay.\nInspired by the complex and varied connectivity observed in the brain, spiking neural networks (SNNs) can be organized into various architectures. These include fully-connected networks[25], liquid state machines[26], spiking convolutional neural networks[27], and spiking Boltzmann machines[28], among others. Such diverse structures enable SNNs to efficiently and effectively process intricate, sparse, and noisy spatio-temporal information. Despite their potential, training SNNs poses significant challenges due to the non-differentiable nature of spike-based communication. Currently, there are three primary methods for training SNNs[1]: unsupervised learning (such as spike-timing-dependent plasticity (STDP)[1]), conversion learning (also known as the ANN-to-SNN conversion method), and supervised learning (which employs gradient descent to train multi-layer SNNs, achieving accuracy comparable to ANNs on complex datasets[1])."}, {"title": "2.2. Graph Neural Networks", "content": "Graphs are common data structures used to represent complex systems, consisting of vertices (nodes) that symbolize entities and edges that indicate relationships between these nodes. Depending on the nature of these relationships, graphs can be classified into several categories, such as directed or undirected, weighted or unweighted, and cyclic or acyclic. Graph Neural Networks (GNNs) are specialized models designed to work with graph data. They leverage both the features of the nodes and the graph's structural information to learn from complex graph datasets. GNNs can be applied to various tasks, including node-level tasks (predicting properties for individual nodes) and graph-level tasks (predicting a single property for the entire graph).\nThe architecture of Graph Neural Networks (GNNs) can be broadly classified into four categories: Convolutional Graph Neural Networks (GCNs)[29, 30], Graph Attention Networks (GATs)[31], Graph Autoencoders (GAEs)[32], and Spatial-Temporal Graph Neural Networks (STGNNs)[33]. GCNs are among the most widely used GNN models, employing convolution operations on graphs to aggregate information from neighboring nodes. These can be further divided into spectral versions, which operate in the spectral domain, and spatial versions, which work directly within the graph's node space. GATs utilize attention mechanisms to prioritize the influence of neighboring nodes, allowing the model to focus on the most relevant information during the learning process. GAEs are unsupervised learning models that use an encoder to project input graph data into a low-dimensional vector space and a decoder to reconstruct the graph or specific properties from this space. Finally, STGNNs are designed to manage graph data with both spatial and temporal aspects, making them particularly useful for"}, {"title": "2.3. Normalization", "content": "Normalization has been crucial in the training of deep learning models, enhancing training efficiency and mitigating issues like vanishing or exploding gradients and internal covariate shift. By scaling data with varying distributions to a consistent range, normalization also speeds up the model's convergence. A pivotal advancement in this area was Batch Normalization (BN)[20], introduced by Ioffe and Szegedy, which normalizes activations within a mini-batch during training, thus accelerating convergence. BN works by adjusting the output of each neuron by subtracting the batch mean and dividing by the batch standard deviation. Subsequent techniques like Layer Normalization (LN)[21] and Group Normalization (GN)[35] have emerged as effective regularizers, helping to reduce overfitting and enhance the generalization capabilities of models.\nIn graph neural networks (GNNs), adapting normalization techniques poses unique challenges due to the non-Euclidean nature of the data and the complex relationships between entities. Layer normalization, tailored for GNNs, helps stabilize training and enhance convergence[31]. Normalizing the adjacency matrix using the degree matrix, known as adjacency matrix normalization, is another crucial step that ensures scale-invariant information propagation[18]. Additionally, spectral normalization, which controls the Lipschitz constant of the network, has been applied to GNNs to prevent overfitting to specific graph structures or nodes[36]. To address the over-smoothing issue and simultaneously increase GNN depth, Zhou et al. introduced the NodeNorm"}, {"title": "3. Graph Spiking Neural Networks", "content": "We present our Graph SNN framework, focusing on the following four key aspects: (1) a method for integrating graph convolution operations into the spiking computing paradigm; (2) an iterative spiking message passing model, along with an overall training framework that consists of two phases; (3) a spatial-temporal feature normalization technique to facilitate convergence; and (4) implementations of specific spiking graph models."}, {"title": "3.1. Spiking Graph Convolution", "content": "Given an attributed graph $G = (V,E)$, where $V$ represents the set of nodes and $E$ represents the set of edges, the graph attributes are typically described by an adjacency matrix $A \\in \\mathbb{R}^{N\\times N}$ and a node feature matrix $X \\in \\mathbb{R}^{N\\times C} = [x_1; x_2;...; x_N]$. Here, each row $x_i$ of $X$ represents the feature vector of a node, and the adjacency matrix $A$ satisfies $A_{ii} = 0$, meaning there are no self-loops. If the signal of a single node is represented by a feature vector $x \\in \\mathbb{R}^C$, the spectral convolution is defined as the multiplication of a filter $F_\\theta = diag(\\theta)$ with the node signal $x$, expressed as:\n$F_\\theta * x = UF_\\theta U^T x,$\nwhere $F_\\theta$ is parameterized by $\\theta \\in \\mathbb{R}^C$, and $U$ is the eigenvector matrix of the Laplacian matrix $L = I \u2013 D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}} = U\\Lambda U^T$. Here, $U^Tx$ can be interpreted as the graph Fourier transform of the signal $x$, and the diagonal matrix $\\Lambda$, containing the eigenvalues, can be filtered using the function $F_\\theta(\\Lambda)$. However, due to the high computational cost associated with this approach, some methods have proposed using approximations and stacking multiple nonlinear layers to reduce the overhead, which has been successfully implemented in recent work[18].\nTo unify the flow of information within spiking dynamics, we convert the initial node signals $X$ into binary components ${X_0, X_1, ..., X_t, ..., X_{T-1}}$, where $T$ represents the length of the time window. The encoding process can be either probabilistic, following distributions such as Bernoulli or Poisson, or deterministic, involving methods like quantitative approximation or the use of an encoding layer to produce spikes[37]. This approach transforms the attributed graph from its original state into a spiking representation. We denote the spiking node embedding at time $t$ in the $n$-th layer as $H_i^{n,t}$, with $H_i^{0,t} = X_t$ (where the tilde indicates binary variables in spike form). The layer-wise spiking graph convolution in the spatial-temporal domain is then defined as:\n$H^{n,t} = \\Phi(G_c(A, H^{n-1,t})W_n, H^{n-1,t}),$\nIn this context, $G_c(A, H)$ represents the spiking feature propagation along the graph's topological structure, which can be implemented using various propagation methods, such as the Chebyshev filter or the first-order model. $\\Phi(\\cdot)$ denotes the non-linear dynamic process that depends on historical states $H^{n-1}_{i}$. The matrix $W_n \\in \\mathbb{R}^{C_{n-1}\\times C_n}$ is a layer-specific trainable weight parameter, where $C_n$ indicates the output dimension of the spiking features in the $n$-th layer, with $C_0 = C$ being the input feature dimension. This formula describes a single spiking graph convolution layer, and a"}, {"title": "3.2. Iterative Spiking Message Passing", "content": "We use the leaky integrate-and-fire (LIF) model as our fundamental neuron unit. This model is computationally efficient and widely used, while also preserving a certain degree of biological realism. The dynamics of the LIF neuron can be described by:\n$\\tau \\frac{dV(t)}{dt} = -(V(t) - V_{reset}) + I(t),$\nIn this model, V(t) represents the membrane potential of the neuron at time t. The parameter $\\tau$ is the time constant, and I(t) denotes the pre-synaptic input, which is the result of synaptic weights combined with the activities of pre-synaptic neurons or external stimuli. When V(t) exceeds a certain threshold $V_{th}$, the neuron generates a spike and the membrane potential is reset to $V_{reset}$. After emitting a spike, the neuron begins to accumulate membrane potential V(t) again in the following time steps.\nThe spiking message passing process comprises an information propagation step and an update step, both of which occur over T time steps. Let $H_i = [h_i^{0,t}; ...; h_i^{t}; ...; h_i^{T-1,t}] \\in \\mathbb{R}^{N\\times C}$ represent the node embeddings at time t, where each $h_i^t$ corresponds to the feature vector of node i. For a node v, we provide a general formulation for its spiking message passing as:\n$h_v^t = U(\\sum_{u\\in \\mathcal{N}(v)} P_\\theta(h_u^t, e_{vu}), h_v^{t-1}),$\nIn this context, $P_\\theta(\\cdot)$ denotes the spiking message aggregation from neighboring nodes, which can be implemented using various graph convolution operations, represented as $G_c(\\cdot)$. The function $U(\\cdot)$ signifies the state update, governed by a non-linear dynamic system. $\\mathcal{N}(v)$ represents the set of all neighbors of node v in the graph G, and $e_{vu}$ indicates the static edge connection between nodes v and u, which can be naturally extended to the formalism of directed multigraphs. Equation (3) provides a specific implementation of this general formulation.\nTo integrate the LIF model into the above framework, we employ the Euler method to convert the first-order differential equation in Eq. (4) into an iterative form. We"}, {"title": "3.3. Spatial-temporal Feature Normalization", "content": "Due to the inclusion of temporal dynamics and the event-driven nature of spiking binary representation, traditional normalization techniques cannot be directly applied to Spiking Neural Networks (SNNs). Additionally, the direct training of SNNs on graph tasks does not ensure convergence or optimal performance. This challenge has led us to propose a spatial-temporal feature normalization (STFN) algorithm specifically designed to address the spiking dynamics in graph-based scenarios.\nConsidering the feature map calculation step, let $S_t \\in \\mathbb{R}^{N\\times C}$ represent the instantaneous membrane potential output of all neurons in a layer at time step t. This can be expressed as $\\sum_j^{l(n)} W_{n,ij} G_c(A, \\hat{H}_i^{n-1,i})$ as shown in equation (7), or as $\\sum_j^{l(n)} w_{n,ij} \\hat{H}_i^{n-1,j}$ as shown in equation (9). In the STFN process, pre-synaptic inputs are normalized along the feature dimension C independently for each node. Given the importance of temporal effects in transforming node features within the topology space, normalization is also applied along the temporal dimension across consecutive time steps. Let $S_{k,v}^t$ denote the $k$th element in the feature vector of node $v$ at time $t$. The normalization of $S_{k,v}^t$ is performed as follows:\n$\\hat{S}_{k,v}^t = \\frac{S_{k,v}^t - \\rho V_{th}(S_{k,v}^t - E[S_v])}{\\sqrt{Var[S_v^2] + \\epsilon}}$,\n$\\gamma_{k,v} = \\lambda \\epsilon \\hat{S}_{k,v} + \\gamma_{k,v},$\nwhere $\\rho$ is a hyperparameter optimized during the training process, and $\\epsilon$ is a small constant to prevent division by zero. $\\lambda_{k,v}$ and $\\gamma_{k,v}$ are two trainable parameter vectors specific to node $v$. $E[S_v]$ and $Var[S_v]$ represent the mean and variance of the feature values of node $v$, respectively, computed across the feature and temporal dimensions.\n$E[S^v] = \\frac{1}{CT}\\sum_{t=0}^{T-1} \\sum_{k=0}^{C-1} S^t_{k,v},$\n$Var[S^v] = \\frac{1}{CT}\\sum_{t=0}^{T-1} \\sum_{k=0}^{C-1} (S^t_{k,v} \u2013 E[S_{k,v}^t])^2.$\nEquation (10) demonstrates the controlling effect of Spatio-Temporal Feature Normalization (STFN) for the differences in node features. Clearly, the normalized variance $\\hat{\\sigma}$ is constrained by the normalization configuration. In cases where $\\sigma$ is large ($\\sigma > 1$), it holds that $\\sigma^{(1- \\frac{\\rho}{p})} < \\sigma$. Therefore, STFN can reduce the variance of node features. Moreover, the smaller the value of $p$, the more significant the reduction effect, with the"}, {"title": "3.4. Graph SNNs Framework", "content": "Our framework comprises two phases: spiking message passing and readout. The spiking message passing phase, detailed in Section 2.2, involves iteratively passing messages for $T$ time steps during the inference process. After completing these iterations, the output spiking signals are decoded and transformed into high-level representations for downstream tasks. Under the rate coding condition, the readout phase involves computing the decoded feature vector for the entire graph using a readout function $R$, as described by the following formula:\n$\\hat{y} = R({x_i: x_i = \\frac{1}{T} \\sum_{t=0}^{T-1} h_i^t, \\forall v_i \\in G}).$\nThe readout function operates on the set of node states and must be invariant to permutations of these states to ensure that Graph SNNs are invariant to graph isomorphism. This means the function should produce the same output for isomorphic graphs, regardless of node order. The readout function can be implemented in various ways, such as using a differentiable function or a neural network that maps the node states to a final output, suitable for downstream tasks."}, {"title": "3.5. Coding Strategy", "content": "In addition to the rate encoding scenario discussed previously, this framework also supports various other temporal encoding schemes. One such scheme is Rank Order Coding (ROC), which this paper explores to highlight the interesting properties of our graph learning framework under different encoding conditions. This demonstrates the framework's compatibility and scalability with various encoding methods.\nRank Order Coding assumes that biological neurons encode information based on the order of firing within a neuron ensemble. Consider a target neuron i receiving input from a presynaptic neuron set $Q_n$ in the $n$-th layer, where each neuron fires only once, with its activation denoted as $H_j^n$. ROC records the relative firing order of these neurons and updates the activation of the target neuron $V_i^{n+1}$ as follows:\n$V_i^{n+1} = \\sum_{j\\in Q_n} \\rho^{\\text{order}(H_j^n)} W_{ij}^{n+1},$\nwhere $r \\in (0, 1)$ is a given penalty constant, and $\\text{order}(H_j^n)$ represents the firing order of neuron $j$ in the presynaptic ensemble. Equation (14) indicates that the sorting factor $r^{\\text{order}(H_j^n)}$ is crucial for Rank Order Coding, encouraging neurons to fire early while penalizing those firing later. As this encoding scheme emphasizes information in the early spikes, it is well-suited for promoting network sparsity and facilitating rapid decision-making [39]. This encoding scheme can be seamlessly integrated into the propagation process of the graph learning framework, influencing membrane potential updates and spike generation. At the decision layer, a winner-takes-all strategy is employed, directly outputting the feature corresponding to the neuron with the fastest spike, enabling rapid decoding within short time steps. The characteristics of Rank Order Coding are advantageous for swift recognition and inference in static graph tasks."}, {"title": "3.6. Model Instantiating: GC-SNN and GA-SNN", "content": "To illustrate the effectiveness of our framework and normalization technique, we implement the framework into specific models by incorporating commonly used propagation methods in GNNs, such as graph convolution aggregators and graph attention mechanisms[18, 19]. In this implementation, our Graph Convolution Spiking Neural"}, {"title": "3.7. Spatial-temporal Embedding for Downstream Tasks", "content": "We further specify node and graph classification tasks on multi-graph datasets to validate the effectiveness of our method. For different downstream tasks, we generate different level representations by using the output of the last GCN layer and provide a loss function for training the network parameters.\nNode classification task. Since the node features can be obtained directly from the GCN output, we directly input the node features into the MLP to obtain logits $y_{i, \\text{pred}} \\in \\mathbb{R}^{C}$ for each class[40]. The formula can be expressed as:\n$y_{i, \\text{pred}} = A \\cdot \\text{ReLU} \\left(W h_i^{n,t}\\right),$\nwhere $A \\in \\mathbb{R}^{d \\times C}$, $W \\in \\mathbb{R}^{d \\times d}$, and the $h_i^{n,t}$ represents the $i$th node's feature of the last GCN layer $n$ at the last time step $t$. To train the network parameters, we use cross entropy between logits and the ground truth labels as the loss function."}, {"title": "Graph classification task.", "content": "For graph classification tasks, we take the average of node features outputted by GCN to generate a representation of the entire graph $y_G$. The formula can be expressed as:\n$y_G = \\frac{1}{\\nu}\\sum_{i=0}^{\\nu} h_i^{n,t},$\nwhere $h_i^{n,t}$ represents the $i$th node's feature of the last GCN layer $n$ at the last time step $t$. Then the representation of the graph is inputted into an MLP to obtain logits $y_{pred}$[40].\n$Y_{\\text{pred}} = A \\cdot \\text{ReLU}\\left(W y_G\\right),$\nwhere $A \\in \\mathbb{R}^{d \\times C}$, $W \\in \\mathbb{R}^{d \\times d}$. Afterward, the cross-entropy between the logits and ground truth labels is used as the error for training."}, {"title": "4. Experiments", "content": "In this section, We firstly investigate the capability of our models over semi-supervised node classification on three citation datasets to examine their performance. Then we demonstrate the effectiveness of the proposed STFN and provide some analysis visualization for the model efficiency."}, {"title": "4.1. Datasets and Pre-processing", "content": "Basic experiments. We first use three standard citation network benchmark datasets\u2014Cora, Pubmed, and Citeseer, where nodes represent paper documents and edges are (undirected) citation links. We summarize the dataset statistics used in our experiments in Table 2. The datasets contain sparse bag-of-words feature vectors for each document and a list of citation links between documents. In Table 2, nodes represent paper documents and edges represent citation links. Label rate denotes the number of labels used for training, and features denote the dimension of feature vector for each node. The Cora dataset contains 2708 nodes, 5429 edges, 7 classes and 1433 features per node. The Pubmed dataset contains 19717 nodes, 44338 edges, 3 classes and 500 features per node. The Citeseer dataset contains 3327 nodes, 4732 edges, 6 classes and 3703 features per node. Each document node has a class label. We only use 20 labels per class during training with all feature vectors.\nWe model the citation links as (undirected) edges and construct a binary, symmetric adjacency matrix A. Note that node features correspond to elements of binary bag-of-words representation. Thus, We treat the binary representations as spike vectors, and re-organize them as an assembling sequence set w.r.t timing, where each component vector is considered equal at different time steps for simplicity. In this manner, we train our SNN modes with spike signals and evaluate them on 1000 test nodes, and we"}, {"title": "4.2. Performance Verification", "content": "Basic Performance. For fairness, we take the same settings for GNN models (GCN, GAT) and our SNN models (GC-SNN, GA-SNN), and also keep the settings of each dataset same. We report our results for 10 trials in Table 6. The results suggest that even if using binary spiking communication, our SNN models can achieve comparable performance with the SOTA results with a minor gap. It proves the feasibility and powerful capability of spiking mechanism and spatial-temporal dynamics, which can bind diversiform features from different nodes and work well on graph scenarios with few labels.\nTo more intuitively demonstrate the advantage of GC-SNN model compared with GCN model, we use t-SNE to visualize the final hidden layer features down to 2 dimensions. t-SNE is a nonlinear dimensionality reduction algorithm that can well reduce high-dimensional data to 2 dimensions for visualization. As shown in Figure 3, when the features obtained with the GC-SNN hidden layers, the samples within the same class are more concentrated and the inter-class spacing is larger and more separated.\nSpecifically, on the Cora, Citeseer, and Pubmed datasets, our SNN model demonstrated superior performance in distinguishing between different classes, thereby exhibiting stronger feature representation capabilities compared to GCN."}, {"title": "Extended Performance.", "content": "When conducting the extended dataset for node-level and graph-level tasks on multi-graph datasets, we used the same settings for the same models to ensure the fairness of the experiments. As shown in Table 6, our model demonstrates similar performance to other existing models, proving that GC-SNN can be adapted to different tasks with good performance."}, {"title": "4.3. Ablation Study for the Impact of STFN", "content": "To further validate the impact of STFN on SNNs in graph learning tasks, this study conducted systematic ablation experiments on the Cora, Citeseer, and Pubmed datasets. Figures 4(a)(b) depict the validation accuracy curves and loss convergence curves during the training process, respectively. The results reveal that STFN exhibits advantages in two main aspects: firstly, it enhances the generalization capability of SNNs, leading to higher recognition accuracy on test samples across all datasets; secondly, it significantly accelerates convergence. Compared to the baseline SNN model without STFN, the SNN with STFN achieves faster convergence on all three datasets, with substantially lower loss errors. These observations demonstrate that STFN facilitates faster convergence, alleviates overfitting, and significantly enhances performance in semi-supervised learning tasks for SNNs.\nTo investigate the influence of STFN on learned synaptic weights, we further visualizes the weight data distribution in Figure 4(c). The results indicate that STFN can concentrate the distribution of synaptic weights around the zero-value range. In this scenario, the normalized membrane potential state can coordinate distribution differences and pulse-triggering thresholds, resulting in sparser weights. This is advantageous for the deployment of neuromorphic hardware and the development of low-power graph computing applications."}, {"title": "4.4. Rate Coding versus Rank Order Coding", "content": "To investigate the performance differences under different encoding schemes, this study conducted comparative experiments between rate coding (RC) and rank-order coding (ROC). As shown in Figure 5, the performance gap of the Graph SNN under the two encodings is relatively small. For graph learning tasks, ROC achieves slightly lower accuracy than RC, but with significantly reduced inference time steps compared to RC. STFN further promotes the recognition accuracy under both encodings in the Citeseer and Pubmed datasets, while also reducing the inference time steps and training time cost for the ROC network (see Figure 5(b)(c)). This indicates that temporal encoding, at the expense of slight accuracy loss, enhances network inference speed and learning efficiency. Additionally, through firing rate analysis, this study found that ROC results"}, {"title": "4.5. Investigation into Oversmoothing Issue in Deeper Structure", "content": "The oversmoothing problem refers to the phenomenon in graph representation learning where the application of graph-based learning algorithms, such as GNNs, results in excessive smoothing of node representations, leading to a reduction in dissimilarity"}, {"title": "4.6. Efficiency Evaluation", "content": "In this section, we further evaluate the computational cost of the proposed spiking neural network for graph learning. As shown in Figure 10, it can be observed that the neural activity intensity of SNN in graph learning tasks is relatively low during the training process. Since the second layer's features are used for decoding and mapping decisions in this study, the neuron activity density is much higher than that of the first layer. For a two-layer network, the highest average firing rate does not exceed 23%"}, {"title": "5. Conclusion", "content": "In this study, we present a general SNN framework designed for graph-structured data, employing an iterative spiking message passing method. Introducing the Spatio-Temporal Feature Normalization (STFN) method, we merge graph propagation and spiking dynamics into a unified paradigm, reconciling them in a collaborative manner. Our framework is adaptable and applicable to various propagation operations and scenarios, exemplified through instantiation into two specific models: GC-SNN for graph convolution and GA-SNN for graph attention. Experimental results on three benchmark datasets showcase the effectiveness of the models and their robust representation capabilities. Notably, Graph SNNs exhibit high-efficiency advantages, making them well-suited for implementation on neuromorphic hardware and applications in graphic scenarios. Overall, this work contributes novel insights into the intersection of spiking dynamics and graph topology, enhancing our understanding of advanced cognitive intelligence."}]}