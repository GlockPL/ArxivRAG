{"title": "Type 1 Diabetes Management using GLIMMER: Glucose Level Indicator Model with Modified Error Rate", "authors": ["Saman Khamesian", "Asiful Arefeen", "Adela Grando", "Bithika Thompson", "Hassan Ghasemzadeh"], "abstract": "Managing Type 1 Diabetes (T1D) demands constant vigilance as individuals strive to regulate their blood glucose levels to avert the dangers of dysglycemia (hyperglycemia or hypoglycemia). Despite the advent of sophisticated technologies such as automated insulin delivery (AID) systems, achieving optimal glycemic control remains a formidable task. AID systems integrate continuous subcutaneous insulin infusion (CSII) and continuous glucose monitors (CGM) data, offering promise in reducing variability and increasing glucose time-in-range. However, these systems often fail to prevent dysglycemia, partly due to limitations in prediction algorithms that lack the precision to avert abnormal glucose events. This gap highlights the need for proactive behavioral adjustments. We address this need with GLIMMER, Glucose Level Indicator Model with Modified Error Rate, a machine learning approach for forecasting blood glucose levels. GLIMMER categorizes glucose values into normal and abnormal ranges and devises a novel custom loss function to prioritize accuracy in dysglycemic events where patient safety is critical. To evaluate the potential of GLIMMER for T1D management, we both use a publicly available dataset and collect new data involving 25 patients with T1D. In predicting next-hour glucose values, GLIMMER achieved a root mean square error (RMSE) of 23.97 (\u00b13.77) and a mean absolute error (MAE) of 15.83 (\u00b12.09) mg/dL. These results reflect a 23% improvement in RMSE and a 31% improvement in MAE compared to the best-reported error rates.", "sections": [{"title": "I. INTRODUCTION", "content": "TYPE 1 diabetes (T1D) is an autoimmune condition char- acterized by the destruction of insulin-producing beta cells in the pancreas, leading to a lifelong dependency on ex- ogenous insulin. Managing T1D is particularly challenging due to the need for continuous monitoring and precise insulin dos- ing to maintain blood glucose levels within a target range. Poor glucose control can lead to severe complications, including cardiovascular diseases, neuropathy, retinopathy, and kidney failure [1]\u2013[3]. Effective management is crucial for enhancing quality of life and reducing the long-term complications asso- ciated with T1D. It is estimated that around 8.4 million people worldwide have T1D, representing approximately 5-10% of all diabetes cases [4]. The prevalence of T1D varies signif- icantly across different populations and regions, highlighting the importance of tailored management strategies to address the unique needs of patients globally. Over the years, several advanced technologies have emerged to aid in managing T1D [4]. These technologies aim to improve glycemic control, reduce the risk of complications, and alleviate the daily burden of diabetes management on patients. Each of the following systems has distinct features and functionalities that contribute to more effective diabetes management, addressing different aspects of glucose monitoring and insulin delivery [1]\u2013[3]."}, {"title": "A. Type 1 Diabetes Management Technologies", "content": "1) Self-Monitoring of Blood Glucose: Self-monitoring of Blood Glucose (SMBG) is essential in managing T1D, allow- ing patients to regularly measure their blood glucose levels. This enables informed adjustments to diet, insulin therapy, and exercise, helping maintain optimal glucose control and prevent dysglycemia [5], [6]. However, SMBG provides only intermit- tent data, potentially missing significant glucose fluctuations. Additionally, excessive testing can lead to insulin stacking, increasing the risk of iatrogenic hypoglycemia. Proper patient education and adherence to monitoring schedules are crucial to maximize SMBG benefits while minimizing risks [7], [8].\n2) Continuous Glucose Monitoring: Continuous Glucose Monitoring (CGM) systems offer real-time, continuous data on glucose levels by measuring concentrations in the interstitial fluid, closely aligning with plasma glucose values [9]. These systems include a sensor, transmitter, and receiver, provid- ing frequent measurements that enhance glycemic control and enable timely interventions. Most FDA-approved CGM devices allow for non-adjunctive use, enabling therapeutic decisions without additional SMBG verification [10]. Despite their advantages, CGMs have a physiological delay of about 5- 6 minutes between blood and interstitial glucose, necessitating occasional SMBG confirmation during rapid glucose changes [11]. In addition, patients must take this delay into account when making decisions about dosing insulin.\n3) Hybrid Closed-loop Systems: Hybrid Closed-loop (HCL) systems integrate CGM data with automated insulin delivery, using algorithms to adjust insulin dosing in real-time based on continuous glucose readings [12]. This integration reduces the manual burden on patients and helps maintain glucose levels within the target range more effectively. Clinical trials have shown that HCL systems improve glycemic out-"}, {"title": "B. Limitations of Prior Research", "content": "Despite advancements in diabetes management technolo- gies, several limitations persist. AID systems often struggle to predict and react quickly to post-meal glucose spikes, delivering corrective boluses that are too slow or insufficient [20], [21]. While CGM systems provide real-time glucose data, they lack predictive features to warn users of impending dysglycemia [22]. Both AID and HCL systems, although integrating CGM and insulin pumps, still require manual in- puts for calibration and meals, limiting automation [13], [23]. SMBG, with intermittent testing, can miss critical glucose fluctuations, increasing the risk of undetected dysglycemia [6]. Additionally, the limited availability of clinical data and the high cost of collecting historical data for training create a cold- start issue for researchers."}, {"title": "C. Proposed Solution", "content": "To address these limitations, we propose GLIMMER (Glu- cose Level Indicator Model with Modified Error Rate), an innovative machine learning model for continuous blood glu- cose forecasting. GLIMMER uses CGM data, insulin dosages, and meal inputs as key features and significantly improves prediction accuracy through a custom loss function that applies higher penalties in dysglycemic regions, effectively reducing errors in these critical areas and lowering overall prediction penalty to forecasting outcomes that are closely representing abnormal glucose events. By predicting glucose trends in advance, GLIMMER enhances AID systems, enabling proac- tive self-management behaviors and insulin adjustments. This allows AID systems to modify insulin delivery before glucose levels reach dangerous thresholds, mitigating physiological delays in glucose sensing and insulin action. Additionally, it allows patients to react to the prediction outcomes and actively engage in appropriate dietary, exercise, and insulin injection behaviors to prevent abnormal blood glucose events. As a result, GLIMMER creates opportunities to improve glycemic control and reduce the risk of adverse events, enhancing the safety and effectiveness of AID systems. In addition"}, {"title": "II. RELATED WORK", "content": "Advancements in forecasting future glucose levels have been crucial for managing patients with T1D, enabling them to proactively respond to glucose fluctuations and significantly improving glucose control. Marigliano et al. [24] demon- strated that integrating predictive alarms with CGM tech- nology reduced hypoglycemic events in adolescents by 40% and severe hypoglycemia by 60%, highlighting the tangible benefits of predictive alerts in real-world settings. Vettoretti et al. [25] further supported these findings by showcasing how artificial intelligence-based diabetes management systems can enhance patient outcomes through early glucose predic- tions, prompting timely interventions such as insulin dose adjustments or dietary changes to maintain stable glucose levels and mitigate risks like cardiovascular disease and nerve damage. Additionally, Shroff et al. [26] emphasized the shift from reactive to proactive diabetes care with personalized prediction systems that learn individual response patterns, offering tailored alerts to meet each patient's unique physi- ological needs. These predictive technologies not only set a new standard in diabetes care by focusing on prevention over treatment but also significantly reduce the daily management burden. Arefeen et al. [27] suggest that machine learning algorithms can effectively predict hyperglycemia events using data from controlled feeding trials. In the following sections, we categorize these algorithms based on their architecture and discuss their approaches to predicting abnormal glucose levels, providing early warnings for timely interventions."}, {"title": "A. Evidential Deep Learning and Meta-Learning", "content": "Machine learning techniques, particularly deep learning algorithms, have achieved reliable glucose-level prediction performance with minimal feature engineering required. Zhu et al. [28] demonstrated the use of evidential deep learning combined with meta-learning to create a model that adapts to individual patient data. This approach significantly enhances prediction accuracy by considering the uncertainty in predic- tions and personalizing the model to each patient's unique glucose response patterns. This method's strength lies in its ability to provide precise predictions with fewer input features, simplifying the data collection process for patients."}, {"title": "B. Convolutional Recurrent Neural Networks", "content": "Another innovative approach is the use of Convolutional Recurrent Neural Networks (CRNN) [29] to estimate glucose levels for up to a 60-minute prediction horizon (PH) based on prior CGM data and information on meal and insulin intakes. Li et al. [30] introduced this model, which combines the feature extraction capabilities of convolutional neural networks (CNN) [31] with the temporal learning capabilities of recurrent neural networks (RNN) [32]. The CRNN model demonstrated superior performance in both simulated and real patient data, providing accurate short-term glucose predictions that are essential for proactive diabetes management."}, {"title": "C. Long Short-Term Memory Networks", "content": "Long Short-Term Memory (LSTM) [33] units have also been employed by Aliberti et al. [34] to predict glucose levels. In this study, they developed a predictive model for blood glucose levels using a multi-patient dataset, focusing on leveraging the strengths of LSTM networks. The researchers compared the performance of LSTM networks with other models like Non-Linear Autoregressive (NAR) neural net- works [35] and found that the LSTM model significantly outperformed others in both short- and long-term predictions. The LSTM model demonstrated superior accuracy due to its ability to handle long-term dependencies and mitigate issues like the vanishing gradient problem that commonly affects traditional RNNs. This study's findings underscore the potential of LSTM networks in enhancing predictive accuracy and clinical outcomes for diabetes management."}, {"title": "D. Bi-Directional LSTM Variants", "content": "Further extending the capabilities of LSTM networks, re- searchers have explored bi-directional LSTM variants for glu- cose prediction [36]. Butt et al. [37] investigated how feature transformation techniques could enhance the efficiency of blood glucose prediction models. By employing bi-directional LSTM units, the model can consider both past and future data points, providing a more comprehensive understanding of glucose trends and improving prediction accuracy."}, {"title": "E. Linear Regression", "content": "The Tandem t:slim X2 with Control-IQ technology employs simple linear regression to forecast blood glucose levels 30 minutes ahead based on previous CGM data, highlighting the importance of understanding these algorithms and their accu- racy. To address the challenges of applying linear regression to time-series data and multi-step predictions, Zhang et al. [38] developed a multiple linear regression (MLR) model that predicts each future time step separately. This MLR approach combines k individual linear regression models, denoted as $L_i$, each trained to relate the training data $X_{train}$ to the CGM values at future time points $Y_{train}(t + i)$ for $i = 1$ to k. For instance, setting k = 6 or 12 corresponds to predicting 30 or 60 minutes into the future, respectively, as illustrated in Fig. 2. During the prediction phase, the trained models utilize their respective coefficients and intercepts to forecast glucose levels for the next k time steps by applying the models to the testing data one time step prior to the first test point. This iterative process is repeated for each row of the testing matrix, enabling the generation of multi-horizon predictions. Despite the inherent difficulties of using linear regression for time- series forecasting, the structured MLR approach enhances the accuracy of glucose level predictions at various future points, thereby improving the reliability of automated insulin delivery systems. Additionally, this method allows for scalability and adaptability in different clinical settings, making it a valuable tool in the ongoing efforts to optimize diabetes management."}, {"title": "III. METHODOLOGY", "content": "While many machine learning algorithms are used for event forecasting, CNN-LSTM models excel in continuous multi-modal data by integrating spatially distributed data and capturing time-series patterns. These models are commonly applied in areas such as stock price forecasting, household load prediction, and wind power estimation [39]\u2013[41]. Recent studies, including Jaloli and Cescon (2023) [42], have demon- strated that a CNN-LSTM model achieved a lower RMSE for glucose level predictions over a longer forecast horizon compared to other methods.\nThe decision to use a CNN-LSTM model for GLIMMER is rooted in its hybrid architecture, which combines the strengths of CNNs and LSTMs [31], [33]. The CNN component excels at automatic feature extraction, capturing spatial relationships within the data, while the LSTM component is adept at learning temporal sequences and long-term dependencies. This combination allows the CNN-LSTM model to effectively extract hidden features and correlations among various physi- ological variables, making it well-suited for forecasting future blood glucose values.\nIn comparative analyses, the CNN-LSTM model demon- strated superior performance over LSTM, CRNN, and other models, both in terms of predictive accuracy and clinical ac- ceptability [42]. This improved performance is attributed to the model's sophisticated architecture, which includes stacks of convolutional and LSTM layers capable of learning complex, hidden features in multivariate datasets. The model's ability to capture rapid and abrupt changes in continuous glucose monitoring trends, due to its capacity to learn intricate dynam- ics and correlations between variables, further underscores its suitability for this task. However, it is important to note that the effectiveness of the CNN-LSTM model is contingent on the availability of a sufficiently large dataset, which also increases the computational cost compared to simpler reference models. To address the common issue of overfitting in LSTM networks, we incorporate dropout layers after each convolutional or LSTM layer, which has proven effective in enhancing model robustness [43]."}, {"title": "B. Custom Loss Function", "content": "Glucose values can be categorized into normal and critical regions, with the latter including hyperglycemia and hypo- glycemia thresholds. For patients with T1D, incorrect predic- tions in these critical regions can be particularly dangerous, resulting in missed intervention opportunities and potentially severe health complications. Despite extensive prior research on predicting glucose levels, a recent review by Woldaregay et al. [44] highlights a significant gap in the field. There is a noticeable lack of comprehensive analysis and modeling concerning the penalties for prediction errors across various dysglycemic regions. Therefore, we propose to penalize the prediction model for errors that occur in critical regions more heavily than those in normal regions. Assuming two thresh- olds $T_{hypo}$ and $T_{hyper}$ representing hypoglycemic threshold and hyperglycemia thresholds, respectively, we classify the blood glucose data $x$ into three regions: 1 (hypoglycemia) for values below $T_{hypo}$, 2 (normal) for values between $T_{hypo}$ and $T_{hyper}$, and 3 (hyperglycemia) for values above $T_{hyper}$. Commonly, insulin delivery devices and research articles set these thresholds to 70 mg/dL for hypoglycemia and 180 mg/dL for hyperglycemia [17]. Although these values may vary slightly from person to person, we use the general values commonly cited in similar studies [24], [25], leaving the in- depth analysis to determine optimal thresholds for each patient for future research."}, {"title": "C. Error Weights", "content": "We classify the CGM values according to the threshold values discussed previously to identify the respective regions. Our next step is to finalize the custom loss function by determining the optimal weight parameters for each region, with a primary focus on dysglycemia areas. For this reason and to simplify the optimization problem, we set $w_{normal}$ to 1, reducing our optimization task to finding the optimal values for $w_{hypo}$ and $w_{hyper}$.\nTo obtain optimal values of $w_{hypo}$ and $w_{hyper}$, we pro- pose to use Genetic Algorithms (GA) [45]. We chose this technique for several reasons. First, GAs are effective for optimization problems where the fitness function involves running another algorithm, particularly for complex or poorly defined problems. This is exactly the case in the problem at hand, finding the optimal weight values of $w_{hypo}$ and $w_{hyper}$ using the fitness function with the overall prediction error as output while also running a machine learning algorithm. Second, GAs do not need derivatives or extra information during the optimization process; they obtain the fitness score directly from the objective function [45]\u2013[47]. Finally, it is straightforward to implement GAs, especially since we are also working on predicting CGM values with a CNN-LSTM network. Based on these considerations, we define our genetic algorithm's terminologies as follows:\n\u2022 Genome or Gene: A real number between [1, 10] representing a weight.\n\u2022 Chromosome or Individual Solution: A pair of weights ($w_{hypo}$, $w_{hyper}$).\n\u2022 Population: A pool of chromosomes of the size of N, each representing a candidate solution.\n\u2022 Crossover: In each generation, crossover is performed by averaging the values of two randomly selected parents to create a new child chromosome.\n\u2022 Mutation: The child chromosome undergoes mutation, where a small random perturbation is added to its values. This ensures diversity in the population.\n\u2022 Selection: The best individuals from the current popula- tion are combined with the new offspring to form the next generation, preserving strong solutions while introducing variations.\n\u2022 Fitness Function: The fitness function evaluates how well each chromosome performs by calculating the total error using the custom loss function. The fitness score is simply the value of this total error; lower fitness scores indicate better solutions. In each generation, the best scores are recorded, and the individuals with the lowest fitness scores are selected as the best individuals.\nBy iterating through multiple generations, the genetic algo- rithm refines the weight parameters, aiming to find the pair ($w_{hypo}$, $w_{hyper}$) that minimizes the error in critical regions. This process balances the need for generalization across all patients to optimize performance in dysglycemic regions. Algorithm 1 provides a high-level pseudo-code overview of the genetic algorithm process proposed to identify the best pair of weights."}, {"title": "IV. EVALUATION APPROACH", "content": "1) OhioT1DM Dataset: We utilized the OhioT1DM dataset [48], which includes data from 12 individuals with T1D. The dataset contains raw glucose values recorded every 5 minutes, along with basal insulin, bolus insulin, and carbohydrate intake over an 8-week period.\n2) AZTID Dataset: In addition to using the OhioT1DM dataset, we also gathered data from 25 patients with T1D on AID systems who visited the endocrinology clinic at the Mayo Clinic in Scottsdale, AZ, between December 2023 and April 2024 for their regular appointments. Informed consents"}, {"title": "F. Evaluation Metrics", "content": "To assess the performance of the GLIMMER model, we employed standard metrics commonly used in related studies [28], [30], [34], [37], including:\n1) Root Mean Square Error (RMSE): This metric provides insight into the average deviation of predicted values from actual values, with an emphasis on larger errors:\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}$\nHere, n represents the number of data points, $y_i$ denotes the ground truth or actual CGM value, and $\\hat{y_i}$ is the predicted CGM value.\n2) Mean Absolute Error (MAE): This metric quantifies the average absolute difference between predicted and observed values, providing a straightforward interpretation of prediction accuracy. It is calculated as follows:\n$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}|$\n3) Precision: This metric indicates the accuracy of the positive predictions made by the model, defined as the ratio of true positives (TP) to the sum of true positives and false positives (FP). It is calculated as:\n$Precision = \\frac{TP}{TP+FP}$\n4) Recall: This metric reflects the model's ability to iden- tify all relevant instances, representing the true positive rate. It is the ratio of true positives to the sum of true positives and false negatives (FN):\n$Recall = \\frac{TP}{TP + FN}$\n5) F1 Score: The F1 score provides a balance between precision and recall, especially useful when dealing with imbalanced classes. It is calculated as:\n$F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$"}, {"title": "6) Clarke Error Grid Analysis", "content": "The Clarke Error Grid (CEG) analysis [54] is a widely accepted tool for evaluating the clinical accuracy of glucose predictions by comparing them to reference glucose values. It classifies predictions into five distinct regions, each representing varying levels of clinical significance:\n\u2022 Region A: Includes values within 20% of the reference value, indicating clinically accurate predictions.\n\u2022 Region B: Contains values outside of the 20% range but unlikely to result in inappropriate treatment.\n\u2022 Region C: Identifies predictions that may lead to unnec- essary treatment.\n\u2022 Region D: Represents predictions where critical hypo- glycemia or hyperglycemia might be missed, posing a potential danger.\n\u2022 Region E: Captures predictions that could lead to confu- sion between treating hypoglycemia and hyperglycemia, a highly dangerous scenario."}, {"title": "V. RESULTS", "content": "Tables II and III summarize the performance comparison of GLIMMER with other methods for the OhioT1DM and AZT1D datasets, both using a PH of 60 minutes. We selected the most recent studies that employed a variety of classical and machine learning models, including Fast-Adaptive and Confident Neural Network (FCNN) [28], CRNN [30], Bi- LSTM [36], transformer models [55], Random Forest Regres- sion (RFR) [28], [56], Support Vector Regression (SVR) [57], and Autoregressive Integrated Moving Average (ARIMA) [58]. Additionally, we included the GLIMMER model without modifications, represented as a basic CNN-LSTM, to highlight the effects of our enhancements, which incorporate two crafted features and a custom loss function.\nThe results include RMSE and MAE, presented as (Mean + Standard Deviation), along with CEG reports, which serve as standard error metrics for predictions. For both RMSE and MAE, lower values indicate better performance. As shown in Table II, GLIMMER demonstrates outstanding performance compared to other models, achieving a 23% improvement in RMSE and a 31% improvement in MAE relative to the best- reported errors. The basic CNN-LSTM results further indicate its potential as a viable candidate for analyses where other models may not be applicable. In the CEG analysis, higher values in Region A are preferable, while lower values are desirable in other regions. Notably, GLIMMER's predictions achieve 85% within Region A, yielding a 15% improvement compared to FCNN, and it also maintains one of the lowest values in other regions.\nTable III presents the results for GLIMMER, and the basic CNN-LSTM model applied to the AZT1D dataset. GLIMMER again outperforms the basic CNN-LSTM model, achieving a 24% improvement in RMSE and a 28% improvement in MAE. Since this dataset has been recently collected and is not publicly available, we could only generate results for these two models, leaving evaluations for other methods to future researchers. However, given the close results in Table II for the basic CNN-LSTM and leading models like FCNN and CRNN, we anticipate similar outcomes.\nTo ensure a fair comparison, we did not include the MLR model in Table II, as this model employs a multi-model approach that requires training a separate model for each PH. In our case, with a PH of 60 minutes, this necessitates the creation of 12 individual models to predict the next 5, 10, 15, 55, and 60 minutes. In contrast, all the methods presented in Table II utilize a single model for their predictions, and the MLR model did not report CEG analysis in their studies. While they achieved an RMSE of 24.58 mg/dL and an MAE of 17.42, which are better than those of some other models, GLIMMER still outperformed them.\nWe visualized the results of the CEG analysis for both the OhioT1DM and AZTID datasets in Fig. 8. The enhanced prediction accuracy of the GLIMMER model compared to the basic CNN-LSTM is evident, demonstrating its ability to accurately forecast blood glucose levels even in critical regions, which is crucial for clinical analysis and real-world applications. Additionally, Fig. 9 illustrates the glucose level predictions of GLIMMER compared to the basic CNN-LSTM. This figure highlights GLIMMER's ability to accurately pre- dict blood glucose levels, particularly during peaks, due to the integration of the custom loss function. The consistent results across the OhioT1DM and AZT1D datasets further demon- strate that GLIMMER is robust and generalizable, making it suitable for use with various datasets.\nIn our analysis, we calculated error metrics separately for normal glucose levels and dysglycemic regions, providing a clearer understanding of the model's performance across dif- ferent glucose conditions. This detailed breakdown highlights the model's strengths and identifies areas for improvement in managing varying glucose states. Precision and recall offer valuable insights: high precision indicates that the model accu- rately predicts dysglycemia, reducing false alarms, while high recall shows that the model effectively detects dysglycemic events, minimizing missed occurrences.\nTables IV and V present these metrics for the OhioT1DM and AZT1D datasets, comparing the performance of the basic CNN-LSTM model and GLIMMER. These metrics, along with RMSE and MAE, provide a comprehensive assessment of the model's reliability and effectiveness in supporting diabetes management and patient safety. In the OhioT1DM dataset, GLIMMER significantly improves hypoglycemia detection, increasing recall from 16% to 42%, meaning it captures more true low blood sugar events, which is vital for patient safety. The F1 score for hypoglycemia rises from 35% to 44%, reflecting a better balance between detecting true events and minimizing false positives. For hyperglycemia, GLIMMER also improves recall by 10%, from 78% to 86%, ensuring more high blood sugar episodes are detected. With a 5% improvement in precision, it reduces false alarms, making the model more reliable and user-friendly in managing glucose levels. In the AZT1D dataset, GLIMMER shows notable gains in both recall and precision for hypoglycemia detection. Recall improves from 2% to 13%, meaning it catches more low blood sugar events, while precision rises from 34% to 47%, reducing unnecessary alerts. For hyperglycemia, GLIMMER's recall jumps from 48% to 73%, a 52% improvement, allowing it to detect more high glucose events. The model also enhances precision by 15%, ensuring better accuracy in its predictions, making it a more effective tool for managing critical dysg- lycemic events."}, {"title": "VI. DISCUSSION", "content": "Our experiments demonstrated that GLIMMER achieves superior performance and accuracy as a predictive model, surpassing the state-of-the-art models. Additionally, CEG anal- ysis validated its reliability in detecting and forecasting dysg- lycemic events. Recent work by Annuzzi et al. [59] explored how certain features affect blood glucose prediction using X\u0391\u0399 methodologies. They reported an RMSE of 24.47 \u00b1 4.27 on the AI4PG dataset, with a PH of 60 minutes. Their model depends on detailed data inputs, including preprandial blood glucose levels, insulin dosages, and meal-related factors such as energy intake, macro-nutrients, glycemic index, and glycemic load. However, we note that in real-world scenarios, obtaining these details can be challenging, as it often requires manual logging of meal and nutritional information. GLIMMER, on the other hand, achieves strong predictions using only features like CGM data, bolus and basal insulin levels, and carbohydrate amounts that are commonly obtained in automated insulin delivery systems by default. As a result, GLIMMER does not impose any additional data collection burden on the patients beyond what the standard of care requires.\nDespite these achievements, certain limitations remain. While GLIMMER shows improvement in F1 score, precision, and recall over the baseline CNN-LSTM model, its hypo- glycemia prediction performance is still limited. One reason for this limitation is the sparsity of hypoglycemic events in both the OhioT1DM and AZT1D datasets used in this study. The scarcity of these events means the algorithm has fewer ex- amples from which to learn hypoglycemia patterns effectively. Additionally, we were unable to compare GLIMMER to other models on the AZT1D dataset because the source codes for these methods are not publicly available. In future work, we plan to implement and evaluate additional models to achieve a more comprehensive assessment.\nAlthough the core architecture of GLIMMER is CNN- LSTM, the methodologies presented in this article, including the proposed custom loss function and the optimization algo- rithm, are model-agnostic and can be adapted to other neural network models as well. Future work will focus on designing more advanced architectures, such as attention-based models, to explore GLIMMER's potential within more complex time- series forecasting frameworks. We also aim to extend the prediction horizon and incorporate long-term features, which could improve accuracy over longer time periods. As shown in Fig. 1, integrating GLIMMER with automated insulin delivery devices and developing a smartphone application to alert patients and physicians about potential dysglycemic events could have transformative effects. This application would provide projections for the next hour of blood glucose levels, acting as a preventive tool and allowing for a comparison of GLIMMER's effectiveness against current methods."}, {"title": "VII. CONCLUSION", "content": "In this paper, we introduce GLIMMER, a machine learning algorithm with a custom loss function designed for accurate prediction of blood glucose levels and to create more reliable opportunities for behavioral and medical treatments in type 1 diabetes management. Our contribution emphasizes predic- tions in dysglycemic regions, where patients face dangerous conditions and require precise forecasts to prevent adverse events. Utilizing carefully selected input features and a custom loss function fine-tuned through a genetic algorithm, GLIM- MER has demonstrated improved performance over state- of-the-art models, reducing RMSE by 23% and MAE by 31% on the OhioT1DM dataset. Additionally, we collected a new dataset containing CGM records and insulin delivery events from 25 patients with T1D, allowing us to validate GLIMMER's generalizability on a larger, real-world dataset while also creating a valuable resource for further research. GLIMMER can be integrated into automated insulin delivery systems and smartphone applications, supporting patients and physicians in more accurately managing T1D and preventing dysglycemia."}]}