{"title": "Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection", "authors": ["Hao Guo", "Zihan Ma", "Zhi Zeng", "Minnan Luo", "Weixin Zeng", "Jiuyang Tang", "Xiang Zhao"], "abstract": "Social platforms, while facilitating access to information, have also become saturated with a plethora of fake news, resulting in negative consequences. Automatic multimodal fake news detection is a worthwhile pursuit. Existing multimodal fake news datasets only provide binary labels of real or fake. However, real news is alike, while each fake news is fake in its own way. These datasets fail to reflect the mixed nature of various types of multimodal fake news. To bridge the gap, we construct an attributing multi-granularity multimodal fake news detection dataset AMG, revealing the inherent fake pattern. Furthermore, we propose a multi-granularity clue alignment model MGCA to achieve multimodal fake news detection and attribution. Experimental results demonstrate that AMG is a challenging dataset, and its attribution setting opens up new avenues for future research.", "sections": [{"title": "Introduction", "content": "Fake news is false or misleading information presented as news (Rubin et al. 2016; Molina et al. 2021). Social media platforms are inundated with fake news, exerting a significant impact on public health, governance, and societal equilibrium (Zannettou et al. 2019; Allcott and Gentzkow 2017; Apuke and Omar 2021). In recent years, the media-rich nature of these platforms has led to a gradual shift in the type of information shared by the public, encompassing not only textual content but also a plethora of visual elements such as images and videos. Because of the \"Multimedia Effect\" (Mayer 2002), multimedia content such as images and videos exerts a heightened allure on individuals (Jamet, Gavota, and Quaireau 2008; Mayer 2014). Furthermore, visual content is commonly utilized as substantiating evidence within storytelling, thus augmenting the credibility of news narratives. Regrettably, fake news publishers have adeptly utilized this opportunity to captivate attention and enhance credibility, leading to an evolution towards multimodal formats (Cao et al. 2020). The task of multimodal fake news detection has grown progressively intricate, which is the focal point of our research.\nIn contrast to news that relies solely on textual content, multimodal fake news encompasses visual, textual, and cross-modal correlation, allowing fabricators to craft deceptive narratives from multiple perspectives. We have observed that real news is alike, each fake news is fake in its own way. In popular social platforms Twitter, multimodal fake news manifests in various distinct types\u00b9, as depicted in Figure 1. However, existing multimodal fake news detection methods typically focus on only one type. First, some methods incorporate visual-textual consistency features into the basis for detection (Zhou, Wu, and Zafarani 2020; Qi et al. 2021a), which aim to capture the correlation between the textual and visual content. The methods focus on detecting types like Figure 1(a), where the key person \"Kamala\" does not appear"}, {"title": "Dataset Construction", "content": "AMG, as the pioneering dataset for multimodal fake news detection and attribution, encompasses posts originating from diverse social platforms. In this section, the data collection, data processing and annotation, and the collation and analysis of AMG will be described in detail."}, {"title": "Data Collection", "content": "For gathering fake news, we intend to utilize existing fact-checking websites as initial sources of news. The ruling articles found on these websites can assist in fine-grained type annotation. Among them, Snopes2 and CHECKYOURFACT\u00b3 are widely recognized websites that verify and expose fake news. Professionals, including journalists, gather pertinent evidence and engage in evidence-based reasoning to formulate ruling articles, providing judgments on the authenticity of news. Instead of crawling short claims from the titles of fact-checking websites (Yao et al. 2023), we crawl the original posts associated with claims from various platforms, primarily including Instagram, Facebook, Twitter, TikTok, and YouTube, which aligns more closely with the reality of fake news on social platforms. Among them, we focus on Instagram, Facebook, and Twitter as the main sources of these posts.\nInitially, we crawl the verified true news from the same fact-checking websites. However, the quantity obtained is quite limited (only 126). Besides, to mitigate inherent biases between real and fake news (Zhu et al. 2022), it is essential to establish a relatedness between real news and the corresponding fake news. Therefore, we compensate for the shortage of real news by the following steps. Firstly, we employ the pre-trained Large Language Model Vicuna (Zheng et al. 2023) as our entity extraction tool. Then, based on the distribution proportion of fake news on social platforms, we crawl real news associated with these entities from authoritative and neutral media accounts4, such as Reuters and NewsNation.\nDue to an insufficient number of retrieved related real news, we have randomly selected a certain quantity of news articles from the aforementioned official account's archive to supplement the dataset. These news span from 2016 to 2023, aligning with the temporal scope of the fake news. To maintain a similar ratio to the previous dataset, we set the quantity of genuine news to be 1.5 times that of fake news."}, {"title": "Data Processing and Annotation", "content": "In order to construct a multimodal fake news dataset, our first step involves filtering news articles based on the presence of relevant multimodal news. Both images and videos are included within the scope of our dataset. Moving forward, we utilize visual content similarity to eliminate news articles with high resemblance to one another, thus preserving the diversity among each piece and safeguarding against potential data leakage.\nDiverging from our previous approach of directly crawling websites with authenticity labels, we have embarked on a more detailed annotation process for news articles, based on these labels and verified articles. Our annotation work is carried out by a team of experts who possess relevant domain knowledge. A comprehensive annotation guideline has been developed, along with specialized training for the annotators. The team consists of a total of 17 individuals (Details in Supplementary).\nBinary labels indicating the truthfulness of news can be easily obtained from verification websites. For fake news, we have meticulously designed each step of the attribution process, as shown in Figure 2. Ruling articles serve as our basis for judgment. Firstly, we perform image pattern checking on the image itself to identify any signs of fabrication or non-evidential content. Secondly, we examine the consistency between the image and the accompanying text across various key factors, attributing entity, event and time inconsistency. It is also possible that some instances do not belong to any of the above categories.\nThe specific explanations and theoretical foundations for each attribution type are as follows (See examples in Figure 3):\nThe authenticity of an image is questionable. This can encompass the application of cutting-edge deepfake techniques as well as simpler forms of manipulation such as image splicing or PS. Furthermore, it also includes the simulation of images imitating official websites or tweets, representing a unique circumstance within the realm of image forgery. Previous research (Wu et al. 2021b; Xue et al. 2021) has already highlighted the use of the authenticity of the image for detection, while (Shao, Wu, and Liu 2023) established a dataset for detecting AIGC-based fake images. So image fabrication is one typical fake attribution of multimodal news.\nrefers to cases where the image consists of textual information that cannot provide evidence or proof for news content. A notable characteristic of real news is that its images provide support for the accompanying text, such as on-site photos of breaking events. On the other hand, images that solely consist of text are a common image pattern found in multimodal fake news.\nrefers to a phenomenon where there is a discrepancy between the key entities depicted in the textual and visual modalities. In other words, there is a lack of alignment or coherence between the entities described in the text and those visually represented, which"}, {"title": "Cross Validation and Discussion", "content": "Each fake news is assigned to three annotators, and the final attribution is determined through a majority vote following (Feng et al. 2022). Furthermore, controversial cases undergo discussion and then secondary round of annotation."}, {"title": "Data Collation and Analysis", "content": "After integrating the collected news, we filter out fake news that does not fall under our attribution types. And the quantities for each attribution type are as follows: 434, 295, 133, 667, 475. The number of multimodal fake news from Instagram, Twitter, and Facebook are 142, 558, and 1,304, respectively. In addition, the final number of real news is set to approximately 1.5 times the number of fake news. The counts for real news and fake news are 3,018 and 2,004. More statistic are listed in Supplementary.\nWe split the whole dataset into training (Train), validation (Val), and test (Test) sets with the number of 3,532, 517 and 1973, respectively. The percentage is nearly 7:1:2. Furthermore, we maintain consistent proportions within each subcategory during the dataset's split.\nUpon analyzing the final statistics, we make an exciting observation: the samples that fall outside our attribution categories account for only around 3% of the total dataset, comprising approximately 60 instances. This observation suggests that our classification rules effectively cover almost all cases of fake news, thereby confirming the soundness of our attribution guidelines.\nFirstly, we adhere to the data scraping rules of each platform. Additionally, all annotators underwent rigorous training and were well-versed in data privacy and security regulations. During the annotation process, the annotators conducted a screening, selecting only posts related to public figures or public events, without involving ordinary users. Furthermore, any associated personal user information was anonymized, including id and name. We also took measures during data processing and training to prevent any leakage of user privacy((Details in Supplementary). All collected data is stored on secure servers, with access restricted to our research team members only.\nThe strength of AMG. (1) Up-to-date and Temporal-inclusive. The fake news in AMG originate from the period between 2020 and 2024, with a small portion encompassing February 2024. AMG includes the publication timestamps of news posts, whereas MR2 (Hu et al. 2023a) does not. (2) Multiple platforms. AMG is platform-agnostic which incorporating content from the three major mainstream social platforms. (3) Multiple domains. Upon a simple aggregation, we find that it encompasses multiple fields such as healthcare, elections, military, entertainment, and more. (4) Multi-granularity attribution labels. Different from Fakeddit (Nakamura, Levy, and Wang 2020), the fine-grained labels of AMG reveals the attribution for fake pattern."}, {"title": "Methodology", "content": "The section primarily discusses our proposed detection and attribution model. (Preliminary in Supplementary)\nAs depicted in Figure 4, MGCA first gathers multi-perspective clues from both images and text."}, {"title": "Multi-View Clue Collection", "content": "We extract the multi-view clues from both the textual input and visual input, which includes time, entity and event.\nDue to the narrative style typically present in news articles, which includes crucial named entities such as characters and locations, the association between these key entities can be instrumental in detecting fake news (Qi et al. 2021b). To enhance this process, we employ the pre-trained Large Language Model Vicuna (Zheng et al. 2023). By designing prompt templates and utilizing the capabilities of the large-scale model's In-context Learning (Mann et al. 2020; Xie et al. 2021), we incorporate examples of entity extraction within these templates, guiding the process. We denote the entity in the text as $E_p$.\nCorresponding to the textual content, certain news articles also contain valuable visual entities within their visual content. For the extraction of visual entities, we utilize Baiduan APIs that specializes in extracting three types of entities: individuals, landmarks, and organizations. We denote this extraction of visual entities as $E_v$.\nTemporal mismatch is a significant type of multimodal fake news. In this article, we consider the temporal information of news as a crucial factor in determining its authenticity. Firstly, we extract the time label of the news, denoted as $t_1$. As news articles often describe past events, we also extract the mentioned time, $t_2$, from the textual content. We then select the earlier time as the temporal reference for the text, which we refer to as $T_p = min{t_1, t_2}$.\nRetrieving the original publication time of an image, along with its relevant content, can be helpful in identifying temporal inconsistencies in multimodal fake news. We employ GoogleLens for performing reverse image searches. By conducting such searches, we obtain the earliest corresponding time $T_v$ and title $R$ of the related image."}, {"title": "Image Event", "content": "In addition to visual entities, we believe that the event present in images is also a valuable auxiliary clue. We utilize multimodal large language model LLaVA (Liu et al. 2023) for extracting image events denoted as $S$ (Conducting details in Supplementary)."}, {"title": "Multimodal Feature Learning", "content": "To enhance the consistency representation, we employ CLIP (Radford et al. 2021) to extract features $P$ and $V$ from the total of news text $P$ and news image $V$. To obtain the rich semantic clue representations, we exploit utilize BERT(Kenton and Toutanova 2019) to acquire $C_s$, $C_r$, $C_p$ and $C_v$ from event clues $S$. Also, we use Bert to encode entity clues $E_p$, $E_v$ and the retrieval clues $R$.\nTo ensure mathematical distribution consistency, we also utilize BERT to obtain the semantic representation $P_r$ of the news text. As for the timeline, we calculate the temporal gap $T_g$ between the images and the text, denoted as $T_g = (T_p - T_v)$ to characterize the temporal inconsistency.\nTo detect the manipulated image, we employ the effective manipulation detection network PSCC-NET (Liu et al. 2022) for detecting image manipulation. Specifically, by freezing the feature extraction layer of PSCC-NET, we obtain the manipulation features $V_m$ for the news images."}, {"title": "Multi-Granularity Clues Alignment", "content": "To detect the entity-level and event-level consistency between news image and text, we utilize a Compare-Net(Shen et al. 2018) to obtain consistency features $E$ and $S$,i.e.,"}, {"title": "$E = f_{cmp} = (C_p, C_v),", "content": "$\\tag{1}$"}, {"title": "$S = f_{cmp} = (C_s, P_b),", "content": ""}, {"title": "Alignment", "content": "where $f_{cmp}$ denotes the Compare-Net(Shen et al. 2018). To measure the embedding closeness and relevance, we design the comparison function as:"}, {"title": "$f_{cmp}(C_1, C_2) = W_c[C_1, C_2, C_1 \u2013 C_2, C_1 * C_2],", "content": "$\\tag{2}$"}, {"title": "Alignment", "content": "where $W_c$ is a transformation matrix and $*$ is Hadamard product. $C_1$ and $C_2$ are the features to be compared. Additionally, we compare the news text with the results obtained from reverse search to verify the presence of temporal alignments. In particular, we concurrently splice temporal features in the vectors of the Compare-Net."}, {"title": "$T = W_tT_g,$", "content": "$\\tag{3}$"}, {"title": "$R = f_{cmp}(C_r, P_b, T)", "content": ""}, {"title": "$= W_r[C_r, P_b, C_r - P_b, C_r * P_b,T],$", "content": ""}, {"title": "Alignment", "content": "where $R$ represents the temporal consistency features, $W_t$ is is a 1-dimensional learnable matrix, $W$ refer to learnable transformation matrix."}, {"title": "Training and Inference", "content": "To obtain a better fake news representation of various attributions, we incorporate a classification head before each category of features to perform a binary classification task"}, {"title": "Alignment", "content": "for distinguishing between real and fake news. The label for this task is denoted as $y_b$. In particular, we also separately perform a binary classification task on the images feature $V_c$ to better distinguish samples of visual effectiveness. We use binary cross-entropy loss to individually optimize these five feature categories:"}, {"title": "Alignment", "content": "$\\hat{y_n} = MLP(n), n = E,S,R,V_m, V_c,$"}, {"content": "$\\tag{4}$"}, {"title": "Alignment", "content": "$L_n = -(y_b log \\hat{y_n} + (1 - y_b) log(1 \u2013 \\hat{y_n})).$"}, {"title": "Alignment", "content": "Simultaneously, we concatenate the features and multiply the probability $\\varphi_n$ of a single judgment network indicating the news as fake with the corresponding network's feature. When the probability approaches 1, it signifies a higher likelihood of the news being false due to that particular feature. Meanwhile, we splice text clip semantic features to better obtain a global multimodal representation of the news. After passing through a Multilayer Perceptron (MLP), we obtain the final prediction result $\\hat{y_b}$, i.e.,"}, {"title": "Alignment", "content": "$\\hat{y_b} = MLP([P_c, E * \\varphi_E, S * \\varphi_S,R* \\varphi_R, V_m * \\varphi_m, V_c * \\varphi_c])."}, {"content": "$\\tag{5}$"}, {"title": "Alignment", "content": "Then, we consider the minimization of the standard binary cross-entropy loss value as the objective function,i.e.,"}, {"title": "Alignment", "content": "$L_b (y_b, \\hat{y_b}) = - (y_b log \\hat{y_b} + (1 \u2013 y_b) log(1 \u2013 \\hat{y_b})) + \\frac{1}{n} \\sum L_n,"}, {"content": "$\\tag{6}$"}, {"title": "Alignment", "content": "Alignment"}, {"content": "where $y_b$ denotes the actual label and $y_b \\in {0, 1}; \\hat{y}$ represent the predicted label. In attributing inference, we define the downstream task as a 6-classification task, and obtain the final attributing prediction $\\hat{y}$ through the MLP,i.e.,"}, {"title": "Alignment", "content": "$\\hat{y} = MLP([P_c, E * \\varphi_E, S * \\varphi_S,R* \\varphi_R, V_m * \\varphi_m, V_c * \\varphi_c]),"}, {"content": "$\\tag{7}$"}, {"title": "Alignment", "content": "and optimize the classification results using cross-entropy loss,i.e.,"}, {"title": "Alignment", "content": "$L = \\sum_{i=1}^{6} \\frac{1}{n} \\sum y_i log \\hat{y} + L_n,$"}, {"content": "$\\tag{8}$"}, {"title": "Alignment", "content": "where $y_i$ is the probability of predicting the sample as class $i$."}, {"title": "Experiment", "content": "Experimental settings can be found in Supplementary, which includes compared methods, implementation details, and evaluation metrics. All experiments are conducted on a cluster of 8 RTX3090 GPUs. Additionally, we also analyze the computational complexity of the model; details can be found in the Supplementary."}, {"title": "Results on Multimodal Fake News Detection", "content": "According to Table 2, our proposed model exhibits the best performance across various metrics. MGCA achieves an approximately 2.5% improvement in overall accuracy (acc) and a 2.8% improvement in F1 score. Additionally, to demonstrate the generalization of MGCA, we conduct experiments on"}, {"title": "Discussion on Dataset Difficulty", "content": "Comparing the experimental results of the same model on previous datasets, we observe that AMG is a more challenging dataset. BMR achieves an accuracy (acc) of 90% on both the Weibo (Jin et al. 2017) and GossipCop (Shu et al. 2020), while the detection accuracy of AMG falls below 81%. Other models also exhibit varying degrees of performance decline. We have analyzed the reasons behind the increased challenge in AMG and arrived at a preliminary conclusion: the presence of entity bias (Zhu et al. 2022) in the collection process of real and fake news. However, our approach of collecting true news has successfully avoided this bias."}, {"title": "Results on Multimodal Fake News Attribution", "content": "We present the overall attribution accuracy and F1 scores in Table 2, while the detailed results on each attribution category are presented in Supplementary. The experimental results show that our model outperforms the baseline model in terms of overall attribution accuracy and F1 scores. Compared to the suboptimal model BMR, our model achieves improvements of approximately 7% and 4.7% in accuracy and F1 score, respectively. Furthermore, MGCA demonstrates a significant enhancement of around 10% in accuracy compared to other methods."}, {"title": "Ablation Study", "content": "To demonstrate the effectiveness of the multi-granularity clue and various feature extraction modules we employed, we conducted ablation experiments. The results of these experiments are displayed in Table 3.\nRemoving individual modules leads to a certain degree of decline in both detection and attribution performance. Among them, the removal of event-level coherence features has the greatest impact on the detection of multimodal fake"}, {"title": "Discrimination Performance", "content": "We utilize heatmaps to visualize the discriminative power of MGCA on AMG. We randomly select 90 real news and 90 fake news. We then calculate the pairwise similarities between the 16-dimensional representations from the binary classification classifier and the attribution classifier. The darker colors indicate weaker correlation and lighter colors indicate stronger correlation.\nFrom Figure 6, we can observe that our model demonstrates strong discriminative ability, with relatively clear intra-class similarity and inter-class differences. Additionally, it is evident that the binary classification representations of genuine news and fake news exhibit a higher level of distinctiveness, while the attribution learning shows a slightly reduced discriminative capacity. This observation indicates that capturing intra-class variations among the fake news instances represents the main challenge faced by AMG."}, {"title": "Conclusion", "content": "In this study, we introduce a novel task, multimodal fake news attribution, which aims to enhance the credibility of model detection results. We believe it will provide promising and meaningful avenues for research. Furthermore, we develop AMG, the first multimodal fake news attribution dataset and make it open-sourced, which will facilitate future follow-up studies. We emphasize the significance of temporal information in the detection of multimodal fake information, highlighting it as a key factor for fake news detection. We also introduce a competitive method MGCA."}, {"title": "Limitation", "content": "AMG focuses solely on the content of multimodal fake news, excluding metadata like comments and social networks. We are collecting this data for future release. Additionally, besides dividing attributions into five categories, we include the label \"Not fall into any of the above types\", during the labeling process. Figure 7 illustrates several instances that fall outside the scope of our attributions. In this regard, (a) delineates the occurrence of multiple overlapping attribution anomalies, encompassing both entity and temporal inconsistency. On the other hand, (b) signifies instances that do not conform to any of our attribution categories."}, {"title": "Appendix", "content": "Figure8 illustrates our annotation process, as described in Section 3.2, we went through six steps: data crawling, data cleaning, expert annotation, cross-validation and discussion, related real news crawling, and data collation. In the process of expert annotation, in order to obtain accurate and robust annotations, we invited 17 researchers in the fields of computer science and news communication to participate in the annotation, who are familiar with the research on the dissemination and detection of fake news, and most of them have published related articles or designed detection systems. All annotators underwent rigorous training and were well-versed in data privacy and security regulations. Specifically, we carefully selected 100 typical cases through group and unified discussions, and assigned each news item to three experts. We then asked them to attribute each sample, with the option of choosing between \"does not belong to any category\" and \"not sure\". We calculated the accuracy and F1 scores between the expert labeling and the labels of the pre-selected typical dataset before voting, and only allowed the expert labeled results to go to the voting stage when all the metrics were above 95%."}, {"title": "Examples of Various Category", "content": "We summarize the statistics of temporal distribution and multi-platforms distribution in Figure 9 in MGCA."}, {"title": "Preliminary", "content": "AMG contains both binary labels for real and fake classification, as well as multi-class labels for attributing different types of errors. Consequently, we conduct two tasks: multimodal fake news detection and multimodal fake news attribution. A piece of multimodal news can be represented as{(p,v), $y_b \\in$ {0,1},$y_a \\in$ {0, 1, 2, 3, 4, 5}}, where p and v represent the textual and visual content, respectively. And $y_b$ denotes the detection label and and $y$ is attribution label."}, {"title": "Alignment", "content": "Given a piece of multimodal news, it seeks to categorize news pieces into fake or real. Each piece of news contains the textual and visual contents, and has a ground-truth label $y_b \\in$ {0,1}, such that 1 denotes fake, 0 denotes real."}, {"title": "Alignment", "content": "Given a piece of multimodal news, attributting task aims to determine the authenticity of news while attributing the reasons behind its falsehood to five pre-defined categories. Each piece of fake news has a ground-truth label $y_a \\in$ {0, 1, 2, 3, 4, 5}, which represents real news, ImageFab, ImageNoE, Entity-Inc, EventInc, or TimeInc, respectively."}, {"title": "Video Preprocessing", "content": "In the case of video in visual modality, we conduct preliminary processing. We consider the middle frame of the video to be crucial. Therefore, we extract the middle frame as a representative for video. Therefore, in the subsequent model section, our treatment of the"}]}