{"title": "Learning Interpretable Network Dynamics via Universal Neural Symbolic Regression", "authors": ["Jiao Hu", "Jiaxu Cui", "Bo Yang"], "abstract": "Discovering governing equations of complex network dynamics is a fundamental challenge in contemporary science with rich data, which can uncover the mysterious patterns and mechanisms of the formation and evolution of complex phenomena in various fields and assist in decision-making. In this work, we develop a universal computational tool that can automatically, efficiently, and accurately learn the symbolic changing patterns of complex system states by combining the excellent fitting ability from deep learning and the equation inference ability from pre-trained symbolic regression. We conduct intensive experimental verifications on more than ten representative scenarios from physics, biochemistry, ecology, epidemiology, etc. Results demonstrate the outstanding effectiveness and efficiency of our tool by comparing with the state-of-the-art symbolic regression techniques for network dynamics. The application to real-world systems including global epidemic transmission and pedestrian movements has verified its practical applicability. We believe that our tool can serve as a universal solution to dispel the fog of hidden mechanisms of changes in complex phenomena, advance toward interpretability, and inspire more scientific discoveries.", "sections": [{"title": "1 Introduction", "content": "From the Book of Changes in ancient China to the dialectical thinking in the West, there exists a common philosophical thought that the only constant is change. Undoubtedly, scientists have been striving to discover the laws of changes in complex phenomena, attempting to explain, forecast, and regulate all things [1], such as emergence [2], chaos [3], synchronization [4], and critical phenomena [5]. As a widely accepted modeling, the changing patterns of states from complex systems are generally governed by a set of nonlinear differential equations [6] as $X(t) = f(X(t), A,t)$, where $X(t) \\in R^{N\\times d}$ is the system states at time t, N and d are the number of system components (nodes) and the state dimension, respectively. A represents the extra information beyond the system states, such as topological interactions among system components. As shown in the above formula, the dynamic behaviors exhibited by complex systems are primarily contingent upon the intricate interdependence between their internal interactions A and dynamics governing equations f"}, {"title": "2 Results", "content": "In this work, we wonder to develop a computational tool LLC (Learning Law of Changes) to discover the ordinary differential equations (ODEs) from observed data of network dynamics, i.e., LLC : O \u2192 F, where observations $O = \\{(X(t), A, M_x, M_a)\\}_{t=0}^T \\subseteq O$ and the ODEs $f \\in F$. In fact, observations are sampled from continuous state data, which is obtained by solving the initial value problem with given initial states $X(0)$ and topology A, i.e., $X(t) = X(0) + \\int_0^t f(X(\\tau), A, \\tau)d\\tau$. Note that $M_x$ and $M_a$ in observations O are the masks for observed states and topological structure respectively, with the same shapes of X(t)"}, {"title": "2.1 The overall process of the LLC (Learning Law of Changes)", "content": "When developing the computational tool, we encounter two stubborn issues: high-dimensional free variables and efficiency issues in symbolic inference. As mentioned earlier, due to the excessive number of nodes and state dimensions, the combination space of the symbolic models is too huge to seek the well-fitted dynamics equations for observed data [31]. Meanwhile, if we simply test all symbolic models by increasing equation length, it may take longer than the age of our universe until we get the target [11]. Even if de novo optimization algorithms such as evolutionary computation [32], reinforcement learning [33], and Monte Carlo tree search [34] are applied to find the objective symbolic model, it will still take an intolerable amount of time. More importantly, the performance of existing symbolic regression methods drops sharply when the number of variables exceeds three [35]. Therefore, to tackle both difficulties, we employ the divide and conquer approach by introducing a few physical priors and using the excellent fitting power from neural networks to achieve dimensionality reduction of high-dimensional network dynamic signals, then using a pre-trained symbolic regression model to accelerate the efficiency of inferring dynamics equations.\nDecoupling network dynamics signals through neural networks and physical priors. To alleviate the curse of dimensionality in network dynamics, we introduce a physical prior in network dynamics that the change of network states can be influenced by its own states and the states of its neighbors [6, 8, 36, 37]. That is, we can decompose the governing equation f into two coupled components: self dynamics (Q(self)) and interaction dynamics (Q(inter)), thereby the governing equations of network dynamics can be reformalized in node-wise form as $X_i(t) = Q^{(self)}(X_i(t)) + \\sum_{j=1}^N A_{i,j} Q^{(inter)}(X_i(t), X_j(t))$, where the subscripts i and j represent the corresponding nodes, $A_{i,j}$ is the adjacency matrix, $Q^{(self)}$ and $Q^{(inter)}$ capture the evolution process of their own states and the neighbors' dynamical mechanism governing the pairwise interactions respectively. At this moment, f is composed of a set of functions, i.e., $f := \\{Q^{(self)}, Q^{(inter)}\\}_{i=1}^N$. Actually, with the appropriate choice of $Q^{(self)}$"}, {"title": "2.2 Inferring one-dimensional network dynamics", "content": "To comprehensively verify the effectiveness of the LLC, we test on six representative one-dimensional homogeneous network dynamics models, including Biochemical (Bio) [44], Gene regulatory (Gene) [45], Mutualistic Interaction (MI) [15], Lotka-Volterra (LV) [46], Neural (Neur) [47], and Epidemic (Epi) [48], which have widespread applications across various fields, including biology, ecology, epidemiology, genomics, and neuroscience, exhibiting diverse characteristics. All network dynamics are simulated on an Erd\u0151s-R\u00e9nyi (ER) network [49], where node degrees are drawn from a Poisson distribution with an average degree of k = (N \u2212 1)p and p is the probability of edge creation, so as to produce the continuous system states, i.e., X(.). We apply the LLC to reconstruct governing equations from the observations $O = \\{(X(t), A, M_x, M_a)\\}_{t=0}^T$ sampled from X(.). Please see Appendix A for the detailed description of the network dynamics models and specific settings.\nWe compare against the state of the arts for interpretable dynamics learning in complex networks, i.e., TPSINDy [8] and GNN+GP [10, 36]. Due to the need for manual setting of function terms for the TPSINDy, we have set up various libraries with prior assumptions to obtain more comprehensive testing. For the GNN+GP, we use an empirically suitable graph neural network version for simulating network dynamics [36], and a high-performance genetic programming-based symbolic regression, i.e., PySR [50], to output equations subsequently. Also, we feed the output of our LLC as the discovered function terms into the TPSINDy, named as LLC+TPSINDy, to overcome its limitation of requiring a pre-defined library and verify our ability to discover new knowledge, i.e., effective function terms."}, {"title": "2.3 Inferring multi-dimensional and heterogeneous network dynamics", "content": "We apply the LLC to two multi-dimensional systems including FitzHugh-Nagumo (FHN) dynamics [54] and predator-prey (PP) system [55]. The FHN is a two-dimensional neuronal dynamics that brain activities governed by the FitzHugh-Nagumo model, capturing the firing behaviors of neurons with two components, i.e., membrane potential ($X_{i,1}(t)$) and recovery variable ($X_{i,2}(t)$), which has a quasi-periodic characteristic. A Barab\u00e1si-Albert (BA) network is used to simulate the interactions among brain functional areas [56]. We get the observations of the sampling nodes by setting the masks, i.e., $M_x$ and $M_a$. As shown in Fig. 3(a-d), our LLC can effectively decompose the self dynamics and interaction dynamics by training neural networks $Q^{(self)}$ and $Q^{(inter)}$. Moreover, compared to the TPSINDy, the equations discovered by the LLC and LLC+TPSINDy are closer to the true multi-dimensional governing equations (Fig. 3(e)), and can achieve smaller predictive errors across all nodes (Fig. 3(f)). Especially as the prediction time increases (up to 100T), our LLC can still make accurate trajectories with periodicity, while the TPSINDy finds it difficult"}, {"title": "2.4 Inferring dynamics of chaotic systems", "content": "We further discover the governing equations for three-dimensional chaotic systems on networks, including Lorenz [60] and R\u00f6ssler dynamics [61]. To examine the impact of the initial sensitivity of chaotic systems on our LLC, we specify the following three initial value settings: fixing the initial states of all nodes to 0.1, sampling from a standard Gaussian distribution, and sampling from a uniform distribution U(0, 2). Then, we employ a random network as the topological structure to produce the dynamics data of the Lorenz. We see that the governing equations found from the dynamics data generated from different initial values are very similar (Fig. 5(a)). The predictive trajectories of the three discovered equations starting from the same initial values are close to the actual system behavior before 1000 time steps, and then the butterfly effect begins to gradually appear afterward (see Fig. 5(b)), which means that our tool can accurately forecast a chaotic system for a long time, that is, 1000 times the training time steps. By comparing the TPSINDy on the R\u00f6ssler system, our LLC restores more accurate governing equations (Fig. 5(c)) and has smaller predictive errors (Fig. 5(d)). We also analyze the state transition behavior of the R\u00f6ssler system, and it is evident from the comparison of bifurcation diagrams generated by the inferred and true equations that period-doubling patterns and the bifurcation points are consistent, showing the transition process from period-1 to period-2, to period-4, to chaos, then to period-3, and finally to chaos again (see Fig. 5(e)). Fig. 5(f-g) also shows the same limit cycle at period-1 and chaotic behavior. This confirms the potential of our tool in analyzing the complex behavior and properties of systems with unknown dynamics. More settings, experimental results, and analysis on chaotic systems can be found in Appendix F."}, {"title": "2.5 Inferring dynamics of empirical systems", "content": "As impressive network dynamics, we collect daily global spreading data on COVID-19 [62], and use the worldwide airline network retrieved from OpenFights [63] as a directed and weighted empirical topology to build an empirical system of real-world global epidemic transmission. Only early data before government intervention, i.e., the first 50 days, is considered here to keep the spread features of the disease itself. By comparing the number of cases in various countries or regions (Fig. 6(a-d)), we found that the trend of the results predicted by the TPSINDy is relatively good in countries with many neighbors, while for countries with few neighbors, the results are overestimated in the early stages of disease transmission and underestimated in the later stages. More results on other countries or regions can be found in Appendix G. From the perspective of the discovered equations (Fig. 6(e)), due to the bounded interaction dynamics term in the TPSINDy, where each neighbor gives a maximum variation of 1, it has been providing a linear increase of approximately kb, where k is the number of neighbors and b is the coefficient of the interaction term, leading to overestimation in the early stage, while in the later stage, the linear increase of neighbors is insufficient and the self dynamics term is small, resulting in underestimation. Counterintuitively, as the node degree decreases, a increases while b increases in the TPSINDy, indicating that the growth of cases is more influenced by neighbors than oneself when the number of neighbors decreases. When predicting the case number in Spain by"}, {"title": "3 Discussion", "content": "We introduced a computational tool to efficiently and accurately discover the effective governing ordinary differential equations from observed data of network dynamics. We proposed decoupling network dynamics signals through neural networks and physical priors, and parsing governing equations via a pre-trained symbolic regression, to alleviate the challenges of excessive free variables and high computational cost. Through sufficient experiments on various network dynamics from biology, ecology, epidemiology, genomics, and neuroscience,"}, {"title": "4 Methods", "content": ""}, {"title": "4.1 Details of the LLC", "content": "In this section, we present the various modules in our LLC, including data acquisition, selection of intervals, differential technology, physical priors, signal decoupling, symbolic regression, and termination conditions.\nData acquisition. Generating synthetic data is a crucial step in validating algorithm performance and simulating real-world network behavior. For a specific dynamics scenario f, we determine its hyperparameters and then choose a reasonable topology structure A, such as the Erd\u0151s-R\u00e9nyi (ER) network [49], C.elegans [57], and Drosophila [58]. After the initial state X(0) is given, we can solve the Initial Value Problem (IVP) via the Runge-Kutta method [71] to simulate the network behavior at any time t, i.e., X(t). Note that we solve the IVP over a fixed time interval $t \\in [0,T]$ and set both relative error and absolute error thresholds to $10^{-12}$ to ensure high precision throughout calculations which is a critical requirement in scientific research where accuracy of results holds paramount importance. Please refer to Appendix A for detailed experimental settings of each scenario. Additionally, we collect real data for the empirical systems, i.e., global spreading data [62] and the trajectories of pedestrians [64]. More details can be found in Appendix G.\nSelection of intervals. When inferring the governing equations of complex network dynamics, whether the data has a reasonable sampling range, i.e., [T', T], and the sampling interval, i.e., dt, have a significant impact on the inference results. For example, the data comes from all nodes reaching a consistent steady state is almost useless information for inferring the governing equation. If the system exhibits periodic changes, the data we choose needs to contain at least one full period to absorb its periodic behavior. For chaotic systems, we should have a sufficiently long time to observe the system's long-term behavior and stability, due to the sensitivity to initial conditions. Therefore, how to choose the reasonable range and interval is a practical problem that needs to be faced and solved. To simplify the optimization process, we set the range to start from 0, i.e., T' = 0, and establish the relationship between T and dt as: $dt = \\frac{T}{S}$, where S is a given sampling steps. Here, we employ the simulated annealing algorithm [72] to perform univariate optimization on T."}, {"title": "4.2 Performance measures", "content": "The performance measures for evaluating the methods in this work are as follows:\nR2 score. R2 score, also known as the coefficient of determination, is used to measure the predictive ability of a method, usually ranging from -\u221e to 1. The closer the R\u00b2 score is to 1, the better the prediction performance. The score can be calculated as:\n$R^2 = 1 - \\frac{\\sum_{i=1}^N \\sum_{t=1}^T (X_i(t) - \\hat{X_i}(t))^2}{\\sum_{i=1}^N \\sum_{t=1}^T (X_i(t) - \\overline{X}(t))^2}$ where $X_i(t)$ and $\\hat{X_i}(t)$ are the true and predictive states of node i at time t, respectively. $\\overline{X}(t)$ is the average of $X_i(t)$ over all node and n is the number of nodes.\nNED. We adopt the Normalized Euclidean distance (NED) to finely evaluate the difference between the predictive states produced by the inferred equation and the true states for each node i as\n$\\text{NED}(X_i, \\hat{X_i}) = \\frac{1}{D_{\\text{max}}} \\sum_{t=0}^{T} \\sqrt{(\\hat{X_i}(t) - X_i(t))^2 + (\\hat{\\dot{X}}_i(t) - \\dot{X_i}(t))^2}$, where, $D_{\\text{max}}$ is the longest Euclidean distance in the pairs composed of the true states. $X_i(t)$ and $\\hat{X_i}(t)$ are the true and predictive states of node i at time t, respectively. $X_i(t)$ and $\\hat{X_i}(t)$ are their respective derivatives.\nRecall. From the perspective of the symbolic form of equations, we use recall to evaluate the accuracy of the discovered equations, i.e., whether a certain function term is present or not. Let $\\overline{\\xi_{\\text{true}}}$ and $\\overline{\\xi_{\\text{pre}}}$ denote the true and inferred coefficients under a candidate library of function terms. For example, a library is [1, x, x2, x3, x4], If a true equation is y = 1+x, then $\\overline{\\xi_{\\text{true}}}$ = [1,1,0,0,0]. And if an inferred equation is y = 1+x2, then $\\overline{\\xi_{\\text{pre}}}$ = [1,0,1,0,0]. Recall"}, {"title": "Appendix A Network Dynamics and Topologies", "content": ""}, {"title": "A.1 Network Dynamics", "content": "We study six representative one-dimensional homogeneous network dynamics spanning the fields of biology, ecology, epidemics, and neuroscience.\n\u2022 Biochemical Dynamics (Bio): Biochemical processes within living cells are mediated by protein-protein interactions in which proteins bind to form protein complexes [44]. Its dynamics of biochemical reactions can be formulated as: $\\dot{X_i}(t) = F_i - B_iX_i(t) + \\sum_{j=1}^N A_{i,j}X_i(t)X_j(t)$, where $X_i(t)$ is the concentration of protein i at time t, $A_{i,j}$ is the effective rate constant of interaction between i and j, and $F_i$ and $B_i$ represent the average influx rate and degradation rate of proteins, respectively. We set $F_i$ = 1 and $B_i$ = \u22121.\n\u2022 Gene Regulatory Dynamics (Gene): The dynamics of gene regulatory networks can be described by the Michaelis-Menten equation [45, 77], given as $\\dot{X_i}(t) = -B_iX_i(t)f + \\sum_{j=1}^N A_{ij} \\frac{X_i^h}{1 + X_j^2}$. The node state $X_i(t)$ is the expression level of gene i. Parameter Bi controls the decay rate. When f = 1, the first term on the right-hand side describes degradation. When f = 2, it describes dimerization corresponding to two or two of the same molecules together to form dimers. The second term captures genetic activation, where h\u2265 0 represents the Hill coefficient, quantifying the saturation rate affected by neighboring nodes. We set $B_i$ = 2, f = 1, and h = 2 here.\n\u2022 Mutualistic Interaction Dynamics (MI): The mutually beneficial interaction dynamics between species in ecology, governed by $\\dot{X_i}(t) = b_i + X_i(t) \\frac{(1 - X_i(t))}{k_i} (X_i(t) - 1) + \\sum_{j=1}^N A_{i,j} \\frac{X_i(t)X_j(t)}{d_i + e_iX_j(t) + h_iX_j(t)}$. The abundance $X_i(t)$ of a captured species in a mutualistic differential equation system [15] consists of an afferent migration term $b_i$, a logical increase in population capacity $k_i$, an Allee effect with a cold starting threshold $c_i$, and a mutualistic interaction term with the interaction network A. The parameters are set as $b_i$ = 1, $k_i$ = 5, $c_i$ = 1, $d_i$ = 5, $e_i$ = 0.9, and $h_i$ = 0.1.\n\u2022 Lotka-Volterra Model (LV): The Lotka-Volterra model (LV) [46] describes the population dynamics of species in competition: $\\dot{X_i}(t) = X_i(t)(a_i - \\theta_iX_i(t)) - \\sum_{j=1}^N A_{i,j} X_i(t)X_j(t)$. Similar to mutualistic dynamics, the node state xi(t) represents the population size of species i, the growth parameters of species i, ai, \u03b8i > 0. In experiments, we sample \u03b1\u03af, \u03b8i from a uniform distribution within the range [0.5, 1.5]. Specifically, ai and di are set to 0.5 and 1 respectively.\n\u2022 Neural Dynamics (Neur): The firing rate of a neuron can be described by the Wilson-Cowan [47] model as $\\dot{X_i}(t) = - \\tau X_i(t)+ \\sum_{j=1}^N A_{i,j} (1 + \\exp(-(X_i(t) - \\mu)))^{-1}$. In this model, $X_i(t)$ is the activity level of neuron i, while the parameters and \u03bc determine the slope and threshold of the neural activation function, respectively. We set \u03c4 = \u22121 and \u03bc = 1.\n\u2022 Epidemic Dynamics (Epi): Epidemic dynamics can be used to describe the outbreak of infectious diseases [48] as: $\\dot{X_i}(t) = -\\delta X(t) + \\sum_{j=1}^N A_{i,j} (1 \u2013 X_i(t))X_j(t)$. In this model, each node can represent an individual, where the node state $X_i \\in [0, 1]$ corresponds to the infection probability of node i. The parameter \u03b4i represents the rate at which individuals recover from infection, which is set to be 1.0."}, {"title": "A.2 Network topologies", "content": "Network topology affects the evolution of node states. In this work, we study four network topologies, including the Erd\u0151s-R\u00e9nyi (ER) [49], Barab\u00e1si-Albert (BA) [80], and two empirical networks, i.e., the C.elegans [57] and Drosophila [58]. Below we describe the unique generation process of each topology.\n\u2022 Synthetic networks: (1) Erd\u0151s-R\u00e9nyi (ER) network [49], also known as a random network, where node degree is drawn from a Poisson distribution with mean degree k = (n - 1)p. p is the probability of edge creation. (2) Barab\u00e1si-Albert (BA) network [80], characterized by a power-law degree distribution. We use a priority connection to construct the network topology, starting with a set of nodes and iteratively introducing new nodes. Each new"}, {"title": "A.3 Initial conditions, sampling intervals, and end time of inferring and predicting", "content": "To ensure the reproducibility of our findings, we provide a comprehensive list of parameter settings on the initial conditions, sampling intervals, and end time of inferring and predicting, where let T and Tend denote the end time of inference and end time of prediction, respectively. If not explicitly stated, the number of nodes (N) is set to 100. The simulations encompass dynamics from time t = 0 to T or Tend with a step-size dt. Table A1 shows the initial conditions, sampling intervals, and end time of inferring and predicting used to simulate network dynamics data."}, {"title": "Appendix B Details of Neural Architectures in Signal Decoupling", "content": "The detailed architectures of the neural networks $\\hat{f}$, $\\psi^{90}$, $\\psi^{91}$ and $\\psi^{92}$ in $Q^{(self)}$ and $Q^{(inter)}$ are shown in Table B2. They were trained using a random division of the times-"}, {"title": "Appendix C More Results of Inferring", "content": ""}, {"title": "C.1 Comparison of discovered equations", "content": "Table C3 shows the discovered equations for each network dynamics scenario, demonstrating the ability of various methods to learn interpretable network dynamics. TPSINDy-HB with only the basic operations and TPSINDy-Hw with lacking the function terms of the ground truth struggle to infer the correct form of the equations for all dynamics systems. Although TPSINDY-HN with a library that has the same function terms as ground truth and TPSINDy-HR with sufficient basis functions can partially restore the terms of the equation, they still fails to accurately infer the coefficients. That is to say, improper basis library settings due to a lack of prior knowledge make it even more difficult for the TPSINDy to identify the correct dynamics equations.\nOn the contrary, the proposed LLC can directly infer the dynamics equations accurately from the node states. Additionally, it can further enhance the TPSINDy. When terms obtained through the LLC are used as the basis function terms for the TPSINDy, the sparse regression method can accurately identify the dynamics equations, which can be supported by comparing the discovered equations of TPSINDy-HN and LLC+TPSINDy."}, {"title": "C.2 More performance comparison", "content": "In addition to the two indicators presented in the main text, i.e., R2 score and Recall, we introduce more performance comparison metrics here to provide a more comprehensive comparison.\n\u2022 Mean Relative Error. MRE is the mean absolute difference between the predicted and true values divided by the absolute value of the true values. It considers the scale of the true value, so it is universal for data of different magnitudes, so as to provide consistent evaluation across different problems and datasets, which can be calculated as\n$MRE = \\frac{1}{TN} \\sum_{i=1}^{N} \\sum_{t=1}^{T} \\frac{|\\hat{X_i}(t) \u2013 X_i(t)|}{|X_i(t)|}$, where, N and T are the number of system nodes and the maximum prediction time, respectively. Xi(t) is the predicted state of node i at time t, and Xi(t) is the ground truth.\n\u2022 Mean Absolute Error. MAE quantifies the mean absolute error between the predictions and the true values over all nodes and at all times, which can be calculated as\n$MAE = \\frac{1}{NT} \\sum_{i=1}^{T} \\sum_{t=1}^{T} |\\hat{X_i}(t) \u2013 X_i(t)|$, where, N and T are the number of system nodes and the maximum prediction time, respectively. Xi(t) is the predicted state of node i at time t, and Xi(t) is the ground truth.\n\u2022 L2 error. This error gives an idea of how close the identified coefficients are to the true coefficients in a relative sense, which can be seen as a quantitative indicator of whether the discovered equation is correct in form.\nL2 $error = \\frac{\\overline{\\xi_{pre}} - \\overline{\\xi_{true}}|^2}{\\overline{\\xi_{true}}|^2}$ where $\\overline{\\xi_{pre}}$ represents the equation coefficients identified by a method and $\\overline{\\xi_{true}}$ represents true coefficients.\n\u2022 Precision. This statistic measures the percentage of correctly identified coefficients among the total number of identified coefficients, which can be calculated as\n$P = \\frac{|\\overline{\\xi_{pre}} \\cdot \\overline{\\xi_{true}}|_0}{|\\overline{\\xi_{pre}}|_0}$, where $\\cdot$ represents the element-by-element product of two vectors, |_0 denotes the number of non-zero elements in the vector."}, {"title": "Appendix D Robustness evaluation", "content": "To evaluate the robustness of our tool, we test the performance when observations are noisy or when topological structures are missing. We choose the Kuramoto dynamics [82], a mathematical model for studying how a set of mutually coupled oscillators can synchronize by interacting with each other, to evaluate the robustness, which can be formulated as\n$\\dot{X_i}(t) = \\omega_i + \\epsilon \\sum_{j=1}^N A_{i,j} sin(X_j(t) \u2013 X_i(t))$,"}, {"title": "Appendix E Multi-Dimensional and Heterogeneous Network Dynamics", "content": ""}, {"title": "E.1 FitzHugh-Nagumo dynamics", "content": "The FitzHugh-Nagumo model (FHN) [54] is a neuron model used to describe the excitatory behavior of neurons, which is a simplified version of the Hodgkin-Huxley model and mainly used to study the action potentials of neurons. It can be defined by a set of two ordinary differential equations that capture the main features of excitability in neural membrane"}, {"title": "E.2 Predator-prey system", "content": "The predator-prey (PP) is a heterogeneous system [59], where node state is the individual's position, but nodes are divided into two roles, i.e., a predator (i = 0) and many preys"}, {"title": "Appendix F Chaotic Networks Dynamics", "content": ""}, {"title": "F.1 Lorzen system", "content": "Coupled Lorzen system [60] exhibits chaotic properties, in particular sensitive dependence on initial conditions, which means that even small changes in initial conditions can lead to significantly different system behavior. To verify whether the proposed LLC is sensitive to initial values, we apply it to the coupled Lorzen system systems with different initial values and examine whether the discovered governing equations are consistent.\nSpecifically, we apply our LLC to a coupled Lorzen system [60] governed by\n$\\begin{cases} \\dot{X_{i,1}}(t) = a(X_{i,2}(t) \u2013 X_{i,1}(t)) + \\epsilon \\sum_{j=1}^N A_{i,j} (X_{j,1}(t) \u2013 X_{i,1}(t)),\\\\ \\dot{X_{i,2}}(t) = rX_{i,1}(t) \u2013 X_{i,1}(t)X_{i,3}(t) \u2013 X_{i,2}(t), \\\\ \\dot{X_{i,3}}(t) = X_{i,2}(t)X_{i,1}(t) \u2013 bX_{i,3}(t), \\end{cases}$ where a = 10, \u0454 = 0.05, r = 28 and $b = \\frac{8}{3}$ are system parameters. Here, the interactions are assumed to occur between the first component $X_{i,1}$ without lack of generalization. Then, we employ a BA network with N = 100 as the topological structure to produce the dynamics data of the Lorenz. We set the end time T = 3, Tend = 100 and time step dt = 0.01.\nWe establish three distinct initial conditions as follows:\n\u2022 Initial condition 1: A Gaussian distribution with zero mean and one variance;\n\u2022 Initial condition 2: A uniform distribution within the range (0, 2);\n\u2022 Initial condition 3: A fixed initial value of 0.1."}, {"title": "F.2 R\u00f6ssler system", "content": "By comparing the TPSINDy on the R\u00f6ssler system, our LLC restores more accurate governing equations (Fig. 5(c)) and has smaller predictive errors (Fig. 5(d)). We also analyze the state transition behavior of the R\u00f6ssler system, and it is evident from the comparison of bifurcation diagrams generated by the inferred and true equations that period-doubling patterns and the bifurcation points are consistent, showing the transition process from period-1 to period-2, to period-4, to chaos, then to period-3, and finally to chaos again (see Fig. 5(e)).\nWe also consider a coupled R\u00f6ssler system, which are often used in classical models to study chaotic dynamics and synchronization phenomena in complex systems. The chaotic states data is generated by the governing equations as\n$\\begin{cases} \\dot{X_{i,1}}(t) = -X_{i,2} \u2013 X_{i,3} + \\epsilon \\sum_{j=1}^N A_{i,j} (X_{j,1} \u2013 X_{i,1}) \\\\ \\dot{X_{i,2}}(t) = X_{i,1} + aX_{i,2} \\\\ \\dot{X_{i,3}}(t) = b + X_{i,3}(X_{i,1} \u2013 c) \\end{cases}$ (F1) where \u20ac = 0.15, a = 0.2, b = 0.2 and c = 5.7 are system parameters. We employ a BA network with N = 100 as the topological structure to produce the dynamics data of the system. We set the end time T = 3, Tend = 100 and time step dt = 0.01."}, {"title": "Appendix G Empirical Systems", "content": ""}, {"title": "G.1 Real-world global epidemic transmission", "content": "We collect daily global spreading data on COVID-19 [62], and use the worldwide airline network retrieved from OpenFights [63] as a directed and weighted empirical topology to build an empirical system of real-world global epidemic transmission. Only early data before government intervention, i.e., the first 45 days, are considered here to maintain the spread characteristics of the disease itself. For example, if a country reports its first case on January 19, data from January 19 to March 3 are used. It is worth noting that although the start of transmission varies across countries, in the interaction dynamics $Q^{(inter)}$ time t corresponds to the same calendar date for all nodes. Our setup is consistent with [8]. Fig. G9 shows the comparative results of the number of cases over time in sufficient countries or regions generated by TPSINDy, LLC, and LLC+TPSINDy, demonstrating the effectiveness of our LLC in discovering new symbolic models for real scenario with unknown dynamics."}, {"title": "G.2 Pedestrian dynamics", "content": "For the crowd trajectory dataset, we use an experimental dataset from a pedestrian dynamics study: unidirectional flow in a corridor: a group of people crossing a corridor in the same direction [64]. Specifically, the experimental data collected at a fixed time interval of"}]}