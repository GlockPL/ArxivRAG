{"title": "ANYECG: FOUNDATIONAL MODELS FOR\nELECTROCARDIOGRAM ANALYSIS", "authors": ["Yue Wang", "Xu Cao", "Yaojun Hu", "Haochao Ying", "James Matthew Rehg", "Jimeng Sun", "Jian Wu", "Jintai\nChen"], "abstract": "Electrocardiogram (ECG), a non-invasive and affordable tool for cardiac monitoring, is highly\nsensitive in detecting acute heart attacks. However, due to the lengthy nature of ECG recordings,\nnumerous machine learning methods have been developed for automated heart disease detection to\nreduce human workload. Despite these efforts, performance remains suboptimal. A key obstacle is\nthe inherent complexity of ECG data, which includes heterogeneity (e.g., varying sampling rates),\nhigh levels of noise, demographic-related pattern shifts, and intricate rhythm-event associations. To\novercome these challenges, this paper introduces AnyECG, a foundational model designed to extract\nrobust representations from any real-world ECG data. Specifically, a tailored ECG Tokenizer encodes\neach fixed-duration ECG fragment into a token and, guided by proxy tasks, converts noisy, continuous\nECG features into discrete, compact, and clinically meaningful local rhythm codes. These codes\nencapsulate basic morphological, frequency, and demographic information (e.g., sex), effectively\nmitigating signal noise. We further pre-train the AnyECG to learn rhythmic pattern associations\nacross ECG tokens, enabling the capture of cardiac event semantics. By being jointly pre-trained on\ndiverse ECG data sources, AnyECG is capable of generalizing across a wide range of downstream\ntasks where ECG signals are recorded from various devices and scenarios. Experimental results\nin anomaly detection, arrhythmia detection, corrupted lead generation, and ultra-long ECG signal\nanalysis demonstrate that AnyECG learns common ECG knowledge from data and significantly\noutperforms cutting-edge methods in each respective task.", "sections": [{"title": "1 Introduction", "content": "The electrocardiogram (ECG) is a widely used test that records the heart's electrical activity, facilitating the monitoring\nand diagnosis of various cardiac conditions. Due to variations in ECG devices, recording conditions, patient charac-\nteristics, the length of recorded ECG signals, the number of leads, the sampling rates, as well as the signal-to-noise\nratio (SNR), can vary significantly. For example, in non-clinical settings, wearable devices typically collect long-term\nsingle-lead or dual-lead ECG signals at lower sampling rates, covering a variety of human activity scenarios, which\noften results in higher noise levels [1, 2]. In contrast, standard devices used in hospital outpatient clinics capture high-"}, {"title": "2 Methodology", "content": "Our proposed AnyECG adopts a common Transformer architecture, incorporating a novel attention module and a\nspecial tokenizer that can be adapted to both the self-supervised learning pretraining pipeline and various downstream\ntasks for any ECG signals, as shown in Figure 1. The self-supervised learning process of AnyECG is divided into two\nphases: pretraining the ECG Tokenizer and pretraining the AnyECG backbone."}, {"title": "2.1 AnyECG Architecture", "content": "ECG Signal Pre-Processing. To preserve the natural characteristics of the ECG signals, we applied minimal pre-\nprocessing steps aimed at reducing noise while maintaining signal integrity. First, we used a bandpass filter between 0.1\nHz and 75 Hz to remove low-frequency noise, followed by a notch filter at 50 Hz to eliminate power-line interference.\nThe ECG signals were then resampled to 300 Hz to standardize the sampling rate across all data sources, as 300 Hz is\nconsidered sufficient for diagnosing most cardiac conditions based on the Nyquist-Shannon sampling theorem. Finally,\nwavelet-based denoising was performed using the 'db6' wavelet, following [7]. To align with the Transformer input\nformat, a multi-channel ECG signal $X \\in \\mathbb{R}^{L\\times T}$ (where $L$ represents the number of ECG leads (channels), and $T$\ndenotes the total number of recorded temporal points) was segmented along the time axis into fixed-duration patches of\nsize $s$. This divides each lead into $P$ patches, where $P$ is the minimal positive integer satisfying $P \\times s > T$. If $T$ is\nnot divisible by $s$, we pad the signal with zeros at the end to reach a length of $Ps$. Each patch $x_{j,k} \\in \\mathbb{R}^{s}$ is defined\nas $x_{j,k} = X_{j, (k-1)s+1:ks}$, where $j = 1, 2, . . ., L$ denotes the lead index and $k = 1, 2, . . ., P$ denotes the patch index\nalong the time axis. The total number of patches is $N = L \\times P$, and we flatten them into a patch sequence $X' \\in \\mathbb{R}^{N \\times s}$\nof length $N$ before feeding it into the model.\nECG Tokenizer. The objective of ECG Tokenizer is to effectively capture both the temporal and spatial features of\nECG signals and generate an embedding $H \\in \\mathbb{R}^{N\\times d}$ from $X'$. We firstly use a temporal encoder to learn local temporal\npatterns by independently processing each ECG patch $x_{j,k}$. The temporal encoder consists of one 1D convolution, a\ngroup normalization, and a GELU activation function. Then, a spatial encoder with 4 Transformer blocks is used. Each\npatch $x_{j,k}$ is processed by the temporal encoder and spatial encoder sequentially to obtain an embedding $h_{j,k} \\in \\mathbb{R}^{d}$.\nTo enhance the model's understanding of the temporal sequence and leads relationships, learnable temporal position\nencoding $T_{k} \\in \\mathbb{R}^{d}$ and lead position encoding $o_{j} \\in \\mathbb{R}^{d}$ are along the temporal dimension $k$ and channel dimension $j$,\nseparately. The output of the ECG Tokenizer is the temporal-spatial encoding $h_{j,k} = h'_{j,k} + T_{k} + 0_{j}$.\nCross-Mask Attention (CMA). Unlike other sequential data like text, ECG signals typically include multiple leads,\nwith the signals at the same positions across leads providing complementary information [8]. Therefore, in contrast to\nconventional multi-head self-attention, we introduce CMA, which differentiates the structure of our AnyECG. CMA\nallows each patch to interact only with patches within relevant channels (i.e. leads) and temporal contexts. We apply"}, {"title": "2.2 ECG Tokenizer Pretraining", "content": "2.2.1 ECG Tokenizer with Rhythm Codebook\nMotivation. ECG signals are inherently high-dimensional time-series data, often characterized by a low SNR due\nto sparse key information and contamination from various types of noise. To address these issues, we propose a\nvector-quantized rhythm codebook that transforms raw ECG signals into compact, discrete tokens, enabling robust\nand noise-resistant representation learning. The transformation of rhythm codebook enhances low-SNR signals into a\nhigh-SNR representation, accurately capturing true cardiac activity while minimizing the effects of noise.\nInitially, each patch $x_{j,k} \\in \\mathbb{R}^{s}$ represents a portion of the signal over $w$ time steps in lead $j$. The tokenizer processes\nthese patches into feature representations, yielding embeddings $h_{j,k} \\in \\mathbb{R}^{d}$, where $d$ is the dimension of each embedding.\nTo discretize these continuous embeddings into tokens suitable for subsequent processing, we employ a quantizer that\nmaps each embedding $h_{j,k}$ to the nearest codeword in a predefined codebook $V$. The codebook $V\\in \\mathbb{R}^{K\\times d}$ consists of\n$K$ codes $V_{1}, V_{2}, ..., V_{K}$. The quantization process is defined as:\n$i^* = \\arg \\min_{i\\in{1,2,...,K}} \\frac{||h_{j,k}||_{2}^{2}}{||V_{i}||_{2}^{2}} - \\frac{h_{j,k} \\cdot V_{i}}{||h_{j,k}||_{2} ||V_{i}||_{2}}$\n(2)\nwhere $||\\cdot||_{2}$ denotes the $l_{2}$-norm, and normalization ensures that the distance measure is equivalent to maximizing the\ncosine similarity. The assigned discrete token index for the patch $x_{j,k}$ is index $i^*$. This process effectively quantizes the\nECG signal into a sequence of discrete tokens ${z_{j,k}}$, reducing the influence of noise and enhancing the signal quality.\nBy transforming the ECG data into a low dimension and high-SNR tokenized representations $z_{j,k}$, the ECG Tokenizer\nenables the model to focus on the meaningful aspects of the cardiac signal, such as heartbeat patterns and rhythms,\nwhich improves the model's ability to generalize across different datasets."}, {"title": "2.2.2 Multi-View Synergistic Decoder", "content": "To better capture the demographic variations and morphological changes inherent in ECG signals, we propose a\nMulti-View Synergistic Decoder containing three decoders for different proxy tasks.\nMorphology Decoder aims to reconstruct the original temporal ECG signals, focusing on preserving time-domain\ninformation critical for identifying features like QRS complexes and arrhythmia. By reconstructing the time-domain\nsignals, we ensure that the essential temporal characteristics of the cardiac cycles are retained, providing a foundation\nfor accurate heartbeat analysis. The reconstruction loss for the Morphology Decoder is defined as:\n$L_{morphology} = \\sum_{j=1}^{C}\\sum_{k=1}^{P}||o_{j,k}^{m} - x_{j,k}||_{2}^{2}$\n(3)\nwhere $o_{j,k}^{m}$ is the output of the Morphology Decoder for patch $x_{j,k}$.\nFrequency Decoder predicts the frequency characteristics of ECG signals by incorporating frequency-domain\ninformation, which is essential for capturing periodic and spectral features associated with cardiac conditions. Unlike\ntraditional methods that focus solely on time-domain or frequency features, this decoder leverages the Discrete Wavelet"}, {"title": "2.3 AnyECG Masked Pre-training", "content": "Inspired by self-supervised learning from masked modeling in NLP [10] and vision [11, 12], we design a hybrid-scale\nmasked ECG modeling strategy, where random segments of ECG signals are masked and the model is learned to\nreconstruct missing parts.\nAfter using ECG Tokenizer process $X'$ to embeddings $H \\in \\mathbb{R}^{N\\times d}$, we randomly generate a mask $M \\in \\mathbb{R}^{N\\times 1}$, where\nits component $m_{j,k} \\in {0,1}$. The masked patches are replaced with a learnable mask token $h_{M} \\in \\mathbb{R}^{d}$. The masked\nembeddings $h_{j,k}$ are defined as: $h_{j,k} = (1-m_{j,k}) \\cdot h_{j,k}+m_{j,k} \\cdot h_{M}$. These augmented embeddings $h_{j,k}$ are then reshaped\ninto a sequential format and fed into a Transformer encoder to generate contextualized representations $\\hat{h_{j,k}} \\in \\mathbb{R}^{d}$. Each\ncontextualized vector $\\hat{h_{j,k}}$ is passed through a linear classifier followed by a softmax function to produce a probability\ndistribution over the codebook tokens $V = {V_{1}, V_{2}, ..., V_{K}}$: $p(v_{i} | H) = softmax (W\\hat{h_{j,k}} + b)$,\nwhere $H$ denotes\nthe collection of all augmented embeddings $h_{j,k}$, and the subscript $i$ refers to the $i$-th element of the output vector. The\ntraining objective for the masked modeling process is to minimize the negative log-likelihood of predicting the correct\ntokens $V_{z_{j,k}}$ at the masked positions:\n$L_{mask} = -\\sum_{j=1}^{L} \\sum_{k=1}^{P} m_{j,k} log p (V_{z_{j,k}} | H)$\n(9)\nThe masked pretraining facilitates the model in learning generic representations from the input data by capturing the\nimplicit rhythm-event associations and sequential relationships crucial for ECG analysis, thereby enhancing its ability\nto capture the underlying cardiac event patterns in the ECG signals."}, {"title": "3 Downstream Application", "content": "This section evaluates AnyECG's performance across multiple ECG datasets to prove its generality. In Section 3.1, we\nsummarize datasets utilized in the experiments. Section 3.2 explains the experimental setup in detail. In Section 3.3, we\npresent the results of our experiments, benchmarking AnyECG against state-of-the-art methods across multiple tasks,\nincluding anomaly detection, arrhythmia detection, ECG lead generation, and ultra-long ECG sequence recognition.\nIn Section 7.4 and 7.3, we also present ablation studies on hyperparameter selection and the necessity of two-stage\npre-training."}, {"title": "3.1 ECG Datasets", "content": "To evaluate the performance of AnyECG and baseline models, we utilized a comprehensive set of ECG datasets that\ninclude all available unlabeled data during pretraining. These datasets cover a wide spectrum of cardiac conditions,\npatient demographics, and recording scenarios, ensuring robust testing across diverse settings. For various downstream\ntasks, we mixed all datasets together to minimize biases introduced by individual datasets and to better validate the\nmodel's generalizability. This approach reduces the discrepancies arising from different data sources and enhances the\nunified capability of the model. The detailed data construction of the datasets can be found in Table 1. All datasets are\nformatted in WFDB format, including associated binary and text files that detail signal attributes and clinical annotations\nusing SNOMED-CT codes. Detailed information about the datasets is provided in Appendix 7.1."}, {"title": "3.2 Experimental Setup", "content": "Model Configurations. We introduce three configurations of AnyECG: AnyECG-B, AnyECG-L, and AnyECG-XL,\ncontaining 254M, 500M, and 1.7B parameters, respectively. The increase in parameters is achieved by deepening the\nTransformer encoder and expanding the hidden layer sizes. To maintain consistency across all configurations, we set\nthe patch size P = 300, which corresponds to 1 second of ECG data. The maximum sequence length is fixed at 1,024\ntokens, sufficient for most ECG applications. During ECG Tokenizer training and AnyECG pre-training, sequences\nshorter than this length are padded. To preserve data integrity, we mask the attention values associated with these\npadding tokens.\nTraining Environment. The pre-training of AnyECG was conducted on a comprehensive dataset compiled from\nseven different sources. For the downstream tasks, data splitting followed standard procedures, dividing the data into\ntraining and validation subsets using an 80/20 ratio. Binary cross-entropy loss was employed for binary classification\ntasks, while cross-entropy loss was utilized for multi-class classification tasks. Evaluation metrics for the downstream\ntasks are detailed in the Appendix 7.2. All experiments were executed on a computing cluster equipped with eight\nhigh-performance GPUs. We used the Adam optimizer with a learning rate of 1e-4 for all models training. Model\nselection was based on the best performance on validation sets, and final evaluations were conducted on separate test\nsets. To ensure the reliability of our results, performance metrics\u2014including averages and standard deviations\u2014were\nreported across five random seeds."}, {"title": "3.3 Experimental Results", "content": "Anomaly Detection. In anomaly detection, we define normal category data as positive samples, with all other\ncategories treated as anomalous samples. Table 2 compares AnyECG to state-of-the-art models in the anomaly\ndetection task. AnyECG consistently outperforms other advanced models across all evaluation metrics. Specifically,\nthe largest variant, AnyECG-XL, achieves the highest scores in accuracy, AUC-PR, AUROC, and Weighted F1 Score,\ndemonstrating its strong ability to capture ECG signal characteristics. In contrast, traditional models like DENS-\nECG [17] and ContraWR [18] show lower performance. DENS-ECG achieves moderate scores in accuracy and\nWeighted F1 Score, while ContraWR falls short in both metrics. Even the smaller versions of AnyECG, such as\nAnyECG-B and AnyECG-L, perform competitively and surpass most baseline models. This indicates that AnyECG\nmaintains high performance across different scales without requiring extensive model parameters. Notably, the finetuned\nECG-FM model [19] performs at an intermediate to above-average level compared to the baseline. However, as a\npre-trained model, its performance may still be hindered by substantial differences between the pre-training data and\nthe downstream task dataset, which likely impedes its ability to fully converge.\nArrhythmia Detection. Table 3 presents a performance comparison between AnyECG and other leading models in\narrhythmia detection. The results show that AnyECG, particularly the AnyECG-XL variant, consistently outperforms\ncompeting models across all metrics. This demonstrates its strong ability to handle arrhythmia detection effectively. In\ncontrast, models like DENS-ECG [17] and ContraWR [18] exhibit lower performance. Notably, although ECG-FM [19]\nemploys pretraining, it achieves significantly lower accuracy. This underscores AnyECG's robustness, as its consistent\nperformance across all metrics confirms its suitability for real-world arrhythmia detection."}, {"title": "4 Related Works", "content": "Heterogeneous ECG Signal Analysis and\nClassification. The application of deep\nlearning techniques has significantly ad-\nvanced the analysis and classification of ECG\nsignals. However, the heterogeneity of ECG\ndata poses a major challenge for model gen-\neralization; models trained on one dataset of-\nten do not perform well on others. Conse-\nquently, researchers have focused on design-\ning specialized models tailored to specific\ndatasets, employing architectures such as con-\nvolutional neural networks (CNNs) [28, 29],\nrecurrent neural networks (RNNs) [30, 31], and transformer-based models [32, 33]. While these efforts have led to\nincremental performance improvements [34, 35, 36, 37], the gains are often not statistically significant due to the limited\nsize and scope of the datasets used. The absence of a unified model capable of handling the diverse nature of ECG\ndata underscores the need for new approaches that can provide more substantial and broadly applicable performance\nimprovements.\nSelf-supervised ECG Representation Learning. Self-supervised learning has emerged as a promising approach\nfor extracting representations from unlabeled ECG signals, enabling the use of large amounts of raw data without\nmanual annotations. Methods such as signal reconstruction, contrastive learning, and masked signal modeling have\nbeen explored [38, 39, 40]. However, existing self-supervised learning methods often struggle to generalize across\nheterogeneous ECG datasets, especially when faced with varying lead configurations and noise levels. For example,\ncontrastive methods [41, 42] encourage similar representations for compatible signal segments but do not adequately\naccount for variability introduced by different lead setups. Moreover, the low SNR inherent in ECG data can cause\nmodels to focus on reconstructing noisy or redundant signal components due to high correlations among leads, rather\nthan capturing critical physiological information. Models like contrastive predictive coding (CPC) [43] and masked\nautoencoders [44, 45] often inadvertently emphasize less relevant features, diminishing their effectiveness in capturing\nessential signal characteristics. This focus on less informative aspects can limit the models' ability to extract meaningful\nrepresentations that transfer effectively to unseen data or datasets with different characteristics."}, {"title": "5 Discussion", "content": "Social Impacts. ECG is one of the most commonly used diagnostic tools in healthcare, with over 100 million ECG\nreports obtained annually in the United States alone [46]. Despite its widespread use, unlike other biomedical signals\nsuch as electroencephalograms (EEG) [47, 48], there is a scarcity of foundation models specifically designed for ECG\ndata. This limitation hampers the potential for advanced analysis and interpretation of ECG signals on a large scale. In\nthis work, we propose AnyECG, the largest ECG foundation model family to date. Compared to prior works [19, 49, 50],\nAnyECG adapts to diverse downstream tasks and achieves significantly better performance. By providing a robust and\ngeneralizable model for ECG data, AnyECG has the potential to greatly enhance diagnostic accuracy, facilitate early\ndetection of cardiovascular diseases, and improve patient outcomes on a broad scale.\nLimitations. Although we pre-trained AnyECG using a large amount of data across seven datasets, there remains\na significant gap between AnyECG and current foundation models like LLMs in the general domain. This gap is\nprimarily due to the difficulty in obtaining extensive healthcare data. Additionally, the model size of AnyECG-XL\n(1.7B parameters) is considerably smaller than that of foundation models in natural language processing and computer\nvision fields. Despite these limitations, it is important to highlight that training a large-scale ECG foundation model\nwith a two-stage self-supervised learning approach and more data does yield appreciable performance gains compared\nto existing methods developed for specific downstream tasks, even if it may be computationally costly. Exploring the\ntrade-off between employing larger AnyECG models and enhancing downstream task performance will be a focus of\nour future work."}, {"title": "6 Conclusion", "content": "In this paper, we proposed AnyECG, a foundation model family that learns universal embeddings through a two-stage\nself-supervised pre-training on seven diverse ECG datasets. AnyECG effectively handles the heterogeneity of ECG data\nthrough the design of a novel ECG Tokenizer, which includes a rhythm codebook and a multi-view synergistic decoder\nto learn representations from different proxy tasks. Additionally, the masked modeling in the second-stage pre-training\nplays a crucial role in enabling effective representation learning of both temporal and lead features of ECG signals. We\nvalidated various sizes of AnyECG models on multiple downstream tasks, including anomaly detection, arrhythmia\ndetection, ECG lead generation, and ultra-long ECG signal recognition. Our experiments demonstrate that AnyECG\noutperforms all state-of-the-art methods in their respective fields, highlighting its effectiveness and versatility in ECG\nsignal analysis."}, {"title": "7 Appendix", "content": "7.1 ECG Datasets\nTo evaluate the performance of AnyECG and baseline models, we utilized a comprehensive set of ECG datasets that\ncover a wide spectrum of cardiac conditions, patient demographics, and recording scenarios, ensuring robust testing\nacross diverse settings. The datasets include:\nCPSC and CPSC-Extra Databases [13]: These consist of 12-lead ECG recordings ranging from 6 to 60 seconds in\nduration, sampled at 500 Hz, and include a balanced mix of male and female subjects.\nINCART Database [14]: This database provides 74 annotated recordings extracted from 32 Holter records, each 30\nminutes long and sampled at 257 Hz, offering high-resolution data ideal for arrhythmia classification.\nPTB [15] and PTB-XL Databases [16]: The PTB Diagnostic ECG Database includes 516 recordings sampled at 1000\nHz, while PTB-XL contains 21,837 12-lead ECGs sampled at 500 Hz, each 10 seconds long, encompassing a wide\nrange of cardiac pathologies.\nGeorgia 12-lead ECG Challenge (G12EC) Database: Comprising 10,344 recordings from the Southeastern United\nStates, sampled at 500 Hz, this dataset adds demographic diversity to our evaluation.\nUndisclosed Database: This dataset contributes an additional 10,000 ECG recordings, providing a geographically\ndistinct test set to further validate the model's performance without data leakage."}, {"title": "7.2 Evaluation Metrics", "content": "We conducted four distinct experiments, each utilizing a specific set of evaluation metrics tailored to the task:\n1. Anomaly Detection: Evaluated using Accuracy, AUC-PR (Area Under the Precision-Recall Curve), AUROC (Area\nUnder the Receiver Operating Characteristic Curve), and Weighted F1 Score. These metrics assess the model's ability\nto correctly identify anomalies and handle class imbalances effectively.\n2. Arrhythmia Detection: Assessed with Accuracy, AUC-PR, Weighted F1 Score, and Precision. This combination\nof metrics evaluates the model's performance in detecting various types of arrhythmias, emphasizing both overall\naccuracy and the precision of positive predictions.\n3. Corrupted Lead Generation: Measured using PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity\nIndex), and MAE (Mean Absolute Error). These metrics quantify the quality of the generated ECG signals by comparing\nthe reconstructed signals to the original ones, focusing on signal fidelity and structural similarity.\n4. Ultra-Long ECG Recognition: Evaluated using Accuracy, AUC-PR, AUROC, and Weighted F1 Score. These\nmetrics measure the model's effectiveness in accurately identifying anomalies and handling class imbalances.\nThe definitions of the evaluation metrics used across these experiments are as follows: Accuracy: The proportion of\ncorrectly predicted instances out of all instances, indicating the overall effectiveness of the model. Precision: The\nratio of true positive predictions to the total number of positive predictions, reflecting the model's ability to avoid false\npositives. AUC-PR (Area Under the Precision-Recall Curve): Measures the trade-off between precision and recall for\ndifferent threshold settings, particularly useful for imbalanced datasets. AUROC (Area Under the Receiver Operating\nCharacteristic Curve): Represents the model's ability to distinguish between classes across all classification thresholds.\nWeighted F1 Score: The harmonic mean of precision and recall, weighted by the number of true instances for each\nclass, providing a balanced evaluation of the model's performance. PSNR (Peak Signal-to-Noise Ratio): Indicates the\nquality of signal reconstruction by comparing the maximum possible signal power to the power of reconstruction noise,\nwith higher values signifying better quality. SSIM (Structural Similarity Index): Assesses the similarity between two\nsignals in terms of luminance, contrast, and structure, with values closer to 1 indicating higher similarity. MAE (Mean\nAbsolute Error): Represents the average absolute difference between predicted and actual values, serving as a measure\nof prediction accuracy. By employing these tailored metrics across different experiments, we ensure a comprehensive\nevaluation of our model's performance in various aspects of ECG signal processing and classification."}, {"title": "7.3 Pre-training Phase Ablation Study", "content": "To evaluate the contribution of each component in our pre-training strategy, we conducted an ablation study focusing on\nthe pre-training phases. Specifically, we analyzed the effects of pre-training the ECG Tokenizer and the full AnyECG\nfoundation model on anomaly detection performance. Table 6 and Figure 3 presents the results of this study. The first\nconfiguration is AnyECG-B without ECG Tokenizer pre-training. The second configuration includes a pre-trained ECG\nTokenizer but skips pre-training the AnyECG foundation model. The final configuration involves full pre-training of\nboth the ECG Tokenizer and the AnyECG. The results show that pre-training the ECG Tokenizer leads to noticeable\nimprovements over the baseline. This indicates that a pre-trained ECG Tokenizer enhances the model's ability to\ncapture meaningful representations of the ECG signals. When the full AnyECG foundation model is also pre-trained,\nwe observe a significant performance boost across all metrics. These gains underscore the importance of comprehensive\npre-training in enhancing the model's anomaly detection capabilities. The fact that full pre-training yields the best\nresults confirms that both components\u2014the ECG Tokenizer and the AnyECG\u2014contribute positively to the overall\nperformance. Pre-training the AnyECG foundation model allows it to learn generalizable features that are beneficial for\ndownstream tasks, while the pre-trained ECG Tokenizer ensures effective encoding of the input signals."}, {"title": "7.4 Loss Function Ablation Study", "content": "To assess the effectiveness of our loss function design, we conducted an ablation study by systematically removing\neach component of the loss function. This allowed us to evaluate how each term contributes to the model's ability to\ncapture meaningful features from ECG signals. Table 7 presents the results of this study. The \"Full Loss\" configuration,\nwhich includes all components of our proposed loss function, serves as the baseline for optimal performance. When\nwe individually removed each loss component, we observed a decrease in performance across all evaluation metrics.\nOmitting the Morphology Loss resulted in a noticeable decline, indicating its significant role in helping the model capture"}, {"title": "7.5 Notations", "content": "Data and Indices\nX \u2208 RL\u00d7T\nL\nT\nS\nMulti-channel ECG signals\nNumber of ECG leads\nTotal time steps\nPatch size (time steps)"}]}