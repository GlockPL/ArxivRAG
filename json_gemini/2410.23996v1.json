{"title": "AN INFORMATION CRITERION FOR CONTROLLED DIS-ENTANGLEMENT OF MULTIMODAL DATA", "authors": ["Chenyu Wang", "Sharut Gupta", "Xinyi Zhang", "Sana Tonekaboni", "Stefanie Jegelka", "Tommi Jaakkola", "Caroline Uhler"], "abstract": "Multimodal representation learning seeks to relate and decompose information in-herent in multiple modalities. By disentangling modality-specific information from information that is shared across modalities, we can improve interpretability and robustness and enable downstream tasks such as the generation of counterfactual outcomes. Separating the two types of information is challenging since they are often deeply entangled in many real-world applications. We propose Disentangled Self-Supervised Learning (DISENTANGLEDSSL), a novel self-supervised approach for learning disentangled representations. We present a comprehensive analysis of the optimality of each disentangled representation, particularly focusing on the scenario not covered in prior work where the so-called Minimum Necessary Information (MNI) point is not attainable. We demonstrate that DISENTANGLEDSSL successfully learns shared and modality-specific features on multiple synthetic and real-world datasets and consistently outperforms baselines on various downstream tasks, including prediction tasks for vision-language data, as well as molecule-phenotype retrieval tasks for biological data.", "sections": [{"title": "INTRODUCTION", "content": "Humans understand and interact with the world using multiple senses, each providing unique and complementary information essential for forming a comprehensive mental representation of the environment. To emulate human-like perception, multimodal representation learning seeks to decipher complex systems by combining information from multiple modalities into holistic representations, showcasing significant applications across fields from vision-language to biology. Large multimodal representation learning models such as CLIP, trained through self-supervised learning, maximally capture the mutual information shared across multiple modalities, exploiting the assumption of multi-view redundancy. This property indicates that shared information between modalities is exactly what is relevant for downstream tasks.\nHowever, the modality gap, rooted in the inherent differences in representational nature and information content across modalities, leads to the misalignment between modalities and restricts the application of these methods in many real-world multimodal scenarios. This highlights the need for a disentangled representation space that captures both shared and modality-specific information effectively, elaborated as follows:\n\u2022\nCoverage: Distinct modalities often contribute unique, complementary information crucial for specific tasks, making it essential to capture modality-specific features effectively. For instance, in multimodal sentiment analysis, text conveys explicit sentiment, while vocal tone and facial expressions provide nuanced emotional cues.\n\u2022\nDisentanglement: As emphasized by Zhang et al. (2024) in biological contexts, separating shared from modality-specific information is vital for interpretability and decision-making. However,"}, {"title": "2 \u041c\u0415\u0422\u041dOD", "content": "In this section, we detail our proposed method, DISENTANGLEDSSL, for learning disentangled representations in multimodal data. We begin by outlining the graphical model that formalizes the problem in Section 2.1 and defining the key properties of \u201cdesirable\u201d representations in Section 2.2. Subsequently, we describe the DISENTANGLEDSSL framework in Section 2.3 and provide theoretical guarantees on the optimality of the learned representations. Finally, in Section 2.4, we present the tractable training objectives that facilitate efficient learning for each term of our method."}, {"title": "2.1 MULTIMODAL REPRESENTATION LEARNING WITH DISENTANGLED LATENT SPACE", "content": "DISENTANGLEDSSL learns disentangled representations in latent space, separating modality-specific information from shared factors across paired observations (X1, X2). This generative process is modeled in Figure 2. Each observation is generated from two distinct latent representations: the modality-specific representations (Z and Z32) that contain information exclusive to their respective modalities, and a shared representation (Z) that contains information common to both modalities. We refer to these as the true latents.\nDISENTANGLEDSSL infers the shared repre-sentation from both modalities independently, i.e. \u017d ~ p(\u00b7|X1) and 22 ~ p(\u00b7|X2). The modality-specific information for each modality is encoded by variables 21 and 22. Note that for the true latents, Z and Ze are conditionally dependent on X\u00b9 due to the V-structure in the graphical model. To preserve such dependen-cies in the inferred latents, 21 and 22 are conditioned on both the respective observations and the inferred shared representations, with 2~p(.X\u00b9, 2) and 22 ~ p(.\\X\u00b2, 22)."}, {"title": "2.2 INFORMATION CRITERIA FOR THE OPTIMAL INFERRED REPRESENTATIONS", "content": "We establish information-theoretic criteria to ensure the shared and modality-specific representations are informative and disentangled, capturing key features while minimizing redundancy."}, {"title": "2.2.1 INFORMATION BOTTLENECK PRINCIPLE AND MINIMUM NECESSARY INFORMATION", "content": "The shared representations \u012e and 22 should effectively balance compactness and expressivity, as studied by the information bottleneck (IB) principle in both supervised and self-supervised settings. The IB objective seeks to optimize the representation Z\u00b9 of an observation X\u00b9 in relation to a target variable X2, following the Markov chain Z\u00b9 \u2190 X1 \u2194 X2. It balances the trade-off between preserving relevant information about X2, i.e. I(Z1; X2), and compressing the representation, i.e. I(Z1; X\u00b9) (see more details in Appendix B). The optimal representation should be both sufficient, i.e. I(Z\u00b9; X\u00b2) = I(X\u00b9; X\u00b2), and minimal"}, {"title": "2.2.2 OPTIMAL SHARED REPRESENTATIONS: MNI ATTAINABLE OR NOT", "content": "We propose a definition of optimality for the shared representations that applies to both scenarios\u2014 when MNI is attainable or not, as defined in Equation 1:\n$$Z1^*\t{ = arg min I(Z\u00b9; X\u00b9|X\u00b2), s.t. I(X\u00b9; X\u00b2) \u2013 I(Z\u00b9; X\u00b2) \\le \\delta_{\\epsilon}}$$\n$$Z2^*\t{ = arg min I (Z2; X2|X\u00b9), s.t. I(X\u00b9; X\u00b2) \u2013 I(Z2; X\u00b9) \\le \\delta_{\\epsilon}}$$\n(1)\nFormally, minimizing the conditional mutual information, I(Z1; X1|X2), ensures that the shared representation captures only the information that is truly common to both X\u00b9 and X2, while discarding modality-specific details unique to X\u00b9. Compared with I(Z1; X\u00b9) in IB, it provides a more precise measure of compression and a more robust objective.\nThe constraint I(X1; X2) \u2013 I(Z1; X2) < \u03b4\u03b5 ensures that 21* retains a substantial portion of the shared information between X\u00b9 and X2, controlling the difference within the limit de and preventing significant information loss.\nIn contrast, Achille & Soatto (2018) formulated the optimization as Z\u00b9 = arg min21:21x1.x2 I(X\u00b9; Z\u00b9), s.t. I(Z\u00b9; X\u00b2) = I(X\u00b9; X\u00b2), leading to MNI when attainable. This holds in supervised settings, assuming the data label X2 is a deterministic function of X\u00b9, as used by previous methods. However, in general multimodal self-supervised scenarios where MNI is not attainable, this results in point B in Figure 3, which includes information of X\u00b9 that has little relevance to X2 to satisfy the equality constraint, causing a gap between the objective and the ideal representation."}, {"title": "2.2.3 OPTIMAL SPECIFIC REPRESENTATIONS: ENSURING COVERAGE AND DISENTANGLEMENT", "content": "Optimal modality-specific representations, 21 and 22, should capture information unique to each modality, being highly informative while minimizing redundancy with the shared representations. We hence define them via the optimization problems\n$$Z1^*\t{ = arg max I(Z\u00b9; X\u00b9|X2), s.t. I(Z\u00b9; Z1*) < \\delta_{s}}$$\n$$Z?^*\t{ = arg max I (Z\u00b2; X2\\X\u00b9), s.t. I(Z2; Z?*) \\le \\delta_{s}}$$\n(2)\n$${^2I(Z\u00b9; X\u00b9\\X2) = I(Z\u00b9; X1,X2)-I(Z\u00b9; X\u00b2) = I(Z\u00b9; X\u00b9)\u2212I(Z\u00b9; X\u00b2) = 0,}$$ where the first equality is due to the property of conditional mutual information, and the second is due to the Markov structure Z\u00b9-X1-X2."}, {"title": "2.3 DISENTANGLEDSSL: A STEP-BY-STEP OPTIMIZATION ALGORITHM", "content": "To achieve the optimal representations discussed in Section 2.2, we introduce a two-step training procedure. The first step focuses on optimizing the shared latent representation, ensuring it captures the minimum necessary information as close as possible. Building upon this, the second step utilizes the learned shared representations in step 1 to facilitate the learning of modality-specific representations. This sequential approach is formalized in the optimization objectives given in Equations 3 and 4:\nStep 1: Learn the shared latent representations by encouraging the shared representation encoded from one modality to be highly informative about the other modality, while minimizing redundancy.\n$$21^*\\qquad\\qquad\\qquad\\t{ = arg max \\mathcal{L}^{1} = arg max I(Z^{1}; X^{2}) \u2013 \\beta \\cdot I(Z^{1}; X^{1}|X^{2}) }$$\n$$Z1\\qquad\\qquad\\t{ Z1\\qquad\\qquad }$$\n$$22^* \\t{ = arg max \\mathcal{L}^{2} = arg max I(Z^{2}; X^{1}) \u2013 \\beta \\cdot I(Z^{2}; X^{2}|X^{1}) }$$\n$$Z2\\qquad\\qquad\\t{ Z2\\qquad\\qquad }$$\n(3)\nStep 2: Learn the modality-specific latent representations based on the learned shared representations from step 1.\n$$Z1^*\\t{ = arg max \\mathcal{L} ^{S} = arg max I(Z^{1}, \\tilde{Z}^{2*}; X^{1}) \u2013 \\lambda \\cdot I(Z^{1}; Z1^*) }$$\n$$Z1\\qquad\\qquad\\t{ Z1\\qquad\\qquad }$$\n$$22^*\\t{ = arg max \\mathcal{L}^{S} = arg max I(Z^{2}, \\tilde{Z}^{1*}; X^{2}) \u2013 \\lambda \\cdot I(Z^{2}; Z2^*) }$$\n$$Z2\\qquad\\qquad\\t{ Z2\\qquad\\qquad }$$\n(4)\nThe hyperparameters \u03b2 and A control the trade-off between relevance and redundancy for the shared and modality-specific representations respectively. We use the same values of \u03b2 and A for both modalities since they operate on similar information scales. Our sequential training approach, instead of a joint one, stems from the self-sufficient nature of each optimization procedure where one sub-optimal representation does not enhance the learning of the other. We offer a comprehensive analysis of the optimality guarantees of this step-by-step method as follows."}, {"title": "2.3.1 OPTIMALITY GUARANTEE FOR THE LEARNED SHARED REPRESENTATIONS", "content": "This section explores how the step 1 objective, L1, optimizes the shared representation between modalities by balancing expressivity and redundancy. We discuss its effectiveness in both scenarios-when MNI is attainable or not.\nL seeks representation Z\u00b9 that maximizes the information shared between the modalities, i.e. I(Z\u00b9; X2), while minimizing the information unique to each modality, i.e. I(Z\u00b9; X1|X2), to capture only the essential shared content. This aligns with the conditional entropy bottleneck (CEB) objective, an extension of the IB Lagrangian $$L = I(Z1; X2) \u2212 \u1e9eI(Z1; X\u00b9)$$\nWhile it serves as a robust objective for learning shared information, its optimality remains underexplored in Fischer (2020), particularly when MNI is unattainable. Additionally, Fischer (2020) focuses on the supervised scenario where X2 is the label of X\u00b9, whereas we address the multimodal case with X\u00b9 and X2 being two data modalities, demonstrating its effectiveness in both attainable and unattainable MNI scenarios.\nWhen MNI is attainable, Proposition 1 states that the step 1 optimization achieves MNI for any positive B. The proof is given in Appendix D."}, {"title": "2.3.2 OPTIMALITY GUARANTEE FOR THE LEARNED MODALITY-SPECIFIC REPRESENTATIONS", "content": "In this section, we demonstrate the step 2 objective, L1, ensures optimal coverage and disentanglement by showing its equivalence (or nearly equivalence) to the Lagrangian of Equation 2.\nL in Equation 4 learns the modality-specific representation Z\u00b9 based on the optimal shared repre-sentations 21* and 22* learned from step 1. It maximizes the information coverage of the data X1 through the combination of Z\u00b9 and 22*, i.e. I(Z1, Z2*; X1). Simultaneously, it promotes disentan-glement by limiting overlap with the shared representation 21* of the same modality, indicated by I(Z1; 21*). This objective is a Lagrangian formulation of the constraint optimization in Equation 2, however replacing I(Z1; X1|X2) with I(Z\u00b9, 22*; X\u00b9).\nWhen MNI is attainable, as justified in Proposition 3, this substitution results in an equivalent objective, allowing L\u00b9 to achieve optimal modality-specific representations (proof in Appendix D).\nWhen MNI is unattainable, Proposition 4 shows such substitution yields an almost equivalent objective, subject to the value of de that corresponds to the \u1e9e used in step 1 optimization. Thus, optimizing L results in nearly optimal modality-specific representations (proof in Appendix D)."}, {"title": "2.4 TRACTABLE TRAINING OBJECTIVES", "content": "Four terms are involved in DISENTANGLEDSSL, including maximizing the mutual information term I(Z1; X2) and minimizing the conditional mutual information term I(Z1; X1|X2) for the shared"}, {"title": "3 EXPERIMENTS", "content": "To evaluate the efficacy of our proposed DISENTANGLEDSSL, we conduct a simulation study and two real-world multimodal experiments to address the following key questions:\n\u2022\nHow do \u1e9e and A affect DISENTANGLEDSSL's learned representations compared to baselines in a controlled simulation setting with known ground truth?\n\u2022\nDoes DISENTANGLEDSSL achieve effective coverage of multimodal information in downstream prediction tasks from MultiBench, using a combination of shared and modality-specific representations?\n\u2022\nHow do DISENTANGLEDSSL's representations perform in high-content drug screening datasets, assessed by molecule-phenotype retrieval (for the shared) and a disentanglement measurement (for modality-specific)?\nWe compare DISENTANGLEDSSL against a disentangled variational autoencoder baseline, DM-VAE, as well as various multimodal contrastive learning methods, including CLIP , which aligns different modalities to learn the shared representations, and FOCAL and FactorCL, which capture both shared and modality-specific information. Additionally, we evaluate a joint optimization variant of DISENTANGLEDSSL, JointOpt, to highlight the advantages of our step-by-step approach."}, {"title": "3.1 SIMULATION STUDY", "content": "Synthetic data generation. We generate synthetic data based on the graphical model in Figure 2. We sample d-dimensional true latents Z1, Z2, and Ze independently from N(\u03bc\u03b1, \u03a3). Using fixed transformations T\u2081 and T2, we create X\u00b9 = T\u2081 \u00b7 [Z, Zc] and X2 = T2 \u00b7 [Z2, Ze]. To simulate unattainable MNI, we add Gaussian noise to ensure the distribution has full support. Binary labels Y1, Y2, and Ye are constructed from the true latents and used to evaluate the information content of learned representations via linear probing accuracy. Denote \u017de as the combination of the learned shared representations of X\u00b9 and X2, i.e. \u017de = [\u017d\u00b9, 22]. Ideally, \u017de should achieve high accuracy on"}, {"title": "3.2 MULTIBENCH", "content": "Dataset description. We utilize the real-world multimodal benchmark from MultiBench, which includes curated datasets across various modalities, such as text, images, and tabular data, along with a downstream label that we expect shared and specific information to have varying importance for. These datasets cover a variety of domains including healthcare, affective computing and multimedia research areas. We follow the same setting (dataset splitting, encoder architecture, pre-extracted features) as in Liang et al. (2024). Additional details can be found in Appendix H.2.\nFor FOCAL, we tune the hyperparameters a and \u5165, defined similarly to JointOpt, where a controls the terms I(2; X\u00b9) and I(22; X\u00b2) and X adjusts the orthogonal loss between shared and specific representations. For DMVAE, we tune \u5165 which denotes the weight of the KL divergence term. We show the best-performing results of FOCAL and DMVAE across hyperparameters in Figure 4b, with full results available in Appendix H.1."}, {"title": "3.3 HIGH-CONTENT DRUG SCREENING", "content": "Dataset description. As characterized in Figure 1, we use two high-content drug screening datasets which provide phenotypic profiles after drug perturbation: RXRX19a containing cell imaging profiles, and LINCS containing L1000 gene expression profiles. For RXRX19a, we select data from the HRCE cell line under active SARS-CoV-2 condition, totaling 1,661 drugs and 10,117 profiles (~ 6 replicates per drug). Hand-crafted image features from CellProfiler are used as encoder inputs. For LINCS, we use the data curated in Wang et al. (2023a), selecting drugs with full observations across all 9 core cell lines and randomly sampling 3 replicates per drug to minimize selection bias, resulting in 3,315 drugs and 86,833 profiles. We conduct train-validation-test splitting according to molecules. Models are pretrained to learn representations of molecular structures and their corresponding phenotypes. We provide additional details on experimental settings in Appendix H.3.\nMolecule-phenotype retrieval using shared representations. We evaluate the shared representa-tions in the molecule-phenotype retrieval task, where the goal is to identify molecules from the whole test set that are most likely to induce a specific phenotype. The shared information, which connects the molecular structure and phenotype, plays a key role in this task. We tune \u1e9e according to validation set performance and show results of top N accuracy (N=1,5,10,20,30) and mean reciprocal rank (MRR) on the test set in Table 2. DISENTANGLEDSSL consistently outperforms baselines on both datasets, effectively capturing relevant shared features while excluding irrelevant modality-specific"}, {"title": "4 RELATED WORK", "content": "Disentangled representations in VAEs and GANs. Disentangled representation learning originated from works on Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), focusing on isolating underlying data variations linked to or independent of labels (e.g., digit identity vs. writing style in MNIST) This concept extended to multimodal data like text and image (Lee et al., 2021) and content and pose in video (Denton et al., 2017), typically using self- and cross-reconstruction with adversarial loss to learn shared and specific components. However, these methods often address simple cases with attainable MNI, lacking a comprehensive analysis for complex real-world multimodal scenarios where MNI is not attainable.\nInformation bottleneck and its variants. The information bottleneck (IB) principle has been used to analyze and optimize deep neural networks and the learned representations from the information theory perspective in both supervised and self-supervised settings with extensions like the conditional entropy bottleneck (CEB) being developed to better refine the information plane. IB has been applied to learn molecular representations from drug screening data. However, these approaches primarily focus on extracting shared features while minimizing specific features, limiting their practical use. Other methods learn disentangled representations by optimizing mutual information and using adversarial loss but are confined to single-modality scenarios and do not address complex multimodal settings with unattainable MNI.\nMultimodal disentanglement in self-supervised learning. Recent studies have explored disentan-gled representation learning in multimodal self-supervised contexts. Liang et al. (2024) factorizes and optimizes mutual information bounds to capture the union of shared and unique features, while not penalizing for redundancy between latents. Zhang et al. (2024) learns disentangled representations of cell state for multimodal data in biological contexts. Liu et al. (2024b) and Li et al. (2024) use mutual information optimization with orthogonal/MMD regularizations for disentangling multimodal time-series signals and T-cell receptor segments, respectively. However, these methods lack a general framework for understanding information content, particularly when data modalities are deeply entangled in real-world applications."}, {"title": "5 CONCLUSIONS", "content": "We present DISENTANGLEDSSL, a self-supervised approach for learning disentangled multimodal representations that effectively separates shared and modality-specific features. Built on a compre-hensive theoretical framework, DISENTANGLEDSSL addresses the challenging scenarios where the Minimum Necessary Information (MNI) is unattainable, enhancing its applications to com-plex real-world multimodal settings and improving interpretability and robustness. Our empirical results show that DISENTANGLEDSSL outperforms baselines across various synthetic and real-world datasets, including vision-language prediction tasks and molecule-phenotype retrieval for high-content drug screens, demonstrating its ability to learn optimal disentangled representations for diverse applications."}, {"title": "A ADDITIONAL EXAMPLES OF UNATTAINABLE MNI", "content": "In this section, we present two additional examples where the Minimum Necessary Information (MNI) is unattainable. These examples offer a clear understanding of how unattainable MNI manifests in data, providing practical insights and making the concept more accessible.\nFirstly, we show an example in a simple mathe-matical case. As illustrated in Figure 5, we have true latent variables are independently drawn from a Bernoulli distribution, i.e. Z, Z, Z~ Bernoulli(0.5), and observations X1 and X2 are generated according to X1 = OR(Zc, Z) and X2 = OR(Zc, Z32). In this scenario, if we observe X1 = 1, we are not able to distinguish whether this result is due to Z = 1, or Z = 1, or both. Thus, extracting purely shared features from the observations is infeasible.\nFurther, we provide an example in 3D geometry, as illustrated in Figure 6. For information such as the height of the cone and the number of spheres, one modality conveys the complete information while the other conveys partial information. This ambiguity makes it challenging to classify the information as purely shared or modality-specific, placing it in an uncertain category."}, {"title": "B BACKGROUND ON INFORMATION BOTTLENECK", "content": "The Information Bottleneck (IB) principle provides a powerful theoretical foundation for our method. IB objective seeks to find a representation Z\u00b9 of a random variable X\u00b9 that optimally trades off the preservation of relevant information with compression. Relevance is defined as the mutual information, I(Z1; X2), between the representation Z\u00b9 and another target variable X2. Compression is enforced by constraining the mutual information between the representation and the original data, I(X1; Z\u00b9), to lie below a specified threshold. This is can be formalize in terms of the following constrained optimization problem:\n$$\t{arg max } I(Z^{1}; X^{2}), s.t. I(Z^{1}; X^{1}) < \\delta$$\n(5)\nwhere Z\u00b9 is from a set of random variables that obey the Markov chain Z\u00b9 \u2194 X1 \u2194 X2. In practice, Equation 5 can be optimized by minimizing the IB Lagrangian in Equation 6.\n$$ \\mathcal{L} = I(Z^{1}; X^{1}) \u2013 \\beta I(Z^{1}; Z^{2})$$\n(6)\nHere, the Lagrangian multiplier \u1e9e controls the emphasis placed on compression versus expressiveness."}, {"title": "C PROPERTIES OF THE IB CURVE", "content": "The information plane is a helpful visualization of the information bottleneck principle, which utilizes I(X1; Z\u00b9) and I (X2; Z\u00b9) as its coordinates that represents the trade-off between compression and prediction The frontier of all possible Z\u00b9s is called the IB curve or F(r) as follows:\n$$F(r)\t{ := max I(Z^{1}; X^{2}) s.t. I(X^{1}; Z^{1}) \\le r}$$\n$$Z^{1}:Z^{1}-X^{1}-X^{2}$$\nThe IB curve has the following properties:\n\u2022\nThe IB curve is concave (Lemma 5 in Gilad-Bachrach et al. (2003)) and monotonically non-decreasing.\n\u2022\nThe IB curve is upper bounded by line I(X2; Z\u00b9) = I(X1; Z\u00b9) and line I(X2; Z1) = I(X1; X2), according to the Markov relationship Z1 \u2013 X1 \u2013 X2.\n\u2022\nWhen the MNI point is attainable for random variables X\u00b9 and X2, the IB curve has the following formula\n$$I(Z^{1}; X^{2}) = \\begin{cases} I(Z^{1}; X^{1}), & \\text{if } I (Z^{1}; X^{1}) \\le I(X^{1}; X^{2}) \\\\\\[2ex] I(X^{1}; X^{2}), & \\text{if } I (X^{1};X^{2}) < I(Z^{1}; X^{1}) \\le H(X^{1}) \\end{cases}$$\nand the Gateaux derivative of I(X2; Z\u00b9) with respect to p(z1|x\u00b9) (as used in) doesn't exist at the MNI point (see details in Appendix F)."}, {"title": "D PROOFS", "content": null}, {"title": "D.1 PROOF OF PROPOSITION 1", "content": "Proposition 1. If MNI is attainable for random variable X\u00b9 and X2, maximizing $$ \\mathcal{L}^{1} = I(Z^{1}; X^{2}) \u2013 \\beta I(Z^{1}; X^{1}|X^{2})$$ achieves MNI for any \u03b2 > 0, i.e. I(\u017d\u00b9*; X\u00b9) = I(21*; X\u00b2) = I(X1; X\u00b2), where 21* := arg maxz1_X1_X2 L.\nProof. Based on data processing inequality and the Markov relationship \uadff \u2190 X1 \u2194 X2, I(21; X\u00b2) \u2264 I(X1; X2). Based on the non-negativity of conditional mutual information, I(21; X1|X\u00b2) \u2265 0. Thus, for \u03b2 > 0,\n$$ \\mathcal{L} = I(\\tilde{Z}^{1}; X^{2}) \u2013 \\beta \\cdot I(\\tilde{Z}^{1}; X^{1}|X^{2}) < I(X^{1}; X^{2}), \\forall \\tilde{Z} $$\nwhere the equality holds when I(21; X\u00b2) = I(X1; X2) and I(21; X1|X\u00b2) = 0"}, {"title": "D.2 PROOF OF PROPOSITION 2", "content": "Proposition 2. For random variables X\u00b9 and X2, when the IB curve I(Z1; X\u00b2) = F(I(Z1; X\u00b9)) is strictly concave,\n1) there exists a bijective mapping from \u03b2 in L\u00b9 to the value of information constraint dc in the definition of optimal shared latent 22* in Equation 1;\n$$2) {\\partial I(Z^{*};X^{1}) \\over \\partial \\beta }< 0, {\\partial I(Z^{*};X^{2}) \\over \\partial \\beta }< 0$$, where Z* is the optimal solution corresponding to a certain B.\nProof. Since the IB curve I(Z1; X\u00b2) = f1B(I(Z\u00b9; X\u00b9)) is monotonically non-decreasing and strictly concave, it is monotonically increasing. When Z1 = X1, fIB achieves the maximum point (H(X1), I(X1; X2)). Thus, I(X1; X\u00b2) > I(X1; X\u00b2) \u2013 I(\u017d1*; X2) > 0 and is monotonically de-creasing. Then there is a bijective mapping between $$ \\delta = I(X^{1}; X^{2}) \u2013 I(\\tilde{Z}^{1*}; X^{2}) \\in [0, I(X^{1}; X^{2})]$$\nSince I(Z1; X1|X\u00b2) = I(Z\u00b9; X\u00b9) \u2013 I(Z\u00b9; X2), we have\n$$I(Z^{1}; X^{1}|X^{2}) = {f_{1B}}^{-1}(I(Z^{1}; X^{2})) \u2013 I(Z^{1}; X^{2}) := f_{CIB}(I(Z^{1}; X^{2}))$$\nwhere fCIB(r) = (f\u012bn(r) \u2013 r)-1. Since f1B(r) \u2264 r, the equality holds when r = 0, and fIB is strictly concave, we have dir< df1B|r=0 <1. Thus df1B|r=0 > 1 and\n$$dfCIB \\over dr = ({df_{1B} \\over dr} \u20131)^{-1} > 0$$\nFurthermore, since is 2< 0 (strict concavity of fIB), we have\n$${d^2 f_{CIB} \\over dr^2} = { \\dfrac{1}{( \\dfrac{df_{1B}}{dr} \u2013 1)^2} \\cdot ( \\dfrac{d^2 f_{1B}}{dr^2})}< 0$$\nTherefore, CIB is also monotonically increasing and strictly concave. Then there is a bijective mapping between $$\\delta = I(X^{1}; X^{2}) \u2013 I(\\tilde{Z}^{1*}; X^{2}) \\in [0, I(X^{1}; X^{2})]$$ and points in the CIB curve fCIB.\nSince fCIB is increasing, the inequality constraint can be replaced by the equality constraint, i.e.\n$$\\tilde{Z}^* = \\t{arg min } I(\\tilde{Z}^{1}; X^{1}\\X^{2}) = \\t{ arg min } I(\\tilde{Z}^{1}; X^{1}\\X^{2})$$\n$$I(Z^{1};X^{2})\\geq I(X^{1};X^{2})-\\delta$$ $$I(Z^{1};X^{2})=I(X^{1};X^{2})-\\delta$$\nThe corresponding Lagrangian function is\n$$ \\mathcal{L} = I(Z^{1}; X^{1}\\X^{2}) \u2013 \\beta \\cdot (I(Z^{1}; X^{2}) \u2013 I(X^{1}; X^{2}) + \\delta)$$\n$$ = f_{c1B}(I(Z^{1}; X^{2})) \u2013 \\beta \\cdot I(Z^{1}; X^{2}) + \\beta \\cdot (I(X^{1}; X^{2}) \u2013 \\delta)$$\nBased on the Lagrangian multiplier theorem, the optimal 21* is achieved when\n$${ d\\mathcal{L} \\over dI(Z^{1}; X^{2})} = {df_{CIB} (I(Z^{1}; X^{2})) \\over dI(Z^{1}; X^{2})} \u2013 \\beta = 0$$\n$$|I(Z^{1};X^{2})=I(X^{1};X^{2})-\\delta$$"}, {"title": "D.3 PROOF OF PROPOSITION 3", "content": "Proposition 3. If MNI is attainable for random variables X\u00b9 and X2,\n$$arg max I(Z^{1}; X^{1}\\X^{2}) = arg max I(Z^{1}, \\tilde{Z}^{2*}; X^{1})$$\nZ1-X1-X2\nZ1-X1-X2\nwhere 22* is the representation based on X2 that satisfies MNI, i.e. I(22*; X1) = I(22*; X2) = I(X\u00b9; X\u00b2).\nProof. Based on the graphical model, 22 || X1|X2, Z1, we have I(22; X1|Z1, X2) = 0. Thus,\n$$I(Z^{1}, X^{2}; X^{1}) = I(Z^{1}, X^{2}; X^{1}) + I(\\tilde{Z}^{2}; X^{1}|Z^{1}, X^{2})$$\n$$= I(Z^{1}, \\tilde{Z}^{2}; X^{1}) = I(Z^{1}, \\tilde{Z}^{2}; X^{1}) + I(X^{1}; X^{2}|Z^{1}, \\tilde{Z}^{2})$$\n(8)\nMeanwhile,\n$$I(X^{1}; X^{2}\\\tilde{Z}^{2}) \u2013 I(X^{1}; X^{2}|Z^{1}, \\tilde{Z}^{2}) = I(X^{2}; Z^{1}\\\tilde{Z}^{2}) \u2013 I(X^{2}; Z^{1}|X^{1}, \\tilde{Z}^{2}) = I(X^{2}; Z^{1}\\\tilde{Z}^{2})$$\nwhere the second equality is due to the conditional independence X2 || Z1|X1, 22 in the graphical model.\nWhen 22 is the MNI point 22*, I(X1; 22*) = I(X1; X2). Thus,\n$$I(X^{1}; X^{2}\\\tilde{Z}^{2*}) = I(X^{1}; X^{2}, \\tilde{Z}^{2*}) \u2013 I(X^{1}; \\tilde{Z}^{2*}) = I(X^{1}; X^{2}) \u2013 I(X^{1}; \\tilde{Z}^{2*}) = 0$$\nwhere the first equality is due to the Markov relationship X1 \u2194 X2 \u2192 22*.\nThen we have \u2013I(X1;X2|Z1, 22*) = I(X2; Z1|22*). Due to the non-negativity of conditional mutual information,\nI(X1; X2|Z1, 22*) = I(X2; Z1|22*) = 0\n(9)\nBased on formula 8 and 9,\n$$I(Z^{1}, X^{2}; X^{1}) = I(Z^{1}, \\tilde{Z}^{2*}; X^{1})$$\nSince I(Z\u00b9; X1|X\u00b2) = I(Z1, X2; X\u00b9) \u2013 I(X\u00b9; X\u00b2) and I(X\u00b9; X\u00b2) is a constant value irrelevant to Z\u00b9, maximizing I(Z1; X1|X\u00b2) is equivalent to maximizing I(Z1, X2; X\u00b9) = I(Z1, 22*; X1)."}, {"title": "D.4 PROOF OF PROPOSITION 4", "content": "Proposition 4. For random variables X\u00b9 and X2,"}]}