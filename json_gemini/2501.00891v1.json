{"title": "DEMYSTIFYing Online CLUSTERING OF BANDITS: ENHANCED EXPLORATION UNDER STOCHASTIC AND SMOOTHED ADVERSARIAL CONTEXTS", "authors": ["Zhuohua Li", "Maoli Liu", "Xiangxiang Dai", "John C.S. Lui"], "abstract": "The contextual multi-armed bandit (MAB) problem is crucial in sequential decision-making. A line of research, known as online clustering of bandits, extends contextual MAB by grouping similar users into clusters, utilizing shared features to improve learning efficiency. However, existing algorithms, which rely on the upper confidence bound (UCB) strategy, struggle to gather adequate statistical information to accurately identify unknown user clusters. As a result, their theoretical analyses require several strong assumptions about the \"diversity\" of contexts generated by the environment, leading to impractical settings, complicated analyses, and poor practical performance. Removing these assumptions has been a long-standing open problem in the clustering of bandits literature. In this paper, we provide two solutions to this open problem. First, following the i.i.d. context generation setting in existing studies, we propose two novel algorithms, UniCLUB and PhaseUniCLUB, which incorporate enhanced exploration mechanisms to accelerate cluster identification. Remarkably, our algorithms require substantially weaker assumptions while achieving regret bounds comparable to prior work. Second, inspired by the smoothed analysis framework, we propose a more practical setting that eliminates the requirement for i.i.d. context generation used in previous studies, thus enhancing the performance of existing algorithms for online clustering of bandits. Our technique can be applied to both graph-based and set-based clustering of bandits frameworks. Extensive evaluations on both synthetic and real-world datasets demonstrate that our proposed algorithms consistently outperform existing approaches.", "sections": [{"title": "1 INTRODUCTION", "content": "The stochastic multi-armed bandit (MAB) problem is an online sequential decision-making problem, where at each time step, the learner selects an action (a.k.a. arm) and observes a reward generated from an unknown probability distribution associated with that arm. The goal of the learner is to maximize cumulative rewards (or equivalently, minimize cumulative regrets) in the long run. The contextual linear bandit problem (Li et al., 2010; Chu et al., 2011) extends the MAB framework by associating each action with a feature vector and a corresponding unknown linear reward function.\nOnline clustering of bandits, first introduced by Gentile et al. (2014), generalizes contextual linear bandits by utilizing preference relationships among users. It adaptively partitions users into clusters and leverages the collaborative effect of similar users to enhance learning efficiency. This approach has many applications in computational advertising, web page content optimization, and recommendation systems (Li & Zhang, 2018). Different from conventional MAB problems that focus solely on regret minimization, online clustering of bandits has two simultaneous goals. Firstly, it infers the underlying cluster structures among users by sequentially recommending arms and receiving user feedback. Secondly, based on the inferred clusters, it minimizes the cumulative regret along"}, {"title": "2 RELATED WORK", "content": "Our work is closely related to the literature of online clustering of bandits. Since the seminal work by Gentile et al. (2014), which first formulated the clustering of bandits problem and proposed a graph-based algorithm, there has been a line of follow-up studies. For example, Li et al. (2016) considers"}, {"title": "3 STOCHASTIC CONTEXT SETTING", "content": "In this section, we study the online clustering of bandits problem under the stochastic context setting but with substantially relaxed assumptions. We begin by introducing the problem setting in Section 3.1, which largely follows the seminal work of Gentile et al. (2014) but without the stringent assumptions. Next, in Section 3.2, we provide the intuition of the key techniques underlying our approach. Finally, we present our proposed algorithms: UniCLUB (Section 3.3), which assumes a known minimum gap between clusters, and PhaseUniCLUB (Section 3.4), which does not require this assumption. We also provide a set-based algorithm UniSCLUB in Appendix C."}, {"title": "3.1 PROBLEM SETTING", "content": "In the following, we use boldface letters for vectors and matrices. We denote $[M] := {1, ..., M}$ for $M\\in \\mathbb{N}+$. For any real vector $x, y$ and positive semi-definite (PSD) matrix_V, $||x||$ denotes the l2 norm of x, $(x, y) = x^Ty$ denotes the dot product of vectors, $(x, y)_V = x^TVy$ denotes the weighted inner product, and $||x||_V$ denotes the Mahalanobis norm $\\sqrt{x^TVx}$. We use $\\lambda_{min}(\\cdot)$ and $\\lambda_{max}(\\cdot)$ to denote the minimum and maximum eigenvalue.\nIn the online clustering of bandit problem, there are $\\mathfrak{u}$ users, denoted by set $[\\$\\mathfrak{u}] = {1,2,..., \\mathfrak{u}}$. Each user $i \\in [\\mathfrak{u}]$ is associated with an unknown preference feature vector $\\theta_i \\in \\mathbb{R}^d$ with $||\\$\\theta_i||_2 \\le 1$."}, {"title": "3.2 DIVERSITY CONDITIONS IN PREVIOUS STUDIES AND KEY TECHNIQUES", "content": "Before delving into detailed algorithms, we first examine the stringent statistical assumptions in previous studies (Gentile et al., 2014; Li & Zhang, 2018; Li et al., 2019; Wang et al., 2023a;b; Liu"}, {"title": "3.3 UNICLUB: ALGORITHM FOR THE CASE WHEN Y IS KNOWN", "content": "In this subsection, we assume the parameter y defined in Assumption 2 is known and introduce two algorithms: a graph-based algorithm called Uniform Exploration Clustering of Bandits (UniCLUB, Algorithm 1) and a set-based algorithm called Uniform Exploration Set-based Clustering of Bandits (UniSCLUB, Algorithm 3). Both algorithms explicitly take y as an input. Due to space constraints, we focus on UniCLUB in the main text, leaving the details of UniSCLUB in Appendix C.\nAs shown in Algorithm 1, inspired by the CLUB algorithm proposed in Gentile et al. (2014), UniCLUB maintains a dynamic undirected graph $G_t = ([u], E_t)$ representing the current estimated cluster structures of all users. The main difference is that UniCLUB includes an additional uniform exploration phase to promote cluster identification. At the beginning, $G_t$ is initialized as a complete graph, indicating that all users are considered in a single cluster. Then at each round t, a user $i_t \\in [u]$ comes to be served with a feasible arm set $A_t$ from which the learner has to choose. The algorithm operates in the following two phases depending on whether the current time step $t \\le T_0$, and the arm selection strategy differs between these phases.\nPure exploration phase. In the first $T_0$ rounds, the algorithm uniformly select arm $a_t$ from $A_t$ (Line 4). This arm selection strategy ensures selecting sufficiently diverse arms so that the minimum eigenvalue of the design matrix grows linearly in time (Lemma 2). In Lemma 3, we will show that the phase length $T_0$ is chosen to guarantee that this phase gathers sufficient statistics to estimate each user's preference vector and correctly infer the underlying user clusters with high probability.\nExploration-exploitation phase. After $T_0$, the algorithm constructs the connected component $V_t$ containing user $i_t$ in the graph $G_{t-1}$ (Line 6), and computes the estimated preference vector $\\hat{\\theta}_{V_t,t-1}$ based on historical information associated with $V_t$ using the least squares estimator with regularization parameter $\\lambda > 0$ (Line 8). The algorithm then recommends an arm using the upper confidence"}, {"title": "3.4 PHASEUNICLUB: ALGORITHM FOR THE CASE WHEN Y IS UNKNOWN", "content": "In this subsection, we present a phase-based algorithm PhaseUniCLUB (Algorithm 2) to handle the scenario where the parameter y is unknown. For convenience, we first define the following notations used in PhaseUniCLUB:\n$T_{init} \\triangleq 16\\mathfrak{u} \\log(\\frac{\\mathfrak{u}}{\\delta}) +4\\mathfrak{u}\\cdot\\frac{8L^2}{\\lambda_a} \\log(\\frac{\\mathfrak{u}d}{\\delta})$,  $T^{(s)} \\triangleq 4\\mathfrak{u} \\cdot\\frac{512d}{2^{-s}\\lambda} \\log(\\frac{\\mathfrak{u}}{\\delta})$.\nSimilar to UniCLUB (Algorithm 1), PhaseUniCLUB also maintains a dynamic undirected graph $G_t = ([u], E_t)$ over all users for clustering purposes. However, to cope with the unknown \u03b3, PhaseUniCLUB leverages the idea of the doubling trick. Specifically, as depicted in Algorithm 2,"}, {"title": "4 SMOOTHED ADVERSARIAL CONTEXT SETTING", "content": "Although UniCLUB and PhaseUniCLUB offer significant theoretical improvements, the stochastic context setting necessitates an i.i.d. context generation process (Assumption 3), which might be impractical in real-world applications. To overcome these limitations, based on the intuition in Sec- tion 3.2, we propose the smoothed adversarial context setting to eliminate the need for explicit pure exploration. This setting interpolates between the two extremes: the i.i.d. context generation in Gentile et al. (2014) and the adversarial context generation in Abbasi-Yadkori et al. (2011). The intrinsic diversity of contexts makes explicit exploration unnecessary, thereby ensuring a well-conditioned design matrix (Lemma 11). This approach allows existing algorithms in previous studies, such as CLUB (Gentile et al., 2014) and SCLUB (Li et al., 2019), which consistently employ the UCB strategy, to perform more effectively."}, {"title": "4.1 PROBLEM SETTING", "content": "In the smoothed adversarial setting, we retain Assumptions 1 and 2, while replacing Assumption 3 with Assumptions 4. As detailed below, Assumption 4 allows feature vectors (i.e., contexts) to be arbitrarily chosen by an adversary, but with some random perturbation to ensure the resulting con- texts remain sufficiently diverse. This approach maintains enough data diversity to support effective learning while avoiding the need for explicit pure exploration.\nAssumption 4 (Context diversity for adversarial contexts). At each time step t, the feature vector $x_a \\in D_t$ for each arm $a \\in A_t$ is drawn by a \"smoothed\u201d adversary, meaning that the adversary first chooses an arbitrary vector $\\mu_a \\in \\mathbb{R}^d$ with $||\\$\\mu_a|| \\le 1$, then samples a noise vector $\\epsilon_a \\in \\mathbb{R}^d$ from a truncated multivariate Gaussian distribution where each dimension is truncated within [-R, R], i.e., $\\epsilon_a \\sim \\mathcal{N}(0, \\sigma^2I)$ conditioned on $|(\\epsilon_a)_j| \\le R,\\forall j \\in [d]$. And the feature vector $x_a = \\mu_a + \\epsilon_a$."}, {"title": "4.2 ALGORITHMS FOR SMOOTHED ADVERSARIAL CONTEXT SETTING", "content": "Our proposed algorithms for the smoothed adversarial context setting, SACLUB and SASCLUB, are essentially CLUB (Gentile et al., 2014) and SCLUB (Li et al., 2019) with $\\lambda$ replaced by $\\lambda_a$ and L replaced by $1 + \\sqrt{d}R$ in the edge deletion threshold. Due to space constraints, we omit the full details of SACLUB and SASCLUB here, and the complete proofs are provided in Appendix E."}, {"title": "5 THEORETICAL ANALYSIS", "content": "In this section, we present the theoretical results of our algorithms, with detailed proofs provided in Appendices B, C, D, and E. For clarity, we ignore the constants but they are fleshed out in the proofs. Note that $\\lambda_a$ appears in the denominator of the regret expressions. This is due to the assumption of bounded contexts ($||X||_2$ is bounded) in the stochastic context setting, resulting in $\\mathfrak{d} = O(1/d)$, and therefore it is important to track the dependency of our regret bounds on $\\lambda_a$.\nTheorem 1 (Regret of UniCLUB). Under the stochastic context setting (Assumptions 1, 2, 3) and assuming the cluster gap y is known, the expected regret of the UniCLUB (Algorithm 1) satisfies:\n$E[R(T)] = O(\\frac{\\mathfrak{ud}}{\\gamma \\epsilon \\lambda_a} \\log(T) + \\frac{\\mathfrak{d}}{\\sqrt{m}}T\\log(T))$.\nTheorem 2 (Regret of UniSCLUB). Under the stochastic context setting (Assumptions 1, 2, 3) and assuming the cluster gap y is known, the expected regret of the UniSCLUB (Algorithm 3) satisfies:\n$E[R(T)] = O(\\frac{\\mathfrak{ud}}{\\gamma \\epsilon \\lambda_a} \\log(T) + \\frac{\\mathfrak{d}}{\\sqrt{m}}T\\log(T))$."}, {"title": "6 PERFORMANCE EVALUATION", "content": "In this section, we present the evaluation results of our algorithms. We focus on the stochastic context setting in the main paper since the smoothed adversarial setting serves mainly for theoreti- cal analysis, and algorithms SACLUB/SASCLUB are minor modifications of CLUB (Gentile et al., 2014)/SCLUB (Li et al., 2019). Nonetheless, we provide detailed evaluations of the smoothed ad- versarial setting and an ablation study on different arm set sizes and user numbers in Appendix G."}, {"title": "6.1 EXPERIMENT SETUP", "content": "We compare our algorithms against the following state-of-the-art algorithms for clustering of ban- dits: (1) LinUCB-One: LinUCB (Li et al., 2010) with a single preference vector shared across all users. (2) LinUCB-Ind: LinUCB (Li et al., 2010) with separate preference vectors estimated for each user. (3) CLUB (Gentile et al., 2014): A graph-based algorithm that consistently employs the UCB strategy. (4) SCLUB (Li et al., 2019): A set-based algorithm with improved practical performance. In addition to these clustering-based baselines, we also evaluate our approach against two graph- based algorithms from a related but distinct setting in Appendix G: GOB.Lin (Cesa-Bianchi et al., 2013), which incorporates user similarities using Laplacian regularization, and GraphUCB (Yang et al., 2020), which utilizes the random-walk Laplacian matrix to encode user relationships. Note that neither GOB.Lin nor GraphUCB explicitly performs clustering. All the experiments were con- ducted on a device equipped with a 3.60 GHz Intel Xeon W-2223 CPU and 32GB RAM. Each experiment was repeated over 5 random seeds, and the results are reported with confidence intervals calculated by dividing the standard deviation by the square root of the number of seeds."}, {"title": "6.2 DATASETS GENERATION AND PREPROCESSING", "content": "In our experiments, we employ one synthetic dataset and three real-world datasets, MovieLens- 25M (Harper & Konstan, 2015), Last.fm (Cantador et al., 2011), and Yelp (Yelp, 2023). We generate"}, {"title": "6.3 EXPERIMENT RESULTS", "content": "In the experiment, to incorporate user clustering, we randomly select 50 users and partition them into 10 clusters. For each cluster j, we calculate the mean preference vector across all users within that cluster to serve as $\\theta^{(j)}$. Note that the number of clusters is unknown to the algorithms. At each round t, we uniformly draw a user $i_t$ from the 50 users, and randomly select 100 arms from A to form the arm set $A_t$. The results are presented in Figure 1.\nAs shown in Figure 1, the algorithms that employ user clustering significantly outperform LinUCB- Ind and LinUCB-One, which do not consider the similarity among users or cluster users. More importantly, our graph-based algorithm UniCLUB consistently outperforms the graph-based base- line CLUB, and our set-based algorithm UniSCLUB is better than the set-based baseline SCLUB across all four datasets. It is important to note that the modest advantage of UniCLUB/UniSCLUB over CLUB/SCLUB is both expected and reasonable, given the logarithmic improvement in the re- gret upper bound. The results demonstrate the effect of uniform exploration and the robustness of our proposed algorithms across various datasets. More evaluation under the smoothed adversarial context setting and ablation study can be found in Appendix G."}, {"title": "7 CONCLUSION", "content": "In this paper, we addressed a long-standing open problem in the online clustering of bandits lit- erature. We proposed two new algorithms, UniCLUB and PhaseUniCLUB, which incorporate explicit exploration to enhance the identification of user clusters. Notably, our algorithms require significantly weaker assumptions while achieving cumulative regrets comparable to previous stud- ies. Furthermore, we introduced the smoothed adversarial context setting, which interpolates be- tween i.i.d. and fully adversarial context generation. We showed that with minor modifications, existing algorithms achieve improved performance in this new setting. Finally, we conducted exten- sive evaluations to validate the effectiveness of our methods."}, {"title": "A MORE DISCUSSIONS ON RELATED WORK", "content": "Leveraging data diversity (i.e., conditions refer to the minimum eigenvalue of a design matrix) in stochastic linear contextual bandits has two lines of research. The first line involves using additional \"diversity conditions\" to improve cumulative regrets. For example, Bastani et al. (2021) introduce a condition for the disjoint-parameter case, and prove that a non-explorative greedy algorithm achieves $O(log T)$ problem-dependent regret on a 2-arm bandit instance. Hao et al. (2020) give a condition and prove a constant problem-dependent regret for LinUCB in the shared-parameter case. Wu et al. (2020) show that under some diversity conditions, LinUCB achieves constant expected regret in the disjoint-parameter case. Ghosh & Sankararaman (2022) use a condition similar to Gentile et al. (2014) and achieve a problem-independent logarithmic regret for linear contextual bandits. The second line of research focuses on achieving concurrent statistical inference and regret minimization (i.e., multi-objective MAB). This involves performing additional tasks on top of regret minimization, such as clustering (Gentile et al., 2014), model selection (Chatterji et al., 2020; Ghosh et al., 2021a), personalization (Ghosh et al., 2021b), and exploration under safety constraints (Amani et al., 2019)."}, {"title": "B THEORETICAL ANALYSIS OF UNICLUB", "content": "Lemma 1. With probability at least 1 \u2013 8 for any $\\delta \\in (0, 1)$, $\\forall t \\in [T]$ and $\\forall i \\in [\\mathfrak{u}]$,\n$||\\hat{\\theta}_{i,t} - \\theta^{(j(i))}\\le \\sqrt{\\frac{2\\log(\\frac{\\mathfrak{u}}{\\delta}) + \\mathfrak{d} \\log(1 + \\frac{T_{i,t}L^2}{\\lambda d})}{\\lambda}} + \\sqrt{\\frac{T_{i,t}L^2}{\\lambda \\min(S_{i,t})}}$.\nProof. Fix a user $i \\in [\\mathfrak{u}]$, for all $t \\in [T]$, we have\n$\\hat{\\theta}_{i,t} - \\theta^{(j(i))}= (\\lambda I + \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}X_{a_{\\tau}}^T)^{-1} (\\lambda I + \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}X_{a_{\\tau}}^T)\\theta^{(j(i))}$\n$= -((\\lambda I + \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}X_{a_{\\tau}}^T)^{-1} (\\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}(X_{a_{\\tau}}^T\\theta_{i} + \\eta_{\\tau}) - (\\lambda I + \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}X_{a_{\\tau}}^T)\\theta^{(j(i))})$\n$=(\\lambda I + S_{i,t})^{-1} \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}\\eta_{\\tau} - \\lambda (\\lambda I + S_{i,t})^{-1}(\\theta^{j(i)} - \\theta^{(j(i))}) = S_{i,t}^{-1} \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}\\eta_{\\tau} - \\lambda\\hat{\\theta}_{i,t}^{(\\epsilon)}$.\nwhere we denote $S_{i,t} \\triangleq \\lambda I + S_{i,t} = \\lambda I + \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}X_{a_{\\tau}}^T$\nFor any vector $x \\in \\mathbb{R}^d$,\nx^T(\\hat{\\theta}_{i,t} - \\theta^{(j(i))}) = x^T( S_{i,t}^{-1} \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}\\eta_{\\tau} - \\lambda\\hat{\\theta}_{i,t}^{(\\epsilon)} )= x^T S_{i,t}^{-1} \\sum_{\\tau\\in[t]:i_{\\tau}=i} X_{a_{\\tau}}\\eta_{\\tau} - \\lambda x^T\\hat{\\theta}_{i,t}^{(\\epsilon)}.$"}, {"title": "C THE SET-BASED ALGORITHM UNISCLUB", "content": "C.1 DETAILS OF THE UNISCLUB ALGORITHM\nIn this section, we introduce a set-based algorithm named Uniform Exploration Set-based Clustering of Bandits (UniSCLUB), which is inspired by SCLUB Li et al. (2019). Instead of using a graph structure to maintain the clustering information, SCLUB uses a set structure for the same purpose. UniSCLUB inherits the set structure from SCLUB, but incorporates the uniform exploration to enhance its performance. The set structure not only supports the split operations which are similar to those in the graph structure, but also enables the merging of two clusters when the algorithm identifies that their estimated preference vectors are closely aligned. By allowing for both split and merge operations, UniSCLUB can adapt to the underlying clusters more flexibly and expedite the overall clustering process.\nThe details of UniSCLUB are shown in Algorithm 3. The algorithm maintains information at two levels. At the cluster level, a cluster index I contains the indices of currently existing clusters, and for each cluster $j \\in I$, the algorithm maintains the set of users $C^{j}$ in this cluster and other corresponding information such as the estimated preference vector $\\hat{\\theta}^{j}$. Initially, there is only a single cluster containing all users. At the user level, for each user i, the algorithm maintains the estimated preference vector $\\hat{\\theta}_{i,t}$ at round t and other corresponding information. Additionally, all users and clusters are associated with a \"checked\" or \"unchecked\u201d status to indicate the estimation accuracy of their preference vectors. UniSCLUB proceeds in phases (Line 1) and each phase $s \\in N^+$ consists of $2^{s-1}$ rounds. At the beginning of each phase, all users revert to the \u201cunchecked\u201d status (Line 2). When a user first appears in a phase, it will be marked as \u201cchecked\u201d (Line 14). A cluster is marked as \u201cchecked\u201d once all its users are checked. The algorithm will only consider merging checked clusters, so as to avoid premature merging because of inaccurate preference vector estimation. At round t, a user $i_t$ comes with a set $A_t$ of items (Line 4). If $t \\le 2T_0$ (with $T_0$ defined in Equation (24)), UniSCLUB uniformly selects the arm $a_t$ from $A_t$ (Line 9). Otherwise, it determines the cluster j to which the user $i_t$ belongs and selects the item $a_t$ based on the cluster information (Lines 6 and 7). The algorithm updates the corresponding information of both the user and the cluster after receiving the feedback of the selected item (Lines 10 to 12). Then the algorithm determines whether any split or merge operations are necessary (Lines 13 and 15). If the estimated preference vector of any user within the cluster j diverges from that of user $i_t$, the algorithm will split $i_t$ from the cluster (Algorithm 4). If the estimated preference vectors of two checked clusters are closely aligned, a merge operation will be performed (Algorithm 5).\nSince no clustering information is utilized during the uniform exploration period, UniSCLUB can only update the user-level information. Then the algorithm clusters all users at round $2T_0$, and continues updating both user and cluster information subsequently. This implementation makes UniSCLUB more efficient and robust compared to SCLUB."}, {"title": "C.2 THEORETICAL ANALYSIS OF UNISCLUB", "content": "Theorem 2 (Regret of UniSCLUB). Under the stochastic context setting (Assumptions 1, 2, 3) and assuming the cluster gap y is known, the expected regret of the UniSCLUB (Algorithm 3) satisfies:\n$E[R(T)] = O(\\frac{\\mathfrak{ud}}{\\gamma \\epsilon \\lambda_a} \\log(T) + \\sqrt{\\frac{\\mathfrak{d}}{m}}T\\log(T))$"}, {"title": "D THEORETICAL ANALYSIS OF PHASEUNICLUB", "content": "To bound the cumulative regret of PhaseUniCLUB, we present the following lemmas.\nLemma 7. Denotes $\\gamma_s \\triangleq 2^{-s} \\gamma$ and $C_p \\triangleq \\frac{2048\\mathfrak{ud} \\log(\\frac{\\mathfrak{u}}{\\delta})}{\\lambda_a}$. With probability at least 1 - $\\frac{3}{\\alpha+1} \\log_2(\\frac{2^{\\alpha+1}T}{C_p} + 1)\\delta$, after the exploration subphase in any phase $s = 0,1,...,$ for all users $i \\in [u]$, we have\n$|| \\hat{\\theta}_{i,t} - \\theta^{(j(i))} ||_2 \\le \\frac{\\gamma_s}{4}$.\nProof. According to Lemma 3, with probability $\\geq 1-3\\delta$, after the exploration subphase in phase $s = 0, 1, . . .,$ for any user $i \\in [\\mathfrak{u}]$, we have\n$|| \\hat{\\theta}_{i,t} - \\theta^{(j(i))} ||_2 \\le \\frac{\\gamma_s}{4}$.\nDenote the number of phases for PhaseUniCLUB by $N_p$. Since phase s contains $2^{s-1} T^{(s)}$ rounds,\nNp is the maximum integer satisfying\n$T^{init} + \\sum^{N_p -1}_{s=0}  2^{s} \\cdot 4\\mathfrak{u}  \\frac{512d}{2^{-s} \\lambda_a}  \\log(\\frac{\\mathfrak{u}}{\\delta})  \\le T$.\nBy some calculations, we have\n$\\frac{1}{\\alpha + 1} \\log_2(\\frac{2^{\\alpha+1}T}{C_p} - \\frac{T_{init}}{C_p} ) \\le N_p + 1 \\le \\frac{1}{\\alpha + 1} \\log_2(\\frac{2^{\\alpha+1}T}{C_p} + 1)$."}, {"title": "E THEORETICAL ANALYSIS OF SACLUB AND SASCLUB", "content": "Lemma 10. Under the smoothed adversary setting, SACLUB and SASCLUB have the following lower bound on the expected minimum eigenvalue of $x_{a_\\tau}x_{a_\\tau}^T$:\n$\\lambda_{min}(E[x_{a_{\\tau}}x_{a_{\\tau}}^T]) \\geq C_1  \\frac{\\sigma^2}{\\log K}  \\lambda_a$,\nwhere $c_1$ is some constant."}, {"title": "FTECHNICAL INEQUALITIES", "content": "We present the technical inequalities used throughout the proofs. For inequalities from existing literature, we provide detailed references for readers' convenience.\nLemma 12 (Matrix Chernoff, Corollary 5.2 in Tropp (2011)). Consider a finite sequence $\\{X_k\\}$ of independent, random, self-adjoint matrices with dimension d. Assume that each random matrix satisfies\n$X_k \\succeq 0$ and $\\lambda_{max}(X_k) \\leq R$ almost surely.\nDefine\nY := \\sum Xk and \\mu_{min} := \\lambda_{min}(E{Y}) = \\lambda_{min}(\\sum E[Xk])\n\nThen, for any $\\delta \\varepsilon (0, 1)$,\n$Pr[\\lambda_{min}(\\sum X_k) \\leq (1 - \\delta)\\mu_{min}] \\leq d  \\exp(-\\frac{\\delta^2}{1}  \\frac{\\mu_{min}}{R})$.\nLemma 13 (Lemma 8 in Li & Zhang (2018)). Let $x_1, x_2,..., x_n$ be independent Bernoulli random variables with mean $0 < p < $. Let $\\delta > 0, B > 0$, then with probability at least 1 \u2013 8,\n$\\sum_{s=1}^{t} x_s\\geq B$,  $\\forall t \\geq \\frac{16}{p}  \\log(\\frac{t}{\\delta}) + \\frac{4B}{p}$.\nLemma 14. For $a > 0, b > 0, ab \\geq 1$, if $t \\geq 2a \\log(ab)$, then\n$t \\geq a  \\log(1+bt)$.\nProof. Since t increases faster than $a \\log(1+bt)$, it suffices to prove $t > a \\log(1+bt)$ for $t = 2a \\log(ab)$. Equivalently, we only need to show:\n$2a \\log(ab) \\geq a \\log(1 + 2ab  \\log(ab)) = a  \\log(ab) + a  \\log(2  \\log(e^{-2}a bab))$,\nwhich follows by observing that $ab > 2  \\log(e^{-2}a bab) = ++ 2  \\log(ab)$ holds when $ab \\geq 1$.\nLemma 15. Let $X_1, X_2, ..., X_n$ be a sequence of n independent and identically distributed (i.i.d.) random variables, each following a distribution P. Let Y be a random variable that is uniformly selected from the set $\\{X_1, X_2, ..., X_n\\}$, then Y follows the same distribution P.\nProof. It suffices to show $\\mathbb{P}r[Y \\in A] = \\mathbb{P}r[X_1 \\in A]$ for any measurable set A. By the law of total probability, we can express the probability that Y falls into the set A as:\n$\\mathbb{P}r[Y \\in A] = \\sum_{i=1}^{n} \\mathbb{P}r[Y \\in A | Y = X_i]  \\mathbb{P}r[Y = X_i]$"}, {"title": "GMORE EXPERIMENTS", "content": "G.1 EVALUATION UNDER THE SMOOTHED ADVERSARIAL CONTEXT SETTING\nTo implement the smoothed adversarial contexts, for each arm in the synthetic dataset and three real- world recommendation system datasets, we add a Gaussian noise vector sampled from $N(0, I/10)$. As illustrated in Figure 2, for all the datasets, SACLUB and SASCLUB (which are essentially adapted versions of CLUB and SCLUB) outperform LinUCB-Ind and LINUCB-One. Additionally, under the smoothed adversarial setting, LinUCB-Ind and LINUCB-One exhibit more significant fluctua- tions compared to SACLUB and SASCLUB, highlighting the increased complexity of the smoothed adversarial setting relative to the stochastic setting. This corroborates our theoretical results, show- ing that with some minor changes, the existing algorithms CLUB and SCLUB can be extended to the more practical smoothed adversarial setting, which is closer to the original setting of contextual linear bandits (Abbasi-Yadkori et al., 2011).\nG.2 CUMULATIVE REGRET WITH DIFFERENT ARM SET SIZES\nUnder the stochastic context setting, we evaluate the impact of the arm set size $|A_t| = K$ by ad- justing $K = 80, 100, 120, 140$ using the Yelp dataset, since it has the largest number of users. As demonstrated in Figure 3, there is no substantial amplification of the cumulative regrets as the arm set size K increases. This observation validates our theoretical results (Theorems 1 and 2), where the regret upper bounds of UniCLUB and UniSCLUB do not involve K.\nG.3 CUMULATIVE REGRET WITH DIFFERENT USER NUMBERS\nTo examine the effect of the number of users, we adjust the number of users $\\mathfrak{u} = 40, 50, 60, 70$ while keeping the number of clusters $\\mathfrak{m} = 10$ using the Yelp dataset. As shown in Figure 4, our proposed algorithms exhibit significant advantages compared to the baselines. Additionally, as the number of users increases, the cumulative regrets also increase. This is expected because a larger number of users poses a greater challenge in learning their preference vectors and identifying the cluster structures."}, {"title": "G.4 COMPARISON WITH NON-CLUSTERING-BASED BASELINES", "content": "In this subsection, we compare our algorithms with two additional graph-based baseline algorithms, GOB.Lin (Cesa-Bianchi et al., 2013) and GraphUCB (Yang et al., 2020), within the stochastic con- text setting"}]}