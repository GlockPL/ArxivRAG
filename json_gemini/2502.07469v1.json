{"title": "5D NEURAL SURROGATES FOR NONLINEAR GYROKI- NETIC SIMULATIONS OF PLASMA TURBULENCE", "authors": ["Gianluca Galletti", "Fabian Paischer", "Paul Setinek", "William Hornsby", "Lorenzo Zanisi", "Naomi Carey", "Stanislas Pamela", "Johannes Brandstetter"], "abstract": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable energy production. A major roadblock to achieving commercially viable fusion power is understanding plasma turbulence, which can significantly degrade plasma confinement. Modelling turbulence is crucial to design performing plasma scenarios for next-generation reactor-class devices and current experimental machines. The nonlinear gyrokinetic equation underpinning turbulence modelling evolves a 5D distribution function over time. Solving this equation numerically is extremely expensive, requiring up to weeks for a single run to converge, making it unfeasible for iterative optimisation and control studies. In this work, we propose a method for training neural surrogates for 5D gyrokinetic simulations. Our method extends a hierarchical vision transformer to five dimensions and is trained on the 5D distribution function for the adiabatic electron approximation. We demonstrate that our model can accurately infer downstream physical quantities such as heat flux time trace and electrostatic potentials for single-step predictions two orders of magnitude faster than numerical codes. Our work paves the way towards neural surrogates for plasma turbulence simulations to accelerate deployment of commercial energy production via nuclear fusion.", "sections": [{"title": "1 INTRODUCTION", "content": "Turbulence is a key driver of plasma confinement degradation, as it causes Plasma to diffuse towards the reactor wall, resulting in most of the heat and particle transport in magnetic fusion devices, such as Tokamaks. The growing turbulence is dampened by the zonal flow system, which regulates turbulence to reach a quasi-stationary saturated state (Itoh et al., 2006). The design and control of performing plasma scenarios strictly requires knowledge of the turbulent transport in the saturated state. This can be obtained via complex nonlinear gyrokinetic simulations, which involve evolution of a 5D distribution function over time.\nComputationally affordable reduced-order quasilinear models of turbulent transport, such as Qua- LiKiz (Bourdelle et al., 2015; Citrin et al., 2017) and TGLF (Staebler et al., 2007; Staebler & Kinsey, 2010), are routinely adopted. They make simplifying assumptions about the mechanism of turbu- lence saturation and modality expressed as so-called saturation rules. As different saturation rules are fitted to specific turbulence modalities, a general quasilinear model is not available to date, which limits their usefulness. A fast, general and reliable estimate of turbulent fluxes is only attainable via expensive nonlinear gyrokinetic simulations.\nNeural surrogates can reduce the complexity of nonlinear gyrokinetic simulations. Current ap- proaches operate on reduced input spaces (Narita et al., 2022; Honda et al., 2023), which do not model the 5D distribution function. This results in information loss, as they do not capture inter- actions across all dimensions. In this work, we attempt for the first time to train a neural surrogate for the evolution of the 5D distribution function. To this end, we first collect simulation data using a state-of-the-art nonlinear solver, namely GKW (Peeters et al., 2009), run with adiabatic electrons for different values of Ion Temperature Gradient (ITG). To compress the high-dimensional input"}, {"title": "2 RELATED WORK", "content": "Machine Learning for Gyrokinetics. Most of the literature to date has focused on multilayer perceptrons as surrogate models of turbulence models that adopt the quasilinear approximation. Faster integrated models (Romanelli et al., 2014; Pereverzev & Yushmanov, 2002) of tokamak dis- charges were obtained for interpretative modelling in existing machines (Meneghini et al., 2017; van de Plassche et al., 2020) as well as predictive modelling (Citrin et al., 2023) and control studies (Mulders et al., 2021) of future reactor-class devices, clearly highlighting the benefits of surrogate modelling, albeit on reduced order models.\nThe literature on surrogates for higher-fidelity models is sparse. To model the linear spectra of micro-tearing modes, Hornsby et al. (2024) propose leveraging gaussian process regression (GPR). GPR also enables uncertainty quantification, but does not scale well to larger datasets and dimen- sionalities. Therefore, Narita et al. (2022) leverage convolutional neural networks based on the spectral images of the absolute values of the distribution function along with the electric potential at a fixed time slice and predict the corresponding heat flux and the time to saturation. Honda et al. (2023) extends this idea to a two-dimensional multimodal input space, including electrostatic po- tentials. Our method fundamentally differs in that it directly models the time evolution of the 5D distribution function, thus enabling the computation of turbulent fluxes at any time.\nNeural Operators. Importantly, our 5D Swin-UNet does not fall into the category of neural oper- ators, as it is not resolution invariant but operates on a fixed resolution. However, in future work we aim to extend our model to a neural operator, hence we elaborate on important related work in this regard. Neural operators (Lu et al., 2021; Li et al., 2020; Kovachki et al., 2023; Alkin et al., 2024a) are formulated with the objective of learning a mapping between function spaces, usually defined as Banach spaces U, V of functions defined on compact input and output domains X and Y, respectively. Neural operators enable continuous outputs that remain consistent across varying input sampling resolutions. A neural operator \u011c : U \u2192 V approximates the ground truth operator G : U \u2192 V, and is usually composed of three maps \u0177 := D\u25e6 A \u25cb E (Seidman et al., 2022), com- prising the encoder E, the approximator A, and the decoder D. Training a neural operator involves constructing a dataset of input-output function pairs evaluated at discrete spatial locations. Training minimizes a mean squared error loss over the discretized space using gradient descent.\nOver the recent years, driven by advances in neural operator learning, deep neural network-based surrogates have emerged as a computationally efficient alternative in science and engineering (Thuerey et al., 2021; Zhang et al., 2023; Brunton et al., 2020), impacting e.g., weather forecast- ing (Kurth et al., 2023; Bi et al., 2023; Lam et al., 2023; Nguyen et al., 2023; Bodnar et al., 2024), protein folding (Jumper et al., 2021; Abramson et al., 2024), material design (Merchant et al., 2023; Zeni et al., 2025; Yang et al., 2024), and multi-physics modeling Alkin et al. (2024b). All these success stories share the common thread of deep learning surrogates unlocking new possibilities to overcome seemingly insurmountable challenges (Brandstetter, 2024)."}, {"title": "3 METHODS", "content": "First, we elaborate on the data generation, preprocessing, and visualization techniques in Section 3.1. Next, we explain our proposed 5D Swin-UNet and elaborate on the architectural details in Sec- tion 3.2. Finally, in Section 3.3, we elaborate on our evaluation protocol."}, {"title": "3.1 DATA GENERATION", "content": "Gyrokinetic simulations are usually initialised from noise and evolved according to nonlinear gy- rokinetic equations (Equation (1)). The simulations usually follow a certain pattern. In the linear phase the linear modes start growing, resulting in an initial increase in the heat flux time trace. Afterwards, the simulations enter the nonlinear or saturated regime where the linear modes start interacting, resulting in an oscillatory behaviour of heat flux. Turbulence is generally established in the nonlinear regime and complex integrals over long time intervals are required to obtain an estimate for the heat flux.\nWe rely on a nonlinear direct numerical gyrokinetic solver to produce samples of the 5D distribution function, namely GKW (Peeters et al., 2009). For background on the gyrokinetic framework, we refer the reader to Appendix A. We consider the adiabatic electron case, where the velocity distri- bution of electrons is assumed to be Boltzmann-like. Therefore, only the distribution function of the ions is considered. To obtain different trajectories, we vary the ITG and collect 5D fields of resolution (32 \u00d7 8 \u00d7 16 \u00d7 255 \u00d7 32 \u00d7 2) where the sixth dimension corresponds to the real and imaginary part of the ballooning transform, which is usually used to describe plasma coordinates. The five remaining spatial dimensions are denoted as (V\u2081\u2081 \u00d7 V\u00b5 \u00d7 s \u00d7 kx \u00d7 ky), where V\u2081\u2081 and V\u00b5 represent velocities parallel and perpendicular to the field lines, s is the toroidal angle and kx and ky are spatial coordinates in the spectral space. We run GKW for different values of ITG and dump the distribution function every 20 steps to ensure sufficient change. The collected trajectories have 500 such steps that are additionally subsampled every third, resulting in an overall time-coarsening of 60 times and a total of 166 snapshots per trajectory. The dataset comprises five trajectories, resulting"}, {"title": "3.2 5D SWIN-UNET", "content": "To process the 5D input, we generalize the hierarchical Swin Transformer (Liu et al., 2021) to an arbitrary number of dimensions. The input to 5D Swin-UNet is a 5D field of shape Vpar\u00d7V\u00d7SXXX y x 2, which consists of the real and imaginary parts of a time snapshot of the nonlinear gyrokinetics simulation. Similarly to other conventional 2D Vision Transformers (Dosovitskiy et al., 2021; Liu et al., 2021), we first partition the input into non-overlapping patches with an n-dimensional patch embedding layer, mapping patch-local information into tokens. Patches are then processed with a UNet-style architecture (Ronneberger et al., 2015), using patch merging and unmerging to produce multiscale hierarchical representations. The original space is reconstructed from patch tokens using a patch expansion layer, which nonlinearly expands the patch space to the original resolution. The proposed 5D Swin-UNet architecture is shown in Figure 1, left.\nThe multi-head self-attention (MSA) used in Vision Transformers scales quadratically with the se- quence length in the 2D case. This effect is exacerbated in 5D, making MSA prohibitively expensive. Therefore, we apply MSA only on local windows as in (Liu et al., 2021, SWin). This is agnostic to dimensionality, i.e., it can be expanded to any number of dimensions with varying window sizes per dimension (nDWin-MSA). To enable interaction between neighboring windows, we also extend cyclic shifts of SWin to 5D (nDSWin-MSA). Finally, we apply self-attention within each window in parallel. Figure 1 (right) visualizes the attention scope for one window in 5D for nDWin-MSA (top) and nDSWin-MSA (bottom)."}, {"title": "3.3 EVALUATION", "content": "To evaluate our method, we consider three approaches. As a first evaluation, we visualize the outputs of the surrogate model. This is done in the same manner as elaborated in Section 3.1 and we apply this scheme to the ground truth data and to the model prediction to obtain a side-by-side comparison. The second evaluation corresponds to visual inspection of the electrostatic potentials. Potentials are"}, {"title": "4 EXPERIMENTS", "content": "In our experiments, we train 5D Swin-UNet for next-step prediction of the nonlinear gyrokinetic simulation. We split the data according to trajectories into training and validation. Specifically, we evaluate on one holdout trajectory and use the remaining ones for training. This way, we evaluate generalization to a holdout trajectory produced with a different ITG. Each sample of a trajectory is normalized on a per-sample basis. We train our model for 100 epochs and evaluate every 20 epochs on the holdout trajectory. For implementation details, we refer the reader to Appendix C.\nDistribution function. We visualize the predicted 5D field of the distribution function over time. Figure 3 shows averages for four of the 10 possible combinations of the different axes for three different timesteps. The first timestep is from the linear regime, whereas the latter are from the saturated phase. The model prediction generally aligns very well with the ground truth, as both model prediction and ground truth are displayed with euqal colour scale.\nElectrostatic Potentials. We obtain the electrostatic potentials as described in Section 3.3 and provide a visual comparison of the predicted and ground-truth electrostatic potential in Figure 4b. It shows that the the vertical wave vector is well reproduced, indicating that our surrogate model captures key aspects of the underlying physics. However, there is a misalignment with respect to the first mode (zonal mode) that represents the zonal flow. To further investigate this, we show the first mode of the electrostatic potential in Figure 4a. Interestingly, 5D Swin-UNet strongly overestimates the presence of zonal flow in the linear phase where it is usually not present (top row). This is likely caused by an imbalanced dataset, where the saturated phase \u2013 with a stronger zonal mode is overrepresented. The zonal flow does not directly contribute to the resulting heat flux in the saturated phase; however, it dampens the development of turbulent transport. This is problematic, especially for autoregressive rollouts, where the predicted zonal flow in the linear phase results in a decaying heat flux. Therefore, we aim to explore different sampling strategies or tailored losses emphasizing the zonal mode in the future."}, {"title": "5 CONCLUSIONS AND FUTURE WORK", "content": "We present a neural surrogate model for nonlinear gyrokinetic equations modelling turbulent trans- port in Plasmas. We first present a simple recipe to visually inspect the 5D distributon function. Then, we propose a neural surrogate that operates in 5D space, namely 5D Swin-UNet, and demon- strate that it accurately captures the underlying physics for single-step prediction. Our work paves the way towards neural surrogates for 5D turbulence modelling for nuclear fusion.\nAs a first step for future work we plan to incorporate additional diagnostics to verify that the sur- rogate model accurately captures physics beyond electrostatic potentials. Furthermore, a fruitful direction is to include a separate head for explicit prediction of electrostaic potentials. This alle- viates the requirement for expensive GKW calls, needed for computing the potential field and the heat flux integrals. Our aim is to achieve stable long-term autoregressive rollouts with our surrogate model which is currently hindered by the overemphasis on the zonal flow. Eventually, our vision is to extend this work beyond next-step prediction to neural operators (Lu et al., 2021; Li et al., 2020; Kovachki et al., 2023; Alkin et al., 2024a) and enable transfer from lower-fidelity simulations that can be produced more efficiently to higher-fidelity ones that can take up to weeks to produce and are of different resolution."}, {"title": "A GYROKINETIC FRAMEWORK", "content": "Solved within GKW is the gyrokinetic set of equations. The full details can be found in Peeters et al. (2009) and references therein. The of approximation is used, in which the distribution function is split into a background, Maxwellian distribution function FM, and a perturbed distribution f which is a 5 dimensional function, f = f(kx, ky, s, V[], V\u00b5). The final equation for the perturbed distribution function f, for each species can be written in the form\n$\\frac{\\partial f}{\\partial t} + (v_{||}b + V_D) \\cdot \\nabla f + v_x \\cdot \\nabla_{\\perp} f - \\frac{\\mu B}{m} b \\cdot \\nabla B \\frac{\\partial f}{\\partial v_{||}} = S,$\nwhere S is the source term which is determined by the background distribution function, \u00b5 is the magnetic moment, v|| is the velocity along the magnetic field, VD denotes the sum of the drift velocities, vx is the E \u00d7 B velocity, B is the magnetic field strength, m and Z are the particle mass and charge number respectively. The background is assumed to be a shifted Maxwellian (FM), whose terms are moved to the right-hand side as a source term S, which represent the drives of the underlying instabilities that are studied. The electrostatic potential, $, is calculated from the gyrokinetic Poisson equation.\nThe thermal velocity vth = \u221a2T/m, and the major radius (R) are used to normalise the length and time scales. Using standard gyrokinetic ordering, the length scale of perturbations along the field line (RV \u2248 1) is significantly longer than those perpendicular to the field (RV\u300d \u2248 1/p*). Here, p* = pi/R is the normalised ion Larmor radius (where pi = mivth/eB and vth = \u221a2Ti/mi). To harness this, GKW uses straight field-line Hamada coordinates (s, \u03b6, \u03c8) where s is the coordinate along the magnetic field and ( is the generalised toroidal angle. GKW uses a Fourier representation in the toroidal (y) and radial directions (x), perpendicular to the magnetic field."}, {"title": "B DATA GENERATION AND VISUALISATION", "content": "Data Generation.\nThe choice of ITG significantly impacts the behaviour of the simulations as it is a major driver of plasma turbulence. In general, higher values lead to the accumulation of particle density, resulting in drift effects that eventually turn into turbulence. This can be visualized by comparing flux traces across different ITGs (see Figure 6). Generally, as ITG increases, the system exhibits more nonlinear interactions, leading to higher heat flux values, f f f. For values of {5.9, 7.9, 10, 15}, one can clearly"}, {"title": "C IMPLEMENTATION DETAILS", "content": "While Vision Transformers usually employ convolutions for patch operations (Dosovitskiy et al., 2021; Liu et al., 2021; 2022), we use simple fully connected layers because the computational cost of generalized convolutions can become significant in higher dimensions without an optimized im- plementation. Patch embedding, merging, and expansions are implemented as linear layers or MLPs. The efficient application of nDSWin-MSA is also implemented similarly to Swin. The shift is per- formed as a cyclic roll along all the window-partitioned axes. Because such operations can produce batches of windows that are not adjacent, we apply a n-dimensional window mask.\nWe use the Adam optimizer (Kingma & Ba, 2015) with a weight decay of le-5 and a cosine learning rate scheduler with linear warmups with a peak at 1e-3, decayed to 0. During training we employ automatic mixed precision and gradient clipping to a magnitude of 1. We also transfer the spectral domains (kx and ky) to real space for training by applying inverse FFT. Since a single training sample comprises several GBs of data, we perform lazy dataloading. Model selection is performed every 20 training epochs based on the mean squared error on the holdout trajectory."}]}