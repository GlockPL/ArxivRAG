{"title": "FinVision: A Multi-Agent Framework for Stock Market Prediction", "authors": ["Sorouralsadat Fatemi", "Yuheng Hu"], "abstract": "Financial trading has been a challenging task, as it requires the integration of vast amounts of data from various modalities. Traditional deep learning and reinforcement learning methods require large training data and often involve encoding various data types into numerical formats for model input, which limits the explainability of model behavior. Recently, LLM-based agents have demonstrated remarkable advancements in handling multi-modal data, enabling them to execute complex, multi-step decision-making tasks while providing insights into their thought processes. This research introduces a multi-modal multi-agent system designed specifically for financial trading tasks. Our framework employs a team of specialized LLM-based agents, each adept at processing and interpreting various forms of financial data, such as textual news reports, candlestick charts, and trading signal charts. A key feature of our approach is the integration of a reflection module, which conducts analyses of historical trading signals and their outcomes. This reflective process is instrumental in enhancing the decision-making capabilities of the system for future trading scenarios. Furthermore, the ablation studies indicate that the visual reflection module plays a crucial role in enhancing the decision-making capabilities of our framework.", "sections": [{"title": "1 Introduction", "content": "The complexities and volatility of financial markets, along with multi-modal data streams, present significant challenges for tasks such as trading and market movement prediction. Effective prediction and trading systems must integrate all available information comprehensively and employ sophisticated algorithmic designs to achieve superior performance [17, 24]. To improve trading systems, the field has progressed from rule-based trading strategies to more advanced deep learning models and Reinforcement Learning (RL)-based agents [10, 11, 19, 32]. However, these models face substantial challenges, including the need for extensive training data, the oversimplification of diverse financial data types, and a lack of interpretability in their decision-making processes [28].\nA key challenge in these advanced models is the effective integration of diverse financial data types without oversimplification. For instance, incorporating textual news data into deep learning and RL models presents complex challenges: reducing multifaceted content to single-variable sentiment scores fails to capture market dynamics, while effectively interpreting this information requires sophisticated financial reasoning to track evolving events and market developments over time [2]. Similarly, representing historical price data and technical indicators poses significant challenges due to their high dimensionality, non-linear relationships, and time-dependent nature, which can lead to information loss or misinterpretation [12, 22]. Attempts to address these issues by increasing the number of variables to represent different aspects of the market often result in increased model complexity, making the internal representations and decision-making processes more intricate and harder to interpret [12, 22].\nRecent advancements in Large Language Models (LLMs) have driven their evolution into agents capable of executing complex, multi-step decision-making tasks [9, 27, 36]. This progress has expanded the potential applications of LLMs to a diverse array of challenging domains, including mathematical reasoning, software development, and scientific research [7, 8, 13, 18]. To address these complex tasks, researchers have developed a methodology that decomposes them into distinct sub-tasks [7]. This approach employs multiple LLM-powered agents that collaborate, each focusing on specific aspects of the overall task, to derive comprehensive solutions. By mimicking human cognitive processes, this method enhances reasoning capabilities and problem-solving efficacy.\nThis collaborative approach significantly addresses a critical limitation of previous deep learning and RL models by enhancing model explainability. The transparent nature of the agents' thought processes through Chain of Thought (CoT) prompting allows for step-by-step tracking of solution derivation, providing valuable insights into their decision-making [35]. This explainable approach not only facilitates a deeper understanding of model operations but also enables the fine-tuning of agent prompts, framework design, and task assignment. Furthermore, the emergence of multi-modal LLMs, such as GPT-4V and the cost-effective GPT-4o, has further expanded LLM capabilities by incorporating both textual and visual data [16]. This integration of multimodal inputs enhances the versatility and applicability of LLM-based agents across a broader range of complex tasks [8].\nThese advancements unlock new possibilities for comprehensive analysis across various domains, particularly in finance. In this field, integrating diverse data types-such as textual reports, news articles, and visual data like charts-is essential for making accurate trading decisions. The evolution of LLMs and multi-agent systems holds the potential to revolutionize financial analysis by providing more sophisticated approaches to understanding market dynamics. The application of LLMs in stock prediction has been evolving, with existing studies primarily focusing on methods such as pre-trained LLMs or instruction tuning, which require extensively annotated datasets [21, 28, 29]. In the context of LLM-based agents, FinAgent proposed a multimodal LLM trading agent with market intelligence and reflection modules [34]. Our study builds upon this framework by experimenting with a significantly shorter training time of just two months, which helps to reduce API costs. Furthermore, we extend the decision-making process by requiring the model to predict the position size for trading as a percentage"}, {"title": "2 Related Works", "content": "Large Language Models (LLMs) have demonstrated strong capabilities across various Natural Language Processing (NLP) tasks [1, 3, 15, 16, 23]. In the finance domain, recent studies have leveraged LLMs for sentiment analysis through instruction fine-tuning, achieving superior performance compared to previous state-of-the-art models [31]. A limited number of studies have explored LLMs' potential in predicting stock market movements and conducting next-day trading through in-context learning, where historical prices and news are used to forecast future movements. However, due to the multi-modal nature of financial data and the need for multi-step reasoning, LLMs initially struggled with effective reasoning and performance in these complex tasks.\nOne study investigated the sentiment extracted from GPT-4 and ChatGPT and its correlation with stock price movements [21, 25]. Another study involved instruction fine-tuning LLaMA models on various financial tasks, including stock market prediction [26]. However, fine-tuning requires massive annotated training data, and the results often lack explainability, which makes refining and improving the models challenging.\nRecently, LLM-based agents have revolutionized the field by equipping systems with advanced cognitive skills for multi-step reasoning and interaction. The use of multiple agents has been widely adopted to enhance reasoning and factuality through frameworks such as Multi-Agent Debate (MAD) and ReConcile, where multiple AI agents engage in collaborative problem-solving to improve reasoning and decision-making abilities by emulating human discussion processes [4-6]. In the realm of LLM-based agents, FinMem introduced an LLM trading agent with a memory mechanism that incorporates numerical historical prices but lacks agents with visual reasoning capabilities [30]. Another research effort proposed FinAgent, a multi-modal LLM trading agent equipped with market intelligence, low-level and high-level reflection modules, and a tool-augmented decision-making process [34]. While FinAgent demonstrated promising results, it required a lengthy one-year training period, leading to significant API costs. Additionally, an essential component of trading, risk management, was not accounted for in the context of this study.\nOur work aims to bridge this gap by applying a multi-modal multi-agent LLM framework to the complex domain of financial trading tasks, featuring a short two-month training period and incorporating risk management into the framework."}, {"title": "3 Methodology", "content": "In this section, we outline the task definition and data specifications for our stock trading framework."}, {"title": "3.1 Summary Module", "content": "The Summary module generates concise, informative summaries from input texts. We prompt an agent to generate summaries of factual information about a specific ticker s from the provided news corpora for the previous day. This process can be formalized as:\n$X_{t-1}^1 = \\text{agent}_{\\text{summarizer}}(s, C_{t-1}, \\text{prompt}_{\\text{summary}})$ (1)\nwhere s is the specified stock, $C_{t-1}$ represents the news text inputs for the previous day, $\\text{agent}_{\\text{summarizer}}$ is the language model agent generating the summary, $X_{t-1}^1$ is the generated summary, and $\\text{prompt}_{\\text{summary}}$ is the instruction given to the agent for the summarization task. This approach distills the previous day's news into concise and pertinent summaries for financial analysis. The prompt message utilized by this agent is presented in Table 4 in Appendix A."}, {"title": "3.2 Technical Analyst Module", "content": "The Technical Analyst module extracts insights from historical price data and technical indicators presented in image format. We prompt an agent to analyze the visual data and generate technical insights for a specific ticker s. This process can be formalized as:\n$X_{t-1}^2 = \\text{agent}_{\\text{technical}}(s, I_{t-1}, \\text{prompt}_{\\text{technical}})$ (2)\nwhere s is the specified stock, $I_{t-1}$ represents the candlestick chart and technical indicator images for the past 60 days up to day t - 1, $\\text{agent}_{\\text{technical}}$ is the vision-capable language model agent generating the technical analysis, $X_{t-1}^2$ is the generated technical analysis, and $\\text{prompt}_{\\text{technical}}$ is the instruction given to the agent for the technical analysis task. This approach leverages the LLM's visual reasoning capabilities to interpret charts and technical indicators, identifying patterns, trends, and potential signals that could influence the stock's future performance. The Technical Analyst module"}, {"title": "3.3 Reflection Module", "content": "The Reflection Module consists of two parts that analyze past trading performance and signals. The first part can be formalized as:\n$X_{t-1}^3 = \\text{agent}_{\\text{reflection1}}(s, H_{t-L:t-1}, \\text{prompt}_{\\text{reflection1}})$ (3)\nwhere s is the specified stock, $H_{t-L:t-1}$ represents the historical trading data and performance for the past L days up to day t - 1, $\\text{agent}_{\\text{reflection1}}$ is the language model agent generating short-term and medium-term insights, $X_{t-1}^3$ is the generated reflection, and $\\text{prompt}_{\\text{reflection1}}$ is the instruction given to the agent for this task. This component provides insights into recent trading performance and decision effectiveness. The second part of the Reflection Module can be formalized as:\n$X_{t-1}^4 = \\text{agent}_{\\text{reflection2}}(s, V_{t-1}, \\text{prompt}_{\\text{reflection2}})$ (4)\nwhere $V_{t-1}$ is the visual representation of trading signals for the past 30 days up to day t \u2013 1, generated by a plotting tool, $\\text{agent}_{\\text{reflection2}}$ is the vision-capable language model agent analyzing this visual data, $X_{t-1}^4$ is the generated feedback, and $\\text{prompt}_{\\text{reflection2}}$ is the instruction for this visual analysis task. This component offers insights into trading signal patterns and their effectiveness based on the visual data. The prompt messages utilized by these agents are presented in Table 4 in Appendix A."}, {"title": "3.4 Final Decision Module", "content": "The Final Decision module generates trading recommendations by integrating comprehensive analyses from previous modules, including news summaries, technical analysis, and reflection outcomes. The decision-making process for each stock can be formalized as:\n$A_{t} = \\text{agent}_{\\text{decision}}(s, X_{t-1}^1, X_{t-1}^2, X_{t-1}^3, X_{t-1}^4, P_{t-1}, \\text{prompt}_{\\text{trading}})$ (5)\nwhere s is the specified stock, $X_{t-1}^1$ is the summary from the Summary module, $X_{t-1}^2$ is the technical analysis from the Technical Analyst module, $X_{t-1}^3$ and $X_{t-1}^4$ are the reflections from the Reflection module, $P_{t-1}$ represents the portfolio status from the previous day generated by the Reward Agent, $\\text{agent}_{\\text{decision}}$ is the language model agent specialized in decision-making, and $\\text{prompt}_{\\text{trading}}$ is the instruction for the trading decision task. The output $A_{t} = (a_{st}, p_{st}, e_{\\text{trading}})$ consists of the recommended action $\\hat{a}_{st} \\in \\{\\text{BUY, SELL, HOLD}\\}$, the position size $p_{st} \\in [1, 10]$ (0 if $\\hat{a}_{st} = \\text{HOLD}$), and the detailed explanation $e_{\\text{trading}}$. This approach ensures that the trading decision benefits from the comprehensive"}, {"title": "3.5 Implementation Details", "content": "Our multi-agent system utilizes the LangGraph library\u00b9 to implement a directed graph structure, where each node corresponds to a specialized agent. The StateGraph class is employed to define the dependencies among agents and manage the flow of information. All agents, except for the final decision agent, utilize the GPT-4o-mini model, a capable multi-modal language model, with a temperature setting of 0.3 to achieve uniform outputs. Notably, the Chart Agent and a portion of the Reflection Agent leverage the model's vision capabilities to analyze candlestick charts, technical indicators, and trading signal images. The Prediction Agent, tasked with making the final trading decision, operates using the 01-mini model, a new GPT model designed for advanced reasoning tasks, with a temperature setting of 1 (the only available option for this model). Additionally, a custom AgentState class manages the trading system's state, encapsulating all relevant trading information. This modular design facilitates flexible agent tuning or replacement while maintaining consistent multi-modal processing throughout the pipeline."}, {"title": "4 Experiments", "content": "To validate the effectiveness of our proposed multi-agent framework, we conduct comprehensive experiments comparing it against baseline models."}, {"title": "4.1 Data Collection", "content": "Our study examines three major technology stocks\u2014Apple (AAPL), Amazon (AMZN), and Microsoft (MSFT)\u2014over a nine-month period from April 1, 2023, to December 29, 2023. We structured this time frame into a two-month training period (April 1 to May 31, 2023) and a seven-month testing period (June 1 to December 29, 2023). The dataset comprises news articles sourced from Yahoo Finance, 2 daily candlestick charts, technical indicators, and reflection data. The candlestick charts, technical indicators, and trading signal images for reflection were all plotted using Matplotlib and various finance libraries. Specifically, we incorporated the following technical indicators: Simple Moving Averages (10 and 50-day), Relative Strength Index (14-day period), Bollinger Bands (20-day period with 2 standard deviations), trading volume, and Moving Average Convergence Divergence (MACD). Reflection data includes trading signal images (which contain signals from previous days) and performance data from past trading activities. This initial training period was crucial for generating sufficient reflection data, ensuring that our multi-agent system had robust historical inputs for the subsequent testing phase. Table 1 presents a summary of our dataset statistics, detailing the number of trading days, news articles, charts, and technical indicators for each asset throughout the study period."}, {"title": "4.2 Evaluation Metrics", "content": "To comprehensively assess the performance of our multi-agent trading system, we employ the following key metrics:\n\u2022 Annual Rate of Return (ARR): This metric provides an annualized measure of portfolio growth, calculated as:\n$\\text{ARR} = \\frac{P_T - P_0}{P_0} \\cdot \\frac{C}{T}$ (6)\nwhere T is the total number of trading days, C is the number of trading days within a year, and $P_T$ and $P_0$ represent the final and initial portfolio values, respectively.\n\u2022 Sharpe Ratio (SR): This measures risk-adjusted returns of portfolios, defined as:\n$\\text{Sharpe Ratio} = \\frac{R_p - R_f}{\\sigma_p}$ (7)\nwhere $R_p$ is the portfolio's average return, $R_f$ is the risk-free rate, and $\\sigma_p$ is the portfolio's volatility. A higher Sharpe Ratio suggests better risk-adjusted performance.\n\u2022 Maximum Drawdown (MDD): This metric measures the largest percentage decline from a historical peak in portfolio value. It is defined as:\n$\\text{MDD} = \\max_{t \\in (0,T)} \\frac{PV_{\\text{peak},t} - PV_t}{PV_{\\text{peak},t}}$ (8)\nwhere $PV_t = \\prod_{i=1}^t V_i$ is the cumulative return up to time t, and $PV_{\\text{peak},t} = \\max_{i \\in (1,t)} PV_i$ is the highest cumulative return up to time t. Here, $V_i$ denotes the portfolio value at time i."}, {"title": "4.3 Benchmark Models", "content": "To evaluate our multi-agent trading framework, we compare its performance against traditional trading strategies and advanced algorithmic approaches:\n4.3.1 Traditional Strategies. We implement three widely-used trading strategies: (1) Buy-and-Hold (B&H), a passive long-term investment approach; (2) Moving Average Convergence Divergence (MACD), utilizing trend-following momentum indicators; and (3) KDJ with RSI Filter, combining oscillators for refined signal generation.\n4.3.2 Reinforcement Learning Models. We employ two reinforcement learning algorithms: (1) Proximal Policy Optimization (PPO), which optimizes trading policies while ensuring stable learning through constrained updates, and (2) Deep Q-Network (DQN),"}, {"title": "5 Main Results", "content": "Our framework demonstrated strong performance across three major technology stocks (AAPL, MSFT, and AMZN), as shown in Table 2. These results highlight its versatility and effectiveness as a trading strategy, especially in the context of a strongly bullish market during the test period.\nComparative Performance: Our FinVision framework outperformed the market buy-and-hold strategy for AAPL and MSFT in terms of Annual Return Rate (ARR) and risk-adjusted returns (Sharpe Ratio). For AAPL, the framework achieved a 14.79% ARR and a Sharpe Ratio of 1.20, compared to the market's 13.56% ARR and 0.67 Sharpe Ratio. Similarly, for MSFT, our framework's ARR of 25.57% and Sharpe Ratio of 1.41 surpassed the market's 22.27% ARR and 1.01 Sharpe Ratio. Although the framework's 42.14% ARR for AMZN slightly lagged behind the market's 43.57% ARR, it significantly improved risk-adjusted performance, achieving a Sharpe Ratio of 1.72 (compared to the market's 1.37) and a lower Maximum Drawdown of 12.09% (versus 17.45% for the market). These results demonstrate the capability of our system to generate competitive returns while effectively managing risk compared to passive strategies.\nPerformance in Bullish Markets: The effectiveness of the buy-and-hold strategy, particularly for AMZN (43.57% ARR), reflects the strong upward trend of these tech stocks during the test period. This bullish environment inherently favors passive strategies, making our framework's outperformance, or near-equivalent returns to buy-and-hold, particularly noteworthy. The framework's capacity to enhance risk-adjusted metrics while maintaining competitive returns demonstrates its effectiveness in risk management, even in strongly trending markets. These results indicate that the model provides value through both return optimization and more robust risk control approaches.\nSuperiority over RL-based Models: The framework demonstrated substantially higher performance compared to reinforcement learning (RL) based models, including PPO and DQN, across all evaluated stocks. For instance, with AAPL, our framework's 14.79% ARR and 1.20 Sharpe Ratio far exceeded those of PPO (7.26% ARR, -0.42 Sharpe Ratio) and DQN (1.22% ARR, -0.90 Sharpe Ratio). The consistent positive Sharpe Ratios achieved by the framework, in contrast to the negative Sharpe Ratios of RL models, indicate superior risk-adjusted performance. These performance differentials suggest that the integrated approach more effectively captures complex market dynamics compared to RL approaches, particularly in trending markets.\nHowever, our method underperformed compared to the FinAgent model, which underscores the efficiency of their extensive training data. Nevertheless, with much less training time, our framework performs well, suggesting potential for further tuning to enhance performance.\nImpact of Reflection Mechanism: The ablation study demonstrated that the reflection component significantly contributes to the framework's performance. A comparison between the full framework and the version without reflection shows substantial improvements in performance metrics across all stocks, validating the effectiveness of this adaptive learning mechanism. This component enables the framework to calibrate its strategy based on historical performance and market conditions, resulting in consistent performance across diverse stocks and market scenarios.\nOur multi-agent framework provides detailed visibility into its trading decision process. As illustrated in Table 3, the example from December 19, 2023, shows the framework's ability to effectively integrate diverse information sources. When technical indicators suggested a bullish trend for Apple stock, the prediction agent incorporated news signals and reflections from previous trading signals to arrive at a more nuanced decision, which proved accurate as the stock price peaked on that day compared to the following trading day. This explainable approach not only offers insights into the decision-making process but also facilitates the optimization of the framework for enhanced performance. Furthermore, the framework's ability to suggest position sizes adds an extra layer of risk management to the trading strategy. By providing clear reasoning for its recommendations, including the specific percentage of the portfolio to trade, the framework allows for more precise control over risk exposure. This combination of explainable decision-making and dynamic position sizing underscores the framework's effectiveness, demonstrating its potential for adaptable and risk-aware trading strategies in complex market conditions"}, {"title": "6 Conclusions and Future Work", "content": "In this study, we proposed a multi-modal multi-agent framework for financial trading tasks that demonstrates superior performance compared to traditional rule-based and reinforcement learning models. The framework implements a risk-controlled investment approach, achieving competitive returns while maintaining effective risk management. The reflection component emerges as a key contributor to the framework's performance, enabling adaptive learning based on historical outcomes and market conditions. Future research will focus on extending the framework by incorporating reinforcement learning techniques, particularly through fine-tuning the policy using verbal prompts in a dynamic refinement process, as proposed by [33]. This enhancement aims to improve the framework's adaptability to rapidly changing market conditions."}]}