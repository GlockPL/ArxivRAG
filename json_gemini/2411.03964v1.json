{"title": "What Really is Commonsense Knowledge?", "authors": ["Quyet V. Do", "Junze Li", "Tung-Duong Vuong", "Zhaowei Wang", "Yangqiu Song", "Xiaojuan Ma"], "abstract": "Commonsense datasets have been well developed in Natural Language Processing, mainly through crowdsource human annotation. However, there are debates on the genuineness of commonsense reasoning benchmarks. In specific, a significant portion of instances in some commonsense benchmarks do not concern commonsense knowledge. That problem would undermine the measurement of the true commonsense reasoning ability of evaluated models. Davis (2024) suggested that the problem originated from a blurry concept of commonsense knowledge, as distinguished from other types of knowledge. To demystify all of the above claims, in this study, we survey existing definitions of commonsense knowledge, ground into the three frameworks for defining concepts (Murphy, 2004), and consolidate them into a multi-framework unified definition of commonsense knowledge (so-called consolidated definition). We then use the consolidated definition for annotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets to examine the above claims. Our study shows that there exists a large portion of non-commonsense-knowledge instances in the two datasets, and a large performance gap on these two subsets where Large Language Models (LLMs) perform worse on commonsense-knowledge instances.", "sections": [{"title": "1 Introduction", "content": "Commonsense datasets have been well developed in Natural Language Processing since the last decade. As commonsense data is known to be implicit, almost all commonsense datasets are constructed through crowd source human annotation instead of relying on automated dataset construction processes. These commonsense datasets serves as valuable resources to augment AI models in various aspects, such as text generation (Zhou et al., 2021; Ilievski et al., 2021b), visual reasoning (Zellers et al., 2019a), or building more capable knowledge models for further downstream applications (Yu et al., 2022; Hwang et al., 2021; Wang et al., 2023a), as well as benchmarks to evaluate the reasoning capability of AI models (Talmor et al., 2019; Zhang et al., 2020; Bhagavatula et al., 2020; Talmor et al., 2022; Fang et al., 2023a).\nHowever, there are debates on the quality of commonsense datasets, especially when they serves as evaluation benchmarks. Davis (2024) argued that many prevalent commonsense datasets are flawed in the sense that they contained a significant portion of instances which do not concern commonsense knowledge but other types of knowledge, namely common, encyclopedia, and expert knowledge (so-called referenced in this work). For example, in the CommonsenseQA 2.0 dataset (Talmor et al., 2022) which consists of Yes/No questions (or assertions), the instance \u201cA male seahorse cannot give birth\" (Answer: no) presents common biology knowledge, meanwhile, \u201cElectrons are smaller than mesons\" (Answer: no) is certainly an encyclopedic fact. As it has been widely discussed that language models excel in memory or retrieval tasks while still struggle in reasoning tasks (Bang et al., 2023; Goldberg, 2023; Huang and Chang, 2023), the flaw in commonsense datasets would undermine the measurement of the true commonsense reasoning ability of evaluated models. Davis (2024) suggested that the problem originated from a blurry concept of commonsense knowledge, as distinguished from other types of knowledge. Due to that blurry concept, both annotators and researchers working on commonsense may not be aware of the genuineness problem of commonsense datasets.\nIndeed, according to our literature review, all works on commonsense have their ways to describe the concept. However, the description of each is not adequate and comprehensive to educate outsiders or even insiders of this research field about the concept and the difference with respect to other relevant concepts, such as referenced knowledge."}, {"title": null, "content": "Also, through the lens of concept definition theory (Murphy, 2004), we posit that each of the existing literature on commonsense only provides a limited number of features, making the concept commonsense not systematically and comprehensively depicted. Regarding the problems, Murphy (2004) suggested combining general description, examples, and list of features of the concept to form a complete definition.\nMotivated by that research gap, in this work, we consolidate the definition of commonsense as follow. Firstly, leveraging the descriptions about commonsense and referenced knowledge from previous works, we attempt to distinguish commonsense knowledge from referenced knowledge. We provide a table of representative cases for each concept to show (or more subjectively, assume) the fundamental and subtle difference of these two concepts. Based on the descriptions and examples, we systematically propose a list of multi-aspect binary-value features that characterize commonsense, referenced knowledge, and their difference. We then validate the significance of features through an empirical study on the CommonsenseQA (Talmor et al., 2019) and CommonsenseQA 2.0 (Talmor et al., 2022) datasets. Overall, we observe that 1) whether we can obtain the knowledge by our own experience/observation and 2) whether the knowledge is only mutual belief are the most significant features to identify commonsense from referenced knowledge.\nGiven the consolidated definition, we analyze the portion of instances of commonsense and referenced knowledge in the development sets of the CommonsenseQA and CommonsenseQA 2.0 datasets, as well as the performance of Large Language Models (LLMs) such as Gemini-Pro, ChatGPT, LLaMa2-7B, and Mixtral-8x7B on the commonsense-knowledge subsets (which consists of instances required commonsense knowledge to answer) and referenced-knowledge subsets from these datasets. Aligned with the claims which motivate for this work, we observe a large portion of referenced knowledge in the two datasets (0.27 \u00b1 0.09 for CommonsenseQA and 0.56 \u00b1 0.1 for CommonsenseQA 2.0)\u00b9, and a large performance gap (4 to 7 point of accuracy) on these two subsets, where LLMs perform worse on commonsense-knowledge instances, suggesting that commonsense reasoning tasks or reasoning tasks in general are more challenging than memory-retrieval tasks.\nThe organization of this paper is as follows. In section 2, we discuss related works (especially background knowledge on the frameworks to define a concept in Murphy (2004)). In section 3, we show a comprehensive survey on the definitions of commonsense knowledge by grounding relevant previous works into three aforementioned definition frameworks, then provide a table of representative cases. After that, we describe the list of features and validation procedure. Finally, in section 4, we apply the consolidated definition to demystify relevant claims which motivate this work."}, {"title": "2 Background and Related Works", "content": "Commonsense Research on commonsense had been started from the last century and early 2000s, with the foundational works such as Davis (1990); Lenat (1995); McCarthy (2002); Liu and Singh (2004). They laid the first building blocks on the definition, meaning, and practical application of commonsense knowledge in the field of language processing. Recent time has witnessed a drastic development of research in commonsense knowledge and reasoning, including resources and benchmarks, with the wide range of format (free text, knowledge graph, knowledge bases, etc.), topics (concept taxonomy, geographical tradition, daily inference, etc.), evaluation tasks (abductive reasoning, question answering, or generation), as well as semantics dimensions (physical, linguistic, textual worlds, etc.) (Ilievski et al., 2021a). Despite a number of works on commonsense, in section 3, we show that the definition of commonsense in existing works is not comprehensive, which possibly leads to the quality problem of commonsense datasets.\nDefinition Frameworks As introduced in the The Big Book of Concepts (Murphy, 2004), there are three major frameworks of how we understand and organize the world around us through the notion of concepts. These frameworks motivate four main Views of concept: Classical View, Prototype View, Exemplar View, and Knowledge View. In layman term, a View of concept means a theoretical way to define a concept.\nMotivating the Knowledge View (Murphy and Medin, 1985), the ideal framework (Barsalou, 1985) views each concept as a part of our knowledge and understanding of the world, in which we do not learn concepts in isolation. It describes how"}, {"title": null, "content": "each concept fits in other parts of our lives, e.g. what is its meaning, how to use it, why people create it, etc. For examples, through the ideal framework, weapon is defined as a thing \u201cdesigned or used for inflicting bodily harm or physical damage\".\nThe feature framework, which bases Classical and Prototype Views, represents a concept by a list of its most typical features. In item categorization, one may examine the similarity of the item to the feature list, then for every feature the item has, it gets \"credit\" for the feature's weight, accumulating to the typicality of the item w.r.t. to the concept. Features are in fact not necessarily disjoint in term of semantics. For example, weapon can be characterized by three features \u201ccan do harm\u201d, \u201cmade of metal\u201d, and \u201csharp\u201d. In a more complex setting (e.g. schemata), value of each feature can be nominal or continuous. However, in this work, we only consider a simple setting with binary-value feature.\nIn contrast, the exemplar framework, as the core of Exemplar View, represents a concept through a collection of specific instances or exemplars that exemplify the concept. This framework emphasizes the role of individual examples in categorization and facilitates greater flexibility in category boundaries. Overall, each framework concerns a level of abstraction of a concept, and one framework is likely not adequate to represent the concept.\nAnalysis with Categorization By nature, the human knowledge is expanded through the separation of concepts for deeper study. Many developments of different fields, e.g. AI (Huang and Chang, 2023; Sun et al., 2023; Wang et al., 2023b), cognitive science (Genon et al., 2018), medicine (Stein et al., 2013), etc., follow the pattern to offer deeper understanding of existing problems and better solutions. Recently, in the field of of AI, there are more and more efforts put into such type of analytical works. For example, to study the design bias of datasets and models in term of their creators' identity and background, Santy et al. (2023) introduced a framework to quantify the alignments of human subjects of different demographic categories with datasets' labels and model predictions. Likewise, Fang et al. (2023b) systematically define distinct kinds of bias in event temporal reasoning, then study knowledge conflicts arising from mismatches between actual temporal relations of events and the prior biases learned by the model. Similarly, in this work, we define commonsense as distinguished from referenced knowledge to better understand how LLMs perform in instances regarding each type of knowledge.\nTerminology To avoid ambiguity, we explain some terminology used in this work. The word \"commonsense\" refers to commonsense knowledge (e.g. Mountains are high), and \u201cnon-commonsense\" refers to knowledge of another type (e.g. Washington D.C. is the capital of the US) rather than an incorrect commonsense knowledge (e.g. PersonX likely goes to sleep when he is hungry). Furthermore, \"knowledge type of an instance\" refers to the type of the knowledge used to do the corresponding task with the instance."}, {"title": "3 Commonsense vs. Referenced Knowledge", "content": null}, {"title": "3.1 \"Commonsense\u201d in Previous Works", "content": "A summary of literature review on many previous works on commonsense in term of three definition frameworks - ideal, feature, and exemplar is shown in Table 1. In the table, we show representative works from three groups: 1) decade-old-foundational or theoretical works, 2) works from the Allen Institute for Artificial Intelligence (AI2)2, 3) works from a variety of research groups.\nIn general, except decade-old-foundational or theoretical works, all other works that we surveyed (Sap et al., 2019a; Talmor et al., 2019; Sap et al., 2019b; Zellers et al., 2018, 2019b; Hwang et al., 2021; Lourie et al., 2021; Forbes et al., 2020; Onoe et al., 2021; Zhang et al., 2023; Richardson and Heck, 2023; Madaan et al., 2022; Sun et al., 2022; Maharana and Bansal, 2022; Lu et al., 2023; Yin et al., 2022; Porada et al., 2022; Zhou et al., 2022; Qasemi et al., 2022; Zhou et al., 2020) do not provide any defining feature about the concept \"commonsense\". They rather provide minimum description (varying from one paragraph to one sentence) as domain-specific ideal about commonsense. That is a common phenomenon in reporting, as humans tend not to fully express a term defined before. Indeed, aforementioned works rely on previous works for reference about the concept. Interestingly, we observed that almost all works in group 2 and 3 refer the concept \"commonsense\u201d back to Liu and Singh (2004), and a majority of works in group 3 refer it back to or cite works in group 2. In term"}, {"title": "3.2 Descriptions and Examples", "content": "We give a summary of assertions that concern either commonsense or referenced knowledge in Table 2 (with reference to previous works), as the mutual ground between us and readers to base our proposal of a list of binary-value features that distinguishes commonsense from referenced knowledge.\nIn term of definition frameworks of concept, the assumption lies between and bridge the exemplar and feature frameworks. It not only regards the definition of concepts to instance level, but also summarizes instances into some representatives of the two concepts, which provide cues of the features by which we can discriminate the two concepts."}, {"title": "3.3 Features of Two Knowledge Types", "content": "To discriminate the two concepts, we dive deep into multiple aspects of knowledge, such as:\n\u2022 Acquisition: where to acquire the knowledge,\n\u2022 Content + Representation: which topics and objects does the knowledge regard,\n\u2022 Scope + Context + Evaluation: to what extent do people agree with or accept the knowledge (here, we do not consider \u201cknowing\u201d, as it is subjective)\nFor each of the aspects, we inherit the viewpoints from previous works and propose extra viewpoints as binary-value features to justify if one instance concerns commonsense or referenced knowledge. Depending on each feature, having the feature (i.e. having value 1) would make the instance inclined to commonsense or referenced knowledge (i.e. the knowledge type tendency of features). These features are summarized in Table 3.\nIt can be observed that the features are not mutually disjoint in terms of semantics (even features in the same aspect). Also, this list may not be complete. However, as the first attempt to toward a comprehensive definition of commonsense, we only work on aforementioned aspects and features. The features are referenced or self-observed but all deemed subjective, thus, it is unclear about the statistical significance of these features in determining which knowledge is commonsense. Therefore, in the next subsection, we conduct a study on the CommonsenseQA and CommonsenseQA 2.0 datasets for examination. We explain our choice of datasets in Appendix B."}, {"title": "3.4 Significance of Selected Features", "content": "Expert Annotation We recruit three expert annotators who are postgraduate research students and having at least one year of research experience in the topic of commonsense. We randomly sample 100 instances from the development set of CommonsenseQA and CommonsenseQA 2.0, then ask three annotators to: 1) first, annotate the knowledge type of each instance (either commonsense or referenced), 2) then, after a week\u00b3, annotate the knowledge type tendency of each instance with respect to each feature. The aggregated value of knowledge type and features are the majority among three annotations."}, {"title": "4 Analysis of Commonsense Datasets", "content": null}, {"title": "4.1 Fraction of Non-commonsense Instances in Commonsense Datasets", "content": "By the annotation of knowledge type of 100 instances in subsection 3.4, we estimate the 95% confidence interval of the proportion $p$ of non-commonsense instances in CommonsenseQA and CommonsenseQA 2.0 datasets. As the label is binary, we treat the knowledge type of an instance as a random variable of binomial distribution, with probability of referenced knowledge type (i.e. value 1) is $p$. By our computation, the proportion $p$ of non-commonsense instances in CommonsenseQA and CommonsenseQA 2.0 datasets are 0.27 \u00b1 0.09 and 0.56 \u00b1 0.1, which suggests the genuineness problem of the two datasets.\nWe also consider other famous commonsense datasets: WSC (Levesque et al., 2012) (one of the first commonsense benchmarks), HellaSwag (Zellers et al., 2019b) (included in HELM Classic (Liang et al., 2023)), and aNLI (Bhagavatula et al., 2020) (abductive reasoning). By the nature of the data from WSC, every instance expresses a specific situation and the task as coreference resolution, which requires implicit (linguistic) knowledge without any proven evidence. Thus, these instances are deemed to be \"Derivative of facts which is not written down and not always true\" (Table 2), which are assumed to be commonsense. That means the portion of non-commonsense knowledge instances in WSC is insignificant. Likewise, aNLI concerns daily situation, thus the dataset is also likely genuine. We proof-check this heuristic by observing 50 random samples in each dataset, the result is as expected. At the meantime, HellaSwag is constructed from two datasets ActivityNet (Krishna et al., 2017) and WikiHow (Koupaee and Wang, 2018). While instances from ActivityNet is as situational as in aNLI, instances from WikiHow is not always commonsense but expert or specialized long-tail engineering knowledge. We evaluate 50 random sam-"}, {"title": "4.2 LLMs' Performance on Commonsense- and Referenced-Knowledge Instances", "content": "For both CommonsenseQA and CommonsenseQA 2.0, we aim to compare the accuracy of LLMs on two subsets, one is on a subset consisting of commonsense-knowledge instances, the other is on a subset consisting of referenced-knowledge instances. Following the prior analysis work (Santy et al., 2023), we scale the annotation of knowledge type to 300 instances for CommonsenseQA and CommonsenseQA 2.0.\nWe employ four LLMs, which are Gemini-Pro, ChatGPT (Jun 2023 version), LLaMa2-7B-chat, and Mixtral-8x7B, as they are available, stable, and four of the most capable models at the time we were conducting our experiments. We set temperature T = 0 and use zero-shot prompt for all generation. The prompt instruction for each task is adapted from HELM. The result is shown in Table 4. We notice a significant performance gap (varying from 4 points to 7 points accuracy) between the performance of LLMs, except ChatGPT, on the two subsets of both datasets. It suggests that tasks involving commonsense knowledge (or in a possibly overclaimed term, commonsense reasoning tasks) are more challenging than tasks involving referenced knowledge, which concerns memory retrieval. In term of ChatGPT, we argue that because OpenAI collects conversation data to further train the models and there are a lot of commonsense benchmarks are used to evaluate ChatGPT, ChatGPT is well-trained with verbalized commonsense knowledge."}, {"title": "5 Conclusion", "content": "In this work, we demystify claims regarding the genuineness of commonsense datasets. We survey and consolidate existing definitions of commonsense knowledge through the three frameworks for defining concepts. We then use the consolidated definition to show that there exists a large portion of non-commonsense knowledge in CommonsenseQA and CommonsenseQA 2.0. There is also a large performance gap on two subsets of commonsense and referenced knowledge in the two datasets, where LLMs perform worse on commonsense-knowledge instances. Although we do not long for perfect commonsense datasets, our work aims to raise the awareness of the genuineness problem of commonsense datasets. In general to the NLP community, we call for theoretical works on subfields of NLP research which deal with unclear concepts. That would facilitate better understanding of the underlining problems for the NLP community."}, {"title": "Limitation", "content": "This paper works on the definition of commonsense as distinguished from referenced knowledge the cover of common, encyclopedic, and expert knowledge, and based on that, it demystifies claims concerning commonsense. Due to limited human resource, only a few datasets are empirically studied and the obtained results are unavoidably subjective in a certain level. Further study with a larger scale is expected to examine the generalizability of insights drawed from this work. Also, this work discusses the blurry concept of commonsense from perspectives of annotators and researchers working on commonsense, which possibly lead to the genuineness problem of commonsense datasets, however, there is no empirical study as attempt to clarify the cause. Experiments with researchers from various research groups and crowdsourced annotators (e.g. in Amazon Mechanical Turk) are preferred to make the arguments in this work more convincing."}, {"title": "Ethical Statments", "content": "This work provides a (more) comprehensive literature of the concept \"commonsense\" by examining and experimenting with many commonsense datasets and benchmarks. Thus, this work shares the same ethical issues as these previous works. By our inspection, all sampled data instances do not contain any private information about any specific entities (e.g., a person or company). We carried out human expert annotation, where annotators are fairly paid according to the minimum wage requirement of the local government.\nIn another aspect, the study of LLMs' performance on data subsets of different knowledge types involves the use of Gemini (gemini-pro), ChatGPT (gpt-3.5-turbo-0613), LLaMa2 (llama-2-7b-chat-hf), and Mixtral (mixtral-8x7b-instruct). Except LLaMa2 which is deployed on local server, other three LLMs are called via APIs provided by GoogleAI, OpenAI, and Fireworks.AI respectively. Thus, the same risks from LLMs research are applicable to this work (Bender et al., 2021)."}, {"title": "A Discussion on Knowledge Types", "content": null}, {"title": "A.1 General", "content": "Although we aim to discriminate commonsense from referenced knowledge, we are not strict in the discrimination (and almost impossible to do it perfectly). It is undeniable that the knowledge type is varying between different people and even different timestamps of a person. We name it the circulation of knowledge, or the journey from unknown to known and popular of a knowledge. A person may learned a popular knowledge from official mass media directly, or learned a knowledge from observation (thus treat it as commonsense), then the knowledge may be conventionalized to be a referenced knowledge. A referenced knowledge that a person does not know may be commonsense for them.\nAbout our decision to group common, expert, and encyclopedic knowledge into the same categories; we observe the dynamics of these knowledge types through time. An expert/encyclopedic knowledge can be popularized, making it more \"common\" to public. Also, a common knowledge for a person may be expert knowledge for others, as different people have different expertise. In fact, by our annotation on CommonsenseQA, the proportion of encyclopedic/expert knowledge is approximately 5%. Therefore, we merge them to a group, named referenced knowledge, as the knowledge is true by nature or conventionalized and it need a reference for its validity.\nFurthermore, we want to relate commonsense and referenced knowledge in our work to other concepts. About the data frequency or distribution, we aforementioned, commonsense tends to be more \"long-tail\" than referenced knowledge. In term of reasoning, commonsense likely exists and be necessary for with abductive reasoning, while referenced associate with logical reasoning. Likewise, commonsense knowledge represents a probabilistic world, and referenced knowledge bases a deterministic world."}, {"title": "B Further Discussion and Supplementary Materials", "content": null}, {"title": "B.1 Choices of Datasets and Annotation Objective", "content": "There are several prevalent (textual) commonsense datasets such as ATOMIC, SocialIQA, Social-Chemistry101, etc., however, we choose Com-"}, {"title": "B.3 Better Guideline for Annotation", "content": "Based on the consolidated definition commonsense, one may rely on the proximity of new instance to the representative cases in Table 2 to decide the knowledge type. Meanwhile, for uncertain cases, one can work with the feature lists in Table 3. Note that the significance of features may vary according to data distribution, thus a pilot study of the significance of features is preferred for better judgment. Nonetheless, 1) whether we can obtain the knowledge by our own experience/observation and 2) whether the knowledge is only mutual belief are the most significant features to identify commonsense from referenced knowledge."}, {"title": "B.4 Portion of Non-Commonsense Instance", "content": "We are aware of the p-hacking problem with sampled data, thus we extend the annotation of knowledge type on CommonsenseQA to its whole development set which consists of 1221 instances and recompute the confidence interval to prove the representativeness of our sampled data. We get 0.2153 \u00b1 0.0231, which is expectedly not varying much in term of lower bound in comparison to previously computed confidence interval. Also, as some people may argue the subjectivity in annotation of basic knowledge which lies between of commonsense and referenced knowledge, we analyze the portion of encyclopedic and expert knowledge which are certainly non-commonsense. Considering the whole development set of CommonsenseQA, there are approximately 5% of the instances which concern encyclopedic and expert knowledge."}, {"title": "B.5 Evaluation of LLMs on Two Subsets", "content": "We want to treat the accuracy as the mean of random variables from two populations (i.e. two subsets), whose random variables are indicator functions with each representing if an LLM's answer to a task instance is correct, and conduct the Two-sample t-test. However, the distribution of our data is binomial, which does not satisfy the assumption of data normality of the test. Therefore, we only compare the accuracy in a straight forward manner."}]}