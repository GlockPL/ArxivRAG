{"title": "HGTUL: A Hypergraph-based Model For Trajectory User Linking", "authors": ["Fengjie Chang", "Xinning Zhu", "Zheng Hu", "Yang Qin"], "abstract": "Trajectory User Linking (TUL), which links anonymous trajectories with users who generate them, plays a crucial role in modeling human mobility. Despite significant advancements in this field, existing studies primarily neglect the high-order inter-trajectory relationships, which represent complex associations among multiple trajectories, manifested through multi-location co-occurrence patterns emerging when trajectories intersect at various Points of Interest (POIs). Furthermore, they also overlook the variable influence of POIs on different trajectories, as well as the user class imbalance problem caused by disparities in user activity levels and check-in frequencies. To address these limitations, we propose a novel HyperGraph-based multi-perspective Trajectory User Linking model (HGTUL). Our model learns trajectory representations from both relational and spatio-temporal perspectives: (1) it captures high-order associations among trajectories by constructing a trajectory hypergraph and leverages a hypergraph attention network to learn the variable impact of POIs on trajectories; (2) it models the spatio-temporal characteristics of trajectories by incorporating their temporal and spatial information into a sequential encoder. Moreover, we design a data balancing method to effectively address the user class imbalance problem and experimentally validate its significance in TUL. Extensive experiments on three real-world datasets demonstrate that HGTUL outperforms state-of-the-art baselines, achieving improvements of 2.57%~20.09% and 5.68%~26.00% in ACC@1 and Macro-F1 metrics, respectively.", "sections": [{"title": "INTRODUCTION", "content": "In recent years, with the rapid development of GPS-based devices and Location-Based Social Networks (LBSN), vast amounts of spatio-temporal trajectory data have been recorded and stored. These data not only contain rich geographical information but also deeply reflect human daily activities and mobility patterns. Through the analysis of trajectory data, researchers can gain insights into complex issues in fields such as urban traffic optimization [22], population flow dynamics [12], and personalized recommendation systems [7]. Among these, Trajectory User Linking (TUL) was recently proposed by Gao et al [9]. The core objective of TUL is to link the anonymous trajectories to the users who generate them. This task holds significant application value in both public safety and commercial fields. For instance, in public safety, TUL can assist in identifying the movement patterns of potential terrorists or criminal suspects; in the commercial domain, it can support personalized recommendations by analyzing user behavior patterns.\nOver the past few years, substantial efforts have been devoted to solving the TUL problem. Deep learning-based methods for TUL can be primarily categorized into two main approaches. The sequence-based models [9] [26] [16] capture user movement patterns by analyzing the time-series features of trajectory points. TULER [9] first utilizes word embedding [17] to learn location representations, which are then fed into an RNN model to capture sequential transition patterns for TUL. DeepTUL [16] employ an attentive RNN to learn from labeled historical trajectory, capturing the multi-periodicity of human mobility while alleviating data sparsity. The graph-based models [25][6][3] leverage GNNs to model locations or trajectories for TUL. GNNTUL [25] builds a check-in graph that combines geographical and temporal information, utilizing a GNN to model user mobility patterns effectively. S2TUL [6] is the first attempt to incorporate trajectory-level information for modeling the TUL problem. It models the inter-trajectory relationships via multiple homogeneous graphs and a GCN for TUL.\nDespite significant prior research, several key challenges still persist in the TUL problem."}, {"title": "RELATED WORK", "content": "Trajectory data provides unprecedented insights into human mobility patterns. Recently, TUL problem was introduced in [9], which links trajectories to their generating-users, and gradually becomes a hot topic in spatio-temporal data mining. Deep learning-based methods for TUL can be broadly categorized into two distinct modeling approaches:\n(1) Sequence-based modeling methods represent trajectories as time-series to address the TUL task. TULER [9] utilizes RNNs to learn sequential transition patterns from trajectory data and link them to users. It first employs word embedding to learn location representations and then fed them into RNN model to capture user mobility patterns for TUL. However, standard RNN-based models face data sparsity issues due to their limitation in leveraging the unlabeled data that inherently contains rich information about user mobility patterns. In their subsequent work [26], TULVAE alleviates the data sparsity problem by leveraging large-scale unlabeled data and captures the hierarchical and structural semantics of trajectories through Variational Autoencoder (VAE). However, it does not exploit the rich features within trajectories or consider the multi-periodicity of human mobility. DeepTUL [16] addresses this limitation by employing an attentive recurrent network to learn from historical trajectory, capturing the multi-periodicity of human mobility while mitigating data sparsity. However, these methods primarily rely on existing sequence models such as LSTM [9] [26] or attention mechanism [16] to capture intra-trajectory information and generate trajectory representations but fail to capture the global association relationships between trajectories.\n(2) Graph-based methods leverage GNNs to model locations or trajectories, capturing more complex and diverse relationships. Instead of only relying on visited sequences as previous methods did, GNNTUL [25] constructs a check-in graph that integrates geographical and temporal information and leverages GNN to effectively model user mobility patterns. However, despite modeling transition patterns using GNN, it remains limited in capturing inter-trajectory relationships. S2TUL [6] is the first attempt to incorporate trajectory-level information for modeling the TUL problem. It models the complex relationships between trajectories by constructing multiple homogeneous and heterogeneous graphs, and then passes this information through a GCN to learn trajectory representations. And then, it combines intra-trajectory and inter-trajectory information to predict the generating users of trajectories. Nevertheless, the aforementioned methods overlook the integration and synergy of local and global information. AttnTUL [3] proposes a hierarchical spatio-temporal attention neural network, which simultaneously models the local and global spatio-temporal characteristics of user mobility trajectories through a GNN architecture. And it designs a hierarchical attention network to jointly encode local transition patterns and global spatial dependencies for TUL. However, due to the limitations of traditional graph structures, they can only model pairwise relationships and fail to effectively capture high-order inter-trajectory association relationships, thus limiting the representation of mobility patterns in trajectories."}, {"title": "Hypergraph Learning", "content": "Hypergraph [1][8][10] is a generalization of graph, which can naturally model complex higher-order relationships among vertices by connecting multiple vertices simultaneously through hyperedges. Due to its remarkable ability to capture higher-order relations, hypergraphs have increasingly drawn significant attention from researchers. To efficiently learn deep embeddings on higher-order graph-structured data, [1] proposed to extend the graph neural network architecture to hypergraphs by introducing two end-to-end trainable operators, namely hypergraph convolution and hypergraph attention.\nIn recent years, hypergraph neural networks have been widely used in spatio-temporal data modeling and user mapping tasks. In user mapping, UMAH [23] models social structure and user profile relationships in a unified hypergraph, learns a common subspace by preserving the hypergraph structure as well as the correspondence relations of labeled users, and facilitates user mapping across social networks based on similarities in the subspace. For spatio-temporal data modeling, STHGCN [20] constructs a hypergraph to model trajectory granularity information, and captures higher-order information including collaborative relationships between trajectories through hypergraph learning. These studies highlight the significant potential of hypergraph-based learning methods and offer a novel solution approach to the trajectory user linking problem."}, {"title": "METHODOLOGY", "content": "To address the limitations of existing research, we propose HGTUL, a HyperGraph-based multi-perspective Trajectory-User Linking model, as shown in Figure 2. The framework consists of three main components: (1) trajectory hypergraph learning, (2) spatio-temporal trajectory learning, and (3) a classification layer. First, we construct a trajectory hypergraph to model the higher-order inter-trajectory relationships. Using a hypergraph attention network, we learn trajectory representations from the relational perspective. Second, we utilize sequence modeling to learn trajectory representations from a spatio-temporal perspective. Finally, we fuse the relational and spatio-temporal trajectory representations to classify trajectories by their users."}, {"title": "Preliminary", "content": "We first introduce some preliminary concepts and define the TUL problem.\nDefinition1 Spatio-Temporal Point. A spatio-temporal point p = (lon, lat, t) represents a visit to a POI at coordinates (lon, lat) at time t. The set of all POIs is denoted as P = {(lon\u2081, lat\u2081), (lon\u2082, lat\u2082), ..., (lon\u2097, lat\u2097)}, where L is the number of POIS.\nDefinition2 Linked Trajectory. A linked trajectory is a sequence of spatio-temporal points generated by a user u\u1d62 during a certain time interval, denoted as T\u1d64\u1d62 = {p\u1d62\u2081, p\u1d62\u2082, ..., p\u1d62\u2099}. The set of all linked trajectories is represented as T\u1d64 = {T\u1d64\u2081, T\u1d64\u2082, ..., T\u1d64\u2092 }, where Q is the total number of users.\nDefinition3 Unlinked Trajectory. Let T\u2096 = {p\u2096\u2081, p\u2096\u2082..., p\u2096\u2099} denote a trajectory with an unknown generating user, called an unlinked trajectory. The set of all unlinked trajectories is represented as T = {T\u2096\u2081, T\u2096\u2082, ..., T\u2096w }, where w is the number of unlinked trajectories.\nDefinition4 Hypergraph. A hypergraph can be represented by G = (V, &), where V is the set of vertices with size |V| and & is the set of hyperedges with size |8|. A hyperedge e \u2208 & can connect any number of vertices v \u2208 V. The incidence matrix H \u2208 R|V|\u00d7|E|\nis used to represent the topological structure of the hypergraph. It is defined such that H\u1d62,\u2c7c = 1 if v\u1d62 \u2208 e\u2c7c, H\u1d62,\u2c7c = 0 otherwise.\nTUL Problem Formulation. Given the set of unlinked trajectories T generated by users U = {u\u2081, u\u2082, ..., u\u209a} and a corresponding set of linked trajectories T\u1d64. The goal of TUL is to learn a mapping function f: T\u2192 U that links unlinked trajectories with their respective users."}, {"title": "Trajectory Hypergraph Learning", "content": "To capture the high-order association relationships among trajectories, we construct a trajectory hypergraph G = (V,E). As shown in Figure 2, the vertices of trajectory hypergraph represent POIs, with each trajectory modeled as a hyperedge, i.e., V = P and E = TUT. Additionally, to describe the interactions between trajectories and POIs, we construct an incidence matrix H \u2208 R\u1d38\u00d7\u1d3a, where L is the number of POIs and N is the number of all trajectories (including both linked and unlinked trajectories). The hyperedge property intuitively characterizes the complex relationships between POIs. By representing multiple trajectories as hyperedges that share vertices, the hypergraph can effectively model the complex high-order associations among these trajectories.\nLeveraging the trajectory hypergraph, the co-occurrence relationships among POIs facilitate the propagation of information across trajectories. For instance, POIs overlapping with multiple trajectories can reveal latent patterns in visitation behaviors. The trajectory hypergraph not only captures the POI information but also reveals individual behavior patterns through high-order trajectory associations, thus offering a relational perspective for TUL."}, {"title": "Trajectory Hypergraph Attention Network", "content": "After constructing the trajectory hypergraph, we introduce the trajectory hypergraph attention network to learn POI representations and the relational trajectory representation based on them. Before encoding, the POI embeddings P \u2208 R\u1d38\u00d7\u1d48 are initialized via a look-up table, where d denotes the embedding dimension.\nPOIs visited within the same trajectory exhibit stronger transitional dependencies compared to randomly paired POIs. We employ hypergraph convolution to model these dependencies. Based on the hypergraph convolution operator in [1], the layer-wise propagation process in the trajectory hypergraph convolution network can be expressed as:\nX\u207d\u1d50\u207a\u00b9\u207e = \u03c3(D\u207b\u00b9/\u00b2HB\u207b\u00b9H\u1d40D\u207b\u00b9/\u00b2X\u207d\u1d50\u207eW\u207d\u1d50\u207e)\nwhere W\u207d\u1d50\u207e is the layer-specific learnable weight matrix, with m denoting the layer index in the trajectory hypergraph convolution network. H is the hypergraph incidence matrix. D is the vertices degree matrix that be calculated as D\u1d62\u1d62 = \u2211\u1d62\u208c\u2081\u1d34 H\u1d62\u2c7c. B is the hyperedge degree matrix that be calculated as B\u2c7c\u2c7c = \u2211\u1d62\u208c\u2081\u1d38 H\u1d62\u2c7c. The term D\u207b\u00b9/\u00b2HB\u207b\u00b9H\u1d40D\u207b\u00b9/\u00b2 performs symmetric normalization to balance information aggregation and stabilize computation. X\u207d\u1d50\u207e \u2208 R\u1d38\u00d7\u1d48 is the output of m-th layer, where d is the embedding dimension, and X\u207d\u2070\u207e = P. o is a non-linear activation function.\nHowever, the relationship between trajectories and POIs is variable rather than fixed. From the perspective of trajectories contributing to POI representation, not all trajectories contribute equally to a POI representation. For example, if a user visits a POI only occasionally (e.g., User A visiting the park POI in Figure 1a), her trajectories have a weaker influence on the POI's representation compared to trajectories of users who visit the POI frequently (e.g., User B visiting the park POI in Figure 1a). Conversely, from the perspective of POI contributing to trajectories representation, POIs that a user visits frequently (e.g., the restaurant POI of User A in Figure 1a) play a more significant role in distinguishing the user and characterizing their trajectories. Thus, it is crucial to capture this variable relationship in TUL.\nTo effectively model the variable relationship, we introduce an attention learning module into the trajectory-POI incidence matrix H. The module dynamically adjusts the incidence matrix by computing attention weights between trajectories and POIs. The trajectory embedding s\u2c7c \u2208 R\u1d48 is initialized as a learnable vector and updated during training to capture the complex relationships between POIs and trajectories. For a given POI p\u1d62 with its embedding x\u1d62, and its associated trajectory hyperedge T\u2c7c with its embedding s\u2c7c, the similarity[1] between POI p\u1d62 and trajectory T\u2c7c can be measured as\nsim(x\u1d62, s\u2c7c) = a[x\u1d62||s\u2c7c]\nHere || denotes concatenation and a is a learnable weight vector used to output a scalar similarity value.\nAnd the attention score between them can be calculated as\nHattn = exp (\u03c3 (sim(x\u1d62, s\u2c7c)))/\u2211\u2096\u2208\ud835\udca9\u1d62 exp (\u03c3 (sim(x\u1d62, s\u2096)))\nA non-linear activation function \u03c3 is applied to enhance the expressiveness of the similarity. \ud835\udca9\u1d62 is the neighborhood set of POI p\u1d62, which consists of the trajectory hyperedges containing p\u1d62. These scores populate the attentive incidence matrix Hattn, which has the same size L X N as the incidence matrix H. Each element in Hattn represents the attention score between p\u1d62 and T\u2c7c, capturing their variable relationships.\nThe trajectory embeddings {s\u2c7c}\u1d3a\u2c7c\u208c\u2081 are initialized as learnable vectors and organized into a matrix Sattn \u2208 R\u1d3a\u00d7\u1d48, where each row represents the embedding of a specific trajectory T\u2c7c. During training, s\u2c7c is dynamically updated based on the attention score Hatin, which quantify the importance of each POI p\u1d62 to trajectory T\u2c7c. This allows Sattn to capture the variable influence of POIs on the trajectories, making it an effective attentive representation of all trajectories.\nWith the attentive incidence matrix Hattn enriched by the attention module, one can also follow Equation 1 to learn the layer-wise attentive embeddings of POIs.\nX\u207d\u1d50\u207a\u00b9\u207e = \u03c3(D\u207b\u00b9/\u00b2Hattn\u207d\u1d50\u207eB\u207b\u00b9Hattn\u207d\u1d50\u207e\u1d40D\u207b\u00b9/\u00b2X\u207d\u1d50\u207eW\u207d\u1d50\u207e)\nwhere Hattn\u207d\u1d50\u207e is the m-th attentive incidence matrix.\nWe employ dropout and residual connections to address overfitting and over-smoothing. The final embeddings of POIs are obtained by averaging the embeddings from all layers.\nXfinal = 1/(M+1) \u2211\u2098\u208c\u2080\u1d39Dropout (AT(Xattn\u207d\u1d50\u207e) + Xattn\u207d\u1d50\u207e)\nwhere M denotes the total number of trajectory hypergraph attention network layers. And AT() propagates POI features through hypergraph attention, as defined in Equation 4. Xfinal \u2208 R\u1d38\u00d7\u1d48 is the final embeddings of POIs."}, {"title": "Spatio-temporal Trajectory Learning", "content": "In the aforementioned trajectory hypergraph learning module, we capture the relational trajectory representations based on hypergraph. However, the temporal and spatial information of visited POIs has not been fully leveraged. So we introduce a sequence modeling module to enhance trajectory representation from a spatio-temporal perspective."}, {"title": "Spatio-temporal Encoder", "content": "To capture the geographical information of POIs, we encode the raw POI coordinates by GeoHash [24]. GeoHash is a grid-based geographical encoding method that maps continuous latitude and longitude coordinates into a discrete string grid, effectively representing the geographic location of a POI. For a given POI with original coordinates (lon\u2096, lat\u2096), we encode it as g\u2096 = GeoHash(lon\u2096, lat\u2096), and the corresponding spatial embedding g\u2091\u2096 = Embedding(g\u2096) \u2208 R\u1d48."}, {"title": "Sequence Modeling with LSTM", "content": "Since trajectory hypergraph learning has captured the relational information, we focus on the sequential features in this perspective. To ensure model efficiency, we choose LSTM [14] for modeling the spatio-temporal characteristics of the trajectories, rather than more complex models like Transformer [19] or other recent time series modeling architectures [13]. Specifically, we use the hidden state at the final timestep of the LSTM to represent the trajectory:\nSst_i = LSTM(Sist_i)\nwhere Sst_i \u2208 R\u1d48 is the spatio-temporal trajectory representation of trajectory T\u1d62."}, {"title": "Classification Layer", "content": "To link trajectories to their respective users, we obtain the final trajectory representation by summing the relational representation learned from the trajectory hypergraph and the spatio-temporal representation extracted by the LSTM. Both representations are normalized using L2 normalization to ensure consistency in their scale. The final representation is then fed into a fully-connected layer for user linking. The process is summarized as follows:\nSfinal_i = NORM(Sst_i) + NORM(Srel_i)\nyi = WcSfinal_i + bc\nwhere NORM denotes L2 normalization, Wc \u2208 R\u1d4c\u00d7\u1d48 and bc \u2208 RO are the learnable parameters of classification layer. Q is the number of users, and yi \u2208 R is the estimated probability of users for trajectory Ti.\nWe train the parameters of model by minimizing the cross-entropy loss function as follows:\nL = -1/Nt \u2211\u1d62\u208c\u2081\u1d3a\u1d57 c\u1d62 log (Softmax (yi))\nwhere ci is the ground truth label of trajectory Ti, Nt is the number of training trajectories."}, {"title": "Data Balancing", "content": "TUL is inherently a multi-class classification problem. However, in real-world check-in data, the diversity of user behaviors leads to an imbalanced distribution of trajectory counts across users. To mitigate the impact of data imbalance on model performance, we propose a data balancing method applied to the training set before model training. First, we calculate the average number of trajectories per user in the training set as Nave = Nt/Q, where Nt is the number of training trajectories and Q is the number of users. Next, for users with Nu < Nave, Nu is the trajectories number of user u in training set, we randomly replicate their trajectories until the count reaches Nave. Additionally, we set a threshold \u03b8t. For users with Nu > (1 + 0t) \u00d7 Nave, we randomly remove trajectories to ensure Nu \u2264 (1+0t) \u00d7 Nave. By effectively balancing the trajectory distribution across users, this approach improves model performance, particularly for users with fewer trajectories."}, {"title": "EXPERIMENTS", "content": "In this section, we conduct experiments on three real-world datasets and report the results. The experiments aims to answer the following research questions: Q1 How does our proposed model perform compared to existing representative models? Q2 How does each module affect the overall performance of the model? Q3 How does our model perform in addressing the user cold-start problem? Q4 How does data balancing affect the TUL task?"}, {"title": "Experiment Settings", "content": "To evaluate the performance of our proposed model, we conduct experiments using three public real-world datasets derived from the raw check-in data of Gowalla[4], Foursquare[21] in New York City (NYC), and Jakarta (JKT). To ensure the quality of the trajectory sequences, we apply the same filtering rules as [11] to clean the raw data. We filter out users with fewer than 10 check-in records as well as locations visited less than 10 times.\nSimilar to previous studies [9] [16], to simulate the TUL, we sort the cleaned check-in data by time for each user and then segment the trajectories with a one-week time interval. To evaluate the robustness of our model, we randomly select 500 and 1000 users from each dataset for experimentation. The trajectory data for each user is divided into training, validation, and test sets in a 6:2:2 ratio.\nThe statistical information of the preprocessed trajectory data is summarized in Table 1, where Length represents the range of the number of spatio-temporal points in the trajectories of the dataset."}, {"title": "Evaluation Metrics", "content": "We evaluate the performance of the proposed model using four key metrics: ACC@k, Macro-P, Macro-R, and Macro-F1. These metrics are commonly used in multi-class classification problems, and TUL can be regarded as such a problem. ACC@k represents the rate of whether the true user is included in the Top-k predicted users. It can be calculated as:\nACC@k = |{Ti \u2208 T : u\u00a1 \u2208 Topk(yi)}|/|T|\nwhere ui is the ground truth user, and Topk (yi) is the predicted Top-k users set.\nMacro-F1 comprehensively reflects the model's performance across all classes by integrating both precision and recall, and it is widely used in multi-class classification problems.It is can be defined as:\nMacro-R = 1/Q \u2211\u1d62\u208c\u2081\u1d4c Ri\nMacro-P = 1/Q \u2211\u1d62\u208c\u2081\u1d4c Pi\nMacro-F1 = 1/Q \u2211\u1d62\u208c\u2081\u1d4c (2 x Pi x Ri)/(Pi + Ri)\nwhere Q is the number of users of unlinked trajectories."}, {"title": "Baselines", "content": "We compare HGTUL with following representative methods for TUL, including (1) Sequence-based methods TULER, DeepTUL and CACSR; (2) Graph-based methods S2TUL and AttnTUL:\n\u2022 TULER [9] It is the original RNN-based approach to learn sequential transition patterns from trajectory data for TUL. There are three variants: RNN with Gated Recurrent Unit [5] (TULER-G), Long Short-Term Memory [14] (TULER-L), and bidirectional LSTM [18] (Bi-TULER).\n\u2022 DeepTUL [16] It is a recurrent network with attention mechanism. It learns from historical trajectory to capture the multi-periodicity of user mobility and mitigate data sparsity for TUL.\n\u2022 CACSR [11] It is a representation model for user check-in sequences, built upon bidirectional LSTM, which captures the spatio-temporal features and high-level semantics of check-in sequences through contrastive learning and adversarial perturbations.\n\u2022 S2TUL [6] It is the first attempt to incorporate trajectory-level information for TUL. It models the relationships between trajectories by multiple graphs with GCN and combines intra-trajectory and inter-trajectory information for TUL.There are two variants: it instantiates with repeatability graphs(S2TUL-R), heterogeneous graphs formed by merging the repeatability and spatial graphs (S2TUL-HRS).\n\u2022 AttnTUL [3] It proposes a hierarchical spatio-temporal attention neural network, which models the local and global spatio-temporal characteristics through a GNN architecture and simultaneously encode the intra-trajectory and inter-trajectory dependencies for TUL."}, {"title": "Overall Performance", "content": "We conduct a comprehensive performance comparison between our proposed model and baseline models across three datasets, with the results summarized in Table 2. The best results are highlighted in bold, while the second-best results are underlined. The experimental results demonstrate that our model significantly outperforms all baseline models across all evaluation metrics. Specifically, compared to the second-best baseline models, our model achieves improvements in ACC@1 ranging from 2.57% to 20.09%, and in Macro-F1, the improvements range from 5.68% to 26.00%.\nFurther analysis of the three variants of the TULER model\u2014 TULER-L, TULER-G, and Bi-TULER provides additional insights. The results reveal that the LSTM-based variants, TULER-L and Bi-TULER, consistently outperform the GRU-based TULER-G across all datasets. This observation underscores the stronger capacity of LSTM models in capturing complex trajectory patterns, which is beneficial to addressing the challenges inherent in the TUL.\nAmong the baseline models, DeepTUL and S2TUL-R stand out, achieving the second-best results. DeepTUL is an attentive recurrent neural network. Although traditional RNN architectures struggle to capture global information between trajectories, DeepTUL introduces a historical attentive module to capture the multi-periodic patterns of user movement from labeled historical trajectories. It partially leverages relational features between trajectories for learning. By using the spatio-temporal features of POIs in historical trajectories as input, DeepTUL highlights the essential role of spatio-temporal information and trajectory movement patterns in the TUL task. S2TUL-R, on the other hand, models the repeatability relationships between trajectories by constructing a repeatability graph and employs a GCN for learning. This approach directly captures global relational between trajectories, achieving excellent performance. These results further underscore the importance of global relational information in addressing the challenges of the TUL problem.\nDespite its strong performance in ACC@k, DeepTUL lags behind S2TUL-R in Macro-F1, likely due to the imbalanced distribution of user data in the TUL task. This imbalance prevents DeepTUL from effectively learning the features of minority-class users, thereby impacting the Macro-F1 score. The effect of data balancing on DeepTUL performance will be further discussion in subsection 4.5.\nMoreover, comparing our model to other baselines, we observe an average improvement of 15.34% in Macro-F1 and 8.99% in ACC@1. The significant improvement in Macro-F1 indicates that our model effectively balance the prediction performance across different users, especially in handling rare users, details will be discussed in subsection 4.4. This highlights the robustness and generalization ability of our model in handling imbalanced data within the TUL task. Finally, we can observe that the performance of all models decreases as the number of users increases. This is because an increase in the number of users complicates the classification task, thereby reducing linking accuracy. However, our model maintains optimal performance even with an increasing number of users, often exhibiting the smallest decline in linking accuracy, further demonstrating the stability of HGTUL performance with respect to the number of users."}, {"title": "Ablation Study", "content": "To evaluate the effectiveness of each module in HGTUL, we conduct an ablation study, with the results presented in Table 3. First, to assess the role of multi-perspective trajectory representations, we remove the attentive trajectory representation HGTUL-A, the structural trajectory representation HGTUL-S, and the spatio-temporal trajectory representation HGTUL-L. The results indicate that removing any of these representations causes a performance decline, with the structural trajectory representation having the greatest impact. The contributions of the spatio-temporal and attentive representations vary across datasets. Specifically, spatio-temporal features are important for the TUL in the GOWALLA (1000users) and JKT (500users) datasets, while meaningful POI features play a more important role in the NYC (1000users) dataset, reflecting the differences in dataset characteristics.\nTo further validate the effectiveness of our attentive trajectory representation learning method, we conduct an additional ablation study HGTUL-Ap, where the attentive trajectory representation is obtained by aggregating vertex features based on attention scores. The results show that our approach, which directly learns trajectory embeddings through dynamic updates, outperforms HGTUL-Ap. However, the performance of HGTUL-Ap still shows improvement compared to HGTUL-A, demonstrating the significance of attentive trajectory representations in the model.\nNext, to explore the contribution of hypergraph modeling, we remove the trajectory hypergraph module HGTUL-H. The results demonstrate a significant performance decline, highlighting the necessity of modeling complex high-order inter-trajectory association relationships for the TUL task. Finally, to examine the effect of data balancing, we remove the data balancing module HGTUL-D. The results show performance degradation across all datasets,"}, {"title": "User Cold-Start Analysis", "content": "To further assess our model's ability to alleviate the user cold-start problem, we consider the sparsity issue inherent in check-in data, where the cold-start problem is particularly pronounced in TUL tasks based on such data. It is especially challenging to accurately identify the user associated with the trajectory for new users who lack historical trajectory information. We categorize users into three groups: active, normal, and inactive, with classification based on the number of user trajectories. In the training set, the top 30% of users, the number of trajectories, are classified as active users, the bottom 30% as inactive users, and the remaining as normal users. We use the best-performing baseline model, S2TUL-R, for comparison. Figure 3 illustrates the comparison of cold-start performance, with Macro-F1 score as the evaluation metric. Experimental results show that the HGTUL outperforms S2TUL in most cases, with the most significant improvement observed for inactive users. This indicates that our model can effectively address the cold-start problem by capturing high-order inter-trajectory relationships. Furthermore, on the NYC and JKT datasets, as the number of users increases, the model's performance improvement becomes more pronounced, suggesting that with more trajectories, more inter-trajectory relationships can be learned in the hypergraph, thereby improving the linking accuracy."}, {"title": "Data Balancing Analysis", "content": "To investigate the impact of data balancing on the performance of the TUL model, we apply the proposed data balancing method to HGTUL and three baseline models. Since Macro-F1 provides a comprehensive measure of multi-class classification performance, we adopt it as the evaluation metric. First, as shown in Figure 4, data balancing enhances the TUL classification performance across all models and datasets, highlighting its essential role in TUL model training-an aspect often overlooked in previous studies. Second, among the baseline models, AttnTUL achieves the most significant improvement through data balancing. By analyzing its architecture, we find that AttnTUL employs a GNN to learn POI representations. Under imbalanced data distributions, the model tends to associate high-frequency user check-in behaviors with specific POIs, leading to incorrect trajectory-user linking for minority users. This makes AttnTUL more sensitive to data imbalance. Finally, after applying data balancing, HGTUL still outperforms other baseline models, demonstrating that our model achieves superior classification performance by effectively integrating high-order association relationships and spatio-temporal information."}, {"title": "CONCLUSION", "content": "In this work, we propose a novel hypergraph-based multi-perspective trajectory user linking model to address the limitations of existing methods in capturing high-order relationships among trajectories and the variable influence of POIs. By constructing a trajectory hypergraph and leveraging a hypergraph attention network, our model effectively learns the high-order inter-trajectory associations and variable impact of POIs on trajectories from relational perspective. And we incorporate the temporal and spatial information of trajectories as sequence features into an LSTM network from spatio-temporal perspective. Additionally, the proposed data balancing method significantly improves the model's performance on inactive users and demonstrates the necessity of addressing class imbalance in TUL tasks. Extensive experiments on three real-world datasets show that HGTUL outperforms state-of-the-art baselines, achieving remarkable improvements in ACC@1 and Macro-F1 metrics.\nOur work presents a method for TUL and suggests the potential of modeling high-order relationships in trajectory data analysis. Future work may investigate extending the proposed framework to other spatio-temporal data mining tasks."}]}