{"title": "Contrasformer: A Brain Network Contrastive Transformer for Neurodegenerative Condition Identification", "authors": ["Jiaxing Xu", "Kai He", "Mengcheng Lan", "Qingtian Bian", "Wei Li", "Tieying Li", "Yiping Ke", "Miao Qiao"], "abstract": "Understanding neurological disorder is a fundamental problem in neuroscience, which often requires the analysis of brain networks derived from functional magnetic resonance imaging (fMRI) data. Despite the prevalence of Graph Neural Networks (GNNs) and Graph Transformers in various domains, applying them to brain networks faces challenges. Specifically, the datasets are severely impacted by the noises caused by distribution shifts across sub-populations and the neglect of node identities, both obstruct the identification of disease-specific patterns. To tackle these challenges, we propose Contrasformer, a novel contrastive brain network Transformer. It generates a prior-knowledge-enhanced contrast graph to address the distribution shifts across sub-populations by a two-stream attention mechanism. A cross attention with identity embedding highlights the identity of nodes, and three auxiliary losses ensure group consistency. Evaluated on 4 functional brain network datasets over 4 different diseases, Contrasformer outperforms the state-of-the-art methods for brain networks by achieving up to 10.8% improvement in accuracy, which demonstrates its efficacy in neurological disorder identification. Case studies illustrate its interpretability, especially in the context of neuroscience. This paper provides a solution for analyzing brain networks, offering valuable insights into neurological disorders.", "sections": [{"title": "1 INTRODUCTION", "content": "In the field of neuroscience, a central objective is to uncover distinctive patterns associated with neurological disorders (e.g., Alzheimer's, Parkinson's, and Autism) by exploring the brain networks of both healthy individuals and patients with neurological disorders [37]. Among the various techniques for neuroimaging, resting-state functional magnetic resonance imaging (fMRI) is widely used to profile the connectivities among brain regions [46], leading to brain networks where each node is a specific brain region, called a region of interest (ROI), and each edge denotes a pairwise correlation between the blood-oxygen-level-dependent (BOLD) signals of two ROIs [50]. The edge reveals the connectivity between brain regions, showcasing which areas tend to be activated together or exhibit correlated activities. Brain networks model neurological systems as graphs and one could apply graph-based techniques to gain insights into their roles and interactions [23, 29, 45]. Such brain networks could help to decipher distinctive patterns associated with neurological disorders, which can contribute to early diagnosis and effective intervention strategies. It's worth noting that the development of graph analytics for brain networks is still in its early stages.\nWhile graph neural networks (GNNs) [18, 26, 43] and graph Transformers [38, 42, 54] have recently been adopted in a wide range of graph-related tasks, applying them to brain networks faces two challenges below in capturing the disease-specific pattern."}, {"title": "Sub-population-specific (SPS) Noise.", "content": "Analyzing neurological disorders aims to capture disease-specific patterns that are invariant across all populations. However, certain features are common to a sub-population (not generalizable to the entire population) and are unrelated to the disease, constituting sub-population-specific (SPS) noise. For instance, brain network datasets like Autism Brain Imaging Data Exchange (ABIDE) [9] and Alzheimer's Disease Neuroimaging Initiative (ADNI) [10] are collected from multiple sites. Subjects from different sites may exhibit site differences (scanner variability, different inclusion/exclusion criteria) [6]. Such noise could lead the model to focus on the site-specific pattern instead of learning population-invariant information. Besides, the varying scanning duration could result in different periods of region activation recorded for subjects. Furthermore, label inconsistencies may arise due to differences in diagnostic criteria used by doctors labeling these subjects. Fig. 1(a) provides an example of the site distribution of subjects in the ABIDE dataset. Each point in the figure represents a subject, and different colors denote the sites from which these subjects are acquired. From this example, it can be observed that subjects from the same site tend to have similar features, as the site-specific noise dominates the similarity. A similar observation is found in the distribution of sub-populations with different scanning durations. As illustrated in Fig. 1(b), each point represents a subject, and different colors denote the lengths of the BOLD signal for these subjects. Such a conspicuous distribution shift across sub-populations could easily mislead the model to overfit the SPS noise, thereby limiting its performance."}, {"title": "Node-identity awareness.", "content": "The construction of brain networks requires a specific parcellation method to split the whole brain into several ROIs. The same parcellation method is applied to all subjects, and thus the ROI definition is identical across all brain networks. Such a property does not generally exist in other graph-structured data, necessitating our specialized tailoring for brain networks. Existing general-purposed GNNs are designed to learn the structural pattern of graphs without considering their node identities [43, 51, 52].\nWhile some recent GNNs have introduced specialized designs for brain networks and addressed issues related to node identity [34, 35, 56], many of them overlook addressing SPS noise and capturing group-specific patterns. Neglecting these aspects can lead to models that overfit outliers and hinder interpretability [19].\nIn this paper, we propose Contrasformer, a novel contrastive brain network Transformer, that harnesses the distinctive properties of brain networks to fully leverage the capabilities of Transformer-based models for brain network analysis. Specifically, we employ a two-stream attention mechanism to generate a contrast graph that encodes group-specific information. Such two-stream attention mechanism can address the SPS noise by reweighting the original feature across ROIs and subjects. The distribution shift will also be corrected as shown in Fig. 1(c) and (d). Meanwhile, an identity embedding is introduced to incorporate the ROI identities with the input brain network, which highlights the node identity awareness. Moreover, we propose a cross decoder to integrate the contrast graph with the encoded brain network using a cross-attention mechanism. We further take advantage of node identity awareness by introducing a contrastive loss to constrain that identical ROIs across subjects have similar representations. Additionally, a cluster"}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Graph Neural Networks (GNNs)", "content": "GNNs have gained prominence as a popular approach in processing and analyzing graph structure data, including social networks [26], molecular data [17], knowledge graphs [33, 47] and user-item graphs [4]. Most GNNs operate on a message-passing scheme [18, 26, 43], wherein they iteratively aggregate information from neighboring nodes and update the representation of each node [52]. In recent years, there has been a surge of interest in employing GNNs for the analysis of brain networks. Ktena et al. [28] utilized graph convolutional networks to learn similarities between pairs of brain networks (subjects). BrainNetCNN [23] introduced edge-to-edge, edge-to-node, and node-to-graph convolutional filters to harness the topological information within brain networks. LiNet [32] presented a two-stage pipeline that uses GNNs to identify brain biomarkers associated with Autism Spectrum Disorder (ASD) from fMRI data. BrainGNN [34] proposed an ROI-selection pooling method to emphasize salient brain regions for each individual. However, these approaches often overlook the unique characteristics of functional brain networks, such as node-identity awareness [29].\nTo better utilize node-identity awareness of brain networks, PRGNN [35] introduced a graph pooling method with group-level regularization, in the mean time ensuring group-level consistency. GroupINN [53] jointly learnt node grouping and graph feature extraction, though without considering node alignment. Lanciano et al. [29] focused on extracting a dense contrast subgraph to filter relevant information for predictions. Nevertheless, their feature extraction and subject classification treated all brain regions and individuals uniformly, potentially making them susceptible to noisy data. Zhang et al. [56] incorporated both local ROI-GNN and global subject-GNN guided by non-imaging data, but the local ROI-GNN did not account for the node alignment in brain networks. ContrastPool [48], introduced a dual attention mechanism to extract discriminative features across ROIs for subjects within the same group. However, it still neglects the graph-level relationship between different groups, which could suffer from the SPS noise.\nIn addition, a general issue for GNNs based on the message-passing scheme is called over-smoothing [24], which refers to the loss of discriminative information as the network iteratively aggregates information from a large number of neighbors. In our context of brain networks, correlation-based graphs naturally possess high density that could easily suffer from over-smoothing. Therefore we discard message-passing architecture in our work."}, {"title": "2.2 Graph Transformer", "content": "An alternative method for graph representation learning involves Transformer-based models [42], which adapt the attention mechanism to consider global information for each node and incorporate positional encoding to capture graph topological information. Graph Transformers have garnered significant attention due to their impressive performance in graph representation learning. Dwivedi et al. [12] introduced edge information into the attention mechanism and used eigenvectors as positional embeddings. SAN [27] implemented an invariant aggregation of Laplacian's eigenvectors for positional embedding and introduced conditional attention for real"}, {"title": "3 PRELIMINARIES", "content": ""}, {"title": "3.1 Brain Network Construction", "content": "In this work, we use the datasets preprocessed and released by Xu et al [50]. We apply Schaefer atlas [40] to parcellate all subjects, which divides the brain into 100 functional ROIs. For each subject, a brain network is represented by a connectivity matrix $M \\in \\mathbb{R}^{m \\times m}$, where $m$ denotes the number of ROIs. The nodes in $M$ are ROIs and the edges are the Pearson's correlation between the region-averaged BOLD signals from pairs of ROIs. Essentially, $M$ captures functional relationships between ROIs. For the detailed preprocessing and brain network construction pipeline, please refer to Xu et al [50]."}, {"title": "3.2 Problem Definition", "content": "Neurological disorder identification for brain networks aims to predict the distinct class of each subject. Given a dataset of labeled brain networks $D = (M, Y) = \\{(M, y_m)\\}$, where $y_m$ is the class label of a brain network $M \\in M$, the problem of neurological disorder identification is to learn a predictive function $f: M \\rightarrow Y$, which maps input brain networks to the groups they belong to, expecting that $f$ also works well on unseen brain networks. We use ABIDE dataset, which contains groups of typical controls (TC) and individuals diagnosed with ASD, as an example to explain our methodology in the following. Notation-wise, we use calligraphic letters to denote sets (e.g., M), bold capital letters to denote matrices (e.g., M), and strings with bold lowercase letters to represent vectors (e.g., $\\mathbf{h}_g$). Subscripts and superscripts are used to distinguish between different variables or parameters, and lowercase letters denote scalars. We use $M(i,:)$ and $M(:,j)$ to denote the $i$-th row and $j$-th column of a matrix $M$, respectively. This notation also extends to a 3d matrix."}, {"title": "4 METHODOLOGY", "content": "In this section, we provide a detailed exposition of the design of our proposed Contrasformer, depicted in Fig. 2. Contrasformer adopts an encoder-decoder architecture, featuring three key components: (1) A contrast graph encoder is introduced (in Section 4.1) to extract the most discriminative task-related features from the training set. To alleviate the SPS noise, a two-stream attention mechanism is employed to generate a contrast graph that captures the invariant information across all sub-population. The learnt contrast graph is then utilized in both training and test stages to be incorporated with the brain network representation learning. (2) A cross decoder is introduced (in Section 4.2) to combine the input brain network with node identity, and subsequently fuse the contrast graph with the identity-embedded brain network by a cross-attention to update node representations. (3) A classification loss $L_{cls}$ and three auxiliary losses $L_{entropy}$, $L_{cluster}$, $L_{contrast}$ are incorporated (in Section 4.3) to guide the end-to-end training. These losses emphasize the node identity of ROIs and consider group-level relationships."}, {"title": "4.1 Contrast Graph Encoder with Two-stream Attention", "content": "To generate a contrast graph with group-specific information, we introduce a two-stream contrast graph encoder. In neuroscience, normally there are only some ROIs in the brain that can reflect the lesion of a neurological disorder. So the aim of this encoder is to extract the most discriminative ROIs for each group while adaptly learning the contribution of each subject. Such a two-stream attention design is able to capture the population-invariant information embedded in subjects and ROIs, which alleviates the impact of SPS noise in the downstream task."}, {"title": "4.2 Cross Decoder with Identity Embedding", "content": "By leveraging the group-discriminative information captured in the contrast graph, the cross decoder of Contrasformer aims to produce a high-quality representation for each input brain network (Fig. 5). In graph transformer models, positional embedding is commonly used to encode the topological information of the graph. However, existing designs for general graph representation learning, such as distance-based, centrality-based and eigenvector-based positional embedding [30, 44, 54], can hardly migrate to brain network due to its high density (always fully connected). The correlation-based brain networks naturally contain sufficient positional information for ROIs. Therefore the general-purposed positional embedding is not only expensive but also redundant in our case.\nInstead of positional embedding that captures the topological information of the graph structure, we propose a learnable identity embedding to adaptively learn the unique identity for each ROI. Such embedding attaches the same identity for nodes that belong to the same ROI. As shown in Eq. (9), we introduce a parameter matrix $W^{(ID)} \\in \\mathbb{R}^{m \\times m}$ to encode the identity of nodes. $\\delta(.)$ denotes a multilayer perceptron (MLP).\n$H^{(l)}_{ID} = H^{(l-1)} + \\delta(H^{(l-1)}_{contrast} + H^{(l-1)})$.\nAfter identity embedding, we combine the contrast graph with the encoded brain network by a cross-attention function followed by a layer normalization. The encoded brain network $H^{(l)}_{ID}$ serves as $Q$ while the contrast graph $H^{(l-1)}_{contrast}$ is treated as $K$ and $V$ in Eq. (1). Each input brain network is fed into the cross-attention module to query the task-specific information in the contrast graph. The intuition here is to use the contrast graph as prior knowledge to guide the brain network representation learning. By hiding the non-indicative ROIs/connections and emphasizing the indicative ones, task-specific domain knowledge is introduced to the embedded brain networks."}, {"title": "4.3 Loss Functions", "content": "In order to introduce domain knowledge and make model optimization easier to converge, we utilize 4 loss functions to guide the end-to-end training. (1) A commonly-used cross-entropy loss $L_{cls}$ [8] for graph classification; (2) an entropy loss $L_{entropy}$ for contrast graph sparsification; (3) a cluster loss $L_{cluster}$ to take the group relationship (i.e., similarity and discrepancy) into account; (4) a contrastive loss $L_{contrast}$ to constrain node-identity awareness. The total loss is computed by:\n$L_{total} = L_{cls} + \\lambda_1 * L_{entropy} + \\lambda_2 * L_{cluster} + \\lambda_3 * L_{contrast}$,\nwhere $\\lambda_1, \\lambda_2$ and $\\lambda_3$ are trainable trade-off hyperparameters.\nEntropy Loss. To prevent a smooth contrast graph that treats all ROIs equally, risking the loss of discriminative ability, we introduce a sparsity constraint. To achieve this, we employ an entropy loss, compelling the model to prioritize the most task-specific ROI connections. The entropy loss is formulated as follows:\n$L_{entropy} = \\frac{1}{m} \\sum^m_{i=1} entropy(H_{contrast} (i,:))$,\n$entropy (p) = - \\sum^m_{j=1} p_j \\log(p_j)$.\nCluster Loss. Most existing GNN/Transformer architectures treat individual input graphs independently during training. Neglecting the relationships between classes could lead to a significant compromise in model effectiveness for downstream classification tasks [49]. For our application, we want to find the common patterns/biomarkers for a certain neurological disorder identification task. Thus we propose a cluster loss to leverage graph-level similarity and make the graph representations more sepratable:\n$L_{cluster} = - \\log \\frac{\\exp(c_{ec} \\sigma_c)}{\\sum_{c' \\in C} \\exp(c_{ec'} \\sigma_{c'})}$,\n$\\mu_c = \\frac{\\sum_{k \\in S_c} h_g^k}{|S^c|}$, $ \\sigma_c = \\frac{\\sum_{k \\in S_c} (h_g^k - \\mu_c)^2}{|S^c|}$,\nwhere $\\mu_c$ and $\\sigma_c$ denote the mean and standard deviation of graph representations belonging to group $c$, $S^c$ denotes the subject indices that belong to group $c$, $C$ denotes the set of classes, and $h_g^k$ denotes the graph representation with index $k$ in $S^c$. As in Fig. 6(a), the cluster loss aims to pull the graph representations within a group close to each other and push the centers of groups as far as possible. By using such cluster loss, the group-level relationship of all classes is considered equally no matter how many subjects it contains.\nContrastive Loss. Existing graph contrastive learning technologies [55, 57] require data argumentation by modifying graph structure or dropping node/edge features. Such contrast is still limited to each individual graph. It also cannot be migrated to our brain networks"}, {"title": "5 EXPERIMENTAL STUDY", "content": ""}, {"title": "5.1 Brain Network Datasets", "content": "We use four brain network datasets from different data sources for various disorders, which are M\u0101tai for mild traumatic brain injury (mTBI) [50], PPMI [3] for Parkinson's disease (PD), ADNI"}, {"title": "5.2 Baseline Models", "content": "We employ diverse baseline models to benchmark our approach, including (1) Conventional machine learning models: Logistic Regression (LR) and Support Vector Machine Classifier (SVM) from scikit-learn [36]. These models take the flattened connectivity matrix as vector input, instead of using the brain network. (2) General-purposed GNNs: GCN [26], a mean pooling baseline with a graph convolution network as a message-passing layer; GraphSAGE [18] is a mean pooling baseline, which adopts sampling to obtain a fixed number of neighbors for each node; GAT [43], a mean pooling"}, {"title": "5.3 Implementation Details", "content": "In Contrasformer, we adopt a Linear layer for input embedding, a mean pooling layer as the readout function Readout(\u00b7), and a two-layer MLP with ReLU as the prediction head. The temperature hyper-parameter $t$ in Eq. (15) is set to 0.02. The settings of our experiments mainly follow those in [13]. We split each dataset into 8:1:1 for training, validation and test, respectively. We evaluate each model with the same random seed under 10-fold cross-validation and report the average accuracy. The whole network is trained in an end-to-end manner using the Adam optimizer [25]. We use the early stopping criterion, i.e., we stop the training once there is no further improvement on the validation loss during 25 epochs. All experiments were conducted on a Linux server with an Intel(R) Core(TM) i9-10940X CPU (3.30GHz), a GeForce GTX 3090 GPU, and a 125GB RAM."}, {"title": "5.4 Main Results", "content": "We report the accuracy on 4 brain network datasets in Table 2. Our proposed Contrasformer consistently outperforms all 13 baselines on all datasets. In particular, Contrasformer improves over all networks specifically designed for brain networks on these four datasets by up to 10.8% ((68.33%-61.67%)/61.67% = 10.8% on M\u0101tai). These experimental results demonstrate the effectiveness of our brain network oriented model design. The improvement may result from two reasons. First, the participation of the contrast graph in brain network representation learning provides reasonable and discriminative information about certain conditions. Second, the properties of fMRI and group constraints are introduced to the model training by dedicated loss functions.\nApart from accuracy, we also report other evaluation metrics, including precision, recall, micro-F1, and ROC-AUC, of all the models on the ABIDE dataset. As shown in Table 3, Contrasformer performs the best over all these metrics except for precision. We can also discover that compared with other baselines, our Contrasformer can dramatically improve recall without sacrificing precision. Besides, in medical diagnostics, it's crucial to ensure that all individuals with a certain condition are correctly identified, even if it means"}, {"title": "5.5 Model Interpretation", "content": "Contrast Graph Visualization. Despite the high accuracy achieved by our model, a critical concern is the interpretability of their decision-making process. In the context of brain biomarker detection, identifying salient ROIs associated with predictions as candidate/potential biomarkers is crucial. In this study, we leverage built-in model interpretability to explore disease-specific biomarker analysis. To interpret Contrasformer's reasoning, we visualize the learnt contrast graphs for Alzheimer's Disease and Autism on the ADNI and ABIDE datasets, by using the Nilearn toolbox [1]. We select edges with the top 10 attention weights. As depicted in Fig. 7(a), highlighted connections between the lateral prefrontal cortex, prefrontal cortex, and dorsal prefrontal cortex medial prefrontal cortex in the ADNI dataset suggest potential AD-specific neural mechanisms [31]. These regions have been recognized as key areas in previous AD studies [16, 39]. Similar ROI-wise interpretations are found in Autism. In Fig. 7(b), highlighted ROIs related to precuneus posterior cingulate cortex, cingulate, and dorsal prefrontal cortex medial prefrontal cortex on ABIDE align with domain knowledge from prior Autism research [2, 15, 22].\nGeneralization Ability. While task-specific biomarkers are valuable for identifying disease-relevant features, it is crucial to determine whether these biomarkers are invariant over the entire population, i.e., whether they generalize well across sub-populations and other diverse populations. To assess the generalization ability of Contrasformer, we conduct evaluations on subjects from previously unseen sites. Specifically, we designate two sites from the ABIDE dataset as the test set, while the remaining subjects are split into training and validation sets, maintaining an 8:1:1 ratio. The test set remains constant across 10 experiments with different train-validation splits, and the average results are reported in Table 4. Notably, Contrasformer consistently outperforms all baseline models, demonstrating its robustness against SPS noise. The baseline models exhibit a significant performance reduction compared to Table 2, indicating the detrimental impact of SPS noise on their generalization ability. In contrast, Contrasformer, with its two-stream attention mechanism, effectively extracts and emphasizes task-related features, mitigating the adverse effects of SPS noise."}, {"title": "5.6 Ablation Study", "content": "In this subsection, we empirically validate the design of (1) the important modules; and (2) the loss functions. All experiments in this subsection are conducted on ABIDE dataset.\nImportant Modules. To inspect the effect of the important modules, we conduct experiments by disabling each of them without modifying other settings. The results are reported in Table 5. For ROI-wise attention $Attn_{ROI}$, subject-wise attention $Attn_{subject}$, and identity encoding (denoted as \"ID enc\" in the table), we disable them by simply removing these modules. When disabling \"batch norm\", we replace the batch normalization functions in the two-stream attention by layer normalizations. The results demonstrate that Contrasformer with all important modules enabled achieves the best performance. Besides, the experiment of disabling $Attn_{subject}$ indicates that the outstanding recall of Contrasformer is mainly contributed by the subject-wise attention, demonstrating the effectiveness of extracting discriminative ROIs across subjects.\nLoss Functions. To verify the effectiveness of our proposed losses, we test our design of the loss functions by disabling them one by one. As shown in Table 5, the results demonstrate that all of those three auxiliary losses are effective in boosting the model performance. Besides, we find that the most important one is the contrastive loss. This observation indicates the necessity of introducing the constraint of node awareness."}, {"title": "6 CONCLUSION AND FUTURE WORKS", "content": "To overcome the hurdles of SPS noise and node-identity awareness, we introduce Contrasformer, a contrastive brain network Transformer. Through a contrast graph encoder with two-stream attention and a cross decoder with identity embedding, Contrasformer adaptly handles SPS noise, enhances node identity awareness, and captures group-specific patterns. Our model outperforms state-of-the-art methods in identifying neurological disorders across diverse datasets. The improvement over all the best models specifically designed for brain networks is up to 10.8%. Beyond superior performance, Contrasformer provides interpretable insights aligned with neuroscience literature. This work marks a significant advancement in harnessing Transformer models for fMRI-based brain network analysis, opening avenues for deeper understanding and diagnosis of neurological conditions. In the future, we plan to extend our model to various modalities of medical imaging, such as Diffusion Tensor Imaging (DTI), and explore the multi-modal solution for neurological disorder identification."}]}