{"title": "A Depression Detection Method Based on Multi-Modal Feature Fusion Using Cross-Attention", "authors": ["Shengjie Li", "Yinhao Xiao"], "abstract": "Depression, a prevalent and serious mental health issue, affects approximately 3.8% of the global population. Despite the existence of effective treatments, over 75% of individuals in low- and middle-income countries remain untreated, partly due to the challenge in accurately diagnosing depression in its early stages. This paper introduces a novel method for detecting depression based on multi-modal feature fusion utilizing cross-attention. By employing MacBERT as a pre-training model to extract lexical features from text and incorporating an additional Transformer module to refine task-specific contextual understanding, the model's adaptability to the targeted task is enhanced. Diverging from previous practices of simply concatenating multimodal features, this approach leverages cross-attention for feature integration, significantly improving the accuracy in depression detection and enabling a more comprehensive and precise analysis of user emotions and behaviors. Furthermore, a Multi-Modal Feature Fusion Network based on Cross-Attention (MFFNC) is constructed, demonstrating exceptional performance in the task of depression identification. The experimental results indicate that our method achieves an accuracy of 0.9495 on the test dataset, marking a substantial improvement over existing approaches. Moreover, it outlines a promising methodology for other social media platforms and tasks involving multi-modal processing. Timely identification and intervention for individuals with depression are crucial for saving lives, highlighting the immense potential of technology in facilitating early intervention for mental health issues.", "sections": [{"title": "I. INTRODUCTION", "content": "Depression(major depressive disorder) is a common and serious mental disorder that negatively affects how you feel, think, act, and perceive the world [1].According to estimates from the World Health Organization (WHO), around 3.8% of the global population is affected by depression, including 5% of adults-comprising 4% of men and 6% of women-and 5.7% of adults aged 60 years and older. Approximately 280 million people worldwide suffer from depression, with women having a roughly 50% higher chance of developing the disorder compared to men. More than 10% of pregnant women and those who have recently given birth globally also experience depression. Each year, over 700,000 individuals die by suicide, making it the fourth leading cause of death among individuals aged 15 to 29. Despite the availability of effective treatments for mental illnesses, over 75% of individuals in low- and middle-income countries do not receive any form of treatment [2]. The challenge in making accurate diagnoses during the early stages of depression contributes to a substantial number of patients being unable to access timely diagnosis and care. With the widespread adoption of the internet and social media, these platforms have gradually evolved into a new window for studying mental health, particularly in identifying early signs of depression [3]. The digital footprints users leave online, such as posted content, comments, liking behavior, frequency and nature of online interactions, serve as vital data sources for analyzing their psychological states. Research has uncovered correlations between specific behavioral patterns and linguistic habits on social media and depression, including frequent posting of negative content, increased nighttime activity, and reduced social engagement, all of which may be indicative of depressive symptoms [4].For example, a study could analyze users' word choices in their texts, looking for frequent occurrences of negative emotion vocabulary like \"loneliness,\" \"fatigue,\" or \"despair\" as indicators of a depressive tendency [3]. Moreover, the application of algorithms and machine learning technologies enables the processing and analysis of large-scale data, identifying more complex and subtle patterns that can facilitate earlier recognition of individuals likely experiencing depression by mental health professionals.In China, Sina Weibo, with its massive young user base, naturally emerges as a priceless resource for this kind of research. By scrutinizing the online behaviors of these users, researchers can not only track trends in mental health but also develop tools to facilitate early interventions.\nBuilding upon prior work, in this paper, we aim to accomplish depression detection through user modeling with improved performance over previous efforts. To this end, we construct a new deep neural network classification model, the Multi-Modal Feature Fusion Model Using Cross-Attention. This model employs MacBERT [5] as the pre-training model to extract word features from text and incorporates an additional Transformer module to further refine context understanding specific to the task at hand, thereby enhancing adaptability to the targeted task. Departing from past practices, our approach utilizes Cross-Attention [6] for multimodal feature integration instead of simply concatenating multiple features. Experimental proofs that our method effectively boosts the accuracy in detecting depression.\nOur Contributions. The major contributions are listed as follows:"}, {"title": "II. BACKGROUND", "content": "In this section, we introduce the dataset utilized in this paper as well as the relevant technologies employed.\nA. Weibo-User-Depression-Detection-Dataset(WU3D)\nThe dataset employed in our research is Weibo User Depression Detection Dataset (hereafter referred to as WU3D), compiled by Wang et al. [7]. Specifically, within the Weibo platform, each user possesses a unique ID, and the WU3D dataset accesses the homepage of each user through web crawling techniques to gather information. With a focus on ensuring authority and high reliability, the dataset underwent dual scrutiny by psychologists and psychiatrists for labeling accuracy. The information collected for each user is illustrated in Fig. 1.\nB. Attention\nAttention is a mechanism, which has found widespread ap- plication in Natural Language Processing (NLP) and computer vision tasks. At its core, the idea is to enable models to selectively focus on the most crucial parts of the input informa- tion during processing, rather than treating all input elements equally or averaging their importance. This mechanism mimics the way humans concentrate their attention on salient details when processing complex information, thereby enhancing the efficiency and performance of models.\nTransformer: Transformer is a groundbreaking sequence transduction model, first proposed by Vaswani et al. in their seminal paper 'Attention Is All You Need' in 2017 [8]. It has utterly transformed the field of Natural Language Processing (NLP), reshaping the landscape dominated by Recurrent Neural Networks (RNNs) and their variants, such as Long Short- Term Memory (LSTM) and Gated Recurrent Units (GRUs). These models traditionally struggled with computational ineffi- ciency when handling long sequences. Vaswani and colleagues addressed this by abandon the loop structure altogether, rely- ing exclusively on self-attention mechanisms. This innovation demonstrated superior performance compared to the best RNN models of the time in machine translation tasks, while also significantly accelerating training speeds.\nCross Attention: Cross Attention is a specialized form of attention mechanism that primarily deals with dependencies between two different sequences [9]. Unlike self-attention, which focuses on interdependencies among elements within the same sequence, cross attention operates through a 'query- answer' paradigm, enabling one sequence to adjust its repre- sentation based on the content of another sequence. In this paper, to uncover the relationships between word features and statistical characteristics, the cross attention mechanism has been employed.\nC. Pre-trained Model\nLarge-scale pre-trained models (PTMs), benefiting from in- tricate pre-training objectives and substantial parameter counts, excel at extracting knowledge from vast amounts of both labeled and unlabeled data. They encapsulate this abundant knowledge within their extensive parameters, which, when fine-tuned for particular tasks, can greatly enhance a wide"}, {"title": "III. MULTIMODAL FEATURE FUSION NETWORK BASED ON CROSS-ATTENTION", "content": "This section describes the architecture of multimodal feature fusion network based on cross-attention(MFFNC), which com- prises four fundamental components: word vector extracting, statistical feature extracting, feature fusion and multilayer per- ceptron(MLP), as shown in Fig. 2. The workflow commences by concatenating the user's nickname, profile, and tweets into a single, extended text sequence. This concatenated sequence is then fed into the pre-training model of MacBERT [5], yielding embedded word vectors which serve as input 1. Concurrently, the text features, social behavioral features, and picture features are encoded separately to generate input 2. Subsequently, both input 1 and input 2 are channeled into a cross-attention module to perform cross-attention mechanisms, thereby yielding a fused feature representation. This fused fea- ture is then propagated through a feedforward neural network for the detection of tendencies indicative of depression.\nA. Word Vector Extraction\nThis module specializes in processing user text informa- tion originating from social media platforms, encompassing multiple dimensions of users, including nicknames, personal profiles, and posted tweets, among others. The process begins by integrating these various categories of information, concatenating them to form a continuous long-text sequence. This design is intended to capture and preserve the full picture of users' online behavior, as each component may harbor clues about their personality traits, emotional states, or social habits. The constructed long-text sequence is then fed into a pre- trained MacBERT model. As an enhanced version of the BERT model, MacBERT introduces error-correcting masked language modeling tasks during pre-training, optimizing the model and reducing inconsistencies between pre-training and downstream tasks. This process enables not only the learning of lexical meanings but also the understanding of contextual nuances, extracting profound semantic information embedded within the text. Through MacBERT's processing, the raw text information is transformed into high-dimensional word embedding vectors. These vectors carry rich semantic and con- textual information, furnishing high-quality input data, referred to as input 1, for subsequent natural language processing tasks. This input 1, derived from deep learning model transfor- mation, embodies a comprehensive understanding and parsing of user textual expressions. It not only facilitates the identifi- fication of key terms but also delves into the text to uncover emotional tendencies, underlying themes, and intricate patterns of interpersonal interactions. In applications such as depression detection, this nuanced text analysis capability is particularly crucial, enabling the recognition of subtle linguistic cues associated with depressive sentiments and providing robust data support for mental health assessments.\nB. Statistical Feature Extraction\nThis module is responsible for extracting statistical informa- tion about users. Based on the research of previous work [7] [11] [12] [13] [14] [15] [16], we have adopted six statistical features: the proportion of negative emotional tweets, the proportion of original tweets, the ratio of posts made during late-night hours, the frequency of posts per week, the standard deviation of posting times, and the proportion of posts that include images. The detailed descriptions of these statistical features are provided in Table I. Detailed calculations for each of these statistical features along with their comprehensive de- scriptions will be elaborated upon in Section IV-B. Following the manual extraction of these statistical features, they are fed into a fully connected network for encoding, serving as input 2, tailored to conform to the dimensional specifications required by the subsequent cross-attention mechanism module.\nC. Cross Attention\nCross-attention [17] is a mechanism predominantly used in Transformer models, calculating attention across two distinct sequences to manage semantic relationships between them. It finds applications in tasks such as machine translation, image captioning, and video-text alignment. This mechanism expands upon self-attention, enabling the model to dynamically aggre- gate information at each position of one sequence (the query sequence) based on the content of another sequence (the key- value sequence).\nThe cross-attention mechanism is a specialized form of multi-head attention, where the input tensor is divided into two parts, $X_1 \\in \\mathbb{R}^{n\\times d_1}$ and $X_2 \\in \\mathbb{R}^{n\\times d_2}$.One part serves as the set of queries, while the other part acts as the key- value set.Its output is a tensor of size n x $d_2$, where for each query vector, there are attention weights assigned to all the key vectors. Fig. 3 illustrates the computation process of cross-attention, where through matrix operations and the softmax function, the model learns to selectively gather perti- nent information from the key-value sequences based on each element in the query sequence. This enhances the model's capability in handling cross-sequence dependencies, thereby boosting its performance. Such a mechanism is particularly crucial in dealing with multimodal tasks, as it enables the model to flexibly integrate features from disparate modalities. For instance, in the joint analysis of image and text, image features can serve as the key-value sequences, while the textual descriptions act as the query sequence. The cross-attention mechanism then facilitates precise alignment and information fusion between the two, thereby enhancing the interpretability and accuracy of the combined multimodal analysis.\nSpecifically, let $Q = X_1W^Q$ and $K = V = X_2W^K$, the computation of the cross-attention is as follows:\nCrossAttention(X1, X2) = Softmax($\\frac{Q K^T}{\\sqrt{d_2}}$) (1)\nWhere $W^Q \\in \\mathbb{R}^{d_1\\times d_k}$ and $W^K \\in \\mathbb{R}^{d_2\\times d_k}$ represent learned projection matrices, $d_k$ denotes the dimensionality of the key-value set (which is also the dimensionality of the query set).\nBelow, we will elaborate on the computation process of cross-attention, as depicted in Figure 10086. This figure illus- trates a mechanism known as \"Cross-attention,\" a commonly employed technique in many modern Natural Language Pro- cessing (NLP) tasks. Within this process, V, K, and Q represent three matrices that collectively determine the attention scores. Here is a concise explanation of each component:\n\u2022 V Matrix (Value): The Value matrix encapsulates infor- mation from the input sequence, which has been encoded for the purpose of computing attention scores. Typically generated by an embedding layer of the input sequence, this layer is responsible for transforming raw text into numerical representations.\n\u2022 K Matrix (Key): Similarly derived from the input se- quence, the Key matrix serves to ascertain which po- sitions are more significant during the calculation of attention scores. Elements in the K matrix are compared against those in the Q matrix to decide which positions ought to receive heightened attention.\n\u2022 Q Matrix (Query): The Query matrix, another derivation from the input sequence, is utilized to inquire about the most relevant positions within the K matrix. Through similarity matching between elements in the Q matrix and those in the K matrix, it facilitates the determination of attention scores.\n\u2022 Attention Scores: Attention scores are the outcome of the interaction between the V, K, and Q matrices. By assessing the similarity between the Q and K matrices, attention scores are computed. These scores are subse- quently employed to weight and combine values from the V matrix, yielding the final output.\nIn practical applications, the cross-attention mechanism typically involves the following steps, as exemplified by Formula 1:\n1) Linear Transformation: Initially, the V, K, and Q matri- ces undergo linear transformations, often through multi- plication with weight matrices, to ensure they all possess the same dimensionality. This preprocessing aligns them for the subsequent computations.\n2) Inner Product Operation: Subsequently, each element in the Q matrix is paired with every element in the K matrix through an inner product operation, yielding a scalar value. These scalars quantify the degree of similarity between each element in the Q matrix and its corresponding elements in the K matrix.\n3) Softmax Function: The outcomes from the inner prod- ucts are then fed into a softmax function. This operation scales the results such that each position's attention score falls within the interval [0, 1], with the sum of all scores equaling 1. Consequently, a probability distribution is obtained, reflecting the relative importance of each position.\n4) Weighted Summation: Finally, the values in the V matrix are aggregated via a weighted summation process, where the weights are determined by the attention scores. This means that positions with higher attention scores contribute more significantly to the resultant output.\nThe cross-attention mechanism is particularly valuable in neural network architectures like the Transformer, as it en- ables the model to focus on different segments of the input sequence. This is crucial for comprehending complex contex- tual dependencies and long-range relationships. Consequently, incorporating cross-attention as our multimodal feature fusion module proves highly efficient; it empowers the model to al- locate attention resources flexibly, thereby achieving enhanced performance.\nD. Multi-Layer Perceptron\nThe Multilayer Perceptron (MLP) [18], short for Multilayer Perceptron, is a type of feedforward artificial neural network model that serves as an extended version of the single-layer perceptron. By incorporating one or more hidden layers, MLP enhances the learning capacity and expressive power of the network. This structural enhancement enables MLPs to fit complex nonlinear functional relationships, thereby excelling in solving many practical problems, particularly in classifica- tion and regression tasks.\nIn this paper, MLP is employed as the final classification head module, comprising two essential components: linear transformation layers and activation functions. Specifically, the MLP consists of two layers of linear transformations, with a Rectified Linear Unit (ReLU) activation function inserted between them. Renowned for its simplicity and efficacy, the ReLU activation function effectively alleviates the vanishing gradient problem, facilitating the training of deeper networks, as defined by the following equation:\nMLP(x) = ReLU(W2(ReLU(W1x+b1))+b2) (2)\nwhere MLP() represents the multilayer perceptron (MLP), x represents the input feature vector, $W_1$ and $W_2$ are the weight matrices of the two linear transformation layers, and $b_1$ and $b_2$ respectively denote the bias terms for these two layers. The ReLU function is defined as f(x) = max(0,x), which maps all negative inputs to zero while preserving positive values unchanged. This approach maintains the nonlinearity of the network while circumventing the issue of gradient saturation in the negative value region.\nEquipped with this architecture, the MLP is capable of learning high-level abstract features from the input data and, through its final output layer, provides category predictions. In the context of depression detection methodologies, the MLP serves as the decision layer, integrating multimodal features fused via the cross-attention mechanism. Through nonlinear transformations, these features are mapped onto a classification probability space, thereby facilitating accurate judgment re- garding whether a user is experiencing depression. This design not only enhances the model's ability to recognize complex emotional and behavioral patterns but also ensures that the model exhibits good generalization performance, capable of making accurate predictions on unseen data.\nE. Psychological Analysis\nIn this section, we delve into the inner world and behavioral manifestations of individuals with depression from a psycho- logical perspective, to present readers with a vivid mental health landscape. Depression, a prevalent mental health issue worldwide [19], not only impacts an individual's emotional experiences but also significantly alters their cognitive func- tions, social behaviors, and even physical health [20]. Our aim, through meticulous data analysis, is to illuminate the distinctions between depression and other mental health states, thereby enhancing public comprehension of this complex psychological condition [21].\n1) Analysis of Characteristics in Individuals with Depression: The subjective experience of individuals with de- pression is often characterized by pervasive negative emo- tions, including sadness, hopelessness, self-deprecation, and loss of interest [22]. These emotions are not confined to specific situations but permeate throughout their daily lives, markedly diminishing their quality of life and sense"}, {"title": "IV. IMPLEMENTATION", "content": "In this section, we provide a detailed exposition on the implementation of the Multimodal Feature Fusion Network based on Cross-Attention (MFFNC), which was introduced in Section III. The overall architecture of the implementation is depicted in Fig. 2.\nA. Implementation of Word Vector Extraction\nIn our study, to conduct a comprehensive analysis of users' emotional states, we integrate various pieces of information left by users on social media platforms, including their user- names, profile descriptions, and posts or retweets, forming a long text sequence. Notably, these posts comprise not only original content created by users but also retweets that shed light on their interests and emotional expressions. Through such integration, the constructed long text sequence transcends the limitations of individual posts, establishing strong con- textual links across multiple tweets. Users may sequentially post tweets at different times to articulate their experiences battling depression or seek solace and express inner distress on social media. Consequently, aggregating this information is crucial for discerning whether a user is undergoing depression.\nWe also observe that posts by depressed users do not always overtly convey distress or relate directly to depression; they may depict routine aspects of daily life. This necessitates meticulous semantic extraction from the text during depression prediction, distinguishing between diverse expressions and identifying subtle signs of depression amidst everyday content. To address this, we employ the MacBERT model as an upstream tool for word embedding. MacBERT, an enhanced version of BERT, introduces a Masked Correction (Mac) pre-training task for the masked language model, resolving the inconsistency issue between pre-training and downstream tasks. By refining its profound understanding of linguistic con- texts, MacBERT enhances performance in downstream tasks. Building upon this, we further leverage manually extracted statistical features, combining them with the word features output by MacBERT through a cross-attention module. The cross-attention mechanism effectively matches points of focus between two distinct feature sequences, fostering complemen- tary information exchange and integration, thereby enhancing feature expressiveness.\nFinally, the fused features are fed into a Multilayer Percep- tron (MLP) classification model, acting as the decision-maker for the downstream task to yield the final depression detection outcome. Through this meticulously designed process, our system can more accurately identify indicators of depression from intricate social media data, providing robust technical support for early detection and intervention in mental health issues.\nB. Implementation of Statistical Feature Extraction\nPrevious studies have defined features that are effective for detecting depressed users, we manually extracted six features, as detailed in Table I.\n1) The Proportion of Original Tweets: The proportion of original tweets is a metric that measures the proportion of original content posted by users on a social media platform relative to retweeted content. This metric is particularly crucial in studies of user behavior, sentiment analysis, and especially in detecting mental health conditions such as depression, as it reflects users' tendencies for self-expression, their engagement in social interactions, and the authenticity of their emotions [13]. It calculates the percentage of original tweets posted by a user out of their total tweet count, which includes both original posts and retweets. Original tweets refer to those composed and shared directly by the user, rather than those forwarded from others. The computational formula is as follows:\nProportion of Original Tweets = $\\frac{N_{original}}{N_{total}}$ \u00d7 100% (3)\nWhere $N_{original}$ represents the number of original tweets posted by the user, $N_{total}$ denotes the total number of tweets by the user, including both original posts and retweets.\n2) The Proportion of Late-Night Posts: The proportion of late-Night posts serves as a quantifiable metric reflecting users' social media activity patterns, playing a crucial role especially in research related to mental health. This indicator assesses the percentage of posts made during a defined \"late-night\" period out of an individual's total posts, offering insights into their sleep patterns, social interaction preferences, and potential mental well-being [11]. Although the exact timeframe for \"late-night\" may vary depending on the research context or cultural differences, it is commonly demarcated as the stretch from midnight to 6:00 AM. This period is chosen as it aligns with the human body's natural sleep cycle, and abnormal levels of activity during these hours can signal mood disorders, stress, insomnia, or other psychological distress.\nThe application of this metric extends beyond academic research and is increasingly being integrated into mental health monitoring systems, where it serves as one of the early indicators for identifying risks of mental health issues such as depression and anxiety. For instance, if a user consistently posts during late-night hours, this may signal the presence of sleep disorders or difficulties in emotion regulation [26], warranting further attention or intervention. The computational formula is as follows:\nProportion of Late-Night Posts = $\\frac{N_{late-night}}{N_{total}}$ \u00d7 100% (4)\nWhere $N_{late-night}$ is the number of posts made during late- night hours (midnight to 6 AM), $N_{total}$ is the total number of posts made during the entire observation period.\n3) The Frequency of Posts Per Week: The frequency of posts per week is a metric that quantifies the average number of tweets a user posts within a week. This indicator sheds light on users' online behavioral patterns, levels of engagement, and potential trends in psychological well-being over time. In the realms of mental health and social behavior studies, both high and low frequencies of posting can be correlated with users' mental health status, highlighting its relevance for understanding psychological conditions through social media activity [7]. The computational formula is as follows:\nFrequency of Posts Per Week = $\\frac{T_{total}}{W_{period}}$ (5)\nWhere $T_{total}$ denotes the total number of posts made during the observation period, $W_{period}$ represents the number of weeks covered in the observation period (note that if the observation spans less than a week, adjust accordingly to the actual number of days covered and convert this into a fraction of a week, e.g., 3 days would be regarded as 0.43 weeks).\n4) The Standard Deviation of Posting Times: The Standard Deviation of Posting Times is a metric that assesses the dispersion of users' posting time distribution. It reveals the degree of variation in posting timestamps throughout a day, indicating how scattered or concentrated their posting habits are. A larger standard deviation suggests a more dispersed pattern of posting times, potentially lacking a fixed or regular routine; conversely, a smaller standard deviation implies that users tend to post at more concentrated intervals, indicating a certain level of posting regularity. This measure provides insights into users' lifestyle habits, patterns of social behav- ior, and even mental health states, as irregular posting time distributions can sometimes correlate with sleep disorders or mood fluctuations. The computational formula is as follows:\nSD = $\\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n}}$ (6)\nWhere X = {$X_1, X_2, ..., X_n$} represents the set of posting times by the user during the observation period, n denotes the total number of posts, $ \\bar{x}$ denotes the mean of the posting times.\n5) The Proportion of Negative Emotional Tweets: In assess- ing the emotional tendencies and mental health status of social media users, accurately measuring the proportion of negative sentiment tweets is a crucial step. This endeavor capitalizes on the methodology proposed in [7], ingeniously employing Baidu Intelligence Cloud's Sentiment Analysis API, a po- tent tool. Leveraging advanced natural language processing techniques and machine learning algorithms, this API delves into the emotional nuances of text, not only identifying basic positive or negative sentiments but also discerning varying degrees of negative emotion expressions, such as sadness, anger, or disappointment.\nImplementation entails inputting each collected social media post as an individual data entry into the sentiment analysis system. The system then conducts a comprehensive scan of these contents, analyzing word choice, contextual frameworks, and underlying emotional cues. By thoroughly dissecting the text, the system outputs a proportion representing the intensity of negative sentiment within the content. As a result, both overt expressions of dissatisfaction and subtly implied pessimistic narratives are effectively identified and quantified.\nThis process is not only highly automated, enhancing the efficiency of data processing, but also ensures consistency and objectivity in assessment. The derived proportion of negative sentiment becomes a pivotal indicator of users' overall emo- tional state, particularly crucial in identifying those potentially in the early stages of depression or facing other mental health challenges. Through such quantitative analysis, researchers and mental health professionals can intervene earlier, pro- viding necessary support and interventions to users, thereby promoting their mental health and wellbeing. Simultaneously, this analytical approach furnishes a reliable data foundation for large-scale mental health monitoring studies based on social media, propelling advancements in related scientific research.\n6) The Frequency of Image Posting: When engaging in social activities, users often enrich their content by combining text with images, a multimodal communication strategy that significantly enhances the expressive power and appeal of the information conveyed. Images, as visual and vivid carriers of information, swiftly capture viewers' attention, conveying emotions and details difficult to express solely through text. Hence, posting pictures on social media has become a pivotal dimension in measuring users' content creation habits and patterns of social behavior.\nThe frequency of picture posts, or the proportion of posts containing images published by a user within a certain time- frame relative to their total posts, is a key indicator in assessing the level of visual content integration on social media platforms. This metric reflects an individual's preferred mode of communication with others: whether they are more inclined to utilize visually enriched formats to narrate stories, share snippets of their life, or express emotions and opinions. For researchers, analyzing picture posting frequency not only uncovers users' online behavioral tendencies, such as their preference for showcasing rather than merely narrating, but also indirectly provides insights into their personality traits, social involvement, and even mental health status [27]. Users who frequently post images may prioritize visual experiences, seeking to connect with others in a more visual manner, which could relate to their outgoing nature and willingness to share. Conversely, those who post fewer images and rely more on text-based communication may have a stronger preference for deep thinking and textual expression, or they may be more conscious about privacy protection. Furthermore, studies on the social media behavior of groups prone to emotional lows, such as individuals with depression, indicate that they tend to be more active at night and share more negative content, yet variations in their image posting frequency can also reveal subtle differences in their emotional states; a reduction in image sharing might signify a decrease in social motivation. Therefore, through meticulous analysis of picture posting frequency, coupled with other social media behavioral statistical features, a multidimensional model of user behavior can be constructed. Such a model serves as a powerful tool for monitoring and preventing mental health issues in fields like public health and psychology research. The computational formula is as follows:\nFrequency of Image Posting = $\\frac{N_{image}}{N_{total}}$ (7)\nwhere $N_{image}$ represents the number of tweets containing images, $N_{total}$ denotes the total number of tweets."}, {"title": "V. EVALUATION", "content": "A. Experiment Setup\n1) Performance Metrics: True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN) form the foundation of the confusion matrix, which are metrics used to gauge the accuracy of model predictions. TP refers to instances where the model correctly predicted the positive class, TN where it correctly identified the negative class, FP represents cases where the model incorrectly labeled instances as positive, and FN denotes instances of the positive class that were incorrectly classified as negative. Based on these concepts, several common performance metrics can be defined to assess the model's performance:\nAccuracy = $\\frac{TP+TN}{TP+TN+FP + FN}$ (8)\nAccuracy: Accuracy represents the proportion of all pre- dictions that are correctly predicted.\nRecall = $\\frac{TP}{TP + FN}$ (9)\nRecall: Recall measures the model's ability to identify all true positive instances, that is, the proportion of actual positives that are correctly identified.\nPrecision = $\\frac{TP}{TP + FP}$ (10)\nPrecision: Precision denotes the proportion of samples predicted as positive by the model that are actually positive, focusing on the accuracy of positive predictions.\nF1 = 2 \u00d7 $\\frac{Precision \u00d7 Recall}{Precision + Recall}$ (11)\nF1-Score: F1 Score ranges from 1 to 0, with a value closer to 1 indicating better model performance, particularly in sce- narios where the distribution of positive and negative samples is imbalanced. The F1 Score serves as a more comprehensive evaluation metric under such conditions.\n2) Dataset: For the datasets setup, we first divide our dataset by categorizing users into two groups: 'Depressed' and 'Normal', from which we sample 10,000 user data points from each category. Subsequently, we apply an 8:2 split ratio to this data (ensuring all experiments utilize a consistent random seed for sampling), resulting in a division of D1:D2 as 16,000: 4,000. This partitioning strategy ensures a balanced and repro- ducible allocation of data across training and Validation sets respectively.\n3) Environment Configuration: The computational environ- ment for this study is anchored within Alibaba Cloud's robust infrastructure-the Platform for Artificial Intelligence (PAI), specifically deploying a high performance interactive modeling tool known as the Data Science Workshop (DSW) server. This server boasts an exceptional configuration, equipped with 8 virtual CPU cores (vCPU), ensuring efficient multitasking and parallel processing capabilities. Its memory allocation stands at 30 GiB RAM, providing ample space for the instant loading of large datasets and the training of intricate models. Of particular note, the inclusion of an NVIDIA A10 GPU with 24GB of video memory lays a solid hardware foundation for the rapid training of deep learning models and the processing of massive data sets, especially suitable for computationally intensive tasks such as image recognition and natural language processing.\nOn the software front, the study embraces a cutting-edge technology stack to guarantee the project's sophistication and compatibility. Specifically, it utilizes the pytorch-develop ver- sion 2.1, a development iteration of the PyTorch deep learning framework that introduces the latest functional updates and performance enhancements, facilitating rapid model iteration and innovation. Python version 3.11, the most recent stable release at the time, was employed, having undergone substan- tial improvements in syntax sugars, performance, and type hinting, thereby augmenting code readability and execution efficiency. CUDA version 11.8, developed by NVIDIA as a parallel computing platform, ensures seamless integration between the GPU and deep learning frameworks, maximizing the utilization of GPU computational capabilities. The oper- ating system selected was Ubuntu 22.04 LTS, renowned for its stability and a rich ecosystem of software, providing an advantageous environment for deep learning research.\nTo optimize model parameters, the Adam optimizer (Adap- tive Moment Estimation) was adopted, an adaptive learning rate method lauded for its excellent convergence speed and generalization abilities across various tasks. A learning rate of 1e-6 was set, a relatively conservative choice aimed at balancing model convergence speed with the mitigation of overfitting risks. Additionally, considering both efficiency and stability in model training, the batch size was determined to be 8, a common practice under limited hardware resources that strikes a balance between computational resource consumption and training effectiveness.\nRegarding the loss function, CrossEntropyLoss was em- ployed, a classic choice for multi-class classification prob- lems. It effectively measures the discrepancy between the model's predicted probability distribution and the true labels, particularly when the last layer of a neural network out- puts class probabilities, thereby enhancing the model's ability to learn more precise classification boundaries. Collectively, the computational environment and the implemented model strategies of this study embody a comprehensive consideration for efficiency, advancement, and practical feasibility, laying a sturdy groundwork for the smooth conduct of the research and the attainment of anticipated outcomes."}, {"title": "VI. RELATED WORKS", "content": "With the advancement of artificial intelligence technology, machine learning approaches have made significant contribu- tions to depression detection on social media. These efforts can be categorized into two main classes: traditional machine learning methods and deep learning-based natural language processing techniques.\nA. Traditional Machine Learning Approaches\nEarly studies, such as those by Choudhury and colleagues [12], employed an elaborate manual feature engineering pro- cess to extract features from Twitter users' behavioral patterns, providing inputs for subsequent depression detection models. This approach relies on researchers' prior knowledge of de- pressive manifestations to manually design features that reflect depressive tendencies. Li et al. [31] utilized sentiment analysis techniques, in conjunction with word embedding methods, to assess the depressive tendency of tweets. This underscores the importance of textual content, particularly emotional ex- pression, in identifying depressive states, further affirming the pivotal role of text-based features in online mental health analyses. Shen et al. [11], in their research, considered not only textual information but also integrated other data types (such as user behavior data), adopting multimodal methods to construct a more comprehensive user profile. This indicates that incorporating diverse information sources can effectively enhance the accuracy and robustness of depression detection.\nB. Natural Language Processing Detection Approaches based on Deep Learning\nRecent research has shifted towards employing deep learn- ing, notably neural network models, for processing social media data and identifying depressive users. The pioneering work by Mustafa and colleagues [32] marks a transition in the field of online social network (OSN) depression detec- tion, shifting from conventional machine learning to the deep learning paradigm. This transition showcases the capability of automatically learning complex and high-dimensional features, thereby enhancing both the efficiency and accuracy of detec- tion.Lin et al.'s work [33] illustrates how cross-disciplinary technological innovation, specifically the integration of state- of-the-art NLP pre-traind models with image processing tech- niques, can advance mental health monitoring. They employed BERT (Bidirectional Encoder Representations from Trans- formers) [34], a groundbreaking pre-trained model, which through deep bidirectional context understanding, generates high-quality word embeddings (i.e., high-dimensional vectors) that capture the nuanced contextual meanings of words in sentences, vastly outperforming previous bag-of-words models or simplistic word embedding approaches.Specifically, Wang et al. [7] constructed a dataset, the Weibo User Depression Detection Dataset (WU3D), and employed the popular pre- trained model XLNet to extract text-based word features. They then devised a Deep Neural Network classification model, the Multimodal Feature Fusion Network (MFFN), which in- tegrates features derived from diverse information sources, further accomplishing the classification task. Their approach demonstrated remarkable performance on the test dataset. The dataset utilized in this paper is the publicly available WU3D dataset provided by their team."}, {"title": "VII. CONCLUSIONS", "content": "This paper presents a depression detection method based on multi-modal feature fusion using cross-attention. By em- ploying MacBERT as the pre-training model and incorpo- rating the cross-attention mechanism, we have significantly enhanced the accuracy of depression detection. Experimen- tal outcomes demonstrate that our approach surpasses other models, achieving an accuracy of 0.9495 and an F1 score of 0.9469. In comparison to alternative methods, ours effectively integrates multi-modal features, thereby furnishing a more precise depression detection. In summary, our method repre- sents a significant advancement in depression detection from social media, offering a potent and accurate tool for mental health monitoring. Future work may explore the integration of additional modalities, such as visual and audio data, to further enhance detection capabilities.\nOf paramount importance is the core value of our research, which lies in the potential to integrate this model seamlessly into mainstream social media platforms like Weibo or WeChat. By doing so, we can facilitate accurate early diagnosis and warning signs of depression at its nascent stage. This real-time intervention mechanism provides a crucial window for initiat- ing psychological interventions promptly, effectively bridging a pathway of hope for those struggling with depression. Empowering mental health care through technology, we aspire to weave a safety net in the digital era, extending care and support to every corner where hearts in need reside."}]}