{"title": "The Master Key Filters Hypothesis:\nDeep Filters Are General in DS-CNNs", "authors": ["Zahra Babaiee", "Peyman M. Kiassari", "Daniela Rus", "Radu Grosu"], "abstract": "This paper challenges the prevailing view that convolutional\nneural network (CNN) filters become increasingly special-\nized in deeper layers. Motivated by recent observations of\nclusterable repeating patterns in depthwise separable CNNs\n(DS-CNNs) trained on ImageNet, we extend this investiga-\ntion across various domains and datasets. Our analysis of\nDS-CNNs reveals that deep filters maintain generality, con-\ntradicting the expected transition to class-specific filters. We\ndemonstrate the generalizability of these filters through trans-\nfer learning experiments, showing that frozen filters from mod-\nels trained on different datasets perform well and can be further\nimproved when sourced from larger datasets. Our findings in-\ndicate that spatial features learned by depthwise separable\nconvolutions remain generic across all layers, domains, and\narchitectures. This research provides new insights into the\nnature of generalization in neural networks, particularly in DS-\nCNNs, and has significant implications for transfer learning\nand model design.", "sections": [{"title": "Introduction", "content": "Understanding the mechanisms by which neural networks\ngeneralize across different tasks and datasets is a pivotal as-\npect of deep learning research (Zhang et al. 2021; Neyshabur\net al. 2017). Generalization, the ability of a model to perform\nwell on unseen data, is often studied by evaluating a model's\nperformance on new, unseen samples or its adaptability to\nnovel domains. While many approaches focus on test accura-\ncies and domain adaptation, in this work, we investigate the\nrole of inner structural aspects of neural networks in general-\nization, particularly examining the properties of depthwise\nseparable convolutional neural networks (DS-CNNs).\nThe first layer of traditional convolutional neural networks\n(CNNs) is well-documented to develop filters resembling\nGabor functions or color blobs (Krizhevsky, Sutskever, and\nHinton 2012), indicative of their role in capturing basic edge\nand color information from the visual stimuli. However, as the\nnetwork progresses into deeper layers, these patterns become\nmore complex and less understood, given the increase in the\nnumber of channels and the entangled nature of spatial and\nchannel representations in traditional CNNs.\nThe highly influential work of (Yosinski et al. 2014) char-\nacterized the first layer filters of CNNs as \"general,\" and\nextended its investigation to deeper layers, examining filter\ngenerality and specificity through innovative layerwise fea-\nture transfer experiments. They empirically demonstrated\nthat when frozen filters from a dissimilar task were trans-\nferred, model performance degradation became progressively\nmore severe as deeper layers were transferred. This led to\nthe widely accepted conclusion that filters in deeper layers\nbecome increasingly specialized.\nDepthwise separable convolutions are an efficient vari-\nant of the standard convolution operation, which decouples\nthe learning of spatial features and channel-wise relation-\nships (Howard et al. 2017, 2019). This separation not only\nreduces computational complexity but also provides a unique\nlens through which the internal representation of spatial infor-\nmation can be inspected, even in deep layers of the network.\nWhen probing the depthwise filters of trained models on\nImageNet, one observes repeating patterns. Figure 1 shows\ndepthwise filters randomly sampled from the first, middle,\nand last layer of the trained ConvNeXt (Liu et al. 2022) Base\nand HorNet (Rao et al. 2022) Small models. The filters have\ncommon characteristics between the two different architec-\ntures. Recent study has shown that depthwise convolutions\nacross different DS-CNN models trained on the ImageNet\ndataset are clusterable into distinct categories related to Gaus-\nsian functions and derivatives (Babaiee et al. 2024a,b).\nInspired by these observations, our paper seeks to explore\nthe possibility general filter sets being learned by depthwise\nseparable convolutions across different domains, architec-\ntures, and model sizes.\nWe hypothesize:\nThe Master Key Filters Hypothesis. There exist master\nkey filter sets that are general for visual data, and the depth-\nwise filters in DS-CNNs tend to converge to these master key\nfilters, regardless of the specific dataset, task, or architecture.\nTo validate this hypothesis, we conduct a comprehensive\nseries of experiments across ImageNet and various other\ndatasets and domains.\n1. Semantically Divided ImageNet: First, we repeat the well-\nknown experiment from (Yosinski et al. 2015), by divid-\ning ImageNet into \"man-made\" and \"natural\" classes that\nare semantically different from each other. We then trans-\nfer and freeze filters from the model trained on man-made"}, {"title": "Related Work", "content": "Generalization in Deep Learning. Generalization has\nbeen a central theme in machine learning research for\ndecades (Neyshabur et al. 2017). The study of generaliza-\ntion seeks to understand how training methodologies, net-\nwork architectures, and data diversity influence a model's\nability to extend beyond its training regime (Goodfellow,\nBengio, and Courville 2016). Various theories, such as uni-\nform convergence, margin theory, and algorithmic stability,\nhave been proposed to explain generalization in machine\nlearning. These frameworks often rely on different notions of\nmodel complexity, and corresponding generalization bounds\nquantify the relationship between the amount of data needed\nand the complexity measure. Despite significant theoreti-\ncal advancements, the practical value and applicability of\nthese theories remain a subject of ongoing debate in the re-\nsearch community (Zhang et al. 2021). Notably, Yosinski et\nal. (Yosinski et al. 2014) investigated the transferability of\nfeatures in deep neural networks by transferring frozen filters\nfrom a CNN trained on half of ImageNet to a network to be\ntrained on another half. They showed that transferring deeper\nthan the third layer filters degrades performance, suggesting\nrepresentation specificity in deep layers.\nDepthwise Separable Convolutions. Depthwise separa-\nble convolutions have gained popularity over traditional con-\nvolutions in recent years due to their computational efficiency\nand scalabilty (Howard et al. 2017, 2019; Tan and Le 2019;\nTan et al. 2019; Li et al. 2022; Trockman and Kolter 2022; Liu\net al. 2022). They reduce parameter count and computational\ncomplexity by decoupling the spatial and channel computa-\ntions. These layers have not only facilitated the development\nof lightweight, scalable models but have also been instru-\nmental in probing the spatial feature extraction capabilities\nof CNNs. A depthwise-separable convolution is an efficient\nalternative to standard convolutions in neural networks, split-\nting the operation into two simpler steps. First, a depthwise\nconvolution applies a separate filter to each input channel\nindependently, capturing spatial patterns within each chan-\nnel. Mathematically, for an input X with C channels, this\nperforms C separate convolutions: $Y = X_c * K_c$, where $K_c$\nis the kernel for channel c. Second, a pointwise convolution\n(1 \u00d7 1 convolution) combines information across channels by\napplying a 1 \u00d7 1 \u00d7 C kernel to each spatial location, creat-\ning new feature maps: $Z = \\Sigma_{c=1}^{C} Y_cW_c$, where $W_c$ are the\nweights for each channel. This decomposition significantly\nreduces the number of parameters and computational cost\ncompared to standard convolutions while maintaining similar\nexpressiveness, making it particularly useful in mobile and\nedge computing applications. Recent work demonstrates that\ndepthwise convolutional kernels, across various DS-CNN\nmodels trained on the ImageNet dataset, exhibit recurring\npatterns that can be categorized into distinct groups (Babaiee\net al. 2024a).\nTransfer Learning and Domain Adaptation. Transfer\nlearning focuses on leveraging knowledge from one or more\nsource tasks to improve learning in a related target task. These\napproaches are particularly valuable in scenarios where la-\nbeled data for the target task is scarce or expensive to obtain.\n(Xu et al. 2024) introduced a method for initializing smaller"}, {"title": "Revisiting Semantically Divided ImageNet", "content": "In this section, we replicate the experiment by (Yosinski et al.\n2014) on convolutional filter transferability across ImageNet\nsubsets (man-made vs. natural objects) on DS-CNNs. This\ndivision creates maximally dissimilar subsets within the Ima-\ngeNet dataset.\nAs demonstrated in Figure 2, we transferred the depth-\nwise filters from the first n layers of the model trained on\nthe man-made subset to a new ConvNeXt tiny model. These\ntransferred layers were then frozen, and the model was trained\non the natural subset. Figure 3c illustrates the performance\nresults, and Figure 3a shows the exact results re-plotted\nfrom (Yosinski et al. 2014). Contrary to (Yosinski et al. 2014),\non ConvNeXt, transferred filters perform comparably to those\ntrained directly on the natural subset, with no substantial per-\nformance trend as the number of transferred layers increases.\nTo evaluate the breadth of filter generality, we conducted\nexperiments comparing three distinct transfer scenarios\nagainst our baseline accuracy. These scenarios included: (1)\nstandard transfer of all filters (Figure 3c), (2) random shuf-\nfling of filters across layers, and (3) a restricted transfer where\nonly the first three layers' filters were used and then repeated\nthroughout the remaining layers. shows the results.\nSurprisingly, even extreme scenarios like retaining only the\nfirst 3 layers showed no significant accuracy drop. These\nresults strongly support the high generality of depthwise con-\nvolution filters across layers.\nThese findings raise an important question: Is the enhanced\ntransferability of deeper filters in DS-CNNs, compared to\nthe traditional CNN studied by Yosinski et al., due to the\nConvNeXt model's depthwise separable architecture, or do"}, {"title": "Cross Domain Transfer", "content": "This section examines the cross-domain transferability of\ndepthwise separable convolutional filters using a diverse set\nof datasets varying in size and domain. We aim to assess the\ngeneralizability of these filters across disparate datasets.\nDatasets. We evaluate the transferability of depthwise fil-\nters across six diverse datasets: Food 101 (Bossard, Guillau-\nmin, and Gool 2014)(food images), Sketch (Peng et al. 2019)\n(hand-drawn object sketches from DomainNet), CIFAR-\n10 (Krizhevsky 2009) (generic images of vehicles and ani-\nmals), Oxford Flowers (Nilsback and Zisserman 2008) (vari-\nous flower species), Oxford Pets (Parkhi et al. 2012) (cat and"}, {"title": "Generality of spatial features in DS-CNNS", "content": "Our primary inquiry centers on whether the spatial features\nlearned by DS-CNNs are universally applicable across vari-\nous datasets and domains. Drawing on the conceptual frame-\nwork presented in (Yosinski et al. 2014), the generality of\nlearned features can be defined by their utility when applied\nto tasks beyond their original training purpose. Specifically,\nexamining how effectively these features perform when trans-\nferred from their initial training task to a different target task.\nThe feasibility of such transfer relies significantly on the\nsimilarity between the source and target tasks.\nTo rigorously test our hypothesis, we engage in an exten-\nsive experimental process where we transfer and freeze the\ndepthwise filters from models trained on different datasets."}, {"title": "Asymmetric Transfer Effects and Dataset Size", "content": "The pat-\ntern revealed in  challenges conventional assumptions\nabout domain-specificity in filter transfer. The predominantly\nred arrows in the upper triangle and green arrows in the\nlower triangle, when datasets are sorted by size, indicate that\nfilters from models trained on larger datasets consistently\noutperform those from smaller ones. This improvement per-\nsists regardless of domain similarity between source and\ntarget datasets, suggesting that increased data variety leads\nto more universally applicable filters. Moreover, we never\nobserve mutual negative impact when transferring filters be-\ntween datasets a finding that contradicts what might be\nexpected if filters were highly domain-specific. This asym-\nmetric pattern suggests that depthwise filters develop general\ncapabilities that become more robust with increased training\nvariety rather than becoming narrowly specialized to specific\ndomains."}, {"title": "Is There a Transition from Generic to Class-specific Filters in Deeper Layers?", "content": "In the experiments in , we\ntransferred all the filters from all layers to the new models on\nnew domains. To investigate the layer trends, we perform a\nsimilar study to the previous section.\nWe continue to use ConvNeXt Femto as our base model.\nFor the source and target datasets, we use Food 101 and\nOxford Pets. Starting from a ConvNeXt Femto model with\nall layers trained on the Food 101 dataset, we iteratively\ntransfer layers, similar to the procedure shown in Figure 2."}, {"title": "What About Pointwise Convolutions, Are They Specialized?", "content": "The results thus far indicate that depthwise filters ex-\nhibit significant generality. This raises an intriguing question:\nIf DS-CNNs extract features hierarchically and transition to\nspecialized features, are the pointwise convolutions respon-\nsible for this specialization? To address this, we conducted\nanother cross-domain experiment, transferring only the point-\nwise layers while training the remaining model weights. Ta-\nble 5 presents the results of these experiments for each pair\nof datasets.\nSurprisingly, transferring pointwise filters consistently de-\ncreased accuracy compared to the original model, even in\nselffer experiments. While improved or maintained accuracy\nduring transfers can suggest filter generality, the accuracy de-\ncreases don't necessarily prove pointwise filter specialization.\nThis is particularly evident given that pointwise filters trans-\nferred from the same dataset also showed significant drops,\nin contrast to selfferred depthwise filters, which generally\nmaintained or improved performance.\nThe performance degradation observed in these experi-\nments may be attributed to optimization challenges related\nto splitting networks between co-adapted neurons. This phe-\nnomenon, termed \"fragile co-adaptation\" by (Yosinski et al.\n2014), suggests that freezing transferred layers may create\na loss landscape that hinders optimal filter learning. This\ndifficulty is underscored by the fact that selfferred pointwise\nfilters suffer similarly to those transferred from other domains.\nUpon examining the filters learned in these experiments, we\nobserved notably noisier patterns, further indicating potential\nconvergence issues."}, {"title": "Cross-Architecture Transfer", "content": "To further investigate the transferability of depthwise filters,\nwe extend our experiments to include different model sizes\nand architectures, while using the ImageNet dataset as the\nsource domain.\nExperimental Setup. For these experiments, we maintain\nour base model as ConvNeXt Femto and use the Oxford Pets\ndataset as the target domain. As source models, we use differ-\nent sizes from the ConvNeXt family (femto, tiny, and large)\nand introduce another architecture family, HorNet (Rao et al.\n2022). HorNet has substantially different blocks compared to\nConvNeXt, with recursive gated convolutions. By including"}, {"title": "Cross-Domain and Cross-Architecture Transfer", "content": "To further demonstrate the generality of the depthwise filters,\nwe extend our experiments by considering both different do-\nmain and different architectures simultaneously. While the\nImageNet dataset is large and may already contain features\nuseful for classifying pets, we aim to investigate the transfer-\nability of filters from a more distant domain. For this purpose,\nwe choose the Food 101 dataset as the source domain, which\nconsists of closeup photos of food on plates or table settings.\nIn contrast, the Oxford Pets dataset, which serves as the target\ndomain, contains images of cat and dog breeds in various set-\ntings, such as indoors or outdoors on grass. By selecting these\ntwo datasets, we can assess the effectiveness of filter transfer\nbetween domains that have minimal common features.\nExperimental Setup. We first train the HorNet Tiny model\non the Food 101 dataset. We then transfer the depthwise\nconvolutional filters from the trained HorNet Tiny model to\nthe ConvNeXt Femto model, which is subsequently trained\non the Oxford Pets dataset with frozen filters. In this scenario,\nboth the dataset domain and the model architecture of the\nsource and target models are different, providing a rigorous\ntest for the generality and transferability of the learned filters.\nResults. The results of this experiment are presented in\n. Remarkably, the ConvNeXt Femto model trained\non the Oxford Pets dataset with transferred filters from the\nHorNet Tiny model trained on the Food 101 dataset achieves\nan accuracy of 55.5%, with a 3.1% increase compared to the"}, {"title": "Conclusions and Discussion", "content": "This paper introduces the Master Key Filters Hypothesis,\nthat there exist master key filter sets that are general, and\nthe depthwise filters tend to converge to them. We provide\nevidence that DS-CNNs learn depthwise convolutional filters\nthat remain general across diverse datasets, domains, and\nmodel architectures.\nOur experiments, spanning semantically divided ImageNet,\ncross-domain, and cross-architecture transfers, reveal that\nthese filters maintain their generality even in deeper layers,\nchallenging prevailing notions from traditional CNNs, that\nthere is a transition from general to specialized filters, and\nfilters get increasingly specialized in deeper layers of the\nnetwork.\nWhen transferring the pointwise layers, we observed con-\nvergence issues across all datasets, even in selffer models,\nsuggesting optimizer difficulties when these layers are frozen.\nThis may be attributed to the higher parameter count in point-\nwise layers, potential sparsity effects, and restricted permuta-\ntion symmetries compared to depthwise layers. These find-\nings align with prior work on fragile co-adaptation in neural\nnetworks (Yosinski et al. 2014), where freezing certain layers\ncan create challenging loss landscapes for training the remain-\ning parameters. Future work could further investigate the\nspecific mechanisms behind these optimization challenges.\nThe generality of depthwise filters has significant impli-\ncations for transfer learning, enabling performance improve-\nments when transferring filters from larger to smaller datasets,\nregardless of domain differences. Our results also open new\navenues for cross-architecture knowledge transfer. But more\nimportant than all, these findings contribute to our understand-\ning of the fundamentals of convolutional neural networks."}]}