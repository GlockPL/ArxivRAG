{"title": "The AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy of Risks From Artificial Intelligence", "authors": ["Peter Slattery", "Alexander K. Saeri", "Emily A. C. Grundy", "Jess Graham", "Michael Noetel", "Risto Uuk", "James Dao", "Soroush Pour", "Stephen Casper", "Neil Thompson"], "abstract": "The risks posed by Artificial Intelligence (AI) are of considerable concern to academics, auditors, policymakers, AI companies, and the public. However, a lack of shared understanding of AI risks can impede our ability to comprehensively discuss, research, and react to them. This paper addresses this gap by creating an AI Risk Repository to serve as a common frame of reference. This comprises a living database of 777 risks extracted from 43 taxonomies, which can be filtered based on two overarching taxonomies and easily accessed, modified, and updated via our website and online spreadsheets. We construct our Repository with a systematic review of taxonomies and other structured classifications of AI risk followed by an expert consultation. We develop our taxonomies of AI risk using a best-fit framework synthesis. Our high-level Causal Taxonomy of AI Risks classifies each risk by its causal factors (1) Entity: Human, AI; (2) Intentionality: Intentional, Unintentional; and (3) Timing: Pre-deployment; Post-deployment. Our mid-level Domain Taxonomy of AI Risks classifies risks into seven AI risk domains: (1) Discrimination & toxicity, (2) Privacy & security, (3) Misinformation, (4) Malicious actors & misuse, (5) Human-computer interaction, (6) Socioeconomic & environmental, and (7) AI system safety, failures, & limitations. These are further divided into 23 subdomains. The AI Risk Repository is, to our knowledge, the first attempt to rigorously curate, analyze, and extract AI risk frameworks into a publicly accessible, comprehensive, extensible, and categorized risk database. This creates a foundation for a more coordinated, coherent, and complete approach to defining, auditing, and managing the risks posed by AI systems.", "sections": [{"title": "Guide for readers", "content": "This is a long document. Here are several ways to use this document and its associated materials, depending on your time and interests.\nTwo-minute engagement\nSkim the Plain Language Summary (p. 3).\nTen-minute engagement\nRead the Plain Language Summary (p. 3).\nRead Insights into the Al Risk Landscape (p. 56), and Implications for key audiences (p. 57).\nPolicymakers, Model Evaluators & Auditors\nRead the Plain Language Summary (p. 3). Skim Detailed descriptions of domains of Al risks (p. 33).\nRead Insights into the Al Risk Landscape (p. 56) and the Policymakers and/or Auditors subsections of Implications for key audiences (p. 57).\nResearchers\nRead the Plain Language Summary (p. 3). Read Figure 1 (p. 15) to understand the methods we used to identify relevant documents and develop two new taxonomies of Al risk; for more detail on how we developed the taxonomies see Best-fit framework synthesis approach (p. 19).\nRead Insights into the Al Risk Landscape (p. 56), and the Academics subsection of Implications for key audiences (p. 59) and skim Limitations and directions for future research (p. 60)."}, {"title": "Plain Language Summary", "content": "The risks posed by Artificial Intelligence (AI) are of considerable concern to a wide range of stakeholders including policymakers, experts, AI companies, and the public. These risks span various domains and can manifest in different ways: The Al Incident Database now includes over 3,000 real-world instances where Al systems have caused or nearly caused harm.\nTo create a clearer overview of this complex set of risks, many researchers have tried to identify and group them. In theory, these efforts should help to simplify complexity, identify patterns, highlight gaps, and facilitate effective communication and risk prevention. In practice, these efforts have often been uncoordinated and varied in their scope and focus, leading to numerous conflicting classification systems. Even when different classification systems use similar terms for risks (e.g., \"privacy\") or focus on similar domains (e.g., \"existential risks\u201d), they can refer to concepts inconsistently. As a result, it is still hard to understand the full scope of Al risk.\nIn this work, we build on previous efforts to classify Al risks by combining their diverse perspectives into a comprehensive, unified classification system. During this synthesis process, we realized that our results contained two types of classification systems:\n\nHigh-level categorizations of causes of Al risks (e.g., when or why risks from Al occur)\nMid-level hazards or harms from Al (e.g, Al is trained on limited data or used to make weapons)\n\nBecause these classification systems were so different, it was hard to unify them; high-level risk categories such as \u201cDiffusion of responsibility\u201d or \u201cHumans create dangerous Al by mistake\" do not map to narrower categories like \u201cMisuse\u201d or \u201cNoisy Training Data,\u201d or vice versa. We therefore decided to create two different classification systems that together would form our unified classification system.\nThe paper we produced and its associated products (i.e., causal taxonomy, domain taxonomy, living database and website) provide a clear, accessible resource for understanding and addressing a comprehensive range of risks associated with Al. We refer to these products as the Al Risk Repository."}, {"title": "What we did", "content": "As shown in Figure A, we used a systematic search strategy, forwards and backwards searching, and expert consultation to identify Al risk classifications, frameworks, and taxonomies. Specifically, we searched several academic databases for relevant research and then used pre-specified rules to define which research would be included in our summary. Next, we consulted experts (i.e., the authors of the included documents) to suggest additional research we should include. Finally, we reviewed i) the bibliographies of the research identified in the first and second stages, and ii) papers that referenced that research to find further relevant research.\nAt the conclusion of this process, we extracted information about 777 different risks from 43 documents, with quotes and page numbers, into a \"living\" database we intend to update over time (see Figure B). You can watch an explainer video for the database here.\nWe used a \"best fit framework synthesis\u201d approach to develop two taxonomies for classifying these risks. This involved choosing the \u201cbest fitting\u201d classification system for our purposes from the set of 43 existing systems we had identified during our search and using this system to categorize the Al risks in our database. Where risks could not be categorized using this system, we updated the existing categories, created new categories, or changed the structure of this system. We repeated this process until we achieved a final version that could effectively code risks in the database."}, {"title": "What we found", "content": "As shown in Table C, most of the risks (51%) were presented as caused by Al systems rather than humans (34%), and as emerging after the Al model has been trained and deployed (65%) rather than before (10%). A similar proportion of risks were presented as intentional (35%) and unintentional (37%)\nAs shown in Table D, the risk domains that were covered the most in previous documents were:\n\nAl system safety, failures & limitations - covered in 76% of documents.\nSocioeconomic & environmental harms - covered in 73% of documents.\nDiscrimination & toxicity - covered in 71% of documents.\n\nHuman-computer interaction (41%) and Misinformation (44%) were less frequently discussed.\nNo document discussed risks from all 23 subdomains; the highest coverage was 16 out of 23 subdomains (70%; Gabriel et al., 2024). On average, documents mentioned 7 out of 23 (34%) of the Al risk subdomains, with a range of 2 to 16 subdomains mentioned. See Table 9 in the body of the paper for a full breakdown of subdomain coverage by paper.\nSome risk subdomains were discussed much more frequently than others, such as:\n\nUnfair discrimination and misrepresentation (8% of risks).\nAl pursuing its own goals in conflict with human goals or values (8% of risks).\nLack of capability or robustness (9% of risks).\n\nSome risk subdomains are relatively underexplored, such as:\n\nAl welfare and rights (<1% of risks).\nPollution of the information ecosystem and loss of consensus reality (1% of risks).\nCompetitive dynamics (1% of risks)."}, {"title": "How to use the Al Risk Repository", "content": "Our Database is free to copy and use. The Causal and Domain Taxonomies can be used separately to filter this database to identify specific risks, for instance, those focused on risks occurring pre-deployment or post-deployment or related to a specific risk domain such as Misinformation.\nThe Causal and Domain Taxonomies can be used together to understand how each causal factor (i.e., entity, intent, and timing) relates to each risk domain or subdomain. For example, a user could filter for Discrimination & toxicity risks and use the causal filter to identify the intentional and unintentional variations of this risk from different sources. Similarly, they could differentiate between sources which examine Discrimination & toxicity risks where Al is trained on toxic content pre-deployment, and those which examine where Al inadvertently causes harm post-deployment by showing toxic content."}, {"title": "How to engage", "content": "We discuss some additional use cases below; see the full paper for more detail.\n\nGeneral:\n\nOnboarding new people to the field of Al risks.\nA foundation to build on for complex projects.\nInforming the development of narrower or more specific taxonomies. (e.g., systemic risks, or EU-related misinformation risks).\nUsing the taxonomy for prioritization (e.g., with expert ratings), synthesis (e.g, for a review) or comparison (e.g., exploring public concern across domains).\nIdentifying underrepresented areas (e.g., Al welfare and rights).\n\nSpecific:\n\nPolicymakers: Regulation and shared standard development.\nAuditors: Developing Al system audits and standards.\nAcademics: Identifying research gaps and develop education and training.\nIndustry: Internally evaluating and preparing for risks, and developing related strategy, education and training.\n\nAccess the Repository via our website: airisk.mit.edu\nUse this form to offer feedback, suggest missing resources or risks, or make contact."}, {"title": "Introduction", "content": "Risks from Artificial Intelligence (AI) are of considerable concern to academics, regulators, policymakers, and the public (Center for Al Safety, 2023; UK Department for Science, Innovation and Technology, 2023a, 2023b). The Responsible Al Collaborative's Al Incident Database now includes over 3,000 real-world instances where Al systems have caused or nearly caused harm (McGregor, 2020). Research and investment in the development and deployment of increasingly capable Al systems has accelerated (Maslej et al., 2024). Concurrent with this attention, researchers and practitioners have sought to understand, evaluate, and address the risks associated with these systems. This work has so far produced a diverse and disparate set of taxonomies, classifications, and other lists of Al risks.\nSeveral examples demonstrate how confusion about Al risks may already impede our effectiveness at risk mitigation. Because there is no canonical set of risks, organizations developing Al are more likely to present risk-mitigation plans that fail to address a comprehensive set of risks (cf. Anthropic, 2023; Google DeepMind, 2024) or lack detail (Anderson-Samways et al., 2024). Similarly, Al-risk evaluators and security professionals are less able to comprehensively evaluate and report on Al risks without a clear understanding of the full range of threats (cf. Nevo et al., 2024). Finally, policymakers may require more extensive support from outside sources (e.g., Department for Science & Technology, 2024) to understand what they need to regulate and legislate.\nAnother source of confusion is that risks that share a similar name, e.g., \u201cprivacy,\u201d can refer to different harms or categories of harm (e.g., Meek et al., 2016; Wirtz et al., 2020). Taxonomies that focus on similar domains of risk, e.g., \u201cexistential,\u201d can vary considerably in their content and how they are constructed (Critch & Russell, 2023; Hendrycks et al., 2023; McLean et al., 2023). Most papers do not base their taxonomies or classifications on a conceptual or theoretical foundation. For those papers that conduct reviews of existing work, most are narrative reviews, rather than the result of a systematic search (for exceptions, Hagendorff, 2024; McLean et al., 2023). In general, the state of taxonomies and classifications for Al risks are not consistent with best practice (Nickerson et al., 2013): they lack mutual exclusivity, collective exhaustivity, or parsimony; are static or based on arbitrary or ad hoc criteria; and tend to be descriptive rather than explanatory. The number of competing taxonomies inadvertently makes it very challenging to integrate relevant research into a cohesive shared understanding.\nThis lack of shared understanding impedes our ability to comprehensively discuss, research, and react to the risks of Al. The absence of shared understanding can cause confusion and impair research usage, cross-study comparison, and the development of cumulative knowledge (Harrison McKnight & Chervany, 2001; e.g., Marcolin et al., 2000). Shared understanding is also important in legal, political, and practical settings; reviews are frequently cited in academic and policy documents (Fang et al., 2020; Haustein et al., 2015), and shared understanding is often cited as a goal for legal and political processes (R\u00f6ttinger, 2006). For example, the U.S.-EU Trade and Technology Council (TTC) stated in its joint roadmap for Trustworthy Al and Risk Management, \"Shared terminologies and taxonomies are essential for operationalizing trustworthy Al and risk management in an interoperable fashion\" (European Commission and the United States Trade and Technology Council, 2022)."}, {"title": "Methods", "content": "Here, we systematically review existing Al risk classifications, frameworks, and taxonomies. We extract the categories and subcategories of risks from the included papers and reports into a \"living\" database that can be updated over time. We apply a \"best fit\" framework synthesis approach (Carroll et al., 2011, 2013) to develop two taxonomies: a high-level Causal Taxonomy of Al Risks to capture three broad causal conditions for any risk (e.g., which entities' action led to the risk, whether the risk was intentional, when it occurred), and a mid-level Domain Taxonomy which classifies the risks into seven risk domains (e.g., Discrimination and toxicity) and 23 subdomains (e.g., exposure to toxic content).\nOur key contribution is the creation of a common frame of reference: an Al Risk Repository comprising a comprehensive synthesis of existing Al risk frameworks into a living Al Risk Database of 777 risks, and the Causal Taxonomy and Domain Taxonomy of Al risks. The database and taxonomies can be used individually or in combination to explore the database, as well as for research, policy, and practice to address risks from Al. All of these artifacts are available online. The Al Risk Repository is, to our knowledge, the first attempt to rigorously curate, analyze, and extract Al risk frameworks into a publicly accessible, comprehensive, extensible, and categorized risk database. This creates a foundation for a more coordinated, coherent, and complete approach to defining, auditing, and managing the risks posed by Al systems."}, {"title": "Systematic literature search", "content": "We used a systematic search strategy, forwards and backwards searching, and expert consultation to identify Al risk classifications, frameworks, and taxonomies. We extracted the individual risks from these documents into a living Al Risk Database. We conducted two best-fit framework syntheses to create a Causal Taxonomy of Al Risks (see Table 2) and Domain Taxonomy of Al Risks (see Table 6), by adapting existing frameworks (Weidinger et al., 2022; Yampolskiy, 2016). We did this by testing their effectiveness at coding our risk data and modifying them until we created a final version that could effectively code all relevant risks."}, {"title": "Search strategy", "content": "Our search strategy comprised two stages. In Stage 1 we conducted a systematic search of peer-reviewed and gray literature (i.e., non peer-reviewed materials) to identify relevant articles. We begin by explaining our search-term generation and strategy, followed by our database searches in Scopus and various preprint databases. We then describe our screening process, which utilizes active learning with ASReview. This process includes four phases: initial random screening for training data, application of active learning with specific stopping rules, model switching for comprehensive coverage, and quality evaluation. Finally, we outline our full-text screening and calibration procedures. In Stage 2 we conducted forwards (citation) and backwards (references) searching and expert consultation to identify additional eligible articles. The two stages are described below."}, {"title": "Stage 1: Searching & screening peer reviewed and gray literature", "content": "Search terms were generated through an iterative process and chosen for their empirical balance between sensitivity and specificity (Wilczynski et al., 2003). This included terms related to artificial intelligence (Artificial intelligence, Al, Artificial general intelligence, AGI), frameworks, taxonomies, and other structured classifications (Framework, Review, Overview, Taxonomy*), and risks (Risk, Harm, Hazard). This led to the following search string:\nTITLE-ABS-KEY ( ( \"artificial intelligence\" OR ai OR \"artificial general intelligence\" OR agi ) AND ( framework OR taxonom* OR review ) AND ( risk OR harm OR hazard ) ) AND ( LIMIT-TO ( LANGUAGE, \"English\" ) ).\nWe conducted a search of Scopus to identify relevant academic research. The same search string was used on the following preprint databases to identify relevant literature: arXiv, Social Science Research Network (SSRN), Research Square, medRxiv, TechRxiv, bioRxiv, and ChemRxiv. Both searches were conducted on 4 April 2024. Relevant articles were downloaded for screening."}, {"title": "Title/abstract and full-text screening", "content": "Two authors formed a team to conduct title/abstract and full-text screening. Prior to screening, the team calibrated their decision-making by screening the same randomly selected articles separately (n = 23), comparing the results, and resolving disagreements. Agreement was achieved on 21 of 23 records (91%). To expedite title and abstract screening, we used a dual-screening approach with active learning in ASReview (van de Schoot et al., 2021).\nActive learning is an emerging research technique which uses machine learning to reduce the total number of records that require manual screening. It is now widely used for efficiently screening large datasets in systematic reviews and meta-analyses (Campos et al., 2024; Gates et al., 2019), and has been validated in a number of diverse fields (Campos et al., 2024; van de Schoot et al., 2021) and datasets (Ferdinands et al., 2023).\nThroughout the active-learning process, the four step SAFE procedure outlined by Boetje and van de Schoot (2024) was followed to ensure that screening identified relevant articles both rigorously and efficiently. The four phases are described below.\nPhase 1: Screen a random set of articles to create training data for active-learning model\nAs per SAFE, the screening team each randomly screened and labeled 1% of the total search yield (264 records in total). Each member of the team then created separate projects in ASReview and uploaded their own files, which included all retrieved studies and the random screening data. The random screening data was automatically marked as prior knowledge, and the active-learning phase commenced.\nStage 2: Apply active learning during screening until stopping rule is reached\nFor the first iteration of the active-learning model, the team followed Boetje and van de Schoot's (2024) recommendation to use the Oracle model and the default model setup (TF-IDF as the feature extractor, Naive Bayes as the classifier, maximum as the query strategy and dynamic resampling (double) as the balance strategy). We aimed to follow Boetje and van de Schoot's (2024) four-fold stopping heuristics, screening until four mutually independent conditions are met:\n\nAll key papers are marked as relevant.\nAt least twice the estimated number of relevant records in the total dataset are screened.\nMore than 10% of the total dataset has been screened.\nNo relevant records are identified in the last 50 records screened.\n\nThese four stopping heuristics aim to achieve a sensitivity of 95% (Campos et al., 2024), ensuring comprehensive data assessment while preventing excessive time spent on unlikely candidates.\nThe team met three of these conditions: they i) screened more than twice the estimated number of relevant records, ii) screened more than 10% of the total dataset, and iii) had not identified any relevant records in the last 50 records. However, one condition ('All key papers are marked as relevant') could not be met due to a bug with the model. Only three out of the four key papers (Critch & Russell, 2023; McLean et al., 2023; Steimers & Schneider, 2022; Weidinger et al., 2022) had appeared in the screening process, and the final key paper was scheduled to appear several thousand papers later. Because Stage 3 of the SAFE process aims to ensure that records are not missed due to the initial model, the screening team switched models to see if a new model would locate the relevant paper.\nStage 3: Switch active-learning model and screen additional records until stopping rule is reached\nBased on a review of relevant literature (e.g., Campos et al., 2024; van de Schoot et al., 2021), we use the Oracle model with the following set-up: a fully connected neural network (2 hidden layers) model as the classifier and sBert as the feature extractor, maximum as the query strategy and dynamic resampling (double) as the balance strategy. The model was trained on the data that was labeled while using the previous model. Screening stopped when no extra relevant records were identified in the last 50 records. Both authors screened in the missing key paper within the first two records found by the new model.\nStage 4: Evaluate quality\nFor quality checks, the screening team screened records previously labeled as irrelevant using the Oracle model and the default model set-up (i.e., the same model that was used in the initial/main model phase). This model was trained using the 10 highest- and lowest-ranked records from the model switching phase. Both team members screened records to identify any relevant records that might have been falsely excluded. This continued until the stopping rule was met (no extra relevant records identified in the last 50 records).\nOne member of the screening team screened the full text of all records that were included at the title/abstracts step. For calibration, 10% of the records were screened in duplicate, with 100% interrater reliability achieved. Conflicts were resolved by discussion for any remaining records."}, {"title": "Stage 2: Forwards and backwards searching and expert consultation", "content": "Following full-text screening, we undertook forwards and backwards searching using Scopus, Google Scholar, and various preprint servers hosting the included gray literature. Backwards searching involved identifying and reviewing all references from articles included in Stage 1, while forwards searching involved identifying and reviewing all articles that cited an included article. We also undertook an expert consultation, which involved sharing the preliminary set of included articles with their authors and other experts and requesting recommendations for relevant frameworks that had been overlooked. All records identified during forwards and backwards searching and expert consultation were screened by one author. Those which met inclusion criteria were added to the backlog for extraction."}, {"title": "Extraction into living Al Risk Database", "content": "Five authors were involved in data extraction. A template data extraction spreadsheet was developed to capture various details from the studies, including title, abstract, author, year, source/outlet, risk category name, risk category description, risk subcategory name, risk subcategory description, and page number. This spreadsheet was refined over several rounds of pilot testing and extractor calibration on subsets of randomly selected articles. Data extraction was then conducted individually, with regular meetings for discussion and conflict resolution. Based on the recommendations of grounded theory, we aimed to capture the studied phenomena directly from the data rather than impose our interpretations (cf. Charmaz, 2006; Corbin & Strauss, 2014). Consequently, we extracted risks based on how the authors presented them, maintaining fidelity to their original categorizations and descriptions."}, {"title": "Best fit framework synthesis approach", "content": "Seven authors were involved in data synthesis. We used a \"best fit\" framework synthesis approach to develop two Al risk taxonomies. Best-fit framework synthesis is a method for rapidly, clearly, and practically understanding the relationships and structures between concepts in a topic area (Carroll et al., 2011, 2013). It combines the strengths of framework synthesis (Ritchie & Spencer, 2002), which is a \"top down\u201d positivist method where concepts are coded against a pre-existing structure, and thematic synthesis (Thomas & Harden, 2008), which is a \u201cbottom up\u201d interpretative method where concepts are iteratively analyzed to identify patterns and structure. We outline the process in Figure 2."}, {"title": "Why we developed two taxonomies of Al risk", "content": "The goal of our best-fit framework synthesis was to create a common frame of reference for understanding and addressing the risks from artificial intelligence. We found that authors implicitly or explicitly used different lenses (e.g., Head, 2008; Nilsen, 2015; Sovacool & Hess, 2017) to create their frameworks. These lenses reveal and obscure different aspects of the Al risk landscape.\nThrough our systematic search, we identified two types of frameworks, which we will refer to here as high- and mid-level frameworks. \u201cHigh-level frameworks\" focused on capturing broad factors that specify how, when, or why an Al risk might emerge (e.g., Critch & Russell, 2023; Kilian et al., 2023) rather than discuss categories of specific hazards and harms. In contrast, \u201cMid-level frameworks\u201d focused on specific hazards and harms (e.g., Solaiman et al., 2023; Weidinger et al., 2021) but didn't explore their causes.\nThe fact that categorizations were at such different levels of specificity made it challenging to create a single framework. Often, specific mid-level risks did not fit into the categories within a high-level framework, and the broad categories in those frameworks were insufficiently specified to be useful, in isolation, for creating shared understanding. Similarly, broad high-level categorizations of how, when, or why an Al risk emerges did not fit with mid-level frameworks outlining narrow and specific sets of risk.\nWe therefore resolved that the ideal common frame of reference required two intersecting taxonomies: one to precisely decompose or define an Al risk based on the high-level conditions under which it occurred (a \"causal taxonomy\"), and one that classified commonly discussed hazards and harms associated with Al into understandable and distinct domains (a \u201cdomain taxonomy\").\nIn the following sections, we describe the process of developing these two taxonomies using a best-fit framework synthesis approach."}, {"title": "Development of high-level Causal Taxonomy of Al Risks", "content": "Best-fit taxonomy: Yampolskiy (2016)\nWe chose Yampolskiy's (2016) Taxonomy of pathways to dangerous Al as our initial best-fit framework for developing a causal taxonomy for Al risk. We selected Yampolskiy's taxonomy as it was highly cited (116 citations, fifth most highly cited from the set of identified papers), simple, comprehensive, and provided sufficient definitions for each category.\nYampolskiy's taxonomy systematically classifies the ways in which an Al system might become dangerous based on two main factors: Timing - whether the Al became dangerous at the pre-deployment or post-deployment stage, and Cause - whether the danger arose from External Causes (On Purpose, By Mistake, Environment) or Internal Causes originating from the Al system itself (Independently).\nYampolskiy proposes that this taxonomy covers scenarios ranging from Al being purposely designed to be dangerous, to becoming dangerous by accident during development or after deployment, to turning dangerous due to environmental factors outside its control, or evolving to become dangerous through recursive self-improvement. Each \u201cpathway\u201d represents a set of causal conditions that lead to Al causing harm, e.g., a person using a large language model (LLM) to generate fake news for political gain would be classified under Path B (\u201cTiming: post-deployment; External cause: on purpose\u201d)."}, {"title": "Coding and iteration process", "content": "We started by using Yampolskiy's taxonomy to categorize a sample of risks from our database. We then identified themes in the Al Risk Database that didn't fit into Yampolskiy's taxonomy. We updated the taxonomy categories, criteria, and descriptions, then coded a further sample of risks. This process was repeated over three iterations until the taxonomy categories, criteria, and descriptions were stable. We describe this iteration process in detail in Appendix A."}, {"title": "Final taxonomy", "content": "The final version of the taxonomy, which we named the Causal Taxonomy of Al Risks, included three categories of causal factors that specify how, why, or when an Al risk might emerge. The first category, Entity, classified the entity (e.g., Al system, Human) that was presented as causing the risk to occur due to a decision or action taken by that entity. The second category, Intent, classified whether the risk was presented as an expected outcome or unexpected outcome of an entity pursuing a goal. The third category, Timing, classified the stage in the Al lifecycle that the risk is presented as occurring (e.g., pre-deployment, post-deployment). Each of these categories includes a third option, \"Other,\" which captures risks that are not clearly categorizable within the primary options. Each of the categories is therefore mutually exclusive; each risk is classified under only one option within each category. The Causal Taxonomy is presented and described in more detail in the Results section."}, {"title": "Development of mid-level Domain Taxonomy of Al Risks", "content": "Best-fit taxonomy: Weidinger (2022)\nWe chose Weidinger et al (2022) \u201cTaxonomy of Risks posed by Language Models\u201d as our initial mid-level best-fit framework because it and its related papers (Weidinger et al., 2021, 2023) are among the highest cited in our review. Although this taxonomy was focused on language models, its set of categories was one of the most comprehensive, and it has been iterated upon over several publications. It included six areas of risks from language models: (1) Discrimination, Hate speech and Exclusion; (2) Information Hazards; (3) Misinformation Harms; (4) Malicious Uses; (5) Human-computer interaction Harms; and (6) Environmental and Socioeconomic Harms. Each area of risk described several subcategories of risk."}, {"title": "Coding and iteration process", "content": "We applied this taxonomy by coding as many of the included risks as possible using the Weidinger (2022) taxonomy. We operationalised the taxonomy by using the definitions or descriptions for each category from Weidinger (2022). Because several similar taxonomies were included in the set identified by the systematic literature review (e.g., Weidinger et al., 2021, 2022, 2023), we considered descriptions and definitions from any of these taxonomies in our initial coding.\nWe iterated on the taxonomy to accommodate risks that could not be coded against the existing Weidinger (2022) taxonomy. The most common risks that could not be accommodated were those related to Al system safety, failures and limitations; Al system security vulnerabilities and attacks; and competitive dynamics or other failures of governance to manage the development and deployment of Al systems. We describe this iteration process in detail in Appendix A."}, {"title": "Final taxonomy: Domain Taxonomy of Al Risks", "content": "The final version of the taxonomy, which we named the Domain Taxonomy of Al Risks, included seven domains of Al risk, and 23 subdomains of hazards and harms associated with Al. The domains were (1) Discrimination & toxicity, (2) Privacy & security, (3) Misinformation, (4) Malicious actors & misuse, (5) Human-computer interaction, (6) Socioeconomic & environmental, and (7) Al system safety, failures & limitations. As with Weidinger's (2022) taxonomy, these risk domains are not mutually exclusive; many risks span multiple domains or subdomains due to their interconnected nature. For example, a risk related to Al-generated disinformation could be relevant to both the Misinformation domain and the Malicious actors & misuse domain. The Domain Taxonomy is presented and described in more detail in the Results section."}, {"title": "Coding", "content": "Three authors were involved in coding risks against our taxonomies. Risks were coded by a single reviewer and discussed with the team where relevant. The coding process involved systematically categorizing each extracted risk according to the definitions within the relevant taxonomy. Based on grounded theory recommendations (cf. Charmaz, 2006; Corbin & Strauss, 2014), we coded risks as they were presented by the authors, aiming to capture the studied phenomena directly rather than impose our own interpretations or infer intent. When coding risks for our high-level Causal Taxonomy, we categorized risks relevant to multiple levels of each causal factor (e.g., both pre-deployment and post-deployment) as \"Other.\" In our mid-level Domain Taxonomy, we categorized risks relevant to multiple domains and subdomains (e.g., Al-generated disinformation) in the single most relevant category."}, {"title": "Results", "content": "We retrieved 17,288 unique articles from our searches and expert consultations. Of these records we screened 7,945. We excluded 9,343 records were not screened by the authors; they were excluded by our stopping criteria while using ASReview which used machine learning to recommend when screening was unlikely to yield further relevant content. We assessed the full text of 91 articles. A total of 43 articles and reports met the eligibility criteria: 21 from our search, 13 from forwards and backwards searching, and 9 from expert suggestions. We present a PRISMA diagram illustrating the search results."}, {"title": "Systematic literature search", "content": "We included 43 documents: 17 peer-reviewed articles, 16 preprints, 6 conference papers, and 4 other reports. We mainly identified recent literature, with all but four of the included documents published later than 2020.\nWe coded the corresponding author's country and found that most of the included documents were from the USA (n = 12), China (n = 8), United Kingdom (n = 6), and Germany (n = 5). Other countries included Singapore, Portugal, Australia, Brazil, India, Iran, Netherlands, Spain, and T\u00fcrkiye. Most of the included documents had a corresponding author affiliated with a university (n = 26), followed by industry organization (n = 11), with the remainder from government, international organizations (i.e., United Nations), or non-government organizations (n = 6). The most common affiliation was DeepMind / Google DeepMind (n = 5). The most common described methodology was a narrative review or \u201csurvey\u201d of existing literature (n = 16), followed by systematic review (n = 6), and scoping review (n ="}]}