{"title": "FUNAvg: Federated Uncertainty Weighted Averaging for Datasets with Diverse Labels", "authors": ["Malte T\u00f6lle", "Fernando Navarro", "Sebastian Eble", "Ivo Wolf", "Bjoern Menze", "Sandy Engelhardt"], "abstract": "Federated learning is one popular paradigm to train a joint model in a distributed, privacy-preserving environment. But partial annotations pose an obstacle meaning that categories of labels are heterogeneous over clients. We propose to learn a joint backbone in a federated manner, while each site receives its own multi-label segmentation head. By using Bayesian techniques we observe that the different segmentation heads although only trained on the individual client's labels also learn information about the other labels not present at the respective site. This information is encoded in their predictive uncertainty. To obtain a final prediction we leverage this uncertainty and perform a weighted averaging of the ensemble of distributed segmentation heads, which allows us to segment \"locally unknown\" structures. With our method, which we refer to as FUNAvg, we are even on-par with the models trained and tested on the same dataset on average. The code is publicly available.", "sections": [{"title": "1 Introduction", "content": "The ability of deep neural networks to accurately segment anatomical structures promises precise quantitative analysis and clinical diagnosis, and has the potential to significantly improve medical decision making [24]. However, due to the required effort for accurately labelling medical images every institution only creates annotations for their particular research endeavour [22]. Despite being from\nthe same modality and capturing a joint field of view, the cumulative information is hardly exploited. This leads to partially annotated, distributed datasets in a sense that some structures might be segmented in one dataset (e.g. liver, kidney) and other structures in the other dataset (e.g., spleen, spine) that cannot be gathered on a central server because of privacy constraints.\nThe standard workflow includes training a model on dataset A that has the structure of interest annotated and applying it to dataset B, which due to domain gaps leads to subpar performance. Recently, self-supervised methods have gained attention which use an unsupervised pre-training on a large corpus of data similar to dataset B, where the model is usually trained to minimize a reconstruction loss [7]. Federated Learning (FL) is one renowned method that reverts the common paradigm of central data storage to circumvent privacy constraints [20]. In FL the model is sent to each data holding institution and subsequently averaged on a central server during model training. Our method combines both approaches by jointly learning all annotated structures across a multitude of datasets while showing that not-annotated information in the data is learned as well and therefore can be explored for improving predictions during inference similar to self-supervised methods. The approach most related to ours, MultiTalent [24], also employs training multiple segmentation heads across different datasets but discards the possible information learned from not-annotated structures, partly because they do not employ a Bayesian approach [24]."}, {"title": "2 Related Work", "content": "Learning from Partially Annotated Datasets. Lately, there has been an increasing amount of studies focusing on multi-organ segmentation using data that is partially labeled. One line of research leverages the inherent homogeneous anatomy of the human body in terms of shape, size, and locations of anatomical structures [21,28]. In another approach, the network is equipped with different encoders for each dataset in the learning procedure [26]. But this method falls short to account for different combinations of the various organs across all datasets present in the model training. Similar to equipping the model with different encoders multiple heads that share a custom backbone can be used [4]. In the approach most similar to ours called MultiTalent the network is equipped with different segmentation heads for each datasets in the learning procedure [24]. It is argued that this is largely needed due to different annotation protocols across the different datasets. However, this fails at leveraging unannotated organs across different datasets that enhances predictive quality due to larger amount of data samples. Further, we believe that varying annotation protocols represent some form of data dependent i.e. aleatoric uncertainty that can be captured with Bayesian techniques [5,12,13]. MultiTalent does not exploit ways of obtaining a final prediction by e.g. averaging of the trained segmentation heads [24].\nBayesian Federated Learning. In contrast to the point estimate used in frequentist deep learning, the Bayesian approach models the parameters with a distribution. Mathematically a prior distribution $p(\\theta|\\alpha)$ is placed over the weights $\\theta$ of a neural network, governed by a hyperparameter $\\alpha$. Our interest lies in the posterior after observing some data $D$ $p(\\theta|D,\\alpha) = p(D|\\theta,\\alpha)p(\\theta|\\alpha)/p(D)$. Unfortunately, this distribution is not tractable, but can be approximated with Bayesian inference techniques such as variational inference (VI).\nIn federated learning, numerous clients collaboratively train a unified global model, while adhering to data privacy as no data is shared with a central server managing the training process called federated averaging (FedAvg) [20]. For a given set of clients, let $D_i = \\{(x_i, y_i)\\}$, represent the data of client $i$ and the weights of the global model. At the beginning of each training round the model"}, {"title": "3 Methods", "content": "Uncertainty. To reduce computational load we opt for the practical Bayesian technique of Monte Carlo (MC) dropout [5]. Using dropout during training and testing has been shown to approximate the true posterior, while not introducing more computational load to capture uncertainty. Uncertainty is divided into aleatoric (data dependent) and epistemic (model dependent) uncertainty. We follow [14] and define uncertainty as\n$U = \\frac{1}{T} \\sum_{t=1}^{T} [diag(p_t) - p_t^2] +  \\frac{1}{T} \\sum_{t=1}^{T} (p_t - \\overline{p})^2$,\n(1)\nwhere T is the number of MC sampling steps, $\\odot$ denotes the outer product, $f$ the network with parameters $\\theta_t$ in step t for input $x^*$, $\\overline{p} = 1/T \\sum_{t=1}^{T} p_t$ and $p_t = p(\\theta_t) = Softmax\\{f_{\\theta_t} (x^*)\\}$. The first part captures the inherent variability in the data that cannot be reduced even if more data were to be collected, while the second term captures the variance in the model's output that can potentially be reduced with more data.\nNeural networks tend to produce overconfident predictions, meaning the predictive uncertainty is smaller than the predictive error, this is also known as miscalibration [16] and can be expressed with\n$\\mathbb{E}_p [|P (y = \\hat{y}|p = q)-q|], \\forall q \\in [0,1]$,\n(2)\nwhich quantifys the expectation of the difference between predicted softmax likelihood $\\hat{y}$ and accuracy and can be approximated by the Expected Calibration"}, {"title": "4 Results", "content": "We performed an 80-20% train-test split at each client. For a baseline, we trained models on single clients (no FL) and evaluated them in the intra-client scenario on the same client (row 1 in Tab. 1) and inter-client scenario on the test split of all other clients where the target label was available (row 2 in Tab. 1). We then performed training similar to MultiTalent [24], where each dataset obtained a separate segmentation head. We performed vanilla averaging and uncertainty weighted averaging for the centralized (Cen Avg and CUNAvg, rows 3 and 4) and federated setting (Fed Avg and FUNAvg, rows 5 and 6).\nDespite the challenges of different quantities of annotated labels, CT scans, and fields of view, federated training was successful for all structures present at any client. Our method (DICE=84.77) is on par with the models trained and evaluated on the same dataset (84.79) and outperforms the centralized setting (81.74) when uncertainty is utilized to enhance predictions. This improvement is especially high in scenarios with limited data, such as Learn2Reg [27],"}, {"title": "5 Discussion", "content": "The information for segmenting all structures across the datasets is encoded in the (federated trained) backbone. Unable to assign a previously unseen label in its fixed number of channels, the segmentation head only learns the presence of some structures encoded in the uncertainty, without being explicitly trained for it. For example, Fig.5 illustrates how a network with a head trained on the BCV Cervix[15] dataset can segment organs well in the uncertainty when applied to\nthe AMOS [9] dataset, which contains none of the labels used for training. In federated learning, the segmentation heads with non-overlapping labels may use the same feature maps from the backbone, whereas in the centralized case, the heads tend to use different feature maps. The improvement of our proposed FUNAvg is larger for underrepresented labels (see Fig. 4 and Tab. 2 in the Appendix). We believe that predictions for these structures are encoded in the uncertainties of the other clients, whereas for labels present at many sites, predictions are already encoded in the output. For these labels, our proposed method may lead to slightly worse results. Future work could explore whether uncertainty can be used more targeted during averaging in such cases."}]}