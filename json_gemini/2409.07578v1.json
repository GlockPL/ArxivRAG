{"title": "A Novel Mathematical Framework for Objective Evaluation of Ideas using a Conversational AI (CAI) System", "authors": ["B. Sankar", "Dibakar Sen"], "abstract": "The demand for innovation in product design necessitates a prolific ideation phase. Conversational AI (CAI) systems that use Large Language Models (LLMs) such as GPT (Generative Pre-trained Transformer) have been shown to be fruitful in augmenting human creativity, providing numerous novel and diverse ideas. Despite the success in ideation quantity, the qualitative assessment of these ideas remains challenging and traditionally reliant on expert human evaluation. This method suffers from limitations such as human judgment errors, bias, and oversight. Addressing this gap, our study introduces a comprehensive mathematical framework for automated analysis to objectively evaluate the plethora of ideas generated by CAI systems and/or humans. This framework is particularly advantageous for novice designers who lack experience in selecting promising ideas. By converting the ideas into higher dimensional vectors and quantitatively measuring the diversity between them using tools such as UMAP, DBSCAN and PCA, the proposed method provides a reliable and objective way of selecting the most promising ideas, thereby enhancing the efficiency of the ideation phase.", "sections": [{"title": "Introduction", "content": "The advent of Conversational AI (CAI) technologies, particularly large language models (LLMs) like GPT, Llama, Gemini, etc., has revolutionized the field of natural language processing (Yuhan, Xiuying, and Rui 2023). These tools offer unprecedented capabilities in generating coherent and contextually relevant text, facilitating new forms of co-creation and collaboration in both individual and group settings (Meyer, Urbanowicz, and Martin 2023). In recent times, since its major outbreak, these models have found their way into several applications, such as Content Generation, Customer Service, Education, Healthcare, Research and Development, Entertainment, Translation and Localization, Personal Assistants, etc. (Desmond et al. 2024a). Among these applications, the ability to generate new human-like content holds significant value in various domains. One such field that stands to benefit greatly is product design (G. E. Gonzalez et al., n.d.). Particularly during the conceptual design phase, designers are tasked with generating ideas\u2014a process that involves the creation of new content (Liu et al. 2023). Recently, the application of Conversational Artificial Intelligence (CAI) models in this context has garnered increasing attention (Shaer et al., n.d.). The authors of this paper have also previously published their research on utilizing CAI as a tool for idea generation in product design.\nConversational Al models have significant implications for the creative content generation process, encompassing both the divergence stage of idea generation and the convergence stage of evaluation and selection of ideasShaer et al. 2024a. During the divergence stage, LLMs can generate numerous ideas rapidly, providing a rich pool of options for further refinement and selection. This capability is particularly advantageous in brainstorming sessions, where the goal is to produce a wide array of ideas without immediate judgment (Shaer et al., n.d.). The increasing availability of LLMs, such as GPT, has enabled widespread adoption in various domains, including creative writing, design, and problem-solving (Shaer et al. 2024b). These models can generate text that is often indistinguishable from human-written content, making them valuable tools for augmenting human creativity Shaer et al. 2024a during the ideation process. However, the integration of LLMs into the creative process also necessitates robust evaluation mechanisms to ensure the quality and relevance of the generated ideas."}, {"title": "", "content": "A crucial aspect of using LLMs in idea generation is distinguishing between Al-generated and human-generated content. Participants in various studies have emphasized the importance of clearly identifying Al contributions, often using visual cues like icons and outlines G. Gonzalez et al. This distinction not only aids in assigning credit but also helps maintain accountability and ethical considerations in collaborative settings. For instance, capturing the prompt that resulted in the Al output and acknowledging the user who wrote the prompt can provide transparency and accountability in the ideation process.\nThe ability to generate a diverse range of ideas is vital for effective ideation. Participants have recognized the need for generating unexpected or provocative ideas to stimulate creative thinking G. Gonzalez et al. Novelty and diversity are essential dimensions of idea quality, as they contribute to the originality and uniqueness of the generated ideas (Fiorineschi and Rotini 2023). While traditional tools may lack controls for low-level generative parameters, modern LLMs can be prompted to evaluate their own ideas for relevance, thereby filtering out less pertinent suggestions and enhancing the overall quality of the ideation process. For example, adjusting the temperature parameter in LLMs can control the randomness and creativity of the generated ideas. Higher temperatures result in more diverse and creative outputs, while lower temperatures produce more focused and predictable ideas.\nGroup brainstorming sessions often face barriers such as peer judgment, free riding, and production blocking, which can limit the effectiveness of the ideation process Shaer et al. 2024a. Peer judgment refers to the influence of group members' opinions on individual contributions, which can discourage the sharing of unconventional ideas. Free riding occurs when some group members rely on others to contribute, leading to reduced individual participation. Production blocking happens when group members wait for their turn to share ideas, resulting in lost opportunities for spontaneous ideation. Online visual workspaces and the integration of LLMs into these platforms offer new avenues for enhancing group creativity by providing diverse perspectives and reducing evaluation apprehension Desmond et al. 2024b. While holistic measures can be efficient, they often conflate multiple constructs, leading to inconsistencies in ratings. Therefore, a more granular approach is necessary to capture the specific aspects of idea quality systematically. For example, using a well-defined set of criteria can provide a structured and consistent evaluation framework.\nEvaluating the quality of ideas is a critical aspect of the creative process. Traditional methods for idea evaluation can be broadly categorized into subjective and objective evaluations.\nSubjective evaluations have traditionally been the cornerstone of idea assessment. nent. These evaluations often involve human judges who rate the quality of ideas based on personal judgment, which can be influenced by individual biases and inconsistencies (Ben Ahmed et al. 2010). While subjective evaluations can capture nuanced insights, they are inherently limited by their lack of scalability and potential for"}, {"title": "", "content": "variability Dean et al. 2006. For example, one rater may intuitively include novelty or workability in their evaluation, while another may not, leading to different ratings. Moreover, a single rater may be inconsistent across ideas because different constructs may seem more important to some ideas than others (Boudier et al. 2023). Thus, despite their efficiency, holistic measures do not address specific evaluation components in a predictable way.\nSeveral researchers (Fiorineschi and Rotini 2023; Kim and Maher 2023; Christensen and Ball 2016; Nelson et al. 2009; Linsey et al. 2011; Bryant et al. 2005; Puccio and Cabra 2012; Kurtoglu, Campbell, and Linsey 2009; Karimi et al. 2019; Han et al. 2018) have reported multiple dimensions for the subjective evaluation of ideas, each capturing a specific aspect of idea quality. The following are some of the key dimensional metrics identified from various literature.\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nNovelty: The degree to which the idea is new and not derivative.\nRarity: The uniqueness of the idea compared to existing ideas.\nOriginality: The novelty and innovativeness of the idea.\nUsefulness: The practical applicability of the idea.\nRelevance: The extent to which the idea is connected to the problem statement.\nWorkability: The feasibility and implementability of the idea.\nDiversity: The range and variety of different ideas.\nQuantity: The total number of ideas generated.\nQuality: The overall excellence of the idea.\nCreativity: The degree of imagination and inventiveness in the idea.\nThoroughness (Specificity): The level of detail and specificity in the idea.\nFeasibility: The practicality and achievability of the idea.\nEffectiveness: The potential impact and success of the idea.\nInnovativeness: The degree of innovation and breakthrough thinking in the idea.\nImpact: The potential effect and influence of the idea.\nUtility: The usefulness and benefits of the idea.\nPracticality: The ease of implementation and practicality of the idea.\nInsightfulness: The depth of understanding and insight reflected in the idea.\nObjective evaluations aim to mitigate the limitations of subjective assessments by employing systematic and quantifiable metrics. Traditional automatic metrics like BLEU, ROUGE, and METEOR have been used to evaluate natural language generation systems (Blagec et al. 2022), but these metrics often show a low correlation with human judgments (Yang et al. 2023). To the best of the author's knowledge, there are no objective evaluation metrics similar to subjective evaluation metrics that align with human judgment. Hence, one of the novel contributions of this research work involves developing certain dimensional metrics that correlate with human judgement.\nThe use of AI for evaluating ideas promises increased speed"}, {"title": "", "content": "and objectivity. Various types of AI evaluation systems have been explored by several researchers, each offering unique advantages and challenges:\n1. N-gram-Based Metrics: These metrics evaluate text based on term frequency and inverse document frequency. While they are simple and computationally efficient, they often fail to capture semantic meaning and contextual relevance (Kim, Baldwin, and Kan 2010).\n2. Embedding-Based Metrics: These metrics measure the semantic similarity between generated text and reference text based on word or sentence embeddings. Examples include WMD, BERTScore, and MoverScore. Embedding-based metrics offer a more robust measure of semantic similarity by capturing contextual nuances (Yang et al. 2023).\n3. Task-Specific Evaluators: These evaluators are fine-tuned for specific tasks, such as dialogue generation or report generation. They provide tailored evaluations based on task-specific criteria (Dahlander et al. 2023).\n4. Unified Evaluators: These evaluators offer a generalized framework for evaluating multiple types of NLG tasks. They provide a consistent evaluation approach across different tasks and domains (Zhong et al. 2022).\n5. LLM-Based Evaluators: These evaluators, such as Prometheus, use large language models to assess generative outputs based on custom score rubrics. They have shown a high correlation with human judgments and offer a scalable alternative to human evaluation. However, such a system has not been explored for idea evaluation in the product design domain. (Desmond et al. 2024b).\nDespite the promise of AI-based evaluation systems, challenges like prompt sensitivity, bias, and hallucinations remain. Ensuring robust and transparent evaluation processes, integrating human oversight, and validating evaluation criteria are essential for enhancing the reliability and validity of AI-based evaluations.\nThe rapid advancements in artificial intelligence (AI) and natural language processing (NLP) have ushered in a new era of innovation, particularly in the realm of idea generation. Conversational AI (CAI) systems, powered by large language models (LLMs) such as GPT, have been shown to demonstrate unprecedented capabilities in generating numerous ideas within a short period. This transformative potential of CAI systems necessitates the development of automated, objective methods for evaluating the vast quantity of ideas they produce.\nIn traditional creative processes, human designers generate ideas through brainstorming sessions, individual reflection, and collaborative discussions. The volume of ideas produced in these settings is typically manageable, allowing human experts to evaluate and rate each idea subjectively. This manual evaluation process, although time-consuming, benefits from the nuanced judgment and contextual understanding of human evaluators. However, the advent of CAI systems has fundamentally altered the landscape of idea generation. These systems can produce an overwhelming number of ideas in a fraction of the time it would take human designers. While this capability significantly enhances the"}, {"title": "", "content": "creative process by providing a rich pool of potential solutions, it also introduces the challenge of idea abundance. The sheer volume of ideas generated by CAI systems renders manual evaluation impractical and inefficient.\nGiven the impracticality of manual evaluation, there is a pressing need for automated methods to assess and evaluate the ideas generated by CAI systems. Such methods must be objective to ensure consistency, scalability, and reliability in the evaluation process. Objective evaluation is particularly crucial in scenarios where the ideas generated are used to inform critical decision-making processes, such as product design, strategic planning, and innovation management.\nThis paper proposes a systematic mathematical framework for the objective evaluation of the ideation process. We can apply quantitative metrics to assess their quality, relevance, and diversity by representing ideas as mathematical entities, such as vectors in high-dimensional space. This approach enables the systematic evaluation of ideas based on clearly defined measures, eliminating the subjectivity and variability inherent in manual evaluations.\nEmbedding-based methods are inherently statistical, necessitating a large set of sample ideas to ensure robust and meaningful analysis. However, obtaining such extensive datasets from human participants often results in a loss of uniformity and a limited number of ideas, complicating systematic analysis. To address this challenge, we leveraged a CAI-based ideation tool, as previously published in our work, which facilitates the generation of a large set of ideas within a specific structured framework. This tool enabled us to generate the necessary sample ideas for the development and validation of our evaluation method. For the sake of completeness, the following section briefly describes the CAI-based generation process, providing context for its role in our study."}, {"title": "2. Idea Generation using CAI", "content": "Idea generation is a cognitively expensive process that requires experience to master (Sankar and Sen 2023). Novice designers often face the struggle to generate a large variety of novel ideas. Conversational AI (CAI) systems powered by advanced natural language processing (NLP) models have been reported in our earlier work (Sankar and Sen 2024) for generating a required number of ideas quickly. The conversational AI system leverages large language models to generate text based on given prompts. These models are trained on extensive datasets, enabling them to understand and generate human-like text across various domains. In the context of idea generation, (Sankar and Sen 2024) established that CAI-based ideation facilitates the creative process by overcoming human cognitive limitations such as fatigue and design fixation."}, {"title": "2.1. Idea Representation using AOC", "content": "A Custom-built interface was developed for generating ideas, as shown in Figure 1 with labels for different fields. The response of the CAI system is managed with a field marked as 'creativity slider', which adjusts the parameter commonly called temperature; a higher temperature setting produces more diverse outputs, while a lower temperature setting produces focused and predictable ideas.\nIn order for CAI to present ideas that are similarly detailed, coherent, and easily interpretable, an Action-Object-Context (AOC) model was developed. Here, action describes what the idea aims to achieve or perform; object refers to the entity involved in the action, and context provides the situation where the action happens. The ideas generated are stored as a JSON file for further investigation."}, {"title": "2.2. Generating Ideas Using AOC", "content": "The problem statements serve as prompts for the CAI system, guiding the generation of relevant ideas. For this study, we used the following six distinct problem statements.\n\u2022 PS1: Product for segregation as a means for effective waste management\n\u2022 PS2: Product for footwear disinfection and cleaning for improved hygiene and safety\n\u2022 PS3: Product for enhancing household dish cleaning efficiency and sustainability\n\u2022 PS4: Product for enhancing comfort and efficiency for prolonged standing in queues\n\u2022 PS5: Product for bird-feeding for fostering mental well-being of elderly individuals at Home\n\u2022 PS6: Product for convenient umbrella drying and storage on travel\nThe CAI tool uses these prompts to generate 100 ideas for each problem statement, each structured according to the AOC model."}, {"title": "2.3. Advantages of Using CAI for Idea Generation", "content": "Using the CAI tool for idea generation offers the following advantages:\nSpeed and Efficiency: The CAI tool can generate many ideas in a fraction of the time it would take human designers. This rapid ideation accelerates the creative process and allows for exploring a broader idea space.\nOvercoming Cognitive Limitations: The CAI tool is not subject to human cognitive limitations such as fatigue, design fixation, and mental blocks. This enables a more comprehensive and unbiased exploration of the idea space.\nStandardization and Consistency: The AOC model provides a standardized format for representing ideas, ensuring consistency and coherence in the generated ideas. This standardization facilitates easier assessment and comparison of ideas."}, {"title": "3. Characteristics of Idea Exploration", "content": "Idea exploration involves generating a wide range of ideas to solve a given problem, with the aim of identifying unique, novel, and effective solutions."}, {"title": "3.1. Concept of Idea Space", "content": "The concept of idea space is rooted in several theoretical frameworks in creativity research and cognitive psychology. One such framework is the Geneplore Model (Hunt 1994; Ward 2004), which posits that creative cognition involves two main processes: generation and exploration. In the generation phase, individuals produce a variety of mental representations known as pre-inventive structures. In the exploration phase, these structures are elaborated, refined, and evaluated to produce novel and useful ideas.\nAnother relevant theory is the Conceptual Blending Theory (Fauconnier and Turner 2003), which suggests that creative ideas arise from the combination of different distinct mental sub-spaces. By blending elements from different sub-spaces, individuals can generate new ideas that transcend the limitations of any single domain.\nThus, the idea space, also known as the solution space, represents the entire range of potential ideas that can be generated to address a specific problem. For the context of this paper, the authors define Idea Space as a multi-dimensional conceptual space where each point corresponds to a unique idea. In an ideal scenario, this space should be uniformly explored to uncover diverse and innovative solutions.\nDesigners navigate this idea space using their cognitive abilities, drawing on their knowledge, experience, and creativity. However, the exploration of idea space is not always uniform. Designers may face cognitive bottlenecks that hinder their ability to generate a wide range of ideas, leading to clusters of similar ideas and gaps in other space areas."}, {"title": "3.1.1. Cognitive Processes Involved in Exploration of Idea Space", "content": "Exploring the idea space involves complex cognitive processes that include divergent thinking, convergent thinking, and analogical reasoning:\nDivergent Thinking: The ability to generate multiple, diverse ideas from a single starting point. Divergent thinking is crucial for expanding the breadth of the idea space.\nConvergent Thinking: The ability to evaluate and refine ideas to identify the most promising solutions. Convergent thinking is essential for exploring the depth of the idea space.\nAnalogical Reasoning: The ability to draw parallels between different domains or contexts to generate novel ideas. Analogical reasoning facilitates the blending of different conceptual spaces."}, {"title": "3.1.2. Challenges in the Exploration of Idea Space", "content": "Despite the potential for generating innovative solutions, exploring the idea space is fraught with challenges (Sankar and Sen 2024). Designers often face cognitive bottlenecks that hinder their ability to explore the idea space comprehensively. These bottlenecks are classified by the authors (Sankar and Sen 2024). For sake of completion, the bottlenecks are given below:\nDesign Fixation: A tendency to become fixated on a particular idea, limiting the exploration of the idea space.\nCognitive Biases: Systematic patterns of deviation from rationality in judgment and decision-making, such as confirmation bias and anchoring.\nLack of Domain Knowledge and/or Experience: Insufficient knowledge or experience in a particular domain can restrict the ability to generate diverse and relevant ideas from different corners of the idea space.\nMental Block: Limited time, budget, and technological resources can constrain the exploration of the idea space."}, {"title": "3.2. Measures for Quantifying Exploration of Idea Space", "content": "To objectively assess the exploration of idea space, we introduce two key measures: dispersion and distribution."}, {"title": "3.2.1. Dispersion", "content": "Dispersion refers to the spread or variability of the idea points in the 2D space. It indicates how much the points are spread out from each other and from the centre of the distribution across the idea space. Dispersion can be thought of as the extent to which the ideas vary from one another. High dispersion indicates that the ideas are diverse and cover a wide range of the solution space, while low dispersion suggests that the ideas are clustered in a specific region.\nKey Aspects of Dispersion:\n1. Range: The distance between the minimum and maximum values in each dimension.\n2. Variance and Standard Deviation: Measures of how much the points deviate from the mean.\n3. Spread: The extent to which points within a cluster are spread out.\n4. Outliers: Points that are far away from the majority of other points, indicating extreme values or unique ideas."}, {"title": "3.2.2. Distribution", "content": "Distribution refers to the overall arrangement or pattern of the idea points in the idea space. It indicates how the points are organized or grouped and where the points are more concentrated or sparse. It refers to the uniformity with which ideas are spread across the idea space. A uniform distribution indicates that all regions of the idea space are explored equally, while a non-uniform distribution suggests that certain areas are more densely populated with ideas than others.\nKey Aspects of Distribution:\n1. Shape: The overall form of the point cloud (e.g., normal, skewed, bimodal).\n2. Density: Areas where points are more concentrated versus areas where points are sparse.\n3. Clusters: Groups of points close to each other, indicating similar ideas.\n4. Patterns: Specific arrangements or structures in the data (e.g., linear, circular)."}, {"title": "3.3. Classification of Idea Space", "content": "To illustrate the concept of idea exploration, we consider four possible scenarios based on the measures of dispersion and distribution:\n1. High Dispersion and Uniform Distribution: This scenario represents the ideal exploration of idea space, where ideas are diverse and evenly spread across the entire solution space. It indicates a comprehensive and balanced approach to idea generation.\n2. High Dispersion and Non-Uniform Distribution: In this scenario, ideas are diverse but clustered in certain regions of the idea space. While there is a wide range of ideas, some areas are over-explored while others are neglected.\n3. Low Dispersion and Uniform Distribution: This scenario represents a limited range of ideas that are evenly spread across the idea space. While the ideas are uniformly distributed, they lack diversity and may not provide innovative solutions.\n4. Low Dispersion and Non-Uniform Distribution: This scenario is the least desirable, where ideas are both limited in range and clustered in specific regions. It indicates a narrow and imbalanced approach to idea generation."}, {"title": "4. Embeddings for Idea Representation", "content": "To objectively assess idea exploration, it is essential to represent ideas as points in a mathematical sense. This allows for the application of quantitative measures to evaluate the dispersion and distribution of ideas. By converting ideas into high-dimensional vectors, we can use techniques such as"}, {"title": "4.1. Nature of Embeddings", "content": "Embeddings work by mapping tokens, which are subwords, words or phrases, to vectors in a high-dimensional space (typically in the order of 1000s). This mapping is typically learned during the training phase of the embedding model. The goal is to position semantically and contextually similar words close to each other in this space while dissimilar words are positioned farther apart."}, {"title": "4.1.1. Semantic Encoding", "content": "The key to the effectiveness of embeddings lies in their ability to encode semantic meaning. This is achieved through training on large corpora of text, where the model learns to predict words based on their meaning. For example, in the sentences \"The cat sat on the mat\" and \"The cat sat on the rug\", embeddings capture the relationship between \"mat\" and \"rug\" and position them nearby in the vector space due to the frequent analogous usage."}, {"title": "4.1.2. Positional Encoding", "content": "In addition to semantic meaning, modern language models like Transformers also incorporate positional encoding to understand the context in which the words are being used. This is crucial because the meaning of a word can depend on its position in a sentence. Positional encoding adds information about the position of each word in the sequence, enabling the model to understand the structure, order and"}, {"title": "", "content": "context of the text better. For example, in the sentences \"The design in the dress was detailed.\" and \"She has a natural talent for fashion design.\", the usage of the word design refers to two different contexts, and this relationship is captured by the embeddings to understand the context."}, {"title": "4.2. Mechanism of Embeddings", "content": "Tokenization is the process of splitting text into smaller units called tokens, which can be words, subwords, or characters. For example, the sentence \"Natural Language Processing\" could be tokenized into [\"Natural\", \"Language\", \"Processing\"] or even into subword units like [\"Nat\", \"ural\", \"Lang\", \"uage\", \"Processing\"] depending on the tokenization strategy. The subword strategy is employed to help the model understand spelling mistakes in words while maintaining their meaning.\nThe dimension of an embedding vector is a critical parameter that influences the model's performance. Common dimensions range from 50 to 4096 or even higher for language models with larger parameters. The choice of dimension depends on the complexity of the task and the computational resources available. Higher dimensions can capture more nuanced relationships but require more computational power. While individual values do not have explicit meanings, collectively, they capture various aspects of semantic and syntactic information. For instance, certain dimensions might capture gender, tense, plurality and other linguistic attributes."}, {"title": "4.3. Properties and Types of Embeddings", "content": "In mathematical terms, embeddings are vectors in a high- dimensional space. They exhibit properties such as linearity, where vector arithmetic can capture analogies (for example, the vector arithmetic between the vectors of \"king\" - \"man\" + \"woman\" \u2248 gives the vector for \"queen\"). This linearity is a powerful feature that enables embeddings to generalize across different contexts.\nEmbeddings can be created at various levels of granularity as follows:\n1. Word Embeddings: Represent individual words (e.g., Word2Vec, GloVe, Text-Embedding-3).\n2. Sentence Embeddings: Represent entire sentences (e.g., Sentence-BERT).\n3. Paragraph Embeddings: Represent longer text segments (e.g., Doc2Vec).\nFor static embedding models like Word2Vec, the embeddings for a given word are constant. However, in contextual models like BERT or Text-Embedding-3, embeddings can vary depending on the word's context within a sentence. This allows for a more nuanced understanding of language."}, {"title": "4.4. Types of Embedding Models", "content": "There are two types of embedding models based on their ability to capture the similarities in the text. They are as follows:"}, {"title": "4.4.1. Static Embedding Models", "content": "Static embedding models capture the semantic similarity in the text. Semantic similarity measures how much the meanings of two words, phrases, or sentences are alike, regardless of their specific contexts. This concept focuses on the intrinsic meaning of the words themselves. Traditional word embedding models like Word2Vec, GloVe (Global Vectors for Word Representation), and FastText produce a single, static vector for each word, which represents its overall semantic meaning. These embeddings do not change based on context. Semantic similarity is about capturing the essence of meaning. For example, \"device\" and \"instrument\" would have high semantic similarity because they represent the same concept."}, {"title": "4.4.2. Dynamic Embedding Models", "content": "Dynamic embedding models capture contextual similarity in addition to semantic similarity in the text. Contextual similarity refers to the similarity between words or phrases based on the contexts in which they appear. This concept is often associated with contextual embeddings, which take into account the surrounding words to generate a representation that varies depending on the context. Contextual embeddings, like those produced by models such as BERT (Bidirectional Encoder Representations from Transformers), ELMO (Embeddings from Language Models), and Text-Embedding-3 model (OpenAI), generate different embeddings for the same word depending on its context. For example, the word \"bank\" will have different embeddings in \"bank of a river\" and \"savings bank\". These embeddings are generated by considering surrounding words, capturing the nuances and specific meanings in different contexts."}, {"title": "4.5. Process of Conversion of Text to Embedding Vectors", "content": "The process of converting text into vectors using any of the aforementioned embedding models involves several steps, such as Tokenization (Splitting the text into tokens), Embedding Generation (Mapping each token to its corresponding vector), and Aggregation (Combining the vectors to form a representation of the entire text segment). In practice, an embedding layer in a neural network architecture performs these steps. During training, the model adjusts the embedding vectors to minimize a loss function, which measures the difference between the model's predictions and the actual outcomes. The result is a set of embeddings that capture the underlying structure and meaning of the text."}, {"title": "4.6. Contribution to CAI Behavior", "content": "Embeddings are crucial for the behaviour of Conversational AI (CAI) models like GPT. They enable the model to understand and generate coherent and contextually appropriate responses. By capturing the semantic and contextual relationships between words, embeddings allow the model to generate text that is not only grammatically correct but also meaningful. The use of embeddings enhances"}, {"title": "", "content": "the model's ability to understand context, making it possible to generate more relevant and accurate responses. This is particularly important in conversational AI, where understanding the context of a conversation is key to providing useful and meaningful interactions."}, {"title": "4.7. Demonstrating the Validity of Embeddings", "content": "In this paper, we use the Text-Embedding-3 (TE3), a dynamic embedding model from OpenAI for implementation. The following examples are shown to demonstrate the power of embeddings to translate text to vectors meaningfully."}, {"title": "4.7.1. Word Embedding", "content": "To illustrate the concept of semantic similarity between words, we compared the word chair against three sets of words using their corresponding embeddings. These sets were selected based on human judgment to represent varying degrees of similarity:\n1. Set 1 (High Similarity): seat, sofa, bench\n2. Set 2 (Moderate Similarity): desk, table, cushion\n3. Set 3 (Low Similarity): light, monitor, fan"}, {"title": "", "content": "Embeddings for all these words were generated as 3072x1 dimensional vectors using the TE3 embedding model, as shown in Table 2.\nThe cosine similarity between these vectors was calculated using the formula given below.\n$$ \\text{cosine similarity} = \\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} = \\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}} $$"}, {"title": "", "content": "and subsequently normalized to form a similarity matrix. The resulting heat map of this matrix is depicted in Figure 3. The heat map clearly indicates that the word \"chair\" exhibits similarity scores in the range of 0.3 to 0.45 with the words in"}, {"title": "", "content": "Set 1 compared to 0. to 0.25 for Set 2 and 0 to 0.1 for Set 3. As seen, the similarity scores are highest for Set 1, moderate for Set 2, and lowest for Set 3. This aligns with human judgment and demonstrates the effectiveness of embeddings in capturing semantic similarity.\nTo further analyze the spatial relationships between these word embeddings, a Uniform Manifold Approximation and Projection (UMAP) was calculated for all the embeddings to reduce the dimensionality from 3072 to 2. The resulting scatter plot is shown in Figure 4. The scatter plot reveals that the embeddings of the words in Set 1 are positioned closer to the word \"chair\" than those in Set 2 and Set 3. This proximity indicates that the vectors for Set 1 words lie closer to the \"chair\" vector, followed by Set 2 and then Set 3.\nThese results conclusively demonstrate that embeddings effectively capture semantic similarity between linguistic terms. The analysis shows that words with higher semantic similarity to \"chair\" are represented by vectors that are closer in the high-dimensional space, validating the robustness of embeddings in representing semantic relationships in the natural language (English language in the current context)."}, {"title": "4.7.2. Sentence Embedding", "content": "To illustrate the concept of contextual similarity, we compared the sentence Sentence 0: \"The chair was designed with ergonomic features to ensure user comfort.\" against three other sentences using their corresponding embeddings. These sentences were selected to represent varying degrees of contextual similarity:\n1. Sentence 1 (High Similarity): \"The seat incorporates ergonomic principles to maximize comfort.\"\n2. Sentence 2 (Moderate Similarity): \"The desk was built to provide ample workspace and adjustable height.\"\n3. Sentence 3 (Low Similarity): \"The light uses LED technology to provide energy-efficient lighting.\""}, {"title": "", "content": "Embeddings for these sentences were generated as 3072x1 dimensional vectors using the TE3 embedding model, as shown in Table 3.\nThe normalized cosine similarity between these vectors was calculated as mentioned above. The resulting heat map of this matrix is depicted in Figure 5.\nThe heat map clearly indicates that the sentence \"The chair was designed with ergonomic features to ensure user comfort.\" exhibits a similarity score of 0.6 with the sentence in the high"}, {"title": "", "content": "similarity category compared to 0.3 in the moderate and 0.02 in the low similarity categories.\nThe scatter plot of UMAP, as shown in Figure 6, reveals that the embeddings of the sentences with high contextual similarity are positioned closer to the reference sentence. The sentences with moderate and low contextual similarity are progressively farther away.\nThese results conclusively demonstrate that sentence embeddings effectively capture contextual similarity between sentences. The analysis shows that sentences with higher contextual similarity to the original sentence are represented by vectors that are closer in the high-dimensional space, validating the robustness of embeddings in representing contextual relationships in the natural language (English language in the present context)."}, {"title": "5. Requirements for Idea Embedding", "content": "It is demonstrated above that embeddings reasonably capture the semantic and contextual aspects of a statement. However, it is required to establish their utility for aiding designers and the design process. It can be appreciated that the task of sifting through a large volume of ideas generated during the ideation phase is challenging even for experts to manually identify and select a few novel and diverse ideas for further development. Also, assessing the effectiveness of the idea-generation phase helps in producing fruitful and innovative solutions. Therefore, a robust and objective framework to assess the result of ideation activity would be useful. To achieve this, we aim to address the following research questions.\nSemantic Validity of Idea Embedding\nThe Idea Embeddings are nothing but vector embeddings generated by a CAI system for the idea statements. However, the validity of these embeddings needs to be established in the design community. The following two research questions are framed to address this.\nRQ1.1: Meaningfulness: is idea embedding semantically acceptable to the designers?\nIt is important to determine if these embeddings align with the designers' understanding and interpretation of the"}, {"title": "", "content": "ideas. By confirming the semantic validity to be in line with the designer's expert opinion, it can be ensured that the quantitative metrics applied to these vectors reflect meaningful dimensions of the idea space, thus facilitating a"}]}