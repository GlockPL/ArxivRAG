{"title": "GEC-RAG: Improving Generative Error Correction via Retrieval-Augmented Generation for Automatic Speech Recognition Systems", "authors": ["Amin Robatian", "Mohammad Hajipour", "Mohammad Reza Peyghan", "Fatemeh Rajabi", "Sajjad Amini", "Shahrokh Ghaemmaghami", "Iman Gholampour"], "abstract": "Automatic Speech Recognition (ASR) systems have demonstrated remarkable performance across various applications. However, limited data and the unique language features of specific domains, such as low-resource languages, significantly degrade their performance and lead to higher Word Error Rates (WER). In this study, we propose Generative Error Correction via Retrieval-Augmented Generation (GEC-RAG), a novel approach designed to improve ASR accuracy for low-resource domains, like Persian. Our approach treats the ASR system as a black-box, a common practice in cloud-based services, and proposes a Retrieval-Augmented Generation (RAG) approach within the In-Context Learning (ICL) scheme to enhance the quality of ASR predictions. By constructing a knowledge base that pairs ASR predictions (1-best and 5-best hypotheses) with their corresponding ground truths, GEC-RAG retrieves lexically similar examples to the ASR transcription using the Term Frequency-Inverse Document Frequency (TF-IDF) measure. This process provides relevant error patterns of the system alongside the ASR transcription to the Generative Large Language Model (LLM), enabling targeted corrections. Our results demonstrate that this strategy significantly reduces WER in Persian and highlights a potential for domain adaptation and low-resource scenarios. This research underscores the effectiveness of using RAG in enhancing ASR systems without requiring direct model modification or fine-tuning, making it adaptable to any domain by simply updating the transcription knowledge base with domain-specific data.", "sections": [{"title": "I. INTRODUCTION", "content": "Automatic Speech Recognition (ASR) systems are designed to transform speech signals into sequences of words, supporting applications such as text-based communication and device control [1]. In recent advancements, ASR technology has seen significant progress, transitioning from traditional Hidden Markov Model (HMM)-based frameworks [2] to cutting-edge end-to-end (E2E) models like wav2vec 2.0 [3] and Whisper [?], [4]. However, due to the lack of data in low-resource languages or specific domains, these systems face challenges and errors. The ongoing presence of ASR errors has increased the need to develop techniques for automatically detecting and correcting errors in ASR systems [1].\nGiven the limitations of paired data for training ASR systems, the use of Language Models (LMs) trained on datasets several orders of magnitude larger has been investigated to improve ASR performance [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]. These approaches are typically classified into two categories: language model fusion methods and Error Correction (EC) techniques as a post-processing step. In this paper, we focus on methods that treat the ASR system as a black-box, an approach that is particularly significant given the increasing use of cloud-based ASR services through APIs. Therefore, we will concentrate on EC methods, which offer a practical solution for improving ASR accuracy without requiring modifications to the core ASR system.\nThe study by Shin et al. [6] employs the BERT model to rescore N-best list hypotheses generated by ASR systems, significantly improving recognition accuracy through enhanced contextual understanding. Similarly, Guo et al. [7] propose a spelling correction model for end-to-end ASR systems, effectively addressing transcription and spelling errors as a post-processing step. Hrinchuk et al. [9] present a transformer-based sequence-to-sequence model for ASR error correction, demonstrating its ability to learn error patterns and generate refined transcriptions. Furthermore, Dutta et al. [13] showcase the effectiveness of BART in ASR error correction by utilizing diverse data augmentation techniques during fine-tuning, leading to significant WER reductions, with further improvements achieved through alignment and rescoring strategies. In addition, Ma et al. [15] introduce an N-best T5 model fine-tuned from a pre-trained T5 language model, which leverages ASR N-best lists to improve transcription accuracy. By transferring knowledge from the language model and extracting richer information from the ASR decoding space, this method outperforms a strong Conformer-Transducer baseline.\nRecent advancements in generative Large Language Models (LLMs) have introduced a transformative paradigm for Generative Error Correction (GER) in automatic speech recognition, aiming to predict accurate transcriptions from the decoded N-best hypotheses through the application of generative LLMs [16], [17], [18], [19], [20], [21], [22]. In the studies by"}, {"title": "II. METHODOLOGY", "content": "In this section, we describe the methodology of GEC-RAG, a novel approach designed to improve the accuracy of ASR systems by leveraging retrieval-augmented generation. The entire GEC-RAG process can be mathematically represented as:\n$t = G(A(v), R(A(v), \u039a))$\nWhere:\n\u2022 v: Represents the voice input, which is the raw audio containing spoken language.\n\u2022 A: The ASR system A processes the voice input v and generates an initial transcription. This transcription may contain errors due to various factors like noise, accents, or misrecognition.\n\u2022 K: The knowledge base, comprising a collection of preprocessed examples and their transcripts. This serves as a repository of reference materials for retrieval.\n\u2022 R: The retriever function, which identifies and retrieves passages from K that are relevant to the query A(v) lexically. It ensures that the retrieved samples align closely with the surface structure and intent of A(v).\n\u2022 G: The generator function, which takes the query \u0391(v) and the retrieved passages R(A(v), D) as inputs. It produces the corrected response t.\nThis mathematical representation encapsulates the core operations of GEC-RAG: retrieval and generation. By grounding the response t in surface-level data, the approach effectively enhances the accuracy and reliability of the final output.\nFigure 1 illustrates the workflow of GEC-RAG, which is composed of four main stages based on the methodology explained: 1) Speech-to-Text conversion, 2) Knowledge base creation, 3) Retrieval of lexically similar samples, and 4) Generating corrected answers. Below, we detail each step of the pipeline."}, {"title": "A. Speech-to-Text", "content": "The first step in our pipeline is the conversion of speech data into text. We apply an advanced ASR model to transcribe the audio data. This step is executed on all parts of the dataset, including training, development, and test sets. The initial transcriptions generated by the ASR model serve as the baseline for further error correction. To improve transcription"}, {"title": "B. Knowkedge Base", "content": "To enable the retrieval mechanism, we first create a knowledge base of vector representations for all ASR transcriptions in the training set. Each ASR transcription is processed into a TF-IDF vector. The purpose of using TF-IDF is to emphasize word-level features, which are crucial for addressing issues arising from lexical similarities rather than contextual meaning. This knowledge base serves as the foundation for identifying relevant examples during the retrieval phase."}, {"title": "C. Retrieval", "content": "To enhance the error correction process, we employ a retrieval mechanism based on TF-IDF and cosine similarity. For each ASR-transcript in the dev and test sets, we compute a TF-IDF vector representation and compare it against the TF-IDF vectors of all ASR-transcripts in the knowledge base using the cosine similarity metric. The top 5 most similar samples from the knowledge base are retrieved for each dev and test sample. These retrieved samples are then used as in-context examples for the few-shot prompting process."}, {"title": "D. Generation", "content": "In this section, the retrieved samples are used as few-shot examples to construct a prompt for a generative LLM. Each of the 5 selected samples from the training set appears in the prompt as a pair of ground-truth and ASR transcriptions for each sample in the development and test sets. This enables the generative LLM to leverage information from the training data to perform error correction on the target ASR transcription from the test set. The model generates a corrected version of the target text."}, {"title": "III. EXPERIMENTS", "content": "The proposed system leverages the multilingual Whisper-large-v3 ASR model alongside a RAG approach to significantly enhance ASR accuracy. The architecture comprises two primary components: the Whisper ASR model, which delivers robust multilingual speech-to-text conversion, and the RAG model, which enhances transcriptions through retrieval and generation. The Whisper model ensures broad applicability across diverse languages and accents, making it ideal for preprocessing. The RAG model features a TF-IDF-based retriever and a generator based on GPT-40. The retriever identifies lexically similar passages from a knowledge base, while the generator combines the ASR output with the retrieved passages to produce corrected transcriptions. Table I details the procedure in which we combine the retrieved information with ASR transcription(s) for error correction.\nFor experimental evaluation, the CommonVoice-v19 dataset [24] is used as a multilingual benchmark, known for its diverse accents and demographic representation. The training set of this dataset is preprocessed to create a knowledge base for the retriever, enabling it to identify lexically aligned examples. The validation set is utilized for prompt tuning and evaluating intermediate results. The test set is reserved for the final evaluation, where metrics such as Word Error Rate are computed to measure the system's overall performance. This setup combines a robust architecture and a comprehensive dataset to validate the system's effectiveness in real-world scenarios."}, {"title": "B. Results", "content": "This section presents the results of our experiments across three scenarios: 1) Focusing on the impact of language-specific text normalization, 2) The GEC-RAG scenario utilizing a knowledge base, and 3) Enlarging the knowledge base. These approaches are evaluated for their effectiveness in improving the Word Error Rate in Persian ASR systems.\n1) Impact of Normalization: In the first scenario, we examined the effect of language-specific normalization on Persian ASR, where significant improvements in Word Error Rate (WER) were observed. For normalization, we utilized the Hazm library, which addresses common text issues in Persian, including:\n\u2022 Correcting spacing and half-spacing errors,\n\u2022 Unifying various Unicode representations, and\n\u2022 Converting English numerals to their Persian equivalents. Furthermore, we developed a dictionary consisting of approximately 10,000 entries, capturing frequent typing errors and alternative word representations in Persian. This dictionary effectively mapped these variations to their correct forms, thereby enabling more accurate output analysis. The results, summarized in Table II, demonstrate that normalization led to a notable reduction in WER, with a decrease of approximately 43% on the development set and 55% on the test set. From now on, all results will be based on using normalization.\n2) The GEC-RAG Approach: In this scenario, we tested the GEC-RAG approach using a knowledge base consisting of the entire training data. The GEC-RAG approach improves ASR error correction by retrieving relevant examples from the knowledge base based on lexical similarity, using 1-best or 5-best ASR hypotheses to help identify and correct common errors. The results for this scenario are shown in Table III.\n3) Enlarging the knowledge base: In the third scenario, we enlarged the retriever's database by utilizing the full CommonVoice dataset. Specifically, we included all audio files from the \"Validated\" part of the dataset that are not part of the train, development, or test sets, applying a filter to select files with a downvote of 0 and an upvote of at least 2. This enlargement involved expanding the knowledge base by a factor of 10. The results are shown in Table IV.\nThis enlargement led to significant improvements, achieving a 67% error reduction compared to the ASR baseline and a 44% reduction compared to ASR with vanilla GPT on the development set. On the test set, the improvements were even more pronounced, with an 82% reduction compared to the ASR baseline and a 66% reduction compared to ASR with vanilla GPT."}, {"title": "IV. CONCLUSION", "content": "In this paper, we introduced GEC-RAG, a novel approach that integrates RAG with a generative LLM to enhance transcription accuracy, particularly for low-resource languages. We tested our pipeline on Persian, a low-resource language, and demonstrated its effectiveness in reducing ASR errors. The approach utilizes a TF-IDF-based retriever that emphasizes lexical similarity, enabling the system to address ASR errors resulting from phonetic and orthographic similarities. By retrieving lexically similar examples, the system provides relevant context to the generative language model, leading to more accurate corrections.\nAdditionally, through experimentation, we showed that enlarging the knowledge base improves the retriever's ability to offer relevant examples, which significantly enhances the overall effectiveness of the error correction process. This enlargement plays a crucial role in reducing the WER by providing more accurate corrections.\nGEC-RAG achieves up to an 82% reduction in WER compared to baseline models, showcasing its potential for low-resource language applications. These results validate the effectiveness of our method, and future work will explore its extension to domain-specific tasks and other linguistic contexts."}]}