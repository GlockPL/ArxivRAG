{"title": "Optimal bounds for dissatisfaction in perpetual voting", "authors": ["Alexander Kozachinskiy", "Alexander Shen", "Tomasz Steifer"], "abstract": "In perpetual voting, multiple decisions are made at different moments in time. Taking the history of previous decisions into account allows us to satisfy properties such as proportionality over periods of time. In this paper, we consider the following question: is there a perpetual approval voting method that guarantees that no voter is dissatisfied too many times? We identify a sufficient condition on voter behavior -which we call 'bounded conflicts' condition-under which a sublinear growth of dissatisfaction is possible. We provide a tight upper bound on the growth of dissatisfaction under bounded conflicts, using techniques from Kolmogorov complexity. We also observe that the approval voting with binary choices mimics the machine learning setting of prediction with expert advice. This allows us to present a voting method with sublinear guarantees on dissatisfaction under bounded conflicts, based on the standard techniques from prediction with expert advice.", "sections": [{"title": "Introduction", "content": "Imagine a group of friends who meet every week to go somewhere together. There are several options \u2013 going to the park, going to the cinema, and so on, but different people like only some of the options. For example, somebody says: \"I don't want to go to the park because it is spring and I have an allergy. And I don't want to go to the cinema because I don't like any of the movies that are currently showing\". Then the other friend says: \"I also don't want to go to the cinema, and I don't want to go to dances, because I broke my leg\". And so on, all friends indicate which option they approve and which disapprove. We have to choose one option for everybody to go there. People, not approving this option, will be dissatisfied.\nThis happens not once but a number of times and the preferences of friends might arbitrarily change (for instance, a person who did not want to go to the cinema now might want to see a new movie). When we make a decision, we assume that the preferences of friends in the future are not known to us we only see what they approve this week and what they wanted in previous weeks.\nThis setting has been recently introduced by Lackner (2020) under the name perpetual voting. The goal here is to devise a voting method that would lead to \"fair\" results. For instance, what would be fair in the following situation: 8 friends meet each weekend to go for dinner, but there are just 2 places, and 5 friends want to go to a pizza place and 3 to a curry place (never changing their preferences and approving just one of the options)? It is natural to say that we have to choose the pizza place roughly 5/8 fraction of times, proportionally to the number of people, wanting it.\nUsing simple majority vote is not a good idea here, it will choose the pizza place all the time. Lackner gives an example of the algorithm that will work better: each time, define the weight of a person as 1/(1 + s), where s is the number of times this person was satisfied, and choose the place with a bigger sum of the weights of people that want it. One can show that out of every 8 times, 5 times it will choose the pizza place and 3 times the curry place.\nMore generally, Lackner introduced simple proportionality, which is fairness in the following sense: in a situation when preferences do not change, and everybody approves just one option, every option has to be chosen the number of times which is proportional to the number of people, approving this option. Lackner and Maly (2023) studied simple proportionality for two classes of voting methods called loss-based WAMs and win-based WAMs (WAM = weighted approval method). A loss-based WAM is a voting method where every person gets a positive weight, which is a function of the number of times this person was dissatisfied, and then the option with the biggest total weight is chosen. A win-base WAM is the same thing, but the weight of a person is determined by the number of times this person was satisfied. Lackner and Maly show that there is no simply proportional loss-based WAM, and they characterize all win-based WAMs.\nExtending simple proportionality to a setting when agents might approve more than one option, and, moreover, might change their preferences over time, is a delicate task (Bulteau et al. 2021), and a recent work of Chandak, Goel, and Peters (2024) gives an excellent overview of this topic. Besides proportionality, Lackner (2020) have formalized and studied other notions of fairness like the independence of uncontroversial decisions (rounds of voting where there is an option, satisfying everyone, should not affect the other rounds) and dry spells (how many times a person can be dissatisfied in a row)."}, {"title": "Our contribution.", "content": "In this paper, we introduce a different kind of question, namely:\nQuestion: Is there a voting method that guarantees that each voter is dissatisfied only a small number of times?\nIn other words, we want to have a perpetual voting method that allows us to minimize dissatisfaction of every voter.\nHere, the dissatisfaction is measured as the number of decisions in which the outcome is not approved by the voter. Elkind, Neoh, and Teh (2024) studied this question in the offline regime, and showed that it is NP-hard to find an optimal way to minimize the dissatisfaction of every voter. Lackner (2020) considered a related notion of dry spells of a voter v, that is, sequences of consecutive decisions, during which v is always dissatisfied, and exemplified some methods which guarantee a uniform bound on the length of a dry spell. Our interest is in a somewhat harder task-we want to guarantee that each voter is satisfied often, instead of just asking for each voter to be satisfied at least once in a while.\nIn the general setting, we face obstacles very quickly. Imagine a scenario where there are two people, one of whom approves only pizza and the other approves only curry all the time. One of them will be unhappy half the time. If we want a strategy whose guaranteed dissatisfaction for everyone is sublinear in the number of decisions, we have to do something about this.\nFor that, we introduce a parameter called the conflict number. In the case of two alternatives, this parameter can be defined as the maximal number of times a pair of agents does not have a commonly approved option. In the general case, we have to consider the same thing for all subgroups of agents, not exceeding the size of the number of alternatives. As we just saw, when the conflict number is not bounded by something sublinear in the number of decisions, strategy with the sublinear dissatisfaction is impossible. Surprisingly, we show the converse: if the conflict number is bounded by something sublinear, there is a strategy with sublinear dissatisfaction (ignoring factors that are logarithmic in the number of agents). For that, we introduce a perpetual voting rule, motivated by a standard machine learning method, the Exponential Weights Algorithm.\nWe then study the minimal achievable dissatisfaction in a regime when the conflict number is bounded by something negligible compared to the number of decisions. We derive the optimal bound, which, however, we do not know if one can reach with the Exponential Weights Algorithm or any other computationally efficient strategy. This is because our proof method is non-constructive, relying on inequalities for Kolmogorov complexity.\nFinally, we discuss a class of simpler algorithms, containing some of the previously studied voting rules (Simple Majority and Perpetual Equality (Lackner 2020)), and show that they fail to guarantee sublinear dissatisfaction, even under the bounded conflicts condition."}, {"title": "Formal setting and contributions", "content": "Following (Lackner 2020), by perpetual voting with k options, N agents, and T rounds, we mean the following game, played between two players that we will call the Decision Maker and the Adversary in rounds r = 1, . . ., T, where in the r-th round:\n\u2022 the Adversary picks N sets $S_i^{(r)}, ..., S_N^{(r)} \\subseteq \\{1,...,k\\}$, where $S_i^{(r)}$ is understood as the set of options, approved by the i-th agent in the r-th round;\n\u2022 the Decision Maker picks an option $\\theta^{(r)} \\in \\{1, ...,k\\}$.\nWe note that this setting does not assume that the set of alternatives is the same at each round. We only denote by k the maximal number of options in one round (and it can be less than k in other rounds) and arbitrarily index these alternatives by numbers from 1 to k in each round, while at different rounds these can be essentially different alternatives (like choosing a restaurant to go to one day and a park to go to the other day)\nFor any play of this game, we define the dissatisfaction of the i-th agent in this play as the number of rounds where the option, chosen by the algorithm, was not approved by this agent:\n$D_i = \\mathbb{I}\\{\\theta^{(1)} \\notin S_i^{(1)}\\} + ... + \\mathbb{I}\\{\\theta^{(T)} \\notin S_i^{(T)}\\}, i = 1, ..., N$.\nIn this paper, we initiate the study of strategies for the Decision Maker that aim to guarantee low dissatisfaction for all agents, i.e., to minimize $max_i D_i$. If the Adversary is unrestricted, it can simply choose all sets to be empty every round, making every agent dissatisfied every time. Therefore, it makes sense to put some restrictions on the Adversary. In what follows, we exactly identify structural restrictions on the game under which a strategy of the Decision Maker with o(T) dissatisfaction exists. Here the number of options is assumed to be a constant k = O(1).\nTo this end, we introduce the concept of a conflict. More specifically, we say that a subset $A \\subseteq \\{1, 2, ..., N\\}$ is in a conflict in the r-th round if there exists no $\\theta \\in \\{1,2,..., k\\}$ such that $\\theta \\in S_i^{(r)}$ for every i \u2208 A (no option satisfies every agent in the subset A). Given some play in the perpetual voting with k options, we define its conflict number as the maximum, over all $S \\subseteq \\{1, 2, ..., N\\}$ with |S| \u2264 k, of the number of rounds S is in a conflict.\nWe start with an observation that as long as $N \\geq k$, there is no strategy of the Decision Maker in the C-conflict perpetual voting, guaranteeing less than C/k dissatisfaction. Namely, assume that for the first C rounds, the Adversary makes everybody approve everything, except that for j = 1,...,k, the j-th agent disapproves the j-th option. After C rounds, everybody approves everything without exceptions. In each of the first C rounds, one of the first k agents is dissatisfied, making one of these agents dissatisfied at least C/k times. On the other hand, the C-conflict condition is trivially fulfilled as only in the first C rounds somebody disapproves something.\nThis observation implies that when the conflict bound C is linear in T, then for constant k no strategy of the Decision Maker can guarantee o(T) dissatisfaction for everybody. We show that, up to the poly(ln N, ln C')-factor, the converse is also true \u2013 if C = o(T), then there is a strategy of the Decision Maker, guaranteeing the o(T) dissatisfaction."}, {"title": "Theorem 1.", "content": "For every k there exists a constant W > 0 that for every N,T,C there exists a strategy in the C-conflict perpetual voting with k options, N agents, and T rounds that guarantees dissatisfaction at most $T^{1-1/k}.C^{1/k}. (ln N. In C)^W$.\nIndeed, for k = O(1) and C = o(T), ignoring the poly(ln N, ln C)-factor, this upper bound becomes $T^{1-(o(T))} = o(T)$.\nRemark 1. One can get rid of the assumption that C and T are known. Namely, assume first that T is known but C is not. We start running the algorithm assuming C = 1. If the maximal dissatisfaction exceeds the upper bound for C = 1, we start again with C = 2. We continue in this way, increasing C by a factor of 2 with each reset. The total maximal dissatisfaction is now an exponential series, with the last term being equal to the whole sum, up to a constant factor. In the algorithm, we can never make our estimate of C twice times bigger than the real one, meaning that the last term is bounded, up to a constant factor, by the same expression. In the same way, one can get rid of the knowledge of T.\nWhen C is negligible compared to T, the dissatisfaction bound becomes of order $T^{1-\\frac{1}{k}}$. We show that this dependence on T is tight, even for C = 1, and with the number of agents N growing as $T^{1/k}$ so that In N is also negligible."}, {"title": "Proposition 1.", "content": "For every k and M, for N = k \u00b7 M there exists no strategy that for the 1-conflict perpetual voting with k options, N agents and $T = M^k$ rounds that guarantees dissatisfaction less than $M^{k-1/k} = T^{(k-1)/k}/k$.\nProof. Consider a strategy of the Adversary where it divides N = kM agents into k equal groups of size M. In each round, for every $i = 1, . . ., k$, in the i-th group there will be one agent, approving everything except the i-th option, and all the other agents of the group approve everything. There will be $T = M^k$ rounds, corresponding to the number of ways to choose one agent per group.\nTo be in a conflict, a subset A with at most k agents has to have one agent from every group (if there is nobody from the i-th group, the i-th option will satisfy everybody in S). That is, there are exactly $T^k$ subsets S that can be in a conflict, corresponding to all ways to choose one agent per group. For such S to be in a conflict in the r-th round, for every $i = 1,..., k$, the agent of the i-th group from S has to disapprove the i-th option in the r-th round. By construction, for every S there exists only one r with this property. Thus, the Adversary fulfills the 1-conflict condition.\nWe now show that regardless of the choices of the Decision Maker, there will be an agent, dissatisfied at least $M^{k-1/k}$ times. Let \u03b8 \u2208 {1,...,k} be the most frequent option, chosen by the Decision Maker. It appears in at least $M^k/k$ rounds. On the other hand, every round involves exactly one agent from the 0-th group, with $M^{k-1}$ rounds for each of M agents of this group (corresponding to $M^{k-1}$ choices of agents from other groups). In one of this $M^{k-1}$-size groups of rounds, in at least (1/k)-fraction of rounds the option \u03b8 was elected, because at least this fraction of rounds in total has \u03b8. The agent of 0-th group that appears in this group of rounds will therefore be dissatisfied at least $M^{k-1/k}$ rounds, as required."}, {"title": "", "content": "Our proof of Theorem 1 uses the Kolmogorov complexity technique which does not yield an efficient strategy achieving this bound. Given k, N, T, C, this strategy can be found by a brute-force algorithm, solving the game by analysing all its positions but it requires exponential time and space.\nWe also give a bound, which has worse dependence on T, but is attained by an explicit voting rule, inspired by the Exponential Weights Algorithm of (Vovk 1990; Littlestone and Warmuth 1994). In this rule, every agent gets a weight that is multiplied by a fixed factor each time this agent is dissatisfied, and the rule is to choose an option that minimally increases the sum of the weights.\nTheorem 2. For any k, N, T, C, there is a strategy of the Decision Maker, guaranteeing that all agents are dissatisfied at most:\n$O\\left(T^{1-\\frac{1}{k+1}} \\cdot (C\\cdot k \\cdot ln N)^{\\frac{1}{k+1}}\\right)$\ntimes in the C-conflict perpetual voting with k options, N agents and T rounds.\nAdditionally, compared to Theorem 1, this bound does not have an additional polynomial dependence on In C, and has an explicit small exponent for In N.\nWe conclude the paper by analyzing some simpler voting rules and showing that they cannot lead to an o(T) dissatisfaction, even for k = 2, C = 1, and N = O(T), when In N is much smaller than the number of rounds. First, we demonstrate this for the simple majority vote, called Approval Vote in (Lackner 2020), where in each round an option with the most approvals is chosen, regardless of the previous history. Second, we show this for the rule called Perpetual Equality in (Lackner 2020), which is the majority vote but over agents with maximal dissatisfaction (it can also be seen as the Exponential Weights Algorithm with a very large factor). In fact, we show this for any compassionate strategy of the Decision Maker, which means the following property if there is a single agent with maximal dissatisfaction approving at least one option, the strategy makes this agent satisfied (i.e., chooses an option approved by them).\nTheorem 3. For any T, the Approval Vote cannot guarantee dissatisfaction less than T in the 1-conflict perpetual voting with 2 options, N = 2T + 1 agents, and T rounds.\nLikewise, for any T, no compassionate strategy (including Perpetual Equality) can guarantee dissatisfaction less than [T/2] in the 1-conflict perpetual voting with 2 options, N = T agents, and T rounds.\nNext three section contain proofs of Theorems 2, 1, and 3, respectively."}, {"title": "Proof of Theorem 2", "content": "Our strategy is as follows. Fixing\n$\\varepsilon = \\frac{ln N}{T})^{\\frac{k}{k+1}}\\cdot \\frac{C \\cdot k}{T})^{\\frac{1}{k+1}}$\n, the strategy works by assigning a weight to every agent, initially 1 for everybody, that is multiplied by (1+\u03b5) each time an agent is dissatisfied. The strategy chooses the option that minimally increases the sum of the weights, breaking ties arbitrarily.\nWe assume that $C T$. Hence, $\\frac{ln N}{T} < \\frac{\\varepsilon k}{C k}$, meaning that $ln N N + ... + C(\\Pi|x_k) + C(\\Pi) \\leq k \\cdot C(\\Pi) + i(\\Pi)$.\nBy (6), it suffices to prove $C(\\Pi|x_1) + ... + C(\\Pi|x_k) + C(\\Pi) \\leq k \\cdot C(\\Pi) + C(\\Pi|x_1,...x_k)$. The last inequality, by definition of the mutual information, is equivalent to:\n$C(\\Pi) \\leq I(\\Pi : x_1) + ... + I(\\Pi : x_k) + C(\\Pi|x_1,...x_k)$.\nRe-writing each mutual information in the other way, we get:\n$C(\\Pi) + C(x_1|\\Pi) + ... + C(x_k|\\Pi)$\n$\\\nBy (7), it is equivalent to:\n$C(\\Pi) + C(x_1,...,x_k|\\Pi)$\n... + C(x_k) + C(\\Pi|x_1,...x_k)$\nThe left-hand side, by the chain rule, is equal to $C(x_1,..., x'_k, \\Pi)$. Therefore, we have reduced everything to the following inequality:\n$C(x_1,...,x'_k, \\Pi) \\leq C(x_1)+...+C(x_k)+C(\\Pi|x_1,...x_k)$.\nIt holds because optimal descriptions of $x_1,..., x'_k$, followed by an optimal description of $\\Pi$ given $x_1,...,x'_k$, with an O(log(i(I) + n))-precision to indicate lengths of these descriptions, can be turned into a description for the whole tuple $x_1,...,x'_k, \\Pi$.\nWe now derive Theorem 1 from this inequality. For the proof, it will be convenient to extend the notion of a conflict from subsets of agents to k-tuples of agents. Namely, we say that an ordered k-tuple $(a_1, . . .,a_k) \\in \\{1,...,N\\}^k$ is in the conflict in the r-th round if for every $i \\in \\{1,...,k\\}$, the agent $a_i$ disapproves the i-th option in the r-th round. The tuple conflict number of a play is the maximum, over all $(\u03b1_1,..., \u03b1\u03ba) \u2208 \\{1, . . ., N }^k$, of the number of rounds the tuple (a1,..., ak) was in the conflict. By the tuple C-conflict perpetual voting we mean a modification of the game where the Adversary has to keep the tuple conflict number of the play at most C.\nLemma 1. The tuple conflict number of any play is upper bounded by the conflict number of the play."}, {"title": "", "content": "Proof. At any round a tuple (a1, ..., ak) is in the conflict, the set {a1,..., ak} is also in the conflict.\nLemma 1 implies that a strategy of decision maker, guaranteeing maximal dissatifaction at most D in tuple C-conflict perpertual voting, also guarantees dissatifaction at most D in the (subset) C-conflict perpetual voting. Hence, it is enough to establish Theorem 1 for the tuple C-conflict perpetual voting.\nWe treat k as a fixed constant. Therefore, all constants in the O(1)-notation below might depend on k, but not on anything else. Next, we observe that it is enough to show the theorem when N, T, and C are powers of 2. Indeed, to show the bound for arbitrary N, T, C, we use the strategy for the smallest powers of 2, exceeding these numbers. This leads to some constant increase in the bound on the dissatisfaction that can be compensated by increasing W.\nNow, for a given n,t, c, our goal is to derive an upper bound on Dn,t,c which is the minimal D such that there is a strategy of Decision Maker, guaranteeing dissatisfaction at most D in the tuple C = 2c-conflict perpetual voting with k options, N = 2n agents, and T = 2t rounds.\nWe define an auxiliary algorithm Alg(n, t, c) that on input (n, t, c) works as follows. First, it computes D = Dn,t,c. It is doable because we simply have to solve a finite perfect-information game, completely given by n, t, c. Because of the determinacy of such games, there also exists a strategy of the Adversary proving the minimality of Dn,t,c, meaning that it guarantees that in any play there will be a Dn,t,c-dissatisfied agent in the perpetual voting with these parameters. The algorithm Alg(n, t, c) finds this strategy of the Adversary.\nThen the algorithm converts this strategy into a strategy of Adversary for the game with the same number of rounds T, with the same conflict bound C, also guaranteeing Dn,t,c-dissatisfaction, but with \u00d1 agents, where \u00d1 is the smallest power of 2 which is at least N+kT. We increase the number of players because we want this strategy of the Adversary to be tuple injective, by which we mean that it never has the same set of tuples in a conflict in two different rounds. This can be achieved by using additional kT 'dummy' agents. Let us numerate these agents by $a_{ri}$ for r = 1,...,T, i = 1,...,k. The agent $a_{ri}$ disapproves the i-th option in the r-th round, and apart from that, this agent approves everything every time. This does not increase the tuple conflict number of any play. Indeed, take any tuple that includes a new agent $a_{rj}$ on the j-th position. This tuple can be in the conflict only once, in the i-th round, and only if i = j. Likewise, the strategy still guarantees Dn,t,c-dissatisfaction by for the initial agents. On the other hand, the r-th round is the only round in which the tuple $(a_1, . . .,a_k)$ is in the conflict, which implies tuple injectivity.\nThe algorithm takes the maximal l such that $2^l < D_{n,t,c}$. Then the algorithm simulates a play against this injective strategy of the Adversary in the game with \u00d1 agents according to the following counter-strategy (identifying agents with binary strings of length n = log2 N). In the r-th round, for \u03b8\u2208 {1,...,k}, let $S_{\\theta} \\subseteq \\{0,1\\}^n$ be the set of agents disapproving the \u03b8-th option. Define $\\Pi^r = S_1 \\times ... \\times S_k$.\nNote that $\\Pi^r$ is exactly the set of k-tuples in a conflict in this round. If $\\Pi^r$ is empty, meaning that $S_{\\theta}$ is empty for some \u03b8\u2208 {1,..., k}, we choose the option \u03b8, thus making all agents satisfied. Otherwise, we start obtaining better and better upper bounds on the conditional Kolmogorov complexity by running the optimal decompression on all inputs. If for some 0 \u2208 {1, ..., k} we find out that C(\u03a0|\u0445\u04e9) < l for every agent xe \u2208 S, we choose the option \u03b8 and the game continues, unless this was already the last round. If it never finds such \u03b8, the algorithm goes into an infinite loop without finishing.\nLet us start by observing that the algorithm Alg(n, t, c) cannot terminate all T rounds of the game. This is because the strategy of the Decision Maker that it uses guarantees that every agent is dissatisfied at most $2^l < D_{n,t,c}$ times. Indeed, each time an agent x \u2208 {0,1}n was dissatisfied, it is because of some non-empty $I^r$ with C(\u03a0|x) < l. There are at most $2^l$ such $\\Pi^r$, and each can appear in at most one round due to tuple injectivity.\nHence, there exists r\u2208 {1,..., T} such that the algorithm never halts when processing $\\Pi^r$. This means that for every option \u03b8\u2208 {1,2,...,k} there is an agent x \u2208 S with C(\u03a0 \u0445\u04e9) \u2265 l (otherwise we would eventually have found all optimal upper bounds on the conditional Kolmogorov complexity for some option 8). By Proposition 2, we obtain that:\nkl \u2264 (k \u2212 1) C(\u03a0\") + \u0456(\u03a0\") + O(log(i(\u03a0", "\u03a0": "As r < T = 2t, we need t+O(log(ntc)) bits for that, obtaining the upper bound C(\u041f", "i(\u03a0": ".", "II": "mong all these sets of k-tuples that contain our tuple, in the same order in which these sets appear during the work of Alg(n, t, c). This gives an upper bound i(Ir) {r=1}\nWith the upper bound we've shown, this reduces to proving that for an agent $e_{\\epsilon}(t)$, $\\epsilon \\in \\{0,1\\}$, approving only $t$ we have $|disagreement(e_{\\epsilon}(t))| \\geq T$, where $|disagreement(e_{\\epsilon}(t))|$ is the number of times that agent $e_{\\epsilon}(t)$ disagreed to which of the options was chosen by the algorithm. Since, in the end, the algorithm choose an option that minimized regret, each time, the agent $e_{\\epsilon}$ disagreed with the chosen option, we have $|disagreement(e_{\\epsilon}(t))| \\geq T$. In the other hand, we can see that $|disagreement(e_{\\epsilon}(t))| \\leq T$, for all $t \\in \\{1,...,T\\}$. Thus, we conclude that our upper bound is tight. Thus, that our strategy is optimal."}]}