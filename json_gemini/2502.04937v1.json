{"title": "Data-driven Modality Fusion: An AI-enabled Framework for Large-Scale Sensor Network Management", "authors": ["Hrishikesh Dutta", "Roberto Minerva", "Maira Alvi", "Noel Crespi"], "abstract": "The development and operation of smart cities rely heavily on large-scale Internet-of-Things (IoT) networks and sensor infrastructures that continuously monitor various aspects of urban environments. These networks generate vast amounts of data, posing challenges related to bandwidth usage, energy consumption, and system scalability. This paper introduces a novel sensing paradigm called Data-driven Modality Fusion (DMF), designed to enhance the efficiency of smart city IoT network management. By leveraging correlations between time-series data from different sensing modalities, the proposed DMF approach reduces the number of physical sensors required for monitoring, thereby minimizing energy expenditure, communication bandwidth, and overall deployment costs. The framework relocates computational complexity from the edge devices to the core, ensuring that resource-constrained IoT devices are not burdened with intensive processing tasks. DMF is validated using data from a real-world IoT deployment in Madrid, demonstrating the effectiveness of the proposed system in accurately estimating traffic, environmental, and pollution metrics from a reduced set of sensors. The proposed solution offers a scalable, efficient mechanism for managing urban IoT networks, while addressing issues of sensor failure and privacy concerns.", "sections": [{"title": "I. INTRODUCTION", "content": "The Internet of Things (IoT) and sensor networks are critical components in the design and operation of smart cities. These systems enable real-time monitoring, data collection, and dy-namic management of urban environments. Sensors distributed across a city, such as those monitoring traffic flow, air quality, energy consumption, waste management, and public safety, generate vast amounts of data that inform the operation and well-being of the urban ecosystem. IoT infrastructure connects these sensors, facilitating seamless communication and data integration across city services like transportation, emergency response, and environmental management. These IoT-based smart city solutions enhance sustainability by optimizing re-source usage, reducing energy consumption, and improving waste management practices, thus driving cities toward more efficient, responsive, and sustainable operations.\nThe efficient operation of smart cities requires extensive networks of IoT devices collecting data from various sensing modalities. For example, Madrid's traffic-monitoring infras-tructure includes over 7,000 sensors deployed at more than 4,000 locations, generating around 145 million data points. Similar networks manage other modalities like pollution levels, meteorological conditions, noise pollution, and energy usage. Managing this large-scale data ecosystem poses several chal-lenges. First, scalable approaches are required for efficient storage, processing, and transmission of the massive data volumes generated. Communication resources, particularly bandwidth for data transmission to cloud-based systems, are also a concern. In addition, the energy expenditure of resource-constrained IoT devices leads to increased carbon footprints, contrary to the sustainability goals of smart city initiatives. Finally, sensor network maintenance is costly, and solutions must address sensor failures effectively.\nPrevious research [1]-[8] has addressed data handling in sensor networks, focusing on communication bandwidth and energy optimization. Techniques like Singular Value Decom-position (SVD), Principal Component Analysis (PCA), and machine learning methods such as autoencoders have been applied for data compression, but these often require compu-tational resources that far exceed the capabilities of resource-constrained IoT devices. These methods impose significant energy and processing burdens on sensor nodes and primarily address data management without offering scalable solutions for managing large sensor networks. The concept of synthetic sensing, as proposed in [9], [10], reduces isolated sensing modalities in smart home systems by leveraging a small number of sensors to infer secondary events. However, these systems still require considerable on-device computation and lack the granularity needed for real-time urban-scale applica-tions.\nThis paper introduces a novel approach, Data-driven Modal-ity Fusion (DMF), to address these challenges. By exploiting correlations between time-series data across multiple sensing modalities, the proposed framework enables high-granularity real-time estimation of various sensing parameters such as traffic intensity, temperature, humidity, and noise levels\u2014from a reduced set of pollution sensor data. The DMF approach shifts the computational burden away from edge devices to the core, thus reducing energy consumption, bandwidth usage, and deployment costs. This method also enhances sensor network robustness by enabling data recovery in case of sensor failure. Importantly, the framework avoids reliance on video or audio data, thereby mitigating privacy concerns. The effectiveness of"}, {"title": "II. RELATED WORK", "content": "There are existing research works that address data handling in sensor networks, primarily from the standpoint of manag-ing communication bandwidth costs and minimizing sensing energy expenditure. Several approaches have been proposed in the literature, focusing on data compression techniques. As outlined in [11], these methods can be divided into two primary categories: local data compression and distributed data compression. In distributed data compression [1]-[4], data from multiple neighboring sensor nodes is aggregated to remove redundant information before transmission. This aggregation typically occurs at a central base station or a cluster head within the network. For this to be effective, spatial correlations must exist in the data collected by multiple sensor nodes. However, this assumption is not always valid for certain applications. In contrast, local data compression techniques rely on temporal correlations within individual sensor nodes to reduce the amount of data that needs to be transmitted [12], [13]. The work in [14] introduced a compression technique that utilizes both spatial and temporal correlations in sensor data. These methods compress the data at the sensor nodes, either in a lossless or lossy manner. Lossless compression methods, such as Huffman coding, run-length encoding, and other statistical techniques, have been developed in [15]\u2013[17]. Lossy compression techniques, including Bayesian Predictive Coding and piecewise linear approximation, have been proposed in [18], [19], but they often suffer from irreversible data loss while also imposing a computational burden on sensor nodes.\nAdditionally, several research efforts focus on leveraging machine learning for data compression in resource-constrained sensor and IoT networks, aimed at improving energy effi-ciency. A much-explored methodology in these works is to encode or compress time-series data into relevant features, which are then transmitted to the cloud for further anal-ysis. Common dimensionality reduction techniques such as Principal Component Analysis (PCA) [5], [6], [20], Singular Value Decomposition (SVD) [7], [8], and Linear Discriminant Analysis (LDA) [21] have been widely adopted for compres-sive sensing in wireless environments. In these methods, the optimal number of components to retain is determined by factors specific to the application, which adds complexity. Furthermore, these techniques require storing the original data matrix, presenting challenges for sensor nodes with limited memory and computational power. Other machine learning-based compression techniques, including autoencoders [22], [23] and reinforcement learning [24], have also been explored. Downstream task-driven semantic communication techniques [25], [26] have also been applied to wireless networks as a novel data compression strategy.\nThe concept of Synthetic Sensing and General Purpose Sensing, as proposed in [9], [10], [27], offers an alternative approach by reducing the number of sensing modalities re-quired for a smart home IoT system. This approach involves deploying a small number of sensors on a single Printed Circuit Board (PCB), capable of generating machine learning features to monitor multiple secondary events. In [9], the authors demonstrate how a single complex sensor can indi-rectly monitor a large context, without direct instrumentation of objects. The paper also demonstrates the system's ability to virtualize raw sensor data into actionable feeds, whilst simultaneously lowering immediate privacy issues. Similarly, in paper [10], the authors explore the feasibility of sensing hand activities from commodity smartwatches. The work pre-sented in [27] develops an approach to sense activities in a room using long-range laser vibrometry as an alternative to using sensing units relying camera or microphone. While this approach of synthetic/general-purpose sensing simplifies sensor deployment and reduces privacy issues, it still requires significant processing complexity at the sensor nodes. Further-more, it does not support the fine-grained real-time estimation of multiple modalities that is often needed in smart city IoT networks, which demand more dynamic and scalable solutions.\nHowever, in most of these approaches, the data processing required for compression takes place at the sensor nodes. This introduces significant challenges for resource-constrained IoT devices that lack the necessary hardware support, such as processing and storage capabilities, to execute computationally intensive learning algorithms. For instance, in the context of smart city IoT networks, where a large number of sensors are deployed, executing complex machine learning algorithms at the sensor nodes can lead to significant energy consumption,"}, {"title": "III. SYSTEM MODEL", "content": "In this work, we consider the IoT network deployed in the smart city of Madrid as the testbed for demonstrating the proposed concept of Data-driven Modality Fusion (DMF). As shown in Fig. 1, the city of Madrid has numerous sensors and IoT devices spread across the city for an efficient urban management assistance. There are sensors gathering spatio-temporal data for different modalities, such as, traffic intensity, air quality, noise pollution, meteorological data, such as, tem-perature, humidity, solar radiation, wind speed and direction, building energy consumption, to name a few. These sensors collect data at different sampling rate as per the application requirement, for example, traffic intensity data is updated every 15 minutes in real time, air quality and meteorological data is sampled at an hourly basis, while noise pollution level is recorded on a daily basis.\nDifferent state-of-the-art sensing techniques are employed for data collection. The most common technique used for traffic monitoring is by deploying magnetic loops embedded underneath the roads that detect the presence of vehicles by measuring changes in inductance as a car passes over the loop [28]. In addition, there are several high-definition cameras, which are used for real-time vehicle classification and detection using image/video processing and AI techniques. There are Doppler radar and LIDAR sensors, as well, that are used for vehicle speed detection and tracking. This data enables the calculation of critical road usage metrics, including traffic flow, occupancy, load, level of service, and speed, which are essential for various traffic management applica-tions. Similarly, the meteorological stations measure different environmental parameters using thermometers, anemometers, barometers, hygrometers, rain gauges and other specialized sensors deployed across the city. Madrid air quality system maintains 24 monitoring stations in the metropolitan area that measures the concentration of different particulate matter, such as, PM2.5, PM10, and other pollutant gases, includ-ing CO2, NOx, SO2, O3. The concentration of Ozone (O3) is measured with ultraviolet absorption at 253.7 nm, nitro-gen oxides using chemiluminescence analyzers, and PM10 concentration is detected with a heated tapered oscillating microbalance (TEOM) [29]. An array of highly sensitive microphones deployed throughout the city is used to detect noise levels in decibels (dB) [30]. Several frequency analyzers are used to detect specific frequencies of noise to classify types of noise pollution (traffic, industrial, etc.).\nAs for the IoT network, roadside devices, in general, trans-mit traffic data wirelessly to central nodes. Long-range, low-power networks, such as LPWAN (LoRa, NB-IoT), are com-monly used to transmit traffic data to centralized servers in ur-ban environments. WiFi and cellular networks (GPRS/4G/5G) facilitate real-time data upload for central processing and analytics. For remote or less accessible areas, meteorological data is sometimes collected via satellite and transferred to local or central servers. Centralized IoT platforms like FiWare or proprietary smart city dashboards are used to collect, process, and analyze the data in real time. Many smart cities, including Madrid, rely on cloud platforms for large-scale data storage, processing, and analytics. Open Data APIs are provided for public access, allowing users to query and integrate the data into applications or perform real-time analysis.\nThe data collected across different sensing modalities, using the system architecture mentioned above, are then uploaded continuously to the cloud in real time. Sensing, processing, storing and uploading of such a huge amount of data consume a lot of networking resources, specifically, bandwidth, energy, memory, carbon footprint etc. In this paper, we develop a Data-driven Modality Fusion framework that allows reduction in the number of sensing modalities, without additional computation at the resource-constrained sensor nodes and yet ensuring the presence of all the high-granular information content. This is accomplished by leveraging the inherent correlation that exists among the data across various sensing modalities which is explained next in section IV."}, {"title": "IV. CORRELATION AMONG SENSING MODALITIES", "content": "The proposed framework of Data-driven Modality Fusion (DMF) is based on the inter-dependency that exists among different sensing modalities. In the context of smart city IoT networks, the sensing modalities that we consider are time series of traffic intensity, meteorological data, noise levels, air quality and pollutant concentrations. In order to analyze the inter-dependency among these modalities, we consider two measures for correlation coefficients, viz, the standard Pearson Correlation Coefficient [31] and Spearman's Rank Correlation [32]. While Pearson's correlation coefficient (denoted as r) measures the strength and direction of a linear relationship between two variables, while, Spearman's rank correlation coefficient (\u03c1) is a non-parametric measure of the strength and direction of association between two ranked variables. It assesses how well the relationship between two variables can be described by a monotonic function, without assuming a linear relationship or normal distribution of the data. The expressions for computing Pearson's and Spearman's rank correlation coefficients between two vectors {x} and {y}, with corresponding sample means of \\(\\overline{x}\\) and \\(\\overline{y}\\) are given in Eqns. 1 and 2, respectively, where di is the difference between the ranks of {x} and {y}.\n\\(r=\\frac{\\sum_{i=1}^{n}(x_{i}-\\overline{x})(y_{i}-\\overline{y})}{\\sqrt{\\sum_{i=1}^{n}(x_{i}-\\overline{x})^{2}\\sum_{i=1}^{n}(y_{i}-\\overline{y})^{2}}}\\) (1)\n\\(\u03c1 = 1 - \\frac{6 \\sum_{i=1}^{n} d_{i}^{2}}{n(n^{2} - 1)}\\) (2)\nThe correlation coefficients computed among the different sensing modalities, in the context of smart city IoT, are reported in Tables I and II respectively. Specifically, we com-pute Pearson's and Spearman's rank correlation coefficients of measured pollutant concentration levels with traffic intensity, noise levels and meteorological information for an entire year."}, {"title": "V. DATA-DRIVEN MODALITY FUSION", "content": "Building on the existing inter-dependency among different sensing modalities, we propose the Data-driven Modality Fusion (DMF) that allows estimation of all other sensing modalities solely from the data collected using the pollutant concentration measuring sensors. The high-level representation of the DMF framework is presented in Fig. 3. Following are the main architectural changes in the proposed system as compared to the traditional approach in Fig. 1. On the IoT network side, the sensors for measuring traffic intensity, noise levels, solar radiation, temperature, humidity and wind speed are no longer required in the proposed approach. The IoT network only needs sensors for measuring pollutant con-centrations. These readings are then uploaded to the cloud on a sample-by-sample basis. The receiver side, which is a central processor, downloads these readings and estimate the corresponding values of other sensing modalities, viz., traffic, temperature, humidity, solar radiation, wind speed and noise pollution. This is accomplished using trained deep learning models whose parameters are learnt using the existing data representing the relationship among all the sensing modalities.\nThe core concept here is to approximate the set of functions (fi), i \u2208 {Traffic intensity, Noise levels, Temperature, Humid-ity, Wind speed, solar radiation}, with the set of function pre-dictors of SO2, CO, NO, PM2.5, PM10, NOx, O3, C6H6, C6H5CH3, C8H10 and any other temporal information. In this work, the above function approximations are accomplished by multi-variate regression models implemented using Deep Neural Network architectures. Two different approaches are explored for the implementation of the multi-variate regression models: Isolated Target Regressors (ITR) and Unified Target Regressor (UTR). In Isolated Target Regressors (ITR) ap-proach, independent regression models are employed for each of the modalities that needs to be estimated from the pollutant concentrations. In other words, for estimating M number of modalities, we employ M regression models independently trained to find the relationship of each of them with the independent predictors. The Mean Square Error (MSE) loss for a model estimating modality m (for a training batch of size N), that needs to be minimized, for this ITR approach is defined by Eqn. 3.\n\\(L(m; \\theta_{k}) = \\sum_{i=1}^{N} (f_{m}(x_{i}; \\theta_{k}) \u2013 Y_{m})^{2}; 1 \u2264 m \u2264 |M|\\) (3)\nHere, \\(\\theta_{k}\\) is the set of model parameters at instance k and \\(f_{m}(x; \\theta_{k})\\) is the function approximated for the mth modality for the input predictor vector x.\nOn the other hand, in the Unified Target Regressor (UTR) approach, all the all the modalities are estimated using a single model. The loss function in this case can be defined as:\n\\(L(\\theta_{k}) = \\sum_{i=1}^{N} \\sum_{m=1}^{M} (f_{m}(x_{i}; \\theta_{k}) \u2013 Y_{m})^{2}\\) (4)\nNote that using the Unified Target Regressor (UTR) ap-proach provides better scalability as it does not require sepa-"}, {"title": "VI. PERFORMANCE EVALUATION", "content": "The system of Data-driven Modality Fusion (DMF) was evaluated using the data collected from the IoT network de-ployed in the city of Madrid\u00b9. For demonstrating the working of the proposed architecture, time-series data recorded over the year of 2023, for multiple sensing modalities detailed above, was used for training the learning models. Details on the model hyperparameters are tabulated in Table III. Performance is evaluated using Mean Absolute Error (MAE) between the true and estimated readings for each inferred modality values. Since the actual value range for each sensing modality is different from one another, we normalize the MAE for a fair comparison of estimation performance across the different modalities. Normalized MAE (NMAE) for modality m is computed by min-max normalizing the MAE of m with its range.\nFig. 4 shows a comparison of the estimated time-series value and true sensor readings for each of the six sensing parameters: traffic intensity, solar radiation, wind speed, noise pollution levels, temperature, and humidity. The estimation is done using the multivariate regression models described in section V.\nFor this set of experiments, Isolated Target Regressors (ITR) were used, where six independent models were trained for synthesizing each modality of the smart city IoT network. The figure demonstrates the perceivable similarity and correlation between the true and the estimated signal for the sensing parameters. It can be observed that the estimated signals by the learning models at the central server have similar amplitude and phase as the original signals sensed by the respective sensors. Moreover, since the prediction is done on a sample-by-sample basis (that is at the sensing sampling rate), there is no lag in the estimated signal, as is evident from the figure.\nFig. 5 summarizes the DMF performance for different sensing modalities estimation with varying model complexity at the receiver. It is observed from the figure, in general, that estimation error goes down with increase in model size and then goes to a point of diminishing return beyond a certain complexity. This is because, an increase in model parameters provides higher degrees of freedom for approximating the non-linear relationship of the sensing modality with the pollutant concentration. Another point to note here is that estimation of noise levels has a higher error as compared to that of the other modalities. In addition, the error goes up with an increase in the model size beyond a certain point. The reason behind this is the low sampling rate of noise intensity values (sampled on a daily basis), and employing more complex models in such scenarios result in overfitting issues due to curse of dimensionality. This could be ameliorated by using"}, {"title": "VII. DMF FEASIBILITY AND LIMITS: EIGEN SPACE REPRESENTATION", "content": "The correlation study presented in section IV helps in un-derstanding the inherent relationships existing among different sensing modalities and serves as a guideline for choosing the smallest subset of modalities with an acceptable DMF performance. However, correlation simply measures pairwise linear relationships between variables without uncovering la-tent structures or global patterns. In addition, it is not entirely evident as to what is the relationship of correlation coefficients with the DMF performance, from the perspective of both estimation accuracy and network bandwidth usage. With the objective of providing an initial step towards understanding the feasibility of DMF from data analytics perspective, we provide an Eigen space representation of different sensing modalities discussed earlier. The motivation behind using Eigen space representation is that for a given dataset, Eigen vectors represent the direction along which it possesses the maximum variance.\nFor a given sensing modality m, we compute the Eigen vector \\(v_{m}\\) with the largest Eigen value \\(\\lambda_{m}\\) = \\(max_{v_{m}}vmCmv_{m}\\). This Eigen vector corresponding the largest Eigen value \\(\\lambda_{m}\\) can be derived using Eqn. 6\n\\(v_{m} = argmax_{v_{m}} (v_{m}^{T}C_{m}v_{m})\\) (6)\nHere Cm is the covariance matrix of the normalized dataset (Dm), related to the mth modality, with \\(n_{D_{m}}\\) samples, which can be computed as follows.\n\\(C_{m} = \\frac{1}{n_{D_{m}}} (D_{m} \u2013 E[D_{m}])^{T}(D_{m} \u2013 E[D_{m}])\\) (7)"}, {"title": "VIII. CONCLUSIONS", "content": "This paper presents the Data-driven Modality Fusion (DMF) paradigm as a promising solution for addressing the challenges associated with managing large-scale smart city IoT networks. By utilizing correlations between data streams from different sensing modalities, DMF reduces the need for numerous physical sensors while maintaining high accuracy in modality estimation. The empirical evaluation using real-world data from Madrid's smart city deployment demonstrates that DMF achieves competitive performance in reconstructing key sens-ing parameters with minimal sensor infrastructure. The results reveal a trade-off between model complexity and estimation accuracy, allowing for flexible configuration based on the resource constraints at the network core and the application's performance requirements.\nDMF also provides a practical solution for reducing commu-nication bandwidth usage and IoT device energy consumption, thereby aligning with the sustainability goals of smart city initiatives. The ability to estimate critical sensing modalities in real-time, even in the event of sensor failure, enhances the reliability and robustness of urban IoT systems. Furthermore, by offloading computation to the network core, the framework alleviates the burden on edge devices, making it particularly suitable for resource-constrained IoT networks.\nOverall, DMF offers a scalable and effective method for managing smart city IoT networks, paving the way for more sustainable, resilient, and efficient urban environments. Future work can explore extending the DMF approach to incorporate spatial correlation among same-modality sensors for further efficiency gains. In addition, defining strict bounds and limits for DMF feasibility is also another direction for extension of this research."}]}