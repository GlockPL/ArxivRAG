{"title": "Sparse Prototype Network for Explainable Pedestrian Behavior Prediction", "authors": ["Yan Feng", "Alexander Carballo", "Kazuya Takeda"], "abstract": "Predicting pedestrian behavior is challenging yet crucial for applications such as autonomous driving and smart city. Recent deep learning models have achieved remarkable performance in making accurate predictions, but they fail to provide explanations of their inner workings. One reason for this problem is the multi-modal inputs. To bridge this gap, we present Sparse Prototype Network (SPN), an explainable method designed to simultaneously predict a pedestrian's future action, trajectory, and pose. SPN leverages an intermediate prototype bottleneck layer to provide sample-based explanations for its predictions. The prototypes are modality-independent, meaning that they can correspond to any modality from the input. Therefore, SPN can extend to arbitrary combinations of modalities. Regularized by mono-semanticity and clustering constraints, the prototypes learn consistent and human-understandable features and achieve state-of-the-art performance on action, trajectory and pose prediction on TITAN and PIE. Finally, we propose a metric named Top-K Mono-semanticity Scale to quantitatively evaluate the explainability. Qualitative results show the positive correlation between sparsity and explainability. Code available at https://github.com/Equinoxxxxx/SPN.", "sections": [{"title": "I. INTRODUCTION", "content": "Predicting pedestrian behavior in complex environments is a critical task for autonomous systems, with applications ranging from self-driving vehicles to intelligent surveillance. While traditional models have focused on predicting either the future trajectory, action, or pose of pedestrians, there has been a growing demand for models that can simultaneously predict pedestrian behaviors in different types, including trajactory, action class and pose.\nRecent efforts in applying deep learning methods to address the prediction of any one type of behavior are proven effective [1]\u2013[4]. However, only a few works dis-cussed joint prediction of multiple types of behaviors [5], [6]. Moreover, most of these works lack the mechanism of revealing their inner workings during inference, which causes additional testing costs when the model faces unseen scenarios, decreases the trustworthiness, and hinders devel-opers and researchers from making further improvements.\nA major challenge that causes the problem is multi-modal inputs. Pedestrian behaviors can be inferred from various\nIn this paper, the term \"behavior\" refers to pedestrian trajectory, action class and pose unless otherwise specified.\nclues, including the historical trajectories, poses, contextual elements, etc. Although many of these clues can originate from visual inputs, the lack of annotated data and the high di-mensionality of raw inputs make it hard for neural networks to learn salient features directly from images and videos. Therefore, disentangling different types of data and regarding them as multi-modalities became a common practice [1], [2], [4], [5], [7]. However, most explaining techniques are modality-specific [8] or architecture-specific [9]\u2013[12], which limits the scalibility of the model. To bridge this gap, we present Sparse Prototype Network (SPN), a prototype-based framework designed to jointly predict multiple types of pedestrian behaviors, and provide explanations of its inferences based on the distance between the prototypes it learns and the input. The method is inspired by the idea that, multi-modalities derived from the same observation can be regarded as different fragments. By mapping the fragments into a joint latent space, a prototype vector can match any one of them, and is thus modality-independent, which enables the model to extend to arbitrary combinations of modalities. The modalities in the training data with the closest distance to a prototype are selected to represent that prototype. Figure ?? briefly illustrates the inner working of SPN.\nIn the wider range of literature on explainable AI (XAI), one major challenge in developing explainable models is poly-semanticity, i.e. a unit of explaining (e.g. a neuron or a vector) activates on multiple semantics in the input. Since SPN uses prototype vectors to explain its inference, it also"}, {"title": "II. RELATED WORKS", "content": "A. Pedestrian Behavior Prediction\nTraditional approaches for predicting pedestrian actions and trajectories relied on handcrafted features and physical models, such as Kalman filters and social force models [15]. These methods, while inherently explainable, often struggle to capture the complexity of real-world pedestrian behavior, especially in crowded or dynamic environments.\nMore recently, the field of pedestrian behavior prediction has witnessed significant advances brought by deep learning [3]\u2013[5], [16]\u2013[18]. State-of-the-art works primarily employed multi-modal inputs such as appearance, motion, past tra-jectory, etc [1], [2], [5], [7], [18]\u2013[20], and applied certain integration strategies, such as attention mechanisms, to make predictions. However, these models often lacked the ability to explain their predictions, limiting their applicability in safety-critical systems such as autonomous driving.\nB. Prototype-based Models\nA large portion of efforts toward explainability in deep learning models have primarily focused on post-hoc expla-nation methods, where explanations are generated after the model has made its predictions [9]\u2013[12]. Recently, large language models (LLMs) have been applied to generate, text-based explanations, thanks to their outstanding ability of reasoning [8], [21]. However, these post-hoc explanations are limited in their fidelity. Moreover, they are often specific to a particular modality, such as visual data, and do not generalize well to multi-modal inputs.\nOn the other hand, prototype-based methods [?], [22] offer an alternative path toward inherently explainable mod-els. These methods learn prototypes\u2014representative fea-tures\u2014from the data, which are then used to make predic-tions. While most of these methods were applied to few-shot learning problem [23]\u2013[25], some were designed to make explainable predictions in simple tasks and small-scale datasets [22], [26]. The advantage of prototype-based approaches is that they provide sample-based explanations, i.e. using representative samples to explain the semantics of certain prototypes. However, these methods typically focus on single modalities and do not address the challenge of multi-modal explainability.\nIn order to bridge the above gaps for pedestrian behavior prediction, SPN leverages modality-independent prototypes, as well as a sparsity loss to promote mono-semanticity of the learned prototypes.\nC. Mono-semantic Explanation\nSample-based explanation has recently become one of the major explaining techniques of XAI methods, including prototype-based methods [22], [26]\u2013[29] and mechanistic methods [8], [30], where the most related samples are used to represent the explaining units such as neurons and prototypes. One recent challenge faced by these methods is poly-semanticity [31], meaning that the units are represented by unrelated samples. On the contrary, mono-semantic units refer to those that are related to relatively consistent features. Although works from the field of language models [14], [32] used sample-wise metric to promote or inhibit the mono-semanticity of a single sample, there has not been a metric to evaluate the mono-semanticity of an explaining unit. Inspired by Mono-semantic Scale [32] where sparsity was used as a proxy of mono-semanticity, we propose Top-K Mono-semanticity Scale (Top-K MS) for short as a quantitative metric for explainability of prototypes."}, {"title": "III. METHOD", "content": "In this section, we describe the architecture of the Sparse Prototype Network (SPN) and the explainability metric Top-K Mono-semanticity Scale (Top-K MS) used to evaluate the model. Our proposed method focuses on creating a predic-tive framework that not only achieves accurate pedestrian behavior prediction but also provides interpretable, human-understandable explanations for its decisions.\nA. Sparse Prototype Network\nThe SPCM employs multi-modal input and predicts three types of data to describe pedestrian behavior: action, tra-jectory, and pose. To achieve this, the model is composed of three main modules: input encoding, prototype layer, and prediction heads.\nInput encoding. The input encoding module processes each modality independently, transforming the raw inputs into compact, high-dimensional feature vectors. Let $X$ ="}, {"title": "IV. EXPERIMENTS", "content": "A. Implementation Details\nThe detailed settings of the multi-modal encoders we used in the experiments are as follows:\n1) Local context. We use the backbone in [2], a multi-layer 2D convolutional block.\n2) Past pose, past trajectory, ego motion and social re-lation. For these modalities, we use a one-layer transformer encoder [35] with 8 heads and 64 dimensions. For modalities with more than one sequence dimension, we flatten these dimensions together with the temporal dimension before feeding the input to the backbone.\nFor the prediction heads of trajectory prediction and pose prediction, we use DePOSit [36], a diffusion-based genera-tion model originally designed for pose regression. We input $E'$ as a condition vector into DePOSit for pose and trajectory prediction.\nWe use Adam optimizer during training with $\\beta_1 = 0.9$, $\\beta_2 = 0.999$. We set $\\lambda_{cluster} = 0.001$ and $\\lambda_{l_1} = 0.01$ out of a random search. We use 50 prototypes and 512 dimensions for each prototype as a default setting. The model is trained for 50 epochs with a batch size of 64."}, {"title": "V. LIMITATIONS", "content": "Despite the improvements in prediction performance and in the mono-semanticity of explanations, the above results also reveal limitations of SPN. First of all, mono-semanticity is only one aspect of general explainability, and applying Top-K MS and sparsity loss cannot totally diminish the subjectivity from the evaluation of explainability. Secondly, despite the fact that the classification task can be made completely interpretable by using linear functions as the prediction head, the transformation from prototypes to the generation results, i.e. trajectory and pose, still remains a black box. Although the prototypes can provide more transparent conditions than previous methods, more efforts are required to improve the explainability of the generation and regression process. Last but not least, although SPN shows progress with a relatively small number of prototypes, the potential still remains to be discovered to have more prototypes than dimensions such that the prototypes can learn further disentangled and fine-grained features from multi-modalities."}, {"title": "VI. CONCLUSIONS", "content": "In this paper, we introduced the Sparse Prototype Network (SPN), an explainable architecture designed to address the challenge of explainable pedestrian behavior prediction. SPN surpasses existing models in three tasks, i.e. action pre-diction, trajectory prediction and pose prediction. By map-ping multi-modal inputs to modality-independent prototypes, SPN can trace its own decisions to human-understandable concepts. To compensate for the lost commonality between modalities, we also apply a complementary combination of regularization terms, preventing the prototypes from collaps-ing and also encouraging the model to learn mono-semantic features.\nFurthermore, we introduced the Top-K Mono-semanticity Scale, a new metric to quantitatively evaluate the explain-ability of not only prototype-based models, but also other explainable methods relying on sample-based explanations. This metric enables a systematic assessment of how well each prototype aligns with a single understandable concept."}]}