{"title": "AlgoRxplorers | Precision in Mutation Enhancing Drug Design with Advanced Protein Stability Prediction Tools*", "authors": ["Karishma Thakrar", "Jiangqin Ma", "Max Diamond", "Akash Patel"], "abstract": "Predicting the impact of single-point amino acid mutations on protein stability is essential for understanding disease mechanisms and advancing drug development. Protein stability, quantified by changes in Gibbs free energy (\u2206\u2206G), is influenced by these mutations. However, the scarcity of data and the complexity of model interpretation pose challenges in accurately predicting stability changes. This study proposes the application of deep neural networks, leveraging transfer learning and fusing complementary information from different models, to create a feature- rich representation of the protein stability landscape. We developed four models, with our third model, ThermoMPNN+, demonstrating the best performance in predicting AAG values. This approach, which integrates diverse feature sets and embeddings through latent transfusion techniques, aims to refine AAG predictions and contribute to a deeper understanding of protein dynamics, potentially leading to advancements in disease research and drug discovery.", "sections": [{"title": "Introduction", "content": "Many drugs target proteins to modulate their activity such that they may bind more efficiently to their targets and lead to more effective treatments\u00b9. A protein's activity is typically impacted by alterations in its sequence, leading to a significant change in its structure and function, thereby influencing protein stability. When mutations cause the protein to become unstable, it often leads to a range of diseases and cancers, underscoring the importance of maintaining protein structure integrity for cellular health. Meanwhile, mutations that enhance protein stability could lead to the development of more effective drugs, offering new avenues for treatment. In 2022 alone, pharmaceutical companies spent nearly $244 billion on R&D, underscoring the importance of a more efficient drug discovery and development process2. We aim to reduce the time taken to identify viable new drug candidates by assessing the impact of protein point mutations on stability. This will be done by analyzing the change in Gibbs free energy (\u2206\u2206G) between naturally occurring, or wild-type, proteins and their mutated"}, {"title": "Current Practice", "content": "Our project draws upon a diverse range of recent scientific research to explore innovative protein stability prediction techniques.\nCao\u00b3, Heyrati 4, Kuhlman, Dieckhaus6, M. Baek\u00b9, Chandra7 and Wei8 introduce neural network models for predicting protein characteristics, ranging from stability change to bioactivity and even protein structure. Cao's\u00b3 DeepDDG model, while directly related to our project, is hard to implement given the code isn't open to the public but its DeepDDG server could be used for benchmarking purposes. While Heyrati\u2019s4 study with a sophisticated Siamese neural network allowed us to learn about feature extraction and similarity learning which our algorithms will also be leveraging, their focus on bioactivity classification offered little overlap with ours. Although it didn't examine proteins beyond their structure, we found Kuhlman's combined use of neural networks along with traditional machine learning methods like SVM on embeddings interesting since we'll also be implementing these methods.\nAlthough M. Baek's\u00b9 work utilizes amino acids to predict proteins structure, which is valuable for our research, it failed to generalize across diverse protein families. Chandra's use of a Transformer and encoded features to predict protein structure was valuable for our research although the training dataset was limited. Wei's\u00ae paper offered a comprehensive overview of applying machine learning techniques to materials science, making otherwise time-consuming tasks more efficient, which resonates with our work. However, the models offered little interpretability which is crucial for trust and adoption.\nJ. Baek 10 introduces the Graph Multiset Transformer (GMT) to predict molecular properties. The paper is valuable for us in learning more about the intricate relationships among amino acids, the building blocks of proteins, despite the limited training dataset. M. Baek\u00b9, Maziarka 11, Dieckhaus 6 and Wang 12 extend the research body to GNNs, which help compress complex protein features while preserving key structural interactions.\nMaziarka\u00b9\u00b9 introduces the Molecule Attention Transformer designed for small molecules which would require significant modifications for us given the complexity of protein structures; the paper was still useful to learn of the various Transformer architectures in the domain. While Wang 12 offered a small training dataset, the GNNs employed of protein structures for property prediction offered a useful perspective. Dieckhaus introduces ThermoMPNN, a model combining GNNs and transfer learning, to predict protein stability changes. ThermoMPNN is relevant for enhancing prediction accuracy by learning from extensive protein behaviors, but the model could be simplified for computational efficiency. Baselious 13 and Rives 14 similarly leverage transfer learning to predict protein structure and properties, respectively.\nBaselious 13 discusses the use of an advanced protein structure prediction algorithm for proteins that play a major role in epigenetic regulation, developing our understanding of the impact of mutations on protein structure and function despite have inconsistencies in accurately predicting the dynamic regions of proteins. Rives 14 introduces ESM, a pretrained protein transformer model, which clusters similar proteins. The features generated by ESM, while underfitting the data slightly, will assist our model's ability to develop a rich understanding of proteins and can pair with a simplified ThermoMPNN architecture to generate strong protein stability change predictions.\nBy leveraging insights across these studies, we will improve upon existing limitations by focusing on building a precise and understandable model."}, {"title": "Methodology", "content": "Our novel approach combines advanced deep learning techniques and visualization to improve pro- tein thermostability prediction and streamline the drug discovery process. The modeling component utilizes latent transfusion, fusing latent features or embeddings learned by multiple deep learning"}, {"title": "Data Preprocessing & EDA", "content": "Before modeling, we carefully examined the FireProtDB dataset, which consists of unique proteins, each with several listed mutations. The dataset contains nearly 3,100 mutations. After adjusting for duplicates, accounting for 0.52% of the training data and 1% of the validation data, there were a total of 2,645 mutations for training and 398 mutations for validation.\nThrough exploratory data analysis, we constructed a confusion matrix comparing wild-type and muta- tion cases, revealing that the amino acids valine (V) and leucine (L) in the wild-type were frequently replaced by alanine (A) due to mutation. We applied the k-means clustering algorithm to both the ThermoMPNN and XGBoost embedding datasets, with PCA for dimensionality reduction. Using twelve clusters, all data points were perfectly allocated to their appropriate clusters, indicating distinct groups within the dataset. Additionally, we observed that the Immunoglobulin G-binding protein, glycine, was one of the most prominent proteins in the dataset, with a count of 600 mutations. The exploration and preprocessing of the dataset provided valuable insights into the data's characteristics and ensured a solid foundation for building accurate and reliable predictive models."}, {"title": "Model Development", "content": "Our research builds upon ThermoMPNN, a cutting-edge graph neural network model that utilizes transfer learning to extract structural features and sequence embeddings from the ProteinMPNN model. By taking 3D protein maps as input, ThermoMPNN captures the spatial proximity of protein components and the wild-type protein structure. The model utilizes encoder-decoder layers to process the protein's structural information, effectively creating a residue \"social network.\" Through the use of a light attention mechanism and a multilayer perceptron, ThermoMPNN refines the input data to predict stability changes resulting from mutations.\nWe also incorporated insights from Chris Deo-tte's Novozymes research, which used Meta's Evo- lutionary Scale Modeling (ESM), a pretrained protein transformer model, to include more protein features in our models. We made significant adjustments to adapt Deotte's models to our dataset such as correcting the backbone atoms used, requiring us to further develop domain knowledge and our understanding of computational chemistry for protein stability prediction 15.\nTo augment our model's performance, we explored approaches that integrate feature sets and embed- dings from deep thermostability prediction models, such as ThermoMPNN and ESM. By combining these embeddings using element-wise multiplication and concatenation, we create a comprehen- sive representation of proteins, capturing the specific characteristics of each protein-mutation pair. Element-wise multiplication captures interactions between corresponding features from different embeddings, while concatenation enables learning from a wider range of features. However, the effectiveness of integrating diverse embeddings depends on their ability to capture the complexity of the relevant data, and the increased feature space may not always improve performance. Acknowl- edging this uncertainty, we adopted an experimental approach, comparing the performance of four different models with unique embedding integration strategies. This iterative process allows us to refine our methods, identify the most promising approach, and develop robust models for predicting protein stability changes.\nOur first model is the original ThermoMPNN model trained on data with duplicates removed, provid- ing a solid foundation but potentially limiting in its ability to capture complex interactions between protein features. The second model concatenates ESM embeddings and ThermoMPNN embeddings after applying light attention to predict \u2206\u2206G. By extracting the ThermoMPNN embeddings after the"}, {"title": "UI Development", "content": "The ThermonMPNN+ modeling is done to enhance predictions of protein thermostability chan-ges, and is supplemented with an innovative web app. Our end product, built with Python, HTML, and JavaScript, complements our innovative approach by providing an interactive 3D visualization of proteins and dashboards for real-time exploration of mutation effects. Designed for researchers and"}, {"title": "Experiments", "content": "The experiments in this study are designed to investigate if and which complementary information captured by different models, can help predict the impact of amino acid changes on protein stability with the highest accuracy. Additionally, our UI experiments aim to determine the most effective ways to present and visualize protein stability data, focusing on the optimal presentation of 3D structures for comparison. The ultimate goal is to create an intuitive, informative, and interactive interface that allows users to easily explore the impact of mutations on protein stability.\nTable 2 presents the performance of our four models in predicting protein stability changes after conducting grid search and fine-tuning while also testing regularization techniques as needed. Model 3,"}, {"title": "Conclusions", "content": "We aimed to improve the drug discovery process by accurately predicting protein thermostability changes caused by single-point mutations. Our novel deep learning model, ThermoMPNN+, improves upon the state-of-the-art by incorporating features from a robust protein transformer model. We also developed an intuitive UI for users to interact with 3D protein structures and explore the impact of mutations on thermostability in real-time. These tools will significantly reduce the time and cost associated with evaluating proteins for new drugs, ultimately leading to faster and improved drug discovery outcomes.\nDuring the modeling phase, we encountered several limitations. Despite attempting to augment the feature space with our various modeling techniques, the limited availability of data likely contributed to the still less than ideal ability of ThermoMPNN+, our best-performing model, to explain the variability in the data, as evidenced by the relatively low R2 values. Model interpretability remains a challenge, as the underlying features used to predict AAG are unknown. Computational complexity is also a significant limitation, with model training taking approximately 3+ hours using GPU. Despite these limitations, ThermoMPNN+ demonstrates improved performance compared to existing models, suggesting that integrating diverse feature sets and embeddings through latent transfusion techniques is a promising approach.\nFuture extensions of this research can include reframing the problem as a binary classification task, predicting whether mutations are stabilizing or destabilizing. Additionally, incorporating other types of information, such as B-factor (a measure of an atom's vibrational motion) and surface area information, could further enhance the model's predictive capabilities according to our domain research. The web app can be improved as well, allowing users to upload their own proteins to generate structural change and AAG predictions on the fly. Additional UI improvements can focus on maximizing the user experience and utility of the application. As we refine these methods, considering trade-offs between model complexity, computational resources, and interpretability is crucial to develop robust and practical tools for protein engineering and drug discovery.\nAll team members have contributed a similar amount of effort."}]}