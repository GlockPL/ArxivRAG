{"title": "An Empirical Comparison of Generative Approaches for Product Attribute-Value Identification", "authors": ["Kassem Sabeh", "Robert Litschko", "Mouna Kacimi", "Barbara Plank", "Johann Gamper"], "abstract": "Product attributes are crucial for e-commerce platforms, supporting applications like search, recommendation, and question answering. The task of Product Attribute and Value Identification (PAVI) involves identifying both attributes and their values from product information. In this paper, we formulate PAVI as a generation task and provide, to the best of our knowledge, the most comprehensive evaluation of PAVI so far. We compare three different attribute-value generation (AVG) strategies based on fine-tuning encoder-decoder models on three datasets. Experiments show that end-to-end AVG approach, which is computationally efficient, outperforms other strategies. However, there are differences depending on model sizes and the underlying language model. The code to reproduce all experiments is available at: https://github.com/kassemsabeh/ pavi-avg", "sections": [{"title": "1 Introduction", "content": "Product attributes are a crucial component of e-commerce platforms, facilitating applications such as product search (Chen et al., 2023), product recommendation (Truong et al., 2022), and product-related question answering (Deng et al., 2023). They provide useful details about product features, enabling customers to compare products and make informed purchasing decisions. Product attribute and value identification (PAVI) refers to the task of identifying both the attributes and their corresponding values from an input context, such as a product title or description. For example, given the product title \"Fossil Men's Watch Analog Display Slim Case Design with Brown Leather Band\" (see Figure 1), a model should identify the attributes Brand, Band Color, and Band Material, with the corresponding values Fossil, Brown, and Leather. Most existing work focuses on product attribute-value extraction (PAVE) (Zheng et al., 2018; Xu et al., 2019; Wang et al., 2020; Yang et al., 2022), which extracts the value of a given attribute from the input context. Despite extensive research on PAVE (Blume et al., 2023; Yang et al., 2023; Brinkmann et al., 2023), PAVI is a more realistic and complex task since it requires the attribute to be generated and not assumed to be part of the input. While recent studies have explored generative models for PAVI, these efforts are limited in scope and often lack comprehensive evaluation across different datasets and settings (Roy et al., 2024; Shinzato et al., 2023). Moreover, existing work focus primarily on end-to-end models without exploring alternative generative strategies. Consequently, it remains unclear which types of PAVI models are effective in practice, as comprehensive experiments and comparisons are lacking.\nIn this paper, we address these gaps by proposing three generative approaches for PAVI and conducting a comprehensive evaluation across multiple datasets. Inspired by recent advancements on question and answer generation methods (Bartolo et al., 2021), we compare between three strategies based on fine-tuning encoder-decoder language models such as T5 (Raffel et al., 2020) and BART (Lewis et al., 2020). Our proposed approaches are: (1) pipeline attribute-value generation (AVG), which decomposes the task into value extraction and attribute generation, and builds a separate model for each sub-task; (2) multitask AVG, which uses a single shared model that is trained on both sub-"}, {"title": "2 Related Work", "content": "Most existing approaches for attribute-value extraction use sequence tagging (Huang et al., 2015; Xu et al., 2019; Yan et al., 2021; Zheng et al., 2018) or question answering (Wang et al., 2020; Yang et al., 2022; Ding et al., 2022; Hu et al., 2022; Sabeh et al., 2022; Yang et al., 2023) methods. However, such approaches carry closed-world assumption, as they require the set of attributes as inputs to extract the corresponding values. More recently, researchers have explored the capabilities of generative models to tackle the PAVI task, in an open-world setting. Roy et al. (2024) proposed a generative framework for joint attribute and value extraction. They conduct experiments on the AE-110k dataset and show that the generative approaches surpass question-answering based methods. Shinzato et al. (2023) fine-tune a pre-trained T5 generative model (Raffel et al., 2020) to decode a set of target attribute-value pairs from the input product text of the MAVE dataset (Yang et al., 2022). They show that the generative approach outperforms extraction and classification-based methods (Chen et al., 2022).\nHowever, all above studies utilize an end-to-end generative approach. They did not explore other generative strategies for attribute-value identification (i.e., pipeline and multi-task). In addition, these approaches are not comparable as they are different in terms of datasets, settings, and evaluation metrics. Finally, none of the above proposed models have been made publicly available. In this work, we propose three generative approaches for PAVI and empirically compare them on three real-world datasets. We summarize how our approach differs from prior work in Table 1. As can be seen, we evaluate in total all approaches across three"}, {"title": "3 Proposed Methods", "content": "Given an input product data (title or description) \\(x = \\{x_1,x_2,...,x_{|x|}\\}\\), attribute-value generation aims to generate attribute-value pairs \\(Q_x\\) related to the information in x:\n\\[Q_x = \\{(\\alpha^1, v^1), (a^2, v^2), (a^3, v^3), ...\\}\\] (1)\nFor instance, if x=\"Fossil\",...,\"Band\", then \\(Q_x\\) = (\"Brand\",\"Fossil\"), (\"Band Color\",\"Brown\"), (\"Band Material\", \"Leather\").\nWe formulate the attribute-value identification problem as an attribute-value generation (AVG) task and propose three approaches based on fine-tuning language models, as depicted in Figure 2."}, {"title": "3.1 Pipeline AVG", "content": "The AVG task can be decomposed into two simpler sub-tasks, value extraction (VE), and attribute generation (AG). The VE model \\(P_{ve}\\) first generates the value candidate \\( \\tilde v \\) from x. Then, the AG model \\(P_{ag}\\) generates an attribute a whose value is \\( \\tilde v \\) in the input x. The VE and AG models can be trained independently on a product dataset consisting of the triplet (x, a, v) by maximizing the conditional log likelihood of:\n\\[\\tilde v = arg \\max_{v} P_{ve}(v | x)\\] (2)\n\\[a = arg \\max_{a} P_{ag} (a | x, v)\\] (3)\nIn practice, the VE model input is \\([x_1, x_2,... x_{|x|}]\\), where xi is the i-th token of the product input x and |x| represents the number of tokens in the sequence. The input to the AG model takes the value into account by highlighting it inside the input. Specifically, following previous work (Chan and Fan, 2019; Ushio et al., 2023), we introduce a highlight token <h1> to take the value into account:\n\\[[x_1,..., < h1 >, v_1, ..., V_{|v|}, < h1 >,... x_{|x|}]\\]\nwhere vi is the i-th token of v. At inference, we simply replace the gold value v of the AG model by the prediction from the VE model, and run the inference over the product context x. For example, if the VE model extracts \"Leather\" from the input x, we highlight \"Leather\" and feed it to the AG model as: [\"Fossil\",...,<h1>,\"Leather\",<h1>,...,\"Band\"]. Thus, the pipeline approach generates at most one attribute-value pair per product context x.\nTo allow the pipeline approach to generate multiple attribute-value pairs, we can convert the values into a flattened sentence y, and fine-tune a sequence-to-sequence model to generate y from x. Formally, we define a function L that maps \\(Q_x\\) to a sentence as:\n\\[L(Q_x) = \"V_1/V_2/V_3...\"\\] (4)\nIn this case, the VE model generates a set of possible values, and for each value we run the AG model to obtain a set of attribute-value pairs."}, {"title": "3.2 Multitask AVG", "content": "Instead of training two separate generative models for each sub-task, we can instead use a single shared model that is fine-tuned in a multi-task learning setting. Namely, we mix the training instances for the VE and AG tasks together, and randomly sample a batch at each iteration of seq2seq fine-tuning. We distinguish each task by adding a prefix to the beginning of the input text. Namely, we add extract value for the VE task, and generate attribute for the AG task."}, {"title": "3.3 End2End AVG", "content": "Instead of breaking the AVG task into two sub-tasks, we can directly model it by transforming the target attribute-value pairs to a flattened sentence z, and fine-tune a seq2seq model to directly generate the z from x. We define a function T that maps the target \\(Q_x\\) to a sentence as:\n\\[T(Q_x) = \\{t(a^1, v^1)|t(a^2, v^2)|...\\}\\]. (5)\n\\[t(a, v) = \"attribute: \\{a\\},value : \\{v\\}\"\\] (6)\nWe use the template t to textualize the attribute-value pairs and separate them using a separator |."}, {"title": "4 Experimental Settings", "content": "Datasets. We use three real-world datasets.\n\u2022 \u0391\u0395-110K (Xu et al., 2019): This dataset contains tuples of product titles, attributes, and values from AliExpress Sports & Entertainment category. Instances with NULL values are removed, resulting in 39,505 products with 2,045 unique attributes and 10,977 unique values.\n\u2022 MAVE (Yang et al., 2022): This is a large and diverse dataset complied from the Amazon Review Dataset (Ni et al., 2019). We remove negative examples from the MAVE dataset, where there are no values for the attributes. The final dataset contains around 2.9M attribute-value annotations from 2.2M cleaned Amazon products.\n\u2022 OA-Mine (Zhang et al., 2022): We use the human-annotated dataset, which contains 1,943 product data from 10 product categories. No further processing is applied to this dataset.\nWe randomly split all datasets in train:val:test = 8:1:1. The splits are stratified by product category. Appendix A shows statistics of the three datasets.\nBase Models. For all approaches (pipeline, multitask, and end2end), we experiment with the base language models T5 (Raffel et al., 2020) and BART (Lewis et al., 2020). We also compare between the model weights t5-{small,base,large} and facebook/bart-{base,large} from Hugging-Face34.\nEvaluation Metrics. Following previous works (Yang et al., 2022; Shinzato et al., 2023), we use precision P, recall R, and F\u2081 score as evaluation metrics. The datasets may contain missing attribute-value pairs that the model might generate. To reduce the impact of such missing attribute-value pairs (Shinzato et al., 2023), we discard predicted attribute-value pairs if there are no ground truth labels for the generated attributes."}, {"title": "5 Results", "content": "Table 2 provides the main results. In addition to the three approaches (i.e., pipeline, multitask, and end2end), we also provide an ensemble model that combines the generated attribute-value pairs"}, {"title": "6 Conclusion", "content": "In this paper, we formalized PAVI as an attribute-value generation task and established three different AVG approaches. Using T5 and BART base models, we conducted experiments on three benchmark product datasets. Our evaluation demonstrates that end2end AVG, which generates attributes and values simultaneously, is generally more reliable. However, pipeline or multitask approach can offer advantages, particularly for smaller models and when using language models like BART."}, {"title": "Limitations", "content": "Our study has two main limitations. First, the datasets used in our experiments do not have standard splits. We randomly split the datasets as discussed in Section 4, but we have provided the exact data splits in our repository to ensure reproducibility and comparability. Second, the evaluation measures employed do not penalize over-generated attribute-value pairs. We assume that the datasets do not have all possible annotations, so the generative models might correctly identify new attribute-value pairs. However, in our evaluation, we discard these newly generated attribute-value pairs. As future work, we plan to develop methods for the automatic evaluation of newly generated attribute-value pairs."}]}