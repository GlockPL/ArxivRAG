{"title": "TCMM: Token Constraint and Multi-Scale Memory Bank\nof Contrastive Learning for Unsupervised Person\nRe-identification", "authors": ["Zheng-An Zhu", "Hsin-Che Chien", "Chen-Kuo Chiang"], "abstract": "This paper proposes the ViT Token Constraint and Multi-scale Memory bank (TCMM)\nmethod to address the patch noises and feature inconsistency in unsupervised person re-\nidentification works. Many excellent methods use ViT features to obtain pseudo labels\nand clustering prototypes, then train the model with contrastive learning. However, ViT\nprocesses images by performing patch embedding, which inevitably introduces noise\nin patches and may compromise the performance of the re-identification model. On the\nother hand, previous memory bank based contrastive methods may lead data inconsis-\ntency due to the limitation of batch size. Furthermore, existing pseudo label methods\noften discard outlier samples that are difficult to cluster. It sacrifices the potential value\nof outlier samples, leading to limited model diversity and robustness. This paper in-\ntroduces the ViT Token Constraint to mitigate the damage caused by patch noises to\nthe ViT architecture. The proposed Multi-scale Memory enhances the exploration of\noutlier samples and maintains feature consistency. Experimental results demonstrate\nthat our system achieves state-of-the-art performance on common benchmarks. The\nproject is available at https://github.com/andy412510/TCMM.", "sections": [{"title": "1. Introduction", "content": "This paper proposes multiple modules based on contrastive learning to mitigate\npatch noises and feature inconsistency that may arise in unsupervised person re-identifi-\ncation (re-id) tasks. Unsupervised person re-id has wide applications in the real world,\nsuch as city security monitoring, traffic control and management, event investigation\nand crime tracking. In real-world surveillance systems, a large amount of video data is\ngenerated daily. The application of supervised learning on this data is limited by the\namount of labeled data. Unsupervised learning can more effectively handle and utilize\nthis vast amount of data, improving the scalability and practicality of the models. Pre-\nvious works on person re-id have utilized ViT models to extract discriminative re-id\nfeatures [1, 2], or employed pseudo labels and prototypes to aid in unsupervised train-\ning [3, 4, 5, 6, 7, 8]. Meanwhile, many excellent unsupervised person re-id systems\nhave incorporated these technologies and trained the model using contrastive learn-\ning [9, 10, 11, 12, 13, 14, 15, 16].\nViT effectively captures global context information through self-attention mecha-\nnism, which enables it to attend to all parts of an image simultaneously. This global\ncontext understanding is crucial for unsupervised learning tasks, where the model needs\nto extract meaningful features from images without relying on class labels or localized\ninformation. ViT is built upon treating image patches as \"visual tokens\", utilizing patch\nembedding and learning patch-to-patch attention mechanisms throughout the process.\nUnlike textual tokens provided in natural language processing, visual tokens must be\nlearned initially and refined iteratively to learn ViTs more effectively.\nDespite the remarkable success of ViT in computer vision [17], the presence of\npatch noises in ViT can significantly impact its performance and effectiveness. Patch\nnoises refer to the situation where the patches extracted from an image contain irrele-\nvant or distracting information, such as background clutter, texture variations, or unre-\nlated objects. The self-attention mechanism has a particular ability to ignore or assign\nlower attention weights to patch noises, but this is not always sufficient. When calcu-\nlating attention weights, all patches participate in the computation, and even if they are\nassigned lower weights, the cumulative effect can still impact the overall results. Ad-"}, {"title": "2. Related Work", "content": "Person re-identification has received widespread attention in the computer vision\nfield [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 1]. Benefiting from the powerful\nperformance of contrastive learning, many unsupervised person re-id methods use con-\ntrastive loss to train models. In these studies based on contrastive learning, ViT features\n[1, 15, 16], pseudo labels [3, 4, 6, 8], and prototypes [5, 7, 33, 9] are often incorporated\nto enhance the effectiveness of contrastive loss. This section briefly introduces and\nsummarizes the application of these techniques in previous unsupervised person re-id\nmethods."}, {"title": "2.1. Vision Transformer", "content": "In recent years, many studies have introduced ViT into computer vision tasks with\noutstanding performance. When combined with the powerful feature extraction capa-\nbilities of ViT, the model can effectively learn from large amounts of unlabeled data,\ncapturing nuanced details and diverse characteristics of the input data. RSPC [18] pro-\nposed a novel training approach that improves the robustness of Transformers from a\nnew perspective. Specifically, RSPC first identifies and masks/distorts the most vulner-\nable patches, and then explicitly reduce their sensitivity by aligning the intermediate\nfeatures between clean and corrupted samples. The construction of patch corruption\nenables adversarial learning for the subsequent feature alignment process, which is\nparticularly effective and inherently different from existing methods. PaCa [34] guides\nclustering-for-attention and attention-for-clustering in ViT models through joint learn-\ning. Given an input X, the lightweight cluster module first computes the cluster assign-\nment C for predefined small clusters M to identify meaningful clusters. Then, through\nmatrix multiplication between the cluster assignment C and X, M potential \"visual-"}, {"title": "2.2. Pseudo labels", "content": "Due to the lack of labeled data in unsupervised learning tasks, it is common to\nrely on self-generated pseudo labels to train the model [21, 35, 36]. Pseudo labels can\ndistinguish between positive and negative pairs with greater accuracy. This synergy\nallows for more effective clustering of similar data points and separation of dissimilar\nones, enhancing the discriminative power of the model. In existing unsupervised clus-\ntering methods, only coarse information of global features is often considered, leading\nto insufficient pseudo labels. PPLR [6] generates PART tokens to enable the model to"}, {"title": "2.3. Prototypes", "content": "Prototype-based models have been widely used in recent unsupervised person re-\nid research [37, 38, 39, 40]. ClusterNCE [14] points out that previous memory-based\ncontrastive learning works are limited by batch size constraints. Only a small portion\nof instance features are allowed the update. This leads to inconsistent distributions\nof small batch oscillations due to rapid updates of the network in each iteration. The\nalgorithm proposed in this paper uses unique prototypes to represent each clustered\ncategory and maintains uniqueness throughout the updating process. IQE [24] intro-\nduces a detail enhancement module to improve the feature extraction capability by\nsimultaneously learning from multiple distorted images, thereby reducing pseudo label\nnoise caused by image distortion. IQE method also proposes a low-light enhance-\nment module that improves image clarity by adaptively adjusting pixel values. Both\nmodules work to enhance feature quality, resulting in higher quality pseudo labels.\nThese pseudo labels are then used to obtain cluster prototypes and outlier samples.\nAll these information is used to compute the contrastive loss. DLCL [25] proposes\nInstance-instance Contrastive Learning, which brings original samples and their aug-\nmented samples closer through contrastive loss to explore intra-instance similarities.\nIt also introduces Instance-Community Contrastive Learning, which uses a clustering\nalgorithm to group augmented samples, treating each group as a community. DLCL\nemploys contrastive loss to attract similar instances into the same sample community\nusing the community centroid and original samples, capturing inter-instance similari-\nties.\nDHCL [26] uses pseudo labels to obtain cluster samples and outlier samples, stor-\ning them in a memory bank and then calculating cluster prototypes. Finally, it em-\nploys contrastive loss to explore intra-category similarity within clustered samples and\ninter-instance discrimination among individual instances. Han X. et al. [9] posits that"}, {"title": "3. Method", "content": "Given person re-id training set $X^M = {x_i}^N_{i=1}$ with N images and batch data X =\n${x_b}^B_{b=1}$ with B samples. All samples are encoded to instance features $f_M, f_b$ by ViT en-\ncoder $E_\\theta$ and assigned pseudo labels $\\hat{y}_M, \\hat{y}_b$ by cluster method. The proposed TCMM\naims to strengthen the encoder $E_\\theta$ to learn more discriminative features, enhancing the\nmodel robustness and diversity. TCMM limits the interference of patch noise through\nthe ViT token constraint, and the multi-scale memory bank improves the accuracy of\npseudo labels. The system ultimately enhances the performance of unsupervised per-\nson re-id. The overall architecture of ViT Token Constraint and Multi-scale Memory\nbank (TCMM) is depicted in Figure 2. Section 3.1 introduces how to restrict ViT to-\nkens to reduce the negative impact of patch noise, while section 3.2 details how to\nutilize multi-scale memory bank to enable $E_\\theta$ to learn more discriminative features."}, {"title": "3.1. ViT Token Constraint", "content": "The success of self-attention heavily relies on the correlation between patch tokens.\nHowever, not all patches in the patch embedding process are helpful. These blocks\nmay introduce patch noises when encountering occlusions, backgrounds, or non-target\npedestrians. These noises could cause irrelevant regions to be perceived as similar\nto the target pedestrian areas, leading to attention being dispersed across different re-\ngions. This dispersion of attention might result in the model focusing on irrelevant\nregions when computing feature representations. Moreover, when running into non-\ntarget pedestrians, some weights might erroneously be assigned to these interfering\nregions, causing even more harm to the model and affecting its accuracy in identifying\nindividuals. Therefore, this paper proposes a ViT token constraint function to limit the\npatch token features obtained from the encoder, thereby reducing the impact of patch\nnoise on the ViT."}, {"title": "3.2. Multi-Scale Memory Bank", "content": "In the model training stage, the feature update of instances in an iteration might\nnot be consistent with the features of the same cluster because of data imbalance lim-\nitations. Moreover, the common clustering methods may result in outlier samples that\nare not assigned to any cluster. For example, the commonly used DBSCAN algo-\nrithm uses -1 as a pseudo label for outlier samples that cannot be clustered. Some\nexisting methods choose to discard outlier samples that are not assigned to any clus-\nter. These methods have demonstrated that discarding outlier samples strategy can"}, {"title": "3.2.1. Prototype Memory and Prototype Contrast Loss", "content": "After applying a clustering algorithm, the training data $X^M$ without outlier samples\nis divided into C clusters and stored in the prototype level memory. Prototype contrast\nloss utilizes the prototypes of the cluster as positive and negative samples to ensure\nfeature consistency. The model consistently considers representative features of each\ncluster during training by treating the centroid of each class cluster as a positive sample.\nThis ensures the stability and consistency of the model feature representation. Using\nthe cluster centroid from other clusters as negative samples helps the model learn to\ndistinguish features between different clusters. The process of prototype memory and\nprototype contrast loss is illustrated in Figure 4. This design can force the model to\nlearn to distinguish the feature representations of different clusters, thereby improving\nthe model classification ability. Equation (3) is the prototypes design.\n$p_c = \\frac{\\sum_{j\\in O_c}f^M_j}{O_c}$\nwhere $O_c$ indicates the c-th cluster set, $f^M_j$ means the j-th instance feature in $O_c$, $O_c$\nis the sample number of c-th cluster set and $p_c$ indicates prototype of the c-th cluster.\nThe centroid feature of each cluster $O_c$ is regarded as the cluster prototype $p_c$ in this\nequation. The prototypes $p_c$ obtained from this equation are also stored in a prototype\nlevel memory $M^{proto} = {p_1, p_2, ..., p_c}$."}, {"title": "3.2.2. Instance Memory and Anchor Contrastive Loss", "content": "As mentioned earlier, previous methods have demonstrated that discarding out-\nliers can reduce the negative impact of potential noise on the model. Outlier values\nmay represent valuable yet difficult-to-classify samples. Discarding these outliers may\nharm the final performance and limit the diversity of the model. To fully consider the\nvalue of all samples, the instance level memory method first extracts features from the\ntraining set $X^M$ and stores them in the memory bank $M^{ins} = {f^M_1, f^M_2,..., f^M_N}$. A clus-\ntering algorithm such as DBSCAN [43] is then used to obtain pseudo labels $\\hat{Y}^M$ for\nall features. During training, the batch features $f_b$ and pseudo labels $\\hat{y}_b$ of input batch\ndata x are also obtained through the same process. To encourage the model to consider\nmore challenging samples and improve its generalization, this paper regards $f_b$ as an\nanchor and rewrites the InfoNCE loss as the proposed anchor contrastive loss. Firstly,\nthe positive samples are replaced by the least similar samples within the same class as\nthe input sample in $M^{ins}$, making the model more challenging to distinguish between\ndifferent instances within the same class. The positive sample design helps the model\nlearn more discriminative features and improves its generalization ability.\nIn a typical contrastive learning loss function, negative samples are usually set to be\nall samples other than the positive sample. However, in the design of the anchor con-\ntrastive loss, the intention is for the model to consider more challenging samples. The\nmodel may consider dissimilar samples from different clusters and hinder the learning\nprocess if the number of negative samples $K$ is too large. On the other hand, when\nthe number of negative samples $\\kappa > 1$, the effect tends to be better as it increases the\ndiversity of negative samples and helps the model better learn to distinguish features\nbetween different categories. In summary, an appropriate number of negative samples\n$K$ can increase the diversity of negative samples, aiding the model in learning feature\nrepresentations.\nAccordingly, the negative samples are replaced by the $\\kappa$ most similar samples from\ndifferent cluster to the input sample in $M^{ins}$. Setting negative samples as the k most\nsimilar samples from different categories forces the model to learn better to distinguish"}, {"title": "3.2.3. Momentum Update", "content": "Encoder $E_\\theta$ updates during every training iteration, while the features in memory\nare generated using an older version of $E_\\theta$. This discrepancy can lead to memory and\nbatch features not being represented by a similar $E_\\theta$. Inspired by previous works such\nas [44, 13, 45], momentum update is employed for the two memories. After computing\nthe prototype contrast loss, a momentum update strategy is employed to update the\nprototype memory. Equation (6) is the definition of prototype momentum update.\n$\\forall p_c\\in M^{proto}, p_c \\leftarrow \\mu p_c + (1 - \\mu) f_b$\nwhere u is the momentum coefficient. When u is 1, the features in the prototype mem-\nory remain unchanged. Whereas when u is 0, the features in the prototype memory\nare exactly the same as the input batch features $f_b$. This equation blends the original\nprototype features and the batch instance features in proportion to u and then updates\nthe prototype features $p_c$ in $M^{proto}$. $M^{proto}$ is updated by batch input in each iteration.\nCompared to recalculating the prototype after training with all the data, this approach\nkeeps the prototype up-to-date and is also faster.\nOn the other hand, the instance level memory is also updated by momentum update"}, {"title": "4. Experimental Results", "content": "In this paper, we use two large-scale person re-ID dataset: Market-1501 [46] and\nMSMT17 [47] for our model evaluation. We don't adopt DukeMTMC-reID dataset\nbecause it has been taken down. Standard evaluation metrics like mean Average Preci-\nsion (mAP) and Rank-1 accuracy from the cumulative matching curve (CMC) [46] are\nutilized in the experiments on both datasets.\nWe construct our ViT model according to [48, 12]. Then, we conduct the pre-\ntraining process using [49, 50]. We use the ViT encoder along with general contrastive\nloss [44] as our baseline. We first resize the input images to 256 \u00d7 128. Then the input"}, {"title": "4.1. Dataset and Implementation", "content": "In this paper, we use two large-scale person re-ID dataset: Market-1501 [46] and\nMSMT17 [47] for our model evaluation. We don't adopt DukeMTMC-reID dataset\nbecause it has been taken down. Standard evaluation metrics like mean Average Preci-\nsion (mAP) and Rank-1 accuracy from the cumulative matching curve (CMC) [46] are\nutilized in the experiments on both datasets.\nWe construct our ViT model according to [48, 12]. Then, we conduct the pre-\ntraining process using [49, 50]. We use the ViT encoder along with general contrastive\nloss [44] as our baseline. We first resize the input images to 256 \u00d7 128. Then the input"}, {"title": "4.2. Ablation Studies", "content": "$\\alpha$ in ViT Constraint. We conduct an ablation study on MSMT17 to investigate\nthe impact of different $\\alpha$ setting in $L_{constraint}$. We investigate the impact of $\\alpha$ on model\nperformance with fixed settings $L_{proto}$ and $L_{anchor}$. We test several settings and calculate\nmAP: from 0.025 to 1, with an interval of 0.025. The experiments in Figure 6 show that\nthe best mAP performance is achieved when $\\alpha$ is set to 0.075 with 52%, respectively.\nWe can observe from Figure 6 that the mAP performance shows a decreasing trend as\n$\\alpha$ increases. The oscillation of mAP performance between $\\alpha$ = 0.025 to 0.6 is likely\ndue to normal perturbations during training. This experiment confirms our hypothesis.\nSince we cannot determine how many patches are noise, the patch noise in a single\nimage is usually not excessive based on our observation. Therefore, treating all patches\nas negative samples in traditional contrastive learning is inappropriate. Using a small\nnumber of patch tokens as negative samples is more beneficial for the model.\n$\\kappa$ in Anchor Loss. We conduct an ablation study on MSMT17 to investigate the\nimpact of different $\\kappa$ setting in $L_{anchor}$. We use fixed settings prototype loss $L_{proto}$ and\nViT constraint $L_{constraint}$ to validate the impact of $\\kappa$ in $L_{anchor}$ on performance. We test"}, {"title": "5. Conclusion", "content": "This paper introduces the ViT Token Constraint and Multi-scale Memory bank\n(TCMM) system to tackle existing unsupervised person re-id issues. The ViT token\nconstraint imposes restrictions on ViT output tokens to alleviate the impact of patch\nnoises on the ViT. The multi-scale memory bank comprises the instance and the proto-\ntype level memory module. The instance memory encourages the model to learn from\nchallenging samples, enabling it to cover various data variations and improve general-\nization capabilities. The prototype memory utilizes prototypes as positive and negative\nsamples for contrastive learning to mitigate feature inconsistencies. According to ex-\nperimental results, TCMM achieves state-of-the-art performance on both Market1501\nand the more complex MSMT17 datasets. This demonstrates that TCMM allows the\nmodel to learn more discriminative re-id features and enhances the robustness. In the\nfuture, we hope to delve deeper into the self-attention mechanism to mitigate the dam-\nage caused by patch and pseudo label noises to the ViT."}, {"title": "CRediT authorship contribution statement", "content": "Zheng-An Zhu: Conceptualization, Methodology, Software, Validation, Formal\nanalysis, Investigation, Data Curation, Writing - Original Draft, Visualization. Chen-\nKuo Chiang: Conceptualization, Resources, Writing - Review & Editing, Supervision,\nProject administration, Funding acquisition."}, {"title": "Data availability", "content": "Data will be made available on request."}]}