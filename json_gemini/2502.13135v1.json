{"title": "Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions", "authors": ["Taedong Yun", "Eric Yang", "Mustafa Safdari", "Jong Ha Lee", "Vaishnavi Vinod Kumar", "S. Sara Mahdavi", "Jonathan Amar", "Derek Peyton", "Reut Aharony", "Andreas Michaelides", "Logan Schneider", "Isaac Galatzer-Levy", "Yugang Jia", "John Canny", "Arthur Gretton", "Maja Matari\u0107"], "abstract": "We present an end-to-end framework for generating synthetic users for evaluating interactive agents designed to encourage positive behavior changes, such as in health and lifestyle coaching. The synthetic users are grounded in health and lifestyle conditions, specifically sleep and diabetes management in this study, to ensure realistic interactions with the health coaching agent. Synthetic users are created in two stages: first, structured data are generated grounded in real-world health and lifestyle factors in addition to basic demographics and behavioral attributes; second, full profiles of the synthetic users are developed conditioned on the structured data. Interactions between synthetic users and the coaching agent are simulated using generative agent-based models such as Concordia, or directly by prompting a language model. Using two independently-developed agents for sleep and diabetes coaching as case studies, the validity of this framework is demonstrated by analyzing the coaching agent's understanding of the synthetic users' needs and challenges. Finally, through multiple blinded evaluations of user-coach interactions by human experts, we demonstrate that our synthetic users with health and behavioral attributes more accurately portray real human users with the same attributes, compared to generic synthetic users not grounded in such attributes. The proposed framework lays the foundation for efficient development of conversational agents through extensive, realistic, and grounded simulated interactions.", "sections": [{"title": "1 Introduction", "content": "Personalization is a key capability for any interactive agents aiming to encourage positive behavior changes, for instance in health and lifestyle (Christakopoulou et al., 2024; Yang et al., 2024). The efficacy of such agents must be assessed via interactions with users; however, collecting and evaluating diverse, long-term human interactions with agents is costly and time-consuming, and the development of such agents can be significantly accelerated with realistic simulation. We address the challenge of realistic user simulation in this context by proposing an end-to-end framework for generating cohorts of synthetic users grounded in health, lifestyle, and behavior, and having them interact with coaching agents. The framework is generally applicable across a range of health and lifestyle domains; we validate it in the domains of sleep and diabetes coaching.\nSynthetic users generated with large language models (LLMs) have been widely studied in recent years (Kapania et al., 2024; Wang et al., 2025; Moon et al., 2024; Park et al., 2024, 2023), often for general purpose alignment and personalization (Castricato et al., 2024), and have been designed to reflect demographic information about the population at large. We focus on a more targeted application, where the synthetic users are employed for interaction with foundation models or agents specialized in health, as done in recent work (Tu et al., 2024; Yu et al., 2024; Johri et al., 2025). We provide an overview of such work in Section 2.\nWe demonstrate an end-to-end-framework for designing a cohort of synthetic users exhibiting health conditions consistent with their specific demographics and behavioral factors, in order for their interaction with a coaching agent to realistically reflect their needs and challenges. We construct the synthetic users by first generating a sample of natural language \"vignettes\", which are in turn generated based on real demographics, health, and behavioral data (such as the Big Five markers; Goldberg, 1992; Serapio-Garc\u00eda et al., 2023). Our framework also allows for optionally including additional information: domain-specific rubrics"}, {"title": "2 Background", "content": "In this section, we briefly survey the development and goals of LLM-based synthetic personas in general, and then provide further details on prior literature on the design and application of synthetic personas for health. We next describe software systems for simulating agent interactions. Finally, we discuss some challenges in using LLM-derived synthetic users for agent development and beyond."}, {"title": "2.1 LLMs as Synthetic Personas", "content": "The time and expense required in human evaluation of LLM agents naturally evokes the need for auto-evaluation. This has led to the development of \"reinforcement learning from AI feedback (RLAIF)\u201d, where LLMs serve to evaluate the output of other LLMs, in a now well-established strategy for ensuring alignment, factuality, helpfulness, and other desiderata (Bai et al., 2022; Lee et al., 2024).\nOne recent approach to RLAIF uses LLMs to construct synthetic personas and to judge their interaction with the model being evaluated. Castricato et al. (2024) generated these synthetic personas from the US census data, and employed them to build an evaluation dataset of prompt and feedback pairs obtained solely from synthetic users. A strength of the approach is that results for specific users can be modeled, rather than general user categories. This approach also motivates the work of Moon et al. (2024).\nIn addition to demographic information, Serapio-Garc\u00eda et al. (2023) showed that LLMs can be designed to display specific personality traits, such as those along the Big Five dimensions (Goldberg, 1992). Effective modeling and control of personality in LLMs is important for two reasons: first since personality is a key factor in determining effective communication; second, because it is important to model interaction of synthetic users over the broad range of personality profiles to be encountered in practice. Serapio-Garc\u00eda et al. (2023) found that instruction-tuned models displayed more reliable and externally valid personality types than pre-trained variants (perhaps due to superior instruction following), and that larger models are better equipped to express complex traits, and to simulate social behaviours."}, {"title": "2.2 LLMs and Synthetic Personas in Health", "content": "Several works have proposed the use of LLMs to provide advice in health or wellness settings.\nTu et al. (2024) introduced Articulate Medical Intelligence Explorer (AMIE), an LLM agent designed for conversational medical diagnosis. The AMIE agent achieved remarkable success, with greater diagnostic accuracy compared to primary care physicians in a randomized, double-blind crossover study. AMIE was trained using self-play with simulated doctor-patient dialogues and was tested with patients simulated first by searching for medical conditions from across three databases (Health QA, MalaCards Human Disease, MedicineNet Diseases & Conditions), and then by performing internet searches on each medical condition in order to retrieve passages on demographics, symptoms, and management, which were screened for relevance. PaLM 2 (Google, 2023) was used as the base model for all agents, including the patients and doctors, which were given role-specific prompts. Instruction fine tuning of both patient and doctor took place, first using static datasets of real doctor-patient interactions, and subsequently using dialogues generated through self-play. A moderator agent is used to manage the dialogue between doctor and patient, and to decide on when the conversation has ended.\nThere were a number of limitations to the synthetic user (patient) design in the AMIE study. First, the retrieval of symptoms and demographics from online discussion might create bias towards demographics of individuals most likely to engage in online discussion of their condition. Second, online discussion might misattribute irrelevant symptoms to conditions, and be misinformed as to mitigation strategies. Third, the model did not explicitly control for personality traits, relying on the distribution of personality traits to be found in online discussion of the medical conditions, which might not be representative of target demographics. Related to this issue, PaLM 2 has undergone a fine-tuning process which may make the patient agents more obliging, sympathetic, and communicative than real patients.\nYu et al. (2024) also described an application of LLMs to simulate user (patient) populations, based on particular medical histories from 1495 patients in the MIMIC-III database (Johnson et al., 2016). The approach represented each patient's medical and demographic status as a knowledge graph (with 15,000 possible nodes and over 26,000 possible edges), then retrieved patient information from this graph in response to doctor queries. The retrieved answers were then expressed in natural language, with tone adapted in accordance with the Big Five personality traits. The key finding was that \u201cpatient LLMs\" that retrieve from a structured representation of patient traits more accurately communicate symptoms and history than simply using unstructured clinical notes in the prompt.\nOur work differs in a number of important ways. First, the representation of each individual as a knowledge graph is suited to clinical settings, where unstructured clinical notes must be organized as a pre-processing step. Accordingly, much of the focus of the paper is on the construction of the graph, and accurate retrieval from it. The graph representation may be less suited to wellness settings, however, where the user's needs and challenges require less structure and granularity. Second, and more importantly, the generation process can only traverse the graph of existing patients, and cannot generate new individuals. This may lead to limitations with respect to both privacy and scalability.\nJohri et al. (2025) described the use of synthetic personas in evaluating an LLM system for patient history collection in medicine. The patient agent was instructed explicitly not to display medical knowledge or generate new symptoms beyond what\""}, {"title": "2.3 Generative Agent-Based Models", "content": "Generative agent-based models, such as the Concordia system which we used (Vezhnevets et al., 2023), are directly relevant to user persona simulation. Concordia offers a framework for generating agent interactions, particularly dialog-based ones, given a sufficient backstory. Its design incorporates several key features beneficial for research in generative agent-based simulation. First, Concordia employs associative memory (Park et al., 2023) and chain-of-thought reasoning (Wei et al., 2022) to ensure that agent utterances are grounded in the provided backstory. Second, it utilizes metadata tags within prompts to clearly delineate different contextual elements, including agent memory, observations, prior conversation turns, and overarching goals. Furthermore, these contextual components can be assigned varying levels of importance, guiding the underlying LLM to generate subsequent dialog using appropriate chain-of-thought reasoning. Third, Concordia provides extensive logging capabilities, enabling detailed examination of the pipeline's internal processes, such as the constructed prompts sent to the LLM, the chain-of-thought reasoning process, post-processing steps, and the final output. Fourth, its modular architecture allows for flexible configuration, enabling researchers to customize the agent pipeline by swapping components.\nA crucial requirement for generative agent-based simulation frameworks is the ability to integrate and manage multiple, mutable states within the interaction environment, as these states can significantly influence an agent's subsequent actions and utterances. Critically, the mutation of these states, often lacking a true real-world simulation, must also be driven by chain-of-thought reasoning. Concordia addresses this need by providing code"}, {"title": "2.4 Challenges of Using LLM-Derived Synthetic Personas", "content": "As discussed by Kapania et al. (2024), there are a number of challenges in using LLMs as synthetic personas (users). LLMs are a consolidation over human experience, and hence they combine multiple viewpoints, failing to represent the diversity of human experience or correlations between different aspects of individuals. They can also lack depth: for instance, they can make references to particular phenomena (e.g., sleep difficulties in our test domain), but these phenomena do not represent situated knowledge, grounded in lived experience and history. This makes it difficult to model human users, since the relevant reasons for the health conditions might be missing. We mitigate this issue with the option of adding backstories, which have been shown to provide grounding to LLM-generated output (Moon et al., 2024).\nTraining data may also be biased as they were drawn largely from English-speaking cultures and individuals with strong online presence. To demonstrate the issue in the domain of sleep disorders, a survey of 27,000 US adults revealed that difficulty in falling and in staying asleep occurs more commonly among residents in non-metropolitan areas, and for those on lower incomes (Adjaye-Gbewonyo et al., 2022). We address this bias by specifying persona statistics drawn from relevant demographic health studies (e.g., Yfantidou et al., 2022; Arges et al., 2020), rather than relying on generation by the LLM.\nA further subtle risk of using LLMs in simulating synthetic users can be understood from a causal inference perspective, as discussed in Gui and Toubia (2023). Providing particular advice to an LLM (e.g., a recommendation regarding better sleep practices) can inadvertently cause unintended variation in other factors (e.g., the LLM's beliefs about the age and lifestyle factors of the synthetic persona). We mitigate this effect through explicit control over demographic and personality factors that that the LLM might otherwise incorrectly impute, a practice recommended by Gui and Toubia (2023), although this remains an ongoing research challenge."}, {"title": "3 Methods", "content": "While LLMs trained on a large data corpus (e.g., the entire Internet) partially represent the general human population, the distributions of subpopulations and health conditions represented in a single model are skewed and poorly understood (Kapania et al., 2024). Furthermore, the instruction fine-tuning step (e.g., reinforcement learning with human feedback) typically employed by high-performance LLMs further impacts the distribution of generated outputs. In this work we propose an end-to-end framework for generating synthetic users grounded in reality, by starting from human user data including demographics, health & lifestyle, and behavioral & psychological characteristics, to accurately represent a desired population. This real cohort can be sampled either uniformly, or with oversampling or undersampling explicitly designed by researchers (e.g., to better surface underrepresented subgroups or conditions). Given this sampled cohort, we optionally add additional health conditions conditioned on already specified attributes of the synthetic users, either using the LLM or via a rule-based algorithm, and also optionally add rich backstories of the synthetic user, conditioned on existing attributes (Moon et al., 2024).\nThis combination of background information grounded in real data constitutes a \"vignette\" of the synthetic user, all based in natural language. In the following sections we explore how these vignettes can be used to generate interactions between synthetic users and coaching agents, in two separate health coaching scenarios: sleep coaching and diabetes coaching, with two independently developed coaching agents."}, {"title": "4 Experiments: Sleep Coaching", "content": "Sleep is vital for health and well-being; insufficient sleep and untreated sleep disorders can have a detrimental effect on cognitive function, mood, mental health, and cardiovascular, cerebrovascular, and metabolic health (Ramar et al., 2021). Sleep disorders are highly prevalent: according to the 2020 National Health Interview Survey (NHIS) (Adjaye-Gbewonyo et al., 2022), 14.5% of US adults had trouble falling asleep most days over the 30-day study period, and over a quarter of adults do not meet the minimum recommended sleep duration per night."}, {"title": "4.1 Synthetic Users with Sleep Conditions", "content": "To generate synthetic users grounded in real sleep conditions, we utilized the publicly available LifeSnaps dataset, a multi-modal, longitudinal, geographically-distributed dataset containing participant demographics, smartwatch measurements including sleep data, health, behavioral, and psychological trait surveys, and ecological momentary assessments (Yfantidou et al., 2022). Among the fields available in this dataset, we focused on basic demographics (age, gender), basic health & sleep attributes (body mass index, sleep duration & efficiency), and five personality markers from the International Personality Item Pool (IPIP) version of the Big Five (Goldberg, 1992). Importantly, given longitudinal sleep data over four months in LifeSnaps, we included both the average sleep duration and the variability of sleep duration, both important health factors. See Appendix A for more details.\nAs outlined in Figure 1, we generated a synthetic \"sleep profile\" for each individuals in LifeSnaps (N=68) conditioned on real demographics, sleep duration & efficiency, and behavioral characteristics. The generated sleep profile consists of the following four key attributes: \u201cprimary sleep concern", "sleep goals\u201d, \u201creasons for goals\u201d, and": "arriers", "vigenettes": "or our synthetic users with sleep conditions.\nFinally, we instantiated each synthetic user in Concordia (Vezhnevets et al., 2023), specifically as a \"SimpleLLMAgent\" to prioritize clarity and reproducibility, where the entire conversation history and the synthetic user's backstory are included within the prompt context for generating each subsequent utterance (Appendix B)."}, {"title": "4.2 The Sleep Coaching Agent", "content": "We used a sleep coaching agent based on Christakopoulou et al. (2024), which proposed a two-agent system consisting of a \u201cTalker\u201d and a \u201cReasoner\" agent. Inspired by Kahneman (2011), the Reasoner (\"System 2\u201d) is responsible for generating an internal model of the use based on conversation history, in addition to planning and calling tools, while the Talker (\u201cSystem 1\") is responsible for generating conversation based on the structured state generated by the Reasoner. We used Gemini 1.5 Pro (Gemini Team, 2024) as the LLM engine for both constituent agents.\""}, {"title": "4.3 Evaluating Agent-Synthetic User Interactions in Sleep Coaching", "content": "Explicit modeling of the user in the sleep coaching agent enabled us to compare the internal user state to the \"true\" sleep profile we explicitly assigned to the synthetic user. After a 10-turn interaction between a synthetic user and the coaching agent, the coaching agent was able to identify the synthetic user's primary sleep concern with 89.7% accuracy (Figure 2). For barriers and sleep goals, which are also explicitly modelled by the coach agent and consist of multiple items (natural language sentences) per user, we computed recall (sensitivity) and precision, as measured by the proportion of the true attributes also captured by the coaching agent's model, and the proportion of the attributes in the coaching agent's model that were present in the true attributes, respectively. When matching sentences, we used fuzzy-matching by a high-performance, instruction-tuned LLM (Gemini 1.5 Pro; Gemini Team (2024)), to account for paraphrasing (e.g. \"inconsistent sleep duration\" and \"variable sleep duration\"; Appendix D), and manually checked a random subset (10 individuals) to make sure the answers were consistent with human answers (an easy task for modern LLMs). We obtained 71.4% mean recall and 72.5% mean precision for the barriers, and 66.4% mean recall and 84.2% mean precision for the sleep goals (Figure 2).\nFinally, to validate our use of synthetic users with health and behavioral/psychological attributes in addition to basic demographic information, we conducted a human expert evaluation of interactions from two synthetic users: one from our full synthetic user pipeline and another from using demographics-only data without health conditions, with the same sleep coaching agent. We asked human evaluators, with training and quality control conducted by a clinical psychologist, to annotate their preference between two interactions with each synthetic user, with 5\u00d7 coverage of each question. The evaluators overwhelmingly favored our full synthetic users over the baseline and the differences were highly statistically significant (p-value = 3.7 \u00d7 10-12 by one-tailed test under binomial null distribution), with high inter-rater reliability (64% of the cases achieving the complete 5/5 agreement and 91% of the cases achieving 4/5 agreement or more) (Figure 3)."}, {"title": "5 Experiments: Diabetes Coaching", "content": "Diabetes mellitus, commonly referred to as diabetes, is a highly prevalent chronic disease, affecting 15% of all US adults in 2021 (CDC, 2024). Understanding lifestyle barriers is crucial for effectively addressing the challenges this condition presents (Deslippe et al., 2023). The barriers significantly impact an individual's ability to adhere to recommended behaviors and achieve optimal health outcomes. Many barriers are intricately driven by demographic, socioeconomic, and clinical circumstances, collectively manifesting into specific challenges. By accurately representing these interconnections, we can create synthetic user profiles that faithfully reflect the real-world complexities encountered by individuals with cardiometabolic conditions, thereby enhancing the realism and applicability of our synthetic users interacting with a diabetes coaching agent (Figure 1)."}, {"title": "5.1 Synthetic Users with Diabetes", "content": "To obtain a representative distribution of cardiometabolic barriers, we leveraged insights from 100 peer-reviewed articles in Yang et al. (2024), which comprehensively identified 246 challenges encountered by cardiometabolic patients, in consultation with behavioral experts. The challenges were classified into six distinct sub-categories within the COM-B (capability, opportunity, motivation - behavior) model, a widely recognized framework for understanding behavior in healthcare (Michie et al., 2011). The challenges were again categorized into 21 distinct barrier concepts by behavioral experts, each belonging to a sub-category within the COM-B model, as shown in Appendix E. Through this process, we ensured that the synthetic user profiles developed for simulated coaching agent interactions were representative, reflecting the appropriate distribution of challenges.\nTo derive our synthetic users with diabetes, we utilized Project Baseline Health Study (PBHS), a longitudinal cohort with diverse backgrounds representative of the entire health spectrum (Arges et al., 2020).\u00b9 After careful preprocessing (Appendix G), we obtained a cohort of 345 Type 2 diabetic individuals with diverse demographic, social, medical, and health attributes (Appendix H).\nTo construct realistic vignettes of synthetic users from this cohort, we first sampled a COM-B category under its original distribution in PBHS (Appendix F), and then uniformly sampled a specific barrier within the selected COM-B category. Using this identified barrier, we randomly selected a corresponding individual from PBHS with relevant symptoms. The selected individual's demographic, socioeconomic, clinical, and behavioral survey data formed the foundation of our natural language vignette (Figure 1). To enhance the narrative quality, realism, and depth of these vignettes, a coherent backstory was generated by an LLM, incorporating the identified barrier (Appendix J). Finally, we generated a communication style field (e.g. tone, verbosity, and confidence) to compose the final vignette. Notably, the specific technical term for the selected barrier was not included in the vignette, since human users are unlikely to label themselves under it. In total, 200 vignettes for synthetic users were generated using the commercially available Gemini 2.0 Flash model chosen for its reasoning and conversation capabilities (Pichai, 2024)."}, {"title": "5.2 The Diabetes Coaching Agent", "content": "The synthetic users generated from the vignettes interacted with a diabetes coaching agent, building upon methodologies developed by Yang et al. (2024). This coaching agent was constructed to assist users to set health goals and overcome identified barriers. After each simulated interaction, the coaching agent was asked to identify one of the 21 barriers in its modeling of the user. Both the synthetic users and the coaching agent were generated using Gemini 1.5 Pro (Gemini Team, 2024).\nThe data use was formally approved by our institution's internal review committee, ensuring ethical compliance."}, {"title": "5.3 Evaluating Agent-Synthetic User Interactions in Diabetes Coaching", "content": "To assess the fidelity and reliability of the synthetic users, we solicited evaluations from a panel of three experts, comprising behavioral scientists and patient care practitioners (Appendix K). Each expert received 25 randomly-selected simulated interactions (out of 200) for assessment. Experts agreed that the synthetic users were highly consistent (92%) and effectively demonstrated the barriers they were designed to portray (100%) (Figure 4; Appendix L).\nSimilarly to our sleep coaching evaluation experiments (Section 4.3), we also conducted a secondary experiment comparing our synthetic users to baseline synthetic users generated from general demographic data only, without the PBHS data and the COM-B barriers that our methodology uniquely provides, in their interactions with the same coaching agent. After randomly selecting an individual from PBHS, the baseline synthetic user was generated from their standard demographic information, while our full synthetic user had the same standard demographics, richer health data, and the individual's original barrier (Appendix I). Both synthetic users were asked to portray an individual with cardiometabolic health challenges, and we ensured both possessed the same standard demographic data, communication style, verbosity, and confidence, for a fair comparison.\nHuman annotators were assigned three evaluation questions (Appendix M) to annotate randomly selected interactions without actual vignettes, testing implicit demonstration of the vignettes through conversations. 75 pairs of interactions (full synthetic users and baseline synthetic users) were evaluated (Figure 5).\nFor consistent representation of a single barrier (correct or not), annotators preferred the interac-"}, {"title": "6 Conclusion", "content": "We designed an end-to-end framework for generating synthetic users for evaluating coaching agents grounded in health, lifestyle, behavioral, and psychological attributes complementing basic demographics from human data. The additional sampling process was employed to ensure that the distribution of these attributes could be explicitly controlled (i.e., to ensure applicability to less represented sub-populations). Realistic backstories and additional health conditions (where not available in human user data) were conditionally generated from the grounded data. The final vignettes generated by this framework were used in a generative agent-based model framework to effectively simulate interactions between the synthetic users and the given coaching agent. We evaluated our methods in two independent, highly prevalent health coaching use cases of sleep coaching and diabetes management.\nEfficient development of autonomous agents is significantly accelerated by evaluation metrics that can be computed without complete dependence on human users, since human evaluation is costly and time-consuming. While there is a large body of literature on the design of general-purpose synthetic users in this setting (see Section 2), we have highlighted the importance of grounding synthetic users' health and behavioral attributes on a real human dataset, with concrete demonstrations and evaluations of our end-to-end pipeline in two independently developed coaching agents. While some of our demonstrations relied on access to the coaching agents' internal user model, the simulated interactions generated by our framework can be evaluated in a way that is agnostic to the design of the agent, so the framework can be applied to any conversational agents.\nThe extensive, realistic, and grounded simulated interactions developed from our proposed framework lay the foundation for efficient development of coaching agents, potentially through a fine-tuning or reinforcement learning loop, as will be pursued in future research."}, {"title": "Limitations", "content": "This work introduced an end-to-end framework for evaluating a coaching agent using automated synthetic users. The ultimate goal of performing this evaluation is to improve the coaching agent itself using the metrics and signals derived from this work, which is left for future research. The coaching agents we evaluated in this work may not have the \"state-of-the-art\" performance, as that was not the focus of this paper. We also did not compare multiple commercial LLMs, as that was also not the focus of this paper.\nIn evaluating coaching agents, a longitudinal assessment of potential behavioral change is crucial. Effectively and realistically simulating synthetic users' behavioral change is a critical open question to be addressed, including modeling non-adherence to coaching advice (e.g., human users may not follow the advice, or may claim they changed their behavior, even if they did not).\nPersonalization and adaptation of coaching and other agents are very important and relevant topics that are beyond the scope of this paper. We hope that grounded, rich, and diverse personas of synthetic users we developed in this work will significantly support the process of evaluating and improving personalized agents adapting to evolving user behaviors and needs."}]}