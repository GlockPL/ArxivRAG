{"title": "EVALUATING HUMAN-AI COLLABORATION: A REVIEW AND METHODOLOGICAL FRAMEWORK", "authors": ["George Fragiadakis", "Christos Diou", "George Kousiouris", "Mara Nikolaidou"], "abstract": "The use of artificial intelligence (AI) in working environments with individuals, known as Human-AI\nCollaboration (HAIC), has become essential in a variety of domains, boosting decision-making,\nefficiency, and innovation. Despite HAIC's wide potential, evaluating its effectiveness remains\nchallenging due to the complex interaction of components involved. This paper provides a detailed\nanalysis of existing HAIC evaluation approaches and develops a fresh paradigm for more effectively\nevaluating these systems. Our framework includes a structured decision tree which assists to select\nrelevant metrics based on distinct HAIC modes (AI-Centric, Human-Centric, and Symbiotic). By\nincluding both quantitative and qualitative metrics, the framework seeks to represent HAIC's dynamic\nand reciprocal nature, enabling the assessment of its impact and success. This framework's practicality\ncan be examined by its application in an array of domains, including manufacturing, healthcare,\nfinance, and education, each of which has unique challenges and requirements. Our hope is that this\nstudy will facilitate further research on the systematic evaluation of HAIC in real-world applications.", "sections": [{"title": "1 Introduction", "content": "The fast advancement of Artificial Intelligence (AI) has fundamentally transformed several domains, blurring the\ndistinctions between human and machine roles and giving rise to new interactions [1]. The notion of Human-AI\nCollaboration (HAIC) has emerged as a pivotal framework, as evidenced by the research conducted by [2] and [3].\nThese studies identify that HAIC has significant potential for enhancing decision-making, increasing efficiency, and\nfostering innovation. They therefore aim at fostering and facilitating effective cooperation between people and AI\nsystems to achieve common goals. On the other hand, assessing the benefits of this cooperation presents its own\nchallenges, owing to the multiple complex factors involved.\nTraditional Human-Machine evaluation frameworks have primarily focused on quantifiable metrics such as task\nperformance, response time, and user satisfaction within human-machine systems [4, 5]. These frameworks typically\nview the machine as a tool and assess how effectively humans can control or interact with this tool to achieve desired\noutcomes.\nHuman-AI Collaboration (HAIC) represents a significant change in which humans and AI work together in a more\nintegrated and mutually beneficial manner. HAIC focuses on more than just human dominance over machines;\nit emphasizes a collaborative partnership where individuals and AI systems actively contribute to shared results.\nThe significance of this partnership has been highlighted in several domains, such as manufacturing [6, 7], financial\nservices [8, 9], healthcare [10, 11], education [12], and others, demonstrating notable advancements in both technological\ninnovation and practical implementation [13, 14].\nHAIC is defined by the process of making decisions together, learning from each other, and adapting, which requires a\nmore comprehensive and nuanced evaluation approach [15, 16]. To effectively evaluate HAIC, it is crucial to consider"}, {"title": "2 Understanding the Fundamentals of Human-AI Collaboration", "content": ""}, {"title": "2.1 From Human-Machine Interaction to Human-AI Collaboration", "content": "Given the rapid pace of advancements in Human-AI Collaboration (HAIC), a comprehensive understanding of the\ncurrent landscape is essential. While foundational research in Human-Machine Interaction (HMI) provides valuable\ninsights into human-technology interactions, it often falls short when applied to HAIC evaluations. Traditional\nHMI methods, as exemplified in the works of Nielsen [20], Shneiderman [21], and Norman [22], primarily focus\non assessing the usability and effectiveness of tools or interfaces designed to augment human performance. These\nmethods often rely on metrics such as task completion time, error rates, and user satisfaction to gauge the success of\nhuman-machine interactions. However, these metrics are not always sufficient to capture the complexities of HAIC,\nwhere the relationship between humans and AI is more dynamic and collaborative. For example, traditional metrics\nmay not adequately assess the level of trust a human places in an AI system's recommendations or the effectiveness of\nshared decision-making processes where both the human and AI contribute to the final outcome [23]. Additionally,\nthese metrics may not fully capture the adaptability of AI systems, which is crucial for HAIC as the AI needs to learn\nand adjust its behavior based on human input and changing circumstances [24]. To effectively evaluate HAIC, we\nmust move beyond the limitations of traditional HMI approaches. We need to consider not just the performance of the\nindividual components (human and AI) but also the quality of their collaboration, the fluidity of their interactions, and\nthe achievement of shared goals. This necessitates a broader range of metrics and methodologies that can capture the\nnuances of these complex partnerships."}, {"title": "2.2 Elements of HAIC", "content": "Human-AI Collaboration (HAIC) is the cooperative partnership between individuals and artificial intelligence (AI)\nsystems in order to accomplish common goals.\nSeveral key elements define the landscape of HAIC:\n\u2022 Tasks: HAIC systems can be designed to tackle a wide array of tasks, from complex decision-making to\ncreative endeavors and knowledge work. The nature of these tasks often dictates the level and type of"}, {"title": "2.3 Modes of Human-AI Collaboration", "content": "One can use any of the HAIC elements, i.e., tasks, goals, types of interaction, and task allocation to differentiate\nbetween different HAIC methods. For the purposes of evaluation, however, perhaps the most useful distinction is in\nterms of allocation [29]. We identify three modes, namely AI-centric, Human-centric, and Symbiotic, which are further\ndescribed below."}, {"title": "Human-Centric Mode", "content": "In the Human-centric mode, humans retain the primary decision-making authority, utilizing AI as an augmentative tool\nto enhance human capabilities without superseding the human role. This mode values human intuition and oversight,\nwith AI employed to manage data-intensive or repetitive tasks. It optimizes the unique cognitive abilities of humans for\nstrategic and ethical decision-making while leveraging AI to augment human capabilities.\nSupporting this mode, Sutthithatip [30] highlights the use of Explainable AI (XAI) in high-stakes sectors like aerospace\nto demystify complex AI operations, thereby enhancing human decision-making. Additionally, How et al. [31] describe\nthe integration of AI in sustainable development, which facilitates the involvement of non-experts in data-driven policy\nmaking, illustrating the supportive role of AI in enhancing human capabilities."}, {"title": "Symbiotic Mode", "content": "The Symbiotic mode represents a balanced partnership where humans and AI systems collaborate closely, mutually\nenhancing each other's capabilities. This mode is characterized by a two-way interaction, shared decision-making, and\na continuous exchange of feedback, aiming to achieve collective goals through a synergistic relationship. This mode is\nparticularly relevant in complex tasks where both human intuition and AI's computational capabilities are essential for\noptimal outcomes.\nStudies like those by Cesta et al. [32] explore the symbiotic integration of AI in operational settings, enhancing the\ncollaborative dynamics between humans and robots. Moreover, Jokinen & Watanabe [33] emphasize the crucial role of\ntrust in these interactions, which is fundamental for a successful symbiotic relationship. Mahmud et al. [34] and Sowa\net al. [35] further illustrate how symbiotic HAIC can revolutionize creative fields and managerial roles by combining\nhuman creativity with AI's analytical strengths to foster innovation and improve decision-making.\nA key example of the symbiotic mode is the Learning to Defer paradigm. This paradigm designs AI systems to\nunderstand their own limitations, knowledge, and expertise. Whether confronted with ambiguity or circumstances in\nwhich their confidence in a decision is low, the AI system proactively defers to human judgment [36]. Several studies\nhave explored this concept in depth. Mozannar and Sontag (2020) [37] proposed a Bayesian framework that emphasizes\nthe integration of human and machine predictions. It is crucial to consider potential biases in both agents. This approach\naligns with a collaborative decision-making approach because it strives for optimization. It is possible to make decisions\nby leveraging the strengths of both humans and AI. In a similar way, Mao et al. (2023) [38] extended this concept\nto scenarios with multiple experts, highlighting the flexibility required in real-world HAIC systems, where multiple\nsources of expertise may be available. Their work underscores the adaptability of the HAIC systems' participants,\nshowcasing the ability to dynamically modify task allocation according to the availability and expertise of various\nagents."}, {"title": "AI-centric Mode", "content": "The AI-centric mode designates AI as the primary agent in the collaboration, where the AI system leads decision-making\nprocesses and operates with minimal human intervention. This mode often features automated interactions where the\nAl executes tasks independently, aimed at enhancing system capabilities and overall efficiency. Such a setup focuses on\nimproving AI functionalities, maximizing system efficiencies, and generally involves a one-directional interaction from\nAI to human, primarily concentrating on tasks suited for AI's computational abilities.\nRecent research underscores the evolving role of AI in traditional human-machine settings. Liu and Zhao [39] discuss\nthe allocation of roles in Human-Machine Collaboration (HMC), advocating for optimal strategies that seamlessly\nintegrate intelligent systems into human-centric operations. Similarly, Wang et al. [40] examine the shift from human-\nhuman to human-AI collaboration, stressing the importance of mutual goal setting and collaborative task management\nto foster effective partnerships.\nIn this section, we looked at the fundamentals of Human-AI Collaboration, such as its main components and the various\nmodes of operation. Evaluating HAIC is critical to ensuring that these systems are successful, efficient, and ethical.\nThe following part looks into the literature on HAIC evaluation, reviewing existing approaches and identifying gaps\nthat suggest areas for further research."}, {"title": "3 Evaluation of Human-AI Collaboration in the Research Literature", "content": "The evaluation of Human-AI Collaboration (HAIC) is essential to understanding the efficacy of these systems, identifying\nareas for improvement, and ultimately unlocking their full potential. This section examines current evaluation approaches\nin HAIC research. While Table 1 provides an overview of a diverse sample of studies across different domains, the\nanalysis in this section will focus on selected key references to illustrate specific evaluation methodologies and their\nimplications.\nThrough this analysis of a wide array of studies, our objectives are as follows:\n\u2022 Examine the advantages and drawbacks of current evaluation methodologies.\n\u2022 Identify the distinct difficulties presented by various HAIC applications and domains.\n\u2022 To effectively address the intricate and diverse aspects of HAIC in different sectors."}, {"title": "3.1 Advancements in Evaluation Frameworks", "content": "Human-AI Collaboration is being judged by a more traditional metrics. These include ethical concerns, the ability to\nscale and the ability to adapt different domains.\nDellermann et al. (2021) [25] propose a classification system for hybrid intelligence, emphasizing the importance of\nunderstanding the nature of tasks and the dynamic relationship between humans and AI. To categorize different types of\nHAIC systems, their framework takes into account factors such as level of autonomy, task interdependence, and degree\nof human control. This classification scheme serves as a foundation for developing tailored evaluation approaches that\naddress the unique characteristics of each type of collaboration.\nThe incorporation of ethical factors into evaluation frameworks is a growing trend, as evidenced by the work of Huang\n& Rust (2022) [67] in marketing and Nasir, Khan, & Bai (2023) [74] in healthcare. These frameworks emphasize\nthe importance of transparency (e.g., disclosing the use of AI in decision-making), fairness (e.g., mitigating bias in\nalgorithms), accountability (e.g., establishing clear lines of responsibility for AI-related outcomes), and human-centered\ndesign (e.g., prioritizing user needs and values) in AI implementation. Lase & Nkosi (2023) [75] further advocate for\na Human-centric perspective in AI development, stressing the significance of aligning AI systems with user values\nand ethical principles. They propose using surveys and interviews to assess user perceptions of fairness, trust, and the\nimpact of AI on their work.\nBojic et al. (2023) [76] highlight the need for standardized and robust evaluation practices, proposing a hierarchical\nframework to guide the design of reliable human evaluations of AI systems. This framework outlines a step-by-step\nprocess for defining evaluation objectives, selecting appropriate metrics (e.g., accuracy, efficiency, user satisfaction),\ndesigning experimental protocols, and analyzing data to draw valid conclusions about the effectiveness of HAIC."}, {"title": "3.2 Advancements in Evaluation Tools and Methodologies: Enabling Real-time Insights and Adaptive\nCollaboration", "content": "Technological advancements are transforming the landscape of HAIC evaluation, enabling real-time monitoring,\nadaptive collaboration, and deeper insights into human-AI interactions.\nAI-powered analytics and real-time monitoring tools, discussed by Wang et al. (2019) [77], are enhancing the precision\nand responsiveness of HAIC evaluations. These tools can automatically track key performance indicators (KPIs) such\nas completion time, error rates, and user interactions, providing immediate feedback on collaboration efficacy and\nenabling timely interventions for improvement.\nAdvancements in interactive machine learning (iML) interfaces, explored by Saha et al. (2023) [78], are fostering grater\ntransparency and user understanding. By providing explanations for AI-generated recommendations and allowing\nusers to adjust system parameters, iML interfaces can improve user comprehension, trust, and satisfaction, ultimately\ncontributing to a more effective and collaborative partnership between humans and AI. Saha et al. [78] evaluate the\neffectiveness of iML interfaces using a combination of user surveys, interviews, and task-based performance metrics."}, {"title": "3.3 Analysis of Existing Approaches", "content": "In Table 1, we show a summary of Human-AI Collaboration (HAIC) evaluation practices we examined for this\nanalysis. While quantitative methods remain dominant, there is a growing recognition of the value of qualitative\nand mixed-methods approaches for capturing the complex interplay between objective performance and subjective\nexperiences.\nQuantitative Focus: Objectivity and Measurable Outcomes\nQuantitative evaluations, prioritizing objective measures to gauge system performance and efficacy,including the\ncombination of humans and AI, are prevalent in HAIC research. In the medical field, Vollmuth et al. (2023) [41] and\nVan Leeuwen et al. (2022) [42] use tests like sensitivity, specificity, precision, recall, and F1-score to carefully check\nhow well AI-assisted tools in oncology and radiology can make diagnoses. To compare how well AI can find fraud in\nthe financial world, Al-Fatlawi et al. (2023) [54] use detection rates (true positives and false positives), and Sachan et al.\n(2024) [68] use quantitative measures to reduce decision noise in financial underwriting. Manufacturing studies, such\nas those by Sankaran et al. (2022) [59] and Massaro (2022) [60], also rely heavily on quantitative metrics to assess\nprocess performance and safety compliance, respectively. Researchers have developed quantitative frameworks to\nassess performance in diverse fields such as game-based AI (Siu et al., 2021) [47] and neuromorphic computing (Yik et\nal., 2024) [50] based on specific domain-relevant metrics."}, {"title": "Qualitative Insights: Illuminating the Subjective Dimension", "content": "To complement the quantitative focus, a growing number of studies are embracing qualitative methods to delve into\nthe subjective experiences of users and stakeholders. Timmons et al. (2023) [43] investigate biases in mental health\nAI through interviews and case studies, shedding light on potential ethical concerns and user perceptions. Their study\nreveals potential ethical concerns, such as the perpetuation of biases and the varying levels of trust users place in AI\nsystems. Rezwana et al. (2023) [46] and Verheijden & Funk (2023) [46] use qualitative assessments in the design\nfield to understand the impact of generative AI on creativity and design co-creation processes. Through focus group\ndiscussions and in-depth interviews with designers, these studies highlight how generative AI tools influence creative\nworkflows. They discovered that while AI can enhance creative output by providing novel ideas, it also raises concerns\nabout authorship and originality, which are critical to the design profession.\nSharma et al. (2023) [49] look at how conversational empathy improves in mental health applications using qualitative\nmeasures. Reddy et al. (2021) [48] suggest a qualitative framework for evaluating the use of AI in healthcare, with a\nfocus on ethical issues and user perspectives. Their framework includes structured interviews with healthcare providers\nand patients, and thematic analysis to identify key concerns such as data privacy, trust in AI diagnoses, and the perceived\nimpact on the patient-provider relationship. Their study underscores the necessity for AI systems to align with ethical\nstandards and user expectations to be effectively integrated into healthcare practices.\nBy capturing the nuanced perspectives of users and stakeholders, these qualitative studies offer a rich understanding of\nthe human factors that shape the adoption and impact of HAIC. However, the subjective nature of qualitative data can\npose challenges in terms of generalizability and require substantial resources for data collection and analysis."}, {"title": "The Mixed-Methods Promise: Towards a Holistic and Contextualized Evaluation", "content": "The limitations of purely quantitative or qualitative approaches have spurred the adoption of mixed-methods evaluations,\naiming to capture both objective performance and subjective experiences in a comprehensive manner.\nDomain-Specific Applications In the realm of design and art, Arias-Rosales (2022) [63] combines quantitative\nshape generation metrics with qualitative assessments of perceived value by designers. Their study uses quantitative\nmetrics to measure the efficiency and novelty of AI-generated shapes, while also conducting interviews and surveys\nwith designers to gather insights on the aesthetic value and usability of these shapes. This approach revealed that\nwhile AI-generated designs were technically innovative, the perceived value varied significantly among designers,\nhighlighting the importance of subjective aesthetic judgment in evaluating creative outputs.\nSimilarly, in finance, Chakravorti et al. (2022) [66] integrate quantitative detection rates with qualitative assessments of\ntrust and perception to evaluate the efficacy of AI prediction markets. They employ quantitative methods to analyze\nthe accuracy and reliability of AI predictions in financial markets, alongside qualitative interviews and surveys with\ntraders and financial analysts. The study found that despite high detection rates, the trust in AI predictions varied, with\nqualitative data uncovering concerns about the transparency and interpretability of AI algorithms.\nGeneralizable Frameworks Yang et al. (2022) [55] look into how AI can model human behavior using both\nquantitative and qualitative data. They use quantitative metrics such as task completion rates and error frequencies to\nevaluate AI performance, while also gathering qualitative data through user interviews and behavioral observations.\nV\u00f6ssing et al. (2022) [79] study includes quantitative measures of system accuracy and user performance metrics,\ncoupled with qualitative trust assessments obtained from user interviews and surveys. The combination of these methods\nrevealed that transparency significantly impacts user trust and acceptance, even when the AI system's performance is\nobjectively high.\nHuang & Rust (2022) [67] propose a mixed-methods framework for collaborative AI in marketing, acknowledging the\nimportance of both performance and ethical considerations.These mixed-methods techniques provide the possibility for\na comprehensive and contextual evaluation of HAIC, recognizing the intricate relationship between objective measure-\nments and subjective perceptions. They employ quantitative analytics to measure marketing campaign performance\nmetrics, such as click-through rates and conversion rates, while also using qualitative methods like focus groups and\nin-depth interviews to assess ethical concerns and user satisfaction. This dual approach provides a comprehensive\nevaluation of the AI's effectiveness and its alignment with ethical standards."}, {"title": "3.4 The domain-specific challenges necessitate a tailored evaluation", "content": "The application domains for HAIC are diverse, each presenting unique challenges that necessitate tailored evaluation\napproaches. These challenges stem not only from the technical complexities of integrating AI into different workflows,\nbut also from the varying priorities and expectations of stakeholders in different sectors. As a result, the evaluation\nmethods employed across HAIC research vary significantly, reflecting the need to adapt assessment strategies to the\nspecific context of each domain.\nHealthcare: Prioritizing Accuracy, Safety, and Ethical Considerations In the healthcare sector, ensuring diagnostic\naccuracy and patient safety is paramount. To find out how well AI-assisted tools work in oncology and radiology,\nstudies like Vollmuth et al. (2023) [41] and Van Leeuwen et al. (2022) [42] use numbers like sensitivity, specificity,\nand outcome improvements. However, the high-stakes nature of medical decisions and the potential for unintended\nconsequences necessitate additional layers of evaluation. Qualitative approaches like interviews and focus groups\n(Fari\u0107 et al., 2024 [14]; Calisto et al., 2022 [45]) can capture user perceptions, identify potential biases (Timmons et al.,\n2023 [43]), and ensure that AI systems are implemented in a way that aligns with ethical principles and patient values\n(Reddy et al., 2021 [48]).\nCreative Arts: Balancing Creativity, User Experience, and Ethical Impact In the creative arts, HAIC evaluation\noften requires a different approach. While quantitative metrics can measure the technical performance of AI systems,\nsuch as the speed or accuracy of generating artistic outputs, qualitative methods such as interviews, user feedback,\nand case studies are crucial for comprehending the influence of AI on creativity, collaboration, and the overall design\nprocess (Rezwana et al., 2023 [46]; Verheijden & Funk, 2023 [57]). Additionally, ethical considerations, such as the\npotential for AI to perpetuate biases or undermine the role of human creativity, necessitate careful evaluation through\nqualitative assessments and critical analysis. Moreover, the cooperative aspect of HAIC plays a crucial role in enhancing\nhuman creativity, since AI's data-driven insights stimulate inventive solutions [80].\nFinance: Mitigating Risks, Ensuring Trust, and Balancing Quantitative and Qualitative Insights The financial\nsector employs a mix of quantitative and qualitative methods to address HAIC's unique challenges in this domain.\nQuantitative metrics like detection rates and false positives are crucial for evaluating the effectiveness of AI in fraud\ndetection (Al-Fatlawi et al., 2023 [54]). However, understanding the impact of AI on decision-making processes, investor\ntrust, and market stability requires qualitative insights through surveys, interviews, and case studies (Chakravorti et al.,\n2022 [66]). Mixed-methods approaches, which combine quantitative and qualitative data, offer a more comprehensive\nunderstanding of the complex interactions between humans, AI, and financial markets.\nIn summary, the review of evaluation approaches demonstrates significant variation in collaboration methods, domain-\nspecific challenges, and methodological approaches. However, one significant obstacle remains: the lack of a compre-\nhensive, mixed-methods evaluation framework that covers a wide range of industries. This gap restricts our ability to\ncompletely evaluate HAIC's effectiveness and maximize its potential across domains.\nThe Path Forward: A Unified Evaluation Framework to Bridge the Gap in HAIC Assessment\nThe analysis of existing approaches to HAIC evaluation reveals a landscape marked by diversity and fragmentation.\nQuantitative, qualitative, and mixed-methods approaches all give useful information, but the lack of a single, flexible\nframework makes it harder to get a full picture of how well HAIC works and what it can do in different fields.\nThis gap is particularly evident when considering the multifaceted nature of HAIC. Quantitative metrics, while essential\nfor measuring objective performance, often fail to capture the nuances of human-AI interaction dynamics, such as trust,\nsatisfaction, and ethical considerations. Qualitative methods, on the other hand, can provide rich insights into these\nsubjective experiences but may lack the rigor and generalizability of quantitative data.\nTherefore, it is imperative to develop a comprehensive, mixed-methods evaluation framework. This framework should\nbe adaptable across a broad spectrum of industries, accommodating the unique characteristics and challenges of\neach while providing a cohesive approach to assessing the effectiveness, challenges, and opportunities of HAIC. By\nintegrating objective performance metrics with subjective experiences, such a framework can offer a more nuanced\nunderstanding of how HAIC systems perform in real-world contexts and how they impact various stakeholders.\nThis unified framework would not only address the current methodological fragmentation but also facilitate cross-study\ncomparison, enhance the generalizability of findings, and promote standardized evaluation practices. It would enable\nresearchers, practitioners, and policymakers to make informed decisions based on a more holistic understanding of the\ncomplex interactions between humans and AI."}, {"title": "4 A Structured Framework for Human-AI Collaboration", "content": ""}, {"title": "4.1 Factors of Identifying the Human-AI Collaboration", "content": "Based on the previous discussion (Section 2) the evaluation of HAIC is centered around three primary factors: Goals,\nInteraction, and Task Allocation. These factors are critical for understanding and enhancing HAIC systems. While tasks\nthemselves are fundamental to HAIC, they are considered the context within which collaboration occurs, rather than a\ncore factor of the evaluation framework. The nature of the task will influence how the other three factors are approached,\nbut the tasks themselves are not directly evaluated by this framework. The literature highlights the importance of these\nfactors in evaluating HAIC.\nResearch by Li et al. [81] and Vossing et al. [65] underscores the significance of evaluating goals through metrics such\nas the learning curve and prediction accuracy. Studies by Hinsen et al. [82] and Amershi et al. [83] emphasize the need\nfor user friendly communication methods and clear interaction mechanisms for successful HAIC. Additionally, Xiong\net al. [84] stress the importance of measuring query efficiency and expertise utilization for effective task allocation.\nFollowing the identification of these primary factors, we further explore the subfactors and metrics that can be used\nto evaluate each factor. These subfactors and metrics are designed to provide a comprehensive understanding of the\neffectiveness, efficiency, and usability of HAIC systems. The structured framework presented here serves as a guide\nfor researchers, practitioners, and policymakers to evaluate and optimize HAIC systems across various domains and\napplications."}, {"title": "4.2 Subfactors & Metrics of the Framework", "content": "To promote further analysis and evaluation of the different types of interactions in HAIC, the three primary factors\nare further analyzed into measurable subfactors, which can be evaluated using a set of metrics. These are presented\nin Table 4.2. Following we provide a detailed description of the subfactors and metrics associated with each primary\nfactor. Please note that Table 3 summarizes all metrics discussed in this section, including their formal definition."}, {"title": "4.3 Building the Framework & Quantifying the Evaluation of HAIC", "content": "Building upon influential research by Fischer [115], Wenskovitch and North [89], and Sharma et. al [49], this framework\noffers a structured approach to Human-AI Collaboration (HAIC) evaluation. This is achieved using a decision tree\n(Fig. 2), that guides users through a series of questions to identify the most relevant metrics for their specific HAIC\nsystem. This combines the factors, subfactors, and metrics identified in the previous sections, based on the HAIC modes\ndescribed earlier in Section 2.3, i.e., AI-Centric, Human-Centric, and Symbiotic."}, {"title": "AI-Centric Collaboration", "content": "Questions in this mode emphasize the AI's autonomous capabilities and performance. We focus on efficiency metrics\n(like Model Improvement Rate) and uncertainty handling, as these are core challenges for AI systems operating\nprimarily independently. The AI-Centric mode is particularly relevant for systems where AI plays a dominant role in\ndecision-making, such as predictive analytics and automated systems.\nHow efficiently does the AI make decisions independently?\n\u2022 Learning Curve: Measures the rate of improvement in AI performance over time.\n\u2022 Model Improvement Rate: Measures improvement over time, indicating decision-making efficiency.\n\u2022 Query Efficiency: Evaluates how much information is gained with minimal queries.\n\u2022 Resource Utilization: Assesses how well the AI manages computing power.\n\u2022 Response Time: Tracks how quickly the AI makes decisions.\n\u2022 Real-time Performance: Evaluates the AI's ability to handle time-sensitive tasks.\n\u2022 Objective Fulfillment Rate: Measures the percentage of tasks successfully completed.\nHow well does the AI handle uncertainty?\n\u2022 System Accuracy: Measures overall performance, partially reflecting uncertainty handling."}, {"title": "Human-Centric Collaboration", "content": "Here, the questions center on how well the AI communicates with and supports the human user. Metrics like Clarity of\nCommunication and Ease of Use are essential for a positive user experience. The Human-Centric mode is particularly\nrelevant for systems where human input is crucial for decision-making, such as in creative fields or complex problem-\nsolving.\nHow clear and usable is the AI's communication?\n\u2022 Clarity of Communication: Directly assesses if queries and responses are understandable.\n\u2022 Ease of Use: Measures overall user satisfaction with the interaction.\n\u2022 User Satisfaction: Indicates if the AI's communication methods are acceptable to humans.\n\u2022 Frequency of Feedback: Quantifies the number of feedback instances.\nHow effectively does the AI support human tasks?\n\u2022 Teaching Efficiency: Gauges how much effort is needed to train the AI.\n\u2022 Error Reduction Rate: Quantifies how much the AI helps in reducing human errors.\n\u2022 Confidence: Measures user trust in the AI's recommendations.\n\u2022 Task Completion Time: Indicates if AI assistance makes tasks faster."}, {"title": "Symbiotic Collaboration", "content": "This mode's questions strike a balance between adaptability and task allocation. We ask about the system's flexibility in\nresponse to feedback (Adaptability Score) and the effectiveness of resource distribution, reflecting the collaborative\ncore of Symbiosis.\nHow easily does the AI adapt to human feedback?\n\u2022 Adaptability Score: A composite metric reflecting flexibility and responsiveness.\n\u2022 Strategy Adaptation Effectiveness: Measures how well the AI changes approaches based on input.\n\u2022 Feedback Quality: Assesses how valuable the provided human feedback is.\n\u2022 Feedback Impact: Shows the improvement resulting from human guidance.\nHow well are tasks allocated to optimize both human and AI strengths?\n\u2022 Dynamic Task Allocation: Reflects the ability to shift task distribution in real-time.\n\u2022 Query Efficiency: Assesses how well information is requested to leverage human expertise.\n\u2022 Expertise Utilization: Measures the degree to which human skills are leveraged.\n\u2022 Knowledge Retention: Evaluates if the AI learns effectively from human input.\n\u2022 Model Improvement Rate: Measures how much human input contributes to AI progress.\n\u2022 Decision Effectiveness: Indicates the impact of decisions on overall task success."}, {"title": "Advantages of the Decision Tree Approach", "content": "This methodology offers several benefits:\n\u2022 User-Friendly: Simplifies the evaluation process, making it accessible to users with varying levels of expertise.\n\u2022 Tailored Assessment: Ensures that the evaluation is relevant to the specific characteristics and goals of the\nHAIC system.\n\u2022 Adaptable Framework: Accommodates the evolving nature of HAIC technologies and practices."}, {"title": "Weighting Mechanism & Overall Score Calculation", "content": "While the decision tree and associated metrics lead the evaluation process, we recognize the importance of a weighting\nmechanism to provide a more comprehensive evaluation of HAIC effectiveness. This system would weight each metric\naccording to its relevance to the specific HAIC mode and the evaluation's criteria. For example, in an AI-Centric system,\naccuracy might be assigned a higher weight than user satisfaction. Conversely, in a Human-Centric system, ease of use\nand trust could be prioritized. In the Symbiotic mode, the weights might be distributed more evenly across metrics\nreflecting collaboration and mutual benefit.\nThe overall score for a HAIC system could then be calculated as the weighted average of the individual metric\nscores. However, determining appropriate weights requires further research and validation across different real - world\nparadigms.\nSeveral studies in the literature have utilized weighting mechanisms to evaluate complex systems. For example, Kamar et\nal. (2012) [116] employed a weighted approach to combine human and machine contributions in a crowdsourcing system,\nemphasizing the importance of weighting in achieving balanced evaluations. Similarly, Amershi et al. (2014) [83]\ndiscussed the role of weighting different interaction metrics to assess the effectiveness of human-AI collaboration tools,\nhighlighting how different priorities can shift the weighting schema.\nMoreover, Vossing et al. (2022) [65] implemented a weighting mechanism to balance transparency and performance\nin Al systems, demonstrating that context-specific weighting can enhance the evaluation's relevance and accuracy.\nThese examples underscore the practical value of weighting mechanisms and support their inclusion in our proposed\nframework.\nBy incorporating a validated weighting mechanism, our framework ensures a nuanced and context-sensitive assessment\nof HAIC systems, aligning with best practices in the literature. Future research should focus on refining these weights\nthrough empirical studies across various HAIC applications to enhance the robustness and applicability of the evaluation\nframework."}, {"title": "5 Implications of the HAIC Evaluation Framework to Real-World Domains", "content": ""}, {"title": "5.1 Manufacturing", "content": "The manufacturing industry's focus on safety, accuracy, and productivity closely corresponds with the Symbiotic mode\nof HAIC, which requires the collaboration of human expertise and AI skills to get the best results. This mode prioritizes\nmetrics like Adaptability Score and Confidence. Recent study highlights a shift from focusing primarily on productivity-\ncentered measures to a more worker-centric approach, placing greater emphasis on safety and trust. Research such\nas Rabby et al.'s (2020) [117] time-driven performance-aware trust model and Okamura and Yamada's (2020) [118]\nadaptive trust calibration approach exemplify this change. These works emphasize the importance of the Interaction\nfactor, specifically focusing on the subfactors of Communication Methods and Adaptability. They achieve this by\ncreating systems that can adapt to human actions and uncertainties. The primary emphasis of Amin et al.'s (2020) [119]\nmixed-perception method is on safety, which aligns with the Task Allocation factor's concentration on Complementarity\nand Mutual Support. This strategy involves the collaboration between human and AI systems to promote worker\nprotection. The focus placed by Ming Hou (2021) [120] on context-based interface design provides additional support\nfor the Symbiotic method. Our methodology proposes the following essential criteria for evaluating HAIC systems in\nmanufacturing: Adaptability Score, Error Reduction Rate, Confidence, and Task Completion Time. These measurements\nwill assess the systems' capacity to adapt to human operators, enhance safety, foster worker confidence, and ultimately\noptimize industrial processes."}, {"title": "5.2 Healthcare", "content": "The integration of AI in healthcare, particularly in medical imaging, often operates in a collaborative mode, where\nAI augments human expertise to achieve more accurate diagnoses. Although AI is highly effective in medical image\nclassification and segmentation ["}]}