{"title": "Minds on the Move: Decoding Trajectory Prediction in Autonomous Driving with Cognitive Insights", "authors": ["Haicheng Liao", "Chengyue Wang", "Kaiqun Zhu", "Yilong Ren", "Bolin Gao", "Shengbo Eben Li", "Chengzhong Xu", "Zhenning Li"], "abstract": "In mixed autonomous driving environments, accurately predicting the future trajectories of surrounding vehicles is crucial for the safe operation of autonomous vehicles (AVs). In driving scenarios, a vehicle's trajectory is determined by the decision-making process of human drivers. However, existing models primarily focus on the inherent statistical patterns in the data, often neglecting the critical aspect of understanding the decision-making processes of human drivers. This oversight results in models that fail to capture the true intentions of human drivers, leading to suboptimal performance in long-term trajectory prediction. To address this limitation, we introduce a Cognitive-Informed Transformer (CITF) that incorporates a cognitive concept, Perceived Safety, to interpret drivers' decision-making mechanisms. Perceived Safety encapsulates the varying risk tolerances across drivers with different driving behaviors. Specifically, we develop a Perceived Safety-aware Module that includes a Quantitative Safety Assessment for measuring the subject risk levels within scenarios, and Driver Behavior Profiling for characterizing driver behaviors. Furthermore, we present a novel module, Leanformer, designed to capture social interactions among vehicles. CITF demonstrates significant performance improvements on three well-established datasets. In terms of long-term prediction, it surpasses existing benchmarks by 12.0% on the NGSIM, 28.2% on the HighD, and 20.8% on the MoCAD dataset. Additionally, its robustness in scenarios with limited or missing data is evident, surpassing most state-of-the-art (SOTA) baselines, and paving the way for real-world applications.", "sections": [{"title": "I. INTRODUCTION", "content": "IN the evolving landscape of autonomous driving (AD) systems, the complex interactions between autonomous vehicles (AVs) and human-driven vehicles (HVs) present a significant challenge to achieving accurate trajectory prediction [1], [2]. The future trajectory of human-driven vehicles is essentially the result of the human driver's decision-making process [3], [4]. Since human drivers require reaction time to adjust their behavior when facing changes in the external environment [5]-[7], the dynamics of the vehicle will not change drastically in the short term, making short-term (\u2264 2 seconds) predictions relatively straightforward. Nevertheless, long-term prediction necessitates models that accurately estimate the impact of numerous factors on the decision-making process of human drivers, a feat that is particularly challenging to achieve [8]. Recent advancements in algorithms and the availability of driving datasets have led to significant breakthroughs in trajectory prediction [9]. However, the accuracy of long-term predictions (i.e., >2 seconds) remains a persistent challenge, primarily due to the inherent complexity of real-world driving scenarios. These challenges stem from the complex interactions between traffic agents, the impact of environmental factors like weather and road conditions, and the unpredictable nature of human driver behavior. These factors introduce significant uncertainty, making reliable long-term forecasts a persistent struggle for researchers in the field.\nThis backdrop prompts us to ask critical questions about the future trajectory of AD: Is the key to advancing AD not just in accumulating more data or refining algorithms, but in gaining a deeper understanding of the driving environment itself? How can we reshape our models to interpret and respond to the intricate human dynamics that underpin driving? Motivated by these questions, our research embarks on an innovative path. We propose a paradigm shift, extending beyond conventional data-driven approaches to embrace a critical yet often-neglected aspect of driving - the concept of perceived safety.\nThis concept, pivotal in shaping driving behaviors and decisions, is deeply rooted in psychological constructs, as detailed in [10]. According to the Theory of Planned Behavior, individual actions in driving are influenced by attitudes (driving behaviors towards others), subjective norms (personal evaluation of safety), and perceived behavioral control (confidence in driving ability) [11]. Further depth is added by neuroscientific research, such as studies by [12], [13] and [14], which unveil that perceived safety is an intricate blend of both conscious and instinctive responses, involving the amygdala's emotional processing and the prefrontal cortex's rational decision-making. Notably, this nuanced understanding of perceived safety is exemplified in diverse driving scenarios. For instance, when encountering a close car ahead, different drivers exhibit markedly varied responses. An aggressive driver, possibly influenced by sensation-seeking tendencies [15], might quickly swerve, perceiving lower risk. Conversely, a cautious driver, perhaps more risk-averse [16], might opt for a complete stop. These behaviors, far from being random, are intricately linked to each driver's psychological profile and past experiences, revealing a significant limitation in current AD systems: their inability to account for these complex, cognitive behavioral patterns. Overall, perceived safety and its influence on the decisions of drivers with different behaviors.\nIn response, our research introduces the Cognitive-Informed Transformer (CITF) that integrates the concept of perceived safety into trajectory prediction for AVs. This integration does more than add a new variable; it injects a human-centric perspective into the heart of these systems. By doing so, we aim to enhance the models' ability to interpret driving behaviors, leading to optimal long-term predictions. This approach, promises a transformative impact on the predictive capabilities of AD systems, aligning them more closely with the multifaceted nature of human driving behavior.\nOverall, the key contributions of this study include:\n\u2022 We introduce the Quantitative Safety Assessment (QSA) as a cornerstone component for objectively evaluating the safety of driving scenarios. In addition, we establish Driver Behavior Profiling (DBP) upon the QSA framework to differentiate between distinct driver profiles. This DBP effectively captures and interprets continuous nuances in driving behavior, while eliminating the dependence on manual labeling or predefined time windows.\n\u2022 We introduce an innovative module, named Leanformer, that represents a significant advancement in understanding social interactions on the road. This lightweight transformer-based framework is adept at capturing the subtle and complex inter-vehicular interactions that occur in everyday traffic. This development reflects a paradigm shift in AD research, aligning with the latest advancements and understanding of vehicular social dynamics.\n\u2022 CITF significantly outperforms the SOTA baseline models when tested on the NGSIM, MoCAD, and HighD datasets. It maintains impressive performance even when trained on only 25% of the dataset and with a much smaller number of model parameters, demonstrating its efficiency and adaptability in various traffic scenes, including highways, campuses, and busy urban locales. Importantly, in a significant stride towards practical applicability, CITF shows unparalleled resilience in scenarios with incomplete or inconsistent data."}, {"title": "II. RELATED WORK", "content": "Trajectory Prediction For Autonomous Driving. In the field of trajectory prediction, the analysis of prediction performance is often categorized into short-term and long-term horizons [3], [17]. Early research employed physical models to represent vehicle motion dynamics, thereby estimating future trajectories. In [18], a trajectory prediction model based on the bicycle model was proposed and successfully applied to an accident warning system. While physical models achieved significant progress in short-term prediction horizons, their inherent simplicity limited their performance in long-term predictions [19]. The complexity of human driving behavior, influenced by numerous factors such as cognitive processes, interactions with surrounding vehicles, and environmental conditions, renders long-term prediction a particularly challenging task [17], [20]. In response to these challenges, researchers have begun integrating deep learning models to account for these factors in the trajectory prediction process. Notable prior efforts [8], [21], [22] have explored the complex social dynamics among traffic participants, revealing crucial latent insights that enhance predictive accuracy. Transformer-based models [23], [24] have been increasingly employed for their ability to predict future trajectory distributions effectively. Graph Neural Networks (GNNs) are also gaining traction for capturing dynamic interactions in complex traffic scenes [25], [26]. These approaches primarily focus on understanding the temporal and spatial interplays between traffic agents from historical data to optimize accuracy. Generative models [27], including Variational Auto Encoders (VAEs), Diffusion models, and Generative Adversarial Networks (GANs), are also being explored for their potential to generate multiple future trajectory possibilities from latent distributions, offering a probabilistic perspective of future paths in this field.\nPerceived Safety Concept. The notion of perceived safety has been a focal point in psychology and physical human-robot interaction (pHRI) studies [28]. In pHRI, it is crucial for assessing and representing individuals' perceptions of danger and comfort during interactions with autonomous systems like mobile robots [29], industrial manipulators [30], humanoid robots [31] and AVs [32]. Despite its relevance, perceived safety remains a challenging concept to quantify due to its subjective nature [33]. Our study breaks new ground in this area by proposing a novel quantitative criterion for perceived safety in self-driving trajectory prediction, drawing from Safety State Metrics (SSMs) and human decision-making processes. This innovation enables our model to more accurately interpret driving behavior and traffic conditions, thereby enhancing prediction accuracy in mixed autonomy environments.\nDriving Behavior Understanding. Existing studies in driving behavior have formulated various criteria and metrics for detecting and representing driving patterns, using scales like the Social Value Orientation (SVO) [34], Driving Anger Scale (DAS) [35], among others [36]. While these methods have been successful, as noted by [1] and [37], they typically depend on manually annotated labels and predetermined sliding time windows for analysis. Our research diverges from these traditional approaches by proposing a dynamic, adaptive set of behavior-aware criteria. This model captures driving behavior in real-time through continuous behavioral data representation, eliminating the reliance on manual labeling in the training phase. This novel approach not only offers enhanced flexibility over fixed-category methods but also effectively addresses the challenges of label shifts and time window selection, leading to a more accurate and fluid representation of driving behavior. This advancement significantly contributes to the development of more refined and effective behavior prediction methodologies in autonomous driving systems."}, {"title": "III. PROBLEM FORMULATION", "content": "In mixed autonomy traffic scenarios, trajectory prediction models within AVs are tasked with forecasting the future trajectories of all surrounding vehicles within their perception range. According to surveys by Mozaffari et al. [38] and Ding et al. [39], the single-agent prediction setting remains a prevalent approach in the field of trajectory prediction. In this setting, the model is developed by selecting one vehicle from the surrounding vehicles as the prediction target. During the evaluation phase, the model's predictive capability is assessed in a traversal manner, which treats each vehicle in the scene as the prediction target once. Adhering to this setting, we can define the terminology used in our study as follows:\n\u2022 Target vehicle: The vehicle is designated as the subject of the trajectory prediction task.\n\u2022 Surrounding agents: The AV and all of its perceived traffic agents, excluding the target vehicle.\nIn summary, our problem could be formulated as developing a trajectory prediction model that could utilize the historical states (position, velocity, etc.) of both the target vehicle $X_{t-t_h:t}^{0}$ and the surrounding vehicles $X_{t-t_h:t}^{1:n}$ spanning from time $t-t_h$ to present moment t, to predict the future trajectory $Y_{t:t+t_f}$ of the target vehicle over the ensuing $t_f$ time intervals.\nA. Discretized Inputs and Outputs\nTheoretically, the inputs (historical states) and outputs (future trajectories) should be represented in a continuous form. However, in practical deployment, the sensors on AVs collect data at fixed intervals. Therefore, to maintain consistency with the collected data, it is widely accepted in both academia [40], [41] and industry [42] to use discretized inputs and outputs when developing trajectory prediction models. Specifically, we define the inputs and outputs as follows:\n\u2022 Inputs: The historical states $X_{t-t_h:t}^{0:n}$ of the target vehicle and its surrounding agents, consists of a sequence of historical states ${X_{t-t_h}, X_{t-t_h+1}, ..., X_t}$. At any time t, the historical states $X_t^{0:n}$ comprise 2D position coordinates $p_t^{0:n}$, velocity $v_t^{0:n}$, and acceleration $a_t^{0:n}$.\n\u2022 Outputs: The predicted trajectory of the target vehicle, denoted as $Y_{t:t+t_f}$, consists of a sequence of predicted positions ${p_{t+1}, p_{t+2},..., p_{t+t_f}}$.\nFor brevity, we also list the primary notations and their meanings in Table I.\nB. Multi-modal Probabilistic Maneuver Prediction\nwe adopt a multimodal prediction framework to tackle the inherent uncertainty and variability in predictions. By evaluating different possible maneuvers that the target vehicle might perform, the framework computes the probability of each maneuver based on historical states $X_{t-t_h:t}^{0:n}$, which include 2D position coordinates, velocity, and acceleration over a defined time horizon $t_h$. This approach generates multiple predictions while also quantifying the confidence level associated with each prediction. This allows AVs to account for and respond to the uncertainty inherent in prediction outcomes, providing a valuable advantage for decision-making processes."}, {"title": "IV. TRAJECTORY PREDICTION MODEL", "content": "Figure 1 shows the hierarchical framework of CITF. Rooted in the encoder-decoder paradigm, the model seamlessly incorporates four novel modules: the Perceived Safety-Aware Module, the Priority-Aware Module, the Interaction-Aware Module, and the Multimodal Decoder. Collectively, these modules are designed to capture human-machine interactions between the target vehicle and its surrounding agents and emulate the human decision-making process during driving. Detailed overviews of these modules follow.\nA. Perceived Safety-Aware Module\nAs mentioned before, perceived safety [43] plays a critical role in human decision-making during driving. The nuances in perceived safety can significantly affect human driver behavior and further impact AV's inability to account for the complex, cognitive behavioral patterns in mixed autonomy environments. Recognizing this, the Perceived Safety-Aware Module is introduced to establish precise criteria and quantify specific criteria for evaluating perceived safety. It consists of two integral components: 1) Quantitative Safety Assessment: This component focuses on the development of physically based, measurable criteria that can accurately reflect how humans subjectively assess the level of danger; 2) Driver Behavior Profiling: This component aims to provide in-depth, real-time analysis and profiling of the continuous driving behavior of human drivers especially those influenced by their perceived safety. Together, as shown in Table II, these components are meticulously designed to enhance AVs' understanding of perceived safety in driving contexts, allowing them to better understand and anticipate human driver responses. By incorporating this type of valuable prior knowledge, we facilitate the synthesis of human-like contextual patterns for the proposed model. This enhancement, along with the Priority-Aware Module, allows our Interaction-Aware Module to better decipher and assimilate the intentions of traffic agents and more closely match the intricacies of human cognition and decision-making in driving scenarios, resulting in improved overall model performance.\n1) Quantitative Safety Assessment: As shown in Figure 1 (c), this component H includes two safety indices: the Safe Magnitude Index (SMI) and the Risk Tendency Index (RTI). In a nutshell, the SMI focuses primarily on quantifying the spatio-temporal distance between different agents and the possibility of collision to evaluate the absolute safety level in real-time scenarios. Conversely, RTI tends toward a more subjective analysis, capturing dynamic shifts in safety trends and congestion conditions that reveal potential escalation or mitigation of risk over time.\nSafe Magnitude Index. In the traffic safety domain, three metrics in SSMs have gained prominence for their comprehensive portrayal of on-road risks: Time-to-Collision, Time Exposed Time-to-Collision (TET), and Time Integrated Time-to-Collision (TIT) [44]. Originating from traffic conflict studies, these metrics are essential tools in microscopic traffic simulations to assess traffic safety. Correspondingly, we synthesize TTC, TIT, and TET into a ternary composite structure within SMI. This composite structure is introduced to evaluate the dynamics of interaction between traffic agents and to estimate the likelihood of potential collisions for each vehicle in realtime scenarios. Specifically, the SMI for an agent at a specific time t can be expressed as $S_t^i$ = [TTC, TET, TIT].\nTo align these with the traffic scenarios, we made slight modifications. Using the 2D position coordinates $p^i,p^j$ and velocity $v^i, v^j$ for vehicles i and j at time t.\n1) Time-to-Collision: TTC is a widely accepted measure used to evaluate the time available before two vehicles collide if they continue on their current trajectories. It offers insights into imminent collision risks and serves as an early warning indicator. The TTC for the i-th vehicle is computed as\n$TTC = \\frac{d_{i,j}}{d_{i,j}}$, where $d_{i,j}$ represents the distance between vehicles i and j, and $\\dot{d_{i,j}}$ is its rate of change:\n$\\begin{aligned}\nd_{i,j} &= \\sqrt{(p_x^i-p_x^j)^2 + (p_y^i-p_y^j)^2} \\\\\n\\dot{d_{i,j}} &= (p_x^i-p_x^j)(v_x^i-v_x^j) + (p_y^i-p_y^j)(v_y^i-v_y^j)\n\\end{aligned}$\nAccordingly, the higher the TTC value, the lower the risk of collision for the vehicle in this case.\n2) Time Exposed Time-to-Collision: TET measures the exposure duration to critical TTC values within $t_h$. It is the sum product of a switching variable and a time threshold $T_{sc}$ (set at 0.1s): $TET_i = \\sum_{t_k=t-t_h}^{t} \\delta_i(t_k) \\cdot T_{sc}$ with the switching variable given by:\n$\\delta_i(t_k) =\\begin{cases}\n1 & \\forall 0 \\leq TTC < TTC^*\\\\\n0 & otherwise\n\\end{cases}$\nIn our study, TTC* = 3.0s, delineating safety threshold.\n3) Time Integrated Time-to-Collision: An adaptation of TET, TIT integrates the TTC profile to evaluate safety levels. It factors in the evolution of each vehicle's TET temporally:\n$TIT_i^{t_h} = \\sum_{t_k=t-t_h}^{t} [TTC^* - TTC_i(t_k)] \\cdot T_{sc}$\nElevated values of TTC, TET, and TIT imply sustained exposure to potential collision risks, underscoring a deterioration in perceived safety. Overall, the SMI provides both real-time crash risk assessment and an aggregated risk evaluation over a defined period, eliminating the need for historical crash data. It also takes into account the fluctuation and rate of change of these risks, assessing the safety benefits of AVs in mixed autonomy environments, and offering a comprehensive safety evaluation for each agent.\nRisk Tendency Index. To further capture congestion patterns in complex traffic environments, we propose an index between the i-th and j-th vehicles at time t, denoted as subjective risk perception indicator (SPR), i.e. $R_{t}^{i,j}$, and dynamic risk volatility indicator (DRV), i.e. $R_{t}^{0,i,j}$, respectively:\n$[R_t^{i,j}, R_t^{0,i,j}] = [log(R_t^{i,j}), log(R_t^{0,i,j})], \\forall i, j \\in [0, n], i \\neq j$\nIn this context, the vector $R_t^{i,j}$ with larger values indicates an increased risk of collision, while the vector $R_t^{0,i,j}$ characterizes the dynamic congestion conditions in complex traffic scenarios. Then, the set of the safety indices H = {${S_{t-t_h:t}^i, R_{t-t_h:t}^{i,j},..., S_{t-t_h:t}^i, R_{t-t_h:t}^{i,j} \\forall i \\in [1,n]}$ serve as contextual cues and are then fed into the safety encoder for embedding into high-level safety features. The definitions of SPR and DRV are defined as follows:\n$\\begin{aligned}\nR_t^{i,j} = R_t^{j,i} &= \\begin{cases}\n\\frac{1}{3}[\\frac{TTC_t^i}{TTC_t^j} + \\frac{TET_t^i}{TET_t^j} + \\frac{TIT_t^i}{TIT_t^j}]>0 \\\\\n0 &,\\text{otherwise}\n\\end{cases}\n\\end{aligned}$\nwhere the $DRV_t R_t^{0,i,j}$ represents the gradient to evaluate fluctuations in SPR $R_t^{i,j}$, and can be expressed as follows:\n$\\begin{aligned}\nR_t^{0,i,j} &= \\begin{cases}\n\\frac{R_t^{i,j} - R_{t-1}^{i,j}}{R_{t-1}^{i,j}} > 0 \\\\\n0 &,\\text{otherwise}\n\\end{cases}\n\\end{aligned}$\nThe quantities $\\Delta_{i,j}^v, and iq;$ are calculated based on several critical parameters related to the dynamics of two traffic agents. These parameters include the lateral velocity $v_l$, longitudinal velocity $v_l$, 2D position coordinate $p_l^x and p_l^y$, as well as the lateral a_l and longitudinal $a_l$. Mathematically, it can be represented as follows:\n$\\begin{aligned}\nL_{i,j}^{l} &= max(\\frac{-\\Delta_{i,j}v_l \\times \\Delta_{i,j}p_l^x + \\Delta_{i,j}v_l \\times \\Delta_{i,j}p_l^y}{\\Delta_{i,j}v_l + \\Delta_{i,j}v_l}) \\\\\nL_{i,j}^{l} &= max(\\frac{\\Delta_{i,j}a_l \\times \\Delta_{i,j}p_l^x + \\Delta_{i,j}a_l \\times \\Delta_{i,j}p_l^y}{\\Delta_{i,j}a_l + \\Delta_{i,j}a_l})\n\\end{aligned}$\nwhere the $\\Delta_{i,j}(.)$ denotes the difference between quantities of the i-th and j-th vehicles. A larger vector $R_t^{i,j}$ indicates a higher risk of collision, while the vector $R_t^{0,i,j}$ describes the dynamic congestion conditions in complex traffic scene.\nSafety Encoder. This encoder applies the GCNs [45] to analyze the spatial layouts of traffic agents and their environmental context. Next, it enhances the scaled dot-product multihead self-attention mechanism [46] for a nuanced analysis of temporal relationships within safety indices.\nSpecifically, for GCN, we employ a convolutional neural network on a fully connected interaction multigraph to capture the dynamic geometric relationships among traffic agents. This multigraph operational layer sequentially incorporates the set of safety indices H as nodes. These nodes represent various security-related properties and states of the traffic agents over time. To establish the connections between these nodes, we use an adjacency matrix A, which is detailed in the following subsection. This matrix represents the edges of the graph and is critical in defining the interactions and relationships between different nodes (agents) within the graph. Formally,\n$\\overline{Z}_t^{k+1} = ReLU(\\overline{D}^{-\\frac{1}{2}}\\overline{A}\\overline{D}^{-\\frac{1}{2}}Z_t^k W^k)$\nwhere the matrix $\\overline{D}$ serves as the scale factor of $\\overline{A}$, is the degree matrix for normalizing the graph structure. It helps to balance the influence of each node based on its connectivity. The $W^k$ represents the trainable weight matrix of the GCN for the k-th layer, while $ReLU$ is the Rectified Linear Unit (ReLU) activation function. Consequently, the matrix $\\overline{A}$ can be defined as $\\overline{A} = A+ l_1I_N$, where $l_1$ is the weight and $I_N$ is the identity matrix. The output of the k-th convolutional layer, denoted as $\\overline{Z}_t^{k+1}$, represents the learned feature matrix of the i-th agent. Moreover, the initial feature $Z_t^0 = \\Phi_{MLP}(H)$, where $\\Phi_{MLP}$ denotes a Multi-Layer Perceptron (MLP). The MLP serves as a fully connected layer to embed the safety indices H into a feature space suitable for graph convolution. In addition, we employ a tri-layer convolutional neural network that incorporates scatter and gathers operations to parallelize the learning of contextual information and spatio-temporal agent interdependencies.\nNext, the feature matrix $\\overline{Z}_t^{k+1}$, $\\overline{Z}_t^k$ and $\\overline{Z}_t^{k-1}$ output from the (k + 1), k and (k \u2212 1)-th GCNs is then converted to the query, key, value vectors, respectively, by the multi-head selfattention mechanism within the encoder to produce the highlevel safety features. Formally,\n$\\begin{aligned}\n&Q^{safety} = \\Phi_{MLP}(WQ \\overline{Z}_t^{k+1}) \\\\\n&K^{safety} = \\Phi_{MLP}(WK \\overline{Z}_t^k) \\\\\n&V^{safety} = \\Phi_{MLP}(WV \\overline{Z}_t^{k-1})\n\\end{aligned}$\nwhere the $W^Q, W^K, W^V$ are learnable weights that can be optimized via gradient descent. For the i-th self-attention head $head_i$, the formulation is as follows:\n$head_i = softmax (\\frac{Q^{safety} (K^{safety})^T}{\\sqrt{d_k}})\\cdot V^{safety}$\nIn the equation provided, $softmax(.)$ denotes the softmax activation function, while $d_k$ represents the dimensionality of the projected key vectors. The output generated by the self-attention mechanism can be expressed as $\\overline{O}_{t-t_h:t}^{safety} = \\frac{1}{h_s} \\sum_{i=1}^{h_s}head_i$, where $h_s$ is the total number of attention heads. To increase training stability and efficiency, our model takes inspiration from ResNet [47] and incorporates Gated Linear Units (GLUs) [48] along with Layer Normalization (LN) [49] for the output of multi-head attention mechanism $\\overline{O}_{t-t_h:t}^{safety}$ to efficiently manage features. Formally,\n$\\overline{O}_{t-t_h:t}^{safety} = \\Phi_{LN} (MLP(\\Phi_{GLUs}(\\alpha)))$\nIn particular, GLUs provide a mechanism to control the flow of information through the network, making the model more adaptable, which can be defined as:\n$\\Phi_{GLUs}(\\alpha) = (\\alpha W_1+b_1) \\odot sigmoid(\\alpha W_2+b_2)$\nwhere \u03b1 represents the safe attention coefficient from the multi-head attention mechanism, $W_1$ and $W_2$ are the learnable weight parameters associated with the GLUs layer, $b_1$ and $b_2$ are the corresponding biases, $\\odot$ denotes element-wise multiplication, $sigmoid$ is the sigmoid activation function, and $\\Phi_{LN}(\\cdot)$ stands for Layer Normalization. Correspondingly, the output of the encoder within the Quantitative Safety Assessment is the high-level safety features, denoted as $\\overline{O}_{t-t_h:t}^{safety}$.\n2) Driver Behavior Profiling: As shown in Figure 1 (b), we represent vehicles and their interactions as nodes and edges, respectively, thereby constructing a Dynamic Geometric Graph (DGG). Leveraging this graph-based framework, we employ centrality measures from graph theory to profile continuum driver behavior in an unsupervised manner.\nDynamic Geometric Graph. Due to the dynamic nature of traffic scenarios, the structure of the DGG evolves over time. At any given moment t, we define the DGG $G_t = {V_t, E_t}$. Specifically, the node set $V_t = {v_i, v_1, ..., v_n^t}$, where node $v_i$ represents vehicle i. The adjacency matrix $A_t$ illustrates whether edges exist between nodes, signifying the presence of interactions between vehicles. The establishment of this matrix is based on the distances between vehicles, which can be mathematically represented as follows:\n$A_t(i, j) = \\begin{cases}1 & \\text{if } d(v_i^t, v_j^t) \\leq r \\text{ and } i \\neq j \\\\\n0 &,\\text{otherwise}\n\\end{cases}$\nwhere $d(v_i^t, v_j^t)$ denotes the distance between vehicle i and vehicle j, and r is a predefined threshold. The number of vehicles interacting with vehicle i is represented as $N_i$.\nWith these configurations in place, we then apply centrality measures to assess agent behavior, identify key agents, and evaluate the overall connectivity within the traffic graph.\nCentrality Measures. Driver behavior significantly shapes the interaction patterns between the driver and surrounding agents, resulting in distinct spatiotemporal dynamics. Therefore, we posit that spatiotemporal dynamics can effectively differentiate between various driver behaviors. Given that centrality measures in graph theory provide a comprehensive description of the properties of nodes within a graph [50], [51], we employ centrality indicators such as degree $J_i^t(D)$, closeness $J_i^t(C)$, eigenvector $J_i^t(E)$, betweenness $J_i^t(B)$, power $J_i^t(P)$, and Katz $J_i^t(K)$ centrality to characterize the spatial interaction dynamics of agent i at each moment t. To account for both the temporal and spatial dimensions of these dynamics, we further analyze the temporal evolution of these indicators and establish the Behavior-aware Criteria, enabling the continuous differentiation of diverse driving behaviors.\n1) Degree Centrality: The number of agents a vehicle can influence reflects its significance within the traffic scene. Degree centrality $J_i^t(D)$, a metric that measures the number of connections a node has, is thus naturally employed to describe the importance of each vehicle i. Formally,\n$J_i^t(D) = |N_i^t| + J_{i-1}^t(D)$\nwhere $N_i^t$ denotes the total agents in $N_t$.\n2) Closeness Centrality: The position of a vehicle within a scene also reflects its significance. It is well-recognized that vehicles located centrally exert greater influence than those at the periphery. Consequently, closeness centrality $J_i^t(C)$, which measures the proximity of a node to the center of the graph, is employed to characterize the importance of a vehicle as:\n$J_i^t(C) = \\frac{|N_t|-1}{\\sum_{v_j \\in N_i^t} d(v_i^t, v_j^t)}$\n3) Eigenvector Centrality: The vehicle's behavior can influence a broader set of agents through those it directly interacts with, meaning that the importance of the directly connected agents also reflects the vehicle's significance. Eigenvector centrality, which considers the importance of connected nodes, is used to assess the vehicle's importance. The eigenvector centrality of the vehicle i can be formulated as follows:\n$J_i^t(E) = \\frac{J_i^t(A)}{\\lambda}$\nwhere $\\lambda$ is the eigenvalue [52].\n4) Betweenness Centrality: The vehicle's influence can be transmitted to distant agents through intermediary agents, implying that vehicles frequently acting as intermediaries play a more crucial role in the network. Betweenness centrality $J_i^t(B)$, a metric that measures the extent to which a node serves as an intermediary within the shortest path between any two nodes, is naturally used to assess the vehicle's importance.\n$J_i^t(B) = \\sum_{v^j, v^k \\in V_t} \\frac{\\sigma_{j,k}(v_i^t)}{\\sigma_{j,k}}$\nwhere $V_t$ denotes the set of all agents present in the scene, $\\sigma_{j,k}$ signifies the total number of shortest paths between agent $v_j$ and agent $v_k$, and $\\sigma_{j,k}(v_i^t)$ represents the number of those paths traversing the agent $v_i$.\n5) Power Centrality: An interaction loop is a closed loop formed by a group of agents through direct or indirect interactions. A vehicle's participation in more interaction loops indicates greater influence within the overall traffic network. Power centrality $J_i^t(P)$, which measures the frequency with which a node is part of closed cycles formed by edges, is used to describe the vehicle's influence.\n$J_i^t(P) = \\sum_{k} A_{ii}^k/k!$\nwhere $A^k$ denotes the i-th diagonal element of the adjacency matrix raised to the k-the power, k! signifies the factorial.\n6) Katz Centrality: To address the limitation of degree centrality, which considers only direct interactions, we employ Katz centrality to emphasize both direct and distant interactions of the vehicle. Mathematically, the Katz centrality $J_i^t(K)$ of an agent $v_i$ at time t can be formulated as:\n$J_i^t(K) = \\sum_{j} \\sum_{k} \\alpha^k \\beta^k, \\forall v_i, j \\in [0, n], where \\alpha^* < \\frac{1}{\\Lambda_{max}}$\nwhere n is the number of agents in the traffic scenario, $a^k$ denotes the decay factor, $\\beta^k$ represents weight for immediate neighbors, and $A_{i,j}^k$ is the i,j-th element of the k-th power of the adjacency matrix. And $\\Lambda_{max}$ denotes the largest eigenvalue of the adjacency matrix. By carefully selecting the value of the decay factor, Katz centrality can underscore the importance of closer interactions while discounting more distant connections.\nBehavior-aware Criteria. Given the centrality metrics that capture the spatial interaction dynamics of traffic agents, we establish Behavior-aware Criteria that identify driving behavior not only based on the magnitude of these metrics but also on their temporal variation. Numerous studies have demonstrated the feasibility of this approach, showing that driving behavior can be identified using not only the instantaneous magnitude of features like speed but also their temporal derivatives, such as acceleration and jerk [53]. This approach also aligns with human intuition, as driving behaviors characterized by large and fluctuating centrality measures over short periods are more likely to be relevant to driving behavior as sudden changes in acceleration within short intervals. Inspired by the established triadic relationship between velocity, acceleration, and jerk, we introduce three continuous criteria: Behavior Magnitude Index (BMI) $C_i^t$, which measures the influence of driving behaviors by evaluating their centrality; Behavior Tendency Index (BTI) $L_i^t$, which quantifies behavior"}, {"title": null, "content": "propensity by calculating temporal derivatives, larger derivatives suggesting higher probabilities of specific behaviors; and Behavior Curvature Index (BCI) $I_i^t$, which uses the jerk concept to measure the intensity of driving behaviors by calculating the second-order derivatives of continuous centrality measures. At time t, the behavior $I_i^t$ for $v_i$ can be defined as $I_i^t$ = [$C_i^t, L_i^t, I_i^t$"}]}