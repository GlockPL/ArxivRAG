[{"title": "Minds on the Move: Decoding Trajectory Prediction in Autonomous Driving with Cognitive Insights", "authors": ["Haicheng Liao", "Chengyue Wang", "Kaiqun Zhu", "Yilong Ren", "Bolin Gao", "Shengbo Eben Li", "Chengzhong Xu", "Zhenning Li"], "abstract": "In mixed autonomous driving environments, accurately predicting the future trajectories of surrounding vehicles is crucial for the safe operation of autonomous vehicles (AVs). In driving scenarios, a vehicle's trajectory is determined by the decision-making process of human drivers. However, existing models primarily focus on the inherent statistical patterns in the data, often neglecting the critical aspect of understanding the decision-making processes of human drivers. This oversight results in models that fail to capture the true intentions of human drivers, leading to suboptimal performance in long-term trajectory prediction. To address this limitation, we introduce a Cognitive-Informed Transformer (CITF) that incorporates a cognitive concept, Perceived Safety, to interpret drivers' decision-making mechanisms. Perceived Safety encapsulates the varying risk tolerances across drivers with different driving behaviors. Specifically, we develop a Perceived Safety-aware Module that includes a Quantitative Safety Assessment for measuring the subject risk levels within scenarios, and Driver Behavior Profiling for characterizing driver behaviors. Furthermore, we present a novel module, Leanformer, designed to capture social interactions among vehicles. CITF demonstrates significant performance improvements on three well-established datasets. In terms of long-term prediction, it surpasses existing benchmarks by 12.0% on the NGSIM, 28.2% on the HighD, and 20.8% on the MoCAD dataset. Additionally, its robustness in scenarios with limited or missing data is evident, surpassing most state-of-the-art (SOTA) baselines, and paving the way for real-world applications.", "sections": [{"title": "I. INTRODUCTION", "content": "IN the evolving landscape of autonomous driving (AD) systems, the complex interactions between autonomous vehicles (AVs) and human-driven vehicles (HVs) present a significant challenge to achieving accurate trajectory prediction [1], [2]. The future trajectory of human-driven vehicles is essentially the result of the human driver's decision-making process [3], [4]. Since human drivers require reaction time to adjust their behavior when facing changes in the external environment [5]-[7], the dynamics of the vehicle will not change drastically in the short term, making short-term (\u2264 2 seconds) predictions relatively straightforward. Nevertheless, long-term prediction necessitates models that accurately estimate the impact of numerous factors on the decision-making process of human drivers, a feat that is particularly challenging to achieve [8]. Recent advancements in algorithms and the availability of driving datasets have led to significant breakthroughs in trajectory prediction [9]. However, the accuracy of long-term predictions (i.e., >2 seconds) remains a persistent challenge, primarily due to the inherent complexity of real-world driving scenarios. These challenges stem from the complex interactions between traffic agents, the impact of environmental factors like weather and road conditions, and the unpredictable nature of human driver behavior. These factors introduce significant uncertainty, making reliable long-term forecasts a persistent struggle for researchers in the field.\nThis backdrop prompts us to ask critical questions about the future trajectory of AD: Is the key to advancing AD not just in accumulating more data or refining algorithms, but in gaining a deeper understanding of the driving environment itself? How can we reshape our models to interpret and respond to the intricate human dynamics that underpin driving? Motivated by these questions, our research embarks on an innovative path. We propose a paradigm shift, extending beyond conventional data-driven approaches to embrace a critical yet often-neglected aspect of driving - the concept of perceived safety.\nThis concept, pivotal in shaping driving behaviors and decisions, is deeply rooted in psychological constructs, as detailed in [10]. According to the Theory of Planned Behavior, individual actions in driving are influenced by attitudes (driving behaviors towards others), subjective norms (personal evaluation of safety), and perceived behavioral control (confidence in driving ability) [11]. Further depth is added by neuroscientific research, such as studies by [12], [13] and [14], which unveil that perceived safety is an intricate blend of both conscious and instinctive responses, involving the amygdala's emotional processing and the prefrontal cortex's rational decision-making. Notably, this nuanced understanding of perceived safety is exemplified in diverse driving scenarios. For instance, when encountering a close car ahead, different drivers exhibit markedly varied responses. An aggressive driver, possibly influenced by sensation-seeking tendencies [15], might quickly swerve, perceiving lower risk. Conversely, a cautious driver, perhaps more risk-averse [16], might opt for a complete stop. These behaviors, far from being random, are intricately linked to each driver's psychological profile and past experiences, revealing a significant limitation in current AD systems: their inability to account for these complex, cognitive behavioral patterns. Overall, perceived safety and its influence on the decisions of drivers with different behaviors.\nIn response, our research introduces the Cognitive-Informed Transformer (CITF) that integrates the concept of perceived safety into trajectory prediction for AVs. This integration does more than add a new variable; it injects a human-centric perspective into the heart of these systems. By doing so, we aim to enhance the models' ability to interpret driving behaviors, leading to optimal long-term predictions. This approach, promises a transformative impact on the predictive capabilities of AD systems, aligning them more closely with the multifaceted nature of human driving behavior.\nOverall, the key contributions of this study include:\nWe introduce the Quantitative Safety Assessment (QSA) as a cornerstone component for objectively evaluating the safety of driving scenarios. In addition, we establish Driver Behavior Profiling (DBP) upon the QSA framework to differentiate between distinct driver profiles. This DBP effectively captures and interprets continuous nuances in driving behavior, while eliminating the dependence on manual labeling or predefined time windows.\nWe introduce an innovative module, named Leanformer, that represents a significant advancement in understanding social interactions on the road. This lightweight transformer-based framework is adept at capturing the subtle and complex inter-vehicular interactions that occur in everyday traffic. This development reflects a paradigm shift in AD research, aligning with the latest advancements and understanding of vehicular social dynamics.\nCITF significantly outperforms the SOTA baseline models when tested on the NGSIM, MoCAD, and HighD datasets. It maintains impressive performance even when trained on only 25% of the dataset and with a much smaller number of model parameters, demonstrating its efficiency and adaptability in various traffic scenes, including highways, campuses, and busy urban locales. Importantly, in a significant stride towards practical applicability, CITF shows unparalleled resilience in scenarios with incomplete or inconsistent data."}, {"title": "II. RELATED WORK", "content": "Trajectory Prediction For Autonomous Driving. In the field of trajectory prediction, the analysis of prediction performance is often categorized into short-term and long-term horizons [3], [17]. Early research employed physical models to represent vehicle motion dynamics, thereby estimating future trajectories. In [18], a trajectory prediction model based on the bicycle model was proposed and successfully applied to an accident warning system. While physical models achieved significant progress in short-term prediction horizons, their inherent simplicity limited their performance in long-term predictions [19]. The complexity of human driving behavior, influenced by numerous factors such as cognitive processes, interactions with surrounding vehicles, and environmental conditions, renders long-term prediction a particularly challenging task [17], [20]. In response to these challenges, researchers have begun integrating deep learning models to account for these factors in the trajectory prediction process. Notable prior efforts [8], [21], [22] have explored the complex social dynamics among traffic participants, revealing crucial latent insights that enhance predictive accuracy. Transformer-based models [23], [24] have been increasingly employed for their ability to predict future trajectory distributions effectively. Graph Neural Networks (GNNs) are also gaining traction for capturing dynamic interactions in complex traffic scenes [25], [26]. These approaches primarily focus on understanding the temporal and spatial interplays between traffic agents from historical data to optimize accuracy. Generative models [27], including Variational Auto Encoders (VAEs), Diffusion models, and Generative Adversarial Networks (GANs), are also being explored for their potential to generate multiple future trajectory possibilities from latent distributions, offering a probabilistic perspective of future paths in this field.\nPerceived Safety Concept. The notion of perceived safety has been a focal point in psychology and physical human-robot interaction (pHRI) studies [28]. In pHRI, it is crucial for assessing and representing individuals' perceptions of danger and comfort during interactions with autonomous systems like mobile robots [29], industrial manipulators [30], humanoid robots [31] and AVs [32]. Despite its relevance, perceived safety remains a challenging concept to quantify due to its subjective nature [33]. Our study breaks new ground in this area by proposing a novel quantitative criterion for perceived safety in self-driving trajectory prediction, drawing from Safety State Metrics (SSMs) and human decision-making processes. This innovation enables our model to more accurately interpret driving behavior and traffic conditions, thereby enhancing prediction accuracy in mixed autonomy environments.\nDriving Behavior Understanding. Existing studies in driving behavior have formulated various criteria and metrics for detecting and representing driving patterns, using scales like the Social Value Orientation (SVO) [34], Driving Anger Scale (DAS) [35], among others [36]. While these methods have been successful, as noted by [1] and [37], they typically depend on manually annotated labels and predetermined sliding time windows for analysis. Our research diverges from these traditional approaches by proposing a dynamic, adaptive set of behavior-aware criteria. This model captures driving behavior in real-time through continuous behavioral data representation, eliminating the reliance on manual labeling in the training phase. This novel approach not only offers enhanced flexibility over fixed-category methods but also effectively addresses the challenges of label shifts and time window selection, leading to a more accurate and fluid representation of driving behavior. This advancement significantly contributes to the development of more refined and effective behavior prediction methodologies in autonomous driving systems."}, {"title": "III. PROBLEM FORMULATION", "content": "In mixed autonomy traffic scenarios, trajectory prediction models within AVs are tasked with forecasting the future trajectories of all surrounding vehicles within their perception range. According to surveys by Mozaffari et al. [38] and Ding et al. [39], the single-agent prediction setting remains a prevalent approach in the field of trajectory prediction. In this setting, the model is developed by selecting one vehicle from the surrounding vehicles as the prediction target. During the evaluation phase, the model's predictive capability is assessed in a traversal manner, which treats each vehicle in the scene as the prediction target once. Adhering to this setting, we can define the terminology used in our study as follows:\nTarget vehicle: The vehicle is designated as the subject of the trajectory prediction task.\nSurrounding agents: The AV and all of its perceived traffic agents, excluding the target vehicle.\nIn summary, our problem could be formulated as developing a trajectory prediction model that could utilize the historical states (position, velocity, etc.) of both the target vehicle $X_{t-th:t}^{0}$ and the surrounding vehicles $X_{t-th:t}^{1:n}$ spanning from time $t-th$ to present moment $t$, to predict the future trajectory $Y_{t:t+tf}$ of the target vehicle over the ensuing $t_f$ time intervals.\nA. Discretized Inputs and Outputs\nTheoretically, the inputs (historical states) and outputs (future trajectories) should be represented in a continuous form. However, in practical deployment, the sensors on AVs collect data at fixed intervals. Therefore, to maintain consistency with the collected data, it is widely accepted in both academia [40], [41] and industry [42] to use discretized inputs and outputs when developing trajectory prediction models. Specifically, we define the inputs and outputs as follows:\nInputs: The historical states $X_{t-th:t}^{0:n}$ of the target vehicle and its surrounding agents, consists of a sequence of historical states $\\{X_{t-th}, X_{t-th+1},...,X_t^{0:n}\\}$. At any time t, the historical states $X_{t}^{0:n}$ comprise 2D position coordinates $p_t^{0:n}$, velocity $v_t^{0:n}$, and acceleration $a_t^{0:n}$.\nOutputs: The predicted trajectory of the target vehicle, denoted as $Y_{t:t+tf}$, consists of a sequence of predicted positions $\\{p_{t+1}^0, p_{t+2}^0,..., p_{t+tf}^0\\}$.\nFor brevity, we also list the primary notations and their meanings in Table I.\nB. Multi-modal Probabilistic Maneuver Prediction\nwe adopt a multimodal prediction framework to tackle the inherent uncertainty and variability in predictions. By evaluating different possible maneuvers that the target vehicle might perform, the framework computes the probability of each maneuver based on historical states $X_{t-th:t}^{0:n}$, which include 2D position coordinates, velocity, and acceleration over a defined time horizon $t_h$. This approach generates multiple predictions while also quantifying the confidence level associated with each prediction. This allows AVs to account for and respond to the uncertainty inherent in prediction outcomes, providing a valuable advantage for decision-making processes."}, {"title": "IV. TRAJECTORY PREDICTION MODEL", "content": "Figure 1 shows the hierarchical framework of CITF. Rooted in the encoder-decoder paradigm", "modules": "the Perceived Safety-Aware Module", "43": "plays a critical role in human decision-making during driving. The nuances in perceived safety can significantly affect human driver behavior and further impact AV's inability to account for the complex", "components": 1, "Assessment": "This component focuses on the development of physically based", "Profiling": "This component aims to provide in-depth"}, {"Assessment": "As shown in Figure 1 (c)", "indices": "the Safe Magnitude Index (SMI) and the Risk Tendency Index (RTI). In a nutshell", "risks": "Time-to-Collision", "44": ".", "TET_t,TIT_t": ".", "Time-to-Collision": "TTC is a widely accepted measure used to evaluate the time available before two vehicles collide if they continue on their current trajectories. It offers insights into imminent collision risks and serves as an early warning indicator. The TTC for the i-th vehicle is computed as\n$TTC = \\frac{d_{i", "change": "n$d_{i"}, {"Time-to-Collision": "TET measures the exposure duration to critical TTC values within $t_h$. It is the sum product of a switching variable and a time threshold $T_{sc"}, 0.1, "s)", {"by": "n$\\delta_i(t_k) = \\begin{cases"}, 3.0, "ime-to-Collision", "emporally", "TTC_i(t_k)"], "respectively": "n$[\\dot R_{t"}, {"R_{t}^{j,i}": ["log(R_{t}^{i,j}), log(R_{t}^{j,i})"], "n": "i \\neq j$\nIn this context", "S_{t-t_h": "t"}, "i, R_{t-t_h:t}^{i,j},..., S_{t-t_h:t}^i, R_{t-t_h:t}^{i,j}, \\forall i \\in [1,n", "serve as contextual cues and are then fed into the safety encoder for embedding into high-level safety features. The definitions of SPR and DRV are defined as follows:\n$R_{t}^{i,j} = R_{t}^{j,i} = \\begin{cases}\n1/L_{i,j} & if L_{i,j} > 0 \\\\\n0 & otherwise\n\\end{cases}$\nwhere the DRV $\\dot R_{t}^{i,j}$, represents the gradient to evaluate fluctuations in SPR $R_{t}^{i,j}$, and can be expressed as follows:\n$\\dot R_{t}^{i,j} = \\begin{cases}\n|\\frac{\\partial L_{t}^{i,j}}{\\partial t}| & if \\frac{\\partial L_{t}^{i,j}}{\\partial t} > 0 \\\\\n0 & otherwise\n\\end{cases}$\nThe quantities $L_{i,j}^t$ and $L_{j,i}^t$ are calculated based on several critical parameters related to the dynamics of two traffic agents. These parameters include the lateral velocity $v_l$, longitudinal velocity $v_p$, 2D position coordinate $p^x$ and $p^y$, as well as the lateral $a_l$ and longitudinal $a_l$. Mathematically, it can be represented as follows:\n$L_{i,j}^t = max\\begin{cases}\n-\\frac{\\Delta_{i,j}v_x \\times \\Delta_{i,j}p_x + \\Delta_{i,j}v_y \\times \\Delta_{i,j}p_y}{\\Delta_{i,j}v_x^2 + \\Delta_{i,j}v_y^2} , \\\\\n-\\frac{\\Delta_{i,j}a_x \\times \\Delta_{i,j}p_x + \\Delta_{i,j}a_y \\times \\Delta_{i,j}p_y}{\\Delta_{i,j}a_x^2 + \\Delta_{i,j}a_y^2}\n\\end{cases}$\nwhere the $\\Delta_{i,j}(.)$ denotes the difference between quantities of the i-th and j-th vehicles. A larger vector $R_{t}^{i,j}$ indicates a higher risk of collision, while the vector $\\dot R_{t}^{i,j}$ describes the dynamic congestion conditions in complex traffic scene.\nSafety Encoder. This encoder applies the GCNs [45", "to analyze the spatial layouts of traffic agents and their environmental context. Next, it enhances the scaled dot-product multi-head self-attention mechanism [46", "for a nuanced analysis of temporal relationships within safety indices.\nSpecifically, for GCN, we employ a convolutional neural network on a fully connected interaction multigraph to capture the dynamic geometric relationships among traffic agents. This multigraph operational layer sequentially incorporates the set of safety indices H as nodes. These nodes represent various security-related properties and states of the traffic agents over time. To establish the connections between these nodes, we use an adjacency matrix A, which is detailed in the following subsection. This matrix represents the edges of the graph and is critical in defining the interactions and relationships between different nodes (agents) within the graph. Formally,\n$\\tilde{Z}_i^{k+1} = ReLU(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}Z_i^k W^k)$\nwhere the matrix $\\tilde{D}$ serves as the scale factor of $\\tilde{A}$, is the degree matrix for normalizing the graph structure. It helps to balance the influence of each node based on its connectivity. The $W^k$ represents the trainable weight matrix of the GCN for the k-th layer, while $ReLU$ is the Rectified Linear Unit (ReLU) activation function. Consequently, the matrix A can be defined as $\\tilde{A} = A + \\lambda_{1}I_N$, where $\\lambda_{1}$ is the weight and $I_N$ is the identity matrix. The output of the k-th convolutional layer, denoted as $\\tilde{Z}_i^{k+1}$, represents the learned feature matrix of the i-th agent. Moreover, the initial feature $Z^0 = MLP(H)$, where $MLP$ denotes a Multi-Layer Perceptron (MLP). The MLP serves as a fully connected layer to embed the safety indices H into a feature space suitable for graph convolution. In addition, we employ a tri-layer convolutional neural network that incorporates scatter and gathers operations to parallelize the learning of contextual information and spatio-temporal agent interdependencies.\nNext, the feature matrix $\\tilde{Z}_i^{k+1}$, $\\tilde{Z}_i^k$ and $\\tilde{Z}_i^{k-1}$ output from the (k + 1), k and (k \u2212 1)-th GCNs is then converted to the query, key, value vectors, respectively, by the multi-head self-attention mechanism within the encoder to produce the high-level safety features. Formally,\n$Q^{safety} = W^Q MLP(\\tilde{Z}_i^{k+1})$\n$K^{safety} = W^K MLP(\\tilde{Z}_i^k)$\n$V^{safety} = W^V MLP(\\tilde{Z}_i^{k-1})$\nwhere the $W^Q, W^K, W^V$ are learnable weights that can be optimized via gradient descent. For the i-th self-attention head $head_i$, the formulation is as follows:\n$head_i = \\phi_{softmax}\\left(\\frac{Q_i^{safety}(K_i^{safety})^T}{\\sqrt{d_k}}\\right) V_i^{safety}$\nIn the equation provided, $\\phi_{softmax}()$ denotes the softmax activation function, while $d_k$ represents the dimensionality of the projected key vectors. The output generated by the self-attention mechanism can be expressed as $\\bar{O}_{t-th:t}^{safety} =\\frac{1}{h_c}\\sum_{i=1}^{h_c} head_i$, where $h_c$ is the total number of attention heads.\nTo increase training stability and efficiency, our model takes inspiration from ResNet [47", "and incorporates Gated Linear Units (GLUs) [48", "along with Layer Normalization (LN) [49", "for the output of multi-head attention mechanism $\\bar{O}_{t-th:t}^{safety}$ to efficiently manage features. Formally,\n$O_{t-th:t}^{safety} = \\phi_{LN}(MLP(\\phi_{GLUs}(\\alpha)))$\nIn particular, GLUs provide a mechanism to control the flow of information through the network, making the model more adaptable, which can be defined as:\n$\\phi_{GLUS}(\\alpha) = (\\alpha W_1 + b_1) \\cdot sigmoid(\\alpha W_2 + b_2)$\nwhere $\\alpha$ represents the safe attention coefficient from the multi-head attention mechanism, $W_1$ and $W_2$ are the learnable weight parameters associated with the GLUs layer, $b_1$ and $b_2$ are the corresponding biases, $\\cdot$ denotes element-wise multiplication, $sigmoid$ is the sigmoid activation function, and $\\phi_{LN}(\\cdot)$ stands for Layer Normalization. Correspondingly, the output of the encoder within the Quantitative Safety Assessment is the high-level safety features, denoted as $\\bar{O}_{t-th:t}^{safety}$.\n2) Driver Behavior Profiling: As shown in Figure 1 (b), we represent vehicles and their interactions as nodes and edges, respectively, thereby constructing a Dynamic Geometric Graph (DGG). Leveraging this graph-based framework, we employ centrality measures from graph theory to profile continuum driver behavior in an unsupervised manner.\nDynamic Geometric Graph. Due to the dynamic nature of traffic scenarios, the structure of the DGG evolves over time. At any given moment t, we define the DGG $G_t = \\{V_t, E_t\\}$. Specifically, the node set $V_t = \\{v_i, v_1, ..., v_n\\}$, where node $v_i$ represents vehicle i. The adjacency matrix $A_t$ illustrates whether edges exist between nodes, signifying the presence of interactions between vehicles. The establishment of this matrix is based on the distances between vehicles, which can be mathematically represented as follows:\n$A_t(i, j) = \\begin{cases}\n\\frac{d(v_i^t, v_j^t)}{r} & if d(v_i^t, v_j^t) \\leq r \\ and i \\neq j \\\\\n0 & otherwise\n\\end{cases}$\nwhere $d(v_i^t, v_j^t)$ denotes the distance between vehicle i and vehicle j, and r is a predefined threshold. The number of vehicles interacting with vehicle i is represented as $|N_t|$.\nWith these configurations in place, we then apply centrality measures to assess agent behavior, identify key agents, and evaluate the overall connectivity within the traffic graph.\nCentrality Measures. Driver behavior significantly shapes the interaction patterns between the driver and surrounding agents, resulting in distinct spatiotemporal dynamics. Therefore, we posit that spatiotemporal dynamics can effectively differentiate between various driver behaviors. Given that centrality measures in graph theory provide a comprehensive description of the properties of nodes within a graph [50", [51], "we employ centrality indicators such as degree $J_t^D(i)$, closeness $J_t^C(i)$, eigenvector $J_t^E(i)$, betweenness $J_t^B(i)$, power $J_t^P(i)$, and Katz $J_t^K(i)$ centrality to characterize the spatial interaction dynamics of agent i at each moment t. To account for both the temporal and spatial dimensions of these dynamics, we further analyze the temporal evolution of these indicators and establish the Behavior-aware Criteria, enabling the continuous differentiation of diverse driving behaviors.\n1) Degree Centrality: The number of agents a vehicle can influence reflects its significance within the traffic scene. Degree centrality $J_t^D(i)$, a metric that measures the number of connections a node has, is thus naturally employed to describe the importance of each vehicle i. Formally,\n$J_t^D(i) = |N_t^i| + J_{t-1}^D(i)$\nwhere $N_t^i$ denotes the total agents in $N_t$.\n2) Closeness Centrality: The position of a vehicle within a scene also reflects its significance. It is well-recognized that vehicles located centrally exert greater influence than those at the periphery. Consequently, closeness centrality $J_t^C(i)$, which measures the proximity of a node to the center of the graph, is employed to characterize the importance of a vehicle as:\n$J_t^C(i) = \\frac{|N_t| - 1}{\\sum_{j\\in N_t} d(v_i^t, v_j^t)}$\n3) Eigenvector Centrality: The vehicle's behavior can influence a broader set of agents through those it directly interacts with, meaning that the importance of the directly connected agents also reflects the vehicle's significance. Eigenvector centrality, which considers the importance of connected nodes, is used to assess the vehicle's importance. The eigenvector centrality of the vehicle i can be formulated as follows:\n$J_t^E(i) = \\frac{J_t^E(j)}{\\lambda}$\nwhere $\\lambda$ is the eigenvalue [52", ".", "n4) Betweenness Centrality: The vehicle's influence can be transmitted to distant agents through intermediary agents, implying that vehicles frequently acting as intermediaries play a more crucial role in the network. Betweenness centrality $J_t^B(i)$, a metric that measures the extent to which a node serves as an intermediary within the shortest path between any two nodes, is naturally used to assess the vehicle's importance.\n$J_t^B(i) = \\sum_{v_j^t, v_k^t \\in V_t} \\frac{\\sigma_{j,k}(v_i^t)}{\\sigma_{j,k}}$\nwhere $V_t$ denotes the set of all agents present in the scene, $\\sigma_{j,k}$ signifies the total number of shortest paths between agent $v_j^t$ and agent $v_k^t$, and $\\sigma_{j,k}(v_i^t)$ represents the number of those paths traversing the agent $v_i^t$.\n5) Power Centrality: An interaction loop is a closed loop formed by a group of agents through direct or indirect interactions. A vehicle's participation in more interaction loops indicates greater influence within the overall traffic network. Power centrality $J_t^P(i)$, which measures the frequency with which a node is part of closed cycles formed by edges, is used to describe the vehicle's influence.\n$J_t^P(i) = \\sum_{k} \\frac{(A_t^k)_{ii}}{k!}$\nwhere $A_t^k$ denotes the i-th diagonal element of the adjacency matrix raised to the k-the power, k! signifies the factorial.\n6) Katz Centrality: To address the limitation of degree centrality, which considers only direct interactions, we employ Katz centrality to emphasize both direct and distant interactions of the vehicle. Mathematically, the Katz centrality $J_t^K(i)$ of an agent $v_i$ at time t can be formulated as:\n$J_t^K(i) = \\sum_{k} \\sum_{j} \\alpha^k + \\beta A_{i,j}^k, \\forall v_i, j \\in [0, n", "where $\\alpha^* < \\frac{1}{\\lambda_{max}}$\nwhere n is the number of agents in the traffic scenario, $\\alpha^k$ denotes the decay factor, $\\beta$ represents weight for immediate neighbors, and $A_{i,j}$ is the i,j-th element of the k-th power of the adjacency matrix. And $\\lambda_{max}$ denotes the largest eigenvalue of the adjacency matrix. By carefully selecting the value of the decay factor, Katz centrality can underscore the importance of closer interactions while discounting more distant connections.\nBehavior-aware Criteria. Given the centrality metrics that capture the spatial interaction dynamics of traffic agents, we establish Behavior-aware Criteria that identify driving behavior not only based on the magnitude of these metrics but also on their temporal variation. Numerous studies have demonstrated the feasibility of this approach, showing that driving behavior can be identified using not only the instantaneous magnitude of features like speed but also their temporal derivatives, such as acceleration and jerk [53", ".", "This approach also aligns with human intuition, as driving behaviors characterized by large and fluctuating centrality measures over short periods are more likely to be relevant to driving behavior as sudden changes in acceleration within short intervals. Inspired by the established triadic relationship between velocity, acceleration, and jerk, we introduce three continuous criteria: Behavior Magnitude Index (BMI) $C_t^i$, which measures the influence of driving behaviors by evaluating their centrality; Behavior Tendency Index (BTI) $L_t^i$, which quantifies behavior propensity by calculating temporal derivatives, larger derivatives suggesting higher probabilities of specific behaviors; and Behavior Curvature Index (BCI) $I_t^i$, which uses the jerk concept to measure the intensity of driving behaviors by calculating the second-order derivatives of continuous centrality measures. At time t, the behavior $I_t^i$ for $v_i$ can be defined as $I_t^i = [C_t^i, L_t^i, I_t^i", "T$. Each component meticulously evaluates the magnitude, probability, and intensity of diverse driving behaviors exhibited by the target vehicle and its surrounding agents. This assessment is conducted through the computation of threshold rates, gradients, and concavities associated with centrality measures, which capture behaviors such as lane changes, acceleration, and deceleration, as well as aggressive, neutral, or conservative driving tendencies. The underlying rationale is that driving behaviors characterized by substantial and volatile centrality measure values over short time intervals are more likely to exert a significant influence on nearby agents, emphasizing the temporal dynamics that are integral to human drivers' decision-making processes.\n1) Behavior Magnitude Index. The BMI is designed to quantify the scale and interconnectedness of various driving behaviors by assessing their centrality measures. The BMI encapsulates the absolute values of these measures, providing a quantitative representation of a behavior's influence on the surrounding traffic agents. Specifically, the BMI focuses on each agent's centrality measures, with a higher index indicating that a particular driving behavior exerts a more significant impact on the current traffic dynamics. Formally, we first formulate the BMI $C_t^i$ for vehicle i as follows:\n$C_t^i = [|J_t^D(i"]