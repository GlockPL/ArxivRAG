{"title": "Is Elo Rating Reliable? A Study Under Model Misspecification", "authors": ["Shange Tang", "Yuanhao Wang", "Chi Jin"], "abstract": "Elo rating, widely used for skill assessment across diverse domains ranging from competitive games to large language models, is often understood as an incremental update algorithm for estimating a stationary Bradley-Terry (BT) model. However, our empirical analysis of practical matching datasets reveals two surprising findings: (1) Most games deviate significantly from the assumptions of the BT model and stationarity, raising questions on the reliability of Elo. (2) Despite these deviations, Elo frequently outperforms more complex rating systems, such as mElo and pairwise models, which are specifically designed to account for non-BT components in the data, particularly in terms of win rate prediction. This paper explains this unexpected phenomenon through three key perspectives: (a) We reinterpret Elo as an instance of online gradient descent, which provides no-regret guarantees even in misspecified and non-stationary settings. (b) Through extensive synthetic experiments on data generated from transitive but non-BT models, such as strongly or weakly stochastic transitive models, we show that the \"sparsity\" of practical matching data is a critical factor behind Elo's superior performance in prediction compared to more complex rating systems. (c) We observe a strong correlation between Elo's predictive accuracy and its ranking performance, further supporting its effectiveness in ranking.", "sections": [{"title": "1 Introduction", "content": "The Elo rating system, introduced by Arpad Elo (Elo, 1961), is a widely-used method for rating player strength in two-player, zero-sum games. Initially developed for chess, Elo has since been adopted across a broad range of games, including Go, sports, video games, and recently, in evaluating large language models (LLMs) and AI agents. Elo rating is usually interpreted as an incremental update algorithm for estimating an underlying stationary Bradley-Terry (BT) model. BT model assumes each player i has a scalar strength rating \u03b8[i] (which does not change), and for a single game between player i and j, the probability that player i wins is \u03c3(\u03b8[i] \u2013 \u03b8[j]), where is the logistic function. Based on this model, after each game, Elo rating system will adjust each player's rating according to the actual game result.\nDespite the widespread use of Elo, its foundation on games following stationary BT models appears restrictive. In this paper, we first examine whether the BT assumption holds in real-world datasets. Using a likelihood ratio test, we show that game outcomes in many datasets deviate significantly from the BT model, indicating substantial model misspecification. Furthermore, we observe that player skills and matchmaking distributions are often non-stationary. This raises serious concerns over Elo's reliability on practical uses. Surprisingly, we also observe that, despite these deviations, Elo still frequently outperform more complex models, such as mElo and pairwise methods-designed to capture non-BT components in predicting outcomes of the real-world games. These findings call for a deeper understanding of Elo beyond its conventional interpretation as a BT model parameter estimator. In this paper, we explore this phenomenon through three key perspectives.\nFirst, we interpret the Elo rating system through the lens of regret minimization. Specifically, Elo can be seen as an instance of online gradient descent\u2014an online convex optimization (OCO) algorithm with"}, {"title": "1.1 Related work", "content": "Methods for rating game players A large number of rating methods used in practice can be viewed as variants of Elo, most notably Glicko (Glickman, 1995), Glicko2 (Glickman, 2012) and TrueSkill (Herbrich et al., 2006). A common characteristic shared by these methods is that they assume a scalar rating for players with parametric probabilistic model (Bradley-Terry in Glicko and Thurstone in TrueSkill) and make incremental gradient-like updates for each game or a small batch of games. mElo (Balduzzi et al., 2018) and Disk Decomposition (Bertrand et al., 2023) generalize Elo score by rating every player with a multi-dimensional vector instead of a scalar. Their approach can be understood as low-rank approximation of the logits of the winning probabilities. In our work we regard them as Elo2k, and examine their performance is a central part of our work.\nBayeselo (Coulom, 2005) and WHR (Coulom, 2008) are two popular Bayesian methods that are also based on the BT model. They differ from Elo-like incremental updates by requiring more compute to produce a maximum a posteriori estimator every step.\nAnalysis of Elo score Despite its popularity and wide applicability, the analysis of Elo score is \"curiously absent\" (Aldous, 2017). Elo discussed practical concerns and small-scale statistical validations of the method in Elo (1978). Most related to this work, however, is the proposal of the linear approximation of the update formula. Aldous (2017) proved the existence and uniqueness of a stationary distribution under the Elo update rules without assuming realizability. However, the nature of this stationary distribution is not explored. de Pinho Zanco et al. (2024) analyzed the convergence of Elo score assuming round-robin match making, realizability of the Bradley-Terry model and linearization of \u03c3. For more empirical and simulation results, see Kir\u00e1ly & Qian (2017) and references within."}, {"title": "2 Preliminary", "content": "We consider the scenario where N players play against each other in a sequential manner. Specifically, for every t \u2208 [T], players it \u2208 [N] and jt \u2208 [N] are chosen by the matchmaking scheme to play against each other at time t. The outcome ot \u2208 [0,1] denotes the utility of player it, which can be chosen as 1, 1/2 and 0 to denote a victory, a draw and a loss respectively; Player jt receives utility 1 - Ot.\nThere are two main tasks in this setting. The first task is prediction, i.e., predicting the outcomes of the game. At time t, the learner is tasked to gives a prediction pt for the player it's win rate against jt, after observing the previous games {(ik, jk, ok)}=1 and the two players at the current round (it, jt). It is natural to evaluate the prediction accuracy of the algorithms by binary cross entropy loss\n$l_t := -(o_t \\ln p_t + (1 - o_t) \\ln(1 \u2013 p_t)).$\n(1)\nThe accumulated loss until time t is Lt := \u2211i=1 li\u00b7\nThe second task is ranking, i.e., give a total order or pairwise order for all players according to their relative strength. A total order ranking is well-defined only if the underlying game has a transitive structure. For simplicity of discussion, this paper will mostly focus on prediction, and leave the discussion of ranking to Section 4.3."}, {"title": "2.1 Algorithms", "content": "Here, we introduce several important and representative online rating algorithms."}, {"title": "3 Experiments on Real-world Matching Data", "content": "In this section, we conduct experiments on real-world datasets. Surprisingly, we find that most games deviate significantly from the assumptions of the BT model and stationarity, raising questions on the reliability of Elo. Despite these deviations, Elo frequently outperforms more complex rating systems, such as mElo and pairwise models, which are designed to account for non-BT components in the data, particularly in terms of win rate prediction."}, {"title": "3.1 Real-world games are neither BT nor stationary", "content": "In the Elo rating update rule (2), \u03c3(\u03b8[i] \u2013 0[j]) represents the predicted win probability of player i against player j. This prediction relies on the assumption that the underlying data follows the Bradley-Terry (BT) model. However, whether real-world data truly follows a stationary BT model remains unverified.\nIn this section, we conduct a likelihood ratio test on real-world datasets to examine the hypothesis that real- world game outcomes are generated by the BT model. Our results indicate that, across all examined datasets, the hypothesis is rejected, suggesting that real-world data does not follow the BT model. Furthermore, we provide evidence that both matchmaking and player skill exhibit non-stationarity in real-world games. These findings suggest that model misspecification widely exists when applying Elo to real-world data.\nRejecting BT on real-world dataset Note that the Bradley-Terry model can be equivalently written as a logistic regression model, where the parameter 0 is N-dimensional, and every game has a feature vector xt := e[it] \u2013 e[jt] \u2208 RN. We randomly split [T] into Ttrain and Ttest = [T] \\ Ttrain. Then the logistic regression loss on the test set is defined as\n$L_{test} (\\theta) = - \\sum_{t \\in [T]} [o_t\\ln(\\sigma(\\theta x_t))\n+ (1 \u2212 o_t) \\ln(1 \u2013 \\sigma(\\theta x_t))]$.\nNext, we augment the logistic model by adding two additional parameters a \u2208 R2, and a two dimensional feature gt \u2208 R2 for every game. In practice, gt is constructed using the training set Ttrain. Define the negative log likelihood of the augmented model as\n$L_{test} ([\\theta; \\alpha]) = - \\sum_{t \\in [T_{test}]} [o_t\\ln(\\sigma(\\theta x_t + \\alpha g_t))\n+ (1 \u2212 o_t) \\ln(1 \u2212 \\sigma(\\theta x_t + \\alpha g_t))]$.\nIf dataset is indeed realizable by a BT model with true scores 0*, the augmented model is also realizable with [0*;0] as long as gt and ot are independent, because\n$\\mathbb{E}[O_t|i_t, j_t, g_t] = \\sigma(\\theta^*[i_t] \u2013 \\theta^*[j_t])$.$"}, {"title": "3.2 Elo achieves good performance under model misspecification", "content": "Section 3.1 establishes that real-world games do not follow a stationary BT model, highlighting model misspecification in the applicaton of the Elo rating system. This raises important concerns regarding Elo's reliability in practical settings. In particular, it prompts the question of whether more sophisticated rating algorithms, such as Elo2k or Pairwise, which may better capture the underlying game distributions, could yield improved predictive performance. However, we examine the prediction accuracy for the next game outcome of various online algorithms in real-world datasets, and surprisingly find that despite the model misspecification, \"Elo-like\" algorithms still achieve strong predictive performance, outperforming complex algorithms even in some non-BT datasets. For each dataset, we compute the cumulative loss L\u315c for Elo, Elo2k (with k = 4), Glicko, TrueSkill, and Pairwise. The results, summarized in Table 2, show that in several real-world datasets, including Renju, Chess, Tennis, Scrabble, StarCraft and Go, Elo and \"Elo-like\" rating outperform more complexity rating systems such as Elo2k and Pairwise."}, {"title": "4 Understand Elo under Misspecification", "content": "The findings in Section 3.2 that the \"Elo-like\" algorithms outperform more complexity rating systems in some non-BT datasets, underscore the importance of adopting a new perspective on Elo (and other online"}, {"title": "4.1 New lens via regret minimization", "content": "In this section, we will view game rating through the lens of regret minimization in online optimization. We will adapt the framework of Online Convex Optimization (OCO) to the online algorithms. To facilitate our presentation, we briefly introduce OCO, following Hazan et al. (2016)'s definition.\nOnline Convex Optimization At iteration t, the online player chooses xt \u2208 K according to the information in steps 1,2,...,t-1. After the player has committed to this choice, a cost function ft \u2208 F : K \u2192 Ris revealed. Here, F is the bounded family of cost functions available to the adversary. The cost incurred by the online player is ft(xt), the value of the cost function for the choice xt. Let T denote the total number of game iterations. The regret is defined as\n$Regret_T := \\sum_{t=1}^{T}f_t(x_t) - min_{x \\in K} \\sum_{t=1}^{T} f(x)$,\nthat is, the cumulative loss minus the optimal loss in hindsight.\nIt turns out that online rating algorithms can be evaluated under this framework. At each time t, let ft be the binary cross entropy loss function induced by the players it and it and the outcome ot, and xt be the parameters updated by algorithms:\nft(xt) := -(ot ln pt + (1 \u2212 ot) ln(1 \u2013 pt)).\nHere pt is actually related to the parameter xt. Under this formulation, we have\n$L_T = Model \\ misspecification \\ error + Regret_T$.\n(3)"}, {"title": "4.2 Synthetic experiments: sparsity is critical", "content": "To further justify our interpretation of why Elo performs well even in non-BT datasets, in this section, we will conduct extensive synthetic experiments, as well as experiments on augmented real-world data. These experiments further show that the \"sparsity\" of the dataset plays a crucial role in the performance of algorithms.\nSynthetic experiments on non-BT datasets We begin with the scenario where the players' skills are stationary in the sense that E[ot|it = i, jt = j] = Pij for some matrix P\u2208RN\u00d7N. We consider the following two notions of the transitivity:\nDefinition 1 (SST). P is strongly stochastic transitive (SST) with respect to ordering \u03c0 if \u03c0(i) > \u03c0(j) implies Pik \u2265 Pjk for all k \u2208 [N].\nDefinition 2 (WST). P is weakly stochastic transitive (WST) with respect to ordering \u03c0if \u03c0(i) > \u03c0(j) implies Pij\u2265"}, {"title": "4.3 Ranking performance of Elo", "content": "Besides prediction, ranking is another important aspect that users consider when utilizing rating algorithms. There are two types of ranking: (1) for general P, we can consider the pairwise ranking, i.e., for each pair (i, j) \u2208 [N] \u00d7 [N], there is a ranking between i, j that is induced by Pij. (2) for transitive P, there exists a ground truth ranking induced by the transitivity. In this subsection, we will show that for pairwise ranking, the ranking performance is strongly correlated to prediction performance. Elo rating, achieves good performance of pairwise ranking in sparse regimes. However Elo should not be blindly trusted, since for the total ordering, Elo may not always give a consistent ranking, even in transitive datasets.\nGood prediction gives good pairwise ranking Regarding the pairwise ranking, it is natural to conjecture that pairwise ranking performance is correlated with the prediction performance, and our synthetic experiments justify this claim. We consider the same setup as the previous synthetic experiments for prediction (Section 4.2), and we calculated the pairwise ranking consistency for each algorithm at each time step: at time t, an algorithm can actually give an prediction Pij for every pair (i, j) \u2208 [N] \u00d7 [N]. We calculate the following quantity: r := 1(1[Pij < 0.5]1[Pij > 0.5]). Lower the value, more consistent the pairwise ranking. We plot against t/N for Elo, Elo2k and Pairwise in Figure 2b. e can see that the ranking performance is strongly correlated with the prediction performance. To be specific, similar to the prediction accuracy, in most sparse regimes, Elo performs well in pairwise ranking. However in"}, {"title": "5 Conclusion", "content": "In this paper, we find that real-world game data are non-BT and non-stationary. However despite the model misspecification, Elo still achieves strong predictive performance. We interpret this phenomenon through three perspectives: first we interpret Elo through a regret-minimization framework, proving its effectiveness under model misspecification. Second we conduct extensive synthetic and real-world experiments, and find that data sparsity plays a crucial role in algorithms' prediction performance. Finally we show a strong correlation between prediction accuracy and pairwise ranking performance."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here."}]}