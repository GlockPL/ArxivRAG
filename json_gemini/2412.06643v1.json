{"title": "Detecting Facial Image Manipulations with Multi-Layer CNN Models", "authors": ["Alejandro Marco Montejano", "Angela Sanchez Perez", "Javier Barrachina", "David Ortiz-Perez", "Manuel Benavent-Lledo", "Jose Garcia-Rodriguez"], "abstract": "The rapid evolution of digital image manipulation techniques poses significant challenges for content verification, with models such as stable diffusion and mid-journey producing highly realistic, yet synthetic, images that can deceive human perception. This research develops and evaluates convolutional neural networks (CNNs) specifically tailored for the detection of these manipulated images. The study implements a comparative analysis of three progressively complex CNN architectures, assessing their ability to classify and localize manipulations across various facial image modifications. Regularization and optimization techniques were systematically incorporated to improve feature extraction and performance. The results indicate that the proposed models achieve an accuracy of up to 76% in distinguishing manipulated images from genuine ones, surpassing traditional approaches. This research not only highlights the potential of CNNs in enhancing the robustness of digital media verification tools, but also provides insights into effective architectural adaptations and training strategies for low-computation environments. Future work will build on these findings by extending the architectures to handle more diverse manipulation techniques and integrating multi-modal data for improved detection capabilities.", "sections": [{"title": "I. INTRODUCTION", "content": "In an increasingly complex digital environment, the authenticity and integrity of visual content are critical for fostering trust and security. The rapid advancement of image generation technologies has made it easier than ever for individuals to create highly realistic visual content, including human representations, objects, and scenes, using simple commands or prompts [1]. While this accessibility has unleashed unprecedented creativity, it also raises significant concerns about the veracity of visual media, particularly in fields like journalism, communication, biometric identification, and online security.\nAmong the most pressing challenges are facial manipulations, which can distort reality and create deceptive imagery. Techniques such as face morphing [2], splicing [3], face swapping [4], and subtle alterations to facial expressions can mislead viewers and pose serious consequences. For example, face morphing blends features from multiple individuals into hybrid images, while splicing combines facial elements from distinct images to fabricate false representations [2]. Face swapping replaces one face with another, and subtle adjustments to facial gestures or expressions can manipulate perceptions without detection [4]. These techniques complicate the verification of image authenticity, underscoring the urgent need for effective detection methods.\nThese facial manipulation techniques pose substantial challenges for image authentication and verification, especially in contexts where digital manipulation can lead to serious consequences, such as biometric identification and online security [5]. Therefore, it is essential to develop effective methods for detecting and mitigating these manipulations to ensure the integrity and authenticity of visual content in critical environments, such as news and communication.\nTo address these challenges, this study focuses on developing tools and methodologies to detect and classify facial manipulations, as well as other forms of digital image tampering. The proposed solutions leverage deep learning models, specifically convolutional neural networks (CNNs), to detect subtle statistical differences between authentic and manipulated images. The study builds upon the MesoNet [6] binary classification model, addressing its key limitations: the inability to generalize beyond its training dataset and its restriction to a single class of image manipulation attacks. By overcoming these constraints, the research aims to enhance the reliability of visual content authentication, particularly in resource-limited environments where computational efficiency is essential.\nIn summary, the contributions of this paper are the following:\n\u2022 Development of a scalable and efficient multi-class classification system that achieves notable accuracy while maintaining computational efficiency. The system is designed to adapt to diverse requirements and effectively"}, {"title": "II. RELATED WORK", "content": "Previous work in relevant topics is reviewed.\n\nProbabilistic noise diffusion models, particularly Denoising Diffusion Probabilistic Models (DDPM), have emerged as a leading technique in image processing and computer vision (CV) for generating high-quality images from Gaussian noise [7]. This iterative approach gradually incorporates noise during training and subsequently removes it, enhancing the accuracy of generated data.\nGenerative Adversarial Networks (GANs) have been widely utilized for synthetic image generation, consisting of a generator and a discriminator that compete against each other. The generator learns to create realistic data that are indistinguishable from real samples, while the discriminator aims to identify the authenticity of the data. Although GANs excel at generating diverse and photorealistic images, they face challenges with regard to training stability and control over the generated results. [8]\nIn contrast, DDPMs offer advantages in training stability, result fidelity, and control during the generation process. They utilize a parameterized Markov chain structure trained via variational inference techniques to produce samples that fit observed data [9]. Recent advances have demonstrated that diffusion models can effectively generate high-quality samples by implementing denoising strategies across multiple noise levels during training, coupled with Langevin dynamics during sampling.\nThe ID Conditional DDPM has emerged as a key player in diffusion-based face exchange, allowing for the controlled transfer of facial identities while preserving attributes of the target face, such as expression and pose. This model leverages pre-trained expert facial models to ensure high fidelity and integrity in face synthesis. [9]\nIn addition, transformers, known for their success in natural language processing (NLP), have shown promise in digitally manipulated image detection. By capturing complex relationships in multimodal data, transformer-based models can analyze both images and text to identify digital manipulations, thus aiding in the preservation of visual content authenticity in an increasingly complex digital landscape. [10]\n\nIn the field of machine learning, there are two primary approaches for processing and understanding data: unimodal models, which handle a single source of data, and multimodal models, which integrate multiple sources or modalities, such as audio, video, text, and images. Multimodal models excel in capturing information from various sources and learning complex interrelationships, enabling them to perform specialized tasks effectively [10].\nThese models are particularly beneficial in applications where information from multiple sources is interrelated, such as in the detection of digital manipulations. Utilizing multimodal models can significantly enhance the results and performance of these tasks. Within the realm of multimodal learning, two specific learning methods stand out for analyzing and processing data, particularly in the context of text and image interactions [10].\nHuman faces are essential for communication and the association of identities, including gender and age. Facial recognition technology is susceptible to manipulation by malicious actors.\nTo address this issue, an approach employing an attentional mechanism for the detection of manipulated facial images and the identification of specific tampered regions is proposed. By refining feature maps during the classification task, the learned attention maps emphasize informative regions, thereby enhancing the accuracy of distinguishing between authentic and manipulated faces and visualizing tampered areas.\n\nThe use of compact networks enables the implementation of detection models on devices with limited computational capacity, facilitating operation without complex systems. DeepFakes can be generated using autoencoders, which compress image data in an encoder to reduce noise and computational cost. The original image can be restored through a decoder. The training process involves extracting faces from existing deepfake videos by selecting specific frames, ensuring that various face angles and resolution levels are uniformly distributed across genuine and deepfake datasets [11].\nMesoNet, a specialized neural network designed to detect manipulations in facial videos, primarily targets techniques"}, {"title": "III. METHODOLOGY", "content": "This section presents the methodology employed in this research to address the challenges of detecting and classifying digitally manipulated facial images. Existing lightweight models, such as MesoNet, are advantageous due to their low computational requirements, making them well-suited for resource-constrained environments. However, their binary classification framework and reduced accuracy on unseen datasets reveal notable limitations. To address these issues, this study introduces advanced preprocessing techniques and architectural improvements designed to enhance the model's robustness and generalization capabilities while maintaining computational efficiency. The result is a novel architecture designated as MesoNet+.\nA critical component in this methodology is the preprocessing and alignment of input images. Proper image alignment ensures standardized face positions and sizes, facilitating feature analysis and enhancing model performance. Facial landmarks, such as eyes, nose, and mouth, are detected using a pre-trained model [14], enabling geometric transformations like translation, rotation, scaling, and cropping. These transformations ensure consistent orientation and size, optimizing the model's ability to detect anomalies and classify manipulation types accurately.\nThe first proposed architecture, MesoNet+, is a refined binary classification model based on the original MesoNet. This enhanced design incorporates two additional convolutional layers, increasing the model's capacity to extract and analyze subtle features. These modifications address MesoNet's limitations, particularly its reduced generalization performance on unseen datasets, by refining the attention mechanism and enhancing feature extraction capabilities.\nBuilding on this foundation, the focus shifts to multi-class classification with the development of the MesoMultiNet model. This architecture adapts the MesoNet framework to classify multiple manipulation types, employing a Softmax activation function for multi-class output. To further improve"}, {"title": "IV. EVALUATION OF IMAGE CLASSIFICATION MODELS. RESULTS AND COMPARATIVE ANALYSIS", "content": "This section presents a detailed analysis of the progress and evolution of the convolutional network based on the MesoNet architecture, a classifier network for genuine images and digital image manipulations. It has been segmented at various points to provide a comprehensive overview of the development and improvements incorporated in each successive version. This approach allows a full understanding of how the network has evolved over time and how the challenges and limitations encountered in previous versions have been addressed.\nIn this research, the dataset plays a fundamental role in training and evaluating the proposed models in the context of detecting and classifying images generated by DeepFake techniques. To ensure the validity and robustness of the experiments, we selected and configured state-of-the-art databases, complemented with specific modifications tailored to meet the particular needs of our system. Below, we detail the selection, organization, and use of the various datasets employed in different phases of the study.\nDataset created by MesoNet principal investigators, images generated by DeepFake methodologies. For the first response, the following data samples are studied [6]. In a first phase, the model was adapted to work with a limited number of predictions, thus avoiding that the memory buffer of our computer would fill up and causing the interruption of the evaluation. For this purpose, in this first phase, we limited ourselves to a total of 19509 images divided into training and evaluation sets."}, {"title": "V. CONCLUSIONS", "content": "In this study, various convolutional neural network (CNN) architectures were designed and evaluated for the classification of digitally manipulated images. The research yielded promising results through the development and implementation of classification models optimized for low computational cost, enabling a discriminative model suitable for execution in resource-constrained systems.\nThe development of the MesoNet+ and MesoMultiNet+ architectures has demonstrated high efficiency in classifying genuine images versus manipulated images. Especially, the MesoMultiNet+ model stands out for its ability to improve performance by including AI-generated images in its training. This underlines the importance of using varied and representative data sets during model training to capture the diversity of possible manipulations."}]}