{"title": "AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG", "authors": ["YICHEN SHI", "ZHUOFU TAO", "YUHAO GAO", "TIANJIA ZHOU", "CHENG CHANG", "YAXING WANG", "BINGYU CHEN", "GENHAO ZHANG", "ALVIN LIU", "ZHIPING YU", "TING-JUNG LIN", "LEI HE"], "abstract": "High-performance analog and mixed-signal (AMS) circuits are mainly full-custom designed, which is time-consuming and labor-intensive. A significant portion of the effort is experience-driven, which makes the automation of AMS circuit design a formidable challenge. Large language models (LLMs) have emerged as powerful tools for Electronic Design Automation (EDA) applications, fostering advancements in the automatic design process for large-scale AMS circuits. However, the absence of high-quality datasets has led to issues such as model hallucination, which undermines the robustness of automatically generated circuit designs. To address this issue, this paper introduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and netlists. We construct a knowledge graph with annotations on detailed functional and performance characteristics. Facilitated by AMSnet-KG, we propose an automated AMS circuit generation framework that utilizes the comprehensive knowledge embedded in LLMs. We first formulate a design strategy (e.g., circuit architecture using a number of circuit components) based on required specifications. Next, matched circuit components are retrieved and assembled into a complete topology, and transistor sizing is obtained through Bayesian optimization. Simulation results of the netlist are fed back to the LLM for further topology refinement, ensuring the circuit design specifications are met. We perform case studies of operational amplifier and comparator design to verify the automatic design flow from specifications to netlists with minimal human effort. The dataset used in this paper will be open-sourced upon publishing of this paper.", "sections": [{"title": "1 Introduction", "content": "Digital circuit synthesis has been extensively utilized in electronic design automation (EDA) [18], enabling contemporary large-scale digital integrated circuits (ICs) in accordance with Moore's Law. However, the degree of automation in analog and mixed-signal (AMS) circuit design significantly lags behind that of digital design [22]. Today's AMS circuits are primarily full-custom designed and still heavily depend on human experts to determine circuit topologies and component sizing. The time-consuming and labor-intensive design process significantly hinders the scalability of AMS circuits.\nLarge language models (LLMs) have recently demonstrated the potential to address various EDA challenges [37], offering new hopes for automatic AMS circuit design. However, the availability of high-quality digital circuit data on the Internet, such as Verilog code, far exceeds that of AMS circuits mainly represented by SPICE netlists [10]. Consequently, LLMs have been extensively applied in the digital circuit domain, with significant work done in RTL code generation [15, 27], yielding promising results. However, their application in AMS circuits is still in an exploratory phase. Researchers have utilized LLMs to assist analog circuit topology design and transistor sizing [4, 10, 13, 35]. Compared to traditional AI methods such as reinforcement learning and Bayesian optimization (BO), LLMs demonstrate much better interactivity, knowledge transfer and expansion capabilities, and interpretability of design solutions.\nHowever, due to the scarcity of public AMS circuit netlist datasets, LLMs are not sufficiently trained to produce accurate netlists with correct topology and reasonable sizing [4, 10]. Researchers have improved the performance of LLMs in designing AMS circuits by training them with datasets collected for specific circuits [4], or by employing prompt engineering techniques including chain of thought (CoT) [32], ReAct [34], and in-context learning (ICL) [8, 10, 14]. Similarly, retrieval-augmented generation (RAG) is also used to supplement LLMs with additional knowledge without requiring the expensive retraining [13]."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Analog Circuit Datset", "content": "Due to the scarcity of open-source AMS circuit data, LLMs cannot achieve satisfactory AMS design results. AMSnet collects many circuit schematics from textbooks and academic papers and generates corresponding netlists [26]. AICircuit provides nine different types of AMS circuits with circuit schematics and a large number of simulation results for sizing[17]. [9] contains five types of AMS circuits, including schematic images, netlists, and testbenches. ALIGN provides a comprehensive collection of AMS circuits along with some well-sized parameters [21]. AncstrGNN Benchmark collects many analog circuit netlists without schematic images [3]. Previous open-source datasets mostly contained only circuit schematic and netlists, which were not directly usable for LLMs. In this work, we expand and annotate the AMSnet dataset, enabling smoother retrieval by LLM during design."}, {"title": "2.2 Machine Learning for AMS Circuit Design", "content": "The automatic design of AMS circuits primarily includes topology synthesis and transistor sizing. In the era before LLMs, traditional machine learning (ML) methods for automatically designing AMS circuits were primarily divided into two types: 1) evolutionary algorithms (EA) based methods and 2) graph-based methods. The EA-based generation of circuit topologies, such as genetic algorithms and evolutionary algorithms, typically involves encoding circuit topologies into forms such as trees [16] and graphs [1]. New circuit topology can be generated through genetic operations, allowing for the evolutionary breeding of circuit designs. In graph-based methods, a comprehensive building block library is established, and circuit topology generation is conducted through the construction of graphs. The predefined building block library includes components such as resistors, capacitors, or any subcircuit (like current mirrors, etc.), and these elements are combined using methods based on reinforcement learning or similar techniques. This approach allows for efficient and intelligent assembly of complex circuit designs.\nLLMs have demonstrated remarkable capabilities in numerous EDA tasks, such as Verilog and RTL code generation[28]. Recent efforts have also explored using LLMs to directly generate circuit topology [4, 10]. However, due to the scarcity of AMS circuit topology data in pretrain datasets, these efforts have not been very effective. Artisian[4] trained an LLM for the automatic behavior-level design of OPAMPs. However, the OPAMP-specific knowledge used to train their LLM cannot be smoothly generalized to other types of circuits, such as comparators and LDOs. Furthermore, it models circuits at a behavior level, resulting in higher transistor counts than a standard design. AnalogCoder [10] did not retrain the model but used carefully designed prompts to leverage the LLM's capability to generate netlists. Due to the"}, {"title": "2.3 Sizing", "content": "The goal of analog integrated circuit sizing is to determine the parameters of circuit components, such as transistors, within a given topology to meet design objectives. However, the substantial intra-class and inter-class variations, coupled with varying design goals across different circuit types, render the sizing process for analog integrated circuits particularly challenging. Researchers have extensively studied the automation of this process, primarily categorizing the methods into two types: 1) knowledge-based and 2) optimization-based methods. For knowledge-based methods such as [7], circuit designers create predefined schemes and equations to calculate transistor sizes. However, deriving design schemes for every existing circuit topology is very time-consuming, and also requires continuous maintenance to keep up with the latest process technologies. Notably, LADAC [13] designed the first LLM agent for analog circuit sizing. By constructing an expert knowledge base, integrating ICL and CoT for decision-making, LADAC successfully derived transistor parameters for multiple circuit topologies, and satisfied their respective design specifications. Optimization-based methods treat the performance of circuits as a black-box function and use heuristic algorithms [11, 12, 20, 23-25, 30] or surrogate model approaches for optimization [5, 6, 19, 33, 36]. The use of Gaussian processes as surrogate models in optimization methods has been widely studied. ADO-LLM[35] combines an LLM with Bayesian Optimization (BO), using both the LLM and the acquisition function to determine the next sampling point. Yet, they did not discuss how to incorporate PDK technology nodes into their workflow, despite that PDKs play an important role in the sizing process. Previous optimization-based methods included expert insights to reduce search space[29], but did not provide a systematic method to store and use these insights. Therefore, we propose an universal format in this work to store expert insights for transistor sizing."}, {"title": "3 AMSnet-KG Construction", "content": "This section discusses the methods used to construct the AMSnet-KG dataset. We collect raw schematics and descriptions from literature sources, and label schematics in pages as well as components in schematics. We then propose a connectivity detection algorithm to create the netlists. Finally, we build the knowledge graph (KG) AMSnet-KG with collected schematics, netlists, and detailed annotations, to be defined below."}, {"title": "3.1 Data Collection", "content": "As shown in Fig. 3, we first collect large quantities of raw data from textbooks and academic papers. These materials are rich in circuit schematics and verbal description, and provide sufficient foundation to form our <schematic, netlist, annotation> dataset. To reduce the cost of manually extracting circuit schematics, we employ a semi-supervised learning approach. We annotate bounding boxes over schematics on a subset of page images, and train an object detection model with the labeled data. This model is then used to identify and extract all circuit schematics from the remaining pages.\nSince most literature print their schematics, individual components are generally printed in a very uniform fashion, which allows us to perform template matching. Instead of manually annotating bounding boxes on components within schematics to form a training set as we did with literature pages, we only need to annotate a single copy of each component type. For example, after annotating a PMOS transistor, the region of interest (RoI) within the bounding box can be template-matched against the other schematics to quickly identify all other PMOS transistors. This drastically"}, {"title": "3.2 Netlist Generation from Schematic Image", "content": "After identifying the components, we can label the net connections. The current version relies on two assumptions: 1) all the wires are represented by solid lines on the schematic diagram, and 2) without a junction, two intersecting wires are not considered connected. These assumptions enable us to implement the net detection algorithm as follows.\nThe first step is to group all neighboring components. Starting from each pixel on each bounding box, the algorithm expands into neighboring wire pixels in all directions, until it encounters other components. This step groups directly components into clusters, each representing a net. Fig. 5 shows an example.\nEach group has four possible cases: 1) The group contains only the starting component, as shown in the green group in Fig. 5. In this case, no connectivity has been detected. 2) The group contains exactly two components, as depicted by the blue and brown groups in Fig. 5; here, the two components are connected. 3) The group has an odd number of components (more than two). This scenario likely indicates that a junction has been omitted. However, the algorithm cannot determine which subset of the group is connected and which is intersecting. Therefore, we flag the entire schematic as an exception; manual attention is required to correct it before it can be analyzed again.\nFor the last case, there are an even number (more than 2) of components in the group, as illustrated in Fig. 6. We assume the schematic has not omitted any junctions; thus, the intersecting wires are not connected. To address this, we locate the intersections by applying a 2D convolution to the searched wiring. Given that the area around the intersection typically contains a higher density of wire pixels, we identify the indices with the maximum values as the intersection point and add it to our labeled components. Later, the algorithm eliminates the four-component cluster by repeating the grouping process, connecting each of the four components to the intersection. In the case of more than four components in the group, each iteration reduces the group size by two until each group is left with two components eventually. It is important to note that line weights and layout may influence this step, making the dimension of the convolution kernel a tunable parameter. We reroute opposite connections to each other, and then delete the intersection to finalize the process.\nAfter all the nets are identified, the SPICE netlist format for some components requires the correct order of connections. For example, the connections to four-terminal MOSFETs must follow the order of drain, gate, source, and body / substrate. For components, the bounding boxes are labeled with orientation, and the algorithm can determine a range of angles for each connection, as shown in Fig. 7. For symbols, as shown in Fig. 4, we mark a number on each pin, and use MLLM to determine their function. The quality of the net labeling process was manually verified, which arrived at an accuracy of 96%. Erroneous results are manually corrected to ensure data quality."}, {"title": "3.3 Circuit Annotation", "content": "In addition to schematics and netlists, we also include annotations to enrich circuit data. We define two types of annotations: local and global, where local annotations describe one or more component(s) of the circuit, while global annotations describe the entire architecture.\nThe purpose of local annotations is to guide usage of the current circuit, and is hand-labeled in this work. Some examples include identifying nets as inputs, biases, outputs, or identifying groups of components as building blocks such as current mirror or differential pair. An important type of local annotation is to label sizing constraints, marking certain sets of components to follow constraints such as symmetry in lengths and widths. These constraints are usually expert insights gained from their design experience, and play an important role in the sizing process to reduce search space and computation costs. Net labels, on the other hand, are used to connect pins of circuits to testbenches.\nThe purpose of global annotations is to guide topology selection, to use a circuit as opposed to other circuits. It is common that each individual circuit does not have a generally agreed name to identify them. Instead, they are described by circuit components or remembered by their specialties. An engineer may describe an OPAMP with its stages, or decide to use it for its exceptional performance in a specific area. To enable this information retrieval process, we label each circuit with its architectural descriptions such as performance specialties and circuit subcomponents. Specifically, we exploit the fact that the source literature where we first obtained each schematic, would most likely include some verbal description in the context. We use this information in addition to the schematic image and invoke MLLM to summarize qualitative description into key-value pairs, such as {gain: high} or {load: current mirror}."}, {"title": "3.4 Knowledge Graph Construction", "content": "A knowledge graph (KG) is a structured form of knowledge representation that expresses the relationships between entities. In a knowledge graph, nodes typically represent entities, and edges signify various semantic relationships between these entities. The basic unit of composition is the \"entity-relation-entity\u201d relation query triplet, where entities are interconnected through relations, forming a graph-like data structure. In this work, we collect all schematics, netlists, and annotation data to create the AMSnet-KG dataset.\nAMSnet-KG defines an entity as either a string or a circuit. The annotation keys and values are simply represented as strings, while the circuit object contains a schematic, a netlist, a set of image attributes such as bounding boxes and net marks, and all local annotations. Relations, on the other hand, only serve to connect entities and are therefore also simply strings. Fig. 9 illustrates a small scale knowledge graph created from two circuits and two testbenches."}, {"title": "3.5 Dataset Summary", "content": "To summarize, AMSnet currently contains 894 circuits with schematic diagrams, component bounding boxes, and netlists. AMSnet-KG selects application-specific circuits and further include local and global annotations. It currently contains OPAMPs, comparators, bandgaps, LDOs, and ADCs, as well as related testbenches."}, {"title": "4 AMSgen: AMSnet-KG Driven Automated Circuit Generation", "content": "The data support from AMSnet-KG enables us to fully automate AMS circuit design, from performance specification to fully sized netlists. In this section, we explore our LLM-assisted, data-driven design pipeline, as shown in Fig. 10, which autonomously selects circuit topology and simulation testbenches in section 4.1, and optimizes transistor sizing in section 4.2. In the case where the initial topology fails to reach performance goals after sizing, we automatically regenerate the topology in section 4.3."}, {"title": "4.1 Topology Selection via KG-RAG", "content": "Traditionally, analog / mixed-signal (AMS) circuits are designed manually by engineers, starting with circuit topology and the testbench selection. At the outset, the engineer considers a set of desired performance specifications. Drawing from their experience or supplementary materials, they identify circuit topologies that meet the design goals and select testbenches to evaluate each performance metric. However, this process is highly labor-intensive, time-consuming, and experience-driven, making it difficult to automate or abstract into code such as RTL. With the LLM technology available today in addition to our AMSnet-KG data support, we are able to fully automate this process and achieve the same goals. Given a set of performance metrics, we obtain a design strategy from the LLM which outlines the circuit architecture as a set of circuit components. Then, we select the corresponding circuits and testbenches from AMSnet-KG, before assembling them for simulation.\nWe design a comprehensive prompt engineering framework, incorporating in-context learning (ICL) [8, 14] and chain of thought (CoT) [32], for generating circuit topology design strategy, a short verion is shown in Fig. 11, while full versions are shown in the Appendix section B. The state-of-art LLMs possess sufficient knowledge to provide a"}, {"title": "4.2 Constraint-Augmented Sizing", "content": "Now that the circuit and testbenches have been fixed, we optimize component parameters to obtain maximal performance achievable with the given topology. In this section, we formulate sizing as a black-box optimization problem and resolve it through Bayesian optimization (BO) with local annotations retrieved from AMSnet-KG. The details of BO are included in Appendix section A."}, {"title": "4.2.1 Problem Formulation", "content": "The standard constrained optimization problem is shown in Equation (1):\nmaximize FoM(x)\ns.t.  \\(g_j(x) \\leq 0, \\forall j\\in \\{1, ..., p\\}\\) (1)"}, {"title": "4.3 Topology Regeneration", "content": "In the case where an initial topology design does not satisfy the desired metrics after a set amount of sizing effort (or it costs too much circuit area for the desired results), we consider this a topology issue and begin regeneration. The topology regeneration process is very similar to the initial topology design process. The only difference is that instead of using a different circuit application in the fewshot examples, here we use actual performance specifications obtained from the previous design(s) to give the LLM additional quantitative knowledge.\nWith the previous design strategy proposed by the LLM and the optimal performance during simulation, we reverse the cause-effect and pretend that we initially wanted to achieve the performance metrics, and then correctly obtained the previous design. For example, suppose we desire an OPAMP with a DM gain of 60 dB, the LLM initially proposed a design strategy to retrieve circuit components and assemble circuit A. Then we go through the process outlined in section 4.2, and finally ended with a fully sized design that only achieves a DM gain of 40 dB. We would now inject"}, {"title": "5 Experiments", "content": ""}, {"title": "5.1 Experiment Setup", "content": "We use YOLO-V8 for object detection during AMSnet-KG construction, Neo4j for knowledge graph implementation, and GPT-4 for various inquiries throughout dataset construction and circuit design. Our experiments are performed using a 28nm technology from SMIC, which restricts our transistor length, width, and number of fingers to [30nm, 1\u00b5m], [100nm, 3\u00b5m), and [1, 100] respectively. We use Bayesian optimization (BO) implemented by the Optuna [2] library, and limit our total simulation count to 2000."}, {"title": "5.2 Case Study of OPAMP Topology Design", "content": ""}, {"title": "5.2.1 Topology selection", "content": "Initially, we request an OPAMP design to achieve the performance goals in Equation 3.\nGain > 80 dB,  CMRR > 80 dB,  PSRR > 80 dB,  GBW > 10 MHz,  PM > 60\u00b0,  \\(C_L = 100 pF\\) (3)\nIn order to keep any incorrect numerical information from the in-context learning, we use a different type of circuit to offer the reasoning format and chain of thought. Specifically, we use a comparator design flow as a fewshot example. Fig. 19 and Fig. 20 in the Appendix section B.1 presents the full conversation. In this case, the LLM responds with the design strategy of a two-stage OPAMP, where the first stage is a differential amplifier with a current mirror load, the second stage is a common-source amplifier, and a Miller compensation is to be added between the outputs of the first and second stage.\nWe then convert this design strategy to a set of relation query triplets, Fig. 21 and Fig. 22 in the Appendix section B.1 presents the full conversation. The triplets are then used to query AMSnet-KG and retrieve circuits. For example, <, input, differential input pair>, <, load, PMOS current mirror> retrieves a single stage 5-transistor OPAMP. Similarly, we retrieve the common source amplifier, the bias circuitry with a current source and an NMOS transistor, and the sequentially connected resistor-capacitor pair for Miller compensation. Using the local annotations on each circuit component, we connect the output from the first stage to the input of the second stage, the bias voltage of both stages to the bias circuitry, and a Miller compensation to the output of the first stage and the output of the second stage. The fully assembled 2-stage OPAMP is shown in Fig. 13."}, {"title": "5.2.2 Sizing", "content": "The given specifications forms the FoM in Equation 4, where \\(f_{gain}(x)\\), \\(f_{cmrr}(x)\\), \\(f_{psrr}(x)\\), \\(f_{gbw}(x)\\), and \\(f_{pm}(x)\\) each represent the simulated gain, CMRR, PSRR, gain-bandwidth product, and phase margin. Each \\(f^{min}\\) and \\(f^{max}\\) represent the corresponding minimum and maximum metric for normalization purposes, and are observed within an initial set of 100 simulations. Note that since the GBW distribution is exponential, we first take the decimal log of each value before using it for FoM to prevent it from overtaking other values. As for phase margin, instead of requiring a high value, we actually want the value to be as close to 60 degrees as possible, therefore we introduce its distance away from 60 degrees as a penalty.\nFoM =  \nAs shown in Fig. 13(e), our design consists of 5 NMOS transistors and 3 PMOS transistors, each of which is described by two parameters: gate length (L) and gate width (W). In addition, we have a current source, a capacitor, and a resistor, each described by a single parameter, for a total of 19 free parameters.\nInsights from experienced engineers could effectively reduce the complexity of the sizing process, such as the parameter search space. We make use of the local annotations stored in AMSnet-KG, as shown in Fig. 13. Transistors with the same highlight color share the same set of L and W. This way, our effective number of free parameters reduces from 19 to 15, and is more manageable."}, {"title": "5.2.3 Topology Regeneration", "content": "The regeneration process for LLM to propose another design strategy is very similar to the initial strategy proposal. Here, instead of using for performance specification requirements and design structure from other applications such as comparators in fewshot examples, we are now able to simply use the previous, unsuccessful design. This allows us to make a numerical comparison between the two circuits for a specification, and thus leverage the LLM's vast knowledge on comparative performance between circuits. As shown in Fig. 23 and Fig. 24 in the Appendix section B.2, we reverse the cause-effect order by pretending that we initially wanted a design to achieve a DM gain of 66.21 dB, gain-bandwidth product of 319MHz, etc. The analysis and design strategy would be the same as the previous circuit topology. Afterwards, by asking the same question, the LLM naturally gains a quantitative comparison between the existing performance specification in the fewshot example and the actual prompt. This resolves our previous issue where the LLM has insufficient knowledge regarding the specific technology node we are using."}, {"title": "5.3 Case Study of Comparator Topology Design", "content": ""}, {"title": "5.3.1 Topology selection", "content": "In order to evaluate the AMSgen workflow on different applications, we introduce another case study on comparators. Similar to generating OPAMPs, we begin by requesting a comparator design from LLMs, using the same PDK and constraints, and a comparator-specific set of performance specifications as follows:\nSampling frequency = 1GHz, Offset voltage < 100 uV, Propagation delay  100 uW\nThe LLM first responds with the use of a latch comparator. Similar to the OPAMP case study, we then take this response, convert it into relation query triplets, and search within AMSnet-KG for matching topologies.\nThis time, we arrive at two different types of comparator topologies: strong-arm latch comparator and double-tail latch comparator. For tie-breaking purposes, we feed the two names back into the LLM to make a final selection, and arrive at the strongarm latch comparator. The conversations are shown in the Appendix section B.3 in Fig. 27 through Fig. 31."}, {"title": "5.3.2 Sizing", "content": "FoM = \nSimilar to the OPAMP case study, we employ Bayesian optimization to obtain the optimal sizing using the FoM in Equation 5, where \\(f_{ov} (x)\\), \\(f_{pd}(x)\\), \\(f_p(x)\\) each represent the simulated offset voltage, propagation delay, and power for given sizing x. Every metric is viewed on a logarithmic scale, similar to GBW in the OPAMP case study. A similar set of local annotations are used to guide sizing constraints. As shown in Fig. 17, there are a total of 5 PMOS and 6 NMOS transistors. Each of them is parameterized by a length and a width for a total of 22 parameters. After considering symmetry, the number of free parameters drop to 10."}, {"title": "6 Conclusions and Disscussions", "content": "In this paper, we introduce a new high-quality dataset for AMS circuits, titled AMSnet-KG, which includes schematics, netlists, and manual annotations, all presented as a knowledge graph. We also propose an AMS circuit topology design process based on LLM and KG-RAG. This process begins from input performance specifications into LLM to obtain a design strategy (e.g., circuit architecture), which is then transformed into relation query triplets. Relevant circuit components and testbenches are then retrieved from the knowledge graph. After assembling a complete circuit using retrieved components, parameter sizing is finalized using Bayesian optimization based on design constraints. If the resulting design fails to meet specifications (or costs too much circuit area to meet specifications), the design strategy is adjusted and the topology is refined. We have experimented two case studies and obtained desired OPAMP and Comparator designs.\nIn the future, we plan to enrich AMSnet-KG with additional information, such as specific parameter sets with corresponding circuit performance. We also plan to introduce new circuits types and additional topologies. The increasing size and dimension could support more application scenarios, such as training AMS-specific foundation models. We will also develop more efficient performance modeling/prediction with reduced SPICE simulation runs or no SPICE simulation for the sizing procedure, and develop better sizing algorithms compared to existing algorithms."}, {"title": "A Background", "content": ""}, {"title": "A.1 Bayesian Optimization", "content": "Bayesian optimization (BO) is a strategy for global optimization, particularly suitable for optimizing black-box functions, usually employed when the function evaluation is expensive or the search space is too large to exhaust. BO treats the black-box function to be optimized as a stochastic process, typically modeled using a Gaussian Process (GP) as a surrogate model. The GP provides a flexible way to describe the distribution of the black-box function and updates predictions based on existing data points.\nBy sampling initial data points, the GP model is trained to fit the black-box function. An acquisition function is selected to balance exploration and exploitation, determining the next sampling point. In the input space, the point that maximizes the acquisition function is found. The selected new point is then evaluated through simulation, and its result is added to the existing dataset, updating the GP model. By balancing exploration and exploitation, BO can avoid getting trapped in local optima and find the global optimum."}, {"title": "A.2 Gaussian Process", "content": "A GP is a stochastic process defined over an input space, where any finite subset of random variables follows a multivariate Gaussian distribution. Given a training dataset \\(\\{(x_i, y_i)\\}_{i=1}^n\\), where \\(x_i\\) are the inputs and \\(y_i\\) are the target values. A GP is completely defined by its mean function \\(\\mu(x)\\) and covariance function \\(k(x, x')\\). The mean function represents the expected value of the function at a given input, and the covariance function (also called the kernel function) represents the correlation or similarity between any two points. Generally, the mean function of a GP is assumed to be zero:\nm(x) = E[f(x)] = 0 (6)\nThe kernel function k(x, x') is defined as:\nk(x, x') = E[(f(x) \u2013 m(x))(f(x') \u2013 m(x'))] (7)\nFor a new input point x, the predictive distribution is also a Gaussian distribution. The mean and variance of the prediction can be computed as follows:\n\\$\\mu_* = k(x_*, X)^TK^{-1}y (8)\n\\$\\sigma_*^2 = k(x_*, x_*) \u2013 k(x_*,X)^TK^{-1}k(x_*, X) (9)\nwhere k(x*, X) is the covariance vector between the new input point and all training data points, and y is the vector of target values for the training data."}, {"title": "A.3 Acquisition Function", "content": "The acquisition function is a key component in BO, used to select the next evaluation point. It balances exploration and exploitation, making trade-offs between exploring unknown regions and exploiting the known best regions.\nExpected Improvement (EI): EI measures the expected amount of improvement over the current best point. The formula is:\n\\$\\alpha_{EI}(x) = E[max(0, f(x) - f(x^+))] (10)\nwhere f(x+) is the current best observed value."}, {"title": "B Complete LLM Conversations", "content": ""}, {"title": "B.1 Opamp Initial Design", "content": ""}, {"title": "B.2 Opamp Regenerated Design", "content": ""}, {"title": "B.3 Comparator Design", "content": ""}]}