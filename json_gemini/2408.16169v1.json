{"title": "Simulating realistic short tandem repeat capillary electrophoretic signal using a generative adversarial network", "authors": ["Duncan Taylor", "Melissa A. Humphries"], "abstract": "DNA profiles are made up from multiple series of electrophoretic signal measuring fluorescence over time. Typically, human DNA analysts \u2018read' DNA profiles using their experience to distinguish instrument noise, artefactual signal, and signal corresponding to DNA fragments of interest. Recent work has developed an artificial neural network (ANN) to carry out the task of classifying fluorescence types into categories in DNA profile electrophoretic signal. But the creation of the necessarily large amount of labelled training data for the ANN is time consuming and expensive, and a limiting factor in the ability to robustly train the ANN. If realistic, pre-labelled, training data could be simulated then this would remove the barrier to training an ANN with high efficacy. Here we develop a generative adversarial network (GAN), modified from the pix2pix GAN to achieve this task. With 1078 DNA profiles we train the GAN and achieve the ability to simulate DNA profile information, and then use the generator from the GAN as a \u2018realism filter' that applies the noise and artefact elements exhibited in typical electrophoretic signal.", "sections": [{"title": "1.0 - Introduction", "content": "The process of classifying the fluorescence in the DNA profile is predominantly done by, commonly two, human readers in forensic biology laboratories. This process is time consuming and produces hard (as opposed to probabilistic) classifications of features into multiple categories. Artificial intelligence (AI) can be used to replace at least one of the human readers (Taylor, 2022; Taylor, Harrison, & Powers, 2017; Taylor, Kitselaar, & Powers, 2019; Taylor & Powers, 2016) and provides probabilistic classifications that can potentially increase the accuracy of DNA profile analysis (Taylor & Buckleton, 2023). However, the efficacy of the Al systems has been limited due to a lack of large amounts of labelled data. This paper presents a method for simulating the highly realistic DNA profiles required to train effective Al classification systems using biologically informed generative adversarial networks (GANs)."}, {"title": "1.1 \u2013 Classifying DNA profiles", "content": "Short tandem repeat (STR) DNA profiles are produced by passing fluorescently tagged amplicons through a gel-filled capillary (separating the fragments according to their size) and past a laser and detector (Butler, 2009). The greater the amount of starting DNA, the more amplified DNA fragments will be present (each with an attached fluorophore) and the greater the detected fluorescent signal will be. The strength of these detected signals is represented in electropherograms, displaying fluorescence over time, measured in relative fluorescence units (rfu). The electropherogram appears as a time series-like output with varying sized peaks representative of the features of the profile. Each point in the series is referred to as a \u2018scan point' in the raw signal, but are processed to represent the base pairs making up the fragment size in the final DNA profile). Modern DNA profiling systems utilise multiple fluorophores,"}, {"title": "1.2 \u2013 Biologically informed Generative Adversarial Networks (GAN)", "content": "One potential avenue that could simulate highly realistic electrophoretic signal is the use of generative adversarial networks (GAN) (Goodfellow et al., 2014). GANs are a system of competing ANNs, in which one ANN generates data designed to look as realistic as possible (the generator) and the other ANN discriminates between the generated data and real examples (the discriminator). As the GAN training progresses, the generator gets better at producing realistic data, and the discriminator gets better at discriminating between real and generated data, until the two systems have reached an equilibrium. At this point the generator is (ideally) generating highly realistic data.\nClassically, GANs are set up to simulate random, realistic data. For example, in the context of DNA profiles, the generator may learn to generate realistic looking signal from supplied random input. In this case, the output is also random and there is no control over the generated features of the signal. There are two practical limitations to using purely random input:\n1) Without defining where allelic signal is expected, pre-labelling of the simulated data as allele or artifact becomes impossible, and\n2) data with specific properties cannot be simulated to fill training data gaps that exist in the current set.\nBut the deepest limitation, keeping in mind that a lack of large amounts of data is driving this exploration, is that the GAN from a purely random input is unlikely to learn the nuances of the biological models that make position and height of peaks realistic (i.e., the level of peak height variability expected for peaks at different heights, the pairing of peaks in complex mixed profiles, the generation of stutter products during PCR). Meaning the output may loosely look real but be biologically invalid.\nFor this reason, the system of DNA profile simulation we propose uses biological models to simulate realistic information about the number, size and height of peaks expected in a DNA profile, and then will use a trained GANs to essentially apply a \u2018realism filter' to the simulated data. This combination of biological and generative models provides an ability to create unlimited, pre-labelled training data that looks highly realistic, and can be used to train a DNA profile classification ANN."}, {"title": "2.0 - Method", "content": "All calculations were carried out using R V4.2.3 (\"R Core Team. R: A language and environment for statistical computing,\" 2013) using packages tensorflow V2.11.0 (Abadi et al., 2015), Keras V2.11.1 (Chollet, 2015), and simDNAmixtures V1.0.1 (Kruijver, Kelly, Bright, & Buckleton, 2023)."}, {"title": "2.1 - Input data", "content": "A total of 1078 GlobalFiler\u2122 DNA profiles were used in the training of the GAN. Of the 1078 profiles, 669 were obtained from the online PROVEDIt dataset (Alfonse, Garrett, Lun, Duffy, & Grgicak, 2017) (taken from the GlobalFiler\u2122\u2122 29 cycle PROVEDIt, 2-5 Person profiles run on a ABI3500 with injection time of 5sec). The remaining 409 profiles were taken from the GlobalFiler\u2122 profile data run on ABI3500 used as training data by Taylor (Taylor, 2022) and de-identified, mixed casework profiles.\nThe DNA profiles ranged from being blank, with only baseline information present, to complex 5-person mixtures. From the PROVEDIt dataset the count of 2 to 5 person mixtures was 167, 141, 149, and 137 respectively (with the remaining 75 PROVEDIt samples being blanks). Peak heights ranged up to 32750 rfu (30 000rfu is typically considered the saturation level of the laboratory instrument used to capture EPG fluorescence and 33 000rfu is the upper capture limit).\nLadders were removed from the input data, however negative and positive controls were retained. HID files were converted to csv format, which held fluorescence at each scan point in each dye lane across the whole profile (approximately 10 000 scan points). Only scan points between 4000 and 9000 were used in training and generation as prior to 4000 the electrophoretic signal associated with primer flare and is not suitable for training, and beyond 9000 no peaks are expected. GlobalFiler\u2122 produces peaks labelled with 6 different fluorophores so the data for each profile is represented by a [6 x 5000] matrix of values. Values for rfu range between -30 000 and 30 000. Prior to use in any ANN, the mode of the fluorescence is then subtracted from each profile (acting as a simple baselining function, without changing the shape and patterns in the signal), and they are scaled down by a factor. Different scaling factors were trialled (data not shown) and a scaling factor of 100 was found to work best with both generator and discriminator."}, {"title": "2.2 - Choice of GAN", "content": "A common input for the generator in GANs is a series of random numbers. The generator then learns to turn these random numbers into the desired output. Isola et al (Isola, Zhu, Zhou, & Efros, 2018) developed a GAN system called pix2pix that provides an image as the input to the generator, and the task for the generator was to convert that image to another image, meeting both the requirements of generating a realistic looking image in the target style, but also retaining the features of the original input. An example use for this type of task would be to take a rough line drawing of an object (such as a building, shoe, or face) and then convert it to a realistic image of that drawn object. The generated image would look like the real object, but retain the shape, size and style of the original sketch. For DNA profile generation the pix2pix GAN allows the flexibility to incorporate a biologically informed \u201csketch\u201d of the DNA profile, making this an idea choice of GAN architecture. The pix2pix takes an idealised DNA profile (i.e., baseline of 0 and peaks represented by gaussian distributions) and learns to convert them to realistic counterparts.\nThere is a pix2pix package available for python (https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix), however this was not suitable for the electropherogram simulation application due to the fact that the input was not a square image (required by the code), but rather effectively six time series with 5000 scan points. Also, electrophoretic input possesses specific patterns of dependence across scan points within a dye lane and at a particular scan point between dye lanes, but not all around a central point such as in an image. Therefore, while the general architecture of GAN was based on pix2pix, a novel construction of ANNs were innovated for electrophoretic inputs, and the generator loss function was modified from the original published construction."}, {"title": "2.3 \u2013 Preparing generator input", "content": "For training to occur the pix2pix generator requires paired input images, one in the style of a typical input the generator will be provided, and the other being its real equivalent. These paired images are created from real starting images. The following steps were undertaken to create a biologically driven, idealised version of a profile:\n1. A baseline trend was determined by modelling the real profile with a lowess line using a smoother span of 0.05. This ensured a clean estimate of the trend, uninfluenced by the peaks. An example of the lowess line seen in Figure 1b.\n2. The lowess trend was subtracted from the real DNA profile to create a de-trended profile that no longer possesses baseline drift but does possess baseline noise.\n3. Using the de-trended profile, peaks were detected using the method of Woldegebriel (Woldegebriel, Asten, Kloosterman, & Viv\u00f3-Truyols, 2017), with two modifications. First, the algorithm weighed up the propositions that a peak was in the central 3 scan points of the window vs in any other scan point of the window, or no peak being present. Second, the context window first had the mode of the data within the window subtracted. This overcame some of the shortcomings of the lowess line (which did not always follow baseline drift completely, particularly when the drift caused relatively 'peaky' mounds). The cut-off for detecting a peak was that the probability for the central 3 scans possessing a peak centre was greater than $10^{10}$.\n4. The original DNA profile was passed through the ANN from Taylor (2022), and any peak centres detected in point 3 that had been classified as baseline or pull-up (according to the category with the maximum probability assigned by the ANN) were removed. If the input DNA profiles already had manually assigned labels then these were used rather than generating new assignments.\n5. The idealised profile was drawn with a baseline of 0 and peaks (with heights matching those in the de-trended real profile) drawn as normal distributions with a standard deviation of 4."}, {"title": "2.4 - The generator architecture", "content": "The generator in the original pix2pix GAN was an implementation of the U-Net convolution network designed by Ronnenberger et al for image segmentation (Ronneberger, Fischer, & Brox, 2015). The design of the U-Net is well suited for images, but not optimised for use on electrophoretic data. The architecture adapted for use on electrophoretic data, which was still based on the U-Net architecture, is shown in Figure 2:\nThe architecture in Figure 2 has several features to note:\nAfter an initial downsizing of the input, there is a U-Net structure that uses convolutional layers with filter sizes [1 x N] that specifically target the within-dye patterns in the profile input.\nThere is a secondary U-Net structure that uses a convolution layer with filter size of [6 x 1] that specifically target the across-dye patterns in the profile input.\nThe within-dye layers and the across-dye layers come together for the final upsizing to the output. The across-dye features are of dimension [1 x 500 x 32] and apply, but act differently, to each dye. Across-dye layers are therefore duplicated and stacked to produce dimension [6 x 500 x 32] - allowing stacking with the within-dye layer of size [6 x 5 x 32].\nThere is a secondary input of size [6 x 500 x 1] that stacks simultaneously with both the within- and across-dye layer stacks. This secondary input allows a structured or randomised element to be introduced into the GAN, both of which were trialled in this work.\nAfter each convolutional layer a ReLu activation function was applied, followed by batch normalisation. The only exception to this was the final output layer, which utilised a leaky ReLu activation and no batch normalisation. Also, in the final convolutional layers 2D spatial dropout was applied with a rate of 0.25.\nThe ANN shown in Figure 2 has 1,433,361 parameters."}, {"title": "2.5- The discriminator architecture", "content": "The discriminator architecture from the pix2pix implementation was used, with modified filter sizes applicable to the [6 x 5000] input. The structure of the discriminator is shown in Figure 3.\nFor the ANN in Figure 3:\nAll but the final layer has a leaky ReLu activation function. The final output has a sigmoid activation.\nAfter each convolutional layer batch normalisation was applied.\nThe final output is a [1 x 20] array, which represents 20 segments of the learned profile features. This type of multi-output in a discriminator is based on the PatchGAN architecture (proposed by (Wand, 2016)).\nThe ANN shown in Figure 3 has 3,302,081 parameters."}, {"title": "2.6 \u2013 Training the GAN", "content": "In general, a GAN works by using a pair of competing ANNs: a generator and a discriminator. The generator has the function of producing an output that adheres to a specific goal, usually to produce highly realistic images. The discriminator has the function of distinguishing between the real and fake images (i.e., comparing a known, true image to the generated image). The discriminator performance is judged by how well it distinguishes between the real and generated images. The generator performance is judged by how well it can produce images that fool the discriminator. The input of a classic generator is an array of random numbers, which it learns to translate into an image. In the pix2pix GAN the performance of the generator is judged on two criteria, the ability to fool the discriminator, but also the ability for the output to match features of the target."}, {"title": "2.7 \u2013 Simulating biologically informed random profiles", "content": "After the GAN training was complete the generator ANN could be used to create realistic DNA profiles from purely simulated data. The R package simDNAmixtures (Kruijver et al., 2023) was used to simulate DNA profile information. It was set up to simulate profiles by:\ndrawing alleles from the Australia Caucasian population (Taylor, Bright, McGovern, Neville, & Grover, 2017),\ndrawing template and degradation values from within user-defined bounds,\napplying back, forward, half-back and double back stutters to allelic peaks based on their expected ratios,\napplying peak height stochastic variability to all peaks based on their fluorescence type, and\napplying inter-locus imbalance.\nExpected stutter ratios and peak and locus balances were based on in-house validation of the GlobalFiler\u2122 profiling kit at the lead author's laboratory.\nOnce simulated the profiles were supplemented in three ways:\nAmelogenin peaks were added by randomly choosing a sex for each contributor and using their simulated DNA amounts to generate X and potentially Y peaks.\nPeaks were added for each internal lane standard (ILS) peak for the Thermo Fischer Scientific GeneScan\u2122 600 LIZ\u2122\u2122 dye Size Standard v2.0.\nA column was added that had a scan point for each peak, which was carried out by multiplying the base pairs by 11.2 and adding 3500. These values were obtained by graphing ILS base pairs vs scans for 20 samples.\nGiven this construction the simulated profile data was then converted to a smoothed idealised profile by setting a baseline of zero and adding modelling peaks with a normal distribution with a mean equal to the scan point of the peak centres and a standard deviation of 4. The fluorescence for each peak was scaled by the corresponding simulated peak height. This smooth electropherogram was then passed through the generator ANN, which acted as a 'realism filter'. At this point a realistic electropherogram was available that had been completed simulated."}, {"title": "3.0 - Results", "content": "Using either a structured or secondary input yielded approximately equivalent results. We do not show the results here, however supplying the structured input lead to the convergence of the GAN in approximately half the epochs was required by the randomised secondary input. However, once trained, the generator with the randomised input has other advantages (which we discuss later) that means that it was ultimately chosen to proceed with. All results shown below are for the generator that uses a random input."}, {"title": "3.1 \u2013 Results of training GAN", "content": "Figure 5 shows the average loss, across the entire dataset, of the GAN training across 200 epochs. The initial very high performance of the discriminator is due to the pre-training (during which the generator output is static) and is the state of the ANN prior to the GAN training. There is an initial decrease followed by an increase in loss for generator. These changes are due to the changing performance of the discriminator rather than a drift of the generated profile away from the real profile. The lower panel of Figure 5 shows the performance of the discriminator at each of the 10 epochs on the real and generated profiles. The results in Figure 5 show the discriminator performance (and the GAN in general) had converged by approximately 140 epochs in this dataset of 1078 profiles. After this point the loss for both discriminator and generator plateaued and the ability for the discriminator to identify real and simulated profiles remained approximately constant."}, {"title": "4.0 - Discussion", "content": ""}, {"title": "4.1 \u2013 performance of the GAN", "content": "The use of a GAN to create an ANN that can apply a \u2018realism filter' to a fake DNA profile data was ultimately successful. Earlier trials to train the same GAN system on 600 profiles consistently failed and given that the current system using 1078 profiles succeeded with no change other than the training dataset it can be surmised that the performance of the system is sensitive to the amount of training data. Even in the training dataset of 1078 there are several indications that further data is needed. One example is shown in Figure 8, where between 25% and 50% of pull-up features in the original profile were recreated in the generated profile.\nAnother indication that further training data may be required is that often, original profiles which exhibited baseline drift had generated profiles that also exhibited similar baseline drift. As there is no indication of baseline drift in the smoothed profiles, this suggests that the generator may be recognising the pattern of legitimate peaks in the input profiles as a means of determining if drift is added. This is a classic instance of overfitting to the dataset.\nA third indication is that, while profile can be generated using simDNAmixtures and will have different patterns of baseline drift (as well as different patterns of baseline noise), if the same input profile is regenerated multiple times with different random number arrays for the secondary input, the pattern of baseline drift is always the same. This may be a result of the finding of the pix2pix authors that random inputs into the pix2pix GAN are effectively ignored, however the baseline noise component of profiles does change with the different random secondary inputs, and so the stable baseline drift may also simply be a product of too few training examples. Because the baseline noise component of the generated profiles varies with the random array of secondary input, it allows multiple attempts to be made at generating a profile with realistic baseline, using the discriminator ANN as a decision tool i.e. a set of peaks is simulated using simDNAmixtures and then the generator is used to generate 1000 versions of this profile as an electropherogram. With each generation the discriminator is used to classify it as real of fake and then the generated electropherogram with the highest discriminator output is the one chosen for any downstream use.\nThere is a possibility for the biological models within simDNAmixtures and the machine learning models in the generator to work against each other. For example, the biological models have a component of peak height variability that can lead to low-level peaks being absent from the profile (a phenomenon known as \u2018drop-out'). In Figure 6 an instance was shown where a stutter peak that had dropped out in the real profile was added back into the generated profile as the generator had learnt that stutter peaks typically precede larger parent peaks. Again, this may be a problem that is addressed by increased training data, as eventually the discriminator will learn that if a profile has a missing stutter peak, then it must be real. This will then lead to the generator learning to sporadically dropout stutter peaks. This will mean that while the biological model drops out peaks sporadically, the machine learning models will sporadically add them back in and drop out others."}, {"title": "4.2 \u2013 further modification of the pix2pix GAN", "content": "In the pix2pix network the generator loss function is a combination of loss coming from the ability of the discriminator, and the closeness of the generator profile to the real image. In their original publication the authors of the pix2pix network (Isola et al., 2018) weighted the component relating to the alignment with the real image as 100 times higher than the component relating to the ability of the discriminator ANN. In our application to electrophoretic data we found that the weighting between the two components had to be equal. When the weighting was too far in favour or replicating the real profiles then the generator would generate profiles that had no randomised features (such as baseline noise and baseline drift) and would only learn the structured patterns in the data. Such a system could be taken further so that the discriminator is removed altogether and just the generator is trained in isolation (i.e. not in a GAN architecture). This may be a useful tool to learn the basic structural features of DNA profiles without the complication of random noise elements. It could also be used to generate foundational data that are used by other algorithms to generate the random or noise components, for example it may be that a time series could model baseline noise, or it may be that a GAN with a different structure to the pix2pix GAN is best suited for random noise generation elements (such the waveGAN (Donahue, McAuley, & Puckette, 2019), which has been used to generate different types of signal noise)."}, {"title": "4.3 - The potential for other generative models", "content": "While our work focussed on the pix2pix GAN model architecture there are other models that could be trialled to generate EPG data. Many of these systems have the ability to generate realistic looking data but possess a reduced ability for generating data whose outcome can be carefully controlled in the same way that the pix2pix GAN. One potential alternative model that could be used is the CycleGAN (Zhu, Park, Isola, & Efros, 2017). CycleGAN does not require paired images, and instead uses the \u2018style' of groups of images within the two domains (in the context of our work this would be the idealised domain and the realistic domain). The model works by the first generator converting images from domain one to domain two, and the discriminator distinguishing between images natively belonging to domain two and generated fakes. The ability to retain features of the original image (from domain one) then comes from a second generator, which takes the fake image that has been generated to appear as though it belongs to domain two and converts it back to a domain one image. A second discriminator then distinguishes between the image belonging to domain one that has been converted to and from domain two and images natively belonging to domain one. CycleGAN is often chosen as a style translation tool due to the fact that it does not require paired data, which can be costly to produce. CycleGAN relies on the optimisation of the structure of the neural network to preserve the original image features, rather than relying on the pairing of the dataset as in pix2pix (Lin, 2023). As such pix2pix provides a better ability to control the fine scale features of the output than CycleGAN. This is the desired behaviour of the current application, where EPGs with specific peaks at specific heights are desired as the output.\nDiffusion models represent another means of potentially generating EPG data and can produce more realistic synthetic data than GANs (Dhariwal & Nichol, 2021). Diffusion models work by adding sequentially more noise to an original image according to a schedule and training a network to identify the noise within one of the noised images. Using this network an input of random noise can then be \u2018de-noised' iteratively until a realistic image is obtained. The popularisation of diffusion models comes from the ability to condition their generation, typically using text prompts. For the application of generating EPG data the conditioning information could be provided in the form of the idealised, smoothed version of the profile with the diffusion model then producing the realistic synthesised data. Some optimisations would be required to balance the synthesis of realistic data and the retention of the conditioned features.\nThere also exist a number of GANs that have been specifically designed for generation of time series data such as TSGAN (Smith & Smith, 2020), GT-GAN (Jeon, Kim, Song, Cho, & Park, 2022), or TTS-CGAN (Li & Ngu, 2022), but again don't provide the same level of fine-scale control on the synthesised data that is provided by the pix2pix network."}, {"title": "4.4- Use cases of the current GAN", "content": "As well as the use of the generator ANN to create training material for other ANNs, the profiles could be generated for other purposes. One such purpose would be for the ongoing training and proficiency testing of analysts within forensic laboratories. It is common for laboratories to regularly construct mixtures with a known number of contributors, with known genotypes, donating known DNA amounts and use these to train and test the proficiency of their analysts at assigning the number of contributors to profiles, and interpreting potential donor genotypes. Generating these training profiles is time-consuming and costly as each round of generation requires informed volunteer consent, laboratory work and use of costly reagents. Being able to construct profile electronically that are indistinguishable from real profiles by analysts therefore has great potential resource advantage. The generated information could be inserted into instrument files with the use of tools such as sequinR (Charif & Lobry, 2007). The profiles could then be provided to analysts in a completely blinded manner (i.e. the analysts do not know which profiles are those they are being test on), which has been shown to provide a better indication of realistic performance (Mejia, Cuellar, & Salyards, 2020).\nAs with all realistic generative capability there is the flipside; with the ability to create realistic electropherograms and embed them into instrument files for training, so too is it possible to create deep-fake profiles for ill intent. Like many generative tools it may be wise to build in tags for generated profiles that identify them as generated to prevent any nefarious use."}, {"title": "5.0 - Conclusion", "content": "The purpose of this work was to be able to generate profiles in order to be able to create unlimited pre-labelled electrophoretic data for use in training a DNA profile classification ANN, such as that in (Taylor, 2022). The profiles simulated using simDNAmixtures will have information that allows labels to be provided for stutter and allele, however not pull-up. Pull- up may still require labelling either manually, or by the current profile classification ANN. This latter option is quite practical as pull-up is well classified in the ANN trained in (Taylor, 2022), and the main training needed to improve performance is for the ANN to distinguish low- level peak data from baseline noise. This will allow the ANN to be used for electropherogram classification of peaks to sub-30-rfu bounds, which appears to be the current barrier to performance based on data in (Taylor & Buckleton, 2023) (see their Figure 7).\nFurther work planned is to apply explainable AI techniques to determine what features of the electrophoretic data the discriminator is using in the generated and real profiles in order to be able to discriminate between them (Linardatos, Papastefanopoulos, & Kotsiantis, 2021). This may provide insight into ways that the generator can be improved."}]}