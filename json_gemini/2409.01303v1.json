{"title": "Topological degree as a discrete diagnostic for disentanglement, with applications to the AVAE", "authors": ["Mahefa Ratsisetraina Ravelonanosy", "Vlado Menkovski", "Jacobus W. Portegies"], "abstract": "We investigate the ability of Diffusion Variational Autoencoder (AVAE) with unit sphere S2 as latent space to capture topological and geometrical structure and disentangle latent factors in datasets. For this, we introduce a new diagnostic of disentanglement: namely the topological degree of the encoder, which is a map from the data manifold to the latent space. By using tools from homology theory, we derive and implement an algorithm that computes this degree. We use the algorithm to compute the degree of the encoder of models that result from the training procedure. Our experimental results show that the AVAE achieves relatively small LSBD scores, and that regardless of the degree after initialization, the degree of the encoder after training becomes -1 or +1, which implies that the resulting encoder is at least homotopic to a homeomorphism.", "sections": [{"title": "Introduction", "content": "The Variational Autoencoder (VAE) [26,33] and its extensions such as [6,11,32] provide a tool to both embed data into a lower-dimensional latent space via an encoder network and to generate new samples by first sampling in the latent space and by mapping it to the original data-space via a decoder network. The dimension of the latent space is often chosen to be less than the dimension of the dataset. This is partly motivated by the manifold hypothesis [16] which states that most high-dimensional data is concentrated near a low-dimensional manifold. The need for discovering low-dimensional representations of a given dataset arises in applications where one wants to make machine learning \"easy\" for downstream tasks. In other words, the learned latent space, which is the data representation, is intended to be used to ease the training process of machine learning algorithms; hence it should concisely explain the variability in the dataset.\nA desired quality for such a data representation is often that it captures or \"disentangles\" the explanatory factors of the dataset [2]. In an example, this would mean that for a dataset of pictures of objects rotated over different angles and taken under different lighting conditions, that the rotation angle and the lighting condition can be read off or easily computed from independent parts of latent space. It is difficult to generalize from such examples to give a general definition of disentanglement of latent factors.\nAlthough there is still no agreed formal definition for disentanglement, mathematical definitions do exist. Higgins et al. [20] introduced two definitions based on group theory: Symmetry Based Disentanglement (SBD) and Linear Symmetry Based Disentanglement (LSBD). Later, Tonnaer et al. [39] converted these definitions for exact disentanglement into a measure to indicate to which extent a representation is disentangled.\nBesides formal definitions of disentanglement, one can also formulate mathematical properties that at least reflect aspects of capturing or disentangling latent factors. One could for instance require that nearby points in the dataspace should correspond to nearby points in the latent space representation. This could lead to a requirement that the encoder should be a homeomorphism [16,17], so that it maps any continuous path in the dataspace into a continuous path in the latent space, and this makes the user aware of the meaning of each directions in the learned latent representation [10]. In order to achieve a homeomorphic encoder, one"}, {"title": "Related works", "content": "The VAE [26,33] and its extensions are among the most used models when it comes to learning disen- tangled representations [6,9,25]. Some VAE extensions propose the use of more complex prior distribution other than the Gaussian in order to better match the distribution of the latent code [22,27,38,35]. Some"}, {"title": "Topological degree as a diagnostic for disentanglement", "content": "In this section we introduce topological degree as a discrete diagnostic for disentanglement. It can be seen as a weakening of a check for homeomorphism. Indeed, in practice to check whether a continuous map is a homeomorphism or not. But at least it is known that homeomorphisms have topological degree \u00b11, and Hopf's Theorem [31, Page 51] implies that a smooth map f : S2 \u2192 S2 has topological degree \u00b11 if and only if f is homotopic to a homoemorphism. Hence, having an encoder of degree \u00b11 indicates that the encoder is at least homotopic to a homeomorphism; and having an encoder with degree other than +1 and \u22121 indicates in particular that the encoder is not a homeomorphism, thus it does not preserve the topology of the dataset. In this section we introduce the degree of the encoder h : X \u2192 Z from a data manifold X to latent space Z."}, {"title": "Topological degree", "content": "In words, the topological degree of the encoder restricted to the data manifold, which is a continuous map h: X \u2192 Z is an integer that represents the number of times that h wraps the data manifold X around the latent space Z (cf. [19, Page 134] and [31, Page 27]). The topological degree can be positive of negative integer, depending on the orientation of h(X) and Z."}, {"title": "Computing the topological degree", "content": "Although general methods exist for the computation of the degree and other properties of homology groups [24], we developed and implemented a basic algorithm targeted to the case at hand of computing the degree of a map between spheres. Our algorithm relies on the following steps for a given function f : S2 \u2192 S2.\nStep 1 We fix two suitable triangulations T(n) and T(k = 3) on the sphere in the domain and the sphere in the codomain of f respectively. The parameter n is a measure of how fine the triangulation is, and needs to be chosen depending on f.\nStep 2 Given f, we construct a smooth function g : S2 \u2192 S2 such that ||g - f||\u221e < \u03c0. It follows that f and g are homotopic, and therefore have the same degree.\nStep 3 We construct a chain map \u011d, which when interpreted as a chain map from simplicial chains to singular chains, is chain homotopic to g#, the chain map induced by the continuous map g. The degree of \u011d is then equal to the degree of g and f.\nStep 4 We finally numerically compute the degree of \u011d, and it corresponds to the degree of f.\nThe steps are worked out in Appendix A."}, {"title": "Experiments", "content": "We evaluate the ability of AVAE to capture topological structure in dataset when the known generating factors have the topological structure of a two-dimensional sphere. Natural datasets with such latent structure are given by pictures of axisymmetric objects rotated over various angles, or pictures of an axisymmetric picture on the sphere taken from different angles. In the latter case, such pictures can be viewed as real-valued functions defined on the unit sphere S2 that are axisymmetric about some axis, which in turn can be expressed as linear combination of real spherical harmonics of degree L [4, Page 88] [3] for a fixed L > 0. This is the basis of our diagnostic dataset."}, {"title": "Data", "content": "For an fixed odd integer L\u2265 3, we start with the real spherical hamonic Y of degree L and order 0, which gives an axisymmetric colouring of S\u00b2. To generate the dataset, we then sample uniformly 4266 group elements in SO(3), let them act on Y and express the resuling functions in their coordinates in the basis <Y\u2081,\u2026\u2026\u2026,Y\u0141 > of real spherical harmonics of degree L [3,18]. The resulting dataset (xi); is then a subset of R2L+1."}, {"title": "The models", "content": "We the train the AVAE [32], and compare the result to the S-VAE [11]. Since the ground truth generating factor of our dataset is homeomorphic to S2, the 2-dimensional sphere is used as latent space in both models. We asymptotically approximate the KL-term in the loss of the AVAE up to and including the term with t\u00b2, following to [30]."}, {"title": "Training", "content": "We train the AVAE and S-VAE with a semisupervised LSBD-loss as in [39], except that we do not alternate between supervised and unsupervised training but rather in every training step consider a batch of data with and a batch of data without labels. Just like in [39], instead of optimizing the infimum in the LSBD score over all representations, we use a trivial upper bound which involves one (in our case the identity) representation. The ratio between data with and data without labels is 0.5. We also add a semisupervised LSBD loss for the decoder. For L = 5,7,9 we train with 600 epochs, and for L = 11 we train with 1200 epochs."}, {"title": "LSBD score", "content": "In addition to the topological degree, we evaluate the LSBD score outlined in [39] with the group SO(3). The dataset is generated via the natural action of SO(3) on spherical harmonics. That action should correspond to a linear action of SO(3) on R\u00b3, which preserves the unit sphere S2. The representation of the data given by the models is then good if the corresponding LSBD score is small."}, {"title": "Further metrics", "content": "Furthermore, we compute the distance distortion metric as given in [32], and the log- likelihood estimate as in [5]; for further details see also [32]."}, {"title": "Experimental results", "content": "We train the AVAE with spherical harmonics dataset of degree L = 5, 7, 9, 11. For each of these values of L, each model is trained 5 times. The model weights are initiated randomly according to PyTorch, but at the end of each training, the encoder of the resulting models reach degree \u00b11. The numerical results of the experiments are presented in Table 1, where the absolute value of the degree is reported."}, {"title": "Evolution of the degree during the training", "content": "In order to get insight into the evolution of the degree during the training, we conducted more experiments for spherical harmonics of degree L = 7, 5, 3 with AVAE. For each L, we performed 5 experiments in which we recorded the degree before and after training. For the five experiments with L = 7, three of the initial models have encoder of degree 0, one with degree 2 and one with degree -1. In the five experiments where L = 5, the degree of the initial models turned out to be 0. For L = 3, four of the initial models have encoder of degree 0, and one has encoder of degree 2. Whereas the absolute value of the degree after all training was 1. In particular, even though we share the opinion that topological obstructions might hamper training [15,16], for the AVAE the obstruction to the degree can be overcome."}, {"title": "Discussion", "content": "We derive a second order expansion of the heat kernel on the unit sphere S2 by using the theoretical result of [30], and use it as approximation in the AVAE loss function. The effect of such higher order approximation in the performance of AVAE is not studied yet. In fact, to guarantee robustness of our algorithm, we limit the possible values of the heat kernel time t by using a sigmoid activation function. Sometimes it requires careful tuning of the parameters to not have t be limited by one of its boundaries.\nOur algorithm for degree computation could be generalized to higher dimensional sphere Sd with d > 2, but due to the curse of dimensionality, practical computation is most likely only feasible in very low dimensions: for a d-dimensional manifold and a discretization length 8, the number of faces needed in the triangulation scales as d-d.\nOur semi-supervised approach is inspired by the result of [8] which states that LSBD cannot be inferred without any supervision, and this approach was also used in [39]. Note that the amount of semisupervision is relatively high in our experiments. For lower degree spherical harmonics (L = 1,3,5), the amount of semisupervision can be reduced drastically, although we have not yet performed a systematic study."}, {"title": "Conclusion", "content": "We evaluate the AVAE with spherical latent space using a diagnostic dataset that arises from the irreducible action of SO(3) on spherical harmonics. In particular, we evaluate to what extent it can capture the topological properties or disentangle the generating factors of the underlying dataset, as measured by the LSBD score, and as expressed by a new discrete diagnostic for disentanglement: the degree of the encoder. We also use the encoder degree as a means to gain more insight in the training behavior.\nFirst, we obtain relatively small LSBD scores, which expresses that the AVAE indeed can capture or disentangle the latent rotational factor relatively well. In comparison with the S-VAE, we find that the S- VAE typically obtains better log-likelihood scores, while the reconstruction error and LSBD score are a bit better for the AVAE.\nSecondly, we implemented an algorithm for computing the topological degree of the encoder and find that even though the encoder is typically initialized with degree 0, this degree can change and after training the encoder indeed has degree of \u00b11, which means by Hopf's Theorem that the encoder is at least homotopic to a homeomorphism and that the learned spherical representation preserves the topological structure of the dataset at least up to a homotopy. In particular, we find that the sphere in latent space is completely covered by the image of the data manifold."}, {"title": "Numerical computation of degree", "content": "In this section, we describe how we triangulate the sphere S2. More precisely, for every n \u2208 N, we endow the sphere S2 with a \u0394-complex structure [19, Page 103].\nThe intuition behind the construction is simple: we make a regular grid in spherical coordinates, except we identify all points with $ = 0 (the North Pole) and all points with \u00a2 = \u03c0 (the South Pole). We divide all"}, {"title": "Step 1: Triangulate spheres", "content": "In this section, we describe how we triangulate the sphere S2. More precisely, for every n \u2208 N, we endow the sphere S2 with a \u0394-complex structure [19, Page 103].\nThe intuition behind the construction is simple: we make a regular grid in spherical coordinates, except we identify all points with $ = 0 (the North Pole) and all points with \u00a2 = \u03c0 (the South Pole). We divide all"}, {"title": "We define the map of spherical coordinates sph : R2 \u2192 S2 by", "content": "\u03a6sph (0, $) := (sin & cos 0, sin o sin \u03b8, cos \u03c6).\nMoreover, define the scaling map Isc : R2 \u2192 R2 by"}, {"title": "Final definition", "content": "Construction of edges as a family of maps Next, we construct a family of maps from the standard 1-simplex D\u00b9 of Equation (1) to S\u00b2. Fix n \u2265 3 and let us define the following index set.\nNow, let T = (T1, T2) \u2208 En. Then 7 indicates an edge \u2206 : D\u00b9 \u2192 S2 in the following manner. Denote by L: R2 \u2192 R2 the (unique) linear map such that L-(eo) = 71 and L-(e1) = 72. Then \u2206\u02dc : D\u00b9 \u2192 S\u00b2 is defined as\n\u0394' (x) := (\u03a6sph Psc L\u2081)(x)."}, {"title": "\u0394-complex T(n) on S2", "content": "Here we construct a \u0394-complex structure cf. [19, Page 103] on the unit sphere. We start by constructing a family of smooth maps from the standard 2-simplex D to S2. We are going to use the notations from Subsection A.1 and Subsection A.1. We first construct an index set by mean of the sets in Equation (2) and in Equation (3). More precisely, fix n \u2265 3 and consider the following index set"}, {"title": "Note that the maps \u0394' for \u03c4\u2208 Ft have opposite orientation from the maps \u0394' for \u03c4\u2208 F\u00f1.", "content": "We then have a family of functions\nsatisfying the conditions for a \u0394-complex structure [19, (i), (ii), (iii), Page 103].\nFor a given n, we denote by T(n) the \u0394-complex structure defined by this family of functions.\nRemark 1. (Important) As mentioned earlier, the maps A's for \u315c\u2208 F have opposite orientation from the maps A's for T\u2208 F This implies that the homology class of\ndoes generate the homology group of S\u00b2 since S2 is an orientable surface.\nInstead, a generator of the homology group of S\u00b2 that we are going to use is the homology class of\nwith"}, {"title": "Geometric interpretation, initial setting and preliminary result", "content": "Geometrically speaking, we just give a triangulation of the sphere: the set of vertices is given by {\u2206\u02dc (D\u00ba) : \u03c4\u2208 Vn}, the set of edges is given by {\u2206\u0384(D1): \u03c4\u2208 En}, and the set of faces is given by {\u2206\u0f0b(D2) : \u03c4\u2208 Fn}.\nThroughout the rest of this work, we fix k = 3 and we use the \u0394-complex structure T (3) on the codomain of the function f."}, {"title": "Step 2: Construction of a map g such that ||g - f||\u221e < \u03c0", "content": "Now, we are going to build a continuous function g : S2 \u2192 S2 that is homotopic to f.\nDefinition of g on the set of vertices Let us define the function g on the set of vertices Ur\u2208\u03bd\u03b7 \u2206\u00ba (D\u00ba).\nFor a vertex x \u2208 Ur\u2208vn \u2206\u00ba (D\u00ba), we choose an element y \u2208 Ur\u2208v3 \u2206\u00ba (D\u00ba) that is closest to f(x) in spherical coordinates, and we define\ng(x) := y.\nNote that this comes down to independently rounding the spherical coordinates to values that are in the grid."}, {"title": "Designated paths between two points on the sphere", "content": "Before we describe how g is defined on edges, let us first indicate some designated paths on the sphere. For p, q \u2208 S\u00b2, we define a designated path ep,q : D1 \u2192 S2 from p to q as follows. We denote by (0p, $p) and (0q, q) the spherical coordinates of p and q respectively. In spherical coordinates, the path ep,q has constant speed and consists of at most one vertical and at most one horizontal segment. The e-coordinate of the vertical segment is"}, {"title": "Definition of g on the 1-skeleton Ur\u025b\u025bn \u2206\u0f0b(D1) of T(n)", "content": "We then define g on the edge \u2206' (D1), with T\u2208 En, by\ng(x) := eg(T1),g(T2) \u25cb (\u25b3)\u00af\u00b9(x)\nfor x \u2208 \u0394' (D1).\nNote that this gives a continuous function g defined on the 1-skeleton Ureen \u0394' (D\u00b9) of T(n).\nLet us end this subsection by proving some properties of g on Ur\u03b5\u03b5 \u0394' (D). We are going to use the following definition."}, {"title": "Lemma 1.", "content": "Define \u0454 := \u221a3sin(\u03c0/8) > 0.66. Let Lf be a Lipschitz constant of f, and let N such that for all n> N we have\nfor all T\u2208 Fn.\nThen for any n > N and for any \u315c \u2208 Fn, the image by g of the boundary of \u2206 (D2) is included in one timezone of T(3) cf. Definition 1."}, {"title": "Definition of g on S2", "content": "Consider n > N where N is specified in Lemma 1. Let us define a continuous function g : S2 \u2192 S2 which is homotopic to f and such that the restriction of g on the 1-skeleton Uree A (D1) is defined in Subsection A.2.\nLet x \u2208 S\u00b9 such that x \u2208 Int (\u0394"}, {"title": "Proof that g and f are homotopic", "content": "We have the following property of the constructed continuous function g.\nLemma 2. Lete, N and Lf be as specified in Lemma 1. Then, for all n \u2265 N, we have\nd(f(x), g(x)) <\u03c0\nfor all x \u2208 S\u00b2, where d denotes the geodesic distance on S\u00b2.\nProof. This follows by construction of g.\nThe fact that f and gare homotopic now follows from the following lemma.\nLemma 3. Let f,g : S2 \u2192 S\u00b2 be smooth maps such that\nwhere d is the geodesic distance on S2. Then\ndeg(f) = deg(g).\nProof. For all x, there exists an unique geodesic joining f(x) and g(x) by assumption. The result follows by using [14, 12.1.2. Theorem] and Hopf's theorem cf. [31, Page 51]."}, {"title": "Step 3: Construction of a chain map \u011d", "content": "In this subsection construct a chain map\nghat: C.(T(n)) \u2192 C.(T(3)),\nwhere\nC.(T(n))\ndenotes the simplicial chain complex. Intuitively, \u011d just corresponds exactly to gon vertices and edges. The details are below.\nWe first define \u011d on vertices. More precisely, we define\nghat: Co(T(n)) \u2192 Co(T(3))"}, {"title": "B Estimating a Lipschitz constant of a neural network", "content": "In this section, we give an estimation of a Lischitz constant of a particular function f : S2 \u2192 S2. Our function f will be the composition of an isometry, a neural network, and a projection on S\u00b2. More precisely, our function f is the composition of the following functions.\nProposition 1. Let ||Wi|| (i = 1, ..., h + 1) be the operator norms of the linear layers of the neural network part of f, i.e. ||Wi|| is the maximum eigenvalue of the square matrix #WiWi. Assume that the range of the neural network part of f does not contain a neighborhood of radius p > 0 of the origin. Then a Lipschitz constant of f is given by\n\nProof. See [37]\nAll we need to do is compute the positive number p specified in Proposition 1 i.e. we need to compute a positive lower bound for min\u2208s2 ||E(x)|| where E denotes the neural network part of f. Note that there is no warranty that such a positive lower bound exists. However, with appropriate regularization, one can get a particular function f such that the following computation works in practice.\nProposition 2. Fix n > 0. Then for all x \u2208 S\u00b2, we have"}]}