{"title": "RAG-Enhanced Collaborative LLM Agents for Drug Discovery", "authors": ["Namkyeong Lee", "Edward De Brouwer", "Ehsan Hajiramezanali", "Chanyoung Park", "Gabriele Scalia"], "abstract": "Recent advances in large language models (LLMs) have shown great potential to accelerate drug discovery. However, the specialized nature of biochemical data often necessitates costly domain-specific fine-tuning, posing critical challenges. First, it hinders the application of more flexible general-purpose LLMS in cutting-edge drug discovery tasks. More importantly, it impedes the rapid integration of the vast amounts of scientific data continuously generated through experiments and research. To investigate these challenges, we propose CLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored to drug discovery tasks. Through the collaboration of multiple LLM agents, CLADD dynamically retrieves information from biomedical knowledge bases, contextualizes query molecules, and integrates relevant evidence to generate responses all without the need for domain-specific fine-tuning. Crucially, we tackle key obstacles in applying RAG workflows to biochemical data, including data heterogeneity, ambiguity, and multi-source integration. We demonstrate the flexibility and effectiveness of this framework across a variety of drug discovery tasks, showing that it outperforms general-purpose and domain-specific LLMs as well as traditional deep learning approaches.", "sections": [{"title": "1. Introduction", "content": "Large language models (LLM) have revolutionized the landscape of natural language processing, emerging as general-purpose foundation models with remarkable abilities across multiple domains (Achiam et al., 2023; Touvron et al., 2023). In particular, their application in biomolecular studies has recently gained significant interest, motivated by the potential to profoundly accelerate scientific innovation and drug discovery applications (Zhang et al., 2024; Pei et al., 2024; Chaves et al., 2024). LLMs provide novel ways to understand and reason about molecular data, building on the wealth of available scientific literature. Additionally, their reasoning and zero-shot abilities help overcome the limitations of task-specific deep learning models, streamlining data needs and improving human-AI collaboration (Fang et al., 2023; Yu et al., 2024).\nHowever, given the inherent complexity and specialized nature of the field, recent works emphasize the importance of domain-specific fine-tuning to boost tasks such as molecular captioning, property prediction, or binding affinity prediction (Fang et al., 2023; Chaves et al., 2024; Yu et al., 2024; Edwards et al., 2024). Consequently, rather than employing readily available general-purpose LLMs, most efforts in drug discovery have focused on fine-tuning LLMs using biochemical annotations or instruction-tuning datasets.\nWhile promising, solely relying on these approaches poses significant challenges that can limit applications. On one hand, the rapid emergence of new LLM architectures and techniques (Minaee et al., 2024; Zhao et al., 2023b) complicates maintaining domain-specific models obtained through expensive fine-tuning. More importantly, drug discovery applications often require promptly incorporating new insights as they become available, for example, as a result of new experiments or through the scientific literature-a process exacerbated by the automation of experimental workflows (Tom et al., 2024). In addition to being impractical, regular rounds of fine-tuning to keep LLMs up-to-date with the latest scientific advances also introduce challenges such as catastrophic forgetting (Luo et al., 2023).\nFrom this perspective, retrieval-augmented generation (RAG) methods offer a promising solution that enables dynamic adaptation of the model's knowledge without the need for expensive fine-tuning (Gao et al., 2023; Fan et al., 2024). However, applying this paradigm in the drug discovery domain presents important obstacles. First, retrieving relevant knowledge is difficult due to the limited domain expertise of general-purpose LLMs, combined with the vastness of the chemical space (Bohacek et al., 1996) that renders exact retrieval suboptimal. Second, biochemical data is extremely heterogeneous, spanning diverse modalities such as molecules, proteins, diseases, and complex relationships between them (Wang et al., 2023). Such data can also exist across multiple sources, introducing challenges in factual integration (Harris, 2023). Finally, the available information is not necessarily relevant to the query, as it may be too general, ambiguous, or partial (Vamathevan et al., 2019).\nIn this study, we tackle these challenges by introducing a Collaborative framework of LLM Agents for Drug Discovery (CLADD). We assume a general setting where external knowledge is available as expert annotations associated with molecules or as knowledge graphs that flexibly represent diverse biochemical entities and their relationships. CLADD is powered by general-purpose LLMs, while also integrating domain-specific LMs, when necessary, to improve molecular understanding. Notably, external knowledge can be updated dynamically without LLM fine-tuning.\nThe multi-agent collaborative framework enables each agent to specialize in a specific data source and/or role based on their team, offering a modular solution that can improve overall information processing (Chan et al., 2024). In particular, CLADD includes a Planning Team to determine relevant data sources, a Knowledge Graph Team to retrieve external heterogeneous information in the knowledge graph and summarize it, also through a novel anchoring approach to retrieve related information when the query molecule is not present in the knowledge base, and a Molecule Understanding Team, which analyzes the query molecule based on its structure along with summaries of external data and tools. The flexibility of the framework enables CLADD to address a wide range of tasks for drug discovery, including zero-shot settings, while also improving interpretability through the transparent interaction of its agents.\nOverall, we highlight the following contributions:\n\u2022 We present CLADD, a multi-agent framework for RAG-based question-answering in drug discovery applications. The framework leverages generalist LLMs and dynamically integrates external biochemical data from multiple sources without requiring fine-tuning.\n\u2022 We demonstrate the flexibility of the framework by tackling diverse applications, including property-specific molecular captioning, drug-target prediction, and molecular toxicity prediction.\n\u2022 We provide comprehensive experimental results showcasing the effectiveness of CLADD compared to general-purpose and domain-specific LLMs, as well as standard deep learning approaches. A further appeal of CLADD is its flexibility and explainability, improving the interaction between scientists and AI."}, {"title": "2. Related Work", "content": "LLMs for Molecules. Leveraging the extensive body of literature and string-based molecular representations such as SMILES, language models (LMs) have been successfully applied to molecular sciences. Inspired by the masked language modeling approach used in BERT training (Devlin et al., 2018), KV-PLM (Zeng et al., 2022) introduces a method to train LMs by reconstructing masked SMILES and textual data. Similarly, MolT5 (Edwards et al., 2022) adopts the \"replace corrupted spans\" objective (Raffel et al., 2020) for pre-training on both SMILES strings and textual data, followed by fine-tuning for downstream tasks such as molecule captioning and generation. Building on this foundation, Pei et al. (2023) and Christofidellis et al. (2023) extend MolT5 with additional pre-training tasks, including protein FASTA reconstruction and chemical reaction prediction. Furthermore, GIMLET (Zhao et al., 2023a), Mol-Instructions (Fang et al., 2023), and MolecularGPT (Liu et al., 2024b) adopt instruction tuning (Zhang et al., 2023) to improve generalization across a wide range of molecular tasks. While these approaches demonstrate enhanced versatility, they still rely on expensive fine-tuning processes to enable molecule-specific tasks or to incorporate new data.\nLLM Agents for Science. An LLM agent is a system that leverages LLMs to interact with users or other systems, perform tasks, and make decisions autonomously (Wang et al., 2024a). Recently, LLM agents have attracted significant interest in scientific applications and biomedical discovery (Gao et al., 2024), with applications including literature search (L\u00e1la et al., 2023), experiment design (Roohani et al., 2024), and hypothesis generation (Wang et al., 2024b), among others. In particular, agents focusing on drug discovery applications have emerged. Systems like ChemCrow (Bran et al., 2023), CACTUS (McNaughton et al., 2024), and Coscientist (Boiko et al., 2023) focus on automating cheminformatics tasks and experiments, streamlining computational and experimental pipelines. Other works leverage agent-based orchestration of tools and data to accelerate specific aspects of scientific workflows, such as search (ODonoghue et al., 2023) or design (Ghafarollahi & Buehler, 2024). In contrast to existing works, we investigate an agent-based framework that can effectively incorporate external knowledge to improve general molecular QA. This could be used either independently or as part of a larger system for automated drug discovery (Tom et al., 2024).\nMulti-Agent Collaborations for Drug Discovery. Only a limited number of studies have explored multi-agent frameworks in the context of drug discovery. DrugAgent (Inoue et al., 2024) introduces a multi-agent framework integrating multiple external data sources but is limited to predicting drug-target interaction scores. Another study with the same name employs an agentic framework for automating machine learning programming for drug discovery tasks (Liu et al., 2024a). In contrast, our work seeks to tackle a diverse array of drug discovery tasks, enabling applicability across a wide variety of use cases."}, {"title": "3. Methodology", "content": "Here, we introduce CLADD, a multi-agent framework for general molecular question-answering that supports multiple drug discovery tasks. Each agent is implemented by an off-the-shelf LLM prompted to elicit a particular behavior. Our framework is composed of three teams, each composed of several agents: the Planning Team, which identifies the most appropriate data sources and overall strategy given the task and the query molecule (Section 3.2.1); the Knowledge Graph (KG) Team, which retrieves relevant contextual information about the molecule from available KG databases (Section 3.2.2); and the Molecular Understanding (MU) Team, which retrieves and integrates information from molecular annotation databases and external tools for molecule description (Section 3.2.3); Finally, the Prediction Agent integrates the findings from the MU and KG teams to generate the final answer. In the following sub-sections, we describe each team in detail. The overall framework is depicted in Figure 1."}, {"title": "3.1. Problem Setup", "content": "Given a query molecule $g_q$ and a textual prompt describing a task of interest $I$, we consider the general problem of generating a relevant response $A_{g_q}$. For instance, given $g_q$ = 'C1=CC(=C(C=C1CCN)O)0' and $I$ = 'Predict liver toxicity', our model should be able to generate an answer stating that $A_{g_q}$ = 'this molecule does not have liver toxicity concerns'. Such a general QA setup can be adapted to tasks such as multi-class classification, captioning, and set-based predictions.\nWe assume access to two types of external databases: (1) molecular annotation databases $C$, which contain textual annotation about molecules (for example, detailing their functions and properties) and (2) knowledge graphs (KGs) connecting molecules to other biomedical entities. In particular, a KG $G$ is composed of a set of entities $E$ and a set of relations $R$ connecting them. KG can include various types of entities, such as drugs, proteins, and diseases. In this paper, we only assume that molecule (or drug) entities are present in KG, while any other types of entities can exist.\nAdditionally, we assume access to pre-trained molecular captioning models that can be used as external tools to complement the external databases. In general, any predictive model on molecules can be considered a captioning model (Edwards et al., 2022; Pei et al., 2023), given that its output can be simply represented as text."}, {"title": "3.2. CLADD", "content": "Here, we introduce CLADD, a multi-agent framework for general molecular question-answering that supports multiple drug discovery tasks. Each agent is implemented by an off-the-shelf LLM prompted to elicit a particular behavior. Our framework is composed of three teams, each composed of several agents: the Planning Team, which identifies the most appropriate data sources and overall strategy given the task and the query molecule (Section 3.2.1); the Knowledge Graph (KG) Team, which retrieves relevant contextual information about the molecule from available KG databases (Section 3.2.2); and the Molecular Understanding (MU) Team, which retrieves and integrates information from molecular annotation databases and external tools for molecule description (Section 3.2.3); Finally, the Prediction Agent integrates the findings from the MU and KG teams to generate the final answer. In the following sub-sections, we describe each team in detail. The overall framework is depicted in Figure 1."}, {"title": "3.2.1. PLANNING TEAM", "content": "The Planning Team assesses prior knowledge for a given query molecule. The team separately assesses the relevance of the molecular annotations and the knowledge graph using a MolAnn Planner agent and a KG Planner agent.\nMolecule Annotation (MolAnn) Planner. This agent first retrieves annotations for the query molecule, $c_q$, from the annotation database $C$. While these annotations can provide valuable biochemical knowledge (Yu et al., 2024), they are often sparse and may lack sufficient details due to the vastness of the chemical space (Lee et al., 2024). Given the vastness of the chemical space, it is also not uncommon for molecules to be completely absent from databases.\nTo this end, the MolAnn Planner determines whether the retrieved annotations provide enough information for subsequent analyses. Specifically, given a query molecule $g_q$ and retrieved annotations $c_q$, the agent is invoked as follows:\n$OMAP = MolAnn Planner(g_q, c_q)$.\n(1)\n$OMAP$ is a Boolean indicating whether annotations should be complemented with additional information from tools.\nKnowledge Graph (KG) Planner. In parallel to analyzing the available description for the query molecule, we analyze the relevance of the contextual information present in the KG. Unlike previous works in general QA tasks, which primarily rely on identifying exact entity matches within the KG (Baek et al., 2023), the vast chemical search space and the limited coverage of existing knowledge bases hinder such approaches.\nTo address this challenge, we propose leveraging the knowledge of drugs that are structurally similar to the query drug, building upon the well-established biochemical principle that structurally similar molecules often exhibit related biological activity (Martin et al., 2002). Specifically, we define the anchor drug $g_a$ as the entity drug that maximizes the cosine similarity between its embedding and that of the query molecule, among the set of all molecules in the KG ($g_g$):\n$g_a = argmax_{g \\in g_g} \\frac{emb(g_q) \\cdot emb(g)}{||emb(g_q)|| ||emb(g)||} ,$\n(2)\nwhere $emb$ is a graph neural network (GNN) pre-trained with 3D geometry (Liu et al., 2021) that outputs structure-aware molecular embeddings.\nThen, the KG Planner agent decides whether to use the KG based on the structural similarity between the query molecule and the retrieved anchor drug. To do so, we also provide the Tanimoto similarity\\u207f to the KG Planner, as this domain-specific metric can be leveraged by the LLM's reasoning about chemical structural similarity as follows:\n$OKGP = KG Planner(g_q, g_a, s_{q,a}),$\n(3)\nwhere $s_{q,a}$ is the Tanimoto similarity between the query and anchor molecules. $OKGP$ is a Boolean indicating whether the KG should be used for the prediction."}, {"title": "3.2.2. KNOWLEDGE GRAPH TEAM", "content": "This team aims to provide relevant contextual information about the query molecule by leveraging the KG, and it is only called if $OKGP$ = TRUE. It consists of the Drug Relation (DrugRel) Agent and the Biological Relation (BioRel) Agent, both of which generate reports on the query molecule based on different aspects of the KG. Specifically, the DrugRel Agent focuses on related drug entities within the KG, primarily leveraging its internal knowledge, whereas the BioRel Agent focuses on summarizing and assessing biological relationships between drugs present in the KG.\nRelated Drugs Retrieval. The typical approach to leveraging a KG for QA tasks involves identifying multiple entities in the query and extracting the subgraph that encompasses those entities (Baek et al., 2023; Wen et al., 2023). However, in molecular understanding for applications related to drug discovery tasks, the question often involves only a single entity, i.e., the query molecule $g_q$, making it challenging to identify information in the KG relevant to the task.\nHere, we introduce a novel approach for extracting relevant information for the query molecule $g_q$ by utilizing the retrieved anchor drug $g_a$, which exhibits high structural similarity to the query molecule. In particular, while the drug entities in the KG $G$ are mainly connected to other types of biological entities (e.g., proteins, diseases), we can infer relationships among drugs by considering the biological entities they share. For example, we can determine the relatedness of the drugs Trastuzumab and Lapatinib by observing their connectivity to the protein HER2 in the KG, as both drugs specifically target and inhibit HER2 to treat HER2-positive breast cancer (De Azambuja et al., 2014). Therefore, to identify relevant related drugs, we first compute the 2-hop paths connecting the anchor drug $g_a$ to other drugs $g_o$ in the KG $G$, i.e., $(g_a, r_{a\\rightarrow e}, e, r_{i\\rightarrow e}, g_i)$, where $r \\in R$, $e \\in E$, and i denotes the index of the other drug. Then, we select the top-k related drugs, denoted as $g_{r1}, ..., g_{rk}$, corresponding to the molecules that have the greatest number of 2-hop paths to the anchor drug. Note that while the anchor drug $g_a$ is selected based on its structural similarity to the query molecule $g_q$, these reference drugs are biologically related to $g_a$, reflecting the relationships captured within the KG.\nDrug Relation (DrugRel) Agent. The DrugRel Agent generates a report on the query molecule, contextualizing it in relation to relevant drugs present in the knowledge base for the specific task instruction. Given a query molecule $g_q$, its anchor drug $g_a$, and the set of related drugs $g_{r1}, ..., g_{rk}$, the DrugRel Agent is defined as follows:\n$ODRA = DrugRel Agent (g_q, g_a, g_{r1}, ..., g_{rk}, T, I)$,\n(4)\nwhere $T = \\{s_{q,a}, s_{q,r1}, ..., s_{q,rk}\\}$ is the set of Tanimoto similarities between the query molecule and the retrieved drugs, and $I$ is the task instruction. This allows the agent to leverage its internal knowledge about related drugs while effectively assessing the relatedness of the information to the target molecule based on the Tanimoto similarity.\nBiological Relation (BioRel) Agent. On the other hand, drugs related to the query molecule in the KG may exhibit limited structural similarity, underscoring the importance of utilizing additional relevant information, such as shared toxicity profiles or interactions with the same target, rather than relying solely on structural resemblance. Therefore, the BioRel Agent summarizes how the anchor drug and the related drugs are biologically related, integrating additional biochemical information present in the KG. Specifically, given an anchor drug $g_a$, a set of reference drugs $g_{r1}, ..., g_{rk}$, the collection of all 2-hop paths $P$ linking the anchor drug to the reference drugs, and the instruction $I$, the agent generates the report as follows:\n$OBRA = BioRel Agent(P, I, g_q, g_a, s_{q,a})$.\n(5)\nThis enables us to obtain a task-relevant summary of the subgraph connected to the anchor drug.\nImportantly, while both the DrugRel Agent and BioRel Agent aim to reason about the query molecule in relation to other relevant drugs in the KG for the specific task, they leverage distinct knowledge sources and perform different roles. Specifically, the BioRel Agent primarily leverages the connectivity between drugs and other biological entities in the KG, focusing on interpreting and summarizing this network of relationships and aligning it with the specific task at hand. In contrast, the DrugRel Agent primarily draws on its internal knowledge, triggered by the names of the related drug entities in the KG, and incorporates structural similarity between them. In Section 4, we demonstrate how these agents complement each other effectively, producing a synergistic effect when combined together."}, {"title": "3.2.3. MOLECULAR UNDERSTANDING TEAM", "content": "While the KG Team compiles the report by aggregating contextual knowledge, the Molecule Understanding (MU) Team focuses primarily on the query molecule itself. The MU Team is composed of a single Molecule Understanding (MU) Agent, which aims to write a report on the query molecule by leveraging its structural information, annotations from tools, and reports from other agents.\nMolecule Understanding (MU) Agent. The MU Agent retrieves annotations for the query molecule, denoted as $c_q$. If the Planning Team decides to use external annotation tools (i.e., $OMAP$ = TRUE), additional captions $\\tilde{c_q}$ are generated with the external captioning tools as follows:\n$\\tilde{C_q}$ = Captioning Tools($g_q$),\n(6)\nand concatenated to the annotations retrieved from the database: $C_q = c_q||\\tilde{c_q}$. External captioning tools allow the system to easily harness recent advances in LLM-driven molecular understanding (Pei et al., 2023; Yu et al., 2024), and can potentially include any specialized tool.\nThe agent then analyzes the structure of the molecule, contextualizing it with reports generated by the other agents. Using the SMILES representation, the caption of the query molecule, and the reports from the KG Team, it compiles a comprehensive molecular annotation report as follows:\n$OMUA = MU Agent(g_q, C_q, ODRA, OBRA, I)$.\n(7)"}, {"title": "3.2.4. PREDICTION AGENT", "content": "Finally, the Prediction Agent performs the user-defined task by considering the reports from the various agents, including the MU and KG teams, as follows:\n$A_{g_q}$ = Task Agent ($g_q, OMUA, ODRA, OBRA, I$).\n(8)\nBy integrating this evidence, the Prediction Agent can perform a comprehensive analysis of the query molecule. Importantly, the output of the Prediction Agent can be flexibly adjusted based on the specific task requirements. For instance, it can be a descriptive caption, a simple yes/no response for binary classification, or a more complex answer listing the top-k targets associated with the query molecule. Such behavior leverages the zero-shot capabilities of LLMs (Kojima et al., 2022) and does not require additional fine-tuning. Therefore, a key advantage of CLADD is its flexibility, which enhances scientist-AI interactions."}, {"title": "4. Experiments", "content": "We assess the effectiveness of CLADD by conducting a range of drug discovery tasks, including property-specific molecular captioning (Section 4.1), drug-target prediction (Section 4.2), and drug toxicity prediction (Section 4.3).\nImplementation Details. In all experiments, we utilize GPT-40 mini through the OpenAI API for each agent. We use PrimeKG (Chandak et al., 2023) as the KG, PubChem (Kim et al., 2021) as an annotation database, and MolT5 (Edwards et al., 2022) as an external captioning tool. Additional implementation details and agent templates can be found in Appendix E and G, respectively."}, {"title": "4.1. Property-Specific Molecular Captioning Task", "content": "Earlier studies on molecular captioning tasks have primarily focused on generating general descriptions of molecules without targeting specific areas of interest, raising concerns about their practical applicability in real-world drug discovery tasks. Indeed, the usefulness of a molecular description is often task-dependent, and scientists may be interested in detailed explanations of specific characteristics of a molecule rather than a general description (Guo et al., 2024; Edwards et al., 2024). Hence, in this paper, we introduce property-specific molecular captioning, where the model is required to generate a description for a given molecule customized to a particular area of interest."}, {"title": "4.2. Drug-Target Prediction Task", "content": "Accurately predicting a drug's protein target is essential for understanding its mechanism of action and optimizing its therapeutic efficacy while minimizing off-target effects (Santos et al., 2017; Batool et al., 2019). Here, we evaluate the models' ability to accurately identify which proteins a given molecule is most likely to activate or inhibit."}, {"title": "4.3. Drug Toxicity Prediction Task", "content": "Accurate predictions of drug toxicity are crucial to ensure patient safety and minimize the risk of adverse effects during drug development (Basile et al., 2019). Here, we evaluate the models' ability to predict the toxicity of a target molecule from its SMILES-based structural description."}, {"title": "5. Conclusion", "content": "In this work, we introduced CLADD, a multi-agent framework for molecular question-answering that dynamically retrieves and integrates external knowledge to support various drug discovery tasks. We showcased its flexibility and effectiveness across multiple tasks, outperforming both general-purpose and domain-specific LLMs as well as standard deep learning methods, without requiring expensive domain-specific fine-tuning. Our analyses highlighted the complementarity of external knowledge sources, internal LLM reasoning, and multi-agent orchestration. CLADD's chain of messages also provides insight into its decision-making process and the role of different data sources, fostering more interpretable scientist-AI interactions.\nFuture Work. Our findings revealed a strong correlation between external knowledge size and system performance, with no observed plateaus, suggesting opportunities in scaling up external data. Additionally, beyond serving as a standalone tool, CLADD could also be leveraged as a component of more complex agentic workflows, for example, combining computational and experimental systems (Tom et al., 2024), which will be the subject of future work."}]}