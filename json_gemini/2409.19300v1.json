{"title": "Sustaining model performance for covid-19 detection from dynamic audio data: Development and evaluation of a comprehensive drift-adaptive framework", "authors": ["Theofanis Ganitidis", "Maria Athanasiou", "Konstantinos Mitsis", "Konstantia Zarkogianni", "Konstantina S. Nikita"], "abstract": "Background: The COVID-19 pandemic has highlighted the need for robust and adaptable diagnostic tools capable of detecting the disease from diverse and continuously evolving data sources. Machine learning models, particularly convolutional neural networks (CNNs), have shown promise in this regard. However, the dynamic nature of real-world data can lead to model drift, where the model's performance degrades over time as the underlying data distribution changes. Addressing this challenge is crucial to maintaining the accuracy and reliability of these models in ongoing diagnostic applications.\nObjective: This study aims to develop a comprehensive framework that not only monitors model drift over time but also employs adaptation mechanisms to mitigate performance fluctuations in COVID-19 detection models trained on dynamic audio data.\nMethods: Two crowd-sourced COVID-19 audio datasets, the COVID-19 Sounds and COSWARA datasets, were used for development and evaluation purposes. Each dataset was divided into two distinct periods: development and post-development. A baseline CNN model was initially trained and evaluated using data (i.e., cough recordings) from the development period. To detect changes in data distributions and the model's performance between these periods, the maximum mean discrepancy (MMD) distance was employed. Upon detecting significant drift, a retraining procedure was triggered to update the baseline model. The study explored two model adaptation approaches: unsupervised domain adaptation (UDA) and active learning (AL), both of which were comparatively assessed.\nResults: The application of the UDA approach led to performance improvement in terms of the balanced accuracy by up to 22% and 24% for the COVID-19 Sounds and COSWARA datasets, respectively. The AL approach yielded even greater improvement, corresponding to a balanced accuracy increase of up to 30% and 60% for the two datasets, respectively.\nConclusions: The proposed framework successfully addresses the challenge of model drift in COVID-19 detection by enabling continuous adaptation to evolving data distributions. This approach ensures sustained model performance over time, contributing to the development of robust and adaptable diagnostic tools for COVID-19 and potentially other infectious diseases.", "sections": [{"title": "Introduction", "content": "The rapid spread of the novel coronavirus (SARS-CoV-2) and its associated disease, covid-19, has brought about a pressing need for accurate and timely diagnostic tools. Traditional diagnostic methods such as polymerase chain reaction (PCR) tests, while reliable, often involve invasive procedures and can be time-consuming. Consequently, there is a growing interest in developing additional diagnostic approaches that are non-invasive, affordable, scalable, and capable of delivering swift results[1].\nDeep learning models have demonstrated exceptional capabilities across various domains, including medical diagnostics [2\u20138] and epidemiological surveillance [9]. Studies [10-13] have illuminated the potential of harnessing deep learning techniques for analyzing diverse data sources, such as clinical and biological biomarkers, CT scan imagery, and clinical characteristics, to predict the severity and progression of covid-19. In recent studies, the analysis of cough sounds has shown potential as a non-invasive modality for covid-19 detection [14-16]. Leveraging the power of deep learning, these models can extract crucial information from acoustic characteristics, aiding in the early identification of infected individuals.\nHowever, in practice, the performance of deep learning models tends to decline during deployment and shows further deterioration over time. This phenomenon, commonly known as model degradation, can be attributed to various factors [17]. One contributing factor is the limited representation of the training data, which fails to capture the complexity of the problem space adequately. As a consequence, the model exhibits unexpected behavior when confronted with input samples lying outside the distribution of training examples [18,19]. Another significant factor is the dynamic nature of the system's environment, which undergoes continuous changes over time [18], posing challenges for a single model to maintain accurate predictions consistently. This factor is particularly critical in the context of covid-19, given the rapid and unpredictable changes due to several reasons, including the emergence of new viral strains.\nThe literature refers to these two factors as concept drift, which is the phenomenon where the input data and their relationship to the labels undergo changes over time.\nNumerous attempts have been made in the past decade to precisely define concept drift [17,20-23]. In this paper, the definition from [22] is adopted, which states that concept drift occurs when either the data distribution changes or the underlying relationship between the input and output changes, or both.\nResearchers have recognized the importance of addressing these challenges and have focused on learning in non-stationary environments [24] and mitigating the impact of concept drift [25\u201328]. Research studies have stressed the importance of integrating a model degradation detector within the learning framework [29] that assesses and tracks the system's performance after deployment to effectively manage the degradation in prediction accuracy. The level of degradation in the model performance serves as an indicator for detecting concept drift within the system. By incorporating these detection components, deep learning systems gain resilience against environmental changes, thereby mitigating the performance degradation of predictive models in this ever-changing setting.\nSince the presence of concept drift between training data and real post-development data impedes the performance of deep learning models on out-of-distribution samples [25], applying the model on new data may necessitate adaptation. Automatic methods have emerged to tackle these challenges; however, collecting large-scale labeled datasets for different populations, emerging virus variants or new pandemics is an arduous task. When working with limited data, it is often necessary to employ more cost-efficient deep learning methodologies, such as unsupervised domain adaptation (UDA) and active learning (AL).\nDomain adaptation is a technique utilized when training and testing data come from different distributions [30] towards addressing the limited generalization abilities of predictive models. The goal is to adapt a model trained on a source domain to perform well on a target domain. This involves minimizing the distribution gap between the domains through learning domain-invariant features [31], weighing samples based on similarities [32], or using model-based techniques like domain adversarial networks [33]. These approaches can improve model generalization in real-world scenarios with varying data distributions as they enable learning from labeled data in the development set, which refers to the past, and applying this knowledge to solve tasks on post-development unlabeled data.\nActive learning, on the other hand, is a machine learning approach where informative samples from a large unlabeled dataset are selected and labeled iteratively to train a model. The objective is to minimize the amount of labeled data needed while maximizing the model's performance [34,35]. A query strategy is selected to determine which unlabeled samples should be labeled. Various strategies exist, such as uncertainty sampling [36,37] or diversity sampling [38]. Given an initially trained model, the chosen query strategy is then applied to the unlabeled dataset, identifying the most informative samples based on the selected criterion. These selected samples are labeled either manually by domain experts or through an automated process. The newly labeled samples are incorporated into the labeled dataset, which is used for retraining the model.\nThe majority of recent studies focusing on covid-19 detection based on the use of audio recordings have primarily employed supervised learning techniques [15,16,39\u201342], whereas the exploration of methods relying on concept drift detection, model degradation detection, UDA, and AL has been limited [27,43]. Nonetheless, UDA and AL approaches appear to be highly promising and well-suited for addressing new pandemics, as they enable the development of reliable models even when confronted with the emergence of novel variants.\nIn this paper, a comprehensive framework is introduced for the diagnosis of infectious diseases, focusing on covid-19 detection from cough sounds. The framework leverages deep learning models combined with supervised and unsupervised learning methodologies to monitor and mitigate model degradation and concept drift. The development and evaluation of the proposed framework is demonstrated on covid-19 data due to their continuously evolving epidemiological and virological characteristics, arising from the complex interplay among the virus, humans, vaccines, and environments. The maximum mean discrepancy (MMD) [44] distance is firstly employed as a metric to quantify the dissimilarity between temporal data distributions. By monitoring the MMD distance between batches of post-development data and data from the initial development period, the framework detects changes in both the data and the model's performance while also providing insights into the impact of the pandemic's evolution on the trained models' diagnostic accuracy. In case concept drift is detected, a retraining process is initiated, including two adaptation methods: i) a UDA process which leverages labeled development data along with unlabeled post-development data to align their distributions and adapt the model to novel data instances and ii) an AL strategy, aiming at selecting informative data to include them with their labels in the retraining process. To the best of the authors' knowledge, this is the first work leveraging UDA and AL approaches towards mitigating the impact of evolving data dynamics on model performance in the case of covid-19 with the ultimate goal to enhance reliability in covid-19 detection and potentially across various diverse epidemiological contexts."}, {"title": "Methods", "content": "The COVID-19 Sounds dataset is a collection of respiratory sound recordings associated with covid-19 infections, which were acquired through a crowd-sourcing platform launched in April 2020. It includes demographic characteristics (i.e., age, gender) along with participant-reported information about medical history and symptoms. It also comprises audio clips of voluntary cough, breathing, and speech captured from healthy individuals and individuals with covid-19. A total of 36,364 participants contributed 75,201 samples to the project. Quality checks were performed on the audio samples to filter out incomplete or noisy recordings [16]. The data were collected in multiple languages, but for the present study the part of the dataset acquired from English-speaking participants [16] was solely considered to avoid language bias, corresponding to a total of 1461 samples.\nThe COSWARA dataset is another crowd-sourced database, recorded between April-2020 and February-2022, which consists of various kinds of sounds, such as shallow and deep breaths, shallow and heavy coughs, sustained vowel phonation (i.e. /ey/ as in made, /i/ as in beet, and /u:/ as in cool), and number counting from one to twenty (normal and fast-paced). Alongside this, information on the participants' covid-19 infection status, symptoms, co-morbidities (if any), gender, age, and broad geographical location is included. In the present study, 2746 shallow cough recordings were considered for composing the models' input space. Specific criteria were applied towards the exclusion of samples that had any of the following characteristics: missing, corrupted, or silent shallow cough recordings. This procedure resulted in 1996 samples.\nRegarding data preprocessing, the setting described in [16] was applied. The audio signals were normalized, and leading and trailing silence was removed. Mel-spectrograms were calculated using a 25 ms window size, a 10 ms window hop, and a total of 64 Mel bins, encompassing frequencies ranging from 125 Hz to 7500 Hz. To handle the varying size of the Mel-spectrograms' time axis, the 0.9 quantile across all spectrograms was calculated. Subsequently, the spectrograms were either cropped or padded with repeated sections of the spectrogram accordingly. Finally, a sliding window approach was employed to extract segments from the spectrogram. The width of the window used was 0.96 s, while the window stride length was equal to half of the window's width (0.48 s). This setting resulted in a Mel spectrogram segment of a 64 \u00d7 96 size."}, {"title": "Proposed methodological framework", "content": "The abstract architecture of the proposed framework is depicted in Figure 1. It comprises three distinct modules, combining a deep neural network with a drift detection mechanism and appropriate adaptation modules with the aim to address differences between data distributions of the development and post-development periods. These modules are explained below:\n\u2022 Baseline model: A baseline model based on Convolutional Neural Networks (CNN) processes input data instances and estimates the probability of covid-19 presence.\n\u2022 Drift detection mechanism: This module is responsible for the identification of shifts in the data, implying changes in covid-19 detection patterns. It monitors the performance of the baseline model through the detection of significant discrepancies between the development data and the post-development data. To this end, a modified version of the CUSUM (CUmulative SUM) algorithm is utilized, employing the MMD distance for measuring the distance between data distributions from the development and post-development periods. A set of hyperparameters, which are appropriately adjusted, are included in the CUSUM algorithm (i.e., drift, threshold) and the MMD distance (i.e., reference distribution, kernel).\n\u2022 Adaptation module: The adaptation module facilitates the adaptation process within the system. It enables the model to dynamically adjust and learn from post-development data, ensuring continuous improvement and robustness against evolving covid-19 characteristics. Two different approaches employing divergence-based UDA and AL are investigated for harnessing post-development, unlabeled data towards model retraining with the aim of enhancing the performance and improving the generalization abilities of the baseline model.\nThe proposed framework's operation is based on the adoption of a batch-based approach for the processing of data instances and the application of a fixed time window (with parametrized overlap between successive windows) to monitor the data stream for changes. The time window length, overlap between successive time windows, and minimum batch size along with the hyperparameters of the drift detection mechanism are appropriately validated to ensure optimal performance for each dataset.\nThe development and evaluation of the proposed framework was based on the use of cough recordings from the COVID-19 Sounds [39] and COSWARA [45] datasets. Both datasets were partitioned into development and post-development sets based on chronological order."}, {"title": "Baseline model", "content": "The baseline model of the proposed framework was built upon the widely used VGGish pretrained model [46,47] which was selected due to its remarkable performance on audio classification tasks [16,48]. The VGGish model is a deep CNN trained on a large-scale audio dataset to learn hierarchical representations of audio signals. In the framework of the present study, the VGGish model was utilized to extract discriminative features from segments of Mel spectrograms with the aim of capturing relevant acoustic patterns and distinguishing covid-19 coughs from non-covid-19 coughs.\nTo adapt the VGGish model to the specific task of the present study, a time-distributed approach was employed. To this end, the VGGish feature extractor was applied on each segment of the Mel spectrogram, resulting in a sequence of feature vectors that represented the temporal evolution of acoustic characteristics within the cough signal. In order to summarize the temporal dynamics captured by the model, the mean value for each feature across the entire sequence was calculated. Following the temporal aggregation, a dense layer with a single node based on the non-linear sigmoid activation function was employed to process the aggregated feature vectors and calculate the final output of the model.\nIn order to address the imbalanced nature of the datasets, the binary focal cross-entropy loss function was employed for training the baseline model due to its ability to focus on rare examples [49]. This loss function effectively assigns higher weights to misclassified samples, thereby alleviating the impact of class imbalance, and improving overall performance. For optimization, the Adam (Adaptive Moment Estimation) optimizer was employed due to its efficient and adaptive nature [50]. A learning rate equal to $10^{-4}$ was used, while the exponential decay rate for the first and second moment estimates was 0.9 and 0.999, respectively.\nDuring training, the labeled samples of the development set were considered for minimizing the chosen loss function. A batch size of 32 and 100 epochs were used, which is a commonly used default training scheme employed in multiple studies [51,52]. The validation score was employed for monitoring the model's convergence and an early stopping regularization technique was applied. After convergence, the performance of the trained model was evaluated on a test subset sampled from the development period and on the entire post-development set."}, {"title": "Drift detection mechanism", "content": "The proposed drift detection mechanism entailed divergence monitoring using the MMD distance and the implementation of the CUSUM algorithm [53,54] for generating drift alerts. The data were utilized in a chronological order towards monitoring the performance of the model. A batch-based approach was adopted for monitoring and processing data instances. An overview of the proposed drift detection mechanism is provided in Figure 4.\nTo effectively track the dissimilarity between the development data and post-development data, the MMD distance was adopted, which was computed by comparing the corresponding embeddings extracted by the VGGish feature extractor, as described in the previous subsection. These embeddings served as a representation of the data distribution and were used for calculating the MMD distances between batches of the post-development data and the development data, with the embeddings of the latter constituting the reference distribution. The MMD distance value between two batches of data is given by the following equation:\n$\\text{MMD}(X,Y) = \\Biggl|\\Biggl| \\frac{1}{n_x} \\sum_{i=1}^{n_x} \\phi(x_i) - \\frac{1}{n_y} \\sum_{i=1}^{n_y} \\phi(y_i) \\Biggl|\\Biggl|_H^2 \\\n\\qquad= \\frac{1}{n_x^2} \\sum_{i,j=1}^{n_x} k(x_i, x_j) + \\frac{1}{n_y^2} \\sum_{i,j=1}^{n_y} k(y_i, y_j) - \\frac{2}{n_x n_y} \\sum_{i=1}^{n_x} \\sum_{j=1}^{n_y} k(x_i, y_j)   \\qquad(1)$", "Monitoring divergence with MMD distance": "", "where": ""}, {"title": "CUSUM algorithm", "content": "After calculating the divergence between the development and post-development data, an implementation of the CUSUM algorithm was deployed for detecting points of significant increase in the divergence measure. CUSUM is a change detection algorithm which is widely used to identify shifts or changes in time series data [55\u201357], particularly when the exact nature of the change is unknown or when there is a need to continuously monitor data for detecting changes. CUSUM is widely adopted for real-time monitoring and surveillance applications in various fields, including quality control, signal processing, and anomaly detection.\nIn this study, the CUSUM algorithm was tailored to match the specific characteristics of the deep learning model and the monitored MMD distance. The proposed implementation introduced the calculation of relative differences between successive values instead of their corresponding absolute values, thus enabling the original CUSUM algorithm to effectively align with the behavior of the MMD distance and the desired level of sensitivity to changes. Therefore, the drift and threshold values represented the tolerance range of relative change in successive values and the minimum cumulative relative change required to trigger a change detection event, respectively."}, {"title": "Adaptation mechanism", "content": "Upon the triggering of an alert by the drift detection mechanism, an adaptation mechanism based on model retraining was activated to update the baseline model. The proposed adaptation mechanism aimed at enhancing the performance and improving the generalization abilities of the baseline model. Two different approaches based on UDA and AL were explored for the development of the adaptation mechanism."}, {"title": "Unsupervised domain adaptation", "content": "The UDA approach involved feeding the model with a batch of post-development data samples, along with a batch of samples from the development set. The model was then trained jointly on two tasks: (i) to correctly classify the labeled development data, and (ii) to minimize the MMD distance between the embeddings of the development and post-development batches. In this way, the model was trained to solve task (i) using domain-invariant features (development and post-development data), aiming at the minimization of two loss functions. The first loss function considered the model's output on samples of the development dataset, essentially employing supervised learning. The second loss function was based on the divergence between the distributions of the post-development data and development data batches using the MMD distance. The Gaussian kernel:\n$k(x,y) = \\exp \\left( - \\frac{||x - y||^2}{2\\sigma^2} \\right)  \\qquad(2)$\nwas selected to be used for the MMD distance calculation due to its ability to distinguish between distributions with differences in any order of moments [33,58] as demonstrated by its Maclaurin series representation:\n$k(x, y) = \\exp \\left( - \\frac{||x - y||^2}{2\\sigma^2} \\right)  = 1 - \\frac{||x - y||^2}{2\\sigma^2} + \\frac{(\\frac{||x - y||^2}{2\\sigma^2})^2}{2!} - \\frac{(\\frac{||x - y||^2}{2\\sigma^2})^3}{3!} + \\frac{(\\frac{||x - y||^2}{2\\sigma^2})^4}{4!} ...  \\qquad(3)$\nIn contrast, the linear kernel cannot distinguish between distributions with the same mean but different higher-order moments while the polynomial kernel of degree two is unable to differentiate between distributions that have the same mean and variance but differ in higher-order moments."}, {"title": "Active learning", "content": "The second adaptation approach incorporated AL principles into the retraining process. Building upon the drift detection mechanism, a methodology was developed able to identify informative data points incorporating both diversity and uncertainty estimation [36,37]. Once a period of divergence was detected by the drift detection mechanism, uncertain instances were selected from the divergent batch of data. To achieve this, the z-scores of the model's outputs on the divergent data were calculated and the data samples whose output fell within one standard deviation around the mean value of the model's predictions were defined as uncertain. Samples within this uncertainty range were selected, thus prioritizing the inclusion of challenging and informative instances during retraining, with the ultimate goal to enhance the model's generalization capabilities.\nConsidering that this adaptation method involved selecting informative unlabeled data and utilizing them as labeled, it was essential to compare the results of AL with those obtained through random sampling. The number of randomly sampled data was equal to the number of data points employed in the adaptation phases of the AL approach."}, {"title": "Results", "content": "The baseline model was assessed in terms of its ability to accurately detect covid-19 cases in the presence of variations or shifts in the data. In particular, the performance evaluation on the two considered datasets for the development and post-development periods is reported in Figure 6."}, {"title": "Baseline model", "content": "The baseline model was assessed in terms of its ability to accurately detect covid-19 cases in the presence of variations or shifts in the data. In particular, the performance evaluation on the two considered datasets for the development and post-development periods is reported in Figure 6.\nBased on the obtained results for the COVID-19 Sounds dataset, it is observed that the baseline model achieved superior performance on the test subset of the development period in terms of the Area Under the ROC Curve (AUC) (69.13%) and sensitivity (67.89%) compared to the best model performance reported in the literature [16] (66% AUC, 59% Sensitivity, 66% Specificity), despite considering a smaller amount of labeled data for training and validation (619 vs 1062 instances). The baseline model achieved a satisfactory F1 score (65.2%) but demonstrated quite low specificity, correctly classifying 58.88% of instances from the negative class. The performance of the baseline model on the post-development data demonstrated a significant decline in terms of the AUC, the F1 score, sensitivity, and specificity, as reported in Figure 6.\nIn the case of the COSWARA dataset, the baseline model displayed moderate discriminative ability on the development data, achieving an AUC value of 66.8%, while the accuracy, sensitivity, and specificity scores were equal to 60.57%, 62.96%, and 60.32%, respectively. The highly imbalanced distribution of the two classes in the development data (11.82% positive vs. 88.18% negative) posed a significant challenge for the model, as highlighted by the notably low F1 score, a metric that exclusively focuses on positive instances. The model's discriminative power on the post-development data presented a decline, as indicated by the AUC, specificity, and sensitivity, which are presented in Figure 6. The high value obtained for the F1 score metric was related to the presence of class imbalance with reversed minority (negative) and majority (positive) classes in the post-development data with respect to the class distribution of the development data, which led to a misleading perception that the model's performance had significantly improved. A more thorough analysis of this issue is provided in the Discussion section."}, {"title": "Hyperparameters' tuning", "content": "Tuning referred to hyperparameters related to data stream scanning and drift detection, which are summarized together with their examined values in Table 2. The tuning procedure considered hyperparameters used for data stream scanning (window length, overlap between successive windows, minimum batch size) and drift detection (kernel type and reference distribution for the MMD distance calculation and drift and threshold values of the CUSUM algorithm). The consideration of the minimum amount of data in a batch among the investigated hyperparameters enabled the inclusion of sufficient data during periods with a low data acquisition frequency, thus ensuring the robustness of the framework."}, {"title": "Unsupervised domain adaptation", "content": "A comparative assessment of the model's performance before and after each adaptation phase using the UDA approach was carried out. The performance of the baseline model, measured in terms of the balanced accuracy on the test subset of the development period, served as a benchmark for the evaluation of the model's performance after each adaptation period. For the COVID-19 Sounds dataset, the obtained balanced accuracy scores of the baseline model and the model after each adaptation phase are presented in Figure 9. It is evident that immediately after each alert period, the model's performance exhibited a considerable improvement, demonstrating the effectiveness of the proposed approach in mitigating the impact of concept drift. More specifically, following the first adaptation, the model showed an improved performance by up to 6% in terms of the balanced accuracy, which was maintained for four consequent batches (batches 2-5) before a second alert was triggered. Following the second adaptation, the model consistently outperformed the baseline model by up to 8%. After the third adaptation, the model enhanced its performance by more than 4%, remaining superior to the baseline model until the next drift detection, when the fourth adaptation led to a performance improvement of up to 15% which was maintained across ten batches (batches 19-28). After the fifth adaptation, the model exhibited a maximum performance increase of up to 24% and continued outperforming the baseline model until the end of the data stream. It is noteworthy that by correctly identifying periods of drift, the drift detection mechanism efficiently prevented the degradation of the model's performance in a timely manner while also contributing to sustaining the model's performance closer to the benchmark established during its development period."}, {"title": "Active learning", "content": "The proposed AL approach was evaluated by comparing the performance of the model after each AL-based retraining phase with that of the baseline model as well as the model following retraining using random sampling. Looking at the COVID-19 Sounds dataset, Figure 13 demonstrates the observed balanced accuracy score across the entire data stream, indicating a substantial and lasting improvement with respect to the baseline model following each adaptation. After the first adaptation, the model exhibited improved performance by up to 20% until the second alert, while a similar improvement was achieved following the second adaptation. After the third adaptation, the model's performance demonstrated a significant increase of up to 30%, sustained over a broad period of 15 batches. After the fourth adaptation, the model showcased outstanding performance, surpassing a 95% balanced accuracy score while achieving an improvement of up to 25% compared to the baseline model.\nThe performance comparison with the random sampling approach highlighted the superiority of the proposed AL approach, indicating its ability to identify informative data. Specifically, the random sampling approach outperformed AL only in four batches (i.e., batches 7, 12, 13, and 21) out of the 41 batches of the data stream. AL significantly outperformed the random sampling approach in all other cases. Similar conclusions can be drawn from Figure 14, where it can be seen that the majority of adaptations based on AL yielded increased performance in terms of all the considered evaluation metrics with respect to the baseline model and the random sampling approach.\nIn the case of the COSWARA dataset, Figure 15 shows that model adaptations led to improved performance during the post-alert periods. Following the first adaptation, there was a marginal increase in the balanced accuracy score, with the model slightly outperforming the baseline model until the subsequent alert. After the second adaptation, a notable enhancement of up to 20% in the balanced accuracy score was observed in the subsequent batches, while the fourth adaptation resulted in performance improvement of up to 25%. In terms of the third and fifth adaptations, although the model's performance exhibited significant enhancement, reaching up to 40% and 60%, respectively, performance fluctuations were also observed, with the model being outperformed by the baseline model in some batches."}, {"title": "Discussion", "content": "The evaluation of the proposed framework for detecting data drift and performing model adaptation provided evidence regarding the framework's ability to maintain model performance, thus highlighting its potential to facilitate the identification of new cases in a dynamic, non-stationary environment caused by a pandemic.\nA baseline model able to detect covid-19 positive cases using cough recordings was trained and evaluated. During the development period, the model achieved an AUC of 69.1% and 66.8% on the COVID-19 Sounds and COSWARA datasets, respectively. However, in the post-development period, there was a notable decline in the baseline model's performance, reflected to an AUC of 60.7% and 59.7%, respectively, thus suggesting the potential presence of concept drift. These findings motivated the development of the proposed approach, which leveraged robust drift detection and efficient adaptation mechanisms to maintain the model's performance in the face of evolving data distributions.\nThe obtained results indicated the efficacy of the proposed drift detection mechanism and provided evidence regarding its ability to enhance the robustness and adaptability of deep learning models in dynamic environments. The combination of the MMD distance monitoring and the use of the CUSUM algorithm for adaptive detection of abrupt changes, which reflect a growing divergence between the reference distribution (development data) and the post-development data, enabled the timely and robust detection of performance degradation. The use of the CUSUM algorithm, tailored to the characteristics of each dataset, ensured the generation of accurate alerts for significant changes in the monitored MMD distance, thus minimizing false alerts and preventing unnecessary interventions.\nTwo distinct retraining strategies based on UDA and AL were comparatively assessed in terms of their ability to mitigate performance degradation. The UDA approach enhanced the model's ability to learn from unlabeled data, while AL facilitated the selection of informative instances for targeted retraining. The results obtained from the analysis of the COVID-19 Sounds dataset showed that the UDA approach significantly improved the model's discriminative ability. The comprehensive examination of the subsequent adaptation phases based on multiple evaluation metrics revealed deviations from the baseline model's performance, most of which corresponded to an improvement in the balanced accuracy, ranging from 10% to 20%.\nThe above findings align with UDA's core advantages, which include cost-effectiveness and adaptability to dynamic environments through the model's adaptation to the target domain's data distribution without requiring labeled target domain samples. This approach is particularly valuable when labeled data from the target domain are scarce or expensive to obtain, as is often the case in emerging pandemic scenarios.\nThe application of the UDA approach on the COSWARA dataset yielded less consistent results. The overall comparison between the adapted models and the baseline model revealed that the adaptation had diverse effects on the model's performance in terms of the considered evaluation metrics.\nThe difference in the effectiveness of the UDA approach on the COVID-19 Sounds and COSWARA data may be attributed to differences in the datasets' characteristics. Figure 17 and Figure 18 illustrate selected descriptive statistics of the development and post-development data of the COVID-19 Sounds and COSWARA dataset. As per [16], the COVID-19 Sounds dataset used in the present study had underwent meticulous curation to eliminate biases as a result of methodological decisions, thus enabling the development of unbiased models. In the case of COSWARA dataset, significant differences were observed in terms of covid-19 prevalence and the frequency of related symptoms between the development and post-development data, which may be attributed to the presence of age and gender biases [59]. In the present study, handling the data in chronological order implicated different levels of data biases present across the various adaptation periods, which may arise in emerging pandemic scenarios.\nThe AL approach resulted in more prominent improvement in the models' performance compared to UDA. This underscored the power of actively selecting informative samples for labeling, which aids in refining the model's understanding of the target domain. Thus, by optimizing both adaptation to the target data and use of labeling resources, AL is considered promising for ensuring model performance in data scarce scenarios, such as during a pandemic.\nGiven that both UDA and AL achieved varying levels of performance improvement on both datasets, it is essential to consider their limitations and potential challenges. UDA relies on the assumption that the source and target domains share some underlying similarity. In the presence of significant differences, adaptation might not yield substantial improvements. On the other hand, AL's performance is determined by human labeling expertise, which is associated with the rise of the related costs and depends on the reliability of the existing diagnostic tests. If the chosen samples are mislabeled, the model's performance could suffer. Moreover, AL's performance is sensitive to the selection of labeled samples, which might introduce biases.\nThe above observations suggest that the proposed adaptation mechanisms effectively addressed the individual challenges linked to the special characteristics of each dataset and mitigated the effects of concept drift during critical periods corresponding to batches in proximity to the alert periods. Figure 19 summarizes the model's performance obtained by applying each adaptation approach on the post-development period of the two datasets and shows that both approaches succeeded in maintaining the models' performance closer to the development period's benchmark. These results highlight the importance of combining effective drift detection mechanisms and intelligent adaptation modules in addressing concept drift. Together, these components form a robust framework that enables the model to continuously adapt to changing data conditions, thereby maintaining its discriminative power and overall performance over time.\nThe significance of the proposed approach lies in its reliance on unsupervised techniques. By minimizing the dependence on labeled data, the proposed framework enables the accurate detection of covid-19 cases even in the absence of comprehensive labeling resources. This aspect becomes particularly crucial when considering the value of a deep learning-based detection model during the early stages of a new pandemic or when dealing with emerging viral variants that may not be adequately detected by existing diagnostic tools. Thus, the proposed framework is able to contribute towards a more generalizable approach that can be applied to future pandemics or novel variants. By collecting knowledge and formulating a well-defined framework, a basis for rapid adaptation and deployment of disease detection tools is established, ensuring timely and accurate identification of infectious diseases."}]}