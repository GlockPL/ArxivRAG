{"title": "Causal Graphs Meet Thoughts: Enhancing Complex Reasoning in Graph-Augmented LLMs", "authors": ["Hang Luo", "Jian Zhang", "Chujun Li"], "abstract": "In knowledge-intensive tasks, especially in high-stakes domains like medicine and law, it is critical not only to retrieve relevant information but also to provide causal reasoning and explainability. Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, integrating knowledge graphs with Graph Retrieval-Augmented Generation (Graph RAG) has emerged as an effective solution. Traditional Graph RAG methods often rely on simple graph traversal or semantic similarity, which do not capture causal relationships or align well with the model's internal reasoning steps. This paper proposes a novel pipeline that filters large knowledge graphs to emphasize cause-effect edges, aligns the retrieval process with the model's chain-of-thought (CoT), and enhances reasoning through multi-stage path improvements. Experiments on medical question-answering tasks show consistent gains, with up to a 10% absolute improvement across multiple large language models (LLMs). This approach demonstrates the value of combining causal reasoning with stepwise retrieval, leading to more interpretable and logically grounded solutions for complex queries.", "sections": [{"title": "1 Introduction", "content": "Human civilization has always advanced by systematically gathering and applying knowledge. In contemporary settings, this process typically involves integrating diverse information from large text corpora, databases, and real-world observations. Domains such as healthcare, law, and scientific research illustrate"}, {"title": "1.1 From Semantic Association to Causal Reasoning: Retrieval Challenges in Knowledge-Intensive Queries", "content": "Significant progress has been made using retrieval-augmented paradigms where queries are matched to semantically related documents [3,4]. However, many knowledge-intensive tasks demand more than semantic overlap: they require understanding logical structure and causal pathways that connect pieces of evidence [5]. For instance, retrieving an article stating \"Disease X is associated with Gene Y\" may be thematically relevant but might not fully answer how or why Gene Y leads to a specific disease manifestation. Hence, purely correlation-based retrieval can fall short in scenarios where an explicit explanation or directional link is needed.\nMoreover, large knowledge graphs (KGs) can exacerbate retrieval complexity. As the number of entities and edges grows often mixing correlational or loosely defined relationships simple similarity-based traversals may retrieve extensive sets of partially relevant or conflicting facts [6,7]. Systems relying on dense or symbolic retrieval alone can thus amass large volumes of loosely associated data, lacking a robust mechanism for highlighting causal edges that yield a coherent inference path, frequently resulting in incomplete or contradictory answers.\nRecent large language models (LLMs), exemplified by GPT-4 [8] and Claude 3 [9], have demonstrated remarkable capabilities in natural language generation and single-step knowledge retrieval. Yet, these models often struggle to maintain consistent reasoning across multiple inference steps, which can lead to hallucinations or logically inconsistent conclusions [11]. Without a transparent mechanism to explain why certain pieces of information connect to others, LLM-based pipelines cannot reliably ensure that each retrieval step aligns with an evolving chain of reasoning [12]. This situation makes it difficult to confirm the correctness of multi-stage answers and raises interpretability and reliability concerns.\nAn emerging consensus holds that causality is a critical missing piece in knowledge-intensive tasks [13,14]. Correlation-based retrieval (e.g., \"A relates to B\") may suffice for thematically aligned lookups but fails to encode directional or explanatory structures. By contrast, causal relationships indicate how and why one factor influences another [15], an especially crucial requirement in medical, legal, and scientific problem-solving.\nFurthermore, chain-of-thought (CoT) prompting [16] improves the interpretability of large language models by allowing them to articulate intermediate steps of reasoning. Rather than relying on the latent parameter space to form an opaque conclusion, CoT can reduce illusions of correctness and highlight each"}, {"title": "1.2 Key Limitations in Existing Graph RAG Approaches", "content": "While graph-based retrieval-augmented generation (RAG) has delivered improvements in various multi-hop tasks, the following interlocking challenges continue to undermine its reliability and explain ability especially in complex knowledge domains such as healthcare:\n1. Lack of Explicit Causal Priorities: Many existing systems treat all edges as equally important or relevant, overshadowing the truly causal links amid a sea of purely semantic or correlational relations [7]. These relations lack directionality or explanatory power.\nEffect: Because the retrieval engine cannot distinguish strong cause-effect edges from weaker associative edges, the final retrieval often includes tangential or trivial facts. As a result:\nPath Confusion: The system's final multi-hop path may jump between loosely connected nodes, making it hard for the model to isolate the true mechanism underlying the question.\nContradictory or Redundant Evidence: Over-representation of non-causal edges leads to clutter, forcing the model's inference steps to process conflicting or irrelevant details, increasing the chance of logical error.\nReduced Explain Ability: Without focusing on cause-effect relationships, the model's explanations (or chain-of-thought) become generic or incoherent, hampering trust in the system for high-stakes domains like healthcare.\n2. Limited Alignment with Model Reasoning: In many designs, the retrieval pipeline operates independently from the LLM's step-by-step inference [12]. Even if the LLM internally follows a coherent chain-of-thought, the external retrieval system might supply large batches of data unrelated to the current inference step.\nEffect: This misalignment severely undermines the synergy between how the model thinks and which facts are fetched:\nDisconnected or Contradictory Support: The LLM's partial solution steps cannot consistently refine retrieval because the engine is unaware of the next sub-question. The model thus tries to integrate data that may not fit the immediate line of reasoning.\nErratic or Inconsistent Conclusions: Since the intermediate logic does not match the retrieved evidence, the final answer can appear correct in some steps but then conflict with half of the retrieved context, causing contradictory or ambiguous reasoning.\nLost Opportunity for Iterative Querying: The model's chain-of-thought typically divides the query into sub-questions; a disconnected retrieval"}, {"title": "1.3 Hierarchical Causal Retrieval and Chain-of-Thought Enhancement", "content": "In this framework, two principles hold equal importance: (1) prioritizing causal edges within a large knowledge graph, and (2) aligning retrieval with the LLM's chain-of-thought to dynamically guide each reasoning step. Concretely, a hierarchical retrieval paradigm is proposed that looks for strong cause-effect links first and resorts to broader correlational or semantic edges only if purely"}, {"title": "1.4 Contributions and Paper Organization.", "content": "This work presents a Causal and Chain-of-Thought Enhancement on Graph RAG framework that:\n1. Develops a hierarchical retrieval scheme prioritizing cause-effect edges, thereby mitigating the noise of large KGs and bridging the gap between correlation-based retrieval and truly cause-oriented reasoning;\n2. Integrates chain-of-thought prompting to precisely align each reasoning step with graph lookups, ensuring retrieval remains in sync with the evolving inference process;\n3. Applies a causal inference-driven filtering stage to remove contradictory or tangential sub-paths, retaining only the subgraph consistent with the model's chain-of-thought.\nTaken together, these contributions advance both retrieval quality (through causal prioritization) and reasoning consistency (through CoT guidance), culminating in a scalable pipeline for complex, multi-hop QA in medical and similarly knowledge-intensive domains."}, {"title": "2 Related Works", "content": null}, {"title": "2.1 Retrieval-Augmented Generation and Graph-Based Knowledge Discovery", "content": "Retrieval-Augmented Generation (RAG) [19] has emerged as a central paradigm for embedding external knowledge into generative models, thereby enhancing their performance on knowledge-intensive tasks. Traditional text-based retrieval"}, {"title": "2.2 Causality in Knowledge-Intensive Natural Language Processing", "content": "Causality has long been recognized as a fundamental cornerstone of advanced knowledge discovery in fields spanning cognitive science, epidemiology, and machine learning [17,24]. Within natural language processing (NLP), numerous lines of inquiry-from causal event extraction [25] and counterfactual generation to specialized question answering-aim to move beyond simple correlations toward why-oriented explanations [13,14]. Nevertheless, integrating explicit causal inference into retrieval-centric architectures remains nontrivial. Many frameworks stop at correlation-based links or unstructured text retrieval, lacking specialized graph structures or annotated metadata to differentiate cause-and-effect from adjacency or co-occurrence [15]. Hence, while semantically relevant facts can be extracted, the logical consistency or directional flow crucial in knowledge-intensive queries is not guaranteed [12]."}, {"title": "2.3 Chain-of-Thought Prompts and Reasoning Transparency", "content": "Chain-of-thought (CoT) prompting [16] has recently garnered attention as a method to expose a language model's intermediate reasoning path. By prompting the model to sequentially articulate partial conclusions rather than jumping to a final answer, CoT can (i) provide interpretable glimpses into the model's decision-making process and (ii) sometimes improve performance on tasks requiring compositional or multi-stage thinking [1]. However, the widespread usage of CoT remains largely decoupled from retrieval pipelines. Typically, the LLM generates an internal chain-of-thought, but the system does not subdivide retrieval according to each CoT step. Consequently, any fine-grained reasoning states are"}, {"title": "2.4 Challenges in Aligning Causality, Graph Retrieval, and CoT Reasoning", "content": "Various research efforts seek to enrich retrieval-augmented generation by weaving in explicit inference or causal structures [16]. Yet persistent difficulties remain:\n1. Causal Under-specification. Many graph-based retrieval modules store correlations or broad associations but do not designate strong cause-and-effect edges. As a result, the pipeline fails to differentiate essential causal links from incidental relationships [7].\n2. Misaligned Retrieval vs. Reasoning Steps. Chain-of-thought prompts typically divide the reasoning into multiple short sub-steps, but standard Graph RAG retrieval is organized as a single module that either returns a large chunk of data or lumps all evidence together [12]. This misalignment can cause the LLM to request step-by-step clarifications, yet the retrieval engine has not subdivided the knowledge base lookups accordingly, thus returning content irrelevant to the current sub-question.\n3. Scalability Issues with Large Knowledge Graphs. In real-world applications, knowledge graphs may contain millions of edges with varying specificity or utility [6]. A naive graph traversal often yields excessively large or tangentially related subgraphs, eclipsing the critical edges. This surplus can confuse both causal reasoning and chain-of-thought, resulting in contradictory or incomplete final answers."}, {"title": "3 Methodology", "content": "This section describes the pipeline for (1) constructing a causal subgraph from a large knowledge graph (KG), (2) generating a chain-of-thought (CoT) that segments reasoning steps using \u201c\u2192\u201d markers, and (3) performing multi-stage retrieval and path enhancement with fallback strategies, including a final phase that re-injects the merged paths and original CoT into the language model."}, {"title": "3.1 Overall Framework", "content": "The method is divided into three main components:\n1. Causal graph construction and updating: A large KG is scanned, and only edges carrying cause-effect significance (e.g., CAUSE, MANIFESTATION_OF) are retained, assigning numeric strengths. Edges deemed purely correlational (e.g., ASSOCIATED_WITH, RELATED_TO) are excluded if their relevance falls below a threshold.\n2. Chain-of-thought-driven causal path retrieval: A CoT is acquired from the LLM, splitting each segment by \u201c\u2192,\u201d and attempting to find paths in the causal subgraph that connect the relevant entities. If no match is found, the method reverts to the full KG.\n3. Causal path processing and multi-stage enhancement: After retrieval, structurally similar paths are merged, refined scores (based on entity/semantic overlaps and path length) are computed, and the top-ranked subset is presented as final evidence. Both the final path set and the original CoT are then fed back to the LLM for a consistency check and \"enhanced\" output.\nBelow, each stage is detailed, referencing code snippets and the formulae used for scoring and filtering."}, {"title": "3.2 Causal Graph Construction and Updating", "content": "Filtering the Knowledge Graph for Causality. Let the original knowledge graph be G = (V,E). Each edge (u,r,v) \u2208 E has a relation label r that could"}, {"title": "3.3 Chain-of-Thought-Driven Causal Path Retrieval", "content": "CoT Generation and Parsing. For each query, the LLM is prompted to produce a chain-of-thought (CoT) in short segments, each separated by \u201c\u2192\u201d and ending with a numeric confidence in [0,100]. The chain is then split on these separators (omitting the final confidence) into segments {$1,82,...,ST}, each si being a concise statement or state.  illustrates this step-by-step retrieval process, showing how each segment is used to form intermediate sub-queries.\nStepwise Retrieval per CoT Segment. A domain-specific entity recognizer is run on each segment si, yielding entity sets E(si). For each consecutive pair (Si, Si+1) in the CoT, the method attempts to connect the recognized entities of si to those of si+1 by querying the causal subgraph Gc. If no suitable path is found, the fallback is the original KG G. These segment-level queries produce a candidate path pool Pcombined.\nPath Scoring and Pruning. Once Pcombined is assembled, a PathScore is assigned to each path p = {e1,...,eL}. Let strength(er) denote the numeric weight (causal strength if in Gc) of edge ei. The path score is computed as:\nPathScore(p) = $\\frac{\\sum_{i=1}^{L} strength(e_i)}{L}$"}, {"title": "3.4 Causal Path Processing and Multi-Stage Enhancement", "content": "After obtaining candidate paths from each CoT segment, we compute a combined score to prune irrelevant or overly long paths. Specifically, we define TotalScore(p) as in Equation (9).  shows a sample scenario of how scoring and pruning operate on three candidate paths.\nFirst-Stage Enhancement: Path Fusion and Preliminary Scoring All segment-level paths (including fallback) are gathered into a global set Pall:\nPall = $\\bigcup_{\\text{segment}} \\text{SelectedPaths}_{\\text{segment}}$\nIf multiple paths share the same start node, end node, and set of intermediate nodes, they are merged. Next, a TotalScore(p) is assigned to each merged path, reflecting relevance to the query. Specifically:"}, {"title": "4 Experiments", "content": "This section evaluates the causal-first Graph RAG framework on two medical multiple-choice QA datasets derived from MedMCQA and MedQA. Both datasets contain clinically oriented questions across multiple medical subtopics. Only items mapping into the causal subgraph are retained for testing; each system is compared using Precision, Recall, and F1 Score as the evaluation metrics."}, {"title": "4.1 Experimental Setup", "content": "Knowledge Graph. All retrievals occur against a SemMedDB-based knowledge graph (KG)\u2020, containing medically oriented entities (e.g., diseases, drugs, pathways) and relations (e.g., CAUSES, MANIFESTATION_OF, ASSOCIATED_WITH). The causal subgraph is constructed as described in Section 3.2, discarding edges whose cause-effect weight is below threshold 0. Some queries that fail to match any node in this subgraph are excluded.\nModels. Three large language models (LLMs) are tested:\nGPT-40: An instruction-tuned model, consistently the top performer among those tested,\nGPT-4: A similarly advanced LLM but slightly weaker in domain tasks,\nGPT-40-mini (40-mini): A smaller-capacity variant that lags behind the others."}, {"title": "4.2 Experimental Results", "content": "Experiment 1: Approached Method vs Direct Model Responses. As shown in Table 1, the LLMs leveraging the proposed method, which includes cause-effect filtering, CoT-aligned retrieval, and multi-stage path refinement, outperform direct single-step model responses across all three metrics Precision, Recall, and Recall F1 Score. The results highlight that the proposed approach, particularly when applied to CGMT(GPT-40 mini), provides significant improvements over direct GPT-40 mini (with precision up to 10% absolute), showcasing the effectiveness of this method in enhancing model performance for knowledge-intensive tasks."}, {"title": "4.3 Chain-of-Thought Cross-Model Evaluation", "content": "Cross-model scenarios were tested, where one model's Chain-of-Thought (CoT) is used by another. These tests involve three stages: the first stage is CoT generation, where one model generates the CoT; the second stage is enhancement, where the CoT is refined and enhanced by a different model; and the third stage is inference, where the final answer is generated based on the enhanced CoT. details the results of three such trials across these stages. Baseline references (92.90% for GPT-40, 83.06% for GPT-40 mini ) come from the \u201cCGMT\" row in Table 1.\nEvaluation. The results from the cross-model experiments provide valuable insights into the interactions between models of varying capacities. Specifically, the following observations were made:\nHigh-Capacity Model with Weak CoT: When GPT-40 relies on the CoT generated by GPT-40-mini, its accuracy drops from 92.90% to 87.98%. This result underscores the importance of a stronger LLM generating its own Chain-of-Thought, as the more complete reasoning chain produced by the high-capacity model leads to better performance.\nWeak Model with Strong CoT: In contrast, when GPT-40-mini uses GPT-40's CoT, its accuracy improves from 83.06% to 85.79%. This suggests that a more coherent and well-structured CoT can help compensate for the limited reasoning capacity of a smaller model.\nMixed CoT and Enhancements: In the scenario where both CoT generation and path enhancements are carried out by the smaller model, with final inference performed by GPT-40, the resulting performance (86.34%) remains intermediate. This highlights the crucial role of both the initial CoT generation and the path enhancement process in determining the final outcome. Even with the final inference step handled by the higher-capacity model, the quality of the preceding stages significantly constrains overall performance."}, {"title": "5 Discussion", "content": "Although the experiments indicate that a causal-first Graph RAG framework, aligned with chain-of-thought (CoT) prompting, can notably enhance multi-hop medical QA, certain limitations and open questions remain:\nUncertainty in Chain-of-Thought Generation. CoT outlines can vary under identical prompts, leading to contradictory or incomplete intermediate states if the LLM's sampling changes. This instability can produce retrieval successes or failures for the same question across multiple runs. Rarely, distinct final answers may also arise, suggesting that while CoT yields overall gains, it adds stochastic elements that must be managed.\nIncomplete or Low-Entropy Knowledge Graphs. Despite leveraging a large SemMedDB-based subgraph, certain clinically relevant edges may be missing, forcing fallback retrieval from correlation-based links. The wide connectivity and shallow semantics (e.g., \"related to\") can also cause clutter. More robust causal-mining and curated domain expansions could mitigate these drawbacks.\nFuture Outlook. The results validate the advantages of aligning causal-first retrieval with CoT. Further gains may be realized by stabilizing CoT prompts (via self-consistency sampling or advanced prompt engineering) and refining the knowledge graph itself (via domain-specific expansions). As LLMs and causal graphs continue to improve, uniting explicit cause-effect edges with chain-of-thought reasoning offers a compelling paradigm for knowledge-intensive domains."}, {"title": "6 Conclusion", "content": "This work has presented a comprehensive framework integrating causal-first knowledge graph filtration with chain-of-thought (CoT) guided retrieval, culmi-"}]}