{"title": "EFFICIENT SOURCE-FREE TIME-Series ADAPTATION VIA PARAMETER SUBSPACE DISENTANGLEMENT", "authors": ["Gaurav Patel", "Chris Sandino", "Behrooz Mahasseni", "Ellen Zippi", "Erdrin Azemi", "Ali Moin", "Juri Minxha"], "abstract": "In this paper, we propose a framework for efficient Source-Free Domain Adaptation (SFDA) in the context of time-series, focusing on enhancing both parameter efficiency and data-sample utilization. Our approach introduces an improved paradigm for source-model preparation and target-side adaptation, aiming to enhance training efficiency during target adaptation. Specifically, we reparameterize the source model's weights in a Tucker-style decomposed manner, factorizing the model into a compact form during the source model preparation phase. During target-side adaptation, only a subset of these decomposed factors is fine-tuned, leading to significant improvements in training efficiency. We demonstrate using PAC Bayesian analysis that this selective fine-tuning strategy implicitly regularizes the adaptation process by constraining the model's learning capacity. Furthermore, this re-parameterization reduces the overall model size and enhances inference efficiency, making the approach particularly well suited for resource-constrained devices. Additionally, we demonstrate that our framework is compatible with various SFDA methods and achieves significant computational efficiency, reducing the number of fine-tuned parameters and inference overhead in terms of MACs by over 90% while maintaining model performance.", "sections": [{"title": "1 INTRODUCTION", "content": "In a typical Source-Free Domain Adaptation (SFDA) setup, the source-pretrained model must adapt to the target distribution using unlabeled samples from the target domain. SFDA strategies have become prevalent due to the restrictive nature of conventional domain adaptation methods which require access to both source and target domain data simultaneously and therefore may not be feasible in real-world scenarios due to privacy and confidentiality concerns. Although SFDA techniques have been extensively investigated for visual tasks their application to time series analysis remains relatively nascent. Nevertheless, time-series models adaptation is crucial due to the nonstationary and heterogeneous nature of time-series data , where each user's data exhibit distinct patterns, necessitating adaptive models that can learn idiosyncratic features.\nDespite growing interest in SFDA, sample and parameter efficiency during adaptation is still largely unexplored. These aspects of SFDA are of particular importance in situations where there is a large resource disparity between the source and the target. For instance, a source-pretrained model may be deployed to a resource-constrained target device, rendering full model adaptation impractical. Additionally, the target-side often has access to substantially fewer reliable samples compared to the volume of data used during source pretraining, increasing the risk of overfitting.\nIn response to these challenges, we revisit both the source-model preparation and target-side adaptation processes. We demonstrate that disentangling the backbone parameter subspace at during source-model preparation and then fine-tuning a selected subset of those parameters during target-side adaptation leads to a computationally efficient adaptation process, while maintaining superior predictive performance. During source-model preparation, we re-parameterize the backbone weights in a low-rank Tucker-style factorized way, decomposing the model into compact parameter subspaces. Tucker-style factorization offers great flexibility and interpretability by breaking down tensors into a core tensor and factor matrices along each mode, capturing multi-dimensional interactions while independently reducing dimensionality. This reparameterization results in a model that is both parameter- and computation-efficient, significantly reducing the model size and inference overhead in terms of Multiply-Accumulate Operations (MACs).\nThe re-parameterized source-model\nis then deployed to the target side.\nDuring target-side adaptation, we\nperform selective fine-tuning (SFT)\nwithin a selected subspace (i.e. the\ncore tensor) that constitutes a very\nsmall fraction of the total num\nber of parameters in the backbone.\nOur findings show that this strat\negy not only enhances parameter ef\nficiency but also serves as a form\nof regularization, mitigating overfit\nting to unreliable target samples by\nrestricting the model's learning ca\npacity. We provide theoretical in\nsights into this regularization effect\nusing PAC-Bayesian generalization\nbounds for the fine-tuned target model.\nEmpirical results demonstrate that low-rank weight disentanglement during source-model preparation enables parameter-efficient adaptation on the target side, consistently improving performance across various SFDA methods and time-series benchmarks. It is important to emphasize that our contribution does not introduce a novel SFDA method for time-series data. Instead, we focus on making the target adaptation process more parameter- and sample-efficient, and demonstrating that our framework can be seamlessly integrated with existing, and potentially future, SFDA techniques. In summary, our key contributions are:\n1.  We propose a novel strategy for source-model preparation by reparameterizing the backbone network's weights using low-rank Tucker-style factorization. This decomposition into a core tensor and factor matrices creates a compact parameter subspace representation, leading to a parameter- and computation-efficient model with reduced size and inference overhead.\n2.  During target-side adaptation, we introduce a selective fine-tuning (SFT) approach that adjusts only a small fraction of the backbone's parameters (i.e. the core tensor) within the decomposed subspace. This strategy enhances parameter efficiency and acts as an implicit regularization mechanism, mitigating the risk of overfitting to unreliable target samples by limiting the model's learning capacity.\n3.  We ground the regularization effect of SFT using the PAC Bayesian generalization bound. Empirical analyses demonstrate that our proposed framework improves the parameter and sample efficiency of adaptation process of various existing SFDA methods across the time-series benchmarks, showcasing its generalizability."}, {"title": "2 RELATED WORK AND OBSERVATIONS", "content": "Unsupervised Domain Adaptation in Time Series. Unsupervised Domain Adaptation (UDA) for time-series data addresses the critical challenge of distribution shifts between the source and target domains. Discrepancy-based methods, such as those of align feature representations through statistical measures, while adversarial approaches"}, {"title": "3 PROPOSED METHODOLOGY", "content": "In this section, we discuss our proposed methodology through several key steps: (1) We begin by discussing the SFDA setup. (2) We discuss the Tucker-style tensor factorization on the weight tensors of the pre-trained source-model, decomposing them into a core tensor and mode-specific factor matrices; where we introduce the rank factor (RF) hyperparameter to control the mode ranks in the decomposition, allowing for flexible trade-offs between model compactness and capacity. (3) During target-side adaptation, we selectively fine-tune the core tensor while keeping the mode factor matrices fixed, effectively adapting to distributional shifts in the target domain while reduced computational overhead and mitigating overfitting. (4) Finally, we offer theoretical insights grounded in PAC-Bayesian generalization analysis, demonstrating how source weight decomposition and target-side selective fine-tuning implicitly regularize the adaptation process, leading to enhanced generalization in predictive performance while rendering the process parameter- and sample-efficient.\nSFDA Setup. SFDA aims to adapt a pre-trained source model to a target domain without access to the original source data. Specifically, in a classification problem, we start with a source dataset \\(D_s = \\{(x_s, y_s); x_s \\in \\mathcal{X}_s, y_s \\in \\mathcal{C}_g\\}\\), where \\(\\mathcal{X}_s\\) denotes the input space, and \\(\\mathcal{C}_g\\) represents the set of class labels for the goal task in a closed-set setting. On the target side, we have access to an unlabeled target dataset \\(D_t = \\{x_t; x_t \\in \\mathcal{X}_t\\}\\), where \\(\\mathcal{X}_t\\) is the input space for the target domain. The aim of SFDA is to learn a target function \\(f_t : \\mathcal{X}_t \\rightarrow \\mathcal{C}_g\\) that can accurately infer the labels \\(y_t \\in \\mathcal{C}_g\\) for the samples in \\(D_t\\). \\(f_t\\) is obtained using only the unlabeled target samples in \\(D_t\\), and the source-model \\(f_s : \\mathcal{X}_s \\rightarrow \\mathcal{C}_g\\), which is pre-trained on the source domain. Each \\(x\\) (either from the source or target domain) is a sample of multivariate time series, i.e., \\(x \\in \\mathbb{R}^{M \\times L}\\), where \\(L\\) is the number of time steps (sequence length) and \\(M\\) denotes number of observations (channels) for the corresponding time step.\nTucker-style Factorization. After the supervised source pre-training , we adopt Tucker-style factorization of the weight tensors for its effectiveness in capturing multi-way interactions among different mode-independent factors. The compact core tensor encapsulates these interactions, and the factor matrices in the decomposition offer low-dimensional representations for each tensor mode. As illustrated in Figure 3A, the rank-\\( (R_1, R_2, R_3) \\) Tucker-style factorization of the 3-way tensor \\( \\mathcal{A} \\in \\mathbb{R}^{I_1 \\times I_2 \\times I_3} \\) is represented as:\n\\[\\mathcal{A} = \\mathcal{G} \\times_1 U^{(1)} \\times_2 U^{(2)} \\times_3 U^{(3)}  \\text{ or, } A_{i,j,k} = \\sum_{r_1=1}^{R_1} \\sum_{r_2=1}^{R_2} \\sum_{r_3=1}^{R_3} G_{r_1,r_2,r_3} U^{(1)}_{i,r_1} U^{(2)}_{j,r_2} U^{(3)}_{k,r_3},\\quad\\forall (i, j, k). \\tag{1}\\]\nwhere \\(\\mathcal{G} \\in \\mathbb{R}^{R_1 \\times R_2 \\times R_3}\\) is referred to as the core tensor, and \\(U^{(1)} \\in \\mathbb{R}^{I_1 \\times R_1}, U^{(2)} \\in \\mathbb{R}^{I_2 \\times R_2}\\) and \\(U^{(3)} \\in \\mathbb{R}^{I_3 \\times R_3}\\) as factor matrices.\nFurthermore, the linear operations involved in Tucker-style representation (Equation (1)), which are primarily mode-independent matrix multiplications between the core tensor and factor matrices, simplify both mathematical treatment and computational implementation. This linearity ensures that linear operations (e.g., convolution or linear projection) in deep networks using the complete tensor can be efficiently represented as sequences of linear suboperations on the core tensor and factor matrices.\nFor instance, in one-dimensional convolutional neural networks (1D-CNNs), the convolution operation transforms an input representation \\(I \\in \\mathbb{R}^{C_{in} \\times L}\\) into an output representation \\(O \\in \\mathbb{R}^{C_{out} \\times L'}\\) using a kernel \\(W \\in \\mathbb{R}^{C_{out} \\times C_{in} \\times K}\\). Here, \\(C_{in}, C_{out}, K, L\\), and \\(L'\\) denote the number of input channels, output channels, kernel size, input sequence length, and output sequence length, respectively. The operation is mathematically defined as:\n\\[O_{i,l} = \\sum_{j=1}^{C_{in}} \\sum_{k=-\\frac{K}{2}}^{\\frac{K}{2}} W_{i,j,k} I_{j,l-k}.\\tag{2}\\]\nGiven that the dimensions of the channels (\\(C_{in}\\) and \\(C_{out}\\)) are typically much larger than the size of the kernel (\\(K\\)), we restrict the decomposition to modes 1 and 2 only, focusing on the input and output channels. The 2-mode decomposition is represented by:\n\\[W = T \\times_1 V^{(1)} \\times_2 V^{(2)} \\text{ or, } W_{i,j,k} = \\sum_{r_1=1}^{R_{out}} \\sum_{r_2=1}^{R_{in}} T_{r_1,r_2,k} V^{(1)}_{i,r_1} V^{(2)}_{j,r_2},\\tag{3}\\]\nwhere \\(T \\in \\mathbb{R}^{R_{out} \\times R_{in} \\times K}\\) is the 2-mode decomposed core tensor, and \\(U^{(1)} \\in \\mathbb{R}^{C_{out} \\times R_{out}}\\) and \\(U^{(2)} \\in \\mathbb{R}^{C_{in} \\times R_{in}}\\) represent the respective factor matrices, also illustrated in Figure 3B. With this decomposed form, the convolution operation can be represented as a sequence of the following linear operations:\n\\[Z_{r_2,l} = \\sum_{j=1}^{C_{in}} V^{(2)}_{j,r_2} I_{j,l},\\tag{4}\\]\n\\[Z_{r_1,l'} = \\sum_{r_2=1}^{R_{in}} \\sum_{k=-\\frac{K}{2}}^{\\frac{K}{2}} T_{r_1,r_2,k} Z_{r_2,l-k},\\tag{5}\\]\n\\[O_{i,l'} = \\sum_{r_1=1}^{R_{out}} V^{(1)}_{i,r_1} Z_{r_1,l'},\\tag{6}\\]\nwhere both the Channel Down-Projection and the Channel Up-Projection operations are implemented as unit window-sized convolution operations.\nBuilding on these insights, we decompose the pre-trained source model weights using Tucker decomposition, optimized via the Higher-Order Orthogonal Iteration (HOOI) algorithm, an alternating least squares method for low-rank tensor approximation (detailed algorithm in Appendix A.1). The optimization problem is defined as:\n\\[T^*, V^{(1)*}, V^{(2)*} = \\arg \\min_{T, V^{(1)}, V^{(2)}} ||W - T \\times_1 V^{(1)} \\times_2 V^{(2)}||_F.\\tag{7}\\]\nThe weight tensor is then re-parameterized with the core tensor \\(T^* \\in \\mathbb{R}^{R_{out} \\times R_{in} \\times K}\\) and mode factor matrices \\(V^{(1)*} \\in \\mathbb{R}^{C_{out} \\times R_{out}}\\) and \\(V^{(2)*} \\in \\mathbb{R}^{C_{in} \\times R_{in}}\\), as formulated in Equations (4), (5), and (6).\nHowever, the re-parameterization is performed after minimizing the linear reconstruction error of the weights (Equation 7), which may degrade the predictive performance on the source domain . To mitigate this effect, we fine-tune the core tensor and factor matrices using the source data for an additional 2-3 epochs, prior to deploying the model on the target side. This fine-tuning effectively restores the original predictive performance, preserving the model's performance while leveraging the benefits of fewer parameters. This behavior strongly aligns with the Lottery Ticket Hypothesis , which suggests that compressing and retraining pre-trained, over-parameterized deep networks can result in superior performance and storage efficiency compared to training smaller networks from scratch. Similar observations have been made by in the context of large language model training.\nMoreover, we introduce the rank factor (RF), a hyperparameter to standardize the mode rank analysis. The mode ranks are set as \\((R_{in}, R_{out})=(\\lceil\\frac{C_{in}}{RF}\\rceil, \\lceil\\frac{C_{out}}{RF}\\rceil)\\), where a higher RF results in lower mode ranks, and vice versa. Although RF can be set independently for the input and output channels, for simplicity in our analysis, we control both \\(R_{in}\\) and \\(R_{out}\\) with a single hyperparameter, RF. This tunable parameter allows for flexible control over the trade-off between parameter reduction and model capacity.\nTarget Side Adaptation. The core tensor in our setup plays a pivotal role by capturing multi-way interactions between different modes, encoding essential inter-modal relationships with the factor matrices. Additionally, its sensitivity to temporal dynamics (cf. Equation (5)) makes it particularly well-suited for addressing distributional shifts in time-series data, where discrepancies often arise due to temporal variations. Therefore, by selectively fine-tuning the core tensor during target adaptation, we can effectively adapt to these shifts while maintaining a compact parameterization. Figure 4 presents a toy experiment that demonstrates how fine-tuning the core tensor suffices in addressing domain shift, aligning the model more effectively with the target domain. This approach not only ensures that the model aligns better with the target domain but also enhances parameter efficiency by reducing the number of parameters that need to be updated, minimizing computational overhead. Moreover, selective fine-tuning mitigates the risk of overfitting, providing a more robust adaptation process, as shown in Figure 2B. This strategy leverages the expressiveness of the core tensor to address temporal domain shifts while maintaining the computational benefits of a structured, low-rank parameterization.\nComputational and Parameter Efficiency. The decomposition significantly reduces the parameter count from \\(C_{out} \\times C_{in} \\times K\\) to:\n\\[R_{out} \\times R_{in} \\times K + C_{out} \\times R_{out} + C_{in} \\times R_{in}\\tag{8}\\]\nwhere \\(R_{out} = \\lceil \\frac{C_{out}}{RF} \\rceil < C_{out}\\) and \\(R_{in} = \\lceil \\frac{C_{in}}{RF} \\rceil < C_{in}\\), ensuring substantial parameter savings. Furthermore, since we selectively finetune the core tensor, the parameter efficiency is further enhanced.\nIn terms of computational efficiency, the factorized convolution reduces the operation count from \\(O(C_{out} \\times C_{in} \\times K \\times L')\\) to a series of smaller convolutions with complexity:\n\\[O(C_{in} \\times R_{in} \\times L) + O(R_{out} \\times R_{in} \\times K \\times L') + O(C_{out} \\times R_{out} \\times L')\\tag{9}\\]\nresulting in a notable reduction in computational cost, dependent on the values of \\(R_{out}\\) and \\(R_{in}\\) (see Appendix A.2 for a detailed explanation).\nRobust Target Adaptation. In this subsection, we aim to uncover the underlying factors contributing to the robustness of the proposed SFT strategy, particularly in terms of sample efficiency and its implicit regularization effects during adaptation. To achieve this, we leverage the PAC-Bayesian generalization theory , which provides a principled framework for bounding the generalization error in deep neural networks during fine-tuning. We analyze the generalization error on the network parameters \\(W = \\{W_i\\}_{i=1}^D\\), i.e., \\(\\mathcal{L}(W) - \\hat{\\mathcal{L}}(W)\\), where \\(\\mathcal{L}(W)\\) is the test loss, \\(\\hat{\\mathcal{L}}(W)\\) is the empirical training loss, and \\(D\\) denotes the number of layers.\nTheorem 1. (PAC-Bayes generalization bound for fine-tuning) Let W be some hypothesis class (network parameters). Let P be a prior (source) distribution on W that is independent of the target training set. Let Q(S) be a posterior (target) distribution on W that depends on the target training set S consisting of n number of samples. Suppose the loss function \\(\\mathcal{L}(.)\\) is bounded by C. If we set the prior distribution \\(P = \\mathcal{N}(W_{src}, \\sigma^2 I)\\), where \\(W_{src}\\) are the weights of the pre-trained network. The posterior distribution Q(S) is centered at the fine-tuned model as \\(\\mathcal{N}(W_{trg}, \\sigma^2 I)\\). Then with probability \\(1 - \\delta\\) over the randomness of the training set, the following holds:\n\\[E_{W \\sim Q(S)}[\\mathcal{L}(W)] \\le E_{W \\sim Q(S)}[\\hat{\\mathcal{L}}(W, S)] + C\\sqrt{\\frac{\\textstyle \\sum_{i=1}^D \\frac{\\textstyle 1}{2\\sigma^2 n} ||W_{trg}^{(i)} - W_{src}^{(i)}||_F^2 + k \\ln \\frac{1}{\\delta}}{\\textstyle n}} + \\frac{k \\ln \\frac{4}{\\delta} + l}{\\textstyle n}},\\tag{10}\\]\nfor some \\(\\delta, k, l > 0\\), where \\(W_{trg}^{(i)}\\) and \\(W_{src}^{(i)}\\in W\\), \\(\\forall 1 \\le i \\le D\\), D denoting the total number of layers."}, {"title": "4 EXPERIMENTS AND ANALYSIS", "content": "Datasets and Methods. We utilize the AdaTime benchmarks proposed by to evaluate the SFDA methods: SSC and MFD , HHAR , UCIHAR , WISDM . Here each dataset involves distinct domains based on individual subjects (SSC), devices (HHAR, UCIHAR, WISDM) or entities (MFD). For comprehensive dataset descriptions and domain details, refer to the Appendix A.5. To assess the effectiveness and generalizability of our decomposition framework, we integrate it with prominent SFDA methods: SHOT , NRC , AAD , and MAPU ."}, {"title": "5 CONCLUSION", "content": "In this work, we presented a framework for improving the parameter and sample efficiency of SFDA methods in time-series data through a low-rank decomposition of source-pretrained models. By leveraging Tucker-style tensor factorization during the source-model preparation phase, we were able to reparameterize the backbone of the model into a compact subspace. This enabled selective fine-tuning (SFT) of the core tensor on the target side, achieving robust adaptation with significantly fewer parameters. Our empirical results demonstrated that the proposed SFT strategy consistently outperformed baseline SFDA methods across various datasets, especially in resource-constrained and low-data scenarios. Theoretical analysis grounded in PAC-Bayesian generalization bounds provided insights into the regularization effect of SFT, highlighting its ability to mitigate overfitting by constraining the distance between source and target model parameters. Our ablation studies further reinforced the effectiveness of selective finetuning, showing that this approach strikes a balance between adaptation flexibility and parameter efficiency. In Appendix A.9 we discuss the limitations of the presented work. Overall, our contributions positively complement the SFDA methods, offering a framework that can be seamlessly integrated with existing SFDA techniques to improve adaptation efficiency. This lays the groundwork for future research into more resource-efficient and personalized domain adaptation techniques."}, {"title": "A APPENDIX", "content": "A.1 HIGHER ORDER ORTHOGONAL ITERATION\nAlgorithm 1: The higher-order orthogonal iteration (HOOI) algorithm.\nInput: Tensor \\(A \\in \\mathbb{R}^{I_1 \\times I_2 \\times\\dots\\times I_N}\\), Truncation \\((R_1, R_2, . . ., R_N)\\), Initial guess\n\\(\\{U^{(n)} : n = 1, 2, ...,N\\}\\)\nOutput: Core tensor \\(G\\), Factor matrices \\(\\{U^{(n)} : n = 1, 2, . . ., N\\}\\)\n\\(k\\leftarrow 0\\);\nwhile not converged do\nfor all \\(n \\in \\{1,2,..., N \\}\\) do\n\\(B^{(n)} \\leftarrow A \\times_1 (U_{k+1}^{(1)})^T \\times_2 \\dots \\times_{n-1} (U_{k+1}^{(n-1)})^T \\times_{n+1} (U_{k}^{(n+1)})^T... \\times_{N} (U_{k}^{(N)})^T\\);\n\\(B^{(n)} \\leftarrow B\\) in matrix format;\n\\(U, \\Sigma, V^T \\leftarrow\\) truncated rank-\\(R_n\\) SVD of \\(B^{(n)}\\);\n\\(U_{k+1}^{(n)} \\leftarrow U\\);\n\\(k\\leftarrow k + 1\\);\n\\(G \\leftarrow \\Sigma V^T\\) in tensor format;\nA.2 PARAMETER AND COMPUTATIONAL EFFICIENCY WITH TUCKER DECOMPOSITION\nA.2.1 TUCKER FACTORIZATION FOR CNN WEIGHTS\nConsider a 3D weight tensor \\(W \\in \\mathbb{R}^{C_{out} \\times C_{in} \\times K}\\) for a 1D convolutional layer, where \\(C_{out}\\) and \\(C_{in}\\) represent the output and input channels, and \\(K\\) is the kernel size. Using Tucker factorization, \\(W\\) can be decomposed into a core tensor \\(T \\in \\mathbb{R}^{R_{out} \\times R_{in} \\times K}\\) and factor matrices \\(V^{(1)} \\in \\mathbb{R}^{C_{out} \\times R_{1}}\\), \\(V^{(2)} \\in \\mathbb{R}^{C_{in} \\times R_{2}}\\), such that:\n\\[W = T \\times_1 U^{(1)} \\times_2 U^{(2)}\\tag{11}\\]\nParameter Efficiency. The number of parameters before factorization is:\n\\[ParamSoriginal = C_{out} \\times C_{in} \\times K\\tag{12}\\]\nAfter 2-Mode Tucker factorization, the number of parameters become:\n\\[ParamsTucker = R_{out} \\times R_{in} \\times K + C_{out} \\times R_{out} + C_{in} \\times R_{in}\\tag{13}\\]\nGiven that \\(R_{in} << C_{in}\\), and \\(R_{out} << C_{out}\\), the reduction in the number of parameters is significant, leading to a parameter-efficient model.\nComputational Efficiency. The convolution operation requires \\(O(C_{out} \\times C_{in} \\times K \\times L')\\) operations, where \\(L'\\) is the length of the output feature map. After Tucker factorization, the convolutional operations become a sequence of smaller convolutions involving the factor matrices and the core tensor, reducing the computational complexity to:\n\\[O(C_{in} \\times R_{in} \\times L) + O(R_{out} \\times R_{in} \\times K \\times L') + O(C_{out} \\times R_{out} \\times L')\\tag{14}\\]\nwhere \\(L\\) denotes the length of the input sequence. This reduction depends on the rank \\(R_{in}\\) and \\(R_{out}\\), leading to lower computational costs compared to the original convolution.\nA.2.2 TUCKER FACTORIZATION FOR FULLY CONNECTED WEIGHTS\nConsider a 2D weight matrix \\(W \\in \\mathbb{R}^{M \\times N}\\) in a fully connected (FC) layer, where \\(M\\) is the input dimension and \\(N\\) is the output dimension."}, {"title": "A.3 LEMMAS", "content": "Lemma 1. Let \\(W_o \\in \\mathbb{R}^{M \\times N}\\) be the initial weight matrix, and \\(W_t \\in \\mathbb{R}^{M \\times N}\\) denote the weight matrix after t iterations of gradient descent with a fixed learning rate \\(\\eta > 0\\). Suppose the gradient of the loss function \\(\\mathcal{L}(W)\\) is bounded, such that for all iterations \\(k = 0,1,..., t - 1\\), we have \\(||\\nabla \\mathcal{L}(W_k)||_{\\infty} \\le G\\) where \\(G > 0\\) is a constant.\nThen, the Frobenius norm of the difference between the initial weight matrix \\(w_o\\) and the weight matrix \\(w_t\\) after t iterations is bounded by:\n\\[||W_t - W_o||_F < \\eta t\\sqrt{MN} G.\\]\nProof. The gradient descent algorithm updates the weight matrix according to the rule:\n\\[W_{k+1} = W_k - \\eta \\nabla \\mathcal{L}(W_k).\\]\nStarting from the initial weights \\(W_o\\), the weights after t iterations are:\n\\[W_t = W_o - \\eta \\sum_{k=0}^{t-1} \\nabla \\mathcal{L}(W_k).\\]\nTaking the Frobenius norm of the difference between \\(w_t\\) and \\(w_o\\), we have:\n\\[||W_t - W_o||_F = \\eta \\sum_{k=0}^{t-1} \\nabla \\mathcal{L}(W_k)\\]\nUsing the triangle inequality for norms:"}, {"title": "A.4 PROOF OF THEOREM 1", "content": "Background. PAC-Bayesian generalization theory offers an appealing method for incorporating data-dependent aspects, like noise robustness and sharpness, into generalization bounds. Recent studies, such as  , have expanded these bounds for deep neural networks to address the mystery of why such models generalize effectively despite possessing more trainable parameters than training samples. Traditionally, the VC dimension of neural networks has been approximated by their number of parameters . While these refined bounds mark a step forward over classical learning theory, questions remain as to whether they are sufficiently tight or non-vacuous. To address this,  proposed a computational framework that optimizes the PAC-Bayes bound, resulting in a tighter bound and lower test error.  validated this framework in a large-scale study. More recently,  compared different complexity measures and found that PAC-Bayes-based tools align better with empirical results. Furthermore,  utilized this bound to motivate their proposed improved regularization and genralization, respectively. Consequently, the classical PAC-Bayesian framework  provides generalization guarantees for randomized predictors . In particular, let \\(f_W\\) be any predictor (not necessarily a neural network) learned from the training data and parametrized by W. We consider the distribution Q over parameters of predictors of the form \\(f_W\\), where W is a random variable whose distribution may also depend on the training data. Given a prior distribution P over the set of predictors that is independent of the training data, S. The PAC-Bayes theorem states that with probability at least 1 \u2013 \\(\\delta\\) over the draw of the training data, the expected error of \\(f_W\\) can be bounded as follows\n\\[E_{W \\sim Q(S)}[\\mathcal{L}(W)] \\le E_{W \\sim Q(S)}[\\hat{\\mathcal{L}}(W, S)] + C\\sqrt{\\frac{K L(Q(S) || P) + k \\ln \\frac{4}{\\delta} + l}{n}},\\tag{15}\\]\nfor some C, k, l > 0. Then based on the above described bound we reduce it for our case, where the prior distribution on the parameters is centered on source pre-trained weights and the posterior distribution on the target-adapted model and define Theorem 1.\nTheorem 1. (PAC-Bayes generalization bound for fine-tuning) Let W be some hypothesis class (network parameter). Let P be a prior (source) distribution on W that is independent of the target training set. Let Q(S) be a posterior (target) distribution on W that depends on the target training set S consisting of n number of samples. Suppose the loss function \\(\\mathcal{L}(.)\\) is bounded by C. If we set the prior distribution \\(P = \\mathcal{N}(W_{src}, \\sigma^2 I)\\), where \\(W_{src}\\) are the weights of the pre-trained network. The posterior distribution Q(S) is centered at the fine-tuned model as \\(\\mathcal{N}(W_{trg}, \\sigma^2 I)\\). Then with probability 1 \u2013 \\(\\delta\\) over the randomness of the training set, the following holds:\n\\[E_{W \\sim Q(S)}[\\mathcal{L}(W)] \\le E_{W \\sim Q(S)}[\\hat{\\mathcal{L}}(W, S)] + C\\sqrt{\\frac{\\textstyle \\sum_{i=1}^D \\frac{\\textstyle 1}{2\\sigma^2 n} ||W_{trg}^{(i)} - W_{src}^{(i)}||_F^2 + k \\ln \\frac{4}{\\delta}}{\\textstyle n}} + \\frac{k \\ln \\frac{4}{\\delta} + l}{\\textstyle n}},\\tag{16}\\]\nfor some \\(\\delta, k, l > 0\\), where \\(W_{trg}^{(i)}\\) and \\(W_{src}^{(i)}\\in W\\), \\(\\forall 1 \\le i \\le D\\), D denoting the total number of layers.\nIt is important to note that the original formulation in  assumes the loss function is restricted to values between 0 and 1. In contrast, the modified version discussed here extends the applicability to loss functions that are bounded between 0 and some positive constant C. This adjustment is made by rescaling the loss function by a factor of \\(\\frac{1}{C}\\), which introduces the constant C in the right-hand side of Equation (15)."}, {"title": "A.5 DATASET DESCRIPTION", "content": "We utilize the benchmark datasets provided by AdaTime . These datasets exhibit diverse attributes such as varying complexity, sensor types, sample sizes, class distributions, and degrees of domain shift, allowing for a comprehensive evaluation across multiple factors.\nTable 3 outlines the specific details of each dataset, including the number of domains, sensor channels, class categories, sample lengths, and the total sample count for both training and testing sets. A detailed description of the selected datasets is provided below:\n\u2022 UCIHAR : The UCIHAR dataset consists of data collected from three types of sensors\u2014accelerometer, gyroscope, and body sensors\u2014used on 30 different subjects. Each subject participated in six distinct activities: walking, walking upstairs, walking downstairs, standing, sitting, and lying down. Given the variability across subjects, each individual is considered a separate domain. From the numerous possible cross-domain combinations, we selected the ten scenarios set by .\n\u2022 WISDM : The WISDM dataset uses accelerometer sensors to gather data from 36 subjects engaged in the same activities as those in the UCIHAR dataset. However, this dataset presents additional challenges due to class imbalance among differ-ent subjects. Specifically, some subjects only contribute samples from a limited set of the overall activity classes. As with the UCIHAR dataset, each subject is treated as an individual domain, and ten cross-domain scenarios set by  are used for evaluation.\n\u2022 HHAR : The Heterogeneity Human Activity Recognition (HHAR) dataset was collected from 9 subjects using sensor data from both smartphones and smart-watches. standardized the use of a single device, specifically a Samsung smartphone, across all subjects to minimize variability. Each subject is treated as an independent domain, and a total of 10 cross-domain scenarios are created by randomly selecting subjects.\n\u2022 SSC : The sleep stage classification (SSC) task focuses on cate-gorizing electroencephalography (EEG) signals into five distinct stages: Wake (W), Non-Rapid Eye Movement stages (N1, N2, N3), and Rapid Eye Movement (REM). This dataset is derived the Sleep-EDF dataset, which provides EEG recordings from 20 healthy individ-uals. Consistent with prior research , we select a single EEG channel (Fpz-Cz) and ten cross-domain scenarios for evaluation.\n\u2022 MFD : The Machine Fault Diagnosis (MFD) dataset has been col-lected by Paderborn University to identify various types of incipient faults using vibration signals. The data was collected under four different operating conditions, and in our experiments, each of these conditions was treated as a separate domain. We used twelve cross-condition scenarios to evaluate the domain adaptation performance. Each sample in the dataset consists of a single univariate channel."}, {}]}