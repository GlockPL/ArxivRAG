{"title": "KANS: Knowledge Discovery Graph Attention Network for Soft Sensing in Multivariate Industrial Processes", "authors": ["Hwa Hui Tew", "Gaoxuan Li", "Fan Ding", "Xuewen Luo", "Junn Yong Loo", "Chee-Ming Ting", "Ze Yang Ding", "Chee Pin Tan"], "abstract": "Soft sensing of hard-to-measure variables is often crucial in industrial processes. Current practices rely heavily on conventional modeling techniques that show success in improving accuracy. However, they overlook the non-linear nature, dynamics characteristics, and non-Euclidean dependencies between complex process variables. To tackle these challenges, we present a framework known as a Knowledge discovery graph Attention Network for effective Soft sensing (KANS). Unlike the existing deep learning soft sensor models, KANS can discover the intrinsic correlations and irregular relationships between the multivariate industrial processes without a predefined topology. First, an unsupervised graph structure learning method is introduced, incorporating the cosine similarity between different sensor embedding to capture the correlations between sensors. Next, we present a graph attention-based representation learning that can compute the multivariate data parallelly to enhance the model in learning complex sensor nodes and edges. To fully explore KANS, knowledge discovery analysis has also been conducted to demonstrate the interpretability of the model. Experimental results demonstrate that KANS significantly outperforms all the baselines and state-of-the-art methods in soft sensing performance. Furthermore, the analysis shows that KANS can find sensors closely related to different process variables without domain knowledge, significantly improving soft sensing accuracy.\nKeywords- Soft sensing, graph attention network, knowledge discovery.", "sections": [{"title": "I. INTRODUCTION", "content": "The fast advances in modern cyber-physical systems has fueled the ever increasing demand of highly-specialized sensors for quality measurements in interlinked multivariate industrial processes. For example, a chemical process plant requires numerous acquisitions such as pressure, flow rate, density, temperature, and current via physical or hardware sensors for continuous monitoring of key quality variables that are critical for process operation [1]. However, physical sensors often suffer from a variety of limitations such as susceptible to harsh conditions, need for regular maintenance and high costs. To overcome these limitations, a soft sensor can be developed as an alternative to the physical hardware sensors [2].\nA soft sensor is capable of inferring hard-to-measure variables by utilising easy-to-measure variables as inputs. In comparison to conventional hardware sensors, soft sensors are less expensive to build, more efficient, and flexible in terms of their adaptability, customizability, and scalability to the fast-evolving industrial systems [3]. There are two main categories of soft sensors: knowledge-based, and data-driven methods. Developing a high-fidelity knowledge-based soft sensor relies on having a deep understanding of the process mechanisms, as well as extensive experience and knowledge about the system process. However, the increasing complexity of industrial processes have given rise to the difficulty of meeting the basic preconditions. Therefore, for practicability, data-driven modeling has become the favorable soft sensing modeling method [4].\nConventional data-driven approaches such as support vector regression (SVR) and partial least square regression (PLR) have been successfully applied to soft sensing in a wide range of industrial applications [5]\u2013[7]. Nonetheless, these models exhibit difficulty in handling multi-modal, high-dimensional sensor data associated with many complex real-world systems. Recently, deep learning techniques such as artificial neural network (ANN), convolutional neural networks (CNN) and recurrent neural networks (RNN) have demonstrated superior capability in capturing the complex non-linearity and rich dynamics underlying most systems. This is attributed to the advanced expressiveness of these deep models, allowing them to learn accurate representations of the data [8]\u2013[10]. Nevertheless, these conventional deep models could not explicitly capture the meaningful non-Euclidean correlations between the sensors; incorporating this spatial information could potentially improve soft sensing performance.\nRecent works have shown promising results in leveraging a graph representation of the multivariate soft sensor data to account for the underlying non-Euclidian spatial correlations [11]\u2013[14]. In particular, graph neural networks (GNN) have shown success in effectively modeling and analyzing graph-structured data. For example, Jia et al. considered spatiotemporal relations in GNN to predict the penicillin fermentation process [15]. Wang et al. utilized GNN to predict the volatile fatty acid concentration of kitchen waste [16]. Feng et al. applied GNN in predicting endpoint composition in steel [17]. However, they overlooked the use of rich graph embedding for both nodes and edges within the graph structure of soft sensing data, instead representing them exclusively as scalar process variables. Furthermore, Wang et al. proposed a fused representation of knowledge and a data-driven method that can enhance soft sensor modeling [18]. Nevertheless, it did not learn the nodes and edges inherently, as opposed to having them as prior knowledge, which requires extensive human knowledge. Besides, Chen et al. presented a deep attention GNN to explore data latent interactions of industrial processes [19]. He et al. combined GRU and attention mechanism to extract and strengthen spatio-temporal feature information [20]. Huang et al. leveraged GNN to capture the correlation of sensors in wafer manufacturing process [21]. One the one hand, they face challenges in capturing long-range dependencies and require high computational effort due to the sequential nature of GRU and graph convolutional operations. On the other hand, they did not explicitly address the deep features and learned graph representations that can provide insights into its interpretability.\nHence, to overcome the challenges in the afore-mentioned works, we present a knowledge discovery graph attention network framework (KANS) to discover underlying knowledge between process variables and learn the relationship between sensors for better soft sensing performance in multivariate industrial processes. Our methods include a latent sensor embedding that can capture sensor characteristics using embedding vectors. Next, an unsupervised constructive graph structure learning is explored, where graph edges between two sensors enforce the corresponding sensor embeddings to be similar. Then, a graph attention-based representation learning is devised to facilitate downstream task (soft sensing) by leveraging the sensor data within the learned graph structure. We conduct extensive experiments on different soft sensor models to evaluate their soft sensing performance. Ultimately, our results demonstrate that KANS can perform more accurately than baselines and state-of-the-art approaches. The main contributions of this paper are summarised as follows:\n1) We present an unsupervised contrastive graph structure learning method that can discover nodes and edges in a graph without a predefined topology. Our method brings an alternative way to handle data that has non-prior information in the field of soft sensing.\n2) We design a graph attention network that can compute multivariate time series data in parallel, achieving better soft sensing performance as compared to a sequential-like model.\n3) We perform knowledge discovery studies on KANS to help in visualizing the learned graph structure and relationships between different sensors.\nThe rest of the paper is summarized as follows: First, Section II explains the methodology of our proposed framework (KANS). Section III describes the implementation details with a case study on real-world industrial processes. Results and knowledge discovery analysis of baselines and KANS are discussed and presented in Section IV. Finally, conclusions are drawn in Section V."}, {"title": "II. METHODOLOGY", "content": "A. PROBLEM DEFINITION\nIn general industrial processes, there are complex topological relationships between the sensors that can be represented using a graph. Nonetheless, constructing a representative graph structure is not a straightforward task due to the non-linear and highly dynamic nature of most complex processes.\nIn this paper, consider a multivariate time series dataset of {s(t), o(t)} 0; where T denotes the number of samples, s(t) \u2208 R^(D-1)\u00d7T is denoted as the sensors data input, D is the total number of sensors and o(t) \u2208 R^(1\u00d7T) is the sensor output to be predicted, which is excluded in the inputs. The input-output of the soft sensing model is defined as follows:\n$$[x^{(t)} = [s^{(t-w)}, s^{(t-w+1)},...,s^{(t)}]$$\n$$y^{(t)} = o^{(t)}$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               (1)\nwhere w is the moving window size. The model is trained exclusively only on x(t). Precisely, our goal is to predict the hard-to-measure output y(t) by discovering the underlying process knowledge of sensors that are not known. Fig. 1 further describes the overview of our proposed framework. It consists of a data preprocessing module that converts raw data to sliding window format, a latent embedding module that extracts the characteristics of each sensor, an unsupervised contrastive graph structure learning module that learns the relationship between sensors, and a graph attention-based representation learning module that yields the final prediction from the graph attention feature module.\nB. LATENT EMBEDDING FOR SENSORS\nIdeally, we would want to extract the meaningful representation and pattern of the data to improve soft sensing performance. Therefore, we incorporate the embedding vector from usual sequence-like models onto sensor embedding that represents the behavior of the processes. In general, the sensor embedding is in the form of zi \u2208 R^d, where i\u2208 {1,2,3, ..., N} and d represents the dimension of the latent embedding. These embedding will help us tackle the following issues: 1) To identify which sensors exhibit equally plausible behaviors, and 2) To allow heterogeneous effects among different sensors using unsupervised contrastive representation learning over neighbors.\nC. UNSUPERVISED CONTRASTIVE GRAPH STRUCTURE LEARNING\nApart from data, graph structure is another basic requirement in training a graph neural network. Previous works need to manually define the graph structure with human knowledge. However, in most soft sensing scenarios, the graph structure of different sensors is often unknown or unattainable. Considering the general setting where there is no prior structure information, we present a flexible way to construct the topology between sensors by assessing the similarity score eji of the sensor i's embedding vector, and the embedding of its candidate j\u2208 Ri as follows:\n$$e_{ji} = \\frac{z_i z_j}{||z_i|| \\cdot ||z_j||}  \\quad for j \\in R_i$$ (2)\nwhere R_i = {1,2,..., N}\\ {i} indicates the candidate relations belongs to set individual sensors i within a system, excluding itself.\nSubsequently, we construct an adjacency matrix Aij that indicates the connection between sensors by selecting the top-k candidates that are the most relevant to sensor i. Otherwise, the adjacency matrix will be considered as 0, which indicates that no connection between the pair of sensor inputs in the graph. Here, the parameter k represents the sparsity level of the graph, where higher k gives rise to a denser graph and lower k leads to a sparser graph, with the following adjacency matrix:\n$$A_{ji} = \\begin{cases} 1, & \\text{if } j \\in \\text{top-k} (\\{ e_{ki} : k \\in R_i\\})\n\\\\ 0, & \\text{otherwise} \\end{cases}$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       (3)\nD. GRAPH ATTENTION-BASED REPRESENTATION LEARNING\nConventional sequence-to-sequence modeling techniques generally employ a recurrent model where the past sensor inputs are dynamically embedded into the recurring hidden states for output prediction. However, they face challenges in retaining information over long horizons, handling multi-modal, and slower computational time. Therefore, we introduce a graph attention feature module that extracts an expressive latent representation of the sensor inputs. This extractor then merges the extracted sensor embedding of each node with those from its neighbors using the learned graph structure. The specific implementation is written as follows:\n$$g_i^{(t)} = z_i \\cdot Wx^{(t)}$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             (4)\n$$\\pi_{i,j} = LeakyReLU\\Big(a^T (g_i^{(t)}|| g_j^{(t)})\\Big)$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (5)\n$$a_{i,j} = \\frac{exp( \\pi_{i,j})}{\\sum_{k \\in N(i) \\cup \\{i\\}} exp(\\pi_{i,k})}$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (6)\n$$n_i^{(t)} = ReLU \\Big( a_{i,i} Wx^{(t)} + \\sum_{j \\in N(i)} a_{i,j} Wx^{(t)} \\Big)$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        (7)\nwhere g(t) represents the hidden state of neuron i, || symbolizes concatenation; hence g(t) concatenates sensor embedding zi with a linear transformation of its input features and W \u2208 R^(d\u00d7w) is a learnable weight matrix. Next, we use an attention mechanism to compute the attention score of the node i and j based on the concatenation of their node embedding g(t) and g(t). This equation computes a normalized attention score of \u03c0i,j via LeakyReLU activation. Furthermore, we convert the normalized attention score to attention probability ai,j using the softmax function in (6). Finally, the aggregation and update for the ith node in the graph is performed via (7) to obtain node embedding n(t).\nAfter deriving the feature extractor, we acquire representations for all N nodes as the set of node embedding for each t to yield the final predictions of sensor values. Here, \u00b7 denotes as the element-wise multiplication, with their respective time-series embedding zi. The resulting element-wise products are then used as the input into a fully-connected layer fe, and the results across all nodes are fed into a readout layer W_readout to obtain the final predictions of sensor \u0177(t):\n$$\\hat{y}^{(t)} = W_{\\text{readout}} \\Big(f_o (z_1^{(t)} \\cdot n_1^{(t)},..., z_N^{(t)} \\cdot n_N^{(t)}) \\Big)$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    (8)\nTo concurrently learn the embedding in (2) and (7) for graph structure and representation, respectively, we introduce a Mean Squared Error (MSE) loss on ground truth y(t) and predicted output \u0177(t) and train the end-to-end via stochastic gradient descent that is defined as follows:\n$$L_{MSE} = \\frac{1}{T} \\sum_{t=0}^{T} (y^{(t)} - \\hat{y}^{(t)})^2$$ (9)\nExisting approaches highlight utilizing prior knowledge to construct a fully-connected graph structure that can be treated as the input to GNN [15]\u2013[17]. However, such knowledge-based approaches neglect the possibility that different sensors may have connections to some sensors but not all. Moreover, prior knowledge is not always available and expert labels are expensive. To summarize our proposed methodology, our method can autonomously uncover patterns of different sensors and discover their inherent graph structure (network) without the consideration of prior graphs and domain knowledge. Furthermore, our approach can facilitate effective and self-contained soft sensor modeling, where its implementation to industrial processes would not require a profound understanding of complex industrial processes in identifying and optimizing the sensor networks."}, {"title": "III. EXPERIMENTS", "content": "A. CASE STUDY\nIn this paper, we evaluate our model performance on a real-world industrial process, known as Cranfield Multiphase Flow Process (MFP) [22]. It's a three-phase flow facility equipped with advanced measurements and monitoring capabilities. The system is operated with 20 different setpoints of air and water flow rates to capture a wide range of process dynamics during its operations. Fig. 2 shows the diagram of the MFP system showing the different sensors across its different locations. The facility collect up to 24 different process variables including pressure, flow rate, density, temperature, valve position, level and current, all of which serve as important dynamic key indicators of the system. Table I details the list of sensor variables in the MFP dataset. All variables are consistently sampled at a rate of 1 Hz. For the results, we consider six experiment settings (as shown in Table II) where we predict each of the sensor variables: 5, 8, 15, 16, 19, and 20. The remaining sensor variables are taken to be the soft sensor inputs in each of the experiment settings, respectively.\nB. BASELINES\nWe compare our model against seven different soft sensor models, in particular support vector regression (SVR) [5], partial least-square regression (PLSR) [6], dense neural network (DNN) [23], gated recurrent units (GRU) [24], and the more recent state-of-the-art approaches such as variable-weight stacked autoencoder (VW-SAE) [25], stacked target-related autoencoder (STAE) [26], gated STAE (GSTAE) [27].\nC. METRICS OF EVALUATION\nA comprehensive evaluation of the soft sensor models is obtained using four important performance metrics: normalized root mean square error (NRMSE), coefficient of determination (R2), normalized mean absolute error (NMAE), and mean absolute percentage error (MAPE). NRMSE and NMAE are used in place of RMSE and MAE so that after scaling, the results are consistent across the output variables of different units. The metrics are defined as follows:\n$$NRMSE = \\sqrt{\\frac{\\frac{1}{T}\\sum_{t=0}^{T} (y^{(t)} - \\hat{y}^{(t)})^2}{y_{max} - y_{min}}}$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             (10)\n$$R^2 = 1 - \\frac{\\sum_{t=0}^{T} (y^{(t)} - \\hat{y}^{(t)})^2}{\\sum_{t=0}^{T} (y^{(t)} - \\bar{y})^2}$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (11)\n$$NMAE = \\frac{\\sum_{t=0}^{T} \\frac{| y^{(t)} - \\hat{y}^{(t)} |}{y_{max} - y_{min}}}{T}$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   (12)\n$$MAPE = \\frac{100%}{T} \\sum_{t=0}^{T}  \\frac{ | y^{(t)} - \\hat{y}^{(t)} |}{y^{(t)} }$$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             (13)\nwhere y(t) represents the true value, \u0177(t) represents the predicted value, T is the number of samples, y is the mean value of the labeled output across time steps, Ymax and Ymin are the maximum and minimum of labeled output respectively. A lower NRMSE, NMAE, MAPE and a higher R2 depict better performance.\nD. IMPLEMENTATION DETAILS\nWe trained our model with a embedding dimension of 64, batch size of 64, hidden layer width of 128, and a dropout of 0.2. The Adam optimizer is used for loss training via a learning rate of 0.001. Here, we set the size of the sliding window to be 85 throughout the experiments. All models are trained for 200 epochs with early stopping."}, {"title": "IV. RESULTS AND DISCUSSIONS", "content": "A. SOFT SENSING PERFORMANCE AND ANALYSIS\nTable II depicts the soft sensing results of our proposed KANS and the other methods evaluated on the test dataset. Due to their inherent simplicity, machine learning models such as SVR and PLSR have performed worse than deep learning models, indicating that the machine learning model falls short of capturing the complex non-linearity of modern industrial processes. Additionally, deep learning models such as GRU performs better in all the metrics compared to DNN, VW-SAE, STAE, and GSTAE. This shows a strong indication that the sensor measurements of the MFP dataset exhibit strong time-varying features that can be modeled by GRU due to its capability to retain temporal information. Even though GRU has achieved better results overall, KANS has outperformed GRU and the other methods across all metrics, demonstrating its superiority in industrial soft sensing. The fundamental difference between our proposed KANS versus the others lies in the incorporation of graph to accurately characterize the relationships between sensor nodes, thus facilitating a better soft sensing performance. Fig. 3 shows the plots of the predicted key variables. The results show that the predictions of KANS follows the ground truth more closely as compared to GRU. Moreover, KANS also demonstrates competence in predicting high-frequency sensor measurements, as apparent in variables 5, 8, and 20.\nB. KNOWLEDGE DISCOVERY\nTo further examine the effectiveness of the proposed soft sensor model (KANS) in learning and discovering the relationship between sensor nodes, a visualization of the graph knowledge discovery results are included in this section to outline interpretability over the correlations between process variables. In particular, the heatmaps between different sensors are obtained from Pearson's correlations of data, embedding, and attention matrices extracted from the model. All the correlations and attention matrices are obtained from the test datasets, which are then visualized as heatmaps in Fig. 4, with respect to each experiment setting in Table II. The darker area (1) and brighter area (-1) represent a stronger spatial correlation between pairwise process variables. Meanwhile, the grey area (0) represents weaker spatial interaction between the corresponding sensors.\nIn most modern industrial settings, the relationship between the dynamic process variables constantly varies. This dynamic variability poses challenges to the existing knowledge-based soft sensor models, which are restricted to using stationary spatial correlation that does not reflect the actual real-world situations, which could deteriorate the resulting soft sensor performance. Meanwhile, the learned embedding offers the advantage of leveraging high dimensional rich graph representation that often encapsulates intricate relationships that may not be able to be captured by non-graph methods. The first and second rows of Fig. 4 visualize the comparison between sensors and between embedding via heatmaps, respectively. It can be observed that the heatmaps reveals distinct clustered patterns within the embedding correlation matrix, some of which resemble the ones in the data correlation matrix. For example, in first experiment setting (variable 5 in Table II), the group of flow rate variables, FT104, FT407, and FT305, form a dense cluster (represented by dark region). Furthermore, it also shows a consistent correlations in both embedding and data, particularly across the group of sensors located along the air supply lines, which are PT312, PT401, PT408, FT305, FT407 and VC302. These clustering patterns have also appeared across other experiments in both the data and embedding matrix, thus demonstrating the capability of our proposed KANS model in accurately capturing the underlying knowledge of the process mechanism.\nApart from that, the last row of Fig. 4 presents the attention matrix that is derived from the adjacency matrix. The attention matrix offers interpretability by showing which process variables are related to one another. Moreover, the attention weights further indicate the importance of each sensor to the final soft sensor prediction; a higher attention weight corresponds to a larger soft sensing output contribution. For instance, the variable 5 experiment setting learns consistent attention across the pressure, level, flow rate, density, and temperature of the 2-phase separator group. Furthermore, PT401 and PT408 show a higher (darker) attention weight, indicating that pressure is an important parameter for the operation of the 2-phase separator."}, {"title": "V. CONCLUSIONS", "content": "In this paper, we proposed the KANS framework to learn the spatiotemporal relationship underlying a complex multivariate industrial process for soft sensing. Our experiments show that KANS can effectively capture underlying patterns of high dimensional data and discover closely related sensors in a multivariate industrial process without any domain knowledge. Furthermore, KANS has outperformed the state-of-the-art in soft sensing performance. In addition, we conducted a knowledge discovery analysis to provide insights into the interaction between the learned node and edge representation for soft sensor prediction. Results show that KANS can harvest different underlying relationships for predicting different process variables. For future work, we suggest using hypergraphs in soft sensing to achieve improved model generalization."}]}