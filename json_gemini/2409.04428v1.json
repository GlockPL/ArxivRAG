{"title": "Hybrid Spiking Neural Networks for Low-Power Intra-Cortical Brain-Machine Interfaces", "authors": ["Alexandru Vasilache", "Jann Krausse", "Klaus Knobloch", "Juergen Becker"], "abstract": "Intra-cortical brain-machine interfaces (iBMIs) have the potential to dramatically improve the lives of people with paraplegia by restoring their ability to perform daily activities. However, current iBMIs suffer from scalability and mobility limitations due to bulky hardware and wiring. Wireless iBMIs offer a solution but are constrained by a limited data rate. To overcome this challenge, we are investigating hybrid spiking neural networks for embedded neural decoding in wireless iBMIs. The networks consist of a temporal convolution-based compression followed by recurrent processing and a final interpolation back to the original sequence length. As recurrent units, we explore gated recurrent units (GRUs), leaky integrate-and-fire (LIF) neurons, and a combination of both spiking GRUs (sGRUs) and analyze their differences in terms of accuracy, footprint, and activation sparsity. To that end, we train decoders on the \"Nonhuman Primate Reaching with Multichannel Sensorimotor Cortex Electrophysiology\" dataset and evaluate it using the NeuroBench framework, targeting both tracks of the IEEE BioCAS Grand Challenge on Neural Decoding. Our approach achieves high accuracy in predicting velocities of primate reaching movements from multichannel primary motor cortex recordings while maintaining a low number of synaptic operations, surpassing the current baseline models in the NeuroBench framework. This work highlights the potential of hybrid neural networks to facilitate wireless iBMIS with high decoding precision and a substantial increase in the number of monitored neurons, paving the way toward more advanced neuroprosthetic technologies.", "sections": [{"title": "I. INTRODUCTION", "content": "Tens of millions of lives worldwide are suffering from paralysis [1], [2]. Those affected experience an impaired ability to direct their movements, which, in severe cases, leads to a complete loss of motor control. This motivates the development of technology that can decode patients' brain activity and accordingly control assistive prostheses. Such devices are called brain machine interfaces (BMIs) [3] and have been very successful with restoring motor control [4], sensory information [5], or even emotional responses [4].\nUsually, BMIs are directly placed on the surface of a patient's brain to ensure the maximal quality of the recorded brain signals (iBMIs). However, this raises two problems.\nFirst, implants are connected via bulky wiring to the operating equipment, severely restricting the patient's movement [6]. Second, permanently opening the skull to allow wiring increases the risk of infection [7]. In hopes of mitigating this, research is moving towards wireless iBMIs [6], [8].\nThe Grand Challenge on Neural Decoding for Motor Control of non-Human Primates of IEEE BioCAS 2024 calls for solutions to the scalability issues of such wireless BMIs. Since data rates are limited due to bit-error rates, heat dissipation, and battery lifetime, an optimal solution should handle the trade-off between high-quality neural decoding, data compression, and resource management. As the development of techniques for embedded artificial intelligence progresses, neural networks present promising candidates for wireless low-power neural decoders [9], [10]. Additionally, biologically inspired spiking neural networks (SNNs) benefit from high temporal sparsity, single-bit communication facilitated by spikes, and an intrinsic recurrence due to their statefulness [11]. Consequently, participants of the Grand Challenge on Neural Decoding are tasked with training a neural network on the Primate Reaching dataset [12] for predicting the velocities of cursor movements. The network is then evaluated using the NeuroBench framework to obtain metrics regarding accuracy and resources [13]. Results are judged based on two challenge tracks: track 1 assesses sole accuracy optimization, while track 2 targets the co-optimization of accuracy, memory footprint, and number of compute operations, as defined in [13].\nOur work presents a hybrid network architecture of temporal convolutions in combination with recurrent processing and a subsequent interpolation back to the original sequence length. While GRUs are very effective in sequence modeling [14], networks based on spiking neurons like the LIF model profit from the advantages of SNNs regarding resourcefulness mentioned above [15]. Hence, we investigate recurrent processing by GRUs, LIF units, and a combination of both and discuss the differences in their results.\nFurthermore, we motivate the chosen architecture via a few experiments before presenting the results of all three types of recurrence. All three network types beat the baselines given by [13] in at least one of the challenge tracks by a good margin. However, the different recurrence types show evident differences in accuracy and resourcefulness. Based on that, we will discuss the implications of using spiking elements. Finally, we point out the possibilities of the real-time deployment of these networks and areas of future work."}, {"title": "II. RELATED WORK", "content": "The authors of [16] used SNNs to predict a rhesus monkey's arm velocity accurately. However, the network was not trained directly on the data. Instead, they mapped a Kalman filter onto the network.\nIn [17], the authors train SNNs on two datasets for offline finger velocity decodings. They achieve high accuracy and compare their approach to the artificial neural networks (ANNs) baseline, even specifying numbers for total operations and memory accesses. Still, their network represents a simple feed-forward architecture and is trained on a different dataset than this work.\nThe clear baseline for this work is given by [13]. Among other datasets, the authors make the dataset of [12] available for deep learning approaches and subsequently train neural networks as baselines. They differentiate between ANNs and SNNs as well as between networks that target pure reconstruction accuracy (track 1) and those that co-optimize accuracy and resource demands (track 2). The used networks are of relatively simple architecture. Their work aims to enable others to benchmark respective datasets easily. We will make use of their work and surpass their baseline using a different network architecture in both challenge tracks."}, {"title": "III. METHODS", "content": ""}, {"title": "A. Motivating an Interpolation-based Approach", "content": "Our interpolation approach is inspired by observing primate cursor movements. In the video, a new target appears each time the previous one is reached, prompting a rapid, goal-directed movement toward it. This suggests that the movement can be approximated by discrete, target-locked actions rather than fine-grained continuous adjustments.\nBased on this, we hypothesize that capturing a few keypoints along the velocity trajectory and interpolating between them can effectively approximate the whole movement velocity. We argue that the resulting error is negligible, assuming that the keypoint prediction is of high quality, as the R2 score between the interpolated test set and the original test set is 0.998 with 4-step interpolation, 0.988 with 8-step interpolation and 0.955 with 16-step interpolation."}, {"title": "B. Model Architecture", "content": "The general architecture of the model involves temporal convolutions to reduce the number of time steps in a sequence of neuron recordings from the input size of 1024 to the desired number of keypoints and efficiently extract temporal features. To create sufficient keypoint pairs, convolutional blocks reduce the sequence to a length of number of keypoints + 1. These features are then processed by recurrent units and a fully connected layer to determine output velocities as keypoints. We apply linear interpolation between the determined keypoints to scale the output sequence back to the original sequence length.\nHere, we compare three types of recurrent units for the architecture described above. Those comprise GRU and LIF units, as well as a fusion of both, which we call the sGRU. We define the sGRU as\n$r_t = LIF(W_r x_t + U_r h_{t-1}),$ \n$z_t = LIF(W_z x_t + U_z h_{t-1}),$ \n$\\tilde{h_t} = LIF(W_h x_t + U_h ((1 - r_t) \\odot h_{t-1})),$ \n$h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h_t},$ where $r_t, z_t, \\tilde{h_t}$, and $h_t$ denote reset gate, update gate, candidate hidden state, and hidden state at time t, respectively. $W_r, W_z, W_h, U_r, U_z,$ and $U_h$ are learnable parameters. $x_t$ denotes the input. LIF refers to the implementation of the LIF spiking neuron model presented in [15].\nBased on this general architecture, we present 2 model sizes, targeting track 1 (GRU-t1, sGRU-t1, LIF-t1) and track 2 (GRU-t2, sGRU-t2, LIF-t2) of the Neural Decoding Challenge. The LIF networks additionally use recurrent weights. Track 1 models employ three convolutional blocks with 32 channels, kernel sizes of 3, 6, and 12, and padding sizes of 5, 3, and 6, targeting 8-step interpolation with 127 keypoints. All max pooling layers use a kernel size and stride of 2. The size of the recurrent blocks is 64. Track 2 models use two convolutional blocks with 10 channels and a kernel size of 3, which reduce the"}, {"title": "IV. EXPERIMENTS AND OBSERVATIONS", "content": "To understand the relationship between model size and the R2 score and the tradeoff that comes with it, we trained four networks of different hidden sizes. Due to time limitations, we performed this experiment only for the sGRU model, training only on the indy2016062201 file with fewer data samples.\nAdditionally, we study the influence of the number of keypoints on the R2 score by training four networks with 1025 to 129 keypoints (1-step to 8-step interpolation). Again, we trained the networks only on the indy2016062201 file with fewer data samples. Note that fewer keypoints directly translate to a higher R2 score. This trend was also confirmed for sGRU- and LIF-based networks.\nWe also ran experiments to evaluate the test performances of models trained on all three recordings for each primate. Interestingly, the R2 score decreases when using aggregated data, contrasting the expected increase in generalizability due to a more representative training set. This hints at a possible change or degradation of the signal recording from the intracortical electrodes across time."}, {"title": "V. RESULTS", "content": ""}, {"title": "A. Baseline Comparison", "content": "We present the best results we obtained for GRU-, sGRU-, and LIF-based networks for challenge tracks 1 and 2 in Table III, on the metrics defined in [13]. Comparing our models to those provided by the baselines in [13], we notice a larger footprint due to the increased input buffer size required for an input of size 1024 and the convolutional blocks. However, our models present fewer synaptic operations, judging by the Dense, MACs, and ACs values.\nAll our track 1 models achieve equal or higher R2 scores than the baselines, with GRU-t1 reaching an R2 score that is increased from 0.615 to 0.707 compared to B-ANN3, while using 26% fewer MACs and 34% less Dense operations.\nFor track 2, we compare GRU-t2 with B-ANN2; it has only roughly 13% of the MACs and an increased R2 score (+0.045). SGRU-t2 uses 60% of the ACs, with the same R2 score when compared to B-SNN2 and 8% of the MACs for the same R2 score when compared to B-ANN2. The LIF-t2 model achieves the same R2 score, with roughly the same activation sparsity, while only using 63% of the Dense and 60% of the ACs when compared to B-SNN2."}, {"title": "B. Recurrence Comparison", "content": "By far, the best performance has been achieved by the GRU recurrent unit for both investigated sizes. Furthermore, the GRU also gives the best trade-off between footprint and R2 score. Across both sizes, the lowest number of synaptic operations (Dense and MACs) is achieved by the LIF recurrence, which reaches the highest activation sparsity, as can be visually confirmed in Fig. 3. The sGRU recurrence achieves higher activation sparsity and lower MACs than the GRU for the same number of total synaptic operations and ACs at the cost of a higher footprint and lower R2 score. Compared to the LIF, SGRU consistently displays a slightly higher R2, hinting at improved memory management, compared to solely using LIF neurons."}, {"title": "VI. DISCUSSION", "content": "We hypothesize that the reason for the higher achieved R2 score, given a sufficiently large receptive field (as seen in our models proposed for track 1), may be that the filtering operations performed by the convolutional layers offer better information aggregation across time, compared to the simple summing aggregation used by the baseline model B-SNN3.\nThe proposed models use an input buffer window of 1024 steps provided by the NeuroBench [13] Primate Reaching Dataset, where each step represents 4 ms. This results in a total buffer window and a latency of 4.096 s. The models are executed for non-overlapping windows of size 1024, meaning that the model execution rate is 0.244 Hz.\nOur current approach comes with a high flexibility in the possible latency and execution rate that it can achieve, as both the convolutional and the recurrent layers allow for iterative data processing. Models GRU-t2, sGRU-t2, and LIF-t2 use a kernel size of 3 applied in two convolutional blocks. With the sizes mentioned above, the computation of one keypoint requires an effective buffer window of 10 steps, which offers a latency of 40 ms. This would also reduce the input buffer size from 1024 to 10, reducing the model footprints by a sizable amount. The stride of the receptive field is 4 steps, or 16 ms, which translates to an execution rate of 62.5 Hz. The theoretical upper limit of the latency of our models (40 ms) is well under the time delay between stimulus and voluntary muscle movement reported by the neuroscience literature [18], which is typically greater than 100 ms. Assuming no further latencies arise from signal transmission and ignoring computation time, our approach would be suitable for deployment in the real world, given an appropriate real-time implementation of the networks."}, {"title": "VII. CONCLUSION AND OUTLOOK", "content": "This work targets both tracks of the Grand Challenge on Neural Decoding for Motor Control of non-Human Primates of IEEE BioCAS 2024. This includes track 1, which focuses on maximizing task accuracy, and track 2, which aims at co-optimizing accuracy and resource demand, which is critical for wireless iBMIs. The networks presented in this work surpass the baselines in [13] by good margins for both tracks. For track 1, GRU- and sGRU-based networks beat the baselines by up to 7.4% in terms of R2 while the LIF-based networks perform equal. For track 2, considering the margin of error, all networks are at least equal in R2 but show an improvement in the double-digit percentages in terms of compute operations. Only the footprint is increased by a rough factor of 6. We explain that this difference is due to large data buffers in our current model implementation. This gap could be eliminated in real-world deployment by taking advantage of the iterative nature of convolutional filters and recurrent units. Generally, the GRU-based networks score the highest in both tracks. However, the total amount of operations is the fewest for the LIF-based networks. Our sGRU-based models consistently achieve a higher R2 than solely using LIF-neurons, suggesting that such spiking neuron models could benefit from improved memory management.\nOur work does not yet leverage some SNN-centered methods to improve their resourcefulness. This includes spike regularization, pruning, and event-triggered updating of the neural units, which will be included in future work. Finally, three of the six recordings in the dataset consist of motor cortex and somatosensory cortex recordings. We do not yet distinguish between the two different data types and expect an improved regression if done so.\nOur work enhances the baseline for the primate reaching dataset and demonstrates the potential of using hybrid neural networks for efficient neural decoders. This advances the field of wireless iBMIs to eventually improve the lives of millions of humans suffering from paralysis."}]}