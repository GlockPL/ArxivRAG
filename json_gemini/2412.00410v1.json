{"title": "Federated Progressive Self-Distillation with Logits Calibration for Personalized IIoT Edge Intelligence", "authors": ["Yingchao Wang", "Wenqi Niu"], "abstract": "Personalized Federated Learning (PFL) focuses on tailoring models to individual IIoT clients in federated learning by addressing data heterogeneity and diverse user needs. Although existing studies have proposed effective PFL solutions from various perspectives, they overlook the issue of forgetting both historical personalized knowledge and global generalized knowledge during local training on clients. Therefore, this study proposes a novel PFL method, Federated Progressive Self-Distillation (FedPSD), based on logits calibration and progressive self-distillation. We analyze the impact mechanism of client data distribution characteristics on personalized and global knowledge forgetting. To address the issue of global knowledge forgetting, we propose a logits calibration approach for the local training loss and design a progressive self-distillation strategy to facilitate the gradual inheritance of global knowledge, where the model outputs from the previous epoch serve as virtual teachers to guide the training of subsequent epochs. Moreover, to address personalized knowledge forgetting, we construct calibrated fusion labels by integrating historical personalized model outputs, which are then used as teacher model outputs to guide the initial epoch of local self-distillation, enabling rapid recall of personalized knowledge. Extensive experiments under various data heterogeneity scenarios demonstrate the effectiveness and superiority of the proposed FedPSD method.", "sections": [{"title": "I. INTRODUCTION", "content": "THE Industrial Internet of Things (IIoT) has emerged as a critical enabler for future industries such as intelligent manufacturing, smart transportation, and smart healthcare, where interconnected devices generate and process vast amounts of data at the network edge [1], [2]. To enable real-time distributed intelligent IIoT services and applications while ensuring data security and privacy, edge computing and federated learning (FL) have been extensively employed to support Artificial Intelligence (AI) driven IIoT applications [3]\u2013[5]. Edge computing, on the one hand, brings computational resources closer to the data source, enabling localized data processing that reduces latency and improves response times in critical IIoT tasks, such as predictive maintenance and quality inspection. On the other hand, FL enables collaborative model training across distributed edge clients without the need to share raw data. Instead, only model updates are exchanged between devices and central servers, ensuring that sensitive data remains localized and secure.\nHowever, traditional FL algorithms struggle to maintain robust performance in highly heterogeneous IIoT edge environments and lack personalized solutions tailored to each edge node's unique data characteristics. A fundamental issue lies in the Non-Independent and Identically Distributed (Non-IID) nature of data across different IIoT edge clients. In real-world IIoT systems, each edge device collects data influenced by its unique operational context, sensor types, geographic location, and usage patterns, resulting in significant variations in data distributions across clients. In such scenarios, the local models on each edge client tend to adapt to their specific data distributions during the FL process, leading to inconsistent parameter update directions during global model aggregation. This inconsistency negatively impacts the convergence and accuracy of the global model, potentially preventing the global model from effectively generalizing to the data of any particular client.\nTherefore, most existing FL studies [6] aim to address the performance issues of the global model under Non-IID datasets, thereby enhancing the performance on local data. For example, FedProx [6] introduced a regularization term in the local sub-optimization problem of FedAvg to limit the parameter distance between the local model and the global model in the parameter space. Although the performance of the global model has been effectively improved, significant differences in resource conditions, data distributions, and task objectives across clients make it challenging for a single global model to fully meet the specific needs of each IIoT client, leading to suboptimal performance in personalized IIoT tasks. This limitation may result in certain IIoT clients benefiting only marginally from FL; in some cases, the global model's performance may even be inferior to that of their locally trained models. This could reduce these IIoT clients' motivation to participate FL, ultimately affecting the overall effectiveness and scalability of FL in real-world IIoT deployments.\nTo address this issue, recent Personalized Federated Learning (PFL) [7] approaches have been introduced to develop personalized models specifically tailored to each client directly. From the perspective of knowledge transfer, the key to PFL is to achieve the effective integration and balance of global knowledge and local personalized knowledge, where the global knowledge comes from the global model in the aggregation and the local personalized knowledge comes from the local training [8]. Some studies [9]\u2013[12] have recognized the importance of preventing global knowledge forgetting during local client training. For example, FedNTD [9], FedSSD [11], FedLMD [10] and FedGKD [12] implemented knowledge distillation (KD) [13] technique on the local client to preserve the global perspective by distilling knowledge from the global model. However, retaining global models and performing distillation incurs non-negligible additional computational and storage overhead, which poses a significant burden for resource-constrained IIoT edge clients. On the other hand, the global model lacks sufficient confidence in the local data, which may potentially introduce erroneous knowledge into the local updates.\nMoreover, these studies ignore the phenomenon of local personalized knowledge forgetting [8], [11], [14]\u2013[16], which primarily arises from the tendency of the client's personalized parameters to be overshadowed or diminished by the \u201caveraging\" effect of the global model. Especially in real IIoT FL environments, edge clients may be unable to participate in every training round regularly due to unstable network connections, limited device resources, and strict local privacy policies. This non-uniform participation of clients can exacerbate the issue of local personalized knowledge forgetting. For example, when client k has been absent from training for an extended period, the global model is more likely to diverge significantly from client k's personalized characteristics. Although local training can relearn personalized knowledge, the absence of historical personalized knowledge not only slows down the convergence of the local model but also hinders the model from gaining diverse insights into local data across different historical training stages. This, in turn, affects the model's ability to effectively personalize.\nTo simultaneously mitigate the forgetting of global knowledge and historical personalized knowledge during local training on resource-constrained IIoT clients, we propose a novel PFL framework Federated Progressive Self-Distillation (FedPSD) that incorporates time-dimensional self-distillation and knowledge calibration techniques. Specifically, to address the issue of global knowledge forgetting, on one hand, FedPSD dynamically calibrates the output logits during local training based on the data distribution of each IIoT client, mitigating the loss of global knowledge. On the other hand, FedPSD employs a progressive self-distillation strategy, where the model output from the previous epoch serves as a virtual teacher to guide the training of the next epoch, facilitating the gradual inheritance of global knowledge. Additionally, to tackle the problem of personalized knowledge forgetting, FedPSD constructs soft labels that integrate outputs from historical personalized models. These soft labels are used to guide the self-distillation process in the initial epoch, enabling rapid recall of personalized knowledge. Extensive experiments demonstrate that FedPSD significantly improves model personalization and overall performance without significantly increasing storage and computational overhead.\nThe main contributions of this study can be summarized as follows.\n\u2022\tWe theoretically demonstrate that the alternating process of aggregation and local training in FL leads to continual forgetting of both global and personalized knowledge.\n\u2022\tWe propose a novel progressive self-distillation mechanism and a dynamic logits calibration technique in PFL to address the global knowledge forgetting challenge posed by Non-IID data in IIoT edge environments.\n\u2022\tWe introduce calibrated fusion soft labels that incorporate clients' historical personalized knowledge to guide the self-distillation process of local models, enabling a rapid review of the historical personalized knowledge.\nThe rest of this paper is organized as follows. Related studies are reviewed in Section II. Section III presents the knowledge-forgetting issues and motivation of this study. Section IV demonstrates the details of FedPSD. Section V shows the experiments in different Non-IID settings on MNIST, CIFAR-10, and CIFAR-100 datasets. Section VI delves into the discussion. Finally, this paper is concluded in Section VII."}, {"title": "II. RELATED WORK", "content": "In PFL, some studies have been devoted to addressing the problem of FL under data heterogeneity from the perspective of knowledge forgetting. Shoham et al. [17] considered knowledge forgetting in FL by analogy with the catastrophic forgetting of lifelong learning and related multi-task learning, and introduced a penalty term to the loss function to avoid forgetting previously learned knowledge. Xu et al. [18] reported the forgetting issue in local clients by empirically showing the increasing loss of previously learned data after the local training and alleviated knowledge forgetting by regularizing locally trained parameters with the loss on generated pseudo data. Unlike these studies, this study primarily employs KD and knowledge calibration techniques to mitigate the problem of forgetting.\nRecent studies [9]\u2013[12], [14]\u2013[16] introduced the KD technique into local training to address forgetting, which is relevant to our research. FedNTD [9] introduced not-true distillation from the global model to prevent clients from forgetting global knowledge. Similarly, FedLMD [10] focused more on preserving minority label knowledge corresponding to the forgetting of each client. FedSSD [11] applied mean squared error to build a distillation loss between the global model and the local model during local training, aiming to minimize the discrepancy between them. FedGKD [12] averaged the global models cached on the server to create a historical global model, which is then used as a teacher model to guide the training of the client model. However, these studies aim to prevent the forgetting of global knowledge but do not take into account the forgetting of personalized knowledge.\nA few studies focus on the problem of personalized knowledge forgetting [14]\u2013[16]. Huang et al. [14] employed KD in local updates, where the distillation process between updated and pre-trained local models provides both inter- and intra-domain knowledge. However, pre-training personalized local models and performing distillation incurs non-negligible additional computational and storage overhead, which poses a significant burden for resource-constrained IIoT edge clients. pFedSD [15] enables clients to distill the knowledge from previous personalized models into the current local models, thereby accelerating the recovery of personalized knowledge for newly initialized clients. Similarly, DKD-pFed [16] introduced the method of decoupled KD [19] to distill the personalized model of the previous round. However, these studies are not concerned with the forgetting of global knowledge. In addition, Yao et al. [8] sought to preserve both global knowledge and local personalized knowledge simultaneously. After local training, an adaptive knowledge matrix is used to fuse knowledge from local, global, and historical models. The fused knowledge is then distilled into the local model. Although the purpose is the same, this study adopted the method of time dimensional progressive self-distillation and knowledge calibration.\nOverall, existing studies primarily focus on the issues of global knowledge forgetting and local knowledge forgetting as separate research areas. They mainly employ KD for knowledge extraction and retention but fail to adequately address the integration and preservation of both types of knowledge. Furthermore, most studies require the retention of teacher models, such as global models or previous local models, which imposes additional storage and computational burdens on resource-constrained IIoT edge devices. Lastly, in terms of KD specifics, the aforementioned studies adopt relatively traditional frameworks, where either the global model or the historical personalized model serves as the teacher to guide training across all local epochs. However, the global model lacks personalized knowledge, and the historical personalized model may not have fully converged, resulting in insufficient confidence on local data and the potential introduction of erroneous knowledge into the local update. Therefore, there is an urgent need to explore a new PFL method that achieves a balanced integration of global and personalized knowledge."}, {"title": "III. MOTIVATION AND THEORETICAL ANALYSIS", "content": "A. Historical Personalized Knowledge Forgetting\n1) Global model aggregation results in the erosion of historical personalized knowledge within local models: The local model $w_k$ of the client $k$ is trained using its local dataset $D_k$, allowing $w_k$ to effectively capture the personalized characteristics of the local data, such as specific feature distributions and class biases. However, during global model aggregation (e.g., FedAvg), the personalized parameters of each client model may be overshadowed or diluted due to the weighted averaging process. Assuming that the parameters of each local model $w_k$ can be decoupled into global parameters $w_{global}$ and local personalized parameters $w_{local,k}$ [20], [21], the parameters of client $k$'s local model can be expressed as $w_k = w_{global} + w_{local,k}$. After global model aggregation, the new global model parameters are computed as $w_{global}^{t+1} = \\sum_{k=1}^{K} \\frac{n_k}{n} (w_{global}^t + w_{local,k}^t)$ which can be further decomposed into $w_{global}^{t+1} = w_{lobal}^t + \\sum_{k=1}^{K} \\frac{n_k}{n} w_{local,k}^t$, where $n_k$ denotes the number of samples on client $k$ and $n = \\sum_{k=1}^{K} n_k$ represents the total number of data samples across all $K$ clients. Since $w_{local,k}$ is closely related to the local data distribution of client $k$, the personalized parameters $w_{local,k}^t$ often vary significantly across clients. During the averaging process in global aggregation, these differences are weakened or canceled out, resulting in the loss of local personalized knowledge in the global model. Furthermore, as the number of aggregation rounds increases, the problem of forgetting historical personalized knowledge becomes more pronounced, with the global model gradually losing the knowledge it learned from earlier local data.\n2) The non-uniform participation of clients exacerbates the issue of historical personalized knowledge forgetting: In real-world distributed federated learning environments, client devices may be unable to participate in every training round due to factors such as unstable network connections, limited device resources, or strict local privacy policies. Additionally, the server typically does not sample all clients in each training round but instead randomly selects a subset of clients for model updates. This non-uniform participation of clients can exacerbate the problem of local personalized knowledge forgetting. For example, when client $k$ has not participated in training for an extended period, the global model may drift further away from capturing the personalized characteristics of client $k$. As a result, when the client re-joins training, it must conduct additional local training to minimize the loss function $L_k(w_k)$ and recover its previously learned personalized knowledge.\nB. Local Personalization-Induced Global Generalization Knowledge Forgetting\nGlobal generalization knowledge refers to the features and patterns learned by the model from the global dataset that possess universality and generalizability. These features enable the model to make accurate predictions on data from different clients. However, as discussed in the previous section, in federated learning, each client starts training from the global model $w^t$ in each new training round and performs local training on their data, which can be expressed as $w_k^{t+1} = w^t \u2013 \\eta \\nabla L_k(w^t; D_k)$, where $\\nabla L_k(w^t; D_k)$ is the gradient of the loss function, reflecting the features and patterns of the client's data $D_k$. If the client's data $D_k$ differs significantly from the global dataset $D$, the gradient direction may deviate substantially from the global optimal gradient direction $\\nabla L(w^t; D)$. This gradient direction bias causes the client model to gradually optimize in a direction different from the global model during local updates. As the number of local training rounds increases, this bias accumulates, causing the client model to drift further away and potentially converge to a local minimum that better fits its local data distribution. This process leads to the forgetting of the generalizable features learned by the global model, akin to the \"catastrophic forgetting\" issue in continual learning [22].\nOverall, based on the theoretical analysis above, this study posits that achieving a balance between global knowledge and local personalized knowledge on the client side is critical for improving the convergence speed and accuracy of local personalized models."}, {"title": "IV. METHODOLOGY", "content": "A. Federated Progressive Self-Distillation Framework\nAs illustrated in Figure 1, the modifications introduced by the FedPSD algorithm are concentrated on the client side. During each communication round, FedPSD retains the output of the locally trained personalized model on client $k$ to guide self-distillation training in the subsequent round. Specifically, in communication round t, when client k is selected to participate in training, the global model $w^t$ provided by the server is used to initialize the local model. During the local self-distillation process, FedPSD assumes that the local model $w_k^{t,e}$ at the $e$-th training epoch serves as the teacher model for the subsequent (e + 1)-th epoch, where $w_k^{t,(e+1)}$ is the student model. The output of $w_k^{t,e}$ is fused with the ground truth labels to create smoother and more confident soft labels, which are then used to guide the training of the student model. Notably, for the initial epoch of student model training (e = 1), FedPSD uses a fusion of the ground truth labels and the historical personalized knowledge to construct the teacher's soft labels. This ensures the retention and recall of personalized knowledge during the initial training stage. Additionally, FedPSD employs calibrated logits to construct the local cross-entropy loss $\\mathcal{L}_{CE}^{k,t}$.\nB. Progressive Self-Distillation Loss\n1) Reviewing Historical Personalized Knowledge: To address the problem of forgetting historical personalized knowledge, this study preserves the output soft labels of the historical personalized model on client $k$ to guide the initial epoch training of the current round's local model. This mechanism enables the local model to quickly recall its prior personalized knowledge. However, since the historical personalized model may not have fully converged, its output might contain erroneous knowledge. To mitigate this, the historical model's output is calibrated using the ground truth labels. Specifically, assuming that in the (t - 1)-th communication round of federated learning, the output probability vector of client k's personalized model after local training is $\\overline{P}_k^{t-1}$, and the corresponding ground truth label is $Y_k$, the calibrated fused label $\\overline{H}_k^{t-1}$ is defined as follows:\n$\\overline{H}_k^{t-1} = \\alpha \\overline{P}_k^{t-1} + (1 - \\alpha) Y_k$,\nwhere $\\alpha \\in [0, 1]$ is an adaptively adjusted weight. In the early stages of federated learning, the performance of the local client model tends to fluctuate due to insufficient convergence, necessitating a higher weight for the ground truth label $Y_k$. As communication rounds progress and the historical model converges, greater weight should be assigned to the historical model's output $\\overline{P}_k^{t-1}$. Thus, $\\alpha \\in [0, 1]$ should progressively increase with the number of communication rounds. A linear growth strategy is adopted in this study, with the calculation given by:\n$\\alpha = \\frac{t}{t_{total}}$,\nwhere $t$ represents the current communication round, and $t_{total}$ denotes the total number of communication rounds.\n2) Progressive Fusion of Personalized Knowledge and Global Knowledge: To mitigate the issue of global knowledge forgetting during local training, this study introduces a progressive self-distillation strategy along the temporal dimension. This approach leverages the output knowledge of the model from the previous epoch to guide the training of the model in the subsequent epoch, thereby achieving a gradual integration of local personalized knowledge and global knowledge. However, since the local model may not have converged and lacks sufficient personalized knowledge at this stage, its output confidence is relatively low. Solely relying on the output of $w_k^{t,e}$ to guide the training of $w_k^{t,(e+1)}$ could result in the latter learning erroneous or ambiguous knowledge. To address this, as in the previous section, the output knowledge of the model from the previous epoch is calibrated using ground truth labels.\nSpecifically, assuming that in communication round t, the predicted probability of client k's model updated during the (e - 1)-th epoch is $P_k^{t,e-1}$, and the ground truth label is $Y_k$, the calibrated fused label $H_k^{t,e-1}$ is computed as follows.\n$H_k^{t,e-1} = P_k^{t,e-1} + (1 - \\alpha) Y_k$\nOverall, the distillation loss for the e-th Epoch in the progressive self-distillation process is formulated as:\n$\\mathcal{L}_{KD}^k = KL(H_k^{t,e-1}|| P_k^{t,e})$,\nwhere $KL(\\cdot||\\cdot)$ represents the Kullback-Leibler divergence, which measures the difference between two probability distributions. For e = 1, $H_k^{t,e-1} = \\overline{H}_k^{t-1}$.\nC. Logits Calibration-Based Local Cross-Entropy Loss\nIn federated learning, during the local training of client k, the presence of non-independent and identically distributed (Non-IID) data often leads to bias in the local cross-entropy loss. Specifically, for client k, assume its data distribution is $P(x, y) = P(x | y) P(y)$. Given an input $x$, the predicted label by the model is $\\hat{y} = \\arg \\max_y f_y(x)$, where $f_y(x)$ represents the model's logits for class $y$. During local training, softmax cross-entropy is typically used as the loss function to maximize the conditional probability $P(y | x)$, indirectly minimizing the classification error rate $P_{x,y}(y \\neq \\hat{y})$. By Bayes' theorem, $P(y | x) \\propto P(x | y) P(y)$, which indicates that the conditional probability $P(y | x)$ is jointly determined by the class-conditional distribution $P(x | y)$ and the class prior $P(y)$.\nHowever, in Non-IID environments, the class distributions across clients exhibit significant heterogeneity, typically reflected as skewed class priors $P(y)$. Under such circumstances, training the model directly by maximizing $P(y | x)$, although it minimizes the overall classification error $P_{x,y}(y \\neq \\hat{y})$, causes the model to favor locally frequent classes, often at the expense of accuracy on infrequent local classes. Thus, minimizing the overall error alone is insufficient to ensure fair classification performance across all classes in imbalanced class distributions. To address this issue, the class probabilities can be calibrated during inference to achieve a balanced form: $P_{Bal}(y | x) \\propto \\frac{P(x | y)}{L}$, where $L$ is the total number of classes, and $\\frac{1}{L}$ represents a uniform prior distribution over all classes. This calibration effectively eliminates the influence of the class prior $P(y)$, enabling the test results to approximate an estimation of $P(x | y)$. The calibrated conditional probability $P_{Bal}(y | x)$ can be expressed as: $P_{Bal}(y | x) = \\frac{P(x | y)}{P(y)L}$. Therefore, the optimization objective based on the balanced probabilities is defined as minimizing the balanced classification error, which is as follows.\n$\\arg \\max_{y \\in L} P_{Bal}(y | x) = \\arg \\max_{y \\in L} \\frac{P(x | y)}{P(y)}$\nFor softmax cross-entropy, where the class probability $P(y | x) \\propto e^{f_y(x)}$, substituting into the Eq. 5 yields:\n$\\arg \\max_{y \\in L} P_{Bal}(y | x) = \\arg \\max_{y \\in L} (f_y(x) - ln P(y))$.\nAs shown in Equation 6, subtracting the logarithm of the class prior from the logits $f_y(x)$ will effectively adjust for the influence of $P(y)$ during inference.\nTherefore, this study calibrates the output probabilities during the training process of the client k in Non-IID environments to indirectly achieve an inference optimization objective equivalent to $\\arg \\max_{y \\in L} (f_y(x) - ln P(y))$. Specifically, the local training cross-entropy loss is modified by adding the logarithm of the class prior weight $ln P(y)$ to the logits $f_y(x)$, guiding the model to prioritize optimization for locally frequent classes. The calibrated output class probability is defined as follows.\n$P_{calibrated}(y | x) = \\frac{P(y)e^{f_y(x)}}{\\sum_{y' \\in L} P(y')e^{f_{y'}(x)}}$\nwhere $P(y)$ denotes the prior distribution of class $y$ in the local client's data. Based on this calibrated probability, the calibrated local cross-entropy loss function is defined as follows.\n$\\mathcal{L}_{CE}(f(x), y) = -log \\frac{P(y)e^{f_y(x)}}{\\sum_{y' \\in L} P(y')e^{f_{y'}(x)}}$.\nIn summary, the loss function for the local training process of client k is defined as follows.\n$\\mathcal{L}_{local} = \\mathcal{L}_{CE} + \\mathcal{L}_{KD}$,\nwhere $\\mathcal{L}_{CE}$ represents the calibrated cross-entropy loss, and $\\mathcal{L}_{KD}$ denotes the knowledge distillation loss."}, {"title": "V. EXPERIMENTS AND DISCUSSION", "content": "A. Datasets and Data Partition\n1) Datasets: To ensure a fair comparison, we selected three of the most commonly used datasets in the field of federated learning: MNIST [23], CIFAR-10, and CIFAR-100 [24].\n2) Data Partition: To simulate Non-IID data scenarios, we adopted two different data partitioning strategies: pathological sharding [25] and Latent Dirichlet Allocation (LDA) [26].\nSharding: The pathological sharding strategy achieves non-IID data distribution by slicing the data based on labels, where each slice is referred to as a shard. The dataset is divided into multiple shards, which are then allocated to different clients. The degree of data heterogeneity is determined by the number of shards owned by each client, corresponding to the number of categories each client has. Specifically, suppose the dataset contains M training samples. We define the number of shards as S and divide the dataset into $S \\times K$ groups, where K is the number of clients, and each group contains $M/(S \\times K)$ samples. Each client then randomly selects S groups as its local dataset. This strategy considers only statistical heterogeneity, as all clients have datasets of equal size, and there is no overlap in data samples across different clients. In this study, for the MNIST dataset, we set S = 2; for the CIFAR-10 dataset, we set S = 2,3,5, 10; and for the CIFAR-100 dataset, we set S = 10.\nLDA: The LDA strategy simulates the heterogeneity of client data distributions by modeling them based on a Dirichlet distribution. Using the Dirichlet distribution's concentration parameter $\\alpha$, training samples of different categories are assigned to each client in varying proportions to achieve non-IID distributions. The parameter $\\alpha$ determines the degree of heterogeneity in the data distribution: as $\\alpha$ increases, the heterogeneity decreases. Given a parameter $\\alpha$, we sample each client's data distribution from Dir($\\alpha$), which specifies the proportion of each category in the client's dataset. Based on these sampled proportions, data samples are randomly assigned to clients. Under this strategy, the size and category distribution of each client's dataset varies, potentially including majority classes, minority classes, or even missing classes, which better reflect real-world scenarios. In this study, for the MNIST dataset, we set $\\alpha$ = 0.1; for the CIFAR-10 dataset, $\\alpha$ = {0.05, 0.1, 0.3,0.5}; and for the CIFAR-100 dataset, $\\alpha$ = 0.1.\nB. Baseline Methods\nWe compared the proposed method with a range of widely recognized mainstream federated learning algorithms, including FedAvg [25], FedProx [6], FedCurv [17], FedNova [27], SCAFFOLD [28], MOON [26], FedNTD [9], and FedLMD [10], each of which has made significant contributions to the field of federated learning.\nC. Implementation Details\nTo ensure a fair comparison, we followed the experimental settings outlined in prior studies [6], [25] and fixed the training seed to maintain consistency in client selection and ensure the reproducibility of experiments. In all experiments, we employed a unified network architecture, SimpleCNN, consisting of two convolutional layers and two fully connected layers. In subsequent sections, we will discuss the performance of our method under different network architectures.\nSpecifically, we set N = 100 total clients, with each client performing 5 local training epochs per communication round. The total number of communication rounds was set to 200, and in each round, 10% of the clients (i.e., 10 clients) were randomly selected for training. For each client, training was conducted using the cross-entropy loss function and the SGD optimizer. The learning rate was set to 0.01 and decayed by a factor of 0.99 after each communication round. Weight decay was set to 1 \u00d7 10\u22125, and the momentum for SGD was set to 0.9. The batch size was fixed at 50. In addition, we employed techniques such as random cropping, random horizontal flipping, and normalization for data augmentation, consistent with previous studies.\nD. Evaluation metrics\nTo ensure reproducibility, the reported results are averaged over three independent runs with different random seeds. The performance of the algorithms is evaluated using two metrics: (1) the Top-1 test accuracy of the globally aggregated model on the server and (2) the average Top-1 test accuracy across all local clients which is defined as follows.\n$A_l = \\frac{1}{K} \\sum_{i=1}^{K} A_i$,\nwhere, K denotes the total number of clients involved in the training process, and $A_i^T$ represents the test Top-1 accuracy of the client $i$ at communication round $T$ (before aggregation) on its local test dataset. Unless otherwise specified, the client accuracy mentioned in this paper refers to the average test accuracy of the clients. Correspondingly, the server accuracy denotes the test accuracy of the globally aggregated server-side model.\nE. Experimental Results\n1) Accuracy: We conducted a comprehensive evaluation of the proposed method and compared it with several mainstream approaches. As shown in Tables I-III, the experimental results demonstrate that the proposed method outperforms the baseline methods in terms of Top-1 accuracy on both client and server sides across multiple datasets, thereby validating its effectiveness. Specifically, the proposed method exhibits superior performance in both the average model accuracy on clients and the global model accuracy on the server. For the average model accuracy on clients, our method achieves a 32.1% improvement on average compared to baseline methods and a 9.6% improvement over the state-of-the-art (SOTA) methods when using the pathological sharding strategy to partition the CIFAR-10 dataset. Notably, under the dataset partitioning strategy with S = 2, our method achieves a maximum improvement of 39.8%. Significant improvements were also observed on the MNIST and CIFAR-100 datasets. When using the Latent Dirichlet Allocation (LDA) strategy to partition the CIFAR-10 dataset, our method similarly demonstrated outstanding performance, achieving an average improvement of 24% over baseline methods and 8.7% over SOTA methods. Even under extremely imbalanced scenarios, such as when $\\alpha$ = 0.05, the proposed method provides effective enhancements. Additionally, significant improvements were observed on the MNIST and CIFAR-100 datasets. These comparative results highlight the effectiveness of our strategy.\nIn addition, as shown in Table III, for the global model Top-1 accuracy on the server, our method also demonstrated excellent performance. When applied to the CIFAR-10 dataset with various data partitioning strategies, it achieved an average accuracy improvement of 11.68% over baseline methods. On the CIFAR-100 dataset, the proposed method similarly achieved significant improvements, surpassing current SOTA methods. These findings indicate that our method is effective in preserving local client knowledge.\n2) Communication Efficiency: We also place particular emphasis on the execution efficiency of federated learning algorithms, a critical factor for resource-constrained real-world applications. To evaluate efficiency, we compare the number of communication rounds required by different methods to achieve the same final accuracy as FedAvg. Figure 3 illustrates the variation in client and server accuracy after each communication round across different methods. Tables IV and V provide detailed statistics on the number of communication rounds required by each method to reach the final accuracy of FedAvg.\nThe results demonstrate that our proposed method is highly competitive in terms of convergence speed and accuracy compared to other approaches. On average, our method requires only 45 communication rounds for local clients to reach the accuracy of FedAvg after 200 rounds. Similarly, at the server level, our method achieves the same accuracy in just 52 communication rounds on average. Specifically, on the CIFAR-10 dataset with various partitioning strategies, our method excels in the Sharding strategy with S = 2, requiring only 10 communication rounds to match FedAvg's 200-round accuracy for local clients. Additionally, under the LDA strategy with $\\alpha$ = 0.05, our method demonstrates outstanding performance, achieving FedAvg's 200-round accuracy in just 46 communication rounds.\nThese comparative results highlight the significant advantage of our approach in reducing communication requirements. Furthermore, as data heterogeneity increases, our method exhibits a more pronounced advantage in balancing communication efficiency and accuracy. This indicates its robustness and adaptability to varying levels of data heterogeneity, further underscoring its effectiveness in addressing the challenges of non-uniform data distributions."}, {"title": "VI. ANALYSIS AND DISCUSSION", "content": "To comprehensively understand and validate the effectiveness of our proposed method, this section first evaluates the importance and contribution of each component through ablation studies. Subsequently, we examine the performance of the method under various network architectures, different numbers of local training epochs, and varying client participation rates. Unless otherwise specified, all experimental settings are consistent with those described in the previous section.\nA. Ablation Study\nBy evaluating each component individually, we clarified their roles and contributions in addressing the issue of knowledge forgetting. The experiments were conducted using the CIFAR-10 dataset with two distinct data partitioning strategies to comprehensively assess the effects of the components. Specifically, we performed ablation studies on the strategy of Reviewing Historical Personalized Knowledge (RHPK), Progressive Self-Distillation (PSD), and Calibrated Logit-based Loss (CLL).\nAs shown in Table VI, the results demonstrate that employing the GSD component alone significantly improves the average accuracy of local models. Compared to the baseline, it achieves improvements of 16.88% and 8.45% under the two different partitioning strategies, respectively. Introducing the PSD component further enhances the average accuracy, with additional gains of 10.91% and 4.04%, respectively, over the baseline. This indicates that revisiting historical personalized knowledge effectively mitigates knowledge forgetting in local clients. Finally, incorporating the RELogits component leads to further performance gains of 12.38% and 18.86%, respectively. This demonstrates that adjusting the weight of different classes based on the local dataset distribution alleviates the problem of local models excessively fitting their own datasets while neglecting the collaborative benefits and knowledge sharing provided by the global model. In addition, when all three components are employed together, both the average accuracy of the local models and the accuracy of the global model are further enhanced, confirming the effectiveness of our method in addressing the challenge of local knowledge forgetting.\nB. Impact of Different Network Architectures\nWe evaluated the applicability of the proposed method across various network architectures. Using the CIFAR-10 dataset, we conducted additional experiments comparing the performance of two representative architectures, MobileNet and ResNet. The results are detailed in Table VII. Experimental findings demonstrate that our method consistently achieves stable performance and significant improvements across multiple network architectures. These results highlight the method's applicability and robustness in real-world federated learning scenarios involving diverse backbone architectures.\nC. Impact of Local Training Epochs\nWe examined the impact of varying the number of local training epochs per communication round on model accuracy. In addition to the fixed configuration of Epoch = 5, we evaluated scenarios with Epoch = 1,3,10, and 20. The experimental results, presented in Figure 4, demonstrate that the proposed method consistently delivers stable and substantial performance improvements across all configurations. Notably, as Epoch increases, methods such as FedNTD exhibit a decline"}]}