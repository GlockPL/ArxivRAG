{"title": "Detecting anxiety and depression in dialogues: a multi-label and explainable approach", "authors": ["Francisco de Arriba-P\u00e9rez", "Silvia Garc\u00eda-M\u00e9ndez"], "abstract": "Anxiety and depression are the most common mental health issues worldwide, affecting a non-negligible part of the population. Accordingly, stakeholders, including governments' health systems, are developing new strategies to promote early detection and prevention from a holistic perspective (i.e., addressing several disorders simultaneously). In this work, an entirely novel system for the multi-label classification of anxiety and depression is proposed. The input data consists of dialogues from user interactions with an assistant chatbot. Another relevant contribution lies in using Large Language Models (LLMS) for feature extraction, provided the complexity and variability of language. The combination of LLMS, given their high capability for language understanding, and Machine Learning (ML) models, provided their contextual knowledge about the classification problem thanks to the labeled data, constitute a promising approach towards mental health assessment. To promote the solution's trustworthiness, reliability, and accountability, explainability descriptions of the model's decision are provided in a graphical dashboard. Experimental results on a real dataset attain 90% accuracy, improving those in the prior literature. The ultimate objective is to contribute in an accessible and scalable way before formal treatment occurs in the healthcare systems.", "sections": [{"title": "1. Introduction", "content": "More than 55 million people in the United States suffer from mental illness as indicated by the National Institutes of Health (NIH, 2023). More in detail, the most common mental conditions are anxiety (19.1%) and major depression (8.3%). At the global level, 4% of the population is affected by anxiety disorder. At the same time, 280 million people worldwide suffer from depression, as stated by the World Health Organization (who, 2023). However, only 25% of people suffering from anxiety receive treatment. A recent report by Forbes completes this information and indicates that 50% of people affected by depression go undiagnosed in the primary care system.\nIn this regard, it should be noted that traditional screening methods (i.e., those that rely on subjective and time-consuming interviews composed of binary questions for patients and their families) face several issues [1]. Among them, the unreliability of self-reported diagnoses due to bias introduced by subjectivity, intentional concealment, and even inconvenience of the number of questions must be considered, resulting in the latter low rates of diagnosis and interventions [2]. Another concern is stigma, which prevents treatment seeking and ignorance of the condition [1]. Representative examples of these self-reporting methodologies are the Beck Depression Inventory (BDI), the General Health Questionnaire (GHQ), the Hamilton Rating Scale for Depression (HRSD), and the Patient Health Questionnaire (PHQ). Similar to the GHQ and the PHQ, the Depression, Anxiety, and Stress Scale (DASS) combines the questionnaires of each factor [3]. Consideration should also be given to the popular Diagnostic and Statistical Manual of Mental Disorders, fifth edition (DSM-5) published by the American Psychiatric Association.\nProvided the severe consequences of anxiety and depression that even increase the risk of suicide [4], early detection and timely diagnoses are critical. In this regard, language can be a good predictor of mood disorders [5]. More in detail, how users engage in a conversation and express themselves is a strong indicator of their mental health state. Accordingly, the arrival of Large Language Models (LLMS, e.g., GPT-4, PaLM, and Alpaca) has contributed significantly to health-related topics thanks to their context-learning capabilities, mostly in generative tasks. Specifically, the literature has reported promising performance of these models in three relevant scenarios: (i) language comprehension, (ii) text generation, and (iii) knowledge inference [6]. Moreover, the potential of these models to leverage large volumes of online data is of great importance for both diagnosis and treatment [7].\nConsequently, several pre-trained language models (PLMS) and LLMS have been deployed for addressing health issues like mental disorders. It is the case of LLMental [8], MentalBERT [9] and MentalLLAMA [10]. Besides, PsychBERT [11] is fine-tuned to detect language patterns in behavioral health, mental health, psychiatry, and psychology texts. However, as indicated by previous works [1], their performance in specific classification problems with task-specific data like anxiety and depression is still immature when used as final solutions (i.e., in zero-shot/few-shot learning or with limited fine-tuning). This is due to the poor detection of nuances and task-specific patterns essential for accurate detection. Similarly, the PLMS exhibit limited generalization and low multitask robustness [12, 13]. Another key limitation is their low interpretability, which prevents their practical use beyond academic research [10].\nSumming up, using PLMS or directly LLms in zero-shot settings is the prominent approach [14]. Regarding the experimental data, most researchers use social media [15]. In recent years, there has even been an increasing interest in detecting mental health states with tracking devices, which results from the growing importance that modern society places on mental well-being [16]. Regardless of the approach, the aspect in which most of the researchers meet is the necessity to provide interpretable results along with explainable descriptions of the rationale of the machine-based solutions, of uttermost importance in the healthcare field provided their direct impact in the decision-making of clinicians and thus, the patient's well-being. In this regard, eXplainable Artificial Intelligence (XAI) comprises post hoc and self-explanatory techniques. While the former posthoc alternatives aim to explain the prediction of black-box classification models like the popular explanatory model-agnostic tools (i.e. those that combine local linear and random models, like LIME and SHAP [17] to approximate feature importance weights with regression and game theory), the self-explanatory approach relies on intrinsically interpretable models that can provide explanations along with the predictions [14]. However, feature importance methods like LIME and SHAP only provide the weight of the selected features without considering the interactions among the features and are low intuitive for end users [18]. In this regard, a major regulatory milestone in the AI field was materialized with the Artificial Intelligence Act (AIA). The final text pays particular attention to interpretability, the right of end users to receive clear explanations, and the disclosure of the use of AI in human interactions [19].\nGiven the safety-critical nature of these conditions, our solution must provide high accuracy and explainability to promote trust among the end users and professionals. Accordingly, we combine the traditional Machine Learning (ML) models (which can offer higher accuracy but lack explainability) operating in a multi-label setting with LLMS (which are intrinsically explicable but lack specific down- stream knowledge). Note that in our approach, LLMS are leveraged to extract users' expert features related to anxiety and depression by detecting linguistic patterns and language usage, taking advantage of their understanding capabilities. Specifically, relying on LLMS solely as part of the feature engineering"}, {"title": "2. Literature review", "content": "Traditional ML, deep learning, and Natural Language Processing (NLP) techniques have been used in the literature for mental health assessment [3]. The most recent works involve word embedding with transformed-based models (also known as PLMS) to take advantage of contextual data [20, 21]. However, scant research is available in state of art related to using LLms like ChatGPT underlying models; most use them as final classification solutions with limited prompt engineering or fine-tuning.\nRegarding the detection of anxiety and depression, many researchers apply a multitask learning perspective (i.e., defining a primary and an auxiliary task), e.g., emotion inference. This is due to the availability of experimental labeled data in terms of emotional content [22]. These works sustain that stressed users are more likely to express negative emotions (e.g., anger, fear, and sadness) rather than positive ones (e.g., happiness). This is the case in many works. In this regard, Qureshi et al. [23] defined emotion classification as the second task, which follows depression as the main task, similar to what Ghosh et al. [24] proposed. Moreover, the solution developed by Turcan et al. [25] is another representative example. Notably, the authors applied this approach to stress detection. They explored single-task models that operate similarly to BERT and multitask learning with a fine-tuned BERT model on emotion detection and stress labels. Finally, they exploited LIME for interpretability. Although we agree with the strong relation between emotion load and mental health state, we believe that relying mainly on emotion detection to assess anxiety, depression, or stress may lead to false positive results. Thus, we incorporated this knowledge into the engineered features, using anxiety and depression-labeled data as main tasks jointly in a multi-label setting.\nMoreover, Ghosh et al. [26] proposed a multitasking framework (not based on ML models) for depression detection, sentiment classification, and emotion recognition. Even if slightly related to our research, the promising results obtained prove the appropriateness of addressing anxiety and depression simultaneously, given the strong link between both mental health conditions. Conversely, Sarkar et al. [27] developed a multitask learning solution with a data-sharing mechanism, providing the relation between anxiety and depression. The authors used word embedding models like bert for feature engineering to feed traditional ML models, similar to our work but without the advantage in terms of explainability that LLMS provide. Alike to the work by Sarkar et al. [27] is the more recent proposal by Park et al. [28]. Additionally, Ilias and Askounis [29] defined a multitask learning framework in which depression and stress detection are the main and auxiliary tasks, respectively, using social media data. Note that two datasets gathered and labeled in different conditions are used. The first proposed approach encompasses a BERT-based layer shared for both tasks, primary and auxiliary, followed by separate BERT-based encoder layers. In contrast, the second approach derives from the first but exploits weighting layers by attention fusion networks. However, no hyperparameter tuning was performed due to limited access to computational resources. Explainability was not provided either.\nDespite the strong relation between anxiety or stress and depression, few studies address the joint assessment of several conditions [29]. In this regard, Lee et al. [2] focused on geriatric (i.e., experimental data from mild cognitive impairment patients) anxiety and depression detection by exploiting low- cost activity trackers. Regarding the multi-label classification approach followed, the authors applied the binary relevance method. That is, unlike in our work, they used two single-label classifiers for anxiety and depression, respectively, which is a more straightforward way of approaching the problem. However, accuracy may be compromised since the solution does not consider the correlation between labels. As in our work, they include questionnaire-based features from the geriatric anxiety inventory (GAI) and the geriatric depression scale (GDS). In addition, Park et al. [30] also integrated the DSM-5 diagnostic criteria into their predictive methodology, which is based on a variant of the BERT model. Similarly, de Souza et al. [31] proposed a stacking solution with two single-binary classifiers for anxiety, depression, and their comorbidity leveraging social media data. Note that the authors used SHAP for interpretability.\nSome authors exploited the already mentioned PLMS. It is the case of Ahmed et al. [1] who proposed a transformer-based architecture for multi-class depression detection (i.e., in severity levels: absent, mild, moderate, and severe). After text processing, different variants of the BERT model are used for classification. The final result is obtained following a voting approach. The authors applied LIME to provide interpretability to the solution. Ultimately, the proposed system was compared with ChatGPT (gpt-3.5-turbo model, non-fine-tuned), which attained poor performance. Related to our work, Chowdhury et al. [7] studied early depression detection from social media data using LLMS (i.e., GPT-4), deep learning (e.g., LSTM) and transformer models (e.g., BERT). However, the authors' approach to explanability is to provide feature-level interpretability. More recently, Ilias et al. [32] developed a transformer-based solution for stress and depression detection from social media data. Extra-linguistic information is introduced to the BERT and MentalBERT models. However, the solution does not approach the detection task simultaneously, as in our work, which is much more challenging. Conversely, experiments were performed with datasets for binary classification of stress and depression, respectively, and a multi-class (i.e., with different severity levels) depression dataset.\nWhen it comes to the application of LLMS, Wang et al. [6] leveraged a fine-tuned version of ChatGPT to detect depression. To ensure accurate predictions, the authors proposed a knowledge-enhanced pre-training scheme with emotion analysis capabilities and human feedback. Moreover, Liu et al. [14] used ChatGPT for data collection along with manually created psychology data that feed BERT and ROBERTA models for depression detection. Regarding interpretability, SHAP was exploited. Similarly, Ohse et al. [33] investigated several PLMS and LLMs (e.g., BERT, GPT-4, LLAMA) for depression assessment using clinical interviews as experimental data. The authors exploited the models following the zero-shot paradigm without fine-tuning or prompt engineering. Despite being a relevant study to endorse the applicability to the mental health field of these models, the authors did not exploit their full potential, as already mentioned with the lack of tuning and also regarding explainability. Furthermore, Wang et al. [34] proposed a solution that searches for depression-related texts from the BDI questionnaire. Then, LLMS are used to fill the latter survey using user data from social media to infer their mental state. Ultimately, Xu et al. [15] evaluated different LLMS (e.g., Alapaca, LLAMA, GPT-4) for mental health classification (binary and multi-class prediction for stress, depression and suicide) from social media data exploiting prompt engineering. Note that this work differs from ours in the absence of the multi-label setting and explainable capabilities."}, {"title": "2.1. Research contributions", "content": "Table 1 shows the most closely related solutions to easily compare and assess our contributions. To the best of our knowledge, our work is the first to apply LLMS to extract users' expert features related to anxiety and depression. By this means, we can detect linguistic patterns and language usage, using the comprehension capabilities of LLMS without sacrificing explainability. Moreover, another relevant contribution is combining traditional ML models in a multi-label setting, which can offer higher accuracy. Consideration should also be given to integrating formal clinical knowledge through standard tests used for data labeling. More in detail, experimental data consists of a free conversation between patients and a conversational chatbot, despite the popularity of social media data for anxiety and depression detection and the rigidity of self-reporting questionnaires. Ultimately, an explainability dashboard describes the most relevant data that leads to the classification decision and its confidence.\nSumming up, the main contributions of the proposed solution for the field are:\n\u2022 A multi-label framework able to predict jointly anxiety and depression.\n\u2022 The use of LLMS to extract high-level reasoning features used to train the ML models.\n\u2022 The explainability dashboard which promotes trust and makes the solution accountable and reliable."}, {"title": "3. Methodology", "content": "Figure 1 shows the scheme of our proposal. It is composed of (i) data acquisition to gather and filter data; (ii) feature engineering to generate new features using prompt engineering through an LLM model and applying sliding window treatment; (iii) feature analysis and selection to remove no-relevant features. Moreover, the (iv) classification module evaluates our multi-label solution. Finally, (v) the explainability module generates a natural language explanation of the classifier predictions leveraging a prompt engineering template."}, {"title": "3.1. Data acquisition", "content": "The experimental dataset is composed of conversations with Celia chatbot. This chatbot establishes an entertaining and engaging dialogue with end users, including fun facts about the conversation topics. Moreover, every 3 months, the chatbot uses the standard questionnaires presented in the Spanish versions of the Goldberg Anxiety and Depression Scales (GADS) and the Yesavage Geriatric Depression Scale (YGDS) to assess the cognitive state of the user. These questions are embedded during the conversation flow. The latter data is used as the label of the user (i.e., absence or presence of anxiety and depression) for the supervised learning stage."}, {"title": "3.2. Feature engineering", "content": "The solution combines feature generation based on prompt engineering with a sliding window strategy to consider the history of past sessions. Table 2 shows the features engineered that can verse on the cognitive state of the end user (i.e., their emotional well-being or health condition) or on the dialogue itself (i.e., the discoursive and linguistic characteristics of the conversation with the chatbot). These features are calculated using an LLM and prompt engineering, and their values range from 0.0 to 1.0.\nEach generated feature is expanded with four new statistical features (average, and the three quartiles Q1, Q2, and Q3). For this purpose, a sliding window is performed with the last 30 sessions (see Equation (1), where n is the number of sessions and X [n] is the historical feature in the last n sessions. Consequently, Y[n] is the ordered version of X [n].\n$\\forall n \\in \\{1...\\infty\\}$\n$X[n] = \\{x[0],...,x[n]\\}.$\n$Y[n] = \\{yo[n], y_1[N], \u2026\u2026\u2026, y_{n-1}[N]\\} | yo[n] \\leq y_1[n] \\leq ... \\leq y_{n-1}[n],$\nwhere; $\\forall x \\in X[n], x \\in Y[n].$\n$\\text{avg}[n] = \\frac{1}{n}\\sum_{i=0}^{n} x[i]$\n$Q_1[n] = Y[n][\\frac{n}{4}]$\n$Q_2[n] = Y[n][\\frac{n}{2}]$\n$Q_3[n] = Y[n][\\frac{3n}{4}]$\n(1)"}, {"title": "3.3. Feature analysis & selection", "content": "In the cold-start step, the system uses 10% of the samples to select the most relevant features. In this first phase, a selector based on a meta-transformer wrapper is applied (i.e., following a model-agnostic strategy). In order to select the most significant features, this transformer uses a tree ML classifier that calculates the Mean Decrease in Impurity (MDI) of each feature. Ultimately, the features with a MDI lower than average are discarded."}, {"title": "3.4. Classification", "content": "In this study, we solve a multi-label binary classification problem. More in detail, this scenario differs from the binary class in the number of labels assigned. In the latter binary-class scenario, the classifier provides a single label between the two classes in the experimental data (i.e., number of classes is 2, the number of resulting labels is 1). Since ours is a binary problem, we applied the Multi-class Transformation Strategy (MTS) [35]. Particularly, in our approach, we group the binary classes into four categories: (none_none), (none_depression), (anxiety_none), and (anxiety_depression). Note that the multi-label classification is a complex problem because the results may be partially correct, preventing the use of standard ML evaluation metrics. Instead, the metrics described below (micro and macro approach) are computed:\n\u2022 Exact match ratio represents the proportion of predictions where both labels are correct (see equation (2), where A is the actual label, P is the predicted label, and n is the number of samples).\n$\\frac{1}{n}\\sum_{i=1}^{n} I(A_i = P_i)$\n(2)\n\u2022 Accuracy is the percentage of correctly predicted labels over the total predicted and actual categories (see equation (3)).\n$\\frac{1}{n}\\sum_{i=1}^{n} \\frac{|A_i \\cap P_i|}{|A_i \\cup P_i|}$\n(3)\n\u2022 Precision is the percentage of correctly predicted labels over predicted labels (see equation (4)).\n$\\frac{1}{n}\\sum_{i=1}^{n} \\frac{|A_i \\cap P_i|}{|P_i|}$\n(4)"}, {"title": "Recall", "content": "\u2022 Recall is the percentage of correctly predicted labels over actual labels (see equation (5)).\n$\\frac{1}{n}\\sum_{i=1}^{n} \\frac{|A_i \\cap P_i|}{|A_i|}$\n(5)\n\u2022 Hamming Loss (HL) calculates the incorrectly predicted labels. In our binary problem, it complements the accuracy (see equation (6)).\n$1 - Accuracy$\n(6)\nOur solution exploits the Naive Bayes (NB), Decision Tree (DT), and Random Forest (RF) classifiers widely used in the literature to solve similar classification problems [2, 24, 27]. We analyze two different scenarios. Scenario 1 uses all user sessions to summarize the analysis, while scenario 2 evaluates the behavior of the system by reducing the number of samples and selecting 2 out of 3 entries."}, {"title": "3.5. Explainability", "content": "Our system explains the predictions obtained by leveraging an LLM with a prompt engineering template. This approach creates an explanation of the predicted majority category every 7 sessions. For this pur- pose and to limit the computational load of the explainability module, the most representative statistics of the features in Table 2 (i.e., the average and the Q2) are considered. Moreover, the conversations of the last two sessions are also sent to the model with the predicted category for interpretability purposes. In addition to promoting trust among end users and clinicians and the accountability and reliability of the solution, this information can be exploited to recommend formal assessment in the primary care health system or treatment to prevent anxiety and depression."}, {"title": "4. Results and discussion", "content": "This section explains the experimental dataset used and the results obtained. The analysis was conducted on a computer with the following specifications:\n\u2022 Operating System (os): Ubuntu 18.04.2 LTS 64 bits\n\u2022 Processor: IntelCore i9-10900K 2.80 GHz\n\u2022 RAM: 96 GB DDR4\n\u2022 Disk storage: 480 GB NVME + 500 GB SSD"}, {"title": "4.1. Experimental data", "content": "The dataset contains the complete conversations between voluntary users and the Celia chatbot from 16 May 2023 to 9 October 2024. Notably, it comprises 2186 user sessions, 32 users, and an average of 68 sessions per user. Moreover, each session comprises an average of 26 interactions and 157 words per session. Table 3 shows the distribution of sessions by categories. More in detail, most cases are concentrated in people without any pathology, and the presence of depression overlaps with anxiety, reducing the number of isolated cases of the former. This increases the difficulty of the classification problem, given the imbalance of experimental data, even more so in the multi-label scenario."}, {"title": "4.2. Data acquisition", "content": "To motivate a new conversation with Celia, the assistant sends notifications by email and shows reminders to the users. In this line, to detect the end of a session, the user must say goodbye, or this is automatically finished after 3 minutes of inactivity. Those sessions with 5 or fewer human interventions are discarded to ensure that a significant amount of data enters the anxiety and depression detection system. In addition, as described in Section 3.1, every 3 months, the samples are re-labeled on anxiety and depression using the standard questionnaires GADS and YGDS."}, {"title": "4.3. Feature engineering", "content": "The features described in Table 2 are generated using the gpt-4o-mini model. It can be accessed by sending requests to OpenAI API, using the prompt in Listing 1. Each request contains the text of the complete session and the temperature parameter set to 0. This removes the randomness and ensures that the model provides the same response to the same input content.\nFor each of the 14 features, the average and the three quartiles Q1, Q2, and Q3 are calculated. In total, 56 features are used in this multi-label problem. Once calculated, the values are rounded to 2 digits, and those with the same values are discarded."}, {"title": "4.4. Feature analysis & selection", "content": "Our approach uses the SelectFromModel library of scikit-learn in combination with the RF classifier to analyze and select the most relevant features. This analysis is performed using the 10% of the dataset. Specifically, 39% of the original features are selected in scenario 1 and 2."}, {"title": "4.5. Classification", "content": "We evaluate our approach using the scikit-learn Python library. The NB, DT and RF models are selected.\nThe hyperparameters of these classifiers are optimized using the GridSearchCV method. We use a 10-fold cross-validation to evaluate the configuration that offers the best accuracy value over the 10% of the experimental dataset. Listings 2, 3 and 4 contain the parameter sets for NB, DT, and RF, respectively. The values selected for scenarios 1 and 2 are shown below.\nScenario 1:\n\u2022 NB: var_smoothing = 1e-05\n\u2022 DT: splitter = best, max_features = None, max_depth = 100, min_samples_split = 0.001, min_samples_leaf = 0.001, criterion = entropy\n\u2022 RF: n_estimators = 200, max_features = sqrt, max_depth = 10, min_samples_split = 2, min_samples_leaf = 1, criterion = gini\nScenario 2:\n\u2022 NB: var_smoothing = 1e-05\n\u2022 DT: splitter = random, max_features = sqrt, max_depth = 100, min_samples_split = 0.001, min_samples_leaf = 0.001, criterion = entropy\nRF: n_estimators = 100, max_features = None, max_depth = 5, min_samples_split = 2, min_samples_leaf = 1, criterion = entropy"}, {"title": "4.6. Explainability", "content": "Figure 2 shows the dashboard accessible to the caregivers, physicians, and end users with the four most relevant features from Table 2 on the top. The boxes are green if the feature values are below 50% and red otherwise. At the bottom of the figure, the explanation generated by the gpt-4o-mini model is shown. Our approach uses the prompt engineering template described in Listing 5 filled with the values of the average and the Q2 of the features in Table 2, the conversations of the last 2 sessions, and the predicted majority category. On the right, the dashboard indicates the prediction and the confidence percentage using Predict_Proba function."}, {"title": "5. Conclusion", "content": "Given the appalling consequences of anxiety and depression, timely detection of these conditions is of uttermost importance. Traditional screening methods are time-consuming and rely on rigid subjective assessment with interviews and questionnaires. Moreover, despite the strong relationship between anxiety or stress and depression, few studies address the joint assessment of several conditions.\nAI-based solutions have proposed several advantages regarding flexibility, scalability, and person- alization. However, their performance in specific classification problems with task-specific data like anxiety and depression is still immature when used as final solutions, as is the case with LLMS. Moreover, some solutions lack generalization and multitask robustness, apart from low interpretability, which prevents their practical use beyond academic research. Interpretability and explainability are especially relevant in this field, provided their direct impact on clinicians' decision-making and, thus, the patient's well-being.\nIn this work, an entirely novel system for the multi-label classification of anxiety and depression is proposed. Another relevant contribution lies in using LLMS for feature extraction, which are intrinsically explicable but lack specific downstream knowledge, with ML models operating in a multi-label setting, which can offer higher accuracy but lack explainability. Specifically, relying on LLMS solely as part of the feature engineering module to extract user-level knowledge from free dialogues with a conversational assistant, we tackle the hallucination problem. In addition, we leverage formal medical knowledge using clinical scales for anxiety and depression to label the experimental data. Moreover, explainability descriptions of the model's decision are provided in a graphical dashboard along with the confidence of the results to promote the solution's trustworthiness, reliability, and accountability. Experimental results on a real dataset attain 90% accuracy, improving those in the prior literature. The ultimate objective is to contribute in an accessible and scalable way before formal treatment occurs in the healthcare systems.\nIn future work, we plan to evolve the solution to study severity levels of mental health conditions, as well as deploy the system in a real-world setting (i.e., stream-based ML). Another line of work will focus on the analysis of non-verbal and paraverbal data (e.g., voice modulation)."}, {"title": "Declaration of competing interest", "content": "The authors have no competing interests to declare relevant to this article's content."}, {"title": "Declaration of studies in humans", "content": "This study was carried out following the World Medical Association Declaration of Helsinki."}, {"title": "Acknowledgments", "content": "This work was partially supported by Xunta de Galicia grants ED481B-2022-093 and ED481D 2024/014, Spain."}]}