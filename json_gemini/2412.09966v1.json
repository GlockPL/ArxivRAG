{"title": "EP-CFG: ENERGY-PRESERVING CLASSIFIER-FREE GUIDANCE", "authors": ["Kai Zhang", "Fujun Luan", "Sai Bi", "Jianming Zhang"], "abstract": "Classifier-free guidance (CFG) (Ho & Salimans, 2022) is widely used in diffusion models (Ho\net al., 2020; Song et al., 2020) for text-guided generation, but often leads to over-contrast and over-\nsaturation artifacts. We propose EP-CFG, a simple yet effective CFG solution that preserves the\nenergy distribution of the conditional prediction while maintaining strong semantic alignment.\nConcretely, given unconditional prediction xu and conditional prediction xc, CFG (Ho & Salimans,\n2022) produces:\n$x_{cfg} = x_u + (\\lambda - 1)(x_c - x_u)$,\nwhere \u03bb \u2265 1 is the CFG strength. Here, we re-write the CFG equation from its common form xcfg =\nxc+(\u03bb\u22121)xu (Ho & Salimans, 2022) to Eq. 1, in order to make it clearer to see the two components\nof CFG prediction xcfg: 1) conditional prediction xe; 2) CFG additive term (\u03bb \u2013 1)(xc \u2013 xu).\nThe CFG additive term (\u03bb \u2013 1)(xc \u2013 xu) added to the conditional term xe can significantly enhance\nthe semantic alignment and structure coherence. Usually, the CFG strength is around 7-10 (Rombach\net al., 2022) in modern text-to-image models for sampling high-quality visuals. However, it is well-\nknown that such high CFG strength can lead to the well-known over-contrast and over-saturation\nartifacts (Ho & Salimans, 2022). Concurrent work (Sadat et al., 2024) proposed APG to address\noversaturation through update term decomposition. Our key observation is that the CFG additive\ncomponent can drastically increase the energy of the sampled latents in the progressive denoising\nprocess; the excessive energy eventually causes the over-contrast and over-saturation artifacts.\nAs a remedy, our proposed EP-CFG rescales the energy of xcfg to match xe at each denoising step:\n$x'_{cfg} = x_{cfg} \\sqrt{\\frac{E_c}{E_{cfg}}}$\nwhere Ec = ||xc||2 and Ecfg = ||xcfg||2. Our EP-CFG differs from prior solution (Lin et al., 2024)\nmainly in two aspects: 1) we scale the CFG prediction based on energy instead of standard devia-\ntion; 2) we do not interpolate between CFG and conditional predictions. Hence, our formulation is\nsimpler and better preserves the information of the CFG prediction.\nTo increase our algorithm's robustness, we ignore the two tails in the energy histogram and only\nconsider a small middle region when estimating the energy terms Ec, Ecfg. Specifically, let P\u2081, Ph\nbe the [th and hth percentiles of a latent x; then the robust energy is derived as:\n$E_{robust} = \\sum x_i^2 \\cdot 1[P_l \\leq x_i \\leq P_h]$.\nIn practice, we recommend using l = 45, h = 55 as we found this setting works best empirically,\nand all results in this report use these values. By using the robust energy estimation, we suppress the\nconfetti artifacts that oftentimes appear in monochromatic regions of generated visuals.", "sections": []}