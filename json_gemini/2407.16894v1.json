{"title": "Estimating the Increase in Emissions caused by AI-augmented Search", "authors": ["Wim Vanderbauwhde"], "abstract": "AI-generated answers to conventional search queries dramatically increase the energy consumption. By our estimates, energy demand increase by 60-70\u00d7. This is a based on an updated estimate of energy consumption for conventional search and recent work on the energy demand of queries to the BLOOM model, a 176B parameter model, and OpenAI's ChatGPT, which is of similar complexity.", "sections": [{"title": "I. INTRODUCTION", "content": "The new trend in search engines, to provide an AI-generated answer to the search query, has a considerable impact on the energy consumption and therefore CO2 emissions per query. To illustrate the impact of AI augmented search queries more clearly, I compare the energy consumption and emission of a query to Google's BLOOM model with that of a conventional Google search-style query. If all search queries are replaced by AI-augmented queries, what does that mean for energy consumption and emissions?"}, {"title": "II. GOOGLE SEARCH ENERGY AND EMISSIONS", "content": "In 2009, The Guardian published an article about the carbon cost of Google search [1]. Google had posted a rebuttal [2] to the claim that every search emits 7 g of CO2 on their blog. What they claimed was that, in 2009, the energy cost was 0.0003 kWh per search, or 1 kJ. That corresponded to 0.2 g CO2, and I think that was indeed a closer estimate.\nThis number is still often cited but it is entirely outdated. In the meanwhile, computing efficiency has rapidly increased [3]: Power Usage Effectiveness (PUE, metric for overhead of the data centre infrastructure) dropped by 25% from 2010 to 2018; server energy intensity dropped by a factor of four; the average number of servers per workload dropped by a factor of five, and average storage drive energy use per TB dropped by almost a factor of ten. Google has released some figures about their data centre efficiency REF that are in line with these broad trends. It is interesting to see that PUE has not improved much in the last decade.\nTherefore, with the current AI hype, I wanted to revise that figure from 2009. Three things have changed: the carbon intensity of electricity generation has dropped [4], server energy efficiency has increased a lot, and PUE of data centres has improved [5]. Combining all that, my new estimate for energy consumption and the carbon footprint of a Google search is 0.00004 kWh and 0.02 g CO2 (using carbon intensity for the US). According to Masanet[3], hardware efficiency increases with 4.17\u00d7 from 2010 to 2018. This is a power law, so extrapolating this to 12 years gives 6.70\u00d71. The calculation of the updated emissions per search query is shown in Alg. 1.\nSo the energy consumption per conventional search query has dropped by 7\u00d7 in 14 years. There is quite some uncertainty on this estimate, but it is conservative, so it will not be less than that, but could be up to 10\u00d7. Microsoft has not published similar figures but there is no reason to assume that their trend would be different; in fact, their use of FPGAs should in principle lead to a lower energy consumption per query. In that same period, carbon emissions per search have dropped about 10x because of the decrease in carbon intensity of electricity."}, {"title": "III. BLOOM ENERGY CONSUMPTION PER QUERY", "content": "In a recent paper [6], Luccioni et al. analysed the en- ergy consumption per query for the 176B-parameter BLOOM model, which is of the same complexity as current versions of GPT. The model was used to provide AI-generated summaries of search queries. They measured power consumption over a period of 18 days, in which the model received an average of 558 requests per hour, for 230,768 requests in total. This resulted 914 kWh of electricity. With the above figure for electricity carbon intensity, the emissions per query to the summarising model are shown in Alg. 2.\nIn other words, the query to the BLOOM model to sum- marise the search result costs 75\u00d7 more energy than the conventional search query itself."}, {"title": "IV. CHATGPT ENERGY CONSUMPTION PER QUERY", "content": "There are several estimates of the energy consumption per query for ChatGPT. I have summarised the ones that I used in the following table. There are many more, these are the top ranked ones in a conventional search.\nReference [11] by de Vries uses the estimates from [12] for energy consumption but does not present a per-query value so I used the query estimate from [12]. Overall, the estimates lie between 24\u00d7 and 236\u00d7 (from [7], which is a collation of estimates from Reddit and therefore very broad) or 28\u00d7 to 160x (all other sources)."}, {"title": "V. OTHER FACTORS CONTRIBUTING TO EMISSIONS", "content": "Contrary to popular belief, it is the use of ChatGPT, not its training, that dominates emissions. I wrote about this in [13]. In the initial phase of adoption, with low numbers of users, emissions from training are not negligible, but in the scenario where conventional search is replaced by ChatGPT- style queries, which is now the case for Bing, Google, Yandex, Baidu and many of the less popular search engines, emissions from training are only a small fraction. How much is hard to say as we don't know how frequently the model gets retrained and what the emissions are from retraining as opposed to the original training; they are almost certainly much lower as the changes in the corpus are small, so it is tuning."}, {"title": "A. Training", "content": "Contrary to popular belief, it is the use of ChatGPT, not its training, that dominates emissions. I wrote about this in [13]. In the initial phase of adoption, with low numbers of users, emissions from training are not negligible, but in the scenario where conventional search is replaced by ChatGPT- style queries, which is now the case for Bing, Google, Yandex, Baidu and many of the less popular search engines, emissions from training are only a small fraction. How much is hard to say as we don't know how frequently the model gets retrained and what the emissions are from retraining as opposed to the original training; they are almost certainly much lower as the changes in the corpus are small, so it is tuning."}, {"title": "B. Data centre efficiency", "content": "As far as I can tell, PUE is not taken into account in the above estimates. For a typical hyperscale data centre, it is around 1.1, so it will not changes the estimate appreciably."}, {"title": "C. Embodied carbon", "content": "Neither the Google search estimate nor the ChatGPT query estimates include embodied carbon. The embodied carbon can be anywhere between 20% and 50% of the emissions from use, depending on many factors. My best guess is that the embodied emission are proportionate to the energy consumption, so this would not affect the factor much."}, {"title": "VI. CONCLUSION", "content": "Taken all this into account, it is possible that the emissions from generating AI summaries for search are more than a hundred times that of the conventional search query. As I don't have enough data to back this up, I will keep the conservative estimates from above (50\u00d7 - 90\u00d7; 60\u00d7 most likely for ChatGPT; 75\u00d7 for BLOOM).\nNow, if we want sustainable ICT, then the sector as a whole needs to reduce its emissions to a quarter from the current ones by 2040. The combined increase in energy use and growth in adoption of AI-augmented search and other generative AI applications is therefore deeply problematic."}]}