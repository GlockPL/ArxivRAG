{"title": "Trustworthy XAI and Application", "authors": ["MD Abdullah Al Nasim", "Parag Biswas", "Abdur Rashid", "Angona Biswas", "Kishor Datta Gupta"], "abstract": "One of today's most significant and transformative technologies is the rapidly developing field of artificial intelligence (AI). Defined as a computer system that simulates human cognitive processes, AI is present in many aspects of our daily lives, from the self-driving cars on the road to the virtual assistants in our smartphones. The term \"black box\" is often used to describe artificial intelligence (AI) because some AI systems are so complex and opaque. With millions of parameters and layers, these systems-deep neural networks in particular-make it difficult for humans to comprehend how they make judgments. Even if AI is capable of producing correct findings, questions of accountability, prejudice, and justice are raised by the opaqueness of its decision-making process. AI has a lot of potential, but it also comes with a lot of difficulties and moral dilemmas. In the context of explainable artificial intelligence (XAI), trust is crucial as it ensures that AI systems behave consistently, fairly, and ethically. In the present article, we explore XAI, reliable XAI, and several practical uses for reliable XAI. Once more, we go over the three main components-transparency, explainability, and trustworthiness of XAI-that we determined are pertinent in this situation. We present an overview of recent scientific studies that employ trustworthy XAI in relation to these fundamental components, as well as an analysis of how trustworthy \u03a7\u0391\u0399 is applied in various application fields. In the end, trustworthiness is crucial for", "sections": [{"title": "1 Introduction", "content": "Philosophers who sought to characterize human thought as the mechanical manipulation of symbols laid the foundations of modern-day artificial intelligence. These efforts resulted in the invention of the programmable digital computer [1] in the 1940s. Though it is now lost, Alan Turing may have published the first article on the subject of artificial intelligence in 1941, indicating that he was at least thinking about the concept at that time. The public was first introduced to Turing's notion of the Turing test in his seminal work \"Computing Machinery and Intelligence\" from 1950 [2]. In it, Turing cast doubt on the viability of building thinking machines. The term artificial intelligence (AI) was first used in 1950 [3] but its general adoption and use in healthcare has been hindered by many shortcomings of the original models. The introduction of deep learning in the early 2000s eliminated many of these limitations. We are entering a new era of technology where AI can be used in clinical practice through risk assessment models that improve workflow efficiency and diagnostic accuracy. AI systems can now analyze complex algorithms and learn on their own. The performance of AI systems has improved significantly in recent years. These new models expand on their capabilities to include text-image synthesis based on nearly any prompt, whereas previous systems focused primarily on generating facial images.\nThe applicability and potential of artificial intelligence (AI) to transform business is already evident in the wide range of areas in which it is applied: In the field of natural language processing (NLP) [5], artificial intelligence (AI) makes it easier for computers to understand and generate human language, enabling tasks such as sentiment analysis, machine translation, and spam filtering. Furthermore, computer vision [6] enables computers to comprehend visual information, promoting developments in fields like object identification, facial recognition, and self-driving automobiles. Computers can now learn from data thanks to machine learning (ML), which has applications in fraud detection, recommendation systems, predictive analytics, and other fields. Robotics [7] is a branch of artificial intelligence that deals with the design, development, and use of machines. These machines are used in a variety of industries, including space exploration, manufacturing, healthcare [8], [9], and many more. Additionally, the incorporation of AI into business intelligence (BI) [10] signals better data gathering, processing, and display, which promotes data-driven decision-making and increases efficiency. AI offers advances in patient outcomes and medical developments in the healthcare industry [11], [12], [13] by assisting in illness diagnosis, therapy development, and tailored care. Al's promise in education is evident in its ability to personalize instruction, engage students, and automate administrative tasks all of"}, {"title": "1.1 Third Wave of Artificial Intelligence (3AI)", "content": "The majority of commercial AI technology today is classified as \"narrow AI,\" meaning that it consists of extremely specialized systems that excel at a limited number of clearly defined jobs and nothing else. Even the most amazing autonomous cars need a combination of limited artificial intelligence algorithms. The reliance of modern AI on enormous training data sets is another drawback. For example, a three-year-old"}, {"title": "1.2 Concept of Explainable AI", "content": "Artificial Intelligence is often criticized for being hard to explain. Many opponents argue that it is hard to trust the results of an AI if one does not know how it can arrive at a certain result or conclusion. This issue becomes particularly problematic when AI-based programs and systems are unable to accomplish their goals. Developing explainability is necessary to boost public confidence in the computational execution. If we are to hold the system accountable, we must take steps to address and minimize input inefficiencies [18].\nArtificial intelligence is known to suffer from the \"black box\" syndrome due to a lack of understanding of how the system works. This has ramifications for human confidentiality, arbitrary discrimination, obfuscation, and legitimacy. There are often underlying prejudices and tendencies present along with this lack of openness. By enhancing users' comprehension of how AI-powered systems reason, XAI seeks to improve their performance. The goal of Transparent AI is to make artificial intelligence (AI) safer and more accessible than ever before [18]. Therefore, each of the TAI's diverse features has to be considered separately, and their many facets need to be talked about.\nAI's use of machine learning (ML) techniques falls into two categories: white box and black box [19]. The results of a white box model are understandable to a subject matter expert. In contrast, a black box model is very difficult to explain and can be confusing even to domain experts [20]. The three criteria of interpretability, explainability, and transparency are adhered to by the XAI algorithm [21]. A model is transparent when the underlying principles of the machine learning model and decision-making can be understood \"when the process of extracting model parameters from training data and generating labels from test data is described and justified by the designers of the approach. \" Because communicating in a way that people can understand is called interpretability [22]. Currently, there is no universally accepted definition of the concept of explainability, but its importance is recognized. An alternative is \"a collection of interpretable features of a domain that can help generate a decision (such as classification or regression) about a given example.\" If an algorithm follows these guidelines, it provides a basis for recording and validating the decision, improving the algorithm, and discovering new information."}, {"title": "1.3 Classification Tree of \u03a7\u0391\u0399", "content": "XAI techniques are divided into two categories: transparent and post-hoc methods. A transparent approach is one that represents the model's capabilities and decision-making process in an easy-to-understand way [24]. Transparent models include Bayesian approaches, decision trees, linear regression, and fuzzy inference systems. Transparent approaches can be useful when the internal feature correlations are highly complex or linear. A comprehensive classification of different XAI methods and approaches related to different types of data is shown in Figure ?? [?].\nPosterior approaches are useful for interpreting the complexity of a model, especially when there are nonlinear relationships or high data complexity. When a model does not follow a direct relationship between data and features, posterior techniques"}, {"title": "1.4 Definition of Transparency in Artificial Intelligence", "content": "In explainable artificial intelligence (XAI), transparency refers to the ability of an AI system to provide understandable justification for its decisions and actions [25]. In fact, transparency is one of the key components of explainable artificial intelligence (XAI). In many real-world applications, particularly those with large social implications, deciphering the reasoning behind an AI system's choice is just as crucial as the decision itself. Assuring transparency in XAI helps prevent AI systems from being viewed as \"black boxes\" and instead as instruments that enable users to get insightful and informative responses [26].\nThe general transparency of AI systems is further enhanced by the insights offered by XAI approaches. Users have the capacity to scrutinize the decision-making procedures, detect any partialities, and evaluate the dependability and equity of the model's results [27]. Transparent systems are essential for guaranteeing accountability and ethical concerns in fields where the implications of AI choices might have large repercussions, such as healthcare, finance, and autonomous cars. \u03a7\u0391\u0399 approaches enable users to find patterns, comprehend relationships, and discover any flaws or biases by providing insightful information about the inner workings of AI models [27]. Stakeholders are better equipped to make judgments, confirm that the model's predictions are accurate, and take necessary action as a result of the improved openness.\nThe examination of the ethical criteria revealed a correlation between explainability and transparency and a number of other quality needs."}, {"title": "1.5 Transparency Vs Explainability in AI", "content": "Transparency and explainability can be compared [29]. When an AI is transparent, the \"basic elements of data and decisions must be available for inspection during and after AI use,\" according to McLarney et al. [30]. Transparency exists when a user can observe how decisions are made or have access to their data. Explainability, on the other hand, is about understanding why AI succeeds or fails and revealing how it draws on the knowledge and decision-making processes of the people it will affect. It provides a rational explanation for the AI's actions. Users need to be able to understand what data is being collected, how the AI program processes it, and how it produces trustworthy outcomes for each individual affected. This straightforward explanation ignores the challenges we confront in simplifying \"black box\" algorithms, the context that is lost, and the accuracy needed when giving consumers clear explanations. The question thus becomes, is minimal explainability preferable to nothing? [30]. Other important factors to consider include the belief that explanations can adequately account for the dynamic nature of the rich information ecosystem and the appropriateness of dealing with anomalies.\nInterestingly, while certain AI algorithms analyze data automatically, an increasing number of AI systems are designed to explain how their algorithms work and"}, {"title": "1.6 Definition of Trustworthiness in Artificial Intelligence", "content": "Artificial intelligence (AI) systems that incorporate trustworthiness must take a multi-faceted approach that takes organizational, ethical, and technical factors into account. Establishing criteria for assessing trustworthiness is the first step in this process. These measures should include accountability, security, privacy, openness, fairness, and ethical compliance. Foundational elements include transparent algorithms that provide intelligible justifications for AI-driven judgments and high-quality, impartial data. Strong security measures and privacy-preserving strategies protect sensitive data and fight off online attacks. Responsible AI usage is encouraged through the establishment of accountability systems and adherence to moral principles and governance structures. User-centric design, ongoing observation, and training guarantee that AI systems satisfy users' demands while developing over time to retain their credibility. Organizations may create trustworthy, transparent, equitable, and ethical systems that inspire confidence in both users and stakeholders by incorporating these principles into all phases of the AI lifecycle.\nThe three elements depicted in Figure 8 - algorithmic ethics, data ethics, and practice ethics come together to form trustworthy AI. These elements offer an abstraction"}, {"title": "1.7 An Overview of Necessities for Reliable AI", "content": "The conditions for reliable AI are still unclear and are addressed incongruously by many institutions and groups, despite contentious social debates over it. The principles of Fairness, Responsibility, Accuracy, Verifiability, and Accountability in Machine Learning (FAT-ML) include accountability, explainability, verifiability, and fairness at a global level [32]. Among the numerous needs under review, explainability, fairness, privacy, and robustness will all be covered in this study."}, {"title": "2 Trustworthy \u03a7\u0391\u0399 Vs AI", "content": "A paradigm change in the field of artificial intelligence (AI) has been brought about with the introduction of Trustworthy Explainable \u0391\u0399 (\u03a7\u0391\u0399). Oftentimes, conventional AI systems operate as opaque black boxes, making it challenging for users to comprehend the decision-making process. On the other hand, Trustworthy XAI tackles significant concerns surrounding the adoption of AI by focusing on accountability, interpretability, and transparency. Reputable XAI seeks to build consumers' confidence by providing clear justifications for its choices. Users are able to evaluate the fairness and dependability of AI-driven results because to this transparency. While typical AI systems are capable of producing precise forecasts or suggestions, they do not have the openness required to establish credibility.\nThe way that reliable XAI and traditional AI make decisions is what sets them apart from one another. Although AI systems have the potential to produce precise"}, {"title": "3 Applications of Trustworthy \u03a7\u0391\u0399", "content": "Authentic Explainable Artificial Intelligence (XAI) has numerous uses in sectors where accountability, interpretability, and transparency are essential. XAI can provide an explanation for a diagnosis or therapy recommendation in medical diagnosis and recommendation systems. Financial institutions can employ XAI for risk assessment, fraud detection, and credit scoring. \u03a7\u0391\u0399 can help attorneys with contract analysis, lawsuit prediction, and legal research. In autonomous vehicles, XAI plays a significant role in providing context for the decisions made by the AI systems, particularly in high-stakes scenarios such as accidents or unanticipated roadside incidents. XAI can be applied to process optimization, predictive maintenance, and quality control in manufacturing settings. By offering justifications for automated responses or suggestions in chatbots and virtual assistants, XAI can improve customer service. By providing an explanation for the recommendations and assessments made by adaptive learning systems, XAI can help with individualized learning. By providing an explanation for the recommendations and assessments made by adaptive learning systems, XAI can help with individualized learning. We shall concentrate on a few particular applications in this section and go into detail about them."}, {"title": "3.1 Application of Trustworthy \u03a7\u0391\u0399 in Medical Science", "content": "The field of artificial intelligence (AI) is rapidly growing on a global scale. The potential uses of artificial intelligence in healthcare are a hot topic for research [33]. There are many opportunities to use AI technology in the healthcare sector, where people's lives and well-being are in danger, because of its essential relevance and the enormous quantity of digital medical data that have been gathered [34]. Artificial intelligence (AI) has made it possible to accomplish tasks quickly that were before unfeasible for traditional technologies. Trustworthy AI is a huge concern these days. Since incidents involving AI-powered chatbots such as Tay and Iruda [35], there has been an increase in interest in the topic of whether an Al's judgment and decision-making system is reliable. The credibility of AI in the medical and healthcare areas requires more investigation. Clinical decision support systems (CDSS) in the medical field use AI technology to aid with important medical duties such as diagnosis and therapy planning [36]. Misuse can have serious consequences in areas where lives are at stake, even if the scope of use is limited to assisting healthcare practitioners. False alarms, for example, which occur often in scenarios involving urgent patients, may exhaust medical personnel.\nThe study [37] adds significantly to the field of medical skin lesion diagnostics in a number of ways. Before anything else, it adapts an existing eXplainable Artificial Intelligence (XAI) technique to increase user confidence and trust in AI decision-making systems. This modification entails describing an AI model that is skilled at differentiating between different kinds of skin lesions. Synthetic exemplar and counter-exemplar images are used to create explanations that illustrate the important characteristics that influence classification choices. This research [37] is based on training a deep learning classifier with the ISIC 2019 dataset using the ResNet architecture. This enables"}, {"title": "3.2 Explainability and Interpretability of Autonomous Systems", "content": "Explainability and interpretability in the context of autonomous systems refer to the ability to understand and make sense of the systems' decisions and behaviors. Explainability refers to an autonomous system's ability to provide clear arguments for its decisions and behaviors [43]. It is critical for increasing acceptance and confidence in AI systems, particularly in areas such as banking, healthcare, and autonomous autos. While explainability and interpretability are closely connected, interpretability places more emphasis on the capacity to comprehend the internal workings and procedures of the autonomous system [44]. An interpretable system provides users with insight into the elements and criteria considered while making decisions, allowing them to comprehend how the system came to its findings.\nThe research paper The research article [18] focuses on trust and dependability in autonomous systems. Autonomous systems have the potential for system operation, rapid information dissemination, massive data processing, working in hazardous environments, operating with greater resilience and tenacity than humans, and even astronomical examination [45], [46]. Following years of research and development, today's automated technologies represent the peak of progress in computer recognition, responsive systems, user-friendly interface design, and sensing automation. According"}, {"title": "3.3 Applications of XAI for Operations in the Industry", "content": "The process industry is a subset of businesses that manufacture items from raw materials (not components) using formulae or recipes. Given the magnitude and dynamic nature of operations in the process sector, it becomes evident that the next great step ahead will be the capacity for people and AI systems to collaborate to ensure production stability and dependability [49]. AI systems must successfully inform the individuals who share the ecosystem about their objectives, intentions, and findings as the first step toward collaboration. In the future, people will work \"with\" automation rather than \"around\" it, thanks in part to the systematic approach to \u03a7\u0391\u0399.\nThis research [50] focuses on Explainable Artificial Intelligence (XAI) applications in the process industry. The research argues that current AI models are not transparent enough for process industry applications, and highlights the need for XAI models that can be understood by human experts. The main contribution is outlining the"}, {"title": "4 Future of Trustworthy (XAI)", "content": "The precise position of each XAI domain and how they relate to the human user are shown in Figure 13. The majority of AI system explanations that are given are usually static and only contain one message [66]. Understanding cannot be attained by explanations alone [67]. Because most existing \u03a7\u0391\u0399 libraries lack user involvement and customization of explanations, users should be able to explore the system using interactive explanations to gain a better understanding of it. This is a promising research direction for extending the XAI field [67] and [66]. To improve human-machine cooperation and move beyond static explanations, a number of efforts have also been proposed.\nExplainable Artificial Intelligence (XAI) has great promise for redefining the relationship between humans and AI systems as it stands at the nexus of technological innovation and societal integration. As AI technologies advance, it is more important than ever to ensure accountability and transparency. Within this framework, \u03a7\u0391\u0399 becomes a crucial facilitator, entrusted with shedding light on the murky inner workings of AI models and cultivating user confidence. A wide range of breakthroughs are anticipated in XAI, from heightened model transparency and human-centric design principles to regulatory compliance requirements and the rise of hybrid AI systems."}, {"title": "5 Conclusions", "content": "Explainable Artificial Intelligence (XAI) is gaining popularity in a range of fields due to its critical role in addressing critical issues connected to AI adoption. As AI systems become more integrated into society, transparency and interpretability become increasingly important. By offering tools to clarify how AI models make decisions, \u03a7\u0391\u0399 helps users develop a sense of confidence and comprehension. XAI's primary objective is to make AI models clear and intelligible. With the help of XAI, the general public will be able to peer inside the black box and comprehend the aspects that affect the AI's decision-making process. The paper discusses the essential details of XAI and offers a comprehensive overview for a solid understanding. Furthermore, this article discusses in detail the three main application fields of XAI. Lastly, the authors attempt to outline the difficulties in applying XAI and suggest potential future paths."}]}