{"title": "Bridging AI and Science: Implications from a Large-Scale Literature Analysis of AI4Science", "authors": ["Yutong Xie", "Hua Xu", "Yijun Pan", "Qiaozhu Mei"], "abstract": "Artificial Intelligence has proven to be a transformative tool for advancing scientific research across a wide range of disciplines. However, a significant gap still exists between AI and scientific communities, limiting the full potential of AI methods in driving broad scientific discovery. Existing efforts in bridging this gap have often relied on qualitative examination of small samples of literature, offering a limited perspective on the broader AI4Science landscape. In this work, we present a large-scale analysis of the AI4Science literature, starting by using large language models to identify scientific problems and AI methods in publications from top science and Al venues. Leveraging this new dataset, we quantitatively highlight key disparities between AI methods and scientific problems in this integrated space, revealing substantial opportunities for deeper AI integration across scientific disciplines. Furthermore, we explore the potential and challenges of facilitating collaboration between AI and scientific communities through the lens of link prediction. Our findings and tools aim to promote more impactful interdisciplinary collaborations and accelerate scientific discovery through deeper and broader Al integration.", "sections": [{"title": "1 Introduction", "content": "The 2024 Nobel Prizes in Physics and Chemistry were both awarded to Artificial Intelligence (AI) researchers. In particular, the developers of AlphaFold [9] were recognized for their groundbreaking work, which is based on the Transformer network and has revolutionized the prediction of protein structures, providing a transformative approach to solving complex biological problems. This is just one example of how Al has emerged as a powerful tool to facilitate scientific research across various disciplines [8, 11, 15, 31, 34].\nHowever, despite the transformative potential of using Al for advancing scientific research (AI4Science), a considerable gap persists between Al and scientific communities, hindering the full exploitation of Al for scientific discovery. On one side, advanced Al methodologies might remain mysterious or underutilized by scientists; on the other side, AI researchers may lack awareness of the specific challenges and potential applications in scientific domains, missing the opportunities for interdisciplinary collaborations.\nExisting efforts to identify and bridge this gap have predominantly involved qualitative reviews of AI's application in science [11, 31], particularly in specialized areas like drug discovery and materials science [8, 15, 34]. Based on qualitative examination of small samples of literature, these reviews often rely on heuristic insights from domain experts to suggest potential uses of Al in solving scientific problems. While valuable, such focused reviews are limited in providing a comprehensive and diverse perspective on the AI4Science landscape.\nWhile recent research from the Science of Science community has conducted larger-scale studies that quantify Al's impact on publications in scientific fields [5, 6], they often heavily rely on established scientific taxonomies in \"AI-heavy\" fields. There remains a lack of delivering a holistic, dynamic, and data-driven overview of AI4Science. Such analysis is crucial for understanding the barriers and identifying new opportunities for deep engagement of fast-evolving AI methodology in scientific research.\nIn this work, we aim to depict the AI4Science landscape via a large-scale and comprehensive analysis of relevant literature in both scientific and AI communities over the past decade. We start by using large language models (LLMs) to identify the scientific problems and Al methods addressed in publications from top science and AI venues, through which we assemble a novel and balanced AI4Science dataset to analyze the role of AI in scientific research (Sec. 3). Then with projection maps (Fig. 1) and a bipartite graph (Fig. 2) constructed from this dataset, we quantitatively reveal the discrepancies between AI and science, leading to several key findings and implications (Sec. 4). Finally, through the lens of link prediction, we demonstrate the potential and challenges in advancing the bridge between AI and science (Sec. 5). We anticipate that our findings and tools will foster more effective interdisciplinary collaborations, ultimately accelerating scientific discovery through a more diverse and deeper integration of AI methods."}, {"title": "2 Related Work", "content": "To identify potential applications of AI techniques in science, researchers typically turn to qualitative literature reviews of relevant papers. These reviews include general explorations of Al's usage"}, {"title": "2.1 Qualitative Literature Reviews of AI4Science", "content": "while Al-engaged work is spreading across disciplines, it does not integrate well with non-AI-engaged work within each specific field.\nAlthough these studies offer valuable insights into AI4Science, they primarily focus on areas where Al and science are already \"blended\" effectively, and overlook the broader and underexplored parts of the landscape. As a result, these approaches often fail to offer insights into the disparities between AI and scientific communities. In contrast, our work offers a more comprehensive view of the AI4Science landscape by showing and quantifying the connections and gaps between scientific problems and AI methods, as well as insights to uncover potential collaborations."}, {"title": "2.2 Quantitative Literature Analysis", "content": "In addition to heuristic and qualitative literature reviews, a few recent papers from the Science of Science community have focused on quantitatively analyzing the AI4Science publications. For instance, Gao and Wang [6] examined how Al benefits scientific research, finding that AI use is prevalent across various scientific disciplines, and that papers incorporating AI tend to receive a citation advantage. Similarly, Duede et al. [5] explored Al's engagement in different fields, uncovering an \"oil-and-water\" phenomenon"}, {"title": "3 A New Dataset of AI4Science", "content": "A major challenge in understanding the disparities and potential of AI4Science is the lack of a comprehensive, balanced dataset. Existing literature data are often biased toward success stories, such as areas where Al and science are already deeply intertwined. Or they reflect the perspective of either the scientific or AI communities, but not both. For example, the AI methods discussed in the scientific literature may not represent the full range of advancements in AI, while the scientific applications explored in AI literature may fail to capture the nuances and challenges of real-world scientific problems. We take the initiative to create a broad and balanced literature dataset to provide a wide-angled lens for understanding AI4Science research."}, {"title": "3.1 Curation of AI4Science Literature", "content": "We collect publications from leading science and AI venues to offer a balanced view from both communities:\n\u2022 For science domains, we include three top multidisciplinary journals that represent cutting-edge and high-quality research (Nature, Science, and PNAS) and two of their subjournals (Nature Communications, and Science Advances).\n\u2022 For Al communities, we include six top conferences from the list of CSRankings.org, comprising two AI-focused venues (AAAI,"}, {"title": "3.2 Extracting Scientific Problems and AI Methods with LLMs", "content": "To understand how AI is applied to science, we need to extract paired entries of scientific problems and AI solutions from relevant publications. Traditionally, this is accomplished through literature reviews and surveys which involve manual examinations of small samples of papers [11, 31], a labor-intensive and time-consuming process. Recent quantitative studies in the Science of Science field have started using metadata entries, such as keywords, to identify AI usage and categorize scientific topics [5, 6]. While this method enables larger-scale analysis, it offers only a coarse-grained view, potentially missing the nuanced details of scientific problems and AI methods. Additionally, it can suffer from issues such as incomplete data entries, limiting the effectiveness of analysis.\nIn contrast, our work leverages large language models (LLMs) to extract detailed descriptions of scientific problems and AI methods from publication titles and abstracts, allowing for a more nuanced, scalable, and data-driven analysis. Such LLM-based extraction techniques have also been employed in recent studies for extracting aspects from scientific literature, such as Zhang et al. [36].\nParticularly, for each publication of interest, we use OpenAI GPT-40 mini to extract the following three key aspects:\n\u2022 Scientific Problem (pi): The primary scientific problem addressed in the paper, including both a keyword or keyphrase summarizing the problem and a detailed definition.\n\u2022 AI Method (mi): The main AI method applied in the paper, including a keyword or keyphrase summarizing the method and a detailed description.\n\u2022 AI Usage (ui): A detailed explanation of how the AI method is specifically applied to the scientific problem.\nIt is possible that a publication did not address a scientific problem or did not use an AI method, in which case the corresponding field(s) would remain empty. If a paper addresses a scientific prob-lem using an Al method \u2013 i.e., pi, mi, and ui are all non-empty - it is considered as an AI4Science work. Figure 1 presents an example of the extraction results of an AI4Science publication.\nTo assess the reliability of GPT extractions, we conducted a small-scale human evaluation on 100 papers. Each extraction record was reviewed by at least two annotators, resulting in an average accuracy of 91.0%. For more details on the extraction prompts, additional examples of the extracted data, and verification with human annotations, please refer to Appendix A.2."}, {"title": "3.3 Semantic Clustering of Scientific Problems and AI methods", "content": "One of the key differences between this new AI4Science dataset and the data used in existing studies [5, 6] is that our dataset contains detailed textual descriptions of the identified scientific problems"}, {"title": "3.4 Dataset Overview and the Bipartite Graph", "content": "Through LLM-based extraction and semantic clustering, we form a comprehensive dataset, D = {(pi, Pi, mi, Mi, ui)}^N_{i=1}, which includes the scientific problems, AI methods, their corresponding cluster labels, and the usage of Al for science. The basic statistics of this dataset are listed in Table 1.\nTo better illustrate the connections between Al and science, we construct a bipartite graph based on the clusters. In this bipartite graph, scientific problem clusters and AI method clusters represent two types of nodes, and the publications act as edges connecting them. Formally, the graph is defined as G = (V, 8), where V = {Pi} \u222a {M} and E = D. As shown in Fig. 2(a), the graph provides an intuitive visual representation of how Al is linked to scientific challenges and vice versa."}, {"title": "4 Discrepancy Between AI and Science", "content": "Both Fig. 1 and 2 show a noticeable pattern of discrepancy between AI and science. This section quantitatively assesses these disparities, providing a deeper understanding of the gaps."}, {"title": "4.1 Uneven Distribution of AI4Science Research", "content": "The projection maps in Fig. 1 illustrate the distribution of AI4Science work within the semantic spaces of scientific problems and AI methods (the green dots among orange and purple dots). The uneven distributions suggest that AI4Science work is heavily clustered in certain subareas, while sit remains underrepresented in wide ranges of both the problem and the method spaces.\nIn Fig. 3, we plot the clusters of scientific problems and AI methods, showing the relation between cluster sizes and the presence of AI4Science publications within each cluster. The slopes of the regression lines represent the average proportions of AI4Science work in the literature of each scientific problem cluster or Al method cluster. Clusters below the regression line indicate problems or"}, {"title": "4.2 Uneven Distribution of Bipartite Links", "content": "Fig. 2 reveals an uneven distribution of node sizes in the bipartite graph, indicating the presence of \"hub\" and \"peripheral\" nodes among both scientific problems and AI methods. This implies that certain scientific challenges and AI techniques play a central role in interdisciplinary AI4Science work, while others are less explored.\nQuantitatively, heavy-tailed degree distributions are observed as visualized in Fig. 2(b-c). Specifically, the degrees for AI method nodes follow a log-normal distribution, while the degree distribution for scientific problem nodes exhibits an even heavier tail, though not as extreme as a power-law distribution. These findings support the idea that a small number of \"hubs\" are linked to a large variety of Al methods or scientific problems, while many other nodes remain peripheral to these interdisciplinary connections.\nHeavy-tailed distributions, particularly log-normals, are also commonly observed in other bipartite networks [30], such as document-term graphs [32], and in collaborative networks [19, 26]. This suggests that the structure of the AI4Science bipartite graph reflects a general pattern of interdisciplinary and collaborative work."}, {"title": "4.3 Discrepancy Between the AI and Science Communities", "content": "Our dataset includes publications from both scientific journals and Al conferences, allowing us to explore how these two communities approach the integration of AI into science in distinct ways.\nIn terms of facilitating scientific discovery with AI, the science community places greater emphasis on challenges such as: Protein Structure and Design, Materials Design, Artificial Intelligence Ethics, and Single-Cell RNA Sequencing; In contrast, the AI community tends to focus more on areas like: Social Media Dynamics, Game Theory, Market Economics, etc. When it comes to applying AI methods to scientific problems, the two communities also show different preferences. In addition to general approaches like Machine Learning and Deep Learning, the science community frequently employs Al techniques specifically tailored for scientific challenges, such as: Genomic Analysis, Protein Design, and Computational Biology. In comparison, the AI community utilizes a broader range of general Al methodologies, covering diverse areas such as: Data Analysis, Game Theory, Causal Inference, Probabilistic Modeling, Reinforcement Learning, Optimization Methods, Generative Models, etc.\nIn addition, by comparing Table 13 with Table 12, we also find that the scientific problems addressed by the AI community, tend to be connected to a wider variety of AI methods. Similarly, AI methods frequently used by the science community are applied across a broader range of scientific challenges. Similarly, AI methods frequently used by the science community are also more likely to be applied across a broader range of scientific challenges. This highlights the discrepancy between the two communities, where the science community engages with a limited range of AI methods compared to the Al community, and vice versa.\nThe distribution of AI4Science work published in scientific journals and Al conferences in the semantic maps (Fig. 6 in the Appendix) also illustrates the different focuses of these two communities."}, {"title": "4.4 Findings and Implications", "content": "Through our analysis of the distribution of AI4Science work, bipartite graph node degrees, and the discrepancies between the AI and science communities, we derive the following key findings:\n(F1) Different AI and science subdomains exhibit varying degrees of engagement in AI4Science research, leaving a substantial number of scientific problems and AI methods under-investigated in the collaboration context (Sec. 4.1);\n(F2) The connectivity between scientific problems and AI methods is highly imbalanced, with certain nodes acting as \"hubs\" while other peripheral nodes are less connected (Sec. 4.2);\n(F3) The science and AI communities take distinct approaches to integrate Al into scientific research, prioritizing different problems and methods (Sec. 4.3).\nThese key findings lead to two important implications for fostering a wider and deeper exploration of AI4Science:\n(11) More attention should be directed toward exploring the under-investigated areas, incorporating a broader range of scientific challenges and Al techniques into the AI4Science landscape.\n(12) Efforts should be made to discover new connections between AI and science, uncovering innovative ways to apply AI methods to scientific research."}, {"title": "5 Bridging AI and Science: Through the Lens of Link Prediction", "content": "Building on the findings and implications above, we delve deeper into the potentials and challenges of advancing the connections between AI and science from the perspective of link prediction."}, {"title": "5.1 Methodology", "content": "In the curated AI4Science dataset D = {(pi, Pi, mi, Mi, ui)}^N_{i=1}, the extracted and clustered scientific problems {pi} and {Pi}, as well as Al methods {m} and {M}, represent the respective landscapes of these two domains. The AI4Science publications, along with their descriptions of Al usage {u}, highlight the connections between scientific challenges and AI methods. To model these connections, we employ the link prediction formulation.\nData. We split the data into training and test sets based on publication dates. The training set includes papers published between 2014 and 2022 (5,829 AI4Science publications), which are used for training models, retrieving data points for generation augmentation, and identifying well/under-investigated areas, as illustrated in Fig. 3. The testing set consists of publications from 2023 and 2024 (1,195 AI4Science publications), serving as the ground truth for evaluating link prediction models. The statistics are provided in Table 14 in the Appendix. It is important to note that the analyses prior to this section involve the full AI4Science dataset, spanning the period from 2014 to 2024.\nModel and evaluation. We employ two types of models to predict links between scientific problems and AI methods. The first category includes conventional bipartite link prediction models [16], such as those based on the Katz index [10] and node2vec embeddings [7]. Formally, given a source node Pi (or Mi) in the bipartite graph, we predict K potential target nodes for linking. We then compare the predicted set with the ground truth target node set and report Precision, Recall, and F1 scores @K [1, 35]. The bipartite graph is constructed and the models are trained using only the training data, with evaluation performed on the testing data. Please note that existing links may also be counted in constructing the ground truth set, because a new AI4Science work may reuse an existing connection between a scientific problem and an AI method.\nIn addition to conventional link prediction, we utilize a large language model (LLM) for generative predictions. Specifically, given a scientific problem pi from cluster Pi, we generate potential AI methods mi that could be applied. These generated texts are then"}, {"title": "5.2 Overall Link Prediction Results", "content": "Table 3 presents models' performances on the test data, where conventional link prediction methods show strong results in both Precision and Recall. Particularly, while both Katz and node2vec rely on suggesting similar nodes to link, node2vec outperforms Katz, suggesting the underlying mechanism connecting scientific problems and Al methods goes beyond homophily in the local neighborhood and potentially considers the broader structures of the AI4Science network.\nNotably, the LLM+RAG approach lags behind conventional link prediction methods, emphasizing the challenge of generative link"}, {"title": "5.3 Prediction in the Well- and Under-investigated Regions", "content": "Fig. 3 reveals the presence of well- and under-investigated areas in both the scientific problem and AI method spaces. Echoing Implication (I1), we comparatively explore the potentials and challenges in facilitating interdisciplinary work for these regions.\nFormally, we refer to scientific problem clusters or AI method clusters above the regression lines as well-investigated areas, while those that fall below the lines are the under-investigated regions. Clusters that reside within the 95% confidence intervals of the regression results are excluded from this analysis.\nTable 4 compares the link prediction results for well-investigated and under-investigated clusters. In both categories of link prediction methods, we observe a similar trend: Precision scores are generally higher for well-investigated scientific problems and AI methods,"}, {"title": "5.4 Discovering Novel Links", "content": "Previous discussions highlight the capability of link prediction models to uncover novel links. Building on this, we further investigate the newly discovered connections in response to Implication (12).\nCompared to the training data up to 2022, human researchers identified 554 new links between scientific problems and AI methods during 2023 and 2024. In contrast, link prediction methods have demonstrated the potential to discover even more connections, especially as K increases, as shown in Table 5.\nRemarkably, the LLM+RAG approach demonstrates strong potential in generating new links, even with a relatively small number of predictions per data point (e.g., @1). This observation aligns with recent research suggesting that LLMs are capable of proposing novel research ideas [24]. Many of the predicted links involve applying Machine Learning, Deep Learning, and various types of Neural Networks (e.g., GNN, RNN, GAN), as well as Reinforcement Learning, to address a wide range of scientific challenges.\nIn comparison, conventional link prediction methods like node2vec, which leverage cluster-level bipartite graph structures, exhibit high accuracy in identifying new links in the test data but show lower novelty compared to LLM+RAG. For instance, in the @1 predictions, the node2vec model successfully identifies 250 of the 254 new links (98.4%) that were also discovered by human researchers. The four remaining links, not identified by human researchers, include: Cardiac Pathophysiology \u2013 Matrix Factorization, Mycobacterium Tuberculosis \u2013 Contrastive Learning, Plant Stress Responses \u2013 Topological Data Analysis, and Prostate Cancer \u2013 Ensemble Learning. Some of these links have since been developed into publications [17, 18, 29, 33], highlighting the model's ability to suggest valuable connections ahead of human exploration."}, {"title": "6 Limitations, Challenges, and Future Work", "content": "Potential bias in data selection. Our analysis focuses on publications from leading science and AI venues, specifically top-tier journals and conferences. While this ensures high-quality and influential work, it introduces a selection bias that may overlook significant contributions from less prominent venues, potentially resulting in an incomplete representation of the AI4Science landscape. To mitigate this bias, future work could expand the dataset to include a broader range of publications. Given that our analysis framework is flexible and can easily accommodate new data sources, such an expansion would be a valuable direction for achieving a more comprehensive understanding of the AI4Science field.\nAbstract-based extraction. The extraction of scientific problems, Al methods, and Al usages in this study rely solely on paper titles and abstracts, due to limited access to full texts and cost considerations. This approach aligns with the existing AI4Science literature analysis efforts, which also focus on the title and abstract as in the metadata [5, 6]. While this method provides useful insights, it may miss important details present in the full text of publications. For example, when extracting the AI methods used in the AlphaFold paper [9], as illustrated in Fig. 1, GPT identifies only the general use of a Neural Networks approach from the abstract. However, the specific use of the backbone Transformer model is detailed in the full text. In future work, efforts can be directed toward incorporating full-text analysis to enrich the extracted content and capture more nuanced AI methodologies used in scientific research.\nThe definition of \"AI4Science\". There is no universally accepted standard for defining the boundaries of the broad terms \"AI\", \"science\", and \"AI4Science\", which presents a challenge for accurate classification. Previous studies have relied on keywords and human annotations [5, 6], but this method can overlook less-known techniques and lacks the ability to capture the full semantic space of AI methods used in science. In contrast, our approach leverages the knowledge and capabilities of LLMs to classify AI4Science work, with human verification on a small-scale subset. To foster more consistent and scalable analyses, the AI4Science community should work toward developing standardized classification guidelines for automatic large-scale literature analysis.\nEvaluation of link prediction. Another limitation of our study is the reliance on publication data as the ground truth for evaluating link prediction models. While this provides a reliable benchmark, it may not fully capture the breadth of potential AI4Science connections, and overlook novel or unconventional links that the models might suggest. Future work could consider incorporating more comprehensive evaluation strategies, such as expert reviews or real-world validation, to assess the effectiveness of the link predictions.\nLimited exploration in link prediction models. Our primary goal in this study is not to optimize the link prediction model, but rather to use link prediction as a lens to explore the potential of connecting Al methods and scientific problems. As a result, we only included a few link prediction models, leaving room for further research to improve the performance of AI4Science link prediction or building recommender systems for Al methods or scientific problems."}, {"title": "7 Conclusion", "content": "This paper aims to identify and bridge the gaps between Al and science in the context of AI4Science research. We introduce a comprehensive, large-scale dataset of AI4Science publications, with scientific problems and AI methods extracted using large language models (LLMs). Through quantitative analysis of this dataset, we uncover several key disparities: (1) Different AI and science sub-domains exhibit varying degrees of engagement in AI4Science research, leaving a substantial number of scientific problems and AI methods under-investigated; (2) The connectivity between scientific problems and AI methods is highly imbalanced, with certain nodes acting as \"hubs\" while other peripheral nodes are less connected; (3) The science and Al communities take distinct approaches to integrating AI into scientific research, prioritizing different problems and methods. We further investigate the potential and challenges of fostering AI4Science collaboration through the lens of link prediction. The experiment results demonstrate great opportunities for using link prediction models to explore the under-investigated scientific problems and AI methods, as well as discover novel connections. We anticipate that our findings and tools will provide valuable insights to enhance interdisciplinary collaboration and accelerate scientific discovery through the integration of AI."}, {"title": "3.4 Dataset Overview and the Bipartite Graph", "content": "Through LLM-based extraction and semantic clustering, we form a comprehensive dataset, \\(D = {\\{(p_i, P_i, m_i, M_i, u_i)\\}}_{i=1}^N\\), which includes the scientific problems, AI methods, their corresponding cluster labels, and the usage of Al for science. The basic statistics of this dataset are listed in Table 1.\nTo better illustrate the connections between Al and science, we construct a bipartite graph based on the clusters. In this bipartite graph, scientific problem clusters and AI method clusters represent two types of nodes, and the publications act as edges connecting them. Formally, the graph is defined as \\(G = (V, 8)\\), where \\(V = {P_i} \\cup {M}\\) and \\(E = D\\). As shown in Fig. 2(a), the graph provides an intuitive visual representation of how Al is linked to scientific challenges and vice versa."}, {"title": "5.1 Methodology", "content": "In the curated AI4Science dataset \\(D = {\\{(p_i, P_i, m_i, M_i, u_i)\\}}_{i=1}^N\\), the extracted and clustered scientific problems \\({p_i}\\) and \\({P_i}\\), as well as Al methods \\({m}\\) and \\({M}\\), represent the respective landscapes of these two domains. The AI4Science publications, along with their descriptions of Al usage \\({u}\\), highlight the connections between scientific challenges and AI methods. To model these connections, we employ the link prediction formulation."}, {"title": "5.2 Overall Link Prediction Results", "content": "all(x, y) = \\(\\sum_{l=1}^{\\infty} a^l (A^l)_{xy}\\) \\(1\\)"}, {"title": "5.3 Prediction in the Well- and Under-investigated Regions", "content": "Precision := \\(\\frac{\\{p \\in T(s) | p\\in P(s)\\}|}{K}\\) \\(2\\)\nRecall := \\(\\frac{\\{t \\in P(s) | t \\in T(s)\\}|}{|T(s)|}\\) \\(3\\)"}]}