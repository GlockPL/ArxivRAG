{"title": "Towards Safer Heuristics With XPlain", "authors": ["Pantea Karimi", "Solal Pirelli", "Siva Kesava Reddy Kakarla", "Ryan Beckett", "Santiago Segarra", "Beibin Li", "Pooria Namyar", "Behnaz Arzani"], "abstract": "Many problems that cloud operators solve are computationally expensive, and operators often use heuristic algorithms (that are faster and scale better than optimal) to solve them more efficiently. Heuristic analyzers enable operators to find when and by how much their heuristics underperform. However, these tools do not provide enough detail for operators to mitigate the heuristic's impact in practice: they only discover a single input instance that causes the heuristic to underperform (and not the full set) and they do not explain why.\nWe propose XPlain, a tool that extends these analyzers and helps operators understand when and why their heuristics underperform. We present promising initial results that show such an extension is viable.", "sections": [{"title": "1 Introduction", "content": "Operators use heuristics (approximate algorithms that are faster or scale better than their optimal counterparts) in production systems to solve computationally difficult or expensive problems. These heuristics perform well across many typical instances, but they can break in unexpected ways when network conditions change [5, 6, 16, 35]. Our community has developed tools that enable operators to identify such situations [1, 2, 6, 16, 35]. These tools find the \u201cperformance gap\" of one heuristic algorithm compared to another heuristic or the optimal \u2013 they identify an example instance of an input which causes a given heuristic to underperform.\nFor example, MetaOpt [35] describes a heuristic deployed in Microsoft's wide area traffic engineering solution and shows it could underperform by 30% (see \u00a72). This means the company would either have to overprovision their networks to support 30% more traffic, drop that traffic, or delay it.\nThe potential benefit of heuristic analyzers is clear: they allow operators to quantify the risk of heuristics they want to deploy. Although these heuristic analyzers have already shed light on the performance gap of many deployed heuristics, they are still in their nascent stage and have limited use for operators who do not have sufficient expertise in formal methods and/or optimization theory. There are crucial features missing: operators have to (1) model the heuristics they want to analyze in terms of mathematical constructs these tools can support and (2) manually analyze the outputs from these tools to understand how to fix their heuristics or their scenarios the tool only provides a performance gap and an example input that caused it. They do not produce the full space of inputs that can cause large gaps nor describe why the heuristic underperformed in these instances.\nThe latter problem limits the operator's ability to use the output of these tools to fix the problem and to either improve the heuristic, create an alternative solution for when it underperforms, or cache the optimal solution for those instances. In our earlier examples, the operator has to look at the tool's example demand matrix to understand why the heuristic routes 30% less traffic than the optimal.\nThe state of these heuristic analyzers today is reminiscent of the early days of our community's exploration of network verifiers and their potential to help network operators configure and manage their networks. In the same way that network verifiers enabled operators to identify bugs in their configurations [10, 14, 15, 19, 22, 24, 27, 28, 30, 32, 39, 47, 49], a heuristic analyzer can help them find the performance gap of the algorithms they deploy. Tools that allow operators to leverage heuristic analyzers more easily, identify why the heuristics underperform, and devise solutions to remediate the issue serve a similar purpose to the tools our community crafted that explained the impact of configuration bugs [23, 25, 39, 40]"}, {"title": "2 What is heuristic analysis?", "content": "Heuristic analyzers [1, 16, 35] take a heuristic model and a benchmark model (e.g., the optimal) as input. Their goal is to characterize the performance gap of the heuristic compared to the benchmark. Recent tools [16, 35] use optimization theory or first-order logic to solve this problem and return a single input instance that causes the heuristic to underperform.\nExample heuristics from these work include:\nDemand Pinning (DP) was deployed in Microsoft's wide area network. DP is a heuristic for the traffic engineering problem. The optimal algorithm assigns traffic (demands) to paths and maximizes the total flow it routes through the network without exceeding the network capacity. Operators use DP to reduce the size of the optimization problem they solve. DP first filters all demands below a pre-defined threshold and routes them through (pins them to) their shortest path. It then routes the remaining demands optimally using the available capacity (see Fig. 1).\nMetaOpt authors modeled DP directly as an optimization problem. They also provided a number of helper functions that allow operators to model it more easily (Fig. 1b). MetaOpt solves a bi-level optimization that produces the performance gap and demand that causes it (the flow in Fig. 1a). It is easy to see what is missing: it is up to the operator to examine the single output and find why DP underperformed. DP is amenable to such manual analysis (see [35]), but not all heuristics are. It is also hard for operators to extrapolate from this example adversarial input and find all other regions of the input space where DP may underperform. These limitations are exacerbated as we move to larger problems with more demands, where it is harder to pinpoint how a heuristic's decision to route a particular demand interferes with its ability to route others.\nVector bin packing (VBP) places multi-dimensional balls into multi-dimensional bins and minimizes the number of bins in use. Operators use VBP in many production systems, such as to place VMs onto servers [9].\nThe VBP problem is APX-hard [45]. One heuristic that solves VBP is first-fit (FF), which greedily places an incoming ball in the first bin it fits in. Fig. 1c shows how we can encode it in MetaOpt.\nMetaOpt produces the adversarial ball sizes 1%, 49%, 51%, 51% (as a percentage of the bin size) for an example with 4 balls and 3 equal-sized bins (we use single-dimensional balls) the optimal uses 2 bins while FF uses 3 (we show a more complex version in Fig. 2). Once again, operators have to reason through this example to identify why FF underperforms and what other inputs cause the same problem. This is harder in FF and other VBP heuristics, such as best fit or first fit decreasing, as evidenced by the years of research by theoreticians in this space [36].\nIn this paper, we use the DP and VBP as running examples. These examples are representative of the heuristics prior work has studied [16, 35] (the scheduling examples Virley studies are conceptually similar to VBP, and we think our discussions directly translate to those use-cases).\nPrior work [5] shows that, using a single adversarial instance, it is difficult to understand why a heuristic underperformed. It is even harder to generalize from why an adversarial input causes the heuristic to underperform on a single problem instance (or a few instances) to what properties in the input and the problem instance cause it to underperform."}, {"title": "3 The case for comprehensive analysis", "content": "Prior work [2, 5, 35] show explaining adversarial inputs can have benefits: we can improve DP's performance gap by an order of magnitude and produce congestion control algorithms that meet pre-specified requirements [2]. But these results require manual analysis [35] or problem-specific models [2, 5]. We see an opportunity for a new tool that enables operators to identify the full risk surface of the heuristic (the set of inputs where the heuristic underperforms) and to identify"}, {"title": "4 Challenges", "content": "It is hard to arrive at low-level models of a heuristic in order to use existing analyzers [2, 16, 35], and operators need to have expertise in either formal methods [2, 16] or optimization theory [12, 35] to do so. We see an analogy with writing imperative programs in assembly code: we can write any program in assembly but it takes time, has a high risk of being buggy, and makes code reviews (i.e., explanations) difficult.\nLow-level models operate over variables and constructs that are often hard to connect to the original problem (\u201cGreek letters\" and \"auxiliary variables\" instead of \"human-readable\u201d text). To model the first fit behavior, MetaOpt uses an auxiliary, binary variable $a_{ij}$ that captures whether bin j is the first bin where ball i fits in, and sets its value through:\n$\\begin{aligned} &\\sum_{j\\in BINS} dij \\leq f_{ij} + \\sum\\{k\\in BINS|k &< j\\} (1 - f_{ik}) \\\\ &\\sum_{j} dij == 1 \\quad \\forall i \\in BALLS, \\forall j \\in BINS \\end{aligned}$\nIt is hard to derive an explanation from such a model and harder still to connect it to how the heuristic works to explain its behavior. We need a better and more descriptive language to encode the behavior of the heuristic. We also need to:\nFind adversarial subspaces and validate them. These are subspaces of the input space where the inputs that fall in those"}, {"title": "5 The XPlain proposal", "content": "We propose XPlain (Fig. 3). Users describe the heuristic and benchmark through its domain specific language (\u00a75.1). The main purpose of this domain-specific language (DSL) is to concretely define the behavior of the heuristic and benchmark, which allows automated systems to analyze, compare, and explain their behavior. The compiler translates the DSL into low-level optimization constructs.\nThe adversarial subspace generator($\\S$5.2) generates a set of contiguous subspaces where the inputs in each subspace cause the heuristic to underperform and the significance checker filters the outputs and ensures the subspaces are statistically significant - it checks that the inputs that fall into these subspaces produce higher gaps compared to those that do not with statistical significance.\nThe explainer (\u00a75.3) describes how the heuristic's actions differ from the benchmark in each contiguous subspace for a given problem instance. The generalizer (Fig. 5.2) extrapolates from these instance-based observations to produce the properties of the inputs and the instance that cause the heuristic to underperform. It uses instance-based explanations across many instances to do so we use the instance generator to create such instances."}, {"title": "5.1 The domain-specific language", "content": "To auto-generate the information we described in \u00a73 we need a DSL to concretely encode the heuristic and benchmark algorithms. We need a DSL that: (1) can represent diverse heuristics; (2) we can use to automatically compile into optimizations that we can efficiently solve (those that existing solvers support and that do not introduce too many additional constraints and variables compared to hand-written models); and (3) is easy and intuitive to use.\nWe design an abstraction based on network flow problems [11]. Network flow problems are optimizations that, given a set of sources and destinations, optimize how to route traffic to respect capacity constraints, maximize link utilization, etc. Network flow problems impose two key constraints: the total flow on each link should be below the link capacity, and what comes into a node should go out (flow conservation).\nThere are advantages to using network flow problems: they have an intuitive graph representation [11] operators know how to reason about the flow of traffic through such graphs; we can easily translate them into convex optimization or feasibility problems [11]; and they have many variants which we can use and build upon.\nWe can use the network flow model and extend it through a set of new \"node behaviors\" to ensure we can apply it to a broad class of heuristics. Node behaviors are a set of constraints that operate on the flows coming in and going out of each node: \"split nodes\" (enforce flow conservation constraints); \"pick nodes\" (enforce flow conservation constraints but only allow flow on a single outgoing edge); \"copy nodes\u201d (copy the flow that comes in onto all of their outgoing edges); \"source\" and \"sink\" nodes (produce or consume traffic); etc. A node can enforce multiple behaviors simultaneously. We include node behaviors that do not enforce flow conservation constraints (such as the \"copy nodes\") or capacity constraints by default so that we can model a broad set of heuristics.\nUsers can also add metadata to each node or edge, which we can use later to improve the explanations we produce.\nUsers encode the problem, the heuristic, and the benchmark in the DSL in abstract terms. For example, to model VBP they specify that the problem operates over (abstract) sequences of different node types that correspond to the balls and bins in the VBP problem. Users also encode the actions the heuristic and the optimal can make in terms of the relationship between the different sequences of nodes and the edges that connect them and rules that govern how flow can traverse from one node to the next. To analyze a specific instance of the VBP problem, users input the number of balls and bins and then XPlain concretizes the encoding (we show a concretized example with 4 one-dimensional balls and 3 bins in Fig. 4b).\nOur DSL allows us to model the examples from prior work. We can model DP with split, source, and sink nodes (Fig. 4a),"}, {"title": "5.2 The adversarial subspace generator", "content": "Random search cannot find adversarial subspaces (it may not even find an adversarial point [35]). We propose an algorithm where we extrapolate from the heuristic analyzer's output and: (1) use the analyzer to find an adversarial example; (2) find the adversarial subspace around that example; (3) exclude that subspace and repeat until we can no longer find an adversarial example (where the heuristic significantly underperforms) outside all of the subspaces we have found so far."}, {"title": "5.3 The explainer", "content": "We hypothesize that the inputs in a contiguous subspace share the same root cause for why they cause the heuristic to underperform. This is where a network-flow-based DSL explicitly encoding the decisions of the heuristic and the benchmark algorithm proves useful. We run samples from within each contiguous subspace through the DSL and score edges based on if: (1) both the benchmark and the heuristic send flow on that edge (score = 0); (2) only the benchmark sends flow (score = 1); or (3) only the heuristic sends flow (score = -1). Such a \"heatmap\" of the differences between the benchmark and the heuristic shows how inputs in the subspace interfere with the heuristic. In Fig. 4a, in a given subspace with 3000 samples, all pinnable demands share the same shortest path (red arrows in 1-2-3 path), and the optimal routes them through alternative paths (blue arrows in 1-4-5-3 path).\nOpen questions. As the instance size (the scale of the problem we want to analyze) grows, the above heatmap may become harder to interpret. We need mechanisms that allow us to summarize the information in this heatmap in a way that the user can interpret and use to improve their heuristic.\nThe heuristic and benchmark also differ in how much flow they route on each edge. We need to define the appropriate data structure to represent this information to a user so that they are interpretable and actionable."}, {"title": "5.4 The generalizer and instance generator", "content": "We can enable operators to improve their heuristics or know when to apply mitigations if we can extrapolate from the type 1 and 2 explanations to form type 3: what properties in the adversarial inputs cause the heuristic to underperform and what aspects of the problem instance exacerbate it? We"}, {"title": "A Formalizing XPlain's DSL", "content": "We prove that we can model any linear optimization in XPlain."}, {"title": "A.1 XPlain's node description", "content": "PRELIMINARIES. Our network-flow-based DSL is a directed graph where we denote the set of nodes with N and the set of directed edges as $\\mathscr{E}$. We treat each edge $(i, j) \\in \\mathscr{E}$ as a variable with a non-negative flow value $f_{(i,j)} \\geq 0$. We impose constraints on these flow variables as needed. We define incoming edges to node $n \\in N$ as those edges which are directed towards $n$ (i.e., $(i,n) \\in \\mathscr{E}$). Outgoing edges are those exiting $n$. The incoming (outgoing) traffic to a node is the sum of all flow that arrives at that node from all the incoming (outgoing) edges.\nWe have the following node behaviors:\nSPLIT NODES ($N_{split}$) split the incoming traffic between the outgoing edges (Fig. 6a). They enforce the traditional flow conservation constraints:\n$\\sum_{\\{i\\in N,(i,n) \\in \\mathscr{E}\\}} f_{(i,n)} = \\sum_{\\{i\\in N,(n,i) \\in \\mathscr{E}\\}} f_{(n,i)} \\quad \\forall n \\in N_{split}$\nThey can also optionally enforce (1) an upper bound on the traffic on an outgoing edge (capacity constraint) and (2) the traffic on an incoming edge to be constant.\n$\\begin{aligned} &f_{(n,i)} \\leq C_{(n,i)} \\quad C_{(n,i)} \\in \\mathbb{R}^+, \\forall i \\in \\{i \\in N, (n, i) \\in \\mathscr{E}\\} \\\\ &f_{(i,n)} = d_{(i,n)} \\quad d_{(i,n)} \\in \\mathbb{R}^{\\geq 0}, \\forall i \\in \\{i \\in N, (i,n) \\in \\mathscr{E}\\} \\end{aligned} \\quad n \\in N_{split}$\nPICK NODES ($N_{pick}$) satisfy flow conservation but only allow one of the outgoing edges to carry traffic (Fig. 6b):\n$\\begin{aligned} &\\sum_{\\{i\\in N,(i,n) \\in \\mathscr{E}\\}} f_{(i,n)} = \\sum_{\\{i\\in N,(n,i) \\in \\mathscr{E}\\}} f_{(n,i)} \\quad \\forall n \\in N_{pick} \\\\ &\\sum_{\\{i\\in N,(n,i) \\in \\mathscr{E}\\}} \\mathbb{1}[f_{(n,i)} > 0] = 1 \\quad \\forall n \\in N_{pick} \\end{aligned}$\nwhere $\\mathbb{1}[x > 0]$ is an indicator function (=1 if $x > 0$, otherwise = 0).\nMULTIPLY NODES ($N_{mult}$) only have one incoming and one outgoing link. They multiply the incoming traffic by a constant $C \\in \\mathbb{R}^+$ before sending it out (Fig. 6c). They only satisfy flow conservation when $C = 1$.\n$f_{(n,i)} = C f_{(j,n)} \\quad \\forall (i, j) \\in \\{(i, j) | i, j \\in N, (n, i), (j, n) \\in \\mathscr{E}\\} \\quad \\forall n \\in N_{mult}$\nALL EQUAL NODES ($N_{alleq}$) require all the incoming and outgoing edges to carry the same amount of traffic (Fig. 6d):\n$f_{(n,i)} = f_{(j,n)} \\quad \\forall (i, j) \\in \\{(i, j) | i, j \\in N, (n, i), (j, n) \\in \\mathscr{E}\\} \\quad \\forall n \\in N_{alleq}$\nTo make it simpler to encode a heuristic in the DSL, we also add the following node types to our DSL:\nCOPY NODES ($N_{copy}$) copy the total incoming flow into each outgoing edge (Fig. 6e):\n$f_{(n,j)} = \\sum_{\\{i\\in N, (i,n) \\in \\mathscr{E}\\}} f_{(i,n)} \\quad \\forall j\\in \\{j | j \\in N, (n, j) \\in \\mathscr{E}\\} \\quad \\forall n \\in N_{copy}$"}, {"title": "A.2 XPlain can model any linear optimization", "content": "THEOREM A.1. We can model any linear optimization (linear programming or mixed integer linear programming) as a flow network using the six node behaviors ($N_{split}, N_{pick}, N_{mult}, N_{alleq}$, and $N_{sink}$)\nPROOF. An optimization problem maximizes (or minimizes) an objective subject to inputs that fall within a feasible space that the optimization constraints characterize. We can express a linear optimization problem as (linear programming or mixed integer linear programming):\n$\\begin{aligned} &\\underset{x,y}{\\text{max}} \\quad cx + c_{y} \\\\ &A_{x}x + A_{y}y \\leq b \\\\ &x \\geq 0 \\\\ &y \\in \\{0,1\\}^{|y|} \\end{aligned}$\nTo show that our DSL is complete, we need to show that we can capture both the feasible space and the objective correctly through our flow model for every possible linear optimization.\nWe first present a general algorithm to express the feasible space of any given linear optimization as a flow model and prove it is correct. Next, we show how we can use the same algorithm to express any linear objective.\nHow to represent the feasible space with a flow model. We can express the feasible space of any linear optimization as:\n$\\begin{aligned} &A_{x}x + A_{y}y \\leq b \\\\ &x \\geq 0 \\\\ &y \\in \\{0,1\\}^{|y|} \\end{aligned}$\nwhere we denote matrices and vectors in bold. $x$ and $y$ are vectors of continuous and binary variables of size $|x| \\times 1$ and $|y|\\times1$, respectively. $b$ is a constant vector of size $|b| \\times 1$. $A_{x}$ and $A_{y}$ are constant matrices of sizes $|b| \\times |x|$ and $|b|\\times |y|$ respectively. Note that we can enforce an equality constraint as two inequality constraints (Eq. 1), and represent any integer variable as the sum of multiple binary variables. We map the variables to flows in our model.\nWe need to transform the above optimization before we can model it with our node behaviors:\n$\\blacktriangleright$ Transformation 1. The matrices $A_{x}$ and $A_{y}$, and the vector $b$ may contain negative entries. This conflicts with the non-negativity requirement of the flows in our flow model. To address this, we decompose these matrices and vector into their positive and negative components:\n$A_{x} = A_{x}^{+} - A_{x}^{-}, A_{y} = A_{y}^{+} - A_{y}^{-}, b = b^{+} - b^{-}$ where all the elements in $A^{+}_{x} = [a^{+,x}_{ij}]$ and $A^{-}_{x} = [a^{-,x}_{ij}]$ are non-negative such that at most one of $a^{+,x}_{ij}$ or $a^{-,x}_{ij}$ is non-zero for every $i \\in \\mathbb{Z}[0,|b|)$ and $j\\in \\mathbb{Z}[0,|x|)$. Note that $\\mathbb{Z}[0,m) = \\{0,..., m - 1\\}$. Same holds for both (1) $A^{-}_{y}$ and $A^{+}_{y}$, and (2) $b^{+} = [b^{+}_{i}]$ and $b^{-} = [b^{-}_{i}]$ over every $i$. All matrices have the same size as their originating matrix. After substituting these decompositions into Eq. 1, we have:\n$A_{x}^{-}x + A_{y}^{-}y + b^{-} \\leq A_{x}^{+}x + A_{y}^{+}y + b^{+}$\n$\\blacktriangleright$ Transformation 2. Eq. 4 and SPLIT NODES qualitatively represent similar behaviors. SPLIT NODES split the incoming traffic across outgoing edges and ensure the traffic on each edge does not exceed the capacity constraints. Ideally, we can"}]}