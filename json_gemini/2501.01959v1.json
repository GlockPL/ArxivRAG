{"title": "STEAM-EEG: Spatiotemporal EEG Analysis with Markov Transfer Fields and\nAttentive CNNS", "authors": ["Jiahao Qin", "Feng Liu"], "abstract": "Electroencephalogram (EEG) signals play a pivotal role\nin biomedical research and clinical applications, includ-\ning epilepsy diagnosis, sleep disorder analysis, and brain-\ncomputer interfaces. However, the effective analysis and\ninterpretation of these complex signals often present sig-\nnificant challenges. This paper presents a novel approach\nthat integrates computer graphics techniques with biolog-\nical signal pattern recognition, specifically using Markov\nTransfer Fields (MTFs) for EEG time series imaging. The\nproposed framework (STEAM-EEG) employs the capabil-\nities of MTFs to capture the spatiotemporal dynamics of\nEEG signals, transforming them into visually informative\nimages. These images are then rendered, visualised, and\nmodelled using state-of-the-art computer graphics tech-\nniques, thereby facilitating enhanced data exploration, pat-\ntern recognition, and decision-making. The code could be\naccessed from GitHub.", "sections": [{"title": "1. Introduction", "content": "Electroencephalogram (EEG) signals play a crucial role\nin neuroscience, clinical diagnosis, and brain-computer in-\nterfaces due to their non-invasive nature and high tempo-\nral resolution [1, 2, 10, 12]. However, EEG signal anal-\nysis presents significant challenges owing to its complex,\nnon-stationary nature, and the presence of noise and arti-\nfacts. Traditional approaches, relying on manual feature\nengineering and conventional machine learning algorithms\n[3, 18, 23, 35], often fail to capture the intricate spatiotem-\nporal dynamics inherent in EEG signals. Recent advance-\nments in deep learning, particularly convolutional neural\nnetworks (CNNs), have revolutionized this field by au-\ntomatically learning hierarchical representations from raw\ndata [27, 42, 45], addressing many limitations of traditional\nmethods.\nThe evolution of EEG signal analysis has seen the in-\ntegration of various advanced techniques. Attention mech-\nanisms have been introduced to focus on relevant parts of\nthe input signal, enhancing the model's ability to capture\ncritical information [8, 33, 36]. Markov Transfer Fields\n(MTFs) have demonstrated promise in modeling complex\nspatiotemporal patterns, providing a more comprehensive\nrepresentation of EEG dynamics [6, 26, 46]. Additionally,\nSingular Spectrum Analysis (SSA) has been employed to\ndecompose EEG signals into trend, seasonal, and noise\ncomponents, facilitating more nuanced feature extraction\n[20,21,29,41,43].\nDespite these advancements, there remains a need for a\ncomprehensive approach that effectively integrates these di-\nverse techniques to address the multifaceted challenges of\nEEG signal analysis. To address this gap, we propose a\nnovel framework that combines Trend-Seasonal Decompo-\nsition using SSA, parallel 1D-CNNs with modified attention\nmechanisms, and MTF imaging. This approach integrates"}, {"title": "2. Related Work", "content": "EEG signal analysis has evolved from traditional time-\ndomain and frequency-domain techniques [11, 15, 38] to\nmore sophisticated machine learning approaches. Support\nvector machines, k-nearest neighbors, and decision trees\nhave shown promise in various EEG classification tasks\n[27, 42, 45], enhancing diagnostic accuracy [34, 44]. Re-\ncent years have seen a shift towards deep learning, particu-\nlarly convolutional neural networks (CNNs). These models\nhave achieved state-of-the-art performance in seizure detec-\ntion [27, 45], emotion recognition [3, 17], and motor im-\nagery classification [7, 13]. To address temporal dependen-\ncies, attention mechanisms have been integrated into EEG\nanalysis models [8, 9, 19, 30, 32, 33, 36], allowing for focus\non relevant signal components.\nMarkov Transfer Fields (MTFs) have emerged as a pow-\nerful tool for capturing complex spatiotemporal patterns\nin EEG data [6, 14, 26, 46]. Concurrently, Singular Spec-\ntrum Analysis (SSA) has been employed to decompose\nEEG signals, facilitating more refined feature extraction\n[20, 21, 29, 41, 43]. Visualization techniques have also\nplayed a crucial role in EEG analysis. Topographic maps\n[16, 40], connectivity graphs [28, 39], and 3D brain mod-\nels [5, 37] have enhanced the interpretability of EEG data\nand analysis results.\nDespite these advancements, there remains a need for\ncomprehensive approaches that effectively integrate ad-\nvanced signal processing, deep learning, and visualization\ntechniques. Our work addresses this gap by combining\nSSA, attention-enhanced CNNs, and MTF imaging for im-\nproved EEG signal analysis."}, {"title": "3. Methodology", "content": "In this section, we present the proposed methodology\nfor enhancing EEG signal analysis through the integration\nof Trend-Seasonal Decomposition using Singular Spectrum\nAnalysis (SSA), parallel 1D Convolutional Neural Net-\nworks (1D-CNNs) with modified attention mechanisms,\nand Markov Transfer Field (MTF) imaging. The overall ar-\nchitecture of the proposed approach is illustrated in Figure\n2."}, {"title": "3.1. Trend-Seasonal Decomposition using Singular\nSpectrum Analysis", "content": "The first step in our approach is to decompose the raw\nEEG time series into trend, seasonal, and noise components\nusing Singular Spectrum Analysis (SSA). SSA is a powerful\ntechnique for analyzing and decomposing time series data,\ncapturing the underlying temporal structure and separating\ndifferent components.\nLet X = (x1,x2,..., XN) be the raw EEG time series\nof length N. The SSA algorithm consists of the following\nsteps:\n1. Embedding: Create a trajectory matrix Y by sliding a\nwindow of length L over the time series X:\n$$Y =\\begin{bmatrix}\nX1 & X2 & ... & XK\\nX2 & X3 & ... & XK+1\\n: & : & ... & :\\nXL & XL+1 & ... & XN\\n\\end{bmatrix}$$,\nwhere K = N -L +1.\n2. Singular Value Decomposition (SVD): Perform SVD\non the trajectory matrix Y:\n$$Y = U\\Sigma VT$$,\nwhere U and V are orthogonal matrices, and \u2211 is a\ndiagonal matrix containing the singular values."}, {"title": "3. Grouping", "content": "Group the singular values and correspond-\ning eigenvectors into distinct components based on\ntheir significance and similarity. Let I1, I2, ..., Im be\nthe indices of the grouped components."}, {"title": "4. Reconstruction", "content": "Reconstruct the time series compo-\nnents using the grouped eigenvectors and singular val-\nues:\n$$X = \\sum_{i \\in Ik} U_i \\sigma_i V_i^T$$,\nwhere Xk represents the reconstructed component se-\nries, U and Vi are the i-th columns of U and V, re-\nspectively, and \u03c3\u03b5 is the i-th singular value.\nBy applying SSA to the raw EEG time series, we obtain\nthree reconstructed component series: trend (Xtrend), sea-\nsonal (Xseasonal), and noise (Xnoise). These component se-\nries capture different temporal patterns and characteristics\nof the EEG signal, providing a more refined representation\nfor subsequent analysis."}, {"title": "3.2. Parallel 1D Convolutional Neural Networks\nwith Modified Attention Mechanisms", "content": "The decomposed EEG component series are then fed\ninto parallel 1D Convolutional Neural Networks (1D-\nCNNs) to learn discriminative features for EEG signal anal-\nysis. We propose a modified attention mechanism that cap-\ntures cross-channel dependencies and enhances the feature\nlearning capabilities of the 1D-CNNs.\nLet Xtrend, X seasonal, and noise denote the trend, sea-\nsonal, and noise component series for EEG channel c, re-\nspectively. Each component series is processed by a sepa-\nrate 1D-CNN, which consists of multiple convolutional lay-\ners followed by pooling layers and fully connected layers.\nThe 1D convolution operation for the l-th layer of the\n1D-CNN can be expressed as:\n$$h = f(Whi^{l-1} + b_l)$$,\nwhere he is the output feature map of the l-th layer for\nchannel c, Wi and by are the learnable weights and biases\nof the l-th layer, * denotes the convolution operation, and\nf() is the activation function, such as ReLU."}, {"title": "To capture the cross-channel dependencies", "content": "To capture the cross-channel dependencies, we intro-\nduce a modified attention mechanism that computes atten-\ntion weights based on the feature maps from all EEG chan-\nnels. Let H\u2081 = [h], h?,..., h] be the concatenated fea-\nture maps from all channels at the l-th layer, where C is the\ntotal number of EEG channels. The attention weights are\ncomputed as:\n$$A_l = softmax(W_a tanh(W_h H_l + b_h))$$,\nwhere Wa and Wh are learnable weight matrices, bh is\na learnable bias vector, and softmax(\u00b7) is the softmax func-\ntion that normalizes the attention weights.\nThe attended feature maps \u0124\u012b are obtained by element-\nwise multiplication of the attention weights with the origi-\nnal feature maps:\n$$\\tilde{H}_l = A_l H_l$$,\nwhere \u2299 denotes element-wise multiplication.\nThe attended feature maps \u0124\u012b are then passed through\nthe subsequent layers of the 1D-CNN for further feature ex-\ntraction and classification. The modified attention mecha-\nnism allows the 1D-CNN to focus on relevant channels and\ncapture cross-channel dependencies, enhancing the discrim-\ninative power of the learned features."}, {"title": "3.3. Markov Transfer Field Imaging", "content": "To model the spatiotemporal dynamics of EEG signals\nand generate informative visual representations, we employ\nMarkov Transfer Field (MTF) imaging. MTF is a proba-\nbilistic graphical model that captures the spatial and tempo-\nral dependencies among different regions of the EEG signal.\nLet S = {$1, $2,..., SM } be a set of M spatial regions\ndefined on the EEG electrode layout. Each region si is as-\nsociated with a state variable xi that represents the activity\nlevel of the region at a given time point. The MTF model\ndefines a joint probability distribution over the state vari-\nables:\n$$P(x) = \\frac{1}{Z} exp\\Big(-\\sum_{i=1}^M \\phi_i(x_i) - \\sum_{(i,j) \\in E} V_{ij}(x_i, x_j)\\Big)$$,\nwhere x = [x1,x2,...,XM] is the state vector, Z is a\nnormalization constant, di(xi) is the unary potential func-\ntion that captures the local evidence for the state of region\nSi, Vij (xi, xj) is the pairwise potential function that models\nthe interaction between regions si and sj, and & is the set\nof edges in the MTF graph representing the spatial relation-\nships between regions.\nThe unary potential function $r(xi) is defined based on\nthe features extracted from the corresponding EEG region\nusing the parallel 1D-CNNs:\n$$\\Phi_i(x_i) = -w f_i(x_i)$$,\nwhere wi is a learnable weight vector and fi (xi) is the\nfeature vector extracted from region si.\nThe pairwise potential function Vij (xi, xj) is defined to\nencourage smoothness and consistency among neighboring\nregions:\n$$V_{ij}(x_i, x_j) = B_{ij} (x_i \u2013 x_j)^2$$,\nwhere Bij is a learnable parameter that controls the\nstrength of the interaction between regions si and sj.\nInference in the MTF model is performed using belief\npropagation to estimate the marginal probabilities of the\nstate variables. The inferred marginal probabilities provide\na measure of the activity level and spatial distribution of the\nEEG signal at each time point.\nTo generate visual representations of the EEG patterns,\nwe map the inferred marginal probabilities onto a 2D to-\npographic map of the EEG electrode layout. The resulting\nMTF images highlight the active regions and their spatial re-\nlationships, providing an intuitive visualization of the EEG\nsignal dynamics."}, {"title": "3.4. Two-dimensional Residual Convolutional Neu-\nral Network with Cross-Channel Split Atten-", "content": "After obtaining the MTF images that capture the spa-\ntiotemporal dynamics of the EEG signals, we employ a two-\ndimensional residual convolutional neural network (2D-\nResNet) with cross-channel split attention to extract dis-\ncriminative features from these images. The 2D-ResNet ar-\nchitecture is well-suited for processing image data and has\ndemonstrated excellent performance in various computer\nvision tasks. The 2D-ResNet consists of multiple residual\nblocks, each containing convolutional layers, batch normal-\nization, and activation functions. The residual connections\nallow the network to learn residual mappings and facilitate\nthe flow of information through the network. Figure 3 illus-\ntrates the architecture of the 2D-ResNet with cross-channel\nsplit attention. Let I \u2208 RH\u00d7W\u00d7C denote the input MTF\nimage, where H, W, and C represent the height, width, and\nnumber of channels, respectively. The 2D convolution op-\neration for the l-th layer of the 2D-ResNet can be expressed\nas:\n$$X_l = f(W_l * X_{l-1} + b_l)$$,\nwhere X is the output feature map of the l-th layer, W\u2081 and\nby are the learnable weights and biases of the l-th layer, *\ndenotes the convolution operation, and f(\u00b7) is the activation\nfunction, such as ReLU. To capture cross-channel depen-\ndencies and enhance the feature extraction capabilities of\nthe 2D-ResNet, we introduce a cross-channel split attention\nmechanism. The attention mechanism allows the network to"}, {"title": "focus on relevant channels and spatial regions of the MTF\nimages", "content": "Let X\u2081 = [x},x},...,xf] be the feature maps of\nthe l-th layer, where x \u2208 RHiWi represents the feature\nmap for channel c. The cross-channel split attention mech-\nanism computes attention weights for each channel based\non the feature maps from all channels:\n$$a_l = softmax(W_a tanh(W_x X_l + b_x))$$,\nwhere al \u2208 RC is the attention weight vector for the l-th\nlayer, Wa and W are learnable weight matrices, b is a\nlearnable bias vector, and softmax(\u00b7) is the softmax function\nthat normalizes the attention weights. The attended feature\nmaps X are obtained by element-wise multiplication of the\nattention weights with the original feature maps:\n$$x = a_l x_i$$,\nwhere af is the attention weight for channel c in the l-th\nlayer, and \u2299 denotes element-wise multiplication. The at-\ntended feature maps \u0160\u012b are then passed through the subse-\nquent layers of the 2D-ResNet for further feature extraction\nand classification. The cross-channel split attention mech-\nanism enables the network to adaptively focus on relevant\nchannels and spatial regions, enhancing the discriminative\npower of the learned features."}, {"title": "4. Results", "content": "To evaluate the performance of our proposed STEAM-\nEEG model, we utilized a comprehensive selection of EEG\nclassification datasets from the UCR [4] Time Series Clas-\nsification Archive. This archive is widely recognized in\nthe time series analysis community and provides a diverse\nrange of EEG datasets, each presenting unique challenges\nand characteristics."}, {"title": "4.2. Baselines", "content": "To evaluate the effectiveness of our proposed approach,\nwe compared it with several state-of-the-art methods for\nEEG signal analysis:\n\u2022 FCNN: A fully convolutional neural network approach\nproposed by [24] for EEG decoding and visualization.\n\u2022 EEGNet: A compact convolutional neural network ar-\nchitecture designed specifically for EEG-based brain-\ncomputer interfaces [25].\n\u2022 DeepConvNet: A deep convolutional network archi-\ntecture for EEG-based movement decoding [22].\n\u2022 STFT-CNN: A method combining short-time Fourier\ntransform and convolutional neural networks for EEG\nclassification [31].\nThese baselines represent a diverse range of approaches\nin EEG signal analysis, from traditional machine learning\nmethods to advanced deep learning architectures."}, {"title": "4.3. Evaluation Metrics", "content": "To comprehensively evaluate the performance of our\nproposed approach, we employed two key metrics. First, we\nused accuracy, which represents the proportion of correct\npredictions among the total number of cases examined. This\nmetric provides a straightforward measure of overall perfor-\nmance. Additionally, we calculated the F1-score, which is\nthe harmonic mean of precision and recall. The F1-score\noffers a balanced measure of the model's performance, par-\nticularly useful in cases where class distribution may be un-\neven. These metrics together provide a robust assessment of\nour model's effectiveness across various EEG classification\ntasks."}, {"title": "4.4. Classification Performance", "content": "Table 1 presents the classification performance of the\nproposed approach compared to the baseline methods\nacross different EEG datasets.\nThe results demonstrate that our proposed approach\nconsistently outperforms the baseline methods across all"}, {"title": "4.5. Ablation Study", "content": "To evaluate the contribution of each component in our\nproposed approach, we conducted a comprehensive ablation\nstudy across multiple EEG datasets. Table 2 presents the\nresults of this study, showing the impact of removing key\ncomponents from the full model.\nThe ablation study results reveal the relative importance\nof each component in our proposed approach. Removing\nthe Trend-Seasonal Decomposition (SSA) component led to\nan average accuracy reduction of 1.7% across all datasets.\nThe absence of MTF Imaging resulted in the most substan-\ntial performance drop, with an average accuracy decrease of\n4.2%. The Cross-Channel Split Attention (CCSA) mecha-\nnism had a less pronounced impact, with its removal result-\ning in an average accuracy decrease of 0.8%.\nThe differential impact of component removal across\ndatasets provides insights into the architecture's behavior"}, {"title": "4.6. Visualization", "content": "To provide deeper insights into the superior performance\nof our proposed approach, we present a comprehensive vi-\nsual analysis of our data processing and feature extraction\nmethods. Figure 4 illustrates the effectiveness of our Singu-\nlar Spectrum Analysis (SSA) decomposition on raw EEG\nsignals, while Figure 5 showcases the feature extraction\nprocess from MTF images.\nFigure 4 demonstrates the power of SSA in decompos-\ning raw EEG signals into trend, seasonal, and noise com-\nponents. This decomposition is crucial for isolating rele-\nvant signal patterns from background noise and artifacts.\nBy separating these components, our model can focus on\nthe most informative aspects of the EEG data, leading to\nmore accurate classification. The clear separation of trend"}, {"title": "and seasonal components", "content": "as shown in the figure, allows\nour subsequent processing steps to work with cleaner, more\nstructured data. This pre-processing step is fundamental\nin enhancing the signal-to-noise ratio and contributing to\nthe overall robustness of our approach across various EEG\ndatasets.\nFigure 5 provides a visual representation of how our\nmodel extracts and refines features from MTF images. The\nprogression from the penultimate image feature extraction\nlayer to the final image feature extraction layer reveals the\nmodel's ability to transform low-level patterns into high-\nlevel, class-specific features. In the penultimate image fea-\nture extraction layer, we observe the capture of localized\nstructures and patterns present in the original MTF images.\nAs we move to the final image feature extraction layer, these\nfeatures become more abstract and discriminative, high-\nlighting regions crucial for classification. The distinct acti-\nvation patterns between Class 0 and Class 1 in the final im-\nage feature extraction layer demonstrate the model's capac-\nity to learn class-specific representations. This hierarchi-\ncal feature extraction process enables our model to capture\nsubtle, yet critical differences between classes that may not\nbe immediately apparent in the original signals. The clear\ndifferentiation in feature maps between classes explains the\nhigh classification accuracy achieved by our model across\ndiverse EEG datasets.\nThese visualizations not only corroborate our quantita-\ntive results but also offer valuable insights into the internal\nworkings of our model. They illustrate how the combina-\ntion of effective signal decomposition (SSA) and hierarchi-\ncal feature learning (MTF imaging and CNN) contributes\nto the superior performance of our approach in EEG signal\nanalysis and classification tasks."}, {"title": "5. Discussion and Limitations", "content": "Our proposed approach for EEG signal analysis, inte-\ngrating Trend-Seasonal Decomposition using SSA, parallel\n1D-CNNs with modified attention mechanisms, and MTF\nimaging, has demonstrated superior performance across\nvarious EEG datasets. This section discusses the implica-\ntions of our results, acknowledges limitations, and suggests\nfuture research directions.\nThe ablation study results in Table 2 reveal the signif-\nicant contributions of each component in our model. The\nMTF imaging component appears to be particularly im-\nportant, with its removal resulting in an average accuracy\ndecrease of 4.2%. This suggests the significance of cap-\nturing spatiotemporal dependencies in EEG signals for ac-\ncurate classification. The Trend-Seasonal Decomposition\nusing SSA also contributes substantially, with its removal\nleading to an average accuracy decrease of 1.7%, indicat-\ning its potential in separating relevant EEG components\nfrom noise. The Cross-Channel Split Attention (CCSA)"}, {"title": "mechanism", "content": "while contributing positively, shows a less pro-\nnounced impact with an average accuracy decrease of 0.8%\nwhen removed. These findings suggest that while the atten-\ntion mechanism may refine the model's focus on relevant\nfeatures, the SSA decomposition and MTF imaging appear\nto be key strengths of our approach.\nDespite the promising results, our study has several lim-\nitations that merit consideration. Our current methodology\nfocuses primarily on single-channel EEG analysis, which\nmay limit its applicability to more complex EEG datasets.\nWhile the integration of multiple advanced techniques\nshows potential, it could increase computational complex-\nity, possibly challenging real-time applications. Moreover,\nour model does not explicitly incorporate domain-specific\nknowledge about EEG signals, which might enhance re-\nsult interpretability if included. The generalizability of\nour approach to diverse populations, such as different age\ngroups or individuals with various neurological conditions,\nrequires further investigation. These limitations suggest av-\nenues for future research. Extending our approach to multi-\nchannel or multi-modal EEG data analysis might yield ad-\nditional insights. Exploring the integration of our method-\nology with other deep learning architectures, such as graph\nconvolutional networks or transformer models, could poten-\ntially capture more complex EEG signal dependencies."}, {"title": "6. Conclusion", "content": "In this study, we have introduced STEAM-EEG, a novel\napproach for EEG signal analysis that integrates Trend-\nSeasonal Decomposition using Singular Spectrum Analysis\n(SSA), parallel 1D-CNNs with modified attention mecha-\nnisms, and Markov Transfer Field (MTF) imaging. Our\nmethodology aims to address the challenges inherent in\nEEG signal analysis, including their complex and non-\nstationary nature, presence of noise artifacts, and the need\nfor effective spatiotemporal modeling and visualization.\nOur experimental results across diverse EEG datasets\nsuggest that STEAM-EEG may offer improvements in clas-\nsification accuracy compared to several existing methods.\nThe SSA decomposition appears to enhance the signal-to-\nnoise ratio, while the MTF imaging component seems to\ncapture important spatiotemporal dependencies. Addition-\nally, our modified attention mechanism in the 1D-CNNs\nshows promise in focusing on relevant features within EEG\nsignals. Through ablation studies and visualizations, we\nhave gained insights into the contributions of individual\ncomponents and the feature extraction process.\nWhile our current focus has been on specific EEG clas-\nsification tasks, STEAM-EEG could potentially be adapted\nto a broader range of biomedical signal processing appli-\ncations. The improvements in accuracy and interpretability\nmight have implications for neuroscience research, clinical\ndiagnosis, and brain-computer interfaces."}]}