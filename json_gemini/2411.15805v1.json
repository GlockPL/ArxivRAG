{"title": "Benchmarking Active Learning for NILM", "authors": ["Dhruv Patel", "Ankita Kumari Jain", "Haikoo Khandor", "Xhitij Choudhary", "Nipun Batra"], "abstract": "Non-intrusive load monitoring (NILM) focuses on disaggre-\ngating total household power consumption into appliance-\nspecific usage. Many advanced NILM methods are based on\nneural networks that typically require substantial amounts of\nlabeled appliance data, which can be challenging and costly\nto collect in real-world settings. We hypothesize that appli-\nance data from all households does not uniformly contribute\nto NILM model improvements. Thus, we propose an active\nlearning approach to selectively install appliance monitors\nin a limited number of houses. This work is the first to bench-\nmark the use of active learning for strategically selecting\nappliance-level data to optimize NILM performance. We first\ndevelop uncertainty-aware neural networks for NILM and\nthen install sensors in homes where disaggregation uncer-\ntainty is highest. Benchmarking our method on the publicly\navailable Pecan Street Dataport dataset, we demonstrate that\nour approach significantly outperforms a standard random\nbaseline and achieves performance comparable to models\ntrained on the entire dataset. Using this approach, we achieve\ncomparable NILM accuracy with approximately (~ 30%) of\nthe data, and for a fixed number of sensors, we observe up to\na 2x reduction in disaggregation errors compared to random\nsampling.", "sections": [{"title": "1 INTRODUCTION", "content": "Non-Intrusive Load Monitoring [11], or (NILM), disaggre-\ngates the total power consumption into appliance-level us-\nage. Prior studies [24] suggest that knowing appliance-wise\npower consumption can help users reduce their energy con-\nsumption by 15%.\nSince George Hart's pioneering work on NILM [11], sev-\neral algorithms have been proposed, including but not lim-\nited to time series models such as additive factorial hidden\nMarkov models [21], discriminative sparse coding [20], graph\nsignal processing [14]. The first neural network based ap-\nproach was proposed by Kelly et al. in 2015 [18]. Many neural\nnetwork based techniques have been proposed since then\n[2, 16, 31, 38].\nConventional neural network (NN) models generally work\nwell when trained on a large labeled dataset. However, col-\nlecting labeled data via individual appliance power meters in\nevery household is prohibitively expensive. But, in general,\nmains energy data is easier to acquire than appliance-level\ndata. As a result, we have access to a huge number of houses\nthat have smart meter data but no appliance-level instru-\nmentation. For the rest of the paper, we refer to such houses\nas unlabeled houses. In this paper, we investigate the pos-\nsibility of achieving accurate disaggregation performance by\nleveraging training data (appliance-level data) from a limited\nselection of strategically chosen houses drawn from a vast pool\nof unlabeled houses.\nThis paper introduces, for the first time, an active learning\nframework for strategically selecting appliance-level data to\nenhance NILM performance, and we evaluate this approach\nin a comprehensive benchmarking setting. Active Learning\n[30] is a subfield of machine learning that employs a selective\napproach to identify and label data that maximizes uncer-\ntainty reduction from a large pool of unlabeled examples.\nThis methodology aims to minimize the cost associated with\nlabeling or annotating data. An acquisition function deter-\nmines the utility of a data example for improving the model\nperformance.\nIn this paper, we use the state-of-the-art neural networks\nfor Non-Intrusive Load Monitoring (NILM) models. We lever-\nage the recent techniques for quantifying the uncertainty in\nmodel predictions [2, 36]. We specifically use Monte Carlo\nDropout [7] to estimate uncertainty and two acquisition"}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "We now discuss the relevant background and related work."}, {"title": "2.1 Neural Energy disaggregation", "content": "As mentioned in the introduction, many neural network\napproach for energy disaggregation have been used and\nSeq2Point [38] model which uses 1d CNN approach still con-\ntinues to be one of the most popular approach. A sequence\nlength is fed as an input and a point prediction of the appli-\nance power series is taken as the output."}, {"title": "2.2 NNs and Uncertainty", "content": "In the context of machine learning, we generally consider\nthe following types of uncertainty:\n1) Aleatoric uncertainty: which is the inherent uncertainty\ndue to variability in the data generation process, noise in the\ndata or measurement errors. Even with an infinite amount\nof data, aleatoric uncertainty cannot be reduced.\n2) Epistemic uncertainty: which is the uncertainty arising\nfrom an incomplete understanding of the model's underlying\nparameters or structure. With more data or by improving the\nmodel architecture, we can minimise epistemic uncertainty.\nWe now briefly discuss different techniques for uncertainty\nquantification in neural nets. The recent surveys shows the\nin-depth discussions on these different methods [7][36]."}, {"title": "2.2.1 Homoskedastic Regression", "content": "Homoskedastic neural net-\nworks model the same variance across all inputs. We assume\nour predictive distribution to be a Gaussian distribution with\nmean \u00b5x and a constant sigma (\u03c3) for all x. Hence they do\naccount for uncertainty but are not useful for active learning\n[30]."}, {"title": "2.2.2 Heteroskedastic Regression", "content": "Heteroskedastic models\nlearn different variance for different data points. Thus, het-\neroskedastic neural networks estimate both \u03bc(x) and \u03c3(x)\nas a function of the input x (via two output nodes in the final\nlayer). These models only consider the data (aleatoric) uncer-\ntainty but do not account for the uncertainty in estimating\nthe parameters (epistemic)."}, {"title": "2.2.3 Bayesian Neural Networks", "content": "A Bayesian neural network\nputs a prior p(0) on the model weights (0), assumes a ho-\nmoskedastic or heteroskedastic likelihood, and computes the\nposterior (p(0|Dtrain)) i.e the distribution of model parame-\nters having observed the data.\nBayesian Neural Networks (BNNs) accounts for both aleatoric\nand epistemic uncertainty, however, such an approach would\nbe computationally intractable [5] and hence we perform\ncertain approximations to quantify the uncertainties.\n\u2022 Sampling based methods: Sample from probability dis-\ntributions to approximate the intractable integrals.\nMarkov chain monte carlo (MCMC) [28] involve con-\nstructing a Markov chain whose final posterior distri-\nbution serves as the chain's equilibrium distribution.\nSeveral MCMC based methods like NUTS [15], Me-\ntropolis Hastings [12], Hamiltonian Monte Carlo [25],\netc. have been proposed.\n\u2022 Variational approximation: Variational inference [13]\napproximates the true posterior p(0|Dtrain) by a proxy\ndistribution q4 (0) with a known functional form pa-\nrameterized by 6 and minimizes the Kullback-Leibler\ndivergence (KL divergence) [22] between q$(0) and\np(0 Dtrain), denoted as:\nKL (q4(0) ||||p(0|Dtrain).\nAfter a few algebraic manipulations, minimizing this\nKL divergence and maximizing the functional below\nturn out to be equivalent:\nLELBO = Eqq (0) [logp(y|0, Dtrain)] (Data Term)\nKL [q4(0)||||p(\u03b8)] (Regularization Term).\nThis functional is often referred to as the Evidence\nLower Bound (ELBO).\n\u2022 Laplace approximation [33]: Uses a normal approxi-\nmation centered at the maximum of the posterior dis-\ntribution, or maximum a posteriori (MAP).\n\u2022 Dropout as Bayesian approximation: A much more\ncomputationally efficient approach, MC Dropout [7]"}, {"title": "2.3 Active Learning", "content": "Our approach uses active learning paradigms to overcome\nbottlenecks while achieving the best performance with fewer\nlabeled samples. A quintessential active learning framework\nconsists of four major parts:\n(1) a small labeled dataset\n(2) an active learner\n(3) an expert Oracle\n(4) unlabeled data pool\nIn the active loop, we first train our model on a small\nlabeled training dataset, then we actively query the data\npoints from a large unlabelled pool dataset, label them and\nkeep expanding our training dataset with these queried data\npoints. Figure 1 illustrates the AL loop.\nThe active learner proactively queries data it wants to\nlearn from instead of being passively trained on all the avail-\nable data. It leverages uncertainty in predictions to pick out\nthe best points from the unlabeled data that significantly\nincrease model performance.\nIn traditional ML models, interactive querying of pool\npoints is done via various uncertainty acquisition functions.\nFor example: Query by Committee, Entropy Sampling, and\nMaximum Standard-Deviation based sampling [30]. The query\nequation is given by\n$** = argmax_{x \\in x_{pool}} A(x)$  (4)\nwhere A (x) is the acquisition function and \u0177 is the queried\npoint from the pool set."}, {"title": "2.4 Active Learning for NILM", "content": "We propose using active learning [30] for reduction in labeled\ndata requirement for low frequency domain in NILM.\nThere is limited prior work on active learning for NILM.\nPrevious literature like [34], use Wave-Net [17] and modified\nBatchBALD [19] for NILM task and [10] use stream based\nuncertainty sampling where the notion of time series is not\nupheld. Both of the papers also attempt to solve a classifica-\ntion task. They adopt a user-based querying approach. Users\nare prompted to use an app or given the snapshot/time-series\nshowing the aggregate power consumption time series, for\nexample, 11:00 - 11:30 am and then asked what ap-\npliance they were using at that time. To the best of our\nknowledge we are the first to benchmark and apply\nactive learning for NILM framework in a regression\nsetting. We propose an active learning approach based on\ninstalling appliance-level sensors. We query a house and add\na sensor to the queried house. Moreover, we use pool-based\nuncertainty sampling for time series for a regression task.\nOur pool-based sampling approach makes our active learn-\ning settings more practical as compared to the stream-based\nsamplings performed in prior literature [10]."}, {"title": "3 PROBLEM STATEMENT AND NOTATION", "content": "In this research paper, we focus on developing a practical\nand data-efficient Non-Intrusive Load Monitoring (NILM)\napproach that achieves performance comparable to conven-\ntional NILM methods at a significantly lower cost. We aim to"}, {"title": "4 APPROACH", "content": "Our objective is to quantify uncertainty and using less but\ninformative data to train the model. We begin by addressing\nour practical setting, examining the pool dataset, and con-\ncluding by explaining the single-task and multi-task settings."}, {"title": "4.1 Disaggregation Method", "content": "4.1.1 Single Output. In single output models, we train a sep-\narate model for each appliance and also set the hyperparame-\nters specific to the appliance. We use current state-of-the-art\nsequence to point (S2P) [38] neural networks for NILM frame-\nwork [2, 4] as the model. We use S2P with heteroskedastic\nlikelihood. Our output is a Gaussian or Normal distribution.\nThus, we predict \u03bc(x) and \u03c3(x) per appliance for all input x.\nFigure 3a shows the model architecture, where the input is a\nsequence of aggregate power and output, \u03bc(x) and \u03c3(x) is\ndisaggregated power consumption of an appliance for the\nmid-point of the input time sequence.\n4.1.2 Multi Output. In multi output models, we train a sin-\ngle model that predicts the mean and sigma for all appliances.\nThis accounts to a total output of 2k parameters where k is\nthe number of appliances. We find learning the sigmas first\nand then a separate layer for learning means to be better\nthan learning all the 2k parameters in the final layer. Figure\n3b shows the model architecture."}, {"title": "4.2 Acquisitions functions", "content": "We query the pool houses based on two different acquisition\nstrategies namely entropy and mutual information. We use\nMC-Dropout as the strategy to quantify the uncertainty by\nrunning N stochastic forward passes (with dropout) of the\ntrained network as discussed in details in Section 2.2.3.\n4.2.1 Entropy. We use differential entropy as an estimate\nto quantify uncertainty in our model [9]. For a univariate\nGaussian, the expression for entropy [1] for a general random\nvariable X is give as:\nH(X) = log(\u221a2\u03c0\u03b5\u03c3) (5)\nWe observe that the entropy is directly proportional to the\nstandard deviation. Hence, we can approximate the entropy\nof the predictive distribution (up to a constant) based on\nequations 1, 2 and 3 as:\n$A_{Entropy} (x) = H [y | x, D_{train} ] \u2248 \\sigma_{ensemble} (x)$  (6)\n4.2.2 Mutual Information. Mutual information quantifies\nthe reduction in uncertainty of one variable (X) given infor-\nmation about another variable (Y). It is generally evaluated"}, {"title": "4.3 Active Learning settings", "content": "We employ an active learning loop by selectively querying\na house with information deemed essential by our model\nfrom the pool set. Subsequently, we deploy a sensor to gather\ndata from this specific house and incorporate the acquired\ndata into our training process. This helps enhance the pre-\ndictive capabilities of our model by choosing houses with\ninformation crucial for better disaggregation.\nWe employ two active learning settings, one for under-\nstanding the upper bounds in the performance (Query Singly)\nand the other, a more practical one (Query all at once) active\nlearning respectively.\n4.3.1 Query Singly Active Learning. In query singly active\nlearning, we individually select a house from the pool set\nfor each appliance. For instance, the house queried for air\nconditioner could be h5 and that for furnace could be h9. The\nselection of a house for an appliance a\u00a1 is solely based on the\nuncertainty of that appliance, disregarding other appliances.\nThe acquisition happens according to the equation 4 above.\nUncertainty is assessed using entropy and mutual infor-\nmation to determine the house to be queried. However, in\npractical scenarios, choosing different houses for dif-\nferent appliances is expensive and would require more\nsensors to be installed. To overcome this limitation, we\nfurther investigate and expand upon this approach in\nthe Query all at once active learning setting.\n4.3.2 Query all at once Active Learning. In \"Query All at\nOnce\" active learning, we select a single house from the pool\nset, taking into account all appliances. The selection of the\nhouse is based on the weighted uncertainties associated with\neach appliance.\nWe employ the following query strategies to query a single\nhouse across different appliances:\n1. Uniform Weighted Uncertainty: The uncertainty is\nweighted uniformly across all the appliances and the house"}, {"title": "4.4 Pool Temporal Context: Static vs\nDynamic", "content": "Our NILM problem has a special time series flavour to it,\nmaking it different from active learning on i.i.d. data setting\nlike images. For example, let us refer back to figure 2. Our\ninitial model is trained on timestamps from t\u2081 (say 1st March)\nthrough t2 (say 10th March). Let us consider a pool home, say\nh\u2081 and pick a time window, t\u2081 (1st March) to t3 (15th March),\nfor which we predict the uncertainty over the appliance\npower. This timeframe may have multiple datapoints over\nwhich we compute the uncertainty in power drawn over. For\nexample: 1st March 8 AM, 1st March 8:30 AM, .., 15th\nMarch 11:30 PM. However, we would need a single metric\nto capture the uncertainty over the entire time period. We\nthus make two important considerations: i) the aggregation\nfunction; ii) aggregation time window.\nWe now discuss these two considerations in details:\n1. Aggregation function: Given a time window T consist-\ning of multiple timestamps, we could aggregate the uncer-\ntainty across these timestamps in two ways: i) uniformly\nby giving equal importance to all the timestamps; or ii) by\ncreating a biased weighing scheme. For a biased weighing ap-"}, {"title": "5 DATASET", "content": "The Pecan Street Dataport database [26] is the world's largest\nresidential energy data source. Out of the 725 homes, 75\nhomes dataset is free for research purposes. Out of these 75\nhomes, we use the 25-home dataset from the publicly avail-\nable dataset of Pecan Street neighborhood of Austin, Texas.\nThe remaining 50 homes have far less data for thorough\nanalysis.\nThe dataset includes information on energy consumption,\nenergy generation (from solar panels), appliance-level energy\nusage, weather data, and demographic information. We use\nthe one-minute frequency dataset to conduct our analyses\nand investigations. Similar to previous studies [2, 18], we cen-\nter our attention on five widely used appliances worldwide:\nair conditioners, dishwashers, clothes washers, refrigerators,\nand furnaces. Other appliances have far less data and most\nfamilies do not have access to it. Additionaly, the dishwasher\nrequires human operation and is occasionally used; on the\nother hand, the refrigerator operates without any human\ninteraction and might be regarded as a background appli-\nance. Moreover, devices like dishwasher and clotheswasher\nfrequently function in different modes (drying, heating, etc..)\nand consume varied amounts of power for these different\nmodes."}, {"title": "5.2 Metrics", "content": "We use the root mean squared error [27] defined as\n$RMSE = \\sqrt{\\frac{\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}{n}}$ (13)\nHere, n is the number of samples, \u0177\u2081 and y\u2081 is the predicted\nappliance reading and ground truth reading of an appliance\nrespectively. Lower RMSE means better performance."}, {"title": "5.3 Experimental Setup", "content": "The power consumption distribution of certain appliances\nvaries with the seasons. For instance, the air conditioner,\npredominantly utilized during summer and sparingly during\nother seasons, exhibits distinct usage patterns based on the\nseasons. Thus, to make the problem setup realistic, we select\nour experimental dates from 1st March 2018 to 10th May\n2018. During the initial few days, there is zero to minimal\nair conditioner usage, and the latter days, there is heavy air\nconditioner usage.\n5.3.1 Disaggregation methods. We employ sequence-to-point\nmodels [38] and draw inspiration for our hyperparameter\nselection from earlier studies [3]. Due to space constraints,\nwe link the list of hyperparameters here."}, {"title": "5.3.7 Pool Temporal Setup", "content": "To compare between the static\nand dynamic pool windows discussed in section 5.4.1, we\nuse two static aggregation time window and a dynamic time\nwindow, all of fifteen days. The dynamic time window in-\ncludes seven days in the past, the current day (T) (when we\nevaluate uncertainty over pool set) and seven days in the\nfuture. We can thus write the weight from the triangle kernel\n(defined at current day T) for any day t \u2208 {T \u2013 7,\uff65\uff65\uff65, T + 7}\nas:\n$W_T(t) = 1 - \\frac{|T-t|}{8}$ (14)\nThe above formula ensures that our weights vary from 0.125\nat extremes to 1 at center. In the experiments, the dynamic\nwindow starts from 5-20 March 2018 and slides forward\nfive days in each subsequent iteration of active learning. The\nstatic windows are 16 \u2013 30 January 2018 and 16 \u2013 30 April\n2018. We chose the above mentioned static window frames\nto account for the seasonal change of energy consumption\nacross appliances. We used both the uniform and triangle\nkernel for the static and dynamic pool windows.\nIt is important to note that we will never have access to\n\"future\" data for evaluating pool uncertainty. For the purposes\nof a practical implementation, one could use the data from\nthe previous year (if available) or introduce a lag in adding\npool data (till the end of the pool window). In this paper, we\ncould not leverage data from the previous year due to the\ndataset limitations. However, we believe such a system to be\nviable as the mains data is generally easier to collect via the\nsmart metering infrastructure."}, {"title": "5.4 Results and analysis", "content": "We now present our main results."}, {"title": "5.4.1 Query Singly", "content": "\u2022 AL v/s Random: In figure 6, we see that the active learn-\ning approaches using entropy and MI perform better as\ncompared to random approach in almost all the iterations.\nIn addition to that, the errors achieved after the last itera-\ntion are comparable with the total baseline error. In other\ndomains [37], a 3% improvement over the mean of the\nrandom baseline has been considered as state-of-the-art.\nIn contrast, we are well below the sigma interval (68%) of\nthe random baseline.\nKey Analysis:\nFor air conditioner, we observe that we are able to de-\ncrease the errors by about 2x (from ~ 700 to ~ 300 in the\nsecond iteration), just by strategically querying data.\nFor air conditioner, we achieve errors closer to the to-\ntal baseline with six iterations (i.e. with only six new"}, {"title": "5.4.2 Query all at once", "content": "Due to resource constraints, we\nhave not evaluated the total baseline error for query\nall at once AL.\n\u2022 Active learning v/s Random\nIn query all at once active learning, we compute the uncer-\ntainties across all appliances during the querying phase,\nand we query the house as per the different acquisition\nstrategies discussed in section 4.3.2.\nWe show our results for the uniform weighted uncertainty\nsampling and attach the rank and round robin based active\nlearning results in Section 6 and 7. Figures 10 - 14 shows\nthe performance of our query at once active learning."}, {"title": "6 RANK", "content": "Figure 15: Performance of the model on dishwasher in\nthe rank-based active learning setting.\nFigure 16: Performance of the model on the refrigera-\ntor in the rank-based active learning setting. The per-\nformance is better than the uniform-weighted active\nlearning"}, {"title": "7 ROUND-ROBIN", "content": "Figure 17: Performance of the model on dishwasher in\nthe round-robin active learning setting. Round robin\nachieves comparable performance to entropy and mu-\ntual information."}, {"title": "8 LIMITATIONS, DISCUSSION AND\nFUTURE WORK", "content": "(1) Presently, we do not consider a stopping criteria. In the\nfuture, we plan to add heuristic methods to stop when we\nget diminishing returns. For e.g., we could stop querying\nonce our uncertainty is below a specified threshold.\n(2) In our current approach, we added appliance data from a\nsingle home every iteration. However, akin to batch ac-\ntive learning, we could add appliance data from a batch of\nhouses every iteration. Such an approach would require"}, {"title": "9 CONCLUSIONS", "content": "In this paper, we took state-of-the-art NILM models and dras-\ntically reduced the requirement for labeled data by strategic\nquerying. Our active learning approach beats the uninforma-\ntive random sampling strategy. Given the different nature\nof appliances from a NILM perspective (regularly used like\nfridge, or sparsely used like dishwasher), we found that ac-\nquisitions that account for model uncertainty alone are likely\nto do better. Overall, we believe that given the non-trivial\nchallenges in acquiring ground truth data in many Buildsys\napplications, active learning approaches could reduce the\nlabeling and sensor maintenance cost. This work contributes\nto the benchmarking track by demonstrating the potential\nof active learning in optimizing NILM systems."}]}