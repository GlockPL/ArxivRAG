{"title": "Unveiling the Threat of Fraud Gangs to Graph Neural Networks:\nMulti-Target Graph Injection Attacks against GNN-Based Fraud Detectors", "authors": ["Jinhyeok Choi", "Heehyeon Kim", "Joyce Jiyoung Whang*"], "abstract": "Graph neural networks (GNNs) have emerged as an effective tool for fraud detection, identifying fraudulent users, and\nuncovering malicious behaviors. However, attacks against\nGNN-based fraud detectors and their risks have rarely been\nstudied, thereby leaving potential threats unaddressed. Recent findings suggest that frauds are increasingly organized\nas gangs or groups. In this work, we design attack scenarios where fraud gangs aim to make their fraud nodes mis-\nclassified as benign by camouflaging their illicit activities in\ncollusion. Based on these scenarios, we study adversarial attacks against GNN-based fraud detectors by simulating at-\ntacks of fraud gangs in three real-world fraud cases: spam\nreviews, fake news, and medical insurance frauds. We define these attacks as multi-target graph injection attacks and\npropose MonTi, a transformer-based Multi-target one-Time\ngraph injection attack model. MonTi simultaneously generates attributes and edges of all attack nodes with a transformer\nencoder, capturing interdependencies between attributes and\nedges more effectively than most existing graph injection attack methods that generate these elements sequentially. Additionally, MonTi adaptively allocates the degree budget for\neach attack node to explore diverse injection structures involving target, candidate, and attack nodes, unlike existing\nmethods that fix the degree budget across all attack nodes.\nExperiments show that MonTi outperforms the state-of-theart graph injection attack methods on five real-world graphs.", "sections": [{"title": "Introduction", "content": "Recent endeavors have highlighted the power of Graph Neural Networks (GNNs) for fraud detection (Dou et al. 2021;\nXu et al. 2022). In fraud detection tasks, complex interactions of fraudsters can be effectively modeled using graphs,\nand frauds are typically represented as nodes corresponding\nto individuals with malicious intentions. GNN-based fraud\ndetection methods aim to determine whether the nodes are\nfraudulent or benign. Meanwhile, it has been reported that\nadversarial attacks can cause GNNs to malfunction across\nvarious domains, including recommender systems and social network analysis (Chen et al. 2022a; You et al. 2023;\nHuang and Li 2023; Shao et al. 2023; Wang et al. 2023a).\nThose works consider vanilla GNNs as victim models,\ne.g., GCN (Kipf and Welling 2017), GraphSAGE (Hamilton, Ying, and Leskovec 2017), and GAT (Veli\u010dkovi\u0107 et al.\n2018). On the other hand, various tailored GNNs for fraud\ndetection have recently been developed to filter the camouflaged fraudsters, such as CARE-GNN (Dou et al. 2020),\nPC-GNN (Liu et al. 2021), and GAGA (Wang et al. 2023c).\nHowever, vulnerabilities of these GNN-based fraud detectors to adversarial attacks remain unexplored.\nIt has been recently observed that frauds are increasingly\norganized into gangs or groups exhibiting collusive patterns\nto carry out fraudulent activities more effectively with reduced risk (Wang et al. 2023b; Yu et al. 2023; Ma et al.\n2023). For example, in the medical insurance domain, fraudsters may collaborate with doctors or insurance agents to\nobtain fake diagnoses. On online review platforms, fraudsters could create multiple fake reviews using different IDs.\nOn social media platforms, fraudsters can spread misinformation by using multiple fake accounts. We design these\nthree attack scenarios where fraud gangs attack GNN-based\nfraud detectors to make them misclassify the fraud nodes\nas benign. Furthermore, to simulate the scenarios, we create\ndatasets and target sets that consist of fraud nodes grouped\nbased on metadata or relations in real-world graphs.\nIn this work, the adversarial attack on GNN-based fraud\ndetectors by fraud gangs is defined as a multi-target graph\ninjection attack. We adopt a graph injection attack, as it is\nmore feasible than a graph modification attack, which requires privileged access to alter existing structures (Chen\net al. 2022b). As illustrated in Figure 1, in our attack scenarios, a fraud gang attempts to deceive the detector by injecting\nmalicious nodes (i.e., attack nodes) into the original graph,\ncausing their fraud nodes to be misclassified by increasing\nthe scores of being benign. We consider a black-box evasion\nattack, where the attacker can access only the original graph,\npartial labels, and a surrogate model, and the attack occurs\nduring the victim model's inference phase (Sun et al. 2023).\nExisting methods (Tao et al. 2021; Zou et al. 2021; Wang\net al. 2022) have focused on adversarial attacks for randomly\ngrouped target nodes. However, fraud nodes are often organized into gangs to camouflage their illicit activities. While\nthe existing methods have investigated attacks where vanilla\nGNNs are employed as victim models, GNN-based fraud detectors are tailored to address heterophily induced by fraud\nnodes, making them more difficult to attack than vanilla\nGNNs. To overcome the limitations of these existing methods in our scenario, we propose MonTi, a transformer-based\nMulti-target one-Time graph injection attack model.\nMonTi significantly differs from the existing graph injection attack methods in several aspects, as summarized in\nTable 1. The existing methods, such as TDGIA (Zou et al.\n2021), Cluster Attack (Wang et al. 2022), and G2A2C (Ju\net al. 2023), inject multiple attack nodes sequentially, fixing\nthe graph structure at each step. Those approaches fix the\ndegree budget across all attack nodes due to the lack of information about future steps, limiting their flexibility and efficiency. In contrast, MonTi injects all attack nodes at once,\nadaptively assigning the degree budget for each attack node\nto explore diverse structures among target, candidate, and\nattack nodes. Furthermore, the existing methods, including\nG-NIA (Tao et al. 2021), overlook interactions within target\nnodes and among attack nodes, which are crucial for modeling the intricate relationships within a fraud gang and attacking target nodes. Additionally, the existing methods sequentially generate attributes and edges of attack nodes, only considering a one-way dependency, which fails to model collusive\npatterns of fraud gangs. On the other hand, MonTi employs\na transformer encoder to effectively capture interdependencies within target and attack nodes, and between attributes\nand edges. Our contributions are summarized as follows:\n\u2022 To the best of our knowledge, our work is the first study\nto investigate the vulnerabilities of GNN-based fraud detectors and also the first study on graph injection attacks\nfor multiple target nodes organized by groups.\n\u2022 We propose a graph injection attack method MonTi,\nwhich generates attributes and edges of all attack nodes at\nonce via the adversarial structure encoding transformer.\n\u2022 MonTi can explore adversarial injection structures comprehensively by generating adversarial edges with adaptive degree budget allocation for each attack node.\n\u2022 Experimental results demonstrate that MonTi substantially outperforms the state-of-the-art graph injection attack methods on five real-world graphs."}, {"title": "Problem Definition", "content": "An undirected attributed graph is defined as G = (V,E,X)\nwhere V is a set of n nodes, E \u2282 V \u00d7 V is a set of edges,\nand X is a set of D-dimensional node attribute vectors. For a\nnode $v \\in V$, we represent its attribute vector as $x_v \\in X$ and its label as $y_v \\in \\{0,1\\}$ where $Y_v = 1$ indicates $v$ is a fraud\nand $y_v = 0$ indicates $v$ is benign. $Y = \\{y_v | v \\in V\\}$ denotes\na set of node labels. We represent a GNN-based fraud detector as $f_@(\\cdot)$ where $@$ indicates learnable parameters. The\nfraud score vector $s \\in \\mathbb{R}^2$ and the predicted label $\\hat{y}_v \\in\n\\{0,1\\}$ are calculated by $s_v = f_@(G,v) = MLP (\\Phi(G, v))$\nand $\\hat{y}_v = \\arg \\max_{i} s_{v,i}$ where $MLP$ is a multi-layer perceptron, $\\Phi(\\cdot)$ denotes a GNN encoder and $s_{v,i}$ denotes the\ni-th element of $s_v$. We formulate the objective function of\nthe fraud detector as $\\max_@ \\sum_{v \\in V} \\mathbb{I} (\\hat{y}_v = y_v)$ where $\\mathbb{I} (\\cdot)$ is\nan indicator function. Most GNN-based fraud detectors utilize label information based on domain-specific knowledge,\nemploying (semi-)supervised approaches (Dou et al. 2020;\nLiu et al. 2022). As the first study of adversarial attacks\nagainst GNN-based fraud detectors, we assume that graphs\nare single-relational, in line with existing studies of adversarial attacks on graphs (Tao et al. 2021; Zou et al. 2021;\nWang et al. 2022; Ju et al. 2023).\nA graph injection attack injects attack nodes $V_{in}$ with attributes $X_{in}$ and adversarial edges $E_{in} \\subset (V' \\times V') \\backslash (V \\times V)$\ninto the original graph $G = (V,E,X)$ where $V' = V \\cup V_{in}$.\nWe define the perturbed graph as $G' = (V',E', X')$ where\n$E' = E \\cup E_{in}$ and $X' = X \\cup X_{in}$. The multi-target graph\ninjection attack against a GNN-based fraud detector aims\nto make fraud nodes in the target set $T \\subset V$ misclassified. For a node $v \\in V$, let $s = f_@^*(G', v)$ where $@^* =$\n$\\arg \\min_@ \\mathcal{L}_{train} (f_@, G, D)$, $\\mathcal{L}_{train}$ is a training loss of $f_@(\\cdot)$,\nand $D \\subset Y$ is a node label set for training. The objective\nfunction of the multi-target graph injection attack is:\n$\\min_{G'} \\sum_{t \\in T} \\mathbb{I} (\\arg \\max s_{t,i} \\neq Y_t)$\ns.t. $|V_{in}| \\leq \\Delta, |E_{in}| \\leq \\eta$ \\newline \\quad (1)\nwhere $\\Delta$ and $\\eta$ denote node and edge budgets, respectively."}, {"title": "Multi-target One-time Graph Injection Attack", "content": "We propose MonTi (Figure 2), a graph injection attack\nmodel with a transformer-based architecture. MonTi utilizes\nself-attention to capture interactions among target, candidate, and attack nodes, simultaneously generating attributes\nand edges of attack nodes to reflect their interdependencies.\nIn addition, by generating edges of all attack nodes at once,\nMonTi enables flexible budget allocation for each node."}, {"title": "Adversarial Structure Encoding", "content": "Three types of contexts can affect multi-target graph injection attacks: target nodes $T = \\{t_1,\\dots,t_m\\}$, attack\nnodes $V_{in} = \\{u_1,\\dots,u_\\Delta\\}$, and candidate nodes. We define $N(K) \\subset V$ as a set of K-hop neighbors of the target nodes, excluding the target nodes themselves. From $N(K)$, we select $a$ nodes to form a set of candidate nodes $C = \\{c_1,\\dots,c_a\\} \\subset N(K)$. The neighborhood of target nodes provides information on how to propagate malicious messages within a GNN-based architecture. MonTi employs multi-head self-attention to learn intermediate representations for nodes in T, $V_{in}$, and C to capture interactions\namong these contexts, distinguishing their respective roles."}, {"title": "Candidate Selection", "content": "The size of $N(K)$ can drastically increase depending on the target nodes, making it computationally inefficient and challenging to find the optimal $G'$.\nTherefore, when the number of possible candidate nodes exceeds the threshold $n_c$, MonTi selects candidate nodes to narrow the search space with a learnable scoring function\n$\\mathcal{J}$; otherwise, all nodes are considered as candidate nodes.\nTo incorporate the class distribution learned by GNN architectures, MonTi utilizes a surrogate GNN model pretrained\non the original graph. MonTi calculates candidate scores for"}, {"title": "Target and Candidate Encoding", "content": "To exploit the structural information of target and candidate nodes, we introduce learnable encodings with three different factors of each\nnode $v$ related to the attack: raw attributes $x_v$, degree $d_v$, and\nthe GNN representation $h_v$. We employ the raw attributes\nto explicitly take into account the node itself. The node degree is utilized to indirectly measure the susceptibility of the\nnode to the change of its neighbors. We use the GNN representation to capture an inherent class distribution learned\nby the surrogate GNN and topological information of the\nnode. With a learnable target encoding function $\\mathcal{P}$, a target\nencoding $Z_i = \\mathcal{P}(x_{t_i}, d_{t_i}, h_{t_i})$ for a target node $t_i \\in T$ is\ncomputed by projecting and integrating all three factors:\n$Z_i = MLP (\\sigma([(Wx_{t_i} + b_1) || (w d_{t_i} + b_2) || h_{t_i}]))$ \\newline \\quad (3)\nwhere $MLP$ transforms the input into $\\mathbb{R}^{D_H}$, $W \\in \\mathbb{R}^{D_H \\times D}$,\n$w \\in \\mathbb{R}^{D_H}$, $b_1 \\in \\mathbb{R}^{D_H}$, $b_2 \\in \\mathbb{R}^{D_H}$. Similarly, we compute\na candidate encoding $\\tilde{z}_i = \\mathcal{P}(x_{c_i}, d_{c_i}, h_{c_i})$ for a candidate\nnode $c_i \\in C$ where $\\mathcal{P}$ denotes a learnable candidate encoding\nfunction. Note that the parameters of $\\mathcal{P}$ and $\\tilde{\\mathcal{P}}$ are distinct."}, {"title": "Adversarial Structure Encoding Transformer", "content": "We propose to adopt the transformer (Vaswani et al. 2017) encoder\nto learn the intermediate node representations of the target, candidate, and attack nodes for adversarial attribute and\nedge generation. Each attack node $u_i \\in V_{in}$ is initialized\nwith the representation $\\tilde{Z}_i \\in \\mathbb{R}^{D_H}$ sampled from a standard Gaussian distribution. The input sequence for the adversarial structure encoding transformer is defined as $Z^{(0)} =$\n$[Z^{(0)}||\\$\\tilde{Z}^{(0)}||\\hat{Z}^{(0)}] = [Z_1\\dots Z_m || \\tilde{Z}_1\\dots \\tilde{Z}_a || \\hat{Z}_1\\dots \\hat{Z}_\\Delta]$ where\n$Z^{(0)}$, $\\tilde{Z}^{(0)}$, and $\\hat{Z}^{(0)}$ denote the input sequence corresponding to the target, candidate, and attack nodes, respectively.\nWe then add learnable positional encodings $p$, $\\tilde{p}$, $\\hat{p} \\in \\mathbb{R}^{D_H}$\nto the corresponding node representations. Subsequently,\n$Z^{(0)}$ is processed through an L-layer transformer encoder\nwith $n_h$ heads to obtain the final representations $Z^{(L)} =\n[Z^{(L)}||\\tilde{Z}^{(L)}||\\hat{Z}^{(L)}]$. To mitigate noise from attack nodes\nwhose edges are not formed yet, we optionally mask the attack nodes when calculating target and candidate node rep-\nresentations, treating this masking as a hyperparameter."}, {"title": "Adversarial Attribute Generation", "content": "To generate the attributes of attack nodes, we project $\\hat{Z}^{(L)}$\ninto D-dimensional space: $F = \\text{sigmoid}(W_a\\hat{Z}^{(L)} + b_a) \\in$\n$\\mathbb{R}^{D \\times \\Delta}$ where $W_a \\in \\mathbb{R}^{D \\times D_H}$ and $b_a \\in \\mathbb{R}^D$. Depending\non whether the raw attributes are continuous or discrete, F is\ntransformed into the malicious attributes in different ways.\nFor continuous attributes, we rescale F by using the min-\nmax vectors of raw attributes $x_{min}, x_{max} \\in \\mathbb{R}^D$ derived from\nthe original graph. The adversarial attribute vector $x_i$ for the\nattack node $u_i \\in V_{in}$ is computed by $x_i = F_i \\odot (x_{max} -$\n$x_{min}) + x_{min}$ where $F_i \\in \\mathbb{R}^D$ denotes the i-th column vector\nof F, and $\\odot$ denotes the element-wise product operator.\nWe adopt the Gumbel-Top-k technique to optimize discrete choices, such as candidate selection, discrete attribute\ngeneration, and edge generation. Following (Tao et al. 2021;\nNguyen Thanh et al. 2023), we additionally utilize the exploration parameter $\\epsilon$ to control the randomness. The Gumbel-\nSoftmax for the discrete attribute generation is defined as:\n$\\text{Gumbel-Softmax}(F_i, \\epsilon)_j = \\frac{\\exp ((F_{ij} + \\epsilon N_j)/\\tau)}{\\sum_{j'=1}^{|F_i|} \\exp ((F_{ij'} + \\epsilon N_{j'})/\\tau)}$  \\newline \\quad (4)\nwhere $F_{ij}$ is the j-th element of $F_i$, $N_j = - \\log(-\\log(U_j))$,\n$U_j \\sim \\text{Uniform}(0, 1)$ is a Uniform random variable, and $\\tau$ is\nthe temperature parameter. The Gumbel-Top-k function $G_a$\nfor discrete attribute generation is defined as:\n$\\mathcal{G}_a(F_i) = \\arg \\text{top-k} \\text{Gumbel-Softmax}(F_i, \\epsilon)_j$ \\newline \\quad (5)\nwhere $\\arg \\text{top-k}$ function returns the indices corresponding\nto the k highest values of the input. Here, we set k as $\\lambda$,\nthe average count of non-zero values in the node attributes\nof the entire graph. Finally, the j-th element of $x_i$ becomes\n$x_{ij} = \\mathbb{I} (j \\in \\mathcal{G}_a(F_i))$. We employ the straight-through estimator to optimize the discrete selection processes, allowing\nfor gradient-based optimization with discrete elements."}, {"title": "Adversarial Edge Generation", "content": "To generate all adversarial edges at once within the edge\nbudget $\\eta$, we construct an edge score matrix and apply the\nGumbel-Top-k. First, we project $\\hat{Z}^{(L)}$ into edge score space:\n$R = W_e\\hat{Z}^{(L)} + b_e = [R||\\$\\tilde{R}||\\hat{R}]$\n$[r_1\\dots r_m || \\tilde{r}_1\\dots \\tilde{r}_a || \\hat{r}_1\\dots \\hat{r}_\\Delta]$ \\newline \\quad (6)\nwhere $W_e \\in \\mathbb{R}^{D_H \\times D_H}$, $b_e \\in \\mathbb{R}^{D_H}$, $R \\in \\mathbb{R}^{D_H \\times m}$,\n$\\tilde{R} \\in \\mathbb{R}^{D_H \\times a}$, $\\hat{R} \\in \\mathbb{R}^{D_H \\times \\Delta}$, $m$ is the number of target\nnodes, $a$ is the number of candidate nodes, $\\Delta$ is a node budget, and $M = m + a + \\Delta$. We define the edge score $e_{ij}$\nbetween an attack node $u_i \\in V_{in}$ and a node $v_j \\in T \\cup C \\cup V_{in}$\nas the cosine similarity between their representations. Then,\nthe edge score matrix $E \\in \\mathbb{R}^{\\Delta \\times M}$ can be written as $E =$\n$\\hat{D}^{-1}R^T \\tilde{D}^{-1}$ where $\\hat{D} = \\text{diag}(||r_1||,\\dots,||r_m||)$, and\n$\\tilde{D} = \\text{diag}(||\\tilde{r}_1||,\\dots,||\\tilde{r}_\\Delta||)$. To guarantee that every attack node is directly connected to the original graph, we generate at least a single edge for each attack node to one of the\ntarget nodes by applying Gumbel-Top-k with k = 1. For all\nremaining possible edges, we apply Gumbel-Top-k across\nthe entire $E$ with k = $\\eta - \\Delta$. Note that edge scores corresponding to self-loops and duplicated edges are masked."}, {"title": "Training of MonTi", "content": "Following the previous works in graph injection attacks (Tao\net al. 2021; Wang et al. 2022), we define the loss function for\nMonTi based on C&W loss (Carlini and Wagner 2017):\n$\\min_{G'} \\mathcal{L}(f_{@^*}, G', T) = \\frac{1}{|T|} \\sum_{t \\in T} \\max (s_{t,1} - s_{t,0}, 0)$ \\newline \\quad (7)\nwhere $s_t = f_{@^*}(G',t) \\in \\mathbb{R}^2$, and $s_{t,i}$ denotes the i-th element of s. We focus on increasing normal scores and decreasing fraud scores of target nodes to align with our attack\nscenarios. In line with our emphasis on black-box attack settings, the loss is calculated using a surrogate model."}, {"title": "Experiments", "content": "We compare MonTi with the state-of-the-art graph injection\nattack baselines on five real-world graphs.\nDatasets Our experiments on multi-target graph injection attacks cover three real-world datasets: GossipCop-S,\nYelpChi, and LifeIns. GossipCop-S and YelpChi have continuous node attributes, whereas LifeIns contains discrete\nones. Using GossipCop (Shu et al. 2020), which includes\nnews articles and their Twitter engagements (Shu et al.\n2020), we create GossipCop-S by following (Wu and Hooi\n2023), linking articles tweeted by the same multiple users.\nYelpChi (Rayana and Akoglu 2015; Mukherjee et al. 2013)\nis a review graph where nodes represent reviews. LifeIns is a\nmedical insurance graph based on real-world data provided\nby an anonymous insurance company. In LifeIns, nodes correspond to claims, and edges represent relationships predefined by domain experts. In experiments, we use p% of\nnodes as training sets, setting p = 40 for GossipCop-S and\nYelpChi, and p = 10 for LifeIns. The remaining nodes are\nsplit into validation and test sets with a ratio of 1:2, following the conventional setting in the GNN-based fraud detection (Tang et al. 2022). We create the training, validation,\nand test target sets with fraud nodes belonging to each split.\nEach target set represents a fraud gang organized based on\nmetadata or relations in each dataset. The statistic of datasets\nfor multi-target attacks is summarized in Table 2. More detailed descriptions of the datasets are in Appendix B.\nAlthough MonTi is designed for multi-target attacks, we\npresent benchmark results for single-target attacks on OGB-\nProd (Hu et al. 2020) and PubMed (Sen et al. 2008) in\nAppendix E.1. Despite not being specifically designed for\nsingle-target attacks, MonTi achieves the highest misclassification rates on both datasets. This demonstrates the effectiveness of MonTi's transformer-based architecture, which\ncaptures intricate interactions around a target node via adversarial structure encoding."}, {"title": "Budgets", "content": "Due to the diverse sizes and substructures of target sets, node and edge budgets should be allocated according to the characteristics of each target set. We also\nimpose limits on the budgets since excessively large budgets can lead to highly noticeable and easy attacks. The\nnode budget $\\Delta$ for each target set is defined as $\\Delta =$\n$\\text{max}([\\rho \\cdot \\text{min}(|N^{(1)} \\cup T|, \\bar{B}) + 0.5], 1)$ where $\\rho$ is a parameter\nto control node budgets, $\\bar{B} = |N^{(1)} \\cup T|$, and $\\bar{B}$ is the average value of $\\bar{B}$ across all target sets within the\ndataset. The edge budget $\\eta$ for each target set is calculated as $\\eta = \\Delta \\cdot \\text{max}([\text{min}(\\bar{d}_T, \\xi \\cdot \\bar{d}) + 0.5], 1)$ where $\\bar{d}_T$ is\nthe average node degree of the target set, $\\xi$ is a parameter to\ncontrol edge budgets, and $\\bar{d}$ is the average node degree of all\nnodes in the graph. Unless specifically stated otherwise, we\nset $\\rho = 0.05$, $\\xi = 0.1$ for GossipCop-S, $\\rho = 0.05$, $\\xi = 0.5$\nfor YelpChi, and $\\rho = 0.2$, $\\xi = 0.5$ for LifeIns. A detailed\nexplanation of the rationale behind defining the budgets and\nanalysis of the effect of $\\rho$ and $\\xi$ is provided in Appendix E.2."}, {"title": "Fraud Detectors, Baselines, and Implementation Details", "content": "We consider following models as surrogate and victim mod-\nels: GCN (Kipf and Welling 2017), GraphSAGE (Hamilton, Ying, and Leskovec 2017), GAT (Veli\u010dkovi\u0107 et al. 2018),\nCARE-GNN (Dou et al. 2020), PC-GNN (Liu et al. 2021),\nand GAGA (Wang et al. 2023c). Since we focus on graph in-\njec-tion evasion attacks where attack nodes are injected into\nthe original graph during the inference phase, we exclude\nfraud detectors that cannot handle the nodes added after\ntraining, such as BWGNN (Tang et al. 2022), SplitGNN (Wu\net al. 2023), and DGA-GNN (Duan et al. 2024). We use G-\nNIA (Tao et al. 2021), TDGIA (Zou et al. 2021), Cluster\nAttack (Wang et al. 2022), and G2A2C (Ju et al. 2023) as\nattack baselines. Further details on the experimental environment and implementation details of the fraud detectors\nand attack baselines are available in Appendix C, and implementation details of MonTi are described in Appendix D."}, {"title": "Performance of Multi-target Attacks", "content": "Table 3 presents the results of multi-target attacks when the\ntypes of surrogate and victim models are the same. We repeat all experiments five times and report the average and\nstandard deviation of the misclassification rates of all target\nsets weighted by their sizes, as the size varies across different target sets. Clean represents the misclassification rates\non the original clean graphs. We see that GNN-based fraud\ndetectors are more robust than vanilla GNNs due to their\nability to handle heterophily. MonTi shows the best attack\nperformance across all datasets, as it can search adversarial\nstructures more extensively than other methods.\nTable 4 shows the results in a more realistic and challeng-\ning scenario where GCN is the surrogate model and CARE-\nGNN, PC-GNN, and GAGA are victim models. MonTi out-\nperforms all baselines, even when merely using GCN as the surrogate model. This demonstrates that MonTi effectively\ngeneralizes its attacks by comprehensively capturing and leveraging the interdependencies between node attributes\nand edges, as well as among target, candidate, and attack\nnodes. More detailed analyses are provided in Appendix E.3."}, {"title": "Ablation Studies and Efficiency Analysis of MonTi", "content": "Table 5 shows the results of ablation studies on GossipCop-S for MonTi with the same settings as in Table 4. We replace the adversarial attribute and edge generation methods with random generation. For attributes, nodes are randomly selected from the original graph, and their attributes are assigned to attack nodes (random attributes). For edges, connections are randomly created among target, candidate, and attack nodes (random edges). We remove the learnable positional encodings p, $\\tilde{p}$, and $\\hat{p}$ (w/o pos. encoding) and modify MonTi to select the candidates randomly (random candidates). Lastly, we fix the degree budget for each attack node (fixed budget). In conclusion, the original MonTi shows the best performance, demonstrating the importance of each component of MonTi for effective graph injection attacks. More ablation studies are presented in Appendix E.4.\nWe also compare MonTi with attack baselines in terms of runtime and memory usage on GossipCop-S, YelpChi,\nand LifeIns, using GCN as the surrogate model and GAGA\nas the victim model in Appendix E.5. Overall, MonTi is\nthe most efficient in terms of runtime while maintaining\nmoderate memory usage. This is because MonTi effectively"}, {"title": "Case Study: Effects of the Size of Fraud Gangs", "content": "To analyze vulnerabilities of GNN-based fraud detectors regarding the size of fraud gangs, we categorize target sets in\nGossipCop-S into three groups based on $\\bar{B} = |N^{(1)} \\cup T|$,\nwhich reflects the size of the fraud gang. Table 6 presents\nthe multi-target attack performance of G-NIA and MonTi\nfor each category, using GCN as the surrogate model. The results show that the disparity in misclassification rates before and after the attack widens with increasing the size of\ngangs ($\\bar{B}$). This highlights the threats that large-scale fraud\ngangs pose to GNNs. Specifically, CARE-GNN and PC-\nGNN, which only filter node-level camouflages, are more\nvulnerable to relatively large fraud gangs ($\\bar{B} > 10$) compared to GAGA. Notably, the performance gap between G-\nNIA and MonTi becomes larger as the size of gangs increases, suggesting that MonTi can explore the complex\nstructures that could be formed by large fraud gangs more"}, {"title": "Discussion on Defenses against MonTi", "content": "Our research aims to investigate the vulnerabilities of GNN-based fraud detectors and highlight their risks by simulating\nattacks of fraud gangs in practical settings. In particular, our\nfindings suggest that GNN-based fraud detectors are especially susceptible to large-scale group attacks, which could\nundermine their reliability in real-world applications. We\ndiscuss potential approaches that could be beneficial to safeguarding against such threats. Our promising approach is to"}, {"title": "Conclusion and Future Work", "content": "We investigate adversarial attacks against GNN-based fraud\ndetectors with various practical scenarios and real-world\ndatasets. To the best of our knowledge, our work is the first\nstudy to explore such attacks against GNN-based fraud de-\ntectors and graph injection attacks for multiple target nodes\nformed by fraud gangs. We define this task as a multi-target\ngraph injection attack and propose MonTi, a new adversar-\nial attack model that injects all attack nodes at once. MonTi\nemploys adaptive degree budget allocation for each node to\nexplore diverse injection structures. Furthermore, MonTi si-\nmultaneously generates attributes and edges of attack nodes,\nconsidering the interdependency between them. Extensive\nexperiments on five real-world graphs show that MonTi out-\nperforms state-of-the-art graph injection attack methods in\nboth multi- and single-target settings. For future work, we\nwill extend MonTi to multi-relational graphs (Kim, Choi,\nand Whang 2023), as considering multiple relation types can\nbe beneficial to effective fraud detection. We also plan to\nexamine our work in inductive settings (Lee, Chung, and\nWhang 2023) where both victim and attack models do not\nobserve test nodes and their connections during training.\nMoreover, we will theoretically investigate MonTi in terms\nof generalization bounds (Lee, Hwang, and Whang 2024)."}, {"title": "Appendix", "content": "A Detailed Discussions on Related Work\nA.1 Graph-based Fraud Detection\nGraph-based fraud detection aims to identify entities associated with illicit activities by considering graph structures. It has\nbeen widely applied across various practical scenarios", "categories": "fraud or benign.\nIn fraud graphs, fraud nodes are much fewer than benign nodes, resulting in a class imbalance problem. In addition, fraud\nnodes tend to connect with benign nodes or imitate attributes of benign nodes to conceal"}]}