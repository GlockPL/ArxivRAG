{"title": "GMOCSO: Multi-objective Cat Swarm Optimization Algorithm based on a Grid\nSystem", "authors": ["Aram M. Ahmed", "Bryar A. Hassan", "Tarik A. Rashid", "Kaniaw A. Noori", "Soran Ab. M. Saeed", "Omed H. Ahmed", "Shahla U. Umar"], "abstract": "This paper presents a multi-objective version of the Cat Swarm Optimization Algorithm called the Grid-based Multi-\nobjective Cat Swarm Optimization Algorithm (GMOCSO). Convergence and diversity preservation are the two main\ngoals pursued by modern multi-objective algorithms to yield robust results. To achieve these goals, we first replace\nthe roulette wheel method of the original CSO algorithm with a greedy method. Then, two key concepts from Pareto\nArchived Evolution Strategy Algorithm (PAES) are adopted: the grid system and double archive strategy. Several test\nfunctions and a real-world scenario called the Pressure vessel design problem are used to evaluate the proposed\nalgorithm's performance. In the experiment, the proposed algorithm is compared with other well-known algorithms\nusing different metrics such as Reversed Generational Distance, Spacing metric, and Spread metric. The optimization\nresults show the robustness of the proposed algorithm, and the results are further confirmed using statistical methods\nand graphs. Finally, conclusions and future directions were presented..", "sections": [{"title": "Introduction:", "content": "The term optimization means trying to select the best solution for a specific problem among many\nalternative solutions. The objective can be minimization, such as minimizing cost or time, or it can\nbe maximization, such as maximizing profit or production [1]. In terms of Mathematics,\noptimization problems can be formulated in a generic form like follows:\n\nmin fi(x), (i = 1,2, ...,I)\nx\u2208Rn\n{\ncj (x) = 0, (j = 1,2,... ,J)\nSubject to\nlck(x) \u2265 0, (k = 1,2,..., K)\n(1)\nHere if we suppose that the parameters of the search space are denoted in a vector like \u201cx\u201d, then\nfi(x) will be the objective functions or sometimes called fitness functions.\nf(x) can be a minimizing or maximizing function depending on the design on hand. Finally, cj (x)\nand ck (x) are the equality and inequality constraints of the design problem respectively [2].\nOptimization Problems can be classified according to the objectives, constraints, landscape, form\nfunctions, and variables. When the classification is based on the number of objectives, there are\ntwo kinds of optimization problems, which are single and multi-objective. If equation (1) is taken,\nthe problem has a single objective, when I = 1. This means that there is only one goal in the search\nspace and all the factors are used to reach that goal. However, when I > 1, it is a multi-objective\nproblem, which contains multiple conflicting objectives or goals. Many of the real-world problems\nare of multi-objective types, for example, maximizing profits and meanwhile minimizing time or\ncost. When these objectives clash with each other, algorithms require having a trade-off between\nthem, which leads to the generation of a set of compromised solutions. This is commonly known\nas Pareto-optimal solutions [3]. In addition, constraints in optimization problems are those\nconditions that a solution must fulfill. Optimization problems can also be classified according to\nthe number of these constraints. For example, in the previous equation: if j = k = 0, this means\nthere are no constraints and it is known as an \u201cunconstrained optimization problem\u201d. As for the\nequation, if j > 0 or k > 0, the problem is known as \u201cequality-constrained optimization problem\u201d\nor \u201cinequality-constrained optimization problem\u201d respectively. Furthermore, depending on the\nnature of the problems, some models may require a discrete set of values to be used for representing\nthe solution sets [4]. These types of optimization are called discrete optimization. However, some\nother models, known as continuous optimization, are only comprehended when actual real\nnumbers are employed to represent the solution sets. It is worth mentioning that continuous\noptimization algorithms can also be used to solve discrete problems. Moreover, problems can be\ncalled linear if the change in the output is proportional to the change in the input. On the other\nhand, nonlinear problems are exactly the opposite, and thus their outputs are unpredictable, and\nthis makes them harder to be solved. Finally, Unimodal problems are those problems that have one\nglobal optimum in the search space, while multimodal problems have multiple global optima in\nthe search space [4].\nWhen dealing with multi-objective problems, Decision, and Objective Spaces need to be taken\ninto consideration. The decision space is a space that contains all the possible solutions, while the\nevaluations of these solutions are presented in a space called objective space. It is worth\nmentioning that, in real-world scenarios, some of these solutions, which are known as infeasible\nregions, are not applicable due to the design limitations of the problem [5]. In single objective\noptimization problems, one can easily compare two solutions and decide which one is better or\nmore optimum. However, in multi-objective optimization problems, the concept of dominance is\nrequired to compare the solutions.\nLet x and y be two solutions for a minimization multi-objective optimization problem, as shown\nin equation (2). Thus, the objectives are as follows:\n\nmin(f1(x), f(x), f3(x),..., fk(x))\nx\u2208X\nmin(f1(y), f2(y), f3(y), ..., fk(y))\nyeX\n(2)\nWhere k \u2265 2 and the set X includes all the feasible solutions.\nThen: x dominates y if:\n1. fi(x) \u2264 fi(y) for all indices i \u2208 {1,2, ..., k}\n2. fj(x) < fj(y) for at least one index j \u2208 {1,2,...,k}\nTherefore, x dominates y i.e. x < y if:\n1. Solution y is not better than solution x in any of the objectives\n2. Solution x is better than solution y in at least one objective.\nIn the process of multi-objective optimization, solutions are often obtained, where neither of\nthem dominates the others i.e. one solution dominates the other for an objective function, and\nmeanwhile, the other solution dominates this solution for a different objective function. These\ntypes of solutions, which cannot be dominated by the other solutions, are known as non-dominated\nsolution set [6].\nIn addition, the non-dominated solution set belonging to the whole feasible decision space is\nknown as the Pareto front. Those Pareto front solutions that cannot be further improved are called\nTrue Pareto front. If an evolutionary multi-objective algorithm is not able to find the True Pareto\nfront, it will attempt to obtain an approximate set of solutions that is close to it. This set of solutions\nis called the Approximate Pareto Front.\nSeveral methods have been offered for multi-objective problems. Schafer initially proposed the\nnovel notion of using evolutionary optimization methods for multi-objective optimization in 1984\n[2]. Ever since many scholars have tried to create various multi-objective algorithms. For example,\nNon-dominated Sorting Genetic Algorithm 2 (NSGA-II) [7], Multi-objective Particle Swarm\nOptimization (MOPSO) [8], Multi-objective Evolutionary Algorithm based on Decomposition\n(MOEA/D) [9], Pareto Archived Evolution Strategy (PAES) [10], and Strength Pareto\nEvolutionary Algorithm (SPEA/SPEA2) [11] are among the most well-known algorithms in the\nliterature. The cat Swarm Optimization Algorithm is a robust metaheuristic swarm-based\nalgorithm, which is originally proposed by Chu et al. in 2006 [12]. Pradhan and Panda proposed\nmulti-objective Cat Swarm Optimization (MOCSO) by extending CSO to deal with multi-\nobjective problems [13]. MOCSO is combined with the concept of the external archive and Pareto\ndominance to handle the non-dominated solutions. Orouskhani et al. proposed a Multiobjective\nalgorithm by combining the CSO algorithm with Borda ranking [14]. They also proposed an\nenhanced version by combining the CSO algorithm with an opposition-based learning technique\nand the elitism idea [15]. Dwivedia et al. extended the quantum-inspired cat swarm optimization\nas a Multiobjective algorithm, which uses the idea of Qubits [16]. Murtza et al. extended the integer\ncat swarm optimization as a multi-objective algorithm, which can be used for binary multi-\nobjective problems [17].\nMulti-objective algorithms have two main goals to pursue while searching for optimum solutions;\nthese goals are convergence and diversity preservation [18]. In the first one, the Approximate\nPareto front has to move towards the True Pareto front as much as possible, and hence, the\nalgorithm obtains better and more optimum solutions. However, in Diversity preservation, the set\nof solutions in the Approximate Pareto front has to be well distributed in the area. The word \u201cwell\ndistribute\" means that they have to cover the whole area of the Pareto front and have uniform\ndistances in between as much as possible. The reason behind this goal is to provide the Decision\nmaker with solutions from all areas and let him/her choose their region of interest (ROI).\nTherefore, this paper presents a multi-objective version of the Cat Swarm Optimization Algorithm,\nwhich is called the Grid-based Multi-objective Cat Swarm Optimization Algorithm (GMOCSO).\nTo accomplish these objectives, we start by substituting a greedy method for the original CSO\nalgorithm's roulette wheel mechanism. The grid structure and double archive method are then\nincorporated as essential ideas from the Pareto Archived Evolution Strategy Algorithm (PAES).\nThe pressure vessel design challenge is a real-world case study that is utilized along with several\ntest functions to gauge how well the suggested method performs. Using various measures,"}, {"title": "Grid-based Multi-objective Cat Swarm Optimization Algorithm\n(GMOCSO):", "content": "The proposed algorithm adopts two key concepts from the PAES algorithm [10] to extend the CSO\nalgorithm into a multi-objective scheme. First, the proposed algorithm has two populations called\ninternal and external populations. The internal population is used to store the initial population and\nthe dominated individuals, whereas the external archive (repository) is used to store the non-\ndominated individuals in each iteration. This external archive is empty at the beginning and has a\npredefined size that cannot be exceeded. Second, the proposed algorithm uses a hyper-grid system\nto determine the least crowded area in the Pareto front of the objective space. This hyper-grid\nscheme divides the objective space into several non-overlapping hyper-boxes, where each box\nmight contain several agents. Figure (1) explains the hyper-grid system.\nThe fitness values of these agents denote their coordinates in the objective space. Consequently,\nthis can be used to specify which agent belongs to which hyper-box. Agents inside the least\ncrowded box are called leaders and one of them is used as a global attraction mechanism, where\nthe rest of the agents tend to move towards it. In addition, the roulette wheel method of the CSO\nalgorithm is replaced with the greedy method to drive the agents to move toward the global\noptimum and hence increase the exploitation ratio of the algorithm.\nTherefore, the algorithm takes the following steps in the optimization process:\n1. Randomly generate the initial population of cats.\n2. Calculate the fitness cost for all the cats.\n3. Determine the non-dominated cats and store them in an external archive.\n4. Use the hyper-grid system to create the hyper boxes.\n5. The archive has a predefined size (for example archive=100); If the archive was overfilled,\nselect the most crowded box and delete the extra members.\n6. Then, select the least crowded box and randomly select a member from the box to be the\nleader.\n7. Send the leader to the tracing mode.\n8. Assign all the cats into the tracing mode.\nUpdate velocities for all the cats using equation (3).\n\nVkd = Vk,d + C\u2081 * rand * (Xleader,d - Xkd)\n(3)\nWhere Vkid is the velocity for the kth cat in the dthdimension; Xleader d is the position of the leader\ncat, which was chosen from the least crowded box; Xkd is the current position of the kth cat in the\ndth dimension. C\u2081 is a constant and rand is a single uniformly distributed random number in the\nrange of [0, 1].\nUpdate positions for all the cats using equation (4).\n\nXkd = Xkd + Vk,d\n(4)\nWhere Xk,d is the position of a cat in the dth dimension.\n9. Assign the cats into the seeking mode:\nUse CDC and SMP parameters to generate the candidate positions, where the original\nposition is one of the candidates.\nDeterminate the non-dominated candidate position to be a new position; if there were\nmore than one non-dominated candidate, randomly select one of them.\n10. If any cat dimension is out of the boundary, it is equal to the limits, as in equation (5):\n\n[\n    Ld La if Xkd < La\nXkd = \n    Ud if Xk,d > Ud\n(5)\nWhere La and U\u0105 are lower and upper bounds for the search space.\nd\n11. Check if the termination condition is satisfied, then terminate the program. Otherwise,\nrepeat Step 2 to Step 10, see Figure (2)"}, {"title": "Performance evaluation framework for the GMOCSO algorithm", "content": "In this section, the performance of the proposed GMOCSO algorithm is evaluated using a general\nperformance evaluation framework as shown in Figure (3). The framework consists of two\ndifferent criteria as follows:\ni. Applying the algorithm on ZDT benchmark functions.\nii.\nApplying the algorithm to a real-world scenario.\n3.1.1 Benchmark functions\nTo assess the performance of the proposed GMOCSO algorithm, it was first applied to five\ncommon benchmark functions which were ZDT1, ZDT2, ZDT3, ZDT4, and ZDT6 [21]."}, {"title": "Experiment setting:", "content": "For each benchmark function, the algorithm was executed for 30 independent runs. For each run,\nthe number of both search agents and iterations was equal to 100. Furthermore, the results were\ncompared with three well-known algorithms, namely Multi-objective Mayfly Optimization\nAlgorithm (MMA) [19], Multi-objective Dragonfly Algorithm (MODA) [20], and Strength Pareto\nEvolutionary Algorithm 2 (SPEA2) [11].\nThen, three essential metrics were used to assess the achieved results, which are listed below:\n1. Reversed Generational Distance\nReversed Generational Distance or rGD. This metric is calculated by determining the Euclidian\ndistance between the points of the true Pareto front and the closes point on the approximate Pareto\ndistance [22]. The main purpose of this criterion is to show the ability of the different algorithms\nto determine a set of non-dominated individuals having the shortest distance with the true Pareto\noptimal fronts. Therefore, it can be seen that algorithms with the smallest generation distance\n(rGD) produce the best convergence to the true Pareto front i.e. the approximate Pareto front is the\nclosest to the true Pareto front. Furthermore, the best rGD value that can be achieved by an\nalgorithm is zero, where the approximate Pareto front and the true Pareto front are similar.\nEquation (6) presents the mathematical details of this metric:\n\nrGD(t) = \\frac{\\sqrt{\\sum_{i=1}^{\\left|P^*(t)\\right|} di}}{\\left|P^*(t)\\right|}\n(6)\nwhere di is the Euclidean distance between the i-th member of P*(t) and its closest point from Q(t);\nP*(t) is the true Pareto front and Q(t) is the obtained Pareto Front.\n2. Spacing metric\nThe main purpose of the Spacing metric (S) is to demonstrate how well the non-dominated\nindividuals are distributed along the approximate Pareto front. The best distribution is where the\nindividuals are equally distributed and the distance between them is equal. Equation (7) presents\nthe mathematical details of the Space metric [23].\n\nS = \\sqrt{\\frac{1}{Npf} \\sum_{i=1}^{npf} (di - \\bar{d})^2}\n(7)\nWhere npf is the number of members in the approximate Pareto front and di is the Euclidean\ndistance between the member within the approximate Pareto front and the nearest member in the\napproximate Pareto front. Therefore, the algorithm with the minimum S value has the best\ndistribution of its individuals. In the best case, the S value is equal to zero, where the solutions are\ncompletely uniform and the distance between the non-dominated solutions is equal.\n3. Spread metric or Delta metric\nThis metric is also called the Delta metric, which is used to show how far the non-dominated\nsolutions have extended and how well they are spread along the approximate Pareto front. Equation\n(8) presents the mathematical details of this metric:\n\n\u0394 = \\frac{df + dl + \\sum_{i=1}^{npf}|di - \\bar{d}|}{df + d\u2081 + (npf - 1)\u0101}\n(8)\nwhere df and dl are the Euclidean distances between the extreme solutions in the true Pareto front\nand the approximate Pareto front, respectively. Further, di is the Euclidean distance between each\npoint in the approximate Pareto front and the closest point in the true Pareto front. npf and d\u00af are\ndefined as the total number of members in the approximate Pareto front and the average of all\ndistances, respectively [23].\nSubsequently, based on the results that can be achieved from the three metrics, the Friedman test\nwas used to rank the algorithms and determine their overall performances. For this, the average\nvalues that were achieved from the 30 independent runs were used. Meanwhile, the Wilcoxon sum\nrank test is used to calculate P-values and confirm the result.\nApart from these well-known metrics, another metric called elapsed time measurement was\nalso used. The elapsed time calculates the amount of time each algorithm requires to finish one\nindependent run."}, {"title": "Appling the GMOCSO algorithm on a real-world scenario", "content": "The proposed GMOCSO algorithm was also applied to a real-world scenario called the Pressure\nvessel design problem [24]. A cylindrical pressure vessel is topped at both ends by curved heads\nas presented in Figure (4).\nThe problem considers the design of an air storage tank with a working pressure of 1000 psi and a\nminimum volume of 750 ft3.\nThe first objective of the problem is to reduce the total cost of a cylindrical pressure vessel. This\ncost involves the cost of material and the cost of forming and welding) :\n\nf1(x) = 0.6224x1x3x4 + 1.7781x2x3 + 3.1661x2x4 + 19.84x2x3,\nSubject to:\ng1 g\u2081(x) = x1 - 0.0193x3 \u2265 0,\ng2(x) = x2 - 0.00954x3 \u2265 0,\n\ng3(x) = \\frac{4}{3}\\pi x3x4 + \\pi x3 \u2013 1296000 \u2265 0,\n(9)\nWherex1, x2 \u2208 {1, \u2026\u2026\u2026\u2026\u2026,100}, x3 \u2208 [10,200], and x4 \u2208 [10,240]. x\u2081 and x2 are integer multiples\nof 0.0625.\nX\u2081 = Ts, which represents the thickness of the shell\nX2 = Tb, which represents the head of the pressure vessel\nX3 = R, which represents the inner radius\nX4 = L, which represents the length of the cylindrical section\nThe second objective of the problem is the sum of the three constraint violations:\n\nf2(x) = \\sum_{i=1}^{3} max{g(x),0}\n(10)\nThe experiment settings and the parameter settings are all the same as in the previous section."}, {"title": "Results and Discussions:", "content": "Based on the evaluation criteria mentioned in the previous section, the following results are obtained,\nwhich are presented below:\n4.1 Results for benchmark functions:\nThe proposed GMOCSO algorithm was first benchmarked on six test functions called the ZDT\nfunctions. In the experiment, three more algorithms were chosen for comparison, namely the multi-\nobjective Mayfly optimization algorithm (MMA) [19], the multi-objective Dragonfly Algorithm\n(MODA) [20], and Strength Pareto Evolutionary Algorithm 2 (SPEA2) [21].\nThe results of the benchmark functions are presented in Table (3).\n3.1.1 Results and Discussions for the Pressure Vessel Design Problem\nThe GMOCSO algorithm was also applied to a real-world scenario called the Pressure Vessel\ndesign problem. Similar to the previous section, the proposed algorithm was compared with three\nmore algorithms, which are the multi-objective Mayfly optimization algorithm (MMA) [19],\nmulti-objective Dragonfly Algorithm (MODA) [20], and Strength Pareto Evolutionary Algorithm\n2 (SPEA2) [21]. The algorithms were run 30 independent times, and each time, the number of\nsearch agents and iterations was 100. Then, the average value and standard deviation of these 30\nindependent runs were taken. Furthermore, the algorithms were also compared using the elapsed\ntime measurement. The results are all presented in Table (7). It can be noticed, that the proposed\nGMOCSO algorithm yields very competitive results."}, {"title": "Conclusion:", "content": "This paper presents a multi-objective version of the Cat Swarm Optimization Algorithm,\nwhich is called the Grid-based Multi-objective Cat Swarm Optimization Algorithm (GMOCSO).\nFor this, two main modifications were made. First, the seeking mode of the algorithm was modified\nand the roulette wheel approach was replaced with a greedy method. This technique increases the\nconvergence rate of the algorithm. Second, to preserve the diversity of the non-dominated solutions\nin the objective space, two key concepts from the PAES algorithm were adopted, which were the\nexternal population and the hyper-grid box techniques. In addition, several benchmark functions\nand a real-world scenario called the Pressure Vessel Design problem were used to evaluate the\nperformance of the proposed algorithm. The results were then compared with three other well-\nknown algorithms. Next, the Friedman test and the Wilcoxon sum rank were used to rank the\nalgorithms and confirm the results. Furthermore, the elapsed time measurement was used to test\nthe efficiency of the algorithm. Finally, it can be concluded that the proposed algorithm can\nefficiently converge towards the Pareto front solutions and still preserve its diversity along the\narea. In the future, one can replace the hyper grid box with the indicator-based method to obtain\nbetter diversity perseverance. We have noticed that in recent years, optimization algorithms are\nstill considered one of the most promising techniques in terms of being integrated with other\ntechnologies. This means that the changes and developments in it are continuing to come up with\nnew methods that can be more effective and capable of yielding more satisfying results. For future\nreading, the authors advise the reader could optionally read the following research works wing\nresearch works [25]-[42]."}]}