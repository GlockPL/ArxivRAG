{"title": "ASD-Diffusion: Anomalous Sound Detection with Diffusion Models", "authors": ["Fengrun Zhang", "Xiang Xie", "Kai Guo"], "abstract": "Unsupervised Anomalous Sound Detection (ASD) aims to design a generalizable method that can be used to detect anomalies when only normal sounds are given. In this paper, Anomalous Sound Detection based on Diffusion Models (ASD-Diffusion) is proposed for ASD in real-world factories. In our pipeline, the anomalies in acoustic features are reconstructed from their noisy corrupted features into their approximate normal pattern. Secondly, a post-processing anomalies filter algorithm is proposed to detect anomalies that exhibit significant deviation from the original input after reconstruction. Furthermore, denoising diffusion implicit model is introduced to accelerate the inference speed by a longer sampling interval of the denoising process. The proposed method is innovative in the application of diffusion models as a new scheme. Experimental results on the development set of DCASE 2023 challenge task 2 outperform the baseline by 7.75%, demonstrating the effectiveness of the proposed method.", "sections": [{"title": "1 Introduction", "content": "The purpose of anomalous sound detection (ASD) in the industrial scene is to monitor the machine's condition by distinguishing between normal and anomalous machine-generated sounds. Detection and classification of acoustic scenes and events (DCASE) challenge and workshop is committed to advancing the field of sound event detection. Since 2020, ASD has been adopted as a new task and held every year until now in DCASE challenge [18]. Previous methods achieve better performance by using test data in development set to tune hyper-parameters of the model [5]. However, in some practical conditions, due to the diversity of operational conditions and atypical anomalies, it is challenging to collect anomalous sounds with comprehensive pattern coverage and collect anomalous data for tuning.\nConsidering all the above factors, a main goal of DCASE 2023 task 2 is to detect anomalous sounds when only normal sounds are given without tunable hyper-parameters of the trained model for each machine type, which is called first-shot ASD.\nA series of methods, which can be generally divided into self-supervised and unsupervised methods, have been proposed to tackle these issues. Self-supervised ASD introduces classification as an auxiliary task to calculate anomalous degree in accordance with classification confidence. However, since classification-based self-supervised approaches extremely rely on additional labels (i.e. machine ID or attribute) from metadata [1,12,8], effectiveness may degrade when auxiliary labels are limited or domain shifts occur [5].\nUnsupervised ASD approaches minimize the negative log-likelihood or reconstruction error as the optimization objective and learn the distribution only from the acoustic features of normal sounds. Anomalies of audio are detected by the inner likelihood of the learned distribution or the reconstruction error of generated samples. A flurry of generative models have been previously explored in ASD, such as variational autoencoder (VAE) [2], generative adversarial network (GAN) [15], and normalizing flows (NF) [4]. In recent studies, denoising diffusion probabilistic model (DDPM) [11], as an emerging generative model, has attracted much attention from researchers in many fields. It has been proven that DDPMs are capable of generating samples from complex data distributions with broader pattern coverage than VAEs and GANs [3]. These properties are considered suitable for anomaly detection that lacks anomalous samples. Recent advances in computer vision also indicate that DDPM is well suited to anomaly detection tasks. Until now, DDPM has been used for anomaly detection in images. AnoDDPM [23] achieves a huge improvement over GAN-based approaches in medical image anomaly detection. DiffusionAD [25] outperforms other methods in general image anomaly detection. However, applying diffusion models to ASD remains challenging and has not been explored.\nSince the high-dimensional time-frequency information in audio can be intuitively represented in the acoustic features (i.e. mel-spectrogram), employing diffusion models for anomaly detection in these acoustic features is a reasonable choice. Inspired by the works mentioned above, we propose ASD-Diffusion, a novel diffusion-based ASD approach. The main contributions of this paper can be summarized as follows:\n*   A diffusion-based approach to ASD. To the best of our knowledge, ASD-Diffusion is the first time that diffusion models have been applied to the field of ASD.\n*   A carefully designed post-processing anomalies filter (AF) algorithm, which is well suited for anomaly detection in samples reconstructed by diffusion models. Meanwhile, it can also be used for anomaly localization.\n*   For problems of long sampling timesteps existing in DDPM, we introduce denoising diffusion implicit model (DDIM) [22] in the inference process to accelerate sampling."}, {"title": "2 Methods", "content": ""}, {"title": "2.1 Diffusion Models for ASD-Diffusion", "content": "DDPM In general, DDPM specifies a forward diffusion process and a reverse denoising process illustrated in Fig. 1. The input data are gradually disturbed by adding Gaussian noise for a few timesteps in the forward diffusion process and DDPM is guided to reconstruct target noise-free data from corrupted data in the reverse denoising process. Assume that the distribution of normal sounds is $\\phi(x)$, the forward diffusion process is defined as\n$q(x_t | x_0) = \\mathcal{N} (x_t | x_0\\sqrt{\\bar{\\alpha}_t}, (1 -\\bar{\\alpha}_t) I)$  (1)\n$x_t = x_0\\sqrt{\\bar{\\alpha}_t} + \\epsilon_t\\sqrt{1 - \\bar{\\alpha}_t}, \\epsilon_t \\sim \\mathcal{N}(0, I)$ (2)\nwhere data $x_0 \\sim \\phi(x)$ is transformed into noisy data $x_t$ for $t \\in \\{0,1,...,T\\}$ by adding noise for $t$ timesteps to $x_0$. Here, $\\bar{\\alpha}_t = \\prod_{i=0}^t \\alpha_i = \\prod_{i=0}^t (1 - \\beta_i)$ and $\\beta_t \\in (0,1)$ represents the noise variance schedule. This can be defined as a schedule from $\\beta_1 = 10^{-4}$ to $\\beta_T = 10^{-2}$ [11,21,13].\nAs $x_T$ is shown in Fig. 1, the distribution of $x_0$ is gradually disrupted and approaches Gaussian noise when $t$ increases. A neural network $\\epsilon_{\\theta} (x_t, t)$ is trained to predict added noise $\\epsilon$ by minimizing the training objective with mean squared error (MSE) loss:\n$L = E_{t\\sim [1-T],x_0\\sim q(x_0),\\epsilon\\sim \\mathcal{N} (0,1)} (||\\epsilon - \\epsilon_{\\theta} (x_t, t)||^2)$ (3)\nAt inference phase, $x_{t-1}$ is reconstructed from previous step $x_t$ in reverse process with the diffusion model $\\epsilon_{\\theta} (x_t, t)$ according to:\n$x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}}(x_t - \\frac{1}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_{\\theta} (x,t)) + \\beta_t z$ (4)\nin which, $z \\sim \\mathcal{N}(0, I)$ and $\\beta_t = \\frac{1 -\\bar{\\alpha}_{t-1}}{1 -\\bar{\\alpha}_t} \\beta_t$. $x_0$ is reconstructed to fit $\\phi(x)$ from $x_t$ in a way of Markovian chain."}, {"title": "DDIM", "content": "DDIM DDIM is generalized from DDPM via a class of non-Markovian diffusion processes. In DDIM, sample $x_{t-1}$ can be generated from sample $x_t$ via:\n$x_{t-1} = \\sqrt{\\alpha_{t-1}} \\Big(\\frac{x_t}{\\sqrt{\\alpha_t}} - \\sqrt{\\frac{1 - \\bar{\\alpha}_t}{\\alpha_t}} \\epsilon_{\\theta} (x_t)\\Big) + \\sqrt{1-\\alpha_{t-1} - \\sigma_t^2} \\epsilon_{\\theta} (x_t) + \\sigma_t\\epsilon$  (5)\n$\\epsilon \\sim \\mathcal{N}(0, I)$ is standard Gaussian noise independent of $x_t$.\nDifferent values of $\\sigma_t$ will lead to different generative processes. When $\\sigma_t = \\sqrt{(1 - \\bar{\\alpha}_{t-1})/(1 -\\bar{\\alpha}_t)}\\sqrt{1-\\bar{\\alpha}_t/\\bar{\\alpha}_{t-1}}$ for all $t$, the forward diffusion process becomes Markovian, and the generative process becomes a DDPM. When $\\sigma_t = 0$ for all $t$, samples are generated from latent variables with a fixed procedure (from $x_T$ to $x_0$), the process becomes DDIM. This fixed denoising procedure results in a more stable reconstruction to approach $\\phi(x)$. The specific derivation process of Eq.5 can be seen in [22].\nIn DDIM, since the forward and reverse processes are non-Markov, samples can be reconstructed with a larger sampling interval in the reverse process, saving a lot of computing resources. Meantime, the training objective is also MSE loss shown in Eq.3, which means that there is no difference in the training process with DDPM."}, {"title": "2.2 Anomaly Detection with Diffusion Models", "content": "The overall architecture of ASD-Diffusion is illustrated in Fig. 2. In our work, filterbank (FBank) features extracted from waveform is chosen for anomaly detection. Since the difference between anomaly and normality can be roughly divided into frequency domain and time domain, FBank is considered suitable for anomaly detection that contains abundant time-frequency information.\nDuring the training stage, ASD-Diffusion corrupts the FBank of normal samples $x_0$ to $x_t$ by adding Gaussian noise with a random parameter $t \\in \\{0,1,...,T\\}$, and noise scale is controlled by $\\alpha_t$ in Eq.1. Then the denoising network $\\epsilon_{\\theta} (x_t, t)$ predicts the added noise of $x_t$. The denoising loss in Eq.3 can be simplified as:\n$L_{denoising} = || \\epsilon_t - \\epsilon_{\\theta} (x_t, t) ||^2$ (6)\nwhere $\\epsilon_{\\theta} (x_t,t)$ learns the distribution of normal samples through minimizing $L_{denoising}$.\nDuring inference, since anomalous samples share distributions different from $\\phi(x)$, an effective method is to corrupt the anomalous samples by forward diffusion and reconstruct them into their approximate normal samples in $\\phi(x)$. Then the anomalies are detected by comparison between original and reconstructed samples. In our method, a strategy of partial diffusion is adopted. The"}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Dataset", "content": "The experiments are carried out on the DCASE 2023 task 2 development dataset (conducted on ToyADMOS2 [10] and MIMII DG [6]) including seven machine types. Each machine type in the dataset has one section that contains data for training and testing. Each audio recording is single-channel with a duration of 6 to 18 sec and a sampling rate of 16 kHz.\nDomain shift is introduced to reflect changes in the working conditions of machines. Most of the training data comes from the source domain. Each section of a machine type contains: (a) 990 clips of normal sounds in the source domain for training. (b) 10 clips of normal sounds in the target domain for training. (c) 100 clips each of normal and anomalous sounds including data from both domains for testing."}, {"title": "3.2 Experimental Settings", "content": "The 128-dimensional FBank is extracted on 25ms hann windows with 10ms shifts after 1024-point Fast Fourier Transformation (FFT), then the magnitude is normalized to [0, 1]. The FBank of each audio is divided into multiple segments of 128 x 128 by applying a sliding window. Since diffusion models do not require a large amount of data, the hop size of the sliding window is 128 for training and 5 for testing. The model is trained on a single NVIDIA 3090 GPU and implemented with PyTorch. As for training parameters, the U-net architecture is adopted as the denoising network. The hyper-parameters are listed in Table. 1.\nReverse timestep t is chosen by experience, since the data is fully corrupted with larger t, the reconstruction error may not be an effective detector. Similarly, if the corruption is minimal with smaller t, it will also be useless."}, {"title": "3.3 Evaluation Metrics", "content": "Area under receiver operator characteristic curve (AUC) is the most widely used metric in ASD, since anomaly detection is essentially a binary classification task. Same to the DCASE 2023 challenge, we adopt source-AUC (SAUC), target-AUC (tAUC) and partial-AUC (pAUC) as the evaluation metrics. Then the final system score is obtained by calculating the harmonic mean (hmean) for all machine domains and types. Compared with arithmetic mean, hmean is more susceptible to the influence of low values, which is adopted to evaluate the overall performance of ASD systems [9]."}, {"title": "4 Results", "content": ""}, {"title": "4.1 Main Results", "content": "To demonstrate the effectiveness of ASD-Diffusion, other unsupervised methods are chosen for comparison. For fairness, we first compared all unsupervised methods from the top five teams in DCASE 2023, specifically those not employing machine ID or machine attribute. AE (MAHALA) [9] is the baseline provided by the challenge organizers. GAN-VAE [24] is the fourth team in the challenge.\nIn our method, the ReLU function is used only for bearing, fan, slider, and Toy-Train, while the parameter K in the TopK function is adjusted for each machine type to achieve the best performance.\nAs illustrated in Table. 2, ASD-Diffusion outperforms other approaches with an improvement of 7.75% and 1.04%, respectively, which means that our method ranks fourth on this dataset. The overall hmean is higher than other methods, which demonstrates that ASD-Diffusion can be better generalized to more machine types. Note that the overall tAUC is substantially superior to other methods on most machine types without any domain adaptation method, even though only 10 normal audios from the target domain are provided for training. We argue that this is due to the powerful pattern coverage ability of diffusion, that is,"}, {"title": "4.2 Comparison with Self-supervised Methods", "content": "In Table. 3, our method is compared with self-supervised methods among the top three teams [14,20,16]. As mentioned in the introduction, self-supervised methods achieve better results due to the use of auxiliary labels for classification. In comparison, unsupervised methods are more broadly applicable and can be used even in the absence of reliable auxiliary labels. As shown in Table. 3, our method is closer to the third self-supervised method [14]. Furthermore, we found that the main performance difference between self-supervised and unsupervised methods is the valve machines, indicating that the reconstructed-based method may not well reflect the anomalous characteristics of the valve. We consider this to be the non-stationary characters of the valve sounds [7] that the reconstructed acoustic features have a large deviation from the original inputs. Therefore, even the normal sounds are reconstructed poorly, showing challenges in detecting anomalies."}, {"title": "4.3 Visualization of Anomaly Detection", "content": "The results of anomalous detection can be visualized in Fig. 3. We chose one normal and one anomalous audio from the test set of fan for comparison. The first and second rows are the original and reconstructed FBank respectively. The third and last rows are the visual detection results of MAE and the AF respectively. In the detection results, the brighter the region, the more likely it is to contain anomalies. While preserving the overall energy distribution of\nacoustic features, details are reconstructed at a fine-grained level. Therefore, subtle anomalies in both the time domain and the frequency domain become apparent. From the comparison of the first and second rows in Fig. 3 (a), there is a clear difference in the middle channels of FBank, which may mean the existence of anomalies. However, subtracting and taking the absolute value causes possible"}, {"title": "4.4 Influence of AF Parameter", "content": "We further explore the influence of hyperparameters in AF on the performance. We choose SAUC as the evaluation metric because it is relatively better and will not be affected by domain adaptation. In other words, different AF parameters will have a more significant impact on it. We conducted experiments from two aspects: whether to use ReLU and the percentage K of the selected TopK pixels to all pixels. In our experiments, different values of K from 0 to 1"}, {"title": "4.5 Accelerating Inference Speed by DDIM", "content": "We conduct a comparative experiment between DDPM and DDIM on the bearing. It is demonstrated in Table. 4 that compared with DDPM, DDIM greatly improves the inference speed with lower Real Time Factor (RTF) while maintaining better performance. Compared with DDPM, the deterministic reverse process exhibits superior consistency [22]. For the ASD task, the consistency of the reverse process is more critical than diversity. We consider this to be a difference between generative tasks and anomalous detection tasks."}, {"title": "5 Conclusions", "content": "In this paper, we introduce diffusion models to the field of anomalous sound detection for the first time and propose a novel method named ASD-Diffusion. Our method showcases the efficacy of diffusion models for ASD. Experimental results outperform other unsupervised methods in DCASE 2023. Meanwhile, from a practical standpoint, our method achieves interpretability and localization of anomalies with the high-quality reconstruction from DDPM. In future work, we will focus on further exploring unsupervised methods and providing better anomaly localization for ASD."}]}