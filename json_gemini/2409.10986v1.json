{"title": "Control-flow Reconstruction Attacks on Business Process Models", "authors": ["Henrik Kirchmann", "Stephan A. Fahrenkrog-Petersen", "Felix Mannhardt", "Matthias Weidlich"], "abstract": "Process models may be automatically generated from event logs that contain as-is data of a business process. While such models generalize over the control-flow of specific, recorded process executions, they are often also annotated with behavioural statistics, such as execution frequencies. Based thereon, once a model is published, certain insights about the original process executions may be reconstructed, so that an external party may extract confidential information about the business process. This work is the first to empirically investigate such reconstruction attempts based on process models. To this end, we propose different play-out strategies that reconstruct the control-flow from process trees, potentially exploiting frequency annotations. To assess the potential success of such reconstruction attacks on process models, and hence the risks imposed by publishing them, we compare the reconstructed process executions with those of the original log for several real-world datasets.", "sections": [{"title": "1 Introduction", "content": "Under the umbrella of process mining, event logs that have been recorded by information systems facilitate the analysis of qualitative and quantitative properties of business processes [27]. Event logs support information systems engineering through the discovery of process models [1], which are useful for understanding the flow of the process and, once annotated with performance characteristics, help to identify performance bottlenecks and improvement opportunities.\nDiscovery algorithms generalize and aggregate the behaviour recorded in an event log. As a consequence, individual process executions are not directly represented, when publishing the model [18], e.g., to an external party for the purpose of process certification, staff training or consulting. However, in practice, process models are not limited to the generalized control-flow of a process. Rather, they also contain summary statistics about the behaviour, most prominently execution frequencies or branching probabilities [3,4,10]."}, {"title": "2 Related Work", "content": "Any attempt to reconstruct the original process executions from a process model is related to privacy risks, which received much attention in recent years. However, we notice that existing work on the quantification of privacy risks in process mining [28] and the development of a large number of related privacy-preserving techniques [11,13,21,22] has focused primarily on event logs. As such, there is a reasonable level of understanding of these risks and possible mitigation strategies.\nThe risks induced by process models discovered from event logs, in turn, have been described only recently in [18]. Here, the authors quantify the re-identification risk in frequency annotated block-structured process models with a two-step approach: First, a play-out strategy is used to reconstruct event logs from the process model. Second, the measures proposed in [20] are used to quantify the re-identification risk in the reconstructed log, to then assess the re-identification risk of the original log caused by the release of the process model. However, this approach is only feasible if there is a strong similarity between the reconstructed logs and the original log. This aspect is not further studied in [18], though, which is a research gap that we close with our work.\nPlay-out strategies and the comparison of the obtained output with a ground truth are also studied in other process mining settings: Conformance checking [6] relates the behaviour described by a process model with behaviour in an event log. Yet, often we cannot fully trust both our model and the source event log, as indicated in [25]. In our context, missing or extra behaviour in the process model as assumed in conformance checking would further impair the chance of a successful reconstruction attack. As such, we assume the process model to be a good representation of the observed process behaviour, which presents the worst case for any attempt to derive insights on the underlying business process, as it simplifies the reconstruction. Both process simulation [5] and stochastic process mining [3] aim to more accurately capture the underlying process observed in process executions. These streams of research investigate how close simulated process executions [7] or the probability distributions in stochastic process model executions [16] are to the actual observations. Unlike our work, however, these approaches do not target the reconstruction of the original log, but on representing the general process behaviour including possible future process executions."}, {"title": "3 Preliminaries", "content": "Below, we summarize essential notions for event logs and process trees that are used in the remainder of the paper.\nEvent Log. Let A be the universe of activities. A trace $t \\in A^*$, where $A^*$ is the set of all finite sequences over A, is a sequence of activities. In such a trace, each activity a denotes the recorded event of the execution of a well-defined step in a process. $T = A^*$ denotes the universe of traces. A trace $t \\in T$ is represented as $t = (a_1, a_2, ..., a_n)$, where $a_1, a_2, ..., a_n \\in A$. With $|t|$ we denote the length of a trace $t \\in T$, i.e., the number of activities in the trace. Denoting with $B(X)$ the set of all possible multisets over X, let $L = B(T)$ be the universe of event logs. An event log $l\\in L$ is a finite multiset of traces.\nProcess Tree. In this work, we consider process trees as the formal model to capture business processes. A process tree represents a process in a hierarchical (block-structured) way [4,15]. Process trees can be transformed into models of other languages for business processes, such as Petri nets or BPMN models [27]. As such, the ideas outlined in the remainder are not limited to process trees. In general, a process tree denotes a process as a rooted tree. Its leaf nodes represent activities and all other nodes represent operators. Following the aforementioned references, we formally define a process tree as follows:\nDefinition 1 (Process Tree). Let $A \\subseteq A$ be a finite set of activities and let $T \\notin A$ denote the silent activity, which cannot be observed in a trace. A process tree Q, is defined recursively as:\nIf $a \\in A \\cup \\{r\\}$, then $Q = a$ is a process tree.\nIf $n \\geq 1, Q_1, Q_2,..., Q_n$ are process trees, and $\\oplus \\in \\{\\rightarrow, \\times, \\wedge\\}$, then $Q = \\oplus(Q_1, Q_2,..., Q_n)$ is a process tree.\nIf $n \\geq 2, Q_1, Q_2,..., Q_n$ are process trees, and $\\oplus =\\u21bb$,\nthen $Q = \\oplus(Q_1, Q_2,..., Q_n)$ is a process tree.\nA process tree might be annotated with information about probabilities or frequencies of the recorded behaviour. We capture such information by a weight $w\\in R$ that is assigned to a process tree Q, which is denoted by Q: w.\nConsider Fig. 2, which shows the process tree $Q = \\rightarrow (\\wedge(a, \\times(b, c)), \\u21bb (d, r))$. The $\\rightarrow$ operator refers to the execution of the child nodes in sequential order, i.e., the execution of $\\wedge(a, \\times(b, c))$ is followed by the execution of $\\u21bb (d, r)$. The $\\wedge$ operator defines the execution of all of its child nodes in any order, while the $\\times$ operator specifies an exclusive choice. The $\\u21bb$ operator has at least two children, the first being the \"do\" part of a loop; all other children representing \"redo\" parts. The \"do\" part is always executed; execution of the \u201credo\" part is optional and only one of the \u201credo\" parts is executed, before the \"do\" part is executed again.\nTo formalize the semantics of process trees, we need the following auxiliary operators for general sequences [27]:\nDefinition 2 (Auxiliary Operators). Let $\\sigma_1,\\sigma_2 \\in A^*$ be two sequences over A and let $S_1, S_2,..., S_n \\subseteq A^*$. We define two operators as:"}, {"title": "4 Control-Flow Reconstruction", "content": "As illustrated in our initial example in Fig. 1, process models may facilitate conclusions on the event log from which the model was discovered. We therefore formulate the respective control-flow reconstruction attacks as five different play-out strategies that, given a process tree, generate a reconstructed event log. We will compare in Section 5 the control-flow of the"}, {"title": "4.1 Play-out Strategies for Process Trees", "content": "In essence, a play-out strategy defines a particular traversal of the process tree according to the control-flow structure defined by it.\nDefinition 4. Given a process tree Q, a play-out strategy $p$ is a function that, applied to Q, returns an event log $L_p \\subseteq B(2^{L(Q)})$.\nBefore we formalize the individual aspects of each play-out strategy, we define some general rules that guide all strategies and apply to any traversal of a process tree, i.e., the generation of a single trace based on the process tree:\nR0 Start the traversal with an empty trace.\nR1 If a non-silent leaf node (i.e., not T) is encountered during the traversal, the respective activity is concatenated to the current trace.\nR2 If a silent leaf node (7) is encountered during the traversal, the current trace remains unchanged.\nR3 Once the traversal considered all children of a node Q, it returns to and continues with the parent node. If Q is the root node, the reconstructed trace will be added to the result.\nSimilarly, we provide some general rules for the play-out of process trees that relate to the operators for sequential composition and parallel composition. R$\\_A$ does not apply to the SOTA Strategy [18].\nR$\\_\\rightarrow$ When $Q = \\rightarrow (Q_1, ..., Q_n)$ is encountered, the traversal continues with the child nodes $Q_1,..., Q_n$ in the respective order."}, {"title": "5 Experimental Evaluation", "content": "In this section, we evaluate how well our proposed play-out strategies can reconstruct the control-flow of logs from their discovered models. We present our experimental setup in Section 5.1, and discuss evaluation measures in Section 5.2. Then, we describe our results in Section 5.3 and discuss them in Section 5.4."}, {"title": "5.1 Experimental Setup", "content": "Experimental Pipeline. We use the inductive miner without noise filtering to discover the process trees. The lack of noise filtering results in a perfect fitting process model, a necessary condition to be able to fully reconstruct the log from the model. In our setting, it is impossible to reconstruct control-flow information about the event log that is not present in the model. To determine the frequency of nodes, we replay each trace of the original event log on the process tree. Each time we visit a node, we increase its weight by one. For each strategy, we do 100 play-outs of each process tree to obtain the evaluation logs. For Strategy A and Strategy B, we fix the number of traces generated to the number of traces in the original log. Hence, our results for these strategies are an upper bound for the reconstruction risks, since usually the number of traces is not known to the adversary, when the model is not annotated with absolute frequencies.\nDataset. We evaluate the play-out strategies using four real-world event logs: the BPIC 2015 Municipalities log [9], the BPIC 2017 log [8], the BPIC 2013 Closed Problems log [26], and the Sepsis log [19]. In Table 1 we show certain characteristics of the logs. The logs range from unstructured (BPIC 2015) to structured (BPIC 2013) and also differ drastically in the number of their activities. In addition to different levels of structuredness, we also considered different trace lengths, since longer traces are potentially harder to reconstruct. The logs differ from having relatively short (BPIC 2013) to very long traces (BPIC 2015).\nImplementation. Our implementation is available on GitHub\\u00b9. We used the inductive miner and earth mover's distance of PM4Py [2]. The runtime of our implemented play-out strategies is fast. On a machine with an AMD Ryzen 5600G a play-out of the BPIC 2013 log is generated in under one second and in 30 seconds one play-out for the BPIC 2017 log."}, {"title": "5.2 Evaluation measures", "content": "Trace Length Distribution. We look into the trace length distribution to investigate the impact of how different play-out strategies handle the $\\u21bb$ operator.\nWe plot the normalized distributions of each play-out strategy and the distribution of the original log as histograms for the BPIC 2017 log. The plots for the other event logs can be found in our appendix\\u2075. We calculate the similarity of the distributions using the normalized histogram intersection for all logs:"}, {"title": "5.3 Results", "content": "Trace Length Distribution. Table 2 shows the NHI size with higher values, meaning better reconstruction of the trace length distribution. We can observe NHI values above 0.7 for 3 out of 4 of the event logs, with the exception being the BPIC 2015 log. Therefore, we can conclude that it is generally possible to mimic the trace length distribution and to rediscover general control-flow properties.\nConsidering the results in more detail, the success of the reconstruction might depend highly on the handling of loops. This aspect can be seen by the difference between the different settings for Strategy D. For BPIC 2015 the worst setting (Strategy D with Variance 0.5) reached a NHI of 0.19, while the best setting (Strategy D with Variance 5) led to a NHI value of 0.44. In Fig. 5, we can see that, compared to the other strategies, Strategy D with Variance 0.5-3 creates considerably fewer traces of length below 20.\nEarth Mover's Distance. Table 2 shows the EMD. Smaller values, correspond to higher similarity between the control-flow of the play-outs and the original log. Unfortunately, computing the EMD for the BPIC 2017 log was not feasible. We can observe that for the BPIC 2013 log, it is possible to generate logs that can be very close to the original event log. However, the BPIC 2015 log shows that this might not be possible for all logs. We can observe that the difference between the logs is significantly larger than between the strategies. This lets us conclude that specifics of the process itself determine the chance of success for the adversary. Strategy A that has no additional information about the control-flow performs the worst but is followed by the SOTA Strategy, despite having knowledge about the absolute frequencies. The other Strategies reconstruct the control-flow of the original log with similar success in terms of the EMD."}, {"title": "5.4 Discussion", "content": "Comparison of Play-out Strategies. Overall, Strategy A performed the worst of all play-out strategies. This is expected, since Strategy A lacks information about probabilities or frequencies in the process model. We conclude that it is indeed harder or even impossible to successfully reconstruct much of the control-flow of the original log the un-annotated process model was discovered from.\nThe play-outs from Strategy B and Strategy C were almost similar in our evaluated statistics. Knowledge of each node's left-over frequency did not help Strategy C to make better reconstruction decisions than Strategy B, when Strategy B knows how many traces to generate. This indicates that when a log with branching probabilities and the number of how many traces the original log contains are released, the model will reveal nearly the same amount of control-flow information as it would have done when released with absolute frequencies.\nStrategy D with Variance $v$ was unable to consistently outperform Strategy C or Strategy B. In our experiments, we could observe that setting the variance value between 1 and 3 led to good results. A limitation of this strategy is that an attacker does not know what variance to pick. When we sample from the normal distribution with a large variance, like in Strategy D with Variance 5 we generate traces that took numerous loop iterations. The longest trace we generated with Strategy D with Variance 5 for the BPIC 2017 log was 863 activities long. Those long traces consume much of the frequency weights, thus forcing the other reconstructed traces to be shorter.\nThe State-of-the-Art Strategy [18] performed worse than Strategy B despite knowing the left-over frequencies of each node. This indicates that we should not execute $\\times$ and $\\wedge$ nodes sequentially if we want to reconstruct the control-flow"}, {"title": "6 Conclusion", "content": "To mitigate confidentially risks, one may resort to publishing a process model instead of an event log for operational analysis. In this paper, we argued that such an approach also potentially incurs risks, since some information about the original process executions may be reconstructed from the released process model. We studied this risk and formulated reconstruction attacks as play-out strategies for models given as process trees. We conclude from our experiments that the reconstruction risk for process trees modelled by the inductive miner from complex real-world event logs is very low. However, there is a considerable reconstruction risk for more structured event logs. The annotation of process trees with frequency information increases the reconstruction risk considerably. Compared to the state of the art, our approaches can consistently provide better results, even with less background knowledge.\nIn future work, we plan to shift our focus from the quantity of information that can be reconstructed to a more nuanced analysis. This will involve examining the specific types of information that can be reconstructed and the associated uncertainties from an attacker's point of view. Our goal is to develop algorithms capable of answering questions such as: given a process model, which traces can be reconstructed that occurred with absolute certainty in the original log."}]}