{"title": "Generational Computation Reduction in Informal Counterexample-Driven Genetic Programming", "authors": ["Thomas Helmuth", "Edward Pantridge", "James Gunder Frazier", "Lee Spector"], "abstract": "Counterexample-driven genetic programming (CDGP) uses specifications provided as formal constraints to generate the training cases used to evaluate evolving programs. It has also been extended to combine formal constraints and user-provided training data to solve symbolic regression problems. Here we show how the ideas underlying CDGP can also be applied using only user-provided training data, without formal specifications. We demonstrate the application of this method, called \"informal CDGP,\" to software synthesis problems. Our results show that informal CDGP finds solutions faster (i.e. with fewer program executions) than standard GP. Additionally, we propose two new variants to informal CDGP, and find that one produces significantly more successful runs on about half of the tested problems. Finally, we study whether the addition of counterexample training cases to the training set is useful by comparing informal CDGP to using a static subsample of the training set, and find that the addition of counterexamples significantly improves performance.", "sections": [{"title": "1 Introduction", "content": "The bulk of the computational effort required for genetic programming (GP) is expended in the evaluation of programs in the evolving population. Typically, each program is evaluated on many inputs, which are generally referred to as \"fitness cases\" or \"training cases.\" In most prior work, all available cases are used to evaluate each program.\nTwo recent developments in GP have offered new approaches to handling training cases that appear to provide significant advantages. One of these methods uses only a small, random sub-sample of the available cases each generation. This \"down-sampling\" saves significant computational effort per program evaluation, allowing one to run the evolutionary system for more generations with"}, {"title": "2 Related Work", "content": "This work takes its motivation from and builds on counterexample-driven GP and down-sampled lexicase selection. We describe each of those techniques in detail, and then discuss other related work."}, {"title": "2.1 Counterexample-Driven GP", "content": "CDGP uses specifications provided as formal constraints in order to generate the training cases used to evaluate a population of evolving programs [23,3,24]. CDGP was extended to use both formal constraints and user-provided training data to solve symbolic regression problems [1,2]. Additionally, CDGP has been combined with synthesis through unification, which allows it to partially decompose parts of problems into subproblems to solve [32].\nCDGP evaluates individuals in the population against both a set of automatically generated training cases and the provided formal constraints. The training set is the primary method of evaluating individuals for parent selection, and the formal constraints are used to generate new training cases when necessary. The CDGP algorithm proceeds as follows: The training set is empty at the start of evolution. Then, each generation, every individual is evaluated on each training case in the training set. If any individual passes all of the training cases6, CDGP uses a Satisfiability Modulo Theories (SMT) solver to test the individual on the problem's formal constraints. If the program passes the formal constraints, evolution stops because it has found a solution. If the individual fails a constraint, the SMT solver returns a counterexample in the form of a new case that the program does not pass. CDGP adds this case to the training set for the next generation. This process continues until it either finds a solution or reaches a maximum number of generations.\nIn standard CDGP, a new counterexample case is added to the training set only when a program passes all current training cases. However, one extension of CDGP adds a fitness threshold $q \\in [0,1]$ that specifies the proportion of the training cases that an individual must pass before running the SMT solver on it to produce a new counterexample case [3]. This allows new cases to be added earlier, giving more search gradient for evolution to follow without having to find a program that passes all cases in the current training set. A value of $q = 1.0$ is equivalent to the standard CDGP, since it adds a new case only when an individual passes all current cases. On the basis of experimentation, the developers of this technique recommend a value for q in the range [0.75, 1].\nWe are unaware of any previous work employing counterexamples without the use of formal specifications, as we do here."}, {"title": "2.2 Down-sampled lexicase selection", "content": "While down-sampling of training data has been occasionally used in GP, it has recently been studied in the program synthesis domain when using lexicase parent selection [19,8,15,16]. In this setting, the training set is down-sampled to include a random subset of the training cases each generation. Down-sampled lexicase selection reduces the cost to evaluate each individual, with the same motivation as iCDGP."}, {"title": "2.3 Other Related Work", "content": "Guiding learning with counterexamples that modify a training set has been re-cently explored in machine learning [7,29]. Implementations of this technique require an error table to be constructed from the model's misclassified data points from training, which is then used as specifications for how to construct counterexamples to train the model.\nMetamorphic testing has been applied to GP to extend the usefulness of each case in exposing undesirable behaviors in candidate solutions without needing to include more cases to train on [30]. To apply metamorphic testing to a problem however, a user must first identify a metamorphic relation a solution program's output must exhibit; these metamorphic relationships are related to but different from the formal specifications required by CDGP.\nThe core of iCDGP has been used to develop human-driven genetic pro-gramming for program synthesis, in which a user is responsible for providing the initial training set and for verifying whether or not generated cases are coun-terexamples to a potential solution. A prototype system has shown promise on some basic program synthesis problems [9]."}, {"title": "3 Informal Counterexample-Driven GP", "content": "Informal counterexample-driven GP (iCDGP) borrows motivation from CDGP, but deviates in some significant and novel ways. Specifically, we aim to adapt the core concept of a small training set that grows with added counterexamples. Since we do not have formal specifications, we instead expect the problem to be defined by a full training set of input/output examples, typically numbering 100 or more, which we call T.\nIn iCDGP, we use an active training set, $T_A \\subset T$, that GP uses to evaluate the individuals in the population. In all of our experiments, $T_A$ initially contains 10 random training cases from T, although other sizes could be used. During evolution, if an individual is found that passes all of the cases in $T_A$, we test the individual on all of the cases in $T \\setminus T_A$; if it also passes all of them, then it is a training set solution and GP terminates. Otherwise, we select a random case in T that the individual does not pass, add it to $T_A$, and continue evolution. Note that if multiple individuals in a generation pass all of the cases in $T_A$, each of them goes through this process, potentially adding multiple new cases to $T_A$ for the next generation.\nGiven that we already have a set of training cases, why does iCDGP use a smaller, likely less-informative set of active training cases? As with other approaches based on the sub-sampling of training cases (such as down-sampled"}, {"title": "4 Experiment Design", "content": "In this study we focus on general program synthesis problems, which require the GP system to generate programs that have similar qualities to the types of programs we expect humans to write. For our experiments we use 12 problems with a range of difficulties selected from the PSB1 benchmark suite [14]. These prob-lems use different data types as inputs and outputs, and many require iteration or recursion and conditional execution to solve."}, {"title": "5 Results", "content": "We first present results comparing iCDGP to GP using the full training set. The first three columns of Table 3 give the number of successful GP runs out of 100 using a full training set, iCDGP, and iCDGP with a fitness threshold of q = 0.8. First, note that iCDGP performed a bit worse than using the full training set, including significantly worse on four problems while only significantly better on one. On the other hand, iCDGP using a fitness threshold performed significantly better than the full training set on three problems while only performing sig-nificantly worse on two, showing the benefits of adding cases before finding a solution on the training set.\nDespite producing no notable improvement in performance on these bench-mark problems over using the full training set, we did notice that the solutions that iCDGP found often occurred earlier in evolutionary time than with the full training set. For example, Figure 1 shows the cumulative number of successes over evolutionary time on the Vector Average problem; this plot is representative"}, {"title": "5.1 Variant: Generation-Based Case Additions", "content": "With generation-based case additions, we add a new case to $T_A$ every time d generations have passed without a new case being added otherwise. We tested three settings for d: 25, 50, and 100 generations. Note that failed iCDGP runs often finished after 1000 to 3000 generations, depending on how many cases are added to $T_A$.\nThe last three columns of Table 3 present the number of successful runs for different settings of d. iCDGP with generation-based additions performed sim-ilarly to or better than iCDGP without them on every problem for all three settings of d. While all three performed sometimes better and sometimes worse than each other, we will concentrate on d = 50 here, which was significantly bet-"}, {"title": "5.2 Variant: Maximum size of active training set", "content": "Since it appears that some of the benefits of iCDGP derive from the fact that it uses a small number of cases per program evaluation, we to hypothesize that its performance might improve if the number of cases were capped. For the experiments that produced the results shown in the columns Max of 10 and Max of 20 in Table 4, we began with the version of iCDGP using generation-based case additions every 50 generations. To this configuration we added a mechanism that removes a case each time a new case is added, once the number of cases has reached a pre-specified maximum. Specifically, whenever we add a case that would increase the size of $T_a$ past the given limit, we first remove the case in TA that is passed by the most individuals in the current population, with the intention to remove cases that provide less useful direction to search.\nAs can be seen in Table 4, limiting Ta to 10 cases degrades problem-solving significantly on the Scrabble Score and Syllables problems. Limiting Ta to 20"}, {"title": "5.3 Benefits of Counterexample Cases", "content": "One may wonder whether the benefits we have demonstrated with iCDGP come entirely from having a small active training set $T_A$ on which we evaluate each individual, reducing the number of program executions per generation. In other words, it is possible that adding counterexample cases to $T_A$ provides no benefits. To test this hypothesis, we conducted a set of runs that use a static active training set consisting of 10 random cases, the same number as the size of $T_A$ at the start of our iCDGP runs. Note that the only functional difference in these methods happens when a program is found that passes all cases in $T_A$. When a run with a static training set finds a program that passes all cases in $T_A$, it is simply tested for generalization.\nTable 4 compares the number of successes produced by GP with iCDGP adding a case every d = 50 generations to GP with a static training set. iCDGP is significantly better on every problem, often by huge margins. These differences highlight the importance of iCDGP's additions of counterexample cases to TA."}, {"title": "5.4 Effects on Population Diversity", "content": "We are interested in the effects of iCDGP, especially with lexicase selection, on population diversity. In particular, as we discussed in Section 4, when an individual passes all cases in $T_A$ and iCDGP adds another case, lexicase selects"}, {"title": "5.5 Number of Active Cases", "content": "In order to get a better idea of how often iCDGP adds cases to $T_A$, we plot the number of cases in $T_a$ over evolutionary time for standard iCDGP in Figure 3 and for the version that adds a case every 50 generations in Figure 4.\nFor iCDGP, we see many different patterns of when and how many cases are added to TA. For example, Compare String Lengths and Mirror Image are"}, {"title": "5.6 Comparison with down-sampled lexicase Selection", "content": "We compare iCDGP to down-sampled lexicase selection, using results from [15]. To ensure fairness of the comparison, we only consider down-sampled lexicase with down-sample rates which result in 10 cases being evaluated each generation,"}, {"title": "6 Conclusions and future work", "content": "We conclude that informal counterexample-driven genetic programming (iCDGP) advances the state of the art for software synthesis by GP. It builds on the recent advance provided by formal CDGP, but it is likely to be more widely applicable because it does not require a formal specification of solutions to the target prob-lem. The same set of test inputs that would be used for traditional GP can be used for iCDGP, with the only difference being how they are used. Specifically, iCDGP begins with a small initial subset of the cases, and augments the subset with counterexamples whenever an individual passes all of the current cases. We introduce new variants of iCDGP that experimentally outperform the standard version. We recommend using the version that adds a new case to the active set $T_A$ every d generations, ensuring that cases are added even if no program is found that passes all cases in $T_A$. This variant performed best for iCDGP, and future work could investigate its use in CDGP with formal constraints.\nAlthough we explored several variants of iCDGP, we anticipate other variants to emerge which may outperform ones presented here. Future work should focus on conducting further analyses of the underlying evolutionary dynamics that are responsible for the success of the technique to guide us in developing improve-ments. We have presented here some preliminary data on behavioral diversity and numbers of cases in $T_A$ over evolutionary time, but many other aspects of these runs can be investigated, and other variants of the technique tested to explore hypotheses about the reasons that it works. For example, with respect to generation-based additions, it would be useful to learn wither it is important to include new cases that are not passed by the best individual, or if the same benefit would result, more simply, from adding any random case from $T \\setminus T_A$."}]}