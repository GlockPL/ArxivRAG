{"title": "Model Alignment Search", "authors": ["Satchel Grant"], "abstract": "When can we say that two neural systems are the same? The answer to this question is goal-dependent, and it is often addressed through correlative methods such as Representational Similarity Analysis (RSA) and Centered Kernel Alignment (CKA). What do we miss when we forgo causal explorations, and how can we target specific types of similarity? In this work, we introduce Model Alignment Search (MAS), a method for causally exploring distributed representational similarity. The method learns invertible linear transformations that align a subspace between two distributed networks' representations where causal information can be freely interchanged. We first show that the method can be used to transfer specific causal variables, such as the number of items in a counting task, between networks with different training seeds. We then explore open questions in number cognition by comparing different types of numeric representations in models trained on structurally different numeric tasks. We then explore differences between MAS vs preexisting causal similarity methods, showing MAS to be more resistant to unwanted exchanges. Lastly, we introduce a counterfactual latent auxiliary loss function that helps shape causally relevant alignments even in cases where we do not have causal access to one of the two models for training.", "sections": [{"title": "1. Introduction", "content": "An important question for understanding both Artificial and Biological Neural Networks (ANNs and BNNs) is knowing what it means for one distributed system to model or represent another (Sucholutsky et al., 2023). Establishing isomorphisms between different distributed systems can be useful for simplifying their complexity and for understanding otherwise opaque inner mechanisms. We cannot yet measure from every individual neuron in most BNNs; even if we could, as is the analogous case in ANNs, it is still difficult to find satisfying ways of understanding the neural behavior. Finding simplified models that exhibit the causal relationships of more complex distributed systems can make the complex systems more interpretable and communicable, potentially leading to useful insights (Cao & Yamins, 2021; 2024; Richards et al., 2019). Furthermore, there are a number of open questions about how representations differ or converge across architectures, tasks, and modalities (Huh et al., 2024; Sucholutsky et al., 2023; Wang et al., 2024; Li et al., 2024; Hosseini et al., 2024; Zhang et al., 2024).\nResearchers often use correlational methods to measure the similarity of different neural representations. We can see examples of this in works that perform direct correlational analyses between ANN activations and BNN firing rates (Yamins & DiCarlo, 2016; Maheswaranathan et al., 2019), and in works that use Representational Similarity Analysis (RSA) to find 2nd order isomorphisms between model and system (Kriegeskorte et al., 2008)\u2014similar to Centered Kernel Alignment (Kornblith et al., 2019). We also see examples of this in linear decoding techniques, where linear decodability can be used as a metric for understanding the type of information encoded in distributed representations (Chen et al., 2020; Radford et al., 2021; Grill et al., 2020; Caron et al., 2021; Haxby et al., 2001; Haxby, 2013). Each of these examples are indeed valuable contributions. Can we, however, develop more causal methods for understanding representational alignment?\nSome works have made progress toward understanding causal/functional representation similarity by attempting to use neural recordings as intermediate inputs to a trained computational model (Sexton & Love, 2022), and in model stitching, where a linear mapping is learned from intermediate representations in one ANN to another for the purpose of measuring similarity or improving one of the two models (L\u00e4hner et al., 2023; Moschella et al., 2023; Bansal et al., 2021; Lenc & Vedaldi, 2015). To build upon these works, we ask: what do these causal mappings tell us about the underlying representations of the two systems? Are successful mappings sufficient for the notion that the models are \"doing the same thing?\" Furthermore, how can we isolate specific causal variables in the representations for more targeted claims?"}, {"title": "2. Methods", "content": "In this work, we build upon the work of (Grant et al., 2024) to examine the causal similarity of distributed representations within models trained on next token prediction, numeric tasks. Each model is trained to \u00bf99.99% accuracy on both training and validation data held before being analyzed and interpreted."}, {"title": "2.1. Numeric Equivalence Tasks", "content": "We offer a brief description of two variants of a numeric equivalence task used in this work. The goal of each task is to first count some number of tokens and then reproduce the same quantity. Each sequence consists of two phases: the demonstration (demo) and response phases. Each sequence has an associated object quantity that is uniformly sampled from 1 to 20. The demo phase of the sequence starts with a Beginning of sequence token, denoted B, continues with a number of Demonstration (D) tokens equal in quantity to the object quantity, and ends with a Trigger (T) token. The response phase then consists of the object quantity of Response (R) tokens and ends with the End of sequence (E) token. Object quantity values range from 1 to 20. During the initial model training, we include all token types in the standard autoregressive, cross entropy loss, even though the number of D tokens and location of the T token is unpredictable from the sequence. After the models are fully trained, we only use the loss from the R and E tokens for the MAS trainings, as these tokens are fully determined by the demo phase. A trial is considered correct when the model produces the appropriate number of R tokens followed by an E token during the response phase. The two task variants are:\nMulti-Object Task: there are 3 possible demo token types {Da, Db, Dc} that are uniformly sampled at each D in the sequence. There is a single response token type, R. As an example of a object quantity of 2, the sequence could be: \"B Dc Da TRRE\"\nSame-Object Task: there is a single token type, C, that is used as both the demo token type and the response token type. An example of a object quantity of 2 would be: \"BCCTCCE\".\nWe make a slight change to the Multi-Object Task when training the transformer models as a means of preventing them from learning a solution that relies on reading out positional information (Grant et al., 2024). In this task variant, each token in the demo phase has a 0.2 probability of being sampled as a unique \"void\u201d token type, V, that is irrelevant to the completion of the numeric equivalence task other than that it breaks the correlation between token positions and quantities. As an example, consider the possible sequence with an object count of 2: \"B VDVVDTRRE\". We only use this task variant for the training of transformer models. All evaluations use the Multi-Object Task."}, {"title": "2.2. Arithmetic Task", "content": "We include a task that consists of a number of addition/subtraction operations, interlaced with the intermediate cumulative value between each operation. An example sequence is as follows: \"B 3 Op 4 + 3 = 7, + 11 = 18, - 5 = 13 E\". The numeral between B and Op indicates the number of operations. This value is sampled between 1 and 10. The numeral following the Op token is a uniformly sampled starting value in the range 1-20. The operations are uniformly sampled when the cumulative value is in the range 1-19, otherwise, the operation is selected to ensure the cumulative value stays in the range 0-20. The possible operands are uniformly sampled from the set that will maintain the cumulative value range conditioned on the operator. The sequence prints the cumulative value after the equals sign. The comma indicates that the next operation should be applied to the cumulative value. Finally, the sequence ends with the E token after the initially indicated number of operations have been performed."}, {"title": "2.3. Model Architectures", "content": "Each model in this work is trained to perform only one of the tasks through next-token prediction (NTP). We train 2 model seeds for each task variant. We consider Gated Recurrent Units (GRUs) (Cho et al., 2014), Long-Short Term Memory recurrent networks (LSTMs) (Hochreiter & Schmidhuber, 1997), and two layer Transformers (Vaswani et al., 2017; Touvron et al., 2023; Su et al., 2023). We leave the details of GRU and LSTM cells to the referenced papers. The GRU and LSTM based models in this paper follow the structure:\n\\begin{equation}\nh_{t+1} = f(h_t, x_t)\n\\end{equation}\n\\begin{equation}\n\\hat{x}_{t+1} = g(h_{t+1})\n\\end{equation}\nWhere $h_t$ is the hidden state vector at step t, $x_t$ is the input token at step t, f is the recurrent function (either a GRU or LSTM cell), and g is a feed-forward network (FFN) used to make a prediction, $\\hat{x}_{t+1}$, of the token at step t + 1 from the updated hidden state $h_{t+1}$.\nThe transformer architecture uses Rotary Positional Encod-ings (ROPE) (Su et al., 2023) and GELU nonlinearities (Hendrycks & Gimpel, 2023). Transformers use a history of input tokens, $X_t = [x_1, x_2, ..., x_t]$, at each time step, t, to make a prediction: $\\hat{x}_{t+1} = f(X_t)$, where f is now the transformer architecture. We show results from 2 layer, single attention head transformers. We refer readers to Figure 7 for more details."}, {"title": "2.4. Model Alignment Search (MAS)", "content": "We first train the models to \u00bf99.99% accuracy, evaluated on both training and held out validation data (we note that MAS can be used on models that are not fully trained). We freeze the model weights for the MAS analysis. MAS can be thought of as a multi-model extension of DAS (Geiger et al., 2021; 2023) where the aligned subspace is used for within model causal interventions (like in DAS) and between model interventions (similar to model stitching). We provide a visual overview in Figure 1. For each distributed system in the analysis, MAS learns an invertible transformation matrix, $R_i = c_iQ_i$, composed of an orthogonal rotation matrix, $Q_i \\in R^{m \\times m}$, and a scaling constant, $c_i$. The transformation matrices rotate the models' representations into a space where causally important information can be exchanged within and between each of the models included in the analysis. These rotation matrices are trained and evaluated using expected counterfactual behavior as NTP labels.\nCounterfactual behavior is behavior that would have occurred if a causally important aspect of the world was different. We can see an example of this by interrupting a recurrent model's token prediction and fully replacing its hidden representation with representations from the same model under different inputs, x, at a different time step, t. If this representational substitution is successful, the model will begin to produce the behavior that it had already produced under x following time step t. We refer to this behavior as the expected counterfactual behavior conditioned on a successful intervention. We can also get expected counterfactual behavior by first assuming the model implements a causal abstraction (like a computer program) and then changing the values of specific variables in this causal abstraction. i.e. transferring only the count of some number of objects while preserving all other information.\nEach causal intervention attempts to transfer the value of a subspace of the rotated representation from the source model into a subspace of a rotated representation from the target model to create an intervened representation. The source and target models can be the same model. The intervened representation is then rotated back to its original space and the target model uses it to continue its predictions. We use the counterfactual behavior-the behavior that would occur if the intervention was successful and our causal abstraction is correct as a training signal for the rotation matrices and as labels for evaluation.\nConcretely, each causal intervention takes information from the source model and substitutes it into the target model. We run the source and target models on different sampled data and take a latent representation from a pre-specified layer for each model from some uniformly sampled time step t for the target model and time u for the source model. These hidden representations are denoted as $h^{(i)}_{trg,t} \\in R^{m_i}$ and $h^{(j)}_{src,u} \\in R^{m_j}$ for the target and source models respectively, where $m_k$ is the number of neurons in the distributed representation from model k. In Figure 1 we can see all four directional permutations for the two models. In the figure, the time step of the latent is abstracted away, and $h^{(k)}$ is labeled $L_{ash}^{(k)}$ where k is the model index and $ \\$ \\in \\{trg, src\\}$ denotes when $h^{(k)}$ is the target model or source model.\nTo perform the causal intervention, we rotate $h^{(i)}_{trg,t}$ and $h^{(j)}_{src,u}$ using the corresponding matrices $R_i$ and $R_j$ into the transformed representations $r^{(i)}_{trg,t}$ and $r^{(j)}_{src,u}$. We then replace a learned or predefined number of dimensions in the target vector $r^{(i)}_{trg,t}$ with the values from the same dimensions from the source vector $r^{(j)}_{src,u}$ to create a new, intervened representation $r^{(i,v)}_{trg,t}$. The substituted dimensions are colored in the $r^{(k)}$ vectors in the diagram with the label \"Aligned.\u201d Lastly, we return $r^{(i,v)}_{trg,t}$ to the original representation space of i using the inverse of the transformation $R_i$ to create $\\nu^{(i)}_{trg,t}$. A single causal intervention on two $h^{(k)}$ vectors can be written as:\n\\begin{equation}\n\\nu^{(i)}_{trg,t} = R_i^{-1}((1 - D_i) R_i h^{(i)}_{trg,t} + D_jR_j h^{(j)}_{src,u})\n\\end{equation}\nWhere $D_i \\in R^{m_i \\times m_i}$ and $D_j \\in R^{m_j \\times m_j}$ are diagonal, binary matrices with the same non-zero entries along the diagonal. The non-zero values are organized contiguously along the diagonal starting from the upper left index, (0,0). These matrices are used to isolate the desired number of dimensions to replace in $\\nu^{(i)}_{trg,t}$. We refer to the space spanned by $D_k r^{(k)}$ as the aligned subspace of the models' representations. This is where the causally relevant information can be freely exchanged. We can handle cases where $m_i \\neq m_j$ by setting the number of non-zero entries in both $D_k$ to be min($m_i, m_j$). The binary values along the diagonal of D can be learned or pre-specified (Geiger et al., 2023). In this work, all experiments pre-specify the number of dimensions to be half of the smallest $m_k$ unless otherwise noted.\nThe last step in the process is to allow the target model, $f_{trg,i}$, to continue making predictions using $\\nu^{(i)}_{trg,t}$ as its hidden state. We simply discard $h^{(i)}_{trg,t}$ here, and $h^{(i)}_{trg,t} = \\nu^{(i)}_{trg,t}$. We measure the success of a causal intervention as the target models' accuracy on the expected counterfactual behavior. This counterfactual accuracy is referred to as Interchange Intervention Accuracy (IIA).\nWe train the transformation matrices, $R_i$ and $R_j$, using the gradient signal generated from an autoregressive cross entropy loss on the counterfactual sequences. Once we have trained the rotation matrices to convergence, we can evaluate the quality of the model alignment using the accuracy of each model's predictions on the counterfactual outputs of unseen causal interventions. This accuracy is referred to as the Interchange Intervention Accuracy (IIA). Higher IIAs indicate stronger alignments between the models used in the analysis."}, {"title": "2.5. Full vs Specific Variable MAS", "content": "The choice of the counterfactual behavior defines what variables(s) MAS attempts to find an aligned subspace for. We have the option to align all behaviorally relevant information by simply using the behavior of the source model as the counterfactual behavior. This is similar to what has been done in previous works such as Bansal et al. (2021); Lenc & Vedaldi (2015); Sexton & Love (2022). In these cases of complete information transfer, MAS differs from previous works in that it 1. performs the interventions in multiple causal directions in a single analysis, and 2. it aligns only a subspace of the activations rather than the full latent space. We can also explore alignment of specific causal variables by conditioning the counterfactual sequences on the transfer of a specific causal variable (i.e. the count of the sequence). These targeted alignments are the multi-model generalization of DAS (Geiger et al., 2023; 2021; Grant et al., 2024). We perform MAS conditioned on each of the following causal variables in models trained on the corresponding task denoted in parentheses:\n1. Full (Arithmetic/Num Equivalence): Refers to cases in which we transfer all causally relevant information between models.\n2. Count (Num Equivalence): The difference between the number of observed demo tokens and the number of response tokens in the sequence. Example: the following sequences have a Count of 2 at the last token:\n\"B D D\", \"B D D D TR\"\n3. Last Value (Num Equivalence): The value of the input token with respect to changing the Count of the sequence. We assign the values as D=1, R=-1, and all other tokens are 0. Example: if we change the Last Value of a single D token from 1 to -1, the counterfactual sequence should be \"B D D D TRE\u201d. Example: in a partial sequence \"B DDT R\", if we change the value of the R token from 1 to 1, the counterfactual sequence is: \"B D D TRRRRE\u201d.\n4. Cumu Val (Arithmetic): The cumulative value of the arithmetic sequence in the Arithmetic task. We perform all interventions of this value on the \"=\" token. Example: if we substitute in a value of 3 at the \"=\" token in the following sequence \"B 1 Op 3 + 5 =\", the counterfactual sequence is \"B 1 Op 3 + 5 = 3 E\u201d.\n5. Rem Ops (Arithmetic): The remaining number of operations in the arithmetic sequence. We perform all interventions of this value on the \",\" token. Example: if we substitute in a value of 2 at the \",\" token in the following sequence \"B 3 Op 3 + 5 = 8 ,\", the counterfactual sequence is \"B 1 Op 3 + 5 = 8, + 1 = 9 E\" where the \"+\" and \"1\" are randomly sampled."}, {"title": "2.6. Unidirectional MAS (UniMAS) and Counterfactual latent MAS (CMAS)", "content": "MAS described up to this point involves systematically running training batches of all index pairings (i,j) \\in \\{(1, 1), (1, 2), (2, 1), (2, 2)\\} for two models $f_1(h, x)$ and $f_2(h, x)$. In some settings, however, we wish to compare to models for which we have neural recordings but no causal access (as is often the case in BNNs). UniMAS uses the activations from both models as source activations, but only uses one of the models, $f_1$, as the target model in causal interventions. Concretely, we train both rotation matrices without backpropagating gradient information from the counterfactual predictions of the causally inaccessible model, $f_2$.\nWe will show that the UniMAS trainings fail to train an $R^2$ such that causal interventions on the inaccessible model have strong IIA. This shortcoming eliminates nearly all benefits of the MAS framework. To address this, we introduce an auxiliary loss function to the UniMAS trainings. The auxiliary loss objective operates on counterfactual latent vectors, $h^{(x)}_{k}$. The objective applies a Manhattan distance and a cosine dissimilarity loss using counterfactual latent vectors as the ground truth. We define counterfactual latent vectors as latent vectors that encode the causal variables that we would expect to exist in the intervened vector, $\\nu^{(i)}_{trg,t}$ from Equation 3, after a successful causal intervention. We can obtain these counterfactual vectors by searching through our neural representation dataset for situations and behaviors that are consistent with the variables we wish to be encoded following a given causal intervention.\nA concrete example could be the following. Assume that a latent vector from the target model train on the Multi-Object task originally contains a Count of 3 and it is in the demo phase. We then perform a causal intervention where we substitute a Count of 5 from the source vector into the target vector. Following the intervention, we would expect the intervened vector to have a Count of 5 while still in the demo phase. We can search through dataset of latent vectors to find a counterfactual latent vector that has a count of 5 in the demo phase.\nReturning to our notation from section 2.4, we denote the target model's latent vector following an intervention as $h^{(v)}_{k}$ and our auxiliary objective vector as $h^{(x)}_{k}$, where v and x are merely notational identifiers and k denotes the index of the sample within a batch of training samples. We calculate the auxiliary loss, $X$, for a single batch of interventions as the following:\n\\begin{equation}\nX = \\frac{1}{N} \\sum_k^N (|| h^{(v)}_{k} - h^{(x)}_{k} ||_1 - \\frac{1}{2} | \\frac{h^{(v)}_k \\cdot h^{(x)}_k}{||h^{(v)}_k||_2 ||h^{(x)}_k||_2} |)\n\\end{equation}\nThe total CMAStraining loss, $\\mathcal{L}$, is a weighted average of the UniMAS autoregressive loss, denoted as U, and the auxiliary loss. $\\mathcal{L} = \\lambda X + (1 - \\lambda) U$ where $\\lambda$ is a tunable hyperparameter."}, {"title": "3. Results/Discussion", "content": "We first turn our attention to the MAS IIA in Figure 2. Each panel represents the similarity between Model\u2081 (along each row) and Model2 (along each column) (see Figure 1). We exclude comparisons of each model seed with itself. We"}, {"title": "3.1. MAS", "content": "We see from Figure 2 and Appendix 8 that MAS is generally successful at performing the Full variable interventions between different recurrent models. This is consistent with the findings of previous work on direct linear mappings between networks (Lenc & Vedaldi, 2015; Bansal et al., 2021; L\u00e4hner et al., 2023; Sexton & Love, 2022; Sucholutsky et al., 2023). Furthermore, MAS is successful at transferring the Count between the Multi-Object GRUs that have previously been shown using DAS to have an interchangeable Count variable (Grant et al., 2024). This success is qualified by MAS' inability to transfer the Count when one of the two models is a Same-Object GRU, which is also expected from the same previous work that showed the Same-Object GRUs do not have an interchangeable Count variable."}, {"title": "3.2. MAS vs RSA", "content": "RSA is a second order correlational method that examines the similarity between sample correlation matrices constructed from two models' representations (see Supplement A.3 for details). Turning our attention again to Figure 2 and Appendix 8, RSA differs from MAS most unintuitively on the embedding layers in all models and the hidden states in the transformers. In the case of the within Multi-Object Transformer hidden states (the lower rightmost panel), we see the RSA value of 0.8032. The value in this comparison is difficult to interpret, as we might expect higher values due to similarities in architecture and training, but we also know from causal experiments that there is little causal transferrability between their representations. In the embedding layers, the largest RSA value is in the within Same-Object GRU comparison with a score of 0.9027, with the next largest between the Multi-Object GRUs at 0.6886. We note that questions on how to interpret RSA values have been addressed in previous works (Kriegeskorte et al., 2008; Sucholutsky et al., 2023; Dujmovi\u0107 et al., 2022)."}, {"title": "3.3. Arithmetic", "content": "We include a MAS analysis between Arithmetic GRUs and GRUs trained on the Numeric Equivalence tasks (see Figure 3). All causal interventions are performed on the equals token for the Cumu Val variable and the comma token for the Rem Ops variable. The leftmost panel shows that we can successfully align the Cumu Val, and the Rem Ops variables between and within the Arithmetic GRUs. The middle panel shows that MAS can successfully align the Count with the Rem Ops variables between GRUs trained on the Multi-Object and Arithmetic tasks respectively. These results are qualified by the lower IIA alignment between the Count and the Cumu Val variables, and the alignments in the Same-Object GRUs. The results are consistent with the hypothesis that the GRUs are using different types of numeric representations for arithmetic than incremental counting."}, {"title": "3.4. Direct Linear Mappings", "content": "Turning to Figure 4, we compare the IIA of direct linear mappings (denoted Linear Map) and MAS. In the Linear Map measurements, activations are taken from the models along the panel columns, transformed using the rotation matrix, and then used by the models along the panel rows. We see that the Count variable can be successfully transferred between the Same-Object GRUs when using direct linear mappings. This is in contrast to MAS and the results of DAS from previous work (Grant et al., 2024). We introduce a theoretical model in Figure 5 to better understand how this can occur."}, {"title": "3.5. CMAS", "content": "We can see from Figure 6 the results of CMAS compared to both MAS and UniMAS. Each panel displays the IIA values for each of the causal directions within and between the two models. It is important to note that during the training of the rotation matrices in UniMAS and CMAS do not include causal directions $1 \\rightarrow 2$ and $2 \\rightarrow 2$. Assuming MAS is a ceiling on the possible IIA for UniMAS and CMAS, the results for UniMAS demonstrate that the causally relevant $R^2$ is not learned for free. In the case of CMAS on the Multi-Object GRU models, however, much of the performance of MAS is recovered. This demonstrates the potential of CMAS to recover causally relevant intervention rotation matrices even when we do not have causal access to one of the models in the comparison."}, {"title": "4. Conclusion", "content": "This work has introduced a new technique for causally measuring the functional similarity of representations in two neural systems. We showed the potential need to compliment commonly used correlational methods with MAS, and we showed how MAS improves upon previous causal similarity methods. We showed that MAS can be used to address questions of representational similarity across diverse task structures, and we introduced CMAS as a promising direction for learning causal interventions in cases where we do not have causal access to one of the two models. This work has been confined to ANNs, but we look forward to future explorations in biological neural settings."}, {"title": "A.2. MAS Training Details", "content": "For each rotation matrix training, we use 10000 intervention samples and 1000 samples for validation and testing. We uniformly sampled corresponding indices upon which to perform interventions, excluding the B, T, and E tokens in the numeric equivalence tasks from possible intervention sample indices. In the Arithmetic task, we used the comma token for Rem Ops interventions and the equals token for Cumu Val interventions. When intervening upon a state in the demo phase in the numeric equivalence tasks, we uniformly sampled 0-3 steps to continue the demo phase before changing the phase by inserting the trigger token. We orthongonalize the matrices, $Q_i$, using PyTorch's orthogonal parametrization with default settings. PyTorch creates the orthogonal matrix as the exponential of a skew symmetric matrix. We train the rotation matrices for 1000 epochs, with a batch size of 512 used for each model index pairing. We only perform experiments considering two models. Each gradient step uses the average gradient over batches of all 4 i, j pairings. We select the checkpoint with the best validation performance for analysis. We use a learning rate of 0.003 and an Adam optimizer."}, {"title": "A.3. RSA Details", "content": "We performed RSA on a dataset of 15 sampled sequences for each object quantity ranging from 1-20 on the task that each model was trained on for each model. We first ran the models on their respective datasets to collect the latent representations. We then used each of these latent vectors as the sample representations in a matrix $M_k \\in R^{N\\times d_k}$ wherek refers to the model index, N is the number of latent vectors (N = 15 \\times 20 = 300 in our analyses), $d_k$ is the dimensionality of a single latent vector for model k. We then calculated the sample correlation matrices for each model resulting in matrices $C_k \\in R^{N\\times N}$. Lastly we calculated the Spearman's Rank Correlation Coefficient between the matrices $C_1$ and $C_2$ as the RSA value (Zar, 2005; Kriegeskorte et al., 2008)."}]}