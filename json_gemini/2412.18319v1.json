{"title": "Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search", "authors": ["Huanjin Yao", "Jiaxing Huang", "Wenhao Wu", "Jingyi Zhang", "Yibo Wang", "Shunyu Liu", "Yingjie Wang", "Yuxin Song", "Haocheng Feng", "Li Shen", "Dacheng Tao"], "abstract": "In this work, we aim to develop an MLLM that understands and solves questions by learning to create each intermediate step of the reasoning involved till the final answer. To this end, we propose Collective Monte Carlo Tree Search (CoMCTS), a new learning-to-reason method for MLLMs, which introduces the concept of collective learning into \"tree search\" for effective and efficient reasoning-path searching and learning. The core idea of CoMCTS is to leverage collective knowledge from multiple models to collaboratively conjecture, search and identify effective reasoning paths toward correct answers via four iterative operations including Expansion, Simulation and Error Positioning, Backpropagation, and Selection. Using CoMCTS, we construct Mulberry-260k, a multimodal dataset with a tree of rich, explicit and well-defined reasoning nodes for each question. With Mulberry-260k, we perform collective SFT to train our model, Mulberry, a series of MLLMs with 01-like step-by-step Reasoning and Reflection capabilities. Extensive experiments demonstrate the superiority of our proposed methods on various benchmarks. Code will be available at https://github.com/HJYao00/Mulberry", "sections": [{"title": "1. Introduction", "content": "\"What I cannot create, I do not understand.\"\n-Richard Feynman\nMultimodal large language models (MLLMs) embody the essence of this dictum, which understand the world by learning to create expected responses to multimodal inputs such as images and text. While MLLMs have recently shown significant progress in straightforward tasks (Liu et al., 2024; Wang et al., 2024b), they often experience obviously increased failures on complex tasks requiring in-depth reasoning (Zhang et al., 2024d). Feynman's dictum might be the perfect metaphor of such failures of MLLMs, as we should only be able to work something out if we can create and have a firm understanding of each step of the reasoning involved. However, current MLLMs predominantly operate in a simple \u201cdirect prediction\u201d mode (Xu et al., 2024), i.e., generating brief, final answers to questions with little explicit and well-defined intermediate reasoning steps.\nIn this work, we aim to develop an MLLM that understands and solves questions by learning to create each intermediate step of the reasoning involved till the final answer. Recent advances in NLP, such as OpenAI 01 (OpenAI, 2024), have"}, {"title": "2. Related Works", "content": "shown great potential in enabling LLM to learn to reason and tackle complex language tasks (Xie et al., 2024). The core design of these advances lies in AlphaGo-like \u201ctree search\u201d: they employ tree search methods, like MCTS (Coulom, 2006), to bootstrap an LLM itself to build a tree of intermediate thoughts, explore effective reasoning paths, and leverage these paths to teach the model to reason step-by-step.\nAn intuitive idea is to directly apply these \"tree search\" methods to search effective reasoning paths for MLLMs, which, however, does not work well. As illustrated in Figure 1, we believe this is largely attributed to several observed search challenges for MLLMs. (1) Search Effectiveness: Traditional MCTS methods generally work by self-bootstrapping while current MLLMs are typically trained with little explicit and well-defined intermediate reasoning steps, making these search methods often trapped in homogeneous low-quality nodes within the reasoning space of a single MLLM, ultimately leading to low search success rates. (2) Search Efficiency: Traditional MCTS methods typically expand and explore only one subsequent reasoning node per search iteration, which advance a single step each time and demand massive iterations, making them inefficient for computation-intensive MLLMs.\nTo tackle these challenges, we propose Collective Monte Carlo Tree Search (CoMCTS), a new learning-to-reason method for MLLMs, which introduces the concept of collective learning into \"tree search\" for effective and efficient reasoning-path searching and learning. The core idea of COMCTS is to leverage collective knowledge to collaboratively conjecture, search and identify effective reasoning paths toward correct answers. Specifically, COMCTS searches effective reasoning paths iteratively, and in each iteration, it leverages collective knowledge from multiple MLLMs to jointly (a) expand diverse and complementary candidate subsequent reasoning nodes till the end from a given start node, (b) simulate reasoning outcomes, position error candidate nodes and prune them along with their child nodes, (c) backpropagate to update the score and visit count of each reasoning node in a bottom-up manner, and (d) select the leaf reasoning node with the highest Upper Confidence Bound value as next start node.\nIn this way, our CoMCTS achieves effective and efficient reasoning search. (1) The joint expansion mechanism enables COMCTS to concatenate reasoning trajectories from multiple MLLMs via iterative search, ultimately constructing an unified reasoning tree comprising diverse and complementary reasoning nodes. Thus, it allows reasoning-path search not only within the reasoning space of a given MLLM itself but also among those of others, benefiting from the synergy of multiple MLLMs while avoiding being trapped in homogeneous low-quality nodes within the reasoning"}, {"title": "2.1. Multimodal Large Language Model", "content": "space of a single MLLM itself. (2) The joint simulation and error positioning mechanism enables CoMCTS to, in each search iteration, skip multiple intermediate steps and select the last correct step as the next start node, largely reducing search time while maintaining search effectiveness. Here, collective knowledge is also crucial as it is often challenging for a model to recognize and position errors made by itself while relatively easy by using other models.\nFurthermore, we extend our CoMCTS for reflective reasoning-path search. Based on the unified reasoning tree constructed by CoMCTS, which provides both positive and negative reasoning nodes, we identify and integrate negative sibling nodes into effective reasoning paths to build the reflective reasoning path that includes a transition from a negative reasoning node to a positive one. By learning from reflective reasoning paths, MLLMs can perform appropriate step-wise reflection, dynamically calibrating their reasoning trajectory from an erroneous node toward a correct one during long-chain reasoning. Here, collective knowledge facilitates reflective reasoning-path search by providing a rich set of diverse positive and negative reasoning nodes.\nUsing our CoMCTS, we search effective and reflective reasoning paths for a set of multimodal inputs, and construct Mulberry-260k, a Multimodal learning-to-Reason-and-Reflect dataset with a tree of rich, explicit and well-defined reasoning nodes for each question. With Mulberry-260k, we perform collective supervised fine-tuning to train our model, Mulberry, a series of Multimodal LLMs with 01-like step-by-step Reasoning and Reflection capabilities.\nThe main contributions of this work are fourfold. First, we introduce the concept of collective learning into MCTS, and propose COMCTS which leverages collective knowledge to collaboratively conjecture, search and identify effective and reflective reasoning paths for MLLMs, showing great superiority in search effectiveness and efficiency. To the best of our knowledge, this is the first work that explores collective learning with MCTS for MLLMs. Second, we construct Mulberry-260k that provides a valuable resource for advancing research in step-by-step reasoning and reflection in MLLMs. Third, we develop Mulberry, a series of MLLMs with outstanding capabilities in step-by-step reasoning and reflection. Fourth, extensive experiments demonstrate the superiority of our proposed methods on various benchmarks."}, {"title": "2.2. Large Language Model Reasoning", "content": "MLLMs (Liu et al., 2024; Wang et al., 2024b; Lu et al., 2024a; Yao et al., 2024a) have made notable advancements in general vision-language understanding, enabling them to interpret visual semantics across various domains. Re-Recent studies (Yue et al., 2024; Zhang et al., 2024d) explore MLLM reasoning and reveal that directly employing CoT prompt to derive the final answer may result in limited gains or even degradation. In addition, some studies (Mitra et al., 2024; Luan et al., 2024) introduce plan-based CoT prompting to guide models to generate intermediate information for predicting final answers. Recent advances (Xu et al., 2024) attempt structured reasoning with a planed flow of certain pre-defined stages, enhancing the CoT capabilities (Zhang et al., 2024c) of MLLMs. Differently, this paper, for the first time, introduces the concept of \"tree search\" into MLLM reasoning and proposes a novel CoMCTS technique to search effective and reflective reasoning paths to train our Mulberry, a series of MLLMs with outstanding capabilities in step-by-step reasoning and reflection.\nLLM reasoning methods can be broadly categorized into three types, including prompt-based, plan-based and learning-based reasoning. Prompt-based methods, like Chain-of-Thought (CoT) (Wei et al., 2022), mimic human reasoning by providing a few hand-crafted, step-by-step solutions as references. Plan-based methods, such as Tree/Graph-of-thought (Yao et al., 2024b; Besta et al., 2024), predict multiple reasoning paths in a tree or graph manner and take consistent units of thought for thoughtful decision-making. Learning-based reasoning methods, represented by GPTo1, Star (Zelikman et al., 2022), Iter-MCTS (Xie et al., 2024) and ReST-MCTS (Zhang et al., 2024a), first employ tree search approaches, like MCTS, to bootstrap an LLM itself to build a tree of intermediate thoughts, explore effective reasoning paths, and leverage these paths to train the model to reason step-by-step."}, {"title": "2.3. Monte-Carlo Tree Search", "content": "Monte-Carlo Tree Search (MCTS) is a powerful search paradigm for complex decision making problems and has been extensively explored across diverse fields, including games (Silver et al., 2017; Ye et al., 2021), robotics (Best et al., 2019; Dam et al., 2022), theorem proving (Lample et al., 2022), matrices multiplication (Fawzi et al., 2022), etc. For instance, AlphaGo (Silver et al., 2017) introduces deep learning into MCTS, achieving superhuman performance in board and video games (Silver et al., 2017; Ye et al., 2021). Besides, (Pitanov et al., 2023; Yang, 2023) explore MCTS for path finding and train timetabling problems, while (Vagadia et al., 2024) integrates MCTS into physics-informed planning networks for robot control. In this work, we propose CoMCTS that enables effective and reflective reasoning-path searching and learning on MLLMs."}, {"title": "2.4. Collective Learning", "content": "Collective learning, also known as Co-training, aims to harness collective intelligence of multiple individuals to improve learning outcomes. This concept originates in early pioneering studies (Blum & Mitchell, 1998; Sun & Jin, 2011; Yu et al., 2011), which utilize collective knowledge to address data insufficiency issues in classification learning. Recent advances introduce collective learning into deep neural networks for efficient and effective deep learning. For example, (Qiao et al., 2018; Saito et al., 2018) employ collective knowledge from multiple classifiers to predict more accurate pseudo-labels for semi-supervised classification; (Cui et al., 2022) utilizes collective knowledge from multiple discriminators to enhance image discrimination and generation; and (Foerster et al., 2016) leverages the synergy of multiple models for reinforcement learning."}, {"title": "3. Methodology", "content": "We first present our proposed CoMCTS that introduces the concept of collective learning into \u201ctree search\" for effective and efficient reasoning-path searching and learning. We then illustrate the extension of CoMCTS for reflective reasoning-path search, and describe data construction (i.e., Mulberry-260k) and model training (i.e., Mulberry) using CoMCTS. More details to be elaborated in the ensuing subsections."}, {"title": "3.1. CoMCTS for effective reasoning", "content": "The core idea of CoMCTS is to leverage collective knowledge to collaboratively conjecture, search and identify effective reasoning nodes in an iterative manner, aiming to find effective reasoning paths leading to correct answers.\nWe denote a policy model as \\(\\pi\\), which is initialized by a pre-trained MLLM. We leverage collective knowledge from a group of MLLMs \\(\\{\\pi_1, \\pi_2, ..., \\pi_\\kappa\\}\\) to jointly search and learn effective reasoning paths. Given a multimodal input question Q (e.g., a text task instruction with an image, Q = \\(\\{\\text{text, image}\\}\\)), each model \\(\\pi\\) can generate a sequence of intermediate reasoning states toward the final answer \\((s_1, s_2, s_3, ..., s_M) \\sim \\pi_\\Theta(\\cdot|Q)\\) via autoregressive next token prediction. We define the intermediate reasoning state at step m as \\(s_m\\) and the state generated by model \\(\\pi_\\kappa\\) at step m as \\(s_m^\\kappa\\). Each reasoning step consists of one or a few sentences containing multiple word tokens.\nCOMCTS algorithm begins at the root node, i.e., either the start of a response or an incomplete response, and performs reasoning-path search via a certain number of iterations, where each iteration comprises four key operations: (a) Expansion, (b) Simulation and Error Positioning, (c) Backpropagation, and (d) Selection, as elaborated below.\n(a) Expansion. The goal of this operation in CoMCTS"}, {"title": "3.2. CoMCTS for reflective reasoning", "content": "is to expand the current leaf reasoning node (if it is not a terminal node) to integrate new subsequent candidate reasoning nodes. Given the current leaf node \\(s_m\\) (i.e., the node selected by Operation (d) Selection or the root node), CoMCTS utilizes collective knowledge from a group of MLLMs, \\(\\{\\pi_1, \\pi_2, ..., \\pi_\\kappa \\}\\), to jointly expand a set of diverse and complementary candidate reasoning paths \\(S_{\\text{candidate}} = \\bigcup_{\\kappa=1}^K S_{\\text{candidate}}^\\kappa\\) in parallel till the terminal node:\n\\[S_{\\text{candidate}}^\\kappa \\sim \\pi_\\kappa(\\cdot|Q, \\text{Parent}(s_m), s_m),\\]\nwhere \\(\\text{Parent}(s_m)\\) returns all parent nodes of \\(s_m\\) and \\((\\text{Parent}(s_m), s_m)\\) denotes the current reasoning path from the root node to \\(s_m\\). \\(S_{\\text{candidate}} = \\{s\\}\\) stands for a potential reasoning path generated by model \\(\\pi_\\kappa\\) starting from \\(s_m\\).\n(b) Simulation and Error Positioning. In this operation, CoMCTS utilizes collective knowledge from \\(\\{\\pi_1, \\pi_2, ..., \\pi_\\kappa\\}\\) to jointly estimate the potential value of child nodes \\(s \\in S_{\\text{candidate}}\\) (added in Operation (a)), and considers low-score nodes as erroneous reasoning nodes, and positions and filters out them along with their child nodes:\n\\[R(s) = \\frac{1}{K} \\sum_{\\kappa=1}^K \\pi_\\kappa(\\cdot|\\text{prompt}_{\\text{eval}}, Q, \\text{Parent}(s), s) \\]\n\\[S_{\\text{candidate}} = \\{s \\in S_{\\text{candidate}}|R(s) >= t\\}\\]\nwhere \\(R(s)\\) denotes a reasoning node evaluation function that uses the prompt, \\(\\text{prompt}_{\\text{eval}}\\), to request a group of MLLMs, \\(\\{\\pi_1, \\pi_2, ..., \\pi_\\kappa\\}\\), to jointly evaluate the candidate reasoning node s. t is a threshold and Discontinued reasoning nodes in \\(S_{\\text{candidate}}\\), are automatically removed following the error node removal in Eq.(3).\n(c) Backpropagation. Given the new reasoning tree expanded and simulated using collective knowledge in Operations (a)-(b), COMCTS performs a bottom-up update from the leaf nodes back to the root node. Each node s along the newly expanded path in the reasoning tree updates its statistics, including visit count N and node value V:\n\\[V(s) \\leftarrow \\frac{N(s) \\cdot V(s) + \\sum_{s'\\in \\text{Child}(s)} R(s')}{N(s) + \\text{CountChild}(S_{\\text{candidate}}, s)}\\]\n\\[N(s) \\leftarrow N(s) + \\text{CountChild}(S_{\\text{candidate}}, s),\\]\nwhere \\(\\text{Child}(s)\\) returns all the child nodes of s, and \\(\\text{CountChild}(S_{\\text{candidate}}, s)\\) is a child node counting function that calculates the number of child nodes of s in \\(S_{\\text{candidate}}\\).\n(d) Selection. Following Operations (a), (b) and (c), CoM-CTS traverses the updated reasoning tree to select the next"}, {"title": "3.3. Training with Collective MCTS", "content": "In this subsection, we extend COMCTS for reflective reasoning-path search. Based on the unified reasoning tree constructed by CoMCTS, i.e., \\(\\{Q, Y, S\\}\\), which provides both positive and negative reasoning nodes, we identify and integrate negative sibling nodes into effective reasoning paths to build the reflective reasoning path that includes a transition from a negative reasoning node to a positive one.\nIdentifying negative sibling node. Given the effective reasoning path Y, we identify the negative sibling reasoning node for \\(s \\in Y\\) using UCB:\n\\[s_{\\text{neg}} = \\arg \\min_{s_i \\in \\text{Sibling}(s)} \\text{UCB}(s_i) - \\text{UCB}(s), \\forall s_i \\in Y,\\]\nwhere \\(\\text{Sibling}(s)\\) returns all the sibling nodes of s, i.e., the nodes on the same hierarchical level under the same parent node of s. \\(\\text{UCB}(s) = V(s) + c \\frac{\\log N(\\xi)}{\\sqrt{1 + N(s)}}\\) as in Eq. 6.\nConstructing reflective reasoning path. Based on Eq. 7, we randomly sample a reasoning node \\(s \\in Y\\) with its negative sibling node \\(s_{\\text{neg}}\\), and concatenate them with a reflection prompt to form a reflection trajectory, i.e., \\((s_{\\text{neg}}, \\text{prompt}_{\\text{reflect}}, s)\\). We then use a function \\(\\text{Replace}()\\) that replaces \\(s \\in Y\\) with \\((s_{\\text{neg}}, \\text{prompt}_{\\text{reflect}}, s)\\) to convert Y"}, {"title": "4. Experiment", "content": "into the reflective reasoning path \\(Y_{\\text{reflect}}\\):\n\\[Y_{\\text{reflect}} = \\text{Replace}(Y, s, (s_{\\text{neg}}, \\text{prompt}_{\\text{reflect}}, s)),\\]\nwhere \\(\\text{prompt}_{\\text{reflect}}\\) denotes a reflection prompt, such as \u201cThe previous reasoning step is wrong and let's rethink it again.\u2019 Then, we can integrate the reflective reasoning path \\(Y_{\\text{reflect}}\\) into our data as a quadruplet \\(\\{Q, Y, Y_{\\text{reflect}}, S\\} \\in D\\).\nUsing COMCTS, we search effective and reflective reasoning paths for a set of multimodal input questions, and construct Mulberry-260k, a multimodal learning-to-reason-and-reflect dataset with a tree of rich, explicit and well-defined reasoning nodes for each question, i.e., a set of quadruplets \\(\\{Q, Y, Y_{\\text{reflect}}, S\\} \\in D\\). To learn collective knowledge from Mulberry-260k, we perform collective SFT to train our model, Mulberry, a series of Multimodal LLMs with 01-like step-by-step Reasoning and Reflection capabilities.\nCollective Supervised Fine-Tuning (CoSFT). Given \\((Q, Y) \\in D\\), we apply standard SFT objective to train our MLLM to learn from D constructed by CoMCTS:\n\\[L_{\\text{COSFT}}(\\pi_\\kappa) = \\sum_{(Q,Y) \\in D} \\log \\pi_\\kappa(Y|Q),\\]\nwhere \\(Y = \\{s\\}\\) denotes the effective reasoning path that includes a sequence of reasoning nodes collectively conjectured, searched and identified by a group of MLLMs.\nCOSFT for reflective reasoning. Given a question and its reasoning tree \\((Q, S) \\in D\\) constructed by CoMCTS, we randomly sample a reflective reasoning path \\(Y_{\\text{reflect}}\\) from S"}, {"title": "4.1. Dataset", "content": "In this section, we first introduce our COMCTS-generated dataset, Mulberry-260K, including its sources, construction, and analysis in Section 4.1, and provide implementation details in Section 4.2. We then present the main results in Section 4.3, demonstrating the effectiveness of the searched data (i.e., Mulberry-260K) and the trained models (i.e., Mulberry). In Section 4.4, we perform comprehensive ablation studies on the impact of effective and reflective reasoning data and the contributions of collective knowledge sources. In final, Section 4.5 discuses the effectiveness and efficiency of tree search methods, explores different training strategies, and provides qualitative comparisons.\nThe Sources of Raw Data. To construct a comprehensive and general-purpose tree-based reasoning dataset, we collect 260K raw multimodal input questions (i.e., a text task instruction with an image as an input question) from a wide range of domains, covering General Multimodal Understanding, Mathematics, Figure Understanding, Realworld Understanding, Science, Medical Image Understanding, etc. The specific data sources are provided in the Appendix A.\nReasoning Data Construction. As detailed in Section 3 and Algorithm 1 and visually illustrated in Figures 2 and 3, we employ our COMCTS to search effective and reflective reasoning paths for a set of raw multimodal input questions as collected from the mentioned \"The Sources of Raw Data\", ultimately constructing our dataset, Mulberry-260K. Note we only sample 15K data for reflective reasoning training to avoid overabundance of reflection data.\nReasoning Data Distribution. We analyze the COMCTS-searched reasoning paths in Mulberry-260K by examining the distribution of reasoning steps, as shown in Figure 4. Specifically, Figure 4 shows that reasoning steps predominantly falls between 6 and 8, with an average of 7.5, for the entire Mulberry-260k. Meanwhile, for simple reasoning tasks, the chart-related subset of Mulberry-260k, reasoning steps typically ranges from 6 to 7, averaging x.x. For complex mathematical and logical reasoning tasks, such as the geometry-related subset of Mulberry-260k, the distribution shifts and largely falls between 7 and 10 steps, with an average of x.x. These observations highlight that the col-"}, {"title": "4.2. Implementation Detail", "content": "lective tree search design in CoMCTS enables to generate effective reasoning trajectories with flexible numbers of reasoning steps, learning from which allows to train a powerful MLLM with great reasoning flexibility, i.e., a model can \u201cthink less and faster\u201d when handling simple questions (i.e., allocate and generate fewer intermediate reasoning steps) and \"think more and slower\" when tackling complex tasks (i.e., allocate and generate a greater number of intermediate reasoning steps).\nIn this paper, we implement the collective learning in CoM-CTS by employing a group of four models, including GPT-40, Qwen2-VL-7B, LLaMA-3.2-11B-Vision-Instruct, and Qwen2-VL-72B, to construct Mulberry-260K. In our COM-CTS, we set the maximum search iteration as 20. In each search iteration, we employ each model from the group to generate one subsequent candidate reasoning path to balance search exploration and exploitation. In Simulation and Error Positioning in CoMCTS, we simply set threshold t as 0. We adopt four popular MLLMs as baseline models, and conduct experiments on baselines Qwen2-VL-7B and LLaMA-3.2-11B-Vision-Instruct to examine the search effectiveness of our COMCTS, and on baselines Qwen2-VL-2B and LLaVA-NeXT-8B to study the generalization of CoMCTS-searched data. The collective SFT experiments are conducted with a batch size of 128, a learning rate of 1e-5, and training over 2 epochs. For Qwen2-VL-7B, a smaller learning rate of 5e-6 is adopted to stabilize the training."}, {"title": "4.3. Main Results", "content": "To examine the effectiveness of the searched data (i.e., Mulberry-260K) and the trained models (i.e., Mulberry), we conduct extensive experiments with four powerful baseline models, and comprehensively benchmark our Mulberry with various state-of-the-arts, including general and reasoning-based MLLMs. The evaluation is performed on 8 widely used and challenging datasets (Huang & Zhang, 2024), covering the fields ranging from general and mathematical reasoning to hallucination and visual illusion, and multi-disciplinary understanding and reasoning, as shown in Table 1.\nComparison with baselines. We first conduct experiments on baselines Qwen2-VL-7B and LLaMA-3.2-11B-Vision-Instruct that are involved in collective learning of COMCTS for joint reasoning-path conjecture, search and identification. We can observe that, trained with jointly-searched data (i.e., Mulberry-260k), our Mulberry-7B and Mulberry-11B bring clear performance improvements against their baselines, i.e., +4.2% over Qwen2-VL-7B and +7.5% over LLaMA-3.2-11B-Vision-Instruct averaged on 8 benchmarks, validating the search effectiveness of our CoMCTS. On the other hand, we examine the generalization of our Mulberry-260k by applying it to train other models that are not involved in collective tree search in CoMCTS, such as Qwen2-VL-2B and LLaVA-NeXT-8B. It can be observed that, trained with Mulberry-260k, our models (i.e., Mulberry-2B and Mulberry-8B) enhance Qwen2-VL-2B and LLaVA-NeXT-8B with +5.4% and +11.0% gains averaged on 8 benchmarks, demonstrating the generalization of COMCTS-searched data.\nComparison with reasoning-response models. We then benchmark our Mulberry with various state-of-the-art reasoning-response models. It shows that, using the same base model LLaVA-NeXT-8B (Li et al., 2024), our Mulberry outperforms LLaVA-Reasoner-8B and Insight-V-8B by +5.7% and +6.5% on mathematical benchmark Math-Vista, and by +3.0% and +1.0% on multi-disciplinary benchmark MMMU, respectively. Besides, Mulberry-11B surpasses LLaVA-COT-11B by +6.3% on reasoning-intensive benchmark MathVista under the same baseline LLaMA-3.2-11B-Vision-Instruct. The great superiority of Mulberry is largely attributed to our CoMCTS that conducts tree search and provides rich, explicit and well-defined reasoning nodes with flexible numbers of steps.\nComparison with state-of-the-arts. In final, we benchmark our Mulberry with popular state-of-the-arts included both open-source and closed-source ones. The results in Table 1 show that our Mulberry, trained on CoMCTS-searched data, outperforms most open-sourced MLLMs and achieves competitive results against closed-source ones, demonstrating outstanding abilities in step-by-step reasoning and reflection."}, {"title": "4.4. Ablation Study", "content": "Ablation Study on CoMCTS. We conduct ablation studies with the powerful GPT-40 as the baseline over 1K samples from Geo3K (Lu et al., 2021a) and GeoQA-Plus (Chen et al., 2021), as shown in Table 2. As the core of our proposed COMCTS, we examine how each model in the collective learning group contribute to the overall tree search performance. Table 2 reports the Search Success Rates (S.S.R.). The baseline GPT-40 works not very well without tree search. It shows that CoMCTS with only GPT-40 improves the performance to 63.8%, largely becuase our tree search designs like expansion, simulation and error positioning can work even without using collective knowledge.\nAblation Study on Mulberry. We train Mulberry with effective and reflective reasoning data searched by COMCTS, and study their respective contributions to overall reasoning performance. Table 3 presents the results on MathVista, which show that incorporating reflection data enhances the performance by 0.8%, demonstrating the complementarity of effective and reflective reasoning data searched by COMCTS."}, {"title": "4.5. Discussion", "content": "Comparison with other tree search methods. We compare our COMCTS with other tree search methods in search effectiveness and efficiency, including the baseline \u201cGPT-40 direction prediction\u201d, \u201ctraditional MCTS (Coulom, 2006)\", \"ReST-MCTS (Zhang et al., 2024a)\" that enhances MCTS by introducing partial search, and \u201cOmega-MCTS (Luo et al., 2024)\" that improves MCTS by designing binary search. Table 4 shows the results in search success rate and average search iteration that indicate search effectiveness and efficiency respectively. We can observe that existing tree search methods improve GPT-40 with limited gains. One main reason lies in that traditional MCTS methods generally work by self-bootstrapping and often get trapped in homogeneous low-quality nodes within the reasoning space of a single MLLM. On the other hand, our CoMCTS shows great superiority in search effectiveness and efficiency, largely thanks to the joint expansion mechanism in CoMCTS that allows reasoning-path search not only within the reasoning space of a given MLLM itself but also among those of others, benefiting from the synergy of multiple MLLMs while avoiding being trapped within the reasoning space of a single MLLM.\nQualitative comparison. We provide qualitative comparison of LLaVA-NeXT-8B (Li et al., 2024), Qwen2-VL-7B (Wang et al., 2024b), and Mulberry-7B in Figure 5. It shows that LLaVA-NeXT-8B and Qwen2-VL-7B generate relatively short predictions without thorough thinking, leading to incorrect answers. On the contrary, our Mulberry, trained with COMCTS-searched reasoning data, creates rich, explicit and well-defined reasoning steps with comprehensive understanding, ultimately arriving at the correct answer.\""}, {"title": "5. Conclusion", "content": "This paper presents COMCTS, a new learning-to-reason approach for MLLMs, which introduces the concept of collective learning into \"tree search\" for effective and efficient reasoning-path searching and learning. Based on the proposed CoMCTS, we search effective and reflective reasoning paths for a set of multimodal inputs, and construct Mulberry-260k, a multimodal learning-to-reason-and-reflect dataset with a tree of rich, explicit and well-defined reasoning nodes for each question. Using Mulberry-260k, we train our model, Mulberry, a series of Multimodal LLMs with ol-like step-by-step Reasoning and Reflection capabilities. Furthermore, we conduct extensive experiments, ablation studies and discussion, which demonstrate the superiority of our proposed methods on various benchmarks. We hope that CoMCTS along with Mulberry-260k and Mulberry will provides valuable resources and offer new insights for multimodal MCTS search and reasoning."}, {"title": "A. The Sources of Raw Data", "content": "To construct a comprehensive and general-purpose tree-based reasoning dataset, we collect 260K raw multimodal input questions spanning varouis domain, including\n\u2022 55K Mathematical Data: From GLLaVA (Gao et al., 2023), GEOS (Seo et al., 2015), UniGeo (Chen et al., 2022), GeoQA Plus (Chen et al., 2021), Geo3K (Lu et al., 2021a), MathVision (Wang et al., 2024a), GeoMverse (Kazemi et al., 2023), and MathV360K (Shi et al., 2024).\n\u2022 116K Figure Understanding data: From DVQA (Kafle et al., 2018), DocVQA (Mathew et al., 2021), FigureQA (Kahou et al., 2017), PlotQA (Methani et al., 2020), ChartQA (Masry et al., 2022), InfoVQA (Mathew et al., 2022), MultiHiertt (Zhao et al., 2022), and LRV-Chart (Liu et al., 2023).\n\u2022 41K Math Word Problem Data: From IconQA (Lu et al., 2021b), TabMWP (Lu et al., 2022b), CLEVR (Johnson et al., 2017), CLEVR-Math (Lindstr\u00f6m & Abraham, 2022), and Super-CLEVR (Li et al., 2023).\n\u2022 2K Mdeical Data: From VQA-RAD (Lau et al., 2018), and PMC-VQA (Zhang et al., 2023).\n\u2022 17K Sience Data: From TQA (Kembhavi et al., 2017), AI2D (Kembhavi et al., 2016), and ScienceQA (Lu et al., 2022a).\n\u2022 24K Nature World QA Data: From VQA-AS (Antol et al., 2015), A-OKVQA (Schwenk et al., 2022), TextVQA (Singh et al., 2019), Vizwiz (Gurari et al., 2018), and VQA2.0 (Goyal et al., 2017)."}]}