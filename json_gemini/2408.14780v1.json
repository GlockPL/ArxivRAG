{"title": "GINN-KAN: Interpretability pipelining with applications in Physics Informed Neural Networks", "authors": ["Nisal Ranasinghe", "Yu Xia", "Sachith Seneviratne", "Saman Halgamuge"], "abstract": "Neural networks are powerful function approximators, yet their \"black-box\" nature often renders them opaque and difficult to interpret. While many post-hoc explanation methods exist, they typically fail to capture the underlying reasoning processes of the networks. A truly interpretable neural network would be trained similarly to conventional models using techniques such as backpropagation, but additionally provide insights into the learned input-output relationships. In this work, we introduce the concept of interpretability pipelining, to incorporate multiple interpretability techniques to outperform each individual technique. To this end, we first evaluate several architectures that promise such interpretability, with a particular focus on two recent models selected for their potential to incorporate interpretability into standard neural network architectures while still leveraging backpropagation: the Growing Interpretable Neural Network (GINN) and Kolmogorov Arnold Networks (KAN). We analyze the limitations and strengths of each and introduce a novel interpretable neural network GINN-KAN that synthesizes the advantages of both models. When tested on the Feynman symbolic regression benchmark datasets, GINN-KAN outperforms both GINN and KAN. To highlight the capabilities and the generalizability of this approach, we position GINN-KAN as an alternative to conventional black-box networks in Physics-Informed Neural Networks (PINNs), which we propose as a challenging testbed for backpropagation-friendly interpretable neural networks. By adding interpretability to PINNS, we allow far more transparent and trustworthy data-driven solutions to differential equations. We expect this to have far-reaching implications in the application of deep learning pipelines in the natural sciences. Our experiments with this interpretable PINN on 15 different partial differential equations demonstrate that GINN-KAN augmented PINNS outperform PINNs with black-box networks in solving differential equations and surpass the capabilities of both GINN and KAN.", "sections": [{"title": "Introduction", "content": "Neural networks have largely driven the advancement of artificial intelligence (AI) over the last decade. They are widely used in many domains including computer vision, natural language processing and speech processing for real-world applications. Such neural networks have already surpassed human performance in many applications. However, neural networks generally consist of a large number of neurons, which results in them learning a complex function that maps the inputs to the outputs. Though this function may be very accurate, their innate opaque nature prevents it from being adopted in many sensitive fields where critical decisions have to be made using the output of the model, and the ability to describe and justify the decision becomes paramount.\nThe interpretability of neural networks is crucial to increasing the trustworthiness of AI, thereby increasing its adoption in real-world applications. Though explainability of machine learning (ML) models including neural networks have been studied in the past (Ribeiro, Singh, and Guestrin 2016; Lundberg and Lee 2017; Zhou et al. 2016; Selvaraju et al. 2016), there is a subtle difference between explainability and interpretability. Explainability focuses on explaining the decisions made by a system and typically does not represent how the model actually made its decision (Ali et al. 2023). On the other hand, an interpretable model aims to provide insights into the reasoning of the model.\nIn this work, we focus on interpretable neural networks, which give insights into the learned representation of a model. In particular, we are interested in networks that can aid in scientific discovery, by learning functions which follow a concise mathematical equation while still being trained on input-output pairs similar to any other neural network. The growing interpretable neural network (GINN) (Ranasinghe et al. 2024) and the Kolmogorov Arnold Network (KAN) (Liu et al. 2024) are two such networks that have shown promise in this task, and have even been shown to be able to discover the ground truth mathematical equations while still being trained using regular backpropagation. The ability to learn equations is similar to symbolic regression (SR) but with a key difference. A SR algorithm searches the equation space in an efficient manner until the best equation describing the dataset is found. In contrast, these methods can be trained on input-output pairs like any other neural network, but in a way that allows the extraction of a mathematical equation upon inspection of the trained neural network.\nLeveraging this unique property exhibited by GINN and KANs, we introduce the concept of interpretability pipelining, which combines multiple interpretability methods to enhance model transparency and performance. We present GINN-KAN, the first such pipelined interpretable neural network, that combines the strengths of the GINN and KAN"}, {"title": "", "content": "architectures, resulting in a far more robust network, while retaining interpretability.\nA promising application for such interpretable neural networks lies in the field of Physics Informed Neural Networks (PINN) (Raissi, Perdikaris, and Karniadakis 2017). PINNs make use of regularization and auto-differentiation to enforce a neural network to fit the underlying partial differential equation. Although PINNs have shown great potential in solving partial differential equations (PDEs), their reliance on black-box neural networks results in black-box solutions to these PDEs, significantly limiting the understanding of these solutions. By incorporating GINN-KAN into the PINN framework, we propose a new type of interpretable PINN which can provide valuable insights into the analytical solution of a PDE. Although this has been briefly investigated in (Liu et al. 2024), a comprehensive evaluation of such interpretable PINNs has not been performed.\nIn this work, we investigate the strengths and weaknesses of current backpropagation-friendly interpretable neural networks. We then use these insights to propose a new type of interpretable network that combines the strengths of these methods and use this to create an interpretable physics-informed neural network. The main contributions of this work are,\n\u2022\tAn evaluation of interpretable neural networks, including KANs on symbolic regression datasets\n\u2022\tGINN-KAN: A new type of interpretable neural network that can aid in scientific discovery\n\u2022\tIntegration of interpretability into PINNs allowing for better inspection/extraction/interoperability of PINN solutions\n\u2022\tAn interpretable PINN using GINN-KAN and its evaluation across multiple different PDEs"}, {"title": "Neural Network Interpretability", "content": "Machine learning model explainability has garnered considerable academic interest. This has resulted in many explainability methods that can visually or quantitatively explain a model's output. Although these methods provide insights into the decisions of the model, they may not reflect the underlying decision-making process. Therefore, even with incorporated explainability methods, machine learning models, especially neural networks remain as black-boxes. On the other hand, a fully interpretable model can be considered a \"white-box\", since its inner workings are fully transparent and human-understandable. Some simple models like linear regressors and decision trees are inherently interpretable since the inner workings of the learned model can be simply interpreted using a mathematical equation (in linear regression) or a set of rules (in decision trees). However, these simple models cannot fit datasets with complex underlying functions.\nNeural networks such as GINN (Ranasinghe et al. 2024), KAN (Liu et al. 2024) and EQL (Sahoo, Lampert, and Martius 2018) can be considered interpretable since they provide insights into the learned function, once trained. They have also been shown to be able to discover mathematical equations that describe the inner workings of the model while being trained using backpropagation."}, {"title": "Growing interpretable network (GINN)", "content": "GINN is an interpretable neural network that uses logarithmic and exponential activations to discover a multivariate Laurent polynomial (LP) equation mapping the input to the output. The network is fast to train and has only a few parameters, and has been shown to perform well in equation discovery when compared to other symbolic regression methods. Though GINN was created to discover equations with a Laurent polynomial structure, it is still reasonably successful in approximating non-LP equations."}, {"title": "Kolmogorov Arnold Networks (KAN)", "content": "The KAN (Liu et al. 2024) is a new class of neural network architecture that has emerged as a potential replacement for the widely used multi-layer perceptrons (MLP). Unlike traditional MLPs, which use fixed activation functions on nodes, KANs have learnable activation functions on edges, replacing linear weights with univariate B-spline functions. Other types of functions like wavelet functions have also been shown to be effective with this architecture (Bozorgasl and Chen 2024). This design enhances interpretability, allowing KANs to be intuitively visualized and easily interacted with, making them potential tools for scientific discovery. While KANs have been extended for applications such as time series forecasting (Vaca-Rubio et al. 2024) and recommendation models (Xu et al. 2024), their capability on symbolic regression datasets has not been comprehensively evaluated.\nIn this work, we focus on GINN and KANs since they have been shown to perform well in learning interpretable functions in the recent literature. Both of them can be trained using backpropagation and output a mathematical equation that describes the learned function."}, {"title": "Limitations of GINN and KAN", "content": "KANs are built around the Kolmogorov-Arnold representation theorem, which states that any multivariate function can be represented as the summation of univariate functions. This allows KANs to learn univariate functions as activations on the edges of the network, which are then summed up at the nodes. KANs can perform equation discovery by replacing each learned activation with a known symbolic function (e.g., cos, log, x2, x3). However, due to the nature of this formulation, KANs need multiple layers to learn a simple multiplication \\(x_1 * x_2\\) of the inputs \\(x_1, x_2\\). The KAN would need to learn this as \\(\\frac{(x_1+x_2)^2}{4} + \\frac{(x_1-x_2)^2}{4}\\), requiring 2 KAN layers.\nIn contrast, GINN can very easily learn multiplications using its power-term approximator blocks (PTA) but struggles to learn trigonometric and exponential functions since it does not explicitly include such functions in the network architecture. However, they can reasonably approximate non-LP functions using a polynomial-like approximation, and can also be ensembled with other SR methods to perform better with non-LP equations."}, {"title": "Physics-informed Neural Networks", "content": "PINNs are a deep learning method for solving PDEs. They ensure that the outputs comply with known physical laws by integrating domain-specific knowledge as soft constraints into the loss function. This is achieved by including \"physics\" loss terms which penalize the neural network from deviating from the underlying governing differential equation. The physics loss is defined as follows:\n\\(L_{physics} = \\frac{1}{N} \\sum_{i=1}^{N} (N[\\hat{u}(x_i, t_i)])^2,\\)\nwhere \\(\\hat{u}(\\cdot)\\) is the estimated solution of the PDE and \\(N\\) represents the linear or nonlinear operator. \\(x\\) and \\(t\\) denote space and time respectively, where \\(x \\in \\Omega \\subset R^d\\), \\(t \\in [0, T]\\). \\(T\\) is the time horizon, and \\(\\Omega\\) is the spatial domain. \\(N\\) is the number of collocation points within the spatiotemporal domain. This allows the network to be optimized using backpropagation techniques. PINNs generally do not require labelled datasets since the labels used for training the network can be generated using the initial or boundary conditions of the differential equation."}, {"title": "Methodology", "content": ""}, {"title": "GINN-KAN", "content": "We introduce GINN-KAN, an improved interpretable neural network that combines the strengths of GINNs and KANs. While GINNs excel when the underlying ground truth equation is a Laurent polynomial, their performance declines with non-LP equations. Conversely, KANs have the theoretical capability to learn non-LP equations, but in practice struggle with equations involving multiplications due to inherent assumptions.\nWe note many parallels between GINNs and KANs, enabling their seamless integration into a more robust network that leverages their strengths while mitigating their individual limitations. Both these networks can be trained using regular backpropagation algorithms on a dataset of input-output pairs. Once trained both GINNs and KANs are interpretable, providing insights into the learned function. Moreover, both of these networks can also use the trained weights of the network to discover a mathematical equation describing the learned function.\nWe make use of these parallels between GINNs and KANs, to create GINN-KAN, an end-to-end differentiable interpretable neural network, which can be trained using backpropagation. Similar to GINN and KAN, once trained, GINN-KAN can be inspected to gain insights into the network.\nThe GINN-KAN architecture is shown in Fig. 1. Both the GINN and KAN components of this network can be expressed in terms of a concise mathematical equation. For the GINN part, this can be done by inspecting the weights and constructing the equation of the network. Each power-term approximator (PTA) block consists of logarithm activations, a single linear activated neuron and an exponential activation. The equation of a PTA block reduces to,\n\\(p_i = X_1^{W_{i1}} * X_2^{W_{i2}} * ... X_n^{W_{in}}\\)\nwhere \\(p_i\\) is the output of the ith PTA block. Hence, the equation for a GINN with n power-term approximator (PTA) blocks is given by,\n\\(y = \\sum_{i=1}^{n} A_i * p_i\\)\nwhere \\(a_i\\) is the ith coefficient of the linear activated neuron, and \\(w_{ij}\\) are the coefficients of the PTAs.\nThe KAN can be expressed using an equation by mapping each learned B-spline function to a symbolic function, by comparing them against a set of pre-defined symbolic functions from a library of univariate functions. Some example functions include sin(x), ex and ln(x)."}, {"title": "GINN-KAN Augmented PINNS", "content": "PINNs are black-box in nature due to the fully connected neural network neural network which is generally used as the function approximator. Though some work attempts to learn symbolic functions that approximate the learned function, this is done by training symbolic regression methods using data generated by black-box surrogate models (Podina, Eastman, and Kohandel 2023). Although this allows the discovery of an interpretable model that approximates the learned function, this may not accurately reflect the decision-making process of the trained PINN.\nIn this paper, we propose replacing the black-box neural networks within PINNs with GINN-KAN to create an interpretable PINN. Since GINN-KAN can be trained using backpropagation, it can be used within PINNs with minimal change to the training strategy. Once trained, the interpretable PINN will be able to provide insights into the learned solution to the differential equation. The architecture of GINN-KAN augmented PINNs is shown in Fig. 2."}, {"title": "Experiment Setup", "content": ""}, {"title": "GINN-KAN", "content": "Investigating the limitations of GINN and KANs. Earlier, we noted that KANs cannot easily approximate multiplications, while GINN cannot easily approximate non-LP equations. To confirm these hypotheses, we construct datasets using eight ground truth equations. Two of these equations are LP equations, two are non-LP equations without any multiplications and the remaining four are non-LP equations with multiplications. We compare the performances of GINN, KAN and GINN-KAN on datasets constructed using these equations. We create these datasets by sampling 2000 points randomly for each input variable and generating the outputs using the ground truth equation."}, {"title": "Symbolic regression benchmark", "content": "We perform the evaluation of GINN-KAN on the popular Feynman symbolic regression benchmark datasets using SRBench, a popular benchmark for symbolic regression methods (La Cava et al. 2021). This dataset contains 114 datasets with known ground truth equations and is often used for evaluating symbolic regression methods (Udrescu and Tegmark 2020)."}, {"title": "GINN-KAN Augmented PINNS", "content": "Partial differential equations. The performance of GINN-KAN is evaluated on 15 PDEs, which are shown in the Appendix. The first 7 equations, include both linear and non-linear PDEs commonly used to model various physical phenomena. These equations vary in complexity and involve different operations (e.g., multiplication, division, addition) and basis functions (e.g., sin, exp, x2). The last 5 equations are designed with LP ground truth analytical equations."}, {"title": "Results and Discussion", "content": ""}, {"title": "GINN-KAN", "content": "We show the results on several synthetic datasets generated in Table 1. The first two equations are non-LP equations with no multiplicative terms. On these datasets, GINN performs poorly but KANs and GINN-KAN both perform well on these datasets. The next two equations are LP equations, on which GINN performs well, but KANs do not perform well. The last 4 equations are non-LP equations with multiplicative terms. On these datasets, GINN-KAN performs more than an order of magnitude better than the next best method. These results further confirm the limitations of KANs when approximating multiplicative terms within variables. Although theoretically possible, in practice KANs seem to perform worse when the underlying function contains a multiplication. Moreover, as expected due to the specialized nature of its architecture, GINN does not perform well when the underlying ground truth equation does not follow a LP form."}, {"title": "GINN-KAN Augmented PINNS", "content": "The results of PINN performance, measured in MSE, with different types of interpretable neural networks, are presented in Table 3. Both KAN, GINN and GINN-KAN out-perform the FC network in most PDEs. GINN performs reasonably well in solving LPs, as evidenced by the LP equations 15. However, its performance varies when dealing with non-LP PDEs. For instance, its performance is much worse than the GINN-KAN and KAN when solving Convection 2, Reaction, and Toy 1 and 2 equations, by orders of magnitude.\nKAN performs best in 7 out of 15 equations, demonstrating its capability in solving PDEs. However, compared to GINN-KAN, it performs worse in recovering analytical solutions involving multiplication (such as the Wave, Diffusion and Toy 1 equations) due to the Kolmogorov-Arnold representation theorem, which treats functions as the summation of multiple univariate functions. This approach makes it challenging to learn multiplication (as discussed earlier).\nIn contrast, GINN-KAN combines the strengths of GINNS and KANs, resulting in the best overall performance across all PDEs. GINN-KAN shows the most consistent performance, with the lowest average MSE (1.41E-01) and the second-best mean rank (2.20) for all equations and best mean rank when excluding the LP equations. It performs well in complex PDEs like Convection 1 and Wave equations, while maintaining competitive performance in LP problems. This demonstrates GINN-KAN's effectiveness in handling a wide range of PDES.\nNotably, GINN-KAN successfully addresses KAN's limitations with multiplicative terms, as evidenced by its performance in equations like Wave and Diffusion. Unlike GINN, which shows proficiency in LP problems but struggles with some non-LP equations, GINN-KAN maintains good performance across both types of problems. This balanced and robust performance across various PDE types further supports the claim that GINN-KAN is a powerful method for solving a wide range of PDEs."}, {"title": "Conclusion", "content": "In this work, we first evaluate interpretable neural networks, specifically focusing on the recently introduced GINN and KANs. While both methods have demonstrated interpretability, they exhibit limitations in learning certain types of functions. Our evaluation shows that GINNs do not perform well on datasets governed by non-LP equations, while KANs do not perform well on datasets governed by equations with multiplications. To address these limitations, we propose a novel interpretable neural network, GINN-KAN, which combines the strengths of both GINN and KANs. Experiments conducted with this novel network on the Feynman symbolic regression benchmark datasets show that GINN-KAN outperforms both GINN and KANs on datasets with known ground truth equations. We then apply GINN-KANs to physics-informed neural networks, showing that they can add interpretability to PINNs. By performing experiments on 15 differential equations, we demonstrate that this interpretable PINN not only adds interpretability but also improves the performance in solving differential equations when compared with traditional PINNs.\nInterpretability is a crucial aspect often overlooked in favor of performance in neural networks. However, methods like GINN-KAN have the potential to be as effective as black-box MLPs while also being interpretable. Since GINN-KAN can be trained using backpropagation, it can be seamlessly integrated into existing machine learning pipelines with minimal adjustments to the training strategy.\nDespite its advantages, GINN-KAN shares the limitation of GINN in being restricted to inputs with positive values. This can be mitigated by shifting all inputs to the positive range. Future research should explore more robust architectures that maintain interpretability while overcoming this limitation. Additionally, better regularization techniques are needed to enable GINN-KAN to accurately discover concise ground truth equations that describe the data.\nIn conclusion, GINN-KAN represents a significant step forward in developing interpretable neural networks, offering a promising balance between interpretability and performance. Its ability to integrate into existing machine learning frameworks and its potential applications in physics-informed neural networks highlight its importance in advancing the field."}]}