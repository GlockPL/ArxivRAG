{"title": "Decoding Poultry Vocalizations - Natural Language Processing and Transformer Models for Semantic and Emotional Analysis", "authors": ["Venkatraman Manikandan", "Suresh Neethirajan"], "abstract": "Deciphering the acoustic \"language\" of chickens opens new frontiers in animal welfare and ecological informatics, illuminating how subtle vocal signals encode health status, emotional states, and interactions within ecosystems. By uncovering the semantics of these vocalizations, we gain a powerful tool for interpreting their functional vocabulary-how each call serves a purpose within the social and environmental context. Here, we leverage state-of-the-art Natural Language Processing (NLP) and transformer-based models to translate bioacoustic data into meaningful insights. Our approach integrates Wave2Vec 2.0 for raw audio feature extraction with a fine-tuned Bidirectional Encoder Representations from Transformers (BERT) model, pretrained on a broad corpus of animal sounds and adapted to poultry-specific tasks. This novel pipeline decodes poultry vocalizations into interpretable categories\u2014such as distress calls, feeding signals, and mating vocalizations\u2014while revealing subtle emotional nuances often overlooked by traditional spectrogram-based analyses. Achieving 92% accuracy in classifying key vocalization types, our methodology demonstrates the feasibility of real-time, automated monitoring of flock health and stress levels. By continuously tracking this functional vocabulary, farmers can respond proactively to environmental or behavioral changes, enhancing poultry welfare, reducing stress-induced productivity losses, and promoting more sustainable farm management. Beyond its direct agricultural applications, this work enriches our understanding of computational ecology. Gaining access to the semantic foundation of animal calls provides a window into the ecological networks of which poultry are a part, potentially serving as indicators of biodiversity, environmental stressors, and species interactions. In bridging animal behavior, machine learning, and ecosystem analysis, our framework lays a foundation for integrative studies that harness acoustic data to inform ecological decision-making and develop more resilient, ethically aligned agricultural systems.", "sections": [{"title": "1. Introduction", "content": "The global poultry industry underpins food security and economic stability, meeting critical protein demands worldwide through meat and egg production (Serbessa et al., 2023). Agriculture remains central to economic development, and poultry farming stands at its forefront, influencing nutritional access and market resilience across numerous nations (He et al., 2022). Yet the health and welfare of poultry should not be viewed merely as a production metric; it is also a linchpin of ethical husbandry and ecological sustainability. Understanding poultry well-being can amplify both economic returns and the ethical foundations of farming, aligning market objectives with compassionate stewardship.\nPoultry vocalizations, inherently rich and varied, reflect intricate internal states and environmental contingencies (McGrath et al., 2017). These vocal signals extend beyond simplistic communication, serving as acoustic windows into birds' emotional and physiological conditions (Herborn et al., 2020). For instance, stressed chickens produce continuous, high-frequency calls that can be recognized as distress signals. Critically, these avian soundscapes have ramifications beyond the individual bird. The diversity or paucity of vocal expressions may mirror broader ecological health-vocal complexity suggests robust, biodiverse systems, whereas a restricted vocal range can indicate ecological stress or habitat simplification. Thus, poultry vocalizations function simultaneously as welfare indicators and bioacoustic sensors of ecosystem integrity.\nHistorically, producers and researchers relied on manual observation and interpretation of poultry calls a method prone to fatigue, bias, and scale limitations (Manteuffel et al., 2004). Although acoustic cues can offer non-invasive health and behavioral assessments, manually parsing these signals becomes prohibitive and error-prone across large flocks. Automating this process is essential. Emerging techniques promise to accurately identify and categorize vocalizations amid background noise, freeing researchers from the constraints of human subjectivity and time-intensive annotation. This shift can democratize insights, putting powerful tools into the hands of farmers who seek efficient, humane monitoring systems.\nChickens exemplify the complex interplay of ecological interactions within farm ecosystems. Their alarm calls can alert conspecifics to predators, while also influencing the responses of cohabiting species. This interconnectedness resonates with the acoustic niche hypothesis: species partition their soundscapes to reduce interference, each occupying unique frequency bands that shape the community's acoustic ecology. By examining how chickens communicate threats, resources, and social cues, we gain insights into predator-prey relationships, interspecies communication, and the dynamic structure of farm soundscapes.\nBeyond immediate welfare implications, happier, less stressed chickens engage more readily in natural behaviors like foraging, thus playing ecological roles such as pest control (Herborn et al., 2020; McGrath et al., 2017). Positive or neutral vocalizations may signal environmental comfort, potentially lowering reliance on chemical pesticides and fostering a healthier agro-ecosystem. Conversely, shifts in vocal patterns can warn of detrimental factors\u2014extreme temperatures, poor air quality, or anthropogenic disturbances\u2014that affect a range of wildlife, not just the chickens. In this sense, poultry vocal data can illuminate environmental feedback loops where localized stressors reverberate throughout the ecosystem.\nGenetic diversity within poultry populations adds another layer of complexity. Analyzing vocal repertoires across crossbred and indigenous strains can reveal differences rooted in genetics, culture, and adaptability. Such insights aid conservation by identifying and preserving native breeds with valuable traits for long-term resilience (Nicol, 2004; Jarvis, 2005; Rugani et al., 2009; Vallortigara, 2004; Emery & Clayton, 2004; Edgar et al., 2011; Marino, 2017). Ecosystems rich in diverse poultry populations, each group expressing distinct vocal signatures, may support a broader range of life forms, ultimately contributing to a more stable and vibrant agricultural landscape.\nTo date, research applying deep learning to avian vocalizations has excelled at species identification, attaining high accuracy with methods leveraging spectrograms and convolutional neural networks (Hu et al., 2023; Lou et al., 2023; Gupta et al., 2021). Yet, these studies often stop at taxonomic classification, leaving the semantics\u2014the meanings behind the calls-largely unexplored. The semantic dimension is crucial: beyond telling us which species is calling, we need to know why. Are the birds hungry, fearful, or comfortable? Do their calls map onto social hierarchies, resource competition, or environmental stress? Understanding these subtleties can offer early warnings of distress, guide interventions to improve productivity and reduce suffering, and help fine-tune environmental conditions within farms. Present-day reliance on manual annotation for distress calls hampers scalability and timeliness, underscoring the urgent need for automated, cost-effective solutions capable of real-time, contextually aware monitoring (Collias, 1987; Manteuffel et al., 2004)."}, {"title": "1.1. Related Works", "content": "Poultry vocalizations are increasingly recognized as critical tools for refining animal welfare management (Soster et al., 2024; Thomas et al., 2024; Xu et al., 2021). Machine learning can streamline vocal analysis, transitioning from subjective, laborious processes to automated, accurate, and timely systems. Non-invasive acoustic monitoring aligns with ethical imperatives, mitigating stress associated with blood sampling or invasive diagnostics. By interpreting vocalizations, farmers can maintain healthy flocks without aggravating existing welfare concerns.\nHowever, several obstacles persist. Standardized, robust datasets remain scarce, making it difficult to compare models or establish performance benchmarks. Poultry calls are context-dependent and complex, influenced by social dynamics, breed differences, resource availability, and environmental factors. Developing algorithms that accurately decode semantic content under real-world farm noise conditions poses a formidable challenge."}, {"title": "1.1.1. Advancements in Bioacoustics and Machine Learning", "content": "The intersection of bioacoustics and machine learning is rapidly advancing. Stowell (2023) provides a thorough review of computational bioacoustics, detailing signal processing principles and machine learning frameworks, while Ghani et al. (2024) highlight the importance of standardized evaluation protocols, fairness in model performance, and resilience to distribution shifts. Brown and White (2023) push the envelope into comparative linguistics, examining whether non-human species' vocal repertoires have syntactic or lexical analogues.\nThe bioacoustic community has responded by creating innovative tools. Bravo Sanchez et al. (2021) present SincNet, an open-source network for raw-waveform bird call classification, bypassing conventional spectrograms. Bolhuis et al. (2018) probe syntactic structures in songbird calls, while Taylor and Johnson (2023) associate vocalizations with behavioral latent states, expanding the contextual dimension of interpretation. Wilson and Lee (2023) illustrate that neural networks can capture contextual dependencies in birdsong, strengthening the case for context-aware modeling. Rauch et al. (2024) introduce BirdSet, a large-scale dataset poised to enhance training and evaluation. Cohen and Nicholson (2023) automate bird song annotation with neural networks, and Nicholson (2023) provides Crowsetta, a Python package that standardizes annotation handling\u2014together streamlining the entire bioacoustic workflow."}, {"title": "1.1.2. Cognitive and Emotional Complexity in Poultry", "content": "Chickens possess surprising cognitive sophistication. Marino (2017) reviews evidence that chickens exhibit complex mental processes, emotional capacities, and social structures rivaling those of mammals. Research on neural similarities between avian and mammalian brains (Jarvis, 2005), social learning (Nicol, 2004), and various cognitive skills (Emery & Clayton, 2004; Vallortigara, 2004; Rugani et al., 2009; G\u00fcnt\u00fcrk\u00fcn, 2005; Edgar et al., 2011) challenge outdated perceptions of poultry as \u201csimple\u201d farm animals. Emotional states influence vocal patterns; for instance, Kriengwatana et al. (2020) link certain hen vocalizations to emotional responses during egg-laying. These findings underscore the complexity embedded in chicken vocal behavior, further justifying the need for semantic-level acoustic analysis."}, {"title": "1.1.3. Applications of Machine Learning in Poultry Vocalization Analysis", "content": "Machine learning has begun to bridge these knowledge gaps. Soster et al. (2024) and Thomas et al. (2024) demonstrate that broiler chicken sounds can be monitored under environmental stress to enhance welfare and health management. Xu et al. (2021) apply deep learning for poultry health diagnostics, incorporating vocal data as a critical input. Hassan et al. (2024) suggest that identifying calls tied to specific rewards or motivations could improve automated welfare assessments, while McGrath et al. (2023) show how audio signal enhancement can sharpen Al's analysis of poultry sounds.\nTzschentke and Rumpf (2011) take bioacoustic analysis to the embryonic stage, noting that bird embryos may engage in acoustic communication to synchronize hatching\u2014an extraordinary example of the complexity inherent in avian acoustic signals. Attentive modeling approaches extend beyond adult vocalizations. Laleye and Moussa (2020) use an attention-based RNN to recognize laying hen behaviors, while Puswal and Liang (2019) integrate acoustic and morphological features, enhancing datasets that monitor welfare.\nCoutant et al. (2020) emphasize bioacoustics as a crucial metric for farm animal welfare assessment. Kriengwatana et al. (2020) explore vocal emotionality in hens, and Goyal et al. (2023) highlight the integrative potential of IoT, computer vision, and sound analysis in creating intelligent poultry farms. Large-scale projects like BirdVoxDetect facilitate real-time monitoring of flight calls (Amirivojdan et al., 2023). Transformer-based methods have shown promise, as evidenced by Lev-Ron et al. (2024), who achieve high precision in classifying broiler vocal responses to stressors.\nDespite these strides, unresolved challenges persist. Many studies underscore machine learning's potential yet acknowledge that current algorithms, though capable of classifying species or detecting anomalies, are not fully decoding the semantic content embedded in calls. They also highlight the scarcity of standardized datasets and the complexity introduced by context."}, {"title": "1.1.4. Bridging Theory and Practice", "content": "While we now comprehend that vocalizations carry a wealth of information, translating this understanding into tangible, farm-ready tools for improving animal welfare remains challenging. Integrating theoretical advances into practical solutions involves developing robust models tested under realistic farm conditions\u2014environments rich in noise, variation, and unpredictability. This step is crucial for closing the gap between cutting-edge research and everyday farming operations (Marino, 2017; Coutant et al., 2020; Hassan et al., 2024).\nContext-aware approaches would enable farmers to interpret nuanced calls in real-time, adjusting management strategies preemptively rather than reactively. Enhanced models could detect subtle shifts in vocal patterns, prompting timely interventions\u2014adjusting temperature, providing fresh bedding, or modifying feeding schedules\u2014to avert stress before it escalates. This proactive stance could reduce reliance on pharmaceuticals, mitigate losses, and foster a more harmonious human-animal-environment relationship."}, {"title": "1.1.5. Path Forward", "content": "The path forward lies in refining algorithms, expanding datasets, and embracing interdisciplinary collaboration. Bioacoustics experts, animal behaviorists, ecologists, and machine learning engineers must converge to produce standardized, annotated corpora and identify the contextual variables that shape vocal signals. Improved models that move beyond classification into semantic interpretation will radically enhance our ability to decode poultry vocalizations.\nIn turn, these insights can inform integrated ecological informatics frameworks, where poultry calls serve as proxies for environmental quality, biodiversity richness, and ecosystem stability. Such holistic perspectives may guide sustainable resource allocation and conservation strategies. Real-time acoustic monitoring integrated with IoT devices could track changes continuously, feeding data back into dynamic management systems and adaptive policy-making.\nThe research landscape is shifting from basic classification of bird calls toward nuanced, semantic-level understanding of vocalizations. Unlocking the functional meaning embedded in poultry calls promises benefits that extend from individual animal welfare to entire agro-ecosystems. By leveraging advances in machine learning, bioacoustics, and cognitive science, we stand on the brink of a transformative era in both poultry farming and ecological informatics\u2014one where compassionate, data-driven strategies support thriving animals, resilient ecosystems, and sustainable agricultural futures."}, {"title": "2. Innovative NLP-Based Framework for Poultry Vocalization Analysis", "content": null}, {"title": "2.1. Transformer Models", "content": "Transformer models have transformed numerous fields, including NLP and computer vision, by efficiently managing sequence data with sophisticated attention-based architectures (Vaswani et al., 2017). Introduced in the seminal \u201cAttention is All You Need\u201d paper, transformers employ self-attention rather than traditional recurrent or convolutional operations, enabling superior parallelization and scalability-particularly valuable for large datasets. Self-attention calculates the importance of each element relative to all others in a sequence, allowing the model to highlight critical components without bias toward input order. Positional encoding addresses the lack of inherent sequence awareness, and a common encoder-decoder structure enables the encoder to create continuous representations and the decoder to generate outputs from these representations. For animal vocalizations, detecting patterns and temporal structures across varying time scales is vital for tasks like species identification and behavioral interpretation. Transformers, through self-attention, excel at emphasizing pertinent sequence parts, regardless of position (Gong et al., 2021). Unlike RNNs, which suffer from vanishing gradients over long sequences, transformers process inputs in parallel, better capturing extended contexts. Their ability to accommodate diverse input forms, including Mel-frequency cepstral coefficients (MFCCs) (Davis & Mermelstein, 1980), makes them ideally suited for decoding the complexity of poultry vocalizations."}, {"title": "2.2. Architecture Behind Wave2Vec", "content": "Wave2Vec (Schneider et al., 2019) advances self-supervised learning of speech features directly from raw waveforms, reducing reliance on costly labeled data. Wave2Vec 2.0 (Baevski et al., 2020) refines this approach by predicting masked audio segments using contextual cues, producing robust latent representations through a CNN feature extractor that quantizes raw signals. A transformer then processes these latent units, capturing nuanced, long-range patterns in the audio. Fine-tuning the pre-trained Wave2Vec 2.0 on downstream tasks, like automatic speech recognition, requires far fewer labels. Crucially, it derives representations from waveforms directly, bypassing extensive feature engineering an immense advantage for bioacoustics research dealing with varied species sounds. This method avoids manipulating sound duration or structure, pivotal when analyzing intricate animal calls. Wave2Vec 2.0's inclusion of transformer-based bidirectional LSTMs strengthens its capacity to model time-dependent characteristics inherent in extended audio sequences. By converting continuous signals into discretized latent variables, it generates general-purpose features that effectively handle the variability and ambient noise typical in field recordings of animal vocalizations."}, {"title": "2.3. The BERT Transformer", "content": "BERT (Bidirectional Encoder Representations from Transformers) revolutionized NLP by capturing bidirectional contexts of words through masked language modeling (MLM) and next sentence prediction (NSP) pre-training (Devlin et al., 2019). Unlike unidirectional predecessors, BERT leverages both left and right contexts, learning richer relational knowledge between words (Banerjee, 2024). Fine-tuning BERT on targeted NLP tasks ranging from classification to translation has achieved state-of-the-art results (Hamidi et al., 2024). Applying BERT's architecture to audio analysis, especially animal vocalizations, is innovative because it can model complex sequences that mirror speech. Bidirectional pre-training allows BERT to grasp dependencies among sounds by considering their full context. Pretraining BERT on extensive unlabeled animal audio fosters an understanding of general acoustic structures, reducing the labeled data needed for tasks like detecting mating calls, distress signals, or territorial vocalizations. Through MLM extended to audio\u2014predicting masked \u201csounds\u201d rather than words-BERT learns the latent sequence structure of vocalizations, accommodating incomplete or noisy recordings. By extracting nuanced temporal and contextual patterns, BERT improves both robustness and precision in analyzing challenging, real-world animal vocal data."}, {"title": "3. Materials and Methods", "content": null}, {"title": "3.1. Datasets", "content": null}, {"title": "3.1.1. Early Disease Detection Dataset", "content": "The early disease detection dataset was generated at Bowen University's poultry research farm (Aworinde et al., 2023). A cohort of day-old chicks was divided into two groups: one treated for respiratory conditions, the other serving as an untreated control. Each group was housed separately under controlled conditions, with microphones strategically positioned to reduce noise interference. Audio data was recorded in 24-bit samples at 96 kHz, ensuring high-fidelity capture. Data collection spanned 65 days, with recordings taken morning, afternoon, and night. Throughout, birds had free access to feed and water, mitigating extraneous stressors and ensuring vocalizations primarily reflected health status."}, {"title": "3.1.2. Stress-Induced Poultry Vocal Dataset", "content": "Building on prior work (Neethirajan, 2024a; Neethirajan, 2024b), this dataset originates from the CARUS facility at Wageningen University, the Netherlands. Fifty-two Super Nick chickens were maintained in three cages under conditions mimicking commercial production. Stress was induced by opening an umbrella and playing dog barking sounds to elicit fear responses. This approach enabled recording of stress-induced vocalizations and subsequent pattern analysis. The dataset is publicly accessible on Zenodo, facilitating broader research and validation."}, {"title": "3.1.3. Chicken Language Dataset", "content": "The chicken language dataset aims to deepen our understanding of poultry communication. Developed to support machine learning translation of chicken calls into human-interpretable information, it leverages work by Nicholas and Elsie Collias at the University of California, Los Angeles. Over 24 distinct chicken calls and their inferred meanings were documented in natural settings and annotated by an experienced poultry farmer, providing rich contextual data."}, {"title": "3.2. Audio Processing Pipeline", "content": "All collected audio underwent preprocessing via PyDub, converting files to 16 kHz mono .wav. Each file was segmented into 32 sections for more granular analysis. Wav2Vec2.0 (Hugging Face) pretrained for speech recognition produced textual transcriptions. A BERT-based model then classified each vocalization as positive, neutral, or negative."}, {"title": "3.3. Phonetic and Sentiment Analysis", "content": "Phonetic composition was examined to identify vowel/consonant patterns. Parallel processing through a thread pool allowed simultaneous handling of multiple audio files, improving efficiency. Results including transcriptions, sentiment labels, and phonetic counts\u2014were compiled into a JSON structure for streamlined organization and retrieval."}, {"title": "3.4. Visualization and Computational Tools", "content": "Matplotlib generated high-resolution histograms and bar charts to illustrate sentiment distributions and phonetic trends. Torch with GPU acceleration managed computationally intensive tasks, while Librosa and NLTK aided in tokenization. GPU utilization ensured parallelization and improved both processing speed and accuracy, optimizing large-scale audio data analysis."}, {"title": "4. Results and Discussion", "content": "The analysis of poultry vocalizations using NLP and transformer models has uncovered profound insights into how vocal behavior correlates with stress levels and health conditions in poultry. The vocal characteristics of poultry, including pitch, frequency, sentiment, and phonetic composition, exhibited distinct patterns depending on their physiological and emotional states. Specifically, our analysis of pitch and frequency revealed that stressed birds produced vocalizations with consistently elevated pitch and concentrated frequency ranges compared to those from relaxed birds. The Wave2Vec 2.0 model demonstrated its effectiveness in capturing these subtleties, with stressed birds showing pitch clusters around higher frequencies (e.g., 480\u2013500 Hz), which aligns with stress-induced physiological constraints such as muscle tension and irregular respiration. In contrast, vocalizations from unstressed birds featured more dispersed frequencies, indicating a more relaxed state with greater variability in vocal output.\nSentiment analysis using a fine-tuned BERT model further elucidated the emotional landscape of poultry vocalizations. Prestress sentiment distribution revealed a relatively balanced mix of neutral, positive, and negative emotional states, reflecting everyday interactions and mild environmental challenges. In contrast, poststress vocalizations demonstrated an increase in negative sentiment and a corresponding decrease in neutral sentiment, suggesting the lingering impact of stress on the birds' emotional state. These insights are particularly significant for animal welfare, as they point to the utility of sentiment analysis in real-time welfare assessment and stress detection.\nPhonetic composition analysis provided another layer of understanding, revealing that the vocalizations of stressed birds were dominated by short, staccato-like sounds\u2014characterized by frequent use of consonants\u2014which are consistent with abrupt and sharp vocal patterns. In contrast, vocalizations from relaxed birds featured a higher proportion of vowels, which contributed to more melodic and fluid vocal patterns. Such differences suggest that stressed birds produce vocalizations with less tonal complexity, possibly due to physiological limitations or as a behavioral adaptation to conserve energy. The prominence of consonants in stressed vocalizations also indicates increased vocal harshness, which may be used to communicate distress or alert flock members.\nThese changes in vocal behavior have important physiological and behavioral implications. The observed increase in pitch and reduction in vocal variety under stress is likely tied to heightened muscle tension in the laryngeal region and increased respiratory rates, both of which are typical physiological responses to stress in birds. The narrowing of pitch frequency and reduced phonetic diversity observed in poststress vocalizations may also represent an adaptive strategy to conserve energy, ensuring that vocalizations are less metabolically demanding. Behaviorally, stressed birds might alter their vocal patterns to signal distress to other flock members, potentially promoting group cohesion and mutual support in challenging environments.\nOur findings demonstrate that vocal behavior serves as a reliable indicator of stress and health conditions in poultry, providing valuable insights for advancing poultry welfare through non-invasive monitoring. By integrating these advanced NLP models into precision livestock management systems, farmers can enhance their ability to monitor the well-being of their flocks, detect stress in real-time, and implement timely interventions\u2014ultimately improving animal welfare, productivity, and sustainability in poultry farming."}, {"title": "4.1. Pitch Analysis During Stress Phases", "content": "The prestress pitch analysis (Figure 2a) highlights a widespread distribution of pitch frequencies, predominantly centered around 500 Hz. The pitch histogram reflects a relatively broad spectrum of vocal frequencies, indicative of a calm and steady state where vocal emissions are produced freely. The absence of any distinct clustering within the frequency range further implies that vocalizations during the prestress phase are primarily casual and routine.\nThis suggests that the chickens are in a comfortable, non-threatening environment. Such vocal behavior likely denotes communication with peers, encompassing a range of vocal expressions for daily activities like feeding, resting, and exploring. In contrast, the poststress pitch analysis (Figure 2b) indicates a significant narrowing of the pitch frequency range, with clustering centered between 480-500 Hz. This reduction in pitch variety points toward a physiological constraint on vocalization, likely resulting from stress-induced muscle tension in the vocal apparatus. The narrowing of frequencies implies that the chickens are adjusting their vocal efforts post-stress, producing more homogenous vocalizations. Such vocal behaviors may reflect a combination of reduced airflow through tightened laryngeal muscles and a conscious attempt to conserve energy. This trend aligns with the concept of adaptive vocal suppression, wherein animals under stress reduce vocal output to minimize resource expenditure or avoid drawing attention from potential predators."}, {"title": "4.2. Physiological and Behavioral Implications of Stress-Induced Vocal Changes", "content": "The changes in pitch frequencies between prestress and poststress phases carry crucial physiological and behavioral implications. Physiologically, stress can induce significant muscle tension, particularly in the laryngeal muscles responsible for pitch control. During stress, these muscles may become tense, reducing the ability of the vocal cords to modulate pitch effectively, resulting in a narrower frequency range. Additionally, stress alters respiratory patterns, leading to shallow and irregular breathing that affects the airflow needed for a diverse pitch output. This constraint reduces the richness and complexity of vocalizations, resulting in a monotonic vocal profile characteristic of stress.\nBehaviorally, such vocal adjustments may serve adaptive purposes. In stressful conditions, animals often modify their communication strategies to signal distress to others in the group. Clustering around mid-range frequencies in the poststress phase suggests that chickens may be consciously attempting to produce more distinct or easily perceivable sounds that can be detected by flock members. This serves to stimulate group cohesion or elicit protective responses from others in the flock. The reduction in vocal effort may also serve as an energy-saving mechanism, as producing varied vocalizations requires substantial metabolic effort, which could be redirected to other essential survival functions under stressful conditions."}, {"title": "4.3. Sentiment Analysis in Prestress and Poststress Phases", "content": "Figure 3a illustrates the sentiment distribution during the prestress phase. Neutral sentiments constitute the largest proportion, at 39.3%, suggesting that a considerable number of vocalizations are emotionally neutral. These may include typical, non-stressful vocal expressions, such as those related to exploration or socialization. The nearly equal distribution of positive (30%) and negative (30.7%) sentiments reflects a balanced emotional state, possibly characterized by routine interactions that oscillate between minor challenges and positive stimuli. The presence of negative sentiment implies that some environmental stressors might have been present, though not at a level that would induce significant stress. In the poststress phase, sentiment distribution (Figure 3b) shows a slight shift compared to prestress. Neutral sentiments decrease slightly to 38.7%, indicating a change in the emotional tone post-stress. Negative sentiment increases to 32%, which may reflect residual stress effects or vocalizations related to stress recovery. The positive sentiment remains largely unchanged at 29.3%, implying some level of resilience among the chickens, as they attempt to revert to a normal emotional state. This indicates that, despite experiencing stress, the chickens are able to maintain a relatively balanced emotional output, possibly aided by supportive environmental factors post-stress."}, {"title": "4.4. Word Frequency Analysis in Stress Dataset", "content": "The word frequency distribution, as depicted in Figure 5, shows a skewed pattern where a few words dominate the vocalizations, while many others are used much less frequently. The most frequent words, each occurring over 500 times, reflect simple and common vocal expressions likely used for basic communication or signaling. The sharp decline in frequency for other words suggests that the chickens employ a wide vocabulary, but most words are situational or context specific. The presence of a long tail of infrequent words highlights the complexity of chicken vocalizations and suggests that their vocal repertoire is adapted to address a wide range of scenarios, even if certain sounds are only used occasionally."}, {"title": "4.5. Phonetic Composition Analysis", "content": "Figure 6 presents the phonetic composition of vocalizations during the prestress phase, showing a bimodal distribution with clusters for both vowels and consonants. The clustering at lower counts for vowels and consonants suggests the frequent use of shorter, concise vocal expressions during the prestress phase. The overlap between vowel and consonant distributions indicates that while many vocalizations are brief, there are selective instances of more complex expressions that may involve vowel-rich vocalizations. Such vowel dominance may suggest an element of tone modulation, used to convey varying degrees of intensity or intent."}, {"title": "4.6. Phonetic Makeup During Poststress Phase", "content": "In the poststress phase, phonetic analysis reveals a shift toward vowel dominance, particularly at higher frequency levels (20 and above). This indicates a shift in vocal strategy, possibly reflecting an emotional adjustment after the stress event. The increased presence of vowels, often associated with musical or melodic qualities, may indicate an attempt to produce more soothing and less jarring vocalizations, which could contribute to emotional regulation or group cohesion post-stress. The reduction in consonants during this phase suggests a move away from harsh or staccato sounds, aligning with the idea that poststress vocalizations are adapted to reduce vocal harshness and foster a calming effect."}, {"title": "4.7. Prestress vs. Poststress Phonetic Composition", "content": "The comparative analysis of phonetic composition between prestress and poststress phases reveals several notable trends. The increased reliance on vowels poststress suggests an emotional transition towards relaxation, while the reduction in consonants may indicate a decrease in vocal harshness and complexity. Consonants, typically associated with sharper sounds, decrease in frequency, which may imply a move towards less urgent and more melodic communication. The presence of scattered outliers in vowel and consonant counts during the prestress phase points to a diverse vocal repertoire that may be associated with higher emotional arousal or variability in vocal expression."}, {"title": "4.8. Pitch Analysis and Physiological Implications", "content": null}, {"title": "4.8.1 Prestress and Poststress Pitch Characteristics", "content": "Pitch analysis provides valuable insights into how chickens modulate their vocalizations in response to stress. During the prestress phase, vocalizations display a wide frequency range, suggesting that chickens are in a relaxed state with the freedom to express themselves across a broad tonal spectrum. In contrast, the narrowing of pitch frequency in the poststress phase indicates a physiological or behavioral adaptation to stress, characterized by reduced vocal complexity and energy conservation. This adaptation may be attributed to increased tension in the vocal muscles, limiting pitch modulation and airflow."}, {"title": "Behavioral and Social Implications", "content": "From a behavioral standpoint, changes in pitch frequency between the prestress and poststress phases suggest a conscious adjustment in vocal strategy. Chickens may reduce their vocal variety as a response to stress, possibly as a means of signaling distress to their flock members or conserving energy. Such changes in vocal behavior may also have social implications, fostering group cohesion or eliciting protective responses from the flock. The clustering of pitch frequencies in the poststress phase may indicate an attempt to produce louder or more distinct sounds, which can be easily perceived by others, thereby enhancing communication within the group during stressful situations."}, {"title": "Sentiment Analysis During Healthy vs. Unhealthy Conditions", "content": null}, {"title": "4.8.2.  Vowel Frequency Comparison (Healthy vs. Unhealthy)", "content": "The comparison of vowel frequency in healthy and unhealthy chickens (Figure 8) reveals that vowels \"a\", \"o\", and \"e\" dominate in both conditions, indicating their fundamental role in poultry vocalization. The increased variation in vowel frequency in unhealthy chickens suggests greater vocal effort, possibly indicating discomfort or a heightened attempt to communicate distress. The dominance of specific vowels, even under different health conditions, highlights the importance of these sounds in the basic structure of poultry communication."}, {"title": "4.8.3. Unigram and Bigram frequency distributions", "content": "Unigram analysis (Figure 10a) shows that \"a\" is the most common sound across both healthy and unhealthy chickens, followed by \"o\", \"i\", and \"e\". The increased variation in unhealthy conditions suggests a more diverse vocal effort, possibly indicating an increased need to express discomfort. Bigram analysis (Figure 10b) provides further insights, with repeated phonemes like \"aa\" being prominent in stressful conditions, which may indicate an intensified attempt to communicate urgency or distress. The variety of bigrams in unhealthy conditions suggests that stress or illness prompts chickens to experiment with different vocal patterns, increasing the diversity of vocal expressions."}, {"title": "Figure 11. Word Cloud Analysis (Healthy vs. Unhealthy)", "content": "The word cloud (Figure 11) presents a visual representation of the vocal patterns in healthy versus unhealthy chickens. Simple vowel-rich words such as \"O\", \"AA\", and \"E\" are predominant in healthy chickens, indicating a reliance on basic vocal elements for everyday communication. In contrast, sounds like \"LUG\", \"BU\", and \"HUSH\" are more frequently used in unhealthy chickens, suggesting heightened use of context-specific vocalizations related to stress or discomfort. This difference highlights the adaptability of poultry vocalization in response to changing health conditions."}, {"title": "4.8.4. Top word Frequency in the Chicken Language Dataset", "content": "On analysis of the third dataset \u2013 the Chicken language dataset, we find somewhat similar results as well. The Chicken Language Dataset presents an intriguing perspective on how chickens interact with each other. This resource was compiled by Nicholas and Elsie Collias by observing the chickens in a farm, through which, they were able to capture the diversity in chicken vocalization and language. In various illustrations included in this work, its analysis opens important patterns for vowel usage and frequency of different words and characters as well as overall complexity of linguistics involved.\nThe vowel frequency chart shows the prominence of certain vowels in the utterances made by the chickens. The instance of vowel \u201ce\u201d is the highest followed by \u201co\u201d and \u201ca,\u201d thus making them the notable triad in chicken communication. Vowels such as \u201ci\u201d and \u201cu\u201d however, are there though relatively in a lower instance and may have supporting roles or be used for less frequent sounds. The imbalance in instance dominance of the two groups in the chicken language could be due to some physiological influencing or limiting factors as well as the relevance of the vowels in the pronouncement of various emotional and environmental signals.\nThe word frequency distribution offers more detailed analysis revolving around the calls made by the chickens. Vowel words or calls \u201ca\u201d, \u201co\u201d, \u201ce\u201d have once again been highlighted among the primary vocabulary of chickens which is evident in the vocalization chart. Certain expressions in chickens' interactions with each other such as \u201cwy\u201d or \u201cin\u201d might imply a sequence of sequential vocalization such as providing an alarm about food or danger. The extensive variety of words suggests that chickens might have a blocked form of language which is systematized to suit various situations.\nThe character frequency chart also depicts how language is structured for the calls made by chickens. The letter e is reported to be the most common character, being followed by a good number of occurrences of o, a, and t. These characters are forming the calls of the chicken conforming to vowels being in the majority in the dataset for this study. It is inferred that c, and d among others are less predominant or less essential characters, therefore they may correspond to limitation in explosives or environmental effects accompanying the production of sound.\nThe word cloud provides extensive information over the dataset as well as the most appropriate words and their behaviours lived up to those frequencies. The terms \u201cT\u201d, \u201cINGEMO\u201d and \u201cEIK\u201d, and \u201cWWI\u201d are some of the notable terms demonstrating a pattern of engagement displays with a likely meaning in communication among chickens.\nThe high frequency of vowels used, the definite occurrence of the same words and characters in the middle of others as well as the degree of variability in the word cloud suggest that the system is indeed complex, robust and situational. Such results emphasize the possibility of further development of audio analysis of the hen's calls, including training of artificial neural networks for"}]}