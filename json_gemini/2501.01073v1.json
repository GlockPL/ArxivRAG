{"title": "Graph Generative Pre-trained Transformer", "authors": ["Xiaohui Chen", "Yinkai Wang", "Jiaxing He", "Yuanqi Du", "Soha Hassoun", "Xiaolin Xu", "Liping Liu"], "abstract": "Graph generation is a critical task in numerous domains, including molecular design and social network analysis, due to its ability to model complex relationships and structured data. While most modern graph generative models utilize adjacency matrix representations, this work revisits an alternative approach that represents graphs as sequences of node set and edge set. We advocate for this approach due to its efficient encoding of graphs and propose a novel representation. Based on this representation, we introduce the Graph Generative Pre-trained Transformer (G2PT), an auto-regressive model that learns graph structures via next-token prediction. To further exploit G2PT's capabilities as a general-purpose foundation model, we explore fine-tuning strategies for two downstream applications: goal-oriented generation and graph property prediction. We conduct extensive experiments across multiple datasets. Results indicate that G2PT achieves superior generative performance on both generic graph and molecule datasets. Furthermore, G2PT exhibits strong adaptability and versatility in downstream tasks from molecular design to property prediction.", "sections": [{"title": "1. Introduction", "content": "Graph generation has become a crucial task in various domains, from chemical discovery to social network analysis, owing to graphs' ability to represent complex relationships and produce realistic, structured data (Du et al., 2021; Zhu et al., 2022). Recent advancements in graph generative models primarily focus on permutation-invariant methods leveraging diffusion-based approaches (Ho et al., 2020; Austin et al., 2021). For example, models like EDP-GNN (Niu et al., 2020) and GDSS (Jo et al., 2022a) represent graphs using continuous adjacency matrices. In contrast, DiGress (Vignac et al., 2022) and EDGE (Chen et al., 2023) employ discrete diffusion, treating node types and all node pairs (edges) as categorical variables. Earlier neural graph generation methods introduced permutation-dependent models, such as GraphRNN (You et al., 2018b) and DeepGMG (Li et al., 2018). hese approaches employed auto-regressive frameworks (e.g., RNNs or LSTMs (Sherstinsky, 2020)) to sequentially generate graphs. For instance, GraphRNN generates adjacency matrix entries step-by-step. DeepGMG frames graph generation as a sequence of actions (e.g., add-node, add-edge), and utilizes an agent-based model to learn the action trajectories.\n\nThe discrete diffusion-based methods, in particular, gain more attention due to it perfectly aligns with the nature of discrete structure of graphs. However, sampling from discrete diffusion models relies on the conditional-independent assumption (Gu et al., 2017): the distribution of each entry at time t is independent of others, given the observation at time t-1. This may lead to a poor approximation of the true distribution, as multiple trajectories can emerge from the current state. A similar argument is made in Campbell et al. (2022), drawing a connection to the Tau-Leaping approximation, which allows changing multiple entries at a single time step. Ideally, the most accurate sampling is to change only one dimension at one timestep, or effectively, employ a large number of denoising steps. In the graph generation problem, this is equivalent to only change the label of one node, or change one node pair in terms of addition, deletion or alteration at a time. Such sampling schema naturally degenerates into an any-order auto-regressive model (Hoogeboom et al., 2021; Campbell et al., 2022).\n\nDue to the recent success of large language models (Achiam et al., 2023; Dubey et al., 2024), in this work, we revisit the family of auto-regressive graph generative models. We propose a new method to represent graph as sequence. Specifically, our designed sequence consists of two parts: node definition and edge definition. The node definition is first established to provide information about the node index and node type. After that, the edge definition specifies how edges are connected by using the defined node indices, as well as the edge labels. Our propose representation is sparse as it only define edges that explicitly exits, contrasting to the adjacency representation. We then utilize transformer decoder to approximate the sequence distribution via the next-token prediction loss. We name it Graph Generative Pre-trained Transformer (G2PT)."}, {"title": "2. A Review of Graph Generative Models.", "content": "To connect our proposed method to prior works, this section provides an overview of existing graph generative models, focusing on their modeling variables and likelihood definitions. We emphasize diffusion and auto-regressive models, given their demonstrated superior performance. For simplicity, and without loss of generality, we assume graphs are undirected and featureless throughout this discussion. A comparison of different frameworks is detailed in Table 1.\n\nDenote a graph as G = (V, E), where V = {v\u2081, ..., v\u2099} is the node set and E = {e\u2081, ..., e\u2098} represents the edge set. Apart from E, adjacency matrix A \u2208 {0,1}\u207f\u00d7\u207f is also commonly used to represent edge connections. Although the adjacency matrix A is denser compared to the edge set E, most existing methods prefer modeling A due to its structural advantages. In the following, we discuss the likelihood definitions over these two representations, their associated model decompositions, and their strength and limitations. We assume graph size n is given."}, {"title": "2.1. Generative Modeling of Adjacency Matrix", "content": "The likelihood of p(A) defines a joint distribution over all entries in the adjacency matrix. For auto-regressive graph models (You et al., 2018b; Liao et al., 2019), the likelihood is decomposed as follows:\n\np(A) = \u220f\u1d62\u208c\u2082 \u220f\u2c7c\u208c\u2081\u2071\u207b\u00b9 p(A\u1d62,\u2c7c|A\u208b\u1d62,\u2c7c), where the model focuses on the strictly lower-triangular portion of the matrix. Such full-condition decomposition is universal and expressive. However, as the number of variables increases quadratically with the number of nodes n, the modeling complexity escalates. Accurately approximating this distribution requires a highly expressive neural network. Moreover, generating samples demands O(n\u00b2) forward passes, which can be computationally intensive.\n\n(Discrete) diffusion models (Vignac et al., 2022; Chen et al., 2023; Qin et al., 2024), on the other hand, defines a sequence"}, {"title": "2.2. Generative Modeling of Edge Set", "content": "While the likelihood p(A) considers all node pairs in a graph as variables, the likelihood of p(E) only considers entries that are actual edges. Specifically,\n\np(E) = p(e\u2081) \u220f\u1d62\u208c\u2082\u1d50 p(e\u1d62|e<\u1d62), where each edge e\u1d63 is modeled by first choosing a source node and then selecting a destination node:\n\np(e\u1d62|e<\u1d62) = p(v\u209b\u1d63c|e<\u1d62)p(v_{dest}|v_{src}, e<\u1d62).\n\nThis decomposition is well-suited for an auto-regressive model since it doesn't have a fix dimension even for graphs of same size. When the training graphs are sparse (i.e., m < n\u00b2), formulating such decomposition via auto-regressive model is computationally feasible as the number of variables is linear to m.\n\nDespite these advantages, modeling the edge set has received limited attention compared to adjacency matrix-based methods. This is largely because previous efforts (Li et al., 2018) have shown less promising results.\n\nRemark 2.1. The architecture for modeling adjacency matrix A can leverage modern sequence models such as LSTM (Sherstinsky, 2020) or Transformers (Vaswani, 2017), as the homogeneous input and output space simplifies the learning process. This design enables the model to"}, {"title": "3. Graph Generative Pre-trained Transformer", "content": "In this work, we show that with proper sequence design and model architecture choice, modeling edge set E can achieve superior performance while being efficient."}, {"title": "3.1. Representing Graph as Sequence", "content": "We consider modeling a graph as a sequence of actions that first generates all nodes of a graph, then the edges among them. Denote a feature graph G = (V, E) Here v \u2208 V is represented as a tuple v := (v\u00ba, v\u1d62d), where v\u1d62d \u2208 Z\u207a is the node index and v\u00ba \u2208 {1, . . ., K\u1d65} is the node type. And e \u2208 E is represented as a triple e := (v\u1d62d\u209b\u1d63c, v\u1d62d_{dest}, e), where the first two elements define the edge connection and e \u2208 {1,..., K\u2091} is the edge type. For a featureless graph, the above representation can be simplified by removing the node and edge type definitions. A graph G with n nodes and m edges can be represented as\n\n[v\u2081\u00ba, v\u2081\u1d62d, ..., v\u2099\u00ba, v\u2099\u1d62d, \u03b1, v\u2081\u1d62d\u209b\u1d63c, v\u2081\u1d62d_{dest}, e\u2081, ..., \u03b1, v\u2098\u1d62d\u209b\u1d63c, v\u2098\u1d62d_{dest}, e\u2098].\n\nHere \u03b1 is used to denote a transition from node generation to edge generation. We illustrate it in Figure 1.\n\nSince a graph can be encoded into different sequences by varying the node permutation and the edge generation ordering. For node orderings, we index the node using a random permutation. Based on the node indices, we obtain the edge generation orderings via the reverse of a degree-based edge-removal process shown in Alg. 1. Intuitively, the reverse of such a process first constructs an \"initial seed graph\" and grows it by iteratively attaching nodes to it. We also explore the effectiveness of using other canonical edge orderings such as breadth-first search (BFS) and depth-first search (DFS) (details are presented in Appendix D.1)."}, {"title": "3.2. Learning Graph Sequences via Transformer", "content": "We utilize a transformer decoder (Vaswani, 2017) for modeling the graph sequences. Unlike language models, our defined graph sequence contains tokens from different action spaces. Here we consider using a tokenizer that unifies all types of actions into one vocabulary."}, {"title": "4. Fine-tuning", "content": "After pre-training a model, we further fine-tune it for downstream tasks. We consider generative (\u00a74.1) and predictive (\u00a74.2) downstream tasks, where the former aims to generate graphs with desired properties, and the latter utilizes the graph embeddings learned from the transformer to predict properties."}, {"title": "4.1. Goal-oriented Generation", "content": "Let z(.) be the function that estimates property z of a graph G. In goal-oriented generation, we are interested in obtaining a new model that generates graphs whose properties are close to z* more often then the pre-trained model. Such a setup has a broad application in the graph generation community such as drug discovery. In this work, we explore obtaining such distribution by fine-tuning the pre-trained model. We consider rejection sampling fine-tuning (RFT) and reinforcement learning (RL) approaches.\n\nRejection sampling fine-tuning. This approach fine-tunes the model using its own generated samples that satisfy the desired property z*. We consider the case where the property is a scalar, and an acceptance function m\u1d43(G) = 1|z*-z(G)|<w is controlled by an distance threshold w.\n\nThe algorithm for generating the fine-tuning dataset D* = {G}\u1d2e\u1d62\u208c\u2081 via rejection sampling is shown in Alg. 2. Note that we expect the learned pre-trained model is able to generate graphs with desired property.\n\nWhen the graph of interest has a low density in the model distribution, RFT becomes inefficient as it rejects most of the samples. To address this, we further propose to self-"}, {"title": "4.2. Property Prediction", "content": "Assume a labeled graph dataset C, where each instance consists a graph G along with a label y. We fine-tune the pre-trained model on it to learn to predict y given G. After the sequence s is generated from G, we extract the activation h of the final token s\u2097 output by the last transformer block as the graph representation. To predict y, we then feed h into a dropout layer followed by a linear layer:\n\np(y|s) = softmax(Dropout(Linear(h))).\n\nWe then maximize the log-likelihood E(G,y)~c log p(y|G). Compared to freezing the whole transformer during training and only update parameters of the linear layer, we found that unlocking the latter half of the transformer blocks significantly enhances performance."}, {"title": "5. Experiments", "content": "5.1. Setup\nDatasets. We consider both generative tasks and predictive tasks in our experiments. In generative tasks, we consider training transformer decoders on molecular datasets and generic graph datasets. For molecular datasets, we use QM9 (Wu et al., 2018b), MOSES (Polykovskiy et al., 2020), and GuacaMol (Brown et al., 2019). For generic graph datasets, we adapted the widely used datasets: Planar, Tree, Lobster, and stochastic block model (SBM). In predictive tasks, we fine-tune models pre-trained from GuacaMol datasets on various molecular property tasks using MoleculeNet (Wu et al., 2018a), detailed in Appendix B.4, to verify the usefulness of the learned graph representations.\n\nModel specifications. We train transformers with three different sizes: (1) the small transformer has 6 transformer layers and 6 attention head, with d_{model} = 384, leading to approximately 10M parameters; (2) the base transformer has 12 transformer layers and 12 attention head, with d_{model} = 768, leading to approximately 85M parameters; (2) the large transformer has 24 transformer layers and 16 attention head, with d_{model} = 1024, leading to approximately"}, {"title": "5.2. A Demonstrative Experiment using Planar Graphs", "content": "We first validate the effectiveness of our proposed graph sequence representation compared to the adjacency matrix. To achieve this, we train transformer decoders on planar graphs using both representations and evaluate their generative performance. For the adjacency representation, planar graphs are encoded as sequences of 0s and 1s derived from the strictly lower triangular matrix, with rows and columns permuted using BFS orderings to augment the training dataset.\nOur proposed representation demonstrates superior generative performance with a much smaller set of tokens, while model learning adjacency matrices struggles to capture the topological rules of the training graphs."}, {"title": "5.3. Generic Graph Generation", "content": "We evaluate G2PT on four generic datasets using Maximum Mean Discrepancy (MMD) to compare the graph statistics distributions of generated and test graphs. The evaluation considers degree (Deg.), clustering coefficient (Clus.), orbit counts (Orbit), spectral properties (Spec.), and wavelet statistics. Moreover, we report the percentage of valid, unique, and novel samples (V.U.N.) (Vignac et al., 2022). For this task, we trained the G2PT small and G2PT base models.\n\nAs shown in Table 2, G2PT demonstrates superior performance compared to the baselines. The details about baseline and metric are introduced in appendix B.5 The base model achieves 11 out of 24 best scores and ranks in the top two for 17 out of 24 metrics. The small model also demonstrates competitive results, indicating that a lightweight model can effectively capture the graph patterns in the datasets."}, {"title": "5.4. Molecule Generation", "content": "De novo molecular design is a key real-world application of graph generation. We assess G2PT's performance on the QM9, MOSES, and GuacaMol datasets. For the QM9 dataset, we adopt the evaluation protocol in Vignac et al. (2022). For MOSES and GuacaMol, we utilize the evaluation pipelines provided by their respective toolkits (Polykovskiy et al., 2020; Brown et al., 2019).\n\nThe quantitative results are presented in Table 4. On MOSES, G2PT surpasses other state-of-the-art models in validity, uniqueness, FCD, and SNN metrics. We introduce the details for metrics in appendix B.6. Notably, the FCD, SNN, and scaffold similarity (Scaf) evaluations compare generated samples to a held-out test set, where the test molecules have scaffolds distinct from the training data. Although the scaffold similarity score is relatively low, the overall performance indicates that G2PT achieves a better goodness of fit on the training set. G2PT also delivers strong performance on the GuacaMol and QM9 datasets. We additionally provide qualitative examples from the MOSES and GuacaMol datasets in the table."}, {"title": "5.5. Goal-oriented Generation", "content": "In addition to distribution learning which aims to draw independent samples from the learned graph distribution, goal-oriented generation is a major task in graph generation that aims to draw samples with additional constraints or preferences and is key to many applications such as molecule optimization (Du et al., 2024).\n\nWe validate the capability of G2PT on goal-oriented generation by fine-tuning the pre-trained model. Practically, we employ the model pre-trained on GuacaMol dataset and select three commonly used physiochemical and binding-related properties: quantitative evaluation of druglikeness (QED), synthesis accessibility (SA), and the activity against target protein Glycogen synthase kinase 3 beta (GSK3\u03b2), detailed in Appendix B.3. The property oracle functions are provided by the Therapeutics Data Commons (TDC) package (Huang et al., 2022).\n\nAs discussed in \u00a74.1, we employ two approaches for fine-tuning: (1) rejection sampling fine-tuning and (2) reinforcement learning with PPO. Figure 2 shows that both methods can effectively push the learned distribution to the distribution of interest. Notably, RFT, with up to three rounds of SBS, significantly shifts the distribution towards a desired one. In contrast, PPO, despite biasing the distribution, suffers from the over-regularization from the base policy, which aims for training stability. In the most challenging"}, {"title": "5.6. Predictive Performance on Downstream Tasks", "content": "We conduct experiments on eight graph classification benchmark datasets from MoleculeNet (Wu et al., 2018a), strictly following the data splitting protocol used in GraphMAE (Hou et al., 2022a) for fair comparison. A detailed description of these datasets is provided in Appendix B.4.\n\nFor downstream fine-tuning, we initialize G2PT with parameters pre-trained on the GuacaMol dataset, which contains molecules with up to 89 heavy atoms. We also provide results where models are not pre-trained.\n\nAs summarized in Table 5, G2PT's graph embeddings demonstrate consistently strong (best or second-best) performance on seven out of eight downstream tasks, achieving an overall performance comparable to GraphMAE, a leading self-supervised learning (SSL) method. Notably, while previous SSL approaches leverage additional features such as 3D information or chirality, G2PT is trained exclusively on 2D graph structural information. Overall, these results indicate that G2PT not only excels in generation but also learns effective graph representations."}, {"title": "5.7. Scaling Effects", "content": "We analyze how scaling the model size and data size will affect the model performance using the three molecular datasets. We use the validity score to quantify the model performance. Results are provided in Figure 3.\n\nFor model scaling, we additionally train G2PTs with 1M, 705M, and 1.5B parameters. We notice that as model size increases, validity score generally increases and saturates at some point, depending on the task complexity. For instance, QM9 saturates at the beginning (1M parameters) while MOSES and GuacaMol require more than 85M (base) parameters to achieve satisfying performance."}, {"title": "6. Conclusion", "content": "This work revisits the graph generative models and proposes a novel sequence-based representation that efficiently encodes graph structures via node and edge definitions. This representation serves as the foundation for the proposed Graph Generative Pre-trained Transformer (G2PT), an auto-regressive model that effectively models graph sequences using next-token prediction. Extensive evaluations demonstrated that G2PT achieves remarkable performance across multiple datasets and tasks, including generic graph and molecule generation, as well as downstream tasks like goal-oriented graph generation and graph property prediction. The results highlight G2PT's adaptability and scalability, making it a versatile framework for various applications. One limitation of our method is that G2PT is order-sensitive, where different graph domains may prefer different edge orderings. Future research could be done by exploring edge orderings that are more universal and expressive."}, {"title": "A. Reinforcement Learning Details", "content": "A.1. Preliminaries on Proximal Policy Optimization (PPO)\nGeneralized Advantage Estimation. In reinforcement learning, the Q function Q(s<1, s\u0131) captures the expected returns when taking an action si at current state s<1, and the value function V(s<1) captures the expected return following the policy from a given state s<1.\n\nThe advantage function A(s\u0131, s<1), defined as the difference between the Q function and the value function, measures whether taking action si is better or worse than the policy's default behavior. In practice, the Q function is estimated using the actual rewards ri and the estimated future returns (the value function). There are two commonly used estimators, one is the one-step Temporal Difference (TD):\n\nQ(s<1, si) = r\u0131 + \u03b3V(s<1+1),\n\nA\u0302(s<\u0131, s\u0131) = r\u0131 + yV(s<1+1) \u2013 V (s<1),\n\nand the full Monte Carlo (MC):\n\nQ(S<1, 51) = \u2211_{1'=1}^{L}\u03b3^{1'-1}r_{1'}\n\nA\u0302(S<1, 1) = \u2211_{1'=1}^{L}\u03b3^{1'-1}r_{1'} \u2013 V(s<1),\n\nassuming finite trajectory with L steps in total. However, the TD estimator exhibits high bias and the MC estimator exhibits high variance. The Generalized Advantage Estimation (GAE) (Schulman et al., 2015) effectively balances the high bias and high variance smoothly using a trade-off parameter \u03b3. Let \u03b4\u03b9 = rt + yV(s<1+1) \u2013 V(s<1), the definition of GAE is:\n\nA\u0302' (S<1, 1) = \u2211_{1'=1}^{L}(\u03b3\u03bb)^{L-1'}\u03b4_{\u03b9\u03bd} = \u03b4\u03b9 + A\u0302'(S<1+1, 81+1).\n\nGAE plays an important role in estimating the policy gradient, and will be used in the PPO algorithm.\n\nProximal Policy Optimization. PPO (Schulman et al., 2017) is a fundamental technique in reinforcement learning, designed to train policies efficiently while preserving stability. It is built on the principle that gradually guides the policy towards an optimal solution, rather than applying aggressive updates that could compromise the stability of the learning process.\n\nIn traditional policy gradient methods, the new policy should remain close to the old policy in the parameters space. However, proximity in parameter space does not indicate similar performance. A large update step in policy may lead to falling \"off the cliff\", thus getting a bad policy. Once it is stuck in a bad policy, it will take a very long time to recover.\n\nPPO introduces two kinds of constraints on policy updates. The first kind is to add an KL-regularization term to the policy gradient \"surrogate\" objective\n\nL_{pg-penalty} (\u03c6) = E_{t} [A_{t} P_{\u03c6}(S\u2081 | S_{<t})/P_{old}(S\u2081 | S_{<t}) - \u03b2KL(P_{old}(\u00b7 | S_{<t}) || P_{\u03c6}(\u00b7 | S_{<t})) ].\n\nHere \u00car[] is the empirical average over a finite batch of samples where sampling and optimization alternates. \u03b2 is the penalty factor. At := A\u0302'(s<\u0131, s\u0131) is GAE, which is detailed in last section.\n\nThe second type is the clipped surrogate objective, expressed as\n\nL_{pg-clip}(\u03c6) = E_{t} [min (A_{t} P_{\u03c6}(S\u2081 | S_{<t})/P_{old}(S\u2081 | S_{<t}), clip (P_{\u03c6}(S\u2081 | S_{<t})/P_{old}(S\u2081 | S_{<t}), 1 - \u03b5, 1 + \u03b5 )) ].\n\nwhere P_{\u03c6}(S\u2081 | S_{<t})/P_{old}(S\u2081 | S_{<t}) is the probability ratio between the new and the old policy. And \u03b5 decides how much the new policy can deviate from the one policy. The clipping operations prevent the policy from changing too much from the older one within one iteration. In the following, we elaborate on how the critic model is optimized."}, {"title": "B. Additional Experimental Details", "content": "Value Function Approximation. The critic model V\u2084(s<1) in PPO algorithm is used to approximate the actual value function VP (s<1). We use the mean absolute value loss to minimize the difference between the predicted values and the actual return values. Specifically, the objective is\n\nL_{critic} = E_{t} [|V_{\u03c6}(S_{<t}) \u2013 V (s_{<t})|].\n\nHere the actual return value is estimated using GAE to balance the bias and variance:\n\nV(s<1) = A\u0302(s<1, S1) + Vold (S<1),\n\nwhere Vold (s<1) is collected during the sampling step in PPO. The critic loss is weight by a factor p2.\n\nA.2. KL-regularization\nAs mentioned in \u00a74.1, we adopt a KL-regularized reinforcement learning approach. Unlike the KL penalty in Lpg-penalty(\u03c6), this regularizer ensures that the policy model p\u03c6 does not diverge significantly from the reference model po. Instead of optimizing this term directly, we incorporate it into the rewards ri. Specifically, we define:\n\nr_{t}^{f} = r_{t} \u2013 p\u2081KL(p_{\u03c6}(\u00b7|[s_{<t}, S_{t}])||p_{o}(\u00b7|[S_{<t}, s_{t}])), where p\u2081 is the penalty factor. In practice, p\u2081 is set to a small value, such as 0.03, to promote exploration.\n\nA.3. Pre-training loss\nFollowing Zheng et al. (2023) and Liu et al. (2024), we incorporate the pre-training loss L_{pt}(\u03c6) o mitigate potential degeneration in the model's ability to produce valid sequences. This is particularly beneficial for helping the actor model recover when it \"falls off the grid\" during PPO. The pre-training data is sourced from the dataset used to train the reference model, and the loss L_{pt}(\u03c6) is weighted by the coefficient p3.\n\nB.1. Graph Generative Pre-training\nGenerative pre-training leverages graph-structured data to learn foundational representations that can be fine-tuned for downstream tasks.\n\nSequence conversion. We convert graphs into sequences of tokens that represent nodes and edges. This transformation involves encoding the molecular structure in a sequential format that captures both the composition and the order of assembly. For instance, we iteratively process the nodes and edges, and insert special tokens to mark key points in the sequence, such as the start and end of generation. Additionally, we apply preprocessing steps like filtering molecules by size, removing hydrogens, or addressing dataset-specific constraints to ensure consistency and suitability for the target tasks.\n\nData splitting. We divide generic datasets into training, validation, and test sets based on splitting ratios 6:2:2. For the molecular datasets, we follow the default settings of the datasets."}, {"title": "B.2. Demonstration Experiment", "content": "We elaborate on how to represent adjacency matrix as sequence and train a transformer decoder on it. We choose planar graphs as the investigation object as it requires a model to be able to capture the rule embedded in the graph. We use G2PT small for this experiment.\n\nSequence conversion. We convert a 2-D adjacency matrix into a 1-D sequence before training the models. Similar to GraphRNN (You et al., 2018b), we consider modeling the strictly lower triangle of the adjacency matrix. To obtain sequence, we flatten the triangle by concatenating the rows together. The i-th row has i \u2013 1 entries, where each entry is either 0 or 1. We employ BFS to determine the node orderings, which is used to permute the rows and columns of the adjacency matrix to reduce the learning complexity (as uniform orderings are generally harder to fit (Chen et al., 2021)).\n\nTraining transformers on adjacency matrices. After obtaining the sequence representation, we prepend and append two special tokens, [SOG] and [EOG], to mark the start and end of the generation of each sequence. The sequence is then tokenized using a vocabulary of size 4, and the transformer is trained on these sequences. Note that no additional token is needed to indicate transitions between rows, as the flattened sequence maintains a fixed correspondence between positions and the referenced node pairs. Specifically, the original row and column indices in the adjacency matrix for the i-th entry in the sequence can be determined as:\n\nrow = \u230a(1 + \u221a(1 + 8i))/2\u230b,  col = i - \u230a(row \u2013 1)(row \u2013 2)/2\u230b\n\nHere \u230a\u00b7\u230b is the ceiling operation. Such correspondence is agnostic to graph size and can be inferred by transformers by using positional embeddings."}, {"title": "B.3. Fine-tuning G2PT for Goal-oriented Generation", "content": "For the goal-oriented generation, we fine-tune G2PT to generate molecules with desired characteristics. Specifically, we consider three properties that are commonly used for molecule optimization whose functions are easily accessed through the Therapeutics Data Commons (TDC) package (Huang et al., 2022).\n\nQuantitative evaluation of druglikeness (QED): range 0-1, the higher the more druglike.\n\nSynthesis accessibility (SA) score: range 1-10, the lower the more synthesizable.\n\nGSK3\u03b2: activity against target protein Glycogen synthase kinase 3 beta, range 0-1, the higher the better activity.\n\nWe use the 85M model pre-trained on GucaMol dataset for all experiments. Below we elaborate on how the RFT and RL algorithms implement each optimization task (property).\n\nRejection-sampling fine-tuning. For RFT algorithm without SBS, we begin by generating samples using the pre-trained model and retain only those that meet the criteria defined by the acceptance function m\u00b2 (\u00b7). We collect 200,000 qualified samples from the generations. Then, we fine-tune the model by initializing it with pre-trained parameters. When combining RFT with SBS, we repeat this process iteratively, using the fine-tuned model from the previous iteration for both sampling and parameter initialization.\n\nFor QED score, we retain samples with scores exceeding thresholds of 0.4, 0.6, 0.8, or 0.9. We do not use the SBS algorithm here, as the pre-trained model generates samples efficiently across all QED score ranges.\n\nFor SA score, we consider thresholds of {< 3.0, < 2.0, < 1.5}. We find that the pre-trained model efficiently generates molecules with SA scores below 2.0 and 3.0 but struggles with scores below 1.5. To address this, we bootstrap the fine-tuned model from the 2.0 threshold to the 1.5 threshold.\n\nFor GSK3\u00df, we consider thresholds in {> 0.2, > 0.4, > 0.6, > 0.8}. We observe that the pre-trained model's score distribution is skewed towards 0, making it challenging to generate satisfactory samples. To resolve this, we fine-tune the model at the 0.2 threshold and progressively bootstrap it through intermediate thresholds (0.4, 0.6) up to 0.8, performing three bootstrapping steps in total.\n\nAll models are trained for 6000 iterations, with batch size of 120 and learning rate of 1e-5. The learning rate gradually decay to 0 using Cosine scheduler."}, {"title": "B.4. Fine-tuning G2PT for Graph Property Prediction", "content": "Datasets. We use eight classification tasks in MoleculeNet (Wu et al., 2018a) following Zhu et al. (2024) to validate the predictive capability of our learned representations.\n\nThe datasets cover two types of molecular properties: biophysical and physiological properties.\n\nBiophysical properties include (1) the HIV dataset for HIV replication inhibition, (2) the Maximum Unbiased Validation (MUV) dataset for virtual screening with nearst neighbor search, (3) the BACE dataset for inhibition of human B-secretase 1 (BACE-1), and (4) the Side Effect Resource (SIDER) dataset for grouping the side effects of marketed drugs into 27 system organ classes.\n\nPhysiological properties include (1) the Blood-brain barrier penetration (BBBP) dataset for predicting barrier permeability of molecules targeting central nervous system, (2) the Tox21, (3) the ClinTox, and (4) the ToxCast datasets that are all associated with certain type of toxicity of the chemical compounds.\n\nWe adopt the scaffold split that divides train, validation and test set by different scaffolds, introduced by Wu et al. (2018b).\n\nFine-tuning details. We fine-tune G2PTsmall and G2PTbase pre-trained on GuacaMol dataset for the downstream tasks. We setup the dropout rate to 0.5 and use a learning rate of 1e-4 for training the linear layer. For the half transformer blocks, we use a learning rate of le-6. We use a batch size of 256 and train the models for 100 epochs. Test result with best validation performance is reported."}, {"title": "B.5. Baselines", "content": "We evaluate our proposed method against a variety of baselines across different datasets. The baselines include models that span diverse methodologies", "categories": "auto-regressive and diffusion graph models. Among them, GRAN (Liao et al., 2019), BiGG (Dai et al., 2020), and BwR (Diamant et al., 2023) are auto-regressive models that sequentially generate graphs. GRAN uses attention-based GNNs to perform block-wise generation, focusing"}]}