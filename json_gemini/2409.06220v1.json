{"title": "CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities", "authors": ["Rashik Shahriar Akash", "Radiful Islam", "S.M. Saiful Islam Badhon", "K. S. M. Tozammel Hossain"], "abstract": "Cervical cancer affects millions of women worldwide and has a significantly higher survival rate when diagnosed early. Pap smears and cervical biopsies are vital screening tools for detecting such cancer. However, the success of these screening processes depends on the skills of cytologists. A recent trend in diagnostic cytology is to apply machine-learning-based models to classify cancer using cell images. These automated models have been shown to perform just as well as, or even better than, expert cytologists. Some notable methods for classifying cervix cancers include ResNet50, VGG16, MobileNet V2, and InceptionV3, based on deep convolutional neural networks (CNN). However, these methods are computationally expensive. We present CerviXpert, a multi-structural Convolutional Neural Network, to identify cervix cancer. We perform extensive experiments on a publicly available dataset, SiPaKMeD, to show the efficacy of our method. CerviXpert presents a promising solution for efficient cervical cancer screening and diagnosis by striking a balance between accuracy and practical feasibility.", "sections": [{"title": "1 Introduction", "content": "Cervical cancer, ranked fourth among women globally, arises from cervix tissue, the lower portion of the uterus [1]. An estimated 604,000 new cases and 342,000 deaths occurred for cervix cancer in 2020, with higher mortality rates in underprivileged regions [2, 3]. The causes for this cancer include smoking, long-term birth control use, multiple childbirths, multiple sexual partners, and poor menstrual hygiene [4-9]. To diagnose cervical cancers, clinicians perform a Pap smear screening on patients, which helps detect malignant cells [10] manually. Due to the limitations of manual diagnosis, there is an increasing trend in automated screening of cervix cancer to achieve better accuracy.\n\nA Pap smear screening involves a gentle scraping of the cervix from both the exterior and the inside to collect cells for analysis.[11] These sample cells are kept on slides and examined via a microscope to detect malignant cells. This manual detection of malignant cells is sometimes challenging as the cells on the slide could dry up, have been coated in mucus or blood, or clump together. As a remedy, a computer-based screening, such as AutoPap and FocalPoint, is employed to capture the microscopic image of cells. A cytologist then analyzes these images to identify abnormal cells. Note that there are three types of cervix cells from the perspective of abnormality: a) normal, b) abnormal, and c) benign. However, this type of computer-based screening is not convenient, as it takes a lot of time, and interpretations of the results depend on the skills of cytologists.\n\nWith the recent advancement of AI and deep learning, researchers are increasingly using various tools to extract information from medical images, including x-ray, cell images [12-16]. Cytologists can use this type of image analysis tools to make efficient diagnosis [17-19]. Some recent research uses deep-learning-based image analysis tools to examine cervix cell images and assist in diagnosing cervix cancer [20-22]. These tools include ResNet50, VGG16, MobileNetV2, and InceptionV3, based on deep convolutional neural networks (CNN). Although these methods demonstrate high diagnostic accuracy rates, they are associated with significant computational demands, posing practical challenges. Addressing this research gap, we propose a deep-learning-based framework-CerviXpert a computationally inexpensive method for classifying cervix cancer using cell images collected via Pap screening. Our key focus is developing an inexpensive method computationally without compromising diagnostic performance. We essentially develop a multi-structural convolutional neural network to solve two problems. The problem asks to classify cell abnormality types, which are normal, abnormal, and benign. These three classes form five different cell types (see Table 2), which the second problem aims to differentiate.\n\nOur key contributions are as follows:\nC1. We present a computationally inexpensive multi-structural convolutional neural network to identify cervix cancer and cell types with relatively high accuracy.\nC2. We perform extensive experiments to evaluate our method against existing methods on a real-world dataset.\nC3. We explained the complexities between our method and existing methods in detail."}, {"title": "2 Literature Review", "content": "We present pertinent research in this section.\n\nCervical cancer detection is a new topic compared to the rapid development of computer-aided diagnostics (CAD). In terms of predicting the correct label of a cell being cancerous or non-cancerous, an expert has almost similar accuracy to AI, in ref [23], The Xception architecture, a deep learning model developed using Convolutional Neural Networks (CNN),488 photos representing 117 women with cancer and 509 cervix cell images obtained from 181 healthy individuals after giving 50 training epochs. When given a T2-weighted picture, deep learning demonstrated better diagnostic ability for detecting cervical cancer than radiologists [24-30].\n\nBhavani et al. [31] shows that support vector machines (SVM), logistic regression (LR), decision trees (DT), k-nearest Neighbors (KNN), and random forests (RF) classification methods have found that the ensemble method produces the best results. Decision Tree produces the highest accuracy with over 91.2% accuracy. The Second Highest was Random Forest with 90.6% accuracy. Similarly, to examine the causes of cervical cancer, this study introduces a DT classification technique. To identify the most useful characteristics for predicting cervical cancer, the authors in [32] exhaustively investigated the feature selection methods of Recursive Feature Elimination (RFE). The used data set was severely unbalanced and had missing values. Classifier accuracy, sensitivity, and specificity have all been compared to visualize the value of class imbalance along with the feature selection in the proposed model. The decision tree improved results by selecting characteristics from RFE and Synthetic Minority Over-sampling Technique, reaching a sensitivity of 100% and an accuracy of 98.72%. The lack of accuracy was caused by missing values due to a numeric data set. In terms of practicality and usefulness, information extracted from visualized images is a little bit ahead. The image-based deep learning algorithms produce almost near-perfect predictions.\n\nFor instance, in ref. [33], for the methodology, a vast number of algorithms was introduced, including decision tree (DT), support vector machine (SVM), K-nearest neighbors (KNN), logistic regression (LR), adaptive boosting, gradient boosting, random forest (RF) and XGBoost. Both prediction and classification results from this study have met expectations. SVM was the highest in terms of accuracy with near perfect 99%. The author of [13] suggests using deep features from the ResNet-34, ResNet-50, and VGG-19 convolutional neural networks to feed a multi-layer perceptron neural network. The feature extraction stage is separated from the classification stage in the machine learning technique that underpins the classification stage. The proposed method demonstrated a high accuracy of 99.23% when tested against the"}, {"title": "3 Datasets", "content": "We use a publicly available dataset, SIPaKMeD [47], to evaluate the existing and proposed methods. We extracted five types of cells, which constituted 25,000 images. Each cell type has ~5,000 images. These cells are collected via a Pap test (a.k.a Pap smear) and labeled by domain experts. Figure 1 illustrates some samples of cervical cells.\n\nThese five types of cells are grouped into three broad categories in terms of cancerous nature. For 3-class classification, the dataset was prepared in three categories-normal, abnormal, and benign class. Normal and abnormal classes have 10000 images each, while the benign class has 5000 images."}, {"title": "3.1 Data Pre-processing", "content": "More than 25,000 pictures of cervical cells have been annotated and included in the SIPaKMeD enhanced dataset. Table 2 describes the number of images from each category and cell. Seventy percent of each class's dataset is utilized for training, twenty percent for validating, and ten percent for testing. Here, a 5-cell categorization was done (dyskeratotic, koilocytotic, metaplastic, superficial, and parabasal). Some examples of advanced artificial neural networks include the convolutional neural network (CNN). The renowned computer scientist developed the convolutional neural network while thinking about how the brain works. A ConvNet is built up of many layers. Figure 2 clearly visualizes the data setting layers.\n\u2022 Forms of layers: First, we'll run a 100-by-100-by-3-pixel picture through a convolutional neural network.\n\u2022 Input Layer: The input layer contains the image's raw data and has the dimensions 100x100x3.\n\u2022 Activation Function Layer: The Activation Function Layer, is also known as the Transfer Function Layer. Activation functions may be split into two categories. To begin, there is the Linear Activation Function and the Nonlinear Activation Function. There are 100x100x12 pixels in the final layer's output.\n\u2022 Convolutional Layer: The dot product of all filters applied to a given picture patch is computed at the convolution layer. Assuming a 100x100x3 input picture, the output won't have the same dimensions if the filter number used is 7. It will produce 100x100x7 as an output.\n\u2022 Fully Connected Layer: Unlike partially connected layers, fully linked layers get data from the layer below them. To do this, it flattens the array into a 1D array of the same length as the class count.\n\u2022 Pooling Layer: The Pool Layer is often placed after the Activation Function Layer. Many distinct pool layer varieties exist. In terms of pool layering methods, max pooling is among the most popular options. The output dimension is 50 by 50 by 12 if it is utilized with a pool size of 2 by 2 and a stride of 2."}, {"title": "4 Methodology", "content": "In this section, we formulate the problem, describe existing methods, and present our approach.\n\nSeveral methods or models are introduced for the classification of both 3-class and 5 types of cells. We detail the approach we used in this study and demonstrate the functionality of the suggested classifiers. Each approach leads to a variety in validation loss and accuracy.\n\nIn this study, we introduce CerviXpert, a multi-structural Convolutional Neural Network (CNN), as a method for identifying cervical cancer. CerviXpert is designed to address the computational expense associated with existing methods such as ResNet50, VGG16, MobileNetV2, and Inception V3, which are based on deep convolutional neural networks (CNN). Convolutional neural networks are gaining more and more attention with each passing day. Using a deep convolutional neural network is the most effective method for accelerating the process of diagnosing crop problems and delivering the appropriate treatment in a short time. Through these experiments and analyses, we aim to showcase CerviXpert as a promising solution for efficient cervical cancer screening and diagnosis, emphasizing its ability to strike a balance between accuracy and practical feasibility in comparison to existing methods.\n\nNow, we describe the existing methods for classifying cervix cancer."}, {"title": "4.1 Existing Methods", "content": "4.1.1 Convolutional Neural Network (CNN)\n\nA form of neural network called a convolutional neural network (CNN) is frequently employed in image and video recognition applications. Convolutional layers are used in CNNs to automatically recognize and extract characteristics from photos or videos. The foundation of a CNN is made up primarily of convolutional layers. They take an input image or feature map and apply a series of learnable filters also referred to as"}, {"title": "4.1.2 ResNet50", "content": "ResNet-50 is a 50-layer deep neural network design including convolutional, batch normalization, and ReLU activation layers in every layer. The structure is broken up into several phases, each of which is made up of various remaining building components. To summarize, each residual block has numerous layers and a fast route link. The input of the block is connected directly to its output through the shortcut connection, which avoids one or more intermediate nodes. In residual connections, the network is trained not on the original mapping between an input and an output block, but on the mapping left behind after the block's processing is complete. As a result, vanishing gradients are no longer an issue, allowing for considerably deeper network training. Bottleneck architecture is used by ResNet-50 to lower the computational cost by decreasing the number of filters in the 1x1 convolutional layers. The next step is an image feature extraction process using 3x3 convolutional layers. As a finishing touch, 1x1 convolutional layers are utilized once more to boost the total number of filters before the output. ResNet-50 has already been trained on the massive ImageNet dataset of over 14 million pictures and 1000 classes. By first pre-training the network, it is able to pick up information from the massive dataset that can be used to additional picture categorization jobs. The performance of the pre-trained network may be enhanced by fine-tuning it on a smaller dataset for a given purpose."}, {"title": "4.1.3 Inception V3", "content": "The latest version of the Inception modules is optimized for speedy calculation. The processing time and the count of parameters necessary for a convolutional filter is reduced by combining them with others. Extracting features from an image is the job of the 3x3 and 5x5 convolutional filters, whereas the 1x1 convolutional filters are employed to reduce the data's dimensionality."}, {"title": "4.1.4 VGG16", "content": "Each layer of the VGG-16 architecture's deep neural network is a mix of convolutional, batch normalization, and ReLU activation layers. The architecture is broken up into"}, {"title": "4.1.5 MobileNet V2", "content": "MobileNet V2's key feature is its use of depth-wise separable convolution, which enables the network to be more computationally efficient without sacrificing accuracy. By using this method, the conventional convolution procedure may be broken down into two distinct phases: a depth-wise convolution and a pointwise convolution. As the name implies, pointwise convolution mixes the results of the depth-wise convolution over all channels, whereas depth-wise convolution applies a single filter to each channel individually. Because of the drastic reduction in parameters and calculation time, this method is particularly well-suited for use in portable and embedded gadgets."}, {"title": "4.2 Proposed Method: CerviXpert", "content": "The model initiates feature extraction with a series of convolutional layers, which are fundamental for capturing spatial hierarchies in the input images. It comprises three convolutional layers. The first convolutional layer begins with 64 filters, each having"}, {"title": "4.2.1 Why CerviXpert?", "content": "The key novelty of our approach lies in the simplicity and efficacy of CerviXpert's CNN architecture. While pre-trained models like ResNet50, VGG16, and Inception V3 boast complex architectures trained on vast datasets like ImageNet, our model CerviXpert diverges by embracing simplicity. By leveraging a streamlined architecture comprising a few convolutional layers followed by max-pooling and dense layers, our model exhibits remarkable efficiency in both training and inference. Furthermore, CerviXpert is trained from scratch, eschewing reliance on pre-existing features learned from unrelated datasets. This departure from transfer learning underscores our commitment to tailoring the model specifically for the nuances of cervical cell classification. Despite starting with randomly initialized weights, our model achieves a commendable accuracy of 98.60%, showcasing its ability to discern relevant features directly"}, {"title": "4.3 Model Evaluation", "content": "The primary focus of this work is to provide a method for reliable cervical cancer diagnosis. Pap smear categorization is done in this regard. The primary metric for assessing the success of such situations is the degree to which they can be classified correctly. As per Section 3.1, samples from the SIPaKMeD dataset can be divided into two or five separate categories. For two-class classifications, the accuracy may be determined using the equation 1, 2, 3, 4.\n\n$Accuracy_{2-class} = (\\frac{TP + TN}{TP + FP + TN + FN} \\times 100)$   (1)\n\nIn addition, the following formula may be used to determine the level of accuracy achieved in a multi-class classification problem:\n\n$Accuracy_{5- class} = (\\frac{Classified samples}{total samples} \\times 100)$  (2)\n\nThere is a significant difference in the likelihood of making a false positive or negative diagnosis between the two groups, making cervical cancer diagnosis a binary classification challenge. In other words, the chance of incorrectly identifying a healthy individual as having cervical cancer is substantially lower than the risk of incorrectly diagnosing an infected individual as being healthy. The effectiveness of the suggested method is measured more by its precision and recall than by its accuracy in this context. The following equations to get these measures of performance:\n\n$Precision = (\\frac{TP}{TP + FP} \\times 100)$ (3)"}, {"title": "5 Results", "content": "To show the efficacy of CerviXpert, we compare the method against existing methods (see Sec. 2) using a real-world dataset (see Sec. 3). In particular, we address the research questions:\n\nRQ1. How does the proposed model fare against the existing models regarding traditional performance measures? (see Sec. 5.2)\nRQ2. How does the model perform in terms of computing time and complexity? (see Sec. 5.3)\nRQ3. Does the model show robustness? (see Sec. 5.4)"}, {"title": "5.1 Experimental Setup", "content": "We use a publicly available SIPaKMeD dataset for evaluating the methods. This dataset contains 25,000 images from five types of cervical cells and falls into three broad classes normal, abnormal, and benign-from the perspective of abnormality. Given the images, we devise two prediction tasks: a) identify the cervix type and b) determine the cell abnormality. Each of the five cell types has \u22485000 instances. As for the abnormality task prediction, the number of normal, abnormal, and benign instances are 10,000, 10,000, and 5,000, respectively."}, {"title": "5.2 Predictive performance of the model (RQ1)", "content": "The study evaluates the performance of four pre-trained deep learning models (InceptionV3, Resnet50, Vgg16, and MobilenetV2) against the proposed method, CerviXpert, using the dataset. In this setting, 70% of the data is used to train the model, 20% of the data is used to validate the model, and the final 10% of the data is used to assess how well the trained model performed. The results showed that the Resnet50 model achieved the highest accuracy of 99.55% in the 3-class cervical cell abnormalities prediction task, followed by Vgg16 with 99.50% accuracy, respectively. CerviXpert, MobileNetV2 and Inception V3 achieved an accuracy of 98.60%, 86.95% and 75.15%, and in the 5-class cervix type prediction task, the Resnet50 model again achieved the highest accuracy of 99.56%, followed by Vgg16, CerviXpert, and MobilenetV2 with 99.48%, 98.04% and 82.79% accuracy, respectively. InceptionV3 achieved an accuracy of 62.42%. CerviXpert stands out by surpassing both MobileNetV2 and InceptionV3 models in terms of both accuracy and computational efficiency. While achieving superior accuracy compared to these models, CerviXpert also outperforms them in computational demands. The results of these five models for 5 and 3 classes are shown in Table 3.\n\nBy examining the CerviXpert model's accuracy, precision, recall, and fl score, the ultimate performance is evaluated."}, {"title": "5.3 Computing performance of the model (RQ2)", "content": "Table 4 and Table 5 summarize the resource utilization during training and testing. The hardware configuration comprised a system equipped with 2 logical CPUs and a total RAM capacity of 12.67 gigabytes (GB). Leveraging the computational prowess of a Tesla T4 GPU, with a dedicated Graphics Processing Unit (GPU) memory total of 15,360 megabytes (MB). This environment is provided by Google Colaboratory.\n\nThe exploration of tradeoffs between accuracy and resource efficiency among models is crucial for identifying the most suitable model for a given task. In our research, we analyzed various resources utilized during both the training and testing phases, including time, RAM usage, GPU usage, and model size. Here's a breakdown of the tradeoffs observed:\nTraining Time: The training time of a model significantly impacts its efficiency and resource utilization during the training phase. We observed variations in training times among the models, with ResNet50 and VGG16 having longer training times compared to MobileNet V2 and our custom model (CerviXpert). The longer training times of"}, {"title": "5.4 Robustness of the model (RQ3)", "content": "To assess the performance of the pre-trained model along with CerviXpert, we employed 5-fold cross-validation. Initially, the dataset was randomly divided into 5 equally sized subsets. Each subset represents a distinct fold in the cross-validation process. Subsequently, the model underwent training and evaluation iteratively for 5 rounds, corresponding to the 5-fold structure. During each iteration, the model was trained on 4 of the subsets, while the remaining 1 subset was designated for validation. This partitioning ensured that the model was exposed to diverse data samples across multiple training and evaluation cycles. This cross-validation approach helps to provide a robust and reliable assessment of the model's performance, as it evaluates the model's generalization capabilities on diverse test sets. The high and consistent classification accuracies obtained across the 5 folds demonstrate the effectiveness of the proposed CerviXpert model in predicting cervix type and cervical cell abnormalities. The obtained result from each model showed in Table 6."}, {"title": "6 Discussion", "content": "Our research underscores the significance of developing resource-efficient deep-learning models for cervical cell classification tasks. The key novelty of our approach lies in the simplicity and efficacy of CerviXpert CNN architecture. While pre-trained models like ResNet50, VGG16, and InceptionV3 boast complex architectures trained on vast datasets like ImageNet, CerviXpert model diverges by embracing simplicity. By leveraging a streamlined architecture comprising a few convolutional layers followed by max-pooling and dense layers, our model exhibits remarkable efficiency in both training and inference.\n\nFurthermore, CerviXpert model is trained from scratch, eschewing reliance on pre-existing features learned from unrelated datasets. This departure from transfer learning underscores our commitment to tailoring the model specifically for the nuances of cervical cell classification. Despite starting with randomly initialized weights, our model achieves a commendable accuracy of 98.60%, showcasing its ability to discern relevant features directly from the dataset.\n\nThe superiority of CerviXpert approach is further underscored by its parameter efficiency. With fewer parameters compared to pre-trained models, CerviXpert architecture not only conserves memory but also accelerates inference speed, making it an appealing choice for resource-constrained environments. Our research highlights the importance of exploring tradeoffs between accuracy and resource efficiency in the development of deep learning models. By optimizing resource utilization and prioritizing efficiency, we can address the challenges of deploying AI technologies in resource-constrained environments. Moving forward, further research efforts should focus on refining lightweight architectures, exploring novel optimization techniques,"}, {"title": "7 Limitations and Future Work", "content": "One possible limitation of employing deep convolutional neural networks for medical diagnostics is the lack of interpretability of the models. It can be difficult to grasp how the model is making its predictions, which might make it challenging to trust the model in a therapeutic environment. To overcome this, researchers can utilize techniques such as visualization and feature attribution to determine the features the model is using to produce its predictions. Additionally, it is crucial to ensure that the model is resistant to perturbations in the data and generalizes effectively to unseen data. This can be achieved by meticulous validation and testing of the model. In future work, our research aims to advance the field by developing a layered combination of deep learning and machine learning models. The primary objective is to improve the model's performance on datasets with higher dimensions, allowing for a more comprehensive analysis of cervical cell samples."}]}